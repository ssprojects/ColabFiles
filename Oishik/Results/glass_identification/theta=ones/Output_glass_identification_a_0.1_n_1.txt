theta for epoch 0 : tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 0 : 185.88434639150833
Test loss for epoch 0 : 185.497167030491
Test Precision for epoch 0 : 0.26153846153846155
Test Recall for epoch 0 : 0.26153846153846155
Test F1 for epoch 0 : 0.26153846153846155


theta for epoch 1 : tensor([[1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 0.9000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000,
         1.1000, 0.9000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 0.9000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 0.9000, 1.1000, 1.1000, 0.9000, 1.1000, 0.9000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 0.9000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 1 : 184.39086012522952
Test loss for epoch 1 : 184.0824831043639
Test Precision for epoch 1 : 0.26153846153846155
Test Recall for epoch 1 : 0.26153846153846155
Test F1 for epoch 1 : 0.26153846153846155


theta for epoch 2 : tensor([[1.1945, 1.1973, 1.1991, 1.1984, 1.1984, 1.1955, 1.1966, 1.1945, 1.1945,
         1.1898, 1.1895, 1.1898, 1.1899, 1.1898, 1.1873, 1.1898, 1.1898, 1.1849,
         1.1468, 1.1279, 1.1557, 1.1483, 1.1618, 1.1624, 1.1611, 1.1625, 1.1625,
         1.1289, 1.1644, 1.1646, 1.1644, 1.1574, 1.1646, 1.1602, 1.1575, 1.1646,
         1.1937, 1.1936, 1.1936, 1.1937, 1.1937, 1.1914, 1.1936, 1.1968, 1.1886,
         1.1991, 1.1996, 1.1998, 1.1999, 1.1995, 1.1998, 1.1971, 1.1999, 1.1999],
        [1.1858, 1.1229, 0.7999, 1.1695, 1.1776, 1.1888, 1.1837, 1.1889, 1.1889,
         1.1952, 1.1977, 1.1900, 1.1990, 1.1943, 1.1996, 1.1948, 1.1863, 1.1993,
         1.1307, 1.1369, 0.8002, 1.1132, 1.1761, 1.1855, 1.1810, 1.1858, 1.1858,
         1.1736, 1.0425, 1.1875, 1.1828, 1.0601, 1.1874, 1.1847, 1.1860, 1.1844,
         1.1973, 1.1982, 1.1981, 1.1975, 1.1952, 1.1979, 1.1981, 0.8015, 1.1934,
         0.9595, 1.1980, 1.1982, 1.1984, 1.1863, 1.1983, 0.8507, 1.1984, 1.1984],
        [1.1766, 1.1720, 1.1667, 1.1644, 1.1502, 1.1765, 1.1588, 1.1766, 1.1766,
         1.1938, 1.1927, 1.1939, 1.1942, 1.1939, 0.8492, 1.1938, 1.1922, 1.1833,
         1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001,
         1.1509, 1.1475, 1.1747, 1.1740, 1.1440, 1.1747, 1.1739, 1.1742, 1.1747,
         1.1956, 1.1958, 1.1958, 1.1949, 1.1958, 1.1958, 1.1958, 0.8817, 1.0334,
         1.1969, 1.1992, 1.1994, 1.1994, 1.1963, 1.1994, 1.1933, 1.1994, 1.1994],
        [1.1699, 1.1692, 1.1197, 1.0911, 1.1662, 1.1672, 1.1674, 1.1699, 1.1699,
         1.1911, 1.1864, 1.1871, 1.1867, 1.1911, 1.1807, 1.1910, 1.1911, 1.0566,
         1.1652, 1.0969, 1.1643, 1.1620, 1.1613, 1.1591, 1.1641, 1.1657, 1.1657,
         1.2001, 1.1991, 1.1974, 1.1989, 1.2000, 1.1971, 1.2000, 1.1975, 1.1970,
         1.1941, 1.1918, 1.1917, 1.1930, 1.1939, 1.1841, 1.1933, 0.8398, 1.1839,
         1.1991, 1.1991, 1.1984, 1.1996, 1.1992, 1.1990, 1.1990, 1.1996, 1.1998],
        [1.1998, 1.1993, 0.8072, 0.8225, 1.1990, 1.1998, 1.1997, 1.1998, 1.1998,
         1.1984, 1.1969, 1.1948, 0.9565, 1.1987, 0.8094, 1.1977, 1.1987, 1.1932,
         1.1997, 0.9442, 0.9117, 1.1985, 1.2000, 1.2000, 1.1990, 1.2000, 1.2000,
         0.8146, 0.8163, 1.1999, 1.1995, 0.8485, 1.1999, 1.1948, 1.1999, 1.1998,
         1.0895, 1.0530, 1.0459, 1.0735, 1.1321, 1.1431, 1.0739, 1.1911, 1.1881,
         0.9484, 0.9728, 1.1817, 1.1926, 0.9702, 1.1922, 0.8606, 1.1905, 1.1939],
        [1.1706, 1.1658, 1.1320, 1.1590, 1.1449, 1.1635, 1.1625, 1.1706, 1.1706,
         1.1845, 1.1790, 1.1788, 1.1771, 1.1907, 0.8427, 1.1847, 1.1907, 1.1601,
         1.1625, 1.1378, 1.0364, 1.1322, 1.1635, 1.1645, 1.1564, 1.1659, 1.1659,
         1.1510, 1.0646, 1.1683, 1.0969, 1.1023, 1.0940, 1.1586, 1.1439, 1.1683,
         1.1923, 1.1673, 1.1926, 1.1915, 1.0753, 1.0277, 1.1926, 0.8079, 0.8004,
         1.1989, 1.1957, 1.1970, 1.1968, 1.1972, 1.1889, 1.1990, 1.1962, 1.1884]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 2 : 183.69365343469815
Test loss for epoch 2 : 183.42012181195082
Test Precision for epoch 2 : 0.26153846153846155
Test Recall for epoch 2 : 0.26153846153846155
Test F1 for epoch 2 : 0.26153846153846155


theta for epoch 3 : tensor([[1.2906, 1.2953, 1.2985, 1.2973, 1.2974, 1.2923, 1.2941, 1.2905, 1.2905,
         1.1861, 1.1835, 1.1862, 1.1783, 1.1860, 1.1574, 1.1855, 1.1864, 1.1621,
         1.2153, 1.1875, 1.2304, 1.2178, 1.2385, 1.2394, 1.2375, 1.2394, 1.2394,
         1.1955, 1.2452, 1.2457, 1.2454, 1.2350, 1.2456, 1.2392, 1.2353, 1.2457,
         1.2856, 1.2861, 1.2861, 1.2859, 1.2859, 1.2798, 1.2856, 1.2734, 1.2688,
         1.1909, 1.1957, 1.1951, 1.1964, 1.1941, 1.1936, 1.1733, 1.1964, 1.1965],
        [1.2777, 1.1858, 0.8438, 1.2527, 1.2651, 1.2824, 1.2744, 1.2825, 1.2825,
         1.1709, 1.1984, 1.1498, 1.2412, 1.1640, 1.2768, 1.1686, 1.1397, 1.2630,
         1.1974, 1.2067, 0.8213, 1.1734, 1.2625, 1.2768, 1.2697, 1.2773, 1.2773,
         1.2540, 1.0883, 1.2764, 1.2690, 1.1121, 1.2762, 1.2718, 1.2740, 1.2716,
         1.2860, 1.2903, 1.2896, 1.2864, 1.2792, 1.2883, 1.2893, 0.7539, 1.2705,
         0.9214, 1.2138, 1.2094, 1.2127, 1.1469, 1.2106, 0.7774, 1.2129, 1.2131],
        [1.2622, 1.2550, 1.2479, 1.2435, 1.2197, 1.2620, 1.2332, 1.2622, 1.2622,
         1.1987, 1.1881, 1.1995, 1.1901, 1.1994, 0.7788, 1.1989, 1.1865, 1.1507,
         1.3004, 1.3004, 1.3004, 1.3004, 1.3003, 1.3003, 1.3004, 1.3001, 1.3001,
         1.2258, 1.2210, 1.2600, 1.2588, 1.2164, 1.2598, 1.2587, 1.2591, 1.2599,
         1.2877, 1.2885, 1.2885, 1.2856, 1.2879, 1.2877, 1.2885, 0.9429, 1.0898,
         1.1789, 1.2041, 1.2019, 1.2021, 1.1695, 1.2017, 1.1629, 1.2017, 1.2022],
        [1.2502, 1.2494, 1.1719, 1.1216, 1.2443, 1.2459, 1.2463, 1.2502, 1.2502,
         1.1909, 1.1686, 1.1683, 1.1619, 1.1911, 1.1418, 1.1889, 1.1904, 0.9867,
         1.2450, 1.1405, 1.2449, 1.2403, 1.2387, 1.2350, 1.2434, 1.2456, 1.2456,
         1.2999, 1.2967, 1.2924, 1.2962, 1.2996, 1.2918, 1.2995, 1.2926, 1.2916,
         1.2863, 1.2817, 1.2811, 1.2835, 1.2851, 1.2656, 1.2844, 0.8945, 1.2605,
         1.1970, 1.1863, 1.1690, 1.1918, 1.1940, 1.1749, 1.1974, 1.1919, 1.1984],
        [1.2842, 1.2601, 0.7114, 0.7349, 1.2327, 1.2811, 1.2738, 1.2842, 1.2842,
         1.2055, 1.1817, 1.1650, 0.9135, 1.2129, 0.7203, 1.1894, 1.2128, 1.1534,
         1.2393, 0.9239, 0.8854, 1.1811, 1.2874, 1.2875, 1.2021, 1.2897, 1.2897,
         0.7284, 0.7346, 1.2987, 1.2973, 0.7980, 1.2988, 1.2543, 1.2989, 1.2985,
         1.1406, 1.0806, 1.0674, 1.1169, 1.2002, 1.2152, 1.1171, 1.2834, 1.2788,
         0.9065, 0.9533, 1.1535, 1.1965, 0.9439, 1.1907, 0.7902, 1.1839, 1.2042],
        [1.2545, 1.2475, 1.2000, 1.2375, 1.2170, 1.2440, 1.2426, 1.2545, 1.2545,
         1.1797, 1.1577, 1.1609, 1.1446, 1.2109, 0.7669, 1.1802, 1.2106, 1.1184,
         1.2425, 1.2077, 1.0642, 1.1996, 1.2440, 1.2454, 1.2337, 1.2475, 1.2475,
         1.2251, 1.1160, 1.2491, 1.1553, 1.1630, 1.1514, 1.2356, 1.2160, 1.2490,
         1.2796, 1.2422, 1.2806, 1.2774, 1.1350, 1.0759, 1.2806, 0.8499, 0.7823,
         1.2452, 1.2000, 1.2122, 1.2107, 1.2103, 1.1623, 1.2449, 1.2023, 1.1609]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 3 : 184.15203325756642
Test loss for epoch 3 : 183.9461999461695
Test Precision for epoch 3 : 0.26153846153846155
Test Recall for epoch 3 : 0.26153846153846155
Test F1 for epoch 3 : 0.26153846153846155


theta for epoch 4 : tensor([[1.2724, 1.2860, 1.3010, 1.2948, 1.2960, 1.2768, 1.2816, 1.2723, 1.2723,
         1.2374, 1.2341, 1.2374, 1.2273, 1.2372, 1.2017, 1.2366, 1.2376, 1.2072,
         1.2089, 1.1745, 1.2350, 1.2137, 1.2434, 1.2448, 1.2426, 1.2448, 1.2448,
         1.2382, 1.3058, 1.2988, 1.2992, 1.2917, 1.2995, 1.2904, 1.2827, 1.2987,
         1.3728, 1.3741, 1.3740, 1.3736, 1.3738, 1.3640, 1.3731, 1.3515, 1.3473,
         1.2327, 1.2392, 1.2379, 1.2397, 1.2371, 1.2358, 1.2068, 1.2398, 1.2399],
        [1.2506, 1.1397, 0.8003, 1.2152, 1.2311, 1.2600, 1.2448, 1.2603, 1.2603,
         1.2169, 1.2529, 1.1891, 1.3080, 1.2078, 1.3570, 1.2139, 1.1762, 1.3371,
         1.1619, 1.1737, 0.7757, 1.1358, 1.2448, 1.2711, 1.2571, 1.2721, 1.2721,
         1.2635, 1.0673, 1.3024, 1.2871, 1.0948, 1.3027, 1.2929, 1.2974, 1.2915,
         1.3379, 1.3541, 1.3513, 1.3398, 1.3202, 1.3479, 1.3503, 0.6865, 1.3009,
         0.9225, 1.2602, 1.2525, 1.2578, 1.1434, 1.2545, 0.7375, 1.2582, 1.2585],
        [1.2468, 1.2349, 1.2254, 1.2187, 1.1860, 1.2466, 1.2033, 1.2468, 1.2468,
         1.2538, 1.2401, 1.2548, 1.2427, 1.2546, 0.8210, 1.2539, 1.2380, 1.1936,
         1.2868, 1.2989, 1.3125, 1.2978, 1.2683, 1.2678, 1.2822, 1.2636, 1.2636,
         1.2797, 1.2748, 1.3217, 1.3207, 1.2675, 1.3223, 1.3206, 1.3208, 1.3216,
         1.3759, 1.3775, 1.3775, 1.3720, 1.3765, 1.3765, 1.3773, 1.0141, 1.1522,
         1.2161, 1.2533, 1.2497, 1.2499, 1.2008, 1.2494, 1.1934, 1.2493, 1.2500],
        [1.2291, 1.2282, 1.1312, 1.0740, 1.2204, 1.2223, 1.2231, 1.2291, 1.2291,
         1.2438, 1.2151, 1.2148, 1.2064, 1.2440, 1.1832, 1.2412, 1.2431, 1.0129,
         1.2544, 1.1159, 1.2597, 1.2481, 1.2419, 1.2358, 1.2513, 1.2539, 1.2539,
         1.3531, 1.3133, 1.2914, 1.3078, 1.3480, 1.2887, 1.3461, 1.2919, 1.2876,
         1.3727, 1.3648, 1.3634, 1.3677, 1.3710, 1.3404, 1.3690, 0.9604, 1.3345,
         1.2426, 1.2251, 1.1964, 1.2331, 1.2375, 1.2056, 1.2438, 1.2332, 1.2434],
        [1.2694, 1.2206, 0.6216, 0.6528, 1.1833, 1.2605, 1.2441, 1.2693, 1.2693,
         1.2542, 1.2168, 1.1891, 0.9282, 1.2656, 0.6684, 1.2288, 1.2653, 1.1689,
         1.1930, 0.8635, 0.8235, 1.1213, 1.2841, 1.2852, 1.1466, 1.2954, 1.2954,
         0.6402, 0.6483, 1.3408, 1.2963, 0.7278, 1.3389, 1.2034, 1.3393, 1.3354,
         1.1905, 1.1030, 1.0831, 1.1584, 1.2687, 1.2881, 1.1577, 1.3770, 1.3709,
         0.9016, 0.9719, 1.1633, 1.2345, 0.9549, 1.2238, 0.7491, 1.2133, 1.2469],
        [1.2317, 1.2218, 1.1661, 1.2097, 1.1830, 1.2169, 1.2151, 1.2317, 1.2317,
         1.2278, 1.1989, 1.2033, 1.1821, 1.2694, 0.8114, 1.2285, 1.2691, 1.1521,
         1.2351, 1.1895, 1.0239, 1.1777, 1.2364, 1.2385, 1.2215, 1.2417, 1.2417,
         1.2427, 1.1117, 1.2740, 1.1498, 1.1653, 1.1456, 1.2539, 1.2255, 1.2739,
         1.3393, 1.2748, 1.3419, 1.3342, 1.1530, 1.0827, 1.3417, 0.8680, 0.7376,
         1.3144, 1.2479, 1.2660, 1.2638, 1.2628, 1.1903, 1.3139, 1.2512, 1.1883]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 4 : 184.52226339612466
Test loss for epoch 4 : 184.36898031368221
Test Precision for epoch 4 : 0.26153846153846155
Test Recall for epoch 4 : 0.26153846153846155
Test F1 for epoch 4 : 0.26153846153846155


theta for epoch 5 : tensor([[1.3037, 1.3228, 1.3445, 1.3357, 1.3373, 1.3098, 1.3163, 1.3036, 1.3036,
         1.3013, 1.2977, 1.3015, 1.2898, 1.3011, 1.2610, 1.3005, 1.3016, 1.2667,
         1.2477, 1.2121, 1.2800, 1.2539, 1.2872, 1.2888, 1.2870, 1.2886, 1.2886,
         1.2729, 1.3583, 1.3407, 1.3424, 1.3409, 1.3425, 1.3316, 1.3181, 1.3407,
         1.3336, 1.3355, 1.3354, 1.3348, 1.3352, 1.3227, 1.3340, 1.3079, 1.3036,
         1.2886, 1.2963, 1.2942, 1.2964, 1.2939, 1.2916, 1.2564, 1.2965, 1.2966],
        [1.2598, 1.1308, 0.7988, 1.2157, 1.2340, 1.2736, 1.2517, 1.2740, 1.2740,
         1.2778, 1.3204, 1.2447, 1.3848, 1.2669, 1.4435, 1.2742, 1.2294, 1.4192,
         1.1667, 1.1825, 0.7746, 1.1399, 1.2647, 1.3009, 1.2819, 1.3022, 1.3022,
         1.2746, 1.0497, 1.3268, 1.3037, 1.0799, 1.3280, 1.3136, 1.3194, 1.3094,
         1.2936, 1.3139, 1.3103, 1.2959, 1.2732, 1.3061, 1.3089, 0.6191, 1.2520,
         0.9537, 1.3238, 1.3135, 1.3201, 1.1678, 1.3159, 0.7334, 1.3206, 1.3209],
        [1.2748, 1.2602, 1.2515, 1.2427, 1.2023, 1.2746, 1.2217, 1.2747, 1.2747,
         1.3209, 1.3051, 1.3222, 1.3083, 1.3219, 0.8793, 1.3212, 1.3025, 1.2517,
         1.3196, 1.3394, 1.3609, 1.3377, 1.2880, 1.2872, 1.3120, 1.2798, 1.2798,
         1.3284, 1.3236, 1.3754, 1.3753, 1.3136, 1.3771, 1.3753, 1.3745, 1.3754,
         1.3382, 1.3408, 1.3405, 1.3327, 1.3393, 1.3394, 1.3403, 0.9732, 1.1067,
         1.2686, 1.3151, 1.3104, 1.3105, 1.2483, 1.3100, 1.2410, 1.3098, 1.3107],
        [1.2590, 1.2584, 1.1539, 1.0944, 1.2492, 1.2509, 1.2521, 1.2590, 1.2590,
         1.3118, 1.2787, 1.2787, 1.2689, 1.3120, 1.2439, 1.3089, 1.3111, 1.0623,
         1.3048, 1.1553, 1.3133, 1.2981, 1.2893, 1.2820, 1.3012, 1.3035, 1.3035,
         1.4075, 1.3299, 1.2875, 1.3176, 1.3977, 1.2828, 1.3929, 1.2886, 1.2809,
         1.3345, 1.3242, 1.3224, 1.3277, 1.3324, 1.2962, 1.3294, 0.9189, 1.2902,
         1.3049, 1.2822, 1.2446, 1.2917, 1.2982, 1.2562, 1.3069, 1.2919, 1.3047],
        [1.3075, 1.2440, 0.6098, 0.6584, 1.1993, 1.2952, 1.2733, 1.3074, 1.3074,
         1.3222, 1.2772, 1.2431, 0.9780, 1.3358, 0.6722, 1.2916, 1.3354, 1.2178,
         1.2187, 0.8880, 0.8518, 1.1405, 1.3304, 1.3320, 1.1684, 1.3455, 1.3455,
         0.6386, 0.6527, 1.4031, 1.3300, 0.7460, 1.4003, 1.1942, 1.4008, 1.3945,
         1.1520, 1.0558, 1.0342, 1.1168, 1.2396, 1.2628, 1.1159, 1.3955, 1.3813,
         0.9354, 1.0210, 1.2049, 1.2947, 0.9989, 1.2809, 0.7554, 1.2682, 1.3101],
        [1.2421, 1.2300, 1.1692, 1.2175, 1.1838, 1.2233, 1.2213, 1.2421, 1.2421,
         1.2925, 1.2589, 1.2641, 1.2404, 1.3413, 0.8759, 1.2933, 1.3410, 1.2074,
         1.2607, 1.2080, 1.0250, 1.1922, 1.2616, 1.2641, 1.2432, 1.2680, 1.2680,
         1.2554, 1.1052, 1.2900, 1.1354, 1.1622, 1.1301, 1.2642, 1.2250, 1.2899,
         1.2974, 1.2262, 1.3007, 1.2912, 1.1021, 1.0301, 1.3003, 0.8182, 0.6761,
         1.3938, 1.3125, 1.3348, 1.3322, 1.3306, 1.2400, 1.3932, 1.3166, 1.2375]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 5 : 183.19437251726072
Test loss for epoch 5 : 183.00905072559732
Test Precision for epoch 5 : 0.26153846153846155
Test Recall for epoch 5 : 0.26153846153846155
Test F1 for epoch 5 : 0.26153846153846155


theta for epoch 6 : tensor([[1.3553, 1.3785, 1.4050, 1.3943, 1.3963, 1.3627, 1.3705, 1.3552, 1.3552,
         1.3341, 1.3303, 1.3348, 1.3218, 1.3336, 1.2911, 1.3333, 1.3343, 1.2958,
         1.2959, 1.2598, 1.3330, 1.3033, 1.3388, 1.3405, 1.3393, 1.3403, 1.3403,
         1.2332, 1.3275, 1.3063, 1.3085, 1.3078, 1.3085, 1.2963, 1.2806, 1.3063,
         1.3047, 1.3073, 1.3071, 1.3062, 1.3071, 1.2918, 1.3052, 1.2753, 1.2707,
         1.3328, 1.3410, 1.3378, 1.3401, 1.3387, 1.3348, 1.2946, 1.3403, 1.3403],
        [1.2963, 1.1537, 0.8308, 1.2459, 1.2656, 1.3135, 1.2865, 1.3139, 1.3139,
         1.3008, 1.3526, 1.2612, 1.4317, 1.2876, 1.5088, 1.2966, 1.2433, 1.4758,
         1.1953, 1.2149, 0.8031, 1.1688, 1.3051, 1.3489, 1.3264, 1.3505, 1.3505,
         1.2402, 1.0006, 1.3012, 1.2731, 1.0320, 1.3034, 1.2853, 1.2920, 1.2793,
         1.2628, 1.2882, 1.2834, 1.2659, 1.2400, 1.2790, 1.2815, 0.5686, 1.2178,
         0.9820, 1.3811, 1.3673, 1.3744, 1.1845, 1.3700, 0.7326, 1.3753, 1.3755],
        [1.3226, 1.3061, 1.2986, 1.2881, 1.2416, 1.3224, 1.2624, 1.3225, 1.3225,
         1.3591, 1.3410, 1.3611, 1.3458, 1.3600, 0.9171, 1.3596, 1.3375, 1.2808,
         1.3687, 1.3948, 1.4226, 1.3926, 1.3260, 1.3252, 1.3588, 1.3148, 1.3148,
         1.2946, 1.2900, 1.3471, 1.3474, 1.2790, 1.3494, 1.3473, 1.3462, 1.3472,
         1.3115, 1.3149, 1.3146, 1.3044, 1.3133, 1.3136, 1.3141, 0.9450, 1.0733,
         1.3097, 1.3659, 1.3597, 1.3594, 1.2839, 1.3591, 1.2784, 1.3587, 1.3597],
        [1.3094, 1.3092, 1.1997, 1.1387, 1.2990, 1.3005, 1.3020, 1.3094, 1.3094,
         1.3561, 1.3177, 1.3191, 1.3081, 1.3560, 1.2833, 1.3530, 1.3551, 1.0895,
         1.3661, 1.2089, 1.3774, 1.3593, 1.3481, 1.3399, 1.3621, 1.3640, 1.3640,
         1.4178, 1.3034, 1.2469, 1.2863, 1.4024, 1.2410, 1.3946, 1.2483, 1.2384,
         1.3092, 1.2964, 1.2940, 1.3006, 1.3071, 1.2650, 1.3027, 0.8938, 1.2598,
         1.3609, 1.3313, 1.2838, 1.3416, 1.3520, 1.2974, 1.3645, 1.3420, 1.3578],
        [1.3557, 1.2784, 0.6060, 0.6730, 1.2261, 1.3402, 1.3129, 1.3557, 1.3557,
         1.3579, 1.3032, 1.2613, 0.9941, 1.3742, 0.6474, 1.3203, 1.3736, 1.2305,
         1.2447, 0.9115, 0.8811, 1.1601, 1.3779, 1.3802, 1.1911, 1.3970, 1.3970,
         0.5955, 0.6140, 1.3875, 1.2967, 0.7126, 1.3843, 1.1435, 1.3849, 1.3765,
         1.1301, 1.0237, 1.0004, 1.0916, 1.2282, 1.2557, 1.0902, 1.4329, 1.4113,
         0.9490, 1.0504, 1.2256, 1.3373, 1.0222, 1.3191, 0.7425, 1.3041, 1.3562],
        [1.2793, 1.2658, 1.2025, 1.2536, 1.2139, 1.2575, 1.2553, 1.2793, 1.2793,
         1.3164, 1.2798, 1.2853, 1.2633, 1.3738, 0.9225, 1.3178, 1.3737, 1.2277,
         1.3053, 1.2476, 1.0534, 1.2285, 1.3055, 1.3082, 1.2845, 1.3127, 1.3127,
         1.2214, 1.0614, 1.2580, 1.0865, 1.1200, 1.0808, 1.2287, 1.1833, 1.2581,
         1.2677, 1.1890, 1.2716, 1.2605, 1.0635, 0.9900, 1.2712, 0.7857, 0.6294,
         1.4592, 1.3576, 1.3857, 1.3822, 1.3794, 1.2662, 1.4585, 1.3627, 1.2631]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 6 : 183.9234880358146
Test loss for epoch 6 : 183.7381445493987
Test Precision for epoch 6 : 0.26153846153846155
Test Recall for epoch 6 : 0.26153846153846155
Test F1 for epoch 6 : 0.26153846153846155


theta for epoch 7 : tensor([[1.4115, 1.4384, 1.4693, 1.4570, 1.4594, 1.4200, 1.4291, 1.4113, 1.4113,
         1.3369, 1.3333, 1.3384, 1.3244, 1.3359, 1.2933, 1.3362, 1.3369, 1.2958,
         1.3112, 1.2746, 1.3516, 1.3198, 1.3566, 1.3582, 1.3577, 1.3579, 1.3579,
         1.2297, 1.3304, 1.3059, 1.3088, 1.3094, 1.3087, 1.2957, 1.2777, 1.3060,
         1.2915, 1.2949, 1.2945, 1.2934, 1.2949, 1.2768, 1.2921, 1.2593, 1.2541,
         1.3369, 1.3446, 1.3404, 1.3423, 1.3432, 1.3367, 1.2939, 1.3428, 1.3427],
        [1.3457, 1.1920, 0.8789, 1.2904, 1.3109, 1.3657, 1.3344, 1.3661, 1.3661,
         1.2905, 1.3514, 1.2450, 1.4468, 1.2752, 1.5485, 1.2856, 1.2247, 1.5034,
         1.2124, 1.2358, 0.8287, 1.1874, 1.3326, 1.3842, 1.3585, 1.3859, 1.3859,
         1.2535, 1.0080, 1.3191, 1.2882, 1.0396, 1.3225, 1.3020, 1.3090, 1.2943,
         1.2501, 1.2811, 1.2748, 1.2539, 1.2251, 1.2706, 1.2724, 0.5394, 1.2026,
         0.9636, 1.3867, 1.3693, 1.3763, 1.1570, 1.3719, 0.6980, 1.3777, 1.3776],
        [1.3803, 1.3626, 1.3565, 1.3441, 1.2927, 1.3802, 1.3145, 1.3802, 1.3802,
         1.3675, 1.3472, 1.3704, 1.3542, 1.3680, 0.9321, 1.3681, 1.3424, 1.2810,
         1.4068, 1.4398, 1.4750, 1.4375, 1.3523, 1.3515, 1.3947, 1.3380, 1.3380,
         1.2955, 1.2916, 1.3521, 1.3531, 1.2798, 1.3551, 1.3527, 1.3512, 1.3522,
         1.3006, 1.3050, 1.3044, 1.2918, 1.3033, 1.3037, 1.3038, 0.9347, 1.0571,
         1.3108, 1.3758, 1.3682, 1.3671, 1.2796, 1.3673, 1.2772, 1.3666, 1.3675],
        [1.3614, 1.3616, 1.2473, 1.1849, 1.3504, 1.3517, 1.3536, 1.3613, 1.3613,
         1.3632, 1.3194, 1.3228, 1.3102, 1.3628, 1.2861, 1.3601, 1.3619, 1.0811,
         1.3872, 1.2236, 1.4011, 1.3805, 1.3664, 1.3570, 1.3828, 1.3841, 1.3841,
         1.4637, 1.3294, 1.2636, 1.3092, 1.4455, 1.2569, 1.4362, 1.2654, 1.2539,
         1.2959, 1.2806, 1.2777, 1.2853, 1.2940, 1.2460, 1.2880, 0.8812, 1.2418,
         1.3710, 1.3336, 1.2768, 1.3447, 1.3600, 1.2920, 1.3768, 1.3452, 1.3643],
        [1.4012, 1.3089, 0.5934, 0.6793, 1.2482, 1.3821, 1.3489, 1.4011, 1.4011,
         1.3575, 1.2935, 1.2444, 0.9758, 1.3766, 0.5985, 1.3130, 1.3757, 1.2087,
         1.2366, 0.9013, 0.8787, 1.1469, 1.3912, 1.3944, 1.1806, 1.4151, 1.4151,
         0.5602, 0.5847, 1.3881, 1.2795, 0.6885, 1.3846, 1.1057, 1.3855, 1.3746,
         1.1329, 1.0158, 0.9909, 1.0912, 1.2413, 1.2733, 1.0892, 1.4881, 1.4607,
         0.9234, 1.0371, 1.2043, 1.3354, 1.0036, 1.3128, 0.6990, 1.2960, 1.3581],
        [1.3320, 1.3176, 1.2534, 1.3060, 1.2614, 1.3079, 1.3057, 1.3319, 1.3319,
         1.3052, 1.2669, 1.2726, 1.2534, 1.3697, 0.9490, 1.3072, 1.3700, 1.2161,
         1.3434, 1.2822, 1.0833, 1.2600, 1.3421, 1.3446, 1.3188, 1.3496, 1.3496,
         1.2379, 1.0760, 1.2740, 1.0936, 1.1332, 1.0878, 1.2431, 1.1934, 1.2742,
         1.2574, 1.1711, 1.2620, 1.2491, 1.0451, 0.9706, 1.2613, 0.7781, 0.6069,
         1.4799, 1.3542, 1.3886, 1.3841, 1.3796, 1.2463, 1.4788, 1.3604, 1.2427]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 7 : 184.02504722212217
Test loss for epoch 7 : 183.8554262194064
Test Precision for epoch 7 : 0.26153846153846155
Test Recall for epoch 7 : 0.26153846153846155
Test F1 for epoch 7 : 0.26153846153846155


theta for epoch 8 : tensor([[1.4207, 1.4517, 1.4875, 1.4733, 1.4761, 1.4304, 1.4408, 1.4205, 1.4205,
         1.3509, 1.3479, 1.3536, 1.3392, 1.3494, 1.3097, 1.3505, 1.3505, 1.3084,
         1.2970, 1.2606, 1.3397, 1.3067, 1.3436, 1.3451, 1.3455, 1.3446, 1.3446,
         1.2564, 1.3613, 1.3339, 1.3376, 1.3395, 1.3373, 1.3239, 1.3041, 1.3341,
         1.2943, 1.2984, 1.2978, 1.2965, 1.2987, 1.2782, 1.2950, 1.2604, 1.2544,
         1.3500, 1.3560, 1.3505, 1.3517, 1.3562, 1.3463, 1.3040, 1.3525, 1.3522],
        [1.3567, 1.1940, 0.8964, 1.2981, 1.3184, 1.3797, 1.3439, 1.3799, 1.3799,
         1.2761, 1.3466, 1.2246, 1.4592, 1.2586, 1.5875, 1.2705, 1.2018, 1.5292,
         1.1998, 1.2268, 0.8294, 1.1769, 1.3285, 1.3873, 1.3590, 1.3891, 1.3891,
         1.2895, 1.0400, 1.3582, 1.3252, 1.0717, 1.3626, 1.3404, 1.3475, 1.3312,
         1.2501, 1.2869, 1.2791, 1.2548, 1.2230, 1.2752, 1.2761, 0.5244, 1.2005,
         0.9491, 1.3942, 1.3730, 1.3793, 1.1321, 1.3752, 0.6715, 1.3814, 1.3810],
        [1.3874, 1.3692, 1.3646, 1.3500, 1.2949, 1.3874, 1.3173, 1.3873, 1.3873,
         1.3829, 1.3610, 1.3870, 1.3703, 1.3829, 0.9581, 1.3838, 1.3545, 1.2898,
         1.4173, 1.4578, 1.5012, 1.4554, 1.3511, 1.3505, 1.4032, 1.3340, 1.3340,
         1.3218, 1.3185, 1.3811, 1.3827, 1.3062, 1.3847, 1.3821, 1.3804, 1.3813,
         1.3036, 1.3090, 1.3081, 1.2932, 1.3073, 1.3079, 1.3073, 0.9404, 1.0565,
         1.3173, 1.3899, 1.3808, 1.3787, 1.2807, 1.3795, 1.2829, 1.3784, 1.3792],
        [1.3609, 1.3616, 1.2436, 1.1809, 1.3497, 1.3507, 1.3528, 1.3608, 1.3608,
         1.3699, 1.3204, 1.3262, 1.3118, 1.3689, 1.2886, 1.3668, 1.3682, 1.0723,
         1.3710, 1.2030, 1.3867, 1.3645, 1.3479, 1.3374, 1.3663, 1.3669, 1.3669,
         1.5260, 1.3777, 1.3051, 1.3552, 1.5059, 1.2978, 1.4954, 1.3070, 1.2943,
         1.2930, 1.2750, 1.2715, 1.2804, 1.2914, 1.2375, 1.2837, 0.8797, 1.2345,
         1.3792, 1.3334, 1.2670, 1.3450, 1.3659, 1.2837, 1.3875, 1.3459, 1.3682],
        [1.3992, 1.2938, 0.5505, 0.6489, 1.2263, 1.3765, 1.3380, 1.3990, 1.3990,
         1.3503, 1.2766, 1.2201, 0.9489, 1.3722, 0.5419, 1.2986, 1.3710, 1.1794,
         1.2000, 0.8636, 0.8475, 1.1066, 1.3713, 1.3755, 1.1426, 1.3995, 1.3995,
         0.5305, 0.5622, 1.4009, 1.2747, 0.6711, 1.3973, 1.0781, 1.3988, 1.3852,
         1.1544, 1.0268, 1.0002, 1.1096, 1.2722, 1.3085, 1.1070, 1.5550, 1.5229,
         0.8881, 1.0139, 1.1742, 1.3251, 0.9752, 1.2975, 0.6470, 1.2792, 1.3515],
        [1.3458, 1.3315, 1.2700, 1.3219, 1.2714, 1.3195, 1.3175, 1.3456, 1.3456,
         1.3005, 1.2620, 1.2676, 1.2531, 1.3713, 0.9893, 1.3033, 1.3722, 1.2145,
         1.3486, 1.2851, 1.0867, 1.2600, 1.3453, 1.3473, 1.3200, 1.3527, 1.3527,
         1.2761, 1.1134, 1.3112, 1.1242, 1.1689, 1.1183, 1.2793, 1.2260, 1.3116,
         1.2597, 1.1655, 1.2650, 1.2504, 1.0397, 0.9644, 1.2640, 0.7856, 0.5991,
         1.4949, 1.3439, 1.3849, 1.3794, 1.3728, 1.2192, 1.4934, 1.3514, 1.2152]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 8 : 183.36454106848538
Test loss for epoch 8 : 183.2143501080526
Test Precision for epoch 8 : 0.26153846153846155
Test Recall for epoch 8 : 0.26153846153846155
Test F1 for epoch 8 : 0.26153846153846155


theta for epoch 9 : tensor([[1.3985, 1.4329, 1.4730, 1.4572, 1.4603, 1.4092, 1.4208, 1.3983, 1.3983,
         1.3740, 1.3717, 1.3780, 1.3638, 1.3717, 1.3369, 1.3738, 1.3731, 1.3311,
         1.2889, 1.2539, 1.3330, 1.2996, 1.3349, 1.3361, 1.3380, 1.3354, 1.3354,
         1.2989, 1.4068, 1.3767, 1.3810, 1.3845, 1.3805, 1.3671, 1.3455, 1.3770,
         1.3087, 1.3136, 1.3126, 1.3112, 1.3142, 1.2913, 1.3094, 1.2744, 1.2673,
         1.3742, 1.3779, 1.3711, 1.3711, 1.3800, 1.3662, 1.3264, 1.3723, 1.3717],
        [1.3352, 1.1658, 0.8831, 1.2744, 1.2942, 1.3605, 1.3213, 1.3606, 1.3606,
         1.2610, 1.3416, 1.2035, 1.4721, 1.2412, 1.6279, 1.2548, 1.1782, 1.5561,
         1.1846, 1.2154, 0.8292, 1.1643, 1.3209, 1.3867, 1.3563, 1.3886, 1.3886,
         1.3370, 1.0843, 1.4077, 1.3731, 1.1161, 1.4130, 1.3896, 1.3964, 1.3787,
         1.2587, 1.3014, 1.2920, 1.2643, 1.2297, 1.2886, 1.2885, 0.5192, 1.2077,
         0.9445, 1.4087, 1.3839, 1.3890, 1.1160, 1.3856, 0.6591, 1.3918, 1.3909],
        [1.3583, 1.3399, 1.3363, 1.3201, 1.2626, 1.3584, 1.2854, 1.3581, 1.3581,
         1.4023, 1.3790, 1.4077, 1.3911, 1.4017, 0.9909, 1.4035, 1.3708, 1.3036,
         1.4245, 1.4727, 1.5244, 1.4704, 1.3469, 1.3466, 1.4088, 1.3270, 1.3270,
         1.3607, 1.3580, 1.4217, 1.4241, 1.3454, 1.4259, 1.4233, 1.4211, 1.4220,
         1.3164, 1.3227, 1.3215, 1.3044, 1.3211, 1.3219, 1.3205, 0.9572, 1.0669,
         1.3304, 1.4097, 1.3993, 1.3959, 1.2888, 1.3974, 1.2964, 1.3959, 1.3965],
        [1.3289, 1.3301, 1.2096, 1.1469, 1.3177, 1.3183, 1.3207, 1.3288, 1.3288,
         1.3786, 1.3237, 1.3323, 1.3162, 1.3772, 1.2943, 1.3757, 1.3765, 1.0669,
         1.3498, 1.1790, 1.3675, 1.3437, 1.3244, 1.3130, 1.3449, 1.3447, 1.3447,
         1.5943, 1.4337, 1.3548, 1.4091, 1.5725, 1.3471, 1.5610, 1.3570, 1.3432,
         1.2996, 1.2791, 1.2750, 1.2850, 1.2984, 1.2391, 1.2889, 0.8895, 1.2377,
         1.3917, 1.3373, 1.2615, 1.3490, 1.3761, 1.2794, 1.4027, 1.3503, 1.3758],
        [1.3666, 1.2517, 0.4903, 0.5973, 1.1795, 1.3412, 1.2989, 1.3664, 1.3664,
         1.3373, 1.2539, 1.1900, 0.9156, 1.3621, 0.4803, 1.2785, 1.3606, 1.1443,
         1.1548, 0.8171, 0.8074, 1.0580, 1.3420, 1.3472, 1.0964, 1.3744, 1.3744,
         0.5048, 0.5444, 1.4197, 1.2760, 0.6582, 1.4161, 1.0557, 1.4182, 1.4018,
         1.1863, 1.0482, 1.0201, 1.1386, 1.3132, 1.3536, 1.1353, 1.6288, 1.5927,
         0.8477, 0.9858, 1.1396, 1.3104, 0.9417, 1.2779, 0.5910, 1.2580, 1.3408],
        [1.3251, 1.3112, 1.2527, 1.3035, 1.2482, 1.2971, 1.2954, 1.3248, 1.3248,
         1.2992, 1.2615, 1.2667, 1.2586, 1.3758, 1.0363, 1.3030, 1.3774, 1.2187,
         1.3481, 1.2832, 1.0872, 1.2553, 1.3424, 1.3438, 1.3154, 1.3495, 1.3495,
         1.3236, 1.1609, 1.3572, 1.1646, 1.2143, 1.1583, 1.3248, 1.2678, 1.3578,
         1.2692, 1.1669, 1.2753, 1.2591, 1.0414, 0.9653, 1.2740, 0.8020, 0.5996,
         1.5139, 1.3375, 1.3854, 1.3786, 1.3695, 1.1953, 1.5121, 1.3463, 1.1907]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 9 : 182.8560686646368
Test loss for epoch 9 : 182.72624554572178
Test Precision for epoch 9 : 0.26153846153846155
Test Recall for epoch 9 : 0.26153846153846155
Test F1 for epoch 9 : 0.26153846153846155


theta for epoch 10 : tensor([[1.3854, 1.4232, 1.4674, 1.4503, 1.4534, 1.3970, 1.4098, 1.3851, 1.3851,
         1.3906, 1.3892, 1.3961, 1.3823, 1.3876, 1.3582, 1.3909, 1.3894, 1.3478,
         1.2909, 1.2579, 1.3352, 1.3024, 1.3351, 1.3361, 1.3395, 1.3352, 1.3352,
         1.3095, 1.4193, 1.3861, 1.3914, 1.3967, 1.3905, 1.3775, 1.3539, 1.3865,
         1.3285, 1.3342, 1.3329, 1.3313, 1.3352, 1.3102, 1.3293, 1.2948, 1.2862,
         1.3983, 1.3996, 1.3915, 1.3902, 1.4037, 1.3859, 1.3492, 1.3919, 1.3910],
        [1.3193, 1.1435, 0.8761, 1.2566, 1.2758, 1.3470, 1.3042, 1.3470, 1.3470,
         1.2489, 1.3400, 1.1854, 1.4888, 1.2269, 1.6722, 1.2422, 1.1575, 1.5870,
         1.1778, 1.2125, 0.8366, 1.1603, 1.3211, 1.3934, 1.3613, 1.3952, 1.3952,
         1.3507, 1.0965, 1.4222, 1.3864, 1.1280, 1.4286, 1.4046, 1.4105, 1.3915,
         1.2717, 1.3204, 1.3093, 1.2782, 1.2411, 1.3067, 1.3052, 0.5188, 1.2198,
         0.9429, 1.4250, 1.3967, 1.4002, 1.1026, 1.3977, 0.6519, 1.4039, 1.4024],
        [1.3340, 1.3155, 1.3131, 1.2954, 1.2356, 1.3341, 1.2587, 1.3337, 1.3337,
         1.4138, 1.3894, 1.4207, 1.4044, 1.4127, 1.0183, 1.4155, 1.3796, 1.3101,
         1.4477, 1.5027, 1.5616, 1.5006, 1.3598, 1.3601, 1.4308, 1.3375, 1.3375,
         1.3638, 1.3616, 1.4256, 1.4288, 1.3488, 1.4303, 1.4280, 1.4252, 1.4260,
         1.3345, 1.3417, 1.3401, 1.3210, 1.3403, 1.3414, 1.3390, 0.9802, 1.0836,
         1.3422, 1.4280, 1.4163, 1.4115, 1.2960, 1.4138, 1.3093, 1.4119, 1.4122],
        [1.3056, 1.3074, 1.1857, 1.1236, 1.2946, 1.2948, 1.2975, 1.3054, 1.3054,
         1.3855, 1.3255, 1.3374, 1.3197, 1.3834, 1.2997, 1.3829, 1.3830, 1.0624,
         1.3408, 1.1693, 1.3603, 1.3352, 1.3131, 1.3006, 1.3357, 1.3343, 1.3343,
         1.6379, 1.4634, 1.3774, 1.4362, 1.6142, 1.3692, 1.6014, 1.3798, 1.3649,
         1.3127, 1.2898, 1.2850, 1.2962, 1.3124, 1.2478, 1.3006, 0.9085, 1.2488,
         1.4078, 1.3451, 1.2602, 1.3562, 1.3901, 1.2788, 1.4218, 1.3579, 1.3865],
        [1.3445, 1.2203, 0.4449, 0.5609, 1.1430, 1.3163, 1.2702, 1.3442, 1.3442,
         1.3259, 1.2333, 1.1634, 0.8877, 1.3532, 0.4265, 1.2607, 1.3514, 1.1123,
         1.1252, 0.7876, 0.7846, 1.0254, 1.3267, 1.3333, 1.0670, 1.3635, 1.3635,
         0.4668, 0.5132, 1.4067, 1.2501, 0.6289, 1.4034, 1.0129, 1.4060, 1.3872,
         1.2102, 1.0613, 1.0315, 1.1596, 1.3468, 1.3917, 1.1554, 1.6993, 1.6586,
         0.8156, 0.9658, 1.1119, 1.3008, 0.9158, 1.2639, 0.5452, 1.2426, 1.3351],
        [1.3077, 1.2942, 1.2394, 1.2888, 1.2287, 1.2780, 1.2766, 1.3073, 1.3073,
         1.2876, 1.2512, 1.2556, 1.2551, 1.3700, 1.0727, 1.2923, 1.3722, 1.2132,
         1.3512, 1.2857, 1.0929, 1.2551, 1.3431, 1.3438, 1.3145, 1.3498, 1.3498,
         1.3369, 1.1762, 1.3677, 1.1712, 1.2259, 1.1642, 1.3359, 1.2745, 1.3686,
         1.2810, 1.1701, 1.2877, 1.2701, 1.0449, 0.9678, 1.2860, 0.8217, 0.6020,
         1.5434, 1.3429, 1.3977, 1.3896, 1.3774, 1.1828, 1.5412, 1.3530, 1.1777]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 10 : 183.32947373544036
Test loss for epoch 10 : 183.2234635926603
Test Precision for epoch 10 : 0.26153846153846155
Test Recall for epoch 10 : 0.26153846153846155
Test F1 for epoch 10 : 0.26153846153846155


theta for epoch 11 : tensor([[1.3970, 1.4376, 1.4854, 1.4673, 1.4703, 1.4094, 1.4233, 1.3967, 1.3967,
         1.3967, 1.3962, 1.4038, 1.3904, 1.3931, 1.3686, 1.3974, 1.3951, 1.3540,
         1.2948, 1.2635, 1.3381, 1.3070, 1.3368, 1.3375, 1.3426, 1.3363, 1.3363,
         1.2870, 1.3980, 1.3625, 1.3685, 1.3752, 1.3673, 1.3548, 1.3295, 1.3630,
         1.3497, 1.3561, 1.3544, 1.3528, 1.3576, 1.3305, 1.3505, 1.3172, 1.3069,
         1.4122, 1.4116, 1.4023, 1.3996, 1.4174, 1.3960, 1.3619, 1.4017, 1.4005],
        [1.3134, 1.1311, 0.8775, 1.2485, 1.2676, 1.3436, 1.2971, 1.3433, 1.3433,
         1.2542, 1.3554, 1.1851, 1.5211, 1.2301, 1.7283, 1.2472, 1.1545, 1.6317,
         1.1741, 1.2130, 0.8440, 1.1596, 1.3249, 1.4035, 1.3698, 1.4053, 1.4053,
         1.3303, 1.0751, 1.4026, 1.3659, 1.1065, 1.4098, 1.3856, 1.3905, 1.3704,
         1.2846, 1.3394, 1.3266, 1.2921, 1.2525, 1.3251, 1.3220, 0.5169, 1.2323,
         0.9318, 1.4338, 1.4026, 1.4042, 1.0812, 1.4027, 0.6347, 1.4088, 1.4066],
        [1.3212, 1.3030, 1.3020, 1.2828, 1.2207, 1.3214, 1.2442, 1.3209, 1.3209,
         1.4172, 1.3917, 1.4255, 1.4096, 1.4155, 1.0382, 1.4193, 1.3803, 1.3084,
         1.4909, 1.5511, 1.6154, 1.5493, 1.3950, 1.3958, 1.4732, 1.3709, 1.3709,
         1.3354, 1.3335, 1.3977, 1.4015, 1.3206, 1.4027, 1.4008, 1.3974, 1.3982,
         1.3543, 1.3625, 1.3605, 1.3394, 1.3613, 1.3627, 1.3591, 1.0055, 1.1028,
         1.3460, 1.4386, 1.4257, 1.4194, 1.2959, 1.4225, 1.3147, 1.4202, 1.4202],
        [1.2965, 1.2990, 1.1767, 1.1155, 1.2860, 1.2856, 1.2885, 1.2963, 1.2963,
         1.3890, 1.3242, 1.3399, 1.3208, 1.3863, 1.3024, 1.3870, 1.3861, 1.0562,
         1.3412, 1.1705, 1.3623, 1.3363, 1.3112, 1.2978, 1.3361, 1.3332, 1.3332,
         1.6642, 1.4749, 1.3813, 1.4446, 1.6382, 1.3726, 1.6239, 1.3840, 1.3680,
         1.3261, 1.3011, 1.2952, 1.3078, 1.3271, 1.2576, 1.3126, 0.9300, 1.2618,
         1.4210, 1.3502, 1.2564, 1.3599, 1.4014, 1.2753, 1.4380, 1.3623, 1.3936],
        [1.3548, 1.2239, 0.4453, 0.5678, 1.1427, 1.3243, 1.2757, 1.3544, 1.3544,
         1.3409, 1.2423, 1.1692, 0.8960, 1.3697, 0.4191, 1.2717, 1.3677, 1.1139,
         1.1357, 0.8008, 0.8029, 1.0346, 1.3457, 1.3534, 1.0790, 1.3854, 1.3854,
         0.4573, 0.5083, 1.3805, 1.2162, 0.6198, 1.3779, 0.9711, 1.3808, 1.3602,
         1.2000, 1.0422, 1.0114, 1.1471, 1.3448, 1.3939, 1.1420, 1.7394, 1.6924,
         0.8182, 0.9765, 1.1141, 1.3146, 0.9220, 1.2749, 0.5405, 1.2529, 1.3518],
        [1.2980, 1.2850, 1.2338, 1.2818, 1.2171, 1.2667, 1.2653, 1.2975, 1.2975,
         1.2633, 1.2284, 1.2315, 1.2387, 1.3519, 1.0912, 1.2690, 1.3547, 1.1942,
         1.3535, 1.2876, 1.0974, 1.2544, 1.3430, 1.3430, 1.3127, 1.3492, 1.3492,
         1.3165, 1.1580, 1.3452, 1.1457, 1.2042, 1.1380, 1.3140, 1.2490, 1.3462,
         1.2900, 1.1697, 1.2974, 1.2783, 1.0444, 0.9661, 1.2953, 0.8388, 0.6000,
         1.5882, 1.3673, 1.4284, 1.4190, 1.4036, 1.1905, 1.5857, 1.3787, 1.1848]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 11 : 182.79649353964408
Test loss for epoch 11 : 182.69241566011254
Test Precision for epoch 11 : 0.26153846153846155
Test Recall for epoch 11 : 0.26153846153846155
Test F1 for epoch 11 : 0.26153846153846155


theta for epoch 12 : tensor([[1.4258, 1.4688, 1.5197, 1.5009, 1.5036, 1.4388, 1.4537, 1.4254, 1.4254,
         1.3874, 1.3877, 1.3959, 1.3830, 1.3833, 1.3632, 1.3886, 1.3855, 1.3447,
         1.2811, 1.2508, 1.3224, 1.2937, 1.3210, 1.3214, 1.3279, 1.3201, 1.3201,
         1.2594, 1.3716, 1.3338, 1.3406, 1.3488, 1.3390, 1.3271, 1.3000, 1.3345,
         1.3725, 1.3797, 1.3776, 1.3759, 1.3816, 1.3526, 1.3733, 1.3417, 1.3297,
         1.4026, 1.4005, 1.3903, 1.3862, 1.4077, 1.3833, 1.3511, 1.3887, 1.3871],
        [1.3183, 1.1297, 0.8887, 1.2512, 1.2703, 1.3509, 1.3008, 1.3504, 1.3504,
         1.2656, 1.3768, 1.1910, 1.5591, 1.2393, 1.7889, 1.2583, 1.1577, 1.6817,
         1.1608, 1.2038, 0.8402, 1.1492, 1.3188, 1.4036, 1.3684, 1.4052, 1.4052,
         1.3065, 1.0501, 1.3792, 1.3417, 1.0813, 1.3871, 1.3631, 1.3666, 1.3456,
         1.2988, 1.3600, 1.3453, 1.3072, 1.2656, 1.3451, 1.3400, 0.5157, 1.2466,
         0.9000, 1.4210, 1.3873, 1.3870, 1.0419, 1.3866, 0.5981, 1.3925, 1.3896],
        [1.3224, 1.3047, 1.3052, 1.2847, 1.2207, 1.3226, 1.2443, 1.3221, 1.3221,
         1.4102, 1.3839, 1.4200, 1.4046, 1.4080, 1.0497, 1.4127, 1.3709, 1.2969,
         1.5356, 1.6009, 1.6702, 1.5993, 1.4321, 1.4336, 1.5174, 1.4063, 1.4063,
         1.3054, 1.3036, 1.3674, 1.3720, 1.2908, 1.3728, 1.3715, 1.3672, 1.3680,
         1.3770, 1.3863, 1.3837, 1.3608, 1.3855, 1.3872, 1.3821, 1.0348, 1.1259,
         1.3312, 1.4302, 1.4162, 1.4083, 1.2779, 1.4123, 1.3017, 1.4096, 1.4092],
        [1.3007, 1.3039, 1.1815, 1.1216, 1.2908, 1.2899, 1.2930, 1.3004, 1.3004,
         1.3836, 1.3144, 1.3343, 1.3138, 1.3803, 1.2970, 1.3823, 1.3803, 1.0431,
         1.3372, 1.1688, 1.3598, 1.3331, 1.3050, 1.2906, 1.3321, 1.3273, 1.3273,
         1.6896, 1.4857, 1.3841, 1.4520, 1.6614, 1.3750, 1.6455, 1.3871, 1.3700,
         1.3416, 1.3146, 1.3075, 1.3213, 1.3442, 1.2701, 1.3265, 0.9552, 1.2782,
         1.4168, 1.3386, 1.2367, 1.3464, 1.3955, 1.2555, 1.4367, 1.3494, 1.3833],
        [1.3821, 1.2456, 0.4657, 0.5939, 1.1609, 1.3497, 1.2989, 1.3816, 1.3816,
         1.3625, 1.2592, 1.1842, 0.9152, 1.3925, 0.4264, 1.2906, 1.3903, 1.1251,
         1.1566, 0.8260, 0.8326, 1.0549, 1.3728, 1.3817, 1.1020, 1.4152, 1.4152,
         0.4761, 0.5306, 1.3648, 1.1976, 0.6375, 1.3634, 0.9512, 1.3664, 1.3444,
         1.1755, 1.0097, 0.9780, 1.1206, 1.3281, 1.3814, 1.1146, 1.7673, 1.7131,
         0.8251, 0.9902, 1.1175, 1.3263, 0.9314, 1.2848, 0.5437, 1.2623, 1.3662],
        [1.2980, 1.2857, 1.2382, 1.2848, 1.2157, 1.2651, 1.2638, 1.2974, 1.2974,
         1.2254, 1.1921, 1.1939, 1.2082, 1.3198, 1.0909, 1.2321, 1.3231, 1.1611,
         1.3427, 1.2770, 1.0894, 1.2412, 1.3299, 1.3292, 1.2981, 1.3354, 1.3354,
         1.2918, 1.1359, 1.3177, 1.1157, 1.1780, 1.1070, 1.2876, 1.2185, 1.3189,
         1.2976, 1.1675, 1.3056, 1.2853, 1.0421, 0.9624, 1.3031, 0.8556, 0.5964,
         1.6361, 1.3955, 1.4628, 1.4520, 1.4331, 1.2017, 1.6333, 1.4081, 1.1953]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 12 : 182.37013851931565
Test loss for epoch 12 : 182.25743984143014
Test Precision for epoch 12 : 0.26153846153846155
Test Recall for epoch 12 : 0.26153846153846155
Test F1 for epoch 12 : 0.26153846153846155


theta for epoch 13 : tensor([[1.4625, 1.5078, 1.5614, 1.5420, 1.5446, 1.4761, 1.4920, 1.4622, 1.4622,
         1.3686, 1.3697, 1.3785, 1.3661, 1.3640, 1.3481, 1.3702, 1.3664, 1.3260,
         1.2450, 1.2153, 1.2843, 1.2580, 1.2832, 1.2835, 1.2911, 1.2820, 1.2820,
         1.2386, 1.3516, 1.3115, 1.3191, 1.3288, 1.3171, 1.3060, 1.2769, 1.3123,
         1.3982, 1.4062, 1.4036, 1.4018, 1.4086, 1.3777, 1.3990, 1.3695, 1.3557,
         1.3792, 1.3758, 1.3646, 1.3592, 1.3844, 1.3571, 1.3269, 1.3622, 1.3602],
        [1.3317, 1.1374, 0.9084, 1.2625, 1.2817, 1.3664, 1.3130, 1.3658, 1.3658,
         1.2747, 1.3959, 1.1946, 1.5950, 1.2463, 1.8482, 1.2671, 1.1586, 1.7300,
         1.1305, 1.1772, 0.8187, 1.1216, 1.2946, 1.3846, 1.3483, 1.3861, 1.3861,
         1.2910, 1.0334, 1.3633, 1.3253, 1.0646, 1.3720, 1.3487, 1.3504, 1.3285,
         1.3164, 1.3838, 1.3672, 1.3258, 1.2822, 1.3686, 1.3613, 0.5186, 1.2646,
         0.8570, 1.3947, 1.3590, 1.3567, 0.9924, 1.3574, 0.5520, 1.3631, 1.3595],
        [1.3362, 1.3193, 1.3215, 1.2999, 1.2343, 1.3366, 1.2578, 1.3358, 1.3358,
         1.3994, 1.3728, 1.4109, 1.3963, 1.3967, 1.0608, 1.4025, 1.3583, 1.2831,
         1.5575, 1.6281, 1.7026, 1.6269, 1.4469, 1.4492, 1.5393, 1.4196, 1.4196,
         1.2875, 1.2859, 1.3480, 1.3537, 1.2732, 1.3539, 1.3535, 1.3480, 1.3488,
         1.4048, 1.4152, 1.4120, 1.3875, 1.4148, 1.4169, 1.4102, 1.0705, 1.1556,
         1.3075, 1.4119, 1.3969, 1.3872, 1.2517, 1.3923, 1.2805, 1.3890, 1.3882],
        [1.3145, 1.3184, 1.1966, 1.1381, 1.3053, 1.3038, 1.3071, 1.3142, 1.3142,
         1.3722, 1.2989, 1.3233, 1.3013, 1.3682, 1.2863, 1.3715, 1.3685, 1.0264,
         1.3186, 1.1540, 1.3428, 1.3156, 1.2844, 1.2691, 1.3138, 1.3069, 1.3069,
         1.7164, 1.4982, 1.3887, 1.4611, 1.6861, 1.3793, 1.6686, 1.3920, 1.3739,
         1.3614, 1.3328, 1.3244, 1.3394, 1.3660, 1.2877, 1.3450, 0.9861, 1.3001,
         1.4009, 1.3158, 1.2066, 1.3212, 1.3783, 1.2249, 1.4240, 1.3250, 1.3612],
        [1.4130, 1.2707, 0.4883, 0.6224, 1.1822, 1.3786, 1.3256, 1.4125, 1.4125,
         1.3747, 1.2668, 1.1907, 0.9260, 1.4057, 0.4263, 1.3004, 1.4034, 1.1274,
         1.1635, 0.8387, 0.8497, 1.0617, 1.3847, 1.3950, 1.1120, 1.4297, 1.4297,
         0.4994, 0.5576, 1.3557, 1.1861, 0.6602, 1.3559, 0.9386, 1.3588, 1.3353,
         1.1552, 0.9810, 0.9483, 1.0982, 1.3159, 1.3736, 1.0913, 1.8011, 1.7398,
         0.8178, 0.9897, 1.1063, 1.3219, 0.9266, 1.2791, 0.5349, 1.2561, 1.3645],
        [1.3069, 1.2955, 1.2522, 1.2970, 1.2240, 1.2727, 1.2715, 1.3062, 1.3062,
         1.1813, 1.1499, 1.1503, 1.1718, 1.2806, 1.0826, 1.1889, 1.2843, 1.1222,
         1.3132, 1.2482, 1.0640, 1.2102, 1.2982, 1.2969, 1.2655, 1.3032, 1.3032,
         1.2747, 1.1219, 1.2967, 1.0928, 1.1592, 1.0827, 1.2686, 1.1946, 1.2982,
         1.3070, 1.1671, 1.3157, 1.2942, 1.0416, 0.9607, 1.3126, 0.8758, 0.5962,
         1.6781, 1.4175, 1.4912, 1.4789, 1.4560, 1.2062, 1.6749, 1.4313, 1.1991]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 13 : 182.13501630235214
Test loss for epoch 13 : 182.01870812393364
Test Precision for epoch 13 : 0.26153846153846155
Test Recall for epoch 13 : 0.26153846153846155
Test F1 for epoch 13 : 0.26153846153846155


theta for epoch 14 : tensor([[1.4919, 1.5394, 1.5957, 1.5758, 1.5781, 1.5061, 1.5229, 1.4916, 1.4916,
         1.3484, 1.3504, 1.3596, 1.3478, 1.3433, 1.3317, 1.3504, 1.3459, 1.3064,
         1.2106, 1.1818, 1.2474, 1.2238, 1.2466, 1.2466, 1.2554, 1.2449, 1.2449,
         1.2284, 1.3418, 1.2993, 1.3078, 1.3191, 1.3054, 1.2952, 1.2640, 1.3002,
         1.4257, 1.4346, 1.4315, 1.4296, 1.4374, 1.4047, 1.4265, 1.3994, 1.3840,
         1.3569, 1.3520, 1.3401, 1.3330, 1.3621, 1.3318, 1.3045, 1.3365, 1.3341],
        [1.3356, 1.1360, 0.9189, 1.2644, 1.2837, 1.3724, 1.3156, 1.3716, 1.3716,
         1.2821, 1.4136, 1.1967, 1.6297, 1.2516, 1.9066, 1.2743, 1.1580, 1.7775,
         1.0989, 1.1490, 0.7952, 1.0927, 1.2682, 1.3628, 1.3258, 1.3641, 1.3641,
         1.2846, 1.0259, 1.3561, 1.3178, 1.0569, 1.3656, 1.3433, 1.3429, 1.3201,
         1.3350, 1.4089, 1.3902, 1.3454, 1.3001, 1.3934, 1.3838, 0.5233, 1.2839,
         0.8144, 1.3670, 1.3297, 1.3249, 0.9438, 1.3270, 0.5085, 1.3322, 1.3279],
        [1.3424, 1.3265, 1.3306, 1.3080, 1.2412, 1.3429, 1.2644, 1.3420, 1.3420,
         1.3887, 1.3622, 1.4019, 1.3883, 1.3854, 1.0741, 1.3923, 1.3459, 1.2707,
         1.5675, 1.6436, 1.7231, 1.6428, 1.4502, 1.4535, 1.5496, 1.4216, 1.4216,
         1.2819, 1.2805, 1.3403, 1.3471, 1.2680, 1.3467, 1.3473, 1.3405, 1.3412,
         1.4353, 1.4467, 1.4429, 1.4168, 1.4468, 1.4493, 1.4407, 1.1098, 1.1891,
         1.2870, 1.3954, 1.3796, 1.3677, 1.2293, 1.3741, 1.2637, 1.3702, 1.3688],
        [1.3200, 1.3247, 1.2039, 1.1472, 1.3117, 1.3095, 1.3130, 1.3196, 1.3196,
         1.3584, 1.2817, 1.3107, 1.2871, 1.3537, 1.2741, 1.3586, 1.3544, 1.0097,
         1.3000, 1.1403, 1.3257, 1.2981, 1.2639, 1.2476, 1.2953, 1.2862, 1.2862,
         1.7453, 1.5134, 1.3961, 1.4730, 1.7131, 1.3865, 1.6941, 1.3999, 1.3806,
         1.3837, 1.3536, 1.3437, 1.3600, 1.3903, 1.3081, 1.3658, 1.0201, 1.3250,
         1.3850, 1.2927, 1.1769, 1.2954, 1.3611, 1.1944, 1.4115, 1.3000, 1.3382],
        [1.4327, 1.2843, 0.5000, 0.6400, 1.1916, 1.3961, 1.3409, 1.4321, 1.4321,
         1.3771, 1.2644, 1.1873, 0.9262, 1.4091, 0.4157, 1.3003, 1.4067, 1.1198,
         1.1618, 0.8422, 0.8575, 1.0597, 1.3880, 1.4000, 1.1136, 1.4358, 1.4358,
         0.5202, 0.5825, 1.3512, 1.1790, 0.6814, 1.3533, 0.9285, 1.3561, 1.3309,
         1.1435, 0.9607, 0.9268, 1.0845, 1.3127, 1.3750, 1.0764, 1.8438, 1.7756,
         0.8004, 0.9794, 1.0859, 1.3083, 0.9119, 1.2644, 0.5163, 1.2408, 1.3538],
        [1.3070, 1.2967, 1.2581, 1.3007, 1.2242, 1.2717, 1.2705, 1.3063, 1.3063,
         1.1358, 1.1070, 1.1061, 1.1347, 1.2390, 1.0722, 1.1444, 1.2433, 1.0833,
         1.2824, 1.2191, 1.0397, 1.1791, 1.2650, 1.2629, 1.2317, 1.2691, 1.2691,
         1.2665, 1.1176, 1.2838, 1.0787, 1.1494, 1.0669, 1.2582, 1.1790, 1.2857,
         1.3169, 1.1675, 1.3263, 1.3038, 1.0423, 0.9602, 1.3226, 0.8982, 0.5987,
         1.7162, 1.4352, 1.5156, 1.5017, 1.4744, 1.2065, 1.7126, 1.4504, 1.1986]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 14 : 182.31584322237532
Test loss for epoch 14 : 182.20020042628138
Test Precision for epoch 14 : 0.26153846153846155
Test Recall for epoch 14 : 0.26153846153846155
Test F1 for epoch 14 : 0.26153846153846155


theta for epoch 15 : tensor([[1.5010, 1.5506, 1.6093, 1.5892, 1.5912, 1.5157, 1.5336, 1.5006, 1.5006,
         1.3406, 1.3436, 1.3533, 1.3421, 1.3350, 1.3280, 1.3431, 1.3379, 1.2997,
         1.2047, 1.1773, 1.2383, 1.2178, 1.2373, 1.2370, 1.2470, 1.2352, 1.2352,
         1.2302, 1.3437, 1.2988, 1.3083, 1.3212, 1.3054, 1.2963, 1.2630, 1.2999,
         1.4494, 1.4592, 1.4555, 1.4536, 1.4624, 1.4282, 1.4502, 1.4257, 1.4089,
         1.3486, 1.3415, 1.3291, 1.3201, 1.3536, 1.3202, 1.2970, 1.3241, 1.3212],
        [1.3161, 1.1123, 0.9053, 1.2431, 1.2627, 1.3547, 1.2951, 1.3538, 1.3538,
         1.2941, 1.4358, 1.2035, 1.6685, 1.2615, 1.9682, 1.2861, 1.1622, 1.8288,
         1.0839, 1.1371, 0.7864, 1.0805, 1.2574, 1.3558, 1.3184, 1.3569, 1.3569,
         1.2866, 1.0268, 1.3571, 1.3187, 1.0578, 1.3676, 1.3463, 1.3438, 1.3200,
         1.3479, 1.4283, 1.4075, 1.3593, 1.3123, 1.4125, 1.4004, 0.5229, 1.2976,
         0.7831, 1.3483, 1.3099, 1.3020, 0.9066, 1.3060, 0.4788, 1.3103, 1.3051],
        [1.3242, 1.3092, 1.3147, 1.2913, 1.2239, 1.3248, 1.2469, 1.3238, 1.3238,
         1.3875, 1.3614, 1.4023, 1.3898, 1.3835, 1.0966, 1.3915, 1.3435, 1.2691,
         1.5810, 1.6621, 1.7464, 1.6619, 1.4574, 1.4618, 1.5636, 1.4277, 1.4277,
         1.2866, 1.2855, 1.3425, 1.3506, 1.2732, 1.3495, 1.3511, 1.3431, 1.3436,
         1.4607, 1.4732, 1.4687, 1.4413, 1.4738, 1.4767, 1.4663, 1.1450, 1.2185,
         1.2793, 1.3900, 1.3738, 1.3594, 1.2202, 1.3672, 1.2608, 1.3626, 1.3605],
        [1.3033, 1.3087, 1.1891, 1.1343, 1.2958, 1.2930, 1.2968, 1.3029, 1.3029,
         1.3540, 1.2742, 1.3079, 1.2826, 1.3483, 1.2716, 1.3549, 1.3494, 1.0041,
         1.2982, 1.1441, 1.3253, 1.2974, 1.2606, 1.2432, 1.2936, 1.2824, 1.2824,
         1.7767, 1.5314, 1.4066, 1.4879, 1.7427, 1.3969, 1.7221, 1.4109, 1.3906,
         1.4014, 1.3702, 1.3587, 1.3761, 1.4102, 1.3245, 1.3822, 1.0501, 1.3457,
         1.3796, 1.2798, 1.1583, 1.2795, 1.3544, 1.1747, 1.4098, 1.2851, 1.3251],
        [1.4310, 1.2770, 0.4933, 0.6388, 1.1806, 1.3924, 1.3351, 1.4303, 1.4303,
         1.3781, 1.2602, 1.1820, 0.9228, 1.4111, 0.3998, 1.2986, 1.4086, 1.1101,
         1.1612, 0.8446, 0.8642, 1.0583, 1.3934, 1.4073, 1.1163, 1.4444, 1.4444,
         0.5387, 0.6054, 1.3525, 1.1773, 0.7016, 1.3567, 0.9223, 1.3597, 1.3324,
         1.1379, 0.9461, 0.9110, 1.0769, 1.3159, 1.3830, 1.0675, 1.8927, 1.8181,
         0.7802, 0.9667, 1.0644, 1.2943, 0.8947, 1.2494, 0.4941, 1.2249, 1.3430],
        [1.2848, 1.2755, 1.2413, 1.2818, 1.2023, 1.2484, 1.2474, 1.2839, 1.2839,
         1.1025, 1.0776, 1.0752, 1.1113, 1.2079, 1.0739, 1.1120, 1.2130, 1.0590,
         1.2705, 1.2103, 1.0374, 1.1687, 1.2506, 1.2476, 1.2173, 1.2535, 1.2535,
         1.2672, 1.1227, 1.2792, 1.0737, 1.1486, 1.0601, 1.2565, 1.1719, 1.2814,
         1.3213, 1.1628, 1.3315, 1.3081, 1.0383, 0.9554, 1.3271, 0.9171, 0.5986,
         1.7537, 1.4525, 1.5398, 1.5243, 1.4921, 1.2063, 1.7497, 1.4692, 1.1976]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 15 : 182.3044056930408
Test loss for epoch 15 : 182.18827003229273
Test Precision for epoch 15 : 0.26153846153846155
Test Recall for epoch 15 : 0.26153846153846155
Test F1 for epoch 15 : 0.26153846153846155


theta for epoch 16 : tensor([[1.5038, 1.5553, 1.6164, 1.5961, 1.5978, 1.5189, 1.5378, 1.5033, 1.5033,
         1.3441, 1.3479, 1.3580, 1.3474, 1.3378, 1.3353, 1.3470, 1.3409, 1.3046,
         1.2198, 1.1939, 1.2501, 1.2329, 1.2489, 1.2483, 1.2593, 1.2463, 1.2463,
         1.2405, 1.3538, 1.3066, 1.3172, 1.3316, 1.3137, 1.3057, 1.2705, 1.3078,
         1.4538, 1.4645, 1.4602, 1.4583, 1.4682, 1.4324, 1.4545, 1.4328, 1.4147,
         1.3538, 1.3441, 1.3314, 1.3203, 1.3584, 1.3219, 1.3039, 1.3249, 1.3215],
        [1.2919, 1.0844, 0.8870, 1.2173, 1.2371, 1.3323, 1.2699, 1.3312, 1.3312,
         1.3097, 1.4615, 1.2141, 1.7104, 1.2750, 2.0324, 1.3015, 1.1701, 1.8831,
         1.0854, 1.1411, 0.7923, 1.0845, 1.2621, 1.3634, 1.3259, 1.3642, 1.3642,
         1.2948, 1.0340, 1.3643, 1.3260, 1.0651, 1.3759, 1.3555, 1.3509, 1.3261,
         1.3411, 1.4280, 1.4050, 1.3536, 1.3052, 1.4118, 1.3973, 0.5054, 1.2918,
         0.7644, 1.3397, 1.3005, 1.2889, 0.8822, 1.2953, 0.4642, 1.2983, 1.2921],
        [1.3015, 1.2875, 1.2943, 1.2702, 1.2024, 1.3021, 1.2251, 1.3009, 1.3009,
         1.3954, 1.3701, 1.4117, 1.4004, 1.3905, 1.1269, 1.3998, 1.3504, 1.2776,
         1.6003, 1.6863, 1.7749, 1.6867, 1.4713, 1.4768, 1.5837, 1.4407, 1.4407,
         1.2986, 1.2978, 1.3519, 1.3613, 1.2858, 1.3595, 1.3620, 1.3528, 1.3532,
         1.4658, 1.4795, 1.4743, 1.4455, 1.4805, 1.4837, 1.4715, 1.1603, 1.2285,
         1.2847, 1.3962, 1.3798, 1.3630, 1.2247, 1.3724, 1.2717, 1.3669, 1.3642],
        [1.2834, 1.2895, 1.1715, 1.1187, 1.2769, 1.2734, 1.2773, 1.2829, 1.2829,
         1.3597, 1.2777, 1.3159, 1.2887, 1.3531, 1.2798, 1.3615, 1.3546, 1.0107,
         1.3124, 1.1641, 1.3407, 1.3128, 1.2736, 1.2553, 1.3079, 1.2948, 1.2948,
         1.8076, 1.5494, 1.4176, 1.5030, 1.7720, 1.4078, 1.7500, 1.4224, 1.4010,
         1.3997, 1.3676, 1.3545, 1.3729, 1.4106, 1.3219, 1.3793, 1.0603, 1.3469,
         1.3863, 1.2789, 1.1527, 1.2756, 1.3601, 1.1679, 1.4204, 1.2821, 1.3236],
        [1.4226, 1.2628, 0.4793, 0.6301, 1.1624, 1.3818, 1.3225, 1.4218, 1.4218,
         1.3792, 1.2557, 1.1760, 0.9171, 1.4133, 0.3797, 1.2968, 1.4106, 1.0997,
         1.1627, 0.8471, 0.8708, 1.0584, 1.4019, 1.4178, 1.1210, 1.4564, 1.4564,
         0.5537, 0.6249, 1.3580, 1.1794, 0.7193, 1.3642, 0.9182, 1.3675, 1.3380,
         1.1318, 0.9307, 0.8943, 1.0686, 1.3188, 1.3910, 1.0579, 1.9429, 1.8618,
         0.7592, 0.9536, 1.0440, 1.2823, 0.8772, 1.2361, 0.4704, 1.2108, 1.3342],
        [1.2591, 1.2510, 1.2218, 1.2598, 1.1777, 1.2220, 1.2212, 1.2581, 1.2581,
         1.0822, 1.0623, 1.0585, 1.1020, 1.1882, 1.0876, 1.0928, 1.1941, 1.0499,
         1.2774, 1.2212, 1.0553, 1.1784, 1.2552, 1.2512, 1.2221, 1.2567, 1.2567,
         1.2747, 1.1354, 1.2812, 1.0762, 1.1550, 1.0606, 1.2618, 1.1719, 1.2839,
         1.3078, 1.1415, 1.3187, 1.2946, 1.0180, 0.9346, 1.3137, 0.9195, 0.5844,
         1.7897, 1.4683, 1.5626, 1.5454, 1.5080, 1.2047, 1.7851, 1.4867, 1.1952]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 16 : 182.144471627323
Test loss for epoch 16 : 182.02350725164354
Test Precision for epoch 16 : 0.26153846153846155
Test Recall for epoch 16 : 0.26153846153846155
Test F1 for epoch 16 : 0.26153846153846155


theta for epoch 17 : tensor([[1.5109, 1.5644, 1.6276, 1.6072, 1.6086, 1.5264, 1.5465, 1.5105, 1.5105,
         1.3505, 1.3553, 1.3657, 1.3556, 1.3436, 1.3455, 1.3538, 1.3469, 1.3126,
         1.2413, 1.2167, 1.2680, 1.2542, 1.2667, 1.2657, 1.2776, 1.2636, 1.2636,
         1.2528, 1.3656, 1.3164, 1.3280, 1.3438, 1.3241, 1.3170, 1.2800, 1.3178,
         1.4414, 1.4529, 1.4480, 1.4461, 1.4570, 1.4198, 1.4421, 1.4228, 1.4038,
         1.3687, 1.3560, 1.3433, 1.3301, 1.3730, 1.3332, 1.3208, 1.3352, 1.3314],
        [1.2756, 1.0650, 0.8767, 1.1995, 1.2196, 1.3176, 1.2527, 1.3162, 1.3162,
         1.3234, 1.4854, 1.2228, 1.7506, 1.2865, 2.0953, 1.3149, 1.1762, 1.9360,
         1.0947, 1.1523, 0.8050, 1.0962, 1.2738, 1.3771, 1.3397, 1.3776, 1.3776,
         1.3050, 1.0435, 1.3734, 1.3354, 1.0747, 1.3862, 1.3667, 1.3599, 1.3343,
         1.3190, 1.4122, 1.3869, 1.3326, 1.2829, 1.3956, 1.3785, 0.4749, 1.2707,
         0.7574, 1.3392, 1.2999, 1.2839, 0.8693, 1.2932, 0.4638, 1.2945, 1.2872],
        [1.2872, 1.2745, 1.2826, 1.2578, 1.1900, 1.2880, 1.2123, 1.2867, 1.2867,
         1.4071, 1.3828, 1.4248, 1.4147, 1.4014, 1.1604, 1.4119, 1.3613, 1.2907,
         1.6201, 1.7107, 1.8034, 1.7118, 1.4862, 1.4929, 1.6046, 1.4548, 1.4548,
         1.3131, 1.3129, 1.3639, 1.3746, 1.3011, 1.3722, 1.3755, 1.3651, 1.3654,
         1.4547, 1.4694, 1.4634, 1.4334, 1.4708, 1.4743, 1.4604, 1.1595, 1.2225,
         1.3017, 1.4128, 1.3965, 1.3772, 1.2414, 1.3882, 1.2948, 1.3818, 1.3785],
        [1.2727, 1.2795, 1.1634, 1.1128, 1.2672, 1.2631, 1.2672, 1.2721, 1.2721,
         1.3709, 1.2871, 1.3296, 1.3004, 1.3631, 1.2936, 1.3734, 1.3650, 1.0244,
         1.3344, 1.1922, 1.3636, 1.3359, 1.2948, 1.2757, 1.3299, 1.3152, 1.3152,
         1.8332, 1.5622, 1.4237, 1.5132, 1.7960, 1.4140, 1.7727, 1.4291, 1.4067,
         1.3828, 1.3500, 1.3354, 1.3546, 1.3956, 1.3043, 1.3613, 1.0547, 1.3327,
         1.4041, 1.2892, 1.1594, 1.2828, 1.3770, 1.1730, 1.4422, 1.2902, 1.3330],
        [1.4155, 1.2495, 0.4638, 0.6203, 1.1447, 1.3724, 1.3109, 1.4147, 1.4147,
         1.3766, 1.2472, 1.1659, 0.9059, 1.4118, 0.3533, 1.2911, 1.4089, 1.0853,
         1.1614, 0.8453, 0.8731, 1.0552, 1.4083, 1.4263, 1.1230, 1.4664, 1.4664,
         0.5592, 0.6350, 1.3607, 1.1780, 0.7279, 1.3691, 0.9094, 1.3727, 1.3409,
         1.1260, 0.9153, 0.8777, 1.0607, 1.3224, 1.3998, 1.0486, 1.9949, 1.9073,
         0.7370, 0.9396, 1.0241, 1.2717, 0.8590, 1.2241, 0.4447, 1.1978, 1.3269],
        [1.2432, 1.2367, 1.2127, 1.2478, 1.1636, 1.2055, 1.2050, 1.2421, 1.2421,
         1.0678, 1.0539, 1.0488, 1.0991, 1.1728, 1.1061, 1.0795, 1.1797, 1.0481,
         1.2939, 1.2421, 1.0843, 1.1987, 1.2695, 1.2644, 1.2367, 1.2694, 1.2694,
         1.2852, 1.1518, 1.2860, 1.0824, 1.1649, 1.0648, 1.2701, 1.1752, 1.2891,
         1.2805, 1.1074, 1.2921, 1.2673, 0.9853, 0.9018, 1.2863, 0.9091, 0.5595,
         1.8219, 1.4802, 1.5817, 1.5629, 1.5197, 1.1995, 1.8166, 1.5004, 1.1892]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 17 : 182.00683753945836
Test loss for epoch 17 : 181.88241338135322
Test Precision for epoch 17 : 0.26153846153846155
Test Recall for epoch 17 : 0.26153846153846155
Test F1 for epoch 17 : 0.26153846153846155


theta for epoch 18 : tensor([[1.5267, 1.5819, 1.6469, 1.6265, 1.6278, 1.5425, 1.5636, 1.5262, 1.5262,
         1.3520, 1.3576, 1.3684, 1.3587, 1.3444, 1.3503, 1.3557, 1.3479, 1.3156,
         1.2448, 1.2211, 1.2676, 1.2574, 1.2667, 1.2655, 1.2779, 1.2633, 1.2633,
         1.2603, 1.3724, 1.3216, 1.3342, 1.3511, 1.3298, 1.3236, 1.2849, 1.3231,
         1.4265, 1.4388, 1.4333, 1.4314, 1.4433, 1.4047, 1.4271, 1.4102, 1.3904,
         1.3900, 1.3741, 1.3615, 1.3462, 1.3937, 1.3509, 1.3444, 1.3518, 1.3475],
        [1.2715, 1.0587, 0.8788, 1.1943, 1.2146, 1.3149, 1.2478, 1.3133, 1.3133,
         1.3282, 1.5006, 1.2229, 1.7824, 1.2893, 2.1518, 1.3196, 1.1738, 1.9816,
         1.0929, 1.1516, 0.8067, 1.0966, 1.2732, 1.3778, 1.3406, 1.3780, 1.3780,
         1.3122, 1.0508, 1.3795, 1.3422, 1.0821, 1.3938, 1.3749, 1.3662, 1.3396,
         1.2961, 1.3955, 1.3678, 1.3107, 1.2600, 1.3785, 1.3589, 0.4454, 1.2490,
         0.7605, 1.3447, 1.3057, 1.2846, 0.8665, 1.2975, 0.4760, 1.2966, 1.2881],
        [1.2855, 1.2741, 1.2835, 1.2582, 1.1907, 1.2863, 1.2124, 1.2849, 1.2849,
         1.4164, 1.3934, 1.4353, 1.4263, 1.4097, 1.1911, 1.4214, 1.3700, 1.3021,
         1.6280, 1.7231, 1.8198, 1.7250, 1.4898, 1.4977, 1.6139, 1.4578, 1.4578,
         1.3250, 1.3253, 1.3733, 1.3853, 1.3139, 1.3822, 1.3861, 1.3748, 1.3749,
         1.4426, 1.4582, 1.4516, 1.4205, 1.4600, 1.4637, 1.4482, 1.1580, 1.2161,
         1.3282, 1.4377, 1.4217, 1.4001, 1.2679, 1.4126, 1.3275, 1.4053, 1.4014],
        [1.2743, 1.2818, 1.1678, 1.1194, 1.2699, 1.2652, 1.2694, 1.2737, 1.2737,
         1.3809, 1.2958, 1.3425, 1.3111, 1.3718, 1.3062, 1.3841, 1.3742, 1.0386,
         1.3456, 1.2100, 1.3754, 1.3482, 1.3057, 1.2857, 1.3412, 1.3252, 1.3252,
         1.8493, 1.5656, 1.4210, 1.5144, 1.8107, 1.4116, 1.7861, 1.4270, 1.4036,
         1.3662, 1.3329, 1.3168, 1.3368, 1.3811, 1.2874, 1.3438, 1.0497, 1.3191,
         1.4308, 1.3083, 1.1759, 1.2991, 1.4028, 1.1879, 1.4726, 1.3074, 1.3512],
        [1.4120, 1.2392, 0.4484, 0.6110, 1.1296, 1.3665, 1.3026, 1.4111, 1.4111,
         1.3652, 1.2298, 1.1470, 0.8854, 1.4013, 0.3176, 1.2766, 1.3982, 1.0621,
         1.1464, 0.8300, 0.8614, 1.0384, 1.4003, 1.4207, 1.1116, 1.4622, 1.4622,
         0.5485, 0.6285, 1.3523, 1.1646, 0.7199, 1.3627, 0.8877, 1.3668, 1.3326,
         1.1275, 0.9072, 0.8681, 1.0600, 1.3333, 1.4161, 1.0464, 2.0532, 1.9596,
         0.7121, 0.9231, 1.0029, 1.2604, 0.8382, 1.2113, 0.4156, 1.1840, 1.3192],
        [1.2410, 1.2363, 1.2178, 1.2497, 1.1639, 1.2030, 1.2028, 1.2397, 1.2397,
         1.0510, 1.0435, 1.0374, 1.0936, 1.1533, 1.1201, 1.0636, 1.1614, 1.0446,
         1.3000, 1.2528, 1.1048, 1.2095, 1.2736, 1.2673, 1.2412, 1.2719, 1.2719,
         1.2938, 1.1674, 1.2889, 1.0879, 1.1735, 1.0683, 1.2766, 1.1771, 1.2925,
         1.2532, 1.0741, 1.2655, 1.2401, 0.9539, 0.8705, 1.2589, 0.9003, 0.5377,
         1.8485, 1.4865, 1.5954, 1.5749, 1.5256, 1.1891, 1.8425, 1.5088, 1.1780]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 18 : 181.85078663963353
Test loss for epoch 18 : 181.73468681447713
Test Precision for epoch 18 : 0.26153846153846155
Test Recall for epoch 18 : 0.26153846153846155
Test F1 for epoch 18 : 0.26153846153846155


theta for epoch 19 : tensor([[1.5497, 1.6065, 1.6731, 1.6529, 1.6539, 1.5659, 1.5880, 1.5492, 1.5492,
         1.3477, 1.3541, 1.3651, 1.3558, 1.3394, 1.3491, 1.3517, 1.3431, 1.3128,
         1.2305, 1.2074, 1.2494, 1.2427, 1.2494, 1.2478, 1.2607, 1.2456, 1.2456,
         1.2614, 1.3727, 1.3205, 1.3340, 1.3519, 1.3293, 1.3239, 1.2837, 1.3222,
         1.4152, 1.4283, 1.4222, 1.4203, 1.4331, 1.3933, 1.4157, 1.4011, 1.3807,
         1.4140, 1.3947, 1.3823, 1.3650, 1.4172, 1.3713, 1.3710, 1.3711, 1.3664],
        [1.2792, 1.0652, 0.8931, 1.2011, 1.2216, 1.3237, 1.2547, 1.3219, 1.3219,
         1.3212, 1.5036, 1.2115, 1.8024, 1.2804, 2.1985, 1.3125, 1.1601, 2.0164,
         1.0807, 1.1395, 0.7982, 1.0862, 1.2610, 1.3659, 1.3292, 1.3659, 1.3659,
         1.3155, 1.0550, 1.3819, 1.3454, 1.0864, 1.3976, 1.3793, 1.3687, 1.3414,
         1.2783, 1.3841, 1.3539, 1.2940, 1.2428, 1.3667, 1.3443, 0.4233, 1.2330,
         0.7713, 1.3532, 1.3148, 1.2881, 0.8711, 1.3048, 0.4982, 1.3015, 1.2917],
        [1.2940, 1.2840, 1.2946, 1.2689, 1.2019, 1.2950, 1.2230, 1.2934, 1.2934,
         1.4207, 1.3992, 1.4409, 1.4329, 1.4131, 1.2165, 1.4261, 1.3741, 1.3090,
         1.6266, 1.7260, 1.8266, 1.7289, 1.4846, 1.4939, 1.6141, 1.4521, 1.4521,
         1.3313, 1.3322, 1.3772, 1.3904, 1.3212, 1.3868, 1.3911, 1.3791, 1.3790,
         1.4350, 1.4516, 1.4442, 1.4122, 1.4538, 1.4577, 1.4406, 1.1612, 1.2149,
         1.3592, 1.4664, 1.4508, 1.4269, 1.2993, 1.4409, 1.3649, 1.4328, 1.4282],
        [1.2860, 1.2943, 1.1823, 1.1361, 1.2827, 1.2774, 1.2818, 1.2854, 1.2854,
         1.3874, 1.3014, 1.3522, 1.3185, 1.3771, 1.3152, 1.3912, 1.3798, 1.0504,
         1.3433, 1.2145, 1.3731, 1.3467, 1.3035, 1.2827, 1.3389, 1.3218, 1.3218,
         1.8576, 1.5616, 1.4114, 1.5084, 1.8177, 1.4023, 1.7921, 1.4180, 1.3937,
         1.3559, 1.3223, 1.3047, 1.3252, 1.3726, 1.2771, 1.3326, 1.0509, 1.3117,
         1.4619, 1.3323, 1.1980, 1.3203, 1.4333, 1.2083, 1.5073, 1.3294, 1.3740],
        [1.4119, 1.2317, 0.4333, 0.6021, 1.1169, 1.3637, 1.2973, 1.4109, 1.4109,
         1.3444, 1.2030, 1.1190, 0.8554, 1.3814, 0.2733, 1.2528, 1.3780, 1.0300,
         1.1185, 0.8022, 0.8366, 1.0089, 1.3788, 1.4015, 1.0876, 1.4443, 1.4443,
         0.5225, 0.6064, 1.3315, 1.1384, 0.6960, 1.3438, 0.8530, 1.3486, 1.3119,
         1.1376, 0.9077, 0.8671, 1.0681, 1.3529, 1.4410, 1.0530, 2.1182, 2.0190,
         0.6822, 0.9014, 0.9773, 1.2451, 0.8127, 1.1944, 0.3815, 1.1661, 1.3076],
        [1.2510, 1.2482, 1.2353, 1.2638, 1.1770, 1.2129, 1.2131, 1.2496, 1.2496,
         1.0306, 1.0299, 1.0230, 1.0844, 1.1289, 1.1288, 1.0442, 1.1382, 1.0377,
         1.2946, 1.2522, 1.1153, 1.2097, 1.2667, 1.2591, 1.2347, 1.2633, 1.2633,
         1.2993, 1.1807, 1.2889, 1.0915, 1.1795, 1.0699, 1.2803, 1.1766, 1.2930,
         1.2312, 1.0468, 1.2441, 1.2184, 0.9289, 0.8458, 1.2367, 0.8985, 0.5243,
         1.8675, 1.4855, 1.6018, 1.5796, 1.5238, 1.1719, 1.8608, 1.5100, 1.1601]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 19 : 181.54989848708877
Test loss for epoch 19 : 181.45492502070425
Test Precision for epoch 19 : 0.26153846153846155
Test Recall for epoch 19 : 0.26153846153846155
Test F1 for epoch 19 : 0.26153846153846155


theta for epoch 20 : tensor([[1.5742, 1.6324, 1.7004, 1.6804, 1.6813, 1.5906, 1.6138, 1.5736, 1.5736,
         1.3427, 1.3497, 1.3611, 1.3522, 1.3336, 1.3471, 1.3469, 1.3375, 1.3092,
         1.2165, 1.1937, 1.2310, 1.2281, 1.2322, 1.2304, 1.2435, 1.2282, 1.2282,
         1.2586, 1.3687, 1.3156, 1.3299, 1.3486, 1.3249, 1.3202, 1.2787, 1.3174,
         1.4088, 1.4229, 1.4160, 1.4141, 1.4279, 1.3869, 1.4093, 1.3973, 1.3762,
         1.4338, 1.4109, 1.3989, 1.3795, 1.4364, 1.3873, 1.3937, 1.3860, 1.3809],
        [1.2932, 1.0790, 0.9145, 1.2149, 1.2354, 1.3387, 1.2682, 1.3367, 1.3367,
         1.3042, 1.4961, 1.1905, 1.8116, 1.2616, 2.2361, 1.2955, 1.1370, 2.0413,
         1.0746, 1.1329, 0.7960, 1.0817, 1.2535, 1.3576, 1.3216, 1.3574, 1.3574,
         1.3169, 1.0582, 1.3823, 1.3469, 1.0897, 1.3994, 1.3818, 1.3693, 1.3415,
         1.2658, 1.3779, 1.3449, 1.2825, 1.2313, 1.3603, 1.3346, 0.4089, 1.2229,
         0.7821, 1.3570, 1.3196, 1.2865, 0.8755, 1.3073, 0.5228, 1.3015, 1.2902],
        [1.3053, 1.2967, 1.3085, 1.2824, 1.2162, 1.3063, 1.2367, 1.3046, 1.3046,
         1.4208, 1.4009, 1.4420, 1.4350, 1.4123, 1.2367, 1.4264, 1.3741, 1.3117,
         1.6307, 1.7341, 1.8381, 1.7379, 1.4856, 1.4963, 1.6202, 1.4529, 1.4529,
         1.3314, 1.3328, 1.3751, 1.3893, 1.3223, 1.3851, 1.3899, 1.3773, 1.3770,
         1.4314, 1.4489, 1.4408, 1.4080, 1.4515, 1.4555, 1.4369, 1.1683, 1.2180,
         1.3834, 1.4877, 1.4728, 1.4467, 1.3243, 1.4621, 1.3957, 1.4532, 1.4480],
        [1.3011, 1.3099, 1.1999, 1.1560, 1.2987, 1.2929, 1.2974, 1.3003, 1.3003,
         1.3911, 1.3045, 1.3592, 1.3234, 1.3796, 1.3212, 1.3956, 1.3828, 1.0600,
         1.3386, 1.2165, 1.3680, 1.3428, 1.2993, 1.2777, 1.3342, 1.3164, 1.3164,
         1.8650, 1.5571, 1.4019, 1.5022, 1.8239, 1.3930, 1.7972, 1.4090, 1.3839,
         1.3509, 1.3172, 1.2981, 1.3191, 1.3696, 1.2726, 1.3269, 1.0572, 1.3099,
         1.4874, 1.3509, 1.2154, 1.3363, 1.4582, 1.2239, 1.5361, 1.3461, 1.3915],
        [1.4131, 1.2255, 0.4184, 0.5936, 1.1051, 1.3623, 1.2933, 1.4120, 1.4120,
         1.3183, 1.1711, 1.0865, 0.8203, 1.3560, 0.2248, 1.2241, 1.3524, 0.9931,
         1.0886, 0.7716, 0.8087, 0.9770, 1.3550, 1.3801, 1.0617, 1.4242, 1.4242,
         0.4888, 0.5760, 1.3042, 1.1058, 0.6638, 1.3181, 0.8125, 1.3238, 1.2847,
         1.1521, 0.9126, 0.8705, 1.0806, 1.3768, 1.4703, 1.0638, 2.1869, 2.0825,
         0.6450, 0.8716, 0.9437, 1.2205, 0.7795, 1.1686, 0.3412, 1.1395, 1.2867],
        [1.2666, 1.2658, 1.2587, 1.2837, 1.1961, 1.2286, 1.2292, 1.2650, 1.2650,
         1.0104, 1.0169, 1.0097, 1.0760, 1.1037, 1.1369, 1.0251, 1.1141, 1.0310,
         1.2922, 1.2548, 1.1297, 1.2136, 1.2630, 1.2543, 1.2315, 1.2579, 1.2579,
         1.3024, 1.1923, 1.2868, 1.0937, 1.1835, 1.0702, 1.2820, 1.1745, 1.2914,
         1.2128, 1.0237, 1.2264, 1.2005, 0.9085, 0.8258, 1.2180, 0.9019, 0.5171,
         1.8783, 1.4767, 1.6003, 1.5763, 1.5136, 1.1474, 1.8707, 1.5032, 1.1348]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 20 : 181.508561957512
Test loss for epoch 20 : 181.44017546957647
Test Precision for epoch 20 : 0.26153846153846155
Test Recall for epoch 20 : 0.26153846153846155
Test F1 for epoch 20 : 0.26153846153846155


theta for epoch 21 : tensor([[1.5917, 1.6512, 1.7205, 1.7009, 1.7015, 1.6083, 1.6326, 1.5910, 1.5910,
         1.3463, 1.3541, 1.3658, 1.3575, 1.3367, 1.3541, 1.3509, 1.3407, 1.3144,
         1.2146, 1.1920, 1.2245, 1.2255, 1.2271, 1.2251, 1.2382, 1.2229, 1.2229,
         1.2583, 1.3668, 1.3131, 1.3281, 1.3473, 1.3228, 1.3190, 1.2761, 1.3150,
         1.4073, 1.4222, 1.4146, 1.4128, 1.4276, 1.3855, 1.4077, 1.3987, 1.3771,
         1.4460, 1.4196, 1.4080, 1.3864, 1.4479, 1.3958, 1.4092, 1.3934, 1.3878],
        [1.3018, 1.0880, 0.9307, 1.2234, 1.2440, 1.3481, 1.2762, 1.3458, 1.3458,
         1.2875, 1.4884, 1.1703, 1.8204, 1.2432, 2.2734, 1.2789, 1.1147, 2.0660,
         1.0806, 1.1378, 0.8052, 1.0891, 1.2575, 1.3599, 1.3247, 1.3595, 1.3595,
         1.3203, 1.0637, 1.3850, 1.3505, 1.0952, 1.4033, 1.3865, 1.3720, 1.3439,
         1.2558, 1.3744, 1.3383, 1.2736, 1.2229, 1.3568, 1.3273, 0.3986, 1.2163,
         0.7870, 1.3521, 1.3158, 1.2761, 0.8743, 1.3010, 0.5427, 1.2928, 1.2800],
        [1.3064, 1.2992, 1.3120, 1.2857, 1.2202, 1.3075, 1.2404, 1.3056, 1.3056,
         1.4226, 1.4044, 1.4447, 1.4388, 1.4133, 1.2574, 1.4284, 1.3760, 1.3160,
         1.6500, 1.7566, 1.8634, 1.7615, 1.5025, 1.5146, 1.6415, 1.4698, 1.4698,
         1.3291, 1.3309, 1.3707, 1.3858, 1.3211, 1.3812, 1.3863, 1.3732, 1.3728,
         1.4304, 1.4487, 1.4399, 1.4064, 1.4518, 1.4558, 1.4358, 1.1777, 1.2239,
         1.3937, 1.4954, 1.4810, 1.4529, 1.3357, 1.4697, 1.4125, 1.4600, 1.4542],
        [1.3067, 1.3161, 1.2079, 1.1664, 1.3053, 1.2990, 1.3036, 1.3059, 1.3059,
         1.3967, 1.3094, 1.3682, 1.3303, 1.3841, 1.3287, 1.4019, 1.3876, 1.0710,
         1.3364, 1.2208, 1.3651, 1.3413, 1.2978, 1.2754, 1.3320, 1.3137, 1.3137,
         1.8828, 1.5646, 1.4045, 1.5080, 1.8408, 1.3961, 1.8133, 1.4122, 1.3865,
         1.3489, 1.3153, 1.2945, 1.3160, 1.3695, 1.2713, 1.3241, 1.0659, 1.3112,
         1.4998, 1.3573, 1.2209, 1.3400, 1.4703, 1.2276, 1.5514, 1.3506, 1.3966],
        [1.4132, 1.2191, 0.4068, 0.5873, 1.0934, 1.3598, 1.2887, 1.4120, 1.4120,
         1.3015, 1.1492, 1.0654, 0.7960, 1.3396, 0.1887, 1.2057, 1.3357, 0.9676,
         1.0719, 0.7532, 0.7921, 0.9582, 1.3432, 1.3707, 1.0489, 1.4158, 1.4158,
         0.4713, 0.5613, 1.2905, 1.0895, 0.6476, 1.3059, 0.7922, 1.3123, 1.2716,
         1.1589, 0.9102, 0.8666, 1.0856, 1.3930, 1.4920, 1.0670, 2.2507, 2.1405,
         0.6093, 0.8412, 0.9092, 1.1916, 0.7467, 1.1395, 0.3050, 1.1098, 1.2613],
        [1.2733, 1.2747, 1.2734, 1.2949, 1.2068, 1.2355, 1.2364, 1.2715, 1.2715,
         0.9945, 1.0086, 1.0011, 1.0733, 1.0827, 1.1493, 1.0106, 1.0942, 1.0283,
         1.2954, 1.2629, 1.1491, 1.2233, 1.2651, 1.2552, 1.2342, 1.2585, 1.2585,
         1.3047, 1.2032, 1.2843, 1.0956, 1.1864, 1.0700, 1.2833, 1.1718, 1.2893,
         1.1928, 0.9991, 1.2070, 1.1811, 0.8867, 0.8041, 1.1977, 0.9047, 0.5087,
         1.8907, 1.4699, 1.6010, 1.5751, 1.5051, 1.1249, 1.8821, 1.4987, 1.1115]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 21 : 181.67902410385682
Test loss for epoch 21 : 181.62552162119098
Test Precision for epoch 21 : 0.26153846153846155
Test Recall for epoch 21 : 0.26153846153846155
Test F1 for epoch 21 : 0.26153846153846155


theta for epoch 22 : tensor([[1.6002, 1.6609, 1.7315, 1.7125, 1.7125, 1.6169, 1.6424, 1.5995, 1.5995,
         1.3605, 1.3688, 1.3807, 1.3732, 1.3503, 1.3716, 1.3654, 1.3544, 1.3301,
         1.2223, 1.1998, 1.2273, 1.2324, 1.2316, 1.2294, 1.2424, 1.2272, 1.2272,
         1.2615, 1.3679, 1.3142, 1.3297, 1.3493, 1.3242, 1.3212, 1.2771, 1.3161,
         1.4096, 1.4254, 1.4169, 1.4152, 1.4313, 1.3882, 1.4098, 1.4044, 1.3824,
         1.4550, 1.4254, 1.4141, 1.3903, 1.4562, 1.4013, 1.4218, 1.3980, 1.3917],
        [1.2965, 1.0834, 0.9325, 1.2181, 1.2390, 1.3435, 1.2704, 1.3410, 1.3410,
         1.2826, 1.4923, 1.1624, 1.8398, 1.2368, 2.3191, 1.2744, 1.1047, 2.1003,
         1.0916, 1.1474, 0.8176, 1.1013, 1.2664, 1.3667, 1.3324, 1.3662, 1.3662,
         1.3245, 1.0697, 1.3889, 1.3552, 1.1014, 1.4081, 1.3923, 1.3758, 1.3476,
         1.2460, 1.3713, 1.3317, 1.2648, 1.2153, 1.3540, 1.3201, 0.3881, 1.2108,
         0.7872, 1.3424, 1.3073, 1.2611, 0.8692, 1.2899, 0.5569, 1.2796, 1.2650],
        [1.2915, 1.2856, 1.2991, 1.2729, 1.2082, 1.2927, 1.2281, 1.2907, 1.2907,
         1.4288, 1.4125, 1.4516, 1.4468, 1.4188, 1.2807, 1.4348, 1.3826, 1.3246,
         1.6833, 1.7926, 1.9015, 1.7984, 1.5341, 1.5475, 1.6768, 1.5014, 1.5014,
         1.3260, 1.3279, 1.3656, 1.3814, 1.3190, 1.3764, 1.3819, 1.3683, 1.3677,
         1.4313, 1.4505, 1.4409, 1.4068, 1.4540, 1.4581, 1.4365, 1.1889, 1.2321,
         1.3954, 1.4947, 1.4810, 1.4509, 1.3389, 1.4689, 1.4206, 1.4586, 1.4523],
        [1.2962, 1.3061, 1.1994, 1.1602, 1.2958, 1.2891, 1.2937, 1.2954, 1.2954,
         1.4051, 1.3169, 1.3798, 1.3400, 1.3916, 1.3381, 1.4108, 1.3953, 1.0837,
         1.3337, 1.2242, 1.3614, 1.3391, 1.2959, 1.2727, 1.3294, 1.3107, 1.3107,
         1.9153, 1.5884, 1.4240, 1.5302, 1.8726, 1.4158, 1.8443, 1.4322, 1.4058,
         1.3483, 1.3149, 1.2923, 1.3144, 1.3710, 1.2717, 1.3229, 1.0752, 1.3142,
         1.5029, 1.3552, 1.2179, 1.3352, 1.4733, 1.2230, 1.5569, 1.3466, 1.3932],
        [1.4141, 1.2154, 0.4052, 0.5893, 1.0855, 1.3586, 1.2862, 1.4128, 1.4128,
         1.3079, 1.1526, 1.0707, 0.7982, 1.3457, 0.1831, 1.2119, 1.3418, 0.9695,
         1.0779, 0.7577, 0.7971, 0.9624, 1.3516, 1.3813, 1.0585, 1.4270, 1.4270,
         0.4877, 0.5792, 1.3049, 1.1052, 0.6648, 1.3212, 0.8088, 1.3282, 1.2869,
         1.1459, 0.8895, 0.8447, 1.0712, 1.3885, 1.4927, 1.0511, 2.2964, 2.1795,
         0.5952, 0.8290, 0.8935, 1.1754, 0.7336, 1.1246, 0.2935, 1.0949, 1.2476],
        [1.2618, 1.2652, 1.2694, 1.2876, 1.1992, 1.2242, 1.2253, 1.2599, 1.2599,
         0.9779, 0.9998, 0.9918, 1.0708, 1.0619, 1.1606, 0.9957, 1.0746, 1.0241,
         1.2948, 1.2670, 1.1633, 1.2288, 1.2635, 1.2524, 1.2328, 1.2554, 1.2554,
         1.3033, 1.2102, 1.2787, 1.0935, 1.1850, 1.0657, 1.2813, 1.1656, 1.2841,
         1.1671, 0.9681, 1.1817, 1.1558, 0.8582, 0.7754, 1.1714, 0.9016, 0.4927,
         1.9185, 1.4807, 1.6189, 1.5911, 1.5136, 1.1200, 1.9091, 1.5117, 1.1058]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 22 : 181.35732345804115
Test loss for epoch 22 : 181.29356555077618
Test Precision for epoch 22 : 0.26153846153846155
Test Recall for epoch 22 : 0.26153846153846155
Test F1 for epoch 22 : 0.26153846153846155


theta for epoch 23 : tensor([[1.6053, 1.6671, 1.7388, 1.7205, 1.7200, 1.6222, 1.6488, 1.6046, 1.6046,
         1.3808, 1.3897, 1.4018, 1.3952, 1.3703, 1.3952, 1.3861, 1.3744, 1.3519,
         1.2292, 1.2067, 1.2293, 1.2385, 1.2354, 1.2330, 1.2459, 1.2309, 1.2309,
         1.2640, 1.3680, 1.3146, 1.3305, 1.3503, 1.3247, 1.3227, 1.2775, 1.3166,
         1.4168, 1.4336, 1.4241, 1.4225, 1.4399, 1.3959, 1.4167, 1.4153, 1.3930,
         1.4625, 1.4300, 1.4192, 1.3932, 1.4630, 1.4057, 1.4330, 1.4014, 1.3945],
        [1.2868, 1.0747, 0.9295, 1.2083, 1.2298, 1.3346, 1.2602, 1.3317, 1.3317,
         1.2846, 1.5024, 1.1618, 1.8648, 1.2375, 2.3692, 1.2769, 1.1021, 2.1398,
         1.0990, 1.1533, 0.8255, 1.1097, 1.2717, 1.3696, 1.3362, 1.3689, 1.3689,
         1.3263, 1.0732, 1.3908, 1.3578, 1.1050, 1.4107, 1.3959, 1.3774, 1.3493,
         1.2389, 1.3711, 1.3278, 1.2587, 1.2108, 1.3542, 1.3155, 0.3804, 1.2086,
         0.7868, 1.3313, 1.2976, 1.2449, 0.8639, 1.2773, 0.5696, 1.2651, 1.2488],
        [1.2721, 1.2674, 1.2816, 1.2555, 1.1918, 1.2734, 1.2114, 1.2713, 1.2713,
         1.4393, 1.4249, 1.4627, 1.4590, 1.4287, 1.3070, 1.4454, 1.3939, 1.3375,
         1.7180, 1.8299, 1.9405, 1.8366, 1.5676, 1.5823, 1.7137, 1.5350, 1.5350,
         1.3206, 1.3224, 1.3581, 1.3746, 1.3146, 1.3692, 1.3750, 1.3611, 1.3604,
         1.4364, 1.4565, 1.4460, 1.4114, 1.4604, 1.4646, 1.4414, 1.2042, 1.2448,
         1.3940, 1.4907, 1.4777, 1.4459, 1.3392, 1.4650, 1.4254, 1.4541, 1.4472],
        [1.2801, 1.2904, 1.1850, 1.1481, 1.2805, 1.2734, 1.2780, 1.2792, 1.2792,
         1.4153, 1.3264, 1.3933, 1.3518, 1.4011, 1.3490, 1.4216, 1.4051, 1.0979,
         1.3247, 1.2210, 1.3511, 1.3305, 1.2879, 1.2639, 1.3204, 1.3016, 1.3016,
         1.9539, 1.6193, 1.4509, 1.5595, 1.9107, 1.4431, 1.8817, 1.4595, 1.4327,
         1.3515, 1.3185, 1.2940, 1.3165, 1.3762, 1.2762, 1.3254, 1.0877, 1.3211,
         1.5011, 1.3490, 1.2112, 1.3265, 1.4716, 1.2146, 1.5572, 1.3384, 1.3858],
        [1.4175, 1.2152, 0.4106, 0.5974, 1.0818, 1.3601, 1.2868, 1.4160, 1.4160,
         1.3256, 1.1681, 1.0890, 0.8132, 1.3630, 0.1917, 1.2303, 1.3591, 0.9847,
         1.0919, 0.7704, 0.8097, 0.9749, 1.3664, 1.3981, 1.0761, 1.4441, 1.4441,
         0.5170, 0.6092, 1.3296, 1.1327, 0.6943, 1.3467, 0.8392, 1.3543, 1.3128,
         1.1239, 0.8605, 0.8144, 1.0479, 1.3745, 1.4840, 1.0262, 2.3346, 2.2104,
         0.5910, 0.8249, 0.8864, 1.1640, 0.7294, 1.1156, 0.2935, 1.0863, 1.2383],
        [1.2430, 1.2485, 1.2579, 1.2730, 1.1844, 1.2057, 1.2068, 1.2409, 1.2409,
         0.9618, 0.9914, 0.9828, 1.0691, 1.0421, 1.1712, 0.9814, 1.0559, 1.0193,
         1.2844, 1.2611, 1.1667, 1.2244, 1.2522, 1.2401, 1.2216, 1.2428, 1.2428,
         1.2968, 1.2119, 1.2682, 1.0865, 1.1780, 1.0562, 1.2745, 1.1544, 1.2741,
         1.1386, 0.9343, 1.1537, 1.1279, 0.8267, 0.7435, 1.1424, 0.8958, 0.4735,
         1.9557, 1.5021, 1.6473, 1.6175, 1.5324, 1.1261, 1.9454, 1.5352, 1.1109]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 23 : 181.21404487698132
Test loss for epoch 23 : 181.12868957603882
Test Precision for epoch 23 : 0.26153846153846155
Test Recall for epoch 23 : 0.26153846153846155
Test F1 for epoch 23 : 0.26153846153846155


theta for epoch 24 : tensor([[1.6138, 1.6766, 1.7493, 1.7318, 1.7307, 1.6308, 1.6586, 1.6131, 1.6131,
         1.3988, 1.4081, 1.4204, 1.4145, 1.3880, 1.4160, 1.4043, 1.3922, 1.3711,
         1.2279, 1.2052, 1.2231, 1.2363, 1.2311, 1.2286, 1.2413, 1.2266, 1.2266,
         1.2607, 1.3621, 1.3093, 1.3256, 1.3454, 1.3196, 1.3184, 1.2723, 1.3114,
         1.4296, 1.4473, 1.4368, 1.4354, 1.4541, 1.4093, 1.4293, 1.4317, 1.4092,
         1.4695, 1.4342, 1.4239, 1.3958, 1.4692, 1.4097, 1.4438, 1.4045, 1.3970],
        [1.2827, 1.0720, 0.9316, 1.2043, 1.2265, 1.3311, 1.2557, 1.3280, 1.3280,
         1.2855, 1.5110, 1.1605, 1.8879, 1.2372, 2.4175, 1.2784, 1.0990, 2.1777,
         1.0989, 1.1512, 0.8253, 1.1104, 1.2693, 1.3643, 1.3318, 1.3636, 1.3636,
         1.3223, 1.0710, 1.3871, 1.3548, 1.1029, 1.4077, 1.3939, 1.3734, 1.3456,
         1.2379, 1.3768, 1.3296, 1.2586, 1.2126, 1.3603, 1.3167, 0.3792, 1.2128,
         0.7883, 1.3210, 1.2888, 1.2296, 0.8610, 1.2655, 0.5836, 1.2515, 1.2334],
        [1.2605, 1.2572, 1.2719, 1.2462, 1.1836, 1.2619, 1.2029, 1.2597, 1.2597,
         1.4502, 1.4378, 1.4740, 1.4713, 1.4392, 1.3328, 1.4564, 1.4059, 1.3511,
         1.7410, 1.8551, 1.9673, 1.8629, 1.5899, 1.6061, 1.7391, 1.5577, 1.5577,
         1.3116, 1.3131, 1.3470, 1.3639, 1.3065, 1.3583, 1.3643, 1.3501, 1.3493,
         1.4484, 1.4693, 1.4579, 1.4231, 1.4737, 1.4780, 1.4531, 1.2263, 1.2650,
         1.3948, 1.4884, 1.4761, 1.4426, 1.3421, 1.4627, 1.4323, 1.4513, 1.4439],
        [1.2694, 1.2800, 1.1760, 1.1415, 1.2707, 1.2632, 1.2678, 1.2685, 1.2685,
         1.4239, 1.3344, 1.4050, 1.3619, 1.4091, 1.3577, 1.4306, 1.4133, 1.1108,
         1.3085, 1.2106, 1.3335, 1.3147, 1.2731, 1.2483, 1.3044, 1.2856, 1.2856,
         1.9871, 1.6453, 1.4733, 1.5842, 1.9434, 1.4658, 1.9139, 1.4823, 1.4552,
         1.3615, 1.3291, 1.3027, 1.3255, 1.3882, 1.2879, 1.3348, 1.1065, 1.3350,
         1.4993, 1.3436, 1.2059, 1.3184, 1.4699, 1.2075, 1.5571, 1.3310, 1.3788],
        [1.4226, 1.2164, 0.4156, 0.6052, 1.0790, 1.3632, 1.2890, 1.4210, 1.4210,
         1.3383, 1.1782, 1.1026, 0.8226, 1.3753, 0.1949, 1.2440, 1.3714, 0.9947,
         1.0982, 0.7754, 0.8137, 0.9794, 1.3730, 1.4068, 1.0862, 1.4530, 1.4530,
         0.5357, 0.6283, 1.3443, 1.1502, 0.7127, 1.3620, 0.8601, 1.3703, 1.3287,
         1.1079, 0.8374, 0.7900, 1.0306, 1.3667, 1.4815, 1.0073, 2.3791, 2.2479,
         0.5792, 0.8135, 0.8719, 1.1446, 0.7176, 1.0988, 0.2863, 1.0699, 1.2212],
        [1.2308, 1.2385, 1.2533, 1.2653, 1.1768, 1.1942, 1.1953, 1.2287, 1.2287,
         0.9505, 0.9874, 0.9782, 1.0712, 1.0267, 1.1832, 0.9718, 1.0416, 1.0176,
         1.2682, 1.2495, 1.1644, 1.2144, 1.2353, 1.2221, 1.2050, 1.2246, 1.2246,
         1.2866, 1.2102, 1.2544, 1.0765, 1.1676, 1.0438, 1.2643, 1.1401, 1.2605,
         1.1144, 0.9057, 1.1300, 1.1044, 0.8006, 0.7172, 1.1176, 0.8951, 0.4609,
         1.9874, 1.5187, 1.6708, 1.6389, 1.5458, 1.1276, 1.9762, 1.5540, 1.1114]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 24 : 181.27426205557063
Test loss for epoch 24 : 181.17657340469012
Test Precision for epoch 24 : 0.26153846153846155
Test Recall for epoch 24 : 0.26153846153846155
Test F1 for epoch 24 : 0.26153846153846155


theta for epoch 25 : tensor([[1.6289, 1.6924, 1.7658, 1.7492, 1.7476, 1.6458, 1.6748, 1.6281, 1.6281,
         1.4021, 1.4116, 1.4240, 1.4188, 1.3912, 1.4215, 1.4078, 1.3954, 1.3752,
         1.2222, 1.1991, 1.2126, 1.2298, 1.2227, 1.2202, 1.2325, 1.2182, 1.2182,
         1.2510, 1.3496, 1.2977, 1.3142, 1.3338, 1.3081, 1.3077, 1.2607, 1.2999,
         1.4472, 1.4659, 1.4544, 1.4531, 1.4731, 1.4275, 1.4468, 1.4527, 1.4303,
         1.4767, 1.4387, 1.4289, 1.3988, 1.4756, 1.4140, 1.4549, 1.4080, 1.4000],
        [1.2862, 1.0771, 0.9406, 1.2077, 1.2308, 1.3351, 1.2588, 1.3318, 1.3318,
         1.2806, 1.5133, 1.1537, 1.9044, 1.2313, 2.4602, 1.2742, 1.0907, 2.2098,
         1.0962, 1.1463, 0.8218, 1.1083, 1.2642, 1.3562, 1.3245, 1.3554, 1.3554,
         1.3122, 1.0628, 1.3778, 1.3461, 1.0950, 1.3989, 1.3859, 1.3637, 1.3363,
         1.2432, 1.3885, 1.3374, 1.2648, 1.2208, 1.3725, 1.3240, 0.3844, 1.2232,
         0.7915, 1.3118, 1.2810, 1.2155, 0.8602, 1.2548, 0.5982, 1.2391, 1.2190],
        [1.2596, 1.2576, 1.2728, 1.2476, 1.1864, 1.2611, 1.2054, 1.2588, 1.2588,
         1.4502, 1.4399, 1.4740, 1.4722, 1.4389, 1.3469, 1.4564, 1.4074, 1.3540,
         1.7531, 1.8691, 1.9827, 1.8779, 1.6018, 1.6194, 1.7538, 1.5700, 1.5700,
         1.2996, 1.3008, 1.3329, 1.3502, 1.2954, 1.3443, 1.3505, 1.3361, 1.3353,
         1.4673, 1.4890, 1.4767, 1.4418, 1.4939, 1.4981, 1.4717, 1.2553, 1.2924,
         1.4002, 1.4900, 1.4785, 1.4433, 1.3498, 1.4643, 1.4436, 1.4526, 1.4445],
        [1.2675, 1.2785, 1.1758, 1.1436, 1.2696, 1.2619, 1.2665, 1.2666, 1.2666,
         1.4210, 1.3313, 1.4051, 1.3605, 1.4059, 1.3543, 1.4281, 1.4102, 1.1131,
         1.2926, 1.2004, 1.3159, 1.2990, 1.2586, 1.2333, 1.2886, 1.2700, 1.2700,
         2.0107, 1.6620, 1.4868, 1.5997, 1.9666, 1.4798, 1.9366, 1.4963, 1.4688,
         1.3788, 1.3473, 1.3191, 1.3421, 1.4075, 1.3073, 1.3518, 1.1323, 1.3562,
         1.5002, 1.3417, 1.2047, 1.3140, 1.4712, 1.2046, 1.5593, 1.3271, 1.3751],
        [1.4280, 1.2170, 0.4164, 0.6096, 1.0749, 1.3663, 1.2910, 1.4264, 1.4264,
         1.3349, 1.1719, 1.1005, 0.8160, 1.3717, 0.1825, 1.2417, 1.3677, 0.9885,
         1.0946, 0.7696, 0.8066, 0.9736, 1.3702, 1.4064, 1.0867, 1.4529, 1.4529,
         0.5364, 0.6291, 1.3434, 1.1513, 0.7127, 1.3616, 0.8640, 1.3706, 1.3288,
         1.1041, 0.8262, 0.7774, 1.0255, 1.3712, 1.4913, 1.0004, 2.4338, 2.2962,
         0.5546, 0.7903, 0.8457, 1.1141, 0.6935, 1.0709, 0.2661, 1.0424, 1.1933],
        [1.2315, 1.2412, 1.2613, 1.2701, 1.1824, 1.1957, 1.1967, 1.2293, 1.2293,
         0.9405, 0.9832, 0.9740, 1.0709, 1.0115, 1.1893, 0.9630, 1.0272, 1.0138,
         1.2589, 1.2452, 1.1695, 1.2118, 1.2255, 1.2115, 1.1960, 1.2137, 1.2137,
         1.2764, 1.2089, 1.2408, 1.0680, 1.1577, 1.0331, 1.2544, 1.1268, 1.2473,
         1.0991, 0.8878, 1.1153, 1.0900, 0.7856, 0.7025, 1.1016, 0.9039, 0.4610,
         2.0030, 1.5199, 1.6787, 1.6447, 1.5434, 1.1151, 1.9907, 1.5574, 1.0981]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 25 : 181.08283082765777
Test loss for epoch 25 : 180.9915256141878
Test Precision for epoch 25 : 0.26153846153846155
Test Recall for epoch 25 : 0.26153846153846155
Test F1 for epoch 25 : 0.26153846153846155


theta for epoch 26 : tensor([[1.6479, 1.7119, 1.7860, 1.7704, 1.7682, 1.6648, 1.6950, 1.6471, 1.6471,
         1.3909, 1.4005, 1.4129, 1.4083, 1.3799, 1.4120, 1.3967, 1.3841, 1.3645,
         1.2172, 1.1936, 1.2030, 1.2239, 1.2152, 1.2126, 1.2245, 1.2107, 1.2107,
         1.2385, 1.3343, 1.2836, 1.3003, 1.3195, 1.2940, 1.2942, 1.2467, 1.2858,
         1.4676, 1.4872, 1.4748, 1.4736, 1.4947, 1.4485, 1.4671, 1.4761, 1.4541,
         1.4860, 1.4456, 1.4363, 1.4043, 1.4842, 1.4208, 1.4680, 1.4140, 1.4054],
        [1.2942, 1.0870, 0.9533, 1.2155, 1.2396, 1.3434, 1.2663, 1.3399, 1.3399,
         1.2695, 1.5087, 1.1410, 1.9139, 1.2194, 2.4969, 1.2639, 1.0766, 2.2354,
         1.0953, 1.1431, 0.8198, 1.1080, 1.2610, 1.3496, 1.3187, 1.3488, 1.3488,
         1.2997, 1.0523, 1.3665, 1.3353, 1.0847, 1.3879, 1.3757, 1.3518, 1.3250,
         1.2524, 1.4038, 1.3489, 1.2747, 1.2331, 1.3882, 1.3350, 0.3937, 1.2375,
         0.7990, 1.3065, 1.2773, 1.2056, 0.8642, 1.2480, 0.6157, 1.2308, 1.2088],
        [1.2656, 1.2648, 1.2806, 1.2560, 1.1963, 1.2671, 1.2149, 1.2648, 1.2648,
         1.4379, 1.4294, 1.4615, 1.4602, 1.4266, 1.3478, 1.4441, 1.3967, 1.3444,
         1.7579, 1.8757, 1.9903, 1.8855, 1.6069, 1.6260, 1.7614, 1.5757, 1.5757,
         1.2878, 1.2887, 1.3191, 1.3366, 1.2847, 1.3305, 1.3367, 1.3223, 1.3215,
         1.4904, 1.5129, 1.4997, 1.4648, 1.5181, 1.5223, 1.4945, 1.2883, 1.3243,
         1.4112, 1.4967, 1.4860, 1.4493, 1.3634, 1.4711, 1.4603, 1.4591, 1.4504],
        [1.2718, 1.2829, 1.1817, 1.1519, 1.2746, 1.2667, 1.2712, 1.2708, 1.2708,
         1.4063, 1.3167, 1.3930, 1.3474, 1.3911, 1.3388, 1.4137, 1.3955, 1.1043,
         1.2815, 1.1951, 1.3029, 1.2880, 1.2493, 1.2235, 1.2777, 1.2594, 1.2594,
         2.0262, 1.6711, 1.4933, 1.6079, 1.9818, 1.4867, 1.9514, 1.5031, 1.4754,
         1.4010, 1.3706, 1.3406, 1.3637, 1.4316, 1.3318, 1.3738, 1.1626, 1.3823,
         1.5057, 1.3453, 1.2096, 1.3150, 1.4772, 1.2078, 1.5658, 1.3287, 1.3767],
        [1.4324, 1.2158, 0.4130, 0.6102, 1.0685, 1.3682, 1.2916, 1.4307, 1.4307,
         1.3173, 1.1511, 1.0846, 0.7956, 1.3539, 0.1572, 1.2255, 1.3500, 0.9682,
         1.0849, 0.7569, 0.7919, 0.9611, 1.3619, 1.4007, 1.0813, 1.4476, 1.4476,
         0.5249, 0.6176, 1.3329, 1.1420, 0.7005, 1.3517, 0.8569, 1.3615, 1.3193,
         1.1091, 0.8238, 0.7735, 1.0293, 1.3848, 1.5102, 1.0023, 2.4961, 2.3526,
         0.5208, 0.7588, 0.8113, 1.0759, 0.6605, 1.0353, 0.2363, 1.0071, 1.1578],
        [1.2401, 1.2518, 1.2769, 1.2826, 1.1961, 1.2053, 1.2062, 1.2377, 1.2377,
         0.9262, 0.9732, 0.9641, 1.0629, 0.9916, 1.1844, 0.9493, 1.0077, 1.0024,
         1.2581, 1.2495, 1.1830, 1.2180, 1.2243, 1.2096, 1.1959, 1.2115, 1.2115,
         1.2679, 1.2096, 1.2291, 1.0620, 1.1499, 1.0252, 1.2462, 1.1159, 1.2358,
         1.0886, 0.8762, 1.1054, 1.0806, 0.7772, 0.6946, 1.0905, 0.9177, 0.4689,
         2.0085, 1.5119, 1.6772, 1.6411, 1.5312, 1.0942, 1.9951, 1.5515, 1.0764]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 26 : 180.87501967387664
Test loss for epoch 26 : 180.80076201714556
Test Precision for epoch 26 : 0.26153846153846155
Test Recall for epoch 26 : 0.26153846153846155
Test F1 for epoch 26 : 0.26153846153846155


theta for epoch 27 : tensor([[1.6643, 1.7288, 1.8033, 1.7888, 1.7861, 1.6812, 1.7125, 1.6635, 1.6635,
         1.3809, 1.3904, 1.4029, 1.3988, 1.3701, 1.4034, 1.3868, 1.3742, 1.3548,
         1.2172, 1.1930, 1.1985, 1.2230, 1.2129, 1.2102, 1.2216, 1.2084, 1.2084,
         1.2296, 1.3223, 1.2730, 1.2897, 1.3085, 1.2834, 1.2843, 1.2361, 1.2751,
         1.4847, 1.5052, 1.4918, 1.4907, 1.5130, 1.4662, 1.4840, 1.4962, 1.4746,
         1.5000, 1.4574, 1.4488, 1.4150, 1.4974, 1.4327, 1.4858, 1.4252, 1.4160],
        [1.2986, 1.0935, 0.9620, 1.2196, 1.2451, 1.3482, 1.2703, 1.3444, 1.3444,
         1.2618, 1.5068, 1.1321, 1.9254, 1.2111, 2.5350, 1.2572, 1.0665, 2.2632,
         1.0980, 1.1435, 0.8207, 1.1112, 1.2616, 1.3466, 1.3164, 1.3458, 1.3458,
         1.2899, 1.0443, 1.3580, 1.3273, 1.0770, 1.3797, 1.3683, 1.3427, 1.3166,
         1.2582, 1.4156, 1.3568, 1.2812, 1.2422, 1.4004, 1.3424, 0.3998, 1.2486,
         0.8136, 1.3083, 1.2807, 1.2034, 0.8757, 1.2486, 0.6385, 1.2300, 1.2063],
        [1.2695, 1.2699, 1.2861, 1.2622, 1.2042, 1.2711, 1.2225, 1.2687, 1.2687,
         1.4282, 1.4216, 1.4513, 1.4505, 1.4169, 1.3500, 1.4343, 1.3890, 1.3375,
         1.7603, 1.8796, 1.9950, 1.8905, 1.6101, 1.6308, 1.7667, 1.5797, 1.5797,
         1.2808, 1.2812, 1.3098, 1.3274, 1.2786, 1.3211, 1.3274, 1.3131, 1.3122,
         1.5105, 1.5339, 1.5197, 1.4849, 1.5394, 1.5436, 1.5143, 1.3183, 1.3537,
         1.4281, 1.5092, 1.4994, 1.4613, 1.3830, 1.4838, 1.4825, 1.4715, 1.4623],
        [1.2740, 1.2853, 1.1856, 1.1581, 1.2776, 1.2695, 1.2738, 1.2730, 1.2730,
         1.3947, 1.3054, 1.3839, 1.3374, 1.3796, 1.3260, 1.4021, 1.3839, 1.0991,
         1.2766, 1.1957, 1.2960, 1.2831, 1.2462, 1.2200, 1.2729, 1.2552, 1.2552,
         2.0396, 1.6788, 1.4988, 1.6149, 1.9950, 1.4927, 1.9643, 1.5090, 1.4811,
         1.4204, 1.3913, 1.3596, 1.3826, 1.4528, 1.3540, 1.3931, 1.1897, 1.4057,
         1.5166, 1.3555, 1.2217, 1.3227, 1.4887, 1.2181, 1.5773, 1.3368, 1.3845],
        [1.4344, 1.2124, 0.4080, 0.6091, 1.0601, 1.3677, 1.2900, 1.4326, 1.4326,
         1.3009, 1.1315, 1.0704, 0.7761, 1.3375, 0.1330, 1.2109, 1.3338, 0.9494,
         1.0773, 0.7456, 0.7781, 0.9505, 1.3556, 1.3971, 1.0781, 1.4443, 1.4443,
         0.5156, 0.6080, 1.3262, 1.1365, 0.6906, 1.3455, 0.8534, 1.3561, 1.3137,
         1.1119, 0.8194, 0.7674, 1.0310, 1.3962, 1.5270, 1.0021, 2.5578, 2.4081,
         0.4883, 0.7290, 0.7791, 1.0390, 0.6289, 1.0012, 0.2078, 0.9734, 1.1236],
        [1.2441, 1.2579, 1.2877, 1.2906, 1.2055, 1.2106, 1.2112, 1.2417, 1.2417,
         0.9132, 0.9640, 0.9548, 1.0551, 0.9735, 1.1780, 0.9368, 0.9901, 0.9905,
         1.2584, 1.2549, 1.1968, 1.2252, 1.2243, 1.2089, 1.1971, 1.2106, 1.2106,
         1.2607, 1.2112, 1.2187, 1.0572, 1.1430, 1.0182, 1.2394, 1.1062, 1.2256,
         1.0707, 0.8577, 1.0882, 1.0638, 0.7617, 0.6799, 1.0720, 0.9238, 0.4700,
         2.0196, 1.5103, 1.6821, 1.6438, 1.5250, 1.0800, 2.0050, 1.5522, 1.0614]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 27 : 180.97082896352052
Test loss for epoch 27 : 180.9071279230686
Test Precision for epoch 27 : 0.26153846153846155
Test Recall for epoch 27 : 0.26153846153846155
Test F1 for epoch 27 : 0.26153846153846155


theta for epoch 28 : tensor([[1.6760, 1.7408, 1.8156, 1.8024, 1.7991, 1.6928, 1.7253, 1.6752, 1.6752,
         1.3820, 1.3913, 1.4036, 1.4001, 1.3713, 1.4053, 1.3879, 1.3753, 1.3559,
         1.2259, 1.2011, 1.2029, 1.2308, 1.2194, 1.2167, 1.2277, 1.2150, 1.2150,
         1.2285, 1.3180, 1.2702, 1.2869, 1.3052, 1.2805, 1.2821, 1.2335, 1.2724,
         1.4914, 1.5129, 1.4984, 1.4974, 1.5208, 1.4735, 1.4906, 1.5058, 1.4849,
         1.5189, 1.4748, 1.4666, 1.4314, 1.5156, 1.4500, 1.5084, 1.4419, 1.4322],
        [1.2953, 1.0923, 0.9622, 1.2158, 1.2429, 1.3452, 1.2666, 1.3412, 1.3412,
         1.2660, 1.5162, 1.1357, 1.9470, 1.2149, 2.5810, 1.2625, 1.0691, 2.3001,
         1.1059, 1.1491, 0.8261, 1.1194, 1.2678, 1.3491, 1.3194, 1.3484, 1.3484,
         1.2863, 1.0420, 1.3560, 1.3255, 1.0750, 1.3777, 1.3671, 1.3399, 1.3146,
         1.2529, 1.4161, 1.3532, 1.2764, 1.2403, 1.4014, 1.3385, 0.3947, 1.2487,
         0.8342, 1.3170, 1.2911, 1.2088, 0.8937, 1.2563, 0.6651, 1.2366, 1.2113],
        [1.2663, 1.2678, 1.2842, 1.2612, 1.2051, 1.2679, 1.2231, 1.2655, 1.2655,
         1.4296, 1.4248, 1.4521, 1.4518, 1.4185, 1.3611, 1.4355, 1.3926, 1.3416,
         1.7676, 1.8880, 2.0038, 1.8999, 1.6185, 1.6408, 1.7769, 1.5890, 1.5890,
         1.2813, 1.2809, 1.3079, 1.3255, 1.2799, 1.3191, 1.3255, 1.3112, 1.3103,
         1.5195, 1.5438, 1.5286, 1.4940, 1.5496, 1.5537, 1.5231, 1.3371, 1.3723,
         1.4495, 1.5263, 1.5172, 1.4780, 1.4071, 1.5011, 1.5086, 1.4887, 1.4789],
        [1.2699, 1.2813, 1.1831, 1.1580, 1.2742, 1.2659, 1.2702, 1.2689, 1.2689,
         1.3947, 1.3061, 1.3862, 1.3394, 1.3799, 1.3250, 1.4022, 1.3842, 1.1055,
         1.2791, 1.2036, 1.2964, 1.2855, 1.2507, 1.2243, 1.2756, 1.2586, 1.2586,
         2.0577, 1.6921, 1.5102, 1.6275, 2.0130, 1.5046, 1.9821, 1.5207, 1.4928,
         1.4286, 1.4010, 1.3674, 1.3903, 1.4628, 1.3651, 1.4013, 1.2048, 1.4179,
         1.5321, 1.3712, 1.2397, 1.3361, 1.5050, 1.2345, 1.5928, 1.3506, 1.3979],
        [1.4366, 1.2104, 0.4078, 0.6117, 1.0537, 1.3677, 1.2894, 1.4347, 1.4347,
         1.3001, 1.1277, 1.0723, 0.7720, 1.3368, 0.1242, 1.2122, 1.3332, 0.9470,
         1.0818, 0.7462, 0.7753, 0.9520, 1.3605, 1.4045, 1.0865, 1.4520, 1.4520,
         0.5232, 0.6150, 1.3368, 1.1488, 0.6979, 1.3565, 0.8679, 1.3678, 1.3252,
         1.1008, 0.8016, 0.7482, 1.0188, 1.3932, 1.5294, 0.9880, 2.6079, 2.4514,
         0.4698, 0.7127, 0.7614, 1.0141, 0.6109, 0.9799, 0.1932, 0.9526, 1.1009],
        [1.2369, 1.2526, 1.2870, 1.2871, 1.2035, 1.2046, 1.2048, 1.2345, 1.2345,
         0.9041, 0.9585, 0.9489, 1.0515, 0.9605, 1.1753, 0.9283, 0.9776, 0.9814,
         1.2565, 1.2579, 1.2073, 1.2296, 1.2220, 1.2060, 1.1956, 1.2074, 1.2074,
         1.2548, 1.2139, 1.2096, 1.0530, 1.1368, 1.0116, 1.2340, 1.0974, 1.2167,
         1.0362, 0.8228, 1.0543, 1.0303, 0.7293, 0.6481, 1.0369, 0.9114, 0.4527,
         2.0462, 1.5256, 1.7036, 1.6632, 1.5355, 1.0829, 2.0303, 1.5697, 1.0634]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 28 : 180.7867701086178
Test loss for epoch 28 : 180.71466748754017
Test Precision for epoch 28 : 0.26153846153846155
Test Recall for epoch 28 : 0.26153846153846155
Test F1 for epoch 28 : 0.26153846153846155


theta for epoch 29 : tensor([[1.6854, 1.7503, 1.8254, 1.8135, 1.8095, 1.7021, 1.7358, 1.6845, 1.6845,
         1.3928, 1.4018, 1.4139, 1.4110, 1.3825, 1.4167, 1.3987, 1.3864, 1.3666,
         1.2391, 1.2137, 1.2123, 1.2432, 1.2308, 1.2281, 1.2385, 1.2266, 1.2266,
         1.2344, 1.3205, 1.2746, 1.2911, 1.3088, 1.2847, 1.2869, 1.2379, 1.2767,
         1.4909, 1.5133, 1.4978, 1.4969, 1.5215, 1.4737, 1.4899, 1.5080, 1.4880,
         1.5364, 1.4910, 1.4834, 1.4468, 1.5323, 1.4663, 1.5295, 1.4576, 1.4475],
        [1.2880, 1.0872, 0.9575, 1.2076, 1.2366, 1.3380, 1.2587, 1.3338, 1.3338,
         1.2796, 1.5341, 1.1490, 1.9760, 1.2284, 2.6326, 1.2774, 1.0817, 2.3438,
         1.1167, 1.1577, 0.8342, 1.1306, 1.2774, 1.3549, 1.3257, 1.3543, 1.3543,
         1.2890, 1.0457, 1.3605, 1.3302, 1.0790, 1.3820, 1.3723, 1.3436, 1.3192,
         1.2406, 1.4094, 1.3424, 1.2646, 1.2315, 1.3952, 1.3274, 0.3828, 1.2419,
         0.8541, 1.3256, 1.3013, 1.2149, 0.9115, 1.2641, 0.6892, 1.2437, 1.2170],
        [1.2588, 1.2613, 1.2778, 1.2558, 1.2016, 1.2604, 1.2193, 1.2580, 1.2580,
         1.4406, 1.4377, 1.4623, 1.4625, 1.4299, 1.3800, 1.4464, 1.4059, 1.3553,
         1.7794, 1.9006, 2.0165, 1.9136, 1.6320, 1.6557, 1.7917, 1.6034, 1.6034,
         1.2882, 1.2868, 1.3125, 1.3299, 1.2875, 1.3234, 1.3299, 1.3157, 1.3148,
         1.5207, 1.5458, 1.5296, 1.4953, 1.5519, 1.5560, 1.5240, 1.3478, 1.3831,
         1.4685, 1.5411, 1.5328, 1.4927, 1.4288, 1.5162, 1.5318, 1.5037, 1.4934],
        [1.2627, 1.2741, 1.1774, 1.1547, 1.2676, 1.2593, 1.2634, 1.2618, 1.2618,
         1.4060, 1.3183, 1.3995, 1.3527, 1.3917, 1.3350, 1.4134, 1.3958, 1.1231,
         1.2863, 1.2160, 1.3014, 1.2926, 1.2600, 1.2334, 1.2831, 1.2668, 1.2668,
         2.0793, 1.7099, 1.5264, 1.6447, 2.0347, 1.5214, 2.0036, 1.5372, 1.5093,
         1.4293, 1.4035, 1.3679, 1.3906, 1.4653, 1.3690, 1.4021, 1.2117, 1.4226,
         1.5464, 1.3867, 1.2577, 1.3493, 1.5201, 1.2511, 1.6068, 1.3641, 1.4109],
        [1.4386, 1.2087, 0.4097, 0.6158, 1.0482, 1.3677, 1.2892, 1.4367, 1.4367,
         1.3100, 1.1345, 1.0849, 0.7776, 1.3469, 0.1247, 1.2243, 1.3435, 0.9554,
         1.0926, 0.7526, 0.7776, 0.9595, 1.3713, 1.4177, 1.1009, 1.4653, 1.4653,
         0.5406, 0.6317, 1.3587, 1.1724, 0.7154, 1.3788, 0.8934, 1.3908, 1.3481,
         1.0821, 0.7768, 0.7218, 0.9991, 1.3826, 1.5241, 0.9665, 2.6526, 2.4887,
         0.4543, 0.6990, 0.7464, 0.9902, 0.5954, 0.9601, 0.1822, 0.9334, 1.0788],
        [1.2252, 1.2427, 1.2815, 1.2788, 1.1971, 1.1942, 1.1939, 1.2226, 1.2226,
         0.9096, 0.9671, 0.9566, 1.0618, 0.9627, 1.1852, 0.9342, 0.9801, 0.9857,
         1.2568, 1.2628, 1.2189, 1.2360, 1.2221, 1.2054, 1.1965, 1.2067, 1.2067,
         1.2542, 1.2214, 1.2060, 1.0539, 1.1354, 1.0101, 1.2340, 1.0939, 1.2132,
         0.9916, 0.7785, 1.0104, 0.9868, 0.6873, 0.6068, 0.9918, 0.8877, 0.4255,
         2.0758, 1.5446, 1.7288, 1.6861, 1.5492, 1.0896, 2.0586, 1.5909, 1.0692]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 29 : 180.62662416579857
Test loss for epoch 29 : 180.5391438927161
Test Precision for epoch 29 : 0.26153846153846155
Test Recall for epoch 29 : 0.26153846153846155
Test F1 for epoch 29 : 0.26153846153846155


theta for epoch 30 : tensor([[1.6978, 1.7626, 1.8378, 1.8273, 1.8227, 1.7142, 1.7492, 1.6968, 1.6968,
         1.4053, 1.4139, 1.4257, 1.4233, 1.3954, 1.4294, 1.4110, 1.3991, 1.3787,
         1.2484, 1.2220, 1.2179, 1.2517, 1.2385, 1.2359, 1.2457, 1.2345, 1.2345,
         1.2433, 1.3261, 1.2821, 1.2983, 1.3154, 1.2920, 1.2948, 1.2454, 1.2842,
         1.4907, 1.5140, 1.4975, 1.4967, 1.5223, 1.4741, 1.4896, 1.5102, 1.4914,
         1.5443, 1.4978, 1.4907, 1.4531, 1.5394, 1.4733, 1.5408, 1.4642, 1.4536],
        [1.2838, 1.0854, 0.9557, 1.2026, 1.2336, 1.3339, 1.2541, 1.3296, 1.3296,
         1.2944, 1.5524, 1.1639, 2.0047, 1.2433, 2.6834, 1.2936, 1.0961, 2.3872,
         1.1259, 1.1645, 0.8410, 1.1401, 1.2855, 1.3591, 1.3301, 1.3587, 1.3587,
         1.2963, 1.0540, 1.3696, 1.3395, 1.0876, 1.3909, 1.3820, 1.3519, 1.3286,
         1.2305, 1.4044, 1.3335, 1.2548, 1.2249, 1.3907, 1.3181, 0.3734, 1.2372,
         0.8655, 1.3261, 1.3035, 1.2137, 0.9214, 1.2641, 0.7038, 1.2431, 1.2152],
        [1.2534, 1.2570, 1.2734, 1.2525, 1.2003, 1.2551, 1.2177, 1.2526, 1.2526,
         1.4535, 1.4522, 1.4741, 1.4747, 1.4432, 1.3991, 1.4589, 1.4212, 1.3705,
         1.7921, 1.9137, 2.0296, 1.9278, 1.6466, 1.6718, 1.8073, 1.6190, 1.6190,
         1.2983, 1.2959, 1.3204, 1.3375, 1.2984, 1.3310, 1.3376, 1.3235, 1.3226,
         1.5221, 1.5481, 1.5309, 1.4970, 1.5543, 1.5584, 1.5251, 1.3582, 1.3941,
         1.4779, 1.5464, 1.5389, 1.4981, 1.4408, 1.5218, 1.5449, 1.5093, 1.4986],
        [1.2590, 1.2703, 1.1751, 1.1548, 1.2645, 1.2562, 1.2600, 1.2581, 1.2581,
         1.4216, 1.3350, 1.4170, 1.3705, 1.4079, 1.3492, 1.4289, 1.4120, 1.1452,
         1.2926, 1.2273, 1.3055, 1.2987, 1.2685, 1.2420, 1.2896, 1.2743, 1.2743,
         2.1003, 1.7277, 1.5431, 1.6621, 2.0559, 1.5386, 2.0246, 1.5541, 1.5264,
         1.4316, 1.4076, 1.3703, 1.3927, 1.4692, 1.3747, 1.4047, 1.2196, 1.4287,
         1.5530, 1.3953, 1.2693, 1.3558, 1.5278, 1.2613, 1.6129, 1.3708, 1.4169],
        [1.4395, 1.2054, 0.4078, 0.6167, 1.0406, 1.3664, 1.2874, 1.4376, 1.4376,
         1.3176, 1.1382, 1.0947, 0.7791, 1.3548, 0.1198, 1.2340, 1.3517, 0.9604,
         1.0974, 0.7524, 0.7727, 0.9606, 1.3763, 1.4253, 1.1095, 1.4730, 1.4730,
         0.5532, 0.6437, 1.3795, 1.1938, 0.7283, 1.3999, 0.9155, 1.4127, 1.3697,
         1.0693, 0.7576, 0.7011, 0.9854, 1.3781, 1.5250, 0.9508, 2.7035, 2.5324,
         0.4249, 0.6718, 0.7173, 0.9520, 0.5660, 0.9258, 0.1577, 0.8999, 1.0422],
        [1.2216, 1.2408, 1.2837, 1.2785, 1.1991, 1.1923, 1.1913, 1.2191, 1.2191,
         0.9369, 0.9963, 0.9850, 1.0914, 0.9866, 1.2129, 0.9614, 1.0041, 1.0103,
         1.2661, 1.2763, 1.2385, 1.2511, 1.2316, 1.2146, 1.2068, 1.2157, 1.2157,
         1.2637, 1.2386, 1.2128, 1.0657, 1.1445, 1.0197, 1.2441, 1.1014, 1.2201,
         0.9507, 0.7397, 0.9703, 0.9469, 0.6511, 0.5718, 0.9505, 0.8674, 0.4051,
         2.0863, 1.5452, 1.7353, 1.6905, 1.5443, 1.0793, 2.0678, 1.5938, 1.0581]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 30 : 180.5499977047802
Test loss for epoch 30 : 180.460886761846
Test Precision for epoch 30 : 0.26153846153846155
Test Recall for epoch 30 : 0.26153846153846155
Test F1 for epoch 30 : 0.26153846153846155


theta for epoch 31 : tensor([[1.7151, 1.7798, 1.8549, 1.8459, 1.8407, 1.7314, 1.7675, 1.7142, 1.7142,
         1.4064, 1.4144, 1.4260, 1.4240, 1.3969, 1.4303, 1.4119, 1.4005, 1.3791,
         1.2498, 1.2226, 1.2160, 1.2524, 1.2388, 1.2363, 1.2453, 1.2350, 1.2350,
         1.2510, 1.3305, 1.2886, 1.3045, 1.3208, 1.2982, 1.3015, 1.2519, 1.2906,
         1.4945, 1.5187, 1.5012, 1.5005, 1.5271, 1.4785, 1.4933, 1.5161, 1.4986,
         1.5507, 1.5035, 1.4969, 1.4584, 1.5451, 1.4791, 1.5504, 1.4696, 1.4587],
        [1.2884, 1.0929, 0.9626, 1.2065, 1.2396, 1.3384, 1.2583, 1.3341, 1.3341,
         1.2964, 1.5568, 1.1666, 2.0189, 1.2456, 2.7213, 1.2972, 1.0986, 2.4171,
         1.1341, 1.1702, 0.8483, 1.1484, 1.2923, 1.3618, 1.3329, 1.3615, 1.3615,
         1.3060, 1.0651, 1.3812, 1.3511, 1.0989, 1.4021, 1.3939, 1.3625, 1.3405,
         1.2275, 1.4059, 1.3313, 1.2520, 1.2254, 1.3927, 1.3157, 0.3727, 1.2395,
         0.8829, 1.3312, 1.3102, 1.2181, 0.9372, 1.2691, 0.7234, 1.2478, 1.2189],
        [1.2544, 1.2588, 1.2752, 1.2555, 1.2053, 1.2561, 1.2225, 1.2537, 1.2537,
         1.4539, 1.4541, 1.4733, 1.4742, 1.4442, 1.4049, 1.4591, 1.4240, 1.3728,
         1.8025, 1.9244, 2.0399, 1.9395, 1.6592, 1.6859, 1.8207, 1.6327, 1.6327,
         1.3078, 1.3043, 1.3277, 1.3445, 1.3085, 1.3380, 1.3445, 1.3306, 1.3299,
         1.5277, 1.5544, 1.5363, 1.5028, 1.5608, 1.5648, 1.5304, 1.3723, 1.4090,
         1.4863, 1.5510, 1.5442, 1.5030, 1.4518, 1.5267, 1.5567, 1.5143, 1.5032],
        [1.2630, 1.2741, 1.1805, 1.1624, 1.2689, 1.2607, 1.2643, 1.2621, 1.2621,
         1.4285, 1.3432, 1.4253, 1.3796, 1.4156, 1.3546, 1.4355, 1.4194, 1.1589,
         1.2960, 1.2355, 1.3066, 1.3017, 1.2742, 1.2478, 1.2933, 1.2791, 1.2791,
         2.1152, 1.7400, 1.5547, 1.6741, 2.0709, 1.5508, 2.0397, 1.5659, 1.5384,
         1.4399, 1.4179, 1.3788, 1.4009, 1.4790, 1.3865, 1.4133, 1.2330, 1.4406,
         1.5609, 1.4059, 1.2833, 1.3646, 1.5367, 1.2741, 1.6197, 1.3796, 1.4250],
        [1.4421, 1.2031, 0.4044, 0.6165, 1.0337, 1.3666, 1.2871, 1.4402, 1.4402,
         1.3141, 1.1306, 1.0940, 0.7699, 1.3519, 0.1051, 1.2331, 1.3490, 0.9544,
         1.0946, 0.7445, 0.7594, 0.9538, 1.3738, 1.4257, 1.1106, 1.4735, 1.4735,
         0.5578, 0.6476, 1.3945, 1.2088, 0.7335, 1.4153, 0.9305, 1.4289, 1.3855,
         1.0635, 0.7455, 0.6873, 0.9786, 1.3807, 1.5331, 0.9421, 2.7608, 2.5829,
         0.3876, 0.6372, 0.6807, 0.9067, 0.5288, 0.8844, 0.1251, 0.8592, 0.9987],
        [1.2263, 1.2470, 1.2936, 1.2861, 1.2092, 1.1986, 1.1970, 1.2237, 1.2237,
         0.9584, 1.0185, 1.0064, 1.1129, 1.0051, 1.2309, 0.9823, 1.0224, 1.0268,
         1.2741, 1.2881, 1.2560, 1.2644, 1.2401, 1.2229, 1.2161, 1.2241, 1.2241,
         1.2753, 1.2577, 1.2221, 1.0800, 1.1559, 1.0321, 1.2565, 1.1116, 1.2294,
         0.9146, 0.7070, 0.9351, 0.9121, 0.6210, 0.5430, 0.9140, 0.8513, 0.3909,
         2.0904, 1.5401, 1.7360, 1.6889, 1.5333, 1.0638, 2.0705, 1.5909, 1.0418]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 31 : 180.46607989035022
Test loss for epoch 31 : 180.38104967372317
Test Precision for epoch 31 : 0.26153846153846155
Test Recall for epoch 31 : 0.26153846153846155
Test F1 for epoch 31 : 0.26153846153846155


theta for epoch 32 : tensor([[1.7356, 1.8000, 1.8748, 1.8674, 1.8615, 1.7516, 1.7889, 1.7346, 1.7346,
         1.3970, 1.4046, 1.4158, 1.4143, 1.3881, 1.4207, 1.4024, 1.3915, 1.3690,
         1.2462, 1.2179, 1.2094, 1.2480, 1.2343, 1.2319, 1.2402, 1.2307, 1.2307,
         1.2537, 1.3298, 1.2901, 1.3056, 1.3212, 1.2995, 1.3032, 1.2535, 1.2921,
         1.5032, 1.5282, 1.5097, 1.5091, 1.5365, 1.4876, 1.5019, 1.5267, 1.5104,
         1.5617, 1.5141, 1.5081, 1.4691, 1.5555, 1.4901, 1.5645, 1.4803, 1.4691],
        [1.3007, 1.1087, 0.9776, 1.2183, 1.2534, 1.3505, 1.2703, 1.3461, 1.3461,
         1.2857, 1.5477, 1.1571, 2.0189, 1.2355, 2.7460, 1.2882, 1.0893, 2.4334,
         1.1427, 1.1763, 0.8578, 1.1571, 1.2992, 1.3643, 1.3356, 1.3642, 1.3642,
         1.3132, 1.0745, 1.3904, 1.3604, 1.1084, 1.4107, 1.4032, 1.3707, 1.3501,
         1.2318, 1.4141, 1.3358, 1.2563, 1.2333, 1.4014, 1.3202, 0.3806, 1.2491,
         0.9133, 1.3486, 1.3291, 1.2357, 0.9658, 1.2867, 0.7552, 1.2654, 1.2359],
        [1.2608, 1.2661, 1.2824, 1.2638, 1.2156, 1.2626, 1.2326, 1.2601, 1.2601,
         1.4422, 1.4437, 1.4604, 1.4614, 1.4332, 1.3980, 1.4471, 1.4146, 1.3626,
         1.8112, 1.9330, 2.0480, 1.9493, 1.6704, 1.6986, 1.8323, 1.6450, 1.6450,
         1.3118, 1.3070, 1.3296, 1.3459, 1.3130, 1.3395, 1.3459, 1.3324, 1.3317,
         1.5379, 1.5652, 1.5463, 1.5133, 1.5718, 1.5757, 1.5403, 1.3903, 1.4283,
         1.4995, 1.5605, 1.5544, 1.5131, 1.4674, 1.5367, 1.5725, 1.5245, 1.5131],
        [1.2736, 1.2845, 1.1925, 1.1765, 1.2800, 1.2718, 1.2752, 1.2727, 1.2727,
         1.4262, 1.3425, 1.4242, 1.3796, 1.4142, 1.3508, 1.4329, 1.4178, 1.1638,
         1.2975, 1.2415, 1.3058, 1.3028, 1.2780, 1.2518, 1.2950, 1.2821, 1.2821,
         2.1210, 1.7437, 1.5581, 1.6777, 2.0771, 1.5547, 2.0458, 1.5694, 1.5422,
         1.4544, 1.4344, 1.3938, 1.4154, 1.4948, 1.4045, 1.4283, 1.2522, 1.4585,
         1.5751, 1.4239, 1.3049, 1.3811, 1.5521, 1.2948, 1.6326, 1.3960, 1.4406],
        [1.4498, 1.2060, 0.4055, 0.6206, 1.0321, 1.3718, 1.2921, 1.4478, 1.4478,
         1.3050, 1.1177, 1.0887, 0.7567, 1.3434, 0.0881, 1.2270, 1.3409, 0.9440,
         1.0910, 0.7359, 0.7449, 0.9462, 1.3699, 1.4245, 1.1108, 1.4724, 1.4724,
         0.5595, 0.6483, 1.4051, 1.2196, 0.7351, 1.4260, 0.9418, 1.4404, 1.3968,
         1.0579, 0.7337, 0.6739, 0.9721, 1.3834, 1.5412, 0.9335, 2.8190, 2.6341,
         0.3550, 0.6079, 0.6498, 0.8668, 0.4965, 0.8484, 0.0966, 0.8240, 0.9603],
        [1.2319, 1.2542, 1.3043, 1.2946, 1.2202, 1.2060, 1.2035, 1.2293, 1.2293,
         0.9567, 1.0171, 1.0040, 1.1106, 1.0018, 1.2253, 0.9801, 1.0189, 1.0191,
         1.2695, 1.2867, 1.2598, 1.2646, 1.2361, 1.2188, 1.2126, 1.2200, 1.2200,
         1.2775, 1.2671, 1.2220, 1.0843, 1.1575, 1.0346, 1.2592, 1.1122, 1.2293,
         0.8776, 0.6733, 0.8989, 0.8762, 0.5895, 0.5127, 0.8765, 0.8333, 0.3742,
         2.1065, 1.5478, 1.7495, 1.7001, 1.5348, 1.0611, 2.0852, 1.6009, 1.0384]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 32 : 180.30856038981372
Test loss for epoch 32 : 180.21917872573147
Test Precision for epoch 32 : 0.26153846153846155
Test Recall for epoch 32 : 0.26153846153846155
Test F1 for epoch 32 : 0.26153846153846155


theta for epoch 33 : tensor([[1.7537, 1.8176, 1.8922, 1.8864, 1.8799, 1.7694, 1.8079, 1.7527, 1.7527,
         1.3913, 1.3983, 1.4091, 1.4080, 1.3831, 1.4146, 1.3965, 1.3863, 1.3625,
         1.2422, 1.2129, 1.2028, 1.2433, 1.2297, 1.2274, 1.2350, 1.2264, 1.2264,
         1.2509, 1.3235, 1.2863, 1.3012, 1.3159, 1.2952, 1.2994, 1.2497, 1.2882,
         1.5165, 1.5422, 1.5229, 1.5223, 1.5506, 1.5014, 1.5151, 1.5415, 1.5268,
         1.5761, 1.5285, 1.5229, 1.4837, 1.5693, 1.5049, 1.5816, 1.4949, 1.4835],
        [1.3133, 1.1247, 0.9924, 1.2303, 1.2676, 1.3628, 1.2826, 1.3583, 1.3583,
         1.2767, 1.5393, 1.1497, 2.0189, 1.2273, 2.7701, 1.2810, 1.0822, 2.4497,
         1.1498, 1.1810, 0.8667, 1.1643, 1.3050, 1.3657, 1.3370, 1.3659, 1.3659,
         1.3139, 1.0775, 1.3931, 1.3632, 1.1113, 1.4127, 1.4058, 1.3725, 1.3534,
         1.2415, 1.4272, 1.3455, 1.2658, 1.2465, 1.4150, 1.3298, 0.3940, 1.2639,
         0.9498, 1.3725, 1.3545, 1.2608, 1.0005, 1.3113, 0.7916, 1.2902, 1.2604],
        [1.2665, 1.2724, 1.2886, 1.2712, 1.2250, 1.2682, 1.2418, 1.2658, 1.2658,
         1.4322, 1.4347, 1.4491, 1.4501, 1.4238, 1.3916, 1.4366, 1.4068, 1.3538,
         1.8213, 1.9427, 2.0570, 1.9600, 1.6832, 1.7128, 1.8452, 1.6589, 1.6589,
         1.3081, 1.3020, 1.3240, 1.3398, 1.3099, 1.3335, 1.3398, 1.3266, 1.3260,
         1.5518, 1.5797, 1.5599, 1.5275, 1.5863, 1.5901, 1.5539, 1.4114, 1.4510,
         1.5145, 1.5720, 1.5665, 1.5254, 1.4846, 1.5488, 1.5895, 1.5368, 1.5252],
        [1.2839, 1.2947, 1.2042, 1.1902, 1.2907, 1.2827, 1.2859, 1.2831, 1.2831,
         1.4266, 1.3445, 1.4256, 1.3824, 1.4157, 1.3496, 1.4330, 1.4190, 1.1711,
         1.2972, 1.2456, 1.3032, 1.3020, 1.2800, 1.2541, 1.2950, 1.2833, 1.2833,
         2.1217, 1.7428, 1.5570, 1.6766, 2.0781, 1.5542, 2.0469, 1.5685, 1.5416,
         1.4733, 1.4554, 1.4133, 1.4344, 1.5149, 1.4270, 1.4478, 1.2752, 1.4807,
         1.5920, 1.4452, 1.3299, 1.4011, 1.5702, 1.3192, 1.6477, 1.4158, 1.4597],
        [1.4606, 1.2129, 0.4119, 0.6294, 1.0353, 1.3805, 1.3008, 1.4586, 1.4586,
         1.3034, 1.1126, 1.0913, 0.7513, 1.3424, 0.0797, 1.2286, 1.3403, 0.9418,
         1.0922, 0.7324, 0.7349, 0.9435, 1.3699, 1.4269, 1.1153, 1.4748, 1.4748,
         0.5631, 0.6504, 1.4142, 1.2294, 0.7379, 1.4349, 0.9533, 1.4502, 1.4065,
         1.0475, 0.7179, 0.6564, 0.9611, 1.3810, 1.5442, 0.9205, 2.8737, 2.6815,
         0.3318, 0.5878, 0.6287, 0.8357, 0.4734, 0.8213, 0.0771, 0.7979, 0.9302],
        [1.2326, 1.2565, 1.3101, 1.2982, 1.2262, 1.2085, 1.2051, 1.2300, 1.2300,
         0.9489, 1.0095, 0.9950, 1.1024, 0.9934, 1.2138, 0.9718, 1.0103, 1.0047,
         1.2546, 1.2746, 1.2523, 1.2538, 1.2218, 1.2043, 1.1984, 1.2056, 1.2056,
         1.2683, 1.2650, 1.2110, 1.0771, 1.1475, 1.0256, 1.2508, 1.1015, 1.2181,
         0.8372, 0.6364, 0.8594, 0.8369, 0.5544, 0.4786, 0.8358, 0.8107, 0.3528,
         2.1348, 1.5684, 1.7757, 1.7241, 1.5490, 1.0714, 2.1120, 1.6238, 1.0480]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 33 : 180.2184435142587
Test loss for epoch 33 : 180.11629284070864
Test Precision for epoch 33 : 0.26153846153846155
Test Recall for epoch 33 : 0.26153846153846155
Test F1 for epoch 33 : 0.26153846153846155


theta for epoch 34 : tensor([[1.7646, 1.8280, 1.9021, 1.8980, 1.8909, 1.7801, 1.8197, 1.7636, 1.7636,
         1.3967, 1.4030, 1.4133, 1.4126, 1.3891, 1.4191, 1.4015, 1.3921, 1.3669,
         1.2443, 1.2140, 1.2028, 1.2449, 1.2315, 1.2294, 1.2361, 1.2285, 1.2285,
         1.2488, 1.3180, 1.2832, 1.2976, 1.3113, 1.2918, 1.2962, 1.2467, 1.2850,
         1.5342, 1.5607, 1.5405, 1.5400, 1.5689, 1.5196, 1.5328, 1.5605, 1.5475,
         1.5863, 1.5390, 1.5338, 1.4946, 1.5789, 1.5158, 1.5944, 1.5057, 1.4942],
        [1.3181, 1.1330, 0.9987, 1.2343, 1.2740, 1.3673, 1.2871, 1.3628, 1.3628,
         1.2795, 1.5419, 1.1545, 2.0286, 1.2311, 2.8021, 1.2857, 1.0874, 2.4751,
         1.1568, 1.1860, 0.8756, 1.1715, 1.3115, 1.3682, 1.3391, 1.3686, 1.3686,
         1.3117, 1.0774, 1.3936, 1.3634, 1.1112, 1.4123, 1.4058, 1.3718, 1.3543,
         1.2556, 1.4441, 1.3592, 1.2796, 1.2639, 1.4323, 1.3436, 0.4107, 1.2827,
         0.9785, 1.3906, 1.3740, 1.2811, 1.0280, 1.3304, 0.8188, 1.3099, 1.2800],
        [1.2645, 1.2711, 1.2869, 1.2708, 1.2267, 1.2663, 1.2433, 1.2638, 1.2638,
         1.4308, 1.4344, 1.4463, 1.4474, 1.4231, 1.3922, 1.4349, 1.4076, 1.3534,
         1.8365, 1.9572, 2.0706, 1.9755, 1.7012, 1.7323, 1.8631, 1.6782, 1.6782,
         1.3024, 1.2949, 1.3165, 1.3317, 1.3047, 1.3256, 1.3317, 1.3190, 1.3184,
         1.5687, 1.5972, 1.5765, 1.5447, 1.6038, 1.6074, 1.5706, 1.4348, 1.4763,
         1.5225, 1.5769, 1.5720, 1.5312, 1.4946, 1.5543, 1.5990, 1.5425, 1.5308],
        [1.2863, 1.2967, 1.2076, 1.1955, 1.2934, 1.2855, 1.2884, 1.2854, 1.2854,
         1.4340, 1.3533, 1.4336, 1.3920, 1.4241, 1.3550, 1.4399, 1.4272, 1.1845,
         1.2969, 1.2492, 1.3008, 1.3013, 1.2819, 1.2564, 1.2950, 1.2846, 1.2846,
         2.1277, 1.7479, 1.5622, 1.6817, 2.0845, 1.5599, 2.0534, 1.5737, 1.5473,
         1.4951, 1.4792, 1.4358, 1.4564, 1.5377, 1.4524, 1.4702, 1.3002, 1.5055,
         1.6014, 1.4594, 1.3478, 1.4144, 1.5809, 1.3366, 1.6552, 1.4288, 1.4720],
        [1.4664, 1.2150, 0.4147, 0.6344, 1.0340, 1.3844, 1.3048, 1.4644, 1.4644,
         1.3097, 1.1149, 1.1014, 0.7522, 1.3496, 0.0762, 1.2382, 1.3480, 0.9468,
         1.0956, 0.7307, 0.7262, 0.9428, 1.3723, 1.4318, 1.1219, 1.4796, 1.4796,
         0.5662, 0.6520, 1.4234, 1.2390, 0.7401, 1.4438, 0.9643, 1.4600, 1.4163,
         1.0381, 0.7032, 0.6402, 0.9511, 1.3796, 1.5480, 0.9084, 2.9300, 2.7303,
         0.3042, 0.5632, 0.6027, 0.7987, 0.4456, 0.7884, 0.0536, 0.7662, 0.8939],
        [1.2309, 1.2563, 1.3130, 1.2992, 1.2300, 1.2089, 1.2044, 1.2284, 1.2284,
         0.9655, 1.0258, 1.0095, 1.1175, 1.0096, 1.2249, 0.9875, 1.0261, 1.0147,
         1.2512, 1.2735, 1.2550, 1.2540, 1.2193, 1.2018, 1.1959, 1.2033, 1.2033,
         1.2632, 1.2665, 1.2047, 1.0746, 1.1419, 1.0218, 1.2466, 1.0959, 1.2117,
         0.8011, 0.6057, 0.8245, 0.8021, 0.5254, 0.4511, 0.7996, 0.7907, 0.3375,
         2.1517, 1.5782, 1.7911, 1.7372, 1.5521, 1.0716, 2.1274, 1.6359, 1.0475]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 34 : 180.10895135678425
Test loss for epoch 34 : 180.00186362306277
Test Precision for epoch 34 : 0.26153846153846155
Test Recall for epoch 34 : 0.26153846153846155
Test F1 for epoch 34 : 0.26153846153846155


theta for epoch 35 : tensor([[1.7702, 1.8329, 1.9065, 1.9042, 1.8964, 1.7854, 1.8262, 1.7692, 1.7692,
         1.4093, 1.4149, 1.4246, 1.4243, 1.4024, 1.4306, 1.4138, 1.4052, 1.3784,
         1.2511, 1.2199, 1.2079, 1.2512, 1.2383, 1.2363, 1.2423, 1.2356, 1.2356,
         1.2505, 1.3162, 1.2842, 1.2978, 1.3104, 1.2923, 1.2969, 1.2478, 1.2859,
         1.5548, 1.5819, 1.5609, 1.5604, 1.5900, 1.5406, 1.5533, 1.5819, 1.5708,
         1.5904, 1.5438, 1.5389, 1.5000, 1.5825, 1.5210, 1.6009, 1.5109, 1.4993],
        [1.3158, 1.1339, 0.9971, 1.2308, 1.2732, 1.3647, 1.2844, 1.3602, 1.3602,
         1.2933, 1.5549, 1.1705, 2.0475, 1.2460, 2.8413, 1.3017, 1.1042, 2.5090,
         1.1624, 1.1899, 0.8832, 1.1776, 1.3177, 1.3707, 1.3410, 1.3714, 1.3714,
         1.3103, 1.0777, 1.3953, 1.3647, 1.1115, 1.4131, 1.4068, 1.3722, 1.3564,
         1.2725, 1.4633, 1.3754, 1.2961, 1.2838, 1.4520, 1.3600, 0.4294, 1.3041,
         0.9973, 1.4009, 1.3857, 1.2946, 1.0461, 1.3421, 0.8347, 1.3224, 1.2929],
        [1.2565, 1.2636, 1.2789, 1.2641, 1.2222, 1.2583, 1.2386, 1.2559, 1.2559,
         1.4356, 1.4401, 1.4496, 1.4508, 1.4288, 1.3978, 1.4393, 1.4147, 1.3590,
         1.8548, 1.9745, 2.0868, 1.9939, 1.7226, 1.7550, 1.8840, 1.7008, 1.7008,
         1.2992, 1.2902, 1.3117, 1.3262, 1.3019, 1.3203, 1.3261, 1.3140, 1.3135,
         1.5874, 1.6164, 1.5951, 1.5639, 1.6229, 1.6265, 1.5891, 1.4593, 1.5032,
         1.5230, 1.5745, 1.5701, 1.5300, 1.4969, 1.5525, 1.6005, 1.5410, 1.5293],
        [1.2806, 1.2907, 1.2027, 1.1924, 1.2879, 1.2802, 1.2829, 1.2798, 1.2798,
         1.4437, 1.3642, 1.4436, 1.4037, 1.4349, 1.3622, 1.4491, 1.4376, 1.1990,
         1.2948, 1.2506, 1.2967, 1.2986, 1.2819, 1.2567, 1.2931, 1.2840, 1.2840,
         2.1444, 1.7645, 1.5791, 1.6983, 2.1017, 1.5773, 2.0708, 1.5906, 1.5646,
         1.5178, 1.5038, 1.4591, 1.4793, 1.5611, 1.4784, 1.4935, 1.3251, 1.5308,
         1.6015, 1.4644, 1.3562, 1.4187, 1.5822, 1.3450, 1.6531, 1.4326, 1.4753],
        [1.4681, 1.2132, 0.4145, 0.6361, 1.0291, 1.3841, 1.3049, 1.4662, 1.4662,
         1.3224, 1.1233, 1.1173, 0.7582, 1.3632, 0.0764, 1.2539, 1.3622, 0.9574,
         1.1012, 0.7306, 0.7186, 0.9441, 1.3768, 1.4388, 1.1304, 1.4867, 1.4867,
         0.5719, 0.6562, 1.4369, 1.2524, 0.7451, 1.4568, 0.9784, 1.4739, 1.4302,
         1.0292, 0.6893, 0.6246, 0.9416, 1.3785, 1.5522, 0.8969, 2.9876, 2.7802,
         0.2717, 0.5334, 0.5710, 0.7555, 0.4126, 0.7491, 0.0256, 0.7282, 0.8508],
        [1.2292, 1.2558, 1.3152, 1.2996, 1.2336, 1.2093, 1.2037, 1.2268, 1.2268,
         1.0023, 1.0621, 1.0441, 1.1523, 1.0461, 1.2550, 1.0235, 1.0623, 1.0453,
         1.2609, 1.2850, 1.2695, 1.2667, 1.2300, 1.2126, 1.2067, 1.2144, 1.2144,
         1.2672, 1.2765, 1.2084, 1.0821, 1.1458, 1.0283, 1.2518, 1.1006, 1.2152,
         0.7699, 0.5817, 0.7944, 0.7720, 0.5031, 0.4308, 0.7683, 0.7732, 0.3290,
         2.1542, 1.5741, 1.7923, 1.7361, 1.5412, 1.0589, 2.1283, 1.6340, 1.0340]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 35 : 179.94493420538186
Test loss for epoch 35 : 179.84118919884642
Test Precision for epoch 35 : 0.26153846153846155
Test Recall for epoch 35 : 0.26153846153846155
Test F1 for epoch 35 : 0.26153846153846155


theta for epoch 36 : tensor([[1.7764, 1.8383, 1.9114, 1.9109, 1.9025, 1.7913, 1.8332, 1.7754, 1.7754,
         1.4159, 1.4208, 1.4299, 1.4298, 1.4098, 1.4359, 1.4200, 1.4123, 1.3839,
         1.2570, 1.2249, 1.2125, 1.2566, 1.2444, 1.2426, 1.2478, 1.2420, 1.2420,
         1.2549, 1.3171, 1.2879, 1.3007, 1.3123, 1.2954, 1.3002, 1.2515, 1.2894,
         1.5753, 1.6030, 1.5813, 1.5807, 1.6108, 1.5614, 1.5738, 1.6029, 1.5939,
         1.5961, 1.5504, 1.5460, 1.5076, 1.5878, 1.5282, 1.6087, 1.5182, 1.5067],
        [1.3139, 1.1351, 0.9954, 1.2275, 1.2727, 1.3625, 1.2821, 1.3580, 1.3580,
         1.3080, 1.5680, 1.1878, 2.0659, 1.2621, 2.8796, 1.3187, 1.1223, 2.5426,
         1.1654, 1.1915, 0.8887, 1.1811, 1.3218, 1.3713, 1.3408, 1.3723, 1.3723,
         1.3110, 1.0799, 1.3993, 1.3682, 1.1135, 1.4160, 1.4099, 1.3749, 1.3609,
         1.2906, 1.4832, 1.3925, 1.3136, 1.3048, 1.4723, 1.3773, 0.4488, 1.3263,
         1.0189, 1.4152, 1.4014, 1.3131, 1.0671, 1.3583, 0.8523, 1.3396, 1.3107],
        [1.2507, 1.2582, 1.2730, 1.2595, 1.2199, 1.2525, 1.2361, 1.2502, 1.2502,
         1.4353, 1.4405, 1.4477, 1.4489, 1.4293, 1.3976, 1.4386, 1.4164, 1.3593,
         1.8694, 1.9877, 2.0988, 2.0082, 1.7404, 1.7740, 1.9010, 1.7197, 1.7197,
         1.2999, 1.2893, 1.3109, 1.3245, 1.3029, 1.3189, 1.3244, 1.3129, 1.3125,
         1.6065, 1.6359, 1.6139, 1.5834, 1.6424, 1.6459, 1.6079, 1.4838, 1.5302,
         1.5264, 1.5753, 1.5713, 1.5321, 1.5019, 1.5539, 1.6042, 1.5428, 1.5312],
        [1.2740, 1.2837, 1.1966, 1.1881, 1.2815, 1.2741, 1.2765, 1.2733, 1.2733,
         1.4436, 1.3650, 1.4436, 1.4054, 1.4359, 1.3591, 1.4485, 1.4383, 1.2028,
         1.2886, 1.2476, 1.2887, 1.2919, 1.2777, 1.2527, 1.2871, 1.2794, 1.2794,
         2.1688, 1.7896, 1.6046, 1.7233, 2.1268, 1.6033, 2.0960, 1.6162, 1.5906,
         1.5393, 1.5272, 1.4814, 1.5011, 1.5833, 1.5032, 1.5158, 1.3481, 1.5547,
         1.6013, 1.4695, 1.3645, 1.4232, 1.5833, 1.3535, 1.6507, 1.4367, 1.4791],
        [1.4757, 1.2183, 0.4225, 0.6453, 1.0320, 1.3901, 1.3116, 1.4737, 1.4737,
         1.3399, 1.1373, 1.1387, 0.7708, 1.3816, 0.0851, 1.2748, 1.3813, 0.9743,
         1.1137, 0.7382, 0.7184, 0.9527, 1.3873, 1.4514, 1.1452, 1.4991, 1.4991,
         0.5893, 0.6722, 1.4608, 1.2765, 0.7618, 1.4802, 1.0032, 1.4981, 1.4546,
         1.0119, 0.6678, 0.6017, 0.9239, 1.3685, 1.5473, 0.8772, 3.0380, 2.8223,
         0.2524, 0.5161, 0.5525, 0.7250, 0.3925, 0.7222, 0.0102, 0.7030, 0.8195],
        [1.2244, 1.2522, 1.3142, 1.2970, 1.2341, 1.2067, 1.1998, 1.2220, 1.2220,
         1.0263, 1.0853, 1.0650, 1.1736, 1.0707, 1.2711, 1.0464, 1.0863, 1.0623,
         1.2621, 1.2877, 1.2749, 1.2703, 1.2320, 1.2147, 1.2086, 1.2167, 1.2167,
         1.2698, 1.2846, 1.2110, 1.0875, 1.1479, 1.0329, 1.2556, 1.1039, 1.2176,
         0.7319, 0.5513, 0.7578, 0.7352, 0.4739, 0.4036, 0.7304, 0.7470, 0.3125,
         2.1676, 1.5814, 1.8050, 1.7464, 1.5414, 1.0574, 2.1400, 1.6437, 1.0318]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 36 : 179.82544925768212
Test loss for epoch 36 : 179.71294534165364
Test Precision for epoch 36 : 0.26153846153846155
Test Recall for epoch 36 : 0.26153846153846155
Test F1 for epoch 36 : 0.26153846153846155


theta for epoch 37 : tensor([[ 1.7872,  1.8482,  1.9205,  1.9219,  1.9129,  1.8017,  1.8448,  1.7862,
          1.7862,  1.4092,  1.4134,  1.4218,  1.4221,  1.4038,  1.4278,  1.4129,
          1.4061,  1.3760,  1.2626,  1.2296,  1.2172,  1.2619,  1.2504,  1.2488,
          1.2533,  1.2482,  1.2482,  1.2586,  1.3177,  1.2911,  1.3031,  1.3136,
          1.2982,  1.3030,  1.2547,  1.2926,  1.5948,  1.6230,  1.6007,  1.6001,
          1.6306,  1.5811,  1.5933,  1.6226,  1.6157,  1.6054,  1.5609,  1.5567,
          1.5192,  1.5968,  1.5392,  1.6198,  1.5294,  1.5180],
        [ 1.3181,  1.1424,  0.9995,  1.2303,  1.2784,  1.3663,  1.2859,  1.3619,
          1.3619,  1.3158,  1.5734,  1.1985,  2.0759,  1.2713,  2.9099,  1.3288,
          1.1340,  2.5682,  1.1702,  1.1952,  0.8972,  1.1866,  1.3280,  1.3743,
          1.3430,  1.3756,  1.3756,  1.3126,  1.0833,  1.4043,  1.3726,  1.1166,
          1.4198,  1.4137,  1.3786,  1.3663,  1.3102,  1.5038,  1.4108,  1.3326,
          1.3270,  1.4933,  1.3959,  0.4703,  1.3497,  1.0477,  1.4376,  1.4250,
          1.3402,  1.0953,  1.3828,  0.8765,  1.3653,  1.3373],
        [ 1.2531,  1.2609,  1.2752,  1.2630,  1.2256,  1.2548,  1.2414,  1.2526,
          1.2526,  1.4241,  1.4298,  1.4350,  1.4360,  1.4189,  1.3864,  1.4270,
          1.4071,  1.3487,  1.8770,  1.9938,  2.1035,  2.0153,  1.7514,  1.7862,
          1.9109,  1.7319,  1.7319,  1.3030,  1.2907,  1.3126,  1.3253,  1.3062,
          1.3200,  1.3252,  1.3143,  1.3141,  1.6259,  1.6557,  1.6331,  1.6033,
          1.6620,  1.6653,  1.6271,  1.5080,  1.5573,  1.5366,  1.5828,  1.5793,
          1.5411,  1.5133,  1.5621,  1.6139,  1.5515,  1.5400],
        [ 1.2729,  1.2821,  1.1958,  1.1889,  1.2804,  1.2733,  1.2754,  1.2722,
          1.2722,  1.4299,  1.3522,  1.4297,  1.3932,  1.4233,  1.3424,  1.4342,
          1.4254,  1.1928,  1.2836,  1.2455,  1.2820,  1.2864,  1.2746,  1.2499,
          1.2823,  1.2758,  1.2758,  2.1929,  1.8149,  1.6305,  1.7487,  2.1516,
          1.6297,  2.1210,  1.6421,  1.6171,  1.5603,  1.5500,  1.5033,  1.5224,
          1.6047,  1.5273,  1.5376,  1.3698,  1.5777,  1.6054,  1.4793,  1.3774,
          1.4328,  1.5888,  1.3668,  1.6524,  1.4457,  1.4878],
        [ 1.4872,  1.2272,  0.4329,  0.6571,  1.0388,  1.4001,  1.3224,  1.4853,
          1.4853,  1.3498,  1.1439,  1.1534,  0.7771,  1.3925,  0.0887,  1.2886,
          1.3929,  0.9842,  1.1256,  0.7450,  0.7172,  0.9605,  1.3973,  1.4635,
          1.1592,  1.5111,  1.5111,  0.6052,  0.6866,  1.4839,  1.2992,  0.7770,
          1.5025,  1.0262,  1.5214,  1.4779,  0.9951,  0.6469,  0.5794,  0.9068,
          1.3590,  1.5429,  0.8581,  3.0900,  2.8657,  0.2341,  0.5005,  0.5359,
          0.6969,  0.3737,  0.6975, -0.0049,  0.6798,  0.7904],
        [ 1.2246,  1.2535,  1.3178,  1.2991,  1.2394,  1.2091,  1.2010,  1.2224,
          1.2224,  1.0377,  1.0953,  1.0726,  1.1812,  1.0832,  1.2727,  1.0565,
          1.0982,  1.0659,  1.2630,  1.2900,  1.2794,  1.2735,  1.2338,  1.2165,
          1.2102,  1.2188,  1.2188,  1.2724,  1.2924,  1.2139,  1.0929,  1.1499,
          1.0377,  1.2594,  1.1073,  1.2202,  0.6922,  0.5199,  0.7194,  0.6966,
          0.4434,  0.3751,  0.6909,  0.7170,  0.2938,  2.1837,  1.5918,  1.8208,
          1.7598,  1.5446,  1.0593,  2.1544,  1.6565,  1.0331]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 37 : 179.73968633071073
Test loss for epoch 37 : 179.61407992458484
Test Precision for epoch 37 : 0.26153846153846155
Test Recall for epoch 37 : 0.26153846153846155
Test F1 for epoch 37 : 0.26153846153846155


theta for epoch 38 : tensor([[ 1.8023,  1.8623,  1.9338,  1.9371,  1.9275,  1.8165,  1.8607,  1.8013,
          1.8013,  1.3987,  1.4021,  1.4099,  1.4104,  1.3940,  1.4157,  1.4020,
          1.3961,  1.3642,  1.2689,  1.2350,  1.2228,  1.2679,  1.2572,  1.2557,
          1.2596,  1.2553,  1.2553,  1.2575,  1.3135,  1.2896,  1.3008,  1.3102,
          1.2962,  1.3010,  1.2533,  1.2910,  1.6121,  1.6408,  1.6179,  1.6172,
          1.6480,  1.5985,  1.6107,  1.6398,  1.6351,  1.6164,  1.5732,  1.5693,
          1.5328,  1.6074,  1.5522,  1.6324,  1.5425,  1.5314],
        [ 1.3278,  1.1551,  1.0088,  1.2386,  1.2895,  1.3756,  1.2951,  1.3712,
          1.3712,  1.3225,  1.5770,  1.2084,  2.0833,  1.2796,  2.9373,  1.3381,
          1.1451,  2.5914,  1.1772,  1.2016,  0.9090,  1.1944,  1.3367,  1.3800,
          1.3479,  1.3817,  1.3817,  1.3101,  1.0826,  1.4052,  1.3729,  1.1155,
          1.4195,  1.4135,  1.3782,  1.3678,  1.3302,  1.5241,  1.4291,  1.3517,
          1.3493,  1.5140,  1.4147,  0.4925,  1.3731,  1.0806,  1.4649,  1.4534,
          1.3729,  1.1274,  1.4125,  0.9042,  1.3963,  1.3694],
        [ 1.2630,  1.2710,  1.2848,  1.2739,  1.2387,  1.2647,  1.2542,  1.2625,
          1.2625,  1.4126,  1.4186,  1.4219,  1.4228,  1.4083,  1.3743,  1.4150,
          1.3974,  1.3376,  1.8789,  1.9939,  2.1022,  2.0164,  1.7567,  1.7927,
          1.9149,  1.7385,  1.7385,  1.3038,  1.2899,  1.3121,  1.3238,  1.3072,
          1.3189,  1.3238,  1.3136,  1.3134,  1.6443,  1.6744,  1.6513,  1.6222,
          1.6805,  1.6837,  1.6454,  1.5308,  1.5831,  1.5513,  1.5949,  1.5917,
          1.5549,  1.5289,  1.5750,  1.6275,  1.5648,  1.5535],
        [ 1.2788,  1.2876,  1.2021,  1.1967,  1.2864,  1.2795,  1.2814,  1.2781,
          1.2781,  1.4160,  1.3393,  1.4154,  1.3809,  1.4105,  1.3256,  1.4198,
          1.4123,  1.1827,  1.2842,  1.2487,  1.2812,  1.2865,  1.2769,  1.2526,
          1.2832,  1.2778,  1.2778,  2.2073,  1.8308,  1.6474,  1.7648,  2.1667,
          1.6470,  2.1363,  1.6588,  1.6344,  1.5807,  1.5722,  1.5247,  1.5434,
          1.6253,  1.5508,  1.5589,  1.3905,  1.5998,  1.6141,  1.4940,  1.3952,
          1.4475,  1.5987,  1.3852,  1.6584,  1.4596,  1.5016],
        [ 1.4975,  1.2336,  0.4374,  0.6638,  1.0424,  1.4084,  1.3312,  1.4957,
          1.4957,  1.3511,  1.1409,  1.1589,  0.7731,  1.3950,  0.0808,  1.2937,
          1.3963,  0.9841,  1.1298,  0.7430,  0.7066,  0.9600,  1.4005,  1.4691,
          1.1657,  1.5168,  1.5168,  0.6055,  0.6855,  1.4933,  1.3072,  0.7764,
          1.5111,  1.0337,  1.5310,  1.4875,  0.9873,  0.6346,  0.5654,  0.8985,
          1.3588,  1.5478,  0.8476,  3.1504,  2.9179,  0.2037,  0.4739,  0.5078,
          0.6585,  0.3433,  0.6622, -0.0326,  0.6460,  0.7515],
        [ 1.2355,  1.2652,  1.3312,  1.3114,  1.2548,  1.2222,  1.2127,  1.2333,
          1.2333,  1.0585,  1.1144,  1.0893,  1.1971,  1.1050,  1.2821,  1.0758,
          1.1192,  1.0791,  1.2757,  1.3037,  1.2948,  1.2878,  1.2472,  1.2302,
          1.2236,  1.2326,  1.2326,  1.2770,  1.3016,  1.2192,  1.1009,  1.1545,
          1.0455,  1.2652,  1.1137,  1.2252,  0.6579,  0.4954,  0.6866,  0.6634,
          0.4196,  0.3538,  0.6571,  0.6897,  0.2813,  2.1875,  1.5906,  1.8247,
          1.7614,  1.5360,  1.0507,  2.1564,  1.6577,  1.0239]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 38 : 179.59149373866524
Test loss for epoch 38 : 179.46392731997747
Test Precision for epoch 38 : 0.26153846153846155
Test Recall for epoch 38 : 0.26153846153846155
Test F1 for epoch 38 : 0.26153846153846155


theta for epoch 39 : tensor([[ 1.8181,  1.8771,  1.9477,  1.9529,  1.9427,  1.8320,  1.8772,  1.8172,
          1.8172,  1.3932,  1.3959,  1.4031,  1.4038,  1.3893,  1.4086,  1.3961,
          1.3911,  1.3575,  1.2767,  1.2420,  1.2303,  1.2755,  1.2657,  1.2644,
          1.2677,  1.2641,  1.2641,  1.2542,  1.3071,  1.2860,  1.2963,  1.3046,
          1.2920,  1.2967,  1.2496,  1.2871,  1.6252,  1.6542,  1.6308,  1.6301,
          1.6611,  1.6115,  1.6238,  1.6524,  1.6500,  1.6295,  1.5879,  1.5842,
          1.5489,  1.6202,  1.5676,  1.6468,  1.5582,  1.5473],
        [ 1.3390,  1.1692,  1.0192,  1.2483,  1.3020,  1.3864,  1.3059,  1.3821,
          1.3821,  1.3340,  1.5847,  1.2233,  2.0938,  1.2928,  2.9669,  1.3521,
          1.1613,  2.6175,  1.1848,  1.2088,  0.9220,  1.2028,  1.3464,  1.3871,
          1.3539,  1.3890,  1.3890,  1.3047,  1.0792,  1.4034,  1.3703,  1.1116,
          1.4164,  1.4102,  1.3750,  1.3664,  1.3475,  1.5411,  1.4444,  1.3681,
          1.3686,  1.5313,  1.4305,  0.5122,  1.3933,  1.1161,  1.4960,  1.4856,
          1.4098,  1.1620,  1.4462,  0.9340,  1.4314,  1.4059],
        [ 1.2760,  1.2842,  1.2974,  1.2877,  1.2547,  1.2777,  1.2698,  1.2755,
          1.2755,  1.4086,  1.4149,  1.4164,  1.4171,  1.4052,  1.3689,  1.4106,
          1.3951,  1.3341,  1.8782,  1.9911,  2.0979,  2.0145,  1.7594,  1.7965,
          1.9161,  1.7424,  1.7424,  1.3032,  1.2877,  1.3103,  1.3210,  1.3067,
          1.3164,  1.3210,  1.3115,  1.3114,  1.6589,  1.6891,  1.6656,  1.6373,
          1.6950,  1.6980,  1.6598,  1.5493,  1.6047,  1.5692,  1.6104,  1.6075,
          1.5723,  1.5474,  1.5914,  1.6438,  1.5816,  1.5707],
        [ 1.2890,  1.2973,  1.2128,  1.2086,  1.2966,  1.2900,  1.2916,  1.2884,
          1.2884,  1.4117,  1.3362,  1.4106,  1.3783,  1.4074,  1.3191,  1.4149,
          1.4088,  1.1826,  1.2911,  1.2579,  1.2870,  1.2929,  1.2853,  1.2615,
          1.2902,  1.2860,  1.2860,  2.2114,  1.8368,  1.6545,  1.7709,  2.1715,
          1.6545,  2.1414,  1.6658,  1.6420,  1.5982,  1.5915,  1.5434,  1.5615,
          1.6428,  1.5712,  1.5773,  1.4079,  1.6186,  1.6276,  1.5138,  1.4182,
          1.4677,  1.6134,  1.4091,  1.6690,  1.4791,  1.5208],
        [ 1.5093,  1.2416,  0.4428,  0.6716,  1.0477,  1.4183,  1.3416,  1.5075,
          1.5075,  1.3567,  1.1420,  1.1683,  0.7724,  1.4020,  0.0755,  1.3031,
          1.4042,  0.9877,  1.1347,  0.7416,  0.6965,  0.9601,  1.4044,  1.4753,
          1.1726,  1.5232,  1.5232,  0.6030,  0.6814,  1.4989,  1.3114,  0.7728,
          1.5159,  1.0372,  1.5369,  1.4932,  0.9777,  0.6207,  0.5500,  0.8886,
          1.3568,  1.5510,  0.8355,  3.2103,  2.9694,  0.1753,  0.4499,  0.4824,
          0.6237,  0.3153,  0.6302, -0.0591,  0.6155,  0.7159],
        [ 1.2458,  1.2763,  1.3439,  1.3230,  1.2696,  1.2347,  1.2238,  1.2437,
          1.2437,  1.0808,  1.1352,  1.1072,  1.2149,  1.1288,  1.2936,  1.0965,
          1.1422,  1.0940,  1.2853,  1.3141,  1.3066,  1.2986,  1.2574,  1.2405,
          1.2336,  1.2432,  1.2432,  1.2765,  1.3053,  1.2192,  1.1031,  1.1538,
          1.0477,  1.2656,  1.1145,  1.2248,  0.6174,  0.4648,  0.6477,  0.6240,
          0.3894,  0.3259,  0.6171,  0.6541,  0.2611,  2.1980,  1.5965,  1.8357,
          1.7700,  1.5343,  1.0492,  2.1651,  1.6660,  1.0219]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 39 : 179.48621973376993
Test loss for epoch 39 : 179.35361368530567
Test Precision for epoch 39 : 0.26153846153846155
Test Recall for epoch 39 : 0.26153846153846155
Test F1 for epoch 39 : 0.26153846153846155


theta for epoch 40 : tensor([[ 1.8307,  1.8885,  1.9582,  1.9653,  1.9546,  1.8442,  1.8905,  1.8298,
          1.8298,  1.3951,  1.3972,  1.4036,  1.4045,  1.3919,  1.4088,  1.3976,
          1.3935,  1.3582,  1.2869,  1.2515,  1.2406,  1.2856,  1.2767,  1.2756,
          1.2783,  1.2754,  1.2754,  1.2550,  1.3051,  1.2865,  1.2960,  1.3033,
          1.2920,  1.2966,  1.2501,  1.2876,  1.6347,  1.6640,  1.6402,  1.6394,
          1.6704,  1.6207,  1.6334,  1.6612,  1.6610,  1.6422,  1.6024,  1.5989,
          1.5651,  1.6328,  1.5829,  1.6606,  1.5738,  1.5633],
        [ 1.3468,  1.1798,  1.0260,  1.2545,  1.3112,  1.3937,  1.3133,  1.3896,
          1.3896,  1.3518,  1.5982,  1.2448,  2.1092,  1.3125,  3.0001,  1.3727,
          1.1841,  2.6480,  1.1922,  1.2163,  0.9354,  1.2112,  1.3564,  1.3948,
          1.3606,  1.3970,  1.3970,  1.3025,  1.0788,  1.4046,  1.3708,  1.1105,
          1.4163,  1.4100,  1.3749,  1.3681,  1.3622,  1.5548,  1.4569,  1.3817,
          1.3849,  1.5453,  1.4435,  0.5293,  1.4106,  1.1501,  1.5268,  1.5175,
          1.4470,  1.1953,  1.4801,  0.9621,  1.4667,  1.4427],
        [ 1.2854,  1.2937,  1.3064,  1.2979,  1.2671,  1.2871,  1.2817,  1.2851,
          1.2851,  1.4116,  1.4180,  1.4178,  1.4184,  1.4089,  1.3697,  1.4131,
          1.3996,  1.3375,  1.8801,  1.9906,  2.0959,  2.0150,  1.7648,  1.8029,
          1.9197,  1.7490,  1.7490,  1.3057,  1.2886,  1.3116,  1.3214,  1.3093,
          1.3172,  1.3214,  1.3126,  1.3126,  1.6691,  1.6995,  1.6756,  1.6480,
          1.7050,  1.7079,  1.6699,  1.5631,  1.6216,  1.5856,  1.6246,  1.6220,
          1.5885,  1.5640,  1.6065,  1.6580,  1.5972,  1.5867],
        [ 1.2975,  1.3054,  1.2218,  1.2188,  1.3050,  1.2989,  1.3002,  1.2970,
          1.2970,  1.4166,  1.3425,  1.4149,  1.3848,  1.4133,  1.3220,  1.4192,
          1.4144,  1.1916,  1.3017,  1.2707,  1.2967,  1.3031,  1.2972,  1.2739,
          1.3010,  1.2978,  1.2978,  2.2137,  1.8416,  1.6605,  1.7759,  2.1746,
          1.6610,  2.1448,  1.6718,  1.6486,  1.6123,  1.6072,  1.5588,  1.5763,
          1.6566,  1.5881,  1.5924,  1.4215,  1.6337,  1.6415,  1.5344,  1.4418,
          1.4888,  1.6287,  1.4339,  1.6800,  1.4994,  1.5409],
        [ 1.5218,  1.2510,  0.4512,  0.6817,  1.0553,  1.4292,  1.3532,  1.5201,
          1.5201,  1.3719,  1.1530,  1.1868,  0.7813,  1.4184,  0.0795,  1.3217,
          1.4216,  1.0009,  1.1450,  0.7462,  0.6923,  0.9660,  1.4134,  1.4864,
          1.1844,  1.5343,  1.5343,  0.6084,  0.6852,  1.5116,  1.3227,  0.7772,
          1.5277,  1.0477,  1.5498,  1.5059,  0.9615,  0.6007,  0.5286,  0.8721,
          1.3477,  1.5468,  0.8170,  3.2649,  3.0148,  0.1558,  0.4344,  0.4661,
          0.5987,  0.2962,  0.6076, -0.0774,  0.5942,  0.6896],
        [ 1.2492,  1.2804,  1.3494,  1.3276,  1.2772,  1.2403,  1.2279,  1.2473,
          1.2473,  1.1022,  1.1554,  1.1241,  1.2325,  1.1522,  1.3053,  1.1164,
          1.1649,  1.1082,  1.2885,  1.3179,  1.3115,  1.3028,  1.2613,  1.2444,
          1.2368,  1.2474,  1.2474,  1.2744,  1.3072,  1.2175,  1.1028,  1.1511,
          1.0474,  1.2643,  1.1132,  1.2227,  0.5689,  0.4259,  0.6008,  0.5764,
          0.3503,  0.2892,  0.5692,  0.6085,  0.2308,  2.2187,  1.6128,  1.8572,
          1.7892,  1.5429,  1.0580,  2.1839,  1.6849,  1.0302]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 40 : 179.395237949578
Test loss for epoch 40 : 179.24959420783028
Test Precision for epoch 40 : 0.26153846153846155
Test Recall for epoch 40 : 0.26153846153846155
Test F1 for epoch 40 : 0.26153846153846155


theta for epoch 41 : tensor([[ 1.8395,  1.8961,  1.9648,  1.9738,  1.9626,  1.8526,  1.9000,  1.8386,
          1.8386,  1.4009,  1.4023,  1.4081,  1.4091,  1.3984,  1.4129,  1.4030,
          1.3998,  1.3628,  1.2991,  1.2630,  1.2531,  1.2977,  1.2898,  1.2888,
          1.2911,  1.2887,  1.2887,  1.2628,  1.3103,  1.2942,  1.3028,  1.3092,
          1.2991,  1.3037,  1.2577,  1.2951,  1.6443,  1.6738,  1.6498,  1.6489,
          1.6798,  1.6301,  1.6432,  1.6699,  1.6720,  1.6484,  1.6105,  1.6072,
          1.5751,  1.6389,  1.5919,  1.6676,  1.5831,  1.5731],
        [ 1.3504,  1.1861,  1.0286,  1.2566,  1.3161,  1.3969,  1.3165,  1.3930,
          1.3930,  1.3724,  1.6138,  1.2691,  2.1258,  1.3349,  3.0337,  1.3960,
          1.2098,  2.6796,  1.2005,  1.2250,  0.9504,  1.2206,  1.3675,  1.4040,
          1.3687,  1.4064,  1.4064,  1.3074,  1.0855,  1.4127,  1.3782,  1.1162,
          1.4232,  1.4168,  1.3818,  1.3767,  1.3784,  1.5694,  1.4706,  1.3966,
          1.4025,  1.5602,  1.4578,  0.5481,  1.4289,  1.1764,  1.5509,  1.5426,
          1.4781,  1.2209,  1.5075,  0.9825,  1.4957,  1.4736],
        [ 1.2890,  1.2973,  1.3093,  1.3019,  1.2734,  1.2907,  1.2876,  1.2887,
          1.2887,  1.4161,  1.4224,  1.4208,  1.4213,  1.4141,  1.3715,  1.4172,
          1.4053,  1.3422,  1.8883,  1.9962,  2.0998,  2.0215,  1.7765,  1.8155,
          1.9293,  1.7618,  1.7618,  1.3133,  1.2945,  1.3182,  1.3271,  1.3169,
          1.3232,  1.3271,  1.3189,  1.3191,  1.6782,  1.7087,  1.6845,  1.6577,
          1.7138,  1.7166,  1.6789,  1.5752,  1.6370,  1.5933,  1.6304,  1.6280,
          1.5964,  1.5717,  1.6133,  1.6632,  1.6045,  1.5945],
        [ 1.3017,  1.3090,  1.2264,  1.2245,  1.3091,  1.3033,  1.3043,  1.3012,
          1.3012,  1.4245,  1.3516,  1.4220,  1.3942,  1.4222,  1.3281,  1.4266,
          1.4230,  1.2032,  1.3131,  1.2839,  1.3073,  1.3140,  1.3098,  1.2869,
          1.3125,  1.3102,  1.3102,  2.2213,  1.8522,  1.6726,  1.7868,  2.1830,
          1.6735,  2.1535,  1.6837,  1.6612,  1.6260,  1.6226,  1.5738,  1.5909,
          1.6699,  1.6045,  1.6073,  1.4342,  1.6481,  1.6486,  1.5480,  1.4584,
          1.5033,  1.6370,  1.4519,  1.6841,  1.5129,  1.5544],
        [ 1.5279,  1.2536,  0.4523,  0.6848,  1.0558,  1.4337,  1.3583,  1.5264,
          1.5264,  1.3860,  1.1622,  1.2036,  0.7873,  1.4339,  0.0793,  1.3391,
          1.4382,  1.0117,  1.1520,  0.7466,  0.6838,  0.9681,  1.4195,  1.4947,
          1.1927,  1.5429,  1.5429,  0.6120,  0.6876,  1.5264,  1.3349,  0.7803,
          1.5416,  1.0575,  1.5648,  1.5205,  0.9504,  0.5858,  0.5123,  0.8608,
          1.3440,  1.5479,  0.8035,  3.3248,  3.0657,  0.1260,  0.4088,  0.4391,
          0.5637,  0.2669,  0.5747, -0.1060,  0.5626,  0.6535],
        [ 1.2551,  1.2868,  1.3566,  1.3341,  1.2870,  1.2484,  1.2345,  1.2533,
          1.2533,  1.1385,  1.1908,  1.1563,  1.2653,  1.1903,  1.3324,  1.1513,
          1.2022,  1.1387,  1.3050,  1.3344,  1.3286,  1.3196,  1.2785,  1.2617,
          1.2535,  1.2650,  1.2650,  1.2859,  1.3217,  1.2298,  1.1164,  1.1624,
          1.0612,  1.2766,  1.1261,  1.2346,  0.5295,  0.3973,  0.5631,  0.5378,
          0.3215,  0.2629,  0.5306,  0.5691,  0.2097,  2.2224,  1.6126,  1.8620,
          1.7916,  1.5351,  1.0513,  2.1857,  1.6872,  1.0231]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 41 : 179.27258431899514
Test loss for epoch 41 : 179.1252902466419
Test Precision for epoch 41 : 0.26153846153846155
Test Recall for epoch 41 : 0.26153846153846155
Test F1 for epoch 41 : 0.26153846153846155


theta for epoch 42 : tensor([[ 1.8474,  1.9026,  1.9704,  1.9813,  1.9696,  1.8601,  1.9086,  1.8465,
          1.8465,  1.4019,  1.4027,  1.4077,  1.4089,  1.4000,  1.4122,  1.4036,
          1.4011,  1.3626,  1.3076,  1.2709,  1.2621,  1.3062,  1.2993,  1.2985,
          1.3003,  1.2984,  1.2984,  1.2760,  1.3212,  1.3074,  1.3151,  1.3206,
          1.3118,  1.3162,  1.2708,  1.3082,  1.6556,  1.6851,  1.6609,  1.6599,
          1.6906,  1.6408,  1.6545,  1.6799,  1.6842,  1.6531,  1.6172,  1.6141,
          1.5838,  1.6436,  1.5996,  1.6728,  1.5911,  1.5817],
        [ 1.3539,  1.1923,  1.0312,  1.2585,  1.3209,  1.4000,  1.3195,  1.3961,
          1.3961,  1.3878,  1.6238,  1.2885,  2.1360,  1.3523,  3.0610,  1.4142,
          1.2307,  2.7050,  1.2070,  1.2321,  0.9648,  1.2282,  1.3767,  1.4116,
          1.3752,  1.4143,  1.4143,  1.3194,  1.0995,  1.4277,  1.3925,  1.1291,
          1.4369,  1.4304,  1.3955,  1.3922,  1.3982,  1.5868,  1.4876,  1.4151,
          1.4233,  1.5779,  1.4754,  0.5711,  1.4503,  1.2029,  1.5756,  1.5682,
          1.5102,  1.2465,  1.5358,  1.0035,  1.5255,  1.5055],
        [ 1.2901,  1.2983,  1.3095,  1.3033,  1.2770,  1.2917,  1.2906,  1.2898,
          1.2898,  1.4129,  1.4192,  1.4164,  1.4167,  1.4117,  1.3658,  1.4136,
          1.4032,  1.3389,  1.8998,  2.0048,  2.1068,  2.0311,  1.7915,  1.8312,
          1.9421,  1.7779,  1.7779,  1.3251,  1.3047,  1.3292,  1.3370,  1.3286,
          1.3335,  1.3371,  1.3296,  1.3299,  1.6881,  1.7185,  1.6942,  1.6682,
          1.7232,  1.7259,  1.6888,  1.5876,  1.6527,  1.5981,  1.6335,  1.6312,
          1.6017,  1.5761,  1.6174,  1.6650,  1.6090,  1.5996],
        [ 1.3043,  1.3111,  1.2292,  1.2283,  1.3115,  1.3061,  1.3068,  1.3039,
          1.3039,  1.4262,  1.3545,  1.4229,  1.3973,  1.4248,  1.3281,  1.4277,
          1.4253,  1.2082,  1.3204,  1.2929,  1.3141,  1.3210,  1.3182,  1.2958,
          1.3200,  1.3186,  1.3186,  2.2338,  1.8684,  1.6902,  1.8032,  2.1965,
          1.6915,  2.1672,  1.7012,  1.6793,  1.6411,  1.6390,  1.5902,  1.6068,
          1.6844,  1.6219,  1.6234,  1.4479,  1.6635,  1.6539,  1.5598,  1.4729,
          1.5162,  1.6435,  1.4680,  1.6864,  1.5248,  1.5664],
        [ 1.5351,  1.2577,  0.4555,  0.6896,  1.0582,  1.4393,  1.3648,  1.5336,
          1.5336,  1.3999,  1.1718,  1.2205,  0.7945,  1.4492,  0.0814,  1.3564,
          1.4545,  1.0228,  1.1604,  0.7490,  0.6775,  0.9720,  1.4268,  1.5039,
          1.2021,  1.5523,  1.5523,  0.6228,  0.6974,  1.5487,  1.3546,  0.7910,
          1.5630,  1.0741,  1.5874,  1.5426,  0.9370,  0.5690,  0.4942,  0.8473,
          1.3374,  1.5461,  0.7878,  3.3829,  3.1143,  0.1020,  0.3887,  0.4180,
          0.5356,  0.2436,  0.5482, -0.1294,  0.5374,  0.6239],
        [ 1.2588,  1.2909,  1.3613,  1.3382,  1.2943,  1.2542,  1.2388,  1.2571,
          1.2571,  1.1666,  1.2179,  1.1802,  1.2897,  1.2204,  1.3513,  1.1779,
          1.2316,  1.1611,  1.3163,  1.3453,  1.3401,  1.3309,  1.2906,  1.2740,
          1.2647,  1.2776,  1.2776,  1.3012,  1.3395,  1.2460,  1.1333,  1.1773,
          1.0786,  1.2927,  1.1427,  1.2504,  0.4906,  0.3692,  0.5260,  0.4998,
          0.2927,  0.2367,  0.4928,  0.5281,  0.1875,  2.2292,  1.6157,  1.8701,
          1.7973,  1.5306,  1.0482,  2.1907,  1.6930,  1.0195]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 42 : 179.18543643258536
Test loss for epoch 42 : 179.03182653528205
Test Precision for epoch 42 : 0.26153846153846155
Test Recall for epoch 42 : 0.26153846153846155
Test F1 for epoch 42 : 0.26153846153846155


theta for epoch 43 : tensor([[ 1.8572,  1.9110,  1.9777,  1.9906,  1.9783,  1.8695,  1.9189,  1.8563,
          1.8563,  1.3961,  1.3964,  1.4007,  1.4020,  1.3948,  1.4047,  1.3974,
          1.3957,  1.3557,  1.3096,  1.2722,  1.2648,  1.3082,  1.3024,  1.3018,
          1.3032,  1.3017,  1.3017,  1.2891,  1.3322,  1.3206,  1.3274,  1.3321,
          1.3245,  1.3287,  1.2839,  1.3212,  1.6692,  1.6986,  1.6744,  1.6733,
          1.7036,  1.6538,  1.6682,  1.6921,  1.6986,  1.6592,  1.6254,  1.6224,
          1.5942,  1.6497,  1.6089,  1.6793,  1.6007,  1.5920],
        [ 1.3604,  1.2015,  1.0370,  1.2637,  1.3287,  1.4060,  1.3257,  1.4024,
          1.4024,  1.3968,  1.6267,  1.3016,  2.1386,  1.3633,  3.0809,  1.4261,
          1.2454,  2.7231,  1.2097,  1.2356,  0.9764,  1.2320,  1.3821,  1.4156,
          1.3781,  1.4184,  1.4184,  1.3332,  1.1155,  1.4441,  1.4083,  1.1439,
          1.4520,  1.4455,  1.4109,  1.4093,  1.4224,  1.6081,  1.5088,  1.4378,
          1.4483,  1.5994,  1.4973,  0.5989,  1.4757,  1.2333,  1.6043,  1.5978,
          1.5464,  1.2757,  1.5681,  1.0288,  1.5594,  1.5416],
        [ 1.2926,  1.3006,  1.3111,  1.3060,  1.2818,  1.2942,  1.2949,  1.2924,
          1.2924,  1.4018,  1.4078,  1.4040,  1.4042,  1.4012,  1.3523,  1.4021,
          1.3929,  1.3274,  1.9113,  2.0133,  2.1135,  2.0406,  1.8063,  1.8469,
          1.9546,  1.7938,  1.7938,  1.3364,  1.3143,  1.3397,  1.3466,  1.3398,
          1.3435,  1.3467,  1.3399,  1.3403,  1.7001,  1.7303,  1.7060,  1.6807,
          1.7347,  1.7372,  1.7007,  1.6016,  1.6700,  1.6039,  1.6379,  1.6357,
          1.6083,  1.5812,  1.6228,  1.6676,  1.6149,  1.6061],
        [ 1.3091,  1.3153,  1.2343,  1.2341,  1.3160,  1.3111,  1.3115,  1.3087,
          1.3087,  1.4213,  1.3507,  1.4171,  1.3937,  1.4208,  1.3216,  1.4223,
          1.4209,  1.2066,  1.3231,  1.2970,  1.3164,  1.3233,  1.3217,  1.2998,
          1.3228,  1.3221,  1.3221,  2.2454,  1.8840,  1.7074,  1.8190,  2.2090,
          1.7091,  2.1801,  1.7182,  1.6970,  1.6589,  1.6581,  1.6094,  1.6255,
          1.7013,  1.6419,  1.6423,  1.4641,  1.6813,  1.6613,  1.5737,  1.4893,
          1.5312,  1.6521,  1.4861,  1.6909,  1.5388,  1.5807],
        [ 1.5463,  1.2664,  0.4635,  0.6990,  1.0658,  1.4492,  1.3756,  1.5449,
          1.5449,  1.4135,  1.1816,  1.2373,  0.8029,  1.4640,  0.0863,  1.3734,
          1.4703,  1.0343,  1.1700,  0.7537,  0.6738,  0.9777,  1.4347,  1.5133,
          1.2122,  1.5620,  1.5620,  0.6380,  0.7116,  1.5739,  1.3773,  0.8059,
          1.5872,  1.0939,  1.6127,  1.5674,  0.9206,  0.5498,  0.4739,  0.8309,
          1.3273,  1.5405,  0.7694,  3.4387,  3.1600,  0.0877,  0.3780,  0.4068,
          0.5191,  0.2302,  0.5326, -0.1441,  0.5229,  0.6056],
        [ 1.2613,  1.2937,  1.3645,  1.3411,  1.3001,  1.2588,  1.2418,  1.2598,
          1.2598,  1.1810,  1.2315,  1.1901,  1.3007,  1.2372,  1.3567,  1.1907,
          1.2475,  1.1698,  1.3169,  1.3452,  1.3404,  1.3311,  1.2920,  1.2755,
          1.2650,  1.2794,  1.2794,  1.3133,  1.3539,  1.2590,  1.1463,  1.1888,
          1.0921,  1.3055,  1.1558,  1.2630,  0.4511,  0.3400,  0.4883,  0.4609,
          0.2624,  0.2086,  0.4543,  0.4846,  0.1623,  2.2447,  1.6277,  1.8871,
          1.8120,  1.5348,  1.0538,  2.2041,  1.7077,  1.0248]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 43 : 179.1219866888844
Test loss for epoch 43 : 178.95497526562562
Test Precision for epoch 43 : 0.26153846153846155
Test Recall for epoch 43 : 0.26153846153846155
Test F1 for epoch 43 : 0.26153846153846155


theta for epoch 44 : tensor([[ 1.8693,  1.9218,  1.9873,  2.0022,  1.9895,  1.8813,  1.9317,  1.8685,
          1.8685,  1.3908,  1.3906,  1.3943,  1.3957,  1.3901,  1.3979,  1.3917,
          1.3908,  1.3494,  1.3091,  1.2712,  1.2650,  1.3078,  1.3031,  1.3026,
          1.3036,  1.3026,  1.3026,  1.2943,  1.3355,  1.3259,  1.3319,  1.3357,
          1.3293,  1.3332,  1.2890,  1.3264,  1.6855,  1.7147,  1.6906,  1.6894,
          1.7192,  1.6692,  1.6846,  1.7068,  1.7153,  1.6647,  1.6330,  1.6302,
          1.6040,  1.6553,  1.6176,  1.6849,  1.6098,  1.6018],
        [ 1.3696,  1.2133,  1.0454,  1.2716,  1.3391,  1.4147,  1.3345,  1.4113,
          1.4113,  1.4064,  1.6299,  1.3154,  2.1406,  1.3749,  3.0997,  1.4386,
          1.2608,  2.7404,  1.2109,  1.2378,  0.9871,  1.2343,  1.3859,  1.4184,
          1.3799,  1.4214,  1.4214,  1.3392,  1.1242,  1.4528,  1.4164,  1.1509,
          1.4594,  1.4528,  1.4184,  1.4185,  1.4507,  1.6329,  1.5339,  1.4646,
          1.4770,  1.6244,  1.5231,  0.6308,  1.5048,  1.2631,  1.6333,  1.6275,
          1.5828,  1.3042,  1.6008,  1.0540,  1.5936,  1.5780],
        [ 1.2978,  1.3056,  1.3154,  1.3112,  1.2891,  1.2993,  1.3016,  1.2976,
          1.2976,  1.3920,  1.3977,  1.3931,  1.3931,  1.3919,  1.3401,  1.3920,
          1.3837,  1.3172,  1.9230,  2.0217,  2.1203,  2.0499,  1.8213,  1.8625,
          1.9671,  1.8098,  1.8098,  1.3396,  1.3159,  1.3423,  1.3483,  1.3429,
          1.3455,  1.3484,  1.3422,  1.3427,  1.7149,  1.7447,  1.7206,  1.6959,
          1.7487,  1.7510,  1.7154,  1.6178,  1.6894,  1.6094,  1.6421,  1.6400,
          1.6148,  1.5857,  1.6281,  1.6695,  1.6207,  1.6126],
        [ 1.3172,  1.3229,  1.2427,  1.2432,  1.3239,  1.3194,  1.3196,  1.3169,
          1.3169,  1.4190,  1.3494,  1.4138,  1.3925,  1.4192,  1.3181,  1.4194,
          1.4190,  1.2075,  1.3259,  1.3011,  1.3191,  1.3258,  1.3252,  1.3037,
          1.3257,  1.3257,  1.3257,  2.2489,  1.8916,  1.7165,  1.8268,  2.2134,
          1.7187,  2.1848,  1.7272,  1.7068,  1.6802,  1.6805,  1.6320,  1.6478,
          1.7216,  1.6651,  1.6646,  1.4837,  1.7024,  1.6696,  1.5883,  1.5062,
          1.5472,  1.6615,  1.5050,  1.6962,  1.5537,  1.5960],
        [ 1.5556,  1.2723,  0.4664,  0.7038,  1.0701,  1.4570,  1.3840,  1.5544,
          1.5544,  1.4226,  1.1862,  1.2491,  0.8051,  1.4745,  0.0837,  1.3858,
          1.4820,  1.0398,  1.1729,  0.7510,  0.6624,  0.9763,  1.4365,  1.5169,
          1.2158,  1.5659,  1.5659,  0.6390,  0.7116,  1.5848,  1.3852,  0.8063,
          1.5970,  1.0988,  1.6238,  1.5780,  0.9126,  0.5387,  0.4617,  0.8229,
          1.3259,  1.5435,  0.7592,  3.5020,  3.2135,  0.0642,  0.3588,  0.3867,
          0.4946,  0.2080,  0.5089, -0.1684,  0.5003,  0.5798],
        [ 1.2723,  1.3049,  1.3756,  1.3520,  1.3140,  1.2718,  1.2533,  1.2709,
          1.2709,  1.2062,  1.2560,  1.2113,  1.3226,  1.2643,  1.3735,  1.2144,
          1.2737,  1.1906,  1.3267,  1.3541,  1.3495,  1.3403,  1.3027,  1.2863,
          1.2746,  1.2905,  1.2905,  1.3250,  1.3673,  1.2719,  1.1595,  1.2005,
          1.1062,  1.3178,  1.1692,  1.2755,  0.4255,  0.3250,  0.4645,  0.4359,
          0.2462,  0.1947,  0.4298,  0.4523,  0.1500,  2.2465,  1.6266,  1.8907,
          1.8132,  1.5260,  1.0474,  2.2039,  1.7092,  1.0181]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 44 : 179.0286010170195
Test loss for epoch 44 : 178.86171979460158
Test Precision for epoch 44 : 0.26153846153846155
Test Recall for epoch 44 : 0.26153846153846155
Test F1 for epoch 44 : 0.26153846153846155


theta for epoch 45 : tensor([[ 1.8814,  1.9325,  1.9968,  2.0136,  2.0005,  1.8930,  1.9444,  1.8806,
          1.8806,  1.3897,  1.3891,  1.3921,  1.3937,  1.3895,  1.3954,  1.3903,
          1.3900,  1.3474,  1.3097,  1.2712,  1.2665,  1.3086,  1.3048,  1.3044,
          1.3052,  1.3045,  1.3045,  1.2923,  1.3318,  1.3241,  1.3294,  1.3324,
          1.3271,  1.3308,  1.2872,  1.3245,  1.7029,  1.7318,  1.7078,  1.7065,
          1.7357,  1.6857,  1.7021,  1.7225,  1.7329,  1.6712,  1.6418,  1.6390,
          1.6151,  1.6620,  1.6274,  1.6913,  1.6201,  1.6128],
        [ 1.3787,  1.2246,  1.0536,  1.2794,  1.3494,  1.4233,  1.3432,  1.4201,
          1.4201,  1.4207,  1.6375,  1.3338,  2.1463,  1.3913,  3.1211,  1.4558,
          1.2808,  2.7611,  1.2115,  1.2397,  0.9972,  1.2360,  1.3893,  1.4212,
          1.3816,  1.4243,  1.4243,  1.3367,  1.1245,  1.4529,  1.4159,  1.1494,
          1.4584,  1.4515,  1.4175,  1.4192,  1.4804,  1.6588,  1.5603,  1.4927,
          1.5070,  1.6506,  1.5504,  0.6640,  1.5349,  1.2922,  1.6624,  1.6573,
          1.6192,  1.3319,  1.6336,  1.0786,  1.6279,  1.6146],
        [ 1.3041,  1.3116,  1.3207,  1.3174,  1.2973,  1.3055,  1.3092,  1.3039,
          1.3039,  1.3878,  1.3932,  1.3880,  1.3878,  1.3882,  1.3334,  1.3875,
          1.3800,  1.3128,  1.9337,  2.0290,  2.1258,  2.0581,  1.8351,  1.8770,
          1.9784,  1.8246,  1.8246,  1.3356,  1.3104,  1.3379,  1.3430,  1.3387,
          1.3406,  1.3432,  1.3376,  1.3382,  1.7308,  1.7603,  1.7363,  1.7124,
          1.7638,  1.7660,  1.7313,  1.6349,  1.7097,  1.6165,  1.6480,  1.6460,
          1.6230,  1.5914,  1.6351,  1.6727,  1.6281,  1.6208],
        [ 1.3263,  1.3315,  1.2520,  1.2531,  1.3327,  1.3286,  1.3286,  1.3260,
          1.3260,  1.4216,  1.3531,  1.4155,  1.3962,  1.4224,  1.3198,  1.4216,
          1.4220,  1.2130,  1.3305,  1.3067,  1.3237,  1.3301,  1.3303,  1.3092,
          1.3303,  1.3309,  1.3309,  2.2460,  1.8930,  1.7194,  1.8284,  2.2114,
          1.7219,  2.1831,  1.7299,  1.7102,  1.7026,  1.7040,  1.6559,  1.6714,
          1.7429,  1.6893,  1.6881,  1.5043,  1.7244,  1.6793,  1.6041,  1.5241,
          1.5645,  1.6722,  1.5249,  1.7030,  1.5700,  1.6127],
        [ 1.5681,  1.2821,  0.4740,  0.7129,  1.0788,  1.4683,  1.3961,  1.5670,
          1.5670,  1.4385,  1.1981,  1.2673,  0.8146,  1.4916,  0.0887,  1.4047,
          1.5002,  1.0520,  1.1805,  0.7537,  0.6571,  0.9801,  1.4427,  1.5244,
          1.2235,  1.5737,  1.5737,  0.6399,  0.7112,  1.5913,  1.3895,  0.8058,
          1.6023,  1.1010,  1.6303,  1.5841,  0.9004,  0.5241,  0.4462,  0.8109,
          1.3197,  1.5415,  0.7451,  3.5617,  3.2629,  0.0515,  0.3499,  0.3776,
          0.4828,  0.1968,  0.4972, -0.1829,  0.4895,  0.5665],
        [ 1.2802,  1.3130,  1.3835,  1.3597,  1.3245,  1.2816,  1.2616,  1.2790,
          1.2790,  1.2278,  1.2773,  1.2290,  1.3416,  1.2882,  1.3878,  1.2346,
          1.2968,  1.2081,  1.3305,  1.3570,  1.3525,  1.3434,  1.3072,  1.2910,
          1.2780,  1.2955,  1.2955,  1.3257,  1.3695,  1.2737,  1.1612,  1.2012,
          1.1091,  1.3191,  1.1713,  1.2770,  0.3976,  0.3071,  0.4384,  0.4086,
          0.2266,  0.1772,  0.4032,  0.4162,  0.1330,  2.2578,  1.6350,  1.9040,
          1.8242,  1.5268,  1.0506,  2.2131,  1.7204,  1.0210]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 45 : 178.93961363201686
Test loss for epoch 45 : 178.7675568552669
Test Precision for epoch 45 : 0.26153846153846155
Test Recall for epoch 45 : 0.26153846153846155
Test F1 for epoch 45 : 0.26153846153846155


theta for epoch 46 : tensor([[ 1.8909,  1.9404,  2.0036,  2.0223,  2.0087,  1.9020,  1.9544,  1.8901,
          1.8901,  1.3916,  1.3906,  1.3930,  1.3947,  1.3918,  1.3959,  1.3919,
          1.3921,  1.3485,  1.3141,  1.2753,  1.2720,  1.3132,  1.3104,  1.3100,
          1.3106,  1.3101,  1.3101,  1.2915,  1.3294,  1.3236,  1.3281,  1.3304,
          1.3261,  1.3295,  1.2865,  1.3239,  1.7198,  1.7483,  1.7246,  1.7231,
          1.7517,  1.7015,  1.7192,  1.7376,  1.7497,  1.6761,  1.6488,  1.6461,
          1.6244,  1.6671,  1.6355,  1.6959,  1.6286,  1.6222],
        [ 1.3849,  1.2328,  1.0588,  1.2844,  1.3567,  1.4291,  1.3490,  1.4261,
          1.4261,  1.4387,  1.6486,  1.3558,  2.1547,  1.4112,  3.1445,  1.4767,
          1.3043,  2.7842,  1.2134,  1.2432,  1.0086,  1.2391,  1.3942,  1.4257,
          1.3851,  1.4289,  1.4289,  1.3340,  1.1246,  1.4528,  1.4151,  1.1475,
          1.4571,  1.4500,  1.4164,  1.4197,  1.5098,  1.6839,  1.5863,  1.5204,
          1.5364,  1.6759,  1.5771,  0.6965,  1.5644,  1.3167,  1.6876,  1.6833,
          1.6518,  1.3549,  1.6626,  1.0990,  1.6583,  1.6473],
        [ 1.3091,  1.3163,  1.3247,  1.3222,  1.3042,  1.3105,  1.3153,  1.3090,
          1.3090,  1.3879,  1.3928,  1.3873,  1.3870,  1.3887,  1.3308,  1.3874,
          1.3803,  1.3126,  1.9428,  2.0346,  2.1297,  2.0645,  1.8473,  1.8896,
          1.9879,  1.8377,  1.8377,  1.3331,  1.3066,  1.3351,  1.3394,  1.3361,
          1.3374,  1.3396,  1.3346,  1.3353,  1.7464,  1.7753,  1.7517,  1.7284,
          1.7784,  1.7804,  1.7468,  1.6513,  1.7291,  1.6222,  1.6526,  1.6507,
          1.6300,  1.5956,  1.6408,  1.6743,  1.6343,  1.6278],
        [ 1.3323,  1.3370,  1.2581,  1.2596,  1.3384,  1.3346,  1.3344,  1.3321,
          1.3321,  1.4247,  1.3570,  1.4177,  1.4002,  1.4260,  1.3221,  1.4242,
          1.4254,  1.2186,  1.3359,  1.3131,  1.3293,  1.3353,  1.3360,  1.3153,
          1.3357,  1.3367,  1.3367,  2.2468,  1.8985,  1.7264,  1.8339,  2.2132,
          1.7292,  2.1852,  1.7367,  1.7177,  1.7235,  1.7257,  1.6781,  1.6934,
          1.7625,  1.7117,  1.7100,  1.5232,  1.7446,  1.6858,  1.6164,  1.5381,
          1.5782,  1.6797,  1.5411,  1.7067,  1.5827,  1.6260],
        [ 1.5798,  1.2914,  0.4815,  0.7217,  1.0873,  1.4789,  1.4076,  1.5788,
          1.5788,  1.4572,  1.2129,  1.2879,  0.8269,  1.5115,  0.0965,  1.4263,
          1.5212,  1.0667,  1.1905,  0.7591,  0.6548,  0.9867,  1.4515,  1.5343,
          1.2334,  1.5840,  1.5840,  0.6427,  0.7128,  1.5992,  1.3952,  0.8073,
          1.6090,  1.1045,  1.6382,  1.5915,  0.8867,  0.5083,  0.4297,  0.7974,
          1.3116,  1.5374,  0.7296,  3.6206,  3.3109,  0.0424,  0.3443,  0.3721,
          0.4757,  0.1894,  0.4898, -0.1943,  0.4830,  0.5581],
        [ 1.2858,  1.3186,  1.3888,  1.3650,  1.3325,  1.2890,  1.2675,  1.2848,
          1.2848,  1.2497,  1.2992,  1.2472,  1.3614,  1.3124,  1.4032,  1.2550,
          1.3202,  1.2266,  1.3359,  1.3613,  1.3569,  1.3479,  1.3131,  1.2969,
          1.2826,  1.3016,  1.3016,  1.3266,  1.3717,  1.2761,  1.1631,  1.2022,
          1.1123,  1.3207,  1.1738,  1.2789,  0.3711,  0.2900,  0.4138,  0.3825,
          0.2076,  0.1601,  0.3779,  0.3798,  0.1154,  2.2697,  1.6443,  1.9181,
          1.8359,  1.5284,  1.0547,  2.2230,  1.7325,  1.0249]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 46 : 178.903983416312
Test loss for epoch 46 : 178.72582096687333
Test Precision for epoch 46 : 0.26153846153846155
Test Recall for epoch 46 : 0.26153846153846155
Test F1 for epoch 46 : 0.26153846153846155


theta for epoch 47 : tensor([[ 1.8976,  1.9456,  2.0076,  2.0283,  2.0143,  1.9084,  1.9617,  1.8968,
          1.8968,  1.3926,  1.3914,  1.3932,  1.3948,  1.3931,  1.3956,  1.3926,
          1.3933,  1.3488,  1.3232,  1.2841,  1.2822,  1.3226,  1.3205,  1.3202,
          1.3207,  1.3203,  1.3203,  1.2965,  1.3332,  1.3289,  1.3327,  1.3344,
          1.3310,  1.3341,  1.2916,  1.3291,  1.7348,  1.7629,  1.7396,  1.7380,
          1.7656,  1.7153,  1.7344,  1.7507,  1.7645,  1.6777,  1.6525,  1.6499,
          1.6304,  1.6690,  1.6404,  1.6971,  1.6339,  1.6283],
        [ 1.3891,  1.2388,  1.0620,  1.2874,  1.3620,  1.4329,  1.3528,  1.4301,
          1.4301,  1.4562,  1.6591,  1.3774,  2.1620,  1.4307,  3.1662,  1.4972,
          1.3273,  2.8060,  1.2189,  1.2504,  1.0236,  1.2458,  1.4026,  1.4339,
          1.3925,  1.4371,  1.4371,  1.3369,  1.1304,  1.4579,  1.4197,  1.1509,
          1.4612,  1.4539,  1.4206,  1.4255,  1.5377,  1.7072,  1.6108,  1.5466,
          1.5642,  1.6994,  1.6023,  0.7279,  1.5920,  1.3354,  1.7077,  1.7040,
          1.6790,  1.3721,  1.6864,  1.1142,  1.6834,  1.6747],
        [ 1.3133,  1.3202,  1.3278,  1.3261,  1.3100,  1.3147,  1.3204,  1.3133,
          1.3133,  1.3882,  1.3926,  1.3868,  1.3865,  1.3893,  1.3287,  1.3874,
          1.3806,  1.3128,  1.9498,  2.0379,  2.1314,  2.0687,  1.8572,  1.9000,
          1.9950,  1.8485,  1.8485,  1.3374,  1.3095,  1.3392,  1.3427,  1.3401,
          1.3410,  1.3429,  1.3385,  1.3393,  1.7603,  1.7887,  1.7654,  1.7428,
          1.7912,  1.7930,  1.7607,  1.6658,  1.7465,  1.6253,  1.6547,  1.6528,
          1.6344,  1.5970,  1.6441,  1.6730,  1.6379,  1.6323],
        [ 1.3346,  1.3389,  1.2605,  1.2625,  1.3404,  1.3371,  1.3366,  1.3345,
          1.3345,  1.4230,  1.3560,  1.4151,  1.3992,  1.4247,  1.3194,  1.4221,
          1.4239,  1.2187,  1.3417,  1.3197,  1.3356,  1.3411,  1.3421,  1.3217,
          1.3416,  1.3429,  1.3429,  2.2566,  1.9134,  1.7427,  1.8489,  2.2241,
          1.7459,  2.1963,  1.7529,  1.7345,  1.7410,  1.7439,  1.6968,  1.7120,
          1.7785,  1.7305,  1.7285,  1.5383,  1.7611,  1.6868,  1.6228,  1.5458,
          1.5860,  1.6816,  1.5512,  1.7051,  1.5895,  1.6337],
        [ 1.5869,  1.2955,  0.4830,  0.7248,  1.0903,  1.4847,  1.4141,  1.5860,
          1.5860,  1.4708,  1.2222,  1.3031,  0.8331,  1.5265,  0.0977,  1.4426,
          1.5373,  1.0750,  1.1977,  0.7610,  0.6489,  0.9900,  1.4581,  1.5422,
          1.2405,  1.5925,  1.5925,  0.6433,  0.7124,  1.6082,  1.4010,  0.8070,
          1.6166,  1.1067,  1.6473,  1.5999,  0.8777,  0.4969,  0.4176,  0.7885,
          1.3083,  1.5381,  0.7186,  3.6842,  3.3637,  0.0252,  0.3311,  0.3585,
          0.4613,  0.1743,  0.4750, -0.2137,  0.4689,  0.5426],
        [ 1.2945,  1.3272,  1.3966,  1.3730,  1.3431,  1.2993,  1.2765,  1.2935,
          1.2935,  1.2765,  1.3261,  1.2709,  1.3863,  1.3411,  1.4241,  1.2806,
          1.3481,  1.2511,  1.3524,  1.3769,  1.3724,  1.3635,  1.3301,  1.3139,
          1.2984,  1.3187,  1.3187,  1.3381,  1.3837,  1.2893,  1.1755,  1.2141,
          1.1263,  1.3328,  1.1872,  1.2917,  0.3535,  0.2814,  0.3978,  0.3652,
          0.1972,  0.1515,  0.3616,  0.3506,  0.1054,  2.2696,  1.6417,  1.9203,
          1.8357,  1.5184,  1.0479,  2.2207,  1.7328,  1.0180]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 47 : 178.85251077745644
Test loss for epoch 47 : 178.67595127340095
Test Precision for epoch 47 : 0.26153846153846155
Test Recall for epoch 47 : 0.26153846153846155
Test F1 for epoch 47 : 0.26153846153846155


theta for epoch 48 : tensor([[ 1.9033,  1.9498,  2.0106,  2.0332,  2.0188,  1.9137,  1.9679,  1.9026,
          1.9026,  1.3903,  1.3888,  1.3901,  1.3918,  1.3911,  1.3922,  1.3900,
          1.3911,  1.3459,  1.3341,  1.2948,  1.2942,  1.3337,  1.3322,  1.3320,
          1.3324,  1.3320,  1.3320,  1.3066,  1.3422,  1.3394,  1.3425,  1.3436,
          1.3411,  1.3439,  1.3019,  1.3395,  1.7459,  1.7734,  1.7506,  1.7489,
          1.7756,  1.7251,  1.7456,  1.7598,  1.7751,  1.6811,  1.6580,  1.6555,
          1.6383,  1.6728,  1.6471,  1.7000,  1.6410,  1.6362],
        [ 1.3937,  1.2451,  1.0659,  1.2911,  1.3678,  1.4372,  1.3570,  1.4346,
          1.4346,  1.4702,  1.6659,  1.3954,  2.1651,  1.4467,  3.1836,  1.5141,
          1.3467,  2.8236,  1.2264,  1.2597,  1.0406,  1.2544,  1.4126,  1.4440,
          1.4018,  1.4472,  1.4472,  1.3453,  1.1419,  1.4683,  1.4296,  1.1598,
          1.4706,  1.4632,  1.4302,  1.4365,  1.5625,  1.7270,  1.6319,  1.5696,
          1.5886,  1.7194,  1.6242,  0.7564,  1.6162,  1.3553,  1.7290,  1.7258,
          1.7070,  1.3902,  1.7112,  1.1313,  1.7095,  1.7031],
        [ 1.3191,  1.3255,  1.3325,  1.3315,  1.3172,  1.3203,  1.3268,  1.3190,
          1.3190,  1.3863,  1.3903,  1.3844,  1.3840,  1.3876,  1.3250,  1.3853,
          1.3787,  1.3109,  1.9528,  2.0371,  2.1290,  2.0687,  1.8629,  1.9061,
          1.9979,  1.8550,  1.8550,  1.3480,  1.3190,  1.3496,  1.3525,  1.3505,
          1.3510,  1.3527,  1.3488,  1.3496,  1.7706,  1.7983,  1.7756,  1.7536,
          1.8004,  1.8020,  1.7710,  1.6766,  1.7600,  1.6313,  1.6597,  1.6578,
          1.6417,  1.6011,  1.6502,  1.6746,  1.6444,  1.6397],
        [ 1.3364,  1.3402,  1.2623,  1.2646,  1.3419,  1.3389,  1.3383,  1.3363,
          1.3363,  1.4156,  1.3491,  1.4069,  1.3924,  1.4177,  1.3113,  1.4144,
          1.4167,  1.2130,  1.3473,  1.3260,  1.3416,  1.3466,  1.3478,  1.3276,
          1.3472,  1.3487,  1.3487,  2.2718,  1.9340,  1.7647,  1.8695,  2.2404,
          1.7682,  2.2129,  1.7747,  1.7570,  1.7535,  1.7570,  1.7106,  1.7256,
          1.7895,  1.7441,  1.7420,  1.5484,  1.7725,  1.6884,  1.6294,  1.5535,
          1.5941,  1.6840,  1.5612,  1.7042,  1.5966,  1.6417],
        [ 1.5972,  1.3039,  0.4897,  0.7325,  1.0982,  1.4942,  1.4244,  1.5964,
          1.5964,  1.4861,  1.2339,  1.3200,  0.8430,  1.5429,  0.1043,  1.4604,
          1.5547,  1.0857,  1.2100,  0.7690,  0.6502,  0.9994,  1.4695,  1.5545,
          1.2523,  1.6053,  1.6053,  0.6536,  0.7220,  1.6259,  1.4158,  0.8167,
          1.6330,  1.1180,  1.6650,  1.6169,  0.8616,  0.4791,  0.3994,  0.7727,
          1.2972,  1.5307,  0.7009,  3.7418,  3.4094,  0.0214,  0.3304,  0.3582,
          0.4616,  0.1725,  0.4744, -0.2208,  0.4689,  0.5420],
        [ 1.2975,  1.3302,  1.3989,  1.3755,  1.3479,  1.3039,  1.2797,  1.2967,
          1.2967,  1.2873,  1.3373,  1.2785,  1.3956,  1.3542,  1.4295,  1.2901,
          1.3604,  1.2596,  1.3592,  1.3830,  1.3784,  1.3694,  1.3371,  1.3207,
          1.3041,  1.3257,  1.3257,  1.3477,  1.3938,  1.3005,  1.1853,  1.2237,
          1.1375,  1.3432,  1.1980,  1.3026,  0.3270,  0.2628,  0.3730,  0.3388,
          0.1763,  0.1321,  0.3364,  0.3120,  0.0840,  2.2834,  1.6532,  1.9365,
          1.8496,  1.5224,  1.0549,  2.2323,  1.7472,  1.0248]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 48 : 178.78158632290467
Test loss for epoch 48 : 178.5933993450643
Test Precision for epoch 48 : 0.26153846153846155
Test Recall for epoch 48 : 0.26153846153846155
Test F1 for epoch 48 : 0.26153846153846155


theta for epoch 49 : tensor([[ 1.9101,  1.9551,  2.0146,  2.0391,  2.0244,  1.9202,  1.9752,  1.9094,
          1.9094,  1.3881,  1.3864,  1.3872,  1.3890,  1.3891,  1.3890,  1.3875,
          1.3890,  1.3432,  1.3440,  1.3046,  1.3053,  1.3439,  1.3430,  1.3428,
          1.3433,  1.3428,  1.3428,  1.3166,  1.3514,  1.3497,  1.3523,  1.3529,
          1.3511,  1.3536,  1.3121,  1.3497,  1.7543,  1.7811,  1.7589,  1.7570,
          1.7827,  1.7321,  1.7541,  1.7662,  1.7828,  1.6846,  1.6635,  1.6609,
          1.6459,  1.6766,  1.6536,  1.7027,  1.6479,  1.6440],
        [ 1.4003,  1.2531,  1.0720,  1.2969,  1.3755,  1.4434,  1.3632,  1.4411,
          1.4411,  1.4830,  1.6713,  1.4120,  2.1663,  1.4614,  3.1987,  1.5297,
          1.3646,  2.8390,  1.2339,  1.2692,  1.0577,  1.2630,  1.4224,  1.4540,
          1.4113,  1.4572,  1.4572,  1.3543,  1.1540,  1.4788,  1.4397,  1.1691,
          1.4803,  1.4729,  1.4400,  1.4477,  1.5852,  1.7445,  1.6510,  1.5905,
          1.6109,  1.7371,  1.6440,  0.7833,  1.6381,  1.3744,  1.7495,  1.7469,
          1.7339,  1.4073,  1.7352,  1.1483,  1.7346,  1.7303],
        [ 1.3273,  1.3334,  1.3398,  1.3393,  1.3268,  1.3286,  1.3355,  1.3273,
          1.3273,  1.3861,  1.3896,  1.3838,  1.3833,  1.3875,  1.3231,  1.3850,
          1.3783,  1.3108,  1.9531,  2.0336,  2.1240,  2.0661,  1.8659,  1.9093,
          1.9980,  1.8587,  1.8587,  1.3594,  1.3292,  1.3609,  1.3631,  1.3616,
          1.3619,  1.3634,  1.3599,  1.3608,  1.7785,  1.8055,  1.7834,  1.7620,
          1.8070,  1.8085,  1.7789,  1.6848,  1.7707,  1.6380,  1.6656,  1.6636,
          1.6497,  1.6058,  1.6572,  1.6768,  1.6517,  1.6478],
        [ 1.3408,  1.3441,  1.2668,  1.2692,  1.3459,  1.3433,  1.3425,  1.3408,
          1.3408,  1.4099,  1.3439,  1.4006,  1.3872,  1.4122,  1.3052,  1.4084,
          1.4111,  1.2090,  1.3540,  1.3332,  1.3489,  1.3532,  1.3545,  1.3345,
          1.3539,  1.3555,  1.3555,  2.2838,  1.9517,  1.7837,  1.8871,  2.2535,
          1.7875,  2.2262,  1.7936,  1.7765,  1.7636,  1.7675,  1.7219,  1.7369,
          1.7979,  1.7551,  1.7530,  1.5561,  1.7812,  1.6910,  1.6368,  1.5615,
          1.6027,  1.6874,  1.5717,  1.7045,  1.6044,  1.6504],
        [ 1.6050,  1.3086,  0.4907,  0.7352,  1.1017,  1.5007,  1.4314,  1.6043,
          1.6043,  1.4956,  1.2391,  1.3306,  0.8456,  1.5536,  0.1025,  1.4724,
          1.5665,  1.0890,  1.2158,  0.7699,  0.6441,  1.0017,  1.4751,  1.5611,
          1.2577,  1.6126,  1.6126,  0.6554,  0.7231,  1.6371,  1.4235,  0.8180,
          1.6429,  1.1213,  1.6765,  1.6274,  0.8519,  0.4674,  0.3872,  0.7633,
          1.2928,  1.5300,  0.6894,  3.8056,  3.4617,  0.0082,  0.3211,  0.3490,
          0.4538,  0.1619,  0.4657, -0.2373,  0.4606,  0.5337],
        [ 1.3066,  1.3391,  1.4068,  1.3838,  1.3583,  1.3144,  1.2889,  1.3059,
          1.3059,  1.3035,  1.3541,  1.2921,  1.4106,  1.3722,  1.4412,  1.3052,
          1.3776,  1.2745,  1.3725,  1.3955,  1.3909,  1.3818,  1.3505,  1.3340,
          1.3165,  1.3391,  1.3391,  1.3620,  1.4080,  1.3163,  1.1997,  1.2382,
          1.1535,  1.3580,  1.2137,  1.3181,  0.3089,  0.2519,  0.3564,  0.3208,
          0.1632,  0.1204,  0.3196,  0.2809,  0.0697,  2.2874,  1.6553,  1.9431,
          1.8539,  1.5172,  1.0532,  2.2342,  1.7522,  1.0230]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 49 : 178.73549509958656
Test loss for epoch 49 : 178.5446521530153
Test Precision for epoch 49 : 0.26153846153846155
Test Recall for epoch 49 : 0.26153846153846155
Test F1 for epoch 49 : 0.26153846153846155


theta for epoch 50 : tensor([[ 1.9187e+00,  1.9621e+00,  2.0204e+00,  2.0468e+00,  2.0317e+00,
          1.9284e+00,  1.9843e+00,  1.9180e+00,  1.9180e+00,  1.3890e+00,
          1.3872e+00,  1.3876e+00,  1.3894e+00,  1.3901e+00,  1.3891e+00,
          1.3882e+00,  1.3899e+00,  1.3438e+00,  1.3521e+00,  1.3126e+00,
          1.3144e+00,  1.3523e+00,  1.3518e+00,  1.3516e+00,  1.3522e+00,
          1.3516e+00,  1.3516e+00,  1.3217e+00,  1.3559e+00,  1.3552e+00,
          1.3572e+00,  1.3574e+00,  1.3563e+00,  1.3585e+00,  1.3173e+00,
          1.3552e+00,  1.7606e+00,  1.7866e+00,  1.7651e+00,  1.7630e+00,
          1.7877e+00,  1.7368e+00,  1.7605e+00,  1.7705e+00,  1.7883e+00,
          1.6895e+00,  1.6703e+00,  1.6678e+00,  1.6549e+00,  1.6819e+00,
          1.6615e+00,  1.7069e+00,  1.6561e+00,  1.6531e+00],
        [ 1.4086e+00,  1.2626e+00,  1.0799e+00,  1.3046e+00,  1.3850e+00,
          1.4514e+00,  1.3712e+00,  1.4493e+00,  1.4493e+00,  1.4975e+00,
          1.6784e+00,  1.4301e+00,  2.1686e+00,  1.4778e+00,  3.2142e+00,
          1.5469e+00,  1.3840e+00,  2.8553e+00,  1.2400e+00,  1.2772e+00,
          1.0730e+00,  1.2701e+00,  1.4305e+00,  1.4626e+00,  1.4193e+00,
          1.4657e+00,  1.4657e+00,  1.3584e+00,  1.1616e+00,  1.4843e+00,
          1.4449e+00,  1.1736e+00,  1.4850e+00,  1.4775e+00,  1.4449e+00,
          1.4539e+00,  1.6064e+00,  1.7602e+00,  1.6684e+00,  1.6097e+00,
          1.6315e+00,  1.7529e+00,  1.6622e+00,  8.0865e-01,  1.6581e+00,
          1.3941e+00,  1.7708e+00,  1.7686e+00,  1.7608e+00,  1.4248e+00,
          1.7595e+00,  1.1666e+00,  1.7599e+00,  1.7577e+00],
        [ 1.3373e+00,  1.3430e+00,  1.3488e+00,  1.3488e+00,  1.3379e+00,
          1.3385e+00,  1.3458e+00,  1.3374e+00,  1.3374e+00,  1.3896e+00,
          1.3926e+00,  1.3871e+00,  1.3866e+00,  1.3912e+00,  1.3252e+00,
          1.3884e+00,  1.3815e+00,  1.3145e+00,  1.9544e+00,  2.0309e+00,
          2.1198e+00,  2.0642e+00,  1.8695e+00,  1.9132e+00,  1.9988e+00,
          1.8630e+00,  1.8630e+00,  1.3656e+00,  1.3344e+00,  1.3671e+00,
          1.3687e+00,  1.3676e+00,  1.3678e+00,  1.3691e+00,  1.3659e+00,
          1.3669e+00,  1.7843e+00,  1.8105e+00,  1.7890e+00,  1.7683e+00,
          1.8115e+00,  1.8128e+00,  1.7847e+00,  1.6907e+00,  1.7790e+00,
          1.6462e+00,  1.6731e+00,  1.6710e+00,  1.6592e+00,  1.6118e+00,
          1.6657e+00,  1.6805e+00,  1.6605e+00,  1.6575e+00],
        [ 1.3492e+00,  1.3521e+00,  1.2754e+00,  1.2779e+00,  1.3539e+00,
          1.3517e+00,  1.3507e+00,  1.3492e+00,  1.3492e+00,  1.4116e+00,
          1.3463e+00,  1.4018e+00,  1.3895e+00,  1.4140e+00,  1.3072e+00,
          1.4099e+00,  1.4128e+00,  1.2127e+00,  1.3634e+00,  1.3431e+00,
          1.3590e+00,  1.3626e+00,  1.3637e+00,  1.3439e+00,  1.3632e+00,
          1.3648e+00,  1.3648e+00,  2.2854e+00,  1.9588e+00,  1.7921e+00,
          1.8942e+00,  2.2561e+00,  1.7962e+00,  2.2290e+00,  1.8019e+00,
          1.7854e+00,  1.7727e+00,  1.7770e+00,  1.7322e+00,  1.7473e+00,
          1.8052e+00,  1.7650e+00,  1.7630e+00,  1.5631e+00,  1.7889e+00,
          1.6976e+00,  1.6478e+00,  1.5732e+00,  1.6150e+00,  1.6947e+00,
          1.5857e+00,  1.7090e+00,  1.6158e+00,  1.6628e+00],
        [ 1.6141e+00,  1.3148e+00,  4.9257e-01,  7.3875e-01,  1.1067e+00,
          1.5087e+00,  1.4399e+00,  1.6135e+00,  1.6135e+00,  1.5068e+00,
          1.2458e+00,  1.3424e+00,  8.4935e-01,  1.5660e+00,  1.0177e-01,
          1.4857e+00,  1.5799e+00,  1.0933e+00,  1.2209e+00,  7.7037e-01,
          6.3793e-01,  1.0037e+00,  1.4800e+00,  1.5669e+00,  1.2624e+00,
          1.6192e+00,  1.6192e+00,  6.5320e-01,  7.2008e-01,  1.6423e+00,
          1.4255e+00,  8.1482e-01,  1.6467e+00,  1.1193e+00,  1.6819e+00,
          1.6318e+00,  8.4201e-01,  4.5554e-01,  3.7514e-01,  7.5365e-01,
          1.2879e+00,  1.5286e+00,  6.7768e-01,  3.8698e+00,  3.5138e+00,
         -1.7871e-03,  3.1505e-01,  3.4314e-01,  4.5028e-01,  1.5474e-01,
          4.6111e-01, -2.5110e-01,  4.5631e-01,  5.3005e-01],
        [ 1.3163e+00,  1.3487e+00,  1.4153e+00,  1.3927e+00,  1.3692e+00,
          1.3254e+00,  1.2986e+00,  1.3157e+00,  1.3157e+00,  1.3192e+00,
          1.3707e+00,  1.3055e+00,  1.4259e+00,  1.3897e+00,  1.4537e+00,
          1.3198e+00,  1.3943e+00,  1.2895e+00,  1.3826e+00,  1.4049e+00,
          1.4002e+00,  1.3911e+00,  1.3607e+00,  1.3441e+00,  1.3255e+00,
          1.3491e+00,  1.3491e+00,  1.3703e+00,  1.4162e+00,  1.3258e+00,
          1.2078e+00,  1.2469e+00,  1.1633e+00,  1.3668e+00,  1.2230e+00,
          1.3273e+00,  2.9100e-01,  2.4032e-01,  3.3995e-01,  3.0295e-01,
          1.4925e-01,  1.0754e-01,  3.0294e-01,  2.4953e-01,  5.3679e-02,
          2.2949e+00,  1.6609e+00,  1.9534e+00,  1.8617e+00,  1.5157e+00,
          1.0552e+00,  2.2395e+00,  1.7608e+00,  1.0251e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 50 : 178.68872137048896
Test loss for epoch 50 : 178.49491001619992
Test Precision for epoch 50 : 0.26153846153846155
Test Recall for epoch 50 : 0.26153846153846155
Test F1 for epoch 50 : 0.26153846153846155


theta for epoch 51 : tensor([[ 1.9280e+00,  1.9700e+00,  2.0271e+00,  2.0552e+00,  2.0398e+00,
          1.9374e+00,  1.9941e+00,  1.9274e+00,  1.9274e+00,  1.3920e+00,
          1.3902e+00,  1.3902e+00,  1.3920e+00,  1.3933e+00,  1.3915e+00,
          1.3911e+00,  1.3930e+00,  1.3466e+00,  1.3580e+00,  1.3184e+00,
          1.3212e+00,  1.3585e+00,  1.3584e+00,  1.3582e+00,  1.3588e+00,
          1.3581e+00,  1.3581e+00,  1.3236e+00,  1.3574e+00,  1.3576e+00,
          1.3591e+00,  1.3589e+00,  1.3584e+00,  1.3603e+00,  1.3195e+00,
          1.3575e+00,  1.7659e+00,  1.7911e+00,  1.7703e+00,  1.7681e+00,
          1.7916e+00,  1.7405e+00,  1.7660e+00,  1.7738e+00,  1.7927e+00,
          1.6949e+00,  1.6775e+00,  1.6750e+00,  1.6641e+00,  1.6877e+00,
          1.6697e+00,  1.7114e+00,  1.6647e+00,  1.6625e+00],
        [ 1.4168e+00,  1.2719e+00,  1.0878e+00,  1.3125e+00,  1.3944e+00,
          1.4594e+00,  1.3791e+00,  1.4575e+00,  1.4575e+00,  1.5136e+00,
          1.6872e+00,  1.4498e+00,  2.1720e+00,  1.4957e+00,  3.2302e+00,
          1.5657e+00,  1.4048e+00,  2.8723e+00,  1.2442e+00,  1.2833e+00,
          1.0861e+00,  1.2750e+00,  1.4366e+00,  1.4692e+00,  1.4255e+00,
          1.4721e+00,  1.4721e+00,  1.3594e+00,  1.1662e+00,  1.4865e+00,
          1.4468e+00,  1.1748e+00,  1.4864e+00,  1.4790e+00,  1.4465e+00,
          1.4568e+00,  1.6268e+00,  1.7750e+00,  1.6851e+00,  1.6282e+00,
          1.6512e+00,  1.7678e+00,  1.6795e+00,  8.3318e-01,  1.6771e+00,
          1.4130e+00,  1.7913e+00,  1.7894e+00,  1.7865e+00,  1.4414e+00,
          1.7829e+00,  1.1847e+00,  1.7841e+00,  1.7838e+00],
        [ 1.3463e+00,  1.3516e+00,  1.3568e+00,  1.3573e+00,  1.3479e+00,
          1.3474e+00,  1.3549e+00,  1.3463e+00,  1.3463e+00,  1.3943e+00,
          1.3968e+00,  1.3916e+00,  1.3912e+00,  1.3958e+00,  1.3285e+00,
          1.3930e+00,  1.3857e+00,  1.3192e+00,  1.9598e+00,  2.0323e+00,
          2.1199e+00,  2.0664e+00,  1.8772e+00,  1.9210e+00,  2.0036e+00,
          1.8713e+00,  1.8713e+00,  1.3675e+00,  1.3353e+00,  1.3691e+00,
          1.3702e+00,  1.3692e+00,  1.3695e+00,  1.3706e+00,  1.3678e+00,
          1.3688e+00,  1.7887e+00,  1.8140e+00,  1.7932e+00,  1.7730e+00,
          1.8145e+00,  1.8155e+00,  1.7891e+00,  1.6950e+00,  1.7854e+00,
          1.6539e+00,  1.6800e+00,  1.6779e+00,  1.6681e+00,  1.6171e+00,
          1.6737e+00,  1.6838e+00,  1.6687e+00,  1.6666e+00],
        [ 1.3592e+00,  1.3617e+00,  1.2857e+00,  1.2881e+00,  1.3635e+00,
          1.3616e+00,  1.3605e+00,  1.3592e+00,  1.3592e+00,  1.4183e+00,
          1.3538e+00,  1.4082e+00,  1.3968e+00,  1.4208e+00,  1.3147e+00,
          1.4165e+00,  1.4195e+00,  1.2217e+00,  1.3738e+00,  1.3541e+00,
          1.3702e+00,  1.3731e+00,  1.3740e+00,  1.3543e+00,  1.3737e+00,
          1.3750e+00,  1.3750e+00,  2.2803e+00,  1.9594e+00,  1.7939e+00,
          1.8946e+00,  2.2520e+00,  1.7983e+00,  2.2252e+00,  1.8035e+00,
          1.7877e+00,  1.7816e+00,  1.7861e+00,  1.7424e+00,  1.7575e+00,
          1.8122e+00,  1.7745e+00,  1.7728e+00,  1.5702e+00,  1.7962e+00,
          1.7065e+00,  1.6607e+00,  1.5864e+00,  1.6292e+00,  1.7041e+00,
          1.6013e+00,  1.7159e+00,  1.6292e+00,  1.6770e+00],
        [ 1.6253e+00,  1.3236e+00,  4.9768e-01,  7.4517e-01,  1.1147e+00,
          1.5190e+00,  1.4507e+00,  1.6248e+00,  1.6248e+00,  1.5217e+00,
          1.2567e+00,  1.3576e+00,  8.5743e-01,  1.5819e+00,  1.0586e-01,
          1.5023e+00,  1.5967e+00,  1.1011e+00,  1.2285e+00,  7.7414e-01,
          6.3585e-01,  1.0087e+00,  1.4872e+00,  1.5746e+00,  1.2692e+00,
          1.6278e+00,  1.6278e+00,  6.5252e-01,  7.1849e-01,  1.6463e+00,
          1.4269e+00,  8.1293e-01,  1.6493e+00,  1.1174e+00,  1.6860e+00,
          1.6350e+00,  8.2881e-01,  4.4092e-01,  3.6046e-01,  7.4082e-01,
          1.2792e+00,  1.5230e+00,  6.6290e-01,  3.9312e+00,  3.5625e+00,
         -3.3366e-03,  3.1694e-01,  3.4571e-01,  4.5588e-01,  1.5602e-01,
          4.6550e-01, -2.5693e-01,  4.6089e-01,  5.3567e-01],
        [ 1.3240e+00,  1.3562e+00,  1.4217e+00,  1.3995e+00,  1.3778e+00,
          1.3343e+00,  1.3063e+00,  1.3235e+00,  1.3235e+00,  1.3314e+00,
          1.3842e+00,  1.3157e+00,  1.4383e+00,  1.4037e+00,  1.4637e+00,
          1.3310e+00,  1.4077e+00,  1.3015e+00,  1.3875e+00,  1.4090e+00,
          1.4042e+00,  1.3950e+00,  1.3655e+00,  1.3488e+00,  1.3291e+00,
          1.3539e+00,  1.3539e+00,  1.3732e+00,  1.4189e+00,  1.3296e+00,
          1.2100e+00,  1.2501e+00,  1.1672e+00,  1.3700e+00,  1.2264e+00,
          1.3309e+00,  2.7200e-01,  2.2657e-01,  3.2237e-01,  2.8389e-01,
          1.3297e-01,  9.2112e-02,  2.8518e-01,  2.1697e-01,  3.4658e-02,
          2.3084e+00,  1.6727e+00,  1.9698e+00,  1.8757e+00,  1.5203e+00,
          1.0634e+00,  2.2508e+00,  1.7757e+00,  1.0332e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 51 : 178.65745454298576
Test loss for epoch 51 : 178.45698382062585
Test Precision for epoch 51 : 0.26153846153846155
Test Recall for epoch 51 : 0.26153846153846155
Test F1 for epoch 51 : 0.26153846153846155


theta for epoch 52 : tensor([[ 1.9367,  1.9771,  2.0330,  2.0629,  2.0471,  1.9457,  2.0032,  1.9360,
          1.9360,  1.3941,  1.3923,  1.3920,  1.3938,  1.3954,  1.3931,  1.3930,
          1.3950,  1.3485,  1.3622,  1.3225,  1.3262,  1.3630,  1.3632,  1.3630,
          1.3637,  1.3629,  1.3629,  1.3276,  1.3611,  1.3620,  1.3631,  1.3626,
          1.3625,  1.3642,  1.3236,  1.3618,  1.7720,  1.7963,  1.7763,  1.7740,
          1.7963,  1.7448,  1.7722,  1.7780,  1.7977,  1.6970,  1.6811,  1.6786,
          1.6696,  1.6901,  1.6744,  1.7126,  1.6696,  1.6682],
        [ 1.4232,  1.2791,  1.0941,  1.3186,  1.4020,  1.4656,  1.3852,  1.4639,
          1.4639,  1.5287,  1.6950,  1.4682,  2.1741,  1.5125,  3.2442,  1.5834,
          1.4243,  2.8876,  1.2472,  1.2882,  1.0977,  1.2788,  1.4412,  1.4745,
          1.4304,  1.4772,  1.4772,  1.3629,  1.1735,  1.4909,  1.4510,  1.1785,
          1.4902,  1.4828,  1.4504,  1.4620,  1.6482,  1.7905,  1.7027,  1.6475,
          1.6718,  1.7835,  1.6978,  0.8586,  1.6969,  1.4270,  1.8067,  1.8051,
          1.8066,  1.4530,  1.8010,  1.1986,  1.8030,  1.8044],
        [ 1.3518,  1.3567,  1.3614,  1.3622,  1.3542,  1.3529,  1.3604,  1.3519,
          1.3519,  1.3957,  1.3978,  1.3930,  1.3926,  1.3972,  1.3290,  1.3944,
          1.3866,  1.3206,  1.9705,  2.0390,  2.1252,  2.0739,  1.8901,  1.9339,
          2.0135,  1.8847,  1.8847,  1.3701,  1.3370,  1.3718,  1.3725,  1.3715,
          1.3720,  1.3729,  1.3704,  1.3715,  1.7931,  1.8175,  1.7975,  1.7779,
          1.8175,  1.8184,  1.7936,  1.6992,  1.7917,  1.6566,  1.6823,  1.6801,
          1.6721,  1.6174,  1.6768,  1.6823,  1.6721,  1.6707],
        [ 1.3671,  1.3692,  1.2939,  1.2962,  1.3710,  1.3694,  1.3682,  1.3671,
          1.3671,  1.4237,  1.3599,  1.4133,  1.4026,  1.4261,  1.3209,  1.4218,
          1.4248,  1.2292,  1.3824,  1.3631,  1.3796,  1.3818,  1.3823,  1.3628,
          1.3822,  1.3834,  1.3834,  2.2777,  1.9627,  1.7983,  1.8977,  2.2504,
          1.8029,  2.2238,  1.8078,  1.7925,  1.7911,  1.7958,  1.7530,  1.7682,
          1.8198,  1.7844,  1.7830,  1.5780,  1.8040,  1.7120,  1.6697,  1.5956,
          1.6392,  1.7101,  1.6127,  1.7197,  1.6385,  1.6874],
        [ 1.6323,  1.3277,  0.4971,  0.7463,  1.1175,  1.5249,  1.4570,  1.6319,
          1.6319,  1.5318,  1.2623,  1.3676,  0.8598,  1.5932,  0.1037,  1.5141,
          1.6089,  1.1029,  1.2316,  0.7730,  0.6288,  1.0091,  1.4904,  1.5785,
          1.2717,  1.6326,  1.6326,  0.6478,  0.7130,  1.6484,  1.4258,  0.8072,
          1.6501,  1.1122,  1.6884,  1.6362,  0.8212,  0.4317,  0.3512,  0.7336,
          1.2761,  1.5231,  0.6536,  3.9977,  3.6164, -0.0125,  0.3114,  0.3404,
          0.4538,  0.1498,  0.4623, -0.2701,  0.4578,  0.5339],
        [ 1.3358,  1.3678,  1.4318,  1.4102,  1.3902,  1.3471,  1.3181,  1.3355,
          1.3355,  1.3503,  1.4044,  1.3333,  1.4576,  1.4238,  1.4812,  1.3491,
          1.4271,  1.3212,  1.4013,  1.4219,  1.4171,  1.4079,  1.3795,  1.3627,
          1.3420,  1.3677,  1.3677,  1.3844,  1.4293,  1.3418,  1.2208,  1.2621,
          1.1798,  1.3815,  1.2383,  1.3428,  0.2670,  0.2259,  0.3185,  0.2788,
          0.1301,  0.0899,  0.2813,  0.1987,  0.0285,  2.3077,  1.6704,  1.9720,
          1.8755,  1.5113,  1.0585,  2.2479,  1.7764,  1.0284]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 52 : 178.63393952434012
Test loss for epoch 52 : 178.4382836182337
Test Precision for epoch 52 : 0.26153846153846155
Test Recall for epoch 52 : 0.26153846153846155
Test F1 for epoch 52 : 0.26153846153846155


theta for epoch 53 : tensor([[ 1.9430,  1.9819,  2.0366,  2.0683,  2.0522,  1.9517,  2.0100,  1.9424,
          1.9424,  1.3934,  1.3917,  1.3911,  1.3929,  1.3946,  1.3921,  1.3922,
          1.3942,  1.3477,  1.3639,  1.3241,  1.3285,  1.3649,  1.3653,  1.3651,
          1.3660,  1.3649,  1.3649,  1.3358,  1.3692,  1.3706,  1.3714,  1.3707,
          1.3710,  1.3724,  1.3320,  1.3704,  1.7787,  1.8021,  1.7829,  1.7805,
          1.8016,  1.7498,  1.7790,  1.7828,  1.8032,  1.6993,  1.6850,  1.6825,
          1.6752,  1.6929,  1.6791,  1.7140,  1.6746,  1.6740],
        [ 1.4273,  1.2839,  1.0985,  1.3227,  1.4073,  1.4694,  1.3890,  1.4680,
          1.4680,  1.5401,  1.6992,  1.4827,  2.1722,  1.5256,  3.2542,  1.5973,
          1.4398,  2.8988,  1.2482,  1.2909,  1.1069,  1.2802,  1.4433,  1.4774,
          1.4329,  1.4799,  1.4799,  1.3713,  1.1857,  1.4998,  1.4598,  1.1870,
          1.4986,  1.4914,  1.4589,  1.4718,  1.6701,  1.8066,  1.7208,  1.6674,
          1.6929,  1.7997,  1.7166,  0.8846,  1.7170,  1.4404,  1.8210,  1.8197,
          1.8250,  1.4637,  1.8177,  1.2126,  1.8203,  1.8233],
        [ 1.3538,  1.3582,  1.3624,  1.3635,  1.3569,  1.3548,  1.3623,  1.3539,
          1.3539,  1.3925,  1.3942,  1.3898,  1.3895,  1.3938,  1.3254,  1.3912,
          1.3828,  1.3172,  1.9827,  2.0471,  2.1319,  2.0828,  1.9041,  1.9480,
          2.0247,  1.8992,  1.8992,  1.3762,  1.3422,  1.3780,  1.3783,  1.3774,
          1.3780,  1.3788,  1.3766,  1.3777,  1.7976,  1.8210,  1.8019,  1.7828,
          1.8206,  1.8213,  1.7981,  1.7033,  1.7977,  1.6586,  1.6838,  1.6815,
          1.6752,  1.6169,  1.6791,  1.6802,  1.6746,  1.6740],
        [ 1.3713,  1.3732,  1.2986,  1.3008,  1.3750,  1.3736,  1.3723,  1.3714,
          1.3714,  1.4238,  1.3606,  1.4134,  1.4030,  1.4261,  1.3219,  1.4218,
          1.4247,  1.2312,  1.3864,  1.3676,  1.3845,  1.3859,  1.3860,  1.3667,
          1.3862,  1.3871,  1.3871,  2.2809,  1.9721,  1.8086,  1.9068,  2.2547,
          1.8136,  2.2282,  1.8181,  1.8034,  1.8002,  1.8050,  1.7632,  1.7787,
          1.8270,  1.7939,  1.7929,  1.5856,  1.8115,  1.7164,  1.6773,  1.6029,
          1.6476,  1.7149,  1.6223,  1.7225,  1.6463,  1.6962],
        [ 1.6420,  1.3359,  0.5032,  0.7530,  1.1253,  1.5340,  1.4666,  1.6416,
          1.6416,  1.5457,  1.2729,  1.3815,  0.8687,  1.6078,  0.1105,  1.5294,
          1.6243,  1.1098,  1.2408,  0.7799,  0.6313,  1.0170,  1.4992,  1.5873,
          1.2800,  1.6422,  1.6422,  0.6562,  0.7207,  1.6609,  1.4361,  0.8148,
          1.6613,  1.1191,  1.7010,  1.6477,  0.8055,  0.4153,  0.3352,  0.7184,
          1.2639,  1.5134,  0.6366,  4.0565,  3.6614, -0.0049,  0.3213,  0.3514,
          0.4683,  0.1600,  0.4755, -0.2669,  0.4711,  0.5487],
        [ 1.3390,  1.3708,  1.4335,  1.4125,  1.3939,  1.3513,  1.3211,  1.3387,
          1.3387,  1.3535,  1.4092,  1.3352,  1.4616,  1.4285,  1.4835,  1.3515,
          1.4312,  1.3251,  1.4019,  1.4216,  1.4169,  1.4077,  1.3801,  1.3632,
          1.3413,  1.3682,  1.3682,  1.3926,  1.4368,  1.3508,  1.2276,  1.2706,
          1.1884,  1.3901,  1.2465,  1.3516,  0.2553,  0.2173,  0.3080,  0.2669,
          0.1190,  0.0791,  0.2707,  0.1740,  0.0137,  2.3214,  1.6826,  1.9887,
          1.8898,  1.5166,  1.0676,  2.2594,  1.7917,  1.0374]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 53 : 178.5837197941849
Test loss for epoch 53 : 178.37953493818264
Test Precision for epoch 53 : 0.26153846153846155
Test Recall for epoch 53 : 0.26153846153846155
Test F1 for epoch 53 : 0.26153846153846155


theta for epoch 54 : tensor([[ 1.9475,  1.9849,  2.0385,  2.0718,  2.0555,  1.9558,  2.0149,  1.9469,
          1.9469,  1.3929,  1.3914,  1.3906,  1.3924,  1.3941,  1.3916,  1.3917,
          1.3936,  1.3474,  1.3647,  1.3249,  1.3299,  1.3659,  1.3664,  1.3662,
          1.3672,  1.3660,  1.3660,  1.3457,  1.3793,  1.3810,  1.3815,  1.3807,
          1.3812,  1.3825,  1.3421,  1.3808,  1.7866,  1.8090,  1.7907,  1.7882,
          1.8080,  1.7559,  1.7870,  1.7889,  1.8098,  1.6987,  1.6857,  1.6832,
          1.6775,  1.6927,  1.6807,  1.7125,  1.6764,  1.6765],
        [ 1.4301,  1.2873,  1.1019,  1.3257,  1.4114,  1.4721,  1.3916,  1.4708,
          1.4708,  1.5493,  1.7013,  1.4948,  2.1678,  1.5364,  3.2613,  1.6089,
          1.4528,  2.9073,  1.2487,  1.2930,  1.1152,  1.2811,  1.4446,  1.4794,
          1.4348,  1.4817,  1.4817,  1.3818,  1.2001,  1.5105,  1.4705,  1.1975,
          1.5089,  1.5019,  1.4693,  1.4833,  1.6930,  1.8236,  1.7401,  1.6883,
          1.7150,  1.8169,  1.7365,  0.9116,  1.7380,  1.4493,  1.8304,  1.8293,
          1.8379,  1.4700,  1.8292,  1.2230,  1.8322,  1.8367],
        [ 1.3546,  1.3586,  1.3623,  1.3636,  1.3582,  1.3555,  1.3627,  1.3547,
          1.3547,  1.3898,  1.3911,  1.3873,  1.3871,  1.3910,  1.3227,  1.3885,
          1.3795,  1.3144,  1.9929,  2.0532,  2.1368,  2.0897,  1.9160,  1.9598,
          2.0339,  1.9115,  1.9115,  1.3843,  1.3494,  1.3862,  1.3862,  1.3851,
          1.3860,  1.3868,  1.3847,  1.3859,  1.8034,  1.8258,  1.8075,  1.7889,
          1.8249,  1.8254,  1.8039,  1.7085,  1.8046,  1.6576,  1.6823,  1.6800,
          1.6751,  1.6134,  1.6785,  1.6753,  1.6741,  1.6742],
        [ 1.3735,  1.3751,  1.3011,  1.3032,  1.3768,  1.3757,  1.3743,  1.3736,
          1.3736,  1.4226,  1.3599,  1.4122,  1.4021,  1.4246,  1.3217,  1.4206,
          1.4233,  1.2317,  1.3879,  1.3694,  1.3867,  1.3875,  1.3871,  1.3679,
          1.3876,  1.3882,  1.3882,  2.2870,  1.9846,  1.8220,  1.9188,  2.2618,
          1.8272,  2.2356,  1.8314,  1.8171,  1.8099,  1.8147,  1.7739,  1.7896,
          1.8347,  1.8038,  1.8032,  1.5940,  1.8194,  1.7169,  1.6805,  1.6057,
          1.6515,  1.7157,  1.6273,  1.7217,  1.6496,  1.7006],
        [ 1.6461,  1.3377,  0.5015,  0.7525,  1.1261,  1.5374,  1.4703,  1.6459,
          1.6459,  1.5531,  1.2761,  1.3886,  0.8695,  1.6161,  0.1083,  1.5380,
          1.6333,  1.1086,  1.2431,  0.7791,  0.6256,  1.0174,  1.5015,  1.5898,
          1.2816,  1.6458,  1.6458,  0.6573,  0.7213,  1.6690,  1.4412,  0.8152,
          1.6680,  1.1197,  1.7095,  1.6548,  0.7978,  0.4065,  0.3267,  0.7112,
          1.2599,  1.5122,  0.6275,  4.1226,  3.7140, -0.0091,  0.3200,  0.3505,
          0.4707,  0.1585,  0.4768, -0.2749,  0.4725,  0.5518],
        [ 1.3461,  1.3776,  1.4388,  1.4184,  1.4011,  1.3592,  1.3281,  1.3459,
          1.3459,  1.3631,  1.4205,  1.3443,  1.4723,  1.4390,  1.4931,  1.3605,
          1.4410,  1.3364,  1.4099,  1.4290,  1.4243,  1.4151,  1.3882,  1.3713,
          1.3485,  1.3761,  1.3761,  1.4080,  1.4511,  1.3669,  1.2420,  1.2866,
          1.2046,  1.4058,  1.2622,  1.3676,  0.2570,  0.2213,  0.3106,  0.2684,
          0.1208,  0.0811,  0.2733,  0.1637,  0.0115,  2.3218,  1.6816,  1.9920,
          1.8907,  1.5092,  1.0642,  2.2575,  1.7937,  1.0342]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 54 : 178.53875128633297
Test loss for epoch 54 : 178.33802217992388
Test Precision for epoch 54 : 0.26153846153846155
Test Recall for epoch 54 : 0.26153846153846155
Test F1 for epoch 54 : 0.26153846153846155


theta for epoch 55 : tensor([[ 1.9513e+00,  1.9873e+00,  2.0397e+00,  2.0747e+00,  2.0582e+00,
          1.9593e+00,  2.0192e+00,  1.9508e+00,  1.9508e+00,  1.3952e+00,
          1.3938e+00,  1.3928e+00,  1.3947e+00,  1.3962e+00,  1.3939e+00,
          1.3939e+00,  1.3958e+00,  1.3498e+00,  1.3663e+00,  1.3266e+00,
          1.3320e+00,  1.3678e+00,  1.3683e+00,  1.3680e+00,  1.3693e+00,
          1.3678e+00,  1.3678e+00,  1.3522e+00,  1.3860e+00,  1.3879e+00,
          1.3882e+00,  1.3873e+00,  1.3880e+00,  1.3890e+00,  1.3487e+00,
          1.3876e+00,  1.7937e+00,  1.8151e+00,  1.7977e+00,  1.7951e+00,
          1.8136e+00,  1.7612e+00,  1.7943e+00,  1.7942e+00,  1.8155e+00,
          1.6991e+00,  1.6872e+00,  1.6846e+00,  1.6803e+00,  1.6934e+00,
          1.6828e+00,  1.7119e+00,  1.6788e+00,  1.6796e+00],
        [ 1.4332e+00,  1.2909e+00,  1.1058e+00,  1.3291e+00,  1.4158e+00,
          1.4750e+00,  1.3944e+00,  1.4739e+00,  1.4739e+00,  1.5587e+00,
          1.7037e+00,  1.5068e+00,  2.1634e+00,  1.5473e+00,  3.2678e+00,
          1.6205e+00,  1.4656e+00,  2.9153e+00,  1.2500e+00,  1.2960e+00,
          1.1239e+00,  1.2827e+00,  1.4464e+00,  1.4819e+00,  1.4372e+00,
          1.4839e+00,  1.4839e+00,  1.3884e+00,  1.2108e+00,  1.5172e+00,
          1.4772e+00,  1.2042e+00,  1.5152e+00,  1.5084e+00,  1.4758e+00,
          1.4909e+00,  1.7149e+00,  1.8396e+00,  1.7582e+00,  1.7081e+00,
          1.7360e+00,  1.8329e+00,  1.7552e+00,  9.3749e-01,  1.7578e+00,
          1.4579e+00,  1.8388e+00,  1.8379e+00,  1.8493e+00,  1.4757e+00,
          1.8394e+00,  1.2335e+00,  1.8428e+00,  1.8485e+00],
        [ 1.3568e+00,  1.3604e+00,  1.3637e+00,  1.3651e+00,  1.3609e+00,
          1.3577e+00,  1.3645e+00,  1.3569e+00,  1.3569e+00,  1.3919e+00,
          1.3928e+00,  1.3897e+00,  1.3895e+00,  1.3928e+00,  1.3249e+00,
          1.3906e+00,  1.3809e+00,  1.3166e+00,  1.9990e+00,  2.0553e+00,
          2.1378e+00,  2.0925e+00,  1.9236e+00,  1.9673e+00,  2.0388e+00,
          1.9194e+00,  1.9194e+00,  1.3896e+00,  1.3541e+00,  1.3918e+00,
          1.3915e+00,  1.3902e+00,  1.3915e+00,  1.3922e+00,  1.3903e+00,
          1.3914e+00,  1.8088e+00,  1.8302e+00,  1.8128e+00,  1.7947e+00,
          1.8289e+00,  1.8292e+00,  1.8094e+00,  1.7135e+00,  1.8110e+00,
          1.6584e+00,  1.6828e+00,  1.6803e+00,  1.6768e+00,  1.6118e+00,
          1.6796e+00,  1.6725e+00,  1.6753e+00,  1.6761e+00],
        [ 1.3762e+00,  1.3775e+00,  1.3044e+00,  1.3062e+00,  1.3792e+00,
          1.3783e+00,  1.3769e+00,  1.3764e+00,  1.3764e+00,  1.4244e+00,
          1.3622e+00,  1.4142e+00,  1.4042e+00,  1.4262e+00,  1.3246e+00,
          1.4224e+00,  1.4249e+00,  1.2353e+00,  1.3903e+00,  1.3723e+00,
          1.3899e+00,  1.3901e+00,  1.3891e+00,  1.3700e+00,  1.3899e+00,
          1.3902e+00,  1.3902e+00,  2.2891e+00,  1.9931e+00,  1.8312e+00,
          1.9269e+00,  2.2650e+00,  1.8367e+00,  2.2389e+00,  1.8406e+00,
          1.8268e+00,  1.8186e+00,  1.8234e+00,  1.7837e+00,  1.7996e+00,
          1.8415e+00,  1.8127e+00,  1.8126e+00,  1.6017e+00,  1.8265e+00,
          1.7182e+00,  1.6842e+00,  1.6087e+00,  1.6557e+00,  1.7173e+00,
          1.6326e+00,  1.7220e+00,  1.6534e+00,  1.7053e+00],
        [ 1.6523e+00,  1.3420e+00,  5.0307e-01,  7.5491e-01,  1.1298e+00,
          1.5429e+00,  1.4762e+00,  1.6521e+00,  1.6521e+00,  1.5636e+00,
          1.2829e+00,  1.3985e+00,  8.7429e-01,  1.6274e+00,  1.1074e-01,
          1.5494e+00,  1.6452e+00,  1.1106e+00,  1.2481e+00,  7.8197e-01,
          6.2456e-01,  1.0212e+00,  1.5064e+00,  1.5947e+00,  1.2859e+00,
          1.6516e+00,  1.6516e+00,  6.5969e-01,  7.2321e-01,  1.6753e+00,
          1.4453e+00,  8.1663e-01,  1.6731e+00,  1.1204e+00,  1.7161e+00,
          1.6602e+00,  7.8672e-01,  3.9480e-01,  3.1546e-01,  7.0057e-01,
          1.2520e+00,  1.5065e+00,  6.1508e-01,  4.1859e+00,  3.7629e+00,
         -5.4530e-03,  3.2592e-01,  3.5722e-01,  4.8072e-01,  1.6478e-01,
          4.8587e-01, -2.7517e-01,  4.8155e-01,  5.6266e-01],
        [ 1.3487e+00,  1.3800e+00,  1.4399e+00,  1.4201e+00,  1.4039e+00,
          1.3625e+00,  1.3305e+00,  1.3486e+00,  1.3486e+00,  1.3655e+00,
          1.4248e+00,  1.3461e+00,  1.4763e+00,  1.4424e+00,  1.4962e+00,
          1.3622e+00,  1.4439e+00,  1.3405e+00,  1.4100e+00,  1.4286e+00,
          1.4241e+00,  1.4146e+00,  1.3881e+00,  1.3710e+00,  1.3474e+00,
          1.3757e+00,  1.3757e+00,  1.4147e+00,  1.4568e+00,  1.3742e+00,
          1.2471e+00,  1.2938e+00,  1.2116e+00,  1.4128e+00,  1.2686e+00,
          1.3747e+00,  2.5346e-01,  2.1896e-01,  3.0796e-01,  2.6456e-01,
          1.1608e-01,  7.6293e-02,  2.7063e-01,  1.4872e-01,  2.5960e-03,
          2.3328e+00,  1.6912e+00,  2.0060e+00,  1.9022e+00,  1.5125e+00,
          1.0712e+00,  2.2663e+00,  1.8065e+00,  1.0412e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 55 : 178.5026927428163
Test loss for epoch 55 : 178.29771261612154
Test Precision for epoch 55 : 0.26153846153846155
Test Recall for epoch 55 : 0.26153846153846155
Test F1 for epoch 55 : 0.26153846153846155


theta for epoch 56 : tensor([[ 1.9564e+00,  1.9909e+00,  2.0422e+00,  2.0788e+00,  2.0620e+00,
          1.9640e+00,  2.0247e+00,  1.9558e+00,  1.9558e+00,  1.3998e+00,
          1.3986e+00,  1.3976e+00,  1.3995e+00,  1.4007e+00,  1.3987e+00,
          1.3985e+00,  1.4002e+00,  1.3547e+00,  1.3710e+00,  1.3314e+00,
          1.3370e+00,  1.3727e+00,  1.3731e+00,  1.3728e+00,  1.3742e+00,
          1.3725e+00,  1.3725e+00,  1.3532e+00,  1.3873e+00,  1.3893e+00,
          1.3894e+00,  1.3885e+00,  1.3893e+00,  1.3901e+00,  1.3499e+00,
          1.3890e+00,  1.7989e+00,  1.8193e+00,  1.8028e+00,  1.8001e+00,
          1.8173e+00,  1.7645e+00,  1.7995e+00,  1.7978e+00,  1.8193e+00,
          1.6992e+00,  1.6883e+00,  1.6856e+00,  1.6825e+00,  1.6939e+00,
          1.6845e+00,  1.7111e+00,  1.6807e+00,  1.6820e+00],
        [ 1.4373e+00,  1.2953e+00,  1.1109e+00,  1.3338e+00,  1.4213e+00,
          1.4791e+00,  1.3983e+00,  1.4782e+00,  1.4782e+00,  1.5696e+00,
          1.7078e+00,  1.5201e+00,  2.1604e+00,  1.5596e+00,  3.2749e+00,
          1.6335e+00,  1.4796e+00,  2.9243e+00,  1.2546e+00,  1.3020e+00,
          1.1352e+00,  1.2874e+00,  1.4511e+00,  1.4872e+00,  1.4426e+00,
          1.4890e+00,  1.4890e+00,  1.3891e+00,  1.2157e+00,  1.5178e+00,
          1.4779e+00,  1.2050e+00,  1.5156e+00,  1.5090e+00,  1.4762e+00,
          1.4924e+00,  1.7344e+00,  1.8533e+00,  1.7741e+00,  1.7256e+00,
          1.7547e+00,  1.8468e+00,  1.7717e+00,  9.6095e-01,  1.7752e+00,
          1.4647e+00,  1.8452e+00,  1.8444e+00,  1.8580e+00,  1.4796e+00,
          1.8473e+00,  1.2428e+00,  1.8510e+00,  1.8577e+00],
        [ 1.3615e+00,  1.3647e+00,  1.3677e+00,  1.3692e+00,  1.3660e+00,
          1.3624e+00,  1.3688e+00,  1.3617e+00,  1.3617e+00,  1.3986e+00,
          1.3993e+00,  1.3967e+00,  1.3967e+00,  1.3992e+00,  1.3320e+00,
          1.3974e+00,  1.3870e+00,  1.3236e+00,  2.0031e+00,  2.0555e+00,
          2.1370e+00,  2.0934e+00,  1.9289e+00,  1.9726e+00,  2.0415e+00,
          1.9251e+00,  1.9251e+00,  1.3905e+00,  1.3544e+00,  1.3929e+00,
          1.3925e+00,  1.3909e+00,  1.3925e+00,  1.3932e+00,  1.3913e+00,
          1.3925e+00,  1.8130e+00,  1.8333e+00,  1.8169e+00,  1.7992e+00,
          1.8316e+00,  1.8316e+00,  1.8135e+00,  1.7171e+00,  1.8159e+00,
          1.6603e+00,  1.6842e+00,  1.6816e+00,  1.6792e+00,  1.6113e+00,
          1.6816e+00,  1.6710e+00,  1.6774e+00,  1.6787e+00],
        [ 1.3808e+00,  1.3819e+00,  1.3096e+00,  1.3111e+00,  1.3835e+00,
          1.3828e+00,  1.3813e+00,  1.3810e+00,  1.3810e+00,  1.4296e+00,
          1.3680e+00,  1.4198e+00,  1.4096e+00,  1.4310e+00,  1.3311e+00,
          1.4277e+00,  1.4298e+00,  1.2424e+00,  1.3964e+00,  1.3788e+00,
          1.3968e+00,  1.3964e+00,  1.3948e+00,  1.3759e+00,  1.3960e+00,
          1.3959e+00,  1.3959e+00,  2.2862e+00,  1.9964e+00,  1.8352e+00,
          1.9297e+00,  2.2631e+00,  1.8409e+00,  2.2371e+00,  1.8445e+00,
          1.8312e+00,  1.8255e+00,  1.8302e+00,  1.7915e+00,  1.8077e+00,
          1.8465e+00,  1.8196e+00,  1.8200e+00,  1.6079e+00,  1.8317e+00,
          1.7199e+00,  1.6879e+00,  1.6115e+00,  1.6595e+00,  1.7191e+00,
          1.6374e+00,  1.7228e+00,  1.6568e+00,  1.7098e+00],
        [ 1.6586e+00,  1.3463e+00,  5.0390e-01,  7.5670e-01,  1.1332e+00,
          1.5485e+00,  1.4820e+00,  1.6584e+00,  1.6584e+00,  1.5736e+00,
          1.2890e+00,  1.4075e+00,  8.7798e-01,  1.6383e+00,  1.1180e-01,
          1.5602e+00,  1.6566e+00,  1.1113e+00,  1.2530e+00,  7.8445e-01,
          6.2334e-01,  1.0249e+00,  1.5115e+00,  1.5997e+00,  1.2900e+00,
          1.6577e+00,  1.6577e+00,  6.5649e-01,  7.1934e-01,  1.6746e+00,
          1.4427e+00,  8.1205e-01,  1.6710e+00,  1.1148e+00,  1.7157e+00,
          1.6584e+00,  7.7695e-01,  3.8439e-01,  3.0565e-01,  6.9131e-01,
          1.2452e+00,  1.5019e+00,  6.0400e-01,  4.2507e+00,  3.8132e+00,
         -3.1617e-03,  3.3049e-01,  3.6244e-01,  4.8908e-01,  1.6964e-01,
          4.9337e-01, -2.7663e-01,  4.8908e-01,  5.7202e-01],
        [ 1.3530e+00,  1.3841e+00,  1.4427e+00,  1.4235e+00,  1.4082e+00,
          1.3674e+00,  1.3345e+00,  1.3530e+00,  1.3530e+00,  1.3691e+00,
          1.4307e+00,  1.3497e+00,  1.4820e+00,  1.4469e+00,  1.5015e+00,
          1.3654e+00,  1.4479e+00,  1.3463e+00,  1.4129e+00,  1.4313e+00,
          1.4271e+00,  1.4172e+00,  1.3907e+00,  1.3735e+00,  1.3491e+00,
          1.3779e+00,  1.3779e+00,  1.4166e+00,  1.4579e+00,  1.3766e+00,
          1.2477e+00,  1.2965e+00,  1.2140e+00,  1.4151e+00,  1.2703e+00,
          1.3771e+00,  2.5202e-01,  2.1793e-01,  3.0731e-01,  2.6284e-01,
          1.1280e-01,  7.2731e-02,  2.6998e-01,  1.3691e-01, -4.9823e-03,
          2.3429e+00,  1.7001e+00,  2.0193e+00,  1.9130e+00,  1.5151e+00,
          1.0777e+00,  2.2742e+00,  1.8185e+00,  1.0477e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 56 : 178.46488406354132
Test loss for epoch 56 : 178.25732240617575
Test Precision for epoch 56 : 0.26153846153846155
Test Recall for epoch 56 : 0.26153846153846155
Test F1 for epoch 56 : 0.26153846153846155


theta for epoch 57 : tensor([[ 1.9630e+00,  1.9962e+00,  2.0464e+00,  2.0845e+00,  2.0675e+00,
          1.9704e+00,  2.0317e+00,  1.9625e+00,  1.9625e+00,  1.4033e+00,
          1.4024e+00,  1.4012e+00,  1.4031e+00,  1.4040e+00,  1.4025e+00,
          1.4020e+00,  1.4035e+00,  1.3584e+00,  1.3776e+00,  1.3380e+00,
          1.3437e+00,  1.3794e+00,  1.3796e+00,  1.3792e+00,  1.3809e+00,
          1.3788e+00,  1.3788e+00,  1.3527e+00,  1.3873e+00,  1.3893e+00,
          1.3892e+00,  1.3883e+00,  1.3892e+00,  1.3899e+00,  1.3495e+00,
          1.3890e+00,  1.8011e+00,  1.8205e+00,  1.8051e+00,  1.8022e+00,
          1.8182e+00,  1.7649e+00,  1.8019e+00,  1.7986e+00,  1.8201e+00,
          1.6984e+00,  1.6883e+00,  1.6856e+00,  1.6834e+00,  1.6935e+00,
          1.6850e+00,  1.7094e+00,  1.6814e+00,  1.6832e+00],
        [ 1.4421e+00,  1.3002e+00,  1.1167e+00,  1.3393e+00,  1.4276e+00,
          1.4839e+00,  1.4029e+00,  1.4831e+00,  1.4831e+00,  1.5808e+00,
          1.7126e+00,  1.5336e+00,  2.1578e+00,  1.5722e+00,  3.2817e+00,
          1.6467e+00,  1.4937e+00,  2.9331e+00,  1.2613e+00,  1.3101e+00,
          1.1478e+00,  1.2940e+00,  1.4577e+00,  1.4945e+00,  1.4500e+00,
          1.4960e+00,  1.4960e+00,  1.3884e+00,  1.2192e+00,  1.5168e+00,
          1.4771e+00,  1.2044e+00,  1.5144e+00,  1.5081e+00,  1.4751e+00,
          1.4924e+00,  1.7508e+00,  1.8639e+00,  1.7869e+00,  1.7399e+00,
          1.7702e+00,  1.8575e+00,  1.7850e+00,  9.8107e-01,  1.7894e+00,
          1.4693e+00,  1.8490e+00,  1.8482e+00,  1.8636e+00,  1.4814e+00,
          1.8523e+00,  1.2503e+00,  1.8561e+00,  1.8636e+00],
        [ 1.3679e+00,  1.3707e+00,  1.3734e+00,  1.3749e+00,  1.3725e+00,
          1.3686e+00,  1.3745e+00,  1.3680e+00,  1.3680e+00,  1.4055e+00,
          1.4060e+00,  1.4040e+00,  1.4041e+00,  1.4058e+00,  1.3397e+00,
          1.4044e+00,  1.3933e+00,  1.3309e+00,  2.0069e+00,  2.0555e+00,
          2.1360e+00,  2.0940e+00,  1.9339e+00,  1.9774e+00,  2.0439e+00,
          1.9303e+00,  1.9303e+00,  1.3909e+00,  1.3543e+00,  1.3934e+00,
          1.3930e+00,  1.3910e+00,  1.3931e+00,  1.3937e+00,  1.3919e+00,
          1.3931e+00,  1.8146e+00,  1.8339e+00,  1.8184e+00,  1.8012e+00,
          1.8318e+00,  1.8317e+00,  1.8152e+00,  1.7183e+00,  1.8181e+00,
          1.6621e+00,  1.6856e+00,  1.6829e+00,  1.6813e+00,  1.6109e+00,
          1.6834e+00,  1.6698e+00,  1.6792e+00,  1.6810e+00],
        [ 1.3860e+00,  1.3869e+00,  1.3154e+00,  1.3167e+00,  1.3884e+00,
          1.3879e+00,  1.3864e+00,  1.3861e+00,  1.3861e+00,  1.4333e+00,
          1.3724e+00,  1.4240e+00,  1.4136e+00,  1.4344e+00,  1.3362e+00,
          1.4316e+00,  1.4333e+00,  1.2479e+00,  1.4040e+00,  1.3869e+00,
          1.4052e+00,  1.4043e+00,  1.4020e+00,  1.3833e+00,  1.4036e+00,
          1.4030e+00,  1.4030e+00,  2.2840e+00,  2.0007e+00,  1.8399e+00,
          1.9334e+00,  2.2619e+00,  1.8458e+00,  2.2360e+00,  1.8492e+00,
          1.8363e+00,  1.8291e+00,  1.8337e+00,  1.7960e+00,  1.8126e+00,
          1.8482e+00,  1.8232e+00,  1.8241e+00,  1.6111e+00,  1.8336e+00,
          1.7206e+00,  1.6901e+00,  1.6126e+00,  1.6618e+00,  1.7198e+00,
          1.6405e+00,  1.7228e+00,  1.6588e+00,  1.7127e+00],
        [ 1.6642e+00,  1.3497e+00,  5.0291e-01,  7.5690e-01,  1.1354e+00,
          1.5535e+00,  1.4870e+00,  1.6642e+00,  1.6642e+00,  1.5807e+00,
          1.2917e+00,  1.4133e+00,  8.7825e-01,  1.6462e+00,  1.0927e-01,
          1.5677e+00,  1.6650e+00,  1.1082e+00,  1.2566e+00,  7.8542e-01,
          6.2073e-01,  1.0273e+00,  1.5158e+00,  1.6040e+00,  1.2930e+00,
          1.6633e+00,  1.6633e+00,  6.4982e-01,  7.1205e-01,  1.6708e+00,
          1.4370e+00,  8.0394e-01,  1.6658e+00,  1.1059e+00,  1.7122e+00,
          1.6535e+00,  7.6913e-01,  3.7585e-01,  2.9776e-01,  6.8399e-01,
          1.2403e+00,  1.4991e+00,  5.9483e-01,  4.3179e+00,  3.8655e+00,
         -4.2977e-03,  3.3166e-01,  3.6404e-01,  4.9343e-01,  1.7100e-01,
          4.9705e-01, -2.8115e-01,  4.9282e-01,  5.7756e-01],
        [ 1.3611e+00,  1.3920e+00,  1.4491e+00,  1.4306e+00,  1.4160e+00,
          1.3759e+00,  1.3424e+00,  1.3611e+00,  1.3611e+00,  1.3752e+00,
          1.4390e+00,  1.3562e+00,  1.4902e+00,  1.4535e+00,  1.5097e+00,
          1.3712e+00,  1.4540e+00,  1.3552e+00,  1.4222e+00,  1.4407e+00,
          1.4368e+00,  1.4264e+00,  1.3997e+00,  1.3823e+00,  1.3575e+00,
          1.3864e+00,  1.3864e+00,  1.4206e+00,  1.4608e+00,  1.3811e+00,
          1.2504e+00,  1.3016e+00,  1.2186e+00,  1.4194e+00,  1.2742e+00,
          1.3815e+00,  2.5576e-01,  2.2135e-01,  3.1162e-01,  2.6628e-01,
          1.1429e-01,  7.3834e-02,  2.7437e-01,  1.3159e-01, -7.6107e-03,
          2.3466e+00,  1.7026e+00,  2.0262e+00,  1.9173e+00,  1.5116e+00,
          1.0782e+00,  2.2757e+00,  1.8242e+00,  1.0484e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 57 : 178.44155835411382
Test loss for epoch 57 : 178.23612482494815
Test Precision for epoch 57 : 0.26153846153846155
Test Recall for epoch 57 : 0.26153846153846155
Test F1 for epoch 57 : 0.26153846153846155


theta for epoch 58 : tensor([[ 1.9700,  2.0018,  2.0510,  2.0906,  2.0734,  1.9771,  2.0391,  1.9695,
          1.9695,  1.4036,  1.4029,  1.4018,  1.4037,  1.4041,  1.4032,  1.4024,
          1.4036,  1.3590,  1.3828,  1.3433,  1.3490,  1.3848,  1.3847,  1.3842,
          1.3862,  1.3839,  1.3839,  1.3549,  1.3901,  1.3919,  1.3918,  1.3909,
          1.3918,  1.3923,  1.3519,  1.3916,  1.8003,  1.8187,  1.8041,  1.8012,
          1.8159,  1.7622,  1.8012,  1.7963,  1.8178,  1.6993,  1.6899,  1.6871,
          1.6858,  1.6947,  1.6870,  1.7096,  1.6835,  1.6857],
        [ 1.4461,  1.3043,  1.1219,  1.3443,  1.4331,  1.4880,  1.4068,  1.4873,
          1.4873,  1.5910,  1.7165,  1.5457,  2.1541,  1.5837,  3.2870,  1.6587,
          1.5063,  2.9407,  1.2666,  1.3166,  1.1585,  1.2991,  1.4628,  1.5001,
          1.4557,  1.5013,  1.5013,  1.3904,  1.2254,  1.5185,  1.4790,  1.2064,
          1.5160,  1.5100,  1.4767,  1.4951,  1.7637,  1.8709,  1.7961,  1.7506,
          1.7821,  1.8647,  1.7947,  0.9975,  1.7999,  1.4748,  1.8531,  1.8523,
          1.8688,  1.4838,  1.8573,  1.2588,  1.8611,  1.8692],
        [ 1.3739,  1.3764,  1.3789,  1.3803,  1.3787,  1.3746,  1.3799,  1.3740,
          1.3740,  1.4092,  1.4095,  1.4082,  1.4084,  1.4092,  1.3445,  1.4082,
          1.3964,  1.3349,  2.0104,  2.0551,  2.1348,  2.0944,  1.9383,  1.9815,
          2.0458,  1.9348,  1.9348,  1.3944,  1.3574,  1.3972,  1.3967,  1.3943,
          1.3968,  1.3975,  1.3957,  1.3968,  1.8134,  1.8316,  1.8171,  1.8002,
          1.8291,  1.8288,  1.8140,  1.7165,  1.8172,  1.6659,  1.6890,  1.6861,
          1.6852,  1.6126,  1.6871,  1.6709,  1.6830,  1.6852],
        [ 1.3899,  1.3907,  1.3201,  1.3210,  1.3920,  1.3916,  1.3901,  1.3900,
          1.3900,  1.4323,  1.3720,  1.4236,  1.4128,  1.4331,  1.3363,  1.4307,
          1.4320,  1.2486,  1.4090,  1.3923,  1.4109,  1.4095,  1.4066,  1.3881,
          1.4086,  1.4075,  1.4075,  2.2869,  2.0102,  1.8497,  1.9422,  2.2658,
          1.8559,  2.2400,  1.8591,  1.8466,  1.8288,  1.8333,  1.7966,  1.8135,
          1.8461,  1.8229,  1.8243,  1.6106,  1.8317,  1.7219,  1.6927,  1.6138,
          1.6641,  1.7212,  1.6438,  1.7237,  1.6609,  1.7158],
        [ 1.6731,  1.3573,  0.5078,  0.7622,  1.1424,  1.5620,  1.4958,  1.6731,
          1.6731,  1.5898,  1.2976,  1.4214,  0.8828,  1.6559,  0.1130,  1.5771,
          1.6750,  1.1085,  1.2650,  0.7926,  0.6255,  1.0356,  1.5246,  1.6123,
          1.3007,  1.6726,  1.6726,  0.6529,  0.7146,  1.6747,  1.4398,  0.8057,
          1.6685,  1.1062,  1.7164,  1.6564,  0.7543,  0.3610,  0.2838,  0.6698,
          1.2276,  1.4881,  0.5790,  4.3788,  3.9105,  0.0067,  0.3440,  0.3772,
          0.5090,  0.1840,  0.5120, -0.2734,  0.5079,  0.5942],
        [ 1.3650,  1.3957,  1.4516,  1.4337,  1.4196,  1.3801,  1.3459,  1.3650,
          1.3650,  1.3710,  1.4370,  1.3524,  1.4883,  1.4498,  1.5076,  1.3666,
          1.4500,  1.3535,  1.4241,  1.4428,  1.4392,  1.4283,  1.4011,  1.3835,
          1.3582,  1.3873,  1.3873,  1.4231,  1.4622,  1.3839,  1.2511,  1.3048,
          1.2212,  1.4223,  1.2760,  1.3843,  0.2526,  0.2172,  0.3091,  0.2628,
          0.1081,  0.0671,  0.2718,  0.1204, -0.0178,  2.3598,  1.7147,  2.0426,
          1.9311,  1.5176,  1.0880,  2.2867,  1.8395,  1.0582]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 58 : 178.411923634401
Test loss for epoch 58 : 178.1985938776562
Test Precision for epoch 58 : 0.26153846153846155
Test Recall for epoch 58 : 0.26153846153846155
Test F1 for epoch 58 : 0.26153846153846155


theta for epoch 59 : tensor([[ 1.9755,  2.0061,  2.0542,  2.0953,  2.0779,  1.9824,  2.0451,  1.9751,
          1.9751,  1.4033,  1.4029,  1.4018,  1.4037,  1.4035,  1.4033,  1.4021,
          1.4031,  1.3591,  1.3858,  1.3463,  1.3519,  1.3879,  1.3875,  1.3870,
          1.3892,  1.3865,  1.3865,  1.3601,  1.3959,  1.3975,  1.3973,  1.3965,
          1.3973,  1.3977,  1.3571,  1.3972,  1.7989,  1.8163,  1.8027,  1.7997,
          1.8132,  1.7591,  1.7999,  1.7937,  1.8150,  1.6996,  1.6906,  1.6878,
          1.6871,  1.6953,  1.6881,  1.7091,  1.6847,  1.6871],
        [ 1.4481,  1.3062,  1.1252,  1.3473,  1.4367,  1.4900,  1.4086,  1.4895,
          1.4895,  1.6009,  1.7203,  1.5572,  2.1502,  1.5947,  3.2915,  1.6702,
          1.5183,  2.9475,  1.2689,  1.3201,  1.1657,  1.3011,  1.4648,  1.5025,
          1.4583,  1.5035,  1.5035,  1.3954,  1.2343,  1.5228,  1.4837,  1.2112,
          1.5203,  1.5146,  1.4811,  1.5005,  1.7753,  1.8770,  1.8043,  1.7601,
          1.7929,  1.8708,  1.8032,  1.0125,  1.8092,  1.4780,  1.8545,  1.8537,
          1.8708,  1.4841,  1.8593,  1.2654,  1.8630,  1.8716],
        [ 1.3778,  1.3800,  1.3822,  1.3836,  1.3826,  1.3785,  1.3831,  1.3779,
          1.3779,  1.4115,  1.4117,  1.4110,  1.4113,  1.4112,  1.3482,  1.4106,
          1.3982,  1.3376,  2.0138,  2.0548,  2.1338,  2.0947,  1.9424,  1.9854,
          2.0476,  1.9391,  1.9391,  1.4008,  1.3634,  1.4037,  1.4032,  1.4004,
          1.4033,  1.4040,  1.4022,  1.4033,  1.8114,  1.8286,  1.8150,  1.7986,
          1.8257,  1.8253,  1.8121,  1.7141,  1.8155,  1.6685,  1.6911,  1.6882,
          1.6878,  1.6131,  1.6895,  1.6711,  1.6854,  1.6879],
        [ 1.3915,  1.3922,  1.3225,  1.3231,  1.3934,  1.3932,  1.3917,  1.3917,
          1.3917,  1.4296,  1.3698,  1.4215,  1.4103,  1.4299,  1.3346,  1.4281,
          1.4289,  1.2475,  1.4107,  1.3944,  1.4131,  1.4113,  1.4079,  1.3896,
          1.4102,  1.4086,  1.4086,  2.2934,  2.0234,  1.8632,  1.9547,  2.2733,
          1.8695,  2.2475,  1.8726,  1.8604,  1.8275,  1.8318,  1.7961,  1.8133,
          1.8430,  1.8215,  1.8234,  1.6094,  1.8289,  1.7218,  1.6936,  1.6131,
          1.6644,  1.7210,  1.6450,  1.7234,  1.6611,  1.7169],
        [ 1.6764,  1.3585,  0.5049,  0.7604,  1.1424,  1.5647,  1.4984,  1.6765,
          1.6765,  1.5924,  1.2959,  1.4226,  0.8793,  1.6592,  0.1076,  1.5798,
          1.6788,  1.1007,  1.2662,  0.7918,  0.6218,  1.0361,  1.5266,  1.6141,
          1.3016,  1.6757,  1.6757,  0.6499,  0.7114,  1.6761,  1.4392,  0.8017,
          1.6685,  1.1020,  1.7182,  1.6566,  0.7468,  0.3530,  0.2766,  0.6627,
          1.2224,  1.4847,  0.5702,  4.4464,  3.9624,  0.0063,  0.3454,  0.3789,
          0.5125,  0.1857,  0.5151, -0.2766,  0.5112,  0.5989],
        [ 1.3736,  1.4041,  1.4586,  1.4414,  1.4277,  1.3889,  1.3543,  1.3736,
          1.3736,  1.3752,  1.4433,  1.3577,  1.4946,  1.4539,  1.5141,  1.3707,
          1.4537,  1.3609,  1.4345,  1.4534,  1.4503,  1.4388,  1.4111,  1.3935,
          1.3680,  1.3969,  1.3969,  1.4350,  1.4728,  1.3961,  1.2617,  1.3178,
          1.2336,  1.4345,  1.2876,  1.3965,  0.2621,  0.2251,  0.3188,  0.2720,
          0.1147,  0.0731,  0.2817,  0.1237, -0.0148,  2.3581,  1.7119,  2.0440,
          1.9300,  1.5094,  1.0839,  2.2827,  1.8399,  1.0542]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 59 : 178.37653849487364
Test loss for epoch 59 : 178.16840439279989
Test Precision for epoch 59 : 0.26153846153846155
Test Recall for epoch 59 : 0.26153846153846155
Test F1 for epoch 59 : 0.26153846153846155


theta for epoch 60 : tensor([[ 1.9787,  2.0080,  2.0552,  2.0976,  2.0800,  1.9853,  2.0487,  1.9783,
          1.9783,  1.4048,  1.4047,  1.4036,  1.4056,  1.4048,  1.4054,  1.4037,
          1.4044,  1.3610,  1.3871,  1.3476,  1.3529,  1.3893,  1.3885,  1.3879,
          1.3903,  1.3874,  1.3874,  1.3655,  1.4020,  1.4032,  1.4031,  1.4024,
          1.4030,  1.4034,  1.3626,  1.4029,  1.7973,  1.8137,  1.8010,  1.7979,
          1.8102,  1.7557,  1.7983,  1.7910,  1.8120,  1.7026,  1.6939,  1.6910,
          1.6906,  1.6985,  1.6915,  1.7114,  1.6882,  1.6909],
        [ 1.4480,  1.3060,  1.1267,  1.3483,  1.4383,  1.4900,  1.4084,  1.4896,
          1.4896,  1.6106,  1.7243,  1.5683,  2.1464,  1.6056,  3.2953,  1.6814,
          1.5298,  2.9539,  1.2688,  1.3209,  1.1700,  1.3005,  1.4641,  1.5022,
          1.4581,  1.5029,  1.5029,  1.4001,  1.2428,  1.5268,  1.4879,  1.2158,
          1.5243,  1.5190,  1.4850,  1.5055,  1.7858,  1.8821,  1.8113,  1.7685,
          1.8027,  1.8760,  1.8107,  1.0263,  1.8174,  1.4829,  1.8569,  1.8560,
          1.8732,  1.4860,  1.8619,  1.2740,  1.8655,  1.8743],
        [ 1.3791,  1.3810,  1.3831,  1.3843,  1.3839,  1.3798,  1.3837,  1.3792,
          1.3792,  1.4144,  1.4145,  1.4143,  1.4148,  1.4137,  1.3526,  1.4136,
          1.4007,  1.3408,  2.0175,  2.0550,  2.1333,  2.0955,  1.9467,  1.9895,
          2.0497,  1.9435,  1.9435,  1.4064,  1.3687,  1.4095,  1.4091,  1.4059,
          1.4092,  1.4100,  1.4081,  1.4092,  1.8088,  1.8250,  1.8123,  1.7963,
          1.8218,  1.8212,  1.8095,  1.7111,  1.8130,  1.6727,  1.6950,  1.6919,
          1.6918,  1.6155,  1.6935,  1.6732,  1.6893,  1.6920],
        [ 1.3919,  1.3925,  1.3239,  1.3242,  1.3936,  1.3935,  1.3920,  1.3921,
          1.3921,  1.4293,  1.3702,  1.4220,  1.4102,  1.4292,  1.3355,  1.4279,
          1.4283,  1.2491,  1.4111,  1.3954,  1.4141,  1.4120,  1.4081,  1.3900,
          1.4106,  1.4086,  1.4086,  2.2970,  2.0338,  1.8736,  1.9642,  2.2779,
          1.8802,  2.2522,  1.8831,  1.8712,  1.8259,  1.8300,  1.7953,  1.8129,
          1.8396,  1.8198,  1.8221,  1.6083,  1.8258,  1.7245,  1.6969,  1.6147,
          1.6670,  1.7235,  1.6485,  1.7260,  1.6636,  1.7202],
        [ 1.6818,  1.3628,  0.5075,  0.7633,  1.1463,  1.5699,  1.5037,  1.6819,
          1.6819,  1.6000,  1.3003,  1.4288,  0.8828,  1.6673,  0.1107,  1.5872,
          1.6870,  1.0993,  1.2720,  0.7972,  0.6256,  1.0424,  1.5327,  1.6196,
          1.3070,  1.6823,  1.6823,  0.6551,  0.7163,  1.6821,  1.4444,  0.8056,
          1.6733,  1.1048,  1.7245,  1.6615,  0.7325,  0.3389,  0.2636,  0.6490,
          1.2096,  1.4732,  0.5549,  4.5078,  4.0069,  0.0187,  0.3588,  0.3930,
          0.5279,  0.1997,  0.5303, -0.2667,  0.5265,  0.6154],
        [ 1.3735,  1.4040,  1.4574,  1.4408,  1.4273,  1.3891,  1.3539,  1.3736,
          1.3736,  1.3687,  1.4391,  1.3521,  1.4905,  1.4476,  1.5104,  1.3640,
          1.4471,  1.3573,  1.4317,  1.4510,  1.4483,  1.4362,  1.4079,  1.3902,
          1.3643,  1.3932,  1.3932,  1.4393,  1.4760,  1.4003,  1.2639,  1.3228,
          1.2375,  1.4392,  1.2907,  1.4008,  0.2618,  0.2227,  0.3188,  0.2714,
          0.1106,  0.0682,  0.2818,  0.1181, -0.0224,  2.3716,  1.7244,  2.0607,
          1.9440,  1.5164,  1.0944,  2.2940,  1.8555,  1.0647]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 60 : 178.33950044882653
Test loss for epoch 60 : 178.12413034616955
Test Precision for epoch 60 : 0.26153846153846155
Test Recall for epoch 60 : 0.26153846153846155
Test F1 for epoch 60 : 0.26153846153846155


theta for epoch 61 : tensor([[ 1.9811,  2.0092,  2.0555,  2.0993,  2.0815,  1.9874,  2.0515,  1.9807,
          1.9807,  1.4086,  1.4087,  1.4077,  1.4097,  1.4082,  1.4098,  1.4076,
          1.4079,  1.3652,  1.3891,  1.3497,  1.3547,  1.3914,  1.3902,  1.3896,
          1.3922,  1.3891,  1.3891,  1.3677,  1.4050,  1.4057,  1.4057,  1.4052,
          1.4056,  1.4059,  1.3648,  1.4054,  1.7969,  1.8123,  1.8005,  1.7974,
          1.8085,  1.7536,  1.7980,  1.7895,  1.8102,  1.7034,  1.6949,  1.6919,
          1.6917,  1.6996,  1.6926,  1.7117,  1.6893,  1.6921],
        [ 1.4474,  1.3053,  1.1279,  1.3490,  1.4394,  1.4895,  1.4077,  1.4892,
          1.4892,  1.6201,  1.7283,  1.5790,  2.1424,  1.6162,  3.2984,  1.6923,
          1.5409,  2.9596,  1.2697,  1.3226,  1.1748,  1.3008,  1.4643,  1.5026,
          1.4587,  1.5031,  1.5031,  1.4016,  1.2481,  1.5273,  1.4889,  1.2173,
          1.5250,  1.5200,  1.4857,  1.5071,  1.7969,  1.8878,  1.8191,  1.7775,
          1.8130,  1.8819,  1.8187,  1.0404,  1.8262,  1.4848,  1.8557,  1.8546,
          1.8715,  1.4851,  1.8607,  1.2798,  1.8640,  1.8729],
        [ 1.3792,  1.3808,  1.3828,  1.3838,  1.3839,  1.3798,  1.3831,  1.3793,
          1.3793,  1.4184,  1.4185,  1.4188,  1.4194,  1.4174,  1.3581,  1.4178,
          1.4043,  1.3451,  2.0240,  2.0580,  2.1357,  2.0991,  1.9537,  1.9961,
          2.0545,  1.9506,  1.9506,  1.4080,  1.3700,  1.4112,  1.4110,  1.4073,
          1.4110,  1.4119,  1.4099,  1.4109,  1.8070,  1.8222,  1.8105,  1.7948,
          1.8187,  1.8179,  1.8078,  1.7088,  1.8112,  1.6738,  1.6958,  1.6926,
          1.6926,  1.6149,  1.6943,  1.6727,  1.6901,  1.6930],
        [ 1.3931,  1.3937,  1.3262,  1.3261,  1.3946,  1.3945,  1.3931,  1.3933,
          1.3933,  1.4335,  1.3753,  1.4270,  1.4146,  1.4330,  1.3410,  1.4323,
          1.4322,  1.2554,  1.4143,  1.3991,  1.4178,  1.4154,  1.4110,  1.3932,
          1.4138,  1.4114,  1.4114,  2.2938,  2.0372,  1.8770,  1.9668,  2.2756,
          1.8838,  2.2499,  1.8865,  1.8750,  1.8261,  1.8301,  1.7963,  1.8142,
          1.8382,  1.8200,  1.8226,  1.6095,  1.8247,  1.7263,  1.6991,  1.6152,
          1.6683,  1.7252,  1.6507,  1.7279,  1.6650,  1.7222],
        [ 1.6831,  1.3623,  0.5038,  0.7604,  1.1447,  1.5707,  1.5045,  1.6832,
          1.6832,  1.6033,  1.2995,  1.4304,  0.8803,  1.6713,  0.1067,  1.5902,
          1.6913,  1.0921,  1.2728,  0.7967,  0.6229,  1.0431,  1.5343,  1.6208,
          1.3076,  1.6849,  1.6849,  0.6507,  0.7117,  1.6796,  1.4409,  0.7997,
          1.6696,  1.0986,  1.7225,  1.6579,  0.7250,  0.3313,  0.2570,  0.6421,
          1.2039,  1.4689,  0.5463,  4.5755,  4.0581,  0.0203,  0.3617,  0.3962,
          0.5317,  0.2029,  0.5341, -0.2669,  0.5306,  0.6204],
        [ 1.3768,  1.4072,  1.4595,  1.4435,  1.4301,  1.3925,  1.3570,  1.3770,
          1.3770,  1.3694,  1.4421,  1.3542,  1.4938,  1.4480,  1.5143,  1.3647,
          1.4473,  1.3614,  1.4359,  1.4556,  1.4533,  1.4407,  1.4117,  1.3940,
          1.3679,  1.3966,  1.3966,  1.4444,  1.4800,  1.4052,  1.2673,  1.3291,
          1.2426,  1.4446,  1.2948,  1.4057,  0.2707,  0.2292,  0.3279,  0.2800,
          0.1158,  0.0726,  0.2910,  0.1233, -0.0203,  2.3755,  1.7274,  2.0678,
          1.9485,  1.5141,  1.0959,  2.2958,  1.8617,  1.0663]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 61 : 178.29370735113284
Test loss for epoch 61 : 178.08153841931784
Test Precision for epoch 61 : 0.26153846153846155
Test Recall for epoch 61 : 0.26153846153846155
Test F1 for epoch 61 : 0.26153846153846155


theta for epoch 62 : tensor([[ 1.9846,  2.0115,  2.0570,  2.1020,  2.0841,  1.9907,  2.0554,  1.9843,
          1.9843,  1.4116,  1.4120,  1.4111,  1.4132,  1.4110,  1.4135,  1.4107,
          1.4107,  1.3686,  1.3901,  1.3507,  1.3553,  1.3924,  1.3909,  1.3902,
          1.3930,  1.3896,  1.3896,  1.3676,  1.4057,  1.4058,  1.4059,  1.4057,
          1.4058,  1.4061,  1.3647,  1.4056,  1.7966,  1.8111,  1.8003,  1.7970,
          1.8070,  1.7517,  1.7978,  1.7884,  1.8086,  1.7028,  1.6942,  1.6911,
          1.6910,  1.6991,  1.6919,  1.7106,  1.6886,  1.6915],
        [ 1.4476,  1.3054,  1.1301,  1.3506,  1.4413,  1.4899,  1.4078,  1.4896,
          1.4896,  1.6280,  1.7311,  1.5880,  2.1371,  1.6251,  3.2996,  1.7013,
          1.5501,  2.9636,  1.2709,  1.3245,  1.1794,  1.3012,  1.4644,  1.5027,
          1.4591,  1.5030,  1.5030,  1.4011,  1.2514,  1.5258,  1.4879,  1.2170,
          1.5236,  1.5191,  1.4843,  1.5067,  1.8078,  1.8936,  1.8267,  1.7863,
          1.8231,  1.8878,  1.8266,  1.0542,  1.8348,  1.4853,  1.8522,  1.8510,
          1.8673,  1.4826,  1.8571,  1.2845,  1.8600,  1.8688],
        [ 1.3794,  1.3808,  1.3827,  1.3835,  1.3839,  1.3800,  1.3825,  1.3795,
          1.3795,  1.4211,  1.4213,  1.4221,  1.4228,  1.4199,  1.3625,  1.4206,
          1.4068,  1.3481,  2.0324,  2.0629,  2.1400,  2.1047,  1.9623,  2.0044,
          2.0611,  1.9592,  1.9592,  1.4069,  1.3687,  1.4103,  1.4102,  1.4061,
          1.4102,  1.4111,  1.4090,  1.4100,  1.8054,  1.8196,  1.8088,  1.7935,
          1.8158,  1.8149,  1.8062,  1.7067,  1.8095,  1.6732,  1.6948,  1.6914,
          1.6914,  1.6126,  1.6932,  1.6707,  1.6889,  1.6919],
        [ 1.3955,  1.3960,  1.3299,  1.3295,  1.3969,  1.3968,  1.3954,  1.3957,
          1.3957,  1.4384,  1.3812,  1.4328,  1.4199,  1.4375,  1.3473,  1.4373,
          1.4368,  1.2627,  1.4181,  1.4034,  1.4219,  1.4193,  1.4145,  1.3970,
          1.4175,  1.4147,  1.4147,  2.2871,  2.0370,  1.8767,  1.9657,  2.2697,
          1.8836,  2.2440,  1.8863,  1.8750,  1.8269,  1.8307,  1.7979,  1.8160,
          1.8374,  1.8207,  1.8236,  1.6118,  1.8243,  1.7276,  1.7006,  1.6149,
          1.6687,  1.7262,  1.6520,  1.7295,  1.6654,  1.7232],
        [ 1.6866,  1.3645,  0.5036,  0.7606,  1.1461,  1.5739,  1.5076,  1.6867,
          1.6867,  1.6079,  1.3006,  1.4334,  0.8803,  1.6764,  0.1061,  1.5943,
          1.6965,  1.0870,  1.2759,  0.7994,  0.6241,  1.0467,  1.5382,  1.6241,
          1.3107,  1.6894,  1.6894,  0.6488,  0.7094,  1.6772,  1.4382,  0.7961,
          1.6661,  1.0941,  1.7205,  1.6544,  0.7149,  0.3215,  0.2483,  0.6326,
          1.1950,  1.4609,  0.5352,  4.6408,  4.1061,  0.0266,  0.3687,  0.4034,
          0.5390,  0.2103,  0.5415, -0.2621,  0.5384,  0.6287],
        [ 1.3778,  1.4083,  1.4595,  1.4441,  1.4306,  1.3936,  1.3577,  1.3780,
          1.3780,  1.3644,  1.4395,  1.3507,  1.4917,  1.4429,  1.5129,  1.3598,
          1.4420,  1.3598,  1.4351,  1.4552,  1.4535,  1.4403,  1.4105,  1.3927,
          1.3664,  1.3950,  1.3950,  1.4445,  1.4791,  1.4047,  1.2652,  1.3303,
          1.2423,  1.4449,  1.2934,  1.4054,  0.2764,  0.2321,  0.3338,  0.2854,
          0.1174,  0.0733,  0.2969,  0.1263, -0.0216,  2.3852,  1.7361,  2.0807,
          1.9587,  1.5176,  1.1029,  2.3033,  1.8736,  1.0733]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 62 : 178.2558285282176
Test loss for epoch 62 : 178.04206040459596
Test Precision for epoch 62 : 0.26153846153846155
Test Recall for epoch 62 : 0.26153846153846155
Test F1 for epoch 62 : 0.26153846153846155


theta for epoch 63 : tensor([[ 1.9899,  2.0157,  2.0603,  2.1066,  2.0885,  1.9958,  2.0611,  1.9896,
          1.9896,  1.4121,  1.4128,  1.4120,  1.4141,  1.4112,  1.4147,  1.4113,
          1.4109,  1.3695,  1.3880,  1.3486,  1.3527,  1.3904,  1.3885,  1.3877,
          1.3906,  1.3871,  1.3871,  1.3679,  1.4067,  1.4063,  1.4066,  1.4065,
          1.4064,  1.4067,  1.3649,  1.4061,  1.7959,  1.8095,  1.7995,  1.7962,
          1.8052,  1.7495,  1.7971,  1.7869,  1.8066,  1.6999,  1.6912,  1.6880,
          1.6878,  1.6963,  1.6888,  1.7073,  1.6855,  1.6884],
        [ 1.4483,  1.3061,  1.1330,  1.3529,  1.4439,  1.4908,  1.4084,  1.4906,
          1.4906,  1.6343,  1.7326,  1.5951,  2.1304,  1.6323,  3.2989,  1.7086,
          1.5574,  2.9658,  1.2702,  1.3243,  1.1818,  1.2996,  1.4625,  1.5007,
          1.4573,  1.5008,  1.5008,  1.4018,  1.2556,  1.5253,  1.4880,  1.2179,
          1.5234,  1.5193,  1.4840,  1.5074,  1.8179,  1.8987,  1.8335,  1.7942,
          1.8325,  1.8930,  1.8337,  1.0671,  1.8426,  1.4835,  1.8459,  1.8445,
          1.8599,  1.4782,  1.8504,  1.2870,  1.8529,  1.8616],
        [ 1.3800,  1.3813,  1.3831,  1.3837,  1.3844,  1.3806,  1.3824,  1.3801,
          1.3801,  1.4215,  1.4218,  1.4229,  1.4237,  1.4200,  1.3648,  1.4212,
          1.4069,  1.3486,  2.0404,  2.0677,  2.1443,  2.1100,  1.9705,  2.0123,
          2.0674,  1.9674,  1.9674,  1.4068,  1.3683,  1.4102,  1.4103,  1.4057,
          1.4102,  1.4112,  1.4089,  1.4099,  1.8035,  1.8169,  1.8069,  1.7920,
          1.8129,  1.8118,  1.8044,  1.7045,  1.8074,  1.6706,  1.6919,  1.6884,
          1.6882,  1.6086,  1.6902,  1.6670,  1.6858,  1.6887],
        [ 1.3979,  1.3984,  1.3337,  1.3329,  1.3991,  1.3990,  1.3977,  1.3980,
          1.3980,  1.4403,  1.3842,  1.4357,  1.4222,  1.4391,  1.3504,  1.4395,
          1.4385,  1.2670,  1.4186,  1.4045,  1.4228,  1.4200,  1.4149,  1.3978,
          1.4181,  1.4149,  1.4149,  2.2830,  2.0396,  1.8790,  1.9673,  2.2665,
          1.8862,  2.2408,  1.8887,  1.8776,  1.8270,  1.8308,  1.7987,  1.8171,
          1.8361,  1.8207,  1.8238,  1.6137,  1.8233,  1.7265,  1.6995,  1.6120,
          1.6663,  1.7249,  1.6507,  1.7289,  1.6631,  1.7214],
        [ 1.6914,  1.3682,  0.5054,  0.7627,  1.1494,  1.5786,  1.5122,  1.6915,
          1.6915,  1.6118,  1.3014,  1.4358,  0.8806,  1.6809,  0.1066,  1.5977,
          1.7011,  1.0820,  1.2794,  0.8029,  0.6266,  1.0510,  1.5422,  1.6273,
          1.3141,  1.6938,  1.6938,  0.6497,  0.7103,  1.6773,  1.4383,  0.7954,
          1.6650,  1.0926,  1.7210,  1.6534,  0.7035,  0.3106,  0.2386,  0.6217,
          1.1842,  1.4510,  0.5229,  4.7050,  4.1524,  0.0345,  0.3768,  0.4117,
          0.5468,  0.2190,  0.5495, -0.2550,  0.5468,  0.6373],
        [ 1.3791,  1.4095,  1.4599,  1.4450,  1.4314,  1.3948,  1.3586,  1.3792,
          1.3792,  1.3569,  1.4344,  1.3448,  1.4868,  1.4350,  1.5088,  1.3524,
          1.4340,  1.3556,  1.4320,  1.4526,  1.4514,  1.4377,  1.4070,  1.3893,
          1.3627,  1.3912,  1.3912,  1.4450,  1.4788,  1.4047,  1.2637,  1.3319,
          1.2425,  1.4457,  1.2924,  1.4055,  0.2823,  0.2350,  0.3398,  0.2911,
          0.1191,  0.0742,  0.3031,  0.1307, -0.0222,  2.3950,  1.7449,  2.0938,
          1.9690,  1.5214,  1.1100,  2.3110,  1.8858,  1.0804]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 63 : 178.2261399924704
Test loss for epoch 63 : 178.0097606906239
Test Precision for epoch 63 : 0.26153846153846155
Test Recall for epoch 63 : 0.26153846153846155
Test F1 for epoch 63 : 0.26153846153846155


theta for epoch 64 : tensor([[ 1.9956,  2.0203,  2.0641,  2.1116,  2.0934,  2.0013,  2.0672,  1.9953,
          1.9953,  1.4113,  1.4123,  1.4117,  1.4138,  1.4102,  1.4147,  1.4107,
          1.4100,  1.3691,  1.3842,  1.3447,  1.3482,  1.3864,  1.3842,  1.3834,
          1.3864,  1.3828,  1.3828,  1.3694,  1.4091,  1.4081,  1.4085,  1.4087,
          1.4083,  1.4086,  1.3664,  1.4079,  1.7944,  1.8071,  1.7979,  1.7946,
          1.8025,  1.7464,  1.7957,  1.7847,  1.8038,  1.6956,  1.6866,  1.6834,
          1.6829,  1.6921,  1.6840,  1.7027,  1.6807,  1.6836],
        [ 1.4481,  1.3059,  1.1350,  1.3543,  1.4456,  1.4907,  1.4082,  1.4906,
          1.4906,  1.6405,  1.7342,  1.6018,  2.1239,  1.6394,  3.2977,  1.7156,
          1.5643,  2.9676,  1.2679,  1.3224,  1.1822,  1.2963,  1.4590,  1.4970,
          1.4537,  1.4969,  1.4969,  1.4041,  1.2612,  1.5263,  1.4896,  1.2205,
          1.5247,  1.5210,  1.4853,  1.5095,  1.8265,  1.9026,  1.8391,  1.8008,
          1.8405,  1.8971,  1.8395,  1.0784,  1.8491,  1.4799,  1.8373,  1.8358,
          1.8498,  1.4720,  1.8412,  1.2878,  1.8433,  1.8516],
        [ 1.3802,  1.3813,  1.3831,  1.3835,  1.3843,  1.3808,  1.3818,  1.3803,
          1.3803,  1.4214,  1.4217,  1.4232,  1.4241,  1.4196,  1.3664,  1.4211,
          1.4066,  1.3487,  2.0470,  2.0712,  2.1474,  2.1140,  1.9771,  2.0186,
          2.0722,  1.9739,  1.9739,  1.4086,  1.3700,  1.4121,  1.4124,  1.4075,
          1.4122,  1.4134,  1.4109,  1.4119,  1.8012,  1.8137,  1.8046,  1.7900,
          1.8095,  1.8083,  1.8021,  1.7018,  1.8048,  1.6671,  1.6880,  1.6845,
          1.6839,  1.6039,  1.6861,  1.6628,  1.6816,  1.6845],
        [ 1.3984,  1.3989,  1.3356,  1.3345,  1.3995,  1.3994,  1.3981,  1.3985,
          1.3985,  1.4396,  1.3846,  1.4359,  1.4218,  1.4379,  1.3506,  1.4389,
          1.4375,  1.2685,  1.4158,  1.4023,  1.4202,  1.4174,  1.4119,  1.3953,
          1.4153,  1.4118,  1.4118,  2.2840,  2.0473,  1.8863,  1.9740,  2.2683,
          1.8937,  2.2427,  1.8962,  1.8853,  1.8256,  1.8293,  1.7980,  1.8168,
          1.8333,  1.8193,  1.8226,  1.6144,  1.8210,  1.7231,  1.6958,  1.6064,
          1.6611,  1.7211,  1.6467,  1.7260,  1.6581,  1.7169],
        [ 1.6941,  1.3695,  0.5043,  0.7620,  1.1499,  1.5810,  1.5145,  1.6942,
          1.6942,  1.6127,  1.2988,  1.4351,  0.8773,  1.6823,  0.1033,  1.5978,
          1.7025,  1.0734,  1.2797,  0.8031,  0.6257,  1.0521,  1.5432,  1.6277,
          1.3147,  1.6954,  1.6954,  0.6491,  0.7097,  1.6773,  1.4381,  0.7932,
          1.6639,  1.0904,  1.7214,  1.6523,  0.6947,  0.3024,  0.2315,  0.6136,
          1.1762,  1.4437,  0.5133,  4.7721,  4.2013,  0.0371,  0.3796,  0.4145,
          0.5484,  0.2222,  0.5514, -0.2526,  0.5493,  0.6398],
        [ 1.3832,  1.4136,  1.4631,  1.4487,  1.4348,  1.3987,  1.3624,  1.3833,
          1.3833,  1.3540,  1.4336,  1.3438,  1.4864,  1.4314,  1.5093,  1.3497,
          1.4303,  1.3562,  1.4334,  1.4546,  1.4540,  1.4396,  1.4082,  1.3905,
          1.3639,  1.3920,  1.3920,  1.4508,  1.4835,  1.4099,  1.2677,  1.3389,
          1.2482,  1.4518,  1.2969,  1.4109,  0.2941,  0.2439,  0.3516,  0.3028,
          0.1272,  0.0814,  0.3149,  0.1425, -0.0160,  2.3968,  1.7457,  2.0988,
          1.9711,  1.5174,  1.1095,  2.3106,  1.8898,  1.0798]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 64 : 178.1970984815935
Test loss for epoch 64 : 177.9843586590721
Test Precision for epoch 64 : 0.26153846153846155
Test Recall for epoch 64 : 0.26153846153846155
Test F1 for epoch 64 : 0.26153846153846155


theta for epoch 65 : tensor([[ 1.9997,  2.0234,  2.0665,  2.1151,  2.0967,  2.0052,  2.0716,  1.9994,
          1.9994,  1.4114,  1.4127,  1.4122,  1.4143,  1.4101,  1.4155,  1.4109,
          1.4099,  1.3696,  1.3816,  1.3421,  1.3451,  1.3838,  1.3812,  1.3804,
          1.3836,  1.3798,  1.3798,  1.3708,  1.4113,  1.4097,  1.4103,  1.4108,
          1.4100,  1.4103,  1.3678,  1.4095,  1.7910,  1.8029,  1.7945,  1.7912,
          1.7982,  1.7417,  1.7923,  1.7808,  1.7993,  1.6945,  1.6852,  1.6819,
          1.6810,  1.6911,  1.6823,  1.7014,  1.6789,  1.6817],
        [ 1.4457,  1.3035,  1.1351,  1.3536,  1.4451,  1.4886,  1.4058,  1.4884,
          1.4884,  1.6473,  1.7369,  1.6091,  2.1185,  1.6471,  3.2969,  1.7231,
          1.5718,  2.9699,  1.2663,  1.3211,  1.1829,  1.2936,  1.4560,  1.4936,
          1.4506,  1.4934,  1.4934,  1.4057,  1.2659,  1.5266,  1.4906,  1.2224,
          1.5253,  1.5221,  1.4858,  1.5110,  1.8325,  1.9040,  1.8419,  1.8047,
          1.8458,  1.8985,  1.8425,  1.0868,  1.8529,  1.4790,  1.8310,  1.8292,
          1.8417,  1.4687,  1.8342,  1.2912,  1.8357,  1.8436],
        [ 1.3789,  1.3799,  1.3817,  1.3818,  1.3828,  1.3795,  1.3798,  1.3790,
          1.3790,  1.4226,  1.4230,  1.4248,  1.4258,  1.4205,  1.3695,  1.4224,
          1.4078,  1.3501,  2.0519,  2.0732,  2.1491,  2.1166,  1.9819,  2.0231,
          2.0754,  1.9786,  1.9786,  1.4107,  1.3720,  1.4142,  1.4148,  1.4095,
          1.4145,  1.4158,  1.4132,  1.4141,  1.7973,  1.8090,  1.8006,  1.7863,
          1.8046,  1.8033,  1.7982,  1.6976,  1.8006,  1.6671,  1.6877,  1.6840,
          1.6830,  1.6030,  1.6855,  1.6625,  1.6809,  1.6836],
        [ 1.3964,  1.3970,  1.3352,  1.3337,  1.3975,  1.3974,  1.3961,  1.3965,
          1.3965,  1.4383,  1.3845,  1.4355,  1.4209,  1.4364,  1.3500,  1.4378,
          1.4360,  1.2694,  1.4127,  1.3997,  1.4171,  1.4144,  1.4087,  1.3925,
          1.4122,  1.4084,  1.4084,  2.2869,  2.0569,  1.8955,  1.9826,  2.2721,
          1.9030,  2.2463,  1.9055,  1.8947,  1.8217,  1.8253,  1.7948,  1.8138,
          1.8282,  1.8154,  1.8188,  1.6128,  1.8163,  1.7216,  1.6941,  1.6026,
          1.6577,  1.7193,  1.6446,  1.7252,  1.6550,  1.7141],
        [ 1.6983,  1.3733,  0.5077,  0.7652,  1.1537,  1.5854,  1.5189,  1.6984,
          1.6984,  1.6176,  1.3011,  1.4385,  0.8799,  1.6875,  0.1070,  1.6017,
          1.7077,  1.0704,  1.2849,  0.8094,  0.6317,  1.0589,  1.5489,  1.6325,
          1.3202,  1.7012,  1.7012,  0.6553,  0.7160,  1.6817,  1.4432,  0.7977,
          1.6672,  1.0945,  1.7262,  1.6558,  0.6799,  0.2887,  0.2191,  0.5994,
          1.1613,  1.4291,  0.4979,  4.8336,  4.2436,  0.0498,  0.3918,  0.4269,
          0.5594,  0.2351,  0.5626, -0.2400,  0.5612,  0.6513],
        [ 1.3809,  1.4114,  1.4602,  1.4462,  1.4321,  1.3963,  1.3598,  1.3810,
          1.3810,  1.3441,  1.4259,  1.3356,  1.4790,  1.4210,  1.5028,  1.3399,
          1.4198,  1.3494,  1.4278,  1.4498,  1.4498,  1.4347,  1.4021,  1.3845,
          1.3578,  1.3856,  1.3856,  1.4512,  1.4832,  1.4099,  1.2661,  1.3405,
          1.2482,  1.4527,  1.2958,  1.4110,  0.2972,  0.2439,  0.3548,  0.3057,
          0.1263,  0.0796,  0.3181,  0.1462, -0.0185,  2.4093,  1.7573,  2.1146,
          1.9841,  1.5242,  1.1194,  2.3210,  1.9048,  1.0897]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 65 : 178.16772541398518
Test loss for epoch 65 : 177.94817722446936
Test Precision for epoch 65 : 0.26153846153846155
Test Recall for epoch 65 : 0.26153846153846155
Test F1 for epoch 65 : 0.26153846153846155


theta for epoch 66 : tensor([[ 2.0024,  2.0252,  2.0676,  2.1172,  2.0987,  2.0077,  2.0748,  2.0021,
          2.0021,  1.4133,  1.4148,  1.4145,  1.4167,  1.4117,  1.4181,  1.4129,
          1.4116,  1.3718,  1.3827,  1.3431,  1.3456,  1.3849,  1.3819,  1.3811,
          1.3843,  1.3804,  1.3804,  1.3696,  1.4109,  1.4086,  1.4095,  1.4101,
          1.4090,  1.4094,  1.3665,  1.4085,  1.7871,  1.7983,  1.7906,  1.7872,
          1.7934,  1.7365,  1.7885,  1.7765,  1.7943,  1.6944,  1.6846,  1.6812,
          1.6799,  1.6911,  1.6815,  1.7012,  1.6780,  1.6805],
        [ 1.4420,  1.3000,  1.1338,  1.3516,  1.4433,  1.4851,  1.4021,  1.4849,
          1.4849,  1.6551,  1.7409,  1.6172,  2.1143,  1.6557,  3.2965,  1.7315,
          1.5800,  2.9730,  1.2678,  1.3229,  1.1863,  1.2940,  1.4561,  1.4933,
          1.4504,  1.4929,  1.4929,  1.4041,  1.2671,  1.5237,  1.4883,  1.2212,
          1.5226,  1.5198,  1.4831,  1.5091,  1.8370,  1.9042,  1.8435,  1.8072,
          1.8498,  1.8988,  1.8442,  1.0937,  1.8555,  1.4785,  1.8247,  1.8227,
          1.8334,  1.4658,  1.8269,  1.2948,  1.8279,  1.8352],
        [ 1.3769,  1.3778,  1.3796,  1.3795,  1.3806,  1.3775,  1.3772,  1.3770,
          1.3770,  1.4261,  1.4267,  1.4287,  1.4297,  1.4239,  1.3747,  1.4260,
          1.4113,  1.3540,  2.0564,  2.0750,  2.1506,  2.1188,  1.9862,  2.0270,
          2.0782,  1.9828,  1.9828,  1.4104,  1.3716,  1.4138,  1.4147,  1.4090,
          1.4143,  1.4157,  1.4129,  1.4138,  1.7931,  1.8041,  1.7964,  1.7824,
          1.7994,  1.7981,  1.7941,  1.6932,  1.7960,  1.6684,  1.6885,  1.6848,
          1.6831,  1.6034,  1.6859,  1.6637,  1.6812,  1.6838],
        [ 1.3934,  1.3941,  1.3338,  1.3321,  1.3945,  1.3943,  1.3931,  1.3935,
          1.3935,  1.4387,  1.3861,  1.4368,  1.4217,  1.4365,  1.3510,  1.4384,
          1.4363,  1.2720,  1.4125,  1.4000,  1.4170,  1.4143,  1.4084,  1.3928,
          1.4120,  1.4080,  1.4080,  2.2876,  2.0642,  1.9023,  1.9889,  2.2736,
          1.9100,  2.2478,  1.9124,  1.9017,  1.8171,  1.8207,  1.7909,  1.8100,
          1.8224,  1.8108,  1.8142,  1.6108,  1.8110,  1.7209,  1.6928,  1.5994,
          1.6547,  1.7182,  1.6429,  1.7251,  1.6522,  1.7117],
        [ 1.6973,  1.3709,  0.5033,  0.7613,  1.1504,  1.5841,  1.5174,  1.6974,
          1.6974,  1.6172,  1.2971,  1.4364,  0.8752,  1.6877,  0.1019,  1.6003,
          1.7080,  1.0605,  1.2849,  0.8091,  0.6304,  1.0597,  1.5501,  1.6331,
          1.3208,  1.7032,  1.7032,  0.6511,  0.7119,  1.6776,  1.4392,  0.7915,
          1.6619,  1.0889,  1.7225,  1.6506,  0.6724,  0.2817,  0.2133,  0.5924,
          1.1542,  1.4225,  0.4895,  4.9021,  4.2933,  0.0502,  0.3926,  0.4275,
          0.5582,  0.2359,  0.5619, -0.2392,  0.5612,  0.6508],
        [ 1.3828,  1.4134,  1.4615,  1.4480,  1.4334,  1.3980,  1.3615,  1.3829,
          1.3829,  1.3444,  1.4281,  1.3380,  1.4815,  1.4203,  1.5064,  1.3405,
          1.4191,  1.3531,  1.4336,  1.4563,  1.4568,  1.4411,  1.4075,  1.3900,
          1.3635,  1.3906,  1.3906,  1.4546,  1.4858,  1.4128,  1.2682,  1.3455,
          1.2520,  1.4564,  1.2982,  1.4141,  0.3091,  0.2530,  0.3666,  0.3175,
          0.1350,  0.0876,  0.3300,  0.1600, -0.0107,  2.4099,  1.7570,  2.1183,
          1.9850,  1.5194,  1.1179,  2.3194,  1.9077,  1.0883]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 66 : 178.12890528925723
Test loss for epoch 66 : 177.91404671989946
Test Precision for epoch 66 : 0.26153846153846155
Test Recall for epoch 66 : 0.26153846153846155
Test F1 for epoch 66 : 0.26153846153846155


theta for epoch 67 : tensor([[ 2.0052,  2.0271,  2.0688,  2.1195,  2.1009,  2.0104,  2.0779,  2.0049,
          2.0049,  1.4147,  1.4164,  1.4163,  1.4185,  1.4130,  1.4202,  1.4144,
          1.4129,  1.3736,  1.3845,  1.3449,  1.3469,  1.3867,  1.3833,  1.3824,
          1.3858,  1.3818,  1.3818,  1.3662,  1.4083,  1.4054,  1.4065,  1.4074,
          1.4059,  1.4064,  1.3630,  1.4053,  1.7821,  1.7926,  1.7856,  1.7822,
          1.7875,  1.7303,  1.7835,  1.7712,  1.7883,  1.6970,  1.6866,  1.6832,
          1.6812,  1.6936,  1.6831,  1.7038,  1.6795,  1.6818],
        [ 1.4387,  1.2969,  1.1332,  1.3500,  1.4419,  1.4820,  1.3988,  1.4819,
          1.4819,  1.6622,  1.7444,  1.6243,  2.1097,  1.6635,  3.2951,  1.7389,
          1.5872,  2.9751,  1.2701,  1.3254,  1.1904,  1.2951,  1.4569,  1.4934,
          1.4508,  1.4929,  1.4929,  1.4001,  1.2658,  1.5184,  1.4837,  1.2179,
          1.5177,  1.5152,  1.4781,  1.5049,  1.8396,  1.9027,  1.8433,  1.8078,
          1.8519,  1.8975,  1.8441,  1.0987,  1.8563,  1.4808,  1.8207,  1.8185,
          1.8271,  1.4658,  1.8218,  1.3011,  1.8223,  1.8288],
        [ 1.3758,  1.3766,  1.3786,  1.3782,  1.3792,  1.3764,  1.3755,  1.3759,
          1.3759,  1.4295,  1.4303,  1.4324,  1.4335,  1.4271,  1.3798,  1.4295,
          1.4149,  1.3578,  2.0595,  2.0755,  2.1510,  2.1198,  1.9890,  2.0294,
          2.0796,  1.9854,  1.9854,  1.4082,  1.3695,  1.4116,  1.4128,  1.4068,
          1.4123,  1.4138,  1.4108,  1.4116,  1.7880,  1.7983,  1.7912,  1.7775,
          1.7935,  1.7920,  1.7890,  1.6880,  1.7905,  1.6725,  1.6923,  1.6884,
          1.6861,  1.6070,  1.6893,  1.6680,  1.6844,  1.6867],
        [ 1.3911,  1.3919,  1.3333,  1.3313,  1.3922,  1.3919,  1.3908,  1.3912,
          1.3912,  1.4391,  1.3879,  1.4380,  1.4225,  1.4366,  1.3518,  1.4389,
          1.4365,  1.2747,  1.4133,  1.4013,  1.4178,  1.4152,  1.4092,  1.3941,
          1.4128,  1.4086,  1.4086,  2.2857,  2.0689,  1.9063,  1.9925,  2.2725,
          1.9141,  2.2466,  1.9166,  1.9060,  1.8114,  1.8150,  1.7857,  1.8051,
          1.8157,  1.8051,  1.8084,  1.6080,  1.8047,  1.7227,  1.6941,  1.5987,
          1.6542,  1.7196,  1.6438,  1.7278,  1.6520,  1.7117],
        [ 1.6997,  1.3726,  0.5046,  0.7626,  1.1521,  1.5866,  1.5198,  1.6998,
          1.6998,  1.6201,  1.2974,  1.4378,  0.8757,  1.6910,  0.1034,  1.6021,
          1.7113,  1.0558,  1.2896,  0.8146,  0.6358,  1.0659,  1.5557,  1.6378,
          1.3261,  1.7090,  1.7090,  0.6521,  0.7131,  1.6758,  1.4385,  0.7904,
          1.6590,  1.0877,  1.7209,  1.6479,  0.6591,  0.2696,  0.2025,  0.5797,
          1.1406,  1.4089,  0.4756,  4.9652,  4.3365,  0.0602,  0.4022,  0.4372,
          0.5660,  0.2458,  0.5701, -0.2288,  0.5702,  0.6591],
        [ 1.3795,  1.4103,  1.4580,  1.4448,  1.4297,  1.3946,  1.3580,  1.3796,
          1.3796,  1.3353,  1.4212,  1.3308,  1.4748,  1.4106,  1.5006,  1.3317,
          1.4095,  1.3470,  1.4306,  1.4543,  1.4553,  1.4389,  1.4040,  1.3866,
          1.3601,  1.3867,  1.3867,  1.4501,  1.4808,  1.4076,  1.2619,  1.3423,
          1.2473,  1.4523,  1.2921,  1.4091,  0.3113,  0.2524,  0.3687,  0.3195,
          0.1337,  0.0854,  0.3322,  0.1644, -0.0128,  2.4228,  1.7690,  2.1346,
          1.9983,  1.5271,  1.1285,  2.3302,  1.9231,  1.0988]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 67 : 178.08756282491166
Test loss for epoch 67 : 177.86628215878497
Test Precision for epoch 67 : 0.26153846153846155
Test Recall for epoch 67 : 0.26153846153846155
Test F1 for epoch 67 : 0.26153846153846155


theta for epoch 68 : tensor([[ 2.0094,  2.0305,  2.0716,  2.1232,  2.1046,  2.0145,  2.0826,  2.0092,
          2.0092,  1.4144,  1.4163,  1.4163,  1.4185,  1.4124,  1.4205,  1.4142,
          1.4125,  1.3735,  1.3841,  1.3444,  1.3458,  1.3861,  1.3825,  1.3815,
          1.3849,  1.3809,  1.3809,  1.3631,  1.4059,  1.4023,  1.4037,  1.4049,
          1.4030,  1.4035,  1.3598,  1.4023,  1.7774,  1.7872,  1.7808,  1.7774,
          1.7820,  1.7245,  1.7788,  1.7662,  1.7826,  1.6968,  1.6858,  1.6822,
          1.6796,  1.6933,  1.6819,  1.7036,  1.6782,  1.6802],
        [ 1.4365,  1.2951,  1.1337,  1.3497,  1.4417,  1.4800,  1.3967,  1.4799,
          1.4799,  1.6684,  1.7475,  1.6305,  2.1048,  1.6704,  3.2927,  1.7454,
          1.5936,  2.9764,  1.2705,  1.3259,  1.1923,  1.2942,  1.4558,  1.4916,
          1.4491,  1.4910,  1.4910,  1.3967,  1.2647,  1.5136,  1.4796,  1.2152,
          1.5132,  1.5112,  1.4735,  1.5012,  1.8419,  1.9012,  1.8428,  1.8082,
          1.8537,  1.8960,  1.8437,  1.1032,  1.8568,  1.4802,  1.8136,  1.8111,
          1.8176,  1.4633,  1.8136,  1.3044,  1.8134,  1.8193],
        [ 1.3760,  1.3768,  1.3788,  1.3782,  1.3791,  1.3765,  1.3750,  1.3760,
          1.3760,  1.4311,  1.4322,  1.4342,  1.4354,  1.4286,  1.3830,  1.4312,
          1.4167,  1.3597,  2.0619,  2.0755,  2.1508,  2.1202,  1.9909,  2.0310,
          2.0803,  1.9872,  1.9872,  1.4065,  1.3679,  1.4099,  1.4113,  1.4051,
          1.4107,  1.4124,  1.4091,  1.4099,  1.7833,  1.7930,  1.7865,  1.7731,
          1.7880,  1.7865,  1.7843,  1.6833,  1.7854,  1.6741,  1.6934,  1.6894,
          1.6864,  1.6081,  1.6899,  1.6700,  1.6849,  1.6869],
        [ 1.3900,  1.3909,  1.3340,  1.3317,  1.3911,  1.3907,  1.3897,  1.3901,
          1.3901,  1.4379,  1.3881,  1.4377,  1.4218,  1.4352,  1.3510,  1.4378,
          1.4352,  1.2759,  1.4123,  1.4008,  1.4167,  1.4142,  1.4082,  1.3936,
          1.4118,  1.4074,  1.4074,  2.2844,  2.0741,  1.9107,  1.9966,  2.2719,
          1.9187,  2.2459,  1.9213,  1.9107,  1.8060,  1.8096,  1.7809,  1.8004,
          1.8093,  1.7997,  1.8029,  1.6057,  1.7988,  1.7221,  1.6929,  1.5956,
          1.6511,  1.7186,  1.6423,  1.7280,  1.6491,  1.7089],
        [ 1.7007,  1.3724,  0.5029,  0.7611,  1.1515,  1.5875,  1.5204,  1.7008,
          1.7008,  1.6187,  1.2928,  1.4349,  0.8712,  1.6902,  0.0993,  1.5996,
          1.7104,  1.0463,  1.2898,  0.8151,  0.6358,  1.0673,  1.5570,  1.6385,
          1.3272,  1.7109,  1.7109,  0.6490,  0.7102,  1.6716,  1.4350,  0.7852,
          1.6536,  1.0833,  1.7171,  1.6428,  0.6501,  0.2616,  0.1957,  0.5713,
          1.1313,  1.3997,  0.4660,  5.0325,  4.3839,  0.0619,  0.4039,  0.4386,
          0.5652,  0.2475,  0.5697, -0.2261,  0.5707,  0.6588],
        [ 1.3810,  1.4119,  1.4592,  1.4464,  1.4307,  1.3957,  1.3592,  1.3810,
          1.3810,  1.3313,  1.4189,  1.3288,  1.4727,  1.4056,  1.4994,  1.3280,
          1.4045,  1.3459,  1.4321,  1.4567,  1.4583,  1.4411,  1.4051,  1.3878,
          1.3616,  1.3876,  1.3876,  1.4497,  1.4799,  1.4066,  1.2602,  1.3435,
          1.2473,  1.4523,  1.2905,  1.4084,  0.3196,  0.2582,  0.3769,  0.3278,
          0.1391,  0.0902,  0.3405,  0.1758, -0.0075,  2.4270,  1.7723,  2.1420,
          2.0027,  1.5262,  1.1306,  2.3323,  1.9298,  1.1009]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 68 : 178.05041328907248
Test loss for epoch 68 : 177.83076319395042
Test Precision for epoch 68 : 0.26153846153846155
Test Recall for epoch 68 : 0.26153846153846155
Test F1 for epoch 68 : 0.26153846153846155


theta for epoch 69 : tensor([[ 2.0144e+00,  2.0347e+00,  2.0753e+00,  2.1278e+00,  2.1090e+00,
          2.0193e+00,  2.0879e+00,  2.0142e+00,  2.0142e+00,  1.4125e+00,
          1.4146e+00,  1.4147e+00,  1.4170e+00,  1.4104e+00,  1.4192e+00,
          1.4124e+00,  1.4105e+00,  1.3719e+00,  1.3805e+00,  1.3408e+00,
          1.3418e+00,  1.3825e+00,  1.3786e+00,  1.3777e+00,  1.3811e+00,
          1.3770e+00,  1.3770e+00,  1.3616e+00,  1.4051e+00,  1.4009e+00,
          1.4025e+00,  1.4039e+00,  1.4018e+00,  1.4024e+00,  1.3582e+00,
          1.4010e+00,  1.7728e+00,  1.7820e+00,  1.7762e+00,  1.7728e+00,
          1.7767e+00,  1.7189e+00,  1.7742e+00,  1.7615e+00,  1.7772e+00,
          1.6944e+00,  1.6827e+00,  1.6791e+00,  1.6758e+00,  1.6908e+00,
          1.6784e+00,  1.7013e+00,  1.6745e+00,  1.6763e+00],
        [ 1.4345e+00,  1.2935e+00,  1.1344e+00,  1.3495e+00,  1.4417e+00,
          1.4782e+00,  1.3948e+00,  1.4781e+00,  1.4781e+00,  1.6743e+00,
          1.7505e+00,  1.6363e+00,  2.1000e+00,  1.6770e+00,  3.2898e+00,
          1.7514e+00,  1.5994e+00,  2.9773e+00,  1.2678e+00,  1.3233e+00,
          1.1911e+00,  1.2902e+00,  1.4516e+00,  1.4866e+00,  1.4442e+00,
          1.4860e+00,  1.4860e+00,  1.3951e+00,  1.2652e+00,  1.5106e+00,
          1.4774e+00,  1.2145e+00,  1.5106e+00,  1.5089e+00,  1.4708e+00,
          1.4992e+00,  1.8436e+00,  1.8993e+00,  1.8419e+00,  1.8080e+00,
          1.8551e+00,  1.8943e+00,  1.8428e+00,  1.1071e+00,  1.8570e+00,
          1.4774e+00,  1.8040e+00,  1.8012e+00,  1.8056e+00,  1.4586e+00,
          1.8028e+00,  1.3053e+00,  1.8021e+00,  1.8072e+00],
        [ 1.3759e+00,  1.3768e+00,  1.3789e+00,  1.3781e+00,  1.3788e+00,
          1.3765e+00,  1.3744e+00,  1.3760e+00,  1.3760e+00,  1.4303e+00,
          1.4316e+00,  1.4336e+00,  1.4348e+00,  1.4277e+00,  1.3837e+00,
          1.4305e+00,  1.4161e+00,  1.3592e+00,  2.0650e+00,  2.0763e+00,
          2.1516e+00,  2.1214e+00,  1.9935e+00,  2.0332e+00,  2.0817e+00,
          1.9896e+00,  1.9896e+00,  1.4063e+00,  1.3677e+00,  1.4096e+00,
          1.4113e+00,  1.4048e+00,  1.4105e+00,  1.4124e+00,  1.4089e+00,
          1.4096e+00,  1.7787e+00,  1.7878e+00,  1.7819e+00,  1.7688e+00,
          1.7827e+00,  1.7812e+00,  1.7798e+00,  1.6786e+00,  1.7803e+00,
          1.6730e+00,  1.6919e+00,  1.6879e+00,  1.6841e+00,  1.6068e+00,
          1.6880e+00,  1.6695e+00,  1.6828e+00,  1.6845e+00],
        [ 1.3890e+00,  1.3900e+00,  1.3349e+00,  1.3324e+00,  1.3901e+00,
          1.3896e+00,  1.3887e+00,  1.3890e+00,  1.3890e+00,  1.4350e+00,
          1.3869e+00,  1.4356e+00,  1.4194e+00,  1.4322e+00,  1.3483e+00,
          1.4351e+00,  1.4322e+00,  1.2755e+00,  1.4082e+00,  1.3972e+00,
          1.4125e+00,  1.4102e+00,  1.4042e+00,  1.3902e+00,  1.4078e+00,
          1.4032e+00,  1.4032e+00,  2.2851e+00,  2.0813e+00,  1.9171e+00,
          2.0027e+00,  2.2733e+00,  1.9253e+00,  2.2472e+00,  1.9279e+00,
          1.9173e+00,  1.8006e+00,  1.8043e+00,  1.7762e+00,  1.7958e+00,
          1.8031e+00,  1.7945e+00,  1.7974e+00,  1.6038e+00,  1.7931e+00,
          1.7193e+00,  1.6895e+00,  1.5903e+00,  1.6457e+00,  1.7154e+00,
          1.6386e+00,  1.7261e+00,  1.6441e+00,  1.7040e+00],
        [ 1.7036e+00,  1.3746e+00,  5.0436e-01,  7.6269e-01,  1.1536e+00,
          1.5906e+00,  1.5233e+00,  1.7037e+00,  1.7037e+00,  1.6185e+00,
          1.2901e+00,  1.4335e+00,  8.6919e-01,  1.6904e+00,  9.8518e-02,
          1.5982e+00,  1.7106e+00,  1.0393e+00,  1.2914e+00,  8.1779e-01,
          6.3834e-01,  1.0705e+00,  1.5593e+00,  1.6401e+00,  1.3297e+00,
          1.7134e+00,  1.7134e+00,  6.5112e-01,  7.1270e-01,  1.6719e+00,
          1.4365e+00,  7.8514e-01,  1.6528e+00,  1.0841e+00,  1.7177e+00,
          1.6423e+00,  6.3835e-01,  2.5123e-01,  1.8652e-01,  5.6013e-01,
          1.1187e+00,  1.3869e+00,  4.5370e-01,  5.0972e+00,  4.4280e+00,
          6.6763e-02,  4.0832e-01,  4.4286e-01,  5.6697e-01,  2.5207e-01,
          5.7186e-01, -2.1983e-01,  5.7383e-01,  6.6078e-01],
        [ 1.3810e+00,  1.4121e+00,  1.4591e+00,  1.4466e+00,  1.4303e+00,
          1.3955e+00,  1.3591e+00,  1.3810e+00,  1.3810e+00,  1.3238e+00,
          1.4132e+00,  1.3233e+00,  1.4671e+00,  1.3973e+00,  1.4945e+00,
          1.3209e+00,  1.3963e+00,  1.3412e+00,  1.4289e+00,  1.4543e+00,
          1.4564e+00,  1.4386e+00,  1.4016e+00,  1.3845e+00,  1.3583e+00,
          1.3838e+00,  1.3838e+00,  1.4492e+00,  1.4789e+00,  1.4054e+00,
          1.2582e+00,  1.3445e+00,  1.2469e+00,  1.4522e+00,  1.2886e+00,
          1.4074e+00,  3.2499e-01,  2.6130e-01,  3.8222e-01,  3.3318e-01,
          1.4193e-01,  9.2421e-02,  3.4592e-01,  1.8481e-01, -4.6100e-03,
          2.4341e+00,  1.7785e+00,  2.1523e+00,  2.0100e+00,  1.5283e+00,
          1.1355e+00,  2.3373e+00,  1.9394e+00,  1.1057e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 69 : 178.0143159518189
Test loss for epoch 69 : 177.79309288849967
Test Precision for epoch 69 : 0.26153846153846155
Test Recall for epoch 69 : 0.26153846153846155
Test F1 for epoch 69 : 0.26153846153846155


theta for epoch 70 : tensor([[ 2.0184e+00,  2.0379e+00,  2.0779e+00,  2.1313e+00,  2.1125e+00,
          2.0231e+00,  2.0922e+00,  2.0181e+00,  2.0181e+00,  1.4111e+00,
          1.4133e+00,  1.4135e+00,  1.4159e+00,  1.4088e+00,  1.4183e+00,
          1.4111e+00,  1.4089e+00,  1.3706e+00,  1.3768e+00,  1.3370e+00,
          1.3375e+00,  1.3786e+00,  1.3746e+00,  1.3736e+00,  1.3770e+00,
          1.3729e+00,  1.3729e+00,  1.3611e+00,  1.4051e+00,  1.4004e+00,
          1.4022e+00,  1.4039e+00,  1.4014e+00,  1.4021e+00,  1.3575e+00,
          1.4004e+00,  1.7688e+00,  1.7775e+00,  1.7722e+00,  1.7687e+00,
          1.7721e+00,  1.7141e+00,  1.7702e+00,  1.7574e+00,  1.7724e+00,
          1.6908e+00,  1.6785e+00,  1.6748e+00,  1.6708e+00,  1.6872e+00,
          1.6737e+00,  1.6980e+00,  1.6697e+00,  1.6711e+00],
        [ 1.4309e+00,  1.2906e+00,  1.1336e+00,  1.3477e+00,  1.4401e+00,
          1.4749e+00,  1.3914e+00,  1.4748e+00,  1.4748e+00,  1.6807e+00,
          1.7544e+00,  1.6425e+00,  2.0960e+00,  1.6841e+00,  3.2872e+00,
          1.7578e+00,  1.6057e+00,  2.9786e+00,  1.2645e+00,  1.3200e+00,
          1.1891e+00,  1.2855e+00,  1.4468e+00,  1.4809e+00,  1.4386e+00,
          1.4802e+00,  1.4802e+00,  1.3942e+00,  1.2661e+00,  1.5083e+00,
          1.4758e+00,  1.2145e+00,  1.5086e+00,  1.5073e+00,  1.4688e+00,
          1.4979e+00,  1.8450e+00,  1.8974e+00,  1.8408e+00,  1.8077e+00,
          1.8562e+00,  1.8924e+00,  1.8417e+00,  1.1107e+00,  1.8569e+00,
          1.4730e+00,  1.7927e+00,  1.7897e+00,  1.7920e+00,  1.4526e+00,
          1.7904e+00,  1.3045e+00,  1.7890e+00,  1.7934e+00],
        [ 1.3737e+00,  1.3746e+00,  1.3769e+00,  1.3758e+00,  1.3763e+00,
          1.3743e+00,  1.3717e+00,  1.3737e+00,  1.3737e+00,  1.4284e+00,
          1.4298e+00,  1.4318e+00,  1.4330e+00,  1.4257e+00,  1.3832e+00,
          1.4286e+00,  1.4144e+00,  1.3574e+00,  2.0707e+00,  2.0799e+00,
          2.1551e+00,  2.1254e+00,  1.9987e+00,  2.0380e+00,  2.0859e+00,
          1.9946e+00,  1.9946e+00,  1.4060e+00,  1.3676e+00,  1.4092e+00,
          1.4112e+00,  1.4045e+00,  1.4103e+00,  1.4123e+00,  1.4086e+00,
          1.4093e+00,  1.7743e+00,  1.7829e+00,  1.7775e+00,  1.7646e+00,
          1.7777e+00,  1.7762e+00,  1.7754e+00,  1.6742e+00,  1.7754e+00,
          1.6697e+00,  1.6882e+00,  1.6841e+00,  1.6796e+00,  1.6035e+00,
          1.6838e+00,  1.6670e+00,  1.6785e+00,  1.6799e+00],
        [ 1.3867e+00,  1.3878e+00,  1.3346e+00,  1.3319e+00,  1.3879e+00,
          1.3873e+00,  1.3864e+00,  1.3868e+00,  1.3868e+00,  1.4327e+00,
          1.3862e+00,  1.4339e+00,  1.4176e+00,  1.4298e+00,  1.3461e+00,
          1.4329e+00,  1.4299e+00,  1.2757e+00,  1.4039e+00,  1.3934e+00,
          1.4080e+00,  1.4059e+00,  1.4000e+00,  1.3866e+00,  1.4035e+00,
          1.3989e+00,  1.3989e+00,  2.2861e+00,  2.0887e+00,  1.9237e+00,
          2.0089e+00,  2.2749e+00,  1.9320e+00,  2.2487e+00,  1.9347e+00,
          1.9241e+00,  1.7957e+00,  1.7996e+00,  1.7719e+00,  1.7916e+00,
          1.7976e+00,  1.7898e+00,  1.7925e+00,  1.6027e+00,  1.7881e+00,
          1.7153e+00,  1.6848e+00,  1.5840e+00,  1.6392e+00,  1.7111e+00,
          1.6339e+00,  1.7230e+00,  1.6378e+00,  1.6977e+00],
        [ 1.7061e+00,  1.3766e+00,  5.0638e-01,  7.6458e-01,  1.1558e+00,
          1.5933e+00,  1.5258e+00,  1.7061e+00,  1.7061e+00,  1.6191e+00,
          1.2885e+00,  1.4330e+00,  8.6851e-01,  1.6914e+00,  9.9270e-02,
          1.5975e+00,  1.7116e+00,  1.0338e+00,  1.2937e+00,  8.2147e-01,
          6.4211e-01,  1.0746e+00,  1.5623e+00,  1.6423e+00,  1.3331e+00,
          1.7166e+00,  1.7166e+00,  6.5536e-01,  7.1741e-01,  1.6742e+00,
          1.4401e+00,  7.8728e-01,  1.6540e+00,  1.0873e+00,  1.7203e+00,
          1.6439e+00,  6.2568e-01,  2.4021e-01,  1.7673e-01,  5.4808e-01,
          1.1049e+00,  1.3726e+00,  4.4067e-01,  5.1612e+00,  4.4708e+00,
          7.2195e-02,  4.1306e-01,  4.4742e-01,  5.6900e-01,  2.5697e-01,
          5.7423e-01, -2.1273e-01,  5.7717e-01,  6.6290e-01],
        [ 1.3793e+00,  1.4106e+00,  1.4575e+00,  1.4452e+00,  1.4282e+00,
          1.3935e+00,  1.3571e+00,  1.3792e+00,  1.3792e+00,  1.3164e+00,
          1.4075e+00,  1.3178e+00,  1.4613e+00,  1.3890e+00,  1.4895e+00,
          1.3139e+00,  1.3881e+00,  1.3363e+00,  1.4248e+00,  1.4509e+00,
          1.4536e+00,  1.4352e+00,  1.3973e+00,  1.3804e+00,  1.3543e+00,
          1.3793e+00,  1.3793e+00,  1.4488e+00,  1.4781e+00,  1.4042e+00,
          1.2562e+00,  1.3456e+00,  1.2466e+00,  1.4521e+00,  1.2867e+00,
          1.4064e+00,  3.2965e-01,  2.6394e-01,  3.8682e-01,  3.3786e-01,
          1.4428e-01,  9.4218e-02,  3.5060e-01,  1.9331e-01, -1.8932e-03,
          2.4416e+00,  1.7851e+00,  2.1632e+00,  2.0178e+00,  1.5309e+00,
          1.1407e+00,  2.3427e+00,  1.9495e+00,  1.1109e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 70 : 177.98293573535767
Test loss for epoch 70 : 177.75954757375763
Test Precision for epoch 70 : 0.26153846153846155
Test Recall for epoch 70 : 0.26153846153846155
Test F1 for epoch 70 : 0.26153846153846155


theta for epoch 71 : tensor([[ 2.0207e+00,  2.0395e+00,  2.0791e+00,  2.1333e+00,  2.1144e+00,
          2.0253e+00,  2.0949e+00,  2.0205e+00,  2.0205e+00,  1.4110e+00,
          1.4133e+00,  1.4137e+00,  1.4161e+00,  1.4087e+00,  1.4187e+00,
          1.4111e+00,  1.4088e+00,  1.3707e+00,  1.3744e+00,  1.3345e+00,
          1.3346e+00,  1.3761e+00,  1.3719e+00,  1.3710e+00,  1.3743e+00,
          1.3703e+00,  1.3703e+00,  1.3596e+00,  1.4042e+00,  1.3989e+00,
          1.4010e+00,  1.4029e+00,  1.4000e+00,  1.4008e+00,  1.3559e+00,
          1.3990e+00,  1.7656e+00,  1.7739e+00,  1.7690e+00,  1.7655e+00,
          1.7685e+00,  1.7102e+00,  1.7671e+00,  1.7542e+00,  1.7686e+00,
          1.6878e+00,  1.6747e+00,  1.6709e+00,  1.6661e+00,  1.6840e+00,
          1.6695e+00,  1.6952e+00,  1.6653e+00,  1.6664e+00],
        [ 1.4257e+00,  1.2861e+00,  1.1313e+00,  1.3443e+00,  1.4368e+00,
          1.4700e+00,  1.3863e+00,  1.4698e+00,  1.4698e+00,  1.6874e+00,
          1.7589e+00,  1.6490e+00,  2.0929e+00,  1.6916e+00,  3.2846e+00,
          1.7644e+00,  1.6123e+00,  2.9802e+00,  1.2621e+00,  1.3176e+00,
          1.1880e+00,  1.2818e+00,  1.4430e+00,  1.4761e+00,  1.4339e+00,
          1.4754e+00,  1.4754e+00,  1.3920e+00,  1.2654e+00,  1.5047e+00,
          1.4731e+00,  1.2134e+00,  1.5054e+00,  1.5044e+00,  1.4655e+00,
          1.4953e+00,  1.8465e+00,  1.8957e+00,  1.8398e+00,  1.8073e+00,
          1.8573e+00,  1.8909e+00,  1.8407e+00,  1.1142e+00,  1.8571e+00,
          1.4690e+00,  1.7816e+00,  1.7785e+00,  1.7786e+00,  1.4472e+00,
          1.7782e+00,  1.3039e+00,  1.7763e+00,  1.7798e+00],
        [ 1.3692e+00,  1.3701e+00,  1.3726e+00,  1.3712e+00,  1.3716e+00,
          1.3699e+00,  1.3668e+00,  1.3693e+00,  1.3693e+00,  1.4267e+00,
          1.4284e+00,  1.4303e+00,  1.4314e+00,  1.4240e+00,  1.3827e+00,
          1.4270e+00,  1.4131e+00,  1.3559e+00,  2.0786e+00,  2.0858e+00,
          2.1610e+00,  2.1316e+00,  2.0059e+00,  2.0450e+00,  2.0922e+00,
          2.0016e+00,  2.0016e+00,  1.4041e+00,  1.3657e+00,  1.4071e+00,
          1.4094e+00,  1.4026e+00,  1.4084e+00,  1.4105e+00,  1.4066e+00,
          1.4073e+00,  1.7704e+00,  1.7786e+00,  1.7736e+00,  1.7609e+00,
          1.7733e+00,  1.7717e+00,  1.7715e+00,  1.6702e+00,  1.7711e+00,
          1.6660e+00,  1.6841e+00,  1.6800e+00,  1.6747e+00,  1.5998e+00,
          1.6793e+00,  1.6642e+00,  1.6738e+00,  1.6749e+00],
        [ 1.3833e+00,  1.3846e+00,  1.3333e+00,  1.3304e+00,  1.3845e+00,
          1.3838e+00,  1.3830e+00,  1.3833e+00,  1.3833e+00,  1.4324e+00,
          1.3876e+00,  1.4342e+00,  1.4178e+00,  1.4294e+00,  1.3458e+00,
          1.4326e+00,  1.4295e+00,  1.2779e+00,  1.4012e+00,  1.3911e+00,
          1.4051e+00,  1.4032e+00,  1.3974e+00,  1.3846e+00,  1.4008e+00,
          1.3962e+00,  1.3962e+00,  2.2847e+00,  2.0936e+00,  1.9277e+00,
          2.0128e+00,  2.2742e+00,  1.9361e+00,  2.2479e+00,  1.9389e+00,
          1.9283e+00,  1.7919e+00,  1.7959e+00,  1.7686e+00,  1.7883e+00,
          1.7932e+00,  1.7862e+00,  1.7884e+00,  1.6028e+00,  1.7841e+00,
          1.7119e+00,  1.6808e+00,  1.5784e+00,  1.6334e+00,  1.7073e+00,
          1.6299e+00,  1.7205e+00,  1.6323e+00,  1.6920e+00],
        [ 1.7055e+00,  1.3751e+00,  5.0473e-01,  7.6303e-01,  1.1544e+00,
          1.5928e+00,  1.5251e+00,  1.7055e+00,  1.7055e+00,  1.6178e+00,
          1.2846e+00,  1.4307e+00,  8.6530e-01,  1.6907e+00,  9.6822e-02,
          1.5950e+00,  1.7109e+00,  1.0262e+00,  1.2938e+00,  8.2245e-01,
          6.4282e-01,  1.0762e+00,  1.5634e+00,  1.6428e+00,  1.3345e+00,
          1.7182e+00,  1.7182e+00,  6.5554e-01,  7.1808e-01,  1.6732e+00,
          1.4403e+00,  7.8519e-01,  1.6518e+00,  1.0868e+00,  1.7196e+00,
          1.6422e+00,  6.1616e-01,  2.3221e-01,  1.6987e-01,  5.3913e-01,
          1.0942e+00,  1.3614e+00,  4.3072e-01,  5.2282e+00,  4.5165e+00,
          7.2414e-02,  4.1298e-01,  4.4701e-01,  5.6612e-01,  2.5677e-01,
          5.7166e-01, -2.1069e-01,  5.7563e-01,  6.6018e-01],
        [ 1.3780e+00,  1.4096e+00,  1.4563e+00,  1.4442e+00,  1.4266e+00,
          1.3919e+00,  1.3558e+00,  1.3779e+00,  1.3779e+00,  1.3139e+00,
          1.4064e+00,  1.3173e+00,  1.4602e+00,  1.3854e+00,  1.4891e+00,
          1.3118e+00,  1.3847e+00,  1.3362e+00,  1.4250e+00,  1.4517e+00,
          1.4548e+00,  1.4359e+00,  1.3973e+00,  1.3807e+00,  1.3546e+00,
          1.3793e+00,  1.3793e+00,  1.4493e+00,  1.4783e+00,  1.4039e+00,
          1.2556e+00,  1.3479e+00,  1.2476e+00,  1.4529e+00,  1.2859e+00,
          1.4064e+00,  3.3777e-01,  2.7044e-01,  3.9483e-01,  3.4603e-01,
          1.5066e-01,  1.0016e-01,  3.5871e-01,  2.0558e-01,  5.1955e-03,
          2.4446e+00,  1.7871e+00,  2.1693e+00,  2.0209e+00,  1.5292e+00,
          1.1415e+00,  2.3435e+00,  1.9550e+00,  1.1117e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 71 : 177.9525485340318
Test loss for epoch 71 : 177.73188701691237
Test Precision for epoch 71 : 0.26153846153846155
Test Recall for epoch 71 : 0.26153846153846155
Test F1 for epoch 71 : 0.26153846153846155


theta for epoch 72 : tensor([[ 2.0227,  2.0409,  2.0801,  2.1350,  2.1160,  2.0272,  2.0973,  2.0225,
          2.0225,  1.4109,  1.4133,  1.4138,  1.4162,  1.4085,  1.4189,  1.4110,
          1.4087,  1.3707,  1.3712,  1.3313,  1.3311,  1.3728,  1.3685,  1.3676,
          1.3709,  1.3669,  1.3669,  1.3567,  1.4018,  1.3959,  1.3983,  1.4004,
          1.3972,  1.3981,  1.3528,  1.3961,  1.7622,  1.7702,  1.7656,  1.7622,
          1.7647,  1.7062,  1.7637,  1.7509,  1.7646,  1.6877,  1.6739,  1.6701,
          1.6646,  1.6838,  1.6683,  1.6954,  1.6639,  1.6647],
        [ 1.4204,  1.2817,  1.1290,  1.3408,  1.4333,  1.4648,  1.3811,  1.4645,
          1.4645,  1.6932,  1.7627,  1.6545,  2.0893,  1.6980,  3.2809,  1.7700,
          1.6179,  2.9807,  1.2595,  1.3150,  1.1866,  1.2778,  1.4388,  1.4709,
          1.4287,  1.4702,  1.4702,  1.3885,  1.2633,  1.4998,  1.4690,  1.2113,
          1.5008,  1.5002,  1.4609,  1.4913,  1.8471,  1.8935,  1.8382,  1.8063,
          1.8577,  1.8887,  1.8391,  1.1171,  1.8566,  1.4689,  1.7744,  1.7710,
          1.7690,  1.4459,  1.7697,  1.3070,  1.7672,  1.7699],
        [ 1.3645,  1.3655,  1.3681,  1.3665,  1.3666,  1.3652,  1.3617,  1.3645,
          1.3645,  1.4250,  1.4269,  1.4286,  1.4297,  1.4223,  1.3820,  1.4253,
          1.4117,  1.3544,  2.0855,  2.0909,  2.1661,  2.1370,  2.0121,  2.0508,
          2.0976,  2.0076,  2.0076,  1.4007,  1.3624,  1.4036,  1.4061,  1.3992,
          1.4050,  1.4072,  1.4031,  1.4038,  1.7664,  1.7742,  1.7696,  1.7572,
          1.7689,  1.7673,  1.7675,  1.6663,  1.7666,  1.6654,  1.6831,  1.6789,
          1.6728,  1.5994,  1.6778,  1.6646,  1.6722,  1.6729],
        [ 1.3798,  1.3812,  1.3320,  1.3290,  1.3811,  1.3803,  1.3796,  1.3799,
          1.3799,  1.4325,  1.3896,  1.4349,  1.4185,  1.4295,  1.3460,  1.4329,
          1.4297,  1.2807,  1.3982,  1.3885,  1.4019,  1.4002,  1.3946,  1.3825,
          1.3979,  1.3933,  1.3933,  2.2812,  2.0963,  1.9294,  2.0143,  2.2713,
          1.9380,  2.2448,  1.9408,  1.9302,  1.7880,  1.7922,  1.7653,  1.7850,
          1.7888,  1.7825,  1.7843,  1.6031,  1.7803,  1.7117,  1.6800,  1.5762,
          1.6308,  1.7067,  1.6293,  1.7212,  1.6299,  1.6895],
        [ 1.7066,  1.3759,  0.5066,  0.7646,  1.1559,  1.5943,  1.5265,  1.7066,
          1.7066,  1.6190,  1.2840,  1.4310,  0.8659,  1.6923,  0.0989,  1.5949,
          1.7125,  1.0226,  1.2965,  0.8267,  0.6473,  1.0807,  1.5667,  1.6454,
          1.3385,  1.7216,  1.7216,  0.6592,  0.7223,  1.6739,  1.4426,  0.7865,
          1.6513,  1.0893,  1.7205,  1.6423,  0.6030,  0.2210,  0.1599,  0.5266,
          1.0793,  1.3457,  0.4174,  5.2918,  4.5579,  0.0791,  0.4192,  0.4531,
          0.5701,  0.2629,  0.5758, -0.2023,  0.5808,  0.6641],
        [ 1.3725,  1.4044,  1.4512,  1.4393,  1.4210,  1.3861,  1.3502,  1.3724,
          1.3724,  1.3055,  1.3996,  1.3107,  1.4532,  1.3763,  1.4828,  1.3037,
          1.3757,  1.3300,  1.4182,  1.4456,  1.4492,  1.4298,  1.3904,  1.3740,
          1.3478,  1.3723,  1.3723,  1.4443,  1.4733,  1.3981,  1.2491,  1.3445,
          1.2429,  1.4482,  1.2794,  1.4008,  0.3392,  0.2704,  0.3962,  0.3475,
          0.1503,  0.0994,  0.3602,  0.2110,  0.0056,  2.4562,  1.7979,  2.1844,
          2.0327,  1.5362,  1.1509,  2.3531,  1.9694,  1.1210]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 72 : 177.92156122720758
Test loss for epoch 72 : 177.69594764986707
Test Precision for epoch 72 : 0.26153846153846155
Test Recall for epoch 72 : 0.26153846153846155
Test F1 for epoch 72 : 0.26153846153846155


theta for epoch 73 : tensor([[ 2.0262,  2.0438,  2.0826,  2.1382,  2.1192,  2.0306,  2.1012,  2.0260,
          2.0260,  1.4094,  1.4119,  1.4125,  1.4149,  1.4070,  1.4178,  1.4096,
          1.4072,  1.3694,  1.3666,  1.3266,  1.3261,  1.3681,  1.3637,  1.3628,
          1.3660,  1.3621,  1.3621,  1.3532,  1.3987,  1.3923,  1.3949,  1.3972,
          1.3937,  1.3948,  1.3491,  1.3925,  1.7587,  1.7664,  1.7621,  1.7587,
          1.7609,  1.7022,  1.7603,  1.7475,  1.7606,  1.6870,  1.6724,  1.6685,
          1.6623,  1.6829,  1.6664,  1.6950,  1.6618,  1.6623],
        [ 1.4160,  1.2784,  1.1277,  1.3382,  1.4307,  1.4606,  1.3769,  1.4603,
          1.4603,  1.6982,  1.7660,  1.6591,  2.0853,  1.7036,  3.2763,  1.7747,
          1.6225,  2.9804,  1.2563,  1.3117,  1.1848,  1.2733,  1.4340,  1.4651,
          1.4230,  1.4645,  1.4645,  1.3850,  1.2609,  1.4949,  1.4649,  1.2092,
          1.4962,  1.4959,  1.4563,  1.4872,  1.8473,  1.8910,  1.8362,  1.8048,
          1.8576,  1.8863,  1.8370,  1.1195,  1.8557,  1.4690,  1.7671,  1.7635,
          1.7595,  1.4448,  1.7614,  1.3100,  1.7582,  1.7602],
        [ 1.3611,  1.3622,  1.3650,  1.3632,  1.3630,  1.3618,  1.3580,  1.3611,
          1.3611,  1.4230,  1.4250,  1.4265,  1.4276,  1.4203,  1.3808,  1.4233,
          1.4100,  1.3525,  2.0904,  2.0942,  2.1694,  2.1406,  2.0163,  2.0547,
          2.1012,  2.0116,  2.0116,  1.3975,  1.3593,  1.4002,  1.4030,  1.3960,
          1.4018,  1.4041,  1.3998,  1.4004,  1.7627,  1.7703,  1.7660,  1.7538,
          1.7649,  1.7633,  1.7639,  1.6628,  1.7625,  1.6648,  1.6821,  1.6779,
          1.6711,  1.5991,  1.6764,  1.6651,  1.6706,  1.6710],
        [ 1.3769,  1.3785,  1.3313,  1.3282,  1.3784,  1.3774,  1.3768,  1.3770,
          1.3770,  1.4314,  1.3904,  1.4342,  1.4179,  1.4284,  1.3448,  1.4318,
          1.4286,  1.2822,  1.3940,  1.3847,  1.3975,  1.3960,  1.3906,  1.3791,
          1.3937,  1.3892,  1.3892,  2.2785,  2.0998,  1.9319,  2.0167,  2.2692,
          1.9405,  2.2426,  1.9435,  1.9329,  1.7839,  1.7884,  1.7618,  1.7814,
          1.7844,  1.7788,  1.7801,  1.6034,  1.7764,  1.7109,  1.6786,  1.5735,
          1.6276,  1.7056,  1.6282,  1.7212,  1.6270,  1.6863],
        [ 1.7054,  1.3737,  0.5039,  0.7622,  1.1537,  1.5932,  1.5251,  1.7055,
          1.7055,  1.6157,  1.2780,  1.4267,  0.8607,  1.6895,  0.0943,  1.5903,
          1.7098,  1.0135,  1.2940,  0.8250,  0.6452,  1.0796,  1.5653,  1.6435,
          1.3377,  1.7207,  1.7207,  0.6568,  0.7204,  1.6706,  1.4404,  0.7815,
          1.6467,  1.0865,  1.7175,  1.6384,  0.5950,  0.2147,  0.1546,  0.5191,
          1.0698,  1.3355,  0.4090,  5.3604,  4.6046,  0.0766,  0.4169,  0.4506,
          0.5654,  0.2602,  0.5714, -0.2030,  0.5774,  0.6597],
        [ 1.3724,  1.4045,  1.4514,  1.4395,  1.4206,  1.3856,  1.3500,  1.3722,
          1.3722,  1.3045,  1.3999,  1.3115,  1.4532,  1.3742,  1.4834,  1.3032,
          1.3739,  1.3310,  1.4182,  1.4461,  1.4500,  1.4302,  1.3903,  1.3742,
          1.3480,  1.3722,  1.3722,  1.4439,  1.4727,  1.3969,  1.2479,  1.3460,
          1.2433,  1.4481,  1.2781,  1.3998,  0.3472,  0.2775,  0.4042,  0.3556,
          0.1574,  0.1063,  0.3682,  0.2232,  0.0139,  2.4579,  1.7987,  2.1893,
          2.0344,  1.5335,  1.1507,  2.3526,  1.9737,  1.1207]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 73 : 177.89046412217655
Test loss for epoch 73 : 177.66897912078815
Test Precision for epoch 73 : 0.26153846153846155
Test Recall for epoch 73 : 0.26153846153846155
Test F1 for epoch 73 : 0.26153846153846155


theta for epoch 74 : tensor([[ 2.0310,  2.0481,  2.0865,  2.1429,  2.1238,  2.0354,  2.1064,  2.0308,
          2.0308,  1.4063,  1.4088,  1.4095,  1.4120,  1.4038,  1.4150,  1.4066,
          1.4041,  1.3663,  1.3615,  1.3215,  1.3207,  1.3629,  1.3585,  1.3576,
          1.3608,  1.3570,  1.3570,  1.3500,  1.3959,  1.3891,  1.3919,  1.3944,
          1.3906,  1.3918,  1.3458,  1.3893,  1.7538,  1.7613,  1.7572,  1.7538,
          1.7557,  1.6969,  1.7554,  1.7427,  1.7553,  1.6864,  1.6711,  1.6672,
          1.6603,  1.6822,  1.6647,  1.6948,  1.6600,  1.6602],
        [ 1.4123,  1.2759,  1.1271,  1.3363,  1.4288,  1.4571,  1.3734,  1.4567,
          1.4567,  1.7027,  1.7691,  1.6633,  2.0813,  1.7088,  3.2711,  1.7788,
          1.6268,  2.9796,  1.2533,  1.3087,  1.1832,  1.2690,  1.4294,  1.4595,
          1.4175,  1.4589,  1.4589,  1.3822,  1.2590,  1.4907,  1.4615,  1.2079,
          1.4923,  1.4922,  1.4523,  1.4838,  1.8455,  1.8868,  1.8324,  1.8016,
          1.8557,  1.8822,  1.8331,  1.1203,  1.8532,  1.4699,  1.7609,  1.7571,
          1.7511,  1.4447,  1.7540,  1.3137,  1.7503,  1.7515],
        [ 1.3589,  1.3601,  1.3630,  1.3611,  1.3606,  1.3596,  1.3556,  1.3589,
          1.3589,  1.4201,  1.4223,  1.4237,  1.4247,  1.4175,  1.3787,  1.4205,
          1.4075,  1.3499,  2.0940,  2.0962,  2.1716,  2.1429,  2.0191,  2.0571,
          2.1034,  2.0141,  2.0141,  1.3954,  1.3575,  1.3979,  1.4009,  1.3939,
          1.3996,  1.4021,  1.3976,  1.3982,  1.7581,  1.7654,  1.7613,  1.7493,
          1.7600,  1.7584,  1.7593,  1.6583,  1.7574,  1.6652,  1.6820,  1.6778,
          1.6703,  1.6000,  1.6760,  1.6667,  1.6700,  1.6701],
        [ 1.3742,  1.3759,  1.3307,  1.3275,  1.3757,  1.3746,  1.3741,  1.3742,
          1.3742,  1.4281,  1.3889,  1.4312,  1.4151,  1.4251,  1.3412,  1.4285,
          1.4253,  1.2813,  1.3889,  1.3798,  1.3920,  1.3908,  1.3856,  1.3747,
          1.3886,  1.3841,  1.3841,  2.2787,  2.1060,  1.9370,  2.0218,  2.2699,
          1.9458,  2.2431,  1.9490,  1.9382,  1.7782,  1.7829,  1.7566,  1.7762,
          1.7784,  1.7734,  1.7741,  1.6020,  1.7709,  1.7099,  1.6771,  1.5707,
          1.6244,  1.7042,  1.6271,  1.7210,  1.6241,  1.6831],
        [ 1.7082,  1.3763,  0.5075,  0.7656,  1.1571,  1.5965,  1.5282,  1.7083,
          1.7083,  1.6159,  1.2768,  1.4265,  0.8612,  1.6901,  0.0966,  1.5894,
          1.7104,  1.0103,  1.2964,  0.8292,  0.6495,  1.0839,  1.5682,  1.6458,
          1.3415,  1.7236,  1.7236,  0.6620,  0.7262,  1.6731,  1.4447,  0.7843,
          1.6481,  1.0910,  1.7202,  1.6405,  0.5810,  0.2029,  0.1439,  0.5057,
          1.0535,  1.3181,  0.3950,  5.4233,  4.6442,  0.0828,  0.4228,  0.4566,
          0.5697,  0.2660,  0.5757, -0.1951,  0.5827,  0.6640],
        [ 1.3687,  1.4011,  1.4481,  1.4364,  1.4167,  1.3816,  1.3461,  1.3685,
          1.3685,  1.2962,  1.3930,  1.3049,  1.4459,  1.3652,  1.4765,  1.2953,
          1.3650,  1.3244,  1.4113,  1.4398,  1.4441,  1.4238,  1.3832,  1.3674,
          1.3412,  1.3651,  1.3651,  1.4396,  1.4684,  1.3919,  1.2424,  1.3434,
          1.2397,  1.4441,  1.2726,  1.3951,  0.3468,  0.2764,  0.4038,  0.3554,
          0.1561,  0.1047,  0.3680,  0.2267,  0.0137,  2.4686,  1.8085,  2.2034,
          2.0452,  1.5398,  1.1593,  2.3612,  1.9873,  1.1292]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 74 : 177.85724047560848
Test loss for epoch 74 : 177.63016501789724
Test Precision for epoch 74 : 0.26153846153846155
Test Recall for epoch 74 : 0.26153846153846155
Test F1 for epoch 74 : 0.26153846153846155


theta for epoch 75 : tensor([[ 2.0359,  2.0525,  2.0906,  2.1476,  2.1285,  2.0403,  2.1117,  2.0358,
          2.0358,  1.4038,  1.4064,  1.4071,  1.4096,  1.4014,  1.4127,  1.4042,
          1.4016,  1.3638,  1.3589,  1.3188,  1.3179,  1.3603,  1.3558,  1.3550,
          1.3581,  1.3543,  1.3543,  1.3470,  1.3932,  1.3860,  1.3890,  1.3917,
          1.3876,  1.3890,  1.3426,  1.3863,  1.7489,  1.7561,  1.7523,  1.7489,
          1.7506,  1.6917,  1.7504,  1.7380,  1.7500,  1.6828,  1.6669,  1.6629,
          1.6554,  1.6784,  1.6601,  1.6916,  1.6552,  1.6551],
        [ 1.4082,  1.2732,  1.1261,  1.3340,  1.4265,  1.4532,  1.3696,  1.4528,
          1.4528,  1.7086,  1.7737,  1.6687,  2.0791,  1.7153,  3.2670,  1.7842,
          1.6323,  2.9800,  1.2526,  1.3079,  1.1838,  1.2669,  1.4271,  1.4562,
          1.4142,  1.4556,  1.4556,  1.3793,  1.2568,  1.4865,  1.4581,  1.2067,
          1.4884,  1.4886,  1.4484,  1.4803,  1.8431,  1.8822,  1.8280,  1.7977,
          1.8531,  1.8777,  1.8286,  1.1204,  1.8501,  1.4675,  1.7515,  1.7475,
          1.7397,  1.4415,  1.7437,  1.3138,  1.7395,  1.7399],
        [ 1.3567,  1.3580,  1.3611,  1.3590,  1.3582,  1.3574,  1.3532,  1.3567,
          1.3567,  1.4183,  1.4206,  1.4217,  1.4227,  1.4157,  1.3773,  1.4186,
          1.4060,  1.3484,  2.0981,  2.0991,  2.1746,  2.1459,  2.0224,  2.0602,
          2.1062,  2.0173,  2.0173,  1.3937,  1.3559,  1.3960,  1.3992,  1.3922,
          1.3979,  1.4004,  1.3958,  1.3963,  1.7536,  1.7608,  1.7569,  1.7450,
          1.7554,  1.7538,  1.7549,  1.6541,  1.7525,  1.6627,  1.6791,  1.6749,
          1.6667,  1.5981,  1.6727,  1.6654,  1.6666,  1.6664],
        [ 1.3708,  1.3726,  1.3295,  1.3262,  1.3724,  1.3712,  1.3707,  1.3708,
          1.3708,  1.4248,  1.3875,  1.4281,  1.4123,  1.4219,  1.3375,  1.4253,
          1.4221,  1.2804,  1.3852,  1.3765,  1.3881,  1.3871,  1.3821,  1.3719,
          1.3849,  1.3806,  1.3806,  2.2806,  2.1139,  1.9439,  2.0286,  2.2724,
          1.9528,  2.2454,  1.9561,  1.9452,  1.7722,  1.7772,  1.7512,  1.7705,
          1.7722,  1.7678,  1.7679,  1.6004,  1.7652,  1.7055,  1.6723,  1.5648,
          1.6180,  1.6996,  1.6229,  1.7174,  1.6179,  1.6767],
        [ 1.7084,  1.3755,  0.5067,  0.7650,  1.1568,  1.5968,  1.5283,  1.7084,
          1.7084,  1.6133,  1.2720,  1.4233,  0.8575,  1.6880,  0.0936,  1.5856,
          1.7085,  1.0033,  1.2958,  0.8295,  0.6495,  1.0847,  1.5688,  1.6459,
          1.3427,  1.7246,  1.7246,  0.6622,  0.7271,  1.6728,  1.4455,  0.7821,
          1.6464,  1.0913,  1.7200,  1.6398,  0.5713,  0.1951,  0.1372,  0.4966,
          1.0418,  1.3054,  0.3852,  5.4903,  4.6883,  0.0802,  0.4204,  0.4539,
          0.5654,  0.2631,  0.5714, -0.1959,  0.5794,  0.6598],
        [ 1.3692,  1.4018,  1.4490,  1.4373,  1.4170,  1.3818,  1.3466,  1.3689,
          1.3689,  1.2966,  1.3944,  1.3069,  1.4468,  1.3647,  1.4778,  1.2961,
          1.3647,  1.3264,  1.4136,  1.4425,  1.4471,  1.4265,  1.3854,  1.3699,
          1.3437,  1.3673,  1.3673,  1.4401,  1.4689,  1.3919,  1.2424,  1.3460,
          1.2415,  1.4449,  1.2725,  1.3953,  0.3526,  0.2820,  0.4095,  0.3613,
          0.1618,  0.1103,  0.3738,  0.2363,  0.0207,  2.4690,  1.8081,  2.2071,
          2.0457,  1.5363,  1.1579,  2.3597,  1.9905,  1.1278]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 75 : 177.82372447335734
Test loss for epoch 75 : 177.5998631827652
Test Precision for epoch 75 : 0.26153846153846155
Test Recall for epoch 75 : 0.26153846153846155
Test F1 for epoch 75 : 0.26153846153846155


theta for epoch 76 : tensor([[ 2.0395,  2.0556,  2.0934,  2.1510,  2.1318,  2.0437,  2.1156,  2.0393,
          2.0393,  1.4025,  1.4051,  1.4058,  1.4084,  1.4001,  1.4115,  1.4029,
          1.4004,  1.3625,  1.3580,  1.3179,  1.3169,  1.3592,  1.3548,  1.3540,
          1.3570,  1.3533,  1.3533,  1.3437,  1.3902,  1.3826,  1.3858,  1.3887,
          1.3844,  1.3858,  1.3392,  1.3829,  1.7442,  1.7513,  1.7476,  1.7442,
          1.7458,  1.6867,  1.7457,  1.7334,  1.7450,  1.6806,  1.6640,  1.6600,
          1.6519,  1.6760,  1.6570,  1.6898,  1.6518,  1.6514],
        [ 1.4034,  1.2698,  1.1244,  1.3308,  1.4233,  1.4485,  1.3650,  1.4480,
          1.4480,  1.7150,  1.7791,  1.6747,  2.0778,  1.7223,  3.2632,  1.7901,
          1.6384,  2.9810,  1.2529,  1.3081,  1.1853,  1.2658,  1.4258,  1.4538,
          1.4118,  1.4532,  1.4532,  1.3757,  1.2536,  1.4817,  1.4541,  1.2049,
          1.4838,  1.4842,  1.4438,  1.4761,  1.8400,  1.8771,  1.8231,  1.7932,
          1.8499,  1.8727,  1.8236,  1.1201,  1.8464,  1.4663,  1.7436,  1.7394,
          1.7300,  1.4397,  1.7348,  1.3150,  1.7301,  1.7300],
        [ 1.3539,  1.3553,  1.3586,  1.3563,  1.3552,  1.3546,  1.3502,  1.3539,
          1.3539,  1.4175,  1.4199,  1.4208,  1.4218,  1.4150,  1.3768,  1.4178,
          1.4055,  1.3479,  2.1018,  2.1015,  2.1772,  2.1486,  2.0253,  2.0627,
          2.1087,  2.0199,  2.0199,  1.3915,  1.3540,  1.3936,  1.3970,  1.3901,
          1.3956,  1.3982,  1.3934,  1.3940,  1.7492,  1.7563,  1.7525,  1.7408,
          1.7509,  1.7493,  1.7505,  1.6500,  1.7477,  1.6613,  1.6772,  1.6730,
          1.6643,  1.5973,  1.6706,  1.6652,  1.6643,  1.6639],
        [ 1.3667,  1.3687,  1.3277,  1.3244,  1.3685,  1.3672,  1.3667,  1.3667,
          1.3667,  1.4224,  1.3870,  1.4259,  1.4105,  1.4196,  1.3347,  1.4229,
          1.4198,  1.2803,  1.3827,  1.3741,  1.3853,  1.3844,  1.3798,  1.3700,
          1.3824,  1.3782,  1.3782,  2.2819,  2.1210,  1.9499,  2.0347,  2.2742,
          1.9589,  2.2470,  1.9624,  1.9513,  1.7662,  1.7715,  1.7457,  1.7649,
          1.7662,  1.7622,  1.7616,  1.5989,  1.7596,  1.7020,  1.6685,  1.5601,
          1.6128,  1.6959,  1.6200,  1.7146,  1.6128,  1.6713],
        [ 1.7102,  1.3771,  0.5097,  0.7678,  1.1594,  1.5991,  1.5304,  1.7102,
          1.7102,  1.6142,  1.2716,  1.4239,  0.8587,  1.6893,  0.0962,  1.5854,
          1.7099,  1.0015,  1.2990,  0.8342,  0.6543,  1.0896,  1.5728,  1.6494,
          1.3476,  1.7287,  1.7287,  0.6670,  0.7325,  1.6754,  1.4496,  0.7844,
          1.6476,  1.0957,  1.7227,  1.6421,  0.5575,  0.1838,  0.1269,  0.4834,
          1.0254,  1.2876,  0.3715,  5.5535,  4.7274,  0.0840,  0.4242,  0.4577,
          0.5681,  0.2666,  0.5739, -0.1906,  0.5829,  0.6625],
        [ 1.3648,  1.3977,  1.4452,  1.4335,  1.4126,  1.3771,  1.3422,  1.3645,
          1.3645,  1.2915,  1.3905,  1.3032,  1.4423,  1.3590,  1.4736,  1.2914,
          1.3592,  1.3226,  1.4099,  1.4393,  1.4443,  1.4232,  1.3816,  1.3663,
          1.3400,  1.3635,  1.3635,  1.4356,  1.4646,  1.3869,  1.2372,  1.3434,
          1.2381,  1.4408,  1.2672,  1.3905,  0.3514,  0.2806,  0.4083,  0.3602,
          0.1602,  0.1087,  0.3728,  0.2384,  0.0204,  2.4781,  1.8163,  2.2196,
          2.0549,  1.5413,  1.1649,  2.3667,  2.0025,  1.1347]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 76 : 177.7910259030035
Test loss for epoch 76 : 177.56244475068053
Test Precision for epoch 76 : 0.26153846153846155
Test Recall for epoch 76 : 0.26153846153846155
Test F1 for epoch 76 : 0.26153846153846155


theta for epoch 77 : tensor([[ 2.0420,  2.0577,  2.0953,  2.1535,  2.1342,  2.0462,  2.1185,  2.0419,
          2.0419,  1.4017,  1.4043,  1.4050,  1.4076,  1.3994,  1.4108,  1.4022,
          1.3996,  1.3617,  1.3568,  1.3167,  1.3157,  1.3580,  1.3536,  1.3529,
          1.3558,  1.3522,  1.3522,  1.3402,  1.3868,  1.3789,  1.3823,  1.3853,
          1.3807,  1.3823,  1.3355,  1.3792,  1.7409,  1.7480,  1.7443,  1.7409,
          1.7425,  1.6834,  1.7425,  1.7304,  1.7415,  1.6787,  1.6615,  1.6575,
          1.6489,  1.6740,  1.6542,  1.6883,  1.6489,  1.6483],
        [ 1.3984,  1.2665,  1.1226,  1.3275,  1.4200,  1.4436,  1.3603,  1.4431,
          1.4431,  1.7211,  1.7844,  1.6804,  2.0767,  1.7290,  3.2589,  1.7957,
          1.6442,  2.9815,  1.2525,  1.3076,  1.1864,  1.2641,  1.4238,  1.4508,
          1.4088,  1.4503,  1.4503,  1.3715,  1.2497,  1.4762,  1.4494,  1.2026,
          1.4786,  1.4791,  1.4386,  1.4713,  1.8377,  1.8731,  1.8191,  1.7896,
          1.8476,  1.8687,  1.8195,  1.1206,  1.8437,  1.4656,  1.7363,  1.7319,
          1.7212,  1.4384,  1.7267,  1.3165,  1.7216,  1.7208],
        [ 1.3510,  1.3525,  1.3560,  1.3536,  1.3522,  1.3518,  1.3472,  1.3510,
          1.3510,  1.4168,  1.4194,  1.4199,  1.4209,  1.4145,  1.3762,  1.4171,
          1.4052,  1.3476,  2.1045,  2.1032,  2.1791,  2.1503,  2.0271,  2.0643,
          2.1103,  2.0215,  2.0215,  1.3886,  1.3513,  1.3906,  1.3942,  1.3873,
          1.3926,  1.3953,  1.3904,  1.3909,  1.7462,  1.7533,  1.7496,  1.7380,
          1.7479,  1.7464,  1.7476,  1.6473,  1.7443,  1.6600,  1.6755,  1.6713,
          1.6621,  1.5968,  1.6685,  1.6651,  1.6621,  1.6615],
        [ 1.3629,  1.3650,  1.3260,  1.3227,  1.3648,  1.3633,  1.3629,  1.3628,
          1.3628,  1.4208,  1.3873,  1.4244,  1.4093,  1.4181,  1.3327,  1.4212,
          1.4183,  1.2810,  1.3800,  1.3717,  1.3824,  1.3817,  1.3773,  1.3681,
          1.3798,  1.3757,  1.3757,  2.2815,  2.1263,  1.9541,  2.0389,  2.2742,
          1.9631,  2.2469,  1.9668,  1.9556,  1.7618,  1.7675,  1.7418,  1.7608,
          1.7618,  1.7582,  1.7570,  1.5990,  1.7556,  1.6990,  1.6653,  1.5561,
          1.6083,  1.6927,  1.6177,  1.7123,  1.6084,  1.6666],
        [ 1.7094,  1.3755,  0.5085,  0.7669,  1.1585,  1.5986,  1.5297,  1.7094,
          1.7094,  1.6121,  1.2675,  1.4214,  0.8558,  1.6877,  0.0939,  1.5822,
          1.7085,  0.9958,  1.2981,  0.8342,  0.6538,  1.0900,  1.5730,  1.6492,
          1.3487,  1.7293,  1.7293,  0.6666,  0.7327,  1.6742,  1.4496,  0.7814,
          1.6450,  1.0953,  1.7217,  1.6406,  0.5481,  0.1766,  0.1206,  0.4746,
          1.0135,  1.2743,  0.3622,  5.6207,  4.7707,  0.0812,  0.4220,  0.4555,
          0.5649,  0.2637,  0.5706, -0.1920,  0.5805,  0.6595],
        [ 1.3627,  1.3959,  1.4438,  1.4321,  1.4105,  1.3748,  1.3401,  1.3624,
          1.3624,  1.2914,  1.3913,  1.3045,  1.4424,  1.3581,  1.4740,  1.2916,
          1.3585,  1.3236,  1.4099,  1.4396,  1.4448,  1.4234,  1.3815,  1.3665,
          1.3400,  1.3635,  1.3635,  1.4331,  1.4623,  1.3840,  1.2343,  1.3430,
          1.2371,  1.4386,  1.2642,  1.3878,  0.3547,  0.2841,  0.4116,  0.3637,
          0.1637,  0.1122,  0.3762,  0.2446,  0.0252,  2.4815,  1.8188,  2.2263,
          2.0582,  1.5408,  1.1665,  2.3680,  2.0088,  1.1362]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 77 : 177.75865340496622
Test loss for epoch 77 : 177.53172109591054
Test Precision for epoch 77 : 0.26153846153846155
Test Recall for epoch 77 : 0.26153846153846155
Test F1 for epoch 77 : 0.26153846153846155


theta for epoch 78 : tensor([[ 2.0447,  2.0600,  2.0974,  2.1561,  2.1368,  2.0489,  2.1215,  2.0445,
          2.0445,  1.3996,  1.4021,  1.4028,  1.4055,  1.3972,  1.4086,  1.4000,
          1.3975,  1.3595,  1.3537,  1.3136,  1.3126,  1.3548,  1.3505,  1.3498,
          1.3526,  1.3491,  1.3491,  1.3369,  1.3836,  1.3754,  1.3790,  1.3821,
          1.3774,  1.3790,  1.3321,  1.3758,  1.7385,  1.7456,  1.7420,  1.7386,
          1.7401,  1.6810,  1.7401,  1.7282,  1.7390,  1.6781,  1.6604,  1.6564,
          1.6473,  1.6732,  1.6529,  1.6881,  1.6474,  1.6466],
        [ 1.3941,  1.2640,  1.1215,  1.3248,  1.4172,  1.4394,  1.3563,  1.4388,
          1.4388,  1.7260,  1.7886,  1.6849,  2.0748,  1.7346,  3.2535,  1.8000,
          1.6489,  2.9809,  1.2502,  1.3053,  1.1857,  1.2606,  1.4200,  1.4459,
          1.4040,  1.4455,  1.4455,  1.3677,  1.2460,  1.4712,  1.4452,  1.2008,
          1.4737,  1.4744,  1.4338,  1.4668,  1.8358,  1.8696,  1.8156,  1.7865,
          1.8456,  1.8653,  1.8159,  1.1218,  1.8415,  1.4668,  1.7311,  1.7267,
          1.7146,  1.4392,  1.7209,  1.3198,  1.7153,  1.7141],
        [ 1.3484,  1.3500,  1.3537,  1.3511,  1.3495,  1.3491,  1.3445,  1.3483,
          1.3483,  1.4140,  1.4167,  1.4170,  1.4179,  1.4118,  1.3735,  1.4143,
          1.4027,  1.3452,  2.1069,  2.1047,  2.1808,  2.1520,  2.0287,  2.0656,
          2.1117,  2.0229,  2.0229,  1.3857,  1.3487,  1.3875,  1.3912,  1.3844,
          1.3896,  1.3924,  1.3874,  1.3879,  1.7441,  1.7511,  1.7474,  1.7360,
          1.7457,  1.7442,  1.7454,  1.6454,  1.7417,  1.6597,  1.6747,  1.6705,
          1.6609,  1.5972,  1.6676,  1.6658,  1.6610,  1.6601],
        [ 1.3597,  1.3620,  1.3251,  1.3217,  1.3618,  1.3601,  1.3598,  1.3597,
          1.3597,  1.4180,  1.3863,  1.4216,  1.4070,  1.4154,  1.3295,  1.4184,
          1.4156,  1.2805,  1.3759,  1.3677,  1.3780,  1.3775,  1.3733,  1.3647,
          1.3757,  1.3717,  1.3717,  2.2806,  2.1309,  1.9576,  2.0425,  2.2737,
          1.9667,  2.2461,  1.9705,  1.9592,  1.7584,  1.7645,  1.7390,  1.7577,
          1.7585,  1.7553,  1.7534,  1.6003,  1.7527,  1.6975,  1.6636,  1.5538,
          1.6054,  1.6909,  1.6171,  1.7113,  1.6056,  1.6634],
        [ 1.7102,  1.3758,  0.5097,  0.7681,  1.1597,  1.5997,  1.5307,  1.7102,
          1.7102,  1.6107,  1.2647,  1.4199,  0.8546,  1.6867,  0.0937,  1.5799,
          1.7077,  0.9921,  1.2980,  0.8354,  0.6547,  1.0914,  1.5737,  1.6496,
          1.3505,  1.7302,  1.7302,  0.6688,  0.7355,  1.6751,  1.4517,  0.7810,
          1.6445,  1.0974,  1.7226,  1.6413,  0.5370,  0.1680,  0.1129,  0.4640,
          0.9994,  1.2586,  0.3512,  5.6861,  4.8116,  0.0818,  0.4234,  0.4569,
          0.5658,  0.2644,  0.5713, -0.1903,  0.5820,  0.6606],
        [ 1.3590,  1.3925,  1.4409,  1.4291,  1.4069,  1.3709,  1.3364,  1.3587,
          1.3587,  1.2873,  1.3882,  1.3016,  1.4385,  1.3535,  1.4702,  1.2879,
          1.3540,  1.3203,  1.4051,  1.4351,  1.4406,  1.4188,  1.3767,  1.3620,
          1.3353,  1.3588,  1.3588,  1.4287,  1.4581,  1.3791,  1.2293,  1.3406,
          1.2341,  1.4344,  1.2592,  1.3831,  0.3549,  0.2848,  0.4119,  0.3640,
          0.1642,  0.1126,  0.3766,  0.2472,  0.0268,  2.4891,  1.8256,  2.2373,
          2.0658,  1.5447,  1.1722,  2.3735,  2.0195,  1.1419]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 78 : 177.7276980897068
Test loss for epoch 78 : 177.49872257785276
Test Precision for epoch 78 : 0.26153846153846155
Test Recall for epoch 78 : 0.26153846153846155
Test F1 for epoch 78 : 0.26153846153846155


theta for epoch 79 : tensor([[ 2.0482,  2.0632,  2.1004,  2.1595,  2.1402,  2.0523,  2.1253,  2.0480,
          2.0480,  1.3963,  1.3987,  1.3994,  1.4021,  1.3940,  1.4053,  1.3967,
          1.3943,  1.3561,  1.3499,  1.3098,  1.3089,  1.3509,  1.3468,  1.3461,
          1.3488,  1.3454,  1.3454,  1.3341,  1.3809,  1.3725,  1.3762,  1.3794,
          1.3745,  1.3763,  1.3292,  1.3729,  1.7366,  1.7437,  1.7401,  1.7367,
          1.7382,  1.6792,  1.7382,  1.7265,  1.7369,  1.6765,  1.6582,  1.6542,
          1.6448,  1.6714,  1.6506,  1.6868,  1.6449,  1.6439],
        [ 1.3902,  1.2619,  1.1207,  1.3224,  1.4147,  1.4356,  1.3527,  1.4349,
          1.4349,  1.7310,  1.7930,  1.6895,  2.0733,  1.7401,  3.2480,  1.8043,
          1.6536,  2.9804,  1.2475,  1.3024,  1.1845,  1.2565,  1.4156,  1.4406,
          1.3987,  1.4403,  1.4403,  1.3646,  1.2429,  1.4669,  1.4417,  1.1997,
          1.4696,  1.4705,  1.4297,  1.4630,  1.8338,  1.8663,  1.8122,  1.7834,
          1.8436,  1.8620,  1.8123,  1.1231,  1.8395,  1.4672,  1.7255,  1.7209,
          1.7078,  1.4392,  1.7147,  1.3221,  1.7087,  1.7070],
        [ 1.3456,  1.3474,  1.3512,  1.3486,  1.3466,  1.3463,  1.3417,  1.3455,
          1.3455,  1.4093,  1.4120,  1.4121,  1.4129,  1.4072,  1.3687,  1.4095,
          1.3982,  1.3408,  2.1115,  2.1084,  2.1848,  2.1558,  2.0325,  2.0690,
          2.1153,  2.0265,  2.0265,  1.3829,  1.3460,  1.3844,  1.3883,  1.3816,
          1.3866,  1.3894,  1.3844,  1.3848,  1.7421,  1.7492,  1.7455,  1.7342,
          1.7438,  1.7424,  1.7435,  1.6438,  1.7394,  1.6577,  1.6723,  1.6681,
          1.6582,  1.5960,  1.6650,  1.6649,  1.6583,  1.6573],
        [ 1.3569,  1.3593,  1.3245,  1.3212,  1.3591,  1.3574,  1.3571,  1.3569,
          1.3569,  1.4143,  1.3845,  1.4179,  1.4038,  1.4119,  1.3254,  1.4147,
          1.4120,  1.2790,  1.3714,  1.3633,  1.3733,  1.3729,  1.3690,  1.3609,
          1.3712,  1.3675,  1.3675,  2.2804,  2.1361,  1.9617,  2.0467,  2.2739,
          1.9709,  2.2461,  1.9749,  1.9634,  1.7556,  1.7620,  1.7367,  1.7551,
          1.7558,  1.7529,  1.7503,  1.6020,  1.7505,  1.6950,  1.6611,  1.5508,
          1.6019,  1.6883,  1.6159,  1.7093,  1.6022,  1.6596],
        [ 1.7112,  1.3762,  0.5110,  0.7695,  1.1611,  1.6011,  1.5319,  1.7112,
          1.7112,  1.6088,  1.2613,  1.4181,  0.8529,  1.6852,  0.0930,  1.5771,
          1.7065,  0.9880,  1.2975,  0.8361,  0.6550,  1.0923,  1.5739,  1.6495,
          1.3519,  1.7307,  1.7307,  0.6711,  0.7385,  1.6767,  1.4543,  0.7808,
          1.6446,  1.0999,  1.7243,  1.6428,  0.5263,  0.1599,  0.1056,  0.4539,
          0.9857,  1.2431,  0.3409,  5.7520,  4.8525,  0.0813,  0.4236,  0.4573,
          0.5659,  0.2640,  0.5712, -0.1901,  0.5827,  0.6610],
        [ 1.3569,  1.3907,  1.4395,  1.4276,  1.4048,  1.3685,  1.3344,  1.3565,
          1.3565,  1.2850,  1.3868,  1.3004,  1.4361,  1.3507,  1.4678,  1.2859,
          1.3514,  1.3188,  1.4021,  1.4323,  1.4379,  1.4159,  1.3738,  1.3594,
          1.3324,  1.3560,  1.3560,  1.4261,  1.4558,  1.3761,  1.2264,  1.3401,
          1.2332,  1.4320,  1.2563,  1.3803,  0.3566,  0.2871,  0.4136,  0.3659,
          0.1664,  0.1149,  0.3786,  0.2509,  0.0301,  2.4940,  1.8296,  2.2456,
          2.0707,  1.5459,  1.1753,  2.3763,  2.0274,  1.1449]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 79 : 177.69797219801882
Test loss for epoch 79 : 177.468998205671
Test Precision for epoch 79 : 0.26153846153846155
Test Recall for epoch 79 : 0.26153846153846155
Test F1 for epoch 79 : 0.26153846153846155


theta for epoch 80 : tensor([[ 2.0520,  2.0667,  2.1038,  2.1634,  2.1441,  2.0561,  2.1295,  2.0519,
          2.0519,  1.3935,  1.3959,  1.3966,  1.3993,  1.3913,  1.4025,  1.3939,
          1.3916,  1.3533,  1.3465,  1.3064,  1.3057,  1.3475,  1.3435,  1.3428,
          1.3455,  1.3422,  1.3422,  1.3317,  1.3784,  1.3699,  1.3737,  1.3770,
          1.3720,  1.3739,  1.3267,  1.3704,  1.7345,  1.7416,  1.7380,  1.7347,
          1.7363,  1.6772,  1.7361,  1.7247,  1.7348,  1.6735,  1.6549,  1.6508,
          1.6411,  1.6683,  1.6471,  1.6842,  1.6413,  1.6401],
        [ 1.3862,  1.2598,  1.1198,  1.3199,  1.4121,  1.4315,  1.3490,  1.4308,
          1.4308,  1.7372,  1.7988,  1.6954,  2.0734,  1.7468,  3.2434,  1.8099,
          1.6596,  2.9808,  1.2451,  1.3000,  1.1838,  1.2528,  1.4117,  1.4358,
          1.3939,  1.4355,  1.4355,  1.3619,  1.2400,  1.4631,  1.4387,  1.1991,
          1.4659,  1.4668,  1.4261,  1.4595,  1.8313,  1.8626,  1.8084,  1.7799,
          1.8411,  1.8584,  1.8083,  1.1241,  1.8369,  1.4664,  1.7190,  1.7143,
          1.7005,  1.4382,  1.7077,  1.3232,  1.7015,  1.6994],
        [ 1.3423,  1.3442,  1.3482,  1.3455,  1.3433,  1.3431,  1.3385,  1.3422,
          1.3422,  1.4046,  1.4074,  1.4072,  1.4080,  1.4027,  1.3639,  1.4048,
          1.3937,  1.3364,  2.1182,  2.1144,  2.1910,  2.1619,  2.0384,  2.0746,
          2.1211,  2.0322,  2.0322,  1.3800,  1.3434,  1.3814,  1.3853,  1.3787,
          1.3836,  1.3865,  1.3814,  1.3818,  1.7399,  1.7471,  1.7433,  1.7321,
          1.7417,  1.7403,  1.7413,  1.6419,  1.7368,  1.6541,  1.6683,  1.6641,
          1.6540,  1.5931,  1.6609,  1.6622,  1.6541,  1.6529],
        [ 1.3541,  1.3566,  1.3238,  1.3206,  1.3565,  1.3546,  1.3544,  1.3541,
          1.3541,  1.4114,  1.3834,  1.4149,  1.4014,  1.4092,  1.3222,  1.4118,
          1.4093,  1.2783,  1.3676,  1.3596,  1.3693,  1.3691,  1.3654,  1.3577,
          1.3674,  1.3638,  1.3638,  2.2808,  2.1419,  1.9663,  2.0515,  2.2747,
          1.9755,  2.2467,  1.9798,  1.9681,  1.7527,  1.7596,  1.7343,  1.7524,
          1.7532,  1.7505,  1.7471,  1.6037,  1.7482,  1.6915,  1.6576,  1.5470,
          1.5976,  1.6847,  1.6139,  1.7062,  1.5979,  1.6549],
        [ 1.7126,  1.3770,  0.5127,  0.7714,  1.1631,  1.6028,  1.5334,  1.7125,
          1.7125,  1.6080,  1.2592,  1.4174,  0.8523,  1.6847,  0.0933,  1.5755,
          1.7063,  0.9854,  1.2977,  0.8375,  0.6560,  1.0938,  1.5750,  1.6503,
          1.3541,  1.7320,  1.7320,  0.6744,  0.7424,  1.6795,  1.4580,  0.7816,
          1.6459,  1.1034,  1.7271,  1.6455,  0.5152,  0.1514,  0.0980,  0.4433,
          0.9711,  1.2267,  0.3301,  5.8175,  4.8923,  0.0809,  0.4241,  0.4579,
          0.5665,  0.2638,  0.5715, -0.1899,  0.5837,  0.6618],
        [ 1.3552,  1.3892,  1.4384,  1.4265,  1.4031,  1.3666,  1.3327,  1.3548,
          1.3548,  1.2847,  1.3872,  1.3009,  1.4355,  1.3498,  1.4671,  1.2858,
          1.3507,  1.3189,  1.4005,  1.4306,  1.4365,  1.4143,  1.3723,  1.3583,
          1.3308,  1.3547,  1.3547,  1.4244,  1.4543,  1.3741,  1.2245,  1.3405,
          1.2332,  1.4304,  1.2543,  1.3784,  0.3581,  0.2895,  0.4152,  0.3676,
          0.1687,  0.1174,  0.3804,  0.2539,  0.0335,  2.4977,  1.8324,  2.2527,
          2.0742,  1.5461,  1.1772,  2.3779,  2.0342,  1.1468]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 80 : 177.66879952977015
Test loss for epoch 80 : 177.44019456083518
Test Precision for epoch 80 : 0.26153846153846155
Test Recall for epoch 80 : 0.26153846153846155
Test F1 for epoch 80 : 0.26153846153846155


theta for epoch 81 : tensor([[ 2.0556,  2.0700,  2.1070,  2.1669,  2.1476,  2.0597,  2.1334,  2.0554,
          2.0554,  1.3920,  1.3944,  1.3949,  1.3977,  1.3899,  1.4008,  1.3924,
          1.3902,  1.3517,  1.3436,  1.3036,  1.3030,  1.3446,  1.3408,  1.3401,
          1.3427,  1.3395,  1.3395,  1.3295,  1.3761,  1.3675,  1.3713,  1.3748,
          1.3696,  1.3716,  1.3243,  1.3679,  1.7322,  1.7395,  1.7358,  1.7324,
          1.7342,  1.6752,  1.7338,  1.7226,  1.7325,  1.6710,  1.6520,  1.6479,
          1.6380,  1.6656,  1.6441,  1.6820,  1.6381,  1.6369],
        [ 1.3820,  1.2577,  1.1189,  1.3172,  1.4092,  1.4274,  1.3452,  1.4266,
          1.4266,  1.7439,  1.8051,  1.7018,  2.0743,  1.7541,  3.2392,  1.8159,
          1.6661,  2.9817,  1.2434,  1.2982,  1.1837,  1.2497,  1.4084,  1.4316,
          1.3897,  1.4314,  1.4314,  1.3594,  1.2371,  1.4594,  1.4358,  1.1986,
          1.4623,  1.4633,  1.4226,  1.4562,  1.8282,  1.8584,  1.8040,  1.7758,
          1.8380,  1.8542,  1.8038,  1.1248,  1.8339,  1.4663,  1.7135,  1.7088,
          1.6944,  1.4379,  1.7020,  1.3250,  1.6954,  1.6931],
        [ 1.3390,  1.3410,  1.3452,  1.3424,  1.3400,  1.3398,  1.3353,  1.3389,
          1.3389,  1.4016,  1.4044,  1.4040,  1.4047,  1.3998,  1.3605,  1.4017,
          1.3908,  1.3338,  2.1244,  2.1199,  2.1967,  2.1675,  2.0438,  2.0797,
          2.1265,  2.0374,  2.0374,  1.3773,  1.3409,  1.3785,  1.3825,  1.3761,
          1.3808,  1.3837,  1.3785,  1.3790,  1.7375,  1.7448,  1.7410,  1.7298,
          1.7395,  1.7382,  1.7390,  1.6398,  1.7340,  1.6510,  1.6647,  1.6606,
          1.6503,  1.5908,  1.6573,  1.6600,  1.6504,  1.6491],
        [ 1.3513,  1.3539,  1.3231,  1.3199,  1.3538,  1.3518,  1.3516,  1.3512,
          1.3512,  1.4101,  1.3838,  1.4134,  1.4005,  1.4080,  1.3206,  1.4104,
          1.4080,  1.2790,  1.3644,  1.3564,  1.3660,  1.3658,  1.3623,  1.3551,
          1.3642,  1.3608,  1.3608,  2.2810,  2.1472,  1.9705,  2.0559,  2.2752,
          1.9798,  2.2470,  1.9842,  1.9723,  1.7496,  1.7569,  1.7317,  1.7495,
          1.7504,  1.7480,  1.7438,  1.6051,  1.7457,  1.6885,  1.6547,  1.5439,
          1.5940,  1.6816,  1.6125,  1.7034,  1.5942,  1.6509],
        [ 1.7144,  1.3784,  0.5154,  0.7741,  1.1657,  1.6050,  1.5355,  1.7143,
          1.7143,  1.6088,  1.2589,  1.4183,  0.8536,  1.6857,  0.0953,  1.5755,
          1.7076,  0.9848,  1.2988,  0.8399,  0.6579,  1.0962,  1.5768,  1.6518,
          1.3572,  1.7340,  1.7340,  0.6788,  0.7473,  1.6832,  1.4626,  0.7836,
          1.6481,  1.1080,  1.7308,  1.6492,  0.5030,  0.1419,  0.0894,  0.4317,
          0.9553,  1.2088,  0.3184,  5.8819,  4.9306,  0.0820,  0.4263,  0.4604,
          0.5691,  0.2653,  0.5738, -0.1884,  0.5866,  0.6647],
        [ 1.3522,  1.3864,  1.4361,  1.4241,  1.4002,  1.3633,  1.3298,  1.3518,
          1.3518,  1.2839,  1.3872,  1.3010,  1.4345,  1.3488,  1.4660,  1.2853,
          1.3498,  1.3185,  1.3974,  1.4274,  1.4334,  1.4111,  1.3693,  1.3555,
          1.3276,  1.3519,  1.3519,  1.4214,  1.4517,  1.3709,  1.2213,  1.3396,
          1.2320,  1.4276,  1.2511,  1.3753,  0.3573,  0.2895,  0.4144,  0.3669,
          0.1686,  0.1174,  0.3798,  0.2539,  0.0341,  2.5037,  1.8376,  2.2621,
          2.0801,  1.5487,  1.1814,  2.3818,  2.0434,  1.1509]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 81 : 177.64160057331728
Test loss for epoch 81 : 177.41114392642862
Test Precision for epoch 81 : 0.26153846153846155
Test Recall for epoch 81 : 0.26153846153846155
Test F1 for epoch 81 : 0.26153846153846155


theta for epoch 82 : tensor([[ 2.0588,  2.0730,  2.1099,  2.1702,  2.1509,  2.0629,  2.1369,  2.0586,
          2.0586,  1.3909,  1.3932,  1.3937,  1.3965,  1.3889,  1.3995,  1.3913,
          1.3891,  1.3505,  1.3413,  1.3013,  1.3009,  1.3423,  1.3386,  1.3379,
          1.3405,  1.3373,  1.3373,  1.3273,  1.3738,  1.3651,  1.3690,  1.3725,
          1.3672,  1.3693,  1.3219,  1.3655,  1.7303,  1.7377,  1.7338,  1.7305,
          1.7324,  1.6735,  1.7319,  1.7209,  1.7306,  1.6689,  1.6497,  1.6456,
          1.6356,  1.6635,  1.6418,  1.6803,  1.6356,  1.6343],
        [ 1.3784,  1.2562,  1.1184,  1.3150,  1.4068,  1.4238,  1.3419,  1.4229,
          1.4229,  1.7497,  1.8105,  1.7073,  2.0746,  1.7604,  3.2339,  1.8210,
          1.6717,  2.9816,  1.2427,  1.2974,  1.1847,  1.2477,  1.4060,  1.4284,
          1.3865,  1.4282,  1.4282,  1.3571,  1.2345,  1.4560,  1.4331,  1.1986,
          1.4590,  1.4601,  1.4194,  1.4531,  1.8251,  1.8545,  1.7998,  1.7719,
          1.8349,  1.8503,  1.7995,  1.1259,  1.8310,  1.4674,  1.7095,  1.7047,
          1.6898,  1.4387,  1.6977,  1.3279,  1.6909,  1.6884],
        [ 1.3364,  1.3386,  1.3429,  1.3401,  1.3375,  1.3373,  1.3328,  1.3364,
          1.3364,  1.3998,  1.4026,  1.4020,  1.4026,  1.3981,  1.3582,  1.3999,
          1.3891,  1.3324,  2.1283,  2.1233,  2.2003,  2.1708,  2.0468,  2.0825,
          2.1296,  2.0403,  2.0403,  1.3751,  1.3389,  1.3761,  1.3802,  1.3739,
          1.3784,  1.3814,  1.3762,  1.3766,  1.7357,  1.7432,  1.7392,  1.7282,
          1.7379,  1.7366,  1.7372,  1.6385,  1.7319,  1.6490,  1.6622,  1.6581,
          1.6477,  1.5895,  1.6547,  1.6587,  1.6477,  1.6464],
        [ 1.3487,  1.3514,  1.3225,  1.3194,  1.3513,  1.3492,  1.3491,  1.3486,
          1.3486,  1.4092,  1.3846,  1.4123,  1.4000,  1.4072,  1.3194,  1.4094,
          1.4072,  1.2800,  1.3619,  1.3539,  1.3633,  1.3631,  1.3599,  1.3530,
          1.3617,  1.3584,  1.3584,  2.2806,  2.1518,  1.9741,  2.0596,  2.2752,
          1.9834,  2.2468,  1.9880,  1.9759,  1.7470,  1.7547,  1.7295,  1.7470,
          1.7480,  1.7458,  1.7409,  1.6068,  1.7437,  1.6860,  1.6525,  1.5416,
          1.5912,  1.6791,  1.6119,  1.7012,  1.5914,  1.6476],
        [ 1.7144,  1.3776,  0.5150,  0.7742,  1.1659,  1.6053,  1.5356,  1.7144,
          1.7144,  1.6074,  1.2559,  1.4171,  0.8518,  1.6847,  0.0935,  1.5735,
          1.7070,  0.9812,  1.2971,  0.8389,  0.6561,  1.0955,  1.5760,  1.6510,
          1.3576,  1.7337,  1.7337,  0.6794,  0.7485,  1.6844,  1.4643,  0.7818,
          1.6477,  1.1091,  1.7320,  1.6504,  0.4937,  0.1353,  0.0835,  0.4230,
          0.9425,  1.1940,  0.3096,  5.9492,  4.9717,  0.0787,  0.4244,  0.4587,
          0.5679,  0.2626,  0.5722, -0.1919,  0.5857,  0.6639],
        [ 1.3508,  1.3852,  1.4354,  1.4232,  1.3989,  1.3618,  1.3285,  1.3504,
          1.3504,  1.2862,  1.3902,  1.3041,  1.4365,  1.3508,  1.4679,  1.2879,
          1.3519,  1.3211,  1.3969,  1.4269,  1.4330,  1.4105,  1.3690,  1.3555,
          1.3271,  1.3517,  1.3517,  1.4200,  1.4506,  1.3693,  1.2199,  1.3404,
          1.2326,  1.4264,  1.2498,  1.3739,  0.3587,  0.2919,  0.4158,  0.3685,
          0.1709,  0.1199,  0.3815,  0.2557,  0.0372,  2.5062,  1.8393,  2.2681,
          2.0825,  1.5480,  1.1824,  2.3823,  2.0492,  1.1518]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 82 : 177.61427373386422
Test loss for epoch 82 : 177.38571773208096
Test Precision for epoch 82 : 0.26153846153846155
Test Recall for epoch 82 : 0.26153846153846155
Test F1 for epoch 82 : 0.26153846153846155


theta for epoch 83 : tensor([[ 2.0620,  2.0761,  2.1128,  2.1735,  2.1542,  2.0661,  2.1405,  2.0619,
          2.0619,  1.3888,  1.3910,  1.3914,  1.3943,  1.3869,  1.3972,  1.3891,
          1.3871,  1.3483,  1.3396,  1.2996,  1.2994,  1.3406,  1.3370,  1.3364,
          1.3388,  1.3357,  1.3357,  1.3253,  1.3715,  1.3629,  1.3668,  1.3703,
          1.3650,  1.3672,  1.3198,  1.3633,  1.7283,  1.7359,  1.7319,  1.7286,
          1.7307,  1.6718,  1.7299,  1.7191,  1.7286,  1.6684,  1.6489,  1.6449,
          1.6348,  1.6629,  1.6411,  1.6801,  1.6348,  1.6334],
        [ 1.3754,  1.2554,  1.1187,  1.3134,  1.4049,  1.4207,  1.3393,  1.4198,
          1.4198,  1.7541,  1.8146,  1.7114,  2.0739,  1.7652,  3.2272,  1.8247,
          1.6760,  2.9801,  1.2431,  1.2977,  1.1869,  1.2469,  1.4046,  1.4262,
          1.3844,  1.4260,  1.4260,  1.3553,  1.2323,  1.4531,  1.4310,  1.1990,
          1.4561,  1.4572,  1.4166,  1.4504,  1.8217,  1.8505,  1.7955,  1.7678,
          1.8316,  1.8463,  1.7950,  1.1271,  1.8280,  1.4707,  1.7079,  1.7030,
          1.6879,  1.4418,  1.6960,  1.3331,  1.6890,  1.6863],
        [ 1.3348,  1.3371,  1.3415,  1.3387,  1.3358,  1.3356,  1.3313,  1.3347,
          1.3347,  1.3976,  1.4004,  1.3996,  1.4003,  1.3960,  1.3556,  1.3977,
          1.3871,  1.3308,  2.1304,  2.1249,  2.2022,  2.1724,  2.0481,  2.0834,
          2.1309,  2.0414,  2.0414,  1.3735,  1.3376,  1.3744,  1.3785,  1.3723,
          1.3767,  1.3796,  1.3744,  1.3748,  1.7341,  1.7418,  1.7377,  1.7267,
          1.7366,  1.7354,  1.7357,  1.6373,  1.7300,  1.6490,  1.6616,  1.6576,
          1.6471,  1.5902,  1.6542,  1.6592,  1.6471,  1.6457],
        [ 1.3464,  1.3493,  1.3222,  1.3192,  1.3492,  1.3470,  1.3469,  1.3464,
          1.3464,  1.4071,  1.3841,  1.4100,  1.3982,  1.4053,  1.3171,  1.4073,
          1.4052,  1.2797,  1.3597,  1.3517,  1.3610,  1.3609,  1.3578,  1.3513,
          1.3595,  1.3564,  1.3564,  2.2806,  2.1566,  1.9778,  2.0635,  2.2755,
          1.9871,  2.2468,  1.9920,  1.9797,  1.7443,  1.7523,  1.7273,  1.7443,
          1.7457,  1.7436,  1.7379,  1.6083,  1.7416,  1.6848,  1.6516,  1.5408,
          1.5899,  1.6779,  1.6127,  1.7002,  1.5900,  1.6459],
        [ 1.7162,  1.3789,  0.5173,  0.7768,  1.1685,  1.6075,  1.5377,  1.7162,
          1.7162,  1.6075,  1.2549,  1.4176,  0.8523,  1.6849,  0.0947,  1.5730,
          1.7077,  0.9801,  1.2976,  0.8405,  0.6571,  1.0972,  1.5773,  1.6521,
          1.3601,  1.7352,  1.7352,  0.6831,  0.7527,  1.6878,  1.4683,  0.7831,
          1.6496,  1.1129,  1.7354,  1.6539,  0.4820,  0.1264,  0.0754,  0.4119,
          0.9268,  1.1760,  0.2985,  6.0140,  5.0096,  0.0801,  0.4273,  0.4620,
          0.5719,  0.2646,  0.5758, -0.1909,  0.5898,  0.6683],
        [ 1.3469,  1.3816,  1.4322,  1.4199,  1.3952,  1.3577,  1.3246,  1.3465,
          1.3465,  1.2830,  1.3880,  1.3016,  1.4332,  1.3476,  1.4643,  1.2849,
          1.3488,  1.3182,  1.3921,  1.4220,  1.4283,  1.4056,  1.3642,  1.3509,
          1.3220,  1.3470,  1.3470,  1.4157,  1.4467,  1.3648,  1.2153,  1.3381,
          1.2301,  1.4222,  1.2453,  1.3695,  0.3553,  0.2895,  0.4125,  0.3652,
          0.1682,  0.1174,  0.3784,  0.2521,  0.0349,  2.5149,  1.8472,  2.2804,
          2.0911,  1.5535,  1.1893,  2.3888,  2.0612,  1.1586]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 83 : 177.58775743387378
Test loss for epoch 83 : 177.35526481985
Test Precision for epoch 83 : 0.26153846153846155
Test Recall for epoch 83 : 0.26153846153846155
Test F1 for epoch 83 : 0.26153846153846155


theta for epoch 84 : tensor([[ 2.0658,  2.0797,  2.1163,  2.1774,  2.1581,  2.0698,  2.1446,  2.0656,
          2.0656,  1.3864,  1.3886,  1.3889,  1.3918,  1.3846,  1.3947,  1.3868,
          1.3848,  1.3458,  1.3390,  1.2991,  1.2991,  1.3400,  1.3365,  1.3359,
          1.3383,  1.3353,  1.3353,  1.3232,  1.3693,  1.3607,  1.3646,  1.3682,
          1.3628,  1.3651,  1.3177,  1.3611,  1.7269,  1.7346,  1.7305,  1.7272,
          1.7295,  1.6708,  1.7285,  1.7178,  1.7273,  1.6661,  1.6464,  1.6424,
          1.6323,  1.6605,  1.6387,  1.6780,  1.6322,  1.6308],
        [ 1.3726,  1.2548,  1.1192,  1.3119,  1.4032,  1.4179,  1.3369,  1.4169,
          1.4169,  1.7593,  1.8195,  1.7164,  2.0742,  1.7709,  3.2212,  1.8292,
          1.6812,  2.9792,  1.2446,  1.2991,  1.1900,  1.2471,  1.4044,  1.4252,
          1.3834,  1.4250,  1.4250,  1.3534,  1.2300,  1.4501,  1.4288,  1.1993,
          1.4532,  1.4544,  1.4138,  1.4476,  1.8186,  1.8468,  1.7915,  1.7640,
          1.8286,  1.8427,  1.7909,  1.1288,  1.8252,  1.4721,  1.7048,  1.6999,
          1.6847,  1.4429,  1.6929,  1.3364,  1.6857,  1.6830],
        [ 1.3334,  1.3358,  1.3403,  1.3375,  1.3345,  1.3343,  1.3301,  1.3333,
          1.3333,  1.3955,  1.3983,  1.3973,  1.3979,  1.3940,  1.3530,  1.3955,
          1.3849,  1.3292,  2.1332,  2.1273,  2.2050,  2.1749,  2.0502,  2.0852,
          2.1331,  2.0433,  2.0433,  1.3719,  1.3362,  1.3727,  1.3768,  1.3708,
          1.3750,  1.3779,  1.3727,  1.3732,  1.7332,  1.7411,  1.7368,  1.7259,
          1.7359,  1.7348,  1.7348,  1.6369,  1.7287,  1.6472,  1.6594,  1.6553,
          1.6449,  1.5892,  1.6520,  1.6580,  1.6448,  1.6434],
        [ 1.3442,  1.3471,  1.3219,  1.3189,  1.3471,  1.3448,  1.3448,  1.3442,
          1.3442,  1.4045,  1.3830,  1.4072,  1.3960,  1.4029,  1.3144,  1.4047,
          1.4028,  1.2789,  1.3584,  1.3504,  1.3597,  1.3595,  1.3565,  1.3503,
          1.3582,  1.3551,  1.3551,  2.2817,  2.1624,  1.9825,  2.0685,  2.2769,
          1.9919,  2.2479,  1.9970,  1.9845,  1.7421,  1.7506,  1.7255,  1.7422,
          1.7439,  1.7419,  1.7355,  1.6102,  1.7400,  1.6819,  1.6490,  1.5383,
          1.5870,  1.6750,  1.6119,  1.6973,  1.5870,  1.6426],
        [ 1.7163,  1.3779,  0.5163,  0.7764,  1.1685,  1.6078,  1.5377,  1.7162,
          1.7162,  1.6051,  1.2507,  1.4154,  0.8492,  1.6827,  0.0915,  1.5701,
          1.7061,  0.9754,  1.2955,  0.8388,  0.6543,  1.0959,  1.5764,  1.6512,
          1.3603,  1.7348,  1.7348,  0.6825,  0.7526,  1.6888,  1.4692,  0.7802,
          1.6489,  1.1131,  1.7364,  1.6548,  0.4740,  0.1209,  0.0706,  0.4043,
          0.9150,  1.1619,  0.2910,  6.0823,  5.0509,  0.0753,  0.4244,  0.4592,
          0.5697,  0.2606,  0.5734, -0.1964,  0.5880,  0.6667],
        [ 1.3471,  1.3819,  1.4330,  1.4206,  1.3955,  1.3578,  1.3249,  1.3466,
          1.3466,  1.2865,  1.3920,  1.3055,  1.4361,  1.3508,  1.4670,  1.2886,
          1.3521,  1.3217,  1.3946,  1.4243,  1.4306,  1.4079,  1.3667,  1.3537,
          1.3243,  1.3497,  1.3497,  1.4155,  1.4468,  1.3647,  1.2154,  1.3401,
          1.2321,  1.4221,  1.2456,  1.3694,  0.3578,  0.2930,  0.4149,  0.3678,
          0.1717,  0.1211,  0.3811,  0.2540,  0.0386,  2.5153,  1.8468,  2.2842,
          2.0912,  1.5509,  1.1882,  2.3871,  2.0649,  1.1574]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 84 : 177.56356576815716
Test loss for epoch 84 : 177.3345622353975
Test Precision for epoch 84 : 0.26153846153846155
Test Recall for epoch 84 : 0.26153846153846155
Test F1 for epoch 84 : 0.26153846153846155


theta for epoch 85 : tensor([[ 2.0697,  2.0835,  2.1201,  2.1815,  2.1622,  2.0738,  2.1489,  2.0696,
          2.0696,  1.3844,  1.3865,  1.3868,  1.3897,  1.3828,  1.3925,  1.3848,
          1.3829,  1.3438,  1.3380,  1.2982,  1.2984,  1.3390,  1.3357,  1.3351,
          1.3375,  1.3345,  1.3345,  1.3212,  1.3670,  1.3585,  1.3625,  1.3660,
          1.3606,  1.3630,  1.3156,  1.3589,  1.7255,  1.7335,  1.7291,  1.7259,
          1.7284,  1.6698,  1.7271,  1.7166,  1.7260,  1.6644,  1.6447,  1.6407,
          1.6306,  1.6588,  1.6370,  1.6765,  1.6304,  1.6290],
        [ 1.3696,  1.2541,  1.1194,  1.3102,  1.4012,  1.4149,  1.3343,  1.4139,
          1.4139,  1.7661,  1.8260,  1.7230,  2.0764,  1.7781,  3.2164,  1.8353,
          1.6880,  2.9798,  1.2452,  1.2996,  1.1923,  1.2463,  1.4032,  1.4233,
          1.3816,  1.4232,  1.4232,  1.3513,  1.2273,  1.4470,  1.4264,  1.1993,
          1.4500,  1.4512,  1.4107,  1.4446,  1.8151,  1.8429,  1.7873,  1.7599,
          1.8251,  1.8387,  1.7865,  1.1303,  1.8222,  1.4739,  1.7025,  1.6976,
          1.6826,  1.4445,  1.6907,  1.3402,  1.6834,  1.6807],
        [ 1.3320,  1.3345,  1.3391,  1.3363,  1.3332,  1.3328,  1.3288,  1.3319,
          1.3319,  1.3935,  1.3963,  1.3951,  1.3957,  1.3921,  1.3505,  1.3935,
          1.3829,  1.3279,  2.1367,  2.1306,  2.2085,  2.1780,  2.0530,  2.0877,
          2.1361,  2.0459,  2.0459,  1.3702,  1.3347,  1.3708,  1.3749,  1.3691,
          1.3731,  1.3760,  1.3708,  1.3713,  1.7322,  1.7403,  1.7359,  1.7249,
          1.7352,  1.7341,  1.7338,  1.6363,  1.7274,  1.6460,  1.6576,  1.6536,
          1.6433,  1.5887,  1.6503,  1.6571,  1.6430,  1.6417],
        [ 1.3420,  1.3449,  1.3214,  1.3185,  1.3449,  1.3426,  1.3425,  1.3419,
          1.3419,  1.4021,  1.3820,  1.4045,  1.3939,  1.4006,  1.3118,  1.4022,
          1.4005,  1.2781,  1.3566,  1.3485,  1.3578,  1.3577,  1.3548,  1.3488,
          1.3564,  1.3534,  1.3534,  2.2837,  2.1689,  1.9880,  2.0742,  2.2791,
          1.9974,  2.2499,  2.0027,  1.9900,  1.7398,  1.7487,  1.7237,  1.7400,
          1.7421,  1.7401,  1.7330,  1.6119,  1.7384,  1.6794,  1.6470,  1.5365,
          1.5847,  1.6725,  1.6117,  1.6948,  1.5847,  1.6399],
        [ 1.7199,  1.3814,  0.5213,  0.7815,  1.1736,  1.6120,  1.5418,  1.7199,
          1.7199,  1.6080,  1.2530,  1.4189,  0.8531,  1.6855,  0.0961,  1.5726,
          1.7094,  0.9778,  1.2987,  0.8432,  0.6583,  1.1002,  1.5801,  1.6548,
          1.3653,  1.7386,  1.7386,  0.6891,  0.7596,  1.6947,  1.4756,  0.7847,
          1.6534,  1.1196,  1.7422,  1.6608,  0.4602,  0.1103,  0.0607,  0.3912,
          0.8967,  1.1410,  0.2781,  6.1447,  5.0850,  0.0805,  0.4308,  0.4662,
          0.5775,  0.2664,  0.5809, -0.1923,  0.5958,  0.6748],
        [ 1.3430,  1.3780,  1.4296,  1.4170,  1.3916,  1.3535,  1.3209,  1.3425,
          1.3425,  1.2834,  1.3897,  1.3028,  1.4326,  1.3479,  1.4631,  1.2856,
          1.3492,  1.3186,  1.3897,  1.4193,  1.4258,  1.4029,  1.3620,  1.3491,
          1.3190,  1.3451,  1.3451,  1.4107,  1.4425,  1.3599,  1.2104,  1.3373,
          1.2293,  1.4175,  1.2409,  1.3647,  0.3530,  0.2891,  0.4102,  0.3631,
          0.1675,  0.1171,  0.3767,  0.2481,  0.0344,  2.5249,  1.8556,  2.2974,
          2.1006,  1.5574,  1.1960,  2.3946,  2.0780,  1.1652]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 85 : 177.5412943556399
Test loss for epoch 85 : 177.3061611014705
Test Precision for epoch 85 : 0.26153846153846155
Test Recall for epoch 85 : 0.26153846153846155
Test F1 for epoch 85 : 0.26153846153846155


theta for epoch 86 : tensor([[ 2.0737,  2.0873,  2.1239,  2.1855,  2.1663,  2.0777,  2.1531,  2.0735,
          2.0735,  1.3833,  1.3852,  1.3854,  1.3883,  1.3817,  1.3910,  1.3835,
          1.3818,  1.3425,  1.3371,  1.2973,  1.2978,  1.3381,  1.3349,  1.3344,
          1.3367,  1.3337,  1.3337,  1.3193,  1.3649,  1.3564,  1.3603,  1.3639,
          1.3585,  1.3609,  1.3136,  1.3568,  1.7254,  1.7336,  1.7291,  1.7259,
          1.7286,  1.6702,  1.7271,  1.7167,  1.7260,  1.6609,  1.6411,  1.6371,
          1.6271,  1.6552,  1.6335,  1.6731,  1.6268,  1.6255],
        [ 1.3667,  1.2534,  1.1196,  1.3085,  1.3993,  1.4119,  1.3318,  1.4109,
          1.4109,  1.7740,  1.8335,  1.7307,  2.0798,  1.7863,  3.2124,  1.8425,
          1.6958,  2.9813,  1.2454,  1.2998,  1.1941,  1.2451,  1.4018,  1.4212,
          1.3795,  1.4210,  1.4210,  1.3491,  1.2244,  1.4437,  1.4239,  1.1991,
          1.4467,  1.4479,  1.4076,  1.4415,  1.8126,  1.8400,  1.7841,  1.7569,
          1.8227,  1.8359,  1.7831,  1.1331,  1.8202,  1.4735,  1.6984,  1.6935,
          1.6787,  1.4438,  1.6868,  1.3418,  1.6794,  1.6768],
        [ 1.3304,  1.3331,  1.3377,  1.3350,  1.3317,  1.3313,  1.3274,  1.3304,
          1.3304,  1.3920,  1.3947,  1.3935,  1.3941,  1.3907,  1.3484,  1.3920,
          1.3814,  1.3270,  2.1411,  2.1346,  2.2128,  2.1820,  2.0566,  2.0910,
          2.1400,  2.0494,  2.0494,  1.3682,  1.3329,  1.3687,  1.3728,  1.3671,
          1.3709,  1.3739,  1.3687,  1.3692,  1.7324,  1.7408,  1.7361,  1.7252,
          1.7357,  1.7346,  1.7341,  1.6370,  1.7273,  1.6426,  1.6536,  1.6497,
          1.6395,  1.5859,  1.6465,  1.6539,  1.6391,  1.6378],
        [ 1.3399,  1.3429,  1.3211,  1.3183,  1.3430,  1.3406,  1.3405,  1.3398,
          1.3398,  1.4006,  1.3818,  1.4028,  1.3927,  1.3992,  1.3102,  1.4007,
          1.3991,  1.2780,  1.3549,  1.3468,  1.3561,  1.3559,  1.3531,  1.3474,
          1.3547,  1.3518,  1.3518,  2.2856,  2.1752,  1.9932,  2.0798,  2.2812,
          2.0026,  2.2518,  2.0082,  1.9952,  1.7391,  1.7483,  1.7234,  1.7393,
          1.7417,  1.7398,  1.7320,  1.6150,  1.7382,  1.6752,  1.6434,  1.5331,
          1.5809,  1.6684,  1.6098,  1.6906,  1.5808,  1.6357],
        [ 1.7198,  1.3800,  0.5194,  0.7805,  1.1730,  1.6120,  1.5416,  1.7198,
          1.7198,  1.6062,  1.2492,  1.4174,  0.8501,  1.6839,  0.0924,  1.5706,
          1.7085,  0.9732,  1.2957,  0.8405,  0.6542,  1.0979,  1.5784,  1.6532,
          1.3647,  1.7376,  1.7376,  0.6874,  0.7585,  1.6951,  1.4757,  0.7808,
          1.6522,  1.1188,  1.7427,  1.6613,  0.4535,  0.1061,  0.0571,  0.3850,
          0.8859,  1.1278,  0.2721,  6.2136,  5.1263,  0.0743,  0.4266,  0.4622,
          0.5741,  0.2611,  0.5772, -0.1996,  0.5926,  0.6720],
        [ 1.3454,  1.3804,  1.4323,  1.4196,  1.3939,  1.3557,  1.3233,  1.3449,
          1.3449,  1.2913,  1.3980,  1.3111,  1.4398,  1.3557,  1.4702,  1.2937,
          1.3570,  1.3265,  1.3952,  1.4244,  1.4309,  1.4081,  1.3676,  1.3550,
          1.3243,  1.3509,  1.3509,  1.4127,  1.4446,  1.3621,  1.2130,  1.3414,
          1.2337,  1.4195,  1.2437,  1.3669,  0.3585,  0.2957,  0.4156,  0.3688,
          0.1741,  0.1239,  0.3825,  0.2523,  0.0409,  2.5209,  1.8509,  2.2968,
          2.0964,  1.5509,  1.1908,  2.3886,  2.0773,  1.1599]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 86 : 177.52466350719692
Test loss for epoch 86 : 177.29661513543584
Test Precision for epoch 86 : 0.26153846153846155
Test Recall for epoch 86 : 0.26153846153846155
Test F1 for epoch 86 : 0.26153846153846155


theta for epoch 87 : tensor([[ 2.0768,  2.0904,  2.1270,  2.1889,  2.1696,  2.0809,  2.1566,  2.0767,
          2.0767,  1.3813,  1.3833,  1.3834,  1.3863,  1.3798,  1.3889,  1.3816,
          1.3800,  1.3405,  1.3354,  1.2957,  1.2964,  1.3365,  1.3334,  1.3328,
          1.3351,  1.3322,  1.3322,  1.3179,  1.3632,  1.3548,  1.3588,  1.3623,
          1.3570,  1.3594,  1.3121,  1.3553,  1.7255,  1.7339,  1.7292,  1.7260,
          1.7290,  1.6707,  1.7272,  1.7169,  1.7262,  1.6610,  1.6412,  1.6372,
          1.6274,  1.6553,  1.6337,  1.6734,  1.6269,  1.6257],
        [ 1.3643,  1.2533,  1.1204,  1.3072,  1.3977,  1.4094,  1.3298,  1.4083,
          1.4083,  1.7802,  1.8392,  1.7368,  2.0817,  1.7928,  3.2068,  1.8480,
          1.7021,  2.9810,  1.2450,  1.2993,  1.1952,  1.2433,  1.3996,  1.4183,
          1.3766,  1.4182,  1.4182,  1.3475,  1.2222,  1.4411,  1.4221,  1.1997,
          1.4441,  1.4453,  1.4050,  1.4389,  1.8101,  1.8372,  1.7809,  1.7539,
          1.8202,  1.8331,  1.7798,  1.1362,  1.8182,  1.4774,  1.6987,  1.6938,
          1.6794,  1.4473,  1.6874,  1.3479,  1.6799,  1.6774],
        [ 1.3290,  1.3318,  1.3365,  1.3338,  1.3304,  1.3299,  1.3262,  1.3290,
          1.3290,  1.3893,  1.3920,  1.3907,  1.3912,  1.3881,  1.3453,  1.3893,
          1.3786,  1.3249,  2.1446,  2.1379,  2.2163,  2.1852,  2.0594,  2.0934,
          2.1430,  2.0521,  2.0521,  1.3664,  1.3313,  1.3668,  1.3708,  1.3653,
          1.3690,  1.3719,  1.3668,  1.3673,  1.7326,  1.7411,  1.7363,  1.7253,
          1.7361,  1.7351,  1.7342,  1.6376,  1.7271,  1.6426,  1.6531,  1.6491,
          1.6391,  1.5864,  1.6460,  1.6540,  1.6386,  1.6374],
        [ 1.3383,  1.3414,  1.3211,  1.3184,  1.3415,  1.3391,  1.3390,  1.3383,
          1.3383,  1.3985,  1.3808,  1.4004,  1.3908,  1.3972,  1.3080,  1.3985,
          1.3970,  1.2772,  1.3527,  1.3445,  1.3540,  1.3537,  1.3509,  1.3454,
          1.3524,  1.3497,  1.3497,  2.2865,  2.1804,  1.9974,  2.0842,  2.2824,
          2.0068,  2.2527,  2.0126,  1.9994,  1.7385,  1.7481,  1.7232,  1.7387,
          1.7416,  1.7397,  1.7312,  1.6180,  1.7382,  1.6746,  1.6434,  1.5334,
          1.5809,  1.6679,  1.6116,  1.6898,  1.5806,  1.6352],
        [ 1.7246,  1.3850,  0.5262,  0.7873,  1.1798,  1.6174,  1.5470,  1.7246,
          1.7246,  1.6107,  1.2534,  1.4226,  0.8560,  1.6881,  0.0992,  1.5747,
          1.7132,  0.9776,  1.2998,  0.8460,  0.6596,  1.1033,  1.5829,  1.6574,
          1.3705,  1.7419,  1.7419,  0.6959,  0.7673,  1.7025,  1.4835,  0.7874,
          1.6582,  1.1269,  1.7498,  1.6688,  0.4386,  0.0945,  0.0462,  0.3707,
          0.8661,  1.1051,  0.2583,  6.2742,  5.1574,  0.0834,  0.4369,  0.4731,
          0.5859,  0.2708,  0.5888, -0.1921,  0.6043,  0.6841],
        [ 1.3393,  1.3745,  1.4269,  1.4141,  1.3881,  1.3496,  1.3173,  1.3388,
          1.3388,  1.2846,  1.3922,  1.3045,  1.4329,  1.3493,  1.4627,  1.2870,
          1.3506,  1.3196,  1.3861,  1.4151,  1.4218,  1.3988,  1.3586,  1.3461,
          1.3146,  1.3419,  1.3419,  1.4058,  1.4383,  1.3553,  1.2057,  1.3364,
          1.2286,  1.4127,  1.2368,  1.3601,  0.3511,  0.2889,  0.4082,  0.3614,
          0.1668,  0.1167,  0.3753,  0.2429,  0.0331,  2.5348,  1.8640,  2.3142,
          2.1100,  1.5618,  1.2029,  2.4004,  2.0947,  1.1719]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 87 : 177.51108017177143
Test loss for epoch 87 : 177.27322532075615
Test Precision for epoch 87 : 0.26153846153846155
Test Recall for epoch 87 : 0.26153846153846155
Test F1 for epoch 87 : 0.26153846153846155


theta for epoch 88 : tensor([[ 2.0798,  2.0933,  2.1299,  2.1920,  2.1728,  2.0839,  2.1599,  2.0797,
          2.0797,  1.3799,  1.3818,  1.3817,  1.3847,  1.3784,  1.3872,  1.3801,
          1.3785,  1.3390,  1.3351,  1.2954,  1.2963,  1.3362,  1.3331,  1.3326,
          1.3349,  1.3319,  1.3319,  1.3170,  1.3620,  1.3537,  1.3576,  1.3612,
          1.3559,  1.3583,  1.3112,  1.3542,  1.7269,  1.7356,  1.7306,  1.7274,
          1.7307,  1.6725,  1.7286,  1.7184,  1.7277,  1.6583,  1.6385,  1.6345,
          1.6248,  1.6525,  1.6311,  1.6707,  1.6242,  1.6231],
        [ 1.3624,  1.2536,  1.1217,  1.3064,  1.3966,  1.4074,  1.3284,  1.4063,
          1.4063,  1.7857,  1.8443,  1.7423,  2.0832,  1.7986,  3.2005,  1.8529,
          1.7077,  2.9800,  1.2464,  1.3004,  1.1980,  1.2433,  1.3990,  1.4171,
          1.3755,  1.4169,  1.4169,  1.3466,  1.2207,  1.4392,  1.4209,  1.2009,
          1.4421,  1.4433,  1.4032,  1.4370,  1.8087,  1.8358,  1.7791,  1.7522,
          1.8189,  1.8317,  1.7778,  1.1408,  1.8174,  1.4784,  1.6963,  1.6914,
          1.6775,  1.4478,  1.6853,  1.3512,  1.6778,  1.6754],
        [ 1.3278,  1.3306,  1.3354,  1.3327,  1.3293,  1.3287,  1.3252,  1.3277,
          1.3277,  1.3868,  1.3894,  1.3881,  1.3886,  1.3856,  1.3424,  1.3868,
          1.3759,  1.3231,  2.1490,  2.1420,  2.2208,  2.1893,  2.0632,  2.0968,
          2.1470,  2.0558,  2.0558,  1.3647,  1.3299,  1.3651,  1.3691,  1.3637,
          1.3673,  1.3702,  1.3651,  1.3656,  1.7339,  1.7428,  1.7377,  1.7267,
          1.7378,  1.7369,  1.7356,  1.6395,  1.7281,  1.6395,  1.6494,  1.6454,
          1.6356,  1.5838,  1.6424,  1.6509,  1.6350,  1.6339],
        [ 1.3372,  1.3403,  1.3216,  1.3189,  1.3405,  1.3380,  1.3380,  1.3372,
          1.3372,  1.3970,  1.3804,  1.3987,  1.3895,  1.3958,  1.3066,  1.3970,
          1.3955,  1.2771,  1.3520,  1.3437,  1.3533,  1.3529,  1.3502,  1.3448,
          1.3517,  1.3490,  1.3490,  2.2871,  2.1849,  2.0010,  2.0881,  2.2831,
          2.0104,  2.2532,  2.0164,  2.0030,  1.7394,  1.7494,  1.7245,  1.7396,
          1.7429,  1.7411,  1.7319,  1.6225,  1.7396,  1.6715,  1.6409,  1.5312,
          1.5784,  1.6649,  1.6108,  1.6865,  1.5779,  1.6323],
        [ 1.7227,  1.3811,  0.5209,  0.7834,  1.1764,  1.6153,  1.5445,  1.7227,
          1.7227,  1.6060,  1.2461,  1.4181,  0.8489,  1.6835,  0.0909,  1.5698,
          1.7094,  0.9687,  1.2936,  0.8395,  0.6513,  1.0974,  1.5783,  1.6531,
          1.3669,  1.7382,  1.7382,  0.6902,  0.7620,  1.7005,  1.4805,  0.7796,
          1.6545,  1.1224,  1.7479,  1.6667,  0.4357,  0.0938,  0.0461,  0.3683,
          0.8593,  1.0958,  0.2560,  6.3457,  5.2011,  0.0730,  0.4288,  0.4651,
          0.5784,  0.2614,  0.5811, -0.2041,  0.5971,  0.6773],
        [ 1.3438,  1.3790,  1.4317,  1.4187,  1.3926,  1.3540,  1.3219,  1.3432,
          1.3432,  1.2945,  1.4023,  1.3146,  1.4420,  1.3591,  1.4717,  1.2970,
          1.3604,  1.3295,  1.3944,  1.4230,  1.4297,  1.4068,  1.3670,  1.3547,
          1.3227,  1.3505,  1.3505,  1.4102,  1.4428,  1.3600,  1.2109,  1.3428,
          1.2355,  1.4171,  1.2422,  1.3648,  0.3600,  0.2985,  0.4169,  0.3703,
          0.1767,  0.1268,  0.3844,  0.2499,  0.0425,  2.5272,  1.8557,  2.3099,
          2.1021,  1.5520,  1.1942,  2.3909,  2.0903,  1.1632]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 88 : 177.50370548613603
Test loss for epoch 88 : 177.27744280570744
Test Precision for epoch 88 : 0.26153846153846155
Test Recall for epoch 88 : 0.26153846153846155
Test F1 for epoch 88 : 0.26153846153846155


theta for epoch 89 : tensor([[ 2.0827,  2.0962,  2.1328,  2.1951,  2.1759,  2.0868,  2.1631,  2.0825,
          2.0825,  1.3786,  1.3805,  1.3804,  1.3834,  1.3773,  1.3858,  1.3788,
          1.3773,  1.3378,  1.3340,  1.2945,  1.2955,  1.3352,  1.3322,  1.3316,
          1.3339,  1.3310,  1.3310,  1.3167,  1.3614,  1.3533,  1.3572,  1.3607,
          1.3554,  1.3579,  1.3108,  1.3537,  1.7268,  1.7357,  1.7305,  1.7273,
          1.7309,  1.6729,  1.7284,  1.7183,  1.7277,  1.6591,  1.6394,  1.6355,
          1.6260,  1.6533,  1.6322,  1.6716,  1.6253,  1.6242],
        [ 1.3608,  1.2542,  1.1233,  1.3058,  1.3957,  1.4056,  1.3271,  1.4044,
          1.4044,  1.7914,  1.8493,  1.7479,  2.0849,  1.8045,  3.1941,  1.8579,
          1.7135,  2.9789,  1.2470,  1.3009,  1.2001,  1.2425,  1.3977,  1.4151,
          1.3736,  1.4150,  1.4150,  1.3464,  1.2199,  1.4379,  1.4204,  1.2027,
          1.4407,  1.4419,  1.4020,  1.4358,  1.8058,  1.8328,  1.7757,  1.7489,
          1.8160,  1.8286,  1.7743,  1.1443,  1.8151,  1.4834,  1.6982,  1.6933,
          1.6799,  1.4523,  1.6875,  1.3587,  1.6800,  1.6778],
        [ 1.3267,  1.3296,  1.3344,  1.3318,  1.3283,  1.3276,  1.3243,  1.3266,
          1.3266,  1.3847,  1.3872,  1.3859,  1.3864,  1.3835,  1.3398,  1.3846,
          1.3736,  1.3216,  2.1528,  2.1457,  2.2248,  2.1929,  2.0664,  2.0996,
          2.1504,  2.0589,  2.0589,  1.3638,  1.3290,  1.3641,  1.3680,  1.3627,
          1.3662,  1.3691,  1.3640,  1.3645,  1.7337,  1.7428,  1.7375,  1.7265,
          1.7379,  1.7370,  1.7354,  1.6398,  1.7277,  1.6401,  1.6493,  1.6454,
          1.6358,  1.5847,  1.6425,  1.6513,  1.6351,  1.6340],
        [ 1.3363,  1.3395,  1.3221,  1.3196,  1.3396,  1.3371,  1.3371,  1.3363,
          1.3363,  1.3959,  1.3802,  1.3973,  1.3885,  1.3947,  1.3056,  1.3958,
          1.3944,  1.2771,  1.3508,  1.3425,  1.3522,  1.3517,  1.3490,  1.3437,
          1.3504,  1.3478,  1.3478,  2.2879,  2.1896,  2.0047,  2.0921,  2.2841,
          2.0141,  2.2539,  2.0203,  2.0067,  1.7388,  1.7491,  1.7243,  1.7389,
          1.7427,  1.7409,  1.7311,  1.6251,  1.7395,  1.6719,  1.6419,  1.5327,
          1.5795,  1.6653,  1.6136,  1.6867,  1.5789,  1.6330],
        [ 1.7291,  1.3880,  0.5299,  0.7924,  1.1852,  1.6224,  1.5516,  1.7291,
          1.7291,  1.6128,  1.2530,  1.4258,  0.8575,  1.6897,  0.1005,  1.5764,
          1.7162,  0.9759,  1.2998,  0.8474,  0.6593,  1.1050,  1.5846,  1.6592,
          1.3747,  1.7444,  1.7444,  0.7015,  0.7735,  1.7102,  1.4906,  0.7893,
          1.6631,  1.1330,  1.7574,  1.6767,  0.4189,  0.0802,  0.0332,  0.3520,
          0.8373,  1.0708,  0.2404,  6.4028,  5.2279,  0.0862,  0.4429,  0.4798,
          0.5939,  0.2750,  0.5963, -0.1929,  0.6125,  0.6929],
        [ 1.3356,  1.3710,  1.4242,  1.4111,  1.3848,  1.3458,  1.3137,  1.3351,
          1.3351,  1.2843,  1.3933,  1.3045,  1.4319,  1.3495,  1.4610,  1.2869,
          1.3507,  1.3192,  1.3821,  1.4105,  1.4175,  1.3943,  1.3548,  1.3426,
          1.3097,  1.3383,  1.3383,  1.4016,  1.4348,  1.3514,  1.2016,  1.3358,
          1.2283,  1.4086,  1.2334,  1.3562,  0.3487,  0.2875,  0.4057,  0.3591,
          0.1652,  0.1154,  0.3734,  0.2362,  0.0301,  2.5451,  1.8729,  2.3312,
          2.1197,  1.5672,  1.2103,  2.4067,  2.1116,  1.1792]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 89 : 177.49258941007207
Test loss for epoch 89 : 177.2520601196101
Test Precision for epoch 89 : 0.26153846153846155
Test Recall for epoch 89 : 0.26153846153846155
Test F1 for epoch 89 : 0.26153846153846155


theta for epoch 90 : tensor([[ 2.0864,  2.0999,  2.1365,  2.1991,  2.1799,  2.0905,  2.1671,  2.0863,
          2.0863,  1.3789,  1.3807,  1.3805,  1.3835,  1.3775,  1.3858,  1.3790,
          1.3776,  1.3380,  1.3343,  1.2947,  1.2959,  1.3354,  1.3325,  1.3320,
          1.3343,  1.3313,  1.3313,  1.3165,  1.3609,  1.3530,  1.3568,  1.3603,
          1.3550,  1.3576,  1.3106,  1.3534,  1.7277,  1.7368,  1.7314,  1.7283,
          1.7321,  1.6742,  1.7294,  1.7193,  1.7287,  1.6544,  1.6347,  1.6308,
          1.6215,  1.6485,  1.6277,  1.6669,  1.6206,  1.6197],
        [ 1.3594,  1.2551,  1.1251,  1.3055,  1.3950,  1.4041,  1.3262,  1.4029,
          1.4029,  1.7988,  1.8560,  1.7553,  2.0885,  1.8120,  3.1891,  1.8647,
          1.7210,  2.9792,  1.2491,  1.3028,  1.2034,  1.2431,  1.3978,  1.4146,
          1.3731,  1.4145,  1.4145,  1.3464,  1.2193,  1.4369,  1.4201,  1.2046,
          1.4396,  1.4408,  1.4010,  1.4348,  1.8038,  1.8308,  1.7734,  1.7467,
          1.8141,  1.8267,  1.7719,  1.1489,  1.8138,  1.4820,  1.6940,  1.6892,
          1.6765,  1.4504,  1.6837,  1.3600,  1.6762,  1.6743],
        [ 1.3260,  1.3290,  1.3338,  1.3313,  1.3278,  1.3269,  1.3238,  1.3260,
          1.3260,  1.3845,  1.3870,  1.3857,  1.3862,  1.3833,  1.3393,  1.3844,
          1.3732,  1.3221,  2.1578,  2.1505,  2.2298,  2.1976,  2.0708,  2.1037,
          2.1551,  2.0632,  2.0632,  1.3631,  1.3285,  1.3633,  1.3671,  1.3619,
          1.3654,  1.3683,  1.3633,  1.3638,  1.7346,  1.7440,  1.7384,  1.7275,
          1.7391,  1.7383,  1.7364,  1.6413,  1.7283,  1.6352,  1.6438,  1.6399,
          1.6306,  1.5802,  1.6372,  1.6463,  1.6297,  1.6287],
        [ 1.3358,  1.3389,  1.3228,  1.3204,  1.3391,  1.3366,  1.3365,  1.3357,
          1.3357,  1.3964,  1.3816,  1.3976,  1.3892,  1.3952,  1.3062,  1.3963,
          1.3949,  1.2787,  1.3509,  1.3426,  1.3524,  1.3519,  1.3491,  1.3440,
          1.3506,  1.3479,  1.3479,  2.2896,  2.1951,  2.0092,  2.0969,  2.2860,
          2.0186,  2.2555,  2.0250,  2.0112,  1.7393,  1.7499,  1.7252,  1.7394,
          1.7437,  1.7418,  1.7315,  1.6288,  1.7405,  1.6671,  1.6377,  1.5289,
          1.5755,  1.6606,  1.6111,  1.6817,  1.5747,  1.6286],
        [ 1.7266,  1.3834,  0.5233,  0.7873,  1.1809,  1.6198,  1.5486,  1.7267,
          1.7267,  1.6084,  1.2456,  1.4215,  0.8499,  1.6854,  0.0911,  1.5720,
          1.7128,  0.9664,  1.2927,  0.8396,  0.6496,  1.0979,  1.5793,  1.6542,
          1.3701,  1.7401,  1.7401,  0.6944,  0.7669,  1.7076,  1.4867,  0.7803,
          1.6589,  1.1273,  1.7549,  1.6740,  0.4177,  0.0810,  0.0344,  0.3512,
          0.8321,  1.0632,  0.2397,  6.4740,  5.2710,  0.0739,  0.4328,  0.4697,
          0.5840,  0.2637,  0.5863, -0.2069,  0.6029,  0.6836],
        [ 1.3427,  1.3780,  1.4314,  1.4182,  1.3917,  1.3528,  1.3210,  1.3422,
          1.3422,  1.2985,  1.4075,  1.3187,  1.4453,  1.3636,  1.4744,  1.3011,
          1.3647,  1.3333,  1.3940,  1.4220,  1.4289,  1.4060,  1.3669,  1.3549,
          1.3214,  1.3505,  1.3505,  1.4091,  1.4423,  1.3593,  1.2099,  1.3451,
          1.2382,  1.4160,  1.2420,  1.3640,  0.3598,  0.2991,  0.4164,  0.3702,
          0.1771,  0.1275,  0.3846,  0.2452,  0.0413,  2.5338,  1.8609,  2.3228,
          2.1080,  1.5540,  1.1979,  2.3937,  2.1032,  1.1668]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 90 : 177.47397186554267
Test loss for epoch 90 : 177.24819999929068
Test Precision for epoch 90 : 0.26153846153846155
Test Recall for epoch 90 : 0.26153846153846155
Test F1 for epoch 90 : 0.26153846153846155


theta for epoch 91 : tensor([[ 2.0902,  2.1037,  2.1403,  2.2031,  2.1839,  2.0943,  2.1712,  2.0900,
          2.0900,  1.3781,  1.3799,  1.3796,  1.3826,  1.3768,  1.3849,  1.3782,
          1.3768,  1.3373,  1.3335,  1.2940,  1.2953,  1.3347,  1.3318,  1.3313,
          1.3336,  1.3306,  1.3306,  1.3165,  1.3605,  1.3528,  1.3565,  1.3601,
          1.3548,  1.3574,  1.3105,  1.3532,  1.7270,  1.7364,  1.7308,  1.7276,
          1.7317,  1.6740,  1.7287,  1.7187,  1.7282,  1.6549,  1.6354,  1.6315,
          1.6225,  1.6491,  1.6285,  1.6674,  1.6215,  1.6206],
        [ 1.3583,  1.2562,  1.1272,  1.3054,  1.3945,  1.4028,  1.3256,  1.4017,
          1.4017,  1.8056,  1.8620,  1.7621,  2.0915,  1.8189,  3.1833,  1.8709,
          1.7279,  2.9788,  1.2503,  1.3039,  1.2057,  1.2428,  1.3971,  1.4132,
          1.3717,  1.4130,  1.4130,  1.3467,  1.2189,  1.4361,  1.4201,  1.2068,
          1.4387,  1.4398,  1.4002,  1.4339,  1.8003,  1.8273,  1.7696,  1.7430,
          1.8107,  1.8232,  1.7679,  1.1523,  1.8109,  1.4867,  1.6960,  1.6912,
          1.6791,  1.4544,  1.6861,  1.3674,  1.6786,  1.6769],
        [ 1.3258,  1.3288,  1.3337,  1.3312,  1.3277,  1.3267,  1.3237,  1.3257,
          1.3257,  1.3838,  1.3863,  1.3849,  1.3854,  1.3826,  1.3383,  1.3837,
          1.3723,  1.3221,  2.1612,  2.1537,  2.2333,  2.2007,  2.0736,  2.1060,
          2.1581,  2.0659,  2.0659,  1.3628,  1.3284,  1.3630,  1.3667,  1.3616,
          1.3650,  1.3678,  1.3629,  1.3634,  1.7341,  1.7437,  1.7379,  1.7269,
          1.7389,  1.7382,  1.7359,  1.6414,  1.7276,  1.6361,  1.6440,  1.6401,
          1.6310,  1.5813,  1.6375,  1.6468,  1.6300,  1.6292],
        [ 1.3354,  1.3385,  1.3237,  1.3213,  1.3387,  1.3362,  1.3362,  1.3353,
          1.3353,  1.3958,  1.3819,  1.3969,  1.3888,  1.3947,  1.3059,  1.3957,
          1.3944,  1.2792,  1.3502,  1.3418,  1.3518,  1.3511,  1.3483,  1.3433,
          1.3498,  1.3472,  1.3472,  2.2914,  2.2005,  2.0137,  2.1018,  2.2880,
          2.0231,  2.2572,  2.0298,  2.0157,  1.7383,  1.7491,  1.7245,  1.7383,
          1.7431,  1.7411,  1.7302,  1.6306,  1.7398,  1.6673,  1.6387,  1.5302,
          1.5766,  1.6610,  1.6136,  1.6816,  1.5756,  1.6293],
        [ 1.7340,  1.3912,  0.5330,  0.7971,  1.1906,  1.6278,  1.5566,  1.7341,
          1.7341,  1.6167,  1.2541,  1.4305,  0.8596,  1.6929,  0.1017,  1.5801,
          1.7209,  0.9746,  1.2998,  0.8484,  0.6585,  1.1065,  1.5865,  1.6612,
          1.3788,  1.7471,  1.7471,  0.7063,  0.7790,  1.7180,  1.4974,  0.7909,
          1.6684,  1.1385,  1.7651,  1.6846,  0.4006,  0.0670,  0.0211,  0.3347,
          0.8098,  1.0378,  0.2240,  6.5288,  5.2949,  0.0880,  0.4477,  0.4851,
          0.5998,  0.2781,  0.6020, -0.1948,  0.6187,  0.6995],
        [ 1.3351,  1.3706,  1.4243,  1.4109,  1.3844,  1.3452,  1.3133,  1.3345,
          1.3345,  1.2891,  1.3991,  1.3092,  1.4360,  1.3548,  1.4647,  1.2916,
          1.3557,  1.3239,  1.3826,  1.4104,  1.4175,  1.3944,  1.3555,  1.3435,
          1.3092,  1.3390,  1.3390,  1.4008,  1.4346,  1.3512,  1.2011,  1.3383,
          1.2313,  1.4079,  1.2337,  1.3559,  0.3483,  0.2876,  0.4049,  0.3587,
          0.1653,  0.1156,  0.3734,  0.2312,  0.0283,  2.5507,  1.8772,  2.3428,
          2.1246,  1.5686,  1.2133,  2.4087,  2.1233,  1.1820]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 91 : 177.42497234092974
Test loss for epoch 91 : 177.184583281151
Test Precision for epoch 91 : 0.26153846153846155
Test Recall for epoch 91 : 0.26153846153846155
Test F1 for epoch 91 : 0.26153846153846155


theta for epoch 92 : tensor([[ 2.0937,  2.1072,  2.1439,  2.2069,  2.1878,  2.0979,  2.1751,  2.0936,
          2.0936,  1.3773,  1.3791,  1.3787,  1.3817,  1.3760,  1.3840,  1.3774,
          1.3760,  1.3365,  1.3343,  1.2948,  1.2962,  1.3355,  1.3326,  1.3321,
          1.3344,  1.3314,  1.3314,  1.3162,  1.3600,  1.3524,  1.3561,  1.3596,
          1.3544,  1.3569,  1.3102,  1.3528,  1.7282,  1.7378,  1.7319,  1.7288,
          1.7332,  1.6756,  1.7298,  1.7199,  1.7295,  1.6529,  1.6335,  1.6296,
          1.6208,  1.6471,  1.6267,  1.6654,  1.6196,  1.6189],
        [ 1.3576,  1.2576,  1.1297,  1.3056,  1.3943,  1.4019,  1.3253,  1.4008,
          1.4008,  1.8116,  1.8670,  1.7681,  2.0939,  1.8249,  3.1768,  1.8763,
          1.7341,  2.9775,  1.2535,  1.3068,  1.2099,  1.2444,  1.3981,  1.4137,
          1.3723,  1.4134,  1.4134,  1.3469,  1.2185,  1.4352,  1.4199,  1.2088,
          1.4376,  1.4388,  1.3993,  1.4330,  1.7986,  1.8257,  1.7676,  1.7412,
          1.8090,  1.8216,  1.7659,  1.1577,  1.8098,  1.4886,  1.6953,  1.6905,
          1.6791,  1.4556,  1.6858,  1.3723,  1.6784,  1.6769],
        [ 1.3259,  1.3290,  1.3339,  1.3315,  1.3280,  1.3269,  1.3240,  1.3259,
          1.3259,  1.3833,  1.3858,  1.3845,  1.3850,  1.3822,  1.3376,  1.3833,
          1.3715,  1.3223,  2.1643,  2.1567,  2.2366,  2.2035,  2.0762,  2.1082,
          2.1610,  2.0684,  2.0684,  1.3624,  1.3281,  1.3626,  1.3662,  1.3612,
          1.3645,  1.3673,  1.3624,  1.3630,  1.7355,  1.7453,  1.7393,  1.7283,
          1.7406,  1.7398,  1.7372,  1.6433,  1.7287,  1.6345,  1.6418,  1.6378,
          1.6290,  1.5800,  1.6354,  1.6449,  1.6279,  1.6271],
        [ 1.3352,  1.3383,  1.3246,  1.3223,  1.3386,  1.3360,  1.3360,  1.3351,
          1.3351,  1.3952,  1.3820,  1.3961,  1.3883,  1.3941,  1.3054,  1.3950,
          1.3937,  1.2795,  1.3510,  1.3426,  1.3527,  1.3519,  1.3490,  1.3441,
          1.3506,  1.3479,  1.3479,  2.2929,  2.2054,  2.0176,  2.1061,  2.2895,
          2.0270,  2.2585,  2.0339,  2.0196,  1.7391,  1.7502,  1.7256,  1.7391,
          1.7444,  1.7423,  1.7309,  1.6342,  1.7411,  1.6652,  1.6372,  1.5290,
          1.5753,  1.6590,  1.6135,  1.6792,  1.5742,  1.6277],
        [ 1.7328,  1.3882,  0.5284,  0.7939,  1.1881,  1.6265,  1.5549,  1.7330,
          1.7330,  1.6135,  1.2482,  1.4274,  0.8537,  1.6894,  0.0945,  1.5768,
          1.7183,  0.9667,  1.2946,  0.8428,  0.6513,  1.1014,  1.5829,  1.6579,
          1.3759,  1.7443,  1.7443,  0.7012,  0.7742,  1.7165,  1.4946,  0.7841,
          1.6654,  1.1344,  1.7636,  1.6830,  0.3978,  0.0661,  0.0208,  0.3323,
          0.8029,  1.0283,  0.2219,  6.5967,  5.3339,  0.0806,  0.4421,  0.4796,
          0.5944,  0.2715,  0.5965, -0.2041,  0.6136,  0.6946],
        [ 1.3400,  1.3754,  1.4292,  1.4158,  1.3892,  1.3500,  1.3183,  1.3394,
          1.3394,  1.2979,  1.4081,  1.3180,  1.4444,  1.3637,  1.4729,  1.3005,
          1.3645,  1.3327,  1.3908,  1.4183,  1.4254,  1.4024,  1.3637,  1.3518,
          1.3170,  1.3473,  1.3473,  1.4056,  1.4394,  1.3563,  1.2064,  1.3446,
          1.2380,  1.4126,  1.2394,  1.3610,  0.3557,  0.2951,  0.4120,  0.3661,
          0.1731,  0.1235,  0.3809,  0.2364,  0.0350,  2.5447,  1.8706,  2.3397,
          2.1182,  1.5609,  1.2063,  2.4011,  2.1202,  1.1750]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 92 : 177.36507229612312
Test loss for epoch 92 : 177.13433336779062
Test Precision for epoch 92 : 0.26153846153846155
Test Recall for epoch 92 : 0.26153846153846155
Test F1 for epoch 92 : 0.26153846153846155


theta for epoch 93 : tensor([[ 2.0965,  2.1101,  2.1468,  2.2099,  2.1908,  2.1007,  2.1781,  2.0964,
          2.0964,  1.3764,  1.3782,  1.3778,  1.3808,  1.3752,  1.3830,  1.3765,
          1.3752,  1.3357,  1.3349,  1.2955,  1.2970,  1.3362,  1.3333,  1.3327,
          1.3351,  1.3320,  1.3320,  1.3161,  1.3595,  1.3521,  1.3557,  1.3592,
          1.3541,  1.3566,  1.3101,  1.3525,  1.7292,  1.7390,  1.7330,  1.7299,
          1.7345,  1.6770,  1.7309,  1.7209,  1.7306,  1.6539,  1.6347,  1.6307,
          1.6222,  1.6481,  1.6281,  1.6664,  1.6209,  1.6203],
        [ 1.3567,  1.2589,  1.1320,  1.3056,  1.3940,  1.4009,  1.3249,  1.3997,
          1.3997,  1.8173,  1.8716,  1.7737,  2.0959,  1.8304,  3.1697,  1.8813,
          1.7399,  2.9756,  1.2563,  1.3093,  1.2135,  1.2457,  1.3988,  1.4136,
          1.3723,  1.4133,  1.4133,  1.3471,  1.2181,  1.4342,  1.4198,  1.2108,
          1.4366,  1.4378,  1.3984,  1.4320,  1.7968,  1.8240,  1.7655,  1.7393,
          1.8071,  1.8198,  1.7637,  1.1633,  1.8086,  1.4937,  1.6979,  1.6931,
          1.6823,  1.4598,  1.6887,  1.3804,  1.6813,  1.6801],
        [ 1.3260,  1.3290,  1.3339,  1.3316,  1.3282,  1.3269,  1.3242,  1.3259,
          1.3259,  1.3828,  1.3852,  1.3839,  1.3845,  1.3816,  1.3370,  1.3827,
          1.3708,  1.3225,  2.1664,  2.1587,  2.2388,  2.2054,  2.0778,  2.1094,
          2.1628,  2.0699,  2.0699,  1.3621,  1.3279,  1.3622,  1.3658,  1.3608,
          1.3641,  1.3669,  1.3621,  1.3626,  1.7367,  1.7467,  1.7405,  1.7294,
          1.7421,  1.7414,  1.7384,  1.6451,  1.7297,  1.6360,  1.6426,  1.6387,
          1.6301,  1.5817,  1.6363,  1.6460,  1.6288,  1.6282],
        [ 1.3348,  1.3379,  1.3253,  1.3231,  1.3383,  1.3357,  1.3357,  1.3347,
          1.3347,  1.3943,  1.3817,  1.3951,  1.3875,  1.3932,  1.3048,  1.3941,
          1.3928,  1.2795,  1.3515,  1.3430,  1.3533,  1.3524,  1.3494,  1.3446,
          1.3510,  1.3483,  1.3483,  2.2940,  2.2097,  2.0211,  2.1099,  2.2907,
          2.0305,  2.2595,  2.0376,  2.0231,  1.7398,  1.7512,  1.7267,  1.7397,
          1.7455,  1.7434,  1.7315,  1.6374,  1.7421,  1.6659,  1.6385,  1.5307,
          1.5768,  1.6598,  1.6162,  1.6796,  1.5755,  1.6289],
        [ 1.7361,  1.3908,  0.5313,  0.7976,  1.1920,  1.6301,  1.5583,  1.7363,
          1.7363,  1.6164,  1.2500,  1.4309,  0.8562,  1.6918,  0.0968,  1.5797,
          1.7215,  0.9671,  1.2962,  0.8451,  0.6531,  1.1039,  1.5853,  1.6603,
          1.3794,  1.7471,  1.7471,  0.7050,  0.7783,  1.7209,  1.4986,  0.7866,
          1.6688,  1.1381,  1.7680,  1.6875,  0.3875,  0.0584,  0.0136,  0.3226,
          0.7880,  1.0104,  0.2127,  6.6570,  5.3636,  0.0858,  0.4484,  0.4861,
          0.6010,  0.2771,  0.6030, -0.2009,  0.6204,  0.7014],
        [ 1.3370,  1.3725,  1.4265,  1.4130,  1.3864,  1.3471,  1.3154,  1.3365,
          1.3365,  1.2949,  1.4059,  1.3149,  1.4414,  1.3611,  1.4696,  1.2975,
          1.3618,  1.3298,  1.3873,  1.4145,  1.4219,  1.3987,  1.3602,  1.3484,
          1.3127,  1.3437,  1.3437,  1.4022,  1.4363,  1.3531,  1.2028,  1.3425,
          1.2361,  1.4092,  1.2363,  1.3578,  0.3522,  0.2914,  0.4083,  0.3626,
          0.1693,  0.1197,  0.3775,  0.2304,  0.0299,  2.5527,  1.8779,  2.3506,
          2.1258,  1.5669,  1.2129,  2.4073,  2.1311,  1.1815]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 93 : 177.3226988612038
Test loss for epoch 93 : 177.08733525269352
Test Precision for epoch 93 : 0.26153846153846155
Test Recall for epoch 93 : 0.26153846153846155
Test F1 for epoch 93 : 0.26153846153846155


theta for epoch 94 : tensor([[ 2.0993,  2.1129,  2.1496,  2.2130,  2.1939,  2.1035,  2.1812,  2.0991,
          2.0991,  1.3765,  1.3783,  1.3778,  1.3809,  1.3753,  1.3830,  1.3766,
          1.3753,  1.3358,  1.3356,  1.2962,  1.2977,  1.3369,  1.3340,  1.3334,
          1.3358,  1.3327,  1.3327,  1.3162,  1.3594,  1.3522,  1.3557,  1.3591,
          1.3540,  1.3566,  1.3102,  1.3525,  1.7306,  1.7406,  1.7344,  1.7313,
          1.7362,  1.6789,  1.7323,  1.7224,  1.7321,  1.6537,  1.6346,  1.6307,
          1.6223,  1.6479,  1.6281,  1.6661,  1.6209,  1.6204],
        [ 1.3556,  1.2599,  1.1341,  1.3054,  1.3934,  1.3997,  1.3244,  1.3985,
          1.3985,  1.8242,  1.8772,  1.7807,  2.0992,  1.8372,  3.1636,  1.8877,
          1.7470,  2.9747,  1.2587,  1.3115,  1.2167,  1.2466,  1.3991,  1.4133,
          1.3720,  1.4130,  1.4130,  1.3474,  1.2177,  1.4334,  1.4197,  1.2128,
          1.4356,  1.4368,  1.3976,  1.4312,  1.7952,  1.8225,  1.7638,  1.7377,
          1.8055,  1.8184,  1.7619,  1.1693,  1.8076,  1.4969,  1.6988,  1.6940,
          1.6839,  1.4622,  1.6900,  1.3868,  1.6827,  1.6817],
        [ 1.3258,  1.3289,  1.3338,  1.3315,  1.3281,  1.3267,  1.3242,  1.3258,
          1.3258,  1.3831,  1.3854,  1.3842,  1.3848,  1.3818,  1.3372,  1.3830,
          1.3708,  1.3235,  2.1693,  2.1615,  2.2418,  2.2080,  2.0803,  2.1113,
          2.1655,  2.0723,  2.0723,  1.3618,  1.3278,  1.3620,  1.3654,  1.3606,
          1.3638,  1.3666,  1.3618,  1.3623,  1.7381,  1.7484,  1.7420,  1.7309,
          1.7438,  1.7431,  1.7399,  1.6472,  1.7309,  1.6361,  1.6420,  1.6380,
          1.6297,  1.5818,  1.6358,  1.6456,  1.6283,  1.6278],
        [ 1.3344,  1.3375,  1.3258,  1.3237,  1.3378,  1.3353,  1.3352,  1.3343,
          1.3343,  1.3942,  1.3823,  1.3949,  1.3876,  1.3931,  1.3049,  1.3941,
          1.3927,  1.2803,  1.3519,  1.3434,  1.3538,  1.3529,  1.3498,  1.3450,
          1.3514,  1.3487,  1.3487,  2.2957,  2.2146,  2.0251,  2.1142,  2.2925,
          2.0344,  2.2610,  2.0417,  2.0270,  1.7409,  1.7524,  1.7280,  1.7407,
          1.7469,  1.7447,  1.7324,  1.6408,  1.7435,  1.6653,  1.6386,  1.5311,
          1.5771,  1.6593,  1.6176,  1.6788,  1.5757,  1.6289],
        [ 1.7392,  1.3931,  0.5337,  0.8009,  1.1955,  1.6334,  1.5614,  1.7394,
          1.7394,  1.6198,  1.2521,  1.4346,  0.8585,  1.6945,  0.0989,  1.5830,
          1.7250,  0.9674,  1.2975,  0.8471,  0.6544,  1.1060,  1.5876,  1.6626,
          1.3827,  1.7497,  1.7497,  0.7083,  0.7818,  1.7252,  1.5023,  0.7886,
          1.6721,  1.1414,  1.7722,  1.6917,  0.3780,  0.0512,  0.0070,  0.3135,
          0.7736,  0.9931,  0.2042,  6.7178,  5.3935,  0.0899,  0.4535,  0.4914,
          0.6061,  0.2815,  0.6081, -0.1987,  0.6257,  0.7067],
        [ 1.3350,  1.3704,  1.4247,  1.4111,  1.3844,  1.3451,  1.3133,  1.3344,
          1.3344,  1.2938,  1.4054,  1.3137,  1.4402,  1.3604,  1.4683,  1.2963,
          1.3609,  1.3289,  1.3851,  1.4122,  1.4198,  1.3965,  1.3580,  1.3463,
          1.3099,  1.3415,  1.3415,  1.4000,  1.4344,  1.3512,  1.2004,  1.3416,
          1.2353,  1.4071,  1.2345,  1.3558,  0.3500,  0.2888,  0.4059,  0.3603,
          0.1668,  0.1171,  0.3753,  0.2257,  0.0260,  2.5589,  1.8835,  2.3598,
          2.1316,  1.5712,  1.2178,  2.4118,  2.1403,  1.1863]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 94 : 177.30957648980464
Test loss for epoch 94 : 177.071148640001
Test Precision for epoch 94 : 0.26153846153846155
Test Recall for epoch 94 : 0.26153846153846155
Test F1 for epoch 94 : 0.26153846153846155


theta for epoch 95 : tensor([[ 2.1029e+00,  2.1165e+00,  2.1533e+00,  2.2168e+00,  2.1978e+00,
          2.1071e+00,  2.1850e+00,  2.1027e+00,  2.1027e+00,  1.3770e+00,
          1.3788e+00,  1.3782e+00,  1.3813e+00,  1.3757e+00,  1.3834e+00,
          1.3770e+00,  1.3757e+00,  1.3363e+00,  1.3364e+00,  1.2970e+00,
          1.2985e+00,  1.3377e+00,  1.3347e+00,  1.3341e+00,  1.3366e+00,
          1.3334e+00,  1.3334e+00,  1.3165e+00,  1.3595e+00,  1.3525e+00,
          1.3559e+00,  1.3593e+00,  1.3543e+00,  1.3569e+00,  1.3105e+00,
          1.3528e+00,  1.7326e+00,  1.7428e+00,  1.7364e+00,  1.7333e+00,
          1.7384e+00,  1.6812e+00,  1.7342e+00,  1.7243e+00,  1.7342e+00,
          1.6503e+00,  1.6314e+00,  1.6274e+00,  1.6193e+00,  1.6445e+00,
          1.6250e+00,  1.6626e+00,  1.6178e+00,  1.6174e+00],
        [ 1.3548e+00,  1.2611e+00,  1.1365e+00,  1.3054e+00,  1.3931e+00,
          1.3988e+00,  1.3241e+00,  1.3976e+00,  1.3976e+00,  1.8324e+00,
          1.8841e+00,  1.7889e+00,  2.1037e+00,  1.8451e+00,  3.1585e+00,
          1.8953e+00,  1.7553e+00,  2.9748e+00,  1.2611e+00,  1.3137e+00,
          1.2198e+00,  1.2474e+00,  1.3994e+00,  1.4130e+00,  1.3717e+00,
          1.4126e+00,  1.4126e+00,  1.3480e+00,  1.2176e+00,  1.4328e+00,
          1.4199e+00,  1.2150e+00,  1.4349e+00,  1.4361e+00,  1.3970e+00,
          1.4305e+00,  1.7942e+00,  1.8217e+00,  1.7627e+00,  1.7368e+00,
          1.8046e+00,  1.8176e+00,  1.7607e+00,  1.1760e+00,  1.8073e+00,
          1.4963e+00,  1.6961e+00,  1.6914e+00,  1.6819e+00,  1.4608e+00,
          1.6877e+00,  1.3897e+00,  1.6805e+00,  1.6798e+00],
        [ 1.3257e+00,  1.3288e+00,  1.3337e+00,  1.3315e+00,  1.3282e+00,
          1.3267e+00,  1.3242e+00,  1.3257e+00,  1.3257e+00,  1.3835e+00,
          1.3858e+00,  1.3847e+00,  1.3852e+00,  1.3822e+00,  1.3376e+00,
          1.3834e+00,  1.3709e+00,  1.3246e+00,  2.1739e+00,  2.1660e+00,
          2.2466e+00,  2.2124e+00,  2.0845e+00,  2.1151e+00,  2.1700e+00,
          2.0765e+00,  2.0765e+00,  1.3616e+00,  1.3277e+00,  1.3618e+00,
          1.3651e+00,  1.3603e+00,  1.3636e+00,  1.3663e+00,  1.3616e+00,
          1.3621e+00,  1.7400e+00,  1.7504e+00,  1.7439e+00,  1.7327e+00,
          1.7459e+00,  1.7453e+00,  1.7418e+00,  1.6498e+00,  1.7326e+00,
          1.6328e+00,  1.6380e+00,  1.6341e+00,  1.6260e+00,  1.5787e+00,
          1.6320e+00,  1.6418e+00,  1.6244e+00,  1.6240e+00],
        [ 1.3342e+00,  1.3373e+00,  1.3265e+00,  1.3244e+00,  1.3377e+00,
          1.3352e+00,  1.3351e+00,  1.3342e+00,  1.3342e+00,  1.3945e+00,
          1.3831e+00,  1.3952e+00,  1.3879e+00,  1.3934e+00,  1.3054e+00,
          1.3944e+00,  1.3930e+00,  1.2813e+00,  1.3524e+00,  1.3439e+00,
          1.3544e+00,  1.3534e+00,  1.3502e+00,  1.3455e+00,  1.3519e+00,
          1.3491e+00,  1.3491e+00,  2.2985e+00,  2.2204e+00,  2.0301e+00,
          2.1195e+00,  2.2954e+00,  2.0394e+00,  2.2637e+00,  2.0469e+00,
          2.0320e+00,  1.7426e+00,  1.7543e+00,  1.7300e+00,  1.7423e+00,
          1.7490e+00,  1.7467e+00,  1.7340e+00,  1.6447e+00,  1.7455e+00,
          1.6618e+00,  1.6357e+00,  1.5285e+00,  1.5743e+00,  1.6559e+00,
          1.6159e+00,  1.6750e+00,  1.5728e+00,  1.6260e+00],
        [ 1.7394e+00,  1.3916e+00,  5.3090e-01,  7.9946e-01,  1.1946e+00,
          1.6335e+00,  1.5611e+00,  1.7397e+00,  1.7397e+00,  1.6195e+00,
          1.2492e+00,  1.4343e+00,  8.5539e-01,  1.6936e+00,  9.4430e-02,
          1.5826e+00,  1.7251e+00,  9.6187e-01,  1.2942e+00,  8.4365e-01,
          6.4980e-01,  1.1031e+00,  1.5858e+00,  1.6611e+00,  1.3817e+00,
          1.7488e+00,  1.7488e+00,  7.0558e-01,  7.7948e-01,  1.7254e+00,
          1.5014e+00,  7.8445e-01,  1.6713e+00,  1.1394e+00,  1.7725e+00,
          1.6919e+00,  3.7378e-01,  4.8997e-02,  5.2859e-03,  3.0973e-01,
          7.6505e-01,  9.8170e-01,  2.0091e-01,  6.7837e+00,  5.4289e+00,
          8.5335e-02,  4.5005e-01,  4.8788e-01,  6.0219e-01,  2.7722e-01,
          6.0416e-01, -2.0496e-01,  6.2209e-01,  7.0300e-01],
        [ 1.3392e+00,  1.3746e+00,  1.4288e+00,  1.4151e+00,  1.3885e+00,
          1.3492e+00,  1.3176e+00,  1.3387e+00,  1.3387e+00,  1.3017e+00,
          1.4135e+00,  1.3215e+00,  1.4479e+00,  1.3684e+00,  1.4758e+00,
          1.3041e+00,  1.3687e+00,  1.3369e+00,  1.3920e+00,  1.4189e+00,
          1.4265e+00,  1.4032e+00,  1.3649e+00,  1.3533e+00,  1.3163e+00,
          1.3484e+00,  1.3484e+00,  1.4044e+00,  1.4389e+00,  1.3560e+00,
          1.2052e+00,  1.3472e+00,  1.2414e+00,  1.4115e+00,  1.2397e+00,
          1.3605e+00,  3.5615e-01,  2.9475e-01,  4.1173e-01,  3.6645e-01,
          1.7296e-01,  1.2336e-01,  3.8152e-01,  2.2973e-01,  3.0869e-02,
          2.5544e+00,  1.8783e+00,  2.3580e+00,  2.1265e+00,  1.5650e+00,
          1.2121e+00,  2.4056e+00,  2.1387e+00,  1.1805e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 95 : 177.30982775999223
Test loss for epoch 95 : 177.07907326581957
Test Precision for epoch 95 : 0.26153846153846155
Test Recall for epoch 95 : 0.26153846153846155
Test F1 for epoch 95 : 0.26153846153846155


theta for epoch 96 : tensor([[ 2.1068e+00,  2.1206e+00,  2.1574e+00,  2.2211e+00,  2.2021e+00,
          2.1111e+00,  2.1893e+00,  2.1067e+00,  2.1067e+00,  1.3762e+00,
          1.3780e+00,  1.3774e+00,  1.3805e+00,  1.3750e+00,  1.3826e+00,
          1.3762e+00,  1.3749e+00,  1.3356e+00,  1.3357e+00,  1.2963e+00,
          1.2978e+00,  1.3371e+00,  1.3341e+00,  1.3335e+00,  1.3360e+00,
          1.3328e+00,  1.3328e+00,  1.3169e+00,  1.3596e+00,  1.3528e+00,
          1.3562e+00,  1.3595e+00,  1.3546e+00,  1.3572e+00,  1.3109e+00,
          1.3531e+00,  1.7334e+00,  1.7438e+00,  1.7372e+00,  1.7342e+00,
          1.7395e+00,  1.6824e+00,  1.7351e+00,  1.7252e+00,  1.7351e+00,
          1.6505e+00,  1.6318e+00,  1.6278e+00,  1.6199e+00,  1.6447e+00,
          1.6255e+00,  1.6627e+00,  1.6183e+00,  1.6180e+00],
        [ 1.3545e+00,  1.2627e+00,  1.1392e+00,  1.3058e+00,  1.3931e+00,
          1.3982e+00,  1.3243e+00,  1.3971e+00,  1.3971e+00,  1.8400e+00,
          1.8901e+00,  1.7965e+00,  2.1077e+00,  1.8524e+00,  3.1526e+00,
          1.9023e+00,  1.7631e+00,  2.9742e+00,  1.2624e+00,  1.3147e+00,
          1.2217e+00,  1.2471e+00,  1.3986e+00,  1.4115e+00,  1.3702e+00,
          1.4111e+00,  1.4111e+00,  1.3488e+00,  1.2178e+00,  1.4324e+00,
          1.4203e+00,  1.2173e+00,  1.4344e+00,  1.4356e+00,  1.3966e+00,
          1.4301e+00,  1.7923e+00,  1.8200e+00,  1.7608e+00,  1.7349e+00,
          1.8027e+00,  1.8158e+00,  1.7587e+00,  1.1820e+00,  1.8059e+00,
          1.4999e+00,  1.6975e+00,  1.6928e+00,  1.6840e+00,  1.4634e+00,
          1.6895e+00,  1.3967e+00,  1.6823e+00,  1.6818e+00],
        [ 1.3259e+00,  1.3290e+00,  1.3338e+00,  1.3316e+00,  1.3284e+00,
          1.3268e+00,  1.3244e+00,  1.3258e+00,  1.3258e+00,  1.3825e+00,
          1.3848e+00,  1.3837e+00,  1.3843e+00,  1.3811e+00,  1.3367e+00,
          1.3824e+00,  1.3696e+00,  1.3242e+00,  2.1786e+00,  2.1705e+00,
          2.2513e+00,  2.2168e+00,  2.0888e+00,  2.1189e+00,  2.1744e+00,
          2.0808e+00,  2.0808e+00,  1.3615e+00,  1.3276e+00,  1.3616e+00,
          1.3649e+00,  1.3601e+00,  1.3633e+00,  1.3661e+00,  1.3614e+00,
          1.3619e+00,  1.7407e+00,  1.7514e+00,  1.7446e+00,  1.7334e+00,
          1.7469e+00,  1.7463e+00,  1.7425e+00,  1.6512e+00,  1.7332e+00,
          1.6332e+00,  1.6377e+00,  1.6337e+00,  1.6259e+00,  1.5791e+00,
          1.6318e+00,  1.6416e+00,  1.6242e+00,  1.6239e+00],
        [ 1.3344e+00,  1.3375e+00,  1.3275e+00,  1.3255e+00,  1.3379e+00,
          1.3354e+00,  1.3353e+00,  1.3344e+00,  1.3344e+00,  1.3936e+00,
          1.3827e+00,  1.3943e+00,  1.3871e+00,  1.3924e+00,  1.3047e+00,
          1.3935e+00,  1.3920e+00,  1.2811e+00,  1.3518e+00,  1.3433e+00,
          1.3539e+00,  1.3528e+00,  1.3496e+00,  1.3450e+00,  1.3513e+00,
          1.3484e+00,  1.3484e+00,  2.3015e+00,  2.2263e+00,  2.0351e+00,
          2.1249e+00,  2.2985e+00,  2.0444e+00,  2.2665e+00,  2.0521e+00,
          2.0370e+00,  1.7433e+00,  1.7551e+00,  1.7309e+00,  1.7429e+00,
          1.7499e+00,  1.7476e+00,  1.7345e+00,  1.6472e+00,  1.7463e+00,
          1.6619e+00,  1.6364e+00,  1.5293e+00,  1.5752e+00,  1.6561e+00,
          1.6176e+00,  1.6747e+00,  1.5735e+00,  1.6266e+00],
        [ 1.7467e+00,  1.3989e+00,  5.3937e-01,  8.0834e-01,  1.2035e+00,
          1.6412e+00,  1.5687e+00,  1.7470e+00,  1.7470e+00,  1.6275e+00,
          1.2570e+00,  1.4429e+00,  8.6380e-01,  1.7006e+00,  1.0336e-01,
          1.5905e+00,  1.7329e+00,  9.6817e-01,  1.3006e+00,  8.5152e-01,
          6.5783e-01,  1.1108e+00,  1.5928e+00,  1.6679e+00,  1.3897e+00,
          1.7556e+00,  1.7556e+00,  7.1571e-01,  7.8984e-01,  1.7346e+00,
          1.5106e+00,  7.9366e-01,  1.6799e+00,  1.1490e+00,  1.7815e+00,
          1.7011e+00,  3.5895e-01,  3.6825e-02, -6.2945e-03,  2.9543e-01,
          7.4502e-01,  9.5848e-01,  1.8742e-01,  6.8385e+00,  5.4511e+00,
          9.7997e-02,  4.6285e-01,  5.0095e-01,  6.1486e-01,  2.8975e-01,
          6.1678e-01, -1.9398e-01,  6.3488e-01,  7.1553e-01],
        [ 1.3338e+00,  1.3692e+00,  1.4237e+00,  1.4099e+00,  1.3833e+00,
          1.3439e+00,  1.3122e+00,  1.3333e+00,  1.3333e+00,  1.2939e+00,
          1.4066e+00,  1.3135e+00,  1.4403e+00,  1.3612e+00,  1.4680e+00,
          1.2962e+00,  1.3613e+00,  1.3293e+00,  1.3836e+00,  1.4102e+00,
          1.4181e+00,  1.3947e+00,  1.3564e+00,  1.3448e+00,  1.3069e+00,
          1.3398e+00,  1.3398e+00,  1.3984e+00,  1.4333e+00,  1.3503e+00,
          1.1986e+00,  1.3423e+00,  1.2364e+00,  1.4057e+00,  1.2338e+00,
          1.3547e+00,  3.4766e-01,  2.8564e-01,  4.0305e-01,  3.5790e-01,
          1.6379e-01,  1.1410e-01,  3.7310e-01,  2.1881e-01,  2.0123e-02,
          2.5678e+00,  1.8912e+00,  2.3745e+00,  2.1396e+00,  1.5765e+00,
          1.2241e+00,  2.4173e+00,  2.1552e+00,  1.1924e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 96 : 177.29756347871634
Test loss for epoch 96 : 177.05505127171872
Test Precision for epoch 96 : 0.26153846153846155
Test Recall for epoch 96 : 0.26153846153846155
Test F1 for epoch 96 : 0.26153846153846155


theta for epoch 97 : tensor([[ 2.1108e+00,  2.1246e+00,  2.1615e+00,  2.2253e+00,  2.2063e+00,
          2.1151e+00,  2.1935e+00,  2.1106e+00,  2.1106e+00,  1.3756e+00,
          1.3775e+00,  1.3768e+00,  1.3800e+00,  1.3744e+00,  1.3820e+00,
          1.3757e+00,  1.3743e+00,  1.3351e+00,  1.3359e+00,  1.2964e+00,
          1.2979e+00,  1.3372e+00,  1.3342e+00,  1.3336e+00,  1.3361e+00,
          1.3329e+00,  1.3329e+00,  1.3170e+00,  1.3595e+00,  1.3528e+00,
          1.3561e+00,  1.3594e+00,  1.3545e+00,  1.3571e+00,  1.3110e+00,
          1.3531e+00,  1.7356e+00,  1.7461e+00,  1.7394e+00,  1.7363e+00,
          1.7419e+00,  1.6849e+00,  1.7372e+00,  1.7273e+00,  1.7373e+00,
          1.6486e+00,  1.6301e+00,  1.6260e+00,  1.6183e+00,  1.6429e+00,
          1.6238e+00,  1.6608e+00,  1.6166e+00,  1.6164e+00],
        [ 1.3544e+00,  1.2646e+00,  1.1423e+00,  1.3065e+00,  1.3935e+00,
          1.3980e+00,  1.3248e+00,  1.3969e+00,  1.3969e+00,  1.8469e+00,
          1.8953e+00,  1.8034e+00,  2.1110e+00,  1.8589e+00,  3.1461e+00,
          1.9086e+00,  1.7701e+00,  2.9726e+00,  1.2650e+00,  1.3168e+00,
          1.2246e+00,  1.2481e+00,  1.3990e+00,  1.4112e+00,  1.3699e+00,
          1.4107e+00,  1.4107e+00,  1.3495e+00,  1.2178e+00,  1.4319e+00,
          1.4206e+00,  1.2196e+00,  1.4339e+00,  1.4351e+00,  1.3961e+00,
          1.4296e+00,  1.7919e+00,  1.8197e+00,  1.7603e+00,  1.7346e+00,
          1.8022e+00,  1.8156e+00,  1.7581e+00,  1.1896e+00,  1.8060e+00,
          1.5012e+00,  1.6966e+00,  1.6919e+00,  1.6837e+00,  1.4638e+00,
          1.6889e+00,  1.4015e+00,  1.6818e+00,  1.6816e+00],
        [ 1.3261e+00,  1.3292e+00,  1.3340e+00,  1.3319e+00,  1.3288e+00,
          1.3271e+00,  1.3248e+00,  1.3261e+00,  1.3261e+00,  1.3818e+00,
          1.3841e+00,  1.3831e+00,  1.3837e+00,  1.3805e+00,  1.3362e+00,
          1.3818e+00,  1.3688e+00,  1.3242e+00,  2.1833e+00,  2.1751e+00,
          2.2561e+00,  2.2212e+00,  2.0932e+00,  2.1228e+00,  2.1790e+00,
          2.0851e+00,  2.0851e+00,  1.3610e+00,  1.3273e+00,  1.3612e+00,
          1.3644e+00,  1.3596e+00,  1.3628e+00,  1.3656e+00,  1.3609e+00,
          1.3615e+00,  1.7428e+00,  1.7536e+00,  1.7466e+00,  1.7354e+00,
          1.7492e+00,  1.7486e+00,  1.7446e+00,  1.6539e+00,  1.7351e+00,
          1.6316e+00,  1.6354e+00,  1.6314e+00,  1.6237e+00,  1.5774e+00,
          1.6295e+00,  1.6394e+00,  1.6219e+00,  1.6217e+00],
        [ 1.3349e+00,  1.3380e+00,  1.3286e+00,  1.3267e+00,  1.3384e+00,
          1.3359e+00,  1.3358e+00,  1.3348e+00,  1.3348e+00,  1.3933e+00,
          1.3827e+00,  1.3940e+00,  1.3868e+00,  1.3920e+00,  1.3045e+00,
          1.3931e+00,  1.3916e+00,  1.2814e+00,  1.3523e+00,  1.3438e+00,
          1.3545e+00,  1.3533e+00,  1.3500e+00,  1.3454e+00,  1.3517e+00,
          1.3488e+00,  1.3488e+00,  2.3037e+00,  2.2312e+00,  2.0392e+00,
          2.1294e+00,  2.3008e+00,  2.0485e+00,  2.2686e+00,  2.0564e+00,
          2.0411e+00,  1.7454e+00,  1.7573e+00,  1.7332e+00,  1.7449e+00,
          1.7524e+00,  1.7499e+00,  1.7365e+00,  1.6511e+00,  1.7486e+00,
          1.6602e+00,  1.6352e+00,  1.5283e+00,  1.5741e+00,  1.6544e+00,
          1.6174e+00,  1.6728e+00,  1.5723e+00,  1.6254e+00],
        [ 1.7459e+00,  1.3960e+00,  5.3443e-01,  8.0512e-01,  1.2010e+00,
          1.6402e+00,  1.5672e+00,  1.7463e+00,  1.7463e+00,  1.6251e+00,
          1.2516e+00,  1.4403e+00,  8.5783e-01,  1.6976e+00,  9.5960e-02,
          1.5879e+00,  1.7309e+00,  9.5947e-01,  1.2953e+00,  8.4586e-01,
          6.5078e-01,  1.1058e+00,  1.5893e+00,  1.6647e+00,  1.3869e+00,
          1.7531e+00,  1.7531e+00,  7.1025e-01,  7.8474e-01,  1.7325e+00,
          1.5073e+00,  7.8678e-01,  1.6769e+00,  1.1443e+00,  1.7796e+00,
          1.6989e+00,  3.5715e-01,  3.6674e-02, -5.9971e-03,  2.9402e-01,
          7.3900e-01,  9.4966e-01,  1.8641e-01,  6.9056e+00,  5.4873e+00,
          9.1222e-02,  4.5716e-01,  4.9510e-01,  6.0843e-01,  2.8319e-01,
          6.1037e-01, -2.0232e-01,  6.2885e-01,  7.0929e-01],
        [ 1.3401e+00,  1.3754e+00,  1.4297e+00,  1.4160e+00,  1.3895e+00,
          1.3502e+00,  1.3185e+00,  1.3396e+00,  1.3396e+00,  1.3029e+00,
          1.4158e+00,  1.3225e+00,  1.4492e+00,  1.3703e+00,  1.4769e+00,
          1.3053e+00,  1.3702e+00,  1.3387e+00,  1.3926e+00,  1.4191e+00,
          1.4270e+00,  1.4037e+00,  1.3655e+00,  1.3539e+00,  1.3155e+00,
          1.3488e+00,  1.3488e+00,  1.4046e+00,  1.4394e+00,  1.3568e+00,
          1.2051e+00,  1.3494e+00,  1.2439e+00,  1.4118e+00,  1.2407e+00,
          1.3611e+00,  3.5626e-01,  2.9380e-01,  4.1126e-01,  3.6645e-01,
          1.7236e-01,  1.2270e-01,  3.8164e-01,  2.2551e-01,  2.7387e-02,
          2.5609e+00,  1.8836e+00,  2.3702e+00,  2.1320e+00,  1.5681e+00,
          1.2160e+00,  2.4088e+00,  2.1510e+00,  1.1843e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 97 : 177.26166314797985
Test loss for epoch 97 : 177.0298375782201
Test Precision for epoch 97 : 0.26153846153846155
Test Recall for epoch 97 : 0.26153846153846155
Test F1 for epoch 97 : 0.26153846153846155


theta for epoch 98 : tensor([[ 2.1136,  2.1275,  2.1645,  2.2285,  2.2095,  2.1180,  2.1967,  2.1135,
          2.1135,  1.3757,  1.3776,  1.3769,  1.3800,  1.3744,  1.3821,  1.3757,
          1.3743,  1.3352,  1.3357,  1.2962,  1.2976,  1.3371,  1.3340,  1.3334,
          1.3359,  1.3327,  1.3327,  1.3172,  1.3596,  1.3530,  1.3562,  1.3595,
          1.3547,  1.3573,  1.3112,  1.3533,  1.7367,  1.7474,  1.7404,  1.7374,
          1.7432,  1.6863,  1.7383,  1.7283,  1.7385,  1.6511,  1.6327,  1.6286,
          1.6211,  1.6454,  1.6265,  1.6631,  1.6193,  1.6192],
        [ 1.3540,  1.2661,  1.1450,  1.3067,  1.3934,  1.3974,  1.3249,  1.3963,
          1.3963,  1.8534,  1.9000,  1.8098,  2.1137,  1.8649,  3.1389,  1.9145,
          1.7767,  2.9705,  1.2670,  1.3185,  1.2271,  1.2486,  1.3988,  1.4104,
          1.3691,  1.4099,  1.4099,  1.3503,  1.2180,  1.4315,  1.4209,  1.2219,
          1.4333,  1.4346,  1.3956,  1.4292,  1.7905,  1.8185,  1.7589,  1.7333,
          1.8008,  1.8143,  1.7567,  1.1965,  1.8051,  1.5071,  1.7003,  1.6956,
          1.6878,  1.4686,  1.6929,  1.4109,  1.6858,  1.6857],
        [ 1.3262,  1.3292,  1.3340,  1.3319,  1.3289,  1.3271,  1.3248,  1.3261,
          1.3261,  1.3819,  1.3842,  1.3833,  1.3839,  1.3805,  1.3366,  1.3819,
          1.3686,  1.3249,  2.1864,  2.1779,  2.2592,  2.2239,  2.0960,  2.1250,
          2.1819,  2.0878,  2.0878,  1.3608,  1.3272,  1.3610,  1.3641,  1.3594,
          1.3626,  1.3654,  1.3607,  1.3613,  1.7438,  1.7547,  1.7476,  1.7364,
          1.7504,  1.7499,  1.7455,  1.6557,  1.7360,  1.6344,  1.6375,  1.6335,
          1.6260,  1.5802,  1.6317,  1.6417,  1.6241,  1.6240],
        [ 1.3351,  1.3381,  1.3294,  1.3275,  1.3385,  1.3361,  1.3359,  1.3350,
          1.3350,  1.3934,  1.3833,  1.3942,  1.3871,  1.3921,  1.3049,  1.3933,
          1.3917,  1.2822,  1.3525,  1.3440,  1.3548,  1.3535,  1.3501,  1.3457,
          1.3519,  1.3489,  1.3489,  2.3051,  2.2351,  2.0423,  2.1328,  2.3022,
          2.0516,  2.2697,  2.0597,  2.0442,  1.7464,  1.7585,  1.7345,  1.7459,
          1.7537,  1.7512,  1.7374,  1.6538,  1.7498,  1.6626,  1.6382,  1.5314,
          1.5772,  1.6570,  1.6212,  1.6750,  1.5753,  1.6284],
        [ 1.7508,  1.4003,  0.5393,  0.8108,  1.2067,  1.6454,  1.5721,  1.7512,
          1.7512,  1.6309,  1.2564,  1.4464,  0.8628,  1.7024,  0.1010,  1.5935,
          1.7365,  0.9621,  1.2989,  0.8505,  0.6553,  1.1105,  1.5937,  1.6690,
          1.3922,  1.7577,  1.7577,  0.7162,  0.7910,  1.7383,  1.5128,  0.7918,
          1.6821,  1.1500,  1.7853,  1.7046,  0.3456,  0.0273, -0.0148,  0.2829,
          0.7225,  0.9301,  0.1760,  6.9626,  5.5115,  0.1001,  0.4664,  0.5045,
          0.6173,  0.2920,  0.6192, -0.1949,  0.6379,  0.7180],
        [ 1.3358,  1.3712,  1.4256,  1.4117,  1.3853,  1.3459,  1.3142,  1.3353,
          1.3353,  1.2972,  1.4108,  1.3166,  1.4438,  1.3650,  1.4713,  1.2995,
          1.3647,  1.3334,  1.3864,  1.4128,  1.4209,  1.3975,  1.3592,  1.3476,
          1.3085,  1.3424,  1.3424,  1.3999,  1.4350,  1.3523,  1.1998,  1.3456,
          1.2400,  1.4073,  1.2361,  1.3566,  0.3501,  0.2869,  0.4049,  0.3603,
          0.1656,  0.1158,  0.3755,  0.2173,  0.0190,  2.5718,  1.8939,  2.3840,
          2.1425,  1.5773,  1.2256,  2.4181,  2.1649,  1.1938]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 98 : 177.2141329808328
Test loss for epoch 98 : 176.97414901572992
Test Precision for epoch 98 : 0.26153846153846155
Test Recall for epoch 98 : 0.26153846153846155
Test F1 for epoch 98 : 0.26153846153846155


theta for epoch 99 : tensor([[ 2.1163,  2.1303,  2.1673,  2.2314,  2.2125,  2.1206,  2.1996,  2.1162,
          2.1162,  1.3767,  1.3786,  1.3779,  1.3810,  1.3754,  1.3831,  1.3767,
          1.3753,  1.3363,  1.3367,  1.2972,  1.2985,  1.3381,  1.3350,  1.3343,
          1.3369,  1.3336,  1.3336,  1.3178,  1.3600,  1.3536,  1.3568,  1.3601,
          1.3552,  1.3578,  1.3118,  1.3539,  1.7381,  1.7490,  1.7419,  1.7389,
          1.7448,  1.6880,  1.7398,  1.7297,  1.7400,  1.6511,  1.6329,  1.6288,
          1.6215,  1.6454,  1.6268,  1.6631,  1.6196,  1.6195],
        [ 1.3534,  1.2674,  1.1475,  1.3068,  1.3931,  1.3967,  1.3249,  1.3956,
          1.3956,  1.8605,  1.9051,  1.8169,  2.1171,  1.8714,  3.1322,  1.9210,
          1.7839,  2.9686,  1.2702,  1.3213,  1.2306,  1.2502,  1.3997,  1.4107,
          1.3694,  1.4101,  1.4101,  1.3516,  1.2186,  1.4314,  1.4216,  1.2245,
          1.4331,  1.4344,  1.3955,  1.4291,  1.7895,  1.8176,  1.7579,  1.7325,
          1.7998,  1.8135,  1.7557,  1.2038,  1.8046,  1.5100,  1.7010,  1.6963,
          1.6890,  1.4705,  1.6938,  1.4175,  1.6868,  1.6869],
        [ 1.3261,  1.3291,  1.3338,  1.3319,  1.3290,  1.3270,  1.3248,  1.3261,
          1.3261,  1.3833,  1.3856,  1.3848,  1.3853,  1.3818,  1.3382,  1.3833,
          1.3698,  1.3269,  2.1896,  2.1810,  2.2624,  2.2268,  2.0989,  2.1274,
          2.1849,  2.0908,  2.0908,  1.3611,  1.3276,  1.3613,  1.3644,  1.3596,
          1.3629,  1.3656,  1.3610,  1.3616,  1.7451,  1.7562,  1.7490,  1.7377,
          1.7520,  1.7515,  1.7469,  1.6578,  1.7373,  1.6349,  1.6373,  1.6332,
          1.6259,  1.5806,  1.6315,  1.6416,  1.6240,  1.6239],
        [ 1.3351,  1.3381,  1.3300,  1.3281,  1.3385,  1.3361,  1.3359,  1.3350,
          1.3350,  1.3946,  1.3848,  1.3954,  1.3883,  1.3932,  1.3062,  1.3945,
          1.3928,  1.2839,  1.3536,  1.3452,  1.3560,  1.3547,  1.3512,  1.3468,
          1.3530,  1.3500,  1.3500,  2.3069,  2.2393,  2.0458,  2.1367,  2.3040,
          2.0550,  2.2714,  2.0633,  2.0477,  1.7478,  1.7600,  1.7361,  1.7472,
          1.7553,  1.7528,  1.7387,  1.6566,  1.7512,  1.6627,  1.6387,  1.5320,
          1.5778,  1.6571,  1.6225,  1.6749,  1.5758,  1.6290],
        [ 1.7521,  1.4002,  0.5384,  0.8112,  1.2074,  1.6467,  1.5729,  1.7526,
          1.7526,  1.6327,  1.2561,  1.4482,  0.8621,  1.7034,  0.0995,  1.5951,
          1.7386,  0.9587,  1.2979,  0.8498,  0.6538,  1.1101,  1.5941,  1.6696,
          1.3934,  1.7587,  1.7587,  0.7160,  0.7911,  1.7397,  1.5135,  0.7904,
          1.6829,  1.1500,  1.7868,  1.7059,  0.3394,  0.0230, -0.0187,  0.2772,
          0.7119,  0.9165,  0.1709,  7.0248,  5.5414,  0.1004,  0.4671,  0.5051,
          0.6172,  0.2921,  0.6192, -0.1960,  0.6382,  0.7180],
        [ 1.3364,  1.3717,  1.4261,  1.4123,  1.3859,  1.3466,  1.3148,  1.3359,
          1.3359,  1.2992,  1.4134,  1.3186,  1.4461,  1.3673,  1.4735,  1.3014,
          1.3668,  1.3360,  1.3882,  1.4145,  1.4228,  1.3993,  1.3609,  1.3494,
          1.3096,  1.3440,  1.3440,  1.4009,  1.4361,  1.3535,  1.2005,  1.3474,
          1.2419,  1.4083,  1.2374,  1.3577,  0.3511,  0.2873,  0.4056,  0.3612,
          0.1662,  0.1164,  0.3765,  0.2165,  0.0182,  2.5738,  1.8953,  2.3887,
          2.1440,  1.5777,  1.2264,  2.4184,  2.1697,  1.1945]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 99 : 177.18394838113784
Test loss for epoch 99 : 176.94550777449768
Test Precision for epoch 99 : 0.26153846153846155
Test Recall for epoch 99 : 0.26153846153846155
Test F1 for epoch 99 : 0.26153846153846155


theta for epoch 100 : tensor([[ 2.1198,  2.1339,  2.1710,  2.2352,  2.2163,  2.1241,  2.2033,  2.1196,
          2.1196,  1.3773,  1.3794,  1.3786,  1.3817,  1.3760,  1.3838,  1.3774,
          1.3759,  1.3371,  1.3379,  1.2983,  1.2995,  1.3392,  1.3361,  1.3354,
          1.3380,  1.3347,  1.3347,  1.3187,  1.3608,  1.3545,  1.3576,  1.3609,
          1.3561,  1.3587,  1.3127,  1.3548,  1.7394,  1.7504,  1.7431,  1.7401,
          1.7463,  1.6895,  1.7410,  1.7309,  1.7413,  1.6494,  1.6313,  1.6271,
          1.6200,  1.6437,  1.6252,  1.6613,  1.6180,  1.6180],
        [ 1.3531,  1.2689,  1.1502,  1.3070,  1.3931,  1.3963,  1.3251,  1.3952,
          1.3952,  1.8682,  1.9107,  1.8245,  2.1209,  1.8784,  3.1259,  1.9281,
          1.7916,  2.9671,  1.2736,  1.3243,  1.2342,  1.2521,  1.4009,  1.4112,
          1.3699,  1.4106,  1.4106,  1.3532,  1.2195,  1.4317,  1.4226,  1.2275,
          1.4333,  1.4347,  1.3958,  1.4294,  1.7886,  1.8168,  1.7569,  1.7318,
          1.7988,  1.8127,  1.7547,  1.2112,  1.8041,  1.5107,  1.6997,  1.6950,
          1.6881,  1.4703,  1.6927,  1.4219,  1.6857,  1.6860],
        [ 1.3264,  1.3294,  1.3340,  1.3321,  1.3293,  1.3273,  1.3251,  1.3263,
          1.3263,  1.3844,  1.3867,  1.3859,  1.3865,  1.3829,  1.3396,  1.3844,
          1.3707,  1.3287,  2.1936,  2.1847,  2.2663,  2.2304,  2.1027,  2.1306,
          2.1887,  2.0945,  2.0945,  1.3619,  1.3284,  1.3621,  1.3651,  1.3604,
          1.3636,  1.3664,  1.3618,  1.3624,  1.7464,  1.7576,  1.7502,  1.7389,
          1.7534,  1.7529,  1.7481,  1.6598,  1.7384,  1.6338,  1.6355,  1.6314,
          1.6242,  1.5794,  1.6297,  1.6400,  1.6222,  1.6222],
        [ 1.3352,  1.3382,  1.3306,  1.3288,  1.3386,  1.3362,  1.3361,  1.3352,
          1.3352,  1.3952,  1.3858,  1.3961,  1.3889,  1.3938,  1.3069,  1.3952,
          1.3934,  1.2851,  1.3548,  1.3464,  1.3572,  1.3559,  1.3523,  1.3481,
          1.3542,  1.3511,  1.3511,  2.3100,  2.2447,  2.0505,  2.1417,  2.3072,
          2.0597,  2.2742,  2.0682,  2.0523,  1.7490,  1.7612,  1.7374,  1.7483,
          1.7568,  1.7541,  1.7398,  1.6591,  1.7525,  1.6611,  1.6375,  1.5308,
          1.5767,  1.6556,  1.6219,  1.6731,  1.5746,  1.6278],
        [ 1.7536,  1.4001,  0.5374,  0.8115,  1.2082,  1.6481,  1.5739,  1.7542,
          1.7542,  1.6344,  1.2555,  1.4497,  0.8610,  1.7042,  0.0975,  1.5965,
          1.7404,  0.9548,  1.2968,  0.8490,  0.6522,  1.1097,  1.5947,  1.6703,
          1.3946,  1.7600,  1.7600,  0.7156,  0.7911,  1.7413,  1.5144,  0.7889,
          1.6840,  1.1501,  1.7885,  1.7074,  0.3337,  0.0190, -0.0223,  0.2718,
          0.7017,  0.9033,  0.1661,  7.0874,  5.5711,  0.0996,  0.4666,  0.5045,
          0.6158,  0.2911,  0.6177, -0.1979,  0.6371,  0.7165],
        [ 1.3383,  1.3736,  1.4279,  1.4140,  1.3878,  1.3485,  1.3167,  1.3378,
          1.3378,  1.3023,  1.4170,  1.3216,  1.4495,  1.3707,  1.4769,  1.3045,
          1.3700,  1.3397,  1.3917,  1.4179,  1.4264,  1.4028,  1.3643,  1.3528,
          1.3124,  1.3473,  1.3473,  1.4033,  1.4386,  1.3562,  1.2028,  1.3505,
          1.2451,  1.4109,  1.2401,  1.3603,  0.3532,  0.2886,  0.4073,  0.3632,
          0.1679,  0.1181,  0.3785,  0.2169,  0.0185,  2.5741,  1.8949,  2.3917,
          2.1436,  1.5764,  1.2254,  2.4171,  2.1728,  1.1933]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 100 : 177.1733648504863
Test loss for epoch 100 : 176.9378099150731
Test Precision for epoch 100 : 0.26153846153846155
Test Recall for epoch 100 : 0.26153846153846155
Test F1 for epoch 100 : 0.26153846153846155


theta for epoch 101 : tensor([[ 2.1241,  2.1383,  2.1755,  2.2399,  2.2210,  2.1285,  2.2079,  2.1239,
          2.1239,  1.3768,  1.3788,  1.3780,  1.3812,  1.3754,  1.3833,  1.3768,
          1.3753,  1.3366,  1.3377,  1.2980,  1.2992,  1.3391,  1.3358,  1.3352,
          1.3378,  1.3344,  1.3344,  1.3192,  1.3613,  1.3551,  1.3582,  1.3614,
          1.3567,  1.3592,  1.3133,  1.3554,  1.7400,  1.7511,  1.7437,  1.7407,
          1.7470,  1.6903,  1.7416,  1.7315,  1.7420,  1.6493,  1.6313,  1.6271,
          1.6201,  1.6437,  1.6253,  1.6611,  1.6181,  1.6182],
        [ 1.3531,  1.2707,  1.1532,  1.3076,  1.3934,  1.3961,  1.3257,  1.3950,
          1.3950,  1.8760,  1.9163,  1.8322,  2.1249,  1.8856,  3.1196,  1.9353,
          1.7996,  2.9656,  1.2757,  1.3260,  1.2365,  1.2527,  1.4008,  1.4104,
          1.3691,  1.4098,  1.4098,  1.3546,  1.2201,  1.4317,  1.4234,  1.2302,
          1.4333,  1.4347,  1.3958,  1.4295,  1.7871,  1.8155,  1.7555,  1.7305,
          1.7973,  1.8114,  1.7532,  1.2182,  1.8030,  1.5132,  1.7000,  1.6953,
          1.6887,  1.4718,  1.6933,  1.4280,  1.6863,  1.6867],
        [ 1.3270,  1.3300,  1.3346,  1.3327,  1.3300,  1.3279,  1.3258,  1.3270,
          1.3270,  1.3843,  1.3866,  1.3859,  1.3865,  1.3827,  1.3400,  1.3844,
          1.3704,  1.3291,  2.1976,  2.1886,  2.2703,  2.2340,  2.1065,  2.1339,
          2.1926,  2.0983,  2.0983,  1.3625,  1.3291,  1.3627,  1.3656,  1.3609,
          1.3642,  1.3669,  1.3623,  1.3630,  1.7469,  1.7583,  1.7508,  1.7395,
          1.7542,  1.7537,  1.7487,  1.6612,  1.7390,  1.6344,  1.6355,  1.6314,
          1.6243,  1.5800,  1.6298,  1.6401,  1.6222,  1.6223],
        [ 1.3357,  1.3387,  1.3316,  1.3297,  1.3391,  1.3367,  1.3366,  1.3357,
          1.3357,  1.3946,  1.3855,  1.3955,  1.3883,  1.3931,  1.3063,  1.3946,
          1.3927,  1.2850,  1.3549,  1.3465,  1.3573,  1.3560,  1.3523,  1.3482,
          1.3543,  1.3511,  1.3511,  2.3137,  2.2507,  2.0557,  2.1472,  2.3109,
          2.0648,  2.2777,  2.0735,  2.0574,  1.7496,  1.7618,  1.7381,  1.7488,
          1.7575,  1.7549,  1.7403,  1.6608,  1.7531,  1.6611,  1.6380,  1.5311,
          1.5771,  1.6556,  1.6229,  1.6729,  1.5750,  1.6282],
        [ 1.7597,  1.4056,  0.5435,  0.8183,  1.2151,  1.6545,  1.5799,  1.7603,
          1.7603,  1.6412,  1.2613,  1.4566,  0.8669,  1.7099,  0.1036,  1.6029,
          1.7469,  0.9582,  1.3018,  0.8552,  0.6585,  1.1158,  1.6007,  1.6761,
          1.4012,  1.7661,  1.7661,  0.7231,  0.7989,  1.7483,  1.5213,  0.7955,
          1.6907,  1.1573,  1.7955,  1.7143,  0.3215,  0.0089, -0.0318,  0.2602,
          0.6847,  0.8832,  0.1551,  7.1433,  5.5927,  0.1088,  0.4755,  0.5134,
          0.6240,  0.2998,  0.6259, -0.1896,  0.6455,  0.7244],
        [ 1.3350,  1.3703,  1.4246,  1.4107,  1.3845,  1.3453,  1.3133,  1.3345,
          1.3345,  1.2965,  1.4119,  1.3157,  1.4442,  1.3653,  1.4714,  1.2986,
          1.3644,  1.3345,  1.3864,  1.4126,  1.4213,  1.3976,  1.3589,  1.3474,
          1.3063,  1.3418,  1.3418,  1.3997,  1.4353,  1.3528,  1.1984,  1.3475,
          1.2419,  1.4075,  1.2364,  1.3569,  0.3470,  0.2815,  0.4008,  0.3569,
          0.1609,  0.1111,  0.3722,  0.2089,  0.0100,  2.5844,  1.9045,  2.4048,
          2.1533,  1.5850,  1.2342,  2.4257,  2.1860,  1.2020]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 101 : 177.1665428163536
Test loss for epoch 101 : 176.9225342965785
Test Precision for epoch 101 : 0.26153846153846155
Test Recall for epoch 101 : 0.26153846153846155
Test F1 for epoch 101 : 0.26153846153846155


theta for epoch 102 : tensor([[ 2.1286,  2.1429,  2.1801,  2.2447,  2.2258,  2.1330,  2.2127,  2.1284,
          2.1284,  1.3763,  1.3785,  1.3777,  1.3809,  1.3750,  1.3830,  1.3764,
          1.3749,  1.3362,  1.3376,  1.2978,  1.2989,  1.3390,  1.3357,  1.3350,
          1.3376,  1.3342,  1.3342,  1.3190,  1.3610,  1.3549,  1.3579,  1.3611,
          1.3564,  1.3590,  1.3131,  1.3552,  1.7418,  1.7530,  1.7455,  1.7426,
          1.7490,  1.6923,  1.7434,  1.7333,  1.7438,  1.6474,  1.6295,  1.6253,
          1.6184,  1.6418,  1.6235,  1.6592,  1.6163,  1.6164],
        [ 1.3530,  1.2724,  1.1560,  1.3080,  1.3936,  1.3960,  1.3263,  1.3949,
          1.3949,  1.8843,  1.9222,  1.8403,  2.1291,  1.8930,  3.1135,  1.9429,
          1.8078,  2.9643,  1.2778,  1.3277,  1.2388,  1.2533,  1.4008,  1.4098,
          1.3684,  1.4091,  1.4091,  1.3551,  1.2200,  1.4309,  1.4233,  1.2320,
          1.4324,  1.4339,  1.3950,  1.4287,  1.7871,  1.8155,  1.7555,  1.7307,
          1.7972,  1.8115,  1.7531,  1.2264,  1.8033,  1.5135,  1.6981,  1.6934,
          1.6872,  1.4711,  1.6916,  1.4318,  1.6846,  1.6852],
        [ 1.3276,  1.3305,  1.3350,  1.3332,  1.3306,  1.3284,  1.3263,  1.3275,
          1.3275,  1.3843,  1.3866,  1.3860,  1.3866,  1.3827,  1.3404,  1.3844,
          1.3703,  1.3296,  2.2022,  2.1929,  2.2747,  2.2382,  2.1109,  2.1377,
          2.1970,  2.1027,  2.1027,  1.3622,  1.3289,  1.3625,  1.3654,  1.3606,
          1.3639,  1.3667,  1.3621,  1.3627,  1.7488,  1.7602,  1.7526,  1.7413,
          1.7561,  1.7556,  1.7505,  1.6638,  1.7407,  1.6333,  1.6337,  1.6295,
          1.6225,  1.5788,  1.6280,  1.6385,  1.6204,  1.6206],
        [ 1.3363,  1.3391,  1.3325,  1.3306,  1.3396,  1.3372,  1.3371,  1.3362,
          1.3362,  1.3943,  1.3855,  1.3954,  1.3881,  1.3928,  1.3060,  1.3943,
          1.3924,  1.2852,  1.3551,  1.3468,  1.3577,  1.3563,  1.3526,  1.3486,
          1.3546,  1.3513,  1.3513,  2.3169,  2.2559,  2.0602,  2.1521,  2.3141,
          2.0693,  2.2807,  2.0782,  2.0619,  1.7515,  1.7638,  1.7402,  1.7507,
          1.7596,  1.7569,  1.7421,  1.6637,  1.7550,  1.6596,  1.6367,  1.5298,
          1.5758,  1.6541,  1.6222,  1.6713,  1.5736,  1.6270],
        [ 1.7597,  1.4035,  0.5396,  0.8161,  1.2135,  1.6543,  1.5791,  1.7604,
          1.7604,  1.6402,  1.2574,  1.4552,  0.8622,  1.7080,  0.0975,  1.6015,
          1.7462,  0.9503,  1.2978,  0.8511,  0.6533,  1.1122,  1.5986,  1.6743,
          1.3997,  1.7649,  1.7649,  0.7187,  0.7949,  1.7466,  1.5187,  0.7899,
          1.6884,  1.1536,  1.7939,  1.7124,  0.3191,  0.0079, -0.0324,  0.2582,
          0.6782,  0.8738,  0.1536,  7.2085,  5.6249,  0.1035,  0.4706,  0.5083,
          0.6180,  0.2943,  0.6199, -0.1957,  0.6399,  0.7185],
        [ 1.3409,  1.3761,  1.4301,  1.4163,  1.3902,  1.3512,  1.3192,  1.3404,
          1.3404,  1.3039,  1.4195,  1.3231,  1.4517,  1.3728,  1.4790,  1.3061,
          1.3716,  1.3426,  1.3945,  1.4206,  1.4294,  1.4057,  1.3669,  1.3555,
          1.3139,  1.3497,  1.3497,  1.4053,  1.4408,  1.3586,  1.2041,  1.3536,
          1.2483,  1.4131,  1.2426,  1.3627,  0.3542,  0.2881,  0.4076,  0.3640,
          0.1680,  0.1182,  0.3793,  0.2150,  0.0159,  2.5790,  1.8984,  2.4020,
          2.1473,  1.5782,  1.2275,  2.4188,  2.1833,  1.1953]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 102 : 177.14755930735436
Test loss for epoch 102 : 176.91264106888508
Test Precision for epoch 102 : 0.26153846153846155
Test Recall for epoch 102 : 0.26153846153846155
Test F1 for epoch 102 : 0.26153846153846155


theta for epoch 103 : tensor([[ 2.1318e+00,  2.1463e+00,  2.1836e+00,  2.2483e+00,  2.2294e+00,
          2.1363e+00,  2.2163e+00,  2.1317e+00,  2.1317e+00,  1.3762e+00,
          1.3783e+00,  1.3775e+00,  1.3807e+00,  1.3748e+00,  1.3829e+00,
          1.3763e+00,  1.3746e+00,  1.3361e+00,  1.3370e+00,  1.2971e+00,
          1.2981e+00,  1.3383e+00,  1.3350e+00,  1.3343e+00,  1.3369e+00,
          1.3336e+00,  1.3336e+00,  1.3186e+00,  1.3606e+00,  1.3546e+00,
          1.3575e+00,  1.3607e+00,  1.3561e+00,  1.3586e+00,  1.3127e+00,
          1.3548e+00,  1.7430e+00,  1.7543e+00,  1.7467e+00,  1.7438e+00,
          1.7504e+00,  1.6936e+00,  1.7446e+00,  1.7344e+00,  1.7451e+00,
          1.6500e+00,  1.6322e+00,  1.6280e+00,  1.6212e+00,  1.6445e+00,
          1.6262e+00,  1.6617e+00,  1.6191e+00,  1.6192e+00],
        [ 1.3522e+00,  1.2733e+00,  1.1582e+00,  1.3077e+00,  1.3931e+00,
          1.3951e+00,  1.3262e+00,  1.3940e+00,  1.3940e+00,  1.8921e+00,
          1.9276e+00,  1.8480e+00,  2.1330e+00,  1.9000e+00,  3.1070e+00,
          1.9501e+00,  1.8157e+00,  2.9624e+00,  1.2790e+00,  1.3285e+00,
          1.2403e+00,  1.2531e+00,  1.3998e+00,  1.4082e+00,  1.3667e+00,
          1.4075e+00,  1.4075e+00,  1.3553e+00,  1.2194e+00,  1.4297e+00,
          1.4228e+00,  1.2335e+00,  1.4312e+00,  1.4327e+00,  1.3938e+00,
          1.4276e+00,  1.7865e+00,  1.8150e+00,  1.7549e+00,  1.7303e+00,
          1.7966e+00,  1.8109e+00,  1.7525e+00,  1.2340e+00,  1.8030e+00,
          1.5184e+00,  1.7007e+00,  1.6961e+00,  1.6900e+00,  1.4750e+00,
          1.6944e+00,  1.4401e+00,  1.6874e+00,  1.6881e+00],
        [ 1.3273e+00,  1.3302e+00,  1.3347e+00,  1.3329e+00,  1.3304e+00,
          1.3282e+00,  1.3261e+00,  1.3273e+00,  1.3273e+00,  1.3842e+00,
          1.3866e+00,  1.3859e+00,  1.3866e+00,  1.3826e+00,  1.3408e+00,
          1.3843e+00,  1.3700e+00,  1.3301e+00,  2.2059e+00,  2.1963e+00,
          2.2783e+00,  2.2414e+00,  2.1145e+00,  2.1407e+00,  2.2006e+00,
          2.1063e+00,  2.1063e+00,  1.3616e+00,  1.3283e+00,  1.3619e+00,
          1.3647e+00,  1.3599e+00,  1.3633e+00,  1.3660e+00,  1.3615e+00,
          1.3621e+00,  1.7498e+00,  1.7614e+00,  1.7537e+00,  1.7423e+00,
          1.7574e+00,  1.7569e+00,  1.7516e+00,  1.6657e+00,  1.7418e+00,
          1.6364e+00,  1.6363e+00,  1.6320e+00,  1.6251e+00,  1.5819e+00,
          1.6305e+00,  1.6411e+00,  1.6230e+00,  1.6231e+00],
        [ 1.3362e+00,  1.3390e+00,  1.3327e+00,  1.3309e+00,  1.3395e+00,
          1.3372e+00,  1.3370e+00,  1.3361e+00,  1.3361e+00,  1.3941e+00,
          1.3856e+00,  1.3952e+00,  1.3879e+00,  1.3925e+00,  1.3057e+00,
          1.3941e+00,  1.3921e+00,  1.2855e+00,  1.3548e+00,  1.3465e+00,
          1.3573e+00,  1.3560e+00,  1.3522e+00,  1.3483e+00,  1.3542e+00,
          1.3509e+00,  1.3509e+00,  2.3192e+00,  2.2601e+00,  2.0637e+00,
          2.1560e+00,  2.3164e+00,  2.0728e+00,  2.2828e+00,  2.0818e+00,
          2.0654e+00,  1.7528e+00,  1.7650e+00,  1.7416e+00,  1.7519e+00,
          1.7611e+00,  1.7583e+00,  1.7433e+00,  1.6659e+00,  1.7563e+00,
          1.6623e+00,  1.6397e+00,  1.5326e+00,  1.5787e+00,  1.6568e+00,
          1.6255e+00,  1.6738e+00,  1.5765e+00,  1.6300e+00],
        [ 1.7650e+00,  1.4082e+00,  5.4513e-01,  8.2240e-01,  1.2197e+00,
          1.6598e+00,  1.5842e+00,  1.7658e+00,  1.7658e+00,  1.6469e+00,
          1.2632e+00,  1.4619e+00,  8.6794e-01,  1.7136e+00,  1.0354e-01,
          1.6078e+00,  1.7526e+00,  9.5351e-01,  1.3025e+00,  8.5710e-01,
          6.5938e-01,  1.1181e+00,  1.6043e+00,  1.6798e+00,  1.4061e+00,
          1.7707e+00,  1.7707e+00,  7.2535e-01,  8.0184e-01,  1.7521e+00,
          1.5245e+00,  7.9567e-01,  1.6939e+00,  1.1597e+00,  1.7994e+00,
          1.7179e+00,  3.0750e-01, -1.7884e-03, -4.1658e-02,  2.4699e-01,
          6.6185e-01,  8.5429e-01,  1.4315e-01,  7.2641e+00,  5.6454e+00,
          1.1321e-01,  4.8000e-01,  5.1778e-01,  6.2680e-01,  3.0340e-01,
          6.2862e-01, -1.8667e-01,  6.4887e-01,  7.2697e-01],
        [ 1.3364e+00,  1.3718e+00,  1.4257e+00,  1.4119e+00,  1.3859e+00,
          1.3468e+00,  1.3147e+00,  1.3360e+00,  1.3360e+00,  1.2974e+00,
          1.4137e+00,  1.3166e+00,  1.4457e+00,  1.3667e+00,  1.4729e+00,
          1.2995e+00,  1.3652e+00,  1.3368e+00,  1.3882e+00,  1.4143e+00,
          1.4234e+00,  1.3995e+00,  1.3605e+00,  1.3491e+00,  1.3067e+00,
          1.3431e+00,  1.3431e+00,  1.4004e+00,  1.4362e+00,  1.3538e+00,
          1.1983e+00,  1.3491e+00,  1.2436e+00,  1.4084e+00,  1.2374e+00,
          1.3578e+00,  3.4783e-01,  2.8084e-01,  4.0106e-01,  3.5763e-01,
          1.6098e-01,  1.1103e-01,  3.7284e-01,  2.0718e-01,  7.3295e-03,
          2.5903e+00,  1.9091e+00,  2.4161e+00,  2.1580e+00,  1.5879e+00,
          1.2374e+00,  2.4285e+00,  2.1975e+00,  1.2051e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 103 : 177.11182349183943
Test loss for epoch 103 : 176.86805662416694
Test Precision for epoch 103 : 0.26153846153846155
Test Recall for epoch 103 : 0.26153846153846155
Test F1 for epoch 103 : 0.26153846153846155


theta for epoch 104 : tensor([[ 2.1345e+00,  2.1491e+00,  2.1865e+00,  2.2513e+00,  2.2325e+00,
          2.1390e+00,  2.2192e+00,  2.1344e+00,  2.1344e+00,  1.3767e+00,
          1.3790e+00,  1.3782e+00,  1.3814e+00,  1.3753e+00,  1.3835e+00,
          1.3768e+00,  1.3752e+00,  1.3367e+00,  1.3375e+00,  1.2976e+00,
          1.2984e+00,  1.3388e+00,  1.3355e+00,  1.3348e+00,  1.3374e+00,
          1.3340e+00,  1.3340e+00,  1.3187e+00,  1.3607e+00,  1.3547e+00,
          1.3576e+00,  1.3608e+00,  1.3561e+00,  1.3587e+00,  1.3128e+00,
          1.3549e+00,  1.7450e+00,  1.7563e+00,  1.7487e+00,  1.7458e+00,
          1.7525e+00,  1.6957e+00,  1.7466e+00,  1.7363e+00,  1.7471e+00,
          1.6502e+00,  1.6325e+00,  1.6283e+00,  1.6215e+00,  1.6447e+00,
          1.6265e+00,  1.6619e+00,  1.6194e+00,  1.6196e+00],
        [ 1.3512e+00,  1.2741e+00,  1.1600e+00,  1.3072e+00,  1.3924e+00,
          1.3940e+00,  1.3258e+00,  1.3930e+00,  1.3930e+00,  1.8998e+00,
          1.9327e+00,  1.8554e+00,  2.1365e+00,  1.9067e+00,  3.1002e+00,
          1.9571e+00,  1.8233e+00,  2.9601e+00,  1.2814e+00,  1.3304e+00,
          1.2429e+00,  1.2542e+00,  1.4000e+00,  1.4078e+00,  1.3663e+00,
          1.4070e+00,  1.4070e+00,  1.3560e+00,  1.2194e+00,  1.4290e+00,
          1.4227e+00,  1.2354e+00,  1.4304e+00,  1.4320e+00,  1.3931e+00,
          1.4269e+00,  1.7868e+00,  1.8153e+00,  1.7552e+00,  1.7309e+00,
          1.7968e+00,  1.8113e+00,  1.7528e+00,  1.2425e+00,  1.8035e+00,
          1.5205e+00,  1.7005e+00,  1.6958e+00,  1.6899e+00,  1.4762e+00,
          1.6943e+00,  1.4456e+00,  1.6873e+00,  1.6880e+00],
        [ 1.3267e+00,  1.3296e+00,  1.3340e+00,  1.3322e+00,  1.3298e+00,
          1.3276e+00,  1.3254e+00,  1.3267e+00,  1.3267e+00,  1.3847e+00,
          1.3871e+00,  1.3865e+00,  1.3871e+00,  1.3830e+00,  1.3417e+00,
          1.3848e+00,  1.3704e+00,  1.3311e+00,  2.2100e+00,  2.2002e+00,
          2.2822e+00,  2.2451e+00,  2.1185e+00,  2.1441e+00,  2.2045e+00,
          2.1103e+00,  2.1103e+00,  1.3613e+00,  1.3282e+00,  1.3616e+00,
          1.3645e+00,  1.3596e+00,  1.3630e+00,  1.3658e+00,  1.3612e+00,
          1.3619e+00,  1.7516e+00,  1.7632e+00,  1.7554e+00,  1.7440e+00,
          1.7592e+00,  1.7588e+00,  1.7533e+00,  1.6682e+00,  1.7435e+00,
          1.6370e+00,  1.6363e+00,  1.6320e+00,  1.6251e+00,  1.5824e+00,
          1.6305e+00,  1.6413e+00,  1.6230e+00,  1.6232e+00],
        [ 1.3358e+00,  1.3386e+00,  1.3326e+00,  1.3308e+00,  1.3390e+00,
          1.3367e+00,  1.3366e+00,  1.3357e+00,  1.3357e+00,  1.3944e+00,
          1.3863e+00,  1.3957e+00,  1.3883e+00,  1.3928e+00,  1.3060e+00,
          1.3945e+00,  1.3925e+00,  1.2863e+00,  1.3553e+00,  1.3470e+00,
          1.3578e+00,  1.3565e+00,  1.3527e+00,  1.3489e+00,  1.3547e+00,
          1.3514e+00,  1.3514e+00,  2.3217e+00,  2.2645e+00,  2.0674e+00,
          2.1600e+00,  2.3189e+00,  2.0764e+00,  2.2851e+00,  2.0856e+00,
          2.0690e+00,  1.7548e+00,  1.7670e+00,  1.7437e+00,  1.7539e+00,
          1.7632e+00,  1.7604e+00,  1.7452e+00,  1.6686e+00,  1.7582e+00,
          1.6625e+00,  1.6402e+00,  1.5329e+00,  1.5791e+00,  1.6570e+00,
          1.6264e+00,  1.6740e+00,  1.5769e+00,  1.6305e+00],
        [ 1.7653e+00,  1.4067e+00,  5.4267e-01,  8.2139e-01,  1.2189e+00,
          1.6600e+00,  1.5838e+00,  1.7662e+00,  1.7662e+00,  1.6476e+00,
          1.2615e+00,  1.4622e+00,  8.6547e-01,  1.7134e+00,  1.0018e-01,
          1.6080e+00,  1.7535e+00,  9.4807e-01,  1.3005e+00,  8.5535e-01,
          6.5684e-01,  1.1166e+00,  1.6040e+00,  1.6797e+00,  1.4063e+00,
          1.7712e+00,  1.7712e+00,  7.2330e-01,  8.0020e-01,  1.7516e+00,
          1.5235e+00,  7.9247e-01,  1.6931e+00,  1.1581e+00,  1.7991e+00,
          1.7172e+00,  3.0338e-01, -4.5343e-03, -4.4023e-02,  2.4325e-01,
          6.5358e-01,  8.4310e-01,  1.3990e-01,  7.3269e+00,  5.6740e+00,
          1.1134e-01,  4.7828e-01,  5.1592e-01,  6.2419e-01,  3.0115e-01,
          6.2597e-01, -1.8908e-01,  6.4657e-01,  7.2428e-01],
        [ 1.3385e+00,  1.3738e+00,  1.4276e+00,  1.4138e+00,  1.3879e+00,
          1.3490e+00,  1.3168e+00,  1.3381e+00,  1.3381e+00,  1.3007e+00,
          1.4174e+00,  1.3199e+00,  1.4494e+00,  1.3701e+00,  1.4766e+00,
          1.3028e+00,  1.3685e+00,  1.3409e+00,  1.3922e+00,  1.4182e+00,
          1.4275e+00,  1.4036e+00,  1.3643e+00,  1.3530e+00,  1.3101e+00,
          1.3469e+00,  1.3469e+00,  1.4029e+00,  1.4387e+00,  1.3566e+00,
          1.2006e+00,  1.3521e+00,  1.2466e+00,  1.4111e+00,  1.2402e+00,
          1.3605e+00,  3.5124e-01,  2.8353e-01,  4.0414e-01,  3.6098e-01,
          1.6410e-01,  1.1414e-01,  3.7611e-01,  2.0956e-01,  9.1963e-03,
          2.5900e+00,  1.9080e+00,  2.4184e+00,  2.1570e+00,  1.5861e+00,
          1.2358e+00,  2.4265e+00,  2.1999e+00,  1.2034e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 104 : 177.0777846813061
Test loss for epoch 104 : 176.83843461365163
Test Precision for epoch 104 : 0.26153846153846155
Test Recall for epoch 104 : 0.26153846153846155
Test F1 for epoch 104 : 0.26153846153846155


theta for epoch 105 : tensor([[ 2.1377e+00,  2.1524e+00,  2.1898e+00,  2.2547e+00,  2.2360e+00,
          2.1421e+00,  2.2226e+00,  2.1375e+00,  2.1375e+00,  1.3771e+00,
          1.3794e+00,  1.3786e+00,  1.3818e+00,  1.3757e+00,  1.3840e+00,
          1.3772e+00,  1.3755e+00,  1.3372e+00,  1.3378e+00,  1.2977e+00,
          1.2985e+00,  1.3391e+00,  1.3357e+00,  1.3350e+00,  1.3376e+00,
          1.3342e+00,  1.3342e+00,  1.3193e+00,  1.3613e+00,  1.3554e+00,
          1.3583e+00,  1.3615e+00,  1.3568e+00,  1.3594e+00,  1.3134e+00,
          1.3556e+00,  1.7462e+00,  1.7576e+00,  1.7499e+00,  1.7470e+00,
          1.7538e+00,  1.6970e+00,  1.7478e+00,  1.7375e+00,  1.7483e+00,
          1.6501e+00,  1.6323e+00,  1.6281e+00,  1.6214e+00,  1.6445e+00,
          1.6264e+00,  1.6617e+00,  1.6193e+00,  1.6195e+00],
        [ 1.3507e+00,  1.2752e+00,  1.1622e+00,  1.3070e+00,  1.3920e+00,
          1.3933e+00,  1.3260e+00,  1.3923e+00,  1.3923e+00,  1.9072e+00,
          1.9374e+00,  1.8626e+00,  2.1397e+00,  1.9131e+00,  3.0932e+00,
          1.9638e+00,  1.8307e+00,  2.9574e+00,  1.2837e+00,  1.3322e+00,
          1.2455e+00,  1.2552e+00,  1.4002e+00,  1.4073e+00,  1.3658e+00,
          1.4066e+00,  1.4066e+00,  1.3575e+00,  1.2201e+00,  1.4290e+00,
          1.4234e+00,  1.2382e+00,  1.4304e+00,  1.4321e+00,  1.3931e+00,
          1.4270e+00,  1.7866e+00,  1.8151e+00,  1.7550e+00,  1.7309e+00,
          1.7965e+00,  1.8111e+00,  1.7526e+00,  1.2505e+00,  1.8034e+00,
          1.5221e+00,  1.6998e+00,  1.6951e+00,  1.6894e+00,  1.4770e+00,
          1.6937e+00,  1.4506e+00,  1.6867e+00,  1.6875e+00],
        [ 1.3265e+00,  1.3293e+00,  1.3336e+00,  1.3319e+00,  1.3296e+00,
          1.3273e+00,  1.3251e+00,  1.3264e+00,  1.3264e+00,  1.3851e+00,
          1.3875e+00,  1.3869e+00,  1.3876e+00,  1.3834e+00,  1.3426e+00,
          1.3852e+00,  1.3706e+00,  1.3320e+00,  2.2140e+00,  2.2039e+00,
          2.2860e+00,  2.2487e+00,  2.1224e+00,  2.1475e+00,  2.2084e+00,
          2.1142e+00,  2.1142e+00,  1.3618e+00,  1.3287e+00,  1.3621e+00,
          1.3649e+00,  1.3600e+00,  1.3635e+00,  1.3663e+00,  1.3617e+00,
          1.3624e+00,  1.7527e+00,  1.7643e+00,  1.7564e+00,  1.7450e+00,
          1.7604e+00,  1.7599e+00,  1.7544e+00,  1.6701e+00,  1.7446e+00,
          1.6373e+00,  1.6360e+00,  1.6317e+00,  1.6249e+00,  1.5827e+00,
          1.6302e+00,  1.6412e+00,  1.6227e+00,  1.6229e+00],
        [ 1.3356e+00,  1.3384e+00,  1.3327e+00,  1.3309e+00,  1.3388e+00,
          1.3366e+00,  1.3364e+00,  1.3356e+00,  1.3356e+00,  1.3945e+00,
          1.3868e+00,  1.3960e+00,  1.3884e+00,  1.3929e+00,  1.3060e+00,
          1.3946e+00,  1.3925e+00,  1.2869e+00,  1.3554e+00,  1.3472e+00,
          1.3579e+00,  1.3566e+00,  1.3529e+00,  1.3492e+00,  1.3548e+00,
          1.3515e+00,  1.3515e+00,  2.3251e+00,  2.2696e+00,  2.0718e+00,
          2.1647e+00,  2.3223e+00,  2.0808e+00,  2.2882e+00,  2.0902e+00,
          2.0734e+00,  1.7560e+00,  1.7682e+00,  1.7450e+00,  1.7551e+00,
          1.7645e+00,  1.7617e+00,  1.7464e+00,  1.6705e+00,  1.7594e+00,
          1.6624e+00,  1.6403e+00,  1.5327e+00,  1.5791e+00,  1.6569e+00,
          1.6267e+00,  1.6738e+00,  1.5768e+00,  1.6305e+00],
        [ 1.7677e+00,  1.4076e+00,  5.4343e-01,  8.2330e-01,  1.2210e+00,
          1.6624e+00,  1.5856e+00,  1.7686e+00,  1.7686e+00,  1.6507e+00,
          1.2627e+00,  1.4650e+00,  8.6615e-01,  1.7155e+00,  1.0043e-01,
          1.6105e+00,  1.7565e+00,  9.4596e-01,  1.3012e+00,  8.5675e-01,
          6.5779e-01,  1.1181e+00,  1.6062e+00,  1.6820e+00,  1.4091e+00,
          1.7739e+00,  1.7739e+00,  7.2506e-01,  8.0236e-01,  1.7541e+00,
          1.5258e+00,  7.9325e-01,  1.6955e+00,  1.1601e+00,  1.8016e+00,
          1.7195e+00,  2.9638e-01, -1.0042e-02, -4.9142e-02,  2.3666e-01,
          6.4231e-01,  8.2886e-01,  1.3387e-01,  7.3867e+00,  5.6987e+00,
          1.1333e-01,  4.8012e-01,  5.1766e-01,  6.2524e-01,  3.0260e-01,
          6.2695e-01, -1.8745e-01,  6.4786e-01,  7.2515e-01],
        [ 1.3382e+00,  1.3735e+00,  1.4272e+00,  1.4134e+00,  1.3876e+00,
          1.3487e+00,  1.3165e+00,  1.3378e+00,  1.3378e+00,  1.3000e+00,
          1.4173e+00,  1.3193e+00,  1.4493e+00,  1.3697e+00,  1.4765e+00,
          1.3021e+00,  1.3678e+00,  1.3412e+00,  1.3922e+00,  1.4183e+00,
          1.4278e+00,  1.4037e+00,  1.3642e+00,  1.3530e+00,  1.3094e+00,
          1.3467e+00,  1.3467e+00,  1.4032e+00,  1.4391e+00,  1.3570e+00,
          1.2003e+00,  1.3527e+00,  1.2471e+00,  1.4115e+00,  1.2404e+00,
          1.3609e+00,  3.5050e-01,  2.8204e-01,  4.0312e-01,  3.6018e-01,
          1.6297e-01,  1.1299e-01,  3.7525e-01,  2.0781e-01,  6.7927e-03,
          2.5941e+00,  1.9114e+00,  2.4251e+00,  2.1604e+00,  1.5887e+00,
          1.2385e+00,  2.4291e+00,  2.2068e+00,  1.2060e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 105 : 177.056398689527
Test loss for epoch 105 : 176.81634588466108
Test Precision for epoch 105 : 0.26153846153846155
Test Recall for epoch 105 : 0.26153846153846155
Test F1 for epoch 105 : 0.26153846153846155


theta for epoch 106 : tensor([[ 2.1418e+00,  2.1566e+00,  2.1941e+00,  2.2591e+00,  2.2404e+00,
          2.1462e+00,  2.2270e+00,  2.1416e+00,  2.1416e+00,  1.3771e+00,
          1.3795e+00,  1.3787e+00,  1.3819e+00,  1.3757e+00,  1.3841e+00,
          1.3773e+00,  1.3755e+00,  1.3372e+00,  1.3373e+00,  1.2972e+00,
          1.2978e+00,  1.3386e+00,  1.3351e+00,  1.3344e+00,  1.3370e+00,
          1.3337e+00,  1.3337e+00,  1.3198e+00,  1.3619e+00,  1.3559e+00,
          1.3588e+00,  1.3620e+00,  1.3574e+00,  1.3599e+00,  1.3139e+00,
          1.3562e+00,  1.7466e+00,  1.7581e+00,  1.7503e+00,  1.7474e+00,
          1.7543e+00,  1.6975e+00,  1.7482e+00,  1.7378e+00,  1.7487e+00,
          1.6495e+00,  1.6318e+00,  1.6276e+00,  1.6209e+00,  1.6440e+00,
          1.6259e+00,  1.6611e+00,  1.6188e+00,  1.6190e+00],
        [ 1.3507e+00,  1.2769e+00,  1.1650e+00,  1.3074e+00,  1.3922e+00,
          1.3932e+00,  1.3267e+00,  1.3922e+00,  1.3922e+00,  1.9150e+00,
          1.9424e+00,  1.8700e+00,  2.1432e+00,  1.9198e+00,  3.0863e+00,
          1.9708e+00,  1.8383e+00,  2.9549e+00,  1.2854e+00,  1.3335e+00,
          1.2476e+00,  1.2557e+00,  1.3998e+00,  1.4064e+00,  1.3648e+00,
          1.4056e+00,  1.4056e+00,  1.3590e+00,  1.2208e+00,  1.4291e+00,
          1.4241e+00,  1.2409e+00,  1.4304e+00,  1.4322e+00,  1.3932e+00,
          1.4272e+00,  1.7859e+00,  1.8143e+00,  1.7542e+00,  1.7304e+00,
          1.7957e+00,  1.8104e+00,  1.7518e+00,  1.2579e+00,  1.8028e+00,
          1.5234e+00,  1.6987e+00,  1.6940e+00,  1.6884e+00,  1.4775e+00,
          1.6927e+00,  1.4550e+00,  1.6857e+00,  1.6865e+00],
        [ 1.3269e+00,  1.3297e+00,  1.3340e+00,  1.3322e+00,  1.3301e+00,
          1.3277e+00,  1.3255e+00,  1.3269e+00,  1.3269e+00,  1.3854e+00,
          1.3879e+00,  1.3872e+00,  1.3879e+00,  1.3837e+00,  1.3433e+00,
          1.3855e+00,  1.3708e+00,  1.3328e+00,  2.2180e+00,  2.2076e+00,
          2.2898e+00,  2.2522e+00,  2.1265e+00,  2.1509e+00,  2.2122e+00,
          2.1182e+00,  2.1182e+00,  1.3624e+00,  1.3294e+00,  1.3627e+00,
          1.3655e+00,  1.3606e+00,  1.3641e+00,  1.3669e+00,  1.3623e+00,
          1.3629e+00,  1.7530e+00,  1.7647e+00,  1.7568e+00,  1.7453e+00,
          1.7608e+00,  1.7604e+00,  1.7547e+00,  1.6713e+00,  1.7450e+00,
          1.6374e+00,  1.6356e+00,  1.6313e+00,  1.6245e+00,  1.5829e+00,
          1.6298e+00,  1.6410e+00,  1.6223e+00,  1.6226e+00],
        [ 1.3360e+00,  1.3388e+00,  1.3334e+00,  1.3316e+00,  1.3392e+00,
          1.3370e+00,  1.3368e+00,  1.3360e+00,  1.3360e+00,  1.3945e+00,
          1.3871e+00,  1.3961e+00,  1.3884e+00,  1.3929e+00,  1.3059e+00,
          1.3946e+00,  1.3925e+00,  1.2873e+00,  1.3551e+00,  1.3470e+00,
          1.3576e+00,  1.3563e+00,  1.3526e+00,  1.3491e+00,  1.3545e+00,
          1.3512e+00,  1.3512e+00,  2.3288e+00,  2.2749e+00,  2.0765e+00,
          2.1698e+00,  2.3260e+00,  2.0854e+00,  2.2917e+00,  2.0951e+00,
          2.0781e+00,  1.7565e+00,  1.7687e+00,  1.7455e+00,  1.7555e+00,
          1.7651e+00,  1.7623e+00,  1.7468e+00,  1.6715e+00,  1.7598e+00,
          1.6620e+00,  1.6401e+00,  1.5323e+00,  1.5788e+00,  1.6566e+00,
          1.6268e+00,  1.6735e+00,  1.5765e+00,  1.6304e+00],
        [ 1.7721e+00,  1.4110e+00,  5.4698e-01,  8.2779e-01,  1.2256e+00,
          1.6669e+00,  1.5895e+00,  1.7731e+00,  1.7731e+00,  1.6556e+00,
          1.2663e+00,  1.4697e+00,  8.6943e-01,  1.7194e+00,  1.0364e-01,
          1.6148e+00,  1.7613e+00,  9.4662e-01,  1.3040e+00,  8.6063e-01,
          6.6151e-01,  1.1219e+00,  1.6104e+00,  1.6860e+00,  1.4137e+00,
          1.7784e+00,  1.7784e+00,  7.2966e-01,  8.0734e-01,  1.7586e+00,
          1.5304e+00,  7.9699e-01,  1.7000e+00,  1.1647e+00,  1.8062e+00,
          1.7239e+00,  2.8706e-01, -1.7785e-02, -5.6495e-02,  2.2775e-01,
          6.2867e-01,  8.1219e-01,  1.2559e-01,  7.4442e+00,  5.7201e+00,
          1.1843e-01,  4.8482e-01,  5.2234e-01,  6.2928e-01,  3.0705e-01,
          6.3090e-01, -1.8252e-01,  6.5206e-01,  7.2893e-01],
        [ 1.3366e+00,  1.3720e+00,  1.4255e+00,  1.4117e+00,  1.3861e+00,
          1.3472e+00,  1.3148e+00,  1.3362e+00,  1.3362e+00,  1.2966e+00,
          1.4145e+00,  1.3159e+00,  1.4464e+00,  1.3666e+00,  1.4736e+00,
          1.2987e+00,  1.3645e+00,  1.3386e+00,  1.3894e+00,  1.4154e+00,
          1.4252e+00,  1.4009e+00,  1.3612e+00,  1.3500e+00,  1.3058e+00,
          1.3435e+00,  1.3435e+00,  1.4016e+00,  1.4376e+00,  1.3554e+00,
          1.1979e+00,  1.3513e+00,  1.2455e+00,  1.4101e+00,  1.2385e+00,
          1.3593e+00,  3.4669e-01,  2.7748e-01,  3.9906e-01,  3.5631e-01,
          1.5871e-01,  1.0872e-01,  3.7133e-01,  2.0304e-01,  1.2744e-03,
          2.6014e+00,  1.9180e+00,  2.4351e+00,  2.1670e+00,  1.5944e+00,
          1.2443e+00,  2.4348e+00,  2.2169e+00,  1.2117e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 106 : 177.04494375941766
Test loss for epoch 106 : 176.80030976853845
Test Precision for epoch 106 : 0.26153846153846155
Test Recall for epoch 106 : 0.26153846153846155
Test F1 for epoch 106 : 0.26153846153846155


theta for epoch 107 : tensor([[ 2.1463e+00,  2.1613e+00,  2.1988e+00,  2.2640e+00,  2.2453e+00,
          2.1508e+00,  2.2318e+00,  2.1462e+00,  2.1462e+00,  1.3773e+00,
          1.3797e+00,  1.3789e+00,  1.3821e+00,  1.3758e+00,  1.3843e+00,
          1.3774e+00,  1.3756e+00,  1.3374e+00,  1.3371e+00,  1.2968e+00,
          1.2974e+00,  1.3383e+00,  1.3349e+00,  1.3342e+00,  1.3368e+00,
          1.3334e+00,  1.3334e+00,  1.3195e+00,  1.3617e+00,  1.3558e+00,
          1.3586e+00,  1.3618e+00,  1.3572e+00,  1.3598e+00,  1.3137e+00,
          1.3560e+00,  1.7474e+00,  1.7589e+00,  1.7511e+00,  1.7482e+00,
          1.7552e+00,  1.6983e+00,  1.7490e+00,  1.7385e+00,  1.7495e+00,
          1.6475e+00,  1.6298e+00,  1.6256e+00,  1.6190e+00,  1.6421e+00,
          1.6239e+00,  1.6591e+00,  1.6168e+00,  1.6171e+00],
        [ 1.3507e+00,  1.2786e+00,  1.1677e+00,  1.3078e+00,  1.3924e+00,
          1.3932e+00,  1.3275e+00,  1.3922e+00,  1.3922e+00,  1.9233e+00,
          1.9480e+00,  1.8780e+00,  2.1471e+00,  1.9270e+00,  3.0800e+00,
          1.9783e+00,  1.8466e+00,  2.9528e+00,  1.2874e+00,  1.3350e+00,
          1.2499e+00,  1.2566e+00,  1.3997e+00,  1.4058e+00,  1.3642e+00,
          1.4050e+00,  1.4050e+00,  1.3598e+00,  1.2207e+00,  1.4284e+00,
          1.4240e+00,  1.2428e+00,  1.4297e+00,  1.4315e+00,  1.3925e+00,
          1.4266e+00,  1.7857e+00,  1.8140e+00,  1.7540e+00,  1.7305e+00,
          1.7955e+00,  1.8101e+00,  1.7516e+00,  1.2656e+00,  1.8026e+00,
          1.5230e+00,  1.6959e+00,  1.6912e+00,  1.6856e+00,  1.4763e+00,
          1.6899e+00,  1.4576e+00,  1.6829e+00,  1.6837e+00],
        [ 1.3274e+00,  1.3302e+00,  1.3344e+00,  1.3327e+00,  1.3306e+00,
          1.3283e+00,  1.3260e+00,  1.3274e+00,  1.3274e+00,  1.3858e+00,
          1.3884e+00,  1.3878e+00,  1.3884e+00,  1.3842e+00,  1.3443e+00,
          1.3860e+00,  1.3712e+00,  1.3338e+00,  2.2227e+00,  2.2119e+00,
          2.2941e+00,  2.2563e+00,  2.1311e+00,  2.1549e+00,  2.2167e+00,
          2.1228e+00,  2.1228e+00,  1.3623e+00,  1.3294e+00,  1.3626e+00,
          1.3654e+00,  1.3605e+00,  1.3640e+00,  1.3668e+00,  1.3622e+00,
          1.3629e+00,  1.7537e+00,  1.7655e+00,  1.7575e+00,  1.7461e+00,
          1.7617e+00,  1.7612e+00,  1.7554e+00,  1.6729e+00,  1.7457e+00,
          1.6362e+00,  1.6338e+00,  1.6295e+00,  1.6228e+00,  1.5817e+00,
          1.6281e+00,  1.6395e+00,  1.6206e+00,  1.6208e+00],
        [ 1.3367e+00,  1.3394e+00,  1.3343e+00,  1.3325e+00,  1.3398e+00,
          1.3376e+00,  1.3374e+00,  1.3367e+00,  1.3367e+00,  1.3949e+00,
          1.3879e+00,  1.3966e+00,  1.3888e+00,  1.3933e+00,  1.3061e+00,
          1.3951e+00,  1.3929e+00,  1.2882e+00,  1.3554e+00,  1.3472e+00,
          1.3578e+00,  1.3566e+00,  1.3528e+00,  1.3494e+00,  1.3548e+00,
          1.3514e+00,  1.3514e+00,  2.3321e+00,  2.2797e+00,  2.0806e+00,
          2.1743e+00,  2.3293e+00,  2.0896e+00,  2.2948e+00,  2.0994e+00,
          2.0823e+00,  1.7575e+00,  1.7697e+00,  1.7466e+00,  1.7565e+00,
          1.7661e+00,  1.7634e+00,  1.7477e+00,  1.6730e+00,  1.7606e+00,
          1.6605e+00,  1.6387e+00,  1.5306e+00,  1.5773e+00,  1.6551e+00,
          1.6256e+00,  1.6720e+00,  1.5749e+00,  1.6289e+00],
        [ 1.7728e+00,  1.4096e+00,  5.4438e-01,  8.2675e-01,  1.2250e+00,
          1.6674e+00,  1.5893e+00,  1.7740e+00,  1.7740e+00,  1.6558e+00,
          1.2639e+00,  1.4693e+00,  8.6610e-01,  1.7187e+00,  9.9334e-02,
          1.6143e+00,  1.7617e+00,  9.4036e-01,  1.3014e+00,  8.5827e-01,
          6.5826e-01,  1.1198e+00,  1.6097e+00,  1.6855e+00,  1.4134e+00,
          1.7785e+00,  1.7785e+00,  7.2688e-01,  8.0500e-01,  1.7575e+00,
          1.5290e+00,  7.9306e-01,  1.6987e+00,  1.1625e+00,  1.8053e+00,
          1.7227e+00,  2.8373e-01, -1.9974e-02, -5.8364e-02,  2.2480e-01,
          6.2147e-01,  8.0215e-01,  1.2306e-01,  7.5074e+00,  5.7479e+00,
          1.1447e-01,  4.8091e-01,  5.1824e-01,  6.2454e-01,  3.0261e-01,
          6.2609e-01, -1.8656e-01,  6.4759e-01,  7.2409e-01],
        [ 1.3411e+00,  1.3764e+00,  1.4296e+00,  1.4160e+00,  1.3904e+00,
          1.3516e+00,  1.3193e+00,  1.3407e+00,  1.3407e+00,  1.3017e+00,
          1.4200e+00,  1.3212e+00,  1.4520e+00,  1.3718e+00,  1.4793e+00,
          1.3039e+00,  1.3695e+00,  1.3447e+00,  1.3952e+00,  1.4212e+00,
          1.4311e+00,  1.4069e+00,  1.3670e+00,  1.3558e+00,  1.3112e+00,
          1.3491e+00,  1.3491e+00,  1.4057e+00,  1.4417e+00,  1.3597e+00,
          1.2018e+00,  1.3557e+00,  1.2499e+00,  1.4145e+00,  1.2429e+00,
          1.3636e+00,  3.5124e-01,  2.8148e-01,  4.0330e-01,  3.6081e-01,
          1.6321e-01,  1.1327e-01,  3.7572e-01,  2.0697e-01,  4.7338e-03,
          2.5989e+00,  1.9147e+00,  2.4351e+00,  2.1637e+00,  1.5904e+00,
          1.2403e+00,  2.4306e+00,  2.2170e+00,  1.2076e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 107 : 177.03333439536075
Test loss for epoch 107 : 176.79529397799865
Test Precision for epoch 107 : 0.26153846153846155
Test Recall for epoch 107 : 0.26153846153846155
Test F1 for epoch 107 : 0.26153846153846155


theta for epoch 108 : tensor([[ 2.1501e+00,  2.1651e+00,  2.2028e+00,  2.2681e+00,  2.2494e+00,
          2.1546e+00,  2.2358e+00,  2.1499e+00,  2.1499e+00,  1.3770e+00,
          1.3795e+00,  1.3787e+00,  1.3819e+00,  1.3756e+00,  1.3842e+00,
          1.3772e+00,  1.3754e+00,  1.3372e+00,  1.3365e+00,  1.2961e+00,
          1.2967e+00,  1.3377e+00,  1.3342e+00,  1.3335e+00,  1.3361e+00,
          1.3328e+00,  1.3328e+00,  1.3190e+00,  1.3613e+00,  1.3553e+00,
          1.3582e+00,  1.3614e+00,  1.3568e+00,  1.3593e+00,  1.3132e+00,
          1.3556e+00,  1.7475e+00,  1.7591e+00,  1.7512e+00,  1.7483e+00,
          1.7554e+00,  1.6984e+00,  1.7491e+00,  1.7386e+00,  1.7497e+00,
          1.6495e+00,  1.6318e+00,  1.6276e+00,  1.6210e+00,  1.6441e+00,
          1.6260e+00,  1.6610e+00,  1.6189e+00,  1.6191e+00],
        [ 1.3500e+00,  1.2796e+00,  1.1695e+00,  1.3073e+00,  1.3919e+00,
          1.3923e+00,  1.3274e+00,  1.3914e+00,  1.3914e+00,  1.9315e+00,
          1.9533e+00,  1.8858e+00,  2.1509e+00,  1.9341e+00,  3.0735e+00,
          1.9858e+00,  1.8546e+00,  2.9504e+00,  1.2885e+00,  1.3357e+00,
          1.2515e+00,  1.2566e+00,  1.3988e+00,  1.4043e+00,  1.3627e+00,
          1.4036e+00,  1.4036e+00,  1.3600e+00,  1.2202e+00,  1.4272e+00,
          1.4234e+00,  1.2443e+00,  1.4285e+00,  1.4304e+00,  1.3913e+00,
          1.4255e+00,  1.7849e+00,  1.8131e+00,  1.7532e+00,  1.7300e+00,
          1.7946e+00,  1.8092e+00,  1.7508e+00,  1.2726e+00,  1.8018e+00,
          1.5267e+00,  1.6971e+00,  1.6924e+00,  1.6868e+00,  1.4793e+00,
          1.6912e+00,  1.4640e+00,  1.6840e+00,  1.6849e+00],
        [ 1.3272e+00,  1.3299e+00,  1.3341e+00,  1.3324e+00,  1.3304e+00,
          1.3280e+00,  1.3257e+00,  1.3272e+00,  1.3272e+00,  1.3857e+00,
          1.3883e+00,  1.3876e+00,  1.3883e+00,  1.3840e+00,  1.3446e+00,
          1.3858e+00,  1.3710e+00,  1.3341e+00,  2.2268e+00,  2.2157e+00,
          2.2979e+00,  2.2599e+00,  2.1352e+00,  2.1584e+00,  2.2206e+00,
          2.1269e+00,  2.1269e+00,  1.3618e+00,  1.3291e+00,  1.3621e+00,
          1.3650e+00,  1.3600e+00,  1.3636e+00,  1.3663e+00,  1.3618e+00,
          1.3624e+00,  1.7538e+00,  1.7656e+00,  1.7575e+00,  1.7460e+00,
          1.7618e+00,  1.7613e+00,  1.7554e+00,  1.6738e+00,  1.7458e+00,
          1.6388e+00,  1.6360e+00,  1.6316e+00,  1.6249e+00,  1.5844e+00,
          1.6302e+00,  1.6418e+00,  1.6227e+00,  1.6230e+00],
        [ 1.3366e+00,  1.3393e+00,  1.3344e+00,  1.3326e+00,  1.3397e+00,
          1.3376e+00,  1.3374e+00,  1.3366e+00,  1.3366e+00,  1.3948e+00,
          1.3881e+00,  1.3965e+00,  1.3887e+00,  1.3931e+00,  1.3058e+00,
          1.3949e+00,  1.3928e+00,  1.2885e+00,  1.3551e+00,  1.3469e+00,
          1.3575e+00,  1.3563e+00,  1.3525e+00,  1.3493e+00,  1.3545e+00,
          1.3511e+00,  1.3511e+00,  2.3350e+00,  2.2840e+00,  2.0842e+00,
          2.1782e+00,  2.3322e+00,  2.0931e+00,  2.2974e+00,  2.1031e+00,
          2.0859e+00,  1.7577e+00,  1.7699e+00,  1.7469e+00,  1.7568e+00,
          1.7665e+00,  1.7637e+00,  1.7478e+00,  1.6736e+00,  1.7608e+00,
          1.6627e+00,  1.6411e+00,  1.5326e+00,  1.5794e+00,  1.6572e+00,
          1.6281e+00,  1.6742e+00,  1.5771e+00,  1.6312e+00],
        [ 1.7779e+00,  1.4139e+00,  5.4967e-01,  8.3269e-01,  1.2308e+00,
          1.6727e+00,  1.5940e+00,  1.7791e+00,  1.7791e+00,  1.6621e+00,
          1.2693e+00,  1.4753e+00,  8.7135e-01,  1.7239e+00,  1.0486e-01,
          1.6199e+00,  1.7677e+00,  9.4325e-01,  1.3060e+00,  8.6425e-01,
          6.6429e-01,  1.1254e+00,  1.6155e+00,  1.6911e+00,  1.4197e+00,
          1.7843e+00,  1.7843e+00,  7.3317e-01,  8.1160e-01,  1.7626e+00,
          1.5346e+00,  7.9854e-01,  1.7039e+00,  1.1685e+00,  1.8103e+00,
          1.7276e+00,  2.7280e-01, -2.9333e-02, -6.7354e-02,  2.1429e-01,
          6.0630e-01,  7.8397e-01,  1.1319e-01,  7.5627e+00,  5.7661e+00,
          1.2277e-01,  4.8878e-01,  5.2620e-01,  6.3210e-01,  3.1026e-01,
          6.3351e-01, -1.7828e-01,  6.5522e-01,  7.3138e-01],
        [ 1.3372e+00,  1.3726e+00,  1.4257e+00,  1.4121e+00,  1.3866e+00,
          1.3478e+00,  1.3153e+00,  1.3368e+00,  1.3368e+00,  1.2955e+00,
          1.4144e+00,  1.3150e+00,  1.4464e+00,  1.3659e+00,  1.4736e+00,
          1.2977e+00,  1.3633e+00,  1.3395e+00,  1.3897e+00,  1.4157e+00,
          1.4259e+00,  1.4015e+00,  1.3612e+00,  1.3501e+00,  1.3048e+00,
          1.3433e+00,  1.3433e+00,  1.4014e+00,  1.4376e+00,  1.3554e+00,
          1.1965e+00,  1.3515e+00,  1.2454e+00,  1.4104e+00,  1.2382e+00,
          1.3593e+00,  3.4487e-01,  2.7441e-01,  3.9674e-01,  3.5439e-01,
          1.5638e-01,  1.0644e-01,  3.6926e-01,  1.9976e-01, -3.3045e-03,
          2.6097e+00,  1.9248e+00,  2.4486e+00,  2.1738e+00,  1.5996e+00,
          1.2496e+00,  2.4399e+00,  2.2306e+00,  1.2168e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 108 : 177.0116244566536
Test loss for epoch 108 : 176.76541324836865
Test Precision for epoch 108 : 0.26153846153846155
Test Recall for epoch 108 : 0.26153846153846155
Test F1 for epoch 108 : 0.26153846153846155


theta for epoch 109 : tensor([[ 2.1533e+00,  2.1685e+00,  2.2061e+00,  2.2716e+00,  2.2530e+00,
          2.1578e+00,  2.2393e+00,  2.1531e+00,  2.1531e+00,  1.3770e+00,
          1.3795e+00,  1.3787e+00,  1.3819e+00,  1.3755e+00,  1.3842e+00,
          1.3772e+00,  1.3753e+00,  1.3372e+00,  1.3365e+00,  1.2961e+00,
          1.2966e+00,  1.3377e+00,  1.3342e+00,  1.3335e+00,  1.3361e+00,
          1.3328e+00,  1.3328e+00,  1.3187e+00,  1.3610e+00,  1.3551e+00,
          1.3580e+00,  1.3612e+00,  1.3565e+00,  1.3591e+00,  1.3129e+00,
          1.3554e+00,  1.7488e+00,  1.7603e+00,  1.7524e+00,  1.7495e+00,
          1.7567e+00,  1.6996e+00,  1.7503e+00,  1.7397e+00,  1.7509e+00,
          1.6496e+00,  1.6320e+00,  1.6277e+00,  1.6212e+00,  1.6442e+00,
          1.6261e+00,  1.6612e+00,  1.6190e+00,  1.6193e+00],
        [ 1.3487e+00,  1.2800e+00,  1.1706e+00,  1.3063e+00,  1.3907e+00,
          1.3909e+00,  1.3269e+00,  1.3900e+00,  1.3900e+00,  1.9397e+00,
          1.9586e+00,  1.8934e+00,  2.1545e+00,  1.9410e+00,  3.0669e+00,
          1.9931e+00,  1.8626e+00,  2.9479e+00,  1.2900e+00,  1.3368e+00,
          1.2535e+00,  1.2572e+00,  1.3984e+00,  1.4034e+00,  1.3618e+00,
          1.4027e+00,  1.4027e+00,  1.3604e+00,  1.2198e+00,  1.4261e+00,
          1.4229e+00,  1.2459e+00,  1.4275e+00,  1.4294e+00,  1.3903e+00,
          1.4246e+00,  1.7852e+00,  1.8133e+00,  1.7535e+00,  1.7306e+00,
          1.7949e+00,  1.8095e+00,  1.7511e+00,  1.2805e+00,  1.8021e+00,
          1.5281e+00,  1.6961e+00,  1.6914e+00,  1.6857e+00,  1.4800e+00,
          1.6901e+00,  1.4681e+00,  1.6830e+00,  1.6838e+00],
        [ 1.3264e+00,  1.3291e+00,  1.3332e+00,  1.3314e+00,  1.3295e+00,
          1.3272e+00,  1.3248e+00,  1.3263e+00,  1.3263e+00,  1.3855e+00,
          1.3881e+00,  1.3875e+00,  1.3882e+00,  1.3839e+00,  1.3449e+00,
          1.3857e+00,  1.3708e+00,  1.3345e+00,  2.2310e+00,  2.2197e+00,
          2.3018e+00,  2.2636e+00,  2.1395e+00,  2.1621e+00,  2.2247e+00,
          2.1313e+00,  2.1313e+00,  1.3615e+00,  1.3289e+00,  1.3619e+00,
          1.3647e+00,  1.3596e+00,  1.3633e+00,  1.3661e+00,  1.3615e+00,
          1.3621e+00,  1.7548e+00,  1.7666e+00,  1.7585e+00,  1.7471e+00,
          1.7629e+00,  1.7624e+00,  1.7565e+00,  1.6758e+00,  1.7469e+00,
          1.6395e+00,  1.6362e+00,  1.6318e+00,  1.6251e+00,  1.5852e+00,
          1.6304e+00,  1.6423e+00,  1.6229e+00,  1.6232e+00],
        [ 1.3360e+00,  1.3386e+00,  1.3340e+00,  1.3322e+00,  1.3390e+00,
          1.3369e+00,  1.3367e+00,  1.3359e+00,  1.3359e+00,  1.3946e+00,
          1.3882e+00,  1.3964e+00,  1.3885e+00,  1.3929e+00,  1.3053e+00,
          1.3947e+00,  1.3925e+00,  1.2887e+00,  1.3550e+00,  1.3468e+00,
          1.3574e+00,  1.3562e+00,  1.3525e+00,  1.3494e+00,  1.3544e+00,
          1.3511e+00,  1.3511e+00,  2.3382e+00,  2.2885e+00,  2.0882e+00,
          2.1825e+00,  2.3354e+00,  2.0970e+00,  2.3004e+00,  2.1072e+00,
          2.0898e+00,  1.7590e+00,  1.7711e+00,  1.7482e+00,  1.7580e+00,
          1.7678e+00,  1.7651e+00,  1.7490e+00,  1.6752e+00,  1.7620e+00,
          1.6629e+00,  1.6414e+00,  1.5326e+00,  1.5795e+00,  1.6575e+00,
          1.6286e+00,  1.6745e+00,  1.5772e+00,  1.6315e+00],
        [ 1.7774e+00,  1.4113e+00,  5.4633e-01,  8.3079e-01,  1.2291e+00,
          1.6720e+00,  1.5925e+00,  1.7787e+00,  1.7787e+00,  1.6617e+00,
          1.2665e+00,  1.4743e+00,  8.6761e-01,  1.7226e+00,  1.0026e-01,
          1.6187e+00,  1.7676e+00,  9.3668e-01,  1.3032e+00,  8.6178e-01,
          6.6090e-01,  1.1231e+00,  1.6147e+00,  1.6903e+00,  1.4192e+00,
          1.7843e+00,  1.7843e+00,  7.3014e-01,  8.0900e-01,  1.7611e+00,
          1.5328e+00,  7.9434e-01,  1.7022e+00,  1.1661e+00,  1.8090e+00,
          1.7259e+00,  2.6995e-01, -3.1165e-02, -6.8901e-02,  2.1180e-01,
          5.9977e-01,  7.7467e-01,  1.1107e-01,  7.6258e+00,  5.7930e+00,
          1.1908e-01,  4.8528e-01,  5.2258e-01,  6.2806e-01,  3.0615e-01,
          6.2935e-01, -1.8195e-01,  6.5139e-01,  7.2729e-01],
        [ 1.3404e+00,  1.3758e+00,  1.4287e+00,  1.4151e+00,  1.3897e+00,
          1.3510e+00,  1.3185e+00,  1.3400e+00,  1.3400e+00,  1.3000e+00,
          1.4192e+00,  1.3196e+00,  1.4513e+00,  1.3704e+00,  1.4786e+00,
          1.3023e+00,  1.3677e+00,  1.3449e+00,  1.3951e+00,  1.4211e+00,
          1.4314e+00,  1.4070e+00,  1.3666e+00,  1.3555e+00,  1.3098e+00,
          1.3485e+00,  1.3485e+00,  1.4052e+00,  1.4414e+00,  1.3593e+00,
          1.2000e+00,  1.3555e+00,  1.2493e+00,  1.4143e+00,  1.2421e+00,
          1.3632e+00,  3.4949e-01,  2.7857e-01,  4.0109e-01,  3.5897e-01,
          1.6100e-01,  1.1114e-01,  3.7372e-01,  2.0392e-01,  3.7642e-04,
          2.6079e+00,  1.9222e+00,  2.4493e+00,  2.1712e+00,  1.5964e+00,
          1.2463e+00,  2.4365e+00,  2.2314e+00,  1.2135e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 109 : 176.98333857950064
Test loss for epoch 109 : 176.74361133865406
Test Precision for epoch 109 : 0.26153846153846155
Test Recall for epoch 109 : 0.26153846153846155
Test F1 for epoch 109 : 0.26153846153846155


theta for epoch 110 : tensor([[ 2.1564e+00,  2.1718e+00,  2.2095e+00,  2.2752e+00,  2.2565e+00,
          2.1610e+00,  2.2428e+00,  2.1563e+00,  2.1563e+00,  1.3766e+00,
          1.3791e+00,  1.3783e+00,  1.3816e+00,  1.3751e+00,  1.3839e+00,
          1.3768e+00,  1.3749e+00,  1.3368e+00,  1.3358e+00,  1.2953e+00,
          1.2958e+00,  1.3370e+00,  1.3335e+00,  1.3328e+00,  1.3354e+00,
          1.3321e+00,  1.3321e+00,  1.3187e+00,  1.3611e+00,  1.3552e+00,
          1.3581e+00,  1.3612e+00,  1.3566e+00,  1.3592e+00,  1.3129e+00,
          1.3555e+00,  1.7494e+00,  1.7610e+00,  1.7530e+00,  1.7501e+00,
          1.7574e+00,  1.7002e+00,  1.7509e+00,  1.7403e+00,  1.7515e+00,
          1.6508e+00,  1.6332e+00,  1.6289e+00,  1.6224e+00,  1.6455e+00,
          1.6273e+00,  1.6623e+00,  1.6202e+00,  1.6205e+00],
        [ 1.3474e+00,  1.2803e+00,  1.1717e+00,  1.3052e+00,  1.3895e+00,
          1.3895e+00,  1.3264e+00,  1.3886e+00,  1.3886e+00,  1.9477e+00,
          1.9636e+00,  1.9009e+00,  2.1579e+00,  1.9477e+00,  3.0602e+00,
          2.0002e+00,  1.8704e+00,  2.9451e+00,  1.2908e+00,  1.3371e+00,
          1.2549e+00,  1.2570e+00,  1.3972e+00,  1.4018e+00,  1.3601e+00,
          1.4011e+00,  1.4011e+00,  1.3611e+00,  1.2196e+00,  1.4254e+00,
          1.4226e+00,  1.2477e+00,  1.4267e+00,  1.4287e+00,  1.3896e+00,
          1.4239e+00,  1.7852e+00,  1.8131e+00,  1.7534e+00,  1.7308e+00,
          1.7948e+00,  1.8093e+00,  1.7510e+00,  1.2879e+00,  1.8019e+00,
          1.5307e+00,  1.6961e+00,  1.6914e+00,  1.6856e+00,  1.4820e+00,
          1.6902e+00,  1.4730e+00,  1.6829e+00,  1.6838e+00],
        [ 1.3256e+00,  1.3283e+00,  1.3323e+00,  1.3306e+00,  1.3287e+00,
          1.3264e+00,  1.3240e+00,  1.3256e+00,  1.3256e+00,  1.3851e+00,
          1.3877e+00,  1.3870e+00,  1.3877e+00,  1.3835e+00,  1.3449e+00,
          1.3853e+00,  1.3702e+00,  1.3346e+00,  2.2347e+00,  2.2230e+00,
          2.3051e+00,  2.2668e+00,  2.1432e+00,  2.1653e+00,  2.2282e+00,
          2.1350e+00,  2.1350e+00,  1.3616e+00,  1.3292e+00,  1.3619e+00,
          1.3648e+00,  1.3597e+00,  1.3633e+00,  1.3662e+00,  1.3616e+00,
          1.3622e+00,  1.7553e+00,  1.7672e+00,  1.7590e+00,  1.7476e+00,
          1.7635e+00,  1.7630e+00,  1.7570e+00,  1.6772e+00,  1.7475e+00,
          1.6412e+00,  1.6376e+00,  1.6332e+00,  1.6265e+00,  1.5871e+00,
          1.6318e+00,  1.6439e+00,  1.6243e+00,  1.6245e+00],
        [ 1.3352e+00,  1.3379e+00,  1.3334e+00,  1.3316e+00,  1.3382e+00,
          1.3361e+00,  1.3359e+00,  1.3352e+00,  1.3352e+00,  1.3939e+00,
          1.3879e+00,  1.3958e+00,  1.3878e+00,  1.3922e+00,  1.3044e+00,
          1.3941e+00,  1.3918e+00,  1.2884e+00,  1.3542e+00,  1.3459e+00,
          1.3565e+00,  1.3554e+00,  1.3517e+00,  1.3487e+00,  1.3536e+00,
          1.3502e+00,  1.3502e+00,  2.3420e+00,  2.2935e+00,  2.0925e+00,
          2.1872e+00,  2.3391e+00,  2.1014e+00,  2.3039e+00,  2.1117e+00,
          2.0941e+00,  1.7597e+00,  1.7718e+00,  1.7489e+00,  1.7587e+00,
          1.7685e+00,  1.7658e+00,  1.7496e+00,  1.6761e+00,  1.7625e+00,
          1.6641e+00,  1.6426e+00,  1.5335e+00,  1.5806e+00,  1.6586e+00,
          1.6299e+00,  1.6757e+00,  1.5782e+00,  1.6327e+00],
        [ 1.7805e+00,  1.4134e+00,  5.4914e-01,  8.3439e-01,  1.2326e+00,
          1.6753e+00,  1.5952e+00,  1.7820e+00,  1.7820e+00,  1.6658e+00,
          1.2695e+00,  1.4781e+00,  8.7027e-01,  1.7258e+00,  1.0296e-01,
          1.6220e+00,  1.7716e+00,  9.3700e-01,  1.3057e+00,  8.6539e-01,
          6.6428e-01,  1.1264e+00,  1.6185e+00,  1.6940e+00,  1.4234e+00,
          1.7883e+00,  1.7883e+00,  7.3419e-01,  8.1337e-01,  1.7646e+00,
          1.5369e+00,  7.9752e-01,  1.7060e+00,  1.1702e+00,  1.8126e+00,
          1.7294e+00,  2.6151e-01, -3.8275e-02, -7.5697e-02,  2.0376e-01,
          5.8742e-01,  7.5945e-01,  1.0357e-01,  7.6831e+00,  5.8127e+00,
          1.2381e-01,  4.8980e-01,  5.2716e-01,  6.3236e-01,  3.1032e-01,
          6.3351e-01, -1.7709e-01,  6.5577e-01,  7.3141e-01],
        [ 1.3380e+00,  1.3735e+00,  1.4262e+00,  1.4126e+00,  1.3873e+00,
          1.3487e+00,  1.3161e+00,  1.3376e+00,  1.3376e+00,  1.2963e+00,
          1.4161e+00,  1.3161e+00,  1.4482e+00,  1.3670e+00,  1.4754e+00,
          1.2986e+00,  1.3640e+00,  1.3422e+00,  1.3922e+00,  1.4181e+00,
          1.4287e+00,  1.4042e+00,  1.3635e+00,  1.3525e+00,  1.3062e+00,
          1.3453e+00,  1.3453e+00,  1.4033e+00,  1.4396e+00,  1.3575e+00,
          1.1973e+00,  1.3537e+00,  1.2473e+00,  1.4127e+00,  1.2399e+00,
          1.3613e+00,  3.4620e-01,  2.7473e-01,  3.9762e-01,  3.5563e-01,
          1.5745e-01,  1.0761e-01,  3.7032e-01,  2.0000e-01, -4.2457e-03,
          2.6155e+00,  1.9289e+00,  2.4595e+00,  2.1780e+00,  1.6023e+00,
          1.2523e+00,  2.4425e+00,  2.2417e+00,  1.2194e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 110 : 176.95617954132587
Test loss for epoch 110 : 176.7123531522741
Test Precision for epoch 110 : 0.26153846153846155
Test Recall for epoch 110 : 0.26153846153846155
Test F1 for epoch 110 : 0.26153846153846155


theta for epoch 111 : tensor([[ 2.1604e+00,  2.1758e+00,  2.2136e+00,  2.2794e+00,  2.2608e+00,
          2.1649e+00,  2.2469e+00,  2.1602e+00,  2.1602e+00,  1.3764e+00,
          1.3790e+00,  1.3782e+00,  1.3815e+00,  1.3750e+00,  1.3838e+00,
          1.3767e+00,  1.3748e+00,  1.3367e+00,  1.3353e+00,  1.2948e+00,
          1.2952e+00,  1.3365e+00,  1.3330e+00,  1.3323e+00,  1.3348e+00,
          1.3316e+00,  1.3316e+00,  1.3184e+00,  1.3610e+00,  1.3550e+00,
          1.3579e+00,  1.3611e+00,  1.3564e+00,  1.3590e+00,  1.3126e+00,
          1.3553e+00,  1.7501e+00,  1.7617e+00,  1.7537e+00,  1.7508e+00,
          1.7581e+00,  1.7009e+00,  1.7516e+00,  1.7409e+00,  1.7522e+00,
          1.6497e+00,  1.6320e+00,  1.6277e+00,  1.6212e+00,  1.6443e+00,
          1.6262e+00,  1.6612e+00,  1.6191e+00,  1.6193e+00],
        [ 1.3467e+00,  1.2813e+00,  1.1734e+00,  1.3047e+00,  1.3889e+00,
          1.3888e+00,  1.3265e+00,  1.3879e+00,  1.3879e+00,  1.9559e+00,
          1.9689e+00,  1.9085e+00,  2.1615e+00,  1.9546e+00,  3.0537e+00,
          2.0074e+00,  1.8783e+00,  2.9424e+00,  1.2919e+00,  1.3378e+00,
          1.2567e+00,  1.2573e+00,  1.3964e+00,  1.4007e+00,  1.3590e+00,
          1.3999e+00,  1.3999e+00,  1.3617e+00,  1.2194e+00,  1.4245e+00,
          1.4222e+00,  1.2495e+00,  1.4259e+00,  1.4280e+00,  1.3888e+00,
          1.4232e+00,  1.7853e+00,  1.8130e+00,  1.7535e+00,  1.7312e+00,
          1.7949e+00,  1.8093e+00,  1.7511e+00,  1.2953e+00,  1.8019e+00,
          1.5307e+00,  1.6936e+00,  1.6889e+00,  1.6830e+00,  1.4815e+00,
          1.6877e+00,  1.4753e+00,  1.6804e+00,  1.6812e+00],
        [ 1.3254e+00,  1.3281e+00,  1.3321e+00,  1.3304e+00,  1.3285e+00,
          1.3262e+00,  1.3238e+00,  1.3254e+00,  1.3254e+00,  1.3850e+00,
          1.3877e+00,  1.3870e+00,  1.3877e+00,  1.3834e+00,  1.3452e+00,
          1.3852e+00,  1.3701e+00,  1.3351e+00,  2.2388e+00,  2.2267e+00,
          2.3088e+00,  2.2703e+00,  2.1474e+00,  2.1688e+00,  2.2321e+00,
          2.1392e+00,  2.1392e+00,  1.3615e+00,  1.3293e+00,  1.3619e+00,
          1.3648e+00,  1.3596e+00,  1.3633e+00,  1.3661e+00,  1.3615e+00,
          1.3621e+00,  1.7559e+00,  1.7678e+00,  1.7596e+00,  1.7481e+00,
          1.7641e+00,  1.7637e+00,  1.7576e+00,  1.6787e+00,  1.7482e+00,
          1.6407e+00,  1.6367e+00,  1.6322e+00,  1.6255e+00,  1.5868e+00,
          1.6309e+00,  1.6433e+00,  1.6233e+00,  1.6236e+00],
        [ 1.3351e+00,  1.3377e+00,  1.3334e+00,  1.3316e+00,  1.3380e+00,
          1.3360e+00,  1.3358e+00,  1.3350e+00,  1.3350e+00,  1.3936e+00,
          1.3880e+00,  1.3956e+00,  1.3875e+00,  1.3920e+00,  1.3039e+00,
          1.3938e+00,  1.3916e+00,  1.2885e+00,  1.3537e+00,  1.3454e+00,
          1.3560e+00,  1.3549e+00,  1.3513e+00,  1.3484e+00,  1.3531e+00,
          1.3498e+00,  1.3498e+00,  2.3457e+00,  2.2984e+00,  2.0968e+00,
          2.1918e+00,  2.3429e+00,  2.1056e+00,  2.3074e+00,  2.1162e+00,
          2.0983e+00,  1.7605e+00,  1.7725e+00,  1.7497e+00,  1.7595e+00,
          1.7693e+00,  1.7666e+00,  1.7503e+00,  1.6771e+00,  1.7631e+00,
          1.6631e+00,  1.6417e+00,  1.5322e+00,  1.5794e+00,  1.6576e+00,
          1.6291e+00,  1.6748e+00,  1.5771e+00,  1.6318e+00],
        [ 1.7828e+00,  1.4141e+00,  5.4997e-01,  8.3623e-01,  1.2345e+00,
          1.6775e+00,  1.5967e+00,  1.7843e+00,  1.7843e+00,  1.6683e+00,
          1.2704e+00,  1.4800e+00,  8.7059e-01,  1.7273e+00,  1.0297e-01,
          1.6236e+00,  1.7741e+00,  9.3492e-01,  1.3063e+00,  8.6677e-01,
          6.6513e-01,  1.1276e+00,  1.6206e+00,  1.6961e+00,  1.4259e+00,
          1.7909e+00,  1.7909e+00,  7.3559e-01,  8.1513e-01,  1.7663e+00,
          1.5388e+00,  7.9797e-01,  1.7077e+00,  1.1719e+00,  1.8144e+00,
          1.7310e+00,  2.5535e-01, -4.3295e-02, -8.0438e-02,  1.9797e-01,
          5.7757e-01,  7.4683e-01,  9.8225e-02,  7.7425e+00,  5.8344e+00,
          1.2460e-01,  4.9050e-01,  5.2785e-01,  6.3279e-01,  3.1059e-01,
          6.3379e-01, -1.7605e-01,  6.5629e-01,  7.3169e-01],
        [ 1.3384e+00,  1.3740e+00,  1.4264e+00,  1.4129e+00,  1.3877e+00,
          1.3491e+00,  1.3164e+00,  1.3380e+00,  1.3380e+00,  1.2961e+00,
          1.4163e+00,  1.3160e+00,  1.4485e+00,  1.3669e+00,  1.4758e+00,
          1.2985e+00,  1.3637e+00,  1.3430e+00,  1.3927e+00,  1.4186e+00,
          1.4294e+00,  1.4047e+00,  1.3638e+00,  1.3529e+00,  1.3060e+00,
          1.3455e+00,  1.3455e+00,  1.4037e+00,  1.4401e+00,  1.3580e+00,
          1.1971e+00,  1.3542e+00,  1.2476e+00,  1.4133e+00,  1.2402e+00,
          1.3618e+00,  3.4604e-01,  2.7415e-01,  3.9728e-01,  3.5544e-01,
          1.5721e-01,  1.0745e-01,  3.7005e-01,  1.9936e-01, -5.4333e-03,
          2.6191e+00,  1.9317e+00,  2.4657e+00,  2.1808e+00,  1.6044e+00,
          1.2543e+00,  2.4445e+00,  2.2480e+00,  1.2213e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 111 : 176.93551010513502
Test loss for epoch 111 : 176.69202735293146
Test Precision for epoch 111 : 0.26153846153846155
Test Recall for epoch 111 : 0.26153846153846155
Test F1 for epoch 111 : 0.26153846153846155


theta for epoch 112 : tensor([[ 2.1646e+00,  2.1802e+00,  2.2181e+00,  2.2840e+00,  2.2654e+00,
          2.1692e+00,  2.2515e+00,  2.1645e+00,  2.1645e+00,  1.3764e+00,
          1.3790e+00,  1.3782e+00,  1.3815e+00,  1.3750e+00,  1.3838e+00,
          1.3767e+00,  1.3747e+00,  1.3367e+00,  1.3350e+00,  1.2944e+00,
          1.2949e+00,  1.3361e+00,  1.3327e+00,  1.3320e+00,  1.3345e+00,
          1.3313e+00,  1.3313e+00,  1.3178e+00,  1.3605e+00,  1.3545e+00,
          1.3574e+00,  1.3606e+00,  1.3559e+00,  1.3585e+00,  1.3120e+00,
          1.3547e+00,  1.7506e+00,  1.7622e+00,  1.7542e+00,  1.7513e+00,
          1.7586e+00,  1.7013e+00,  1.7521e+00,  1.7413e+00,  1.7527e+00,
          1.6478e+00,  1.6301e+00,  1.6258e+00,  1.6193e+00,  1.6425e+00,
          1.6243e+00,  1.6593e+00,  1.6172e+00,  1.6174e+00],
        [ 1.3463e+00,  1.2827e+00,  1.1752e+00,  1.3045e+00,  1.3887e+00,
          1.3883e+00,  1.3269e+00,  1.3874e+00,  1.3874e+00,  1.9641e+00,
          1.9741e+00,  1.9161e+00,  2.1650e+00,  1.9614e+00,  3.0472e+00,
          2.0147e+00,  1.8863e+00,  2.9397e+00,  1.2933e+00,  1.3388e+00,
          1.2589e+00,  1.2580e+00,  1.3960e+00,  1.3999e+00,  1.3582e+00,
          1.3991e+00,  1.3991e+00,  1.3620e+00,  1.2188e+00,  1.4233e+00,
          1.4215e+00,  1.2510e+00,  1.4247e+00,  1.4269e+00,  1.3877e+00,
          1.4221e+00,  1.7855e+00,  1.8130e+00,  1.7536e+00,  1.7316e+00,
          1.7950e+00,  1.8093e+00,  1.7512e+00,  1.3026e+00,  1.8019e+00,
          1.5301e+00,  1.6904e+00,  1.6857e+00,  1.6798e+00,  1.4803e+00,
          1.6845e+00,  1.4767e+00,  1.6771e+00,  1.6779e+00],
        [ 1.3256e+00,  1.3282e+00,  1.3322e+00,  1.3304e+00,  1.3286e+00,
          1.3264e+00,  1.3238e+00,  1.3255e+00,  1.3255e+00,  1.3851e+00,
          1.3878e+00,  1.3870e+00,  1.3877e+00,  1.3835e+00,  1.3456e+00,
          1.3853e+00,  1.3701e+00,  1.3357e+00,  2.2432e+00,  2.2307e+00,
          2.3127e+00,  2.2741e+00,  2.1519e+00,  2.1727e+00,  2.2363e+00,
          2.1437e+00,  2.1437e+00,  1.3610e+00,  1.3290e+00,  1.3614e+00,
          1.3644e+00,  1.3591e+00,  1.3629e+00,  1.3657e+00,  1.3611e+00,
          1.3617e+00,  1.7564e+00,  1.7682e+00,  1.7601e+00,  1.7486e+00,
          1.7646e+00,  1.7642e+00,  1.7580e+00,  1.6800e+00,  1.7487e+00,
          1.6395e+00,  1.6350e+00,  1.6306e+00,  1.6239e+00,  1.5858e+00,
          1.6293e+00,  1.6419e+00,  1.6217e+00,  1.6220e+00],
        [ 1.3353e+00,  1.3379e+00,  1.3338e+00,  1.3320e+00,  1.3382e+00,
          1.3362e+00,  1.3360e+00,  1.3353e+00,  1.3353e+00,  1.3937e+00,
          1.3885e+00,  1.3957e+00,  1.3876e+00,  1.3921e+00,  1.3037e+00,
          1.3940e+00,  1.3918e+00,  1.2890e+00,  1.3536e+00,  1.3452e+00,
          1.3558e+00,  1.3548e+00,  1.3512e+00,  1.3485e+00,  1.3530e+00,
          1.3497e+00,  1.3497e+00,  2.3490e+00,  2.3028e+00,  2.1005e+00,
          2.1959e+00,  2.3462e+00,  2.1093e+00,  2.3105e+00,  2.1201e+00,
          2.1021e+00,  1.7612e+00,  1.7731e+00,  1.7503e+00,  1.7602e+00,
          1.7700e+00,  1.7674e+00,  1.7509e+00,  1.6779e+00,  1.7637e+00,
          1.6616e+00,  1.6402e+00,  1.5304e+00,  1.5777e+00,  1.6561e+00,
          1.6277e+00,  1.6734e+00,  1.5754e+00,  1.6302e+00],
        [ 1.7844e+00,  1.4141e+00,  5.4978e-01,  8.3716e-01,  1.2357e+00,
          1.6792e+00,  1.5975e+00,  1.7862e+00,  1.7862e+00,  1.6698e+00,
          1.2702e+00,  1.4810e+00,  8.6968e-01,  1.7280e+00,  1.0157e-01,
          1.6242e+00,  1.7758e+00,  9.3165e-01,  1.3058e+00,  8.6701e-01,
          6.6468e-01,  1.1277e+00,  1.6218e+00,  1.6973e+00,  1.4274e+00,
          1.7926e+00,  1.7926e+00,  7.3546e-01,  8.1534e-01,  1.7667e+00,
          1.5394e+00,  7.9681e-01,  1.7081e+00,  1.1721e+00,  1.8149e+00,
          1.7312e+00,  2.5037e-01, -4.7250e-02, -8.4141e-02,  1.9336e-01,
          5.6908e-01,  7.3563e-01,  9.3999e-02,  7.8031e+00,  5.8570e+00,
          1.2347e-01,  4.8940e-01,  5.2673e-01,  6.3144e-01,  3.0899e-01,
          6.3230e-01, -1.7688e-01,  6.5504e-01,  7.3024e-01],
        [ 1.3401e+00,  1.3757e+00,  1.4279e+00,  1.4145e+00,  1.3893e+00,
          1.3508e+00,  1.3181e+00,  1.3396e+00,  1.3396e+00,  1.2975e+00,
          1.4182e+00,  1.3176e+00,  1.4504e+00,  1.3685e+00,  1.4777e+00,
          1.3001e+00,  1.3651e+00,  1.3455e+00,  1.3948e+00,  1.4207e+00,
          1.4316e+00,  1.4069e+00,  1.3658e+00,  1.3549e+00,  1.3077e+00,
          1.3474e+00,  1.3474e+00,  1.4050e+00,  1.4414e+00,  1.3593e+00,
          1.1979e+00,  1.3556e+00,  1.2488e+00,  1.4148e+00,  1.2414e+00,
          1.3631e+00,  3.4733e-01,  2.7511e-01,  3.9839e-01,  3.5670e-01,
          1.5852e-01,  1.0886e-01,  3.7122e-01,  2.0023e-01, -4.9901e-03,
          2.6209e+00,  1.9327e+00,  2.4700e+00,  2.1818e+00,  1.6046e+00,
          1.2545e+00,  2.4447e+00,  2.2524e+00,  1.2214e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 112 : 176.92091325218126
Test loss for epoch 112 : 176.6799507037978
Test Precision for epoch 112 : 0.26153846153846155
Test Recall for epoch 112 : 0.26153846153846155
Test F1 for epoch 112 : 0.26153846153846155


theta for epoch 113 : tensor([[ 2.1684,  2.1842,  2.2220,  2.2881,  2.2696,  2.1730,  2.2555,  2.1682,
          2.1682,  1.3762,  1.3789,  1.3780,  1.3814,  1.3748,  1.3837,  1.3765,
          1.3745,  1.3365,  1.3343,  1.2936,  1.2941,  1.3354,  1.3320,  1.3313,
          1.3338,  1.3306,  1.3306,  1.3172,  1.3600,  1.3540,  1.3569,  1.3601,
          1.3554,  1.3580,  1.3114,  1.3542,  1.7505,  1.7621,  1.7541,  1.7512,
          1.7586,  1.7012,  1.7520,  1.7412,  1.7525,  1.6483,  1.6306,  1.6263,
          1.6198,  1.6430,  1.6249,  1.6598,  1.6177,  1.6180],
        [ 1.3456,  1.2837,  1.1767,  1.3040,  1.3880,  1.3875,  1.3270,  1.3866,
          1.3866,  1.9721,  1.9791,  1.9233,  2.1682,  1.9679,  3.0405,  2.0216,
          1.8939,  2.9365,  1.2941,  1.3391,  1.2605,  1.2582,  1.3950,  1.3985,
          1.3569,  1.3978,  1.3978,  1.3622,  1.2183,  1.4221,  1.4207,  1.2524,
          1.4235,  1.4258,  1.3866,  1.4210,  1.7852,  1.8124,  1.7532,  1.7316,
          1.7946,  1.8088,  1.7508,  1.3092,  1.8014,  1.5321,  1.6898,  1.6851,
          1.6790,  1.4818,  1.6839,  1.4805,  1.6764,  1.6772],
        [ 1.3253,  1.3279,  1.3318,  1.3301,  1.3283,  1.3261,  1.3235,  1.3253,
          1.3253,  1.3848,  1.3875,  1.3867,  1.3874,  1.3833,  1.3457,  1.3850,
          1.3697,  1.3359,  2.2472,  2.2344,  2.3163,  2.2775,  2.1560,  2.1762,
          2.2400,  2.1478,  2.1478,  1.3605,  1.3288,  1.3610,  1.3639,  1.3586,
          1.3624,  1.3653,  1.3606,  1.3612,  1.7562,  1.7681,  1.7599,  1.7484,
          1.7644,  1.7640,  1.7578,  1.6807,  1.7486,  1.6406,  1.6358,  1.6314,
          1.6247,  1.5872,  1.6300,  1.6429,  1.6225,  1.6228],
        [ 1.3351,  1.3378,  1.3339,  1.3320,  1.3380,  1.3360,  1.3358,  1.3351,
          1.3351,  1.3936,  1.3887,  1.3956,  1.3874,  1.3920,  1.3033,  1.3938,
          1.3916,  1.2892,  1.3530,  1.3445,  1.3551,  1.3541,  1.3506,  1.3480,
          1.3524,  1.3491,  1.3491,  2.3523,  2.3070,  2.1042,  2.1998,  2.3495,
          2.1130,  2.3135,  2.1239,  2.1057,  1.7612,  1.7731,  1.7503,  1.7603,
          1.7700,  1.7675,  1.7508,  1.6780,  1.7635,  1.6623,  1.6409,  1.5308,
          1.5783,  1.6568,  1.6286,  1.6741,  1.5760,  1.6309],
        [ 1.7882,  1.4169,  0.5536,  0.8416,  1.2400,  1.6831,  1.6008,  1.7901,
          1.7901,  1.6743,  1.2738,  1.4850,  0.8731,  1.7316,  0.1051,  1.6277,
          1.7802,  0.9330,  1.3089,  0.8713,  0.6687,  1.1315,  1.6261,  1.7014,
          1.4321,  1.7970,  1.7970,  0.7400,  0.8201,  1.7703,  1.5436,  0.8005,
          1.7119,  1.1766,  1.8185,  1.7348,  0.2416, -0.0548, -0.0914,  0.1850,
          0.5567,  0.7205,  0.0861,  7.8596,  5.8745,  0.1285,  0.4943,  0.5318,
          0.6364,  0.3136,  0.6371, -0.1715,  0.6600,  0.7351],
        [ 1.3375,  1.3733,  1.4254,  1.4120,  1.3868,  1.3483,  1.3155,  1.3371,
          1.3371,  1.2932,  1.4145,  1.3135,  1.4468,  1.3644,  1.4740,  1.2959,
          1.3608,  1.3422,  1.3910,  1.4168,  1.4280,  1.4032,  1.3618,  1.3510,
          1.3032,  1.3434,  1.3434,  1.4021,  1.4386,  1.3564,  1.1941,  1.3527,
          1.2457,  1.4121,  1.2381,  1.3603,  0.3430,  0.2704,  0.3939,  0.3523,
          0.1540,  0.1044,  0.3668,  0.1953, -0.0105,  2.6296,  1.9405,  2.4813,
          2.1897,  1.6116,  1.2615,  2.4517,  2.2638,  1.2283]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 113 : 176.90715067527822
Test loss for epoch 113 : 176.66114848028798
Test Precision for epoch 113 : 0.26153846153846155
Test Recall for epoch 113 : 0.26153846153846155
Test F1 for epoch 113 : 0.26153846153846155


theta for epoch 114 : tensor([[ 2.1718e+00,  2.1877e+00,  2.2256e+00,  2.2919e+00,  2.2734e+00,
          2.1765e+00,  2.2593e+00,  2.1717e+00,  2.1717e+00,  1.3761e+00,
          1.3788e+00,  1.3780e+00,  1.3813e+00,  1.3747e+00,  1.3836e+00,
          1.3764e+00,  1.3744e+00,  1.3364e+00,  1.3338e+00,  1.2931e+00,
          1.2936e+00,  1.3349e+00,  1.3315e+00,  1.3309e+00,  1.3333e+00,
          1.3301e+00,  1.3301e+00,  1.3168e+00,  1.3597e+00,  1.3537e+00,
          1.3566e+00,  1.3598e+00,  1.3551e+00,  1.3577e+00,  1.3110e+00,
          1.3539e+00,  1.7509e+00,  1.7625e+00,  1.7545e+00,  1.7516e+00,
          1.7590e+00,  1.7015e+00,  1.7524e+00,  1.7415e+00,  1.7529e+00,
          1.6480e+00,  1.6303e+00,  1.6260e+00,  1.6195e+00,  1.6428e+00,
          1.6245e+00,  1.6595e+00,  1.6174e+00,  1.6176e+00],
        [ 1.3444e+00,  1.2842e+00,  1.1775e+00,  1.3029e+00,  1.3869e+00,
          1.3862e+00,  1.3266e+00,  1.3853e+00,  1.3853e+00,  1.9801e+00,
          1.9841e+00,  1.9306e+00,  2.1714e+00,  1.9745e+00,  3.0339e+00,
          2.0286e+00,  1.9016e+00,  2.9335e+00,  1.2949e+00,  1.3395e+00,
          1.2621e+00,  1.2584e+00,  1.3941e+00,  1.3973e+00,  1.3557e+00,
          1.3966e+00,  1.3966e+00,  1.3626e+00,  1.2179e+00,  1.4210e+00,
          1.4200e+00,  1.2539e+00,  1.4225e+00,  1.4248e+00,  1.3856e+00,
          1.4201e+00,  1.7854e+00,  1.8123e+00,  1.7533e+00,  1.7321e+00,
          1.7948e+00,  1.8088e+00,  1.7509e+00,  1.3160e+00,  1.8013e+00,
          1.5330e+00,  1.6881e+00,  1.6834e+00,  1.6771e+00,  1.4822e+00,
          1.6822e+00,  1.4830e+00,  1.6746e+00,  1.6753e+00],
        [ 1.3244e+00,  1.3270e+00,  1.3309e+00,  1.3292e+00,  1.3274e+00,
          1.3252e+00,  1.3226e+00,  1.3244e+00,  1.3244e+00,  1.3844e+00,
          1.3872e+00,  1.3863e+00,  1.3870e+00,  1.3829e+00,  1.3456e+00,
          1.3846e+00,  1.3692e+00,  1.3361e+00,  2.2515e+00,  2.2383e+00,
          2.3201e+00,  2.2812e+00,  2.1605e+00,  2.1801e+00,  2.2441e+00,
          2.1523e+00,  2.1523e+00,  1.3602e+00,  1.3286e+00,  1.3606e+00,
          1.3636e+00,  1.3583e+00,  1.3621e+00,  1.3649e+00,  1.3603e+00,
          1.3609e+00,  1.7565e+00,  1.7683e+00,  1.7601e+00,  1.7486e+00,
          1.7647e+00,  1.7643e+00,  1.7581e+00,  1.6819e+00,  1.7489e+00,
          1.6406e+00,  1.6355e+00,  1.6311e+00,  1.6244e+00,  1.5875e+00,
          1.6298e+00,  1.6429e+00,  1.6222e+00,  1.6225e+00],
        [ 1.3344e+00,  1.3370e+00,  1.3333e+00,  1.3315e+00,  1.3373e+00,
          1.3353e+00,  1.3351e+00,  1.3344e+00,  1.3344e+00,  1.3933e+00,
          1.3888e+00,  1.3953e+00,  1.3871e+00,  1.3917e+00,  1.3027e+00,
          1.3935e+00,  1.3913e+00,  1.2892e+00,  1.3523e+00,  1.3437e+00,
          1.3544e+00,  1.3534e+00,  1.3499e+00,  1.3474e+00,  1.3517e+00,
          1.3484e+00,  1.3484e+00,  2.3561e+00,  2.3117e+00,  2.1082e+00,
          2.2042e+00,  2.3532e+00,  2.1170e+00,  2.3170e+00,  2.1282e+00,
          2.1098e+00,  1.7616e+00,  1.7735e+00,  1.7507e+00,  1.7608e+00,
          1.7704e+00,  1.7680e+00,  1.7511e+00,  1.6786e+00,  1.7639e+00,
          1.6620e+00,  1.6406e+00,  1.5302e+00,  1.5778e+00,  1.6565e+00,
          1.6284e+00,  1.6739e+00,  1.5755e+00,  1.6305e+00],
        [ 1.7878e+00,  1.4144e+00,  5.5076e-01,  8.4000e-01,  1.2386e+00,
          1.6826e+00,  1.5993e+00,  1.7898e+00,  1.7898e+00,  1.6737e+00,
          1.2712e+00,  1.4837e+00,  8.6959e-01,  1.7302e+00,  1.0087e-01,
          1.6261e+00,  1.7799e+00,  9.2722e-01,  1.3062e+00,  8.6906e-01,
          6.6548e-01,  1.1292e+00,  1.6252e+00,  1.7006e+00,  1.4314e+00,
          1.7968e+00,  1.7968e+00,  7.3742e-01,  8.1787e-01,  1.7690e+00,
          1.5424e+00,  7.9686e-01,  1.7105e+00,  1.1747e+00,  1.8174e+00,
          1.7333e+00,  2.3887e-01, -5.6734e-02, -9.3161e-02,  1.8259e-01,
          5.5079e-01,  7.1204e-01,  8.3982e-02,  7.9221e+00,  5.8985e+00,
          1.2467e-01,  4.9088e-01,  5.2830e-01,  6.3290e-01,  3.0941e-01,
          6.3345e-01, -1.7514e-01,  6.5661e-01,  7.3155e-01],
        [ 1.3405e+00,  1.3764e+00,  1.4282e+00,  1.4148e+00,  1.3897e+00,
          1.3513e+00,  1.3186e+00,  1.3401e+00,  1.3401e+00,  1.2974e+00,
          1.4189e+00,  1.3179e+00,  1.4513e+00,  1.3686e+00,  1.4786e+00,
          1.3003e+00,  1.3649e+00,  1.3474e+00,  1.3957e+00,  1.4214e+00,
          1.4328e+00,  1.4080e+00,  1.3664e+00,  1.3557e+00,  1.3075e+00,
          1.3479e+00,  1.3479e+00,  1.4056e+00,  1.4421e+00,  1.3600e+00,
          1.1974e+00,  1.3563e+00,  1.2492e+00,  1.4158e+00,  1.2416e+00,
          1.3639e+00,  3.4706e-01,  2.7431e-01,  3.9783e-01,  3.5637e-01,
          1.5833e-01,  1.0889e-01,  3.7075e-01,  1.9911e-01, -6.8618e-03,
          2.6285e+00,  1.9385e+00,  2.4826e+00,  2.1877e+00,  1.6090e+00,
          1.2588e+00,  2.4491e+00,  2.2653e+00,  1.2256e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 114 : 176.890239472348
Test loss for epoch 114 : 176.6506231466154
Test Precision for epoch 114 : 0.26153846153846155
Test Recall for epoch 114 : 0.26153846153846155
Test F1 for epoch 114 : 0.26153846153846155


theta for epoch 115 : tensor([[ 2.1752,  2.1912,  2.2291,  2.2956,  2.2771,  2.1798,  2.2629,  2.1750,
          2.1750,  1.3756,  1.3783,  1.3775,  1.3808,  1.3742,  1.3832,  1.3760,
          1.3740,  1.3359,  1.3329,  1.2922,  1.2926,  1.3339,  1.3305,  1.3299,
          1.3323,  1.3292,  1.3292,  1.3165,  1.3595,  1.3534,  1.3564,  1.3596,
          1.3549,  1.3575,  1.3107,  1.3537,  1.7505,  1.7621,  1.7541,  1.7512,
          1.7586,  1.7010,  1.7520,  1.7410,  1.7525,  1.6497,  1.6319,  1.6277,
          1.6212,  1.6445,  1.6262,  1.6612,  1.6191,  1.6194],
        [ 1.3429,  1.2844,  1.1780,  1.3015,  1.3854,  1.3846,  1.3260,  1.3837,
          1.3837,  1.9883,  1.9894,  1.9380,  2.1748,  1.9812,  3.0276,  2.0357,
          1.9095,  2.9306,  1.2949,  1.3392,  1.2631,  1.2579,  1.3924,  1.3954,
          1.3538,  1.3947,  1.3947,  1.3629,  1.2174,  1.4199,  1.4192,  1.2553,
          1.4214,  1.4238,  1.3846,  1.4191,  1.7849,  1.8115,  1.7526,  1.7318,
          1.7942,  1.8080,  1.7503,  1.3220,  1.8005,  1.5360,  1.6886,  1.6838,
          1.6774,  1.4848,  1.6826,  1.4875,  1.6749,  1.6756],
        [ 1.3234,  1.3260,  1.3299,  1.3281,  1.3263,  1.3242,  1.3215,  1.3234,
          1.3234,  1.3835,  1.3863,  1.3854,  1.3862,  1.3821,  1.3451,  1.3838,
          1.3683,  1.3359,  2.2555,  2.2421,  2.3237,  2.2847,  2.1647,  2.1837,
          2.2480,  2.1566,  2.1566,  1.3598,  1.3286,  1.3603,  1.3633,  1.3580,
          1.3618,  1.3646,  1.3600,  1.3606,  1.7559,  1.7677,  1.7595,  1.7480,
          1.7641,  1.7637,  1.7575,  1.6823,  1.7484,  1.6426,  1.6372,  1.6328,
          1.6261,  1.5899,  1.6315,  1.6448,  1.6240,  1.6243],
        [ 1.3335,  1.3361,  1.3326,  1.3307,  1.3364,  1.3343,  1.3342,  1.3335,
          1.3335,  1.3925,  1.3884,  1.3946,  1.3863,  1.3910,  1.3017,  1.3928,
          1.3906,  1.2888,  1.3511,  1.3424,  1.3531,  1.3522,  1.3487,  1.3464,
          1.3505,  1.3473,  1.3473,  2.3601,  2.3164,  2.1124,  2.2087,  2.3572,
          2.1212,  2.3207,  2.1325,  2.1140,  1.7612,  1.7731,  1.7502,  1.7604,
          1.7700,  1.7676,  1.7506,  1.6782,  1.7633,  1.6635,  1.6422,  1.5315,
          1.5791,  1.6580,  1.6301,  1.6756,  1.5769,  1.6320],
        [ 1.7914,  1.4172,  0.5550,  0.8446,  1.2429,  1.6864,  1.6024,  1.7935,
          1.7935,  1.6783,  1.2753,  1.4880,  0.8736,  1.7339,  0.1051,  1.6298,
          1.7845,  0.9295,  1.3098,  0.8739,  0.6701,  1.1334,  1.6298,  1.7049,
          1.4364,  1.8014,  1.8014,  0.7428,  0.8235,  1.7733,  1.5475,  0.8015,
          1.7151,  1.1800,  1.8218,  1.7377,  0.2297, -0.0647, -0.1009,  0.1738,
          0.5382,  0.6968,  0.0756,  7.9778,  5.9142,  0.1308,  0.4970,  0.5346,
          0.6393,  0.3151,  0.6397, -0.1687,  0.6630,  0.7379],
        [ 1.3371,  1.3731,  1.4247,  1.4114,  1.3863,  1.3479,  1.3151,  1.3366,
          1.3366,  1.2925,  1.4146,  1.3132,  1.4470,  1.3640,  1.4742,  1.2955,
          1.3600,  1.3434,  1.3912,  1.4168,  1.4284,  1.4035,  1.3617,  1.3511,
          1.3023,  1.3431,  1.3431,  1.4025,  1.4392,  1.3569,  1.1934,  1.3532,
          1.2458,  1.4130,  1.2381,  1.3608,  0.3422,  0.2691,  0.3929,  0.3514,
          0.1533,  0.1040,  0.3658,  0.1937, -0.0127,  2.6381,  1.9472,  2.4948,
          2.1964,  1.6169,  1.2666,  2.4570,  2.2776,  1.2333]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 115 : 176.8691824393651
Test loss for epoch 115 : 176.62361518740985
Test Precision for epoch 115 : 0.26153846153846155
Test Recall for epoch 115 : 0.26153846153846155
Test F1 for epoch 115 : 0.26153846153846155


theta for epoch 116 : tensor([[ 2.1792,  2.1953,  2.2333,  2.2999,  2.2814,  2.1838,  2.2672,  2.1790,
          2.1790,  1.3754,  1.3780,  1.3772,  1.3806,  1.3740,  1.3829,  1.3757,
          1.3737,  1.3356,  1.3325,  1.2918,  1.2923,  1.3336,  1.3302,  1.3296,
          1.3320,  1.3288,  1.3288,  1.3158,  1.3589,  1.3528,  1.3558,  1.3590,
          1.3543,  1.3569,  1.3100,  1.3531,  1.7507,  1.7622,  1.7542,  1.7514,
          1.7587,  1.7010,  1.7522,  1.7411,  1.7526,  1.6482,  1.6304,  1.6262,
          1.6197,  1.6430,  1.6248,  1.6598,  1.6176,  1.6179],
        [ 1.3419,  1.2851,  1.1788,  1.3005,  1.3844,  1.3834,  1.3258,  1.3826,
          1.3826,  1.9969,  1.9950,  1.9457,  2.1785,  1.9882,  3.0216,  2.0431,
          1.9177,  2.9280,  1.2957,  1.3396,  1.2648,  1.2583,  1.3916,  1.3944,
          1.3528,  1.3936,  1.3936,  1.3629,  1.2166,  1.4186,  1.4182,  1.2565,
          1.4201,  1.4225,  1.3834,  1.4178,  1.7851,  1.8113,  1.7526,  1.7322,
          1.7943,  1.8078,  1.7503,  1.3284,  1.8003,  1.5357,  1.6856,  1.6809,
          1.6744,  1.4841,  1.6797,  1.4884,  1.6719,  1.6726],
        [ 1.3228,  1.3254,  1.3293,  1.3275,  1.3258,  1.3236,  1.3209,  1.3228,
          1.3228,  1.3831,  1.3859,  1.3849,  1.3857,  1.3817,  1.3449,  1.3833,
          1.3677,  1.3360,  2.2601,  2.2463,  2.3278,  2.2887,  2.1695,  2.1879,
          2.2524,  2.1613,  2.1613,  1.3592,  1.3282,  1.3597,  1.3628,  1.3574,
          1.3612,  1.3641,  1.3594,  1.3600,  1.7560,  1.7678,  1.7596,  1.7480,
          1.7642,  1.7638,  1.7576,  1.6833,  1.7485,  1.6416,  1.6359,  1.6315,
          1.6248,  1.5893,  1.6302,  1.6438,  1.6226,  1.6229],
        [ 1.3331,  1.3357,  1.3324,  1.3305,  1.3359,  1.3339,  1.3337,  1.3330,
          1.3330,  1.3922,  1.3885,  1.3943,  1.3859,  1.3908,  1.3012,  1.3925,
          1.3903,  1.2888,  1.3507,  1.3419,  1.3527,  1.3518,  1.3484,  1.3461,
          1.3501,  1.3469,  1.3469,  2.3639,  2.3210,  2.1164,  2.2130,  2.3610,
          2.1251,  2.3242,  2.1367,  2.1179,  1.7615,  1.7733,  1.7504,  1.7607,
          1.7702,  1.7679,  1.7507,  1.6785,  1.7634,  1.6622,  1.6409,  1.5300,
          1.5777,  1.6567,  1.6289,  1.6744,  1.5754,  1.6307],
        [ 1.7917,  1.4156,  0.5534,  0.8441,  1.2426,  1.6866,  1.6017,  1.7939,
          1.7939,  1.6783,  1.2737,  1.4874,  0.8712,  1.7332,  0.1021,  1.6288,
          1.7848,  0.9250,  1.3081,  0.8728,  0.6680,  1.1320,  1.6298,  1.7049,
          1.4366,  1.8020,  1.8020,  0.7414,  0.8222,  1.7727,  1.5471,  0.7991,
          1.7145,  1.1791,  1.8213,  1.7370,  0.2263, -0.0673, -0.1033,  0.1708,
          0.5318,  0.6880,  0.0729,  8.0391,  5.9362,  0.1279,  0.4945,  0.5321,
          0.6369,  0.3120,  0.6371, -0.1714,  0.6606,  0.7354],
        [ 1.3397,  1.3758,  1.4272,  1.4139,  1.3889,  1.3505,  1.3177,  1.3392,
          1.3392,  1.2960,  1.4183,  1.3169,  1.4507,  1.3675,  1.4780,  1.2991,
          1.3634,  1.3477,  1.3951,  1.4206,  1.4323,  1.4075,  1.3655,  1.3550,
          1.3059,  1.3469,  1.3469,  1.4052,  1.4418,  1.3597,  1.1958,  1.3560,
          1.2485,  1.4158,  1.2408,  1.3636,  0.3454,  0.2723,  0.3960,  0.3547,
          0.1568,  0.1077,  0.3690,  0.1966, -0.0099,  2.6381,  1.9462,  2.4971,
          2.1954,  1.6152,  1.2649,  2.4554,  2.2800,  1.2315]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 116 : 176.84628089153438
Test loss for epoch 116 : 176.6059225723718
Test Precision for epoch 116 : 0.26153846153846155
Test Recall for epoch 116 : 0.26153846153846155
Test F1 for epoch 116 : 0.26153846153846155


theta for epoch 117 : tensor([[ 2.1833,  2.1995,  2.2375,  2.3043,  2.2859,  2.1879,  2.2715,  2.1831,
          2.1831,  1.3748,  1.3775,  1.3767,  1.3800,  1.3734,  1.3823,  1.3752,
          1.3732,  1.3350,  1.3318,  1.2910,  1.2916,  1.3328,  1.3295,  1.3289,
          1.3313,  1.3281,  1.3281,  1.3150,  1.3582,  1.3521,  1.3550,  1.3583,
          1.3535,  1.3561,  1.3092,  1.3523,  1.7505,  1.7620,  1.7540,  1.7512,
          1.7586,  1.7007,  1.7520,  1.7408,  1.7524,  1.6476,  1.6298,  1.6256,
          1.6191,  1.6424,  1.6242,  1.6592,  1.6170,  1.6173],
        [ 1.3411,  1.2861,  1.1798,  1.2998,  1.3836,  1.3825,  1.3258,  1.3817,
          1.3817,  2.0051,  2.0002,  1.9530,  2.1818,  1.9948,  3.0155,  2.0500,
          1.9254,  2.9250,  1.2961,  1.3396,  1.2661,  1.2583,  1.3904,  1.3930,
          1.3515,  1.3923,  1.3923,  1.3628,  1.2157,  1.4171,  1.4170,  1.2575,
          1.4186,  1.4211,  1.3820,  1.4165,  1.7850,  1.8109,  1.7524,  1.7323,
          1.7942,  1.8074,  1.7501,  1.3343,  1.7998,  1.5363,  1.6838,  1.6791,
          1.6724,  1.4844,  1.6778,  1.4902,  1.6700,  1.6706],
        [ 1.3227,  1.3252,  1.3291,  1.3273,  1.3255,  1.3234,  1.3207,  1.3226,
          1.3226,  1.3826,  1.3854,  1.3844,  1.3852,  1.3812,  1.3446,  1.3828,
          1.3671,  1.3361,  2.2639,  2.2497,  2.3310,  2.2918,  2.1735,  2.1913,
          2.2560,  2.1653,  2.1653,  1.3586,  1.3279,  1.3592,  1.3622,  1.3568,
          1.3607,  1.3636,  1.3589,  1.3595,  1.7558,  1.7676,  1.7594,  1.7478,
          1.7640,  1.7636,  1.7573,  1.6840,  1.7484,  1.6415,  1.6356,  1.6312,
          1.6245,  1.5896,  1.6299,  1.6437,  1.6223,  1.6226],
        [ 1.3330,  1.3356,  1.3325,  1.3305,  1.3358,  1.3338,  1.3336,  1.3329,
          1.3329,  1.3919,  1.3885,  1.3939,  1.3855,  1.3905,  1.3006,  1.3921,
          1.3900,  1.2887,  1.3502,  1.3412,  1.3521,  1.3512,  1.3478,  1.3456,
          1.3495,  1.3464,  1.3464,  2.3672,  2.3250,  2.1198,  2.2167,  2.3643,
          2.1285,  2.3273,  2.1403,  2.1214,  1.7615,  1.7732,  1.7503,  1.7607,
          1.7702,  1.7679,  1.7505,  1.6784,  1.7632,  1.6618,  1.6405,  1.5294,
          1.5771,  1.6563,  1.6287,  1.6740,  1.5748,  1.6302],
        [ 1.7947,  1.4176,  0.5565,  0.8477,  1.2461,  1.6899,  1.6042,  1.7972,
          1.7972,  1.6816,  1.2763,  1.4902,  0.8735,  1.7357,  0.1045,  1.6310,
          1.7881,  0.9258,  1.3103,  0.8761,  0.6709,  1.1347,  1.6331,  1.7080,
          1.4402,  1.8054,  1.8054,  0.7448,  0.8258,  1.7755,  1.5506,  0.8017,
          1.7174,  1.1826,  1.8241,  1.7397,  0.2189, -0.0737, -0.1095,  0.1638,
          0.5214,  0.6751,  0.0662,  8.0962,  5.9527,  0.1312,  0.4980,  0.5358,
          0.6406,  0.3150,  0.6407, -0.1678,  0.6643,  0.7390],
        [ 1.3381,  1.3743,  1.4256,  1.4124,  1.3874,  1.3489,  1.3162,  1.3377,
          1.3377,  1.2931,  1.4159,  1.3142,  1.4483,  1.3648,  1.4756,  1.2964,
          1.3605,  1.3457,  1.3926,  1.4180,  1.4299,  1.4050,  1.3629,  1.3525,
          1.3028,  1.3442,  1.3442,  1.4032,  1.4399,  1.3576,  1.1930,  1.3539,
          1.2462,  1.4140,  1.2385,  1.3616,  0.3426,  0.2694,  0.3932,  0.3519,
          0.1541,  0.1051,  0.3661,  0.1933, -0.0135,  2.6453,  1.9524,  2.5068,
          2.2017,  1.6207,  1.2702,  2.4609,  2.2898,  1.2367]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 117 : 176.8241450005609
Test loss for epoch 117 : 176.58086212988283
Test Precision for epoch 117 : 0.26153846153846155
Test Recall for epoch 117 : 0.26153846153846155
Test F1 for epoch 117 : 0.26153846153846155


theta for epoch 118 : tensor([[ 2.1870,  2.2034,  2.2414,  2.3084,  2.2900,  2.1917,  2.2756,  2.1868,
          2.1868,  1.3744,  1.3771,  1.3762,  1.3796,  1.3730,  1.3819,  1.3747,
          1.3728,  1.3346,  1.3313,  1.2905,  1.2911,  1.3323,  1.3290,  1.3284,
          1.3308,  1.3276,  1.3276,  1.3144,  1.3577,  1.3515,  1.3545,  1.3578,
          1.3530,  1.3556,  1.3086,  1.3518,  1.7506,  1.7622,  1.7542,  1.7513,
          1.7587,  1.7008,  1.7522,  1.7409,  1.7525,  1.6465,  1.6287,  1.6245,
          1.6180,  1.6414,  1.6231,  1.6581,  1.6159,  1.6162],
        [ 1.3402,  1.2869,  1.1807,  1.2990,  1.3827,  1.3814,  1.3258,  1.3806,
          1.3806,  2.0129,  2.0052,  1.9598,  2.1848,  2.0011,  3.0091,  2.0566,
          1.9329,  2.9218,  1.2966,  1.3398,  1.2677,  1.2585,  1.3894,  1.3919,
          1.3504,  1.3911,  1.3911,  1.3628,  1.2151,  1.4158,  1.4160,  1.2587,
          1.4174,  1.4199,  1.3809,  1.4153,  1.7853,  1.8108,  1.7525,  1.7329,
          1.7944,  1.8074,  1.7503,  1.3404,  1.7997,  1.5366,  1.6815,  1.6768,
          1.6700,  1.4843,  1.6755,  1.4914,  1.6676,  1.6682],
        [ 1.3223,  1.3249,  1.3287,  1.3269,  1.3252,  1.3231,  1.3204,  1.3223,
          1.3223,  1.3821,  1.3849,  1.3839,  1.3848,  1.3808,  1.3444,  1.3823,
          1.3665,  1.3363,  2.2674,  2.2529,  2.3340,  2.2947,  2.1772,  2.1945,
          2.2592,  2.1690,  2.1690,  1.3582,  1.3278,  1.3588,  1.3619,  1.3564,
          1.3603,  1.3632,  1.3585,  1.3591,  1.7559,  1.7677,  1.7595,  1.7479,
          1.7641,  1.7637,  1.7575,  1.6850,  1.7485,  1.6410,  1.6347,  1.6304,
          1.6236,  1.5895,  1.6291,  1.6431,  1.6215,  1.6218],
        [ 1.3326,  1.3353,  1.3323,  1.3304,  1.3355,  1.3335,  1.3333,  1.3326,
          1.3326,  1.3915,  1.3884,  1.3935,  1.3850,  1.3901,  1.3000,  1.3917,
          1.3896,  1.2885,  1.3496,  1.3405,  1.3515,  1.3506,  1.3473,  1.3452,
          1.3490,  1.3458,  1.3458,  2.3707,  2.3290,  2.1233,  2.2205,  2.3678,
          2.1320,  2.3304,  2.1440,  2.1248,  1.7617,  1.7734,  1.7505,  1.7610,
          1.7704,  1.7682,  1.7507,  1.6787,  1.7633,  1.6609,  1.6396,  1.5282,
          1.5760,  1.6554,  1.6279,  1.6732,  1.5738,  1.6292],
        [ 1.7961,  1.4176,  0.5570,  0.8490,  1.2474,  1.6914,  1.6049,  1.7987,
          1.7987,  1.6828,  1.2764,  1.4909,  0.8733,  1.7361,  0.1040,  1.6312,
          1.7895,  0.9238,  1.3102,  0.8768,  0.6709,  1.1349,  1.6344,  1.7092,
          1.4417,  1.8070,  1.8070,  0.7456,  0.8268,  1.7764,  1.5520,  0.8017,
          1.7184,  1.1837,  1.8252,  1.7406,  0.2139, -0.0779, -0.1135,  0.1591,
          0.5135,  0.6648,  0.0618,  8.1555,  5.9715,  0.1312,  0.4983,  0.5362,
          0.6411,  0.3147,  0.6410, -0.1676,  0.6648,  0.7395],
        [ 1.3384,  1.3747,  1.4258,  1.4126,  1.3876,  1.3492,  1.3164,  1.3379,
          1.3379,  1.2931,  1.4162,  1.3144,  1.4487,  1.3649,  1.4759,  1.2966,
          1.3604,  1.3466,  1.3929,  1.4182,  1.4303,  1.4053,  1.3630,  1.3527,
          1.3027,  1.3443,  1.3443,  1.4033,  1.4401,  1.3578,  1.1926,  1.3541,
          1.2463,  1.4143,  1.2385,  1.3618,  0.3429,  0.2696,  0.3933,  0.3521,
          0.1545,  0.1056,  0.3663,  0.1930, -0.0138,  2.6492,  1.9553,  2.5132,
          2.2047,  1.6228,  1.2722,  2.4632,  2.2963,  1.2387]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 118 : 176.80493349618862
Test loss for epoch 118 : 176.56293724018926
Test Precision for epoch 118 : 0.26153846153846155
Test Recall for epoch 118 : 0.26153846153846155
Test F1 for epoch 118 : 0.26153846153846155


theta for epoch 119 : tensor([[ 2.1903,  2.2068,  2.2448,  2.3120,  2.2936,  2.1950,  2.2791,  2.1901,
          2.1901,  1.3741,  1.3768,  1.3759,  1.3793,  1.3728,  1.3816,  1.3744,
          1.3725,  1.3343,  1.3309,  1.2902,  1.2908,  1.3319,  1.3287,  1.3281,
          1.3304,  1.3273,  1.3273,  1.3140,  1.3574,  1.3511,  1.3542,  1.3575,
          1.3526,  1.3553,  1.3082,  1.3514,  1.7507,  1.7622,  1.7543,  1.7514,
          1.7588,  1.7008,  1.7522,  1.7409,  1.7525,  1.6460,  1.6281,  1.6239,
          1.6174,  1.6409,  1.6226,  1.6576,  1.6153,  1.6156],
        [ 1.3389,  1.2873,  1.1810,  1.2977,  1.3813,  1.3799,  1.3253,  1.3791,
          1.3791,  2.0208,  2.0102,  1.9666,  2.1878,  2.0074,  3.0029,  2.0632,
          1.9403,  2.9186,  1.2971,  1.3400,  1.2691,  1.2588,  1.3885,  1.3907,
          1.3493,  1.3900,  1.3900,  1.3630,  1.2146,  1.4147,  1.4151,  1.2599,
          1.4163,  1.4188,  1.3799,  1.4143,  1.7856,  1.8106,  1.7526,  1.7334,
          1.7946,  1.8073,  1.7504,  1.3463,  1.7995,  1.5373,  1.6797,  1.6750,
          1.6681,  1.4847,  1.6737,  1.4930,  1.6658,  1.6663],
        [ 1.3214,  1.3240,  1.3278,  1.3260,  1.3243,  1.3222,  1.3195,  1.3214,
          1.3214,  1.3815,  1.3844,  1.3833,  1.3842,  1.3803,  1.3440,  1.3818,
          1.3658,  1.3364,  2.2711,  2.2563,  2.3372,  2.2979,  2.1812,  2.1979,
          2.2628,  2.1731,  2.1731,  1.3578,  1.3278,  1.3584,  1.3615,  1.3561,
          1.3600,  1.3628,  1.3581,  1.3587,  1.7559,  1.7676,  1.7595,  1.7479,
          1.7641,  1.7637,  1.7575,  1.6859,  1.7485,  1.6407,  1.6342,  1.6299,
          1.6231,  1.5897,  1.6286,  1.6428,  1.6210,  1.6213],
        [ 1.3318,  1.3345,  1.3317,  1.3298,  1.3346,  1.3326,  1.3325,  1.3318,
          1.3318,  1.3910,  1.3882,  1.3930,  1.3844,  1.3896,  1.2993,  1.3912,
          1.3891,  1.2883,  1.3490,  1.3397,  1.3509,  1.3500,  1.3467,  1.3446,
          1.3483,  1.3452,  1.3452,  2.3745,  2.3334,  2.1271,  2.2246,  2.3716,
          2.1358,  2.3340,  2.1480,  2.1286,  1.7619,  1.7735,  1.7505,  1.7612,
          1.7704,  1.7684,  1.7506,  1.6788,  1.7633,  1.6602,  1.6390,  1.5274,
          1.5752,  1.6548,  1.6274,  1.6726,  1.5730,  1.6285],
        [ 1.7970,  1.4171,  0.5572,  0.8499,  1.2483,  1.6923,  1.6050,  1.7998,
          1.7998,  1.6838,  1.2764,  1.4913,  0.8728,  1.7364,  0.1032,  1.6312,
          1.7907,  0.9216,  1.3100,  0.8774,  0.6707,  1.1350,  1.6355,  1.7102,
          1.4430,  1.8084,  1.8084,  0.7463,  0.8276,  1.7774,  1.5533,  0.8015,
          1.7194,  1.1848,  1.8262,  1.7415,  0.2092, -0.0818, -0.1173,  0.1547,
          0.5060,  0.6551,  0.0577,  8.2150,  5.9900,  0.1310,  0.4986,  0.5366,
          0.6416,  0.3143,  0.6414, -0.1676,  0.6653,  0.7400],
        [ 1.3385,  1.3749,  1.4258,  1.4127,  1.3877,  1.3493,  1.3166,  1.3380,
          1.3380,  1.2935,  1.4169,  1.3150,  1.4494,  1.3654,  1.4766,  1.2972,
          1.3608,  1.3477,  1.3936,  1.4187,  1.4309,  1.4060,  1.3635,  1.3533,
          1.3029,  1.3448,  1.3448,  1.4038,  1.4406,  1.3583,  1.1926,  1.3547,
          1.2467,  1.4149,  1.2389,  1.3623,  0.3434,  0.2702,  0.3938,  0.3526,
          0.1552,  0.1065,  0.3668,  0.1931, -0.0138,  2.6529,  1.9580,  2.5193,
          2.2074,  1.6248,  1.2740,  2.4652,  2.3024,  1.2404]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 119 : 176.78849476662162
Test loss for epoch 119 : 176.54818320241048
Test Precision for epoch 119 : 0.26153846153846155
Test Recall for epoch 119 : 0.26153846153846155
Test F1 for epoch 119 : 0.26153846153846155


theta for epoch 120 : tensor([[ 2.1937,  2.2103,  2.2484,  2.3158,  2.2974,  2.1984,  2.2828,  2.1935,
          2.1935,  1.3737,  1.3764,  1.3755,  1.3789,  1.3724,  1.3812,  1.3740,
          1.3721,  1.3339,  1.3303,  1.2896,  1.2903,  1.3313,  1.3281,  1.3275,
          1.3298,  1.3267,  1.3267,  1.3134,  1.3569,  1.3506,  1.3537,  1.3570,
          1.3521,  1.3548,  1.3076,  1.3509,  1.7503,  1.7618,  1.7539,  1.7510,
          1.7584,  1.7002,  1.7518,  1.7404,  1.7521,  1.6463,  1.6285,  1.6243,
          1.6178,  1.6413,  1.6230,  1.6580,  1.6157,  1.6160],
        [ 1.3374,  1.2876,  1.1810,  1.2962,  1.3798,  1.3783,  1.3247,  1.3775,
          1.3775,  2.0290,  2.0157,  1.9738,  2.1911,  2.0140,  2.9972,  2.0701,
          1.9481,  2.9157,  1.2972,  1.3398,  1.2702,  1.2587,  1.3871,  1.3893,
          1.3479,  1.3885,  1.3885,  1.3629,  1.2139,  1.4133,  1.4139,  1.2609,
          1.4150,  1.4176,  1.3788,  1.4130,  1.7853,  1.8100,  1.7522,  1.7334,
          1.7943,  1.8067,  1.7500,  1.3515,  1.7988,  1.5391,  1.6790,  1.6743,
          1.6673,  1.4861,  1.6730,  1.4954,  1.6650,  1.6654],
        [ 1.3204,  1.3229,  1.3268,  1.3249,  1.3232,  1.3211,  1.3184,  1.3203,
          1.3203,  1.3807,  1.3836,  1.3825,  1.3835,  1.3795,  1.3435,  1.3810,
          1.3649,  1.3363,  2.2753,  2.2602,  2.3409,  2.3015,  2.1856,  2.2018,
          2.2668,  2.1775,  2.1775,  1.3571,  1.3275,  1.3578,  1.3609,  1.3555,
          1.3594,  1.3622,  1.3575,  1.3581,  1.7554,  1.7670,  1.7589,  1.7473,
          1.7635,  1.7631,  1.7569,  1.6863,  1.7480,  1.6413,  1.6345,  1.6302,
          1.6234,  1.5907,  1.6289,  1.6433,  1.6213,  1.6216],
        [ 1.3308,  1.3335,  1.3309,  1.3290,  1.3337,  1.3316,  1.3315,  1.3308,
          1.3308,  1.3904,  1.3879,  1.3923,  1.3837,  1.3891,  1.2985,  1.3907,
          1.3886,  1.2879,  1.3481,  1.3386,  1.3499,  1.3490,  1.3458,  1.3438,
          1.3474,  1.3443,  1.3443,  2.3786,  2.3379,  2.1310,  2.2289,  2.3756,
          2.1397,  2.3377,  2.1522,  2.1326,  1.7614,  1.7730,  1.7499,  1.7608,
          1.7700,  1.7680,  1.7500,  1.6784,  1.7627,  1.6604,  1.6392,  1.5275,
          1.5753,  1.6550,  1.6278,  1.6729,  1.5731,  1.6286],
        [ 1.7993,  1.4184,  0.5599,  0.8530,  1.2512,  1.6949,  1.6068,  1.8022,
          1.8022,  1.6867,  1.2790,  1.4939,  0.8751,  1.7386,  0.1056,  1.6331,
          1.7938,  0.9226,  1.3121,  0.8806,  0.6733,  1.1374,  1.6385,  1.7130,
          1.4463,  1.8115,  1.8115,  0.7498,  0.8311,  1.7803,  1.5569,  0.8044,
          1.7224,  1.1884,  1.8292,  1.7445,  0.2022, -0.0879, -0.1233,  0.1481,
          0.4963,  0.6430,  0.0513,  8.2721,  6.0052,  0.1345,  0.5025,  0.5406,
          0.6458,  0.3176,  0.6454, -0.1639,  0.6695,  0.7441],
        [ 1.3365,  1.3732,  1.4239,  1.4108,  1.3858,  1.3474,  1.3147,  1.3360,
          1.3360,  1.2912,  1.4150,  1.3128,  1.4474,  1.3633,  1.4746,  1.2950,
          1.3584,  1.3461,  1.3913,  1.4162,  1.4287,  1.4037,  1.3611,  1.3510,
          1.3001,  1.3423,  1.3423,  1.4020,  1.4390,  1.3566,  1.1903,  1.3530,
          1.2448,  1.4134,  1.2369,  1.3607,  0.3410,  0.2677,  0.3914,  0.3502,
          0.1529,  0.1043,  0.3644,  0.1901, -0.0168,  2.6600,  1.9641,  2.5289,
          2.2136,  1.6301,  1.2793,  2.4707,  2.3122,  1.2456]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 120 : 176.77350004652305
Test loss for epoch 120 : 176.53062472739074
Test Precision for epoch 120 : 0.26153846153846155
Test Recall for epoch 120 : 0.26153846153846155
Test F1 for epoch 120 : 0.26153846153846155


theta for epoch 121 : tensor([[ 2.1978,  2.2145,  2.2526,  2.3202,  2.3018,  2.2025,  2.2872,  2.1976,
          2.1976,  1.3732,  1.3760,  1.3751,  1.3784,  1.3720,  1.3807,  1.3736,
          1.3717,  1.3335,  1.3297,  1.2889,  1.2896,  1.3307,  1.3274,  1.3269,
          1.3292,  1.3261,  1.3261,  1.3125,  1.3561,  1.3498,  1.3528,  1.3562,
          1.3513,  1.3539,  1.3068,  1.3501,  1.7501,  1.7615,  1.7536,  1.7507,
          1.7581,  1.6999,  1.7516,  1.7400,  1.7518,  1.6451,  1.6273,  1.6231,
          1.6165,  1.6401,  1.6218,  1.6568,  1.6144,  1.6147],
        [ 1.3364,  1.2883,  1.1815,  1.2951,  1.3786,  1.3771,  1.3244,  1.3762,
          1.3762,  2.0375,  2.0214,  1.9811,  2.1948,  2.0208,  2.9918,  2.0773,
          1.9561,  2.9132,  1.2974,  1.3396,  1.2712,  1.2587,  1.3860,  1.3880,
          1.3467,  1.3873,  1.3873,  1.3626,  1.2129,  1.4118,  1.4125,  1.2616,
          1.4134,  1.4161,  1.3774,  1.4115,  1.7853,  1.8096,  1.7520,  1.7337,
          1.7943,  1.8064,  1.7498,  1.3568,  1.7984,  1.5392,  1.6768,  1.6721,
          1.6649,  1.4860,  1.6707,  1.4962,  1.6626,  1.6631],
        [ 1.3197,  1.3223,  1.3261,  1.3242,  1.3224,  1.3205,  1.3178,  1.3196,
          1.3196,  1.3800,  1.3829,  1.3817,  1.3828,  1.3788,  1.3429,  1.3803,
          1.3640,  1.3363,  2.2800,  2.2645,  2.3450,  2.3055,  2.1905,  2.2062,
          2.2712,  2.1824,  2.1824,  1.3562,  1.3269,  1.3569,  1.3601,  1.3546,
          1.3585,  1.3613,  1.3567,  1.3572,  1.7550,  1.7667,  1.7586,  1.7469,
          1.7632,  1.7628,  1.7565,  1.6869,  1.7477,  1.6403,  1.6333,  1.6289,
          1.6222,  1.5902,  1.6277,  1.6423,  1.6201,  1.6204],
        [ 1.3303,  1.3330,  1.3306,  1.3286,  1.3331,  1.3311,  1.3310,  1.3303,
          1.3303,  1.3900,  1.3878,  1.3919,  1.3832,  1.3887,  1.2979,  1.3902,
          1.3882,  1.2876,  1.3473,  1.3377,  1.3492,  1.3483,  1.3450,  1.3431,
          1.3467,  1.3436,  1.3436,  2.3826,  2.3423,  2.1349,  2.2330,  2.3797,
          2.1436,  2.3414,  2.1563,  2.1365,  1.7612,  1.7728,  1.7496,  1.7607,
          1.7697,  1.7678,  1.7496,  1.6782,  1.7624,  1.6593,  1.6381,  1.5263,
          1.5740,  1.6538,  1.6268,  1.6717,  1.5718,  1.6274],
        [ 1.7996,  1.4171,  0.5590,  0.8529,  1.2511,  1.6952,  1.6062,  1.8027,
          1.8027,  1.6866,  1.2777,  1.4931,  0.8733,  1.7378,  0.1032,  1.6320,
          1.7940,  0.9191,  1.3106,  0.8797,  0.6714,  1.1360,  1.6384,  1.7129,
          1.4463,  1.8118,  1.8118,  0.7488,  0.8301,  1.7800,  1.5568,  0.8025,
          1.7220,  1.1878,  1.8289,  1.7441,  0.1989, -0.0906, -0.1258,  0.1451,
          0.4905,  0.6352,  0.0485,  8.3328,  6.0243,  0.1323,  0.5009,  0.5391,
          0.6443,  0.3153,  0.6439, -0.1660,  0.6681,  0.7427],
        [ 1.3389,  1.3756,  1.4261,  1.4131,  1.3881,  1.3497,  1.3171,  1.3384,
          1.3384,  1.2945,  1.4185,  1.3163,  1.4509,  1.3666,  1.4780,  1.2986,
          1.3617,  1.3501,  1.3946,  1.4193,  1.4319,  1.4070,  1.3643,  1.3543,
          1.3031,  1.3455,  1.3455,  1.4043,  1.4412,  1.3589,  1.1923,  1.3553,
          1.2471,  1.4157,  1.2392,  1.3630,  0.3441,  0.2709,  0.3944,  0.3533,
          0.1563,  0.1079,  0.3674,  0.1927, -0.0141,  2.6608,  1.9638,  2.5320,
          2.2133,  1.6291,  1.2780,  2.4698,  2.3153,  1.2443]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 121 : 176.75860466626787
Test loss for epoch 121 : 176.52067407010674
Test Precision for epoch 121 : 0.26153846153846155
Test Recall for epoch 121 : 0.26153846153846155
Test F1 for epoch 121 : 0.26153846153846155


theta for epoch 122 : tensor([[ 2.2019,  2.2187,  2.2568,  2.3246,  2.3063,  2.2066,  2.2916,  2.2017,
          2.2017,  1.3724,  1.3752,  1.3742,  1.3776,  1.3712,  1.3799,  1.3728,
          1.3709,  1.3326,  1.3286,  1.2878,  1.2886,  1.3296,  1.3263,  1.3258,
          1.3281,  1.3250,  1.3250,  1.3117,  1.3553,  1.3489,  1.3520,  1.3553,
          1.3505,  1.3531,  1.3059,  1.3492,  1.7493,  1.7607,  1.7528,  1.7500,
          1.7573,  1.6990,  1.7508,  1.7392,  1.7509,  1.6454,  1.6275,  1.6233,
          1.6168,  1.6403,  1.6220,  1.6570,  1.6147,  1.6150],
        [ 1.3356,  1.2892,  1.1821,  1.2943,  1.3777,  1.3761,  1.3244,  1.3752,
          1.3752,  2.0455,  2.0268,  1.9879,  2.1980,  2.0272,  2.9861,  2.0839,
          1.9636,  2.9102,  1.2972,  1.3391,  1.2719,  1.2583,  1.3844,  1.3863,
          1.3451,  1.3856,  1.3856,  1.3622,  1.2121,  1.4103,  1.4112,  1.2623,
          1.4120,  1.4146,  1.3760,  1.4101,  1.7849,  1.8087,  1.7514,  1.7335,
          1.7938,  1.8055,  1.7492,  1.3614,  1.7975,  1.5411,  1.6763,  1.6716,
          1.6644,  1.4875,  1.6702,  1.4986,  1.6621,  1.6625],
        [ 1.3193,  1.3219,  1.3257,  1.3238,  1.3221,  1.3201,  1.3174,  1.3193,
          1.3193,  1.3791,  1.3819,  1.3808,  1.3818,  1.3779,  1.3422,  1.3794,
          1.3629,  1.3360,  2.2838,  2.2681,  2.3483,  2.3088,  2.1947,  2.2098,
          2.2749,  2.1866,  2.1866,  1.3553,  1.3264,  1.3561,  1.3593,  1.3538,
          1.3577,  1.3605,  1.3558,  1.3564,  1.7542,  1.7658,  1.7578,  1.7460,
          1.7623,  1.7620,  1.7557,  1.6870,  1.7469,  1.6408,  1.6336,  1.6293,
          1.6225,  1.5912,  1.6281,  1.6428,  1.6204,  1.6207],
        [ 1.3300,  1.3327,  1.3305,  1.3286,  1.3328,  1.3308,  1.3307,  1.3299,
          1.3299,  1.3892,  1.3873,  1.3911,  1.3824,  1.3880,  1.2970,  1.3895,
          1.3874,  1.2870,  1.3463,  1.3364,  1.3481,  1.3473,  1.3440,  1.3421,
          1.3456,  1.3425,  1.3425,  2.3864,  2.3464,  2.1385,  2.2369,  2.3834,
          2.1472,  2.3449,  2.1601,  2.1400,  1.7605,  1.7721,  1.7487,  1.7600,
          1.7690,  1.7672,  1.7488,  1.6775,  1.7616,  1.6595,  1.6384,  1.5265,
          1.5742,  1.6541,  1.6273,  1.6720,  1.5720,  1.6276],
        [ 1.8030,  1.4199,  0.5633,  0.8574,  1.2555,  1.6990,  1.6092,  1.8063,
          1.8063,  1.6902,  1.2813,  1.4964,  0.8769,  1.7407,  0.1070,  1.6346,
          1.7977,  0.9216,  1.3136,  0.8839,  0.6753,  1.1393,  1.6422,  1.7163,
          1.4503,  1.8154,  1.8154,  0.7535,  0.8348,  1.7837,  1.5613,  0.8067,
          1.7258,  1.1924,  1.8326,  1.7479,  0.1910, -0.0976, -0.1327,  0.1376,
          0.4800,  0.6225,  0.0412,  8.3885,  6.0371,  0.1375,  0.5064,  0.5447,
          0.6502,  0.3203,  0.6496, -0.1607,  0.6739,  0.7484],
        [ 1.3364,  1.3733,  1.4237,  1.4106,  1.3857,  1.3472,  1.3145,  1.3358,
          1.3358,  1.2906,  1.4150,  1.3126,  1.4473,  1.3630,  1.4744,  1.2948,
          1.3578,  1.3468,  1.3906,  1.4151,  1.4279,  1.4030,  1.3602,  1.3503,
          1.2985,  1.3414,  1.3414,  1.4012,  1.4382,  1.3558,  1.1885,  1.3523,
          1.2439,  1.4128,  1.2359,  1.3600,  0.3402,  0.2670,  0.3905,  0.3494,
          0.1524,  0.1042,  0.3636,  0.1881, -0.0187,  2.6698,  1.9717,  2.5434,
          2.2213,  1.6362,  1.2850,  2.4771,  2.3269,  1.2512]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 122 : 176.74253086639823
Test loss for epoch 122 : 176.50001723154944
Test Precision for epoch 122 : 0.26153846153846155
Test Recall for epoch 122 : 0.26153846153846155
Test F1 for epoch 122 : 0.26153846153846155


theta for epoch 123 : tensor([[ 2.2057,  2.2226,  2.2607,  2.3287,  2.3103,  2.2103,  2.2957,  2.2054,
          2.2054,  1.3720,  1.3747,  1.3738,  1.3772,  1.3708,  1.3794,  1.3724,
          1.3705,  1.3322,  1.3284,  1.2877,  1.2884,  1.3294,  1.3262,  1.3256,
          1.3279,  1.3248,  1.3248,  1.3111,  1.3547,  1.3484,  1.3515,  1.3548,
          1.3499,  1.3525,  1.3053,  1.3487,  1.7493,  1.7607,  1.7528,  1.7499,
          1.7573,  1.6989,  1.7508,  1.7391,  1.7509,  1.6436,  1.6257,  1.6216,
          1.6150,  1.6386,  1.6203,  1.6552,  1.6129,  1.6132],
        [ 1.3347,  1.2901,  1.1825,  1.2933,  1.3767,  1.3750,  1.3244,  1.3741,
          1.3741,  2.0533,  2.0319,  1.9945,  2.2010,  2.0333,  2.9805,  2.0902,
          1.9710,  2.9072,  1.2978,  1.3394,  1.2733,  1.2588,  1.3838,  1.3856,
          1.3444,  1.3848,  1.3848,  1.3622,  1.2115,  1.4090,  1.4101,  1.2632,
          1.4108,  1.4134,  1.3750,  1.4089,  1.7852,  1.8085,  1.7515,  1.7340,
          1.7941,  1.8054,  1.7493,  1.3666,  1.7972,  1.5408,  1.6736,  1.6689,
          1.6617,  1.4869,  1.6675,  1.4987,  1.6594,  1.6598],
        [ 1.3188,  1.3215,  1.3253,  1.3234,  1.3215,  1.3196,  1.3170,  1.3188,
          1.3188,  1.3785,  1.3814,  1.3802,  1.3814,  1.3774,  1.3419,  1.3788,
          1.3622,  1.3362,  2.2877,  2.2717,  2.3516,  2.3120,  2.1989,  2.2134,
          2.2785,  2.1908,  2.1908,  1.3547,  1.3262,  1.3555,  1.3587,  1.3532,
          1.3571,  1.3600,  1.3553,  1.3559,  1.7541,  1.7657,  1.7577,  1.7459,
          1.7623,  1.7619,  1.7557,  1.6879,  1.7468,  1.6393,  1.6318,  1.6275,
          1.6208,  1.5902,  1.6263,  1.6412,  1.6187,  1.6190],
        [ 1.3295,  1.3323,  1.3303,  1.3283,  1.3324,  1.3303,  1.3303,  1.3295,
          1.3295,  1.3889,  1.3871,  1.3907,  1.3819,  1.3877,  1.2965,  1.3892,
          1.3871,  1.2868,  1.3460,  1.3360,  1.3479,  1.3470,  1.3437,  1.3418,
          1.3453,  1.3423,  1.3423,  2.3901,  2.3505,  2.1420,  2.2407,  2.3872,
          2.1507,  2.3483,  2.1639,  2.1436,  1.7606,  1.7721,  1.7486,  1.7601,
          1.7690,  1.7673,  1.7486,  1.6776,  1.7615,  1.6578,  1.6367,  1.5247,
          1.5724,  1.6524,  1.6258,  1.6704,  1.5702,  1.6258],
        [ 1.8026,  1.4179,  0.5616,  0.8565,  1.2548,  1.6987,  1.6080,  1.8062,
          1.8062,  1.6892,  1.2792,  1.4948,  0.8742,  1.7390,  0.1037,  1.6326,
          1.7971,  0.9173,  1.3115,  0.8822,  0.6725,  1.1371,  1.6414,  1.7155,
          1.4496,  1.8150,  1.8150,  0.7518,  0.8330,  1.7829,  1.5606,  0.8040,
          1.7249,  1.1911,  1.8319,  1.7470,  0.1886, -0.0994, -0.1343,  0.1356,
          0.4755,  0.6160,  0.0392,  8.4498,  6.0561,  0.1342,  0.5038,  0.5422,
          0.6477,  0.3170,  0.6470, -0.1640,  0.6714,  0.7459],
        [ 1.3389,  1.3759,  1.4261,  1.4131,  1.3881,  1.3496,  1.3172,  1.3383,
          1.3383,  1.2942,  1.4187,  1.3164,  1.4511,  1.3666,  1.4781,  1.2987,
          1.3613,  1.3510,  1.3942,  1.4185,  1.4315,  1.4066,  1.3638,  1.3539,
          1.3019,  1.3449,  1.3449,  1.4037,  1.4407,  1.3585,  1.1909,  1.3549,
          1.2465,  1.4154,  1.2385,  1.3626,  0.3439,  0.2708,  0.3942,  0.3530,
          0.1564,  0.1084,  0.3672,  0.1912, -0.0153,  2.6701,  1.9709,  2.5460,
          2.2205,  1.6347,  1.2832,  2.4757,  2.3296,  1.2494]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 123 : 176.7251480728201
Test loss for epoch 123 : 176.48867247917912
Test Precision for epoch 123 : 0.26153846153846155
Test Recall for epoch 123 : 0.26153846153846155
Test F1 for epoch 123 : 0.26153846153846155


theta for epoch 124 : tensor([[ 2.2088,  2.2258,  2.2639,  2.3322,  2.3138,  2.2135,  2.2991,  2.2086,
          2.2086,  1.3717,  1.3744,  1.3734,  1.3768,  1.3705,  1.3791,  1.3721,
          1.3702,  1.3319,  1.3281,  1.2874,  1.2882,  1.3291,  1.3259,  1.3253,
          1.3277,  1.3245,  1.3245,  1.3108,  1.3545,  1.3481,  1.3512,  1.3546,
          1.3496,  1.3523,  1.3050,  1.3484,  1.7489,  1.7602,  1.7524,  1.7495,
          1.7568,  1.6983,  1.7504,  1.7386,  1.7504,  1.6437,  1.6259,  1.6217,
          1.6151,  1.6387,  1.6204,  1.6553,  1.6130,  1.6133],
        [ 1.3334,  1.2905,  1.1826,  1.2920,  1.3752,  1.3734,  1.3238,  1.3726,
          1.3726,  2.0610,  2.0371,  2.0009,  2.2040,  2.0393,  2.9750,  2.0965,
          1.9782,  2.9041,  1.2981,  1.3394,  1.2743,  1.2590,  1.3827,  1.3845,
          1.3434,  1.3837,  1.3837,  1.3622,  1.2111,  1.4080,  1.4092,  1.2642,
          1.4097,  1.4124,  1.3741,  1.4079,  1.7850,  1.8079,  1.7511,  1.7341,
          1.7939,  1.8048,  1.7489,  1.3712,  1.7965,  1.5425,  1.6730,  1.6683,
          1.6609,  1.4882,  1.6669,  1.5007,  1.6587,  1.6590],
        [ 1.3180,  1.3206,  1.3244,  1.3225,  1.3207,  1.3188,  1.3162,  1.3179,
          1.3179,  1.3780,  1.3809,  1.3797,  1.3809,  1.3769,  1.3416,  1.3783,
          1.3614,  1.3364,  2.2910,  2.2749,  2.3544,  2.3148,  2.2025,  2.2166,
          2.2817,  2.1944,  2.1944,  1.3544,  1.3262,  1.3552,  1.3584,  1.3529,
          1.3568,  1.3597,  1.3550,  1.3556,  1.7536,  1.7652,  1.7572,  1.7453,
          1.7617,  1.7613,  1.7551,  1.6883,  1.7462,  1.6396,  1.6319,  1.6276,
          1.6209,  1.5911,  1.6264,  1.6415,  1.6187,  1.6190],
        [ 1.3287,  1.3315,  1.3297,  1.3277,  1.3316,  1.3295,  1.3294,  1.3287,
          1.3287,  1.3884,  1.3869,  1.3902,  1.3813,  1.3872,  1.2959,  1.3887,
          1.3866,  1.2864,  1.3455,  1.3352,  1.3473,  1.3464,  1.3432,  1.3413,
          1.3448,  1.3417,  1.3417,  2.3939,  2.3545,  2.1455,  2.2444,  2.3910,
          2.1541,  2.3518,  2.1676,  2.1470,  1.7601,  1.7716,  1.7480,  1.7597,
          1.7684,  1.7668,  1.7479,  1.6772,  1.7609,  1.6578,  1.6367,  1.5247,
          1.5723,  1.6524,  1.6260,  1.6703,  1.5701,  1.6257],
        [ 1.8053,  1.4200,  0.5654,  0.8604,  1.2584,  1.7017,  1.6103,  1.8091,
          1.8091,  1.6925,  1.2826,  1.4978,  0.8776,  1.7416,  0.1073,  1.6350,
          1.8005,  0.9196,  1.3143,  0.8862,  0.6761,  1.1402,  1.6449,  1.7187,
          1.4533,  1.8184,  1.8184,  0.7563,  0.8374,  1.7866,  1.5650,  0.8081,
          1.7287,  1.1956,  1.8356,  1.7508,  0.1812, -0.1059, -0.1408,  0.1285,
          0.4658,  0.6043,  0.0324,  8.5056,  6.0683,  0.1391,  0.5090,  0.5475,
          0.6531,  0.3217,  0.6523, -0.1591,  0.6768,  0.7513],
        [ 1.3357,  1.3728,  1.4230,  1.4100,  1.3850,  1.3464,  1.3139,  1.3351,
          1.3351,  1.2902,  1.4151,  1.3125,  1.4474,  1.3628,  1.4743,  1.2949,
          1.3573,  1.3475,  1.3901,  1.4142,  1.4275,  1.4025,  1.3596,  1.3498,
          1.2973,  1.3407,  1.3407,  1.4007,  1.4378,  1.3554,  1.1872,  1.3520,
          1.2434,  1.4125,  1.2352,  1.3596,  0.3401,  0.2670,  0.3904,  0.3492,
          0.1526,  0.1047,  0.3634,  0.1866, -0.0199,  2.6794,  1.9790,  2.5577,
          2.2288,  1.6420,  1.2903,  2.4833,  2.3413,  1.2564]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 124 : 176.70652986115428
Test loss for epoch 124 : 176.46568829272607
Test Precision for epoch 124 : 0.26153846153846155
Test Recall for epoch 124 : 0.26153846153846155
Test F1 for epoch 124 : 0.26153846153846155


theta for epoch 125 : tensor([[ 2.2123,  2.2294,  2.2675,  2.3360,  2.3176,  2.2169,  2.3029,  2.2120,
          2.2120,  1.3714,  1.3742,  1.3732,  1.3766,  1.3703,  1.3788,  1.3719,
          1.3699,  1.3317,  1.3280,  1.2873,  1.2881,  1.3290,  1.3258,  1.3252,
          1.3276,  1.3244,  1.3244,  1.3103,  1.3540,  1.3476,  1.3508,  1.3541,
          1.3492,  1.3519,  1.3045,  1.3480,  1.7489,  1.7602,  1.7524,  1.7495,
          1.7568,  1.6983,  1.7504,  1.7385,  1.7503,  1.6421,  1.6242,  1.6201,
          1.6135,  1.6372,  1.6188,  1.6538,  1.6114,  1.6117],
        [ 1.3322,  1.2910,  1.1826,  1.2907,  1.3739,  1.3720,  1.3234,  1.3711,
          1.3711,  2.0691,  2.0427,  2.0077,  2.2074,  2.0457,  2.9699,  2.1030,
          1.9858,  2.9015,  1.2985,  1.3395,  1.2754,  1.2594,  1.3820,  1.3836,
          1.3427,  1.3829,  1.3829,  1.3621,  1.2106,  1.4068,  1.4081,  1.2650,
          1.4085,  1.4112,  1.3731,  1.4068,  1.7853,  1.8077,  1.7512,  1.7347,
          1.7941,  1.8047,  1.7490,  1.3760,  1.7963,  1.5422,  1.6705,  1.6658,
          1.6585,  1.4876,  1.6644,  1.5008,  1.6562,  1.6566],
        [ 1.3172,  1.3199,  1.3237,  1.3218,  1.3199,  1.3180,  1.3155,  1.3171,
          1.3171,  1.3776,  1.3805,  1.3793,  1.3805,  1.3765,  1.3414,  1.3779,
          1.3608,  1.3367,  2.2949,  2.2785,  2.3578,  2.3181,  2.2067,  2.2203,
          2.2854,  2.1986,  2.1986,  1.3538,  1.3261,  1.3547,  1.3579,  1.3524,
          1.3563,  1.3592,  1.3545,  1.3550,  1.7536,  1.7651,  1.7571,  1.7452,
          1.7616,  1.7613,  1.7551,  1.6891,  1.7461,  1.6382,  1.6302,  1.6259,
          1.6192,  1.5901,  1.6247,  1.6399,  1.6170,  1.6173],
        [ 1.3280,  1.3307,  1.3292,  1.3272,  1.3308,  1.3288,  1.3287,  1.3279,
          1.3279,  1.3881,  1.3867,  1.3898,  1.3809,  1.3870,  1.2955,  1.3884,
          1.3863,  1.2862,  1.3452,  1.3348,  1.3471,  1.3461,  1.3428,  1.3410,
          1.3445,  1.3414,  1.3414,  2.3979,  2.3587,  2.1491,  2.2483,  2.3949,
          2.1577,  2.3554,  2.1715,  2.1506,  1.7601,  1.7716,  1.7479,  1.7598,
          1.7684,  1.7669,  1.7478,  1.6773,  1.7608,  1.6561,  1.6350,  1.5231,
          1.5706,  1.6507,  1.6246,  1.6686,  1.5684,  1.6240],
        [ 1.8050,  1.4183,  0.5642,  0.8600,  1.2580,  1.7015,  1.6093,  1.8090,
          1.8090,  1.6920,  1.2812,  1.4968,  0.8757,  1.7404,  0.1048,  1.6335,
          1.8003,  0.9163,  1.3127,  0.8851,  0.6740,  1.1385,  1.6445,  1.7182,
          1.4530,  1.8183,  1.8183,  0.7553,  0.8363,  1.7864,  1.5650,  0.8064,
          1.7284,  1.1950,  1.8355,  1.7505,  0.1786, -0.1080, -0.1428,  0.1262,
          0.4611,  0.5978,  0.0301,  8.5661,  6.0857,  0.1368,  0.5074,  0.5459,
          0.6515,  0.3194,  0.6506, -0.1614,  0.6753,  0.7496],
        [ 1.3375,  1.3748,  1.4247,  1.4117,  1.3867,  1.3482,  1.3158,  1.3369,
          1.3369,  1.2933,  1.4183,  1.3158,  1.4505,  1.3660,  1.4774,  1.2982,
          1.3604,  1.3511,  1.3931,  1.4170,  1.4303,  1.4055,  1.3624,  1.3528,
          1.3000,  1.3436,  1.3436,  1.4027,  1.4399,  1.3576,  1.1891,  1.3541,
          1.2456,  1.4147,  1.2374,  1.3618,  0.3432,  0.2703,  0.3935,  0.3523,
          0.1559,  0.1083,  0.3666,  0.1891, -0.0171,  2.6806,  1.9790,  2.5612,
          2.2289,  1.6413,  1.2894,  2.4829,  2.3449,  1.2554]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 125 : 176.68783401527872
Test loss for epoch 125 : 176.45213336217188
Test Precision for epoch 125 : 0.26153846153846155
Test Recall for epoch 125 : 0.26153846153846155
Test F1 for epoch 125 : 0.26153846153846155


theta for epoch 126 : tensor([[ 2.2162,  2.2334,  2.2715,  2.3402,  2.3219,  2.2208,  2.3071,  2.2159,
          2.2159,  1.3706,  1.3733,  1.3723,  1.3758,  1.3695,  1.3779,  1.3710,
          1.3691,  1.3308,  1.3272,  1.2865,  1.2873,  1.3282,  1.3249,  1.3244,
          1.3267,  1.3236,  1.3236,  1.3096,  1.3533,  1.3469,  1.3500,  1.3534,
          1.3485,  1.3511,  1.3038,  1.3472,  1.7484,  1.7596,  1.7519,  1.7490,
          1.7563,  1.6976,  1.7499,  1.7379,  1.7497,  1.6420,  1.6241,  1.6200,
          1.6134,  1.6371,  1.6187,  1.6536,  1.6113,  1.6116],
        [ 1.3313,  1.2917,  1.1829,  1.2897,  1.3727,  1.3708,  1.3232,  1.3699,
          1.3699,  2.0771,  2.0483,  2.0143,  2.2107,  2.0520,  2.9650,  2.1095,
          1.9933,  2.8990,  1.2983,  1.3389,  1.2758,  1.2591,  1.3805,  1.3821,
          1.3412,  1.3813,  1.3813,  1.3617,  1.2098,  1.4053,  1.4067,  1.2654,
          1.4071,  1.4098,  1.3719,  1.4054,  1.7850,  1.8070,  1.7507,  1.7347,
          1.7938,  1.8040,  1.7486,  1.3802,  1.7955,  1.5437,  1.6699,  1.6652,
          1.6577,  1.4888,  1.6637,  1.5026,  1.6555,  1.6558],
        [ 1.3167,  1.3193,  1.3232,  1.3212,  1.3193,  1.3174,  1.3150,  1.3166,
          1.3166,  1.3766,  1.3795,  1.3783,  1.3796,  1.3755,  1.3406,  1.3770,
          1.3597,  1.3364,  2.2987,  2.2822,  2.3611,  2.3214,  2.2109,  2.2239,
          2.2890,  2.2028,  2.2028,  1.3530,  1.3256,  1.3539,  1.3571,  1.3516,
          1.3555,  1.3584,  1.3537,  1.3543,  1.7530,  1.7645,  1.7565,  1.7446,
          1.7610,  1.7607,  1.7545,  1.6895,  1.7455,  1.6382,  1.6300,  1.6257,
          1.6190,  1.5907,  1.6245,  1.6399,  1.6168,  1.6172],
        [ 1.3275,  1.3303,  1.3289,  1.3269,  1.3304,  1.3283,  1.3283,  1.3275,
          1.3275,  1.3873,  1.3861,  1.3890,  1.3800,  1.3862,  1.2946,  1.3876,
          1.3856,  1.2855,  1.3444,  1.3337,  1.3462,  1.3453,  1.3420,  1.3402,
          1.3436,  1.3406,  1.3406,  2.4018,  2.3627,  2.1526,  2.2521,  2.3988,
          2.1613,  2.3590,  2.1753,  2.1542,  1.7596,  1.7711,  1.7472,  1.7593,
          1.7679,  1.7664,  1.7470,  1.6768,  1.7602,  1.6559,  1.6349,  1.5230,
          1.5704,  1.6506,  1.6246,  1.6685,  1.5682,  1.6237],
        [ 1.8076,  1.4203,  0.5676,  0.8636,  1.2615,  1.7045,  1.6115,  1.8118,
          1.8118,  1.6946,  1.2840,  1.4991,  0.8785,  1.7424,  0.1077,  1.6353,
          1.8031,  0.9180,  1.3150,  0.8884,  0.6768,  1.1410,  1.6473,  1.7208,
          1.4561,  1.8211,  1.8211,  0.7591,  0.8399,  1.7895,  1.5686,  0.8097,
          1.7315,  1.1987,  1.8385,  1.7537,  0.1719, -0.1139, -0.1486,  0.1199,
          0.4523,  0.5873,  0.0239,  8.6224,  6.0976,  0.1409,  0.5118,  0.5505,
          0.6560,  0.3233,  0.6551, -0.1574,  0.6798,  0.7541],
        [ 1.3356,  1.3731,  1.4229,  1.4100,  1.3849,  1.3464,  1.3140,  1.3350,
          1.3350,  1.2907,  1.4160,  1.3133,  1.4482,  1.3636,  1.4749,  1.2958,
          1.3578,  1.3489,  1.3903,  1.4140,  1.4275,  1.4027,  1.3596,  1.3500,
          1.2968,  1.3407,  1.3407,  1.4005,  1.4378,  1.3554,  1.1863,  1.3521,
          1.2434,  1.4126,  1.2351,  1.3597,  0.3409,  0.2680,  0.3912,  0.3499,
          0.1536,  0.1061,  0.3642,  0.1859, -0.0201,  2.6884,  1.9856,  2.5713,
          2.2355,  1.6471,  1.2949,  2.4889,  2.3551,  1.2609]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 126 : 176.669228947276
Test loss for epoch 126 : 176.43080367597756
Test Precision for epoch 126 : 0.26153846153846155
Test Recall for epoch 126 : 0.26153846153846155
Test F1 for epoch 126 : 0.26153846153846155


theta for epoch 127 : tensor([[ 2.2202,  2.2375,  2.2756,  2.3446,  2.3263,  2.2249,  2.3115,  2.2200,
          2.2200,  1.3698,  1.3725,  1.3715,  1.3749,  1.3687,  1.3771,  1.3702,
          1.3683,  1.3300,  1.3265,  1.2858,  1.2867,  1.3275,  1.3243,  1.3237,
          1.3261,  1.3229,  1.3229,  1.3088,  1.3525,  1.3461,  1.3492,  1.3526,
          1.3476,  1.3503,  1.3029,  1.3464,  1.7481,  1.7593,  1.7516,  1.7487,
          1.7560,  1.6972,  1.7496,  1.7375,  1.7494,  1.6410,  1.6231,  1.6189,
          1.6123,  1.6360,  1.6177,  1.6526,  1.6102,  1.6105],
        [ 1.3305,  1.2926,  1.1832,  1.2888,  1.3717,  1.3697,  1.3231,  1.3689,
          1.3689,  2.0850,  2.0539,  2.0208,  2.2141,  2.0582,  2.9603,  2.1159,
          2.0007,  2.8965,  1.2984,  1.3387,  1.2764,  1.2591,  1.3795,  1.3810,
          1.3401,  1.3802,  1.3802,  1.3612,  1.2091,  1.4039,  1.4053,  1.2658,
          1.4057,  1.4084,  1.3706,  1.4040,  1.7850,  1.8065,  1.7505,  1.7350,
          1.7938,  1.8036,  1.7484,  1.3845,  1.7950,  1.5443,  1.6684,  1.6637,
          1.6562,  1.4890,  1.6622,  1.5035,  1.6540,  1.6543],
        [ 1.3162,  1.3189,  1.3227,  1.3208,  1.3189,  1.3170,  1.3146,  1.3161,
          1.3161,  1.3757,  1.3785,  1.3773,  1.3787,  1.3746,  1.3399,  1.3760,
          1.3585,  1.3361,  2.3029,  2.2861,  2.3647,  2.3250,  2.2154,  2.2280,
          2.2930,  2.2073,  2.2073,  1.3520,  1.3251,  1.3530,  1.3562,  1.3507,
          1.3546,  1.3575,  1.3528,  1.3534,  1.7526,  1.7641,  1.7562,  1.7441,
          1.7606,  1.7603,  1.7541,  1.6900,  1.7450,  1.6374,  1.6288,  1.6246,
          1.6178,  1.5903,  1.6234,  1.6389,  1.6157,  1.6160],
        [ 1.3271,  1.3299,  1.3287,  1.3268,  1.3300,  1.3279,  1.3279,  1.3271,
          1.3271,  1.3866,  1.3855,  1.3883,  1.3791,  1.3855,  1.2938,  1.3869,
          1.3848,  1.2848,  1.3438,  1.3330,  1.3457,  1.3447,  1.3414,  1.3396,
          1.3430,  1.3400,  1.3400,  2.4057,  2.3668,  2.1561,  2.2559,  2.4028,
          2.1648,  2.3626,  2.1791,  2.1577,  1.7594,  1.7708,  1.7468,  1.7591,
          1.7676,  1.7662,  1.7466,  1.6767,  1.7598,  1.6549,  1.6340,  1.5221,
          1.5694,  1.6496,  1.6239,  1.6674,  1.5672,  1.6227],
        [ 1.8083,  1.4198,  0.5679,  0.8643,  1.2623,  1.7054,  1.6116,  1.8128,
          1.8128,  1.6948,  1.2836,  1.4988,  0.8778,  1.7419,  0.1066,  1.6346,
          1.8036,  0.9160,  1.3144,  0.8885,  0.6760,  1.1403,  1.6477,  1.7210,
          1.4565,  1.8216,  1.8216,  0.7592,  0.8398,  1.7900,  1.5694,  0.8092,
          1.7319,  1.1990,  1.8391,  1.7542,  0.1683, -0.1169, -0.1515,  0.1166,
          0.4469,  0.5801,  0.0207,  8.6816,  6.1127,  0.1405,  0.5120,  0.5506,
          0.6561,  0.3228,  0.6551, -0.1579,  0.6800,  0.7542],
        [ 1.3370,  1.3745,  1.4242,  1.4113,  1.3862,  1.3477,  1.3155,  1.3364,
          1.3364,  1.2925,  1.4179,  1.3153,  1.4500,  1.3655,  1.4768,  1.2978,
          1.3596,  1.3511,  1.3920,  1.4154,  1.4292,  1.4044,  1.3612,  1.3518,
          1.2982,  1.3424,  1.3424,  1.4015,  1.4388,  1.3565,  1.1872,  1.3532,
          1.2446,  1.4137,  1.2362,  1.3608,  0.3428,  0.2701,  0.3931,  0.3519,
          0.1557,  0.1084,  0.3662,  0.1872, -0.0186,  2.6911,  1.9871,  2.5763,
          2.2371,  1.6478,  1.2953,  2.4899,  2.3601,  1.2613]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 127 : 176.65134666664187
Test loss for epoch 127 : 176.41625968060293
Test Precision for epoch 127 : 0.26153846153846155
Test Recall for epoch 127 : 0.26153846153846155
Test F1 for epoch 127 : 0.26153846153846155


theta for epoch 128 : tensor([[ 2.2238,  2.2412,  2.2793,  2.3485,  2.3302,  2.2285,  2.3154,  2.2236,
          2.2236,  1.3693,  1.3720,  1.3710,  1.3744,  1.3682,  1.3766,  1.3698,
          1.3678,  1.3296,  1.3260,  1.2854,  1.2862,  1.3271,  1.3238,  1.3233,
          1.3256,  1.3225,  1.3225,  1.3082,  1.3519,  1.3455,  1.3486,  1.3520,
          1.3471,  1.3497,  1.3024,  1.3458,  1.7476,  1.7588,  1.7511,  1.7482,
          1.7555,  1.6967,  1.7491,  1.7370,  1.7488,  1.6408,  1.6229,  1.6187,
          1.6121,  1.6358,  1.6174,  1.6523,  1.6100,  1.6103],
        [ 1.3295,  1.2932,  1.1834,  1.2877,  1.3705,  1.3685,  1.3229,  1.3676,
          1.3676,  2.0928,  2.0594,  2.0271,  2.2173,  2.0642,  2.9556,  2.1221,
          2.0080,  2.8939,  1.2985,  1.3384,  1.2769,  1.2592,  1.3785,  1.3799,
          1.3391,  1.3791,  1.3791,  1.3610,  1.2086,  1.4027,  1.4042,  1.2663,
          1.4045,  1.4072,  1.3696,  1.4028,  1.7847,  1.8059,  1.7501,  1.7350,
          1.7935,  1.8030,  1.7480,  1.3884,  1.7943,  1.5457,  1.6677,  1.6630,
          1.6556,  1.4901,  1.6616,  1.5052,  1.6533,  1.6536],
        [ 1.3155,  1.3182,  1.3221,  1.3201,  1.3182,  1.3163,  1.3140,  1.3154,
          1.3154,  1.3750,  1.3779,  1.3767,  1.3781,  1.3740,  1.3395,  1.3754,
          1.3576,  1.3362,  2.3067,  2.2898,  2.3680,  2.3283,  2.2196,  2.2317,
          2.2967,  2.2115,  2.2115,  1.3512,  1.3248,  1.3523,  1.3556,  1.3500,
          1.3540,  1.3568,  1.3522,  1.3527,  1.7520,  1.7635,  1.7556,  1.7435,
          1.7600,  1.7597,  1.7536,  1.6904,  1.7444,  1.6372,  1.6284,  1.6242,
          1.6175,  1.5906,  1.6230,  1.6387,  1.6153,  1.6156],
        [ 1.3265,  1.3293,  1.3283,  1.3263,  1.3294,  1.3273,  1.3273,  1.3264,
          1.3264,  1.3861,  1.3851,  1.3877,  1.3784,  1.3850,  1.2932,  1.3864,
          1.3843,  1.2843,  1.3432,  1.3322,  1.3451,  1.3442,  1.3408,  1.3391,
          1.3424,  1.3394,  1.3394,  2.4097,  2.3709,  2.1597,  2.2597,  2.4068,
          2.1683,  2.3662,  2.1830,  2.1612,  1.7589,  1.7703,  1.7461,  1.7586,
          1.7670,  1.7658,  1.7458,  1.6763,  1.7593,  1.6545,  1.6337,  1.5218,
          1.5691,  1.6492,  1.6238,  1.6670,  1.5668,  1.6223],
        [ 1.8099,  1.4207,  0.5700,  0.8667,  1.2646,  1.7073,  1.6129,  1.8146,
          1.8146,  1.6965,  1.2853,  1.5003,  0.8794,  1.7429,  0.1081,  1.6355,
          1.8056,  0.9164,  1.3156,  0.8906,  0.6776,  1.1416,  1.6496,  1.7227,
          1.4586,  1.8234,  1.8234,  0.7617,  0.8420,  1.7922,  1.5720,  0.8112,
          1.7341,  1.2014,  1.8413,  1.7564,  0.1629, -0.1217, -0.1561,  0.1115,
          0.4396,  0.5712,  0.0157,  8.7389,  6.1250,  0.1431,  0.5149,  0.5536,
          0.6591,  0.3252,  0.6580, -0.1554,  0.6829,  0.7570],
        [ 1.3360,  1.3737,  1.4233,  1.4103,  1.3853,  1.3467,  1.3145,  1.3353,
          1.3353,  1.2915,  1.4171,  1.3144,  1.4491,  1.3647,  1.4758,  1.2970,
          1.3586,  1.3504,  1.3907,  1.4139,  1.4279,  1.4031,  1.3599,  1.3505,
          1.2965,  1.3410,  1.3410,  1.4004,  1.4378,  1.3555,  1.1857,  1.3522,
          1.2435,  1.4126,  1.2351,  1.3598,  0.3419,  0.2692,  0.3922,  0.3509,
          0.1548,  0.1077,  0.3653,  0.1855, -0.0202,  2.6973,  1.9920,  2.5848,
          2.2422,  1.6519,  1.2992,  2.4944,  2.3686,  1.2651]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 128 : 176.63414982753173
Test loss for epoch 128 : 176.3984567941741
Test Precision for epoch 128 : 0.26153846153846155
Test Recall for epoch 128 : 0.26153846153846155
Test F1 for epoch 128 : 0.26153846153846155


theta for epoch 129 : tensor([[ 2.2271,  2.2446,  2.2827,  2.3521,  2.3338,  2.2318,  2.3190,  2.2269,
          2.2269,  1.3692,  1.3719,  1.3709,  1.3743,  1.3681,  1.3764,  1.3696,
          1.3677,  1.3294,  1.3259,  1.2852,  1.2861,  1.3270,  1.3237,  1.3231,
          1.3255,  1.3223,  1.3223,  1.3079,  1.3516,  1.3452,  1.3483,  1.3517,
          1.3468,  1.3494,  1.3021,  1.3455,  1.7473,  1.7585,  1.7508,  1.7479,
          1.7551,  1.6963,  1.7488,  1.7366,  1.7485,  1.6400,  1.6221,  1.6179,
          1.6114,  1.6351,  1.6167,  1.6516,  1.6092,  1.6095],
        [ 1.3285,  1.2938,  1.1834,  1.2866,  1.3692,  1.3671,  1.3225,  1.3663,
          1.3663,  2.1004,  2.0649,  2.0332,  2.2206,  2.0701,  2.9510,  2.1281,
          2.0151,  2.8914,  1.2989,  1.3385,  1.2777,  1.2595,  1.3778,  1.3791,
          1.3384,  1.3783,  1.3783,  1.3609,  1.2084,  1.4017,  1.4033,  1.2670,
          1.4035,  1.4062,  1.3688,  1.4018,  1.7846,  1.8053,  1.7498,  1.7353,
          1.7934,  1.8025,  1.7477,  1.3924,  1.7937,  1.5466,  1.6665,  1.6618,
          1.6544,  1.4906,  1.6604,  1.5063,  1.6521,  1.6524],
        [ 1.3147,  1.3175,  1.3213,  1.3194,  1.3174,  1.3155,  1.3133,  1.3147,
          1.3147,  1.3748,  1.3776,  1.3764,  1.3780,  1.3737,  1.3395,  1.3752,
          1.3572,  1.3366,  2.3103,  2.2934,  2.3712,  2.3314,  2.2236,  2.2352,
          2.3001,  2.2155,  2.2155,  1.3507,  1.3247,  1.3519,  1.3551,  1.3496,
          1.3535,  1.3563,  1.3517,  1.3522,  1.7516,  1.7630,  1.7552,  1.7430,
          1.7596,  1.7593,  1.7532,  1.6909,  1.7439,  1.6366,  1.6275,  1.6232,
          1.6165,  1.5904,  1.6220,  1.6379,  1.6143,  1.6146],
        [ 1.3257,  1.3286,  1.3278,  1.3258,  1.3287,  1.3265,  1.3265,  1.3257,
          1.3257,  1.3858,  1.3850,  1.3875,  1.3780,  1.3847,  1.2928,  1.3862,
          1.3840,  1.2841,  1.3428,  1.3317,  1.3448,  1.3438,  1.3404,  1.3387,
          1.3421,  1.3390,  1.3390,  2.4138,  2.3750,  2.1632,  2.2635,  2.4109,
          2.1719,  2.3699,  2.1868,  2.1648,  1.7585,  1.7700,  1.7455,  1.7583,
          1.7666,  1.7655,  1.7452,  1.6760,  1.7588,  1.6536,  1.6328,  1.5210,
          1.5682,  1.6483,  1.6231,  1.6661,  1.5659,  1.6213],
        [ 1.8107,  1.4206,  0.5709,  0.8680,  1.2658,  1.7084,  1.6132,  1.8157,
          1.8157,  1.6975,  1.2860,  1.5008,  0.8798,  1.7432,  0.1083,  1.6357,
          1.8068,  0.9157,  1.3158,  0.8916,  0.6778,  1.1418,  1.6506,  1.7235,
          1.4597,  1.8245,  1.8245,  0.7630,  0.8430,  1.7936,  1.5737,  0.8120,
          1.7354,  1.2028,  1.8427,  1.7579,  0.1587, -0.1253, -0.1597,  0.1076,
          0.4336,  0.5637,  0.0118,  8.7972,  6.1381,  0.1440,  0.5162,  0.5549,
          0.6603,  0.3259,  0.6591, -0.1546,  0.6842,  0.7582],
        [ 1.3358,  1.3736,  1.4231,  1.4101,  1.3850,  1.3464,  1.3144,  1.3351,
          1.3351,  1.2919,  1.4177,  1.3149,  1.4496,  1.3653,  1.4762,  1.2976,
          1.3590,  1.3511,  1.3908,  1.4138,  1.4279,  1.4032,  1.3599,  1.3506,
          1.2963,  1.3410,  1.3410,  1.4004,  1.4378,  1.3556,  1.1854,  1.3524,
          1.2437,  1.4127,  1.2351,  1.3599,  0.3423,  0.2696,  0.3926,  0.3513,
          0.1553,  0.1083,  0.3657,  0.1851, -0.0204,  2.7020,  1.9954,  2.5917,
          2.2457,  1.6545,  1.3015,  2.4973,  2.3756,  1.2673]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 129 : 176.6176412367509
Test loss for epoch 129 : 176.38335817642655
Test Precision for epoch 129 : 0.26153846153846155
Test Recall for epoch 129 : 0.26153846153846155
Test F1 for epoch 129 : 0.26153846153846155


theta for epoch 130 : tensor([[ 2.2307e+00,  2.2482e+00,  2.2863e+00,  2.3560e+00,  2.3377e+00,
          2.2354e+00,  2.3229e+00,  2.2304e+00,  2.2304e+00,  1.3688e+00,
          1.3715e+00,  1.3705e+00,  1.3739e+00,  1.3678e+00,  1.3760e+00,
          1.3693e+00,  1.3673e+00,  1.3291e+00,  1.3257e+00,  1.2850e+00,
          1.2859e+00,  1.3267e+00,  1.3235e+00,  1.3229e+00,  1.3253e+00,
          1.3221e+00,  1.3221e+00,  1.3076e+00,  1.3512e+00,  1.3448e+00,
          1.3480e+00,  1.3514e+00,  1.3464e+00,  1.3491e+00,  1.3017e+00,
          1.3452e+00,  1.7470e+00,  1.7582e+00,  1.7506e+00,  1.7476e+00,
          1.7548e+00,  1.6960e+00,  1.7485e+00,  1.7362e+00,  1.7481e+00,
          1.6390e+00,  1.6211e+00,  1.6169e+00,  1.6103e+00,  1.6341e+00,
          1.6157e+00,  1.6505e+00,  1.6082e+00,  1.6085e+00],
        [ 1.3277e+00,  1.2946e+00,  1.1837e+00,  1.2857e+00,  1.3682e+00,
          1.3660e+00,  1.3223e+00,  1.3651e+00,  1.3651e+00,  2.1079e+00,
          2.0703e+00,  2.0392e+00,  2.2238e+00,  2.0759e+00,  2.9466e+00,
          2.1340e+00,  2.0222e+00,  2.8889e+00,  1.2993e+00,  1.3386e+00,
          1.2784e+00,  1.2599e+00,  1.3771e+00,  1.3784e+00,  1.3377e+00,
          1.3775e+00,  1.3775e+00,  1.3609e+00,  1.2082e+00,  1.4008e+00,
          1.4024e+00,  1.2677e+00,  1.4026e+00,  1.4053e+00,  1.3681e+00,
          1.4009e+00,  1.7845e+00,  1.8048e+00,  1.7495e+00,  1.7355e+00,
          1.7933e+00,  1.8020e+00,  1.7474e+00,  1.3963e+00,  1.7931e+00,
          1.5471e+00,  1.6652e+00,  1.6605e+00,  1.6530e+00,  1.4909e+00,
          1.6590e+00,  1.5072e+00,  1.6507e+00,  1.6511e+00],
        [ 1.3142e+00,  1.3170e+00,  1.3208e+00,  1.3189e+00,  1.3169e+00,
          1.3150e+00,  1.3129e+00,  1.3141e+00,  1.3141e+00,  1.3744e+00,
          1.3772e+00,  1.3761e+00,  1.3777e+00,  1.3733e+00,  1.3394e+00,
          1.3748e+00,  1.3566e+00,  1.3369e+00,  2.3139e+00,  2.2969e+00,
          2.3743e+00,  2.3345e+00,  2.2275e+00,  2.2388e+00,  2.3036e+00,
          2.2194e+00,  2.2194e+00,  1.3502e+00,  1.3246e+00,  1.3515e+00,
          1.3547e+00,  1.3491e+00,  1.3531e+00,  1.3559e+00,  1.3513e+00,
          1.3518e+00,  1.7513e+00,  1.7627e+00,  1.7549e+00,  1.7426e+00,
          1.7592e+00,  1.7590e+00,  1.7528e+00,  1.6915e+00,  1.7434e+00,
          1.6357e+00,  1.6263e+00,  1.6221e+00,  1.6153e+00,  1.5900e+00,
          1.6209e+00,  1.6368e+00,  1.6131e+00,  1.6135e+00],
        [ 1.3252e+00,  1.3281e+00,  1.3274e+00,  1.3255e+00,  1.3281e+00,
          1.3260e+00,  1.3260e+00,  1.3252e+00,  1.3252e+00,  1.3854e+00,
          1.3847e+00,  1.3871e+00,  1.3775e+00,  1.3844e+00,  1.2924e+00,
          1.3858e+00,  1.3836e+00,  1.2837e+00,  1.3425e+00,  1.3312e+00,
          1.3445e+00,  1.3435e+00,  1.3401e+00,  1.3384e+00,  1.3418e+00,
          1.3387e+00,  1.3387e+00,  2.4178e+00,  2.3790e+00,  2.1667e+00,
          2.2673e+00,  2.4149e+00,  2.1754e+00,  2.3735e+00,  2.1907e+00,
          2.1683e+00,  1.7582e+00,  1.7697e+00,  1.7450e+00,  1.7580e+00,
          1.7663e+00,  1.7652e+00,  1.7447e+00,  1.6759e+00,  1.7584e+00,
          1.6525e+00,  1.6318e+00,  1.5201e+00,  1.5671e+00,  1.6472e+00,
          1.6222e+00,  1.6649e+00,  1.5648e+00,  1.6202e+00],
        [ 1.8117e+00,  1.4208e+00,  5.7201e-01,  8.6949e-01,  1.2672e+00,
          1.7097e+00,  1.6138e+00,  1.8169e+00,  1.8169e+00,  1.6985e+00,
          1.2867e+00,  1.5014e+00,  8.8036e-01,  1.7435e+00,  1.0853e-01,
          1.6359e+00,  1.8080e+00,  9.1501e-01,  1.3162e+00,  8.9264e-01,
          6.7826e-01,  1.1421e+00,  1.6517e+00,  1.7244e+00,  1.4609e+00,
          1.8256e+00,  1.8256e+00,  7.6433e-01,  8.4406e-01,  1.7951e+00,
          1.5754e+00,  8.1288e-01,  1.7369e+00,  1.2043e+00,  1.8442e+00,
          1.7594e+00,  1.5441e-01, -1.2900e-01, -1.6333e-01,  1.0367e-01,
          4.2775e-01,  5.5638e-01,  7.9298e-03,  8.8553e+00,  6.1507e+00,
          1.4498e-01,  5.1750e-01,  5.5621e-01,  6.6143e-01,  3.2675e-01,
          6.6027e-01, -1.5372e-01,  6.8544e-01,  7.5925e-01],
        [ 1.3357e+00,  1.3736e+00,  1.4230e+00,  1.4101e+00,  1.3849e+00,
          1.3463e+00,  1.3144e+00,  1.3350e+00,  1.3350e+00,  1.2922e+00,
          1.4180e+00,  1.3152e+00,  1.4499e+00,  1.3657e+00,  1.4765e+00,
          1.2981e+00,  1.3593e+00,  1.3517e+00,  1.3908e+00,  1.4136e+00,
          1.4279e+00,  1.4032e+00,  1.3598e+00,  1.3506e+00,  1.2960e+00,
          1.3410e+00,  1.3410e+00,  1.4003e+00,  1.4378e+00,  1.3556e+00,
          1.1850e+00,  1.3524e+00,  1.2437e+00,  1.4126e+00,  1.2351e+00,
          1.3599e+00,  3.4264e-01,  2.7000e-01,  3.9292e-01,  3.5159e-01,
          1.5566e-01,  1.0878e-01,  3.6609e-01,  1.8469e-01, -2.0612e-02,
          2.7068e+00,  1.9988e+00,  2.5987e+00,  2.2492e+00,  1.6572e+00,
          1.3038e+00,  2.5004e+00,  2.3827e+00,  1.2696e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 130 : 176.60173724474186
Test loss for epoch 130 : 176.36878958770447
Test Precision for epoch 130 : 0.26153846153846155
Test Recall for epoch 130 : 0.26153846153846155
Test F1 for epoch 130 : 0.26153846153846155


theta for epoch 131 : tensor([[ 2.2346e+00,  2.2522e+00,  2.2903e+00,  2.3602e+00,  2.3419e+00,
          2.2393e+00,  2.3271e+00,  2.2343e+00,  2.2343e+00,  1.3681e+00,
          1.3708e+00,  1.3698e+00,  1.3732e+00,  1.3671e+00,  1.3753e+00,
          1.3686e+00,  1.3666e+00,  1.3284e+00,  1.3252e+00,  1.2845e+00,
          1.2853e+00,  1.3262e+00,  1.3229e+00,  1.3223e+00,  1.3247e+00,
          1.3215e+00,  1.3215e+00,  1.3070e+00,  1.3506e+00,  1.3442e+00,
          1.3474e+00,  1.3508e+00,  1.3458e+00,  1.3485e+00,  1.3011e+00,
          1.3446e+00,  1.7467e+00,  1.7578e+00,  1.7502e+00,  1.7472e+00,
          1.7545e+00,  1.6956e+00,  1.7482e+00,  1.7358e+00,  1.7477e+00,
          1.6383e+00,  1.6204e+00,  1.6162e+00,  1.6096e+00,  1.6333e+00,
          1.6149e+00,  1.6498e+00,  1.6074e+00,  1.6078e+00],
        [ 1.3272e+00,  1.2955e+00,  1.1842e+00,  1.2850e+00,  1.3673e+00,
          1.3651e+00,  1.3223e+00,  1.3642e+00,  1.3642e+00,  2.1155e+00,
          2.0759e+00,  2.0452e+00,  2.2271e+00,  2.0817e+00,  2.9424e+00,
          2.1400e+00,  2.0292e+00,  2.8866e+00,  1.2995e+00,  1.3383e+00,
          1.2788e+00,  1.2600e+00,  1.3762e+00,  1.3774e+00,  1.3368e+00,
          1.3765e+00,  1.3765e+00,  1.3606e+00,  1.2078e+00,  1.3996e+00,
          1.4013e+00,  1.2681e+00,  1.4014e+00,  1.4041e+00,  1.3671e+00,
          1.3997e+00,  1.7843e+00,  1.8042e+00,  1.7492e+00,  1.7357e+00,
          1.7931e+00,  1.8015e+00,  1.7471e+00,  1.4000e+00,  1.7924e+00,
          1.5480e+00,  1.6642e+00,  1.6595e+00,  1.6521e+00,  1.4914e+00,
          1.6580e+00,  1.5084e+00,  1.6498e+00,  1.6501e+00],
        [ 1.3139e+00,  1.3167e+00,  1.3205e+00,  1.3186e+00,  1.3166e+00,
          1.3147e+00,  1.3126e+00,  1.3138e+00,  1.3138e+00,  1.3737e+00,
          1.3765e+00,  1.3754e+00,  1.3770e+00,  1.3726e+00,  1.3390e+00,
          1.3741e+00,  1.3556e+00,  1.3368e+00,  2.3176e+00,  2.3005e+00,
          2.3776e+00,  2.3377e+00,  2.2316e+00,  2.2424e+00,  2.3071e+00,
          2.2235e+00,  2.2235e+00,  1.3495e+00,  1.3243e+00,  1.3508e+00,
          1.3540e+00,  1.3485e+00,  1.3524e+00,  1.3552e+00,  1.3506e+00,
          1.3511e+00,  1.7509e+00,  1.7622e+00,  1.7545e+00,  1.7421e+00,
          1.7588e+00,  1.7585e+00,  1.7524e+00,  1.6920e+00,  1.7429e+00,
          1.6351e+00,  1.6254e+00,  1.6212e+00,  1.6145e+00,  1.5899e+00,
          1.6200e+00,  1.6361e+00,  1.6122e+00,  1.6126e+00],
        [ 1.3249e+00,  1.3278e+00,  1.3273e+00,  1.3254e+00,  1.3279e+00,
          1.3257e+00,  1.3258e+00,  1.3249e+00,  1.3249e+00,  1.3848e+00,
          1.3842e+00,  1.3864e+00,  1.3767e+00,  1.3837e+00,  1.2917e+00,
          1.3852e+00,  1.3830e+00,  1.2831e+00,  1.3421e+00,  1.3306e+00,
          1.3441e+00,  1.3431e+00,  1.3397e+00,  1.3379e+00,  1.3413e+00,
          1.3382e+00,  1.3382e+00,  2.4218e+00,  2.3830e+00,  2.1701e+00,
          2.2709e+00,  2.4189e+00,  2.1788e+00,  2.3771e+00,  2.1944e+00,
          2.1717e+00,  1.7579e+00,  1.7693e+00,  1.7445e+00,  1.7577e+00,
          1.7659e+00,  1.7649e+00,  1.7441e+00,  1.6757e+00,  1.7580e+00,
          1.6518e+00,  1.6311e+00,  1.5195e+00,  1.5664e+00,  1.6465e+00,
          1.6217e+00,  1.6641e+00,  1.5641e+00,  1.6194e+00],
        [ 1.8134e+00,  1.4219e+00,  5.7420e-01,  8.7194e-01,  1.2696e+00,
          1.7118e+00,  1.6152e+00,  1.8189e+00,  1.8189e+00,  1.7000e+00,
          1.2883e+00,  1.5027e+00,  8.8189e-01,  1.7443e+00,  1.0996e-01,
          1.6368e+00,  1.8098e+00,  9.1539e-01,  1.3174e+00,  8.9470e-01,
          6.7980e-01,  1.1433e+00,  1.6535e+00,  1.7260e+00,  1.4628e+00,
          1.8273e+00,  1.8273e+00,  7.6669e-01,  8.4608e-01,  1.7973e+00,
          1.5778e+00,  8.1486e-01,  1.7389e+00,  1.2066e+00,  1.8464e+00,
          1.7616e+00,  1.4935e-01, -1.3344e-01, -1.6769e-01,  9.8947e-02,
          4.2111e-01,  5.4834e-01,  3.2342e-03,  8.9125e+00,  6.1617e+00,
          1.4739e-01,  5.2013e-01,  5.5885e-01,  6.6391e-01,  3.2893e-01,
          6.6270e-01, -1.5138e-01,  6.8797e-01,  7.6162e-01],
        [ 1.3351e+00,  1.3731e+00,  1.4224e+00,  1.4094e+00,  1.3843e+00,
          1.3456e+00,  1.3138e+00,  1.3343e+00,  1.3343e+00,  1.2913e+00,
          1.4172e+00,  1.3144e+00,  1.4491e+00,  1.3649e+00,  1.4755e+00,
          1.2973e+00,  1.3583e+00,  1.3510e+00,  1.3897e+00,  1.4122e+00,
          1.4268e+00,  1.4021e+00,  1.3587e+00,  1.3495e+00,  1.2945e+00,
          1.3398e+00,  1.3398e+00,  1.3992e+00,  1.4369e+00,  1.3546e+00,
          1.1837e+00,  1.3516e+00,  1.2428e+00,  1.4117e+00,  1.2341e+00,
          1.3590e+00,  3.4193e-01,  2.6930e-01,  3.9221e-01,  3.5085e-01,
          1.5492e-01,  1.0818e-01,  3.6541e-01,  1.8317e-01, -2.2004e-02,
          2.7129e+00,  2.0036e+00,  2.6071e+00,  2.2541e+00,  1.6611e+00,
          1.3074e+00,  2.5047e+00,  2.3910e+00,  1.2731e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 131 : 176.58626543975586
Test loss for epoch 131 : 176.3530285956517
Test Precision for epoch 131 : 0.26153846153846155
Test Recall for epoch 131 : 0.26153846153846155
Test F1 for epoch 131 : 0.26153846153846155


theta for epoch 132 : tensor([[ 2.2385e+00,  2.2562e+00,  2.2942e+00,  2.3644e+00,  2.3461e+00,
          2.2432e+00,  2.3313e+00,  2.2382e+00,  2.2382e+00,  1.3675e+00,
          1.3702e+00,  1.3691e+00,  1.3726e+00,  1.3664e+00,  1.3746e+00,
          1.3679e+00,  1.3660e+00,  1.3278e+00,  1.3247e+00,  1.2840e+00,
          1.2848e+00,  1.3257e+00,  1.3224e+00,  1.3218e+00,  1.3242e+00,
          1.3210e+00,  1.3210e+00,  1.3063e+00,  1.3500e+00,  1.3436e+00,
          1.3467e+00,  1.3501e+00,  1.3451e+00,  1.3478e+00,  1.3005e+00,
          1.3439e+00,  1.7465e+00,  1.7576e+00,  1.7500e+00,  1.7471e+00,
          1.7543e+00,  1.6953e+00,  1.7480e+00,  1.7356e+00,  1.7475e+00,
          1.6372e+00,  1.6193e+00,  1.6151e+00,  1.6086e+00,  1.6323e+00,
          1.6139e+00,  1.6487e+00,  1.6064e+00,  1.6067e+00],
        [ 1.3265e+00,  1.2963e+00,  1.1845e+00,  1.2841e+00,  1.3663e+00,
          1.3641e+00,  1.3222e+00,  1.3632e+00,  1.3632e+00,  2.1233e+00,
          2.0817e+00,  2.0514e+00,  2.2307e+00,  2.0877e+00,  2.9386e+00,
          2.1461e+00,  2.0366e+00,  2.8847e+00,  1.2996e+00,  1.3380e+00,
          1.2790e+00,  1.2601e+00,  1.3753e+00,  1.3764e+00,  1.3359e+00,
          1.3755e+00,  1.3755e+00,  1.3601e+00,  1.2073e+00,  1.3984e+00,
          1.4001e+00,  1.2682e+00,  1.4002e+00,  1.4029e+00,  1.3661e+00,
          1.3985e+00,  1.7843e+00,  1.8038e+00,  1.7490e+00,  1.7360e+00,
          1.7930e+00,  1.8011e+00,  1.7469e+00,  1.4037e+00,  1.7919e+00,
          1.5485e+00,  1.6629e+00,  1.6581e+00,  1.6508e+00,  1.4916e+00,
          1.6567e+00,  1.5092e+00,  1.6485e+00,  1.6488e+00],
        [ 1.3134e+00,  1.3162e+00,  1.3201e+00,  1.3181e+00,  1.3161e+00,
          1.3142e+00,  1.3122e+00,  1.3133e+00,  1.3133e+00,  1.3730e+00,
          1.3758e+00,  1.3747e+00,  1.3764e+00,  1.3719e+00,  1.3386e+00,
          1.3734e+00,  1.3547e+00,  1.3367e+00,  2.3216e+00,  2.3044e+00,
          2.3811e+00,  2.3412e+00,  2.2360e+00,  2.2464e+00,  2.3110e+00,
          2.2279e+00,  2.2279e+00,  1.3486e+00,  1.3239e+00,  1.3500e+00,
          1.3532e+00,  1.3477e+00,  1.3516e+00,  1.3544e+00,  1.3499e+00,
          1.3504e+00,  1.7507e+00,  1.7620e+00,  1.7542e+00,  1.7418e+00,
          1.7586e+00,  1.7583e+00,  1.7522e+00,  1.6927e+00,  1.7425e+00,
          1.6342e+00,  1.6242e+00,  1.6200e+00,  1.6133e+00,  1.5894e+00,
          1.6188e+00,  1.6350e+00,  1.6110e+00,  1.6114e+00],
        [ 1.3245e+00,  1.3274e+00,  1.3271e+00,  1.3251e+00,  1.3275e+00,
          1.3253e+00,  1.3254e+00,  1.3244e+00,  1.3244e+00,  1.3842e+00,
          1.3837e+00,  1.3859e+00,  1.3760e+00,  1.3832e+00,  1.2910e+00,
          1.3846e+00,  1.3824e+00,  1.2825e+00,  1.3417e+00,  1.3301e+00,
          1.3437e+00,  1.3427e+00,  1.3393e+00,  1.3376e+00,  1.3409e+00,
          1.3378e+00,  1.3378e+00,  2.4258e+00,  2.3869e+00,  2.1736e+00,
          2.2746e+00,  2.4229e+00,  2.1822e+00,  2.3808e+00,  2.1981e+00,
          2.1752e+00,  1.7577e+00,  1.7692e+00,  1.7441e+00,  1.7576e+00,
          1.7658e+00,  1.7648e+00,  1.7437e+00,  1.6757e+00,  1.7578e+00,
          1.6507e+00,  1.6301e+00,  1.5186e+00,  1.5654e+00,  1.6455e+00,
          1.6209e+00,  1.6631e+00,  1.5631e+00,  1.6183e+00],
        [ 1.8140e+00,  1.4217e+00,  5.7467e-01,  8.7286e-01,  1.2706e+00,
          1.7127e+00,  1.6155e+00,  1.8199e+00,  1.8199e+00,  1.7004e+00,
          1.2883e+00,  1.5026e+00,  8.8170e-01,  1.7440e+00,  1.0941e-01,
          1.6364e+00,  1.8105e+00,  9.1389e-01,  1.3171e+00,  8.9509e-01,
          6.7950e-01,  1.1429e+00,  1.6540e+00,  1.7264e+00,  1.4634e+00,
          1.8279e+00,  1.8279e+00,  7.6717e-01,  8.4621e-01,  1.7981e+00,
          1.5788e+00,  8.1487e-01,  1.7396e+00,  1.2071e+00,  1.8471e+00,
          1.7623e+00,  1.4590e-01, -1.3636e-01, -1.7056e-01,  9.5822e-02,
          4.1623e-01,  5.4214e-01,  7.8485e-05,  8.9712e+00,  6.1741e+00,
          1.4752e-01,  5.2055e-01,  5.5922e-01,  6.6409e-01,  3.2883e-01,
          6.6284e-01, -1.5132e-01,  6.8823e-01,  7.6172e-01],
        [ 1.3361e+00,  1.3742e+00,  1.4234e+00,  1.4104e+00,  1.3852e+00,
          1.3466e+00,  1.3148e+00,  1.3353e+00,  1.3353e+00,  1.2928e+00,
          1.4188e+00,  1.3160e+00,  1.4506e+00,  1.3666e+00,  1.4770e+00,
          1.2990e+00,  1.3598e+00,  1.3527e+00,  1.3911e+00,  1.4133e+00,
          1.4280e+00,  1.4034e+00,  1.3600e+00,  1.3509e+00,  1.2956e+00,
          1.3412e+00,  1.3412e+00,  1.4000e+00,  1.4376e+00,  1.3555e+00,
          1.1843e+00,  1.3525e+00,  1.2438e+00,  1.4124e+00,  1.2350e+00,
          1.3598e+00,  3.4362e-01,  2.7102e-01,  3.9387e-01,  3.5250e-01,
          1.5664e-01,  1.1005e-01,  3.6712e-01,  1.8414e-01, -2.0861e-02,
          2.7163e+00,  2.0055e+00,  2.6126e+00,  2.2562e+00,  1.6622e+00,
          1.3082e+00,  2.5063e+00,  2.3966e+00,  1.2739e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 132 : 176.57122305080816
Test loss for epoch 132 : 176.34097544659147
Test Precision for epoch 132 : 0.26153846153846155
Test Recall for epoch 132 : 0.26153846153846155
Test F1 for epoch 132 : 0.26153846153846155


theta for epoch 133 : tensor([[ 2.2420e+00,  2.2598e+00,  2.2978e+00,  2.3683e+00,  2.3500e+00,
          2.2467e+00,  2.3352e+00,  2.2417e+00,  2.2417e+00,  1.3669e+00,
          1.3696e+00,  1.3686e+00,  1.3720e+00,  1.3659e+00,  1.3741e+00,
          1.3674e+00,  1.3654e+00,  1.3272e+00,  1.3241e+00,  1.2834e+00,
          1.2842e+00,  1.3252e+00,  1.3219e+00,  1.3213e+00,  1.3237e+00,
          1.3205e+00,  1.3205e+00,  1.3059e+00,  1.3495e+00,  1.3431e+00,
          1.3462e+00,  1.3496e+00,  1.3446e+00,  1.3473e+00,  1.3000e+00,
          1.3434e+00,  1.7462e+00,  1.7572e+00,  1.7497e+00,  1.7467e+00,
          1.7539e+00,  1.6949e+00,  1.7477e+00,  1.7351e+00,  1.7470e+00,
          1.6373e+00,  1.6194e+00,  1.6152e+00,  1.6087e+00,  1.6324e+00,
          1.6140e+00,  1.6488e+00,  1.6065e+00,  1.6068e+00],
        [ 1.3255e+00,  1.2967e+00,  1.1845e+00,  1.2830e+00,  1.3650e+00,
          1.3627e+00,  1.3218e+00,  1.3618e+00,  1.3618e+00,  2.1310e+00,
          2.0875e+00,  2.0575e+00,  2.2343e+00,  2.0937e+00,  2.9350e+00,
          2.1522e+00,  2.0438e+00,  2.8828e+00,  1.2994e+00,  1.3375e+00,
          1.2790e+00,  1.2599e+00,  1.3741e+00,  1.3751e+00,  1.3347e+00,
          1.3743e+00,  1.3743e+00,  1.3597e+00,  1.2070e+00,  1.3973e+00,
          1.3990e+00,  1.2684e+00,  1.3990e+00,  1.4017e+00,  1.3651e+00,
          1.3974e+00,  1.7840e+00,  1.8031e+00,  1.7485e+00,  1.7361e+00,
          1.7927e+00,  1.8004e+00,  1.7464e+00,  1.4071e+00,  1.7912e+00,
          1.5502e+00,  1.6627e+00,  1.6580e+00,  1.6507e+00,  1.4929e+00,
          1.6566e+00,  1.5111e+00,  1.6483e+00,  1.6487e+00],
        [ 1.3126e+00,  1.3155e+00,  1.3193e+00,  1.3174e+00,  1.3153e+00,
          1.3134e+00,  1.3115e+00,  1.3126e+00,  1.3126e+00,  1.3723e+00,
          1.3752e+00,  1.3740e+00,  1.3758e+00,  1.3713e+00,  1.3383e+00,
          1.3728e+00,  1.3539e+00,  1.3367e+00,  2.3253e+00,  2.3082e+00,
          2.3845e+00,  2.3445e+00,  2.2402e+00,  2.2502e+00,  2.3146e+00,
          2.2321e+00,  2.2321e+00,  1.3479e+00,  1.3236e+00,  1.3494e+00,
          1.3526e+00,  1.3470e+00,  1.3510e+00,  1.3538e+00,  1.3492e+00,
          1.3497e+00,  1.7502e+00,  1.7615e+00,  1.7538e+00,  1.7412e+00,
          1.7581e+00,  1.7579e+00,  1.7517e+00,  1.6931e+00,  1.7420e+00,
          1.6343e+00,  1.6241e+00,  1.6198e+00,  1.6131e+00,  1.5900e+00,
          1.6186e+00,  1.6350e+00,  1.6109e+00,  1.6112e+00],
        [ 1.3238e+00,  1.3267e+00,  1.3266e+00,  1.3246e+00,  1.3268e+00,
          1.3246e+00,  1.3247e+00,  1.3237e+00,  1.3237e+00,  1.3836e+00,
          1.3832e+00,  1.3853e+00,  1.3753e+00,  1.3826e+00,  1.2903e+00,
          1.3841e+00,  1.3818e+00,  1.2819e+00,  1.3411e+00,  1.3293e+00,
          1.3431e+00,  1.3421e+00,  1.3386e+00,  1.3370e+00,  1.3403e+00,
          1.3372e+00,  1.3372e+00,  2.4299e+00,  2.3910e+00,  2.1771e+00,
          2.2784e+00,  2.4271e+00,  2.1858e+00,  2.3845e+00,  2.2020e+00,
          2.1787e+00,  1.7573e+00,  1.7688e+00,  1.7435e+00,  1.7572e+00,
          1.7653e+00,  1.7644e+00,  1.7431e+00,  1.6755e+00,  1.7573e+00,
          1.6507e+00,  1.6301e+00,  1.5187e+00,  1.5655e+00,  1.6455e+00,
          1.6211e+00,  1.6630e+00,  1.5631e+00,  1.6183e+00],
        [ 1.8159e+00,  1.4232e+00,  5.7746e-01,  8.7580e-01,  1.2734e+00,
          1.7150e+00,  1.6172e+00,  1.8221e+00,  1.8221e+00,  1.7027e+00,
          1.2908e+00,  1.5046e+00,  8.8422e-01,  1.7456e+00,  1.1192e-01,
          1.6380e+00,  1.8129e+00,  9.1532e-01,  1.3190e+00,  8.9797e-01,
          6.8203e-01,  1.1449e+00,  1.6564e+00,  1.7286e+00,  1.4659e+00,
          1.8301e+00,  1.8301e+00,  7.7046e-01,  8.4909e-01,  1.8008e+00,
          1.5819e+00,  8.1786e-01,  1.7423e+00,  1.2102e+00,  1.8499e+00,
          1.7652e+00,  1.4024e-01, -1.4137e-01, -1.7549e-01,  9.0502e-02,
          4.0912e-01,  5.3377e-01, -5.2168e-03,  9.0275e+00,  6.1833e+00,
          1.5129e-01,  5.2439e-01,  5.6307e-01,  6.6778e-01,  3.3230e-01,
          6.6649e-01, -1.4761e-01,  6.9195e-01,  7.6528e-01],
        [ 1.3344e+00,  1.3727e+00,  1.4218e+00,  1.4088e+00,  1.3836e+00,
          1.3449e+00,  1.3132e+00,  1.3336e+00,  1.3336e+00,  1.2910e+00,
          1.4172e+00,  1.3143e+00,  1.4488e+00,  1.3650e+00,  1.4752e+00,
          1.2974e+00,  1.3581e+00,  1.3511e+00,  1.3890e+00,  1.4110e+00,
          1.4259e+00,  1.4013e+00,  1.3578e+00,  1.3488e+00,  1.2931e+00,
          1.3390e+00,  1.3390e+00,  1.3983e+00,  1.4360e+00,  1.3539e+00,
          1.1822e+00,  1.3509e+00,  1.2423e+00,  1.4108e+00,  1.2333e+00,
          1.3582e+00,  3.4197e-01,  2.6933e-01,  3.9221e-01,  3.5081e-01,
          1.5489e-01,  1.0841e-01,  3.6551e-01,  1.8165e-01, -2.3284e-02,
          2.7236e+00,  2.0115e+00,  2.6222e+00,  2.2624e+00,  1.6673e+00,
          1.3129e+00,  2.5119e+00,  2.4062e+00,  1.2786e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 133 : 176.55656914865645
Test loss for epoch 133 : 176.3245821506971
Test Precision for epoch 133 : 0.26153846153846155
Test Recall for epoch 133 : 0.26153846153846155
Test F1 for epoch 133 : 0.26153846153846155


theta for epoch 134 : tensor([[ 2.2455e+00,  2.2634e+00,  2.3014e+00,  2.3721e+00,  2.3538e+00,
          2.2502e+00,  2.3390e+00,  2.2452e+00,  2.2452e+00,  1.3665e+00,
          1.3693e+00,  1.3682e+00,  1.3716e+00,  1.3655e+00,  1.3737e+00,
          1.3670e+00,  1.3650e+00,  1.3269e+00,  1.3240e+00,  1.2832e+00,
          1.2840e+00,  1.3250e+00,  1.3217e+00,  1.3211e+00,  1.3235e+00,
          1.3203e+00,  1.3203e+00,  1.3055e+00,  1.3491e+00,  1.3427e+00,
          1.3458e+00,  1.3493e+00,  1.3443e+00,  1.3470e+00,  1.2997e+00,
          1.3430e+00,  1.7461e+00,  1.7572e+00,  1.7497e+00,  1.7467e+00,
          1.7539e+00,  1.6949e+00,  1.7477e+00,  1.7351e+00,  1.7469e+00,
          1.6363e+00,  1.6183e+00,  1.6141e+00,  1.6076e+00,  1.6313e+00,
          1.6129e+00,  1.6477e+00,  1.6053e+00,  1.6057e+00],
        [ 1.3247e+00,  1.2973e+00,  1.1846e+00,  1.2820e+00,  1.3638e+00,
          1.3615e+00,  1.3214e+00,  1.3606e+00,  1.3606e+00,  2.1386e+00,
          2.0932e+00,  2.0634e+00,  2.2379e+00,  2.0994e+00,  2.9315e+00,
          2.1581e+00,  2.0509e+00,  2.8810e+00,  1.2998e+00,  1.3375e+00,
          1.2794e+00,  1.2603e+00,  1.3735e+00,  1.3744e+00,  1.3341e+00,
          1.3736e+00,  1.3736e+00,  1.3595e+00,  1.2068e+00,  1.3964e+00,
          1.3981e+00,  1.2688e+00,  1.3981e+00,  1.4008e+00,  1.3644e+00,
          1.3964e+00,  1.7840e+00,  1.8027e+00,  1.7484e+00,  1.7365e+00,
          1.7927e+00,  1.8001e+00,  1.7463e+00,  1.4108e+00,  1.7908e+00,
          1.5505e+00,  1.6614e+00,  1.6566e+00,  1.6494e+00,  1.4929e+00,
          1.6552e+00,  1.5118e+00,  1.6470e+00,  1.6473e+00],
        [ 1.3119e+00,  1.3148e+00,  1.3186e+00,  1.3167e+00,  1.3146e+00,
          1.3127e+00,  1.3109e+00,  1.3118e+00,  1.3118e+00,  1.3719e+00,
          1.3747e+00,  1.3736e+00,  1.3755e+00,  1.3708e+00,  1.3381e+00,
          1.3724e+00,  1.3532e+00,  1.3368e+00,  2.3292e+00,  2.3121e+00,
          2.3879e+00,  2.3480e+00,  2.2445e+00,  2.2541e+00,  2.3184e+00,
          2.2363e+00,  2.2363e+00,  1.3473e+00,  1.3235e+00,  1.3489e+00,
          1.3520e+00,  1.3465e+00,  1.3505e+00,  1.3533e+00,  1.3487e+00,
          1.3492e+00,  1.7501e+00,  1.7614e+00,  1.7537e+00,  1.7410e+00,
          1.7580e+00,  1.7578e+00,  1.7516e+00,  1.6939e+00,  1.7417e+00,
          1.6333e+00,  1.6228e+00,  1.6185e+00,  1.6118e+00,  1.5894e+00,
          1.6173e+00,  1.6338e+00,  1.6095e+00,  1.6099e+00],
        [ 1.3231e+00,  1.3261e+00,  1.3260e+00,  1.3241e+00,  1.3261e+00,
          1.3239e+00,  1.3240e+00,  1.3231e+00,  1.3231e+00,  1.3832e+00,
          1.3828e+00,  1.3849e+00,  1.3747e+00,  1.3821e+00,  1.2898e+00,
          1.3836e+00,  1.3814e+00,  1.2815e+00,  1.3409e+00,  1.3290e+00,
          1.3429e+00,  1.3419e+00,  1.3384e+00,  1.3367e+00,  1.3401e+00,
          1.3370e+00,  1.3370e+00,  2.4342e+00,  2.3952e+00,  2.1807e+00,
          2.2822e+00,  2.4314e+00,  2.1894e+00,  2.3884e+00,  2.2060e+00,
          2.1824e+00,  1.7573e+00,  1.7687e+00,  1.7432e+00,  1.7572e+00,
          1.7653e+00,  1.7644e+00,  1.7428e+00,  1.6757e+00,  1.7573e+00,
          1.6495e+00,  1.6290e+00,  1.5177e+00,  1.5644e+00,  1.6443e+00,
          1.6201e+00,  1.6618e+00,  1.5620e+00,  1.6171e+00],
        [ 1.8157e+00,  1.4220e+00,  5.7685e-01,  8.7571e-01,  1.2733e+00,
          1.7152e+00,  1.6166e+00,  1.8222e+00,  1.8222e+00,  1.7024e+00,
          1.2901e+00,  1.5039e+00,  8.8314e-01,  1.7446e+00,  1.1034e-01,
          1.6371e+00,  1.8130e+00,  9.1282e-01,  1.3180e+00,  8.9750e-01,
          6.8082e-01,  1.1437e+00,  1.6562e+00,  1.7283e+00,  1.4658e+00,
          1.8300e+00,  1.8300e+00,  7.7003e-01,  8.4829e-01,  1.8011e+00,
          1.5821e+00,  8.1696e-01,  1.7424e+00,  1.2099e+00,  1.8502e+00,
          1.7654e+00,  1.3774e-01, -1.4342e-01, -1.7749e-01,  8.8320e-02,
          4.0537e-01,  5.2887e-01, -7.4785e-03,  9.0869e+00,  6.1958e+00,
          1.5019e-01,  5.2355e-01,  5.6215e-01,  6.6664e-01,  3.3094e-01,
          6.6532e-01, -1.4874e-01,  6.9091e-01,  7.6408e-01],
        [ 1.3360e+00,  1.3742e+00,  1.4232e+00,  1.4102e+00,  1.3850e+00,
          1.3464e+00,  1.3148e+00,  1.3351e+00,  1.3351e+00,  1.2936e+00,
          1.4198e+00,  1.3170e+00,  1.4514e+00,  1.3677e+00,  1.4777e+00,
          1.3002e+00,  1.3607e+00,  1.3539e+00,  1.3915e+00,  1.4133e+00,
          1.4284e+00,  1.4038e+00,  1.3603e+00,  1.3514e+00,  1.2954e+00,
          1.3415e+00,  1.3415e+00,  1.4000e+00,  1.4377e+00,  1.3557e+00,
          1.1839e+00,  1.3528e+00,  1.2442e+00,  1.4125e+00,  1.2352e+00,
          1.3600e+00,  3.4468e-01,  2.7207e-01,  3.9488e-01,  3.5349e-01,
          1.5763e-01,  1.1129e-01,  3.6824e-01,  1.8370e-01, -2.1074e-02,
          2.7259e+00,  2.0122e+00,  2.6265e+00,  2.2633e+00,  1.6673e+00,
          1.3125e+00,  2.5123e+00,  2.4106e+00,  1.2781e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 134 : 176.542525598964
Test loss for epoch 134 : 176.31514773253585
Test Precision for epoch 134 : 0.26153846153846155
Test Recall for epoch 134 : 0.26153846153846155
Test F1 for epoch 134 : 0.26153846153846155


theta for epoch 135 : tensor([[ 2.2492,  2.2671,  2.3050,  2.3761,  2.3578,  2.2538,  2.3430,  2.2489,
          2.2489,  1.3660,  1.3687,  1.3676,  1.3711,  1.3650,  1.3731,  1.3665,
          1.3645,  1.3263,  1.3234,  1.2827,  1.2835,  1.3245,  1.3212,  1.3206,
          1.3230,  1.3198,  1.3198,  1.3051,  1.3487,  1.3423,  1.3454,  1.3489,
          1.3439,  1.3466,  1.2993,  1.3426,  1.7457,  1.7567,  1.7492,  1.7462,
          1.7534,  1.6944,  1.7472,  1.7345,  1.7464,  1.6363,  1.6183,  1.6141,
          1.6076,  1.6313,  1.6129,  1.6477,  1.6054,  1.6057],
        [ 1.3241,  1.2981,  1.1851,  1.2813,  1.3629,  1.3606,  1.3213,  1.3597,
          1.3597,  2.1457,  2.0987,  2.0688,  2.2412,  2.1048,  2.9280,  2.1636,
          2.0576,  2.8790,  1.2999,  1.3372,  1.2795,  1.2604,  1.3727,  1.3735,
          1.3332,  1.3726,  1.3726,  1.3593,  1.2068,  1.3955,  1.3973,  1.2692,
          1.3972,  1.3999,  1.3637,  1.3956,  1.7836,  1.8019,  1.7479,  1.7365,
          1.7923,  1.7993,  1.7458,  1.4140,  1.7899,  1.5522,  1.6613,  1.6566,
          1.6493,  1.4943,  1.6551,  1.5138,  1.6469,  1.6473],
        [ 1.3115,  1.3144,  1.3182,  1.3163,  1.3142,  1.3123,  1.3106,  1.3114,
          1.3114,  1.3714,  1.3742,  1.3731,  1.3750,  1.3703,  1.3379,  1.3718,
          1.3525,  1.3369,  2.3326,  2.3156,  2.3910,  2.3510,  2.2483,  2.2575,
          2.3217,  2.2402,  2.2402,  1.3468,  1.3234,  1.3484,  1.3516,  1.3460,
          1.3500,  1.3528,  1.3482,  1.3487,  1.7496,  1.7609,  1.7532,  1.7404,
          1.7575,  1.7572,  1.7511,  1.6943,  1.7410,  1.6334,  1.6227,  1.6184,
          1.6117,  1.5900,  1.6172,  1.6338,  1.6094,  1.6098],
        [ 1.3227,  1.3256,  1.3258,  1.3239,  1.3257,  1.3235,  1.3236,  1.3226,
          1.3226,  1.3826,  1.3823,  1.3843,  1.3740,  1.3816,  1.2891,  1.3831,
          1.3808,  1.2809,  1.3404,  1.3283,  1.3424,  1.3414,  1.3379,  1.3363,
          1.3396,  1.3365,  1.3365,  2.4383,  2.3992,  2.1842,  2.2859,  2.4355,
          2.1929,  2.3920,  2.2098,  2.1858,  1.7568,  1.7682,  1.7425,  1.7567,
          1.7648,  1.7640,  1.7420,  1.6754,  1.7567,  1.6495,  1.6290,  1.5178,
          1.5644,  1.6442,  1.6203,  1.6616,  1.5620,  1.6170],
        [ 1.8182,  1.4244,  0.5805,  0.8794,  1.2769,  1.7181,  1.6190,  1.8250,
          1.8250,  1.7053,  1.2933,  1.5065,  0.8865,  1.7467,  0.1138,  1.6394,
          1.8159,  0.9152,  1.3207,  0.9012,  0.6844,  1.1465,  1.6593,  1.7311,
          1.4689,  1.8328,  1.8328,  0.7742,  0.8520,  1.8045,  1.5859,  0.8209,
          1.7458,  1.2138,  1.8535,  1.7688,  0.1315, -0.1490, -0.1830,  0.0824,
          0.3978,  0.5201, -0.0134,  9.1423,  6.2031,  0.1550,  0.5283,  0.5669,
          0.6712,  0.3354,  0.6699, -0.1439,  0.6955,  0.7685],
        [ 1.3336,  1.3720,  1.4209,  1.4079,  1.3827,  1.3440,  1.3125,  1.3327,
          1.3327,  1.2905,  1.4168,  1.3138,  1.4483,  1.3648,  1.4746,  1.2972,
          1.3576,  1.3509,  1.3881,  1.4097,  1.4250,  1.4005,  1.3569,  1.3480,
          1.2916,  1.3381,  1.3381,  1.3973,  1.4353,  1.3531,  1.1808,  1.3503,
          1.2417,  1.4099,  1.2325,  1.3575,  0.3417,  0.2690,  0.3919,  0.3505,
          0.1545,  0.1082,  0.3653,  0.1799, -0.0249,  2.7348,  2.0197,  2.6376,
          2.2709,  1.6738,  1.3186,  2.5194,  2.4217,  1.2841]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 135 : 176.52917563845233
Test loss for epoch 135 : 176.29842585981538
Test Precision for epoch 135 : 0.26153846153846155
Test Recall for epoch 135 : 0.26153846153846155
Test F1 for epoch 135 : 0.26153846153846155


theta for epoch 136 : tensor([[ 2.2531,  2.2711,  2.3090,  2.3803,  2.3621,  2.2578,  2.3473,  2.2528,
          2.2528,  1.3656,  1.3684,  1.3673,  1.3707,  1.3646,  1.3728,  1.3661,
          1.3641,  1.3260,  1.3233,  1.2825,  1.2832,  1.3243,  1.3210,  1.3204,
          1.3228,  1.3196,  1.3196,  1.3046,  1.3481,  1.3418,  1.3449,  1.3483,
          1.3433,  1.3460,  1.2988,  1.3421,  1.7457,  1.7567,  1.7493,  1.7463,
          1.7534,  1.6944,  1.7472,  1.7345,  1.7464,  1.6343,  1.6164,  1.6122,
          1.6057,  1.6294,  1.6109,  1.6458,  1.6034,  1.6037],
        [ 1.3238,  1.2990,  1.1857,  1.2808,  1.3622,  1.3599,  1.3215,  1.3590,
          1.3590,  2.1530,  2.1043,  2.0744,  2.2447,  2.1104,  2.9248,  2.1693,
          2.0645,  2.8773,  1.3005,  1.3374,  1.2801,  1.2610,  1.3723,  1.3731,
          1.3328,  1.3722,  1.3722,  1.3591,  1.2067,  1.3946,  1.3964,  1.2694,
          1.3963,  1.3990,  1.3629,  1.3946,  1.7836,  1.8016,  1.7479,  1.7370,
          1.7923,  1.7991,  1.7457,  1.4176,  1.7896,  1.5517,  1.6592,  1.6544,
          1.6473,  1.4935,  1.6530,  1.5137,  1.6448,  1.6452],
        [ 1.3113,  1.3141,  1.3180,  1.3161,  1.3140,  1.3120,  1.3104,  1.3112,
          1.3112,  1.3712,  1.3740,  1.3729,  1.3749,  1.3701,  1.3380,  1.3716,
          1.3520,  1.3373,  2.3364,  2.3195,  2.3945,  2.3544,  2.2526,  2.2614,
          2.3254,  2.2444,  2.2444,  1.3461,  1.3232,  1.3478,  1.3510,  1.3454,
          1.3494,  1.3522,  1.3477,  1.3482,  1.7496,  1.7608,  1.7532,  1.7403,
          1.7574,  1.7572,  1.7511,  1.6952,  1.7408,  1.6317,  1.6206,  1.6163,
          1.6097,  1.5887,  1.6151,  1.6319,  1.6073,  1.6077],
        [ 1.3225,  1.3255,  1.3257,  1.3238,  1.3255,  1.3233,  1.3234,  1.3224,
          1.3224,  1.3824,  1.3822,  1.3841,  1.3737,  1.3814,  1.2888,  1.3829,
          1.3806,  1.2807,  1.3404,  1.3282,  1.3424,  1.3414,  1.3378,  1.3362,
          1.3395,  1.3364,  1.3364,  2.4424,  2.4031,  2.1876,  2.2895,  2.4396,
          2.1963,  2.3957,  2.2135,  2.1892,  1.7568,  1.7683,  1.7424,  1.7568,
          1.7648,  1.7641,  1.7418,  1.6757,  1.7567,  1.6476,  1.6272,  1.5161,
          1.5626,  1.6424,  1.6186,  1.6598,  1.5602,  1.6152],
        [ 1.8178,  1.4228,  0.5791,  0.8787,  1.2763,  1.7179,  1.6181,  1.8249,
          1.8249,  1.7043,  1.2916,  1.5050,  0.8844,  1.7450,  0.1111,  1.6378,
          1.8154,  0.9116,  1.3188,  0.8998,  0.6821,  1.1445,  1.6583,  1.7301,
          1.4680,  1.8321,  1.8321,  0.7726,  0.8500,  1.8038,  1.5851,  0.8188,
          1.7449,  1.2124,  1.8529,  1.7681,  0.1300, -0.1501, -0.1841,  0.0812,
          0.3952,  0.5166, -0.0147,  9.2024,  6.2157,  0.1523,  0.5259,  0.5643,
          0.6684,  0.3324,  0.6670, -0.1466,  0.6928,  0.7657],
        [ 1.3364,  1.3748,  1.4236,  1.4106,  1.3854,  1.3467,  1.3153,  1.3355,
          1.3355,  1.2945,  1.4207,  1.3179,  1.4522,  1.3689,  1.4785,  1.3013,
          1.3615,  1.3550,  1.3920,  1.4133,  1.4288,  1.4044,  1.3607,  1.3519,
          1.2953,  1.3419,  1.3419,  1.3999,  1.4378,  1.3558,  1.1835,  1.3531,
          1.2446,  1.4125,  1.2354,  1.3602,  0.3457,  0.2730,  0.3958,  0.3544,
          0.1585,  0.1123,  0.3693,  0.1833, -0.0214,  2.7354,  2.0188,  2.6403,
          2.2702,  1.6721,  1.3165,  2.5183,  2.4244,  1.2820]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 136 : 176.51725495904387
Test loss for epoch 136 : 176.29308904250703
Test Precision for epoch 136 : 0.26153846153846155
Test Recall for epoch 136 : 0.26153846153846155
Test F1 for epoch 136 : 0.26153846153846155


theta for epoch 137 : tensor([[ 2.2568,  2.2748,  2.3127,  2.3843,  2.3660,  2.2614,  2.3512,  2.2565,
          2.2565,  1.3651,  1.3679,  1.3668,  1.3702,  1.3641,  1.3723,  1.3656,
          1.3636,  1.3255,  1.3226,  1.2817,  1.2825,  1.3237,  1.3203,  1.3197,
          1.3221,  1.3189,  1.3189,  1.3042,  1.3477,  1.3413,  1.3444,  1.3479,
          1.3429,  1.3456,  1.2983,  1.3417,  1.7451,  1.7561,  1.7487,  1.7457,
          1.7528,  1.6938,  1.7466,  1.7339,  1.7458,  1.6348,  1.6169,  1.6127,
          1.6062,  1.6299,  1.6114,  1.6463,  1.6039,  1.6043],
        [ 1.3233,  1.2997,  1.1861,  1.2801,  1.3613,  1.3589,  1.3214,  1.3580,
          1.3580,  2.1603,  2.1099,  2.0799,  2.2483,  2.1158,  2.9217,  2.1749,
          2.0713,  2.8756,  1.3004,  1.3368,  1.2799,  1.2608,  1.3713,  1.3719,
          1.3317,  1.3710,  1.3710,  1.3587,  1.2066,  1.3936,  1.3955,  1.2696,
          1.3954,  1.3980,  1.3622,  1.3937,  1.7830,  1.8007,  1.7471,  1.7368,
          1.7917,  1.7981,  1.7450,  1.4206,  1.7886,  1.5537,  1.6596,  1.6548,
          1.6477,  1.4953,  1.6534,  1.5161,  1.6452,  1.6457],
        [ 1.3108,  1.3137,  1.3176,  1.3157,  1.3136,  1.3116,  1.3101,  1.3107,
          1.3107,  1.3707,  1.3735,  1.3725,  1.3745,  1.3696,  1.3379,  1.3712,
          1.3513,  1.3373,  2.3399,  2.3231,  2.3976,  2.3575,  2.2565,  2.2650,
          2.3288,  2.2483,  2.2483,  1.3455,  1.3230,  1.3473,  1.3504,  1.3448,
          1.3489,  1.3516,  1.3471,  1.3476,  1.7489,  1.7602,  1.7525,  1.7395,
          1.7568,  1.7566,  1.7505,  1.6955,  1.7400,  1.6323,  1.6210,  1.6167,
          1.6100,  1.5897,  1.6154,  1.6323,  1.6077,  1.6081],
        [ 1.3221,  1.3250,  1.3254,  1.3235,  1.3251,  1.3229,  1.3230,  1.3220,
          1.3220,  1.3819,  1.3817,  1.3837,  1.3731,  1.3809,  1.2882,  1.3824,
          1.3801,  1.2803,  1.3397,  1.3274,  1.3418,  1.3408,  1.3372,  1.3356,
          1.3389,  1.3358,  1.3358,  2.4464,  2.4071,  2.1910,  2.2932,  2.4437,
          2.1997,  2.3994,  2.2173,  2.1926,  1.7562,  1.7677,  1.7416,  1.7562,
          1.7642,  1.7635,  1.7409,  1.6753,  1.7561,  1.6480,  1.6277,  1.5166,
          1.5631,  1.6428,  1.6192,  1.6601,  1.5607,  1.6156],
        [ 1.8210,  1.4262,  0.5840,  0.8835,  1.2809,  1.7217,  1.6215,  1.8284,
          1.8284,  1.7083,  1.2963,  1.5088,  0.8893,  1.7482,  0.1163,  1.6412,
          1.8194,  0.9155,  1.3228,  0.9049,  0.6872,  1.1486,  1.6624,  1.7338,
          1.4722,  1.8358,  1.8358,  0.7782,  0.8551,  1.8082,  1.5900,  0.8243,
          1.7493,  1.2176,  1.8572,  1.7725,  0.1226, -0.1567, -0.1906,  0.0742,
          0.3866,  0.5070, -0.0217,  9.2563,  6.2206,  0.1590,  0.5323,  0.5708,
          0.6747,  0.3386,  0.6733, -0.1398,  0.6991,  0.7718],
        [ 1.3329,  1.3714,  1.4202,  1.4072,  1.3819,  1.3432,  1.3118,  1.3320,
          1.3320,  1.2898,  1.4162,  1.3132,  1.4477,  1.3645,  1.4738,  1.2967,
          1.3569,  1.3505,  1.3870,  1.4081,  1.4239,  1.3995,  1.3557,  1.3469,
          1.2898,  1.3369,  1.3369,  1.3961,  1.4342,  1.3520,  1.1791,  1.3494,
          1.2408,  1.4087,  1.2314,  1.3564,  0.3411,  0.2682,  0.3912,  0.3498,
          0.1536,  0.1075,  0.3647,  0.1778, -0.0270,  2.7463,  2.0281,  2.6533,
          2.2797,  1.6804,  1.3244,  2.5272,  2.4374,  1.2899]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 137 : 176.50704442755276
Test loss for epoch 137 : 176.27714397080385
Test Precision for epoch 137 : 0.26153846153846155
Test Recall for epoch 137 : 0.26153846153846155
Test F1 for epoch 137 : 0.26153846153846155


theta for epoch 138 : tensor([[ 2.2604,  2.2786,  2.3164,  2.3883,  2.3700,  2.2651,  2.3552,  2.2601,
          2.2601,  1.3649,  1.3676,  1.3666,  1.3700,  1.3639,  1.3721,  1.3654,
          1.3633,  1.3253,  1.3226,  1.2817,  1.2824,  1.3236,  1.3202,  1.3196,
          1.3221,  1.3188,  1.3188,  1.3038,  1.3473,  1.3410,  1.3441,  1.3475,
          1.3425,  1.3452,  1.2980,  1.3413,  1.7454,  1.7564,  1.7490,  1.7460,
          1.7531,  1.6941,  1.7470,  1.7342,  1.7460,  1.6330,  1.6150,  1.6108,
          1.6043,  1.6280,  1.6095,  1.6444,  1.6020,  1.6024],
        [ 1.3227,  1.3003,  1.1865,  1.2793,  1.3603,  1.3579,  1.3211,  1.3570,
          1.3570,  2.1677,  2.1157,  2.0855,  2.2521,  2.1214,  2.9191,  2.1806,
          2.0783,  2.8744,  1.3009,  1.3369,  1.2803,  1.2613,  1.3709,  1.3714,
          1.3313,  1.3706,  1.3706,  1.3585,  1.2066,  1.3928,  1.3947,  1.2697,
          1.3945,  1.3972,  1.3615,  1.3929,  1.7832,  1.8006,  1.7473,  1.7375,
          1.7919,  1.7981,  1.7451,  1.4242,  1.7884,  1.5530,  1.6574,  1.6526,
          1.6456,  1.4945,  1.6513,  1.5158,  1.6431,  1.6435],
        [ 1.3102,  1.3131,  1.3169,  1.3150,  1.3129,  1.3109,  1.3095,  1.3101,
          1.3101,  1.3703,  1.3732,  1.3721,  1.3742,  1.3693,  1.3378,  1.3708,
          1.3508,  1.3375,  2.3440,  2.3274,  2.4015,  2.3613,  2.2611,  2.2693,
          2.3329,  2.2530,  2.2530,  1.3448,  1.3228,  1.3467,  1.3499,  1.3442,
          1.3483,  1.3511,  1.3466,  1.3471,  1.7491,  1.7604,  1.7527,  1.7396,
          1.7570,  1.7568,  1.7507,  1.6965,  1.7400,  1.6305,  1.6189,  1.6146,
          1.6080,  1.5882,  1.6134,  1.6303,  1.6056,  1.6060],
        [ 1.3215,  1.3245,  1.3250,  1.3231,  1.3245,  1.3223,  1.3224,  1.3214,
          1.3214,  1.3816,  1.3815,  1.3834,  1.3726,  1.3806,  1.2878,  1.3821,
          1.3797,  1.2799,  1.3397,  1.3272,  1.3417,  1.3407,  1.3371,  1.3356,
          1.3388,  1.3357,  1.3357,  2.4508,  2.4113,  2.1947,  2.2971,  2.4481,
          2.2034,  2.4034,  2.2213,  2.1963,  1.7565,  1.7680,  1.7416,  1.7565,
          1.7645,  1.7638,  1.7410,  1.6759,  1.7563,  1.6461,  1.6258,  1.5149,
          1.5613,  1.6410,  1.6175,  1.6582,  1.5588,  1.6137],
        [ 1.8193,  1.4232,  0.5808,  0.8812,  1.2788,  1.7202,  1.6192,  1.8271,
          1.8271,  1.7061,  1.2930,  1.5061,  0.8856,  1.7454,  0.1117,  1.6384,
          1.8177,  0.9101,  1.3195,  0.9020,  0.6834,  1.1451,  1.6603,  1.7318,
          1.4701,  1.8340,  1.8340,  0.7749,  0.8514,  1.8063,  1.5879,  0.8205,
          1.7472,  1.2146,  1.8554,  1.7706,  0.1227, -0.1564, -0.1903,  0.0746,
          0.3858,  0.5053, -0.0215,  9.3175,  6.2340,  0.1542,  0.5278,  0.5662,
          0.6699,  0.3336,  0.6684, -0.1445,  0.6945,  0.7670],
        [ 1.3370,  1.3755,  1.4242,  1.4112,  1.3859,  1.3473,  1.3161,  1.3361,
          1.3361,  1.2960,  1.4222,  1.3195,  1.4537,  1.3707,  1.4798,  1.3031,
          1.3629,  1.3567,  1.3932,  1.4141,  1.4300,  1.4056,  1.3618,  1.3531,
          1.2959,  1.3431,  1.3431,  1.4005,  1.4385,  1.3566,  1.1837,  1.3539,
          1.2456,  1.4131,  1.2362,  1.3609,  0.3473,  0.2744,  0.3973,  0.3559,
          0.1599,  0.1139,  0.3709,  0.1835, -0.0211,  2.7445,  2.0246,  2.6535,
          2.2765,  1.6762,  1.3198,  2.5237,  2.4375,  1.2852]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 138 : 176.50028256536604
Test loss for epoch 138 : 176.2800604962521
Test Precision for epoch 138 : 0.26153846153846155
Test Recall for epoch 138 : 0.26153846153846155
Test F1 for epoch 138 : 0.26153846153846155


theta for epoch 139 : tensor([[ 2.2639,  2.2821,  2.3199,  2.3920,  2.3738,  2.2685,  2.3590,  2.2636,
          2.2636,  1.3641,  1.3669,  1.3658,  1.3693,  1.3631,  1.3713,  1.3647,
          1.3626,  1.3246,  1.3217,  1.2808,  1.2815,  1.3227,  1.3193,  1.3187,
          1.3211,  1.3179,  1.3179,  1.3035,  1.3469,  1.3406,  1.3437,  1.3471,
          1.3422,  1.3449,  1.2976,  1.3409,  1.7448,  1.7558,  1.7483,  1.7453,
          1.7525,  1.6935,  1.7463,  1.7335,  1.7453,  1.6346,  1.6166,  1.6124,
          1.6059,  1.6296,  1.6111,  1.6459,  1.6036,  1.6040],
        [ 1.3220,  1.3007,  1.1867,  1.2784,  1.3592,  1.3568,  1.3208,  1.3559,
          1.3559,  2.1747,  2.1212,  2.0908,  2.2557,  2.1267,  2.9164,  2.1860,
          2.0850,  2.8729,  1.3004,  1.3359,  1.2797,  1.2608,  1.3695,  1.3699,
          1.3299,  1.3691,  1.3691,  1.3582,  1.2066,  1.3919,  1.3939,  1.2699,
          1.3936,  1.3963,  1.3608,  1.3920,  1.7824,  1.7995,  1.7464,  1.7372,
          1.7911,  1.7970,  1.7443,  1.4269,  1.7873,  1.5561,  1.6589,  1.6541,
          1.6471,  1.4973,  1.6528,  1.5192,  1.6446,  1.6451],
        [ 1.3095,  1.3124,  1.3162,  1.3144,  1.3123,  1.3103,  1.3089,  1.3094,
          1.3094,  1.3695,  1.3724,  1.3713,  1.3734,  1.3684,  1.3373,  1.3700,
          1.3497,  1.3372,  2.3473,  2.3310,  2.4046,  2.3643,  2.2649,  2.2727,
          2.3362,  2.2568,  2.2568,  1.3442,  1.3226,  1.3463,  1.3494,  1.3436,
          1.3478,  1.3506,  1.3461,  1.3466,  1.7484,  1.7596,  1.7520,  1.7387,
          1.7563,  1.7561,  1.7499,  1.6967,  1.7391,  1.6321,  1.6203,  1.6160,
          1.6094,  1.5903,  1.6147,  1.6318,  1.6070,  1.6074],
        [ 1.3209,  1.3239,  1.3245,  1.3226,  1.3239,  1.3217,  1.3218,  1.3208,
          1.3208,  1.3808,  1.3807,  1.3826,  1.3717,  1.3797,  1.2868,  1.3813,
          1.3789,  1.2791,  1.3388,  1.3262,  1.3408,  1.3398,  1.3362,  1.3347,
          1.3379,  1.3348,  1.3348,  2.4550,  2.4153,  2.1981,  2.3008,  2.4523,
          2.2068,  2.4072,  2.2252,  2.1998,  1.7558,  1.7673,  1.7407,  1.7558,
          1.7638,  1.7631,  1.7400,  1.6754,  1.7556,  1.6475,  1.6273,  1.5164,
          1.5627,  1.6424,  1.6191,  1.6595,  1.5603,  1.6152],
        [ 1.8236,  1.4281,  0.5875,  0.8876,  1.2849,  1.7251,  1.6238,  1.8317,
          1.8317,  1.7114,  1.2995,  1.5114,  0.8924,  1.7499,  0.1192,  1.6434,
          1.8229,  0.9162,  1.3252,  0.9090,  0.6907,  1.1511,  1.6658,  1.7369,
          1.4757,  1.8390,  1.8390,  0.7827,  0.8586,  1.8122,  1.5944,  0.8283,
          1.7533,  1.2217,  1.8611,  1.7766,  0.1137, -0.1646, -0.1983,  0.0660,
          0.3756,  0.4942, -0.0300,  9.3691,  6.2356,  0.1637,  0.5369,  0.5754,
          0.6790,  0.3426,  0.6775, -0.1349,  0.7035,  0.7759],
        [ 1.3316,  1.3702,  1.4188,  1.4058,  1.3805,  1.3419,  1.3106,  1.3306,
          1.3306,  1.2886,  1.4152,  1.3121,  1.4465,  1.3637,  1.4725,  1.2958,
          1.3557,  1.3496,  1.3857,  1.4064,  1.4226,  1.3982,  1.3543,  1.3456,
          1.2878,  1.3355,  1.3355,  1.3948,  1.4330,  1.3509,  1.1773,  1.3484,
          1.2399,  1.4075,  1.2303,  1.3553,  0.3402,  0.2672,  0.3902,  0.3488,
          0.1524,  0.1065,  0.3639,  0.1756, -0.0293,  2.7582,  2.0368,  2.6694,
          2.2889,  1.6874,  1.3306,  2.5356,  2.4535,  1.2960]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 139 : 176.496657412414
Test loss for epoch 139 : 176.26706659493314
Test Precision for epoch 139 : 0.26153846153846155
Test Recall for epoch 139 : 0.26153846153846155
Test F1 for epoch 139 : 0.26153846153846155


theta for epoch 140 : tensor([[ 2.2679,  2.2861,  2.3238,  2.3963,  2.3781,  2.2725,  2.3633,  2.2675,
          2.2675,  1.3639,  1.3666,  1.3656,  1.3690,  1.3629,  1.3711,  1.3644,
          1.3623,  1.3243,  1.3217,  1.2808,  1.2815,  1.3228,  1.3194,  1.3188,
          1.3212,  1.3180,  1.3180,  1.3030,  1.3464,  1.3401,  1.3432,  1.3466,
          1.3417,  1.3443,  1.2971,  1.3404,  1.7454,  1.7564,  1.7489,  1.7459,
          1.7531,  1.6941,  1.7469,  1.7340,  1.7459,  1.6316,  1.6136,  1.6093,
          1.6029,  1.6266,  1.6081,  1.6430,  1.6005,  1.6009],
        [ 1.3217,  1.3015,  1.1873,  1.2779,  1.3585,  1.3560,  1.3208,  1.3551,
          1.3551,  2.1821,  2.1271,  2.0963,  2.2596,  2.1322,  2.9141,  2.1917,
          2.0920,  2.8720,  1.3011,  1.3362,  1.2802,  1.2615,  1.3693,  1.3697,
          1.3298,  1.3689,  1.3689,  1.3578,  1.2065,  1.3911,  1.3931,  1.2699,
          1.3927,  1.3954,  1.3600,  1.3911,  1.7828,  1.7997,  1.7468,  1.7382,
          1.7916,  1.7972,  1.7447,  1.4307,  1.7874,  1.5541,  1.6554,  1.6507,
          1.6438,  1.4952,  1.6494,  1.5177,  1.6412,  1.6417],
        [ 1.3092,  1.3121,  1.3159,  1.3140,  1.3120,  1.3099,  1.3086,  1.3091,
          1.3091,  1.3693,  1.3722,  1.3712,  1.3733,  1.3683,  1.3374,  1.3699,
          1.3494,  1.3375,  2.3515,  2.3354,  2.4085,  2.3681,  2.2696,  2.2771,
          2.3404,  2.2614,  2.2614,  1.3435,  1.3224,  1.3457,  1.3488,  1.3430,
          1.3472,  1.3500,  1.3455,  1.3460,  1.7489,  1.7602,  1.7525,  1.7391,
          1.7568,  1.7566,  1.7505,  1.6981,  1.7394,  1.6292,  1.6172,  1.6128,
          1.6062,  1.5878,  1.6116,  1.6288,  1.6038,  1.6043],
        [ 1.3206,  1.3236,  1.3243,  1.3224,  1.3236,  1.3214,  1.3215,  1.3205,
          1.3205,  1.3806,  1.3806,  1.3824,  1.3714,  1.3796,  1.2866,  1.3812,
          1.3787,  1.2790,  1.3389,  1.3262,  1.3410,  1.3400,  1.3364,  1.3349,
          1.3381,  1.3350,  1.3350,  2.4593,  2.4194,  2.2017,  2.3046,  2.4566,
          2.2104,  2.4110,  2.2291,  2.2033,  1.7564,  1.7679,  1.7411,  1.7564,
          1.7644,  1.7638,  1.7404,  1.6763,  1.7562,  1.6447,  1.6245,  1.5136,
          1.5599,  1.6395,  1.6164,  1.6567,  1.5574,  1.6123],
        [ 1.8207,  1.4235,  0.5821,  0.8833,  1.2809,  1.7223,  1.6202,  1.8292,
          1.8292,  1.7075,  1.2941,  1.5067,  0.8863,  1.7454,  0.1119,  1.6389,
          1.8197,  0.9082,  1.3199,  0.9038,  0.6844,  1.1454,  1.6620,  1.7332,
          1.4719,  1.8357,  1.8357,  0.7768,  0.8524,  1.8084,  1.5902,  0.8217,
          1.7491,  1.2164,  1.8575,  1.7726,  0.1160, -0.1621, -0.1959,  0.0685,
          0.3772,  0.4951, -0.0277,  9.4319,  6.2506,  0.1557,  0.5293,  0.5676,
          0.6710,  0.3343,  0.6694, -0.1428,  0.6957,  0.7679],
        [ 1.3382,  1.3767,  1.4252,  1.4122,  1.3869,  1.3484,  1.3173,  1.3372,
          1.3372,  1.2979,  1.4241,  1.3214,  1.4555,  1.3729,  1.4816,  1.3052,
          1.3648,  1.3588,  1.3950,  1.4155,  1.4317,  1.4075,  1.3636,  1.3550,
          1.2972,  1.3449,  1.3449,  1.4015,  1.4395,  1.3578,  1.1845,  1.3552,
          1.2470,  1.4142,  1.2375,  1.3621,  0.3495,  0.2765,  0.3993,  0.3580,
          0.1618,  0.1160,  0.3731,  0.1846, -0.0201,  2.7528,  2.0298,  2.6658,
          2.2821,  1.6796,  1.3223,  2.5284,  2.4499,  1.2876]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 140 : 176.4992684393048
Test loss for epoch 140 : 176.28380965900055
Test Precision for epoch 140 : 0.26153846153846155
Test Recall for epoch 140 : 0.26153846153846155
Test F1 for epoch 140 : 0.26153846153846155


theta for epoch 141 : tensor([[ 2.2715,  2.2898,  2.3275,  2.4002,  2.3820,  2.2761,  2.3673,  2.2711,
          2.2711,  1.3632,  1.3659,  1.3649,  1.3683,  1.3622,  1.3704,  1.3637,
          1.3616,  1.3236,  1.3207,  1.2797,  1.2804,  1.3217,  1.3183,  1.3177,
          1.3201,  1.3169,  1.3169,  1.3026,  1.3460,  1.3397,  1.3427,  1.3462,
          1.3412,  1.3439,  1.2967,  1.3400,  1.7444,  1.7554,  1.7480,  1.7449,
          1.7521,  1.6931,  1.7459,  1.7330,  1.7449,  1.6335,  1.6155,  1.6113,
          1.6049,  1.6286,  1.6100,  1.6449,  1.6025,  1.6029],
        [ 1.3213,  1.3022,  1.1879,  1.2773,  1.3577,  1.3552,  1.3207,  1.3543,
          1.3543,  2.1889,  2.1326,  2.1013,  2.2632,  2.1372,  2.9118,  2.1970,
          2.0985,  2.8707,  1.3005,  1.3351,  1.2795,  1.2609,  1.3678,  1.3682,
          1.3283,  1.3673,  1.3673,  1.3574,  1.2065,  1.3902,  1.3922,  1.2699,
          1.3918,  1.3945,  1.3593,  1.3902,  1.7817,  1.7983,  1.7456,  1.7375,
          1.7904,  1.7958,  1.7434,  1.4330,  1.7860,  1.5576,  1.6574,  1.6526,
          1.6458,  1.4984,  1.6513,  1.5215,  1.6432,  1.6437],
        [ 1.3088,  1.3117,  1.3156,  1.3137,  1.3116,  1.3096,  1.3084,  1.3087,
          1.3087,  1.3687,  1.3715,  1.3705,  1.3727,  1.3676,  1.3371,  1.3692,
          1.3485,  1.3374,  2.3545,  2.3386,  2.4113,  2.3708,  2.2730,  2.2802,
          2.3434,  2.2649,  2.2649,  1.3430,  1.3222,  1.3452,  1.3483,  1.3425,
          1.3468,  1.3496,  1.3450,  1.3455,  1.7479,  1.7591,  1.7515,  1.7380,
          1.7558,  1.7557,  1.7494,  1.6979,  1.7382,  1.6314,  1.6191,  1.6147,
          1.6082,  1.5903,  1.6135,  1.6307,  1.6057,  1.6062],
        [ 1.3202,  1.3232,  1.3241,  1.3222,  1.3233,  1.3210,  1.3212,  1.3202,
          1.3202,  1.3800,  1.3800,  1.3818,  1.3706,  1.3789,  1.2858,  1.3805,
          1.3780,  1.2784,  1.3380,  1.3252,  1.3400,  1.3390,  1.3355,  1.3340,
          1.3372,  1.3340,  1.3340,  2.4633,  2.4232,  2.2049,  2.3080,  2.4607,
          2.2136,  2.4146,  2.2327,  2.2066,  1.7554,  1.7669,  1.7399,  1.7554,
          1.7634,  1.7629,  1.7391,  1.6755,  1.7552,  1.6465,  1.6264,  1.5156,
          1.5619,  1.6414,  1.6184,  1.6585,  1.5594,  1.6142],
        [ 1.8266,  1.4306,  0.5915,  0.8921,  1.2893,  1.7291,  1.6268,  1.8354,
          1.8354,  1.7149,  1.3031,  1.5142,  0.8960,  1.7520,  0.1226,  1.6460,
          1.8269,  0.9174,  1.3280,  0.9135,  0.6947,  1.1540,  1.6696,  1.7404,
          1.4796,  1.8425,  1.8425,  0.7874,  0.8624,  1.8162,  1.5989,  0.8325,
          1.7572,  1.2260,  1.8651,  1.7806,  0.1048, -0.1724, -0.2061,  0.0577,
          0.3648,  0.4819, -0.0384,  9.4803,  6.2484,  0.1685,  0.5416,  0.5801,
          0.6835,  0.3466,  0.6818, -0.1298,  0.7081,  0.7802],
        [ 1.3305,  1.3692,  1.4176,  1.4046,  1.3793,  1.3407,  1.3095,  1.3294,
          1.3294,  1.2872,  1.4139,  1.3108,  1.4451,  1.3627,  1.4711,  1.2946,
          1.3543,  1.3485,  1.3842,  1.4044,  1.4211,  1.3967,  1.3527,  1.3441,
          1.2857,  1.3339,  1.3339,  1.3931,  1.4315,  1.3495,  1.1752,  1.3470,
          1.2386,  1.4060,  1.2288,  1.3538,  0.3391,  0.2658,  0.3890,  0.3476,
          0.1509,  0.1051,  0.3628,  0.1733, -0.0318,  2.7703,  2.0457,  2.6854,
          2.2983,  1.6945,  1.3368,  2.5440,  2.4695,  1.3021]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 141 : 176.5008314627286
Test loss for epoch 141 : 176.27118724961898
Test Precision for epoch 141 : 0.26153846153846155
Test Recall for epoch 141 : 0.26153846153846155
Test F1 for epoch 141 : 0.26153846153846155


theta for epoch 142 : tensor([[ 2.2754,  2.2937,  2.3314,  2.4044,  2.3862,  2.2800,  2.3715,  2.2750,
          2.2750,  1.3632,  1.3659,  1.3649,  1.3683,  1.3622,  1.3704,  1.3637,
          1.3616,  1.3236,  1.3211,  1.2801,  1.2808,  1.3222,  1.3187,  1.3182,
          1.3206,  1.3173,  1.3173,  1.3022,  1.3456,  1.3393,  1.3424,  1.3458,
          1.3409,  1.3436,  1.2963,  1.3396,  1.7452,  1.7562,  1.7488,  1.7458,
          1.7530,  1.6940,  1.7468,  1.7338,  1.7457,  1.6296,  1.6116,  1.6074,
          1.6009,  1.6247,  1.6061,  1.6411,  1.5986,  1.5990],
        [ 1.3211,  1.3029,  1.1886,  1.2769,  1.3570,  1.3545,  1.3207,  1.3536,
          1.3536,  2.1959,  2.1382,  2.1064,  2.2670,  2.1425,  2.9097,  2.2023,
          2.1052,  2.8698,  1.3017,  1.3358,  1.2805,  1.2621,  1.3682,  1.3685,
          1.3286,  1.3676,  1.3676,  1.3572,  1.2068,  1.3895,  1.3917,  1.2701,
          1.3912,  1.3939,  1.3588,  1.3896,  1.7823,  1.7987,  1.7462,  1.7388,
          1.7911,  1.7963,  1.7441,  1.4370,  1.7864,  1.5546,  1.6530,  1.6482,
          1.6415,  1.4954,  1.6470,  1.5190,  1.6388,  1.6394],
        [ 1.3085,  1.3114,  1.3152,  1.3134,  1.3113,  1.3092,  1.3081,  1.3084,
          1.3084,  1.3687,  1.3716,  1.3706,  1.3728,  1.3677,  1.3374,  1.3693,
          1.3483,  1.3379,  2.3587,  2.3431,  2.4153,  2.3747,  2.2777,  2.2846,
          2.3475,  2.2696,  2.2696,  1.3424,  1.3221,  1.3448,  1.3479,  1.3420,
          1.3464,  1.3491,  1.3446,  1.3451,  1.7487,  1.7599,  1.7523,  1.7386,
          1.7566,  1.7565,  1.7503,  1.6996,  1.7388,  1.6277,  1.6151,  1.6107,
          1.6042,  1.5869,  1.6095,  1.6269,  1.6017,  1.6022],
        [ 1.3200,  1.3229,  1.3239,  1.3220,  1.3230,  1.3207,  1.3209,  1.3199,
          1.3199,  1.3800,  1.3802,  1.3819,  1.3706,  1.3790,  1.2857,  1.3806,
          1.3781,  1.2785,  1.3385,  1.3256,  1.3405,  1.3395,  1.3359,  1.3345,
          1.3376,  1.3345,  1.3345,  2.4677,  2.4273,  2.2085,  2.3119,  2.4650,
          2.2173,  2.4185,  2.2366,  2.2102,  1.7563,  1.7678,  1.7406,  1.7563,
          1.7643,  1.7638,  1.7398,  1.6767,  1.7561,  1.6429,  1.6227,  1.5119,
          1.5582,  1.6377,  1.6148,  1.6548,  1.5557,  1.6105],
        [ 1.8222,  1.4241,  0.5837,  0.8856,  1.2833,  1.7246,  1.6214,  1.8314,
          1.8314,  1.7091,  1.2953,  1.5076,  0.8874,  1.7456,  0.1126,  1.6396,
          1.8218,  0.9067,  1.3207,  0.9060,  0.6859,  1.1462,  1.6639,  1.7349,
          1.4739,  1.8375,  1.8375,  0.7790,  0.8536,  1.8105,  1.5926,  0.8233,
          1.7511,  1.2184,  1.8596,  1.7747,  0.1094, -0.1678, -0.2015,  0.0626,
          0.3689,  0.4854, -0.0339,  9.5442,  6.2649,  0.1574,  0.5310,  0.5693,
          0.6725,  0.3352,  0.6708, -0.1408,  0.6973,  0.7693],
        [ 1.3393,  1.3779,  1.4261,  1.4131,  1.3878,  1.3494,  1.3184,  1.3383,
          1.3383,  1.2995,  1.4257,  1.3231,  1.4570,  1.3747,  1.4832,  1.3069,
          1.3663,  1.3607,  1.3965,  1.4166,  1.4333,  1.4091,  1.3651,  1.3566,
          1.2982,  1.3464,  1.3464,  1.4023,  1.4404,  1.3588,  1.1850,  1.3562,
          1.2482,  1.4150,  1.2386,  1.3630,  0.3513,  0.2780,  0.4010,  0.3597,
          0.1633,  0.1176,  0.3750,  0.1854, -0.0196,  2.7616,  2.0352,  2.6782,
          2.2881,  1.6833,  1.3251,  2.5336,  2.4623,  1.2904]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 142 : 176.50143933629195
Test loss for epoch 142 : 176.2902968407621
Test Precision for epoch 142 : 0.26153846153846155
Test Recall for epoch 142 : 0.26153846153846155
Test F1 for epoch 142 : 0.26153846153846155


theta for epoch 143 : tensor([[ 2.2786,  2.2969,  2.3346,  2.4079,  2.3897,  2.2832,  2.3750,  2.2782,
          2.2782,  1.3625,  1.3653,  1.3643,  1.3677,  1.3615,  1.3698,  1.3631,
          1.3609,  1.3230,  1.3200,  1.2790,  1.2797,  1.3211,  1.3176,  1.3171,
          1.3195,  1.3162,  1.3162,  1.3020,  1.3454,  1.3391,  1.3422,  1.3456,
          1.3407,  1.3434,  1.2961,  1.3394,  1.7441,  1.7551,  1.7477,  1.7446,
          1.7519,  1.6929,  1.7456,  1.7327,  1.7445,  1.6325,  1.6146,  1.6103,
          1.6039,  1.6276,  1.6091,  1.6439,  1.6015,  1.6020],
        [ 1.3205,  1.3033,  1.1890,  1.2762,  1.3561,  1.3535,  1.3204,  1.3526,
          1.3526,  2.2023,  2.1433,  2.1110,  2.2704,  2.1471,  2.9074,  2.2072,
          2.1113,  2.8685,  1.3009,  1.3346,  1.2796,  1.2614,  1.3665,  1.3668,
          1.3271,  1.3659,  1.3659,  1.3570,  1.2070,  1.3889,  1.3910,  1.2703,
          1.3905,  1.3932,  1.3582,  1.3889,  1.7810,  1.7971,  1.7448,  1.7380,
          1.7897,  1.7947,  1.7427,  1.4391,  1.7848,  1.5590,  1.6559,  1.6511,
          1.6444,  1.4996,  1.6499,  1.5236,  1.6417,  1.6423],
        [ 1.3079,  1.3108,  1.3146,  1.3128,  1.3107,  1.3087,  1.3076,  1.3078,
          1.3078,  1.3680,  1.3709,  1.3699,  1.3722,  1.3670,  1.3371,  1.3686,
          1.3474,  1.3377,  2.3614,  2.3461,  2.4179,  2.3772,  2.2809,  2.2875,
          2.3503,  2.2727,  2.2727,  1.3421,  1.3222,  1.3445,  1.3476,  1.3416,
          1.3461,  1.3489,  1.3443,  1.3448,  1.7475,  1.7587,  1.7511,  1.7372,
          1.7554,  1.7553,  1.7490,  1.6992,  1.7374,  1.6307,  1.6179,  1.6136,
          1.6070,  1.5903,  1.6124,  1.6298,  1.6046,  1.6051],
        [ 1.3194,  1.3224,  1.3234,  1.3215,  1.3224,  1.3202,  1.3203,  1.3193,
          1.3193,  1.3793,  1.3795,  1.3811,  1.3697,  1.3782,  1.2848,  1.3798,
          1.3773,  1.2778,  1.3373,  1.3243,  1.3393,  1.3384,  1.3348,  1.3334,
          1.3365,  1.3333,  1.3333,  2.4717,  2.4312,  2.2118,  2.3153,  2.4691,
          2.2205,  2.4222,  2.2403,  2.2135,  1.7550,  1.7666,  1.7392,  1.7551,
          1.7631,  1.7626,  1.7383,  1.6757,  1.7549,  1.6455,  1.6255,  1.5147,
          1.5610,  1.6404,  1.6176,  1.6575,  1.5584,  1.6133],
        [ 1.8287,  1.4320,  0.5941,  0.8954,  1.2926,  1.7320,  1.6287,  1.8382,
          1.8382,  1.7175,  1.3056,  1.5162,  0.8984,  1.7532,  0.1246,  1.6477,
          1.8299,  0.9174,  1.3299,  0.9169,  0.6976,  1.1560,  1.6725,  1.7430,
          1.4827,  1.8452,  1.8452,  0.7910,  0.8649,  1.8193,  1.6024,  0.8355,
          1.7603,  1.2293,  1.8682,  1.7837,  0.0972, -0.1791, -0.2127,  0.0507,
          0.3556,  0.4714, -0.0456,  9.5901,  6.2602,  0.1718,  0.5450,  0.5834,
          0.6868,  0.3492,  0.6850, -0.1262,  0.7114,  0.7834],
        [ 1.3301,  1.3688,  1.4171,  1.4040,  1.3787,  1.3402,  1.3091,  1.3290,
          1.3290,  1.2872,  1.4138,  1.3108,  1.4451,  1.3629,  1.4711,  1.2948,
          1.3543,  1.3487,  1.3841,  1.4040,  1.4210,  1.3968,  1.3526,  1.3441,
          1.2851,  1.3338,  1.3338,  1.3927,  1.4312,  1.3492,  1.1744,  1.3468,
          1.2385,  1.4056,  1.2285,  1.3535,  0.3394,  0.2658,  0.3891,  0.3478,
          0.1508,  0.1051,  0.3631,  0.1726, -0.0328,  2.7806,  2.0527,  2.6993,
          2.3059,  1.6998,  1.3412,  2.5508,  2.4833,  1.3064]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 143 : 176.47974542119445
Test loss for epoch 143 : 176.2521222324384
Test Precision for epoch 143 : 0.26153846153846155
Test Recall for epoch 143 : 0.26153846153846155
Test F1 for epoch 143 : 0.26153846153846155


theta for epoch 144 : tensor([[ 2.2821,  2.3005,  2.3381,  2.4117,  2.3935,  2.2867,  2.3789,  2.2817,
          2.2817,  1.3626,  1.3654,  1.3644,  1.3678,  1.3616,  1.3699,  1.3632,
          1.3610,  1.3231,  1.3205,  1.2794,  1.2801,  1.3215,  1.3181,  1.3175,
          1.3199,  1.3167,  1.3167,  1.3017,  1.3451,  1.3388,  1.3419,  1.3453,
          1.3403,  1.3431,  1.2958,  1.3391,  1.7450,  1.7560,  1.7486,  1.7455,
          1.7528,  1.6938,  1.7465,  1.7336,  1.7454,  1.6294,  1.6113,  1.6071,
          1.6007,  1.6244,  1.6058,  1.6408,  1.5983,  1.5987],
        [ 1.3204,  1.3041,  1.1897,  1.2758,  1.3555,  1.3529,  1.3205,  1.3520,
          1.3520,  2.2087,  2.1485,  2.1155,  2.2738,  2.1517,  2.9054,  2.2120,
          2.1174,  2.8674,  1.3020,  1.3352,  1.2805,  1.2626,  1.3668,  1.3670,
          1.3274,  1.3661,  1.3661,  1.3568,  1.2073,  1.3883,  1.3905,  1.2704,
          1.3899,  1.3926,  1.3578,  1.3883,  1.7816,  1.7975,  1.7455,  1.7392,
          1.7904,  1.7952,  1.7433,  1.4430,  1.7852,  1.5566,  1.6522,  1.6474,
          1.6407,  1.4973,  1.6462,  1.5217,  1.6380,  1.6386],
        [ 1.3076,  1.3105,  1.3143,  1.3125,  1.3104,  1.3083,  1.3073,  1.3075,
          1.3075,  1.3681,  1.3710,  1.3700,  1.3723,  1.3671,  1.3374,  1.3687,
          1.3473,  1.3383,  2.3652,  2.3502,  2.4215,  2.3807,  2.2852,  2.2915,
          2.3541,  2.2770,  2.2770,  1.3415,  1.3221,  1.3441,  1.3472,  1.3411,
          1.3456,  1.3484,  1.3439,  1.3444,  1.7483,  1.7596,  1.7520,  1.7379,
          1.7562,  1.7561,  1.7499,  1.7009,  1.7380,  1.6276,  1.6146,  1.6102,
          1.6037,  1.5876,  1.6090,  1.6266,  1.6012,  1.6017],
        [ 1.3191,  1.3221,  1.3232,  1.3214,  1.3221,  1.3199,  1.3201,  1.3190,
          1.3190,  1.3794,  1.3798,  1.3813,  1.3698,  1.3784,  1.2849,  1.3800,
          1.3775,  1.2780,  1.3378,  1.3246,  1.3398,  1.3388,  1.3352,  1.3339,
          1.3369,  1.3338,  1.3338,  2.4756,  2.4349,  2.2149,  2.3187,  2.4730,
          2.2237,  2.4257,  2.2438,  2.2166,  1.7560,  1.7676,  1.7399,  1.7560,
          1.7641,  1.7636,  1.7390,  1.6770,  1.7558,  1.6425,  1.6224,  1.5117,
          1.5579,  1.6373,  1.6147,  1.6545,  1.5554,  1.6102],
        [ 1.8243,  1.4258,  0.5867,  0.8892,  1.2868,  1.7276,  1.6236,  1.8342,
          1.8342,  1.7119,  1.2982,  1.5098,  0.8903,  1.7470,  0.1152,  1.6416,
          1.8251,  0.9073,  1.3228,  0.9099,  0.6894,  1.1485,  1.6670,  1.7376,
          1.4771,  1.8404,  1.8404,  0.7830,  0.8566,  1.8137,  1.5963,  0.8269,
          1.7543,  1.2220,  1.8628,  1.7780,  0.1016, -0.1747, -0.2083,  0.0553,
          0.3595,  0.4748, -0.0413,  9.6524,  6.2752,  0.1617,  0.5355,  0.5737,
          0.6770,  0.3389,  0.6751, -0.1362,  0.7018,  0.7736],
        [ 1.3382,  1.3768,  1.4249,  1.4119,  1.3866,  1.3482,  1.3173,  1.3371,
          1.3371,  1.2983,  1.4245,  1.3219,  1.4559,  1.3738,  1.4820,  1.3059,
          1.3651,  1.3597,  1.3953,  1.4149,  1.4321,  1.4079,  1.3638,  1.3554,
          1.2963,  1.3451,  1.3451,  1.4011,  1.4394,  1.3577,  1.1834,  1.3552,
          1.2473,  1.4139,  1.2375,  1.3620,  0.3506,  0.2770,  0.4002,  0.3589,
          0.1622,  0.1165,  0.3743,  0.1837, -0.0216,  2.7732,  2.0436,  2.6934,
          2.2970,  1.6900,  1.3309,  2.5418,  2.4774,  1.2961]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 144 : 176.4436299176097
Test loss for epoch 144 : 176.233262789587
Test Precision for epoch 144 : 0.26153846153846155
Test Recall for epoch 144 : 0.26153846153846155
Test F1 for epoch 144 : 0.26153846153846155


theta for epoch 145 : tensor([[ 2.2851,  2.3036,  2.3412,  2.4151,  2.3969,  2.2897,  2.3823,  2.2847,
          2.2847,  1.3622,  1.3651,  1.3640,  1.3675,  1.3613,  1.3696,  1.3628,
          1.3606,  1.3228,  1.3197,  1.2787,  1.2794,  1.3208,  1.3173,  1.3168,
          1.3192,  1.3159,  1.3159,  1.3014,  1.3448,  1.3386,  1.3416,  1.3451,
          1.3401,  1.3428,  1.2956,  1.3389,  1.7443,  1.7553,  1.7479,  1.7448,
          1.7521,  1.6931,  1.7458,  1.7328,  1.7447,  1.6315,  1.6134,  1.6091,
          1.6028,  1.6265,  1.6079,  1.6429,  1.6004,  1.6008],
        [ 1.3202,  1.3047,  1.1905,  1.2754,  1.3548,  1.3522,  1.3205,  1.3513,
          1.3513,  2.2146,  2.1532,  2.1196,  2.2770,  2.1559,  2.9031,  2.2164,
          2.1231,  2.8660,  1.3016,  1.3344,  1.2800,  1.2622,  1.3656,  1.3657,
          1.3262,  1.3649,  1.3649,  1.3565,  1.2075,  1.3876,  1.3898,  1.2705,
          1.3892,  1.3919,  1.3572,  1.3876,  1.7806,  1.7964,  1.7444,  1.7388,
          1.7894,  1.7940,  1.7423,  1.4454,  1.7840,  1.5600,  1.6541,  1.6494,
          1.6426,  1.5006,  1.6481,  1.5254,  1.6400,  1.6406],
        [ 1.3073,  1.3102,  1.3140,  1.3122,  1.3101,  1.3080,  1.3070,  1.3072,
          1.3072,  1.3676,  1.3706,  1.3695,  1.3719,  1.3666,  1.3372,  1.3682,
          1.3466,  1.3383,  2.3677,  2.3532,  2.4239,  2.3830,  2.2882,  2.2943,
          2.3566,  2.2800,  2.2800,  1.3410,  1.3220,  1.3437,  1.3468,  1.3407,
          1.3453,  1.3481,  1.3436,  1.3440,  1.7475,  1.7588,  1.7511,  1.7369,
          1.7555,  1.7554,  1.7490,  1.7009,  1.7370,  1.6297,  1.6166,  1.6122,
          1.6057,  1.5901,  1.6110,  1.6286,  1.6032,  1.6037],
        [ 1.3189,  1.3219,  1.3231,  1.3213,  1.3219,  1.3197,  1.3198,  1.3188,
          1.3188,  1.3790,  1.3795,  1.3809,  1.3693,  1.3780,  1.2844,  1.3796,
          1.3771,  1.2777,  1.3371,  1.3239,  1.3391,  1.3381,  1.3345,  1.3332,
          1.3362,  1.3331,  1.3331,  2.4791,  2.4380,  2.2176,  2.3215,  2.4765,
          2.2263,  2.4287,  2.2468,  2.2192,  1.7552,  1.7668,  1.7390,  1.7552,
          1.7634,  1.7629,  1.7380,  1.6765,  1.7551,  1.6445,  1.6244,  1.5137,
          1.5600,  1.6393,  1.6167,  1.6564,  1.5574,  1.6122],
        [ 1.8289,  1.4312,  0.5938,  0.8961,  1.2933,  1.7329,  1.6287,  1.8392,
          1.8392,  1.7177,  1.3052,  1.5156,  0.8977,  1.7521,  0.1233,  1.6471,
          1.8308,  0.9141,  1.3290,  0.9175,  0.6974,  1.1551,  1.6729,  1.7432,
          1.4833,  1.8458,  1.8458,  0.7912,  0.8641,  1.8197,  1.6031,  0.8350,
          1.7605,  1.2294,  1.8686,  1.7841,  0.0925, -0.1830, -0.2166,  0.0466,
          0.3495,  0.4643, -0.0500,  9.7004,  6.2733,  0.1715,  0.5450,  0.5834,
          0.6867,  0.3483,  0.6848, -0.1263,  0.7115,  0.7833],
        [ 1.3320,  1.3707,  1.4188,  1.4058,  1.3804,  1.3420,  1.3110,  1.3308,
          1.3308,  1.2900,  1.4166,  1.3137,  1.4478,  1.3659,  1.4739,  1.2977,
          1.3570,  1.3517,  1.3870,  1.4064,  1.4239,  1.3997,  1.3554,  1.3470,
          1.2875,  1.3367,  1.3367,  1.3944,  1.4330,  1.3511,  1.1760,  1.3487,
          1.2406,  1.4073,  1.2306,  1.3553,  0.3427,  0.2689,  0.3923,  0.3510,
          0.1539,  0.1082,  0.3665,  0.1752, -0.0305,  2.7875,  2.0563,  2.7095,
          2.3100,  1.7018,  1.3422,  2.5543,  2.4934,  1.3074]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 145 : 176.39768760683364
Test loss for epoch 145 : 176.1769718711273
Test Precision for epoch 145 : 0.26153846153846155
Test Recall for epoch 145 : 0.26153846153846155
Test F1 for epoch 145 : 0.26153846153846155


theta for epoch 146 : tensor([[ 2.2883,  2.3068,  2.3443,  2.4186,  2.4004,  2.2929,  2.3858,  2.2879,
          2.2879,  1.3623,  1.3652,  1.3641,  1.3676,  1.3614,  1.3697,  1.3629,
          1.3607,  1.3229,  1.3200,  1.2789,  1.2796,  1.3210,  1.3175,  1.3170,
          1.3194,  1.3161,  1.3161,  1.3014,  1.3447,  1.3385,  1.3415,  1.3450,
          1.3400,  1.3427,  1.2955,  1.3388,  1.7447,  1.7557,  1.7482,  1.7452,
          1.7525,  1.6935,  1.7462,  1.7332,  1.7450,  1.6299,  1.6118,  1.6076,
          1.6012,  1.6249,  1.6063,  1.6413,  1.5988,  1.5992],
        [ 1.3202,  1.3056,  1.1914,  1.2753,  1.3544,  1.3518,  1.3207,  1.3509,
          1.3509,  2.2206,  2.1580,  2.1237,  2.2802,  2.1600,  2.9011,  2.2208,
          2.1288,  2.8649,  1.3023,  1.3346,  1.2805,  1.2630,  1.3655,  1.3656,
          1.3262,  1.3647,  1.3647,  1.3565,  1.2080,  1.3871,  1.3894,  1.2708,
          1.3887,  1.3915,  1.3568,  1.3871,  1.7806,  1.7962,  1.7445,  1.7394,
          1.7895,  1.7939,  1.7423,  1.4488,  1.7839,  1.5593,  1.6520,  1.6473,
          1.6406,  1.4999,  1.6461,  1.5250,  1.6379,  1.6385],
        [ 1.3071,  1.3101,  1.3138,  1.3120,  1.3100,  1.3079,  1.3069,  1.3070,
          1.3070,  1.3676,  1.3705,  1.3695,  1.3719,  1.3666,  1.3374,  1.3682,
          1.3464,  1.3387,  2.3709,  2.3567,  2.4270,  2.3859,  2.2918,  2.2977,
          2.3598,  2.2836,  2.2836,  1.3407,  1.3221,  1.3435,  1.3466,  1.3404,
          1.3451,  1.3479,  1.3433,  1.3438,  1.7478,  1.7590,  1.7514,  1.7370,
          1.7557,  1.7557,  1.7493,  1.7019,  1.7370,  1.6282,  1.6148,  1.6105,
          1.6040,  1.5889,  1.6093,  1.6269,  1.6015,  1.6020],
        [ 1.3188,  1.3218,  1.3231,  1.3213,  1.3218,  1.3196,  1.3198,  1.3187,
          1.3187,  1.3791,  1.3797,  1.3811,  1.3693,  1.3781,  1.2844,  1.3797,
          1.3772,  1.2778,  1.3372,  1.3239,  1.3392,  1.3383,  1.3347,  1.3334,
          1.3364,  1.3333,  1.3333,  2.4827,  2.4414,  2.2204,  2.3246,  2.4801,
          2.2291,  2.4319,  2.2499,  2.2221,  1.7556,  1.7672,  1.7392,  1.7556,
          1.7637,  1.7633,  1.7381,  1.6771,  1.7554,  1.6430,  1.6229,  1.5123,
          1.5585,  1.6378,  1.6153,  1.6549,  1.5558,  1.6107],
        [ 1.8278,  1.4293,  0.5917,  0.8946,  1.2920,  1.7321,  1.6273,  1.8385,
          1.8385,  1.7162,  1.3029,  1.5136,  0.8952,  1.7500,  0.1202,  1.6451,
          1.8298,  0.9102,  1.3268,  0.9157,  0.6950,  1.1527,  1.6716,  1.7419,
          1.4820,  1.8446,  1.8446,  0.7891,  0.8616,  1.8184,  1.6017,  0.8326,
          1.7590,  1.2275,  1.8673,  1.7826,  0.0921, -0.1832, -0.2168,  0.0464,
          0.3485,  0.4629, -0.0503,  9.7571,  6.2813,  0.1684,  0.5422,  0.5806,
          0.6838,  0.3449,  0.6818, -0.1292,  0.7087,  0.7804],
        [ 1.3348,  1.3734,  1.4215,  1.4084,  1.3831,  1.3447,  1.3139,  1.3336,
          1.3336,  1.2938,  1.4202,  1.3175,  1.4515,  1.3697,  1.4776,  1.3015,
          1.3607,  1.3556,  1.3908,  1.4100,  1.4277,  1.4035,  1.3592,  1.3509,
          1.2911,  1.3405,  1.3405,  1.3972,  1.4358,  1.3540,  1.1789,  1.3516,
          1.2436,  1.4101,  1.2336,  1.3582,  0.3467,  0.2727,  0.3961,  0.3549,
          0.1577,  0.1120,  0.3704,  0.1788, -0.0270,  2.7882,  2.0553,  2.7117,
          2.3093,  1.7000,  1.3400,  2.5533,  2.4957,  1.3051]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 146 : 176.36572186069333
Test loss for epoch 146 : 176.15212578546848
Test Precision for epoch 146 : 0.26153846153846155
Test Recall for epoch 146 : 0.26153846153846155
Test F1 for epoch 146 : 0.26153846153846155


theta for epoch 147 : tensor([[ 2.2915,  2.3100,  2.3475,  2.4221,  2.4039,  2.2960,  2.3893,  2.2911,
          2.2911,  1.3623,  1.3651,  1.3641,  1.3675,  1.3613,  1.3697,  1.3629,
          1.3607,  1.3229,  1.3199,  1.2788,  1.2795,  1.3209,  1.3175,  1.3169,
          1.3193,  1.3161,  1.3161,  1.3014,  1.3447,  1.3385,  1.3415,  1.3450,
          1.3400,  1.3427,  1.2955,  1.3388,  1.7447,  1.7557,  1.7483,  1.7452,
          1.7525,  1.6935,  1.7462,  1.7332,  1.7450,  1.6291,  1.6111,  1.6068,
          1.6005,  1.6242,  1.6056,  1.6406,  1.5980,  1.5985],
        [ 1.3201,  1.3062,  1.1922,  1.2749,  1.3539,  1.3512,  1.3208,  1.3503,
          1.3503,  2.2267,  2.1629,  2.1279,  2.2836,  2.1644,  2.8995,  2.2254,
          2.1347,  2.8640,  1.3025,  1.3344,  1.2806,  1.2633,  1.3649,  1.3650,
          1.3258,  1.3641,  1.3641,  1.3565,  1.2085,  1.3867,  1.3891,  1.2711,
          1.3883,  1.3911,  1.3565,  1.3867,  1.7803,  1.7957,  1.7442,  1.7397,
          1.7891,  1.7934,  1.7420,  1.4518,  1.7834,  1.5594,  1.6508,  1.6461,
          1.6394,  1.5001,  1.6449,  1.5254,  1.6367,  1.6373],
        [ 1.3069,  1.3098,  1.3136,  1.3118,  1.3097,  1.3076,  1.3067,  1.3068,
          1.3068,  1.3674,  1.3704,  1.3693,  1.3717,  1.3664,  1.3374,  1.3680,
          1.3459,  1.3390,  2.3741,  2.3603,  2.4301,  2.3889,  2.2955,  2.3011,
          2.3631,  2.2873,  2.2873,  1.3404,  1.3223,  1.3434,  1.3465,  1.3401,
          1.3449,  1.3478,  1.3432,  1.3437,  1.7477,  1.7589,  1.7513,  1.7367,
          1.7557,  1.7556,  1.7492,  1.7026,  1.7367,  1.6275,  1.6140,  1.6096,
          1.6031,  1.5886,  1.6084,  1.6261,  1.6006,  1.6011],
        [ 1.3187,  1.3217,  1.3230,  1.3212,  1.3217,  1.3194,  1.3196,  1.3186,
          1.3186,  1.3790,  1.3796,  1.3810,  1.3692,  1.3780,  1.2842,  1.3796,
          1.3770,  1.2778,  1.3371,  1.3237,  1.3390,  1.3381,  1.3345,  1.3333,
          1.3362,  1.3331,  1.3331,  2.4866,  2.4451,  2.2235,  2.3279,  2.4840,
          2.2322,  2.4353,  2.2534,  2.2252,  1.7555,  1.7672,  1.7390,  1.7555,
          1.7638,  1.7633,  1.7379,  1.6773,  1.7554,  1.6422,  1.6222,  1.5115,
          1.5577,  1.6370,  1.6146,  1.6541,  1.5551,  1.6100],
        [ 1.8284,  1.4295,  0.5922,  0.8956,  1.2930,  1.7331,  1.6278,  1.8395,
          1.8395,  1.7169,  1.3034,  1.5140,  0.8956,  1.7501,  0.1204,  1.6455,
          1.8308,  0.9094,  1.3271,  0.9167,  0.6957,  1.1530,  1.6725,  1.7427,
          1.4829,  1.8455,  1.8455,  0.7901,  0.8621,  1.8193,  1.6028,  0.8333,
          1.7600,  1.2284,  1.8683,  1.7836,  0.0891, -0.1857, -0.2193,  0.0438,
          0.3450,  0.4589, -0.0531,  9.8111,  6.2859,  0.1689,  0.5428,  0.5811,
          0.6844,  0.3451,  0.6823, -0.1285,  0.7093,  0.7809],
        [ 1.3351,  1.3737,  1.4217,  1.4087,  1.3833,  1.3450,  1.3142,  1.3339,
          1.3339,  1.2942,  1.4206,  1.3180,  1.4519,  1.3702,  1.4781,  1.3020,
          1.3610,  1.3562,  1.3912,  1.4103,  1.4281,  1.4040,  1.3596,  1.3513,
          1.2913,  1.3410,  1.3410,  1.3975,  1.4361,  1.3544,  1.1790,  1.3520,
          1.2441,  1.4105,  1.2340,  1.3586,  0.3472,  0.2731,  0.3965,  0.3554,
          0.1580,  0.1124,  0.3709,  0.1789, -0.0270,  2.7926,  2.0581,  2.7178,
          2.3124,  1.7019,  1.3414,  2.5561,  2.5017,  1.3066]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 147 : 176.35464597891945
Test loss for epoch 147 : 176.14320368537548
Test Precision for epoch 147 : 0.26153846153846155
Test Recall for epoch 147 : 0.26153846153846155
Test F1 for epoch 147 : 0.26153846153846155


theta for epoch 148 : tensor([[ 2.2949,  2.3135,  2.3509,  2.4258,  2.4076,  2.2994,  2.3930,  2.2945,
          2.2945,  1.3619,  1.3648,  1.3638,  1.3672,  1.3610,  1.3693,  1.3625,
          1.3603,  1.3225,  1.3192,  1.2782,  1.2789,  1.3203,  1.3168,  1.3163,
          1.3187,  1.3154,  1.3154,  1.3012,  1.3445,  1.3383,  1.3413,  1.3448,
          1.3398,  1.3425,  1.2953,  1.3386,  1.7442,  1.7552,  1.7478,  1.7447,
          1.7521,  1.6931,  1.7457,  1.7327,  1.7445,  1.6299,  1.6118,  1.6075,
          1.6012,  1.6250,  1.6063,  1.6413,  1.5988,  1.5993],
        [ 1.3199,  1.3067,  1.1929,  1.2744,  1.3531,  1.3505,  1.3207,  1.3496,
          1.3496,  2.2331,  2.1682,  2.1324,  2.2875,  2.1690,  2.8983,  2.2303,
          2.1410,  2.8635,  1.3021,  1.3335,  1.2800,  1.2630,  1.3637,  1.3638,
          1.3246,  1.3629,  1.3629,  1.3561,  1.2087,  1.3861,  1.3885,  1.2712,
          1.3877,  1.3905,  1.3560,  1.3861,  1.7795,  1.7948,  1.7434,  1.7395,
          1.7883,  1.7925,  1.7412,  1.4543,  1.7824,  1.5611,  1.6511,  1.6464,
          1.6398,  1.5018,  1.6453,  1.5274,  1.6370,  1.6377],
        [ 1.3064,  1.3094,  1.3131,  1.3113,  1.3093,  1.3072,  1.3063,  1.3063,
          1.3063,  1.3669,  1.3698,  1.3688,  1.3712,  1.3659,  1.3370,  1.3675,
          1.3452,  1.3389,  2.3774,  2.3641,  2.4334,  2.3920,  2.2993,  2.3047,
          2.3665,  2.2911,  2.2911,  1.3400,  1.3223,  1.3431,  1.3461,  1.3397,
          1.3446,  1.3474,  1.3429,  1.3434,  1.7471,  1.7584,  1.7507,  1.7360,
          1.7551,  1.7551,  1.7486,  1.7028,  1.7359,  1.6283,  1.6146,  1.6102,
          1.6038,  1.5897,  1.6091,  1.6268,  1.6012,  1.6018],
        [ 1.3183,  1.3213,  1.3227,  1.3209,  1.3213,  1.3191,  1.3192,  1.3182,
          1.3182,  1.3785,  1.3793,  1.3805,  1.3686,  1.3776,  1.2836,  1.3791,
          1.3766,  1.2774,  1.3363,  1.3228,  1.3383,  1.3374,  1.3338,  1.3326,
          1.3355,  1.3323,  1.3323,  2.4907,  2.4490,  2.2268,  2.3315,  2.4882,
          2.2356,  2.4391,  2.2571,  2.2285,  1.7550,  1.7667,  1.7383,  1.7550,
          1.7632,  1.7628,  1.7371,  1.6770,  1.7549,  1.6428,  1.6229,  1.5122,
          1.5584,  1.6377,  1.6153,  1.6548,  1.5557,  1.6106],
        [ 1.8314,  1.4329,  0.5967,  0.9001,  1.2973,  1.7367,  1.6311,  1.8429,
          1.8429,  1.7207,  1.3079,  1.5176,  0.9002,  1.7533,  0.1253,  1.6490,
          1.8348,  0.9132,  1.3310,  0.9217,  0.7009,  1.1571,  1.6765,  1.7465,
          1.4871,  1.8492,  1.8492,  0.7954,  0.8669,  1.8234,  1.6074,  0.8385,
          1.7642,  1.2333,  1.8723,  1.7877,  0.0826, -0.1916, -0.2252,  0.0375,
          0.3376,  0.4511, -0.0593,  9.8612,  6.2856,  0.1748,  0.5484,  0.5868,
          0.6901,  0.3505,  0.6880, -0.1224,  0.7150,  0.7866],
        [ 1.3318,  1.3705,  1.4185,  1.4054,  1.3800,  1.3416,  1.3108,  1.3306,
          1.3306,  1.2898,  1.4164,  1.3137,  1.4477,  1.3661,  1.4738,  1.2977,
          1.3567,  1.3520,  1.3868,  1.4057,  1.4238,  1.3996,  1.3552,  1.3469,
          1.2865,  1.3365,  1.3365,  1.3941,  1.4328,  1.3510,  1.1750,  1.3486,
          1.2406,  1.4071,  1.2304,  1.3552,  0.3428,  0.2685,  0.3921,  0.3510,
          0.1534,  0.1077,  0.3666,  0.1740, -0.0322,  2.8025,  2.0663,  2.7294,
          2.3209,  1.7092,  1.3482,  2.5642,  2.5132,  1.3134]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 148 : 176.35743696817488
Test loss for epoch 148 : 176.14090002850696
Test Precision for epoch 148 : 0.26153846153846155
Test Recall for epoch 148 : 0.26153846153846155
Test F1 for epoch 148 : 0.26153846153846155


theta for epoch 149 : tensor([[ 2.2988,  2.3174,  2.3548,  2.4300,  2.4118,  2.3033,  2.3973,  2.2984,
          2.2984,  1.3616,  1.3645,  1.3635,  1.3669,  1.3607,  1.3690,  1.3622,
          1.3600,  1.3222,  1.3191,  1.2780,  1.2787,  1.3201,  1.3167,  1.3161,
          1.3186,  1.3153,  1.3153,  1.3006,  1.3440,  1.3377,  1.3408,  1.3442,
          1.3392,  1.3420,  1.2947,  1.3380,  1.7447,  1.7558,  1.7483,  1.7452,
          1.7526,  1.6937,  1.7463,  1.7332,  1.7450,  1.6276,  1.6095,  1.6052,
          1.5989,  1.6226,  1.6040,  1.6390,  1.5964,  1.5969],
        [ 1.3197,  1.3072,  1.1935,  1.2740,  1.3525,  1.3498,  1.3206,  1.3489,
          1.3489,  2.2398,  2.1738,  2.1372,  2.2916,  2.1739,  2.8974,  2.2355,
          2.1475,  2.8634,  1.3025,  1.3334,  1.2802,  1.2634,  1.3634,  1.3634,
          1.3244,  1.3625,  1.3625,  1.3556,  1.2087,  1.3852,  1.3877,  1.2710,
          1.3868,  1.3896,  1.3552,  1.3852,  1.7797,  1.7948,  1.7436,  1.7404,
          1.7885,  1.7926,  1.7414,  1.4578,  1.7825,  1.5596,  1.6483,  1.6436,
          1.6370,  1.5004,  1.6424,  1.5261,  1.6342,  1.6349],
        [ 1.3060,  1.3089,  1.3127,  1.3109,  1.3089,  1.3067,  1.3059,  1.3059,
          1.3059,  1.3665,  1.3694,  1.3684,  1.3709,  1.3656,  1.3368,  1.3671,
          1.3446,  1.3389,  2.3815,  2.3687,  2.4375,  2.3960,  2.3039,  2.3091,
          2.3707,  2.2957,  2.2957,  1.3392,  1.3220,  1.3424,  1.3455,  1.3390,
          1.3440,  1.3468,  1.3423,  1.3428,  1.7475,  1.7589,  1.7512,  1.7362,
          1.7556,  1.7556,  1.7491,  1.7041,  1.7361,  1.6261,  1.6122,  1.6079,
          1.6014,  1.5879,  1.6067,  1.6245,  1.5989,  1.5994],
        [ 1.3180,  1.3210,  1.3224,  1.3206,  1.3209,  1.3187,  1.3189,  1.3178,
          1.3178,  1.3783,  1.3791,  1.3803,  1.3683,  1.3773,  1.2833,  1.3789,
          1.3763,  1.2772,  1.3363,  1.3226,  1.3382,  1.3373,  1.3337,  1.3325,
          1.3354,  1.3323,  1.3323,  2.4950,  2.4531,  2.2304,  2.3352,  2.4925,
          2.2391,  2.4429,  2.2610,  2.2321,  1.7556,  1.7672,  1.7387,  1.7556,
          1.7638,  1.7634,  1.7375,  1.6778,  1.7554,  1.6407,  1.6207,  1.5100,
          1.5562,  1.6355,  1.6132,  1.6526,  1.5535,  1.6085],
        [ 1.8290,  1.4292,  0.5921,  0.8965,  1.2941,  1.7345,  1.6281,  1.8409,
          1.8409,  1.7175,  1.3034,  1.5138,  0.8953,  1.7495,  0.1195,  1.6453,
          1.8323,  0.9067,  1.3267,  0.9178,  0.6961,  1.1526,  1.6735,  1.7436,
          1.4840,  1.8467,  1.8467,  0.7908,  0.8617,  1.8202,  1.6040,  0.8334,
          1.7607,  1.2290,  1.8692,  1.7844,  0.0843, -0.1897, -0.2233,  0.0395,
          0.3390,  0.4521, -0.0576,  9.9196,  6.2949,  0.1685,  0.5424,  0.5807,
          0.6839,  0.3439,  0.6818, -0.1285,  0.7090,  0.7804],
        [ 1.3375,  1.3760,  1.4239,  1.4108,  1.3855,  1.3473,  1.3166,  1.3362,
          1.3362,  1.2973,  1.4237,  1.3212,  1.4550,  1.3736,  1.4812,  1.3053,
          1.3641,  1.3596,  1.3945,  1.4131,  1.4313,  1.4073,  1.3629,  1.3546,
          1.2941,  1.3442,  1.3442,  1.3998,  1.4384,  1.3569,  1.1811,  1.3544,
          1.2467,  1.4128,  1.2366,  1.3610,  0.3502,  0.2760,  0.3994,  0.3584,
          0.1609,  0.1152,  0.3740,  0.1812, -0.0249,  2.7990,  2.0610,  2.7273,
          2.3160,  1.7031,  1.3417,  2.5591,  2.5111,  1.3068]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 149 : 176.3611001854799
Test loss for epoch 149 : 176.15660310807985
Test Precision for epoch 149 : 0.26153846153846155
Test Recall for epoch 149 : 0.26153846153846155
Test F1 for epoch 149 : 0.26153846153846155


theta for epoch 150 : tensor([[ 2.3023,  2.3210,  2.3583,  2.4338,  2.4156,  2.3069,  2.4012,  2.3019,
          2.3019,  1.3608,  1.3636,  1.3627,  1.3661,  1.3599,  1.3682,  1.3614,
          1.3592,  1.3213,  1.3179,  1.2768,  1.2775,  1.3189,  1.3155,  1.3149,
          1.3173,  1.3141,  1.3141,  1.2999,  1.3433,  1.3371,  1.3401,  1.3436,
          1.3386,  1.3413,  1.2940,  1.3374,  1.7439,  1.7550,  1.7476,  1.7445,
          1.7519,  1.6929,  1.7455,  1.7324,  1.7443,  1.6298,  1.6117,  1.6075,
          1.6012,  1.6249,  1.6063,  1.6412,  1.5987,  1.5993],
        [ 1.3192,  1.3074,  1.1939,  1.2733,  1.3515,  1.3488,  1.3203,  1.3479,
          1.3479,  2.2459,  2.1789,  2.1415,  2.2954,  2.1784,  2.8964,  2.2402,
          2.1535,  2.8631,  1.3016,  1.3321,  1.2792,  1.2627,  1.3618,  1.3618,
          1.3229,  1.3609,  1.3609,  1.3549,  1.2087,  1.3842,  1.3867,  1.2706,
          1.3858,  1.3886,  1.3543,  1.3842,  1.7786,  1.7936,  1.7426,  1.7399,
          1.7875,  1.7914,  1.7403,  1.4601,  1.7812,  1.5631,  1.6505,  1.6458,
          1.6391,  1.5039,  1.6446,  1.5298,  1.6364,  1.6370],
        [ 1.3054,  1.3083,  1.3121,  1.3103,  1.3083,  1.3061,  1.3054,  1.3053,
          1.3053,  1.3657,  1.3686,  1.3676,  1.3701,  1.3648,  1.3363,  1.3663,
          1.3436,  1.3386,  2.3845,  2.3721,  2.4405,  2.3988,  2.3074,  2.3123,
          2.3738,  2.2992,  2.2992,  1.3385,  1.3216,  1.3418,  1.3449,  1.3382,
          1.3434,  1.3462,  1.3417,  1.3422,  1.7468,  1.7581,  1.7504,  1.7352,
          1.7548,  1.7548,  1.7483,  1.7041,  1.7351,  1.6286,  1.6146,  1.6103,
          1.6038,  1.5907,  1.6091,  1.6269,  1.6013,  1.6018],
        [ 1.3174,  1.3204,  1.3219,  1.3201,  1.3203,  1.3181,  1.3183,  1.3173,
          1.3173,  1.3775,  1.3784,  1.3794,  1.3674,  1.3765,  1.2823,  1.3781,
          1.3755,  1.2764,  1.3351,  1.3214,  1.3371,  1.3362,  1.3326,  1.3315,
          1.3343,  1.3312,  1.3312,  2.4991,  2.4569,  2.2336,  2.3387,  2.4966,
          2.2423,  2.4466,  2.2646,  2.2353,  1.7548,  1.7665,  1.7377,  1.7547,
          1.7631,  1.7627,  1.7365,  1.6772,  1.7547,  1.6429,  1.6230,  1.5123,
          1.5584,  1.6377,  1.6155,  1.6548,  1.5558,  1.6108],
        [ 1.8339,  1.4351,  0.5998,  0.9038,  1.3011,  1.7401,  1.6337,  1.8462,
          1.8462,  1.7238,  1.3110,  1.5201,  0.9033,  1.7552,  0.1282,  1.6514,
          1.8385,  0.9142,  1.3336,  0.9260,  0.7048,  1.1599,  1.6801,  1.7499,
          1.4908,  1.8527,  1.8527,  0.7995,  0.8698,  1.8266,  1.6112,  0.8421,
          1.7674,  1.2369,  1.8755,  1.7909,  0.0749, -0.1983, -0.2319,  0.0304,
          0.3287,  0.4415, -0.0666,  9.9662,  6.2901,  0.1787,  0.5523,  0.5907,
          0.6940,  0.3537,  0.6918, -0.1180,  0.7189,  0.7903],
        [ 1.3311,  1.3697,  1.4176,  1.4044,  1.3791,  1.3408,  1.3101,  1.3298,
          1.3298,  1.2888,  1.4155,  1.3128,  1.4468,  1.3655,  1.4729,  1.2968,
          1.3557,  1.3515,  1.3860,  1.4044,  1.4229,  1.3989,  1.3543,  1.3461,
          1.2851,  1.3357,  1.3357,  1.3930,  1.4319,  1.3500,  1.1735,  1.3476,
          1.2397,  1.4061,  1.2294,  1.3542,  0.3419,  0.2674,  0.3910,  0.3500,
          0.1521,  0.1065,  0.3657,  0.1723, -0.0342,  2.8134,  2.0737,  2.7434,
          2.3290,  1.7149,  1.3531,  2.5717,  2.5272,  1.3181]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 150 : 176.35045037990272
Test loss for epoch 150 : 176.1348580793217
Test Precision for epoch 150 : 0.26153846153846155
Test Recall for epoch 150 : 0.26153846153846155
Test F1 for epoch 150 : 0.26153846153846155


theta for epoch 151 : tensor([[ 2.3059,  2.3246,  2.3619,  2.4377,  2.4195,  2.3104,  2.4051,  2.3054,
          2.3054,  1.3607,  1.3636,  1.3626,  1.3660,  1.3598,  1.3681,  1.3613,
          1.3591,  1.3212,  1.3181,  1.2770,  1.2777,  1.3191,  1.3157,  1.3151,
          1.3175,  1.3143,  1.3143,  1.2995,  1.3429,  1.3367,  1.3397,  1.3431,
          1.3382,  1.3409,  1.2936,  1.3370,  1.7448,  1.7558,  1.7484,  1.7453,
          1.7527,  1.6937,  1.7463,  1.7332,  1.7451,  1.6272,  1.6091,  1.6048,
          1.5986,  1.6223,  1.6037,  1.6386,  1.5961,  1.5966],
        [ 1.3190,  1.3078,  1.1946,  1.2729,  1.3509,  1.3482,  1.3202,  1.3473,
          1.3473,  2.2518,  2.1838,  2.1454,  2.2989,  2.1825,  2.8953,  2.2446,
          2.1593,  2.8626,  1.3025,  1.3325,  1.2799,  1.2637,  1.3620,  1.3620,
          1.3232,  1.3611,  1.3611,  1.3546,  1.2090,  1.3836,  1.3862,  1.2707,
          1.3852,  1.3880,  1.3537,  1.3836,  1.7791,  1.7940,  1.7431,  1.7411,
          1.7880,  1.7918,  1.7409,  1.4639,  1.7816,  1.5612,  1.6473,  1.6426,
          1.6360,  1.5023,  1.6415,  1.5282,  1.6333,  1.6340],
        [ 1.3050,  1.3079,  1.3116,  1.3098,  1.3079,  1.3057,  1.3050,  1.3049,
          1.3049,  1.3658,  1.3687,  1.3677,  1.3702,  1.3649,  1.3365,  1.3664,
          1.3434,  1.3391,  2.3879,  2.3760,  2.4439,  2.4020,  2.3113,  2.3160,
          2.3773,  2.3031,  2.3031,  1.3380,  1.3216,  1.3415,  1.3446,  1.3378,
          1.3430,  1.3459,  1.3413,  1.3418,  1.7476,  1.7589,  1.7513,  1.7359,
          1.7557,  1.7557,  1.7491,  1.7056,  1.7357,  1.6262,  1.6121,  1.6077,
          1.6013,  1.5887,  1.6066,  1.6244,  1.5987,  1.5993],
        [ 1.3169,  1.3199,  1.3215,  1.3197,  1.3199,  1.3177,  1.3179,  1.3168,
          1.3168,  1.3775,  1.3784,  1.3794,  1.3673,  1.3765,  1.2822,  1.3781,
          1.3755,  1.2764,  1.3354,  1.3216,  1.3373,  1.3364,  1.3329,  1.3317,
          1.3345,  1.3314,  1.3314,  2.5031,  2.4606,  2.2368,  2.3421,  2.5006,
          2.2456,  2.4501,  2.2682,  2.2385,  1.7556,  1.7673,  1.7384,  1.7556,
          1.7640,  1.7636,  1.7372,  1.6783,  1.7555,  1.6404,  1.6205,  1.5098,
          1.5559,  1.6353,  1.6131,  1.6524,  1.5533,  1.6083],
        [ 1.8307,  1.4306,  0.5943,  0.8994,  1.2969,  1.7371,  1.6299,  1.8434,
          1.8434,  1.7199,  1.3057,  1.5155,  0.8975,  1.7508,  0.1214,  1.6470,
          1.8354,  0.9066,  1.3286,  0.9212,  0.6991,  1.1545,  1.6764,  1.7463,
          1.4871,  1.8495,  1.8495,  0.7940,  0.8638,  1.8227,  1.6070,  0.8360,
          1.7632,  1.2318,  1.8717,  1.7869,  0.0775, -0.1956, -0.2292,  0.0333,
          0.3310,  0.4435, -0.0639, 10.0248,  6.2995,  0.1713,  0.5452,  0.5835,
          0.6867,  0.3460,  0.6845, -0.1252,  0.7118,  0.7831],
        [ 1.3370,  1.3755,  1.4232,  1.4101,  1.3848,  1.3467,  1.3160,  1.3357,
          1.3357,  1.2968,  1.4232,  1.3208,  1.4546,  1.3734,  1.4808,  1.3048,
          1.3635,  1.3595,  1.3942,  1.4123,  1.4310,  1.4070,  1.3625,  1.3543,
          1.2932,  1.3438,  1.3438,  1.3991,  1.4379,  1.3563,  1.1800,  1.3538,
          1.2462,  1.4123,  1.2360,  1.3605,  0.3498,  0.2753,  0.3988,  0.3578,
          0.1601,  0.1145,  0.3736,  0.1800, -0.0264,  2.8094,  2.0679,  2.7407,
          2.3235,  1.7083,  1.3459,  2.5660,  2.5245,  1.3110]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 151 : 176.32641329508678
Test loss for epoch 151 : 176.12405987551307
Test Precision for epoch 151 : 0.26153846153846155
Test Recall for epoch 151 : 0.26153846153846155
Test F1 for epoch 151 : 0.26153846153846155


theta for epoch 152 : tensor([[ 2.3089,  2.3276,  2.3649,  2.4410,  2.4228,  2.3134,  2.4084,  2.3084,
          2.3084,  1.3605,  1.3633,  1.3623,  1.3657,  1.3596,  1.3679,  1.3611,
          1.3589,  1.3210,  1.3176,  1.2764,  1.2772,  1.3186,  1.3152,  1.3146,
          1.3170,  1.3138,  1.3138,  1.2993,  1.3427,  1.3365,  1.3395,  1.3430,
          1.3380,  1.3407,  1.2934,  1.3368,  1.7443,  1.7554,  1.7479,  1.7448,
          1.7523,  1.6933,  1.7458,  1.7327,  1.7446,  1.6284,  1.6103,  1.6061,
          1.5998,  1.6235,  1.6049,  1.6398,  1.5973,  1.5979],
        [ 1.3187,  1.3081,  1.1952,  1.2724,  1.3501,  1.3474,  1.3200,  1.3465,
          1.3465,  2.2571,  2.1882,  2.1489,  2.3021,  2.1861,  2.8940,  2.2486,
          2.1646,  2.8617,  1.3025,  1.3320,  1.2796,  1.2638,  1.3612,  1.3612,
          1.3225,  1.3603,  1.3603,  1.3544,  1.2095,  1.3831,  1.3857,  1.2709,
          1.3847,  1.3875,  1.3533,  1.3832,  1.7783,  1.7932,  1.7424,  1.7410,
          1.7873,  1.7910,  1.7402,  1.4665,  1.7808,  1.5636,  1.6484,  1.6437,
          1.6371,  1.5048,  1.6426,  1.5307,  1.6343,  1.6350],
        [ 1.3046,  1.3075,  1.3112,  1.3094,  1.3074,  1.3053,  1.3046,  1.3044,
          1.3044,  1.3656,  1.3686,  1.3675,  1.3701,  1.3647,  1.3365,  1.3663,
          1.3431,  1.3394,  2.3902,  2.3789,  2.4463,  2.4041,  2.3141,  2.3186,
          2.3797,  2.3059,  2.3059,  1.3377,  1.3218,  1.3414,  1.3445,  1.3376,
          1.3429,  1.3458,  1.3412,  1.3417,  1.7471,  1.7585,  1.7508,  1.7352,
          1.7553,  1.7553,  1.7487,  1.7059,  1.7351,  1.6276,  1.6134,  1.6091,
          1.6027,  1.5905,  1.6080,  1.6258,  1.6001,  1.6007],
        [ 1.3165,  1.3195,  1.3211,  1.3193,  1.3194,  1.3172,  1.3174,  1.3164,
          1.3164,  1.3772,  1.3783,  1.3792,  1.3670,  1.3763,  1.2819,  1.3778,
          1.3752,  1.2762,  1.3349,  1.3210,  1.3368,  1.3359,  1.3323,  1.3312,
          1.3340,  1.3309,  1.3309,  2.5067,  2.4640,  2.2396,  2.3451,  2.5042,
          2.2484,  2.4534,  2.2714,  2.2414,  1.7552,  1.7669,  1.7378,  1.7551,
          1.7636,  1.7632,  1.7365,  1.6781,  1.7551,  1.6416,  1.6217,  1.5110,
          1.5572,  1.6365,  1.6144,  1.6535,  1.5545,  1.6095],
        [ 1.8341,  1.4345,  0.5994,  0.9044,  1.3018,  1.7411,  1.6337,  1.8472,
          1.8472,  1.7244,  1.3109,  1.5199,  0.9030,  1.7547,  0.1273,  1.6512,
          1.8400,  0.9115,  1.3333,  0.9271,  0.7051,  1.1595,  1.6811,  1.7508,
          1.4919,  1.8539,  1.8539,  0.8001,  0.8693,  1.8274,  1.6123,  0.8421,
          1.7681,  1.2374,  1.8763,  1.7917,  0.0703, -0.2021, -0.2357,  0.0264,
          0.3231,  0.4353, -0.0708, 10.0730,  6.2965,  0.1781,  0.5518,  0.5902,
          0.6934,  0.3524,  0.6912, -0.1181,  0.7184,  0.7897],
        [ 1.3322,  1.3707,  1.4185,  1.4053,  1.3801,  1.3418,  1.3111,  1.3308,
          1.3308,  1.2906,  1.4173,  1.3147,  1.4487,  1.3675,  1.4748,  1.2988,
          1.3574,  1.3537,  1.3880,  1.4059,  1.4249,  1.4009,  1.3563,  1.3481,
          1.2865,  1.3376,  1.3376,  1.3942,  1.4332,  1.3514,  1.1744,  1.3489,
          1.2412,  1.4075,  1.2308,  1.3556,  0.3437,  0.2691,  0.3926,  0.3517,
          0.1537,  0.1080,  0.3675,  0.1733, -0.0333,  2.8211,  2.0778,  2.7540,
          2.3338,  1.7173,  1.3545,  2.5760,  2.5377,  1.3195]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 152 : 176.29572098607048
Test loss for epoch 152 : 176.08624669198838
Test Precision for epoch 152 : 0.26153846153846155
Test Recall for epoch 152 : 0.26153846153846155
Test F1 for epoch 152 : 0.26153846153846155


theta for epoch 153 : tensor([[ 2.3121,  2.3308,  2.3680,  2.4445,  2.4262,  2.3165,  2.4119,  2.3116,
          2.3116,  1.3605,  1.3634,  1.3624,  1.3658,  1.3596,  1.3679,  1.3612,
          1.3589,  1.3211,  1.3177,  1.2765,  1.2773,  1.3187,  1.3153,  1.3147,
          1.3171,  1.3139,  1.3139,  1.2991,  1.3426,  1.3364,  1.3394,  1.3428,
          1.3379,  1.3406,  1.2932,  1.3367,  1.7446,  1.7557,  1.7482,  1.7451,
          1.7526,  1.6936,  1.7461,  1.7330,  1.7449,  1.6270,  1.6090,  1.6047,
          1.5985,  1.6222,  1.6036,  1.6385,  1.5960,  1.5965],
        [ 1.3188,  1.3087,  1.1961,  1.2722,  1.3497,  1.3469,  1.3202,  1.3460,
          1.3460,  2.2626,  2.1927,  2.1525,  2.3054,  2.1899,  2.8929,  2.2526,
          2.1700,  2.8612,  1.3031,  1.3321,  1.2800,  1.2645,  1.3611,  1.3610,
          1.3225,  1.3601,  1.3601,  1.3543,  1.2100,  1.3827,  1.3854,  1.2711,
          1.3843,  1.3871,  1.3530,  1.3828,  1.7782,  1.7930,  1.7424,  1.7417,
          1.7872,  1.7908,  1.7401,  1.4697,  1.7806,  1.5631,  1.6466,  1.6419,
          1.6353,  1.5044,  1.6408,  1.5303,  1.6325,  1.6332],
        [ 1.3043,  1.3073,  1.3110,  1.3092,  1.3072,  1.3051,  1.3044,  1.3042,
          1.3042,  1.3657,  1.3686,  1.3676,  1.3701,  1.3648,  1.3366,  1.3663,
          1.3429,  1.3399,  2.3932,  2.3824,  2.4494,  2.4070,  2.3176,  2.3219,
          2.3829,  2.3094,  2.3094,  1.3374,  1.3219,  1.3413,  1.3443,  1.3373,
          1.3428,  1.3456,  1.3411,  1.3416,  1.7473,  1.7587,  1.7510,  1.7352,
          1.7555,  1.7555,  1.7489,  1.7068,  1.7350,  1.6264,  1.6121,  1.6077,
          1.6013,  1.5896,  1.6066,  1.6244,  1.5987,  1.5993],
        [ 1.3163,  1.3193,  1.3210,  1.3192,  1.3193,  1.3171,  1.3173,  1.3162,
          1.3162,  1.3773,  1.3785,  1.3793,  1.3670,  1.3764,  1.2819,  1.3780,
          1.3754,  1.2764,  1.3350,  1.3210,  1.3368,  1.3360,  1.3324,  1.3313,
          1.3341,  1.3310,  1.3310,  2.5103,  2.4674,  2.2425,  2.3482,  2.5079,
          2.2513,  2.4566,  2.2745,  2.2442,  1.7554,  1.7672,  1.7380,  1.7554,
          1.7639,  1.7635,  1.7367,  1.6786,  1.7554,  1.6403,  1.6205,  1.5098,
          1.5559,  1.6352,  1.6132,  1.6523,  1.5532,  1.6083],
        [ 1.8335,  1.4332,  0.5980,  0.9036,  1.3011,  1.7408,  1.6328,  1.8470,
          1.8470,  1.7235,  1.3095,  1.5186,  0.9013,  1.7534,  0.1252,  1.6500,
          1.8397,  0.9085,  1.3318,  0.9262,  0.7038,  1.1579,  1.6806,  1.7502,
          1.4914,  1.8535,  1.8535,  0.7990,  0.8676,  1.8267,  1.6117,  0.8406,
          1.7674,  1.2363,  1.8756,  1.7909,  0.0693, -0.2028, -0.2364,  0.0257,
          0.3216,  0.4336, -0.0717, 10.1275,  6.3006,  0.1758,  0.5496,  0.5880,
          0.6912,  0.3499,  0.6889, -0.1202,  0.7163,  0.7874],
        [ 1.3341,  1.3726,  1.4203,  1.4072,  1.3819,  1.3437,  1.3130,  1.3327,
          1.3327,  1.2932,  1.4198,  1.3173,  1.4512,  1.3701,  1.4774,  1.3013,
          1.3599,  1.3564,  1.3906,  1.4083,  1.4275,  1.4035,  1.3588,  1.3507,
          1.2889,  1.3402,  1.3402,  1.3962,  1.4352,  1.3535,  1.1763,  1.3509,
          1.2432,  1.4095,  1.2329,  1.3576,  0.3460,  0.2714,  0.3949,  0.3540,
          0.1560,  0.1103,  0.3698,  0.1753, -0.0313,  2.8231,  2.0780,  2.7574,
          2.3344,  1.7167,  1.3533,  2.5763,  2.5411,  1.3184]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 153 : 176.27310013710957
Test loss for epoch 153 : 176.06923542416752
Test Precision for epoch 153 : 0.26153846153846155
Test Recall for epoch 153 : 0.26153846153846155
Test F1 for epoch 153 : 0.26153846153846155


theta for epoch 154 : tensor([[ 2.3154,  2.3342,  2.3714,  2.4481,  2.4299,  2.3199,  2.4156,  2.3149,
          2.3149,  1.3604,  1.3632,  1.3622,  1.3656,  1.3595,  1.3677,  1.3610,
          1.3588,  1.3209,  1.3174,  1.2762,  1.2770,  1.3184,  1.3150,  1.3144,
          1.3168,  1.3136,  1.3136,  1.2989,  1.3424,  1.3362,  1.3392,  1.3426,
          1.3376,  1.3404,  1.2930,  1.3365,  1.7445,  1.7557,  1.7482,  1.7450,
          1.7525,  1.6936,  1.7461,  1.7329,  1.7448,  1.6265,  1.6084,  1.6042,
          1.5979,  1.6217,  1.6030,  1.6379,  1.5954,  1.5960],
        [ 1.3188,  1.3093,  1.1970,  1.2720,  1.3492,  1.3465,  1.3203,  1.3456,
          1.3456,  2.2684,  2.1976,  2.1564,  2.3092,  2.1940,  2.8922,  2.2571,
          2.1758,  2.8610,  1.3030,  1.3315,  1.2797,  1.2646,  1.3603,  1.3603,
          1.3219,  1.3594,  1.3594,  1.3539,  1.2104,  1.3821,  1.3848,  1.2712,
          1.3837,  1.3865,  1.3525,  1.3822,  1.7778,  1.7925,  1.7420,  1.7419,
          1.7868,  1.7903,  1.7397,  1.4726,  1.7801,  1.5633,  1.6455,  1.6408,
          1.6342,  1.5048,  1.6398,  1.5307,  1.6314,  1.6322],
        [ 1.3041,  1.3070,  1.3107,  1.3089,  1.3070,  1.3048,  1.3042,  1.3040,
          1.3040,  1.3653,  1.3682,  1.3672,  1.3697,  1.3644,  1.3363,  1.3659,
          1.3422,  1.3399,  2.3966,  2.3864,  2.4529,  2.4103,  2.3215,  2.3257,
          2.3865,  2.3133,  2.3133,  1.3369,  1.3218,  1.3409,  1.3440,  1.3368,
          1.3424,  1.3453,  1.3407,  1.3412,  1.7472,  1.7586,  1.7509,  1.7348,
          1.7554,  1.7554,  1.7487,  1.7073,  1.7346,  1.6258,  1.6114,  1.6071,
          1.6007,  1.5894,  1.6060,  1.6238,  1.5981,  1.5987],
        [ 1.3162,  1.3192,  1.3209,  1.3191,  1.3192,  1.3170,  1.3172,  1.3161,
          1.3161,  1.3772,  1.3784,  1.3791,  1.3668,  1.3763,  1.2817,  1.3778,
          1.3752,  1.2763,  1.3346,  1.3205,  1.3365,  1.3357,  1.3321,  1.3310,
          1.3337,  1.3307,  1.3307,  2.5141,  2.4709,  2.2455,  2.3514,  2.5117,
          2.2543,  2.4600,  2.2779,  2.2472,  1.7554,  1.7672,  1.7378,  1.7553,
          1.7638,  1.7635,  1.7364,  1.6787,  1.7553,  1.6398,  1.6200,  1.5093,
          1.5554,  1.6347,  1.6128,  1.6518,  1.5527,  1.6078],
        [ 1.8340,  1.4334,  0.5982,  0.9043,  1.3019,  1.7417,  1.6333,  1.8479,
          1.8479,  1.7241,  1.3098,  1.5187,  0.9015,  1.7534,  0.1251,  1.6501,
          1.8407,  0.9076,  1.3319,  0.9270,  0.7043,  1.1580,  1.6813,  1.7509,
          1.4922,  1.8544,  1.8544,  0.7997,  0.8677,  1.8274,  1.6126,  0.8410,
          1.7681,  1.2370,  1.8764,  1.7916,  0.0667, -0.2050, -0.2386,  0.0233,
          0.3185,  0.4302, -0.0741, 10.1802,  6.3024,  0.1759,  0.5497,  0.5880,
          0.6911,  0.3496,  0.6889, -0.1199,  0.7163,  0.7874],
        [ 1.3347,  1.3732,  1.4208,  1.4077,  1.3824,  1.3443,  1.3136,  1.3332,
          1.3332,  1.2938,  1.4204,  1.3180,  1.4518,  1.3708,  1.4780,  1.3020,
          1.3604,  1.3572,  1.3913,  1.4087,  1.4281,  1.4042,  1.3594,  1.3513,
          1.2892,  1.3408,  1.3408,  1.3967,  1.4357,  1.3540,  1.1766,  1.3514,
          1.2438,  1.4100,  1.2334,  1.3582,  0.3464,  0.2717,  0.3951,  0.3543,
          0.1562,  0.1106,  0.3702,  0.1753, -0.0313,  2.8272,  2.0804,  2.7630,
          2.3371,  1.7181,  1.3543,  2.5787,  2.5466,  1.3193]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 154 : 176.26264977748826
Test loss for epoch 154 : 176.06136213778694
Test Precision for epoch 154 : 0.26153846153846155
Test Recall for epoch 154 : 0.26153846153846155
Test F1 for epoch 154 : 0.26153846153846155


theta for epoch 155 : tensor([[ 2.3188,  2.3376,  2.3748,  2.4518,  2.4336,  2.3233,  2.4193,  2.3183,
          2.3183,  1.3599,  1.3627,  1.3617,  1.3651,  1.3590,  1.3672,  1.3605,
          1.3583,  1.3204,  1.3165,  1.2753,  1.2761,  1.3175,  1.3141,  1.3136,
          1.3160,  1.3128,  1.3128,  1.2985,  1.3420,  1.3358,  1.3388,  1.3423,
          1.3373,  1.3400,  1.2926,  1.3361,  1.7441,  1.7552,  1.7477,  1.7446,
          1.7521,  1.6931,  1.7456,  1.7324,  1.7443,  1.6274,  1.6094,  1.6051,
          1.5989,  1.6226,  1.6040,  1.6388,  1.5964,  1.5970],
        [ 1.3186,  1.3096,  1.1976,  1.2716,  1.3485,  1.3457,  1.3201,  1.3448,
          1.3448,  2.2745,  2.2027,  2.1607,  2.3132,  2.1984,  2.8920,  2.2618,
          2.1819,  2.8612,  1.3022,  1.3303,  1.2787,  1.2639,  1.3589,  1.3588,
          1.3206,  1.3579,  1.3579,  1.3533,  1.2105,  1.3813,  1.3840,  1.2710,
          1.3829,  1.3857,  1.3517,  1.3814,  1.7770,  1.7916,  1.7412,  1.7418,
          1.7859,  1.7894,  1.7389,  1.4751,  1.7792,  1.5651,  1.6461,  1.6414,
          1.6347,  1.5068,  1.6403,  1.5325,  1.6320,  1.6327],
        [ 1.3036,  1.3065,  1.3102,  1.3084,  1.3065,  1.3044,  1.3037,  1.3035,
          1.3035,  1.3644,  1.3674,  1.3663,  1.3689,  1.3636,  1.3356,  1.3651,
          1.3412,  1.3395,  2.4001,  2.3905,  2.4565,  2.4137,  2.3255,  2.3295,
          2.3901,  2.3173,  2.3173,  1.3362,  1.3216,  1.3404,  1.3435,  1.3361,
          1.3419,  1.3448,  1.3402,  1.3407,  1.7466,  1.7580,  1.7503,  1.7340,
          1.7548,  1.7548,  1.7481,  1.7075,  1.7338,  1.6267,  1.6122,  1.6079,
          1.6015,  1.5907,  1.6068,  1.6246,  1.5989,  1.5995],
        [ 1.3159,  1.3189,  1.3207,  1.3189,  1.3189,  1.3167,  1.3168,  1.3158,
          1.3158,  1.3766,  1.3779,  1.3785,  1.3661,  1.3757,  1.2810,  1.3772,
          1.3746,  1.2757,  1.3337,  1.3195,  1.3356,  1.3347,  1.3312,  1.3301,
          1.3328,  1.3298,  1.3298,  2.5182,  2.4748,  2.2488,  2.3549,  2.5157,
          2.2575,  2.4636,  2.2815,  2.2505,  1.7549,  1.7667,  1.7372,  1.7548,
          1.7634,  1.7630,  1.7358,  1.6784,  1.7548,  1.6407,  1.6209,  1.5102,
          1.5563,  1.6356,  1.6137,  1.6526,  1.5536,  1.6087],
        [ 1.8367,  1.4364,  0.6019,  0.9081,  1.3057,  1.7449,  1.6362,  1.8510,
          1.8510,  1.7273,  1.3134,  1.5217,  0.9054,  1.7561,  0.1291,  1.6530,
          1.8442,  0.9106,  1.3352,  0.9313,  0.7085,  1.1614,  1.6848,  1.7542,
          1.4958,  1.8576,  1.8576,  0.8041,  0.8716,  1.8309,  1.6165,  0.8453,
          1.7716,  1.2410,  1.8798,  1.7951,  0.0610, -0.2101, -0.2438,  0.0179,
          0.3122,  0.4236, -0.0795, 10.2296,  6.2998,  0.1805,  0.5542,  0.5925,
          0.6956,  0.3538,  0.6934, -0.1149,  0.7208,  0.7918],
        [ 1.3321,  1.3707,  1.4182,  1.4051,  1.3798,  1.3417,  1.3110,  1.3306,
          1.3306,  1.2902,  1.4171,  1.3145,  1.4484,  1.3675,  1.4745,  1.2985,
          1.3569,  1.3539,  1.3877,  1.4048,  1.4245,  1.4006,  1.3558,  1.3477,
          1.2852,  1.3371,  1.3371,  1.3939,  1.4330,  1.3513,  1.1733,  1.3487,
          1.2409,  1.4073,  1.2305,  1.3554,  0.3426,  0.2679,  0.3913,  0.3505,
          0.1523,  0.1066,  0.3665,  0.1710, -0.0357,  2.8360,  2.0873,  2.7733,
          2.3444,  1.7242,  1.3599,  2.5857,  2.5569,  1.3249]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 155 : 176.25960388952072
Test loss for epoch 155 : 176.05459593361996
Test Precision for epoch 155 : 0.26153846153846155
Test Recall for epoch 155 : 0.26153846153846155
Test F1 for epoch 155 : 0.26153846153846155


theta for epoch 156 : tensor([[ 2.3224,  2.3412,  2.3783,  2.4557,  2.4374,  2.3268,  2.4232,  2.3219,
          2.3219,  1.3596,  1.3624,  1.3614,  1.3648,  1.3587,  1.3669,  1.3602,
          1.3580,  1.3201,  1.3164,  1.2752,  1.2759,  1.3174,  1.3140,  1.3134,
          1.3158,  1.3126,  1.3126,  1.2980,  1.3416,  1.3354,  1.3384,  1.3418,
          1.3368,  1.3396,  1.2922,  1.3357,  1.7445,  1.7557,  1.7482,  1.7450,
          1.7526,  1.6936,  1.7461,  1.7329,  1.7448,  1.6258,  1.6077,  1.6035,
          1.5973,  1.6210,  1.6024,  1.6372,  1.5948,  1.5953],
        [ 1.3183,  1.3098,  1.1981,  1.2711,  1.3477,  1.3449,  1.3199,  1.3441,
          1.3441,  2.2806,  2.2080,  2.1649,  2.3174,  2.2029,  2.8919,  2.2666,
          2.1881,  2.8616,  1.3023,  1.3299,  1.2785,  1.2641,  1.3583,  1.3582,
          1.3202,  1.3574,  1.3574,  1.3527,  1.2106,  1.3804,  1.3832,  1.2708,
          1.3820,  1.3849,  1.3510,  1.3806,  1.7771,  1.7916,  1.7414,  1.7426,
          1.7861,  1.7894,  1.7391,  1.4784,  1.7792,  1.5641,  1.6439,  1.6392,
          1.6326,  1.5060,  1.6381,  1.5317,  1.6298,  1.6305],
        [ 1.3031,  1.3060,  1.3097,  1.3079,  1.3059,  1.3038,  1.3032,  1.3030,
          1.3030,  1.3640,  1.3669,  1.3658,  1.3684,  1.3631,  1.3352,  1.3646,
          1.3404,  1.3394,  2.4041,  2.3950,  2.4605,  2.4174,  2.3300,  2.3337,
          2.3943,  2.3217,  2.3217,  1.3354,  1.3213,  1.3398,  1.3429,  1.3354,
          1.3413,  1.3442,  1.3397,  1.3401,  1.7470,  1.7584,  1.7507,  1.7342,
          1.7552,  1.7552,  1.7485,  1.7085,  1.7339,  1.6251,  1.6105,  1.6062,
          1.5998,  1.5895,  1.6051,  1.6229,  1.5972,  1.5978],
        [ 1.3155,  1.3184,  1.3203,  1.3184,  1.3184,  1.3162,  1.3164,  1.3153,
          1.3153,  1.3762,  1.3775,  1.3781,  1.3656,  1.3753,  1.2805,  1.3768,
          1.3742,  1.2754,  1.3335,  1.3192,  1.3353,  1.3345,  1.3310,  1.3299,
          1.3325,  1.3295,  1.3295,  2.5224,  2.4788,  2.2523,  2.3586,  2.5200,
          2.2610,  2.4674,  2.2853,  2.2540,  1.7554,  1.7672,  1.7376,  1.7553,
          1.7639,  1.7635,  1.7361,  1.6790,  1.7553,  1.6391,  1.6193,  1.5086,
          1.5546,  1.6340,  1.6122,  1.6510,  1.5520,  1.6071],
        [ 1.8347,  1.4334,  0.5984,  0.9053,  1.3032,  1.7432,  1.6338,  1.8495,
          1.8495,  1.7248,  1.3100,  1.5187,  0.9015,  1.7532,  0.1245,  1.6501,
          1.8425,  0.9053,  1.3319,  0.9284,  0.7049,  1.1578,  1.6826,  1.7521,
          1.4936,  1.8558,  1.8558,  0.8007,  0.8675,  1.8285,  1.6141,  0.8414,
          1.7691,  1.2378,  1.8775,  1.7927,  0.0620, -0.2089, -0.2426,  0.0191,
          0.3127,  0.4240, -0.0785, 10.2857,  6.3050,  0.1756,  0.5495,  0.5877,
          0.6907,  0.3486,  0.6885, -0.1196,  0.7159,  0.7869],
        [ 1.3365,  1.3750,  1.4224,  1.4093,  1.3841,  1.3460,  1.3154,  1.3350,
          1.3350,  1.2960,  1.4227,  1.3204,  1.4541,  1.3732,  1.4803,  1.3043,
          1.3625,  1.3598,  1.3936,  1.4104,  1.4302,  1.4065,  1.3616,  1.3536,
          1.2909,  1.3430,  1.3430,  1.3984,  1.4375,  1.3559,  1.1779,  1.3532,
          1.2457,  1.4118,  1.2353,  1.3600,  0.3481,  0.2734,  0.3966,  0.3559,
          0.1578,  0.1121,  0.3719,  0.1762, -0.0303,  2.8344,  2.0838,  2.7730,
          2.3413,  1.7199,  1.3551,  2.5824,  2.5565,  1.3201]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 156 : 176.2559779157015
Test loss for epoch 156 : 176.06094030711407
Test Precision for epoch 156 : 0.26153846153846155
Test Recall for epoch 156 : 0.26153846153846155
Test F1 for epoch 156 : 0.26153846153846155


theta for epoch 157 : tensor([[ 2.3256,  2.3444,  2.3815,  2.4592,  2.4410,  2.3300,  2.4268,  2.3251,
          2.3251,  1.3590,  1.3618,  1.3608,  1.3642,  1.3581,  1.3663,  1.3596,
          1.3574,  1.3195,  1.3155,  1.2743,  1.2751,  1.3165,  1.3131,  1.3126,
          1.3150,  1.3118,  1.3118,  1.2975,  1.3411,  1.3348,  1.3379,  1.3413,
          1.3363,  1.3391,  1.2916,  1.3351,  1.7440,  1.7552,  1.7477,  1.7446,
          1.7521,  1.6931,  1.7456,  1.7324,  1.7443,  1.6274,  1.6094,  1.6052,
          1.5990,  1.6227,  1.6041,  1.6388,  1.5965,  1.5970],
        [ 1.3178,  1.3099,  1.1985,  1.2704,  1.3468,  1.3440,  1.3196,  1.3431,
          1.3431,  2.2862,  2.2127,  2.1687,  2.3211,  2.2068,  2.8916,  2.2709,
          2.1938,  2.8617,  1.3017,  1.3289,  1.2777,  1.2637,  1.3571,  1.3570,
          1.3191,  1.3561,  1.3561,  1.3521,  1.2106,  1.3796,  1.3824,  1.2705,
          1.3812,  1.3840,  1.3502,  1.3797,  1.7762,  1.7908,  1.7406,  1.7425,
          1.7853,  1.7886,  1.7383,  1.4809,  1.7783,  1.5668,  1.6454,  1.6407,
          1.6340,  1.5088,  1.6396,  1.5344,  1.6312,  1.6319],
        [ 1.3025,  1.3054,  1.3090,  1.3073,  1.3053,  1.3032,  1.3026,  1.3024,
          1.3024,  1.3634,  1.3663,  1.3653,  1.3679,  1.3626,  1.3348,  1.3640,
          1.3396,  1.3392,  2.4068,  2.3984,  2.4634,  2.4200,  2.3332,  2.3368,
          2.3972,  2.3249,  2.3249,  1.3348,  1.3211,  1.3394,  1.3424,  1.3348,
          1.3409,  1.3437,  1.3392,  1.3397,  1.7465,  1.7579,  1.7502,  1.7335,
          1.7548,  1.7548,  1.7481,  1.7087,  1.7332,  1.6270,  1.6123,  1.6080,
          1.6016,  1.5917,  1.6069,  1.6247,  1.5990,  1.5997],
        [ 1.3148,  1.3178,  1.3197,  1.3178,  1.3177,  1.3156,  1.3157,  1.3147,
          1.3147,  1.3755,  1.3769,  1.3775,  1.3649,  1.3747,  1.2798,  1.3762,
          1.3735,  1.2747,  1.3326,  1.3182,  1.3344,  1.3336,  1.3301,  1.3291,
          1.3317,  1.3287,  1.3287,  2.5263,  2.4825,  2.2554,  2.3619,  2.5239,
          2.2642,  2.4709,  2.2888,  2.2571,  1.7548,  1.7667,  1.7369,  1.7548,
          1.7634,  1.7630,  1.7354,  1.6786,  1.7548,  1.6406,  1.6209,  1.5102,
          1.5562,  1.6356,  1.6138,  1.6526,  1.5535,  1.6087],
        [ 1.8385,  1.4379,  0.6040,  0.9109,  1.3085,  1.7476,  1.6380,  1.8536,
          1.8536,  1.7296,  1.3157,  1.5235,  0.9076,  1.7576,  0.1310,  1.6547,
          1.8475,  0.9108,  1.3371,  0.9348,  0.7115,  1.1633,  1.6878,  1.7571,
          1.4989,  1.8607,  1.8607,  0.8074,  0.8736,  1.8336,  1.6198,  0.8480,
          1.7744,  1.2440,  1.8825,  1.7978,  0.0544, -0.2158, -0.2495,  0.0119,
          0.3045,  0.4155, -0.0857, 10.3328,  6.2993,  0.1831,  0.5567,  0.5950,
          0.6980,  0.3557,  0.6958, -0.1119,  0.7232,  0.7940],
        [ 1.3315,  1.3700,  1.4174,  1.4043,  1.3791,  1.3409,  1.3103,  1.3299,
          1.3299,  1.2895,  1.4165,  1.3139,  1.4478,  1.3670,  1.4739,  1.2979,
          1.3561,  1.3536,  1.3871,  1.4036,  1.4238,  1.4000,  1.3551,  1.3471,
          1.2839,  1.3364,  1.3364,  1.3931,  1.4324,  1.3507,  1.1720,  1.3480,
          1.2403,  1.4067,  1.2298,  1.3548,  0.3415,  0.2668,  0.3900,  0.3492,
          0.1509,  0.1052,  0.3653,  0.1690, -0.0377,  2.8465,  2.0941,  2.7866,
          2.3519,  1.7292,  1.3639,  2.5927,  2.5701,  1.3289]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 157 : 176.24407676744437
Test loss for epoch 157 : 176.0411169486033
Test Precision for epoch 157 : 0.26153846153846155
Test Recall for epoch 157 : 0.26153846153846155
Test F1 for epoch 157 : 0.26153846153846155


theta for epoch 158 : tensor([[ 2.3291,  2.3479,  2.3850,  2.4630,  2.4448,  2.3335,  2.4306,  2.3286,
          2.3286,  1.3589,  1.3617,  1.3607,  1.3641,  1.3580,  1.3662,  1.3595,
          1.3573,  1.3193,  1.3157,  1.2745,  1.2752,  1.3167,  1.3133,  1.3128,
          1.3151,  1.3120,  1.3120,  1.2970,  1.3406,  1.3344,  1.3374,  1.3408,
          1.3359,  1.3386,  1.2911,  1.3347,  1.7447,  1.7559,  1.7484,  1.7452,
          1.7528,  1.6938,  1.7463,  1.7330,  1.7450,  1.6250,  1.6070,  1.6027,
          1.5965,  1.6202,  1.6017,  1.6363,  1.5940,  1.5946],
        [ 1.3178,  1.3102,  1.1992,  1.2701,  1.3462,  1.3434,  1.3196,  1.3425,
          1.3425,  2.2915,  2.2172,  2.1722,  2.3246,  2.2105,  2.8911,  2.2749,
          2.1992,  2.8615,  1.3027,  1.3293,  1.2783,  1.2648,  1.3573,  1.3573,
          1.3195,  1.3564,  1.3564,  1.3517,  1.2110,  1.3790,  1.3818,  1.2705,
          1.3806,  1.3834,  1.3496,  1.3791,  1.7767,  1.7911,  1.7411,  1.7436,
          1.7857,  1.7890,  1.7388,  1.4846,  1.7786,  1.5651,  1.6425,  1.6379,
          1.6312,  1.5075,  1.6368,  1.5329,  1.6285,  1.6292],
        [ 1.3022,  1.3051,  1.3087,  1.3070,  1.3050,  1.3029,  1.3023,  1.3021,
          1.3021,  1.3636,  1.3665,  1.3655,  1.3681,  1.3628,  1.3350,  1.3642,
          1.3396,  1.3398,  2.4098,  2.4020,  2.4666,  2.4229,  2.3366,  2.3401,
          2.4004,  2.3284,  2.3284,  1.3343,  1.3211,  1.3391,  1.3422,  1.3343,
          1.3406,  1.3434,  1.3389,  1.3394,  1.7473,  1.7587,  1.7510,  1.7340,
          1.7555,  1.7556,  1.7488,  1.7101,  1.7337,  1.6248,  1.6101,  1.6058,
          1.5994,  1.5899,  1.6047,  1.6225,  1.5968,  1.5975],
        [ 1.3144,  1.3174,  1.3193,  1.3175,  1.3174,  1.3152,  1.3154,  1.3143,
          1.3143,  1.3755,  1.3770,  1.3775,  1.3648,  1.3747,  1.2797,  1.3762,
          1.3736,  1.2747,  1.3329,  1.3184,  1.3347,  1.3339,  1.3304,  1.3293,
          1.3319,  1.3289,  1.3289,  2.5301,  2.4861,  2.2585,  2.3652,  2.5277,
          2.2672,  2.4744,  2.2922,  2.2602,  1.7556,  1.7674,  1.7376,  1.7555,
          1.7642,  1.7638,  1.7361,  1.6796,  1.7555,  1.6384,  1.6187,  1.5080,
          1.5540,  1.6334,  1.6117,  1.6503,  1.5513,  1.6065],
        [ 1.8362,  1.4345,  0.6000,  0.9076,  1.3056,  1.7455,  1.6353,  1.8518,
          1.8518,  1.7268,  1.3118,  1.5200,  0.9033,  1.7543,  0.1259,  1.6514,
          1.8455,  0.9050,  1.3334,  0.9315,  0.7074,  1.1593,  1.6853,  1.7547,
          1.4964,  1.8586,  1.8586,  0.8035,  0.8690,  1.8308,  1.6169,  0.8436,
          1.7714,  1.2403,  1.8798,  1.7950,  0.0559, -0.2141, -0.2478,  0.0136,
          0.3056,  0.4165, -0.0841, 10.3890,  6.3043,  0.1775,  0.5513,  0.5895,
          0.6923,  0.3498,  0.6902, -0.1174,  0.7177,  0.7884],
        [ 1.3359,  1.3743,  1.4216,  1.4085,  1.3833,  1.3453,  1.3147,  1.3343,
          1.3343,  1.2953,  1.4222,  1.3198,  1.4536,  1.3728,  1.4797,  1.3038,
          1.3618,  1.3596,  1.3931,  1.4093,  1.4297,  1.4060,  1.3610,  1.3530,
          1.2897,  1.3424,  1.3424,  1.3977,  1.4369,  1.3553,  1.1766,  1.3525,
          1.2450,  1.4112,  1.2346,  1.3594,  0.3471,  0.2724,  0.3955,  0.3548,
          0.1566,  0.1109,  0.3709,  0.1744, -0.0322,  2.8448,  2.0904,  2.7861,
          2.3487,  1.7247,  1.3589,  2.5893,  2.5696,  1.3238]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 158 : 176.2253263876593
Test loss for epoch 158 : 176.0329256858004
Test Precision for epoch 158 : 0.26153846153846155
Test Recall for epoch 158 : 0.26153846153846155
Test F1 for epoch 158 : 0.26153846153846155


theta for epoch 159 : tensor([[ 2.3324e+00,  2.3512e+00,  2.3882e+00,  2.4665e+00,  2.4483e+00,
          2.3367e+00,  2.4342e+00,  2.3318e+00,  2.3318e+00,  1.3585e+00,
          1.3614e+00,  1.3604e+00,  1.3637e+00,  1.3577e+00,  1.3658e+00,
          1.3592e+00,  1.3569e+00,  1.3190e+00,  1.3151e+00,  1.2739e+00,
          1.2747e+00,  1.3161e+00,  1.3128e+00,  1.3122e+00,  1.3146e+00,
          1.3114e+00,  1.3114e+00,  1.2966e+00,  1.3402e+00,  1.3340e+00,
          1.3370e+00,  1.3404e+00,  1.3355e+00,  1.3382e+00,  1.2907e+00,
          1.3343e+00,  1.7444e+00,  1.7556e+00,  1.7480e+00,  1.7449e+00,
          1.7525e+00,  1.6935e+00,  1.7459e+00,  1.7326e+00,  1.7446e+00,
          1.6256e+00,  1.6076e+00,  1.6034e+00,  1.5972e+00,  1.6209e+00,
          1.6023e+00,  1.6369e+00,  1.5947e+00,  1.5953e+00],
        [ 1.3176e+00,  1.3105e+00,  1.1999e+00,  1.2697e+00,  1.3455e+00,
          1.3427e+00,  1.3195e+00,  1.3419e+00,  1.3419e+00,  2.2965e+00,
          2.2214e+00,  2.1754e+00,  2.3280e+00,  2.2139e+00,  2.8905e+00,
          2.2787e+00,  2.2044e+00,  2.8612e+00,  1.3027e+00,  1.3289e+00,
          1.2780e+00,  1.2650e+00,  1.3567e+00,  1.3566e+00,  1.3190e+00,
          1.3557e+00,  1.3557e+00,  1.3513e+00,  1.2114e+00,  1.3784e+00,
          1.3812e+00,  1.2706e+00,  1.3800e+00,  1.3829e+00,  1.3491e+00,
          1.3786e+00,  1.7761e+00,  1.7905e+00,  1.7406e+00,  1.7437e+00,
          1.7851e+00,  1.7883e+00,  1.7382e+00,  1.4873e+00,  1.7780e+00,
          1.5669e+00,  1.6431e+00,  1.6384e+00,  1.6318e+00,  1.5094e+00,
          1.6374e+00,  1.5347e+00,  1.6290e+00,  1.6297e+00],
        [ 1.3019e+00,  1.3048e+00,  1.3084e+00,  1.3066e+00,  1.3047e+00,
          1.3026e+00,  1.3020e+00,  1.3018e+00,  1.3018e+00,  1.3635e+00,
          1.3664e+00,  1.3654e+00,  1.3680e+00,  1.3627e+00,  1.3350e+00,
          1.3641e+00,  1.3392e+00,  1.3401e+00,  2.4121e+00,  2.4050e+00,
          2.4691e+00,  2.4252e+00,  2.3395e+00,  2.3427e+00,  2.4029e+00,
          2.3312e+00,  2.3312e+00,  1.3340e+00,  1.3211e+00,  1.3389e+00,
          1.3420e+00,  1.3340e+00,  1.3404e+00,  1.3433e+00,  1.3388e+00,
          1.3392e+00,  1.7470e+00,  1.7584e+00,  1.7507e+00,  1.7334e+00,
          1.7553e+00,  1.7553e+00,  1.7485e+00,  1.7104e+00,  1.7331e+00,
          1.6258e+00,  1.6110e+00,  1.6067e+00,  1.6003e+00,  1.5912e+00,
          1.6056e+00,  1.6233e+00,  1.5977e+00,  1.5984e+00],
        [ 1.3141e+00,  1.3170e+00,  1.3190e+00,  1.3172e+00,  1.3170e+00,
          1.3148e+00,  1.3150e+00,  1.3139e+00,  1.3139e+00,  1.3753e+00,
          1.3768e+00,  1.3772e+00,  1.3645e+00,  1.3745e+00,  1.2794e+00,
          1.3759e+00,  1.3733e+00,  1.2745e+00,  1.3324e+00,  1.3179e+00,
          1.3342e+00,  1.3334e+00,  1.3299e+00,  1.3289e+00,  1.3315e+00,
          1.3285e+00,  1.3285e+00,  2.5337e+00,  2.4895e+00,  2.2614e+00,
          2.3682e+00,  2.5313e+00,  2.2701e+00,  2.4776e+00,  2.2953e+00,
          2.2631e+00,  1.7553e+00,  1.7671e+00,  1.7372e+00,  1.7552e+00,
          1.7639e+00,  1.7635e+00,  1.7356e+00,  1.6793e+00,  1.7552e+00,
          1.6390e+00,  1.6194e+00,  1.5087e+00,  1.5547e+00,  1.6341e+00,
          1.6124e+00,  1.6510e+00,  1.5520e+00,  1.6072e+00],
        [ 1.8389e+00,  1.4377e+00,  6.0401e-01,  9.1170e-01,  1.3095e+00,
          1.7488e+00,  1.6383e+00,  1.8550e+00,  1.8550e+00,  1.7303e+00,
          1.3160e+00,  1.5234e+00,  9.0763e-01,  1.7574e+00,  1.3036e-01,
          1.6547e+00,  1.8493e+00,  9.0859e-01,  1.3371e+00,  9.3619e-01,
          7.1220e-01,  1.1631e+00,  1.6892e+00,  1.7584e+00,  1.5003e+00,
          1.8622e+00,  1.8622e+00,  8.0837e-01,  8.7324e-01,  1.8346e+00,
          1.6212e+00,  8.4837e-01,  1.7754e+00,  1.2447e+00,  1.8836e+00,
          1.7988e+00,  4.9981e-02, -2.1941e-01, -2.5321e-01,  7.9553e-03,
          2.9907e-01,  4.0969e-01, -8.9774e-02,  1.0437e+01,  6.2997e+00,
          1.8267e-01,  5.5633e-01,  5.9452e-01,  6.9736e-01,  3.5460e-01,
          6.9520e-01, -1.1201e-01,  7.2268e-01,  7.9333e-01],
        [ 1.3323e+00,  1.3707e+00,  1.4180e+00,  1.4049e+00,  1.3797e+00,
          1.3416e+00,  1.3110e+00,  1.3306e+00,  1.3306e+00,  1.2907e+00,
          1.4178e+00,  1.3153e+00,  1.4491e+00,  1.3684e+00,  1.4751e+00,
          1.2992e+00,  1.3572e+00,  1.3552e+00,  1.3884e+00,  1.4044e+00,
          1.4250e+00,  1.4013e+00,  1.3563e+00,  1.3483e+00,  1.2845e+00,
          1.3376e+00,  1.3376e+00,  1.3939e+00,  1.4332e+00,  1.3515e+00,
          1.1722e+00,  1.3488e+00,  1.2411e+00,  1.4076e+00,  1.2306e+00,
          1.3557e+00,  3.4225e-01,  2.6754e-01,  3.9062e-01,  3.4993e-01,
          1.5151e-01,  1.0581e-01,  3.6613e-01,  1.6895e-01, -3.7727e-02,
          2.8548e+00,  2.0985e+00,  2.7975e+00,  2.3572e+00,  1.7319e+00,
          1.3656e+00,  2.5975e+00,  2.5810e+00,  1.3305e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 159 : 176.20370264788326
Test loss for epoch 159 : 176.00633261974892
Test Precision for epoch 159 : 0.26153846153846155
Test Recall for epoch 159 : 0.26153846153846155
Test F1 for epoch 159 : 0.26153846153846155


theta for epoch 160 : tensor([[ 2.3357e+00,  2.3545e+00,  2.3915e+00,  2.4701e+00,  2.4519e+00,
          2.3400e+00,  2.4378e+00,  2.3351e+00,  2.3351e+00,  1.3584e+00,
          1.3612e+00,  1.3602e+00,  1.3636e+00,  1.3576e+00,  1.3657e+00,
          1.3590e+00,  1.3568e+00,  1.3188e+00,  1.3150e+00,  1.2737e+00,
          1.2745e+00,  1.3160e+00,  1.3126e+00,  1.3121e+00,  1.3144e+00,
          1.3112e+00,  1.3112e+00,  1.2963e+00,  1.3399e+00,  1.3337e+00,
          1.3367e+00,  1.3401e+00,  1.3352e+00,  1.3379e+00,  1.2904e+00,
          1.3340e+00,  1.7445e+00,  1.7557e+00,  1.7482e+00,  1.7450e+00,
          1.7526e+00,  1.6936e+00,  1.7460e+00,  1.7327e+00,  1.7447e+00,
          1.6246e+00,  1.6066e+00,  1.6024e+00,  1.5962e+00,  1.6199e+00,
          1.6014e+00,  1.6359e+00,  1.5937e+00,  1.5943e+00],
        [ 1.3175e+00,  1.3109e+00,  1.2006e+00,  1.2694e+00,  1.3449e+00,
          1.3421e+00,  1.3194e+00,  1.3413e+00,  1.3413e+00,  2.3017e+00,
          2.2259e+00,  2.1789e+00,  2.3316e+00,  2.2176e+00,  2.8903e+00,
          2.2827e+00,  2.2099e+00,  2.8613e+00,  1.3030e+00,  1.3287e+00,
          1.2780e+00,  1.2655e+00,  1.3563e+00,  1.3562e+00,  1.3188e+00,
          1.3553e+00,  1.3553e+00,  1.3510e+00,  1.2119e+00,  1.3779e+00,
          1.3807e+00,  1.2707e+00,  1.3795e+00,  1.3823e+00,  1.3486e+00,
          1.3781e+00,  1.7759e+00,  1.7903e+00,  1.7405e+00,  1.7443e+00,
          1.7849e+00,  1.7881e+00,  1.7382e+00,  1.4904e+00,  1.7778e+00,
          1.5667e+00,  1.6418e+00,  1.6371e+00,  1.6304e+00,  1.5095e+00,
          1.6360e+00,  1.5346e+00,  1.6277e+00,  1.6284e+00],
        [ 1.3015e+00,  1.3044e+00,  1.3080e+00,  1.3062e+00,  1.3043e+00,
          1.3022e+00,  1.3017e+00,  1.3014e+00,  1.3014e+00,  1.3633e+00,
          1.3662e+00,  1.3652e+00,  1.3679e+00,  1.3625e+00,  1.3349e+00,
          1.3640e+00,  1.3388e+00,  1.3403e+00,  2.4153e+00,  2.4089e+00,
          2.4725e+00,  2.4282e+00,  2.3431e+00,  2.3463e+00,  2.4064e+00,
          2.3349e+00,  2.3349e+00,  1.3335e+00,  1.3211e+00,  1.3386e+00,
          1.3417e+00,  1.3335e+00,  1.3401e+00,  1.3430e+00,  1.3385e+00,
          1.3389e+00,  1.7471e+00,  1.7585e+00,  1.7508e+00,  1.7333e+00,
          1.7554e+00,  1.7554e+00,  1.7486e+00,  1.7111e+00,  1.7330e+00,
          1.6249e+00,  1.6100e+00,  1.6057e+00,  1.5994e+00,  1.5907e+00,
          1.6046e+00,  1.6223e+00,  1.5967e+00,  1.5974e+00],
        [ 1.3137e+00,  1.3167e+00,  1.3187e+00,  1.3169e+00,  1.3166e+00,
          1.3145e+00,  1.3147e+00,  1.3136e+00,  1.3136e+00,  1.3752e+00,
          1.3768e+00,  1.3771e+00,  1.3644e+00,  1.3744e+00,  1.2793e+00,
          1.3759e+00,  1.3732e+00,  1.2745e+00,  1.3323e+00,  1.3177e+00,
          1.3341e+00,  1.3333e+00,  1.3298e+00,  1.3288e+00,  1.3313e+00,
          1.3283e+00,  1.3283e+00,  2.5375e+00,  2.4930e+00,  2.2644e+00,
          2.3715e+00,  2.5351e+00,  2.2731e+00,  2.4810e+00,  2.2987e+00,
          2.2661e+00,  1.7554e+00,  1.7673e+00,  1.7372e+00,  1.7553e+00,
          1.7640e+00,  1.7637e+00,  1.7357e+00,  1.6796e+00,  1.7553e+00,
          1.6381e+00,  1.6186e+00,  1.5078e+00,  1.5538e+00,  1.6332e+00,
          1.6116e+00,  1.6500e+00,  1.5511e+00,  1.6063e+00],
        [ 1.8384e+00,  1.4366e+00,  6.0276e-01,  9.1101e-01,  1.3090e+00,
          1.7486e+00,  1.6376e+00,  1.8549e+00,  1.8549e+00,  1.7296e+00,
          1.3149e+00,  1.5223e+00,  9.0633e-01,  1.7563e+00,  1.2859e-01,
          1.6536e+00,  1.8493e+00,  9.0608e-01,  1.3360e+00,  9.3562e-01,
          7.1114e-01,  1.1618e+00,  1.6888e+00,  1.7580e+00,  1.5000e+00,
          1.8621e+00,  1.8621e+00,  8.0756e-01,  8.7178e-01,  1.8342e+00,
          1.6209e+00,  8.4720e-01,  1.7749e+00,  1.2440e+00,  1.8832e+00,
          1.7984e+00,  4.8882e-02, -2.2016e-01, -2.5403e-01,  7.1097e-03,
          2.9750e-01,  4.0795e-01, -9.0724e-02,  1.0491e+01,  6.3006e+00,
          1.8091e-01,  5.5466e-01,  5.9278e-01,  6.9555e-01,  3.5252e-01,
          6.9340e-01, -1.1363e-01,  7.2094e-01,  7.9149e-01],
        [ 1.3340e+00,  1.3724e+00,  1.4196e+00,  1.4065e+00,  1.3814e+00,
          1.3433e+00,  1.3127e+00,  1.3323e+00,  1.3323e+00,  1.2929e+00,
          1.4200e+00,  1.3176e+00,  1.4514e+00,  1.3707e+00,  1.4774e+00,
          1.3015e+00,  1.3594e+00,  1.3577e+00,  1.3907e+00,  1.4064e+00,
          1.4273e+00,  1.4036e+00,  1.3585e+00,  1.3506e+00,  1.2865e+00,
          1.3399e+00,  1.3399e+00,  1.3957e+00,  1.4350e+00,  1.3534e+00,
          1.1739e+00,  1.3506e+00,  1.2430e+00,  1.4094e+00,  1.2325e+00,
          1.3576e+00,  3.4421e-01,  2.6953e-01,  3.9248e-01,  3.5184e-01,
          1.5344e-01,  1.0773e-01,  3.6809e-01,  1.7053e-01, -3.6077e-02,
          2.8571e+00,  2.0989e+00,  2.8011e+00,  2.3580e+00,  1.7314e+00,
          1.3646e+00,  2.5980e+00,  2.5845e+00,  1.3295e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 160 : 176.18570863021299
Test loss for epoch 160 : 175.9935601916583
Test Precision for epoch 160 : 0.26153846153846155
Test Recall for epoch 160 : 0.26153846153846155
Test F1 for epoch 160 : 0.26153846153846155


theta for epoch 161 : tensor([[ 2.3389e+00,  2.3578e+00,  2.3947e+00,  2.4737e+00,  2.4555e+00,
          2.3432e+00,  2.4414e+00,  2.3383e+00,  2.3383e+00,  1.3581e+00,
          1.3610e+00,  1.3600e+00,  1.3633e+00,  1.3573e+00,  1.3654e+00,
          1.3588e+00,  1.3565e+00,  1.3186e+00,  1.3145e+00,  1.2733e+00,
          1.2740e+00,  1.3155e+00,  1.3122e+00,  1.3116e+00,  1.3140e+00,
          1.3108e+00,  1.3108e+00,  1.2960e+00,  1.3397e+00,  1.3335e+00,
          1.3365e+00,  1.3399e+00,  1.3350e+00,  1.3377e+00,  1.2902e+00,
          1.3338e+00,  1.7444e+00,  1.7556e+00,  1.7480e+00,  1.7449e+00,
          1.7525e+00,  1.6934e+00,  1.7459e+00,  1.7326e+00,  1.7446e+00,
          1.6246e+00,  1.6067e+00,  1.6025e+00,  1.5963e+00,  1.6200e+00,
          1.6014e+00,  1.6359e+00,  1.5938e+00,  1.5944e+00],
        [ 1.3173e+00,  1.3111e+00,  1.2012e+00,  1.2690e+00,  1.3442e+00,
          1.3414e+00,  1.3193e+00,  1.3405e+00,  1.3405e+00,  2.3072e+00,
          2.2306e+00,  2.1826e+00,  2.3355e+00,  2.2215e+00,  2.8903e+00,
          2.2870e+00,  2.2156e+00,  2.8616e+00,  1.3027e+00,  1.3280e+00,
          1.2774e+00,  1.2654e+00,  1.3554e+00,  1.3553e+00,  1.3181e+00,
          1.3544e+00,  1.3544e+00,  1.3505e+00,  1.2123e+00,  1.3772e+00,
          1.3801e+00,  1.2707e+00,  1.3788e+00,  1.3817e+00,  1.3481e+00,
          1.3774e+00,  1.7754e+00,  1.7898e+00,  1.7401e+00,  1.7445e+00,
          1.7845e+00,  1.7876e+00,  1.7377e+00,  1.4932e+00,  1.7772e+00,
          1.5675e+00,  1.6414e+00,  1.6368e+00,  1.6301e+00,  1.5105e+00,
          1.6357e+00,  1.5354e+00,  1.6273e+00,  1.6281e+00],
        [ 1.3010e+00,  1.3039e+00,  1.3075e+00,  1.3057e+00,  1.3038e+00,
          1.3017e+00,  1.3012e+00,  1.3009e+00,  1.3009e+00,  1.3628e+00,
          1.3657e+00,  1.3647e+00,  1.3674e+00,  1.3620e+00,  1.3344e+00,
          1.3635e+00,  1.3380e+00,  1.3402e+00,  2.4187e+00,  2.4130e+00,
          2.4761e+00,  2.4316e+00,  2.3471e+00,  2.3500e+00,  2.4100e+00,
          2.3388e+00,  2.3388e+00,  1.3329e+00,  1.3209e+00,  1.3382e+00,
          1.3413e+00,  1.3329e+00,  1.3397e+00,  1.3425e+00,  1.3381e+00,
          1.3385e+00,  1.7468e+00,  1.7583e+00,  1.7506e+00,  1.7328e+00,
          1.7552e+00,  1.7552e+00,  1.7484e+00,  1.7115e+00,  1.7325e+00,
          1.6248e+00,  1.6099e+00,  1.6056e+00,  1.5993e+00,  1.5910e+00,
          1.6045e+00,  1.6222e+00,  1.5967e+00,  1.5973e+00],
        [ 1.3134e+00,  1.3164e+00,  1.3184e+00,  1.3166e+00,  1.3163e+00,
          1.3141e+00,  1.3143e+00,  1.3133e+00,  1.3133e+00,  1.3749e+00,
          1.3765e+00,  1.3768e+00,  1.3640e+00,  1.3741e+00,  1.2790e+00,
          1.3756e+00,  1.3729e+00,  1.2742e+00,  1.3318e+00,  1.3171e+00,
          1.3336e+00,  1.3328e+00,  1.3293e+00,  1.3283e+00,  1.3309e+00,
          1.3279e+00,  1.3279e+00,  2.5413e+00,  2.4966e+00,  2.2675e+00,
          2.3747e+00,  2.5389e+00,  2.2762e+00,  2.4844e+00,  2.3020e+00,
          2.2692e+00,  1.7553e+00,  1.7671e+00,  1.7370e+00,  1.7552e+00,
          1.7639e+00,  1.7636e+00,  1.7354e+00,  1.6796e+00,  1.7551e+00,
          1.6381e+00,  1.6186e+00,  1.5079e+00,  1.5538e+00,  1.6332e+00,
          1.6117e+00,  1.6500e+00,  1.5511e+00,  1.6063e+00],
        [ 1.8391e+00,  1.4371e+00,  6.0337e-01,  9.1197e-01,  1.3101e+00,
          1.7497e+00,  1.6382e+00,  1.8560e+00,  1.8560e+00,  1.7304e+00,
          1.3156e+00,  1.5227e+00,  9.0699e-01,  1.7567e+00,  1.2896e-01,
          1.6540e+00,  1.8506e+00,  9.0570e-01,  1.3364e+00,  9.3686e-01,
          7.1206e-01,  1.1622e+00,  1.6898e+00,  1.7590e+00,  1.5011e+00,
          1.8631e+00,  1.8631e+00,  8.0875e-01,  8.7230e-01,  1.8353e+00,
          1.6222e+00,  8.4812e-01,  1.7760e+00,  1.2450e+00,  1.8843e+00,
          1.7995e+00,  4.6109e-02, -2.2250e-01, -2.5642e-01,  4.5914e-03,
          2.9420e-01,  4.0448e-01, -9.3295e-02,  1.0542e+01,  6.2991e+00,
          1.8166e-01,  5.5542e-01,  5.9352e-01,  6.9623e-01,  3.5295e-01,
          6.9409e-01, -1.1275e-01,  7.2167e-01,  7.9213e-01],
        [ 1.3341e+00,  1.3725e+00,  1.4196e+00,  1.4065e+00,  1.3814e+00,
          1.3433e+00,  1.3128e+00,  1.3323e+00,  1.3323e+00,  1.2930e+00,
          1.4202e+00,  1.3178e+00,  1.4515e+00,  1.3709e+00,  1.4775e+00,
          1.3017e+00,  1.3594e+00,  1.3580e+00,  1.3907e+00,  1.4061e+00,
          1.4272e+00,  1.4036e+00,  1.3585e+00,  1.3506e+00,  1.2862e+00,
          1.3398e+00,  1.3398e+00,  1.3957e+00,  1.4352e+00,  1.3535e+00,
          1.1737e+00,  1.3507e+00,  1.2431e+00,  1.4095e+00,  1.2326e+00,
          1.3577e+00,  3.4394e-01,  2.6928e-01,  3.9213e-01,  3.5154e-01,
          1.5309e-01,  1.0737e-01,  3.6783e-01,  1.6982e-01, -3.6746e-02,
          2.8619e+00,  2.1017e+00,  2.8072e+00,  2.3612e+00,  1.7333e+00,
          1.3661e+00,  2.6011e+00,  2.5906e+00,  1.3309e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 161 : 176.17348154958992
Test loss for epoch 161 : 175.9831609399736
Test Precision for epoch 161 : 0.26153846153846155
Test Recall for epoch 161 : 0.26153846153846155
Test F1 for epoch 161 : 0.26153846153846155


theta for epoch 162 : tensor([[ 2.3421e+00,  2.3610e+00,  2.3979e+00,  2.4772e+00,  2.4590e+00,
          2.3464e+00,  2.4449e+00,  2.3415e+00,  2.3415e+00,  1.3578e+00,
          1.3606e+00,  1.3596e+00,  1.3629e+00,  1.3570e+00,  1.3650e+00,
          1.3584e+00,  1.3562e+00,  1.3182e+00,  1.3139e+00,  1.2726e+00,
          1.2734e+00,  1.3149e+00,  1.3115e+00,  1.3110e+00,  1.3134e+00,
          1.3102e+00,  1.3102e+00,  1.2957e+00,  1.3394e+00,  1.3332e+00,
          1.3362e+00,  1.3396e+00,  1.3347e+00,  1.3374e+00,  1.2899e+00,
          1.3335e+00,  1.7441e+00,  1.7553e+00,  1.7478e+00,  1.7446e+00,
          1.7522e+00,  1.6931e+00,  1.7456e+00,  1.7323e+00,  1.7443e+00,
          1.6252e+00,  1.6073e+00,  1.6031e+00,  1.5970e+00,  1.6206e+00,
          1.6021e+00,  1.6365e+00,  1.5944e+00,  1.5951e+00],
        [ 1.3171e+00,  1.3113e+00,  1.2017e+00,  1.2686e+00,  1.3435e+00,
          1.3407e+00,  1.3192e+00,  1.3398e+00,  1.3398e+00,  2.3127e+00,
          2.2354e+00,  2.1864e+00,  2.3395e+00,  2.2255e+00,  2.8906e+00,
          2.2913e+00,  2.2214e+00,  2.8621e+00,  1.3021e+00,  1.3269e+00,
          1.2765e+00,  1.2650e+00,  1.3543e+00,  1.3541e+00,  1.3170e+00,
          1.3532e+00,  1.3532e+00,  1.3500e+00,  1.2125e+00,  1.3764e+00,
          1.3793e+00,  1.2705e+00,  1.3781e+00,  1.3809e+00,  1.3473e+00,
          1.3767e+00,  1.7748e+00,  1.7891e+00,  1.7395e+00,  1.7446e+00,
          1.7838e+00,  1.7869e+00,  1.7371e+00,  1.4958e+00,  1.7765e+00,
          1.5689e+00,  1.6417e+00,  1.6371e+00,  1.6304e+00,  1.5121e+00,
          1.6360e+00,  1.5368e+00,  1.6276e+00,  1.6283e+00],
        [ 1.3006e+00,  1.3034e+00,  1.3070e+00,  1.3053e+00,  1.3034e+00,
          1.3013e+00,  1.3008e+00,  1.3004e+00,  1.3004e+00,  1.3621e+00,
          1.3650e+00,  1.3640e+00,  1.3667e+00,  1.3613e+00,  1.3338e+00,
          1.3628e+00,  1.3371e+00,  1.3399e+00,  2.4220e+00,  2.4169e+00,
          2.4797e+00,  2.4348e+00,  2.3509e+00,  2.3536e+00,  2.4136e+00,
          2.3426e+00,  2.3426e+00,  1.3322e+00,  1.3207e+00,  1.3377e+00,
          1.3408e+00,  1.3322e+00,  1.3392e+00,  1.3421e+00,  1.3376e+00,
          1.3381e+00,  1.7464e+00,  1.7579e+00,  1.7502e+00,  1.7321e+00,
          1.7548e+00,  1.7548e+00,  1.7480e+00,  1.7117e+00,  1.7318e+00,
          1.6254e+00,  1.6104e+00,  1.6061e+00,  1.5998e+00,  1.5919e+00,
          1.6050e+00,  1.6227e+00,  1.5972e+00,  1.5978e+00],
        [ 1.3131e+00,  1.3160e+00,  1.3181e+00,  1.3163e+00,  1.3160e+00,
          1.3138e+00,  1.3140e+00,  1.3130e+00,  1.3130e+00,  1.3745e+00,
          1.3761e+00,  1.3764e+00,  1.3635e+00,  1.3737e+00,  1.2785e+00,
          1.3751e+00,  1.3725e+00,  1.2738e+00,  1.3311e+00,  1.3164e+00,
          1.3330e+00,  1.3322e+00,  1.3286e+00,  1.3276e+00,  1.3302e+00,
          1.3272e+00,  1.3272e+00,  2.5450e+00,  2.5002e+00,  2.2705e+00,
          2.3779e+00,  2.5427e+00,  2.2793e+00,  2.4878e+00,  2.3054e+00,
          2.2722e+00,  1.7550e+00,  1.7668e+00,  1.7366e+00,  1.7548e+00,
          1.7636e+00,  1.7633e+00,  1.7350e+00,  1.6794e+00,  1.7548e+00,
          1.6387e+00,  1.6192e+00,  1.5085e+00,  1.5544e+00,  1.6338e+00,
          1.6124e+00,  1.6506e+00,  1.5517e+00,  1.6069e+00],
        [ 1.8408e+00,  1.4389e+00,  6.0569e-01,  9.1448e-01,  1.3126e+00,
          1.7519e+00,  1.6401e+00,  1.8581e+00,  1.8581e+00,  1.7324e+00,
          1.3179e+00,  1.5246e+00,  9.0943e-01,  1.7584e+00,  1.3132e-01,
          1.6558e+00,  1.8531e+00,  9.0727e-01,  1.3385e+00,  9.3976e-01,
          7.1484e-01,  1.1643e+00,  1.6922e+00,  1.7612e+00,  1.5036e+00,
          1.8654e+00,  1.8654e+00,  8.1176e-01,  8.7463e-01,  1.8377e+00,
          1.6250e+00,  8.5094e-01,  1.7784e+00,  1.2478e+00,  1.8867e+00,
          1.8019e+00,  4.1835e-02, -2.2627e-01, -2.6023e-01,  5.7166e-04,
          2.8934e-01,  3.9943e-01, -9.7319e-02,  1.0592e+01,  6.2953e+00,
          1.8467e-01,  5.5836e-01,  5.9645e-01,  6.9912e-01,  3.5561e-01,
          6.9699e-01, -1.0962e-01,  7.2459e-01,  7.9496e-01],
        [ 1.3326e+00,  1.3710e+00,  1.4180e+00,  1.4050e+00,  1.3798e+00,
          1.3418e+00,  1.3112e+00,  1.3308e+00,  1.3308e+00,  1.2910e+00,
          1.4182e+00,  1.3158e+00,  1.4496e+00,  1.3690e+00,  1.4755e+00,
          1.2997e+00,  1.3573e+00,  1.3561e+00,  1.3886e+00,  1.4036e+00,
          1.4250e+00,  1.4015e+00,  1.3563e+00,  1.3484e+00,  1.2836e+00,
          1.3376e+00,  1.3376e+00,  1.3940e+00,  1.4336e+00,  1.3519e+00,
          1.1716e+00,  1.3490e+00,  1.2414e+00,  1.4079e+00,  1.2308e+00,
          1.3561e+00,  3.4159e-01,  2.6691e-01,  3.8970e-01,  3.4913e-01,
          1.5059e-01,  1.0485e-01,  3.6549e-01,  1.6696e-01, -3.9613e-02,
          2.8691e+00,  2.1069e+00,  2.8157e+00,  2.3668e+00,  1.7376e+00,
          1.3699e+00,  2.6064e+00,  2.5991e+00,  1.3347e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 162 : 176.16554079492408
Test loss for epoch 162 : 175.97386023491316
Test Precision for epoch 162 : 0.26153846153846155
Test Recall for epoch 162 : 0.26153846153846155
Test F1 for epoch 162 : 0.26153846153846155


theta for epoch 163 : tensor([[ 2.3455e+00,  2.3643e+00,  2.4012e+00,  2.4808e+00,  2.4626e+00,
          2.3498e+00,  2.4486e+00,  2.3448e+00,  2.3448e+00,  1.3576e+00,
          1.3604e+00,  1.3594e+00,  1.3627e+00,  1.3568e+00,  1.3648e+00,
          1.3582e+00,  1.3560e+00,  1.3180e+00,  1.3139e+00,  1.2726e+00,
          1.2733e+00,  1.3149e+00,  1.3115e+00,  1.3110e+00,  1.3133e+00,
          1.3101e+00,  1.3101e+00,  1.2953e+00,  1.3390e+00,  1.3328e+00,
          1.3358e+00,  1.3392e+00,  1.3343e+00,  1.3370e+00,  1.2895e+00,
          1.3332e+00,  1.7444e+00,  1.7557e+00,  1.7481e+00,  1.7449e+00,
          1.7526e+00,  1.6935e+00,  1.7460e+00,  1.7326e+00,  1.7446e+00,
          1.6238e+00,  1.6059e+00,  1.6017e+00,  1.5955e+00,  1.6192e+00,
          1.6006e+00,  1.6350e+00,  1.5930e+00,  1.5936e+00],
        [ 1.3170e+00,  1.3116e+00,  1.2025e+00,  1.2684e+00,  1.3430e+00,
          1.3402e+00,  1.3192e+00,  1.3393e+00,  1.3393e+00,  2.3181e+00,
          2.2401e+00,  2.1901e+00,  2.3434e+00,  2.2293e+00,  2.8908e+00,
          2.2956e+00,  2.2271e+00,  2.8626e+00,  1.3023e+00,  1.3266e+00,
          1.2763e+00,  1.2653e+00,  1.3538e+00,  1.3537e+00,  1.3168e+00,
          1.3528e+00,  1.3528e+00,  1.3495e+00,  1.2128e+00,  1.3758e+00,
          1.3786e+00,  1.2705e+00,  1.3774e+00,  1.3802e+00,  1.3467e+00,
          1.3760e+00,  1.7748e+00,  1.7891e+00,  1.7396e+00,  1.7454e+00,
          1.7839e+00,  1.7869e+00,  1.7372e+00,  1.4991e+00,  1.7765e+00,
          1.5680e+00,  1.6398e+00,  1.6352e+00,  1.6285e+00,  1.5115e+00,
          1.6341e+00,  1.5360e+00,  1.6257e+00,  1.6264e+00],
        [ 1.3003e+00,  1.3032e+00,  1.3067e+00,  1.3050e+00,  1.3031e+00,
          1.3010e+00,  1.3005e+00,  1.3002e+00,  1.3002e+00,  1.3618e+00,
          1.3647e+00,  1.3637e+00,  1.3664e+00,  1.3610e+00,  1.3335e+00,
          1.3625e+00,  1.3365e+00,  1.3399e+00,  2.4254e+00,  2.4210e+00,
          2.4833e+00,  2.4380e+00,  2.3547e+00,  2.3573e+00,  2.4172e+00,
          2.3465e+00,  2.3465e+00,  1.3315e+00,  1.3205e+00,  1.3373e+00,
          1.3404e+00,  1.3316e+00,  1.3388e+00,  1.3417e+00,  1.3372e+00,
          1.3376e+00,  1.7468e+00,  1.7582e+00,  1.7505e+00,  1.7322e+00,
          1.7551e+00,  1.7551e+00,  1.7483e+00,  1.7126e+00,  1.7318e+00,
          1.6239e+00,  1.6089e+00,  1.6046e+00,  1.5983e+00,  1.5908e+00,
          1.6035e+00,  1.6212e+00,  1.5956e+00,  1.5963e+00],
        [ 1.3129e+00,  1.3158e+00,  1.3179e+00,  1.3161e+00,  1.3158e+00,
          1.3136e+00,  1.3138e+00,  1.3127e+00,  1.3127e+00,  1.3742e+00,
          1.3759e+00,  1.3761e+00,  1.3632e+00,  1.3734e+00,  1.2782e+00,
          1.3749e+00,  1.3722e+00,  1.2736e+00,  1.3310e+00,  1.3162e+00,
          1.3328e+00,  1.3320e+00,  1.3285e+00,  1.3275e+00,  1.3300e+00,
          1.3271e+00,  1.3271e+00,  2.5488e+00,  2.5038e+00,  2.2736e+00,
          2.3812e+00,  2.5465e+00,  2.2824e+00,  2.4913e+00,  2.3088e+00,
          2.2754e+00,  1.7554e+00,  1.7672e+00,  1.7369e+00,  1.7552e+00,
          1.7640e+00,  1.7637e+00,  1.7352e+00,  1.6799e+00,  1.7551e+00,
          1.6372e+00,  1.6178e+00,  1.5072e+00,  1.5530e+00,  1.6324e+00,
          1.6110e+00,  1.6491e+00,  1.5502e+00,  1.6055e+00],
        [ 1.8397e+00,  1.4371e+00,  6.0343e-01,  9.1288e-01,  1.3113e+00,
          1.7511e+00,  1.6387e+00,  1.8575e+00,  1.8575e+00,  1.7308e+00,
          1.3157e+00,  1.5225e+00,  9.0700e-01,  1.7564e+00,  1.2826e-01,
          1.6538e+00,  1.8523e+00,  9.0353e-01,  1.3363e+00,  9.3815e-01,
          7.1260e-01,  1.1619e+00,  1.6910e+00,  1.7600e+00,  1.5024e+00,
          1.8645e+00,  1.8645e+00,  8.0978e-01,  8.7196e-01,  1.8364e+00,
          1.6238e+00,  8.4856e-01,  1.7770e+00,  1.2459e+00,  1.8855e+00,
          1.8006e+00,  4.1824e-02, -2.2599e-01, -2.6002e-01,  8.0286e-04,
          2.8888e-01,  3.9881e-01, -9.7204e-02,  1.0646e+01,  6.2963e+00,
          1.8153e-01,  5.5535e-01,  5.9336e-01,  6.9593e-01,  3.5216e-01,
          6.9381e-01, -1.1267e-01,  7.2150e-01,  7.9176e-01],
        [ 1.3355e+00,  1.3739e+00,  1.4208e+00,  1.4078e+00,  1.3827e+00,
          1.3447e+00,  1.3142e+00,  1.3337e+00,  1.3337e+00,  1.2947e+00,
          1.4219e+00,  1.3196e+00,  1.4532e+00,  1.3728e+00,  1.4792e+00,
          1.3035e+00,  1.3609e+00,  1.3600e+00,  1.3923e+00,  1.4070e+00,
          1.4287e+00,  1.4052e+00,  1.3600e+00,  1.3522e+00,  1.2871e+00,
          1.3414e+00,  1.3414e+00,  1.3970e+00,  1.4365e+00,  1.3549e+00,
          1.1745e+00,  1.3520e+00,  1.2444e+00,  1.4109e+00,  1.2339e+00,
          1.3591e+00,  3.4505e-01,  2.7044e-01,  3.9305e-01,  3.5256e-01,
          1.5406e-01,  1.0832e-01,  3.6894e-01,  1.7008e-01, -3.6386e-02,
          2.8698e+00,  2.1055e+00,  2.8176e+00,  2.3659e+00,  1.7354e+00,
          1.3671e+00,  2.6053e+00,  2.6009e+00,  1.3320e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 163 : 176.1585295534718
Test loss for epoch 163 : 175.97427376024555
Test Precision for epoch 163 : 0.26153846153846155
Test Recall for epoch 163 : 0.26153846153846155
Test F1 for epoch 163 : 0.26153846153846155


theta for epoch 164 : tensor([[ 2.3486e+00,  2.3675e+00,  2.4043e+00,  2.4842e+00,  2.4660e+00,
          2.3529e+00,  2.4520e+00,  2.3479e+00,  2.3479e+00,  1.3572e+00,
          1.3600e+00,  1.3590e+00,  1.3623e+00,  1.3564e+00,  1.3644e+00,
          1.3578e+00,  1.3555e+00,  1.3176e+00,  1.3134e+00,  1.2721e+00,
          1.2728e+00,  1.3144e+00,  1.3110e+00,  1.3104e+00,  1.3128e+00,
          1.3096e+00,  1.3096e+00,  1.2949e+00,  1.3387e+00,  1.3325e+00,
          1.3355e+00,  1.3389e+00,  1.3340e+00,  1.3367e+00,  1.2891e+00,
          1.3328e+00,  1.7441e+00,  1.7553e+00,  1.7478e+00,  1.7446e+00,
          1.7523e+00,  1.6932e+00,  1.7456e+00,  1.7322e+00,  1.7443e+00,
          1.6246e+00,  1.6067e+00,  1.6025e+00,  1.5964e+00,  1.6200e+00,
          1.6015e+00,  1.6358e+00,  1.5938e+00,  1.5945e+00],
        [ 1.3168e+00,  1.3118e+00,  1.2031e+00,  1.2680e+00,  1.3423e+00,
          1.3394e+00,  1.3191e+00,  1.3386e+00,  1.3386e+00,  2.3232e+00,
          2.2444e+00,  2.1934e+00,  2.3471e+00,  2.2329e+00,  2.8908e+00,
          2.2995e+00,  2.2325e+00,  2.8628e+00,  1.3021e+00,  1.3259e+00,
          1.2757e+00,  1.2653e+00,  1.3529e+00,  1.3528e+00,  1.3161e+00,
          1.3519e+00,  1.3519e+00,  1.3489e+00,  1.2132e+00,  1.3750e+00,
          1.3779e+00,  1.2704e+00,  1.3767e+00,  1.3795e+00,  1.3461e+00,
          1.3753e+00,  1.7742e+00,  1.7884e+00,  1.7390e+00,  1.7455e+00,
          1.7833e+00,  1.7863e+00,  1.7367e+00,  1.5017e+00,  1.7758e+00,
          1.5697e+00,  1.6404e+00,  1.6358e+00,  1.6291e+00,  1.5134e+00,
          1.6347e+00,  1.5378e+00,  1.6263e+00,  1.6270e+00],
        [ 1.3000e+00,  1.3028e+00,  1.3064e+00,  1.3046e+00,  1.3027e+00,
          1.3006e+00,  1.3002e+00,  1.2998e+00,  1.2998e+00,  1.3615e+00,
          1.3643e+00,  1.3633e+00,  1.3661e+00,  1.3607e+00,  1.3332e+00,
          1.3621e+00,  1.3359e+00,  1.3399e+00,  2.4279e+00,  2.4242e+00,
          2.4861e+00,  2.4405e+00,  2.3577e+00,  2.3602e+00,  2.4200e+00,
          2.3494e+00,  2.3494e+00,  1.3310e+00,  1.3205e+00,  1.3370e+00,
          1.3401e+00,  1.3311e+00,  1.3385e+00,  1.3413e+00,  1.3369e+00,
          1.3373e+00,  1.7465e+00,  1.7579e+00,  1.7502e+00,  1.7316e+00,
          1.7548e+00,  1.7548e+00,  1.7480e+00,  1.7128e+00,  1.7312e+00,
          1.6249e+00,  1.6098e+00,  1.6055e+00,  1.5992e+00,  1.5921e+00,
          1.6045e+00,  1.6220e+00,  1.5966e+00,  1.5973e+00],
        [ 1.3125e+00,  1.3154e+00,  1.3175e+00,  1.3158e+00,  1.3153e+00,
          1.3132e+00,  1.3134e+00,  1.3123e+00,  1.3123e+00,  1.3738e+00,
          1.3755e+00,  1.3757e+00,  1.3626e+00,  1.3730e+00,  1.2777e+00,
          1.3744e+00,  1.3717e+00,  1.2732e+00,  1.3304e+00,  1.3156e+00,
          1.3322e+00,  1.3315e+00,  1.3279e+00,  1.3270e+00,  1.3295e+00,
          1.3265e+00,  1.3265e+00,  2.5526e+00,  2.5073e+00,  2.2766e+00,
          2.3844e+00,  2.5502e+00,  2.2854e+00,  2.4946e+00,  2.3121e+00,
          2.2784e+00,  1.7550e+00,  1.7668e+00,  1.7365e+00,  1.7549e+00,
          1.7637e+00,  1.7634e+00,  1.7348e+00,  1.6796e+00,  1.7548e+00,
          1.6379e+00,  1.6186e+00,  1.5080e+00,  1.5537e+00,  1.6331e+00,
          1.6118e+00,  1.6498e+00,  1.5510e+00,  1.6063e+00],
        [ 1.8426e+00,  1.4405e+00,  6.0764e-01,  9.1706e-01,  1.3154e+00,
          1.7545e+00,  1.6419e+00,  1.8607e+00,  1.8607e+00,  1.7343e+00,
          1.3200e+00,  1.5260e+00,  9.1150e-01,  1.7595e+00,  1.3289e-01,
          1.6571e+00,  1.8562e+00,  9.0738e-01,  1.3402e+00,  9.4302e-01,
          7.1755e-01,  1.1658e+00,  1.6949e+00,  1.7638e+00,  1.5064e+00,
          1.8681e+00,  1.8681e+00,  8.1486e-01,  8.7633e-01,  1.8403e+00,
          1.6282e+00,  8.5354e-01,  1.7811e+00,  1.2505e+00,  1.8893e+00,
          1.8045e+00,  3.5927e-02, -2.3129e-01, -2.6536e-01, -4.8433e-03,
          2.8233e-01,  3.9206e-01, -1.0279e-01,  1.0694e+01,  6.2896e+00,
          1.8702e-01,  5.6067e-01,  5.9871e-01,  7.0126e-01,  3.5729e-01,
          6.9915e-01, -1.0708e-01,  7.2684e-01,  7.9701e-01],
        [ 1.3318e+00,  1.3703e+00,  1.4172e+00,  1.4042e+00,  1.3791e+00,
          1.3410e+00,  1.3104e+00,  1.3300e+00,  1.3300e+00,  1.2900e+00,
          1.4174e+00,  1.3149e+00,  1.4486e+00,  1.3683e+00,  1.4745e+00,
          1.2988e+00,  1.3562e+00,  1.3555e+00,  1.3875e+00,  1.4019e+00,
          1.4239e+00,  1.4005e+00,  1.3552e+00,  1.3473e+00,  1.2818e+00,
          1.3365e+00,  1.3365e+00,  1.3931e+00,  1.4328e+00,  1.3511e+00,
          1.1700e+00,  1.3481e+00,  1.2405e+00,  1.4072e+00,  1.2299e+00,
          1.3553e+00,  3.4017e-01,  2.6550e-01,  3.8810e-01,  3.4763e-01,
          1.4894e-01,  1.0318e-01,  3.6409e-01,  1.6460e-01, -4.1940e-02,
          2.8799e+00,  2.1137e+00,  2.8290e+00,  2.3745e+00,  1.7426e+00,
          1.3738e+00,  2.6136e+00,  2.6124e+00,  1.3386e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 164 : 176.14900409694488
Test loss for epoch 164 : 175.9595803112232
Test Precision for epoch 164 : 0.26153846153846155
Test Recall for epoch 164 : 0.26153846153846155
Test F1 for epoch 164 : 0.26153846153846155


theta for epoch 165 : tensor([[ 2.3519e+00,  2.3708e+00,  2.4076e+00,  2.4878e+00,  2.4696e+00,
          2.3562e+00,  2.4557e+00,  2.3513e+00,  2.3513e+00,  1.3571e+00,
          1.3599e+00,  1.3589e+00,  1.3622e+00,  1.3563e+00,  1.3642e+00,
          1.3577e+00,  1.3554e+00,  1.3174e+00,  1.3136e+00,  1.2722e+00,
          1.2730e+00,  1.3146e+00,  1.3112e+00,  1.3106e+00,  1.3130e+00,
          1.3098e+00,  1.3098e+00,  1.2945e+00,  1.3383e+00,  1.3321e+00,
          1.3351e+00,  1.3385e+00,  1.3336e+00,  1.3363e+00,  1.2887e+00,
          1.3324e+00,  1.7446e+00,  1.7559e+00,  1.7483e+00,  1.7451e+00,
          1.7528e+00,  1.6937e+00,  1.7462e+00,  1.7327e+00,  1.7448e+00,
          1.6226e+00,  1.6047e+00,  1.6006e+00,  1.5944e+00,  1.6180e+00,
          1.5995e+00,  1.6338e+00,  1.5919e+00,  1.5925e+00],
        [ 1.3167e+00,  1.3120e+00,  1.2037e+00,  1.2677e+00,  1.3416e+00,
          1.3388e+00,  1.3190e+00,  1.3379e+00,  1.3379e+00,  2.3282e+00,
          2.2488e+00,  2.1968e+00,  2.3508e+00,  2.2364e+00,  2.8909e+00,
          2.3034e+00,  2.2379e+00,  2.8630e+00,  1.3028e+00,  1.3262e+00,
          1.2761e+00,  1.2662e+00,  1.3531e+00,  1.3528e+00,  1.3164e+00,
          1.3520e+00,  1.3520e+00,  1.3485e+00,  1.2136e+00,  1.3744e+00,
          1.3773e+00,  1.2704e+00,  1.3760e+00,  1.3789e+00,  1.3455e+00,
          1.3747e+00,  1.7745e+00,  1.7887e+00,  1.7394e+00,  1.7465e+00,
          1.7836e+00,  1.7865e+00,  1.7370e+00,  1.5052e+00,  1.7761e+00,
          1.5684e+00,  1.6381e+00,  1.6335e+00,  1.6268e+00,  1.5124e+00,
          1.6324e+00,  1.5366e+00,  1.6240e+00,  1.6248e+00],
        [ 1.2996e+00,  1.3025e+00,  1.3061e+00,  1.3043e+00,  1.3024e+00,
          1.3003e+00,  1.2999e+00,  1.2995e+00,  1.2995e+00,  1.3616e+00,
          1.3644e+00,  1.3635e+00,  1.3662e+00,  1.3608e+00,  1.3334e+00,
          1.3622e+00,  1.3357e+00,  1.3404e+00,  2.4309e+00,  2.4279e+00,
          2.4893e+00,  2.4433e+00,  2.3611e+00,  2.3635e+00,  2.4233e+00,
          2.3529e+00,  2.3529e+00,  1.3305e+00,  1.3204e+00,  1.3367e+00,
          1.3398e+00,  1.3306e+00,  1.3383e+00,  1.3411e+00,  1.3366e+00,
          1.3371e+00,  1.7470e+00,  1.7585e+00,  1.7508e+00,  1.7319e+00,
          1.7554e+00,  1.7554e+00,  1.7486e+00,  1.7140e+00,  1.7315e+00,
          1.6231e+00,  1.6079e+00,  1.6037e+00,  1.5974e+00,  1.5906e+00,
          1.6026e+00,  1.6202e+00,  1.5947e+00,  1.5954e+00],
        [ 1.3121e+00,  1.3150e+00,  1.3172e+00,  1.3154e+00,  1.3149e+00,
          1.3127e+00,  1.3130e+00,  1.3119e+00,  1.3119e+00,  1.3737e+00,
          1.3754e+00,  1.3756e+00,  1.3625e+00,  1.3729e+00,  1.2776e+00,
          1.3744e+00,  1.3716e+00,  1.2731e+00,  1.3306e+00,  1.3156e+00,
          1.3324e+00,  1.3316e+00,  1.3281e+00,  1.3271e+00,  1.3296e+00,
          1.3267e+00,  1.3267e+00,  2.5564e+00,  2.5110e+00,  2.2797e+00,
          2.3877e+00,  2.5540e+00,  2.2885e+00,  2.4981e+00,  2.3154e+00,
          2.2815e+00,  1.7556e+00,  1.7674e+00,  1.7370e+00,  1.7554e+00,
          1.7642e+00,  1.7639e+00,  1.7353e+00,  1.6803e+00,  1.7553e+00,
          1.6360e+00,  1.6167e+00,  1.5062e+00,  1.5518e+00,  1.6312e+00,
          1.6100e+00,  1.6479e+00,  1.5491e+00,  1.6044e+00],
        [ 1.8407e+00,  1.4377e+00,  6.0435e-01,  9.1450e-01,  1.3131e+00,
          1.7529e+00,  1.6397e+00,  1.8593e+00,  1.8593e+00,  1.7319e+00,
          1.3169e+00,  1.5232e+00,  9.0812e-01,  1.7568e+00,  1.2874e-01,
          1.6543e+00,  1.8546e+00,  9.0260e-01,  1.3372e+00,  9.4051e-01,
          7.1433e-01,  1.1626e+00,  1.6929e+00,  1.7619e+00,  1.5045e+00,
          1.8665e+00,  1.8665e+00,  8.1185e-01,  8.7262e-01,  1.8382e+00,
          1.6261e+00,  8.5009e-01,  1.7789e+00,  1.2476e+00,  1.8873e+00,
          1.8024e+00,  3.6882e-02, -2.3009e-01, -2.6425e-01, -3.6563e-03,
          2.8285e-01,  3.9244e-01, -1.0174e-01,  1.0748e+01,  6.2910e+00,
          1.8268e-01,  5.5652e-01,  5.9446e-01,  6.9692e-01,  3.5266e-01,
          6.9482e-01, -1.1136e-01,  7.2262e-01,  7.9268e-01],
        [ 1.3355e+00,  1.3739e+00,  1.4207e+00,  1.4077e+00,  1.3826e+00,
          1.3446e+00,  1.3141e+00,  1.3336e+00,  1.3336e+00,  1.2948e+00,
          1.4221e+00,  1.3199e+00,  1.4534e+00,  1.3731e+00,  1.4793e+00,
          1.3037e+00,  1.3609e+00,  1.3604e+00,  1.3925e+00,  1.4065e+00,
          1.4288e+00,  1.4054e+00,  1.3601e+00,  1.3523e+00,  1.2865e+00,
          1.3414e+00,  1.3414e+00,  1.3969e+00,  1.4365e+00,  1.3549e+00,
          1.1737e+00,  1.3519e+00,  1.2444e+00,  1.4109e+00,  1.2339e+00,
          1.3591e+00,  3.4480e-01,  2.7019e-01,  3.9262e-01,  3.5222e-01,
          1.5359e-01,  1.0783e-01,  3.6870e-01,  1.6892e-01, -3.7513e-02,
          2.8794e+00,  2.1111e+00,  2.8297e+00,  2.3723e+00,  1.7391e+00,
          1.3698e+00,  2.6113e+00,  2.6129e+00,  1.3347e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 165 : 176.13643506498823
Test loss for epoch 165 : 175.95618259297828
Test Precision for epoch 165 : 0.26153846153846155
Test Recall for epoch 165 : 0.26153846153846155
Test F1 for epoch 165 : 0.26153846153846155


theta for epoch 166 : tensor([[ 2.3551e+00,  2.3740e+00,  2.4108e+00,  2.4913e+00,  2.4731e+00,
          2.3593e+00,  2.4592e+00,  2.3544e+00,  2.3544e+00,  1.3566e+00,
          1.3594e+00,  1.3585e+00,  1.3618e+00,  1.3559e+00,  1.3638e+00,
          1.3573e+00,  1.3550e+00,  1.3170e+00,  1.3129e+00,  1.2716e+00,
          1.2723e+00,  1.3139e+00,  1.3105e+00,  1.3100e+00,  1.3123e+00,
          1.3092e+00,  1.3092e+00,  1.2941e+00,  1.3378e+00,  1.3317e+00,
          1.3347e+00,  1.3380e+00,  1.3331e+00,  1.3358e+00,  1.2883e+00,
          1.3320e+00,  1.7442e+00,  1.7554e+00,  1.7479e+00,  1.7447e+00,
          1.7524e+00,  1.6932e+00,  1.7457e+00,  1.7323e+00,  1.7443e+00,
          1.6236e+00,  1.6058e+00,  1.6016e+00,  1.5955e+00,  1.6190e+00,
          1.6006e+00,  1.6347e+00,  1.5929e+00,  1.5936e+00],
        [ 1.3164e+00,  1.3121e+00,  1.2042e+00,  1.2673e+00,  1.3408e+00,
          1.3380e+00,  1.3188e+00,  1.3371e+00,  1.3371e+00,  2.3330e+00,
          2.2530e+00,  2.2000e+00,  2.3544e+00,  2.2399e+00,  2.8910e+00,
          2.3071e+00,  2.2432e+00,  2.8633e+00,  1.3026e+00,  1.3255e+00,
          1.2755e+00,  1.2662e+00,  1.3522e+00,  1.3520e+00,  1.3157e+00,
          1.3511e+00,  1.3511e+00,  1.3480e+00,  1.2140e+00,  1.3738e+00,
          1.3767e+00,  1.2704e+00,  1.3754e+00,  1.3782e+00,  1.3449e+00,
          1.3740e+00,  1.7739e+00,  1.7880e+00,  1.7388e+00,  1.7465e+00,
          1.7829e+00,  1.7858e+00,  1.7364e+00,  1.5078e+00,  1.7754e+00,
          1.5704e+00,  1.6391e+00,  1.6345e+00,  1.6278e+00,  1.5147e+00,
          1.6334e+00,  1.5386e+00,  1.6250e+00,  1.6258e+00],
        [ 1.2992e+00,  1.3020e+00,  1.3056e+00,  1.3038e+00,  1.3019e+00,
          1.2998e+00,  1.2994e+00,  1.2990e+00,  1.2990e+00,  1.3613e+00,
          1.3642e+00,  1.3632e+00,  1.3659e+00,  1.3605e+00,  1.3331e+00,
          1.3620e+00,  1.3352e+00,  1.3405e+00,  2.4334e+00,  2.4312e+00,
          2.4922e+00,  2.4458e+00,  2.3641e+00,  2.3663e+00,  2.4261e+00,
          2.3558e+00,  2.3558e+00,  1.3300e+00,  1.3204e+00,  1.3364e+00,
          1.3395e+00,  1.3301e+00,  1.3379e+00,  1.3407e+00,  1.3363e+00,
          1.3367e+00,  1.7466e+00,  1.7581e+00,  1.7504e+00,  1.7312e+00,
          1.7550e+00,  1.7550e+00,  1.7482e+00,  1.7141e+00,  1.7308e+00,
          1.6243e+00,  1.6091e+00,  1.6048e+00,  1.5985e+00,  1.5922e+00,
          1.6038e+00,  1.6213e+00,  1.5959e+00,  1.5966e+00],
        [ 1.3115e+00,  1.3145e+00,  1.3167e+00,  1.3149e+00,  1.3144e+00,
          1.3122e+00,  1.3125e+00,  1.3114e+00,  1.3114e+00,  1.3733e+00,
          1.3751e+00,  1.3752e+00,  1.3621e+00,  1.3725e+00,  1.2772e+00,
          1.3740e+00,  1.3712e+00,  1.2728e+00,  1.3300e+00,  1.3150e+00,
          1.3318e+00,  1.3310e+00,  1.3275e+00,  1.3266e+00,  1.3290e+00,
          1.3261e+00,  1.3261e+00,  2.5600e+00,  2.5144e+00,  2.2827e+00,
          2.3909e+00,  2.5577e+00,  2.2914e+00,  2.5014e+00,  2.3187e+00,
          2.2844e+00,  1.7552e+00,  1.7670e+00,  1.7365e+00,  1.7550e+00,
          1.7638e+00,  1.7635e+00,  1.7348e+00,  1.6800e+00,  1.7549e+00,
          1.6370e+00,  1.6177e+00,  1.5072e+00,  1.5529e+00,  1.6322e+00,
          1.6111e+00,  1.6488e+00,  1.5501e+00,  1.6055e+00],
        [ 1.8433e+00,  1.4409e+00,  6.0831e-01,  9.1844e-01,  1.3170e+00,
          1.7561e+00,  1.6426e+00,  1.8624e+00,  1.8624e+00,  1.7352e+00,
          1.3210e+00,  1.5265e+00,  9.1245e-01,  1.7599e+00,  1.3315e-01,
          1.6574e+00,  1.8584e+00,  9.0628e-01,  1.3409e+00,  9.4518e-01,
          7.1906e-01,  1.1663e+00,  1.6967e+00,  1.7654e+00,  1.5084e+00,
          1.8700e+00,  1.8700e+00,  8.1671e-01,  8.7676e-01,  1.8420e+00,
          1.6303e+00,  8.5485e-01,  1.7827e+00,  1.2521e+00,  1.8910e+00,
          1.8062e+00,  3.1220e-02, -2.3519e-01, -2.6938e-01, -9.0788e-03,
          2.7654e-01,  3.8592e-01, -1.0710e-01,  1.0796e+01,  6.2838e+00,
          1.8807e-01,  5.6176e-01,  5.9974e-01,  7.0219e-01,  3.5770e-01,
          7.0009e-01, -1.0593e-01,  7.2792e-01,  7.9788e-01],
        [ 1.3320e+00,  1.3704e+00,  1.4172e+00,  1.4042e+00,  1.3791e+00,
          1.3411e+00,  1.3105e+00,  1.3300e+00,  1.3300e+00,  1.2905e+00,
          1.4180e+00,  1.3156e+00,  1.4492e+00,  1.3690e+00,  1.4750e+00,
          1.2994e+00,  1.3565e+00,  1.3563e+00,  1.3880e+00,  1.4016e+00,
          1.4243e+00,  1.4009e+00,  1.3555e+00,  1.3477e+00,  1.2815e+00,
          1.3368e+00,  1.3368e+00,  1.3932e+00,  1.4330e+00,  1.3513e+00,
          1.1695e+00,  1.3483e+00,  1.2407e+00,  1.4074e+00,  1.2301e+00,
          1.3555e+00,  3.4024e-01,  2.6556e-01,  3.8798e-01,  3.4761e-01,
          1.4880e-01,  1.0301e-01,  3.6416e-01,  1.6379e-01, -4.2731e-02,
          2.8893e+00,  2.1188e+00,  2.8408e+00,  2.3805e+00,  1.7459e+00,
          1.3762e+00,  2.6192e+00,  2.6241e+00,  1.3410e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 166 : 176.1208800533049
Test loss for epoch 166 : 175.93583420327755
Test Precision for epoch 166 : 0.26153846153846155
Test Recall for epoch 166 : 0.26153846153846155
Test F1 for epoch 166 : 0.26153846153846155


theta for epoch 167 : tensor([[ 2.3585e+00,  2.3774e+00,  2.4141e+00,  2.4949e+00,  2.4767e+00,
          2.3627e+00,  2.4628e+00,  2.3578e+00,  2.3578e+00,  1.3564e+00,
          1.3592e+00,  1.3583e+00,  1.3616e+00,  1.3557e+00,  1.3636e+00,
          1.3571e+00,  1.3548e+00,  1.3168e+00,  1.3127e+00,  1.2714e+00,
          1.2721e+00,  1.3137e+00,  1.3103e+00,  1.3098e+00,  1.3122e+00,
          1.3090e+00,  1.3090e+00,  1.2937e+00,  1.3374e+00,  1.3313e+00,
          1.3343e+00,  1.3376e+00,  1.3328e+00,  1.3355e+00,  1.2879e+00,
          1.3316e+00,  1.7444e+00,  1.7556e+00,  1.7481e+00,  1.7449e+00,
          1.7526e+00,  1.6934e+00,  1.7459e+00,  1.7324e+00,  1.7445e+00,
          1.6224e+00,  1.6046e+00,  1.6004e+00,  1.5943e+00,  1.6179e+00,
          1.5994e+00,  1.6335e+00,  1.5917e+00,  1.5924e+00],
        [ 1.3163e+00,  1.3124e+00,  1.2049e+00,  1.2670e+00,  1.3402e+00,
          1.3374e+00,  1.3187e+00,  1.3365e+00,  1.3365e+00,  2.3380e+00,
          2.2574e+00,  2.2034e+00,  2.3581e+00,  2.2434e+00,  2.8912e+00,
          2.3110e+00,  2.2486e+00,  2.8636e+00,  1.3029e+00,  1.3254e+00,
          1.2755e+00,  1.2667e+00,  1.3519e+00,  1.3517e+00,  1.3157e+00,
          1.3508e+00,  1.3508e+00,  1.3475e+00,  1.2145e+00,  1.3732e+00,
          1.3761e+00,  1.2704e+00,  1.3748e+00,  1.3776e+00,  1.3444e+00,
          1.3734e+00,  1.7739e+00,  1.7879e+00,  1.7388e+00,  1.7472e+00,
          1.7829e+00,  1.7858e+00,  1.7365e+00,  1.5110e+00,  1.7753e+00,
          1.5700e+00,  1.6377e+00,  1.6331e+00,  1.6264e+00,  1.5145e+00,
          1.6320e+00,  1.5383e+00,  1.6236e+00,  1.6244e+00],
        [ 1.2988e+00,  1.3016e+00,  1.3052e+00,  1.3034e+00,  1.3015e+00,
          1.2995e+00,  1.2991e+00,  1.2986e+00,  1.2986e+00,  1.3611e+00,
          1.3640e+00,  1.3630e+00,  1.3658e+00,  1.3603e+00,  1.3329e+00,
          1.3618e+00,  1.3347e+00,  1.3406e+00,  2.4367e+00,  2.4351e+00,
          2.4957e+00,  2.4489e+00,  2.3678e+00,  2.3698e+00,  2.4297e+00,
          2.3595e+00,  2.3595e+00,  1.3294e+00,  1.3202e+00,  1.3360e+00,
          1.3391e+00,  1.3295e+00,  1.3375e+00,  1.3403e+00,  1.3359e+00,
          1.3363e+00,  1.7468e+00,  1.7583e+00,  1.7506e+00,  1.7311e+00,
          1.7552e+00,  1.7552e+00,  1.7484e+00,  1.7148e+00,  1.7307e+00,
          1.6232e+00,  1.6079e+00,  1.6036e+00,  1.5974e+00,  1.5914e+00,
          1.6026e+00,  1.6201e+00,  1.5947e+00,  1.5954e+00],
        [ 1.3112e+00,  1.3141e+00,  1.3164e+00,  1.3146e+00,  1.3141e+00,
          1.3119e+00,  1.3121e+00,  1.3111e+00,  1.3111e+00,  1.3732e+00,
          1.3750e+00,  1.3751e+00,  1.3619e+00,  1.3724e+00,  1.2771e+00,
          1.3739e+00,  1.3711e+00,  1.2727e+00,  1.3299e+00,  1.3149e+00,
          1.3317e+00,  1.3310e+00,  1.3274e+00,  1.3265e+00,  1.3289e+00,
          1.3260e+00,  1.3260e+00,  2.5637e+00,  2.5179e+00,  2.2857e+00,
          2.3940e+00,  2.5614e+00,  2.2944e+00,  2.5047e+00,  2.3219e+00,
          2.2874e+00,  1.7554e+00,  1.7672e+00,  1.7367e+00,  1.7552e+00,
          1.7641e+00,  1.7638e+00,  1.7349e+00,  1.6803e+00,  1.7551e+00,
          1.6359e+00,  1.6167e+00,  1.5062e+00,  1.5518e+00,  1.6312e+00,
          1.6101e+00,  1.6477e+00,  1.5491e+00,  1.6044e+00],
        [ 1.8422e+00,  1.4391e+00,  6.0614e-01,  9.1687e-01,  1.3157e+00,
          1.7553e+00,  1.6412e+00,  1.8617e+00,  1.8617e+00,  1.7336e+00,
          1.3190e+00,  1.5246e+00,  9.1023e-01,  1.7580e+00,  1.3028e-01,
          1.6555e+00,  1.8576e+00,  9.0279e-01,  1.3389e+00,  9.4371e-01,
          7.1700e-01,  1.1641e+00,  1.6955e+00,  1.7643e+00,  1.5072e+00,
          1.8691e+00,  1.8691e+00,  8.1491e-01,  8.7423e-01,  1.8408e+00,
          1.6292e+00,  8.5266e-01,  1.7814e+00,  1.2503e+00,  1.8899e+00,
          1.8049e+00,  3.1202e-02, -2.3492e-01, -2.6920e-01, -8.8719e-03,
          2.7605e-01,  3.8528e-01, -1.0699e-01,  1.0850e+01,  6.2832e+00,
          1.8535e-01,  5.5920e-01,  5.9711e-01,  6.9950e-01,  3.5469e-01,
          6.9740e-01, -1.0864e-01,  7.2533e-01,  7.9520e-01],
        [ 1.3347e+00,  1.3731e+00,  1.4198e+00,  1.4068e+00,  1.3817e+00,
          1.3437e+00,  1.3133e+00,  1.3327e+00,  1.3327e+00,  1.2941e+00,
          1.4215e+00,  1.3192e+00,  1.4527e+00,  1.3726e+00,  1.4785e+00,
          1.3031e+00,  1.3600e+00,  1.3600e+00,  1.3916e+00,  1.4048e+00,
          1.4277e+00,  1.4045e+00,  1.3590e+00,  1.3513e+00,  1.2848e+00,
          1.3403e+00,  1.3403e+00,  1.3960e+00,  1.4358e+00,  1.3542e+00,
          1.1722e+00,  1.3511e+00,  1.2436e+00,  1.4102e+00,  1.2330e+00,
          1.3584e+00,  3.4357e-01,  2.6893e-01,  3.9119e-01,  3.5090e-01,
          1.5211e-01,  1.0632e-01,  3.6748e-01,  1.6678e-01, -3.9662e-02,
          2.8902e+00,  2.1177e+00,  2.8429e+00,  2.3798e+00,  1.7439e+00,
          1.3737e+00,  2.6184e+00,  2.6261e+00,  1.3385e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 167 : 176.10480191875837
Test loss for epoch 167 : 175.9269146514208
Test Precision for epoch 167 : 0.26153846153846155
Test Recall for epoch 167 : 0.26153846153846155
Test F1 for epoch 167 : 0.26153846153846155


theta for epoch 168 : tensor([[ 2.3616,  2.3805,  2.4172,  2.4983,  2.4801,  2.3658,  2.4663,  2.3609,
          2.3609,  1.3561,  1.3589,  1.3580,  1.3613,  1.3554,  1.3633,  1.3568,
          1.3545,  1.3165,  1.3122,  1.2709,  1.2716,  1.3132,  1.3098,  1.3093,
          1.3117,  1.3085,  1.3085,  1.2934,  1.3372,  1.3310,  1.3340,  1.3374,
          1.3325,  1.3352,  1.2877,  1.3313,  1.7441,  1.7553,  1.7478,  1.7445,
          1.7523,  1.6930,  1.7456,  1.7321,  1.7442,  1.6228,  1.6051,  1.6009,
          1.5948,  1.6184,  1.5999,  1.6340,  1.5923,  1.5929],
        [ 1.3162,  1.3126,  1.2056,  1.2667,  1.3396,  1.3368,  1.3187,  1.3359,
          1.3359,  2.3428,  2.2616,  2.2066,  2.3618,  2.2469,  2.8914,  2.3148,
          2.2539,  2.8640,  1.3026,  1.3246,  1.2749,  1.2667,  1.3511,  1.3508,
          1.3150,  1.3499,  1.3499,  1.3471,  1.2150,  1.3726,  1.3755,  1.2704,
          1.3742,  1.3770,  1.3438,  1.3728,  1.7733,  1.7873,  1.7383,  1.7473,
          1.7823,  1.7852,  1.7359,  1.5136,  1.7746,  1.5713,  1.6380,  1.6334,
          1.6267,  1.5160,  1.6323,  1.5396,  1.6239,  1.6247],
        [ 1.2984,  1.3013,  1.3048,  1.3031,  1.3012,  1.2991,  1.2987,  1.2983,
          1.2983,  1.3607,  1.3635,  1.3626,  1.3654,  1.3599,  1.3325,  1.3614,
          1.3340,  1.3405,  2.4396,  2.4388,  2.4989,  2.4518,  2.3711,  2.3731,
          2.4329,  2.3629,  2.3629,  1.3288,  1.3201,  1.3357,  1.3387,  1.3290,
          1.3372,  1.3400,  1.3356,  1.3360,  1.7465,  1.7579,  1.7503,  1.7305,
          1.7548,  1.7549,  1.7480,  1.7150,  1.7300,  1.6236,  1.6083,  1.6040,
          1.5978,  1.5922,  1.6030,  1.6205,  1.5951,  1.5959],
        [ 1.3109,  1.3139,  1.3162,  1.3144,  1.3138,  1.3116,  1.3119,  1.3108,
          1.3108,  1.3729,  1.3748,  1.3748,  1.3616,  1.3721,  1.2768,  1.3736,
          1.3708,  1.2725,  1.3295,  1.3143,  1.3313,  1.3305,  1.3269,  1.3260,
          1.3285,  1.3255,  1.3255,  2.5672,  2.5212,  2.2885,  2.3970,  2.5649,
          2.2973,  2.5078,  2.3250,  2.2903,  1.7551,  1.7669,  1.7363,  1.7549,
          1.7637,  1.7635,  1.7345,  1.6801,  1.7547,  1.6364,  1.6172,  1.5068,
          1.5523,  1.6317,  1.6107,  1.6482,  1.5496,  1.6049],
        [ 1.8438,  1.4410,  0.6084,  0.9193,  1.3181,  1.7574,  1.6430,  1.8637,
          1.8637,  1.7355,  1.3213,  1.5264,  0.9127,  1.7596,  0.1326,  1.6572,
          1.8600,  0.9044,  1.3409,  0.9466,  0.7198,  1.1661,  1.6977,  1.7664,
          1.5096,  1.8712,  1.8712,  0.8179,  0.8765,  1.8431,  1.6319,  0.8555,
          1.7838,  1.2530,  1.8922,  1.8073,  0.0272, -0.2385, -0.2728, -0.0127,
          0.2714,  0.3805, -0.1108, 10.8988,  6.2772,  0.1885,  0.5623,  0.6002,
          0.7026,  0.3575,  0.7005, -0.1055,  0.7284,  0.7982],
        [ 1.3331,  1.3715,  1.4181,  1.4051,  1.3801,  1.3421,  1.3116,  1.3310,
          1.3310,  1.2920,  1.4195,  1.3172,  1.4507,  1.3706,  1.4764,  1.3010,
          1.3578,  1.3580,  1.3893,  1.4022,  1.4255,  1.4022,  1.3567,  1.3490,
          1.2821,  1.3380,  1.3380,  1.3942,  1.4342,  1.3525,  1.1700,  1.3493,
          1.2418,  1.4085,  1.2312,  1.3567,  0.3412,  0.2665,  0.3888,  0.3485,
          0.1496,  0.1038,  0.3652,  0.1640, -0.0425,  2.8976,  2.1229,  2.8514,
          2.3855,  1.7482,  1.3775,  2.6238,  2.6347,  1.3422]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 168 : 176.08971952165666
Test loss for epoch 168 : 175.9104595661147
Test Precision for epoch 168 : 0.26153846153846155
Test Recall for epoch 168 : 0.26153846153846155
Test F1 for epoch 168 : 0.26153846153846155


theta for epoch 169 : tensor([[ 2.3646,  2.3835,  2.4202,  2.5016,  2.4834,  2.3688,  2.4696,  2.3638,
          2.3638,  1.3561,  1.3588,  1.3579,  1.3612,  1.3553,  1.3632,  1.3567,
          1.3544,  1.3164,  1.3121,  1.2707,  1.2715,  1.3131,  1.3097,  1.3092,
          1.3115,  1.3083,  1.3083,  1.2933,  1.3371,  1.3309,  1.3339,  1.3373,
          1.3324,  1.3351,  1.2875,  1.3312,  1.7441,  1.7553,  1.7478,  1.7446,
          1.7523,  1.6930,  1.7456,  1.7321,  1.7442,  1.6223,  1.6045,  1.6004,
          1.5943,  1.6178,  1.5993,  1.6334,  1.5917,  1.5924],
        [ 1.3161,  1.3129,  1.2064,  1.2666,  1.3391,  1.3362,  1.3187,  1.3354,
          1.3354,  2.3476,  2.2659,  2.2099,  2.3655,  2.2503,  2.8917,  2.3187,
          2.2593,  2.8644,  1.3027,  1.3242,  1.2746,  1.2669,  1.3505,  1.3503,
          1.3147,  1.3494,  1.3494,  1.3468,  1.2157,  1.3721,  1.3750,  1.2706,
          1.3737,  1.3766,  1.3434,  1.3724,  1.7731,  1.7870,  1.7381,  1.7478,
          1.7821,  1.7849,  1.7357,  1.5165,  1.7743,  1.5713,  1.6370,  1.6324,
          1.6258,  1.5163,  1.6314,  1.5398,  1.6230,  1.6238],
        [ 1.2981,  1.3010,  1.3045,  1.3028,  1.3009,  1.2988,  1.2985,  1.2980,
          1.2980,  1.3604,  1.3633,  1.3623,  1.3651,  1.3597,  1.3323,  1.3611,
          1.3334,  1.3406,  2.4425,  2.4425,  2.5022,  2.4546,  2.3745,  2.3763,
          2.4362,  2.3663,  2.3663,  1.3283,  1.3201,  1.3355,  1.3385,  1.3285,
          1.3370,  1.3397,  1.3353,  1.3358,  1.7464,  1.7579,  1.7502,  1.7301,
          1.7548,  1.7548,  1.7480,  1.7154,  1.7297,  1.6230,  1.6076,  1.6033,
          1.5971,  1.5918,  1.6023,  1.6198,  1.5944,  1.5952],
        [ 1.3108,  1.3137,  1.3160,  1.3143,  1.3136,  1.3114,  1.3117,  1.3106,
          1.3106,  1.3728,  1.3747,  1.3747,  1.3614,  1.3720,  1.2767,  1.3735,
          1.3707,  1.2724,  1.3293,  1.3141,  1.3311,  1.3303,  1.3268,  1.3259,
          1.3283,  1.3254,  1.3254,  2.5706,  2.5245,  2.2913,  2.4000,  2.5684,
          2.3001,  2.5110,  2.3281,  2.2931,  1.7551,  1.7669,  1.7363,  1.7549,
          1.7638,  1.7635,  1.7345,  1.6802,  1.7547,  1.6358,  1.6166,  1.5063,
          1.5518,  1.6311,  1.6102,  1.6475,  1.5490,  1.6044],
        [ 1.8439,  1.4409,  0.6083,  0.9195,  1.3186,  1.7579,  1.6430,  1.8642,
          1.8642,  1.7354,  1.3213,  1.5261,  0.9126,  1.7593,  0.1321,  1.6569,
          1.8607,  0.9033,  1.3407,  0.9471,  0.7199,  1.1658,  1.6981,  1.7667,
          1.5101,  1.8716,  1.8716,  0.8183,  0.8762,  1.8436,  1.6326,  0.8556,
          1.7843,  1.2533,  1.8927,  1.8078,  0.0254, -0.2399, -0.2743, -0.0142,
          0.2691,  0.3780, -0.1124, 10.9503,  6.2736,  0.1884,  0.5622,  0.6001,
          0.7025,  0.3571,  0.7004, -0.1056,  0.7284,  0.7981],
        [ 1.3337,  1.3721,  1.4187,  1.4057,  1.3807,  1.3427,  1.3122,  1.3316,
          1.3316,  1.2928,  1.4203,  1.3181,  1.4515,  1.3715,  1.4772,  1.3020,
          1.3586,  1.3590,  1.3901,  1.4026,  1.4261,  1.4030,  1.3574,  1.3497,
          1.2825,  1.3387,  1.3387,  1.3949,  1.4348,  1.3532,  1.1704,  1.3500,
          1.2425,  1.4092,  1.2319,  1.3574,  0.3419,  0.2672,  0.3893,  0.3491,
          0.1501,  0.1043,  0.3658,  0.1642, -0.0423,  2.9016,  2.1247,  2.8565,
          2.3879,  1.7492,  1.3779,  2.6260,  2.6398,  1.3427]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 169 : 176.07667462799242
Test loss for epoch 169 : 175.90062387236608
Test Precision for epoch 169 : 0.26153846153846155
Test Recall for epoch 169 : 0.26153846153846155
Test F1 for epoch 169 : 0.26153846153846155


theta for epoch 170 : tensor([[ 2.3675,  2.3864,  2.4231,  2.5049,  2.4867,  2.3717,  2.4729,  2.3668,
          2.3668,  1.3559,  1.3587,  1.3578,  1.3611,  1.3552,  1.3631,  1.3566,
          1.3543,  1.3163,  1.3121,  1.2707,  1.2714,  1.3131,  1.3096,  1.3091,
          1.3115,  1.3083,  1.3083,  1.2931,  1.3369,  1.3308,  1.3338,  1.3371,
          1.3323,  1.3349,  1.2874,  1.3311,  1.7442,  1.7554,  1.7479,  1.7446,
          1.7524,  1.6931,  1.7457,  1.7321,  1.7442,  1.6217,  1.6040,  1.5998,
          1.5937,  1.6172,  1.5988,  1.6328,  1.5911,  1.5918],
        [ 1.3161,  1.3131,  1.2071,  1.2664,  1.3385,  1.3357,  1.3187,  1.3348,
          1.3348,  2.3524,  2.2701,  2.2132,  2.3692,  2.2538,  2.8920,  2.3224,
          2.2646,  2.8647,  1.3027,  1.3238,  1.2743,  1.2672,  1.3500,  1.3497,
          1.3144,  1.3488,  1.3488,  1.3464,  1.2163,  1.3716,  1.3745,  1.2707,
          1.3732,  1.3760,  1.3429,  1.3718,  1.7729,  1.7868,  1.7380,  1.7483,
          1.7819,  1.7846,  1.7355,  1.5195,  1.7741,  1.5713,  1.6361,  1.6315,
          1.6249,  1.5165,  1.6304,  1.5398,  1.6221,  1.6228],
        [ 1.2979,  1.3008,  1.3043,  1.3026,  1.3007,  1.2986,  1.2982,  1.2978,
          1.2978,  1.3602,  1.3631,  1.3621,  1.3649,  1.3594,  1.3321,  1.3609,
          1.3329,  1.3407,  2.4453,  2.4461,  2.5054,  2.4573,  2.3777,  2.3794,
          2.4394,  2.3695,  2.3695,  1.3279,  1.3201,  1.3352,  1.3383,  1.3281,
          1.3367,  1.3395,  1.3351,  1.3356,  1.7465,  1.7579,  1.7503,  1.7299,
          1.7548,  1.7549,  1.7480,  1.7160,  1.7294,  1.6224,  1.6069,  1.6026,
          1.5964,  1.5915,  1.6016,  1.6191,  1.5937,  1.5945],
        [ 1.3106,  1.3135,  1.3159,  1.3141,  1.3134,  1.3112,  1.3115,  1.3104,
          1.3104,  1.3726,  1.3745,  1.3746,  1.3612,  1.3719,  1.2765,  1.3733,
          1.3705,  1.2723,  1.3292,  1.3139,  1.3309,  1.3302,  1.3266,  1.3257,
          1.3281,  1.3252,  1.3252,  2.5741,  2.5279,  2.2942,  2.4030,  2.5719,
          2.3029,  2.5141,  2.3311,  2.2959,  1.7552,  1.7670,  1.7363,  1.7550,
          1.7638,  1.7636,  1.7345,  1.6804,  1.7547,  1.6352,  1.6160,  1.5058,
          1.5512,  1.6305,  1.6096,  1.6469,  1.5484,  1.6038],
        [ 1.8442,  1.4409,  0.6083,  0.9200,  1.3192,  1.7586,  1.6433,  1.8649,
          1.8649,  1.7355,  1.3215,  1.5261,  0.9128,  1.7591,  0.1319,  1.6567,
          1.8615,  0.9024,  1.3408,  0.9479,  0.7203,  1.1657,  1.6986,  1.7672,
          1.5107,  1.8722,  1.8722,  0.8190,  0.8761,  1.8442,  1.6335,  0.8560,
          1.7849,  1.2538,  1.8934,  1.8084,  0.0235, -0.2415, -0.2759, -0.0160,
          0.2666,  0.3753, -0.1141, 11.0015,  6.2694,  0.1886,  0.5625,  0.6003,
          0.7026,  0.3570,  0.7005, -0.1054,  0.7287,  0.7982],
        [ 1.3341,  1.3725,  1.4190,  1.4061,  1.3810,  1.3430,  1.3126,  1.3320,
          1.3320,  1.2933,  1.4209,  1.3187,  1.4520,  1.3721,  1.4777,  1.3025,
          1.3590,  1.3596,  1.3905,  1.4027,  1.4265,  1.4034,  1.3579,  1.3502,
          1.2826,  1.3391,  1.3391,  1.3952,  1.4352,  1.3536,  1.1704,  1.3504,
          1.2429,  1.4096,  1.2323,  1.3578,  0.3423,  0.2676,  0.3896,  0.3495,
          0.1504,  0.1046,  0.3662,  0.1642, -0.0423,  2.9060,  2.1269,  2.8620,
          2.3905,  1.7504,  1.3787,  2.6284,  2.6453,  1.3434]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 170 : 176.06556573853396
Test loss for epoch 170 : 175.89232305226523
Test Precision for epoch 170 : 0.26153846153846155
Test Recall for epoch 170 : 0.26153846153846155
Test F1 for epoch 170 : 0.26153846153846155


theta for epoch 171 : tensor([[ 2.3705,  2.3894,  2.4261,  2.5082,  2.4900,  2.3747,  2.4762,  2.3697,
          2.3697,  1.3557,  1.3584,  1.3575,  1.3608,  1.3549,  1.3628,  1.3563,
          1.3540,  1.3160,  1.3118,  1.2704,  1.2711,  1.3128,  1.3094,  1.3088,
          1.3112,  1.3080,  1.3080,  1.2929,  1.3367,  1.3305,  1.3335,  1.3369,
          1.3320,  1.3347,  1.2871,  1.3308,  1.7441,  1.7552,  1.7478,  1.7445,
          1.7522,  1.6929,  1.7456,  1.7320,  1.7441,  1.6218,  1.6041,  1.6000,
          1.5939,  1.6174,  1.5989,  1.6329,  1.5913,  1.5920],
        [ 1.3160,  1.3133,  1.2078,  1.2662,  1.3379,  1.3351,  1.3186,  1.3342,
          1.3342,  2.3571,  2.2744,  2.2164,  2.3729,  2.2572,  2.8923,  2.3261,
          2.2699,  2.8651,  1.3026,  1.3233,  1.2738,  1.2674,  1.3493,  1.3490,
          1.3140,  1.3481,  1.3481,  1.3459,  1.2168,  1.3709,  1.3739,  1.2706,
          1.3725,  1.3754,  1.3423,  1.3712,  1.7725,  1.7864,  1.7376,  1.7486,
          1.7815,  1.7842,  1.7352,  1.5223,  1.7736,  1.5721,  1.6360,  1.6314,
          1.6248,  1.5176,  1.6303,  1.5407,  1.6220,  1.6228],
        [ 1.2977,  1.3005,  1.3040,  1.3023,  1.3004,  1.2983,  1.2980,  1.2975,
          1.2975,  1.3599,  1.3627,  1.3618,  1.3646,  1.3591,  1.3317,  1.3606,
          1.3323,  1.3406,  2.4480,  2.4495,  2.5084,  2.4599,  2.3808,  2.3823,
          2.4424,  2.3726,  2.3726,  1.3273,  1.3200,  1.3349,  1.3380,  1.3275,
          1.3364,  1.3392,  1.3348,  1.3352,  1.7463,  1.7578,  1.7501,  1.7294,
          1.7547,  1.7547,  1.7479,  1.7163,  1.7289,  1.6225,  1.6070,  1.6028,
          1.5966,  1.5920,  1.6017,  1.6192,  1.5939,  1.5946],
        [ 1.3103,  1.3132,  1.3156,  1.3138,  1.3131,  1.3109,  1.3112,  1.3101,
          1.3101,  1.3723,  1.3742,  1.3742,  1.3608,  1.3715,  1.2761,  1.3730,
          1.3701,  1.2720,  1.3288,  1.3135,  1.3305,  1.3298,  1.3262,  1.3254,
          1.3277,  1.3248,  1.3248,  2.5776,  2.5312,  2.2970,  2.4060,  2.5754,
          2.3058,  2.5173,  2.3342,  2.2988,  1.7551,  1.7668,  1.7361,  1.7548,
          1.7637,  1.7634,  1.7343,  1.6803,  1.7545,  1.6352,  1.6161,  1.5059,
          1.5513,  1.6305,  1.6098,  1.6469,  1.5485,  1.6039],
        [ 1.8455,  1.4425,  0.6102,  0.9220,  1.3213,  1.7604,  1.6447,  1.8667,
          1.8667,  1.7369,  1.3234,  1.5275,  0.9148,  1.7603,  0.1337,  1.6580,
          1.8635,  0.9036,  1.3424,  0.9504,  0.7227,  1.1673,  1.7005,  1.7690,
          1.5128,  1.8740,  1.8740,  0.8215,  0.8779,  1.8462,  1.6358,  0.8583,
          1.7869,  1.2561,  1.8953,  1.8104,  0.0200, -0.2445, -0.2791, -0.0192,
          0.2625,  0.3710, -0.1174, 11.0511,  6.2629,  0.1912,  0.5650,  0.6028,
          0.7051,  0.3593,  0.7030, -0.1028,  0.7312,  0.8007],
        [ 1.3328,  1.3712,  1.4177,  1.4048,  1.3797,  1.3417,  1.3113,  1.3306,
          1.3306,  1.2917,  1.4193,  1.3170,  1.4504,  1.3706,  1.4760,  1.3009,
          1.3573,  1.3581,  1.3888,  1.4006,  1.4248,  1.4017,  1.3561,  1.3484,
          1.2804,  1.3373,  1.3373,  1.3938,  1.4339,  1.3522,  1.1686,  1.3489,
          1.2414,  1.4082,  1.2308,  1.3564,  0.3405,  0.2658,  0.3877,  0.3477,
          0.1485,  0.1026,  0.3644,  0.1619, -0.0446,  2.9128,  2.1315,  2.8700,
          2.3956,  1.7541,  1.3819,  2.6333,  2.6533,  1.3466]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 171 : 176.05565226222163
Test loss for epoch 171 : 175.88183097368918
Test Precision for epoch 171 : 0.26153846153846155
Test Recall for epoch 171 : 0.26153846153846155
Test F1 for epoch 171 : 0.26153846153846155


theta for epoch 172 : tensor([[ 2.3737,  2.3927,  2.4293,  2.5116,  2.4934,  2.3778,  2.4797,  2.3729,
          2.3729,  1.3554,  1.3582,  1.3573,  1.3605,  1.3547,  1.3626,  1.3561,
          1.3538,  1.3158,  1.3117,  1.2703,  1.2710,  1.3127,  1.3093,  1.3087,
          1.3111,  1.3079,  1.3079,  1.2924,  1.3362,  1.3301,  1.3331,  1.3364,
          1.3316,  1.3342,  1.2867,  1.3304,  1.7443,  1.7555,  1.7480,  1.7447,
          1.7525,  1.6931,  1.7458,  1.7322,  1.7443,  1.6207,  1.6031,  1.5989,
          1.5928,  1.6163,  1.5979,  1.6318,  1.5902,  1.5910],
        [ 1.3159,  1.3135,  1.2086,  1.2660,  1.3373,  1.3345,  1.3186,  1.3336,
          1.3336,  2.3618,  2.2787,  2.2197,  2.3767,  2.2607,  2.8928,  2.3299,
          2.2752,  2.8656,  1.3029,  1.3231,  1.2737,  1.2679,  1.3491,  1.3487,
          1.3139,  1.3478,  1.3478,  1.3454,  1.2172,  1.3702,  1.3732,  1.2706,
          1.3718,  1.3747,  1.3417,  1.3705,  1.7725,  1.7863,  1.7377,  1.7492,
          1.7815,  1.7842,  1.7353,  1.5254,  1.7736,  1.5716,  1.6346,  1.6301,
          1.6235,  1.5174,  1.6290,  1.5404,  1.6206,  1.6215],
        [ 1.2974,  1.3002,  1.3037,  1.3020,  1.3001,  1.2980,  1.2977,  1.2972,
          1.2972,  1.3597,  1.3626,  1.3616,  1.3644,  1.3589,  1.3316,  1.3604,
          1.3318,  1.3407,  2.4509,  2.4532,  2.5117,  2.4628,  2.3842,  2.3856,
          2.4457,  2.3759,  2.3759,  1.3266,  1.3198,  1.3345,  1.3375,  1.3269,
          1.3360,  1.3388,  1.3344,  1.3348,  1.7466,  1.7580,  1.7504,  1.7293,
          1.7549,  1.7549,  1.7481,  1.7170,  1.7288,  1.6216,  1.6060,  1.6017,
          1.5955,  1.5913,  1.6007,  1.6181,  1.5928,  1.5936],
        [ 1.3099,  1.3128,  1.3153,  1.3135,  1.3127,  1.3106,  1.3108,  1.3097,
          1.3097,  1.3720,  1.3739,  1.3739,  1.3605,  1.3712,  1.2758,  1.3727,
          1.3699,  1.2718,  1.3287,  1.3133,  1.3304,  1.3297,  1.3261,  1.3252,
          1.3276,  1.3247,  1.3247,  2.5813,  2.5347,  2.3001,  2.4092,  2.5790,
          2.3088,  2.5207,  2.3375,  2.3018,  1.7553,  1.7670,  1.7363,  1.7551,
          1.7639,  1.7637,  1.7344,  1.6806,  1.7547,  1.6342,  1.6151,  1.5050,
          1.5502,  1.6295,  1.6088,  1.6458,  1.5475,  1.6028],
        [ 1.8447,  1.4413,  0.6087,  0.9210,  1.3205,  1.7599,  1.6438,  1.8663,
          1.8663,  1.7358,  1.3221,  1.5261,  0.9133,  1.7589,  0.1316,  1.6566,
          1.8632,  0.9009,  1.3411,  0.9496,  0.7214,  1.1658,  1.6999,  1.7683,
          1.5122,  1.8735,  1.8735,  0.8204,  0.8760,  1.8455,  1.6351,  0.8569,
          1.7861,  1.2549,  1.8946,  1.8096,  0.0195, -0.2447, -0.2793, -0.0195,
          0.2616,  0.3699, -0.1177, 11.1037,  6.2598,  0.1894,  0.5633,  0.6011,
          0.7034,  0.3572,  0.7013, -0.1045,  0.7296,  0.7990],
        [ 1.3349,  1.3733,  1.4197,  1.4068,  1.3817,  1.3437,  1.3134,  1.3327,
          1.3327,  1.2945,  1.4220,  1.3199,  1.4531,  1.3734,  1.4787,  1.3038,
          1.3600,  1.3609,  1.3916,  1.4029,  1.4275,  1.4045,  1.3588,  1.3512,
          1.2829,  1.3401,  1.3401,  1.3958,  1.4359,  1.3543,  1.1705,  1.3510,
          1.2436,  1.4103,  1.2330,  1.3585,  0.3432,  0.2684,  0.3902,  0.3503,
          0.1511,  0.1052,  0.3671,  0.1643, -0.0423,  2.9147,  2.1312,  2.8729,
          2.3958,  1.7529,  1.3802,  2.6333,  2.6562,  1.3449]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 172 : 176.04613203878466
Test loss for epoch 172 : 175.8783108757824
Test Precision for epoch 172 : 0.26153846153846155
Test Recall for epoch 172 : 0.26153846153846155
Test F1 for epoch 172 : 0.26153846153846155


theta for epoch 173 : tensor([[ 2.3768,  2.3958,  2.4324,  2.5150,  2.4968,  2.3809,  2.4831,  2.3760,
          2.3760,  1.3551,  1.3578,  1.3569,  1.3602,  1.3543,  1.3622,  1.3557,
          1.3534,  1.3154,  1.3111,  1.2697,  1.2704,  1.3121,  1.3087,  1.3082,
          1.3105,  1.3073,  1.3073,  1.2920,  1.3358,  1.3297,  1.3326,  1.3360,
          1.3311,  1.3338,  1.2863,  1.3300,  1.7439,  1.7551,  1.7476,  1.7443,
          1.7521,  1.6927,  1.7454,  1.7318,  1.7439,  1.6215,  1.6038,  1.5997,
          1.5936,  1.6171,  1.5987,  1.6326,  1.5910,  1.5917],
        [ 1.3156,  1.3136,  1.2091,  1.2657,  1.3366,  1.3337,  1.3184,  1.3329,
          1.3329,  2.3664,  2.2828,  2.2230,  2.3804,  2.2640,  2.8932,  2.3336,
          2.2805,  2.8660,  1.3026,  1.3224,  1.2731,  1.2679,  1.3483,  1.3479,
          1.3134,  1.3470,  1.3470,  1.3448,  1.2177,  1.3695,  1.3725,  1.2705,
          1.3711,  1.3740,  1.3411,  1.3698,  1.7720,  1.7857,  1.7371,  1.7493,
          1.7810,  1.7836,  1.7347,  1.5280,  1.7729,  1.5732,  1.6353,  1.6307,
          1.6241,  1.5192,  1.6297,  1.5421,  1.6213,  1.6221],
        [ 1.2969,  1.2998,  1.3033,  1.3016,  1.2997,  1.2976,  1.2973,  1.2968,
          1.2968,  1.3594,  1.3623,  1.3613,  1.3642,  1.3587,  1.3312,  1.3601,
          1.3312,  1.3407,  2.4535,  2.4566,  2.5147,  2.4653,  2.3872,  2.3885,
          2.4487,  2.3789,  2.3789,  1.3260,  1.3197,  1.3341,  1.3372,  1.3263,
          1.3356,  1.3384,  1.3340,  1.3345,  1.7462,  1.7576,  1.7500,  1.7286,
          1.7546,  1.7546,  1.7477,  1.7171,  1.7281,  1.6224,  1.6068,  1.6025,
          1.5963,  1.5924,  1.6015,  1.6189,  1.5936,  1.5944],
        [ 1.3094,  1.3124,  1.3148,  1.3131,  1.3123,  1.3101,  1.3104,  1.3093,
          1.3093,  1.3716,  1.3736,  1.3736,  1.3600,  1.3709,  1.2754,  1.3723,
          1.3695,  1.2714,  1.3281,  1.3127,  1.3298,  1.3291,  1.3256,  1.3247,
          1.3270,  1.3241,  1.3241,  2.5849,  2.5381,  2.3030,  2.4123,  2.5826,
          2.3117,  2.5240,  2.3407,  2.3047,  1.7549,  1.7666,  1.7359,  1.7547,
          1.7635,  1.7633,  1.7339,  1.6803,  1.7543,  1.6348,  1.6158,  1.5058,
          1.5510,  1.6302,  1.6096,  1.6465,  1.5482,  1.6036],
        [ 1.8468,  1.4438,  0.6118,  0.9241,  1.3236,  1.7625,  1.6461,  1.8688,
          1.8688,  1.7382,  1.3253,  1.5287,  0.9168,  1.7611,  0.1351,  1.6589,
          1.8662,  0.9037,  1.3440,  0.9534,  0.7253,  1.1687,  1.7028,  1.7711,
          1.5153,  1.8763,  1.8763,  0.8243,  0.8791,  1.8484,  1.6386,  0.8606,
          1.7891,  1.2584,  1.8975,  1.8126,  0.0149, -0.2488, -0.2835, -0.0239,
          0.2563,  0.3644, -0.1220, 11.1519,  6.2510,  0.1938,  0.5676,  0.6054,
          0.7076,  0.3613,  0.7055, -0.1001,  0.7339,  0.8032],
        [ 1.3324,  1.3708,  1.4171,  1.4042,  1.3792,  1.3412,  1.3108,  1.3301,
          1.3301,  1.2914,  1.4190,  1.3168,  1.4500,  1.3704,  1.4756,  1.3007,
          1.3568,  1.3579,  1.3883,  1.3993,  1.4242,  1.4012,  1.3555,  1.3479,
          1.2792,  1.3368,  1.3368,  1.3932,  1.4334,  1.3517,  1.1673,  1.3484,
          1.2409,  1.4077,  1.2302,  1.3559,  0.3399,  0.2651,  0.3869,  0.3470,
          0.1476,  0.1017,  0.3638,  0.1605, -0.0461,  2.9233,  2.1375,  2.8826,
          2.4026,  1.7583,  1.3850,  2.6399,  2.6660,  1.3498]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 173 : 176.03620221761798
Test loss for epoch 173 : 175.86535476883864
Test Precision for epoch 173 : 0.26153846153846155
Test Recall for epoch 173 : 0.26153846153846155
Test F1 for epoch 173 : 0.26153846153846155


theta for epoch 174 : tensor([[ 2.3800,  2.3989,  2.4355,  2.5185,  2.5003,  2.3841,  2.4866,  2.3792,
          2.3792,  1.3549,  1.3577,  1.3568,  1.3600,  1.3542,  1.3621,  1.3556,
          1.3533,  1.3153,  1.3111,  1.2697,  1.2704,  1.3121,  1.3087,  1.3082,
          1.3105,  1.3073,  1.3073,  1.2917,  1.3355,  1.3294,  1.3323,  1.3357,
          1.3308,  1.3335,  1.2860,  1.3297,  1.7441,  1.7553,  1.7479,  1.7446,
          1.7523,  1.6929,  1.7456,  1.7320,  1.7441,  1.6200,  1.6024,  1.5982,
          1.5922,  1.6156,  1.5972,  1.6311,  1.5895,  1.5903],
        [ 1.3155,  1.3138,  1.2099,  1.2656,  1.3360,  1.3332,  1.3183,  1.3323,
          1.3323,  2.3708,  2.2869,  2.2261,  2.3841,  2.2673,  2.8935,  2.3372,
          2.2857,  2.8664,  1.3031,  1.3224,  1.2732,  1.2686,  1.3482,  1.3478,
          1.3136,  1.3469,  1.3469,  1.3445,  1.2184,  1.3691,  1.3720,  1.2707,
          1.3707,  1.3735,  1.3406,  1.3693,  1.7720,  1.7857,  1.7373,  1.7501,
          1.7810,  1.7836,  1.7348,  1.5311,  1.7729,  1.5723,  1.6336,  1.6291,
          1.6225,  1.5186,  1.6280,  1.5414,  1.6196,  1.6205],
        [ 1.2966,  1.2995,  1.3030,  1.3012,  1.2993,  1.2973,  1.2970,  1.2964,
          1.2964,  1.3594,  1.3622,  1.3613,  1.3642,  1.3586,  1.3312,  1.3601,
          1.3308,  1.3410,  2.4565,  2.4604,  2.5181,  2.4682,  2.3905,  2.3917,
          2.4521,  2.3823,  2.3823,  1.3255,  1.3196,  1.3339,  1.3369,  1.3258,
          1.3354,  1.3381,  1.3338,  1.3342,  1.7465,  1.7579,  1.7503,  1.7285,
          1.7548,  1.7548,  1.7480,  1.7178,  1.7280,  1.6211,  1.6053,  1.6011,
          1.5949,  1.5913,  1.6001,  1.6175,  1.5922,  1.5930],
        [ 1.3091,  1.3121,  1.3146,  1.3128,  1.3119,  1.3098,  1.3100,  1.3089,
          1.3089,  1.3716,  1.3736,  1.3735,  1.3599,  1.3708,  1.2754,  1.3723,
          1.3694,  1.2714,  1.3281,  1.3127,  1.3299,  1.3292,  1.3256,  1.3247,
          1.3271,  1.3242,  1.3242,  2.5884,  2.5415,  2.3059,  2.4153,  2.5862,
          2.3146,  2.5272,  2.3438,  2.3076,  1.7552,  1.7669,  1.7361,  1.7549,
          1.7638,  1.7636,  1.7342,  1.6807,  1.7545,  1.6335,  1.6145,  1.5045,
          1.5496,  1.6288,  1.6083,  1.6451,  1.5468,  1.6022],
        [ 1.8454,  1.4418,  0.6093,  0.9223,  1.3221,  1.7614,  1.6445,  1.8678,
          1.8678,  1.7363,  1.3231,  1.5266,  0.9144,  1.7590,  0.1320,  1.6568,
          1.8652,  0.9000,  1.3418,  0.9518,  0.7230,  1.1662,  1.7014,  1.7698,
          1.5140,  1.8751,  1.8751,  0.8223,  0.8763,  1.8470,  1.6372,  0.8582,
          1.7876,  1.2564,  1.8962,  1.8112,  0.0153, -0.2482, -0.2829, -0.0233,
          0.2562,  0.3642, -0.1215, 11.2053,  6.2482,  0.1909,  0.5648,  0.6025,
          0.7047,  0.3581,  0.7026, -0.1031,  0.7311,  0.8003],
        [ 1.3353,  1.3736,  1.4199,  1.4070,  1.3820,  1.3440,  1.3137,  1.3330,
          1.3330,  1.2953,  1.4228,  1.3207,  1.4538,  1.3743,  1.4794,  1.3047,
          1.3606,  1.3619,  1.3922,  1.4028,  1.4279,  1.4051,  1.3593,  1.3517,
          1.2827,  1.3406,  1.3406,  1.3961,  1.4363,  1.3548,  1.1702,  1.3514,
          1.2440,  1.4107,  1.2334,  1.3590,  0.3436,  0.2688,  0.3904,  0.3507,
          0.1513,  0.1054,  0.3675,  0.1640, -0.0427,  2.9240,  2.1359,  2.8843,
          2.4015,  1.7558,  1.3821,  2.6387,  2.6677,  1.3468]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 174 : 176.02568960505627
Test loss for epoch 174 : 175.86254913445586
Test Precision for epoch 174 : 0.26153846153846155
Test Recall for epoch 174 : 0.26153846153846155
Test F1 for epoch 174 : 0.26153846153846155


theta for epoch 175 : tensor([[ 2.3829e+00,  2.4018e+00,  2.4384e+00,  2.5217e+00,  2.5035e+00,
          2.3870e+00,  2.4898e+00,  2.3821e+00,  2.3821e+00,  1.3547e+00,
          1.3574e+00,  1.3565e+00,  1.3598e+00,  1.3539e+00,  1.3618e+00,
          1.3554e+00,  1.3530e+00,  1.3150e+00,  1.3106e+00,  1.2691e+00,
          1.2698e+00,  1.3116e+00,  1.3082e+00,  1.3076e+00,  1.3100e+00,
          1.3068e+00,  1.3068e+00,  1.2915e+00,  1.3353e+00,  1.3292e+00,
          1.3321e+00,  1.3355e+00,  1.3306e+00,  1.3333e+00,  1.2858e+00,
          1.3295e+00,  1.7437e+00,  1.7548e+00,  1.7474e+00,  1.7441e+00,
          1.7519e+00,  1.6924e+00,  1.7452e+00,  1.7315e+00,  1.7436e+00,
          1.6208e+00,  1.6032e+00,  1.5990e+00,  1.5930e+00,  1.6164e+00,
          1.5980e+00,  1.6319e+00,  1.5903e+00,  1.5911e+00],
        [ 1.3154e+00,  1.3139e+00,  1.2107e+00,  1.2654e+00,  1.3354e+00,
          1.3326e+00,  1.3182e+00,  1.3317e+00,  1.3317e+00,  2.3751e+00,
          2.2908e+00,  2.2291e+00,  2.3875e+00,  2.2704e+00,  2.8937e+00,
          2.3406e+00,  2.2907e+00,  2.8666e+00,  1.3028e+00,  1.3217e+00,
          1.2727e+00,  1.2686e+00,  1.3474e+00,  1.3470e+00,  1.3131e+00,
          1.3461e+00,  1.3461e+00,  1.3441e+00,  1.2192e+00,  1.3686e+00,
          1.3716e+00,  1.2708e+00,  1.3702e+00,  1.3730e+00,  1.3402e+00,
          1.3689e+00,  1.7714e+00,  1.7851e+00,  1.7366e+00,  1.7501e+00,
          1.7804e+00,  1.7830e+00,  1.7342e+00,  1.5336e+00,  1.7722e+00,
          1.5738e+00,  1.6343e+00,  1.6297e+00,  1.6232e+00,  1.5204e+00,
          1.6287e+00,  1.5430e+00,  1.6203e+00,  1.6212e+00],
        [ 1.2963e+00,  1.2992e+00,  1.3026e+00,  1.3009e+00,  1.2990e+00,
          1.2969e+00,  1.2967e+00,  1.2961e+00,  1.2961e+00,  1.3591e+00,
          1.3620e+00,  1.3610e+00,  1.3639e+00,  1.3584e+00,  1.3309e+00,
          1.3598e+00,  1.3303e+00,  1.3410e+00,  2.4588e+00,  2.4635e+00,
          2.5209e+00,  2.4705e+00,  2.3933e+00,  2.3944e+00,  2.4549e+00,
          2.3851e+00,  2.3851e+00,  1.3250e+00,  1.3196e+00,  1.3337e+00,
          1.3367e+00,  1.3253e+00,  1.3352e+00,  1.3379e+00,  1.3336e+00,
          1.3340e+00,  1.7460e+00,  1.7574e+00,  1.7498e+00,  1.7277e+00,
          1.7544e+00,  1.7544e+00,  1.7476e+00,  1.7179e+00,  1.7272e+00,
          1.6219e+00,  1.6061e+00,  1.6019e+00,  1.5957e+00,  1.5924e+00,
          1.6009e+00,  1.6182e+00,  1.5930e+00,  1.5938e+00],
        [ 1.3088e+00,  1.3118e+00,  1.3143e+00,  1.3126e+00,  1.3117e+00,
          1.3095e+00,  1.3098e+00,  1.3086e+00,  1.3086e+00,  1.3714e+00,
          1.3734e+00,  1.3733e+00,  1.3597e+00,  1.3706e+00,  1.2752e+00,
          1.3721e+00,  1.3692e+00,  1.2713e+00,  1.3277e+00,  1.3122e+00,
          1.3294e+00,  1.3287e+00,  1.3251e+00,  1.3243e+00,  1.3266e+00,
          1.3237e+00,  1.3237e+00,  2.5916e+00,  2.5446e+00,  2.3085e+00,
          2.4181e+00,  2.5894e+00,  2.3172e+00,  2.5301e+00,  2.3466e+00,
          2.3103e+00,  1.7547e+00,  1.7664e+00,  1.7356e+00,  1.7545e+00,
          1.7634e+00,  1.7631e+00,  1.7336e+00,  1.6803e+00,  1.7541e+00,
          1.6342e+00,  1.6153e+00,  1.5054e+00,  1.5504e+00,  1.6296e+00,
          1.6091e+00,  1.6459e+00,  1.5476e+00,  1.6030e+00],
        [ 1.8477e+00,  1.4447e+00,  6.1278e-01,  9.2574e-01,  1.3255e+00,
          1.7642e+00,  1.6471e+00,  1.8705e+00,  1.8705e+00,  1.7390e+00,
          1.3267e+00,  1.5295e+00,  9.1822e-01,  1.7615e+00,  1.3581e-01,
          1.6594e+00,  1.8685e+00,  9.0323e-01,  1.3450e+00,  9.5593e-01,
          7.2725e-01,  1.1695e+00,  1.7046e+00,  1.7728e+00,  1.5173e+00,
          1.8780e+00,  1.8780e+00,  8.2663e-01,  8.7990e-01,  1.8503e+00,
          1.6410e+00,  8.6246e-01,  1.7910e+00,  1.2603e+00,  1.8994e+00,
          1.8145e+00,  1.0424e-02, -2.5258e-01, -2.8742e-01, -2.8016e-02,
          2.5065e-01,  3.5839e-01, -1.2611e-01,  1.1253e+01,  6.2384e+00,
          1.9576e-01,  5.6943e-01,  6.0717e-01,  7.0945e-01,  3.6258e-01,
          7.0733e-01, -9.8211e-02,  7.3585e-01,  8.0497e-01],
        [ 1.3322e+00,  1.3707e+00,  1.4169e+00,  1.4040e+00,  1.3790e+00,
          1.3409e+00,  1.3107e+00,  1.3299e+00,  1.3299e+00,  1.2915e+00,
          1.4191e+00,  1.3170e+00,  1.4501e+00,  1.3707e+00,  1.4756e+00,
          1.3009e+00,  1.3568e+00,  1.3582e+00,  1.3882e+00,  1.3984e+00,
          1.4240e+00,  1.4011e+00,  1.3553e+00,  1.3477e+00,  1.2783e+00,
          1.3366e+00,  1.3366e+00,  1.3930e+00,  1.4333e+00,  1.3516e+00,
          1.1665e+00,  1.3482e+00,  1.2408e+00,  1.4077e+00,  1.2301e+00,
          1.3558e+00,  3.3974e-01,  2.6479e-01,  3.8643e-01,  3.4675e-01,
          1.4716e-01,  1.0127e-01,  3.6363e-01,  1.5959e-01, -4.7195e-02,
          2.9333e+00,  2.1429e+00,  2.8947e+00,  2.4091e+00,  1.7619e+00,
          1.3876e+00,  2.6460e+00,  2.6781e+00,  1.3524e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 175 : 176.01415723025508
Test loss for epoch 175 : 175.8471755975305
Test Precision for epoch 175 : 0.26153846153846155
Test Recall for epoch 175 : 0.26153846153846155
Test F1 for epoch 175 : 0.26153846153846155


theta for epoch 176 : tensor([[ 2.3859e+00,  2.4048e+00,  2.4414e+00,  2.5250e+00,  2.5067e+00,
          2.3899e+00,  2.4931e+00,  2.3850e+00,  2.3850e+00,  1.3546e+00,
          1.3574e+00,  1.3565e+00,  1.3597e+00,  1.3539e+00,  1.3618e+00,
          1.3553e+00,  1.3529e+00,  1.3150e+00,  1.3107e+00,  1.2692e+00,
          1.2699e+00,  1.3117e+00,  1.3082e+00,  1.3077e+00,  1.3101e+00,
          1.3069e+00,  1.3069e+00,  1.2913e+00,  1.3352e+00,  1.3290e+00,
          1.3320e+00,  1.3354e+00,  1.3305e+00,  1.3332e+00,  1.2856e+00,
          1.3293e+00,  1.7440e+00,  1.7551e+00,  1.7477e+00,  1.7444e+00,
          1.7521e+00,  1.6927e+00,  1.7455e+00,  1.7318e+00,  1.7439e+00,
          1.6192e+00,  1.6016e+00,  1.5974e+00,  1.5914e+00,  1.6149e+00,
          1.5964e+00,  1.6303e+00,  1.5888e+00,  1.5895e+00],
        [ 1.3155e+00,  1.3142e+00,  1.2116e+00,  1.2654e+00,  1.3350e+00,
          1.3321e+00,  1.3183e+00,  1.3313e+00,  1.3313e+00,  2.3794e+00,
          2.2949e+00,  2.2322e+00,  2.3912e+00,  2.2736e+00,  2.8940e+00,
          2.3441e+00,  2.2959e+00,  2.8669e+00,  1.3031e+00,  1.3217e+00,
          1.2727e+00,  1.2693e+00,  1.3472e+00,  1.3469e+00,  1.3132e+00,
          1.3460e+00,  1.3460e+00,  1.3439e+00,  1.2200e+00,  1.3682e+00,
          1.3712e+00,  1.2710e+00,  1.3698e+00,  1.3726e+00,  1.3399e+00,
          1.3684e+00,  1.7715e+00,  1.7851e+00,  1.7368e+00,  1.7508e+00,
          1.7805e+00,  1.7830e+00,  1.7343e+00,  1.5367e+00,  1.7723e+00,
          1.5727e+00,  1.6324e+00,  1.6278e+00,  1.6213e+00,  1.5196e+00,
          1.6268e+00,  1.5421e+00,  1.6184e+00,  1.6193e+00],
        [ 1.2961e+00,  1.2990e+00,  1.3024e+00,  1.3007e+00,  1.2988e+00,
          1.2967e+00,  1.2965e+00,  1.2959e+00,  1.2959e+00,  1.3590e+00,
          1.3619e+00,  1.3609e+00,  1.3638e+00,  1.3583e+00,  1.3307e+00,
          1.3597e+00,  1.3298e+00,  1.3412e+00,  2.4617e+00,  2.4672e+00,
          2.5243e+00,  2.4733e+00,  2.3966e+00,  2.3975e+00,  2.4582e+00,
          2.3883e+00,  2.3883e+00,  1.3246e+00,  1.3196e+00,  1.3335e+00,
          1.3365e+00,  1.3249e+00,  1.3350e+00,  1.3377e+00,  1.3333e+00,
          1.3338e+00,  1.7463e+00,  1.7577e+00,  1.7501e+00,  1.7277e+00,
          1.7546e+00,  1.7546e+00,  1.7478e+00,  1.7186e+00,  1.7271e+00,
          1.6203e+00,  1.6044e+00,  1.6002e+00,  1.5940e+00,  1.5911e+00,
          1.5992e+00,  1.6166e+00,  1.5913e+00,  1.5921e+00],
        [ 1.3087e+00,  1.3116e+00,  1.3142e+00,  1.3125e+00,  1.3115e+00,
          1.3094e+00,  1.3096e+00,  1.3085e+00,  1.3085e+00,  1.3714e+00,
          1.3734e+00,  1.3733e+00,  1.3596e+00,  1.3706e+00,  1.2752e+00,
          1.3721e+00,  1.3692e+00,  1.2714e+00,  1.3278e+00,  1.3122e+00,
          1.3295e+00,  1.3288e+00,  1.3253e+00,  1.3244e+00,  1.3267e+00,
          1.3238e+00,  1.3238e+00,  2.5949e+00,  2.5478e+00,  2.3112e+00,
          2.4209e+00,  2.5927e+00,  2.3199e+00,  2.5331e+00,  2.3495e+00,
          2.3129e+00,  1.7551e+00,  1.7668e+00,  1.7359e+00,  1.7548e+00,
          1.7637e+00,  1.7635e+00,  1.7339e+00,  1.6808e+00,  1.7544e+00,
          1.6327e+00,  1.6138e+00,  1.5040e+00,  1.5490e+00,  1.6281e+00,
          1.6077e+00,  1.6444e+00,  1.5461e+00,  1.6015e+00],
        [ 1.8463e+00,  1.4427e+00,  6.1021e-01,  9.2379e-01,  1.3239e+00,
          1.7631e+00,  1.6455e+00,  1.8695e+00,  1.8695e+00,  1.7369e+00,
          1.3243e+00,  1.5273e+00,  9.1567e-01,  1.7592e+00,  1.3255e-01,
          1.6571e+00,  1.8673e+00,  8.9938e-01,  1.3427e+00,  9.5414e-01,
          7.2487e-01,  1.1669e+00,  1.7030e+00,  1.7712e+00,  1.5158e+00,
          1.8766e+00,  1.8766e+00,  8.2447e-01,  8.7694e-01,  1.8488e+00,
          1.6395e+00,  8.5989e-01,  1.7894e+00,  1.2582e+00,  1.8979e+00,
          1.8130e+00,  1.1039e-02, -2.5176e-01, -2.8671e-01, -2.7229e-02,
          2.5078e-01,  3.5835e-01, -1.2539e-01,  1.1306e+01,  6.2351e+00,
          1.9265e-01,  5.6642e-01,  6.0408e-01,  7.0633e-01,  3.5917e-01,
          7.0421e-01, -1.0133e-01,  7.3284e-01,  8.0187e-01],
        [ 1.3352e+00,  1.3736e+00,  1.4197e+00,  1.4069e+00,  1.3819e+00,
          1.3439e+00,  1.3137e+00,  1.3329e+00,  1.3329e+00,  1.2954e+00,
          1.4229e+00,  1.3209e+00,  1.4539e+00,  1.3746e+00,  1.4794e+00,
          1.3049e+00,  1.3606e+00,  1.3622e+00,  1.3921e+00,  1.4019e+00,
          1.4278e+00,  1.4050e+00,  1.3592e+00,  1.3516e+00,  1.2819e+00,
          1.3405e+00,  1.3405e+00,  1.3961e+00,  1.4364e+00,  1.3548e+00,
          1.1695e+00,  1.3513e+00,  1.2440e+00,  1.4107e+00,  1.2333e+00,
          1.3590e+00,  3.4356e-01,  2.6861e-01,  3.9010e-01,  3.5054e-01,
          1.5095e-01,  1.0506e-01,  3.6743e-01,  1.6317e-01, -4.3616e-02,
          2.9339e+00,  2.1412e+00,  2.8963e+00,  2.4079e+00,  1.7593e+00,
          1.3846e+00,  2.6446e+00,  2.6798e+00,  1.3493e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 176 : 176.00213145124815
Test loss for epoch 176 : 175.84313982455205
Test Precision for epoch 176 : 0.26153846153846155
Test Recall for epoch 176 : 0.26153846153846155
Test F1 for epoch 176 : 0.26153846153846155


theta for epoch 177 : tensor([[ 2.3886e+00,  2.4076e+00,  2.4441e+00,  2.5280e+00,  2.5098e+00,
          2.3926e+00,  2.4961e+00,  2.3877e+00,  2.3877e+00,  1.3544e+00,
          1.3571e+00,  1.3562e+00,  1.3595e+00,  1.3536e+00,  1.3615e+00,
          1.3551e+00,  1.3526e+00,  1.3147e+00,  1.3102e+00,  1.2687e+00,
          1.2695e+00,  1.3112e+00,  1.3078e+00,  1.3072e+00,  1.3096e+00,
          1.3064e+00,  1.3064e+00,  1.2912e+00,  1.3350e+00,  1.3289e+00,
          1.3318e+00,  1.3352e+00,  1.3303e+00,  1.3330e+00,  1.2855e+00,
          1.3292e+00,  1.7436e+00,  1.7547e+00,  1.7474e+00,  1.7440e+00,
          1.7518e+00,  1.6923e+00,  1.7451e+00,  1.7314e+00,  1.7435e+00,
          1.6200e+00,  1.6024e+00,  1.5983e+00,  1.5922e+00,  1.6157e+00,
          1.5973e+00,  1.6311e+00,  1.5896e+00,  1.5904e+00],
        [ 1.3153e+00,  1.3143e+00,  1.2123e+00,  1.2653e+00,  1.3344e+00,
          1.3315e+00,  1.3182e+00,  1.3306e+00,  1.3306e+00,  2.3837e+00,
          2.2990e+00,  2.2353e+00,  2.3948e+00,  2.2768e+00,  2.8944e+00,
          2.3476e+00,  2.3010e+00,  2.8673e+00,  1.3027e+00,  1.3208e+00,
          1.2719e+00,  1.2691e+00,  1.3463e+00,  1.3459e+00,  1.3125e+00,
          1.3450e+00,  1.3450e+00,  1.3434e+00,  1.2206e+00,  1.3676e+00,
          1.3706e+00,  1.2711e+00,  1.3692e+00,  1.3721e+00,  1.3393e+00,
          1.3679e+00,  1.7709e+00,  1.7844e+00,  1.7362e+00,  1.7508e+00,
          1.7799e+00,  1.7824e+00,  1.7337e+00,  1.5392e+00,  1.7716e+00,
          1.5741e+00,  1.6330e+00,  1.6284e+00,  1.6219e+00,  1.5212e+00,
          1.6274e+00,  1.5435e+00,  1.6190e+00,  1.6199e+00],
        [ 1.2958e+00,  1.2987e+00,  1.3021e+00,  1.3004e+00,  1.2985e+00,
          1.2964e+00,  1.2963e+00,  1.2956e+00,  1.2956e+00,  1.3586e+00,
          1.3615e+00,  1.3605e+00,  1.3634e+00,  1.3579e+00,  1.3302e+00,
          1.3593e+00,  1.3291e+00,  1.3410e+00,  2.4642e+00,  2.4705e+00,
          2.5272e+00,  2.4757e+00,  2.3994e+00,  2.4003e+00,  2.4611e+00,
          2.3912e+00,  2.3912e+00,  1.3240e+00,  1.3195e+00,  1.3332e+00,
          1.3362e+00,  1.3244e+00,  1.3347e+00,  1.3374e+00,  1.3331e+00,
          1.3335e+00,  1.7459e+00,  1.7572e+00,  1.7497e+00,  1.7269e+00,
          1.7542e+00,  1.7542e+00,  1.7474e+00,  1.7186e+00,  1.7263e+00,
          1.6211e+00,  1.6052e+00,  1.6009e+00,  1.5948e+00,  1.5921e+00,
          1.5999e+00,  1.6173e+00,  1.5920e+00,  1.5929e+00],
        [ 1.3085e+00,  1.3114e+00,  1.3140e+00,  1.3123e+00,  1.3113e+00,
          1.3091e+00,  1.3094e+00,  1.3083e+00,  1.3083e+00,  1.3710e+00,
          1.3731e+00,  1.3730e+00,  1.3593e+00,  1.3703e+00,  1.2749e+00,
          1.3718e+00,  1.3688e+00,  1.2711e+00,  1.3273e+00,  1.3117e+00,
          1.3290e+00,  1.3283e+00,  1.3247e+00,  1.3239e+00,  1.3262e+00,
          1.3233e+00,  1.3233e+00,  2.5981e+00,  2.5508e+00,  2.3138e+00,
          2.4237e+00,  2.5959e+00,  2.3225e+00,  2.5361e+00,  2.3523e+00,
          2.3155e+00,  1.7547e+00,  1.7663e+00,  1.7354e+00,  1.7544e+00,
          1.7633e+00,  1.7631e+00,  1.7334e+00,  1.6804e+00,  1.7539e+00,
          1.6334e+00,  1.6145e+00,  1.5048e+00,  1.5497e+00,  1.6289e+00,
          1.6084e+00,  1.6451e+00,  1.5469e+00,  1.6023e+00],
        [ 1.8485e+00,  1.4455e+00,  6.1354e-01,  9.2711e-01,  1.3272e+00,
          1.7658e+00,  1.6480e+00,  1.8720e+00,  1.8720e+00,  1.7394e+00,
          1.3278e+00,  1.5300e+00,  9.1934e-01,  1.7616e+00,  1.3622e-01,
          1.6596e+00,  1.8704e+00,  9.0241e-01,  1.3458e+00,  9.5814e-01,
          7.2893e-01,  1.1700e+00,  1.7060e+00,  1.7741e+00,  1.5190e+00,
          1.8794e+00,  1.8794e+00,  8.2862e-01,  8.8033e-01,  1.8519e+00,
          1.6431e+00,  8.6393e-01,  1.7926e+00,  1.2619e+00,  1.9010e+00,
          1.8161e+00,  6.3429e-03, -2.5599e-01, -2.9101e-01, -3.1755e-02,
          2.4543e-01,  3.5278e-01, -1.2983e-01,  1.1354e+01,  6.2248e+00,
          1.9733e-01,  5.7092e-01,  6.0859e-01,  7.1087e-01,  3.6353e-01,
          7.0875e-01, -9.6645e-02,  7.3742e-01,  8.0637e-01],
        [ 1.3324e+00,  1.3709e+00,  1.4170e+00,  1.4041e+00,  1.3791e+00,
          1.3411e+00,  1.3108e+00,  1.3300e+00,  1.3300e+00,  1.2919e+00,
          1.4195e+00,  1.3174e+00,  1.4504e+00,  1.3712e+00,  1.4759e+00,
          1.3014e+00,  1.3570e+00,  1.3587e+00,  1.3884e+00,  1.3978e+00,
          1.4241e+00,  1.4014e+00,  1.3555e+00,  1.3479e+00,  1.2777e+00,
          1.3367e+00,  1.3367e+00,  1.3931e+00,  1.4336e+00,  1.3518e+00,
          1.1659e+00,  1.3484e+00,  1.2410e+00,  1.4079e+00,  1.2302e+00,
          1.3560e+00,  3.3998e-01,  2.6492e-01,  3.8639e-01,  3.4692e-01,
          1.4713e-01,  1.0122e-01,  3.6385e-01,  1.5912e-01, -4.7814e-02,
          2.9430e+00,  2.1479e+00,  2.9063e+00,  2.4151e+00,  1.7650e+00,
          1.3898e+00,  2.6516e+00,  2.6899e+00,  1.3545e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 177 : 175.98949298829655
Test loss for epoch 177 : 175.82701230351765
Test Precision for epoch 177 : 0.26153846153846155
Test Recall for epoch 177 : 0.26153846153846155
Test F1 for epoch 177 : 0.26153846153846155


theta for epoch 178 : tensor([[ 2.3915e+00,  2.4105e+00,  2.4470e+00,  2.5312e+00,  2.5130e+00,
          2.3955e+00,  2.4994e+00,  2.3906e+00,  2.3906e+00,  1.3542e+00,
          1.3570e+00,  1.3561e+00,  1.3593e+00,  1.3535e+00,  1.3613e+00,
          1.3549e+00,  1.3525e+00,  1.3146e+00,  1.3102e+00,  1.2688e+00,
          1.2695e+00,  1.3112e+00,  1.3078e+00,  1.3073e+00,  1.3096e+00,
          1.3064e+00,  1.3064e+00,  1.2909e+00,  1.3348e+00,  1.3286e+00,
          1.3316e+00,  1.3350e+00,  1.3301e+00,  1.3328e+00,  1.2852e+00,
          1.3289e+00,  1.7438e+00,  1.7550e+00,  1.7476e+00,  1.7443e+00,
          1.7520e+00,  1.6925e+00,  1.7454e+00,  1.7316e+00,  1.7437e+00,
          1.6188e+00,  1.6012e+00,  1.5971e+00,  1.5910e+00,  1.6145e+00,
          1.5961e+00,  1.6299e+00,  1.5884e+00,  1.5892e+00],
        [ 1.3153e+00,  1.3144e+00,  1.2132e+00,  1.2652e+00,  1.3339e+00,
          1.3310e+00,  1.3181e+00,  1.3301e+00,  1.3301e+00,  2.3880e+00,
          2.3031e+00,  2.2385e+00,  2.3986e+00,  2.2801e+00,  2.8948e+00,
          2.3512e+00,  2.3063e+00,  2.8678e+00,  1.3028e+00,  1.3206e+00,
          1.2718e+00,  1.2696e+00,  1.3460e+00,  1.3456e+00,  1.3125e+00,
          1.3447e+00,  1.3447e+00,  1.3429e+00,  1.2213e+00,  1.3671e+00,
          1.3700e+00,  1.2711e+00,  1.3686e+00,  1.3715e+00,  1.3388e+00,
          1.3673e+00,  1.7710e+00,  1.7844e+00,  1.7362e+00,  1.7514e+00,
          1.7799e+00,  1.7824e+00,  1.7338e+00,  1.5422e+00,  1.7715e+00,
          1.5732e+00,  1.6314e+00,  1.6268e+00,  1.6203e+00,  1.5206e+00,
          1.6258e+00,  1.5429e+00,  1.6174e+00,  1.6183e+00],
        [ 1.2956e+00,  1.2984e+00,  1.3019e+00,  1.3002e+00,  1.2983e+00,
          1.2962e+00,  1.2960e+00,  1.2954e+00,  1.2954e+00,  1.3584e+00,
          1.3612e+00,  1.3603e+00,  1.3632e+00,  1.3576e+00,  1.3299e+00,
          1.3591e+00,  1.3285e+00,  1.3410e+00,  2.4671e+00,  2.4743e+00,
          2.5306e+00,  2.4785e+00,  2.4027e+00,  2.4034e+00,  2.4645e+00,
          2.3945e+00,  2.3945e+00,  1.3234e+00,  1.3194e+00,  1.3329e+00,
          1.3359e+00,  1.3238e+00,  1.3344e+00,  1.3371e+00,  1.3328e+00,
          1.3332e+00,  1.7461e+00,  1.7574e+00,  1.7499e+00,  1.7267e+00,
          1.7544e+00,  1.7544e+00,  1.7476e+00,  1.7192e+00,  1.7262e+00,
          1.6199e+00,  1.6038e+00,  1.5996e+00,  1.5935e+00,  1.5911e+00,
          1.5986e+00,  1.6160e+00,  1.5907e+00,  1.5916e+00],
        [ 1.3082e+00,  1.3111e+00,  1.3138e+00,  1.3121e+00,  1.3110e+00,
          1.3089e+00,  1.3091e+00,  1.3080e+00,  1.3080e+00,  1.3708e+00,
          1.3729e+00,  1.3728e+00,  1.3590e+00,  1.3701e+00,  1.2746e+00,
          1.3715e+00,  1.3686e+00,  1.2709e+00,  1.3272e+00,  1.3115e+00,
          1.3289e+00,  1.3282e+00,  1.3247e+00,  1.3239e+00,  1.3261e+00,
          1.3232e+00,  1.3232e+00,  2.6016e+00,  2.5541e+00,  2.3166e+00,
          2.4266e+00,  2.5993e+00,  2.3253e+00,  2.5392e+00,  2.3554e+00,
          2.3184e+00,  1.7549e+00,  1.7666e+00,  1.7356e+00,  1.7547e+00,
          1.7635e+00,  1.7633e+00,  1.7336e+00,  1.6808e+00,  1.7541e+00,
          1.6322e+00,  1.6133e+00,  1.5037e+00,  1.5485e+00,  1.6277e+00,
          1.6073e+00,  1.6438e+00,  1.5457e+00,  1.6010e+00],
        [ 1.8473e+00,  1.4438e+00,  6.1138e-01,  9.2552e-01,  1.3259e+00,
          1.7649e+00,  1.6467e+00,  1.8713e+00,  1.8713e+00,  1.7376e+00,
          1.3258e+00,  1.5281e+00,  9.1722e-01,  1.7596e+00,  1.3346e-01,
          1.6576e+00,  1.8695e+00,  8.9906e-01,  1.3438e+00,  9.5678e-01,
          7.2703e-01,  1.1678e+00,  1.7048e+00,  1.7729e+00,  1.5179e+00,
          1.8784e+00,  1.8784e+00,  8.2689e-01,  8.7778e-01,  1.8507e+00,
          1.6419e+00,  8.6180e-01,  1.7912e+00,  1.2602e+00,  1.8998e+00,
          1.8148e+00,  6.6332e-03, -2.5549e-01, -2.9062e-01, -3.1307e-02,
          2.4523e-01,  3.5239e-01, -1.2943e-01,  1.1407e+01,  6.2203e+00,
          1.9484e-01,  5.6849e-01,  6.0610e-01,  7.0834e-01,  3.6074e-01,
          7.0623e-01, -9.9135e-02,  7.3501e-01,  8.0387e-01],
        [ 1.3351e+00,  1.3735e+00,  1.4195e+00,  1.4067e+00,  1.3817e+00,
          1.3437e+00,  1.3135e+00,  1.3327e+00,  1.3327e+00,  1.2954e+00,
          1.4228e+00,  1.3209e+00,  1.4538e+00,  1.3747e+00,  1.4793e+00,
          1.3050e+00,  1.3603e+00,  1.3622e+00,  1.3919e+00,  1.4009e+00,
          1.4275e+00,  1.4048e+00,  1.3589e+00,  1.3514e+00,  1.2809e+00,
          1.3402e+00,  1.3402e+00,  1.3958e+00,  1.4362e+00,  1.3546e+00,
          1.1685e+00,  1.3511e+00,  1.2439e+00,  1.4106e+00,  1.2331e+00,
          1.3588e+00,  3.4343e-01,  2.6836e-01,  3.8969e-01,  3.5033e-01,
          1.5053e-01,  1.0463e-01,  3.6727e-01,  1.6234e-01, -4.4616e-02,
          2.9441e+00,  2.1466e+00,  2.9084e+00,  2.4143e+00,  1.7629e+00,
          1.3871e+00,  2.6508e+00,  2.6920e+00,  1.3518e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 178 : 175.9768044227004
Test loss for epoch 178 : 175.82160459055495
Test Precision for epoch 178 : 0.26153846153846155
Test Recall for epoch 178 : 0.26153846153846155
Test F1 for epoch 178 : 0.26153846153846155


theta for epoch 179 : tensor([[ 2.3943e+00,  2.4133e+00,  2.4498e+00,  2.5343e+00,  2.5161e+00,
          2.3983e+00,  2.5025e+00,  2.3934e+00,  2.3934e+00,  1.3539e+00,
          1.3567e+00,  1.3558e+00,  1.3590e+00,  1.3532e+00,  1.3610e+00,
          1.3546e+00,  1.3522e+00,  1.3143e+00,  1.3098e+00,  1.2683e+00,
          1.2690e+00,  1.3108e+00,  1.3074e+00,  1.3068e+00,  1.3092e+00,
          1.3060e+00,  1.3060e+00,  1.2906e+00,  1.3345e+00,  1.3283e+00,
          1.3313e+00,  1.3346e+00,  1.3298e+00,  1.3325e+00,  1.2849e+00,
          1.3286e+00,  1.7435e+00,  1.7546e+00,  1.7473e+00,  1.7439e+00,
          1.7517e+00,  1.6922e+00,  1.7450e+00,  1.7312e+00,  1.7434e+00,
          1.6196e+00,  1.6019e+00,  1.5978e+00,  1.5918e+00,  1.6152e+00,
          1.5968e+00,  1.6306e+00,  1.5891e+00,  1.5899e+00],
        [ 1.3151e+00,  1.3145e+00,  1.2139e+00,  1.2650e+00,  1.3332e+00,
          1.3304e+00,  1.3180e+00,  1.3295e+00,  1.3295e+00,  2.3922e+00,
          2.3071e+00,  2.2416e+00,  2.4022e+00,  2.2833e+00,  2.8952e+00,
          2.3545e+00,  2.3114e+00,  2.8681e+00,  1.3025e+00,  1.3199e+00,
          1.2711e+00,  1.2696e+00,  1.3452e+00,  1.3448e+00,  1.3121e+00,
          1.3439e+00,  1.3439e+00,  1.3424e+00,  1.2219e+00,  1.3664e+00,
          1.3694e+00,  1.2711e+00,  1.3680e+00,  1.3708e+00,  1.3382e+00,
          1.3667e+00,  1.7704e+00,  1.7838e+00,  1.7357e+00,  1.7515e+00,
          1.7794e+00,  1.7818e+00,  1.7332e+00,  1.5447e+00,  1.7709e+00,
          1.5745e+00,  1.6319e+00,  1.6273e+00,  1.6208e+00,  1.5222e+00,
          1.6263e+00,  1.5443e+00,  1.6179e+00,  1.6188e+00],
        [ 1.2953e+00,  1.2981e+00,  1.3016e+00,  1.2999e+00,  1.2980e+00,
          1.2959e+00,  1.2958e+00,  1.2951e+00,  1.2951e+00,  1.3580e+00,
          1.3609e+00,  1.3599e+00,  1.3629e+00,  1.3573e+00,  1.3295e+00,
          1.3587e+00,  1.3278e+00,  1.3409e+00,  2.4695e+00,  2.4775e+00,
          2.5334e+00,  2.4808e+00,  2.4054e+00,  2.4060e+00,  2.4673e+00,
          2.3972e+00,  2.3972e+00,  1.3228e+00,  1.3192e+00,  1.3325e+00,
          1.3355e+00,  1.3232e+00,  1.3340e+00,  1.3368e+00,  1.3324e+00,
          1.3328e+00,  1.7457e+00,  1.7571e+00,  1.7496e+00,  1.7260e+00,
          1.7541e+00,  1.7541e+00,  1.7473e+00,  1.7193e+00,  1.7255e+00,
          1.6206e+00,  1.6045e+00,  1.6003e+00,  1.5942e+00,  1.5921e+00,
          1.5993e+00,  1.6167e+00,  1.5914e+00,  1.5923e+00],
        [ 1.3079e+00,  1.3108e+00,  1.3135e+00,  1.3117e+00,  1.3107e+00,
          1.3085e+00,  1.3088e+00,  1.3077e+00,  1.3077e+00,  1.3704e+00,
          1.3725e+00,  1.3724e+00,  1.3585e+00,  1.3697e+00,  1.2742e+00,
          1.3711e+00,  1.3682e+00,  1.2706e+00,  1.3267e+00,  1.3110e+00,
          1.3284e+00,  1.3277e+00,  1.3241e+00,  1.3234e+00,  1.3256e+00,
          1.3227e+00,  1.3227e+00,  2.6049e+00,  2.5573e+00,  2.3194e+00,
          2.4295e+00,  2.6027e+00,  2.3281e+00,  2.5422e+00,  2.3583e+00,
          2.3211e+00,  1.7545e+00,  1.7662e+00,  1.7352e+00,  1.7543e+00,
          1.7631e+00,  1.7630e+00,  1.7332e+00,  1.6805e+00,  1.7537e+00,
          1.6328e+00,  1.6140e+00,  1.5044e+00,  1.5491e+00,  1.6283e+00,
          1.6079e+00,  1.6444e+00,  1.5463e+00,  1.6017e+00],
        [ 1.8492e+00,  1.4462e+00,  6.1416e-01,  9.2834e-01,  1.3287e+00,
          1.7673e+00,  1.6488e+00,  1.8735e+00,  1.8735e+00,  1.7396e+00,
          1.3287e+00,  1.5304e+00,  9.2036e-01,  1.7616e+00,  1.3655e-01,
          1.6597e+00,  1.8722e+00,  9.0152e-01,  1.3465e+00,  9.6030e-01,
          7.3056e-01,  1.1704e+00,  1.7074e+00,  1.7754e+00,  1.5207e+00,
          1.8808e+00,  1.8808e+00,  8.3045e-01,  8.8056e-01,  1.8533e+00,
          1.6450e+00,  8.6521e-01,  1.7940e+00,  1.2633e+00,  1.9024e+00,
          1.8175e+00,  2.4576e-03, -2.5925e-01, -2.9444e-01, -3.5328e-02,
          2.4042e-01,  3.4736e-01, -1.3337e-01,  1.1455e+01,  6.2100e+00,
          1.9887e-01,  5.7236e-01,  6.0997e-01,  7.1224e-01,  3.6446e-01,
          7.1013e-01, -9.5085e-02,  7.3896e-01,  8.0773e-01],
        [ 1.3328e+00,  1.3713e+00,  1.4173e+00,  1.4044e+00,  1.3794e+00,
          1.3414e+00,  1.3112e+00,  1.3303e+00,  1.3303e+00,  1.2926e+00,
          1.4200e+00,  1.3181e+00,  1.4509e+00,  1.3720e+00,  1.4764e+00,
          1.3022e+00,  1.3574e+00,  1.3594e+00,  1.3889e+00,  1.3975e+00,
          1.4245e+00,  1.4019e+00,  1.3559e+00,  1.3484e+00,  1.2774e+00,
          1.3372e+00,  1.3372e+00,  1.3933e+00,  1.4339e+00,  1.3522e+00,
          1.1656e+00,  1.3487e+00,  1.2414e+00,  1.4082e+00,  1.2306e+00,
          1.3564e+00,  3.4055e-01,  2.6539e-01,  3.8669e-01,  3.4742e-01,
          1.4744e-01,  1.0152e-01,  3.6439e-01,  1.5905e-01, -4.8056e-02,
          2.9523e+00,  2.1525e+00,  2.9176e+00,  2.4207e+00,  1.7678e+00,
          1.3916e+00,  2.6569e+00,  2.7013e+00,  1.3563e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 179 : 175.96401776030433
Test loss for epoch 179 : 175.80635413341093
Test Precision for epoch 179 : 0.26153846153846155
Test Recall for epoch 179 : 0.26153846153846155
Test F1 for epoch 179 : 0.26153846153846155


theta for epoch 180 : tensor([[ 2.3972e+00,  2.4162e+00,  2.4527e+00,  2.5375e+00,  2.5193e+00,
          2.4012e+00,  2.5057e+00,  2.3963e+00,  2.3963e+00,  1.3538e+00,
          1.3566e+00,  1.3557e+00,  1.3589e+00,  1.3531e+00,  1.3609e+00,
          1.3545e+00,  1.3521e+00,  1.3142e+00,  1.3098e+00,  1.2683e+00,
          1.2690e+00,  1.3108e+00,  1.3074e+00,  1.3068e+00,  1.3092e+00,
          1.3060e+00,  1.3060e+00,  1.2903e+00,  1.3341e+00,  1.3280e+00,
          1.3310e+00,  1.3343e+00,  1.3295e+00,  1.3322e+00,  1.2846e+00,
          1.3283e+00,  1.7437e+00,  1.7548e+00,  1.7475e+00,  1.7441e+00,
          1.7519e+00,  1.6923e+00,  1.7452e+00,  1.7314e+00,  1.7435e+00,
          1.6184e+00,  1.6008e+00,  1.5966e+00,  1.5906e+00,  1.6141e+00,
          1.5956e+00,  1.6295e+00,  1.5879e+00,  1.5887e+00],
        [ 1.3151e+00,  1.3147e+00,  1.2148e+00,  1.2650e+00,  1.3328e+00,
          1.3299e+00,  1.3179e+00,  1.3290e+00,  1.3290e+00,  2.3962e+00,
          2.3110e+00,  2.2446e+00,  2.4058e+00,  2.2863e+00,  2.8955e+00,
          2.3579e+00,  2.3164e+00,  2.8683e+00,  1.3028e+00,  1.3198e+00,
          1.2712e+00,  1.2702e+00,  1.3450e+00,  1.3446e+00,  1.3123e+00,
          1.3437e+00,  1.3437e+00,  1.3420e+00,  1.2226e+00,  1.3659e+00,
          1.3689e+00,  1.2712e+00,  1.3675e+00,  1.3703e+00,  1.3378e+00,
          1.3661e+00,  1.7704e+00,  1.7838e+00,  1.7357e+00,  1.7521e+00,
          1.7794e+00,  1.7817e+00,  1.7332e+00,  1.5476e+00,  1.7709e+00,
          1.5738e+00,  1.6305e+00,  1.6259e+00,  1.6194e+00,  1.5218e+00,
          1.6249e+00,  1.5438e+00,  1.6165e+00,  1.6174e+00],
        [ 1.2950e+00,  1.2979e+00,  1.3014e+00,  1.2997e+00,  1.2977e+00,
          1.2956e+00,  1.2955e+00,  1.2948e+00,  1.2948e+00,  1.3580e+00,
          1.3609e+00,  1.3599e+00,  1.3628e+00,  1.3573e+00,  1.3293e+00,
          1.3587e+00,  1.3275e+00,  1.3411e+00,  2.4721e+00,  2.4809e+00,
          2.5366e+00,  2.4833e+00,  2.4084e+00,  2.4089e+00,  2.4704e+00,
          2.4002e+00,  2.4002e+00,  1.3223e+00,  1.3191e+00,  1.3323e+00,
          1.3353e+00,  1.3226e+00,  1.3337e+00,  1.3365e+00,  1.3321e+00,
          1.3326e+00,  1.7459e+00,  1.7572e+00,  1.7498e+00,  1.7258e+00,
          1.7543e+00,  1.7543e+00,  1.7474e+00,  1.7198e+00,  1.7252e+00,
          1.6196e+00,  1.6034e+00,  1.5992e+00,  1.5930e+00,  1.5913e+00,
          1.5982e+00,  1.6156e+00,  1.5902e+00,  1.5911e+00],
        [ 1.3076e+00,  1.3105e+00,  1.3132e+00,  1.3115e+00,  1.3104e+00,
          1.3082e+00,  1.3085e+00,  1.3074e+00,  1.3074e+00,  1.3703e+00,
          1.3724e+00,  1.3723e+00,  1.3584e+00,  1.3696e+00,  1.2741e+00,
          1.3710e+00,  1.3680e+00,  1.2706e+00,  1.3267e+00,  1.3109e+00,
          1.3284e+00,  1.3277e+00,  1.3241e+00,  1.3233e+00,  1.3256e+00,
          1.3227e+00,  1.3227e+00,  2.6082e+00,  2.5605e+00,  2.3221e+00,
          2.4323e+00,  2.6060e+00,  2.3308e+00,  2.5452e+00,  2.3612e+00,
          2.3238e+00,  1.7547e+00,  1.7663e+00,  1.7353e+00,  1.7544e+00,
          1.7633e+00,  1.7631e+00,  1.7333e+00,  1.6808e+00,  1.7538e+00,
          1.6317e+00,  1.6128e+00,  1.5034e+00,  1.5480e+00,  1.6272e+00,
          1.6068e+00,  1.6433e+00,  1.5451e+00,  1.6005e+00],
        [ 1.8483e+00,  1.4449e+00,  6.1253e-01,  9.2721e-01,  1.3279e+00,
          1.7667e+00,  1.6478e+00,  1.8730e+00,  1.8730e+00,  1.7382e+00,
          1.3274e+00,  1.5291e+00,  9.1888e-01,  1.7601e+00,  1.3449e-01,
          1.6582e+00,  1.8718e+00,  8.9888e-01,  1.3451e+00,  9.5952e-01,
          7.2932e-01,  1.1688e+00,  1.7066e+00,  1.7746e+00,  1.5200e+00,
          1.8801e+00,  1.8801e+00,  8.2929e-01,  8.7859e-01,  1.8524e+00,
          1.6443e+00,  8.6368e-01,  1.7930e+00,  1.2621e+00,  1.9016e+00,
          1.8166e+00,  2.2861e-03, -2.5920e-01, -2.9450e-01, -3.5357e-02,
          2.3974e-01,  3.4649e-01, -1.3342e-01,  1.1507e+01,  6.2042e+00,
          1.9709e-01,  5.7059e-01,  6.0813e-01,  7.1038e-01,  3.6238e-01,
          7.0828e-01, -9.6852e-02,  7.3721e-01,  8.0588e-01],
        [ 1.3349e+00,  1.3733e+00,  1.4192e+00,  1.4064e+00,  1.3813e+00,
          1.3434e+00,  1.3133e+00,  1.3323e+00,  1.3323e+00,  1.2953e+00,
          1.4227e+00,  1.3209e+00,  1.4536e+00,  1.3747e+00,  1.4791e+00,
          1.3050e+00,  1.3601e+00,  1.3622e+00,  1.3917e+00,  1.3999e+00,
          1.4272e+00,  1.4046e+00,  1.3587e+00,  1.3512e+00,  1.2799e+00,
          1.3399e+00,  1.3399e+00,  1.3953e+00,  1.4359e+00,  1.3543e+00,
          1.1675e+00,  1.3508e+00,  1.2435e+00,  1.4102e+00,  1.2328e+00,
          1.3585e+00,  3.4321e-01,  2.6803e-01,  3.8920e-01,  3.5006e-01,
          1.5004e-01,  1.0413e-01,  3.6703e-01,  1.6147e-01, -4.5671e-02,
          2.9544e+00,  2.1520e+00,  2.9205e+00,  2.4208e+00,  1.7665e+00,
          1.3898e+00,  2.6569e+00,  2.7043e+00,  1.3544e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 180 : 175.95145456920082
Test loss for epoch 180 : 175.79994817515455
Test Precision for epoch 180 : 0.26153846153846155
Test Recall for epoch 180 : 0.26153846153846155
Test F1 for epoch 180 : 0.26153846153846155


theta for epoch 181 : tensor([[ 2.4001e+00,  2.4190e+00,  2.4555e+00,  2.5406e+00,  2.5224e+00,
          2.4040e+00,  2.5088e+00,  2.3991e+00,  2.3991e+00,  1.3536e+00,
          1.3564e+00,  1.3555e+00,  1.3587e+00,  1.3529e+00,  1.3607e+00,
          1.3543e+00,  1.3519e+00,  1.3140e+00,  1.3094e+00,  1.2679e+00,
          1.2686e+00,  1.3104e+00,  1.3070e+00,  1.3064e+00,  1.3088e+00,
          1.3056e+00,  1.3056e+00,  1.2900e+00,  1.3339e+00,  1.3277e+00,
          1.3307e+00,  1.3341e+00,  1.3292e+00,  1.3319e+00,  1.2843e+00,
          1.3280e+00,  1.7434e+00,  1.7545e+00,  1.7472e+00,  1.7438e+00,
          1.7516e+00,  1.6920e+00,  1.7449e+00,  1.7311e+00,  1.7432e+00,
          1.6186e+00,  1.6010e+00,  1.5969e+00,  1.5909e+00,  1.6143e+00,
          1.5959e+00,  1.6297e+00,  1.5882e+00,  1.5890e+00],
        [ 1.3149e+00,  1.3147e+00,  1.2156e+00,  1.2650e+00,  1.3322e+00,
          1.3293e+00,  1.3178e+00,  1.3284e+00,  1.3284e+00,  2.4000e+00,
          2.3148e+00,  2.2475e+00,  2.4092e+00,  2.2892e+00,  2.8956e+00,
          2.3610e+00,  2.3213e+00,  2.8685e+00,  1.3027e+00,  1.3194e+00,
          1.2708e+00,  1.2705e+00,  1.3445e+00,  1.3441e+00,  1.3121e+00,
          1.3432e+00,  1.3432e+00,  1.3416e+00,  1.2234e+00,  1.3654e+00,
          1.3684e+00,  1.2714e+00,  1.3670e+00,  1.3699e+00,  1.3373e+00,
          1.3657e+00,  1.7700e+00,  1.7833e+00,  1.7353e+00,  1.7522e+00,
          1.7790e+00,  1.7812e+00,  1.7328e+00,  1.5502e+00,  1.7703e+00,
          1.5746e+00,  1.6306e+00,  1.6261e+00,  1.6196e+00,  1.5229e+00,
          1.6250e+00,  1.5448e+00,  1.6166e+00,  1.6176e+00],
        [ 1.2947e+00,  1.2976e+00,  1.3011e+00,  1.2994e+00,  1.2974e+00,
          1.2954e+00,  1.2953e+00,  1.2945e+00,  1.2945e+00,  1.3579e+00,
          1.3607e+00,  1.3598e+00,  1.3627e+00,  1.3572e+00,  1.3291e+00,
          1.3586e+00,  1.3270e+00,  1.3412e+00,  2.4744e+00,  2.4840e+00,
          2.5394e+00,  2.4855e+00,  2.4110e+00,  2.4114e+00,  2.4732e+00,
          2.4028e+00,  2.4028e+00,  1.3218e+00,  1.3191e+00,  1.3320e+00,
          1.3350e+00,  1.3221e+00,  1.3335e+00,  1.3363e+00,  1.3319e+00,
          1.3323e+00,  1.7456e+00,  1.7569e+00,  1.7495e+00,  1.7252e+00,
          1.7540e+00,  1.7540e+00,  1.7472e+00,  1.7200e+00,  1.7246e+00,
          1.6199e+00,  1.6037e+00,  1.5995e+00,  1.5933e+00,  1.5918e+00,
          1.5985e+00,  1.6159e+00,  1.5905e+00,  1.5914e+00],
        [ 1.3073e+00,  1.3102e+00,  1.3129e+00,  1.3112e+00,  1.3101e+00,
          1.3079e+00,  1.3082e+00,  1.3071e+00,  1.3071e+00,  1.3701e+00,
          1.3723e+00,  1.3721e+00,  1.3581e+00,  1.3694e+00,  1.2739e+00,
          1.3708e+00,  1.3678e+00,  1.2704e+00,  1.3263e+00,  1.3105e+00,
          1.3280e+00,  1.3273e+00,  1.3238e+00,  1.3230e+00,  1.3252e+00,
          1.3223e+00,  1.3223e+00,  2.6114e+00,  2.5635e+00,  2.3247e+00,
          2.4351e+00,  2.6092e+00,  2.3334e+00,  2.5482e+00,  2.3640e+00,
          2.3264e+00,  1.7544e+00,  1.7660e+00,  1.7350e+00,  1.7541e+00,
          1.7630e+00,  1.7628e+00,  1.7329e+00,  1.6806e+00,  1.7535e+00,
          1.6319e+00,  1.6131e+00,  1.5037e+00,  1.5483e+00,  1.6274e+00,
          1.6071e+00,  1.6435e+00,  1.5454e+00,  1.6008e+00],
        [ 1.8497e+00,  1.4468e+00,  6.1464e-01,  9.2943e-01,  1.3302e+00,
          1.7686e+00,  1.6495e+00,  1.8748e+00,  1.8748e+00,  1.7398e+00,
          1.3297e+00,  1.5309e+00,  9.2138e-01,  1.7616e+00,  1.3686e-01,
          1.6598e+00,  1.8741e+00,  9.0064e-01,  1.3472e+00,  9.6242e-01,
          7.3216e-01,  1.1709e+00,  1.7088e+00,  1.7767e+00,  1.5224e+00,
          1.8821e+00,  1.8821e+00,  8.3218e-01,  8.8069e-01,  1.8546e+00,
          1.6468e+00,  8.6638e-01,  1.7952e+00,  1.2646e+00,  1.9037e+00,
          1.8188e+00, -1.2641e-03, -2.6237e-01, -2.9776e-01, -3.8769e-02,
          2.3558e-01,  3.4212e-01, -1.3676e-01,  1.1556e+01,  6.1939e+00,
          2.0021e-01,  5.7356e-01,  6.1108e-01,  7.1334e-01,  3.6520e-01,
          7.1125e-01, -9.3691e-02,  7.4022e-01,  8.0882e-01],
        [ 1.3332e+00,  1.3716e+00,  1.4174e+00,  1.4046e+00,  1.3796e+00,
          1.3416e+00,  1.3115e+00,  1.3306e+00,  1.3306e+00,  1.2933e+00,
          1.4207e+00,  1.3188e+00,  1.4515e+00,  1.3728e+00,  1.4770e+00,
          1.3030e+00,  1.3579e+00,  1.3602e+00,  1.3895e+00,  1.3972e+00,
          1.4250e+00,  1.4025e+00,  1.3564e+00,  1.3489e+00,  1.2772e+00,
          1.3377e+00,  1.3377e+00,  1.3935e+00,  1.4342e+00,  1.3525e+00,
          1.1652e+00,  1.3489e+00,  1.2417e+00,  1.4084e+00,  1.2309e+00,
          1.3567e+00,  3.4106e-01,  2.6579e-01,  3.8691e-01,  3.4787e-01,
          1.4769e-01,  1.0177e-01,  3.6488e-01,  1.5894e-01, -4.8340e-02,
          2.9618e+00,  2.1570e+00,  2.9288e+00,  2.4263e+00,  1.7705e+00,
          1.3933e+00,  2.6622e+00,  2.7127e+00,  1.3580e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 181 : 175.93906792948212
Test loss for epoch 181 : 175.78632358676535
Test Precision for epoch 181 : 0.26153846153846155
Test Recall for epoch 181 : 0.26153846153846155
Test F1 for epoch 181 : 0.26153846153846155


theta for epoch 182 : tensor([[ 2.4029e+00,  2.4219e+00,  2.4584e+00,  2.5438e+00,  2.5255e+00,
          2.4069e+00,  2.5120e+00,  2.4020e+00,  2.4020e+00,  1.3535e+00,
          1.3562e+00,  1.3553e+00,  1.3585e+00,  1.3527e+00,  1.3606e+00,
          1.3542e+00,  1.3517e+00,  1.3138e+00,  1.3093e+00,  1.2677e+00,
          1.2684e+00,  1.3102e+00,  1.3068e+00,  1.3063e+00,  1.3086e+00,
          1.3055e+00,  1.3055e+00,  1.2898e+00,  1.3337e+00,  1.3275e+00,
          1.3305e+00,  1.3339e+00,  1.3290e+00,  1.3317e+00,  1.2841e+00,
          1.3278e+00,  1.7434e+00,  1.7545e+00,  1.7473e+00,  1.7439e+00,
          1.7516e+00,  1.6921e+00,  1.7449e+00,  1.7311e+00,  1.7432e+00,
          1.6177e+00,  1.6001e+00,  1.5959e+00,  1.5899e+00,  1.6134e+00,
          1.5949e+00,  1.6288e+00,  1.5872e+00,  1.5881e+00],
        [ 1.3149e+00,  1.3148e+00,  1.2165e+00,  1.2649e+00,  1.3317e+00,
          1.3288e+00,  1.3177e+00,  1.3279e+00,  1.3279e+00,  2.4039e+00,
          2.3187e+00,  2.2505e+00,  2.4128e+00,  2.2922e+00,  2.8959e+00,
          2.3643e+00,  2.3262e+00,  2.8687e+00,  1.3029e+00,  1.3192e+00,
          1.2707e+00,  1.2710e+00,  1.3442e+00,  1.3438e+00,  1.3121e+00,
          1.3429e+00,  1.3429e+00,  1.3413e+00,  1.2243e+00,  1.3650e+00,
          1.3680e+00,  1.2716e+00,  1.3666e+00,  1.3694e+00,  1.3370e+00,
          1.3653e+00,  1.7699e+00,  1.7831e+00,  1.7352e+00,  1.7527e+00,
          1.7789e+00,  1.7811e+00,  1.7327e+00,  1.5530e+00,  1.7702e+00,
          1.5741e+00,  1.6294e+00,  1.6249e+00,  1.6184e+00,  1.5227e+00,
          1.6239e+00,  1.5444e+00,  1.6155e+00,  1.6164e+00],
        [ 1.2944e+00,  1.2973e+00,  1.3008e+00,  1.2991e+00,  1.2972e+00,
          1.2951e+00,  1.2950e+00,  1.2942e+00,  1.2942e+00,  1.3578e+00,
          1.3606e+00,  1.3597e+00,  1.3626e+00,  1.3570e+00,  1.3288e+00,
          1.3585e+00,  1.3265e+00,  1.3413e+00,  2.4770e+00,  2.4875e+00,
          2.5425e+00,  2.4881e+00,  2.4139e+00,  2.4143e+00,  2.4763e+00,
          2.4057e+00,  2.4057e+00,  1.3213e+00,  1.3190e+00,  1.3318e+00,
          1.3348e+00,  1.3216e+00,  1.3333e+00,  1.3361e+00,  1.3317e+00,
          1.3321e+00,  1.7457e+00,  1.7570e+00,  1.7496e+00,  1.7249e+00,
          1.7541e+00,  1.7541e+00,  1.7472e+00,  1.7204e+00,  1.7243e+00,
          1.6190e+00,  1.6028e+00,  1.5985e+00,  1.5924e+00,  1.5912e+00,
          1.5976e+00,  1.6150e+00,  1.5896e+00,  1.5905e+00],
        [ 1.3070e+00,  1.3099e+00,  1.3127e+00,  1.3110e+00,  1.3098e+00,
          1.3076e+00,  1.3079e+00,  1.3068e+00,  1.3068e+00,  1.3700e+00,
          1.3722e+00,  1.3720e+00,  1.3580e+00,  1.3693e+00,  1.2739e+00,
          1.3708e+00,  1.3677e+00,  1.2704e+00,  1.3262e+00,  1.3103e+00,
          1.3279e+00,  1.3273e+00,  1.3237e+00,  1.3229e+00,  1.3251e+00,
          1.3223e+00,  1.3223e+00,  2.6146e+00,  2.5666e+00,  2.3273e+00,
          2.4378e+00,  2.6124e+00,  2.3360e+00,  2.5511e+00,  2.3668e+00,
          2.3291e+00,  1.7545e+00,  1.7661e+00,  1.7350e+00,  1.7542e+00,
          1.7631e+00,  1.7630e+00,  1.7330e+00,  1.6808e+00,  1.7536e+00,
          1.6311e+00,  1.6122e+00,  1.5030e+00,  1.5474e+00,  1.6265e+00,
          1.6063e+00,  1.6427e+00,  1.5445e+00,  1.5999e+00],
        [ 1.8492e+00,  1.4460e+00,  6.1357e-01,  9.2879e-01,  1.3298e+00,
          1.7684e+00,  1.6489e+00,  1.8746e+00,  1.8746e+00,  1.7388e+00,
          1.3289e+00,  1.5301e+00,  9.2050e-01,  1.7605e+00,  1.3550e-01,
          1.6588e+00,  1.8741e+00,  8.9867e-01,  1.3464e+00,  9.6219e-01,
          7.3154e-01,  1.1698e+00,  1.7084e+00,  1.7763e+00,  1.5221e+00,
          1.8818e+00,  1.8818e+00,  8.3168e-01,  8.7936e-01,  1.8542e+00,
          1.6467e+00,  8.6553e-01,  1.7948e+00,  1.2640e+00,  1.9034e+00,
          1.8184e+00, -1.9217e-03, -2.6279e-01, -2.9829e-01, -3.9299e-02,
          2.3441e-01,  3.4075e-01, -1.3729e-01,  1.1607e+01,  6.1868e+00,
          1.9916e-01,  5.7248e-01,  6.0994e-01,  7.1218e-01,  3.6385e-01,
          7.1010e-01, -9.4704e-02,  7.3916e-01,  8.0766e-01],
        [ 1.3346e+00,  1.3730e+00,  1.4188e+00,  1.4060e+00,  1.3810e+00,
          1.3430e+00,  1.3130e+00,  1.3320e+00,  1.3320e+00,  1.2953e+00,
          1.4226e+00,  1.3209e+00,  1.4534e+00,  1.3748e+00,  1.4789e+00,
          1.3050e+00,  1.3598e+00,  1.3623e+00,  1.3914e+00,  1.3988e+00,
          1.4269e+00,  1.4044e+00,  1.3583e+00,  1.3509e+00,  1.2788e+00,
          1.3396e+00,  1.3396e+00,  1.3950e+00,  1.4357e+00,  1.3540e+00,
          1.1665e+00,  1.3505e+00,  1.2433e+00,  1.4100e+00,  1.2325e+00,
          1.3582e+00,  3.4296e-01,  2.6767e-01,  3.8867e-01,  3.4975e-01,
          1.4952e-01,  1.0360e-01,  3.6676e-01,  1.6060e-01, -4.6734e-02,
          2.9646e+00,  2.1573e+00,  2.9325e+00,  2.4273e+00,  1.7700e+00,
          1.3923e+00,  2.6630e+00,  2.7165e+00,  1.3569e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 182 : 175.92695402249362
Test loss for epoch 182 : 175.77926911743918
Test Precision for epoch 182 : 0.26153846153846155
Test Recall for epoch 182 : 0.26153846153846155
Test F1 for epoch 182 : 0.26153846153846155


theta for epoch 183 : tensor([[ 2.4057e+00,  2.4247e+00,  2.4611e+00,  2.5468e+00,  2.5286e+00,
          2.4096e+00,  2.5151e+00,  2.4047e+00,  2.4047e+00,  1.3532e+00,
          1.3559e+00,  1.3550e+00,  1.3583e+00,  1.3525e+00,  1.3603e+00,
          1.3539e+00,  1.3514e+00,  1.3135e+00,  1.3088e+00,  1.2672e+00,
          1.2680e+00,  1.3098e+00,  1.3064e+00,  1.3058e+00,  1.3082e+00,
          1.3050e+00,  1.3050e+00,  1.2896e+00,  1.3334e+00,  1.3273e+00,
          1.3303e+00,  1.3336e+00,  1.3288e+00,  1.3315e+00,  1.2839e+00,
          1.3276e+00,  1.7432e+00,  1.7543e+00,  1.7470e+00,  1.7436e+00,
          1.7514e+00,  1.6918e+00,  1.7447e+00,  1.7308e+00,  1.7430e+00,
          1.6179e+00,  1.6003e+00,  1.5962e+00,  1.5902e+00,  1.6137e+00,
          1.5952e+00,  1.6290e+00,  1.5875e+00,  1.5883e+00],
        [ 1.3147e+00,  1.3148e+00,  1.2173e+00,  1.2648e+00,  1.3311e+00,
          1.3282e+00,  1.3176e+00,  1.3273e+00,  1.3273e+00,  2.4078e+00,
          2.3226e+00,  2.2535e+00,  2.4164e+00,  2.2953e+00,  2.8962e+00,
          2.3675e+00,  2.3312e+00,  2.8689e+00,  1.3026e+00,  1.3185e+00,
          1.2701e+00,  1.2710e+00,  1.3434e+00,  1.3430e+00,  1.3118e+00,
          1.3421e+00,  1.3421e+00,  1.3409e+00,  1.2250e+00,  1.3645e+00,
          1.3675e+00,  1.2717e+00,  1.3661e+00,  1.3689e+00,  1.3365e+00,
          1.3648e+00,  1.7695e+00,  1.7826e+00,  1.7348e+00,  1.7528e+00,
          1.7785e+00,  1.7807e+00,  1.7323e+00,  1.5555e+00,  1.7697e+00,
          1.5748e+00,  1.6295e+00,  1.6249e+00,  1.6184e+00,  1.5237e+00,
          1.6239e+00,  1.5453e+00,  1.6155e+00,  1.6164e+00],
        [ 1.2941e+00,  1.2970e+00,  1.3004e+00,  1.2987e+00,  1.2968e+00,
          1.2947e+00,  1.2947e+00,  1.2939e+00,  1.2939e+00,  1.3574e+00,
          1.3603e+00,  1.3593e+00,  1.3623e+00,  1.3567e+00,  1.3283e+00,
          1.3582e+00,  1.3258e+00,  1.3411e+00,  2.4795e+00,  2.4909e+00,
          2.5456e+00,  2.4905e+00,  2.4167e+00,  2.4170e+00,  2.4793e+00,
          2.4085e+00,  2.4085e+00,  1.3207e+00,  1.3189e+00,  1.3316e+00,
          1.3346e+00,  1.3211e+00,  1.3330e+00,  1.3358e+00,  1.3314e+00,
          1.3319e+00,  1.7454e+00,  1.7567e+00,  1.7493e+00,  1.7242e+00,
          1.7538e+00,  1.7538e+00,  1.7470e+00,  1.7205e+00,  1.7236e+00,
          1.6193e+00,  1.6030e+00,  1.5987e+00,  1.5926e+00,  1.5916e+00,
          1.5977e+00,  1.6152e+00,  1.5898e+00,  1.5907e+00],
        [ 1.3067e+00,  1.3096e+00,  1.3124e+00,  1.3107e+00,  1.3095e+00,
          1.3073e+00,  1.3076e+00,  1.3065e+00,  1.3065e+00,  1.3698e+00,
          1.3720e+00,  1.3717e+00,  1.3577e+00,  1.3690e+00,  1.2736e+00,
          1.3705e+00,  1.3675e+00,  1.2702e+00,  1.3258e+00,  1.3099e+00,
          1.3275e+00,  1.3269e+00,  1.3233e+00,  1.3225e+00,  1.3247e+00,
          1.3219e+00,  1.3219e+00,  2.6177e+00,  2.5695e+00,  2.3298e+00,
          2.4405e+00,  2.6155e+00,  2.3385e+00,  2.5539e+00,  2.3696e+00,
          2.3316e+00,  1.7543e+00,  1.7659e+00,  1.7348e+00,  1.7540e+00,
          1.7629e+00,  1.7627e+00,  1.7327e+00,  1.6807e+00,  1.7533e+00,
          1.6313e+00,  1.6125e+00,  1.5033e+00,  1.5477e+00,  1.6268e+00,
          1.6065e+00,  1.6429e+00,  1.5447e+00,  1.6002e+00],
        [ 1.8503e+00,  1.4475e+00,  6.1515e-01,  9.3053e-01,  1.3316e+00,
          1.7699e+00,  1.6502e+00,  1.8761e+00,  1.8761e+00,  1.7399e+00,
          1.3307e+00,  1.5314e+00,  9.2243e-01,  1.7616e+00,  1.3725e-01,
          1.6600e+00,  1.8759e+00,  8.9981e-01,  1.3479e+00,  9.6456e-01,
          7.3381e-01,  1.1713e+00,  1.7101e+00,  1.7779e+00,  1.5240e+00,
          1.8834e+00,  1.8834e+00,  8.3401e-01,  8.8089e-01,  1.8560e+00,
          1.6488e+00,  8.6765e-01,  1.7966e+00,  1.2660e+00,  1.9051e+00,
          1.8202e+00, -4.9649e-03, -2.6549e-01, -3.0109e-01, -4.2221e-02,
          2.3078e-01,  3.3691e-01, -1.4014e-01,  1.1656e+01,  6.1764e+00,
          2.0162e-01,  5.7478e-01,  6.1221e-01,  7.1446e-01,  3.6600e-01,
          7.1240e-01, -9.2199e-02,  7.4151e-01,  8.0993e-01],
        [ 1.3334e+00,  1.3718e+00,  1.4176e+00,  1.4048e+00,  1.3798e+00,
          1.3418e+00,  1.3118e+00,  1.3308e+00,  1.3308e+00,  1.2939e+00,
          1.4212e+00,  1.3195e+00,  1.4520e+00,  1.3735e+00,  1.4775e+00,
          1.3037e+00,  1.3584e+00,  1.3609e+00,  1.3899e+00,  1.3969e+00,
          1.4253e+00,  1.4029e+00,  1.3568e+00,  1.3494e+00,  1.2768e+00,
          1.3381e+00,  1.3381e+00,  1.3938e+00,  1.4345e+00,  1.3528e+00,
          1.1648e+00,  1.3493e+00,  1.2421e+00,  1.4088e+00,  1.2312e+00,
          1.3571e+00,  3.4151e-01,  2.6615e-01,  3.8708e-01,  3.4827e-01,
          1.4790e-01,  1.0198e-01,  3.6531e-01,  1.5880e-01, -4.8645e-02,
          2.9712e+00,  2.1614e+00,  2.9400e+00,  2.4319e+00,  1.7732e+00,
          1.3950e+00,  2.6675e+00,  2.7241e+00,  1.3597e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 183 : 175.9150298407102
Test loss for epoch 183 : 175.7671909792378
Test Precision for epoch 183 : 0.26153846153846155
Test Recall for epoch 183 : 0.26153846153846155
Test F1 for epoch 183 : 0.26153846153846155


theta for epoch 184 : tensor([[ 2.4085e+00,  2.4274e+00,  2.4639e+00,  2.5498e+00,  2.5316e+00,
          2.4124e+00,  2.5181e+00,  2.4075e+00,  2.4075e+00,  1.3530e+00,
          1.3557e+00,  1.3548e+00,  1.3580e+00,  1.3523e+00,  1.3601e+00,
          1.3537e+00,  1.3512e+00,  1.3133e+00,  1.3086e+00,  1.2670e+00,
          1.2678e+00,  1.3096e+00,  1.3062e+00,  1.3056e+00,  1.3080e+00,
          1.3048e+00,  1.3048e+00,  1.2893e+00,  1.3332e+00,  1.3271e+00,
          1.3300e+00,  1.3334e+00,  1.3285e+00,  1.3312e+00,  1.2836e+00,
          1.3274e+00,  1.7432e+00,  1.7543e+00,  1.7471e+00,  1.7437e+00,
          1.7514e+00,  1.6918e+00,  1.7447e+00,  1.7309e+00,  1.7430e+00,
          1.6173e+00,  1.5997e+00,  1.5956e+00,  1.5896e+00,  1.6131e+00,
          1.5946e+00,  1.6284e+00,  1.5868e+00,  1.5877e+00],
        [ 1.3146e+00,  1.3149e+00,  1.2181e+00,  1.2648e+00,  1.3305e+00,
          1.3276e+00,  1.3174e+00,  1.3268e+00,  1.3268e+00,  2.4117e+00,
          2.3267e+00,  2.2567e+00,  2.4201e+00,  2.2984e+00,  2.8966e+00,
          2.3709e+00,  2.3363e+00,  2.8693e+00,  1.3025e+00,  1.3180e+00,
          1.2697e+00,  1.2713e+00,  1.3429e+00,  1.3425e+00,  1.3116e+00,
          1.3416e+00,  1.3416e+00,  1.3405e+00,  1.2258e+00,  1.3640e+00,
          1.3670e+00,  1.2718e+00,  1.3655e+00,  1.3684e+00,  1.3360e+00,
          1.3642e+00,  1.7693e+00,  1.7824e+00,  1.7347e+00,  1.7532e+00,
          1.7783e+00,  1.7805e+00,  1.7322e+00,  1.5583e+00,  1.7695e+00,
          1.5745e+00,  1.6285e+00,  1.6240e+00,  1.6175e+00,  1.5237e+00,
          1.6230e+00,  1.5451e+00,  1.6145e+00,  1.6155e+00],
        [ 1.2938e+00,  1.2967e+00,  1.3001e+00,  1.2984e+00,  1.2965e+00,
          1.2944e+00,  1.2944e+00,  1.2936e+00,  1.2936e+00,  1.3571e+00,
          1.3600e+00,  1.3590e+00,  1.3620e+00,  1.3564e+00,  1.3279e+00,
          1.3579e+00,  1.3252e+00,  1.3410e+00,  2.4821e+00,  2.4944e+00,
          2.5488e+00,  2.4931e+00,  2.4197e+00,  2.4198e+00,  2.4825e+00,
          2.4115e+00,  2.4115e+00,  1.3201e+00,  1.3188e+00,  1.3313e+00,
          1.3343e+00,  1.3205e+00,  1.3327e+00,  1.3355e+00,  1.3311e+00,
          1.3316e+00,  1.7455e+00,  1.7567e+00,  1.7493e+00,  1.7238e+00,
          1.7538e+00,  1.7538e+00,  1.7470e+00,  1.7209e+00,  1.7232e+00,
          1.6187e+00,  1.6023e+00,  1.5981e+00,  1.5920e+00,  1.5912e+00,
          1.5971e+00,  1.6145e+00,  1.5891e+00,  1.5901e+00],
        [ 1.3065e+00,  1.3094e+00,  1.3122e+00,  1.3105e+00,  1.3093e+00,
          1.3071e+00,  1.3074e+00,  1.3063e+00,  1.3063e+00,  1.3696e+00,
          1.3718e+00,  1.3715e+00,  1.3574e+00,  1.3688e+00,  1.2734e+00,
          1.3703e+00,  1.3673e+00,  1.2701e+00,  1.3256e+00,  1.3096e+00,
          1.3273e+00,  1.3267e+00,  1.3231e+00,  1.3223e+00,  1.3245e+00,
          1.3217e+00,  1.3217e+00,  2.6208e+00,  2.5725e+00,  2.3324e+00,
          2.4431e+00,  2.6186e+00,  2.3411e+00,  2.5568e+00,  2.3723e+00,
          2.3341e+00,  1.7543e+00,  1.7659e+00,  1.7348e+00,  1.7540e+00,
          1.7629e+00,  1.7628e+00,  1.7326e+00,  1.6809e+00,  1.7534e+00,
          1.6307e+00,  1.6119e+00,  1.5028e+00,  1.5471e+00,  1.6262e+00,
          1.6060e+00,  1.6423e+00,  1.5442e+00,  1.5996e+00],
        [ 1.8501e+00,  1.4471e+00,  6.1453e-01,  9.3030e-01,  1.3316e+00,
          1.7700e+00,  1.6500e+00,  1.8762e+00,  1.8762e+00,  1.7393e+00,
          1.3303e+00,  1.5310e+00,  9.2202e-01,  1.7608e+00,  1.3642e-01,
          1.6593e+00,  1.8762e+00,  8.9837e-01,  1.3475e+00,  9.6478e-01,
          7.3368e-01,  1.1707e+00,  1.7101e+00,  1.7779e+00,  1.5241e+00,
          1.8834e+00,  1.8834e+00,  8.3397e-01,  8.8002e-01,  1.8560e+00,
          1.6489e+00,  8.6727e-01,  1.7965e+00,  1.2658e+00,  1.9051e+00,
          1.8201e+00, -5.9979e-03, -2.6629e-01, -3.0199e-01, -4.3143e-02,
          2.2923e-01,  3.3515e-01, -1.4104e-01,  1.1708e+01,  6.1681e+00,
          2.0118e-01,  5.7427e-01,  6.1164e-01,  7.1388e-01,  3.6527e-01,
          7.1183e-01, -9.2594e-02,  7.4102e-01,  8.0934e-01],
        [ 1.3345e+00,  1.3729e+00,  1.4186e+00,  1.4058e+00,  1.3808e+00,
          1.3428e+00,  1.3129e+00,  1.3318e+00,  1.3318e+00,  1.2954e+00,
          1.4226e+00,  1.3209e+00,  1.4534e+00,  1.3750e+00,  1.4788e+00,
          1.3051e+00,  1.3597e+00,  1.3624e+00,  1.3913e+00,  1.3978e+00,
          1.4267e+00,  1.4043e+00,  1.3582e+00,  1.3508e+00,  1.2779e+00,
          1.3395e+00,  1.3395e+00,  1.3948e+00,  1.4356e+00,  1.3539e+00,
          1.1656e+00,  1.3503e+00,  1.2432e+00,  1.4098e+00,  1.2324e+00,
          1.3581e+00,  3.4287e-01,  2.6748e-01,  3.8830e-01,  3.4960e-01,
          1.4917e-01,  1.0326e-01,  3.6665e-01,  1.5991e-01, -4.7594e-02,
          2.9747e+00,  2.1624e+00,  2.9443e+00,  2.4334e+00,  1.7732e+00,
          1.3945e+00,  2.6689e+00,  2.7285e+00,  1.3592e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 184 : 175.9032897022014
Test loss for epoch 184 : 175.75967650995145
Test Precision for epoch 184 : 0.26153846153846155
Test Recall for epoch 184 : 0.26153846153846155
Test F1 for epoch 184 : 0.26153846153846155


theta for epoch 185 : tensor([[ 2.4111e+00,  2.4301e+00,  2.4666e+00,  2.5528e+00,  2.5346e+00,
          2.4150e+00,  2.5211e+00,  2.4101e+00,  2.4101e+00,  1.3527e+00,
          1.3555e+00,  1.3546e+00,  1.3578e+00,  1.3520e+00,  1.3598e+00,
          1.3534e+00,  1.3509e+00,  1.3131e+00,  1.3083e+00,  1.2667e+00,
          1.2675e+00,  1.3093e+00,  1.3059e+00,  1.3053e+00,  1.3077e+00,
          1.3045e+00,  1.3045e+00,  1.2891e+00,  1.3330e+00,  1.3268e+00,
          1.3298e+00,  1.3331e+00,  1.3283e+00,  1.3310e+00,  1.2834e+00,
          1.3271e+00,  1.7431e+00,  1.7541e+00,  1.7469e+00,  1.7435e+00,
          1.7513e+00,  1.6917e+00,  1.7446e+00,  1.7307e+00,  1.7428e+00,
          1.6174e+00,  1.5998e+00,  1.5957e+00,  1.5896e+00,  1.6132e+00,
          1.5947e+00,  1.6285e+00,  1.5869e+00,  1.5878e+00],
        [ 1.3145e+00,  1.3149e+00,  1.2190e+00,  1.2648e+00,  1.3300e+00,
          1.3271e+00,  1.3173e+00,  1.3262e+00,  1.3262e+00,  2.4154e+00,
          2.3306e+00,  2.2598e+00,  2.4237e+00,  2.3014e+00,  2.8969e+00,
          2.3741e+00,  2.3413e+00,  2.8695e+00,  1.3022e+00,  1.3174e+00,
          1.2692e+00,  1.2714e+00,  1.3423e+00,  1.3418e+00,  1.3113e+00,
          1.3409e+00,  1.3409e+00,  1.3400e+00,  1.2265e+00,  1.3634e+00,
          1.3664e+00,  1.2718e+00,  1.3650e+00,  1.3678e+00,  1.3355e+00,
          1.3637e+00,  1.7689e+00,  1.7820e+00,  1.7343e+00,  1.7533e+00,
          1.7779e+00,  1.7801e+00,  1.7318e+00,  1.5608e+00,  1.7690e+00,
          1.5750e+00,  1.6284e+00,  1.6238e+00,  1.6173e+00,  1.5244e+00,
          1.6228e+00,  1.5457e+00,  1.6143e+00,  1.6153e+00],
        [ 1.2935e+00,  1.2964e+00,  1.2999e+00,  1.2982e+00,  1.2963e+00,
          1.2942e+00,  1.2941e+00,  1.2933e+00,  1.2933e+00,  1.3568e+00,
          1.3596e+00,  1.3587e+00,  1.3617e+00,  1.3561e+00,  1.3274e+00,
          1.3576e+00,  1.3245e+00,  1.3409e+00,  2.4845e+00,  2.4977e+00,
          2.5518e+00,  2.4954e+00,  2.4224e+00,  2.4224e+00,  2.4854e+00,
          2.4142e+00,  2.4142e+00,  1.3195e+00,  1.3186e+00,  1.3310e+00,
          1.3340e+00,  1.3199e+00,  1.3325e+00,  1.3352e+00,  1.3309e+00,
          1.3313e+00,  1.7453e+00,  1.7565e+00,  1.7492e+00,  1.7232e+00,
          1.7536e+00,  1.7536e+00,  1.7468e+00,  1.7211e+00,  1.7226e+00,
          1.6188e+00,  1.6024e+00,  1.5981e+00,  1.5920e+00,  1.5915e+00,
          1.5971e+00,  1.6146e+00,  1.5891e+00,  1.5901e+00],
        [ 1.3062e+00,  1.3091e+00,  1.3119e+00,  1.3102e+00,  1.3090e+00,
          1.3068e+00,  1.3071e+00,  1.3060e+00,  1.3060e+00,  1.3693e+00,
          1.3715e+00,  1.3712e+00,  1.3571e+00,  1.3685e+00,  1.2731e+00,
          1.3700e+00,  1.3669e+00,  1.2698e+00,  1.3253e+00,  1.3092e+00,
          1.3269e+00,  1.3263e+00,  1.3227e+00,  1.3220e+00,  1.3241e+00,
          1.3213e+00,  1.3213e+00,  2.6239e+00,  2.5755e+00,  2.3350e+00,
          2.4458e+00,  2.6217e+00,  2.3437e+00,  2.5596e+00,  2.3751e+00,
          2.3367e+00,  1.7541e+00,  1.7657e+00,  1.7345e+00,  1.7538e+00,
          1.7627e+00,  1.7626e+00,  1.7324e+00,  1.6808e+00,  1.7531e+00,
          1.6307e+00,  1.6119e+00,  1.5029e+00,  1.5471e+00,  1.6262e+00,
          1.6060e+00,  1.6423e+00,  1.5442e+00,  1.5996e+00],
        [ 1.8510e+00,  1.4483e+00,  6.1574e-01,  9.3170e-01,  1.3331e+00,
          1.7713e+00,  1.6511e+00,  1.8775e+00,  1.8775e+00,  1.7400e+00,
          1.3318e+00,  1.5320e+00,  9.2355e-01,  1.7616e+00,  1.3776e-01,
          1.6601e+00,  1.8778e+00,  8.9908e-01,  1.3488e+00,  9.6680e-01,
          7.3556e-01,  1.1718e+00,  1.7115e+00,  1.7792e+00,  1.5257e+00,
          1.8848e+00,  1.8848e+00,  8.3588e-01,  8.8112e-01,  1.8574e+00,
          1.6507e+00,  8.6893e-01,  1.7980e+00,  1.2674e+00,  1.9064e+00,
          1.8216e+00, -8.6680e-03, -2.6864e-01, -3.0444e-01, -4.5709e-02,
          2.2600e-01,  3.3170e-01, -1.4354e-01,  1.1757e+01,  6.1575e+00,
          2.0312e-01,  5.7605e-01,  6.1338e-01,  7.1562e-01,  3.6690e-01,
          7.1359e-01, -9.0601e-02,  7.4283e-01,  8.1106e-01],
        [ 1.3337e+00,  1.3721e+00,  1.4178e+00,  1.4050e+00,  1.3799e+00,
          1.3420e+00,  1.3121e+00,  1.3310e+00,  1.3310e+00,  1.2945e+00,
          1.4216e+00,  1.3200e+00,  1.4524e+00,  1.3741e+00,  1.4778e+00,
          1.3042e+00,  1.3587e+00,  1.3615e+00,  1.3903e+00,  1.3964e+00,
          1.4256e+00,  1.4033e+00,  1.3571e+00,  1.3497e+00,  1.2764e+00,
          1.3384e+00,  1.3384e+00,  1.3939e+00,  1.4348e+00,  1.3531e+00,
          1.1643e+00,  1.3495e+00,  1.2423e+00,  1.4090e+00,  1.2315e+00,
          1.3573e+00,  3.4185e-01,  2.6641e-01,  3.8714e-01,  3.4856e-01,
          1.4800e-01,  1.0210e-01,  3.6563e-01,  1.5858e-01, -4.9034e-02,
          2.9808e+00,  2.1659e+00,  2.9513e+00,  2.4376e+00,  1.7758e+00,
          1.3967e+00,  2.6728e+00,  2.7356e+00,  1.3613e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 185 : 175.89167054558305
Test loss for epoch 185 : 175.7486489049155
Test Precision for epoch 185 : 0.26153846153846155
Test Recall for epoch 185 : 0.26153846153846155
Test F1 for epoch 185 : 0.26153846153846155


theta for epoch 186 : tensor([[ 2.4138e+00,  2.4328e+00,  2.4693e+00,  2.5558e+00,  2.5376e+00,
          2.4177e+00,  2.5241e+00,  2.4128e+00,  2.4128e+00,  1.3526e+00,
          1.3553e+00,  1.3544e+00,  1.3576e+00,  1.3519e+00,  1.3597e+00,
          1.3533e+00,  1.3508e+00,  1.3129e+00,  1.3082e+00,  1.2666e+00,
          1.2673e+00,  1.3092e+00,  1.3057e+00,  1.3052e+00,  1.3076e+00,
          1.3044e+00,  1.3044e+00,  1.2888e+00,  1.3327e+00,  1.3266e+00,
          1.3295e+00,  1.3329e+00,  1.3280e+00,  1.3307e+00,  1.2831e+00,
          1.3269e+00,  1.7431e+00,  1.7541e+00,  1.7469e+00,  1.7435e+00,
          1.7513e+00,  1.6917e+00,  1.7446e+00,  1.7307e+00,  1.7428e+00,
          1.6168e+00,  1.5992e+00,  1.5950e+00,  1.5890e+00,  1.6125e+00,
          1.5940e+00,  1.6279e+00,  1.5863e+00,  1.5872e+00],
        [ 1.3144e+00,  1.3149e+00,  1.2199e+00,  1.2648e+00,  1.3295e+00,
          1.3266e+00,  1.3171e+00,  1.3257e+00,  1.3257e+00,  2.4191e+00,
          2.3345e+00,  2.2628e+00,  2.4273e+00,  2.3043e+00,  2.8971e+00,
          2.3773e+00,  2.3462e+00,  2.8697e+00,  1.3022e+00,  1.3172e+00,
          1.2689e+00,  1.2718e+00,  1.3419e+00,  1.3415e+00,  1.3114e+00,
          1.3406e+00,  1.3406e+00,  1.3396e+00,  1.2273e+00,  1.3629e+00,
          1.3659e+00,  1.2720e+00,  1.3645e+00,  1.3673e+00,  1.3350e+00,
          1.3631e+00,  1.7688e+00,  1.7818e+00,  1.7342e+00,  1.7537e+00,
          1.7778e+00,  1.7799e+00,  1.7316e+00,  1.5635e+00,  1.7688e+00,
          1.5746e+00,  1.6274e+00,  1.6229e+00,  1.6164e+00,  1.5243e+00,
          1.6219e+00,  1.5456e+00,  1.6134e+00,  1.6144e+00],
        [ 1.2933e+00,  1.2962e+00,  1.2996e+00,  1.2980e+00,  1.2960e+00,
          1.2939e+00,  1.2939e+00,  1.2931e+00,  1.2931e+00,  1.3567e+00,
          1.3595e+00,  1.3586e+00,  1.3615e+00,  1.3560e+00,  1.3271e+00,
          1.3574e+00,  1.3240e+00,  1.3410e+00,  2.4869e+00,  2.5010e+00,
          2.5548e+00,  2.4978e+00,  2.4251e+00,  2.4251e+00,  2.4884e+00,
          2.4169e+00,  2.4169e+00,  1.3190e+00,  1.3185e+00,  1.3307e+00,
          1.3337e+00,  1.3194e+00,  1.3322e+00,  1.3350e+00,  1.3306e+00,
          1.3310e+00,  1.7453e+00,  1.7566e+00,  1.7492e+00,  1.7228e+00,
          1.7537e+00,  1.7537e+00,  1.7468e+00,  1.7214e+00,  1.7222e+00,
          1.6182e+00,  1.6017e+00,  1.5975e+00,  1.5914e+00,  1.5911e+00,
          1.5965e+00,  1.6139e+00,  1.5885e+00,  1.5895e+00],
        [ 1.3059e+00,  1.3088e+00,  1.3117e+00,  1.3100e+00,  1.3087e+00,
          1.3065e+00,  1.3069e+00,  1.3057e+00,  1.3057e+00,  1.3690e+00,
          1.3713e+00,  1.3710e+00,  1.3568e+00,  1.3683e+00,  1.2729e+00,
          1.3698e+00,  1.3667e+00,  1.2697e+00,  1.3251e+00,  1.3089e+00,
          1.3267e+00,  1.3261e+00,  1.3225e+00,  1.3218e+00,  1.3239e+00,
          1.3211e+00,  1.3211e+00,  2.6271e+00,  2.5785e+00,  2.3376e+00,
          2.4485e+00,  2.6249e+00,  2.3463e+00,  2.5625e+00,  2.3779e+00,
          2.3394e+00,  1.7541e+00,  1.7657e+00,  1.7345e+00,  1.7538e+00,
          1.7628e+00,  1.7626e+00,  1.7323e+00,  1.6809e+00,  1.7531e+00,
          1.6301e+00,  1.6113e+00,  1.5024e+00,  1.5465e+00,  1.6256e+00,
          1.6054e+00,  1.6417e+00,  1.5435e+00,  1.5990e+00],
        [ 1.8510e+00,  1.4481e+00,  6.1535e-01,  9.3167e-01,  1.3333e+00,
          1.7716e+00,  1.6511e+00,  1.8778e+00,  1.8778e+00,  1.7395e+00,
          1.3316e+00,  1.5318e+00,  9.2341e-01,  1.7611e+00,  1.3723e-01,
          1.6597e+00,  1.8783e+00,  8.9795e-01,  1.3486e+00,  9.6728e-01,
          7.3572e-01,  1.1715e+00,  1.7117e+00,  1.7794e+00,  1.5260e+00,
          1.8850e+00,  1.8850e+00,  8.3608e-01,  8.8049e-01,  1.8575e+00,
          1.6511e+00,  8.6881e-01,  1.7981e+00,  1.2674e+00,  1.9066e+00,
          1.8217e+00, -9.8844e-03, -2.6961e-01, -3.0553e-01, -4.6830e-02,
          2.2427e-01,  3.2977e-01, -1.4462e-01,  1.1808e+01,  6.1483e+00,
          2.0293e-01,  5.7577e-01,  6.1303e-01,  7.1525e-01,  3.6642e-01,
          7.1325e-01, -9.0726e-02,  7.4256e-01,  8.1070e-01],
        [ 1.3345e+00,  1.3728e+00,  1.4185e+00,  1.4057e+00,  1.3806e+00,
          1.3427e+00,  1.3128e+00,  1.3317e+00,  1.3317e+00,  1.2956e+00,
          1.4226e+00,  1.3210e+00,  1.4534e+00,  1.3752e+00,  1.4788e+00,
          1.3053e+00,  1.3596e+00,  1.3626e+00,  1.3913e+00,  1.3970e+00,
          1.4266e+00,  1.4043e+00,  1.3581e+00,  1.3507e+00,  1.2771e+00,
          1.3394e+00,  1.3394e+00,  1.3946e+00,  1.4355e+00,  1.3539e+00,
          1.1648e+00,  1.3502e+00,  1.2431e+00,  1.4097e+00,  1.2323e+00,
          1.3581e+00,  3.4282e-01,  2.6735e-01,  3.8797e-01,  3.4950e-01,
          1.4888e-01,  1.0298e-01,  3.6658e-01,  1.5929e-01, -4.8385e-02,
          2.9847e+00,  2.1672e+00,  2.9559e+00,  2.4394e+00,  1.7762e+00,
          1.3966e+00,  2.6745e+00,  2.7404e+00,  1.3612e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 186 : 175.88014961946803
Test loss for epoch 186 : 175.74086813282926
Test Precision for epoch 186 : 0.26153846153846155
Test Recall for epoch 186 : 0.26153846153846155
Test F1 for epoch 186 : 0.26153846153846155


theta for epoch 187 : tensor([[ 2.4165,  2.4355,  2.4719,  2.5588,  2.5405,  2.4204,  2.5271,  2.4155,
          2.4155,  1.3524,  1.3551,  1.3542,  1.3574,  1.3517,  1.3595,  1.3531,
          1.3506,  1.3127,  1.3079,  1.2663,  1.2670,  1.3089,  1.3055,  1.3049,
          1.3073,  1.3041,  1.3041,  1.2885,  1.3324,  1.3263,  1.3292,  1.3326,
          1.3277,  1.3304,  1.2828,  1.3266,  1.7429,  1.7540,  1.7468,  1.7433,
          1.7512,  1.6915,  1.7444,  1.7305,  1.7427,  1.6167,  1.5991,  1.5949,
          1.5889,  1.6125,  1.5940,  1.6278,  1.5862,  1.5871],
        [ 1.3143,  1.3149,  1.2208,  1.2648,  1.3290,  1.3261,  1.3170,  1.3252,
          1.3252,  2.4226,  2.3383,  2.2658,  2.4308,  2.3072,  2.8973,  2.3804,
          2.3511,  2.8698,  1.3021,  1.3167,  1.2686,  1.2721,  1.3414,  1.3410,
          1.3113,  1.3401,  1.3401,  1.3391,  1.2280,  1.3624,  1.3654,  1.2721,
          1.3639,  1.3668,  1.3345,  1.3626,  1.7684,  1.7814,  1.7339,  1.7538,
          1.7774,  1.7795,  1.7313,  1.5660,  1.7684,  1.5750,  1.6272,  1.6226,
          1.6162,  1.5249,  1.6216,  1.5460,  1.6131,  1.6142],
        [ 1.2931,  1.2959,  1.2994,  1.2977,  1.2958,  1.2937,  1.2937,  1.2929,
          1.2929,  1.3566,  1.3594,  1.3584,  1.3614,  1.3559,  1.3268,  1.3573,
          1.3235,  1.3410,  2.4892,  2.5041,  2.5577,  2.5000,  2.4277,  2.4275,
          2.4912,  2.4195,  2.4195,  1.3184,  1.3184,  1.3305,  1.3335,  1.3188,
          1.3320,  1.3347,  1.3304,  1.3308,  1.7451,  1.7564,  1.7490,  1.7222,
          1.7535,  1.7535,  1.7466,  1.7216,  1.7216,  1.6182,  1.6017,  1.5975,
          1.5914,  1.5913,  1.5965,  1.6139,  1.5885,  1.5894],
        [ 1.3056,  1.3085,  1.3114,  1.3097,  1.3084,  1.3062,  1.3066,  1.3054,
          1.3054,  1.3688,  1.3711,  1.3707,  1.3565,  1.3681,  1.2727,  1.3695,
          1.3664,  1.2695,  1.3248,  1.3086,  1.3264,  1.3258,  1.3222,  1.3215,
          1.3236,  1.3208,  1.3208,  2.6302,  2.5815,  2.3402,  2.4512,  2.6281,
          2.3489,  2.5654,  2.3807,  2.3419,  1.7539,  1.7655,  1.7342,  1.7536,
          1.7626,  1.7625,  1.7320,  1.6809,  1.7529,  1.6299,  1.6112,  1.5024,
          1.5464,  1.6255,  1.6053,  1.6416,  1.5434,  1.5989],
        [ 1.8517,  1.4491,  0.6163,  0.9329,  1.3346,  1.7727,  1.6520,  1.8789,
          1.8789,  1.7402,  1.3329,  1.5328,  0.9248,  1.7617,  0.1384,  1.6604,
          1.8798,  0.8985,  1.3497,  0.9691,  0.7374,  1.1725,  1.7130,  1.7806,
          1.5274,  1.8862,  1.8862,  0.8378,  0.8813,  1.8587,  1.6526,  0.8702,
          1.7994,  1.2688,  1.9078,  1.8229, -0.0123, -0.2718, -0.3078, -0.0492,
          0.2213,  0.3266, -0.1469, 11.8573,  6.1372,  0.2046,  0.5772,  0.6145,
          0.7167,  0.3678,  0.7147, -0.0890,  0.7441,  0.8121],
        [ 1.3338,  1.3722,  1.4178,  1.4050,  1.3800,  1.3421,  1.3121,  1.3310,
          1.3310,  1.2949,  1.4219,  1.3203,  1.4526,  1.3746,  1.4781,  1.3046,
          1.3588,  1.3619,  1.3905,  1.3958,  1.4258,  1.4035,  1.3573,  1.3499,
          1.2758,  1.3386,  1.3386,  1.3939,  1.4349,  1.3532,  1.1637,  1.3495,
          1.2424,  1.4090,  1.2315,  1.3574,  0.3420,  0.2665,  0.3870,  0.3486,
          0.1479,  0.1020,  0.3657,  0.1582, -0.0496,  2.9906,  2.1705,  2.9626,
          2.4433,  1.7785,  1.3985,  2.6782,  2.7472,  1.3631]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 187 : 175.86869819947137
Test loss for epoch 187 : 175.7303968716993
Test Precision for epoch 187 : 0.26153846153846155
Test Recall for epoch 187 : 0.26153846153846155
Test F1 for epoch 187 : 0.26153846153846155


theta for epoch 188 : tensor([[ 2.4193,  2.4382,  2.4747,  2.5618,  2.5435,  2.4231,  2.5301,  2.4182,
          2.4182,  1.3522,  1.3549,  1.3540,  1.3572,  1.3515,  1.3593,  1.3529,
          1.3504,  1.3125,  1.3077,  1.2660,  1.2668,  1.3086,  1.3052,  1.3047,
          1.3070,  1.3039,  1.3039,  1.2882,  1.3321,  1.3260,  1.3289,  1.3323,
          1.3274,  1.3301,  1.2825,  1.3263,  1.7429,  1.7539,  1.7468,  1.7433,
          1.7511,  1.6915,  1.7444,  1.7305,  1.7426,  1.6162,  1.5986,  1.5944,
          1.5884,  1.6119,  1.5934,  1.6273,  1.5856,  1.5865],
        [ 1.3141,  1.3149,  1.2217,  1.2648,  1.3285,  1.3256,  1.3168,  1.3247,
          1.3247,  2.4261,  2.3422,  2.2688,  2.4344,  2.3100,  2.8975,  2.3834,
          2.3560,  2.8700,  1.3021,  1.3164,  1.2683,  1.2725,  1.3410,  1.3406,
          1.3113,  1.3397,  1.3397,  1.3387,  1.2288,  1.3619,  1.3649,  1.2722,
          1.3634,  1.3663,  1.3341,  1.3621,  1.7683,  1.7812,  1.7337,  1.7541,
          1.7773,  1.7793,  1.7311,  1.5686,  1.7682,  1.5748,  1.6264,  1.6219,
          1.6154,  1.5250,  1.6209,  1.5460,  1.6124,  1.6134],
        [ 1.2928,  1.2956,  1.2991,  1.2974,  1.2955,  1.2934,  1.2934,  1.2926,
          1.2926,  1.3564,  1.3592,  1.3583,  1.3613,  1.3557,  1.3264,  1.3571,
          1.3230,  1.3410,  2.4917,  2.5075,  2.5608,  2.5024,  2.4304,  2.4302,
          2.4943,  2.4222,  2.4222,  1.3178,  1.3182,  1.3302,  1.3332,  1.3182,
          1.3317,  1.3344,  1.3301,  1.3305,  1.7451,  1.7564,  1.7490,  1.7218,
          1.7535,  1.7535,  1.7466,  1.7219,  1.7212,  1.6178,  1.6012,  1.5970,
          1.5909,  1.5910,  1.5960,  1.6134,  1.5880,  1.5890],
        [ 1.3053,  1.3082,  1.3111,  1.3094,  1.3081,  1.3059,  1.3062,  1.3051,
          1.3051,  1.3686,  1.3709,  1.3705,  1.3563,  1.3679,  1.2725,  1.3693,
          1.3662,  1.2694,  1.3245,  1.3083,  1.3261,  1.3255,  1.3220,  1.3213,
          1.3233,  1.3206,  1.3206,  2.6333,  2.5845,  2.3428,  2.4539,  2.6312,
          2.3515,  2.5682,  2.3834,  2.3445,  1.7539,  1.7655,  1.7342,  1.7536,
          1.7626,  1.7625,  1.7320,  1.6810,  1.7529,  1.6294,  1.6107,  1.5020,
          1.5459,  1.6250,  1.6048,  1.6411,  1.5429,  1.5984],
        [ 1.8517,  1.4491,  0.6160,  0.9329,  1.3349,  1.7730,  1.6520,  1.8792,
          1.8792,  1.7397,  1.3329,  1.5326,  0.9247,  1.7613,  0.1380,  1.6601,
          1.8804,  0.8975,  1.3496,  0.9697,  0.7376,  1.1722,  1.7132,  1.7809,
          1.5278,  1.8865,  1.8865,  0.8380,  0.8808,  1.8589,  1.6530,  0.8702,
          1.7995,  1.2689,  1.9080,  1.8231, -0.0136, -0.2728, -0.3089, -0.0504,
          0.2195,  0.3246, -0.1480, 11.9080,  6.1272,  0.2045,  0.5771,  0.6142,
          0.7164,  0.3674,  0.7145, -0.0890,  0.7439,  0.8119],
        [ 1.3345,  1.3728,  1.4184,  1.4056,  1.3806,  1.3427,  1.3128,  1.3317,
          1.3317,  1.2959,  1.4228,  1.3213,  1.4535,  1.3757,  1.4790,  1.3057,
          1.3597,  1.3629,  1.3914,  1.3963,  1.4266,  1.4045,  1.3582,  1.3509,
          1.2764,  1.3395,  1.3395,  1.3945,  1.4355,  1.3539,  1.1640,  1.3502,
          1.2431,  1.4097,  1.2323,  1.3581,  0.3429,  0.2673,  0.3877,  0.3495,
          0.1487,  0.1028,  0.3666,  0.1588, -0.0491,  2.9945,  2.1718,  2.9673,
          2.4452,  1.7790,  1.3984,  2.6800,  2.7521,  1.3630]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 188 : 175.857311672555
Test loss for epoch 188 : 175.72262942717214
Test Precision for epoch 188 : 0.26153846153846155
Test Recall for epoch 188 : 0.26153846153846155
Test F1 for epoch 188 : 0.26153846153846155


theta for epoch 189 : tensor([[ 2.4220,  2.4409,  2.4774,  2.5648,  2.5465,  2.4258,  2.5331,  2.4209,
          2.4209,  1.3519,  1.3546,  1.3538,  1.3569,  1.3512,  1.3590,  1.3526,
          1.3501,  1.3122,  1.3072,  1.2656,  1.2663,  1.3082,  1.3048,  1.3043,
          1.3066,  1.3034,  1.3034,  1.2879,  1.3318,  1.3257,  1.3286,  1.3320,
          1.3271,  1.3298,  1.2822,  1.3260,  1.7427,  1.7538,  1.7466,  1.7431,
          1.7510,  1.6913,  1.7442,  1.7303,  1.7425,  1.6162,  1.5986,  1.5944,
          1.5884,  1.6120,  1.5935,  1.6273,  1.5857,  1.5866],
        [ 1.3139,  1.3148,  1.2225,  1.2648,  1.3279,  1.3250,  1.3166,  1.3241,
          1.3241,  2.4296,  2.3460,  2.2718,  2.4380,  2.3129,  2.8977,  2.3865,
          2.3608,  2.8701,  1.3019,  1.3159,  1.2678,  1.2727,  1.3404,  1.3400,
          1.3111,  1.3391,  1.3391,  1.3383,  1.2296,  1.3614,  1.3644,  1.2723,
          1.3629,  1.3658,  1.3336,  1.3616,  1.7679,  1.7808,  1.7334,  1.7543,
          1.7769,  1.7789,  1.7308,  1.5711,  1.7678,  1.5752,  1.6263,  1.6218,
          1.6153,  1.5257,  1.6208,  1.5465,  1.6123,  1.6133],
        [ 1.2924,  1.2953,  1.2987,  1.2970,  1.2951,  1.2930,  1.2931,  1.2922,
          1.2922,  1.3561,  1.3589,  1.3580,  1.3610,  1.3554,  1.3259,  1.3569,
          1.3223,  1.3409,  2.4941,  2.5108,  2.5638,  2.5047,  2.4331,  2.4327,
          2.4973,  2.4249,  2.4249,  1.3172,  1.3181,  1.3299,  1.3329,  1.3176,
          1.3314,  1.3341,  1.3298,  1.3302,  1.7449,  1.7562,  1.7489,  1.7212,
          1.7533,  1.7534,  1.7465,  1.7221,  1.7206,  1.6179,  1.6013,  1.5970,
          1.5909,  1.5912,  1.5961,  1.6134,  1.5880,  1.5890],
        [ 1.3049,  1.3079,  1.3108,  1.3091,  1.3078,  1.3056,  1.3059,  1.3047,
          1.3047,  1.3684,  1.3707,  1.3703,  1.3560,  1.3677,  1.2723,  1.3691,
          1.3660,  1.2692,  1.3241,  1.3078,  1.3257,  1.3252,  1.3216,  1.3209,
          1.3229,  1.3202,  1.3202,  2.6363,  2.5874,  2.3453,  2.4564,  2.6342,
          2.3540,  2.5710,  2.3861,  2.3470,  1.7538,  1.7653,  1.7340,  1.7534,
          1.7624,  1.7623,  1.7317,  1.6810,  1.7527,  1.6295,  1.6107,  1.5022,
          1.5459,  1.6250,  1.6049,  1.6411,  1.5429,  1.5984],
        [ 1.8525,  1.4501,  0.6170,  0.9341,  1.3362,  1.7742,  1.6530,  1.8802,
          1.8802,  1.7403,  1.3341,  1.5336,  0.9261,  1.7619,  0.1391,  1.6608,
          1.8819,  0.8980,  1.3508,  0.9715,  0.7393,  1.1731,  1.7145,  1.7821,
          1.5293,  1.8877,  1.8877,  0.8397,  0.8817,  1.8602,  1.6546,  0.8716,
          1.8008,  1.2703,  1.9092,  1.8244, -0.0160, -0.2750, -0.3112, -0.0528,
          0.2165,  0.3214, -0.1503, 11.9574,  6.1155,  0.2062,  0.5786,  0.6157,
          0.7179,  0.3688,  0.7160, -0.0873,  0.7454,  0.8133],
        [ 1.3339,  1.3722,  1.4177,  1.4049,  1.3799,  1.3420,  1.3122,  1.3310,
          1.3310,  1.2953,  1.4221,  1.3206,  1.4528,  1.3750,  1.4783,  1.3050,
          1.3590,  1.3623,  1.3906,  1.3950,  1.4258,  1.4037,  1.3574,  1.3501,
          1.2752,  1.3387,  1.3387,  1.3938,  1.4349,  1.3532,  1.1630,  1.3495,
          1.2425,  1.4090,  1.2316,  1.3574,  0.3420,  0.2665,  0.3868,  0.3487,
          0.1477,  0.1019,  0.3658,  0.1577, -0.0503,  3.0004,  2.1750,  2.9739,
          2.4490,  1.7812,  1.4002,  2.6836,  2.7589,  1.3648]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 189 : 175.84598562238037
Test loss for epoch 189 : 175.71231343356166
Test Precision for epoch 189 : 0.26153846153846155
Test Recall for epoch 189 : 0.26153846153846155
Test F1 for epoch 189 : 0.26153846153846155


theta for epoch 190 : tensor([[ 2.4247,  2.4436,  2.4801,  2.5678,  2.5495,  2.4285,  2.5361,  2.4236,
          2.4236,  1.3517,  1.3544,  1.3535,  1.3567,  1.3510,  1.3587,  1.3524,
          1.3499,  1.3119,  1.3070,  1.2653,  1.2661,  1.3079,  1.3045,  1.3040,
          1.3063,  1.3032,  1.3032,  1.2877,  1.3316,  1.3254,  1.3284,  1.3317,
          1.3269,  1.3296,  1.2820,  1.3257,  1.7427,  1.7538,  1.7466,  1.7431,
          1.7510,  1.6913,  1.7442,  1.7303,  1.7425,  1.6156,  1.5980,  1.5939,
          1.5879,  1.6114,  1.5929,  1.6267,  1.5851,  1.5860],
        [ 1.3138,  1.3147,  1.2234,  1.2647,  1.3273,  1.3244,  1.3164,  1.3236,
          1.3236,  2.4330,  2.3500,  2.2749,  2.4416,  2.3158,  2.8979,  2.3896,
          2.3657,  2.8703,  1.3018,  1.3155,  1.2674,  1.2730,  1.3399,  1.3395,
          1.3111,  1.3386,  1.3386,  1.3379,  1.2305,  1.3609,  1.3639,  1.2725,
          1.3625,  1.3653,  1.3332,  1.3611,  1.7677,  1.7806,  1.7333,  1.7546,
          1.7768,  1.7787,  1.7307,  1.5737,  1.7675,  1.5749,  1.6255,  1.6210,
          1.6145,  1.5257,  1.6200,  1.5464,  1.6114,  1.6125],
        [ 1.2921,  1.2950,  1.2984,  1.2967,  1.2948,  1.2927,  1.2928,  1.2919,
          1.2919,  1.3559,  1.3587,  1.3578,  1.3608,  1.3552,  1.3254,  1.3566,
          1.3217,  1.3408,  2.4966,  2.5142,  2.5670,  2.5071,  2.4358,  2.4354,
          2.5004,  2.4276,  2.4276,  1.3166,  1.3179,  1.3297,  1.3326,  1.3170,
          1.3311,  1.3339,  1.3295,  1.3300,  1.7449,  1.7562,  1.7489,  1.7207,
          1.7534,  1.7534,  1.7465,  1.7224,  1.7201,  1.6173,  1.6007,  1.5965,
          1.5904,  1.5909,  1.5955,  1.6128,  1.5874,  1.5885],
        [ 1.3047,  1.3076,  1.3105,  1.3088,  1.3075,  1.3053,  1.3056,  1.3044,
          1.3044,  1.3682,  1.3705,  1.3701,  1.3557,  1.3675,  1.2721,  1.3689,
          1.3658,  1.2691,  1.3239,  1.3076,  1.3255,  1.3250,  1.3214,  1.3207,
          1.3227,  1.3200,  1.3200,  2.6394,  2.5903,  2.3478,  2.4590,  2.6372,
          2.3565,  2.5738,  2.3888,  2.3495,  1.7538,  1.7653,  1.7339,  1.7534,
          1.7624,  1.7623,  1.7317,  1.6811,  1.7527,  1.6289,  1.6102,  1.5018,
          1.5454,  1.6245,  1.6044,  1.6406,  1.5424,  1.5979],
        [ 1.8524,  1.4499,  0.6165,  0.9340,  1.3363,  1.7744,  1.6529,  1.8805,
          1.8805,  1.7398,  1.3340,  1.5334,  0.9259,  1.7614,  0.1386,  1.6603,
          1.8824,  0.8969,  1.3506,  0.9719,  0.7394,  1.1727,  1.7147,  1.7822,
          1.5295,  1.8879,  1.8879,  0.8399,  0.8810,  1.8603,  1.6550,  0.8715,
          1.8009,  1.2703,  1.9094,  1.8245, -0.0172, -0.2759, -0.3123, -0.0538,
          0.2149,  0.3196, -0.1514, 12.0081,  6.1050,  0.2059,  0.5782,  0.6153,
          0.7175,  0.3683,  0.7156, -0.0875,  0.7451,  0.8129],
        [ 1.3347,  1.3729,  1.4184,  1.4057,  1.3806,  1.3428,  1.3130,  1.3318,
          1.3318,  1.2964,  1.4232,  1.3217,  1.4538,  1.3762,  1.4793,  1.3061,
          1.3600,  1.3634,  1.3917,  1.3957,  1.4268,  1.4047,  1.3585,  1.3511,
          1.2758,  1.3398,  1.3398,  1.3946,  1.4358,  1.3541,  1.1635,  1.3503,
          1.2434,  1.4099,  1.2325,  1.3583,  0.3430,  0.2675,  0.3876,  0.3496,
          0.1486,  0.1028,  0.3668,  0.1584, -0.0495,  3.0042,  2.1761,  2.9784,
          2.4507,  1.7814,  1.3999,  2.6852,  2.7636,  1.3646]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 190 : 175.83474949329621
Test loss for epoch 190 : 175.70495495953242
Test Precision for epoch 190 : 0.26153846153846155
Test Recall for epoch 190 : 0.26153846153846155
Test F1 for epoch 190 : 0.26153846153846155


theta for epoch 191 : tensor([[ 2.4272,  2.4462,  2.4826,  2.5706,  2.5524,  2.4310,  2.5390,  2.4261,
          2.4261,  1.3514,  1.3541,  1.3533,  1.3564,  1.3507,  1.3585,  1.3521,
          1.3496,  1.3117,  1.3066,  1.2650,  1.2657,  1.3076,  1.3042,  1.3037,
          1.3060,  1.3028,  1.3028,  1.2874,  1.3313,  1.3252,  1.3282,  1.3315,
          1.3267,  1.3294,  1.2817,  1.3255,  1.7425,  1.7536,  1.7465,  1.7430,
          1.7508,  1.6911,  1.7440,  1.7301,  1.7423,  1.6157,  1.5981,  1.5939,
          1.5879,  1.6115,  1.5930,  1.6268,  1.5851,  1.5861],
        [ 1.3136,  1.3146,  1.2242,  1.2647,  1.3268,  1.3239,  1.3161,  1.3230,
          1.3230,  2.4363,  2.3538,  2.2780,  2.4452,  2.3187,  2.8981,  2.3927,
          2.3706,  2.8704,  1.3015,  1.3149,  1.2669,  1.2732,  1.3393,  1.3389,
          1.3109,  1.3380,  1.3380,  1.3375,  1.2313,  1.3604,  1.3635,  1.2726,
          1.3620,  1.3648,  1.3327,  1.3607,  1.7674,  1.7802,  1.7329,  1.7546,
          1.7764,  1.7783,  1.7303,  1.5761,  1.7671,  1.5753,  1.6253,  1.6208,
          1.6143,  1.5263,  1.6198,  1.5468,  1.6113,  1.6123],
        [ 1.2918,  1.2947,  1.2981,  1.2964,  1.2945,  1.2924,  1.2925,  1.2916,
          1.2916,  1.3557,  1.3584,  1.3575,  1.3605,  1.3550,  1.3249,  1.3564,
          1.3210,  1.3407,  2.4988,  2.5174,  2.5700,  2.5093,  2.4384,  2.4378,
          2.5033,  2.4301,  2.4301,  1.3160,  1.3178,  1.3294,  1.3324,  1.3165,
          1.3309,  1.3337,  1.3293,  1.3297,  1.7448,  1.7560,  1.7487,  1.7201,
          1.7532,  1.7532,  1.7463,  1.7225,  1.7195,  1.6174,  1.6008,  1.5966,
          1.5904,  1.5911,  1.5956,  1.6128,  1.5875,  1.5885],
        [ 1.3044,  1.3073,  1.3102,  1.3086,  1.3072,  1.3050,  1.3053,  1.3042,
          1.3042,  1.3679,  1.3703,  1.3699,  1.3554,  1.3672,  1.2719,  1.3687,
          1.3655,  1.2689,  1.3236,  1.3072,  1.3252,  1.3246,  1.3210,  1.3203,
          1.3224,  1.3196,  1.3196,  2.6423,  2.5931,  2.3502,  2.4615,  2.6402,
          2.3589,  2.5765,  2.3914,  2.3520,  1.7536,  1.7652,  1.7337,  1.7532,
          1.7623,  1.7622,  1.7314,  1.6811,  1.7525,  1.6290,  1.6103,  1.5019,
          1.5455,  1.6246,  1.6045,  1.6406,  1.5424,  1.5980],
        [ 1.8533,  1.4511,  0.6177,  0.9353,  1.3378,  1.7757,  1.6540,  1.8817,
          1.8817,  1.7405,  1.3354,  1.5346,  0.9275,  1.7622,  0.1400,  1.6612,
          1.8840,  0.8976,  1.3519,  0.9740,  0.7413,  1.1739,  1.7161,  1.7836,
          1.5311,  1.8892,  1.8892,  0.8418,  0.8821,  1.8617,  1.6567,  0.8731,
          1.8024,  1.2719,  1.9108,  1.8260, -0.0198, -0.2782, -0.3147, -0.0564,
          0.2118,  0.3162, -0.1538, 12.0574,  6.0923,  0.2078,  0.5799,  0.6169,
          0.7191,  0.3699,  0.7173, -0.0855,  0.7468,  0.8145],
        [ 1.3338,  1.3721,  1.4175,  1.4048,  1.3797,  1.3419,  1.3121,  1.3309,
          1.3309,  1.2954,  1.4221,  1.3207,  1.4528,  1.3753,  1.4783,  1.3052,
          1.3589,  1.3624,  1.3906,  1.3941,  1.4257,  1.4037,  1.3573,  1.3500,
          1.2743,  1.3387,  1.3387,  1.3937,  1.4349,  1.3532,  1.1622,  1.3494,
          1.2425,  1.4090,  1.2315,  1.3574,  0.3419,  0.2663,  0.3864,  0.3485,
          0.1474,  0.1015,  0.3656,  0.1570, -0.0511,  3.0104,  2.1795,  2.9853,
          2.4547,  1.7840,  1.4020,  2.6891,  2.7707,  1.3666]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 191 : 175.82363971678265
Test loss for epoch 191 : 175.6944728508291
Test Precision for epoch 191 : 0.26153846153846155
Test Recall for epoch 191 : 0.26153846153846155
Test F1 for epoch 191 : 0.26153846153846155


theta for epoch 192 : tensor([[ 2.4299,  2.4488,  2.4852,  2.5735,  2.5553,  2.4336,  2.5419,  2.4287,
          2.4287,  1.3513,  1.3540,  1.3531,  1.3563,  1.3506,  1.3583,  1.3520,
          1.3494,  1.3115,  1.3065,  1.2649,  1.2656,  1.3075,  1.3041,  1.3036,
          1.3059,  1.3027,  1.3027,  1.2872,  1.3311,  1.3250,  1.3279,  1.3313,
          1.3264,  1.3291,  1.2815,  1.3253,  1.7426,  1.7537,  1.7465,  1.7430,
          1.7509,  1.6912,  1.7441,  1.7301,  1.7423,  1.6149,  1.5973,  1.5932,
          1.5872,  1.6107,  1.5922,  1.6260,  1.5844,  1.5853],
        [ 1.3135,  1.3146,  1.2251,  1.2648,  1.3263,  1.3234,  1.3160,  1.3225,
          1.3225,  2.4396,  2.3577,  2.2811,  2.4488,  2.3215,  2.8983,  2.3957,
          2.3754,  2.8706,  1.3015,  1.3146,  1.2667,  1.2736,  1.3390,  1.3385,
          1.3110,  1.3376,  1.3376,  1.3370,  1.2321,  1.3599,  1.3630,  1.2728,
          1.3615,  1.3643,  1.3323,  1.3602,  1.7672,  1.7800,  1.7328,  1.7549,
          1.7763,  1.7782,  1.7302,  1.5787,  1.7669,  1.5747,  1.6243,  1.6198,
          1.6133,  1.5260,  1.6188,  1.5464,  1.6102,  1.6113],
        [ 1.2916,  1.2944,  1.2979,  1.2962,  1.2943,  1.2922,  1.2923,  1.2914,
          1.2914,  1.3555,  1.3583,  1.3574,  1.3603,  1.3548,  1.3245,  1.3562,
          1.3204,  1.3407,  2.5012,  2.5207,  2.5730,  2.5117,  2.4410,  2.4404,
          2.5063,  2.4328,  2.4328,  1.3154,  1.3177,  1.3292,  1.3322,  1.3159,
          1.3307,  1.3334,  1.3291,  1.3295,  1.7448,  1.7561,  1.7488,  1.7197,
          1.7533,  1.7533,  1.7463,  1.7228,  1.7191,  1.6167,  1.6000,  1.5958,
          1.5897,  1.5906,  1.5949,  1.6121,  1.5868,  1.5878],
        [ 1.3041,  1.3071,  1.3100,  1.3083,  1.3069,  1.3048,  1.3051,  1.3039,
          1.3039,  1.3678,  1.3701,  1.3697,  1.3552,  1.3671,  1.2718,  1.3685,
          1.3653,  1.2688,  1.3235,  1.3070,  1.3250,  1.3245,  1.3209,  1.3202,
          1.3222,  1.3195,  1.3195,  2.6453,  2.5959,  2.3527,  2.4641,  2.6432,
          2.3614,  2.5792,  2.3941,  2.3544,  1.7537,  1.7652,  1.7337,  1.7533,
          1.7624,  1.7623,  1.7314,  1.6813,  1.7525,  1.6282,  1.6096,  1.5013,
          1.5447,  1.6239,  1.6038,  1.6399,  1.5417,  1.5972],
        [ 1.8530,  1.4507,  0.6168,  0.9349,  1.3376,  1.7756,  1.6537,  1.8817,
          1.8817,  1.7396,  1.3349,  1.5340,  0.9269,  1.7614,  0.1390,  1.6604,
          1.8842,  0.8961,  1.3513,  0.9740,  0.7410,  1.1731,  1.7159,  1.7834,
          1.5311,  1.8891,  1.8891,  0.8416,  0.8810,  1.8616,  1.6567,  0.8725,
          1.8021,  1.2715,  1.9106,  1.8258, -0.0205, -0.2787, -0.3153, -0.0571,
          0.2106,  0.3148, -0.1544, 12.1084,  6.0817,  0.2071,  0.5791,  0.6160,
          0.7182,  0.3689,  0.7164, -0.0862,  0.7460,  0.8136],
        [ 1.3350,  1.3732,  1.4186,  1.4059,  1.3808,  1.3430,  1.3132,  1.3320,
          1.3320,  1.2970,  1.4236,  1.3222,  1.4542,  1.3768,  1.4797,  1.3067,
          1.3603,  1.3640,  1.3921,  1.3952,  1.4271,  1.4052,  1.3588,  1.3515,
          1.2754,  1.3402,  1.3402,  1.3948,  1.4361,  1.3544,  1.1631,  1.3506,
          1.2437,  1.4101,  1.2328,  1.3586,  0.3433,  0.2677,  0.3876,  0.3499,
          0.1487,  0.1029,  0.3670,  0.1582, -0.0499,  3.0137,  2.1801,  2.9893,
          2.4559,  1.7837,  1.4012,  2.6902,  2.7748,  1.3658]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 192 : 175.8127723380932
Test loss for epoch 192 : 175.68825156663584
Test Precision for epoch 192 : 0.26153846153846155
Test Recall for epoch 192 : 0.26153846153846155
Test F1 for epoch 192 : 0.26153846153846155


theta for epoch 193 : tensor([[ 2.4324,  2.4514,  2.4878,  2.5763,  2.5581,  2.4361,  2.5447,  2.4312,
          2.4312,  1.3510,  1.3537,  1.3528,  1.3560,  1.3503,  1.3580,  1.3517,
          1.3492,  1.3113,  1.3062,  1.2645,  1.2652,  1.3071,  1.3037,  1.3032,
          1.3055,  1.3024,  1.3024,  1.2869,  1.3308,  1.3247,  1.3277,  1.3310,
          1.3262,  1.3289,  1.2812,  1.3250,  1.7424,  1.7534,  1.7463,  1.7428,
          1.7507,  1.6910,  1.7439,  1.7299,  1.7421,  1.6152,  1.5976,  1.5935,
          1.5875,  1.6111,  1.5925,  1.6263,  1.5847,  1.5857],
        [ 1.3133,  1.3145,  1.2260,  1.2648,  1.3258,  1.3229,  1.3158,  1.3220,
          1.3220,  2.4428,  2.3615,  2.2842,  2.4524,  2.3243,  2.8985,  2.3987,
          2.3802,  2.8706,  1.3012,  1.3140,  1.2661,  1.2738,  1.3383,  1.3379,
          1.3108,  1.3370,  1.3370,  1.3366,  1.2329,  1.3594,  1.3625,  1.2729,
          1.3609,  1.3638,  1.3318,  1.3597,  1.7668,  1.7795,  1.7324,  1.7549,
          1.7759,  1.7777,  1.7298,  1.5810,  1.7665,  1.5753,  1.6244,  1.6199,
          1.6134,  1.5269,  1.6189,  1.5471,  1.6103,  1.6114],
        [ 1.2914,  1.2942,  1.2976,  1.2960,  1.2940,  1.2919,  1.2920,  1.2911,
          1.2911,  1.3553,  1.3580,  1.3571,  1.3601,  1.3546,  1.3240,  1.3560,
          1.3198,  1.3406,  2.5034,  2.5238,  2.5759,  2.5138,  2.4433,  2.4427,
          2.5091,  2.4351,  2.4351,  1.3148,  1.3176,  1.3289,  1.3319,  1.3153,
          1.3304,  1.3332,  1.3288,  1.3292,  1.7446,  1.7559,  1.7486,  1.7190,
          1.7530,  1.7531,  1.7461,  1.7229,  1.7184,  1.6171,  1.6004,  1.5962,
          1.5901,  1.5911,  1.5952,  1.6124,  1.5871,  1.5882],
        [ 1.3038,  1.3068,  1.3097,  1.3080,  1.3066,  1.3044,  1.3048,  1.3036,
          1.3036,  1.3675,  1.3698,  1.3694,  1.3548,  1.3667,  1.2715,  1.3682,
          1.3650,  1.2686,  1.3230,  1.3065,  1.3246,  1.3241,  1.3205,  1.3198,
          1.3218,  1.3191,  1.3191,  2.6483,  2.5987,  2.3552,  2.4666,  2.6461,
          2.3639,  2.5819,  2.3967,  2.3569,  1.7534,  1.7650,  1.7334,  1.7530,
          1.7621,  1.7620,  1.7311,  1.6812,  1.7523,  1.6285,  1.6098,  1.5017,
          1.5450,  1.6241,  1.6041,  1.6401,  1.5419,  1.5975],
        [ 1.8543,  1.4523,  0.6185,  0.9367,  1.3395,  1.7772,  1.6552,  1.8832,
          1.8832,  1.7407,  1.3369,  1.5356,  0.9290,  1.7626,  0.1410,  1.6617,
          1.8862,  0.8975,  1.3531,  0.9766,  0.7435,  1.1747,  1.7177,  1.7852,
          1.5331,  1.8908,  1.8908,  0.8440,  0.8826,  1.8633,  1.6589,  0.8747,
          1.8040,  1.2736,  1.9124,  1.8276, -0.0235, -0.2814, -0.3182, -0.0600,
          0.2070,  0.3111, -0.1573, 12.1571,  6.0678,  0.2096,  0.5815,  0.6184,
          0.7206,  0.3712,  0.7188, -0.0836,  0.7484,  0.8160],
        [ 1.3336,  1.3718,  1.4172,  1.4045,  1.3794,  1.3416,  1.3118,  1.3306,
          1.3306,  1.2954,  1.4219,  1.3205,  1.4525,  1.3752,  1.4780,  1.3051,
          1.3585,  1.3624,  1.3903,  1.3930,  1.4253,  1.4034,  1.3570,  1.3497,
          1.2732,  1.3384,  1.3384,  1.3933,  1.4347,  1.3529,  1.1611,  1.3491,
          1.2422,  1.4087,  1.2312,  1.3571,  0.3415,  0.2659,  0.3857,  0.3481,
          0.1467,  0.1009,  0.3652,  0.1560, -0.0522,  3.0206,  2.1843,  2.9969,
          2.4607,  1.7869,  1.4040,  2.6948,  2.7827,  1.3686]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 193 : 175.8023207247605
Test loss for epoch 193 : 175.67741155115507
Test Precision for epoch 193 : 0.26153846153846155
Test Recall for epoch 193 : 0.26153846153846155
Test F1 for epoch 193 : 0.26153846153846155


theta for epoch 194 : tensor([[ 2.4350,  2.4540,  2.4904,  2.5793,  2.5610,  2.4388,  2.5477,  2.4339,
          2.4339,  1.3509,  1.3536,  1.3527,  1.3559,  1.3502,  1.3579,  1.3516,
          1.3490,  1.3111,  1.3061,  1.2644,  1.2651,  1.3071,  1.3036,  1.3031,
          1.3055,  1.3023,  1.3023,  1.2866,  1.3305,  1.3244,  1.3274,  1.3307,
          1.3259,  1.3286,  1.2809,  1.3247,  1.7425,  1.7535,  1.7465,  1.7429,
          1.7508,  1.6911,  1.7440,  1.7300,  1.7422,  1.6142,  1.5967,  1.5925,
          1.5866,  1.6101,  1.5916,  1.6253,  1.5837,  1.5847],
        [ 1.3131,  1.3144,  1.2270,  1.2649,  1.3253,  1.3224,  1.3156,  1.3216,
          1.3216,  2.4460,  2.3654,  2.2873,  2.4561,  2.3271,  2.8986,  2.4017,
          2.3851,  2.8708,  1.3012,  1.3138,  1.2660,  1.2743,  1.3381,  1.3376,
          1.3110,  1.3367,  1.3367,  1.3361,  1.2337,  1.3589,  1.3620,  1.2730,
          1.3604,  1.3633,  1.3313,  1.3592,  1.7668,  1.7795,  1.7324,  1.7553,
          1.7759,  1.7777,  1.7298,  1.5836,  1.7664,  1.5745,  1.6232,  1.6187,
          1.6122,  1.5263,  1.6177,  1.5465,  1.6091,  1.6102],
        [ 1.2911,  1.2939,  1.2973,  1.2957,  1.2938,  1.2917,  1.2918,  1.2909,
          1.2909,  1.3551,  1.3579,  1.3570,  1.3600,  1.3544,  1.3237,  1.3558,
          1.3192,  1.3406,  2.5059,  2.5272,  2.5791,  2.5162,  2.4461,  2.4453,
          2.5123,  2.4379,  2.4379,  1.3142,  1.3174,  1.3287,  1.3317,  1.3147,
          1.3301,  1.3329,  1.3286,  1.3290,  1.7447,  1.7560,  1.7487,  1.7187,
          1.7532,  1.7532,  1.7463,  1.7233,  1.7180,  1.6162,  1.5994,  1.5952,
          1.5891,  1.5903,  1.5942,  1.6114,  1.5861,  1.5872],
        [ 1.3036,  1.3065,  1.3094,  1.3078,  1.3063,  1.3042,  1.3045,  1.3033,
          1.3033,  1.3673,  1.3696,  1.3692,  1.3546,  1.3666,  1.2714,  1.3680,
          1.3648,  1.2685,  1.3229,  1.3063,  1.3245,  1.3239,  1.3203,  1.3197,
          1.3217,  1.3189,  1.3189,  2.6513,  2.6017,  2.3578,  2.4692,  2.6492,
          2.3665,  2.5848,  2.3995,  2.3595,  1.7535,  1.7651,  1.7335,  1.7531,
          1.7622,  1.7622,  1.7311,  1.6815,  1.7524,  1.6275,  1.6089,  1.5009,
          1.5440,  1.6231,  1.6031,  1.6391,  1.5410,  1.5965],
        [ 1.8536,  1.4512,  0.6169,  0.9355,  1.3387,  1.7767,  1.6544,  1.8828,
          1.8828,  1.7392,  1.3356,  1.5344,  0.9276,  1.7612,  0.1391,  1.6604,
          1.8859,  0.8950,  1.3519,  0.9759,  0.7423,  1.1732,  1.7170,  1.7845,
          1.5325,  1.8902,  1.8902,  0.8429,  0.8806,  1.8625,  1.6582,  0.8732,
          1.8031,  1.2724,  1.9116,  1.8267, -0.0236, -0.2813, -0.3182, -0.0601,
          0.2066,  0.3104, -0.1572, 12.2089,  6.0573,  0.2079,  0.5797,  0.6165,
          0.7187,  0.3692,  0.7169, -0.0853,  0.7467,  0.8141],
        [ 1.3356,  1.3737,  1.4191,  1.4064,  1.3813,  1.3435,  1.3138,  1.3325,
          1.3325,  1.2980,  1.4244,  1.3231,  1.4550,  1.3778,  1.4805,  1.3077,
          1.3610,  1.3650,  1.3928,  1.3951,  1.4278,  1.4059,  1.3596,  1.3523,
          1.2754,  1.3409,  1.3409,  1.3953,  1.4366,  1.3550,  1.1629,  1.3511,
          1.2443,  1.4107,  1.2334,  1.3591,  0.3439,  0.2683,  0.3880,  0.3505,
          0.1491,  0.1033,  0.3676,  0.1583, -0.0499,  3.0228,  2.1836,  2.9997,
          2.4606,  1.7854,  1.4020,  2.6947,  2.7857,  1.3666]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 194 : 175.79273644741906
Test loss for epoch 194 : 175.6740737926116
Test Precision for epoch 194 : 0.26153846153846155
Test Recall for epoch 194 : 0.26153846153846155
Test F1 for epoch 194 : 0.26153846153846155


theta for epoch 195 : tensor([[ 2.4376,  2.4565,  2.4929,  2.5821,  2.5638,  2.4413,  2.5505,  2.4364,
          2.4364,  1.3506,  1.3533,  1.3524,  1.3556,  1.3499,  1.3576,  1.3513,
          1.3487,  1.3108,  1.3055,  1.2638,  1.2646,  1.3065,  1.3031,  1.3026,
          1.3049,  1.3017,  1.3017,  1.2863,  1.3302,  1.3241,  1.3271,  1.3304,
          1.3256,  1.3283,  1.2806,  1.3244,  1.7421,  1.7532,  1.7461,  1.7426,
          1.7505,  1.6907,  1.7436,  1.7296,  1.7418,  1.6150,  1.5974,  1.5933,
          1.5873,  1.6108,  1.5924,  1.6261,  1.5845,  1.5855],
        [ 1.3129,  1.3142,  1.2278,  1.2649,  1.3248,  1.3218,  1.3153,  1.3210,
          1.3210,  2.4490,  2.3692,  2.2903,  2.4597,  2.3298,  2.8987,  2.4046,
          2.3898,  2.8708,  1.3007,  1.3131,  1.2653,  1.2743,  1.3373,  1.3368,
          1.3107,  1.3359,  1.3359,  1.3357,  1.2344,  1.3583,  1.3614,  1.2731,
          1.3599,  1.3628,  1.3308,  1.3586,  1.7662,  1.7789,  1.7319,  1.7551,
          1.7753,  1.7771,  1.7292,  1.5857,  1.7658,  1.5757,  1.6238,  1.6193,
          1.6128,  1.5277,  1.6183,  1.5477,  1.6098,  1.6109],
        [ 1.2908,  1.2936,  1.2970,  1.2954,  1.2935,  1.2914,  1.2915,  1.2905,
          1.2905,  1.3549,  1.3576,  1.3567,  1.3597,  1.3542,  1.3231,  1.3556,
          1.3185,  1.3405,  2.5080,  2.5302,  2.5820,  2.5182,  2.4484,  2.4475,
          2.5150,  2.4402,  2.4402,  1.3135,  1.3172,  1.3284,  1.3314,  1.3140,
          1.3298,  1.3326,  1.3283,  1.3287,  1.7444,  1.7556,  1.7484,  1.7178,
          1.7528,  1.7529,  1.7459,  1.7232,  1.7172,  1.6170,  1.6002,  1.5960,
          1.5899,  1.5912,  1.5951,  1.6122,  1.5869,  1.5880],
        [ 1.3032,  1.3061,  1.3091,  1.3074,  1.3060,  1.3038,  1.3041,  1.3030,
          1.3030,  1.3670,  1.3693,  1.3688,  1.3542,  1.3663,  1.2711,  1.3677,
          1.3645,  1.2683,  1.3224,  1.3057,  1.3239,  1.3234,  1.3198,  1.3191,
          1.3211,  1.3184,  1.3184,  2.6542,  2.6044,  2.3602,  2.4717,  2.6521,
          2.3689,  2.5874,  2.4021,  2.3619,  1.7531,  1.7647,  1.7330,  1.7527,
          1.7618,  1.7618,  1.7307,  1.6813,  1.7520,  1.6282,  1.6096,  1.5018,
          1.5448,  1.6239,  1.6039,  1.6398,  1.5417,  1.5973],
        [ 1.8555,  1.4538,  0.6197,  0.9383,  1.3416,  1.7790,  1.6567,  1.8850,
          1.8850,  1.7412,  1.3387,  1.5370,  0.9309,  1.7633,  0.1425,  1.6626,
          1.8887,  0.8978,  1.3547,  0.9795,  0.7460,  1.1759,  1.7197,  1.7870,
          1.5353,  1.8927,  1.8927,  0.8465,  0.8835,  1.8652,  1.6613,  0.8767,
          1.8059,  1.2755,  1.9142,  1.8295, -0.0276, -0.2850, -0.3219, -0.0640,
          0.2020,  0.3057, -0.1610, 12.2564,  6.0416,  0.2119,  0.5835,  0.6203,
          0.7225,  0.3730,  0.7208, -0.0812,  0.7506,  0.8179],
        [ 1.3331,  1.3713,  1.4166,  1.4039,  1.3788,  1.3410,  1.3113,  1.3300,
          1.3300,  1.2950,  1.4214,  1.3200,  1.4520,  1.3749,  1.4774,  1.3046,
          1.3579,  1.3620,  1.3896,  1.3914,  1.4246,  1.4028,  1.3563,  1.3491,
          1.2716,  1.3377,  1.3377,  1.3927,  1.4341,  1.3524,  1.1598,  1.3485,
          1.2416,  1.4081,  1.2306,  1.3566,  0.3407,  0.2651,  0.3847,  0.3473,
          0.1457,  0.0999,  0.3645,  0.1547, -0.0536,  3.0313,  2.1893,  3.0088,
          2.4670,  1.7901,  1.4064,  2.7008,  2.7951,  1.3710]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 195 : 175.7847074538838
Test loss for epoch 195 : 175.663447840449
Test Precision for epoch 195 : 0.26153846153846155
Test Recall for epoch 195 : 0.26153846153846155
Test F1 for epoch 195 : 0.26153846153846155


theta for epoch 196 : tensor([[ 2.4403,  2.4592,  2.4956,  2.5850,  2.5668,  2.4440,  2.5535,  2.4391,
          2.4391,  1.3505,  1.3532,  1.3523,  1.3554,  1.3498,  1.3575,  1.3512,
          1.3486,  1.3107,  1.3056,  1.2639,  1.2646,  1.3066,  1.3031,  1.3026,
          1.3049,  1.3018,  1.3018,  1.2860,  1.3300,  1.3238,  1.3268,  1.3301,
          1.3253,  1.3280,  1.2803,  1.3241,  1.7425,  1.7535,  1.7464,  1.7429,
          1.7508,  1.6911,  1.7440,  1.7299,  1.7422,  1.6133,  1.5957,  1.5916,
          1.5856,  1.6092,  1.5907,  1.6244,  1.5828,  1.5838],
        [ 1.3128,  1.3142,  1.2287,  1.2650,  1.3243,  1.3214,  1.3151,  1.3205,
          1.3205,  2.4520,  2.3731,  2.2935,  2.4633,  2.3325,  2.8989,  2.4075,
          2.3946,  2.8709,  1.3010,  1.3131,  1.2653,  1.2751,  1.3372,  1.3368,
          1.3112,  1.3359,  1.3359,  1.3353,  1.2353,  1.3579,  1.3610,  1.2733,
          1.3595,  1.3624,  1.3305,  1.3582,  1.7664,  1.7790,  1.7321,  1.7557,
          1.7755,  1.7773,  1.7294,  1.5885,  1.7659,  1.5741,  1.6219,  1.6174,
          1.6109,  1.5264,  1.6164,  1.5463,  1.6078,  1.6089],
        [ 1.2905,  1.2934,  1.2967,  1.2951,  1.2932,  1.2911,  1.2912,  1.2903,
          1.2903,  1.3548,  1.3575,  1.3566,  1.3596,  1.3541,  1.3227,  1.3555,
          1.3181,  1.3406,  2.5106,  2.5338,  2.5854,  2.5208,  2.4512,  2.4503,
          2.5184,  2.4430,  2.4430,  1.3129,  1.3170,  1.3281,  1.3311,  1.3134,
          1.3296,  1.3324,  1.3280,  1.3284,  1.7447,  1.7560,  1.7487,  1.7177,
          1.7532,  1.7532,  1.7462,  1.7238,  1.7171,  1.6153,  1.5986,  1.5944,
          1.5883,  1.5897,  1.5934,  1.6105,  1.5853,  1.5864],
        [ 1.3030,  1.3059,  1.3088,  1.3072,  1.3057,  1.3036,  1.3039,  1.3027,
          1.3027,  1.3669,  1.3693,  1.3688,  1.3541,  1.3662,  1.2711,  1.3676,
          1.3644,  1.2683,  1.3224,  1.3057,  1.3239,  1.3234,  1.3199,  1.3192,
          1.3211,  1.3185,  1.3185,  2.6572,  2.6073,  2.3627,  2.4742,  2.6551,
          2.3714,  2.5902,  2.4048,  2.3645,  1.7535,  1.7651,  1.7334,  1.7531,
          1.7622,  1.7622,  1.7310,  1.6818,  1.7523,  1.6266,  1.6080,  1.5003,
          1.5432,  1.6223,  1.6023,  1.6382,  1.5401,  1.5957],
        [ 1.8538,  1.4514,  0.6164,  0.9357,  1.3394,  1.7774,  1.6547,  1.8835,
          1.8835,  1.7384,  1.3358,  1.5345,  0.9279,  1.7606,  0.1387,  1.6599,
          1.8873,  0.8935,  1.3521,  0.9773,  0.7431,  1.1729,  1.7177,  1.7851,
          1.5334,  1.8910,  1.8910,  0.8437,  0.8798,  1.8631,  1.6592,  0.8735,
          1.8037,  1.2728,  1.9122,  1.8273, -0.0261, -0.2834, -0.3206, -0.0626,
          0.2031,  0.3065, -0.1596, 12.3096,  6.0323,  0.2081,  0.5797,  0.6164,
          0.7186,  0.3689,  0.7169, -0.0850,  0.7468,  0.8140],
        [ 1.3366,  1.3747,  1.4200,  1.4073,  1.3823,  1.3445,  1.3148,  1.3336,
          1.3336,  1.2996,  1.4258,  1.3246,  1.4565,  1.3795,  1.4820,  1.3093,
          1.3624,  1.3666,  1.3942,  1.3956,  1.4291,  1.4074,  1.3610,  1.3537,
          1.2760,  1.3423,  1.3423,  1.3963,  1.4377,  1.3561,  1.1634,  1.3522,
          1.2454,  1.4118,  1.2345,  1.3603,  0.3452,  0.2696,  0.3890,  0.3518,
          0.1502,  0.1044,  0.3689,  0.1591, -0.0492,  3.0311,  2.1863,  3.0092,
          2.4646,  1.7863,  1.4020,  2.6984,  2.7957,  1.3666]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 196 : 175.78006222552133
Test loss for epoch 196 : 175.66831675389514
Test Precision for epoch 196 : 0.26153846153846155
Test Recall for epoch 196 : 0.26153846153846155
Test F1 for epoch 196 : 0.26153846153846155


theta for epoch 197 : tensor([[ 2.4427,  2.4616,  2.4981,  2.5877,  2.5695,  2.4464,  2.5562,  2.4415,
          2.4415,  1.3501,  1.3528,  1.3519,  1.3551,  1.3494,  1.3571,  1.3508,
          1.3482,  1.3103,  1.3048,  1.2631,  1.2638,  1.3058,  1.3024,  1.3019,
          1.3042,  1.3010,  1.3010,  1.2857,  1.3297,  1.3236,  1.3266,  1.3299,
          1.3251,  1.3277,  1.2801,  1.3239,  1.7418,  1.7529,  1.7458,  1.7423,
          1.7502,  1.6904,  1.7433,  1.7293,  1.7415,  1.6148,  1.5973,  1.5932,
          1.5873,  1.6107,  1.5923,  1.6259,  1.5844,  1.5854],
        [ 1.3125,  1.3139,  1.2295,  1.2649,  1.3237,  1.3208,  1.3148,  1.3199,
          1.3199,  2.4549,  2.3769,  2.2965,  2.4669,  2.3351,  2.8990,  2.4104,
          2.3992,  2.8709,  1.3002,  1.3121,  1.2643,  1.2748,  1.3361,  1.3357,
          1.3106,  1.3348,  1.3348,  1.3349,  1.2361,  1.3574,  1.3605,  1.2734,
          1.3590,  1.3619,  1.3300,  1.3577,  1.7656,  1.7782,  1.7313,  1.7552,
          1.7747,  1.7764,  1.7286,  1.5903,  1.7650,  1.5761,  1.6234,  1.6189,
          1.6124,  1.5285,  1.6179,  1.5483,  1.6093,  1.6104],
        [ 1.2902,  1.2930,  1.2964,  1.2948,  1.2929,  1.2908,  1.2909,  1.2900,
          1.2900,  1.3544,  1.3572,  1.3563,  1.3593,  1.3537,  1.3221,  1.3551,
          1.3173,  1.3403,  2.5124,  2.5366,  2.5880,  2.5226,  2.4532,  2.4522,
          2.5209,  2.4450,  2.4450,  1.3124,  1.3169,  1.3279,  1.3309,  1.3129,
          1.3294,  1.3322,  1.3278,  1.3282,  1.7441,  1.7554,  1.7481,  1.7166,
          1.7526,  1.7526,  1.7456,  1.7235,  1.7159,  1.6170,  1.6002,  1.5960,
          1.5899,  1.5915,  1.5951,  1.6120,  1.5869,  1.5880],
        [ 1.3026,  1.3055,  1.3085,  1.3069,  1.3054,  1.3032,  1.3036,  1.3024,
          1.3024,  1.3665,  1.3689,  1.3684,  1.3537,  1.3658,  1.2708,  1.3673,
          1.3640,  1.2681,  1.3217,  1.3049,  1.3232,  1.3227,  1.3191,  1.3185,
          1.3204,  1.3177,  1.3177,  2.6600,  2.6099,  2.3650,  2.4765,  2.6579,
          2.3737,  2.5927,  2.4073,  2.3667,  1.7528,  1.7644,  1.7326,  1.7524,
          1.7616,  1.7615,  1.7302,  1.6813,  1.7517,  1.6281,  1.6095,  1.5020,
          1.5447,  1.6238,  1.6038,  1.6397,  1.5416,  1.5972],
        [ 1.8572,  1.4558,  0.6215,  0.9405,  1.3441,  1.7812,  1.6586,  1.8871,
          1.8871,  1.7422,  1.3411,  1.5390,  0.9336,  1.7645,  0.1447,  1.6640,
          1.8917,  0.8989,  1.3569,  0.9831,  0.7492,  1.1778,  1.7221,  1.7893,
          1.5380,  1.8950,  1.8950,  0.8498,  0.8851,  1.8676,  1.6643,  0.8795,
          1.8084,  1.2782,  1.9166,  1.8319, -0.0321, -0.2890, -0.3262, -0.0686,
          0.1965,  0.2998, -0.1653, 12.3549,  6.0134,  0.2151,  0.5864,  0.6231,
          0.7254,  0.3757,  0.7237, -0.0780,  0.7536,  0.8208],
        [ 1.3319,  1.3700,  1.4153,  1.4026,  1.3776,  1.3398,  1.3100,  1.3288,
          1.3288,  1.2937,  1.4200,  1.3186,  1.4505,  1.3737,  1.4760,  1.3033,
          1.3563,  1.3607,  1.3881,  1.3889,  1.4230,  1.4012,  1.3548,  1.3475,
          1.2692,  1.3361,  1.3361,  1.3914,  1.4330,  1.3512,  1.1577,  1.3472,
          1.2404,  1.4069,  1.2294,  1.3554,  0.3391,  0.2635,  0.3828,  0.3457,
          0.1439,  0.0981,  0.3629,  0.1525, -0.0559,  3.0429,  2.1952,  3.0216,
          2.4741,  1.7942,  1.4096,  2.7077,  2.8084,  1.3742]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 197 : 175.7811733839689
Test loss for epoch 197 : 175.66229977000376
Test Precision for epoch 197 : 0.26153846153846155
Test Recall for epoch 197 : 0.26153846153846155
Test F1 for epoch 197 : 0.26153846153846155


theta for epoch 198 : tensor([[ 2.4455,  2.4644,  2.5008,  2.5908,  2.5725,  2.4491,  2.5592,  2.4442,
          2.4442,  1.3501,  1.3527,  1.3519,  1.3550,  1.3494,  1.3571,  1.3508,
          1.3482,  1.3103,  1.3052,  1.2635,  1.2642,  1.3062,  1.3028,  1.3023,
          1.3046,  1.3014,  1.3014,  1.2855,  1.3295,  1.3234,  1.3263,  1.3297,
          1.3248,  1.3275,  1.2798,  1.3237,  1.7426,  1.7536,  1.7465,  1.7430,
          1.7509,  1.6911,  1.7440,  1.7300,  1.7422,  1.6118,  1.5943,  1.5902,
          1.5842,  1.6077,  1.5892,  1.6229,  1.5813,  1.5823],
        [ 1.3124,  1.3139,  1.2305,  1.2651,  1.3234,  1.3204,  1.3147,  1.3196,
          1.3196,  2.4580,  2.3808,  2.2998,  2.4706,  2.3380,  2.8992,  2.4135,
          2.4041,  2.8711,  1.3009,  1.3125,  1.2648,  1.2759,  1.3365,  1.3360,
          1.3114,  1.3351,  1.3351,  1.3346,  1.2370,  1.3570,  1.3601,  1.2737,
          1.3586,  1.3615,  1.3297,  1.3573,  1.7661,  1.7787,  1.7319,  1.7562,
          1.7752,  1.7769,  1.7292,  1.5934,  1.7655,  1.5730,  1.6199,  1.6154,
          1.6090,  1.5257,  1.6145,  1.5454,  1.6059,  1.6070],
        [ 1.2900,  1.2928,  1.2962,  1.2946,  1.2927,  1.2906,  1.2907,  1.2898,
          1.2898,  1.3545,  1.3572,  1.3563,  1.3593,  1.3538,  1.3218,  1.3552,
          1.3169,  1.3405,  2.5153,  2.5405,  2.5917,  2.5254,  2.4563,  2.4553,
          2.5245,  2.4481,  2.4481,  1.3118,  1.3168,  1.3277,  1.3307,  1.3123,
          1.3292,  1.3319,  1.3276,  1.3280,  1.7448,  1.7561,  1.7489,  1.7168,
          1.7533,  1.7534,  1.7463,  1.7244,  1.7161,  1.6140,  1.5972,  1.5930,
          1.5869,  1.5886,  1.5920,  1.6090,  1.5839,  1.5850],
        [ 1.3024,  1.3053,  1.3083,  1.3067,  1.3052,  1.3030,  1.3034,  1.3022,
          1.3022,  1.3666,  1.3690,  1.3685,  1.3537,  1.3659,  1.2710,  1.3673,
          1.3640,  1.2682,  1.3221,  1.3053,  1.3236,  1.3231,  1.3196,  1.3189,
          1.3208,  1.3181,  1.3181,  2.6631,  2.6128,  2.3677,  2.4792,  2.6610,
          2.3763,  2.5955,  2.4101,  2.3694,  1.7536,  1.7652,  1.7334,  1.7532,
          1.7624,  1.7623,  1.7309,  1.6823,  1.7524,  1.6252,  1.6066,  1.4992,
          1.5418,  1.6209,  1.6010,  1.6368,  1.5387,  1.5943],
        [ 1.8534,  1.4509,  0.6151,  0.9351,  1.3393,  1.7775,  1.6543,  1.8837,
          1.8837,  1.7369,  1.3352,  1.5338,  0.9272,  1.7593,  0.1373,  1.6587,
          1.8880,  0.8909,  1.3514,  0.9778,  0.7430,  1.1716,  1.7176,  1.7850,
          1.5336,  1.8910,  1.8910,  0.8437,  0.8780,  1.8631,  1.6596,  0.8727,
          1.8036,  1.2724,  1.9122,  1.8272, -0.0278, -0.2847, -0.3221, -0.0643,
          0.2005,  0.3036, -0.1610, 12.4108,  6.0072,  0.2072,  0.5787,  0.6152,
          0.7175,  0.3676,  0.7158, -0.0859,  0.7459,  0.8130],
        [ 1.3387,  1.3767,  1.4219,  1.4092,  1.3842,  1.3465,  1.3169,  1.3356,
          1.3356,  1.3025,  1.4284,  1.3273,  1.4591,  1.3823,  1.4846,  1.3121,
          1.3649,  1.3694,  1.3969,  1.3975,  1.4317,  1.4100,  1.3636,  1.3564,
          1.2780,  1.3450,  1.3450,  1.3984,  1.4399,  1.3583,  1.1650,  1.3543,
          1.2477,  1.4139,  1.2368,  1.3625,  0.3478,  0.2722,  0.3913,  0.3543,
          0.1526,  0.1068,  0.3714,  0.1612, -0.0472,  3.0381,  2.1875,  3.0172,
          2.4670,  1.7857,  1.4006,  2.7006,  2.8042,  1.3652]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 198 : 175.79494153781928
Test loss for epoch 198 : 175.69200729637004
Test Precision for epoch 198 : 0.26153846153846155
Test Recall for epoch 198 : 0.26153846153846155
Test F1 for epoch 198 : 0.26153846153846155


theta for epoch 199 : tensor([[ 2.4478,  2.4668,  2.5032,  2.5934,  2.5751,  2.4515,  2.5619,  2.4466,
          2.4466,  1.3495,  1.3522,  1.3513,  1.3545,  1.3488,  1.3565,  1.3502,
          1.3476,  1.3097,  1.3040,  1.2623,  1.2630,  1.3050,  1.3016,  1.3010,
          1.3034,  1.3002,  1.3002,  1.2852,  1.3292,  1.3231,  1.3260,  1.3294,
          1.3245,  1.3272,  1.2795,  1.3234,  1.7413,  1.7524,  1.7453,  1.7417,
          1.7497,  1.6899,  1.7428,  1.7287,  1.7410,  1.6150,  1.5976,  1.5935,
          1.5875,  1.6110,  1.5925,  1.6261,  1.5846,  1.5856],
        [ 1.3120,  1.3135,  1.2312,  1.2649,  1.3226,  1.3197,  1.3142,  1.3188,
          1.3188,  2.4609,  2.3848,  2.3030,  2.4744,  2.3407,  2.8994,  2.4164,
          2.4089,  2.8713,  1.2995,  1.3109,  1.2632,  1.2750,  1.3348,  1.3343,
          1.3102,  1.3334,  1.3334,  1.3340,  1.2377,  1.3564,  1.3595,  1.2737,
          1.3580,  1.3608,  1.3291,  1.3567,  1.7646,  1.7772,  1.7305,  1.7550,
          1.7738,  1.7755,  1.7278,  1.5946,  1.7641,  1.5767,  1.6232,  1.6187,
          1.6122,  1.5295,  1.6177,  1.5491,  1.6091,  1.6102],
        [ 1.2896,  1.2925,  1.2958,  1.2942,  1.2923,  1.2902,  1.2904,  1.2894,
          1.2894,  1.3539,  1.3566,  1.3557,  1.3587,  1.3532,  1.3210,  1.3546,
          1.3158,  1.3400,  2.5169,  2.5430,  2.5941,  2.5269,  2.4580,  2.4569,
          2.5268,  2.4498,  2.4498,  1.3111,  1.3166,  1.3275,  1.3305,  1.3117,
          1.3289,  1.3317,  1.3274,  1.3278,  1.7436,  1.7549,  1.7477,  1.7151,
          1.7521,  1.7522,  1.7451,  1.7234,  1.7145,  1.6173,  1.6005,  1.5963,
          1.5902,  1.5920,  1.5953,  1.6122,  1.5872,  1.5884],
        [ 1.3020,  1.3049,  1.3079,  1.3063,  1.3048,  1.3026,  1.3030,  1.3018,
          1.3018,  1.3660,  1.3684,  1.3678,  1.3530,  1.3652,  1.2704,  1.3667,
          1.3634,  1.2677,  1.3209,  1.3040,  1.3224,  1.3219,  1.3183,  1.3177,
          1.3196,  1.3169,  1.3169,  2.6659,  2.6155,  2.3700,  2.4815,  2.6638,
          2.3787,  2.5981,  2.4126,  2.3717,  1.7523,  1.7639,  1.7320,  1.7518,
          1.7611,  1.7610,  1.7295,  1.6811,  1.7511,  1.6282,  1.6097,  1.5025,
          1.5449,  1.6240,  1.6041,  1.6398,  1.5418,  1.5974],
        [ 1.8596,  1.4589,  0.6246,  0.9439,  1.3477,  1.7843,  1.6614,  1.8900,
          1.8900,  1.7442,  1.3448,  1.5421,  0.9376,  1.7667,  0.1485,  1.6665,
          1.8956,  0.9016,  1.3603,  0.9878,  0.7538,  1.1808,  1.7255,  1.7926,
          1.5418,  1.8981,  1.8981,  0.8544,  0.8881,  1.8711,  1.6684,  0.8836,
          1.8119,  1.2821,  1.9200,  1.8354, -0.0377, -0.2940, -0.3315, -0.0741,
          0.1900,  0.2928, -0.1706, 12.4515,  5.9829,  0.2199,  0.5910,  0.6276,
          0.7300,  0.3801,  0.7283, -0.0732,  0.7584,  0.8254],
        [ 1.3298,  1.3679,  1.4131,  1.4004,  1.3754,  1.3376,  1.3078,  1.3266,
          1.3266,  1.2913,  1.4174,  1.3160,  1.4479,  1.3713,  1.4734,  1.3008,
          1.3537,  1.3583,  1.3853,  1.3853,  1.4202,  1.3985,  1.3520,  1.3448,
          1.2656,  1.3334,  1.3334,  1.3891,  1.4308,  1.3490,  1.1546,  1.3450,
          1.2381,  1.4047,  1.2270,  1.3532,  0.3364,  0.2607,  0.3799,  0.3430,
          0.1408,  0.0950,  0.3602,  0.1492, -0.0595,  3.0557,  2.2023,  3.0355,
          2.4825,  1.7996,  1.4141,  2.7158,  2.8229,  1.3786]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 199 : 175.8236343133153
Test loss for epoch 199 : 175.70492190090036
Test Precision for epoch 199 : 0.26153846153846155
Test Recall for epoch 199 : 0.26153846153846155
Test F1 for epoch 199 : 0.26153846153846155


theta for epoch 200 : tensor([[ 2.4509,  2.4699,  2.5063,  2.5968,  2.5785,  2.4545,  2.5652,  2.4496,
          2.4496,  1.3496,  1.3523,  1.3514,  1.3546,  1.3490,  1.3566,  1.3503,
          1.3477,  1.3098,  1.3049,  1.2632,  1.2639,  1.3059,  1.3025,  1.3019,
          1.3043,  1.3011,  1.3011,  1.2849,  1.3289,  1.3228,  1.3257,  1.3291,
          1.3242,  1.3269,  1.2792,  1.3231,  1.7426,  1.7537,  1.7466,  1.7431,
          1.7510,  1.6912,  1.7441,  1.7300,  1.7423,  1.6096,  1.5921,  1.5880,
          1.5821,  1.6056,  1.5871,  1.6208,  1.5792,  1.5802],
        [ 1.3120,  1.3136,  1.2323,  1.2652,  1.3224,  1.3195,  1.3142,  1.3186,
          1.3186,  2.4640,  2.3890,  2.3066,  2.4784,  2.3437,  2.8998,  2.4197,
          2.4140,  2.8716,  1.3007,  1.3119,  1.2642,  1.2768,  1.3358,  1.3353,
          1.3117,  1.3344,  1.3344,  1.3337,  1.2386,  1.3560,  1.3591,  1.2739,
          1.3576,  1.3605,  1.3287,  1.3563,  1.7658,  1.7783,  1.7317,  1.7565,
          1.7750,  1.7766,  1.7290,  1.5982,  1.7652,  1.5710,  1.6172,  1.6127,
          1.6063,  1.5242,  1.6118,  1.5437,  1.6032,  1.6044],
        [ 1.2895,  1.2923,  1.2957,  1.2941,  1.2922,  1.2901,  1.2902,  1.2893,
          1.2893,  1.3540,  1.3567,  1.3559,  1.3589,  1.3533,  1.3208,  1.3547,
          1.3155,  1.3403,  2.5205,  2.5476,  2.5985,  2.5305,  2.4618,  2.4606,
          2.5312,  2.4536,  2.4536,  1.3104,  1.3164,  1.3272,  1.3301,  1.3110,
          1.3286,  1.3314,  1.3271,  1.3275,  1.7449,  1.7562,  1.7490,  1.7159,
          1.7535,  1.7535,  1.7465,  1.7250,  1.7152,  1.6119,  1.5951,  1.5909,
          1.5848,  1.5868,  1.5899,  1.6068,  1.5818,  1.5829],
        [ 1.3019,  1.3048,  1.3078,  1.3062,  1.3047,  1.3025,  1.3028,  1.3016,
          1.3016,  1.3661,  1.3685,  1.3680,  1.3531,  1.3654,  1.2706,  1.3668,
          1.3635,  1.2679,  1.3217,  1.3048,  1.3232,  1.3228,  1.3192,  1.3185,
          1.3204,  1.3178,  1.3178,  2.6692,  2.6187,  2.3730,  2.4845,  2.6672,
          2.3816,  2.6012,  2.4157,  2.3747,  1.7537,  1.7652,  1.7333,  1.7532,
          1.7625,  1.7624,  1.7309,  1.6827,  1.7525,  1.6231,  1.6045,  1.4975,
          1.5397,  1.6188,  1.5990,  1.6348,  1.5366,  1.5922],
        [ 1.8525,  1.4497,  0.6130,  0.9338,  1.3385,  1.7770,  1.6534,  1.8833,
          1.8833,  1.7345,  1.3337,  1.5324,  0.9257,  1.7572,  0.1350,  1.6568,
          1.8879,  0.8876,  1.3500,  0.9775,  0.7419,  1.1696,  1.7169,  1.7843,
          1.5331,  1.8904,  1.8904,  0.8427,  0.8754,  1.8622,  1.6590,  0.8711,
          1.8026,  1.2711,  1.9113,  1.8263, -0.0285, -0.2851, -0.3228, -0.0650,
          0.1990,  0.3018, -0.1616, 12.5115,  5.9824,  0.2054,  0.5769,  0.6134,
          0.7157,  0.3654,  0.7140, -0.0878,  0.7443,  0.8112],
        [ 1.3422,  1.3801,  1.4252,  1.4126,  1.3875,  1.3499,  1.3203,  1.3390,
          1.3390,  1.3070,  1.4327,  1.3317,  1.4633,  1.3867,  1.4889,  1.3165,
          1.3691,  1.3738,  1.4012,  1.4010,  1.4359,  1.4144,  1.3680,  1.3607,
          1.2817,  1.3494,  1.3494,  1.4019,  1.4433,  1.3619,  1.1681,  1.3578,
          1.2513,  1.4174,  1.2405,  1.3661,  0.3521,  0.2765,  0.3953,  0.3586,
          0.1567,  0.1109,  0.3757,  0.1651, -0.0434,  3.0432,  2.1869,  3.0233,
          2.4677,  1.7835,  1.3975,  2.7011,  2.8108,  1.3621]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 200 : 175.8783140372065
Test loss for epoch 200 : 175.78619941666864
Test Precision for epoch 200 : 0.26153846153846155
Test Recall for epoch 200 : 0.26153846153846155
Test F1 for epoch 200 : 0.26153846153846155


theta for epoch 201 : tensor([[ 2.4532,  2.4722,  2.5086,  2.5994,  2.5811,  2.4569,  2.5679,  2.4520,
          2.4520,  1.3488,  1.3515,  1.3506,  1.3538,  1.3481,  1.3558,  1.3495,
          1.3469,  1.3090,  1.3029,  1.2612,  1.2619,  1.3039,  1.3005,  1.3000,
          1.3023,  1.2991,  1.2991,  1.2845,  1.3285,  1.3224,  1.3253,  1.3287,
          1.3238,  1.3265,  1.2788,  1.3227,  1.7405,  1.7516,  1.7446,  1.7410,
          1.7490,  1.6892,  1.7420,  1.7279,  1.7403,  1.6151,  1.5976,  1.5935,
          1.5875,  1.6110,  1.5926,  1.6261,  1.5847,  1.5857],
        [ 1.3114,  1.3130,  1.2328,  1.2648,  1.3215,  1.3186,  1.3135,  1.3177,
          1.3177,  2.4670,  2.3931,  2.3100,  2.4823,  2.3466,  2.9002,  2.4228,
          2.4189,  2.8720,  1.2984,  1.3094,  1.2617,  1.2750,  1.3332,  1.3327,
          1.3096,  1.3318,  1.3318,  1.3329,  1.2390,  1.3552,  1.3583,  1.2737,
          1.3568,  1.3597,  1.3280,  1.3555,  1.7635,  1.7760,  1.7294,  1.7545,
          1.7727,  1.7743,  1.7266,  1.5985,  1.7629,  1.5770,  1.6229,  1.6184,
          1.6119,  1.5303,  1.6174,  1.5497,  1.6087,  1.6099],
        [ 1.2890,  1.2919,  1.2952,  1.2936,  1.2917,  1.2896,  1.2897,  1.2888,
          1.2888,  1.3532,  1.3559,  1.3550,  1.3581,  1.3525,  1.3197,  1.3539,
          1.3143,  1.3396,  2.5217,  2.5498,  2.6006,  2.5317,  2.4631,  2.4619,
          2.5332,  2.4549,  2.4549,  1.3097,  1.3161,  1.3268,  1.3298,  1.3103,
          1.3283,  1.3310,  1.3267,  1.3271,  1.7428,  1.7541,  1.7469,  1.7133,
          1.7514,  1.7515,  1.7444,  1.7232,  1.7127,  1.6175,  1.6006,  1.5964,
          1.5904,  1.5924,  1.5955,  1.6123,  1.5873,  1.5885],
        [ 1.3013,  1.3042,  1.3072,  1.3056,  1.3041,  1.3019,  1.3022,  1.3010,
          1.3010,  1.3651,  1.3676,  1.3670,  1.3521,  1.3644,  1.2697,  1.3659,
          1.3625,  1.2671,  1.3198,  1.3028,  1.3213,  1.3208,  1.3172,  1.3165,
          1.3184,  1.3158,  1.3158,  2.6722,  2.6215,  2.3754,  2.4869,  2.6701,
          2.3841,  2.6039,  2.4184,  2.3771,  1.7514,  1.7630,  1.7310,  1.7510,
          1.7603,  1.7602,  1.7285,  1.6807,  1.7502,  1.6282,  1.6097,  1.5028,
          1.5449,  1.6239,  1.6041,  1.6398,  1.5417,  1.5974],
        [ 1.8626,  1.4627,  0.6284,  0.9479,  1.3519,  1.7878,  1.6648,  1.8933,
          1.8933,  1.7467,  1.3492,  1.5458,  0.9422,  1.7695,  0.1529,  1.6696,
          1.8999,  0.9051,  1.3644,  0.9932,  0.7590,  1.1846,  1.7294,  1.7963,
          1.5460,  1.9017,  1.9017,  0.8596,  0.8918,  1.8749,  1.6730,  0.8885,
          1.8159,  1.2867,  1.9237,  1.8393, -0.0436, -0.2994, -0.3371, -0.0801,
          0.1831,  0.2856, -0.1762, 12.5454,  5.9516,  0.2256,  0.5966,  0.6332,
          0.7358,  0.3854,  0.7341, -0.0677,  0.7643,  0.8312],
        [ 1.3278,  1.3659,  1.4111,  1.3984,  1.3733,  1.3356,  1.3058,  1.3246,
          1.3246,  1.2893,  1.4153,  1.3139,  1.4457,  1.3694,  1.4711,  1.2988,
          1.3514,  1.3562,  1.3830,  1.3821,  1.4178,  1.3962,  1.3497,  1.3425,
          1.2625,  1.3311,  1.3311,  1.3869,  1.4288,  1.3469,  1.1517,  1.3428,
          1.2360,  1.4026,  1.2249,  1.3511,  0.3343,  0.2584,  0.3775,  0.3409,
          0.1384,  0.0925,  0.3581,  0.1467, -0.0623,  3.0679,  2.2089,  3.0487,
          2.4903,  1.8045,  1.4182,  2.7234,  2.8366,  1.3828]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 201 : 175.90970014351907
Test loss for epoch 201 : 175.79069620572872
Test Precision for epoch 201 : 0.26153846153846155
Test Recall for epoch 201 : 0.26153846153846155
Test F1 for epoch 201 : 0.26153846153846155


theta for epoch 202 : tensor([[ 2.4561,  2.4751,  2.5115,  2.6026,  2.5843,  2.4597,  2.5710,  2.4548,
          2.4548,  1.3491,  1.3517,  1.3509,  1.3540,  1.3484,  1.3561,  1.3498,
          1.3472,  1.3093,  1.3044,  1.2627,  1.2634,  1.3054,  1.3020,  1.3014,
          1.3038,  1.3006,  1.3006,  1.2842,  1.3283,  1.3221,  1.3251,  1.3284,
          1.3236,  1.3263,  1.2785,  1.3224,  1.7425,  1.7535,  1.7465,  1.7429,
          1.7509,  1.6911,  1.7440,  1.7298,  1.7422,  1.6080,  1.5905,  1.5864,
          1.5804,  1.6040,  1.5854,  1.6192,  1.5775,  1.5785],
        [ 1.3116,  1.3133,  1.2341,  1.2653,  1.3215,  1.3185,  1.3137,  1.3177,
          1.3177,  2.4694,  2.3966,  2.3129,  2.4857,  2.3490,  2.9001,  2.4254,
          2.4233,  2.8718,  1.3005,  1.3113,  1.2636,  1.2776,  1.3350,  1.3345,
          1.3120,  1.3336,  1.3336,  1.3328,  1.2401,  1.3550,  1.3581,  1.2741,
          1.3566,  1.3595,  1.3278,  1.3553,  1.7653,  1.7778,  1.7313,  1.7567,
          1.7745,  1.7761,  1.7285,  1.6026,  1.7646,  1.5697,  1.6151,  1.6107,
          1.6043,  1.5233,  1.6097,  1.5426,  1.6011,  1.6023],
        [ 1.2890,  1.2918,  1.2952,  1.2936,  1.2917,  1.2896,  1.2897,  1.2888,
          1.2888,  1.3536,  1.3563,  1.3554,  1.3584,  1.3529,  1.3197,  1.3543,
          1.3142,  1.3400,  2.5251,  2.5542,  2.6049,  2.5350,  2.4667,  2.4654,
          2.5374,  2.4585,  2.4585,  1.3091,  1.3159,  1.3266,  1.3296,  1.3096,
          1.3280,  1.3308,  1.3265,  1.3269,  1.7448,  1.7561,  1.7489,  1.7148,
          1.7534,  1.7535,  1.7463,  1.7253,  1.7141,  1.6105,  1.5935,  1.5894,
          1.5833,  1.5855,  1.5884,  1.6053,  1.5802,  1.5814],
        [ 1.3013,  1.3042,  1.3072,  1.3056,  1.3041,  1.3019,  1.3022,  1.3010,
          1.3010,  1.3655,  1.3679,  1.3674,  1.3524,  1.3648,  1.2702,  1.3662,
          1.3629,  1.2676,  1.3212,  1.3042,  1.3227,  1.3223,  1.3186,  1.3180,
          1.3199,  1.3172,  1.3172,  2.6751,  2.6243,  2.3780,  2.4895,  2.6731,
          2.3867,  2.6066,  2.4211,  2.3797,  1.7535,  1.7651,  1.7330,  1.7530,
          1.7624,  1.7623,  1.7305,  1.6829,  1.7523,  1.6215,  1.6029,  1.4962,
          1.5381,  1.6172,  1.5974,  1.6332,  1.5349,  1.5906],
        [ 1.8528,  1.4503,  0.6131,  0.9344,  1.3394,  1.7777,  1.6538,  1.8839,
          1.8839,  1.7337,  1.3344,  1.5327,  0.9266,  1.7567,  0.1354,  1.6565,
          1.8891,  0.8871,  1.3506,  0.9793,  0.7434,  1.1698,  1.7176,  1.7849,
          1.5342,  1.8910,  1.8910,  0.8441,  0.8753,  1.8628,  1.6602,  0.8721,
          1.8032,  1.2719,  1.9118,  1.8270, -0.0309, -0.2871, -0.3251, -0.0675,
          0.1958,  0.2982, -0.1638, 12.6072,  5.9553,  0.2072,  0.5789,  0.6153,
          0.7179,  0.3669,  0.7161, -0.0863,  0.7467,  0.8135],
        [ 1.3438,  1.3816,  1.4267,  1.4140,  1.3890,  1.3515,  1.3219,  1.3406,
          1.3406,  1.3091,  1.4345,  1.3336,  1.4651,  1.3888,  1.4907,  1.3186,
          1.3709,  1.3758,  1.4031,  1.4020,  1.4377,  1.4162,  1.3698,  1.3626,
          1.2828,  1.3513,  1.3513,  1.4033,  1.4448,  1.3635,  1.1691,  1.3593,
          1.2530,  1.4189,  1.2422,  1.3677,  0.3545,  0.2786,  0.3975,  0.3610,
          0.1587,  0.1129,  0.3781,  0.1671, -0.0417,  3.0510,  2.1892,  3.0319,
          2.4712,  1.7842,  1.3974,  2.7044,  2.8200,  1.3620]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 202 : 175.89766675957955
Test loss for epoch 202 : 175.81193245225734
Test Precision for epoch 202 : 0.26153846153846155
Test Recall for epoch 202 : 0.26153846153846155
Test F1 for epoch 202 : 0.26153846153846155


theta for epoch 203 : tensor([[ 2.4575,  2.4765,  2.5129,  2.6042,  2.5859,  2.4611,  2.5727,  2.4562,
          2.4562,  1.3487,  1.3514,  1.3505,  1.3537,  1.3480,  1.3557,  1.3494,
          1.3468,  1.3090,  1.3029,  1.2612,  1.2619,  1.3039,  1.3004,  1.2999,
          1.3023,  1.2991,  1.2991,  1.2841,  1.3282,  1.3220,  1.3250,  1.3283,
          1.3234,  1.3262,  1.2784,  1.3223,  1.7406,  1.7517,  1.7447,  1.7411,
          1.7492,  1.6893,  1.7421,  1.7280,  1.7404,  1.6138,  1.5963,  1.5922,
          1.5862,  1.6097,  1.5912,  1.6249,  1.5833,  1.5843],
        [ 1.3111,  1.3128,  1.2347,  1.2651,  1.3208,  1.3178,  1.3132,  1.3169,
          1.3169,  2.4710,  2.3995,  2.3151,  2.4885,  2.3506,  2.8995,  2.4273,
          2.4270,  2.8711,  1.2986,  1.3092,  1.2617,  1.2762,  1.3329,  1.3324,
          1.3104,  1.3314,  1.3314,  1.3324,  1.2409,  1.3545,  1.3576,  1.2742,
          1.3561,  1.3590,  1.3273,  1.3548,  1.7632,  1.7757,  1.7292,  1.7549,
          1.7725,  1.7741,  1.7264,  1.6031,  1.7626,  1.5760,  1.6211,  1.6166,
          1.6101,  1.5297,  1.6156,  1.5490,  1.6069,  1.6081],
        [ 1.2887,  1.2915,  1.2949,  1.2933,  1.2914,  1.2893,  1.2894,  1.2885,
          1.2885,  1.3533,  1.3560,  1.3551,  1.3582,  1.3526,  1.3191,  1.3540,
          1.3134,  1.3398,  2.5249,  2.5551,  2.6056,  2.5348,  2.4666,  2.4652,
          2.5380,  2.4584,  2.4584,  1.3087,  1.3160,  1.3265,  1.3295,  1.3092,
          1.3280,  1.3308,  1.3264,  1.3268,  1.7430,  1.7543,  1.7471,  1.7124,
          1.7517,  1.7517,  1.7445,  1.7237,  1.7118,  1.6163,  1.5994,  1.5952,
          1.5891,  1.5914,  1.5942,  1.6111,  1.5860,  1.5872],
        [ 1.3009,  1.3038,  1.3069,  1.3053,  1.3037,  1.3015,  1.3018,  1.3006,
          1.3006,  1.3651,  1.3675,  1.3670,  1.3520,  1.3644,  1.2699,  1.3658,
          1.3624,  1.2673,  1.3197,  1.3027,  1.3212,  1.3208,  1.3171,  1.3165,
          1.3184,  1.3157,  1.3157,  2.6768,  2.6258,  2.3792,  2.4906,  2.6748,
          2.3879,  2.6081,  2.4225,  2.3809,  1.7515,  1.7632,  1.7310,  1.7510,
          1.7605,  1.7604,  1.7285,  1.6812,  1.7504,  1.6269,  1.6084,  1.5018,
          1.5435,  1.6227,  1.6028,  1.6386,  1.5404,  1.5960],
        [ 1.8616,  1.4617,  0.6267,  0.9469,  1.3513,  1.7872,  1.6640,  1.8927,
          1.8927,  1.7444,  1.3480,  1.5446,  0.9412,  1.7675,  0.1511,  1.6678,
          1.8997,  0.9024,  1.3633,  0.9932,  0.7584,  1.1829,  1.7286,  1.7954,
          1.5456,  1.9008,  1.9008,  0.8590,  0.8897,  1.8739,  1.6725,  0.8873,
          1.8149,  1.2857,  1.9227,  1.8383, -0.0444, -0.3000, -0.3379, -0.0810,
          0.1816,  0.2838, -0.1769, 12.6410,  5.9270,  0.2251,  0.5966,  0.6332,
          0.7361,  0.3847,  0.7342, -0.0686,  0.7648,  0.8316],
        [ 1.3305,  1.3684,  1.4135,  1.4008,  1.3758,  1.3382,  1.3084,  1.3272,
          1.3272,  1.2931,  1.4187,  1.3176,  1.4492,  1.3731,  1.4748,  1.3026,
          1.3549,  1.3599,  1.3867,  1.3851,  1.4214,  1.3999,  1.3534,  1.3462,
          1.2656,  1.3348,  1.3348,  1.3895,  1.4314,  1.3497,  1.1541,  1.3455,
          1.2389,  1.4053,  1.2279,  1.3539,  0.3389,  0.2628,  0.3818,  0.3455,
          0.1426,  0.0968,  0.3626,  0.1511, -0.0583,  3.0733,  2.2090,  3.0548,
          2.4916,  1.8031,  1.4160,  2.7245,  2.8433,  1.3806]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 203 : 175.78312953479764
Test loss for epoch 203 : 175.67393139775703
Test Precision for epoch 203 : 0.26153846153846155
Test Recall for epoch 203 : 0.26153846153846155
Test F1 for epoch 203 : 0.26153846153846155


theta for epoch 204 : tensor([[ 2.4583,  2.4772,  2.5137,  2.6053,  2.5870,  2.4619,  2.5737,  2.4569,
          2.4569,  1.3495,  1.3521,  1.3513,  1.3544,  1.3488,  1.3565,  1.3502,
          1.3475,  1.3097,  1.3046,  1.2629,  1.2637,  1.3056,  1.3021,  1.3016,
          1.3039,  1.3007,  1.3007,  1.2846,  1.3286,  1.3224,  1.3254,  1.3288,
          1.3239,  1.3266,  1.2788,  1.3227,  1.7420,  1.7530,  1.7460,  1.7424,
          1.7505,  1.6907,  1.7434,  1.7293,  1.7418,  1.6113,  1.5937,  1.5896,
          1.5836,  1.6072,  1.5886,  1.6224,  1.5806,  1.5817],
        [ 1.3115,  1.3133,  1.2363,  1.2659,  1.3210,  1.3180,  1.3136,  1.3172,
          1.3172,  2.4710,  2.4007,  2.3157,  2.4896,  2.3506,  2.8974,  2.4275,
          2.4289,  2.8688,  1.3006,  1.3110,  1.2635,  1.2787,  1.3345,  1.3340,
          1.3126,  1.3331,  1.3331,  1.3328,  1.2425,  1.3548,  1.3580,  1.2752,
          1.3564,  1.3593,  1.3277,  1.3551,  1.7643,  1.7768,  1.7304,  1.7562,
          1.7736,  1.7752,  1.7276,  1.6065,  1.7637,  1.5735,  1.6181,  1.6137,
          1.6071,  1.5274,  1.6126,  1.5466,  1.6039,  1.6051],
        [ 1.2890,  1.2919,  1.2953,  1.2936,  1.2917,  1.2896,  1.2898,  1.2888,
          1.2888,  1.3540,  1.3567,  1.3558,  1.3589,  1.3532,  1.3195,  1.3547,
          1.3136,  1.3406,  2.5253,  2.5565,  2.6070,  2.5352,  2.4671,  2.4657,
          2.5392,  2.4589,  2.4589,  1.3087,  1.3164,  1.3269,  1.3299,  1.3092,
          1.3283,  1.3311,  1.3268,  1.3272,  1.7443,  1.7556,  1.7484,  1.7131,
          1.7529,  1.7530,  1.7458,  1.7252,  1.7126,  1.6137,  1.5967,  1.5925,
          1.5864,  1.5889,  1.5915,  1.6084,  1.5833,  1.5845],
        [ 1.3012,  1.3041,  1.3072,  1.3056,  1.3040,  1.3018,  1.3022,  1.3010,
          1.3010,  1.3659,  1.3683,  1.3677,  1.3528,  1.3651,  1.2709,  1.3666,
          1.3632,  1.2683,  1.3212,  1.3041,  1.3228,  1.3223,  1.3186,  1.3180,
          1.3199,  1.3172,  1.3172,  2.6776,  2.6263,  2.3794,  2.4908,  2.6755,
          2.3881,  2.6085,  2.4229,  2.3812,  1.7529,  1.7645,  1.7323,  1.7524,
          1.7618,  1.7618,  1.7298,  1.6827,  1.7518,  1.6245,  1.6059,  1.4995,
          1.5410,  1.6202,  1.6003,  1.6362,  1.5378,  1.5935],
        [ 1.8564,  1.4554,  0.6191,  0.9402,  1.3451,  1.7820,  1.6583,  1.8878,
          1.8878,  1.7373,  1.3406,  1.5379,  0.9334,  1.7606,  0.1425,  1.6609,
          1.8941,  0.8933,  1.3563,  0.9866,  0.7509,  1.1754,  1.7225,  1.7895,
          1.5396,  1.8952,  1.8952,  0.8516,  0.8814,  1.8677,  1.6662,  0.8794,
          1.8084,  1.2784,  1.9166,  1.8320, -0.0386, -0.2943, -0.3324, -0.0752,
          0.1872,  0.2893, -0.1711, 12.6943,  5.9220,  0.2169,  0.5889,  0.6255,
          0.7284,  0.3765,  0.7265, -0.0771,  0.7574,  0.8241],
        [ 1.3371,  1.3749,  1.4201,  1.4074,  1.3823,  1.3448,  1.3151,  1.3339,
          1.3339,  1.3014,  1.4267,  1.3257,  1.4572,  1.3811,  1.4830,  1.3107,
          1.3629,  1.3681,  1.3950,  1.3932,  1.4297,  1.4082,  1.3618,  1.3546,
          1.2740,  1.3433,  1.3433,  1.3964,  1.4382,  1.3567,  1.1612,  1.3524,
          1.2460,  1.4121,  1.2351,  1.3608,  0.3480,  0.2718,  0.3907,  0.3546,
          0.1516,  0.1057,  0.3717,  0.1601, -0.0494,  3.0689,  2.2020,  3.0506,
          2.4851,  1.7953,  1.4079,  2.7180,  2.8393,  1.3724]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 204 : 175.68832437622922
Test loss for epoch 204 : 175.59605164633095
Test Precision for epoch 204 : 0.26153846153846155
Test Recall for epoch 204 : 0.26153846153846155
Test F1 for epoch 204 : 0.26153846153846155


theta for epoch 205 : tensor([[ 2.4590,  2.4779,  2.5144,  2.6063,  2.5879,  2.4625,  2.5747,  2.4576,
          2.4576,  1.3503,  1.3530,  1.3521,  1.3553,  1.3496,  1.3574,  1.3510,
          1.3483,  1.3107,  1.3055,  1.2638,  1.2646,  1.3065,  1.3029,  1.3024,
          1.3048,  1.3015,  1.3015,  1.2853,  1.3293,  1.3231,  1.3261,  1.3295,
          1.3246,  1.3273,  1.2796,  1.3234,  1.7421,  1.7532,  1.7461,  1.7425,
          1.7506,  1.6908,  1.7436,  1.7294,  1.7419,  1.6111,  1.5935,  1.5894,
          1.5834,  1.6070,  1.5884,  1.6223,  1.5804,  1.5815],
        [ 1.3119,  1.3137,  1.2377,  1.2666,  1.3212,  1.3182,  1.3140,  1.3173,
          1.3173,  2.4716,  2.4026,  2.3170,  2.4915,  2.3512,  2.8959,  2.4284,
          2.4316,  2.8671,  1.3012,  1.3115,  1.2640,  1.2799,  1.3349,  1.3343,
          1.3135,  1.3334,  1.3334,  1.3333,  1.2441,  1.3551,  1.3583,  1.2762,
          1.3567,  1.3597,  1.3281,  1.3555,  1.7641,  1.7766,  1.7302,  1.7563,
          1.7735,  1.7750,  1.7274,  1.6087,  1.7635,  1.5732,  1.6175,  1.6130,
          1.6065,  1.5273,  1.6120,  1.5465,  1.6033,  1.6045],
        [ 1.2893,  1.2922,  1.2956,  1.2940,  1.2921,  1.2899,  1.2901,  1.2891,
          1.2891,  1.3545,  1.3572,  1.3563,  1.3594,  1.3538,  1.3197,  1.3552,
          1.3137,  1.3413,  2.5257,  2.5579,  2.6083,  2.5355,  2.4676,  2.4661,
          2.5403,  2.4593,  2.4593,  1.3088,  1.3169,  1.3273,  1.3303,  1.3093,
          1.3288,  1.3316,  1.3272,  1.3276,  1.7442,  1.7556,  1.7484,  1.7126,
          1.7530,  1.7530,  1.7457,  1.7253,  1.7120,  1.6133,  1.5962,  1.5920,
          1.5859,  1.5885,  1.5910,  1.6080,  1.5827,  1.5840],
        [ 1.3016,  1.3046,  1.3077,  1.3061,  1.3044,  1.3022,  1.3026,  1.3014,
          1.3014,  1.3666,  1.3691,  1.3685,  1.3535,  1.3659,  1.2719,  1.3673,
          1.3639,  1.2693,  1.3218,  1.3047,  1.3234,  1.3229,  1.3192,  1.3185,
          1.3204,  1.3177,  1.3177,  2.6786,  2.6271,  2.3800,  2.4914,  2.6765,
          2.3887,  2.6093,  2.4237,  2.3817,  1.7529,  1.7646,  1.7323,  1.7524,
          1.7619,  1.7619,  1.7298,  1.6830,  1.7518,  1.6241,  1.6055,  1.4993,
          1.5406,  1.6199,  1.5999,  1.6359,  1.5374,  1.5931],
        [ 1.8560,  1.4550,  0.6184,  0.9398,  1.3448,  1.7818,  1.6579,  1.8876,
          1.8876,  1.7362,  1.3401,  1.5373,  0.9330,  1.7596,  0.1418,  1.6600,
          1.8940,  0.8921,  1.3557,  0.9866,  0.7506,  1.1746,  1.7220,  1.7890,
          1.5393,  1.8947,  1.8947,  0.8515,  0.8806,  1.8674,  1.6661,  0.8790,
          1.8081,  1.2781,  1.9163,  1.8317, -0.0391, -0.2948, -0.3330, -0.0758,
          0.1863,  0.2882, -0.1716, 12.7410,  5.9091,  0.2169,  0.5891,  0.6257,
          0.7287,  0.3764,  0.7268, -0.0773,  0.7578,  0.8244],
        [ 1.3373,  1.3750,  1.4202,  1.4075,  1.3824,  1.3449,  1.3152,  1.3340,
          1.3340,  1.3017,  1.4268,  1.3259,  1.4574,  1.3814,  1.4832,  1.3110,
          1.3631,  1.3683,  1.3951,  1.3929,  1.4298,  1.4083,  1.3619,  1.3547,
          1.2737,  1.3434,  1.3434,  1.3966,  1.4384,  1.3569,  1.1612,  1.3526,
          1.2462,  1.4123,  1.2353,  1.3610,  0.3487,  0.2723,  0.3913,  0.3553,
          0.1520,  0.1062,  0.3723,  0.1606, -0.0491,  3.0731,  2.2036,  3.0552,
          2.4873,  1.7962,  1.4084,  2.7202,  2.8442,  1.3730]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 205 : 175.6837929766896
Test loss for epoch 205 : 175.5952480513731
Test Precision for epoch 205 : 0.26153846153846155
Test Recall for epoch 205 : 0.26153846153846155
Test F1 for epoch 205 : 0.26153846153846155


theta for epoch 206 : tensor([[ 2.4611,  2.4801,  2.5166,  2.6087,  2.5903,  2.4646,  2.5771,  2.4597,
          2.4597,  1.3504,  1.3531,  1.3522,  1.3554,  1.3497,  1.3575,  1.3511,
          1.3484,  1.3107,  1.3045,  1.2629,  1.2637,  1.3056,  1.3020,  1.3015,
          1.3039,  1.3006,  1.3006,  1.2857,  1.3297,  1.3235,  1.3265,  1.3299,
          1.3249,  1.3277,  1.2799,  1.3238,  1.7405,  1.7516,  1.7446,  1.7409,
          1.7491,  1.6893,  1.7420,  1.7279,  1.7404,  1.6128,  1.5952,  1.5911,
          1.5851,  1.6088,  1.5901,  1.6240,  1.5822,  1.5832],
        [ 1.3119,  1.3137,  1.2388,  1.2669,  1.3209,  1.3179,  1.3139,  1.3170,
          1.3170,  2.4746,  2.4070,  2.3208,  2.4958,  2.3543,  2.8966,  2.4318,
          2.4368,  2.8678,  1.2995,  1.3096,  1.2622,  1.2787,  1.3330,  1.3325,
          1.3121,  1.3315,  1.3315,  1.3331,  1.2451,  1.3549,  1.3581,  1.2765,
          1.3565,  1.3595,  1.3279,  1.3552,  1.7622,  1.7747,  1.7283,  1.7547,
          1.7716,  1.7731,  1.7255,  1.6092,  1.7616,  1.5748,  1.6188,  1.6143,
          1.6078,  1.5290,  1.6132,  1.5482,  1.6045,  1.6057],
        [ 1.2893,  1.2922,  1.2956,  1.2940,  1.2920,  1.2899,  1.2901,  1.2891,
          1.2891,  1.3540,  1.3567,  1.3558,  1.3590,  1.3533,  1.3190,  1.3547,
          1.3128,  1.3409,  2.5280,  2.5612,  2.6115,  2.5378,  2.4699,  2.4684,
          2.5434,  2.4617,  2.4617,  1.3084,  1.3170,  1.3273,  1.3304,  1.3090,
          1.3288,  1.3316,  1.3272,  1.3276,  1.7425,  1.7538,  1.7466,  1.7102,
          1.7512,  1.7513,  1.7440,  1.7238,  1.7098,  1.6147,  1.5976,  1.5934,
          1.5873,  1.5900,  1.5924,  1.6093,  1.5841,  1.5853],
        [ 1.3017,  1.3047,  1.3078,  1.3062,  1.3046,  1.3023,  1.3027,  1.3015,
          1.3015,  1.3664,  1.3689,  1.3683,  1.3533,  1.3657,  1.2718,  1.3671,
          1.3636,  1.2692,  1.3206,  1.3034,  1.3221,  1.3217,  1.3180,  1.3173,
          1.3192,  1.3165,  1.3165,  2.6816,  2.6299,  2.3826,  2.4939,  2.6795,
          2.3913,  2.6120,  2.4264,  2.3843,  1.7511,  1.7628,  1.7305,  1.7506,
          1.7602,  1.7602,  1.7279,  1.6814,  1.7501,  1.6256,  1.6070,  1.5010,
          1.5421,  1.6213,  1.6014,  1.6373,  1.5389,  1.5945],
        [ 1.8617,  1.4621,  0.6264,  0.9474,  1.3523,  1.7879,  1.6643,  1.8933,
          1.8933,  1.7425,  1.3483,  1.5445,  0.9417,  1.7661,  0.1509,  1.6668,
          1.9007,  0.9009,  1.3632,  0.9950,  0.7595,  1.1823,  1.7286,  1.7954,
          1.5463,  1.9007,  1.9007,  0.8606,  0.8891,  1.8745,  1.6739,  0.8881,
          1.8155,  1.2865,  1.9232,  1.8390, -0.0475, -0.3027, -0.3409, -0.0843,
          0.1774,  0.2791, -0.1797, 12.7795,  5.8865,  0.2269,  0.5989,  0.6355,
          0.7387,  0.3862,  0.7367, -0.0673,  0.7678,  0.8343],
        [ 1.3307,  1.3685,  1.4137,  1.4010,  1.3759,  1.3383,  1.3086,  1.3274,
          1.3274,  1.2937,  1.4189,  1.3178,  1.4494,  1.3735,  1.4752,  1.3030,
          1.3550,  1.3603,  1.3867,  1.3840,  1.4213,  1.3999,  1.3535,  1.3463,
          1.2647,  1.3349,  1.3349,  1.3897,  1.4317,  1.3501,  1.1535,  1.3458,
          1.2392,  1.4055,  1.2283,  1.3542,  0.3404,  0.2639,  0.3829,  0.3470,
          0.1434,  0.0976,  0.3641,  0.1520, -0.0580,  3.0866,  2.2145,  3.0690,
          2.4988,  1.8063,  1.4181,  2.7314,  2.8584,  1.3827]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 206 : 175.73875469147757
Test loss for epoch 206 : 175.63845344002232
Test Precision for epoch 206 : 0.26153846153846155
Test Recall for epoch 206 : 0.26153846153846155
Test F1 for epoch 206 : 0.26153846153846155


theta for epoch 207 : tensor([[ 2.4649,  2.4839,  2.5204,  2.6128,  2.5944,  2.4685,  2.5812,  2.4636,
          2.4636,  1.3499,  1.3525,  1.3517,  1.3548,  1.3492,  1.3569,  1.3506,
          1.3478,  1.3102,  1.3047,  1.2631,  1.2638,  1.3058,  1.3022,  1.3017,
          1.3041,  1.3008,  1.3008,  1.2852,  1.3292,  1.3230,  1.3260,  1.3294,
          1.3244,  1.3272,  1.2794,  1.3233,  1.7414,  1.7525,  1.7455,  1.7418,
          1.7500,  1.6902,  1.7429,  1.7287,  1.7413,  1.6069,  1.5892,  1.5851,
          1.5791,  1.6028,  1.5841,  1.6181,  1.5761,  1.5772],
        [ 1.3119,  1.3138,  1.2399,  1.2672,  1.3208,  1.3178,  1.3140,  1.3169,
          1.3169,  2.4786,  2.4123,  2.3256,  2.5009,  2.3584,  2.8980,  2.4362,
          2.4428,  2.8693,  1.2998,  1.3097,  1.2623,  1.2795,  1.3331,  1.3326,
          1.3127,  1.3316,  1.3316,  1.3324,  1.2455,  1.3542,  1.3574,  1.2764,
          1.3558,  1.3588,  1.3273,  1.3545,  1.7628,  1.7753,  1.7291,  1.7556,
          1.7723,  1.7738,  1.7262,  1.6121,  1.7622,  1.5684,  1.6121,  1.6076,
          1.6011,  1.5228,  1.6065,  1.5419,  1.5978,  1.5991],
        [ 1.2892,  1.2921,  1.2955,  1.2939,  1.2919,  1.2898,  1.2900,  1.2889,
          1.2889,  1.3531,  1.3558,  1.3549,  1.3580,  1.3524,  1.3177,  1.3538,
          1.3114,  1.3400,  2.5332,  2.5674,  2.6176,  2.5429,  2.4753,  2.4737,
          2.5495,  2.4671,  2.4671,  1.3073,  1.3163,  1.3266,  1.3296,  1.3078,
          1.3281,  1.3309,  1.3265,  1.3269,  1.7432,  1.7546,  1.7474,  1.7105,
          1.7520,  1.7521,  1.7447,  1.7247,  1.7100,  1.6085,  1.5913,  1.5872,
          1.5810,  1.5839,  1.5861,  1.6031,  1.5778,  1.5791],
        [ 1.3017,  1.3047,  1.3078,  1.3062,  1.3046,  1.3023,  1.3027,  1.3015,
          1.3015,  1.3658,  1.3682,  1.3676,  1.3525,  1.3650,  1.2711,  1.3665,
          1.3630,  1.2686,  1.3207,  1.3035,  1.3223,  1.3218,  1.3181,  1.3175,
          1.3193,  1.3167,  1.3167,  2.6858,  2.6340,  2.3865,  2.4978,  2.6838,
          2.3952,  2.6160,  2.4306,  2.3883,  1.7520,  1.7637,  1.7313,  1.7515,
          1.7611,  1.7611,  1.7287,  1.6825,  1.7510,  1.6198,  1.6012,  1.4953,
          1.5362,  1.6156,  1.5956,  1.6316,  1.5330,  1.5887],
        [ 1.8554,  1.4542,  0.6164,  0.9386,  1.3443,  1.7815,  1.6573,  1.8874,
          1.8874,  1.7337,  1.3386,  1.5358,  0.9314,  1.7574,  0.1394,  1.6580,
          1.8937,  0.8889,  1.3541,  0.9859,  0.7493,  1.1725,  1.7208,  1.7878,
          1.5384,  1.8936,  1.8936,  0.8505,  0.8782,  1.8666,  1.6655,  0.8775,
          1.8073,  1.2768,  1.9155,  1.8309, -0.0393, -0.2947, -0.3332, -0.0761,
          0.1854,  0.2871, -0.1717, 12.8348,  5.8837,  0.2148,  0.5870,  0.6235,
          0.7266,  0.3739,  0.7247, -0.0795,  0.7559,  0.8223],
        [ 1.3432,  1.3808,  1.4259,  1.4132,  1.3881,  1.3507,  1.3211,  1.3399,
          1.3399,  1.3084,  1.4332,  1.3325,  1.4637,  1.3880,  1.4897,  1.3177,
          1.3695,  1.3749,  1.4015,  1.3986,  1.4360,  1.4147,  1.3684,  1.3612,
          1.2797,  1.3499,  1.3499,  1.4023,  1.4440,  1.3628,  1.1667,  1.3583,
          1.2521,  1.4180,  1.2414,  1.3669,  0.3550,  0.2786,  0.3973,  0.3617,
          0.1582,  0.1123,  0.3786,  0.1668, -0.0431,  3.0752,  2.2004,  3.0577,
          2.4853,  1.7916,  1.4030,  2.7180,  2.8473,  1.3676]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 207 : 175.7727980699411
Test loss for epoch 207 : 175.69646548392797
Test Precision for epoch 207 : 0.26153846153846155
Test Recall for epoch 207 : 0.26153846153846155
Test F1 for epoch 207 : 0.26153846153846155


theta for epoch 208 : tensor([[ 2.4674,  2.4863,  2.5228,  2.6155,  2.5971,  2.4709,  2.5839,  2.4660,
          2.4660,  1.3484,  1.3510,  1.3502,  1.3533,  1.3477,  1.3554,  1.3491,
          1.3463,  1.3087,  1.3023,  1.2606,  1.2613,  1.3033,  1.2998,  1.2992,
          1.3016,  1.2984,  1.2984,  1.2839,  1.3280,  1.3217,  1.3247,  1.3281,
          1.3232,  1.3260,  1.2781,  1.3220,  1.7398,  1.7510,  1.7439,  1.7402,
          1.7485,  1.6886,  1.7413,  1.7272,  1.7398,  1.6124,  1.5948,  1.5907,
          1.5846,  1.6084,  1.5897,  1.6237,  1.5817,  1.5827],
        [ 1.3108,  1.3127,  1.2398,  1.2664,  1.3194,  1.3164,  1.3128,  1.3156,
          1.3156,  2.4812,  2.4164,  2.3291,  2.5049,  2.3612,  2.8984,  2.4393,
          2.4476,  2.8697,  1.2971,  1.3069,  1.2595,  1.2773,  1.3302,  1.3297,
          1.3104,  1.3288,  1.3288,  1.3309,  1.2451,  1.3527,  1.3558,  1.2754,
          1.3542,  1.3572,  1.3257,  1.3530,  1.7611,  1.7736,  1.7273,  1.7541,
          1.7706,  1.7721,  1.7245,  1.6127,  1.7605,  1.5746,  1.6180,  1.6135,
          1.6069,  1.5290,  1.6124,  1.5481,  1.6037,  1.6048],
        [ 1.2883,  1.2912,  1.2946,  1.2930,  1.2910,  1.2889,  1.2891,  1.2880,
          1.2880,  1.3518,  1.3546,  1.3537,  1.3568,  1.3511,  1.3162,  1.3525,
          1.3097,  1.3388,  2.5343,  2.5695,  2.6197,  2.5440,  2.4764,  2.4748,
          2.5514,  2.4682,  2.4682,  1.3059,  1.3153,  1.3256,  1.3286,  1.3064,
          1.3271,  1.3299,  1.3255,  1.3259,  1.7418,  1.7532,  1.7460,  1.7085,
          1.7506,  1.7507,  1.7433,  1.7235,  1.7081,  1.6144,  1.5972,  1.5930,
          1.5869,  1.5898,  1.5920,  1.6089,  1.5837,  1.5849],
        [ 1.3007,  1.3036,  1.3068,  1.3052,  1.3035,  1.3013,  1.3017,  1.3004,
          1.3004,  1.3642,  1.3667,  1.3661,  1.3510,  1.3635,  1.2697,  1.3649,
          1.3615,  1.2672,  1.3185,  1.3012,  1.3200,  1.3196,  1.3159,  1.3152,
          1.3171,  1.3144,  1.3144,  2.6884,  2.6364,  2.3887,  2.4998,  2.6864,
          2.3974,  2.6184,  2.4329,  2.3904,  1.7504,  1.7621,  1.7296,  1.7499,
          1.7595,  1.7595,  1.7270,  1.6811,  1.7494,  1.6252,  1.6065,  1.5008,
          1.5416,  1.6209,  1.6009,  1.6369,  1.5383,  1.5940],
        [ 1.8633,  1.4642,  0.6282,  0.9495,  1.3547,  1.7899,  1.6662,  1.8952,
          1.8952,  1.7430,  1.3503,  1.5462,  0.9440,  1.7669,  0.1528,  1.6679,
          1.9030,  0.9019,  1.3652,  0.9981,  0.7623,  1.1839,  1.7306,  1.7972,
          1.5485,  1.9025,  1.9025,  0.8632,  0.8903,  1.8762,  1.6760,  0.8904,
          1.8172,  1.2885,  1.9248,  1.8407, -0.0511, -0.3059, -0.3444, -0.0880,
          0.1731,  0.2745, -0.1831, 12.8688,  5.8567,  0.2300,  0.6019,  0.6385,
          0.7417,  0.3890,  0.7398, -0.0644,  0.7710,  0.8374],
        [ 1.3324,  1.3701,  1.4152,  1.4025,  1.3774,  1.3400,  1.3103,  1.3290,
          1.3290,  1.2957,  1.4206,  1.3197,  1.4510,  1.3755,  1.4769,  1.3049,
          1.3568,  1.3622,  1.3885,  1.3851,  1.4231,  1.4018,  1.3554,  1.3482,
          1.2660,  1.3369,  1.3369,  1.3909,  1.4329,  1.3514,  1.1544,  1.3470,
          1.2407,  1.4067,  1.2297,  1.3556,  0.3427,  0.2660,  0.3849,  0.3493,
          0.1454,  0.0995,  0.3663,  0.1540, -0.0562,  3.0935,  2.2163,  3.0765,
          2.5016,  1.8066,  1.4178,  2.7342,  2.8664,  1.3824]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 208 : 175.70975776596921
Test loss for epoch 208 : 175.6142436113827
Test Precision for epoch 208 : 0.26153846153846155
Test Recall for epoch 208 : 0.26153846153846155
Test F1 for epoch 208 : 0.26153846153846155


theta for epoch 209 : tensor([[ 2.4681,  2.4871,  2.5236,  2.6165,  2.5981,  2.4716,  2.5849,  2.4667,
          2.4667,  1.3485,  1.3511,  1.3503,  1.3534,  1.3478,  1.3555,  1.3492,
          1.3464,  1.3088,  1.3035,  1.2618,  1.2625,  1.3045,  1.3009,  1.3004,
          1.3028,  1.2995,  1.2995,  1.2834,  1.3274,  1.3212,  1.3242,  1.3276,
          1.3226,  1.3254,  1.2776,  1.3215,  1.7415,  1.7527,  1.7457,  1.7420,
          1.7502,  1.6904,  1.7430,  1.7289,  1.7415,  1.6112,  1.5935,  1.5894,
          1.5833,  1.6071,  1.5883,  1.6224,  1.5803,  1.5814],
        [ 1.3103,  1.3123,  1.2404,  1.2662,  1.3188,  1.3158,  1.3123,  1.3149,
          1.3149,  2.4806,  2.4172,  2.3294,  2.5058,  2.3608,  2.8961,  2.4392,
          2.4493,  2.8672,  1.2992,  1.3088,  1.2615,  1.2799,  1.3321,  1.3316,
          1.3128,  1.3306,  1.3306,  1.3306,  1.2459,  1.3523,  1.3555,  1.2756,
          1.3539,  1.3568,  1.3254,  1.3526,  1.7627,  1.7752,  1.7291,  1.7560,
          1.7722,  1.7738,  1.7262,  1.6165,  1.7621,  1.5737,  1.6168,  1.6123,
          1.6057,  1.5284,  1.6112,  1.5475,  1.6024,  1.6036],
        [ 1.2878,  1.2907,  1.2941,  1.2925,  1.2906,  1.2884,  1.2886,  1.2876,
          1.2876,  1.3527,  1.3554,  1.3545,  1.3576,  1.3520,  1.3167,  1.3534,
          1.3102,  1.3398,  2.5337,  2.5700,  2.6202,  2.5435,  2.4760,  2.4743,
          2.5517,  2.4677,  2.4677,  1.3054,  1.3153,  1.3254,  1.3285,  1.3060,
          1.3269,  1.3297,  1.3253,  1.3258,  1.7437,  1.7551,  1.7479,  1.7099,
          1.7526,  1.7526,  1.7452,  1.7255,  1.7095,  1.6136,  1.5963,  1.5921,
          1.5860,  1.5891,  1.5911,  1.6081,  1.5828,  1.5840],
        [ 1.3000,  1.3029,  1.3061,  1.3045,  1.3028,  1.3005,  1.3009,  1.2997,
          1.2997,  1.3645,  1.3670,  1.3664,  1.3512,  1.3638,  1.2701,  1.3652,
          1.3617,  1.2676,  1.3199,  1.3025,  1.3214,  1.3209,  1.3172,  1.3166,
          1.3184,  1.3158,  1.3158,  2.6889,  2.6367,  2.3888,  2.4999,  2.6869,
          2.3975,  2.6187,  2.4332,  2.3906,  1.7522,  1.7640,  1.7314,  1.7517,
          1.7614,  1.7614,  1.7288,  1.6832,  1.7512,  1.6241,  1.6054,  1.4999,
          1.5404,  1.6198,  1.5997,  1.6359,  1.5371,  1.5928],
        [ 1.8581,  1.4580,  0.6210,  0.9431,  1.3486,  1.7847,  1.6606,  1.8903,
          1.8903,  1.7366,  1.3436,  1.5401,  0.9371,  1.7606,  0.1452,  1.6616,
          1.8981,  0.8937,  1.3591,  0.9922,  0.7557,  1.1772,  1.7253,  1.7920,
          1.5433,  1.8976,  1.8976,  0.8563,  0.8827,  1.8702,  1.6699,  0.8830,
          1.8110,  1.2817,  1.9189,  1.8346, -0.0459, -0.3008, -0.3395, -0.0828,
          0.1781,  0.2794, -0.1780, 12.9201,  5.8500,  0.2229,  0.5950,  0.6315,
          0.7348,  0.3818,  0.7329, -0.0716,  0.7642,  0.8306],
        [ 1.3376,  1.3752,  1.4202,  1.4076,  1.3825,  1.3451,  1.3155,  1.3342,
          1.3342,  1.3026,  1.4272,  1.3265,  1.4577,  1.3822,  1.4837,  1.3118,
          1.3635,  1.3690,  1.3957,  1.3920,  1.4302,  1.4089,  1.3625,  1.3554,
          1.2731,  1.3440,  1.3440,  1.3964,  1.4384,  1.3570,  1.1601,  1.3525,
          1.2464,  1.4122,  1.2356,  1.3612,  0.3504,  0.2737,  0.3925,  0.3571,
          0.1531,  0.1072,  0.3740,  0.1617, -0.0486,  3.0902,  2.2105,  3.0734,
          2.4964,  1.8001,  1.4110,  2.7289,  2.8636,  1.3755]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 209 : 175.6349085886261
Test loss for epoch 209 : 175.55453094915106
Test Precision for epoch 209 : 0.26153846153846155
Test Recall for epoch 209 : 0.26153846153846155
Test F1 for epoch 209 : 0.26153846153846155


theta for epoch 210 : tensor([[ 2.4686,  2.4876,  2.5241,  2.6173,  2.5989,  2.4721,  2.5857,  2.4672,
          2.4672,  1.3495,  1.3521,  1.3512,  1.3544,  1.3488,  1.3565,  1.3502,
          1.3474,  1.3098,  1.3047,  1.2630,  1.2638,  1.3057,  1.3022,  1.3016,
          1.3040,  1.3008,  1.3008,  1.2839,  1.3280,  1.3217,  1.3247,  1.3281,
          1.3232,  1.3259,  1.2781,  1.3220,  1.7420,  1.7532,  1.7461,  1.7424,
          1.7507,  1.6909,  1.7435,  1.7293,  1.7420,  1.6102,  1.5925,  1.5884,
          1.5823,  1.6061,  1.5873,  1.6215,  1.5793,  1.5804],
        [ 1.3103,  1.3123,  1.2414,  1.2665,  1.3186,  1.3156,  1.3122,  1.3147,
          1.3147,  2.4802,  2.4183,  2.3300,  2.5069,  2.3606,  2.8939,  2.4393,
          2.4510,  2.8649,  1.3011,  1.3105,  1.2632,  1.2823,  1.3337,  1.3331,
          1.3149,  1.3322,  1.3322,  1.3313,  1.2477,  1.3529,  1.3561,  1.2768,
          1.3545,  1.3575,  1.3261,  1.3532,  1.7631,  1.7756,  1.7295,  1.7566,
          1.7726,  1.7742,  1.7266,  1.6190,  1.7625,  1.5731,  1.6159,  1.6113,
          1.6047,  1.5279,  1.6102,  1.5470,  1.6014,  1.6026],
        [ 1.2879,  1.2908,  1.2942,  1.2926,  1.2907,  1.2885,  1.2887,  1.2877,
          1.2877,  1.3544,  1.3571,  1.3562,  1.3593,  1.3536,  1.3180,  1.3550,
          1.3115,  1.3415,  2.5328,  2.5702,  2.6203,  2.5426,  2.4751,  2.4734,
          2.5517,  2.4669,  2.4669,  1.3059,  1.3162,  1.3263,  1.3294,  1.3065,
          1.3278,  1.3306,  1.3262,  1.3266,  1.7443,  1.7557,  1.7485,  1.7100,
          1.7532,  1.7533,  1.7458,  1.7263,  1.7096,  1.6130,  1.5957,  1.5915,
          1.5853,  1.5885,  1.5904,  1.6075,  1.5820,  1.5833],
        [ 1.2997,  1.3027,  1.3059,  1.3043,  1.3026,  1.3003,  1.3007,  1.2995,
          1.2995,  1.3656,  1.3681,  1.3675,  1.3523,  1.3649,  1.2714,  1.3663,
          1.3628,  1.2689,  1.3211,  1.3037,  1.3226,  1.3221,  1.3184,  1.3178,
          1.3196,  1.3170,  1.3170,  2.6898,  2.6374,  2.3893,  2.5003,  2.6878,
          2.3980,  2.6193,  2.4339,  2.3911,  1.7527,  1.7645,  1.7319,  1.7522,
          1.7619,  1.7619,  1.7292,  1.6839,  1.7517,  1.6231,  1.6044,  1.4991,
          1.5394,  1.6188,  1.5988,  1.6349,  1.5361,  1.5918],
        [ 1.8570,  1.4569,  0.6196,  0.9420,  1.3476,  1.7838,  1.6595,  1.8894,
          1.8894,  1.7353,  1.3427,  1.5393,  0.9362,  1.7595,  0.1440,  1.6606,
          1.8978,  0.8921,  1.3583,  0.9919,  0.7551,  1.1761,  1.7247,  1.7914,
          1.5428,  1.8970,  1.8970,  0.8557,  0.8813,  1.8696,  1.6694,  0.8820,
          1.8104,  1.2808,  1.9183,  1.8340, -0.0459, -0.3008, -0.3396, -0.0830,
          0.1777,  0.2789, -0.1780, 12.9659,  5.8368,  0.2219,  0.5940,  0.6304,
          0.7337,  0.3807,  0.7318, -0.0726,  0.7632,  0.8295],
        [ 1.3372,  1.3748,  1.4199,  1.4072,  1.3821,  1.3447,  1.3151,  1.3339,
          1.3339,  1.3028,  1.4274,  1.3266,  1.4579,  1.3825,  1.4840,  1.3120,
          1.3635,  1.3693,  1.3958,  1.3919,  1.4304,  1.4091,  1.3626,  1.3555,
          1.2729,  1.3442,  1.3442,  1.3965,  1.4385,  1.3571,  1.1599,  1.3526,
          1.2465,  1.4123,  1.2356,  1.3613,  0.3508,  0.2741,  0.3928,  0.3575,
          0.1533,  0.1075,  0.3744,  0.1619, -0.0485,  3.0943,  2.2119,  3.0776,
          2.4984,  1.8008,  1.4113,  2.7308,  2.8682,  1.3759]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 210 : 175.63292215982926
Test loss for epoch 210 : 175.55676114250798
Test Precision for epoch 210 : 0.26153846153846155
Test Recall for epoch 210 : 0.26153846153846155
Test F1 for epoch 210 : 0.26153846153846155


theta for epoch 211 : tensor([[ 2.4710,  2.4900,  2.5266,  2.6200,  2.6016,  2.4745,  2.5884,  2.4696,
          2.4696,  1.3498,  1.3524,  1.3516,  1.3548,  1.3491,  1.3568,  1.3505,
          1.3477,  1.3101,  1.3040,  1.2623,  1.2631,  1.3050,  1.3015,  1.3009,
          1.3033,  1.3001,  1.3001,  1.2846,  1.3287,  1.3224,  1.3254,  1.3288,
          1.3239,  1.3267,  1.2788,  1.3227,  1.7402,  1.7514,  1.7443,  1.7406,
          1.7490,  1.6891,  1.7417,  1.7275,  1.7402,  1.6102,  1.5925,  1.5884,
          1.5823,  1.6062,  1.5873,  1.6215,  1.5793,  1.5804],
        [ 1.3107,  1.3127,  1.2428,  1.2672,  1.3188,  1.3158,  1.3126,  1.3149,
          1.3149,  2.4827,  2.4223,  2.3335,  2.5109,  2.3633,  2.8943,  2.4423,
          2.4557,  2.8652,  1.3001,  1.3094,  1.2621,  1.2819,  1.3326,  1.3320,
          1.3143,  1.3311,  1.3311,  1.3319,  1.2493,  1.3534,  1.3566,  1.2778,
          1.3550,  1.3579,  1.3266,  1.3537,  1.7611,  1.7736,  1.7275,  1.7548,
          1.7706,  1.7722,  1.7246,  1.6192,  1.7605,  1.5731,  1.6156,  1.6111,
          1.6045,  1.5281,  1.6100,  1.5471,  1.6012,  1.6024],
        [ 1.2883,  1.2912,  1.2946,  1.2930,  1.2911,  1.2889,  1.2892,  1.2881,
          1.2881,  1.3545,  1.3572,  1.3563,  1.3595,  1.3538,  1.3179,  1.3552,
          1.3113,  1.3417,  2.5349,  2.5732,  2.6233,  2.5446,  2.4772,  2.4755,
          2.5546,  2.4690,  2.4690,  1.3062,  1.3169,  1.3270,  1.3300,  1.3068,
          1.3284,  1.3313,  1.3269,  1.3273,  1.7424,  1.7539,  1.7467,  1.7076,
          1.7514,  1.7514,  1.7440,  1.7246,  1.7072,  1.6129,  1.5955,  1.5914,
          1.5852,  1.5885,  1.5903,  1.6073,  1.5819,  1.5832],
        [ 1.3002,  1.3031,  1.3063,  1.3047,  1.3030,  1.3008,  1.3012,  1.2999,
          1.2999,  1.3659,  1.3684,  1.3677,  1.3525,  1.3652,  1.2718,  1.3666,
          1.3631,  1.2693,  1.3203,  1.3029,  1.3218,  1.3214,  1.3177,  1.3170,
          1.3189,  1.3162,  1.3162,  2.6929,  2.6403,  2.3921,  2.5029,  2.6909,
          2.4008,  2.6221,  2.4368,  2.3938,  1.7508,  1.7625,  1.7299,  1.7502,
          1.7600,  1.7600,  1.7272,  1.6822,  1.7498,  1.6231,  1.6044,  1.4993,
          1.5394,  1.6188,  1.5987,  1.6349,  1.5361,  1.5918],
        [ 1.8628,  1.4638,  0.6272,  0.9492,  1.3548,  1.7899,  1.6658,  1.8951,
          1.8951,  1.7415,  1.3505,  1.5463,  0.9443,  1.7659,  0.1524,  1.6672,
          1.9044,  0.9002,  1.3654,  0.9998,  0.7633,  1.1833,  1.7311,  1.7977,
          1.5494,  1.9030,  1.9030,  0.8642,  0.8893,  1.8767,  1.6771,  0.8906,
          1.8177,  1.2888,  1.9253,  1.8412, -0.0539, -0.3084, -0.3472, -0.0910,
          0.1693,  0.2704, -0.1858, 13.0037,  5.8141,  0.2305,  0.6020,  0.6383,
          0.7416,  0.3890,  0.7398, -0.0639,  0.7711,  0.8373],
        [ 1.3311,  1.3687,  1.4138,  1.4011,  1.3760,  1.3386,  1.3089,  1.3277,
          1.3277,  1.2953,  1.4199,  1.3190,  1.4504,  1.3751,  1.4765,  1.3044,
          1.3560,  1.3618,  1.3879,  1.3835,  1.4224,  1.4012,  1.3547,  1.3476,
          1.2644,  1.3362,  1.3362,  1.3902,  1.4324,  1.3508,  1.1528,  1.3463,
          1.2400,  1.4061,  1.2290,  1.3549,  0.3425,  0.2657,  0.3844,  0.3492,
          0.1448,  0.0989,  0.3662,  0.1532, -0.0573,  3.1068,  2.2219,  3.0904,
          2.5089,  1.8100,  1.4202,  2.7412,  2.8814,  1.3848]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 211 : 175.67303650182393
Test loss for epoch 211 : 175.5860956691431
Test Precision for epoch 211 : 0.26153846153846155
Test Recall for epoch 211 : 0.26153846153846155
Test F1 for epoch 211 : 0.26153846153846155


theta for epoch 212 : tensor([[ 2.4749,  2.4939,  2.5305,  2.6241,  2.6057,  2.4784,  2.5926,  2.4735,
          2.4735,  1.3492,  1.3518,  1.3509,  1.3541,  1.3485,  1.3562,  1.3498,
          1.3471,  1.3094,  1.3036,  1.2618,  1.2626,  1.3046,  1.3011,  1.3006,
          1.3029,  1.2997,  1.2997,  1.2843,  1.3284,  1.3221,  1.3251,  1.3285,
          1.3236,  1.3264,  1.2785,  1.3225,  1.7405,  1.7517,  1.7447,  1.7410,
          1.7493,  1.6894,  1.7420,  1.7278,  1.7405,  1.6050,  1.5872,  1.5831,
          1.5770,  1.6009,  1.5821,  1.6163,  1.5740,  1.5751],
        [ 1.3112,  1.3133,  1.2443,  1.2680,  1.3191,  1.3162,  1.3131,  1.3153,
          1.3153,  2.4865,  2.4277,  2.3384,  2.5161,  2.3673,  2.8958,  2.4467,
          2.4617,  2.8669,  1.2995,  1.3087,  1.2614,  1.2817,  1.3319,  1.3314,
          1.3141,  1.3304,  1.3304,  1.3313,  1.2498,  1.3528,  1.3560,  1.2776,
          1.3544,  1.3574,  1.3260,  1.3531,  1.7612,  1.7737,  1.7277,  1.7551,
          1.7708,  1.7723,  1.7248,  1.6214,  1.7606,  1.5673,  1.6096,  1.6051,
          1.5986,  1.5225,  1.6040,  1.5415,  1.5952,  1.5965],
        [ 1.2886,  1.2914,  1.2948,  1.2932,  1.2913,  1.2891,  1.2894,  1.2883,
          1.2883,  1.3531,  1.3557,  1.3549,  1.3580,  1.3523,  1.3161,  1.3537,
          1.3094,  1.3402,  2.5406,  2.5799,  2.6299,  2.5502,  2.4830,  2.4812,
          2.5611,  2.4748,  2.4748,  1.3050,  1.3161,  1.3262,  1.3292,  1.3056,
          1.3276,  1.3305,  1.3261,  1.3265,  1.7425,  1.7540,  1.7468,  1.7071,
          1.7515,  1.7515,  1.7440,  1.7248,  1.7068,  1.6072,  1.5898,  1.5856,
          1.5794,  1.5828,  1.5845,  1.6016,  1.5761,  1.5774],
        [ 1.3008,  1.3038,  1.3070,  1.3054,  1.3037,  1.3014,  1.3018,  1.3006,
          1.3006,  1.3653,  1.3678,  1.3671,  1.3518,  1.3645,  1.2711,  1.3660,
          1.3624,  1.2687,  1.3200,  1.3025,  1.3215,  1.3211,  1.3174,  1.3168,
          1.3186,  1.3159,  1.3159,  2.6967,  2.6440,  2.3957,  2.5064,  2.6948,
          2.4044,  2.6257,  2.4406,  2.3974,  1.7511,  1.7629,  1.7302,  1.7506,
          1.7604,  1.7604,  1.7275,  1.6827,  1.7501,  1.6181,  1.5993,  1.4945,
          1.5343,  1.6138,  1.5938,  1.6299,  1.5310,  1.5867],
        [ 1.8579,  1.4574,  0.6189,  0.9419,  1.3483,  1.7849,  1.6603,  1.8906,
          1.8906,  1.7339,  1.3422,  1.5389,  0.9356,  1.7584,  0.1427,  1.6597,
          1.8986,  0.8899,  1.3575,  0.9920,  0.7546,  1.1748,  1.7244,  1.7912,
          1.5426,  1.8969,  1.8969,  0.8557,  0.8799,  1.8702,  1.6701,  0.8816,
          1.8109,  1.2807,  1.9190,  1.8345, -0.0472, -0.3018, -0.3408, -0.0844,
          0.1759,  0.2769, -0.1792, 13.0562,  5.8087,  0.2200,  0.5915,  0.6276,
          0.7308,  0.3782,  0.7290, -0.0743,  0.7604,  0.8265],
        [ 1.3422,  1.3797,  1.4247,  1.4121,  1.3869,  1.3497,  1.3201,  1.3388,
          1.3388,  1.3078,  1.4321,  1.3314,  1.4626,  1.3874,  1.4887,  1.3168,
          1.3682,  1.3741,  1.4003,  1.3956,  1.4347,  1.4135,  1.3672,  1.3600,
          1.2768,  1.3487,  1.3487,  1.4011,  1.4430,  1.3618,  1.1641,  1.3572,
          1.2511,  1.4169,  1.2404,  1.3659,  0.3544,  0.2778,  0.3962,  0.3611,
          0.1569,  0.1111,  0.3780,  0.1652, -0.0451,  3.0975,  2.2100,  3.0812,
          2.4975,  1.7975,  1.4074,  2.7299,  2.8725,  1.3719]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 212 : 175.68056234721232
Test loss for epoch 212 : 175.61444387752877
Test Precision for epoch 212 : 0.26153846153846155
Test Recall for epoch 212 : 0.26153846153846155
Test F1 for epoch 212 : 0.26153846153846155


theta for epoch 213 : tensor([[ 2.4766,  2.4956,  2.5321,  2.6261,  2.6076,  2.4801,  2.5945,  2.4752,
          2.4752,  1.3479,  1.3505,  1.3496,  1.3528,  1.3471,  1.3549,  1.3485,
          1.3457,  1.3081,  1.3012,  1.2594,  1.2601,  1.3022,  1.2987,  1.2982,
          1.3005,  1.2973,  1.2973,  1.2832,  1.3273,  1.3210,  1.3240,  1.3274,
          1.3225,  1.3253,  1.2774,  1.3214,  1.7393,  1.7506,  1.7435,  1.7398,
          1.7481,  1.6882,  1.7408,  1.7266,  1.7394,  1.6112,  1.5935,  1.5894,
          1.5833,  1.6072,  1.5883,  1.6225,  1.5802,  1.5813],
        [ 1.3100,  1.3121,  1.2441,  1.2670,  1.3178,  1.3148,  1.3119,  1.3139,
          1.3139,  2.4893,  2.4320,  2.3423,  2.5204,  2.3704,  2.8966,  2.4501,
          2.4668,  2.8676,  1.2961,  1.3051,  1.2578,  1.2788,  1.3283,  1.3278,
          1.3110,  1.3269,  1.3269,  1.3295,  1.2489,  1.3510,  1.3542,  1.2763,
          1.3525,  1.3555,  1.3242,  1.3513,  1.7596,  1.7721,  1.7261,  1.7537,
          1.7692,  1.7707,  1.7232,  1.6220,  1.7590,  1.5737,  1.6158,  1.6113,
          1.6046,  1.5289,  1.6102,  1.5478,  1.6013,  1.6025],
        [ 1.2874,  1.2903,  1.2937,  1.2921,  1.2901,  1.2880,  1.2882,  1.2872,
          1.2872,  1.3510,  1.3537,  1.3528,  1.3559,  1.3503,  1.3138,  1.3517,
          1.3069,  1.3382,  2.5427,  2.5830,  2.6330,  2.5523,  2.4852,  2.4833,
          2.5641,  2.4769,  2.4769,  1.3031,  1.3146,  1.3246,  1.3277,  1.3037,
          1.3261,  1.3289,  1.3245,  1.3249,  1.7411,  1.7526,  1.7454,  1.7052,
          1.7501,  1.7502,  1.7426,  1.7236,  1.7049,  1.6131,  1.5957,  1.5915,
          1.5852,  1.5887,  1.5904,  1.6073,  1.5820,  1.5833],
        [ 1.3000,  1.3030,  1.3061,  1.3046,  1.3028,  1.3006,  1.3010,  1.2997,
          1.2997,  1.3637,  1.3662,  1.3656,  1.3502,  1.3630,  1.2697,  1.3644,
          1.3609,  1.2673,  1.3176,  1.3001,  1.3191,  1.3187,  1.3150,  1.3144,
          1.3162,  1.3135,  1.3135,  2.6987,  2.6457,  2.3973,  2.5078,  2.6967,
          2.4060,  2.6274,  2.4424,  2.3990,  1.7498,  1.7616,  1.7288,  1.7492,
          1.7591,  1.7591,  1.7261,  1.6816,  1.7488,  1.6239,  1.6052,  1.5005,
          1.5402,  1.6197,  1.5996,  1.6357,  1.5368,  1.5926],
        [ 1.8639,  1.4649,  0.6275,  0.9500,  1.3561,  1.7913,  1.6670,  1.8965,
          1.8965,  1.7407,  1.3508,  1.5466,  0.9448,  1.7655,  0.1525,  1.6670,
          1.9056,  0.8992,  1.3657,  1.0010,  0.7642,  1.1831,  1.7316,  1.7982,
          1.5501,  1.9035,  1.9035,  0.8650,  0.8887,  1.8772,  1.6778,  0.8909,
          1.8182,  1.2892,  1.9258,  1.8417, -0.0563, -0.3105, -0.3496, -0.0936,
          0.1662,  0.2671, -0.1880, 13.0921,  5.7842,  0.2313,  0.6024,  0.6385,
          0.7418,  0.3894,  0.7400, -0.0629,  0.7714,  0.8374],
        [ 1.3341,  1.3717,  1.4168,  1.4041,  1.3789,  1.3416,  1.3119,  1.3307,
          1.3307,  1.2983,  1.4226,  1.3218,  1.4530,  1.3780,  1.4791,  1.3073,
          1.3587,  1.3646,  1.3904,  1.3853,  1.4248,  1.4037,  1.3573,  1.3502,
          1.2664,  1.3388,  1.3388,  1.3924,  1.4346,  1.3532,  1.1548,  1.3486,
          1.2424,  1.4084,  1.2315,  1.3573,  0.3450,  0.2682,  0.3867,  0.3517,
          0.1472,  0.1014,  0.3686,  0.1554, -0.0551,  3.1120,  2.2220,  3.0960,
          2.5101,  1.8088,  1.4184,  2.7423,  2.8876,  1.3829]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 213 : 175.62024437047913
Test loss for epoch 213 : 175.54062283518817
Test Precision for epoch 213 : 0.26153846153846155
Test Recall for epoch 213 : 0.26153846153846155
Test F1 for epoch 213 : 0.26153846153846155


theta for epoch 214 : tensor([[ 2.4766,  2.4956,  2.5321,  2.6263,  2.6079,  2.4801,  2.5947,  2.4751,
          2.4751,  1.3478,  1.3504,  1.3495,  1.3527,  1.3471,  1.3548,  1.3485,
          1.3457,  1.3080,  1.3020,  1.2602,  1.2610,  1.3030,  1.2995,  1.2990,
          1.3013,  1.2981,  1.2981,  1.2828,  1.3268,  1.3206,  1.3236,  1.3270,
          1.3220,  1.3248,  1.2770,  1.3209,  1.7408,  1.7520,  1.7450,  1.7413,
          1.7496,  1.6898,  1.7423,  1.7281,  1.7409,  1.6124,  1.5946,  1.5905,
          1.5844,  1.6083,  1.5894,  1.6237,  1.5813,  1.5825],
        [ 1.3090,  1.3111,  1.2440,  1.2663,  1.3166,  1.3136,  1.3108,  1.3127,
          1.3127,  2.4891,  2.4334,  2.3432,  2.5219,  2.3706,  2.8948,  2.4506,
          2.4689,  2.8657,  1.2969,  1.3058,  1.2586,  1.2801,  1.3290,  1.3285,
          1.3121,  1.3275,  1.3275,  1.3288,  1.2493,  1.3503,  1.3535,  1.2761,
          1.3518,  1.3548,  1.3236,  1.3506,  1.7608,  1.7733,  1.7274,  1.7551,
          1.7705,  1.7720,  1.7245,  1.6251,  1.7602,  1.5750,  1.6169,  1.6124,
          1.6057,  1.5304,  1.6112,  1.5493,  1.6023,  1.6036],
        [ 1.2865,  1.2893,  1.2927,  1.2911,  1.2892,  1.2870,  1.2873,  1.2862,
          1.2862,  1.3511,  1.3538,  1.3529,  1.3560,  1.3504,  1.3136,  1.3518,
          1.3066,  1.3383,  2.5424,  2.5838,  2.6338,  2.5521,  2.4850,  2.4831,
          2.5647,  2.4767,  2.4767,  1.3024,  1.3142,  1.3242,  1.3273,  1.3030,
          1.3257,  1.3285,  1.3241,  1.3245,  1.7427,  1.7541,  1.7469,  1.7062,
          1.7517,  1.7517,  1.7442,  1.7252,  1.7059,  1.6143,  1.5969,  1.5927,
          1.5864,  1.5900,  1.5916,  1.6086,  1.5832,  1.5845],
        [ 1.2989,  1.3018,  1.3050,  1.3034,  1.3017,  1.2995,  1.2999,  1.2986,
          1.2986,  1.3634,  1.3659,  1.3652,  1.3499,  1.3627,  1.2695,  1.3641,
          1.3606,  1.2672,  1.3181,  1.3005,  1.3196,  1.3192,  1.3155,  1.3149,
          1.3167,  1.3141,  1.3141,  2.6993,  2.6462,  2.3976,  2.5080,  2.6974,
          2.4063,  2.6278,  2.4429,  2.3994,  1.7513,  1.7631,  1.7302,  1.7507,
          1.7606,  1.7606,  1.7275,  1.6833,  1.7503,  1.6248,  1.6061,  1.5017,
          1.5411,  1.6206,  1.6005,  1.6367,  1.5377,  1.5935],
        [ 1.8606,  1.4611,  0.6232,  0.9461,  1.3523,  1.7880,  1.6635,  1.8934,
          1.8934,  1.7368,  1.3469,  1.5431,  0.9409,  1.7617,  0.1482,  1.6633,
          1.9030,  0.8943,  1.3622,  0.9979,  0.7605,  1.1792,  1.7287,  1.7953,
          1.5472,  1.9008,  1.9008,  0.8611,  0.8841,  1.8738,  1.6744,  0.8867,
          1.8147,  1.2852,  1.9224,  1.8382, -0.0538, -0.3080, -0.3472, -0.0912,
          0.1685,  0.2692, -0.1856, 13.1397,  5.7732,  0.2276,  0.5986,  0.6346,
          0.7378,  0.3855,  0.7361, -0.0666,  0.7676,  0.8336],
        [ 1.3362,  1.3737,  1.4187,  1.4060,  1.3809,  1.3436,  1.3140,  1.3327,
          1.3327,  1.3014,  1.4256,  1.3249,  1.4560,  1.3810,  1.4821,  1.3104,
          1.3616,  1.3676,  1.3937,  1.3883,  1.4281,  1.4070,  1.3605,  1.3535,
          1.2694,  1.3421,  1.3421,  1.3949,  1.4370,  1.3557,  1.1572,  1.3510,
          1.2450,  1.4108,  1.2341,  1.3598,  0.3487,  0.2720,  0.3903,  0.3554,
          0.1509,  0.1050,  0.3723,  0.1589, -0.0515,  3.1126,  2.2199,  3.0967,
          2.5086,  1.8062,  1.4154,  2.7407,  2.8887,  1.3799]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 214 : 175.5788897691864
Test loss for epoch 214 : 175.50868036701763
Test Precision for epoch 214 : 0.26153846153846155
Test Recall for epoch 214 : 0.26153846153846155
Test F1 for epoch 214 : 0.26153846153846155


theta for epoch 215 : tensor([[ 2.4778,  2.4968,  2.5334,  2.6278,  2.6094,  2.4813,  2.5962,  2.4764,
          2.4764,  1.3485,  1.3511,  1.3502,  1.3534,  1.3478,  1.3555,  1.3492,
          1.3464,  1.3087,  1.3035,  1.2617,  1.2625,  1.3045,  1.3010,  1.3005,
          1.3028,  1.2996,  1.2996,  1.2831,  1.3272,  1.3209,  1.3239,  1.3273,
          1.3224,  1.3252,  1.2773,  1.3213,  1.7418,  1.7530,  1.7460,  1.7422,
          1.7506,  1.6907,  1.7432,  1.7290,  1.7418,  1.6089,  1.5911,  1.5870,
          1.5809,  1.6048,  1.5859,  1.6202,  1.5778,  1.5789],
        [ 1.3090,  1.3112,  1.2450,  1.2666,  1.3165,  1.3135,  1.3109,  1.3126,
          1.3126,  2.4892,  2.4351,  2.3445,  2.5237,  2.3710,  2.8933,  2.4514,
          2.4712,  2.8641,  1.2992,  1.3080,  1.2607,  1.2829,  1.3311,  1.3305,
          1.3147,  1.3296,  1.3296,  1.3295,  1.2509,  1.3508,  1.3540,  1.2771,
          1.3524,  1.3554,  1.3242,  1.3512,  1.7617,  1.7742,  1.7284,  1.7562,
          1.7714,  1.7729,  1.7255,  1.6280,  1.7611,  1.5717,  1.6133,  1.6088,
          1.6022,  1.5273,  1.6077,  1.5461,  1.5988,  1.6001],
        [ 1.2867,  1.2896,  1.2930,  1.2914,  1.2894,  1.2873,  1.2875,  1.2865,
          1.2865,  1.3529,  1.3555,  1.3546,  1.3577,  1.3521,  1.3149,  1.3535,
          1.3080,  1.3401,  2.5422,  2.5846,  2.6345,  2.5518,  2.4847,  2.4828,
          2.5653,  2.4765,  2.4765,  1.3030,  1.3152,  1.3252,  1.3282,  1.3036,
          1.3267,  1.3295,  1.3251,  1.3255,  1.7439,  1.7554,  1.7481,  1.7070,
          1.7529,  1.7529,  1.7454,  1.7265,  1.7066,  1.6114,  1.5939,  1.5897,
          1.5835,  1.5871,  1.5887,  1.6056,  1.5802,  1.5815],
        [ 1.2985,  1.3015,  1.3047,  1.3031,  1.3014,  1.2991,  1.2995,  1.2983,
          1.2983,  1.3641,  1.3666,  1.3659,  1.3505,  1.3634,  1.2703,  1.3648,
          1.3613,  1.2680,  1.3194,  1.3018,  1.3209,  1.3205,  1.3168,  1.3162,
          1.3180,  1.3154,  1.3154,  2.7013,  2.6479,  2.3994,  2.5096,  2.6993,
          2.4080,  2.6296,  2.4448,  2.4011,  1.7522,  1.7640,  1.7312,  1.7516,
          1.7615,  1.7615,  1.7284,  1.6845,  1.7512,  1.6214,  1.6027,  1.4985,
          1.5377,  1.6172,  1.5971,  1.6333,  1.5343,  1.5901],
        [ 1.8585,  1.4585,  0.6199,  0.9433,  1.3498,  1.7859,  1.6611,  1.8915,
          1.8915,  1.7340,  1.3442,  1.5406,  0.9380,  1.7591,  0.1448,  1.6607,
          1.9014,  0.8904,  1.3597,  0.9957,  0.7579,  1.1763,  1.7268,  1.7935,
          1.5453,  1.8992,  1.8992,  0.8584,  0.8807,  1.8718,  1.6723,  0.8836,
          1.8125,  1.2824,  1.9205,  1.8361, -0.0521, -0.3062, -0.3455, -0.0896,
          0.1700,  0.2707, -0.1838, 13.1866,  5.7613,  0.2236,  0.5943,  0.6301,
          0.7333,  0.3813,  0.7317, -0.0704,  0.7631,  0.8290],
        [ 1.3382,  1.3757,  1.4207,  1.4081,  1.3829,  1.3456,  1.3161,  1.3348,
          1.3348,  1.3044,  1.4284,  1.3277,  1.4589,  1.3839,  1.4850,  1.3133,
          1.3644,  1.3706,  1.3967,  1.3910,  1.4311,  1.4101,  1.3635,  1.3565,
          1.2722,  1.3451,  1.3451,  1.3974,  1.4396,  1.3582,  1.1595,  1.3535,
          1.2475,  1.4133,  1.2367,  1.3623,  0.3515,  0.2748,  0.3930,  0.3582,
          0.1536,  0.1078,  0.3751,  0.1615, -0.0489,  3.1133,  2.2181,  3.0975,
          2.5073,  1.8036,  1.4125,  2.7394,  2.8899,  1.3771]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 215 : 175.59501350702217
Test loss for epoch 215 : 175.533147139531
Test Precision for epoch 215 : 0.26153846153846155
Test Recall for epoch 215 : 0.26153846153846155
Test F1 for epoch 215 : 0.26153846153846155


theta for epoch 216 : tensor([[ 2.4814,  2.5004,  2.5370,  2.6317,  2.6132,  2.4849,  2.6001,  2.4800,
          2.4800,  1.3483,  1.3508,  1.3500,  1.3532,  1.3476,  1.3552,  1.3489,
          1.3461,  1.3084,  1.3023,  1.2605,  1.2612,  1.3033,  1.2998,  1.2993,
          1.3017,  1.2985,  1.2985,  1.2830,  1.3271,  1.3209,  1.3239,  1.3272,
          1.3223,  1.3251,  1.2772,  1.3212,  1.7399,  1.7512,  1.7441,  1.7404,
          1.7488,  1.6889,  1.7414,  1.7272,  1.7400,  1.6080,  1.5903,  1.5862,
          1.5801,  1.6040,  1.5851,  1.6193,  1.5770,  1.5781],
        [ 1.3094,  1.3116,  1.2464,  1.2673,  1.3167,  1.3137,  1.3113,  1.3129,
          1.3129,  2.4917,  2.4393,  2.3483,  2.5278,  2.3738,  2.8939,  2.4546,
          2.4760,  2.8647,  1.2987,  1.3073,  1.2601,  1.2828,  1.3304,  1.3298,
          1.3145,  1.3289,  1.3289,  1.3296,  1.2520,  1.3510,  1.3542,  1.2777,
          1.3525,  1.3555,  1.3243,  1.3513,  1.7599,  1.7724,  1.7267,  1.7546,
          1.7696,  1.7711,  1.7237,  1.6282,  1.7593,  1.5712,  1.6127,  1.6082,
          1.6016,  1.5270,  1.6071,  1.5456,  1.5982,  1.5995],
        [ 1.2874,  1.2903,  1.2937,  1.2921,  1.2902,  1.2880,  1.2883,  1.2872,
          1.2872,  1.3535,  1.3561,  1.3553,  1.3584,  1.3528,  1.3153,  1.3542,
          1.3083,  1.3408,  2.5437,  2.5871,  2.6371,  2.5534,  2.4863,  2.4843,
          2.5677,  2.4781,  2.4781,  1.3032,  1.3157,  1.3257,  1.3287,  1.3038,
          1.3272,  1.3300,  1.3256,  1.3260,  1.7423,  1.7538,  1.7466,  1.7049,
          1.7514,  1.7514,  1.7438,  1.7251,  1.7046,  1.6111,  1.5937,  1.5895,
          1.5833,  1.5869,  1.5884,  1.6052,  1.5799,  1.5813],
        [ 1.2988,  1.3018,  1.3050,  1.3034,  1.3017,  1.2994,  1.2998,  1.2986,
          1.2986,  1.3642,  1.3666,  1.3659,  1.3505,  1.3634,  1.2704,  1.3648,
          1.3613,  1.2681,  1.3186,  1.3009,  1.3201,  1.3197,  1.3160,  1.3154,
          1.3172,  1.3146,  1.3146,  2.7048,  2.6514,  2.4027,  2.5127,  2.7029,
          2.4114,  2.6329,  2.4483,  2.4044,  1.7504,  1.7622,  1.7293,  1.7497,
          1.7597,  1.7597,  1.7265,  1.6829,  1.7494,  1.6208,  1.6021,  1.4981,
          1.5371,  1.6165,  1.5965,  1.6326,  1.5337,  1.5895],
        [ 1.8651,  1.4662,  0.6283,  0.9513,  1.3577,  1.7928,  1.6683,  1.8980,
          1.8980,  1.7411,  1.3527,  1.5484,  0.9469,  1.7664,  0.1541,  1.6682,
          1.9088,  0.8993,  1.3678,  1.0044,  0.7670,  1.1844,  1.7342,  1.8007,
          1.5527,  1.9061,  1.9061,  0.8675,  0.8893,  1.8795,  1.6804,  0.8928,
          1.8205,  1.2910,  1.9281,  1.8439, -0.0607, -0.3143, -0.3538, -0.0983,
          0.1610,  0.2615, -0.1922, 13.2228,  5.7368,  0.2325,  0.6026,  0.6383,
          0.7414,  0.3899,  0.7398, -0.0612,  0.7711,  0.8370],
        [ 1.3315,  1.3691,  1.4141,  1.4014,  1.3763,  1.3390,  1.3093,  1.3281,
          1.3281,  1.2962,  1.4203,  1.3194,  1.4507,  1.3759,  1.4768,  1.3050,
          1.3561,  1.3624,  1.3882,  1.3820,  1.4226,  1.4015,  1.3550,  1.3479,
          1.2630,  1.3365,  1.3365,  1.3902,  1.4326,  1.3511,  1.1516,  1.3464,
          1.2402,  1.4063,  1.2293,  1.3552,  0.3422,  0.2656,  0.3837,  0.3490,
          0.1442,  0.0984,  0.3659,  0.1519, -0.0586,  3.1263,  2.2285,  3.1107,
          2.5182,  1.8133,  1.4219,  2.7502,  2.9034,  1.3864]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 216 : 175.61672519372266
Test loss for epoch 216 : 175.54272858831018
Test Precision for epoch 216 : 0.26153846153846155
Test Recall for epoch 216 : 0.26153846153846155
Test F1 for epoch 216 : 0.26153846153846155


theta for epoch 217 : tensor([[ 2.4852,  2.5042,  2.5408,  2.6357,  2.6172,  2.4887,  2.6041,  2.4837,
          2.4837,  1.3474,  1.3499,  1.3491,  1.3522,  1.3467,  1.3543,  1.3480,
          1.3452,  1.3075,  1.3017,  1.2598,  1.2606,  1.3027,  1.2992,  1.2987,
          1.3011,  1.2979,  1.2979,  1.2820,  1.3261,  1.3199,  1.3229,  1.3263,
          1.3214,  1.3241,  1.2763,  1.3202,  1.7403,  1.7515,  1.7445,  1.7407,
          1.7492,  1.6892,  1.7418,  1.7275,  1.7403,  1.6044,  1.5867,  1.5826,
          1.5764,  1.6004,  1.5815,  1.6157,  1.5734,  1.5745],
        [ 1.3095,  1.3117,  1.2473,  1.2676,  1.3167,  1.3137,  1.3114,  1.3128,
          1.3128,  2.4945,  2.4436,  2.3522,  2.5322,  2.3770,  2.8948,  2.4580,
          2.4810,  2.8656,  1.2986,  1.3071,  1.2599,  1.2832,  1.3302,  1.3297,
          1.3147,  1.3288,  1.3288,  1.3288,  1.2521,  1.3502,  1.3533,  1.2773,
          1.3517,  1.3547,  1.3236,  1.3505,  1.7603,  1.7728,  1.7271,  1.7551,
          1.7700,  1.7715,  1.7241,  1.6304,  1.7597,  1.5676,  1.6090,  1.6045,
          1.5979,  1.5236,  1.6034,  1.5422,  1.5945,  1.5959],
        [ 1.2873,  1.2901,  1.2935,  1.2919,  1.2900,  1.2878,  1.2881,  1.2870,
          1.2870,  1.3525,  1.3551,  1.3542,  1.3573,  1.3518,  1.3139,  1.3531,
          1.3069,  1.3398,  2.5483,  2.5926,  2.6425,  2.5578,  2.4909,  2.4889,
          2.5731,  2.4827,  2.4827,  1.3018,  1.3147,  1.3247,  1.3277,  1.3024,
          1.3262,  1.3290,  1.3246,  1.3250,  1.7427,  1.7542,  1.7470,  1.7048,
          1.7517,  1.7518,  1.7442,  1.7256,  1.7044,  1.6075,  1.5901,  1.5859,
          1.5796,  1.5833,  1.5848,  1.6016,  1.5763,  1.5777],
        [ 1.2989,  1.3019,  1.3050,  1.3035,  1.3018,  1.2995,  1.2999,  1.2987,
          1.2987,  1.3636,  1.3661,  1.3654,  1.3499,  1.3629,  1.2700,  1.3643,
          1.3608,  1.2677,  1.3185,  1.3008,  1.3200,  1.3196,  1.3160,  1.3154,
          1.3171,  1.3145,  1.3145,  2.7080,  2.6543,  2.4056,  2.5154,  2.7060,
          2.4143,  2.6358,  2.4514,  2.4074,  1.7509,  1.7627,  1.7297,  1.7503,
          1.7602,  1.7602,  1.7270,  1.6837,  1.7499,  1.6176,  1.5989,  1.4952,
          1.5339,  1.6134,  1.5934,  1.6294,  1.5305,  1.5863],
        [ 1.8606,  1.4604,  0.6208,  0.9448,  1.3519,  1.7883,  1.6632,  1.8939,
          1.8939,  1.7345,  1.3455,  1.5420,  0.9393,  1.7599,  0.1456,  1.6617,
          1.9038,  0.8904,  1.3610,  0.9977,  0.7595,  1.1770,  1.7284,  1.7951,
          1.5469,  1.9009,  1.9009,  0.8600,  0.8810,  1.8735,  1.6741,  0.8848,
          1.8143,  1.2837,  1.9223,  1.8379, -0.0550, -0.3087, -0.3483, -0.0926,
          0.1665,  0.2670, -0.1865, 13.2735,  5.7293,  0.2235,  0.5935,  0.6289,
          0.7319,  0.3807,  0.7305, -0.0701,  0.7618,  0.8276],
        [ 1.3406,  1.3780,  1.4230,  1.4103,  1.3852,  1.3480,  1.3184,  1.3371,
          1.3371,  1.3065,  1.4304,  1.3297,  1.4608,  1.3860,  1.4869,  1.3153,
          1.3662,  1.3726,  1.3985,  1.3921,  1.4328,  1.4118,  1.3653,  1.3582,
          1.2733,  1.3469,  1.3469,  1.3990,  1.4413,  1.3600,  1.1607,  1.3552,
          1.2493,  1.4151,  1.2384,  1.3641,  0.3520,  0.2755,  0.3933,  0.3588,
          0.1542,  0.1084,  0.3756,  0.1616, -0.0486,  3.1192,  2.2188,  3.1036,
          2.5091,  1.8030,  1.4113,  2.7411,  2.8967,  1.3758]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 217 : 175.59424694956215
Test loss for epoch 217 : 175.5383789888281
Test Precision for epoch 217 : 0.26153846153846155
Test Recall for epoch 217 : 0.26153846153846155
Test F1 for epoch 217 : 0.26153846153846155


theta for epoch 218 : tensor([[ 2.4860,  2.5050,  2.5417,  2.6368,  2.6183,  2.4895,  2.6052,  2.4846,
          2.4846,  1.3465,  1.3490,  1.3482,  1.3513,  1.3458,  1.3534,  1.3471,
          1.3444,  1.3066,  1.2999,  1.2580,  1.2587,  1.3009,  1.2974,  1.2969,
          1.2992,  1.2961,  1.2961,  1.2812,  1.3253,  1.3191,  1.3221,  1.3254,
          1.3206,  1.3233,  1.2755,  1.3194,  1.7396,  1.7508,  1.7438,  1.7400,
          1.7485,  1.6885,  1.7411,  1.7268,  1.7396,  1.6107,  1.5930,  1.5889,
          1.5828,  1.6067,  1.5879,  1.6220,  1.5797,  1.5809],
        [ 1.3079,  1.3102,  1.2466,  1.2663,  1.3150,  1.3120,  1.3098,  1.3111,
          1.3111,  2.4963,  2.4471,  2.3553,  2.5357,  2.3791,  2.8949,  2.4606,
          2.4850,  2.8658,  1.2960,  1.3044,  1.2572,  1.2810,  1.3275,  1.3270,
          1.3125,  1.3261,  1.3261,  1.3274,  1.2516,  1.3488,  1.3520,  1.2764,
          1.3504,  1.3533,  1.3222,  1.3491,  1.7593,  1.7718,  1.7261,  1.7543,
          1.7690,  1.7705,  1.7231,  1.6313,  1.7587,  1.5743,  1.6155,  1.6110,
          1.6043,  1.5303,  1.6098,  1.5488,  1.6009,  1.6022],
        [ 1.2856,  1.2884,  1.2917,  1.2902,  1.2882,  1.2861,  1.2864,  1.2853,
          1.2853,  1.3509,  1.3534,  1.3526,  1.3556,  1.3501,  1.3120,  1.3515,
          1.3049,  1.3381,  2.5501,  2.5955,  2.6454,  2.5597,  2.4928,  2.4907,
          2.5758,  2.4845,  2.4845,  1.3002,  1.3135,  1.3234,  1.3265,  1.3008,
          1.3249,  1.3277,  1.3233,  1.3237,  1.7418,  1.7532,  1.7461,  1.7034,
          1.7508,  1.7509,  1.7433,  1.7248,  1.7030,  1.6134,  1.5960,  1.5918,
          1.5856,  1.5892,  1.5907,  1.6074,  1.5822,  1.5836],
        [ 1.2976,  1.3006,  1.3038,  1.3022,  1.3005,  1.2982,  1.2986,  1.2974,
          1.2974,  1.3627,  1.3651,  1.3644,  1.3488,  1.3619,  1.2691,  1.3633,
          1.3598,  1.2669,  1.3167,  1.2989,  1.3181,  1.3178,  1.3142,  1.3136,
          1.3153,  1.3127,  1.3127,  2.7093,  2.6554,  2.4067,  2.5163,  2.7074,
          2.4154,  2.6369,  2.4526,  2.4084,  1.7501,  1.7619,  1.7289,  1.7495,
          1.7595,  1.7595,  1.7261,  1.6832,  1.7491,  1.6235,  1.6049,  1.5014,
          1.5399,  1.6193,  1.5993,  1.6353,  1.5365,  1.5923],
        [ 1.8638,  1.4645,  0.6256,  0.9493,  1.3562,  1.7917,  1.6668,  1.8970,
          1.8970,  1.7385,  1.3506,  1.5466,  0.9448,  1.7640,  0.1514,  1.6660,
          1.9083,  0.8956,  1.3657,  1.0031,  0.7652,  1.1818,  1.7327,  1.7993,
          1.5514,  1.9048,  1.9048,  0.8655,  0.8860,  1.8778,  1.6787,  0.8903,
          1.8187,  1.2887,  1.9265,  1.8422, -0.0609, -0.3143, -0.3540, -0.0987,
          0.1602,  0.2606, -0.1923, 13.3120,  5.7077,  0.2306,  0.6002,  0.6357,
          0.7387,  0.3876,  0.7373, -0.0629,  0.7686,  0.8343],
        [ 1.3349,  1.3724,  1.4173,  1.4047,  1.3796,  1.3423,  1.3127,  1.3315,
          1.3315,  1.3004,  1.4243,  1.3235,  1.4547,  1.3800,  1.4807,  1.3092,
          1.3600,  1.3665,  1.3920,  1.3852,  1.4263,  1.4054,  1.3588,  1.3518,
          1.2664,  1.3404,  1.3404,  1.3934,  1.4358,  1.3544,  1.1546,  1.3496,
          1.2436,  1.4095,  1.2327,  1.3585,  0.3457,  0.2693,  0.3870,  0.3526,
          0.1478,  0.1020,  0.3694,  0.1551, -0.0552,  3.1298,  2.2269,  3.1145,
          2.5177,  1.8105,  1.4185,  2.7496,  2.9079,  1.3830]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 218 : 175.54533892017406
Test loss for epoch 218 : 175.48225813507037
Test Precision for epoch 218 : 0.26153846153846155
Test Recall for epoch 218 : 0.26153846153846155
Test F1 for epoch 218 : 0.26153846153846155


theta for epoch 219 : tensor([[ 2.4862,  2.5052,  2.5418,  2.6372,  2.6187,  2.4896,  2.6056,  2.4847,
          2.4847,  1.3467,  1.3492,  1.3484,  1.3515,  1.3460,  1.3536,  1.3473,
          1.3446,  1.3068,  1.3002,  1.2583,  1.2591,  1.3012,  1.2977,  1.2972,
          1.2995,  1.2964,  1.2964,  1.2814,  1.3256,  1.3193,  1.3223,  1.3257,
          1.3208,  1.3235,  1.2757,  1.3196,  1.7402,  1.7515,  1.7445,  1.7407,
          1.7492,  1.6892,  1.7417,  1.7274,  1.7403,  1.6123,  1.5946,  1.5905,
          1.5844,  1.6083,  1.5895,  1.6235,  1.5813,  1.5825],
        [ 1.3071,  1.3093,  1.2466,  1.2657,  1.3140,  1.3110,  1.3089,  1.3101,
          1.3101,  2.4969,  2.4492,  2.3571,  2.5380,  2.3801,  2.8939,  2.4619,
          2.4878,  2.8648,  1.2959,  1.3041,  1.2570,  1.2813,  1.3272,  1.3267,
          1.3126,  1.3258,  1.3258,  1.3273,  1.2524,  1.3486,  1.3518,  1.2766,
          1.3502,  1.3531,  1.3221,  1.3489,  1.7596,  1.7721,  1.7266,  1.7548,
          1.7694,  1.7708,  1.7236,  1.6335,  1.7590,  1.5758,  1.6168,  1.6123,
          1.6056,  1.5319,  1.6112,  1.5503,  1.6022,  1.6035],
        [ 1.2847,  1.2875,  1.2908,  1.2893,  1.2874,  1.2852,  1.2855,  1.2844,
          1.2844,  1.3507,  1.3532,  1.3524,  1.3555,  1.3500,  1.3115,  1.3513,
          1.3044,  1.3380,  2.5508,  2.5971,  2.6471,  2.5603,  2.4935,  2.4914,
          2.5773,  2.4852,  2.4852,  1.2999,  1.3135,  1.3234,  1.3264,  1.3005,
          1.3249,  1.3277,  1.3233,  1.3237,  1.7423,  1.7538,  1.7466,  1.7034,
          1.7514,  1.7514,  1.7438,  1.7254,  1.7031,  1.6147,  1.5973,  1.5931,
          1.5869,  1.5906,  1.5921,  1.6087,  1.5836,  1.5850],
        [ 1.2969,  1.2998,  1.3030,  1.3014,  1.2997,  1.2974,  1.2978,  1.2966,
          1.2966,  1.3626,  1.3650,  1.3643,  1.3487,  1.3618,  1.2692,  1.3632,
          1.3597,  1.2670,  1.3167,  1.2988,  1.3181,  1.3177,  1.3141,  1.3135,
          1.3152,  1.3127,  1.3127,  2.7104,  2.6564,  2.4076,  2.5170,  2.7085,
          2.4163,  2.6378,  2.4537,  2.4094,  1.7507,  1.7625,  1.7295,  1.7501,
          1.7601,  1.7601,  1.7267,  1.6840,  1.7497,  1.6248,  1.6062,  1.5030,
          1.5413,  1.6206,  1.6006,  1.6366,  1.5378,  1.5936],
        [ 1.8630,  1.4636,  0.6246,  0.9485,  1.3554,  1.7910,  1.6660,  1.8964,
          1.8964,  1.7375,  1.3500,  1.5461,  0.9443,  1.7632,  0.1507,  1.6653,
          1.9083,  0.8944,  1.3652,  1.0031,  0.7649,  1.1810,  1.7324,  1.7990,
          1.5511,  1.9046,  1.9046,  0.8652,  0.8850,  1.8776,  1.6786,  0.8897,
          1.8184,  1.2882,  1.9263,  1.8420, -0.0614, -0.3147, -0.3545, -0.0993,
          0.1594,  0.2597, -0.1927, 13.3560,  5.6923,  0.2303,  0.5997,  0.6349,
          0.7380,  0.3871,  0.7367, -0.0631,  0.7680,  0.8337],
        [ 1.3342,  1.3717,  1.4166,  1.4040,  1.3789,  1.3416,  1.3120,  1.3307,
          1.3307,  1.3001,  1.4239,  1.3231,  1.4543,  1.3797,  1.4803,  1.3089,
          1.3596,  1.3662,  1.3917,  1.3845,  1.4259,  1.4050,  1.3584,  1.3514,
          1.2657,  1.3400,  1.3400,  1.3932,  1.4357,  1.3542,  1.1541,  1.3494,
          1.2434,  1.4093,  1.2325,  1.3583,  0.3455,  0.2691,  0.3867,  0.3524,
          0.1475,  0.1017,  0.3692,  0.1545, -0.0557,  3.1339,  2.2284,  3.1186,
          2.5198,  1.8113,  1.4191,  2.7516,  2.9125,  1.3836]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 219 : 175.53488032563578
Test loss for epoch 219 : 175.47528883896595
Test Precision for epoch 219 : 0.26153846153846155
Test Recall for epoch 219 : 0.26153846153846155
Test F1 for epoch 219 : 0.26153846153846155


theta for epoch 220 : tensor([[ 2.4885,  2.5075,  2.5442,  2.6397,  2.6213,  2.4920,  2.6081,  2.4870,
          2.4870,  1.3473,  1.3498,  1.3490,  1.3521,  1.3466,  1.3541,  1.3479,
          1.3452,  1.3074,  1.3016,  1.2597,  1.2604,  1.3026,  1.2991,  1.2986,
          1.3009,  1.2978,  1.2978,  1.2820,  1.3262,  1.3200,  1.3229,  1.3263,
          1.3214,  1.3241,  1.2763,  1.3203,  1.7412,  1.7524,  1.7454,  1.7416,
          1.7501,  1.6901,  1.7427,  1.7283,  1.7412,  1.6063,  1.5887,  1.5846,
          1.5785,  1.6023,  1.5835,  1.6176,  1.5754,  1.5766],
        [ 1.3079,  1.3102,  1.2483,  1.2668,  1.3147,  1.3117,  1.3097,  1.3109,
          1.3109,  2.4981,  2.4521,  2.3597,  2.5409,  2.3818,  2.8936,  2.4640,
          2.4913,  2.8644,  1.2976,  1.3058,  1.2586,  1.2835,  1.3288,  1.3283,
          1.3146,  1.3274,  1.3274,  1.3280,  1.2539,  1.3493,  1.3525,  1.2777,
          1.3509,  1.3538,  1.3228,  1.3496,  1.7605,  1.7730,  1.7275,  1.7558,
          1.7702,  1.7717,  1.7245,  1.6360,  1.7598,  1.5694,  1.6104,  1.6059,
          1.5993,  1.5258,  1.6048,  1.5441,  1.5959,  1.5973],
        [ 1.2857,  1.2886,  1.2919,  1.2903,  1.2884,  1.2863,  1.2865,  1.2855,
          1.2855,  1.3517,  1.3543,  1.3534,  1.3565,  1.3510,  1.3122,  1.3524,
          1.3051,  1.3390,  2.5524,  2.5997,  2.6496,  2.5619,  2.4950,  2.4929,
          2.5797,  2.4868,  2.4868,  1.3004,  1.3144,  1.3243,  1.3273,  1.3011,
          1.3258,  1.3286,  1.3242,  1.3246,  1.7434,  1.7549,  1.7477,  1.7040,
          1.7525,  1.7525,  1.7449,  1.7266,  1.7036,  1.6090,  1.5916,  1.5874,
          1.5812,  1.5849,  1.5864,  1.6029,  1.5779,  1.5793],
        [ 1.2976,  1.3005,  1.3037,  1.3021,  1.3004,  1.2981,  1.2985,  1.2973,
          1.2973,  1.3632,  1.3656,  1.3649,  1.3492,  1.3624,  1.2699,  1.3638,
          1.3603,  1.2677,  1.3179,  1.3000,  1.3193,  1.3190,  1.3153,  1.3147,
          1.3164,  1.3139,  1.3139,  2.7130,  2.6588,  2.4101,  2.5193,  2.7111,
          2.4187,  2.6401,  2.4563,  2.4118,  1.7517,  1.7635,  1.7304,  1.7510,
          1.7610,  1.7610,  1.7276,  1.6853,  1.7506,  1.6191,  1.6005,  1.4976,
          1.5356,  1.6149,  1.5950,  1.6309,  1.5321,  1.5879],
        [ 1.8609,  1.4606,  0.6205,  0.9450,  1.3524,  1.7888,  1.6635,  1.8945,
          1.8945,  1.7338,  1.3460,  1.5426,  0.9401,  1.7597,  0.1459,  1.6618,
          1.9059,  0.8891,  1.3616,  0.9996,  0.7608,  1.1769,  1.7295,  1.7962,
          1.5482,  1.9021,  1.9021,  0.8613,  0.8804,  1.8748,  1.6756,  0.8854,
          1.8155,  1.2844,  1.9237,  1.8392, -0.0585, -0.3117, -0.3516, -0.0964,
          0.1622,  0.2623, -0.1898, 13.4035,  5.6808,  0.2243,  0.5933,  0.6284,
          0.7313,  0.3808,  0.7301, -0.0689,  0.7614,  0.8269],
        [ 1.3388,  1.3762,  1.4211,  1.4086,  1.3834,  1.3461,  1.3166,  1.3353,
          1.3353,  1.3052,  1.4289,  1.3281,  1.4593,  1.3847,  1.4853,  1.3139,
          1.3645,  1.3713,  1.3968,  1.3894,  1.4310,  1.4102,  1.3636,  1.3565,
          1.2706,  1.3451,  1.3451,  1.3978,  1.4402,  1.3588,  1.1586,  1.3540,
          1.2480,  1.4140,  1.2372,  1.3629,  0.3501,  0.2738,  0.3912,  0.3570,
          0.1522,  0.1064,  0.3738,  0.1590, -0.0511,  3.1321,  2.2240,  3.1168,
          2.5158,  1.8062,  1.4136,  2.7477,  2.9111,  1.3782]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 220 : 175.55216596712302
Test loss for epoch 220 : 175.5038755562596
Test Precision for epoch 220 : 0.26153846153846155
Test Recall for epoch 220 : 0.26153846153846155
Test F1 for epoch 220 : 0.26153846153846155


theta for epoch 221 : tensor([[ 2.4919,  2.5109,  2.5475,  2.6433,  2.6248,  2.4953,  2.6117,  2.4904,
          2.4904,  1.3468,  1.3493,  1.3484,  1.3515,  1.3461,  1.3536,  1.3474,
          1.3446,  1.3068,  1.3004,  1.2585,  1.2592,  1.3014,  1.2979,  1.2974,
          1.2997,  1.2966,  1.2966,  1.2816,  1.3258,  1.3196,  1.3226,  1.3259,
          1.3210,  1.3238,  1.2759,  1.3199,  1.7398,  1.7510,  1.7441,  1.7402,
          1.7487,  1.6887,  1.7413,  1.7269,  1.7398,  1.6063,  1.5888,  1.5847,
          1.5786,  1.6024,  1.5837,  1.6175,  1.5755,  1.5768],
        [ 1.3085,  1.3107,  1.2497,  1.2676,  1.3151,  1.3122,  1.3103,  1.3113,
          1.3113,  2.5005,  2.4561,  2.3633,  2.5450,  2.3846,  2.8943,  2.4671,
          2.4959,  2.8652,  1.2965,  1.3046,  1.2574,  1.2828,  1.3276,  1.3271,
          1.3138,  1.3262,  1.3262,  1.3277,  1.2543,  1.3489,  1.3521,  1.2777,
          1.3505,  1.3534,  1.3224,  1.3492,  1.7590,  1.7715,  1.7261,  1.7545,
          1.7688,  1.7702,  1.7231,  1.6364,  1.7584,  1.5696,  1.6105,  1.6061,
          1.5995,  1.5262,  1.6050,  1.5444,  1.5961,  1.5975],
        [ 1.2867,  1.2895,  1.2928,  1.2913,  1.2893,  1.2872,  1.2875,  1.2864,
          1.2864,  1.3518,  1.3543,  1.3535,  1.3566,  1.3511,  1.3120,  1.3524,
          1.3048,  1.3392,  2.5537,  2.6020,  2.6520,  2.5632,  2.4964,  2.4943,
          2.5819,  2.4882,  2.4882,  1.3002,  1.3144,  1.3244,  1.3274,  1.3008,
          1.3258,  1.3286,  1.3243,  1.3247,  1.7422,  1.7537,  1.7466,  1.7024,
          1.7513,  1.7513,  1.7437,  1.7255,  1.7020,  1.6095,  1.5921,  1.5880,
          1.5818,  1.5855,  1.5869,  1.6033,  1.5784,  1.5799],
        [ 1.2981,  1.3010,  1.3042,  1.3027,  1.3009,  1.2987,  1.2991,  1.2978,
          1.2978,  1.3628,  1.3652,  1.3645,  1.3488,  1.3620,  1.2697,  1.3634,
          1.3598,  1.2675,  1.3169,  1.2989,  1.3183,  1.3179,  1.3143,  1.3137,
          1.3154,  1.3129,  1.3129,  2.7160,  2.6617,  2.4129,  2.5219,  2.7141,
          2.4216,  2.6429,  2.4594,  2.4147,  1.7503,  1.7621,  1.7290,  1.7496,
          1.7596,  1.7596,  1.7261,  1.6841,  1.7492,  1.6192,  1.6007,  1.4980,
          1.5359,  1.6151,  1.5953,  1.6310,  1.5324,  1.5882],
        [ 1.8673,  1.4681,  0.6285,  0.9526,  1.3600,  1.7955,  1.6704,  1.9008,
          1.9008,  1.7404,  1.3539,  1.5498,  0.9483,  1.7664,  0.1545,  1.6687,
          1.9127,  0.8974,  1.3691,  1.0077,  0.7693,  1.1844,  1.7364,  1.8029,
          1.5552,  1.9086,  1.9086,  0.8697,  0.8884,  1.8819,  1.6830,  0.8938,
          1.8228,  1.2922,  1.9306,  1.8463, -0.0665, -0.3193, -0.3593, -0.1046,
          0.1537,  0.2537, -0.1976, 13.4396,  5.6560,  0.2327,  0.6012,  0.6361,
          0.7391,  0.3890,  0.7379, -0.0602,  0.7691,  0.8346],
        [ 1.3324,  1.3699,  1.4149,  1.4023,  1.3771,  1.3398,  1.3101,  1.3289,
          1.3289,  1.2971,  1.4209,  1.3200,  1.4512,  1.3768,  1.4772,  1.3058,
          1.3563,  1.3632,  1.3884,  1.3805,  1.4227,  1.4019,  1.3552,  1.3481,
          1.2617,  1.3367,  1.3367,  1.3906,  1.4333,  1.3516,  1.1507,  1.3468,
          1.2407,  1.4069,  1.2297,  1.3558,  0.3412,  0.2650,  0.3823,  0.3481,
          0.1432,  0.0974,  0.3649,  0.1497, -0.0604,  3.1446,  2.2339,  3.1295,
          2.5263,  1.8155,  1.4226,  2.7580,  2.9242,  1.3871]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 221 : 175.5506558791176
Test loss for epoch 221 : 175.49104043892476
Test Precision for epoch 221 : 0.26153846153846155
Test Recall for epoch 221 : 0.26153846153846155
Test F1 for epoch 221 : 0.26153846153846155


theta for epoch 222 : tensor([[ 2.4941,  2.5131,  2.5497,  2.6457,  2.6272,  2.4975,  2.6141,  2.4926,
          2.4926,  1.3460,  1.3485,  1.3477,  1.3508,  1.3453,  1.3528,  1.3467,
          1.3439,  1.3060,  1.3003,  1.2584,  1.2591,  1.3013,  1.2978,  1.2973,
          1.2996,  1.2965,  1.2965,  1.2805,  1.3247,  1.3185,  1.3215,  1.3248,
          1.3199,  1.3227,  1.2748,  1.3188,  1.7405,  1.7518,  1.7448,  1.7410,
          1.7494,  1.6895,  1.7420,  1.7277,  1.7405,  1.6060,  1.5885,  1.5844,
          1.5784,  1.6021,  1.5834,  1.6172,  1.5752,  1.5765],
        [ 1.3078,  1.3100,  1.2497,  1.2671,  1.3143,  1.3113,  1.3095,  1.3105,
          1.3105,  2.5022,  2.4593,  2.3663,  2.5483,  2.3866,  2.8944,  2.4696,
          2.4998,  2.8653,  1.2967,  1.3047,  1.2575,  1.2834,  1.3276,  1.3271,
          1.3143,  1.3262,  1.3262,  1.3265,  1.2540,  1.3478,  1.3509,  1.2770,
          1.3493,  1.3522,  1.3213,  1.3481,  1.7597,  1.7722,  1.7269,  1.7553,
          1.7695,  1.7709,  1.7238,  1.6387,  1.7590,  1.5695,  1.6103,  1.6058,
          1.5993,  1.5262,  1.6048,  1.5443,  1.5959,  1.5973],
        [ 1.2858,  1.2886,  1.2919,  1.2904,  1.2885,  1.2864,  1.2866,  1.2856,
          1.2856,  1.3510,  1.3535,  1.3527,  1.3557,  1.3503,  1.3109,  1.3516,
          1.3037,  1.3384,  2.5565,  2.6058,  2.6557,  2.5660,  2.4992,  2.4970,
          2.5856,  2.4910,  2.4910,  1.2987,  1.3133,  1.3233,  1.3263,  1.2993,
          1.3247,  1.3275,  1.3232,  1.3236,  1.7430,  1.7545,  1.7474,  1.7027,
          1.7521,  1.7521,  1.7445,  1.7264,  1.7023,  1.6092,  1.5919,  1.5877,
          1.5815,  1.5852,  1.5867,  1.6029,  1.5782,  1.5796],
        [ 1.2973,  1.3002,  1.3034,  1.3018,  1.3001,  1.2979,  1.2983,  1.2970,
          1.2970,  1.3620,  1.3644,  1.3637,  1.3479,  1.3613,  1.2690,  1.3627,
          1.3591,  1.2669,  1.3168,  1.2988,  1.3182,  1.3178,  1.3142,  1.3137,
          1.3153,  1.3129,  1.3129,  2.7183,  2.6638,  2.4151,  2.5237,  2.7164,
          2.4237,  2.6450,  2.4617,  2.4168,  1.7511,  1.7629,  1.7297,  1.7504,
          1.7604,  1.7604,  1.7269,  1.6852,  1.7499,  1.6189,  1.6005,  1.4980,
          1.5356,  1.6148,  1.5950,  1.6307,  1.5321,  1.5880],
        [ 1.8632,  1.4630,  0.6222,  0.9471,  1.3549,  1.7913,  1.6658,  1.8970,
          1.8970,  1.7349,  1.3480,  1.5446,  0.9422,  1.7611,  0.1478,  1.6633,
          1.9086,  0.8901,  1.3637,  1.0025,  0.7634,  1.1785,  1.7318,  1.7985,
          1.5506,  1.9044,  1.9044,  0.8636,  0.8815,  1.8768,  1.6777,  0.8873,
          1.8175,  1.2861,  1.9256,  1.8411, -0.0621, -0.3149, -0.3551, -0.1003,
          0.1579,  0.2579, -0.1932, 13.4883,  5.6459,  0.2261,  0.5945,  0.6294,
          0.7323,  0.3823,  0.7312, -0.0667,  0.7625,  0.8279],
        [ 1.3385,  1.3759,  1.4207,  1.4082,  1.3831,  1.3458,  1.3162,  1.3350,
          1.3350,  1.3045,  1.4280,  1.3272,  1.4583,  1.3840,  1.4843,  1.3130,
          1.3635,  1.3704,  1.3958,  1.3877,  1.4300,  1.4093,  1.3626,  1.3555,
          1.2690,  1.3441,  1.3441,  1.3967,  1.4393,  1.3578,  1.1570,  1.3530,
          1.2470,  1.4130,  1.2361,  1.3619,  0.3483,  0.2722,  0.3893,  0.3553,
          0.1504,  0.1046,  0.3720,  0.1567, -0.0532,  3.1406,  2.2273,  3.1255,
          2.5202,  1.8083,  1.4152,  2.7519,  2.9205,  1.3797]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 222 : 175.51585257236977
Test loss for epoch 222 : 175.47073709650468
Test Precision for epoch 222 : 0.26153846153846155
Test Recall for epoch 222 : 0.26153846153846155
Test F1 for epoch 222 : 0.26153846153846155


theta for epoch 223 : tensor([[ 2.4948,  2.5138,  2.5505,  2.6467,  2.6282,  2.4982,  2.6151,  2.4933,
          2.4933,  1.3456,  1.3481,  1.3472,  1.3503,  1.3449,  1.3524,  1.3462,
          1.3435,  1.3056,  1.2994,  1.2575,  1.2582,  1.3004,  1.2969,  1.2964,
          1.2987,  1.2956,  1.2956,  1.2798,  1.3239,  1.3178,  1.3207,  1.3241,
          1.3192,  1.3219,  1.2741,  1.3181,  1.7403,  1.7515,  1.7446,  1.7407,
          1.7492,  1.6892,  1.7417,  1.7274,  1.7402,  1.6109,  1.5935,  1.5894,
          1.5834,  1.6070,  1.5884,  1.6221,  1.5803,  1.5815],
        [ 1.3060,  1.3083,  1.2488,  1.2656,  1.3124,  1.3094,  1.3077,  1.3086,
          1.3086,  2.5035,  2.4623,  2.3690,  2.5515,  2.3884,  2.8944,  2.4718,
          2.5033,  2.8653,  1.2955,  1.3033,  1.2562,  1.2826,  1.3262,  1.3257,
          1.3133,  1.3249,  1.3249,  1.3255,  1.2538,  1.3468,  1.3499,  1.2763,
          1.3483,  1.3512,  1.3204,  1.3471,  1.7593,  1.7717,  1.7265,  1.7550,
          1.7690,  1.7704,  1.7234,  1.6399,  1.7585,  1.5749,  1.6155,  1.6111,
          1.6044,  1.5316,  1.6099,  1.5496,  1.6011,  1.6024],
        [ 1.2840,  1.2868,  1.2900,  1.2885,  1.2866,  1.2845,  1.2848,  1.2837,
          1.2837,  1.3503,  1.3528,  1.3520,  1.3550,  1.3496,  1.3099,  1.3509,
          1.3026,  1.3377,  2.5580,  2.6082,  2.6582,  2.5675,  2.5007,  2.4985,
          2.5879,  2.4925,  2.4925,  1.2975,  1.3124,  1.3224,  1.3254,  1.2981,
          1.3239,  1.3266,  1.3223,  1.3227,  1.7427,  1.7541,  1.7470,  1.7019,
          1.7517,  1.7517,  1.7442,  1.7261,  1.7014,  1.6140,  1.5967,  1.5926,
          1.5864,  1.5900,  1.5915,  1.6077,  1.5830,  1.5845],
        [ 1.2955,  1.2984,  1.3016,  1.3001,  1.2983,  1.2961,  1.2965,  1.2953,
          1.2953,  1.3614,  1.3638,  1.3631,  1.3472,  1.3606,  1.2686,  1.3620,
          1.3584,  1.2664,  1.3157,  1.2976,  1.3170,  1.3167,  1.3131,  1.3125,
          1.3142,  1.3117,  1.3117,  2.7201,  2.6654,  2.4167,  2.5251,  2.7182,
          2.4254,  2.6465,  2.4635,  2.4185,  1.7507,  1.7625,  1.7293,  1.7500,
          1.7600,  1.7600,  1.7265,  1.6851,  1.7495,  1.6235,  1.6051,  1.5029,
          1.5402,  1.6194,  1.5996,  1.6352,  1.5368,  1.5926],
        [ 1.8641,  1.4642,  0.6239,  0.9487,  1.3563,  1.7924,  1.6669,  1.8979,
          1.8979,  1.7365,  1.3503,  1.5467,  0.9447,  1.7628,  0.1502,  1.6652,
          1.9109,  0.8922,  1.3658,  1.0051,  0.7660,  1.1805,  1.7338,  1.8004,
          1.5527,  1.9063,  1.9063,  0.8660,  0.8834,  1.8786,  1.6797,  0.8896,
          1.8194,  1.2882,  1.9274,  1.8430, -0.0652, -0.3178, -0.3580, -0.1035,
          0.1545,  0.2543, -0.1962, 13.5292,  5.6267,  0.2296,  0.5979,  0.6326,
          0.7357,  0.3856,  0.7347, -0.0632,  0.7659,  0.8313],
        [ 1.3353,  1.3728,  1.4176,  1.4051,  1.3800,  1.3427,  1.3131,  1.3318,
          1.3318,  1.3018,  1.4253,  1.3244,  1.4556,  1.3813,  1.4815,  1.3103,
          1.3606,  1.3677,  1.3929,  1.3844,  1.4270,  1.4063,  1.3596,  1.3526,
          1.2656,  1.3412,  1.3412,  1.3940,  1.4367,  1.3551,  1.1540,  1.3503,
          1.2443,  1.4104,  1.2334,  1.3593,  0.3454,  0.2694,  0.3863,  0.3523,
          0.1473,  0.1016,  0.3691,  0.1535, -0.0564,  3.1475,  2.2317,  3.1325,
          2.5251,  1.8121,  1.4187,  2.7568,  2.9280,  1.3832]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 223 : 175.48992980478968
Test loss for epoch 223 : 175.44319311647405
Test Precision for epoch 223 : 0.26153846153846155
Test Recall for epoch 223 : 0.26153846153846155
Test F1 for epoch 223 : 0.26153846153846155


theta for epoch 224 : tensor([[ 2.4968,  2.5158,  2.5525,  2.6490,  2.6305,  2.5002,  2.6174,  2.4953,
          2.4953,  1.3457,  1.3482,  1.3473,  1.3504,  1.3450,  1.3525,  1.3463,
          1.3435,  1.3057,  1.2991,  1.2572,  1.2579,  1.3001,  1.2967,  1.2962,
          1.2985,  1.2954,  1.2954,  1.2799,  1.3241,  1.3179,  1.3209,  1.3242,
          1.3194,  1.3221,  1.2743,  1.3182,  1.7400,  1.7512,  1.7443,  1.7404,
          1.7489,  1.6889,  1.7415,  1.7271,  1.7399,  1.6106,  1.5932,  1.5891,
          1.5831,  1.6067,  1.5881,  1.6217,  1.5800,  1.5813],
        [ 1.3058,  1.3081,  1.2493,  1.2656,  1.3121,  1.3091,  1.3075,  1.3082,
          1.3082,  2.5050,  2.4654,  2.3718,  2.5547,  2.3904,  2.8945,  2.4741,
          2.5070,  2.8654,  1.2954,  1.3031,  1.2560,  1.2829,  1.3260,  1.3255,
          1.3135,  1.3246,  1.3246,  1.3257,  1.2547,  1.3469,  1.3501,  1.2769,
          1.3485,  1.3514,  1.3206,  1.3472,  1.7589,  1.7714,  1.7262,  1.7548,
          1.7686,  1.7701,  1.7231,  1.6411,  1.7581,  1.5747,  1.6152,  1.6108,
          1.6042,  1.5315,  1.6097,  1.5494,  1.6008,  1.6022],
        [ 1.2838,  1.2866,  1.2898,  1.2883,  1.2864,  1.2843,  1.2846,  1.2835,
          1.2835,  1.3506,  1.3531,  1.3522,  1.3553,  1.3499,  1.3098,  1.3512,
          1.3025,  1.3380,  2.5596,  2.6107,  2.6608,  2.5690,  2.5023,  2.5000,
          2.5903,  2.4940,  2.4940,  1.2975,  1.3127,  1.3227,  1.3257,  1.2981,
          1.3241,  1.3269,  1.3226,  1.3230,  1.7425,  1.7539,  1.7468,  1.7013,
          1.7515,  1.7515,  1.7440,  1.7260,  1.7008,  1.6138,  1.5965,  1.5924,
          1.5863,  1.5898,  1.5914,  1.6074,  1.5829,  1.5844],
        [ 1.2953,  1.2982,  1.3013,  1.2999,  1.2981,  1.2959,  1.2963,  1.2950,
          1.2950,  1.3616,  1.3640,  1.3632,  1.3474,  1.3608,  1.2690,  1.3622,
          1.3586,  1.2669,  1.3155,  1.2974,  1.3168,  1.3165,  1.3129,  1.3124,
          1.3140,  1.3116,  1.3116,  2.7225,  2.6675,  2.4190,  2.5271,  2.7206,
          2.4276,  2.6487,  2.4659,  2.4207,  1.7504,  1.7622,  1.7290,  1.7497,
          1.7598,  1.7597,  1.7261,  1.6851,  1.7492,  1.6232,  1.6049,  1.5030,
          1.5401,  1.6191,  1.5994,  1.6349,  1.5366,  1.5925],
        [ 1.8659,  1.4662,  0.6259,  0.9507,  1.3584,  1.7942,  1.6688,  1.8997,
          1.8997,  1.7382,  1.3526,  1.5488,  0.9471,  1.7647,  0.1526,  1.6672,
          1.9134,  0.8942,  1.3679,  1.0077,  0.7686,  1.1825,  1.7359,  1.8025,
          1.5549,  1.9084,  1.9084,  0.8686,  0.8855,  1.8810,  1.6822,  0.8921,
          1.8218,  1.2906,  1.9298,  1.8454, -0.0681, -0.3204, -0.3607, -0.1064,
          0.1513,  0.2510, -0.1990, 13.5704,  5.6074,  0.2318,  0.5998,  0.6345,
          0.7376,  0.3877,  0.7366, -0.0609,  0.7678,  0.8332],
        [ 1.3333,  1.3708,  1.4155,  1.4030,  1.3779,  1.3406,  1.3110,  1.3298,
          1.3298,  1.2996,  1.4231,  1.3222,  1.4534,  1.3792,  1.4792,  1.3081,
          1.3583,  1.3656,  1.3905,  1.3816,  1.4246,  1.4040,  1.3572,  1.3502,
          1.2629,  1.3387,  1.3387,  1.3921,  1.4349,  1.3533,  1.1517,  1.3484,
          1.2424,  1.4086,  1.2314,  1.3574,  0.3427,  0.2667,  0.3835,  0.3496,
          0.1446,  0.0988,  0.3664,  0.1505, -0.0594,  3.1537,  2.2352,  3.1387,
          2.5292,  1.8150,  1.4214,  2.7608,  2.9347,  1.3859]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 224 : 175.49119050771645
Test loss for epoch 224 : 175.44347430620462
Test Precision for epoch 224 : 0.26153846153846155
Test Recall for epoch 224 : 0.26153846153846155
Test F1 for epoch 224 : 0.26153846153846155


theta for epoch 225 : tensor([[ 2.5002,  2.5192,  2.5559,  2.6526,  2.6341,  2.5036,  2.6210,  2.4987,
          2.4987,  1.3459,  1.3483,  1.3475,  1.3506,  1.3452,  1.3526,  1.3465,
          1.3437,  1.3059,  1.2999,  1.2580,  1.2587,  1.3009,  1.2974,  1.2969,
          1.2992,  1.2961,  1.2961,  1.2803,  1.3245,  1.3183,  1.3213,  1.3246,
          1.3198,  1.3225,  1.2747,  1.3186,  1.7407,  1.7519,  1.7450,  1.7412,
          1.7496,  1.6896,  1.7422,  1.7278,  1.7406,  1.6039,  1.5866,  1.5825,
          1.5765,  1.6001,  1.5816,  1.6151,  1.5734,  1.5747],
        [ 1.3071,  1.3094,  1.2514,  1.2672,  1.3133,  1.3104,  1.3089,  1.3095,
          1.3095,  2.5064,  2.4683,  2.3745,  2.5578,  2.3922,  2.8945,  2.4763,
          2.5105,  2.8654,  1.2969,  1.3046,  1.2574,  1.2848,  1.3274,  1.3269,
          1.3152,  1.3260,  1.3260,  1.3265,  1.2562,  1.3477,  1.3508,  1.2780,
          1.3492,  1.3521,  1.3213,  1.3480,  1.7597,  1.7722,  1.7270,  1.7557,
          1.7694,  1.7709,  1.7239,  1.6434,  1.7589,  1.5678,  1.6083,  1.6039,
          1.5974,  1.5249,  1.6029,  1.5427,  1.5940,  1.5955],
        [ 1.2852,  1.2880,  1.2913,  1.2898,  1.2879,  1.2858,  1.2860,  1.2850,
          1.2850,  1.3513,  1.3538,  1.3529,  1.3560,  1.3506,  1.3102,  1.3519,
          1.3029,  1.3387,  2.5619,  2.6139,  2.6640,  2.5713,  2.5046,  2.5023,
          2.5934,  2.4963,  2.4963,  1.2979,  1.3135,  1.3234,  1.3264,  1.2986,
          1.3249,  1.3276,  1.3234,  1.3238,  1.7434,  1.7548,  1.7478,  1.7017,
          1.7524,  1.7524,  1.7449,  1.7270,  1.7012,  1.6075,  1.5902,  1.5861,
          1.5800,  1.5836,  1.5851,  1.6010,  1.5766,  1.5781],
        [ 1.2966,  1.2994,  1.3026,  1.3011,  1.2993,  1.2971,  1.2975,  1.2963,
          1.2963,  1.3623,  1.3647,  1.3639,  1.3481,  1.3615,  1.2699,  1.3629,
          1.3593,  1.2677,  1.3167,  1.2985,  1.3180,  1.3177,  1.3141,  1.3135,
          1.3151,  1.3127,  1.3127,  2.7250,  2.6699,  2.4214,  2.5292,  2.7231,
          2.4301,  2.6510,  2.4685,  2.4232,  1.7514,  1.7631,  1.7299,  1.7506,
          1.7607,  1.7606,  1.7270,  1.6863,  1.7501,  1.6172,  1.5989,  1.4973,
          1.5341,  1.6131,  1.5935,  1.6289,  1.5306,  1.5865],
        [ 1.8640,  1.4634,  0.6217,  0.9472,  1.3555,  1.7923,  1.6665,  1.8980,
          1.8980,  1.7344,  1.3484,  1.5452,  0.9427,  1.7610,  0.1476,  1.6635,
          1.9108,  0.8888,  1.3641,  1.0040,  0.7643,  1.1782,  1.7328,  1.7996,
          1.5518,  1.9057,  1.9057,  0.8645,  0.8808,  1.8782,  1.6790,  0.8876,
          1.8188,  1.2866,  1.9271,  1.8424, -0.0649, -0.3171, -0.3576, -0.1033,
          0.1544,  0.2540, -0.1958, 13.6177,  5.5952,  0.2256,  0.5933,  0.6278,
          0.7309,  0.3812,  0.7299, -0.0669,  0.7612,  0.8265],
        [ 1.3387,  1.3761,  1.4209,  1.4084,  1.3833,  1.3460,  1.3164,  1.3352,
          1.3352,  1.3052,  1.4286,  1.3277,  1.4589,  1.3847,  1.4848,  1.3137,
          1.3638,  1.3711,  1.3961,  1.3870,  1.4302,  1.4096,  1.3628,  1.3558,
          1.2683,  1.3444,  1.3444,  1.3973,  1.4400,  1.3584,  1.1568,  1.3535,
          1.2476,  1.4137,  1.2367,  1.3626,  0.3477,  0.2719,  0.3886,  0.3547,
          0.1497,  0.1040,  0.3715,  0.1554, -0.0544,  3.1512,  2.2301,  3.1361,
          2.5246,  1.8092,  1.4153,  2.7562,  2.9325,  1.3798]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 225 : 175.49759357727305
Test loss for epoch 225 : 175.46179443187071
Test Precision for epoch 225 : 0.26153846153846155
Test Recall for epoch 225 : 0.26153846153846155
Test F1 for epoch 225 : 0.26153846153846155


theta for epoch 226 : tensor([[ 2.5021,  2.5211,  2.5578,  2.6547,  2.6361,  2.5055,  2.6231,  2.5006,
          2.5006,  1.3457,  1.3481,  1.3473,  1.3503,  1.3449,  1.3524,  1.3462,
          1.3435,  1.3056,  1.2990,  1.2571,  1.2579,  1.3000,  1.2966,  1.2961,
          1.2984,  1.2953,  1.2953,  1.2802,  1.3244,  1.3182,  1.3212,  1.3245,
          1.3197,  1.3224,  1.2746,  1.3185,  1.7401,  1.7513,  1.7444,  1.7406,
          1.7490,  1.6890,  1.7416,  1.7272,  1.7400,  1.6057,  1.5885,  1.5844,
          1.5785,  1.6019,  1.5835,  1.6169,  1.5754,  1.5767],
        [ 1.3071,  1.3095,  1.2521,  1.2674,  1.3132,  1.3103,  1.3088,  1.3094,
          1.3094,  2.5079,  2.4713,  2.3772,  2.5609,  2.3941,  2.8946,  2.4785,
          2.5141,  2.8655,  1.2957,  1.3033,  1.2562,  1.2840,  1.3261,  1.3256,
          1.3143,  1.3247,  1.3247,  1.3262,  1.2566,  1.3473,  1.3505,  1.2780,
          1.3489,  1.3518,  1.3210,  1.3476,  1.7590,  1.7714,  1.7263,  1.7551,
          1.7687,  1.7701,  1.7233,  1.6443,  1.7581,  1.5697,  1.6101,  1.6058,
          1.5993,  1.5269,  1.6047,  1.5446,  1.5959,  1.5973],
        [ 1.2854,  1.2882,  1.2915,  1.2900,  1.2881,  1.2860,  1.2862,  1.2852,
          1.2852,  1.3511,  1.3535,  1.3527,  1.3558,  1.3503,  1.3097,  1.3517,
          1.3023,  1.3385,  2.5627,  2.6157,  2.6658,  2.5721,  2.5054,  2.5031,
          2.5951,  2.4971,  2.4971,  1.2976,  1.3135,  1.3234,  1.3264,  1.2982,
          1.3249,  1.3276,  1.3233,  1.3237,  1.7428,  1.7543,  1.7472,  1.7008,
          1.7519,  1.7518,  1.7444,  1.7265,  1.7002,  1.6093,  1.5922,  1.5881,
          1.5820,  1.5855,  1.5871,  1.6027,  1.5786,  1.5802],
        [ 1.2968,  1.2996,  1.3028,  1.3013,  1.2995,  1.2973,  1.2977,  1.2965,
          1.2965,  1.3621,  1.3645,  1.3637,  1.3478,  1.3613,  1.2699,  1.3627,
          1.3591,  1.2678,  1.3159,  1.2977,  1.3172,  1.3169,  1.3133,  1.3128,
          1.3143,  1.3120,  1.3120,  2.7266,  2.6713,  2.4230,  2.5304,  2.7247,
          2.4316,  2.6524,  2.4702,  2.4247,  1.7508,  1.7625,  1.7293,  1.7501,
          1.7601,  1.7600,  1.7264,  1.6860,  1.7495,  1.6189,  1.6007,  1.4995,
          1.5360,  1.6149,  1.5954,  1.6306,  1.5325,  1.5884],
        [ 1.8685,  1.4687,  0.6276,  0.9528,  1.3610,  1.7970,  1.6714,  1.9025,
          1.9025,  1.7391,  1.3542,  1.5504,  0.9488,  1.7659,  0.1540,  1.6685,
          1.9158,  0.8949,  1.3696,  1.0100,  0.7707,  1.1837,  1.7377,  1.8044,
          1.5569,  1.9103,  1.9103,  0.8708,  0.8867,  1.8833,  1.6845,  0.8939,
          1.8241,  1.2924,  1.9322,  1.8476, -0.0710, -0.3229, -0.3635, -0.1096,
          0.1478,  0.2473, -0.2017, 13.6553,  5.5717,  0.2323,  0.5998,  0.6342,
          0.7374,  0.3878,  0.7365, -0.0601,  0.7677,  0.8329],
        [ 1.3330,  1.3706,  1.4153,  1.4028,  1.3777,  1.3404,  1.3107,  1.3295,
          1.3295,  1.2984,  1.4219,  1.3208,  1.4521,  1.3780,  1.4779,  1.3068,
          1.3569,  1.3644,  1.3891,  1.3795,  1.4231,  1.4026,  1.3557,  1.3487,
          1.2607,  1.3372,  1.3372,  1.3912,  1.4342,  1.3524,  1.1501,  1.3475,
          1.2414,  1.4078,  1.2304,  1.3565,  0.3407,  0.2648,  0.3814,  0.3477,
          0.1424,  0.0967,  0.3644,  0.1480, -0.0619,  3.1622,  2.2385,  3.1472,
          2.5335,  1.8170,  1.4228,  2.7650,  2.9441,  1.3873]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 226 : 175.48078721990845
Test loss for epoch 226 : 175.43686883758036
Test Precision for epoch 226 : 0.26153846153846155
Test Recall for epoch 226 : 0.26153846153846155
Test F1 for epoch 226 : 0.26153846153846155


theta for epoch 227 : tensor([[ 2.5026,  2.5216,  2.5583,  2.6554,  2.6369,  2.5060,  2.6238,  2.5011,
          2.5011,  1.3455,  1.3479,  1.3471,  1.3501,  1.3447,  1.3522,  1.3461,
          1.3433,  1.3054,  1.2994,  1.2575,  1.2583,  1.3004,  1.2970,  1.2965,
          1.2988,  1.2957,  1.2957,  1.2798,  1.3240,  1.3178,  1.3208,  1.3241,
          1.3193,  1.3220,  1.2742,  1.3181,  1.7411,  1.7523,  1.7454,  1.7415,
          1.7499,  1.6899,  1.7426,  1.7281,  1.7409,  1.6078,  1.5905,  1.5865,
          1.5806,  1.6040,  1.5856,  1.6189,  1.5775,  1.5788],
        [ 1.3059,  1.3082,  1.2516,  1.2664,  1.3119,  1.3089,  1.3076,  1.3081,
          1.3081,  2.5090,  2.4740,  2.3797,  2.5638,  2.3957,  2.8945,  2.4805,
          2.5174,  2.8655,  1.2955,  1.3030,  1.2559,  1.2841,  1.3257,  1.3252,
          1.3143,  1.3243,  1.3243,  1.3254,  1.2564,  1.3464,  1.3496,  1.2775,
          1.3480,  1.3509,  1.3202,  1.3468,  1.7597,  1.7721,  1.7271,  1.7559,
          1.7694,  1.7708,  1.7240,  1.6464,  1.7588,  1.5716,  1.6119,  1.6076,
          1.6011,  1.5289,  1.6065,  1.5465,  1.5977,  1.5991],
        [ 1.2841,  1.2869,  1.2901,  1.2886,  1.2867,  1.2846,  1.2849,  1.2838,
          1.2838,  1.3502,  1.3527,  1.3518,  1.3549,  1.3495,  1.3085,  1.3508,
          1.3011,  1.3377,  2.5647,  2.6186,  2.6687,  2.5741,  2.5073,  2.5050,
          2.5979,  2.4991,  2.4991,  1.2965,  1.3126,  1.3226,  1.3256,  1.2971,
          1.3240,  1.3268,  1.3225,  1.3229,  1.7437,  1.7551,  1.7480,  1.7011,
          1.7527,  1.7526,  1.7452,  1.7274,  1.7005,  1.6110,  1.5939,  1.5898,
          1.5837,  1.5872,  1.5888,  1.6043,  1.5803,  1.5819],
        [ 1.2956,  1.2984,  1.3016,  1.3001,  1.2983,  1.2961,  1.2965,  1.2953,
          1.2953,  1.3614,  1.3638,  1.3631,  1.3472,  1.3607,  1.2695,  1.3621,
          1.3585,  1.2674,  1.3157,  1.2975,  1.3171,  1.3168,  1.3132,  1.3126,
          1.3142,  1.3118,  1.3118,  2.7281,  2.6726,  2.4244,  2.5316,  2.7263,
          2.4331,  2.6537,  2.4718,  2.4262,  1.7516,  1.7634,  1.7301,  1.7509,
          1.7609,  1.7609,  1.7272,  1.6872,  1.7503,  1.6206,  1.6024,  1.5014,
          1.5378,  1.6166,  1.5971,  1.6323,  1.5342,  1.5902],
        [ 1.8652,  1.4648,  0.6230,  0.9487,  1.3571,  1.7937,  1.6678,  1.8994,
          1.8994,  1.7351,  1.3501,  1.5468,  0.9447,  1.7621,  0.1494,  1.6647,
          1.9130,  0.8898,  1.3658,  1.0066,  0.7667,  1.1796,  1.7345,  1.8013,
          1.5537,  1.9074,  1.9074,  0.8667,  0.8820,  1.8799,  1.6809,  0.8895,
          1.8205,  1.2883,  1.9288,  1.8441, -0.0682, -0.3201, -0.3608, -0.1069,
          0.1504,  0.2498, -0.1989, 13.7020,  5.5586,  0.2284,  0.5960,  0.6303,
          0.7336,  0.3838,  0.7327, -0.0641,  0.7639,  0.8292],
        [ 1.3362,  1.3736,  1.4183,  1.4059,  1.3808,  1.3435,  1.3139,  1.3326,
          1.3326,  1.3027,  1.4260,  1.3251,  1.4562,  1.3822,  1.4820,  1.3111,
          1.3610,  1.3686,  1.3934,  1.3835,  1.4274,  1.4069,  1.3600,  1.3530,
          1.2649,  1.3415,  1.3415,  1.3948,  1.4377,  1.3560,  1.1538,  1.3511,
          1.2451,  1.4114,  1.2341,  1.3601,  0.3450,  0.2692,  0.3857,  0.3521,
          0.1468,  0.1011,  0.3687,  0.1522, -0.0576,  3.1614,  2.2350,  3.1464,
          2.5306,  1.8130,  1.4186,  2.7621,  2.9436,  1.3831]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 227 : 175.45339038233357
Test loss for epoch 227 : 175.41988655305994
Test Precision for epoch 227 : 0.26153846153846155
Test Recall for epoch 227 : 0.26153846153846155
Test F1 for epoch 227 : 0.26153846153846155


theta for epoch 228 : tensor([[ 2.5042,  2.5232,  2.5599,  2.6572,  2.6387,  2.5076,  2.6256,  2.5027,
          2.5027,  1.3452,  1.3476,  1.3468,  1.3498,  1.3445,  1.3519,  1.3458,
          1.3430,  1.3051,  1.2991,  1.2572,  1.2579,  1.3001,  1.2966,  1.2961,
          1.2984,  1.2953,  1.2953,  1.2793,  1.3235,  1.3174,  1.3204,  1.3236,
          1.3188,  1.3215,  1.2738,  1.3177,  1.7408,  1.7520,  1.7452,  1.7413,
          1.7497,  1.6897,  1.7423,  1.7279,  1.7407,  1.6099,  1.5927,  1.5887,
          1.5828,  1.6061,  1.5878,  1.6210,  1.5797,  1.5810],
        [ 1.3049,  1.3073,  1.2514,  1.2657,  1.3108,  1.3079,  1.3066,  1.3070,
          1.3070,  2.5111,  2.4775,  2.3830,  2.5675,  2.3982,  2.8952,  2.4834,
          2.5215,  2.8662,  1.2947,  1.3021,  1.2550,  1.2836,  1.3248,  1.3243,
          1.3137,  1.3234,  1.3234,  1.3246,  1.2564,  1.3457,  1.3488,  1.2771,
          1.3472,  1.3501,  1.3194,  1.3460,  1.7593,  1.7716,  1.7267,  1.7556,
          1.7689,  1.7704,  1.7236,  1.6474,  1.7583,  1.5737,  1.6140,  1.6096,
          1.6031,  1.5311,  1.6086,  1.5486,  1.5997,  1.6012],
        [ 1.2832,  1.2860,  1.2892,  1.2877,  1.2858,  1.2837,  1.2840,  1.2829,
          1.2829,  1.3496,  1.3520,  1.3512,  1.3542,  1.3488,  1.3076,  1.3502,
          1.3001,  1.3371,  2.5669,  2.6217,  2.6719,  2.5763,  2.5096,  2.5072,
          2.6009,  2.5013,  2.5013,  1.2956,  1.3120,  1.3220,  1.3250,  1.2962,
          1.3234,  1.3262,  1.3219,  1.3223,  1.7434,  1.7548,  1.7478,  1.7004,
          1.7524,  1.7523,  1.7449,  1.7272,  1.6998,  1.6129,  1.5958,  1.5918,
          1.5857,  1.5891,  1.5908,  1.6062,  1.5823,  1.5839],
        [ 1.2946,  1.2975,  1.3006,  1.2992,  1.2974,  1.2952,  1.2956,  1.2944,
          1.2944,  1.3608,  1.3631,  1.3624,  1.3464,  1.3600,  1.2690,  1.3614,
          1.3578,  1.2670,  1.3149,  1.2967,  1.3163,  1.3160,  1.3124,  1.3118,
          1.3134,  1.3110,  1.3110,  2.7307,  2.6751,  2.4270,  2.5338,  2.7289,
          2.4356,  2.6561,  2.4745,  2.4287,  1.7513,  1.7630,  1.7297,  1.7505,
          1.7606,  1.7605,  1.7268,  1.6872,  1.7499,  1.6224,  1.6043,  1.5035,
          1.5396,  1.6184,  1.5989,  1.6340,  1.5361,  1.5920],
        [ 1.8655,  1.4652,  0.6233,  0.9491,  1.3576,  1.7940,  1.6681,  1.8997,
          1.8997,  1.7354,  1.3507,  1.5474,  0.9454,  1.7625,  0.1499,  1.6651,
          1.9140,  0.8900,  1.3665,  1.0076,  0.7676,  1.1801,  1.7352,  1.8020,
          1.5545,  1.9081,  1.9081,  0.8675,  0.8822,  1.8805,  1.6816,  0.8901,
          1.8211,  1.2888,  1.9294,  1.8448, -0.0696, -0.3213, -0.3621, -0.1084,
          0.1487,  0.2480, -0.2002, 13.7444,  5.5403,  0.2295,  0.5970,  0.6313,
          0.7347,  0.3848,  0.7338, -0.0630,  0.7651,  0.8304],
        [ 1.3357,  1.3732,  1.4178,  1.4054,  1.3803,  1.3430,  1.3134,  1.3321,
          1.3321,  1.3026,  1.4258,  1.3249,  1.4560,  1.3821,  1.4817,  1.3109,
          1.3608,  1.3684,  1.3931,  1.3829,  1.4271,  1.4066,  1.3597,  1.3527,
          1.2643,  1.3413,  1.3413,  1.3945,  1.4375,  1.3558,  1.1533,  1.3508,
          1.2449,  1.4111,  1.2339,  1.3599,  0.3445,  0.2688,  0.3851,  0.3516,
          0.1463,  0.1005,  0.3682,  0.1515, -0.0583,  3.1654,  2.2365,  3.1504,
          2.5326,  1.8139,  1.4192,  2.7640,  2.9482,  1.3837]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 228 : 175.44220217569261
Test loss for epoch 228 : 175.4107749522709
Test Precision for epoch 228 : 0.26153846153846155
Test Recall for epoch 228 : 0.26153846153846155
Test F1 for epoch 228 : 0.26153846153846155


theta for epoch 229 : tensor([[ 2.5077,  2.5266,  2.5633,  2.6609,  2.6424,  2.5110,  2.6293,  2.5061,
          2.5061,  1.3450,  1.3474,  1.3465,  1.3496,  1.3442,  1.3516,  1.3455,
          1.3427,  1.3049,  1.2985,  1.2566,  1.2573,  1.2995,  1.2960,  1.2955,
          1.2978,  1.2947,  1.2947,  1.2791,  1.3233,  1.3172,  1.3201,  1.3234,
          1.3186,  1.3213,  1.2735,  1.3175,  1.7399,  1.7511,  1.7442,  1.7404,
          1.7487,  1.6887,  1.7414,  1.7269,  1.7397,  1.6085,  1.5914,  1.5874,
          1.5815,  1.6047,  1.5864,  1.6196,  1.5784,  1.5797],
        [ 1.3055,  1.3079,  1.2526,  1.2665,  1.3113,  1.3084,  1.3072,  1.3075,
          1.3075,  2.5133,  2.4812,  2.3865,  2.5714,  2.4009,  2.8961,  2.4864,
          2.5258,  2.8672,  1.2944,  1.3017,  1.2547,  1.2837,  1.3244,  1.3239,
          1.3137,  1.3230,  1.3230,  1.3245,  1.2569,  1.3456,  1.3487,  1.2774,
          1.3471,  1.3500,  1.3194,  1.3459,  1.7584,  1.7707,  1.7259,  1.7548,
          1.7681,  1.7695,  1.7228,  1.6480,  1.7574,  1.5724,  1.6127,  1.6083,
          1.6018,  1.5300,  1.6073,  1.5474,  1.5985,  1.5999],
        [ 1.2840,  1.2867,  1.2899,  1.2885,  1.2866,  1.2845,  1.2848,  1.2837,
          1.2837,  1.3499,  1.3523,  1.3515,  1.3545,  1.3491,  1.3076,  1.3505,
          1.3000,  1.3374,  2.5690,  2.6247,  2.6749,  2.5784,  2.5116,  2.5092,
          2.6038,  2.5034,  2.5034,  1.2954,  1.3122,  1.3221,  1.3251,  1.2960,
          1.3236,  1.3263,  1.3220,  1.3224,  1.7426,  1.7540,  1.7470,  1.6993,
          1.7516,  1.7516,  1.7441,  1.7265,  1.6986,  1.6119,  1.5948,  1.5908,
          1.5848,  1.5881,  1.5898,  1.6051,  1.5813,  1.5829],
        [ 1.2951,  1.2979,  1.3011,  1.2996,  1.2978,  1.2956,  1.2960,  1.2948,
          1.2948,  1.3607,  1.3631,  1.3623,  1.3463,  1.3599,  1.2691,  1.3613,
          1.3577,  1.2671,  1.3145,  1.2962,  1.3158,  1.3155,  1.3119,  1.3114,
          1.3129,  1.3106,  1.3106,  2.7339,  2.6781,  2.4301,  2.5366,  2.7320,
          2.4388,  2.6590,  2.4778,  2.4318,  1.7504,  1.7621,  1.7287,  1.7496,
          1.7596,  1.7596,  1.7258,  1.6866,  1.7489,  1.6211,  1.6031,  1.5027,
          1.5385,  1.6172,  1.5978,  1.6327,  1.5349,  1.5909],
        [ 1.8689,  1.4689,  0.6270,  0.9527,  1.3613,  1.7975,  1.6716,  1.9031,
          1.9031,  1.7383,  1.3544,  1.5509,  0.9493,  1.7656,  0.1537,  1.6684,
          1.9175,  0.8937,  1.3700,  1.0115,  0.7716,  1.1835,  1.7385,  1.8052,
          1.5579,  1.9112,  1.9112,  0.8714,  0.8858,  1.8839,  1.6851,  0.8940,
          1.8247,  1.2925,  1.9328,  1.8482, -0.0736, -0.3249, -0.3658, -0.1124,
          0.1444,  0.2436, -0.2040, 13.7841,  5.5188,  0.2330,  0.6004,  0.6346,
          0.7380,  0.3883,  0.7372, -0.0593,  0.7685,  0.8337],
        [ 1.3336,  1.3711,  1.4157,  1.4033,  1.3782,  1.3409,  1.3113,  1.3300,
          1.3300,  1.2997,  1.4230,  1.3219,  1.4531,  1.3793,  1.4788,  1.3080,
          1.3578,  1.3656,  1.3900,  1.3795,  1.4240,  1.4035,  1.3566,  1.3496,
          1.2608,  1.3381,  1.3381,  1.3919,  1.4350,  1.3532,  1.1502,  1.3482,
          1.2422,  1.4086,  1.2312,  1.3573,  0.3409,  0.2652,  0.3814,  0.3480,
          0.1426,  0.0968,  0.3646,  0.1476, -0.0622,  3.1724,  2.2408,  3.1573,
          2.5374,  1.8175,  1.4226,  2.7687,  2.9556,  1.3871]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 229 : 175.44253264666597
Test loss for epoch 229 : 175.40807138182058
Test Precision for epoch 229 : 0.26153846153846155
Test Recall for epoch 229 : 0.26153846153846155
Test F1 for epoch 229 : 0.26153846153846155


theta for epoch 230 : tensor([[ 2.5105,  2.5295,  2.5662,  2.6640,  2.6454,  2.5139,  2.6324,  2.5090,
          2.5090,  1.3452,  1.3476,  1.3468,  1.3498,  1.3445,  1.3518,  1.3458,
          1.3430,  1.3051,  1.2993,  1.2574,  1.2581,  1.3003,  1.2968,  1.2963,
          1.2986,  1.2955,  1.2955,  1.2791,  1.3233,  1.3172,  1.3201,  1.3234,
          1.3186,  1.3213,  1.2735,  1.3175,  1.7406,  1.7517,  1.7450,  1.7411,
          1.7494,  1.6894,  1.7421,  1.7276,  1.7404,  1.6039,  1.5868,  1.5828,
          1.5769,  1.6001,  1.5819,  1.6149,  1.5738,  1.5751],
        [ 1.3064,  1.3088,  1.2542,  1.2676,  1.3121,  1.3092,  1.3081,  1.3084,
          1.3084,  2.5141,  2.4834,  2.3885,  2.5739,  2.4021,  2.8958,  2.4880,
          2.5286,  2.8669,  1.2961,  1.3034,  1.2563,  1.2858,  1.3260,  1.3255,
          1.3157,  1.3246,  1.3246,  1.3250,  1.2580,  1.3460,  1.3491,  1.2781,
          1.3475,  1.3504,  1.3198,  1.3463,  1.7592,  1.7715,  1.7268,  1.7557,
          1.7689,  1.7703,  1.7237,  1.6501,  1.7582,  1.5679,  1.6080,  1.6037,
          1.5973,  1.5256,  1.6027,  1.5429,  1.5939,  1.5954],
        [ 1.2849,  1.2877,  1.2909,  1.2894,  1.2875,  1.2855,  1.2857,  1.2847,
          1.2847,  1.3507,  1.3532,  1.3523,  1.3554,  1.3500,  1.3081,  1.3513,
          1.3006,  1.3383,  2.5706,  2.6272,  2.6775,  2.5799,  2.5132,  2.5108,
          2.6063,  2.5050,  2.5050,  1.2955,  1.3126,  1.3226,  1.3255,  1.2962,
          1.3240,  1.3267,  1.3225,  1.3229,  1.7436,  1.7549,  1.7480,  1.6998,
          1.7525,  1.7525,  1.7451,  1.7275,  1.6990,  1.6077,  1.5906,  1.5866,
          1.5806,  1.5839,  1.5856,  1.6008,  1.5771,  1.5788],
        [ 1.2958,  1.2987,  1.3018,  1.3003,  1.2985,  1.2964,  1.2968,  1.2955,
          1.2955,  1.3613,  1.3637,  1.3630,  1.3469,  1.3605,  1.2700,  1.3619,
          1.3583,  1.2680,  1.3156,  1.2973,  1.3170,  1.3167,  1.3131,  1.3125,
          1.3141,  1.3117,  1.3117,  2.7359,  2.6799,  2.4322,  2.5382,  2.7341,
          2.4408,  2.6608,  2.4800,  2.4339,  1.7512,  1.7629,  1.7296,  1.7505,
          1.7605,  1.7604,  1.7266,  1.6878,  1.7497,  1.6170,  1.5989,  1.4989,
          1.5343,  1.6130,  1.5937,  1.6285,  1.5308,  1.5868],
        [ 1.8668,  1.4660,  0.6230,  0.9493,  1.3584,  1.7953,  1.6691,  1.9012,
          1.9012,  1.7347,  1.3505,  1.5474,  0.9452,  1.7621,  0.1491,  1.6648,
          1.9150,  0.8887,  1.3664,  1.0081,  0.7677,  1.1795,  1.7356,  1.8024,
          1.5550,  1.9086,  1.9086,  0.8674,  0.8813,  1.8810,  1.6819,  0.8897,
          1.8215,  1.2886,  1.9299,  1.8452, -0.0706, -0.3219, -0.3628, -0.1095,
          0.1472,  0.2463, -0.2010, 13.8309,  5.5054,  0.2277,  0.5950,  0.6291,
          0.7326,  0.3829,  0.7318, -0.0645,  0.7631,  0.8283],
        [ 1.3381,  1.3756,  1.4201,  1.4078,  1.3827,  1.3454,  1.3158,  1.3346,
          1.3346,  1.3047,  1.4278,  1.3268,  1.4580,  1.3842,  1.4837,  1.3130,
          1.3626,  1.3705,  1.3951,  1.3843,  1.4290,  1.4086,  1.3617,  1.3546,
          1.2657,  1.3432,  1.3432,  1.3962,  1.4393,  1.3575,  1.1546,  1.3526,
          1.2467,  1.4130,  1.2357,  1.3617,  0.3456,  0.2699,  0.3860,  0.3527,
          0.1472,  0.1015,  0.3693,  0.1521, -0.0576,  3.1706,  2.2363,  3.1555,
          2.5335,  1.8125,  1.4174,  2.7648,  2.9542,  1.3819]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 230 : 175.4380957465716
Test loss for epoch 230 : 175.41475249572608
Test Precision for epoch 230 : 0.26153846153846155
Test Recall for epoch 230 : 0.26153846153846155
Test F1 for epoch 230 : 0.26153846153846155


theta for epoch 231 : tensor([[ 2.5110,  2.5300,  2.5667,  2.6647,  2.6462,  2.5144,  2.6331,  2.5095,
          2.5095,  1.3454,  1.3478,  1.3470,  1.3501,  1.3447,  1.3521,  1.3460,
          1.3432,  1.3054,  1.2990,  1.2572,  1.2579,  1.3001,  1.2966,  1.2961,
          1.2984,  1.2952,  1.2952,  1.2792,  1.3234,  1.3173,  1.3203,  1.3235,
          1.3188,  1.3214,  1.2737,  1.3176,  1.7407,  1.7518,  1.7450,  1.7412,
          1.7495,  1.6894,  1.7422,  1.7276,  1.7404,  1.6068,  1.5897,  1.5858,
          1.5799,  1.6030,  1.5848,  1.6178,  1.5768,  1.5781],
        [ 1.3056,  1.3080,  1.2541,  1.2671,  1.3112,  1.3083,  1.3073,  1.3075,
          1.3075,  2.5145,  2.4852,  2.3901,  2.5760,  2.4029,  2.8952,  2.4892,
          2.5309,  2.8663,  1.2957,  1.3029,  1.2558,  1.2857,  1.3254,  1.3249,
          1.3155,  1.3240,  1.3240,  1.3250,  1.2586,  1.3459,  1.3491,  1.2785,
          1.3475,  1.3504,  1.3198,  1.3462,  1.7592,  1.7715,  1.7268,  1.7558,
          1.7688,  1.7702,  1.7236,  1.6514,  1.7581,  1.5710,  1.6110,  1.6067,
          1.6003,  1.5288,  1.6057,  1.5461,  1.5969,  1.5984],
        [ 1.2842,  1.2869,  1.2901,  1.2887,  1.2868,  1.2847,  1.2850,  1.2839,
          1.2839,  1.3509,  1.3534,  1.3525,  1.3556,  1.3502,  1.3081,  1.3515,
          1.3005,  1.3385,  2.5706,  2.6281,  2.6785,  2.5800,  2.5132,  2.5108,
          2.6071,  2.5050,  2.5050,  1.2954,  1.3128,  1.3227,  1.3257,  1.2960,
          1.3241,  1.3269,  1.3226,  1.3230,  1.7437,  1.7550,  1.7481,  1.6995,
          1.7526,  1.7525,  1.7452,  1.7277,  1.6987,  1.6106,  1.5936,  1.5895,
          1.5835,  1.5869,  1.5886,  1.6036,  1.5801,  1.5817],
        [ 1.2951,  1.2979,  1.3010,  1.2996,  1.2978,  1.2956,  1.2960,  1.2948,
          1.2948,  1.3615,  1.3639,  1.3632,  1.3471,  1.3608,  1.2705,  1.3621,
          1.3585,  1.2685,  1.3153,  1.2970,  1.3167,  1.3164,  1.3128,  1.3122,
          1.3137,  1.3114,  1.3114,  2.7368,  2.6806,  2.4330,  2.5387,  2.7350,
          2.4417,  2.6615,  2.4811,  2.4348,  1.7513,  1.7629,  1.7296,  1.7505,
          1.7605,  1.7604,  1.7267,  1.6882,  1.7498,  1.6197,  1.6017,  1.5020,
          1.5372,  1.6158,  1.5965,  1.6312,  1.5336,  1.5896],
        [ 1.8690,  1.4688,  0.6264,  0.9525,  1.3614,  1.7977,  1.6717,  1.9034,
          1.9034,  1.7376,  1.3543,  1.5508,  0.9492,  1.7651,  0.1532,  1.6680,
          1.9183,  0.8926,  1.3699,  1.0121,  0.7718,  1.1830,  1.7387,  1.8054,
          1.5583,  1.9115,  1.9115,  0.8715,  0.8850,  1.8842,  1.6854,  0.8938,
          1.8249,  1.2923,  1.9331,  1.8485, -0.0747, -0.3257, -0.3667, -0.1137,
          0.1428,  0.2418, -0.2049, 13.8703,  5.4833,  0.2326,  0.5999,  0.6339,
          0.7375,  0.3877,  0.7367, -0.0597,  0.7681,  0.8332],
        [ 1.3333,  1.3708,  1.4153,  1.4030,  1.3779,  1.3406,  1.3109,  1.3297,
          1.3297,  1.2997,  1.4228,  1.3217,  1.4529,  1.3792,  1.4786,  1.3079,
          1.3574,  1.3655,  1.3898,  1.3786,  1.4237,  1.4033,  1.3563,  1.3493,
          1.2600,  1.3378,  1.3378,  1.3917,  1.4349,  1.3530,  1.1495,  1.3480,
          1.2420,  1.4085,  1.2309,  1.3571,  0.3405,  0.2648,  0.3809,  0.3477,
          0.1420,  0.0962,  0.3643,  0.1468, -0.0631,  3.1798,  2.2429,  3.1647,
          2.5406,  1.8185,  1.4232,  2.7718,  2.9639,  1.3877]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 231 : 175.41870268469455
Test loss for epoch 231 : 175.39075530821705
Test Precision for epoch 231 : 0.26153846153846155
Test Recall for epoch 231 : 0.26153846153846155
Test F1 for epoch 231 : 0.26153846153846155


theta for epoch 232 : tensor([[ 2.5119,  2.5309,  2.5676,  2.6658,  2.6472,  2.5152,  2.6342,  2.5103,
          2.5103,  1.3453,  1.3477,  1.3469,  1.3499,  1.3446,  1.3520,  1.3459,
          1.3431,  1.3053,  1.2991,  1.2572,  1.2579,  1.3001,  1.2966,  1.2961,
          1.2984,  1.2953,  1.2953,  1.2792,  1.3234,  1.3173,  1.3203,  1.3235,
          1.3187,  1.3214,  1.2737,  1.3176,  1.7414,  1.7525,  1.7458,  1.7419,
          1.7502,  1.6902,  1.7429,  1.7284,  1.7411,  1.6081,  1.5910,  1.5871,
          1.5812,  1.6043,  1.5861,  1.6191,  1.5781,  1.5794],
        [ 1.3046,  1.3070,  1.2538,  1.2663,  1.3102,  1.3073,  1.3063,  1.3064,
          1.3064,  2.5156,  2.4877,  2.3925,  2.5788,  2.4045,  2.8953,  2.4911,
          2.5340,  2.8664,  1.2953,  1.3024,  1.2554,  1.2856,  1.3249,  1.3244,
          1.3153,  1.3235,  1.3235,  1.3247,  1.2589,  1.3456,  1.3487,  1.2785,
          1.3471,  1.3500,  1.3195,  1.3459,  1.7597,  1.7720,  1.7273,  1.7564,
          1.7693,  1.7707,  1.7242,  1.6532,  1.7586,  1.5722,  1.6121,  1.6078,
          1.6014,  1.5300,  1.6068,  1.5472,  1.5980,  1.5995],
        [ 1.2831,  1.2858,  1.2890,  1.2876,  1.2857,  1.2836,  1.2839,  1.2828,
          1.2828,  1.3502,  1.3527,  1.3518,  1.3549,  1.3495,  1.3071,  1.3508,
          1.2994,  1.3378,  2.5726,  2.6309,  2.6814,  2.5819,  2.5151,  2.5126,
          2.6098,  2.5068,  2.5068,  1.2947,  1.3124,  1.3223,  1.3253,  1.2954,
          1.3238,  1.3265,  1.3222,  1.3226,  1.7443,  1.7556,  1.7487,  1.6997,
          1.7532,  1.7531,  1.7458,  1.7283,  1.6989,  1.6115,  1.5945,  1.5905,
          1.5845,  1.5878,  1.5895,  1.6045,  1.5810,  1.5827],
        [ 1.2942,  1.2971,  1.3002,  1.2987,  1.2969,  1.2948,  1.2952,  1.2939,
          1.2939,  1.3612,  1.3636,  1.3628,  1.3468,  1.3604,  1.2705,  1.3618,
          1.3581,  1.2684,  1.3151,  1.2967,  1.3164,  1.3162,  1.3126,  1.3120,
          1.3135,  1.3112,  1.3112,  2.7384,  2.6820,  2.4346,  2.5399,  2.7365,
          2.4432,  2.6628,  2.4828,  2.4363,  1.7520,  1.7636,  1.7303,  1.7512,
          1.7612,  1.7611,  1.7273,  1.6893,  1.7504,  1.6208,  1.6028,  1.5034,
          1.5383,  1.6168,  1.5976,  1.6323,  1.5347,  1.5908],
        [ 1.8672,  1.4667,  0.6239,  0.9503,  1.3593,  1.7959,  1.6697,  1.9017,
          1.9017,  1.7354,  1.3521,  1.5489,  0.9471,  1.7631,  0.1508,  1.6659,
          1.9170,  0.8898,  1.3680,  1.0105,  0.7698,  1.1808,  1.7370,  1.8038,
          1.5568,  1.9100,  1.9100,  0.8696,  0.8825,  1.8826,  1.6837,  0.8916,
          1.8232,  1.2902,  1.9316,  1.8469, -0.0735, -0.3244, -0.3655, -0.1126,
          0.1438,  0.2426, -0.2037, 13.9152,  5.4673,  0.2307,  0.5981,  0.6320,
          0.7358,  0.3858,  0.7350, -0.0617,  0.7665,  0.8316],
        [ 1.3348,  1.3723,  1.4167,  1.4045,  1.3794,  1.3421,  1.3125,  1.3312,
          1.3312,  1.3020,  1.4250,  1.3239,  1.4551,  1.3814,  1.4807,  1.3101,
          1.3596,  1.3677,  1.3920,  1.3806,  1.4258,  1.4055,  1.3586,  1.3515,
          1.2620,  1.3400,  1.3400,  1.3937,  1.4369,  1.3550,  1.1515,  1.3500,
          1.2441,  1.4105,  1.2330,  1.3592,  0.3429,  0.2673,  0.3833,  0.3501,
          0.1444,  0.0986,  0.3667,  0.1490, -0.0609,  3.1811,  2.2415,  3.1659,
          2.5398,  1.8166,  1.4210,  2.7709,  2.9656,  1.3855]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 232 : 175.4014378305981
Test loss for epoch 232 : 175.38047815382168
Test Precision for epoch 232 : 0.26153846153846155
Test Recall for epoch 232 : 0.26153846153846155
Test F1 for epoch 232 : 0.26153846153846155


theta for epoch 233 : tensor([[ 2.5148,  2.5337,  2.5705,  2.6689,  2.6503,  2.5181,  2.6373,  2.5132,
          2.5132,  1.3448,  1.3472,  1.3463,  1.3494,  1.3440,  1.3514,  1.3453,
          1.3425,  1.3047,  1.2984,  1.2566,  1.2573,  1.2995,  1.2960,  1.2955,
          1.2978,  1.2947,  1.2947,  1.2789,  1.3231,  1.3170,  1.3200,  1.3232,
          1.3184,  1.3211,  1.2733,  1.3173,  1.7411,  1.7522,  1.7455,  1.7416,
          1.7499,  1.6898,  1.7426,  1.7280,  1.7408,  1.6073,  1.5903,  1.5864,
          1.5805,  1.6036,  1.5855,  1.6184,  1.5774,  1.5788],
        [ 1.3046,  1.3071,  1.2545,  1.2666,  1.3101,  1.3072,  1.3063,  1.3064,
          1.3064,  2.5182,  2.4917,  2.3963,  2.5830,  2.4075,  2.8967,  2.4945,
          2.5386,  2.8679,  1.2944,  1.3014,  1.2544,  1.2851,  1.3239,  1.3234,
          1.3146,  1.3225,  1.3225,  1.3241,  1.2589,  1.3451,  1.3482,  1.2783,
          1.3466,  1.3495,  1.3190,  1.3454,  1.7593,  1.7715,  1.7270,  1.7561,
          1.7689,  1.7702,  1.7238,  1.6541,  1.7581,  1.5712,  1.6111,  1.6068,
          1.6004,  1.5292,  1.6058,  1.5463,  1.5970,  1.5985],
        [ 1.2831,  1.2859,  1.2891,  1.2876,  1.2857,  1.2837,  1.2839,  1.2829,
          1.2829,  1.3494,  1.3518,  1.3510,  1.3540,  1.3486,  1.3060,  1.3500,
          1.2982,  1.3370,  2.5758,  2.6350,  2.6855,  2.5851,  2.5183,  2.5158,
          2.6138,  2.5100,  2.5100,  1.2940,  1.3119,  1.3219,  1.3248,  1.2946,
          1.3233,  1.3260,  1.3218,  1.3222,  1.7439,  1.7552,  1.7483,  1.6989,
          1.7528,  1.7527,  1.7454,  1.7280,  1.6981,  1.6106,  1.5937,  1.5897,
          1.5837,  1.5870,  1.5887,  1.6036,  1.5802,  1.5819],
        [ 1.2944,  1.2972,  1.3003,  1.2989,  1.2971,  1.2949,  1.2953,  1.2941,
          1.2941,  1.3606,  1.3630,  1.3623,  1.3462,  1.3599,  1.2701,  1.3612,
          1.3576,  1.2681,  1.3145,  1.2961,  1.3158,  1.3156,  1.3120,  1.3114,
          1.3129,  1.3106,  1.3106,  2.7411,  2.6846,  2.4374,  2.5423,  2.7393,
          2.4460,  2.6654,  2.4857,  2.4391,  1.7517,  1.7633,  1.7299,  1.7509,
          1.7609,  1.7608,  1.7270,  1.6893,  1.7501,  1.6201,  1.6022,  1.5031,
          1.5377,  1.6162,  1.5970,  1.6316,  1.5341,  1.5901],
        [ 1.8678,  1.4672,  0.6241,  0.9506,  1.3599,  1.7966,  1.6703,  1.9024,
          1.9024,  1.7352,  1.3523,  1.5491,  0.9473,  1.7630,  0.1507,  1.6659,
          1.9175,  0.8895,  1.3681,  1.0110,  0.7702,  1.1808,  1.7373,  1.8040,
          1.5571,  1.9103,  1.9103,  0.8699,  0.8824,  1.8830,  1.6840,  0.8917,
          1.8235,  1.2904,  1.9319,  1.8472, -0.0742, -0.3249, -0.3661, -0.1134,
          0.1428,  0.2415, -0.2043, 13.9581,  5.4488,  0.2308,  0.5981,  0.6320,
          0.7359,  0.3858,  0.7351, -0.0616,  0.7666,  0.8316],
        [ 1.3360,  1.3736,  1.4179,  1.4057,  1.3807,  1.3433,  1.3137,  1.3324,
          1.3324,  1.3032,  1.4261,  1.3250,  1.4562,  1.3826,  1.4817,  1.3113,
          1.3607,  1.3688,  1.3930,  1.3813,  1.4268,  1.4066,  1.3596,  1.3526,
          1.2628,  1.3411,  1.3411,  1.3947,  1.4379,  1.3560,  1.1523,  1.3510,
          1.2451,  1.4116,  1.2341,  1.3602,  0.3437,  0.2680,  0.3840,  0.3509,
          0.1451,  0.0993,  0.3674,  0.1496, -0.0603,  3.1836,  2.2414,  3.1684,
          2.5402,  1.8159,  1.4201,  2.7713,  2.9686,  1.3846]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 233 : 175.39355878087534
Test loss for epoch 233 : 175.37627458393322
Test Precision for epoch 233 : 0.26153846153846155
Test Recall for epoch 233 : 0.26153846153846155
Test F1 for epoch 233 : 0.26153846153846155


theta for epoch 234 : tensor([[ 2.5178,  2.5368,  2.5735,  2.6721,  2.6536,  2.5212,  2.6405,  2.5162,
          2.5162,  1.3445,  1.3469,  1.3460,  1.3491,  1.3437,  1.3511,  1.3450,
          1.3422,  1.3044,  1.2978,  1.2559,  1.2566,  1.2988,  1.2953,  1.2948,
          1.2971,  1.2940,  1.2940,  1.2786,  1.3228,  1.3168,  1.3197,  1.3229,
          1.3182,  1.3209,  1.2731,  1.3170,  1.7402,  1.7512,  1.7445,  1.7407,
          1.7489,  1.6889,  1.7417,  1.7271,  1.7398,  1.6070,  1.5900,  1.5861,
          1.5802,  1.6033,  1.5852,  1.6180,  1.5771,  1.5785],
        [ 1.3051,  1.3076,  1.2556,  1.2673,  1.3106,  1.3076,  1.3068,  1.3068,
          1.3068,  2.5205,  2.4953,  2.3998,  2.5868,  2.4102,  2.8978,  2.4976,
          2.5428,  2.8692,  1.2936,  1.3006,  1.2536,  1.2847,  1.3231,  1.3226,
          1.3142,  1.3217,  1.3217,  1.3238,  1.2592,  1.3447,  1.3478,  1.2782,
          1.3462,  1.3491,  1.3186,  1.3450,  1.7583,  1.7705,  1.7260,  1.7552,
          1.7679,  1.7692,  1.7229,  1.6544,  1.7571,  1.5709,  1.6107,  1.6064,
          1.6000,  1.5289,  1.6054,  1.5460,  1.5966,  1.5982],
        [ 1.2838,  1.2866,  1.2898,  1.2883,  1.2864,  1.2844,  1.2847,  1.2836,
          1.2836,  1.3493,  1.3517,  1.3508,  1.3539,  1.3485,  1.3056,  1.3498,
          1.2978,  1.3369,  2.5778,  2.6379,  2.6884,  2.5871,  2.5202,  2.5177,
          2.6166,  2.5120,  2.5120,  1.2936,  1.3118,  1.3217,  1.3247,  1.2942,
          1.3232,  1.3259,  1.3217,  1.3220,  1.7431,  1.7544,  1.7475,  1.6977,
          1.7520,  1.7519,  1.7446,  1.7273,  1.6968,  1.6105,  1.5935,  1.5895,
          1.5835,  1.5868,  1.5886,  1.6033,  1.5801,  1.5818],
        [ 1.2949,  1.2978,  1.3009,  1.2994,  1.2977,  1.2955,  1.2959,  1.2946,
          1.2946,  1.3603,  1.3627,  1.3620,  1.3458,  1.3596,  1.2701,  1.3609,
          1.3573,  1.2681,  1.3139,  1.2955,  1.3153,  1.3150,  1.3114,  1.3108,
          1.3123,  1.3100,  1.3100,  2.7438,  2.6871,  2.4401,  2.5446,  2.7420,
          2.4487,  2.6678,  2.4886,  2.4418,  1.7507,  1.7623,  1.7289,  1.7499,
          1.7599,  1.7598,  1.7260,  1.6887,  1.7491,  1.6198,  1.6020,  1.5032,
          1.5374,  1.6159,  1.5968,  1.6313,  1.5338,  1.5899],
        [ 1.8710,  1.4708,  0.6277,  0.9541,  1.3635,  1.7999,  1.6736,  1.9056,
          1.9056,  1.7379,  1.3557,  1.5523,  0.9510,  1.7659,  0.1544,  1.6689,
          1.9207,  0.8930,  1.3715,  1.0147,  0.7740,  1.1841,  1.7404,  1.8070,
          1.5604,  1.9132,  1.9132,  0.8736,  0.8858,  1.8861,  1.6873,  0.8954,
          1.8267,  1.2938,  1.9350,  1.8504, -0.0780, -0.3284, -0.3697, -0.1173,
          0.1387,  0.2373, -0.2080, 13.9978,  5.4266,  0.2346,  0.6018,  0.6356,
          0.7396,  0.3895,  0.7388, -0.0578,  0.7703,  0.8353],
        [ 1.3340,  1.3715,  1.4159,  1.4037,  1.3786,  1.3413,  1.3116,  1.3304,
          1.3304,  1.3003,  1.4232,  1.3221,  1.4533,  1.3798,  1.4788,  1.3084,
          1.3577,  1.3660,  1.3900,  1.3779,  1.4237,  1.4036,  1.3566,  1.3495,
          1.2594,  1.3380,  1.3380,  1.3920,  1.4353,  1.3534,  1.1493,  1.3484,
          1.2425,  1.4090,  1.2313,  1.3576,  0.3403,  0.2646,  0.3805,  0.3475,
          0.1416,  0.0958,  0.3640,  0.1460, -0.0640,  3.1905,  2.2456,  3.1752,
          2.5449,  1.8195,  1.4235,  2.7759,  2.9759,  1.3880]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 234 : 175.39072856086335
Test loss for epoch 234 : 175.37057186499953
Test Precision for epoch 234 : 0.26153846153846155
Test Recall for epoch 234 : 0.26153846153846155
Test F1 for epoch 234 : 0.26153846153846155


theta for epoch 235 : tensor([[ 2.5190,  2.5380,  2.5747,  2.6736,  2.6550,  2.5224,  2.6420,  2.5175,
          2.5175,  1.3450,  1.3474,  1.3465,  1.3496,  1.3442,  1.3516,  1.3455,
          1.3427,  1.3049,  1.2991,  1.2572,  1.2579,  1.3001,  1.2966,  1.2961,
          1.2984,  1.2953,  1.2953,  1.2788,  1.3230,  1.3169,  1.3199,  1.3231,
          1.3183,  1.3210,  1.2732,  1.3172,  1.7409,  1.7520,  1.7453,  1.7414,
          1.7497,  1.6896,  1.7424,  1.7278,  1.7405,  1.6054,  1.5884,  1.5845,
          1.5786,  1.6017,  1.5836,  1.6164,  1.5755,  1.5769],
        [ 1.3052,  1.3076,  1.2563,  1.2676,  1.3105,  1.3076,  1.3068,  1.3068,
          1.3068,  2.5208,  2.4969,  2.4013,  2.5888,  2.4110,  2.8973,  2.4986,
          2.5450,  2.8687,  1.2952,  1.3020,  1.2551,  1.2865,  1.3245,  1.3240,
          1.3159,  1.3231,  1.3231,  1.3240,  1.2599,  1.3449,  1.3480,  1.2788,
          1.3464,  1.3493,  1.3188,  1.3452,  1.7590,  1.7712,  1.7268,  1.7560,
          1.7686,  1.7699,  1.7236,  1.6563,  1.7578,  1.5692,  1.6089,  1.6046,
          1.5983,  1.5274,  1.6037,  1.5444,  1.5949,  1.5964],
        [ 1.2839,  1.2867,  1.2899,  1.2884,  1.2865,  1.2845,  1.2848,  1.2837,
          1.2837,  1.3500,  1.3525,  1.3516,  1.3547,  1.3493,  1.3061,  1.3506,
          1.2983,  1.3377,  2.5786,  2.6395,  2.6901,  2.5879,  2.5210,  2.5185,
          2.6182,  2.5128,  2.5128,  1.2936,  1.3121,  1.3221,  1.3250,  1.2943,
          1.3235,  1.3262,  1.3220,  1.3224,  1.7439,  1.7552,  1.7484,  1.6981,
          1.7528,  1.7527,  1.7454,  1.7282,  1.6973,  1.6090,  1.5920,  1.5880,
          1.5820,  1.5853,  1.5871,  1.6018,  1.5786,  1.5803],
        [ 1.2947,  1.2976,  1.3007,  1.2993,  1.2975,  1.2953,  1.2957,  1.2945,
          1.2945,  1.3607,  1.3631,  1.3623,  1.3461,  1.3599,  1.2707,  1.3613,
          1.3576,  1.2687,  1.3149,  1.2964,  1.3162,  1.3159,  1.3123,  1.3118,
          1.3133,  1.3109,  1.3109,  2.7454,  2.6885,  2.4417,  2.5458,  2.7436,
          2.4504,  2.6692,  2.4904,  2.4435,  1.7514,  1.7630,  1.7296,  1.7506,
          1.7606,  1.7605,  1.7266,  1.6898,  1.7497,  1.6181,  1.6003,  1.5019,
          1.5357,  1.6142,  1.5951,  1.6296,  1.5321,  1.5882],
        [ 1.8684,  1.4677,  0.6238,  0.9507,  1.3604,  1.7973,  1.6708,  1.9032,
          1.9032,  1.7345,  1.3522,  1.5492,  0.9474,  1.7627,  0.1503,  1.6656,
          1.9183,  0.8885,  1.3683,  1.0117,  0.7706,  1.1806,  1.7377,  1.8044,
          1.5577,  1.9107,  1.9107,  0.8700,  0.8817,  1.8832,  1.6842,  0.8916,
          1.8237,  1.2902,  1.9322,  1.8474, -0.0753, -0.3257, -0.3671, -0.1147,
          0.1412,  0.2397, -0.2053, 14.0442,  5.4118,  0.2305,  0.5978,  0.6315,
          0.7356,  0.3853,  0.7348, -0.0620,  0.7664,  0.8314],
        [ 1.3371,  1.3746,  1.4189,  1.4068,  1.3817,  1.3444,  1.3148,  1.3335,
          1.3335,  1.3042,  1.4271,  1.3260,  1.4571,  1.3836,  1.4826,  1.3122,
          1.3615,  1.3699,  1.3940,  1.3818,  1.4277,  1.4076,  1.3606,  1.3535,
          1.2633,  1.3420,  1.3420,  1.3953,  1.4386,  1.3568,  1.1527,  1.3517,
          1.2459,  1.4124,  1.2348,  1.3610,  0.3442,  0.2685,  0.3843,  0.3514,
          0.1454,  0.0996,  0.3679,  0.1498, -0.0602,  3.1900,  2.2425,  3.1746,
          2.5423,  1.8158,  1.4196,  2.7733,  2.9758,  1.3841]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 235 : 175.38061673973294
Test loss for epoch 235 : 175.3703524887775
Test Precision for epoch 235 : 0.26153846153846155
Test Recall for epoch 235 : 0.26153846153846155
Test F1 for epoch 235 : 0.26153846153846155


theta for epoch 236 : tensor([[ 2.5195,  2.5384,  2.5751,  2.6742,  2.6556,  2.5228,  2.6426,  2.5179,
          2.5179,  1.3454,  1.3478,  1.3469,  1.3500,  1.3446,  1.3520,  1.3459,
          1.3431,  1.3053,  1.2992,  1.2574,  1.2581,  1.3002,  1.2968,  1.2963,
          1.2986,  1.2954,  1.2954,  1.2790,  1.3232,  1.3171,  1.3200,  1.3233,
          1.3185,  1.3212,  1.2734,  1.3174,  1.7410,  1.7520,  1.7454,  1.7415,
          1.7497,  1.6897,  1.7425,  1.7279,  1.7406,  1.6078,  1.5908,  1.5869,
          1.5810,  1.6041,  1.5860,  1.6187,  1.5779,  1.5793],
        [ 1.3044,  1.3069,  1.2562,  1.2671,  1.3097,  1.3068,  1.3061,  1.3060,
          1.3060,  2.5210,  2.4983,  2.4026,  2.5906,  2.4116,  2.8967,  2.4996,
          2.5470,  2.8681,  1.2952,  1.3020,  1.2551,  1.2869,  1.3245,  1.3239,
          1.3162,  1.3230,  1.3230,  1.3240,  1.2605,  1.3448,  1.3480,  1.2791,
          1.3464,  1.3493,  1.3188,  1.3452,  1.7590,  1.7712,  1.7268,  1.7561,
          1.7685,  1.7699,  1.7236,  1.6575,  1.7577,  1.5717,  1.6113,  1.6071,
          1.6007,  1.5300,  1.6061,  1.5470,  1.5973,  1.5988],
        [ 1.2833,  1.2861,  1.2893,  1.2878,  1.2859,  1.2839,  1.2842,  1.2831,
          1.2831,  1.3505,  1.3530,  1.3521,  1.3552,  1.3498,  1.3063,  1.3511,
          1.2985,  1.3382,  2.5785,  2.6402,  2.6909,  2.5878,  2.5208,  2.5183,
          2.6188,  2.5126,  2.5126,  1.2936,  1.3124,  1.3223,  1.3252,  1.2942,
          1.3237,  1.3264,  1.3222,  1.3226,  1.7440,  1.7553,  1.7485,  1.6979,
          1.7529,  1.7528,  1.7456,  1.7284,  1.6970,  1.6114,  1.5944,  1.5905,
          1.5845,  1.5877,  1.5895,  1.6042,  1.5810,  1.5827],
        [ 1.2939,  1.2968,  1.2999,  1.2985,  1.2967,  1.2945,  1.2949,  1.2937,
          1.2937,  1.3608,  1.3632,  1.3624,  1.3462,  1.3600,  1.2711,  1.3614,
          1.3577,  1.2691,  1.3147,  1.2962,  1.3161,  1.3158,  1.3122,  1.3116,
          1.3131,  1.3108,  1.3108,  2.7465,  2.6894,  2.4430,  2.5466,  2.7447,
          2.4516,  2.6702,  2.4918,  2.4447,  1.7514,  1.7630,  1.7295,  1.7506,
          1.7606,  1.7604,  1.7266,  1.6901,  1.7497,  1.6202,  1.6024,  1.5043,
          1.5378,  1.6163,  1.5972,  1.6316,  1.5342,  1.5903],
        [ 1.8698,  1.4695,  0.6261,  0.9528,  1.3624,  1.7988,  1.6724,  1.9046,
          1.9046,  1.7364,  1.3548,  1.5515,  0.9502,  1.7648,  0.1531,  1.6678,
          1.9207,  0.8912,  1.3708,  1.0146,  0.7736,  1.1831,  1.7399,  1.8066,
          1.5601,  1.9128,  1.9128,  0.8729,  0.8843,  1.8854,  1.6866,  0.8944,
          1.8261,  1.2928,  1.9344,  1.8497, -0.0783, -0.3284, -0.3699, -0.1178,
          0.1379,  0.2363, -0.2081, 14.0846,  5.3900,  0.2341,  0.6014,  0.6350,
          0.7392,  0.3889,  0.7385, -0.0585,  0.7701,  0.8351],
        [ 1.3334,  1.3710,  1.4153,  1.4031,  1.3781,  1.3407,  1.3111,  1.3298,
          1.3298,  1.3006,  1.4235,  1.3223,  1.4535,  1.3801,  1.4790,  1.3086,
          1.3578,  1.3663,  1.3903,  1.3777,  1.4240,  1.4039,  1.3568,  1.3498,
          1.2591,  1.3382,  1.3382,  1.3920,  1.4355,  1.3535,  1.1490,  1.3484,
          1.2425,  1.4091,  1.2314,  1.3576,  0.3406,  0.2649,  0.3806,  0.3479,
          0.1417,  0.0959,  0.3644,  0.1460, -0.0641,  3.1977,  2.2475,  3.1823,
          2.5478,  1.8202,  1.4238,  2.7787,  2.9840,  1.3883]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 236 : 175.36506856749986
Test loss for epoch 236 : 175.35246445919938
Test Precision for epoch 236 : 0.26153846153846155
Test Recall for epoch 236 : 0.26153846153846155
Test F1 for epoch 236 : 0.26153846153846155


theta for epoch 237 : tensor([[ 2.5216,  2.5406,  2.5773,  2.6766,  2.6580,  2.5250,  2.6450,  2.5200,
          2.5200,  1.3452,  1.3476,  1.3467,  1.3498,  1.3444,  1.3518,  1.3457,
          1.3429,  1.3051,  1.2990,  1.2570,  1.2578,  1.3000,  1.2965,  1.2960,
          1.2983,  1.2951,  1.2951,  1.2788,  1.3230,  1.3169,  1.3198,  1.3231,
          1.3183,  1.3210,  1.2732,  1.3172,  1.7413,  1.7523,  1.7456,  1.7418,
          1.7500,  1.6899,  1.7427,  1.7282,  1.7409,  1.6068,  1.5898,  1.5859,
          1.5800,  1.6031,  1.5850,  1.6178,  1.5769,  1.5783],
        [ 1.3044,  1.3069,  1.2568,  1.2673,  1.3096,  1.3067,  1.3060,  1.3058,
          1.3058,  2.5224,  2.5010,  2.4052,  2.5937,  2.4135,  2.8973,  2.5018,
          2.5503,  2.8687,  1.2951,  1.3018,  1.2549,  1.2870,  1.3242,  1.3237,
          1.3162,  1.3228,  1.3228,  1.3238,  1.2609,  1.3446,  1.3478,  1.2793,
          1.3462,  1.3491,  1.3186,  1.3449,  1.7592,  1.7714,  1.7270,  1.7564,
          1.7687,  1.7701,  1.7239,  1.6588,  1.7579,  1.5707,  1.6102,  1.6060,
          1.5996,  1.5290,  1.6050,  1.5460,  1.5962,  1.5977],
        [ 1.2832,  1.2860,  1.2891,  1.2877,  1.2858,  1.2837,  1.2840,  1.2829,
          1.2829,  1.3502,  1.3527,  1.3518,  1.3549,  1.3495,  1.3058,  1.3508,
          1.2979,  1.3379,  2.5806,  2.6432,  2.6940,  2.5899,  2.5229,  2.5204,
          2.6218,  2.5147,  2.5147,  1.2930,  1.3121,  1.3220,  1.3250,  1.2937,
          1.3235,  1.3262,  1.3219,  1.3223,  1.7443,  1.7555,  1.7488,  1.6978,
          1.7532,  1.7530,  1.7458,  1.7287,  1.6968,  1.6103,  1.5934,  1.5894,
          1.5834,  1.5867,  1.5885,  1.6031,  1.5799,  1.5817],
        [ 1.2939,  1.2967,  1.2998,  1.2984,  1.2966,  1.2944,  1.2948,  1.2936,
          1.2936,  1.3607,  1.3631,  1.3623,  1.3461,  1.3599,  1.2712,  1.3613,
          1.3576,  1.2693,  1.3146,  1.2960,  1.3159,  1.3156,  1.3120,  1.3115,
          1.3129,  1.3106,  1.3106,  2.7485,  2.6912,  2.4450,  2.5482,  2.7467,
          2.4537,  2.6719,  2.4940,  2.4468,  1.7517,  1.7632,  1.7298,  1.7509,
          1.7609,  1.7607,  1.7268,  1.6908,  1.7499,  1.6193,  1.6015,  1.5038,
          1.5369,  1.6154,  1.5963,  1.6308,  1.5333,  1.5894],
        [ 1.8695,  1.4691,  0.6253,  0.9522,  1.3620,  1.7985,  1.6721,  1.9043,
          1.9043,  1.7355,  1.3541,  1.5510,  0.9496,  1.7640,  0.1522,  1.6670,
          1.9205,  0.8900,  1.3702,  1.0143,  0.7730,  1.1823,  1.7394,  1.8061,
          1.5598,  1.9124,  1.9124,  0.8723,  0.8833,  1.8850,  1.6860,  0.8936,
          1.8256,  1.2921,  1.9339,  1.8492, -0.0781, -0.3282, -0.3696, -0.1177,
          0.1378,  0.2362, -0.2079, 14.1283,  5.3719,  0.2333,  0.6006,  0.6341,
          0.7385,  0.3880,  0.7377, -0.0593,  0.7694,  0.8343],
        [ 1.3347,  1.3723,  1.4165,  1.4044,  1.3794,  1.3420,  1.3124,  1.3311,
          1.3311,  1.3022,  1.4249,  1.3238,  1.4549,  1.3815,  1.4804,  1.3101,
          1.3592,  1.3678,  1.3917,  1.3788,  1.4254,  1.4053,  1.3582,  1.3512,
          1.2604,  1.3397,  1.3397,  1.3933,  1.4367,  1.3548,  1.1502,  1.3497,
          1.2438,  1.4104,  1.2327,  1.3589,  0.3421,  0.2663,  0.3820,  0.3493,
          0.1431,  0.0972,  0.3658,  0.1473, -0.0629,  3.1999,  2.2469,  3.1843,
          2.5478,  1.8191,  1.4225,  2.7786,  2.9865,  1.3870]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 237 : 175.35143735749517
Test loss for epoch 237 : 175.3438270267154
Test Precision for epoch 237 : 0.26153846153846155
Test Recall for epoch 237 : 0.26153846153846155
Test F1 for epoch 237 : 0.26153846153846155


theta for epoch 238 : tensor([[ 2.5247,  2.5436,  2.5804,  2.6799,  2.6613,  2.5280,  2.6483,  2.5231,
          2.5231,  1.3446,  1.3470,  1.3461,  1.3492,  1.3438,  1.3512,  1.3451,
          1.3423,  1.3045,  1.2981,  1.2561,  1.2569,  1.2991,  1.2956,  1.2951,
          1.2974,  1.2943,  1.2943,  1.2784,  1.3226,  1.3165,  1.3195,  1.3227,
          1.3179,  1.3206,  1.2728,  1.3168,  1.7411,  1.7521,  1.7455,  1.7416,
          1.7498,  1.6897,  1.7426,  1.7280,  1.7406,  1.6054,  1.5884,  1.5845,
          1.5786,  1.6017,  1.5836,  1.6163,  1.5755,  1.5769],
        [ 1.3046,  1.3071,  1.2576,  1.2678,  1.3097,  1.3068,  1.3063,  1.3060,
          1.3060,  2.5247,  2.5045,  2.4086,  2.5975,  2.4162,  2.8986,  2.5048,
          2.5544,  2.8701,  1.2942,  1.3009,  1.2540,  1.2865,  1.3233,  1.3228,
          1.3156,  1.3219,  1.3219,  1.3234,  1.2610,  1.3442,  1.3474,  1.2792,
          1.3457,  1.3486,  1.3182,  1.3445,  1.7590,  1.7711,  1.7268,  1.7562,
          1.7685,  1.7698,  1.7237,  1.6598,  1.7577,  1.5692,  1.6087,  1.6044,
          1.5980,  1.5276,  1.6034,  1.5446,  1.5946,  1.5961],
        [ 1.2834,  1.2861,  1.2893,  1.2878,  1.2860,  1.2839,  1.2842,  1.2831,
          1.2831,  1.3494,  1.3519,  1.3510,  1.3541,  1.3487,  1.3048,  1.3500,
          1.2968,  1.3371,  2.5837,  2.6471,  2.6979,  2.5930,  2.5260,  2.5234,
          2.6256,  2.5178,  2.5178,  1.2923,  1.3117,  1.3216,  1.3246,  1.2930,
          1.3230,  1.3258,  1.3215,  1.3219,  1.7441,  1.7553,  1.7486,  1.6972,
          1.7530,  1.7528,  1.7456,  1.7286,  1.6962,  1.6089,  1.5919,  1.5880,
          1.5820,  1.5853,  1.5870,  1.6016,  1.5784,  1.5802],
        [ 1.2942,  1.2971,  1.3001,  1.2988,  1.2970,  1.2948,  1.2952,  1.2940,
          1.2940,  1.3603,  1.3627,  1.3619,  1.3457,  1.3595,  1.2711,  1.3609,
          1.3572,  1.2691,  1.3141,  1.2955,  1.3154,  1.3151,  1.3115,  1.3109,
          1.3124,  1.3101,  1.3101,  2.7509,  2.6935,  2.4476,  2.5502,  2.7491,
          2.4562,  2.6741,  2.4967,  2.4493,  1.7516,  1.7631,  1.7297,  1.7508,
          1.7607,  1.7606,  1.7267,  1.6911,  1.7498,  1.6181,  1.6003,  1.5029,
          1.5357,  1.6142,  1.5951,  1.6296,  1.5321,  1.5883],
        [ 1.8701,  1.4696,  0.6254,  0.9525,  1.3625,  1.7992,  1.6726,  1.9050,
          1.9050,  1.7353,  1.3541,  1.5511,  0.9497,  1.7639,  0.1521,  1.6670,
          1.9209,  0.8897,  1.3703,  1.0147,  0.7733,  1.1822,  1.7396,  1.8062,
          1.5600,  1.9125,  1.9125,  0.8725,  0.8831,  1.8852,  1.6862,  0.8937,
          1.8258,  1.2921,  1.9341,  1.8494, -0.0786, -0.3285, -0.3701, -0.1183,
          0.1370,  0.2353, -0.2083, 14.1713,  5.3527,  0.2333,  0.6005,  0.6339,
          0.7383,  0.3879,  0.7376, -0.0593,  0.7693,  0.8342],
        [ 1.3361,  1.3737,  1.4178,  1.4058,  1.3807,  1.3434,  1.3138,  1.3325,
          1.3325,  1.3035,  1.4261,  1.3250,  1.4561,  1.3828,  1.4816,  1.3114,
          1.3604,  1.3690,  1.3928,  1.3797,  1.4264,  1.4064,  1.3594,  1.3524,
          1.2613,  1.3408,  1.3408,  1.3943,  1.4378,  1.3559,  1.1511,  1.3507,
          1.2449,  1.4115,  1.2338,  1.3600,  0.3431,  0.2673,  0.3829,  0.3504,
          0.1440,  0.0982,  0.3668,  0.1482, -0.0620,  3.2023,  2.2466,  3.1866,
          2.5480,  1.8182,  1.4215,  2.7788,  2.9893,  1.3860]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 238 : 175.34377957932656
Test loss for epoch 238 : 175.3401090953047
Test Precision for epoch 238 : 0.26153846153846155
Test Recall for epoch 238 : 0.26153846153846155
Test F1 for epoch 238 : 0.26153846153846155


theta for epoch 239 : tensor([[ 2.5264,  2.5453,  2.5820,  2.6817,  2.6632,  2.5297,  2.6501,  2.5248,
          2.5248,  1.3443,  1.3467,  1.3459,  1.3490,  1.3436,  1.3510,  1.3449,
          1.3420,  1.3043,  1.2975,  1.2555,  1.2563,  1.2985,  1.2950,  1.2945,
          1.2968,  1.2937,  1.2937,  1.2783,  1.3226,  1.3165,  1.3194,  1.3226,
          1.3179,  1.3206,  1.2728,  1.3167,  1.7406,  1.7516,  1.7450,  1.7411,
          1.7494,  1.6892,  1.7421,  1.7275,  1.7402,  1.6068,  1.5898,  1.5859,
          1.5800,  1.6031,  1.5850,  1.6177,  1.5769,  1.5783],
        [ 1.3042,  1.3067,  1.2578,  1.2676,  1.3093,  1.3064,  1.3059,  1.3055,
          1.3055,  2.5262,  2.5071,  2.4113,  2.6005,  2.4182,  2.8993,  2.5070,
          2.5577,  2.8709,  1.2933,  1.2999,  1.2531,  1.2859,  1.3224,  1.3219,
          1.3150,  1.3210,  1.3210,  1.3231,  1.2612,  1.3439,  1.3471,  1.2792,
          1.3454,  1.3483,  1.3179,  1.3442,  1.7584,  1.7705,  1.7263,  1.7557,
          1.7680,  1.7693,  1.7231,  1.6604,  1.7571,  1.5706,  1.6099,  1.6057,
          1.5993,  1.5290,  1.6047,  1.5460,  1.5958,  1.5974],
        [ 1.2830,  1.2858,  1.2889,  1.2875,  1.2856,  1.2836,  1.2839,  1.2828,
          1.2828,  1.3490,  1.3515,  1.3506,  1.3537,  1.3483,  1.3041,  1.3496,
          1.2961,  1.3367,  2.5852,  2.6495,  2.7004,  2.5945,  2.5275,  2.5249,
          2.6279,  2.5193,  2.5193,  1.2919,  1.3115,  1.3214,  1.3244,  1.2926,
          1.3229,  1.3256,  1.3213,  1.3217,  1.7437,  1.7548,  1.7481,  1.6964,
          1.7525,  1.7523,  1.7452,  1.7282,  1.6954,  1.6102,  1.5933,  1.5893,
          1.5833,  1.5866,  1.5883,  1.6029,  1.5797,  1.5815],
        [ 1.2940,  1.2968,  1.2999,  1.2985,  1.2967,  1.2945,  1.2949,  1.2937,
          1.2937,  1.3600,  1.3624,  1.3616,  1.3454,  1.3592,  1.2710,  1.3606,
          1.3569,  1.2691,  1.3135,  1.2949,  1.3148,  1.3145,  1.3109,  1.3104,
          1.3118,  1.3095,  1.3095,  2.7527,  2.6951,  2.4495,  2.5517,  2.7509,
          2.4581,  2.6757,  2.4987,  2.4512,  1.7511,  1.7626,  1.7292,  1.7503,
          1.7602,  1.7601,  1.7262,  1.6911,  1.7493,  1.6194,  1.6016,  1.5046,
          1.5370,  1.6155,  1.5964,  1.6308,  1.5334,  1.5895],
        [ 1.8719,  1.4718,  0.6278,  0.9548,  1.3648,  1.8011,  1.6746,  1.9068,
          1.9068,  1.7371,  1.3566,  1.5534,  0.9525,  1.7659,  0.1548,  1.6690,
          1.9232,  0.8921,  1.3727,  1.0175,  0.7761,  1.1846,  1.7417,  1.8083,
          1.5624,  1.9145,  1.9145,  0.8753,  0.8856,  1.8874,  1.6885,  0.8964,
          1.8281,  1.2946,  1.9363,  1.8517, -0.0815, -0.3312, -0.3728, -0.1212,
          0.1339,  0.2320, -0.2111, 14.2119,  5.3306,  0.2365,  0.6037,  0.6370,
          0.7416,  0.3911,  0.7408, -0.0561,  0.7726,  0.8374],
        [ 1.3339,  1.3715,  1.4156,  1.4036,  1.3786,  1.3412,  1.3116,  1.3303,
          1.3303,  1.3011,  1.4237,  1.3225,  1.4536,  1.3804,  1.4791,  1.3089,
          1.3579,  1.3665,  1.3902,  1.3768,  1.4238,  1.4039,  1.3568,  1.3498,
          1.2584,  1.3382,  1.3382,  1.3921,  1.4357,  1.3537,  1.1486,  1.3485,
          1.2427,  1.4094,  1.2316,  1.3579,  0.3405,  0.2647,  0.3802,  0.3478,
          0.1413,  0.0955,  0.3642,  0.1454, -0.0649,  3.2087,  2.2503,  3.1929,
          2.5522,  1.8214,  1.4245,  2.7830,  2.9962,  1.3890]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 239 : 175.33742564028387
Test loss for epoch 239 : 175.3322885836663
Test Precision for epoch 239 : 0.26153846153846155
Test Recall for epoch 239 : 0.26153846153846155
Test F1 for epoch 239 : 0.26153846153846155


theta for epoch 240 : tensor([[ 2.5271,  2.5460,  2.5828,  2.6826,  2.6641,  2.5304,  2.6510,  2.5255,
          2.5255,  1.3447,  1.3471,  1.3463,  1.3493,  1.3440,  1.3514,  1.3453,
          1.3424,  1.3047,  1.2985,  1.2565,  1.2573,  1.2995,  1.2960,  1.2955,
          1.2978,  1.2947,  1.2947,  1.2786,  1.3228,  1.3167,  1.3196,  1.3229,
          1.3181,  1.3208,  1.2730,  1.3170,  1.7413,  1.7522,  1.7456,  1.7418,
          1.7500,  1.6898,  1.7427,  1.7281,  1.7408,  1.6064,  1.5895,  1.5856,
          1.5797,  1.6027,  1.5846,  1.6174,  1.5765,  1.5779],
        [ 1.3038,  1.3063,  1.2580,  1.2675,  1.3088,  1.3059,  1.3054,  1.3050,
          1.3050,  2.5266,  2.5087,  2.4128,  2.6025,  2.4190,  2.8990,  2.5081,
          2.5598,  2.8706,  1.2943,  1.3008,  1.2539,  1.2871,  1.3232,  1.3227,
          1.3161,  1.3218,  1.3218,  1.3232,  1.2618,  1.3440,  1.3471,  1.2796,
          1.3455,  1.3484,  1.3180,  1.3443,  1.7589,  1.7710,  1.7268,  1.7563,
          1.7684,  1.7697,  1.7236,  1.6619,  1.7576,  1.5701,  1.6094,  1.6051,
          1.5987,  1.5287,  1.6041,  1.5456,  1.5952,  1.5968],
        [ 1.2827,  1.2854,  1.2886,  1.2872,  1.2853,  1.2832,  1.2835,  1.2824,
          1.2824,  1.3494,  1.3519,  1.3510,  1.3541,  1.3487,  1.3043,  1.3500,
          1.2962,  1.3371,  2.5860,  2.6510,  2.7020,  2.5953,  2.5282,  2.5256,
          2.6294,  2.5200,  2.5200,  1.2919,  1.3118,  1.3216,  1.3246,  1.2925,
          1.3231,  1.3258,  1.3215,  1.3219,  1.7443,  1.7554,  1.7487,  1.6966,
          1.7531,  1.7529,  1.7458,  1.7288,  1.6956,  1.6098,  1.5928,  1.5889,
          1.5828,  1.5862,  1.5879,  1.6025,  1.5793,  1.5811],
        [ 1.2935,  1.2963,  1.2994,  1.2980,  1.2962,  1.2940,  1.2944,  1.2932,
          1.2932,  1.3601,  1.3625,  1.3617,  1.3455,  1.3593,  1.2715,  1.3607,
          1.3570,  1.2696,  1.3141,  1.2955,  1.3155,  1.3152,  1.3116,  1.3110,
          1.3125,  1.3102,  1.3102,  2.7540,  2.6962,  2.4509,  2.5526,  2.7522,
          2.4595,  2.6768,  2.5003,  2.4526,  1.7516,  1.7631,  1.7297,  1.7508,
          1.7608,  1.7606,  1.7267,  1.6920,  1.7498,  1.6188,  1.6010,  1.5044,
          1.5365,  1.6150,  1.5959,  1.6303,  1.5328,  1.5890],
        [ 1.8696,  1.4691,  0.6247,  0.9520,  1.3622,  1.7988,  1.6721,  1.9046,
          1.9046,  1.7343,  1.3538,  1.5509,  0.9496,  1.7633,  0.1515,  1.6663,
          1.9213,  0.8886,  1.3701,  1.0152,  0.7734,  1.1818,  1.7395,  1.8062,
          1.5603,  1.9125,  1.9125,  0.8725,  0.8823,  1.8851,  1.6861,  0.8933,
          1.8257,  1.2917,  1.9341,  1.8494, -0.0794, -0.3291, -0.3708, -0.1193,
          0.1357,  0.2338, -0.2090, 14.2575,  5.3141,  0.2336,  0.6009,  0.6340,
          0.7386,  0.3881,  0.7379, -0.0592,  0.7697,  0.8346],
        [ 1.3361,  1.3737,  1.4178,  1.4057,  1.3807,  1.3434,  1.3138,  1.3325,
          1.3325,  1.3041,  1.4266,  1.3255,  1.4566,  1.3834,  1.4820,  1.3119,
          1.3608,  1.3695,  1.3934,  1.3798,  1.4269,  1.4070,  1.3599,  1.3529,
          1.2614,  1.3414,  1.3414,  1.3947,  1.4383,  1.3563,  1.1513,  1.3512,
          1.2454,  1.4120,  1.2343,  1.3605,  0.3436,  0.2677,  0.3832,  0.3509,
          0.1444,  0.0985,  0.3673,  0.1484, -0.0619,  3.2092,  2.2481,  3.1933,
          2.5506,  1.8187,  1.4216,  2.7813,  2.9971,  1.3861]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 240 : 175.3273034848681
Test loss for epoch 240 : 175.3306064536084
Test Precision for epoch 240 : 0.26153846153846155
Test Recall for epoch 240 : 0.26153846153846155
Test F1 for epoch 240 : 0.26153846153846155


theta for epoch 241 : tensor([[ 2.5285,  2.5474,  2.5842,  2.6843,  2.6657,  2.5318,  2.6527,  2.5269,
          2.5269,  1.3448,  1.3472,  1.3464,  1.3494,  1.3441,  1.3515,  1.3454,
          1.3425,  1.3048,  1.2985,  1.2565,  1.2573,  1.2995,  1.2960,  1.2955,
          1.2978,  1.2947,  1.2947,  1.2786,  1.3228,  1.3167,  1.3197,  1.3229,
          1.3181,  1.3208,  1.2730,  1.3170,  1.7409,  1.7518,  1.7453,  1.7414,
          1.7496,  1.6895,  1.7424,  1.7278,  1.7404,  1.6070,  1.5901,  1.5862,
          1.5803,  1.6034,  1.5852,  1.6180,  1.5771,  1.5785],
        [ 1.3037,  1.3063,  1.2586,  1.2677,  1.3087,  1.3058,  1.3054,  1.3050,
          1.3050,  2.5274,  2.5106,  2.4147,  2.6049,  2.4203,  2.8992,  2.5096,
          2.5624,  2.8708,  1.2943,  1.3008,  1.2539,  1.2874,  1.3232,  1.3226,
          1.3163,  1.3217,  1.3217,  1.3232,  1.2622,  1.3438,  1.3470,  1.2799,
          1.3454,  1.3483,  1.3179,  1.3442,  1.7585,  1.7705,  1.7264,  1.7559,
          1.7680,  1.7693,  1.7232,  1.6626,  1.7571,  1.5708,  1.6099,  1.6057,
          1.5992,  1.5294,  1.6046,  1.5463,  1.5958,  1.5973],
        [ 1.2829,  1.2856,  1.2887,  1.2874,  1.2855,  1.2834,  1.2837,  1.2826,
          1.2826,  1.3498,  1.3522,  1.3514,  1.3545,  1.3491,  1.3044,  1.3504,
          1.2964,  1.3375,  2.5865,  2.6524,  2.7034,  2.5958,  2.5286,  2.5260,
          2.6306,  2.5204,  2.5204,  1.2918,  1.3119,  1.3218,  1.3248,  1.2925,
          1.3232,  1.3260,  1.3217,  1.3221,  1.7440,  1.7551,  1.7484,  1.6960,
          1.7528,  1.7526,  1.7455,  1.7286,  1.6950,  1.6106,  1.5936,  1.5897,
          1.5836,  1.5870,  1.5886,  1.6032,  1.5800,  1.5818],
        [ 1.2934,  1.2962,  1.2993,  1.2980,  1.2961,  1.2939,  1.2944,  1.2931,
          1.2931,  1.3601,  1.3625,  1.3617,  1.3454,  1.3593,  1.2717,  1.3607,
          1.3570,  1.2698,  1.3140,  1.2954,  1.3153,  1.3151,  1.3115,  1.3109,
          1.3123,  1.3101,  1.3101,  2.7555,  2.6976,  2.4526,  2.5538,  2.7538,
          2.4612,  2.6782,  2.5021,  2.4543,  1.7512,  1.7627,  1.7292,  1.7503,
          1.7603,  1.7601,  1.7262,  1.6920,  1.7493,  1.6193,  1.6015,  1.5053,
          1.5370,  1.6155,  1.5964,  1.6308,  1.5333,  1.5895],
        [ 1.8714,  1.4713,  0.6270,  0.9542,  1.3644,  1.8006,  1.6741,  1.9064,
          1.9064,  1.7361,  1.3561,  1.5530,  0.9522,  1.7652,  0.1541,  1.6683,
          1.9234,  0.8909,  1.3725,  1.0179,  0.7762,  1.1841,  1.7416,  1.8082,
          1.5625,  1.9145,  1.9145,  0.8751,  0.8846,  1.8872,  1.6882,  0.8959,
          1.8278,  1.2940,  1.9361,  1.8515, -0.0821, -0.3316, -0.3734, -0.1221,
          0.1328,  0.2307, -0.2116, 14.2982,  5.2919,  0.2366,  0.6037,  0.6368,
          0.7415,  0.3910,  0.7408, -0.0562,  0.7726,  0.8374],
        [ 1.3338,  1.3714,  1.4154,  1.4034,  1.3784,  1.3411,  1.3115,  1.3301,
          1.3301,  1.3015,  1.4240,  1.3228,  1.4539,  1.3808,  1.4794,  1.3092,
          1.3581,  1.3669,  1.3906,  1.3768,  1.4242,  1.4043,  1.3572,  1.3501,
          1.2584,  1.3386,  1.3386,  1.3923,  1.4359,  1.3539,  1.1485,  1.3487,
          1.2429,  1.4096,  1.2318,  1.3581,  0.3408,  0.2649,  0.3804,  0.3481,
          0.1415,  0.0956,  0.3645,  0.1455, -0.0650,  3.2159,  2.2520,  3.1998,
          2.5550,  1.8220,  1.4247,  2.7856,  3.0042,  1.3892]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 241 : 175.3141962792627
Test loss for epoch 241 : 175.31611033150313
Test Precision for epoch 241 : 0.26153846153846155
Test Recall for epoch 241 : 0.26153846153846155
Test F1 for epoch 241 : 0.26153846153846155


theta for epoch 242 : tensor([[ 2.5310,  2.5500,  2.5867,  2.6870,  2.6684,  2.5343,  2.6554,  2.5294,
          2.5294,  1.3446,  1.3470,  1.3462,  1.3492,  1.3439,  1.3513,  1.3452,
          1.3423,  1.3045,  1.2984,  1.2564,  1.2571,  1.2994,  1.2959,  1.2954,
          1.2977,  1.2946,  1.2946,  1.2783,  1.3226,  1.3165,  1.3194,  1.3227,
          1.3179,  1.3206,  1.2728,  1.3168,  1.7408,  1.7518,  1.7452,  1.7413,
          1.7495,  1.6894,  1.7423,  1.7277,  1.7404,  1.6052,  1.5882,  1.5844,
          1.5784,  1.6015,  1.5834,  1.6162,  1.5752,  1.5767],
        [ 1.3041,  1.3067,  1.2596,  1.2684,  1.3091,  1.3061,  1.3058,  1.3053,
          1.3053,  2.5289,  2.5132,  2.4173,  2.6078,  2.4222,  2.9000,  2.5118,
          2.5656,  2.8717,  1.2943,  1.3008,  1.2539,  1.2877,  1.3232,  1.3226,
          1.3166,  1.3218,  1.3218,  1.3230,  1.2624,  1.3436,  1.3468,  1.2800,
          1.3452,  1.3481,  1.3177,  1.3439,  1.7584,  1.7705,  1.7264,  1.7559,
          1.7679,  1.7692,  1.7232,  1.6636,  1.7570,  1.5689,  1.6079,  1.6037,
          1.5973,  1.5276,  1.6026,  1.5445,  1.5938,  1.5954],
        [ 1.2833,  1.2861,  1.2892,  1.2878,  1.2859,  1.2838,  1.2841,  1.2830,
          1.2830,  1.3498,  1.3522,  1.3513,  1.3544,  1.3490,  1.3041,  1.3503,
          1.2960,  1.3375,  2.5885,  2.6551,  2.7063,  2.5978,  2.5306,  2.5280,
          2.6334,  2.5224,  2.5224,  1.2914,  1.3118,  1.3216,  1.3246,  1.2921,
          1.3231,  1.3258,  1.3215,  1.3219,  1.7440,  1.7551,  1.7484,  1.6956,
          1.7528,  1.7526,  1.7455,  1.7287,  1.6946,  1.6089,  1.5919,  1.5879,
          1.5818,  1.5853,  1.5869,  1.6015,  1.5782,  1.5800],
        [ 1.2937,  1.2966,  1.2996,  1.2983,  1.2965,  1.2943,  1.2947,  1.2935,
          1.2935,  1.3599,  1.3623,  1.3615,  1.3452,  1.3592,  1.2718,  1.3605,
          1.3568,  1.2700,  1.3140,  1.2953,  1.3153,  1.3150,  1.3114,  1.3109,
          1.3123,  1.3100,  1.3100,  2.7576,  2.6995,  2.4549,  2.5555,  2.7559,
          2.4635,  2.6801,  2.5046,  2.4566,  1.7511,  1.7626,  1.7291,  1.7503,
          1.7603,  1.7601,  1.7261,  1.6923,  1.7492,  1.6176,  1.5998,  1.5040,
          1.5352,  1.6137,  1.5946,  1.6291,  1.5315,  1.5877],
        [ 1.8716,  1.4713,  0.6267,  0.9541,  1.3645,  1.8009,  1.6742,  1.9067,
          1.9067,  1.7355,  1.3558,  1.5528,  0.9519,  1.7648,  0.1536,  1.6679,
          1.9235,  0.8901,  1.3722,  1.0179,  0.7760,  1.1837,  1.7415,  1.8081,
          1.5625,  1.9144,  1.9144,  0.8748,  0.8840,  1.8870,  1.6879,  0.8954,
          1.8276,  1.2936,  1.9359,  1.8513, -0.0822, -0.3316, -0.3734, -0.1223,
          0.1324,  0.2303, -0.2117, 14.3417,  5.2725,  0.2360,  0.6030,  0.6360,
          0.7408,  0.3904,  0.7401, -0.0568,  0.7719,  0.8367],
        [ 1.3352,  1.3727,  1.4168,  1.4048,  1.3798,  1.3424,  1.3129,  1.3315,
          1.3315,  1.3028,  1.4253,  1.3241,  1.4552,  1.3821,  1.4807,  1.3106,
          1.3593,  1.3682,  1.3920,  1.3779,  1.4255,  1.4056,  1.3585,  1.3515,
          1.2595,  1.3399,  1.3399,  1.3933,  1.4370,  1.3550,  1.1495,  1.3498,
          1.2440,  1.4107,  1.2329,  1.3592,  0.3420,  0.2660,  0.3815,  0.3493,
          0.1426,  0.0967,  0.3656,  0.1466, -0.0639,  3.2182,  2.2516,  3.2019,
          2.5551,  1.8211,  1.4236,  2.7857,  3.0069,  1.3881]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 242 : 175.3020885160855
Test loss for epoch 242 : 175.3085483363033
Test Precision for epoch 242 : 0.26153846153846155
Test Recall for epoch 242 : 0.26153846153846155
Test F1 for epoch 242 : 0.26153846153846155


theta for epoch 243 : tensor([[ 2.5329,  2.5518,  2.5886,  2.6891,  2.6705,  2.5362,  2.6575,  2.5313,
          2.5313,  1.3444,  1.3467,  1.3459,  1.3490,  1.3436,  1.3510,  1.3449,
          1.3420,  1.3043,  1.2979,  1.2559,  1.2566,  1.2989,  1.2954,  1.2949,
          1.2972,  1.2941,  1.2941,  1.2781,  1.3223,  1.3162,  1.3192,  1.3224,
          1.3177,  1.3204,  1.2725,  1.3165,  1.7409,  1.7518,  1.7453,  1.7414,
          1.7496,  1.6894,  1.7424,  1.7278,  1.7404,  1.6050,  1.5881,  1.5842,
          1.5782,  1.6014,  1.5832,  1.6161,  1.5750,  1.5765],
        [ 1.3039,  1.3064,  1.2599,  1.2684,  1.3087,  1.3058,  1.3055,  1.3050,
          1.3050,  2.5304,  2.5157,  2.4198,  2.6108,  2.4242,  2.9007,  2.5139,
          2.5687,  2.8725,  1.2938,  1.3002,  1.2533,  1.2874,  1.3226,  1.3221,
          1.3162,  1.3212,  1.3212,  1.3226,  1.2625,  1.3432,  1.3464,  1.2800,
          1.3448,  1.3477,  1.3173,  1.3436,  1.7584,  1.7704,  1.7263,  1.7560,
          1.7679,  1.7692,  1.7232,  1.6646,  1.7570,  1.5687,  1.6077,  1.6034,
          1.5970,  1.5274,  1.6023,  1.5443,  1.5935,  1.5950],
        [ 1.2830,  1.2857,  1.2888,  1.2875,  1.2856,  1.2835,  1.2838,  1.2827,
          1.2827,  1.3493,  1.3517,  1.3508,  1.3539,  1.3485,  1.3034,  1.3498,
          1.2953,  1.3370,  2.5906,  2.6580,  2.7092,  2.5999,  2.5327,  2.5300,
          2.6362,  2.5244,  2.5244,  1.2908,  1.3114,  1.3212,  1.3242,  1.2914,
          1.3227,  1.3254,  1.3212,  1.3215,  1.7440,  1.7551,  1.7484,  1.6953,
          1.7528,  1.7526,  1.7455,  1.7287,  1.6943,  1.6086,  1.5916,  1.5876,
          1.5815,  1.5850,  1.5866,  1.6012,  1.5779,  1.5797],
        [ 1.2935,  1.2963,  1.2994,  1.2981,  1.2962,  1.2940,  1.2945,  1.2932,
          1.2932,  1.3596,  1.3620,  1.3612,  1.3449,  1.3588,  1.2718,  1.3602,
          1.3564,  1.2699,  1.3135,  1.2947,  1.3148,  1.3145,  1.3109,  1.3104,
          1.3118,  1.3095,  1.3095,  2.7596,  2.7013,  2.4570,  2.5571,  2.7578,
          2.4656,  2.6818,  2.5069,  2.4587,  1.7512,  1.7626,  1.7291,  1.7503,
          1.7603,  1.7601,  1.7261,  1.6928,  1.7492,  1.6174,  1.5996,  1.5041,
          1.5349,  1.6135,  1.5944,  1.6289,  1.5312,  1.5875],
        [ 1.8717,  1.4715,  0.6267,  0.9541,  1.3646,  1.8010,  1.6744,  1.9068,
          1.9068,  1.7352,  1.3558,  1.5529,  0.9521,  1.7647,  0.1535,  1.6677,
          1.9238,  0.8898,  1.3723,  1.0183,  0.7763,  1.1836,  1.7416,  1.8082,
          1.5627,  1.9145,  1.9145,  0.8750,  0.8838,  1.8871,  1.6880,  0.8954,
          1.8277,  1.2935,  1.9360,  1.8514, -0.0827, -0.3320, -0.3739, -0.1229,
          0.1317,  0.2295, -0.2121, 14.3847,  5.2525,  0.2362,  0.6032,  0.6360,
          0.7409,  0.3905,  0.7402, -0.0566,  0.7720,  0.8368],
        [ 1.3357,  1.3733,  1.4172,  1.4053,  1.3803,  1.3430,  1.3134,  1.3320,
          1.3320,  1.3035,  1.4259,  1.3247,  1.4558,  1.3828,  1.4813,  1.3113,
          1.3599,  1.3689,  1.3926,  1.3782,  1.4261,  1.4062,  1.3591,  1.3521,
          1.2599,  1.3406,  1.3406,  1.3938,  1.4375,  1.3556,  1.1499,  1.3503,
          1.2446,  1.4113,  1.2335,  1.3597,  0.3426,  0.2666,  0.3820,  0.3500,
          0.1432,  0.0973,  0.3663,  0.1471, -0.0634,  3.2212,  2.2519,  3.2048,
          2.5559,  1.8209,  1.4232,  2.7865,  3.0104,  1.3877]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 243 : 175.29307999427334
Test loss for epoch 243 : 175.30315275842366
Test Precision for epoch 243 : 0.26153846153846155
Test Recall for epoch 243 : 0.26153846153846155
Test F1 for epoch 243 : 0.26153846153846155


theta for epoch 244 : tensor([[ 2.5338,  2.5527,  2.5895,  2.6902,  2.6716,  2.5371,  2.6586,  2.5322,
          2.5322,  1.3442,  1.3466,  1.3457,  1.3488,  1.3435,  1.3508,  1.3448,
          1.3419,  1.3041,  1.2973,  1.2553,  1.2561,  1.2984,  1.2949,  1.2944,
          1.2967,  1.2936,  1.2936,  1.2780,  1.3222,  1.3161,  1.3191,  1.3223,
          1.3175,  1.3202,  1.2724,  1.3164,  1.7408,  1.7518,  1.7452,  1.7413,
          1.7495,  1.6894,  1.7423,  1.7277,  1.7404,  1.6070,  1.5900,  1.5861,
          1.5801,  1.6033,  1.5851,  1.6180,  1.5769,  1.5784],
        [ 1.3030,  1.3056,  1.2597,  1.2678,  1.3079,  1.3050,  1.3047,  1.3041,
          1.3041,  2.5314,  2.5177,  2.4218,  2.6133,  2.4256,  2.9011,  2.5155,
          2.5714,  2.8729,  1.2930,  1.2993,  1.2525,  1.2868,  1.3217,  1.3212,
          1.3156,  1.3203,  1.3203,  1.3222,  1.2626,  1.3429,  1.3461,  1.2799,
          1.3444,  1.3473,  1.3170,  1.3432,  1.7582,  1.7702,  1.7262,  1.7558,
          1.7677,  1.7690,  1.7230,  1.6654,  1.7568,  1.5706,  1.6095,  1.6053,
          1.5988,  1.5294,  1.6042,  1.5463,  1.5953,  1.5969],
        [ 1.2821,  1.2849,  1.2880,  1.2866,  1.2847,  1.2827,  1.2830,  1.2819,
          1.2819,  1.3489,  1.3513,  1.3504,  1.3535,  1.3481,  1.3028,  1.3494,
          1.2946,  1.3366,  2.5919,  2.6600,  2.7113,  2.6011,  2.5339,  2.5312,
          2.6382,  2.5257,  2.5257,  1.2902,  1.3111,  1.3209,  1.3239,  1.2909,
          1.3224,  1.3251,  1.3209,  1.3212,  1.7438,  1.7550,  1.7483,  1.6948,
          1.7527,  1.7525,  1.7453,  1.7287,  1.6938,  1.6104,  1.5933,  1.5893,
          1.5833,  1.5868,  1.5883,  1.6029,  1.5796,  1.5815],
        [ 1.2927,  1.2956,  1.2986,  1.2973,  1.2955,  1.2933,  1.2937,  1.2925,
          1.2925,  1.3593,  1.3617,  1.3609,  1.3445,  1.3585,  1.2718,  1.3598,
          1.3561,  1.2699,  1.3128,  1.2941,  1.3141,  1.3139,  1.3103,  1.3097,
          1.3111,  1.3089,  1.3089,  2.7609,  2.7024,  2.4586,  2.5581,  2.7592,
          2.4672,  2.6830,  2.5085,  2.4603,  1.7510,  1.7625,  1.7289,  1.7501,
          1.7601,  1.7599,  1.7259,  1.6931,  1.7491,  1.6191,  1.6013,  1.5062,
          1.5366,  1.6152,  1.5961,  1.6306,  1.5329,  1.5891],
        [ 1.8726,  1.4726,  0.6281,  0.9554,  1.3659,  1.8020,  1.6754,  1.9077,
          1.9077,  1.7363,  1.3574,  1.5544,  0.9539,  1.7659,  0.1553,  1.6690,
          1.9253,  0.8913,  1.3739,  1.0202,  0.7782,  1.1852,  1.7430,  1.8095,
          1.5643,  1.9157,  1.9157,  0.8768,  0.8853,  1.8885,  1.6894,  0.8971,
          1.8292,  1.2951,  1.9374,  1.8528, -0.0848, -0.3339, -0.3758, -0.1250,
          0.1294,  0.2271, -0.2140, 14.4261,  5.2305,  0.2386,  0.6056,  0.6383,
          0.7432,  0.3929,  0.7426, -0.0542,  0.7744,  0.8392],
        [ 1.3338,  1.3714,  1.4153,  1.4034,  1.3784,  1.3411,  1.3115,  1.3302,
          1.3302,  1.3018,  1.4242,  1.3229,  1.4540,  1.3811,  1.4795,  1.3095,
          1.3581,  1.3672,  1.3907,  1.3761,  1.4242,  1.4043,  1.3572,  1.3502,
          1.2578,  1.3387,  1.3387,  1.3922,  1.4360,  1.3539,  1.1481,  1.3486,
          1.2430,  1.4097,  1.2318,  1.3581,  0.3409,  0.2649,  0.3803,  0.3483,
          0.1414,  0.0955,  0.3646,  0.1453, -0.0653,  3.2269,  2.2549,  3.2104,
          2.5594,  1.8233,  1.4255,  2.7899,  3.0166,  1.3900]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 244 : 175.28521132136743
Test loss for epoch 244 : 175.29534493172454
Test Precision for epoch 244 : 0.26153846153846155
Test Recall for epoch 244 : 0.26153846153846155
Test F1 for epoch 244 : 0.26153846153846155


theta for epoch 245 : tensor([[ 2.5353,  2.5543,  2.5910,  2.6920,  2.6734,  2.5386,  2.6603,  2.5337,
          2.5337,  1.3442,  1.3466,  1.3457,  1.3488,  1.3434,  1.3508,  1.3447,
          1.3419,  1.3041,  1.2976,  1.2556,  1.2563,  1.2986,  1.2952,  1.2947,
          1.2970,  1.2938,  1.2938,  1.2780,  1.3222,  1.3161,  1.3191,  1.3223,
          1.3175,  1.3202,  1.2724,  1.3164,  1.7412,  1.7521,  1.7456,  1.7417,
          1.7499,  1.6897,  1.7426,  1.7280,  1.7407,  1.6059,  1.5889,  1.5850,
          1.5790,  1.6022,  1.5840,  1.6169,  1.5758,  1.5772],
        [ 1.3029,  1.3055,  1.2601,  1.2679,  1.3077,  1.3048,  1.3046,  1.3039,
          1.3039,  2.5322,  2.5195,  2.4237,  2.6156,  2.4269,  2.9015,  2.5170,
          2.5739,  2.8733,  1.2934,  1.2996,  1.2528,  1.2875,  1.3220,  1.3215,
          1.3162,  1.3206,  1.3206,  1.3222,  1.2630,  1.3428,  1.3460,  1.2802,
          1.3444,  1.3473,  1.3169,  1.3431,  1.7584,  1.7704,  1.7265,  1.7562,
          1.7679,  1.7692,  1.7233,  1.6667,  1.7570,  1.5695,  1.6083,  1.6040,
          1.5975,  1.5283,  1.6029,  1.5452,  1.5940,  1.5956],
        [ 1.2820,  1.2848,  1.2878,  1.2865,  1.2846,  1.2825,  1.2828,  1.2817,
          1.2817,  1.3489,  1.3513,  1.3504,  1.3535,  1.3481,  1.3026,  1.3494,
          1.2944,  1.3366,  2.5933,  2.6622,  2.7136,  2.6026,  2.5353,  2.5326,
          2.6403,  2.5270,  2.5270,  1.2900,  1.3111,  1.3209,  1.3239,  1.2906,
          1.3224,  1.3251,  1.3208,  1.3212,  1.7442,  1.7553,  1.7487,  1.6948,
          1.7530,  1.7528,  1.7457,  1.7291,  1.6938,  1.6093,  1.5922,  1.5882,
          1.5821,  1.5857,  1.5872,  1.6018,  1.5785,  1.5803],
        [ 1.2926,  1.2954,  1.2985,  1.2972,  1.2953,  1.2931,  1.2936,  1.2923,
          1.2923,  1.3593,  1.3617,  1.3609,  1.3445,  1.3585,  1.2721,  1.3599,
          1.3561,  1.2702,  1.3131,  1.2943,  1.3144,  1.3142,  1.3106,  1.3100,
          1.3114,  1.3092,  1.3092,  2.7623,  2.7037,  2.4602,  2.5592,  2.7606,
          2.4688,  2.6842,  2.5103,  2.4619,  1.7513,  1.7628,  1.7292,  1.7504,
          1.7605,  1.7602,  1.7262,  1.6939,  1.7494,  1.6180,  1.6002,  1.5056,
          1.5356,  1.6142,  1.5950,  1.6296,  1.5318,  1.5880],
        [ 1.8713,  1.4711,  0.6261,  0.9537,  1.3644,  1.8007,  1.6740,  1.9065,
          1.9065,  1.7343,  1.3555,  1.5528,  0.9521,  1.7642,  0.1531,  1.6672,
          1.9242,  0.8889,  1.3722,  1.0188,  0.7765,  1.1833,  1.7416,  1.8082,
          1.5630,  1.9145,  1.9145,  0.8750,  0.8832,  1.8871,  1.6878,  0.8951,
          1.8277,  1.2932,  1.9360,  1.8513, -0.0836, -0.3326, -0.3746, -0.1239,
          0.1305,  0.2281, -0.2128, 14.4709,  5.2122,  0.2366,  0.6035,  0.6360,
          0.7411,  0.3908,  0.7405, -0.0562,  0.7723,  0.8370],
        [ 1.3358,  1.3733,  1.4172,  1.4054,  1.3804,  1.3430,  1.3135,  1.3321,
          1.3321,  1.3043,  1.4265,  1.3253,  1.4564,  1.3835,  1.4819,  1.3119,
          1.3605,  1.3696,  1.3931,  1.3784,  1.4266,  1.4068,  1.3597,  1.3527,
          1.2601,  1.3412,  1.3412,  1.3943,  1.4380,  1.3561,  1.1502,  1.3507,
          1.2451,  1.4118,  1.2340,  1.3602,  0.3434,  0.2673,  0.3826,  0.3508,
          0.1438,  0.0979,  0.3670,  0.1477, -0.0630,  3.2281,  2.2533,  3.2114,
          2.5583,  1.8212,  1.4231,  2.7888,  3.0181,  1.3876]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 245 : 175.27588046069138
Test loss for epoch 245 : 175.29301022178504
Test Precision for epoch 245 : 0.26153846153846155
Test Recall for epoch 245 : 0.26153846153846155
Test F1 for epoch 245 : 0.26153846153846155


theta for epoch 246 : tensor([[ 2.5375,  2.5564,  2.5932,  2.6943,  2.6757,  2.5407,  2.6627,  2.5358,
          2.5358,  1.3440,  1.3463,  1.3455,  1.3486,  1.3432,  1.3506,  1.3445,
          1.3416,  1.3038,  1.2972,  1.2552,  1.2559,  1.2982,  1.2948,  1.2943,
          1.2966,  1.2935,  1.2935,  1.2779,  1.3221,  1.3160,  1.3190,  1.3222,
          1.3174,  1.3201,  1.2723,  1.3163,  1.7406,  1.7515,  1.7450,  1.7411,
          1.7493,  1.6891,  1.7421,  1.7274,  1.7401,  1.6055,  1.5884,  1.5846,
          1.5786,  1.6018,  1.5835,  1.6165,  1.5754,  1.5768],
        [ 1.3031,  1.3057,  1.2609,  1.2684,  1.3079,  1.3049,  1.3048,  1.3041,
          1.3041,  2.5334,  2.5217,  2.4260,  2.6183,  2.4286,  2.9021,  2.5188,
          2.5767,  2.8740,  1.2931,  1.2994,  1.2525,  1.2875,  1.3218,  1.3212,
          1.3161,  1.3203,  1.3203,  1.3221,  1.2633,  1.3427,  1.3459,  1.2805,
          1.3443,  1.3472,  1.3169,  1.3430,  1.7578,  1.7698,  1.7259,  1.7556,
          1.7673,  1.7686,  1.7227,  1.6671,  1.7564,  1.5691,  1.6078,  1.6036,
          1.5971,  1.5280,  1.6025,  1.5449,  1.5936,  1.5952],
        [ 1.2824,  1.2852,  1.2883,  1.2869,  1.2850,  1.2829,  1.2832,  1.2821,
          1.2821,  1.3490,  1.3514,  1.3506,  1.3536,  1.3483,  1.3026,  1.3496,
          1.2943,  1.3368,  2.5944,  2.6640,  2.7155,  2.6036,  2.5362,  2.5335,
          2.6420,  2.5280,  2.5280,  1.2899,  1.3113,  1.3211,  1.3241,  1.2906,
          1.3225,  1.3253,  1.3210,  1.3214,  1.7437,  1.7548,  1.7482,  1.6940,
          1.7526,  1.7523,  1.7452,  1.7286,  1.6930,  1.6091,  1.5920,  1.5881,
          1.5819,  1.5855,  1.5870,  1.6016,  1.5783,  1.5801],
        [ 1.2928,  1.2957,  1.2987,  1.2974,  1.2956,  1.2934,  1.2938,  1.2926,
          1.2926,  1.3592,  1.3616,  1.3608,  1.3444,  1.3584,  1.2723,  1.3598,
          1.3560,  1.2705,  1.3129,  1.2941,  1.3142,  1.3140,  1.3104,  1.3098,
          1.3112,  1.3090,  1.3090,  2.7640,  2.7052,  2.4621,  2.5605,  2.7623,
          2.4708,  2.6857,  2.5124,  2.4639,  1.7507,  1.7622,  1.7286,  1.7498,
          1.7599,  1.7596,  1.7256,  1.6937,  1.7488,  1.6177,  1.5998,  1.5056,
          1.5352,  1.6138,  1.5947,  1.6292,  1.5314,  1.5877],
        [ 1.8733,  1.4734,  0.6286,  0.9560,  1.3668,  1.8028,  1.6761,  1.9085,
          1.9085,  1.7361,  1.3578,  1.5550,  0.9546,  1.7662,  0.1557,  1.6692,
          1.9263,  0.8912,  1.3746,  1.0214,  0.7792,  1.1857,  1.7437,  1.8103,
          1.5653,  1.9164,  1.9164,  0.8776,  0.8855,  1.8892,  1.6899,  0.8976,
          1.8299,  1.2955,  1.9381,  1.8535, -0.0862, -0.3351, -0.3771, -0.1266,
          0.1276,  0.2251, -0.2154, 14.5117,  5.1892,  0.2393,  0.6060,  0.6384,
          0.7435,  0.3934,  0.7430, -0.0534,  0.7748,  0.8394],
        [ 1.3341,  1.3717,  1.4155,  1.4037,  1.3787,  1.3414,  1.3118,  1.3304,
          1.3304,  1.3022,  1.4244,  1.3231,  1.4542,  1.3813,  1.4797,  1.3098,
          1.3583,  1.3674,  1.3909,  1.3759,  1.4244,  1.4046,  1.3575,  1.3505,
          1.2576,  1.3389,  1.3389,  1.3923,  1.4362,  1.3541,  1.1480,  1.3488,
          1.2431,  1.4099,  1.2320,  1.3583,  0.3410,  0.2649,  0.3802,  0.3484,
          0.1413,  0.0954,  0.3646,  0.1452, -0.0655,  3.2342,  2.2566,  3.2173,
          2.5621,  1.8239,  1.4257,  2.7926,  3.0246,  1.3902]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 246 : 175.26437984498233
Test loss for epoch 246 : 175.28052090825804
Test Precision for epoch 246 : 0.26153846153846155
Test Recall for epoch 246 : 0.26153846153846155
Test F1 for epoch 246 : 0.26153846153846155


theta for epoch 247 : tensor([[ 2.5392,  2.5581,  2.5949,  2.6962,  2.6776,  2.5425,  2.6646,  2.5376,
          2.5376,  1.3439,  1.3463,  1.3454,  1.3485,  1.3432,  1.3505,  1.3444,
          1.3416,  1.3037,  1.2974,  1.2554,  1.2561,  1.2984,  1.2950,  1.2945,
          1.2968,  1.2936,  1.2936,  1.2778,  1.3221,  1.3159,  1.3189,  1.3221,
          1.3174,  1.3201,  1.2722,  1.3162,  1.7406,  1.7515,  1.7450,  1.7411,
          1.7493,  1.6891,  1.7420,  1.7274,  1.7401,  1.6044,  1.5874,  1.5835,
          1.5775,  1.6007,  1.5825,  1.6155,  1.5743,  1.5757],
        [ 1.3031,  1.3057,  1.2615,  1.2687,  1.3078,  1.3049,  1.3048,  1.3040,
          1.3040,  2.5345,  2.5237,  2.4281,  2.6208,  2.4302,  2.9027,  2.5205,
          2.5794,  2.8746,  1.2934,  1.2996,  1.2527,  1.2879,  1.3219,  1.3214,
          1.3165,  1.3205,  1.3205,  1.3220,  1.2636,  1.3426,  1.3458,  1.2807,
          1.3441,  1.3471,  1.3167,  1.3429,  1.7578,  1.7697,  1.7258,  1.7556,
          1.7673,  1.7685,  1.7226,  1.6680,  1.7563,  1.5680,  1.6067,  1.6024,
          1.5959,  1.5270,  1.6013,  1.5438,  1.5924,  1.5940],
        [ 1.2825,  1.2853,  1.2883,  1.2870,  1.2851,  1.2830,  1.2833,  1.2822,
          1.2822,  1.3491,  1.3515,  1.3506,  1.3537,  1.3483,  1.3024,  1.3496,
          1.2941,  1.3368,  2.5958,  2.6662,  2.7177,  2.6050,  2.5376,  2.5349,
          2.6441,  2.5294,  2.5294,  1.2897,  1.3113,  1.3211,  1.3241,  1.2904,
          1.3225,  1.3253,  1.3210,  1.3214,  1.7437,  1.7548,  1.7482,  1.6937,
          1.7526,  1.7523,  1.7452,  1.7287,  1.6927,  1.6081,  1.5910,  1.5871,
          1.5810,  1.5846,  1.5860,  1.6006,  1.5772,  1.5791],
        [ 1.2928,  1.2956,  1.2987,  1.2974,  1.2955,  1.2933,  1.2938,  1.2925,
          1.2925,  1.3591,  1.3615,  1.3606,  1.3442,  1.3583,  1.2725,  1.3596,
          1.3559,  1.2707,  1.3130,  1.2942,  1.3143,  1.3141,  1.3105,  1.3099,
          1.3113,  1.3091,  1.3091,  2.7657,  2.7067,  2.4641,  2.5619,  2.7640,
          2.4727,  2.6872,  2.5145,  2.4658,  1.7507,  1.7621,  1.7285,  1.7498,
          1.7598,  1.7596,  1.7255,  1.6941,  1.7487,  1.6166,  1.5988,  1.5050,
          1.5341,  1.6128,  1.5936,  1.6282,  1.5303,  1.5866],
        [ 1.8729,  1.4729,  0.6277,  0.9553,  1.3663,  1.8024,  1.6757,  1.9081,
          1.9081,  1.7352,  1.3570,  1.5543,  0.9539,  1.7654,  0.1547,  1.6684,
          1.9260,  0.8899,  1.3739,  1.0210,  0.7786,  1.1849,  1.7433,  1.8098,
          1.5649,  1.9160,  1.9160,  0.8769,  0.8844,  1.8887,  1.6892,  0.8967,
          1.8293,  1.2947,  1.9375,  1.8529, -0.0860, -0.3348, -0.3769, -0.1265,
          0.1276,  0.2250, -0.2151, 14.5555,  5.1695,  0.2384,  0.6049,  0.6372,
          0.7424,  0.3924,  0.7419, -0.0543,  0.7737,  0.8383],
        [ 1.3354,  1.3729,  1.4167,  1.4049,  1.3799,  1.3426,  1.3130,  1.3317,
          1.3317,  1.3036,  1.4257,  1.3245,  1.4556,  1.3828,  1.4811,  1.3112,
          1.3597,  1.3688,  1.3924,  1.3772,  1.4258,  1.4061,  1.3590,  1.3520,
          1.2589,  1.3404,  1.3404,  1.3935,  1.4374,  1.3554,  1.1492,  1.3500,
          1.2444,  1.4111,  1.2333,  1.3595,  0.3423,  0.2662,  0.3814,  0.3497,
          0.1426,  0.0967,  0.3660,  0.1465, -0.0643,  3.2364,  2.2560,  3.2193,
          2.5621,  1.8229,  1.4245,  2.7925,  3.0272,  1.3890]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 247 : 175.2528156915112
Test loss for epoch 247 : 175.27407360276348
Test Precision for epoch 247 : 0.26153846153846155
Test Recall for epoch 247 : 0.26153846153846155
Test F1 for epoch 247 : 0.26153846153846155


theta for epoch 248 : tensor([[ 2.5402,  2.5591,  2.5959,  2.6974,  2.6788,  2.5435,  2.6658,  2.5386,
          2.5386,  1.3438,  1.3462,  1.3453,  1.3484,  1.3431,  1.3504,  1.3444,
          1.3415,  1.3037,  1.2973,  1.2553,  1.2560,  1.2983,  1.2949,  1.2944,
          1.2966,  1.2935,  1.2935,  1.2777,  1.3219,  1.3158,  1.3188,  1.3220,
          1.3172,  1.3199,  1.2721,  1.3161,  1.7406,  1.7515,  1.7450,  1.7411,
          1.7493,  1.6891,  1.7421,  1.7275,  1.7401,  1.6054,  1.5883,  1.5844,
          1.5784,  1.6017,  1.5834,  1.6164,  1.5752,  1.5766],
        [ 1.3025,  1.3052,  1.2615,  1.2684,  1.3072,  1.3043,  1.3042,  1.3034,
          1.3034,  2.5355,  2.5256,  2.4300,  2.6232,  2.4316,  2.9032,  2.5221,
          2.5820,  2.8752,  1.2930,  1.2992,  1.2523,  1.2878,  1.3215,  1.3210,
          1.3163,  1.3201,  1.3201,  1.3216,  1.2636,  1.3422,  1.3454,  1.2807,
          1.3438,  1.3467,  1.3164,  1.3425,  1.7576,  1.7696,  1.7257,  1.7556,
          1.7672,  1.7684,  1.7225,  1.6688,  1.7562,  1.5689,  1.6075,  1.6032,
          1.5967,  1.5279,  1.6021,  1.5447,  1.5932,  1.5948],
        [ 1.2819,  1.2847,  1.2878,  1.2864,  1.2846,  1.2825,  1.2828,  1.2817,
          1.2817,  1.3488,  1.3512,  1.3503,  1.3534,  1.3481,  1.3019,  1.3494,
          1.2937,  1.3366,  2.5971,  2.6682,  2.7198,  2.6063,  2.5388,  2.5361,
          2.6461,  2.5306,  2.5306,  1.2892,  1.3110,  1.3208,  1.3238,  1.2899,
          1.3223,  1.3250,  1.3207,  1.3211,  1.7437,  1.7548,  1.7482,  1.6934,
          1.7526,  1.7523,  1.7452,  1.7287,  1.6924,  1.6090,  1.5918,  1.5879,
          1.5818,  1.5854,  1.5868,  1.6015,  1.5780,  1.5799],
        [ 1.2922,  1.2951,  1.2981,  1.2968,  1.2950,  1.2928,  1.2932,  1.2919,
          1.2919,  1.3588,  1.3611,  1.3603,  1.3439,  1.3580,  1.2725,  1.3593,
          1.3556,  1.2707,  1.3127,  1.2938,  1.3140,  1.3137,  1.3101,  1.3096,
          1.3109,  1.3087,  1.3087,  2.7671,  2.7080,  2.4658,  2.5629,  2.7654,
          2.4744,  2.6885,  2.5163,  2.4675,  1.7506,  1.7620,  1.7284,  1.7497,
          1.7597,  1.7595,  1.7254,  1.6945,  1.7486,  1.6174,  1.5995,  1.5061,
          1.5348,  1.6135,  1.5943,  1.6289,  1.5310,  1.5873],
        [ 1.8729,  1.4730,  0.6278,  0.9554,  1.3664,  1.8025,  1.6757,  1.9082,
          1.9082,  1.7351,  1.3572,  1.5546,  0.9543,  1.7655,  0.1549,  1.6684,
          1.9265,  0.8898,  1.3743,  1.0216,  0.7791,  1.1851,  1.7436,  1.8101,
          1.5653,  1.9163,  1.9163,  0.8773,  0.8845,  1.8889,  1.6894,  0.8969,
          1.8296,  1.2948,  1.9378,  1.8532, -0.0868, -0.3355, -0.3776, -0.1274,
          0.1267,  0.2240, -0.2158, 14.5983,  5.1483,  0.2390,  0.6055,  0.6377,
          0.7429,  0.3930,  0.7425, -0.0536,  0.7743,  0.8389],
        [ 1.3350,  1.3725,  1.4163,  1.4046,  1.3796,  1.3423,  1.3127,  1.3313,
          1.3313,  1.3036,  1.4256,  1.3244,  1.4554,  1.3827,  1.4810,  1.3111,
          1.3595,  1.3687,  1.3923,  1.3768,  1.4257,  1.4059,  1.3589,  1.3518,
          1.2586,  1.3403,  1.3403,  1.3933,  1.4372,  1.3552,  1.1489,  1.3498,
          1.2443,  1.4110,  1.2331,  1.3594,  0.3423,  0.2661,  0.3813,  0.3497,
          0.1425,  0.0966,  0.3659,  0.1463, -0.0645,  3.2403,  2.2572,  3.2230,
          2.5638,  1.8235,  1.4250,  2.7941,  3.0315,  1.3895]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 248 : 175.24256978244975
Test loss for epoch 248 : 175.2666455620009
Test Precision for epoch 248 : 0.26153846153846155
Test Recall for epoch 248 : 0.26153846153846155
Test F1 for epoch 248 : 0.26153846153846155


theta for epoch 249 : tensor([[ 2.5415,  2.5605,  2.5973,  2.6990,  2.6804,  2.5448,  2.6674,  2.5399,
          2.5399,  1.3436,  1.3459,  1.3451,  1.3481,  1.3428,  1.3502,  1.3441,
          1.3412,  1.3034,  1.2968,  1.2548,  1.2555,  1.2978,  1.2944,  1.2939,
          1.2961,  1.2930,  1.2930,  1.2774,  1.3217,  1.3156,  1.3185,  1.3218,
          1.3170,  1.3197,  1.2718,  1.3159,  1.7405,  1.7514,  1.7449,  1.7410,
          1.7492,  1.6891,  1.7420,  1.7274,  1.7401,  1.6062,  1.5891,  1.5853,
          1.5792,  1.6025,  1.5842,  1.6172,  1.5760,  1.5774],
        [ 1.3021,  1.3048,  1.2616,  1.2683,  1.3067,  1.3038,  1.3038,  1.3030,
          1.3030,  2.5366,  2.5275,  2.4321,  2.6257,  2.4332,  2.9039,  2.5237,
          2.5846,  2.8759,  1.2923,  1.2984,  1.2516,  1.2873,  1.3208,  1.3203,
          1.3158,  1.3194,  1.3194,  1.3212,  1.2636,  1.3418,  1.3450,  1.2806,
          1.3433,  1.3462,  1.3160,  1.3421,  1.7574,  1.7694,  1.7255,  1.7554,
          1.7670,  1.7682,  1.7223,  1.6696,  1.7560,  1.5697,  1.6082,  1.6040,
          1.5974,  1.5288,  1.6028,  1.5456,  1.5939,  1.5955],
        [ 1.2815,  1.2843,  1.2873,  1.2860,  1.2841,  1.2821,  1.2824,  1.2813,
          1.2813,  1.3484,  1.3508,  1.3499,  1.3530,  1.3476,  1.3013,  1.3490,
          1.2930,  1.3361,  2.5985,  2.6704,  2.7221,  2.6078,  2.5403,  2.5375,
          2.6482,  2.5321,  2.5321,  1.2886,  1.3106,  1.3204,  1.3234,  1.2893,
          1.3219,  1.3246,  1.3203,  1.3207,  1.7436,  1.7547,  1.7480,  1.6929,
          1.7524,  1.7521,  1.7450,  1.7287,  1.6919,  1.6097,  1.5926,  1.5886,
          1.5825,  1.5862,  1.5875,  1.6022,  1.5787,  1.5806],
        [ 1.2918,  1.2947,  1.2977,  1.2964,  1.2946,  1.2924,  1.2928,  1.2916,
          1.2916,  1.3584,  1.3607,  1.3599,  1.3435,  1.3576,  1.2725,  1.3589,
          1.3552,  1.2707,  1.3120,  1.2932,  1.3133,  1.3131,  1.3095,  1.3090,
          1.3103,  1.3081,  1.3081,  2.7686,  2.7093,  2.4676,  2.5641,  2.7669,
          2.4762,  2.6898,  2.5183,  2.4693,  1.7504,  1.7619,  1.7282,  1.7495,
          1.7596,  1.7593,  1.7252,  1.6949,  1.7485,  1.6180,  1.6002,  1.5072,
          1.5355,  1.6142,  1.5949,  1.6296,  1.5317,  1.5880],
        [ 1.8737,  1.4739,  0.6289,  0.9564,  1.3675,  1.8033,  1.6766,  1.9090,
          1.9090,  1.7357,  1.3583,  1.5557,  0.9555,  1.7663,  0.1561,  1.6692,
          1.9276,  0.8907,  1.3753,  1.0230,  0.7805,  1.1861,  1.7445,  1.8110,
          1.5665,  1.9172,  1.9172,  0.8785,  0.8854,  1.8898,  1.6903,  0.8980,
          1.8305,  1.2958,  1.9387,  1.8542, -0.0883, -0.3368, -0.3790, -0.1290,
          0.1249,  0.2222, -0.2173, 14.6403,  5.1262,  0.2406,  0.6070,  0.6390,
          0.7443,  0.3945,  0.7439, -0.0520,  0.7757,  0.8403],
        [ 1.3342,  1.3717,  1.4154,  1.4037,  1.3787,  1.3414,  1.3118,  1.3305,
          1.3305,  1.3027,  1.4247,  1.3235,  1.4545,  1.3818,  1.4800,  1.3102,
          1.3586,  1.3678,  1.3913,  1.3756,  1.4247,  1.4050,  1.3579,  1.3509,
          1.2574,  1.3394,  1.3394,  1.3924,  1.4364,  1.3544,  1.1479,  1.3489,
          1.2434,  1.4102,  1.2322,  1.3585,  0.3414,  0.2652,  0.3804,  0.3489,
          0.1416,  0.0957,  0.3650,  0.1453, -0.0655,  3.2450,  2.2591,  3.2276,
          2.5662,  1.8249,  1.4262,  2.7965,  3.0367,  1.3908]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 249 : 175.23377986661222
Test loss for epoch 249 : 175.2592282395575
Test Precision for epoch 249 : 0.26153846153846155
Test Recall for epoch 249 : 0.26153846153846155
Test F1 for epoch 249 : 0.26153846153846155


theta for epoch 250 : tensor([[ 2.5436,  2.5625,  2.5993,  2.7013,  2.6826,  2.5469,  2.6696,  2.5420,
          2.5420,  1.3434,  1.3457,  1.3449,  1.3479,  1.3426,  1.3499,  1.3439,
          1.3410,  1.3032,  1.2966,  1.2546,  1.2553,  1.2976,  1.2942,  1.2937,
          1.2960,  1.2929,  1.2929,  1.2772,  1.3215,  1.3154,  1.3183,  1.3216,
          1.3168,  1.3195,  1.2716,  1.3157,  1.7407,  1.7516,  1.7451,  1.7412,
          1.7494,  1.6892,  1.7421,  1.7275,  1.7402,  1.6045,  1.5874,  1.5835,
          1.5775,  1.6008,  1.5825,  1.6155,  1.5743,  1.5757],
        [ 1.3023,  1.3049,  1.2623,  1.2687,  1.3068,  1.3039,  1.3039,  1.3031,
          1.3031,  2.5378,  2.5296,  2.4343,  2.6283,  2.4349,  2.9046,  2.5255,
          2.5874,  2.8767,  1.2924,  1.2984,  1.2516,  1.2875,  1.3208,  1.3202,
          1.3159,  1.3193,  1.3193,  1.3210,  1.2638,  1.3416,  1.3448,  1.2807,
          1.3432,  1.3461,  1.3158,  1.3419,  1.7575,  1.7695,  1.7256,  1.7556,
          1.7671,  1.7683,  1.7224,  1.6706,  1.7561,  1.5680,  1.6064,  1.6022,
          1.5956,  1.5271,  1.6011,  1.5439,  1.5921,  1.5937],
        [ 1.2816,  1.2844,  1.2874,  1.2861,  1.2843,  1.2822,  1.2825,  1.2814,
          1.2814,  1.3482,  1.3506,  1.3497,  1.3528,  1.3475,  1.3009,  1.3488,
          1.2926,  1.3360,  2.6004,  2.6730,  2.7247,  2.6096,  2.5421,  2.5394,
          2.6508,  2.5339,  2.5339,  1.2882,  1.3104,  1.3203,  1.3233,  1.2889,
          1.3217,  1.3245,  1.3202,  1.3206,  1.7437,  1.7548,  1.7482,  1.6927,
          1.7526,  1.7523,  1.7452,  1.7288,  1.6918,  1.6080,  1.5909,  1.5869,
          1.5808,  1.5845,  1.5858,  1.6005,  1.5770,  1.5790],
        [ 1.2919,  1.2948,  1.2978,  1.2965,  1.2947,  1.2925,  1.2929,  1.2917,
          1.2917,  1.3582,  1.3606,  1.3598,  1.3433,  1.3574,  1.2727,  1.3588,
          1.3550,  1.2709,  1.3120,  1.2931,  1.3133,  1.3130,  1.3094,  1.3089,
          1.3102,  1.3081,  1.3081,  2.7703,  2.7108,  2.4696,  2.5655,  2.7686,
          2.4783,  2.6913,  2.5204,  2.4714,  1.7506,  1.7620,  1.7284,  1.7496,
          1.7597,  1.7594,  1.7253,  1.6955,  1.7486,  1.6164,  1.5985,  1.5061,
          1.5339,  1.6126,  1.5933,  1.6280,  1.5300,  1.5863],
        [ 1.8733,  1.4734,  0.6279,  0.9556,  1.3669,  1.8029,  1.6761,  1.9086,
          1.9086,  1.7346,  1.3573,  1.5549,  0.9546,  1.7654,  0.1550,  1.6683,
          1.9271,  0.8892,  1.3745,  1.0224,  0.7797,  1.1851,  1.7439,  1.8104,
          1.5659,  1.9166,  1.9166,  0.8776,  0.8842,  1.8892,  1.6894,  0.8969,
          1.8298,  1.2947,  1.9380,  1.8535, -0.0879, -0.3364, -0.3786, -0.1286,
          0.1252,  0.2224, -0.2168, 14.6844,  5.1061,  0.2393,  0.6056,  0.6374,
          0.7428,  0.3931,  0.7424, -0.0532,  0.7742,  0.8388],
        [ 1.3359,  1.3734,  1.4171,  1.4054,  1.3804,  1.3431,  1.3135,  1.3322,
          1.3322,  1.3046,  1.4265,  1.3253,  1.4563,  1.3837,  1.4818,  1.3121,
          1.3604,  1.3697,  1.3931,  1.3773,  1.4265,  1.4068,  1.3597,  1.3527,
          1.2591,  1.3412,  1.3412,  1.3940,  1.4379,  1.3560,  1.1494,  1.3505,
          1.2450,  1.4117,  1.2339,  1.3602,  0.3432,  0.2670,  0.3821,  0.3506,
          0.1434,  0.0974,  0.3668,  0.1471, -0.0638,  3.2467,  2.2581,  3.2291,
          2.5657,  1.8234,  1.4245,  2.7960,  3.0388,  1.3890]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 250 : 175.22471868676055
Test loss for epoch 250 : 175.25585754614062
Test Precision for epoch 250 : 0.26153846153846155
Test Recall for epoch 250 : 0.26153846153846155
Test F1 for epoch 250 : 0.26153846153846155


theta for epoch 251 : tensor([[ 2.5452,  2.5642,  2.6010,  2.7031,  2.6845,  2.5485,  2.6715,  2.5436,
          2.5436,  1.3432,  1.3455,  1.3447,  1.3478,  1.3425,  1.3498,  1.3437,
          1.3408,  1.3030,  1.2963,  1.2542,  1.2549,  1.2973,  1.2938,  1.2933,
          1.2956,  1.2925,  1.2925,  1.2771,  1.3214,  1.3153,  1.3182,  1.3215,
          1.3167,  1.3194,  1.2715,  1.3156,  1.7403,  1.7512,  1.7447,  1.7408,
          1.7490,  1.6888,  1.7418,  1.7271,  1.7398,  1.6045,  1.5875,  1.5836,
          1.5776,  1.6008,  1.5825,  1.6156,  1.5743,  1.5758],
        [ 1.3022,  1.3048,  1.2627,  1.2689,  1.3067,  1.3038,  1.3038,  1.3029,
          1.3029,  2.5388,  2.5314,  2.4363,  2.6307,  2.4364,  2.9053,  2.5270,
          2.5899,  2.8774,  1.2920,  1.2980,  1.2512,  1.2874,  1.3204,  1.3199,
          1.3158,  1.3190,  1.3190,  1.3209,  1.2640,  1.3415,  1.3447,  1.2809,
          1.3430,  1.3459,  1.3157,  1.3418,  1.7571,  1.7691,  1.7252,  1.7552,
          1.7667,  1.7679,  1.7220,  1.6711,  1.7557,  1.5681,  1.6065,  1.6022,
          1.5957,  1.5273,  1.6011,  1.5440,  1.5921,  1.5938],
        [ 1.2816,  1.2844,  1.2874,  1.2861,  1.2843,  1.2822,  1.2825,  1.2814,
          1.2814,  1.3483,  1.3506,  1.3498,  1.3528,  1.3475,  1.3008,  1.3488,
          1.2924,  1.3360,  2.6015,  2.6748,  2.7266,  2.6107,  2.5431,  2.5403,
          2.6525,  2.5349,  2.5349,  1.2880,  1.3105,  1.3203,  1.3233,  1.2887,
          1.3217,  1.3245,  1.3202,  1.3206,  1.7434,  1.7545,  1.7479,  1.6921,
          1.7523,  1.7520,  1.7449,  1.7286,  1.6912,  1.6082,  1.5910,  1.5871,
          1.5810,  1.5847,  1.5860,  1.6006,  1.5772,  1.5791],
        [ 1.2918,  1.2947,  1.2977,  1.2964,  1.2946,  1.2924,  1.2928,  1.2915,
          1.2915,  1.3581,  1.3605,  1.3597,  1.3432,  1.3573,  1.2729,  1.3587,
          1.3549,  1.2711,  1.3117,  1.2927,  1.3129,  1.3127,  1.3091,  1.3086,
          1.3099,  1.3077,  1.3077,  2.7718,  2.7121,  2.4714,  2.5666,  2.7701,
          2.4801,  2.6926,  2.5224,  2.4732,  1.7502,  1.7616,  1.7279,  1.7492,
          1.7593,  1.7590,  1.7249,  1.6956,  1.7482,  1.6165,  1.5986,  1.5066,
          1.5340,  1.6126,  1.5934,  1.6281,  1.5301,  1.5864],
        [ 1.8749,  1.4752,  0.6299,  0.9575,  1.3688,  1.8046,  1.6779,  1.9102,
          1.9102,  1.7361,  1.3592,  1.5567,  0.9568,  1.7671,  0.1571,  1.6699,
          1.9290,  0.8912,  1.3765,  1.0247,  0.7820,  1.1871,  1.7457,  1.8121,
          1.5678,  1.9182,  1.9182,  0.8797,  0.8861,  1.8910,  1.6912,  0.8989,
          1.8317,  1.2967,  1.9398,  1.8553, -0.0902, -0.3385, -0.3808, -0.1311,
          0.1227,  0.2197, -0.2191, 14.7256,  5.0827,  0.2417,  0.6077,  0.6394,
          0.7449,  0.3954,  0.7445, -0.0508,  0.7764,  0.8408],
        [ 1.3342,  1.3717,  1.4154,  1.4037,  1.3787,  1.3415,  1.3119,  1.3305,
          1.3305,  1.3027,  1.4247,  1.3234,  1.4544,  1.3818,  1.4800,  1.3102,
          1.3585,  1.3678,  1.3912,  1.3751,  1.4245,  1.4048,  1.3578,  1.3508,
          1.2569,  1.3393,  1.3393,  1.3922,  1.4363,  1.3543,  1.1475,  1.3488,
          1.2433,  1.4101,  1.2322,  1.3585,  0.3412,  0.2650,  0.3800,  0.3487,
          0.1413,  0.0954,  0.3648,  0.1449, -0.0659,  3.2525,  2.2611,  3.2347,
          2.5692,  1.8258,  1.4268,  2.7994,  3.0450,  1.3913]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 251 : 175.2145603520386
Test loss for epoch 251 : 175.2453814706329
Test Precision for epoch 251 : 0.26153846153846155
Test Recall for epoch 251 : 0.26153846153846155
Test F1 for epoch 251 : 0.26153846153846155


theta for epoch 252 : tensor([[ 2.5464,  2.5653,  2.6021,  2.7044,  2.6858,  2.5496,  2.6728,  2.5447,
          2.5447,  1.3432,  1.3455,  1.3447,  1.3477,  1.3424,  1.3497,  1.3437,
          1.3408,  1.3030,  1.2965,  1.2545,  1.2552,  1.2975,  1.2941,  1.2936,
          1.2959,  1.2928,  1.2928,  1.2770,  1.3213,  1.3152,  1.3182,  1.3214,
          1.3166,  1.3194,  1.2715,  1.3155,  1.7405,  1.7514,  1.7449,  1.7410,
          1.7492,  1.6890,  1.7419,  1.7273,  1.7400,  1.6042,  1.5872,  1.5833,
          1.5773,  1.6006,  1.5822,  1.6153,  1.5740,  1.5755],
        [ 1.3018,  1.3045,  1.2629,  1.2688,  1.3063,  1.3033,  1.3034,  1.3025,
          1.3025,  2.5395,  2.5329,  2.4379,  2.6328,  2.4376,  2.9056,  2.5282,
          2.5921,  2.8778,  1.2923,  1.2983,  1.2515,  1.2879,  1.3206,  1.3201,
          1.3162,  1.3192,  1.3192,  1.3208,  1.2642,  1.3414,  1.3446,  1.2812,
          1.3429,  1.3458,  1.3156,  1.3417,  1.7572,  1.7692,  1.7253,  1.7554,
          1.7668,  1.7681,  1.7221,  1.6721,  1.7558,  1.5678,  1.6061,  1.6019,
          1.5953,  1.5270,  1.6008,  1.5437,  1.5918,  1.5934],
        [ 1.2813,  1.2841,  1.2871,  1.2858,  1.2839,  1.2819,  1.2822,  1.2811,
          1.2811,  1.3483,  1.3507,  1.3498,  1.3529,  1.3476,  1.3006,  1.3489,
          1.2923,  1.3361,  2.6025,  2.6765,  2.7284,  2.6117,  2.5441,  2.5413,
          2.6542,  2.5359,  2.5359,  1.2878,  1.3105,  1.3203,  1.3233,  1.2885,
          1.3217,  1.3245,  1.3202,  1.3206,  1.7436,  1.7547,  1.7481,  1.6920,
          1.7525,  1.7522,  1.7451,  1.7288,  1.6911,  1.6080,  1.5908,  1.5869,
          1.5807,  1.5845,  1.5858,  1.6004,  1.5769,  1.5789],
        [ 1.2914,  1.2943,  1.2973,  1.2960,  1.2942,  1.2920,  1.2924,  1.2911,
          1.2911,  1.3581,  1.3604,  1.3596,  1.3431,  1.3573,  1.2732,  1.3586,
          1.3549,  1.2714,  1.3118,  1.2929,  1.3131,  1.3129,  1.3093,  1.3088,
          1.3100,  1.3079,  1.3079,  2.7730,  2.7132,  2.4730,  2.5675,  2.7713,
          2.4816,  2.6936,  2.5241,  2.4748,  1.7503,  1.7617,  1.7281,  1.7493,
          1.7595,  1.7592,  1.7250,  1.6962,  1.7483,  1.6161,  1.5983,  1.5067,
          1.5336,  1.6123,  1.5931,  1.6277,  1.5297,  1.5861],
        [ 1.8739,  1.4741,  0.6286,  0.9563,  1.3677,  1.8036,  1.6768,  1.9093,
          1.9093,  1.7348,  1.3579,  1.5557,  0.9556,  1.7659,  0.1557,  1.6687,
          1.9283,  0.8894,  1.3754,  1.0238,  0.7810,  1.1859,  1.7448,  1.8113,
          1.5671,  1.9175,  1.9175,  0.8785,  0.8846,  1.8901,  1.6901,  0.8975,
          1.8307,  1.2953,  1.9389,  1.8544, -0.0896, -0.3379, -0.3803, -0.1306,
          0.1231,  0.2201, -0.2185, 14.7698,  5.0626,  0.2404,  0.6064,  0.6379,
          0.7435,  0.3940,  0.7432, -0.0520,  0.7750,  0.8395],
        [ 1.3354,  1.3728,  1.4165,  1.4048,  1.3798,  1.3426,  1.3130,  1.3317,
          1.3317,  1.3043,  1.4262,  1.3249,  1.4559,  1.3833,  1.4815,  1.3118,
          1.3600,  1.3693,  1.3928,  1.3765,  1.4261,  1.4064,  1.3594,  1.3524,
          1.2584,  1.3409,  1.3409,  1.3936,  1.4376,  1.3557,  1.1489,  1.3501,
          1.2447,  1.4114,  1.2336,  1.3598,  0.3428,  0.2665,  0.3815,  0.3502,
          0.1429,  0.0969,  0.3664,  0.1464, -0.0644,  3.2546,  2.2603,  3.2366,
          2.5690,  1.8246,  1.4255,  2.7992,  3.0474,  1.3900]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 252 : 175.20347174698284
Test loss for epoch 252 : 175.2400388713876
Test Precision for epoch 252 : 0.26153846153846155
Test Recall for epoch 252 : 0.26153846153846155
Test F1 for epoch 252 : 0.26153846153846155


theta for epoch 253 : tensor([[ 2.5477,  2.5666,  2.6034,  2.7059,  2.6873,  2.5509,  2.6743,  2.5460,
          2.5460,  1.3430,  1.3453,  1.3444,  1.3475,  1.3422,  1.3495,  1.3435,
          1.3406,  1.3028,  1.2963,  1.2542,  1.2550,  1.2973,  1.2938,  1.2934,
          1.2956,  1.2925,  1.2925,  1.2769,  1.3212,  1.3150,  1.3180,  1.3212,
          1.3165,  1.3192,  1.2713,  1.3153,  1.7403,  1.7512,  1.7447,  1.7408,
          1.7490,  1.6888,  1.7417,  1.7271,  1.7398,  1.6049,  1.5879,  1.5840,
          1.5780,  1.6013,  1.5830,  1.6160,  1.5747,  1.5762],
        [ 1.3014,  1.3041,  1.2630,  1.2687,  1.3058,  1.3029,  1.3030,  1.3021,
          1.3021,  2.5405,  2.5346,  2.4399,  2.6352,  2.4391,  2.9063,  2.5297,
          2.5946,  2.8785,  1.2920,  1.2979,  1.2511,  1.2877,  1.3202,  1.3197,
          1.3160,  1.3188,  1.3188,  1.3205,  1.2643,  1.3411,  1.3443,  1.2812,
          1.3426,  1.3455,  1.3153,  1.3414,  1.7569,  1.7689,  1.7250,  1.7551,
          1.7665,  1.7677,  1.7218,  1.6727,  1.7555,  1.5685,  1.6068,  1.6026,
          1.5960,  1.5278,  1.6014,  1.5445,  1.5925,  1.5941],
        [ 1.2810,  1.2838,  1.2868,  1.2855,  1.2836,  1.2816,  1.2819,  1.2808,
          1.2808,  1.3481,  1.3505,  1.3496,  1.3527,  1.3474,  1.3003,  1.3487,
          1.2919,  1.3359,  2.6037,  2.6784,  2.7303,  2.6129,  2.5452,  2.5424,
          2.6560,  2.5370,  2.5370,  1.2875,  1.3103,  1.3201,  1.3231,  1.2881,
          1.3216,  1.3243,  1.3200,  1.3204,  1.7434,  1.7545,  1.7479,  1.6915,
          1.7523,  1.7519,  1.7449,  1.7286,  1.6906,  1.6087,  1.5915,  1.5876,
          1.5814,  1.5852,  1.5865,  1.6011,  1.5776,  1.5796],
        [ 1.2911,  1.2939,  1.2969,  1.2957,  1.2938,  1.2916,  1.2920,  1.2908,
          1.2908,  1.3578,  1.3602,  1.3593,  1.3429,  1.3570,  1.2734,  1.3583,
          1.3546,  1.2716,  1.3115,  1.2925,  1.3128,  1.3126,  1.3090,  1.3084,
          1.3097,  1.3076,  1.3076,  2.7743,  2.7143,  2.4747,  2.5685,  2.7726,
          2.4833,  2.6948,  2.5259,  2.4765,  1.7500,  1.7615,  1.7278,  1.7490,
          1.7592,  1.7589,  1.7247,  1.6965,  1.7480,  1.6168,  1.5989,  1.5078,
          1.5342,  1.6129,  1.5937,  1.6284,  1.5303,  1.5867],
        [ 1.8745,  1.4749,  0.6294,  0.9570,  1.3685,  1.8043,  1.6775,  1.9099,
          1.9099,  1.7353,  1.3587,  1.5566,  0.9567,  1.7667,  0.1567,  1.6693,
          1.9292,  0.8900,  1.3763,  1.0250,  0.7821,  1.1868,  1.7457,  1.8121,
          1.5681,  1.9183,  1.9183,  0.8796,  0.8854,  1.8909,  1.6908,  0.8984,
          1.8316,  1.2961,  1.9397,  1.8552, -0.0910, -0.3392, -0.3816, -0.1321,
          0.1215,  0.2184, -0.2198, 14.8120,  5.0400,  0.2417,  0.6075,  0.6389,
          0.7446,  0.3952,  0.7443, -0.0506,  0.7761,  0.8406],
        [ 1.3346,  1.3721,  1.4157,  1.4041,  1.3791,  1.3418,  1.3123,  1.3309,
          1.3309,  1.3036,  1.4254,  1.3242,  1.4551,  1.3826,  1.4807,  1.3110,
          1.3592,  1.3686,  1.3920,  1.3755,  1.4253,  1.4057,  1.3586,  1.3516,
          1.2574,  1.3401,  1.3401,  1.3928,  1.4370,  1.3550,  1.1480,  1.3494,
          1.2440,  1.4108,  1.2329,  1.3591,  0.3420,  0.2658,  0.3807,  0.3495,
          0.1420,  0.0961,  0.3656,  0.1456, -0.0653,  3.2592,  2.2621,  3.2409,
          2.5713,  1.8259,  1.4266,  2.8014,  3.0524,  1.3911]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 253 : 175.19272312828508
Test loss for epoch 253 : 175.23098070175658
Test Precision for epoch 253 : 0.26153846153846155
Test Recall for epoch 253 : 0.26153846153846155
Test F1 for epoch 253 : 0.26153846153846155


theta for epoch 254 : tensor([[ 2.5496,  2.5685,  2.6053,  2.7080,  2.6894,  2.5528,  2.6764,  2.5479,
          2.5479,  1.3427,  1.3450,  1.3441,  1.3472,  1.3419,  1.3492,  1.3432,
          1.3403,  1.3024,  1.2959,  1.2539,  1.2546,  1.2969,  1.2935,  1.2930,
          1.2952,  1.2922,  1.2922,  1.2766,  1.3209,  1.3148,  1.3178,  1.3210,
          1.3162,  1.3189,  1.2710,  1.3151,  1.7400,  1.7509,  1.7445,  1.7405,
          1.7488,  1.6886,  1.7415,  1.7269,  1.7396,  1.6044,  1.5874,  1.5835,
          1.5775,  1.6008,  1.5825,  1.6155,  1.5742,  1.5757],
        [ 1.3013,  1.3040,  1.2635,  1.2689,  1.3057,  1.3028,  1.3030,  1.3020,
          1.3020,  2.5419,  2.5368,  2.4422,  2.6379,  2.4410,  2.9073,  2.5316,
          2.5975,  2.8796,  1.2916,  1.2974,  1.2507,  1.2874,  1.3197,  1.3192,
          1.3157,  1.3183,  1.3183,  1.3202,  1.2643,  1.3408,  1.3440,  1.2812,
          1.3423,  1.3452,  1.3150,  1.3411,  1.7566,  1.7686,  1.7247,  1.7548,
          1.7662,  1.7674,  1.7215,  1.6733,  1.7552,  1.5680,  1.6062,  1.6020,
          1.5954,  1.5273,  1.6009,  1.5439,  1.5919,  1.5935],
        [ 1.2810,  1.2838,  1.2868,  1.2855,  1.2836,  1.2815,  1.2819,  1.2807,
          1.2807,  1.3478,  1.3502,  1.3493,  1.3524,  1.3470,  1.2998,  1.3483,
          1.2913,  1.3356,  2.6054,  2.6808,  2.7328,  2.6146,  2.5469,  2.5441,
          2.6584,  2.5387,  2.5387,  1.2870,  1.3101,  1.3199,  1.3229,  1.2877,
          1.3213,  1.3241,  1.3198,  1.3202,  1.7431,  1.7543,  1.7477,  1.6910,
          1.7521,  1.7517,  1.7446,  1.7285,  1.6901,  1.6082,  1.5911,  1.5871,
          1.5810,  1.5847,  1.5860,  1.6006,  1.5771,  1.5792],
        [ 1.2910,  1.2939,  1.2968,  1.2956,  1.2938,  1.2916,  1.2920,  1.2907,
          1.2907,  1.3575,  1.3598,  1.3590,  1.3425,  1.3567,  1.2734,  1.3580,
          1.3543,  1.2716,  1.3112,  1.2921,  1.3124,  1.3122,  1.3086,  1.3081,
          1.3093,  1.3072,  1.3072,  2.7760,  2.7159,  2.4768,  2.5699,  2.7743,
          2.4854,  2.6963,  2.5281,  2.4785,  1.7498,  1.7612,  1.7275,  1.7487,
          1.7590,  1.7586,  1.7244,  1.6967,  1.7477,  1.6163,  1.5984,  1.5078,
          1.5338,  1.6124,  1.5932,  1.6279,  1.5298,  1.5862],
        [ 1.8752,  1.4756,  0.6300,  0.9576,  1.3692,  1.8050,  1.6782,  1.9106,
          1.9106,  1.7355,  1.3592,  1.5571,  0.9573,  1.7671,  0.1571,  1.6696,
          1.9299,  0.8902,  1.3769,  1.0258,  0.7829,  1.1873,  1.7462,  1.8127,
          1.5687,  1.9188,  1.9188,  0.8802,  0.8857,  1.8915,  1.6913,  0.8989,
          1.8322,  1.2965,  1.9403,  1.8558, -0.0920, -0.3401, -0.3825, -0.1331,
          0.1204,  0.2172, -0.2207, 14.8547,  5.0177,  0.2422,  0.6079,  0.6392,
          0.7450,  0.3957,  0.7447, -0.0500,  0.7765,  0.8410],
        [ 1.3348,  1.3723,  1.4158,  1.4043,  1.3793,  1.3420,  1.3125,  1.3311,
          1.3311,  1.3038,  1.4255,  1.3242,  1.4552,  1.3827,  1.4808,  1.3111,
          1.3593,  1.3687,  1.3921,  1.3754,  1.4254,  1.4057,  1.3587,  1.3517,
          1.2573,  1.3402,  1.3402,  1.3929,  1.4370,  1.3551,  1.1480,  1.3494,
          1.2441,  1.4109,  1.2330,  1.3592,  0.3420,  0.2657,  0.3806,  0.3495,
          0.1420,  0.0961,  0.3656,  0.1455, -0.0654,  3.2628,  2.2629,  3.2443,
          2.5726,  1.8262,  1.4267,  2.8027,  3.0564,  1.3913]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 254 : 175.18273344654688
Test loss for epoch 254 : 175.22376553792088
Test Precision for epoch 254 : 0.26153846153846155
Test Recall for epoch 254 : 0.26153846153846155
Test F1 for epoch 254 : 0.26153846153846155


theta for epoch 255 : tensor([[ 2.5512,  2.5702,  2.6070,  2.7099,  2.6913,  2.5545,  2.6783,  2.5496,
          2.5496,  1.3425,  1.3448,  1.3440,  1.3470,  1.3417,  1.3490,  1.3430,
          1.3401,  1.3023,  1.2958,  1.2537,  1.2545,  1.2968,  1.2933,  1.2928,
          1.2951,  1.2920,  1.2920,  1.2764,  1.3208,  1.3146,  1.3176,  1.3208,
          1.3161,  1.3188,  1.2709,  1.3149,  1.7401,  1.7510,  1.7446,  1.7406,
          1.7489,  1.6886,  1.7416,  1.7269,  1.7397,  1.6035,  1.5865,  1.5827,
          1.5766,  1.5999,  1.5816,  1.6146,  1.5733,  1.5748],
        [ 1.3013,  1.3040,  1.2639,  1.2692,  1.3057,  1.3027,  1.3029,  1.3019,
          1.3019,  2.5430,  2.5386,  2.4443,  2.6404,  2.4426,  2.9081,  2.5332,
          2.6001,  2.8804,  1.2914,  1.2973,  1.2505,  1.2875,  1.3196,  1.3190,
          1.3157,  1.3181,  1.3181,  1.3200,  1.2643,  1.3406,  1.3438,  1.2814,
          1.3421,  1.3450,  1.3148,  1.3409,  1.7566,  1.7686,  1.7247,  1.7549,
          1.7662,  1.7674,  1.7215,  1.6742,  1.7552,  1.5670,  1.6052,  1.6010,
          1.5945,  1.5264,  1.5999,  1.5430,  1.5909,  1.5926],
        [ 1.2810,  1.2838,  1.2867,  1.2855,  1.2836,  1.2815,  1.2818,  1.2807,
          1.2807,  1.3476,  1.3500,  1.3491,  1.3522,  1.3468,  1.2994,  1.3482,
          1.2909,  1.3354,  2.6071,  2.6831,  2.7351,  2.6162,  2.5485,  2.5457,
          2.6607,  2.5403,  2.5403,  1.2867,  1.3099,  1.3197,  1.3227,  1.2873,
          1.3212,  1.3239,  1.3196,  1.3200,  1.7432,  1.7543,  1.7477,  1.6908,
          1.7521,  1.7518,  1.7447,  1.7286,  1.6898,  1.6073,  1.5902,  1.5862,
          1.5801,  1.5839,  1.5852,  1.5997,  1.5762,  1.5783],
        [ 1.2909,  1.2938,  1.2967,  1.2956,  1.2937,  1.2915,  1.2919,  1.2907,
          1.2907,  1.3573,  1.3596,  1.3588,  1.3423,  1.3565,  1.2736,  1.3578,
          1.3541,  1.2718,  1.3109,  1.2919,  1.3122,  1.3120,  1.3084,  1.3079,
          1.3091,  1.3070,  1.3070,  2.7776,  2.7173,  2.4788,  2.5712,  2.7758,
          2.4874,  2.6977,  2.5302,  2.4806,  1.7498,  1.7612,  1.7275,  1.7487,
          1.7590,  1.7586,  1.7244,  1.6973,  1.7477,  1.6153,  1.5975,  1.5074,
          1.5329,  1.6115,  1.5923,  1.6269,  1.5289,  1.5853],
        [ 1.8752,  1.4755,  0.6296,  0.9574,  1.3692,  1.8050,  1.6781,  1.9106,
          1.9106,  1.7350,  1.3588,  1.5569,  0.9571,  1.7668,  0.1567,  1.6692,
          1.9300,  0.8895,  1.3767,  1.0258,  0.7827,  1.1869,  1.7461,  1.8126,
          1.5687,  1.9187,  1.9187,  0.8799,  0.8852,  1.8913,  1.6909,  0.8984,
          1.8320,  1.2961,  1.9402,  1.8557, -0.0922, -0.3402, -0.3827, -0.1334,
          0.1200,  0.2167, -0.2209, 14.8981,  4.9961,  0.2418,  0.6074,  0.6385,
          0.7444,  0.3952,  0.7441, -0.0503,  0.7759,  0.8403],
        [ 1.3357,  1.3731,  1.4166,  1.4051,  1.3801,  1.3429,  1.3133,  1.3320,
          1.3320,  1.3047,  1.4264,  1.3252,  1.4561,  1.3837,  1.4817,  1.3121,
          1.3601,  1.3696,  1.3930,  1.3762,  1.4263,  1.4067,  1.3596,  1.3526,
          1.2581,  1.3411,  1.3411,  1.3936,  1.4378,  1.3559,  1.1488,  1.3502,
          1.2449,  1.4117,  1.2338,  1.3601,  0.3429,  0.2666,  0.3815,  0.3504,
          0.1429,  0.0969,  0.3664,  0.1463, -0.0646,  3.2655,  2.2628,  3.2468,
          2.5731,  1.8256,  1.4260,  2.8031,  3.0595,  1.3905]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 255 : 175.1733965931738
Test loss for epoch 255 : 175.21878701327825
Test Precision for epoch 255 : 0.26153846153846155
Test Recall for epoch 255 : 0.26153846153846155
Test F1 for epoch 255 : 0.26153846153846155


theta for epoch 256 : tensor([[ 2.5523,  2.5712,  2.6080,  2.7112,  2.6925,  2.5556,  2.6795,  2.5507,
          2.5507,  1.3425,  1.3448,  1.3439,  1.3470,  1.3417,  1.3490,  1.3430,
          1.3401,  1.3022,  1.2956,  1.2535,  1.2543,  1.2966,  1.2931,  1.2926,
          1.2949,  1.2918,  1.2918,  1.2763,  1.3207,  1.3146,  1.3175,  1.3207,
          1.3160,  1.3187,  1.2708,  1.3148,  1.7401,  1.7510,  1.7445,  1.7406,
          1.7489,  1.6886,  1.7415,  1.7269,  1.7396,  1.6042,  1.5872,  1.5834,
          1.5773,  1.6006,  1.5823,  1.6153,  1.5740,  1.5755],
        [ 1.3009,  1.3036,  1.2641,  1.2691,  1.3053,  1.3023,  1.3025,  1.3015,
          1.3015,  2.5438,  2.5400,  2.4460,  2.6425,  2.4439,  2.9086,  2.5343,
          2.6023,  2.8809,  1.2911,  1.2969,  1.2502,  1.2873,  1.3192,  1.3187,
          1.3155,  1.3178,  1.3178,  1.3198,  1.2644,  1.3403,  1.3436,  1.2815,
          1.3419,  1.3448,  1.3146,  1.3407,  1.7565,  1.7684,  1.7246,  1.7548,
          1.7660,  1.7673,  1.7214,  1.6749,  1.7551,  1.5677,  1.6059,  1.6017,
          1.5952,  1.5271,  1.6006,  1.5437,  1.5916,  1.5932],
        [ 1.2807,  1.2834,  1.2864,  1.2852,  1.2833,  1.2812,  1.2815,  1.2804,
          1.2804,  1.3476,  1.3499,  1.3490,  1.3521,  1.3468,  1.2991,  1.3481,
          1.2907,  1.3354,  2.6079,  2.6846,  2.7368,  2.6171,  2.5493,  2.5465,
          2.6622,  2.5411,  2.5411,  1.2864,  1.3098,  1.3196,  1.3226,  1.2870,
          1.3211,  1.3238,  1.3195,  1.3199,  1.7432,  1.7543,  1.7477,  1.6905,
          1.7521,  1.7517,  1.7446,  1.7285,  1.6895,  1.6080,  1.5909,  1.5869,
          1.5808,  1.5846,  1.5858,  1.6003,  1.5769,  1.5790],
        [ 1.2906,  1.2934,  1.2963,  1.2952,  1.2933,  1.2911,  1.2915,  1.2903,
          1.2903,  1.3571,  1.3595,  1.3586,  1.3421,  1.3563,  1.2738,  1.3577,
          1.3539,  1.2721,  1.3106,  1.2916,  1.3119,  1.3117,  1.3081,  1.3075,
          1.3087,  1.3067,  1.3067,  2.7787,  2.7183,  2.4804,  2.5720,  2.7770,
          2.4890,  2.6987,  2.5319,  2.4821,  1.7497,  1.7611,  1.7274,  1.7486,
          1.7589,  1.7585,  1.7243,  1.6977,  1.7476,  1.6159,  1.5980,  1.5084,
          1.5335,  1.6121,  1.5929,  1.6275,  1.5295,  1.5859],
        [ 1.8760,  1.4766,  0.6308,  0.9585,  1.3703,  1.8059,  1.6791,  1.9115,
          1.9115,  1.7358,  1.3600,  1.5581,  0.9585,  1.7678,  0.1581,  1.6702,
          1.9312,  0.8906,  1.3779,  1.0274,  0.7842,  1.1881,  1.7472,  1.8137,
          1.5700,  1.9198,  1.9198,  0.8813,  0.8864,  1.8925,  1.6920,  0.8997,
          1.8332,  1.2973,  1.9413,  1.8568, -0.0939, -0.3418, -0.3843, -0.1352,
          0.1181,  0.2148, -0.2225, 14.9400,  4.9727,  0.2435,  0.6089,  0.6399,
          0.7459,  0.3968,  0.7456, -0.0486,  0.7775,  0.8419],
        [ 1.3344,  1.3718,  1.4153,  1.4038,  1.3788,  1.3415,  1.3120,  1.3306,
          1.3306,  1.3034,  1.4250,  1.3238,  1.4547,  1.3823,  1.4803,  1.3107,
          1.3587,  1.3682,  1.3915,  1.3745,  1.4248,  1.4052,  1.3582,  1.3512,
          1.2564,  1.3397,  1.3397,  1.3923,  1.4366,  1.3547,  1.1473,  1.3489,
          1.2436,  1.4104,  1.2325,  1.3588,  0.3415,  0.2653,  0.3801,  0.3490,
          0.1415,  0.0955,  0.3651,  0.1448, -0.0661,  3.2707,  2.2652,  3.2518,
          2.5760,  1.8275,  1.4277,  2.8059,  3.0652,  1.3922]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 256 : 175.16379633074175
Test loss for epoch 256 : 175.21011921620112
Test Precision for epoch 256 : 0.26153846153846155
Test Recall for epoch 256 : 0.26153846153846155
Test F1 for epoch 256 : 0.26153846153846155


theta for epoch 257 : tensor([[ 2.5535,  2.5725,  2.6093,  2.7126,  2.6940,  2.5568,  2.6810,  2.5519,
          2.5519,  1.3424,  1.3447,  1.3439,  1.3469,  1.3417,  1.3489,  1.3429,
          1.3400,  1.3022,  1.2957,  1.2537,  1.2544,  1.2967,  1.2933,  1.2928,
          1.2951,  1.2920,  1.2920,  1.2762,  1.3205,  1.3144,  1.3174,  1.3206,
          1.3159,  1.3186,  1.2707,  1.3147,  1.7403,  1.7512,  1.7448,  1.7408,
          1.7491,  1.6889,  1.7418,  1.7271,  1.7399,  1.6037,  1.5867,  1.5828,
          1.5768,  1.6000,  1.5818,  1.6147,  1.5735,  1.5750],
        [ 1.3007,  1.3034,  1.2644,  1.2692,  1.3050,  1.3021,  1.3023,  1.3012,
          1.3012,  2.5445,  2.5413,  2.4476,  2.6445,  2.4451,  2.9091,  2.5355,
          2.6045,  2.8815,  1.2913,  1.2971,  1.2503,  1.2877,  1.3194,  1.3188,
          1.3158,  1.3179,  1.3179,  1.3197,  1.2646,  1.3402,  1.3434,  1.2817,
          1.3417,  1.3447,  1.3144,  1.3405,  1.7566,  1.7686,  1.7248,  1.7550,
          1.7662,  1.7675,  1.7215,  1.6759,  1.7552,  1.5671,  1.6053,  1.6012,
          1.5946,  1.5266,  1.6000,  1.5432,  1.5910,  1.5927],
        [ 1.2805,  1.2832,  1.2861,  1.2849,  1.2831,  1.2810,  1.2813,  1.2802,
          1.2802,  1.3476,  1.3499,  1.3490,  1.3521,  1.3468,  1.2990,  1.3481,
          1.2905,  1.3354,  2.6092,  2.6865,  2.7387,  2.6184,  2.5505,  2.5477,
          2.6640,  2.5423,  2.5423,  1.2861,  1.3097,  1.3195,  1.3225,  1.2868,
          1.3210,  1.3237,  1.3194,  1.3198,  1.7434,  1.7545,  1.7479,  1.6904,
          1.7523,  1.7519,  1.7449,  1.7288,  1.6895,  1.6075,  1.5903,  1.5864,
          1.5803,  1.5841,  1.5853,  1.5998,  1.5764,  1.5785],
        [ 1.2903,  1.2931,  1.2960,  1.2949,  1.2930,  1.2908,  1.2912,  1.2900,
          1.2900,  1.3570,  1.3594,  1.3586,  1.3421,  1.3562,  1.2742,  1.3576,
          1.3538,  1.2724,  1.3107,  1.2916,  1.3119,  1.3117,  1.3081,  1.3076,
          1.3088,  1.3068,  1.3068,  2.7799,  2.7193,  2.4821,  2.5729,  2.7782,
          2.4907,  2.6998,  2.5337,  2.4838,  1.7498,  1.7613,  1.7276,  1.7488,
          1.7591,  1.7587,  1.7244,  1.6984,  1.7478,  1.6153,  1.5975,  1.5084,
          1.5329,  1.6115,  1.5923,  1.6269,  1.5289,  1.5853],
        [ 1.8753,  1.4757,  0.6297,  0.9574,  1.3694,  1.8052,  1.6783,  1.9108,
          1.9108,  1.7346,  1.3589,  1.5572,  0.9575,  1.7668,  0.1568,  1.6691,
          1.9307,  0.8890,  1.3770,  1.0266,  0.7833,  1.1871,  1.7465,  1.8129,
          1.5694,  1.9191,  1.9191,  0.8803,  0.8850,  1.8917,  1.6910,  0.8984,
          1.8324,  1.2961,  1.9405,  1.8560, -0.0935, -0.3413, -0.3839, -0.1349,
          0.1184,  0.2150, -0.2221, 14.9842,  4.9516,  0.2423,  0.6077,  0.6385,
          0.7446,  0.3955,  0.7444, -0.0497,  0.7762,  0.8406],
        [ 1.3355,  1.3729,  1.4164,  1.4049,  1.3799,  1.3427,  1.3131,  1.3318,
          1.3318,  1.3049,  1.4265,  1.3252,  1.4561,  1.3838,  1.4817,  1.3122,
          1.3602,  1.3697,  1.3930,  1.3758,  1.4263,  1.4067,  1.3597,  1.3527,
          1.2578,  1.3412,  1.3412,  1.3936,  1.4379,  1.3559,  1.1486,  1.3501,
          1.2449,  1.4117,  1.2338,  1.3601,  0.3430,  0.2668,  0.3816,  0.3505,
          0.1430,  0.0970,  0.3666,  0.1462, -0.0646,  3.2728,  2.2645,  3.2537,
          2.5758,  1.8263,  1.4264,  2.8057,  3.0677,  1.3909]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 257 : 175.15371557838955
Test loss for epoch 257 : 175.2056370039398
Test Precision for epoch 257 : 0.26153846153846155
Test Recall for epoch 257 : 0.26153846153846155
Test F1 for epoch 257 : 0.26153846153846155


theta for epoch 258 : tensor([[ 2.5553,  2.5742,  2.6111,  2.7146,  2.6959,  2.5586,  2.6829,  2.5537,
          2.5537,  1.3421,  1.3444,  1.3436,  1.3466,  1.3414,  1.3487,  1.3427,
          1.3397,  1.3019,  1.2953,  1.2533,  1.2540,  1.2963,  1.2929,  1.2924,
          1.2946,  1.2915,  1.2915,  1.2760,  1.3203,  1.3142,  1.3172,  1.3204,
          1.3156,  1.3184,  1.2704,  1.3145,  1.7399,  1.7508,  1.7444,  1.7404,
          1.7487,  1.6885,  1.7414,  1.7267,  1.7395,  1.6037,  1.5867,  1.5829,
          1.5769,  1.6001,  1.5818,  1.6148,  1.5736,  1.5751],
        [ 1.3005,  1.3032,  1.2647,  1.2694,  1.3048,  1.3019,  1.3022,  1.3010,
          1.3010,  2.5457,  2.5432,  2.4498,  2.6471,  2.4469,  2.9101,  2.5371,
          2.6071,  2.8825,  1.2909,  1.2966,  1.2499,  1.2874,  1.3189,  1.3183,
          1.3155,  1.3175,  1.3175,  1.3194,  1.2646,  1.3400,  1.3432,  1.2819,
          1.3415,  1.3444,  1.3142,  1.3403,  1.7562,  1.7681,  1.7244,  1.7546,
          1.7658,  1.7671,  1.7211,  1.6763,  1.7548,  1.5672,  1.6054,  1.6012,
          1.5947,  1.5267,  1.6001,  1.5432,  1.5911,  1.5928],
        [ 1.2804,  1.2832,  1.2861,  1.2849,  1.2830,  1.2809,  1.2813,  1.2802,
          1.2802,  1.3474,  1.3497,  1.3489,  1.3519,  1.3466,  1.2986,  1.3479,
          1.2902,  1.3352,  2.6105,  2.6886,  2.7408,  2.6197,  2.5519,  2.5490,
          2.6660,  2.5437,  2.5437,  1.2858,  1.3096,  1.3194,  1.3224,  1.2865,
          1.3208,  1.3236,  1.3193,  1.3197,  1.7430,  1.7542,  1.7476,  1.6898,
          1.7520,  1.7516,  1.7445,  1.7285,  1.6889,  1.6076,  1.5905,  1.5866,
          1.5805,  1.5842,  1.5855,  1.5999,  1.5765,  1.5787],
        [ 1.2901,  1.2930,  1.2959,  1.2948,  1.2929,  1.2907,  1.2911,  1.2899,
          1.2899,  1.3568,  1.3592,  1.3583,  1.3418,  1.3560,  1.2743,  1.3573,
          1.3536,  1.2726,  1.3103,  1.2912,  1.3116,  1.3113,  1.3077,  1.3072,
          1.3084,  1.3064,  1.3064,  2.7814,  2.7207,  2.4841,  2.5741,  2.7797,
          2.4927,  2.7011,  2.5359,  2.4858,  1.7494,  1.7609,  1.7271,  1.7483,
          1.7587,  1.7583,  1.7240,  1.6985,  1.7474,  1.6154,  1.5976,  1.5089,
          1.5330,  1.6116,  1.5924,  1.6270,  1.5290,  1.5854],
        [ 1.8766,  1.4771,  0.6312,  0.9588,  1.3709,  1.8065,  1.6797,  1.9120,
          1.9120,  1.7357,  1.3603,  1.5586,  0.9591,  1.7681,  0.1584,  1.6702,
          1.9321,  0.8903,  1.3785,  1.0283,  0.7850,  1.1885,  1.7478,  1.8142,
          1.5708,  1.9204,  1.9204,  0.8818,  0.8864,  1.8931,  1.6922,  0.8998,
          1.8338,  1.2975,  1.9419,  1.8574, -0.0954, -0.3430, -0.3857, -0.1368,
          0.1164,  0.2129, -0.2239, 15.0259,  4.9277,  0.2440,  0.6092,  0.6399,
          0.7462,  0.3972,  0.7459, -0.0479,  0.7778,  0.8421],
        [ 1.3346,  1.3720,  1.4154,  1.4040,  1.3790,  1.3418,  1.3122,  1.3309,
          1.3309,  1.3038,  1.4254,  1.3241,  1.4550,  1.3827,  1.4806,  1.3111,
          1.3590,  1.3686,  1.3918,  1.3745,  1.4251,  1.4055,  1.3585,  1.3515,
          1.2564,  1.3400,  1.3400,  1.3925,  1.4369,  1.3550,  1.1475,  1.3491,
          1.2439,  1.4108,  1.2328,  1.3591,  0.3418,  0.2656,  0.3803,  0.3493,
          0.1417,  0.0957,  0.3654,  0.1448, -0.0660,  3.2777,  2.2666,  3.2583,
          2.5784,  1.8279,  1.4279,  2.8083,  3.0730,  1.3924]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 258 : 175.14312090496838
Test loss for epoch 258 : 175.1959229170354
Test Precision for epoch 258 : 0.26153846153846155
Test Recall for epoch 258 : 0.26153846153846155
Test F1 for epoch 258 : 0.26153846153846155


theta for epoch 259 : tensor([[ 2.5571,  2.5760,  2.6128,  2.7165,  2.6979,  2.5604,  2.6849,  2.5555,
          2.5555,  1.3419,  1.3442,  1.3433,  1.3464,  1.3411,  1.3484,  1.3424,
          1.3395,  1.3017,  1.2952,  1.2531,  1.2538,  1.2962,  1.2927,  1.2922,
          1.2945,  1.2914,  1.2914,  1.2758,  1.3202,  1.3141,  1.3170,  1.3202,
          1.3155,  1.3182,  1.2703,  1.3143,  1.7398,  1.7507,  1.7443,  1.7403,
          1.7486,  1.6884,  1.7413,  1.7266,  1.7394,  1.6030,  1.5861,  1.5823,
          1.5762,  1.5994,  1.5812,  1.6141,  1.5729,  1.5745],
        [ 1.3004,  1.3031,  1.2651,  1.2696,  1.3047,  1.3017,  1.3020,  1.3009,
          1.3009,  2.5469,  2.5450,  2.4519,  2.6496,  2.4487,  2.9111,  2.5387,
          2.6098,  2.8835,  1.2907,  1.2965,  1.2497,  1.2875,  1.3187,  1.3182,
          1.3155,  1.3173,  1.3173,  1.3192,  1.2647,  1.3398,  1.3430,  1.2820,
          1.3413,  1.3442,  1.3140,  1.3401,  1.7560,  1.7680,  1.7242,  1.7545,
          1.7656,  1.7669,  1.7209,  1.6770,  1.7547,  1.5665,  1.6047,  1.6005,
          1.5940,  1.5261,  1.5994,  1.5426,  1.5904,  1.5921],
        [ 1.2804,  1.2831,  1.2860,  1.2848,  1.2830,  1.2809,  1.2812,  1.2801,
          1.2801,  1.3472,  1.3495,  1.3487,  1.3517,  1.3464,  1.2983,  1.3477,
          1.2898,  1.3351,  2.6122,  2.6908,  2.7431,  2.6214,  2.5535,  2.5506,
          2.6682,  2.5453,  2.5453,  1.2855,  1.3095,  1.3193,  1.3223,  1.2861,
          1.3207,  1.3235,  1.3192,  1.3196,  1.7430,  1.7541,  1.7475,  1.6895,
          1.7519,  1.7515,  1.7444,  1.7284,  1.6886,  1.6070,  1.5899,  1.5860,
          1.5799,  1.5836,  1.5849,  1.5993,  1.5759,  1.5781],
        [ 1.2900,  1.2929,  1.2958,  1.2947,  1.2928,  1.2906,  1.2910,  1.2898,
          1.2898,  1.3566,  1.3589,  1.3581,  1.3416,  1.3558,  1.2745,  1.3571,
          1.3533,  1.2728,  1.3102,  1.2911,  1.3114,  1.3112,  1.3076,  1.3071,
          1.3082,  1.3062,  1.3062,  2.7830,  2.7221,  2.4861,  2.5754,  2.7813,
          2.4948,  2.7025,  2.5380,  2.4879,  1.7493,  1.7608,  1.7270,  1.7482,
          1.7585,  1.7581,  1.7239,  1.6990,  1.7472,  1.6147,  1.5969,  1.5088,
          1.5324,  1.6109,  1.5918,  1.6263,  1.5283,  1.5848],
        [ 1.8766,  1.4770,  0.6309,  0.9586,  1.3709,  1.8065,  1.6796,  1.9121,
          1.9121,  1.7352,  1.3599,  1.5584,  0.9589,  1.7678,  0.1580,  1.6698,
          1.9321,  0.8895,  1.3783,  1.0284,  0.7849,  1.1882,  1.7477,  1.8142,
          1.5708,  1.9203,  1.9203,  0.8816,  0.8859,  1.8930,  1.6920,  0.8994,
          1.8337,  1.2971,  1.9419,  1.8573, -0.0957, -0.3432, -0.3859, -0.1372,
          0.1160,  0.2124, -0.2241, 15.0694,  4.9055,  0.2436,  0.6088,  0.6393,
          0.7457,  0.3967,  0.7455, -0.0482,  0.7773,  0.8417],
        [ 1.3355,  1.3729,  1.4162,  1.4048,  1.3798,  1.3427,  1.3131,  1.3318,
          1.3318,  1.3048,  1.4263,  1.3250,  1.4558,  1.3836,  1.4814,  1.3120,
          1.3599,  1.3695,  1.3928,  1.3752,  1.4260,  1.4065,  1.3595,  1.3525,
          1.2572,  1.3410,  1.3410,  1.3933,  1.4377,  1.3558,  1.1483,  1.3499,
          1.2448,  1.4116,  1.2337,  1.3600,  0.3426,  0.2664,  0.3811,  0.3501,
          0.1425,  0.0965,  0.3662,  0.1456, -0.0652,  3.2804,  2.2665,  3.2608,
          2.5788,  1.8273,  1.4271,  2.8086,  3.0761,  1.3916]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 259 : 175.1326157511727
Test loss for epoch 259 : 175.18972539887955
Test Precision for epoch 259 : 0.26153846153846155
Test Recall for epoch 259 : 0.26153846153846155
Test F1 for epoch 259 : 0.26153846153846155


theta for epoch 260 : tensor([[ 2.5583,  2.5772,  2.6140,  2.7180,  2.6993,  2.5616,  2.6863,  2.5567,
          2.5567,  1.3418,  1.3441,  1.3432,  1.3463,  1.3410,  1.3483,  1.3423,
          1.3394,  1.3016,  1.2951,  1.2530,  1.2537,  1.2961,  1.2926,  1.2921,
          1.2944,  1.2913,  1.2913,  1.2757,  1.3200,  1.3139,  1.3169,  1.3201,
          1.3154,  1.3181,  1.2702,  1.3142,  1.7398,  1.7507,  1.7443,  1.7403,
          1.7486,  1.6884,  1.7412,  1.7266,  1.7394,  1.6033,  1.5864,  1.5826,
          1.5765,  1.5997,  1.5815,  1.6144,  1.5733,  1.5748],
        [ 1.3001,  1.3028,  1.2653,  1.2696,  1.3043,  1.3014,  1.3017,  1.3005,
          1.3005,  2.5478,  2.5465,  2.4537,  2.6518,  2.4501,  2.9118,  2.5400,
          2.6121,  2.8842,  1.2905,  1.2962,  1.2495,  1.2874,  1.3185,  1.3179,
          1.3154,  1.3171,  1.3171,  1.3190,  1.2647,  1.3395,  1.3428,  1.2822,
          1.3411,  1.3440,  1.3138,  1.3399,  1.7559,  1.7679,  1.7241,  1.7544,
          1.7655,  1.7668,  1.7208,  1.6777,  1.7546,  1.5668,  1.6049,  1.6008,
          1.5942,  1.5264,  1.5996,  1.5428,  1.5907,  1.5923],
        [ 1.2801,  1.2828,  1.2857,  1.2846,  1.2827,  1.2806,  1.2809,  1.2798,
          1.2798,  1.3471,  1.3494,  1.3485,  1.3516,  1.3463,  1.2980,  1.3476,
          1.2895,  1.3349,  2.6133,  2.6926,  2.7449,  2.6225,  2.5546,  2.5517,
          2.6700,  2.5464,  2.5464,  1.2852,  1.3094,  1.3192,  1.3222,  1.2859,
          1.3206,  1.3234,  1.3191,  1.3195,  1.7429,  1.7541,  1.7475,  1.6892,
          1.7519,  1.7515,  1.7444,  1.7285,  1.6883,  1.6073,  1.5902,  1.5863,
          1.5802,  1.5839,  1.5852,  1.5996,  1.5762,  1.5784],
        [ 1.2897,  1.2925,  1.2954,  1.2943,  1.2924,  1.2902,  1.2907,  1.2894,
          1.2894,  1.3564,  1.3588,  1.3579,  1.3414,  1.3556,  1.2748,  1.3569,
          1.3532,  1.2730,  1.3100,  1.2909,  1.3113,  1.3110,  1.3074,  1.3069,
          1.3080,  1.3061,  1.3061,  2.7841,  2.7231,  2.4878,  2.5763,  2.7824,
          2.4965,  2.7035,  2.5398,  2.4896,  1.7492,  1.7607,  1.7269,  1.7481,
          1.7585,  1.7581,  1.7238,  1.6995,  1.7471,  1.6149,  1.5972,  1.5096,
          1.5327,  1.6111,  1.5920,  1.6265,  1.5286,  1.5850],
        [ 1.8768,  1.4774,  0.6312,  0.9588,  1.3712,  1.8068,  1.6799,  1.9124,
          1.9124,  1.7352,  1.3601,  1.5588,  0.9593,  1.7681,  0.1583,  1.6700,
          1.9326,  0.8895,  1.3787,  1.0290,  0.7855,  1.1886,  1.7481,  1.8145,
          1.5714,  1.9207,  1.9207,  0.8820,  0.8861,  1.8934,  1.6922,  0.8997,
          1.8341,  1.2973,  1.9422,  1.8577, -0.0965, -0.3440, -0.3867, -0.1382,
          0.1150,  0.2113, -0.2249, 15.1122,  4.8824,  0.2441,  0.6092,  0.6396,
          0.7461,  0.3972,  0.7459, -0.0476,  0.7778,  0.8421],
        [ 1.3353,  1.3726,  1.4159,  1.4046,  1.3796,  1.3424,  1.3128,  1.3315,
          1.3315,  1.3046,  1.4261,  1.3248,  1.4556,  1.3834,  1.4812,  1.3119,
          1.3597,  1.3693,  1.3926,  1.3749,  1.4258,  1.4063,  1.3593,  1.3523,
          1.2569,  1.3408,  1.3408,  1.3931,  1.4376,  1.3557,  1.1481,  1.3497,
          1.2447,  1.4115,  1.2335,  1.3598,  0.3425,  0.2663,  0.3809,  0.3500,
          0.1423,  0.0963,  0.3660,  0.1453, -0.0654,  3.2843,  2.2675,  3.2644,
          2.5803,  1.8279,  1.4276,  2.8101,  3.0803,  1.3921]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 260 : 175.12239895645624
Test loss for epoch 260 : 175.18236770345544
Test Precision for epoch 260 : 0.26153846153846155
Test Recall for epoch 260 : 0.26153846153846155
Test F1 for epoch 260 : 0.26153846153846155


theta for epoch 261 : tensor([[ 2.5595,  2.5784,  2.6152,  2.7193,  2.7006,  2.5627,  2.6877,  2.5578,
          2.5578,  1.3417,  1.3440,  1.3432,  1.3462,  1.3410,  1.3482,  1.3423,
          1.3393,  1.3015,  1.2950,  1.2529,  1.2537,  1.2960,  1.2926,  1.2921,
          1.2943,  1.2912,  1.2912,  1.2756,  1.3200,  1.3139,  1.3168,  1.3200,
          1.3153,  1.3180,  1.2701,  1.3141,  1.7398,  1.7508,  1.7443,  1.7404,
          1.7487,  1.6884,  1.7413,  1.7266,  1.7394,  1.6035,  1.5866,  1.5828,
          1.5768,  1.5999,  1.5817,  1.6146,  1.5735,  1.5750],
        [ 1.2998,  1.3025,  1.2655,  1.2696,  1.3040,  1.3011,  1.3014,  1.3002,
          1.3002,  2.5486,  2.5478,  2.4554,  2.6539,  2.4515,  2.9124,  2.5411,
          2.6143,  2.8849,  1.2904,  1.2960,  1.2493,  1.2874,  1.3183,  1.3177,
          1.3153,  1.3168,  1.3168,  1.3189,  1.2648,  1.3394,  1.3426,  1.2823,
          1.3409,  1.3438,  1.3136,  1.3397,  1.7559,  1.7678,  1.7241,  1.7544,
          1.7655,  1.7668,  1.7208,  1.6785,  1.7545,  1.5670,  1.6051,  1.6010,
          1.5944,  1.5266,  1.5998,  1.5430,  1.5908,  1.5925],
        [ 1.2799,  1.2826,  1.2855,  1.2844,  1.2825,  1.2804,  1.2807,  1.2796,
          1.2796,  1.3470,  1.3493,  1.3485,  1.3515,  1.3462,  1.2978,  1.3475,
          1.2892,  1.3349,  2.6144,  2.6943,  2.7466,  2.6235,  2.5556,  2.5527,
          2.6716,  2.5474,  2.5474,  1.2849,  1.3093,  1.3191,  1.3221,  1.2856,
          1.3205,  1.3233,  1.3190,  1.3194,  1.7430,  1.7541,  1.7475,  1.6890,
          1.7520,  1.7515,  1.7445,  1.7285,  1.6881,  1.6075,  1.5904,  1.5866,
          1.5804,  1.5841,  1.5855,  1.5997,  1.5764,  1.5786],
        [ 1.2894,  1.2923,  1.2951,  1.2941,  1.2922,  1.2900,  1.2904,  1.2892,
          1.2892,  1.3563,  1.3586,  1.3578,  1.3413,  1.3555,  1.2751,  1.3568,
          1.3530,  1.2733,  1.3098,  1.2907,  1.3111,  1.3108,  1.3073,  1.3067,
          1.3078,  1.3059,  1.3059,  2.7852,  2.7241,  2.4895,  2.5771,  2.7836,
          2.4981,  2.7045,  2.5416,  2.4912,  1.7492,  1.7607,  1.7269,  1.7481,
          1.7585,  1.7581,  1.7238,  1.7000,  1.7471,  1.6150,  1.5973,  1.5102,
          1.5328,  1.6113,  1.5921,  1.6266,  1.5287,  1.5852],
        [ 1.8772,  1.4778,  0.6316,  0.9592,  1.3717,  1.8072,  1.6804,  1.9128,
          1.9128,  1.7354,  1.3605,  1.5593,  0.9599,  1.7685,  0.1587,  1.6703,
          1.9333,  0.8897,  1.3792,  1.0297,  0.7862,  1.1890,  1.7486,  1.8150,
          1.5720,  1.9212,  1.9212,  0.8826,  0.8864,  1.8940,  1.6925,  0.9001,
          1.8346,  1.2977,  1.9428,  1.8583, -0.0975, -0.3449, -0.3877, -0.1392,
          0.1138,  0.2100, -0.2259, 15.1549,  4.8591,  0.2448,  0.6098,  0.6401,
          0.7467,  0.3978,  0.7466, -0.0469,  0.7784,  0.8427],
        [ 1.3348,  1.3722,  1.4155,  1.4042,  1.3792,  1.3420,  1.3124,  1.3311,
          1.3311,  1.3043,  1.4257,  1.3244,  1.4552,  1.3831,  1.4808,  1.3115,
          1.3593,  1.3689,  1.3921,  1.3742,  1.4253,  1.4058,  1.3588,  1.3519,
          1.2563,  1.3404,  1.3404,  1.3927,  1.4373,  1.3553,  1.1476,  1.3493,
          1.2443,  1.4111,  1.2332,  1.3595,  0.3421,  0.2659,  0.3805,  0.3496,
          0.1419,  0.0959,  0.3657,  0.1448, -0.0659,  3.2884,  2.2688,  3.2683,
          2.5821,  1.8287,  1.4282,  2.8118,  3.0848,  1.3927]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 261 : 175.1125792269453
Test loss for epoch 261 : 175.17510566316156
Test Precision for epoch 261 : 0.26153846153846155
Test Recall for epoch 261 : 0.26153846153846155
Test F1 for epoch 261 : 0.26153846153846155


theta for epoch 262 : tensor([[ 2.5611,  2.5800,  2.6168,  2.7211,  2.7024,  2.5643,  2.6895,  2.5594,
          2.5594,  1.3417,  1.3439,  1.3431,  1.3461,  1.3409,  1.3481,  1.3422,
          1.3392,  1.3014,  1.2950,  1.2529,  1.2536,  1.2960,  1.2925,  1.2920,
          1.2943,  1.2912,  1.2912,  1.2755,  1.3198,  1.3137,  1.3167,  1.3199,
          1.3152,  1.3179,  1.2700,  1.3140,  1.7399,  1.7509,  1.7444,  1.7404,
          1.7488,  1.6885,  1.7414,  1.7267,  1.7395,  1.6026,  1.5857,  1.5819,
          1.5759,  1.5990,  1.5808,  1.6137,  1.5726,  1.5741],
        [ 1.2998,  1.3025,  1.2660,  1.2699,  1.3039,  1.3010,  1.3014,  1.3002,
          1.3002,  2.5495,  2.5494,  2.4573,  2.6562,  2.4531,  2.9132,  2.5425,
          2.6167,  2.8858,  1.2904,  1.2960,  1.2493,  1.2875,  1.3182,  1.3177,
          1.3154,  1.3168,  1.3168,  1.3187,  1.2649,  1.3392,  1.3425,  1.2826,
          1.3408,  1.3437,  1.3135,  1.3396,  1.7559,  1.7679,  1.7241,  1.7545,
          1.7655,  1.7668,  1.7208,  1.6794,  1.7546,  1.5660,  1.6041,  1.6000,
          1.5934,  1.5257,  1.5988,  1.5421,  1.5899,  1.5915],
        [ 1.2799,  1.2827,  1.2855,  1.2844,  1.2825,  1.2804,  1.2808,  1.2796,
          1.2796,  1.3469,  1.3493,  1.3484,  1.3514,  1.3461,  1.2975,  1.3474,
          1.2890,  1.3348,  2.6159,  2.6964,  2.7488,  2.6250,  2.5570,  2.5541,
          2.6737,  2.5488,  2.5488,  1.2847,  1.3092,  1.3190,  1.3220,  1.2853,
          1.3204,  1.3232,  1.3189,  1.3193,  1.7431,  1.7543,  1.7477,  1.6889,
          1.7521,  1.7516,  1.7446,  1.7287,  1.6880,  1.6066,  1.5895,  1.5857,
          1.5795,  1.5833,  1.5846,  1.5988,  1.5755,  1.5778],
        [ 1.2894,  1.2922,  1.2951,  1.2940,  1.2921,  1.2899,  1.2903,  1.2891,
          1.2891,  1.3561,  1.3585,  1.3576,  1.3411,  1.3553,  1.2754,  1.3567,
          1.3529,  1.2736,  1.3097,  1.2905,  1.3110,  1.3108,  1.3072,  1.3066,
          1.3077,  1.3058,  1.3058,  2.7866,  2.7253,  2.4915,  2.5782,  2.7850,
          2.5001,  2.7057,  2.5437,  2.4932,  1.7493,  1.7608,  1.7270,  1.7481,
          1.7585,  1.7581,  1.7238,  1.7006,  1.7472,  1.6141,  1.5964,  1.5099,
          1.5319,  1.6104,  1.5913,  1.6257,  1.5278,  1.5843],
        [ 1.8772,  1.4777,  0.6312,  0.9589,  1.3716,  1.8072,  1.6803,  1.9128,
          1.9128,  1.7348,  1.3601,  1.5591,  0.9596,  1.7681,  0.1582,  1.6698,
          1.9333,  0.8889,  1.3790,  1.0297,  0.7860,  1.1887,  1.7485,  1.8149,
          1.5720,  1.9211,  1.9211,  0.8822,  0.8859,  1.8938,  1.6921,  0.8995,
          1.8345,  1.2972,  1.9426,  1.8581, -0.0977, -0.3450, -0.3878, -0.1395,
          0.1135,  0.2096, -0.2260, 15.1985,  4.8365,  0.2443,  0.6092,  0.6393,
          0.7461,  0.3972,  0.7460, -0.0473,  0.7779,  0.8421],
        [ 1.3357,  1.3730,  1.4162,  1.4050,  1.3800,  1.3428,  1.3132,  1.3320,
          1.3320,  1.3052,  1.4266,  1.3252,  1.4560,  1.3839,  1.4817,  1.3124,
          1.3601,  1.3698,  1.3930,  1.3750,  1.4262,  1.4067,  1.3597,  1.3527,
          1.2570,  1.3413,  1.3413,  1.3935,  1.4380,  1.3561,  1.1484,  1.3501,
          1.2451,  1.4119,  1.2340,  1.3603,  0.3429,  0.2668,  0.3813,  0.3505,
          0.1428,  0.0968,  0.3665,  0.1455, -0.0652,  3.2911,  2.2686,  3.2707,
          2.5825,  1.8280,  1.4275,  2.8122,  3.0879,  1.3920]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 262 : 175.1028114637003
Test loss for epoch 262 : 175.16979895471437
Test Precision for epoch 262 : 0.26153846153846155
Test Recall for epoch 262 : 0.26153846153846155
Test F1 for epoch 262 : 0.26153846153846155


theta for epoch 263 : tensor([[ 2.5627,  2.5816,  2.6184,  2.7229,  2.7042,  2.5659,  2.6913,  2.5611,
          2.5611,  1.3415,  1.3438,  1.3429,  1.3459,  1.3407,  1.3480,  1.3420,
          1.3391,  1.3012,  1.2946,  1.2525,  1.2533,  1.2956,  1.2922,  1.2917,
          1.2939,  1.2908,  1.2908,  1.2753,  1.3197,  1.3136,  1.3165,  1.3197,
          1.3150,  1.3177,  1.2698,  1.3139,  1.7397,  1.7506,  1.7442,  1.7402,
          1.7485,  1.6883,  1.7411,  1.7264,  1.7393,  1.6027,  1.5858,  1.5820,
          1.5760,  1.5991,  1.5810,  1.6137,  1.5727,  1.5743],
        [ 1.2996,  1.3024,  1.2664,  1.2702,  1.3038,  1.3009,  1.3013,  1.3000,
          1.3000,  2.5507,  2.5510,  2.4594,  2.6587,  2.4548,  2.9142,  2.5439,
          2.6192,  2.8868,  1.2900,  1.2955,  1.2488,  1.2872,  1.3178,  1.3173,
          1.3151,  1.3164,  1.3164,  1.3185,  1.2649,  1.3390,  1.3422,  1.2827,
          1.3405,  1.3435,  1.3132,  1.3393,  1.7556,  1.7676,  1.7238,  1.7542,
          1.7653,  1.7665,  1.7205,  1.6799,  1.7543,  1.5661,  1.6042,  1.6001,
          1.5935,  1.5258,  1.5989,  1.5421,  1.5899,  1.5916],
        [ 1.2798,  1.2826,  1.2854,  1.2843,  1.2824,  1.2804,  1.2807,  1.2796,
          1.2796,  1.3468,  1.3491,  1.3482,  1.3513,  1.3460,  1.2972,  1.3473,
          1.2887,  1.3347,  2.6172,  2.6984,  2.7508,  2.6264,  2.5584,  2.5555,
          2.6756,  2.5502,  2.5502,  1.2843,  1.3091,  1.3189,  1.3219,  1.2850,
          1.3203,  1.3231,  1.3188,  1.3192,  1.7429,  1.7540,  1.7474,  1.6884,
          1.7519,  1.7514,  1.7444,  1.7285,  1.6875,  1.6067,  1.5897,  1.5858,
          1.5797,  1.5834,  1.5847,  1.5989,  1.5757,  1.5779],
        [ 1.2892,  1.2921,  1.2949,  1.2939,  1.2920,  1.2898,  1.2902,  1.2890,
          1.2890,  1.3559,  1.3583,  1.3574,  1.3409,  1.3551,  1.2755,  1.3565,
          1.3527,  1.2738,  1.3093,  1.2901,  1.3106,  1.3104,  1.3068,  1.3062,
          1.3073,  1.3054,  1.3054,  2.7881,  2.7266,  2.4935,  2.5794,  2.7864,
          2.5021,  2.7070,  2.5458,  2.4952,  1.7490,  1.7605,  1.7267,  1.7478,
          1.7583,  1.7578,  1.7235,  1.7009,  1.7468,  1.6142,  1.5964,  1.5104,
          1.5320,  1.6104,  1.5913,  1.6257,  1.5279,  1.5844],
        [ 1.8783,  1.4790,  0.6325,  0.9601,  1.3729,  1.8084,  1.6815,  1.9139,
          1.9139,  1.7357,  1.3612,  1.5603,  0.9610,  1.7693,  0.1595,  1.6708,
          1.9345,  0.8900,  1.3802,  1.0312,  0.7874,  1.1899,  1.7496,  1.8160,
          1.5732,  1.9222,  1.9222,  0.8836,  0.8870,  1.8950,  1.6932,  0.9008,
          1.8357,  1.2984,  1.9438,  1.8593, -0.0994, -0.3466, -0.3894, -0.1413,
          0.1116,  0.2077, -0.2277, 15.2405,  4.8120,  0.2457,  0.6106,  0.6406,
          0.7475,  0.3987,  0.7474, -0.0458,  0.7793,  0.8435],
        [ 1.3349,  1.3722,  1.4154,  1.4042,  1.3792,  1.3421,  1.3125,  1.3312,
          1.3312,  1.3043,  1.4256,  1.3242,  1.4551,  1.3830,  1.4807,  1.3114,
          1.3591,  1.3689,  1.3920,  1.3737,  1.4251,  1.4057,  1.3587,  1.3517,
          1.2558,  1.3402,  1.3402,  1.3926,  1.4372,  1.3553,  1.1474,  1.3492,
          1.2442,  1.4111,  1.2331,  1.3594,  0.3419,  0.2657,  0.3802,  0.3494,
          0.1417,  0.0957,  0.3655,  0.1443, -0.0663,  3.2958,  2.2705,  3.2751,
          2.5849,  1.8294,  1.4287,  2.8145,  3.0930,  1.3932]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 263 : 175.09289720203213
Test loss for epoch 263 : 175.16115865054786
Test Precision for epoch 263 : 0.26153846153846155
Test Recall for epoch 263 : 0.26153846153846155
Test F1 for epoch 263 : 0.26153846153846155


theta for epoch 264 : tensor([[ 2.5640,  2.5829,  2.6198,  2.7244,  2.7058,  2.5673,  2.6928,  2.5624,
          2.5624,  1.3414,  1.3437,  1.3428,  1.3458,  1.3406,  1.3479,  1.3419,
          1.3389,  1.3011,  1.2946,  1.2526,  1.2533,  1.2956,  1.2922,  1.2917,
          1.2940,  1.2909,  1.2909,  1.2752,  1.3195,  1.3134,  1.3164,  1.3196,
          1.3148,  1.3175,  1.2696,  1.3137,  1.7398,  1.7507,  1.7443,  1.7403,
          1.7486,  1.6884,  1.7412,  1.7265,  1.7394,  1.6025,  1.5856,  1.5819,
          1.5758,  1.5989,  1.5808,  1.6135,  1.5725,  1.5741],
        [ 1.2994,  1.3021,  1.2666,  1.2702,  1.3035,  1.3006,  1.3010,  1.2997,
          1.2997,  2.5515,  2.5524,  2.4612,  2.6609,  2.4563,  2.9150,  2.5451,
          2.6215,  2.8876,  1.2900,  1.2955,  1.2488,  1.2874,  1.3178,  1.3172,
          1.3152,  1.3163,  1.3163,  1.3183,  1.2649,  1.3388,  1.3420,  1.2829,
          1.3403,  1.3433,  1.3130,  1.3391,  1.7556,  1.7676,  1.7238,  1.7543,
          1.7653,  1.7666,  1.7205,  1.6807,  1.7543,  1.5659,  1.6039,  1.5998,
          1.5933,  1.5256,  1.5987,  1.5419,  1.5897,  1.5914],
        [ 1.2796,  1.2823,  1.2852,  1.2841,  1.2822,  1.2801,  1.2805,  1.2793,
          1.2793,  1.3466,  1.3490,  1.3481,  1.3512,  1.3458,  1.2970,  1.3472,
          1.2884,  1.3346,  2.6186,  2.7004,  2.7528,  2.6278,  2.5598,  2.5568,
          2.6776,  2.5516,  2.5516,  1.2840,  1.3090,  1.3187,  1.3217,  1.2847,
          1.3201,  1.3229,  1.3186,  1.3190,  1.7430,  1.7541,  1.7475,  1.6883,
          1.7520,  1.7515,  1.7445,  1.7286,  1.6874,  1.6065,  1.5895,  1.5857,
          1.5795,  1.5832,  1.5845,  1.5987,  1.5754,  1.5777],
        [ 1.2889,  1.2918,  1.2946,  1.2936,  1.2917,  1.2895,  1.2899,  1.2887,
          1.2887,  1.3558,  1.3581,  1.3572,  1.3407,  1.3549,  1.2758,  1.3563,
          1.3525,  1.2741,  1.3093,  1.2901,  1.3105,  1.3103,  1.3067,  1.3062,
          1.3073,  1.3053,  1.3053,  2.7893,  2.7277,  2.4953,  2.5803,  2.7876,
          2.5040,  2.7081,  2.5477,  2.4971,  1.7490,  1.7605,  1.7268,  1.7478,
          1.7583,  1.7578,  1.7236,  1.7016,  1.7469,  1.6139,  1.5962,  1.5107,
          1.5318,  1.6102,  1.5911,  1.6255,  1.5276,  1.5841],
        [ 1.8779,  1.4784,  0.6317,  0.9593,  1.3723,  1.8079,  1.6810,  1.9135,
          1.9135,  1.7348,  1.3604,  1.5597,  0.9604,  1.7686,  0.1586,  1.6699,
          1.9342,  0.8888,  1.3796,  1.0307,  0.7869,  1.1892,  1.7491,  1.8156,
          1.5729,  1.9217,  1.9217,  0.8829,  0.8861,  1.8945,  1.6924,  0.8998,
          1.8352,  1.2975,  1.9433,  1.8588, -0.0993, -0.3464, -0.3893, -0.1412,
          0.1116,  0.2076, -0.2275, 15.2844,  4.7896,  0.2450,  0.6099,  0.6397,
          0.7467,  0.3979,  0.7466, -0.0465,  0.7785,  0.8428],
        [ 1.3358,  1.3732,  1.4163,  1.4051,  1.3801,  1.3430,  1.3134,  1.3321,
          1.3321,  1.3055,  1.4268,  1.3254,  1.4562,  1.3841,  1.4818,  1.3126,
          1.3603,  1.3700,  1.3932,  1.3748,  1.4263,  1.4068,  1.3599,  1.3529,
          1.2569,  1.3414,  1.3414,  1.3936,  1.4382,  1.3563,  1.1484,  1.3502,
          1.2453,  1.4121,  1.2342,  1.3604,  0.3431,  0.2669,  0.3814,  0.3506,
          0.1428,  0.0968,  0.3666,  0.1454, -0.0652,  3.2982,  2.2700,  3.2773,
          2.5849,  1.8285,  1.4277,  2.8145,  3.0958,  1.3922]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 264 : 175.08267639322486
Test loss for epoch 264 : 175.15598631637116
Test Precision for epoch 264 : 0.26153846153846155
Test Recall for epoch 264 : 0.26153846153846155
Test F1 for epoch 264 : 0.26153846153846155


theta for epoch 265 : tensor([[ 2.5653,  2.5842,  2.6210,  2.7259,  2.7072,  2.5685,  2.6942,  2.5636,
          2.5636,  1.3413,  1.3435,  1.3427,  1.3457,  1.3405,  1.3477,  1.3418,
          1.3388,  1.3010,  1.2944,  1.2524,  1.2531,  1.2955,  1.2920,  1.2915,
          1.2938,  1.2907,  1.2907,  1.2751,  1.3194,  1.3133,  1.3163,  1.3195,
          1.3147,  1.3174,  1.2695,  1.3136,  1.7396,  1.7506,  1.7441,  1.7401,
          1.7485,  1.6882,  1.7411,  1.7264,  1.7392,  1.6030,  1.5862,  1.5825,
          1.5764,  1.5995,  1.5814,  1.6141,  1.5731,  1.5747],
        [ 1.2990,  1.3018,  1.2668,  1.2703,  1.3031,  1.3002,  1.3007,  1.2994,
          1.2994,  2.5524,  2.5538,  2.4630,  2.6631,  2.4578,  2.9158,  2.5463,
          2.6238,  2.8884,  1.2897,  1.2952,  1.2485,  1.2872,  1.3175,  1.3169,
          1.3151,  1.3160,  1.3160,  1.3181,  1.2649,  1.3386,  1.3418,  1.2831,
          1.3401,  1.3431,  1.3128,  1.3389,  1.7554,  1.7674,  1.7236,  1.7541,
          1.7651,  1.7663,  1.7203,  1.6813,  1.7540,  1.5664,  1.6045,  1.6004,
          1.5938,  1.5262,  1.5992,  1.5425,  1.5902,  1.5919],
        [ 1.2794,  1.2821,  1.2849,  1.2838,  1.2820,  1.2799,  1.2802,  1.2791,
          1.2791,  1.3466,  1.3489,  1.3480,  1.3511,  1.3458,  1.2968,  1.3471,
          1.2882,  1.3345,  2.6197,  2.7020,  2.7545,  2.6288,  2.5608,  2.5578,
          2.6792,  2.5526,  2.5526,  1.2838,  1.3089,  1.3186,  1.3216,  1.2845,
          1.3201,  1.3228,  1.3185,  1.3189,  1.7428,  1.7540,  1.7474,  1.6879,
          1.7519,  1.7513,  1.7443,  1.7285,  1.6870,  1.6071,  1.5901,  1.5863,
          1.5801,  1.5838,  1.5851,  1.5993,  1.5760,  1.5783],
        [ 1.2886,  1.2915,  1.2943,  1.2933,  1.2914,  1.2892,  1.2896,  1.2884,
          1.2884,  1.3556,  1.3579,  1.3571,  1.3406,  1.3548,  1.2761,  1.3561,
          1.3523,  1.2743,  1.3090,  1.2898,  1.3103,  1.3101,  1.3065,  1.3060,
          1.3070,  1.3051,  1.3051,  2.7904,  2.7287,  2.4971,  2.5812,  2.7887,
          2.5057,  2.7091,  2.5496,  2.4988,  1.7488,  1.7603,  1.7265,  1.7476,
          1.7581,  1.7576,  1.7234,  1.7020,  1.7467,  1.6144,  1.5967,  1.5118,
          1.5323,  1.6106,  1.5916,  1.6259,  1.5281,  1.5847],
        [ 1.8786,  1.4792,  0.6326,  0.9601,  1.3732,  1.8087,  1.6818,  1.9142,
          1.9142,  1.7354,  1.3613,  1.5606,  0.9614,  1.7694,  0.1596,  1.6706,
          1.9352,  0.8895,  1.3806,  1.0319,  0.7880,  1.1902,  1.7500,  1.8164,
          1.5739,  1.9226,  1.9226,  0.8839,  0.8869,  1.8954,  1.6932,  0.9007,
          1.8361,  1.2983,  1.9442,  1.8598, -0.1007, -0.3477, -0.3906, -0.1428,
          0.1100,  0.2059, -0.2289, 15.3267,  4.7651,  0.2462,  0.6111,  0.6407,
          0.7479,  0.3991,  0.7478, -0.0452,  0.7798,  0.8440],
        [ 1.3350,  1.3723,  1.4154,  1.4043,  1.3793,  1.3422,  1.3126,  1.3313,
          1.3313,  1.3046,  1.4259,  1.3245,  1.4553,  1.3833,  1.4809,  1.3118,
          1.3594,  1.3692,  1.3922,  1.3737,  1.4254,  1.4059,  1.3590,  1.3520,
          1.2558,  1.3405,  1.3405,  1.3927,  1.4375,  1.3555,  1.1475,  1.3494,
          1.2445,  1.4114,  1.2334,  1.3597,  0.3422,  0.2660,  0.3804,  0.3497,
          0.1419,  0.0959,  0.3657,  0.1443, -0.0662,  3.3028,  2.2718,  3.2816,
          2.5872,  1.8298,  1.4289,  2.8167,  3.1008,  1.3934]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 265 : 175.07231740609026
Test loss for epoch 265 : 175.14730861373442
Test Precision for epoch 265 : 0.26153846153846155
Test Recall for epoch 265 : 0.26153846153846155
Test F1 for epoch 265 : 0.26153846153846155


theta for epoch 266 : tensor([[ 2.5669,  2.5858,  2.6226,  2.7277,  2.7090,  2.5701,  2.6960,  2.5652,
          2.5652,  1.3412,  1.3434,  1.3426,  1.3456,  1.3404,  1.3476,  1.3417,
          1.3387,  1.3009,  1.2944,  1.2524,  1.2531,  1.2955,  1.2920,  1.2915,
          1.2938,  1.2907,  1.2907,  1.2750,  1.3193,  1.3132,  1.3162,  1.3194,
          1.3146,  1.3174,  1.2694,  1.3135,  1.7396,  1.7506,  1.7441,  1.7402,
          1.7485,  1.6882,  1.7411,  1.7264,  1.7393,  1.6023,  1.5855,  1.5817,
          1.5757,  1.5987,  1.5806,  1.6133,  1.5724,  1.5740],
        [ 1.2990,  1.3017,  1.2673,  1.2705,  1.3031,  1.3002,  1.3006,  1.2993,
          1.2993,  2.5534,  2.5552,  2.4649,  2.6653,  2.4594,  2.9166,  2.5476,
          2.6262,  2.8893,  1.2897,  1.2952,  1.2485,  1.2874,  1.3175,  1.3169,
          1.3152,  1.3161,  1.3161,  1.3180,  1.2650,  1.3385,  1.3418,  1.2834,
          1.3400,  1.3430,  1.3127,  1.3388,  1.7554,  1.7674,  1.7236,  1.7541,
          1.7650,  1.7663,  1.7203,  1.6821,  1.7540,  1.5656,  1.6037,  1.5996,
          1.5930,  1.5255,  1.5984,  1.5417,  1.5894,  1.5911],
        [ 1.2794,  1.2821,  1.2849,  1.2838,  1.2820,  1.2799,  1.2802,  1.2791,
          1.2791,  1.3466,  1.3489,  1.3480,  1.3511,  1.3457,  1.2966,  1.3471,
          1.2880,  1.3345,  2.6210,  2.7040,  2.7565,  2.6302,  2.5621,  2.5591,
          2.6811,  2.5539,  2.5539,  1.2836,  1.3089,  1.3186,  1.3217,  1.2843,
          1.3201,  1.3228,  1.3185,  1.3189,  1.7429,  1.7541,  1.7475,  1.6877,
          1.7519,  1.7514,  1.7444,  1.7285,  1.6868,  1.6064,  1.5894,  1.5856,
          1.5794,  1.5831,  1.5845,  1.5986,  1.5753,  1.5777],
        [ 1.2886,  1.2914,  1.2942,  1.2932,  1.2913,  1.2891,  1.2895,  1.2883,
          1.2883,  1.3555,  1.3579,  1.3570,  1.3405,  1.3547,  1.2764,  1.3560,
          1.3522,  1.2747,  1.3090,  1.2898,  1.3103,  1.3101,  1.3065,  1.3060,
          1.3070,  1.3051,  1.3051,  2.7917,  2.7299,  2.4990,  2.5822,  2.7900,
          2.5076,  2.7102,  2.5516,  2.5008,  1.7488,  1.7603,  1.7266,  1.7476,
          1.7581,  1.7576,  1.7234,  1.7026,  1.7466,  1.6137,  1.5960,  1.5116,
          1.5316,  1.6099,  1.5909,  1.6252,  1.5274,  1.5840],
        [ 1.8787,  1.4792,  0.6324,  0.9599,  1.3732,  1.8087,  1.6818,  1.9143,
          1.9143,  1.7350,  1.3610,  1.5605,  0.9613,  1.7692,  0.1592,  1.6703,
          1.9353,  0.8889,  1.3805,  1.0320,  0.7880,  1.1900,  1.7500,  1.8164,
          1.5740,  1.9226,  1.9226,  0.8838,  0.8865,  1.8954,  1.6930,  0.9003,
          1.8361,  1.2980,  1.9442,  1.8597, -0.1011, -0.3480, -0.3909, -0.1432,
          0.1096,  0.2054, -0.2292, 15.3701,  4.7419,  0.2459,  0.6107,  0.6402,
          0.7476,  0.3988,  0.7475, -0.0454,  0.7794,  0.8437],
        [ 1.3356,  1.3729,  1.4159,  1.4049,  1.3799,  1.3428,  1.3132,  1.3319,
          1.3319,  1.3053,  1.4266,  1.3251,  1.4559,  1.3839,  1.4815,  1.3124,
          1.3600,  1.3698,  1.3929,  1.3742,  1.4260,  1.4066,  1.3596,  1.3527,
          1.2563,  1.3412,  1.3412,  1.3933,  1.4381,  1.3562,  1.1481,  1.3499,
          1.2451,  1.4120,  1.2340,  1.3603,  0.3428,  0.2666,  0.3810,  0.3503,
          0.1425,  0.0964,  0.3663,  0.1448, -0.0657,  3.3057,  2.2718,  3.2842,
          2.5878,  1.8294,  1.4283,  2.8173,  3.1041,  1.3928]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 266 : 175.0619410386851
Test loss for epoch 266 : 175.14106805779562
Test Precision for epoch 266 : 0.26153846153846155
Test Recall for epoch 266 : 0.26153846153846155
Test F1 for epoch 266 : 0.26153846153846155


theta for epoch 267 : tensor([[ 2.5684,  2.5873,  2.6242,  2.7294,  2.7107,  2.5717,  2.6977,  2.5668,
          2.5668,  1.3410,  1.3433,  1.3425,  1.3455,  1.3403,  1.3475,  1.3416,
          1.3386,  1.3008,  1.2943,  1.2522,  1.2529,  1.2953,  1.2918,  1.2913,
          1.2936,  1.2905,  1.2905,  1.2749,  1.3192,  1.3131,  1.3161,  1.3193,
          1.3146,  1.3173,  1.2693,  1.3134,  1.7396,  1.7506,  1.7441,  1.7401,
          1.7485,  1.6882,  1.7411,  1.7263,  1.7392,  1.6019,  1.5851,  1.5814,
          1.5754,  1.5984,  1.5803,  1.6130,  1.5720,  1.5736],
        [ 1.2989,  1.3017,  1.2677,  1.2708,  1.3030,  1.3000,  1.3005,  1.2992,
          1.2992,  2.5543,  2.5566,  2.4669,  2.6676,  2.4611,  2.9175,  2.5489,
          2.6286,  2.8902,  1.2895,  1.2950,  1.2483,  1.2873,  1.3173,  1.3167,
          1.3151,  1.3158,  1.3158,  1.3179,  1.2651,  1.3384,  1.3416,  1.2836,
          1.3399,  1.3428,  1.3126,  1.3387,  1.7553,  1.7673,  1.7235,  1.7540,
          1.7649,  1.7662,  1.7202,  1.6828,  1.7539,  1.5652,  1.6032,  1.5992,
          1.5926,  1.5251,  1.5980,  1.5413,  1.5890,  1.5907],
        [ 1.2794,  1.2821,  1.2849,  1.2838,  1.2820,  1.2799,  1.2802,  1.2791,
          1.2791,  1.3465,  1.3488,  1.3479,  1.3510,  1.3457,  1.2964,  1.3470,
          1.2878,  1.3344,  2.6223,  2.7059,  2.7584,  2.6315,  2.5634,  2.5604,
          2.6829,  2.5552,  2.5552,  1.2834,  1.3089,  1.3186,  1.3216,  1.2841,
          1.3200,  1.3228,  1.3185,  1.3189,  1.7429,  1.7541,  1.7475,  1.6875,
          1.7519,  1.7513,  1.7444,  1.7285,  1.6866,  1.6061,  1.5891,  1.5853,
          1.5791,  1.5828,  1.5842,  1.5982,  1.5750,  1.5774],
        [ 1.2885,  1.2913,  1.2941,  1.2931,  1.2912,  1.2890,  1.2895,  1.2882,
          1.2882,  1.3554,  1.3577,  1.3568,  1.3403,  1.3545,  1.2767,  1.3559,
          1.3521,  1.2750,  1.3089,  1.2896,  1.3101,  1.3099,  1.3063,  1.3058,
          1.3068,  1.3049,  1.3049,  2.7929,  2.7310,  2.5009,  2.5832,  2.7913,
          2.5096,  2.7113,  2.5536,  2.5027,  1.7488,  1.7603,  1.7265,  1.7475,
          1.7581,  1.7575,  1.7233,  1.7031,  1.7465,  1.6133,  1.5957,  1.5118,
          1.5313,  1.6096,  1.5906,  1.6248,  1.5270,  1.5836],
        [ 1.8792,  1.4798,  0.6329,  0.9604,  1.3738,  1.8093,  1.6823,  1.9149,
          1.9149,  1.7351,  1.3613,  1.5610,  0.9619,  1.7697,  0.1596,  1.6705,
          1.9359,  0.8891,  1.3810,  1.0328,  0.7887,  1.1905,  1.7505,  1.8169,
          1.5747,  1.9231,  1.9231,  0.8843,  0.8869,  1.8960,  1.6933,  0.9007,
          1.8367,  1.2984,  1.9448,  1.8603, -0.1020, -0.3488, -0.3918, -0.1442,
          0.1085,  0.2042, -0.2301, 15.4129,  4.7177,  0.2465,  0.6112,  0.6406,
          0.7480,  0.3993,  0.7480, -0.0448,  0.7800,  0.8442],
        [ 1.3355,  1.3728,  1.4158,  1.4048,  1.3798,  1.3427,  1.3131,  1.3318,
          1.3318,  1.3052,  1.4264,  1.3249,  1.4557,  1.3838,  1.4813,  1.3123,
          1.3598,  1.3696,  1.3927,  1.3738,  1.4258,  1.4064,  1.3594,  1.3525,
          1.2559,  1.3410,  1.3410,  1.3931,  1.4380,  1.3560,  1.1479,  1.3498,
          1.2450,  1.4119,  1.2339,  1.3602,  0.3425,  0.2664,  0.3808,  0.3501,
          0.1422,  0.0962,  0.3661,  0.1445, -0.0660,  3.3095,  2.2727,  3.2878,
          2.5892,  1.8299,  1.4287,  2.8187,  3.1083,  1.3932]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 267 : 175.05173484891586
Test loss for epoch 267 : 175.13363172396555
Test Precision for epoch 267 : 0.26153846153846155
Test Recall for epoch 267 : 0.26153846153846155
Test F1 for epoch 267 : 0.26153846153846155


theta for epoch 268 : tensor([[ 2.5697,  2.5886,  2.6254,  2.7308,  2.7121,  2.5729,  2.6992,  2.5680,
          2.5680,  1.3410,  1.3432,  1.3424,  1.3454,  1.3402,  1.3474,  1.3415,
          1.3385,  1.3007,  1.2941,  1.2521,  1.2528,  1.2951,  1.2917,  1.2912,
          1.2935,  1.2904,  1.2904,  1.2748,  1.3191,  1.3130,  1.3160,  1.3192,
          1.3144,  1.3172,  1.2692,  1.3133,  1.7396,  1.7506,  1.7441,  1.7402,
          1.7485,  1.6882,  1.7411,  1.7264,  1.7393,  1.6021,  1.5853,  1.5816,
          1.5756,  1.5986,  1.5805,  1.6132,  1.5723,  1.5739],
        [ 1.2986,  1.3014,  1.2679,  1.2709,  1.3027,  1.2998,  1.3003,  1.2989,
          1.2989,  2.5552,  2.5579,  2.4687,  2.6698,  2.4626,  2.9183,  2.5500,
          2.6309,  2.8910,  1.2893,  1.2947,  1.2481,  1.2872,  1.3170,  1.3165,
          1.3150,  1.3156,  1.3156,  1.3177,  1.2651,  1.3382,  1.3414,  1.2838,
          1.3397,  1.3426,  1.3124,  1.3385,  1.7552,  1.7672,  1.7234,  1.7540,
          1.7649,  1.7662,  1.7201,  1.6835,  1.7539,  1.5654,  1.6034,  1.5993,
          1.5927,  1.5253,  1.5981,  1.5415,  1.5892,  1.5909],
        [ 1.2791,  1.2819,  1.2846,  1.2836,  1.2817,  1.2797,  1.2800,  1.2789,
          1.2789,  1.3463,  1.3486,  1.3477,  1.3508,  1.3455,  1.2961,  1.3468,
          1.2875,  1.3343,  2.6236,  2.7077,  2.7602,  2.6327,  2.5646,  2.5616,
          2.6847,  2.5564,  2.5564,  1.2831,  1.3087,  1.3184,  1.3214,  1.2838,
          1.3198,  1.3226,  1.3183,  1.3187,  1.7429,  1.7541,  1.7475,  1.6873,
          1.7519,  1.7513,  1.7444,  1.7286,  1.6864,  1.6062,  1.5893,  1.5855,
          1.5793,  1.5830,  1.5844,  1.5984,  1.5752,  1.5776],
        [ 1.2882,  1.2910,  1.2938,  1.2929,  1.2910,  1.2888,  1.2892,  1.2880,
          1.2880,  1.3552,  1.3575,  1.3567,  1.3402,  1.3544,  1.2769,  1.3557,
          1.3519,  1.2752,  1.3086,  1.2894,  1.3099,  1.3097,  1.3061,  1.3056,
          1.3066,  1.3047,  1.3047,  2.7941,  2.7320,  2.5027,  2.5841,  2.7924,
          2.5114,  2.7123,  2.5555,  2.5045,  1.7487,  1.7602,  1.7265,  1.7474,
          1.7580,  1.7575,  1.7233,  1.7037,  1.7465,  1.6134,  1.5958,  1.5125,
          1.5314,  1.6097,  1.5907,  1.6249,  1.5271,  1.5838],
        [ 1.8795,  1.4801,  0.6332,  0.9606,  1.3742,  1.8097,  1.6827,  1.9152,
          1.9152,  1.7352,  1.3616,  1.5614,  0.9624,  1.7699,  0.1599,  1.6706,
          1.9364,  0.8891,  1.3814,  1.0333,  0.7892,  1.1908,  1.7509,  1.8173,
          1.5752,  1.9235,  1.9235,  0.8847,  0.8871,  1.8964,  1.6935,  0.9009,
          1.8370,  1.2986,  1.9452,  1.8607, -0.1029, -0.3496, -0.3926, -0.1451,
          0.1075,  0.2031, -0.2309, 15.4559,  4.6935,  0.2470,  0.6117,  0.6409,
          0.7485,  0.3998,  0.7485, -0.0443,  0.7805,  0.8446],
        [ 1.3354,  1.3727,  1.4156,  1.4046,  1.3796,  1.3425,  1.3129,  1.3317,
          1.3317,  1.3051,  1.4263,  1.3248,  1.4556,  1.3837,  1.4812,  1.3122,
          1.3596,  1.3695,  1.3925,  1.3735,  1.4256,  1.4062,  1.3593,  1.3523,
          1.2556,  1.3408,  1.3408,  1.3930,  1.4379,  1.3559,  1.1477,  1.3496,
          1.2449,  1.4118,  1.2338,  1.3601,  0.3424,  0.2663,  0.3807,  0.3500,
          0.1421,  0.0960,  0.3660,  0.1442, -0.0663,  3.3132,  2.2736,  3.2912,
          2.5906,  1.8303,  1.4290,  2.8200,  3.1124,  1.3935]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 268 : 175.04165150000787
Test loss for epoch 268 : 175.1265368918079
Test Precision for epoch 268 : 0.26153846153846155
Test Recall for epoch 268 : 0.26153846153846155
Test F1 for epoch 268 : 0.26153846153846155


theta for epoch 269 : tensor([[ 2.5709,  2.5898,  2.6267,  2.7323,  2.7136,  2.5742,  2.7006,  2.5693,
          2.5693,  1.3409,  1.3432,  1.3423,  1.3453,  1.3401,  1.3474,  1.3414,
          1.3384,  1.3007,  1.2941,  1.2520,  1.2527,  1.2951,  1.2917,  1.2912,
          1.2934,  1.2903,  1.2903,  1.2747,  1.3190,  1.3129,  1.3159,  1.3191,
          1.3143,  1.3171,  1.2691,  1.3132,  1.7397,  1.7507,  1.7442,  1.7402,
          1.7486,  1.6883,  1.7412,  1.7264,  1.7393,  1.6021,  1.5854,  1.5817,
          1.5756,  1.5986,  1.5805,  1.6132,  1.5723,  1.5739],
        [ 1.2984,  1.3012,  1.2682,  1.2711,  1.3024,  1.2995,  1.3000,  1.2986,
          1.2986,  2.5560,  2.5592,  2.4705,  2.6720,  2.4642,  2.9192,  2.5511,
          2.6331,  2.8919,  1.2892,  1.2945,  1.2479,  1.2872,  1.3168,  1.3163,
          1.3149,  1.3154,  1.3154,  1.3174,  1.2651,  1.3380,  1.3412,  1.2840,
          1.3395,  1.3424,  1.3122,  1.3383,  1.7552,  1.7672,  1.7234,  1.7540,
          1.7649,  1.7662,  1.7201,  1.6843,  1.7539,  1.5654,  1.6033,  1.5993,
          1.5927,  1.5253,  1.5981,  1.5414,  1.5891,  1.5908],
        [ 1.2789,  1.2817,  1.2844,  1.2834,  1.2815,  1.2794,  1.2798,  1.2786,
          1.2786,  1.3462,  1.3485,  1.3476,  1.3507,  1.3454,  1.2959,  1.3467,
          1.2872,  1.3341,  2.6250,  2.7096,  2.7622,  2.6341,  2.5659,  2.5630,
          2.6866,  2.5577,  2.5577,  1.2828,  1.3086,  1.3183,  1.3213,  1.2835,
          1.3197,  1.3225,  1.3182,  1.3186,  1.7430,  1.7541,  1.7476,  1.6872,
          1.7520,  1.7514,  1.7445,  1.7287,  1.6862,  1.6062,  1.5892,  1.5855,
          1.5793,  1.5830,  1.5843,  1.5983,  1.5751,  1.5775],
        [ 1.2880,  1.2908,  1.2935,  1.2926,  1.2907,  1.2885,  1.2889,  1.2877,
          1.2877,  1.3550,  1.3574,  1.3565,  1.3400,  1.3542,  1.2772,  1.3555,
          1.3517,  1.2755,  1.3085,  1.2892,  1.3097,  1.3095,  1.3059,  1.3054,
          1.3064,  1.3046,  1.3046,  2.7952,  2.7330,  2.5046,  2.5850,  2.7936,
          2.5132,  2.7134,  2.5575,  2.5064,  1.7487,  1.7602,  1.7265,  1.7474,
          1.7581,  1.7575,  1.7233,  1.7043,  1.7465,  1.6133,  1.5957,  1.5129,
          1.5313,  1.6096,  1.5906,  1.6248,  1.5270,  1.5837],
        [ 1.8795,  1.4800,  0.6329,  0.9604,  1.3741,  1.8096,  1.6826,  1.9152,
          1.9152,  1.7347,  1.3612,  1.5613,  0.9622,  1.7698,  0.1595,  1.6703,
          1.9364,  0.8885,  1.3813,  1.0334,  0.7891,  1.1907,  1.7508,  1.8172,
          1.5752,  1.9234,  1.9234,  0.8845,  0.8867,  1.8963,  1.6932,  0.9005,
          1.8370,  1.2983,  1.9451,  1.8606, -0.1032, -0.3499, -0.3929, -0.1456,
          0.1070,  0.2025, -0.2312, 15.4993,  4.6698,  0.2469,  0.6116,  0.6407,
          0.7484,  0.3997,  0.7484, -0.0444,  0.7804,  0.8445],
        [ 1.3358,  1.3731,  1.4159,  1.4050,  1.3800,  1.3429,  1.3133,  1.3321,
          1.3321,  1.3057,  1.4268,  1.3253,  1.4561,  1.3842,  1.4817,  1.3128,
          1.3601,  1.3701,  1.3931,  1.3738,  1.4261,  1.4068,  1.3598,  1.3528,
          1.2560,  1.3414,  1.3414,  1.3934,  1.4384,  1.3564,  1.1482,  1.3501,
          1.2454,  1.4123,  1.2343,  1.3605,  0.3430,  0.2669,  0.3812,  0.3505,
          0.1426,  0.0965,  0.3666,  0.1446, -0.0658,  3.3162,  2.2738,  3.2939,
          2.5913,  1.8300,  1.4286,  2.8207,  3.1158,  1.3931]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 269 : 175.031668870442
Test loss for epoch 269 : 175.12060922561744
Test Precision for epoch 269 : 0.26153846153846155
Test Recall for epoch 269 : 0.26153846153846155
Test F1 for epoch 269 : 0.26153846153846155


theta for epoch 270 : tensor([[ 2.5725,  2.5914,  2.6282,  2.7340,  2.7153,  2.5757,  2.7023,  2.5708,
          2.5708,  1.3408,  1.3431,  1.3422,  1.3452,  1.3400,  1.3473,  1.3413,
          1.3383,  1.3005,  1.2939,  1.2518,  1.2525,  1.2949,  1.2914,  1.2909,
          1.2932,  1.2901,  1.2901,  1.2745,  1.3189,  1.3128,  1.3158,  1.3190,
          1.3142,  1.3169,  1.2690,  1.3131,  1.7395,  1.7505,  1.7440,  1.7400,
          1.7484,  1.6881,  1.7410,  1.7262,  1.7391,  1.6022,  1.5854,  1.5817,
          1.5756,  1.5986,  1.5805,  1.6132,  1.5723,  1.5739],
        [ 1.2983,  1.3010,  1.2686,  1.2713,  1.3022,  1.2993,  1.2999,  1.2985,
          1.2985,  2.5570,  2.5606,  2.4725,  2.6743,  2.4659,  2.9201,  2.5524,
          2.6356,  2.8929,  1.2889,  1.2943,  1.2476,  1.2870,  1.3166,  1.3160,
          1.3148,  1.3151,  1.3151,  1.3173,  1.2651,  1.3378,  1.3410,  1.2843,
          1.3393,  1.3423,  1.3120,  1.3381,  1.7550,  1.7669,  1.7232,  1.7538,
          1.7646,  1.7659,  1.7199,  1.6849,  1.7536,  1.5654,  1.6033,  1.5992,
          1.5926,  1.5253,  1.5980,  1.5414,  1.5890,  1.5908],
        [ 1.2789,  1.2816,  1.2843,  1.2833,  1.2815,  1.2794,  1.2797,  1.2786,
          1.2786,  1.3461,  1.3484,  1.3475,  1.3506,  1.3453,  1.2957,  1.3466,
          1.2870,  1.3341,  2.6262,  2.7114,  2.7640,  2.6354,  2.5672,  2.5642,
          2.6884,  2.5590,  2.5590,  1.2826,  1.3085,  1.3182,  1.3212,  1.2833,
          1.3196,  1.3224,  1.3181,  1.3185,  1.7428,  1.7540,  1.7474,  1.6868,
          1.7518,  1.7512,  1.7443,  1.7285,  1.6859,  1.6062,  1.5893,  1.5855,
          1.5794,  1.5831,  1.5844,  1.5983,  1.5751,  1.5776],
        [ 1.2878,  1.2906,  1.2933,  1.2924,  1.2906,  1.2884,  1.2888,  1.2875,
          1.2875,  1.3548,  1.3572,  1.3563,  1.3398,  1.3540,  1.2774,  1.3554,
          1.3515,  1.2757,  1.3082,  1.2889,  1.3095,  1.3093,  1.3057,  1.3051,
          1.3061,  1.3043,  1.3043,  2.7965,  2.7342,  2.5066,  2.5861,  2.7949,
          2.5152,  2.7146,  2.5596,  2.5084,  1.7485,  1.7600,  1.7263,  1.7472,
          1.7578,  1.7572,  1.7231,  1.7046,  1.7462,  1.6133,  1.5957,  1.5134,
          1.5313,  1.6096,  1.5906,  1.6248,  1.5270,  1.5837],
        [ 1.8803,  1.4809,  0.6338,  0.9612,  1.3750,  1.8104,  1.6834,  1.9160,
          1.9160,  1.7353,  1.3620,  1.5622,  0.9633,  1.7706,  0.1604,  1.6709,
          1.9374,  0.8892,  1.3822,  1.0345,  0.7902,  1.1916,  1.7517,  1.8181,
          1.5762,  1.9242,  1.9242,  0.8855,  0.8875,  1.8972,  1.6939,  0.9013,
          1.8378,  1.2991,  1.9460,  1.8615, -0.1046, -0.3511, -0.3941, -0.1470,
          0.1055,  0.2010, -0.2325, 15.5418,  4.6448,  0.2479,  0.6126,  0.6415,
          0.7494,  0.4007,  0.7494, -0.0432,  0.7814,  0.8455],
        [ 1.3353,  1.3726,  1.4154,  1.4045,  1.3795,  1.3425,  1.3129,  1.3316,
          1.3316,  1.3051,  1.4262,  1.3247,  1.4555,  1.3836,  1.4810,  1.3122,
          1.3595,  1.3695,  1.3924,  1.3730,  1.4255,  1.4061,  1.3591,  1.3522,
          1.2552,  1.3407,  1.3407,  1.3928,  1.4378,  1.3559,  1.1476,  1.3495,
          1.2448,  1.4118,  1.2337,  1.3600,  0.3423,  0.2662,  0.3805,  0.3498,
          0.1419,  0.0958,  0.3659,  0.1438, -0.0666,  3.3205,  2.2752,  3.2979,
          2.5932,  1.8310,  1.4294,  2.8225,  3.1205,  1.3939]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 270 : 175.02163872157072
Test loss for epoch 270 : 175.11257681906602
Test Precision for epoch 270 : 0.26153846153846155
Test Recall for epoch 270 : 0.26153846153846155
Test F1 for epoch 270 : 0.26153846153846155


theta for epoch 271 : tensor([[ 2.5740,  2.5929,  2.6298,  2.7357,  2.7170,  2.5773,  2.7041,  2.5724,
          2.5724,  1.3407,  1.3430,  1.3421,  1.3451,  1.3399,  1.3472,  1.3412,
          1.3382,  1.3004,  1.2939,  1.2518,  1.2525,  1.2949,  1.2915,  1.2910,
          1.2932,  1.2902,  1.2902,  1.2744,  1.3188,  1.3127,  1.3157,  1.3189,
          1.3141,  1.3168,  1.2689,  1.3130,  1.7395,  1.7505,  1.7441,  1.7401,
          1.7484,  1.6881,  1.7410,  1.7262,  1.7392,  1.6014,  1.5847,  1.5810,
          1.5749,  1.5979,  1.5798,  1.6124,  1.5716,  1.5732],
        [ 1.2982,  1.3010,  1.2691,  1.2717,  1.3022,  1.2993,  1.2999,  1.2984,
          1.2984,  2.5579,  2.5619,  2.4743,  2.6766,  2.4675,  2.9210,  2.5535,
          2.6379,  2.8937,  1.2890,  1.2943,  1.2477,  1.2872,  1.3166,  1.3161,
          1.3149,  1.3152,  1.3152,  1.3172,  1.2652,  1.3377,  1.3409,  1.2846,
          1.3392,  1.3422,  1.3119,  1.3380,  1.7550,  1.7669,  1.7232,  1.7538,
          1.7646,  1.7659,  1.7198,  1.6857,  1.7536,  1.5646,  1.6025,  1.5984,
          1.5919,  1.5245,  1.5972,  1.5407,  1.5882,  1.5900],
        [ 1.2789,  1.2817,  1.2843,  1.2834,  1.2815,  1.2794,  1.2798,  1.2786,
          1.2786,  1.3461,  1.3484,  1.3475,  1.3506,  1.3453,  1.2956,  1.3466,
          1.2869,  1.3341,  2.6276,  2.7133,  2.7659,  2.6367,  2.5685,  2.5655,
          2.6903,  2.5603,  2.5603,  1.2824,  1.3085,  1.3181,  1.3212,  1.2831,
          1.3196,  1.3224,  1.3181,  1.3184,  1.7429,  1.7540,  1.7475,  1.6867,
          1.7519,  1.7512,  1.7444,  1.7286,  1.6857,  1.6056,  1.5886,  1.5849,
          1.5787,  1.5824,  1.5837,  1.5977,  1.5744,  1.5769],
        [ 1.2878,  1.2906,  1.2933,  1.2924,  1.2905,  1.2883,  1.2887,  1.2875,
          1.2875,  1.3547,  1.3571,  1.3562,  1.3397,  1.3539,  1.2778,  1.3553,
          1.3514,  1.2761,  1.3082,  1.2889,  1.3095,  1.3093,  1.3057,  1.3052,
          1.3061,  1.3043,  1.3043,  2.7977,  2.7353,  2.5086,  2.5870,  2.7961,
          2.5172,  2.7156,  2.5616,  2.5103,  1.7485,  1.7600,  1.7263,  1.7472,
          1.7578,  1.7572,  1.7231,  1.7053,  1.7462,  1.6126,  1.5950,  1.5132,
          1.5306,  1.6088,  1.5899,  1.6241,  1.5262,  1.5829],
        [ 1.8802,  1.4808,  0.6333,  0.9608,  1.3748,  1.8103,  1.6833,  1.9159,
          1.9159,  1.7346,  1.3615,  1.5619,  0.9629,  1.7702,  0.1598,  1.6704,
          1.9373,  0.8883,  1.3820,  1.0344,  0.7900,  1.1912,  1.7515,  1.8179,
          1.5761,  1.9241,  1.9241,  0.8851,  0.8869,  1.8970,  1.6934,  0.9007,
          1.8376,  1.2985,  1.9458,  1.8613, -0.1047, -0.3511, -0.3942, -0.1472,
          0.1053,  0.2006, -0.2326, 15.5855,  4.6211,  0.2474,  0.6121,  0.6409,
          0.7488,  0.4002,  0.7489, -0.0437,  0.7809,  0.8450],
        [ 1.3361,  1.3734,  1.4161,  1.4053,  1.3803,  1.3432,  1.3136,  1.3324,
          1.3324,  1.3060,  1.4271,  1.3255,  1.4563,  1.3845,  1.4819,  1.3131,
          1.3603,  1.3703,  1.3933,  1.3738,  1.4263,  1.4070,  1.3600,  1.3531,
          1.2560,  1.3416,  1.3416,  1.3935,  1.4386,  1.3567,  1.1484,  1.3502,
          1.2456,  1.4126,  1.2345,  1.3608,  0.3431,  0.2670,  0.3812,  0.3506,
          0.1427,  0.0966,  0.3667,  0.1445, -0.0659,  3.3231,  2.2750,  3.3003,
          2.5935,  1.8303,  1.4287,  2.8228,  3.1235,  1.3932]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 271 : 175.01153455803615
Test loss for epoch 271 : 175.10701683335236
Test Precision for epoch 271 : 0.26153846153846155
Test Recall for epoch 271 : 0.26153846153846155
Test F1 for epoch 271 : 0.26153846153846155


theta for epoch 272 : tensor([[ 2.5753,  2.5942,  2.6310,  2.7372,  2.7185,  2.5785,  2.7055,  2.5736,
          2.5736,  1.3406,  1.3429,  1.3420,  1.3451,  1.3398,  1.3471,  1.3411,
          1.3382,  1.3004,  1.2937,  1.2516,  1.2524,  1.2948,  1.2913,  1.2908,
          1.2931,  1.2900,  1.2900,  1.2744,  1.3187,  1.3126,  1.3156,  1.3188,
          1.3140,  1.3168,  1.2688,  1.3129,  1.7394,  1.7504,  1.7440,  1.7400,
          1.7483,  1.6880,  1.7409,  1.7261,  1.7391,  1.6018,  1.5850,  1.5813,
          1.5753,  1.5982,  1.5802,  1.6128,  1.5719,  1.5735],
        [ 1.2980,  1.3007,  1.2693,  1.2718,  1.3019,  1.2990,  1.2996,  1.2982,
          1.2982,  2.5587,  2.5631,  2.4761,  2.6787,  2.4690,  2.9218,  2.5545,
          2.6401,  2.8946,  1.2888,  1.2941,  1.2474,  1.2871,  1.3164,  1.3158,
          1.3148,  1.3150,  1.3150,  1.3170,  1.2652,  1.3375,  1.3408,  1.2848,
          1.3390,  1.3420,  1.3117,  1.3378,  1.7548,  1.7668,  1.7230,  1.7537,
          1.7645,  1.7658,  1.7197,  1.6863,  1.7534,  1.5649,  1.6028,  1.5988,
          1.5921,  1.5249,  1.5975,  1.5410,  1.5885,  1.5903],
        [ 1.2787,  1.2815,  1.2841,  1.2832,  1.2813,  1.2793,  1.2796,  1.2785,
          1.2785,  1.3461,  1.3484,  1.3475,  1.3505,  1.3452,  1.2954,  1.3466,
          1.2867,  1.3340,  2.6286,  2.7149,  2.7675,  2.6377,  2.5695,  2.5665,
          2.6918,  2.5613,  2.5613,  1.2823,  1.3084,  1.3181,  1.3211,  1.2829,
          1.3195,  1.3223,  1.3180,  1.3184,  1.7428,  1.7540,  1.7474,  1.6864,
          1.7519,  1.7512,  1.7443,  1.7286,  1.6855,  1.6060,  1.5890,  1.5853,
          1.5791,  1.5828,  1.5841,  1.5980,  1.5748,  1.5773],
        [ 1.2875,  1.2903,  1.2930,  1.2921,  1.2902,  1.2880,  1.2885,  1.2872,
          1.2872,  1.3546,  1.3570,  1.3561,  1.3396,  1.3538,  1.2781,  1.3551,
          1.3513,  1.2764,  1.3080,  1.2887,  1.3093,  1.3091,  1.3055,  1.3050,
          1.3059,  1.3041,  1.3041,  2.7987,  2.7362,  2.5103,  2.5878,  2.7971,
          2.5189,  2.7165,  2.5634,  2.5121,  1.7484,  1.7599,  1.7262,  1.7470,
          1.7577,  1.7570,  1.7230,  1.7058,  1.7460,  1.6128,  1.5953,  1.5141,
          1.5309,  1.6091,  1.5902,  1.6243,  1.5265,  1.5832],
        [ 1.8808,  1.4815,  0.6342,  0.9615,  1.3757,  1.8110,  1.6840,  1.9166,
          1.9166,  1.7351,  1.3622,  1.5628,  0.9639,  1.7710,  0.1606,  1.6709,
          1.9381,  0.8890,  1.3829,  1.0355,  0.7910,  1.1921,  1.7523,  1.8187,
          1.5771,  1.9249,  1.9249,  0.8860,  0.8877,  1.8978,  1.6941,  0.9015,
          1.8385,  1.2993,  1.9466,  1.8621, -0.1061, -0.3523, -0.3954, -0.1486,
          0.1038,  0.1991, -0.2339, 15.6280,  4.5958,  0.2486,  0.6132,  0.6418,
          0.7499,  0.4013,  0.7500, -0.0425,  0.7820,  0.8461],
        [ 1.3354,  1.3726,  1.4153,  1.4046,  1.3796,  1.3425,  1.3129,  1.3317,
          1.3317,  1.3053,  1.4263,  1.3247,  1.4555,  1.3837,  1.4810,  1.3123,
          1.3595,  1.3695,  1.3925,  1.3728,  1.4255,  1.4062,  1.3592,  1.3523,
          1.2550,  1.3408,  1.3408,  1.3928,  1.4380,  1.3560,  1.1476,  1.3495,
          1.2449,  1.4120,  1.2338,  1.3601,  0.3423,  0.2662,  0.3804,  0.3498,
          0.1418,  0.0957,  0.3659,  0.1435, -0.0668,  3.3275,  2.2765,  3.3044,
          2.5955,  1.8314,  1.4297,  2.8248,  3.1283,  1.3942]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 272 : 175.0013082592633
Test loss for epoch 272 : 175.09872264181243
Test Precision for epoch 272 : 0.26153846153846155
Test Recall for epoch 272 : 0.26153846153846155
Test F1 for epoch 272 : 0.26153846153846155


theta for epoch 273 : tensor([[ 2.5765,  2.5954,  2.6323,  2.7386,  2.7199,  2.5798,  2.7070,  2.5749,
          2.5749,  1.3405,  1.3428,  1.3419,  1.3450,  1.3397,  1.3470,  1.3410,
          1.3381,  1.3003,  1.2937,  1.2516,  1.2524,  1.2947,  1.2913,  1.2908,
          1.2931,  1.2900,  1.2900,  1.2743,  1.3187,  1.3126,  1.3156,  1.3187,
          1.3140,  1.3167,  1.2688,  1.3129,  1.7396,  1.7505,  1.7441,  1.7401,
          1.7485,  1.6882,  1.7410,  1.7263,  1.7392,  1.6016,  1.5848,  1.5811,
          1.5750,  1.5980,  1.5800,  1.6126,  1.5717,  1.5733],
        [ 1.2977,  1.3005,  1.2696,  1.2720,  1.3016,  1.2987,  1.2993,  1.2979,
          1.2979,  2.5595,  2.5643,  2.4779,  2.6809,  2.4706,  2.9226,  2.5556,
          2.6423,  2.8954,  1.2887,  1.2940,  1.2473,  1.2871,  1.3163,  1.3157,
          1.3148,  1.3149,  1.3149,  1.3168,  1.2652,  1.3374,  1.3406,  1.2851,
          1.3389,  1.3418,  1.3116,  1.3377,  1.7549,  1.7668,  1.7231,  1.7538,
          1.7645,  1.7658,  1.7197,  1.6872,  1.7535,  1.5646,  1.6025,  1.5985,
          1.5918,  1.5246,  1.5972,  1.5407,  1.5882,  1.5900],
        [ 1.2785,  1.2813,  1.2839,  1.2830,  1.2811,  1.2790,  1.2794,  1.2782,
          1.2782,  1.3459,  1.3482,  1.3473,  1.3504,  1.3451,  1.2952,  1.3464,
          1.2865,  1.3339,  2.6299,  2.7168,  2.7694,  2.6390,  2.5708,  2.5678,
          2.6936,  2.5626,  2.5626,  1.2820,  1.3083,  1.3180,  1.3210,  1.2827,
          1.3194,  1.3222,  1.3179,  1.3183,  1.7430,  1.7541,  1.7476,  1.6864,
          1.7520,  1.7513,  1.7445,  1.7287,  1.6854,  1.6057,  1.5888,  1.5850,
          1.5788,  1.5826,  1.5839,  1.5978,  1.5745,  1.5771],
        [ 1.2873,  1.2901,  1.2927,  1.2919,  1.2900,  1.2878,  1.2883,  1.2870,
          1.2870,  1.3545,  1.3568,  1.3559,  1.3394,  1.3536,  1.2783,  1.3550,
          1.3512,  1.2766,  1.3080,  1.2886,  1.3092,  1.3090,  1.3054,  1.3049,
          1.3058,  1.3041,  1.3041,  2.7998,  2.7371,  2.5122,  2.5887,  2.7982,
          2.5208,  2.7175,  2.5653,  2.5139,  1.7485,  1.7600,  1.7263,  1.7471,
          1.7578,  1.7571,  1.7231,  1.7065,  1.7461,  1.6126,  1.5950,  1.5143,
          1.5307,  1.6089,  1.5899,  1.6241,  1.5262,  1.5830],
        [ 1.8806,  1.4812,  0.6337,  0.9610,  1.3754,  1.8108,  1.6838,  1.9164,
          1.9164,  1.7345,  1.3617,  1.5625,  0.9636,  1.7706,  0.1600,  1.6704,
          1.9380,  0.8881,  1.3826,  1.0354,  0.7908,  1.1918,  1.7521,  1.8185,
          1.5770,  1.9247,  1.9247,  0.8856,  0.8871,  1.8976,  1.6936,  0.9009,
          1.8382,  1.2988,  1.9464,  1.8619, -0.1062, -0.3524, -0.3955, -0.1488,
          0.1035,  0.1987, -0.2340, 15.6717,  4.5718,  0.2482,  0.6128,  0.6413,
          0.7495,  0.4009,  0.7496, -0.0429,  0.7816,  0.8457],
        [ 1.3360,  1.3732,  1.4158,  1.4051,  1.3801,  1.3431,  1.3135,  1.3322,
          1.3322,  1.3060,  1.4271,  1.3255,  1.4562,  1.3844,  1.4817,  1.3131,
          1.3602,  1.3703,  1.3932,  1.3734,  1.4262,  1.4069,  1.3600,  1.3530,
          1.2556,  1.3415,  1.3415,  1.3934,  1.4386,  1.3566,  1.1482,  1.3501,
          1.2456,  1.4127,  1.2345,  1.3608,  0.3430,  0.2670,  0.3811,  0.3506,
          0.1426,  0.0964,  0.3666,  0.1441, -0.0661,  3.3303,  2.2764,  3.3069,
          2.5959,  1.8309,  1.4290,  2.8251,  3.1315,  1.3935]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 273 : 174.9910329283316
Test loss for epoch 273 : 175.0929094590407
Test Precision for epoch 273 : 0.26153846153846155
Test Recall for epoch 273 : 0.26153846153846155
Test F1 for epoch 273 : 0.26153846153846155


theta for epoch 274 : tensor([[ 2.5780,  2.5969,  2.6338,  2.7403,  2.7216,  2.5813,  2.7086,  2.5764,
          2.5764,  1.3404,  1.3427,  1.3418,  1.3448,  1.3396,  1.3468,  1.3409,
          1.3379,  1.3001,  1.2935,  1.2513,  1.2521,  1.2945,  1.2910,  1.2905,
          1.2928,  1.2897,  1.2897,  1.2742,  1.3185,  1.3124,  1.3154,  1.3186,
          1.3138,  1.3166,  1.2686,  1.3127,  1.7395,  1.7504,  1.7440,  1.7400,
          1.7483,  1.6880,  1.7409,  1.7261,  1.7391,  1.6016,  1.5848,  1.5812,
          1.5751,  1.5981,  1.5800,  1.6126,  1.5717,  1.5733],
        [ 1.2975,  1.3003,  1.2700,  1.2722,  1.3015,  1.2986,  1.2992,  1.2977,
          1.2977,  2.5604,  2.5656,  2.4799,  2.6832,  2.4723,  2.9236,  2.5568,
          2.6447,  2.8964,  1.2883,  1.2936,  1.2470,  1.2868,  1.3159,  1.3154,
          1.3145,  1.3145,  1.3145,  1.3166,  1.2651,  1.3372,  1.3404,  1.2853,
          1.3387,  1.3416,  1.3114,  1.3375,  1.7547,  1.7667,  1.7229,  1.7537,
          1.7644,  1.7656,  1.7195,  1.6878,  1.7533,  1.5646,  1.6024,  1.5984,
          1.5918,  1.5246,  1.5972,  1.5407,  1.5882,  1.5899],
        [ 1.2784,  1.2812,  1.2838,  1.2829,  1.2810,  1.2789,  1.2793,  1.2781,
          1.2781,  1.3458,  1.3481,  1.3472,  1.3502,  1.3449,  1.2949,  1.3463,
          1.2862,  1.3337,  2.6313,  2.7187,  2.7713,  2.6404,  2.5721,  2.5691,
          2.6955,  2.5639,  2.5639,  1.2818,  1.3082,  1.3179,  1.3209,  1.2824,
          1.3193,  1.3221,  1.3178,  1.3182,  1.7429,  1.7540,  1.7475,  1.6861,
          1.7519,  1.7511,  1.7443,  1.7286,  1.6851,  1.6057,  1.5888,  1.5850,
          1.5788,  1.5826,  1.5839,  1.5978,  1.5745,  1.5771],
        [ 1.2871,  1.2899,  1.2926,  1.2918,  1.2899,  1.2877,  1.2881,  1.2869,
          1.2869,  1.3543,  1.3566,  1.3557,  1.3392,  1.3534,  1.2785,  1.3548,
          1.3510,  1.2769,  1.3077,  1.2883,  1.3089,  1.3087,  1.3051,  1.3046,
          1.3055,  1.3038,  1.3038,  2.8010,  2.7382,  2.5141,  2.5896,  2.7994,
          2.5227,  2.7186,  2.5674,  2.5158,  1.7483,  1.7598,  1.7261,  1.7469,
          1.7576,  1.7569,  1.7229,  1.7069,  1.7459,  1.6125,  1.5950,  1.5149,
          1.5306,  1.6088,  1.5899,  1.6241,  1.5262,  1.5830],
        [ 1.8813,  1.4820,  0.6344,  0.9616,  1.3762,  1.8116,  1.6845,  1.9171,
          1.9171,  1.7349,  1.3623,  1.5632,  0.9645,  1.7713,  0.1607,  1.6708,
          1.9388,  0.8886,  1.3834,  1.0364,  0.7917,  1.1925,  1.7528,  1.8192,
          1.5779,  1.9254,  1.9254,  0.8865,  0.8878,  1.8983,  1.6941,  0.9015,
          1.8390,  1.2994,  1.9471,  1.8626, -0.1074, -0.3535, -0.3966, -0.1501,
          0.1022,  0.1973, -0.2351, 15.7143,  4.5465,  0.2492,  0.6137,  0.6420,
          0.7504,  0.4018,  0.7505, -0.0419,  0.7825,  0.8466],
        [ 1.3356,  1.3729,  1.4153,  1.4048,  1.3798,  1.3427,  1.3131,  1.3319,
          1.3319,  1.3056,  1.4266,  1.3250,  1.4557,  1.3840,  1.4813,  1.3126,
          1.3597,  1.3698,  1.3927,  1.3727,  1.4257,  1.4064,  1.3595,  1.3525,
          1.2549,  1.3410,  1.3410,  1.3929,  1.4383,  1.3563,  1.1478,  1.3496,
          1.2452,  1.4123,  1.2341,  1.3604,  0.3425,  0.2664,  0.3806,  0.3501,
          0.1420,  0.0959,  0.3661,  0.1435, -0.0668,  3.3343,  2.2776,  3.3106,
          2.5976,  1.8316,  1.4296,  2.8268,  3.1359,  1.3942]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 274 : 174.98073108853856
Test loss for epoch 274 : 175.08492039734438
Test Precision for epoch 274 : 0.26153846153846155
Test Recall for epoch 274 : 0.26153846153846155
Test F1 for epoch 274 : 0.26153846153846155


theta for epoch 275 : tensor([[ 2.5795,  2.5984,  2.6353,  2.7420,  2.7232,  2.5828,  2.7103,  2.5779,
          2.5779,  1.3403,  1.3426,  1.3417,  1.3447,  1.3395,  1.3467,  1.3408,
          1.3378,  1.3000,  1.2934,  1.2512,  1.2520,  1.2944,  1.2909,  1.2904,
          1.2927,  1.2896,  1.2896,  1.2741,  1.3184,  1.3123,  1.3153,  1.3185,
          1.3137,  1.3165,  1.2685,  1.3126,  1.7394,  1.7504,  1.7440,  1.7400,
          1.7483,  1.6880,  1.7409,  1.7261,  1.7391,  1.6012,  1.5844,  1.5808,
          1.5747,  1.5977,  1.5796,  1.6122,  1.5713,  1.5730],
        [ 1.2975,  1.3003,  1.2704,  1.2725,  1.3014,  1.2985,  1.2991,  1.2976,
          1.2976,  2.5613,  2.5668,  2.4818,  2.6855,  2.4740,  2.9245,  2.5579,
          2.6471,  2.8973,  1.2882,  1.2934,  1.2468,  1.2868,  1.3158,  1.3152,
          1.3145,  1.3144,  1.3144,  1.3165,  1.2651,  1.3370,  1.3402,  1.2856,
          1.3385,  1.3415,  1.3112,  1.3373,  1.7546,  1.7666,  1.7228,  1.7536,
          1.7643,  1.7656,  1.7195,  1.6885,  1.7532,  1.5642,  1.6020,  1.5980,
          1.5913,  1.5242,  1.5967,  1.5403,  1.5877,  1.5895],
        [ 1.2784,  1.2811,  1.2837,  1.2828,  1.2810,  1.2789,  1.2792,  1.2781,
          1.2781,  1.3457,  1.3480,  1.3471,  1.3501,  1.3448,  1.2947,  1.3462,
          1.2860,  1.3337,  2.6327,  2.7205,  2.7732,  2.6418,  2.5735,  2.5705,
          2.6974,  2.5653,  2.5653,  1.2815,  1.3081,  1.3178,  1.3208,  1.2822,
          1.3192,  1.3220,  1.3177,  1.3181,  1.7429,  1.7540,  1.7475,  1.6859,
          1.7519,  1.7511,  1.7443,  1.7286,  1.6849,  1.6054,  1.5884,  1.5847,
          1.5785,  1.5822,  1.5835,  1.5974,  1.5741,  1.5767],
        [ 1.2870,  1.2898,  1.2924,  1.2917,  1.2898,  1.2876,  1.2880,  1.2868,
          1.2868,  1.3541,  1.3565,  1.3556,  1.3391,  1.3533,  1.2788,  1.3546,
          1.3508,  1.2771,  1.3075,  1.2881,  1.3088,  1.3086,  1.3050,  1.3045,
          1.3053,  1.3036,  1.3036,  2.8022,  2.7393,  2.5161,  2.5906,  2.8006,
          2.5247,  2.7196,  2.5694,  2.5178,  1.7483,  1.7597,  1.7260,  1.7468,
          1.7576,  1.7568,  1.7228,  1.7075,  1.7458,  1.6121,  1.5946,  1.5150,
          1.5302,  1.6084,  1.5895,  1.6236,  1.5257,  1.5825],
        [ 1.8815,  1.4822,  0.6344,  0.9616,  1.3763,  1.8117,  1.6847,  1.9173,
          1.9173,  1.7346,  1.3622,  1.5633,  0.9646,  1.7713,  0.1605,  1.6706,
          1.9390,  0.8883,  1.3835,  1.0367,  0.7919,  1.1926,  1.7530,  1.8193,
          1.5781,  1.9255,  1.9255,  0.8865,  0.8876,  1.8984,  1.6940,  0.9014,
          1.8391,  1.2993,  1.9472,  1.8627, -0.1079, -0.3539, -0.3971, -0.1507,
          0.1016,  0.1966, -0.2356, 15.7577,  4.5218,  0.2492,  0.6137,  0.6418,
          0.7503,  0.4019,  0.7505, -0.0418,  0.7825,  0.8465],
        [ 1.3360,  1.3732,  1.4156,  1.4052,  1.3801,  1.3431,  1.3135,  1.3323,
          1.3323,  1.3061,  1.4270,  1.3254,  1.4561,  1.3844,  1.4816,  1.3131,
          1.3601,  1.3702,  1.3931,  1.3729,  1.4261,  1.4068,  1.3599,  1.3529,
          1.2552,  1.3414,  1.3414,  1.3932,  1.4386,  1.3566,  1.1481,  1.3499,
          1.2455,  1.4127,  1.2344,  1.3607,  0.3429,  0.2668,  0.3809,  0.3504,
          0.1424,  0.0962,  0.3665,  0.1437, -0.0665,  3.3374,  2.2778,  3.3134,
          2.5983,  1.8314,  1.4294,  2.8275,  3.1394,  1.3939]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 275 : 174.97047114392646
Test loss for epoch 275 : 175.07844468103178
Test Precision for epoch 275 : 0.26153846153846155
Test Recall for epoch 275 : 0.26153846153846155
Test F1 for epoch 275 : 0.26153846153846155


theta for epoch 276 : tensor([[ 2.5807,  2.5996,  2.6365,  2.7434,  2.7247,  2.5840,  2.7117,  2.5791,
          2.5791,  1.3403,  1.3425,  1.3416,  1.3447,  1.3394,  1.3467,  1.3408,
          1.3378,  1.3000,  1.2933,  1.2512,  1.2519,  1.2943,  1.2909,  1.2904,
          1.2927,  1.2896,  1.2896,  1.2740,  1.3184,  1.3123,  1.3153,  1.3184,
          1.3137,  1.3164,  1.2684,  1.3125,  1.7394,  1.7504,  1.7440,  1.7400,
          1.7483,  1.6880,  1.7409,  1.7261,  1.7390,  1.6012,  1.5845,  1.5808,
          1.5747,  1.5977,  1.5797,  1.6122,  1.5714,  1.5730],
        [ 1.2973,  1.3001,  1.2708,  1.2728,  1.3011,  1.2982,  1.2989,  1.2974,
          1.2974,  2.5620,  2.5679,  2.4835,  2.6876,  2.4755,  2.9253,  2.5588,
          2.6492,  2.8981,  1.2881,  1.2933,  1.2467,  1.2868,  1.3157,  1.3151,
          1.3145,  1.3143,  1.3143,  1.3163,  1.2651,  1.3368,  1.3401,  1.2859,
          1.3384,  1.3413,  1.3110,  1.3372,  1.7545,  1.7665,  1.7227,  1.7535,
          1.7642,  1.7655,  1.7194,  1.6892,  1.7532,  1.5642,  1.6020,  1.5980,
          1.5913,  1.5242,  1.5967,  1.5403,  1.5877,  1.5894],
        [ 1.2783,  1.2810,  1.2836,  1.2827,  1.2808,  1.2788,  1.2791,  1.2780,
          1.2780,  1.3457,  1.3480,  1.3471,  1.3501,  1.3448,  1.2946,  1.3462,
          1.2859,  1.3337,  2.6337,  2.7221,  2.7748,  2.6429,  2.5745,  2.5715,
          2.6989,  2.5663,  2.5663,  1.2813,  1.3081,  1.3177,  1.3208,  1.2820,
          1.3191,  1.3219,  1.3176,  1.3180,  1.7429,  1.7540,  1.7475,  1.6857,
          1.7519,  1.7511,  1.7443,  1.7286,  1.6847,  1.6054,  1.5885,  1.5847,
          1.5785,  1.5823,  1.5835,  1.5975,  1.5741,  1.5768],
        [ 1.2868,  1.2896,  1.2922,  1.2914,  1.2895,  1.2873,  1.2878,  1.2865,
          1.2865,  1.3540,  1.3563,  1.3554,  1.3389,  1.3531,  1.2791,  1.3545,
          1.3507,  1.2774,  1.3074,  1.2880,  1.3087,  1.3085,  1.3049,  1.3043,
          1.3051,  1.3035,  1.3035,  2.8032,  2.7402,  2.5179,  2.5914,  2.8016,
          2.5265,  2.7205,  2.5713,  2.5196,  1.7482,  1.7597,  1.7260,  1.7467,
          1.7575,  1.7567,  1.7228,  1.7080,  1.7457,  1.6121,  1.5945,  1.5155,
          1.5302,  1.6084,  1.5895,  1.6236,  1.5257,  1.5825],
        [ 1.8818,  1.4825,  0.6346,  0.9618,  1.3767,  1.8120,  1.6849,  1.9176,
          1.9176,  1.7346,  1.3624,  1.5636,  0.9650,  1.7716,  0.1607,  1.6707,
          1.9394,  0.8883,  1.3838,  1.0372,  0.7924,  1.1929,  1.7533,  1.8197,
          1.5786,  1.9259,  1.9259,  0.8868,  0.8878,  1.8987,  1.6941,  0.9015,
          1.8394,  1.2994,  1.9475,  1.8631, -0.1087, -0.3545, -0.3977, -0.1515,
          0.1007,  0.1956, -0.2363, 15.8008,  4.4967,  0.2496,  0.6141,  0.6421,
          0.7507,  0.4023,  0.7509, -0.0414,  0.7829,  0.8469],
        [ 1.3359,  1.3731,  1.4154,  1.4050,  1.3800,  1.3430,  1.3134,  1.3321,
          1.3321,  1.3060,  1.4270,  1.3253,  1.4560,  1.3843,  1.4815,  1.3130,
          1.3600,  1.3702,  1.3930,  1.3727,  1.4260,  1.4067,  1.3598,  1.3528,
          1.2549,  1.3413,  1.3413,  1.3931,  1.4385,  1.3565,  1.1480,  1.3498,
          1.2455,  1.4126,  1.2343,  1.3607,  0.3428,  0.2667,  0.3808,  0.3503,
          0.1422,  0.0960,  0.3664,  0.1435, -0.0667,  3.3410,  2.2786,  3.3167,
          2.5996,  1.8318,  1.4296,  2.8287,  3.1434,  1.3941]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 276 : 174.96024385565758
Test loss for epoch 276 : 175.07134510157684
Test Precision for epoch 276 : 0.26153846153846155
Test Recall for epoch 276 : 0.26153846153846155
Test F1 for epoch 276 : 0.26153846153846155


theta for epoch 277 : tensor([[ 2.5820,  2.6009,  2.6378,  2.7448,  2.7261,  2.5852,  2.7131,  2.5803,
          2.5803,  1.3402,  1.3425,  1.3416,  1.3446,  1.3394,  1.3466,  1.3407,
          1.3377,  1.2999,  1.2933,  1.2512,  1.2519,  1.2943,  1.2909,  1.2904,
          1.2926,  1.2896,  1.2896,  1.2739,  1.3183,  1.3122,  1.3152,  1.3184,
          1.3136,  1.3163,  1.2684,  1.3125,  1.7394,  1.7503,  1.7439,  1.7400,
          1.7483,  1.6880,  1.7409,  1.7261,  1.7390,  1.6013,  1.5845,  1.5809,
          1.5748,  1.5978,  1.5797,  1.6123,  1.5714,  1.5730],
        [ 1.2970,  1.2999,  1.2711,  1.2730,  1.3009,  1.2980,  1.2987,  1.2972,
          1.2972,  2.5627,  2.5689,  2.4852,  2.6897,  2.4770,  2.9261,  2.5597,
          2.6514,  2.8989,  1.2880,  1.2932,  1.2466,  1.2868,  1.3156,  1.3150,
          1.3144,  1.3141,  1.3141,  1.3162,  1.2651,  1.3367,  1.3400,  1.2862,
          1.3382,  1.3412,  1.3109,  1.3370,  1.7544,  1.7664,  1.7226,  1.7535,
          1.7641,  1.7654,  1.7193,  1.6899,  1.7531,  1.5642,  1.6019,  1.5979,
          1.5913,  1.5242,  1.5967,  1.5403,  1.5876,  1.5894],
        [ 1.2781,  1.2809,  1.2834,  1.2826,  1.2807,  1.2786,  1.2790,  1.2778,
          1.2778,  1.3456,  1.3479,  1.3470,  1.3501,  1.3448,  1.2945,  1.3461,
          1.2857,  1.3337,  2.6349,  2.7238,  2.7764,  2.6440,  2.5756,  2.5726,
          2.7005,  2.5674,  2.5674,  1.2812,  1.3080,  1.3176,  1.3207,  1.2818,
          1.3191,  1.3219,  1.3176,  1.3179,  1.7428,  1.7540,  1.7474,  1.6855,
          1.7519,  1.7510,  1.7443,  1.7287,  1.6845,  1.6055,  1.5885,  1.5848,
          1.5786,  1.5824,  1.5836,  1.5975,  1.5741,  1.5768],
        [ 1.2866,  1.2894,  1.2920,  1.2912,  1.2893,  1.2871,  1.2876,  1.2863,
          1.2863,  1.3539,  1.3562,  1.3553,  1.3388,  1.3530,  1.2794,  1.3544,
          1.3505,  1.2777,  1.3073,  1.2878,  1.3085,  1.3083,  1.3047,  1.3042,
          1.3050,  1.3034,  1.3034,  2.8043,  2.7411,  2.5197,  2.5922,  2.8027,
          2.5283,  2.7215,  2.5732,  2.5215,  1.7481,  1.7596,  1.7259,  1.7466,
          1.7574,  1.7566,  1.7227,  1.7085,  1.7456,  1.6121,  1.5945,  1.5159,
          1.5302,  1.6084,  1.5894,  1.6236,  1.5256,  1.5825],
        [ 1.8820,  1.4828,  0.6348,  0.9619,  1.3770,  1.8123,  1.6852,  1.9178,
          1.9178,  1.7345,  1.3625,  1.5640,  0.9654,  1.7718,  0.1609,  1.6707,
          1.9398,  0.8882,  1.3842,  1.0377,  0.7928,  1.1932,  1.7537,  1.8200,
          1.5791,  1.9262,  1.9262,  0.8871,  0.8879,  1.8990,  1.6942,  0.9016,
          1.8397,  1.2996,  1.9479,  1.8634, -0.1094, -0.3552, -0.3984, -0.1523,
          0.0998,  0.1946, -0.2370, 15.8440,  4.4715,  0.2500,  0.6144,  0.6423,
          0.7511,  0.4027,  0.7512, -0.0409,  0.7833,  0.8473],
        [ 1.3358,  1.3730,  1.4152,  1.4049,  1.3799,  1.3429,  1.3133,  1.3320,
          1.3320,  1.3060,  1.4269,  1.3252,  1.4559,  1.3842,  1.4814,  1.3130,
          1.3599,  1.3701,  1.3929,  1.3724,  1.4259,  1.4066,  1.3597,  1.3528,
          1.2547,  1.3413,  1.3413,  1.3929,  1.4385,  1.3565,  1.1479,  1.3497,
          1.2454,  1.4126,  1.2343,  1.3606,  0.3427,  0.2666,  0.3807,  0.3502,
          0.1421,  0.0959,  0.3663,  0.1433, -0.0669,  3.3446,  2.2793,  3.3200,
          2.6008,  1.8321,  1.4298,  2.8299,  3.1474,  1.3943]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 277 : 174.95007005776904
Test loss for epoch 277 : 175.06432364327588
Test Precision for epoch 277 : 0.26153846153846155
Test Recall for epoch 277 : 0.26153846153846155
Test F1 for epoch 277 : 0.26153846153846155


theta for epoch 278 : tensor([[ 2.5835,  2.6024,  2.6393,  2.7465,  2.7277,  2.5867,  2.7148,  2.5818,
          2.5818,  1.3401,  1.3423,  1.3414,  1.3445,  1.3392,  1.3465,  1.3406,
          1.3376,  1.2997,  1.2932,  1.2510,  1.2518,  1.2942,  1.2907,  1.2902,
          1.2925,  1.2894,  1.2894,  1.2738,  1.3182,  1.3121,  1.3151,  1.3182,
          1.3135,  1.3162,  1.2683,  1.3124,  1.7394,  1.7503,  1.7439,  1.7400,
          1.7483,  1.6879,  1.7409,  1.7260,  1.7390,  1.6009,  1.5842,  1.5805,
          1.5744,  1.5974,  1.5793,  1.6119,  1.5710,  1.5727],
        [ 1.2969,  1.2997,  1.2715,  1.2733,  1.3008,  1.2979,  1.2986,  1.2970,
          1.2970,  2.5636,  2.5701,  2.4872,  2.6920,  2.4788,  2.9270,  2.5608,
          2.6538,  2.8999,  1.2879,  1.2930,  1.2464,  1.2867,  1.3154,  1.3148,
          1.3143,  1.3140,  1.3140,  1.3160,  1.2651,  1.3365,  1.3398,  1.2865,
          1.3380,  1.3410,  1.3107,  1.3368,  1.7544,  1.7663,  1.7226,  1.7534,
          1.7641,  1.7653,  1.7192,  1.6907,  1.7530,  1.5638,  1.6015,  1.5975,
          1.5908,  1.5238,  1.5962,  1.5399,  1.5872,  1.5890],
        [ 1.2780,  1.2808,  1.2833,  1.2825,  1.2806,  1.2786,  1.2789,  1.2778,
          1.2778,  1.3455,  1.3478,  1.3469,  1.3500,  1.3447,  1.2943,  1.3460,
          1.2855,  1.3335,  2.6362,  2.7256,  2.7783,  2.6453,  2.5770,  2.5739,
          2.7024,  2.5688,  2.5688,  1.2809,  1.3079,  1.3175,  1.3206,  1.2816,
          1.3190,  1.3218,  1.3175,  1.3178,  1.7428,  1.7540,  1.7475,  1.6853,
          1.7519,  1.7510,  1.7443,  1.7287,  1.6843,  1.6051,  1.5882,  1.5845,
          1.5782,  1.5820,  1.5833,  1.5972,  1.5737,  1.5765],
        [ 1.2865,  1.2893,  1.2918,  1.2911,  1.2892,  1.2870,  1.2874,  1.2862,
          1.2862,  1.3537,  1.3560,  1.3551,  1.3386,  1.3528,  1.2797,  1.3542,
          1.3504,  1.2780,  1.3071,  1.2877,  1.3084,  1.3082,  1.3046,  1.3041,
          1.3048,  1.3032,  1.3032,  2.8054,  2.7421,  2.5217,  2.5931,  2.8038,
          2.5303,  2.7225,  2.5752,  2.5234,  1.7481,  1.7595,  1.7259,  1.7465,
          1.7574,  1.7565,  1.7227,  1.7091,  1.7455,  1.6117,  1.5941,  1.5161,
          1.5298,  1.6080,  1.5891,  1.6232,  1.5252,  1.5821],
        [ 1.8822,  1.4829,  0.6349,  0.9619,  1.3772,  1.8125,  1.6854,  1.9180,
          1.9180,  1.7343,  1.3624,  1.5641,  0.9655,  1.7719,  0.1607,  1.6705,
          1.9401,  0.8879,  1.3843,  1.0380,  0.7930,  1.1933,  1.7538,  1.8202,
          1.5794,  1.9264,  1.9264,  0.8872,  0.8878,  1.8992,  1.6941,  0.9015,
          1.8399,  1.2995,  1.9480,  1.8635, -0.1099, -0.3556, -0.3989, -0.1529,
          0.0992,  0.1939, -0.2375, 15.8874,  4.4465,  0.2501,  0.6145,  0.6422,
          0.7511,  0.4027,  0.7513, -0.0408,  0.7833,  0.8473],
        [ 1.3361,  1.3733,  1.4155,  1.4052,  1.3802,  1.3432,  1.3136,  1.3323,
          1.3323,  1.3064,  1.4273,  1.3255,  1.4562,  1.3845,  1.4817,  1.3133,
          1.3602,  1.3705,  1.3933,  1.3726,  1.4262,  1.4070,  1.3600,  1.3531,
          1.2549,  1.3416,  1.3416,  1.3932,  1.4388,  1.3568,  1.1482,  1.3499,
          1.2457,  1.4129,  1.2346,  1.3609,  0.3430,  0.2669,  0.3809,  0.3505,
          0.1424,  0.0961,  0.3666,  0.1434, -0.0667,  3.3478,  2.2795,  3.3229,
          2.6016,  1.8319,  1.4295,  2.8306,  3.1510,  1.3941]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 278 : 174.9399077795421
Test loss for epoch 278 : 175.05787520299674
Test Precision for epoch 278 : 0.26153846153846155
Test Recall for epoch 278 : 0.26153846153846155
Test F1 for epoch 278 : 0.26153846153846155


theta for epoch 279 : tensor([[ 2.5849,  2.6038,  2.6407,  2.7481,  2.7293,  2.5881,  2.7164,  2.5833,
          2.5833,  1.3399,  1.3421,  1.3413,  1.3443,  1.3391,  1.3463,  1.3404,
          1.3374,  1.2996,  1.2929,  1.2508,  1.2515,  1.2939,  1.2905,  1.2900,
          1.2922,  1.2892,  1.2892,  1.2737,  1.3181,  1.3120,  1.3150,  1.3181,
          1.3134,  1.3161,  1.2681,  1.3122,  1.7393,  1.7502,  1.7438,  1.7399,
          1.7482,  1.6878,  1.7408,  1.7259,  1.7389,  1.6009,  1.5842,  1.5805,
          1.5744,  1.5974,  1.5793,  1.6119,  1.5710,  1.5727],
        [ 1.2967,  1.2995,  1.2718,  1.2735,  1.3006,  1.2977,  1.2984,  1.2968,
          1.2968,  2.5644,  2.5713,  2.4891,  2.6943,  2.4805,  2.9279,  2.5619,
          2.6562,  2.9008,  1.2875,  1.2927,  1.2461,  1.2865,  1.3150,  1.3145,
          1.3141,  1.3136,  1.3136,  1.3158,  1.2650,  1.3363,  1.3396,  1.2867,
          1.3378,  1.3408,  1.3105,  1.3366,  1.7542,  1.7662,  1.7224,  1.7533,
          1.7639,  1.7652,  1.7190,  1.6913,  1.7528,  1.5637,  1.6014,  1.5974,
          1.5908,  1.5238,  1.5962,  1.5398,  1.5871,  1.5889],
        [ 1.2779,  1.2807,  1.2831,  1.2824,  1.2805,  1.2784,  1.2788,  1.2777,
          1.2777,  1.3453,  1.3476,  1.3467,  1.3498,  1.3445,  1.2940,  1.3458,
          1.2852,  1.3334,  2.6375,  2.7274,  2.7801,  2.6466,  2.5782,  2.5752,
          2.7042,  2.5700,  2.5700,  1.2807,  1.3078,  1.3174,  1.3205,  1.2814,
          1.3189,  1.3217,  1.3173,  1.3177,  1.7428,  1.7539,  1.7474,  1.6851,
          1.7518,  1.7509,  1.7443,  1.7286,  1.6841,  1.6051,  1.5882,  1.5845,
          1.5782,  1.5821,  1.5833,  1.5972,  1.5737,  1.5765],
        [ 1.2863,  1.2891,  1.2916,  1.2910,  1.2891,  1.2869,  1.2873,  1.2860,
          1.2860,  1.3535,  1.3558,  1.3549,  1.3384,  1.3527,  1.2799,  1.3540,
          1.3502,  1.2782,  1.3069,  1.2874,  1.3081,  1.3079,  1.3044,  1.3038,
          1.3045,  1.3030,  1.3030,  2.8065,  2.7431,  2.5236,  2.5940,  2.8049,
          2.5322,  2.7234,  2.5772,  2.5253,  1.7479,  1.7594,  1.7257,  1.7464,
          1.7572,  1.7564,  1.7225,  1.7095,  1.7453,  1.6116,  1.5941,  1.5166,
          1.5298,  1.6080,  1.5890,  1.6232,  1.5251,  1.5821],
        [ 1.8828,  1.4836,  0.6355,  0.9624,  1.3778,  1.8131,  1.6860,  1.9186,
          1.9186,  1.7346,  1.3629,  1.5647,  0.9663,  1.7724,  0.1613,  1.6709,
          1.9407,  0.8883,  1.3850,  1.0389,  0.7938,  1.1940,  1.7545,  1.8208,
          1.5801,  1.9269,  1.9269,  0.8879,  0.8884,  1.8998,  1.6946,  0.9020,
          1.8405,  1.3000,  1.9486,  1.8642, -0.1110, -0.3566, -0.3998, -0.1541,
          0.0980,  0.1926, -0.2385, 15.9302,  4.4207,  0.2510,  0.6152,  0.6428,
          0.7518,  0.4035,  0.7520, -0.0399,  0.7840,  0.8480],
        [ 1.3358,  1.3730,  1.4151,  1.4049,  1.3799,  1.3429,  1.3133,  1.3320,
          1.3320,  1.3061,  1.4269,  1.3252,  1.4559,  1.3842,  1.4814,  1.3130,
          1.3598,  1.3701,  1.3929,  1.3721,  1.4258,  1.4066,  1.3597,  1.3527,
          1.2544,  1.3412,  1.3412,  1.3928,  1.4385,  1.3565,  1.1478,  1.3496,
          1.2454,  1.4126,  1.2343,  1.3606,  0.3426,  0.2665,  0.3805,  0.3501,
          0.1420,  0.0957,  0.3662,  0.1429, -0.0672,  3.3516,  2.2805,  3.3264,
          2.6031,  1.8325,  1.4300,  2.8320,  3.1552,  1.3946]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 279 : 174.92975520815773
Test loss for epoch 279 : 175.05028380010114
Test Precision for epoch 279 : 0.26153846153846155
Test Recall for epoch 279 : 0.26153846153846155
Test F1 for epoch 279 : 0.26153846153846155


theta for epoch 280 : tensor([[ 2.5862,  2.6050,  2.6420,  2.7495,  2.7308,  2.5894,  2.7178,  2.5845,
          2.5845,  1.3398,  1.3421,  1.3412,  1.3442,  1.3390,  1.3462,  1.3403,
          1.3373,  1.2995,  1.2929,  1.2507,  1.2515,  1.2939,  1.2904,  1.2900,
          1.2922,  1.2891,  1.2891,  1.2736,  1.3180,  1.3119,  1.3149,  1.3180,
          1.3133,  1.3160,  1.2680,  1.3122,  1.7394,  1.7503,  1.7439,  1.7399,
          1.7482,  1.6879,  1.7408,  1.7260,  1.7390,  1.6007,  1.5840,  1.5803,
          1.5742,  1.5972,  1.5791,  1.6117,  1.5708,  1.5725],
        [ 1.2965,  1.2993,  1.2722,  1.2738,  1.3003,  1.2974,  1.2982,  1.2966,
          1.2966,  2.5651,  2.5723,  2.4909,  2.6964,  2.4821,  2.9287,  2.5628,
          2.6584,  2.9016,  1.2874,  1.2926,  1.2460,  1.2865,  1.3149,  1.3144,
          1.3140,  1.3135,  1.3135,  1.3156,  1.2650,  1.3362,  1.3394,  1.2870,
          1.3377,  1.3407,  1.3103,  1.3365,  1.7542,  1.7662,  1.7224,  1.7533,
          1.7639,  1.7652,  1.7190,  1.6921,  1.7528,  1.5635,  1.6011,  1.5972,
          1.5905,  1.5236,  1.5959,  1.5396,  1.5868,  1.5886],
        [ 1.2777,  1.2805,  1.2829,  1.2822,  1.2803,  1.2783,  1.2786,  1.2775,
          1.2775,  1.3452,  1.3475,  1.3466,  1.3497,  1.3444,  1.2938,  1.3457,
          1.2850,  1.3333,  2.6388,  2.7292,  2.7818,  2.6479,  2.5795,  2.5764,
          2.7059,  2.5713,  2.5713,  1.2805,  1.3077,  1.3173,  1.3204,  1.2812,
          1.3188,  1.3216,  1.3172,  1.3176,  1.7428,  1.7540,  1.7475,  1.6850,
          1.7519,  1.7509,  1.7443,  1.7287,  1.6840,  1.6049,  1.5880,  1.5843,
          1.5780,  1.5819,  1.5830,  1.5970,  1.5735,  1.5763],
        [ 1.2861,  1.2889,  1.2914,  1.2907,  1.2888,  1.2866,  1.2871,  1.2858,
          1.2858,  1.3534,  1.3557,  1.3548,  1.3383,  1.3525,  1.2801,  1.3539,
          1.3501,  1.2785,  1.3068,  1.2873,  1.3081,  1.3078,  1.3043,  1.3037,
          1.3044,  1.3029,  1.3029,  2.8075,  2.7440,  2.5254,  2.5948,  2.8059,
          2.5340,  2.7243,  2.5791,  2.5271,  1.7480,  1.7594,  1.7258,  1.7464,
          1.7573,  1.7564,  1.7226,  1.7102,  1.7453,  1.6114,  1.5938,  1.5168,
          1.5295,  1.6077,  1.5888,  1.6229,  1.5249,  1.5818],
        [ 1.8827,  1.4834,  0.6352,  0.9621,  1.3777,  1.8130,  1.6859,  1.9185,
          1.9185,  1.7341,  1.3625,  1.5646,  0.9661,  1.7722,  0.1609,  1.6704,
          1.9407,  0.8877,  1.3849,  1.0389,  0.7938,  1.1938,  1.7544,  1.8207,
          1.5802,  1.9269,  1.9269,  0.8877,  0.8880,  1.8997,  1.6942,  0.9015,
          1.8404,  1.2997,  1.9485,  1.8641, -0.1113, -0.3568, -0.4000, -0.1544,
          0.0976,  0.1921, -0.2387, 15.9739,  4.3957,  0.2508,  0.6150,  0.6424,
          0.7515,  0.4033,  0.7518, -0.0401,  0.7838,  0.8478],
        [ 1.3362,  1.3734,  1.4154,  1.4053,  1.3803,  1.3433,  1.3137,  1.3325,
          1.3325,  1.3067,  1.4275,  1.3257,  1.4564,  1.3847,  1.4819,  1.3136,
          1.3603,  1.3707,  1.3935,  1.3725,  1.4263,  1.4071,  1.3602,  1.3533,
          1.2548,  1.3418,  1.3418,  1.3932,  1.4390,  1.3570,  1.1483,  1.3500,
          1.2459,  1.4131,  1.2348,  1.3611,  0.3431,  0.2670,  0.3810,  0.3506,
          0.1425,  0.0962,  0.3667,  0.1434, -0.0667,  3.3545,  2.2806,  3.3290,
          2.6036,  1.8321,  1.4296,  2.8325,  3.1585,  1.3941]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 280 : 174.91957978344854
Test loss for epoch 280 : 175.0443159573941
Test Precision for epoch 280 : 0.26153846153846155
Test Recall for epoch 280 : 0.26153846153846155
Test F1 for epoch 280 : 0.26153846153846155


theta for epoch 281 : tensor([[ 2.5874,  2.6063,  2.6432,  2.7509,  2.7322,  2.5906,  2.7192,  2.5857,
          2.5857,  1.3398,  1.3420,  1.3411,  1.3441,  1.3389,  1.3462,  1.3402,
          1.3372,  1.2994,  1.2927,  1.2506,  1.2513,  1.2937,  1.2903,  1.2898,
          1.2920,  1.2890,  1.2890,  1.2735,  1.3179,  1.3118,  1.3148,  1.3180,
          1.3132,  1.3160,  1.2680,  1.3121,  1.7393,  1.7502,  1.7438,  1.7399,
          1.7482,  1.6878,  1.7408,  1.7259,  1.7389,  1.6009,  1.5842,  1.5805,
          1.5744,  1.5974,  1.5793,  1.6119,  1.5710,  1.5727],
        [ 1.2963,  1.2991,  1.2725,  1.2740,  1.3001,  1.2972,  1.2979,  1.2964,
          1.2964,  2.5658,  2.5733,  2.4927,  2.6986,  2.4837,  2.9295,  2.5636,
          2.6606,  2.9024,  1.2872,  1.2923,  1.2458,  1.2863,  1.3147,  1.3142,
          1.3139,  1.3133,  1.3133,  1.3154,  1.2650,  1.3360,  1.3393,  1.2873,
          1.3375,  1.3405,  1.3102,  1.3363,  1.7541,  1.7660,  1.7222,  1.7532,
          1.7638,  1.7650,  1.7189,  1.6928,  1.7527,  1.5636,  1.6013,  1.5973,
          1.5906,  1.5237,  1.5960,  1.5398,  1.5869,  1.5888],
        [ 1.2776,  1.2803,  1.2828,  1.2821,  1.2802,  1.2781,  1.2785,  1.2773,
          1.2773,  1.3452,  1.3475,  1.3466,  1.3496,  1.3443,  1.2937,  1.3457,
          1.2849,  1.3332,  2.6399,  2.7307,  2.7833,  2.6489,  2.5805,  2.5775,
          2.7074,  2.5723,  2.5723,  1.2803,  1.3077,  1.3173,  1.3203,  1.2810,
          1.3187,  1.3215,  1.3172,  1.3176,  1.7428,  1.7539,  1.7474,  1.6847,
          1.7518,  1.7508,  1.7443,  1.7286,  1.6837,  1.6051,  1.5882,  1.5845,
          1.5782,  1.5821,  1.5833,  1.5972,  1.5736,  1.5765],
        [ 1.2859,  1.2887,  1.2911,  1.2905,  1.2886,  1.2864,  1.2869,  1.2856,
          1.2856,  1.3532,  1.3556,  1.3547,  1.3382,  1.3524,  1.2804,  1.3538,
          1.3499,  1.2788,  1.3066,  1.2870,  1.3078,  1.3076,  1.3040,  1.3035,
          1.3042,  1.3027,  1.3027,  2.8085,  2.7449,  2.5272,  2.5956,  2.8069,
          2.5358,  2.7252,  2.5810,  2.5289,  1.7478,  1.7593,  1.7256,  1.7462,
          1.7571,  1.7562,  1.7224,  1.7106,  1.7452,  1.6115,  1.5940,  1.5175,
          1.5297,  1.6078,  1.5889,  1.6230,  1.5249,  1.5819],
        [ 1.8832,  1.4841,  0.6358,  0.9626,  1.3784,  1.8136,  1.6865,  1.9191,
          1.9191,  1.7344,  1.3630,  1.5653,  0.9669,  1.7729,  0.1615,  1.6708,
          1.9414,  0.8881,  1.3856,  1.0398,  0.7946,  1.1946,  1.7550,  1.8214,
          1.5810,  1.9275,  1.9275,  0.8885,  0.8886,  1.9004,  1.6947,  0.9021,
          1.8411,  1.3002,  1.9492,  1.8647, -0.1124, -0.3578, -0.4010, -0.1556,
          0.0964,  0.1908, -0.2397, 16.0167,  4.3696,  0.2517,  0.6159,  0.6432,
          0.7524,  0.4042,  0.7526, -0.0391,  0.7847,  0.8486],
        [ 1.3357,  1.3729,  1.4148,  1.4048,  1.3798,  1.3428,  1.3132,  1.3319,
          1.3319,  1.3062,  1.4270,  1.3251,  1.4558,  1.3842,  1.4813,  1.3131,
          1.3598,  1.3701,  1.3929,  1.3717,  1.4257,  1.4066,  1.3596,  1.3527,
          1.2541,  1.3412,  1.3412,  1.3926,  1.4385,  1.3565,  1.1477,  1.3494,
          1.2454,  1.4127,  1.2342,  1.3606,  0.3425,  0.2664,  0.3804,  0.3500,
          0.1419,  0.0955,  0.3661,  0.1426, -0.0674,  3.3586,  2.2818,  3.3328,
          2.6054,  1.8329,  1.4303,  2.8342,  3.1630,  1.3948]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 281 : 174.90938348927864
Test loss for epoch 281 : 175.0364908278646
Test Precision for epoch 281 : 0.26153846153846155
Test Recall for epoch 281 : 0.26153846153846155
Test F1 for epoch 281 : 0.26153846153846155


theta for epoch 282 : tensor([[ 2.5888,  2.6077,  2.6446,  2.7525,  2.7337,  2.5920,  2.7208,  2.5871,
          2.5871,  1.3397,  1.3419,  1.3410,  1.3440,  1.3388,  1.3461,  1.3402,
          1.3372,  1.2993,  1.2927,  1.2506,  1.2513,  1.2937,  1.2903,  1.2898,
          1.2920,  1.2890,  1.2890,  1.2734,  1.3178,  1.3117,  1.3147,  1.3179,
          1.3131,  1.3159,  1.2679,  1.3120,  1.7393,  1.7502,  1.7438,  1.7399,
          1.7482,  1.6878,  1.7408,  1.7259,  1.7389,  1.6004,  1.5836,  1.5800,
          1.5739,  1.5969,  1.5788,  1.6114,  1.5705,  1.5722],
        [ 1.2962,  1.2990,  1.2729,  1.2744,  1.3000,  1.2971,  1.2979,  1.2963,
          1.2963,  2.5665,  2.5743,  2.4945,  2.7008,  2.4853,  2.9304,  2.5645,
          2.6628,  2.9033,  1.2872,  1.2923,  1.2457,  1.2864,  1.3147,  1.3141,
          1.3139,  1.3133,  1.3133,  1.3153,  1.2649,  1.3359,  1.3391,  1.2877,
          1.3374,  1.3404,  1.3100,  1.3362,  1.7540,  1.7660,  1.7222,  1.7532,
          1.7637,  1.7650,  1.7188,  1.6936,  1.7526,  1.5630,  1.6007,  1.5967,
          1.5900,  1.5232,  1.5954,  1.5392,  1.5864,  1.5882],
        [ 1.2776,  1.2803,  1.2827,  1.2820,  1.2802,  1.2781,  1.2784,  1.2773,
          1.2773,  1.3451,  1.3474,  1.3465,  1.3496,  1.3443,  1.2935,  1.3456,
          1.2847,  1.3332,  2.6411,  2.7325,  2.7851,  2.6502,  2.5818,  2.5787,
          2.7091,  2.5736,  2.5736,  1.2801,  1.3076,  1.3172,  1.3202,  1.2808,
          1.3186,  1.3214,  1.3171,  1.3175,  1.7428,  1.7539,  1.7474,  1.6846,
          1.7518,  1.7508,  1.7443,  1.7287,  1.6836,  1.6047,  1.5877,  1.5840,
          1.5777,  1.5816,  1.5828,  1.5967,  1.5731,  1.5760],
        [ 1.2858,  1.2886,  1.2910,  1.2904,  1.2885,  1.2863,  1.2868,  1.2855,
          1.2855,  1.3531,  1.3554,  1.3545,  1.3381,  1.3523,  1.2807,  1.3536,
          1.3498,  1.2790,  1.3065,  1.2869,  1.3078,  1.3076,  1.3040,  1.3035,
          1.3041,  1.3026,  1.3026,  2.8096,  2.7459,  2.5291,  2.5965,  2.8080,
          2.5377,  2.7262,  2.5830,  2.5308,  1.7478,  1.7592,  1.7256,  1.7461,
          1.7571,  1.7561,  1.7224,  1.7112,  1.7451,  1.6110,  1.5934,  1.5174,
          1.5291,  1.6073,  1.5883,  1.6225,  1.5244,  1.5814],
        [ 1.8832,  1.4840,  0.6356,  0.9623,  1.3783,  1.8135,  1.6864,  1.9191,
          1.9191,  1.7339,  1.3626,  1.5652,  0.9668,  1.7727,  0.1611,  1.6704,
          1.9414,  0.8875,  1.3855,  1.0399,  0.7945,  1.1944,  1.7550,  1.8213,
          1.5811,  1.9275,  1.9275,  0.8882,  0.8882,  1.9003,  1.6944,  0.9016,
          1.8410,  1.2999,  1.9491,  1.8646, -0.1126, -0.3579, -0.4012, -0.1559,
          0.0961,  0.1903, -0.2399, 16.0604,  4.3445,  0.2514,  0.6156,  0.6427,
          0.7520,  0.4039,  0.7523, -0.0393,  0.7844,  0.8483],
        [ 1.3362,  1.3735,  1.4153,  1.4054,  1.3804,  1.3434,  1.3137,  1.3325,
          1.3325,  1.3068,  1.4276,  1.3258,  1.4565,  1.3848,  1.4819,  1.3137,
          1.3604,  1.3708,  1.3935,  1.3723,  1.4264,  1.4072,  1.3603,  1.3534,
          1.2546,  1.3419,  1.3419,  1.3931,  1.4391,  1.3570,  1.1483,  1.3499,
          1.2460,  1.4132,  1.2348,  1.3612,  0.3431,  0.2670,  0.3810,  0.3506,
          0.1424,  0.0961,  0.3667,  0.1431, -0.0669,  3.3613,  2.2817,  3.3352,
          2.6057,  1.8324,  1.4297,  2.8345,  3.1661,  1.3942]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 282 : 174.89915933859584
Test loss for epoch 282 : 175.03057783361993
Test Precision for epoch 282 : 0.26153846153846155
Test Recall for epoch 282 : 0.26153846153846155
Test F1 for epoch 282 : 0.26153846153846155


theta for epoch 283 : tensor([[ 2.5902,  2.6090,  2.6460,  2.7541,  2.7353,  2.5934,  2.7223,  2.5885,
          2.5885,  1.3395,  1.3418,  1.3409,  1.3439,  1.3387,  1.3459,  1.3400,
          1.3370,  1.2992,  1.2925,  1.2503,  1.2511,  1.2935,  1.2901,  1.2896,
          1.2918,  1.2888,  1.2888,  1.2733,  1.3177,  1.3116,  1.3146,  1.3177,
          1.3130,  1.3157,  1.2677,  1.3119,  1.7392,  1.7501,  1.7437,  1.7397,
          1.7480,  1.6877,  1.7406,  1.7258,  1.7388,  1.6005,  1.5837,  1.5801,
          1.5740,  1.5970,  1.5789,  1.6115,  1.5706,  1.5722],
        [ 1.2960,  1.2989,  1.2733,  1.2746,  1.2998,  1.2969,  1.2977,  1.2961,
          1.2961,  2.5673,  2.5753,  2.4964,  2.7030,  2.4871,  2.9313,  2.5655,
          2.6652,  2.9042,  1.2869,  1.2920,  1.2454,  1.2862,  1.3144,  1.3138,
          1.3137,  1.3129,  1.3129,  1.3151,  1.2649,  1.3357,  1.3389,  1.2879,
          1.3372,  1.3402,  1.3098,  1.3360,  1.7538,  1.7658,  1.7220,  1.7530,
          1.7635,  1.7648,  1.7186,  1.6942,  1.7524,  1.5631,  1.6007,  1.5968,
          1.5901,  1.5232,  1.5955,  1.5392,  1.5864,  1.5882],
        [ 1.2775,  1.2802,  1.2826,  1.2819,  1.2801,  1.2780,  1.2784,  1.2772,
          1.2772,  1.3450,  1.3473,  1.3464,  1.3495,  1.3442,  1.2933,  1.3455,
          1.2845,  1.3331,  2.6423,  2.7342,  2.7867,  2.6514,  2.5830,  2.5799,
          2.7108,  2.5748,  2.5748,  1.2799,  1.3075,  1.3171,  1.3201,  1.2806,
          1.3185,  1.3213,  1.3170,  1.3174,  1.7427,  1.7538,  1.7473,  1.6843,
          1.7517,  1.7506,  1.7442,  1.7286,  1.6833,  1.6048,  1.5878,  1.5841,
          1.5778,  1.5817,  1.5829,  1.5968,  1.5732,  1.5761],
        [ 1.2856,  1.2884,  1.2908,  1.2903,  1.2884,  1.2862,  1.2866,  1.2853,
          1.2853,  1.3529,  1.3553,  1.3543,  1.3379,  1.3521,  1.2809,  1.3535,
          1.3496,  1.2792,  1.3062,  1.2866,  1.3075,  1.3073,  1.3037,  1.3032,
          1.3038,  1.3023,  1.3023,  2.8106,  2.7468,  2.5310,  2.5973,  2.8091,
          2.5396,  2.7272,  2.5850,  2.5327,  1.7476,  1.7591,  1.7254,  1.7459,
          1.7569,  1.7559,  1.7222,  1.7116,  1.7449,  1.6110,  1.5934,  1.5179,
          1.5292,  1.6073,  1.5884,  1.6225,  1.5244,  1.5814],
        [ 1.8839,  1.4848,  0.6363,  0.9629,  1.3791,  1.8142,  1.6871,  1.9197,
          1.9197,  1.7343,  1.3632,  1.5659,  0.9677,  1.7734,  0.1618,  1.6708,
          1.9422,  0.8880,  1.3863,  1.0409,  0.7955,  1.1952,  1.7557,  1.8220,
          1.5820,  1.9282,  1.9282,  0.8891,  0.8889,  1.9010,  1.6949,  0.9023,
          1.8417,  1.3005,  1.9498,  1.8654, -0.1138, -0.3590, -0.4023, -0.1571,
          0.0948,  0.1889, -0.2410, 16.1032,  4.3181,  0.2524,  0.6165,  0.6434,
          0.7529,  0.4049,  0.7532, -0.0383,  0.7853,  0.8492],
        [ 1.3358,  1.3730,  1.4147,  1.4049,  1.3799,  1.3429,  1.3133,  1.3320,
          1.3320,  1.3064,  1.4271,  1.3252,  1.4559,  1.3843,  1.4814,  1.3132,
          1.3598,  1.3702,  1.3930,  1.3715,  1.4258,  1.4067,  1.3597,  1.3528,
          1.2539,  1.3413,  1.3413,  1.3926,  1.4386,  1.3565,  1.1478,  1.3494,
          1.2455,  1.4128,  1.2343,  1.3607,  0.3425,  0.2664,  0.3804,  0.3500,
          0.1418,  0.0955,  0.3661,  0.1424, -0.0676,  3.3654,  2.2828,  3.3390,
          2.6074,  1.8332,  1.4304,  2.8362,  3.1706,  1.3949]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 283 : 174.88891812000952
Test loss for epoch 283 : 175.02264093133556
Test Precision for epoch 283 : 0.26153846153846155
Test Recall for epoch 283 : 0.26153846153846155
Test F1 for epoch 283 : 0.26153846153846155


theta for epoch 284 : tensor([[ 2.5914,  2.6103,  2.6472,  2.7555,  2.7367,  2.5947,  2.7238,  2.5898,
          2.5898,  1.3394,  1.3417,  1.3408,  1.3438,  1.3386,  1.3458,  1.3399,
          1.3369,  1.2991,  1.2925,  1.2503,  1.2510,  1.2935,  1.2900,  1.2895,
          1.2918,  1.2887,  1.2887,  1.2732,  1.3176,  1.3115,  1.3145,  1.3176,
          1.3129,  1.3156,  1.2676,  1.3118,  1.7392,  1.7501,  1.7438,  1.7398,
          1.7481,  1.6877,  1.7407,  1.7258,  1.7388,  1.6003,  1.5835,  1.5799,
          1.5738,  1.5968,  1.5787,  1.6113,  1.5704,  1.5720],
        [ 1.2958,  1.2986,  1.2736,  1.2749,  1.2996,  1.2967,  1.2974,  1.2958,
          1.2958,  2.5680,  2.5763,  2.4982,  2.7052,  2.4887,  2.9321,  2.5663,
          2.6674,  2.9050,  1.2868,  1.2919,  1.2453,  1.2861,  1.3142,  1.3137,
          1.3136,  1.3128,  1.3128,  1.3149,  1.2648,  1.3355,  1.3388,  1.2882,
          1.3370,  1.3400,  1.3096,  1.3358,  1.7538,  1.7658,  1.7219,  1.7530,
          1.7635,  1.7648,  1.7186,  1.6950,  1.7524,  1.5628,  1.6004,  1.5965,
          1.5898,  1.5230,  1.5952,  1.5390,  1.5861,  1.5879],
        [ 1.2773,  1.2800,  1.2824,  1.2818,  1.2799,  1.2778,  1.2782,  1.2770,
          1.2770,  1.3449,  1.3472,  1.3463,  1.3493,  1.3440,  1.2931,  1.3454,
          1.2843,  1.3330,  2.6436,  2.7359,  2.7885,  2.6527,  2.5842,  2.5812,
          2.7125,  2.5760,  2.5760,  1.2796,  1.3074,  1.3170,  1.3200,  1.2803,
          1.3184,  1.3212,  1.3169,  1.3173,  1.7427,  1.7539,  1.7474,  1.6842,
          1.7518,  1.7507,  1.7442,  1.7287,  1.6832,  1.6046,  1.5876,  1.5839,
          1.5776,  1.5815,  1.5827,  1.5966,  1.5729,  1.5759],
        [ 1.2854,  1.2882,  1.2906,  1.2901,  1.2881,  1.2859,  1.2864,  1.2851,
          1.2851,  1.3528,  1.3551,  1.3542,  1.3377,  1.3519,  1.2811,  1.3533,
          1.3494,  1.2795,  1.3061,  1.2865,  1.3074,  1.3072,  1.3036,  1.3031,
          1.3036,  1.3022,  1.3022,  2.8117,  2.7477,  2.5328,  2.5981,  2.8101,
          2.5414,  2.7280,  2.5869,  2.5345,  1.7476,  1.7591,  1.7255,  1.7459,
          1.7569,  1.7559,  1.7222,  1.7122,  1.7448,  1.6108,  1.5932,  1.5182,
          1.5289,  1.6071,  1.5881,  1.6223,  1.5241,  1.5812],
        [ 1.8838,  1.4846,  0.6360,  0.9626,  1.3789,  1.8141,  1.6870,  1.9196,
          1.9196,  1.7338,  1.3628,  1.5658,  0.9675,  1.7732,  0.1613,  1.6704,
          1.9421,  0.8873,  1.3861,  1.0409,  0.7954,  1.1950,  1.7556,  1.8219,
          1.5820,  1.9281,  1.9281,  0.8888,  0.8885,  1.9009,  1.6945,  0.9018,
          1.8416,  1.3001,  1.9497,  1.8652, -0.1140, -0.3591, -0.4024, -0.1574,
          0.0945,  0.1885, -0.2412, 16.1470,  4.2928,  0.2522,  0.6162,  0.6430,
          0.7526,  0.4046,  0.7529, -0.0385,  0.7850,  0.8489],
        [ 1.3363,  1.3735,  1.4151,  1.4054,  1.3804,  1.3434,  1.3137,  1.3325,
          1.3325,  1.3070,  1.4277,  1.3258,  1.4565,  1.3849,  1.4820,  1.3139,
          1.3604,  1.3709,  1.3936,  1.3720,  1.4264,  1.4073,  1.3604,  1.3534,
          1.2544,  1.3419,  1.3419,  1.3930,  1.4391,  1.3571,  1.1483,  1.3498,
          1.2460,  1.4133,  1.2349,  1.3612,  0.3431,  0.2670,  0.3809,  0.3506,
          0.1424,  0.0960,  0.3667,  0.1429, -0.0670,  3.3681,  2.2827,  3.3414,
          2.6078,  1.8327,  1.4298,  2.8365,  3.1738,  1.3943]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 284 : 174.87865921847313
Test loss for epoch 284 : 175.0167035074793
Test Precision for epoch 284 : 0.26153846153846155
Test Recall for epoch 284 : 0.26153846153846155
Test F1 for epoch 284 : 0.26153846153846155


theta for epoch 285 : tensor([[ 2.5926,  2.6115,  2.6485,  2.7569,  2.7381,  2.5959,  2.7252,  2.5910,
          2.5910,  1.3393,  1.3415,  1.3407,  1.3437,  1.3385,  1.3457,  1.3398,
          1.3368,  1.2990,  1.2923,  1.2501,  1.2508,  1.2933,  1.2898,  1.2893,
          1.2916,  1.2885,  1.2885,  1.2731,  1.3175,  1.3114,  1.3144,  1.3176,
          1.3128,  1.3155,  1.2675,  1.3117,  1.7392,  1.7501,  1.7437,  1.7397,
          1.7480,  1.6877,  1.7406,  1.7258,  1.7388,  1.6005,  1.5837,  1.5801,
          1.5740,  1.5970,  1.5789,  1.6115,  1.5706,  1.5722],
        [ 1.2956,  1.2984,  1.2739,  1.2751,  1.2993,  1.2964,  1.2972,  1.2956,
          1.2956,  2.5687,  2.5772,  2.5000,  2.7074,  2.4904,  2.9329,  2.5672,
          2.6697,  2.9059,  1.2865,  1.2916,  1.2450,  1.2859,  1.3139,  1.3134,
          1.3134,  1.3125,  1.3125,  1.3147,  1.2647,  1.3353,  1.3386,  1.2885,
          1.3368,  1.3398,  1.3094,  1.3356,  1.7537,  1.7656,  1.7218,  1.7529,
          1.7634,  1.7646,  1.7184,  1.6956,  1.7523,  1.5629,  1.6006,  1.5966,
          1.5899,  1.5231,  1.5953,  1.5391,  1.5862,  1.5880],
        [ 1.2771,  1.2799,  1.2822,  1.2816,  1.2797,  1.2776,  1.2780,  1.2769,
          1.2769,  1.3448,  1.3470,  1.3461,  1.3492,  1.3439,  1.2929,  1.3453,
          1.2841,  1.3328,  2.6448,  2.7375,  2.7900,  2.6538,  2.5853,  2.5822,
          2.7141,  2.5771,  2.5771,  1.2794,  1.3073,  1.3169,  1.3199,  1.2801,
          1.3183,  1.3211,  1.3168,  1.3172,  1.7427,  1.7538,  1.7473,  1.6840,
          1.7517,  1.7506,  1.7442,  1.7286,  1.6830,  1.6047,  1.5878,  1.5841,
          1.5778,  1.5817,  1.5828,  1.5968,  1.5730,  1.5761],
        [ 1.2852,  1.2880,  1.2903,  1.2898,  1.2879,  1.2857,  1.2862,  1.2849,
          1.2849,  1.3526,  1.3549,  1.3540,  1.3375,  1.3517,  1.2813,  1.3531,
          1.3493,  1.2797,  1.3059,  1.2862,  1.3072,  1.3069,  1.3034,  1.3028,
          1.3034,  1.3020,  1.3020,  2.8126,  2.7486,  2.5346,  2.5989,  2.8111,
          2.5432,  2.7289,  2.5887,  2.5363,  1.7475,  1.7589,  1.7253,  1.7457,
          1.7568,  1.7557,  1.7221,  1.7126,  1.7447,  1.6109,  1.5933,  1.5188,
          1.5291,  1.6072,  1.5883,  1.6224,  1.5242,  1.5813],
        [ 1.8843,  1.4852,  0.6366,  0.9631,  1.3796,  1.8147,  1.6876,  1.9202,
          1.9202,  1.7341,  1.3633,  1.5664,  0.9683,  1.7738,  0.1619,  1.6707,
          1.9428,  0.8878,  1.3869,  1.0418,  0.7962,  1.1957,  1.7563,  1.8226,
          1.5828,  1.9287,  1.9287,  0.8896,  0.8891,  1.9015,  1.6950,  0.9024,
          1.8422,  1.3007,  1.9503,  1.8659, -0.1151, -0.3601, -0.4034, -0.1586,
          0.0933,  0.1872, -0.2422, 16.1899,  4.2663,  0.2530,  0.6170,  0.6437,
          0.7534,  0.4055,  0.7537, -0.0376,  0.7858,  0.8497],
        [ 1.3358,  1.3730,  1.4146,  1.4049,  1.3799,  1.3429,  1.3133,  1.3320,
          1.3320,  1.3066,  1.4273,  1.3253,  1.4560,  1.3844,  1.4814,  1.3134,
          1.3599,  1.3704,  1.3931,  1.3713,  1.4259,  1.4068,  1.3598,  1.3529,
          1.2537,  1.3414,  1.3414,  1.3925,  1.4387,  1.3566,  1.1478,  1.3493,
          1.2455,  1.4129,  1.2344,  1.3608,  0.3426,  0.2664,  0.3804,  0.3500,
          0.1419,  0.0954,  0.3662,  0.1423, -0.0676,  3.3721,  2.2839,  3.3451,
          2.6094,  1.8334,  1.4304,  2.8381,  3.1782,  1.3950]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 285 : 174.86839387102023
Test loss for epoch 285 : 175.00890797336032
Test Precision for epoch 285 : 0.26153846153846155
Test Recall for epoch 285 : 0.26153846153846155
Test F1 for epoch 285 : 0.26153846153846155


theta for epoch 286 : tensor([[ 2.5940,  2.6129,  2.6499,  2.7584,  2.7397,  2.5973,  2.7267,  2.5924,
          2.5924,  1.3392,  1.3414,  1.3405,  1.3436,  1.3384,  1.3456,  1.3397,
          1.3367,  1.2988,  1.2922,  1.2500,  1.2508,  1.2932,  1.2898,  1.2893,
          1.2915,  1.2885,  1.2885,  1.2730,  1.3174,  1.3113,  1.3143,  1.3175,
          1.3127,  1.3155,  1.2674,  1.3116,  1.7392,  1.7501,  1.7437,  1.7398,
          1.7480,  1.6877,  1.7406,  1.7258,  1.7388,  1.6000,  1.5832,  1.5796,
          1.5735,  1.5965,  1.5784,  1.6110,  1.5701,  1.5718],
        [ 1.2955,  1.2983,  1.2744,  1.2754,  1.2992,  1.2963,  1.2971,  1.2955,
          1.2955,  2.5694,  2.5782,  2.5019,  2.7096,  2.4921,  2.9338,  2.5680,
          2.6719,  2.9067,  1.2864,  1.2915,  1.2449,  1.2859,  1.3139,  1.3133,
          1.3134,  1.3124,  1.3124,  1.3146,  1.2647,  1.3351,  1.3384,  1.2888,
          1.3367,  1.3397,  1.3093,  1.3355,  1.7536,  1.7656,  1.7218,  1.7529,
          1.7633,  1.7646,  1.7184,  1.6964,  1.7523,  1.5624,  1.6000,  1.5961,
          1.5894,  1.5226,  1.5948,  1.5386,  1.5857,  1.5875],
        [ 1.2771,  1.2798,  1.2821,  1.2815,  1.2796,  1.2776,  1.2779,  1.2768,
          1.2768,  1.3447,  1.3470,  1.3461,  1.3491,  1.3438,  1.2928,  1.3452,
          1.2839,  1.3328,  2.6460,  2.7392,  2.7917,  2.6551,  2.5866,  2.5835,
          2.7158,  2.5784,  2.5784,  1.2792,  1.3072,  1.3168,  1.3199,  1.2799,
          1.3182,  1.3210,  1.3167,  1.3171,  1.7427,  1.7538,  1.7473,  1.6839,
          1.7517,  1.7506,  1.7442,  1.7287,  1.6829,  1.6043,  1.5873,  1.5836,
          1.5774,  1.5813,  1.5824,  1.5963,  1.5725,  1.5756],
        [ 1.2851,  1.2879,  1.2902,  1.2897,  1.2878,  1.2856,  1.2861,  1.2848,
          1.2848,  1.3525,  1.3548,  1.3539,  1.3374,  1.3516,  1.2816,  1.3530,
          1.3492,  1.2800,  1.3058,  1.2861,  1.3071,  1.3069,  1.3033,  1.3028,
          1.3033,  1.3019,  1.3019,  2.8136,  2.7495,  2.5364,  2.5997,  2.8121,
          2.5451,  2.7298,  2.5906,  2.5382,  1.7475,  1.7589,  1.7253,  1.7457,
          1.7568,  1.7557,  1.7221,  1.7132,  1.7446,  1.6104,  1.5928,  1.5188,
          1.5286,  1.6067,  1.5878,  1.6219,  1.5236,  1.5808],
        [ 1.8843,  1.4852,  0.6365,  0.9629,  1.3796,  1.8147,  1.6876,  1.9202,
          1.9202,  1.7336,  1.3630,  1.5664,  0.9682,  1.7737,  0.1616,  1.6703,
          1.9429,  0.8872,  1.3868,  1.0419,  0.7962,  1.1956,  1.7563,  1.8226,
          1.5829,  1.9287,  1.9287,  0.8895,  0.8889,  1.9015,  1.6948,  0.9020,
          1.8422,  1.3005,  1.9503,  1.8658, -0.1154, -0.3603, -0.4036, -0.1590,
          0.0929,  0.1867, -0.2425, 16.2336,  4.2407,  0.2529,  0.6168,  0.6433,
          0.7531,  0.4053,  0.7535, -0.0377,  0.7856,  0.8494],
        [ 1.3362,  1.3734,  1.4149,  1.4053,  1.3803,  1.3433,  1.3137,  1.3325,
          1.3325,  1.3071,  1.4278,  1.3258,  1.4565,  1.3849,  1.4819,  1.3140,
          1.3604,  1.3709,  1.3936,  1.3717,  1.4264,  1.4073,  1.3604,  1.3534,
          1.2541,  1.3420,  1.3420,  1.3928,  1.4392,  1.3571,  1.1483,  1.3497,
          1.2460,  1.4134,  1.2349,  1.3612,  0.3431,  0.2669,  0.3808,  0.3505,
          0.1423,  0.0959,  0.3666,  0.1427, -0.0672,  3.3749,  2.2838,  3.3476,
          2.6099,  1.8330,  1.4300,  2.8385,  3.1814,  1.3945]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 286 : 174.85812341648787
Test loss for epoch 286 : 175.00278102014727
Test Precision for epoch 286 : 0.26153846153846155
Test Recall for epoch 286 : 0.26153846153846155
Test F1 for epoch 286 : 0.26153846153846155


theta for epoch 287 : tensor([[ 2.5953,  2.6142,  2.6512,  2.7599,  2.7412,  2.5986,  2.7282,  2.5937,
          2.5937,  1.3391,  1.3413,  1.3404,  1.3434,  1.3383,  1.3455,  1.3396,
          1.3366,  1.2987,  1.2920,  1.2499,  1.2506,  1.2930,  1.2896,  1.2891,
          1.2913,  1.2883,  1.2883,  1.2729,  1.3173,  1.3112,  1.3142,  1.3174,
          1.3126,  1.3154,  1.2673,  1.3115,  1.7391,  1.7500,  1.7436,  1.7397,
          1.7479,  1.6876,  1.7405,  1.7257,  1.7387,  1.6000,  1.5832,  1.5796,
          1.5735,  1.5965,  1.5784,  1.6110,  1.5701,  1.5718],
        [ 1.2953,  1.2981,  1.2748,  1.2758,  1.2990,  1.2961,  1.2969,  1.2953,
          1.2953,  2.5701,  2.5791,  2.5037,  2.7118,  2.4938,  2.9346,  2.5689,
          2.6742,  2.9075,  1.2862,  1.2912,  1.2447,  1.2857,  1.3136,  1.3131,
          1.3132,  1.3122,  1.3122,  1.3144,  1.2646,  1.3350,  1.3383,  1.2892,
          1.3365,  1.3395,  1.3091,  1.3353,  1.7535,  1.7654,  1.7216,  1.7527,
          1.7632,  1.7645,  1.7182,  1.6971,  1.7521,  1.5624,  1.6000,  1.5960,
          1.5893,  1.5225,  1.5947,  1.5385,  1.5856,  1.5875],
        [ 1.2770,  1.2797,  1.2820,  1.2814,  1.2796,  1.2775,  1.2778,  1.2767,
          1.2767,  1.3446,  1.3469,  1.3460,  1.3490,  1.3438,  1.2926,  1.3451,
          1.2838,  1.3327,  2.6472,  2.7408,  2.7933,  2.6562,  2.5877,  2.5846,
          2.7173,  2.5795,  2.5795,  1.2791,  1.3071,  1.3167,  1.3198,  1.2797,
          1.3181,  1.3209,  1.3166,  1.3170,  1.7426,  1.7537,  1.7472,  1.6837,
          1.7516,  1.7504,  1.7441,  1.7286,  1.6827,  1.6043,  1.5873,  1.5837,
          1.5774,  1.5813,  1.5824,  1.5963,  1.5725,  1.5756],
        [ 1.2849,  1.2877,  1.2900,  1.2896,  1.2877,  1.2855,  1.2859,  1.2846,
          1.2846,  1.3524,  1.3547,  1.3537,  1.3373,  1.3515,  1.2818,  1.3529,
          1.3490,  1.2802,  1.3056,  1.2859,  1.3069,  1.3067,  1.3031,  1.3026,
          1.3030,  1.3017,  1.3017,  2.8147,  2.7504,  2.5383,  2.6005,  2.8131,
          2.5469,  2.7307,  2.5925,  2.5400,  1.7473,  1.7588,  1.7252,  1.7455,
          1.7566,  1.7555,  1.7220,  1.7136,  1.7444,  1.6103,  1.5928,  1.5192,
          1.5285,  1.6067,  1.5877,  1.6218,  1.5236,  1.5808],
        [ 1.8849,  1.4859,  0.6370,  0.9633,  1.3802,  1.8153,  1.6882,  1.9208,
          1.9208,  1.7339,  1.3634,  1.5670,  0.9689,  1.7742,  0.1621,  1.6707,
          1.9435,  0.8876,  1.3875,  1.0427,  0.7970,  1.1963,  1.7569,  1.8232,
          1.5837,  1.9293,  1.9293,  0.8902,  0.8894,  1.9021,  1.6952,  0.9025,
          1.8428,  1.3010,  1.9509,  1.8665, -0.1164, -0.3612, -0.4045, -0.1600,
          0.0917,  0.1854, -0.2435, 16.2766,  4.2141,  0.2537,  0.6175,  0.6439,
          0.7538,  0.4061,  0.7542, -0.0368,  0.7863,  0.8501],
        [ 1.3359,  1.3731,  1.4144,  1.4050,  1.3800,  1.3430,  1.3134,  1.3321,
          1.3321,  1.3068,  1.4274,  1.3254,  1.4561,  1.3845,  1.4815,  1.3136,
          1.3600,  1.3705,  1.3932,  1.3711,  1.4259,  1.4069,  1.3600,  1.3530,
          1.2535,  1.3415,  1.3415,  1.3924,  1.4388,  1.3567,  1.1479,  1.3493,
          1.2456,  1.4130,  1.2345,  1.3609,  0.3426,  0.2665,  0.3804,  0.3500,
          0.1419,  0.0954,  0.3662,  0.1421, -0.0677,  3.3788,  2.2848,  3.3512,
          2.6114,  1.8336,  1.4305,  2.8400,  3.1857,  1.3950]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 287 : 174.84785658192214
Test loss for epoch 287 : 174.995145380145
Test Precision for epoch 287 : 0.26153846153846155
Test Recall for epoch 287 : 0.26153846153846155
Test F1 for epoch 287 : 0.26153846153846155


theta for epoch 288 : tensor([[ 2.5966,  2.6155,  2.6524,  2.7613,  2.7425,  2.5998,  2.7296,  2.5949,
          2.5949,  1.3390,  1.3412,  1.3403,  1.3434,  1.3382,  1.3454,  1.3395,
          1.3365,  1.2986,  1.2920,  1.2498,  1.2506,  1.2930,  1.2896,  1.2891,
          1.2913,  1.2883,  1.2883,  1.2728,  1.3172,  1.3111,  1.3141,  1.3172,
          1.3125,  1.3153,  1.2672,  1.3114,  1.7391,  1.7500,  1.7436,  1.7397,
          1.7480,  1.6876,  1.7405,  1.7257,  1.7387,  1.5998,  1.5831,  1.5795,
          1.5733,  1.5963,  1.5783,  1.6108,  1.5699,  1.5716],
        [ 1.2951,  1.2979,  1.2751,  1.2760,  1.2988,  1.2959,  1.2967,  1.2951,
          1.2951,  2.5707,  2.5800,  2.5055,  2.7140,  2.4954,  2.9354,  2.5696,
          2.6764,  2.9083,  1.2861,  1.2911,  1.2446,  1.2857,  1.3135,  1.3130,
          1.3132,  1.3121,  1.3121,  1.3142,  1.2645,  1.3348,  1.3381,  1.2895,
          1.3363,  1.3393,  1.3089,  1.3351,  1.7534,  1.7654,  1.7215,  1.7527,
          1.7631,  1.7644,  1.7181,  1.6978,  1.7521,  1.5622,  1.5998,  1.5958,
          1.5891,  1.5224,  1.5945,  1.5383,  1.5854,  1.5873],
        [ 1.2768,  1.2796,  1.2818,  1.2813,  1.2794,  1.2773,  1.2777,  1.2765,
          1.2765,  1.3445,  1.3468,  1.3459,  1.3489,  1.3437,  1.2925,  1.3450,
          1.2836,  1.3326,  2.6484,  2.7425,  2.7949,  2.6575,  2.5889,  2.5858,
          2.7190,  2.5807,  2.5807,  1.2788,  1.3070,  1.3166,  1.3197,  1.2795,
          1.3180,  1.3208,  1.3165,  1.3169,  1.7426,  1.7538,  1.7473,  1.6835,
          1.7517,  1.7504,  1.7441,  1.7286,  1.6825,  1.6041,  1.5872,  1.5835,
          1.5772,  1.5812,  1.5823,  1.5962,  1.5723,  1.5755],
        [ 1.2847,  1.2875,  1.2898,  1.2894,  1.2874,  1.2852,  1.2857,  1.2844,
          1.2844,  1.3522,  1.3545,  1.3536,  1.3371,  1.3513,  1.2821,  1.3527,
          1.3489,  1.2804,  1.3055,  1.2858,  1.3068,  1.3065,  1.3030,  1.3024,
          1.3029,  1.3016,  1.3016,  2.8157,  2.7513,  2.5401,  2.6013,  2.8141,
          2.5487,  2.7316,  2.5944,  2.5418,  1.7473,  1.7587,  1.7252,  1.7454,
          1.7566,  1.7554,  1.7219,  1.7141,  1.7444,  1.6101,  1.5926,  1.5194,
          1.5284,  1.6065,  1.5875,  1.6217,  1.5233,  1.5806],
        [ 1.8849,  1.4858,  0.6369,  0.9631,  1.3802,  1.8153,  1.6882,  1.9208,
          1.9208,  1.7335,  1.3631,  1.5670,  0.9689,  1.7742,  0.1619,  1.6703,
          1.9436,  0.8871,  1.3875,  1.0429,  0.7970,  1.1962,  1.7569,  1.8232,
          1.5839,  1.9293,  1.9293,  0.8901,  0.8892,  1.9021,  1.6950,  0.9022,
          1.8428,  1.3008,  1.9509,  1.8664, -0.1167, -0.3614, -0.4048, -0.1605,
          0.0913,  0.1849, -0.2438, 16.3203,  4.1882,  0.2536,  0.6174,  0.6437,
          0.7537,  0.4060,  0.7541, -0.0368,  0.7862,  0.8500],
        [ 1.3362,  1.3734,  1.4146,  1.4053,  1.3803,  1.3433,  1.3137,  1.3325,
          1.3325,  1.3072,  1.4279,  1.3258,  1.4565,  1.3849,  1.4819,  1.3141,
          1.3604,  1.3709,  1.3936,  1.3714,  1.4264,  1.4073,  1.3604,  1.3535,
          1.2538,  1.3420,  1.3420,  1.3927,  1.4392,  1.3571,  1.1483,  1.3495,
          1.2460,  1.4134,  1.2349,  1.3612,  0.3430,  0.2669,  0.3807,  0.3504,
          0.1423,  0.0958,  0.3666,  0.1424, -0.0673,  3.3817,  2.2849,  3.3538,
          2.6120,  1.8333,  1.4301,  2.8405,  3.1890,  1.3946]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 288 : 174.83758973697115
Test loss for epoch 288 : 174.98891248725232
Test Precision for epoch 288 : 0.26153846153846155
Test Recall for epoch 288 : 0.26153846153846155
Test F1 for epoch 288 : 0.26153846153846155


theta for epoch 289 : tensor([[ 2.5978,  2.6167,  2.6536,  2.7628,  2.7440,  2.6011,  2.7310,  2.5962,
          2.5962,  1.3389,  1.3411,  1.3402,  1.3432,  1.3380,  1.3453,  1.3394,
          1.3364,  1.2985,  1.2918,  1.2496,  1.2504,  1.2928,  1.2894,  1.2889,
          1.2911,  1.2881,  1.2881,  1.2726,  1.3171,  1.3110,  1.3140,  1.3171,
          1.3124,  1.3151,  1.2671,  1.3113,  1.7390,  1.7499,  1.7436,  1.7396,
          1.7479,  1.6875,  1.7405,  1.7256,  1.7386,  1.5999,  1.5832,  1.5796,
          1.5735,  1.5964,  1.5784,  1.6109,  1.5700,  1.5717],
        [ 1.2949,  1.2977,  1.2754,  1.2763,  1.2986,  1.2957,  1.2965,  1.2948,
          1.2948,  2.5713,  2.5809,  2.5074,  2.7162,  2.4971,  2.9362,  2.5705,
          2.6787,  2.9091,  1.2858,  1.2909,  1.2443,  1.2855,  1.3133,  1.3127,
          1.3129,  1.3118,  1.3118,  1.3140,  1.2644,  1.3346,  1.3379,  1.2898,
          1.3361,  1.3391,  1.3087,  1.3349,  1.7533,  1.7652,  1.7214,  1.7526,
          1.7630,  1.7643,  1.7180,  1.6985,  1.7519,  1.5622,  1.5998,  1.5959,
          1.5892,  1.5224,  1.5946,  1.5384,  1.5855,  1.5873],
        [ 1.2767,  1.2794,  1.2816,  1.2811,  1.2792,  1.2772,  1.2775,  1.2764,
          1.2764,  1.3444,  1.3467,  1.3458,  1.3488,  1.3435,  1.2923,  1.3449,
          1.2834,  1.3325,  2.6495,  2.7441,  2.7965,  2.6586,  2.5900,  2.5869,
          2.7206,  2.5818,  2.5818,  1.2786,  1.3069,  1.3165,  1.3196,  1.2793,
          1.3179,  1.3207,  1.3164,  1.3168,  1.7426,  1.7537,  1.7472,  1.6833,
          1.7516,  1.7503,  1.7441,  1.7285,  1.6823,  1.6043,  1.5873,  1.5837,
          1.5774,  1.5813,  1.5824,  1.5963,  1.5724,  1.5756],
        [ 1.2845,  1.2873,  1.2895,  1.2892,  1.2872,  1.2851,  1.2855,  1.2842,
          1.2842,  1.3520,  1.3544,  1.3534,  1.3370,  1.3511,  1.2822,  1.3526,
          1.3487,  1.2806,  1.3053,  1.2855,  1.3065,  1.3063,  1.3027,  1.3022,
          1.3026,  1.3014,  1.3014,  2.8167,  2.7521,  2.5419,  2.6021,  2.8151,
          2.5505,  2.7325,  2.5963,  2.5436,  1.7472,  1.7586,  1.7250,  1.7452,
          1.7565,  1.7552,  1.7218,  1.7145,  1.7442,  1.6102,  1.5926,  1.5200,
          1.5284,  1.6065,  1.5876,  1.6217,  1.5234,  1.5806],
        [ 1.8853,  1.4864,  0.6374,  0.9635,  1.3808,  1.8157,  1.6886,  1.9212,
          1.9212,  1.7337,  1.3635,  1.5675,  0.9696,  1.7747,  0.1623,  1.6705,
          1.9441,  0.8874,  1.3880,  1.0436,  0.7977,  1.1968,  1.7574,  1.8237,
          1.5845,  1.9298,  1.9298,  0.8907,  0.8896,  1.9026,  1.6953,  0.9026,
          1.8433,  1.3012,  1.9514,  1.8670, -0.1176, -0.3623, -0.4056, -0.1615,
          0.0903,  0.1837, -0.2446, 16.3634,  4.1616,  0.2543,  0.6180,  0.6442,
          0.7543,  0.4067,  0.7548, -0.0361,  0.7869,  0.8507],
        [ 1.3359,  1.3731,  1.4143,  1.4050,  1.3800,  1.3430,  1.3134,  1.3322,
          1.3322,  1.3070,  1.4276,  1.3255,  1.4561,  1.3846,  1.4816,  1.3138,
          1.3601,  1.3706,  1.3933,  1.3709,  1.4260,  1.4070,  1.3601,  1.3531,
          1.2533,  1.3417,  1.3417,  1.3923,  1.4389,  1.3568,  1.1480,  1.3492,
          1.2457,  1.4132,  1.2346,  1.3610,  0.3427,  0.2665,  0.3804,  0.3501,
          0.1419,  0.0954,  0.3663,  0.1420, -0.0677,  3.3854,  2.2858,  3.3572,
          2.6133,  1.8338,  1.4305,  2.8418,  3.1932,  1.3950]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 289 : 174.82732829290714
Test loss for epoch 289 : 174.9814745114722
Test Precision for epoch 289 : 0.26153846153846155
Test Recall for epoch 289 : 0.26153846153846155
Test F1 for epoch 289 : 0.26153846153846155


theta for epoch 290 : tensor([[ 2.5992,  2.6180,  2.6550,  2.7643,  2.7455,  2.6024,  2.7325,  2.5975,
          2.5975,  1.3388,  1.3410,  1.3401,  1.3431,  1.3379,  1.3451,  1.3393,
          1.3362,  1.2984,  1.2917,  1.2495,  1.2503,  1.2927,  1.2893,  1.2888,
          1.2910,  1.2880,  1.2880,  1.2725,  1.3170,  1.3109,  1.3139,  1.3170,
          1.3123,  1.3150,  1.2670,  1.3111,  1.7390,  1.7499,  1.7436,  1.7396,
          1.7479,  1.6875,  1.7405,  1.7256,  1.7386,  1.5996,  1.5829,  1.5793,
          1.5731,  1.5961,  1.5780,  1.6106,  1.5697,  1.5714],
        [ 1.2947,  1.2976,  1.2758,  1.2766,  1.2984,  1.2955,  1.2964,  1.2947,
          1.2947,  2.5720,  2.5817,  2.5092,  2.7184,  2.4988,  2.9370,  2.5713,
          2.6809,  2.9100,  1.2857,  1.2907,  1.2442,  1.2854,  1.3131,  1.3126,
          1.3129,  1.3117,  1.3117,  1.3138,  1.2643,  1.3344,  1.3377,  1.2901,
          1.3360,  1.3389,  1.3085,  1.3348,  1.7532,  1.7651,  1.7213,  1.7525,
          1.7629,  1.7642,  1.7179,  1.6992,  1.7518,  1.5618,  1.5994,  1.5955,
          1.5888,  1.5220,  1.5941,  1.5379,  1.5850,  1.5869],
        [ 1.2766,  1.2793,  1.2815,  1.2811,  1.2792,  1.2771,  1.2775,  1.2763,
          1.2763,  1.3443,  1.3466,  1.3456,  1.3487,  1.3434,  1.2921,  1.3448,
          1.2832,  1.3324,  2.6508,  2.7458,  2.7982,  2.6599,  2.5913,  2.5882,
          2.7223,  2.5831,  2.5831,  1.2784,  1.3068,  1.3164,  1.3195,  1.2791,
          1.3178,  1.3206,  1.3163,  1.3167,  1.7426,  1.7537,  1.7472,  1.6832,
          1.7516,  1.7503,  1.7441,  1.7286,  1.6822,  1.6039,  1.5870,  1.5833,
          1.5770,  1.5810,  1.5821,  1.5960,  1.5720,  1.5753],
        [ 1.2844,  1.2872,  1.2894,  1.2890,  1.2871,  1.2849,  1.2854,  1.2841,
          1.2841,  1.3519,  1.3542,  1.3533,  1.3368,  1.3510,  1.2825,  1.3524,
          1.3485,  1.2808,  1.3051,  1.2853,  1.3064,  1.3062,  1.3026,  1.3021,
          1.3025,  1.3012,  1.3012,  2.8177,  2.7531,  2.5437,  2.6030,  2.8162,
          2.5523,  2.7334,  2.5982,  2.5455,  1.7471,  1.7586,  1.7250,  1.7451,
          1.7564,  1.7551,  1.7218,  1.7150,  1.7441,  1.6098,  1.5923,  1.5200,
          1.5281,  1.6061,  1.5872,  1.6213,  1.5230,  1.5803],
        [ 1.8855,  1.4865,  0.6374,  0.9634,  1.3809,  1.8159,  1.6888,  1.9214,
          1.9214,  1.7334,  1.3633,  1.5676,  0.9697,  1.7747,  0.1622,  1.6703,
          1.9443,  0.8871,  1.3881,  1.0439,  0.7979,  1.1969,  1.7575,  1.8238,
          1.5848,  1.9300,  1.9300,  0.8908,  0.8896,  1.9027,  1.6952,  0.9025,
          1.8434,  1.3011,  1.9515,  1.8671, -0.1181, -0.3626, -0.4060, -0.1620,
          0.0897,  0.1831, -0.2450, 16.4070,  4.1354,  0.2543,  0.6180,  0.6440,
          0.7542,  0.4067,  0.7547, -0.0360,  0.7869,  0.8506],
        [ 1.3362,  1.3734,  1.4144,  1.4053,  1.3803,  1.3433,  1.3137,  1.3325,
          1.3325,  1.3074,  1.4279,  1.3258,  1.4565,  1.3850,  1.4819,  1.3142,
          1.3604,  1.3710,  1.3936,  1.3711,  1.4264,  1.4073,  1.3604,  1.3535,
          1.2535,  1.3420,  1.3420,  1.3925,  1.4392,  1.3571,  1.1483,  1.3494,
          1.2460,  1.4135,  1.2349,  1.3613,  0.3430,  0.2668,  0.3807,  0.3503,
          0.1422,  0.0957,  0.3666,  0.1422, -0.0675,  3.3884,  2.2859,  3.3599,
          2.6140,  1.8336,  1.4302,  2.8424,  3.1966,  1.3948]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 290 : 174.81706889022175
Test loss for epoch 290 : 174.97507729184167
Test Precision for epoch 290 : 0.26153846153846155
Test Recall for epoch 290 : 0.26153846153846155
Test F1 for epoch 290 : 0.26153846153846155


theta for epoch 291 : tensor([[ 2.6004,  2.6193,  2.6563,  2.7657,  2.7469,  2.6037,  2.7340,  2.5988,
          2.5988,  1.3387,  1.3409,  1.3400,  1.3430,  1.3378,  1.3450,  1.3392,
          1.3361,  1.2983,  1.2916,  1.2494,  1.2501,  1.2926,  1.2892,  1.2887,
          1.2909,  1.2879,  1.2879,  1.2724,  1.3169,  1.3108,  1.3138,  1.3169,
          1.3122,  1.3149,  1.2669,  1.3111,  1.7389,  1.7498,  1.7435,  1.7395,
          1.7478,  1.6874,  1.7404,  1.7255,  1.7386,  1.5995,  1.5828,  1.5792,
          1.5730,  1.5960,  1.5780,  1.6105,  1.5696,  1.5713],
        [ 1.2945,  1.2974,  1.2762,  1.2769,  1.2982,  1.2953,  1.2962,  1.2945,
          1.2945,  2.5727,  2.5826,  2.5111,  2.7206,  2.5005,  2.9378,  2.5720,
          2.6832,  2.9108,  1.2855,  1.2905,  1.2439,  1.2852,  1.3129,  1.3124,
          1.3127,  1.3115,  1.3115,  1.3137,  1.2642,  1.3343,  1.3376,  1.2904,
          1.3358,  1.3388,  1.3084,  1.3346,  1.7531,  1.7650,  1.7211,  1.7524,
          1.7628,  1.7641,  1.7178,  1.6999,  1.7517,  1.5617,  1.5993,  1.5954,
          1.5886,  1.5219,  1.5940,  1.5378,  1.5849,  1.5868],
        [ 1.2765,  1.2792,  1.2813,  1.2810,  1.2791,  1.2770,  1.2774,  1.2762,
          1.2762,  1.3442,  1.3465,  1.3456,  1.3486,  1.3433,  1.2920,  1.3447,
          1.2831,  1.3323,  2.6520,  2.7474,  2.7997,  2.6610,  2.5924,  2.5893,
          2.7238,  2.5842,  2.5842,  1.2782,  1.3068,  1.3163,  1.3194,  1.2789,
          1.3177,  1.3205,  1.3162,  1.3166,  1.7425,  1.7536,  1.7471,  1.6830,
          1.7516,  1.7502,  1.7440,  1.7285,  1.6820,  1.6039,  1.5869,  1.5833,
          1.5770,  1.5809,  1.5820,  1.5959,  1.5719,  1.5753],
        [ 1.2842,  1.2870,  1.2892,  1.2889,  1.2870,  1.2848,  1.2852,  1.2840,
          1.2840,  1.3518,  1.3541,  1.3531,  1.3367,  1.3509,  1.2827,  1.3523,
          1.3484,  1.2810,  1.3050,  1.2851,  1.3062,  1.3060,  1.3024,  1.3019,
          1.3022,  1.3011,  1.3011,  2.8187,  2.7539,  2.5455,  2.6037,  2.8172,
          2.5541,  2.7343,  2.6001,  2.5472,  1.7470,  1.7585,  1.7249,  1.7450,
          1.7563,  1.7550,  1.7217,  1.7154,  1.7440,  1.6097,  1.5922,  1.5204,
          1.5280,  1.6060,  1.5871,  1.6212,  1.5228,  1.5802],
        [ 1.8859,  1.4870,  0.6378,  0.9637,  1.3814,  1.8163,  1.6892,  1.9218,
          1.9218,  1.7335,  1.3636,  1.5681,  0.9702,  1.7751,  0.1626,  1.6705,
          1.9448,  0.8873,  1.3887,  1.0446,  0.7985,  1.1974,  1.7580,  1.8243,
          1.5855,  1.9304,  1.9304,  0.8914,  0.8900,  1.9032,  1.6955,  0.9028,
          1.8439,  1.3015,  1.9520,  1.8676, -0.1189, -0.3634, -0.4068, -0.1629,
          0.0888,  0.1820, -0.2458, 16.4502,  4.1087,  0.2549,  0.6185,  0.6444,
          0.7547,  0.4073,  0.7553, -0.0353,  0.7874,  0.8511],
        [ 1.3360,  1.3731,  1.4141,  1.4051,  1.3800,  1.3431,  1.3134,  1.3322,
          1.3322,  1.3072,  1.4277,  1.3255,  1.4562,  1.3847,  1.4817,  1.3140,
          1.3601,  1.3707,  1.3933,  1.3707,  1.4261,  1.4070,  1.3601,  1.3532,
          1.2531,  1.3418,  1.3418,  1.3922,  1.4390,  1.3569,  1.1480,  1.3491,
          1.2458,  1.4133,  1.2347,  1.3610,  0.3427,  0.2665,  0.3804,  0.3501,
          0.1419,  0.0954,  0.3663,  0.1418, -0.0678,  3.3920,  2.2867,  3.3632,
          2.6152,  1.8340,  1.4306,  2.8436,  3.2007,  1.3951]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 291 : 174.8068146409595
Test loss for epoch 291 : 174.96776578684506
Test Precision for epoch 291 : 0.26153846153846155
Test Recall for epoch 291 : 0.26153846153846155
Test F1 for epoch 291 : 0.26153846153846155


theta for epoch 292 : tensor([[ 2.6016,  2.6205,  2.6575,  2.7671,  2.7483,  2.6049,  2.7353,  2.6000,
          2.6000,  1.3386,  1.3408,  1.3399,  1.3429,  1.3377,  1.3449,  1.3391,
          1.3360,  1.2982,  1.2915,  1.2493,  1.2501,  1.2925,  1.2891,  1.2886,
          1.2908,  1.2878,  1.2878,  1.2723,  1.3168,  1.3107,  1.3137,  1.3168,
          1.3121,  1.3148,  1.2668,  1.3110,  1.7390,  1.7499,  1.7435,  1.7396,
          1.7478,  1.6875,  1.7404,  1.7256,  1.7386,  1.5994,  1.5827,  1.5791,
          1.5729,  1.5959,  1.5778,  1.6104,  1.5695,  1.5712],
        [ 1.2943,  1.2972,  1.2765,  1.2772,  1.2980,  1.2951,  1.2960,  1.2943,
          1.2943,  2.5732,  2.5834,  2.5128,  2.7228,  2.5022,  2.9386,  2.5727,
          2.6854,  2.9115,  1.2854,  1.2904,  1.2438,  1.2852,  1.3128,  1.3122,
          1.3126,  1.3114,  1.3114,  1.3135,  1.2642,  1.3341,  1.3374,  1.2907,
          1.3356,  1.3386,  1.3082,  1.3344,  1.7530,  1.7650,  1.7211,  1.7524,
          1.7627,  1.7640,  1.7177,  1.7007,  1.7517,  1.5615,  1.5991,  1.5952,
          1.5884,  1.5217,  1.5938,  1.5376,  1.5847,  1.5866],
        [ 1.2763,  1.2791,  1.2811,  1.2808,  1.2789,  1.2769,  1.2772,  1.2761,
          1.2761,  1.3441,  1.3464,  1.3455,  1.3485,  1.3433,  1.2918,  1.3446,
          1.2829,  1.3323,  2.6531,  2.7489,  2.8012,  2.6622,  2.5935,  2.5904,
          2.7254,  2.5853,  2.5853,  1.2780,  1.3067,  1.3162,  1.3193,  1.2787,
          1.3176,  1.3205,  1.3161,  1.3165,  1.7426,  1.7537,  1.7472,  1.6829,
          1.7516,  1.7502,  1.7440,  1.7286,  1.6819,  1.6037,  1.5868,  1.5832,
          1.5769,  1.5808,  1.5819,  1.5958,  1.5718,  1.5751],
        [ 1.2840,  1.2869,  1.2889,  1.2887,  1.2868,  1.2846,  1.2850,  1.2838,
          1.2838,  1.3517,  1.3540,  1.3530,  1.3366,  1.3507,  1.2829,  1.3522,
          1.3483,  1.2813,  1.3049,  1.2850,  1.3061,  1.3059,  1.3023,  1.3018,
          1.3021,  1.3010,  1.3010,  2.8196,  2.7548,  2.5472,  2.6045,  2.8181,
          2.5558,  2.7351,  2.6019,  2.5490,  1.7470,  1.7584,  1.7249,  1.7449,
          1.7563,  1.7549,  1.7217,  1.7159,  1.7439,  1.6095,  1.5920,  1.5206,
          1.5278,  1.6059,  1.5870,  1.6210,  1.5226,  1.5800],
        [ 1.8860,  1.4870,  0.6378,  0.9636,  1.3815,  1.8164,  1.6893,  1.9219,
          1.9219,  1.7332,  1.3634,  1.5682,  0.9703,  1.7752,  0.1624,  1.6702,
          1.9450,  0.8870,  1.3887,  1.0448,  0.7986,  1.1975,  1.7581,  1.8244,
          1.5857,  1.9305,  1.9305,  0.8914,  0.8899,  1.9033,  1.6954,  0.9026,
          1.8440,  1.3014,  1.9521,  1.8677, -0.1194, -0.3637, -0.4071, -0.1634,
          0.0882,  0.1813, -0.2462, 16.4939,  4.0823,  0.2550,  0.6186,  0.6443,
          0.7547,  0.4073,  0.7553, -0.0352,  0.7875,  0.8512],
        [ 1.3362,  1.3733,  1.4142,  1.4052,  1.3802,  1.3432,  1.3136,  1.3324,
          1.3324,  1.3075,  1.4280,  1.3258,  1.4564,  1.3850,  1.4819,  1.3143,
          1.3604,  1.3710,  1.3936,  1.3708,  1.4263,  1.4073,  1.3604,  1.3535,
          1.2532,  1.3420,  1.3420,  1.3923,  1.4392,  1.3571,  1.1482,  1.3492,
          1.2460,  1.4135,  1.2349,  1.3613,  0.3430,  0.2668,  0.3806,  0.3503,
          0.1422,  0.0956,  0.3665,  0.1420, -0.0676,  3.3951,  2.2869,  3.3660,
          2.6159,  1.8339,  1.4303,  2.8443,  3.2041,  1.3949]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 292 : 174.79656252582743
Test loss for epoch 292 : 174.96134681608913
Test Precision for epoch 292 : 0.26153846153846155
Test Recall for epoch 292 : 0.26153846153846155
Test F1 for epoch 292 : 0.26153846153846155


theta for epoch 293 : tensor([[ 2.6029,  2.6218,  2.6587,  2.7685,  2.7497,  2.6061,  2.7368,  2.6012,
          2.6012,  1.3385,  1.3407,  1.3398,  1.3428,  1.3376,  1.3448,  1.3390,
          1.3359,  1.2981,  1.2914,  1.2492,  1.2499,  1.2924,  1.2889,  1.2885,
          1.2907,  1.2876,  1.2876,  1.2722,  1.3167,  1.3106,  1.3136,  1.3167,
          1.3120,  1.3147,  1.2667,  1.3108,  1.7389,  1.7498,  1.7434,  1.7395,
          1.7478,  1.6874,  1.7404,  1.7255,  1.7385,  1.5994,  1.5827,  1.5791,
          1.5730,  1.5959,  1.5779,  1.6104,  1.5695,  1.5712],
        [ 1.2941,  1.2970,  1.2769,  1.2775,  1.2978,  1.2949,  1.2958,  1.2941,
          1.2941,  2.5739,  2.5842,  2.5147,  2.7250,  2.5039,  2.9394,  2.5735,
          2.6877,  2.9123,  1.2852,  1.2901,  1.2436,  1.2850,  1.3126,  1.3120,
          1.3125,  1.3111,  1.3111,  1.3133,  1.2640,  1.3339,  1.3372,  1.2910,
          1.3355,  1.3385,  1.3080,  1.3343,  1.7529,  1.7648,  1.7209,  1.7523,
          1.7626,  1.7639,  1.7176,  1.7014,  1.7516,  1.5615,  1.5990,  1.5952,
          1.5884,  1.5217,  1.5938,  1.5376,  1.5847,  1.5866],
        [ 1.2762,  1.2789,  1.2810,  1.2807,  1.2788,  1.2767,  1.2771,  1.2759,
          1.2759,  1.3440,  1.3463,  1.3454,  1.3484,  1.3431,  1.2916,  1.3445,
          1.2828,  1.3322,  2.6543,  2.7505,  2.8028,  2.6633,  2.5947,  2.5916,
          2.7270,  2.5865,  2.5865,  1.2778,  1.3066,  1.3161,  1.3192,  1.2785,
          1.3175,  1.3204,  1.3160,  1.3164,  1.7425,  1.7536,  1.7471,  1.6827,
          1.7515,  1.7500,  1.7440,  1.7285,  1.6817,  1.6038,  1.5868,  1.5832,
          1.5769,  1.5808,  1.5819,  1.5958,  1.5718,  1.5752],
        [ 1.2839,  1.2867,  1.2887,  1.2885,  1.2866,  1.2844,  1.2849,  1.2836,
          1.2836,  1.3515,  1.3538,  1.3529,  1.3364,  1.3506,  1.2831,  1.3520,
          1.3481,  1.2814,  1.3047,  1.2848,  1.3060,  1.3057,  1.3022,  1.3016,
          1.3019,  1.3008,  1.3008,  2.8206,  2.7556,  2.5490,  2.6053,  2.8191,
          2.5576,  2.7360,  2.6037,  2.5507,  1.7469,  1.7583,  1.7248,  1.7448,
          1.7562,  1.7548,  1.7215,  1.7163,  1.7437,  1.6095,  1.5920,  1.5210,
          1.5278,  1.6058,  1.5870,  1.6210,  1.5226,  1.5800],
        [ 1.8864,  1.4875,  0.6382,  0.9639,  1.3820,  1.8168,  1.6897,  1.9223,
          1.9223,  1.7333,  1.3637,  1.5686,  0.9709,  1.7756,  0.1628,  1.6704,
          1.9454,  0.8871,  1.3892,  1.0455,  0.7992,  1.1979,  1.7586,  1.8249,
          1.5863,  1.9310,  1.9310,  0.8920,  0.8903,  1.9038,  1.6957,  0.9029,
          1.8445,  1.3017,  1.9525,  1.8681, -0.1202, -0.3645, -0.4079, -0.1644,
          0.0873,  0.1803, -0.2470, 16.5371,  4.0555,  0.2555,  0.6191,  0.6447,
          0.7552,  0.4079,  0.7558, -0.0346,  0.7880,  0.8517],
        [ 1.3360,  1.3731,  1.4139,  1.4050,  1.3800,  1.3431,  1.3134,  1.3322,
          1.3322,  1.3073,  1.4278,  1.3256,  1.4562,  1.3848,  1.4817,  1.3141,
          1.3601,  1.3708,  1.3934,  1.3704,  1.4261,  1.4071,  1.3602,  1.3533,
          1.2529,  1.3418,  1.3418,  1.3920,  1.4391,  1.3570,  1.1480,  1.3489,
          1.2459,  1.4134,  1.2347,  1.3611,  0.3428,  0.2666,  0.3804,  0.3500,
          0.1419,  0.0953,  0.3663,  0.1416, -0.0678,  3.3987,  2.2876,  3.3692,
          2.6171,  1.8342,  1.4306,  2.8454,  3.2081,  1.3952]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 293 : 174.7863150723506
Test loss for epoch 293 : 174.95412340873338
Test Precision for epoch 293 : 0.26153846153846155
Test Recall for epoch 293 : 0.26153846153846155
Test F1 for epoch 293 : 0.26153846153846155


theta for epoch 294 : tensor([[ 2.6042,  2.6231,  2.6601,  2.7700,  2.7512,  2.6075,  2.7383,  2.6026,
          2.6026,  1.3384,  1.3406,  1.3397,  1.3427,  1.3375,  1.3447,  1.3389,
          1.3358,  1.2980,  1.2913,  1.2491,  1.2498,  1.2923,  1.2888,  1.2883,
          1.2906,  1.2875,  1.2875,  1.2721,  1.3165,  1.3104,  1.3135,  1.3166,
          1.3118,  1.3146,  1.2666,  1.3107,  1.7389,  1.7498,  1.7434,  1.7395,
          1.7477,  1.6873,  1.7403,  1.7254,  1.7385,  1.5991,  1.5824,  1.5789,
          1.5727,  1.5956,  1.5776,  1.6101,  1.5692,  1.5710],
        [ 1.2940,  1.2968,  1.2772,  1.2778,  1.2976,  1.2948,  1.2956,  1.2939,
          1.2939,  2.5745,  2.5850,  2.5166,  2.7272,  2.5057,  2.9402,  2.5743,
          2.6900,  2.9131,  1.2850,  1.2900,  1.2434,  1.2849,  1.3124,  1.3119,
          1.3124,  1.3110,  1.3110,  1.3132,  1.2639,  1.3338,  1.3371,  1.2914,
          1.3353,  1.3383,  1.3079,  1.3341,  1.7528,  1.7647,  1.7208,  1.7522,
          1.7625,  1.7638,  1.7175,  1.7021,  1.7515,  1.5611,  1.5987,  1.5949,
          1.5881,  1.5214,  1.5935,  1.5373,  1.5844,  1.5863],
        [ 1.2761,  1.2789,  1.2808,  1.2806,  1.2787,  1.2766,  1.2770,  1.2759,
          1.2759,  1.3439,  1.3462,  1.3453,  1.3483,  1.3430,  1.2915,  1.3444,
          1.2826,  1.3321,  2.6555,  2.7522,  2.8044,  2.6646,  2.5959,  2.5928,
          2.7286,  2.5877,  2.5877,  1.2776,  1.3065,  1.3160,  1.3191,  1.2783,
          1.3174,  1.3203,  1.3159,  1.3163,  1.7425,  1.7536,  1.7471,  1.6825,
          1.7515,  1.7500,  1.7440,  1.7285,  1.6815,  1.6035,  1.5866,  1.5830,
          1.5767,  1.5806,  1.5817,  1.5955,  1.5715,  1.5749],
        [ 1.2837,  1.2865,  1.2885,  1.2884,  1.2865,  1.2843,  1.2847,  1.2835,
          1.2835,  1.3514,  1.3537,  1.3527,  1.3363,  1.3504,  1.2832,  1.3519,
          1.3480,  1.2816,  1.3045,  1.2846,  1.3058,  1.3056,  1.3020,  1.3015,
          1.3017,  1.3006,  1.3006,  2.8217,  2.7566,  2.5508,  2.6061,  2.8202,
          2.5594,  2.7369,  2.6056,  2.5526,  1.7468,  1.7583,  1.7247,  1.7447,
          1.7561,  1.7546,  1.7215,  1.7167,  1.7436,  1.6092,  1.5917,  1.5212,
          1.5276,  1.6055,  1.5867,  1.6207,  1.5222,  1.5797],
        [ 1.8865,  1.4877,  0.6383,  0.9638,  1.3821,  1.8170,  1.6899,  1.9225,
          1.9225,  1.7331,  1.3635,  1.5688,  0.9710,  1.7757,  0.1627,  1.6702,
          1.9456,  0.8869,  1.3894,  1.0458,  0.7994,  1.1981,  1.7587,  1.8250,
          1.5867,  1.9311,  1.9311,  0.8921,  0.8903,  1.9039,  1.6957,  0.9029,
          1.8446,  1.3017,  1.9527,  1.8683, -0.1207, -0.3649, -0.4083, -0.1649,
          0.0867,  0.1796, -0.2474, 16.5807,  4.0289,  0.2556,  0.6191,  0.6447,
          0.7553,  0.4079,  0.7559, -0.0344,  0.7881,  0.8517],
        [ 1.3362,  1.3733,  1.4140,  1.4053,  1.3802,  1.3433,  1.3137,  1.3325,
          1.3325,  1.3077,  1.4281,  1.3258,  1.4565,  1.3850,  1.4819,  1.3144,
          1.3604,  1.3711,  1.3937,  1.3705,  1.4264,  1.4073,  1.3605,  1.3536,
          1.2530,  1.3421,  1.3421,  1.3921,  1.4393,  1.3572,  1.1483,  1.3491,
          1.2461,  1.4136,  1.2350,  1.3613,  0.3430,  0.2668,  0.3806,  0.3502,
          0.1422,  0.0955,  0.3665,  0.1418, -0.0676,  3.4017,  2.2878,  3.3720,
          2.6178,  1.8341,  1.4304,  2.8461,  3.2116,  1.3949]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 294 : 174.77607178900809
Test loss for epoch 294 : 174.94765481015318
Test Precision for epoch 294 : 0.26153846153846155
Test Recall for epoch 294 : 0.26153846153846155
Test F1 for epoch 294 : 0.26153846153846155


theta for epoch 295 : tensor([[ 2.6055,  2.6243,  2.6613,  2.7715,  2.7526,  2.6087,  2.7397,  2.6038,
          2.6038,  1.3383,  1.3405,  1.3396,  1.3426,  1.3374,  1.3446,  1.3388,
          1.3357,  1.2979,  1.2911,  1.2489,  1.2497,  1.2921,  1.2887,  1.2882,
          1.2904,  1.2874,  1.2874,  1.2720,  1.3164,  1.3103,  1.3134,  1.3165,
          1.3117,  1.3145,  1.2665,  1.3106,  1.7388,  1.7497,  1.7434,  1.7394,
          1.7477,  1.6873,  1.7403,  1.7254,  1.7384,  1.5991,  1.5824,  1.5789,
          1.5727,  1.5956,  1.5776,  1.6101,  1.5692,  1.5710],
        [ 1.2938,  1.2967,  1.2776,  1.2781,  1.2975,  1.2946,  1.2954,  1.2937,
          1.2937,  2.5751,  2.5858,  2.5184,  2.7294,  2.5074,  2.9410,  2.5750,
          2.6922,  2.9139,  1.2848,  1.2898,  1.2432,  1.2847,  1.3122,  1.3117,
          1.3122,  1.3108,  1.3108,  1.3130,  1.2638,  1.3336,  1.3369,  1.2917,
          1.3351,  1.3381,  1.3077,  1.3339,  1.7527,  1.7646,  1.7207,  1.7521,
          1.7624,  1.7637,  1.7173,  1.7028,  1.7513,  1.5611,  1.5986,  1.5948,
          1.5880,  1.5213,  1.5934,  1.5372,  1.5843,  1.5862],
        [ 1.2760,  1.2787,  1.2807,  1.2805,  1.2786,  1.2765,  1.2769,  1.2757,
          1.2757,  1.3439,  1.3461,  1.3452,  1.3482,  1.3430,  1.2913,  1.3443,
          1.2824,  1.3320,  2.6567,  2.7538,  2.8059,  2.6657,  2.5970,  2.5939,
          2.7302,  2.5888,  2.5888,  1.2774,  1.3064,  1.3159,  1.3190,  1.2781,
          1.3173,  1.3202,  1.3158,  1.3162,  1.7424,  1.7535,  1.7470,  1.6823,
          1.7514,  1.7499,  1.7439,  1.7284,  1.6813,  1.6035,  1.5866,  1.5830,
          1.5767,  1.5806,  1.5817,  1.5955,  1.5714,  1.5749],
        [ 1.2836,  1.2864,  1.2883,  1.2882,  1.2863,  1.2841,  1.2846,  1.2833,
          1.2833,  1.3512,  1.3535,  1.3526,  1.3361,  1.3503,  1.2834,  1.3517,
          1.3478,  1.2818,  1.3044,  1.2844,  1.3056,  1.3054,  1.3018,  1.3013,
          1.3015,  1.3005,  1.3005,  2.8227,  2.7574,  2.5526,  2.6069,  2.8212,
          2.5612,  2.7378,  2.6074,  2.5543,  1.7467,  1.7581,  1.7246,  1.7445,
          1.7560,  1.7545,  1.7214,  1.7171,  1.7435,  1.6091,  1.5916,  1.5215,
          1.5275,  1.6055,  1.5866,  1.6206,  1.5221,  1.5797],
        [ 1.8870,  1.4881,  0.6387,  0.9641,  1.3826,  1.8175,  1.6904,  1.9229,
          1.9229,  1.7332,  1.3638,  1.5692,  0.9715,  1.7761,  0.1631,  1.6703,
          1.9461,  0.8871,  1.3899,  1.0465,  0.8000,  1.1985,  1.7592,  1.8255,
          1.5873,  1.9316,  1.9316,  0.8927,  0.8907,  1.9044,  1.6960,  0.9032,
          1.8451,  1.3021,  1.9531,  1.8687, -0.1215, -0.3656, -0.4090, -0.1658,
          0.0858,  0.1785, -0.2482, 16.6240,  4.0019,  0.2562,  0.6197,  0.6451,
          0.7558,  0.4085,  0.7564, -0.0338,  0.7886,  0.8522],
        [ 1.3360,  1.3731,  1.4137,  1.4051,  1.3800,  1.3431,  1.3135,  1.3323,
          1.3323,  1.3075,  1.4279,  1.3256,  1.4562,  1.3848,  1.4817,  1.3143,
          1.3602,  1.3709,  1.3934,  1.3701,  1.4261,  1.4071,  1.3603,  1.3534,
          1.2526,  1.3419,  1.3419,  1.3918,  1.4391,  1.3570,  1.1481,  1.3488,
          1.2459,  1.4134,  1.2348,  1.3611,  0.3428,  0.2665,  0.3803,  0.3500,
          0.1419,  0.0952,  0.3663,  0.1415, -0.0679,  3.4052,  2.2885,  3.3752,
          2.6190,  1.8344,  1.4307,  2.8472,  3.2156,  1.3952]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 295 : 174.76583457907367
Test loss for epoch 295 : 174.94044379091193
Test Precision for epoch 295 : 0.26153846153846155
Test Recall for epoch 295 : 0.26153846153846155
Test F1 for epoch 295 : 0.26153846153846155


theta for epoch 296 : tensor([[ 2.6067,  2.6255,  2.6625,  2.7728,  2.7540,  2.6099,  2.7410,  2.6050,
          2.6050,  1.3382,  1.3404,  1.3395,  1.3425,  1.3373,  1.3445,  1.3387,
          1.3356,  1.2978,  1.2911,  1.2489,  1.2496,  1.2921,  1.2887,  1.2882,
          1.2904,  1.2874,  1.2874,  1.2719,  1.3163,  1.3102,  1.3133,  1.3164,
          1.3116,  1.3144,  1.2664,  1.3105,  1.7388,  1.7497,  1.7434,  1.7394,
          1.7477,  1.6873,  1.7403,  1.7254,  1.7385,  1.5989,  1.5822,  1.5787,
          1.5725,  1.5954,  1.5774,  1.6099,  1.5691,  1.5708],
        [ 1.2936,  1.2965,  1.2779,  1.2784,  1.2972,  1.2944,  1.2952,  1.2935,
          1.2935,  2.5757,  2.5866,  2.5202,  2.7316,  2.5091,  2.9417,  2.5757,
          2.6944,  2.9146,  1.2847,  1.2897,  1.2431,  1.2847,  1.3121,  1.3116,
          1.3121,  1.3107,  1.3107,  1.3128,  1.2637,  1.3334,  1.3367,  1.2920,
          1.3350,  1.3380,  1.3075,  1.3338,  1.7527,  1.7646,  1.7207,  1.7521,
          1.7623,  1.7637,  1.7173,  1.7035,  1.7513,  1.5608,  1.5984,  1.5946,
          1.5878,  1.5211,  1.5932,  1.5369,  1.5841,  1.5860],
        [ 1.2759,  1.2786,  1.2805,  1.2803,  1.2785,  1.2764,  1.2768,  1.2756,
          1.2756,  1.3438,  1.3460,  1.3451,  1.3481,  1.3429,  1.2912,  1.3443,
          1.2823,  1.3319,  2.6578,  2.7553,  2.8074,  2.6669,  2.5981,  2.5950,
          2.7317,  2.5899,  2.5899,  1.2772,  1.3063,  1.3158,  1.3189,  1.2779,
          1.3172,  1.3201,  1.3157,  1.3161,  1.7425,  1.7535,  1.7471,  1.6822,
          1.7515,  1.7499,  1.7439,  1.7285,  1.6812,  1.6033,  1.5864,  1.5828,
          1.5765,  1.5804,  1.5815,  1.5954,  1.5712,  1.5748],
        [ 1.2834,  1.2862,  1.2881,  1.2880,  1.2861,  1.2839,  1.2844,  1.2831,
          1.2831,  1.3511,  1.3534,  1.3524,  1.3360,  1.3502,  1.2836,  1.3516,
          1.3477,  1.2820,  1.3043,  1.2842,  1.3056,  1.3053,  1.3017,  1.3012,
          1.3013,  1.3004,  1.3004,  2.8237,  2.7583,  2.5543,  2.6077,  2.8222,
          2.5629,  2.7386,  2.6092,  2.5560,  1.7467,  1.7581,  1.7246,  1.7444,
          1.7560,  1.7544,  1.7214,  1.7175,  1.7434,  1.6089,  1.5914,  1.5217,
          1.5273,  1.6053,  1.5864,  1.6204,  1.5219,  1.5795],
        [ 1.8870,  1.4882,  0.6387,  0.9640,  1.3827,  1.8175,  1.6904,  1.9230,
          1.9230,  1.7329,  1.3636,  1.5693,  0.9716,  1.7762,  0.1630,  1.6701,
          1.9463,  0.8868,  1.3899,  1.0467,  0.8001,  1.1986,  1.7593,  1.8256,
          1.5876,  1.9317,  1.9317,  0.8927,  0.8906,  1.9045,  1.6959,  0.9030,
          1.8452,  1.3020,  1.9532,  1.8688, -0.1219, -0.3659, -0.4094, -0.1663,
          0.0853,  0.1779, -0.2486, 16.6677,  3.9753,  0.2563,  0.6197,  0.6450,
          0.7558,  0.4085,  0.7564, -0.0337,  0.7887,  0.8522],
        [ 1.3362,  1.3733,  1.4137,  1.4052,  1.3802,  1.3433,  1.3136,  1.3325,
          1.3325,  1.3078,  1.4282,  1.3259,  1.4565,  1.3851,  1.4820,  1.3146,
          1.3604,  1.3712,  1.3937,  1.3702,  1.4264,  1.4074,  1.3605,  1.3536,
          1.2527,  1.3421,  1.3421,  1.3919,  1.4393,  1.3572,  1.1483,  1.3489,
          1.2461,  1.4137,  1.2350,  1.3614,  0.3430,  0.2668,  0.3806,  0.3502,
          0.1422,  0.0954,  0.3666,  0.1416, -0.0677,  3.4083,  2.2887,  3.3779,
          2.6197,  1.8343,  1.4305,  2.8478,  3.2191,  1.3950]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 296 : 174.7556032090819
Test loss for epoch 296 : 174.93408049030813
Test Precision for epoch 296 : 0.26153846153846155
Test Recall for epoch 296 : 0.26153846153846155
Test F1 for epoch 296 : 0.26153846153846155


theta for epoch 297 : tensor([[ 2.6079,  2.6268,  2.6638,  2.7742,  2.7554,  2.6111,  2.7424,  2.6062,
          2.6062,  1.3381,  1.3403,  1.3394,  1.3424,  1.3372,  1.3444,  1.3386,
          1.3355,  1.2977,  1.2909,  1.2487,  1.2495,  1.2919,  1.2885,  1.2880,
          1.2902,  1.2872,  1.2872,  1.2718,  1.3162,  1.3101,  1.3132,  1.3163,
          1.3115,  1.3143,  1.2663,  1.3104,  1.7388,  1.7497,  1.7433,  1.7394,
          1.7477,  1.6872,  1.7402,  1.7253,  1.7384,  1.5989,  1.5822,  1.5787,
          1.5725,  1.5954,  1.5774,  1.6099,  1.5691,  1.5708],
        [ 1.2934,  1.2963,  1.2783,  1.2786,  1.2971,  1.2942,  1.2950,  1.2933,
          1.2933,  2.5763,  2.5873,  2.5220,  2.7338,  2.5108,  2.9425,  2.5764,
          2.6967,  2.9154,  1.2845,  1.2894,  1.2429,  1.2845,  1.3119,  1.3113,
          1.3119,  1.3104,  1.3104,  1.3126,  1.2636,  1.3333,  1.3366,  1.2923,
          1.3348,  1.3378,  1.3073,  1.3336,  1.7525,  1.7644,  1.7205,  1.7520,
          1.7622,  1.7635,  1.7172,  1.7042,  1.7512,  1.5608,  1.5984,  1.5945,
          1.5878,  1.5211,  1.5931,  1.5369,  1.5840,  1.5859],
        [ 1.2758,  1.2785,  1.2803,  1.2802,  1.2783,  1.2763,  1.2766,  1.2755,
          1.2755,  1.3437,  1.3459,  1.3450,  1.3480,  1.3428,  1.2911,  1.3442,
          1.2822,  1.3318,  2.6590,  2.7569,  2.8089,  2.6680,  2.5992,  2.5961,
          2.7332,  2.5911,  2.5911,  1.2770,  1.3062,  1.3157,  1.3188,  1.2777,
          1.3172,  1.3200,  1.3157,  1.3160,  1.7424,  1.7535,  1.7470,  1.6820,
          1.7514,  1.7498,  1.7439,  1.7284,  1.6810,  1.6033,  1.5864,  1.5829,
          1.5765,  1.5805,  1.5816,  1.5954,  1.5712,  1.5748],
        [ 1.2832,  1.2860,  1.2879,  1.2879,  1.2860,  1.2838,  1.2842,  1.2830,
          1.2830,  1.3510,  1.3533,  1.3523,  1.3359,  1.3500,  1.2838,  1.3515,
          1.3476,  1.2822,  1.3041,  1.2840,  1.3054,  1.3051,  1.3016,  1.3011,
          1.3011,  1.3002,  1.3002,  2.8247,  2.7592,  2.5560,  2.6085,  2.8232,
          2.5646,  2.7395,  2.6110,  2.5577,  1.7466,  1.7580,  1.7245,  1.7443,
          1.7559,  1.7543,  1.7213,  1.7179,  1.7433,  1.6089,  1.5914,  1.5220,
          1.5273,  1.6052,  1.5864,  1.6204,  1.5218,  1.5795],
        [ 1.8875,  1.4887,  0.6392,  0.9644,  1.3832,  1.8180,  1.6909,  1.9234,
          1.9234,  1.7330,  1.3639,  1.5698,  0.9722,  1.7766,  0.1634,  1.6703,
          1.9468,  0.8870,  1.3905,  1.0474,  0.8008,  1.1991,  1.7598,  1.8261,
          1.5882,  1.9322,  1.9322,  0.8933,  0.8910,  1.9049,  1.6962,  0.9034,
          1.8457,  1.3024,  1.9537,  1.8693, -0.1228, -0.3667, -0.4101, -0.1673,
          0.0843,  0.1768, -0.2494, 16.7110,  3.9481,  0.2568,  0.6202,  0.6454,
          0.7563,  0.4091,  0.7570, -0.0330,  0.7893,  0.8528],
        [ 1.3360,  1.3731,  1.4133,  1.4050,  1.3800,  1.3430,  1.3134,  1.3322,
          1.3322,  1.3076,  1.4280,  1.3256,  1.4562,  1.3848,  1.4817,  1.3143,
          1.3602,  1.3709,  1.3934,  1.3697,  1.4261,  1.4071,  1.3603,  1.3533,
          1.2523,  1.3419,  1.3419,  1.3916,  1.4391,  1.3570,  1.1481,  1.3486,
          1.2459,  1.4135,  1.2348,  1.3611,  0.3427,  0.2665,  0.3803,  0.3499,
          0.1419,  0.0951,  0.3663,  0.1412, -0.0680,  3.4118,  2.2894,  3.3812,
          2.6209,  1.8347,  1.4308,  2.8490,  3.2231,  1.3954]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 297 : 174.74538100572437
Test loss for epoch 297 : 174.9268166028047
Test Precision for epoch 297 : 0.26153846153846155
Test Recall for epoch 297 : 0.26153846153846155
Test F1 for epoch 297 : 0.26153846153846155


theta for epoch 298 : tensor([[ 2.6092,  2.6281,  2.6651,  2.7757,  2.7568,  2.6124,  2.7439,  2.6075,
          2.6075,  1.3380,  1.3402,  1.3393,  1.3423,  1.3371,  1.3443,  1.3385,
          1.3354,  1.2976,  1.2908,  1.2486,  1.2494,  1.2918,  1.2884,  1.2879,
          1.2901,  1.2871,  1.2871,  1.2717,  1.3161,  1.3100,  1.3131,  1.3162,
          1.3114,  1.3142,  1.2661,  1.3103,  1.7388,  1.7497,  1.7433,  1.7394,
          1.7477,  1.6872,  1.7402,  1.7253,  1.7384,  1.5986,  1.5819,  1.5784,
          1.5722,  1.5951,  1.5771,  1.6096,  1.5688,  1.5705],
        [ 1.2933,  1.2961,  1.2786,  1.2790,  1.2969,  1.2940,  1.2949,  1.2932,
          1.2932,  2.5769,  2.5881,  2.5239,  2.7360,  2.5125,  2.9433,  2.5771,
          2.6990,  2.9162,  1.2844,  1.2893,  1.2427,  1.2844,  1.3117,  1.3112,
          1.3119,  1.3103,  1.3103,  1.3125,  1.2635,  1.3331,  1.3364,  1.2926,
          1.3346,  1.3376,  1.3072,  1.3334,  1.7525,  1.7644,  1.7205,  1.7519,
          1.7622,  1.7635,  1.7171,  1.7049,  1.7511,  1.5604,  1.5980,  1.5942,
          1.5874,  1.5207,  1.5928,  1.5365,  1.5836,  1.5856],
        [ 1.2757,  1.2784,  1.2802,  1.2801,  1.2782,  1.2762,  1.2765,  1.2754,
          1.2754,  1.3436,  1.3458,  1.3449,  1.3479,  1.3427,  1.2909,  1.3441,
          1.2820,  1.3317,  2.6602,  2.7586,  2.8105,  2.6693,  2.6005,  2.5974,
          2.7349,  2.5923,  2.5923,  1.2768,  1.3061,  1.3156,  1.3187,  1.2775,
          1.3171,  1.3199,  1.3156,  1.3159,  1.7424,  1.7535,  1.7470,  1.6819,
          1.7514,  1.7497,  1.7439,  1.7284,  1.6809,  1.6030,  1.5861,  1.5826,
          1.5763,  1.5802,  1.5813,  1.5951,  1.5708,  1.5745],
        [ 1.2831,  1.2859,  1.2877,  1.2878,  1.2858,  1.2836,  1.2841,  1.2828,
          1.2828,  1.3508,  1.3531,  1.3522,  1.3357,  1.3499,  1.2839,  1.3513,
          1.3474,  1.2823,  1.3040,  1.2839,  1.3053,  1.3050,  1.3015,  1.3009,
          1.3010,  1.3001,  1.3001,  2.8257,  2.7601,  2.5577,  2.6093,  2.8243,
          2.5663,  2.7404,  2.6128,  2.5595,  1.7466,  1.7580,  1.7245,  1.7442,
          1.7559,  1.7542,  1.7213,  1.7183,  1.7432,  1.6086,  1.5911,  1.5221,
          1.5270,  1.6049,  1.5861,  1.6201,  1.5215,  1.5791],
        [ 1.8876,  1.4888,  0.6391,  0.9642,  1.3833,  1.8181,  1.6910,  1.9235,
          1.9235,  1.7327,  1.3637,  1.5699,  0.9723,  1.7766,  0.1632,  1.6700,
          1.9469,  0.8867,  1.3905,  1.0477,  0.8009,  1.1992,  1.7599,  1.8261,
          1.5885,  1.9323,  1.9323,  0.8934,  0.8909,  1.9050,  1.6961,  0.9033,
          1.8457,  1.3023,  1.9538,  1.8694, -0.1232, -0.3670, -0.4105, -0.1678,
          0.0838,  0.1762, -0.2498, 16.7548,  3.9214,  0.2568,  0.6202,  0.6453,
          0.7562,  0.4091,  0.7569, -0.0329,  0.7893,  0.8527],
        [ 1.3363,  1.3734,  1.4135,  1.4053,  1.3803,  1.3434,  1.3137,  1.3325,
          1.3325,  1.3080,  1.4284,  1.3259,  1.4566,  1.3852,  1.4820,  1.3147,
          1.3605,  1.3713,  1.3938,  1.3699,  1.4264,  1.4074,  1.3606,  1.3537,
          1.2525,  1.3423,  1.3423,  1.3918,  1.4394,  1.3573,  1.1484,  1.3488,
          1.2462,  1.4138,  1.2351,  1.3615,  0.3431,  0.2669,  0.3806,  0.3502,
          0.1422,  0.0954,  0.3666,  0.1415, -0.0677,  3.4147,  2.2895,  3.3838,
          2.6214,  1.8344,  1.4305,  2.8495,  3.2264,  1.3950]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 298 : 174.7351729914351
Test loss for epoch 298 : 174.92057716062467
Test Precision for epoch 298 : 0.26153846153846155
Test Recall for epoch 298 : 0.26153846153846155
Test F1 for epoch 298 : 0.26153846153846155


theta for epoch 299 : tensor([[ 2.6104,  2.6293,  2.6663,  2.7771,  2.7582,  2.6137,  2.7453,  2.6088,
          2.6088,  1.3379,  1.3401,  1.3392,  1.3422,  1.3370,  1.3442,  1.3384,
          1.3353,  1.2975,  1.2907,  1.2484,  1.2492,  1.2917,  1.2883,  1.2878,
          1.2900,  1.2869,  1.2869,  1.2716,  1.3160,  1.3099,  1.3130,  1.3161,
          1.3113,  1.3141,  1.2660,  1.3102,  1.7387,  1.7496,  1.7432,  1.7393,
          1.7476,  1.6871,  1.7401,  1.7252,  1.7383,  1.5987,  1.5820,  1.5785,
          1.5723,  1.5952,  1.5772,  1.6097,  1.5688,  1.5706],
        [ 1.2931,  1.2959,  1.2790,  1.2792,  1.2967,  1.2938,  1.2947,  1.2930,
          1.2930,  2.5775,  2.5889,  2.5257,  2.7382,  2.5143,  2.9441,  2.5778,
          2.7012,  2.9170,  1.2841,  1.2890,  1.2425,  1.2842,  1.3115,  1.3109,
          1.3116,  1.3101,  1.3101,  1.3123,  1.2634,  1.3329,  1.3362,  1.2929,
          1.3345,  1.3375,  1.3070,  1.3332,  1.7523,  1.7642,  1.7203,  1.7518,
          1.7620,  1.7633,  1.7169,  1.7055,  1.7510,  1.5605,  1.5980,  1.5942,
          1.5874,  1.5207,  1.5928,  1.5366,  1.5837,  1.5856],
        [ 1.2755,  1.2783,  1.2800,  1.2800,  1.2781,  1.2761,  1.2764,  1.2753,
          1.2753,  1.3435,  1.3457,  1.3448,  1.3478,  1.3426,  1.2908,  1.3440,
          1.2818,  1.3317,  2.6614,  2.7601,  2.8120,  2.6704,  2.6016,  2.5985,
          2.7364,  2.5934,  2.5934,  1.2766,  1.3061,  1.3155,  1.3186,  1.2773,
          1.3170,  1.3198,  1.3155,  1.3158,  1.7423,  1.7534,  1.7469,  1.6817,
          1.7514,  1.7496,  1.7438,  1.7284,  1.6807,  1.6031,  1.5862,  1.5827,
          1.5764,  1.5803,  1.5814,  1.5952,  1.5709,  1.5746],
        [ 1.2829,  1.2857,  1.2875,  1.2876,  1.2857,  1.2835,  1.2839,  1.2826,
          1.2826,  1.3507,  1.3530,  1.3520,  1.3356,  1.3498,  1.2841,  1.3512,
          1.3473,  1.2825,  1.3038,  1.2836,  1.3051,  1.3048,  1.3013,  1.3007,
          1.3007,  1.2999,  1.2999,  2.8268,  2.7610,  2.5595,  2.6101,  2.8253,
          2.5681,  2.7413,  2.6146,  2.5612,  1.7465,  1.7579,  1.7244,  1.7440,
          1.7558,  1.7540,  1.7211,  1.7186,  1.7430,  1.6086,  1.5912,  1.5225,
          1.5271,  1.6050,  1.5861,  1.6201,  1.5215,  1.5792],
        [ 1.8881,  1.4894,  0.6397,  0.9646,  1.3839,  1.8186,  1.6915,  1.9240,
          1.9240,  1.7330,  1.3641,  1.5704,  0.9729,  1.7772,  0.1637,  1.6703,
          1.9475,  0.8870,  1.3911,  1.0485,  0.8016,  1.1998,  1.7604,  1.8267,
          1.5892,  1.9328,  1.9328,  0.8941,  0.8915,  1.9056,  1.6966,  0.9038,
          1.8463,  1.3028,  1.9544,  1.8700, -0.1241, -0.3678, -0.4113, -0.1688,
          0.0828,  0.1750, -0.2506, 16.7980,  3.8940,  0.2576,  0.6209,  0.6459,
          0.7569,  0.4098,  0.7576, -0.0321,  0.7900,  0.8534],
        [ 1.3359,  1.3731,  1.4131,  1.4050,  1.3799,  1.3430,  1.3134,  1.3322,
          1.3322,  1.3077,  1.4280,  1.3256,  1.4562,  1.3848,  1.4816,  1.3144,
          1.3601,  1.3709,  1.3934,  1.3694,  1.4260,  1.4071,  1.3602,  1.3533,
          1.2519,  1.3419,  1.3419,  1.3913,  1.4391,  1.3570,  1.1480,  1.3483,
          1.2459,  1.4135,  1.2348,  1.3611,  0.3427,  0.2665,  0.3802,  0.3498,
          0.1418,  0.0950,  0.3662,  0.1410, -0.0681,  3.4184,  2.2904,  3.3872,
          2.6228,  1.8349,  1.4310,  2.8508,  3.2306,  1.3955]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 299 : 174.72498215397243
Test loss for epoch 299 : 174.91316843497768
Test Precision for epoch 299 : 0.26153846153846155
Test Recall for epoch 299 : 0.26153846153846155
Test F1 for epoch 299 : 0.26153846153846155


theta for epoch 300 : tensor([[ 2.6116,  2.6305,  2.6675,  2.7785,  2.7596,  2.6149,  2.7467,  2.6100,
          2.6100,  1.3378,  1.3400,  1.3391,  1.3421,  1.3369,  1.3441,  1.3383,
          1.3352,  1.2974,  1.2906,  1.2484,  1.2492,  1.2916,  1.2882,  1.2877,
          1.2899,  1.2869,  1.2869,  1.2715,  1.3159,  1.3098,  1.3129,  1.3160,
          1.3112,  1.3140,  1.2659,  1.3101,  1.7387,  1.7496,  1.7433,  1.7393,
          1.7476,  1.6872,  1.7402,  1.7253,  1.7384,  1.5984,  1.5818,  1.5783,
          1.5721,  1.5950,  1.5770,  1.6094,  1.5686,  1.5704],
        [ 1.2929,  1.2957,  1.2793,  1.2795,  1.2965,  1.2936,  1.2945,  1.2928,
          1.2928,  2.5780,  2.5896,  2.5275,  2.7404,  2.5160,  2.9448,  2.5785,
          2.7034,  2.9177,  1.2841,  1.2890,  1.2424,  1.2842,  1.3114,  1.3109,
          1.3116,  1.3100,  1.3100,  1.3122,  1.2633,  1.3328,  1.3361,  1.2933,
          1.3343,  1.3373,  1.3068,  1.3331,  1.7523,  1.7642,  1.7203,  1.7518,
          1.7620,  1.7633,  1.7169,  1.7063,  1.7510,  1.5602,  1.5977,  1.5939,
          1.5871,  1.5204,  1.5925,  1.5362,  1.5833,  1.5853],
        [ 1.2754,  1.2781,  1.2799,  1.2799,  1.2780,  1.2759,  1.2763,  1.2751,
          1.2751,  1.3434,  1.3457,  1.3447,  1.3478,  1.3425,  1.2906,  1.3439,
          1.2817,  1.3316,  2.6625,  2.7617,  2.8135,  2.6716,  2.6028,  2.5996,
          2.7380,  2.5946,  2.5946,  1.2765,  1.3060,  1.3154,  1.3185,  1.2771,
          1.3169,  1.3197,  1.3154,  1.3157,  1.7424,  1.7535,  1.7470,  1.6816,
          1.7514,  1.7496,  1.7439,  1.7284,  1.6806,  1.6029,  1.5860,  1.5824,
          1.5761,  1.5801,  1.5811,  1.5949,  1.5706,  1.5744],
        [ 1.2828,  1.2856,  1.2873,  1.2874,  1.2855,  1.2833,  1.2837,  1.2825,
          1.2825,  1.3506,  1.3529,  1.3519,  1.3355,  1.3496,  1.2842,  1.3511,
          1.3472,  1.2826,  1.3037,  1.2835,  1.3050,  1.3048,  1.3012,  1.3007,
          1.3006,  1.2998,  1.2998,  2.8278,  2.7618,  2.5611,  2.6109,  2.8263,
          2.5697,  2.7422,  2.6163,  2.5629,  1.7465,  1.7579,  1.7244,  1.7440,
          1.7558,  1.7540,  1.7211,  1.7190,  1.7430,  1.6083,  1.5909,  1.5226,
          1.5268,  1.6047,  1.5859,  1.6198,  1.5211,  1.5789],
        [ 1.8880,  1.4893,  0.6395,  0.9643,  1.3838,  1.8186,  1.6915,  1.9240,
          1.9240,  1.7325,  1.3637,  1.5703,  0.9728,  1.7770,  0.1634,  1.6699,
          1.9474,  0.8865,  1.3910,  1.0485,  0.8015,  1.1997,  1.7604,  1.8266,
          1.5894,  1.9328,  1.9328,  0.8940,  0.8912,  1.9055,  1.6963,  0.9034,
          1.8462,  1.3025,  1.9543,  1.8699, -0.1244, -0.3680, -0.4115, -0.1691,
          0.0825,  0.1746, -0.2509, 16.8419,  3.8674,  0.2574,  0.6207,  0.6455,
          0.7567,  0.4096,  0.7574, -0.0323,  0.7898,  0.8532],
        [ 1.3363,  1.3734,  1.4133,  1.4054,  1.3803,  1.3434,  1.3138,  1.3326,
          1.3326,  1.3082,  1.4285,  1.3260,  1.4567,  1.3853,  1.4821,  1.3150,
          1.3606,  1.3714,  1.3939,  1.3697,  1.4265,  1.4076,  1.3608,  1.3538,
          1.2523,  1.3424,  1.3424,  1.3916,  1.4395,  1.3574,  1.1485,  1.3486,
          1.2463,  1.4139,  1.2352,  1.3616,  0.3432,  0.2669,  0.3807,  0.3503,
          0.1423,  0.0954,  0.3667,  0.1414, -0.0676,  3.4211,  2.2903,  3.3896,
          2.6231,  1.8345,  1.4305,  2.8511,  3.2338,  1.3950]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 300 : 174.71482267626354
Test loss for epoch 300 : 174.9072782396056
Test Precision for epoch 300 : 0.26153846153846155
Test Recall for epoch 300 : 0.26153846153846155
Test F1 for epoch 300 : 0.26153846153846155


theta for epoch 301 : tensor([[ 2.6129,  2.6317,  2.6687,  2.7799,  2.7610,  2.6161,  2.7481,  2.6112,
          2.6112,  1.3377,  1.3399,  1.3390,  1.3420,  1.3368,  1.3440,  1.3382,
          1.3351,  1.2973,  1.2905,  1.2482,  1.2490,  1.2915,  1.2880,  1.2876,
          1.2898,  1.2867,  1.2867,  1.2713,  1.3158,  1.3097,  1.3128,  1.3159,
          1.3111,  1.3139,  1.2658,  1.3100,  1.7386,  1.7495,  1.7432,  1.7392,
          1.7475,  1.6871,  1.7401,  1.7251,  1.7383,  1.5985,  1.5819,  1.5784,
          1.5722,  1.5951,  1.5771,  1.6095,  1.5687,  1.5705],
        [ 1.2927,  1.2956,  1.2796,  1.2798,  1.2963,  1.2934,  1.2943,  1.2926,
          1.2926,  2.5786,  2.5903,  2.5293,  2.7426,  2.5177,  2.9456,  2.5791,
          2.7057,  2.9185,  1.2838,  1.2887,  1.2421,  1.2840,  1.3112,  1.3106,
          1.3114,  1.3097,  1.3097,  1.3120,  1.2632,  1.3326,  1.3359,  1.2936,
          1.3341,  1.3371,  1.3067,  1.3329,  1.7521,  1.7640,  1.7201,  1.7516,
          1.7618,  1.7631,  1.7167,  1.7069,  1.7508,  1.5602,  1.5978,  1.5940,
          1.5872,  1.5205,  1.5926,  1.5363,  1.5834,  1.5854],
        [ 1.2753,  1.2780,  1.2797,  1.2798,  1.2779,  1.2758,  1.2762,  1.2750,
          1.2750,  1.3433,  1.3456,  1.3446,  1.3477,  1.3424,  1.2905,  1.3438,
          1.2816,  1.3315,  2.6636,  2.7632,  2.8149,  2.6727,  2.6038,  2.6007,
          2.7395,  2.5956,  2.5956,  1.2763,  1.3059,  1.3154,  1.3185,  1.2770,
          1.3168,  1.3196,  1.3153,  1.3157,  1.7423,  1.7534,  1.7469,  1.6814,
          1.7513,  1.7494,  1.7438,  1.7283,  1.6804,  1.6030,  1.5861,  1.5826,
          1.5763,  1.5802,  1.5813,  1.5950,  1.5706,  1.5745],
        [ 1.2826,  1.2854,  1.2871,  1.2873,  1.2853,  1.2831,  1.2836,  1.2823,
          1.2823,  1.3505,  1.3527,  1.3518,  1.3353,  1.3495,  1.2844,  1.3510,
          1.3470,  1.2828,  1.3035,  1.2833,  1.3048,  1.3046,  1.3010,  1.3005,
          1.3004,  1.2996,  1.2996,  2.8288,  2.7627,  2.5628,  2.6117,  2.8274,
          2.5714,  2.7430,  2.6181,  2.5645,  1.7463,  1.7577,  1.7242,  1.7438,
          1.7557,  1.7538,  1.7210,  1.7193,  1.7428,  1.6084,  1.5910,  1.5230,
          1.5269,  1.6048,  1.5859,  1.6199,  1.5212,  1.5790],
        [ 1.8887,  1.4900,  0.6403,  0.9649,  1.3846,  1.8192,  1.6922,  1.9246,
          1.9246,  1.7329,  1.3643,  1.5711,  0.9737,  1.7777,  0.1641,  1.6703,
          1.9482,  0.8871,  1.3918,  1.0495,  0.8024,  1.2005,  1.7611,  1.8273,
          1.5903,  1.9334,  1.9334,  0.8949,  0.8920,  1.9062,  1.6969,  0.9041,
          1.8470,  1.3032,  1.9550,  1.8706, -0.1255, -0.3690, -0.4125, -0.1703,
          0.0813,  0.1732, -0.2519, 16.8850,  3.8397,  0.2583,  0.6215,  0.6463,
          0.7575,  0.4105,  0.7583, -0.0313,  0.7907,  0.8541],
        [ 1.3358,  1.3729,  1.4126,  1.4048,  1.3798,  1.3429,  1.3132,  1.3321,
          1.3321,  1.3077,  1.4280,  1.3254,  1.4561,  1.3847,  1.4815,  1.3144,
          1.3600,  1.3708,  1.3933,  1.3689,  1.4259,  1.4069,  1.3601,  1.3532,
          1.2515,  1.3418,  1.3418,  1.3909,  1.4390,  1.3569,  1.1479,  1.3480,
          1.2458,  1.4134,  1.2347,  1.3611,  0.3426,  0.2663,  0.3801,  0.3496,
          0.1417,  0.0948,  0.3661,  0.1407, -0.0683,  3.4250,  2.2913,  3.3932,
          2.6247,  1.8352,  1.4312,  2.8526,  3.2381,  1.3957]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 301 : 174.70470687616378
Test loss for epoch 301 : 174.89959315082035
Test Precision for epoch 301 : 0.26153846153846155
Test Recall for epoch 301 : 0.26153846153846155
Test F1 for epoch 301 : 0.26153846153846155


theta for epoch 302 : tensor([[ 2.6141,  2.6330,  2.6700,  2.7813,  2.7624,  2.6174,  2.7495,  2.6125,
          2.6125,  1.3376,  1.3398,  1.3389,  1.3419,  1.3367,  1.3439,  1.3381,
          1.3350,  1.2972,  1.2905,  1.2482,  1.2490,  1.2915,  1.2880,  1.2876,
          1.2897,  1.2867,  1.2867,  1.2712,  1.3157,  1.3096,  1.3127,  1.3158,
          1.3110,  1.3138,  1.2657,  1.3099,  1.7387,  1.7496,  1.7432,  1.7393,
          1.7476,  1.6871,  1.7401,  1.7252,  1.7384,  1.5980,  1.5814,  1.5779,
          1.5717,  1.5946,  1.5766,  1.6090,  1.5682,  1.5700],
        [ 1.2926,  1.2954,  1.2800,  1.2801,  1.2962,  1.2933,  1.2942,  1.2924,
          1.2924,  2.5792,  2.5911,  2.5312,  2.7448,  2.5194,  2.9463,  2.5798,
          2.7079,  2.9192,  1.2838,  1.2887,  1.2421,  1.2840,  1.3111,  1.3106,
          1.3114,  1.3097,  1.3097,  1.3118,  1.2631,  1.3325,  1.3358,  1.2939,
          1.3340,  1.3370,  1.3065,  1.3328,  1.7521,  1.7640,  1.7201,  1.7516,
          1.7618,  1.7632,  1.7167,  1.7077,  1.7508,  1.5597,  1.5972,  1.5934,
          1.5866,  1.5200,  1.5920,  1.5357,  1.5828,  1.5848],
        [ 1.2752,  1.2779,  1.2796,  1.2797,  1.2778,  1.2757,  1.2761,  1.2750,
          1.2750,  1.3433,  1.3455,  1.3445,  1.3476,  1.3423,  1.2904,  1.3437,
          1.2815,  1.3314,  2.6649,  2.7648,  2.8165,  2.6740,  2.6051,  2.6019,
          2.7411,  2.5969,  2.5969,  1.2761,  1.3058,  1.3153,  1.3184,  1.2768,
          1.3167,  1.3195,  1.3152,  1.3156,  1.7424,  1.7535,  1.7470,  1.6813,
          1.7514,  1.7494,  1.7439,  1.7284,  1.6804,  1.6025,  1.5857,  1.5821,
          1.5758,  1.5797,  1.5808,  1.5945,  1.5701,  1.5741],
        [ 1.2825,  1.2853,  1.2869,  1.2871,  1.2852,  1.2830,  1.2835,  1.2822,
          1.2822,  1.3503,  1.3526,  1.3517,  1.3352,  1.3494,  1.2845,  1.3508,
          1.3469,  1.2829,  1.3035,  1.2832,  1.3048,  1.3045,  1.3010,  1.3005,
          1.3003,  1.2996,  1.2996,  2.8299,  2.7636,  2.5645,  2.6126,  2.8285,
          2.5731,  2.7440,  2.6199,  2.5663,  1.7464,  1.7578,  1.7243,  1.7438,
          1.7557,  1.7538,  1.7211,  1.7198,  1.7428,  1.6079,  1.5905,  1.5229,
          1.5264,  1.6043,  1.5854,  1.6194,  1.5206,  1.5785],
        [ 1.8885,  1.4898,  0.6399,  0.9645,  1.3843,  1.8191,  1.6920,  1.9245,
          1.9245,  1.7323,  1.3637,  1.5708,  0.9733,  1.7774,  0.1636,  1.6697,
          1.9480,  0.8864,  1.3915,  1.0494,  0.8021,  1.2001,  1.7609,  1.8271,
          1.5902,  1.9332,  1.9332,  0.8946,  0.8915,  1.9060,  1.6965,  0.9036,
          1.8467,  1.3028,  1.9548,  1.8704, -0.1255, -0.3690, -0.4125, -0.1705,
          0.0812,  0.1730, -0.2519, 16.9292,  3.8132,  0.2578,  0.6211,  0.6457,
          0.7570,  0.4101,  0.7578, -0.0317,  0.7903,  0.8536],
        [ 1.3365,  1.3736,  1.4132,  1.4055,  1.3805,  1.3436,  1.3139,  1.3328,
          1.3328,  1.3085,  1.4288,  1.3262,  1.4568,  1.3855,  1.4823,  1.3152,
          1.3608,  1.3716,  1.3941,  1.3696,  1.4267,  1.4077,  1.3610,  1.3541,
          1.2522,  1.3426,  1.3426,  1.3915,  1.4397,  1.3576,  1.1487,  1.3486,
          1.2465,  1.4141,  1.2354,  1.3618,  0.3433,  0.2671,  0.3808,  0.3504,
          0.1425,  0.0955,  0.3669,  0.1414, -0.0675,  3.4274,  2.2909,  3.3952,
          2.6247,  1.8345,  1.4304,  2.8526,  3.2410,  1.3949]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 302 : 174.69467420690773
Test loss for epoch 302 : 174.89429409115766
Test Precision for epoch 302 : 0.26153846153846155
Test Recall for epoch 302 : 0.26153846153846155
Test F1 for epoch 302 : 0.26153846153846155


theta for epoch 303 : tensor([[ 2.6153,  2.6342,  2.6712,  2.7827,  2.7638,  2.6186,  2.7509,  2.6137,
          2.6137,  1.3375,  1.3397,  1.3388,  1.3418,  1.3366,  1.3438,  1.3380,
          1.3349,  1.2970,  1.2902,  1.2480,  1.2487,  1.2912,  1.2878,  1.2873,
          1.2895,  1.2865,  1.2865,  1.2711,  1.3156,  1.3095,  1.3126,  1.3157,
          1.3109,  1.3137,  1.2656,  1.3098,  1.7385,  1.7494,  1.7431,  1.7392,
          1.7474,  1.6870,  1.7400,  1.7251,  1.7382,  1.5984,  1.5818,  1.5783,
          1.5721,  1.5949,  1.5770,  1.6094,  1.5686,  1.5704],
        [ 1.2923,  1.2952,  1.2803,  1.2804,  1.2959,  1.2930,  1.2940,  1.2922,
          1.2922,  2.5798,  2.5918,  2.5330,  2.7470,  2.5212,  2.9471,  2.5805,
          2.7102,  2.9200,  1.2834,  1.2883,  1.2417,  1.2836,  1.3108,  1.3102,
          1.3111,  1.3093,  1.3093,  1.3116,  1.2630,  1.3323,  1.3356,  1.2941,
          1.3338,  1.3368,  1.3063,  1.3326,  1.7519,  1.7638,  1.7199,  1.7514,
          1.7616,  1.7629,  1.7165,  1.7082,  1.7506,  1.5600,  1.5975,  1.5937,
          1.5869,  1.5203,  1.5923,  1.5361,  1.5832,  1.5851],
        [ 1.2751,  1.2778,  1.2794,  1.2795,  1.2777,  1.2756,  1.2760,  1.2748,
          1.2748,  1.3431,  1.3454,  1.3444,  1.3475,  1.3422,  1.2902,  1.3436,
          1.2813,  1.3313,  2.6660,  2.7663,  2.8179,  2.6750,  2.6061,  2.6030,
          2.7426,  2.5979,  2.5979,  1.2759,  1.3057,  1.3152,  1.3183,  1.2766,
          1.3166,  1.3194,  1.3151,  1.3155,  1.7422,  1.7533,  1.7468,  1.6810,
          1.7513,  1.7492,  1.7437,  1.7283,  1.6801,  1.6029,  1.5860,  1.5825,
          1.5762,  1.5801,  1.5812,  1.5949,  1.5704,  1.5744],
        [ 1.2823,  1.2851,  1.2867,  1.2870,  1.2850,  1.2828,  1.2833,  1.2820,
          1.2820,  1.3502,  1.3525,  1.3515,  1.3351,  1.3492,  1.2846,  1.3507,
          1.3468,  1.2830,  1.3032,  1.2829,  1.3045,  1.3042,  1.3007,  1.3002,
          1.2999,  1.2993,  1.2993,  2.8309,  2.7645,  2.5662,  2.6134,  2.8295,
          2.5748,  2.7448,  2.6216,  2.5679,  1.7462,  1.7576,  1.7241,  1.7435,
          1.7555,  1.7535,  1.7209,  1.7200,  1.7425,  1.6082,  1.5908,  1.5235,
          1.5267,  1.6046,  1.5858,  1.6197,  1.5209,  1.5788],
        [ 1.8894,  1.4908,  0.6410,  0.9654,  1.3853,  1.8200,  1.6929,  1.9253,
          1.9253,  1.7330,  1.3646,  1.5718,  0.9745,  1.7784,  0.1647,  1.6704,
          1.9489,  0.8873,  1.3926,  1.0506,  0.8033,  1.2012,  1.7618,  1.8281,
          1.5914,  1.9341,  1.9341,  0.8958,  0.8926,  1.9070,  1.6974,  0.9046,
          1.8477,  1.3038,  1.9557,  1.8714, -0.1269, -0.3703, -0.4138, -0.1720,
          0.0797,  0.1713, -0.2532, 16.9719,  3.7851,  0.2592,  0.6223,  0.6469,
          0.7583,  0.4114,  0.7591, -0.0303,  0.7916,  0.8549],
        [ 1.3356,  1.3727,  1.4122,  1.4047,  1.3796,  1.3427,  1.3131,  1.3319,
          1.3319,  1.3076,  1.4279,  1.3252,  1.4558,  1.3845,  1.4813,  1.3143,
          1.3598,  1.3707,  1.3931,  1.3683,  1.4257,  1.4067,  1.3599,  1.3530,
          1.2510,  1.3416,  1.3416,  1.3905,  1.4389,  1.3568,  1.1478,  1.3476,
          1.2456,  1.4133,  1.2345,  1.3609,  0.3423,  0.2661,  0.3798,  0.3493,
          0.1414,  0.0945,  0.3659,  0.1402, -0.0686,  3.4317,  2.2924,  3.3993,
          2.6267,  1.8356,  1.4315,  2.8546,  3.2458,  1.3960]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 303 : 174.68477412862563
Test loss for epoch 303 : 174.88617141182638
Test Precision for epoch 303 : 0.26153846153846155
Test Recall for epoch 303 : 0.26153846153846155
Test F1 for epoch 303 : 0.26153846153846155


theta for epoch 304 : tensor([[ 2.6166,  2.6354,  2.6725,  2.7841,  2.7652,  2.6198,  2.7523,  2.6149,
          2.6149,  1.3374,  1.3396,  1.3387,  1.3417,  1.3365,  1.3437,  1.3379,
          1.3348,  1.2970,  1.2903,  1.2480,  1.2488,  1.2913,  1.2879,  1.2874,
          1.2896,  1.2866,  1.2866,  1.2710,  1.3155,  1.3094,  1.3125,  1.3156,
          1.3108,  1.3136,  1.2655,  1.3097,  1.7387,  1.7496,  1.7432,  1.7393,
          1.7476,  1.6871,  1.7401,  1.7252,  1.7384,  1.5978,  1.5812,  1.5777,
          1.5714,  1.5943,  1.5764,  1.6087,  1.5679,  1.5698],
        [ 1.2922,  1.2951,  1.2806,  1.2807,  1.2958,  1.2929,  1.2938,  1.2920,
          1.2920,  2.5803,  2.5925,  2.5348,  2.7492,  2.5229,  2.9478,  2.5812,
          2.7124,  2.9207,  1.2835,  1.2884,  1.2418,  1.2837,  1.3108,  1.3103,
          1.3112,  1.3094,  1.3094,  1.3115,  1.2629,  1.3321,  1.3355,  1.2945,
          1.3337,  1.3367,  1.3062,  1.3325,  1.7520,  1.7639,  1.7200,  1.7515,
          1.7617,  1.7630,  1.7166,  1.7091,  1.7507,  1.5593,  1.5968,  1.5930,
          1.5863,  1.5196,  1.5916,  1.5354,  1.5825,  1.5844],
        [ 1.2750,  1.2777,  1.2792,  1.2794,  1.2775,  1.2755,  1.2758,  1.2747,
          1.2747,  1.3431,  1.3453,  1.3443,  1.3474,  1.3421,  1.2901,  1.3435,
          1.2812,  1.3312,  2.6673,  2.7680,  2.8195,  2.6763,  2.6074,  2.6043,
          2.7443,  2.5992,  2.5992,  1.2757,  1.3056,  1.3151,  1.3182,  1.2764,
          1.3165,  1.3193,  1.3150,  1.3154,  1.7424,  1.7535,  1.7470,  1.6811,
          1.7514,  1.7493,  1.7439,  1.7284,  1.6801,  1.6023,  1.5854,  1.5819,
          1.5755,  1.5795,  1.5805,  1.5943,  1.5697,  1.5738],
        [ 1.2822,  1.2850,  1.2865,  1.2868,  1.2849,  1.2827,  1.2832,  1.2819,
          1.2819,  1.3501,  1.3524,  1.3514,  1.3350,  1.3491,  1.2848,  1.3506,
          1.3467,  1.2832,  1.3032,  1.2829,  1.3045,  1.3043,  1.3007,  1.3002,
          1.2999,  1.2994,  1.2994,  2.8320,  2.7654,  2.5678,  2.6142,  2.8306,
          2.5764,  2.7458,  2.6233,  2.5696,  1.7463,  1.7577,  1.7243,  1.7436,
          1.7556,  1.7536,  1.7210,  1.7205,  1.7426,  1.6076,  1.5902,  1.5232,
          1.5261,  1.6040,  1.5852,  1.6191,  1.5202,  1.5782],
        [ 1.8889,  1.4901,  0.6401,  0.9644,  1.3847,  1.8194,  1.6923,  1.9248,
          1.9248,  1.7319,  1.3635,  1.5711,  0.9737,  1.7777,  0.1636,  1.6694,
          1.9484,  0.8860,  1.3919,  1.0501,  0.8026,  1.2004,  1.7612,  1.8275,
          1.5910,  1.9336,  1.9336,  0.8950,  0.8916,  1.9063,  1.6965,  0.9036,
          1.8470,  1.3029,  1.9551,  1.8707, -0.1265, -0.3698, -0.4133, -0.1717,
          0.0800,  0.1715, -0.2528, 17.0166,  3.7590,  0.2582,  0.6213,  0.6458,
          0.7572,  0.4104,  0.7580, -0.0313,  0.7906,  0.8538],
        [ 1.3368,  1.3738,  1.4131,  1.4058,  1.3807,  1.3438,  1.3142,  1.3330,
          1.3330,  1.3090,  1.4292,  1.3266,  1.4571,  1.3858,  1.4826,  1.3157,
          1.3611,  1.3720,  1.3944,  1.3696,  1.4270,  1.4081,  1.3613,  1.3544,
          1.2522,  1.3430,  1.3430,  1.3915,  1.4400,  1.3580,  1.1490,  1.3486,
          1.2468,  1.4145,  1.2357,  1.3621,  0.3437,  0.2674,  0.3811,  0.3506,
          0.1428,  0.0958,  0.3672,  0.1415, -0.0672,  3.4335,  2.2914,  3.4007,
          2.6261,  1.8343,  1.4301,  2.8540,  3.2480,  1.3947]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 304 : 174.67512826364714
Test loss for epoch 304 : 174.88219604079634
Test Precision for epoch 304 : 0.26153846153846155
Test Recall for epoch 304 : 0.26153846153846155
Test F1 for epoch 304 : 0.26153846153846155


theta for epoch 305 : tensor([[ 2.6178,  2.6367,  2.6737,  2.7855,  2.7666,  2.6210,  2.7536,  2.6161,
          2.6161,  1.3373,  1.3395,  1.3385,  1.3416,  1.3364,  1.3436,  1.3378,
          1.3347,  1.2968,  1.2899,  1.2477,  1.2484,  1.2909,  1.2875,  1.2870,
          1.2892,  1.2862,  1.2862,  1.2709,  1.3154,  1.3093,  1.3124,  1.3155,
          1.3107,  1.3135,  1.2654,  1.3096,  1.7384,  1.7493,  1.7430,  1.7391,
          1.7473,  1.6869,  1.7399,  1.7249,  1.7381,  1.5984,  1.5818,  1.5783,
          1.5721,  1.5949,  1.5770,  1.6093,  1.5686,  1.5704],
        [ 1.2920,  1.2948,  1.2809,  1.2809,  1.2955,  1.2927,  1.2936,  1.2918,
          1.2918,  2.5810,  2.5932,  2.5367,  2.7514,  2.5247,  2.9486,  2.5819,
          2.7147,  2.9215,  1.2830,  1.2879,  1.2413,  1.2833,  1.3104,  1.3098,
          1.3107,  1.3089,  1.3089,  1.3113,  1.2627,  1.3319,  1.3353,  1.2947,
          1.3335,  1.3365,  1.3060,  1.3323,  1.7517,  1.7636,  1.7196,  1.7512,
          1.7614,  1.7627,  1.7162,  1.7095,  1.7504,  1.5599,  1.5975,  1.5936,
          1.5868,  1.5202,  1.5922,  1.5360,  1.5830,  1.5850],
        [ 1.2748,  1.2776,  1.2790,  1.2793,  1.2774,  1.2754,  1.2757,  1.2746,
          1.2746,  1.3430,  1.3452,  1.3442,  1.3473,  1.3420,  1.2900,  1.3435,
          1.2810,  1.3312,  2.6682,  2.7694,  2.8208,  2.6773,  2.6083,  2.6052,
          2.7456,  2.6001,  2.6001,  1.2755,  1.3055,  1.3150,  1.3181,  1.2762,
          1.3164,  1.3192,  1.3149,  1.3153,  1.7421,  1.7532,  1.7467,  1.6807,
          1.7512,  1.7490,  1.7436,  1.7282,  1.6797,  1.6029,  1.5861,  1.5825,
          1.5762,  1.5801,  1.5812,  1.5949,  1.5703,  1.5745],
        [ 1.2820,  1.2848,  1.2863,  1.2866,  1.2847,  1.2825,  1.2830,  1.2817,
          1.2817,  1.3499,  1.3522,  1.3512,  1.3348,  1.3490,  1.2849,  1.3504,
          1.3465,  1.2833,  1.3029,  1.2824,  1.3042,  1.3039,  1.3004,  1.2998,
          1.2995,  1.2990,  1.2990,  2.8330,  2.7663,  2.5694,  2.6150,  2.8316,
          2.5780,  2.7466,  2.6250,  2.5712,  1.7460,  1.7574,  1.7239,  1.7432,
          1.7553,  1.7532,  1.7207,  1.7205,  1.7422,  1.6081,  1.5907,  1.5241,
          1.5267,  1.6045,  1.5857,  1.6196,  1.5207,  1.5788],
        [ 1.8901,  1.4916,  0.6419,  0.9659,  1.3862,  1.8208,  1.6937,  1.9261,
          1.9261,  1.7332,  1.3651,  1.5727,  0.9756,  1.7792,  0.1654,  1.6707,
          1.9498,  0.8878,  1.3935,  1.0519,  0.8044,  1.2022,  1.7627,  1.8289,
          1.5926,  1.9350,  1.9350,  0.8969,  0.8934,  1.9078,  1.6980,  0.9053,
          1.8486,  1.3045,  1.9566,  1.8722, -0.1285, -0.3717, -0.4152, -0.1738,
          0.0779,  0.1693, -0.2547, 17.0588,  3.7302,  0.2602,  0.6233,  0.6477,
          0.7593,  0.4125,  0.7601, -0.0291,  0.7927,  0.8558],
        [ 1.3353,  1.3723,  1.4115,  1.4043,  1.3792,  1.3423,  1.3127,  1.3315,
          1.3315,  1.3073,  1.4275,  1.3248,  1.4554,  1.3841,  1.4809,  1.3140,
          1.3594,  1.3703,  1.3926,  1.3675,  1.4252,  1.4063,  1.3595,  1.3526,
          1.2502,  1.3412,  1.3412,  1.3898,  1.4385,  1.3564,  1.1474,  1.3469,
          1.2453,  1.4130,  1.2341,  1.3605,  0.3419,  0.2657,  0.3793,  0.3488,
          0.1410,  0.0939,  0.3654,  0.1396, -0.0690,  3.4386,  2.2937,  3.4056,
          2.6289,  1.8363,  1.4321,  2.8567,  3.2537,  1.3966]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 305 : 174.66592715609707
Test loss for epoch 305 : 174.87351562661874
Test Precision for epoch 305 : 0.26153846153846155
Test Recall for epoch 305 : 0.26153846153846155
Test F1 for epoch 305 : 0.26153846153846155


theta for epoch 306 : tensor([[ 2.6191,  2.6380,  2.6750,  2.7870,  2.7680,  2.6223,  2.7551,  2.6174,
          2.6174,  1.3372,  1.3394,  1.3385,  1.3415,  1.3363,  1.3435,  1.3377,
          1.3346,  1.2968,  1.2902,  1.2479,  1.2487,  1.2912,  1.2878,  1.2873,
          1.2894,  1.2864,  1.2864,  1.2708,  1.3153,  1.3092,  1.3123,  1.3154,
          1.3106,  1.3134,  1.2653,  1.3095,  1.7387,  1.7496,  1.7432,  1.7393,
          1.7476,  1.6871,  1.7401,  1.7252,  1.7384,  1.5972,  1.5806,  1.5771,
          1.5709,  1.5938,  1.5758,  1.6082,  1.5674,  1.5692],
        [ 1.2919,  1.2948,  1.2813,  1.2813,  1.2955,  1.2926,  1.2935,  1.2917,
          1.2917,  2.5815,  2.5939,  2.5384,  2.7536,  2.5264,  2.9493,  2.5825,
          2.7169,  2.9223,  1.2833,  1.2882,  1.2416,  1.2836,  1.3107,  1.3101,
          1.3111,  1.3092,  1.3092,  1.3112,  1.2627,  1.3319,  1.3352,  1.2951,
          1.3334,  1.3364,  1.3059,  1.3322,  1.7519,  1.7638,  1.7198,  1.7515,
          1.7616,  1.7629,  1.7165,  1.7104,  1.7506,  1.5586,  1.5962,  1.5924,
          1.5856,  1.5189,  1.5909,  1.5347,  1.5818,  1.5837],
        [ 1.2748,  1.2775,  1.2789,  1.2792,  1.2774,  1.2753,  1.2757,  1.2745,
          1.2745,  1.3429,  1.3451,  1.3442,  1.3472,  1.3420,  1.2899,  1.3434,
          1.2809,  1.3311,  2.6697,  2.7712,  2.8226,  2.6787,  2.6098,  2.6066,
          2.7475,  2.6016,  2.6016,  1.2753,  1.3055,  1.3149,  1.3180,  1.2760,
          1.3163,  1.3191,  1.3148,  1.3152,  1.7424,  1.7535,  1.7470,  1.6808,
          1.7514,  1.7492,  1.7439,  1.7285,  1.6799,  1.6017,  1.5849,  1.5813,
          1.5750,  1.5790,  1.5800,  1.5937,  1.5690,  1.5733],
        [ 1.2819,  1.2847,  1.2862,  1.2866,  1.2846,  1.2824,  1.2829,  1.2816,
          1.2816,  1.3499,  1.3522,  1.3512,  1.3347,  1.3489,  1.2850,  1.3504,
          1.3464,  1.2834,  1.3031,  1.2826,  1.3044,  1.3041,  1.3006,  1.3001,
          1.2997,  1.2992,  1.2992,  2.8341,  2.7673,  2.5711,  2.6159,  2.8328,
          2.5797,  2.7476,  2.6268,  2.5729,  1.7463,  1.7577,  1.7242,  1.7434,
          1.7556,  1.7534,  1.7210,  1.7212,  1.7424,  1.6070,  1.5896,  1.5232,
          1.5256,  1.6034,  1.5846,  1.6185,  1.5195,  1.5776],
        [ 1.8891,  1.4903,  0.6401,  0.9642,  1.3848,  1.8196,  1.6925,  1.9251,
          1.9251,  1.7314,  1.3632,  1.5712,  0.9738,  1.7778,  0.1634,  1.6689,
          1.9486,  0.8855,  1.3920,  1.0506,  0.8028,  1.2006,  1.7614,  1.8277,
          1.5915,  1.9338,  1.9338,  0.8953,  0.8915,  1.9065,  1.6964,  0.9034,
          1.8472,  1.3027,  1.9553,  1.8708, -0.1273, -0.3705, -0.4140, -0.1727,
          0.0790,  0.1703, -0.2536, 17.1042,  3.7050,  0.2582,  0.6213,  0.6456,
          0.7572,  0.4104,  0.7580, -0.0311,  0.7906,  0.8538],
        [ 1.3373,  1.3744,  1.4134,  1.4063,  1.3812,  1.3444,  1.3147,  1.3336,
          1.3336,  1.3097,  1.4299,  1.3272,  1.4578,  1.3865,  1.4832,  1.3164,
          1.3617,  1.3727,  1.3951,  1.3699,  1.4277,  1.4087,  1.3620,  1.3551,
          1.2526,  1.3436,  1.3436,  1.3918,  1.4406,  1.3585,  1.1496,  1.3489,
          1.2474,  1.4151,  1.2363,  1.3627,  0.3443,  0.2681,  0.3817,  0.3512,
          0.1434,  0.0963,  0.3678,  0.1419, -0.0666,  3.4392,  2.2915,  3.4058,
          2.6272,  1.8338,  1.4295,  2.8549,  3.2547,  1.3941]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 306 : 174.65762321490286
Test loss for epoch 306 : 174.87259760081432
Test Precision for epoch 306 : 0.26153846153846155
Test Recall for epoch 306 : 0.26153846153846155
Test F1 for epoch 306 : 0.26153846153846155


theta for epoch 307 : tensor([[ 2.6202,  2.6391,  2.6762,  2.7883,  2.7693,  2.6235,  2.7564,  2.6186,
          2.6186,  1.3371,  1.3393,  1.3383,  1.3413,  1.3362,  1.3434,  1.3376,
          1.3345,  1.2966,  1.2896,  1.2473,  1.2481,  1.2906,  1.2872,  1.2867,
          1.2888,  1.2858,  1.2858,  1.2707,  1.3152,  1.3091,  1.3121,  1.3152,
          1.3105,  1.3133,  1.2652,  1.3094,  1.7382,  1.7491,  1.7428,  1.7389,
          1.7471,  1.6867,  1.7397,  1.7247,  1.7380,  1.5985,  1.5819,  1.5784,
          1.5722,  1.5950,  1.5771,  1.6094,  1.5686,  1.5705],
        [ 1.2916,  1.2945,  1.2814,  1.2814,  1.2952,  1.2923,  1.2932,  1.2914,
          1.2914,  2.5822,  2.5947,  2.5403,  2.7559,  2.5282,  2.9502,  2.5832,
          2.7192,  2.9231,  1.2825,  1.2874,  1.2408,  1.2829,  1.3099,  1.3093,
          1.3103,  1.3085,  1.3085,  1.3110,  1.2625,  1.3316,  1.3349,  1.2953,
          1.3331,  1.3361,  1.3057,  1.3319,  1.7514,  1.7633,  1.7193,  1.7510,
          1.7611,  1.7624,  1.7159,  1.7107,  1.7501,  1.5599,  1.5975,  1.5937,
          1.5869,  1.5202,  1.5922,  1.5360,  1.5830,  1.5850],
        [ 1.2746,  1.2773,  1.2787,  1.2791,  1.2772,  1.2751,  1.2755,  1.2743,
          1.2743,  1.3428,  1.3450,  1.3441,  1.3471,  1.3419,  1.2897,  1.3433,
          1.2808,  1.3310,  2.6704,  2.7724,  2.8236,  2.6795,  2.6105,  2.6073,
          2.7486,  2.6023,  2.6023,  1.2751,  1.3054,  1.3148,  1.3179,  1.2758,
          1.3162,  1.3191,  1.3147,  1.3151,  1.7420,  1.7531,  1.7466,  1.6803,
          1.7510,  1.7487,  1.7435,  1.7281,  1.6793,  1.6030,  1.5862,  1.5827,
          1.5763,  1.5803,  1.5813,  1.5951,  1.5703,  1.5746],
        [ 1.2817,  1.2845,  1.2859,  1.2863,  1.2844,  1.2822,  1.2827,  1.2814,
          1.2814,  1.3497,  1.3520,  1.3510,  1.3345,  1.3487,  1.2851,  1.3502,
          1.3463,  1.2835,  1.3025,  1.2819,  1.3038,  1.3035,  1.3000,  1.2994,
          1.2990,  1.2986,  1.2986,  2.8352,  2.7682,  2.5727,  2.6167,  2.8338,
          2.5813,  2.7485,  2.6284,  2.5744,  1.7458,  1.7572,  1.7237,  1.7429,
          1.7551,  1.7529,  1.7205,  1.7210,  1.7419,  1.6082,  1.5908,  1.5247,
          1.5268,  1.6046,  1.5858,  1.6196,  1.5206,  1.5789],
        [ 1.8912,  1.4928,  0.6431,  0.9668,  1.3875,  1.8218,  1.6948,  1.9271,
          1.9271,  1.7338,  1.3660,  1.5739,  0.9770,  1.7804,  0.1666,  1.6714,
          1.9510,  0.8886,  1.3948,  1.0536,  0.8059,  1.2035,  1.7638,  1.8300,
          1.5942,  1.9360,  1.9360,  0.8984,  0.8946,  1.9090,  1.6989,  0.9065,
          1.8498,  1.3056,  1.9577,  1.8734, -0.1304, -0.3734, -0.4169, -0.1759,
          0.0758,  0.1669, -0.2565, 17.1453,  3.6748,  0.2617,  0.6248,  0.6490,
          0.7607,  0.4140,  0.7615, -0.0275,  0.7942,  0.8573],
        [ 1.3346,  1.3716,  1.4105,  1.4036,  1.3785,  1.3416,  1.3120,  1.3308,
          1.3308,  1.3066,  1.4268,  1.3240,  1.4546,  1.3834,  1.4801,  1.3133,
          1.3586,  1.3695,  1.3918,  1.3663,  1.4244,  1.4055,  1.3587,  1.3518,
          1.2490,  1.3403,  1.3403,  1.3888,  1.4378,  1.3557,  1.1466,  1.3460,
          1.2446,  1.4123,  1.2334,  1.3598,  0.3411,  0.2648,  0.3785,  0.3479,
          0.1401,  0.0930,  0.3646,  0.1385, -0.0699,  3.4459,  2.2954,  3.4123,
          2.6316,  1.8374,  1.4331,  2.8592,  3.2620,  1.3976]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 307 : 174.6508917633267
Test loss for epoch 307 : 174.86398344918808
Test Precision for epoch 307 : 0.26153846153846155
Test Recall for epoch 307 : 0.26153846153846155
Test F1 for epoch 307 : 0.26153846153846155


theta for epoch 308 : tensor([[ 2.6216,  2.6404,  2.6775,  2.7898,  2.7708,  2.6248,  2.7579,  2.6199,
          2.6199,  1.3370,  1.3392,  1.3383,  1.3413,  1.3361,  1.3433,  1.3375,
          1.3344,  1.2966,  1.2901,  1.2479,  1.2486,  1.2911,  1.2877,  1.2872,
          1.2894,  1.2864,  1.2864,  1.2706,  1.3151,  1.3090,  1.3121,  1.3151,
          1.3104,  1.3132,  1.2651,  1.3093,  1.7388,  1.7497,  1.7434,  1.7395,
          1.7477,  1.6873,  1.7403,  1.7253,  1.7385,  1.5965,  1.5799,  1.5764,
          1.5702,  1.5931,  1.5751,  1.6075,  1.5666,  1.5685],
        [ 1.2916,  1.2944,  1.2819,  1.2818,  1.2951,  1.2922,  1.2932,  1.2914,
          1.2914,  2.5827,  2.5953,  2.5421,  2.7580,  2.5298,  2.9509,  2.5838,
          2.7213,  2.9238,  1.2832,  1.2881,  1.2415,  1.2836,  1.3105,  1.3100,
          1.3110,  1.3091,  1.3091,  1.3109,  1.2625,  1.3315,  1.3349,  1.2957,
          1.3331,  1.3361,  1.3056,  1.3319,  1.7519,  1.7638,  1.7198,  1.7515,
          1.7616,  1.7630,  1.7164,  1.7119,  1.7507,  1.5578,  1.5953,  1.5915,
          1.5847,  1.5181,  1.5901,  1.5339,  1.5809,  1.5829],
        [ 1.2745,  1.2773,  1.2786,  1.2790,  1.2771,  1.2751,  1.2754,  1.2743,
          1.2743,  1.3427,  1.3449,  1.3440,  1.3470,  1.3418,  1.2896,  1.3432,
          1.2806,  1.3309,  2.6722,  2.7745,  2.8257,  2.6812,  2.6122,  2.6091,
          2.7508,  2.6040,  2.6040,  1.2749,  1.3052,  1.3147,  1.3178,  1.2756,
          1.3161,  1.3189,  1.3146,  1.3150,  1.7425,  1.7536,  1.7472,  1.6807,
          1.7516,  1.7492,  1.7440,  1.7286,  1.6798,  1.6010,  1.5842,  1.5807,
          1.5743,  1.5783,  1.5793,  1.5931,  1.5682,  1.5726],
        [ 1.2816,  1.2844,  1.2857,  1.2863,  1.2843,  1.2821,  1.2826,  1.2813,
          1.2813,  1.3496,  1.3519,  1.3509,  1.3345,  1.3487,  1.2852,  1.3501,
          1.3462,  1.2837,  1.3030,  1.2824,  1.3043,  1.3040,  1.3005,  1.2999,
          1.2994,  1.2991,  1.2991,  2.8364,  2.7692,  2.5744,  2.6177,  2.8350,
          2.5830,  2.7495,  2.6302,  2.5761,  1.7464,  1.7578,  1.7243,  1.7434,
          1.7557,  1.7534,  1.7210,  1.7219,  1.7424,  1.6063,  1.5889,  1.5231,
          1.5249,  1.6027,  1.5839,  1.6177,  1.5186,  1.5769],
        [ 1.8889,  1.4900,  0.6397,  0.9635,  1.3846,  1.8195,  1.6923,  1.9249,
          1.9249,  1.7305,  1.3623,  1.5709,  0.9735,  1.7774,  0.1626,  1.6681,
          1.9484,  0.8844,  1.3917,  1.0506,  0.8025,  1.2002,  1.7612,  1.8275,
          1.5917,  1.9336,  1.9336,  0.8950,  0.8909,  1.9062,  1.6958,  0.9027,
          1.8469,  1.3022,  1.9550,  1.8706, -0.1277, -0.3707, -0.4142, -0.1733,
          0.0785,  0.1695, -0.2538, 17.1923,  3.6514,  0.2577,  0.6207,  0.6448,
          0.7566,  0.4099,  0.7574, -0.0315,  0.7902,  0.8532],
        [ 1.3384,  1.3754,  1.4140,  1.4073,  1.3822,  1.3454,  1.3158,  1.3346,
          1.3346,  1.3111,  1.4312,  1.3284,  1.4590,  1.3877,  1.4844,  1.3177,
          1.3629,  1.3739,  1.3964,  1.3708,  1.4289,  1.4100,  1.3633,  1.3564,
          1.2535,  1.3449,  1.3449,  1.3926,  1.4417,  1.3596,  1.1508,  1.3497,
          1.2485,  1.4162,  1.2374,  1.3638,  0.3455,  0.2693,  0.3829,  0.3523,
          0.1446,  0.0975,  0.3690,  0.1430, -0.0653,  3.4443,  2.2910,  3.4103,
          2.6276,  1.8327,  1.4284,  2.8553,  3.2608,  1.3929]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 308 : 174.6475066355025
Test loss for epoch 308 : 174.87135303655432
Test Precision for epoch 308 : 0.26153846153846155
Test Recall for epoch 308 : 0.26153846153846155
Test F1 for epoch 308 : 0.26153846153846155


theta for epoch 309 : tensor([[ 2.6227,  2.6416,  2.6786,  2.7911,  2.7721,  2.6259,  2.7592,  2.6210,
          2.6210,  1.3368,  1.3390,  1.3381,  1.3411,  1.3359,  1.3431,  1.3373,
          1.3342,  1.2964,  1.2890,  1.2468,  1.2475,  1.2900,  1.2866,  1.2861,
          1.2883,  1.2853,  1.2853,  1.2704,  1.3149,  1.3088,  1.3119,  1.3150,
          1.3102,  1.3130,  1.2649,  1.3091,  1.7379,  1.7488,  1.7425,  1.7386,
          1.7468,  1.6864,  1.7394,  1.7244,  1.7377,  1.5989,  1.5823,  1.5789,
          1.5726,  1.5955,  1.5775,  1.6099,  1.5691,  1.5709],
        [ 1.2912,  1.2940,  1.2820,  1.2818,  1.2947,  1.2918,  1.2928,  1.2910,
          1.2910,  2.5835,  2.5962,  2.5441,  2.7604,  2.5318,  2.9518,  2.5847,
          2.7238,  2.9248,  1.2818,  1.2867,  1.2401,  1.2822,  1.3092,  1.3086,
          1.3097,  1.3078,  1.3078,  1.3106,  1.2622,  1.3312,  1.3345,  1.2958,
          1.3327,  1.3358,  1.3053,  1.3315,  1.7509,  1.7628,  1.7189,  1.7506,
          1.7607,  1.7620,  1.7155,  1.7117,  1.7497,  1.5603,  1.5978,  1.5940,
          1.5872,  1.5206,  1.5926,  1.5363,  1.5834,  1.5854],
        [ 1.2744,  1.2771,  1.2783,  1.2788,  1.2769,  1.2749,  1.2752,  1.2741,
          1.2741,  1.3426,  1.3448,  1.3438,  1.3469,  1.3416,  1.2894,  1.3430,
          1.2805,  1.3308,  2.6727,  2.7754,  2.8264,  2.6817,  2.6126,  2.6095,
          2.7516,  2.6045,  2.6045,  1.2747,  1.3052,  1.3146,  1.3177,  1.2754,
          1.3160,  1.3188,  1.3145,  1.3149,  1.7417,  1.7528,  1.7463,  1.6797,
          1.7508,  1.7483,  1.7432,  1.7278,  1.6788,  1.6035,  1.5867,  1.5832,
          1.5768,  1.5808,  1.5818,  1.5955,  1.5706,  1.5751],
        [ 1.2813,  1.2841,  1.2854,  1.2860,  1.2841,  1.2819,  1.2823,  1.2811,
          1.2811,  1.3494,  1.3517,  1.3506,  1.3342,  1.3484,  1.2852,  1.3499,
          1.3459,  1.2836,  1.3019,  1.2813,  1.3032,  1.3030,  1.2994,  1.2989,
          1.2983,  1.2980,  1.2980,  2.8375,  2.7701,  2.5759,  2.6185,  2.8361,
          2.5845,  2.7504,  2.6318,  2.5777,  1.7454,  1.7569,  1.7234,  1.7424,
          1.7548,  1.7524,  1.7201,  1.7213,  1.7414,  1.6085,  1.5911,  1.5257,
          1.5271,  1.6049,  1.5861,  1.6200,  1.5209,  1.5792],
        [ 1.8927,  1.4946,  0.6451,  0.9684,  1.3893,  1.8234,  1.6965,  1.9286,
          1.9286,  1.7350,  1.3675,  1.5758,  0.9791,  1.7821,  0.1686,  1.6727,
          1.9527,  0.8904,  1.3967,  1.0559,  0.8081,  1.2054,  1.7655,  1.8317,
          1.5963,  1.9376,  1.9376,  0.9007,  0.8966,  1.9107,  1.7005,  0.9084,
          1.8516,  1.3074,  1.9594,  1.8751, -0.1329, -0.3757, -0.4192, -0.1786,
          0.0731,  0.1639, -0.2590, 17.2310,  3.6186,  0.2641,  0.6271,  0.6512,
          0.7630,  0.4163,  0.7638, -0.0250,  0.7966,  0.8596],
        [ 1.3332,  1.3703,  1.4088,  1.4022,  1.3771,  1.3403,  1.3106,  1.3295,
          1.3295,  1.3052,  1.4254,  1.3225,  1.4531,  1.3818,  1.4785,  1.3119,
          1.3570,  1.3680,  1.3902,  1.3643,  1.4228,  1.4039,  1.3571,  1.3502,
          1.2469,  1.3388,  1.3388,  1.3871,  1.4365,  1.3544,  1.1452,  1.3443,
          1.2432,  1.4110,  1.2320,  1.3585,  0.3395,  0.2632,  0.3769,  0.3463,
          0.1385,  0.0913,  0.3630,  0.1368, -0.0715,  3.4540,  2.2979,  3.4198,
          2.6350,  1.8393,  1.4349,  2.8626,  3.2711,  1.3994]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 309 : 174.64967713538957
Test loss for epoch 309 : 174.8669263139391
Test Precision for epoch 309 : 0.26153846153846155
Test Recall for epoch 309 : 0.26153846153846155
Test F1 for epoch 309 : 0.26153846153846155


theta for epoch 310 : tensor([[ 2.6242,  2.6431,  2.6802,  2.7928,  2.7738,  2.6275,  2.7609,  2.6226,
          2.6226,  1.3368,  1.3390,  1.3380,  1.3411,  1.3359,  1.3431,  1.3373,
          1.3342,  1.2963,  1.2902,  1.2479,  1.2487,  1.2912,  1.2878,  1.2873,
          1.2895,  1.2865,  1.2865,  1.2704,  1.3149,  1.3088,  1.3118,  1.3149,
          1.3102,  1.3130,  1.2649,  1.3091,  1.7390,  1.7499,  1.7435,  1.7396,
          1.7479,  1.6874,  1.7404,  1.7255,  1.7387,  1.5951,  1.5785,  1.5750,
          1.5687,  1.5916,  1.5737,  1.6060,  1.5652,  1.5671],
        [ 1.2913,  1.2942,  1.2825,  1.2824,  1.2948,  1.2920,  1.2929,  1.2911,
          1.2911,  2.5840,  2.5968,  2.5458,  2.7624,  2.5334,  2.9525,  2.5853,
          2.7259,  2.9254,  1.2833,  1.2881,  1.2415,  1.2837,  1.3106,  1.3101,
          1.3111,  1.3092,  1.3092,  1.3106,  1.2622,  1.3313,  1.3346,  1.2962,
          1.3328,  1.3358,  1.3053,  1.3316,  1.7520,  1.7639,  1.7199,  1.7516,
          1.7617,  1.7631,  1.7165,  1.7133,  1.7508,  1.5562,  1.5937,  1.5899,
          1.5832,  1.5165,  1.5885,  1.5323,  1.5793,  1.5813],
        [ 1.2743,  1.2771,  1.2782,  1.2788,  1.2769,  1.2749,  1.2752,  1.2741,
          1.2741,  1.3425,  1.3447,  1.3437,  1.3468,  1.3415,  1.2893,  1.3430,
          1.2803,  1.3307,  2.6750,  2.7781,  2.8290,  2.6840,  2.6150,  2.6118,
          2.7543,  2.6068,  2.6068,  1.2745,  1.3050,  1.3145,  1.3176,  1.2752,
          1.3159,  1.3187,  1.3144,  1.3148,  1.7427,  1.7538,  1.7474,  1.6806,
          1.7518,  1.7493,  1.7442,  1.7288,  1.6797,  1.5996,  1.5828,  1.5792,
          1.5729,  1.5769,  1.5779,  1.5916,  1.5666,  1.5712],
        [ 1.2814,  1.2842,  1.2854,  1.2860,  1.2841,  1.2819,  1.2824,  1.2811,
          1.2811,  1.3494,  1.3517,  1.3507,  1.3342,  1.3484,  1.2854,  1.3499,
          1.3460,  1.2838,  1.3030,  1.2823,  1.3043,  1.3040,  1.3005,  1.3000,
          1.2994,  1.2991,  1.2991,  2.8388,  2.7713,  2.5778,  2.6196,  2.8375,
          2.5864,  2.7516,  2.6337,  2.5795,  1.7465,  1.7579,  1.7244,  1.7434,
          1.7558,  1.7534,  1.7212,  1.7227,  1.7424,  1.6048,  1.5874,  1.5222,
          1.5234,  1.6012,  1.5825,  1.6163,  1.5171,  1.5755],
        [ 1.8882,  1.4890,  0.6385,  0.9621,  1.3836,  1.8187,  1.6914,  1.9243,
          1.9243,  1.7288,  1.3607,  1.5699,  0.9723,  1.7763,  0.1610,  1.6665,
          1.9476,  0.8825,  1.3907,  1.0499,  0.8014,  1.1991,  1.7603,  1.8267,
          1.5913,  1.9329,  1.9329,  0.8940,  0.8894,  1.9053,  1.6945,  0.9012,
          1.8459,  1.3008,  1.9541,  1.8696, -0.1272, -0.3702, -0.4137, -0.1731,
          0.0788,  0.1695, -0.2534, 17.2809,  3.5988,  0.2562,  0.6193,  0.6432,
          0.7550,  0.4084,  0.7559, -0.0329,  0.7888,  0.8517],
        [ 1.3405,  1.3774,  1.4158,  1.4094,  1.3843,  1.3475,  1.3179,  1.3367,
          1.3367,  1.3136,  1.4336,  1.3308,  1.4613,  1.3900,  1.4868,  1.3202,
          1.3653,  1.3763,  1.3988,  1.3730,  1.4314,  1.4125,  1.3658,  1.3589,
          1.2557,  1.3475,  1.3475,  1.3944,  1.4437,  1.3618,  1.1531,  1.3516,
          1.2507,  1.4183,  1.2397,  1.3659,  0.3480,  0.2717,  0.3854,  0.3547,
          0.1471,  0.0998,  0.3715,  0.1453, -0.0628,  3.4481,  2.2892,  3.4135,
          2.6268,  1.8304,  1.4260,  2.8544,  3.2655,  1.3905]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 310 : 174.66392786659003
Test loss for epoch 310 : 174.89834500317428
Test Precision for epoch 310 : 0.26153846153846155
Test Recall for epoch 310 : 0.26153846153846155
Test F1 for epoch 310 : 0.26153846153846155


theta for epoch 311 : tensor([[ 2.6253,  2.6442,  2.6813,  2.7940,  2.7751,  2.6285,  2.7621,  2.6237,
          2.6237,  1.3365,  1.3387,  1.3378,  1.3408,  1.3356,  1.3428,  1.3370,
          1.3339,  1.2960,  1.2882,  1.2460,  1.2467,  1.2892,  1.2858,  1.2853,
          1.2875,  1.2845,  1.2845,  1.2702,  1.3147,  1.3085,  1.3116,  1.3147,
          1.3099,  1.3128,  1.2646,  1.3088,  1.7374,  1.7483,  1.7419,  1.7380,
          1.7463,  1.6858,  1.7388,  1.7239,  1.7372,  1.5996,  1.5830,  1.5796,
          1.5733,  1.5962,  1.5783,  1.6106,  1.5698,  1.5717],
        [ 1.2907,  1.2936,  1.2824,  1.2822,  1.2942,  1.2914,  1.2923,  1.2905,
          1.2905,  2.5851,  2.5980,  2.5481,  2.7651,  2.5357,  2.9537,  2.5864,
          2.7286,  2.9267,  1.2808,  1.2857,  1.2391,  1.2813,  1.3082,  1.3076,
          1.3087,  1.3067,  1.3067,  1.3101,  1.2618,  1.3308,  1.3341,  1.2962,
          1.3323,  1.3353,  1.3048,  1.3311,  1.7503,  1.7622,  1.7182,  1.7499,
          1.7600,  1.7614,  1.7148,  1.7124,  1.7491,  1.5609,  1.5985,  1.5947,
          1.5878,  1.5212,  1.5932,  1.5369,  1.5840,  1.5860],
        [ 1.2741,  1.2768,  1.2779,  1.2785,  1.2766,  1.2746,  1.2749,  1.2738,
          1.2738,  1.3423,  1.3446,  1.3436,  1.3466,  1.3414,  1.2891,  1.3428,
          1.2801,  1.3306,  2.6749,  2.7784,  2.8292,  2.6839,  2.6148,  2.6116,
          2.7546,  2.6066,  2.6066,  1.2743,  1.3050,  1.3144,  1.3175,  1.2750,
          1.3158,  1.3186,  1.3143,  1.3147,  1.7412,  1.7523,  1.7458,  1.6789,
          1.7502,  1.7477,  1.7426,  1.7273,  1.6781,  1.6043,  1.5875,  1.5840,
          1.5776,  1.5816,  1.5826,  1.5963,  1.5712,  1.5759],
        [ 1.2809,  1.2837,  1.2849,  1.2856,  1.2837,  1.2815,  1.2819,  1.2807,
          1.2807,  1.3490,  1.3513,  1.3503,  1.3339,  1.3480,  1.2853,  1.3495,
          1.3456,  1.2837,  1.3011,  1.2804,  1.3024,  1.3022,  1.2986,  1.2981,
          1.2974,  1.2972,  1.2972,  2.8399,  2.7722,  2.5793,  2.6205,  2.8386,
          2.5879,  2.7525,  2.6353,  2.5810,  1.7448,  1.7562,  1.7227,  1.7416,
          1.7541,  1.7516,  1.7195,  1.7213,  1.7407,  1.6091,  1.5918,  1.5268,
          1.5278,  1.6056,  1.5868,  1.6206,  1.5214,  1.5799],
        [ 1.8951,  1.4975,  0.6485,  0.9712,  1.3923,  1.8259,  1.6991,  1.9310,
          1.9310,  1.7374,  1.3705,  1.5788,  0.9826,  1.7850,  0.1720,  1.6751,
          1.9553,  0.8936,  1.3998,  1.0595,  0.8116,  1.2087,  1.7683,  1.8343,
          1.5995,  1.9401,  1.9401,  0.9043,  0.9000,  1.9135,  1.7033,  0.9118,
          1.8544,  1.3106,  1.9622,  1.8780, -0.1366, -0.3792, -0.4226, -0.1825,
          0.0693,  0.1597, -0.2625, 17.3152,  3.5616,  0.2680,  0.6309,  0.6549,
          0.7668,  0.4202,  0.7677, -0.0211,  0.8006,  0.8634],
        [ 1.3309,  1.3679,  1.4061,  1.3999,  1.3748,  1.3380,  1.3082,  1.3271,
          1.3271,  1.3027,  1.4228,  1.3198,  1.4504,  1.3792,  1.4758,  1.3093,
          1.3544,  1.3654,  1.3874,  1.3610,  1.4200,  1.4011,  1.3544,  1.3475,
          1.2437,  1.3360,  1.3360,  1.3844,  1.4341,  1.3520,  1.1426,  1.3416,
          1.2407,  1.4086,  1.2296,  1.3561,  0.3369,  0.2605,  0.3742,  0.3435,
          0.1358,  0.0884,  0.3604,  0.1339, -0.0743,  3.4633,  2.3017,  3.4285,
          2.6397,  1.8425,  1.4380,  2.8672,  3.2815,  1.4026]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 311 : 174.69292432498202
Test loss for epoch 311 : 174.91202317042652
Test Precision for epoch 311 : 0.26153846153846155
Test Recall for epoch 311 : 0.26153846153846155
Test F1 for epoch 311 : 0.26153846153846155


theta for epoch 312 : tensor([[ 2.6272,  2.6461,  2.6831,  2.7961,  2.7771,  2.6304,  2.7642,  2.6255,
          2.6255,  1.3365,  1.3387,  1.3377,  1.3407,  1.3356,  1.3428,  1.3370,
          1.3339,  1.2960,  1.2904,  1.2481,  1.2489,  1.2914,  1.2880,  1.2875,
          1.2897,  1.2867,  1.2867,  1.2701,  1.3146,  1.3085,  1.3115,  1.3146,
          1.3099,  1.3127,  1.2645,  1.3088,  1.7393,  1.7501,  1.7438,  1.7399,
          1.7482,  1.6877,  1.7407,  1.7257,  1.7390,  1.5927,  1.5761,  1.5726,
          1.5663,  1.5893,  1.5713,  1.6037,  1.5628,  1.5646],
        [ 1.2910,  1.2939,  1.2831,  1.2829,  1.2945,  1.2917,  1.2926,  1.2908,
          1.2908,  2.5855,  2.5986,  2.5497,  2.7671,  2.5372,  2.9543,  2.5869,
          2.7306,  2.9273,  1.2836,  1.2884,  1.2418,  1.2840,  1.3109,  1.3104,
          1.3115,  1.3095,  1.3095,  1.3103,  1.2620,  1.3310,  1.3343,  1.2967,
          1.3325,  1.3355,  1.3050,  1.3313,  1.7522,  1.7641,  1.7201,  1.7518,
          1.7619,  1.7633,  1.7167,  1.7148,  1.7510,  1.5536,  1.5911,  1.5873,
          1.5806,  1.5140,  1.5859,  1.5297,  1.5767,  1.5787],
        [ 1.2741,  1.2768,  1.2778,  1.2785,  1.2766,  1.2746,  1.2749,  1.2738,
          1.2738,  1.3421,  1.3444,  1.3434,  1.3464,  1.3412,  1.2889,  1.3426,
          1.2799,  1.3304,  2.6783,  2.7822,  2.8329,  2.6873,  2.6183,  2.6151,
          2.7584,  2.6101,  2.6101,  1.2740,  1.3048,  1.3142,  1.3173,  1.2747,
          1.3156,  1.3184,  1.3141,  1.3145,  1.7430,  1.7541,  1.7477,  1.6807,
          1.7521,  1.7494,  1.7445,  1.7291,  1.6798,  1.5973,  1.5804,  1.5769,
          1.5705,  1.5746,  1.5755,  1.5893,  1.5640,  1.5688],
        [ 1.2811,  1.2839,  1.2850,  1.2857,  1.2838,  1.2816,  1.2821,  1.2808,
          1.2808,  1.3491,  1.3513,  1.3503,  1.3339,  1.3481,  1.2855,  1.3496,
          1.3456,  1.2839,  1.3032,  1.2823,  1.3045,  1.3042,  1.3007,  1.3002,
          1.2994,  1.2993,  1.2993,  2.8416,  2.7737,  2.5814,  2.6219,  2.8403,
          2.5900,  2.7540,  2.6375,  2.5831,  1.7468,  1.7582,  1.7247,  1.7435,
          1.7561,  1.7535,  1.7215,  1.7236,  1.7426,  1.6025,  1.5851,  1.5204,
          1.5211,  1.5989,  1.5801,  1.6141,  1.5146,  1.5732],
        [ 1.8867,  1.4872,  0.6363,  0.9598,  1.3818,  1.8172,  1.6898,  1.9228,
          1.9228,  1.7263,  1.3582,  1.5679,  0.9701,  1.7744,  0.1583,  1.6640,
          1.9460,  0.8795,  1.3888,  1.0483,  0.7993,  1.1970,  1.7586,  1.8250,
          1.5900,  1.9313,  1.9313,  0.8919,  0.8870,  1.9034,  1.6923,  0.8987,
          1.8440,  1.2985,  1.9522,  1.8677, -0.1258, -0.3687, -0.4122, -0.1719,
          0.0802,  0.1705, -0.2519, 17.3699,  3.5481,  0.2537,  0.6169,  0.6406,
          0.7526,  0.4059,  0.7535, -0.0355,  0.7866,  0.8493],
        [ 1.3440,  1.3809,  1.4189,  1.4128,  1.3877,  1.3510,  1.3214,  1.3403,
          1.3403,  1.3177,  1.4376,  1.3349,  1.4653,  1.3941,  1.4908,  1.3244,
          1.3694,  1.3803,  1.4031,  1.3769,  1.4355,  1.4167,  1.3701,  1.3632,
          1.2598,  1.3518,  1.3518,  1.3977,  1.4473,  1.3655,  1.1570,  1.3549,
          1.2544,  1.4219,  1.2434,  1.3696,  0.3522,  0.2759,  0.3896,  0.3588,
          0.1513,  0.1039,  0.3757,  0.1495, -0.0585,  3.4501,  2.2859,  3.4149,
          2.6243,  1.8265,  1.4220,  2.8518,  3.2686,  1.3865]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 312 : 174.75128570426565
Test loss for epoch 312 : 174.99840470617622
Test Precision for epoch 312 : 0.26153846153846155
Test Recall for epoch 312 : 0.26153846153846155
Test F1 for epoch 312 : 0.26153846153846155


theta for epoch 313 : tensor([[ 2.6284e+00,  2.6473e+00,  2.6843e+00,  2.7974e+00,  2.7785e+00,
          2.6316e+00,  2.7655e+00,  2.6267e+00,  2.6267e+00,  1.3361e+00,
          1.3383e+00,  1.3373e+00,  1.3403e+00,  1.3351e+00,  1.3423e+00,
          1.3365e+00,  1.3334e+00,  1.2956e+00,  1.2869e+00,  1.2446e+00,
          1.2454e+00,  1.2879e+00,  1.2845e+00,  1.2840e+00,  1.2862e+00,
          1.2832e+00,  1.2832e+00,  1.2697e+00,  1.3142e+00,  1.3081e+00,
          1.3112e+00,  1.3143e+00,  1.3095e+00,  1.3123e+00,  1.2642e+00,
          1.3084e+00,  1.7364e+00,  1.7473e+00,  1.7410e+00,  1.7371e+00,
          1.7454e+00,  1.6849e+00,  1.7379e+00,  1.7229e+00,  1.7363e+00,
          1.6002e+00,  1.5836e+00,  1.5801e+00,  1.5739e+00,  1.5967e+00,
          1.5788e+00,  1.6111e+00,  1.5703e+00,  1.5722e+00],
        [ 1.2901e+00,  1.2930e+00,  1.2826e+00,  1.2824e+00,  1.2936e+00,
          1.2907e+00,  1.2917e+00,  1.2899e+00,  1.2899e+00,  2.5874e+00,
          2.6005e+00,  2.5527e+00,  2.7705e+00,  2.5402e+00,  2.9562e+00,
          2.5889e+00,  2.7341e+00,  2.9293e+00,  1.2792e+00,  1.2841e+00,
          1.2375e+00,  1.2797e+00,  1.3066e+00,  1.3061e+00,  1.3072e+00,
          1.3052e+00,  1.3052e+00,  1.3095e+00,  1.2613e+00,  1.3302e+00,
          1.3335e+00,  1.2964e+00,  1.3317e+00,  1.3347e+00,  1.3042e+00,
          1.3305e+00,  1.7492e+00,  1.7611e+00,  1.7171e+00,  1.7488e+00,
          1.7589e+00,  1.7603e+00,  1.7137e+00,  1.7127e+00,  1.7481e+00,
          1.5614e+00,  1.5989e+00,  1.5951e+00,  1.5882e+00,  1.5216e+00,
          1.5936e+00,  1.5374e+00,  1.5844e+00,  1.5864e+00],
        [ 1.2737e+00,  1.2764e+00,  1.2774e+00,  1.2781e+00,  1.2763e+00,
          1.2742e+00,  1.2746e+00,  1.2734e+00,  1.2734e+00,  1.3420e+00,
          1.3442e+00,  1.3432e+00,  1.3463e+00,  1.3410e+00,  1.2887e+00,
          1.3425e+00,  1.2797e+00,  1.3302e+00,  2.6775e+00,  2.7818e+00,
          2.8324e+00,  2.6865e+00,  2.6173e+00,  2.6142e+00,  2.7579e+00,
          2.6091e+00,  2.6091e+00,  1.2738e+00,  1.3046e+00,  1.3140e+00,
          1.3171e+00,  1.2745e+00,  1.3154e+00,  1.3183e+00,  1.3139e+00,
          1.3143e+00,  1.7403e+00,  1.7514e+00,  1.7449e+00,  1.6778e+00,
          1.7493e+00,  1.7466e+00,  1.7417e+00,  1.7264e+00,  1.6770e+00,
          1.6050e+00,  1.5881e+00,  1.5846e+00,  1.5783e+00,  1.5823e+00,
          1.5833e+00,  1.5970e+00,  1.5717e+00,  1.5765e+00],
        [ 1.2804e+00,  1.2832e+00,  1.2843e+00,  1.2851e+00,  1.2832e+00,
          1.2810e+00,  1.2814e+00,  1.2802e+00,  1.2802e+00,  1.3485e+00,
          1.3508e+00,  1.3498e+00,  1.3333e+00,  1.3475e+00,  1.2851e+00,
          1.3490e+00,  1.3450e+00,  1.2835e+00,  1.2998e+00,  1.2790e+00,
          1.3011e+00,  1.3009e+00,  1.2973e+00,  1.2968e+00,  1.2960e+00,
          1.2959e+00,  1.2959e+00,  2.8430e+00,  2.7750e+00,  2.5832e+00,
          2.6230e+00,  2.8417e+00,  2.5918e+00,  2.7552e+00,  2.6394e+00,
          2.5849e+00,  1.7438e+00,  1.7552e+00,  1.7217e+00,  1.7404e+00,
          1.7531e+00,  1.7504e+00,  1.7184e+00,  1.7209e+00,  1.7395e+00,
          1.6096e+00,  1.5923e+00,  1.5278e+00,  1.5283e+00,  1.6060e+00,
          1.5872e+00,  1.6211e+00,  1.5217e+00,  1.5803e+00],
        [ 1.8983e+00,  1.5014e+00,  6.5295e-01,  9.7510e-01,  1.3963e+00,
          1.8292e+00,  1.7027e+00,  1.9341e+00,  1.9341e+00,  1.7408e+00,
          1.3746e+00,  1.5828e+00,  9.8723e-01,  1.7889e+00,  1.7668e-01,
          1.6787e+00,  1.9588e+00,  8.9821e-01,  1.4039e+00,  1.0641e+00,
          8.1625e-01,  1.2130e+00,  1.7718e+00,  1.8378e+00,  1.6036e+00,
          1.9433e+00,  1.9433e+00,  9.0907e-01,  9.0460e-01,  1.9172e+00,
          1.7071e+00,  9.1640e-01,  1.8583e+00,  1.3148e+00,  1.9658e+00,
          1.8818e+00, -1.4109e-01, -3.8346e-01, -4.2688e-01, -1.8720e-01,
          6.4538e-02,  1.5465e-01, -2.6687e-01,  1.7397e+01,  3.5046e+00,
          2.7325e-01,  6.3627e-01,  6.6020e-01,  7.7234e-01,  4.2555e-01,
          7.7319e-01, -1.5903e-02,  8.0624e-01,  8.6896e-01],
        [ 1.3283e+00,  1.3653e+00,  1.4031e+00,  1.3973e+00,  1.3722e+00,
          1.3354e+00,  1.3056e+00,  1.3246e+00,  1.3246e+00,  1.3000e+00,
          1.4201e+00,  1.3170e+00,  1.4475e+00,  1.3765e+00,  1.4730e+00,
          1.3066e+00,  1.3516e+00,  1.3626e+00,  1.3845e+00,  1.3576e+00,
          1.4170e+00,  1.3981e+00,  1.3514e+00,  1.3445e+00,  1.2403e+00,
          1.3331e+00,  1.3331e+00,  1.3813e+00,  1.4315e+00,  1.3494e+00,
          1.1399e+00,  1.3386e+00,  1.2381e+00,  1.4060e+00,  1.2269e+00,
          1.3535e+00,  3.3420e-01,  2.5770e-01,  3.7150e-01,  3.4079e-01,
          1.3293e-01,  8.5468e-02,  3.5773e-01,  1.3103e-01, -7.7133e-02,
          3.4730e+00,  2.3061e+00,  3.4377e+00,  2.6450e+00,  1.8462e+00,
          1.4417e+00,  2.8723e+00,  3.2922e+00,  1.4062e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 313 : 174.80269886980398
Test loss for epoch 313 : 175.02205513303664
Test Precision for epoch 313 : 0.26153846153846155
Test Recall for epoch 313 : 0.26153846153846155
Test F1 for epoch 313 : 0.26153846153846155


theta for epoch 314 : tensor([[ 2.6303,  2.6492,  2.6862,  2.7995,  2.7805,  2.6335,  2.7676,  2.6286,
          2.6286,  1.3359,  1.3381,  1.3371,  1.3401,  1.3350,  1.3422,  1.3364,
          1.3332,  1.2954,  1.2905,  1.2482,  1.2489,  1.2915,  1.2880,  1.2875,
          1.2897,  1.2867,  1.2867,  1.2696,  1.3141,  1.3080,  1.3111,  1.3142,
          1.3094,  1.3122,  1.2641,  1.3083,  1.7393,  1.7502,  1.7438,  1.7400,
          1.7482,  1.6877,  1.7407,  1.7258,  1.7391,  1.5903,  1.5736,  1.5701,
          1.5638,  1.5868,  1.5688,  1.6013,  1.5602,  1.5621],
        [ 1.2907,  1.2936,  1.2836,  1.2833,  1.2942,  1.2913,  1.2923,  1.2905,
          1.2905,  2.5871,  2.6003,  2.5536,  2.7717,  2.5409,  2.9562,  2.5886,
          2.7354,  2.9292,  1.2838,  1.2887,  1.2420,  1.2843,  1.3111,  1.3106,
          1.3117,  1.3097,  1.3097,  1.3099,  1.2616,  1.3305,  1.3339,  1.2971,
          1.3320,  1.3351,  1.3046,  1.3308,  1.7521,  1.7640,  1.7200,  1.7518,
          1.7619,  1.7633,  1.7167,  1.7161,  1.7510,  1.5510,  1.5884,  1.5846,
          1.5779,  1.5113,  1.5832,  1.5272,  1.5739,  1.5760],
        [ 1.2737,  1.2765,  1.2774,  1.2782,  1.2763,  1.2743,  1.2746,  1.2735,
          1.2735,  1.3415,  1.3438,  1.3428,  1.3458,  1.3406,  1.2882,  1.3420,
          1.2792,  1.3298,  2.6818,  2.7865,  2.8369,  2.6908,  2.6217,  2.6185,
          2.7627,  2.6135,  2.6135,  1.2734,  1.3044,  1.3137,  1.3169,  1.2741,
          1.3152,  1.3180,  1.3137,  1.3140,  1.7430,  1.7541,  1.7477,  1.6804,
          1.7521,  1.7493,  1.7445,  1.7291,  1.6795,  1.5949,  1.5780,  1.5745,
          1.5681,  1.5722,  1.5731,  1.5870,  1.5614,  1.5663],
        [ 1.2807,  1.2835,  1.2845,  1.2854,  1.2835,  1.2813,  1.2817,  1.2805,
          1.2805,  1.3485,  1.3508,  1.3498,  1.3333,  1.3475,  1.2853,  1.3490,
          1.3450,  1.2837,  1.3033,  1.2823,  1.3046,  1.3043,  1.3008,  1.3003,
          1.2994,  1.2994,  1.2994,  2.8445,  2.7762,  2.5850,  2.6242,  2.8432,
          2.5936,  2.7565,  2.6413,  2.5868,  1.7468,  1.7582,  1.7247,  1.7434,
          1.7562,  1.7534,  1.7214,  1.7242,  1.7425,  1.6002,  1.5827,  1.5185,
          1.5187,  1.5966,  1.5777,  1.6118,  1.5120,  1.5707],
        [ 1.8859,  1.4865,  0.6356,  0.9589,  1.3811,  1.8165,  1.6890,  1.9220,
          1.9220,  1.7248,  1.3570,  1.5670,  0.9693,  1.7734,  0.1572,  1.6626,
          1.9450,  0.8783,  1.3881,  1.0481,  0.7987,  1.1964,  1.7578,  1.8242,
          1.5898,  1.9305,  1.9305,  0.8914,  0.8861,  1.9024,  1.6912,  0.8978,
          1.8430,  1.2976,  1.9512,  1.8668, -0.1253, -0.3682, -0.4117, -0.1716,
          0.0805,  0.1704, -0.2514, 17.4557,  3.4978,  0.2533,  0.6168,  0.6405,
          0.7528,  0.4056,  0.7536, -0.0360,  0.7870,  0.8495],
        [ 1.3470,  1.3838,  1.4215,  1.4157,  1.3906,  1.3540,  1.3244,  1.3433,
          1.3433,  1.3211,  1.4409,  1.3381,  1.4685,  1.3973,  1.4941,  1.3277,
          1.3727,  1.3836,  1.4066,  1.3801,  1.4390,  1.4202,  1.3736,  1.3667,
          1.2630,  1.3553,  1.3553,  1.4003,  1.4502,  1.3685,  1.1602,  1.3575,
          1.2575,  1.4249,  1.2466,  1.3726,  0.3561,  0.2796,  0.3934,  0.3627,
          0.1551,  0.1076,  0.3796,  0.1534, -0.0547,  3.4533,  2.2839,  3.4176,
          2.6232,  1.8239,  1.4193,  2.8506,  3.2727,  1.3839]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 314 : 174.83807951787884
Test loss for epoch 314 : 175.09544735975044
Test Precision for epoch 314 : 0.26153846153846155
Test Recall for epoch 314 : 0.26153846153846155
Test F1 for epoch 314 : 0.26153846153846155


theta for epoch 315 : tensor([[ 2.6307e+00,  2.6496e+00,  2.6867e+00,  2.8002e+00,  2.7812e+00,
          2.6340e+00,  2.7682e+00,  2.6291e+00,  2.6291e+00,  1.3360e+00,
          1.3382e+00,  1.3372e+00,  1.3402e+00,  1.3350e+00,  1.3423e+00,
          1.3365e+00,  1.3333e+00,  1.2955e+00,  1.2863e+00,  1.2441e+00,
          1.2448e+00,  1.2873e+00,  1.2839e+00,  1.2834e+00,  1.2856e+00,
          1.2825e+00,  1.2825e+00,  1.2695e+00,  1.3140e+00,  1.3078e+00,
          1.3109e+00,  1.3141e+00,  1.3092e+00,  1.3121e+00,  1.2639e+00,
          1.3081e+00,  1.7361e+00,  1.7470e+00,  1.7407e+00,  1.7368e+00,
          1.7451e+00,  1.6846e+00,  1.7375e+00,  1.7226e+00,  1.7361e+00,
          1.5993e+00,  1.5827e+00,  1.5792e+00,  1.5729e+00,  1.5959e+00,
          1.5778e+00,  1.6104e+00,  1.5693e+00,  1.5712e+00],
        [ 1.2897e+00,  1.2926e+00,  1.2831e+00,  1.2828e+00,  1.2933e+00,
          1.2903e+00,  1.2913e+00,  1.2895e+00,  1.2895e+00,  2.5885e+00,
          2.6019e+00,  2.5561e+00,  2.7747e+00,  2.5434e+00,  2.9578e+00,
          2.5901e+00,  2.7384e+00,  2.9308e+00,  1.2786e+00,  1.2834e+00,
          1.2369e+00,  1.2791e+00,  1.3059e+00,  1.3053e+00,  1.3065e+00,
          1.3044e+00,  1.3044e+00,  1.3092e+00,  1.2610e+00,  1.3298e+00,
          1.3332e+00,  1.2968e+00,  1.3313e+00,  1.3344e+00,  1.3038e+00,
          1.3301e+00,  1.7487e+00,  1.7607e+00,  1.7166e+00,  1.7484e+00,
          1.7586e+00,  1.7600e+00,  1.7132e+00,  1.7136e+00,  1.7478e+00,
          1.5603e+00,  1.5977e+00,  1.5940e+00,  1.5870e+00,  1.5205e+00,
          1.5924e+00,  1.5364e+00,  1.5831e+00,  1.5851e+00],
        [ 1.2735e+00,  1.2762e+00,  1.2771e+00,  1.2780e+00,  1.2761e+00,
          1.2740e+00,  1.2744e+00,  1.2732e+00,  1.2732e+00,  1.3421e+00,
          1.3444e+00,  1.3434e+00,  1.3464e+00,  1.3411e+00,  1.2888e+00,
          1.3426e+00,  1.2797e+00,  1.3304e+00,  2.6791e+00,  2.7842e+00,
          2.8345e+00,  2.6881e+00,  2.6188e+00,  2.6157e+00,  2.7603e+00,
          2.6106e+00,  2.6106e+00,  1.2735e+00,  1.3045e+00,  1.3139e+00,
          1.3170e+00,  1.2742e+00,  1.3153e+00,  1.3182e+00,  1.3138e+00,
          1.3142e+00,  1.7399e+00,  1.7511e+00,  1.7446e+00,  1.6772e+00,
          1.7491e+00,  1.7462e+00,  1.7414e+00,  1.7261e+00,  1.6765e+00,
          1.6043e+00,  1.5874e+00,  1.5839e+00,  1.5775e+00,  1.5816e+00,
          1.5825e+00,  1.5964e+00,  1.5707e+00,  1.5757e+00],
        [ 1.2801e+00,  1.2830e+00,  1.2839e+00,  1.2848e+00,  1.2829e+00,
          1.2807e+00,  1.2811e+00,  1.2798e+00,  1.2798e+00,  1.3484e+00,
          1.3508e+00,  1.3497e+00,  1.3333e+00,  1.3474e+00,  1.2855e+00,
          1.3489e+00,  1.3449e+00,  1.2839e+00,  1.2993e+00,  1.2783e+00,
          1.3006e+00,  1.3003e+00,  1.2967e+00,  1.2962e+00,  1.2953e+00,
          1.2953e+00,  1.2953e+00,  2.8452e+00,  2.7767e+00,  2.5860e+00,
          2.6246e+00,  2.8439e+00,  2.5946e+00,  2.7570e+00,  2.6423e+00,
          2.5877e+00,  1.7434e+00,  1.7549e+00,  1.7213e+00,  1.7399e+00,
          1.7528e+00,  1.7500e+00,  1.7180e+00,  1.7210e+00,  1.7391e+00,
          1.6088e+00,  1.5913e+00,  1.5272e+00,  1.5273e+00,  1.6052e+00,
          1.5862e+00,  1.6203e+00,  1.5205e+00,  1.5793e+00],
        [ 1.8985e+00,  1.5020e+00,  6.5370e-01,  9.7553e-01,  1.3969e+00,
          1.8295e+00,  1.7031e+00,  1.9343e+00,  1.9343e+00,  1.7408e+00,
          1.3750e+00,  1.5834e+00,  9.8804e-01,  1.7893e+00,  1.7715e-01,
          1.6788e+00,  1.9591e+00,  8.9860e-01,  1.4044e+00,  1.0651e+00,
          8.1700e-01,  1.2136e+00,  1.7720e+00,  1.8378e+00,  1.6043e+00,
          1.9432e+00,  1.9432e+00,  9.1002e-01,  9.0523e-01,  1.9174e+00,
          1.7073e+00,  9.1705e-01,  1.8585e+00,  1.3154e+00,  1.9659e+00,
          1.8820e+00, -1.4198e-01, -3.8433e-01, -4.2771e-01, -1.8834e-01,
          6.3481e-02,  1.5328e-01, -2.6772e-01,  1.7480e+01,  3.4542e+00,
          2.7470e-01,  6.3828e-01,  6.6223e-01,  7.7470e-01,  4.2714e-01,
          7.7540e-01, -1.4776e-02,  8.0886e-01,  8.7140e-01],
        [ 1.3297e+00,  1.3666e+00,  1.4041e+00,  1.3985e+00,  1.3734e+00,
          1.3367e+00,  1.3070e+00,  1.3259e+00,  1.3259e+00,  1.3019e+00,
          1.4218e+00,  1.3187e+00,  1.4492e+00,  1.3782e+00,  1.4749e+00,
          1.3084e+00,  1.3534e+00,  1.3643e+00,  1.3862e+00,  1.3591e+00,
          1.4187e+00,  1.3999e+00,  1.3533e+00,  1.3464e+00,  1.2419e+00,
          1.3350e+00,  1.3350e+00,  1.3824e+00,  1.4328e+00,  1.3508e+00,
          1.1415e+00,  1.3396e+00,  1.2396e+00,  1.4073e+00,  1.2284e+00,
          1.3549e+00,  3.3697e-01,  2.6018e-01,  3.7417e-01,  3.4348e-01,
          1.3545e-01,  8.7852e-02,  3.6047e-01,  1.3380e-01, -7.4518e-02,
          3.4778e+00,  2.3058e+00,  3.4419e+00,  2.6456e+00,  1.8454e+00,
          1.4408e+00,  2.8728e+00,  3.2980e+00,  1.4054e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 315 : 174.7476708423608
Test loss for epoch 315 : 174.97459094038373
Test Precision for epoch 315 : 0.26153846153846155
Test Recall for epoch 315 : 0.26153846153846155
Test F1 for epoch 315 : 0.26153846153846155


theta for epoch 316 : tensor([[ 2.6303,  2.6492,  2.6863,  2.7999,  2.7809,  2.6336,  2.7680,  2.6287,
          2.6287,  1.3361,  1.3383,  1.3373,  1.3403,  1.3351,  1.3424,  1.3365,
          1.3333,  1.2957,  1.2908,  1.2486,  1.2494,  1.2918,  1.2884,  1.2878,
          1.2901,  1.2870,  1.2870,  1.2699,  1.3144,  1.3083,  1.3114,  1.3145,
          1.3097,  1.3125,  1.2643,  1.3085,  1.7387,  1.7497,  1.7433,  1.7394,
          1.7477,  1.6873,  1.7402,  1.7252,  1.7387,  1.5933,  1.5765,  1.5731,
          1.5667,  1.5899,  1.5717,  1.6045,  1.5631,  1.5650],
        [ 1.2906,  1.2935,  1.2843,  1.2840,  1.2941,  1.2912,  1.2922,  1.2904,
          1.2904,  2.5852,  2.5986,  2.5539,  2.7730,  2.5412,  2.9552,  2.5869,
          2.7366,  2.9280,  1.2840,  1.2889,  1.2422,  1.2845,  1.3112,  1.3106,
          1.3119,  1.3097,  1.3097,  1.3101,  1.2619,  1.3306,  1.3340,  1.2980,
          1.3321,  1.3352,  1.3046,  1.3309,  1.7514,  1.7633,  1.7193,  1.7511,
          1.7612,  1.7627,  1.7159,  1.7166,  1.7505,  1.5541,  1.5913,  1.5876,
          1.5807,  1.5144,  1.5860,  1.5304,  1.5767,  1.5788],
        [ 1.2737,  1.2765,  1.2774,  1.2783,  1.2764,  1.2743,  1.2746,  1.2735,
          1.2735,  1.3416,  1.3438,  1.3428,  1.3459,  1.3406,  1.2884,  1.3421,
          1.2792,  1.3299,  2.6807,  2.7862,  2.8365,  2.6898,  2.6205,  2.6173,
          2.7624,  2.6123,  2.6123,  1.2735,  1.3046,  1.3139,  1.3170,  1.2742,
          1.3153,  1.3182,  1.3138,  1.3142,  1.7424,  1.7535,  1.7470,  1.6794,
          1.7515,  1.7486,  1.7438,  1.7285,  1.6787,  1.5979,  1.5809,  1.5774,
          1.5710,  1.5752,  1.5760,  1.5901,  1.5641,  1.5692],
        [ 1.2807,  1.2836,  1.2844,  1.2854,  1.2835,  1.2813,  1.2817,  1.2804,
          1.2804,  1.3485,  1.3509,  1.3498,  1.3335,  1.3475,  1.2858,  1.3491,
          1.3450,  1.2842,  1.3035,  1.2824,  1.3048,  1.3046,  1.3009,  1.3004,
          1.2994,  1.2995,  1.2995,  2.8441,  2.7754,  2.5852,  2.6232,  2.8429,
          2.5938,  2.7557,  2.6416,  2.5869,  1.7461,  1.7576,  1.7240,  1.7425,
          1.7556,  1.7526,  1.7207,  1.7240,  1.7418,  1.6030,  1.5854,  1.5216,
          1.5213,  1.5993,  1.5803,  1.6146,  1.5144,  1.5733],
        [ 1.8889,  1.4907,  0.6409,  0.9634,  1.3855,  1.8196,  1.6926,  1.9248,
          1.9248,  1.7283,  1.3616,  1.5713,  0.9747,  1.7772,  0.1628,  1.6663,
          1.9480,  0.8839,  1.3928,  1.0534,  0.8042,  1.2014,  1.7615,  1.8276,
          1.5941,  1.9334,  1.9334,  0.8970,  0.8916,  1.9060,  1.6952,  0.9034,
          1.8468,  1.3025,  1.9546,  1.8705, -0.1303, -0.3730, -0.4165, -0.1769,
          0.0752,  0.1649, -0.2563, 17.5332,  3.4435,  0.2608,  0.6250,  0.6488,
          0.7615,  0.4133,  0.7622, -0.0289,  0.7960,  0.8584],
        [ 1.3422,  1.3790,  1.4164,  1.4109,  1.3858,  1.3492,  1.3196,  1.3385,
          1.3385,  1.3158,  1.4354,  1.3326,  1.4630,  1.3919,  1.4888,  1.3223,
          1.3673,  1.3781,  1.4014,  1.3744,  1.4338,  1.4150,  1.3684,  1.3616,
          1.2574,  1.3502,  1.3502,  1.3951,  1.4454,  1.3637,  1.1551,  1.3523,
          1.2526,  1.4200,  1.2416,  1.3678,  0.3524,  0.2755,  0.3895,  0.3588,
          0.1509,  0.1032,  0.3758,  0.1494, -0.0589,  3.4658,  2.2913,  3.4295,
          2.6315,  1.8307,  1.4261,  2.8588,  3.2862,  1.3906]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 316 : 174.62329139166863
Test loss for epoch 316 : 174.87830551898836
Test Precision for epoch 316 : 0.26153846153846155
Test Recall for epoch 316 : 0.26153846153846155
Test F1 for epoch 316 : 0.26153846153846155


theta for epoch 317 : tensor([[ 2.6292,  2.6481,  2.6852,  2.7990,  2.7800,  2.6324,  2.7670,  2.6275,
          2.6275,  1.3376,  1.3398,  1.3388,  1.3419,  1.3366,  1.3440,  1.3381,
          1.3349,  1.2973,  1.2894,  1.2473,  1.2480,  1.2904,  1.2869,  1.2864,
          1.2886,  1.2855,  1.2855,  1.2708,  1.3153,  1.3091,  1.3122,  1.3154,
          1.3105,  1.3134,  1.2652,  1.3094,  1.7379,  1.7489,  1.7425,  1.7387,
          1.7470,  1.6866,  1.7394,  1.7245,  1.7380,  1.5973,  1.5805,  1.5770,
          1.5706,  1.5938,  1.5756,  1.6084,  1.5670,  1.5689],
        [ 1.2907,  1.2936,  1.2848,  1.2845,  1.2943,  1.2913,  1.2924,  1.2905,
          1.2905,  2.5844,  2.5979,  2.5541,  2.7736,  2.5413,  2.9548,  2.5861,
          2.7372,  2.9275,  1.2816,  1.2865,  1.2400,  1.2822,  1.3088,  1.3082,
          1.3095,  1.3073,  1.3073,  1.3105,  1.2623,  1.3309,  1.3344,  1.2987,
          1.3325,  1.3356,  1.3050,  1.3313,  1.7503,  1.7623,  1.7182,  1.7501,
          1.7602,  1.7617,  1.7148,  1.7162,  1.7495,  1.5579,  1.5951,  1.5913,
          1.5843,  1.5181,  1.5897,  1.5342,  1.5803,  1.5824],
        [ 1.2743,  1.2771,  1.2779,  1.2789,  1.2770,  1.2748,  1.2752,  1.2740,
          1.2740,  1.3432,  1.3455,  1.3445,  1.3476,  1.3422,  1.2900,  1.3437,
          1.2808,  1.3317,  2.6772,  2.7832,  2.8333,  2.6863,  2.6169,  2.6138,
          2.7593,  2.6087,  2.6087,  1.2743,  1.3055,  1.3147,  1.3179,  1.2750,
          1.3161,  1.3191,  1.3146,  1.3150,  1.7415,  1.7527,  1.7461,  1.6785,
          1.7507,  1.7477,  1.7430,  1.7277,  1.6779,  1.6018,  1.5848,  1.5813,
          1.5748,  1.5791,  1.5798,  1.5941,  1.5679,  1.5730],
        [ 1.2811,  1.2840,  1.2848,  1.2859,  1.2839,  1.2816,  1.2821,  1.2808,
          1.2808,  1.3499,  1.3523,  1.3512,  1.3349,  1.3489,  1.2875,  1.3504,
          1.3464,  1.2858,  1.3018,  1.2807,  1.3032,  1.3029,  1.2992,  1.2987,
          1.2977,  1.2978,  1.2978,  2.8431,  2.7741,  2.5843,  2.6218,  2.8418,
          2.5929,  2.7545,  2.6408,  2.5860,  1.7452,  1.7567,  1.7231,  1.7415,
          1.7547,  1.7517,  1.7198,  1.7234,  1.7408,  1.6066,  1.5889,  1.5253,
          1.5249,  1.6029,  1.5838,  1.6182,  1.5179,  1.5768],
        [ 1.8923,  1.4952,  0.6462,  0.9682,  1.3900,  1.8232,  1.6966,  1.9282,
          1.9282,  1.7329,  1.3669,  1.5761,  0.9803,  1.7818,  0.1687,  1.6709,
          1.9521,  0.8898,  1.3970,  1.0581,  0.8093,  1.2060,  1.7648,  1.8307,
          1.5978,  1.9362,  1.9362,  0.9026,  0.8972,  1.9102,  1.6998,  0.9091,
          1.8512,  1.3077,  1.9587,  1.8748, -0.1354, -0.3780, -0.4214, -0.1821,
          0.0700,  0.1595, -0.2613, 17.5689,  3.4139,  0.2677,  0.6321,  0.6561,
          0.7689,  0.4203,  0.7695, -0.0223,  0.8035,  0.8658],
        [ 1.3364,  1.3733,  1.4105,  1.4052,  1.3801,  1.3434,  1.3138,  1.3327,
          1.3327,  1.3095,  1.4292,  1.3263,  1.4567,  1.3857,  1.4826,  1.3161,
          1.3610,  1.3719,  1.3942,  1.3670,  1.4267,  1.4078,  1.3613,  1.3545,
          1.2500,  1.3431,  1.3431,  1.3890,  1.4396,  1.3578,  1.1490,  1.3463,
          1.2467,  1.4141,  1.2357,  1.3619,  0.3466,  0.2695,  0.3837,  0.3531,
          0.1448,  0.0971,  0.3701,  0.1435, -0.0650,  3.4760,  2.2991,  3.4395,
          2.6397,  1.8382,  1.4335,  2.8669,  3.2970,  1.3980]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 317 : 174.54861262130274
Test loss for epoch 317 : 174.79678316198897
Test Precision for epoch 317 : 0.26153846153846155
Test Recall for epoch 317 : 0.26153846153846155
Test F1 for epoch 317 : 0.26153846153846155


theta for epoch 318 : tensor([[ 2.6295,  2.6485,  2.6856,  2.7995,  2.7805,  2.6328,  2.7675,  2.6279,
          2.6279,  1.3377,  1.3400,  1.3390,  1.3421,  1.3368,  1.3442,  1.3382,
          1.3350,  1.2974,  1.2905,  1.2484,  1.2492,  1.2916,  1.2880,  1.2875,
          1.2897,  1.2866,  1.2866,  1.2715,  1.3160,  1.3098,  1.3129,  1.3161,
          1.3112,  1.3141,  1.2659,  1.3101,  1.7371,  1.7481,  1.7417,  1.7378,
          1.7462,  1.6857,  1.7385,  1.7236,  1.7372,  1.5974,  1.5805,  1.5771,
          1.5707,  1.5939,  1.5756,  1.6086,  1.5670,  1.5689],
        [ 1.2910,  1.2939,  1.2855,  1.2851,  1.2946,  1.2916,  1.2926,  1.2907,
          1.2907,  2.5846,  2.5981,  2.5554,  2.7753,  2.5426,  2.9552,  2.5863,
          2.7389,  2.9279,  1.2821,  1.2870,  1.2404,  1.2827,  1.3092,  1.3087,
          1.3100,  1.3078,  1.3078,  1.3108,  1.2626,  1.3312,  1.3346,  1.2994,
          1.3328,  1.3359,  1.3053,  1.3315,  1.7493,  1.7613,  1.7172,  1.7490,
          1.7592,  1.7606,  1.7137,  1.7158,  1.7485,  1.5576,  1.5947,  1.5909,
          1.5839,  1.5177,  1.5893,  1.5338,  1.5799,  1.5819],
        [ 1.2744,  1.2772,  1.2780,  1.2790,  1.2771,  1.2750,  1.2754,  1.2741,
          1.2741,  1.3425,  1.3447,  1.3437,  1.3469,  1.3414,  1.2893,  1.3429,
          1.2800,  1.3309,  2.6792,  2.7855,  2.8355,  2.6883,  2.6188,  2.6157,
          2.7616,  2.6106,  2.6106,  1.2743,  1.3056,  1.3148,  1.3180,  1.2750,
          1.3162,  1.3192,  1.3147,  1.3151,  1.7403,  1.7515,  1.7449,  1.6771,
          1.7496,  1.7465,  1.7418,  1.7265,  1.6766,  1.6014,  1.5843,  1.5808,
          1.5743,  1.5786,  1.5793,  1.5936,  1.5673,  1.5725],
        [ 1.2815,  1.2844,  1.2852,  1.2863,  1.2843,  1.2821,  1.2826,  1.2812,
          1.2812,  1.3497,  1.3520,  1.3510,  1.3347,  1.3487,  1.2874,  1.3502,
          1.3461,  1.2858,  1.3025,  1.2813,  1.3038,  1.3035,  1.2998,  1.2993,
          1.2983,  1.2984,  1.2984,  2.8439,  2.7747,  2.5854,  2.6223,  2.8427,
          2.5940,  2.7551,  2.6419,  2.5871,  1.7441,  1.7557,  1.7220,  1.7404,
          1.7537,  1.7506,  1.7188,  1.7225,  1.7398,  1.6064,  1.5887,  1.5253,
          1.5247,  1.6027,  1.5836,  1.6181,  1.5176,  1.5766],
        [ 1.8947,  1.4980,  0.6495,  0.9712,  1.3930,  1.8257,  1.6992,  1.9304,
          1.9304,  1.7352,  1.3697,  1.5788,  0.9834,  1.7843,  0.1720,  1.6733,
          1.9543,  0.8930,  1.4001,  1.0615,  0.8128,  1.2093,  1.7676,  1.8334,
          1.6009,  1.9388,  1.9388,  0.9060,  0.9006,  1.9129,  1.7027,  0.9125,
          1.8540,  1.3109,  1.9613,  1.8775, -0.1386, -0.3810, -0.4244, -0.1853,
          0.0668,  0.1561, -0.2643, 17.6067,  3.3866,  0.2713,  0.6359,  0.6598,
          0.7728,  0.4240,  0.7733, -0.0187,  0.8074,  0.8697],
        [ 1.3342,  1.3711,  1.4082,  1.4031,  1.3779,  1.3413,  1.3116,  1.3305,
          1.3305,  1.3068,  1.4265,  1.3235,  1.4539,  1.3829,  1.4799,  1.3134,
          1.3582,  1.3692,  1.3919,  1.3644,  1.4244,  1.4055,  1.3591,  1.3522,
          1.2474,  1.3408,  1.3408,  1.3866,  1.4374,  1.3555,  1.1466,  1.3439,
          1.2444,  1.4119,  1.2334,  1.3597,  0.3443,  0.2670,  0.3813,  0.3506,
          0.1423,  0.0945,  0.3677,  0.1411, -0.0675,  3.4820,  2.3027,  3.4453,
          2.6436,  1.8415,  1.4367,  2.8708,  3.3035,  1.4012]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 318 : 174.56735279079516
Test loss for epoch 318 : 174.813746486998
Test Precision for epoch 318 : 0.26153846153846155
Test Recall for epoch 318 : 0.26153846153846155
Test F1 for epoch 318 : 0.26153846153846155


theta for epoch 319 : tensor([[ 2.6321,  2.6510,  2.6882,  2.8022,  2.7832,  2.6353,  2.7702,  2.6304,
          2.6304,  1.3372,  1.3395,  1.3385,  1.3416,  1.3363,  1.3437,  1.3377,
          1.3345,  1.2969,  1.2912,  1.2491,  1.2499,  1.2923,  1.2887,  1.2882,
          1.2905,  1.2874,  1.2874,  1.2714,  1.3159,  1.3096,  1.3128,  1.3159,
          1.3110,  1.3139,  1.2657,  1.3099,  1.7381,  1.7491,  1.7427,  1.7388,
          1.7472,  1.6868,  1.7396,  1.7246,  1.7383,  1.5912,  1.5742,  1.5707,
          1.5643,  1.5876,  1.5693,  1.6024,  1.5606,  1.5625],
        [ 1.2914,  1.2943,  1.2863,  1.2859,  1.2950,  1.2921,  1.2931,  1.2912,
          1.2912,  2.5863,  2.5999,  2.5582,  2.7784,  2.5453,  2.9570,  2.5881,
          2.7421,  2.9297,  1.2829,  1.2878,  1.2412,  1.2835,  1.3101,  1.3095,
          1.3109,  1.3086,  1.3086,  1.3106,  1.2625,  1.3311,  1.3345,  1.2995,
          1.3326,  1.3357,  1.3051,  1.3314,  1.7502,  1.7622,  1.7181,  1.7500,
          1.7602,  1.7616,  1.7147,  1.7173,  1.7495,  1.5507,  1.5877,  1.5840,
          1.5771,  1.5110,  1.5824,  1.5271,  1.5730,  1.5751],
        [ 1.2746,  1.2774,  1.2781,  1.2792,  1.2773,  1.2752,  1.2756,  1.2744,
          1.2744,  1.3415,  1.3438,  1.3427,  1.3459,  1.3405,  1.2882,  1.3420,
          1.2790,  1.3299,  2.6834,  2.7901,  2.8399,  2.6924,  2.6230,  2.6198,
          2.7661,  2.6148,  2.6148,  1.2737,  1.3052,  1.3144,  1.3176,  1.2744,
          1.3158,  1.3187,  1.3143,  1.3147,  1.7412,  1.7524,  1.7458,  1.6778,
          1.7505,  1.7473,  1.7427,  1.7274,  1.6773,  1.5949,  1.5777,  1.5742,
          1.5677,  1.5722,  1.5727,  1.5872,  1.5606,  1.5659],
        [ 1.2819,  1.2848,  1.2855,  1.2867,  1.2847,  1.2825,  1.2830,  1.2816,
          1.2816,  1.3491,  1.3514,  1.3504,  1.3341,  1.3481,  1.2869,  1.3496,
          1.3456,  1.2853,  1.3031,  1.2818,  1.3045,  1.3042,  1.3005,  1.2999,
          1.2988,  1.2991,  1.2991,  2.8465,  2.7771,  2.5882,  2.6246,  2.8452,
          2.5968,  2.7574,  2.6449,  2.5899,  1.7452,  1.7567,  1.7230,  1.7413,
          1.7547,  1.7516,  1.7198,  1.7238,  1.7408,  1.6004,  1.5826,  1.5193,
          1.5185,  1.5967,  1.5775,  1.6121,  1.5113,  1.5704],
        [ 1.8892,  1.4914,  0.6417,  0.9638,  1.3862,  1.8201,  1.6932,  1.9252,
          1.9252,  1.7277,  1.3615,  1.5715,  0.9752,  1.7771,  0.1631,  1.6658,
          1.9478,  0.8839,  1.3927,  1.0541,  0.8046,  1.2014,  1.7609,  1.8268,
          1.5944,  1.9325,  1.9325,  0.8981,  0.8922,  1.9062,  1.6954,  0.9041,
          1.8470,  1.3030,  1.9547,  1.8707, -0.1314, -0.3740, -0.4174, -0.1783,
          0.0740,  0.1632, -0.2572, 17.6549,  3.3711,  0.2621,  0.6268,  0.6506,
          0.7636,  0.4147,  0.7641, -0.0280,  0.7984,  0.8605],
        [ 1.3445,  1.3812,  1.4181,  1.4132,  1.3880,  1.3515,  1.3218,  1.3408,
          1.3408,  1.3179,  1.4374,  1.3347,  1.4649,  1.3939,  1.4910,  1.3245,
          1.3694,  1.3802,  1.4033,  1.3758,  1.4357,  1.4168,  1.3705,  1.3636,
          1.2589,  1.3523,  1.3523,  1.3967,  1.4474,  1.3658,  1.1574,  1.3539,
          1.2548,  1.4220,  1.2439,  1.3699,  0.3556,  0.2783,  0.3926,  0.3619,
          0.1537,  0.1059,  0.3790,  0.1526, -0.0559,  3.4732,  2.2915,  3.4362,
          2.6328,  1.8301,  1.4252,  2.8601,  3.2950,  1.3898]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 319 : 174.63259986523013
Test loss for epoch 319 : 174.89899714804457
Test Precision for epoch 319 : 0.26153846153846155
Test Recall for epoch 319 : 0.26153846153846155
Test F1 for epoch 319 : 0.26153846153846155


theta for epoch 320 : tensor([[ 2.6337e+00,  2.6527e+00,  2.6898e+00,  2.8041e+00,  2.7850e+00,
          2.6370e+00,  2.7721e+00,  2.6321e+00,  2.6321e+00,  1.3364e+00,
          1.3386e+00,  1.3376e+00,  1.3407e+00,  1.3354e+00,  1.3428e+00,
          1.3369e+00,  1.3336e+00,  1.2960e+00,  1.2865e+00,  1.2443e+00,
          1.2450e+00,  1.2875e+00,  1.2840e+00,  1.2835e+00,  1.2857e+00,
          1.2826e+00,  1.2826e+00,  1.2701e+00,  1.3146e+00,  1.3083e+00,
          1.3115e+00,  1.3147e+00,  1.3098e+00,  1.3127e+00,  1.2644e+00,
          1.3086e+00,  1.7357e+00,  1.7468e+00,  1.7403e+00,  1.7364e+00,
          1.7449e+00,  1.6844e+00,  1.7372e+00,  1.7223e+00,  1.7360e+00,
          1.5984e+00,  1.5815e+00,  1.5780e+00,  1.5716e+00,  1.5949e+00,
          1.5766e+00,  1.6096e+00,  1.5679e+00,  1.5698e+00],
        [ 1.2899e+00,  1.2928e+00,  1.2851e+00,  1.2847e+00,  1.2935e+00,
          1.2905e+00,  1.2915e+00,  1.2897e+00,  1.2897e+00,  2.5890e+00,
          2.6027e+00,  2.5620e+00,  2.7825e+00,  2.5490e+00,  2.9595e+00,
          2.5909e+00,  2.7463e+00,  2.9325e+00,  1.2774e+00,  1.2823e+00,
          1.2358e+00,  1.2781e+00,  1.3047e+00,  1.3042e+00,  1.3055e+00,
          1.3032e+00,  1.3032e+00,  1.3090e+00,  1.2609e+00,  1.3294e+00,
          1.3329e+00,  1.2982e+00,  1.3310e+00,  1.3341e+00,  1.3035e+00,
          1.3298e+00,  1.7477e+00,  1.7598e+00,  1.7156e+00,  1.7475e+00,
          1.7577e+00,  1.7592e+00,  1.7122e+00,  1.7155e+00,  1.7471e+00,
          1.5584e+00,  1.5955e+00,  1.5916e+00,  1.5846e+00,  1.5185e+00,
          1.5900e+00,  1.5347e+00,  1.5806e+00,  1.5826e+00],
        [ 1.2738e+00,  1.2766e+00,  1.2772e+00,  1.2784e+00,  1.2765e+00,
          1.2743e+00,  1.2747e+00,  1.2735e+00,  1.2735e+00,  1.3414e+00,
          1.3437e+00,  1.3427e+00,  1.3458e+00,  1.3404e+00,  1.2882e+00,
          1.3419e+00,  1.2789e+00,  1.3298e+00,  2.6822e+00,  2.7893e+00,
          2.8391e+00,  2.6913e+00,  2.6218e+00,  2.6186e+00,  2.7654e+00,
          2.6136e+00,  2.6136e+00,  1.2729e+00,  1.3044e+00,  1.3136e+00,
          1.3168e+00,  1.2736e+00,  1.3150e+00,  1.3180e+00,  1.3135e+00,
          1.3139e+00,  1.7390e+00,  1.7503e+00,  1.7436e+00,  1.6755e+00,
          1.7483e+00,  1.7451e+00,  1.7405e+00,  1.7253e+00,  1.6751e+00,
          1.6027e+00,  1.5856e+00,  1.5820e+00,  1.5755e+00,  1.5800e+00,
          1.5806e+00,  1.5950e+00,  1.5683e+00,  1.5737e+00],
        [ 1.2807e+00,  1.2836e+00,  1.2842e+00,  1.2855e+00,  1.2835e+00,
          1.2812e+00,  1.2817e+00,  1.2804e+00,  1.2804e+00,  1.3483e+00,
          1.3506e+00,  1.3496e+00,  1.3332e+00,  1.3473e+00,  1.2862e+00,
          1.3488e+00,  1.3447e+00,  1.2846e+00,  1.2987e+00,  1.2774e+00,
          1.3001e+00,  1.2998e+00,  1.2961e+00,  1.2956e+00,  1.2944e+00,
          1.2947e+00,  1.2947e+00,  2.8482e+00,  2.7786e+00,  2.5901e+00,
          2.6260e+00,  2.8470e+00,  2.5987e+00,  2.7589e+00,  2.6468e+00,
          2.5919e+00,  1.7427e+00,  1.7543e+00,  1.7205e+00,  1.7387e+00,
          1.7523e+00,  1.7490e+00,  1.7173e+00,  1.7215e+00,  1.7382e+00,
          1.6074e+00,  1.5896e+00,  1.5265e+00,  1.5255e+00,  1.6037e+00,
          1.5844e+00,  1.6191e+00,  1.5182e+00,  1.5774e+00],
        [ 1.8987e+00,  1.5029e+00,  6.5516e-01,  9.7615e-01,  1.3979e+00,
          1.8298e+00,  1.7037e+00,  1.9344e+00,  1.9344e+00,  1.7397e+00,
          1.3749e+00,  1.5838e+00,  9.8910e-01,  1.7892e+00,  1.7781e-01,
          1.6779e+00,  1.9586e+00,  8.9877e-01,  1.4047e+00,  1.0667e+00,
          8.1807e-01,  1.2141e+00,  1.7715e+00,  1.8371e+00,  1.6053e+00,
          1.9421e+00,  1.9421e+00,  9.1172e-01,  9.0614e-01,  1.9172e+00,
          1.7072e+00,  9.1808e-01,  1.8584e+00,  1.3160e+00,  1.9655e+00,
          1.8819e+00, -1.4389e-01, -3.8618e-01, -4.2949e-01, -1.9088e-01,
          6.1231e-02,  1.5023e-01, -2.6953e-01,  1.7683e+01,  3.3333e+00,
          2.7773e-01,  6.4230e-01,  6.6620e-01,  7.7931e-01,  4.3041e-01,
          7.7975e-01, -1.2323e-02,  8.1407e-01,  8.7617e-01],
        [ 1.3323e+00,  1.3690e+00,  1.4058e+00,  1.4010e+00,  1.3758e+00,
          1.3393e+00,  1.3095e+00,  1.3286e+00,  1.3286e+00,  1.3046e+00,
          1.4242e+00,  1.3212e+00,  1.4515e+00,  1.3807e+00,  1.4776e+00,
          1.3112e+00,  1.3560e+00,  1.3668e+00,  1.3890e+00,  1.3611e+00,
          1.4215e+00,  1.4026e+00,  1.3562e+00,  1.3494e+00,  1.2441e+00,
          1.3380e+00,  1.3380e+00,  1.3838e+00,  1.4350e+00,  1.3532e+00,
          1.1442e+00,  1.3411e+00,  1.2421e+00,  1.4095e+00,  1.2310e+00,
          1.3573e+00,  3.4221e-01,  2.6478e-01,  3.7918e-01,  3.4851e-01,
          1.4009e-01,  9.2179e-02,  3.6567e-01,  1.3893e-01, -6.9626e-02,
          3.4910e+00,  2.3069e+00,  3.4538e+00,  2.6486e+00,  1.8451e+00,
          1.4402e+00,  2.8757e+00,  3.3135e+00,  1.4048e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 320 : 174.64416537991082
Test loss for epoch 320 : 174.88942695028868
Test Precision for epoch 320 : 0.26153846153846155
Test Recall for epoch 320 : 0.26153846153846155
Test F1 for epoch 320 : 0.26153846153846155


theta for epoch 321 : tensor([[ 2.6343,  2.6532,  2.6904,  2.8048,  2.7857,  2.6376,  2.7728,  2.6326,
          2.6326,  1.3353,  1.3376,  1.3366,  1.3396,  1.3343,  1.3417,  1.3358,
          1.3326,  1.2950,  1.2908,  1.2486,  1.2494,  1.2918,  1.2883,  1.2878,
          1.2900,  1.2869,  1.2869,  1.2693,  1.3138,  1.3076,  1.3107,  1.3139,
          1.3090,  1.3119,  1.2637,  1.3079,  1.7383,  1.7493,  1.7429,  1.7390,
          1.7475,  1.6870,  1.7397,  1.7248,  1.7386,  1.5927,  1.5757,  1.5722,
          1.5657,  1.5891,  1.5707,  1.6039,  1.5620,  1.5639],
        [ 1.2895,  1.2925,  1.2851,  1.2847,  1.2932,  1.2902,  1.2912,  1.2893,
          1.2893,  2.5865,  2.6003,  2.5604,  2.7815,  2.5475,  2.9577,  2.5884,
          2.7451,  2.9304,  1.2835,  1.2885,  1.2418,  1.2842,  1.3107,  1.3102,
          1.3115,  1.3092,  1.3092,  1.3090,  1.2609,  1.3295,  1.3329,  1.2986,
          1.3310,  1.3341,  1.3035,  1.3298,  1.7505,  1.7626,  1.7184,  1.7503,
          1.7605,  1.7620,  1.7150,  1.7186,  1.7499,  1.5530,  1.5899,  1.5861,
          1.5791,  1.5132,  1.5845,  1.5294,  1.5751,  1.5771],
        [ 1.2728,  1.2756,  1.2762,  1.2774,  1.2755,  1.2734,  1.2738,  1.2725,
          1.2725,  1.3405,  1.3428,  1.3417,  1.3449,  1.3395,  1.2872,  1.3410,
          1.2779,  1.3289,  2.6852,  2.7926,  2.8422,  2.6942,  2.6247,  2.6216,
          2.7687,  2.6165,  2.6165,  1.2721,  1.3037,  1.3129,  1.3161,  1.2728,
          1.3144,  1.3173,  1.3129,  1.3132,  1.7416,  1.7529,  1.7462,  1.6780,
          1.7510,  1.7476,  1.7431,  1.7278,  1.6776,  1.5971,  1.5799,  1.5764,
          1.5698,  1.5744,  1.5749,  1.5895,  1.5625,  1.5680],
        [ 1.2799,  1.2827,  1.2833,  1.2847,  1.2827,  1.2804,  1.2809,  1.2796,
          1.2796,  1.3475,  1.3498,  1.3488,  1.3324,  1.3465,  1.2855,  1.3480,
          1.3439,  1.2839,  1.3032,  1.2818,  1.3046,  1.3043,  1.3006,  1.3001,
          1.2988,  1.2992,  1.2992,  2.8484,  2.7785,  2.5904,  2.6258,  2.8471,
          2.5990,  2.7588,  2.6472,  2.5922,  1.7454,  1.7570,  1.7233,  1.7414,
          1.7551,  1.7517,  1.7200,  1.7245,  1.7410,  1.6021,  1.5842,  1.5213,
          1.5201,  1.5983,  1.5790,  1.6138,  1.5127,  1.5719],
        [ 1.8896,  1.4923,  0.6434,  0.9649,  1.3872,  1.8205,  1.6938,  1.9254,
          1.9254,  1.7285,  1.3629,  1.5728,  0.9771,  1.7783,  0.1650,  1.6667,
          1.9488,  0.8855,  1.3947,  1.0565,  0.8069,  1.2036,  1.7626,  1.8285,
          1.5967,  1.9341,  1.9341,  0.8999,  0.8938,  1.9068,  1.6961,  0.9057,
          1.8477,  1.3042,  1.9552,  1.8714, -0.1335, -0.3761, -0.4195, -0.1807,
          0.0717,  0.1605, -0.2593, 17.7334,  3.3219,  0.2650,  0.6299,  0.6536,
          0.7668,  0.4177,  0.7672, -0.0250,  0.8017,  0.8637],
        [ 1.3434,  1.3801,  1.4166,  1.4120,  1.3868,  1.3504,  1.3208,  1.3397,
          1.3397,  1.3173,  1.4367,  1.3339,  1.4641,  1.3932,  1.4903,  1.3239,
          1.3687,  1.3794,  1.4032,  1.3754,  1.4357,  1.4168,  1.3705,  1.3636,
          1.2585,  1.3523,  1.3523,  1.3953,  1.4464,  1.3649,  1.1565,  1.3526,
          1.2539,  1.4210,  1.2430,  1.3690,  0.3560,  0.2786,  0.3930,  0.3623,
          0.1540,  0.1060,  0.3794,  0.1529, -0.0555,  3.4800,  2.2935,  3.4425,
          2.6357,  1.8316,  1.4267,  2.8628,  3.3028,  1.3913]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 321 : 174.5861964876148
Test loss for epoch 321 : 174.85692544520185
Test Precision for epoch 321 : 0.26153846153846155
Test Recall for epoch 321 : 0.26153846153846155
Test F1 for epoch 321 : 0.26153846153846155


theta for epoch 322 : tensor([[ 2.6343e+00,  2.6533e+00,  2.6904e+00,  2.8050e+00,  2.7859e+00,
          2.6376e+00,  2.7729e+00,  2.6327e+00,  2.6327e+00,  1.3366e+00,
          1.3389e+00,  1.3379e+00,  1.3410e+00,  1.3356e+00,  1.3431e+00,
          1.3371e+00,  1.3339e+00,  1.2963e+00,  1.2876e+00,  1.2454e+00,
          1.2462e+00,  1.2886e+00,  1.2851e+00,  1.2846e+00,  1.2869e+00,
          1.2838e+00,  1.2838e+00,  1.2697e+00,  1.3142e+00,  1.3079e+00,
          1.3111e+00,  1.3143e+00,  1.3094e+00,  1.3123e+00,  1.2640e+00,
          1.3082e+00,  1.7370e+00,  1.7481e+00,  1.7416e+00,  1.7378e+00,
          1.7463e+00,  1.6858e+00,  1.7385e+00,  1.7236e+00,  1.7374e+00,
          1.5966e+00,  1.5795e+00,  1.5761e+00,  1.5696e+00,  1.5930e+00,
          1.5746e+00,  1.6078e+00,  1.5659e+00,  1.5678e+00],
        [ 1.2892e+00,  1.2922e+00,  1.2852e+00,  1.2847e+00,  1.2928e+00,
          1.2899e+00,  1.2909e+00,  1.2890e+00,  1.2890e+00,  2.5865e+00,
          2.6003e+00,  2.5614e+00,  2.7828e+00,  2.5484e+00,  2.9579e+00,
          2.5884e+00,  2.7465e+00,  2.9306e+00,  1.2803e+00,  1.2852e+00,
          1.2387e+00,  1.2810e+00,  1.3075e+00,  1.3070e+00,  1.3083e+00,
          1.3060e+00,  1.3060e+00,  1.3094e+00,  1.2614e+00,  1.3298e+00,
          1.3333e+00,  1.2993e+00,  1.3314e+00,  1.3345e+00,  1.3039e+00,
          1.3302e+00,  1.7493e+00,  1.7614e+00,  1.7171e+00,  1.7491e+00,
          1.7593e+00,  1.7608e+00,  1.7137e+00,  1.7180e+00,  1.7487e+00,
          1.5573e+00,  1.5942e+00,  1.5903e+00,  1.5832e+00,  1.5174e+00,
          1.5887e+00,  1.5336e+00,  1.5792e+00,  1.5812e+00],
        [ 1.2733e+00,  1.2761e+00,  1.2766e+00,  1.2779e+00,  1.2759e+00,
          1.2738e+00,  1.2742e+00,  1.2730e+00,  1.2730e+00,  1.3433e+00,
          1.3456e+00,  1.3445e+00,  1.3477e+00,  1.3423e+00,  1.2900e+00,
          1.3438e+00,  1.2808e+00,  1.3318e+00,  2.6806e+00,  2.7885e+00,
          2.8380e+00,  2.6897e+00,  2.6201e+00,  2.6169e+00,  2.7645e+00,
          2.6118e+00,  2.6118e+00,  1.2733e+00,  1.3050e+00,  1.3141e+00,
          1.3173e+00,  1.2740e+00,  1.3156e+00,  1.3185e+00,  1.3141e+00,
          1.3144e+00,  1.7407e+00,  1.7520e+00,  1.7454e+00,  1.6770e+00,
          1.7501e+00,  1.7467e+00,  1.7422e+00,  1.7270e+00,  1.6767e+00,
          1.6018e+00,  1.5846e+00,  1.5810e+00,  1.5745e+00,  1.5791e+00,
          1.5795e+00,  1.5942e+00,  1.5670e+00,  1.5726e+00],
        [ 1.2796e+00,  1.2825e+00,  1.2830e+00,  1.2844e+00,  1.2824e+00,
          1.2801e+00,  1.2806e+00,  1.2793e+00,  1.2793e+00,  1.3490e+00,
          1.3514e+00,  1.3503e+00,  1.3340e+00,  1.3480e+00,  1.2872e+00,
          1.3496e+00,  1.3455e+00,  1.2856e+00,  1.3004e+00,  1.2789e+00,
          1.3018e+00,  1.3014e+00,  1.2978e+00,  1.2972e+00,  1.2959e+00,
          1.2963e+00,  1.2963e+00,  2.8485e+00,  2.7783e+00,  2.5906e+00,
          2.6255e+00,  2.8472e+00,  2.5992e+00,  2.7587e+00,  2.6475e+00,
          2.5924e+00,  1.7442e+00,  1.7558e+00,  1.7220e+00,  1.7400e+00,
          1.7538e+00,  1.7504e+00,  1.7187e+00,  1.7235e+00,  1.7397e+00,
          1.6058e+00,  1.5880e+00,  1.5252e+00,  1.5238e+00,  1.6021e+00,
          1.5827e+00,  1.6176e+00,  1.5163e+00,  1.5757e+00],
        [ 1.8943e+00,  1.4981e+00,  6.5027e-01,  9.7115e-01,  1.3932e+00,
          1.8254e+00,  1.6991e+00,  1.9301e+00,  1.9301e+00,  1.7350e+00,
          1.3699e+00,  1.5795e+00,  9.8441e-01,  1.7848e+00,  1.7273e-01,
          1.6732e+00,  1.9547e+00,  8.9325e-01,  1.4003e+00,  1.0627e+00,
          8.1345e-01,  1.2096e+00,  1.7673e+00,  1.8330e+00,  1.6018e+00,
          1.9382e+00,  1.9382e+00,  9.0715e-01,  9.0105e-01,  1.9127e+00,
          1.7024e+00,  9.1302e-01,  1.8539e+00,  1.3110e+00,  1.9610e+00,
          1.8774e+00, -1.4026e-01, -3.8261e-01, -4.2595e-01, -1.8753e-01,
          6.4819e-02,  1.5350e-01, -2.6593e-01,  1.7767e+01,  3.2913e+00,
          2.7310e-01,  6.3781e-01,  6.6155e-01,  7.7477e-01,  4.2579e-01,
          7.7522e-01, -1.6951e-02,  8.0976e-01,  8.7169e-01],
        [ 1.3359e+00,  1.3726e+00,  1.4090e+00,  1.4046e+00,  1.3794e+00,
          1.3429e+00,  1.3132e+00,  1.3322e+00,  1.3322e+00,  1.3096e+00,
          1.4290e+00,  1.3261e+00,  1.4564e+00,  1.3854e+00,  1.4826e+00,
          1.3161e+00,  1.3609e+00,  1.3717e+00,  1.3942e+00,  1.3660e+00,
          1.4267e+00,  1.4078e+00,  1.3614e+00,  1.3546e+00,  1.2491e+00,
          1.3433e+00,  1.3433e+00,  1.3877e+00,  1.4391e+00,  1.3575e+00,
          1.1488e+00,  1.3451e+00,  1.2465e+00,  1.4137e+00,  1.2355e+00,
          1.3616e+00,  3.4806e-01,  2.7052e-01,  3.8499e-01,  3.5428e-01,
          1.4588e-01,  9.7859e-02,  3.7150e-01,  1.4475e-01, -6.3699e-02,
          3.4917e+00,  2.3029e+00,  3.4540e+00,  2.6455e+00,  1.8407e+00,
          1.4357e+00,  2.8725e+00,  3.3151e+00,  1.4003e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 322 : 174.51316934179425
Test loss for epoch 322 : 174.77396574184604
Test Precision for epoch 322 : 0.26153846153846155
Test Recall for epoch 322 : 0.26153846153846155
Test F1 for epoch 322 : 0.26153846153846155


theta for epoch 323 : tensor([[ 2.6348e+00,  2.6537e+00,  2.6909e+00,  2.8056e+00,  2.7865e+00,
          2.6380e+00,  2.7735e+00,  2.6331e+00,  2.6331e+00,  1.3366e+00,
          1.3388e+00,  1.3378e+00,  1.3409e+00,  1.3356e+00,  1.3430e+00,
          1.3371e+00,  1.3338e+00,  1.2962e+00,  1.2901e+00,  1.2479e+00,
          1.2487e+00,  1.2911e+00,  1.2876e+00,  1.2871e+00,  1.2893e+00,
          1.2862e+00,  1.2862e+00,  1.2704e+00,  1.3149e+00,  1.3086e+00,
          1.3118e+00,  1.3149e+00,  1.3100e+00,  1.3129e+00,  1.2647e+00,
          1.3089e+00,  1.7367e+00,  1.7478e+00,  1.7413e+00,  1.7374e+00,
          1.7459e+00,  1.6855e+00,  1.7382e+00,  1.7233e+00,  1.7371e+00,
          1.5946e+00,  1.5775e+00,  1.5741e+00,  1.5676e+00,  1.5910e+00,
          1.5726e+00,  1.6058e+00,  1.5638e+00,  1.5658e+00],
        [ 1.2901e+00,  1.2930e+00,  1.2863e+00,  1.2858e+00,  1.2937e+00,
          1.2907e+00,  1.2917e+00,  1.2898e+00,  1.2898e+00,  2.5855e+00,
          2.5994e+00,  2.5614e+00,  2.7832e+00,  2.5483e+00,  2.9573e+00,
          2.5875e+00,  2.7469e+00,  2.9299e+00,  1.2829e+00,  1.2878e+00,
          1.2412e+00,  1.2836e+00,  1.3101e+00,  1.3095e+00,  1.3109e+00,
          1.3086e+00,  1.3086e+00,  1.3101e+00,  1.2620e+00,  1.3305e+00,
          1.3339e+00,  1.3002e+00,  1.3320e+00,  1.3352e+00,  1.3046e+00,
          1.3308e+00,  1.7489e+00,  1.7610e+00,  1.7168e+00,  1.7487e+00,
          1.7590e+00,  1.7605e+00,  1.7133e+00,  1.7181e+00,  1.7484e+00,
          1.5551e+00,  1.5920e+00,  1.5881e+00,  1.5811e+00,  1.5153e+00,
          1.5865e+00,  1.5315e+00,  1.5770e+00,  1.5791e+00],
        [ 1.2737e+00,  1.2765e+00,  1.2770e+00,  1.2783e+00,  1.2764e+00,
          1.2743e+00,  1.2747e+00,  1.2734e+00,  1.2734e+00,  1.3425e+00,
          1.3448e+00,  1.3437e+00,  1.3469e+00,  1.3415e+00,  1.2892e+00,
          1.3430e+00,  1.2799e+00,  1.3309e+00,  2.6830e+00,  2.7913e+00,
          2.8406e+00,  2.6921e+00,  2.6224e+00,  2.6193e+00,  2.7673e+00,
          2.6142e+00,  2.6142e+00,  1.2733e+00,  1.3052e+00,  1.3143e+00,
          1.3175e+00,  1.2740e+00,  1.3158e+00,  1.3187e+00,  1.3142e+00,
          1.3146e+00,  1.7401e+00,  1.7514e+00,  1.7447e+00,  1.6763e+00,
          1.7495e+00,  1.7460e+00,  1.7416e+00,  1.7263e+00,  1.6760e+00,
          1.5993e+00,  1.5821e+00,  1.5786e+00,  1.5720e+00,  1.5766e+00,
          1.5770e+00,  1.5917e+00,  1.5645e+00,  1.5701e+00],
        [ 1.2805e+00,  1.2834e+00,  1.2838e+00,  1.2853e+00,  1.2833e+00,
          1.2810e+00,  1.2815e+00,  1.2802e+00,  1.2802e+00,  1.3490e+00,
          1.3513e+00,  1.3503e+00,  1.3339e+00,  1.3480e+00,  1.2873e+00,
          1.3495e+00,  1.3454e+00,  1.2857e+00,  1.3027e+00,  1.2812e+00,
          1.3041e+00,  1.3038e+00,  1.3001e+00,  1.2996e+00,  1.2982e+00,
          1.2987e+00,  1.2987e+00,  2.8486e+00,  2.7782e+00,  2.5909e+00,
          2.6254e+00,  2.8474e+00,  2.5995e+00,  2.7586e+00,  2.6478e+00,
          2.5926e+00,  1.7438e+00,  1.7554e+00,  1.7217e+00,  1.7396e+00,
          1.7535e+00,  1.7500e+00,  1.7184e+00,  1.7233e+00,  1.7392e+00,
          1.6039e+00,  1.5861e+00,  1.5234e+00,  1.5219e+00,  1.6002e+00,
          1.5808e+00,  1.6157e+00,  1.5143e+00,  1.5737e+00],
        [ 1.8946e+00,  1.4983e+00,  6.5040e-01,  9.7115e-01,  1.3934e+00,
          1.8257e+00,  1.6993e+00,  1.9303e+00,  1.9303e+00,  1.7344e+00,
          1.3694e+00,  1.5791e+00,  9.8412e-01,  1.7844e+00,  1.7247e-01,
          1.6726e+00,  1.9544e+00,  8.9272e-01,  1.4007e+00,  1.0632e+00,
          8.1374e-01,  1.2099e+00,  1.7679e+00,  1.8337e+00,  1.6025e+00,
          1.9389e+00,  1.9389e+00,  9.0723e-01,  9.0096e-01,  1.9128e+00,
          1.7024e+00,  9.1296e-01,  1.8539e+00,  1.3109e+00,  1.9611e+00,
          1.8774e+00, -1.4067e-01, -3.8301e-01, -4.2636e-01, -1.8808e-01,
          6.4373e-02,  1.5290e-01, -2.6633e-01,  1.7806e+01,  3.2679e+00,
          2.7263e-01,  6.3716e-01,  6.6080e-01,  7.7400e-01,  4.2525e-01,
          7.7448e-01, -1.7282e-02,  8.0906e-01,  8.7089e-01],
        [ 1.3363e+00,  1.3730e+00,  1.4092e+00,  1.4050e+00,  1.3798e+00,
          1.3433e+00,  1.3136e+00,  1.3326e+00,  1.3326e+00,  1.3094e+00,
          1.4288e+00,  1.3259e+00,  1.4562e+00,  1.3853e+00,  1.4825e+00,
          1.3160e+00,  1.3607e+00,  1.3716e+00,  1.3950e+00,  1.3666e+00,
          1.4275e+00,  1.4086e+00,  1.3622e+00,  1.3554e+00,  1.2497e+00,
          1.3441e+00,  1.3441e+00,  1.3878e+00,  1.4394e+00,  1.3578e+00,
          1.1490e+00,  1.3451e+00,  1.2467e+00,  1.4139e+00,  1.2357e+00,
          1.3619e+00,  3.4811e-01,  2.7058e-01,  3.8504e-01,  3.5429e-01,
          1.4594e-01,  9.7876e-02,  3.7155e-01,  1.4475e-01, -6.3575e-02,
          3.4943e+00,  2.3032e+00,  3.4564e+00,  2.6461e+00,  1.8407e+00,
          1.4356e+00,  2.8731e+00,  3.3182e+00,  1.4002e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 323 : 174.5004439822504
Test loss for epoch 323 : 174.7650984111549
Test Precision for epoch 323 : 0.26153846153846155
Test Recall for epoch 323 : 0.26153846153846155
Test F1 for epoch 323 : 0.26153846153846155


theta for epoch 324 : tensor([[ 2.6360,  2.6549,  2.6921,  2.8069,  2.7879,  2.6392,  2.7749,  2.6343,
          2.6343,  1.3367,  1.3390,  1.3380,  1.3410,  1.3357,  1.3431,  1.3372,
          1.3340,  1.2963,  1.2902,  1.2480,  1.2487,  1.2912,  1.2877,  1.2872,
          1.2894,  1.2864,  1.2864,  1.2708,  1.3153,  1.3090,  1.3122,  1.3154,
          1.3105,  1.3134,  1.2651,  1.3093,  1.7373,  1.7484,  1.7419,  1.7381,
          1.7466,  1.6861,  1.7388,  1.7239,  1.7378,  1.5913,  1.5742,  1.5708,
          1.5643,  1.5878,  1.5692,  1.6026,  1.5605,  1.5624],
        [ 1.2906,  1.2935,  1.2871,  1.2866,  1.2942,  1.2912,  1.2923,  1.2903,
          1.2903,  2.5871,  2.6011,  2.5640,  2.7861,  2.5509,  2.9589,  2.5892,
          2.7498,  2.9316,  1.2821,  1.2871,  1.2404,  1.2828,  1.3094,  1.3089,
          1.3102,  1.3080,  1.3080,  1.3100,  1.2620,  1.3305,  1.3339,  1.3004,
          1.3320,  1.3351,  1.3045,  1.3308,  1.7492,  1.7614,  1.7171,  1.7490,
          1.7593,  1.7608,  1.7137,  1.7189,  1.7488,  1.5511,  1.5879,  1.5841,
          1.5771,  1.5113,  1.5825,  1.5275,  1.5730,  1.5751],
        [ 1.2740,  1.2768,  1.2772,  1.2786,  1.2767,  1.2745,  1.2750,  1.2737,
          1.2737,  1.3415,  1.3438,  1.3427,  1.3459,  1.3405,  1.2881,  1.3420,
          1.2789,  1.3299,  2.6862,  2.7949,  2.8440,  2.6953,  2.6257,  2.6225,
          2.7709,  2.6174,  2.6174,  1.2729,  1.3048,  1.3140,  1.3172,  1.2736,
          1.3155,  1.3184,  1.3139,  1.3143,  1.7403,  1.7517,  1.7450,  1.6764,
          1.7498,  1.7461,  1.7418,  1.7266,  1.6761,  1.5954,  1.5781,  1.5746,
          1.5680,  1.5727,  1.5730,  1.5878,  1.5603,  1.5661],
        [ 1.2812,  1.2841,  1.2845,  1.2860,  1.2841,  1.2818,  1.2823,  1.2809,
          1.2809,  1.3489,  1.3512,  1.3501,  1.3338,  1.3478,  1.2873,  1.3494,
          1.3453,  1.2856,  1.3025,  1.2809,  1.3039,  1.3036,  1.2999,  1.2994,
          1.2979,  1.2985,  1.2985,  2.8501,  2.7795,  2.5926,  2.6266,  2.8489,
          2.6012,  2.7598,  2.6496,  2.5943,  1.7443,  1.7560,  1.7222,  1.7400,
          1.7540,  1.7504,  1.7189,  1.7240,  1.7397,  1.6006,  1.5827,  1.5203,
          1.5185,  1.5969,  1.5775,  1.6124,  1.5109,  1.5703],
        [ 1.8913,  1.4942,  0.6455,  0.9664,  1.3891,  1.8223,  1.6956,  1.9272,
          1.9272,  1.7295,  1.3640,  1.5744,  0.9788,  1.7798,  0.1667,  1.6677,
          1.9503,  0.8867,  1.3956,  1.0582,  0.8083,  1.2046,  1.7633,  1.8292,
          1.5981,  1.9346,  1.9346,  0.9021,  0.8955,  1.9086,  1.6977,  0.9075,
          1.8496,  1.3058,  1.9570,  1.8732, -0.1364, -0.3788, -0.4222, -0.1839,
          0.0687,  0.1571, -0.2621, 17.8506,  3.2499,  0.2665,  0.6308,  0.6543,
          0.7675,  0.4190,  0.7680, -0.0233,  0.8026,  0.8643],
        [ 1.3427,  1.3793,  1.4154,  1.4113,  1.3861,  1.3497,  1.3200,  1.3390,
          1.3390,  1.3161,  1.4355,  1.3326,  1.4628,  1.3919,  1.4891,  1.3227,
          1.3674,  1.3782,  1.4015,  1.3730,  1.4339,  1.4150,  1.3688,  1.3619,
          1.2562,  1.3506,  1.3506,  1.3939,  1.4456,  1.3641,  1.1556,  1.3512,
          1.2530,  1.4202,  1.2421,  1.3681,  0.3546,  0.2771,  0.3915,  0.3607,
          0.1526,  0.1045,  0.3780,  0.1513, -0.0568,  3.4899,  2.2966,  3.4518,
          2.6399,  1.8339,  1.4287,  2.8669,  3.3143,  1.3933]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 324 : 174.5347476134108
Test loss for epoch 324 : 174.81311733229808
Test Precision for epoch 324 : 0.26153846153846155
Test Recall for epoch 324 : 0.26153846153846155
Test F1 for epoch 324 : 0.26153846153846155


theta for epoch 325 : tensor([[ 2.6370e+00,  2.6560e+00,  2.6932e+00,  2.8082e+00,  2.7891e+00,
          2.6403e+00,  2.7761e+00,  2.6353e+00,  2.6353e+00,  1.3362e+00,
          1.3384e+00,  1.3374e+00,  1.3404e+00,  1.3352e+00,  1.3425e+00,
          1.3366e+00,  1.3334e+00,  1.2957e+00,  1.2859e+00,  1.2436e+00,
          1.2444e+00,  1.2869e+00,  1.2834e+00,  1.2829e+00,  1.2851e+00,
          1.2821e+00,  1.2821e+00,  1.2702e+00,  1.3147e+00,  1.3084e+00,
          1.3116e+00,  1.3147e+00,  1.3099e+00,  1.3127e+00,  1.2645e+00,
          1.3087e+00,  1.7355e+00,  1.7466e+00,  1.7401e+00,  1.7363e+00,
          1.7448e+00,  1.6843e+00,  1.7370e+00,  1.7221e+00,  1.7360e+00,
          1.5979e+00,  1.5808e+00,  1.5773e+00,  1.5709e+00,  1.5943e+00,
          1.5758e+00,  1.6091e+00,  1.5671e+00,  1.5690e+00],
        [ 1.2892e+00,  1.2922e+00,  1.2860e+00,  1.2855e+00,  1.2928e+00,
          1.2898e+00,  1.2909e+00,  1.2890e+00,  1.2890e+00,  2.5905e+00,
          2.6045e+00,  2.5683e+00,  2.7907e+00,  2.5551e+00,  2.9620e+00,
          2.5926e+00,  2.7545e+00,  2.9348e+00,  1.2762e+00,  1.2811e+00,
          1.2345e+00,  1.2769e+00,  1.3036e+00,  1.3030e+00,  1.3044e+00,
          1.3021e+00,  1.3021e+00,  1.3085e+00,  1.2605e+00,  1.3290e+00,
          1.3324e+00,  1.2992e+00,  1.3305e+00,  1.3337e+00,  1.3030e+00,
          1.3293e+00,  1.7470e+00,  1.7592e+00,  1.7149e+00,  1.7469e+00,
          1.7572e+00,  1.7587e+00,  1.7115e+00,  1.7173e+00,  1.7466e+00,
          1.5574e+00,  1.5943e+00,  1.5905e+00,  1.5833e+00,  1.5175e+00,
          1.5888e+00,  1.5337e+00,  1.5793e+00,  1.5814e+00],
        [ 1.2731e+00,  1.2759e+00,  1.2762e+00,  1.2778e+00,  1.2758e+00,
          1.2737e+00,  1.2741e+00,  1.2729e+00,  1.2729e+00,  1.3406e+00,
          1.3429e+00,  1.3418e+00,  1.3449e+00,  1.3396e+00,  1.2872e+00,
          1.3411e+00,  1.2779e+00,  1.3290e+00,  2.6865e+00,  2.7956e+00,
          2.8445e+00,  2.6956e+00,  2.6260e+00,  2.6228e+00,  2.7716e+00,
          2.6177e+00,  2.6177e+00,  1.2720e+00,  1.3040e+00,  1.3132e+00,
          1.3164e+00,  1.2727e+00,  1.3146e+00,  1.3176e+00,  1.3131e+00,
          1.3135e+00,  1.7384e+00,  1.7497e+00,  1.7430e+00,  1.6743e+00,
          1.7478e+00,  1.7441e+00,  1.7399e+00,  1.7247e+00,  1.6741e+00,
          1.6017e+00,  1.5845e+00,  1.5809e+00,  1.5744e+00,  1.5790e+00,
          1.5794e+00,  1.5941e+00,  1.5666e+00,  1.5725e+00],
        [ 1.2803e+00,  1.2832e+00,  1.2835e+00,  1.2851e+00,  1.2831e+00,
          1.2808e+00,  1.2813e+00,  1.2800e+00,  1.2800e+00,  1.3478e+00,
          1.3501e+00,  1.3490e+00,  1.3326e+00,  1.3468e+00,  1.2862e+00,
          1.3483e+00,  1.3443e+00,  1.2846e+00,  1.2980e+00,  1.2763e+00,
          1.2993e+00,  1.2990e+00,  1.2954e+00,  1.2949e+00,  1.2933e+00,
          1.2940e+00,  1.2940e+00,  2.8523e+00,  2.7814e+00,  2.5949e+00,
          2.6284e+00,  2.8511e+00,  2.6035e+00,  2.7618e+00,  2.6519e+00,
          2.5966e+00,  1.7422e+00,  1.7539e+00,  1.7201e+00,  1.7379e+00,
          1.7520e+00,  1.7483e+00,  1.7168e+00,  1.7221e+00,  1.7376e+00,
          1.6066e+00,  1.5887e+00,  1.5264e+00,  1.5246e+00,  1.6028e+00,
          1.5835e+00,  1.6183e+00,  1.5168e+00,  1.5764e+00],
        [ 1.8985e+00,  1.5028e+00,  6.5534e-01,  9.7552e-01,  1.3978e+00,
          1.8297e+00,  1.7035e+00,  1.9342e+00,  1.9342e+00,  1.7384e+00,
          1.3737e+00,  1.5835e+00,  9.8887e-01,  1.7888e+00,  1.7747e-01,
          1.6767e+00,  1.9585e+00,  8.9739e-01,  1.4043e+00,  1.0673e+00,
          8.1793e-01,  1.2137e+00,  1.7710e+00,  1.8366e+00,  1.6061e+00,
          1.9416e+00,  1.9416e+00,  9.1218e-01,  9.0568e-01,  1.9170e+00,
          1.7066e+00,  9.1776e-01,  1.8582e+00,  1.3154e+00,  1.9653e+00,
          1.8817e+00, -1.4592e-01, -3.8803e-01, -4.3138e-01, -1.9356e-01,
          5.9002e-02,  1.4719e-01, -2.7147e-01,  1.7881e+01,  3.2164e+00,
          2.7762e-01,  6.4162e-01,  6.6510e-01,  7.7819e-01,  4.3011e-01,
          7.7879e-01, -1.1929e-02,  8.1333e-01,  8.7502e-01],
        [ 1.3338e+00,  1.3705e+00,  1.4063e+00,  1.4024e+00,  1.3772e+00,
          1.3408e+00,  1.3110e+00,  1.3301e+00,  1.3301e+00,  1.3064e+00,
          1.4257e+00,  1.3227e+00,  1.4530e+00,  1.3822e+00,  1.4792e+00,
          1.3129e+00,  1.3576e+00,  1.3684e+00,  1.3908e+00,  1.3619e+00,
          1.4232e+00,  1.4043e+00,  1.3581e+00,  1.3512e+00,  1.2451e+00,
          1.3399e+00,  1.3399e+00,  1.3845e+00,  1.4366e+00,  1.3549e+00,
          1.1460e+00,  1.3419e+00,  1.2438e+00,  1.4111e+00,  1.2328e+00,
          1.3590e+00,  3.4438e-01,  2.6692e-01,  3.8130e-01,  3.5048e-01,
          1.4228e-01,  9.4144e-02,  3.6783e-01,  1.4084e-01, -6.7119e-02,
          3.5035e+00,  2.3078e+00,  3.4651e+00,  2.6515e+00,  1.8448e+00,
          1.4396e+00,  2.8784e+00,  3.3284e+00,  1.4042e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 325 : 174.54983020328632
Test loss for epoch 325 : 174.81357628165904
Test Precision for epoch 325 : 0.26153846153846155
Test Recall for epoch 325 : 0.26153846153846155
Test F1 for epoch 325 : 0.26153846153846155


theta for epoch 326 : tensor([[ 2.6385,  2.6575,  2.6947,  2.8098,  2.7907,  2.6418,  2.7777,  2.6368,
          2.6368,  1.3345,  1.3367,  1.3357,  1.3387,  1.3335,  1.3408,  1.3350,
          1.3318,  1.2940,  1.2896,  1.2473,  1.2481,  1.2906,  1.2872,  1.2867,
          1.2889,  1.2859,  1.2859,  1.2690,  1.3136,  1.3073,  1.3105,  1.3136,
          1.3087,  1.3116,  1.2634,  1.3076,  1.7375,  1.7486,  1.7421,  1.7382,
          1.7468,  1.6863,  1.7389,  1.7240,  1.7380,  1.5926,  1.5756,  1.5721,
          1.5656,  1.5891,  1.5706,  1.6039,  1.5618,  1.5638],
        [ 1.2889,  1.2918,  1.2860,  1.2854,  1.2925,  1.2895,  1.2905,  1.2886,
          1.2886,  2.5896,  2.6037,  2.5683,  2.7910,  2.5551,  2.9614,  2.5917,
          2.7549,  2.9342,  1.2813,  1.2862,  1.2395,  1.2820,  1.3087,  1.3081,
          1.3095,  1.3072,  1.3072,  1.3080,  1.2599,  1.3285,  1.3319,  1.2990,
          1.3300,  1.3331,  1.3025,  1.3288,  1.7492,  1.7614,  1.7171,  1.7491,
          1.7593,  1.7609,  1.7137,  1.7197,  1.7488,  1.5524,  1.5893,  1.5855,
          1.5784,  1.5126,  1.5838,  1.5288,  1.5743,  1.5764],
        [ 1.2722,  1.2750,  1.2752,  1.2768,  1.2749,  1.2728,  1.2732,  1.2720,
          1.2720,  1.3388,  1.3410,  1.3400,  1.3431,  1.3378,  1.2854,  1.3393,
          1.2761,  1.3271,  2.6909,  2.8004,  2.8491,  2.7000,  2.6304,  2.6272,
          2.7764,  2.6222,  2.6222,  1.2707,  1.3029,  1.3121,  1.3152,  1.2714,
          1.3135,  1.3164,  1.3120,  1.3124,  1.7404,  1.7517,  1.7450,  1.6761,
          1.7498,  1.7460,  1.7419,  1.7266,  1.6759,  1.5966,  1.5793,  1.5757,
          1.5692,  1.5739,  1.5742,  1.5889,  1.5613,  1.5673],
        [ 1.2795,  1.2824,  1.2826,  1.2843,  1.2823,  1.2801,  1.2806,  1.2792,
          1.2792,  1.3462,  1.3485,  1.3474,  1.3310,  1.3451,  1.2846,  1.3467,
          1.3427,  1.2831,  1.3017,  1.2799,  1.3030,  1.3028,  1.2992,  1.2986,
          1.2970,  1.2978,  1.2978,  2.8536,  2.7825,  2.5963,  2.6295,  2.8524,
          2.6049,  2.7629,  2.6535,  2.5981,  1.7444,  1.7560,  1.7222,  1.7399,
          1.7541,  1.7503,  1.7189,  1.7244,  1.7396,  1.6017,  1.5838,  1.5216,
          1.5196,  1.5979,  1.5785,  1.6134,  1.5117,  1.5714],
        [ 1.8918,  1.4947,  0.6463,  0.9669,  1.3897,  1.8228,  1.6961,  1.9277,
          1.9277,  1.7297,  1.3643,  1.5750,  0.9795,  1.7804,  0.1676,  1.6679,
          1.9509,  0.8870,  1.3968,  1.0597,  0.8095,  1.2057,  1.7647,  1.8306,
          1.5999,  1.9361,  1.9361,  0.9030,  0.8960,  1.9091,  1.6981,  0.9081,
          1.8500,  1.3062,  1.9575,  1.8736, -0.1381, -0.3804, -0.4238, -0.1860,
          0.0668,  0.1549, -0.2638, 17.9283,  3.2025,  0.2674,  0.6312,  0.6545,
          0.7675,  0.4197,  0.7682, -0.0220,  0.8028,  0.8644],
        [ 1.3428,  1.3794,  1.4151,  1.4114,  1.3862,  1.3498,  1.3201,  1.3391,
          1.3391,  1.3163,  1.4355,  1.3327,  1.4628,  1.3920,  1.4891,  1.3228,
          1.3675,  1.3783,  1.4022,  1.3734,  1.4346,  1.4158,  1.3695,  1.3627,
          1.2566,  1.3514,  1.3514,  1.3936,  1.4456,  1.3642,  1.1557,  1.3509,
          1.2532,  1.4202,  1.2423,  1.3682,  0.3548,  0.2775,  0.3918,  0.3609,
          0.1529,  0.1048,  0.3783,  0.1514, -0.0563,  3.4950,  2.2971,  3.4564,
          2.6412,  1.8339,  1.4287,  2.8681,  3.3204,  1.3933]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 326 : 174.51855399740137
Test loss for epoch 326 : 174.80278231556568
Test Precision for epoch 326 : 0.26153846153846155
Test Recall for epoch 326 : 0.26153846153846155
Test F1 for epoch 326 : 0.26153846153846155


theta for epoch 327 : tensor([[ 2.6399e+00,  2.6588e+00,  2.6960e+00,  2.8113e+00,  2.7922e+00,
          2.6431e+00,  2.7792e+00,  2.6382e+00,  2.6382e+00,  1.3353e+00,
          1.3375e+00,  1.3365e+00,  1.3395e+00,  1.3343e+00,  1.3416e+00,
          1.3358e+00,  1.3326e+00,  1.2948e+00,  1.2860e+00,  1.2436e+00,
          1.2444e+00,  1.2870e+00,  1.2836e+00,  1.2831e+00,  1.2852e+00,
          1.2822e+00,  1.2822e+00,  1.2683e+00,  1.3129e+00,  1.3067e+00,
          1.3098e+00,  1.3129e+00,  1.3081e+00,  1.3110e+00,  1.2627e+00,
          1.3070e+00,  1.7366e+00,  1.7477e+00,  1.7412e+00,  1.7373e+00,
          1.7459e+00,  1.6854e+00,  1.7380e+00,  1.7231e+00,  1.7371e+00,
          1.5954e+00,  1.5783e+00,  1.5749e+00,  1.5684e+00,  1.5918e+00,
          1.5734e+00,  1.6066e+00,  1.5646e+00,  1.5666e+00],
        [ 1.2883e+00,  1.2912e+00,  1.2857e+00,  1.2851e+00,  1.2919e+00,
          1.2889e+00,  1.2900e+00,  1.2881e+00,  1.2881e+00,  2.5904e+00,
          2.6045e+00,  2.5700e+00,  2.7930e+00,  2.5567e+00,  2.9623e+00,
          2.5925e+00,  2.7569e+00,  2.9351e+00,  1.2783e+00,  1.2833e+00,
          1.2366e+00,  1.2791e+00,  1.3057e+00,  1.3052e+00,  1.3065e+00,
          1.3043e+00,  1.3043e+00,  1.3077e+00,  1.2597e+00,  1.3282e+00,
          1.3316e+00,  1.2990e+00,  1.3298e+00,  1.3329e+00,  1.3023e+00,
          1.3285e+00,  1.7485e+00,  1.7607e+00,  1.7164e+00,  1.7483e+00,
          1.7586e+00,  1.7602e+00,  1.7130e+00,  1.7195e+00,  1.7481e+00,
          1.5560e+00,  1.5929e+00,  1.5890e+00,  1.5819e+00,  1.5161e+00,
          1.5874e+00,  1.5322e+00,  1.5778e+00,  1.5799e+00],
        [ 1.2727e+00,  1.2754e+00,  1.2755e+00,  1.2772e+00,  1.2753e+00,
          1.2732e+00,  1.2736e+00,  1.2724e+00,  1.2724e+00,  1.3421e+00,
          1.3444e+00,  1.3433e+00,  1.3464e+00,  1.3411e+00,  1.2886e+00,
          1.3426e+00,  1.2795e+00,  1.3305e+00,  2.6864e+00,  2.7963e+00,
          2.8449e+00,  2.6955e+00,  2.6258e+00,  2.6226e+00,  2.7722e+00,
          2.6176e+00,  2.6176e+00,  1.2715e+00,  1.3037e+00,  1.3129e+00,
          1.3161e+00,  1.2722e+00,  1.3143e+00,  1.3173e+00,  1.3128e+00,
          1.3132e+00,  1.7402e+00,  1.7516e+00,  1.7448e+00,  1.6759e+00,
          1.7497e+00,  1.7457e+00,  1.7417e+00,  1.7264e+00,  1.6757e+00,
          1.6007e+00,  1.5835e+00,  1.5799e+00,  1.5734e+00,  1.5780e+00,
          1.5784e+00,  1.5931e+00,  1.5654e+00,  1.5715e+00],
        [ 1.2788e+00,  1.2817e+00,  1.2818e+00,  1.2836e+00,  1.2816e+00,
          1.2794e+00,  1.2799e+00,  1.2785e+00,  1.2785e+00,  1.3475e+00,
          1.3498e+00,  1.3488e+00,  1.3323e+00,  1.3465e+00,  1.2861e+00,
          1.3480e+00,  1.3440e+00,  1.2845e+00,  1.2988e+00,  1.2769e+00,
          1.3001e+00,  1.2998e+00,  1.2962e+00,  1.2957e+00,  1.2940e+00,
          1.2949e+00,  1.2949e+00,  2.8546e+00,  2.7833e+00,  2.5974e+00,
          2.6301e+00,  2.8534e+00,  2.6060e+00,  2.7636e+00,  2.6546e+00,
          2.5991e+00,  1.7436e+00,  1.7553e+00,  1.7214e+00,  1.7390e+00,
          1.7533e+00,  1.7494e+00,  1.7181e+00,  1.7237e+00,  1.7387e+00,
          1.6046e+00,  1.5867e+00,  1.5247e+00,  1.5226e+00,  1.6008e+00,
          1.5815e+00,  1.6163e+00,  1.5146e+00,  1.5744e+00],
        [ 1.8961e+00,  1.4998e+00,  6.5223e-01,  9.7224e-01,  1.3948e+00,
          1.8272e+00,  1.7008e+00,  1.9318e+00,  1.9318e+00,  1.7355e+00,
          1.3705e+00,  1.5809e+00,  9.8584e-01,  1.7863e+00,  1.7425e-01,
          1.6738e+00,  1.9565e+00,  8.9363e-01,  1.4017e+00,  1.0650e+00,
          8.1507e-01,  1.2109e+00,  1.7689e+00,  1.8346e+00,  1.6044e+00,
          1.9399e+00,  1.9399e+00,  9.0909e-01,  9.0210e-01,  1.9141e+00,
          1.7034e+00,  9.1423e-01,  1.8552e+00,  1.3119e+00,  1.9625e+00,
          1.8788e+00, -1.4410e-01, -3.8613e-01, -4.2954e-01, -1.9202e-01,
          6.0776e-02,  1.4863e-01, -2.6964e-01,  1.7962e+01,  3.1733e+00,
          2.7382e-01,  6.3732e-01,  6.6054e-01,  7.7351e-01,  4.2614e-01,
          7.7426e-01, -1.5311e-02,  8.0878e-01,  8.7031e-01],
        [ 1.3363e+00,  1.3729e+00,  1.4084e+00,  1.4049e+00,  1.3797e+00,
          1.3433e+00,  1.3135e+00,  1.3326e+00,  1.3326e+00,  1.3097e+00,
          1.4290e+00,  1.3260e+00,  1.4563e+00,  1.3854e+00,  1.4825e+00,
          1.3162e+00,  1.3609e+00,  1.3717e+00,  1.3944e+00,  1.3652e+00,
          1.4268e+00,  1.4079e+00,  1.3616e+00,  1.3548e+00,  1.2484e+00,
          1.3435e+00,  1.3435e+00,  1.3868e+00,  1.4391e+00,  1.3576e+00,
          1.1488e+00,  1.3442e+00,  1.2465e+00,  1.4137e+00,  1.2355e+00,
          1.3617e+00,  3.4765e-01,  2.7034e-01,  3.8461e-01,  3.5367e-01,
          1.4571e-01,  9.7503e-02,  3.7110e-01,  1.4397e-01, -6.3547e-02,
          3.5052e+00,  2.3050e+00,  3.4664e+00,  2.6495e+00,  1.8416e+00,
          1.4363e+00,  2.8763e+00,  3.3311e+00,  1.4008e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 327 : 174.46807103957332
Test loss for epoch 327 : 174.7441443120856
Test Precision for epoch 327 : 0.26153846153846155
Test Recall for epoch 327 : 0.26153846153846155
Test F1 for epoch 327 : 0.26153846153846155


theta for epoch 328 : tensor([[ 2.6406e+00,  2.6596e+00,  2.6968e+00,  2.8122e+00,  2.7931e+00,
          2.6439e+00,  2.7801e+00,  2.6390e+00,  2.6390e+00,  1.3348e+00,
          1.3370e+00,  1.3360e+00,  1.3390e+00,  1.3338e+00,  1.3411e+00,
          1.3353e+00,  1.3321e+00,  1.2943e+00,  1.2885e+00,  1.2461e+00,
          1.2469e+00,  1.2895e+00,  1.2861e+00,  1.2856e+00,  1.2878e+00,
          1.2848e+00,  1.2848e+00,  1.2683e+00,  1.3129e+00,  1.3067e+00,
          1.3098e+00,  1.3129e+00,  1.3081e+00,  1.3110e+00,  1.2627e+00,
          1.3070e+00,  1.7367e+00,  1.7478e+00,  1.7413e+00,  1.7374e+00,
          1.7460e+00,  1.6855e+00,  1.7381e+00,  1.7232e+00,  1.7372e+00,
          1.5937e+00,  1.5767e+00,  1.5732e+00,  1.5667e+00,  1.5901e+00,
          1.5717e+00,  1.6049e+00,  1.5629e+00,  1.5649e+00],
        [ 1.2883e+00,  1.2913e+00,  1.2860e+00,  1.2854e+00,  1.2919e+00,
          1.2890e+00,  1.2900e+00,  1.2881e+00,  1.2881e+00,  2.5890e+00,
          2.6031e+00,  2.5694e+00,  2.7928e+00,  2.5561e+00,  2.9613e+00,
          2.5911e+00,  2.7567e+00,  2.9339e+00,  1.2821e+00,  1.2870e+00,
          1.2402e+00,  1.2828e+00,  1.3094e+00,  1.3089e+00,  1.3102e+00,
          1.3080e+00,  1.3080e+00,  1.3083e+00,  1.2603e+00,  1.3288e+00,
          1.3322e+00,  1.2998e+00,  1.3304e+00,  1.3335e+00,  1.3029e+00,
          1.3292e+00,  1.7488e+00,  1.7610e+00,  1.7167e+00,  1.7487e+00,
          1.7589e+00,  1.7605e+00,  1.7133e+00,  1.7202e+00,  1.7485e+00,
          1.5548e+00,  1.5917e+00,  1.5878e+00,  1.5807e+00,  1.5149e+00,
          1.5862e+00,  1.5310e+00,  1.5767e+00,  1.5788e+00],
        [ 1.2724e+00,  1.2751e+00,  1.2751e+00,  1.2769e+00,  1.2750e+00,
          1.2729e+00,  1.2733e+00,  1.2721e+00,  1.2721e+00,  1.3419e+00,
          1.3441e+00,  1.3431e+00,  1.3462e+00,  1.3409e+00,  1.2883e+00,
          1.3424e+00,  1.2793e+00,  1.3302e+00,  2.6882e+00,  2.7984e+00,
          2.8468e+00,  2.6973e+00,  2.6275e+00,  2.6244e+00,  2.7743e+00,
          2.6193e+00,  2.6193e+00,  1.2716e+00,  1.3039e+00,  1.3131e+00,
          1.3163e+00,  1.2723e+00,  1.3146e+00,  1.3175e+00,  1.3131e+00,
          1.3134e+00,  1.7403e+00,  1.7517e+00,  1.7450e+00,  1.6759e+00,
          1.7498e+00,  1.7458e+00,  1.7418e+00,  1.7265e+00,  1.6757e+00,
          1.5992e+00,  1.5820e+00,  1.5784e+00,  1.5719e+00,  1.5765e+00,
          1.5769e+00,  1.5916e+00,  1.5638e+00,  1.5700e+00],
        [ 1.2786e+00,  1.2814e+00,  1.2815e+00,  1.2834e+00,  1.2814e+00,
          1.2791e+00,  1.2796e+00,  1.2783e+00,  1.2783e+00,  1.3474e+00,
          1.3496e+00,  1.3486e+00,  1.3322e+00,  1.3463e+00,  1.2860e+00,
          1.3479e+00,  1.3439e+00,  1.2845e+00,  1.3016e+00,  1.2796e+00,
          1.3029e+00,  1.3026e+00,  1.2990e+00,  1.2985e+00,  1.2967e+00,
          1.2977e+00,  1.2977e+00,  2.8551e+00,  2.7835e+00,  2.5979e+00,
          2.6303e+00,  2.8539e+00,  2.6065e+00,  2.7638e+00,  2.6552e+00,
          2.5996e+00,  1.7438e+00,  1.7555e+00,  1.7217e+00,  1.7391e+00,
          1.7535e+00,  1.7496e+00,  1.7184e+00,  1.7241e+00,  1.7388e+00,
          1.6032e+00,  1.5853e+00,  1.5235e+00,  1.5212e+00,  1.5994e+00,
          1.5801e+00,  1.6149e+00,  1.5132e+00,  1.5730e+00],
        [ 1.8954e+00,  1.4989e+00,  6.5140e-01,  9.7128e-01,  1.3939e+00,
          1.8265e+00,  1.7000e+00,  1.9312e+00,  1.9312e+00,  1.7344e+00,
          1.3693e+00,  1.5800e+00,  9.8484e-01,  1.7854e+00,  1.7330e-01,
          1.6727e+00,  1.9557e+00,  8.9232e-01,  1.4016e+00,  1.0650e+00,
          8.1474e-01,  1.2107e+00,  1.7692e+00,  1.8351e+00,  1.6048e+00,
          1.9404e+00,  1.9404e+00,  9.0840e-01,  9.0120e-01,  1.9136e+00,
          1.7027e+00,  9.1336e-01,  1.8547e+00,  1.3111e+00,  1.9620e+00,
          1.8782e+00, -1.4399e-01, -3.8597e-01, -4.2940e-01, -1.9205e-01,
          6.0862e-02,  1.4855e-01, -2.6952e-01,  1.8001e+01,  3.1511e+00,
          2.7243e-01,  6.3561e-01,  6.5870e-01,  7.7158e-01,  4.2466e-01,
          7.7242e-01, -1.6432e-02,  8.0690e-01,  8.6835e-01],
        [ 1.3364e+00,  1.3730e+00,  1.4083e+00,  1.4050e+00,  1.3798e+00,
          1.3434e+00,  1.3136e+00,  1.3327e+00,  1.3327e+00,  1.3098e+00,
          1.4291e+00,  1.3261e+00,  1.4564e+00,  1.3855e+00,  1.4826e+00,
          1.3163e+00,  1.3609e+00,  1.3718e+00,  1.3955e+00,  1.3661e+00,
          1.4279e+00,  1.4090e+00,  1.3627e+00,  1.3559e+00,  1.2492e+00,
          1.3446e+00,  1.3446e+00,  1.3869e+00,  1.4395e+00,  1.3579e+00,
          1.1491e+00,  1.3443e+00,  1.2468e+00,  1.4140e+00,  1.2359e+00,
          1.3620e+00,  3.4771e-01,  2.7049e-01,  3.8469e-01,  3.5368e-01,
          1.4587e-01,  9.7622e-02,  3.7117e-01,  1.4392e-01, -6.3339e-02,
          3.5073e+00,  2.3049e+00,  3.4683e+00,  2.6497e+00,  1.8412e+00,
          1.4358e+00,  2.8765e+00,  3.3338e+00,  1.4004e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 328 : 174.453337986289
Test loss for epoch 328 : 174.7340932308012
Test Precision for epoch 328 : 0.26153846153846155
Test Recall for epoch 328 : 0.26153846153846155
Test F1 for epoch 328 : 0.26153846153846155


theta for epoch 329 : tensor([[ 2.6420,  2.6609,  2.6982,  2.8137,  2.7946,  2.6452,  2.7816,  2.6403,
          2.6403,  1.3350,  1.3372,  1.3362,  1.3392,  1.3340,  1.3413,  1.3355,
          1.3323,  1.2944,  1.2883,  1.2459,  1.2467,  1.2893,  1.2859,  1.2854,
          1.2876,  1.2846,  1.2846,  1.2687,  1.3133,  1.3071,  1.3102,  1.3133,
          1.3085,  1.3114,  1.2631,  1.3074,  1.7371,  1.7482,  1.7417,  1.7379,
          1.7464,  1.6859,  1.7385,  1.7236,  1.7376,  1.5912,  1.5742,  1.5708,
          1.5643,  1.5877,  1.5693,  1.6024,  1.5605,  1.5625],
        [ 1.2885,  1.2914,  1.2863,  1.2857,  1.2920,  1.2891,  1.2901,  1.2882,
          1.2882,  2.5905,  2.6047,  2.5717,  2.7954,  2.5584,  2.9628,  2.5927,
          2.7594,  2.9355,  1.2815,  1.2865,  1.2397,  1.2823,  1.3089,  1.3084,
          1.3097,  1.3075,  1.3075,  1.3086,  1.2606,  1.3291,  1.3325,  1.3003,
          1.3306,  1.3337,  1.3032,  1.3294,  1.7491,  1.7613,  1.7170,  1.7490,
          1.7592,  1.7608,  1.7136,  1.7209,  1.7488,  1.5519,  1.5889,  1.5851,
          1.5780,  1.5122,  1.5835,  1.5282,  1.5739,  1.5761],
        [ 1.2722,  1.2750,  1.2749,  1.2768,  1.2748,  1.2728,  1.2731,  1.2720,
          1.2720,  1.3414,  1.3436,  1.3426,  1.3456,  1.3404,  1.2878,  1.3419,
          1.2787,  1.3297,  2.6911,  2.8016,  2.8499,  2.7002,  2.6305,  2.6273,
          2.7776,  2.6222,  2.6222,  1.2715,  1.3039,  1.3131,  1.3163,  1.2722,
          1.3146,  1.3175,  1.3131,  1.3134,  1.7405,  1.7519,  1.7452,  1.6760,
          1.7500,  1.7459,  1.7420,  1.7267,  1.6758,  1.5963,  1.5791,  1.5756,
          1.5690,  1.5737,  1.5741,  1.5886,  1.5609,  1.5672],
        [ 1.2789,  1.2817,  1.2817,  1.2836,  1.2817,  1.2794,  1.2799,  1.2786,
          1.2786,  1.3476,  1.3499,  1.3489,  1.3324,  1.3466,  1.2864,  1.3481,
          1.3442,  1.2848,  1.3014,  1.2794,  1.3027,  1.3024,  1.2989,  1.2984,
          1.2965,  1.2975,  1.2975,  2.8567,  2.7849,  2.5996,  2.6316,  2.8556,
          2.6082,  2.7652,  2.6569,  2.6013,  1.7442,  1.7559,  1.7221,  1.7395,
          1.7540,  1.7499,  1.7188,  1.7247,  1.7392,  1.6008,  1.5830,  1.5213,
          1.5189,  1.5971,  1.5778,  1.6126,  1.5108,  1.5707],
        [ 1.8929,  1.4957,  0.6476,  0.9676,  1.3906,  1.8239,  1.6972,  1.9288,
          1.9288,  1.7309,  1.3653,  1.5765,  0.9809,  1.7821,  0.1690,  1.6691,
          1.9529,  0.8877,  1.3978,  1.0613,  0.8106,  1.2067,  1.7658,  1.8318,
          1.6016,  1.9374,  1.9374,  0.9046,  0.8971,  1.9108,  1.6994,  0.9093,
          1.8517,  1.3073,  1.9592,  1.8753, -0.1410, -0.3830, -0.4265, -0.1892,
          0.0639,  0.1514, -0.2666, 18.0439,  3.1321,  0.2675,  0.6304,  0.6533,
          0.7661,  0.4196,  0.7670, -0.0211,  0.8015,  0.8628],
        [ 1.3408,  1.3774,  1.4125,  1.4094,  1.3842,  1.3478,  1.3181,  1.3371,
          1.3371,  1.3146,  1.4339,  1.3309,  1.4612,  1.3902,  1.4874,  1.3211,
          1.3657,  1.3766,  1.4000,  1.3704,  1.4324,  1.4135,  1.3672,  1.3604,
          1.2536,  1.3491,  1.3491,  1.3913,  1.4440,  1.3625,  1.1538,  1.3487,
          1.2514,  1.4186,  1.2405,  1.3666,  0.3519,  0.2749,  0.3890,  0.3579,
          0.1503,  0.1020,  0.3754,  0.1481, -0.0588,  3.5048,  2.3001,  3.4655,
          2.6453,  1.8362,  1.4308,  2.8721,  3.3317,  1.3954]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 329 : 174.47070715054872
Test loss for epoch 329 : 174.76232948194257
Test Precision for epoch 329 : 0.26153846153846155
Test Recall for epoch 329 : 0.26153846153846155
Test F1 for epoch 329 : 0.26153846153846155


theta for epoch 330 : tensor([[ 2.6436e+00,  2.6625e+00,  2.6998e+00,  2.8154e+00,  2.7963e+00,
          2.6468e+00,  2.7833e+00,  2.6419e+00,  2.6419e+00,  1.3347e+00,
          1.3368e+00,  1.3358e+00,  1.3388e+00,  1.3337e+00,  1.3409e+00,
          1.3351e+00,  1.3319e+00,  1.2941e+00,  1.2841e+00,  1.2417e+00,
          1.2425e+00,  1.2851e+00,  1.2817e+00,  1.2813e+00,  1.2834e+00,
          1.2804e+00,  1.2804e+00,  1.2685e+00,  1.3131e+00,  1.3069e+00,
          1.3100e+00,  1.3131e+00,  1.3083e+00,  1.3111e+00,  1.2629e+00,
          1.3072e+00,  1.7354e+00,  1.7465e+00,  1.7400e+00,  1.7362e+00,
          1.7447e+00,  1.6842e+00,  1.7368e+00,  1.7219e+00,  1.7359e+00,
          1.5963e+00,  1.5795e+00,  1.5760e+00,  1.5695e+00,  1.5928e+00,
          1.5745e+00,  1.6075e+00,  1.5657e+00,  1.5678e+00],
        [ 1.2878e+00,  1.2908e+00,  1.2859e+00,  1.2853e+00,  1.2914e+00,
          1.2884e+00,  1.2895e+00,  1.2876e+00,  1.2876e+00,  2.5943e+00,
          2.6085e+00,  2.5763e+00,  2.8002e+00,  2.5630e+00,  2.9662e+00,
          2.5965e+00,  2.7643e+00,  2.9391e+00,  1.2755e+00,  1.2804e+00,
          1.2337e+00,  1.2763e+00,  1.3030e+00,  1.3025e+00,  1.3038e+00,
          1.3016e+00,  1.3016e+00,  1.3074e+00,  1.2594e+00,  1.3280e+00,
          1.3314e+00,  1.2994e+00,  1.3295e+00,  1.3326e+00,  1.3020e+00,
          1.3283e+00,  1.7470e+00,  1.7592e+00,  1.7150e+00,  1.7469e+00,
          1.7572e+00,  1.7587e+00,  1.7115e+00,  1.7193e+00,  1.7467e+00,
          1.5567e+00,  1.5938e+00,  1.5900e+00,  1.5829e+00,  1.5169e+00,
          1.5884e+00,  1.5328e+00,  1.5788e+00,  1.5809e+00],
        [ 1.2719e+00,  1.2747e+00,  1.2745e+00,  1.2764e+00,  1.2745e+00,
          1.2724e+00,  1.2728e+00,  1.2716e+00,  1.2716e+00,  1.3402e+00,
          1.3424e+00,  1.3414e+00,  1.3445e+00,  1.3392e+00,  1.2866e+00,
          1.3407e+00,  1.2775e+00,  1.3285e+00,  2.6925e+00,  2.8034e+00,
          2.8515e+00,  2.7016e+00,  2.6318e+00,  2.6286e+00,  2.7794e+00,
          2.6236e+00,  2.6236e+00,  1.2706e+00,  1.3032e+00,  1.3124e+00,
          1.3156e+00,  1.2713e+00,  1.3138e+00,  1.3167e+00,  1.3123e+00,
          1.3127e+00,  1.7386e+00,  1.7500e+00,  1.7433e+00,  1.6739e+00,
          1.7481e+00,  1.7439e+00,  1.7401e+00,  1.7248e+00,  1.6737e+00,
          1.6010e+00,  1.5838e+00,  1.5803e+00,  1.5738e+00,  1.5783e+00,
          1.5788e+00,  1.5933e+00,  1.5656e+00,  1.5720e+00],
        [ 1.2789e+00,  1.2817e+00,  1.2816e+00,  1.2836e+00,  1.2816e+00,
          1.2794e+00,  1.2799e+00,  1.2786e+00,  1.2786e+00,  1.3470e+00,
          1.3493e+00,  1.3482e+00,  1.3317e+00,  1.3460e+00,  1.2858e+00,
          1.3475e+00,  1.3436e+00,  1.2843e+00,  1.2971e+00,  1.2751e+00,
          1.2984e+00,  1.2982e+00,  1.2946e+00,  1.2941e+00,  1.2922e+00,
          1.2933e+00,  1.2933e+00,  2.8588e+00,  2.7867e+00,  2.6017e+00,
          2.6334e+00,  2.8576e+00,  2.6103e+00,  2.7670e+00,  2.6591e+00,
          2.6035e+00,  1.7424e+00,  1.7541e+00,  1.7202e+00,  1.7375e+00,
          1.7521e+00,  1.7479e+00,  1.7169e+00,  1.7229e+00,  1.7372e+00,
          1.6056e+00,  1.5879e+00,  1.5263e+00,  1.5238e+00,  1.6019e+00,
          1.5827e+00,  1.6173e+00,  1.5156e+00,  1.5756e+00],
        [ 1.8992e+00,  1.5028e+00,  6.5549e-01,  9.7491e-01,  1.3978e+00,
          1.8302e+00,  1.7038e+00,  1.9349e+00,  1.9349e+00,  1.7379e+00,
          1.3729e+00,  1.5837e+00,  9.8870e-01,  1.7892e+00,  1.7735e-01,
          1.6762e+00,  1.9595e+00,  8.9602e-01,  1.4043e+00,  1.0683e+00,
          8.1793e-01,  1.2136e+00,  1.7717e+00,  1.8375e+00,  1.6078e+00,
          1.9428e+00,  1.9428e+00,  9.1254e-01,  9.0508e-01,  1.9176e+00,
          1.7065e+00,  9.1734e-01,  1.8587e+00,  1.3148e+00,  1.9661e+00,
          1.8822e+00, -1.4870e-01, -3.9040e-01, -4.3386e-01, -1.9700e-01,
          5.6043e-02,  1.4338e-01, -2.7411e-01,  1.8075e+01,  3.1012e+00,
          2.7587e-01,  6.3834e-01,  6.6122e-01,  7.7394e-01,  4.2791e-01,
          7.7495e-01, -1.2458e-02,  8.0931e-01,  8.7063e-01],
        [ 1.3341e+00,  1.3708e+00,  1.4057e+00,  1.4028e+00,  1.3776e+00,
          1.3411e+00,  1.3113e+00,  1.3304e+00,  1.3304e+00,  1.3070e+00,
          1.4264e+00,  1.3232e+00,  1.4535e+00,  1.3827e+00,  1.4796e+00,
          1.3135e+00,  1.3581e+00,  1.3689e+00,  1.3913e+00,  1.3614e+00,
          1.4237e+00,  1.4049e+00,  1.3586e+00,  1.3518e+00,  1.2446e+00,
          1.3405e+00,  1.3405e+00,  1.3840e+00,  1.4371e+00,  1.3554e+00,
          1.1464e+00,  1.3415e+00,  1.2443e+00,  1.4116e+00,  1.2333e+00,
          1.3595e+00,  3.4353e-01,  2.6655e-01,  3.8057e-01,  3.4942e-01,
          1.4191e-01,  9.3605e-02,  3.6701e-01,  1.3949e-01, -6.7187e-02,
          3.5158e+00,  2.3088e+00,  3.4763e+00,  2.6543e+00,  1.8446e+00,
          1.4392e+00,  2.8811e+00,  3.3432e+00,  1.4037e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 330 : 174.4793331910472
Test loss for epoch 330 : 174.760303835389
Test Precision for epoch 330 : 0.26153846153846155
Test Recall for epoch 330 : 0.26153846153846155
Test F1 for epoch 330 : 0.26153846153846155


theta for epoch 331 : tensor([[ 2.6448,  2.6637,  2.7010,  2.8168,  2.7976,  2.6480,  2.7847,  2.6431,
          2.6431,  1.3332,  1.3353,  1.3343,  1.3373,  1.3322,  1.3394,  1.3336,
          1.3305,  1.2926,  1.2878,  1.2454,  1.2461,  1.2888,  1.2854,  1.2849,
          1.2870,  1.2841,  1.2841,  1.2679,  1.3125,  1.3063,  1.3094,  1.3125,
          1.3077,  1.3106,  1.2624,  1.3066,  1.7370,  1.7482,  1.7416,  1.7378,
          1.7463,  1.6858,  1.7385,  1.7235,  1.7375,  1.5926,  1.5757,  1.5722,
          1.5658,  1.5891,  1.5708,  1.6037,  1.5620,  1.5640],
        [ 1.2879,  1.2908,  1.2862,  1.2855,  1.2914,  1.2885,  1.2895,  1.2876,
          1.2876,  2.5941,  2.6084,  2.5769,  2.8012,  2.5636,  2.9663,  2.5964,
          2.7653,  2.9392,  1.2795,  1.2844,  1.2376,  1.2802,  1.3069,  1.3064,
          1.3077,  1.3055,  1.3055,  1.3069,  1.2589,  1.3275,  1.3309,  1.2991,
          1.3290,  1.3321,  1.3015,  1.3278,  1.7486,  1.7608,  1.7166,  1.7485,
          1.7588,  1.7603,  1.7131,  1.7211,  1.7483,  1.5527,  1.5898,  1.5860,
          1.5790,  1.5129,  1.5844,  1.5288,  1.5749,  1.5771],
        [ 1.2713,  1.2741,  1.2738,  1.2758,  1.2739,  1.2719,  1.2722,  1.2711,
          1.2711,  1.3376,  1.3398,  1.3388,  1.3418,  1.3366,  1.2839,  1.3381,
          1.2748,  1.3258,  2.6977,  2.8090,  2.8568,  2.7067,  2.6371,  2.6339,
          2.7849,  2.6288,  2.6288,  1.2693,  1.3019,  1.3112,  1.3144,  1.2700,
          1.3126,  1.3155,  1.3112,  1.3115,  1.7400,  1.7513,  1.7447,  1.6752,
          1.7494,  1.7451,  1.7415,  1.7261,  1.6749,  1.5966,  1.5795,  1.5760,
          1.5695,  1.5740,  1.5745,  1.5889,  1.5612,  1.5677],
        [ 1.2787,  1.2816,  1.2814,  1.2835,  1.2815,  1.2793,  1.2798,  1.2785,
          1.2785,  1.3452,  1.3475,  1.3464,  1.3299,  1.3442,  1.2841,  1.3457,
          1.3418,  1.2826,  1.3003,  1.2782,  1.3016,  1.3014,  1.2979,  1.2973,
          1.2953,  1.2965,  1.2965,  2.8602,  2.7879,  2.6032,  2.6345,  2.8591,
          2.6118,  2.7682,  2.6606,  2.6049,  1.7440,  1.7557,  1.7219,  1.7391,
          1.7537,  1.7495,  1.7186,  1.7247,  1.7388,  1.6019,  1.5842,  1.5228,
          1.5202,  1.5982,  1.5790,  1.6136,  1.5119,  1.5720],
        [ 1.8941,  1.4965,  0.6484,  0.9681,  1.3914,  1.8250,  1.6982,  1.9300,
          1.9300,  1.7307,  1.3651,  1.5767,  0.9810,  1.7823,  0.1693,  1.6690,
          1.9533,  0.8875,  1.3984,  1.0622,  0.8111,  1.2072,  1.7668,  1.8328,
          1.6029,  1.9385,  1.9385,  0.9052,  0.8973,  1.9114,  1.6997,  0.9096,
          1.8522,  1.3075,  1.9599,  1.8759, -0.1427, -0.3844, -0.4279, -0.1911,
          0.0621,  0.1493, -0.2681, 18.1208,  3.0858,  0.2674,  0.6297,  0.6524,
          0.7650,  0.4194,  0.7661, -0.0207,  0.8005,  0.8617],
        [ 1.3414,  1.3781,  1.4127,  1.4100,  1.3848,  1.3484,  1.3187,  1.3378,
          1.3378,  1.3146,  1.4339,  1.3308,  1.4610,  1.3902,  1.4871,  1.3211,
          1.3657,  1.3765,  1.4003,  1.3703,  1.4327,  1.4138,  1.3676,  1.3608,
          1.2535,  1.3495,  1.3495,  1.3912,  1.4442,  1.3627,  1.1540,  1.3486,
          1.2517,  1.4188,  1.2407,  1.3668,  0.3514,  0.2746,  0.3885,  0.3573,
          0.1500,  0.1017,  0.3749,  0.1474, -0.0589,  3.5095,  2.3003,  3.4698,
          2.6462,  1.8360,  1.4305,  2.8730,  3.3374,  1.3951]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 331 : 174.45814194033548
Test loss for epoch 331 : 174.75605569485057
Test Precision for epoch 331 : 0.26153846153846155
Test Recall for epoch 331 : 0.26153846153846155
Test F1 for epoch 331 : 0.26153846153846155


theta for epoch 332 : tensor([[ 2.6456e+00,  2.6645e+00,  2.7018e+00,  2.8178e+00,  2.7986e+00,
          2.6488e+00,  2.7857e+00,  2.6439e+00,  2.6439e+00,  1.3343e+00,
          1.3365e+00,  1.3355e+00,  1.3385e+00,  1.3333e+00,  1.3405e+00,
          1.3348e+00,  1.3316e+00,  1.2937e+00,  1.2849e+00,  1.2425e+00,
          1.2433e+00,  1.2859e+00,  1.2825e+00,  1.2820e+00,  1.2841e+00,
          1.2812e+00,  1.2812e+00,  1.2676e+00,  1.3122e+00,  1.3061e+00,
          1.3092e+00,  1.3122e+00,  1.3075e+00,  1.3103e+00,  1.2621e+00,
          1.3063e+00,  1.7366e+00,  1.7478e+00,  1.7412e+00,  1.7374e+00,
          1.7459e+00,  1.6855e+00,  1.7381e+00,  1.7231e+00,  1.7371e+00,
          1.5953e+00,  1.5785e+00,  1.5750e+00,  1.5686e+00,  1.5918e+00,
          1.5736e+00,  1.6064e+00,  1.5648e+00,  1.5669e+00],
        [ 1.2872e+00,  1.2901e+00,  1.2857e+00,  1.2851e+00,  1.2907e+00,
          1.2878e+00,  1.2888e+00,  1.2870e+00,  1.2870e+00,  2.5956e+00,
          2.6099e+00,  2.5791e+00,  2.8037e+00,  2.5658e+00,  2.9677e+00,
          2.5979e+00,  2.7679e+00,  2.9407e+00,  1.2764e+00,  1.2813e+00,
          1.2346e+00,  1.2772e+00,  1.3039e+00,  1.3034e+00,  1.3047e+00,
          1.3025e+00,  1.3025e+00,  1.3066e+00,  1.2586e+00,  1.3272e+00,
          1.3306e+00,  1.2990e+00,  1.3287e+00,  1.3318e+00,  1.3012e+00,
          1.3275e+00,  1.7483e+00,  1.7604e+00,  1.7162e+00,  1.7482e+00,
          1.7584e+00,  1.7599e+00,  1.7128e+00,  1.7211e+00,  1.7479e+00,
          1.5557e+00,  1.5929e+00,  1.5891e+00,  1.5820e+00,  1.5159e+00,
          1.5875e+00,  1.5317e+00,  1.5780e+00,  1.5801e+00],
        [ 1.2718e+00,  1.2745e+00,  1.2742e+00,  1.2762e+00,  1.2743e+00,
          1.2723e+00,  1.2726e+00,  1.2715e+00,  1.2715e+00,  1.3407e+00,
          1.3429e+00,  1.3418e+00,  1.3449e+00,  1.3397e+00,  1.2869e+00,
          1.3411e+00,  1.2780e+00,  1.3290e+00,  2.6936e+00,  2.8053e+00,
          2.8530e+00,  2.7027e+00,  2.6329e+00,  2.6298e+00,  2.7812e+00,
          2.6247e+00,  2.6247e+00,  1.2701e+00,  1.3028e+00,  1.3121e+00,
          1.3152e+00,  1.2708e+00,  1.3135e+00,  1.3164e+00,  1.3120e+00,
          1.3124e+00,  1.7402e+00,  1.7515e+00,  1.7448e+00,  1.6753e+00,
          1.7496e+00,  1.7452e+00,  1.7416e+00,  1.7263e+00,  1.6750e+00,
          1.6004e+00,  1.5833e+00,  1.5798e+00,  1.5733e+00,  1.5778e+00,
          1.5784e+00,  1.5926e+00,  1.5650e+00,  1.5715e+00],
        [ 1.2780e+00,  1.2808e+00,  1.2806e+00,  1.2827e+00,  1.2808e+00,
          1.2785e+00,  1.2790e+00,  1.2777e+00,  1.2777e+00,  1.3464e+00,
          1.3486e+00,  1.3476e+00,  1.3310e+00,  1.3453e+00,  1.2853e+00,
          1.3469e+00,  1.3429e+00,  1.2838e+00,  1.2974e+00,  1.2752e+00,
          1.2987e+00,  1.2984e+00,  1.2949e+00,  1.2944e+00,  1.2923e+00,
          1.2936e+00,  1.2936e+00,  2.8617e+00,  2.7891e+00,  2.6047e+00,
          2.6356e+00,  2.8606e+00,  2.6132e+00,  2.7694e+00,  2.6622e+00,
          2.6064e+00,  1.7436e+00,  1.7553e+00,  1.7215e+00,  1.7386e+00,
          1.7533e+00,  1.7489e+00,  1.7182e+00,  1.7244e+00,  1.7382e+00,
          1.6044e+00,  1.5868e+00,  1.5255e+00,  1.5228e+00,  1.6008e+00,
          1.5816e+00,  1.6160e+00,  1.5144e+00,  1.5746e+00],
        [ 1.8975e+00,  1.5005e+00,  6.5305e-01,  9.7230e-01,  1.3955e+00,
          1.8285e+00,  1.7019e+00,  1.9334e+00,  1.9334e+00,  1.7355e+00,
          1.3701e+00,  1.5815e+00,  9.8609e-01,  1.7872e+00,  1.7462e-01,
          1.6737e+00,  1.9579e+00,  8.9276e-01,  1.4022e+00,  1.0664e+00,
          8.1547e-01,  1.2112e+00,  1.7700e+00,  1.8360e+00,  1.6065e+00,
          1.9415e+00,  1.9415e+00,  9.1005e-01,  9.0213e-01,  1.9156e+00,
          1.7040e+00,  9.1448e-01,  1.8565e+00,  1.3120e+00,  1.9641e+00,
          1.8801e+00, -1.4749e-01, -3.8903e-01, -4.3254e-01, -1.9606e-01,
          5.7185e-02,  1.4416e-01, -2.7286e-01,  1.8155e+01,  3.0583e+00,
          2.7240e-01,  6.3437e-01,  6.5702e-01,  7.6963e-01,  4.2429e-01,
          7.7080e-01, -1.5449e-02,  8.0512e-01,  8.6629e-01],
        [ 1.3359e+00,  1.3725e+00,  1.4070e+00,  1.4045e+00,  1.3793e+00,
          1.3429e+00,  1.3131e+00,  1.3322e+00,  1.3322e+00,  1.3091e+00,
          1.4285e+00,  1.3253e+00,  1.4556e+00,  1.3847e+00,  1.4816e+00,
          1.3156e+00,  1.3601e+00,  1.3710e+00,  1.3936e+00,  1.3632e+00,
          1.4259e+00,  1.4071e+00,  1.3608e+00,  1.3540e+00,  1.2464e+00,
          1.3427e+00,  1.3427e+00,  1.3854e+00,  1.4388e+00,  1.3572e+00,
          1.1482e+00,  1.3429e+00,  1.2461e+00,  1.4134e+00,  1.2351e+00,
          1.3613e+00,  3.4522e-01,  2.6848e-01,  3.8234e-01,  3.5102e-01,
          1.4382e-01,  9.5449e-02,  3.6871e-01,  1.4093e-01, -6.5166e-02,
          3.5183e+00,  2.3069e+00,  3.4783e+00,  2.6532e+00,  1.8423e+00,
          1.4368e+00,  2.8799e+00,  3.3468e+00,  1.4013e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 332 : 174.42310180185817
Test loss for epoch 332 : 174.7149103011074
Test Precision for epoch 332 : 0.26153846153846155
Test Recall for epoch 332 : 0.26153846153846155
Test F1 for epoch 332 : 0.26153846153846155


theta for epoch 333 : tensor([[ 2.6470e+00,  2.6659e+00,  2.7032e+00,  2.8193e+00,  2.8001e+00,
          2.6502e+00,  2.7872e+00,  2.6453e+00,  2.6453e+00,  1.3337e+00,
          1.3358e+00,  1.3348e+00,  1.3378e+00,  1.3327e+00,  1.3398e+00,
          1.3341e+00,  1.3310e+00,  1.2930e+00,  1.2875e+00,  1.2452e+00,
          1.2459e+00,  1.2885e+00,  1.2852e+00,  1.2847e+00,  1.2868e+00,
          1.2839e+00,  1.2839e+00,  1.2672e+00,  1.3118e+00,  1.3056e+00,
          1.3087e+00,  1.3118e+00,  1.3070e+00,  1.3098e+00,  1.2617e+00,
          1.3059e+00,  1.7370e+00,  1.7481e+00,  1.7416e+00,  1.7378e+00,
          1.7462e+00,  1.6858e+00,  1.7384e+00,  1.7234e+00,  1.7375e+00,
          1.5934e+00,  1.5766e+00,  1.5732e+00,  1.5668e+00,  1.5899e+00,
          1.5718e+00,  1.6045e+00,  1.5630e+00,  1.5651e+00],
        [ 1.2872e+00,  1.2901e+00,  1.2859e+00,  1.2853e+00,  1.2907e+00,
          1.2878e+00,  1.2888e+00,  1.2870e+00,  1.2870e+00,  2.5945e+00,
          2.6089e+00,  2.5788e+00,  2.8037e+00,  2.5654e+00,  2.9670e+00,
          2.5968e+00,  2.7679e+00,  2.9399e+00,  1.2804e+00,  1.2854e+00,
          1.2386e+00,  1.2812e+00,  1.3078e+00,  1.3073e+00,  1.3087e+00,
          1.3064e+00,  1.3064e+00,  1.3069e+00,  1.2589e+00,  1.3275e+00,
          1.3309e+00,  1.2995e+00,  1.3290e+00,  1.3321e+00,  1.3016e+00,
          1.3278e+00,  1.7489e+00,  1.7611e+00,  1.7169e+00,  1.7489e+00,
          1.7590e+00,  1.7606e+00,  1.7135e+00,  1.7221e+00,  1.7486e+00,
          1.5544e+00,  1.5916e+00,  1.5879e+00,  1.5809e+00,  1.5147e+00,
          1.5863e+00,  1.5304e+00,  1.5768e+00,  1.5790e+00],
        [ 1.2716e+00,  1.2743e+00,  1.2739e+00,  1.2760e+00,  1.2741e+00,
          1.2721e+00,  1.2724e+00,  1.2713e+00,  1.2713e+00,  1.3407e+00,
          1.3429e+00,  1.3418e+00,  1.3449e+00,  1.3397e+00,  1.2869e+00,
          1.3411e+00,  1.2780e+00,  1.3290e+00,  2.6953e+00,  2.8073e+00,
          2.8548e+00,  2.7043e+00,  2.6346e+00,  2.6314e+00,  2.7832e+00,
          2.6263e+00,  2.6263e+00,  1.2701e+00,  1.3029e+00,  1.3122e+00,
          1.3153e+00,  1.2708e+00,  1.3136e+00,  1.3164e+00,  1.3121e+00,
          1.3125e+00,  1.7408e+00,  1.7521e+00,  1.7455e+00,  1.6758e+00,
          1.7502e+00,  1.7457e+00,  1.7423e+00,  1.7269e+00,  1.6755e+00,
          1.5989e+00,  1.5820e+00,  1.5784e+00,  1.5720e+00,  1.5764e+00,
          1.5770e+00,  1.5912e+00,  1.5635e+00,  1.5702e+00],
        [ 1.2776e+00,  1.2804e+00,  1.2801e+00,  1.2823e+00,  1.2803e+00,
          1.2781e+00,  1.2786e+00,  1.2773e+00,  1.2773e+00,  1.3460e+00,
          1.3482e+00,  1.3472e+00,  1.3307e+00,  1.3449e+00,  1.2850e+00,
          1.3465e+00,  1.3425e+00,  1.2835e+00,  1.3002e+00,  1.2779e+00,
          1.3015e+00,  1.3012e+00,  1.2977e+00,  1.2972e+00,  1.2950e+00,
          1.2964e+00,  1.2964e+00,  2.8629e+00,  2.7900e+00,  2.6058e+00,
          2.6365e+00,  2.8617e+00,  2.6144e+00,  2.7703e+00,  2.6634e+00,
          2.6075e+00,  1.7441e+00,  1.7558e+00,  1.7220e+00,  1.7390e+00,
          1.7538e+00,  1.7493e+00,  1.7186e+00,  1.7250e+00,  1.7386e+00,
          1.6028e+00,  1.5852e+00,  1.5241e+00,  1.5213e+00,  1.5992e+00,
          1.5801e+00,  1.6144e+00,  1.5129e+00,  1.5731e+00],
        [ 1.8969e+00,  1.4997e+00,  6.5218e-01,  9.7131e-01,  1.3946e+00,
          1.8279e+00,  1.7011e+00,  1.9328e+00,  1.9328e+00,  1.7344e+00,
          1.3689e+00,  1.5806e+00,  9.8507e-01,  1.7863e+00,  1.7361e-01,
          1.6727e+00,  1.9572e+00,  8.9147e-01,  1.4022e+00,  1.0663e+00,
          8.1515e-01,  1.2110e+00,  1.7705e+00,  1.8365e+00,  1.6070e+00,
          1.9422e+00,  1.9422e+00,  9.0925e-01,  9.0112e-01,  1.9149e+00,
          1.7032e+00,  9.1352e-01,  1.8558e+00,  1.3111e+00,  1.9635e+00,
          1.8794e+00, -1.4727e-01, -3.8872e-01, -4.3225e-01, -1.9598e-01,
          5.7361e-02,  1.4415e-01, -2.7261e-01,  1.8194e+01,  3.0366e+00,
          2.7090e-01,  6.3261e-01,  6.5515e-01,  7.6770e-01,  4.2271e-01,
          7.6894e-01, -1.6711e-02,  8.0325e-01,  8.6435e-01],
        [ 1.3360e+00,  1.3727e+00,  1.4069e+00,  1.4046e+00,  1.3794e+00,
          1.3430e+00,  1.3132e+00,  1.3323e+00,  1.3323e+00,  1.3092e+00,
          1.4287e+00,  1.3254e+00,  1.4557e+00,  1.3848e+00,  1.4817e+00,
          1.3157e+00,  1.3602e+00,  1.3712e+00,  1.3947e+00,  1.3642e+00,
          1.4271e+00,  1.4083e+00,  1.3619e+00,  1.3551e+00,  1.2473e+00,
          1.3438e+00,  1.3438e+00,  1.3855e+00,  1.4390e+00,  1.3574e+00,
          1.1485e+00,  1.3429e+00,  1.2463e+00,  1.4136e+00,  1.2353e+00,
          1.3615e+00,  3.4527e-01,  2.6865e-01,  3.8242e-01,  3.5103e-01,
          1.4397e-01,  9.5557e-02,  3.6877e-01,  1.4084e-01, -6.4981e-02,
          3.5202e+00,  2.3066e+00,  3.4800e+00,  2.6532e+00,  1.8418e+00,
          1.4362e+00,  2.8799e+00,  3.3493e+00,  1.4007e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 333 : 174.40942243236935
Test loss for epoch 333 : 174.70591053756624
Test Precision for epoch 333 : 0.26153846153846155
Test Recall for epoch 333 : 0.26153846153846155
Test F1 for epoch 333 : 0.26153846153846155


theta for epoch 334 : tensor([[ 2.6494,  2.6683,  2.7056,  2.8218,  2.8027,  2.6526,  2.7897,  2.6477,
          2.6477,  1.3335,  1.3357,  1.3347,  1.3377,  1.3326,  1.3397,  1.3340,
          1.3309,  1.2929,  1.2870,  1.2446,  1.2454,  1.2880,  1.2847,  1.2842,
          1.2863,  1.2834,  1.2834,  1.2669,  1.3115,  1.3054,  1.3085,  1.3115,
          1.3068,  1.3096,  1.2614,  1.3057,  1.7373,  1.7484,  1.7419,  1.7381,
          1.7465,  1.6860,  1.7387,  1.7237,  1.7377,  1.5911,  1.5744,  1.5710,
          1.5646,  1.5877,  1.5696,  1.6021,  1.5608,  1.5629],
        [ 1.2873,  1.2902,  1.2862,  1.2855,  1.2907,  1.2879,  1.2889,  1.2870,
          1.2870,  2.5960,  2.6105,  2.5810,  2.8062,  2.5676,  2.9685,  2.5984,
          2.7704,  2.9414,  1.2805,  1.2854,  1.2386,  1.2813,  1.3079,  1.3073,
          1.3087,  1.3065,  1.3065,  1.3070,  1.2590,  1.3276,  1.3309,  1.2998,
          1.3291,  1.3321,  1.3017,  1.3279,  1.7494,  1.7615,  1.7174,  1.7493,
          1.7594,  1.7610,  1.7139,  1.7228,  1.7490,  1.5523,  1.5896,  1.5858,
          1.5789,  1.5126,  1.5843,  1.5283,  1.5748,  1.5771],
        [ 1.2714,  1.2741,  1.2737,  1.2759,  1.2740,  1.2719,  1.2723,  1.2712,
          1.2712,  1.3407,  1.3429,  1.3419,  1.3449,  1.3397,  1.2869,  1.3412,
          1.2780,  1.3290,  2.6978,  2.8102,  2.8575,  2.7069,  2.6371,  2.6339,
          2.7862,  2.6289,  2.6289,  1.2699,  1.3027,  1.3120,  1.3151,  1.2706,
          1.3134,  1.3163,  1.3120,  1.3123,  1.7412,  1.7525,  1.7458,  1.6761,
          1.7506,  1.7460,  1.7427,  1.7272,  1.6757,  1.5967,  1.5798,  1.5763,
          1.5699,  1.5742,  1.5749,  1.5890,  1.5614,  1.5681],
        [ 1.2776,  1.2804,  1.2800,  1.2823,  1.2803,  1.2781,  1.2786,  1.2773,
          1.2773,  1.3463,  1.3486,  1.3475,  1.3310,  1.3453,  1.2855,  1.3468,
          1.3429,  1.2839,  1.3001,  1.2778,  1.3014,  1.3012,  1.2977,  1.2972,
          1.2949,  1.2963,  1.2963,  2.8649,  2.7918,  2.6078,  2.6382,  2.8638,
          2.6164,  2.7720,  2.6655,  2.6095,  1.7445,  1.7562,  1.7224,  1.7393,
          1.7542,  1.7496,  1.7191,  1.7256,  1.7389,  1.6009,  1.5834,  1.5224,
          1.5195,  1.5973,  1.5783,  1.6125,  1.5110,  1.5713],
        [ 1.8953,  1.4974,  0.6495,  0.9687,  1.3923,  1.8261,  1.6992,  1.9312,
          1.9312,  1.7320,  1.3662,  1.5783,  0.9823,  1.7841,  0.1706,  1.6702,
          1.9554,  0.8883,  1.3995,  1.0638,  0.8122,  1.2082,  1.7682,  1.8343,
          1.6049,  1.9402,  1.9402,  0.9066,  0.8982,  1.9129,  1.7008,  0.9106,
          1.8537,  1.3083,  1.9615,  1.8773, -0.1452, -0.3866, -0.4302, -0.1941,
          0.0594,  0.1460, -0.2706, 18.2354,  3.0169,  0.2672,  0.6288,  0.6512,
          0.7637,  0.4190,  0.7650, -0.0201,  0.7993,  0.8603],
        [ 1.3392,  1.3759,  1.4099,  1.4078,  1.3826,  1.3462,  1.3165,  1.3355,
          1.3355,  1.3128,  1.4323,  1.3290,  1.4593,  1.3884,  1.4852,  1.3193,
          1.3638,  1.3747,  1.3980,  1.3673,  1.4304,  1.4116,  1.3652,  1.3584,
          1.2505,  1.3471,  1.3471,  1.3885,  1.4423,  1.3607,  1.1518,  1.3460,
          1.2496,  1.4169,  1.2386,  1.3648,  0.3482,  0.2717,  0.3854,  0.3539,
          0.1471,  0.0986,  0.3717,  0.1437, -0.0618,  3.5189,  2.3031,  3.4785,
          2.6501,  1.8381,  1.4325,  2.8768,  3.3485,  1.3970]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 334 : 174.41644427476552
Test loss for epoch 334 : 174.7216238935663
Test Precision for epoch 334 : 0.26153846153846155
Test Recall for epoch 334 : 0.26153846153846155
Test F1 for epoch 334 : 0.26153846153846155


theta for epoch 335 : tensor([[ 2.6512e+00,  2.6702e+00,  2.7074e+00,  2.8238e+00,  2.8047e+00,
          2.6545e+00,  2.7917e+00,  2.6496e+00,  2.6496e+00,  1.3334e+00,
          1.3356e+00,  1.3346e+00,  1.3376e+00,  1.3324e+00,  1.3396e+00,
          1.3339e+00,  1.3308e+00,  1.2928e+00,  1.2832e+00,  1.2408e+00,
          1.2416e+00,  1.2842e+00,  1.2808e+00,  1.2803e+00,  1.2824e+00,
          1.2795e+00,  1.2795e+00,  1.2667e+00,  1.3113e+00,  1.3053e+00,
          1.3083e+00,  1.3114e+00,  1.3066e+00,  1.3094e+00,  1.2612e+00,
          1.3055e+00,  1.7359e+00,  1.7470e+00,  1.7405e+00,  1.7367e+00,
          1.7451e+00,  1.6846e+00,  1.7374e+00,  1.7223e+00,  1.7363e+00,
          1.5955e+00,  1.5789e+00,  1.5754e+00,  1.5691e+00,  1.5920e+00,
          1.5741e+00,  1.6064e+00,  1.5653e+00,  1.5674e+00],
        [ 1.2865e+00,  1.2894e+00,  1.2855e+00,  1.2849e+00,  1.2899e+00,
          1.2871e+00,  1.2881e+00,  1.2862e+00,  1.2862e+00,  2.5995e+00,
          2.6139e+00,  2.5851e+00,  2.8105e+00,  2.5716e+00,  2.9716e+00,
          2.6018e+00,  2.7749e+00,  2.9447e+00,  1.2755e+00,  1.2805e+00,
          1.2337e+00,  1.2763e+00,  1.3030e+00,  1.3025e+00,  1.3038e+00,
          1.3016e+00,  1.3016e+00,  1.3063e+00,  1.2584e+00,  1.3270e+00,
          1.3303e+00,  1.2994e+00,  1.3285e+00,  1.3315e+00,  1.3010e+00,
          1.3273e+00,  1.7478e+00,  1.7600e+00,  1.7158e+00,  1.7478e+00,
          1.7579e+00,  1.7594e+00,  1.7124e+00,  1.7217e+00,  1.7474e+00,
          1.5565e+00,  1.5940e+00,  1.5902e+00,  1.5833e+00,  1.5168e+00,
          1.5887e+00,  1.5325e+00,  1.5792e+00,  1.5814e+00],
        [ 1.2708e+00,  1.2735e+00,  1.2730e+00,  1.2752e+00,  1.2734e+00,
          1.2713e+00,  1.2717e+00,  1.2705e+00,  1.2705e+00,  1.3401e+00,
          1.3423e+00,  1.3413e+00,  1.3443e+00,  1.3391e+00,  1.2863e+00,
          1.3406e+00,  1.2774e+00,  1.3284e+00,  2.6993e+00,  2.8120e+00,
          2.8591e+00,  2.7083e+00,  2.6385e+00,  2.6353e+00,  2.7880e+00,
          2.6303e+00,  2.6303e+00,  1.2694e+00,  1.3023e+00,  1.3116e+00,
          1.3148e+00,  1.2701e+00,  1.3131e+00,  1.3159e+00,  1.3116e+00,
          1.3119e+00,  1.7397e+00,  1.7510e+00,  1.7444e+00,  1.6745e+00,
          1.7491e+00,  1.7444e+00,  1.7412e+00,  1.7258e+00,  1.6742e+00,
          1.6008e+00,  1.5840e+00,  1.5805e+00,  1.5741e+00,  1.5783e+00,
          1.5791e+00,  1.5930e+00,  1.5655e+00,  1.5724e+00],
        [ 1.2773e+00,  1.2801e+00,  1.2796e+00,  1.2820e+00,  1.2800e+00,
          1.2778e+00,  1.2783e+00,  1.2770e+00,  1.2770e+00,  1.3463e+00,
          1.3485e+00,  1.3475e+00,  1.3310e+00,  1.3453e+00,  1.2855e+00,
          1.3468e+00,  1.3428e+00,  1.2840e+00,  1.2966e+00,  1.2741e+00,
          1.2978e+00,  1.2976e+00,  1.2941e+00,  1.2936e+00,  1.2913e+00,
          1.2927e+00,  1.2927e+00,  2.8671e+00,  2.7937e+00,  2.6099e+00,
          2.6400e+00,  2.8659e+00,  2.6185e+00,  2.7739e+00,  2.6677e+00,
          2.6117e+00,  1.7432e+00,  1.7548e+00,  1.7210e+00,  1.7379e+00,
          1.7528e+00,  1.7481e+00,  1.7177e+00,  1.7243e+00,  1.7374e+00,
          1.6051e+00,  1.5877e+00,  1.5268e+00,  1.5239e+00,  1.6016e+00,
          1.5827e+00,  1.6167e+00,  1.5153e+00,  1.5757e+00],
        [ 1.9000e+00,  1.5027e+00,  6.5553e-01,  9.7423e-01,  1.3977e+00,
          1.8309e+00,  1.7042e+00,  1.9358e+00,  1.9358e+00,  1.7376e+00,
          1.3722e+00,  1.5839e+00,  9.8843e-01,  1.7897e+00,  1.7704e-01,
          1.6758e+00,  1.9607e+00,  8.9472e-01,  1.4045e+00,  1.0692e+00,
          8.1784e-01,  1.2135e+00,  1.7727e+00,  1.8386e+00,  1.6096e+00,
          1.9443e+00,  1.9443e+00,  9.1279e-01,  9.0439e-01,  1.9184e+00,
          1.7064e+00,  9.1694e-01,  1.8593e+00,  1.3143e+00,  1.9670e+00,
          1.8829e+00, -1.5125e-01, -3.9239e-01, -4.3593e-01, -2.0021e-01,
          5.3227e-02,  1.3963e-01, -2.7646e-01,  1.8268e+01,  2.9883e+00,
          2.7372e-01,  6.3502e-01,  6.5743e-01,  7.6993e-01,  4.2545e-01,
          7.7128e-01, -1.3489e-02,  8.0557e-01,  8.6655e-01],
        [ 1.3339e+00,  1.3706e+00,  1.4043e+00,  1.4025e+00,  1.3774e+00,
          1.3409e+00,  1.3111e+00,  1.3302e+00,  1.3302e+00,  1.3070e+00,
          1.4265e+00,  1.3231e+00,  1.4535e+00,  1.3826e+00,  1.4793e+00,
          1.3135e+00,  1.3579e+00,  1.3689e+00,  1.3912e+00,  1.3601e+00,
          1.4235e+00,  1.4047e+00,  1.3584e+00,  1.3516e+00,  1.2433e+00,
          1.3403e+00,  1.3403e+00,  1.3829e+00,  1.4370e+00,  1.3553e+00,
          1.1462e+00,  1.3404e+00,  1.2441e+00,  1.4116e+00,  1.2331e+00,
          1.3594e+00,  3.4158e-01,  2.6520e-01,  3.7881e-01,  3.4725e-01,
          1.4047e-01,  9.1986e-02,  3.6510e-01,  1.3684e-01, -6.8395e-02,
          3.5279e+00,  2.3098e+00,  3.4873e+00,  2.6572e+00,  1.8446e+00,
          1.4390e+00,  2.8838e+00,  3.3580e+00,  1.4035e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 335 : 174.41995108021547
Test loss for epoch 335 : 174.71759826119438
Test Precision for epoch 335 : 0.26153846153846155
Test Recall for epoch 335 : 0.26153846153846155
Test F1 for epoch 335 : 0.26153846153846155


theta for epoch 336 : tensor([[ 2.6522,  2.6711,  2.7084,  2.8249,  2.8057,  2.6554,  2.7928,  2.6505,
          2.6505,  1.3323,  1.3344,  1.3334,  1.3364,  1.3313,  1.3384,  1.3327,
          1.3296,  1.2916,  1.2867,  1.2443,  1.2451,  1.2877,  1.2843,  1.2838,
          1.2859,  1.2830,  1.2830,  1.2667,  1.3113,  1.3053,  1.3083,  1.3114,
          1.3067,  1.3095,  1.2613,  1.3056,  1.7372,  1.7483,  1.7419,  1.7381,
          1.7464,  1.6860,  1.7387,  1.7236,  1.7376,  1.5929,  1.5763,  1.5729,
          1.5666,  1.5895,  1.5715,  1.6038,  1.5628,  1.5649],
        [ 1.2865,  1.2894,  1.2857,  1.2851,  1.2899,  1.2871,  1.2881,  1.2862,
          1.2862,  2.5994,  2.6139,  2.5857,  2.8114,  2.5722,  2.9718,  2.6018,
          2.7759,  2.9449,  1.2790,  1.2839,  1.2371,  1.2798,  1.3064,  1.3058,
          1.3073,  1.3050,  1.3050,  1.3063,  1.2583,  1.3269,  1.3303,  1.2995,
          1.3285,  1.3315,  1.3010,  1.3273,  1.7491,  1.7612,  1.7171,  1.7491,
          1.7591,  1.7607,  1.7137,  1.7231,  1.7487,  1.5536,  1.5911,  1.5874,
          1.5805,  1.5139,  1.5859,  1.5295,  1.5764,  1.5787],
        [ 1.2701,  1.2728,  1.2722,  1.2745,  1.2726,  1.2706,  1.2710,  1.2698,
          1.2698,  1.3374,  1.3396,  1.3386,  1.3416,  1.3364,  1.2836,  1.3379,
          1.2746,  1.3257,  2.7045,  2.8175,  2.8644,  2.7134,  2.6438,  2.6406,
          2.7935,  2.6355,  2.6355,  1.2684,  1.3015,  1.3108,  1.3139,  1.2691,
          1.3122,  1.3151,  1.3108,  1.3111,  1.7407,  1.7520,  1.7454,  1.6754,
          1.7500,  1.7452,  1.7422,  1.7268,  1.6750,  1.5974,  1.5806,  1.5772,
          1.5708,  1.5749,  1.5758,  1.5896,  1.5621,  1.5691],
        [ 1.2773,  1.2801,  1.2796,  1.2819,  1.2800,  1.2778,  1.2783,  1.2770,
          1.2770,  1.3449,  1.3471,  1.3461,  1.3296,  1.3439,  1.2842,  1.3454,
          1.3415,  1.2827,  1.2996,  1.2771,  1.3009,  1.3007,  1.2972,  1.2967,
          1.2943,  1.2958,  1.2958,  2.8683,  2.7946,  2.6111,  2.6408,  2.8671,
          2.6196,  2.7748,  2.6689,  2.6128,  1.7446,  1.7562,  1.7224,  1.7392,
          1.7542,  1.7494,  1.7191,  1.7259,  1.7387,  1.6026,  1.5852,  1.5245,
          1.5214,  1.5990,  1.5802,  1.6141,  1.5128,  1.5733],
        [ 1.8958,  1.4977,  0.6498,  0.9687,  1.3925,  1.8266,  1.6996,  1.9318,
          1.9318,  1.7317,  1.3658,  1.5782,  0.9821,  1.7840,  0.1705,  1.6699,
          1.9556,  0.8878,  1.3998,  1.0644,  0.8124,  1.2084,  1.7688,  1.8350,
          1.6058,  1.9409,  1.9409,  0.9070,  0.8982,  1.9135,  1.7011,  0.9108,
          1.8542,  1.3085,  1.9622,  1.8779, -0.1464, -0.3875, -0.4311, -0.1955,
          0.0581,  0.1443, -0.2716, 18.3120,  2.9720,  0.2669,  0.6282,  0.6505,
          0.7630,  0.4186,  0.7644, -0.0201,  0.7988,  0.8596],
        [ 1.3396,  1.3763,  1.4098,  1.4082,  1.3830,  1.3466,  1.3168,  1.3359,
          1.3359,  1.3130,  1.4324,  1.3290,  1.4593,  1.3885,  1.4851,  1.3195,
          1.3638,  1.3748,  1.3983,  1.3671,  1.4306,  1.4118,  1.3655,  1.3587,
          1.2503,  1.3474,  1.3474,  1.3886,  1.4428,  1.3612,  1.1523,  1.3461,
          1.2500,  1.4174,  1.2390,  1.3653,  0.3477,  0.2715,  0.3850,  0.3533,
          0.1468,  0.0983,  0.3712,  0.1429, -0.0620,  3.5234,  2.3032,  3.4826,
          2.6509,  1.8378,  1.4321,  2.8775,  3.3541,  1.3967]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 336 : 174.40542069316643
Test loss for epoch 336 : 174.71725302275456
Test Precision for epoch 336 : 0.26153846153846155
Test Recall for epoch 336 : 0.26153846153846155
Test F1 for epoch 336 : 0.26153846153846155


theta for epoch 337 : tensor([[ 2.6532e+00,  2.6721e+00,  2.7094e+00,  2.8260e+00,  2.8069e+00,
          2.6564e+00,  2.7939e+00,  2.6515e+00,  2.6515e+00,  1.3336e+00,
          1.3358e+00,  1.3348e+00,  1.3377e+00,  1.3326e+00,  1.3397e+00,
          1.3341e+00,  1.3309e+00,  1.2930e+00,  1.2841e+00,  1.2418e+00,
          1.2425e+00,  1.2851e+00,  1.2817e+00,  1.2812e+00,  1.2833e+00,
          1.2804e+00,  1.2804e+00,  1.2669e+00,  1.3115e+00,  1.3055e+00,
          1.3085e+00,  1.3116e+00,  1.3069e+00,  1.3096e+00,  1.2615e+00,
          1.3058e+00,  1.7370e+00,  1.7481e+00,  1.7416e+00,  1.7378e+00,
          1.7461e+00,  1.6857e+00,  1.7384e+00,  1.7233e+00,  1.7374e+00,
          1.5950e+00,  1.5785e+00,  1.5751e+00,  1.5689e+00,  1.5917e+00,
          1.5738e+00,  1.6060e+00,  1.5651e+00,  1.5672e+00],
        [ 1.2864e+00,  1.2893e+00,  1.2859e+00,  1.2852e+00,  1.2899e+00,
          1.2870e+00,  1.2881e+00,  1.2862e+00,  1.2862e+00,  2.6014e+00,
          2.6159e+00,  2.5883e+00,  2.8143e+00,  2.5749e+00,  2.9737e+00,
          2.6038e+00,  2.7788e+00,  2.9469e+00,  1.2756e+00,  1.2805e+00,
          1.2338e+00,  1.2764e+00,  1.3030e+00,  1.3025e+00,  1.3039e+00,
          1.3016e+00,  1.3016e+00,  1.3062e+00,  1.2582e+00,  1.3268e+00,
          1.3301e+00,  1.2995e+00,  1.3283e+00,  1.3313e+00,  1.3009e+00,
          1.3271e+00,  1.7487e+00,  1.7608e+00,  1.7167e+00,  1.7487e+00,
          1.7587e+00,  1.7602e+00,  1.7133e+00,  1.7230e+00,  1.7482e+00,
          1.5556e+00,  1.5932e+00,  1.5895e+00,  1.5826e+00,  1.5159e+00,
          1.5880e+00,  1.5315e+00,  1.5786e+00,  1.5808e+00],
        [ 1.2711e+00,  1.2738e+00,  1.2731e+00,  1.2755e+00,  1.2736e+00,
          1.2716e+00,  1.2720e+00,  1.2708e+00,  1.2708e+00,  1.3399e+00,
          1.3421e+00,  1.3411e+00,  1.3441e+00,  1.3389e+00,  1.2861e+00,
          1.3404e+00,  1.2772e+00,  1.3283e+00,  2.7013e+00,  2.8148e+00,
          2.8615e+00,  2.7103e+00,  2.6405e+00,  2.6373e+00,  2.7907e+00,
          2.6323e+00,  2.6323e+00,  1.2693e+00,  1.3024e+00,  1.3117e+00,
          1.3148e+00,  1.2700e+00,  1.3131e+00,  1.3160e+00,  1.3117e+00,
          1.3120e+00,  1.7408e+00,  1.7521e+00,  1.7455e+00,  1.6754e+00,
          1.7501e+00,  1.7452e+00,  1.7423e+00,  1.7268e+00,  1.6750e+00,
          1.6002e+00,  1.5835e+00,  1.5800e+00,  1.5737e+00,  1.5777e+00,
          1.5786e+00,  1.5923e+00,  1.5649e+00,  1.5720e+00],
        [ 1.2774e+00,  1.2802e+00,  1.2796e+00,  1.2821e+00,  1.2801e+00,
          1.2780e+00,  1.2784e+00,  1.2772e+00,  1.2772e+00,  1.3461e+00,
          1.3484e+00,  1.3473e+00,  1.3308e+00,  1.3451e+00,  1.2856e+00,
          1.3466e+00,  1.3427e+00,  1.2840e+00,  1.2969e+00,  1.2743e+00,
          1.2982e+00,  1.2979e+00,  1.2944e+00,  1.2939e+00,  1.2915e+00,
          1.2930e+00,  1.2930e+00,  2.8697e+00,  2.7958e+00,  2.6124e+00,
          2.6419e+00,  2.8686e+00,  2.6210e+00,  2.7760e+00,  2.6703e+00,
          2.6141e+00,  1.7442e+00,  1.7558e+00,  1.7221e+00,  1.7387e+00,
          1.7538e+00,  1.7489e+00,  1.7188e+00,  1.7256e+00,  1.7382e+00,
          1.6045e+00,  1.5872e+00,  1.5266e+00,  1.5235e+00,  1.6010e+00,
          1.5822e+00,  1.6160e+00,  1.5148e+00,  1.5753e+00],
        [ 1.8991e+00,  1.5013e+00,  6.5392e-01,  9.7245e-01,  1.3962e+00,
          1.8299e+00,  1.7030e+00,  1.9350e+00,  1.9350e+00,  1.7357e+00,
          1.3701e+00,  1.5823e+00,  9.8649e-01,  1.7882e+00,  1.7494e-01,
          1.6740e+00,  1.9595e+00,  8.9231e-01,  1.4029e+00,  1.0678e+00,
          8.1597e-01,  1.2117e+00,  1.7713e+00,  1.8374e+00,  1.6087e+00,
          1.9432e+00,  1.9432e+00,  9.1119e-01,  9.0237e-01,  1.9171e+00,
          1.7049e+00,  9.1506e-01,  1.8579e+00,  1.3124e+00,  1.9658e+00,
          1.8816e+00, -1.5050e-01, -3.9143e-01, -4.3500e-01, -1.9972e-01,
          5.3859e-02,  1.3988e-01, -2.7563e-01,  1.8347e+01,  2.9457e+00,
          2.7118e-01,  6.3231e-01,  6.5460e-01,  7.6713e-01,  4.2286e-01,
          7.6854e-01, -1.5770e-02,  8.0293e-01,  8.6376e-01],
        [ 1.3351e+00,  1.3718e+00,  1.4051e+00,  1.4038e+00,  1.3786e+00,
          1.3421e+00,  1.3123e+00,  1.3314e+00,  1.3314e+00,  1.3082e+00,
          1.4278e+00,  1.3243e+00,  1.4547e+00,  1.3838e+00,  1.4803e+00,
          1.3147e+00,  1.3590e+00,  1.3701e+00,  1.3923e+00,  1.3608e+00,
          1.4246e+00,  1.4059e+00,  1.3595e+00,  1.3527e+00,  1.2440e+00,
          1.3413e+00,  1.3413e+00,  1.3837e+00,  1.4382e+00,  1.3565e+00,
          1.1473e+00,  1.3412e+00,  1.2453e+00,  1.4128e+00,  1.2342e+00,
          1.3606e+00,  3.4235e-01,  2.6616e-01,  3.7965e-01,  3.4792e-01,
          1.4139e-01,  9.2811e-02,  3.6589e-01,  1.3732e-01, -6.7402e-02,
          3.5312e+00,  2.3088e+00,  3.4901e+00,  2.6568e+00,  1.8432e+00,
          1.4375e+00,  2.8834e+00,  3.3625e+00,  1.4020e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 337 : 174.3807928633168
Test loss for epoch 337 : 174.68787989324946
Test Precision for epoch 337 : 0.26153846153846155
Test Recall for epoch 337 : 0.26153846153846155
Test F1 for epoch 337 : 0.26153846153846155


theta for epoch 338 : tensor([[ 2.6545e+00,  2.6734e+00,  2.7107e+00,  2.8275e+00,  2.8084e+00,
          2.6578e+00,  2.7954e+00,  2.6528e+00,  2.6528e+00,  1.3331e+00,
          1.3353e+00,  1.3343e+00,  1.3373e+00,  1.3321e+00,  1.3393e+00,
          1.3336e+00,  1.3304e+00,  1.2925e+00,  1.2871e+00,  1.2448e+00,
          1.2456e+00,  1.2881e+00,  1.2847e+00,  1.2843e+00,  1.2864e+00,
          1.2834e+00,  1.2834e+00,  1.2667e+00,  1.3114e+00,  1.3053e+00,
          1.3084e+00,  1.3114e+00,  1.3067e+00,  1.3095e+00,  1.2613e+00,
          1.3056e+00,  1.7375e+00,  1.7485e+00,  1.7421e+00,  1.7383e+00,
          1.7466e+00,  1.6861e+00,  1.7389e+00,  1.7238e+00,  1.7378e+00,
          1.5930e+00,  1.5766e+00,  1.5732e+00,  1.5670e+00,  1.5897e+00,
          1.5719e+00,  1.6040e+00,  1.5632e+00,  1.5653e+00],
        [ 1.2868e+00,  1.2896e+00,  1.2864e+00,  1.2857e+00,  1.2902e+00,
          1.2874e+00,  1.2884e+00,  1.2865e+00,  1.2865e+00,  2.6010e+00,
          2.6156e+00,  2.5885e+00,  2.8148e+00,  2.5750e+00,  2.9737e+00,
          2.6034e+00,  2.7794e+00,  2.9468e+00,  1.2793e+00,  1.2843e+00,
          1.2374e+00,  1.2801e+00,  1.3066e+00,  1.3061e+00,  1.3075e+00,
          1.3052e+00,  1.3052e+00,  1.3063e+00,  1.2583e+00,  1.3269e+00,
          1.3303e+00,  1.2999e+00,  1.3284e+00,  1.3315e+00,  1.3010e+00,
          1.3272e+00,  1.7493e+00,  1.7614e+00,  1.7174e+00,  1.7493e+00,
          1.7593e+00,  1.7609e+00,  1.7139e+00,  1.7239e+00,  1.7488e+00,
          1.5538e+00,  1.5914e+00,  1.5877e+00,  1.5809e+00,  1.5141e+00,
          1.5863e+00,  1.5296e+00,  1.5768e+00,  1.5791e+00],
        [ 1.2713e+00,  1.2740e+00,  1.2733e+00,  1.2757e+00,  1.2738e+00,
          1.2718e+00,  1.2722e+00,  1.2710e+00,  1.2710e+00,  1.3396e+00,
          1.3418e+00,  1.3407e+00,  1.3437e+00,  1.3386e+00,  1.2858e+00,
          1.3400e+00,  1.2768e+00,  1.3279e+00,  2.7034e+00,  2.8172e+00,
          2.8638e+00,  2.7124e+00,  2.6426e+00,  2.6394e+00,  2.7932e+00,
          2.6344e+00,  2.6344e+00,  1.2692e+00,  1.3024e+00,  1.3117e+00,
          1.3148e+00,  1.2699e+00,  1.3131e+00,  1.3159e+00,  1.3116e+00,
          1.3120e+00,  1.7414e+00,  1.7527e+00,  1.7461e+00,  1.6760e+00,
          1.7507e+00,  1.7457e+00,  1.7429e+00,  1.7274e+00,  1.6755e+00,
          1.5983e+00,  1.5817e+00,  1.5782e+00,  1.5719e+00,  1.5759e+00,
          1.5769e+00,  1.5904e+00,  1.5630e+00,  1.5702e+00],
        [ 1.2774e+00,  1.2802e+00,  1.2795e+00,  1.2821e+00,  1.2801e+00,
          1.2780e+00,  1.2784e+00,  1.2772e+00,  1.2772e+00,  1.3455e+00,
          1.3477e+00,  1.3467e+00,  1.3301e+00,  1.3444e+00,  1.2850e+00,
          1.3460e+00,  1.3420e+00,  1.2835e+00,  1.2995e+00,  1.2769e+00,
          1.3008e+00,  1.3006e+00,  1.2971e+00,  1.2966e+00,  1.2941e+00,
          1.2957e+00,  1.2957e+00,  2.8712e+00,  2.7971e+00,  2.6138e+00,
          2.6431e+00,  2.8701e+00,  2.6224e+00,  2.7773e+00,  2.6718e+00,
          2.6156e+00,  1.7447e+00,  1.7563e+00,  1.7226e+00,  1.7392e+00,
          1.7543e+00,  1.7493e+00,  1.7193e+00,  1.7262e+00,  1.7386e+00,
          1.6026e+00,  1.5853e+00,  1.5248e+00,  1.5216e+00,  1.5990e+00,
          1.5804e+00,  1.6140e+00,  1.5128e+00,  1.5735e+00],
        [ 1.8985e+00,  1.5005e+00,  6.5299e-01,  9.7145e-01,  1.3954e+00,
          1.8293e+00,  1.7024e+00,  1.9345e+00,  1.9345e+00,  1.7345e+00,
          1.3687e+00,  1.5811e+00,  9.8526e-01,  1.7870e+00,  1.7367e-01,
          1.6727e+00,  1.9586e+00,  8.9085e-01,  1.4027e+00,  1.0676e+00,
          8.1544e-01,  1.2114e+00,  1.7716e+00,  1.8377e+00,  1.6090e+00,
          1.9437e+00,  1.9437e+00,  9.1022e-01,  9.0120e-01,  1.9163e+00,
          1.7039e+00,  9.1396e-01,  1.8570e+00,  1.3113e+00,  1.9650e+00,
          1.8807e+00, -1.4995e-01, -3.9078e-01, -4.3436e-01, -1.9930e-01,
          5.4338e-02,  1.4016e-01, -2.7504e-01,  1.8386e+01,  2.9247e+00,
          2.6956e-01,  6.3063e-01,  6.5287e-01,  7.6540e-01,  4.2123e-01,
          7.6685e-01, -1.7265e-02,  8.0129e-01,  8.6205e-01],
        [ 1.3358e+00,  1.3725e+00,  1.4056e+00,  1.4044e+00,  1.3793e+00,
          1.3428e+00,  1.3130e+00,  1.3321e+00,  1.3321e+00,  1.3087e+00,
          1.4283e+00,  1.3247e+00,  1.4551e+00,  1.3842e+00,  1.4807e+00,
          1.3152e+00,  1.3595e+00,  1.3706e+00,  1.3938e+00,  1.3621e+00,
          1.4261e+00,  1.4074e+00,  1.3610e+00,  1.3541e+00,  1.2452e+00,
          1.3428e+00,  1.3428e+00,  1.3841e+00,  1.4388e+00,  1.3571e+00,
          1.1479e+00,  1.3416e+00,  1.2459e+00,  1.4135e+00,  1.2348e+00,
          1.3612e+00,  3.4286e-01,  2.6674e-01,  3.8019e-01,  3.4838e-01,
          1.4195e-01,  9.3322e-02,  3.6641e-01,  1.3769e-01, -6.6803e-02,
          3.5326e+00,  2.3081e+00,  3.4914e+00,  2.6565e+00,  1.8422e+00,
          1.4365e+00,  2.8830e+00,  3.3645e+00,  1.4010e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 338 : 174.36707962752493
Test loss for epoch 338 : 174.67924792051127
Test Precision for epoch 338 : 0.26153846153846155
Test Recall for epoch 338 : 0.26153846153846155
Test F1 for epoch 338 : 0.26153846153846155


theta for epoch 339 : tensor([[ 2.6566,  2.6755,  2.7128,  2.8297,  2.8106,  2.6598,  2.7976,  2.6549,
          2.6549,  1.3332,  1.3354,  1.3344,  1.3373,  1.3322,  1.3394,  1.3337,
          1.3305,  1.2926,  1.2869,  1.2445,  1.2453,  1.2879,  1.2845,  1.2840,
          1.2861,  1.2832,  1.2832,  1.2664,  1.3111,  1.3050,  1.3081,  1.3111,
          1.3064,  1.3092,  1.2610,  1.3053,  1.7378,  1.7488,  1.7424,  1.7386,
          1.7469,  1.6864,  1.7393,  1.7241,  1.7381,  1.5920,  1.5756,  1.5722,
          1.5660,  1.5886,  1.5709,  1.6029,  1.5622,  1.5644],
        [ 1.2866,  1.2895,  1.2864,  1.2857,  1.2901,  1.2872,  1.2882,  1.2864,
          1.2864,  2.6026,  2.6171,  2.5907,  2.8172,  2.5771,  2.9752,  2.6050,
          2.7819,  2.9484,  1.2793,  1.2843,  1.2374,  1.2801,  1.3066,  1.3061,
          1.3076,  1.3052,  1.3052,  1.3062,  1.2582,  1.3268,  1.3302,  1.2999,
          1.3283,  1.3314,  1.3009,  1.3272,  1.7498,  1.7618,  1.7178,  1.7498,
          1.7597,  1.7613,  1.7144,  1.7246,  1.7492,  1.5528,  1.5905,  1.5868,
          1.5800,  1.5131,  1.5854,  1.5286,  1.5760,  1.5782],
        [ 1.2711,  1.2738,  1.2730,  1.2755,  1.2736,  1.2716,  1.2720,  1.2708,
          1.2708,  1.3398,  1.3420,  1.3410,  1.3440,  1.3388,  1.2860,  1.3403,
          1.2771,  1.3282,  2.7053,  2.8195,  2.8658,  2.7143,  2.6445,  2.6413,
          2.7955,  2.6363,  2.6363,  1.2689,  1.3022,  1.3115,  1.3146,  1.2696,
          1.3129,  1.3158,  1.3115,  1.3118,  1.7419,  1.7531,  1.7466,  1.6763,
          1.7511,  1.7460,  1.7434,  1.7278,  1.6758,  1.5974,  1.5808,  1.5773,
          1.5710,  1.5750,  1.5760,  1.5894,  1.5621,  1.5693],
        [ 1.2771,  1.2799,  1.2791,  1.2817,  1.2798,  1.2776,  1.2781,  1.2768,
          1.2768,  1.3456,  1.3479,  1.3468,  1.3303,  1.3446,  1.2852,  1.3461,
          1.3421,  1.2837,  1.2993,  1.2766,  1.3006,  1.3003,  1.2968,  1.2963,
          1.2937,  1.2954,  1.2954,  2.8736,  2.7991,  2.6161,  2.6451,  2.8725,
          2.6247,  2.7793,  2.6741,  2.6178,  1.7451,  1.7567,  1.7230,  1.7395,
          1.7546,  1.7496,  1.7197,  1.7267,  1.7389,  1.6016,  1.5844,  1.5240,
          1.5207,  1.5980,  1.5795,  1.6130,  1.5118,  1.5726],
        [ 1.8975,  1.4991,  0.6514,  0.9698,  1.3940,  1.8282,  1.7011,  1.9335,
          1.9335,  1.7330,  1.3671,  1.5798,  0.9836,  1.7858,  0.1718,  1.6712,
          1.9576,  0.8890,  1.4011,  1.0662,  0.8137,  1.2097,  1.7702,  1.8364,
          1.6079,  1.9425,  1.9425,  0.9087,  0.8994,  1.9150,  1.7024,  0.9122,
          1.8557,  1.3097,  1.9637,  1.8794, -0.1488, -0.3895, -0.4331, -0.1983,
          0.0555,  0.1411, -0.2738, 18.4258,  2.9045,  0.2674,  0.6285,  0.6507,
          0.7633,  0.4191,  0.7647, -0.0193,  0.7993,  0.8599],
        [ 1.3377,  1.3744,  1.4072,  1.4063,  1.3812,  1.3447,  1.3149,  1.3340,
          1.3340,  1.3110,  1.4306,  1.3270,  1.4574,  1.3865,  1.4830,  1.3175,
          1.3618,  1.3729,  1.3958,  1.3639,  1.4281,  1.4094,  1.3630,  1.3562,
          1.2470,  1.3448,  1.3448,  1.3859,  1.4408,  1.3591,  1.1500,  1.3434,
          1.2479,  1.4155,  1.2369,  1.3632,  0.3447,  0.2687,  0.3821,  0.3502,
          0.1439,  0.0952,  0.3683,  0.1394, -0.0648,  3.5328,  2.3060,  3.4913,
          2.6548,  1.8400,  1.4342,  2.8813,  3.3652,  1.3988]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 339 : 174.3667074567161
Test loss for epoch 339 : 174.68536306991817
Test Precision for epoch 339 : 0.26153846153846155
Test Recall for epoch 339 : 0.26153846153846155
Test F1 for epoch 339 : 0.26153846153846155


theta for epoch 340 : tensor([[ 2.6586e+00,  2.6775e+00,  2.7148e+00,  2.8319e+00,  2.8127e+00,
          2.6618e+00,  2.7998e+00,  2.6569e+00,  2.6569e+00,  1.3332e+00,
          1.3353e+00,  1.3343e+00,  1.3373e+00,  1.3322e+00,  1.3393e+00,
          1.3337e+00,  1.3305e+00,  1.2926e+00,  1.2837e+00,  1.2413e+00,
          1.2421e+00,  1.2847e+00,  1.2813e+00,  1.2808e+00,  1.2829e+00,
          1.2800e+00,  1.2800e+00,  1.2660e+00,  1.3106e+00,  1.3046e+00,
          1.3077e+00,  1.3107e+00,  1.3060e+00,  1.3088e+00,  1.2606e+00,
          1.3049e+00,  1.7369e+00,  1.7479e+00,  1.7415e+00,  1.7377e+00,
          1.7459e+00,  1.6855e+00,  1.7383e+00,  1.7232e+00,  1.7372e+00,
          1.5956e+00,  1.5793e+00,  1.5759e+00,  1.5697e+00,  1.5922e+00,
          1.5746e+00,  1.6064e+00,  1.5659e+00,  1.5681e+00],
        [ 1.2859e+00,  1.2887e+00,  1.2858e+00,  1.2851e+00,  1.2893e+00,
          1.2864e+00,  1.2875e+00,  1.2856e+00,  1.2856e+00,  2.6053e+00,
          2.6198e+00,  2.5939e+00,  2.8207e+00,  2.5804e+00,  2.9778e+00,
          2.6077e+00,  2.7855e+00,  2.9511e+00,  1.2757e+00,  1.2807e+00,
          1.2339e+00,  1.2765e+00,  1.3031e+00,  1.3025e+00,  1.3040e+00,
          1.3017e+00,  1.3017e+00,  1.3057e+00,  1.2577e+00,  1.3263e+00,
          1.3296e+00,  1.2996e+00,  1.3278e+00,  1.3308e+00,  1.3004e+00,
          1.3266e+00,  1.7488e+00,  1.7609e+00,  1.7169e+00,  1.7488e+00,
          1.7587e+00,  1.7603e+00,  1.7134e+00,  1.7239e+00,  1.7483e+00,
          1.5566e+00,  1.5943e+00,  1.5906e+00,  1.5838e+00,  1.5169e+00,
          1.5892e+00,  1.5323e+00,  1.5798e+00,  1.5821e+00],
        [ 1.2704e+00,  1.2731e+00,  1.2723e+00,  1.2748e+00,  1.2730e+00,
          1.2709e+00,  1.2713e+00,  1.2702e+00,  1.2702e+00,  1.3398e+00,
          1.3420e+00,  1.3410e+00,  1.3440e+00,  1.3388e+00,  1.2859e+00,
          1.3403e+00,  1.2770e+00,  1.3282e+00,  2.7064e+00,  2.8209e+00,
          2.8671e+00,  2.7154e+00,  2.6456e+00,  2.6423e+00,  2.7969e+00,
          2.6373e+00,  2.6373e+00,  1.2685e+00,  1.3018e+00,  1.3111e+00,
          1.3142e+00,  1.2691e+00,  1.3125e+00,  1.3154e+00,  1.3111e+00,
          1.3114e+00,  1.7410e+00,  1.7522e+00,  1.7457e+00,  1.6754e+00,
          1.7502e+00,  1.7450e+00,  1.7425e+00,  1.7270e+00,  1.6748e+00,
          1.6010e+00,  1.5844e+00,  1.5810e+00,  1.5747e+00,  1.5786e+00,
          1.5797e+00,  1.5930e+00,  1.5657e+00,  1.5730e+00],
        [ 1.2766e+00,  1.2794e+00,  1.2786e+00,  1.2812e+00,  1.2793e+00,
          1.2771e+00,  1.2776e+00,  1.2763e+00,  1.2763e+00,  1.3458e+00,
          1.3480e+00,  1.3470e+00,  1.3304e+00,  1.3447e+00,  1.2854e+00,
          1.3463e+00,  1.3423e+00,  1.2839e+00,  1.2965e+00,  1.2737e+00,
          1.2978e+00,  1.2975e+00,  1.2940e+00,  1.2935e+00,  1.2909e+00,
          1.2926e+00,  1.2926e+00,  2.8757e+00,  2.8010e+00,  2.6181e+00,
          2.6468e+00,  2.8746e+00,  2.6267e+00,  2.7811e+00,  2.6762e+00,
          2.6198e+00,  1.7442e+00,  1.7557e+00,  1.7221e+00,  1.7385e+00,
          1.7537e+00,  1.7486e+00,  1.7188e+00,  1.7259e+00,  1.7379e+00,
          1.6052e+00,  1.5881e+00,  1.5277e+00,  1.5244e+00,  1.6017e+00,
          1.5831e+00,  1.6165e+00,  1.5155e+00,  1.5763e+00],
        [ 1.9008e+00,  1.5030e+00,  6.5578e-01,  9.7380e-01,  1.3978e+00,
          1.8316e+00,  1.7047e+00,  1.9368e+00,  1.9368e+00,  1.7372e+00,
          1.3716e+00,  1.5841e+00,  9.8825e-01,  1.7900e+00,  1.7660e-01,
          1.6754e+00,  1.9615e+00,  8.9381e-01,  1.4048e+00,  1.0701e+00,
          8.1783e-01,  1.2136e+00,  1.7734e+00,  1.8395e+00,  1.6114e+00,
          1.9454e+00,  1.9454e+00,  9.1325e-01,  9.0397e-01,  1.9189e+00,
          1.7065e+00,  9.1692e-01,  1.8597e+00,  1.3140e+00,  1.9676e+00,
          1.8834e+00, -1.5316e-01, -3.9368e-01, -4.3724e-01, -2.0275e-01,
          5.0931e-02,  1.3635e-01, -2.7810e-01,  1.8460e+01,  2.8782e+00,
          2.7242e-01,  6.3351e-01,  6.5572e-01,  7.6835e-01,  4.2414e-01,
          7.6981e-01, -1.4300e-02,  8.0439e-01,  8.6502e-01],
        [ 1.3337e+00,  1.3704e+00,  1.4030e+00,  1.4023e+00,  1.3772e+00,
          1.3407e+00,  1.3109e+00,  1.3300e+00,  1.3300e+00,  1.3069e+00,
          1.4265e+00,  1.3229e+00,  1.4533e+00,  1.3824e+00,  1.4787e+00,
          1.3134e+00,  1.3576e+00,  1.3687e+00,  1.3908e+00,  1.3585e+00,
          1.4230e+00,  1.4043e+00,  1.3579e+00,  1.3511e+00,  1.2417e+00,
          1.3397e+00,  1.3397e+00,  1.3816e+00,  1.4368e+00,  1.3551e+00,
          1.1458e+00,  1.3391e+00,  1.2438e+00,  1.4115e+00,  1.2327e+00,
          1.3592e+00,  3.3994e-01,  2.6393e-01,  3.7731e-01,  3.4535e-01,
          1.3909e-01,  9.0351e-02,  3.6350e-01,  1.3445e-01, -6.9597e-02,
          3.5399e+00,  2.3111e+00,  3.4983e+00,  2.6601e+00,  1.8448e+00,
          1.4390e+00,  2.8866e+00,  3.3730e+00,  1.4036e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 340 : 174.36727214884735
Test loss for epoch 340 : 174.68123405780455
Test Precision for epoch 340 : 0.26153846153846155
Test Recall for epoch 340 : 0.26153846153846155
Test F1 for epoch 340 : 0.26153846153846155


theta for epoch 341 : tensor([[ 2.6602,  2.6791,  2.7164,  2.8336,  2.8145,  2.6634,  2.8015,  2.6585,
          2.6585,  1.3321,  1.3343,  1.3333,  1.3363,  1.3311,  1.3383,  1.3326,
          1.3294,  1.2915,  1.2866,  1.2442,  1.2450,  1.2875,  1.2842,  1.2837,
          1.2858,  1.2828,  1.2828,  1.2660,  1.3106,  1.3046,  1.3076,  1.3106,
          1.3060,  1.3087,  1.2606,  1.3049,  1.7378,  1.7488,  1.7425,  1.7387,
          1.7468,  1.6864,  1.7393,  1.7241,  1.7381,  1.5929,  1.5766,  1.5733,
          1.5671,  1.5896,  1.5719,  1.6037,  1.5633,  1.5655],
        [ 1.2860,  1.2888,  1.2860,  1.2854,  1.2894,  1.2866,  1.2876,  1.2857,
          1.2857,  2.6053,  2.6199,  2.5944,  2.8216,  2.5809,  2.9781,  2.6077,
          2.7864,  2.9514,  1.2791,  1.2841,  1.2372,  1.2799,  1.3064,  1.3059,
          1.3074,  1.3050,  1.3050,  1.3059,  1.2579,  1.3265,  1.3298,  1.2999,
          1.3280,  1.3310,  1.3006,  1.3268,  1.7499,  1.7619,  1.7180,  1.7499,
          1.7597,  1.7613,  1.7145,  1.7252,  1.7493,  1.5538,  1.5916,  1.5880,
          1.5812,  1.5142,  1.5865,  1.5296,  1.5772,  1.5795],
        [ 1.2698,  1.2725,  1.2716,  1.2742,  1.2724,  1.2703,  1.2707,  1.2696,
          1.2696,  1.3377,  1.3399,  1.3389,  1.3419,  1.3367,  1.2839,  1.3382,
          1.2749,  1.3260,  2.7112,  2.8261,  2.8720,  2.7202,  2.6504,  2.6472,
          2.8021,  2.6422,  2.6422,  1.2678,  1.3012,  1.3106,  1.3136,  1.2685,
          1.3120,  1.3148,  1.3105,  1.3108,  1.7418,  1.7530,  1.7465,  1.6760,
          1.7509,  1.7457,  1.7433,  1.7277,  1.6754,  1.5978,  1.5812,  1.5778,
          1.5716,  1.5754,  1.5765,  1.5898,  1.5625,  1.5699],
        [ 1.2767,  1.2794,  1.2786,  1.2813,  1.2794,  1.2772,  1.2777,  1.2764,
          1.2764,  1.3449,  1.3471,  1.3461,  1.3295,  1.3438,  1.2847,  1.3454,
          1.3414,  1.2831,  1.2994,  1.2766,  1.3007,  1.3005,  1.2969,  1.2964,
          1.2938,  1.2956,  1.2956,  2.8770,  2.8020,  2.6192,  2.6477,  2.8759,
          2.6278,  2.7821,  2.6774,  2.6210,  1.7454,  1.7569,  1.7232,  1.7396,
          1.7548,  1.7496,  1.7199,  1.7272,  1.7389,  1.6028,  1.5857,  1.5255,
          1.5221,  1.5993,  1.5808,  1.6141,  1.5130,  1.5740],
        [ 1.8976,  1.4991,  0.6514,  0.9695,  1.3939,  1.8283,  1.7011,  1.9336,
          1.9336,  1.7326,  1.3667,  1.5796,  0.9835,  1.7856,  0.1715,  1.6709,
          1.9575,  0.8885,  1.4013,  1.0666,  0.8137,  1.2098,  1.7706,  1.8368,
          1.6087,  1.9430,  1.9430,  0.9089,  0.8993,  1.9152,  1.7024,  0.9123,
          1.8558,  1.3096,  1.9639,  1.8796, -0.1494, -0.3899, -0.4335, -0.1991,
          0.0547,  0.1399, -0.2743, 18.5025,  2.8611,  0.2673,  0.6284,  0.6506,
          0.7633,  0.4190,  0.7647, -0.0194,  0.7995,  0.8600],
        [ 1.3382,  1.3749,  1.4073,  1.4068,  1.3817,  1.3452,  1.3155,  1.3345,
          1.3345,  1.3116,  1.4312,  1.3276,  1.4580,  1.3871,  1.4834,  1.3181,
          1.3623,  1.3734,  1.3965,  1.3641,  1.4287,  1.4101,  1.3637,  1.3569,
          1.2473,  1.3455,  1.3455,  1.3861,  1.4415,  1.3598,  1.1507,  1.3436,
          1.2486,  1.4162,  1.2375,  1.3639,  0.3449,  0.2689,  0.3823,  0.3502,
          0.1441,  0.0953,  0.3684,  0.1393, -0.0645,  3.5369,  2.3059,  3.4950,
          2.6553,  1.8395,  1.4337,  2.8817,  3.3705,  1.3982]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 341 : 174.3582186637932
Test loss for epoch 341 : 174.68394456503108
Test Precision for epoch 341 : 0.26153846153846155
Test Recall for epoch 341 : 0.26153846153846155
Test F1 for epoch 341 : 0.26153846153846155


theta for epoch 342 : tensor([[ 2.6614e+00,  2.6803e+00,  2.7176e+00,  2.8350e+00,  2.8158e+00,
          2.6647e+00,  2.8029e+00,  2.6598e+00,  2.6598e+00,  1.3335e+00,
          1.3356e+00,  1.3346e+00,  1.3376e+00,  1.3325e+00,  1.3396e+00,
          1.3340e+00,  1.3308e+00,  1.2929e+00,  1.2839e+00,  1.2416e+00,
          1.2424e+00,  1.2849e+00,  1.2815e+00,  1.2810e+00,  1.2832e+00,
          1.2802e+00,  1.2802e+00,  1.2666e+00,  1.3112e+00,  1.3052e+00,
          1.3082e+00,  1.3112e+00,  1.3065e+00,  1.3093e+00,  1.2612e+00,
          1.3054e+00,  1.7375e+00,  1.7484e+00,  1.7421e+00,  1.7383e+00,
          1.7464e+00,  1.6860e+00,  1.7389e+00,  1.7237e+00,  1.7377e+00,
          1.5945e+00,  1.5783e+00,  1.5749e+00,  1.5688e+00,  1.5912e+00,
          1.5736e+00,  1.6053e+00,  1.5650e+00,  1.5672e+00],
        [ 1.2860e+00,  1.2888e+00,  1.2862e+00,  1.2855e+00,  1.2894e+00,
          1.2866e+00,  1.2876e+00,  1.2857e+00,  1.2857e+00,  2.6074e+00,
          2.6221e+00,  2.5971e+00,  2.8246e+00,  2.5835e+00,  2.9802e+00,
          2.6099e+00,  2.7894e+00,  2.9536e+00,  1.2757e+00,  1.2807e+00,
          1.2339e+00,  1.2766e+00,  1.3031e+00,  1.3025e+00,  1.3040e+00,
          1.3017e+00,  1.3017e+00,  1.3062e+00,  1.2582e+00,  1.3268e+00,
          1.3301e+00,  1.3004e+00,  1.3283e+00,  1.3313e+00,  1.3009e+00,
          1.3271e+00,  1.7494e+00,  1.7614e+00,  1.7174e+00,  1.7494e+00,
          1.7592e+00,  1.7608e+00,  1.7140e+00,  1.7250e+00,  1.7488e+00,
          1.5552e+00,  1.5931e+00,  1.5894e+00,  1.5827e+00,  1.5156e+00,
          1.5880e+00,  1.5310e+00,  1.5786e+00,  1.5809e+00],
        [ 1.2707e+00,  1.2734e+00,  1.2724e+00,  1.2751e+00,  1.2732e+00,
          1.2712e+00,  1.2715e+00,  1.2704e+00,  1.2704e+00,  1.3400e+00,
          1.3422e+00,  1.3412e+00,  1.3442e+00,  1.3390e+00,  1.2861e+00,
          1.3405e+00,  1.2772e+00,  1.3284e+00,  2.7088e+00,  2.8241e+00,
          2.8698e+00,  2.7178e+00,  2.6479e+00,  2.6447e+00,  2.8000e+00,
          2.6397e+00,  2.6397e+00,  1.2689e+00,  1.3023e+00,  1.3117e+00,
          1.3148e+00,  1.2696e+00,  1.3131e+00,  1.3159e+00,  1.3116e+00,
          1.3120e+00,  1.7417e+00,  1.7529e+00,  1.7464e+00,  1.6759e+00,
          1.7508e+00,  1.7455e+00,  1.7432e+00,  1.7277e+00,  1.6752e+00,
          1.5998e+00,  1.5834e+00,  1.5800e+00,  1.5737e+00,  1.5775e+00,
          1.5786e+00,  1.5919e+00,  1.5646e+00,  1.5721e+00],
        [ 1.2770e+00,  1.2797e+00,  1.2788e+00,  1.2816e+00,  1.2797e+00,
          1.2775e+00,  1.2780e+00,  1.2767e+00,  1.2767e+00,  1.3463e+00,
          1.3486e+00,  1.3475e+00,  1.3310e+00,  1.3452e+00,  1.2862e+00,
          1.3468e+00,  1.3428e+00,  1.2846e+00,  1.2969e+00,  1.2741e+00,
          1.2982e+00,  1.2979e+00,  1.2944e+00,  1.2939e+00,  1.2912e+00,
          1.2930e+00,  1.2930e+00,  2.8785e+00,  2.8032e+00,  2.6206e+00,
          2.6489e+00,  2.8774e+00,  2.6292e+00,  2.7834e+00,  2.6788e+00,
          2.6223e+00,  1.7450e+00,  1.7564e+00,  1.7228e+00,  1.7391e+00,
          1.7544e+00,  1.7491e+00,  1.7195e+00,  1.7269e+00,  1.7384e+00,
          1.6043e+00,  1.5873e+00,  1.5271e+00,  1.5237e+00,  1.6008e+00,
          1.5824e+00,  1.6156e+00,  1.5146e+00,  1.5756e+00],
        [ 1.9006e+00,  1.5025e+00,  6.5529e-01,  9.7310e-01,  1.3974e+00,
          1.8314e+00,  1.7044e+00,  1.9366e+00,  1.9366e+00,  1.7365e+00,
          1.3708e+00,  1.5835e+00,  9.8756e-01,  1.7895e+00,  1.7570e-01,
          1.6747e+00,  1.9612e+00,  8.9285e-01,  1.4041e+00,  1.0698e+00,
          8.1709e-01,  1.2129e+00,  1.7729e+00,  1.8390e+00,  1.6113e+00,
          1.9450e+00,  1.9450e+00,  9.1297e-01,  9.0333e-01,  1.9188e+00,
          1.7061e+00,  9.1647e-01,  1.8595e+00,  1.3135e+00,  1.9675e+00,
          1.8832e+00, -1.5307e-01, -3.9337e-01, -4.3692e-01, -2.0291e-01,
          5.0848e-02,  1.3586e-01, -2.7791e-01,  1.8537e+01,  2.8358e+00,
          2.7133e-01,  6.3255e-01,  6.5474e-01,  7.6748e-01,  4.2310e-01,
          7.6892e-01, -1.5367e-02,  8.0371e-01,  8.6419e-01],
        [ 1.3342e+00,  1.3710e+00,  1.4031e+00,  1.4029e+00,  1.3778e+00,
          1.3412e+00,  1.3114e+00,  1.3305e+00,  1.3305e+00,  1.3075e+00,
          1.4271e+00,  1.3234e+00,  1.4539e+00,  1.3830e+00,  1.4792e+00,
          1.3140e+00,  1.3581e+00,  1.3692e+00,  1.3911e+00,  1.3584e+00,
          1.4234e+00,  1.4047e+00,  1.3583e+00,  1.3514e+00,  1.2416e+00,
          1.3401e+00,  1.3401e+00,  1.3819e+00,  1.4375e+00,  1.3558e+00,
          1.1464e+00,  1.3394e+00,  1.2445e+00,  1.4123e+00,  1.2334e+00,
          1.3599e+00,  3.4016e-01,  2.6421e-01,  3.7756e-01,  3.4547e-01,
          1.3933e-01,  9.0471e-02,  3.6373e-01,  1.3442e-01, -6.9269e-02,
          3.5441e+00,  2.3109e+00,  3.5020e+00,  2.6607e+00,  1.8443e+00,
          1.4385e+00,  2.8870e+00,  3.3784e+00,  1.4030e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 342 : 174.3407376119112
Test loss for epoch 342 : 174.66237178277302
Test Precision for epoch 342 : 0.26153846153846155
Test Recall for epoch 342 : 0.26153846153846155
Test F1 for epoch 342 : 0.26153846153846155


theta for epoch 343 : tensor([[ 2.6623e+00,  2.6812e+00,  2.7185e+00,  2.8361e+00,  2.8169e+00,
          2.6656e+00,  2.8040e+00,  2.6607e+00,  2.6607e+00,  1.3330e+00,
          1.3352e+00,  1.3341e+00,  1.3371e+00,  1.3320e+00,  1.3391e+00,
          1.3335e+00,  1.3303e+00,  1.2924e+00,  1.2871e+00,  1.2448e+00,
          1.2455e+00,  1.2881e+00,  1.2847e+00,  1.2842e+00,  1.2863e+00,
          1.2833e+00,  1.2833e+00,  1.2668e+00,  1.3113e+00,  1.3053e+00,
          1.3084e+00,  1.3114e+00,  1.3067e+00,  1.3095e+00,  1.2613e+00,
          1.3056e+00,  1.7381e+00,  1.7490e+00,  1.7427e+00,  1.7389e+00,
          1.7470e+00,  1.6866e+00,  1.7395e+00,  1.7243e+00,  1.7383e+00,
          1.5931e+00,  1.5768e+00,  1.5735e+00,  1.5674e+00,  1.5898e+00,
          1.5722e+00,  1.6039e+00,  1.5636e+00,  1.5657e+00],
        [ 1.2863e+00,  1.2891e+00,  1.2867e+00,  1.2860e+00,  1.2897e+00,
          1.2869e+00,  1.2879e+00,  1.2860e+00,  1.2860e+00,  2.6072e+00,
          2.6218e+00,  2.5973e+00,  2.8251e+00,  2.5837e+00,  2.9803e+00,
          2.6097e+00,  2.7900e+00,  2.9537e+00,  1.2790e+00,  1.2840e+00,
          1.2371e+00,  1.2798e+00,  1.3063e+00,  1.3058e+00,  1.3073e+00,
          1.3049e+00,  1.3049e+00,  1.3064e+00,  1.2584e+00,  1.3269e+00,
          1.3303e+00,  1.3007e+00,  1.3284e+00,  1.3315e+00,  1.3010e+00,
          1.3272e+00,  1.7500e+00,  1.7620e+00,  1.7181e+00,  1.7500e+00,
          1.7598e+00,  1.7614e+00,  1.7146e+00,  1.7258e+00,  1.7494e+00,
          1.5536e+00,  1.5914e+00,  1.5878e+00,  1.5811e+00,  1.5140e+00,
          1.5864e+00,  1.5294e+00,  1.5770e+00,  1.5794e+00],
        [ 1.2708e+00,  1.2735e+00,  1.2724e+00,  1.2752e+00,  1.2733e+00,
          1.2713e+00,  1.2717e+00,  1.2705e+00,  1.2705e+00,  1.3390e+00,
          1.3412e+00,  1.3402e+00,  1.3432e+00,  1.3380e+00,  1.2852e+00,
          1.3395e+00,  1.2762e+00,  1.3274e+00,  2.7112e+00,  2.8269e+00,
          2.8725e+00,  2.7202e+00,  2.6504e+00,  2.6472e+00,  2.8029e+00,
          2.6422e+00,  2.6422e+00,  1.2687e+00,  1.3023e+00,  1.3116e+00,
          1.3147e+00,  1.2694e+00,  1.3130e+00,  1.3158e+00,  1.3115e+00,
          1.3119e+00,  1.7423e+00,  1.7534e+00,  1.7469e+00,  1.6763e+00,
          1.7513e+00,  1.7459e+00,  1.7437e+00,  1.7282e+00,  1.6756e+00,
          1.5982e+00,  1.5817e+00,  1.5783e+00,  1.5720e+00,  1.5758e+00,
          1.5770e+00,  1.5902e+00,  1.5628e+00,  1.5704e+00],
        [ 1.2771e+00,  1.2799e+00,  1.2789e+00,  1.2817e+00,  1.2798e+00,
          1.2777e+00,  1.2781e+00,  1.2769e+00,  1.2769e+00,  1.3455e+00,
          1.3478e+00,  1.3467e+00,  1.3302e+00,  1.3445e+00,  1.2855e+00,
          1.3460e+00,  1.3420e+00,  1.2839e+00,  1.2996e+00,  1.2767e+00,
          1.3009e+00,  1.3006e+00,  1.2971e+00,  1.2966e+00,  1.2938e+00,
          1.2957e+00,  1.2957e+00,  2.8797e+00,  2.8042e+00,  2.6216e+00,
          2.6497e+00,  2.8786e+00,  2.6302e+00,  2.7843e+00,  2.6800e+00,
          2.6234e+00,  1.7456e+00,  1.7570e+00,  1.7234e+00,  1.7396e+00,
          1.7549e+00,  1.7495e+00,  1.7201e+00,  1.7276e+00,  1.7389e+00,
          1.6027e+00,  1.5857e+00,  1.5257e+00,  1.5222e+00,  1.5993e+00,
          1.5809e+00,  1.6141e+00,  1.5130e+00,  1.5741e+00],
        [ 1.8996e+00,  1.5012e+00,  6.5384e-01,  9.7159e-01,  1.3960e+00,
          1.8303e+00,  1.7032e+00,  1.9356e+00,  1.9356e+00,  1.7345e+00,
          1.3689e+00,  1.5817e+00,  9.8575e-01,  1.7877e+00,  1.7380e-01,
          1.6728e+00,  1.9595e+00,  8.9081e-01,  1.4034e+00,  1.0691e+00,
          8.1598e-01,  1.2120e+00,  1.7724e+00,  1.8386e+00,  1.6110e+00,
          1.9447e+00,  1.9447e+00,  9.1151e-01,  9.0165e-01,  1.9174e+00,
          1.7046e+00,  9.1488e-01,  1.8581e+00,  1.3119e+00,  1.9661e+00,
          1.8818e+00, -1.5188e-01, -3.9211e-01, -4.3567e-01, -2.0187e-01,
          5.1953e-02,  1.3676e-01, -2.7670e-01,  1.8577e+01,  2.8160e+00,
          2.6945e-01,  6.3077e-01,  6.5293e-01,  7.6574e-01,  4.2125e-01,
          7.6717e-01, -1.7265e-02,  8.0208e-01,  8.6247e-01],
        [ 1.3355e+00,  1.3723e+00,  1.4041e+00,  1.4041e+00,  1.3791e+00,
          1.3425e+00,  1.3127e+00,  1.3318e+00,  1.3318e+00,  1.3086e+00,
          1.4282e+00,  1.3245e+00,  1.4549e+00,  1.3840e+00,  1.4802e+00,
          1.3151e+00,  1.3591e+00,  1.3703e+00,  1.3933e+00,  1.3603e+00,
          1.4255e+00,  1.4068e+00,  1.3604e+00,  1.3535e+00,  1.2434e+00,
          1.3421e+00,  1.3421e+00,  1.3829e+00,  1.4388e+00,  1.3570e+00,
          1.1477e+00,  1.3404e+00,  1.2458e+00,  1.4135e+00,  1.2346e+00,
          1.3611e+00,  3.4152e-01,  2.6557e-01,  3.7892e-01,  3.4677e-01,
          1.4069e-01,  9.1765e-02,  3.6509e-01,  1.3567e-01, -6.7853e-02,
          3.5449e+00,  2.3096e+00,  3.5026e+00,  2.6597e+00,  1.8428e+00,
          1.4369e+00,  2.8860e+00,  3.3798e+00,  1.4015e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 343 : 174.32686172371655
Test loss for epoch 343 : 174.65454742555363
Test Precision for epoch 343 : 0.26153846153846155
Test Recall for epoch 343 : 0.26153846153846155
Test F1 for epoch 343 : 0.26153846153846155


theta for epoch 344 : tensor([[ 2.6639e+00,  2.6828e+00,  2.7201e+00,  2.8378e+00,  2.8187e+00,
          2.6672e+00,  2.8057e+00,  2.6623e+00,  2.6623e+00,  1.3333e+00,
          1.3355e+00,  1.3344e+00,  1.3374e+00,  1.3323e+00,  1.3394e+00,
          1.3338e+00,  1.3306e+00,  1.2927e+00,  1.2866e+00,  1.2443e+00,
          1.2451e+00,  1.2876e+00,  1.2842e+00,  1.2837e+00,  1.2859e+00,
          1.2829e+00,  1.2829e+00,  1.2666e+00,  1.3112e+00,  1.3051e+00,
          1.3082e+00,  1.3112e+00,  1.3065e+00,  1.3093e+00,  1.2611e+00,
          1.3054e+00,  1.7383e+00,  1.7492e+00,  1.7429e+00,  1.7391e+00,
          1.7472e+00,  1.6867e+00,  1.7397e+00,  1.7245e+00,  1.7385e+00,
          1.5932e+00,  1.5769e+00,  1.5736e+00,  1.5675e+00,  1.5898e+00,
          1.5723e+00,  1.6040e+00,  1.5637e+00,  1.5658e+00],
        [ 1.2862e+00,  1.2891e+00,  1.2868e+00,  1.2861e+00,  1.2897e+00,
          1.2868e+00,  1.2878e+00,  1.2860e+00,  1.2860e+00,  2.6090e+00,
          2.6236e+00,  2.5996e+00,  2.8277e+00,  2.5860e+00,  2.9821e+00,
          2.6115e+00,  2.7926e+00,  2.9556e+00,  1.2782e+00,  1.2832e+00,
          1.2364e+00,  1.2791e+00,  1.3056e+00,  1.3050e+00,  1.3066e+00,
          1.3041e+00,  1.3041e+00,  1.3060e+00,  1.2580e+00,  1.3265e+00,
          1.3299e+00,  1.3005e+00,  1.3280e+00,  1.3311e+00,  1.3007e+00,
          1.3269e+00,  1.7501e+00,  1.7621e+00,  1.7182e+00,  1.7502e+00,
          1.7599e+00,  1.7615e+00,  1.7148e+00,  1.7261e+00,  1.7495e+00,
          1.5535e+00,  1.5913e+00,  1.5877e+00,  1.5810e+00,  1.5138e+00,
          1.5863e+00,  1.5292e+00,  1.5769e+00,  1.5793e+00],
        [ 1.2709e+00,  1.2735e+00,  1.2725e+00,  1.2753e+00,  1.2734e+00,
          1.2714e+00,  1.2717e+00,  1.2706e+00,  1.2706e+00,  1.3393e+00,
          1.3415e+00,  1.3405e+00,  1.3435e+00,  1.3383e+00,  1.2854e+00,
          1.3398e+00,  1.2765e+00,  1.3277e+00,  2.7125e+00,  2.8285e+00,
          2.8739e+00,  2.7215e+00,  2.6516e+00,  2.6484e+00,  2.8045e+00,
          2.6434e+00,  2.6434e+00,  1.2684e+00,  1.3020e+00,  1.3113e+00,
          1.3144e+00,  1.2691e+00,  1.3127e+00,  1.3156e+00,  1.3113e+00,
          1.3116e+00,  1.7425e+00,  1.7536e+00,  1.7471e+00,  1.6764e+00,
          1.7515e+00,  1.7460e+00,  1.7439e+00,  1.7284e+00,  1.6757e+00,
          1.5982e+00,  1.5817e+00,  1.5784e+00,  1.5721e+00,  1.5758e+00,
          1.5770e+00,  1.5902e+00,  1.5628e+00,  1.5705e+00],
        [ 1.2771e+00,  1.2798e+00,  1.2788e+00,  1.2817e+00,  1.2798e+00,
          1.2776e+00,  1.2780e+00,  1.2768e+00,  1.2768e+00,  1.3455e+00,
          1.3478e+00,  1.3467e+00,  1.3302e+00,  1.3445e+00,  1.2855e+00,
          1.3460e+00,  1.3420e+00,  1.2840e+00,  1.2989e+00,  1.2759e+00,
          1.3002e+00,  1.2999e+00,  1.2964e+00,  1.2958e+00,  1.2930e+00,
          1.2950e+00,  1.2950e+00,  2.8818e+00,  2.8060e+00,  2.6235e+00,
          2.6514e+00,  2.8808e+00,  2.6321e+00,  2.7861e+00,  2.6820e+00,
          2.6253e+00,  1.7457e+00,  1.7571e+00,  1.7235e+00,  1.7396e+00,
          1.7550e+00,  1.7495e+00,  1.7202e+00,  1.7278e+00,  1.7389e+00,
          1.6026e+00,  1.5857e+00,  1.5257e+00,  1.5221e+00,  1.5992e+00,
          1.5808e+00,  1.6139e+00,  1.5129e+00,  1.5740e+00],
        [ 1.8994e+00,  1.5009e+00,  6.5350e-01,  9.7115e-01,  1.3957e+00,
          1.8301e+00,  1.7029e+00,  1.9354e+00,  1.9354e+00,  1.7342e+00,
          1.3685e+00,  1.5815e+00,  9.8538e-01,  1.7874e+00,  1.7327e-01,
          1.6724e+00,  1.9593e+00,  8.9031e-01,  1.4028e+00,  1.0687e+00,
          8.1543e-01,  1.2114e+00,  1.7719e+00,  1.8381e+00,  1.6108e+00,
          1.9442e+00,  1.9442e+00,  9.1115e-01,  9.0111e-01,  1.9169e+00,
          1.7041e+00,  9.1444e-01,  1.8576e+00,  1.3114e+00,  1.9657e+00,
          1.8813e+00, -1.5167e-01, -3.9180e-01, -4.3535e-01, -2.0178e-01,
          5.2079e-02,  1.3668e-01, -2.7643e-01,  1.8616e+01,  2.7952e+00,
          2.6897e-01,  6.3041e-01,  6.5256e-01,  7.6544e-01,  4.2082e-01,
          7.6686e-01, -1.7786e-02,  8.0189e-01,  8.6219e-01],
        [ 1.3363e+00,  1.3731e+00,  1.4046e+00,  1.4049e+00,  1.3798e+00,
          1.3433e+00,  1.3135e+00,  1.3325e+00,  1.3325e+00,  1.3095e+00,
          1.4292e+00,  1.3254e+00,  1.4559e+00,  1.3850e+00,  1.4811e+00,
          1.3160e+00,  1.3601e+00,  1.3713e+00,  1.3938e+00,  1.3607e+00,
          1.4260e+00,  1.4074e+00,  1.3610e+00,  1.3541e+00,  1.2438e+00,
          1.3427e+00,  1.3427e+00,  1.3834e+00,  1.4394e+00,  1.3577e+00,
          1.1484e+00,  1.3409e+00,  1.2464e+00,  1.4142e+00,  1.2353e+00,
          1.3618e+00,  3.4218e-01,  2.6623e-01,  3.7958e-01,  3.4738e-01,
          1.4135e-01,  9.2363e-02,  3.6575e-01,  1.3624e-01, -6.7123e-02,
          3.5466e+00,  2.3091e+00,  3.5040e+00,  2.6595e+00,  1.8421e+00,
          1.4362e+00,  2.8858e+00,  3.3820e+00,  1.4008e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 344 : 174.32118804125238
Test loss for epoch 344 : 174.65303547645672
Test Precision for epoch 344 : 0.26153846153846155
Test Recall for epoch 344 : 0.26153846153846155
Test F1 for epoch 344 : 0.26153846153846155


theta for epoch 345 : tensor([[ 2.6659e+00,  2.6848e+00,  2.7220e+00,  2.8399e+00,  2.8207e+00,
          2.6691e+00,  2.8078e+00,  2.6642e+00,  2.6642e+00,  1.3333e+00,
          1.3355e+00,  1.3344e+00,  1.3374e+00,  1.3323e+00,  1.3395e+00,
          1.3338e+00,  1.3306e+00,  1.2927e+00,  1.2846e+00,  1.2423e+00,
          1.2430e+00,  1.2856e+00,  1.2822e+00,  1.2817e+00,  1.2838e+00,
          1.2809e+00,  1.2809e+00,  1.2662e+00,  1.3108e+00,  1.3048e+00,
          1.3078e+00,  1.3108e+00,  1.3061e+00,  1.3089e+00,  1.2608e+00,
          1.3050e+00,  1.7376e+00,  1.7485e+00,  1.7422e+00,  1.7385e+00,
          1.7465e+00,  1.6860e+00,  1.7391e+00,  1.7239e+00,  1.7378e+00,
          1.5954e+00,  1.5792e+00,  1.5759e+00,  1.5697e+00,  1.5921e+00,
          1.5746e+00,  1.6062e+00,  1.5659e+00,  1.5681e+00],
        [ 1.2858e+00,  1.2887e+00,  1.2865e+00,  1.2858e+00,  1.2893e+00,
          1.2864e+00,  1.2874e+00,  1.2856e+00,  1.2856e+00,  2.6112e+00,
          2.6259e+00,  2.6023e+00,  2.8307e+00,  2.5887e+00,  2.9844e+00,
          2.6138e+00,  2.7957e+00,  2.9580e+00,  1.2759e+00,  1.2809e+00,
          1.2341e+00,  1.2767e+00,  1.3033e+00,  1.3027e+00,  1.3042e+00,
          1.3018e+00,  1.3018e+00,  1.3055e+00,  1.2575e+00,  1.3260e+00,
          1.3294e+00,  1.3001e+00,  1.3275e+00,  1.3306e+00,  1.3002e+00,
          1.3264e+00,  1.7495e+00,  1.7614e+00,  1.7175e+00,  1.7495e+00,
          1.7592e+00,  1.7608e+00,  1.7141e+00,  1.7258e+00,  1.7488e+00,
          1.5558e+00,  1.5936e+00,  1.5900e+00,  1.5833e+00,  1.5161e+00,
          1.5886e+00,  1.5315e+00,  1.5792e+00,  1.5815e+00],
        [ 1.2706e+00,  1.2732e+00,  1.2721e+00,  1.2750e+00,  1.2731e+00,
          1.2711e+00,  1.2714e+00,  1.2703e+00,  1.2703e+00,  1.3393e+00,
          1.3415e+00,  1.3405e+00,  1.3435e+00,  1.3383e+00,  1.2854e+00,
          1.3398e+00,  1.2765e+00,  1.3277e+00,  2.7137e+00,  2.8301e+00,
          2.8753e+00,  2.7227e+00,  2.6528e+00,  2.6496e+00,  2.8061e+00,
          2.6446e+00,  2.6446e+00,  1.2679e+00,  1.3016e+00,  1.3110e+00,
          1.3141e+00,  1.2686e+00,  1.3124e+00,  1.3152e+00,  1.3109e+00,
          1.3112e+00,  1.7419e+00,  1.7529e+00,  1.7465e+00,  1.6757e+00,
          1.7509e+00,  1.7453e+00,  1.7433e+00,  1.7278e+00,  1.6750e+00,
          1.6004e+00,  1.5840e+00,  1.5806e+00,  1.5743e+00,  1.5780e+00,
          1.5793e+00,  1.5924e+00,  1.5650e+00,  1.5727e+00],
        [ 1.2767e+00,  1.2795e+00,  1.2784e+00,  1.2813e+00,  1.2794e+00,
          1.2772e+00,  1.2777e+00,  1.2764e+00,  1.2764e+00,  1.3454e+00,
          1.3477e+00,  1.3466e+00,  1.3301e+00,  1.3444e+00,  1.2854e+00,
          1.3459e+00,  1.3419e+00,  1.2839e+00,  1.2968e+00,  1.2738e+00,
          1.2982e+00,  1.2979e+00,  1.2943e+00,  1.2938e+00,  1.2909e+00,
          1.2930e+00,  1.2930e+00,  2.8842e+00,  2.8081e+00,  2.6257e+00,
          2.6534e+00,  2.8831e+00,  2.6343e+00,  2.7882e+00,  2.6842e+00,
          2.6275e+00,  1.7450e+00,  1.7564e+00,  1.7227e+00,  1.7388e+00,
          1.7543e+00,  1.7487e+00,  1.7195e+00,  1.7272e+00,  1.7381e+00,
          1.6047e+00,  1.5878e+00,  1.5279e+00,  1.5242e+00,  1.6013e+00,
          1.5829e+00,  1.6160e+00,  1.5149e+00,  1.5762e+00],
        [ 1.9017e+00,  1.5036e+00,  6.5666e-01,  9.7400e-01,  1.3985e+00,
          1.8325e+00,  1.7055e+00,  1.9377e+00,  1.9377e+00,  1.7371e+00,
          1.3716e+00,  1.5844e+00,  9.8862e-01,  1.7903e+00,  1.7658e-01,
          1.6753e+00,  1.9620e+00,  8.9373e-01,  1.4055e+00,  1.0716e+00,
          8.1837e-01,  1.2142e+00,  1.7742e+00,  1.8403e+00,  1.6133e+00,
          1.9463e+00,  1.9463e+00,  9.1439e-01,  9.0428e-01,  1.9196e+00,
          1.7068e+00,  9.1773e-01,  1.8603e+00,  1.3144e+00,  1.9683e+00,
          1.8840e+00, -1.5468e-01, -3.9464e-01, -4.3815e-01, -2.0490e-01,
          4.8936e-02,  1.3334e-01, -2.7935e-01,  1.8651e+01,  2.7710e+00,
          2.7254e-01,  6.3407e-01,  6.5626e-01,  7.6919e-01,  4.2444e-01,
          7.7059e-01, -1.4271e-02,  8.0572e-01,  8.6596e-01],
        [ 1.3337e+00,  1.3705e+00,  1.4018e+00,  1.4024e+00,  1.3773e+00,
          1.3407e+00,  1.3110e+00,  1.3300e+00,  1.3300e+00,  1.3069e+00,
          1.4266e+00,  1.3228e+00,  1.4532e+00,  1.3823e+00,  1.4784e+00,
          1.3134e+00,  1.3574e+00,  1.3686e+00,  1.3906e+00,  1.3571e+00,
          1.4228e+00,  1.4042e+00,  1.3577e+00,  1.3509e+00,  1.2403e+00,
          1.3395e+00,  1.3395e+00,  1.3805e+00,  1.4368e+00,  1.3551e+00,
          1.1457e+00,  1.3380e+00,  1.2438e+00,  1.4116e+00,  1.2326e+00,
          1.3592e+00,  3.3916e-01,  2.6319e-01,  3.7655e-01,  3.4430e-01,
          1.3829e-01,  8.9227e-02,  3.6273e-01,  1.3308e-01, -7.0145e-02,
          3.5521e+00,  2.3125e+00,  3.5094e+00,  2.6633e+00,  1.8453e+00,
          1.4394e+00,  2.8895e+00,  3.3882e+00,  1.4040e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 345 : 174.3192878287127
Test loss for epoch 345 : 174.64897662296826
Test Precision for epoch 345 : 0.26153846153846155
Test Recall for epoch 345 : 0.26153846153846155
Test F1 for epoch 345 : 0.26153846153846155


theta for epoch 346 : tensor([[ 2.6675e+00,  2.6864e+00,  2.7237e+00,  2.8418e+00,  2.8226e+00,
          2.6708e+00,  2.8096e+00,  2.6659e+00,  2.6659e+00,  1.3325e+00,
          1.3347e+00,  1.3337e+00,  1.3366e+00,  1.3315e+00,  1.3387e+00,
          1.3330e+00,  1.3298e+00,  1.2919e+00,  1.2869e+00,  1.2445e+00,
          1.2453e+00,  1.2879e+00,  1.2845e+00,  1.2840e+00,  1.2861e+00,
          1.2832e+00,  1.2832e+00,  1.2661e+00,  1.3107e+00,  1.3046e+00,
          1.3077e+00,  1.3107e+00,  1.3060e+00,  1.3088e+00,  1.2607e+00,
          1.3049e+00,  1.7383e+00,  1.7492e+00,  1.7429e+00,  1.7392e+00,
          1.7472e+00,  1.6867e+00,  1.7398e+00,  1.7246e+00,  1.7385e+00,
          1.5930e+00,  1.5768e+00,  1.5734e+00,  1.5673e+00,  1.5897e+00,
          1.5721e+00,  1.6038e+00,  1.5635e+00,  1.5657e+00],
        [ 1.2859e+00,  1.2888e+00,  1.2867e+00,  1.2861e+00,  1.2893e+00,
          1.2865e+00,  1.2875e+00,  1.2857e+00,  1.2857e+00,  2.6112e+00,
          2.6259e+00,  2.6028e+00,  2.8315e+00,  2.5891e+00,  2.9848e+00,
          2.6138e+00,  2.7965e+00,  2.9583e+00,  1.2789e+00,  1.2839e+00,
          1.2370e+00,  1.2798e+00,  1.3063e+00,  1.3058e+00,  1.3073e+00,
          1.3049e+00,  1.3049e+00,  1.3057e+00,  1.2577e+00,  1.3263e+00,
          1.3296e+00,  1.3005e+00,  1.3278e+00,  1.3308e+00,  1.3004e+00,
          1.3266e+00,  1.7503e+00,  1.7622e+00,  1.7184e+00,  1.7504e+00,
          1.7600e+00,  1.7616e+00,  1.7150e+00,  1.7268e+00,  1.7497e+00,
          1.5534e+00,  1.5913e+00,  1.5877e+00,  1.5810e+00,  1.5138e+00,
          1.5862e+00,  1.5292e+00,  1.5769e+00,  1.5792e+00],
        [ 1.2700e+00,  1.2727e+00,  1.2715e+00,  1.2744e+00,  1.2726e+00,
          1.2705e+00,  1.2709e+00,  1.2698e+00,  1.2698e+00,  1.3379e+00,
          1.3401e+00,  1.3391e+00,  1.3421e+00,  1.3369e+00,  1.2841e+00,
          1.3384e+00,  1.2750e+00,  1.3263e+00,  2.7177e+00,  2.8344e+00,
          2.8795e+00,  2.7266e+00,  2.6567e+00,  2.6535e+00,  2.8104e+00,
          2.6485e+00,  2.6485e+00,  1.2674e+00,  1.3012e+00,  1.3105e+00,
          1.3136e+00,  1.2681e+00,  1.3119e+00,  1.3147e+00,  1.3104e+00,
          1.3108e+00,  1.7425e+00,  1.7535e+00,  1.7471e+00,  1.6762e+00,
          1.7515e+00,  1.7458e+00,  1.7439e+00,  1.7284e+00,  1.6754e+00,
          1.5977e+00,  1.5813e+00,  1.5779e+00,  1.5716e+00,  1.5753e+00,
          1.5765e+00,  1.5897e+00,  1.5622e+00,  1.5700e+00],
        [ 1.2766e+00,  1.2794e+00,  1.2782e+00,  1.2812e+00,  1.2793e+00,
          1.2771e+00,  1.2776e+00,  1.2763e+00,  1.2763e+00,  1.3448e+00,
          1.3470e+00,  1.3459e+00,  1.3294e+00,  1.3437e+00,  1.2848e+00,
          1.3452e+00,  1.3413e+00,  1.2833e+00,  1.2993e+00,  1.2761e+00,
          1.3006e+00,  1.3003e+00,  1.2968e+00,  1.2962e+00,  1.2933e+00,
          1.2954e+00,  1.2954e+00,  2.8858e+00,  2.8093e+00,  2.6271e+00,
          2.6545e+00,  2.8847e+00,  2.6356e+00,  2.7894e+00,  2.6856e+00,
          2.6288e+00,  1.7458e+00,  1.7572e+00,  1.7236e+00,  1.7396e+00,
          1.7551e+00,  1.7494e+00,  1.7203e+00,  1.7281e+00,  1.7388e+00,
          1.6025e+00,  1.5856e+00,  1.5258e+00,  1.5220e+00,  1.5991e+00,
          1.5807e+00,  1.6138e+00,  1.5126e+00,  1.5739e+00],
        [ 1.8993e+00,  1.5008e+00,  6.5348e-01,  9.7086e-01,  1.3956e+00,
          1.8300e+00,  1.7028e+00,  1.9354e+00,  1.9354e+00,  1.7337e+00,
          1.3681e+00,  1.5812e+00,  9.8516e-01,  1.7871e+00,  1.7289e-01,
          1.6720e+00,  1.9591e+00,  8.8992e-01,  1.4030e+00,  1.0692e+00,
          8.1550e-01,  1.2116e+00,  1.7722e+00,  1.8384e+00,  1.6115e+00,
          1.9446e+00,  1.9446e+00,  9.1126e-01,  9.0089e-01,  1.9168e+00,
          1.7038e+00,  9.1443e-01,  1.8574e+00,  1.3112e+00,  1.9655e+00,
          1.8812e+00, -1.5185e-01, -3.9180e-01, -4.3532e-01, -2.0222e-01,
          5.1703e-02,  1.3590e-01, -2.7652e-01,  1.8692e+01,  2.7534e+00,
          2.6887e-01,  6.3054e-01,  6.5268e-01,  7.6567e-01,  4.2080e-01,
          7.6706e-01, -1.7989e-02,  8.0233e-01,  8.6246e-01],
        [ 1.3371e+00,  1.3739e+00,  1.4050e+00,  1.4058e+00,  1.3807e+00,
          1.3441e+00,  1.3144e+00,  1.3334e+00,  1.3334e+00,  1.3106e+00,
          1.4302e+00,  1.3264e+00,  1.4568e+00,  1.3859e+00,  1.4820e+00,
          1.3171e+00,  1.3610e+00,  1.3722e+00,  1.3951e+00,  1.3615e+00,
          1.4272e+00,  1.4087e+00,  1.3622e+00,  1.3554e+00,  1.2447e+00,
          1.3440e+00,  1.3440e+00,  1.3838e+00,  1.4403e+00,  1.3586e+00,
          1.1494e+00,  1.3414e+00,  1.2474e+00,  1.4152e+00,  1.2363e+00,
          1.3628e+00,  3.4303e-01,  2.6705e-01,  3.8042e-01,  3.4811e-01,
          1.4217e-01,  9.3053e-02,  3.6659e-01,  1.3693e-01, -6.6145e-02,
          3.5504e+00,  2.3087e+00,  3.5075e+00,  2.6598e+00,  1.8413e+00,
          1.4354e+00,  2.8860e+00,  3.3871e+00,  1.4000e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 346 : 174.31362795448192
Test loss for epoch 346 : 174.6528506806594
Test Precision for epoch 346 : 0.26153846153846155
Test Recall for epoch 346 : 0.26153846153846155
Test F1 for epoch 346 : 0.26153846153846155


theta for epoch 347 : tensor([[ 2.6689e+00,  2.6878e+00,  2.7250e+00,  2.8433e+00,  2.8241e+00,
          2.6721e+00,  2.8111e+00,  2.6672e+00,  2.6672e+00,  1.3337e+00,
          1.3358e+00,  1.3348e+00,  1.3378e+00,  1.3327e+00,  1.3398e+00,
          1.3341e+00,  1.3309e+00,  1.2931e+00,  1.2842e+00,  1.2418e+00,
          1.2426e+00,  1.2852e+00,  1.2818e+00,  1.2813e+00,  1.2834e+00,
          1.2805e+00,  1.2805e+00,  1.2664e+00,  1.3110e+00,  1.3050e+00,
          1.3081e+00,  1.3111e+00,  1.3064e+00,  1.3092e+00,  1.2610e+00,
          1.3053e+00,  1.7380e+00,  1.7488e+00,  1.7425e+00,  1.7388e+00,
          1.7468e+00,  1.6863e+00,  1.7394e+00,  1.7242e+00,  1.7381e+00,
          1.5945e+00,  1.5783e+00,  1.5750e+00,  1.5689e+00,  1.5912e+00,
          1.5737e+00,  1.6053e+00,  1.5651e+00,  1.5672e+00],
        [ 1.2857e+00,  1.2886e+00,  1.2867e+00,  1.2860e+00,  1.2892e+00,
          1.2863e+00,  1.2874e+00,  1.2855e+00,  1.2855e+00,  2.6131e+00,
          2.6278e+00,  2.6050e+00,  2.8340e+00,  2.5914e+00,  2.9867e+00,
          2.6156e+00,  2.7992e+00,  2.9603e+00,  1.2759e+00,  1.2809e+00,
          1.2341e+00,  1.2768e+00,  1.3033e+00,  1.3028e+00,  1.3043e+00,
          1.3019e+00,  1.3019e+00,  1.3059e+00,  1.2580e+00,  1.3265e+00,
          1.3298e+00,  1.3009e+00,  1.3280e+00,  1.3310e+00,  1.3006e+00,
          1.3268e+00,  1.7499e+00,  1.7618e+00,  1.7179e+00,  1.7500e+00,
          1.7596e+00,  1.7612e+00,  1.7145e+00,  1.7266e+00,  1.7493e+00,
          1.5550e+00,  1.5929e+00,  1.5892e+00,  1.5825e+00,  1.5153e+00,
          1.5878e+00,  1.5307e+00,  1.5784e+00,  1.5807e+00],
        [ 1.2705e+00,  1.2732e+00,  1.2719e+00,  1.2749e+00,  1.2730e+00,
          1.2710e+00,  1.2714e+00,  1.2702e+00,  1.2702e+00,  1.3401e+00,
          1.3423e+00,  1.3413e+00,  1.3443e+00,  1.3391e+00,  1.2862e+00,
          1.3406e+00,  1.2772e+00,  1.3285e+00,  2.7156e+00,  2.8327e+00,
          2.8776e+00,  2.7246e+00,  2.6546e+00,  2.6514e+00,  2.8087e+00,
          2.6464e+00,  2.6464e+00,  1.2683e+00,  1.3021e+00,  1.3114e+00,
          1.3145e+00,  1.2690e+00,  1.3128e+00,  1.3157e+00,  1.3113e+00,
          1.3117e+00,  1.7424e+00,  1.7534e+00,  1.7470e+00,  1.6760e+00,
          1.7513e+00,  1.7456e+00,  1.7438e+00,  1.7283e+00,  1.6753e+00,
          1.5998e+00,  1.5833e+00,  1.5799e+00,  1.5737e+00,  1.5774e+00,
          1.5786e+00,  1.5917e+00,  1.5641e+00,  1.5720e+00],
        [ 1.2767e+00,  1.2795e+00,  1.2782e+00,  1.2813e+00,  1.2794e+00,
          1.2772e+00,  1.2777e+00,  1.2764e+00,  1.2764e+00,  1.3462e+00,
          1.3485e+00,  1.3474e+00,  1.3308e+00,  1.3451e+00,  1.2864e+00,
          1.3467e+00,  1.3427e+00,  1.2848e+00,  1.2970e+00,  1.2738e+00,
          1.2983e+00,  1.2980e+00,  1.2944e+00,  1.2939e+00,  1.2909e+00,
          1.2931e+00,  1.2931e+00,  2.8871e+00,  2.8103e+00,  2.6281e+00,
          2.6554e+00,  2.8860e+00,  2.6367e+00,  2.7904e+00,  2.6868e+00,
          2.6299e+00,  1.7455e+00,  1.7568e+00,  1.7232e+00,  1.7392e+00,
          1.7547e+00,  1.7490e+00,  1.7199e+00,  1.7278e+00,  1.7384e+00,
          1.6042e+00,  1.5872e+00,  1.5275e+00,  1.5236e+00,  1.6007e+00,
          1.5823e+00,  1.6154e+00,  1.5141e+00,  1.5756e+00],
        [ 1.9019e+00,  1.5038e+00,  6.5704e-01,  9.7407e-01,  1.3987e+00,
          1.8326e+00,  1.7056e+00,  1.9379e+00,  1.9379e+00,  1.7372e+00,
          1.3719e+00,  1.5848e+00,  9.8898e-01,  1.7907e+00,  1.7676e-01,
          1.6755e+00,  1.9624e+00,  8.9396e-01,  1.4056e+00,  1.0722e+00,
          8.1861e-01,  1.2144e+00,  1.7743e+00,  1.8404e+00,  1.6139e+00,
          1.9464e+00,  1.9464e+00,  9.1503e-01,  9.0461e-01,  1.9199e+00,
          1.7071e+00,  9.1827e-01,  1.8607e+00,  1.3147e+00,  1.9686e+00,
          1.8844e+00, -1.5516e-01, -3.9494e-01, -4.3842e-01, -2.0564e-01,
          4.8259e-02,  1.3225e-01, -2.7973e-01,  1.8727e+01,  2.7292e+00,
          2.7282e-01,  6.3456e-01,  6.5673e-01,  7.6978e-01,  4.2480e-01,
          7.7115e-01, -1.4100e-02,  8.0651e-01,  8.6657e-01],
        [ 1.3335e+00,  1.3703e+00,  1.4011e+00,  1.4021e+00,  1.3771e+00,
          1.3405e+00,  1.3107e+00,  1.3297e+00,  1.3297e+00,  1.3069e+00,
          1.4267e+00,  1.3228e+00,  1.4533e+00,  1.3824e+00,  1.4784e+00,
          1.3134e+00,  1.3574e+00,  1.3686e+00,  1.3903e+00,  1.3564e+00,
          1.4225e+00,  1.4039e+00,  1.3574e+00,  1.3506e+00,  1.2396e+00,
          1.3391e+00,  1.3391e+00,  1.3800e+00,  1.4368e+00,  1.3550e+00,
          1.1456e+00,  1.3376e+00,  1.2437e+00,  1.4116e+00,  1.2326e+00,
          1.3592e+00,  3.3897e-01,  2.6294e-01,  3.7634e-01,  3.4400e-01,
          1.3802e-01,  8.8822e-02,  3.6254e-01,  1.3271e-01, -7.0264e-02,
          3.5572e+00,  2.3133e+00,  3.5140e+00,  2.6647e+00,  1.8458e+00,
          1.4399e+00,  2.8909e+00,  3.3946e+00,  1.4044e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 347 : 174.30171254086176
Test loss for epoch 347 : 174.63751961201498
Test Precision for epoch 347 : 0.26153846153846155
Test Recall for epoch 347 : 0.26153846153846155
Test F1 for epoch 347 : 0.26153846153846155


theta for epoch 348 : tensor([[ 2.6699e+00,  2.6888e+00,  2.7261e+00,  2.8445e+00,  2.8253e+00,
          2.6732e+00,  2.8123e+00,  2.6683e+00,  2.6683e+00,  1.3328e+00,
          1.3350e+00,  1.3340e+00,  1.3370e+00,  1.3318e+00,  1.3390e+00,
          1.3333e+00,  1.3301e+00,  1.2922e+00,  1.2869e+00,  1.2445e+00,
          1.2453e+00,  1.2879e+00,  1.2845e+00,  1.2840e+00,  1.2861e+00,
          1.2832e+00,  1.2832e+00,  1.2666e+00,  1.3112e+00,  1.3051e+00,
          1.3082e+00,  1.3112e+00,  1.3065e+00,  1.3093e+00,  1.2612e+00,
          1.3054e+00,  1.7385e+00,  1.7493e+00,  1.7431e+00,  1.7394e+00,
          1.7473e+00,  1.6869e+00,  1.7400e+00,  1.7248e+00,  1.7387e+00,
          1.5930e+00,  1.5767e+00,  1.5734e+00,  1.5673e+00,  1.5897e+00,
          1.5721e+00,  1.6038e+00,  1.5634e+00,  1.5656e+00],
        [ 1.2859e+00,  1.2887e+00,  1.2870e+00,  1.2863e+00,  1.2893e+00,
          1.2865e+00,  1.2875e+00,  1.2856e+00,  1.2856e+00,  2.6128e+00,
          2.6275e+00,  2.6051e+00,  2.8346e+00,  2.5915e+00,  2.9869e+00,
          2.6154e+00,  2.7997e+00,  2.9604e+00,  1.2789e+00,  1.2840e+00,
          1.2371e+00,  1.2798e+00,  1.3063e+00,  1.3058e+00,  1.3073e+00,
          1.3049e+00,  1.3049e+00,  1.3062e+00,  1.2582e+00,  1.3267e+00,
          1.3300e+00,  1.3012e+00,  1.3282e+00,  1.3313e+00,  1.3008e+00,
          1.3270e+00,  1.7505e+00,  1.7623e+00,  1.7185e+00,  1.7506e+00,
          1.7602e+00,  1.7617e+00,  1.7151e+00,  1.7274e+00,  1.7499e+00,
          1.5533e+00,  1.5912e+00,  1.5875e+00,  1.5808e+00,  1.5137e+00,
          1.5861e+00,  1.5291e+00,  1.5767e+00,  1.5790e+00],
        [ 1.2703e+00,  1.2730e+00,  1.2717e+00,  1.2747e+00,  1.2728e+00,
          1.2708e+00,  1.2712e+00,  1.2700e+00,  1.2700e+00,  1.3387e+00,
          1.3409e+00,  1.3399e+00,  1.3429e+00,  1.3377e+00,  1.2849e+00,
          1.3392e+00,  1.2758e+00,  1.3271e+00,  2.7185e+00,  2.8360e+00,
          2.8807e+00,  2.7275e+00,  2.6575e+00,  2.6543e+00,  2.8120e+00,
          2.6493e+00,  2.6493e+00,  1.2680e+00,  1.3020e+00,  1.3113e+00,
          1.3144e+00,  1.2687e+00,  1.3127e+00,  1.3155e+00,  1.3112e+00,
          1.3116e+00,  1.7428e+00,  1.7538e+00,  1.7474e+00,  1.6764e+00,
          1.7518e+00,  1.7459e+00,  1.7443e+00,  1.7287e+00,  1.6756e+00,
          1.5979e+00,  1.5815e+00,  1.5781e+00,  1.5718e+00,  1.5755e+00,
          1.5767e+00,  1.5899e+00,  1.5622e+00,  1.5702e+00],
        [ 1.2768e+00,  1.2795e+00,  1.2783e+00,  1.2814e+00,  1.2795e+00,
          1.2773e+00,  1.2778e+00,  1.2765e+00,  1.2765e+00,  1.3454e+00,
          1.3476e+00,  1.3465e+00,  1.3300e+00,  1.3443e+00,  1.2856e+00,
          1.3458e+00,  1.3419e+00,  1.2840e+00,  1.2996e+00,  1.2764e+00,
          1.3009e+00,  1.3006e+00,  1.2971e+00,  1.2966e+00,  1.2935e+00,
          1.2957e+00,  1.2957e+00,  2.8881e+00,  2.8111e+00,  2.6289e+00,
          2.6560e+00,  2.8871e+00,  2.6375e+00,  2.7912e+00,  2.6877e+00,
          2.6307e+00,  1.7461e+00,  1.7574e+00,  1.7238e+00,  1.7397e+00,
          1.7553e+00,  1.7495e+00,  1.7205e+00,  1.7285e+00,  1.7389e+00,
          1.6027e+00,  1.5857e+00,  1.5260e+00,  1.5221e+00,  1.5992e+00,
          1.5808e+00,  1.6139e+00,  1.5125e+00,  1.5740e+00],
        [ 1.9004e+00,  1.5021e+00,  6.5521e-01,  9.7219e-01,  1.3969e+00,
          1.8311e+00,  1.7040e+00,  1.9365e+00,  1.9365e+00,  1.7349e+00,
          1.3695e+00,  1.5826e+00,  9.8679e-01,  1.7885e+00,  1.7447e-01,
          1.6732e+00,  1.9603e+00,  8.9153e-01,  1.4045e+00,  1.0710e+00,
          8.1712e-01,  1.2131e+00,  1.7734e+00,  1.8396e+00,  1.6133e+00,
          1.9457e+00,  1.9457e+00,  9.1325e-01,  9.0260e-01,  1.9182e+00,
          1.7053e+00,  9.1636e-01,  1.8589e+00,  1.3128e+00,  1.9670e+00,
          1.8826e+00, -1.5354e-01, -3.9328e-01, -4.3676e-01, -2.0416e-01,
          4.9812e-02,  1.3360e-01, -2.7808e-01,  1.8767e+01,  2.7105e+00,
          2.7070e-01,  6.3255e-01,  6.5469e-01,  7.6779e-01,  4.2271e-01,
          7.6914e-01, -1.6277e-02,  8.0463e-01,  8.6459e-01],
        [ 1.3353e+00,  1.3721e+00,  1.4027e+00,  1.4039e+00,  1.3789e+00,
          1.3423e+00,  1.3125e+00,  1.3315e+00,  1.3315e+00,  1.3087e+00,
          1.4284e+00,  1.3245e+00,  1.4550e+00,  1.3841e+00,  1.4800e+00,
          1.3152e+00,  1.3591e+00,  1.3703e+00,  1.3931e+00,  1.3590e+00,
          1.4252e+00,  1.4066e+00,  1.3602e+00,  1.3533e+00,  1.2421e+00,
          1.3419e+00,  1.3419e+00,  1.3817e+00,  1.4387e+00,  1.3570e+00,
          1.1476e+00,  1.3393e+00,  1.2457e+00,  1.4136e+00,  1.2345e+00,
          1.3611e+00,  3.4112e-01,  2.6505e-01,  3.7847e-01,  3.4608e-01,
          1.4015e-01,  9.0882e-02,  3.6467e-01,  1.3482e-01, -6.8030e-02,
          3.5574e+00,  2.3114e+00,  3.5141e+00,  2.6632e+00,  1.8437e+00,
          1.4378e+00,  2.8893e+00,  3.3954e+00,  1.4023e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 348 : 174.2889616346044
Test loss for epoch 348 : 174.6316316348648
Test Precision for epoch 348 : 0.26153846153846155
Test Recall for epoch 348 : 0.26153846153846155
Test F1 for epoch 348 : 0.26153846153846155


theta for epoch 349 : tensor([[ 2.6714e+00,  2.6903e+00,  2.7275e+00,  2.8461e+00,  2.8269e+00,
          2.6746e+00,  2.8140e+00,  2.6697e+00,  2.6697e+00,  1.3332e+00,
          1.3353e+00,  1.3343e+00,  1.3373e+00,  1.3322e+00,  1.3393e+00,
          1.3336e+00,  1.3304e+00,  1.2926e+00,  1.2858e+00,  1.2434e+00,
          1.2442e+00,  1.2868e+00,  1.2834e+00,  1.2829e+00,  1.2850e+00,
          1.2821e+00,  1.2821e+00,  1.2666e+00,  1.3112e+00,  1.3051e+00,
          1.3082e+00,  1.3112e+00,  1.3065e+00,  1.3093e+00,  1.2612e+00,
          1.3054e+00,  1.7384e+00,  1.7491e+00,  1.7429e+00,  1.7392e+00,
          1.7471e+00,  1.6867e+00,  1.7398e+00,  1.7246e+00,  1.7385e+00,
          1.5935e+00,  1.5773e+00,  1.5740e+00,  1.5678e+00,  1.5902e+00,
          1.5726e+00,  1.6043e+00,  1.5639e+00,  1.5661e+00],
        [ 1.2857e+00,  1.2886e+00,  1.2870e+00,  1.2863e+00,  1.2892e+00,
          1.2863e+00,  1.2874e+00,  1.2855e+00,  1.2855e+00,  2.6150e+00,
          2.6297e+00,  2.6077e+00,  2.8374e+00,  2.5941e+00,  2.9891e+00,
          2.6176e+00,  2.8027e+00,  2.9628e+00,  1.2772e+00,  1.2823e+00,
          1.2353e+00,  1.2781e+00,  1.3046e+00,  1.3041e+00,  1.3056e+00,
          1.3032e+00,  1.3032e+00,  1.3058e+00,  1.2579e+00,  1.3264e+00,
          1.3297e+00,  1.3010e+00,  1.3279e+00,  1.3309e+00,  1.3005e+00,
          1.3267e+00,  1.7502e+00,  1.7620e+00,  1.7182e+00,  1.7503e+00,
          1.7598e+00,  1.7614e+00,  1.7148e+00,  1.7273e+00,  1.7495e+00,
          1.5536e+00,  1.5914e+00,  1.5877e+00,  1.5810e+00,  1.5139e+00,
          1.5863e+00,  1.5293e+00,  1.5769e+00,  1.5792e+00],
        [ 1.2704e+00,  1.2731e+00,  1.2717e+00,  1.2749e+00,  1.2730e+00,
          1.2709e+00,  1.2713e+00,  1.2702e+00,  1.2702e+00,  1.3391e+00,
          1.3413e+00,  1.3402e+00,  1.3433e+00,  1.3381e+00,  1.2852e+00,
          1.3396e+00,  1.2762e+00,  1.3275e+00,  2.7193e+00,  2.8372e+00,
          2.8817e+00,  2.7283e+00,  2.6582e+00,  2.6550e+00,  2.8132e+00,
          2.6500e+00,  2.6500e+00,  1.2679e+00,  1.3019e+00,  1.3112e+00,
          1.3143e+00,  1.2686e+00,  1.3126e+00,  1.3155e+00,  1.3112e+00,
          1.3115e+00,  1.7426e+00,  1.7536e+00,  1.7472e+00,  1.6761e+00,
          1.7516e+00,  1.7456e+00,  1.7441e+00,  1.7286e+00,  1.6753e+00,
          1.5984e+00,  1.5819e+00,  1.5786e+00,  1.5723e+00,  1.5760e+00,
          1.5772e+00,  1.5904e+00,  1.5626e+00,  1.5706e+00],
        [ 1.2768e+00,  1.2796e+00,  1.2782e+00,  1.2814e+00,  1.2795e+00,
          1.2773e+00,  1.2778e+00,  1.2765e+00,  1.2765e+00,  1.3455e+00,
          1.3477e+00,  1.3467e+00,  1.3301e+00,  1.3444e+00,  1.2857e+00,
          1.3460e+00,  1.3420e+00,  1.2842e+00,  1.2983e+00,  1.2750e+00,
          1.2997e+00,  1.2994e+00,  1.2958e+00,  1.2953e+00,  1.2922e+00,
          1.2945e+00,  1.2945e+00,  2.8902e+00,  2.8128e+00,  2.6307e+00,
          2.6576e+00,  2.8891e+00,  2.6393e+00,  2.7929e+00,  2.6895e+00,
          2.6324e+00,  1.7458e+00,  1.7571e+00,  1.7235e+00,  1.7394e+00,
          1.7550e+00,  1.7491e+00,  1.7203e+00,  1.7284e+00,  1.7386e+00,
          1.6030e+00,  1.5860e+00,  1.5264e+00,  1.5224e+00,  1.5996e+00,
          1.5812e+00,  1.6143e+00,  1.5128e+00,  1.5744e+00],
        [ 1.9011e+00,  1.5029e+00,  6.5618e-01,  9.7299e-01,  1.3978e+00,
          1.8318e+00,  1.7048e+00,  1.9372e+00,  1.9372e+00,  1.7357e+00,
          1.3704e+00,  1.5835e+00,  9.8775e-01,  1.7894e+00,  1.7536e-01,
          1.6741e+00,  1.9612e+00,  8.9249e-01,  1.4050e+00,  1.0718e+00,
          8.1780e-01,  1.2137e+00,  1.7738e+00,  1.8399e+00,  1.6139e+00,
          1.9460e+00,  1.9460e+00,  9.1425e-01,  9.0346e-01,  1.9189e+00,
          1.7060e+00,  9.1734e-01,  1.8597e+00,  1.3136e+00,  1.9676e+00,
          1.8833e+00, -1.5443e-01, -3.9407e-01, -4.3753e-01, -2.0517e-01,
          4.8828e-02,  1.3242e-01, -2.7892e-01,  1.8805e+01,  2.6892e+00,
          2.7173e-01,  6.3366e-01,  6.5581e-01,  7.6894e-01,  4.2378e-01,
          7.7028e-01, -1.5297e-02,  8.0588e-01,  8.6575e-01],
        [ 1.3349e+00,  1.3718e+00,  1.4021e+00,  1.4036e+00,  1.3786e+00,
          1.3420e+00,  1.3122e+00,  1.3312e+00,  1.3312e+00,  1.3084e+00,
          1.4281e+00,  1.3242e+00,  1.4547e+00,  1.3838e+00,  1.4797e+00,
          1.3149e+00,  1.3588e+00,  1.3700e+00,  1.3923e+00,  1.3579e+00,
          1.4244e+00,  1.4059e+00,  1.3594e+00,  1.3525e+00,  1.2411e+00,
          1.3411e+00,  1.3411e+00,  1.3811e+00,  1.4383e+00,  1.3566e+00,
          1.1472e+00,  1.3386e+00,  1.2453e+00,  1.4132e+00,  1.2341e+00,
          1.3607e+00,  3.4059e-01,  2.6447e-01,  3.7792e-01,  3.4549e-01,
          1.3958e-01,  9.0244e-02,  3.6414e-01,  1.3422e-01, -6.8498e-02,
          3.5604e+00,  2.3123e+00,  3.5169e+00,  2.6644e+00,  1.8445e+00,
          1.4385e+00,  2.8906e+00,  3.3992e+00,  1.4031e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 349 : 174.2799113356208
Test loss for epoch 349 : 174.62440836763204
Test Precision for epoch 349 : 0.26153846153846155
Test Recall for epoch 349 : 0.26153846153846155
Test F1 for epoch 349 : 0.26153846153846155


theta for epoch 350 : tensor([[ 2.6729e+00,  2.6918e+00,  2.7290e+00,  2.8478e+00,  2.8286e+00,
          2.6761e+00,  2.8157e+00,  2.6712e+00,  2.6712e+00,  1.3331e+00,
          1.3352e+00,  1.3342e+00,  1.3372e+00,  1.3320e+00,  1.3392e+00,
          1.3335e+00,  1.3303e+00,  1.2924e+00,  1.2850e+00,  1.2426e+00,
          1.2434e+00,  1.2860e+00,  1.2826e+00,  1.2821e+00,  1.2842e+00,
          1.2813e+00,  1.2813e+00,  1.2663e+00,  1.3110e+00,  1.3049e+00,
          1.3080e+00,  1.3110e+00,  1.3063e+00,  1.3091e+00,  1.2609e+00,
          1.3052e+00,  1.7380e+00,  1.7487e+00,  1.7425e+00,  1.7389e+00,
          1.7468e+00,  1.6863e+00,  1.7394e+00,  1.7242e+00,  1.7381e+00,
          1.5947e+00,  1.5785e+00,  1.5751e+00,  1.5690e+00,  1.5914e+00,
          1.5738e+00,  1.6055e+00,  1.5651e+00,  1.5673e+00],
        [ 1.2856e+00,  1.2884e+00,  1.2870e+00,  1.2863e+00,  1.2890e+00,
          1.2861e+00,  1.2872e+00,  1.2853e+00,  1.2853e+00,  2.6168e+00,
          2.6315e+00,  2.6099e+00,  2.8399e+00,  2.5962e+00,  2.9910e+00,
          2.6193e+00,  2.8052e+00,  2.9648e+00,  1.2761e+00,  1.2811e+00,
          1.2342e+00,  1.2769e+00,  1.3035e+00,  1.3030e+00,  1.3045e+00,
          1.3021e+00,  1.3021e+00,  1.3053e+00,  1.2573e+00,  1.3259e+00,
          1.3292e+00,  1.3007e+00,  1.3274e+00,  1.3304e+00,  1.3000e+00,
          1.3262e+00,  1.7497e+00,  1.7615e+00,  1.7177e+00,  1.7498e+00,
          1.7593e+00,  1.7609e+00,  1.7143e+00,  1.7271e+00,  1.7491e+00,
          1.5546e+00,  1.5924e+00,  1.5888e+00,  1.5820e+00,  1.5149e+00,
          1.5873e+00,  1.5304e+00,  1.5779e+00,  1.5802e+00],
        [ 1.2703e+00,  1.2730e+00,  1.2716e+00,  1.2747e+00,  1.2729e+00,
          1.2708e+00,  1.2712e+00,  1.2700e+00,  1.2700e+00,  1.3388e+00,
          1.3409e+00,  1.3399e+00,  1.3429e+00,  1.3377e+00,  1.2848e+00,
          1.3392e+00,  1.2758e+00,  1.3271e+00,  2.7208e+00,  2.8391e+00,
          2.8834e+00,  2.7298e+00,  2.6597e+00,  2.6565e+00,  2.8151e+00,
          2.6515e+00,  2.6515e+00,  1.2674e+00,  1.3015e+00,  1.3108e+00,
          1.3139e+00,  1.2681e+00,  1.3122e+00,  1.3150e+00,  1.3107e+00,
          1.3111e+00,  1.7422e+00,  1.7531e+00,  1.7468e+00,  1.6755e+00,
          1.7511e+00,  1.7451e+00,  1.7436e+00,  1.7281e+00,  1.6748e+00,
          1.5995e+00,  1.5830e+00,  1.5796e+00,  1.5733e+00,  1.5771e+00,
          1.5782e+00,  1.5915e+00,  1.5635e+00,  1.5716e+00],
        [ 1.2767e+00,  1.2794e+00,  1.2780e+00,  1.2813e+00,  1.2794e+00,
          1.2772e+00,  1.2777e+00,  1.2764e+00,  1.2764e+00,  1.3451e+00,
          1.3473e+00,  1.3462e+00,  1.3296e+00,  1.3440e+00,  1.2853e+00,
          1.3455e+00,  1.3416e+00,  1.2838e+00,  1.2973e+00,  1.2740e+00,
          1.2986e+00,  1.2984e+00,  1.2948e+00,  1.2943e+00,  1.2911e+00,
          1.2935e+00,  1.2935e+00,  2.8922e+00,  2.8146e+00,  2.6325e+00,
          2.6593e+00,  2.8912e+00,  2.6411e+00,  2.7947e+00,  2.6914e+00,
          2.6343e+00,  1.7453e+00,  1.7566e+00,  1.7230e+00,  1.7388e+00,
          1.7545e+00,  1.7486e+00,  1.7197e+00,  1.7279e+00,  1.7380e+00,
          1.6040e+00,  1.5870e+00,  1.5274e+00,  1.5234e+00,  1.6005e+00,
          1.5821e+00,  1.6153e+00,  1.5136e+00,  1.5753e+00],
        [ 1.9024e+00,  1.5044e+00,  6.5797e-01,  9.7454e-01,  1.3993e+00,
          1.8332e+00,  1.7062e+00,  1.9384e+00,  1.9384e+00,  1.7372e+00,
          1.3720e+00,  1.5851e+00,  9.8946e-01,  1.7908e+00,  1.7711e-01,
          1.6755e+00,  1.9625e+00,  8.9426e-01,  1.4065e+00,  1.0735e+00,
          8.1945e-01,  1.2152e+00,  1.7751e+00,  1.8412e+00,  1.6155e+00,
          1.9471e+00,  1.9471e+00,  9.1603e-01,  9.0513e-01,  1.9202e+00,
          1.7074e+00,  9.1912e-01,  1.8610e+00,  1.3152e+00,  1.9689e+00,
          1.8847e+00, -1.5608e-01, -3.9562e-01, -4.3905e-01, -2.0695e-01,
          4.7070e-02,  1.3046e-01, -2.8051e-01,  1.8841e+01,  2.6673e+00,
          2.7375e-01,  6.3573e-01,  6.5788e-01,  7.7105e-01,  4.2583e-01,
          7.7238e-01, -1.3332e-02,  8.0807e-01,  8.6785e-01],
        [ 1.3338e+00,  1.3707e+00,  1.4007e+00,  1.4025e+00,  1.3775e+00,
          1.3408e+00,  1.3111e+00,  1.3301e+00,  1.3301e+00,  1.3072e+00,
          1.4269e+00,  1.3230e+00,  1.4534e+00,  1.3826e+00,  1.4784e+00,
          1.3137e+00,  1.3576e+00,  1.3688e+00,  1.3909e+00,  1.3563e+00,
          1.4230e+00,  1.4044e+00,  1.3580e+00,  1.3511e+00,  1.2395e+00,
          1.3397e+00,  1.3397e+00,  1.3795e+00,  1.4370e+00,  1.3553e+00,
          1.1459e+00,  1.3371e+00,  1.2440e+00,  1.4119e+00,  1.2328e+00,
          1.3594e+00,  3.3923e-01,  2.6305e-01,  3.7652e-01,  3.4407e-01,
          1.3817e-01,  8.8759e-02,  3.6276e-01,  1.3279e-01, -6.9808e-02,
          3.5644e+00,  2.3142e+00,  3.5207e+00,  2.6666e+00,  1.8461e+00,
          1.4402e+00,  2.8927e+00,  3.4038e+00,  1.4048e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 350 : 174.27496554603493
Test loss for epoch 350 : 174.61990502928097
Test Precision for epoch 350 : 0.26153846153846155
Test Recall for epoch 350 : 0.26153846153846155
Test F1 for epoch 350 : 0.26153846153846155


theta for epoch 351 : tensor([[ 2.6742e+00,  2.6931e+00,  2.7304e+00,  2.8493e+00,  2.8301e+00,
          2.6775e+00,  2.8171e+00,  2.6726e+00,  2.6726e+00,  1.3326e+00,
          1.3347e+00,  1.3337e+00,  1.3367e+00,  1.3315e+00,  1.3387e+00,
          1.3330e+00,  1.3298e+00,  1.2919e+00,  1.2867e+00,  1.2442e+00,
          1.2450e+00,  1.2877e+00,  1.2843e+00,  1.2838e+00,  1.2859e+00,
          1.2830e+00,  1.2830e+00,  1.2662e+00,  1.3108e+00,  1.3047e+00,
          1.3078e+00,  1.3108e+00,  1.3061e+00,  1.3089e+00,  1.2607e+00,
          1.3050e+00,  1.7385e+00,  1.7492e+00,  1.7430e+00,  1.7394e+00,
          1.7472e+00,  1.6867e+00,  1.7399e+00,  1.7247e+00,  1.7386e+00,
          1.5932e+00,  1.5769e+00,  1.5736e+00,  1.5674e+00,  1.5899e+00,
          1.5722e+00,  1.6040e+00,  1.5635e+00,  1.5657e+00],
        [ 1.2857e+00,  1.2885e+00,  1.2872e+00,  1.2865e+00,  1.2891e+00,
          1.2862e+00,  1.2873e+00,  1.2854e+00,  1.2854e+00,  2.6168e+00,
          2.6316e+00,  2.6103e+00,  2.8407e+00,  2.5966e+00,  2.9915e+00,
          2.6194e+00,  2.8060e+00,  2.9652e+00,  1.2782e+00,  1.2832e+00,
          1.2363e+00,  1.2791e+00,  1.3056e+00,  1.3051e+00,  1.3066e+00,
          1.3042e+00,  1.3042e+00,  1.3053e+00,  1.2573e+00,  1.3258e+00,
          1.3292e+00,  1.3008e+00,  1.3273e+00,  1.3304e+00,  1.3000e+00,
          1.3262e+00,  1.7503e+00,  1.7621e+00,  1.7183e+00,  1.7504e+00,
          1.7599e+00,  1.7615e+00,  1.7149e+00,  1.7278e+00,  1.7497e+00,
          1.5532e+00,  1.5909e+00,  1.5872e+00,  1.5805e+00,  1.5135e+00,
          1.5858e+00,  1.5289e+00,  1.5763e+00,  1.5787e+00],
        [ 1.2700e+00,  1.2727e+00,  1.2712e+00,  1.2745e+00,  1.2726e+00,
          1.2705e+00,  1.2709e+00,  1.2698e+00,  1.2698e+00,  1.3379e+00,
          1.3401e+00,  1.3390e+00,  1.3421e+00,  1.3369e+00,  1.2840e+00,
          1.3384e+00,  1.2749e+00,  1.3262e+00,  2.7236e+00,  2.8422e+00,
          2.8864e+00,  2.7325e+00,  2.6624e+00,  2.6592e+00,  2.8182e+00,
          2.6542e+00,  2.6542e+00,  1.2669e+00,  1.3011e+00,  1.3104e+00,
          1.3135e+00,  1.2676e+00,  1.3118e+00,  1.3146e+00,  1.3103e+00,
          1.3107e+00,  1.7426e+00,  1.7535e+00,  1.7472e+00,  1.6758e+00,
          1.7515e+00,  1.7454e+00,  1.7440e+00,  1.7285e+00,  1.6751e+00,
          1.5977e+00,  1.5812e+00,  1.5778e+00,  1.5715e+00,  1.5754e+00,
          1.5764e+00,  1.5898e+00,  1.5616e+00,  1.5698e+00],
        [ 1.2765e+00,  1.2793e+00,  1.2779e+00,  1.2812e+00,  1.2793e+00,
          1.2771e+00,  1.2775e+00,  1.2763e+00,  1.2763e+00,  1.3444e+00,
          1.3467e+00,  1.3456e+00,  1.3290e+00,  1.3434e+00,  1.2847e+00,
          1.3449e+00,  1.3410e+00,  1.2832e+00,  1.2988e+00,  1.2754e+00,
          1.3002e+00,  1.2999e+00,  1.2964e+00,  1.2958e+00,  1.2926e+00,
          1.2950e+00,  1.2950e+00,  2.8938e+00,  2.8158e+00,  2.6338e+00,
          2.6604e+00,  2.8928e+00,  2.6424e+00,  2.7960e+00,  2.6928e+00,
          2.6355e+00,  1.7458e+00,  1.7571e+00,  1.7234e+00,  1.7392e+00,
          1.7550e+00,  1.7489e+00,  1.7202e+00,  1.7285e+00,  1.7384e+00,
          1.6025e+00,  1.5854e+00,  1.5259e+00,  1.5218e+00,  1.5990e+00,
          1.5805e+00,  1.6138e+00,  1.5119e+00,  1.5737e+00],
        [ 1.9008e+00,  1.5026e+00,  6.5604e-01,  9.7257e-01,  1.3975e+00,
          1.8316e+00,  1.7045e+00,  1.9369e+00,  1.9369e+00,  1.7350e+00,
          1.3698e+00,  1.5830e+00,  9.8728e-01,  1.7888e+00,  1.7480e-01,
          1.6733e+00,  1.9606e+00,  8.9183e-01,  1.4050e+00,  1.0721e+00,
          8.1769e-01,  1.2136e+00,  1.7738e+00,  1.8400e+00,  1.6144e+00,
          1.9461e+00,  1.9461e+00,  9.1408e-01,  9.0295e-01,  1.9183e+00,
          1.7054e+00,  9.1704e-01,  1.8590e+00,  1.3131e+00,  1.9670e+00,
          1.8827e+00, -1.5433e-01, -3.9385e-01, -4.3728e-01, -2.0534e-01,
          4.8761e-02,  1.3195e-01, -2.7874e-01,  1.8881e+01,  2.6492e+00,
          2.7154e-01,  6.3359e-01,  6.5569e-01,  7.6889e-01,  4.2364e-01,
          7.7021e-01, -1.5576e-02,  8.0602e-01,  8.6569e-01],
        [ 1.3360e+00,  1.3729e+00,  1.4027e+00,  1.4046e+00,  1.3797e+00,
          1.3430e+00,  1.3133e+00,  1.3323e+00,  1.3323e+00,  1.3096e+00,
          1.4292e+00,  1.3254e+00,  1.4557e+00,  1.3849e+00,  1.4808e+00,
          1.3161e+00,  1.3600e+00,  1.3711e+00,  1.3939e+00,  1.3590e+00,
          1.4259e+00,  1.4074e+00,  1.3610e+00,  1.3541e+00,  1.2423e+00,
          1.3427e+00,  1.3427e+00,  1.3816e+00,  1.4392e+00,  1.3575e+00,
          1.1483e+00,  1.3391e+00,  1.2463e+00,  1.4141e+00,  1.2351e+00,
          1.3617e+00,  3.4180e-01,  2.6558e-01,  3.7907e-01,  3.4658e-01,
          1.4073e-01,  9.1256e-02,  3.6532e-01,  1.3537e-01, -6.7100e-02,
          3.5643e+00,  2.3120e+00,  3.5204e+00,  2.6647e+00,  1.8437e+00,
          1.4378e+00,  2.8908e+00,  3.4043e+00,  1.4023e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 351 : 174.2702794002991
Test loss for epoch 351 : 174.62242257402465
Test Precision for epoch 351 : 0.26153846153846155
Test Recall for epoch 351 : 0.26153846153846155
Test F1 for epoch 351 : 0.26153846153846155


theta for epoch 352 : tensor([[ 2.6755e+00,  2.6944e+00,  2.7317e+00,  2.8508e+00,  2.8316e+00,
          2.6788e+00,  2.8186e+00,  2.6739e+00,  2.6739e+00,  1.3335e+00,
          1.3356e+00,  1.3346e+00,  1.3376e+00,  1.3325e+00,  1.3396e+00,
          1.3340e+00,  1.3308e+00,  1.2928e+00,  1.2843e+00,  1.2418e+00,
          1.2426e+00,  1.2853e+00,  1.2819e+00,  1.2814e+00,  1.2835e+00,
          1.2806e+00,  1.2806e+00,  1.2663e+00,  1.3109e+00,  1.3048e+00,
          1.3079e+00,  1.3109e+00,  1.3062e+00,  1.3090e+00,  1.2608e+00,
          1.3051e+00,  1.7381e+00,  1.7488e+00,  1.7426e+00,  1.7390e+00,
          1.7468e+00,  1.6863e+00,  1.7395e+00,  1.7243e+00,  1.7383e+00,
          1.5943e+00,  1.5780e+00,  1.5747e+00,  1.5685e+00,  1.5910e+00,
          1.5733e+00,  1.6052e+00,  1.5646e+00,  1.5668e+00],
        [ 1.2855e+00,  1.2883e+00,  1.2871e+00,  1.2864e+00,  1.2889e+00,
          1.2860e+00,  1.2871e+00,  1.2852e+00,  1.2852e+00,  2.6185e+00,
          2.6333e+00,  2.6123e+00,  2.8430e+00,  2.5986e+00,  2.9934e+00,
          2.6211e+00,  2.8084e+00,  2.9672e+00,  1.2757e+00,  1.2807e+00,
          1.2338e+00,  1.2766e+00,  1.3032e+00,  1.3026e+00,  1.3042e+00,
          1.3018e+00,  1.3018e+00,  1.3054e+00,  1.2574e+00,  1.3259e+00,
          1.3293e+00,  1.3010e+00,  1.3274e+00,  1.3305e+00,  1.3001e+00,
          1.3262e+00,  1.7499e+00,  1.7616e+00,  1.7179e+00,  1.7500e+00,
          1.7595e+00,  1.7611e+00,  1.7145e+00,  1.7276e+00,  1.7493e+00,
          1.5544e+00,  1.5921e+00,  1.5884e+00,  1.5816e+00,  1.5146e+00,
          1.5869e+00,  1.5301e+00,  1.5775e+00,  1.5798e+00],
        [ 1.2703e+00,  1.2730e+00,  1.2714e+00,  1.2747e+00,  1.2728e+00,
          1.2708e+00,  1.2712e+00,  1.2700e+00,  1.2700e+00,  1.3397e+00,
          1.3419e+00,  1.3408e+00,  1.3439e+00,  1.3387e+00,  1.2857e+00,
          1.3402e+00,  1.2768e+00,  1.3281e+00,  2.7222e+00,  2.8412e+00,
          2.8852e+00,  2.7312e+00,  2.6610e+00,  2.6578e+00,  2.8172e+00,
          2.6528e+00,  2.6528e+00,  1.2674e+00,  1.3017e+00,  1.3109e+00,
          1.3141e+00,  1.2681e+00,  1.3123e+00,  1.3152e+00,  1.3109e+00,
          1.3112e+00,  1.7424e+00,  1.7533e+00,  1.7470e+00,  1.6755e+00,
          1.7513e+00,  1.7451e+00,  1.7439e+00,  1.7284e+00,  1.6748e+00,
          1.5993e+00,  1.5828e+00,  1.5794e+00,  1.5730e+00,  1.5769e+00,
          1.5780e+00,  1.5913e+00,  1.5631e+00,  1.5714e+00],
        [ 1.2764e+00,  1.2792e+00,  1.2777e+00,  1.2811e+00,  1.2791e+00,
          1.2769e+00,  1.2774e+00,  1.2761e+00,  1.2761e+00,  1.3455e+00,
          1.3478e+00,  1.3467e+00,  1.3301e+00,  1.3445e+00,  1.2859e+00,
          1.3460e+00,  1.3421e+00,  1.2843e+00,  1.2967e+00,  1.2732e+00,
          1.2980e+00,  1.2978e+00,  1.2942e+00,  1.2937e+00,  1.2904e+00,
          1.2929e+00,  1.2929e+00,  2.8954e+00,  2.8171e+00,  2.6351e+00,
          2.6615e+00,  2.8943e+00,  2.6436e+00,  2.7972e+00,  2.6942e+00,
          2.6368e+00,  1.7454e+00,  1.7566e+00,  1.7230e+00,  1.7387e+00,
          1.7546e+00,  1.7485e+00,  1.7198e+00,  1.7282e+00,  1.7380e+00,
          1.6036e+00,  1.5865e+00,  1.5271e+00,  1.5229e+00,  1.6001e+00,
          1.5816e+00,  1.6149e+00,  1.5130e+00,  1.5748e+00],
        [ 1.9030e+00,  1.5052e+00,  6.5915e-01,  9.7535e-01,  1.4001e+00,
          1.8338e+00,  1.7069e+00,  1.9390e+00,  1.9390e+00,  1.7380e+00,
          1.3730e+00,  1.5861e+00,  9.9062e-01,  1.7918e+00,  1.7820e-01,
          1.6764e+00,  1.9635e+00,  8.9535e-01,  1.4073e+00,  1.0747e+00,
          8.2043e-01,  1.2161e+00,  1.7757e+00,  1.8418e+00,  1.6166e+00,
          1.9476e+00,  1.9476e+00,  9.1735e-01,  9.0615e-01,  1.9210e+00,
          1.7082e+00,  9.2036e-01,  1.8618e+00,  1.3161e+00,  1.9696e+00,
          1.8854e+00, -1.5720e-01, -3.9659e-01, -4.3998e-01, -2.0832e-01,
          4.5780e-02,  1.2877e-01, -2.8153e-01,  1.8917e+01,  2.6263e+00,
          2.7500e-01,  6.3703e-01,  6.5914e-01,  7.7234e-01,  4.2711e-01,
          7.7366e-01, -1.2144e-02,  8.0954e-01,  8.6913e-01],
        [ 1.3330e+00,  1.3699e+00,  1.3994e+00,  1.4017e+00,  1.3767e+00,
          1.3400e+00,  1.3103e+00,  1.3293e+00,  1.3293e+00,  1.3067e+00,
          1.4264e+00,  1.3224e+00,  1.4529e+00,  1.3820e+00,  1.4779e+00,
          1.3132e+00,  1.3571e+00,  1.3682e+00,  1.3900e+00,  1.3549e+00,
          1.4221e+00,  1.4035e+00,  1.3571e+00,  1.3502e+00,  1.2381e+00,
          1.3388e+00,  1.3388e+00,  1.3784e+00,  1.4363e+00,  1.3546e+00,
          1.1452e+00,  1.3359e+00,  1.2433e+00,  1.4112e+00,  1.2321e+00,
          1.3587e+00,  3.3855e-01,  2.6225e-01,  3.7578e-01,  3.4327e-01,
          1.3739e-01,  8.7846e-02,  3.6207e-01,  1.3202e-01, -7.0340e-02,
          3.5703e+00,  2.3159e+00,  3.5262e+00,  2.6690e+00,  1.8475e+00,
          1.4415e+00,  2.8950e+00,  3.4111e+00,  1.4061e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 352 : 174.26259191990016
Test loss for epoch 352 : 174.61232658009726
Test Precision for epoch 352 : 0.26153846153846155
Test Recall for epoch 352 : 0.26153846153846155
Test F1 for epoch 352 : 0.26153846153846155


theta for epoch 353 : tensor([[ 2.6769e+00,  2.6958e+00,  2.7330e+00,  2.8523e+00,  2.8331e+00,
          2.6801e+00,  2.8202e+00,  2.6752e+00,  2.6752e+00,  1.3325e+00,
          1.3346e+00,  1.3336e+00,  1.3366e+00,  1.3314e+00,  1.3386e+00,
          1.3329e+00,  1.3297e+00,  1.2918e+00,  1.2865e+00,  1.2440e+00,
          1.2448e+00,  1.2875e+00,  1.2841e+00,  1.2836e+00,  1.2857e+00,
          1.2828e+00,  1.2828e+00,  1.2662e+00,  1.3108e+00,  1.3047e+00,
          1.3078e+00,  1.3108e+00,  1.3061e+00,  1.3089e+00,  1.2607e+00,
          1.3050e+00,  1.7385e+00,  1.7493e+00,  1.7430e+00,  1.7394e+00,
          1.7473e+00,  1.6868e+00,  1.7400e+00,  1.7248e+00,  1.7387e+00,
          1.5924e+00,  1.5761e+00,  1.5727e+00,  1.5665e+00,  1.5891e+00,
          1.5713e+00,  1.6033e+00,  1.5626e+00,  1.5648e+00],
        [ 1.2854e+00,  1.2883e+00,  1.2873e+00,  1.2865e+00,  1.2889e+00,
          1.2860e+00,  1.2871e+00,  1.2852e+00,  1.2852e+00,  2.6184e+00,
          2.6332e+00,  2.6125e+00,  2.8436e+00,  2.5988e+00,  2.9938e+00,
          2.6210e+00,  2.8090e+00,  2.9675e+00,  1.2784e+00,  1.2835e+00,
          1.2365e+00,  1.2794e+00,  1.3059e+00,  1.3054e+00,  1.3069e+00,
          1.3045e+00,  1.3045e+00,  1.3055e+00,  1.2576e+00,  1.3261e+00,
          1.3294e+00,  1.3012e+00,  1.3276e+00,  1.3306e+00,  1.3002e+00,
          1.3264e+00,  1.7504e+00,  1.7622e+00,  1.7184e+00,  1.7505e+00,
          1.7600e+00,  1.7616e+00,  1.7150e+00,  1.7283e+00,  1.7498e+00,
          1.5525e+00,  1.5902e+00,  1.5865e+00,  1.5797e+00,  1.5128e+00,
          1.5850e+00,  1.5283e+00,  1.5755e+00,  1.5779e+00],
        [ 1.2698e+00,  1.2725e+00,  1.2709e+00,  1.2743e+00,  1.2724e+00,
          1.2703e+00,  1.2707e+00,  1.2695e+00,  1.2695e+00,  1.3382e+00,
          1.3404e+00,  1.3394e+00,  1.3424e+00,  1.3372e+00,  1.2843e+00,
          1.3387e+00,  1.2753e+00,  1.3266e+00,  2.7255e+00,  2.8448e+00,
          2.8887e+00,  2.7344e+00,  2.6642e+00,  2.6610e+00,  2.8208e+00,
          2.6560e+00,  2.6560e+00,  1.2670e+00,  1.3014e+00,  1.3106e+00,
          1.3137e+00,  1.2677e+00,  1.3120e+00,  1.3149e+00,  1.3106e+00,
          1.3109e+00,  1.7427e+00,  1.7537e+00,  1.7473e+00,  1.6758e+00,
          1.7516e+00,  1.7454e+00,  1.7442e+00,  1.7287e+00,  1.6751e+00,
          1.5972e+00,  1.5806e+00,  1.5772e+00,  1.5709e+00,  1.5748e+00,
          1.5758e+00,  1.5893e+00,  1.5608e+00,  1.5692e+00],
        [ 1.2763e+00,  1.2791e+00,  1.2775e+00,  1.2810e+00,  1.2791e+00,
          1.2769e+00,  1.2773e+00,  1.2761e+00,  1.2761e+00,  1.3447e+00,
          1.3469e+00,  1.3459e+00,  1.3292e+00,  1.3436e+00,  1.2850e+00,
          1.3452e+00,  1.3412e+00,  1.2835e+00,  1.2991e+00,  1.2755e+00,
          1.3004e+00,  1.3001e+00,  1.2966e+00,  1.2961e+00,  1.2927e+00,
          1.2952e+00,  1.2952e+00,  2.8966e+00,  2.8180e+00,  2.6360e+00,
          2.6623e+00,  2.8956e+00,  2.6446e+00,  2.7982e+00,  2.6952e+00,
          2.6378e+00,  1.7459e+00,  1.7572e+00,  1.7236e+00,  1.7392e+00,
          1.7551e+00,  1.7489e+00,  1.7203e+00,  1.7288e+00,  1.7385e+00,
          1.6019e+00,  1.5848e+00,  1.5254e+00,  1.5211e+00,  1.5984e+00,
          1.5799e+00,  1.6132e+00,  1.5111e+00,  1.5730e+00],
        [ 1.9015e+00,  1.5034e+00,  6.5729e-01,  9.7343e-01,  1.3983e+00,
          1.8322e+00,  1.7052e+00,  1.9375e+00,  1.9375e+00,  1.7357e+00,
          1.3707e+00,  1.5840e+00,  9.8842e-01,  1.7897e+00,  1.7594e-01,
          1.6741e+00,  1.9614e+00,  8.9291e-01,  1.4060e+00,  1.0736e+00,
          8.1889e-01,  1.2147e+00,  1.7748e+00,  1.8409e+00,  1.6159e+00,
          1.9469e+00,  1.9469e+00,  9.1554e-01,  9.0410e-01,  1.9192e+00,
          1.7063e+00,  9.1842e-01,  1.8600e+00,  1.3141e+00,  1.9679e+00,
          1.8837e+00, -1.5552e-01, -3.9490e-01, -4.3830e-01, -2.0679e-01,
          4.7397e-02,  1.3020e-01, -2.7985e-01,  1.8957e+01,  2.6085e+00,
          2.7283e-01,  6.3487e-01,  6.5693e-01,  7.7014e-01,  4.2493e-01,
          7.7145e-01, -1.4319e-02,  8.0744e-01,  8.6692e-01],
        [ 1.3351e+00,  1.3720e+00,  1.4013e+00,  1.4037e+00,  1.3788e+00,
          1.3422e+00,  1.3124e+00,  1.3314e+00,  1.3314e+00,  1.3089e+00,
          1.4285e+00,  1.3246e+00,  1.4550e+00,  1.3842e+00,  1.4800e+00,
          1.3153e+00,  1.3592e+00,  1.3704e+00,  1.3931e+00,  1.3578e+00,
          1.4252e+00,  1.4066e+00,  1.3602e+00,  1.3533e+00,  1.2410e+00,
          1.3419e+00,  1.3419e+00,  1.3804e+00,  1.4385e+00,  1.3568e+00,
          1.1475e+00,  1.3380e+00,  1.2455e+00,  1.4134e+00,  1.2344e+00,
          1.3610e+00,  3.4109e-01,  2.6475e-01,  3.7829e-01,  3.4575e-01,
          1.3992e-01,  9.0313e-02,  3.6459e-01,  1.3457e-01, -6.7646e-02,
          3.5703e+00,  2.3137e+00,  3.5260e+00,  2.6671e+00,  1.8452e+00,
          1.4392e+00,  2.8931e+00,  3.4117e+00,  1.4037e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 353 : 174.25248352992577
Test loss for epoch 353 : 174.60930833623502
Test Precision for epoch 353 : 0.26153846153846155
Test Recall for epoch 353 : 0.26153846153846155
Test F1 for epoch 353 : 0.26153846153846155


theta for epoch 354 : tensor([[ 2.6784e+00,  2.6973e+00,  2.7345e+00,  2.8540e+00,  2.8348e+00,
          2.6816e+00,  2.8219e+00,  2.6768e+00,  2.6768e+00,  1.3327e+00,
          1.3348e+00,  1.3338e+00,  1.3368e+00,  1.3316e+00,  1.3388e+00,
          1.3331e+00,  1.3299e+00,  1.2920e+00,  1.2845e+00,  1.2420e+00,
          1.2428e+00,  1.2855e+00,  1.2821e+00,  1.2816e+00,  1.2837e+00,
          1.2808e+00,  1.2808e+00,  1.2661e+00,  1.3107e+00,  1.3047e+00,
          1.3078e+00,  1.3108e+00,  1.3061e+00,  1.3089e+00,  1.2607e+00,
          1.3050e+00,  1.7381e+00,  1.7488e+00,  1.7426e+00,  1.7390e+00,
          1.7469e+00,  1.6864e+00,  1.7395e+00,  1.7244e+00,  1.7384e+00,
          1.5935e+00,  1.5771e+00,  1.5738e+00,  1.5675e+00,  1.5901e+00,
          1.5724e+00,  1.6043e+00,  1.5636e+00,  1.5658e+00],
        [ 1.2851e+00,  1.2880e+00,  1.2870e+00,  1.2863e+00,  1.2885e+00,
          1.2857e+00,  1.2867e+00,  1.2848e+00,  1.2848e+00,  2.6206e+00,
          2.6354e+00,  2.6151e+00,  2.8465e+00,  2.6014e+00,  2.9961e+00,
          2.6232e+00,  2.8119e+00,  2.9699e+00,  1.2760e+00,  1.2811e+00,
          1.2341e+00,  1.2769e+00,  1.3035e+00,  1.3030e+00,  1.3045e+00,
          1.3021e+00,  1.3021e+00,  1.3052e+00,  1.2572e+00,  1.3257e+00,
          1.3291e+00,  1.3010e+00,  1.3272e+00,  1.3303e+00,  1.2999e+00,
          1.3260e+00,  1.7499e+00,  1.7616e+00,  1.7179e+00,  1.7500e+00,
          1.7595e+00,  1.7611e+00,  1.7145e+00,  1.7280e+00,  1.7493e+00,
          1.5534e+00,  1.5911e+00,  1.5874e+00,  1.5806e+00,  1.5137e+00,
          1.5859e+00,  1.5292e+00,  1.5764e+00,  1.5788e+00],
        [ 1.2698e+00,  1.2725e+00,  1.2708e+00,  1.2742e+00,  1.2724e+00,
          1.2703e+00,  1.2707e+00,  1.2695e+00,  1.2695e+00,  1.3387e+00,
          1.3409e+00,  1.3399e+00,  1.3429e+00,  1.3377e+00,  1.2847e+00,
          1.3392e+00,  1.2758e+00,  1.3271e+00,  2.7256e+00,  2.8454e+00,
          2.8891e+00,  2.7346e+00,  2.6643e+00,  2.6611e+00,  2.8214e+00,
          2.6562e+00,  2.6562e+00,  1.2670e+00,  1.3014e+00,  1.3107e+00,
          1.3138e+00,  1.2677e+00,  1.3121e+00,  1.3150e+00,  1.3106e+00,
          1.3110e+00,  1.7424e+00,  1.7533e+00,  1.7470e+00,  1.6753e+00,
          1.7513e+00,  1.7449e+00,  1.7438e+00,  1.7284e+00,  1.6747e+00,
          1.5984e+00,  1.5818e+00,  1.5784e+00,  1.5720e+00,  1.5760e+00,
          1.5770e+00,  1.5905e+00,  1.5619e+00,  1.5703e+00],
        [ 1.2762e+00,  1.2790e+00,  1.2774e+00,  1.2809e+00,  1.2790e+00,
          1.2768e+00,  1.2772e+00,  1.2760e+00,  1.2760e+00,  1.3450e+00,
          1.3472e+00,  1.3461e+00,  1.3295e+00,  1.3439e+00,  1.2853e+00,
          1.3455e+00,  1.3415e+00,  1.2838e+00,  1.2973e+00,  1.2736e+00,
          1.2986e+00,  1.2983e+00,  1.2948e+00,  1.2943e+00,  1.2908e+00,
          1.2935e+00,  1.2935e+00,  2.8984e+00,  2.8195e+00,  2.6375e+00,
          2.6636e+00,  2.8974e+00,  2.6460e+00,  2.7996e+00,  2.6967e+00,
          2.6392e+00,  1.7455e+00,  1.7567e+00,  1.7231e+00,  1.7387e+00,
          1.7547e+00,  1.7484e+00,  1.7199e+00,  1.7284e+00,  1.7380e+00,
          1.6029e+00,  1.5858e+00,  1.5265e+00,  1.5221e+00,  1.5994e+00,
          1.5809e+00,  1.6143e+00,  1.5120e+00,  1.5740e+00],
        [ 1.9028e+00,  1.5050e+00,  6.5922e-01,  9.7511e-01,  1.3999e+00,
          1.8336e+00,  1.7066e+00,  1.9388e+00,  1.9388e+00,  1.7375e+00,
          1.3726e+00,  1.5858e+00,  9.9038e-01,  1.7914e+00,  1.7796e-01,
          1.6759e+00,  1.9631e+00,  8.9494e-01,  1.4073e+00,  1.0751e+00,
          8.2047e-01,  1.2161e+00,  1.7758e+00,  1.8418e+00,  1.6172e+00,
          1.9477e+00,  1.9477e+00,  9.1753e-01,  9.0599e-01,  1.9208e+00,
          1.7080e+00,  9.2042e-01,  1.8616e+00,  1.3159e+00,  1.9694e+00,
          1.8852e+00, -1.5731e-01, -3.9660e-01, -4.3998e-01, -2.0870e-01,
          4.5518e-02,  1.2813e-01, -2.8158e-01,  1.8993e+01,  2.5871e+00,
          2.7499e-01,  6.3700e-01,  6.5905e-01,  7.7225e-01,  4.2709e-01,
          7.7357e-01, -1.2164e-02,  8.0963e-01,  8.6902e-01],
        [ 1.3338e+00,  1.3706e+00,  1.3997e+00,  1.4024e+00,  1.3774e+00,
          1.3408e+00,  1.3111e+00,  1.3300e+00,  1.3300e+00,  1.3076e+00,
          1.4272e+00,  1.3233e+00,  1.4537e+00,  1.3829e+00,  1.4787e+00,
          1.3141e+00,  1.3579e+00,  1.3691e+00,  1.3912e+00,  1.3556e+00,
          1.4232e+00,  1.4047e+00,  1.3583e+00,  1.3514e+00,  1.2389e+00,
          1.3400e+00,  1.3400e+00,  1.3788e+00,  1.4372e+00,  1.3555e+00,
          1.1461e+00,  1.3364e+00,  1.2442e+00,  1.4121e+00,  1.2330e+00,
          1.3596e+00,  3.3957e-01,  2.6316e-01,  3.7673e-01,  3.4417e-01,
          1.3835e-01,  8.8674e-02,  3.6306e-01,  1.3301e-01, -6.9075e-02,
          3.5746e+00,  2.3159e+00,  3.5300e+00,  2.6696e+00,  1.8471e+00,
          1.4411e+00,  2.8955e+00,  3.4167e+00,  1.4057e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 354 : 174.2424627230788
Test loss for epoch 354 : 174.59932681075713
Test Precision for epoch 354 : 0.26153846153846155
Test Recall for epoch 354 : 0.26153846153846155
Test F1 for epoch 354 : 0.26153846153846155


theta for epoch 355 : tensor([[ 2.6796e+00,  2.6985e+00,  2.7357e+00,  2.8554e+00,  2.8362e+00,
          2.6828e+00,  2.8232e+00,  2.6780e+00,  2.6780e+00,  1.3322e+00,
          1.3343e+00,  1.3333e+00,  1.3363e+00,  1.3312e+00,  1.3383e+00,
          1.3327e+00,  1.3295e+00,  1.2915e+00,  1.2848e+00,  1.2423e+00,
          1.2431e+00,  1.2858e+00,  1.2824e+00,  1.2819e+00,  1.2840e+00,
          1.2811e+00,  1.2811e+00,  1.2659e+00,  1.3106e+00,  1.3045e+00,
          1.3076e+00,  1.3106e+00,  1.3059e+00,  1.3087e+00,  1.2605e+00,
          1.3048e+00,  1.7380e+00,  1.7487e+00,  1.7425e+00,  1.7389e+00,
          1.7467e+00,  1.6862e+00,  1.7394e+00,  1.7242e+00,  1.7383e+00,
          1.5938e+00,  1.5774e+00,  1.5740e+00,  1.5678e+00,  1.5904e+00,
          1.5726e+00,  1.6046e+00,  1.5638e+00,  1.5661e+00],
        [ 1.2849e+00,  1.2877e+00,  1.2869e+00,  1.2862e+00,  1.2883e+00,
          1.2854e+00,  1.2865e+00,  1.2846e+00,  1.2846e+00,  2.6218e+00,
          2.6366e+00,  2.6165e+00,  2.8483e+00,  2.6028e+00,  2.9976e+00,
          2.6244e+00,  2.8138e+00,  2.9714e+00,  1.2761e+00,  1.2811e+00,
          1.2342e+00,  1.2770e+00,  1.3036e+00,  1.3031e+00,  1.3046e+00,
          1.3022e+00,  1.3022e+00,  1.3048e+00,  1.2568e+00,  1.3254e+00,
          1.3287e+00,  1.3008e+00,  1.3269e+00,  1.3299e+00,  1.2995e+00,
          1.3257e+00,  1.7497e+00,  1.7614e+00,  1.7176e+00,  1.7498e+00,
          1.7592e+00,  1.7609e+00,  1.7143e+00,  1.7280e+00,  1.7492e+00,
          1.5536e+00,  1.5912e+00,  1.5875e+00,  1.5807e+00,  1.5138e+00,
          1.5860e+00,  1.5294e+00,  1.5765e+00,  1.5789e+00],
        [ 1.2695e+00,  1.2722e+00,  1.2705e+00,  1.2740e+00,  1.2721e+00,
          1.2700e+00,  1.2704e+00,  1.2693e+00,  1.2693e+00,  1.3380e+00,
          1.3401e+00,  1.3391e+00,  1.3421e+00,  1.3369e+00,  1.2840e+00,
          1.3384e+00,  1.2750e+00,  1.3263e+00,  2.7276e+00,  2.8477e+00,
          2.8913e+00,  2.7365e+00,  2.6663e+00,  2.6631e+00,  2.8237e+00,
          2.6581e+00,  2.6581e+00,  1.2666e+00,  1.3011e+00,  1.3103e+00,
          1.3134e+00,  1.2672e+00,  1.3117e+00,  1.3146e+00,  1.3102e+00,
          1.3106e+00,  1.7421e+00,  1.7531e+00,  1.7467e+00,  1.6750e+00,
          1.7510e+00,  1.7446e+00,  1.7436e+00,  1.7281e+00,  1.6743e+00,
          1.5985e+00,  1.5819e+00,  1.5784e+00,  1.5721e+00,  1.5761e+00,
          1.5770e+00,  1.5906e+00,  1.5618e+00,  1.5704e+00],
        [ 1.2761e+00,  1.2788e+00,  1.2771e+00,  1.2807e+00,  1.2788e+00,
          1.2766e+00,  1.2771e+00,  1.2758e+00,  1.2758e+00,  1.3444e+00,
          1.3466e+00,  1.3455e+00,  1.3289e+00,  1.3433e+00,  1.2848e+00,
          1.3448e+00,  1.3409e+00,  1.2833e+00,  1.2974e+00,  1.2737e+00,
          1.2987e+00,  1.2984e+00,  1.2949e+00,  1.2944e+00,  1.2909e+00,
          1.2936e+00,  1.2936e+00,  2.9001e+00,  2.8208e+00,  2.6388e+00,
          2.6648e+00,  2.8990e+00,  2.6474e+00,  2.8009e+00,  2.6981e+00,
          2.6405e+00,  1.7453e+00,  1.7565e+00,  1.7229e+00,  1.7384e+00,
          1.7545e+00,  1.7481e+00,  1.7197e+00,  1.7283e+00,  1.7377e+00,
          1.6031e+00,  1.5860e+00,  1.5267e+00,  1.5222e+00,  1.5996e+00,
          1.5810e+00,  1.6145e+00,  1.5120e+00,  1.5741e+00],
        [ 1.9029e+00,  1.5052e+00,  6.5960e-01,  9.7531e-01,  1.4001e+00,
          1.8337e+00,  1.7068e+00,  1.9389e+00,  1.9389e+00,  1.7375e+00,
          1.3727e+00,  1.5859e+00,  9.9058e-01,  1.7915e+00,  1.7820e-01,
          1.6759e+00,  1.9631e+00,  8.9508e-01,  1.4077e+00,  1.0757e+00,
          8.2086e-01,  1.2165e+00,  1.7761e+00,  1.8422e+00,  1.6178e+00,
          1.9481e+00,  1.9481e+00,  9.1791e-01,  9.0621e-01,  1.9209e+00,
          1.7081e+00,  9.2075e-01,  1.8617e+00,  1.3161e+00,  1.9695e+00,
          1.8853e+00, -1.5773e-01, -3.9697e-01, -4.4034e-01, -2.0925e-01,
          4.5030e-02,  1.2745e-01, -2.8197e-01,  1.9031e+01,  2.5674e+00,
          2.7543e-01,  6.3740e-01,  6.5941e-01,  7.7261e-01,  4.2752e-01,
          7.7394e-01, -1.1720e-02,  8.1008e-01,  8.6937e-01],
        [ 1.3339e+00,  1.3707e+00,  1.3996e+00,  1.4025e+00,  1.3775e+00,
          1.3409e+00,  1.3112e+00,  1.3302e+00,  1.3302e+00,  1.3077e+00,
          1.4273e+00,  1.3234e+00,  1.4537e+00,  1.3830e+00,  1.4788e+00,
          1.3141e+00,  1.3580e+00,  1.3691e+00,  1.3915e+00,  1.3557e+00,
          1.4235e+00,  1.4050e+00,  1.3586e+00,  1.3517e+00,  1.2390e+00,
          1.3403e+00,  1.3403e+00,  1.3787e+00,  1.4373e+00,  1.3556e+00,
          1.1462e+00,  1.3363e+00,  1.2443e+00,  1.4122e+00,  1.2331e+00,
          1.3597e+00,  3.3971e-01,  2.6325e-01,  3.7684e-01,  3.4425e-01,
          1.3847e-01,  8.8732e-02,  3.6319e-01,  1.3314e-01, -6.8786e-02,
          3.5771e+00,  2.3163e+00,  3.5324e+00,  2.6704e+00,  1.8474e+00,
          1.4414e+00,  2.8962e+00,  3.4199e+00,  1.4059e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 355 : 174.2347442318873
Test loss for epoch 355 : 174.59453929041354
Test Precision for epoch 355 : 0.26153846153846155
Test Recall for epoch 355 : 0.26153846153846155
Test F1 for epoch 355 : 0.26153846153846155


theta for epoch 356 : tensor([[ 2.6808e+00,  2.6997e+00,  2.7369e+00,  2.8567e+00,  2.8375e+00,
          2.6840e+00,  2.8246e+00,  2.6791e+00,  2.6791e+00,  1.3320e+00,
          1.3342e+00,  1.3331e+00,  1.3361e+00,  1.3310e+00,  1.3381e+00,
          1.3325e+00,  1.3293e+00,  1.2913e+00,  1.2856e+00,  1.2431e+00,
          1.2439e+00,  1.2865e+00,  1.2832e+00,  1.2827e+00,  1.2848e+00,
          1.2819e+00,  1.2819e+00,  1.2658e+00,  1.3105e+00,  1.3044e+00,
          1.3075e+00,  1.3105e+00,  1.3058e+00,  1.3086e+00,  1.2604e+00,
          1.3047e+00,  1.7381e+00,  1.7488e+00,  1.7426e+00,  1.7390e+00,
          1.7469e+00,  1.6864e+00,  1.7395e+00,  1.7244e+00,  1.7384e+00,
          1.5929e+00,  1.5765e+00,  1.5731e+00,  1.5668e+00,  1.5895e+00,
          1.5717e+00,  1.6038e+00,  1.5629e+00,  1.5651e+00],
        [ 1.2849e+00,  1.2878e+00,  1.2871e+00,  1.2863e+00,  1.2884e+00,
          1.2855e+00,  1.2865e+00,  1.2847e+00,  1.2847e+00,  2.6224e+00,
          2.6372e+00,  2.6175e+00,  2.8496e+00,  2.6038e+00,  2.9986e+00,
          2.6250e+00,  2.8151e+00,  2.9725e+00,  1.2769e+00,  1.2820e+00,
          1.2350e+00,  1.2778e+00,  1.3044e+00,  1.3039e+00,  1.3055e+00,
          1.3031e+00,  1.3031e+00,  1.3047e+00,  1.2567e+00,  1.3253e+00,
          1.3286e+00,  1.3008e+00,  1.3268e+00,  1.3298e+00,  1.2994e+00,
          1.3256e+00,  1.7498e+00,  1.7615e+00,  1.7177e+00,  1.7499e+00,
          1.7594e+00,  1.7610e+00,  1.7144e+00,  1.7283e+00,  1.7493e+00,
          1.5527e+00,  1.5903e+00,  1.5866e+00,  1.5797e+00,  1.5129e+00,
          1.5851e+00,  1.5285e+00,  1.5755e+00,  1.5779e+00],
        [ 1.2695e+00,  1.2722e+00,  1.2704e+00,  1.2739e+00,  1.2721e+00,
          1.2700e+00,  1.2704e+00,  1.2692e+00,  1.2692e+00,  1.3377e+00,
          1.3398e+00,  1.3388e+00,  1.3418e+00,  1.3366e+00,  1.2837e+00,
          1.3381e+00,  1.2747e+00,  1.3260e+00,  2.7293e+00,  2.8498e+00,
          2.8932e+00,  2.7382e+00,  2.6679e+00,  2.6647e+00,  2.8258e+00,
          2.6597e+00,  2.6597e+00,  1.2663e+00,  1.3009e+00,  1.3101e+00,
          1.3132e+00,  1.2670e+00,  1.3115e+00,  1.3144e+00,  1.3100e+00,
          1.3104e+00,  1.7422e+00,  1.7531e+00,  1.7468e+00,  1.6749e+00,
          1.7511e+00,  1.7446e+00,  1.7437e+00,  1.7282e+00,  1.6743e+00,
          1.5975e+00,  1.5809e+00,  1.5774e+00,  1.5711e+00,  1.5751e+00,
          1.5760e+00,  1.5896e+00,  1.5607e+00,  1.5693e+00],
        [ 1.2760e+00,  1.2788e+00,  1.2770e+00,  1.2806e+00,  1.2787e+00,
          1.2765e+00,  1.2770e+00,  1.2757e+00,  1.2757e+00,  1.3440e+00,
          1.3462e+00,  1.3452e+00,  1.3285e+00,  1.3429e+00,  1.2844e+00,
          1.3445e+00,  1.3405e+00,  1.2829e+00,  1.2980e+00,  1.2742e+00,
          1.2993e+00,  1.2990e+00,  1.2955e+00,  1.2950e+00,  1.2914e+00,
          1.2941e+00,  1.2941e+00,  2.9017e+00,  2.8222e+00,  2.6402e+00,
          2.6660e+00,  2.9007e+00,  2.6487e+00,  2.8023e+00,  2.6996e+00,
          2.6419e+00,  1.7453e+00,  1.7566e+00,  1.7229e+00,  1.7384e+00,
          1.7545e+00,  1.7481e+00,  1.7197e+00,  1.7284e+00,  1.7377e+00,
          1.6021e+00,  1.5849e+00,  1.5257e+00,  1.5212e+00,  1.5986e+00,
          1.5800e+00,  1.6135e+00,  1.5109e+00,  1.5731e+00],
        [ 1.9025e+00,  1.5046e+00,  6.5911e-01,  9.7470e-01,  1.3996e+00,
          1.8333e+00,  1.7063e+00,  1.9385e+00,  1.9385e+00,  1.7367e+00,
          1.3719e+00,  1.5852e+00,  9.8989e-01,  1.7908e+00,  1.7750e-01,
          1.6751e+00,  1.9625e+00,  8.9425e-01,  1.4073e+00,  1.0754e+00,
          8.2037e-01,  1.2160e+00,  1.7758e+00,  1.8419e+00,  1.6177e+00,
          1.9478e+00,  1.9478e+00,  9.1739e-01,  9.0550e-01,  1.9202e+00,
          1.7074e+00,  9.2015e-01,  1.8610e+00,  1.3154e+00,  1.9689e+00,
          1.8847e+00, -1.5732e-01, -3.9653e-01, -4.3990e-01, -2.0897e-01,
          4.5384e-02,  1.2762e-01, -2.8154e-01,  1.9070e+01,  2.5487e+00,
          2.7472e-01,  6.3663e-01,  6.5860e-01,  7.7179e-01,  4.2679e-01,
          7.7312e-01, -1.2382e-02,  8.0934e-01,  8.6852e-01],
        [ 1.3348e+00,  1.3716e+00,  1.4003e+00,  1.4034e+00,  1.3784e+00,
          1.3418e+00,  1.3121e+00,  1.3311e+00,  1.3311e+00,  1.3086e+00,
          1.4282e+00,  1.3243e+00,  1.4547e+00,  1.3839e+00,  1.4797e+00,
          1.3151e+00,  1.3590e+00,  1.3701e+00,  1.3927e+00,  1.3567e+00,
          1.4248e+00,  1.4062e+00,  1.3598e+00,  1.3530e+00,  1.2400e+00,
          1.3415e+00,  1.3415e+00,  1.3793e+00,  1.4381e+00,  1.3565e+00,
          1.1471e+00,  1.3369e+00,  1.2452e+00,  1.4130e+00,  1.2340e+00,
          1.3606e+00,  3.4074e-01,  2.6424e-01,  3.7784e-01,  3.4523e-01,
          1.3949e-01,  8.9689e-02,  3.6421e-01,  1.3418e-01, -6.7588e-02,
          3.5786e+00,  2.3158e+00,  3.5337e+00,  2.6701e+00,  1.8467e+00,
          1.4406e+00,  2.8960e+00,  3.4222e+00,  1.4052e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 356 : 174.22890675409855
Test loss for epoch 356 : 174.59324123410198
Test Precision for epoch 356 : 0.26153846153846155
Test Recall for epoch 356 : 0.26153846153846155
Test F1 for epoch 356 : 0.26153846153846155


theta for epoch 357 : tensor([[ 2.6821e+00,  2.7010e+00,  2.7382e+00,  2.8582e+00,  2.8390e+00,
          2.6854e+00,  2.8261e+00,  2.6805e+00,  2.6805e+00,  1.3326e+00,
          1.3347e+00,  1.3337e+00,  1.3367e+00,  1.3316e+00,  1.3387e+00,
          1.3330e+00,  1.3299e+00,  1.2919e+00,  1.2839e+00,  1.2414e+00,
          1.2422e+00,  1.2849e+00,  1.2816e+00,  1.2811e+00,  1.2832e+00,
          1.2803e+00,  1.2803e+00,  1.2657e+00,  1.3104e+00,  1.3043e+00,
          1.3074e+00,  1.3104e+00,  1.3057e+00,  1.3085e+00,  1.2603e+00,
          1.3046e+00,  1.7378e+00,  1.7485e+00,  1.7423e+00,  1.7387e+00,
          1.7466e+00,  1.6860e+00,  1.7392e+00,  1.7241e+00,  1.7382e+00,
          1.5934e+00,  1.5770e+00,  1.5736e+00,  1.5673e+00,  1.5900e+00,
          1.5722e+00,  1.6043e+00,  1.5634e+00,  1.5656e+00],
        [ 1.2849e+00,  1.2878e+00,  1.2872e+00,  1.2864e+00,  1.2883e+00,
          1.2854e+00,  1.2865e+00,  1.2846e+00,  1.2846e+00,  2.6239e+00,
          2.6387e+00,  2.6193e+00,  2.8516e+00,  2.6055e+00,  3.0004e+00,
          2.6265e+00,  2.8173e+00,  2.9742e+00,  1.2752e+00,  1.2803e+00,
          1.2333e+00,  1.2761e+00,  1.3027e+00,  1.3022e+00,  1.3037e+00,
          1.3013e+00,  1.3013e+00,  1.3046e+00,  1.2566e+00,  1.3252e+00,
          1.3285e+00,  1.3008e+00,  1.3267e+00,  1.3297e+00,  1.2993e+00,
          1.3255e+00,  1.7494e+00,  1.7611e+00,  1.7174e+00,  1.7496e+00,
          1.7590e+00,  1.7606e+00,  1.7140e+00,  1.7281e+00,  1.7490e+00,
          1.5532e+00,  1.5908e+00,  1.5871e+00,  1.5803e+00,  1.5134e+00,
          1.5856e+00,  1.5290e+00,  1.5760e+00,  1.5784e+00],
        [ 1.2697e+00,  1.2724e+00,  1.2706e+00,  1.2742e+00,  1.2723e+00,
          1.2703e+00,  1.2706e+00,  1.2695e+00,  1.2695e+00,  1.3388e+00,
          1.3409e+00,  1.3399e+00,  1.3429e+00,  1.3377e+00,  1.2847e+00,
          1.3392e+00,  1.2758e+00,  1.3271e+00,  2.7289e+00,  2.8498e+00,
          2.8930e+00,  2.7378e+00,  2.6674e+00,  2.6642e+00,  2.8257e+00,
          2.6592e+00,  2.6592e+00,  1.2664e+00,  1.3011e+00,  1.3103e+00,
          1.3134e+00,  1.2671e+00,  1.3117e+00,  1.3146e+00,  1.3103e+00,
          1.3106e+00,  1.7420e+00,  1.7529e+00,  1.7466e+00,  1.6746e+00,
          1.7509e+00,  1.7443e+00,  1.7434e+00,  1.7280e+00,  1.6741e+00,
          1.5983e+00,  1.5816e+00,  1.5782e+00,  1.5718e+00,  1.5759e+00,
          1.5768e+00,  1.5905e+00,  1.5614e+00,  1.5701e+00],
        [ 1.2759e+00,  1.2787e+00,  1.2769e+00,  1.2806e+00,  1.2787e+00,
          1.2765e+00,  1.2769e+00,  1.2756e+00,  1.2756e+00,  1.3445e+00,
          1.3468e+00,  1.3457e+00,  1.3291e+00,  1.3435e+00,  1.2850e+00,
          1.3450e+00,  1.3411e+00,  1.2835e+00,  1.2963e+00,  1.2725e+00,
          1.2977e+00,  1.2974e+00,  1.2939e+00,  1.2934e+00,  1.2897e+00,
          1.2925e+00,  1.2925e+00,  2.9035e+00,  2.8236e+00,  2.6416e+00,
          2.6673e+00,  2.9025e+00,  2.6501e+00,  2.8037e+00,  2.7011e+00,
          2.6433e+00,  1.7449e+00,  1.7562e+00,  1.7225e+00,  1.7379e+00,
          1.7541e+00,  1.7476e+00,  1.7193e+00,  1.7281e+00,  1.7373e+00,
          1.6026e+00,  1.5854e+00,  1.5262e+00,  1.5216e+00,  1.5990e+00,
          1.5804e+00,  1.6140e+00,  1.5113e+00,  1.5735e+00],
        [ 1.9041e+00,  1.5066e+00,  6.6144e-01,  9.7676e-01,  1.4016e+00,
          1.8350e+00,  1.7081e+00,  1.9401e+00,  1.9401e+00,  1.7388e+00,
          1.3742e+00,  1.5874e+00,  9.9225e-01,  1.7930e+00,  1.7998e-01,
          1.6773e+00,  1.9645e+00,  8.9671e-01,  1.4089e+00,  1.0774e+00,
          8.2236e-01,  1.2178e+00,  1.7772e+00,  1.8432e+00,  1.6193e+00,
          1.9490e+00,  1.9490e+00,  9.1974e-01,  9.0776e-01,  1.9221e+00,
          1.7093e+00,  9.2251e-01,  1.8629e+00,  1.3175e+00,  1.9707e+00,
          1.8866e+00, -1.5948e-01, -3.9860e-01, -4.4195e-01, -2.1125e-01,
          4.3141e-02,  1.2519e-01, -2.8365e-01,  1.9106e+01,  2.5275e+00,
          2.7715e-01,  6.3894e-01,  6.6089e-01,  7.7405e-01,  4.2918e-01,
          7.7539e-01, -9.9027e-03,  8.1166e-01,  8.7076e-01],
        [ 1.3329e+00,  1.3697e+00,  1.3982e+00,  1.4015e+00,  1.3765e+00,
          1.3399e+00,  1.3101e+00,  1.3291e+00,  1.3291e+00,  1.3067e+00,
          1.4263e+00,  1.3224e+00,  1.4528e+00,  1.3820e+00,  1.4778e+00,
          1.3132e+00,  1.3571e+00,  1.3681e+00,  1.3902e+00,  1.3539e+00,
          1.4222e+00,  1.4037e+00,  1.3573e+00,  1.3504e+00,  1.2372e+00,
          1.3390e+00,  1.3390e+00,  1.3771e+00,  1.4361e+00,  1.3545e+00,
          1.1450e+00,  1.3347e+00,  1.2431e+00,  1.4111e+00,  1.2320e+00,
          1.3586e+00,  3.3859e-01,  2.6204e-01,  3.7566e-01,  3.4302e-01,
          1.3729e-01,  8.7429e-02,  3.6205e-01,  1.3198e-01, -6.9628e-02,
          3.5836e+00,  2.3186e+00,  3.5385e+00,  2.6733e+00,  1.8493e+00,
          1.4433e+00,  2.8991e+00,  3.4279e+00,  1.4078e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 357 : 174.22307957327746
Test loss for epoch 357 : 174.58670049937228
Test Precision for epoch 357 : 0.26153846153846155
Test Recall for epoch 357 : 0.26153846153846155
Test F1 for epoch 357 : 0.26153846153846155


theta for epoch 358 : tensor([[ 2.6834e+00,  2.7023e+00,  2.7395e+00,  2.8597e+00,  2.8405e+00,
          2.6867e+00,  2.8276e+00,  2.6818e+00,  2.6818e+00,  1.3317e+00,
          1.3338e+00,  1.3328e+00,  1.3357e+00,  1.3306e+00,  1.3378e+00,
          1.3321e+00,  1.3289e+00,  1.2909e+00,  1.2856e+00,  1.2431e+00,
          1.2439e+00,  1.2866e+00,  1.2832e+00,  1.2827e+00,  1.2848e+00,
          1.2819e+00,  1.2819e+00,  1.2654e+00,  1.3101e+00,  1.3040e+00,
          1.3071e+00,  1.3101e+00,  1.3054e+00,  1.3082e+00,  1.2600e+00,
          1.3043e+00,  1.7382e+00,  1.7489e+00,  1.7427e+00,  1.7391e+00,
          1.7469e+00,  1.6864e+00,  1.7396e+00,  1.7244e+00,  1.7386e+00,
          1.5919e+00,  1.5754e+00,  1.5721e+00,  1.5658e+00,  1.5885e+00,
          1.5707e+00,  1.6028e+00,  1.5618e+00,  1.5641e+00],
        [ 1.2848e+00,  1.2876e+00,  1.2872e+00,  1.2864e+00,  1.2882e+00,
          1.2853e+00,  1.2864e+00,  1.2845e+00,  1.2845e+00,  2.6240e+00,
          2.6389e+00,  2.6197e+00,  2.8524e+00,  2.6059e+00,  3.0010e+00,
          2.6267e+00,  2.8181e+00,  2.9748e+00,  1.2773e+00,  1.2825e+00,
          1.2354e+00,  1.2783e+00,  1.3048e+00,  1.3043e+00,  1.3059e+00,
          1.3034e+00,  1.3034e+00,  1.3045e+00,  1.2565e+00,  1.3251e+00,
          1.3284e+00,  1.3008e+00,  1.3266e+00,  1.3296e+00,  1.2992e+00,
          1.3254e+00,  1.7498e+00,  1.7616e+00,  1.7178e+00,  1.7500e+00,
          1.7594e+00,  1.7611e+00,  1.7144e+00,  1.7287e+00,  1.7495e+00,
          1.5519e+00,  1.5894e+00,  1.5857e+00,  1.5789e+00,  1.5121e+00,
          1.5842e+00,  1.5276e+00,  1.5746e+00,  1.5770e+00],
        [ 1.2692e+00,  1.2719e+00,  1.2699e+00,  1.2736e+00,  1.2718e+00,
          1.2697e+00,  1.2701e+00,  1.2689e+00,  1.2689e+00,  1.3374e+00,
          1.3396e+00,  1.3385e+00,  1.3415e+00,  1.3364e+00,  1.2834e+00,
          1.3379e+00,  1.2744e+00,  1.3258e+00,  2.7320e+00,  2.8533e+00,
          2.8963e+00,  2.7410e+00,  2.6706e+00,  2.6674e+00,  2.8293e+00,
          2.6624e+00,  2.6624e+00,  1.2658e+00,  1.3005e+00,  1.3098e+00,
          1.3129e+00,  1.2665e+00,  1.3112e+00,  1.3140e+00,  1.3097e+00,
          1.3101e+00,  1.7422e+00,  1.7532e+00,  1.7468e+00,  1.6748e+00,
          1.7512e+00,  1.7445e+00,  1.7437e+00,  1.7283e+00,  1.6743e+00,
          1.5966e+00,  1.5799e+00,  1.5765e+00,  1.5701e+00,  1.5743e+00,
          1.5751e+00,  1.5888e+00,  1.5596e+00,  1.5684e+00],
        [ 1.2757e+00,  1.2785e+00,  1.2766e+00,  1.2803e+00,  1.2784e+00,
          1.2762e+00,  1.2767e+00,  1.2754e+00,  1.2754e+00,  1.3437e+00,
          1.3459e+00,  1.3448e+00,  1.3282e+00,  1.3426e+00,  1.2842e+00,
          1.3442e+00,  1.3402e+00,  1.2827e+00,  1.2980e+00,  1.2741e+00,
          1.2993e+00,  1.2990e+00,  1.2956e+00,  1.2950e+00,  1.2913e+00,
          1.2942e+00,  1.2942e+00,  2.9049e+00,  2.8247e+00,  2.6427e+00,
          2.6683e+00,  2.9039e+00,  2.6512e+00,  2.8049e+00,  2.7023e+00,
          2.6444e+00,  1.7453e+00,  1.7566e+00,  1.7229e+00,  1.7382e+00,
          1.7546e+00,  1.7480e+00,  1.7197e+00,  1.7286e+00,  1.7377e+00,
          1.6012e+00,  1.5840e+00,  1.5248e+00,  1.5202e+00,  1.5977e+00,
          1.5790e+00,  1.6126e+00,  1.5098e+00,  1.5721e+00],
        [ 1.9028e+00,  1.5051e+00,  6.5992e-01,  9.7515e-01,  1.4001e+00,
          1.8336e+00,  1.7067e+00,  1.9388e+00,  1.9388e+00,  1.7369e+00,
          1.3722e+00,  1.5856e+00,  9.9042e-01,  1.7912e+00,  1.7815e-01,
          1.6754e+00,  1.9628e+00,  8.9465e-01,  1.4079e+00,  1.0764e+00,
          8.2106e-01,  1.2166e+00,  1.7764e+00,  1.8425e+00,  1.6187e+00,
          1.9484e+00,  1.9484e+00,  9.1821e-01,  9.0600e-01,  1.9206e+00,
          1.7077e+00,  9.2085e-01,  1.8613e+00,  1.3158e+00,  1.9692e+00,
          1.8850e+00, -1.5818e-01, -3.9729e-01, -4.4065e-01, -2.1009e-01,
          4.4404e-02,  1.2627e-01, -2.8234e-01,  1.9145e+01,  2.5102e+00,
          2.7533e-01,  6.3704e-01,  6.5892e-01,  7.7206e-01,  4.2732e-01,
          7.7342e-01, -1.1654e-02,  8.0977e-01,  8.6876e-01],
        [ 1.3348e+00,  1.3716e+00,  1.3998e+00,  1.4033e+00,  1.3784e+00,
          1.3418e+00,  1.3120e+00,  1.3310e+00,  1.3310e+00,  1.3087e+00,
          1.4283e+00,  1.3244e+00,  1.4547e+00,  1.3840e+00,  1.4798e+00,
          1.3152e+00,  1.3590e+00,  1.3701e+00,  1.3929e+00,  1.3565e+00,
          1.4250e+00,  1.4064e+00,  1.3600e+00,  1.3532e+00,  1.2398e+00,
          1.3418e+00,  1.3418e+00,  1.3788e+00,  1.4380e+00,  1.3565e+00,
          1.1471e+00,  1.3364e+00,  1.2451e+00,  1.4130e+00,  1.2340e+00,
          1.3606e+00,  3.4088e-01,  2.6429e-01,  3.7793e-01,  3.4526e-01,
          1.3959e-01,  8.9672e-02,  3.6433e-01,  1.3430e-01, -6.7123e-02,
          3.5839e+00,  2.3168e+00,  3.5386e+00,  2.6719e+00,  1.8474e+00,
          1.4413e+00,  2.8976e+00,  3.4289e+00,  1.4059e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 358 : 174.21581596710544
Test loss for epoch 358 : 174.58593508472734
Test Precision for epoch 358 : 0.26153846153846155
Test Recall for epoch 358 : 0.26153846153846155
Test F1 for epoch 358 : 0.26153846153846155


theta for epoch 359 : tensor([[ 2.6849e+00,  2.7038e+00,  2.7410e+00,  2.8614e+00,  2.8422e+00,
          2.6881e+00,  2.8293e+00,  2.6832e+00,  2.6832e+00,  1.3319e+00,
          1.3340e+00,  1.3330e+00,  1.3360e+00,  1.3309e+00,  1.3380e+00,
          1.3323e+00,  1.3292e+00,  1.2912e+00,  1.2832e+00,  1.2408e+00,
          1.2415e+00,  1.2842e+00,  1.2809e+00,  1.2804e+00,  1.2825e+00,
          1.2796e+00,  1.2796e+00,  1.2652e+00,  1.3099e+00,  1.3039e+00,
          1.3069e+00,  1.3099e+00,  1.3052e+00,  1.3081e+00,  1.2598e+00,
          1.3042e+00,  1.7377e+00,  1.7484e+00,  1.7422e+00,  1.7387e+00,
          1.7465e+00,  1.6860e+00,  1.7391e+00,  1.7240e+00,  1.7382e+00,
          1.5932e+00,  1.5767e+00,  1.5733e+00,  1.5671e+00,  1.5898e+00,
          1.5719e+00,  1.6041e+00,  1.5631e+00,  1.5654e+00],
        [ 1.2842e+00,  1.2871e+00,  1.2868e+00,  1.2860e+00,  1.2877e+00,
          1.2848e+00,  1.2859e+00,  1.2840e+00,  1.2840e+00,  2.6262e+00,
          2.6411e+00,  2.6221e+00,  2.8552e+00,  2.6084e+00,  3.0033e+00,
          2.6289e+00,  2.8209e+00,  2.9773e+00,  1.2746e+00,  1.2797e+00,
          1.2327e+00,  1.2755e+00,  1.3022e+00,  1.3017e+00,  1.3032e+00,
          1.3008e+00,  1.3008e+00,  1.3042e+00,  1.2562e+00,  1.3247e+00,
          1.3281e+00,  1.3006e+00,  1.3263e+00,  1.3293e+00,  1.2989e+00,
          1.3251e+00,  1.7493e+00,  1.7610e+00,  1.7173e+00,  1.7495e+00,
          1.7589e+00,  1.7606e+00,  1.7139e+00,  1.7284e+00,  1.7490e+00,
          1.5531e+00,  1.5907e+00,  1.5870e+00,  1.5801e+00,  1.5133e+00,
          1.5855e+00,  1.5289e+00,  1.5759e+00,  1.5783e+00],
        [ 1.2690e+00,  1.2717e+00,  1.2697e+00,  1.2734e+00,  1.2716e+00,
          1.2695e+00,  1.2699e+00,  1.2687e+00,  1.2687e+00,  1.3380e+00,
          1.3402e+00,  1.3392e+00,  1.3422e+00,  1.3370e+00,  1.2840e+00,
          1.3385e+00,  1.2751e+00,  1.3264e+00,  2.7320e+00,  2.8536e+00,
          2.8965e+00,  2.7409e+00,  2.6705e+00,  2.6673e+00,  2.8296e+00,
          2.6623e+00,  2.6623e+00,  1.2658e+00,  1.3006e+00,  1.3098e+00,
          1.3130e+00,  1.2665e+00,  1.3112e+00,  1.3141e+00,  1.3098e+00,
          1.3101e+00,  1.7419e+00,  1.7528e+00,  1.7464e+00,  1.6743e+00,
          1.7508e+00,  1.7441e+00,  1.7433e+00,  1.7279e+00,  1.6738e+00,
          1.5981e+00,  1.5814e+00,  1.5780e+00,  1.5716e+00,  1.5758e+00,
          1.5765e+00,  1.5903e+00,  1.5610e+00,  1.5699e+00],
        [ 1.2754e+00,  1.2781e+00,  1.2762e+00,  1.2800e+00,  1.2781e+00,
          1.2759e+00,  1.2764e+00,  1.2751e+00,  1.2751e+00,  1.3441e+00,
          1.3463e+00,  1.3453e+00,  1.3286e+00,  1.3430e+00,  1.2846e+00,
          1.3446e+00,  1.3406e+00,  1.2831e+00,  1.2959e+00,  1.2720e+00,
          1.2972e+00,  1.2970e+00,  1.2935e+00,  1.2930e+00,  1.2892e+00,
          1.2921e+00,  1.2921e+00,  2.9067e+00,  2.8262e+00,  2.6441e+00,
          2.6696e+00,  2.9057e+00,  2.6527e+00,  2.8063e+00,  2.7038e+00,
          2.6458e+00,  1.7449e+00,  1.7562e+00,  1.7225e+00,  1.7377e+00,
          1.7541e+00,  1.7475e+00,  1.7192e+00,  1.7282e+00,  1.7372e+00,
          1.6025e+00,  1.5853e+00,  1.5262e+00,  1.5215e+00,  1.5990e+00,
          1.5803e+00,  1.6139e+00,  1.5110e+00,  1.5734e+00],
        [ 1.9044e+00,  1.5070e+00,  6.6228e-01,  9.7722e-01,  1.4020e+00,
          1.8353e+00,  1.7085e+00,  1.9404e+00,  1.9404e+00,  1.7392e+00,
          1.3746e+00,  1.5879e+00,  9.9286e-01,  1.7934e+00,  1.8073e-01,
          1.6776e+00,  1.9649e+00,  8.9720e-01,  1.4095e+00,  1.0783e+00,
          8.2306e-01,  1.2184e+00,  1.7777e+00,  1.8437e+00,  1.6203e+00,
          1.9495e+00,  1.9495e+00,  9.2066e-01,  9.0836e-01,  1.9225e+00,
          1.7098e+00,  9.2333e-01,  1.8634e+00,  1.3180e+00,  1.9711e+00,
          1.8870e+00, -1.6046e-01, -3.9948e-01, -4.4282e-01, -2.1248e-01,
          4.2046e-02,  1.2373e-01, -2.8457e-01,  1.9181e+01,  2.4892e+00,
          2.7795e-01,  6.3953e-01,  6.6140e-01,  7.7452e-01,  4.2991e-01,
          7.7588e-01, -8.9681e-03,  8.1228e-01,  8.7118e-01],
        [ 1.3329e+00,  1.3697e+00,  1.3977e+00,  1.4015e+00,  1.3765e+00,
          1.3400e+00,  1.3102e+00,  1.3292e+00,  1.3292e+00,  1.3069e+00,
          1.4265e+00,  1.3226e+00,  1.4530e+00,  1.3822e+00,  1.4780e+00,
          1.3134e+00,  1.3573e+00,  1.3683e+00,  1.3904e+00,  1.3538e+00,
          1.4225e+00,  1.4039e+00,  1.3576e+00,  1.3507e+00,  1.2371e+00,
          1.3393e+00,  1.3393e+00,  1.3768e+00,  1.4363e+00,  1.3547e+00,
          1.1452e+00,  1.3344e+00,  1.2433e+00,  1.4112e+00,  1.2322e+00,
          1.3588e+00,  3.3887e-01,  2.6224e-01,  3.7589e-01,  3.4319e-01,
          1.3755e-01,  8.7567e-02,  3.6231e-01,  1.3224e-01, -6.8990e-02,
          3.5888e+00,  2.3196e+00,  3.5433e+00,  2.6750e+00,  1.8500e+00,
          1.4439e+00,  2.9007e+00,  3.4346e+00,  1.4085e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 359 : 174.20719319619994
Test loss for epoch 359 : 174.57649421837172
Test Precision for epoch 359 : 0.26153846153846155
Test Recall for epoch 359 : 0.26153846153846155
Test F1 for epoch 359 : 0.26153846153846155


theta for epoch 360 : tensor([[ 2.6863e+00,  2.7052e+00,  2.7424e+00,  2.8630e+00,  2.8438e+00,
          2.6895e+00,  2.8308e+00,  2.6846e+00,  2.6846e+00,  1.3311e+00,
          1.3332e+00,  1.3322e+00,  1.3352e+00,  1.3301e+00,  1.3372e+00,
          1.3315e+00,  1.3284e+00,  1.2903e+00,  1.2842e+00,  1.2417e+00,
          1.2425e+00,  1.2852e+00,  1.2819e+00,  1.2814e+00,  1.2835e+00,
          1.2806e+00,  1.2806e+00,  1.2650e+00,  1.3097e+00,  1.3037e+00,
          1.3067e+00,  1.3097e+00,  1.3050e+00,  1.3078e+00,  1.2596e+00,
          1.3039e+00,  1.7377e+00,  1.7485e+00,  1.7423e+00,  1.7387e+00,
          1.7466e+00,  1.6860e+00,  1.7392e+00,  1.7240e+00,  1.7382e+00,
          1.5923e+00,  1.5759e+00,  1.5725e+00,  1.5662e+00,  1.5890e+00,
          1.5711e+00,  1.6033e+00,  1.5622e+00,  1.5645e+00],
        [ 1.2841e+00,  1.2869e+00,  1.2867e+00,  1.2859e+00,  1.2875e+00,
          1.2846e+00,  1.2857e+00,  1.2838e+00,  1.2838e+00,  2.6269e+00,
          2.6418e+00,  2.6231e+00,  2.8565e+00,  2.6094e+00,  3.0045e+00,
          2.6296e+00,  2.8223e+00,  2.9784e+00,  1.2758e+00,  1.2809e+00,
          1.2338e+00,  1.2767e+00,  1.3033e+00,  1.3028e+00,  1.3044e+00,
          1.3019e+00,  1.3019e+00,  1.3040e+00,  1.2560e+00,  1.3246e+00,
          1.3279e+00,  1.3005e+00,  1.3261e+00,  1.3291e+00,  1.2987e+00,
          1.3249e+00,  1.7493e+00,  1.7611e+00,  1.7173e+00,  1.7496e+00,
          1.7590e+00,  1.7606e+00,  1.7139e+00,  1.7286e+00,  1.7491e+00,
          1.5523e+00,  1.5899e+00,  1.5862e+00,  1.5793e+00,  1.5125e+00,
          1.5846e+00,  1.5281e+00,  1.5750e+00,  1.5774e+00],
        [ 1.2687e+00,  1.2713e+00,  1.2693e+00,  1.2731e+00,  1.2712e+00,
          1.2692e+00,  1.2695e+00,  1.2684e+00,  1.2684e+00,  1.3370e+00,
          1.3391e+00,  1.3381e+00,  1.3411e+00,  1.3359e+00,  1.2830e+00,
          1.3374e+00,  1.2740e+00,  1.3254e+00,  2.7345e+00,  2.8565e+00,
          2.8993e+00,  2.7434e+00,  2.6729e+00,  2.6697e+00,  2.8325e+00,
          2.6648e+00,  2.6648e+00,  1.2654e+00,  1.3003e+00,  1.3095e+00,
          1.3126e+00,  1.2661e+00,  1.3109e+00,  1.3138e+00,  1.3095e+00,
          1.3098e+00,  1.7418e+00,  1.7528e+00,  1.7464e+00,  1.6742e+00,
          1.7508e+00,  1.7440e+00,  1.7433e+00,  1.7279e+00,  1.6737e+00,
          1.5972e+00,  1.5805e+00,  1.5770e+00,  1.5706e+00,  1.5748e+00,
          1.5756e+00,  1.5894e+00,  1.5599e+00,  1.5689e+00],
        [ 1.2752e+00,  1.2780e+00,  1.2760e+00,  1.2799e+00,  1.2779e+00,
          1.2757e+00,  1.2762e+00,  1.2749e+00,  1.2749e+00,  1.3434e+00,
          1.3456e+00,  1.3445e+00,  1.3279e+00,  1.3423e+00,  1.2840e+00,
          1.3438e+00,  1.3399e+00,  1.2825e+00,  1.2970e+00,  1.2729e+00,
          1.2983e+00,  1.2980e+00,  1.2945e+00,  1.2940e+00,  1.2901e+00,
          1.2932e+00,  1.2932e+00,  2.9083e+00,  2.8274e+00,  2.6453e+00,
          2.6707e+00,  2.9072e+00,  2.6539e+00,  2.8076e+00,  2.7051e+00,
          2.6470e+00,  1.7450e+00,  1.7562e+00,  1.7225e+00,  1.7377e+00,
          1.7542e+00,  1.7475e+00,  1.7193e+00,  1.7283e+00,  1.7372e+00,
          1.6018e+00,  1.5845e+00,  1.5255e+00,  1.5208e+00,  1.5982e+00,
          1.5795e+00,  1.6132e+00,  1.5101e+00,  1.5726e+00],
        [ 1.9039e+00,  1.5063e+00,  6.6169e-01,  9.7651e-01,  1.4013e+00,
          1.8347e+00,  1.7079e+00,  1.9399e+00,  1.9399e+00,  1.7382e+00,
          1.3736e+00,  1.5870e+00,  9.9199e-01,  1.7925e+00,  1.7992e-01,
          1.6766e+00,  1.9640e+00,  8.9617e-01,  1.4091e+00,  1.0781e+00,
          8.2257e-01,  1.2180e+00,  1.7775e+00,  1.8436e+00,  1.6203e+00,
          1.9494e+00,  1.9494e+00,  9.2007e-01,  9.0758e-01,  1.9219e+00,
          1.7090e+00,  9.2264e-01,  1.8627e+00,  1.3172e+00,  1.9705e+00,
          1.8863e+00, -1.6006e-01, -3.9906e-01, -4.4240e-01, -2.1222e-01,
          4.2404e-02,  1.2391e-01, -2.8416e-01,  1.9220e+01,  2.4714e+00,
          2.7713e-01,  6.3861e-01,  6.6043e-01,  7.7352e-01,  4.2905e-01,
          7.7490e-01, -9.6886e-03,  8.1137e-01,  8.7017e-01],
        [ 1.3340e+00,  1.3708e+00,  1.3986e+00,  1.4025e+00,  1.3776e+00,
          1.3410e+00,  1.3113e+00,  1.3303e+00,  1.3303e+00,  1.3080e+00,
          1.4276e+00,  1.3237e+00,  1.4540e+00,  1.3833e+00,  1.4790e+00,
          1.3145e+00,  1.3584e+00,  1.3694e+00,  1.3920e+00,  1.3552e+00,
          1.4241e+00,  1.4055e+00,  1.3592e+00,  1.3523e+00,  1.2385e+00,
          1.3409e+00,  1.3409e+00,  1.3777e+00,  1.4374e+00,  1.3558e+00,
          1.1464e+00,  1.3353e+00,  1.2445e+00,  1.4123e+00,  1.2334e+00,
          1.3600e+00,  3.4013e-01,  2.6347e-01,  3.7712e-01,  3.4440e-01,
          1.3881e-01,  8.8783e-02,  3.6356e-01,  1.3351e-01, -6.7509e-02,
          3.5902e+00,  2.3189e+00,  3.5445e+00,  2.6746e+00,  1.8491e+00,
          1.4430e+00,  2.9003e+00,  3.4367e+00,  1.4076e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 360 : 174.19855909632358
Test loss for epoch 360 : 174.57261436984817
Test Precision for epoch 360 : 0.26153846153846155
Test Recall for epoch 360 : 0.26153846153846155
Test F1 for epoch 360 : 0.26153846153846155


theta for epoch 361 : tensor([[ 2.6876e+00,  2.7064e+00,  2.7437e+00,  2.8644e+00,  2.8452e+00,
          2.6908e+00,  2.8323e+00,  2.6859e+00,  2.6859e+00,  1.3311e+00,
          1.3332e+00,  1.3322e+00,  1.3352e+00,  1.3301e+00,  1.3372e+00,
          1.3316e+00,  1.3284e+00,  1.2904e+00,  1.2839e+00,  1.2414e+00,
          1.2422e+00,  1.2849e+00,  1.2815e+00,  1.2811e+00,  1.2831e+00,
          1.2803e+00,  1.2803e+00,  1.2649e+00,  1.3096e+00,  1.3036e+00,
          1.3066e+00,  1.3096e+00,  1.3049e+00,  1.3077e+00,  1.2595e+00,
          1.3039e+00,  1.7376e+00,  1.7483e+00,  1.7421e+00,  1.7385e+00,
          1.7464e+00,  1.6859e+00,  1.7390e+00,  1.7239e+00,  1.7381e+00,
          1.5922e+00,  1.5757e+00,  1.5723e+00,  1.5660e+00,  1.5888e+00,
          1.5709e+00,  1.6031e+00,  1.5620e+00,  1.5643e+00],
        [ 1.2840e+00,  1.2869e+00,  1.2867e+00,  1.2859e+00,  1.2874e+00,
          1.2846e+00,  1.2856e+00,  1.2837e+00,  1.2837e+00,  2.6281e+00,
          2.6430e+00,  2.6246e+00,  2.8583e+00,  2.6108e+00,  3.0061e+00,
          2.6308e+00,  2.8242e+00,  2.9800e+00,  1.2754e+00,  1.2805e+00,
          1.2334e+00,  1.2763e+00,  1.3029e+00,  1.3024e+00,  1.3039e+00,
          1.3015e+00,  1.3015e+00,  1.3039e+00,  1.2559e+00,  1.3245e+00,
          1.3278e+00,  1.3005e+00,  1.3260e+00,  1.3290e+00,  1.2986e+00,
          1.3248e+00,  1.7491e+00,  1.7609e+00,  1.7171e+00,  1.7494e+00,
          1.7588e+00,  1.7604e+00,  1.7137e+00,  1.7285e+00,  1.7489e+00,
          1.5521e+00,  1.5897e+00,  1.5860e+00,  1.5791e+00,  1.5123e+00,
          1.5844e+00,  1.5278e+00,  1.5748e+00,  1.5772e+00],
        [ 1.2688e+00,  1.2714e+00,  1.2693e+00,  1.2732e+00,  1.2713e+00,
          1.2693e+00,  1.2697e+00,  1.2685e+00,  1.2685e+00,  1.3372e+00,
          1.3394e+00,  1.3384e+00,  1.3414e+00,  1.3362e+00,  1.2832e+00,
          1.3377e+00,  1.2743e+00,  1.3256e+00,  2.7352e+00,  2.8576e+00,
          2.9002e+00,  2.7441e+00,  2.6736e+00,  2.6704e+00,  2.8336e+00,
          2.6654e+00,  2.6654e+00,  1.2654e+00,  1.3003e+00,  1.3096e+00,
          1.3127e+00,  1.2660e+00,  1.3110e+00,  1.3138e+00,  1.3095e+00,
          1.3099e+00,  1.7417e+00,  1.7527e+00,  1.7463e+00,  1.6740e+00,
          1.7507e+00,  1.7438e+00,  1.7432e+00,  1.7278e+00,  1.6736e+00,
          1.5971e+00,  1.5804e+00,  1.5770e+00,  1.5706e+00,  1.5748e+00,
          1.5755e+00,  1.5893e+00,  1.5598e+00,  1.5688e+00],
        [ 1.2752e+00,  1.2779e+00,  1.2759e+00,  1.2798e+00,  1.2779e+00,
          1.2757e+00,  1.2762e+00,  1.2749e+00,  1.2749e+00,  1.3434e+00,
          1.3456e+00,  1.3446e+00,  1.3279e+00,  1.3424e+00,  1.2841e+00,
          1.3439e+00,  1.3400e+00,  1.2826e+00,  1.2966e+00,  1.2725e+00,
          1.2979e+00,  1.2977e+00,  1.2942e+00,  1.2937e+00,  1.2897e+00,
          1.2928e+00,  1.2928e+00,  2.9099e+00,  2.8287e+00,  2.6466e+00,
          2.6718e+00,  2.9089e+00,  2.6551e+00,  2.8089e+00,  2.7064e+00,
          2.6483e+00,  1.7448e+00,  1.7560e+00,  1.7223e+00,  1.7374e+00,
          1.7540e+00,  1.7472e+00,  1.7191e+00,  1.7282e+00,  1.7369e+00,
          1.6016e+00,  1.5843e+00,  1.5253e+00,  1.5206e+00,  1.5980e+00,
          1.5793e+00,  1.6130e+00,  1.5098e+00,  1.5724e+00],
        [ 1.9044e+00,  1.5070e+00,  6.6255e-01,  9.7717e-01,  1.4020e+00,
          1.8353e+00,  1.7085e+00,  1.9404e+00,  1.9404e+00,  1.7387e+00,
          1.3742e+00,  1.5877e+00,  9.9271e-01,  1.7931e+00,  1.8075e-01,
          1.6772e+00,  1.9647e+00,  8.9685e-01,  1.4097e+00,  1.0789e+00,
          8.2324e-01,  1.2185e+00,  1.7780e+00,  1.8440e+00,  1.6210e+00,
          1.9499e+00,  1.9499e+00,  9.2090e-01,  9.0827e-01,  1.9224e+00,
          1.7096e+00,  9.2344e-01,  1.8633e+00,  1.3178e+00,  1.9710e+00,
          1.8869e+00, -1.6097e-01, -3.9991e-01, -4.4324e-01, -2.1325e-01,
          4.1445e-02,  1.2278e-01, -2.8503e-01,  1.9257e+01,  2.4523e+00,
          2.7785e-01,  6.3919e-01,  6.6097e-01,  7.7404e-01,  4.2972e-01,
          7.7542e-01, -8.8691e-03,  8.1195e-01,  8.7066e-01],
        [ 1.3336e+00,  1.3704e+00,  1.3980e+00,  1.4021e+00,  1.3772e+00,
          1.3406e+00,  1.3109e+00,  1.3299e+00,  1.3299e+00,  1.3076e+00,
          1.4271e+00,  1.3232e+00,  1.4536e+00,  1.3829e+00,  1.4786e+00,
          1.3141e+00,  1.3580e+00,  1.3689e+00,  1.3915e+00,  1.3545e+00,
          1.4235e+00,  1.4050e+00,  1.3587e+00,  1.3518e+00,  1.2378e+00,
          1.3404e+00,  1.3404e+00,  1.3771e+00,  1.4369e+00,  1.3554e+00,
          1.1460e+00,  1.3347e+00,  1.2440e+00,  1.4119e+00,  1.2329e+00,
          1.3595e+00,  3.3964e-01,  2.6296e-01,  3.7662e-01,  3.4386e-01,
          1.3832e-01,  8.8237e-02,  3.6307e-01,  1.3301e-01, -6.7800e-02,
          3.5934e+00,  2.3200e+00,  3.5475e+00,  2.6760e+00,  1.8501e+00,
          1.4439e+00,  2.9017e+00,  3.4407e+00,  1.4085e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 361 : 174.19095810606424
Test loss for epoch 361 : 174.5670151319295
Test Precision for epoch 361 : 0.26153846153846155
Test Recall for epoch 361 : 0.26153846153846155
Test F1 for epoch 361 : 0.26153846153846155


theta for epoch 362 : tensor([[ 2.6888e+00,  2.7076e+00,  2.7449e+00,  2.8658e+00,  2.8466e+00,
          2.6920e+00,  2.8337e+00,  2.6871e+00,  2.6871e+00,  1.3313e+00,
          1.3334e+00,  1.3324e+00,  1.3353e+00,  1.3302e+00,  1.3373e+00,
          1.3317e+00,  1.3285e+00,  1.2905e+00,  1.2835e+00,  1.2410e+00,
          1.2418e+00,  1.2844e+00,  1.2811e+00,  1.2806e+00,  1.2827e+00,
          1.2798e+00,  1.2798e+00,  1.2648e+00,  1.3095e+00,  1.3035e+00,
          1.3065e+00,  1.3095e+00,  1.3048e+00,  1.3076e+00,  1.2594e+00,
          1.3038e+00,  1.7374e+00,  1.7482e+00,  1.7420e+00,  1.7384e+00,
          1.7463e+00,  1.6858e+00,  1.7389e+00,  1.7237e+00,  1.7380e+00,
          1.5922e+00,  1.5757e+00,  1.5724e+00,  1.5661e+00,  1.5888e+00,
          1.5710e+00,  1.6031e+00,  1.5621e+00,  1.5644e+00],
        [ 1.2839e+00,  1.2868e+00,  1.2867e+00,  1.2859e+00,  1.2873e+00,
          1.2845e+00,  1.2855e+00,  1.2836e+00,  1.2836e+00,  2.6293e+00,
          2.6442e+00,  2.6260e+00,  2.8601e+00,  2.6123e+00,  3.0076e+00,
          2.6320e+00,  2.8260e+00,  2.9816e+00,  1.2748e+00,  1.2800e+00,
          1.2329e+00,  1.2757e+00,  1.3023e+00,  1.3018e+00,  1.3034e+00,
          1.3009e+00,  1.3009e+00,  1.3038e+00,  1.2557e+00,  1.3243e+00,
          1.3277e+00,  1.3004e+00,  1.3258e+00,  1.3289e+00,  1.2985e+00,
          1.3246e+00,  1.7490e+00,  1.7607e+00,  1.7169e+00,  1.7492e+00,
          1.7586e+00,  1.7603e+00,  1.7135e+00,  1.7285e+00,  1.7488e+00,
          1.5521e+00,  1.5897e+00,  1.5860e+00,  1.5791e+00,  1.5123e+00,
          1.5845e+00,  1.5279e+00,  1.5749e+00,  1.5773e+00],
        [ 1.2688e+00,  1.2715e+00,  1.2693e+00,  1.2732e+00,  1.2714e+00,
          1.2693e+00,  1.2697e+00,  1.2685e+00,  1.2685e+00,  1.3375e+00,
          1.3397e+00,  1.3387e+00,  1.3417e+00,  1.3365e+00,  1.2835e+00,
          1.3380e+00,  1.2746e+00,  1.3260e+00,  2.7358e+00,  2.8586e+00,
          2.9011e+00,  2.7448e+00,  2.6742e+00,  2.6710e+00,  2.8346e+00,
          2.6660e+00,  2.6660e+00,  1.2653e+00,  1.3003e+00,  1.3095e+00,
          1.3126e+00,  1.2659e+00,  1.3109e+00,  1.3138e+00,  1.3095e+00,
          1.3098e+00,  1.7416e+00,  1.7526e+00,  1.7462e+00,  1.6738e+00,
          1.7506e+00,  1.7436e+00,  1.7431e+00,  1.7276e+00,  1.6734e+00,
          1.5972e+00,  1.5805e+00,  1.5771e+00,  1.5707e+00,  1.5749e+00,
          1.5757e+00,  1.5895e+00,  1.5598e+00,  1.5690e+00],
        [ 1.2750e+00,  1.2778e+00,  1.2757e+00,  1.2797e+00,  1.2778e+00,
          1.2756e+00,  1.2761e+00,  1.2748e+00,  1.2748e+00,  1.3435e+00,
          1.3457e+00,  1.3446e+00,  1.3280e+00,  1.3424e+00,  1.2842e+00,
          1.3439e+00,  1.3400e+00,  1.2826e+00,  1.2960e+00,  1.2719e+00,
          1.2973e+00,  1.2971e+00,  1.2936e+00,  1.2931e+00,  1.2891e+00,
          1.2922e+00,  1.2922e+00,  2.9117e+00,  2.8301e+00,  2.6479e+00,
          2.6731e+00,  2.9106e+00,  2.6565e+00,  2.8103e+00,  2.7079e+00,
          2.6497e+00,  1.7446e+00,  1.7559e+00,  1.7221e+00,  1.7371e+00,
          1.7538e+00,  1.7469e+00,  1.7189e+00,  1.7280e+00,  1.7367e+00,
          1.6015e+00,  1.5843e+00,  1.5254e+00,  1.5205e+00,  1.5980e+00,
          1.5793e+00,  1.6130e+00,  1.5097e+00,  1.5724e+00],
        [ 1.9051e+00,  1.5078e+00,  6.6361e-01,  9.7802e-01,  1.4028e+00,
          1.8360e+00,  1.7092e+00,  1.9411e+00,  1.9411e+00,  1.7395e+00,
          1.3751e+00,  1.5885e+00,  9.9366e-01,  1.7940e+00,  1.8183e-01,
          1.6780e+00,  1.9655e+00,  8.9779e-01,  1.4104e+00,  1.0798e+00,
          8.2411e-01,  1.2193e+00,  1.7786e+00,  1.8446e+00,  1.6219e+00,
          1.9504e+00,  1.9504e+00,  9.2194e-01,  9.0918e-01,  1.9232e+00,
          1.7104e+00,  9.2445e-01,  1.8641e+00,  1.3187e+00,  1.9718e+00,
          1.8877e+00, -1.6209e-01, -4.0096e-01, -4.4429e-01, -2.1448e-01,
          4.0273e-02,  1.2143e-01, -2.8611e-01,  1.9294e+01,  2.4333e+00,
          2.7881e-01,  6.4002e-01,  6.6176e-01,  7.7480e-01,  4.3063e-01,
          7.7620e-01, -7.7942e-03,  8.1278e-01,  8.7140e-01],
        [ 1.3330e+00,  1.3698e+00,  1.3971e+00,  1.4015e+00,  1.3765e+00,
          1.3400e+00,  1.3102e+00,  1.3293e+00,  1.3293e+00,  1.3070e+00,
          1.4265e+00,  1.3226e+00,  1.4529e+00,  1.3822e+00,  1.4780e+00,
          1.3134e+00,  1.3574e+00,  1.3683e+00,  1.3907e+00,  1.3534e+00,
          1.4227e+00,  1.4042e+00,  1.3579e+00,  1.3510e+00,  1.2368e+00,
          1.3396e+00,  1.3396e+00,  1.3762e+00,  1.4362e+00,  1.3547e+00,
          1.1453e+00,  1.3338e+00,  1.2434e+00,  1.4112e+00,  1.2322e+00,
          1.3589e+00,  3.3892e-01,  2.6222e-01,  3.7588e-01,  3.4310e-01,
          1.3759e-01,  8.7454e-02,  3.6234e-01,  1.3225e-01, -6.8329e-02,
          3.5969e+00,  2.3214e+00,  3.5509e+00,  2.6778e+00,  1.8513e+00,
          1.4451e+00,  2.9034e+00,  3.4450e+00,  1.4097e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 362 : 174.1844989766335
Test loss for epoch 362 : 174.56215856828965
Test Precision for epoch 362 : 0.26153846153846155
Test Recall for epoch 362 : 0.26153846153846155
Test F1 for epoch 362 : 0.26153846153846155


theta for epoch 363 : tensor([[ 2.6901e+00,  2.7089e+00,  2.7462e+00,  2.8673e+00,  2.8481e+00,
          2.6933e+00,  2.8352e+00,  2.6884e+00,  2.6884e+00,  1.3307e+00,
          1.3328e+00,  1.3318e+00,  1.3347e+00,  1.3297e+00,  1.3368e+00,
          1.3311e+00,  1.3280e+00,  1.2899e+00,  1.2843e+00,  1.2419e+00,
          1.2426e+00,  1.2853e+00,  1.2819e+00,  1.2815e+00,  1.2835e+00,
          1.2807e+00,  1.2807e+00,  1.2645e+00,  1.3092e+00,  1.3032e+00,
          1.3062e+00,  1.3092e+00,  1.3045e+00,  1.3073e+00,  1.2591e+00,
          1.3034e+00,  1.7376e+00,  1.7484e+00,  1.7422e+00,  1.7386e+00,
          1.7465e+00,  1.6860e+00,  1.7391e+00,  1.7239e+00,  1.7383e+00,
          1.5914e+00,  1.5749e+00,  1.5716e+00,  1.5653e+00,  1.5880e+00,
          1.5702e+00,  1.6023e+00,  1.5613e+00,  1.5636e+00],
        [ 1.2838e+00,  1.2866e+00,  1.2867e+00,  1.2858e+00,  1.2872e+00,
          1.2843e+00,  1.2854e+00,  1.2835e+00,  1.2835e+00,  2.6300e+00,
          2.6449e+00,  2.6269e+00,  2.8614e+00,  2.6132e+00,  3.0087e+00,
          2.6327e+00,  2.8273e+00,  2.9827e+00,  1.2758e+00,  1.2810e+00,
          1.2339e+00,  1.2768e+00,  1.3034e+00,  1.3028e+00,  1.3044e+00,
          1.3020e+00,  1.3020e+00,  1.3035e+00,  1.2555e+00,  1.3241e+00,
          1.3274e+00,  1.3003e+00,  1.3256e+00,  1.3286e+00,  1.2982e+00,
          1.3244e+00,  1.7492e+00,  1.7609e+00,  1.7171e+00,  1.7494e+00,
          1.7588e+00,  1.7605e+00,  1.7137e+00,  1.7288e+00,  1.7490e+00,
          1.5514e+00,  1.5890e+00,  1.5853e+00,  1.5784e+00,  1.5115e+00,
          1.5838e+00,  1.5271e+00,  1.5741e+00,  1.5766e+00],
        [ 1.2684e+00,  1.2711e+00,  1.2688e+00,  1.2728e+00,  1.2709e+00,
          1.2689e+00,  1.2693e+00,  1.2681e+00,  1.2681e+00,  1.3365e+00,
          1.3387e+00,  1.3377e+00,  1.3407e+00,  1.3355e+00,  1.2825e+00,
          1.3370e+00,  1.2736e+00,  1.3250e+00,  2.7384e+00,  2.8616e+00,
          2.9038e+00,  2.7474e+00,  2.6768e+00,  2.6736e+00,  2.8376e+00,
          2.6686e+00,  2.6686e+00,  1.2647e+00,  1.2998e+00,  1.3090e+00,
          1.3121e+00,  1.2653e+00,  1.3104e+00,  1.3133e+00,  1.3090e+00,
          1.3093e+00,  1.7417e+00,  1.7526e+00,  1.7463e+00,  1.6737e+00,
          1.7507e+00,  1.7436e+00,  1.7431e+00,  1.7277e+00,  1.6734e+00,
          1.5963e+00,  1.5796e+00,  1.5761e+00,  1.5697e+00,  1.5740e+00,
          1.5747e+00,  1.5885e+00,  1.5588e+00,  1.5680e+00],
        [ 1.2748e+00,  1.2776e+00,  1.2754e+00,  1.2795e+00,  1.2775e+00,
          1.2753e+00,  1.2758e+00,  1.2745e+00,  1.2745e+00,  1.3428e+00,
          1.3450e+00,  1.3439e+00,  1.3273e+00,  1.3417e+00,  1.2835e+00,
          1.3433e+00,  1.3393e+00,  1.2820e+00,  1.2967e+00,  1.2725e+00,
          1.2980e+00,  1.2978e+00,  1.2943e+00,  1.2938e+00,  1.2897e+00,
          1.2929e+00,  1.2929e+00,  2.9134e+00,  2.8315e+00,  2.6493e+00,
          2.6744e+00,  2.9124e+00,  2.6579e+00,  2.8117e+00,  2.7094e+00,
          2.6511e+00,  1.7447e+00,  1.7560e+00,  1.7223e+00,  1.7372e+00,
          1.7540e+00,  1.7470e+00,  1.7191e+00,  1.7282e+00,  1.7368e+00,
          1.6007e+00,  1.5835e+00,  1.5246e+00,  1.5197e+00,  1.5972e+00,
          1.5785e+00,  1.6121e+00,  1.5089e+00,  1.5716e+00],
        [ 1.9046e+00,  1.5071e+00,  6.6302e-01,  9.7731e-01,  1.4022e+00,
          1.8355e+00,  1.7086e+00,  1.9406e+00,  1.9406e+00,  1.7386e+00,
          1.3741e+00,  1.5877e+00,  9.9280e-01,  1.7931e+00,  1.8106e-01,
          1.6771e+00,  1.9647e+00,  8.9678e-01,  1.4099e+00,  1.0795e+00,
          8.2357e-01,  1.2188e+00,  1.7783e+00,  1.8444e+00,  1.6218e+00,
          1.9503e+00,  1.9503e+00,  9.2131e-01,  9.0835e-01,  1.9225e+00,
          1.7096e+00,  9.2373e-01,  1.8633e+00,  1.3178e+00,  1.9711e+00,
          1.8870e+00, -1.6172e-01, -4.0057e-01, -4.4391e-01, -2.1425e-01,
          4.0602e-02,  1.2159e-01, -2.8573e-01,  1.9333e+01,  2.4160e+00,
          2.7795e-01,  6.3903e-01,  6.6073e-01,  7.7375e-01,  4.2971e-01,
          7.7516e-01, -8.5378e-03,  8.1181e-01,  8.7032e-01],
        [ 1.3341e+00,  1.3708e+00,  1.3980e+00,  1.4026e+00,  1.3776e+00,
          1.3411e+00,  1.3113e+00,  1.3304e+00,  1.3304e+00,  1.3081e+00,
          1.4276e+00,  1.3237e+00,  1.4540e+00,  1.3833e+00,  1.4791e+00,
          1.3146e+00,  1.3585e+00,  1.3694e+00,  1.3922e+00,  1.3548e+00,
          1.4243e+00,  1.4057e+00,  1.3594e+00,  1.3526e+00,  1.2382e+00,
          1.3412e+00,  1.3412e+00,  1.3771e+00,  1.4373e+00,  1.3559e+00,
          1.1464e+00,  1.3347e+00,  1.2445e+00,  1.4123e+00,  1.2334e+00,
          1.3600e+00,  3.4021e-01,  2.6351e-01,  3.7716e-01,  3.4434e-01,
          1.3890e-01,  8.8717e-02,  3.6363e-01,  1.3354e-01, -6.6795e-02,
          3.5983e+00,  2.3208e+00,  3.5521e+00,  2.6774e+00,  1.8505e+00,
          1.4443e+00,  2.9030e+00,  3.4472e+00,  1.4088e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 363 : 174.17835319571464
Test loss for epoch 363 : 174.56078721034285
Test Precision for epoch 363 : 0.26153846153846155
Test Recall for epoch 363 : 0.26153846153846155
Test F1 for epoch 363 : 0.26153846153846155


theta for epoch 364 : tensor([[ 2.6917e+00,  2.7105e+00,  2.7477e+00,  2.8691e+00,  2.8499e+00,
          2.6949e+00,  2.8370e+00,  2.6900e+00,  2.6900e+00,  1.3309e+00,
          1.3330e+00,  1.3320e+00,  1.3350e+00,  1.3299e+00,  1.3370e+00,
          1.3313e+00,  1.3282e+00,  1.2901e+00,  1.2823e+00,  1.2399e+00,
          1.2407e+00,  1.2833e+00,  1.2800e+00,  1.2795e+00,  1.2816e+00,
          1.2787e+00,  1.2787e+00,  1.2642e+00,  1.3089e+00,  1.3029e+00,
          1.3060e+00,  1.3089e+00,  1.3043e+00,  1.3071e+00,  1.2588e+00,
          1.3032e+00,  1.7373e+00,  1.7481e+00,  1.7418e+00,  1.7383e+00,
          1.7461e+00,  1.6856e+00,  1.7387e+00,  1.7236e+00,  1.7380e+00,
          1.5923e+00,  1.5758e+00,  1.5725e+00,  1.5662e+00,  1.5889e+00,
          1.5711e+00,  1.6032e+00,  1.5622e+00,  1.5645e+00],
        [ 1.2834e+00,  1.2863e+00,  1.2864e+00,  1.2856e+00,  1.2868e+00,
          1.2840e+00,  1.2850e+00,  1.2831e+00,  1.2831e+00,  2.6320e+00,
          2.6470e+00,  2.6293e+00,  2.8640e+00,  2.6155e+00,  3.0110e+00,
          2.6348e+00,  2.8300e+00,  2.9851e+00,  1.2736e+00,  1.2788e+00,
          1.2317e+00,  1.2745e+00,  1.3011e+00,  1.3006e+00,  1.3022e+00,
          1.2997e+00,  1.2997e+00,  1.3032e+00,  1.2551e+00,  1.3238e+00,
          1.3271e+00,  1.3000e+00,  1.3253e+00,  1.3283e+00,  1.2979e+00,
          1.3241e+00,  1.7487e+00,  1.7605e+00,  1.7167e+00,  1.7490e+00,
          1.7584e+00,  1.7601e+00,  1.7133e+00,  1.7286e+00,  1.7487e+00,
          1.5523e+00,  1.5899e+00,  1.5862e+00,  1.5794e+00,  1.5124e+00,
          1.5847e+00,  1.5280e+00,  1.5751e+00,  1.5775e+00],
        [ 1.2683e+00,  1.2710e+00,  1.2686e+00,  1.2727e+00,  1.2708e+00,
          1.2688e+00,  1.2692e+00,  1.2680e+00,  1.2680e+00,  1.3371e+00,
          1.3392e+00,  1.3382e+00,  1.3412e+00,  1.3360e+00,  1.2830e+00,
          1.3375e+00,  1.2741e+00,  1.3255e+00,  2.7388e+00,  2.8624e+00,
          2.9044e+00,  2.7477e+00,  2.6771e+00,  2.6739e+00,  2.8383e+00,
          2.6689e+00,  2.6689e+00,  1.2645e+00,  1.2997e+00,  1.3089e+00,
          1.3120e+00,  1.2652e+00,  1.3103e+00,  1.3132e+00,  1.3089e+00,
          1.3092e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6734e+00,
          1.7504e+00,  1.7433e+00,  1.7429e+00,  1.7274e+00,  1.6731e+00,
          1.5973e+00,  1.5806e+00,  1.5772e+00,  1.5708e+00,  1.5750e+00,
          1.5758e+00,  1.5895e+00,  1.5598e+00,  1.5691e+00],
        [ 1.2746e+00,  1.2773e+00,  1.2751e+00,  1.2792e+00,  1.2773e+00,
          1.2751e+00,  1.2756e+00,  1.2743e+00,  1.2743e+00,  1.3431e+00,
          1.3453e+00,  1.3442e+00,  1.3276e+00,  1.3420e+00,  1.2839e+00,
          1.3436e+00,  1.3396e+00,  1.2823e+00,  1.2949e+00,  1.2706e+00,
          1.2962e+00,  1.2959e+00,  1.2924e+00,  1.2919e+00,  1.2878e+00,
          1.2911e+00,  1.2911e+00,  2.9153e+00,  2.8332e+00,  2.6509e+00,
          2.6758e+00,  2.9143e+00,  2.6595e+00,  2.8133e+00,  2.7110e+00,
          2.6526e+00,  1.7444e+00,  1.7557e+00,  1.7219e+00,  1.7368e+00,
          1.7537e+00,  1.7466e+00,  1.7187e+00,  1.7279e+00,  1.7364e+00,
          1.6016e+00,  1.5844e+00,  1.5256e+00,  1.5207e+00,  1.5981e+00,
          1.5794e+00,  1.6130e+00,  1.5097e+00,  1.5725e+00],
        [ 1.9061e+00,  1.5089e+00,  6.6515e-01,  9.7918e-01,  1.4040e+00,
          1.8371e+00,  1.7103e+00,  1.9421e+00,  1.9421e+00,  1.7406e+00,
          1.3762e+00,  1.5897e+00,  9.9493e-01,  1.7951e+00,  1.8336e-01,
          1.6791e+00,  1.9666e+00,  8.9898e-01,  1.4114e+00,  1.0812e+00,
          8.2532e-01,  1.2204e+00,  1.7795e+00,  1.8455e+00,  1.6232e+00,
          1.9513e+00,  1.9513e+00,  9.2344e-01,  9.1039e-01,  1.9242e+00,
          1.7114e+00,  9.2587e-01,  1.8651e+00,  1.3198e+00,  1.9728e+00,
          1.8887e+00, -1.6384e-01, -4.0260e-01, -4.4592e-01, -2.1648e-01,
          3.8413e-02,  1.1923e-01, -2.8781e-01,  1.9369e+01,  2.3962e+00,
          2.8014e-01,  6.4108e-01,  6.6276e-01,  7.7576e-01,  4.3186e-01,
          7.7717e-01, -6.2277e-03,  8.1387e-01,  8.7231e-01],
        [ 1.3326e+00,  1.3694e+00,  1.3963e+00,  1.4011e+00,  1.3761e+00,
          1.3396e+00,  1.3098e+00,  1.3289e+00,  1.3289e+00,  1.3066e+00,
          1.4261e+00,  1.3222e+00,  1.4525e+00,  1.3819e+00,  1.4776e+00,
          1.3131e+00,  1.3570e+00,  1.3679e+00,  1.3901e+00,  1.3525e+00,
          1.4222e+00,  1.4036e+00,  1.3573e+00,  1.3505e+00,  1.2359e+00,
          1.3391e+00,  1.3391e+00,  1.3753e+00,  1.4358e+00,  1.3543e+00,
          1.1448e+00,  1.3330e+00,  1.2429e+00,  1.4107e+00,  1.2318e+00,
          1.3584e+00,  3.3852e-01,  2.6179e-01,  3.7545e-01,  3.4260e-01,
          1.3719e-01,  8.6954e-02,  3.6193e-01,  1.3178e-01, -6.8306e-02,
          3.6029e+00,  2.3233e+00,  3.5565e+00,  2.6802e+00,  1.8528e+00,
          1.4465e+00,  2.9058e+00,  3.4525e+00,  1.4111e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 364 : 174.17169878837123
Test loss for epoch 364 : 174.55384117774875
Test Precision for epoch 364 : 0.26153846153846155
Test Recall for epoch 364 : 0.26153846153846155
Test F1 for epoch 364 : 0.26153846153846155


theta for epoch 365 : tensor([[ 2.6931e+00,  2.7120e+00,  2.7492e+00,  2.8707e+00,  2.8515e+00,
          2.6963e+00,  2.8386e+00,  2.6914e+00,  2.6914e+00,  1.3301e+00,
          1.3322e+00,  1.3312e+00,  1.3342e+00,  1.3291e+00,  1.3362e+00,
          1.3305e+00,  1.3274e+00,  1.2893e+00,  1.2836e+00,  1.2411e+00,
          1.2419e+00,  1.2846e+00,  1.2812e+00,  1.2807e+00,  1.2828e+00,
          1.2799e+00,  1.2799e+00,  1.2640e+00,  1.3087e+00,  1.3027e+00,
          1.3057e+00,  1.3087e+00,  1.3040e+00,  1.3068e+00,  1.2586e+00,
          1.3030e+00,  1.7375e+00,  1.7483e+00,  1.7420e+00,  1.7385e+00,
          1.7464e+00,  1.6858e+00,  1.7389e+00,  1.7238e+00,  1.7382e+00,
          1.5911e+00,  1.5747e+00,  1.5713e+00,  1.5650e+00,  1.5877e+00,
          1.5699e+00,  1.6020e+00,  1.5610e+00,  1.5633e+00],
        [ 1.2833e+00,  1.2861e+00,  1.2863e+00,  1.2855e+00,  1.2867e+00,
          1.2838e+00,  1.2849e+00,  1.2830e+00,  1.2830e+00,  2.6326e+00,
          2.6475e+00,  2.6301e+00,  2.8651e+00,  2.6162e+00,  3.0121e+00,
          2.6353e+00,  2.8311e+00,  2.9861e+00,  1.2751e+00,  1.2804e+00,
          1.2332e+00,  1.2761e+00,  1.3027e+00,  1.3022e+00,  1.3038e+00,
          1.3013e+00,  1.3013e+00,  1.3031e+00,  1.2551e+00,  1.3237e+00,
          1.3270e+00,  1.3001e+00,  1.3252e+00,  1.3282e+00,  1.2978e+00,
          1.3240e+00,  1.7490e+00,  1.7608e+00,  1.7170e+00,  1.7493e+00,
          1.7587e+00,  1.7604e+00,  1.7136e+00,  1.7289e+00,  1.7490e+00,
          1.5512e+00,  1.5888e+00,  1.5851e+00,  1.5783e+00,  1.5113e+00,
          1.5836e+00,  1.5268e+00,  1.5740e+00,  1.5765e+00],
        [ 1.2679e+00,  1.2706e+00,  1.2681e+00,  1.2723e+00,  1.2704e+00,
          1.2684e+00,  1.2688e+00,  1.2676e+00,  1.2676e+00,  1.3360e+00,
          1.3382e+00,  1.3371e+00,  1.3401e+00,  1.3350e+00,  1.2820e+00,
          1.3365e+00,  1.2731e+00,  1.3245e+00,  2.7415e+00,  2.8655e+00,
          2.9073e+00,  2.7504e+00,  2.6798e+00,  2.6766e+00,  2.8414e+00,
          2.6716e+00,  2.6716e+00,  1.2641e+00,  1.2994e+00,  1.3086e+00,
          1.3117e+00,  1.2648e+00,  1.3100e+00,  1.3128e+00,  1.3086e+00,
          1.3089e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6734e+00,
          1.7505e+00,  1.7434e+00,  1.7430e+00,  1.7276e+00,  1.6732e+00,
          1.5960e+00,  1.5793e+00,  1.5759e+00,  1.5695e+00,  1.5737e+00,
          1.5745e+00,  1.5883e+00,  1.5584e+00,  1.5678e+00],
        [ 1.2744e+00,  1.2771e+00,  1.2748e+00,  1.2790e+00,  1.2771e+00,
          1.2749e+00,  1.2754e+00,  1.2741e+00,  1.2741e+00,  1.3424e+00,
          1.3446e+00,  1.3436e+00,  1.3269e+00,  1.3413e+00,  1.2832e+00,
          1.3429e+00,  1.3389e+00,  1.2817e+00,  1.2962e+00,  1.2719e+00,
          1.2975e+00,  1.2972e+00,  1.2937e+00,  1.2932e+00,  1.2891e+00,
          1.2924e+00,  1.2924e+00,  2.9169e+00,  2.8344e+00,  2.6521e+00,
          2.6770e+00,  2.9159e+00,  2.6607e+00,  2.8146e+00,  2.7123e+00,
          2.6539e+00,  1.7446e+00,  1.7560e+00,  1.7222e+00,  1.7369e+00,
          1.7539e+00,  1.7468e+00,  1.7189e+00,  1.7282e+00,  1.7367e+00,
          1.6005e+00,  1.5833e+00,  1.5246e+00,  1.5196e+00,  1.5970e+00,
          1.5783e+00,  1.6120e+00,  1.5086e+00,  1.5714e+00],
        [ 1.9053e+00,  1.5079e+00,  6.6422e-01,  9.7815e-01,  1.4030e+00,
          1.8362e+00,  1.7094e+00,  1.9413e+00,  1.9413e+00,  1.7393e+00,
          1.3748e+00,  1.5885e+00,  9.9370e-01,  1.7939e+00,  1.8222e-01,
          1.6778e+00,  1.9654e+00,  8.9757e-01,  1.4107e+00,  1.0807e+00,
          8.2452e-01,  1.2196e+00,  1.7791e+00,  1.8452e+00,  1.6230e+00,
          1.9510e+00,  1.9510e+00,  9.2250e-01,  9.0926e-01,  1.9233e+00,
          1.7104e+00,  9.2483e-01,  1.8641e+00,  1.3187e+00,  1.9719e+00,
          1.8878e+00, -1.6323e-01, -4.0195e-01, -4.4529e-01, -2.1599e-01,
          3.9000e-02,  1.1965e-01, -2.8718e-01,  1.9408e+01,  2.3797e+00,
          2.7885e-01,  6.3969e-01,  6.6132e-01,  7.7430e-01,  4.3052e-01,
          7.7573e-01, -7.3771e-03,  8.1250e-01,  8.7084e-01],
        [ 1.3340e+00,  1.3707e+00,  1.3975e+00,  1.4024e+00,  1.3775e+00,
          1.3410e+00,  1.3112e+00,  1.3303e+00,  1.3303e+00,  1.3080e+00,
          1.4275e+00,  1.3236e+00,  1.4539e+00,  1.3832e+00,  1.4790e+00,
          1.3145e+00,  1.3584e+00,  1.3693e+00,  1.3921e+00,  1.3543e+00,
          1.4241e+00,  1.4056e+00,  1.3593e+00,  1.3525e+00,  1.2377e+00,
          1.3411e+00,  1.3411e+00,  1.3766e+00,  1.4372e+00,  1.3558e+00,
          1.1463e+00,  1.3342e+00,  1.2444e+00,  1.4122e+00,  1.2333e+00,
          1.3599e+00,  3.4012e-01,  2.6340e-01,  3.7705e-01,  3.4416e-01,
          1.3882e-01,  8.8541e-02,  3.6352e-01,  1.3338e-01, -6.6446e-02,
          3.6040e+00,  2.3222e+00,  3.5574e+00,  2.6795e+00,  1.8516e+00,
          1.4453e+00,  2.9050e+00,  3.4544e+00,  1.4099e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 365 : 174.16430840924107
Test loss for epoch 365 : 174.55176852706117
Test Precision for epoch 365 : 0.26153846153846155
Test Recall for epoch 365 : 0.26153846153846155
Test F1 for epoch 365 : 0.26153846153846155


theta for epoch 366 : tensor([[ 2.6945e+00,  2.7134e+00,  2.7506e+00,  2.8723e+00,  2.8531e+00,
          2.6977e+00,  2.8402e+00,  2.6928e+00,  2.6928e+00,  1.3303e+00,
          1.3324e+00,  1.3314e+00,  1.3344e+00,  1.3293e+00,  1.3364e+00,
          1.3308e+00,  1.3276e+00,  1.2896e+00,  1.2825e+00,  1.2400e+00,
          1.2408e+00,  1.2835e+00,  1.2801e+00,  1.2796e+00,  1.2817e+00,
          1.2788e+00,  1.2788e+00,  1.2639e+00,  1.3087e+00,  1.3026e+00,
          1.3057e+00,  1.3087e+00,  1.3040e+00,  1.3068e+00,  1.2586e+00,
          1.3029e+00,  1.7372e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7461e+00,  1.6856e+00,  1.7386e+00,  1.7235e+00,  1.7379e+00,
          1.5915e+00,  1.5751e+00,  1.5718e+00,  1.5655e+00,  1.5882e+00,
          1.5704e+00,  1.6024e+00,  1.5615e+00,  1.5638e+00],
        [ 1.2830e+00,  1.2859e+00,  1.2862e+00,  1.2853e+00,  1.2864e+00,
          1.2836e+00,  1.2846e+00,  1.2827e+00,  1.2827e+00,  2.6342e+00,
          2.6492e+00,  2.6319e+00,  2.8673e+00,  2.6181e+00,  3.0140e+00,
          2.6369e+00,  2.8334e+00,  2.9881e+00,  1.2739e+00,  1.2791e+00,
          1.2320e+00,  1.2748e+00,  1.3015e+00,  1.3009e+00,  1.3025e+00,
          1.3001e+00,  1.3001e+00,  1.3031e+00,  1.2550e+00,  1.3236e+00,
          1.3270e+00,  1.3001e+00,  1.3251e+00,  1.3281e+00,  1.2978e+00,
          1.3239e+00,  1.7487e+00,  1.7605e+00,  1.7166e+00,  1.7489e+00,
          1.7584e+00,  1.7601e+00,  1.7132e+00,  1.7288e+00,  1.7487e+00,
          1.5516e+00,  1.5893e+00,  1.5856e+00,  1.5788e+00,  1.5118e+00,
          1.5841e+00,  1.5273e+00,  1.5745e+00,  1.5770e+00],
        [ 1.2679e+00,  1.2706e+00,  1.2682e+00,  1.2723e+00,  1.2705e+00,
          1.2685e+00,  1.2688e+00,  1.2677e+00,  1.2677e+00,  1.3367e+00,
          1.3389e+00,  1.3378e+00,  1.3408e+00,  1.3357e+00,  1.2827e+00,
          1.3372e+00,  1.2738e+00,  1.3252e+00,  2.7415e+00,  2.8659e+00,
          2.9076e+00,  2.7505e+00,  2.6797e+00,  2.6765e+00,  2.8419e+00,
          2.6716e+00,  2.6716e+00,  1.2643e+00,  1.2997e+00,  1.3089e+00,
          1.3120e+00,  1.2650e+00,  1.3103e+00,  1.3131e+00,  1.3088e+00,
          1.3092e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6732e+00,
          1.7504e+00,  1.7431e+00,  1.7428e+00,  1.7274e+00,  1.6730e+00,
          1.5967e+00,  1.5801e+00,  1.5767e+00,  1.5703e+00,  1.5745e+00,
          1.5752e+00,  1.5890e+00,  1.5591e+00,  1.5686e+00],
        [ 1.2742e+00,  1.2770e+00,  1.2746e+00,  1.2789e+00,  1.2769e+00,
          1.2747e+00,  1.2752e+00,  1.2739e+00,  1.2739e+00,  1.3428e+00,
          1.3450e+00,  1.3439e+00,  1.3273e+00,  1.3417e+00,  1.2836e+00,
          1.3433e+00,  1.3393e+00,  1.2821e+00,  1.2952e+00,  1.2708e+00,
          1.2965e+00,  1.2963e+00,  1.2928e+00,  1.2922e+00,  1.2880e+00,
          1.2914e+00,  1.2914e+00,  2.9186e+00,  2.8358e+00,  2.6535e+00,
          2.6782e+00,  2.9176e+00,  2.6620e+00,  2.8160e+00,  2.7137e+00,
          2.6552e+00,  1.7444e+00,  1.7557e+00,  1.7219e+00,  1.7366e+00,
          1.7537e+00,  1.7465e+00,  1.7187e+00,  1.7280e+00,  1.7363e+00,
          1.6010e+00,  1.5838e+00,  1.5251e+00,  1.5202e+00,  1.5975e+00,
          1.5788e+00,  1.6124e+00,  1.5090e+00,  1.5720e+00],
        [ 1.9065e+00,  1.5093e+00,  6.6588e-01,  9.7957e-01,  1.4043e+00,
          1.8374e+00,  1.7107e+00,  1.9425e+00,  1.9425e+00,  1.7407e+00,
          1.3764e+00,  1.5900e+00,  9.9533e-01,  1.7954e+00,  1.8402e-01,
          1.6792e+00,  1.9669e+00,  8.9924e-01,  1.4119e+00,  1.0821e+00,
          8.2590e-01,  1.2209e+00,  1.7801e+00,  1.8461e+00,  1.6242e+00,
          1.9519e+00,  1.9519e+00,  9.2421e-01,  9.1086e-01,  1.9247e+00,
          1.7118e+00,  9.2653e-01,  1.8656e+00,  1.3202e+00,  1.9733e+00,
          1.8892e+00, -1.6499e-01, -4.0364e-01, -4.4697e-01, -2.1787e-01,
          3.7173e-02,  1.1765e-01, -2.8890e-01,  1.9444e+01,  2.3607e+00,
          2.8049e-01,  6.4120e-01,  6.6281e-01,  7.7578e-01,  4.3211e-01,
          7.7721e-01, -5.6192e-03,  8.1403e-01,  8.7229e-01],
        [ 1.3327e+00,  1.3694e+00,  1.3960e+00,  1.4011e+00,  1.3761e+00,
          1.3397e+00,  1.3099e+00,  1.3290e+00,  1.3290e+00,  1.3067e+00,
          1.4262e+00,  1.3223e+00,  1.4526e+00,  1.3820e+00,  1.4777e+00,
          1.3132e+00,  1.3571e+00,  1.3680e+00,  1.3904e+00,  1.3524e+00,
          1.4224e+00,  1.4039e+00,  1.3577e+00,  1.3508e+00,  1.2358e+00,
          1.3395e+00,  1.3395e+00,  1.3751e+00,  1.4359e+00,  1.3545e+00,
          1.1450e+00,  1.3327e+00,  1.2431e+00,  1.4109e+00,  1.2320e+00,
          1.3586e+00,  3.3866e-01,  2.6194e-01,  3.7559e-01,  3.4265e-01,
          1.3735e-01,  8.7024e-02,  3.6207e-01,  1.3185e-01, -6.7710e-02,
          3.6083e+00,  2.3245e+00,  3.5616e+00,  2.6821e+00,  1.8537e+00,
          1.4473e+00,  2.9076e+00,  3.4595e+00,  1.4119e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 366 : 174.156563151076
Test loss for epoch 366 : 174.54437296623573
Test Precision for epoch 366 : 0.26153846153846155
Test Recall for epoch 366 : 0.26153846153846155
Test F1 for epoch 366 : 0.26153846153846155


theta for epoch 367 : tensor([[ 2.6959e+00,  2.7147e+00,  2.7520e+00,  2.8739e+00,  2.8547e+00,
          2.6991e+00,  2.8418e+00,  2.6942e+00,  2.6942e+00,  1.3300e+00,
          1.3321e+00,  1.3311e+00,  1.3341e+00,  1.3290e+00,  1.3361e+00,
          1.3304e+00,  1.3273e+00,  1.2893e+00,  1.2830e+00,  1.2406e+00,
          1.2414e+00,  1.2840e+00,  1.2807e+00,  1.2802e+00,  1.2822e+00,
          1.2794e+00,  1.2794e+00,  1.2638e+00,  1.3085e+00,  1.3025e+00,
          1.3055e+00,  1.3085e+00,  1.3038e+00,  1.3066e+00,  1.2584e+00,
          1.3028e+00,  1.7372e+00,  1.7481e+00,  1.7418e+00,  1.7383e+00,
          1.7461e+00,  1.6856e+00,  1.7387e+00,  1.7235e+00,  1.7380e+00,
          1.5909e+00,  1.5745e+00,  1.5712e+00,  1.5649e+00,  1.5875e+00,
          1.5698e+00,  1.6018e+00,  1.5609e+00,  1.5632e+00],
        [ 1.2829e+00,  1.2858e+00,  1.2861e+00,  1.2853e+00,  1.2863e+00,
          1.2835e+00,  1.2845e+00,  1.2826e+00,  1.2826e+00,  2.6352e+00,
          2.6501e+00,  2.6331e+00,  2.8688e+00,  2.6193e+00,  3.0154e+00,
          2.6379e+00,  2.8349e+00,  2.9895e+00,  1.2745e+00,  1.2797e+00,
          1.2326e+00,  1.2755e+00,  1.3021e+00,  1.3016e+00,  1.3032e+00,
          1.3007e+00,  1.3007e+00,  1.3030e+00,  1.2549e+00,  1.3235e+00,
          1.3268e+00,  1.3000e+00,  1.3250e+00,  1.3280e+00,  1.2977e+00,
          1.3238e+00,  1.7487e+00,  1.7605e+00,  1.7167e+00,  1.7490e+00,
          1.7584e+00,  1.7602e+00,  1.7133e+00,  1.7289e+00,  1.7488e+00,
          1.5510e+00,  1.5887e+00,  1.5850e+00,  1.5782e+00,  1.5112e+00,
          1.5835e+00,  1.5266e+00,  1.5739e+00,  1.5764e+00],
        [ 1.2678e+00,  1.2705e+00,  1.2680e+00,  1.2722e+00,  1.2704e+00,
          1.2683e+00,  1.2687e+00,  1.2675e+00,  1.2675e+00,  1.3363e+00,
          1.3385e+00,  1.3374e+00,  1.3404e+00,  1.3353e+00,  1.2823e+00,
          1.3368e+00,  1.2734e+00,  1.3248e+00,  2.7433e+00,  2.8681e+00,
          2.9096e+00,  2.7523e+00,  2.6815e+00,  2.6783e+00,  2.8441e+00,
          2.6733e+00,  2.6733e+00,  1.2641e+00,  1.2995e+00,  1.3087e+00,
          1.3118e+00,  1.2647e+00,  1.3101e+00,  1.3129e+00,  1.3087e+00,
          1.3090e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6731e+00,
          1.7504e+00,  1.7431e+00,  1.7429e+00,  1.7274e+00,  1.6729e+00,
          1.5961e+00,  1.5794e+00,  1.5760e+00,  1.5697e+00,  1.5738e+00,
          1.5746e+00,  1.5883e+00,  1.5584e+00,  1.5680e+00],
        [ 1.2741e+00,  1.2769e+00,  1.2744e+00,  1.2787e+00,  1.2768e+00,
          1.2746e+00,  1.2751e+00,  1.2738e+00,  1.2738e+00,  1.3424e+00,
          1.3447e+00,  1.3436e+00,  1.3270e+00,  1.3414e+00,  1.2833e+00,
          1.3429e+00,  1.3390e+00,  1.2818e+00,  1.2957e+00,  1.2713e+00,
          1.2971e+00,  1.2968e+00,  1.2933e+00,  1.2928e+00,  1.2885e+00,
          1.2919e+00,  1.2919e+00,  2.9204e+00,  2.8372e+00,  2.6548e+00,
          2.6794e+00,  2.9193e+00,  2.6633e+00,  2.8174e+00,  2.7151e+00,
          2.6565e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7366e+00,
          1.7537e+00,  1.7465e+00,  1.7187e+00,  1.7281e+00,  1.7363e+00,
          1.6004e+00,  1.5833e+00,  1.5246e+00,  1.5196e+00,  1.5969e+00,
          1.5783e+00,  1.6118e+00,  1.5084e+00,  1.5714e+00],
        [ 1.9064e+00,  1.5091e+00,  6.6578e-01,  9.7933e-01,  1.4041e+00,
          1.8373e+00,  1.7105e+00,  1.9424e+00,  1.9424e+00,  1.7403e+00,
          1.3760e+00,  1.5896e+00,  9.9499e-01,  1.7951e+00,  1.8380e-01,
          1.6788e+00,  1.9666e+00,  8.9879e-01,  1.4118e+00,  1.0821e+00,
          8.2576e-01,  1.2207e+00,  1.7800e+00,  1.8461e+00,  1.6244e+00,
          1.9519e+00,  1.9519e+00,  9.2407e-01,  9.1055e-01,  1.9245e+00,
          1.7115e+00,  9.2633e-01,  1.8653e+00,  1.3199e+00,  1.9731e+00,
          1.8890e+00, -1.6515e-01, -4.0374e-01, -4.4708e-01, -2.1814e-01,
          3.6977e-02,  1.1729e-01, -2.8904e-01,  1.9482e+01,  2.3437e+00,
          2.8009e-01,  6.4070e-01,  6.6229e-01,  7.7524e-01,  4.3167e-01,
          7.7667e-01, -5.8818e-03,  8.1357e-01,  8.7174e-01],
        [ 1.3333e+00,  1.3700e+00,  1.3963e+00,  1.4016e+00,  1.3767e+00,
          1.3403e+00,  1.3105e+00,  1.3295e+00,  1.3295e+00,  1.3073e+00,
          1.4267e+00,  1.3228e+00,  1.4531e+00,  1.3825e+00,  1.4782e+00,
          1.3137e+00,  1.3577e+00,  1.3685e+00,  1.3912e+00,  1.3530e+00,
          1.4232e+00,  1.4047e+00,  1.3585e+00,  1.3516e+00,  1.2364e+00,
          1.3403e+00,  1.3403e+00,  1.3755e+00,  1.4365e+00,  1.3551e+00,
          1.1456e+00,  1.3331e+00,  1.2437e+00,  1.4114e+00,  1.2326e+00,
          1.3592e+00,  3.3928e-01,  2.6257e-01,  3.7621e-01,  3.4323e-01,
          1.3799e-01,  8.7619e-02,  3.6268e-01,  1.3242e-01, -6.6850e-02,
          3.6104e+00,  2.3245e+00,  3.5635e+00,  2.6825e+00,  1.8535e+00,
          1.4472e+00,  2.9079e+00,  3.4625e+00,  1.4117e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 367 : 174.14910729440132
Test loss for epoch 367 : 174.54065314816657
Test Precision for epoch 367 : 0.26153846153846155
Test Recall for epoch 367 : 0.26153846153846155
Test F1 for epoch 367 : 0.26153846153846155


theta for epoch 368 : tensor([[ 2.6974e+00,  2.7162e+00,  2.7534e+00,  2.8756e+00,  2.8564e+00,
          2.7006e+00,  2.8434e+00,  2.6957e+00,  2.6957e+00,  1.3298e+00,
          1.3319e+00,  1.3309e+00,  1.3339e+00,  1.3288e+00,  1.3359e+00,
          1.3302e+00,  1.3271e+00,  1.2891e+00,  1.2828e+00,  1.2404e+00,
          1.2412e+00,  1.2838e+00,  1.2805e+00,  1.2800e+00,  1.2820e+00,
          1.2792e+00,  1.2792e+00,  1.2635e+00,  1.3083e+00,  1.3022e+00,
          1.3053e+00,  1.3083e+00,  1.3036e+00,  1.3064e+00,  1.2582e+00,
          1.3025e+00,  1.7372e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7461e+00,  1.6856e+00,  1.7386e+00,  1.7234e+00,  1.7380e+00,
          1.5909e+00,  1.5745e+00,  1.5712e+00,  1.5649e+00,  1.5875e+00,
          1.5698e+00,  1.6018e+00,  1.5609e+00,  1.5632e+00],
        [ 1.2828e+00,  1.2856e+00,  1.2861e+00,  1.2852e+00,  1.2862e+00,
          1.2833e+00,  1.2844e+00,  1.2825e+00,  1.2825e+00,  2.6365e+00,
          2.6515e+00,  2.6347e+00,  2.8707e+00,  2.6209e+00,  3.0172e+00,
          2.6393e+00,  2.8369e+00,  2.9912e+00,  1.2742e+00,  1.2794e+00,
          1.2323e+00,  1.2752e+00,  1.3018e+00,  1.3013e+00,  1.3029e+00,
          1.3004e+00,  1.3004e+00,  1.3027e+00,  1.2546e+00,  1.3233e+00,
          1.3266e+00,  1.2998e+00,  1.3248e+00,  1.3278e+00,  1.2974e+00,
          1.3236e+00,  1.7486e+00,  1.7605e+00,  1.7166e+00,  1.7489e+00,
          1.7583e+00,  1.7601e+00,  1.7132e+00,  1.7289e+00,  1.7487e+00,
          1.5510e+00,  1.5887e+00,  1.5850e+00,  1.5782e+00,  1.5111e+00,
          1.5835e+00,  1.5266e+00,  1.5739e+00,  1.5764e+00],
        [ 1.2676e+00,  1.2703e+00,  1.2677e+00,  1.2720e+00,  1.2702e+00,
          1.2681e+00,  1.2685e+00,  1.2674e+00,  1.2674e+00,  1.3360e+00,
          1.3381e+00,  1.3371e+00,  1.3401e+00,  1.3349e+00,  1.2819e+00,
          1.3364e+00,  1.2730e+00,  1.3245e+00,  2.7450e+00,  2.8702e+00,
          2.9116e+00,  2.7540e+00,  2.6832e+00,  2.6800e+00,  2.8462e+00,
          2.6750e+00,  2.6750e+00,  1.2637e+00,  1.2992e+00,  1.3084e+00,
          1.3115e+00,  1.2644e+00,  1.3098e+00,  1.3126e+00,  1.3084e+00,
          1.3087e+00,  1.7413e+00,  1.7523e+00,  1.7459e+00,  1.6729e+00,
          1.7503e+00,  1.7429e+00,  1.7428e+00,  1.7273e+00,  1.6728e+00,
          1.5960e+00,  1.5794e+00,  1.5760e+00,  1.5696e+00,  1.5738e+00,
          1.5746e+00,  1.5882e+00,  1.5583e+00,  1.5679e+00],
        [ 1.2740e+00,  1.2767e+00,  1.2742e+00,  1.2786e+00,  1.2767e+00,
          1.2745e+00,  1.2750e+00,  1.2737e+00,  1.2737e+00,  1.3422e+00,
          1.3444e+00,  1.3433e+00,  1.3267e+00,  1.3411e+00,  1.2831e+00,
          1.3426e+00,  1.3387e+00,  1.2816e+00,  1.2954e+00,  1.2709e+00,
          1.2967e+00,  1.2964e+00,  1.2929e+00,  1.2924e+00,  1.2881e+00,
          1.2916e+00,  1.2916e+00,  2.9223e+00,  2.8388e+00,  2.6564e+00,
          2.6809e+00,  2.9213e+00,  2.6649e+00,  2.8190e+00,  2.7168e+00,
          2.6581e+00,  1.7443e+00,  1.7557e+00,  1.7219e+00,  1.7364e+00,
          1.7537e+00,  1.7463e+00,  1.7186e+00,  1.7280e+00,  1.7362e+00,
          1.6004e+00,  1.5832e+00,  1.5246e+00,  1.5196e+00,  1.5969e+00,
          1.5782e+00,  1.6118e+00,  1.5083e+00,  1.5714e+00],
        [ 1.9069e+00,  1.5096e+00,  6.6645e-01,  9.7983e-01,  1.4046e+00,
          1.8378e+00,  1.7110e+00,  1.9428e+00,  1.9428e+00,  1.7407e+00,
          1.3764e+00,  1.5901e+00,  9.9548e-01,  1.7955e+00,  1.8443e-01,
          1.6792e+00,  1.9670e+00,  8.9924e-01,  1.4122e+00,  1.0827e+00,
          8.2627e-01,  1.2212e+00,  1.7805e+00,  1.8465e+00,  1.6250e+00,
          1.9524e+00,  1.9524e+00,  9.2469e-01,  9.1104e-01,  1.9249e+00,
          1.7119e+00,  9.2691e-01,  1.8657e+00,  1.3203e+00,  1.9735e+00,
          1.8894e+00, -1.6601e-01, -4.0453e-01, -4.4787e-01, -2.1911e-01,
          3.6067e-02,  1.1622e-01, -2.8986e-01,  1.9519e+01,  2.3262e+00,
          2.8058e-01,  6.4109e-01,  6.6265e-01,  7.7560e-01,  4.3211e-01,
          7.7703e-01, -5.2740e-03,  8.1399e-01,  8.7208e-01],
        [ 1.3332e+00,  1.3699e+00,  1.3961e+00,  1.4016e+00,  1.3766e+00,
          1.3402e+00,  1.3104e+00,  1.3295e+00,  1.3295e+00,  1.3072e+00,
          1.4266e+00,  1.3227e+00,  1.4530e+00,  1.3824e+00,  1.4781e+00,
          1.3136e+00,  1.3576e+00,  1.3684e+00,  1.3911e+00,  1.3527e+00,
          1.4231e+00,  1.4046e+00,  1.3584e+00,  1.3516e+00,  1.2362e+00,
          1.3402e+00,  1.3402e+00,  1.3752e+00,  1.4364e+00,  1.3550e+00,
          1.1455e+00,  1.3328e+00,  1.2436e+00,  1.4113e+00,  1.2325e+00,
          1.3591e+00,  3.3916e-01,  2.6246e-01,  3.7610e-01,  3.4308e-01,
          1.3788e-01,  8.7472e-02,  3.6257e-01,  1.3225e-01, -6.6737e-02,
          3.6134e+00,  2.3254e+00,  3.5663e+00,  2.6836e+00,  1.8542e+00,
          1.4478e+00,  2.9090e+00,  3.4662e+00,  1.4124e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 368 : 174.14222792904005
Test loss for epoch 368 : 174.53616775358842
Test Precision for epoch 368 : 0.26153846153846155
Test Recall for epoch 368 : 0.26153846153846155
Test F1 for epoch 368 : 0.26153846153846155


theta for epoch 369 : tensor([[ 2.6989e+00,  2.7177e+00,  2.7549e+00,  2.8772e+00,  2.8580e+00,
          2.7021e+00,  2.8451e+00,  2.6972e+00,  2.6972e+00,  1.3299e+00,
          1.3320e+00,  1.3310e+00,  1.3339e+00,  1.3288e+00,  1.3359e+00,
          1.3303e+00,  1.3271e+00,  1.2891e+00,  1.2820e+00,  1.2395e+00,
          1.2403e+00,  1.2830e+00,  1.2796e+00,  1.2791e+00,  1.2812e+00,
          1.2783e+00,  1.2783e+00,  1.2633e+00,  1.3081e+00,  1.3020e+00,
          1.3051e+00,  1.3081e+00,  1.3034e+00,  1.3062e+00,  1.2580e+00,
          1.3023e+00,  1.7371e+00,  1.7479e+00,  1.7416e+00,  1.7381e+00,
          1.7460e+00,  1.6855e+00,  1.7385e+00,  1.7233e+00,  1.7379e+00,
          1.5912e+00,  1.5748e+00,  1.5715e+00,  1.5653e+00,  1.5878e+00,
          1.5701e+00,  1.6020e+00,  1.5612e+00,  1.5636e+00],
        [ 1.2826e+00,  1.2854e+00,  1.2859e+00,  1.2851e+00,  1.2860e+00,
          1.2831e+00,  1.2842e+00,  1.2823e+00,  1.2823e+00,  2.6382e+00,
          2.6532e+00,  2.6365e+00,  2.8729e+00,  2.6227e+00,  3.0191e+00,
          2.6409e+00,  2.8391e+00,  2.9933e+00,  1.2732e+00,  1.2784e+00,
          1.2313e+00,  1.2741e+00,  1.3008e+00,  1.3003e+00,  1.3019e+00,
          1.2994e+00,  1.2994e+00,  1.3024e+00,  1.2543e+00,  1.3230e+00,
          1.3263e+00,  1.2996e+00,  1.3245e+00,  1.3275e+00,  1.2971e+00,
          1.3233e+00,  1.7485e+00,  1.7603e+00,  1.7165e+00,  1.7488e+00,
          1.7582e+00,  1.7600e+00,  1.7131e+00,  1.7289e+00,  1.7486e+00,
          1.5513e+00,  1.5890e+00,  1.5854e+00,  1.5785e+00,  1.5114e+00,
          1.5839e+00,  1.5268e+00,  1.5743e+00,  1.5767e+00],
        [ 1.2675e+00,  1.2702e+00,  1.2675e+00,  1.2719e+00,  1.2700e+00,
          1.2680e+00,  1.2684e+00,  1.2672e+00,  1.2672e+00,  1.3360e+00,
          1.3382e+00,  1.3372e+00,  1.3402e+00,  1.3350e+00,  1.2820e+00,
          1.3365e+00,  1.2731e+00,  1.3245e+00,  2.7462e+00,  2.8717e+00,
          2.9130e+00,  2.7552e+00,  2.6844e+00,  2.6812e+00,  2.8477e+00,
          2.6762e+00,  2.6762e+00,  1.2634e+00,  1.2990e+00,  1.3082e+00,
          1.3113e+00,  1.2641e+00,  1.3096e+00,  1.3124e+00,  1.3082e+00,
          1.3085e+00,  1.7412e+00,  1.7523e+00,  1.7458e+00,  1.6728e+00,
          1.7503e+00,  1.7428e+00,  1.7427e+00,  1.7272e+00,  1.6726e+00,
          1.5963e+00,  1.5797e+00,  1.5763e+00,  1.5700e+00,  1.5741e+00,
          1.5749e+00,  1.5885e+00,  1.5586e+00,  1.5683e+00],
        [ 1.2738e+00,  1.2765e+00,  1.2739e+00,  1.2784e+00,  1.2765e+00,
          1.2743e+00,  1.2748e+00,  1.2735e+00,  1.2735e+00,  1.3422e+00,
          1.3444e+00,  1.3433e+00,  1.3267e+00,  1.3411e+00,  1.2831e+00,
          1.3426e+00,  1.3387e+00,  1.2816e+00,  1.2945e+00,  1.2700e+00,
          1.2958e+00,  1.2955e+00,  1.2920e+00,  1.2915e+00,  1.2871e+00,
          1.2907e+00,  1.2907e+00,  2.9243e+00,  2.8405e+00,  2.6580e+00,
          2.6824e+00,  2.9233e+00,  2.6665e+00,  2.8207e+00,  2.7185e+00,
          2.6597e+00,  1.7442e+00,  1.7556e+00,  1.7218e+00,  1.7362e+00,
          1.7536e+00,  1.7461e+00,  1.7185e+00,  1.7280e+00,  1.7360e+00,
          1.6006e+00,  1.5835e+00,  1.5249e+00,  1.5199e+00,  1.5971e+00,
          1.5785e+00,  1.6120e+00,  1.5085e+00,  1.5717e+00],
        [ 1.9077e+00,  1.5104e+00,  6.6753e-01,  9.8072e-01,  1.4055e+00,
          1.8386e+00,  1.7118e+00,  1.9436e+00,  1.9436e+00,  1.7416e+00,
          1.3773e+00,  1.5910e+00,  9.9646e-01,  1.7964e+00,  1.8556e-01,
          1.6801e+00,  1.9679e+00,  9.0021e-01,  1.4129e+00,  1.0836e+00,
          8.2710e-01,  1.2219e+00,  1.7811e+00,  1.8471e+00,  1.6258e+00,
          1.9529e+00,  1.9529e+00,  9.2574e-01,  9.1197e-01,  1.9257e+00,
          1.7128e+00,  9.2794e-01,  1.8666e+00,  1.3212e+00,  1.9743e+00,
          1.8902e+00, -1.6726e-01, -4.0570e-01, -4.4903e-01, -2.2047e-01,
          3.4762e-02,  1.1475e-01, -2.9107e-01,  1.9556e+01,  2.3085e+00,
          2.8154e-01,  6.4196e-01,  6.6351e-01,  7.7646e-01,  4.3304e-01,
          7.7789e-01, -4.1894e-03,  8.1492e-01,  8.7293e-01],
        [ 1.3327e+00,  1.3694e+00,  1.3954e+00,  1.4011e+00,  1.3761e+00,
          1.3397e+00,  1.3099e+00,  1.3290e+00,  1.3290e+00,  1.3067e+00,
          1.4261e+00,  1.3222e+00,  1.4524e+00,  1.3819e+00,  1.4775e+00,
          1.3131e+00,  1.3571e+00,  1.3678e+00,  1.3904e+00,  1.3518e+00,
          1.4223e+00,  1.4038e+00,  1.3576e+00,  1.3508e+00,  1.2352e+00,
          1.3394e+00,  1.3394e+00,  1.3744e+00,  1.4358e+00,  1.3545e+00,
          1.1449e+00,  1.3321e+00,  1.2431e+00,  1.4108e+00,  1.2320e+00,
          1.3586e+00,  3.3857e-01,  2.6188e-01,  3.7551e-01,  3.4245e-01,
          1.3729e-01,  8.6838e-02,  3.6198e-01,  1.3158e-01, -6.7117e-02,
          3.6168e+00,  2.3267e+00,  3.5696e+00,  2.6853e+00,  1.8554e+00,
          1.4490e+00,  2.9107e+00,  3.4705e+00,  1.4135e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 369 : 174.13583248561298
Test loss for epoch 369 : 174.53134145677745
Test Precision for epoch 369 : 0.26153846153846155
Test Recall for epoch 369 : 0.26153846153846155
Test F1 for epoch 369 : 0.26153846153846155


theta for epoch 370 : tensor([[ 2.7003e+00,  2.7192e+00,  2.7564e+00,  2.8789e+00,  2.8597e+00,
          2.7035e+00,  2.8468e+00,  2.6987e+00,  2.6987e+00,  1.3294e+00,
          1.3315e+00,  1.3305e+00,  1.3335e+00,  1.3284e+00,  1.3355e+00,
          1.3299e+00,  1.3267e+00,  1.2887e+00,  1.2828e+00,  1.2403e+00,
          1.2411e+00,  1.2838e+00,  1.2804e+00,  1.2800e+00,  1.2820e+00,
          1.2791e+00,  1.2791e+00,  1.2631e+00,  1.3078e+00,  1.3018e+00,
          1.3049e+00,  1.3078e+00,  1.3032e+00,  1.3060e+00,  1.2578e+00,
          1.3021e+00,  1.7373e+00,  1.7481e+00,  1.7418e+00,  1.7383e+00,
          1.7462e+00,  1.6857e+00,  1.7387e+00,  1.7235e+00,  1.7382e+00,
          1.5904e+00,  1.5741e+00,  1.5707e+00,  1.5645e+00,  1.5871e+00,
          1.5694e+00,  1.6013e+00,  1.5605e+00,  1.5629e+00],
        [ 1.2825e+00,  1.2853e+00,  1.2859e+00,  1.2851e+00,  1.2859e+00,
          1.2830e+00,  1.2841e+00,  1.2822e+00,  1.2822e+00,  2.6390e+00,
          2.6540e+00,  2.6375e+00,  2.8742e+00,  2.6237e+00,  3.0204e+00,
          2.6417e+00,  2.8405e+00,  2.9945e+00,  1.2742e+00,  1.2795e+00,
          1.2323e+00,  1.2752e+00,  1.3018e+00,  1.3013e+00,  1.3029e+00,
          1.3004e+00,  1.3004e+00,  1.3024e+00,  1.2542e+00,  1.3229e+00,
          1.3262e+00,  1.2996e+00,  1.3244e+00,  1.3274e+00,  1.2971e+00,
          1.3232e+00,  1.7487e+00,  1.7606e+00,  1.7167e+00,  1.7490e+00,
          1.7585e+00,  1.7602e+00,  1.7133e+00,  1.7292e+00,  1.7489e+00,
          1.5505e+00,  1.5883e+00,  1.5847e+00,  1.5779e+00,  1.5107e+00,
          1.5832e+00,  1.5261e+00,  1.5736e+00,  1.5761e+00],
        [ 1.2672e+00,  1.2699e+00,  1.2672e+00,  1.2716e+00,  1.2698e+00,
          1.2677e+00,  1.2681e+00,  1.2670e+00,  1.2670e+00,  1.3354e+00,
          1.3375e+00,  1.3365e+00,  1.3395e+00,  1.3343e+00,  1.2814e+00,
          1.3358e+00,  1.2724e+00,  1.3239e+00,  2.7485e+00,  2.8744e+00,
          2.9154e+00,  2.7574e+00,  2.6866e+00,  2.6834e+00,  2.8504e+00,
          2.6784e+00,  2.6784e+00,  1.2631e+00,  1.2988e+00,  1.3079e+00,
          1.3110e+00,  1.2638e+00,  1.3093e+00,  1.3121e+00,  1.3079e+00,
          1.3082e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6729e+00,
          1.7504e+00,  1.7429e+00,  1.7429e+00,  1.7274e+00,  1.6727e+00,
          1.5954e+00,  1.5789e+00,  1.5755e+00,  1.5692e+00,  1.5733e+00,
          1.5741e+00,  1.5877e+00,  1.5577e+00,  1.5675e+00],
        [ 1.2736e+00,  1.2763e+00,  1.2737e+00,  1.2782e+00,  1.2763e+00,
          1.2741e+00,  1.2746e+00,  1.2733e+00,  1.2733e+00,  1.3417e+00,
          1.3439e+00,  1.3429e+00,  1.3262e+00,  1.3406e+00,  1.2827e+00,
          1.3422e+00,  1.3382e+00,  1.2812e+00,  1.2953e+00,  1.2707e+00,
          1.2966e+00,  1.2963e+00,  1.2928e+00,  1.2923e+00,  1.2879e+00,
          1.2915e+00,  1.2915e+00,  2.9261e+00,  2.8419e+00,  2.6593e+00,
          2.6837e+00,  2.9250e+00,  2.6679e+00,  2.8221e+00,  2.7199e+00,
          2.6611e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7364e+00,
          1.7538e+00,  1.7463e+00,  1.7187e+00,  1.7282e+00,  1.7362e+00,
          1.5999e+00,  1.5828e+00,  1.5243e+00,  1.5192e+00,  1.5964e+00,
          1.5778e+00,  1.6113e+00,  1.5078e+00,  1.5710e+00],
        [ 1.9073e+00,  1.5100e+00,  6.6716e-01,  9.8024e-01,  1.4050e+00,
          1.8382e+00,  1.7114e+00,  1.9433e+00,  1.9433e+00,  1.7409e+00,
          1.3766e+00,  1.5904e+00,  9.9585e-01,  1.7958e+00,  1.8506e-01,
          1.6794e+00,  1.9673e+00,  8.9948e-01,  1.4127e+00,  1.0835e+00,
          8.2676e-01,  1.2216e+00,  1.7809e+00,  1.8470e+00,  1.6258e+00,
          1.9529e+00,  1.9529e+00,  9.2534e-01,  9.1141e-01,  1.9253e+00,
          1.7122e+00,  9.2747e-01,  1.8661e+00,  1.3206e+00,  1.9739e+00,
          1.8898e+00, -1.6722e-01, -4.0560e-01, -4.4894e-01, -2.2054e-01,
          3.4758e-02,  1.1459e-01, -2.9100e-01,  1.9594e+01,  2.2924e+00,
          2.8087e-01,  6.4122e-01,  6.6274e-01,  7.7569e-01,  4.3233e-01,
          7.7712e-01, -4.7424e-03,  8.1422e-01,  8.7215e-01],
        [ 1.3335e+00,  1.3702e+00,  1.3960e+00,  1.4018e+00,  1.3769e+00,
          1.3405e+00,  1.3107e+00,  1.3298e+00,  1.3298e+00,  1.3075e+00,
          1.4269e+00,  1.3230e+00,  1.4532e+00,  1.3827e+00,  1.4783e+00,
          1.3139e+00,  1.3579e+00,  1.3686e+00,  1.3915e+00,  1.3527e+00,
          1.4235e+00,  1.4050e+00,  1.3588e+00,  1.3520e+00,  1.2362e+00,
          1.3406e+00,  1.3406e+00,  1.3751e+00,  1.4366e+00,  1.3553e+00,
          1.1458e+00,  1.3327e+00,  1.2439e+00,  1.4116e+00,  1.2328e+00,
          1.3594e+00,  3.3948e-01,  2.6281e-01,  3.7644e-01,  3.4332e-01,
          1.3822e-01,  8.7729e-02,  3.6289e-01,  1.3243e-01, -6.5966e-02,
          3.6187e+00,  2.3265e+00,  3.5713e+00,  2.6854e+00,  1.8550e+00,
          1.4485e+00,  2.9108e+00,  3.4732e+00,  1.4131e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 370 : 174.1295304103651
Test loss for epoch 370 : 174.5292110788021
Test Precision for epoch 370 : 0.26153846153846155
Test Recall for epoch 370 : 0.26153846153846155
Test F1 for epoch 370 : 0.26153846153846155


theta for epoch 371 : tensor([[ 2.7019e+00,  2.7208e+00,  2.7580e+00,  2.8807e+00,  2.8615e+00,
          2.7051e+00,  2.8486e+00,  2.7003e+00,  2.7003e+00,  1.3296e+00,
          1.3318e+00,  1.3307e+00,  1.3337e+00,  1.3286e+00,  1.3357e+00,
          1.3301e+00,  1.3269e+00,  1.2889e+00,  1.2817e+00,  1.2392e+00,
          1.2400e+00,  1.2826e+00,  1.2793e+00,  1.2788e+00,  1.2809e+00,
          1.2780e+00,  1.2780e+00,  1.2631e+00,  1.3078e+00,  1.3018e+00,
          1.3048e+00,  1.3078e+00,  1.3031e+00,  1.3059e+00,  1.2577e+00,
          1.3021e+00,  1.7370e+00,  1.7479e+00,  1.7416e+00,  1.7381e+00,
          1.7460e+00,  1.6855e+00,  1.7385e+00,  1.7233e+00,  1.7380e+00,
          1.5908e+00,  1.5745e+00,  1.5712e+00,  1.5649e+00,  1.5874e+00,
          1.5698e+00,  1.6016e+00,  1.5609e+00,  1.5633e+00],
        [ 1.2823e+00,  1.2851e+00,  1.2858e+00,  1.2849e+00,  1.2857e+00,
          1.2828e+00,  1.2839e+00,  1.2820e+00,  1.2820e+00,  2.6407e+00,
          2.6557e+00,  2.6395e+00,  2.8764e+00,  2.6256e+00,  3.0225e+00,
          2.6435e+00,  2.8428e+00,  2.9967e+00,  1.2730e+00,  1.2782e+00,
          1.2310e+00,  1.2739e+00,  1.3006e+00,  1.3000e+00,  1.3017e+00,
          1.2992e+00,  1.2992e+00,  1.3023e+00,  1.2542e+00,  1.3228e+00,
          1.3262e+00,  1.2996e+00,  1.3243e+00,  1.3274e+00,  1.2970e+00,
          1.3232e+00,  1.7485e+00,  1.7603e+00,  1.7165e+00,  1.7488e+00,
          1.7582e+00,  1.7600e+00,  1.7131e+00,  1.7291e+00,  1.7487e+00,
          1.5509e+00,  1.5887e+00,  1.5851e+00,  1.5783e+00,  1.5111e+00,
          1.5836e+00,  1.5265e+00,  1.5740e+00,  1.5765e+00],
        [ 1.2673e+00,  1.2700e+00,  1.2672e+00,  1.2717e+00,  1.2698e+00,
          1.2678e+00,  1.2682e+00,  1.2670e+00,  1.2670e+00,  1.3361e+00,
          1.3382e+00,  1.3372e+00,  1.3402e+00,  1.3350e+00,  1.2820e+00,
          1.3365e+00,  1.2731e+00,  1.3246e+00,  2.7488e+00,  2.8751e+00,
          2.9160e+00,  2.7577e+00,  2.6868e+00,  2.6836e+00,  2.8510e+00,
          2.6787e+00,  2.6787e+00,  1.2633e+00,  1.2990e+00,  1.3081e+00,
          1.3112e+00,  1.2639e+00,  1.3095e+00,  1.3124e+00,  1.3081e+00,
          1.3084e+00,  1.7413e+00,  1.7523e+00,  1.7459e+00,  1.6727e+00,
          1.7504e+00,  1.7427e+00,  1.7428e+00,  1.7273e+00,  1.6726e+00,
          1.5960e+00,  1.5795e+00,  1.5761e+00,  1.5698e+00,  1.5739e+00,
          1.5747e+00,  1.5883e+00,  1.5583e+00,  1.5681e+00],
        [ 1.2735e+00,  1.2762e+00,  1.2735e+00,  1.2781e+00,  1.2762e+00,
          1.2740e+00,  1.2745e+00,  1.2732e+00,  1.2732e+00,  1.3421e+00,
          1.3443e+00,  1.3432e+00,  1.3266e+00,  1.3410e+00,  1.2831e+00,
          1.3426e+00,  1.3386e+00,  1.2816e+00,  1.2943e+00,  1.2697e+00,
          1.2956e+00,  1.2953e+00,  1.2918e+00,  1.2913e+00,  1.2868e+00,
          1.2905e+00,  1.2905e+00,  2.9279e+00,  2.8435e+00,  2.6608e+00,
          2.6851e+00,  2.9269e+00,  2.6694e+00,  2.8237e+00,  2.7215e+00,
          2.6626e+00,  1.7442e+00,  1.7556e+00,  1.7218e+00,  1.7361e+00,
          1.7536e+00,  1.7460e+00,  1.7185e+00,  1.7281e+00,  1.7360e+00,
          1.6003e+00,  1.5832e+00,  1.5248e+00,  1.5197e+00,  1.5968e+00,
          1.5783e+00,  1.6117e+00,  1.5082e+00,  1.5715e+00],
        [ 1.9085e+00,  1.5113e+00,  6.6878e-01,  9.8164e-01,  1.4064e+00,
          1.8395e+00,  1.7127e+00,  1.9445e+00,  1.9445e+00,  1.7424e+00,
          1.3781e+00,  1.5919e+00,  9.9743e-01,  1.7973e+00,  1.8681e-01,
          1.6809e+00,  1.9688e+00,  9.0112e-01,  1.4138e+00,  1.0848e+00,
          8.2810e-01,  1.2228e+00,  1.7819e+00,  1.8479e+00,  1.6270e+00,
          1.9537e+00,  1.9537e+00,  9.2699e-01,  9.1297e-01,  1.9267e+00,
          1.7136e+00,  9.2912e-01,  1.8675e+00,  1.3221e+00,  1.9752e+00,
          1.8911e+00, -1.6900e-01, -4.0728e-01, -4.5061e-01, -2.2242e-01,
          3.2907e-02,  1.1258e-01, -2.9274e-01,  1.9630e+01,  2.2745e+00,
          2.8242e-01,  6.4270e-01,  6.6422e-01,  7.7717e-01,  4.3385e-01,
          7.7859e-01, -3.0788e-03,  8.1575e-01,  8.7360e-01],
        [ 1.3323e+00,  1.3690e+00,  1.3946e+00,  1.4006e+00,  1.3757e+00,
          1.3393e+00,  1.3095e+00,  1.3286e+00,  1.3286e+00,  1.3063e+00,
          1.4257e+00,  1.3218e+00,  1.4520e+00,  1.3815e+00,  1.4771e+00,
          1.3127e+00,  1.3567e+00,  1.3674e+00,  1.3899e+00,  1.3509e+00,
          1.4219e+00,  1.4033e+00,  1.3572e+00,  1.3504e+00,  1.2344e+00,
          1.3390e+00,  1.3390e+00,  1.3737e+00,  1.4354e+00,  1.3541e+00,
          1.1445e+00,  1.3314e+00,  1.2427e+00,  1.4104e+00,  1.2316e+00,
          1.3582e+00,  3.3811e-01,  2.6145e-01,  3.7507e-01,  3.4191e-01,
          1.3684e-01,  8.6303e-02,  3.6153e-01,  1.3094e-01, -6.7148e-02,
          3.6230e+00,  2.3287e+00,  3.5754e+00,  2.6880e+00,  1.8570e+00,
          1.4505e+00,  2.9133e+00,  3.4784e+00,  1.4151e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 371 : 174.12300542576506
Test loss for epoch 371 : 174.52309052021934
Test Precision for epoch 371 : 0.26153846153846155
Test Recall for epoch 371 : 0.26153846153846155
Test F1 for epoch 371 : 0.26153846153846155


theta for epoch 372 : tensor([[ 2.7035e+00,  2.7224e+00,  2.7596e+00,  2.8825e+00,  2.8633e+00,
          2.7067e+00,  2.8504e+00,  2.7019e+00,  2.7019e+00,  1.3291e+00,
          1.3312e+00,  1.3302e+00,  1.3332e+00,  1.3281e+00,  1.3352e+00,
          1.3296e+00,  1.3264e+00,  1.2884e+00,  1.2826e+00,  1.2401e+00,
          1.2409e+00,  1.2836e+00,  1.2802e+00,  1.2797e+00,  1.2818e+00,
          1.2789e+00,  1.2789e+00,  1.2629e+00,  1.3076e+00,  1.3016e+00,
          1.3047e+00,  1.3076e+00,  1.3030e+00,  1.3058e+00,  1.2575e+00,
          1.3019e+00,  1.7372e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7461e+00,  1.6856e+00,  1.7386e+00,  1.7234e+00,  1.7381e+00,
          1.5899e+00,  1.5736e+00,  1.5703e+00,  1.5641e+00,  1.5866e+00,
          1.5689e+00,  1.6007e+00,  1.5601e+00,  1.5624e+00],
        [ 1.2821e+00,  1.2850e+00,  1.2857e+00,  1.2849e+00,  1.2855e+00,
          1.2827e+00,  1.2837e+00,  1.2819e+00,  1.2819e+00,  2.6417e+00,
          2.6567e+00,  2.6407e+00,  2.8779e+00,  2.6268e+00,  3.0239e+00,
          2.6445e+00,  2.8444e+00,  2.9981e+00,  1.2741e+00,  1.2793e+00,
          1.2321e+00,  1.2751e+00,  1.3017e+00,  1.3012e+00,  1.3028e+00,
          1.3003e+00,  1.3003e+00,  1.3022e+00,  1.2541e+00,  1.3228e+00,
          1.3261e+00,  1.2996e+00,  1.3243e+00,  1.3273e+00,  1.2969e+00,
          1.3231e+00,  1.7486e+00,  1.7605e+00,  1.7166e+00,  1.7490e+00,
          1.7584e+00,  1.7602e+00,  1.7132e+00,  1.7293e+00,  1.7489e+00,
          1.5501e+00,  1.5879e+00,  1.5843e+00,  1.5775e+00,  1.5102e+00,
          1.5828e+00,  1.5256e+00,  1.5732e+00,  1.5757e+00],
        [ 1.2670e+00,  1.2697e+00,  1.2669e+00,  1.2714e+00,  1.2696e+00,
          1.2675e+00,  1.2679e+00,  1.2668e+00,  1.2668e+00,  1.3353e+00,
          1.3375e+00,  1.3365e+00,  1.3394e+00,  1.3343e+00,  1.2813e+00,
          1.3358e+00,  1.2724e+00,  1.3239e+00,  2.7512e+00,  2.8779e+00,
          2.9186e+00,  2.7602e+00,  2.6893e+00,  2.6861e+00,  2.8539e+00,
          2.6811e+00,  2.6811e+00,  1.2630e+00,  1.2988e+00,  1.3079e+00,
          1.3110e+00,  1.2636e+00,  1.3093e+00,  1.3121e+00,  1.3079e+00,
          1.3082e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6727e+00,
          1.7505e+00,  1.7427e+00,  1.7429e+00,  1.7274e+00,  1.6726e+00,
          1.5951e+00,  1.5786e+00,  1.5752e+00,  1.5689e+00,  1.5730e+00,
          1.5738e+00,  1.5874e+00,  1.5573e+00,  1.5672e+00],
        [ 1.2733e+00,  1.2761e+00,  1.2733e+00,  1.2779e+00,  1.2760e+00,
          1.2738e+00,  1.2743e+00,  1.2730e+00,  1.2730e+00,  1.3416e+00,
          1.3438e+00,  1.3427e+00,  1.3261e+00,  1.3405e+00,  1.2826e+00,
          1.3421e+00,  1.3381e+00,  1.2811e+00,  1.2953e+00,  1.2706e+00,
          1.2966e+00,  1.2963e+00,  1.2928e+00,  1.2923e+00,  1.2878e+00,
          1.2915e+00,  1.2915e+00,  2.9298e+00,  2.8450e+00,  2.6623e+00,
          2.6864e+00,  2.9287e+00,  2.6708e+00,  2.8252e+00,  2.7230e+00,
          2.6640e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7362e+00,
          1.7538e+00,  1.7461e+00,  1.7187e+00,  1.7283e+00,  1.7361e+00,
          1.5995e+00,  1.5825e+00,  1.5241e+00,  1.5189e+00,  1.5960e+00,
          1.5775e+00,  1.6109e+00,  1.5074e+00,  1.5707e+00],
        [ 1.9081e+00,  1.5107e+00,  6.6823e-01,  9.8099e-01,  1.4058e+00,
          1.8390e+00,  1.7122e+00,  1.9440e+00,  1.9440e+00,  1.7415e+00,
          1.3772e+00,  1.5911e+00,  9.9662e-01,  1.7965e+00,  1.8609e-01,
          1.6800e+00,  1.9681e+00,  9.0018e-01,  1.4134e+00,  1.0845e+00,
          8.2759e-01,  1.2224e+00,  1.7817e+00,  1.8477e+00,  1.6269e+00,
          1.9536e+00,  1.9536e+00,  9.2642e-01,  9.1224e-01,  1.9261e+00,
          1.7130e+00,  9.2848e-01,  1.8669e+00,  1.3214e+00,  1.9747e+00,
          1.8906e+00, -1.6883e-01, -4.0705e-01, -4.5038e-01, -2.2236e-01,
          3.3038e-02,  1.1255e-01, -2.9254e-01,  1.9668e+01,  2.2590e+00,
          2.8154e-01,  6.4177e-01,  6.6327e-01,  7.7623e-01,  4.3294e-01,
          7.7763e-01, -3.8542e-03,  8.1488e-01,  8.7265e-01],
        [ 1.3334e+00,  1.3700e+00,  1.3955e+00,  1.4016e+00,  1.3767e+00,
          1.3404e+00,  1.3105e+00,  1.3297e+00,  1.3297e+00,  1.3073e+00,
          1.4267e+00,  1.3228e+00,  1.4530e+00,  1.3825e+00,  1.4780e+00,
          1.3137e+00,  1.3577e+00,  1.3684e+00,  1.3913e+00,  1.3522e+00,
          1.4233e+00,  1.4048e+00,  1.3586e+00,  1.3518e+00,  1.2357e+00,
          1.3405e+00,  1.3405e+00,  1.3746e+00,  1.4365e+00,  1.3552e+00,
          1.1457e+00,  1.3323e+00,  1.2438e+00,  1.4115e+00,  1.2327e+00,
          1.3593e+00,  3.3925e-01,  2.6262e-01,  3.7623e-01,  3.4302e-01,
          1.3801e-01,  8.7434e-02,  3.6267e-01,  1.3202e-01, -6.5759e-02,
          3.6247e+00,  2.3283e+00,  3.5769e+00,  2.6878e+00,  1.8564e+00,
          1.4498e+00,  2.9131e+00,  3.4808e+00,  1.4144e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 372 : 174.11619066641958
Test loss for epoch 372 : 174.52076039363993
Test Precision for epoch 372 : 0.26153846153846155
Test Recall for epoch 372 : 0.26153846153846155
Test F1 for epoch 372 : 0.26153846153846155


theta for epoch 373 : tensor([[ 2.7051e+00,  2.7240e+00,  2.7612e+00,  2.8843e+00,  2.8651e+00,
          2.7084e+00,  2.8522e+00,  2.7035e+00,  2.7035e+00,  1.3292e+00,
          1.3313e+00,  1.3303e+00,  1.3332e+00,  1.3282e+00,  1.3352e+00,
          1.3296e+00,  1.3264e+00,  1.2884e+00,  1.2816e+00,  1.2391e+00,
          1.2399e+00,  1.2825e+00,  1.2792e+00,  1.2787e+00,  1.2808e+00,
          1.2779e+00,  1.2779e+00,  1.2627e+00,  1.3075e+00,  1.3015e+00,
          1.3045e+00,  1.3075e+00,  1.3028e+00,  1.3056e+00,  1.2574e+00,
          1.3017e+00,  1.7370e+00,  1.7478e+00,  1.7415e+00,  1.7380e+00,
          1.7459e+00,  1.6854e+00,  1.7384e+00,  1.7232e+00,  1.7379e+00,
          1.5905e+00,  1.5743e+00,  1.5710e+00,  1.5648e+00,  1.5872e+00,
          1.5696e+00,  1.6013e+00,  1.5607e+00,  1.5631e+00],
        [ 1.2819e+00,  1.2847e+00,  1.2855e+00,  1.2847e+00,  1.2853e+00,
          1.2824e+00,  1.2835e+00,  1.2816e+00,  1.2816e+00,  2.6436e+00,
          2.6586e+00,  2.6427e+00,  2.8803e+00,  2.6289e+00,  3.0261e+00,
          2.6464e+00,  2.8468e+00,  3.0004e+00,  1.2728e+00,  1.2781e+00,
          1.2309e+00,  1.2738e+00,  1.3005e+00,  1.3000e+00,  1.3016e+00,
          1.2991e+00,  1.2991e+00,  1.3020e+00,  1.2539e+00,  1.3226e+00,
          1.3259e+00,  1.2995e+00,  1.3240e+00,  1.3271e+00,  1.2967e+00,
          1.3229e+00,  1.7484e+00,  1.7602e+00,  1.7164e+00,  1.7487e+00,
          1.7581e+00,  1.7599e+00,  1.7130e+00,  1.7292e+00,  1.7486e+00,
          1.5507e+00,  1.5885e+00,  1.5849e+00,  1.5781e+00,  1.5108e+00,
          1.5834e+00,  1.5262e+00,  1.5738e+00,  1.5763e+00],
        [ 1.2669e+00,  1.2696e+00,  1.2667e+00,  1.2713e+00,  1.2695e+00,
          1.2674e+00,  1.2678e+00,  1.2667e+00,  1.2667e+00,  1.3355e+00,
          1.3377e+00,  1.3367e+00,  1.3397e+00,  1.3345e+00,  1.2815e+00,
          1.3360e+00,  1.2726e+00,  1.3241e+00,  2.7522e+00,  2.8792e+00,
          2.9198e+00,  2.7611e+00,  2.6902e+00,  2.6870e+00,  2.8552e+00,
          2.6820e+00,  2.6820e+00,  1.2629e+00,  1.2987e+00,  1.3078e+00,
          1.3109e+00,  1.2635e+00,  1.3092e+00,  1.3121e+00,  1.3078e+00,
          1.3081e+00,  1.7412e+00,  1.7523e+00,  1.7459e+00,  1.6725e+00,
          1.7503e+00,  1.7425e+00,  1.7427e+00,  1.7272e+00,  1.6724e+00,
          1.5958e+00,  1.5793e+00,  1.5759e+00,  1.5696e+00,  1.5737e+00,
          1.5745e+00,  1.5880e+00,  1.5579e+00,  1.5680e+00],
        [ 1.2731e+00,  1.2759e+00,  1.2731e+00,  1.2778e+00,  1.2759e+00,
          1.2737e+00,  1.2742e+00,  1.2729e+00,  1.2729e+00,  1.3417e+00,
          1.3439e+00,  1.3428e+00,  1.3262e+00,  1.3406e+00,  1.2827e+00,
          1.3421e+00,  1.3382e+00,  1.2812e+00,  1.2943e+00,  1.2696e+00,
          1.2956e+00,  1.2953e+00,  1.2918e+00,  1.2913e+00,  1.2867e+00,
          1.2905e+00,  1.2905e+00,  2.9318e+00,  2.8467e+00,  2.6639e+00,
          2.6880e+00,  2.9308e+00,  2.6725e+00,  2.8269e+00,  2.7247e+00,
          2.6656e+00,  1.7442e+00,  1.7556e+00,  1.7218e+00,  1.7359e+00,
          1.7536e+00,  1.7458e+00,  1.7185e+00,  1.7281e+00,  1.7358e+00,
          1.6001e+00,  1.5831e+00,  1.5247e+00,  1.5196e+00,  1.5966e+00,
          1.5782e+00,  1.6114e+00,  1.5080e+00,  1.5714e+00],
        [ 1.9092e+00,  1.5119e+00,  6.6969e-01,  9.8225e-01,  1.4070e+00,
          1.8401e+00,  1.7133e+00,  1.9451e+00,  1.9451e+00,  1.7428e+00,
          1.3786e+00,  1.5924e+00,  9.9802e-01,  1.7978e+00,  1.8766e-01,
          1.6813e+00,  1.9693e+00,  9.0162e-01,  1.4144e+00,  1.0857e+00,
          8.2882e-01,  1.2235e+00,  1.7825e+00,  1.8486e+00,  1.6280e+00,
          1.9544e+00,  1.9544e+00,  9.2789e-01,  9.1361e-01,  1.9273e+00,
          1.7142e+00,  9.2995e-01,  1.8681e+00,  1.3227e+00,  1.9759e+00,
          1.8918e+00, -1.7050e-01, -4.0862e-01, -4.5194e-01, -2.2412e-01,
          3.1298e-02,  1.1065e-01, -2.9416e-01,  1.9704e+01,  2.2417e+00,
          2.8299e-01,  6.4316e-01,  6.6467e-01,  7.7763e-01,  4.3436e-01,
          7.7902e-01, -2.3218e-03,  8.1634e-01,  8.7404e-01],
        [ 1.3324e+00,  1.3690e+00,  1.3943e+00,  1.4007e+00,  1.3758e+00,
          1.3394e+00,  1.3096e+00,  1.3287e+00,  1.3287e+00,  1.3064e+00,
          1.4257e+00,  1.3218e+00,  1.4520e+00,  1.3815e+00,  1.4770e+00,
          1.3128e+00,  1.3568e+00,  1.3674e+00,  1.3900e+00,  1.3507e+00,
          1.4220e+00,  1.4035e+00,  1.3573e+00,  1.3505e+00,  1.2342e+00,
          1.3392e+00,  1.3392e+00,  1.3734e+00,  1.4355e+00,  1.3543e+00,
          1.1447e+00,  1.3311e+00,  1.2428e+00,  1.4105e+00,  1.2318e+00,
          1.3584e+00,  3.3815e-01,  2.6153e-01,  3.7514e-01,  3.4189e-01,
          1.3690e-01,  8.6284e-02,  3.6158e-01,  1.3081e-01, -6.6667e-02,
          3.6287e+00,  2.3302e+00,  3.5807e+00,  2.6901e+00,  1.8581e+00,
          1.4515e+00,  2.9153e+00,  3.4858e+00,  1.4161e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 373 : 174.10921940855522
Test loss for epoch 373 : 174.514504361244
Test Precision for epoch 373 : 0.26153846153846155
Test Recall for epoch 373 : 0.26153846153846155
Test F1 for epoch 373 : 0.26153846153846155


theta for epoch 374 : tensor([[ 2.7067e+00,  2.7255e+00,  2.7627e+00,  2.8860e+00,  2.8668e+00,
          2.7099e+00,  2.8539e+00,  2.7050e+00,  2.7050e+00,  1.3289e+00,
          1.3311e+00,  1.3300e+00,  1.3330e+00,  1.3279e+00,  1.3350e+00,
          1.3294e+00,  1.3262e+00,  1.2882e+00,  1.2819e+00,  1.2394e+00,
          1.2402e+00,  1.2829e+00,  1.2795e+00,  1.2790e+00,  1.2811e+00,
          1.2782e+00,  1.2782e+00,  1.2626e+00,  1.3073e+00,  1.3013e+00,
          1.3043e+00,  1.3073e+00,  1.3027e+00,  1.3054e+00,  1.2572e+00,
          1.3016e+00,  1.7371e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7460e+00,  1.6855e+00,  1.7386e+00,  1.7233e+00,  1.7381e+00,
          1.5901e+00,  1.5739e+00,  1.5706e+00,  1.5644e+00,  1.5868e+00,
          1.5692e+00,  1.6009e+00,  1.5603e+00,  1.5627e+00],
        [ 1.2818e+00,  1.2847e+00,  1.2855e+00,  1.2846e+00,  1.2852e+00,
          1.2824e+00,  1.2834e+00,  1.2815e+00,  1.2815e+00,  2.6448e+00,
          2.6598e+00,  2.6441e+00,  2.8820e+00,  2.6303e+00,  3.0278e+00,
          2.6476e+00,  2.8486e+00,  3.0020e+00,  1.2732e+00,  1.2784e+00,
          1.2312e+00,  1.2741e+00,  1.3008e+00,  1.3003e+00,  1.3019e+00,
          1.2994e+00,  1.2994e+00,  1.3018e+00,  1.2537e+00,  1.3224e+00,
          1.3257e+00,  1.2994e+00,  1.3239e+00,  1.3269e+00,  1.2965e+00,
          1.3227e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7489e+00,
          1.7583e+00,  1.7601e+00,  1.7131e+00,  1.7294e+00,  1.7488e+00,
          1.5503e+00,  1.5881e+00,  1.5845e+00,  1.5777e+00,  1.5103e+00,
          1.5830e+00,  1.5257e+00,  1.5734e+00,  1.5759e+00],
        [ 1.2667e+00,  1.2694e+00,  1.2665e+00,  1.2711e+00,  1.2693e+00,
          1.2672e+00,  1.2676e+00,  1.2665e+00,  1.2665e+00,  1.3351e+00,
          1.3373e+00,  1.3362e+00,  1.3392e+00,  1.3341e+00,  1.2811e+00,
          1.3356e+00,  1.2722e+00,  1.3236e+00,  2.7543e+00,  2.8817e+00,
          2.9221e+00,  2.7632e+00,  2.6923e+00,  2.6891e+00,  2.8577e+00,
          2.6841e+00,  2.6841e+00,  1.2625e+00,  1.2984e+00,  1.3076e+00,
          1.3106e+00,  1.2632e+00,  1.3090e+00,  1.3118e+00,  1.3075e+00,
          1.3079e+00,  1.7413e+00,  1.7524e+00,  1.7460e+00,  1.6725e+00,
          1.7504e+00,  1.7425e+00,  1.7428e+00,  1.7273e+00,  1.6724e+00,
          1.5953e+00,  1.5788e+00,  1.5754e+00,  1.5691e+00,  1.5732e+00,
          1.5740e+00,  1.5875e+00,  1.5574e+00,  1.5675e+00],
        [ 1.2730e+00,  1.2758e+00,  1.2729e+00,  1.2776e+00,  1.2757e+00,
          1.2735e+00,  1.2740e+00,  1.2727e+00,  1.2727e+00,  1.3413e+00,
          1.3436e+00,  1.3425e+00,  1.3258e+00,  1.3403e+00,  1.2824e+00,
          1.3418e+00,  1.3379e+00,  1.2809e+00,  1.2945e+00,  1.2697e+00,
          1.2959e+00,  1.2956e+00,  1.2921e+00,  1.2916e+00,  1.2869e+00,
          1.2907e+00,  1.2907e+00,  2.9337e+00,  2.8484e+00,  2.6655e+00,
          2.6895e+00,  2.9327e+00,  2.6740e+00,  2.8285e+00,  2.7264e+00,
          2.6672e+00,  1.7444e+00,  1.7558e+00,  1.7219e+00,  1.7360e+00,
          1.7537e+00,  1.7459e+00,  1.7187e+00,  1.7283e+00,  1.7359e+00,
          1.5997e+00,  1.5827e+00,  1.5243e+00,  1.5192e+00,  1.5962e+00,
          1.5778e+00,  1.6110e+00,  1.5075e+00,  1.5710e+00],
        [ 1.9091e+00,  1.5118e+00,  6.6963e-01,  9.8208e-01,  1.4069e+00,
          1.8400e+00,  1.7132e+00,  1.9451e+00,  1.9451e+00,  1.7425e+00,
          1.3783e+00,  1.5921e+00,  9.9777e-01,  1.7975e+00,  1.8750e-01,
          1.6810e+00,  1.9691e+00,  9.0128e-01,  1.4143e+00,  1.0858e+00,
          8.2868e-01,  1.2233e+00,  1.7825e+00,  1.8486e+00,  1.6282e+00,
          1.9544e+00,  1.9544e+00,  9.2779e-01,  9.1337e-01,  1.9271e+00,
          1.7140e+00,  9.2980e-01,  1.8679e+00,  1.3224e+00,  1.9757e+00,
          1.8916e+00, -1.7076e-01, -4.0881e-01, -4.5213e-01, -2.2449e-01,
          3.0975e-02,  1.1017e-01, -2.9439e-01,  1.9742e+01,  2.2261e+00,
          2.8268e-01,  6.4283e-01,  6.6432e-01,  7.7729e-01,  4.3404e-01,
          7.7867e-01, -2.5397e-03,  8.1607e-01,  8.7368e-01],
        [ 1.3330e+00,  1.3696e+00,  1.3947e+00,  1.4012e+00,  1.3763e+00,
          1.3400e+00,  1.3101e+00,  1.3293e+00,  1.3293e+00,  1.3069e+00,
          1.4263e+00,  1.3223e+00,  1.4525e+00,  1.3821e+00,  1.4775e+00,
          1.3133e+00,  1.3573e+00,  1.3679e+00,  1.3907e+00,  1.3513e+00,
          1.4227e+00,  1.4042e+00,  1.3581e+00,  1.3512e+00,  1.2348e+00,
          1.3399e+00,  1.3399e+00,  1.3738e+00,  1.4360e+00,  1.3548e+00,
          1.1452e+00,  1.3315e+00,  1.2434e+00,  1.4110e+00,  1.2323e+00,
          1.3589e+00,  3.3876e-01,  2.6216e-01,  3.7577e-01,  3.4246e-01,
          1.3752e-01,  8.6867e-02,  3.6219e-01,  1.3132e-01, -6.5835e-02,
          3.6310e+00,  2.3304e+00,  3.5828e+00,  2.6906e+00,  1.8581e+00,
          1.4515e+00,  2.9158e+00,  3.4889e+00,  1.4160e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 374 : 174.10234306206283
Test loss for epoch 374 : 174.51118350584244
Test Precision for epoch 374 : 0.26153846153846155
Test Recall for epoch 374 : 0.26153846153846155
Test F1 for epoch 374 : 0.26153846153846155


theta for epoch 375 : tensor([[ 2.7082e+00,  2.7271e+00,  2.7643e+00,  2.8878e+00,  2.8686e+00,
          2.7114e+00,  2.8557e+00,  2.7066e+00,  2.7066e+00,  1.3289e+00,
          1.3311e+00,  1.3300e+00,  1.3330e+00,  1.3279e+00,  1.3350e+00,
          1.3294e+00,  1.3262e+00,  1.2882e+00,  1.2817e+00,  1.2392e+00,
          1.2400e+00,  1.2827e+00,  1.2794e+00,  1.2789e+00,  1.2809e+00,
          1.2781e+00,  1.2781e+00,  1.2625e+00,  1.3072e+00,  1.3012e+00,
          1.3042e+00,  1.3072e+00,  1.3025e+00,  1.3053e+00,  1.2571e+00,
          1.3015e+00,  1.7371e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7460e+00,  1.6855e+00,  1.7386e+00,  1.7233e+00,  1.7381e+00,
          1.5900e+00,  1.5738e+00,  1.5705e+00,  1.5643e+00,  1.5867e+00,
          1.5691e+00,  1.6008e+00,  1.5602e+00,  1.5626e+00],
        [ 1.2817e+00,  1.2846e+00,  1.2855e+00,  1.2846e+00,  1.2851e+00,
          1.2823e+00,  1.2833e+00,  1.2815e+00,  1.2815e+00,  2.6461e+00,
          2.6612e+00,  2.6457e+00,  2.8839e+00,  2.6318e+00,  3.0296e+00,
          2.6489e+00,  2.8505e+00,  3.0038e+00,  1.2730e+00,  1.2783e+00,
          1.2311e+00,  1.2740e+00,  1.3007e+00,  1.3002e+00,  1.3018e+00,
          1.2993e+00,  1.2993e+00,  1.3017e+00,  1.2536e+00,  1.3223e+00,
          1.3256e+00,  1.2993e+00,  1.3238e+00,  1.3268e+00,  1.2964e+00,
          1.3226e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7489e+00,
          1.7583e+00,  1.7601e+00,  1.7131e+00,  1.7295e+00,  1.7489e+00,
          1.5501e+00,  1.5880e+00,  1.5844e+00,  1.5776e+00,  1.5102e+00,
          1.5829e+00,  1.5256e+00,  1.5733e+00,  1.5758e+00],
        [ 1.2667e+00,  1.2693e+00,  1.2664e+00,  1.2711e+00,  1.2692e+00,
          1.2672e+00,  1.2676e+00,  1.2664e+00,  1.2664e+00,  1.3351e+00,
          1.3373e+00,  1.3362e+00,  1.3392e+00,  1.3341e+00,  1.2811e+00,
          1.3356e+00,  1.2722e+00,  1.3236e+00,  2.7557e+00,  2.8835e+00,
          2.9238e+00,  2.7647e+00,  2.6937e+00,  2.6905e+00,  2.8595e+00,
          2.6855e+00,  2.6855e+00,  1.2624e+00,  1.2983e+00,  1.3075e+00,
          1.3105e+00,  1.2630e+00,  1.3088e+00,  1.3117e+00,  1.3074e+00,
          1.3077e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6725e+00,
          1.7504e+00,  1.7425e+00,  1.7428e+00,  1.7273e+00,  1.6724e+00,
          1.5952e+00,  1.5787e+00,  1.5753e+00,  1.5691e+00,  1.5731e+00,
          1.5740e+00,  1.5874e+00,  1.5572e+00,  1.5674e+00],
        [ 1.2729e+00,  1.2757e+00,  1.2728e+00,  1.2775e+00,  1.2756e+00,
          1.2734e+00,  1.2739e+00,  1.2726e+00,  1.2726e+00,  1.3413e+00,
          1.3435e+00,  1.3424e+00,  1.3258e+00,  1.3402e+00,  1.2824e+00,
          1.3418e+00,  1.3378e+00,  1.2809e+00,  1.2943e+00,  1.2695e+00,
          1.2957e+00,  1.2954e+00,  1.2919e+00,  1.2914e+00,  1.2867e+00,
          1.2905e+00,  1.2905e+00,  2.9357e+00,  2.8500e+00,  2.6671e+00,
          2.6910e+00,  2.9347e+00,  2.6756e+00,  2.8302e+00,  2.7281e+00,
          2.6688e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7359e+00,
          1.7537e+00,  1.7459e+00,  1.7187e+00,  1.7283e+00,  1.7359e+00,
          1.5995e+00,  1.5826e+00,  1.5243e+00,  1.5191e+00,  1.5961e+00,
          1.5776e+00,  1.6109e+00,  1.5073e+00,  1.5709e+00],
        [ 1.9097e+00,  1.5124e+00,  6.7039e-01,  9.8268e-01,  1.4075e+00,
          1.8406e+00,  1.7138e+00,  1.9456e+00,  1.9456e+00,  1.7430e+00,
          1.3789e+00,  1.5927e+00,  9.9840e-01,  1.7981e+00,  1.8826e-01,
          1.6815e+00,  1.9696e+00,  9.0190e-01,  1.4149e+00,  1.0865e+00,
          8.2931e-01,  1.2239e+00,  1.7830e+00,  1.8491e+00,  1.6289e+00,
          1.9549e+00,  1.9549e+00,  9.2853e-01,  9.1400e-01,  1.9277e+00,
          1.7145e+00,  9.3051e-01,  1.8685e+00,  1.3230e+00,  1.9762e+00,
          1.8921e+00, -1.7178e-01, -4.0973e-01, -4.5305e-01, -2.2560e-01,
          2.9888e-02,  1.0893e-01, -2.9536e-01,  1.9779e+01,  2.2100e+00,
          2.8328e-01,  6.4339e-01,  6.6488e-01,  7.7785e-01,  4.3462e-01,
          7.7923e-01, -1.8599e-03,  8.1669e-01,  8.7423e-01],
        [ 1.3327e+00,  1.3693e+00,  1.3942e+00,  1.4009e+00,  1.3760e+00,
          1.3397e+00,  1.3098e+00,  1.3290e+00,  1.3290e+00,  1.3066e+00,
          1.4259e+00,  1.3220e+00,  1.4521e+00,  1.3817e+00,  1.4772e+00,
          1.3130e+00,  1.3570e+00,  1.3675e+00,  1.3903e+00,  1.3507e+00,
          1.4223e+00,  1.4038e+00,  1.3577e+00,  1.3509e+00,  1.2342e+00,
          1.3395e+00,  1.3395e+00,  1.3733e+00,  1.4357e+00,  1.3545e+00,
          1.1449e+00,  1.3310e+00,  1.2431e+00,  1.4107e+00,  1.2320e+00,
          1.3586e+00,  3.3838e-01,  2.6180e-01,  3.7540e-01,  3.4205e-01,
          1.3713e-01,  8.6442e-02,  3.6182e-01,  1.3083e-01, -6.6021e-02,
          3.6343e+00,  2.3316e+00,  3.5860e+00,  2.6921e+00,  1.8591e+00,
          1.4524e+00,  2.9173e+00,  3.4930e+00,  1.4170e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 375 : 174.09570794415484
Test loss for epoch 375 : 174.50653310623824
Test Precision for epoch 375 : 0.26153846153846155
Test Recall for epoch 375 : 0.26153846153846155
Test F1 for epoch 375 : 0.26153846153846155


theta for epoch 376 : tensor([[ 2.7099e+00,  2.7287e+00,  2.7659e+00,  2.8896e+00,  2.8704e+00,
          2.7131e+00,  2.8575e+00,  2.7082e+00,  2.7082e+00,  1.3290e+00,
          1.3311e+00,  1.3301e+00,  1.3330e+00,  1.3279e+00,  1.3350e+00,
          1.3294e+00,  1.3262e+00,  1.2882e+00,  1.2814e+00,  1.2389e+00,
          1.2397e+00,  1.2824e+00,  1.2791e+00,  1.2786e+00,  1.2806e+00,
          1.2778e+00,  1.2778e+00,  1.2624e+00,  1.3071e+00,  1.3011e+00,
          1.3041e+00,  1.3071e+00,  1.3025e+00,  1.3052e+00,  1.2570e+00,
          1.3014e+00,  1.7371e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7460e+00,  1.6855e+00,  1.7386e+00,  1.7233e+00,  1.7381e+00,
          1.5899e+00,  1.5737e+00,  1.5704e+00,  1.5642e+00,  1.5866e+00,
          1.5690e+00,  1.6007e+00,  1.5601e+00,  1.5625e+00],
        [ 1.2816e+00,  1.2845e+00,  1.2854e+00,  1.2846e+00,  1.2850e+00,
          1.2822e+00,  1.2832e+00,  1.2813e+00,  1.2813e+00,  2.6476e+00,
          2.6627e+00,  2.6474e+00,  2.8859e+00,  2.6335e+00,  3.0315e+00,
          2.6504e+00,  2.8526e+00,  3.0057e+00,  1.2727e+00,  1.2780e+00,
          1.2308e+00,  1.2737e+00,  1.3004e+00,  1.2999e+00,  1.3015e+00,
          1.2990e+00,  1.2990e+00,  1.3016e+00,  1.2535e+00,  1.3222e+00,
          1.3255e+00,  1.2993e+00,  1.3237e+00,  1.3267e+00,  1.2963e+00,
          1.3225e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7489e+00,
          1.7583e+00,  1.7601e+00,  1.7131e+00,  1.7296e+00,  1.7489e+00,
          1.5500e+00,  1.5879e+00,  1.5843e+00,  1.5775e+00,  1.5101e+00,
          1.5828e+00,  1.5255e+00,  1.5732e+00,  1.5757e+00],
        [ 1.2666e+00,  1.2693e+00,  1.2663e+00,  1.2710e+00,  1.2692e+00,
          1.2671e+00,  1.2675e+00,  1.2664e+00,  1.2664e+00,  1.3352e+00,
          1.3374e+00,  1.3364e+00,  1.3394e+00,  1.3342e+00,  1.2812e+00,
          1.3357e+00,  1.2723e+00,  1.3238e+00,  2.7570e+00,  2.8852e+00,
          2.9252e+00,  2.7659e+00,  2.6949e+00,  2.6917e+00,  2.8611e+00,
          2.6867e+00,  2.6867e+00,  1.2623e+00,  1.2983e+00,  1.3074e+00,
          1.3105e+00,  1.2630e+00,  1.3088e+00,  1.3117e+00,  1.3074e+00,
          1.3077e+00,  1.7414e+00,  1.7525e+00,  1.7460e+00,  1.6724e+00,
          1.7505e+00,  1.7425e+00,  1.7429e+00,  1.7273e+00,  1.6724e+00,
          1.5951e+00,  1.5787e+00,  1.5753e+00,  1.5690e+00,  1.5730e+00,
          1.5739e+00,  1.5873e+00,  1.5571e+00,  1.5673e+00],
        [ 1.2728e+00,  1.2755e+00,  1.2726e+00,  1.2774e+00,  1.2755e+00,
          1.2733e+00,  1.2738e+00,  1.2725e+00,  1.2725e+00,  1.3413e+00,
          1.3435e+00,  1.3425e+00,  1.3258e+00,  1.3402e+00,  1.2824e+00,
          1.3418e+00,  1.3378e+00,  1.2809e+00,  1.2940e+00,  1.2691e+00,
          1.2954e+00,  1.2951e+00,  1.2916e+00,  1.2911e+00,  1.2863e+00,
          1.2902e+00,  1.2902e+00,  2.9377e+00,  2.8517e+00,  2.6687e+00,
          2.6925e+00,  2.9367e+00,  2.6772e+00,  2.8319e+00,  2.7297e+00,
          2.6704e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7359e+00,
          1.7537e+00,  1.7458e+00,  1.7187e+00,  1.7283e+00,  1.7358e+00,
          1.5994e+00,  1.5825e+00,  1.5242e+00,  1.5190e+00,  1.5959e+00,
          1.5775e+00,  1.6107e+00,  1.5072e+00,  1.5708e+00],
        [ 1.9101e+00,  1.5129e+00,  6.7106e-01,  9.8320e-01,  1.4080e+00,
          1.8411e+00,  1.7143e+00,  1.9461e+00,  1.9461e+00,  1.7435e+00,
          1.3794e+00,  1.5932e+00,  9.9896e-01,  1.7986e+00,  1.8893e-01,
          1.6820e+00,  1.9702e+00,  9.0245e-01,  1.4153e+00,  1.0871e+00,
          8.2983e-01,  1.2244e+00,  1.7834e+00,  1.8495e+00,  1.6294e+00,
          1.9553e+00,  1.9553e+00,  9.2919e-01,  9.1455e-01,  1.9282e+00,
          1.7150e+00,  9.3115e-01,  1.8690e+00,  1.3236e+00,  1.9767e+00,
          1.8926e+00, -1.7273e-01, -4.1058e-01, -4.5389e-01, -2.2664e-01,
          2.8872e-02,  1.0776e-01, -2.9626e-01,  1.9816e+01,  2.1941e+00,
          2.8379e-01,  6.4387e-01,  6.6536e-01,  7.7834e-01,  4.3511e-01,
          7.7970e-01, -1.2757e-03,  8.1724e-01,  8.7470e-01],
        [ 1.3325e+00,  1.3691e+00,  1.3938e+00,  1.4007e+00,  1.3758e+00,
          1.3395e+00,  1.3096e+00,  1.3288e+00,  1.3288e+00,  1.3063e+00,
          1.4257e+00,  1.3217e+00,  1.4519e+00,  1.3815e+00,  1.4769e+00,
          1.3128e+00,  1.3567e+00,  1.3673e+00,  1.3900e+00,  1.3502e+00,
          1.4219e+00,  1.4035e+00,  1.3573e+00,  1.3505e+00,  1.2337e+00,
          1.3392e+00,  1.3392e+00,  1.3729e+00,  1.4355e+00,  1.3543e+00,
          1.1446e+00,  1.3306e+00,  1.2428e+00,  1.4105e+00,  1.2318e+00,
          1.3584e+00,  3.3810e-01,  2.6153e-01,  3.7513e-01,  3.4174e-01,
          1.3685e-01,  8.6116e-02,  3.6154e-01,  1.3043e-01, -6.6109e-02,
          3.6375e+00,  2.3327e+00,  3.5890e+00,  2.6936e+00,  1.8600e+00,
          1.4533e+00,  2.9187e+00,  3.4971e+00,  1.4179e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 376 : 174.08934178111735
Test loss for epoch 376 : 174.50226952046884
Test Precision for epoch 376 : 0.26153846153846155
Test Recall for epoch 376 : 0.26153846153846155
Test F1 for epoch 376 : 0.26153846153846155


theta for epoch 377 : tensor([[ 2.7115e+00,  2.7304e+00,  2.7676e+00,  2.8915e+00,  2.8723e+00,
          2.7148e+00,  2.8594e+00,  2.7099e+00,  2.7099e+00,  1.3286e+00,
          1.3307e+00,  1.3297e+00,  1.3326e+00,  1.3275e+00,  1.3346e+00,
          1.3290e+00,  1.3258e+00,  1.2878e+00,  1.2818e+00,  1.2393e+00,
          1.2401e+00,  1.2828e+00,  1.2794e+00,  1.2790e+00,  1.2810e+00,
          1.2781e+00,  1.2781e+00,  1.2622e+00,  1.3069e+00,  1.3009e+00,
          1.3040e+00,  1.3069e+00,  1.3023e+00,  1.3051e+00,  1.2568e+00,
          1.3012e+00,  1.7371e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7461e+00,  1.6855e+00,  1.7386e+00,  1.7233e+00,  1.7382e+00,
          1.5895e+00,  1.5734e+00,  1.5700e+00,  1.5639e+00,  1.5862e+00,
          1.5687e+00,  1.6003e+00,  1.5598e+00,  1.5622e+00],
        [ 1.2815e+00,  1.2843e+00,  1.2853e+00,  1.2845e+00,  1.2848e+00,
          1.2820e+00,  1.2831e+00,  1.2812e+00,  1.2812e+00,  2.6489e+00,
          2.6640e+00,  2.6488e+00,  2.8877e+00,  2.6349e+00,  3.0332e+00,
          2.6517e+00,  2.8545e+00,  3.0075e+00,  1.2732e+00,  1.2784e+00,
          1.2312e+00,  1.2741e+00,  1.3008e+00,  1.3003e+00,  1.3019e+00,
          1.2994e+00,  1.2994e+00,  1.3015e+00,  1.2534e+00,  1.3221e+00,
          1.3254e+00,  1.2992e+00,  1.3236e+00,  1.3266e+00,  1.2962e+00,
          1.3224e+00,  1.7486e+00,  1.7605e+00,  1.7166e+00,  1.7490e+00,
          1.7583e+00,  1.7601e+00,  1.7132e+00,  1.7297e+00,  1.7490e+00,
          1.5497e+00,  1.5876e+00,  1.5840e+00,  1.5772e+00,  1.5098e+00,
          1.5825e+00,  1.5251e+00,  1.5729e+00,  1.5754e+00],
        [ 1.2664e+00,  1.2691e+00,  1.2660e+00,  1.2708e+00,  1.2689e+00,
          1.2669e+00,  1.2673e+00,  1.2661e+00,  1.2661e+00,  1.3348e+00,
          1.3369e+00,  1.3359e+00,  1.3389e+00,  1.3337e+00,  1.2807e+00,
          1.3352e+00,  1.2718e+00,  1.3233e+00,  2.7591e+00,  2.8877e+00,
          2.9276e+00,  2.7680e+00,  2.6970e+00,  2.6938e+00,  2.8636e+00,
          2.6888e+00,  2.6888e+00,  1.2620e+00,  1.2981e+00,  1.3072e+00,
          1.3103e+00,  1.2627e+00,  1.3086e+00,  1.3114e+00,  1.3072e+00,
          1.3075e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6724e+00,
          1.7505e+00,  1.7424e+00,  1.7429e+00,  1.7274e+00,  1.6724e+00,
          1.5947e+00,  1.5783e+00,  1.5749e+00,  1.5687e+00,  1.5727e+00,
          1.5735e+00,  1.5870e+00,  1.5567e+00,  1.5670e+00],
        [ 1.2726e+00,  1.2754e+00,  1.2724e+00,  1.2773e+00,  1.2754e+00,
          1.2732e+00,  1.2737e+00,  1.2724e+00,  1.2724e+00,  1.3409e+00,
          1.3432e+00,  1.3421e+00,  1.3254e+00,  1.3399e+00,  1.2821e+00,
          1.3414e+00,  1.3375e+00,  1.2806e+00,  1.2944e+00,  1.2695e+00,
          1.2958e+00,  1.2955e+00,  1.2920e+00,  1.2915e+00,  1.2867e+00,
          1.2906e+00,  1.2906e+00,  2.9397e+00,  2.8534e+00,  2.6702e+00,
          2.6940e+00,  2.9387e+00,  2.6788e+00,  2.8335e+00,  2.7314e+00,
          2.6720e+00,  1.7445e+00,  1.7559e+00,  1.7220e+00,  1.7359e+00,
          1.7538e+00,  1.7458e+00,  1.7188e+00,  1.7285e+00,  1.7359e+00,
          1.5991e+00,  1.5822e+00,  1.5240e+00,  1.5187e+00,  1.5957e+00,
          1.5773e+00,  1.6104e+00,  1.5069e+00,  1.5705e+00],
        [ 1.9102e+00,  1.5128e+00,  6.7111e-01,  9.8314e-01,  1.4079e+00,
          1.8411e+00,  1.7142e+00,  1.9461e+00,  1.9461e+00,  1.7433e+00,
          1.3792e+00,  1.5931e+00,  9.9884e-01,  1.7984e+00,  1.8891e-01,
          1.6818e+00,  1.9700e+00,  9.0227e-01,  1.4154e+00,  1.0873e+00,
          8.2987e-01,  1.2244e+00,  1.7836e+00,  1.8496e+00,  1.6297e+00,
          1.9555e+00,  1.9555e+00,  9.2924e-01,  9.1447e-01,  1.9281e+00,
          1.7150e+00,  9.3116e-01,  1.8689e+00,  1.3235e+00,  1.9767e+00,
          1.8926e+00, -1.7315e-01, -4.1091e-01, -4.5422e-01, -2.2714e-01,
          2.8390e-02,  1.0713e-01, -2.9664e-01,  1.9853e+01,  2.1791e+00,
          2.8367e-01,  6.4374e-01,  6.6521e-01,  7.7820e-01,  4.3498e-01,
          7.7955e-01, -1.3339e-03,  8.1716e-01,  8.7455e-01],
        [ 1.3329e+00,  1.3695e+00,  1.3941e+00,  1.4011e+00,  1.3762e+00,
          1.3399e+00,  1.3100e+00,  1.3292e+00,  1.3292e+00,  1.3067e+00,
          1.4261e+00,  1.3221e+00,  1.4523e+00,  1.3819e+00,  1.4772e+00,
          1.3131e+00,  1.3571e+00,  1.3677e+00,  1.3906e+00,  1.3506e+00,
          1.4225e+00,  1.4040e+00,  1.3579e+00,  1.3511e+00,  1.2342e+00,
          1.3398e+00,  1.3398e+00,  1.3732e+00,  1.4359e+00,  1.3547e+00,
          1.1451e+00,  1.3309e+00,  1.2433e+00,  1.4109e+00,  1.2322e+00,
          1.3588e+00,  3.3853e-01,  2.6198e-01,  3.7558e-01,  3.4214e-01,
          1.3729e-01,  8.6518e-02,  3.6198e-01,  1.3075e-01, -6.5466e-02,
          3.6400e+00,  2.3331e+00,  3.5913e+00,  2.6943e+00,  1.8602e+00,
          1.4534e+00,  2.9193e+00,  3.5005e+00,  1.4180e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 377 : 174.08313058777168
Test loss for epoch 377 : 174.49928603539678
Test Precision for epoch 377 : 0.26153846153846155
Test Recall for epoch 377 : 0.26153846153846155
Test F1 for epoch 377 : 0.26153846153846155


theta for epoch 378 : tensor([[ 2.7133e+00,  2.7321e+00,  2.7693e+00,  2.8934e+00,  2.8742e+00,
          2.7165e+00,  2.8613e+00,  2.7116e+00,  2.7116e+00,  1.3286e+00,
          1.3307e+00,  1.3297e+00,  1.3326e+00,  1.3276e+00,  1.3346e+00,
          1.3291e+00,  1.3259e+00,  1.2878e+00,  1.2809e+00,  1.2384e+00,
          1.2392e+00,  1.2819e+00,  1.2786e+00,  1.2781e+00,  1.2801e+00,
          1.2773e+00,  1.2773e+00,  1.2621e+00,  1.3068e+00,  1.3008e+00,
          1.3038e+00,  1.3068e+00,  1.3022e+00,  1.3049e+00,  1.2567e+00,
          1.3011e+00,  1.7370e+00,  1.7478e+00,  1.7415e+00,  1.7380e+00,
          1.7459e+00,  1.6854e+00,  1.7384e+00,  1.7231e+00,  1.7380e+00,
          1.5900e+00,  1.5738e+00,  1.5705e+00,  1.5643e+00,  1.5867e+00,
          1.5691e+00,  1.6007e+00,  1.5603e+00,  1.5627e+00],
        [ 1.2812e+00,  1.2840e+00,  1.2851e+00,  1.2843e+00,  1.2846e+00,
          1.2818e+00,  1.2828e+00,  1.2809e+00,  1.2809e+00,  2.6508e+00,
          2.6659e+00,  2.6509e+00,  2.8901e+00,  2.6370e+00,  3.0355e+00,
          2.6537e+00,  2.8569e+00,  3.0098e+00,  1.2721e+00,  1.2774e+00,
          1.2302e+00,  1.2731e+00,  1.2998e+00,  1.2993e+00,  1.3009e+00,
          1.2984e+00,  1.2984e+00,  1.3013e+00,  1.2532e+00,  1.3219e+00,
          1.3252e+00,  1.2991e+00,  1.3234e+00,  1.3264e+00,  1.2960e+00,
          1.3222e+00,  1.7484e+00,  1.7603e+00,  1.7164e+00,  1.7488e+00,
          1.7581e+00,  1.7599e+00,  1.7130e+00,  1.7296e+00,  1.7488e+00,
          1.5501e+00,  1.5880e+00,  1.5844e+00,  1.5776e+00,  1.5101e+00,
          1.5829e+00,  1.5255e+00,  1.5733e+00,  1.5758e+00],
        [ 1.2663e+00,  1.2690e+00,  1.2659e+00,  1.2707e+00,  1.2688e+00,
          1.2668e+00,  1.2672e+00,  1.2660e+00,  1.2660e+00,  1.3350e+00,
          1.3371e+00,  1.3361e+00,  1.3391e+00,  1.3339e+00,  1.2809e+00,
          1.3354e+00,  1.2720e+00,  1.3235e+00,  2.7602e+00,  2.8892e+00,
          2.9289e+00,  2.7691e+00,  2.6981e+00,  2.6949e+00,  2.8651e+00,
          2.6899e+00,  2.6899e+00,  1.2620e+00,  1.2981e+00,  1.3072e+00,
          1.3103e+00,  1.2626e+00,  1.3086e+00,  1.3114e+00,  1.3072e+00,
          1.3075e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6722e+00,
          1.7504e+00,  1.7423e+00,  1.7428e+00,  1.7272e+00,  1.6722e+00,
          1.5952e+00,  1.5788e+00,  1.5755e+00,  1.5692e+00,  1.5732e+00,
          1.5741e+00,  1.5875e+00,  1.5572e+00,  1.5675e+00],
        [ 1.2725e+00,  1.2752e+00,  1.2722e+00,  1.2771e+00,  1.2752e+00,
          1.2730e+00,  1.2735e+00,  1.2722e+00,  1.2722e+00,  1.3410e+00,
          1.3433e+00,  1.3422e+00,  1.3255e+00,  1.3400e+00,  1.2822e+00,
          1.3415e+00,  1.3376e+00,  1.2807e+00,  1.2937e+00,  1.2687e+00,
          1.2950e+00,  1.2947e+00,  1.2912e+00,  1.2907e+00,  1.2859e+00,
          1.2899e+00,  1.2899e+00,  2.9417e+00,  2.8551e+00,  2.6719e+00,
          2.6956e+00,  2.9407e+00,  2.6805e+00,  2.8353e+00,  2.7331e+00,
          2.6736e+00,  1.7443e+00,  1.7557e+00,  1.7219e+00,  1.7357e+00,
          1.7537e+00,  1.7456e+00,  1.7186e+00,  1.7283e+00,  1.7357e+00,
          1.5996e+00,  1.5826e+00,  1.5244e+00,  1.5192e+00,  1.5961e+00,
          1.5777e+00,  1.6108e+00,  1.5073e+00,  1.5710e+00],
        [ 1.9110e+00,  1.5138e+00,  6.7232e-01,  9.8417e-01,  1.4089e+00,
          1.8420e+00,  1.7152e+00,  1.9470e+00,  1.9470e+00,  1.7443e+00,
          1.3803e+00,  1.5942e+00,  1.0000e+00,  1.7995e+00,  1.9020e-01,
          1.6829e+00,  1.9711e+00,  9.0347e-01,  1.4163e+00,  1.0883e+00,
          8.3089e-01,  1.2254e+00,  1.7843e+00,  1.8503e+00,  1.6307e+00,
          1.9561e+00,  1.9561e+00,  9.3047e-01,  9.1562e-01,  1.9291e+00,
          1.7160e+00,  9.3239e-01,  1.8699e+00,  1.3246e+00,  1.9777e+00,
          1.8936e+00, -1.7462e-01, -4.1226e-01, -4.5556e-01, -2.2870e-01,
          2.6840e-02,  1.0543e-01, -2.9805e-01,  1.9889e+01,  2.1632e+00,
          2.8487e-01,  6.4491e-01,  6.6639e-01,  7.7939e-01,  4.3616e-01,
          7.8073e-01, -8.1242e-05,  8.1840e-01,  8.7572e-01],
        [ 1.3322e+00,  1.3687e+00,  1.3932e+00,  1.4003e+00,  1.3755e+00,
          1.3392e+00,  1.3093e+00,  1.3285e+00,  1.3285e+00,  1.3060e+00,
          1.4253e+00,  1.3214e+00,  1.4515e+00,  1.3812e+00,  1.4765e+00,
          1.3124e+00,  1.3564e+00,  1.3669e+00,  1.3896e+00,  1.3494e+00,
          1.4215e+00,  1.4030e+00,  1.3569e+00,  1.3501e+00,  1.2330e+00,
          1.3388e+00,  1.3388e+00,  1.3723e+00,  1.4351e+00,  1.3540e+00,
          1.1443e+00,  1.3300e+00,  1.2425e+00,  1.4102e+00,  1.2315e+00,
          1.3581e+00,  3.3767e-01,  2.6113e-01,  3.7473e-01,  3.4125e-01,
          1.3642e-01,  8.5609e-02,  3.6113e-01,  1.2976e-01, -6.6144e-02,
          3.6438e+00,  2.3349e+00,  3.5950e+00,  2.6964e+00,  1.8618e+00,
          1.4549e+00,  2.9214e+00,  3.5052e+00,  1.4195e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 378 : 174.07694482886103
Test loss for epoch 378 : 174.49414749013928
Test Precision for epoch 378 : 0.26153846153846155
Test Recall for epoch 378 : 0.26153846153846155
Test F1 for epoch 378 : 0.26153846153846155


theta for epoch 379 : tensor([[ 2.7150e+00,  2.7338e+00,  2.7710e+00,  2.8953e+00,  2.8761e+00,
          2.7182e+00,  2.8632e+00,  2.7133e+00,  2.7133e+00,  1.3282e+00,
          1.3304e+00,  1.3293e+00,  1.3323e+00,  1.3272e+00,  1.3343e+00,
          1.3287e+00,  1.3255e+00,  1.2874e+00,  1.2815e+00,  1.2390e+00,
          1.2398e+00,  1.2825e+00,  1.2792e+00,  1.2787e+00,  1.2807e+00,
          1.2779e+00,  1.2779e+00,  1.2619e+00,  1.3067e+00,  1.3007e+00,
          1.3037e+00,  1.3067e+00,  1.3020e+00,  1.3048e+00,  1.2566e+00,
          1.3010e+00,  1.7371e+00,  1.7480e+00,  1.7417e+00,  1.7382e+00,
          1.7460e+00,  1.6855e+00,  1.7386e+00,  1.7233e+00,  1.7382e+00,
          1.5893e+00,  1.5731e+00,  1.5698e+00,  1.5636e+00,  1.5860e+00,
          1.5684e+00,  1.6001e+00,  1.5596e+00,  1.5620e+00],
        [ 1.2811e+00,  1.2840e+00,  1.2851e+00,  1.2842e+00,  1.2845e+00,
          1.2817e+00,  1.2827e+00,  1.2808e+00,  1.2808e+00,  2.6520e+00,
          2.6671e+00,  2.6523e+00,  2.8918e+00,  2.6384e+00,  3.0372e+00,
          2.6548e+00,  2.8587e+00,  3.0115e+00,  1.2729e+00,  1.2781e+00,
          1.2309e+00,  1.2738e+00,  1.3006e+00,  1.3000e+00,  1.3017e+00,
          1.2992e+00,  1.2992e+00,  1.3012e+00,  1.2531e+00,  1.3218e+00,
          1.3251e+00,  1.2991e+00,  1.3233e+00,  1.3263e+00,  1.2959e+00,
          1.3221e+00,  1.7486e+00,  1.7605e+00,  1.7166e+00,  1.7490e+00,
          1.7583e+00,  1.7601e+00,  1.7132e+00,  1.7298e+00,  1.7490e+00,
          1.5494e+00,  1.5873e+00,  1.5837e+00,  1.5769e+00,  1.5095e+00,
          1.5822e+00,  1.5248e+00,  1.5726e+00,  1.5751e+00],
        [ 1.2661e+00,  1.2687e+00,  1.2656e+00,  1.2705e+00,  1.2686e+00,
          1.2666e+00,  1.2670e+00,  1.2658e+00,  1.2658e+00,  1.3344e+00,
          1.3366e+00,  1.3355e+00,  1.3385e+00,  1.3334e+00,  1.2804e+00,
          1.3349e+00,  1.2715e+00,  1.3230e+00,  2.7626e+00,  2.8919e+00,
          2.9315e+00,  2.7715e+00,  2.7004e+00,  2.6972e+00,  2.8679e+00,
          2.6922e+00,  2.6922e+00,  1.2617e+00,  1.2979e+00,  1.3070e+00,
          1.3101e+00,  1.2624e+00,  1.3084e+00,  1.3112e+00,  1.3069e+00,
          1.3073e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6723e+00,
          1.7505e+00,  1.7423e+00,  1.7430e+00,  1.7274e+00,  1.6722e+00,
          1.5945e+00,  1.5781e+00,  1.5747e+00,  1.5684e+00,  1.5724e+00,
          1.5733e+00,  1.5867e+00,  1.5564e+00,  1.5667e+00],
        [ 1.2724e+00,  1.2751e+00,  1.2720e+00,  1.2770e+00,  1.2751e+00,
          1.2729e+00,  1.2734e+00,  1.2721e+00,  1.2721e+00,  1.3407e+00,
          1.3429e+00,  1.3418e+00,  1.3251e+00,  1.3396e+00,  1.2818e+00,
          1.3411e+00,  1.3372e+00,  1.2804e+00,  1.2943e+00,  1.2692e+00,
          1.2956e+00,  1.2953e+00,  1.2918e+00,  1.2913e+00,  1.2864e+00,
          1.2905e+00,  1.2905e+00,  2.9437e+00,  2.8568e+00,  2.6735e+00,
          2.6971e+00,  2.9427e+00,  2.6821e+00,  2.8370e+00,  2.7348e+00,
          2.6752e+00,  1.7445e+00,  1.7559e+00,  1.7221e+00,  1.7358e+00,
          1.7538e+00,  1.7457e+00,  1.7188e+00,  1.7285e+00,  1.7358e+00,
          1.5989e+00,  1.5820e+00,  1.5238e+00,  1.5185e+00,  1.5955e+00,
          1.5771e+00,  1.6102e+00,  1.5066e+00,  1.5703e+00],
        [ 1.9108e+00,  1.5135e+00,  6.7206e-01,  9.8382e-01,  1.4086e+00,
          1.8417e+00,  1.7149e+00,  1.9468e+00,  1.9468e+00,  1.7438e+00,
          1.3798e+00,  1.5937e+00,  9.9955e-01,  1.7991e+00,  1.8982e-01,
          1.6824e+00,  1.9706e+00,  9.0293e-01,  1.4161e+00,  1.0882e+00,
          8.3063e-01,  1.2251e+00,  1.7842e+00,  1.8503e+00,  1.6307e+00,
          1.9561e+00,  1.9561e+00,  9.3019e-01,  9.1521e-01,  1.9288e+00,
          1.7156e+00,  9.3206e-01,  1.8696e+00,  1.3242e+00,  1.9774e+00,
          1.8933e+00, -1.7473e-01, -4.1229e-01, -4.5559e-01, -2.2889e-01,
          2.6664e-02,  1.0510e-01, -2.9812e-01,  1.9927e+01,  2.1489e+00,
          2.8437e-01,  6.4440e-01,  6.6586e-01,  7.7886e-01,  4.3564e-01,
          7.8019e-01, -5.3172e-04,  8.1794e-01,  8.7518e-01],
        [ 1.3329e+00,  1.3695e+00,  1.3937e+00,  1.4010e+00,  1.3762e+00,
          1.3399e+00,  1.3100e+00,  1.3292e+00,  1.3292e+00,  1.3067e+00,
          1.4260e+00,  1.3221e+00,  1.4522e+00,  1.3819e+00,  1.4771e+00,
          1.3131e+00,  1.3571e+00,  1.3676e+00,  1.3906e+00,  1.3503e+00,
          1.4225e+00,  1.4040e+00,  1.3579e+00,  1.3511e+00,  1.2339e+00,
          1.3398e+00,  1.3398e+00,  1.3729e+00,  1.4359e+00,  1.3548e+00,
          1.1451e+00,  1.3306e+00,  1.2433e+00,  1.4109e+00,  1.2322e+00,
          1.3589e+00,  3.3847e-01,  2.6194e-01,  3.7554e-01,  3.4201e-01,
          1.3722e-01,  8.6373e-02,  3.6193e-01,  1.3046e-01, -6.5141e-02,
          3.6459e+00,  2.3349e+00,  3.5969e+00,  2.6967e+00,  1.8616e+00,
          1.4547e+00,  2.9217e+00,  3.5082e+00,  1.4192e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 379 : 174.0706905988155
Test loss for epoch 379 : 174.4916930747105
Test Precision for epoch 379 : 0.26153846153846155
Test Recall for epoch 379 : 0.26153846153846155
Test F1 for epoch 379 : 0.26153846153846155


theta for epoch 380 : tensor([[ 2.7166e+00,  2.7355e+00,  2.7727e+00,  2.8972e+00,  2.8780e+00,
          2.7199e+00,  2.8651e+00,  2.7150e+00,  2.7150e+00,  1.3284e+00,
          1.3305e+00,  1.3295e+00,  1.3324e+00,  1.3274e+00,  1.3344e+00,
          1.3289e+00,  1.3257e+00,  1.2876e+00,  1.2808e+00,  1.2382e+00,
          1.2390e+00,  1.2817e+00,  1.2784e+00,  1.2779e+00,  1.2800e+00,
          1.2771e+00,  1.2771e+00,  1.2619e+00,  1.3066e+00,  1.3006e+00,
          1.3036e+00,  1.3066e+00,  1.3020e+00,  1.3047e+00,  1.2565e+00,
          1.3009e+00,  1.7370e+00,  1.7479e+00,  1.7416e+00,  1.7381e+00,
          1.7459e+00,  1.6854e+00,  1.7385e+00,  1.7232e+00,  1.7381e+00,
          1.5896e+00,  1.5734e+00,  1.5701e+00,  1.5640e+00,  1.5863e+00,
          1.5687e+00,  1.6004e+00,  1.5599e+00,  1.5623e+00],
        [ 1.2810e+00,  1.2838e+00,  1.2850e+00,  1.2842e+00,  1.2844e+00,
          1.2816e+00,  1.2826e+00,  1.2807e+00,  1.2807e+00,  2.6537e+00,
          2.6688e+00,  2.6541e+00,  2.8939e+00,  2.6402e+00,  3.0393e+00,
          2.6565e+00,  2.8609e+00,  3.0136e+00,  1.2720e+00,  1.2773e+00,
          1.2300e+00,  1.2730e+00,  1.2997e+00,  1.2992e+00,  1.3008e+00,
          1.2983e+00,  1.2983e+00,  1.3011e+00,  1.2529e+00,  1.3217e+00,
          1.3250e+00,  1.2990e+00,  1.3232e+00,  1.3262e+00,  1.2958e+00,
          1.3220e+00,  1.7485e+00,  1.7603e+00,  1.7164e+00,  1.7489e+00,
          1.7582e+00,  1.7600e+00,  1.7130e+00,  1.7298e+00,  1.7489e+00,
          1.5497e+00,  1.5876e+00,  1.5840e+00,  1.5772e+00,  1.5097e+00,
          1.5825e+00,  1.5251e+00,  1.5729e+00,  1.5754e+00],
        [ 1.2661e+00,  1.2688e+00,  1.2656e+00,  1.2705e+00,  1.2686e+00,
          1.2666e+00,  1.2670e+00,  1.2658e+00,  1.2658e+00,  1.3348e+00,
          1.3369e+00,  1.3359e+00,  1.3389e+00,  1.3337e+00,  1.2807e+00,
          1.3352e+00,  1.2718e+00,  1.3233e+00,  2.7635e+00,  2.8932e+00,
          2.9327e+00,  2.7724e+00,  2.7013e+00,  2.6981e+00,  2.8692e+00,
          2.6931e+00,  2.6931e+00,  1.2616e+00,  1.2979e+00,  1.3070e+00,
          1.3101e+00,  1.2623e+00,  1.3084e+00,  1.3112e+00,  1.3069e+00,
          1.3073e+00,  1.7414e+00,  1.7525e+00,  1.7461e+00,  1.6722e+00,
          1.7505e+00,  1.7422e+00,  1.7429e+00,  1.7273e+00,  1.6721e+00,
          1.5949e+00,  1.5784e+00,  1.5751e+00,  1.5688e+00,  1.5728e+00,
          1.5737e+00,  1.5871e+00,  1.5567e+00,  1.5671e+00],
        [ 1.2723e+00,  1.2750e+00,  1.2719e+00,  1.2769e+00,  1.2750e+00,
          1.2728e+00,  1.2733e+00,  1.2720e+00,  1.2720e+00,  1.3408e+00,
          1.3430e+00,  1.3420e+00,  1.3253e+00,  1.3397e+00,  1.2820e+00,
          1.3413e+00,  1.3374e+00,  1.2805e+00,  1.2935e+00,  1.2684e+00,
          1.2948e+00,  1.2945e+00,  1.2910e+00,  1.2905e+00,  1.2856e+00,
          1.2897e+00,  1.2897e+00,  2.9458e+00,  2.8586e+00,  2.6752e+00,
          2.6987e+00,  2.9448e+00,  2.6837e+00,  2.8387e+00,  2.7366e+00,
          2.6769e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7356e+00,
          1.7537e+00,  1.7455e+00,  1.7187e+00,  1.7285e+00,  1.7356e+00,
          1.5992e+00,  1.5823e+00,  1.5241e+00,  1.5188e+00,  1.5957e+00,
          1.5774e+00,  1.6105e+00,  1.5068e+00,  1.5706e+00],
        [ 1.9118e+00,  1.5146e+00,  6.7336e-01,  9.8494e-01,  1.4097e+00,
          1.8427e+00,  1.7159e+00,  1.9477e+00,  1.9477e+00,  1.7450e+00,
          1.3810e+00,  1.5949e+00,  1.0008e+00,  1.8002e+00,  1.9120e-01,
          1.6835e+00,  1.9717e+00,  9.0423e-01,  1.4170e+00,  1.0893e+00,
          8.3173e-01,  1.2261e+00,  1.7850e+00,  1.8511e+00,  1.6317e+00,
          1.9568e+00,  1.9568e+00,  9.3149e-01,  9.1643e-01,  1.9298e+00,
          1.7167e+00,  9.3336e-01,  1.8706e+00,  1.3253e+00,  1.9784e+00,
          1.8943e+00, -1.7625e-01, -4.1369e-01, -4.5698e-01, -2.3050e-01,
          2.5048e-02,  1.0334e-01, -2.9959e-01,  1.9963e+01,  2.1333e+00,
          2.8564e-01,  6.4564e-01,  6.6711e-01,  7.8011e-01,  4.3691e-01,
          7.8143e-01,  7.8722e-04,  8.1924e-01,  8.7641e-01],
        [ 1.3320e+00,  1.3686e+00,  1.3927e+00,  1.4001e+00,  1.3753e+00,
          1.3390e+00,  1.3091e+00,  1.3283e+00,  1.3283e+00,  1.3058e+00,
          1.4251e+00,  1.3212e+00,  1.4513e+00,  1.3810e+00,  1.4762e+00,
          1.3122e+00,  1.3562e+00,  1.3667e+00,  1.3894e+00,  1.3489e+00,
          1.4212e+00,  1.4028e+00,  1.3568e+00,  1.3499e+00,  1.2325e+00,
          1.3386e+00,  1.3386e+00,  1.3718e+00,  1.4350e+00,  1.3539e+00,
          1.1441e+00,  1.3295e+00,  1.2424e+00,  1.4100e+00,  1.2313e+00,
          1.3580e+00,  3.3744e-01,  2.6092e-01,  3.7452e-01,  3.4095e-01,
          1.3617e-01,  8.5283e-02,  3.6090e-01,  1.2929e-01, -6.6006e-02,
          3.6500e+00,  2.3369e+00,  3.6009e+00,  2.6990e+00,  1.8633e+00,
          1.4564e+00,  2.9240e+00,  3.5132e+00,  1.4209e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 380 : 174.0643459672458
Test loss for epoch 380 : 174.4861899127625
Test Precision for epoch 380 : 0.26153846153846155
Test Recall for epoch 380 : 0.26153846153846155
Test F1 for epoch 380 : 0.26153846153846155


theta for epoch 381 : tensor([[ 2.7183e+00,  2.7371e+00,  2.7743e+00,  2.8990e+00,  2.8798e+00,
          2.7215e+00,  2.8670e+00,  2.7166e+00,  2.7166e+00,  1.3282e+00,
          1.3303e+00,  1.3292e+00,  1.3322e+00,  1.3271e+00,  1.3342e+00,
          1.3286e+00,  1.3254e+00,  1.2874e+00,  1.2812e+00,  1.2387e+00,
          1.2395e+00,  1.2822e+00,  1.2789e+00,  1.2784e+00,  1.2804e+00,
          1.2776e+00,  1.2776e+00,  1.2617e+00,  1.3064e+00,  1.3004e+00,
          1.3035e+00,  1.3064e+00,  1.3018e+00,  1.3046e+00,  1.2564e+00,
          1.3007e+00,  1.7372e+00,  1.7480e+00,  1.7418e+00,  1.7383e+00,
          1.7461e+00,  1.6855e+00,  1.7386e+00,  1.7233e+00,  1.7383e+00,
          1.5891e+00,  1.5729e+00,  1.5696e+00,  1.5634e+00,  1.5857e+00,
          1.5682e+00,  1.5998e+00,  1.5593e+00,  1.5617e+00],
        [ 1.2809e+00,  1.2838e+00,  1.2850e+00,  1.2841e+00,  1.2843e+00,
          1.2815e+00,  1.2825e+00,  1.2807e+00,  1.2807e+00,  2.6550e+00,
          2.6701e+00,  2.6555e+00,  2.8957e+00,  2.6416e+00,  3.0410e+00,
          2.6578e+00,  2.8627e+00,  3.0154e+00,  1.2725e+00,  1.2778e+00,
          1.2306e+00,  1.2735e+00,  1.3003e+00,  1.2997e+00,  1.3014e+00,
          1.2989e+00,  1.2989e+00,  1.3010e+00,  1.2528e+00,  1.3216e+00,
          1.3249e+00,  1.2989e+00,  1.3230e+00,  1.3261e+00,  1.2957e+00,
          1.3219e+00,  1.7486e+00,  1.7605e+00,  1.7166e+00,  1.7491e+00,
          1.7584e+00,  1.7602e+00,  1.7132e+00,  1.7300e+00,  1.7491e+00,
          1.5491e+00,  1.5870e+00,  1.5834e+00,  1.5767e+00,  1.5092e+00,
          1.5819e+00,  1.5245e+00,  1.5723e+00,  1.5749e+00],
        [ 1.2659e+00,  1.2686e+00,  1.2653e+00,  1.2703e+00,  1.2685e+00,
          1.2664e+00,  1.2668e+00,  1.2656e+00,  1.2656e+00,  1.3344e+00,
          1.3365e+00,  1.3355e+00,  1.3384e+00,  1.3333e+00,  1.2803e+00,
          1.3348e+00,  1.2714e+00,  1.3229e+00,  2.7657e+00,  2.8958e+00,
          2.9350e+00,  2.7746e+00,  2.7035e+00,  2.7003e+00,  2.8718e+00,
          2.6953e+00,  2.6953e+00,  1.2613e+00,  1.2977e+00,  1.3067e+00,
          1.3098e+00,  1.2620e+00,  1.3081e+00,  1.3110e+00,  1.3067e+00,
          1.3070e+00,  1.7416e+00,  1.7526e+00,  1.7462e+00,  1.6722e+00,
          1.7506e+00,  1.7423e+00,  1.7430e+00,  1.7274e+00,  1.6722e+00,
          1.5942e+00,  1.5778e+00,  1.5745e+00,  1.5682e+00,  1.5722e+00,
          1.5730e+00,  1.5865e+00,  1.5560e+00,  1.5665e+00],
        [ 1.2721e+00,  1.2749e+00,  1.2717e+00,  1.2767e+00,  1.2749e+00,
          1.2727e+00,  1.2732e+00,  1.2719e+00,  1.2719e+00,  1.3405e+00,
          1.3427e+00,  1.3416e+00,  1.3250e+00,  1.3394e+00,  1.2817e+00,
          1.3410e+00,  1.3370e+00,  1.2802e+00,  1.2939e+00,  1.2688e+00,
          1.2952e+00,  1.2949e+00,  1.2914e+00,  1.2909e+00,  1.2860e+00,
          1.2901e+00,  1.2901e+00,  2.9479e+00,  2.8603e+00,  2.6768e+00,
          2.7003e+00,  2.9468e+00,  2.6854e+00,  2.8405e+00,  2.7383e+00,
          2.6786e+00,  1.7446e+00,  1.7559e+00,  1.7221e+00,  1.7357e+00,
          1.7539e+00,  1.7456e+00,  1.7189e+00,  1.7287e+00,  1.7357e+00,
          1.5986e+00,  1.5817e+00,  1.5236e+00,  1.5182e+00,  1.5952e+00,
          1.5768e+00,  1.6099e+00,  1.5062e+00,  1.5700e+00],
        [ 1.9116e+00,  1.5143e+00,  6.7318e-01,  9.8467e-01,  1.4095e+00,
          1.8425e+00,  1.7157e+00,  1.9476e+00,  1.9476e+00,  1.7446e+00,
          1.3806e+00,  1.5946e+00,  1.0005e+00,  1.7999e+00,  1.9092e-01,
          1.6832e+00,  1.9714e+00,  9.0381e-01,  1.4169e+00,  1.0893e+00,
          8.3154e-01,  1.2260e+00,  1.7850e+00,  1.8510e+00,  1.6318e+00,
          1.9568e+00,  1.9568e+00,  9.3128e-01,  9.1609e-01,  1.9295e+00,
          1.7163e+00,  9.3311e-01,  1.8703e+00,  1.3250e+00,  1.9781e+00,
          1.8940e+00, -1.7644e-01, -4.1379e-01, -4.5707e-01, -2.3076e-01,
          2.4790e-02,  1.0293e-01, -2.9973e-01,  2.0000e+01,  2.1195e+00,
          2.8526e-01,  6.4525e-01,  6.6670e-01,  7.7970e-01,  4.3651e-01,
          7.8101e-01,  4.4982e-04,  8.1889e-01,  8.7598e-01],
        [ 1.3327e+00,  1.3692e+00,  1.3931e+00,  1.4007e+00,  1.3759e+00,
          1.3396e+00,  1.3097e+00,  1.3289e+00,  1.3289e+00,  1.3064e+00,
          1.4258e+00,  1.3218e+00,  1.4519e+00,  1.3816e+00,  1.4768e+00,
          1.3128e+00,  1.3568e+00,  1.3673e+00,  1.3902e+00,  1.3496e+00,
          1.4221e+00,  1.4036e+00,  1.3576e+00,  1.3508e+00,  1.2332e+00,
          1.3394e+00,  1.3394e+00,  1.3723e+00,  1.4355e+00,  1.3545e+00,
          1.1448e+00,  1.3300e+00,  1.2430e+00,  1.4106e+00,  1.2319e+00,
          1.3586e+00,  3.3812e-01,  2.6160e-01,  3.7520e-01,  3.4160e-01,
          1.3684e-01,  8.5924e-02,  3.6158e-01,  1.2985e-01, -6.5133e-02,
          3.6523e+00,  2.3370e+00,  3.6030e+00,  2.6995e+00,  1.8633e+00,
          1.4563e+00,  2.9244e+00,  3.5164e+00,  1.4208e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 381 : 174.05797190495107
Test loss for epoch 381 : 174.48339446025807
Test Precision for epoch 381 : 0.26153846153846155
Test Recall for epoch 381 : 0.26153846153846155
Test F1 for epoch 381 : 0.26153846153846155


theta for epoch 382 : tensor([[ 2.7200e+00,  2.7389e+00,  2.7761e+00,  2.9010e+00,  2.8818e+00,
          2.7233e+00,  2.8689e+00,  2.7184e+00,  2.7184e+00,  1.3281e+00,
          1.3302e+00,  1.3292e+00,  1.3321e+00,  1.3271e+00,  1.3341e+00,
          1.3286e+00,  1.3254e+00,  1.2873e+00,  1.2807e+00,  1.2381e+00,
          1.2389e+00,  1.2817e+00,  1.2783e+00,  1.2779e+00,  1.2799e+00,
          1.2771e+00,  1.2771e+00,  1.2616e+00,  1.3063e+00,  1.3003e+00,
          1.3034e+00,  1.3063e+00,  1.3017e+00,  1.3045e+00,  1.2562e+00,
          1.3006e+00,  1.7370e+00,  1.7479e+00,  1.7416e+00,  1.7381e+00,
          1.7459e+00,  1.6854e+00,  1.7385e+00,  1.7232e+00,  1.7382e+00,
          1.5893e+00,  1.5732e+00,  1.5699e+00,  1.5637e+00,  1.5860e+00,
          1.5685e+00,  1.6001e+00,  1.5596e+00,  1.5620e+00],
        [ 1.2807e+00,  1.2836e+00,  1.2849e+00,  1.2840e+00,  1.2841e+00,
          1.2813e+00,  1.2824e+00,  1.2805e+00,  1.2805e+00,  2.6567e+00,
          2.6719e+00,  2.6575e+00,  2.8979e+00,  2.6435e+00,  3.0432e+00,
          2.6596e+00,  2.8650e+00,  3.0176e+00,  1.2719e+00,  1.2772e+00,
          1.2299e+00,  1.2728e+00,  1.2996e+00,  1.2991e+00,  1.3007e+00,
          1.2982e+00,  1.2982e+00,  1.3008e+00,  1.2526e+00,  1.3214e+00,
          1.3247e+00,  1.2988e+00,  1.3229e+00,  1.3259e+00,  1.2955e+00,
          1.3217e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7489e+00,
          1.7582e+00,  1.7600e+00,  1.7130e+00,  1.7299e+00,  1.7489e+00,
          1.5494e+00,  1.5873e+00,  1.5837e+00,  1.5769e+00,  1.5094e+00,
          1.5822e+00,  1.5248e+00,  1.5726e+00,  1.5751e+00],
        [ 1.2658e+00,  1.2685e+00,  1.2652e+00,  1.2702e+00,  1.2683e+00,
          1.2663e+00,  1.2667e+00,  1.2655e+00,  1.2655e+00,  1.3344e+00,
          1.3365e+00,  1.3355e+00,  1.3385e+00,  1.3333e+00,  1.2803e+00,
          1.3348e+00,  1.2714e+00,  1.3230e+00,  2.7671e+00,  2.8976e+00,
          2.9367e+00,  2.7760e+00,  2.7049e+00,  2.7017e+00,  2.8736e+00,
          2.6967e+00,  2.6967e+00,  1.2612e+00,  1.2976e+00,  1.3066e+00,
          1.3097e+00,  1.2619e+00,  1.3080e+00,  1.3109e+00,  1.3066e+00,
          1.3069e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6721e+00,
          1.7505e+00,  1.7421e+00,  1.7429e+00,  1.7273e+00,  1.6720e+00,
          1.5945e+00,  1.5781e+00,  1.5748e+00,  1.5685e+00,  1.5725e+00,
          1.5734e+00,  1.5868e+00,  1.5563e+00,  1.5668e+00],
        [ 1.2720e+00,  1.2747e+00,  1.2715e+00,  1.2766e+00,  1.2747e+00,
          1.2725e+00,  1.2730e+00,  1.2717e+00,  1.2717e+00,  1.3404e+00,
          1.3426e+00,  1.3416e+00,  1.3249e+00,  1.3394e+00,  1.2816e+00,
          1.3409e+00,  1.3370e+00,  1.2802e+00,  1.2933e+00,  1.2682e+00,
          1.2947e+00,  1.2944e+00,  1.2909e+00,  1.2904e+00,  1.2854e+00,
          1.2895e+00,  1.2895e+00,  2.9500e+00,  2.8622e+00,  2.6786e+00,
          2.7020e+00,  2.9490e+00,  2.6871e+00,  2.8424e+00,  2.7401e+00,
          2.6803e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7355e+00,
          1.7537e+00,  1.7454e+00,  1.7187e+00,  1.7285e+00,  1.7356e+00,
          1.5989e+00,  1.5820e+00,  1.5239e+00,  1.5185e+00,  1.5954e+00,
          1.5771e+00,  1.6101e+00,  1.5064e+00,  1.5703e+00],
        [ 1.9124e+00,  1.5152e+00,  6.7423e-01,  9.8557e-01,  1.4103e+00,
          1.8433e+00,  1.7165e+00,  1.9483e+00,  1.9483e+00,  1.7454e+00,
          1.3815e+00,  1.5955e+00,  1.0014e+00,  1.8007e+00,  1.9202e-01,
          1.6840e+00,  1.9723e+00,  9.0482e-01,  1.4177e+00,  1.0903e+00,
          8.3246e-01,  1.2268e+00,  1.7857e+00,  1.8517e+00,  1.6327e+00,
          1.9575e+00,  1.9575e+00,  9.3233e-01,  9.1707e-01,  1.9303e+00,
          1.7172e+00,  9.3416e-01,  1.8712e+00,  1.3259e+00,  1.9789e+00,
          1.8948e+00, -1.7776e-01, -4.1499e-01, -4.5826e-01, -2.3216e-01,
          2.3382e-02,  1.0138e-01, -3.0099e-01,  2.0036e+01,  2.1046e+00,
          2.8630e-01,  6.4626e-01,  6.6772e-01,  7.8072e-01,  4.3754e-01,
          7.8201e-01,  1.5276e-03,  8.1995e-01,  8.7697e-01],
        [ 1.3321e+00,  1.3686e+00,  1.3924e+00,  1.4002e+00,  1.3753e+00,
          1.3391e+00,  1.3092e+00,  1.3284e+00,  1.3284e+00,  1.3058e+00,
          1.4252e+00,  1.3212e+00,  1.4513e+00,  1.3810e+00,  1.4761e+00,
          1.3122e+00,  1.3562e+00,  1.3667e+00,  1.3895e+00,  1.3487e+00,
          1.4213e+00,  1.4029e+00,  1.3568e+00,  1.3500e+00,  1.2323e+00,
          1.3387e+00,  1.3387e+00,  1.3715e+00,  1.4349e+00,  1.3539e+00,
          1.1442e+00,  1.3292e+00,  1.2424e+00,  1.4100e+00,  1.2313e+00,
          1.3580e+00,  3.3742e-01,  2.6091e-01,  3.7451e-01,  3.4088e-01,
          1.3614e-01,  8.5177e-02,  3.6089e-01,  1.2903e-01, -6.5653e-02,
          3.6560e+00,  2.3387e+00,  3.6066e+00,  2.7015e+00,  1.8647e+00,
          1.4576e+00,  2.9263e+00,  3.5210e+00,  1.4222e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 382 : 174.05163091448512
Test loss for epoch 382 : 174.47833482794096
Test Precision for epoch 382 : 0.26153846153846155
Test Recall for epoch 382 : 0.26153846153846155
Test F1 for epoch 382 : 0.26153846153846155


theta for epoch 383 : tensor([[ 2.7219e+00,  2.7407e+00,  2.7779e+00,  2.9030e+00,  2.8838e+00,
          2.7251e+00,  2.8709e+00,  2.7202e+00,  2.7202e+00,  1.3278e+00,
          1.3300e+00,  1.3289e+00,  1.3319e+00,  1.3268e+00,  1.3339e+00,
          1.3283e+00,  1.3251e+00,  1.2870e+00,  1.2807e+00,  1.2381e+00,
          1.2389e+00,  1.2817e+00,  1.2784e+00,  1.2779e+00,  1.2799e+00,
          1.2771e+00,  1.2771e+00,  1.2614e+00,  1.3062e+00,  1.3002e+00,
          1.3032e+00,  1.3062e+00,  1.3015e+00,  1.3043e+00,  1.2561e+00,
          1.3005e+00,  1.7371e+00,  1.7479e+00,  1.7416e+00,  1.7382e+00,
          1.7459e+00,  1.6854e+00,  1.7385e+00,  1.7232e+00,  1.7382e+00,
          1.5891e+00,  1.5729e+00,  1.5696e+00,  1.5634e+00,  1.5857e+00,
          1.5682e+00,  1.5998e+00,  1.5593e+00,  1.5617e+00],
        [ 1.2806e+00,  1.2834e+00,  1.2848e+00,  1.2839e+00,  1.2840e+00,
          1.2811e+00,  1.2822e+00,  1.2803e+00,  1.2803e+00,  2.6583e+00,
          2.6734e+00,  2.6592e+00,  2.9000e+00,  2.6453e+00,  3.0452e+00,
          2.6611e+00,  2.8672e+00,  3.0196e+00,  1.2719e+00,  1.2772e+00,
          1.2299e+00,  1.2729e+00,  1.2997e+00,  1.2991e+00,  1.3008e+00,
          1.2983e+00,  1.2983e+00,  1.3006e+00,  1.2524e+00,  1.3212e+00,
          1.3245e+00,  1.2987e+00,  1.3227e+00,  1.3257e+00,  1.2953e+00,
          1.3215e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7489e+00,
          1.7582e+00,  1.7601e+00,  1.7131e+00,  1.7300e+00,  1.7490e+00,
          1.5491e+00,  1.5870e+00,  1.5834e+00,  1.5766e+00,  1.5091e+00,
          1.5819e+00,  1.5245e+00,  1.5723e+00,  1.5748e+00],
        [ 1.2656e+00,  1.2683e+00,  1.2650e+00,  1.2700e+00,  1.2682e+00,
          1.2661e+00,  1.2665e+00,  1.2654e+00,  1.2654e+00,  1.3341e+00,
          1.3362e+00,  1.3352e+00,  1.3382e+00,  1.3331e+00,  1.2800e+00,
          1.3346e+00,  1.2712e+00,  1.3227e+00,  2.7691e+00,  2.8999e+00,
          2.9389e+00,  2.7780e+00,  2.7068e+00,  2.7036e+00,  2.8759e+00,
          2.6986e+00,  2.6986e+00,  1.2610e+00,  1.2974e+00,  1.3065e+00,
          1.3096e+00,  1.2617e+00,  1.3079e+00,  1.3107e+00,  1.3064e+00,
          1.3068e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6720e+00,
          1.7505e+00,  1.7421e+00,  1.7430e+00,  1.7273e+00,  1.6720e+00,
          1.5943e+00,  1.5778e+00,  1.5745e+00,  1.5682e+00,  1.5722e+00,
          1.5731e+00,  1.5865e+00,  1.5559e+00,  1.5665e+00],
        [ 1.2719e+00,  1.2746e+00,  1.2713e+00,  1.2765e+00,  1.2746e+00,
          1.2724e+00,  1.2729e+00,  1.2716e+00,  1.2716e+00,  1.3402e+00,
          1.3424e+00,  1.3413e+00,  1.3247e+00,  1.3391e+00,  1.2814e+00,
          1.3407e+00,  1.3368e+00,  1.2800e+00,  1.2934e+00,  1.2682e+00,
          1.2947e+00,  1.2944e+00,  1.2909e+00,  1.2904e+00,  1.2854e+00,
          1.2896e+00,  1.2896e+00,  2.9521e+00,  2.8640e+00,  2.6803e+00,
          2.7036e+00,  2.9511e+00,  2.6888e+00,  2.8442e+00,  2.7419e+00,
          2.6820e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7355e+00,
          1.7538e+00,  1.7454e+00,  1.7188e+00,  1.7286e+00,  1.7355e+00,
          1.5986e+00,  1.5817e+00,  1.5236e+00,  1.5182e+00,  1.5952e+00,
          1.5768e+00,  1.6099e+00,  1.5060e+00,  1.5700e+00],
        [ 1.9125e+00,  1.5153e+00,  6.7445e-01,  9.8568e-01,  1.4104e+00,
          1.8434e+00,  1.7166e+00,  1.9485e+00,  1.9485e+00,  1.7455e+00,
          1.3816e+00,  1.5955e+00,  1.0015e+00,  1.8008e+00,  1.9219e-01,
          1.6841e+00,  1.9724e+00,  9.0488e-01,  1.4179e+00,  1.0905e+00,
          8.3263e-01,  1.2270e+00,  1.7859e+00,  1.8519e+00,  1.6330e+00,
          1.9577e+00,  1.9577e+00,  9.3255e-01,  9.1718e-01,  1.9304e+00,
          1.7173e+00,  9.3435e-01,  1.8713e+00,  1.3260e+00,  1.9790e+00,
          1.8949e+00, -1.7832e-01, -4.1545e-01, -4.5871e-01, -2.3279e-01,
          2.2744e-02,  1.0059e-01, -3.0150e-01,  2.0073e+01,  2.0908e+00,
          2.8640e-01,  6.4634e-01,  6.6778e-01,  7.8077e-01,  4.3763e-01,
          7.8206e-01,  1.6629e-03,  8.2006e-01,  8.7701e-01],
        [ 1.3323e+00,  1.3689e+00,  1.3925e+00,  1.4004e+00,  1.3756e+00,
          1.3393e+00,  1.3094e+00,  1.3286e+00,  1.3286e+00,  1.3061e+00,
          1.4254e+00,  1.3214e+00,  1.4515e+00,  1.3813e+00,  1.4764e+00,
          1.3125e+00,  1.3565e+00,  1.3669e+00,  1.3898e+00,  1.3489e+00,
          1.4216e+00,  1.4032e+00,  1.3572e+00,  1.3504e+00,  1.2325e+00,
          1.3390e+00,  1.3390e+00,  1.3716e+00,  1.4352e+00,  1.3542e+00,
          1.1444e+00,  1.3294e+00,  1.2427e+00,  1.4103e+00,  1.2316e+00,
          1.3583e+00,  3.3767e-01,  2.6116e-01,  3.7477e-01,  3.4110e-01,
          1.3638e-01,  8.5386e-02,  3.6114e-01,  1.2916e-01, -6.5216e-02,
          3.6588e+00,  2.3393e+00,  3.6091e+00,  2.7025e+00,  1.8651e+00,
          1.4580e+00,  2.9273e+00,  3.5247e+00,  1.4225e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 383 : 174.04539211509518
Test loss for epoch 383 : 174.47489461560713
Test Precision for epoch 383 : 0.26153846153846155
Test Recall for epoch 383 : 0.26153846153846155
Test F1 for epoch 383 : 0.26153846153846155


theta for epoch 384 : tensor([[ 2.7236e+00,  2.7424e+00,  2.7796e+00,  2.9050e+00,  2.8858e+00,
          2.7268e+00,  2.8729e+00,  2.7220e+00,  2.7220e+00,  1.3277e+00,
          1.3298e+00,  1.3288e+00,  1.3317e+00,  1.3267e+00,  1.3337e+00,
          1.3281e+00,  1.3250e+00,  1.2869e+00,  1.2806e+00,  1.2380e+00,
          1.2388e+00,  1.2815e+00,  1.2782e+00,  1.2777e+00,  1.2798e+00,
          1.2769e+00,  1.2769e+00,  1.2613e+00,  1.3060e+00,  1.3001e+00,
          1.3031e+00,  1.3060e+00,  1.3014e+00,  1.3042e+00,  1.2559e+00,
          1.3003e+00,  1.7370e+00,  1.7479e+00,  1.7416e+00,  1.7381e+00,
          1.7459e+00,  1.6854e+00,  1.7385e+00,  1.7231e+00,  1.7382e+00,
          1.5889e+00,  1.5728e+00,  1.5695e+00,  1.5633e+00,  1.5856e+00,
          1.5681e+00,  1.5997e+00,  1.5592e+00,  1.5616e+00],
        [ 1.2804e+00,  1.2833e+00,  1.2846e+00,  1.2838e+00,  1.2838e+00,
          1.2810e+00,  1.2820e+00,  1.2802e+00,  1.2802e+00,  2.6598e+00,
          2.6750e+00,  2.6609e+00,  2.9020e+00,  2.6469e+00,  3.0472e+00,
          2.6627e+00,  2.8692e+00,  3.0217e+00,  1.2718e+00,  1.2771e+00,
          1.2298e+00,  1.2728e+00,  1.2996e+00,  1.2990e+00,  1.3007e+00,
          1.2982e+00,  1.2982e+00,  1.3005e+00,  1.2523e+00,  1.3211e+00,
          1.3244e+00,  1.2986e+00,  1.3226e+00,  1.3256e+00,  1.2952e+00,
          1.3214e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7489e+00,
          1.7582e+00,  1.7600e+00,  1.7130e+00,  1.7301e+00,  1.7490e+00,
          1.5490e+00,  1.5869e+00,  1.5833e+00,  1.5765e+00,  1.5090e+00,
          1.5817e+00,  1.5243e+00,  1.5721e+00,  1.5747e+00],
        [ 1.2655e+00,  1.2681e+00,  1.2648e+00,  1.2699e+00,  1.2680e+00,
          1.2660e+00,  1.2664e+00,  1.2652e+00,  1.2652e+00,  1.3340e+00,
          1.3361e+00,  1.3351e+00,  1.3381e+00,  1.3329e+00,  1.2799e+00,
          1.3344e+00,  1.2711e+00,  1.3226e+00,  2.7707e+00,  2.9019e+00,
          2.9408e+00,  2.7796e+00,  2.7084e+00,  2.7052e+00,  2.8779e+00,
          2.7002e+00,  2.7002e+00,  1.2609e+00,  1.2973e+00,  1.3064e+00,
          1.3095e+00,  1.2615e+00,  1.3078e+00,  1.3106e+00,  1.3064e+00,
          1.3067e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6719e+00,
          1.7505e+00,  1.7420e+00,  1.7430e+00,  1.7273e+00,  1.6720e+00,
          1.5942e+00,  1.5777e+00,  1.5744e+00,  1.5681e+00,  1.5722e+00,
          1.5730e+00,  1.5865e+00,  1.5558e+00,  1.5664e+00],
        [ 1.2717e+00,  1.2744e+00,  1.2711e+00,  1.2763e+00,  1.2744e+00,
          1.2722e+00,  1.2727e+00,  1.2714e+00,  1.2714e+00,  1.3401e+00,
          1.3423e+00,  1.3412e+00,  1.3246e+00,  1.3390e+00,  1.2813e+00,
          1.3406e+00,  1.3366e+00,  1.2799e+00,  1.2933e+00,  1.2681e+00,
          1.2947e+00,  1.2944e+00,  1.2909e+00,  1.2904e+00,  1.2853e+00,
          1.2895e+00,  1.2895e+00,  2.9542e+00,  2.8658e+00,  2.6819e+00,
          2.7052e+00,  2.9532e+00,  2.6905e+00,  2.8459e+00,  2.7436e+00,
          2.6837e+00,  1.7445e+00,  1.7558e+00,  1.7220e+00,  1.7355e+00,
          1.7538e+00,  1.7453e+00,  1.7188e+00,  1.7286e+00,  1.7355e+00,
          1.5986e+00,  1.5816e+00,  1.5236e+00,  1.5181e+00,  1.5951e+00,
          1.5767e+00,  1.6098e+00,  1.5059e+00,  1.5699e+00],
        [ 1.9129e+00,  1.5157e+00,  6.7503e-01,  9.8613e-01,  1.4109e+00,
          1.8438e+00,  1.7170e+00,  1.9489e+00,  1.9489e+00,  1.7458e+00,
          1.3820e+00,  1.5960e+00,  1.0020e+00,  1.8012e+00,  1.9277e-01,
          1.6845e+00,  1.9728e+00,  9.0536e-01,  1.4183e+00,  1.0911e+00,
          8.3316e-01,  1.2275e+00,  1.7863e+00,  1.8523e+00,  1.6336e+00,
          1.9581e+00,  1.9581e+00,  9.3314e-01,  9.1768e-01,  1.9309e+00,
          1.7177e+00,  9.3493e-01,  1.8717e+00,  1.3264e+00,  1.9794e+00,
          1.8954e+00, -1.7921e-01, -4.1623e-01, -4.5949e-01, -2.3375e-01,
          2.1767e-02,  9.9474e-02, -3.0234e-01,  2.0109e+01,  2.0768e+00,
          2.8692e-01,  6.4682e-01,  6.6826e-01,  7.8124e-01,  4.3813e-01,
          7.8252e-01,  2.2171e-03,  8.2058e-01,  8.7746e-01],
        [ 1.3321e+00,  1.3687e+00,  1.3921e+00,  1.4002e+00,  1.3754e+00,
          1.3391e+00,  1.3092e+00,  1.3284e+00,  1.3284e+00,  1.3059e+00,
          1.4252e+00,  1.3212e+00,  1.4513e+00,  1.3811e+00,  1.4761e+00,
          1.3123e+00,  1.3563e+00,  1.3667e+00,  1.3896e+00,  1.3485e+00,
          1.4214e+00,  1.4030e+00,  1.3570e+00,  1.3502e+00,  1.2322e+00,
          1.3389e+00,  1.3389e+00,  1.3713e+00,  1.4350e+00,  1.3540e+00,
          1.1442e+00,  1.3290e+00,  1.2425e+00,  1.4101e+00,  1.2314e+00,
          1.3581e+00,  3.3745e-01,  2.6093e-01,  3.7454e-01,  3.4084e-01,
          1.3614e-01,  8.5112e-02,  3.6092e-01,  1.2882e-01, -6.5264e-02,
          3.6621e+00,  2.3405e+00,  3.6123e+00,  2.7040e+00,  1.8661e+00,
          1.4588e+00,  2.9287e+00,  3.5289e+00,  1.4234e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 384 : 174.03927383479072
Test loss for epoch 384 : 174.4708446937471
Test Precision for epoch 384 : 0.26153846153846155
Test Recall for epoch 384 : 0.26153846153846155
Test F1 for epoch 384 : 0.26153846153846155


theta for epoch 385 : tensor([[ 2.7254e+00,  2.7442e+00,  2.7814e+00,  2.9070e+00,  2.8878e+00,
          2.7286e+00,  2.8749e+00,  2.7237e+00,  2.7237e+00,  1.3276e+00,
          1.3297e+00,  1.3287e+00,  1.3317e+00,  1.3266e+00,  1.3336e+00,
          1.3281e+00,  1.3249e+00,  1.2868e+00,  1.2803e+00,  1.2377e+00,
          1.2385e+00,  1.2813e+00,  1.2779e+00,  1.2775e+00,  1.2795e+00,
          1.2767e+00,  1.2767e+00,  1.2612e+00,  1.3060e+00,  1.3000e+00,
          1.3030e+00,  1.3059e+00,  1.3013e+00,  1.3041e+00,  1.2558e+00,
          1.3002e+00,  1.7370e+00,  1.7479e+00,  1.7416e+00,  1.7381e+00,
          1.7459e+00,  1.6853e+00,  1.7385e+00,  1.7231e+00,  1.7382e+00,
          1.5888e+00,  1.5727e+00,  1.5694e+00,  1.5632e+00,  1.5855e+00,
          1.5680e+00,  1.5996e+00,  1.5591e+00,  1.5615e+00],
        [ 1.2803e+00,  1.2831e+00,  1.2845e+00,  1.2837e+00,  1.2837e+00,
          1.2808e+00,  1.2819e+00,  1.2800e+00,  1.2800e+00,  2.6614e+00,
          2.6766e+00,  2.6626e+00,  2.9041e+00,  2.6487e+00,  3.0493e+00,
          2.6643e+00,  2.8714e+00,  3.0238e+00,  1.2715e+00,  1.2768e+00,
          1.2295e+00,  1.2725e+00,  1.2993e+00,  1.2988e+00,  1.3004e+00,
          1.2979e+00,  1.2979e+00,  1.3004e+00,  1.2522e+00,  1.3210e+00,
          1.3243e+00,  1.2985e+00,  1.3225e+00,  1.3255e+00,  1.2951e+00,
          1.3213e+00,  1.7485e+00,  1.7603e+00,  1.7164e+00,  1.7489e+00,
          1.7582e+00,  1.7600e+00,  1.7130e+00,  1.7301e+00,  1.7490e+00,
          1.5489e+00,  1.5868e+00,  1.5831e+00,  1.5764e+00,  1.5089e+00,
          1.5816e+00,  1.5242e+00,  1.5720e+00,  1.5746e+00],
        [ 1.2654e+00,  1.2680e+00,  1.2646e+00,  1.2698e+00,  1.2679e+00,
          1.2659e+00,  1.2663e+00,  1.2651e+00,  1.2651e+00,  1.3340e+00,
          1.3361e+00,  1.3351e+00,  1.3381e+00,  1.3330e+00,  1.2799e+00,
          1.3345e+00,  1.2711e+00,  1.3226e+00,  2.7722e+00,  2.9038e+00,
          2.9425e+00,  2.7812e+00,  2.7099e+00,  2.7067e+00,  2.8798e+00,
          2.7017e+00,  2.7017e+00,  1.2608e+00,  1.2973e+00,  1.3063e+00,
          1.3094e+00,  1.2614e+00,  1.3077e+00,  1.3106e+00,  1.3063e+00,
          1.3066e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6719e+00,
          1.7505e+00,  1.7420e+00,  1.7430e+00,  1.7273e+00,  1.6719e+00,
          1.5941e+00,  1.5777e+00,  1.5743e+00,  1.5680e+00,  1.5721e+00,
          1.5729e+00,  1.5864e+00,  1.5556e+00,  1.5663e+00],
        [ 1.2716e+00,  1.2743e+00,  1.2710e+00,  1.2762e+00,  1.2743e+00,
          1.2721e+00,  1.2726e+00,  1.2713e+00,  1.2713e+00,  1.3400e+00,
          1.3423e+00,  1.3412e+00,  1.3245e+00,  1.3390e+00,  1.2813e+00,
          1.3405e+00,  1.3366e+00,  1.2798e+00,  1.2931e+00,  1.2678e+00,
          1.2944e+00,  1.2941e+00,  1.2906e+00,  1.2901e+00,  1.2850e+00,
          1.2893e+00,  1.2893e+00,  2.9563e+00,  2.8676e+00,  2.6836e+00,
          2.7068e+00,  2.9553e+00,  2.6922e+00,  2.8477e+00,  2.7454e+00,
          2.6854e+00,  1.7445e+00,  1.7558e+00,  1.7220e+00,  1.7354e+00,
          1.7538e+00,  1.7453e+00,  1.7188e+00,  1.7286e+00,  1.7355e+00,
          1.5984e+00,  1.5815e+00,  1.5235e+00,  1.5180e+00,  1.5950e+00,
          1.5766e+00,  1.6097e+00,  1.5057e+00,  1.5698e+00],
        [ 1.9133e+00,  1.5162e+00,  6.7566e-01,  9.8663e-01,  1.4114e+00,
          1.8443e+00,  1.7175e+00,  1.9493e+00,  1.9493e+00,  1.7463e+00,
          1.3825e+00,  1.5965e+00,  1.0026e+00,  1.8017e+00,  1.9342e-01,
          1.6849e+00,  1.9732e+00,  9.0592e-01,  1.4188e+00,  1.0917e+00,
          8.3369e-01,  1.2280e+00,  1.7867e+00,  1.8527e+00,  1.6342e+00,
          1.9585e+00,  1.9585e+00,  9.3379e-01,  9.1823e-01,  1.9313e+00,
          1.7182e+00,  9.3556e-01,  1.8721e+00,  1.3270e+00,  1.9799e+00,
          1.8958e+00, -1.8013e-01, -4.1704e-01, -4.6029e-01, -2.3474e-01,
          2.0754e-02,  9.8320e-02, -3.0320e-01,  2.0146e+01,  2.0631e+00,
          2.8749e-01,  6.4735e-01,  6.6879e-01,  7.8176e-01,  4.3868e-01,
          7.8302e-01,  2.8231e-03,  8.2113e-01,  8.7795e-01],
        [ 1.3319e+00,  1.3684e+00,  1.3917e+00,  1.3999e+00,  1.3751e+00,
          1.3389e+00,  1.3090e+00,  1.3282e+00,  1.3282e+00,  1.3057e+00,
          1.4250e+00,  1.3210e+00,  1.4511e+00,  1.3808e+00,  1.4759e+00,
          1.3121e+00,  1.3561e+00,  1.3665e+00,  1.3893e+00,  1.3481e+00,
          1.4211e+00,  1.4027e+00,  1.3567e+00,  1.3499e+00,  1.2318e+00,
          1.3386e+00,  1.3386e+00,  1.3709e+00,  1.4348e+00,  1.3538e+00,
          1.1440e+00,  1.3287e+00,  1.2423e+00,  1.4099e+00,  1.2312e+00,
          1.3579e+00,  3.3718e-01,  2.6065e-01,  3.7427e-01,  3.4054e-01,
          1.3585e-01,  8.4786e-02,  3.6065e-01,  1.2842e-01, -6.5368e-02,
          3.6654e+00,  2.3417e+00,  3.6155e+00,  2.7055e+00,  1.8671e+00,
          1.4598e+00,  2.9303e+00,  3.5332e+00,  1.4244e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 385 : 174.03326788815838
Test loss for epoch 385 : 174.46680104858868
Test Precision for epoch 385 : 0.26153846153846155
Test Recall for epoch 385 : 0.26153846153846155
Test F1 for epoch 385 : 0.26153846153846155


theta for epoch 386 : tensor([[ 2.7271e+00,  2.7460e+00,  2.7831e+00,  2.9090e+00,  2.8898e+00,
          2.7304e+00,  2.8769e+00,  2.7255e+00,  2.7255e+00,  1.3274e+00,
          1.3295e+00,  1.3285e+00,  1.3314e+00,  1.3264e+00,  1.3334e+00,
          1.3278e+00,  1.3247e+00,  1.2865e+00,  1.2804e+00,  1.2378e+00,
          1.2386e+00,  1.2814e+00,  1.2781e+00,  1.2776e+00,  1.2796e+00,
          1.2768e+00,  1.2768e+00,  1.2610e+00,  1.3058e+00,  1.2998e+00,
          1.3028e+00,  1.3058e+00,  1.3012e+00,  1.3039e+00,  1.2557e+00,
          1.3001e+00,  1.7371e+00,  1.7479e+00,  1.7416e+00,  1.7382e+00,
          1.7459e+00,  1.6854e+00,  1.7385e+00,  1.7232e+00,  1.7382e+00,
          1.5885e+00,  1.5723e+00,  1.5690e+00,  1.5628e+00,  1.5852e+00,
          1.5676e+00,  1.5993e+00,  1.5587e+00,  1.5611e+00],
        [ 1.2802e+00,  1.2830e+00,  1.2845e+00,  1.2836e+00,  1.2836e+00,
          1.2807e+00,  1.2818e+00,  1.2799e+00,  1.2799e+00,  2.6629e+00,
          2.6780e+00,  2.6642e+00,  2.9061e+00,  2.6503e+00,  3.0512e+00,
          2.6658e+00,  2.8734e+00,  3.0257e+00,  1.2717e+00,  1.2770e+00,
          1.2297e+00,  1.2726e+00,  1.2994e+00,  1.2989e+00,  1.3005e+00,
          1.2980e+00,  1.2980e+00,  1.3003e+00,  1.2520e+00,  1.3209e+00,
          1.3242e+00,  1.2984e+00,  1.3223e+00,  1.3254e+00,  1.2950e+00,
          1.3212e+00,  1.7485e+00,  1.7604e+00,  1.7165e+00,  1.7490e+00,
          1.7583e+00,  1.7601e+00,  1.7131e+00,  1.7303e+00,  1.7491e+00,
          1.5485e+00,  1.5864e+00,  1.5828e+00,  1.5760e+00,  1.5085e+00,
          1.5813e+00,  1.5239e+00,  1.5716e+00,  1.5742e+00],
        [ 1.2652e+00,  1.2678e+00,  1.2644e+00,  1.2696e+00,  1.2677e+00,
          1.2657e+00,  1.2661e+00,  1.2649e+00,  1.2649e+00,  1.3336e+00,
          1.3358e+00,  1.3348e+00,  1.3377e+00,  1.3326e+00,  1.2796e+00,
          1.3341e+00,  1.2707e+00,  1.3223e+00,  2.7743e+00,  2.9063e+00,
          2.9448e+00,  2.7832e+00,  2.7120e+00,  2.7087e+00,  2.8823e+00,
          2.7038e+00,  2.7038e+00,  1.2605e+00,  1.2971e+00,  1.3061e+00,
          1.3092e+00,  1.2611e+00,  1.3075e+00,  1.3103e+00,  1.3061e+00,
          1.3064e+00,  1.7415e+00,  1.7525e+00,  1.7462e+00,  1.6719e+00,
          1.7505e+00,  1.7419e+00,  1.7430e+00,  1.7274e+00,  1.6719e+00,
          1.5937e+00,  1.5773e+00,  1.5739e+00,  1.5676e+00,  1.5717e+00,
          1.5725e+00,  1.5860e+00,  1.5552e+00,  1.5659e+00],
        [ 1.2714e+00,  1.2742e+00,  1.2708e+00,  1.2760e+00,  1.2741e+00,
          1.2720e+00,  1.2724e+00,  1.2712e+00,  1.2712e+00,  1.3398e+00,
          1.3420e+00,  1.3409e+00,  1.3242e+00,  1.3387e+00,  1.2811e+00,
          1.3403e+00,  1.3363e+00,  1.2796e+00,  1.2932e+00,  1.2679e+00,
          1.2945e+00,  1.2942e+00,  1.2907e+00,  1.2902e+00,  1.2850e+00,
          1.2894e+00,  1.2894e+00,  2.9584e+00,  2.8695e+00,  2.6854e+00,
          2.7085e+00,  2.9575e+00,  2.6939e+00,  2.8496e+00,  2.7472e+00,
          2.6871e+00,  1.7445e+00,  1.7559e+00,  1.7221e+00,  1.7354e+00,
          1.7538e+00,  1.7452e+00,  1.7188e+00,  1.7287e+00,  1.7355e+00,
          1.5981e+00,  1.5812e+00,  1.5232e+00,  1.5177e+00,  1.5946e+00,
          1.5762e+00,  1.6094e+00,  1.5053e+00,  1.5695e+00],
        [ 1.9135e+00,  1.5163e+00,  6.7589e-01,  9.8676e-01,  1.4115e+00,
          1.8444e+00,  1.7176e+00,  1.9494e+00,  1.9494e+00,  1.7463e+00,
          1.3826e+00,  1.5965e+00,  1.0027e+00,  1.8018e+00,  1.9360e-01,
          1.6850e+00,  1.9733e+00,  9.0599e-01,  1.4190e+00,  1.0920e+00,
          8.3389e-01,  1.2282e+00,  1.7869e+00,  1.8529e+00,  1.6345e+00,
          1.9587e+00,  1.9587e+00,  9.3400e-01,  9.1834e-01,  1.9314e+00,
          1.7182e+00,  9.3574e-01,  1.8722e+00,  1.3270e+00,  1.9799e+00,
          1.8959e+00, -1.8068e-01, -4.1749e-01, -4.6073e-01, -2.3535e-01,
          2.0121e-02,  9.7546e-02, -3.0370e-01,  2.0182e+01,  2.0500e+00,
          2.8760e-01,  6.4742e-01,  6.6884e-01,  7.8180e-01,  4.3877e-01,
          7.8306e-01,  2.9723e-03,  8.2123e-01,  8.7797e-01],
        [ 1.3321e+00,  1.3687e+00,  1.3918e+00,  1.4001e+00,  1.3754e+00,
          1.3391e+00,  1.3092e+00,  1.3284e+00,  1.3284e+00,  1.3059e+00,
          1.4252e+00,  1.3212e+00,  1.4513e+00,  1.3811e+00,  1.4761e+00,
          1.3123e+00,  1.3563e+00,  1.3667e+00,  1.3897e+00,  1.3483e+00,
          1.4214e+00,  1.4031e+00,  1.3570e+00,  1.3502e+00,  1.2320e+00,
          1.3389e+00,  1.3389e+00,  1.3710e+00,  1.4350e+00,  1.3540e+00,
          1.1442e+00,  1.3288e+00,  1.2425e+00,  1.4101e+00,  1.2314e+00,
          1.3581e+00,  3.3741e-01,  2.6089e-01,  3.7450e-01,  3.4074e-01,
          1.3608e-01,  8.4981e-02,  3.6089e-01,  1.2855e-01, -6.4946e-02,
          3.6682e+00,  2.3424e+00,  3.6181e+00,  2.7066e+00,  1.8676e+00,
          1.4602e+00,  2.9313e+00,  3.5369e+00,  1.4248e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 386 : 174.0273390888551
Test loss for epoch 386 : 174.46362146780606
Test Precision for epoch 386 : 0.26153846153846155
Test Recall for epoch 386 : 0.26153846153846155
Test F1 for epoch 386 : 0.26153846153846155


theta for epoch 387 : tensor([[ 2.7290e+00,  2.7478e+00,  2.7850e+00,  2.9110e+00,  2.8918e+00,
          2.7322e+00,  2.8789e+00,  2.7273e+00,  2.7273e+00,  1.3273e+00,
          1.3295e+00,  1.3284e+00,  1.3314e+00,  1.3263e+00,  1.3333e+00,
          1.3278e+00,  1.3246e+00,  1.2865e+00,  1.2798e+00,  1.2373e+00,
          1.2381e+00,  1.2808e+00,  1.2775e+00,  1.2770e+00,  1.2790e+00,
          1.2762e+00,  1.2762e+00,  1.2609e+00,  1.3056e+00,  1.2996e+00,
          1.3027e+00,  1.3056e+00,  1.3010e+00,  1.3038e+00,  1.2555e+00,
          1.2999e+00,  1.7370e+00,  1.7478e+00,  1.7415e+00,  1.7381e+00,
          1.7458e+00,  1.6852e+00,  1.7384e+00,  1.7230e+00,  1.7381e+00,
          1.5887e+00,  1.5725e+00,  1.5692e+00,  1.5630e+00,  1.5854e+00,
          1.5678e+00,  1.5995e+00,  1.5589e+00,  1.5614e+00],
        [ 1.2800e+00,  1.2829e+00,  1.2844e+00,  1.2835e+00,  1.2834e+00,
          1.2806e+00,  1.2816e+00,  1.2797e+00,  1.2797e+00,  2.6648e+00,
          2.6799e+00,  2.6662e+00,  2.9084e+00,  2.6523e+00,  3.0535e+00,
          2.6676e+00,  2.8758e+00,  3.0281e+00,  1.2710e+00,  1.2763e+00,
          1.2290e+00,  1.2720e+00,  1.2988e+00,  1.2982e+00,  1.2999e+00,
          1.2974e+00,  1.2974e+00,  1.3000e+00,  1.2518e+00,  1.3206e+00,
          1.3239e+00,  1.2982e+00,  1.3221e+00,  1.3251e+00,  1.2947e+00,
          1.3209e+00,  1.7484e+00,  1.7603e+00,  1.7163e+00,  1.7489e+00,
          1.7581e+00,  1.7599e+00,  1.7129e+00,  1.7302e+00,  1.7490e+00,
          1.5487e+00,  1.5866e+00,  1.5830e+00,  1.5762e+00,  1.5087e+00,
          1.5815e+00,  1.5240e+00,  1.5718e+00,  1.5744e+00],
        [ 1.2651e+00,  1.2677e+00,  1.2643e+00,  1.2695e+00,  1.2676e+00,
          1.2656e+00,  1.2660e+00,  1.2648e+00,  1.2648e+00,  1.3337e+00,
          1.3358e+00,  1.3348e+00,  1.3377e+00,  1.3326e+00,  1.2796e+00,
          1.3341e+00,  1.2708e+00,  1.3223e+00,  2.7758e+00,  2.9082e+00,
          2.9466e+00,  2.7847e+00,  2.7134e+00,  2.7102e+00,  2.8841e+00,
          2.7052e+00,  2.7052e+00,  1.2603e+00,  1.2969e+00,  1.3060e+00,
          1.3090e+00,  1.2609e+00,  1.3073e+00,  1.3102e+00,  1.3059e+00,
          1.3063e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6717e+00,
          1.7504e+00,  1.7418e+00,  1.7429e+00,  1.7273e+00,  1.6718e+00,
          1.5940e+00,  1.5775e+00,  1.5742e+00,  1.5679e+00,  1.5720e+00,
          1.5727e+00,  1.5863e+00,  1.5554e+00,  1.5662e+00],
        [ 1.2713e+00,  1.2740e+00,  1.2706e+00,  1.2759e+00,  1.2740e+00,
          1.2718e+00,  1.2723e+00,  1.2710e+00,  1.2710e+00,  1.3397e+00,
          1.3419e+00,  1.3408e+00,  1.3242e+00,  1.3386e+00,  1.2810e+00,
          1.3402e+00,  1.3363e+00,  1.2795e+00,  1.2926e+00,  1.2672e+00,
          1.2939e+00,  1.2936e+00,  1.2901e+00,  1.2896e+00,  1.2844e+00,
          1.2888e+00,  1.2888e+00,  2.9607e+00,  2.8714e+00,  2.6872e+00,
          2.7102e+00,  2.9597e+00,  2.6957e+00,  2.8515e+00,  2.7491e+00,
          2.6889e+00,  1.7444e+00,  1.7557e+00,  1.7219e+00,  1.7352e+00,
          1.7537e+00,  1.7451e+00,  1.7187e+00,  1.7286e+00,  1.7353e+00,
          1.5983e+00,  1.5813e+00,  1.5234e+00,  1.5178e+00,  1.5948e+00,
          1.5764e+00,  1.6095e+00,  1.5055e+00,  1.5696e+00],
        [ 1.9142e+00,  1.5171e+00,  6.7687e-01,  9.8760e-01,  1.4123e+00,
          1.8451e+00,  1.7184e+00,  1.9501e+00,  1.9501e+00,  1.7472e+00,
          1.3834e+00,  1.5974e+00,  1.0036e+00,  1.8026e+00,  1.9463e-01,
          1.6858e+00,  1.9741e+00,  9.0694e-01,  1.4197e+00,  1.0929e+00,
          8.3474e-01,  1.2289e+00,  1.7876e+00,  1.8536e+00,  1.6353e+00,
          1.9593e+00,  1.9593e+00,  9.3496e-01,  9.1924e-01,  1.9321e+00,
          1.7190e+00,  9.3670e-01,  1.8730e+00,  1.3279e+00,  1.9807e+00,
          1.8966e+00, -1.8191e-01, -4.1860e-01, -4.6183e-01, -2.3665e-01,
          1.8791e-02,  9.6079e-02, -3.0487e-01,  2.0218e+01,  2.0364e+00,
          2.8858e-01,  6.4835e-01,  6.6977e-01,  7.8271e-01,  4.3973e-01,
          7.8396e-01,  3.9899e-03,  8.2218e-01,  8.7885e-01],
        [ 1.3316e+00,  1.3681e+00,  1.3911e+00,  1.3996e+00,  1.3749e+00,
          1.3386e+00,  1.3087e+00,  1.3279e+00,  1.3279e+00,  1.3054e+00,
          1.4247e+00,  1.3207e+00,  1.4508e+00,  1.3806e+00,  1.4755e+00,
          1.3118e+00,  1.3558e+00,  1.3661e+00,  1.3890e+00,  1.3475e+00,
          1.4207e+00,  1.4024e+00,  1.3564e+00,  1.3496e+00,  1.2311e+00,
          1.3382e+00,  1.3382e+00,  1.3703e+00,  1.4345e+00,  1.3535e+00,
          1.1437e+00,  1.3281e+00,  1.2420e+00,  1.4096e+00,  1.2309e+00,
          1.3576e+00,  3.3680e-01,  2.6026e-01,  3.7389e-01,  3.4010e-01,
          1.3546e-01,  8.4316e-02,  3.6027e-01,  1.2782e-01, -6.5389e-02,
          3.6720e+00,  2.3440e+00,  3.6217e+00,  2.7086e+00,  1.8690e+00,
          1.4615e+00,  2.9332e+00,  3.5416e+00,  1.4261e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 387 : 174.021451788119
Test loss for epoch 387 : 174.45906210241475
Test Precision for epoch 387 : 0.26153846153846155
Test Recall for epoch 387 : 0.26153846153846155
Test F1 for epoch 387 : 0.26153846153846155


theta for epoch 388 : tensor([[ 2.7307e+00,  2.7496e+00,  2.7867e+00,  2.9130e+00,  2.8938e+00,
          2.7340e+00,  2.8809e+00,  2.7291e+00,  2.7291e+00,  1.3270e+00,
          1.3292e+00,  1.3281e+00,  1.3311e+00,  1.3260e+00,  1.3330e+00,
          1.3275e+00,  1.3243e+00,  1.2862e+00,  1.2802e+00,  1.2376e+00,
          1.2384e+00,  1.2811e+00,  1.2778e+00,  1.2773e+00,  1.2794e+00,
          1.2765e+00,  1.2765e+00,  1.2607e+00,  1.3055e+00,  1.2995e+00,
          1.3025e+00,  1.3055e+00,  1.3008e+00,  1.3036e+00,  1.2553e+00,
          1.2998e+00,  1.7370e+00,  1.7478e+00,  1.7416e+00,  1.7381e+00,
          1.7459e+00,  1.6853e+00,  1.7385e+00,  1.7231e+00,  1.7382e+00,
          1.5883e+00,  1.5721e+00,  1.5688e+00,  1.5626e+00,  1.5850e+00,
          1.5674e+00,  1.5990e+00,  1.5585e+00,  1.5609e+00],
        [ 1.2799e+00,  1.2827e+00,  1.2843e+00,  1.2834e+00,  1.2833e+00,
          1.2804e+00,  1.2815e+00,  1.2796e+00,  1.2796e+00,  2.6662e+00,
          2.6813e+00,  2.6678e+00,  2.9103e+00,  2.6538e+00,  3.0555e+00,
          2.6691e+00,  2.8778e+00,  3.0301e+00,  1.2713e+00,  1.2767e+00,
          1.2293e+00,  1.2723e+00,  1.2991e+00,  1.2986e+00,  1.3002e+00,
          1.2977e+00,  1.2977e+00,  1.2999e+00,  1.2516e+00,  1.3205e+00,
          1.3238e+00,  1.2981e+00,  1.3220e+00,  1.3250e+00,  1.2946e+00,
          1.3208e+00,  1.7485e+00,  1.7603e+00,  1.7164e+00,  1.7490e+00,
          1.7582e+00,  1.7600e+00,  1.7130e+00,  1.7303e+00,  1.7491e+00,
          1.5483e+00,  1.5862e+00,  1.5825e+00,  1.5758e+00,  1.5082e+00,
          1.5810e+00,  1.5236e+00,  1.5714e+00,  1.5739e+00],
        [ 1.2649e+00,  1.2675e+00,  1.2640e+00,  1.2693e+00,  1.2674e+00,
          1.2654e+00,  1.2658e+00,  1.2646e+00,  1.2646e+00,  1.3333e+00,
          1.3354e+00,  1.3344e+00,  1.3373e+00,  1.3322e+00,  1.2792e+00,
          1.3337e+00,  1.2703e+00,  1.3219e+00,  2.7780e+00,  2.9107e+00,
          2.9490e+00,  2.7869e+00,  2.7156e+00,  2.7123e+00,  2.8867e+00,
          2.7074e+00,  2.7074e+00,  1.2600e+00,  1.2967e+00,  1.3057e+00,
          1.3088e+00,  1.2607e+00,  1.3071e+00,  1.3100e+00,  1.3057e+00,
          1.3060e+00,  1.7415e+00,  1.7525e+00,  1.7461e+00,  1.6717e+00,
          1.7505e+00,  1.7418e+00,  1.7429e+00,  1.7273e+00,  1.6717e+00,
          1.5935e+00,  1.5770e+00,  1.5737e+00,  1.5674e+00,  1.5715e+00,
          1.5722e+00,  1.5858e+00,  1.5548e+00,  1.5656e+00],
        [ 1.2711e+00,  1.2739e+00,  1.2704e+00,  1.2757e+00,  1.2738e+00,
          1.2716e+00,  1.2721e+00,  1.2709e+00,  1.2709e+00,  1.3394e+00,
          1.3416e+00,  1.3405e+00,  1.3238e+00,  1.3383e+00,  1.2807e+00,
          1.3399e+00,  1.3359e+00,  1.2792e+00,  1.2928e+00,  1.2675e+00,
          1.2942e+00,  1.2938e+00,  1.2904e+00,  1.2899e+00,  1.2846e+00,
          1.2890e+00,  1.2890e+00,  2.9629e+00,  2.8733e+00,  2.6889e+00,
          2.7119e+00,  2.9619e+00,  2.6975e+00,  2.8534e+00,  2.7510e+00,
          2.6907e+00,  1.7444e+00,  1.7558e+00,  1.7220e+00,  1.7353e+00,
          1.7537e+00,  1.7451e+00,  1.7187e+00,  1.7287e+00,  1.7353e+00,
          1.5978e+00,  1.5809e+00,  1.5229e+00,  1.5174e+00,  1.5944e+00,
          1.5760e+00,  1.6091e+00,  1.5050e+00,  1.5692e+00],
        [ 1.9141e+00,  1.5170e+00,  6.7687e-01,  9.8751e-01,  1.4122e+00,
          1.8451e+00,  1.7183e+00,  1.9501e+00,  1.9501e+00,  1.7469e+00,
          1.3833e+00,  1.5972e+00,  1.0035e+00,  1.8024e+00,  1.9456e-01,
          1.6856e+00,  1.9739e+00,  9.0674e-01,  1.4198e+00,  1.0930e+00,
          8.3474e-01,  1.2289e+00,  1.7877e+00,  1.8537e+00,  1.6355e+00,
          1.9594e+00,  1.9594e+00,  9.3495e-01,  9.1912e-01,  1.9320e+00,
          1.7189e+00,  9.3665e-01,  1.8728e+00,  1.3277e+00,  1.9806e+00,
          1.8965e+00, -1.8225e-01, -4.1885e-01, -4.6207e-01, -2.3705e-01,
          1.8367e-02,  9.5517e-02, -3.0517e-01,  2.0255e+01,  2.0240e+00,
          2.8845e-01,  6.4817e-01,  6.6957e-01,  7.8250e-01,  4.3957e-01,
          7.8374e-01,  3.8974e-03,  8.2201e-01,  8.7861e-01],
        [ 1.3321e+00,  1.3686e+00,  1.3914e+00,  1.4001e+00,  1.3753e+00,
          1.3391e+00,  1.3091e+00,  1.3284e+00,  1.3284e+00,  1.3059e+00,
          1.4252e+00,  1.3212e+00,  1.4512e+00,  1.3810e+00,  1.4759e+00,
          1.3123e+00,  1.3562e+00,  1.3666e+00,  1.3896e+00,  1.3480e+00,
          1.4213e+00,  1.4030e+00,  1.3570e+00,  1.3502e+00,  1.2317e+00,
          1.3389e+00,  1.3389e+00,  1.3706e+00,  1.4349e+00,  1.3540e+00,
          1.1441e+00,  1.3284e+00,  1.2424e+00,  1.4100e+00,  1.2314e+00,
          1.3581e+00,  3.3728e-01,  2.6074e-01,  3.7436e-01,  3.4055e-01,
          1.3593e-01,  8.4759e-02,  3.6075e-01,  1.2820e-01, -6.4721e-02,
          3.6746e+00,  2.3445e+00,  3.6242e+00,  2.7094e+00,  1.8692e+00,
          1.4617e+00,  2.9340e+00,  3.5451e+00,  1.4262e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 388 : 174.01558217594027
Test loss for epoch 388 : 174.45630561732298
Test Precision for epoch 388 : 0.26153846153846155
Test Recall for epoch 388 : 0.26153846153846155
Test F1 for epoch 388 : 0.26153846153846155


theta for epoch 389 : tensor([[ 2.7326e+00,  2.7514e+00,  2.7886e+00,  2.9151e+00,  2.8959e+00,
          2.7358e+00,  2.8830e+00,  2.7309e+00,  2.7309e+00,  1.3270e+00,
          1.3291e+00,  1.3281e+00,  1.3310e+00,  1.3260e+00,  1.3330e+00,
          1.3275e+00,  1.3243e+00,  1.2862e+00,  1.2796e+00,  1.2370e+00,
          1.2378e+00,  1.2806e+00,  1.2772e+00,  1.2768e+00,  1.2788e+00,
          1.2759e+00,  1.2759e+00,  1.2606e+00,  1.3054e+00,  1.2994e+00,
          1.3024e+00,  1.3053e+00,  1.3007e+00,  1.3035e+00,  1.2552e+00,
          1.2997e+00,  1.7369e+00,  1.7477e+00,  1.7414e+00,  1.7380e+00,
          1.7457e+00,  1.6852e+00,  1.7383e+00,  1.7230e+00,  1.7381e+00,
          1.5884e+00,  1.5723e+00,  1.5689e+00,  1.5627e+00,  1.5851e+00,
          1.5675e+00,  1.5992e+00,  1.5586e+00,  1.5611e+00],
        [ 1.2797e+00,  1.2825e+00,  1.2841e+00,  1.2833e+00,  1.2831e+00,
          1.2802e+00,  1.2813e+00,  1.2794e+00,  1.2794e+00,  2.6680e+00,
          2.6832e+00,  2.6697e+00,  2.9126e+00,  2.6558e+00,  3.0578e+00,
          2.6709e+00,  2.8802e+00,  3.0324e+00,  1.2707e+00,  1.2760e+00,
          1.2287e+00,  1.2717e+00,  1.2985e+00,  1.2980e+00,  1.2996e+00,
          1.2971e+00,  1.2971e+00,  1.2997e+00,  1.2515e+00,  1.3203e+00,
          1.3237e+00,  1.2980e+00,  1.3218e+00,  1.3248e+00,  1.2945e+00,
          1.3207e+00,  1.7483e+00,  1.7602e+00,  1.7163e+00,  1.7488e+00,
          1.7580e+00,  1.7599e+00,  1.7129e+00,  1.7302e+00,  1.7489e+00,
          1.5484e+00,  1.5863e+00,  1.5827e+00,  1.5759e+00,  1.5084e+00,
          1.5812e+00,  1.5237e+00,  1.5715e+00,  1.5741e+00],
        [ 1.2648e+00,  1.2675e+00,  1.2639e+00,  1.2692e+00,  1.2674e+00,
          1.2653e+00,  1.2657e+00,  1.2645e+00,  1.2645e+00,  1.3334e+00,
          1.3355e+00,  1.3345e+00,  1.3375e+00,  1.3324e+00,  1.2793e+00,
          1.3339e+00,  1.2705e+00,  1.3220e+00,  2.7793e+00,  2.9124e+00,
          2.9505e+00,  2.7882e+00,  2.7168e+00,  2.7136e+00,  2.8884e+00,
          2.7086e+00,  2.7086e+00,  1.2600e+00,  1.2967e+00,  1.3057e+00,
          1.3088e+00,  1.2606e+00,  1.3071e+00,  1.3099e+00,  1.3057e+00,
          1.3060e+00,  1.7414e+00,  1.7524e+00,  1.7460e+00,  1.6715e+00,
          1.7504e+00,  1.7416e+00,  1.7429e+00,  1.7272e+00,  1.6716e+00,
          1.5937e+00,  1.5773e+00,  1.5739e+00,  1.5676e+00,  1.5717e+00,
          1.5725e+00,  1.5861e+00,  1.5550e+00,  1.5659e+00],
        [ 1.2710e+00,  1.2737e+00,  1.2702e+00,  1.2756e+00,  1.2737e+00,
          1.2715e+00,  1.2720e+00,  1.2707e+00,  1.2707e+00,  1.3394e+00,
          1.3416e+00,  1.3405e+00,  1.3239e+00,  1.3383e+00,  1.2807e+00,
          1.3399e+00,  1.3360e+00,  1.2793e+00,  1.2923e+00,  1.2669e+00,
          1.2936e+00,  1.2933e+00,  1.2899e+00,  1.2893e+00,  1.2841e+00,
          1.2885e+00,  1.2885e+00,  2.9650e+00,  2.8752e+00,  2.6907e+00,
          2.7136e+00,  2.9640e+00,  2.6992e+00,  2.8553e+00,  2.7528e+00,
          2.6924e+00,  1.7443e+00,  1.7556e+00,  1.7218e+00,  1.7351e+00,
          1.7536e+00,  1.7449e+00,  1.7186e+00,  1.7286e+00,  1.7352e+00,
          1.5980e+00,  1.5811e+00,  1.5231e+00,  1.5175e+00,  1.5945e+00,
          1.5761e+00,  1.6093e+00,  1.5051e+00,  1.5693e+00],
        [ 1.9149e+00,  1.5179e+00,  6.7795e-01,  9.8843e-01,  1.4131e+00,
          1.8458e+00,  1.7191e+00,  1.9508e+00,  1.9508e+00,  1.7479e+00,
          1.3842e+00,  1.5982e+00,  1.0045e+00,  1.8034e+00,  1.9571e-01,
          1.6865e+00,  1.9748e+00,  9.0781e-01,  1.4206e+00,  1.0940e+00,
          8.3570e-01,  1.2298e+00,  1.7884e+00,  1.8544e+00,  1.6364e+00,
          1.9601e+00,  1.9601e+00,  9.3604e-01,  9.2014e-01,  1.9329e+00,
          1.7197e+00,  9.3774e-01,  1.8737e+00,  1.3287e+00,  1.9814e+00,
          1.8974e+00, -1.8357e-01, -4.2004e-01, -4.6325e-01, -2.3842e-01,
          1.6949e-02,  9.3966e-02, -3.0642e-01,  2.0291e+01,  2.0107e+00,
          2.8953e-01,  6.4919e-01,  6.7058e-01,  7.8349e-01,  4.4063e-01,
          7.8473e-01,  5.0250e-03,  8.2304e-01,  8.7958e-01],
        [ 1.3314e+00,  1.3679e+00,  1.3906e+00,  1.3994e+00,  1.3746e+00,
          1.3384e+00,  1.3085e+00,  1.3277e+00,  1.3277e+00,  1.3052e+00,
          1.4245e+00,  1.3205e+00,  1.4505e+00,  1.3803e+00,  1.4752e+00,
          1.3116e+00,  1.3556e+00,  1.3659e+00,  1.3888e+00,  1.3470e+00,
          1.4205e+00,  1.4021e+00,  1.3562e+00,  1.3494e+00,  1.2307e+00,
          1.3380e+00,  1.3380e+00,  1.3698e+00,  1.4342e+00,  1.3533e+00,
          1.1434e+00,  1.3276e+00,  1.2418e+00,  1.4094e+00,  1.2307e+00,
          1.3574e+00,  3.3651e-01,  2.5994e-01,  3.7357e-01,  3.3975e-01,
          1.3513e-01,  8.3925e-02,  3.5997e-01,  1.2730e-01, -6.5336e-02,
          3.6785e+00,  2.3463e+00,  3.6280e+00,  2.7115e+00,  1.8708e+00,
          1.4632e+00,  2.9361e+00,  3.5500e+00,  1.4277e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 389 : 174.00971487434933
Test loss for epoch 389 : 174.4515107677141
Test Precision for epoch 389 : 0.26153846153846155
Test Recall for epoch 389 : 0.26153846153846155
Test F1 for epoch 389 : 0.26153846153846155


theta for epoch 390 : tensor([[ 2.7344e+00,  2.7532e+00,  2.7904e+00,  2.9171e+00,  2.8980e+00,
          2.7376e+00,  2.8851e+00,  2.7328e+00,  2.7328e+00,  1.3267e+00,
          1.3288e+00,  1.3278e+00,  1.3307e+00,  1.3257e+00,  1.3327e+00,
          1.3271e+00,  1.3240e+00,  1.2858e+00,  1.2799e+00,  1.2373e+00,
          1.2381e+00,  1.2808e+00,  1.2775e+00,  1.2770e+00,  1.2791e+00,
          1.2762e+00,  1.2762e+00,  1.2604e+00,  1.3052e+00,  1.2992e+00,
          1.3022e+00,  1.3052e+00,  1.3006e+00,  1.3034e+00,  1.2551e+00,
          1.2995e+00,  1.7370e+00,  1.7478e+00,  1.7415e+00,  1.7381e+00,
          1.7458e+00,  1.6852e+00,  1.7384e+00,  1.7230e+00,  1.7382e+00,
          1.5879e+00,  1.5717e+00,  1.5684e+00,  1.5622e+00,  1.5846e+00,
          1.5670e+00,  1.5986e+00,  1.5580e+00,  1.5605e+00],
        [ 1.2796e+00,  1.2824e+00,  1.2840e+00,  1.2832e+00,  1.2829e+00,
          1.2801e+00,  1.2812e+00,  1.2793e+00,  1.2793e+00,  2.6695e+00,
          2.6846e+00,  2.6713e+00,  2.9145e+00,  2.6573e+00,  3.0597e+00,
          2.6723e+00,  2.8822e+00,  3.0344e+00,  1.2710e+00,  1.2764e+00,
          1.2291e+00,  1.2720e+00,  1.2989e+00,  1.2983e+00,  1.3000e+00,
          1.2975e+00,  1.2975e+00,  1.2996e+00,  1.2514e+00,  1.3202e+00,
          1.3235e+00,  1.2980e+00,  1.3217e+00,  1.3247e+00,  1.2943e+00,
          1.3205e+00,  1.7484e+00,  1.7603e+00,  1.7163e+00,  1.7489e+00,
          1.7581e+00,  1.7600e+00,  1.7130e+00,  1.7304e+00,  1.7491e+00,
          1.5479e+00,  1.5858e+00,  1.5821e+00,  1.5754e+00,  1.5078e+00,
          1.5806e+00,  1.5232e+00,  1.5710e+00,  1.5735e+00],
        [ 1.2646e+00,  1.2673e+00,  1.2637e+00,  1.2690e+00,  1.2671e+00,
          1.2651e+00,  1.2655e+00,  1.2643e+00,  1.2643e+00,  1.3330e+00,
          1.3351e+00,  1.3341e+00,  1.3371e+00,  1.3320e+00,  1.2790e+00,
          1.3335e+00,  1.2701e+00,  1.3217e+00,  2.7815e+00,  2.9150e+00,
          2.9530e+00,  2.7904e+00,  2.7190e+00,  2.7158e+00,  2.8909e+00,
          2.7108e+00,  2.7108e+00,  1.2597e+00,  1.2965e+00,  1.3055e+00,
          1.3086e+00,  1.2604e+00,  1.3069e+00,  1.3097e+00,  1.3055e+00,
          1.3058e+00,  1.7415e+00,  1.7524e+00,  1.7461e+00,  1.6715e+00,
          1.7504e+00,  1.7416e+00,  1.7429e+00,  1.7273e+00,  1.6716e+00,
          1.5931e+00,  1.5767e+00,  1.5733e+00,  1.5670e+00,  1.5712e+00,
          1.5719e+00,  1.5855e+00,  1.5544e+00,  1.5653e+00],
        [ 1.2708e+00,  1.2736e+00,  1.2700e+00,  1.2754e+00,  1.2736e+00,
          1.2714e+00,  1.2719e+00,  1.2706e+00,  1.2706e+00,  1.3391e+00,
          1.3413e+00,  1.3403e+00,  1.3236e+00,  1.3381e+00,  1.2805e+00,
          1.3396e+00,  1.3357e+00,  1.2790e+00,  1.2926e+00,  1.2672e+00,
          1.2939e+00,  1.2936e+00,  1.2902e+00,  1.2896e+00,  1.2844e+00,
          1.2888e+00,  1.2888e+00,  2.9672e+00,  2.8770e+00,  2.6924e+00,
          2.7153e+00,  2.9662e+00,  2.7010e+00,  2.8571e+00,  2.7546e+00,
          2.6942e+00,  1.7444e+00,  1.7557e+00,  1.7219e+00,  1.7351e+00,
          1.7537e+00,  1.7449e+00,  1.7187e+00,  1.7287e+00,  1.7352e+00,
          1.5975e+00,  1.5805e+00,  1.5226e+00,  1.5170e+00,  1.5940e+00,
          1.5756e+00,  1.6087e+00,  1.5045e+00,  1.5688e+00],
        [ 1.9148e+00,  1.5178e+00,  6.7793e-01,  9.8833e-01,  1.4130e+00,
          1.8458e+00,  1.7190e+00,  1.9508e+00,  1.9508e+00,  1.7476e+00,
          1.3840e+00,  1.5980e+00,  1.0044e+00,  1.8032e+00,  1.9563e-01,
          1.6863e+00,  1.9747e+00,  9.0760e-01,  1.4206e+00,  1.0941e+00,
          8.3568e-01,  1.2298e+00,  1.7884e+00,  1.8544e+00,  1.6366e+00,
          1.9602e+00,  1.9602e+00,  9.3601e-01,  9.2002e-01,  1.9328e+00,
          1.7196e+00,  9.3768e-01,  1.8736e+00,  1.3286e+00,  1.9813e+00,
          1.8973e+00, -1.8389e-01, -4.2026e-01, -4.6347e-01, -2.3880e-01,
          1.6547e-02,  9.3430e-02, -3.0669e-01,  2.0327e+01,  1.9988e+00,
          2.8937e-01,  6.4896e-01,  6.7034e-01,  7.8323e-01,  4.4044e-01,
          7.8446e-01,  4.9147e-03,  8.2283e-01,  8.7929e-01],
        [ 1.3319e+00,  1.3683e+00,  1.3909e+00,  1.3998e+00,  1.3751e+00,
          1.3388e+00,  1.3089e+00,  1.3282e+00,  1.3282e+00,  1.3057e+00,
          1.4250e+00,  1.3209e+00,  1.4510e+00,  1.3808e+00,  1.4757e+00,
          1.3121e+00,  1.3560e+00,  1.3663e+00,  1.3894e+00,  1.3475e+00,
          1.4211e+00,  1.4028e+00,  1.3568e+00,  1.3500e+00,  1.2312e+00,
          1.3387e+00,  1.3387e+00,  1.3702e+00,  1.4347e+00,  1.3538e+00,
          1.1439e+00,  1.3279e+00,  1.2422e+00,  1.4098e+00,  1.2312e+00,
          1.3579e+00,  3.3701e-01,  2.6043e-01,  3.7407e-01,  3.4022e-01,
          1.3563e-01,  8.4391e-02,  3.6047e-01,  1.2771e-01, -6.4646e-02,
          3.6811e+00,  2.3468e+00,  3.6304e+00,  2.7124e+00,  1.8711e+00,
          1.4633e+00,  2.9369e+00,  3.5536e+00,  1.4279e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 390 : 174.003857248715
Test loss for epoch 390 : 174.44876432660618
Test Precision for epoch 390 : 0.26153846153846155
Test Recall for epoch 390 : 0.26153846153846155
Test F1 for epoch 390 : 0.26153846153846155


theta for epoch 391 : tensor([[ 2.7363e+00,  2.7551e+00,  2.7923e+00,  2.9192e+00,  2.9000e+00,
          2.7395e+00,  2.8872e+00,  2.7346e+00,  2.7346e+00,  1.3266e+00,
          1.3287e+00,  1.3277e+00,  1.3306e+00,  1.3256e+00,  1.3326e+00,
          1.3271e+00,  1.3239e+00,  1.2858e+00,  1.2792e+00,  1.2366e+00,
          1.2374e+00,  1.2802e+00,  1.2769e+00,  1.2764e+00,  1.2784e+00,
          1.2756e+00,  1.2756e+00,  1.2602e+00,  1.3050e+00,  1.2991e+00,
          1.3021e+00,  1.3050e+00,  1.3004e+00,  1.3032e+00,  1.2549e+00,
          1.2993e+00,  1.7368e+00,  1.7476e+00,  1.7414e+00,  1.7380e+00,
          1.7457e+00,  1.6851e+00,  1.7383e+00,  1.7229e+00,  1.7381e+00,
          1.5881e+00,  1.5719e+00,  1.5686e+00,  1.5624e+00,  1.5848e+00,
          1.5672e+00,  1.5988e+00,  1.5583e+00,  1.5607e+00],
        [ 1.2793e+00,  1.2822e+00,  1.2839e+00,  1.2830e+00,  1.2827e+00,
          1.2799e+00,  1.2810e+00,  1.2791e+00,  1.2791e+00,  2.6713e+00,
          2.6865e+00,  2.6733e+00,  2.9169e+00,  2.6593e+00,  3.0621e+00,
          2.6742e+00,  2.8846e+00,  3.0367e+00,  1.2703e+00,  1.2757e+00,
          1.2283e+00,  1.2713e+00,  1.2982e+00,  1.2976e+00,  1.2993e+00,
          1.2968e+00,  1.2968e+00,  1.2994e+00,  1.2512e+00,  1.3200e+00,
          1.3234e+00,  1.2978e+00,  1.3215e+00,  1.3245e+00,  1.2941e+00,
          1.3204e+00,  1.7483e+00,  1.7601e+00,  1.7162e+00,  1.7488e+00,
          1.7580e+00,  1.7598e+00,  1.7128e+00,  1.7303e+00,  1.7489e+00,
          1.5481e+00,  1.5860e+00,  1.5824e+00,  1.5756e+00,  1.5080e+00,
          1.5808e+00,  1.5233e+00,  1.5712e+00,  1.5737e+00],
        [ 1.2645e+00,  1.2671e+00,  1.2635e+00,  1.2688e+00,  1.2670e+00,
          1.2650e+00,  1.2654e+00,  1.2642e+00,  1.2642e+00,  1.3330e+00,
          1.3352e+00,  1.3341e+00,  1.3371e+00,  1.3320e+00,  1.2790e+00,
          1.3335e+00,  1.2701e+00,  1.3217e+00,  2.7830e+00,  2.9169e+00,
          2.9548e+00,  2.7919e+00,  2.7205e+00,  2.7173e+00,  2.8928e+00,
          2.7123e+00,  2.7123e+00,  1.2596e+00,  1.2964e+00,  1.3054e+00,
          1.3085e+00,  1.2602e+00,  1.3068e+00,  1.3096e+00,  1.3054e+00,
          1.3057e+00,  1.7414e+00,  1.7523e+00,  1.7460e+00,  1.6714e+00,
          1.7503e+00,  1.7415e+00,  1.7428e+00,  1.7272e+00,  1.6715e+00,
          1.5934e+00,  1.5769e+00,  1.5736e+00,  1.5673e+00,  1.5714e+00,
          1.5721e+00,  1.5857e+00,  1.5546e+00,  1.5655e+00],
        [ 1.2707e+00,  1.2734e+00,  1.2698e+00,  1.2753e+00,  1.2734e+00,
          1.2712e+00,  1.2717e+00,  1.2704e+00,  1.2704e+00,  1.3391e+00,
          1.3413e+00,  1.3402e+00,  1.3235e+00,  1.3380e+00,  1.2805e+00,
          1.3396e+00,  1.3356e+00,  1.2790e+00,  1.2920e+00,  1.2665e+00,
          1.2933e+00,  1.2930e+00,  1.2896e+00,  1.2890e+00,  1.2837e+00,
          1.2882e+00,  1.2882e+00,  2.9694e+00,  2.8790e+00,  2.6942e+00,
          2.7170e+00,  2.9684e+00,  2.7028e+00,  2.8591e+00,  2.7565e+00,
          2.6960e+00,  1.7443e+00,  1.7556e+00,  1.7218e+00,  1.7350e+00,
          1.7535e+00,  1.7448e+00,  1.7186e+00,  1.7286e+00,  1.7351e+00,
          1.5977e+00,  1.5807e+00,  1.5228e+00,  1.5172e+00,  1.5942e+00,
          1.5758e+00,  1.6089e+00,  1.5047e+00,  1.5690e+00],
        [ 1.9156e+00,  1.5186e+00,  6.7897e-01,  9.8923e-01,  1.4138e+00,
          1.8465e+00,  1.7198e+00,  1.9515e+00,  1.9515e+00,  1.7485e+00,
          1.3850e+00,  1.5989e+00,  1.0054e+00,  1.8041e+00,  1.9674e-01,
          1.6872e+00,  1.9755e+00,  9.0863e-01,  1.4214e+00,  1.0950e+00,
          8.3660e-01,  1.2306e+00,  1.7891e+00,  1.8551e+00,  1.6374e+00,
          1.9608e+00,  1.9608e+00,  9.3706e-01,  9.2100e-01,  1.9336e+00,
          1.7204e+00,  9.3873e-01,  1.8744e+00,  1.3295e+00,  1.9821e+00,
          1.8981e+00, -1.8517e-01, -4.2142e-01, -4.6461e-01, -2.4013e-01,
          1.5169e-02,  9.1922e-02, -3.0791e-01,  2.0363e+01,  1.9861e+00,
          2.9043e-01,  6.4995e-01,  6.7132e-01,  7.8419e-01,  4.4147e-01,
          7.8542e-01,  6.0228e-03,  8.2382e-01,  8.8023e-01],
        [ 1.3313e+00,  1.3677e+00,  1.3902e+00,  1.3992e+00,  1.3745e+00,
          1.3382e+00,  1.3083e+00,  1.3276e+00,  1.3276e+00,  1.3051e+00,
          1.4244e+00,  1.3203e+00,  1.4504e+00,  1.3802e+00,  1.4750e+00,
          1.3115e+00,  1.3555e+00,  1.3657e+00,  1.3887e+00,  1.3466e+00,
          1.4203e+00,  1.4020e+00,  1.3561e+00,  1.3493e+00,  1.2303e+00,
          1.3379e+00,  1.3379e+00,  1.3694e+00,  1.4341e+00,  1.3532e+00,
          1.1433e+00,  1.3272e+00,  1.2416e+00,  1.4092e+00,  1.2306e+00,
          1.3573e+00,  3.3632e-01,  2.5973e-01,  3.7337e-01,  3.3951e-01,
          1.3493e-01,  8.3654e-02,  3.5978e-01,  1.2692e-01, -6.5164e-02,
          3.6850e+00,  2.3486e+00,  3.6342e+00,  2.7145e+00,  1.8726e+00,
          1.4647e+00,  2.9390e+00,  3.5585e+00,  1.4293e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 391 : 173.99801726160297
Test loss for epoch 391 : 174.4440669095824
Test Precision for epoch 391 : 0.26153846153846155
Test Recall for epoch 391 : 0.26153846153846155
Test F1 for epoch 391 : 0.26153846153846155


theta for epoch 392 : tensor([[ 2.7381e+00,  2.7570e+00,  2.7941e+00,  2.9213e+00,  2.9021e+00,
          2.7414e+00,  2.8892e+00,  2.7365e+00,  2.7365e+00,  1.3263e+00,
          1.3285e+00,  1.3274e+00,  1.3304e+00,  1.3253e+00,  1.3323e+00,
          1.3268e+00,  1.3236e+00,  1.2855e+00,  1.2794e+00,  1.2368e+00,
          1.2376e+00,  1.2804e+00,  1.2770e+00,  1.2766e+00,  1.2786e+00,
          1.2758e+00,  1.2758e+00,  1.2600e+00,  1.3048e+00,  1.2989e+00,
          1.3019e+00,  1.3048e+00,  1.3002e+00,  1.3030e+00,  1.2547e+00,
          1.2992e+00,  1.7369e+00,  1.7477e+00,  1.7414e+00,  1.7380e+00,
          1.7457e+00,  1.6851e+00,  1.7383e+00,  1.7229e+00,  1.7382e+00,
          1.5877e+00,  1.5715e+00,  1.5682e+00,  1.5620e+00,  1.5844e+00,
          1.5668e+00,  1.5985e+00,  1.5579e+00,  1.5603e+00],
        [ 1.2792e+00,  1.2821e+00,  1.2838e+00,  1.2829e+00,  1.2826e+00,
          1.2798e+00,  1.2808e+00,  1.2789e+00,  1.2789e+00,  2.6729e+00,
          2.6880e+00,  2.6750e+00,  2.9189e+00,  2.6610e+00,  3.0642e+00,
          2.6757e+00,  2.8867e+00,  3.0388e+00,  1.2705e+00,  1.2759e+00,
          1.2285e+00,  1.2715e+00,  1.2984e+00,  1.2979e+00,  1.2995e+00,
          1.2970e+00,  1.2970e+00,  1.2992e+00,  1.2510e+00,  1.3199e+00,
          1.3232e+00,  1.2977e+00,  1.3214e+00,  1.3244e+00,  1.2940e+00,
          1.3202e+00,  1.7484e+00,  1.7602e+00,  1.7162e+00,  1.7489e+00,
          1.7580e+00,  1.7599e+00,  1.7129e+00,  1.7304e+00,  1.7490e+00,
          1.5477e+00,  1.5856e+00,  1.5820e+00,  1.5752e+00,  1.5076e+00,
          1.5805e+00,  1.5230e+00,  1.5708e+00,  1.5734e+00],
        [ 1.2642e+00,  1.2669e+00,  1.2632e+00,  1.2686e+00,  1.2668e+00,
          1.2647e+00,  1.2651e+00,  1.2640e+00,  1.2640e+00,  1.3326e+00,
          1.3348e+00,  1.3337e+00,  1.3367e+00,  1.3316e+00,  1.2786e+00,
          1.3331e+00,  1.2697e+00,  1.3213e+00,  2.7853e+00,  2.9195e+00,
          2.9572e+00,  2.7942e+00,  2.7227e+00,  2.7194e+00,  2.8954e+00,
          2.7145e+00,  2.7145e+00,  1.2593e+00,  1.2962e+00,  1.3052e+00,
          1.3082e+00,  1.2599e+00,  1.3066e+00,  1.3094e+00,  1.3051e+00,
          1.3055e+00,  1.7414e+00,  1.7523e+00,  1.7460e+00,  1.6713e+00,
          1.7503e+00,  1.7415e+00,  1.7428e+00,  1.7272e+00,  1.6715e+00,
          1.5929e+00,  1.5765e+00,  1.5731e+00,  1.5668e+00,  1.5710e+00,
          1.5717e+00,  1.5853e+00,  1.5541e+00,  1.5651e+00],
        [ 1.2705e+00,  1.2732e+00,  1.2696e+00,  1.2751e+00,  1.2732e+00,
          1.2710e+00,  1.2715e+00,  1.2702e+00,  1.2702e+00,  1.3388e+00,
          1.3410e+00,  1.3399e+00,  1.3232e+00,  1.3377e+00,  1.2802e+00,
          1.3392e+00,  1.3353e+00,  1.2787e+00,  1.2921e+00,  1.2666e+00,
          1.2935e+00,  1.2931e+00,  1.2897e+00,  1.2892e+00,  1.2838e+00,
          1.2883e+00,  1.2883e+00,  2.9717e+00,  2.8809e+00,  2.6961e+00,
          2.7188e+00,  2.9707e+00,  2.7046e+00,  2.8610e+00,  2.7584e+00,
          2.6978e+00,  1.7443e+00,  1.7556e+00,  1.7218e+00,  1.7350e+00,
          1.7536e+00,  1.7447e+00,  1.7186e+00,  1.7286e+00,  1.7351e+00,
          1.5973e+00,  1.5804e+00,  1.5225e+00,  1.5168e+00,  1.5938e+00,
          1.5754e+00,  1.6086e+00,  1.5042e+00,  1.5686e+00],
        [ 1.9156e+00,  1.5186e+00,  6.7909e-01,  9.8926e-01,  1.4139e+00,
          1.8466e+00,  1.7198e+00,  1.9515e+00,  1.9515e+00,  1.7484e+00,
          1.3849e+00,  1.5989e+00,  1.0054e+00,  1.8040e+00,  1.9682e-01,
          1.6871e+00,  1.9755e+00,  9.0857e-01,  1.4215e+00,  1.0952e+00,
          8.3670e-01,  1.2307e+00,  1.7893e+00,  1.8552e+00,  1.6377e+00,
          1.9610e+00,  1.9610e+00,  9.3716e-01,  9.2100e-01,  1.9336e+00,
          1.7204e+00,  9.3880e-01,  1.8744e+00,  1.3295e+00,  1.9821e+00,
          1.8981e+00, -1.8560e-01, -4.2176e-01, -4.6494e-01, -2.4062e-01,
          1.4648e-02,  9.1272e-02, -3.0829e-01,  2.0399e+01,  1.9745e+00,
          2.9043e-01,  6.4988e-01,  6.7124e-01,  7.8409e-01,  4.4144e-01,
          7.8531e-01,  6.0812e-03,  8.2376e-01,  8.8010e-01],
        [ 1.3316e+00,  1.3681e+00,  1.3904e+00,  1.3995e+00,  1.3748e+00,
          1.3386e+00,  1.3087e+00,  1.3279e+00,  1.3279e+00,  1.3054e+00,
          1.4247e+00,  1.3207e+00,  1.4507e+00,  1.3806e+00,  1.4754e+00,
          1.3118e+00,  1.3558e+00,  1.3661e+00,  1.3891e+00,  1.3470e+00,
          1.4208e+00,  1.4025e+00,  1.3565e+00,  1.3498e+00,  1.2307e+00,
          1.3384e+00,  1.3384e+00,  1.3696e+00,  1.4344e+00,  1.3535e+00,
          1.1437e+00,  1.3274e+00,  1.2420e+00,  1.4096e+00,  1.2309e+00,
          1.3576e+00,  3.3670e-01,  2.6009e-01,  3.7374e-01,  3.3986e-01,
          1.3531e-01,  8.3998e-02,  3.6016e-01,  1.2721e-01, -6.4597e-02,
          3.6878e+00,  2.3493e+00,  3.6368e+00,  2.7155e+00,  1.8730e+00,
          1.4651e+00,  2.9399e+00,  3.5622e+00,  1.4296e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 392 : 173.99221293588988
Test loss for epoch 392 : 174.44111232008737
Test Precision for epoch 392 : 0.26153846153846155
Test Recall for epoch 392 : 0.26153846153846155
Test F1 for epoch 392 : 0.26153846153846155


theta for epoch 393 : tensor([[ 2.7400e+00,  2.7588e+00,  2.7960e+00,  2.9234e+00,  2.9042e+00,
          2.7432e+00,  2.8914e+00,  2.7383e+00,  2.7383e+00,  1.3263e+00,
          1.3284e+00,  1.3274e+00,  1.3303e+00,  1.3253e+00,  1.3323e+00,
          1.3267e+00,  1.3236e+00,  1.2854e+00,  1.2790e+00,  1.2364e+00,
          1.2372e+00,  1.2799e+00,  1.2766e+00,  1.2761e+00,  1.2782e+00,
          1.2753e+00,  1.2753e+00,  1.2599e+00,  1.3047e+00,  1.2987e+00,
          1.3017e+00,  1.3047e+00,  1.3001e+00,  1.3028e+00,  1.2546e+00,
          1.2990e+00,  1.7368e+00,  1.7476e+00,  1.7413e+00,  1.7379e+00,
          1.7456e+00,  1.6850e+00,  1.7382e+00,  1.7228e+00,  1.7381e+00,
          1.5877e+00,  1.5716e+00,  1.5683e+00,  1.5621e+00,  1.5844e+00,
          1.5668e+00,  1.5985e+00,  1.5579e+00,  1.5604e+00],
        [ 1.2791e+00,  1.2819e+00,  1.2836e+00,  1.2828e+00,  1.2824e+00,
          1.2796e+00,  1.2807e+00,  1.2788e+00,  1.2788e+00,  2.6747e+00,
          2.6898e+00,  2.6769e+00,  2.9212e+00,  2.6629e+00,  3.0665e+00,
          2.6776e+00,  2.8890e+00,  3.0412e+00,  1.2700e+00,  1.2754e+00,
          1.2281e+00,  1.2710e+00,  1.2979e+00,  1.2974e+00,  1.2990e+00,
          1.2965e+00,  1.2965e+00,  1.2991e+00,  1.2508e+00,  1.3197e+00,
          1.3230e+00,  1.2975e+00,  1.3212e+00,  1.3242e+00,  1.2938e+00,
          1.3200e+00,  1.7482e+00,  1.7600e+00,  1.7161e+00,  1.7487e+00,
          1.7579e+00,  1.7598e+00,  1.7127e+00,  1.7304e+00,  1.7489e+00,
          1.5478e+00,  1.5857e+00,  1.5820e+00,  1.5753e+00,  1.5076e+00,
          1.5805e+00,  1.5230e+00,  1.5709e+00,  1.5734e+00],
        [ 1.2641e+00,  1.2668e+00,  1.2631e+00,  1.2685e+00,  1.2667e+00,
          1.2647e+00,  1.2651e+00,  1.2639e+00,  1.2639e+00,  1.3326e+00,
          1.3348e+00,  1.3337e+00,  1.3367e+00,  1.3316e+00,  1.2786e+00,
          1.3331e+00,  1.2698e+00,  1.3213e+00,  2.7868e+00,  2.9214e+00,
          2.9590e+00,  2.7957e+00,  2.7242e+00,  2.7210e+00,  2.8974e+00,
          2.7160e+00,  2.7160e+00,  1.2591e+00,  1.2961e+00,  1.3051e+00,
          1.3081e+00,  1.2598e+00,  1.3064e+00,  1.3093e+00,  1.3050e+00,
          1.3054e+00,  1.7413e+00,  1.7523e+00,  1.7459e+00,  1.6712e+00,
          1.7503e+00,  1.7413e+00,  1.7427e+00,  1.7271e+00,  1.6713e+00,
          1.5930e+00,  1.5766e+00,  1.5732e+00,  1.5669e+00,  1.5711e+00,
          1.5718e+00,  1.5854e+00,  1.5541e+00,  1.5652e+00],
        [ 1.2703e+00,  1.2731e+00,  1.2694e+00,  1.2749e+00,  1.2731e+00,
          1.2709e+00,  1.2714e+00,  1.2701e+00,  1.2701e+00,  1.3387e+00,
          1.3409e+00,  1.3398e+00,  1.3232e+00,  1.3376e+00,  1.2801e+00,
          1.3392e+00,  1.3353e+00,  1.2786e+00,  1.2917e+00,  1.2662e+00,
          1.2930e+00,  1.2927e+00,  1.2892e+00,  1.2887e+00,  1.2833e+00,
          1.2879e+00,  1.2879e+00,  2.9740e+00,  2.8829e+00,  2.6979e+00,
          2.7206e+00,  2.9730e+00,  2.7064e+00,  2.8630e+00,  2.7603e+00,
          2.6996e+00,  1.7442e+00,  1.7555e+00,  1.7217e+00,  1.7348e+00,
          1.7535e+00,  1.7446e+00,  1.7185e+00,  1.7285e+00,  1.7349e+00,
          1.5973e+00,  1.5804e+00,  1.5225e+00,  1.5169e+00,  1.5938e+00,
          1.5754e+00,  1.6086e+00,  1.5042e+00,  1.5687e+00],
        [ 1.9162e+00,  1.5193e+00,  6.7998e-01,  9.9001e-01,  1.4146e+00,
          1.8472e+00,  1.7205e+00,  1.9522e+00,  1.9522e+00,  1.7492e+00,
          1.3857e+00,  1.5996e+00,  1.0062e+00,  1.8047e+00,  1.9775e-01,
          1.6878e+00,  1.9762e+00,  9.0940e-01,  1.4221e+00,  1.0960e+00,
          8.3748e-01,  1.2314e+00,  1.7899e+00,  1.8558e+00,  1.6384e+00,
          1.9615e+00,  1.9615e+00,  9.3802e-01,  9.2180e-01,  1.9342e+00,
          1.7211e+00,  9.3966e-01,  1.8751e+00,  1.3302e+00,  1.9827e+00,
          1.8987e+00, -1.8672e-01, -4.2277e-01, -4.6594e-01, -2.4179e-01,
          1.3430e-02,  8.9927e-02, -3.0935e-01,  2.0435e+01,  1.9624e+00,
          2.9128e-01,  6.5065e-01,  6.7200e-01,  7.8483e-01,  4.4225e-01,
          7.8604e-01,  6.9911e-03,  8.2454e-01,  8.8081e-01],
        [ 1.3312e+00,  1.3677e+00,  1.3898e+00,  1.3991e+00,  1.3744e+00,
          1.3381e+00,  1.3082e+00,  1.3275e+00,  1.3275e+00,  1.3050e+00,
          1.4243e+00,  1.3203e+00,  1.4503e+00,  1.3801e+00,  1.4749e+00,
          1.3114e+00,  1.3554e+00,  1.3656e+00,  1.3886e+00,  1.3463e+00,
          1.4203e+00,  1.4020e+00,  1.3560e+00,  1.3492e+00,  1.2300e+00,
          1.3379e+00,  1.3379e+00,  1.3691e+00,  1.4339e+00,  1.3531e+00,
          1.1432e+00,  1.3268e+00,  1.2415e+00,  1.4091e+00,  1.2305e+00,
          1.3572e+00,  3.3619e-01,  2.5956e-01,  3.7321e-01,  3.3931e-01,
          1.3478e-01,  8.3437e-02,  3.5964e-01,  1.2659e-01, -6.4940e-02,
          3.6916e+00,  2.3509e+00,  3.6404e+00,  2.7174e+00,  1.8743e+00,
          1.4663e+00,  2.9418e+00,  3.5669e+00,  1.4309e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 393 : 173.98645367218484
Test loss for epoch 393 : 174.43676413511486
Test Precision for epoch 393 : 0.26153846153846155
Test Recall for epoch 393 : 0.26153846153846155
Test F1 for epoch 393 : 0.26153846153846155


theta for epoch 394 : tensor([[ 2.7419e+00,  2.7607e+00,  2.7979e+00,  2.9255e+00,  2.9063e+00,
          2.7451e+00,  2.8935e+00,  2.7402e+00,  2.7402e+00,  1.3261e+00,
          1.3282e+00,  1.3271e+00,  1.3301e+00,  1.3250e+00,  1.3320e+00,
          1.3265e+00,  1.3233e+00,  1.2852e+00,  1.2791e+00,  1.2365e+00,
          1.2373e+00,  1.2800e+00,  1.2767e+00,  1.2762e+00,  1.2783e+00,
          1.2754e+00,  1.2754e+00,  1.2597e+00,  1.3045e+00,  1.2986e+00,
          1.3016e+00,  1.3045e+00,  1.2999e+00,  1.3027e+00,  1.2544e+00,
          1.2988e+00,  1.7368e+00,  1.7476e+00,  1.7413e+00,  1.7379e+00,
          1.7456e+00,  1.6850e+00,  1.7382e+00,  1.7228e+00,  1.7381e+00,
          1.5874e+00,  1.5712e+00,  1.5679e+00,  1.5617e+00,  1.5841e+00,
          1.5665e+00,  1.5981e+00,  1.5576e+00,  1.5600e+00],
        [ 1.2789e+00,  1.2818e+00,  1.2835e+00,  1.2827e+00,  1.2823e+00,
          1.2795e+00,  1.2805e+00,  1.2786e+00,  1.2786e+00,  2.6763e+00,
          2.6914e+00,  2.6786e+00,  2.9233e+00,  2.6646e+00,  3.0686e+00,
          2.6791e+00,  2.8912e+00,  3.0433e+00,  1.2702e+00,  1.2756e+00,
          1.2282e+00,  1.2712e+00,  1.2980e+00,  1.2975e+00,  1.2992e+00,
          1.2966e+00,  1.2966e+00,  1.2989e+00,  1.2506e+00,  1.3196e+00,
          1.3229e+00,  1.2974e+00,  1.3210e+00,  1.3240e+00,  1.2936e+00,
          1.3199e+00,  1.7482e+00,  1.7601e+00,  1.7161e+00,  1.7488e+00,
          1.7579e+00,  1.7598e+00,  1.7127e+00,  1.7305e+00,  1.7490e+00,
          1.5474e+00,  1.5853e+00,  1.5817e+00,  1.5749e+00,  1.5073e+00,
          1.5801e+00,  1.5226e+00,  1.5705e+00,  1.5731e+00],
        [ 1.2640e+00,  1.2666e+00,  1.2629e+00,  1.2684e+00,  1.2665e+00,
          1.2645e+00,  1.2649e+00,  1.2637e+00,  1.2637e+00,  1.3324e+00,
          1.3345e+00,  1.3335e+00,  1.3364e+00,  1.3313e+00,  1.2783e+00,
          1.3328e+00,  1.2695e+00,  1.3211e+00,  2.7888e+00,  2.9238e+00,
          2.9613e+00,  2.7977e+00,  2.7262e+00,  2.7229e+00,  2.8998e+00,
          2.7180e+00,  2.7180e+00,  1.2589e+00,  1.2959e+00,  1.3049e+00,
          1.3080e+00,  1.2596e+00,  1.3063e+00,  1.3091e+00,  1.3049e+00,
          1.3052e+00,  1.7413e+00,  1.7523e+00,  1.7459e+00,  1.6711e+00,
          1.7503e+00,  1.7413e+00,  1.7427e+00,  1.7271e+00,  1.6713e+00,
          1.5926e+00,  1.5762e+00,  1.5729e+00,  1.5666e+00,  1.5707e+00,
          1.5714e+00,  1.5851e+00,  1.5537e+00,  1.5648e+00],
        [ 1.2702e+00,  1.2729e+00,  1.2693e+00,  1.2748e+00,  1.2729e+00,
          1.2707e+00,  1.2712e+00,  1.2699e+00,  1.2699e+00,  1.3385e+00,
          1.3407e+00,  1.3396e+00,  1.3229e+00,  1.3374e+00,  1.2799e+00,
          1.3389e+00,  1.3350e+00,  1.2784e+00,  1.2918e+00,  1.2662e+00,
          1.2931e+00,  1.2928e+00,  1.2893e+00,  1.2888e+00,  1.2834e+00,
          1.2880e+00,  1.2880e+00,  2.9762e+00,  2.8849e+00,  2.6997e+00,
          2.7224e+00,  2.9752e+00,  2.7083e+00,  2.8650e+00,  2.7622e+00,
          2.7015e+00,  1.7442e+00,  1.7555e+00,  1.7217e+00,  1.7347e+00,
          1.7535e+00,  1.7445e+00,  1.7185e+00,  1.7286e+00,  1.7349e+00,
          1.5970e+00,  1.5800e+00,  1.5222e+00,  1.5165e+00,  1.5935e+00,
          1.5751e+00,  1.6082e+00,  1.5038e+00,  1.5683e+00],
        [ 1.9164e+00,  1.5195e+00,  6.8029e-01,  9.9023e-01,  1.4148e+00,
          1.8474e+00,  1.7207e+00,  1.9524e+00,  1.9524e+00,  1.7493e+00,
          1.3858e+00,  1.5998e+00,  1.0064e+00,  1.8049e+00,  1.9804e-01,
          1.6879e+00,  1.9763e+00,  9.0956e-01,  1.4224e+00,  1.0964e+00,
          8.3775e-01,  1.2317e+00,  1.7901e+00,  1.8561e+00,  1.6388e+00,
          1.9618e+00,  1.9618e+00,  9.3831e-01,  9.2200e-01,  1.9344e+00,
          1.7213e+00,  9.3992e-01,  1.8752e+00,  1.3304e+00,  1.9829e+00,
          1.8989e+00, -1.8732e-01, -4.2326e-01, -4.6643e-01, -2.4244e-01,
          1.2740e-02,  8.9112e-02, -3.0990e-01,  2.0471e+01,  1.9511e+00,
          2.9148e-01,  6.5076e-01,  6.7210e-01,  7.8492e-01,  4.4241e-01,
          7.8612e-01,  7.2509e-03,  8.2466e-01,  8.8087e-01],
        [ 1.3313e+00,  1.3678e+00,  1.3898e+00,  1.3992e+00,  1.3745e+00,
          1.3383e+00,  1.3084e+00,  1.3276e+00,  1.3276e+00,  1.3051e+00,
          1.4244e+00,  1.3204e+00,  1.4504e+00,  1.3803e+00,  1.4750e+00,
          1.3115e+00,  1.3555e+00,  1.3657e+00,  1.3888e+00,  1.3464e+00,
          1.4205e+00,  1.4022e+00,  1.3562e+00,  1.3494e+00,  1.2302e+00,
          1.3381e+00,  1.3381e+00,  1.3691e+00,  1.4341e+00,  1.3532e+00,
          1.1433e+00,  1.3268e+00,  1.2417e+00,  1.4093e+00,  1.2306e+00,
          1.3573e+00,  3.3633e-01,  2.5968e-01,  3.7334e-01,  3.3942e-01,
          1.3491e-01,  8.3537e-02,  3.5977e-01,  1.2664e-01, -6.4621e-02,
          3.6946e+00,  2.3518e+00,  3.6433e+00,  2.7187e+00,  1.8750e+00,
          1.4669e+00,  2.9431e+00,  3.5710e+00,  1.4315e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 394 : 173.98074942877705
Test loss for epoch 394 : 174.43351491204507
Test Precision for epoch 394 : 0.26153846153846155
Test Recall for epoch 394 : 0.26153846153846155
Test F1 for epoch 394 : 0.26153846153846155


theta for epoch 395 : tensor([[ 2.7438e+00,  2.7626e+00,  2.7998e+00,  2.9277e+00,  2.9085e+00,
          2.7470e+00,  2.8956e+00,  2.7421e+00,  2.7421e+00,  1.3259e+00,
          1.3280e+00,  1.3270e+00,  1.3299e+00,  1.3249e+00,  1.3319e+00,
          1.3264e+00,  1.3232e+00,  1.2850e+00,  1.2787e+00,  1.2361e+00,
          1.2369e+00,  1.2797e+00,  1.2764e+00,  1.2759e+00,  1.2779e+00,
          1.2751e+00,  1.2751e+00,  1.2596e+00,  1.3044e+00,  1.2984e+00,
          1.3014e+00,  1.3044e+00,  1.2998e+00,  1.3025e+00,  1.2542e+00,
          1.2987e+00,  1.7367e+00,  1.7475e+00,  1.7413e+00,  1.7379e+00,
          1.7456e+00,  1.6849e+00,  1.7382e+00,  1.7228e+00,  1.7381e+00,
          1.5873e+00,  1.5711e+00,  1.5678e+00,  1.5616e+00,  1.5840e+00,
          1.5664e+00,  1.5981e+00,  1.5575e+00,  1.5600e+00],
        [ 1.2787e+00,  1.2816e+00,  1.2834e+00,  1.2825e+00,  1.2821e+00,
          1.2793e+00,  1.2803e+00,  1.2784e+00,  1.2784e+00,  2.6781e+00,
          2.6932e+00,  2.6805e+00,  2.9256e+00,  2.6665e+00,  3.0710e+00,
          2.6810e+00,  2.8935e+00,  3.0457e+00,  1.2698e+00,  1.2752e+00,
          1.2278e+00,  1.2708e+00,  1.2977e+00,  1.2972e+00,  1.2988e+00,
          1.2963e+00,  1.2963e+00,  1.2987e+00,  1.2504e+00,  1.3194e+00,
          1.3227e+00,  1.2973e+00,  1.3209e+00,  1.3239e+00,  1.2935e+00,
          1.3197e+00,  1.7482e+00,  1.7600e+00,  1.7160e+00,  1.7487e+00,
          1.7579e+00,  1.7597e+00,  1.7127e+00,  1.7304e+00,  1.7489e+00,
          1.5473e+00,  1.5852e+00,  1.5816e+00,  1.5749e+00,  1.5072e+00,
          1.5801e+00,  1.5225e+00,  1.5705e+00,  1.5730e+00],
        [ 1.2638e+00,  1.2665e+00,  1.2627e+00,  1.2682e+00,  1.2664e+00,
          1.2643e+00,  1.2647e+00,  1.2636e+00,  1.2636e+00,  1.3323e+00,
          1.3344e+00,  1.3334e+00,  1.3364e+00,  1.3312e+00,  1.2783e+00,
          1.3327e+00,  1.2694e+00,  1.3210e+00,  2.7906e+00,  2.9259e+00,
          2.9633e+00,  2.7995e+00,  2.7279e+00,  2.7246e+00,  2.9019e+00,
          2.7197e+00,  2.7197e+00,  1.2588e+00,  1.2958e+00,  1.3048e+00,
          1.3078e+00,  1.2594e+00,  1.3062e+00,  1.3090e+00,  1.3047e+00,
          1.3051e+00,  1.7412e+00,  1.7522e+00,  1.7458e+00,  1.6710e+00,
          1.7502e+00,  1.7412e+00,  1.7427e+00,  1.7270e+00,  1.6712e+00,
          1.5926e+00,  1.5762e+00,  1.5728e+00,  1.5665e+00,  1.5707e+00,
          1.5714e+00,  1.5850e+00,  1.5537e+00,  1.5648e+00],
        [ 1.2700e+00,  1.2728e+00,  1.2691e+00,  1.2746e+00,  1.2727e+00,
          1.2706e+00,  1.2711e+00,  1.2698e+00,  1.2698e+00,  1.3383e+00,
          1.3405e+00,  1.3395e+00,  1.3228e+00,  1.3373e+00,  1.2798e+00,
          1.3388e+00,  1.3349e+00,  1.2783e+00,  1.2915e+00,  1.2659e+00,
          1.2928e+00,  1.2925e+00,  1.2890e+00,  1.2885e+00,  1.2831e+00,
          1.2877e+00,  1.2877e+00,  2.9785e+00,  2.8869e+00,  2.7016e+00,
          2.7241e+00,  2.9775e+00,  2.7101e+00,  2.8670e+00,  2.7642e+00,
          2.7033e+00,  1.7441e+00,  1.7554e+00,  1.7217e+00,  1.7346e+00,
          1.7534e+00,  1.7444e+00,  1.7184e+00,  1.7285e+00,  1.7348e+00,
          1.5969e+00,  1.5800e+00,  1.5222e+00,  1.5165e+00,  1.5934e+00,
          1.5750e+00,  1.6082e+00,  1.5038e+00,  1.5683e+00],
        [ 1.9169e+00,  1.5201e+00,  6.8097e-01,  9.9079e-01,  1.4153e+00,
          1.8479e+00,  1.7212e+00,  1.9528e+00,  1.9528e+00,  1.7498e+00,
          1.3863e+00,  1.6003e+00,  1.0070e+00,  1.8054e+00,  1.9876e-01,
          1.6884e+00,  1.9768e+00,  9.1016e-01,  1.4229e+00,  1.0970e+00,
          8.3835e-01,  1.2322e+00,  1.7906e+00,  1.8565e+00,  1.6394e+00,
          1.9622e+00,  1.9622e+00,  9.3899e-01,  9.2261e-01,  1.9349e+00,
          1.7218e+00,  9.4059e-01,  1.8758e+00,  1.3309e+00,  1.9834e+00,
          1.8994e+00, -1.8826e-01, -4.2410e-01, -4.6725e-01, -2.4343e-01,
          1.1707e-02,  8.7956e-02, -3.1078e-01,  2.0507e+01,  1.9397e+00,
          2.9211e-01,  6.5131e-01,  6.7264e-01,  7.8544e-01,  4.4300e-01,
          7.8663e-01,  7.9492e-03,  8.2522e-01,  8.8136e-01],
        [ 1.3311e+00,  1.3675e+00,  1.3894e+00,  1.3989e+00,  1.3742e+00,
          1.3380e+00,  1.3081e+00,  1.3274e+00,  1.3274e+00,  1.3049e+00,
          1.4242e+00,  1.3202e+00,  1.4502e+00,  1.3801e+00,  1.4748e+00,
          1.3113e+00,  1.3553e+00,  1.3655e+00,  1.3885e+00,  1.3460e+00,
          1.4202e+00,  1.4019e+00,  1.3560e+00,  1.3492e+00,  1.2298e+00,
          1.3378e+00,  1.3378e+00,  1.3687e+00,  1.4338e+00,  1.3530e+00,
          1.1431e+00,  1.3265e+00,  1.2414e+00,  1.4090e+00,  1.2304e+00,
          1.3571e+00,  3.3605e-01,  2.5939e-01,  3.7305e-01,  3.3912e-01,
          1.3462e-01,  8.3224e-02,  3.5950e-01,  1.2627e-01, -6.4717e-02,
          3.6982e+00,  2.3532e+00,  3.6467e+00,  2.7205e+00,  1.8762e+00,
          1.4679e+00,  2.9448e+00,  3.5755e+00,  1.4325e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 395 : 173.97509896593297
Test loss for epoch 395 : 174.42960867310293
Test Precision for epoch 395 : 0.26153846153846155
Test Recall for epoch 395 : 0.26153846153846155
Test F1 for epoch 395 : 0.26153846153846155


theta for epoch 396 : tensor([[ 2.7457e+00,  2.7645e+00,  2.8017e+00,  2.9298e+00,  2.9107e+00,
          2.7489e+00,  2.8978e+00,  2.7441e+00,  2.7441e+00,  1.3257e+00,
          1.3278e+00,  1.3268e+00,  1.3297e+00,  1.3246e+00,  1.3316e+00,
          1.3261e+00,  1.3230e+00,  1.2848e+00,  1.2786e+00,  1.2360e+00,
          1.2368e+00,  1.2796e+00,  1.2763e+00,  1.2758e+00,  1.2778e+00,
          1.2750e+00,  1.2750e+00,  1.2594e+00,  1.3042e+00,  1.2982e+00,
          1.3013e+00,  1.3042e+00,  1.2996e+00,  1.3024e+00,  1.2541e+00,
          1.2985e+00,  1.7367e+00,  1.7475e+00,  1.7412e+00,  1.7378e+00,
          1.7455e+00,  1.6849e+00,  1.7381e+00,  1.7227e+00,  1.7381e+00,
          1.5872e+00,  1.5710e+00,  1.5677e+00,  1.5615e+00,  1.5838e+00,
          1.5663e+00,  1.5979e+00,  1.5574e+00,  1.5598e+00],
        [ 1.2785e+00,  1.2814e+00,  1.2832e+00,  1.2823e+00,  1.2819e+00,
          1.2791e+00,  1.2801e+00,  1.2783e+00,  1.2783e+00,  2.6798e+00,
          2.6950e+00,  2.6823e+00,  2.9278e+00,  2.6683e+00,  3.0732e+00,
          2.6827e+00,  2.8958e+00,  3.0480e+00,  1.2696e+00,  1.2751e+00,
          1.2277e+00,  1.2706e+00,  1.2975e+00,  1.2970e+00,  1.2987e+00,
          1.2962e+00,  1.2962e+00,  1.2986e+00,  1.2502e+00,  1.3192e+00,
          1.3225e+00,  1.2971e+00,  1.3207e+00,  1.3237e+00,  1.2933e+00,
          1.3195e+00,  1.7481e+00,  1.7599e+00,  1.7160e+00,  1.7487e+00,
          1.7578e+00,  1.7597e+00,  1.7126e+00,  1.7305e+00,  1.7489e+00,
          1.5472e+00,  1.5851e+00,  1.5815e+00,  1.5747e+00,  1.5070e+00,
          1.5800e+00,  1.5223e+00,  1.5703e+00,  1.5729e+00],
        [ 1.2636e+00,  1.2663e+00,  1.2625e+00,  1.2680e+00,  1.2662e+00,
          1.2641e+00,  1.2645e+00,  1.2634e+00,  1.2634e+00,  1.3320e+00,
          1.3341e+00,  1.3331e+00,  1.3361e+00,  1.3310e+00,  1.2780e+00,
          1.3325e+00,  1.2692e+00,  1.3207e+00,  2.7926e+00,  2.9283e+00,
          2.9656e+00,  2.8015e+00,  2.7299e+00,  2.7266e+00,  2.9043e+00,
          2.7217e+00,  2.7217e+00,  1.2585e+00,  1.2956e+00,  1.3046e+00,
          1.3077e+00,  1.2592e+00,  1.3060e+00,  1.3088e+00,  1.3046e+00,
          1.3049e+00,  1.7412e+00,  1.7522e+00,  1.7458e+00,  1.6709e+00,
          1.7502e+00,  1.7411e+00,  1.7427e+00,  1.7270e+00,  1.6712e+00,
          1.5924e+00,  1.5760e+00,  1.5727e+00,  1.5664e+00,  1.5706e+00,
          1.5712e+00,  1.5849e+00,  1.5535e+00,  1.5647e+00],
        [ 1.2699e+00,  1.2726e+00,  1.2688e+00,  1.2745e+00,  1.2726e+00,
          1.2704e+00,  1.2709e+00,  1.2696e+00,  1.2696e+00,  1.3381e+00,
          1.3403e+00,  1.3393e+00,  1.3226e+00,  1.3371e+00,  1.2796e+00,
          1.3386e+00,  1.3347e+00,  1.2781e+00,  1.2914e+00,  1.2657e+00,
          1.2927e+00,  1.2924e+00,  1.2889e+00,  1.2884e+00,  1.2829e+00,
          1.2876e+00,  1.2876e+00,  2.9808e+00,  2.8889e+00,  2.7034e+00,
          2.7259e+00,  2.9798e+00,  2.7119e+00,  2.8690e+00,  2.7661e+00,
          2.7051e+00,  1.7441e+00,  1.7554e+00,  1.7216e+00,  1.7346e+00,
          1.7534e+00,  1.7444e+00,  1.7184e+00,  1.7285e+00,  1.7348e+00,
          1.5968e+00,  1.5798e+00,  1.5221e+00,  1.5164e+00,  1.5933e+00,
          1.5749e+00,  1.6080e+00,  1.5036e+00,  1.5681e+00],
        [ 1.9172e+00,  1.5204e+00,  6.8149e-01,  9.9120e-01,  1.4157e+00,
          1.8482e+00,  1.7216e+00,  1.9532e+00,  1.9532e+00,  1.7501e+00,
          1.3867e+00,  1.6006e+00,  1.0074e+00,  1.8057e+00,  1.9929e-01,
          1.6888e+00,  1.9771e+00,  9.1056e-01,  1.4233e+00,  1.0975e+00,
          8.3881e-01,  1.2326e+00,  1.7910e+00,  1.8569e+00,  1.6399e+00,
          1.9626e+00,  1.9626e+00,  9.3950e-01,  9.2304e-01,  1.9353e+00,
          1.7221e+00,  9.4108e-01,  1.8761e+00,  1.3313e+00,  1.9838e+00,
          1.8998e+00, -1.8905e-01, -4.2478e-01, -4.6792e-01, -2.4426e-01,
          1.0823e-02,  8.6951e-02, -3.1152e-01,  2.0543e+01,  1.9286e+00,
          2.9256e-01,  6.5168e-01,  6.7300e-01,  7.8578e-01,  4.4341e-01,
          7.8696e-01,  8.4696e-03,  8.2559e-01,  8.8168e-01],
        [ 1.3310e+00,  1.3675e+00,  1.3893e+00,  1.3989e+00,  1.3742e+00,
          1.3380e+00,  1.3081e+00,  1.3273e+00,  1.3273e+00,  1.3048e+00,
          1.4241e+00,  1.3201e+00,  1.4501e+00,  1.3800e+00,  1.4747e+00,
          1.3112e+00,  1.3553e+00,  1.3654e+00,  1.3885e+00,  1.3459e+00,
          1.4201e+00,  1.4019e+00,  1.3560e+00,  1.3492e+00,  1.2296e+00,
          1.3378e+00,  1.3378e+00,  1.3686e+00,  1.4338e+00,  1.3530e+00,
          1.1430e+00,  1.3263e+00,  1.2414e+00,  1.4090e+00,  1.2303e+00,
          1.3571e+00,  3.3599e-01,  2.5931e-01,  3.7297e-01,  3.3903e-01,
          1.3455e-01,  8.3125e-02,  3.5943e-01,  1.2612e-01, -6.4600e-02,
          3.7015e+00,  2.3544e+00,  3.6499e+00,  2.7220e+00,  1.8771e+00,
          1.4687e+00,  2.9463e+00,  3.5798e+00,  1.4333e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 396 : 173.96950446463663
Test loss for epoch 396 : 174.42606682073952
Test Precision for epoch 396 : 0.26153846153846155
Test Recall for epoch 396 : 0.26153846153846155
Test F1 for epoch 396 : 0.26153846153846155


theta for epoch 397 : tensor([[ 2.7477e+00,  2.7665e+00,  2.8036e+00,  2.9320e+00,  2.9129e+00,
          2.7509e+00,  2.9000e+00,  2.7460e+00,  2.7460e+00,  1.3255e+00,
          1.3276e+00,  1.3266e+00,  1.3295e+00,  1.3245e+00,  1.3315e+00,
          1.3260e+00,  1.3228e+00,  1.2846e+00,  1.2784e+00,  1.2358e+00,
          1.2366e+00,  1.2794e+00,  1.2760e+00,  1.2756e+00,  1.2776e+00,
          1.2748e+00,  1.2748e+00,  1.2592e+00,  1.3040e+00,  1.2981e+00,
          1.3011e+00,  1.3040e+00,  1.2994e+00,  1.3022e+00,  1.2539e+00,
          1.2983e+00,  1.7367e+00,  1.7474e+00,  1.7412e+00,  1.7378e+00,
          1.7455e+00,  1.6849e+00,  1.7381e+00,  1.7227e+00,  1.7380e+00,
          1.5870e+00,  1.5708e+00,  1.5675e+00,  1.5613e+00,  1.5836e+00,
          1.5661e+00,  1.5977e+00,  1.5572e+00,  1.5596e+00],
        [ 1.2784e+00,  1.2812e+00,  1.2831e+00,  1.2822e+00,  1.2817e+00,
          1.2789e+00,  1.2800e+00,  1.2781e+00,  1.2781e+00,  2.6816e+00,
          2.6967e+00,  2.6842e+00,  2.9300e+00,  2.6702e+00,  3.0755e+00,
          2.6844e+00,  2.8981e+00,  3.0503e+00,  1.2694e+00,  1.2749e+00,
          1.2275e+00,  1.2704e+00,  1.2974e+00,  1.2968e+00,  1.2985e+00,
          1.2960e+00,  1.2960e+00,  1.2984e+00,  1.2501e+00,  1.3191e+00,
          1.3224e+00,  1.2970e+00,  1.3205e+00,  1.3235e+00,  1.2931e+00,
          1.3194e+00,  1.7481e+00,  1.7599e+00,  1.7160e+00,  1.7486e+00,
          1.7578e+00,  1.7597e+00,  1.7126e+00,  1.7305e+00,  1.7489e+00,
          1.5470e+00,  1.5849e+00,  1.5813e+00,  1.5746e+00,  1.5068e+00,
          1.5798e+00,  1.5221e+00,  1.5702e+00,  1.5727e+00],
        [ 1.2635e+00,  1.2661e+00,  1.2623e+00,  1.2678e+00,  1.2660e+00,
          1.2640e+00,  1.2644e+00,  1.2632e+00,  1.2632e+00,  1.3319e+00,
          1.3340e+00,  1.3330e+00,  1.3359e+00,  1.3308e+00,  1.2778e+00,
          1.3323e+00,  1.2690e+00,  1.3206e+00,  2.7946e+00,  2.9306e+00,
          2.9678e+00,  2.8034e+00,  2.7318e+00,  2.7285e+00,  2.9066e+00,
          2.7236e+00,  2.7236e+00,  1.2583e+00,  1.2954e+00,  1.3044e+00,
          1.3075e+00,  1.2590e+00,  1.3058e+00,  1.3086e+00,  1.3044e+00,
          1.3047e+00,  1.7412e+00,  1.7521e+00,  1.7457e+00,  1.6709e+00,
          1.7501e+00,  1.7410e+00,  1.7426e+00,  1.7270e+00,  1.6711e+00,
          1.5922e+00,  1.5758e+00,  1.5725e+00,  1.5662e+00,  1.5704e+00,
          1.5710e+00,  1.5847e+00,  1.5533e+00,  1.5645e+00],
        [ 1.2697e+00,  1.2724e+00,  1.2686e+00,  1.2743e+00,  1.2724e+00,
          1.2702e+00,  1.2707e+00,  1.2694e+00,  1.2694e+00,  1.3380e+00,
          1.3402e+00,  1.3391e+00,  1.3224e+00,  1.3369e+00,  1.2794e+00,
          1.3384e+00,  1.3345e+00,  1.2780e+00,  1.2912e+00,  1.2655e+00,
          1.2925e+00,  1.2922e+00,  1.2887e+00,  1.2882e+00,  1.2827e+00,
          1.2874e+00,  1.2874e+00,  2.9831e+00,  2.8910e+00,  2.7053e+00,
          2.7278e+00,  2.9821e+00,  2.7138e+00,  2.8710e+00,  2.7681e+00,
          2.7070e+00,  1.7441e+00,  1.7554e+00,  1.7216e+00,  1.7345e+00,
          1.7533e+00,  1.7443e+00,  1.7184e+00,  1.7285e+00,  1.7347e+00,
          1.5966e+00,  1.5797e+00,  1.5219e+00,  1.5162e+00,  1.5931e+00,
          1.5747e+00,  1.6078e+00,  1.5034e+00,  1.5680e+00],
        [ 1.9176e+00,  1.5208e+00,  6.8201e-01,  9.9161e-01,  1.4161e+00,
          1.8486e+00,  1.7219e+00,  1.9535e+00,  1.9535e+00,  1.7504e+00,
          1.3871e+00,  1.6010e+00,  1.0078e+00,  1.8061e+00,  1.9983e-01,
          1.6891e+00,  1.9775e+00,  9.1097e-01,  1.4237e+00,  1.0980e+00,
          8.3925e-01,  1.2330e+00,  1.7913e+00,  1.8573e+00,  1.6403e+00,
          1.9630e+00,  1.9630e+00,  9.3999e-01,  9.2346e-01,  1.9356e+00,
          1.7225e+00,  9.4156e-01,  1.8765e+00,  1.3317e+00,  1.9841e+00,
          1.9001e+00, -1.8983e-01, -4.2546e-01, -4.6859e-01, -2.4509e-01,
          9.9521e-03,  8.5961e-02, -3.1225e-01,  2.0578e+01,  1.9178e+00,
          2.9298e-01,  6.5202e-01,  6.7333e-01,  7.8609e-01,  4.4379e-01,
          7.8726e-01,  8.9690e-03,  8.2594e-01,  8.8196e-01],
        [ 1.3310e+00,  1.3674e+00,  1.3891e+00,  1.3988e+00,  1.3741e+00,
          1.3380e+00,  1.3080e+00,  1.3273e+00,  1.3273e+00,  1.3048e+00,
          1.4241e+00,  1.3201e+00,  1.4501e+00,  1.3800e+00,  1.4746e+00,
          1.3112e+00,  1.3553e+00,  1.3654e+00,  1.3885e+00,  1.3457e+00,
          1.4201e+00,  1.4018e+00,  1.3559e+00,  1.3491e+00,  1.2295e+00,
          1.3378e+00,  1.3378e+00,  1.3684e+00,  1.4337e+00,  1.3530e+00,
          1.1430e+00,  1.3262e+00,  1.2414e+00,  1.4089e+00,  1.2303e+00,
          1.3571e+00,  3.3594e-01,  2.5923e-01,  3.7290e-01,  3.3895e-01,
          1.3449e-01,  8.3035e-02,  3.5937e-01,  1.2598e-01, -6.4475e-02,
          3.7049e+00,  2.3556e+00,  3.6531e+00,  2.7235e+00,  1.8780e+00,
          1.4696e+00,  2.9478e+00,  3.5841e+00,  1.4341e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 397 : 173.96396127449455
Test loss for epoch 397 : 174.42257385921596
Test Precision for epoch 397 : 0.26153846153846155
Test Recall for epoch 397 : 0.26153846153846155
Test F1 for epoch 397 : 0.26153846153846155


theta for epoch 398 : tensor([[ 2.7496e+00,  2.7684e+00,  2.8055e+00,  2.9342e+00,  2.9150e+00,
          2.7528e+00,  2.9021e+00,  2.7479e+00,  2.7479e+00,  1.3254e+00,
          1.3275e+00,  1.3264e+00,  1.3294e+00,  1.3243e+00,  1.3313e+00,
          1.3258e+00,  1.3227e+00,  1.2845e+00,  1.2782e+00,  1.2356e+00,
          1.2364e+00,  1.2792e+00,  1.2759e+00,  1.2754e+00,  1.2774e+00,
          1.2746e+00,  1.2746e+00,  1.2590e+00,  1.3038e+00,  1.2979e+00,
          1.3009e+00,  1.3038e+00,  1.2992e+00,  1.3020e+00,  1.2537e+00,
          1.2982e+00,  1.7366e+00,  1.7474e+00,  1.7411e+00,  1.7378e+00,
          1.7454e+00,  1.6848e+00,  1.7380e+00,  1.7226e+00,  1.7380e+00,
          1.5868e+00,  1.5707e+00,  1.5674e+00,  1.5612e+00,  1.5835e+00,
          1.5660e+00,  1.5976e+00,  1.5571e+00,  1.5595e+00],
        [ 1.2782e+00,  1.2811e+00,  1.2830e+00,  1.2821e+00,  1.2816e+00,
          1.2788e+00,  1.2798e+00,  1.2779e+00,  1.2779e+00,  2.6833e+00,
          2.6985e+00,  2.6860e+00,  2.9323e+00,  2.6720e+00,  3.0778e+00,
          2.6862e+00,  2.9005e+00,  3.0527e+00,  1.2692e+00,  1.2747e+00,
          1.2272e+00,  1.2702e+00,  1.2972e+00,  1.2967e+00,  1.2983e+00,
          1.2958e+00,  1.2958e+00,  1.2982e+00,  1.2499e+00,  1.3189e+00,
          1.3222e+00,  1.2969e+00,  1.3204e+00,  1.3234e+00,  1.2930e+00,
          1.3192e+00,  1.7480e+00,  1.7598e+00,  1.7159e+00,  1.7486e+00,
          1.7577e+00,  1.7596e+00,  1.7125e+00,  1.7305e+00,  1.7489e+00,
          1.5469e+00,  1.5848e+00,  1.5812e+00,  1.5745e+00,  1.5067e+00,
          1.5797e+00,  1.5220e+00,  1.5701e+00,  1.5727e+00],
        [ 1.2633e+00,  1.2660e+00,  1.2621e+00,  1.2677e+00,  1.2659e+00,
          1.2638e+00,  1.2642e+00,  1.2631e+00,  1.2631e+00,  1.3317e+00,
          1.3339e+00,  1.3328e+00,  1.3358e+00,  1.3307e+00,  1.2777e+00,
          1.3322e+00,  1.2689e+00,  1.3205e+00,  2.7964e+00,  2.9328e+00,
          2.9699e+00,  2.8053e+00,  2.7335e+00,  2.7303e+00,  2.9088e+00,
          2.7254e+00,  2.7254e+00,  1.2582e+00,  1.2953e+00,  1.3043e+00,
          1.3073e+00,  1.2588e+00,  1.3057e+00,  1.3085e+00,  1.3043e+00,
          1.3046e+00,  1.7411e+00,  1.7521e+00,  1.7457e+00,  1.6708e+00,
          1.7501e+00,  1.7409e+00,  1.7426e+00,  1.7269e+00,  1.6710e+00,
          1.5922e+00,  1.5757e+00,  1.5724e+00,  1.5661e+00,  1.5703e+00,
          1.5710e+00,  1.5846e+00,  1.5531e+00,  1.5644e+00],
        [ 1.2695e+00,  1.2723e+00,  1.2684e+00,  1.2741e+00,  1.2722e+00,
          1.2700e+00,  1.2705e+00,  1.2693e+00,  1.2693e+00,  1.3378e+00,
          1.3400e+00,  1.3390e+00,  1.3223e+00,  1.3368e+00,  1.2793e+00,
          1.3383e+00,  1.3344e+00,  1.2779e+00,  1.2910e+00,  1.2653e+00,
          1.2923e+00,  1.2920e+00,  1.2885e+00,  1.2880e+00,  1.2825e+00,
          1.2872e+00,  1.2872e+00,  2.9854e+00,  2.8930e+00,  2.7072e+00,
          2.7296e+00,  2.9844e+00,  2.7157e+00,  2.8731e+00,  2.7700e+00,
          2.7089e+00,  1.7440e+00,  1.7553e+00,  1.7215e+00,  1.7344e+00,
          1.7533e+00,  1.7442e+00,  1.7183e+00,  1.7284e+00,  1.7347e+00,
          1.5965e+00,  1.5795e+00,  1.5218e+00,  1.5161e+00,  1.5930e+00,
          1.5746e+00,  1.6077e+00,  1.5032e+00,  1.5679e+00],
        [ 1.9181e+00,  1.5213e+00,  6.8269e-01,  9.9218e-01,  1.4166e+00,
          1.8491e+00,  1.7224e+00,  1.9540e+00,  1.9540e+00,  1.7509e+00,
          1.3876e+00,  1.6015e+00,  1.0084e+00,  1.8066e+00,  2.0055e-01,
          1.6896e+00,  1.9780e+00,  9.1156e-01,  1.4242e+00,  1.0987e+00,
          8.3986e-01,  1.2336e+00,  1.7918e+00,  1.8578e+00,  1.6410e+00,
          1.9635e+00,  1.9635e+00,  9.4066e-01,  9.2406e-01,  1.9361e+00,
          1.7230e+00,  9.4221e-01,  1.8770e+00,  1.3322e+00,  1.9846e+00,
          1.9006e+00, -1.9077e-01, -4.2629e-01, -4.6941e-01, -2.4606e-01,
          8.9236e-03,  8.4816e-02, -3.1313e-01,  2.0614e+01,  1.9070e+00,
          2.9359e-01,  6.5254e-01,  6.7385e-01,  7.8659e-01,  4.4436e-01,
          7.8775e-01,  9.6570e-03,  8.2647e-01,  8.8243e-01],
        [ 1.3308e+00,  1.3672e+00,  1.3887e+00,  1.3985e+00,  1.3739e+00,
          1.3377e+00,  1.3078e+00,  1.3271e+00,  1.3271e+00,  1.3046e+00,
          1.4239e+00,  1.3198e+00,  1.4498e+00,  1.3798e+00,  1.4744e+00,
          1.3110e+00,  1.3550e+00,  1.3651e+00,  1.3882e+00,  1.3454e+00,
          1.4198e+00,  1.4016e+00,  1.3557e+00,  1.3489e+00,  1.2291e+00,
          1.3376e+00,  1.3376e+00,  1.3680e+00,  1.4335e+00,  1.3527e+00,
          1.1427e+00,  1.3258e+00,  1.2411e+00,  1.4087e+00,  1.2301e+00,
          1.3568e+00,  3.3566e-01,  2.5894e-01,  3.7262e-01,  3.3865e-01,
          1.3421e-01,  8.2725e-02,  3.5909e-01,  1.2562e-01, -6.4574e-02,
          3.7085e+00,  2.3570e+00,  3.6566e+00,  2.7253e+00,  1.8792e+00,
          1.4706e+00,  2.9496e+00,  3.5887e+00,  1.4352e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 398 : 173.95846297919135
Test loss for epoch 398 : 174.41878568842193
Test Precision for epoch 398 : 0.26153846153846155
Test Recall for epoch 398 : 0.26153846153846155
Test F1 for epoch 398 : 0.26153846153846155


theta for epoch 399 : tensor([[ 2.7515e+00,  2.7703e+00,  2.8075e+00,  2.9364e+00,  2.9172e+00,
          2.7547e+00,  2.9043e+00,  2.7499e+00,  2.7499e+00,  1.3252e+00,
          1.3273e+00,  1.3263e+00,  1.3292e+00,  1.3242e+00,  1.3311e+00,
          1.3256e+00,  1.3225e+00,  1.2843e+00,  1.2782e+00,  1.2356e+00,
          1.2364e+00,  1.2792e+00,  1.2759e+00,  1.2754e+00,  1.2774e+00,
          1.2746e+00,  1.2746e+00,  1.2589e+00,  1.3037e+00,  1.2977e+00,
          1.3007e+00,  1.3037e+00,  1.2991e+00,  1.3018e+00,  1.2535e+00,
          1.2980e+00,  1.7366e+00,  1.7474e+00,  1.7411e+00,  1.7378e+00,
          1.7454e+00,  1.6848e+00,  1.7380e+00,  1.7226e+00,  1.7380e+00,
          1.5866e+00,  1.5704e+00,  1.5671e+00,  1.5609e+00,  1.5832e+00,
          1.5657e+00,  1.5973e+00,  1.5568e+00,  1.5592e+00],
        [ 1.2781e+00,  1.2809e+00,  1.2828e+00,  1.2820e+00,  1.2814e+00,
          1.2786e+00,  1.2797e+00,  1.2778e+00,  1.2778e+00,  2.6850e+00,
          2.7002e+00,  2.6878e+00,  2.9345e+00,  2.6738e+00,  3.0801e+00,
          2.6879e+00,  2.9027e+00,  3.0550e+00,  1.2692e+00,  1.2747e+00,
          1.2272e+00,  1.2702e+00,  1.2972e+00,  1.2967e+00,  1.2983e+00,
          1.2958e+00,  1.2958e+00,  1.2981e+00,  1.2497e+00,  1.3187e+00,
          1.3220e+00,  1.2967e+00,  1.3202e+00,  1.3232e+00,  1.2928e+00,
          1.3191e+00,  1.7480e+00,  1.7598e+00,  1.7159e+00,  1.7486e+00,
          1.7577e+00,  1.7596e+00,  1.7125e+00,  1.7305e+00,  1.7489e+00,
          1.5466e+00,  1.5846e+00,  1.5810e+00,  1.5742e+00,  1.5064e+00,
          1.5794e+00,  1.5217e+00,  1.5698e+00,  1.5724e+00],
        [ 1.2632e+00,  1.2658e+00,  1.2619e+00,  1.2675e+00,  1.2657e+00,
          1.2637e+00,  1.2641e+00,  1.2629e+00,  1.2629e+00,  1.3315e+00,
          1.3337e+00,  1.3326e+00,  1.3356e+00,  1.3305e+00,  1.2775e+00,
          1.3320e+00,  1.2687e+00,  1.3203e+00,  2.7984e+00,  2.9352e+00,
          2.9722e+00,  2.8073e+00,  2.7355e+00,  2.7323e+00,  2.9112e+00,
          2.7273e+00,  2.7273e+00,  1.2579e+00,  1.2951e+00,  1.3041e+00,
          1.3072e+00,  1.2586e+00,  1.3055e+00,  1.3083e+00,  1.3041e+00,
          1.3044e+00,  1.7411e+00,  1.7521e+00,  1.7457e+00,  1.6707e+00,
          1.7501e+00,  1.7409e+00,  1.7426e+00,  1.7269e+00,  1.6710e+00,
          1.5919e+00,  1.5755e+00,  1.5721e+00,  1.5658e+00,  1.5700e+00,
          1.5707e+00,  1.5843e+00,  1.5528e+00,  1.5641e+00],
        [ 1.2694e+00,  1.2721e+00,  1.2683e+00,  1.2740e+00,  1.2721e+00,
          1.2699e+00,  1.2704e+00,  1.2691e+00,  1.2691e+00,  1.3376e+00,
          1.3398e+00,  1.3388e+00,  1.3221e+00,  1.3366e+00,  1.2791e+00,
          1.3381e+00,  1.3342e+00,  1.2777e+00,  1.2909e+00,  1.2652e+00,
          1.2923e+00,  1.2919e+00,  1.2885e+00,  1.2880e+00,  1.2824e+00,
          1.2871e+00,  1.2871e+00,  2.9878e+00,  2.8951e+00,  2.7091e+00,
          2.7315e+00,  2.9868e+00,  2.7176e+00,  2.8751e+00,  2.7720e+00,
          2.7108e+00,  1.7440e+00,  1.7553e+00,  1.7215e+00,  1.7343e+00,
          1.7533e+00,  1.7441e+00,  1.7183e+00,  1.7285e+00,  1.7346e+00,
          1.5962e+00,  1.5793e+00,  1.5215e+00,  1.5158e+00,  1.5927e+00,
          1.5743e+00,  1.6074e+00,  1.5029e+00,  1.5676e+00],
        [ 1.9183e+00,  1.5216e+00,  6.8305e-01,  9.9244e-01,  1.4169e+00,
          1.8493e+00,  1.7227e+00,  1.9542e+00,  1.9542e+00,  1.7511e+00,
          1.3878e+00,  1.6018e+00,  1.0086e+00,  1.8068e+00,  2.0091e-01,
          1.6898e+00,  1.9782e+00,  9.1178e-01,  1.4245e+00,  1.0990e+00,
          8.4016e-01,  1.2338e+00,  1.7921e+00,  1.8580e+00,  1.6413e+00,
          1.9637e+00,  1.9637e+00,  9.4099e-01,  9.2432e-01,  1.9363e+00,
          1.7232e+00,  9.4252e-01,  1.8772e+00,  1.3325e+00,  1.9848e+00,
          1.9009e+00, -1.9141e-01, -4.2683e-01, -4.6995e-01, -2.4675e-01,
          8.1939e-03,  8.3971e-02, -3.1372e-01,  2.0649e+01,  1.8968e+00,
          2.9384e-01,  6.5270e-01,  6.7400e-01,  7.8672e-01,  4.4456e-01,
          7.8788e-01,  9.9811e-03,  8.2664e-01,  8.8254e-01],
        [ 1.3309e+00,  1.3673e+00,  1.3887e+00,  1.3986e+00,  1.3740e+00,
          1.3378e+00,  1.3079e+00,  1.3272e+00,  1.3272e+00,  1.3047e+00,
          1.4240e+00,  1.3199e+00,  1.4499e+00,  1.3799e+00,  1.4744e+00,
          1.3111e+00,  1.3551e+00,  1.3652e+00,  1.3884e+00,  1.3454e+00,
          1.4200e+00,  1.4017e+00,  1.3558e+00,  1.3490e+00,  1.2292e+00,
          1.3377e+00,  1.3377e+00,  1.3680e+00,  1.4335e+00,  1.3528e+00,
          1.1428e+00,  1.3258e+00,  1.2412e+00,  1.4088e+00,  1.2302e+00,
          1.3569e+00,  3.3576e-01,  2.5903e-01,  3.7271e-01,  3.3873e-01,
          1.3431e-01,  8.2799e-02,  3.5919e-01,  1.2564e-01, -6.4288e-02,
          3.7117e+00,  2.3581e+00,  3.6596e+00,  2.7268e+00,  1.8800e+00,
          1.4713e+00,  2.9509e+00,  3.5929e+00,  1.4359e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 399 : 173.9530091650991
Test loss for epoch 399 : 174.4156217726177
Test Precision for epoch 399 : 0.26153846153846155
Test Recall for epoch 399 : 0.26153846153846155
Test F1 for epoch 399 : 0.26153846153846155


Max Test F1 is for epoch 0 : 0.26153846153846155
