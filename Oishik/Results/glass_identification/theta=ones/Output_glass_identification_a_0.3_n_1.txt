theta for epoch 0 : tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 0 : 192.4662760096285
Test loss for epoch 0 : 192.07909664861117
Test Precision for epoch 0 : 0.26153846153846155
Test Recall for epoch 0 : 0.26153846153846155
Test F1 for epoch 0 : 0.26153846153846155


theta for epoch 1 : tensor([[1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 0.9000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 0.9000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 0.9000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 1 : 190.11892296615707
Test loss for epoch 1 : 189.753659018465
Test Precision for epoch 1 : 0.26153846153846155
Test Recall for epoch 1 : 0.26153846153846155
Test F1 for epoch 1 : 0.26153846153846155


theta for epoch 2 : tensor([[1.1912, 1.1928, 1.1945, 1.1937, 1.1938, 1.1917, 1.1923, 1.1912, 1.1912,
         1.1460, 1.1439, 1.1459, 1.1367, 1.1459, 1.1149, 1.1455, 1.1461, 1.1281,
         1.0988, 1.0848, 1.1020, 1.1002, 1.1125, 1.1134, 1.1115, 1.1135, 1.1135,
         1.1885, 1.1928, 1.1924, 1.1924, 1.1922, 1.1924, 1.1918, 1.1913, 1.1924,
         1.1836, 1.1843, 1.1843, 1.1841, 1.1842, 1.1780, 1.1837, 1.1539, 1.1652,
         1.1901, 1.1906, 1.1907, 1.1910, 1.1904, 1.1905, 1.1851, 1.1910, 1.1910],
        [1.1988, 1.1969, 1.1620, 1.1984, 1.1984, 1.1989, 1.1987, 1.1989, 1.1989,
         1.1973, 1.1982, 1.1961, 1.1989, 1.1970, 1.1994, 1.1971, 1.1955, 1.1992,
         1.1180, 1.1166, 1.0296, 1.1099, 1.1520, 1.1641, 1.1573, 1.1647, 1.1647,
         1.2001, 1.1995, 1.2001, 1.2001, 1.1999, 1.2001, 1.2001, 1.2001, 1.2001,
         1.1996, 1.1996, 1.1996, 1.1996, 1.1995, 1.1996, 1.1996, 0.8029, 1.1996,
         1.1991, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 0.8566, 1.2001, 1.2001],
        [1.1814, 1.1796, 1.1764, 1.1754, 1.1703, 1.1814, 1.1732, 1.1814, 1.1814,
         1.1499, 1.1435, 1.1503, 1.1412, 1.1503, 1.0387, 1.1500, 1.1422, 1.1174,
         1.1980, 1.1985, 1.1989, 1.1985, 1.1968, 1.1966, 1.1978, 1.1962, 1.1962,
         1.1917, 1.1916, 1.1941, 1.1941, 1.1911, 1.1941, 1.1940, 1.1940, 1.1941,
         1.1865, 1.1871, 1.1870, 1.1842, 1.1868, 1.1865, 1.1870, 1.0555, 1.1134,
         1.1886, 1.1929, 1.1929, 1.1929, 1.1836, 1.1929, 1.1845, 1.1929, 1.1929],
        [1.1762, 1.1759, 1.1522, 1.1401, 1.1744, 1.1746, 1.1748, 1.1762, 1.1762,
         1.1435, 1.1300, 1.1289, 1.1200, 1.1436, 1.1004, 1.1420, 1.1431, 1.0628,
         1.1108, 1.0709, 1.1035, 1.1073, 1.1076, 1.1054, 1.1093, 1.1116, 1.1116,
         1.1953, 1.1919, 1.1900, 1.1916, 1.1948, 1.1898, 1.1947, 1.1901, 1.1897,
         1.1828, 1.1785, 1.1771, 1.1798, 1.1818, 1.1650, 1.1807, 1.0366, 1.1571,
         1.1901, 1.1864, 1.1778, 1.1882, 1.1888, 1.1815, 1.1906, 1.1882, 1.1899],
        [1.1914, 1.1889, 0.9444, 0.9622, 1.1874, 1.1911, 1.1903, 1.1914, 1.1914,
         1.1927, 1.1907, 1.1891, 1.1799, 1.1932, 0.9188, 1.1915, 1.1933, 1.1880,
         1.1915, 1.1828, 1.1766, 1.1892, 1.1949, 1.1949, 1.1900, 1.1952, 1.1952,
         0.9621, 0.9619, 1.1900, 1.1873, 0.9708, 1.1898, 1.1831, 1.1899, 1.1896,
         1.0545, 1.0432, 1.0407, 1.0495, 1.0693, 1.0738, 1.0498, 1.1349, 1.1261,
         0.9729, 1.1811, 1.1841, 1.1896, 1.1802, 1.1893, 0.9497, 1.1882, 1.1905],
        [1.1982, 1.1981, 1.1979, 1.1981, 1.1974, 1.1980, 1.1980, 1.1982, 1.1982,
         1.1809, 1.1754, 1.1767, 1.1677, 1.1864, 1.0595, 1.1810, 1.1864, 1.1643,
         1.1569, 1.1357, 1.0684, 1.1364, 1.1576, 1.1584, 1.1526, 1.1598, 1.1598,
         1.2001, 1.2000, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001, 1.2001,
         1.1992, 1.1985, 1.1992, 1.1992, 1.1976, 1.1938, 1.1992, 0.9308, 0.8059,
         1.2001, 1.1998, 1.1999, 1.1999, 1.2000, 1.1992, 1.2001, 1.1999, 1.1991]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 2 : 189.4089542986297
Test loss for epoch 2 : 189.0276292824872
Test Precision for epoch 2 : 0.26153846153846155
Test Recall for epoch 2 : 0.26153846153846155
Test F1 for epoch 2 : 0.26153846153846155


theta for epoch 3 : tensor([[1.2063, 1.2149, 1.2251, 1.2206, 1.2218, 1.2090, 1.2122, 1.2062, 1.2062,
         1.2189, 1.2161, 1.2188, 1.2066, 1.2187, 1.1785, 1.2182, 1.2191, 1.1953,
         1.1562, 1.1375, 1.1606, 1.1581, 1.1745, 1.1757, 1.1732, 1.1758, 1.1758,
         1.1850, 1.2158, 1.2179, 1.2176, 1.2071, 1.2178, 1.2125, 1.2098, 1.2178,
         1.2658, 1.2672, 1.2672, 1.2668, 1.2669, 1.2573, 1.2661, 1.2248, 1.2391,
         1.2598, 1.2638, 1.2644, 1.2655, 1.2621, 1.2634, 1.2380, 1.2655, 1.2656],
        [1.2509, 1.2019, 1.1059, 1.2285, 1.2375, 1.2571, 1.2468, 1.2572, 1.2572,
         1.2953, 1.2969, 1.2931, 1.2982, 1.2947, 1.2991, 1.2950, 1.2921, 1.2988,
         1.1824, 1.1807, 1.0501, 1.1720, 1.2267, 1.2429, 1.2335, 1.2438, 1.2438,
         1.2076, 1.1693, 1.2284, 1.2210, 1.1740, 1.2283, 1.2227, 1.2257, 1.2229,
         1.2913, 1.2931, 1.2926, 1.2914, 1.2895, 1.2923, 1.2925, 0.8010, 1.2867,
         1.1572, 1.2651, 1.2638, 1.2663, 1.1961, 1.2651, 0.7848, 1.2664, 1.2664],
        [1.1990, 1.1905, 1.1762, 1.1746, 1.1607, 1.1988, 1.1699, 1.1990, 1.1990,
         1.2245, 1.2153, 1.2250, 1.2122, 1.2251, 1.0535, 1.2246, 1.2135, 1.1787,
         1.2969, 1.2977, 1.2984, 1.2976, 1.2948, 1.2945, 1.2964, 1.2939, 1.2939,
         1.1696, 1.1679, 1.1909, 1.1900, 1.1665, 1.1909, 1.1898, 1.1903, 1.1909,
         1.2738, 1.2749, 1.2748, 1.2700, 1.2741, 1.2737, 1.2747, 1.1088, 1.1779,
         1.1880, 1.2260, 1.2258, 1.2260, 1.1698, 1.2256, 1.1653, 1.2254, 1.2261],
        [1.2625, 1.2620, 1.2253, 1.2060, 1.2596, 1.2599, 1.2603, 1.2625, 1.2625,
         1.2147, 1.1979, 1.1966, 1.1856, 1.2149, 1.1618, 1.2128, 1.2142, 1.1140,
         1.1738, 1.1230, 1.1647, 1.1695, 1.1698, 1.1670, 1.1720, 1.1748, 1.1748,
         1.1977, 1.1776, 1.1702, 1.1760, 1.1941, 1.1693, 1.1936, 1.1704, 1.1691,
         1.2617, 1.2556, 1.2537, 1.2573, 1.2600, 1.2375, 1.2585, 1.0921, 1.2274,
         1.2846, 1.2788, 1.2652, 1.2815, 1.2824, 1.2709, 1.2854, 1.2815, 1.2842],
        [1.1964, 1.1827, 0.8973, 0.9261, 1.1764, 1.1941, 1.1893, 1.1964, 1.1964,
         1.2332, 1.2209, 1.2105, 1.1731, 1.2369, 0.8679, 1.2246, 1.2369, 1.2038,
         1.2137, 1.1687, 1.1560, 1.1990, 1.2403, 1.2405, 1.2035, 1.2440, 1.2440,
         0.9251, 0.9250, 1.1887, 1.1761, 0.9415, 1.1877, 1.1618, 1.1882, 1.1870,
         1.0991, 1.0813, 1.0769, 1.0917, 1.1203, 1.1265, 1.0919, 1.2040, 1.1931,
         0.9518, 1.1627, 1.1727, 1.1954, 1.1593, 1.1925, 0.9083, 1.1883, 1.1998],
        [1.2784, 1.2755, 1.2597, 1.2724, 1.2652, 1.2744, 1.2743, 1.2784, 1.2784,
         1.2638, 1.2557, 1.2577, 1.2447, 1.2724, 1.1139, 1.2640, 1.2723, 1.2400,
         1.2322, 1.2051, 1.1206, 1.2060, 1.2332, 1.2342, 1.2267, 1.2360, 1.2360,
         1.2333, 1.1948, 1.2469, 1.2092, 1.2125, 1.2091, 1.2394, 1.2307, 1.2469,
         1.2891, 1.2835, 1.2894, 1.2884, 1.2773, 1.2690, 1.2894, 0.9967, 0.8466,
         1.2559, 1.2166, 1.2278, 1.2266, 1.2270, 1.1845, 1.2562, 1.2190, 1.1834]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 3 : 188.95469859674142
Test loss for epoch 3 : 188.65862734928572
Test Precision for epoch 3 : 0.26153846153846155
Test Recall for epoch 3 : 0.26153846153846155
Test F1 for epoch 3 : 0.26153846153846155


theta for epoch 4 : tensor([[1.2602, 1.2723, 1.2867, 1.2805, 1.2822, 1.2641, 1.2686, 1.2602, 1.2602,
         1.2303, 1.2267, 1.2303, 1.2140, 1.2301, 1.1795, 1.2294, 1.2306, 1.1996,
         1.1841, 1.1594, 1.1907, 1.1869, 1.2080, 1.2095, 1.2065, 1.2096, 1.2096,
         1.2038, 1.2586, 1.2621, 1.2617, 1.2435, 1.2621, 1.2530, 1.2479, 1.2621,
         1.3019, 1.3047, 1.3047, 1.3038, 1.3040, 1.2869, 1.3024, 1.2423, 1.2600,
         1.2505, 1.2618, 1.2638, 1.2667, 1.2578, 1.2609, 1.2082, 1.2668, 1.2669],
        [1.3208, 1.2580, 1.1435, 1.2916, 1.3033, 1.3291, 1.3153, 1.3293, 1.3293,
         1.2533, 1.2599, 1.2478, 1.2707, 1.2514, 1.2889, 1.2525, 1.2453, 1.2798,
         1.2604, 1.2584, 1.1081, 1.2488, 1.3100, 1.3285, 1.3178, 1.3296, 1.3296,
         1.2644, 1.2141, 1.2910, 1.2815, 1.2207, 1.2909, 1.2837, 1.2875, 1.2838,
         1.3857, 1.3888, 1.3880, 1.3859, 1.3828, 1.3874, 1.3878, 0.8493, 1.3780,
         1.1949, 1.3409, 1.3390, 1.3426, 1.2485, 1.3409, 0.8246, 1.3428, 1.3428],
        [1.2587, 1.2486, 1.2318, 1.2300, 1.2139, 1.2585, 1.2246, 1.2587, 1.2587,
         1.3079, 1.2972, 1.3084, 1.2935, 1.3086, 1.1102, 1.3080, 1.2951, 1.2550,
         1.2689, 1.2726, 1.2768, 1.2725, 1.2619, 1.2615, 1.2674, 1.2597, 1.2597,
         1.2190, 1.2169, 1.2454, 1.2442, 1.2153, 1.2453, 1.2439, 1.2445, 1.2453,
         1.3631, 1.3646, 1.3645, 1.3583, 1.3635, 1.3631, 1.3645, 1.1805, 1.2544,
         1.2431, 1.2898, 1.2896, 1.2899, 1.2214, 1.2894, 1.2162, 1.2891, 1.2900],
        [1.2526, 1.2516, 1.1942, 1.1694, 1.2470, 1.2476, 1.2484, 1.2526, 1.2526,
         1.2188, 1.1972, 1.1955, 1.1821, 1.2191, 1.1548, 1.2164, 1.2182, 1.0957,
         1.1938, 1.1283, 1.1831, 1.1884, 1.1882, 1.1845, 1.1913, 1.1947, 1.1947,
         1.2488, 1.2205, 1.2103, 1.2183, 1.2437, 1.2090, 1.2431, 1.2105, 1.2087,
         1.2846, 1.2744, 1.2716, 1.2771, 1.2816, 1.2483, 1.2791, 1.0843, 1.2356,
         1.2744, 1.2610, 1.2359, 1.2692, 1.2703, 1.2457, 1.2762, 1.2691, 1.2771],
        [1.2000, 1.1735, 0.8442, 0.8844, 1.1613, 1.1953, 1.1859, 1.2000, 1.2000,
         1.2418, 1.2170, 1.1966, 1.1335, 1.2494, 0.7994, 1.2239, 1.2494, 1.1839,
         1.2195, 1.1343, 1.1174, 1.1905, 1.2745, 1.2750, 1.1992, 1.2825, 1.2825,
         0.8976, 0.8980, 1.2036, 1.1799, 0.9233, 1.2017, 1.1539, 1.2026, 1.2004,
         1.1481, 1.1232, 1.1170, 1.1380, 1.1759, 1.1840, 1.1383, 1.2779, 1.2649,
         0.9236, 1.1364, 1.1537, 1.1962, 1.1299, 1.1901, 0.8591, 1.1826, 1.2046],
        [1.2929, 1.2844, 1.2432, 1.2732, 1.2575, 1.2805, 1.2801, 1.2929, 1.2929,
         1.2740, 1.2611, 1.2638, 1.2454, 1.2906, 1.0937, 1.2743, 1.2905, 1.2400,
         1.2733, 1.2367, 1.1301, 1.2374, 1.2742, 1.2755, 1.2648, 1.2781, 1.2781,
         1.2756, 1.1985, 1.3022, 1.2264, 1.2332, 1.2255, 1.2877, 1.2699, 1.3021,
         1.3308, 1.3083, 1.3323, 1.3274, 1.2896, 1.2725, 1.3322, 0.9993, 0.8252,
         1.3291, 1.2740, 1.2896, 1.2880, 1.2885, 1.2280, 1.3296, 1.2774, 1.2264]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 4 : 188.22484409423552
Test loss for epoch 4 : 187.9026047026158
Test Precision for epoch 4 : 0.26153846153846155
Test Recall for epoch 4 : 0.26153846153846155
Test F1 for epoch 4 : 0.26153846153846155


theta for epoch 5 : tensor([[1.3065, 1.3226, 1.3416, 1.3335, 1.3358, 1.3117, 1.3177, 1.3064, 1.3064,
         1.2668, 1.2627, 1.2669, 1.2475, 1.2665, 1.2088, 1.2658, 1.2672, 1.2307,
         1.2311, 1.2021, 1.2395, 1.2347, 1.2592, 1.2609, 1.2577, 1.2610, 1.2610,
         1.2575, 1.3239, 1.3281, 1.3276, 1.3057, 1.3280, 1.3170, 1.3106, 1.3280,
         1.2793, 1.2833, 1.2833, 1.2819, 1.2822, 1.2597, 1.2800, 1.2077, 1.2273,
         1.2724, 1.2883, 1.2911, 1.2951, 1.2830, 1.2869, 1.2148, 1.2953, 1.2956],
        [1.3624, 1.2811, 1.1468, 1.3240, 1.3393, 1.3742, 1.3550, 1.3744, 1.3744,
         1.2594, 1.2710, 1.2505, 1.2904, 1.2563, 1.3219, 1.2582, 1.2464, 1.3063,
         1.3136, 1.3121, 1.1343, 1.3006, 1.3721, 1.3949, 1.3818, 1.3961, 1.3961,
         1.3103, 1.2456, 1.3435, 1.3315, 1.2540, 1.3434, 1.3345, 1.3392, 1.3344,
         1.3801, 1.3891, 1.3872, 1.3811, 1.3728, 1.3849, 1.3864, 0.8160, 1.3644,
         1.1930, 1.3872, 1.3844, 1.3895, 1.2618, 1.3871, 0.8276, 1.3897, 1.3899],
        [1.3044, 1.2927, 1.2738, 1.2713, 1.2524, 1.3042, 1.2644, 1.3044, 1.3044,
         1.3852, 1.3728, 1.3859, 1.3687, 1.3860, 1.1579, 1.3853, 1.3702, 1.3241,
         1.2734, 1.2801, 1.2877, 1.2798, 1.2613, 1.2608, 1.2708, 1.2578, 1.2578,
         1.2647, 1.2622, 1.2962, 1.2948, 1.2601, 1.2962, 1.2946, 1.2953, 1.2962,
         1.3640, 1.3665, 1.3663, 1.3569, 1.3646, 1.3641, 1.3661, 1.1668, 1.2411,
         1.2810, 1.3377, 1.3374, 1.3376, 1.2550, 1.3371, 1.2498, 1.3367, 1.3377],
        [1.2481, 1.2468, 1.1687, 1.1384, 1.2399, 1.2406, 1.2420, 1.2481, 1.2481,
         1.2347, 1.2081, 1.2064, 1.1903, 1.2350, 1.1598, 1.2319, 1.2339, 1.0880,
         1.2206, 1.1406, 1.2086, 1.2144, 1.2135, 1.2087, 1.2176, 1.2214, 1.2214,
         1.3078, 1.2720, 1.2590, 1.2691, 1.3015, 1.2573, 1.3007, 1.2593, 1.2569,
         1.2592, 1.2460, 1.2423, 1.2494, 1.2551, 1.2141, 1.2519, 1.0396, 1.2001,
         1.2682, 1.2458, 1.2083, 1.2595, 1.2618, 1.2220, 1.2714, 1.2595, 1.2731],
        [1.2388, 1.2032, 0.8366, 0.8887, 1.1863, 1.2325, 1.2198, 1.2388, 1.2388,
         1.2913, 1.2606, 1.2352, 1.1575, 1.3007, 0.8000, 1.2690, 1.3008, 1.2193,
         1.2697, 1.1668, 1.1487, 1.2348, 1.3362, 1.3367, 1.2453, 1.3460, 1.3460,
         0.9136, 0.9143, 1.2498, 1.2187, 0.9468, 1.2473, 1.1841, 1.2485, 1.2456,
         1.1386, 1.1070, 1.0993, 1.1260, 1.1732, 1.1834, 1.1263, 1.3013, 1.2845,
         0.9386, 1.1515, 1.1750, 1.2323, 1.1422, 1.2239, 0.8543, 1.2141, 1.2435],
        [1.3306, 1.3180, 1.2584, 1.3013, 1.2775, 1.3114, 1.3109, 1.3305, 1.3305,
         1.3071, 1.2904, 1.2934, 1.2711, 1.3305, 1.1025, 1.3075, 1.3303, 1.2651,
         1.3292, 1.2852, 1.1610, 1.2857, 1.3300, 1.3316, 1.3184, 1.3347, 1.3347,
         1.3402, 1.2422, 1.3740, 1.2769, 1.2861, 1.2756, 1.3555, 1.3326, 1.3739,
         1.3128, 1.2772, 1.3154, 1.3071, 1.2507, 1.2289, 1.3153, 0.9578, 0.7714,
         1.3998, 1.3271, 1.3477, 1.3457, 1.3461, 1.2655, 1.4004, 1.3317, 1.2634]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 5 : 187.94841499475626
Test loss for epoch 5 : 187.57535199867567
Test Precision for epoch 5 : 0.26153846153846155
Test Recall for epoch 5 : 0.26153846153846155
Test F1 for epoch 5 : 0.26153846153846155


theta for epoch 6 : tensor([[1.3210, 1.3419, 1.3665, 1.3561, 1.3593, 1.3277, 1.3354, 1.3209, 1.3209,
         1.3195, 1.3151, 1.3197, 1.2981, 1.3192, 1.2564, 1.3184, 1.3199, 1.2795,
         1.2839, 1.2514, 1.2937, 1.2880, 1.3154, 1.3172, 1.3139, 1.3173, 1.3173,
         1.3052, 1.3823, 1.3851, 1.3851, 1.3614, 1.3854, 1.3727, 1.3646, 1.3850,
         1.2818, 1.2868, 1.2868, 1.2851, 1.2854, 1.2581, 1.2827, 1.2011, 1.2217,
         1.3133, 1.3321, 1.3354, 1.3400, 1.3261, 1.3304, 1.2449, 1.3404, 1.3407],
        [1.3657, 1.2660, 1.1160, 1.3178, 1.3368, 1.3814, 1.3562, 1.3817, 1.3817,
         1.2949, 1.3103, 1.2831, 1.3361, 1.2907, 1.3772, 1.2933, 1.2778, 1.3571,
         1.3189, 1.3183, 1.1149, 1.3046, 1.3881, 1.4172, 1.4006, 1.4186, 1.4186,
         1.3183, 1.2385, 1.3591, 1.3440, 1.2488, 1.3591, 1.3481, 1.3538, 1.3475,
         1.3677, 1.3831, 1.3799, 1.3695, 1.3558, 1.3759, 1.3786, 0.7717, 1.3438,
         1.1571, 1.3951, 1.3912, 1.3979, 1.2376, 1.3948, 0.7970, 1.3983, 1.3986],
        [1.3147, 1.3015, 1.2807, 1.2770, 1.2552, 1.3144, 1.2684, 1.3147, 1.3147,
         1.4267, 1.4114, 1.4276, 1.4071, 1.4276, 1.1635, 1.4269, 1.4077, 1.3535,
         1.3067, 1.3156, 1.3260, 1.3154, 1.2903, 1.2898, 1.3031, 1.2857, 1.2857,
         1.2755, 1.2727, 1.3127, 1.3112, 1.2701, 1.3128, 1.3109, 1.3116, 1.3126,
         1.3574, 1.3608, 1.3606, 1.3479, 1.3582, 1.3577, 1.3603, 1.1438, 1.2189,
         1.2815, 1.3487, 1.3483, 1.3484, 1.2512, 1.3480, 1.2466, 1.3474, 1.3486],
        [1.2801, 1.2788, 1.1879, 1.1536, 1.2705, 1.2711, 1.2730, 1.2800, 1.2800,
         1.2769, 1.2467, 1.2452, 1.2271, 1.2772, 1.1945, 1.2737, 1.2760, 1.1131,
         1.2662, 1.1753, 1.2534, 1.2593, 1.2578, 1.2522, 1.2627, 1.2668, 1.2668,
         1.3293, 1.2842, 1.2679, 1.2805, 1.3213, 1.2658, 1.3202, 1.2684, 1.2653,
         1.2642, 1.2483, 1.2437, 1.2523, 1.2594, 1.2115, 1.2551, 1.0296, 1.1974,
         1.2977, 1.2680, 1.2210, 1.2855, 1.2892, 1.2375, 1.3021, 1.2855, 1.3032],
        [1.2773, 1.2318, 0.8264, 0.8915, 1.2099, 1.2692, 1.2530, 1.2773, 1.2773,
         1.3457, 1.3092, 1.2789, 1.1866, 1.3569, 0.8044, 1.3191, 1.3569, 1.2598,
         1.3131, 1.1913, 1.1720, 1.2718, 1.3923, 1.3932, 1.2846, 1.4043, 1.4043,
         0.9202, 0.9213, 1.2879, 1.2486, 0.9615, 1.2850, 1.2044, 1.2865, 1.2827,
         1.1328, 1.0938, 1.0845, 1.1175, 1.1748, 1.1872, 1.1176, 1.3310, 1.3101,
         0.9525, 1.1651, 1.1952, 1.2681, 1.1522, 1.2571, 0.8471, 1.2449, 1.2821],
        [1.3859, 1.3706, 1.2993, 1.3507, 1.3207, 1.3619, 1.3614, 1.3858, 1.3858,
         1.3587, 1.3393, 1.3424, 1.3175, 1.3871, 1.1372, 1.3592, 1.3870, 1.3112,
         1.3920, 1.3421, 1.2038, 1.3422, 1.3927, 1.3945, 1.3792, 1.3980, 1.3980,
         1.4024, 1.2862, 1.4413, 1.3249, 1.3377, 1.3231, 1.4195, 1.3912, 1.4412,
         1.3210, 1.2728, 1.3246, 1.3132, 1.2386, 1.2119, 1.3244, 0.9490, 0.7517,
         1.4373, 1.3404, 1.3671, 1.3646, 1.3647, 1.2619, 1.4379, 1.3464, 1.2592]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 6 : 187.4425161843297
Test loss for epoch 6 : 187.07989930923782
Test Precision for epoch 6 : 0.26153846153846155
Test Recall for epoch 6 : 0.26153846153846155
Test F1 for epoch 6 : 0.26153846153846155


theta for epoch 7 : tensor([[1.3355, 1.3614, 1.3917, 1.3790, 1.3830, 1.3439, 1.3533, 1.3354, 1.3354,
         1.3649, 1.3604, 1.3654, 1.3416, 1.3645, 1.2975, 1.3639, 1.3654, 1.3216,
         1.3038, 1.2683, 1.3154, 1.3089, 1.3391, 1.3410, 1.3378, 1.3411, 1.3411,
         1.3376, 1.4258, 1.4253, 1.4263, 1.4020, 1.4264, 1.4121, 1.4016, 1.4253,
         1.3024, 1.3084, 1.3083, 1.3064, 1.3068, 1.2752, 1.3035, 1.2147, 1.2357,
         1.3702, 1.3910, 1.3947, 1.3995, 1.3846, 1.3891, 1.2943, 1.4000, 1.4004],
        [1.3722, 1.2536, 1.0880, 1.3149, 1.3374, 1.3919, 1.3605, 1.3922, 1.3922,
         1.3319, 1.3514, 1.3171, 1.3839, 1.3266, 1.4348, 1.3299, 1.3105, 1.4100,
         1.2972, 1.2976, 1.0738, 1.2820, 1.3756, 1.4106, 1.3909, 1.4123, 1.4123,
         1.3164, 1.2211, 1.3646, 1.3463, 1.2333, 1.3648, 1.3517, 1.3583, 1.3505,
         1.3663, 1.3883, 1.3840, 1.3690, 1.3497, 1.3781, 1.3821, 0.7352, 1.3340,
         1.1254, 1.4087, 1.4036, 1.4119, 1.2179, 1.4083, 0.7699, 1.4124, 1.4128],
        [1.3201, 1.3054, 1.2832, 1.2780, 1.2530, 1.3199, 1.2673, 1.3201, 1.3201,
         1.4384, 1.4200, 1.4397, 1.4158, 1.4394, 1.1430, 1.4386, 1.4150, 1.3534,
         1.3458, 1.3571, 1.3702, 1.3568, 1.3251, 1.3246, 1.3414, 1.3195, 1.3195,
         1.2716, 1.2685, 1.3144, 1.3130, 1.2653, 1.3147, 1.3125, 1.3133, 1.3143,
         1.3572, 1.3616, 1.3613, 1.3450, 1.3583, 1.3578, 1.3609, 1.1258, 1.2022,
         1.2789, 1.3570, 1.3565, 1.3562, 1.2439, 1.3561, 1.2404, 1.3552, 1.3567],
        [1.3335, 1.3323, 1.2329, 1.1956, 1.3231, 1.3236, 1.3258, 1.3335, 1.3335,
         1.3258, 1.2925, 1.2912, 1.2715, 1.3261, 1.2376, 1.3225, 1.3248, 1.1473,
         1.3070, 1.2062, 1.2938, 1.2996, 1.2972, 1.2908, 1.3031, 1.3073, 1.3073,
         1.3295, 1.2748, 1.2553, 1.2703, 1.3199, 1.2529, 1.3184, 1.2560, 1.2522,
         1.2914, 1.2731, 1.2678, 1.2777, 1.2860, 1.2322, 1.2808, 1.0446, 1.2185,
         1.3497, 1.3149, 1.2612, 1.3349, 1.3398, 1.2796, 1.3552, 1.3350, 1.3555],
        [1.3141, 1.2580, 0.8107, 0.8896, 1.2305, 1.3041, 1.2841, 1.3141, 1.3141,
         1.3857, 1.3423, 1.3067, 1.1980, 1.3991, 0.7921, 1.3541, 1.3990, 1.2837,
         1.3206, 1.1807, 1.1606, 1.2728, 1.4144, 1.4158, 1.2884, 1.4293, 1.4293,
         0.9129, 0.9144, 1.3143, 1.2658, 0.9627, 1.3108, 1.2109, 1.3128, 1.3079,
         1.1409, 1.0941, 1.0830, 1.1228, 1.1904, 1.2050, 1.1227, 1.3739, 1.3491,
         0.9637, 1.1767, 1.2143, 1.3036, 1.1600, 1.2899, 0.8359, 1.2752, 1.3205],
        [1.4527, 1.4355, 1.3559, 1.4134, 1.3784, 1.4250, 1.4245, 1.4526, 1.4526,
         1.4044, 1.3822, 1.3855, 1.3584, 1.4381, 1.1683, 1.4049, 1.4380, 1.3519,
         1.4232, 1.3668, 1.2152, 1.3659, 1.4237, 1.4257, 1.4079, 1.4297, 1.4297,
         1.4516, 1.3179, 1.4949, 1.3578, 1.3759, 1.3553, 1.4699, 1.4348, 1.4949,
         1.3473, 1.2871, 1.3517, 1.3377, 1.2457, 1.2142, 1.3514, 0.9614, 0.7532,
         1.4735, 1.3509, 1.3843, 1.3812, 1.3807, 1.2546, 1.4740, 1.3584, 1.2514]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 7 : 187.29967567202561
Test loss for epoch 7 : 186.97963324439138
Test Precision for epoch 7 : 0.26153846153846155
Test Recall for epoch 7 : 0.26153846153846155
Test F1 for epoch 7 : 0.26153846153846155


theta for epoch 8 : tensor([[1.3639, 1.3944, 1.4299, 1.4150, 1.4199, 1.3738, 1.3848, 1.3638, 1.3638,
         1.3717, 1.3672, 1.3726, 1.3468, 1.3712, 1.3012, 1.3707, 1.3722, 1.3256,
         1.3008, 1.2625, 1.3145, 1.3068, 1.3397, 1.3417, 1.3386, 1.3416, 1.3416,
         1.3686, 1.4677, 1.4634, 1.4655, 1.4415, 1.4654, 1.4496, 1.4364, 1.4635,
         1.3327, 1.3396, 1.3394, 1.3372, 1.3378, 1.3022, 1.3340, 1.2389, 1.2600,
         1.4315, 1.4538, 1.4577, 1.4627, 1.4474, 1.4518, 1.3492, 1.4633, 1.4638],
        [1.4009, 1.2673, 1.0894, 1.3366, 1.3615, 1.4238, 1.3875, 1.4240, 1.4240,
         1.3389, 1.3628, 1.3211, 1.4028, 1.3326, 1.4655, 1.3366, 1.3132, 1.4350,
         1.2801, 1.2818, 1.0402, 1.2643, 1.3668, 1.4075, 1.3850, 1.4093, 1.4093,
         1.3322, 1.2229, 1.3864, 1.3656, 1.2370, 1.3870, 1.3721, 1.3795, 1.3701,
         1.3869, 1.4146, 1.4093, 1.3903, 1.3662, 1.4019, 1.4069, 0.7262, 1.3476,
         1.1266, 1.4455, 1.4396, 1.4488, 1.2289, 1.4450, 0.7751, 1.4495, 1.4499],
        [1.3348, 1.3190, 1.2958, 1.2888, 1.2607, 1.3346, 1.2758, 1.3347, 1.3347,
         1.4208, 1.3999, 1.4225, 1.3961, 1.4217, 1.1025, 1.4210, 1.3937, 1.3268,
         1.3759, 1.3898, 1.4060, 1.3895, 1.3506, 1.3501, 1.3706, 1.3438, 1.3438,
         1.2742, 1.2711, 1.3223, 1.3211, 1.2672, 1.3229, 1.3204, 1.3212, 1.3223,
         1.3721, 1.3774, 1.3770, 1.3575, 1.3735, 1.3730, 1.3765, 1.1246, 1.2017,
         1.2900, 1.3778, 1.3773, 1.3766, 1.2506, 1.3769, 1.2487, 1.3756, 1.3772],
        [1.3842, 1.3832, 1.2753, 1.2348, 1.3730, 1.3734, 1.3759, 1.3842, 1.3842,
         1.3449, 1.3082, 1.3074, 1.2860, 1.3451, 1.2519, 1.3414, 1.3437, 1.1519,
         1.3264, 1.2153, 1.3133, 1.3186, 1.3149, 1.3076, 1.3220, 1.3261, 1.3261,
         1.3393, 1.2747, 1.2518, 1.2693, 1.3280, 1.2490, 1.3262, 1.2527, 1.2482,
         1.3243, 1.3037, 1.2976, 1.3088, 1.3184, 1.2587, 1.3122, 1.0651, 1.2454,
         1.4029, 1.3625, 1.3021, 1.3851, 1.3915, 1.3224, 1.4094, 1.3852, 1.4086],
        [1.3490, 1.2816, 0.7901, 0.8832, 1.2480, 1.3370, 1.3129, 1.3490, 1.3490,
         1.3968, 1.3460, 1.3051, 1.1812, 1.4124, 0.7574, 1.3599, 1.4124, 1.2782,
         1.3094, 1.1523, 1.1320, 1.2553, 1.4180, 1.4200, 1.2737, 1.4360, 1.4360,
         0.9015, 0.9035, 1.3390, 1.2808, 0.9602, 1.3349, 1.2144, 1.3374, 1.3312,
         1.1598, 1.1049, 1.0923, 1.1389, 1.2167, 1.2336, 1.1386, 1.4264, 1.3980,
         0.9737, 1.1878, 1.2332, 1.3397, 1.1670, 1.3229, 0.8225, 1.3058, 1.3595],
        [1.5165, 1.4978, 1.4111, 1.4738, 1.4338, 1.4852, 1.4848, 1.5164, 1.5164,
         1.4106, 1.3858, 1.3892, 1.3603, 1.4501, 1.1633, 1.4113, 1.4500, 1.3540,
         1.4295, 1.3664, 1.2024, 1.3645, 1.4295, 1.4317, 1.4113, 1.4363, 1.4363,
         1.4975, 1.3473, 1.5451, 1.3866, 1.4104, 1.3833, 1.5170, 1.4742, 1.5452,
         1.3821, 1.3100, 1.3872, 1.3707, 1.2615, 1.2251, 1.3868, 0.9830, 0.7627,
         1.5226, 1.3774, 1.4169, 1.4132, 1.4120, 1.2642, 1.5231, 1.3864, 1.2605]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 8 : 187.066509992056
Test loss for epoch 8 : 186.77959187836336
Test Precision for epoch 8 : 0.26153846153846155
Test Recall for epoch 8 : 0.26153846153846155
Test F1 for epoch 8 : 0.26153846153846155


theta for epoch 9 : tensor([[1.3918, 1.4270, 1.4677, 1.4507, 1.4564, 1.4033, 1.4159, 1.3917, 1.3917,
         1.3724, 1.3680, 1.3737, 1.3461, 1.3717, 1.2998, 1.3714, 1.3728, 1.3238,
         1.2961, 1.2553, 1.3123, 1.3031, 1.3381, 1.3401, 1.3375, 1.3400, 1.3400,
         1.3973, 1.5068, 1.4985, 1.5018, 1.4784, 1.5014, 1.4843, 1.4682, 1.4988,
         1.3704, 1.3780, 1.3777, 1.3754, 1.3760, 1.3369, 1.3717, 1.2716, 1.2923,
         1.4672, 1.4902, 1.4943, 1.4990, 1.4844, 1.4881, 1.3796, 1.4998, 1.5004],
        [1.4261, 1.2793, 1.0925, 1.3561, 1.3827, 1.4519, 1.4113, 1.4521, 1.4521,
         1.3319, 1.3603, 1.3112, 1.4081, 1.3245, 1.4835, 1.3292, 1.3020, 1.4468,
         1.2772, 1.2806, 1.0231, 1.2612, 1.3712, 1.4173, 1.3925, 1.4191, 1.4191,
         1.3595, 1.2374, 1.4190, 1.3958, 1.2532, 1.4198, 1.4034, 1.4114, 1.4006,
         1.4214, 1.4541, 1.4479, 1.4255, 1.3970, 1.4393, 1.4451, 0.7351, 1.3761,
         1.1352, 1.4856, 1.4788, 1.4887, 1.2460, 1.4849, 0.7903, 1.4895, 1.4900],
        [1.3447, 1.3282, 1.3050, 1.2959, 1.2647, 1.3445, 1.2803, 1.3445, 1.3445,
         1.4107, 1.3877, 1.4130, 1.3849, 1.4115, 1.0751, 1.4110, 1.3801, 1.3095,
         1.3936, 1.4104, 1.4299, 1.4100, 1.3635, 1.3629, 1.3875, 1.3555, 1.3555,
         1.2873, 1.2843, 1.3401, 1.3392, 1.2796, 1.3409, 1.3382, 1.3390, 1.3401,
         1.4019, 1.4080, 1.4075, 1.3852, 1.4037, 1.4033, 1.4069, 1.1413, 1.2186,
         1.3051, 1.4010, 1.4004, 1.3992, 1.2616, 1.4000, 1.2621, 1.3982, 1.4001],
        [1.3959, 1.3953, 1.2800, 1.2366, 1.3841, 1.3841, 1.3872, 1.3957, 1.3957,
         1.3496, 1.3093, 1.3090, 1.2858, 1.3497, 1.2517, 1.3460, 1.3483, 1.1413,
         1.3315, 1.2094, 1.3188, 1.3233, 1.3180, 1.3098, 1.3266, 1.3306, 1.3306,
         1.3667, 1.2929, 1.2668, 1.2866, 1.3539, 1.2636, 1.3517, 1.2678, 1.2626,
         1.3557, 1.3325, 1.3256, 1.3383, 1.3493, 1.2831, 1.3420, 1.0825, 1.2704,
         1.4279, 1.3809, 1.3133, 1.4060, 1.4148, 1.3353, 1.4360, 1.4063, 1.4329],
        [1.3716, 1.2922, 0.7593, 0.8657, 1.2519, 1.3572, 1.3288, 1.3715, 1.3715,
         1.4049, 1.3467, 1.3002, 1.1611, 1.4230, 0.7203, 1.3626, 1.4229, 1.2696,
         1.2983, 1.1237, 1.1039, 1.2377, 1.4220, 1.4245, 1.2591, 1.4431, 1.4431,
         0.8911, 0.8939, 1.3655, 1.2974, 0.9589, 1.3608, 1.2190, 1.3639, 1.3565,
         1.1827, 1.1195, 1.1052, 1.1590, 1.2471, 1.2665, 1.1584, 1.4832, 1.4513,
         0.9774, 1.1917, 1.2451, 1.3693, 1.1666, 1.3493, 0.8033, 1.3299, 1.3923],
        [1.5366, 1.5167, 1.4249, 1.4914, 1.4459, 1.5013, 1.5011, 1.5364, 1.5364,
         1.4097, 1.3824, 1.3858, 1.3557, 1.4551, 1.1528, 1.4106, 1.4552, 1.3495,
         1.4328, 1.3634, 1.1875, 1.3601, 1.4322, 1.4345, 1.4113, 1.4395, 1.4395,
         1.5384, 1.3730, 1.5903, 1.4101, 1.4397, 1.4057, 1.5593, 1.5081, 1.5906,
         1.4232, 1.3393, 1.4290, 1.4102, 1.2840, 1.2426, 1.4284, 1.0119, 0.7788,
         1.5762, 1.4091, 1.4547, 1.4505, 1.4483, 1.2790, 1.5766, 1.4196, 1.2748]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 9 : 186.90081222124417
Test loss for epoch 9 : 186.62843016571247
Test Precision for epoch 9 : 0.26153846153846155
Test Recall for epoch 9 : 0.26153846153846155
Test F1 for epoch 9 : 0.26153846153846155


theta for epoch 10 : tensor([[1.4169, 1.4569, 1.5028, 1.4837, 1.4903, 1.4299, 1.4442, 1.4167, 1.4167,
         1.3821, 1.3780, 1.3841, 1.3549, 1.3813, 1.3087, 1.3813, 1.3826, 1.3317,
         1.3022, 1.2595, 1.3211, 1.3102, 1.3467, 1.3486, 1.3466, 1.3483, 1.3483,
         1.4095, 1.5290, 1.5166, 1.5211, 1.4988, 1.5204, 1.5023, 1.4830, 1.5171,
         1.4135, 1.4217, 1.4214, 1.4189, 1.4197, 1.3772, 1.4149, 1.3109, 1.3309,
         1.4587, 1.4819, 1.4860, 1.4902, 1.4768, 1.4796, 1.3678, 1.4914, 1.4920],
        [1.4362, 1.2772, 1.0836, 1.3610, 1.3891, 1.4649, 1.4199, 1.4650, 1.4650,
         1.3290, 1.3621, 1.3051, 1.4180, 1.3205, 1.5065, 1.3260, 1.2946, 1.4634,
         1.2832, 1.2886, 1.0149, 1.2672, 1.3845, 1.4357, 1.4088, 1.4375, 1.4375,
         1.3823, 1.2474, 1.4469, 1.4213, 1.2650, 1.4481, 1.4302, 1.4388, 1.4266,
         1.4601, 1.4978, 1.4907, 1.4649, 1.4323, 1.4810, 1.4875, 0.7483, 1.4094,
         1.1225, 1.5001, 1.4924, 1.5029, 1.2399, 1.4992, 0.7887, 1.5039, 1.5045],
        [1.3493, 1.3326, 1.3105, 1.2990, 1.2647, 1.3492, 1.2805, 1.3491, 1.3491,
         1.4212, 1.3967, 1.4243, 1.3952, 1.4219, 1.0731, 1.4217, 1.3877, 1.3147,
         1.4053, 1.4252, 1.4481, 1.4247, 1.3702, 1.3697, 1.3984, 1.3610, 1.3610,
         1.3029, 1.3002, 1.3600, 1.3594, 1.2948, 1.3611, 1.3583, 1.3590, 1.3600,
         1.4413, 1.4481, 1.4475, 1.4226, 1.4434, 1.4431, 1.4467, 1.1699, 1.2469,
         1.3052, 1.4075, 1.4067, 1.4048, 1.2583, 1.4063, 1.2617, 1.4039, 1.4059],
        [1.3830, 1.3828, 1.2613, 1.2154, 1.3708, 1.3703, 1.3739, 1.3828, 1.3828,
         1.3525, 1.3082, 1.3087, 1.2835, 1.3524, 1.2493, 1.3487, 1.3510, 1.1274,
         1.3334, 1.1998, 1.3214, 1.3250, 1.3178, 1.3084, 1.3280, 1.3317, 1.3317,
         1.4057, 1.3234, 1.2941, 1.3163, 1.3916, 1.2906, 1.3891, 1.2953, 1.2895,
         1.3850, 1.3591, 1.3513, 1.3655, 1.3782, 1.3053, 1.3695, 1.0966, 1.2933,
         1.4186, 1.3656, 1.2922, 1.3928, 1.4040, 1.3156, 1.4283, 1.3933, 1.4227],
        [1.3903, 1.2991, 0.7284, 0.8474, 1.2520, 1.3735, 1.3408, 1.3901, 1.3901,
         1.4257, 1.3607, 1.3089, 1.1555, 1.4459, 0.6981, 1.3783, 1.4457, 1.2748,
         1.3017, 1.1102, 1.0919, 1.2350, 1.4392, 1.4423, 1.2594, 1.4633, 1.4633,
         0.8842, 0.8880, 1.3941, 1.3164, 0.9611, 1.3888, 1.2259, 1.3926, 1.3838,
         1.2012, 1.1293, 1.1134, 1.1746, 1.2734, 1.2955, 1.1737, 1.5380, 1.5021,
         0.9723, 1.1845, 1.2454, 1.3871, 1.1550, 1.3637, 0.7771, 1.3422, 1.4132],
        [1.5344, 1.5136, 1.4185, 1.4877, 1.4371, 1.4954, 1.4955, 1.5340, 1.5340,
         1.4193, 1.3901, 1.3933, 1.3628, 1.4705, 1.1557, 1.4204, 1.4707, 1.3566,
         1.4483, 1.3737, 1.1880, 1.3689, 1.4468, 1.4491, 1.4236, 1.4544, 1.4544,
         1.5657, 1.3872, 1.6218, 1.4202, 1.4554, 1.4146, 1.5880, 1.5277, 1.6222,
         1.4703, 1.3752, 1.4767, 1.4559, 1.3135, 1.2672, 1.4760, 1.0489, 0.8031,
         1.6186, 1.4276, 1.4798, 1.4750, 1.4714, 1.2800, 1.6188, 1.4398, 1.2752]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 10 : 186.59620778785234
Test loss for epoch 10 : 186.3311501926907
Test Precision for epoch 10 : 0.26153846153846155
Test Recall for epoch 10 : 0.26153846153846155
Test F1 for epoch 10 : 0.26153846153846155


theta for epoch 11 : tensor([[1.4405, 1.4853, 1.5366, 1.5153, 1.5228, 1.4551, 1.4710, 1.4402, 1.4402,
         1.4024, 1.3986, 1.4051, 1.3747, 1.4013, 1.3291, 1.4018, 1.4028, 1.3507,
         1.3202, 1.2765, 1.3417, 1.3293, 1.3664, 1.3683, 1.3672, 1.3678, 1.3678,
         1.3827, 1.5096, 1.4941, 1.4994, 1.4778, 1.4985, 1.4795, 1.4578, 1.4946,
         1.4585, 1.4675, 1.4670, 1.4644, 1.4654, 1.4199, 1.4600, 1.3535, 1.3725,
         1.4398, 1.4629, 1.4669, 1.4703, 1.4587, 1.4604, 1.3466, 1.4718, 1.4725],
        [1.4344, 1.2635, 1.0641, 1.3543, 1.3838, 1.4661, 1.4168, 1.4661, 1.4661,
         1.3373, 1.3751, 1.3102, 1.4390, 1.3276, 1.5401, 1.3339, 1.2984, 1.4909,
         1.2916, 1.2993, 1.0082, 1.2756, 1.4005, 1.4570, 1.4281, 1.4588, 1.4588,
         1.3816, 1.2348, 1.4511, 1.4232, 1.2540, 1.4527, 1.4333, 1.4423, 1.4287,
         1.4965, 1.5394, 1.5312, 1.5021, 1.4651, 1.5205, 1.5276, 0.7574, 1.4403,
         1.0970, 1.5008, 1.4921, 1.5030, 1.2203, 1.4995, 0.7749, 1.5043, 1.5050],
        [1.3522, 1.3357, 1.3154, 1.3014, 1.2639, 1.3522, 1.2795, 1.3519, 1.3519,
         1.4452, 1.4194, 1.4491, 1.4193, 1.4457, 1.0869, 1.4459, 1.4090, 1.3342,
         1.4182, 1.4411, 1.4676, 1.4406, 1.3779, 1.3774, 1.4103, 1.3674, 1.3674,
         1.3034, 1.3010, 1.3640, 1.3639, 1.2947, 1.3656, 1.3626, 1.3631, 1.3642,
         1.4834, 1.4910, 1.4901, 1.4629, 1.4860, 1.4858, 1.4892, 1.2026, 1.2791,
         1.3008, 1.4084, 1.4074, 1.4045, 1.2507, 1.4070, 1.2575, 1.4039, 1.4061],
        [1.3622, 1.3625, 1.2355, 1.1872, 1.3497, 1.3488, 1.3530, 1.3619, 1.3619,
         1.3598, 1.3114, 1.3130, 1.2857, 1.3596, 1.2516, 1.3560, 1.3582, 1.1175,
         1.3399, 1.1950, 1.3289, 1.3314, 1.3218, 1.3113, 1.3340, 1.3370, 1.3370,
         1.4452, 1.3541, 1.3215, 1.3461, 1.4297, 1.3177, 1.4268, 1.3230, 1.3164,
         1.4132, 1.3846, 1.3759, 1.3917, 1.4061, 1.3265, 1.3960, 1.1099, 1.3155,
         1.3995, 1.3406, 1.2617, 1.3696, 1.3833, 1.2861, 1.4109, 1.3703, 1.4024],
        [1.4149, 1.3128, 0.7086, 0.8394, 1.2591, 1.3957, 1.3592, 1.4146, 1.4146,
         1.4602, 1.3894, 1.3332, 1.1673, 1.4822, 0.6949, 1.4085, 1.4820, 1.2960,
         1.3216, 1.1153, 1.0989, 1.2496, 1.4708, 1.4744, 1.2767, 1.4974, 1.4974,
         0.8733, 0.8783, 1.4147, 1.3275, 0.9588, 1.4090, 1.2252, 1.4134, 1.4033,
         1.2099, 1.1290, 1.1114, 1.1803, 1.2902, 1.3152, 1.1789, 1.5859, 1.5457,
         0.9735, 1.1827, 1.2503, 1.4080, 1.1488, 1.3817, 0.7591, 1.3582, 1.4373],
        [1.5236, 1.5024, 1.4056, 1.4764, 1.4209, 1.4812, 1.4816, 1.5232, 1.5232,
         1.4384, 1.4076, 1.4103, 1.3803, 1.4949, 1.1702, 1.4397, 1.4952, 1.3740,
         1.4737, 1.3950, 1.2010, 1.3886, 1.4711, 1.4734, 1.4459, 1.4790, 1.4790,
         1.5475, 1.3595, 1.6073, 1.3896, 1.4284, 1.3829, 1.5711, 1.5037, 1.6078,
         1.5187, 1.4124, 1.5255, 1.5030, 1.3446, 1.2935, 1.5247, 1.0886, 0.8299,
         1.6600, 1.4449, 1.5038, 1.4984, 1.4932, 1.2794, 1.6600, 1.4589, 1.2741]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 11 : 186.2053186719862
Test loss for epoch 11 : 185.94470392914374
Test Precision for epoch 11 : 0.26153846153846155
Test Recall for epoch 11 : 0.26153846153846155
Test F1 for epoch 11 : 0.26153846153846155


theta for epoch 12 : tensor([[1.4612, 1.5109, 1.5675, 1.5441, 1.5524, 1.4773, 1.4949, 1.4608, 1.4608,
         1.4290, 1.4258, 1.4324, 1.4012, 1.4277, 1.3568, 1.4286, 1.4294, 1.3766,
         1.3459, 1.3017, 1.3698, 1.3560, 1.3932, 1.3949, 1.3948, 1.3942, 1.3942,
         1.3452, 1.4785, 1.4596, 1.4659, 1.4454, 1.4647, 1.4451, 1.4211, 1.4603,
         1.4924, 1.5021, 1.5013, 1.4987, 1.4999, 1.4516, 1.4939, 1.3862, 1.4037,
         1.4282, 1.4504, 1.4543, 1.4566, 1.4475, 1.4478, 1.3339, 1.4585, 1.4592],
        [1.4273, 1.2444, 1.0397, 1.3425, 1.3733, 1.4621, 1.4084, 1.4619, 1.4619,
         1.3545, 1.3970, 1.3242, 1.4687, 1.3437, 1.5821, 1.3507, 1.3111, 1.5269,
         1.2978, 1.3082, 0.9988, 1.2819, 1.4147, 1.4767, 1.4458, 1.4785, 1.4785,
         1.3692, 1.2107, 1.4433, 1.4131, 1.2315, 1.4453, 1.4246, 1.4340, 1.4190,
         1.5191, 1.5675, 1.5583, 1.5255, 1.4840, 1.5466, 1.5543, 0.7534, 1.4574,
         1.0678, 1.4982, 1.4886, 1.4996, 1.1971, 1.4966, 0.7566, 1.5013, 1.5021],
        [1.3550, 1.3388, 1.3211, 1.3044, 1.2634, 1.3551, 1.2786, 1.3545, 1.3545,
         1.4726, 1.4457, 1.4774, 1.4472, 1.4729, 1.1054, 1.4736, 1.4339, 1.3576,
         1.4357, 1.4618, 1.4919, 1.4612, 1.3903, 1.3899, 1.4270, 1.3785, 1.3785,
         1.2955, 1.2937, 1.3592, 1.3598, 1.2863, 1.3613, 1.3582, 1.3585, 1.3595,
         1.5137, 1.5221, 1.5210, 1.4914, 1.5169, 1.5169, 1.5199, 1.2245, 1.3001,
         1.2983, 1.4108, 1.4096, 1.4056, 1.2453, 1.4092, 1.2557, 1.4053, 1.4076],
        [1.3442, 1.3453, 1.2135, 1.1630, 1.3318, 1.3303, 1.3350, 1.3439, 1.3439,
         1.3723, 1.3199, 1.3228, 1.2933, 1.3720, 1.2597, 1.3686, 1.3706, 1.1133,
         1.3524, 1.1973, 1.3429, 1.3439, 1.3320, 1.3202, 1.3460, 1.3483, 1.3483,
         1.4816, 1.3814, 1.3453, 1.3723, 1.4647, 1.3412, 1.4613, 1.3470, 1.3397,
         1.4329, 1.4017, 1.3918, 1.4093, 1.4257, 1.3394, 1.4139, 1.1159, 1.3300,
         1.3847, 1.3198, 1.2355, 1.3502, 1.3671, 1.2609, 1.3978, 1.3512, 1.3859],
        [1.4457, 1.3335, 0.6991, 0.8409, 1.2735, 1.4242, 1.3842, 1.4453, 1.4453,
         1.5017, 1.4256, 1.3654, 1.1882, 1.5253, 0.7018, 1.4462, 1.5251, 1.3254,
         1.3499, 1.1303, 1.1158, 1.2731, 1.5097, 1.5139, 1.3031, 1.5387, 1.5387,
         0.8625, 0.8688, 1.4328, 1.3366, 0.9562, 1.4269, 1.2225, 1.4319, 1.4204,
         1.2085, 1.1186, 1.0994, 1.1760, 1.2972, 1.3252, 1.1741, 1.6267, 1.5816,
         0.9839, 1.1908, 1.2644, 1.4365, 1.1524, 1.4075, 0.7520, 1.3823, 1.4685],
        [1.5126, 1.4914, 1.3947, 1.4660, 1.4056, 1.4671, 1.4679, 1.5121, 1.5121,
         1.4609, 1.4290, 1.4311, 1.4021, 1.5226, 1.1900, 1.4625, 1.5231, 1.3957,
         1.5028, 1.4207, 1.2198, 1.4125, 1.4990, 1.5012, 1.4719, 1.5069, 1.5069,
         1.5143, 1.3185, 1.5771, 1.3453, 1.3873, 1.3375, 1.5390, 1.4649, 1.5777,
         1.5543, 1.4359, 1.5616, 1.5374, 1.3620, 1.3062, 1.5607, 1.1169, 0.8452,
         1.7057, 1.4675, 1.5331, 1.5270, 1.5199, 1.2845, 1.7054, 1.4833, 1.2786]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 12 : 186.17326182822828
Test loss for epoch 12 : 185.9124434884567
Test Precision for epoch 12 : 0.26153846153846155
Test Recall for epoch 12 : 0.26153846153846155
Test F1 for epoch 12 : 0.26153846153846155


theta for epoch 13 : tensor([[1.4819, 1.5363, 1.5980, 1.5727, 1.5818, 1.4996, 1.5187, 1.4814, 1.4814,
         1.4532, 1.4505, 1.4575, 1.4257, 1.4517, 1.3830, 1.4531, 1.4536, 1.4007,
         1.3722, 1.3281, 1.3985, 1.3832, 1.4200, 1.4215, 1.4226, 1.4206, 1.4206,
         1.3253, 1.4631, 1.4398, 1.4475, 1.4293, 1.4459, 1.4260, 1.3997, 1.4407,
         1.5030, 1.5136, 1.5125, 1.5098, 1.5113, 1.4604, 1.5045, 1.3965, 1.4122,
         1.4327, 1.4536, 1.4572, 1.4581, 1.4523, 1.4508, 1.3390, 1.4604, 1.4612],
        [1.4261, 1.2314, 1.0218, 1.3370, 1.3690, 1.4640, 1.4060, 1.4636, 1.4636,
         1.3736, 1.4208, 1.3401, 1.5007, 1.3616, 1.6263, 1.3694, 1.3256, 1.5652,
         1.3000, 1.3133, 0.9860, 1.2844, 1.4249, 1.4924, 1.4595, 1.4941, 1.4941,
         1.3613, 1.1910, 1.4396, 1.4073, 1.2133, 1.4422, 1.4202, 1.4298, 1.4133,
         1.5216, 1.5758, 1.5654, 1.5288, 1.4829, 1.5527, 1.5609, 0.7335, 1.4545,
         1.0449, 1.5020, 1.4914, 1.5024, 1.1801, 1.5000, 0.7429, 1.5044, 1.5053],
        [1.3632, 1.3476, 1.3328, 1.3132, 1.2686, 1.3634, 1.2833, 1.3626, 1.3626,
         1.4920, 1.4640, 1.4977, 1.4673, 1.4921, 1.1174, 1.4932, 1.4508, 1.3733,
         1.4575, 1.4869, 1.5204, 1.4862, 1.4070, 1.4067, 1.4481, 1.3940, 1.3940,
         1.2916, 1.2904, 1.3581, 1.3594, 1.2820, 1.3607, 1.3576, 1.3577, 1.3584,
         1.5212, 1.5305, 1.5292, 1.4971, 1.5251, 1.5253, 1.5279, 1.2253, 1.2992,
         1.3025, 1.4196, 1.4182, 1.4129, 1.2466, 1.4178, 1.2610, 1.4130, 1.4154],
        [1.3388, 1.3408, 1.2053, 1.1526, 1.3268, 1.3245, 1.3298, 1.3383, 1.3383,
         1.3855, 1.3294, 1.3337, 1.3023, 1.3850, 1.2696, 1.3819, 1.3837, 1.1112,
         1.3683, 1.2045, 1.3606, 1.3600, 1.3455, 1.3325, 1.3614, 1.3628, 1.3628,
         1.5152, 1.4058, 1.3661, 1.3957, 1.4969, 1.3617, 1.4931, 1.3681, 1.3600,
         1.4370, 1.4033, 1.3924, 1.4115, 1.4298, 1.3373, 1.4163, 1.1090, 1.3298,
         1.3827, 1.3117, 1.2225, 1.3433, 1.3637, 1.2486, 1.3976, 1.3446, 1.3818],
        [1.4805, 1.3585, 0.6932, 0.8461, 1.2920, 1.4568, 1.4134, 1.4800, 1.4800,
         1.5385, 1.4569, 1.3927, 1.2040, 1.5637, 0.7038, 1.4791, 1.5636, 1.3499,
         1.3745, 1.1414, 1.1292, 1.2928, 1.5450, 1.5500, 1.3259, 1.5765, 1.5765,
         0.8549, 0.8625, 1.4548, 1.3496, 0.9570, 1.4487, 1.2236, 1.4543, 1.4414,
         1.2029, 1.1037, 1.0829, 1.1674, 1.3002, 1.3315, 1.1650, 1.6656, 1.6152,
         0.9982, 1.2042, 1.2837, 1.4695, 1.1610, 1.4380, 0.7491, 1.4113, 1.5043],
        [1.5147, 1.4941, 1.3995, 1.4701, 1.4054, 1.4666, 1.4678, 1.5140, 1.5140,
         1.4798, 1.4470, 1.4482, 1.4209, 1.5464, 1.2084, 1.4816, 1.5472, 1.4143,
         1.5300, 1.4454, 1.2390, 1.4353, 1.5250, 1.5270, 1.4961, 1.5328, 1.5328,
         1.4944, 1.2939, 1.5585, 1.3153, 1.3607, 1.3062, 1.5192, 1.4388, 1.5592,
         1.5670, 1.4366, 1.5748, 1.5489, 1.3570, 1.2969, 1.5737, 1.1246, 0.8410,
         1.7538, 1.4935, 1.5655, 1.5588, 1.5494, 1.2932, 1.7531, 1.5110, 1.2867]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 13 : 186.27124757787416
Test loss for epoch 13 : 186.00592832393656
Test Precision for epoch 13 : 0.26153846153846155
Test Recall for epoch 13 : 0.26153846153846155
Test F1 for epoch 13 : 0.26153846153846155


theta for epoch 14 : tensor([[1.5031, 1.5622, 1.6288, 1.6016, 1.6115, 1.5223, 1.5430, 1.5026, 1.5026,
         1.4629, 1.4610, 1.4681, 1.4360, 1.4611, 1.3955, 1.4631, 1.4632, 1.4109,
         1.3875, 1.3441, 1.4160, 1.3993, 1.4352, 1.4365, 1.4388, 1.4353, 1.4353,
         1.3268, 1.4674, 1.4392, 1.4484, 1.4334, 1.4464, 1.4266, 1.3980, 1.4402,
         1.5055, 1.5169, 1.5154, 1.5128, 1.5146, 1.4613, 1.5071, 1.3992, 1.4129,
         1.4517, 1.4709, 1.4741, 1.4734, 1.4715, 1.4679, 1.3595, 1.4761, 1.4771],
        [1.4360, 1.2306, 1.0167, 1.3435, 1.3762, 1.4767, 1.4147, 1.4761, 1.4761,
         1.3865, 1.4388, 1.3497, 1.5270, 1.3734, 1.6657, 1.3820, 1.3340, 1.5983,
         1.2940, 1.3102, 0.9672, 1.2789, 1.4261, 1.4988, 1.4641, 1.5004, 1.5004,
         1.3636, 1.1818, 1.4454, 1.4112, 1.2056, 1.4487, 1.4255, 1.4353, 1.4172,
         1.5178, 1.5777, 1.5662, 1.5259, 1.4755, 1.5525, 1.5612, 0.7098, 1.4454,
         1.0337, 1.5156, 1.5042, 1.5149, 1.1744, 1.5133, 0.7392, 1.5173, 1.5183],
        [1.3777, 1.3630, 1.3514, 1.3288, 1.2805, 1.3781, 1.2947, 1.3770, 1.3770,
         1.4916, 1.4627, 1.4982, 1.4678, 1.4913, 1.1121, 1.4930, 1.4479, 1.3700,
         1.4803, 1.5131, 1.5501, 1.5123, 1.4247, 1.4245, 1.4702, 1.4105, 1.4105,
         1.2944, 1.2941, 1.3634, 1.3657, 1.2845, 1.3667, 1.3635, 1.3633, 1.3639,
         1.5192, 1.5293, 1.5277, 1.4932, 1.5236, 1.5241, 1.5262, 1.2170, 1.2889,
         1.3135, 1.4349, 1.4333, 1.4266, 1.2550, 1.4329, 1.2734, 1.4271, 1.4295],
        [1.3472, 1.3502, 1.2120, 1.1573, 1.3357, 1.3326, 1.3386, 1.3466, 1.3466,
         1.3913, 1.3318, 1.3377, 1.3044, 1.3904, 1.2734, 1.3878, 1.3893, 1.1037,
         1.3796, 1.2090, 1.3743, 1.3718, 1.3546, 1.3403, 1.3723, 1.3725, 1.3725,
         1.5454, 1.4265, 1.3832, 1.4153, 1.5258, 1.3785, 1.5213, 1.3855, 1.3765,
         1.4376, 1.4017, 1.3897, 1.4103, 1.4305, 1.3323, 1.4151, 1.1003, 1.3267,
         1.3937, 1.3170, 1.2233, 1.3494, 1.3736, 1.2499, 1.4105, 1.3509, 1.3904],
        [1.5135, 1.3808, 0.6810, 0.8457, 1.3073, 1.4873, 1.4401, 1.5129, 1.5129,
         1.5564, 1.4688, 1.4004, 1.1999, 1.5835, 0.6868, 1.4927, 1.5833, 1.3546,
         1.3804, 1.1338, 1.1237, 1.2937, 1.5625, 1.5684, 1.3304, 1.5969, 1.5969,
         0.8443, 0.8533, 1.4774, 1.3628, 0.9553, 1.4712, 1.2241, 1.4775, 1.4630,
         1.2060, 1.0972, 1.0748, 1.1675, 1.3120, 1.3466, 1.1644, 1.7126, 1.6573,
         1.0075, 1.2143, 1.3003, 1.5009, 1.1657, 1.4667, 0.7399, 1.4382, 1.5385],
        [1.5333, 1.5140, 1.4230, 1.4916, 1.4235, 1.4834, 1.4851, 1.5325, 1.5325,
         1.4858, 1.4525, 1.4529, 1.4278, 1.5571, 1.2170, 1.4878, 1.5581, 1.4211,
         1.5469, 1.4606, 1.2510, 1.4486, 1.5406, 1.5423, 1.5100, 1.5482, 1.5482,
         1.4957, 1.2946, 1.5593, 1.3089, 1.3575, 1.2986, 1.5201, 1.4340, 1.5603,
         1.5729, 1.4307, 1.5812, 1.5537, 1.3459, 1.2819, 1.5798, 1.1277, 0.8333,
         1.7979, 1.5153, 1.5939, 1.5866, 1.5746, 1.2981, 1.7968, 1.5347, 1.2911]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 14 : 186.2092660083963
Test loss for epoch 14 : 185.94729163018664
Test Precision for epoch 14 : 0.26153846153846155
Test Recall for epoch 14 : 0.26153846153846155
Test F1 for epoch 14 : 0.26153846153846155


theta for epoch 15 : tensor([[1.5207, 1.5843, 1.6555, 1.6266, 1.6373, 1.5413, 1.5635, 1.5201, 1.5201,
         1.4612, 1.4601, 1.4674, 1.4352, 1.4591, 1.3972, 1.4617, 1.4615, 1.4102,
         1.3878, 1.3454, 1.4184, 1.4004, 1.4351, 1.4361, 1.4396, 1.4346, 1.4346,
         1.3460, 1.4884, 1.4551, 1.4661, 1.4544, 1.4636, 1.4440, 1.4135, 1.4563,
         1.5085, 1.5206, 1.5189, 1.5162, 1.5183, 1.4630, 1.5101, 1.4031, 1.4148,
         1.4802, 1.4974, 1.5003, 1.4978, 1.5002, 1.4944, 1.3904, 1.5010, 1.5020],
        [1.4529, 1.2381, 1.0210, 1.3577, 1.3909, 1.4962, 1.4307, 1.4953, 1.4953,
         1.3929, 1.4503, 1.3528, 1.5473, 1.3787, 1.6996, 1.3880, 1.3357, 1.6257,
         1.2774, 1.2965, 0.9405, 1.2629, 1.4157, 1.4932, 1.4569, 1.4947, 1.4947,
         1.3755, 1.1829, 1.4603, 1.4245, 1.2082, 1.4644, 1.4401, 1.4500, 1.4303,
         1.5145, 1.5802, 1.5675, 1.5236, 1.4688, 1.5529, 1.5621, 0.6884, 1.4370,
         1.0316, 1.5362, 1.5240, 1.5343, 1.1774, 1.5337, 0.7435, 1.5370, 1.5381],
        [1.3946, 1.3808, 1.3726, 1.3469, 1.2950, 1.3951, 1.3086, 1.3937, 1.3937,
         1.4760, 1.4463, 1.4836, 1.4534, 1.4754, 1.0937, 1.4777, 1.4302, 1.3523,
         1.5019, 1.5381, 1.5787, 1.5373, 1.4411, 1.4410, 1.4910, 1.4256, 1.4256,
         1.3038, 1.3045, 1.3749, 1.3783, 1.2937, 1.3791, 1.3757, 1.3752, 1.3755,
         1.5149, 1.5259, 1.5240, 1.4871, 1.5200, 1.5207, 1.5222, 1.2066, 1.2767,
         1.3284, 1.4536, 1.4518, 1.4435, 1.2673, 1.4514, 1.2900, 1.4445, 1.4470],
        [1.3646, 1.3688, 1.2286, 1.1721, 1.3539, 1.3498, 1.3565, 1.3639, 1.3639,
         1.3909, 1.3284, 1.3361, 1.3011, 1.3898, 1.2724, 1.3876, 1.3888, 1.0922,
         1.3819, 1.2061, 1.3792, 1.3746, 1.3547, 1.3393, 1.3741, 1.3732, 1.3732,
         1.5722, 1.4436, 1.3966, 1.4313, 1.5511, 1.3917, 1.5462, 1.3992, 1.3894,
         1.4412, 1.4033, 1.3902, 1.4122, 1.4343, 1.3309, 1.4171, 1.0962, 1.3274,
         1.4141, 1.3318, 1.2342, 1.3646, 1.3931, 1.2612, 1.4327, 1.3666, 1.4081],
        [1.5391, 1.3944, 0.6573, 0.8339, 1.3131, 1.5102, 1.4588, 1.5385, 1.5385,
         1.5569, 1.4628, 1.3903, 1.1782, 1.5859, 0.6529, 1.4887, 1.5858, 1.3414,
         1.3654, 1.1060, 1.0980, 1.2739, 1.5591, 1.5661, 1.3141, 1.5966, 1.5966,
         0.8279, 0.8383, 1.4985, 1.3739, 0.9484, 1.4922, 1.2212, 1.4993, 1.4830,
         1.2222, 1.1038, 1.0798, 1.1809, 1.3366, 1.3745, 1.1770, 1.7697, 1.7100,
         1.0066, 1.2158, 1.3089, 1.5259, 1.1611, 1.4886, 0.7196, 1.4582, 1.5666],
        [1.5624, 1.5447, 1.4583, 1.5242, 1.4534, 1.5112, 1.5135, 1.5614, 1.5614,
         1.4824, 1.4491, 1.4484, 1.4261, 1.5580, 1.2190, 1.4847, 1.5593, 1.4194,
         1.5498, 1.4627, 1.2521, 1.4488, 1.5423, 1.5437, 1.5100, 1.5495, 1.5495,
         1.5155, 1.3161, 1.5774, 1.3230, 1.3746, 1.3117, 1.5388, 1.4481, 1.5786,
         1.5806, 1.4271, 1.5893, 1.5605, 1.3377, 1.2701, 1.5876, 1.1351, 0.8313,
         1.8335, 1.5282, 1.6137, 1.6056, 1.5904, 1.2946, 1.8317, 1.5496, 1.2869]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 15 : 185.89086405473967
Test loss for epoch 15 : 185.64568254508083
Test Precision for epoch 15 : 0.26153846153846155
Test Recall for epoch 15 : 0.26153846153846155
Test F1 for epoch 15 : 0.26153846153846155


theta for epoch 16 : tensor([[1.5265, 1.5946, 1.6705, 1.6398, 1.6514, 1.5485, 1.5722, 1.5258, 1.5258,
         1.4593, 1.4590, 1.4666, 1.4345, 1.4568, 1.3995, 1.4601, 1.4594, 1.4097,
         1.3840, 1.3431, 1.4166, 1.3974, 1.4304, 1.4311, 1.4358, 1.4294, 1.4294,
         1.3776, 1.5208, 1.4825, 1.4952, 1.4872, 1.4922, 1.4731, 1.4407, 1.4839,
         1.5131, 1.5260, 1.5239, 1.5212, 1.5236, 1.4667, 1.5147, 1.4094, 1.4189,
         1.5089, 1.5235, 1.5261, 1.5217, 1.5289, 1.5207, 1.4222, 1.5254, 1.5265],
        [1.4632, 1.2403, 1.0216, 1.3660, 1.3993, 1.5089, 1.4402, 1.5077, 1.5077,
         1.3979, 1.4605, 1.3543, 1.5664, 1.3824, 1.7326, 1.3926, 1.3359, 1.6521,
         1.2569, 1.2792, 0.9117, 1.2432, 1.4009, 1.4829, 1.4452, 1.4842, 1.4842,
         1.3936, 1.1907, 1.4809, 1.4437, 1.2174, 1.4859, 1.4606, 1.4706, 1.4492,
         1.5118, 1.5831, 1.5693, 1.5218, 1.4627, 1.5538, 1.5634, 0.6687, 1.4293,
         1.0302, 1.5555, 1.5426, 1.5521, 1.1804, 1.5527, 0.7483, 1.5552, 1.5564],
        [1.4012, 1.3886, 1.3842, 1.3553, 1.2999, 1.4019, 1.3127, 1.4001, 1.4001,
         1.4569, 1.4266, 1.4656, 1.4357, 1.4560, 1.0731, 1.4589, 1.4090, 1.3316,
         1.5243, 1.5641, 1.6083, 1.5632, 1.4584, 1.4585, 1.5129, 1.4417, 1.4417,
         1.3178, 1.3197, 1.3906, 1.3954, 1.3076, 1.3958, 1.3922, 1.3915, 1.3914,
         1.5096, 1.5215, 1.5193, 1.4801, 1.5154, 1.5163, 1.5172, 1.1958, 1.2639,
         1.3395, 1.4679, 1.4660, 1.4561, 1.2762, 1.4657, 1.3032, 1.4575, 1.4602],
        [1.3802, 1.3858, 1.2449, 1.1868, 1.3705, 1.3654, 1.3729, 1.3794, 1.3794,
         1.3926, 1.3275, 1.3371, 1.3006, 1.3911, 1.2746, 1.3896, 1.3905, 1.0846,
         1.3832, 1.2040, 1.3836, 1.3766, 1.3539, 1.3375, 1.3749, 1.3727, 1.3727,
         1.5959, 1.4575, 1.4066, 1.4440, 1.5734, 1.4015, 1.5678, 1.4096, 1.3989,
         1.4479, 1.4082, 1.3941, 1.4174, 1.4413, 1.3332, 1.4223, 1.0969, 1.3320,
         1.4370, 1.3493, 1.2482, 1.3823, 1.4151, 1.2755, 1.4576, 1.3846, 1.4280],
        [1.5512, 1.3937, 0.6208, 0.8085, 1.3042, 1.5192, 1.4633, 1.5504, 1.5504,
         1.5503, 1.4497, 1.3729, 1.1489, 1.5815, 0.6110, 1.4776, 1.5812, 1.3210,
         1.3400, 1.0681, 1.0622, 1.2437, 1.5453, 1.5535, 1.2876, 1.5861, 1.5861,
         0.8077, 0.8195, 1.5186, 1.3835, 0.9380, 1.5122, 1.2162, 1.5203, 1.5019,
         1.2473, 1.1195, 1.0938, 1.2032, 1.3699, 1.4110, 1.1985, 1.8337, 1.7700,
         0.9945, 1.2070, 1.3074, 1.5415, 1.1455, 1.5009, 0.6885, 1.4686, 1.5856],
        [1.5840, 1.5683, 1.4880, 1.5502, 1.4772, 1.5319, 1.5347, 1.5827, 1.5827,
         1.4791, 1.4464, 1.4444, 1.4254, 1.5587, 1.2238, 1.4817, 1.5602, 1.4187,
         1.5481, 1.4611, 1.2514, 1.4453, 1.5394, 1.5404, 1.5055, 1.5460, 1.5460,
         1.5467, 1.3504, 1.6063, 1.3497, 1.4040, 1.3375, 1.5688, 1.4739, 1.6076,
         1.5899, 1.4256, 1.5990, 1.5691, 1.3321, 1.2613, 1.5970, 1.1461, 0.8338,
         1.8608, 1.5327, 1.6251, 1.6161, 1.5973, 1.2830, 1.8583, 1.5560, 1.2748]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 16 : 185.68055418885322
Test loss for epoch 16 : 185.46276963398358
Test Precision for epoch 16 : 0.26153846153846155
Test Recall for epoch 16 : 0.26153846153846155
Test F1 for epoch 16 : 0.26153846153846155


theta for epoch 17 : tensor([[1.5290, 1.6016, 1.6821, 1.6498, 1.6621, 1.5524, 1.5776, 1.5283, 1.5283,
         1.4616, 1.4623, 1.4700, 1.4383, 1.4587, 1.4067, 1.4627, 1.4616, 1.4139,
         1.3832, 1.3441, 1.4175, 1.3972, 1.4283, 1.4285, 1.4345, 1.4266, 1.4266,
         1.4106, 1.5542, 1.5105, 1.5250, 1.5211, 1.5215, 1.5030, 1.4688, 1.5122,
         1.5159, 1.5296, 1.5271, 1.5244, 1.5271, 1.4687, 1.5175, 1.4146, 1.4216,
         1.5242, 1.5362, 1.5383, 1.5319, 1.5441, 1.5335, 1.4413, 1.5360, 1.5373],
        [1.4612, 1.2315, 1.0131, 1.3628, 1.3959, 1.5090, 1.4374, 1.5076, 1.5076,
         1.4049, 1.4729, 1.3580, 1.5878, 1.3883, 1.7681, 1.3992, 1.3382, 1.6808,
         1.2406, 1.2661, 0.8880, 1.2279, 1.3899, 1.4760, 1.4372, 1.4771, 1.4771,
         1.4132, 1.2002, 1.5024, 1.4640, 1.2283, 1.5084, 1.4822, 1.4920, 1.4690,
         1.5082, 1.5852, 1.5702, 1.5191, 1.4560, 1.5540, 1.5638, 0.6491, 1.4210,
         1.0225, 1.5661, 1.5525, 1.5612, 1.1762, 1.5632, 0.7477, 1.5646, 1.5660],
        [1.3950, 1.3839, 1.3835, 1.3515, 1.2928, 1.3959, 1.3047, 1.3938, 1.3938,
         1.4437, 1.4131, 1.4536, 1.4242, 1.4424, 1.0602, 1.4460, 1.3940, 1.3174,
         1.5483, 1.5916, 1.6394, 1.5907, 1.4773, 1.4777, 1.5363, 1.4594, 1.4594,
         1.3337, 1.3369, 1.4076, 1.4138, 1.3234, 1.4139, 1.4102, 1.4091, 1.4086,
         1.5036, 1.5164, 1.5139, 1.4725, 1.5101, 1.5114, 1.5115, 1.1854, 1.2512,
         1.3416, 1.4726, 1.4707, 1.4589, 1.2767, 1.4704, 1.3082, 1.4608, 1.4636],
        [1.3885, 1.3956, 1.2555, 1.1961, 1.3802, 1.3739, 1.3821, 1.3875, 1.3875,
         1.4013, 1.3339, 1.3455, 1.3076, 1.3994, 1.2848, 1.3987, 1.3991, 1.0852,
         1.3913, 1.2103, 1.3951, 1.3856, 1.3601, 1.3425, 1.3826, 1.3789, 1.3789,
         1.6169, 1.4686, 1.4138, 1.4540, 1.5930, 1.4085, 1.5869, 1.4173, 1.4057,
         1.4557, 1.4145, 1.3993, 1.4238, 1.4496, 1.3374, 1.4288, 1.1002, 1.3386,
         1.4557, 1.3628, 1.2590, 1.3956, 1.4333, 1.2863, 1.4783, 1.3983, 1.4434],
        [1.5533, 1.3833, 0.5790, 0.7766, 1.2859, 1.5182, 1.4579, 1.5524, 1.5524,
         1.5471, 1.4398, 1.3589, 1.1232, 1.5802, 0.5723, 1.4699, 1.5799, 1.3040,
         1.3169, 1.0328, 1.0290, 1.2159, 1.5337, 1.5431, 1.2637, 1.5778, 1.5778,
         0.7892, 0.8026, 1.5394, 1.3942, 0.9292, 1.5331, 1.2124, 1.5421, 1.5216,
         1.2724, 1.1349, 1.1078, 1.2256, 1.4033, 1.4476, 1.2200, 1.8984, 1.8306,
         0.9762, 1.1918, 1.2990, 1.5496, 1.1235, 1.5058, 0.6529, 1.4716, 1.5970],
        [1.5865, 1.5732, 1.4998, 1.5576, 1.4826, 1.5339, 1.5373, 1.5851, 1.5851,
         1.4802, 1.4484, 1.4449, 1.4300, 1.5635, 1.2346, 1.4831, 1.5653, 1.4231,
         1.5491, 1.4629, 1.2551, 1.4450, 1.5390, 1.5396, 1.5037, 1.5450, 1.5450,
         1.5789, 1.3868, 1.6355, 1.3777, 1.4349, 1.3644, 1.5995, 1.5004, 1.6371,
         1.5973, 1.4224, 1.6068, 1.5760, 1.3250, 1.2511, 1.6045, 1.1565, 0.8355,
         1.8865, 1.5358, 1.6353, 1.6255, 1.6025, 1.2704, 1.8832, 1.5613, 1.2615]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 17 : 185.70347956510648
Test loss for epoch 17 : 185.51365972873072
Test Precision for epoch 17 : 0.26153846153846155
Test Recall for epoch 17 : 0.26153846153846155
Test F1 for epoch 17 : 0.26153846153846155


theta for epoch 18 : tensor([[1.5474, 1.6238, 1.7083, 1.6747, 1.6876, 1.5719, 1.5986, 1.5466, 1.5466,
         1.4655, 1.4673, 1.4753, 1.4440, 1.4623, 1.4158, 1.4671, 1.4655, 1.4198,
         1.3833, 1.3460, 1.4193, 1.3980, 1.4267, 1.4265, 1.4340, 1.4242, 1.4242,
         1.4246, 1.5689, 1.5194, 1.5359, 1.5361, 1.5317, 1.5140, 1.4776, 1.5214,
         1.5126, 1.5270, 1.5241, 1.5214, 1.5245, 1.4647, 1.5142, 1.4142, 1.4185,
         1.5216, 1.5310, 1.5328, 1.5242, 1.5415, 1.5284, 1.4423, 1.5288, 1.5303],
        [1.4554, 1.2200, 1.0030, 1.3562, 1.3890, 1.5051, 1.4310, 1.5034, 1.5034,
         1.4148, 1.4882, 1.3644, 1.6121, 1.3970, 1.8063, 1.4088, 1.3433, 1.7125,
         1.2311, 1.2601, 0.8718, 1.2194, 1.3852, 1.4752, 1.4355, 1.4760, 1.4760,
         1.4261, 1.2036, 1.5166, 1.4771, 1.2329, 1.5236, 1.4969, 1.5062, 1.4817,
         1.5027, 1.5853, 1.5691, 1.5146, 1.4475, 1.5523, 1.5623, 0.6289, 1.4112,
         1.0089, 1.5685, 1.5542, 1.5618, 1.1653, 1.5653, 0.7420, 1.5657, 1.5672],
        [1.3879, 1.3784, 1.3824, 1.3475, 1.2856, 1.3890, 1.2966, 1.3864, 1.3864,
         1.4406, 1.4098, 1.4517, 1.4233, 1.4389, 1.0597, 1.4432, 1.3892, 1.3142,
         1.5714, 1.6183, 1.6697, 1.6174, 1.4954, 1.4961, 1.5590, 1.4763, 1.4763,
         1.3449, 1.3495, 1.4191, 1.4269, 1.3346, 1.4264, 1.4228, 1.4212, 1.4203,
         1.4973, 1.5110, 1.5081, 1.4646, 1.5046, 1.5061, 1.5053, 1.1763, 1.2395,
         1.3385, 1.4710, 1.4689, 1.4552, 1.2726, 1.4687, 1.3084, 1.4577, 1.4606],
        [1.3939, 1.4025, 1.2638, 1.2035, 1.3870, 1.3795, 1.3885, 1.3928, 1.3928,
         1.4157, 1.3461, 1.3600, 1.3207, 1.4134, 1.3012, 1.4135, 1.4134, 1.0923,
         1.4056, 1.2237, 1.4130, 1.4009, 1.3723, 1.3536, 1.3965, 1.3911, 1.3911,
         1.6363, 1.4780, 1.4192, 1.4621, 1.6110, 1.4137, 1.6042, 1.4230, 1.4106,
         1.4616, 1.4190, 1.4027, 1.4284, 1.4562, 1.3401, 1.4332, 1.1029, 1.3440,
         1.4679, 1.3701, 1.2637, 1.4022, 1.4450, 1.2909, 1.4924, 1.4054, 1.4521],
        [1.5597, 1.3787, 0.5499, 0.7557, 1.2740, 1.5215, 1.4575, 1.5586, 1.5586,
         1.5540, 1.4409, 1.3566, 1.1106, 1.5889, 0.5481, 1.4729, 1.5886, 1.2991,
         1.3060, 1.0113, 1.0098, 1.2008, 1.5327, 1.5434, 1.2526, 1.5798, 1.5798,
         0.7764, 0.7912, 1.5593, 1.4052, 0.9246, 1.5531, 1.2105, 1.5630, 1.5407,
         1.2868, 1.1397, 1.1110, 1.2372, 1.4259, 1.4737, 1.2306, 1.9551, 1.8826,
         0.9627, 1.1811, 1.2937, 1.5580, 1.1061, 1.5117, 0.6257, 1.4759, 1.6085],
        [1.5774, 1.5663, 1.4999, 1.5534, 1.4766, 1.5242, 1.5280, 1.5758, 1.5758,
         1.4835, 1.4529, 1.4476, 1.4374, 1.5705, 1.2485, 1.4867, 1.5727, 1.4301,
         1.5515, 1.4666, 1.2610, 1.4466, 1.5399, 1.5400, 1.5032, 1.5452, 1.5452,
         1.5935, 1.4064, 1.6468, 1.3878, 1.4479, 1.3733, 1.6126, 1.5089, 1.6487,
         1.5993, 1.4132, 1.6091, 1.5775, 1.3119, 1.2348, 1.6065, 1.1616, 0.8306,
         1.9206, 1.5494, 1.6555, 1.6449, 1.6174, 1.2686, 1.9165, 1.5769, 1.2591]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 18 : 185.71702480631194
Test loss for epoch 18 : 185.54320381088556
Test Precision for epoch 18 : 0.26153846153846155
Test Recall for epoch 18 : 0.26153846153846155
Test F1 for epoch 18 : 0.26153846153846155


theta for epoch 19 : tensor([[1.5805, 1.6602, 1.7479, 1.7135, 1.7267, 1.6060, 1.6338, 1.5796, 1.5796,
         1.4703, 1.4731, 1.4813, 1.4508, 1.4666, 1.4261, 1.4722, 1.4701, 1.4266,
         1.3845, 1.3491, 1.4221, 1.3998, 1.4258, 1.4252, 1.4343, 1.4226, 1.4226,
         1.4138, 1.5588, 1.5039, 1.5223, 1.5262, 1.5175, 1.5005, 1.4621, 1.5062,
         1.5053, 1.5205, 1.5172, 1.5145, 1.5180, 1.4567, 1.5068, 1.4104, 1.4118,
         1.5078, 1.5147, 1.5161, 1.5054, 1.5277, 1.5121, 1.4321, 1.5105, 1.5121],
        [1.4504, 1.2104, 0.9957, 1.3511, 1.3835, 1.5019, 1.4255, 1.4999, 1.4999,
         1.4265, 1.5054, 1.3728, 1.6383, 1.4075, 1.8465, 1.4202, 1.3504, 1.7460,
         1.2285, 1.2611, 0.8637, 1.2181, 1.3870, 1.4803, 1.4402, 1.4808, 1.4808,
         1.4273, 1.1962, 1.5186, 1.4782, 1.2267, 1.5266, 1.4995, 1.5083, 1.4822,
         1.4968, 1.5849, 1.5675, 1.5097, 1.4390, 1.5504, 1.5602, 0.6096, 1.4016,
         0.9937, 1.5669, 1.5520, 1.5582, 1.1520, 1.5633, 0.7347, 1.5626, 1.5642],
        [1.3856, 1.3781, 1.3867, 1.3492, 1.2844, 1.3869, 1.2943, 1.3840, 1.3840,
         1.4467, 1.4162, 1.4592, 1.4321, 1.4446, 1.0710, 1.4497, 1.3941, 1.3212,
         1.5918, 1.6423, 1.6972, 1.6414, 1.5108, 1.5118, 1.5790, 1.4906, 1.4906,
         1.3467, 1.3528, 1.4204, 1.4298, 1.3364, 1.4287, 1.4254, 1.4231, 1.4218,
         1.4925, 1.5071, 1.5038, 1.4585, 1.5007, 1.5026, 1.5006, 1.1708, 1.2310,
         1.3358, 1.4687, 1.4662, 1.4506, 1.2696, 1.4661, 1.3096, 1.4537, 1.4567],
        [1.3959, 1.4061, 1.2689, 1.2078, 1.3905, 1.3817, 1.3915, 1.3945, 1.3945,
         1.4312, 1.3594, 1.3757, 1.3350, 1.4285, 1.3189, 1.4294, 1.4287, 1.1003,
         1.4211, 1.2387, 1.4323, 1.4175, 1.3856, 1.3657, 1.4116, 1.4042, 1.4042,
         1.6571, 1.4889, 1.4260, 1.4716, 1.6305, 1.4203, 1.6229, 1.4302, 1.4168,
         1.4644, 1.4204, 1.4029, 1.4299, 1.4598, 1.3399, 1.4346, 1.1028, 1.3468,
         1.4731, 1.3703, 1.2616, 1.4016, 1.4497, 1.2884, 1.4995, 1.4053, 1.4535],
        [1.5752, 1.3855, 0.5401, 0.7518, 1.2745, 1.5343, 1.4676, 1.5739, 1.5739,
         1.5712, 1.4532, 1.3663, 1.1118, 1.6076, 0.5402, 1.4870, 1.6073, 1.3068,
         1.3086, 1.0055, 1.0064, 1.2000, 1.5432, 1.5553, 1.2556, 1.5930, 1.5930,
         0.7679, 0.7840, 1.5747, 1.4132, 0.9223, 1.5689, 1.2076, 1.5796, 1.5555,
         1.2881, 1.1318, 1.1018, 1.2360, 1.4354, 1.4867, 1.2284, 2.0012, 1.9236,
         0.9602, 1.1814, 1.2976, 1.5720, 1.1003, 1.5238, 0.6142, 1.4870, 1.6252],
        [1.5615, 1.5528, 1.4935, 1.5425, 1.4639, 1.5078, 1.5120, 1.5597, 1.5597,
         1.4868, 1.4577, 1.4505, 1.4456, 1.5777, 1.2633, 1.4904, 1.5802, 1.4374,
         1.5543, 1.4710, 1.2676, 1.4489, 1.5411, 1.5406, 1.5029, 1.5454, 1.5454,
         1.5835, 1.4013, 1.6337, 1.3735, 1.4363, 1.3576, 1.6011, 1.4930, 1.6358,
         1.5969, 1.3992, 1.6072, 1.5749, 1.2941, 1.2138, 1.6041, 1.1624, 0.8200,
         1.9653, 1.5761, 1.6884, 1.6769, 1.6448, 1.2810, 1.9604, 1.6054, 1.2709]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 19 : 185.50905709634623
Test loss for epoch 19 : 185.33546007369247
Test Precision for epoch 19 : 0.26153846153846155
Test Recall for epoch 19 : 0.26153846153846155
Test F1 for epoch 19 : 0.26153846153846155


theta for epoch 20 : tensor([[1.6118, 1.6946, 1.7854, 1.7502, 1.7637, 1.6381, 1.6672, 1.6108, 1.6108,
         1.4758, 1.4797, 1.4883, 1.4588, 1.4717, 1.4379, 1.4782, 1.4756, 1.4345,
         1.3898, 1.3565, 1.4288, 1.4057, 1.4285, 1.4273, 1.4383, 1.4243, 1.4243,
         1.3938, 1.5389, 1.4791, 1.4991, 1.5067, 1.4938, 1.4776, 1.4373, 1.4816,
         1.5006, 1.5167, 1.5129, 1.5103, 1.5143, 1.4517, 1.5020, 1.4104, 1.4087,
         1.4906, 1.4948, 1.4956, 1.4829, 1.5103, 1.4921, 1.4188, 1.4885, 1.4902],
        [1.4445, 1.2012, 0.9902, 1.3459, 1.3777, 1.4976, 1.4193, 1.4953, 1.4953,
         1.4376, 1.5219, 1.3805, 1.6640, 1.4174, 1.8863, 1.4309, 1.3568, 1.7791,
         1.2307, 1.2670, 0.8616, 1.2216, 1.3927, 1.4890, 1.4487, 1.4892, 1.4892,
         1.4226, 1.1838, 1.5143, 1.4732, 1.2152, 1.5233, 1.4960, 1.5041, 1.4767,
         1.4935, 1.5869, 1.5682, 1.5073, 1.4332, 1.5510, 1.5604, 0.5940, 1.3951,
         0.9785, 1.5627, 1.5471, 1.5518, 1.1377, 1.5587, 0.7273, 1.5568, 1.5585],
        [1.3845, 1.3794, 1.3930, 1.3531, 1.2855, 1.3860, 1.2940, 1.3827, 1.3827,
         1.4563, 1.4263, 1.4702, 1.4448, 1.4536, 1.0882, 1.4597, 1.4026, 1.3325,
         1.6091, 1.6633, 1.7217, 1.6624, 1.5233, 1.5247, 1.5960, 1.5020, 1.5020,
         1.3440, 1.3515, 1.4166, 1.4276, 1.3337, 1.4259, 1.4230, 1.4199, 1.4182,
         1.4914, 1.5071, 1.5032, 1.4564, 1.5007, 1.5030, 1.4996, 1.1708, 1.2278,
         1.3335, 1.4655, 1.4627, 1.4450, 1.2675, 1.4626, 1.3116, 1.4488, 1.4519],
        [1.3892, 1.4010, 1.2654, 1.2036, 1.3854, 1.3753, 1.3859, 1.3877, 1.3877,
         1.4408, 1.3666, 1.3857, 1.3434, 1.4376, 1.3305, 1.4395, 1.4383, 1.1016,
         1.4312, 1.2479, 1.4463, 1.4287, 1.3933, 1.3720, 1.4212, 1.4118, 1.4118,
         1.6851, 1.5073, 1.4402, 1.4886, 1.6573, 1.4344, 1.6490, 1.4449, 1.4306,
         1.4646, 1.4192, 1.4004, 1.4286, 1.4608, 1.3370, 1.4333, 1.0994, 1.3469,
         1.4690, 1.3614, 1.2500, 1.3916, 1.4453, 1.2765, 1.4974, 1.3958, 1.4456],
        [1.5928, 1.3956, 0.5384, 0.7546, 1.2788, 1.5494, 1.4804, 1.5915, 1.5915,
         1.5917, 1.4692, 1.3802, 1.1183, 1.6293, 0.5388, 1.5048, 1.6291, 1.3188,
         1.3174, 1.0072, 1.0104, 1.2058, 1.5589, 1.5723, 1.2653, 1.6113, 1.6113,
         0.7611, 0.7785, 1.5867, 1.4185, 0.9206, 1.5812, 1.2034, 1.5928, 1.5670,
         1.2841, 1.1187, 1.0874, 1.2295, 1.4395, 1.4945, 1.2209, 2.0436, 1.9605,
         0.9618, 1.1858, 1.3045, 1.5868, 1.0988, 1.5372, 0.6093, 1.4997, 1.6425],
        [1.5408, 1.5346, 1.4830, 1.5271, 1.4469, 1.4867, 1.4912, 1.5388, 1.5388,
         1.4888, 1.4615, 1.4521, 1.4531, 1.5834, 1.2782, 1.4927, 1.5863, 1.4436,
         1.5581, 1.4771, 1.2767, 1.4527, 1.5430, 1.5419, 1.5035, 1.5463, 1.5463,
         1.5620, 1.3854, 1.6091, 1.3483, 1.4134, 1.3312, 1.5783, 1.4660, 1.6114,
         1.5955, 1.3862, 1.6060, 1.5732, 1.2775, 1.1940, 1.6026, 1.1652, 0.8109,
         2.0121, 1.6061, 1.7244, 1.7120, 1.6750, 1.2973, 2.0063, 1.6373, 1.2865]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 20 : 185.4207468205554
Test loss for epoch 20 : 185.2383344027249
Test Precision for epoch 20 : 0.26153846153846155
Test Recall for epoch 20 : 0.26153846153846155
Test F1 for epoch 20 : 0.26153846153846155


theta for epoch 21 : tensor([[1.6255, 1.7114, 1.8053, 1.7694, 1.7830, 1.6526, 1.6830, 1.6245, 1.6245,
         1.4790, 1.4841, 1.4930, 1.4648, 1.4744, 1.4481, 1.4819, 1.4786, 1.4404,
         1.3995, 1.3689, 1.4397, 1.4160, 1.4349, 1.4332, 1.4460, 1.4298, 1.4298,
         1.3801, 1.5241, 1.4599, 1.4814, 1.4926, 1.4755, 1.4603, 1.4184, 1.4627,
         1.5044, 1.5214, 1.5169, 1.5145, 1.5191, 1.4558, 1.5057, 1.4201, 1.4152,
         1.4780, 1.4791, 1.4793, 1.4643, 1.4974, 1.4762, 1.4112, 1.4704, 1.4723],
        [1.4372, 1.1919, 0.9857, 1.3400, 1.3709, 1.4917, 1.4119, 1.4889, 1.4889,
         1.4454, 1.5351, 1.3850, 1.6865, 1.4240, 1.9233, 1.4384, 1.3599, 1.8093,
         1.2333, 1.2733, 0.8617, 1.2257, 1.3983, 1.4971, 1.4569, 1.4969, 1.4969,
         1.4188, 1.1730, 1.5107, 1.4689, 1.2054, 1.5206, 1.4933, 1.5006, 1.4719,
         1.4946, 1.5932, 1.5732, 1.5094, 1.4323, 1.5560, 1.5649, 0.5840, 1.3936,
         0.9649, 1.5577, 1.5415, 1.5445, 1.1245, 1.5532, 0.7212, 1.5500, 1.5519],
        [1.3814, 1.3789, 1.3980, 1.3556, 1.2854, 1.3831, 1.2924, 1.3794, 1.3794,
         1.4599, 1.4306, 1.4753, 1.4517, 1.4567, 1.1018, 1.4638, 1.4055, 1.3384,
         1.6245, 1.6825, 1.7443, 1.6816, 1.5340, 1.5358, 1.6113, 1.5117, 1.5117,
         1.3421, 1.3511, 1.4134, 1.4260, 1.3320, 1.4237, 1.4211, 1.4173, 1.4153,
         1.4950, 1.5116, 1.5072, 1.4591, 1.5054, 1.5080, 1.5032, 1.1764, 1.2303,
         1.3309, 1.4612, 1.4581, 1.4383, 1.2656, 1.4579, 1.3140, 1.4428, 1.4459],
        [1.3732, 1.3868, 1.2526, 1.1900, 1.3711, 1.3597, 1.3711, 1.3715, 1.3715,
         1.4382, 1.3614, 1.3834, 1.3394, 1.4346, 1.3295, 1.4375, 1.4356, 1.0903,
         1.4308, 1.2462, 1.4498, 1.4294, 1.3905, 1.3677, 1.4204, 1.4088, 1.4088,
         1.7224, 1.5355, 1.4644, 1.5154, 1.6934, 1.4584, 1.6844, 1.4695, 1.4543,
         1.4636, 1.4167, 1.3966, 1.4261, 1.4607, 1.3330, 1.4308, 1.0940, 1.3459,
         1.4573, 1.3445, 1.2304, 1.3737, 1.4333, 1.2566, 1.4876, 1.3785, 1.4300],
        [1.6059, 1.4012, 0.5337, 0.7538, 1.2785, 1.5597, 1.4885, 1.6043, 1.6043,
         1.6060, 1.4790, 1.3881, 1.1190, 1.6449, 0.5323, 1.5165, 1.6447, 1.3247,
         1.3232, 1.0059, 1.0117, 1.2087, 1.5714, 1.5863, 1.2723, 1.6265, 1.6265,
         0.7527, 0.7715, 1.5965, 1.4219, 0.9169, 1.5914, 1.1973, 1.6039, 1.5764,
         1.2838, 1.1092, 1.0767, 1.2268, 1.4473, 1.5061, 1.2170, 2.0900, 2.0014,
         0.9593, 1.1866, 1.3077, 1.5976, 1.0935, 1.5464, 0.6014, 1.5084, 1.6557],
        [1.5202, 1.5169, 1.4740, 1.5127, 1.4312, 1.4661, 1.4711, 1.5180, 1.5180,
         1.4863, 1.4613, 1.4497, 1.4570, 1.5841, 1.2910, 1.4907, 1.5875, 1.4460,
         1.5626, 1.4848, 1.2893, 1.4584, 1.5457, 1.5439, 1.5052, 1.5478, 1.5478,
         1.5433, 1.3738, 1.5871, 1.3273, 1.3942, 1.3090, 1.5582, 1.4423, 1.5896,
         1.6001, 1.3804, 1.6109, 1.5780, 1.2689, 1.1826, 1.6071, 1.1764, 0.8113,
         2.0496, 1.6268, 1.7512, 1.7378, 1.6952, 1.3048, 2.0428, 1.6600, 1.2935]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 21 : 185.35180750461043
Test loss for epoch 21 : 185.16284996945697
Test Precision for epoch 21 : 0.26153846153846155
Test Recall for epoch 21 : 0.26153846153846155
Test F1 for epoch 21 : 0.26153846153846155


theta for epoch 22 : tensor([[1.6276, 1.7164, 1.8131, 1.7767, 1.7904, 1.6554, 1.6871, 1.6265, 1.6265,
         1.4751, 1.4814, 1.4906, 1.4639, 1.4700, 1.4517, 1.4785, 1.4747, 1.4396,
         1.4067, 1.3789, 1.4477, 1.4235, 1.4383, 1.4360, 1.4506, 1.4323, 1.4323,
         1.3747, 1.5167, 1.4484, 1.4713, 1.4861, 1.4649, 1.4509, 1.4075, 1.4514,
         1.5156, 1.5333, 1.5283, 1.5260, 1.5311, 1.4677, 1.5168, 1.4378, 1.4300,
         1.4734, 1.4709, 1.4704, 1.4531, 1.4923, 1.4677, 1.4120, 1.4598, 1.4618],
        [1.4324, 1.1861, 0.9853, 1.3373, 1.3672, 1.4880, 1.4071, 1.4849, 1.4849,
         1.4493, 1.5446, 1.3856, 1.7055, 1.4268, 1.9571, 1.4421, 1.3592, 1.8361,
         1.2310, 1.2745, 0.8585, 1.2249, 1.3983, 1.4991, 1.4592, 1.4985, 1.4985,
         1.4175, 1.1652, 1.5093, 1.4670, 1.1985, 1.5201, 1.4928, 1.4992, 1.4694,
         1.4997, 1.6032, 1.5818, 1.5154, 1.4356, 1.5648, 1.5731, 0.5789, 1.3963,
         0.9554, 1.5548, 1.5380, 1.5392, 1.1146, 1.5497, 0.7181, 1.5452, 1.5472],
        [1.3796, 1.3799, 1.4046, 1.3599, 1.2869, 1.3815, 1.2925, 1.3774, 1.3774,
         1.4527, 1.4242, 1.4696, 1.4479, 1.4489, 1.1063, 1.4570, 1.3977, 1.3339,
         1.6384, 1.7001, 1.7654, 1.6993, 1.5432, 1.5456, 1.6251, 1.5200, 1.5200,
         1.3421, 1.3525, 1.4117, 1.4259, 1.3322, 1.4230, 1.4208, 1.4162, 1.4138,
         1.5021, 1.5197, 1.5147, 1.4653, 1.5136, 1.5165, 1.5102, 1.1860, 1.2370,
         1.3303, 1.4582, 1.4546, 1.4327, 1.2659, 1.4544, 1.3185, 1.4379, 1.4411],
        [1.3555, 1.3708, 1.2382, 1.1748, 1.3552, 1.3422, 1.3546, 1.3535, 1.3535,
         1.4243, 1.3449, 1.3699, 1.3241, 1.4202, 1.3172, 1.4240, 1.4216, 1.0683,
         1.4198, 1.2340, 1.4425, 1.4194, 1.3771, 1.3528, 1.4089, 1.3952, 1.3952,
         1.7645, 1.5688, 1.4938, 1.5474, 1.7344, 1.4876, 1.7247, 1.4994, 1.4833,
         1.4638, 1.4156, 1.3941, 1.4249, 1.4619, 1.3304, 1.4295, 1.0896, 1.3462,
         1.4442, 1.3260, 1.2092, 1.3542, 1.4198, 1.2350, 1.4765, 1.3595, 1.4127],
        [1.6150, 1.4023, 0.5237, 0.7477, 1.2732, 1.5658, 1.4924, 1.6133, 1.6133,
         1.6094, 1.4777, 1.3851, 1.1088, 1.6496, 0.5153, 1.5174, 1.6495, 1.3196,
         1.3199, 0.9955, 1.0038, 1.2023, 1.5748, 1.5914, 1.2705, 1.6328, 1.6328,
         0.7400, 0.7601, 1.6035, 1.4221, 0.9090, 1.5987, 1.1876, 1.6123, 1.5830,
         1.2908, 1.1070, 1.0733, 1.2315, 1.4624, 1.5250, 1.2205, 2.1428, 2.0490,
         0.9510, 1.1828, 1.3063, 1.6042, 1.0830, 1.5515, 0.5875, 1.5130, 1.6650],
        [1.5083, 1.5083, 1.4750, 1.5076, 1.4255, 1.4549, 1.4603, 1.5059, 1.5059,
         1.4777, 1.4552, 1.4413, 1.4551, 1.5780, 1.2996, 1.4824, 1.5818, 1.4426,
         1.5641, 1.4906, 1.3020, 1.4623, 1.5455, 1.5429, 1.5043, 1.5464, 1.5464,
         1.5324, 1.3716, 1.5724, 1.3156, 1.3840, 1.2962, 1.5459, 1.4271, 1.5752,
         1.6118, 1.3831, 1.6228, 1.5901, 1.2696, 1.1813, 1.6185, 1.1969, 0.8230,
         2.0736, 1.6344, 1.7648, 1.7504, 1.7017, 1.3000, 2.0657, 1.6696, 1.2882]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 22 : 185.21863542667865
Test loss for epoch 22 : 185.03251666713757
Test Precision for epoch 22 : 0.26153846153846155
Test Recall for epoch 22 : 0.26153846153846155
Test F1 for epoch 22 : 0.26153846153846155


theta for epoch 23 : tensor([[1.6312, 1.7225, 1.8219, 1.7851, 1.7988, 1.6595, 1.6924, 1.6299, 1.6299,
         1.4652, 1.4727, 1.4822, 1.4571, 1.4596, 1.4491, 1.4691, 1.4646, 1.4327,
         1.4048, 1.3797, 1.4463, 1.4219, 1.4325, 1.4296, 1.4459, 1.4256, 1.4256,
         1.3703, 1.5101, 1.4376, 1.4619, 1.4804, 1.4549, 1.4422, 1.3975, 1.4408,
         1.5268, 1.5453, 1.5396, 1.5374, 1.5432, 1.4798, 1.5278, 1.4559, 1.4451,
         1.4750, 1.4689, 1.4677, 1.4480, 1.4933, 1.4655, 1.4193, 1.4552, 1.4574],
        [1.4317, 1.1850, 0.9897, 1.3388, 1.3677, 1.4884, 1.4064, 1.4849, 1.4849,
         1.4525, 1.5534, 1.3855, 1.7238, 1.4289, 1.9905, 1.4450, 1.3578, 1.8624,
         1.2209, 1.2678, 0.8487, 1.2164, 1.3901, 1.4926, 1.4531, 1.4916, 1.4916,
         1.4157, 1.1574, 1.5072, 1.4644, 1.1916, 1.5189, 1.4918, 1.4972, 1.4662,
         1.5043, 1.6125, 1.5899, 1.5208, 1.4387, 1.5732, 1.5807, 0.5741, 1.3989,
         0.9504, 1.5553, 1.5379, 1.5371, 1.1090, 1.5496, 0.7181, 1.5437, 1.5459],
        [1.3811, 1.3842, 1.4145, 1.3675, 1.2920, 1.3832, 1.2962, 1.3787, 1.3787,
         1.4384, 1.4108, 1.4568, 1.4370, 1.4341, 1.1046, 1.4431, 1.3830, 1.3225,
         1.6519, 1.7174, 1.7862, 1.7167, 1.5522, 1.5551, 1.6387, 1.5281, 1.5281,
         1.3410, 1.3530, 1.4087, 1.4246, 1.3315, 1.4210, 1.4192, 1.4139, 1.4111,
         1.5082, 1.5267, 1.5211, 1.4707, 1.5208, 1.5241, 1.5162, 1.1953, 1.2435,
         1.3331, 1.4583, 1.4544, 1.4302, 1.2698, 1.4542, 1.3266, 1.4362, 1.4394],
        [1.3456, 1.3628, 1.2321, 1.1683, 1.3472, 1.3328, 1.3460, 1.3435, 1.3435,
         1.4086, 1.3270, 1.3549, 1.3076, 1.4039, 1.3037, 1.4088, 1.4057, 1.0463,
         1.4046, 1.2190, 1.4309, 1.4053, 1.3598, 1.3342, 1.3933, 1.3777, 1.3777,
         1.8018, 1.5971, 1.5182, 1.5745, 1.7706, 1.5120, 1.7602, 1.5243, 1.5074,
         1.4664, 1.4172, 1.3942, 1.4261, 1.4656, 1.3310, 1.4308, 1.0891, 1.3496,
         1.4381, 1.3150, 1.1959, 1.3418, 1.4136, 1.2212, 1.4723, 1.3477, 1.4024],
        [1.6233, 1.4022, 0.5115, 0.7396, 1.2666, 1.5709, 1.4952, 1.6214, 1.6214,
         1.6059, 1.4694, 1.3752, 1.0916, 1.6474, 0.4912, 1.5113, 1.6472, 1.3075,
         1.3077, 0.9764, 0.9871, 1.1871, 1.5694, 1.5878, 1.2601, 1.6304, 1.6304,
         0.7223, 0.7438, 1.6065, 1.4181, 0.8962, 1.6021, 1.1734, 1.6168, 1.5856,
         1.3027, 1.1097, 1.0747, 1.2411, 1.4823, 1.5488, 1.2288, 2.2002, 2.1012,
         0.9400, 1.1777, 1.3037, 1.6098, 1.0706, 1.5555, 0.5707, 1.5165, 1.6733],
        [1.5063, 1.5097, 1.4862, 1.5125, 1.4304, 1.4540, 1.4598, 1.5037, 1.5037,
         1.4656, 1.4459, 1.4298, 1.4502, 1.5679, 1.3061, 1.4707, 1.5720, 1.4360,
         1.5586, 1.4899, 1.3096, 1.4600, 1.5384, 1.5351, 1.4966, 1.5380, 1.5380,
         1.5248, 1.3736, 1.5604, 1.3079, 1.3774, 1.2874, 1.5366, 1.4151, 1.5634,
         1.6249, 1.3883, 1.6361, 1.6037, 1.2734, 1.1835, 1.6313, 1.2206, 0.8392,
         2.0916, 1.6365, 1.7729, 1.7575, 1.7021, 1.2906, 2.0825, 1.6736, 1.2782]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 23 : 185.18314028300614
Test loss for epoch 23 : 185.00929245695457
Test Precision for epoch 23 : 0.26153846153846155
Test Recall for epoch 23 : 0.26153846153846155
Test F1 for epoch 23 : 0.26153846153846155


theta for epoch 24 : tensor([[1.6432, 1.7368, 1.8383, 1.8015, 1.8150, 1.6720, 1.7061, 1.6419, 1.6419,
         1.4541, 1.4627, 1.4726, 1.4491, 1.4481, 1.4452, 1.4585, 1.4534, 1.4247,
         1.3973, 1.3749, 1.4389, 1.4146, 1.4212, 1.4178, 1.4356, 1.4134, 1.4134,
         1.3624, 1.5000, 1.4229, 1.4489, 1.4712, 1.4412, 1.4298, 1.3836, 1.4263,
         1.5274, 1.5469, 1.5405, 1.5384, 1.5448, 1.4815, 1.5283, 1.4636, 1.4498,
         1.4803, 1.4707, 1.4689, 1.4468, 1.4981, 1.4672, 1.4301, 1.4546, 1.4569],
        [1.4325, 1.1856, 0.9955, 1.3417, 1.3698, 1.4901, 1.4072, 1.4862, 1.4862,
         1.4592, 1.5657, 1.3889, 1.7455, 1.4344, 2.0271, 1.4514, 1.3599, 1.8921,
         1.2067, 1.2569, 0.8352, 1.2037, 1.3776, 1.4816, 1.4425, 1.4803, 1.4803,
         1.4112, 1.1470, 1.5020, 1.4589, 1.1820, 1.5148, 1.4878, 1.4922, 1.4600,
         1.5007, 1.6136, 1.5897, 1.5180, 1.4336, 1.5732, 1.5799, 0.5624, 1.3933,
         0.9484, 1.5584, 1.5406, 1.5378, 1.1063, 1.5524, 0.7194, 1.5449, 1.5473],
        [1.3834, 1.3892, 1.4248, 1.3758, 1.2980, 1.3857, 1.3008, 1.3807, 1.3807,
         1.4229, 1.3963, 1.4427, 1.4249, 1.4180, 1.1019, 1.4280, 1.3671, 1.3100,
         1.6691, 1.7383, 1.8105, 1.7378, 1.5650, 1.5686, 1.6561, 1.5401, 1.5401,
         1.3368, 1.3504, 1.4021, 1.4197, 1.3276, 1.4155, 1.4141, 1.4080, 1.4047,
         1.5052, 1.5247, 1.5185, 1.4670, 1.5189, 1.5226, 1.5131, 1.1960, 1.2413,
         1.3385, 1.4611, 1.4568, 1.4304, 1.2766, 1.4566, 1.3374, 1.4371, 1.4404],
        [1.3485, 1.3673, 1.2394, 1.1756, 1.3519, 1.3362, 1.3501, 1.3461, 1.3461,
         1.4015, 1.3186, 1.3493, 1.3007, 1.3964, 1.2998, 1.4022, 1.3986, 1.0362,
         1.3972, 1.2142, 1.4269, 1.3990, 1.3509, 1.3241, 1.3856, 1.3681, 1.3681,
         1.8261, 1.6125, 1.5297, 1.5886, 1.7938, 1.5234, 1.7827, 1.5363, 1.5185,
         1.4677, 1.4180, 1.3938, 1.4265, 1.4682, 1.3317, 1.4310, 1.0907, 1.3530,
         1.4444, 1.3174, 1.1970, 1.3426, 1.4201, 1.2217, 1.4801, 1.3490, 1.4047],
        [1.6328, 1.4035, 0.5016, 0.7334, 1.2613, 1.5773, 1.4993, 1.6308, 1.6308,
         1.6021, 1.4608, 1.3653, 1.0746, 1.6449, 0.4670, 1.5051, 1.6447, 1.2955,
         1.2932, 0.9554, 0.9682, 1.1697, 1.5613, 1.5817, 1.2478, 1.6255, 1.6255,
         0.7031, 0.7257, 1.6066, 1.4114, 0.8814, 1.6027, 1.1570, 1.6185, 1.5853,
         1.3131, 1.1108, 1.0746, 1.2492, 1.5007, 1.5712, 1.2355, 2.2572, 2.1530,
         0.9312, 1.1763, 1.3046, 1.6180, 1.0613, 1.5622, 0.5565, 1.5229, 1.6841],
        [1.5083, 1.5149, 1.5011, 1.5213, 1.4395, 1.4573, 1.4632, 1.5055, 1.5055,
         1.4538, 1.4372, 1.4187, 1.4460, 1.5578, 1.3137, 1.4593, 1.5624, 1.4299,
         1.5489, 1.4853, 1.3136, 1.4538, 1.5272, 1.5232, 1.4848, 1.5256, 1.5256,
         1.5151, 1.3741, 1.5458, 1.2980, 1.3690, 1.2763, 1.5250, 1.4008, 1.5490,
         1.6286, 1.3844, 1.6401, 1.6082, 1.2685, 1.1773, 1.6348, 1.2359, 0.8475,
         2.1132, 1.6436, 1.7859, 1.7694, 1.7070, 1.2871, 2.1028, 1.6828, 1.2742]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 24 : 185.127040762291
Test loss for epoch 24 : 184.9688414644107
Test Precision for epoch 24 : 0.26153846153846155
Test Recall for epoch 24 : 0.26153846153846155
Test F1 for epoch 24 : 0.26153846153846155


theta for epoch 25 : tensor([[1.6594, 1.7549, 1.8584, 1.8217, 1.8350, 1.6886, 1.7238, 1.6580, 1.6580,
         1.4464, 1.4560, 1.4662, 1.4444, 1.4398, 1.4444, 1.4512, 1.4455, 1.4199,
         1.3910, 1.3710, 1.4323, 1.4083, 1.4110, 1.4070, 1.4263, 1.4023, 1.4023,
         1.3553, 1.4907, 1.4087, 1.4364, 1.4628, 1.4280, 1.4181, 1.3702, 1.4124,
         1.5148, 1.5352, 1.5281, 1.5261, 1.5331, 1.4699, 1.5156, 1.4578, 1.4412,
         1.4871, 1.4741, 1.4716, 1.4472, 1.5042, 1.4704, 1.4422, 1.4556, 1.4580],
        [1.4290, 1.1822, 0.9973, 1.3404, 1.3678, 1.4875, 1.4037, 1.4833, 1.4833,
         1.4707, 1.5827, 1.3971, 1.7719, 1.4448, 2.0680, 1.4627, 1.3669, 1.9263,
         1.1930, 1.2464, 0.8221, 1.1915, 1.3657, 1.4710, 1.4322, 1.4694, 1.4694,
         1.4063, 1.1364, 1.4961, 1.4529, 1.1722, 1.5099, 1.4835, 1.4865, 1.4531,
         1.4861, 1.6036, 1.5784, 1.5042, 1.4176, 1.5623, 1.5681, 0.5413, 1.3768,
         0.9468, 1.5618, 1.5435, 1.5387, 1.1040, 1.5553, 0.7201, 1.5463, 1.5488],
        [1.3805, 1.3890, 1.4298, 1.3791, 1.2989, 1.3830, 1.3005, 1.3776, 1.3776,
         1.4099, 1.3842, 1.4311, 1.4151, 1.4044, 1.1016, 1.4154, 1.3538, 1.2999,
         1.6918, 1.7645, 1.8398, 1.7641, 1.5835, 1.5878, 1.6790, 1.5578, 1.5578,
         1.3321, 1.3473, 1.3946, 1.4141, 1.3232, 1.4090, 1.4083, 1.4012, 1.3975,
         1.4903, 1.5109, 1.5041, 1.4515, 1.5052, 1.5092, 1.4981, 1.1855, 1.2279,
         1.3437, 1.4636, 1.4590, 1.4305, 1.2833, 1.4589, 1.3479, 1.4378, 1.4412],
        [1.3577, 1.3781, 1.2539, 1.1905, 1.3631, 1.3462, 1.3607, 1.3553, 1.3553,
         1.4047, 1.3210, 1.3545, 1.3049, 1.3992, 1.3069, 1.4060, 1.4018, 1.0390,
         1.4008, 1.2223, 1.4336, 1.4038, 1.3534, 1.3257, 1.3890, 1.3699, 1.3699,
         1.8406, 1.6183, 1.5317, 1.5930, 1.8074, 1.5252, 1.7955, 1.5387, 1.5200,
         1.4635, 1.4139, 1.3884, 1.4217, 1.4654, 1.3280, 1.4261, 1.0897, 1.3519,
         1.4594, 1.3296, 1.2084, 1.3527, 1.4356, 1.2324, 1.4965, 1.3596, 1.4160],
        [1.6418, 1.4049, 0.4945, 0.7294, 1.2564, 1.5831, 1.5031, 1.6395, 1.6395,
         1.6021, 1.4563, 1.3599, 1.0625, 1.6462, 0.4474, 1.5031, 1.6460, 1.2882,
         1.2822, 0.9385, 0.9529, 1.1558, 1.5562, 1.5787, 1.2394, 1.6234, 1.6234,
         0.6885, 0.7121, 1.6086, 1.4073, 0.8705, 1.6052, 1.1442, 1.6221, 1.5870,
         1.3177, 1.1063, 1.0690, 1.2517, 1.5135, 1.5880, 1.2365, 2.3104, 2.2008,
         0.9261, 1.1799, 1.3098, 1.6290, 1.0568, 1.5722, 0.5475, 1.5327, 1.6974],
        [1.5055, 1.5154, 1.5111, 1.5253, 1.4439, 1.4560, 1.4620, 1.5026, 1.5026,
         1.4448, 1.4316, 1.4105, 1.4450, 1.5504, 1.3244, 1.4506, 1.5553, 1.4268,
         1.5395, 1.4813, 1.3184, 1.4484, 1.5165, 1.5118, 1.4736, 1.5136, 1.5136,
         1.5058, 1.3752, 1.5311, 1.2881, 1.3607, 1.2649, 1.5136, 1.3863, 1.5346,
         1.6190, 1.3675, 1.6308, 1.5994, 1.2507, 1.1584, 1.6250, 1.2382, 0.8430,
         2.1409, 1.6585, 1.8064, 1.7887, 1.7188, 1.2920, 2.1292, 1.6997, 1.2785]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 25 : 184.98629700820078
Test loss for epoch 25 : 184.83991026409046
Test Precision for epoch 25 : 0.26153846153846155
Test Recall for epoch 25 : 0.26153846153846155
Test F1 for epoch 25 : 0.26153846153846155


theta for epoch 26 : tensor([[1.6716, 1.7689, 1.8741, 1.8377, 1.8507, 1.7010, 1.7374, 1.6700, 1.6700,
         1.4430, 1.4537, 1.4643, 1.4443, 1.4360, 1.4480, 1.4483, 1.4421, 1.4196,
         1.3885, 1.3710, 1.4291, 1.4058, 1.4045, 1.4000, 1.4206, 1.3950, 1.3950,
         1.3549, 1.4880, 1.4010, 1.4304, 1.4608, 1.4213, 1.4131, 1.3634, 1.4051,
         1.4974, 1.5187, 1.5110, 1.5089, 1.5166, 1.4537, 1.4981, 1.4474, 1.4280,
         1.4887, 1.4725, 1.4694, 1.4428, 1.5052, 1.4687, 1.4493, 1.4516, 1.4543],
        [1.4168, 1.1709, 0.9916, 1.3304, 1.3571, 1.4760, 1.3914, 1.4714, 1.4714,
         1.4845, 1.6021, 1.4078, 1.8005, 1.4575, 2.1110, 1.4763, 1.3764, 1.9627,
         1.1825, 1.2389, 0.8125, 1.1824, 1.3567, 1.4631, 1.4247, 1.4611, 1.4611,
         1.4051, 1.1298, 1.4936, 1.4503, 1.1663, 1.5084, 1.4826, 1.4842, 1.4497,
         1.4673, 1.5894, 1.5628, 1.4863, 1.3978, 1.5471, 1.5520, 0.5176, 1.3565,
         0.9418, 1.5602, 1.5416, 1.5347, 1.0977, 1.5534, 0.7172, 1.5428, 1.5454],
        [1.3681, 1.3792, 1.4250, 1.3729, 1.2905, 1.3708, 1.2910, 1.3650, 1.3650,
         1.4009, 1.3764, 1.4235, 1.4094, 1.3949, 1.1057, 1.4068, 1.3447, 1.2940,
         1.7166, 1.7929, 1.8713, 1.7927, 1.6045, 1.6095, 1.7043, 1.5781, 1.5781,
         1.3315, 1.3481, 1.3907, 1.4121, 1.3229, 1.4062, 1.4061, 1.3980, 1.3939,
         1.4711, 1.4927, 1.4853, 1.4318, 1.4870, 1.4915, 1.4788, 1.1715, 1.2109,
         1.3434, 1.4605, 1.4555, 1.4249, 1.2849, 1.4555, 1.3531, 1.4329, 1.4364],
        [1.3619, 1.3837, 1.2639, 1.2013, 1.3692, 1.3511, 1.3661, 1.3593, 1.3593,
         1.4125, 1.3282, 1.3645, 1.3140, 1.4064, 1.3188, 1.4143, 1.4095, 1.0472,
         1.4090, 1.2356, 1.4446, 1.4130, 1.3607, 1.3322, 1.3971, 1.3762, 1.3762,
         1.8548, 1.6238, 1.5334, 1.5972, 1.8206, 1.5269, 1.8079, 1.5409, 1.5214,
         1.4561, 1.4067, 1.3800, 1.4137, 1.4594, 1.3216, 1.4179, 1.0866, 1.3481,
         1.4724, 1.3401, 1.2187, 1.3610, 1.4491, 1.2418, 1.5106, 1.3684, 1.4254],
        [1.6448, 1.4010, 0.4862, 0.7231, 1.2466, 1.5829, 1.5013, 1.6424, 1.6424,
         1.6056, 1.4553, 1.3586, 1.0548, 1.6508, 0.4320, 1.5047, 1.6506, 1.2849,
         1.2747, 0.9257, 0.9414, 1.1456, 1.5540, 1.5788, 1.2348, 1.6243, 1.6243,
         0.6811, 0.7055, 1.6152, 1.4086, 0.8660, 1.6124, 1.1380, 1.6304, 1.5935,
         1.3190, 1.0986, 1.0601, 1.2509, 1.5228, 1.6016, 1.2343, 2.3617, 2.2464,
         0.9197, 1.1823, 1.3132, 1.6368, 1.0510, 1.5793, 0.5386, 1.5399, 1.7076],
        [1.4920, 1.5049, 1.5099, 1.5183, 1.4375, 1.4440, 1.4499, 1.4888, 1.4888,
         1.4397, 1.4301, 1.4063, 1.4482, 1.5464, 1.3394, 1.4458, 1.5518, 1.4276,
         1.5328, 1.4805, 1.3267, 1.4464, 1.5087, 1.5032, 1.4652, 1.5045, 1.5045,
         1.5020, 1.3822, 1.5217, 1.2839, 1.3579, 1.2590, 1.5078, 1.3774, 1.5256,
         1.6040, 1.3457, 1.6161, 1.5852, 1.2281, 1.1349, 1.6097, 1.2359, 0.8339,
         2.1681, 1.6738, 1.8272, 1.8083, 1.7304, 1.2977, 2.1550, 1.7170, 1.2837]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 26 : 184.91820737462703
Test loss for epoch 26 : 184.7797918392971
Test Precision for epoch 26 : 0.26153846153846155
Test Recall for epoch 26 : 0.26153846153846155
Test F1 for epoch 26 : 0.26153846153846155


theta for epoch 27 : tensor([[1.6818, 1.7807, 1.8875, 1.8517, 1.8642, 1.7114, 1.7490, 1.6802, 1.6802,
         1.4400, 1.4518, 1.4626, 1.4446, 1.4326, 1.4520, 1.4458, 1.4390, 1.4196,
         1.3863, 1.3710, 1.4258, 1.4035, 1.3981, 1.3931, 1.4150, 1.3878, 1.3878,
         1.3611, 1.4916, 1.4003, 1.4312, 1.4654, 1.4213, 1.4149, 1.3635, 1.4046,
         1.4821, 1.5043, 1.4960, 1.4939, 1.5022, 1.4397, 1.4828, 1.4394, 1.4173,
         1.4785, 1.4591, 1.4554, 1.4267, 1.4942, 1.4551, 1.4443, 1.4360, 1.4388],
        [1.4016, 1.1579, 0.9848, 1.3178, 1.3439, 1.4612, 1.3763, 1.4563, 1.4563,
         1.4958, 1.6189, 1.4161, 1.8266, 1.4678, 2.1516, 1.4875, 1.3834, 1.9968,
         1.1761, 1.2353, 0.8084, 1.1774, 1.3511, 1.4578, 1.4200, 1.4554, 1.4554,
         1.4101, 1.1302, 1.4969, 1.4537, 1.1674, 1.5127, 1.4876, 1.4877, 1.4522,
         1.4520, 1.5782, 1.5504, 1.4718, 1.3818, 1.5353, 1.5391, 0.4991, 1.3402,
         0.9325, 1.5511, 1.5322, 1.5232, 1.0862, 1.5439, 0.7107, 1.5318, 1.5346],
        [1.3528, 1.3665, 1.4169, 1.3638, 1.2796, 1.3556, 1.2792, 1.3496, 1.3496,
         1.3955, 1.3723, 1.4195, 1.4074, 1.3890, 1.1146, 1.4018, 1.3395, 1.2921,
         1.7375, 1.8173, 1.8986, 1.8173, 1.6216, 1.6274, 1.7256, 1.5946, 1.5946,
         1.3379, 1.3559, 1.3935, 1.4166, 1.3297, 1.4100, 1.4106, 1.4014, 1.3969,
         1.4558, 1.4784, 1.4704, 1.4162, 1.4728, 1.4776, 1.4633, 1.1626, 1.1991,
         1.3356, 1.4492, 1.4439, 1.4114, 1.2793, 1.4440, 1.3508, 1.4200, 1.4236],
        [1.3580, 1.3813, 1.2659, 1.2042, 1.3673, 1.3480, 1.3635, 1.3552, 1.3552,
         1.4177, 1.3328, 1.3720, 1.3205, 1.4112, 1.3279, 1.4201, 1.4147, 1.0527,
         1.4136, 1.2453, 1.4520, 1.4187, 1.3644, 1.3350, 1.4015, 1.3790, 1.3790,
         1.8753, 1.6358, 1.5417, 1.6079, 1.8401, 1.5352, 1.8267, 1.5497, 1.5294,
         1.4484, 1.3994, 1.3714, 1.4055, 1.4532, 1.3152, 1.4096, 1.0831, 1.3441,
         1.4745, 1.3399, 1.2185, 1.3585, 1.4519, 1.2407, 1.5139, 1.3665, 1.4239],
        [1.6425, 1.3922, 0.4754, 0.7136, 1.2320, 1.5774, 1.4944, 1.6399, 1.6399,
         1.6090, 1.4545, 1.3576, 1.0476, 1.6553, 0.4172, 1.5066, 1.6552, 1.2820,
         1.2675, 0.9134, 0.9302, 1.1356, 1.5518, 1.5788, 1.2308, 1.6252, 1.6252,
         0.6789, 0.7041, 1.6257, 1.4144, 0.8664, 1.6234, 1.1372, 1.6427, 1.6040,
         1.3211, 1.0918, 1.0523, 1.2511, 1.5330, 1.6160, 1.2328, 2.4145, 2.2934,
         0.9057, 1.1769, 1.3082, 1.6355, 1.0374, 1.5774, 0.5236, 1.5381, 1.7086],
        [1.4726, 1.4884, 1.5024, 1.5051, 1.4253, 1.4263, 1.4320, 1.4693, 1.4693,
         1.4360, 1.4302, 1.4036, 1.4530, 1.5435, 1.3562, 1.4424, 1.5493, 1.4299,
         1.5273, 1.4812, 1.3370, 1.4460, 1.5020, 1.4958, 1.4582, 1.4965, 1.4965,
         1.5055, 1.3966, 1.5198, 1.2875, 1.3626, 1.2610, 1.5094, 1.3761, 1.5239,
         1.5914, 1.3269, 1.6038, 1.5737, 1.2090, 1.1152, 1.5969, 1.2369, 0.8286,
         2.1886, 1.6828, 1.8417, 1.8216, 1.7351, 1.2977, 2.1740, 1.7281, 1.2831]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 27 : 184.87070643394912
Test loss for epoch 27 : 184.7387711110337
Test Precision for epoch 27 : 0.26153846153846155
Test Recall for epoch 27 : 0.26153846153846155
Test F1 for epoch 27 : 0.26153846153846155


theta for epoch 28 : tensor([[1.6959, 1.7962, 1.9042, 1.8691, 1.8811, 1.7255, 1.7644, 1.6942, 1.6942,
         1.4314, 1.4440, 1.4553, 1.4392, 1.4234, 1.4501, 1.4375, 1.4302, 1.4137,
         1.3795, 1.3662, 1.4179, 1.3965, 1.3871, 1.3815, 1.4047, 1.3760, 1.3760,
         1.3677, 1.4954, 1.4002, 1.4324, 1.4701, 1.4218, 1.4172, 1.3642, 1.4048,
         1.4714, 1.4944, 1.4854, 1.4834, 1.4923, 1.4302, 1.4719, 1.4360, 1.4113,
         1.4611, 1.4386, 1.4344, 1.4039, 1.4761, 1.4346, 1.4320, 1.4135, 1.4165],
        [1.3920, 1.1520, 0.9855, 1.3112, 1.3366, 1.4515, 1.3669, 1.4464, 1.4464,
         1.5005, 1.6289, 1.4177, 1.8458, 1.4715, 2.1858, 1.4920, 1.3840, 2.0242,
         1.1731, 1.2346, 0.8098, 1.1758, 1.3477, 1.4540, 1.4173, 1.4513, 1.4513,
         1.4191, 1.1362, 1.5041, 1.4610, 1.1738, 1.5206, 1.4965, 1.4950, 1.4589,
         1.4440, 1.5737, 1.5446, 1.4643, 1.3735, 1.5302, 1.5329, 0.4904, 1.3317,
         0.9262, 1.5410, 1.5218, 1.5108, 1.0767, 1.5335, 0.7072, 1.5199, 1.5229],
        [1.3436, 1.3599, 1.4145, 1.3608, 1.2756, 1.3466, 1.2742, 1.3403, 1.3403,
         1.3907, 1.3690, 1.4159, 1.4060, 1.3836, 1.1258, 1.3973, 1.3351, 1.2913,
         1.7498, 1.8330, 1.9173, 1.8333, 1.6304, 1.6371, 1.7386, 1.6029, 1.6029,
         1.3492, 1.3685, 1.4008, 1.4256, 1.3415, 1.4181, 1.4196, 1.4094, 1.4045,
         1.4481, 1.4717, 1.4631, 1.4085, 1.4662, 1.4713, 1.4554, 1.1626, 1.1963,
         1.3284, 1.4374, 1.4318, 1.3977, 1.2749, 1.4321, 1.3490, 1.4069, 1.4106],
        [1.3498, 1.3745, 1.2632, 1.2025, 1.3610, 1.3406, 1.3566, 1.3469, 1.3469,
         1.4154, 1.3298, 1.3720, 1.3195, 1.4084, 1.3294, 1.4184, 1.4124, 1.0505,
         1.4102, 1.2467, 1.4513, 1.4162, 1.3601, 1.3296, 1.3978, 1.3737, 1.3737,
         1.9021, 1.6546, 1.5569, 1.6254, 1.8662, 1.5502, 1.8520, 1.5653, 1.5442,
         1.4421, 1.3934, 1.3641, 1.3985, 1.4483, 1.3101, 1.4026, 1.0803, 1.3413,
         1.4686, 1.3317, 1.2102, 1.3481, 1.4466, 1.2315, 1.5090, 1.3565, 1.4144],
        [1.6390, 1.3824, 0.4646, 0.7037, 1.2166, 1.5706, 1.4863, 1.6363, 1.6363,
         1.6087, 1.4499, 1.3532, 1.0373, 1.6561, 0.3995, 1.5049, 1.6559, 1.2757,
         1.2578, 0.8988, 0.9165, 1.1231, 1.5467, 1.5761, 1.2245, 1.6232, 1.6232,
         0.6777, 0.7035, 1.6360, 1.4202, 0.8672, 1.6343, 1.1371, 1.6547, 1.6143,
         1.3257, 1.0876, 1.0471, 1.2537, 1.5455, 1.6328, 1.2339, 2.4699, 2.3430,
         0.8869, 1.1667, 1.2982, 1.6285, 1.0190, 1.5698, 0.5046, 1.5310, 1.7040],
        [1.4533, 1.4719, 1.4944, 1.4917, 1.4131, 1.4090, 1.4143, 1.4499, 1.4499,
         1.4271, 1.4254, 1.3959, 1.4528, 1.5354, 1.3683, 1.4339, 1.5415, 1.4268,
         1.5176, 1.4778, 1.3434, 1.4416, 1.4911, 1.4842, 1.4470, 1.4843, 1.4843,
         1.5100, 1.4122, 1.5191, 1.2925, 1.3683, 1.2643, 1.5122, 1.3762, 1.5234,
         1.5833, 1.3131, 1.5959, 1.5667, 1.1951, 1.1009, 1.5885, 1.2429, 0.8284,
         2.2077, 1.6912, 1.8556, 1.8342, 1.7386, 1.2974, 2.1915, 1.7386, 1.2824]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 28 : 184.80126732845127
Test loss for epoch 28 : 184.67238794939018
Test Precision for epoch 28 : 0.26153846153846155
Test Recall for epoch 28 : 0.26153846153846155
Test F1 for epoch 28 : 0.26153846153846155


theta for epoch 29 : tensor([[1.7121, 1.8135, 1.9225, 1.8883, 1.8996, 1.7417, 1.7818, 1.7103, 1.7103,
         1.4182, 1.4317, 1.4434, 1.4292, 1.4098, 1.4435, 1.4247, 1.4169, 1.4032,
         1.3714, 1.3600, 1.4085, 1.3882, 1.3748, 1.3686, 1.3930, 1.3629, 1.3629,
         1.3643, 1.4893, 1.3908, 1.4240, 1.4649, 1.4128, 1.4099, 1.3555, 1.3955,
         1.4660, 1.4899, 1.4802, 1.4782, 1.4877, 1.4262, 1.4664, 1.4382, 1.4109,
         1.4466, 1.4211, 1.4162, 1.3841, 1.4608, 1.4170, 1.4224, 1.3941, 1.3974],
        [1.3893, 1.1542, 0.9940, 1.3118, 1.3366, 1.4484, 1.3645, 1.4430, 1.4430,
         1.5001, 1.6338, 1.4144, 1.8599, 1.4701, 2.2152, 1.4915, 1.3796, 2.0467,
         1.1736, 1.2370, 0.8161, 1.1777, 1.3470, 1.4523, 1.4167, 1.4493, 1.4493,
         1.4236, 1.1389, 1.5064, 1.4637, 1.1767, 1.5237, 1.5006, 1.4974, 1.4609,
         1.4423, 1.5752, 1.5449, 1.4632, 1.3719, 1.5313, 1.5327, 0.4898, 1.3302,
         0.9277, 1.5357, 1.5164, 1.5035, 1.0744, 1.5280, 0.7102, 1.5129, 1.5162],
        [1.3416, 1.3602, 1.4186, 1.3648, 1.2788, 1.3447, 1.2768, 1.3381, 1.3381,
         1.3848, 1.3648, 1.4112, 1.4034, 1.3771, 1.1372, 1.3918, 1.3300, 1.2899,
         1.7569, 1.8436, 1.9306, 1.8442, 1.6342, 1.6418, 1.7465, 1.6062, 1.6062,
         1.3558, 1.3762, 1.4032, 1.4294, 1.3487, 1.4212, 1.4234, 1.4123, 1.4071,
         1.4471, 1.4717, 1.4624, 1.4077, 1.4663, 1.4715, 1.4542, 1.1703, 1.2013,
         1.3278, 1.4315, 1.4256, 1.3902, 1.2772, 1.4261, 1.3535, 1.3998, 1.4037],
        [1.3414, 1.3675, 1.2599, 1.2004, 1.3545, 1.3329, 1.3493, 1.3383, 1.3383,
         1.4073, 1.3209, 1.3663, 1.3126, 1.3999, 1.3249, 1.4108, 1.4043, 1.0426,
         1.4025, 1.2438, 1.4462, 1.4094, 1.3515, 1.3199, 1.3899, 1.3641, 1.3641,
         1.9303, 1.6748, 1.5734, 1.6442, 1.8935, 1.5667, 1.8786, 1.5823, 1.5605,
         1.4385, 1.3903, 1.3598, 1.3944, 1.4462, 1.3080, 1.3985, 1.0801, 1.3414,
         1.4617, 1.3227, 1.2012, 1.3368, 1.4405, 1.2216, 1.5031, 1.3457, 1.4042],
        [1.6372, 1.3748, 0.4568, 0.6965, 1.2035, 1.5655, 1.4802, 1.6343, 1.6343,
         1.6053, 1.4423, 1.3462, 1.0247, 1.6537, 0.3802, 1.5003, 1.6535, 1.2669,
         1.2476, 0.8841, 0.9023, 1.1101, 1.5406, 1.5726, 1.2179, 1.6203, 1.6203,
         0.6713, 0.6976, 1.6386, 1.4186, 0.8623, 1.6373, 1.1304, 1.6589, 1.6170,
         1.3317, 1.0850, 1.0435, 1.2578, 1.5593, 1.6509, 1.2364, 2.5269, 2.3943,
         0.8696, 1.1590, 1.2900, 1.6225, 1.0028, 1.5635, 0.4879, 1.5253, 1.7003],
        [1.4359, 1.4573, 1.4877, 1.4799, 1.4028, 1.3936, 1.3984, 1.4324, 1.4324,
         1.4120, 1.4142, 1.3818, 1.4462, 1.5209, 1.3738, 1.4191, 1.5275, 1.4171,
         1.5043, 1.4708, 1.3460, 1.4338, 1.4767, 1.4691, 1.4323, 1.4687, 1.4687,
         1.5030, 1.4164, 1.5074, 1.2865, 1.3626, 1.2567, 1.5038, 1.3654, 1.5120,
         1.5789, 1.3034, 1.5918, 1.5636, 1.1856, 1.0909, 1.5838, 1.2529, 0.8319,
         2.2317, 1.7060, 1.8758, 1.8530, 1.7479, 1.3043, 2.2139, 1.7556, 1.2889]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 29 : 184.73589299902375
Test loss for epoch 29 : 184.60685857145236
Test Precision for epoch 29 : 0.26153846153846155
Test Recall for epoch 29 : 0.26153846153846155
Test F1 for epoch 29 : 0.26153846153846155


theta for epoch 30 : tensor([[1.7236, 1.8259, 1.9357, 1.9026, 1.9132, 1.7531, 1.7944, 1.7218, 1.7218,
         1.4074, 1.4217, 1.4338, 1.4215, 1.3986, 1.4391, 1.4143, 1.4061, 1.3949,
         1.3690, 1.3593, 1.4044, 1.3855, 1.3682, 1.3615, 1.3869, 1.3556, 1.3556,
         1.3482, 1.4701, 1.3689, 1.4030, 1.4466, 1.3912, 1.3899, 1.3344, 1.3738,
         1.4657, 1.4905, 1.4801, 1.4781, 1.4882, 1.4275, 1.4659, 1.4457, 1.4159,
         1.4399, 1.4115, 1.4062, 1.3727, 1.4532, 1.4073, 1.4203, 1.3830, 1.3865],
        [1.3879, 1.1579, 1.0037, 1.3137, 1.3380, 1.4466, 1.3634, 1.4410, 1.4410,
         1.5011, 1.6400, 1.4126, 1.8753, 1.4702, 2.2458, 1.4924, 1.3767, 2.0706,
         1.1760, 1.2411, 0.8243, 1.1813, 1.3480, 1.4521, 1.4177, 1.4488, 1.4488,
         1.4165, 1.1306, 1.4973, 1.4550, 1.1686, 1.5151, 1.4932, 1.4884, 1.4515,
         1.4431, 1.5789, 1.5475, 1.4645, 1.3731, 1.5348, 1.5348, 0.4917, 1.3315,
         0.9325, 1.5334, 1.5140, 1.4992, 1.0754, 1.5253, 0.7154, 1.5090, 1.5125],
        [1.3408, 1.3618, 1.4237, 1.3700, 1.2835, 1.3440, 1.2808, 1.3372, 1.3372,
         1.3785, 1.3602, 1.4061, 1.4003, 1.3704, 1.1483, 1.3858, 1.3246, 1.2879,
         1.7662, 1.8562, 1.9459, 1.8571, 1.6405, 1.6490, 1.7567, 1.6121, 1.6121,
         1.3504, 1.3717, 1.3934, 1.4210, 1.3437, 1.4121, 1.4151, 1.4030, 1.3976,
         1.4488, 1.4742, 1.4643, 1.4097, 1.4689, 1.4744, 1.4555, 1.1808, 1.2095,
         1.3306, 1.4292, 1.4229, 1.3863, 1.2832, 1.4235, 1.3613, 1.3963, 1.4004],
        [1.3342, 1.3616, 1.2577, 1.1994, 1.3491, 1.3265, 1.3433, 1.3310, 1.3310,
         1.3986, 1.3116, 1.3601, 1.3054, 1.3908, 1.3197, 1.4028, 1.3956, 1.0346,
         1.3961, 1.2423, 1.4421, 1.4040, 1.3444, 1.3119, 1.3833, 1.3560, 1.3560,
         1.9552, 1.6918, 1.5868, 1.6599, 1.9177, 1.5800, 1.9020, 1.5961, 1.5735,
         1.4377, 1.3901, 1.3583, 1.3931, 1.4469, 1.3090, 1.3972, 1.0828, 1.3443,
         1.4573, 1.3164, 1.1949, 1.3283, 1.4368, 1.2144, 1.4994, 1.3376, 1.3966],
        [1.6377, 1.3703, 0.4540, 0.6937, 1.1940, 1.5628, 1.4769, 1.6348, 1.6348,
         1.6028, 1.4358, 1.3408, 1.0142, 1.6520, 0.3633, 1.4970, 1.6519, 1.2597,
         1.2408, 0.8734, 0.8916, 1.1006, 1.5373, 1.5718, 1.2150, 1.6200, 1.6200,
         0.6582, 0.6847, 1.6306, 1.4068, 0.8496, 1.6298, 1.1147, 1.6526, 1.6093,
         1.3364, 1.0813, 1.0389, 1.2608, 1.5716, 1.6676, 1.2377, 2.5835, 2.4450,
         0.8575, 1.1571, 1.2872, 1.6205, 0.9925, 1.5615, 0.4771, 1.5241, 1.7004],
        [1.4211, 1.4450, 1.4832, 1.4705, 1.3950, 1.3810, 1.3850, 1.4175, 1.4175,
         1.3966, 1.4028, 1.3675, 1.4393, 1.5059, 1.3789, 1.4040, 1.5128, 1.4069,
         1.4931, 1.4661, 1.3510, 1.4284, 1.4646, 1.4563, 1.4199, 1.4553, 1.4553,
         1.4812, 1.4055, 1.4813, 1.2659, 1.3422, 1.2346, 1.4807, 1.3402, 1.4860,
         1.5773, 1.2969, 1.5904, 1.5633, 1.1795, 1.0845, 1.5818, 1.2660, 0.8385,
         2.2585, 1.7249, 1.8998, 1.8756, 1.7606, 1.3158, 2.2390, 1.7766, 1.3000]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 30 : 184.6581470102914
Test loss for epoch 30 : 184.5301375869305
Test Precision for epoch 30 : 0.26153846153846155
Test Recall for epoch 30 : 0.26153846153846155
Test F1 for epoch 30 : 0.26153846153846155


theta for epoch 31 : tensor([[1.7279, 1.8308, 1.9412, 1.9094, 1.9191, 1.7571, 1.7996, 1.7259, 1.7259,
         1.4017, 1.4167, 1.4292, 1.4188, 1.3926, 1.4393, 1.4090, 1.4003, 1.3914,
         1.3722, 1.3639, 1.4053, 1.3881, 1.3672, 1.3601, 1.3864, 1.3541, 1.3541,
         1.3294, 1.4480, 1.3445, 1.3794, 1.4253, 1.3670, 1.3673, 1.3110, 1.3497,
         1.4668, 1.4924, 1.4814, 1.4793, 1.4901, 1.4304, 1.4669, 1.4547, 1.4226,
         1.4380, 1.4070, 1.4010, 1.3663, 1.4503, 1.4026, 1.4230, 1.3769, 1.3806],
        [1.3820, 1.1567, 1.0078, 1.3108, 1.3350, 1.4404, 1.3578, 1.4346, 1.4346,
         1.5079, 1.6521, 1.4168, 1.8964, 1.4762, 2.2817, 1.4992, 1.3798, 2.1000,
         1.1759, 1.2425, 0.8291, 1.1824, 1.3470, 1.4498, 1.4164, 1.4462, 1.4462,
         1.4026, 1.1153, 1.4815, 1.4394, 1.1536, 1.4999, 1.4790, 1.4725, 1.4353,
         1.4414, 1.5802, 1.5475, 1.4633, 1.3719, 1.5358, 1.5344, 0.4903, 1.3303,
         0.9336, 1.5283, 1.5087, 1.4922, 1.0728, 1.5199, 0.7163, 1.5023, 1.5060],
        [1.3359, 1.3591, 1.4244, 1.3710, 1.2839, 1.3392, 1.2807, 1.3322, 1.3322,
         1.3714, 1.3549, 1.4002, 1.3962, 1.3629, 1.1581, 1.3791, 1.3186, 1.2848,
         1.7813, 1.8744, 1.9667, 1.8757, 1.6527, 1.6622, 1.7728, 1.6239, 1.6239,
         1.3382, 1.3603, 1.3770, 1.4058, 1.3320, 1.3962, 1.4000, 1.3870, 1.3814,
         1.4481, 1.4745, 1.4639, 1.4093, 1.4693, 1.4750, 1.4546, 1.1892, 1.2157,
         1.3306, 1.4242, 1.4175, 1.3798, 1.2863, 1.4184, 1.3662, 1.3903, 1.3945],
        [1.3267, 1.3553, 1.2553, 1.1982, 1.3435, 1.3198, 1.3370, 1.3234, 1.3234,
         1.3915, 1.3040, 1.3555, 1.2997, 1.3833, 1.3158, 1.3962, 1.3885, 1.0285,
         1.3912, 1.2424, 1.4391, 1.3999, 1.3391, 1.3056, 1.3783, 1.3497, 1.3497,
         1.9788, 1.7074, 1.5988, 1.6742, 1.9405, 1.5920, 1.9241, 1.6087, 1.5853,
         1.4363, 1.3897, 1.3565, 1.3914, 1.4471, 1.3100, 1.3955, 1.0855, 1.3470,
         1.4534, 1.3109, 1.1895, 1.3206, 1.4338, 1.2082, 1.4962, 1.3302, 1.3897],
        [1.6398, 1.3683, 0.4564, 0.6954, 1.1876, 1.5618, 1.4756, 1.6367, 1.6367,
         1.6032, 1.4327, 1.3395, 1.0083, 1.6533, 0.3516, 1.4972, 1.6532, 1.2565,
         1.2382, 0.8678, 0.8852, 1.0956, 1.5374, 1.5744, 1.2165, 1.6230, 1.6230,
         0.6464, 0.6730, 1.6201, 1.3932, 0.8373, 1.6197, 1.0987, 1.6436, 1.5990,
         1.3371, 1.0740, 1.0307, 1.2599, 1.5799, 1.6803, 1.2351, 2.6375, 2.4929,
         0.8499, 1.1599, 1.2886, 1.6209, 0.9874, 1.5623, 0.4720, 1.5260, 1.7028],
        [1.4099, 1.4361, 1.4817, 1.4645, 1.3909, 1.3722, 1.3753, 1.4062, 1.4062,
         1.3864, 1.3967, 1.3586, 1.4374, 1.4955, 1.3888, 1.3940, 1.5028, 1.4015,
         1.4872, 1.4668, 1.3618, 1.4288, 1.4580, 1.4491, 1.4134, 1.4477, 1.4477,
         1.4566, 1.3919, 1.4524, 1.2433, 1.3191, 1.2104, 1.4548, 1.3128, 1.4573,
         1.5764, 1.2924, 1.5898, 1.5639, 1.1757, 1.0809, 1.5806, 1.2809, 0.8480,
         2.2789, 1.7383, 1.9182, 1.8926, 1.7672, 1.3226, 2.2577, 1.7922, 1.3064]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 31 : 184.59751793039246
Test loss for epoch 31 : 184.47413717453915
Test Precision for epoch 31 : 0.26153846153846155
Test Recall for epoch 31 : 0.26153846153846155
Test F1 for epoch 31 : 0.26153846153846155


theta for epoch 32 : tensor([[1.7317, 1.8350, 1.9459, 1.9155, 1.9243, 1.7606, 1.8044, 1.7297, 1.7297,
         1.3979, 1.4134, 1.4263, 1.4178, 1.3885, 1.4408, 1.4055, 1.3964, 1.3896,
         1.3736, 1.3665, 1.4042, 1.3890, 1.3649, 1.3574, 1.3843, 1.3513, 1.3513,
         1.3164, 1.4314, 1.3262, 1.3616, 1.4097, 1.3488, 1.3507, 1.2935, 1.3315,
         1.4640, 1.4906, 1.4788, 1.4767, 1.4881, 1.4295, 1.4640, 1.4598, 1.4255,
         1.4360, 1.4024, 1.3959, 1.3601, 1.4473, 1.3978, 1.4253, 1.3709, 1.3748],
        [1.3729, 1.1518, 1.0075, 1.3042, 1.3285, 1.4311, 1.3488, 1.4250, 1.4250,
         1.5197, 1.6689, 1.4259, 1.9221, 1.4871, 2.3219, 1.5110, 1.3879, 2.1340,
         1.1705, 1.2384, 0.8280, 1.1780, 1.3410, 1.4425, 1.4101, 1.4387, 1.4387,
         1.3893, 1.1005, 1.4665, 1.4248, 1.1391, 1.4854, 1.4657, 1.4575, 1.4200,
         1.4345, 1.5762, 1.5422, 1.4568, 1.3656, 1.5316, 1.5287, 0.4834, 1.3241,
         0.9299, 1.5192, 1.4995, 1.4812, 1.0657, 1.5106, 0.7123, 1.4917, 1.4956],
        [1.3286, 1.3539, 1.4222, 1.3693, 1.2816, 1.3320, 1.2782, 1.3248, 1.3248,
         1.3638, 1.3490, 1.3935, 1.3913, 1.3548, 1.1666, 1.3718, 1.3120, 1.2808,
         1.7995, 1.8956, 1.9903, 1.8973, 1.6682, 1.6788, 1.7921, 1.6392, 1.6392,
         1.3277, 1.3504, 1.3622, 1.3921, 1.3220, 1.3819, 1.3866, 1.3726, 1.3668,
         1.4426, 1.4700, 1.4588, 1.4042, 1.4649, 1.4707, 1.4488, 1.1930, 1.2176,
         1.3269, 1.4156, 1.4086, 1.3698, 1.2855, 1.4096, 1.3673, 1.3807, 1.3851],
        [1.3198, 1.3495, 1.2532, 1.1976, 1.3384, 1.3137, 1.3312, 1.3163, 1.3163,
         1.3856, 1.2976, 1.3521, 1.2954, 1.3770, 1.3128, 1.3907, 1.3826, 1.0241,
         1.3847, 1.2411, 1.4341, 1.3940, 1.3324, 1.2980, 1.3717, 1.3420, 1.3420,
         2.0032, 1.7242, 1.6120, 1.6896, 1.9642, 1.6052, 1.9471, 1.6223, 1.5983,
         1.4315, 1.3860, 1.3515, 1.3862, 1.4439, 1.3079, 1.3904, 1.0851, 1.3464,
         1.4489, 1.3051, 1.1841, 1.3125, 1.4302, 1.2018, 1.4924, 1.3225, 1.3822],
        [1.6436, 1.3689, 0.4636, 0.7014, 1.1846, 1.5628, 1.4766, 1.6405, 1.6405,
         1.6060, 1.4322, 1.3413, 1.0063, 1.6568, 0.3441, 1.5001, 1.6566, 1.2565,
         1.2372, 0.8646, 0.8807, 1.0923, 1.5381, 1.5777, 1.2199, 1.6266, 1.6266,
         0.6426, 0.6690, 1.6145, 1.3856, 0.8323, 1.6145, 1.0902, 1.6395, 1.5938,
         1.3332, 1.0624, 1.0183, 1.2545, 1.5834, 1.6883, 1.2280, 2.6885, 2.5375,
         0.8449, 1.1655, 1.2922, 1.6222, 0.9854, 1.5642, 0.4709, 1.5292, 1.7057],
        [1.4046, 1.4329, 1.4851, 1.4640, 1.3926, 1.3697, 1.3717, 1.4009, 1.4009,
         1.3818, 1.3962, 1.3553, 1.4408, 1.4899, 1.4038, 1.3896, 1.4975, 1.4014,
         1.4836, 1.4699, 1.3752, 1.4320, 1.4540, 1.4445, 1.4097, 1.4426, 1.4426,
         1.4407, 1.3871, 1.4323, 1.2301, 1.3052, 1.1957, 1.4378, 1.2946, 1.4374,
         1.5736, 1.2871, 1.5872, 1.5626, 1.1717, 1.0774, 1.5774, 1.2949, 0.8579,
         2.2895, 1.7425, 1.9273, 1.9001, 1.7641, 1.3209, 2.2666, 1.7985, 1.3044]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 32 : 184.54620958836747
Test loss for epoch 32 : 184.4296057583684
Test Precision for epoch 32 : 0.26153846153846155
Test Recall for epoch 32 : 0.26153846153846155
Test F1 for epoch 32 : 0.26153846153846155


theta for epoch 33 : tensor([[1.7413, 1.8448, 1.9558, 1.9270, 1.9348, 1.7699, 1.8148, 1.7392, 1.7392,
         1.3907, 1.4067, 1.4199, 1.4133, 1.3811, 1.4384, 1.3986, 1.3892, 1.3841,
         1.3672, 1.3610, 1.3951, 1.3820, 1.3550, 1.3471, 1.3745, 1.3410, 1.3410,
         1.3107, 1.4223, 1.3156, 1.3515, 1.4014, 1.3381, 1.3417, 1.2836, 1.3210,
         1.4560, 1.4835, 1.4711, 1.4688, 1.4809, 1.4233, 1.4560, 1.4592, 1.4231,
         1.4334, 1.3975, 1.3906, 1.3538, 1.4438, 1.3928, 1.4269, 1.3648, 1.3688],
        [1.3653, 1.1485, 1.0080, 1.2987, 1.3235, 1.4231, 1.3412, 1.4168, 1.4168,
         1.5311, 1.6854, 1.4348, 1.9474, 1.4978, 2.3617, 1.5226, 1.3958, 2.1676,
         1.1610, 1.2299, 0.8230, 1.1695, 1.3306, 1.4307, 1.3991, 1.4267, 1.4267,
         1.3819, 1.0920, 1.4574, 1.4160, 1.1308, 1.4768, 1.4582, 1.4483, 1.4107,
         1.4246, 1.5691, 1.5338, 1.4473, 1.3565, 1.5242, 1.5198, 0.4748, 1.3151,
         0.9279, 1.5112, 1.4915, 1.4716, 1.0602, 1.5023, 0.7094, 1.4823, 1.4864],
        [1.3229, 1.3500, 1.4208, 1.3688, 1.2809, 1.3264, 1.2774, 1.3191, 1.3191,
         1.3553, 1.3421, 1.3858, 1.3851, 1.3459, 1.1740, 1.3634, 1.3045, 1.2755,
         1.8156, 1.9146, 2.0117, 1.9168, 1.6820, 1.6936, 1.8094, 1.6528, 1.6528,
         1.3238, 1.3470, 1.3539, 1.3849, 1.3186, 1.3739, 1.3795, 1.3646, 1.3586,
         1.4340, 1.4624, 1.4505, 1.3961, 1.4572, 1.4633, 1.4399, 1.1941, 1.2168,
         1.3247, 1.4087, 1.4014, 1.3618, 1.2863, 1.4026, 1.3697, 1.3730, 1.3774],
        [1.3156, 1.3462, 1.2534, 1.1994, 1.3358, 1.3103, 1.3279, 1.3120, 1.3120,
         1.3796, 1.2914, 1.3489, 1.2912, 1.3707, 1.3098, 1.3852, 1.3766, 1.0206,
         1.3752, 1.2372, 1.4256, 1.3851, 1.3230, 1.2878, 1.3622, 1.3315, 1.3315,
         2.0275, 1.7410, 1.6254, 1.7051, 1.9879, 1.6186, 1.9700, 1.6362, 1.6115,
         1.4243, 1.3801, 1.3443, 1.3788, 1.4382, 1.3038, 1.3831, 1.0831, 1.3436,
         1.4465, 1.3019, 1.1814, 1.3069, 1.4289, 1.1982, 1.4904, 1.3173, 1.3772],
        [1.6480, 1.3706, 0.4724, 0.7088, 1.1827, 1.5643, 1.4783, 1.6448, 1.6448,
         1.6077, 1.4306, 1.3424, 1.0038, 1.6591, 0.3363, 1.5020, 1.6589, 1.2559,
         1.2335, 0.8593, 0.8735, 1.0864, 1.5357, 1.5779, 1.2207, 1.6268, 1.6268,
         0.6458, 0.6718, 1.6150, 1.3845, 0.8338, 1.6155, 1.0893, 1.6414, 1.5948,
         1.3275, 1.0493, 1.0044, 1.2474, 1.5851, 1.6945, 1.2192, 2.7389, 2.5814,
         0.8410, 1.1727, 1.2970, 1.6240, 0.9848, 1.5669, 0.4709, 1.5333, 1.7092],
        [1.4028, 1.4327, 1.4907, 1.4661, 1.3974, 1.3706, 1.3714, 1.3991, 1.3991,
         1.3767, 1.3952, 1.3516, 1.4434, 1.4836, 1.4175, 1.3847, 1.4914, 1.4003,
         1.4752, 1.4679, 1.3834, 1.4303, 1.4454, 1.4355, 1.4015, 1.4332, 1.4332,
         1.4345, 1.3917, 1.4220, 1.2269, 1.3008, 1.1909, 1.4306, 1.2865, 1.4273,
         1.5672, 1.2790, 1.5812, 1.5579, 1.1650, 1.0716, 1.5707, 1.3058, 0.8655,
         2.2981, 1.7456, 1.9351, 1.9064, 1.7592, 1.3186, 2.2733, 1.8037, 1.3019]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 33 : 184.51157866843778
Test loss for epoch 33 : 184.39991472658676
Test Precision for epoch 33 : 0.26153846153846155
Test Recall for epoch 33 : 0.26153846153846155
Test F1 for epoch 33 : 0.26153846153846155


theta for epoch 34 : tensor([[1.7545, 1.8579, 1.9687, 1.9417, 1.9485, 1.7826, 1.8287, 1.7523, 1.7523,
         1.3783, 1.3945, 1.4082, 1.4031, 1.3684, 1.4302, 1.3864, 1.3767, 1.3729,
         1.3556, 1.3499, 1.3806, 1.3698, 1.3402, 1.3321, 1.3598, 1.3259, 1.3259,
         1.3115, 1.4199, 1.3120, 1.3482, 1.3999, 1.3344, 1.3396, 1.2807, 1.3176,
         1.4455, 1.4740, 1.4609, 1.4585, 1.4710, 1.4144, 1.4454, 1.4557, 1.4178,
         1.4317, 1.3937, 1.3863, 1.3489, 1.4410, 1.3889, 1.4287, 1.3599, 1.3642],
        [1.3602, 1.1484, 1.0114, 1.2957, 1.3211, 1.4174, 1.3362, 1.4110, 1.4110,
         1.5376, 1.6968, 1.4388, 1.9675, 1.5035, 2.3966, 1.5292, 1.3989, 2.1963,
         1.1530, 1.2224, 0.8206, 1.1624, 1.3212, 1.4194, 1.3887, 1.4152, 1.4152,
         1.3820, 1.0919, 1.4557, 1.4147, 1.1308, 1.4754, 1.4581, 1.4464, 1.4089,
         1.4157, 1.5623, 1.5259, 1.4386, 1.3485, 1.5174, 1.5115, 0.4694, 1.3074,
         0.9328, 1.5082, 1.4885, 1.4672, 1.0613, 1.4992, 0.7126, 1.4782, 1.4824],
        [1.3178, 1.3464, 1.4191, 1.3682, 1.2806, 1.3214, 1.2773, 1.3140, 1.3140,
         1.3448, 1.3334, 1.3760, 1.3768, 1.3351, 1.1794, 1.3531, 1.2953, 1.2684,
         1.8282, 1.9301, 2.0293, 1.9327, 1.6924, 1.7051, 1.8234, 1.6631, 1.6631,
         1.3268, 1.3502, 1.3523, 1.3842, 1.3222, 1.3727, 1.3791, 1.3633, 1.3572,
         1.4253, 1.4546, 1.4420, 1.3879, 1.4493, 1.4554, 1.4309, 1.1955, 1.2165,
         1.3268, 1.4060, 1.3985, 1.3583, 1.2914, 1.3999, 1.3758, 1.3697, 1.3743],
        [1.3137, 1.3450, 1.2557, 1.2035, 1.3353, 1.3093, 1.3269, 1.3101, 1.3101,
         1.3733, 1.2852, 1.3454, 1.2870, 1.3641, 1.3064, 1.3793, 1.3704, 1.0179,
         1.3664, 1.2344, 1.4176, 1.3767, 1.3146, 1.2788, 1.3534, 1.3220, 1.3220,
         2.0493, 1.7555, 1.6365, 1.7183, 2.0092, 1.6297, 1.9905, 1.6478, 1.6224,
         1.4182, 1.3756, 1.3387, 1.3727, 1.4335, 1.3012, 1.3771, 1.0830, 1.3418,
         1.4484, 1.3035, 1.1839, 1.3063, 1.4318, 1.1999, 1.4924, 1.3170, 1.3769],
        [1.6486, 1.3681, 0.4766, 0.7116, 1.1767, 1.5619, 1.4761, 1.6453, 1.6453,
         1.6048, 1.4243, 1.3392, 0.9966, 1.6570, 0.3234, 1.4996, 1.6568, 1.2508,
         1.2256, 0.8496, 0.8613, 1.0761, 1.5291, 1.5741, 1.2175, 1.6231, 1.6231,
         0.6507, 0.6763, 1.6187, 1.3866, 0.8376, 1.6196, 1.0916, 1.6466, 1.5991,
         1.3243, 1.0388, 0.9932, 1.2428, 1.5893, 1.7031, 1.2130, 2.7922, 2.6281,
         0.8347, 1.1785, 1.3006, 1.6246, 0.9823, 1.5685, 0.4678, 1.5364, 1.7117],
        [1.3970, 1.4284, 1.4913, 1.4637, 1.3977, 1.3677, 1.3670, 1.3933, 1.3933,
         1.3656, 1.3880, 1.3418, 1.4396, 1.4714, 1.4244, 1.3737, 1.4794, 1.3928,
         1.4608, 1.4594, 1.3844, 1.4223, 1.4309, 1.4207, 1.3872, 1.4180, 1.4180,
         1.4340, 1.4017, 1.4179, 1.2292, 1.3019, 1.1915, 1.4293, 1.2843, 1.4232,
         1.5579, 1.2681, 1.5721, 1.5501, 1.1556, 1.0629, 1.5611, 1.3134, 0.8694,
         2.3124, 1.7558, 1.9499, 1.9196, 1.7610, 1.3241, 2.2857, 1.8160, 1.3070]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 34 : 184.45818954696952
Test loss for epoch 34 : 184.3481845935215
Test Precision for epoch 34 : 0.26153846153846155
Test Recall for epoch 34 : 0.26153846153846155
Test F1 for epoch 34 : 0.26153846153846155


theta for epoch 35 : tensor([[1.7651, 1.8682, 1.9788, 1.9537, 1.9594, 1.7927, 1.8400, 1.7629, 1.7629,
         1.3648, 1.3812, 1.3952, 1.3917, 1.3547, 1.4202, 1.3730, 1.3632, 1.3604,
         1.3463, 1.3407, 1.3682, 1.3598, 1.3280, 1.3197, 1.3474, 1.3135, 1.3135,
         1.3168, 1.4222, 1.3135, 1.3498, 1.4030, 1.3356, 1.3423, 1.2827, 1.3191,
         1.4357, 1.4649, 1.4513, 1.4487, 1.4616, 1.4060, 1.4355, 1.4523, 1.4128,
         1.4289, 1.3892, 1.3814, 1.3438, 1.4373, 1.3845, 1.4291, 1.3548, 1.3594],
        [1.3547, 1.1485, 1.0147, 1.2920, 1.3182, 1.4109, 1.3307, 1.4044, 1.4044,
         1.5399, 1.7038, 1.4388, 1.9831, 1.5051, 2.4271, 1.5315, 1.3979, 2.2207,
         1.1512, 1.2206, 0.8248, 1.1613, 1.3176, 1.4133, 1.3835, 1.4090, 1.4090,
         1.3870, 1.0975, 1.4588, 1.4183, 1.1364, 1.4787, 1.4628, 1.4494, 1.4121,
         1.4093, 1.5577, 1.5202, 1.4323, 1.3434, 1.5126, 1.5054, 0.4685, 1.3026,
         0.9417, 1.5071, 1.4877, 1.4653, 1.0661, 1.4983, 0.7193, 1.4763, 1.4808],
        [1.3094, 1.3392, 1.4132, 1.3638, 1.2768, 1.3130, 1.2739, 1.3056, 1.3056,
         1.3344, 1.3248, 1.3662, 1.3682, 1.3245, 1.1846, 1.3429, 1.2864, 1.2612,
         1.8397, 1.9443, 2.0456, 1.9473, 1.7019, 1.7158, 1.8363, 1.6725, 1.6725,
         1.3336, 1.3571, 1.3544, 1.3871, 1.3295, 1.3750, 1.3822, 1.3657, 1.3595,
         1.4177, 1.4478, 1.4348, 1.3811, 1.4425, 1.4486, 1.4231, 1.1983, 1.2177,
         1.3289, 1.4034, 1.3957, 1.3554, 1.2966, 1.3975, 1.3815, 1.3668, 1.3717],
        [1.3122, 1.3439, 1.2581, 1.2079, 1.3350, 1.3085, 1.3261, 1.3086, 1.3086,
         1.3690, 1.2813, 1.3439, 1.2850, 1.3595, 1.3051, 1.3754, 1.3661, 1.0185,
         1.3634, 1.2376, 1.4150, 1.3741, 1.3124, 1.2761, 1.3505, 1.3187, 1.3187,
         2.0670, 1.7660, 1.6439, 1.7276, 2.0263, 1.6370, 2.0069, 1.6556, 1.6296,
         1.4152, 1.3744, 1.3366, 1.3698, 1.4317, 1.3021, 1.3745, 1.0868, 1.3433,
         1.4523, 1.3078, 1.1896, 1.3087, 1.4369, 1.2049, 1.4963, 1.3195, 1.3794],
        [1.6421, 1.3580, 0.4722, 0.7063, 1.1626, 1.5522, 1.4665, 1.6388, 1.6388,
         1.5983, 1.4140, 1.3321, 0.9849, 1.6513, 0.3050, 1.4936, 1.6510, 1.2417,
         1.2155, 0.8369, 0.8455, 1.0630, 1.5208, 1.5686, 1.2120, 1.6178, 1.6178,
         0.6531, 0.6781, 1.6222, 1.3880, 0.8392, 1.6235, 1.0928, 1.6516, 1.6031,
         1.3258, 1.0330, 0.9867, 1.2430, 1.5980, 1.7164, 1.2114, 2.8498, 2.6794,
         0.8221, 1.1787, 1.2989, 1.6207, 0.9735, 1.5654, 0.4574, 1.5348, 1.7097],
        [1.3838, 1.4162, 1.4832, 1.4531, 1.3898, 1.3572, 1.3548, 1.3801, 1.3801,
         1.3511, 1.3774, 1.3284, 1.4321, 1.4559, 1.4269, 1.3593, 1.4641, 1.3814,
         1.4462, 1.4504, 1.3844, 1.4138, 1.4164, 1.4059, 1.3728, 1.4029, 1.4029,
         1.4357, 1.4136, 1.4163, 1.2334, 1.3048, 1.1940, 1.4304, 1.2843, 1.4218,
         1.5474, 1.2564, 1.5620, 1.5413, 1.1451, 1.0532, 1.5504, 1.3194, 0.8716,
         2.3309, 1.7714, 1.9700, 1.9381, 1.7677, 1.3354, 2.3024, 1.8338, 1.3181]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 35 : 184.3922623225559
Test loss for epoch 35 : 184.2843095480219
Test Precision for epoch 35 : 0.26153846153846155
Test Recall for epoch 35 : 0.26153846153846155
Test F1 for epoch 35 : 0.26153846153846155


theta for epoch 36 : tensor([[1.7734, 1.8761, 1.9862, 1.9632, 1.9677, 1.8004, 1.8490, 1.7712, 1.7712,
         1.3552, 1.3717, 1.3860, 1.3839, 1.3450, 1.4137, 1.3636, 1.3536, 1.3516,
         1.3428, 1.3371, 1.3615, 1.3554, 1.3219, 1.3134, 1.3410, 1.3073, 1.3073,
         1.3217, 1.4240, 1.3150, 1.3513, 1.4055, 1.3367, 1.3448, 1.2846, 1.3207,
         1.4271, 1.4571, 1.4430, 1.4401, 1.4534, 1.3988, 1.4269, 1.4498, 1.4088,
         1.4208, 1.3796, 1.3717, 1.3340, 1.4283, 1.3752, 1.4239, 1.3450, 1.3499],
        [1.3483, 1.1479, 1.0167, 1.2872, 1.3143, 1.4035, 1.3244, 1.3970, 1.3970,
         1.5421, 1.7106, 1.4388, 1.9985, 1.5067, 2.4575, 1.5340, 1.3972, 2.2449,
         1.1549, 1.2238, 0.8342, 1.1655, 1.3194, 1.4124, 1.3834, 1.4081, 1.4081,
         1.3915, 1.1032, 1.4615, 1.4216, 1.1420, 1.4814, 1.4669, 1.4518, 1.4149,
         1.4042, 1.5539, 1.5155, 1.4273, 1.3398, 1.5089, 1.5003, 0.4697, 1.2993,
         0.9471, 1.5018, 1.4826, 1.4594, 1.0674, 1.4932, 0.7233, 1.4704, 1.4752],
        [1.2998, 1.3305, 1.4052, 1.3575, 1.2714, 1.3034, 1.2692, 1.2960, 1.2960,
         1.3281, 1.3203, 1.3602, 1.3634, 1.3179, 1.1928, 1.3367, 1.2816, 1.2578,
         1.8517, 1.9589, 2.0621, 1.9624, 1.7121, 1.7273, 1.8498, 1.6828, 1.6828,
         1.3397, 1.3632, 1.3560, 1.3894, 1.3362, 1.3767, 1.3847, 1.3675, 1.3612,
         1.4113, 1.4422, 1.4287, 1.3755, 1.4366, 1.4428, 1.4164, 1.2023, 1.2203,
         1.3257, 1.3956, 1.3878, 1.3477, 1.2963, 1.3900, 1.3815, 1.3591, 1.3642],
        [1.3114, 1.3434, 1.2609, 1.2128, 1.3352, 1.3085, 1.3258, 1.3078, 1.3078,
         1.3690, 1.2818, 1.3467, 1.2873, 1.3593, 1.3077, 1.3757, 1.3661, 1.0237,
         1.3670, 1.2473, 1.4185, 1.3779, 1.3170, 1.2803, 1.3542, 1.3222, 1.3222,
         2.0812, 1.7732, 1.6479, 1.7336, 2.0401, 1.6411, 2.0199, 1.6601, 1.6335,
         1.4145, 1.3758, 1.3371, 1.3695, 1.4322, 1.3057, 1.3743, 1.0934, 1.3470,
         1.4539, 1.3103, 1.1938, 1.3094, 1.4397, 1.2084, 1.4976, 1.3203, 1.3798],
        [1.6318, 1.3439, 0.4631, 0.6964, 1.1444, 1.5386, 1.4528, 1.6285, 1.6285,
         1.5919, 1.4036, 1.3251, 0.9729, 1.6458, 0.2853, 1.4877, 1.6455, 1.2326,
         1.2061, 0.8244, 0.8295, 1.0504, 1.5135, 1.5643, 1.2074, 1.6137, 1.6137,
         0.6514, 0.6758, 1.6227, 1.3861, 0.8370, 1.6242, 1.0908, 1.6535, 1.6041,
         1.3301, 1.0303, 0.9831, 1.2460, 1.6094, 1.7324, 1.2126, 2.9102, 2.7336,
         0.8024, 1.1721, 1.2903, 1.6101, 0.9573, 1.5558, 0.4395, 1.5267, 1.7013],
        [1.3691, 1.4022, 1.4726, 1.4404, 1.3801, 1.3454, 1.3410, 1.3656, 1.3656,
         1.3404, 1.3704, 1.3187, 1.4279, 1.4439, 1.4321, 1.3486, 1.4523, 1.3733,
         1.4375, 1.4469, 1.3896, 1.4111, 1.4079, 1.3971, 1.3644, 1.3939, 1.3939,
         1.4367, 1.4244, 1.4144, 1.2371, 1.3070, 1.1960, 1.4309, 1.2840, 1.4199,
         1.5377, 1.2460, 1.5526, 1.5331, 1.1362, 1.0451, 1.5404, 1.3259, 0.8746,
         2.3462, 1.7844, 1.9875, 1.9539, 1.7714, 1.3444, 2.3157, 1.8491, 1.3270]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 36 : 184.34557641882515
Test loss for epoch 36 : 184.2442401314268
Test Precision for epoch 36 : 0.26153846153846155
Test Recall for epoch 36 : 0.26153846153846155
Test F1 for epoch 36 : 0.26153846153846155


theta for epoch 37 : tensor([[1.7834, 1.8853, 1.9947, 1.9739, 1.9773, 1.8097, 1.8594, 1.7811, 1.7811,
         1.3507, 1.3672, 1.3818, 1.3809, 1.3404, 1.4117, 1.3591, 1.3491, 1.3476,
         1.3427, 1.3367, 1.3581, 1.3546, 1.3195, 1.3109, 1.3383, 1.3049, 1.3049,
         1.3208, 1.4202, 1.3113, 1.3474, 1.4024, 1.3326, 1.3419, 1.2814, 1.3171,
         1.4183, 1.4491, 1.4346, 1.4314, 1.4449, 1.3913, 1.4182, 1.4467, 1.4044,
         1.4090, 1.3665, 1.3584, 1.3210, 1.4156, 1.3624, 1.4147, 1.3318, 1.3370],
        [1.3433, 1.1483, 1.0188, 1.2833, 1.3117, 1.3975, 1.3193, 1.3910, 1.3910,
         1.5473, 1.7203, 1.4420, 2.0165, 1.5114, 2.4902, 1.5395, 1.3995, 2.2718,
         1.1602, 1.2285, 0.8446, 1.1713, 1.3230, 1.4134, 1.3851, 1.4090, 1.4090,
         1.3910, 1.1040, 1.4593, 1.4199, 1.1427, 1.4794, 1.4661, 1.4494, 1.4129,
         1.3984, 1.5493, 1.5100, 1.4215, 1.3355, 1.5042, 1.4944, 0.4701, 1.2955,
         0.9480, 1.4920, 1.4731, 1.4492, 1.0642, 1.4837, 0.7232, 1.4602, 1.4653],
        [1.2940, 1.3254, 1.4003, 1.3546, 1.2696, 1.2976, 1.2682, 1.2903, 1.2903,
         1.3277, 1.3216, 1.3601, 1.3641, 1.3174, 1.2059, 1.3363, 1.2828, 1.2600,
         1.8632, 1.9728, 2.0779, 1.9769, 1.7222, 1.7386, 1.8629, 1.6929, 1.6929,
         1.3422, 1.3654, 1.3540, 1.3879, 1.3393, 1.3747, 1.3835, 1.3656, 1.3594,
         1.4054, 1.4370, 1.4231, 1.3704, 1.4312, 1.4373, 1.4102, 1.2070, 1.2238,
         1.3196, 1.3851, 1.3772, 1.3375, 1.2931, 1.3799, 1.3783, 1.3488, 1.3542],
        [1.3118, 1.3439, 1.2643, 1.2185, 1.3364, 1.3097, 1.3267, 1.3082, 1.3082,
         1.3718, 1.2852, 1.3522, 1.2924, 1.3620, 1.3128, 1.3788, 1.3691, 1.0316,
         1.3725, 1.2585, 1.4236, 1.3835, 1.3236, 1.2864, 1.3597, 1.3278, 1.3278,
         2.0948, 1.7798, 1.6515, 1.7391, 2.0532, 1.6447, 2.0323, 1.6641, 1.6370,
         1.4131, 1.3765, 1.3371, 1.3684, 1.4319, 1.3087, 1.3736, 1.0990, 1.3499,
         1.4520, 1.3095, 1.1949, 1.3069, 1.4390, 1.2087, 1.4953, 1.3178, 1.3770],
        [1.6242, 1.3330, 0.4577, 0.6901, 1.1299, 1.5278, 1.4422, 1.6208, 1.6208,
         1.5892, 1.3971, 1.3224, 0.9653, 1.6439, 0.2698, 1.4859, 1.6436, 1.2278,
         1.2003, 0.8157, 0.8167, 1.0413, 1.5093, 1.5631, 1.2062, 1.6125, 1.6125,
         0.6483, 0.6719, 1.6198, 1.3812, 0.8329, 1.6215, 1.0866, 1.6518, 1.6017,
         1.3323, 1.0258, 0.9780, 1.2471, 1.6187, 1.7462, 1.2119, 2.9696, 2.7865,
         0.7823, 1.1644, 1.2804, 1.5976, 0.9406, 1.5443, 0.4216, 1.5168, 1.6908],
        [1.3596, 1.3931, 1.4658, 1.4321, 1.3749, 1.3386, 1.3322, 1.3561, 1.3561,
         1.3359, 1.3695, 1.3153, 1.4294, 1.4379, 1.4423, 1.3441, 1.4464, 1.3711,
         1.4338, 1.4482, 1.3994, 1.4135, 1.4047, 1.3937, 1.3614, 1.3903, 1.3903,
         1.4334, 1.4306, 1.4086, 1.2369, 1.3048, 1.1941, 1.4273, 1.2800, 1.4142,
         1.5283, 1.2367, 1.5435, 1.5253, 1.1284, 1.0383, 1.5308, 1.3327, 0.8785,
         2.3571, 1.7937, 2.0011, 1.9657, 1.7709, 1.3501, 2.3246, 1.8606, 1.3325]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 37 : 184.3187622323743
Test loss for epoch 37 : 184.22572265948057
Test Precision for epoch 37 : 0.26153846153846155
Test Recall for epoch 37 : 0.26153846153846155
Test F1 for epoch 37 : 0.26153846153846155


theta for epoch 38 : tensor([[1.7946, 1.8957, 2.0042, 1.9858, 1.9879, 1.8202, 1.8712, 1.7923, 1.7923,
         1.3493, 1.3657, 1.3805, 1.3808, 1.3390, 1.4125, 1.3578, 1.3478, 1.3463,
         1.3422, 1.3357, 1.3544, 1.3533, 1.3170, 1.3083, 1.3353, 1.3024, 1.3024,
         1.3149, 1.4113, 1.3032, 1.3389, 1.3942, 1.3238, 1.3342, 1.2735, 1.3089,
         1.4094, 1.4409, 1.4259, 1.4224, 1.4362, 1.3835, 1.4093, 1.4430, 1.3997,
         1.4003, 1.3567, 1.3484, 1.3115, 1.4059, 1.3528, 1.4082, 1.3222, 1.3276],
        [1.3407, 1.1507, 1.0222, 1.2815, 1.3114, 1.3940, 1.3166, 1.3875, 1.3875,
         1.5547, 1.7321, 1.4474, 2.0365, 1.5183, 2.5248, 1.5472, 1.4042, 2.3008,
         1.1636, 1.2312, 0.8527, 1.1752, 1.3249, 1.4126, 1.3849, 1.4081, 1.4081,
         1.3856, 1.1003, 1.4526, 1.4138, 1.1389, 1.4726, 1.4606, 1.4424, 1.4065,
         1.3916, 1.5436, 1.5033, 1.4146, 1.3304, 1.4985, 1.4873, 0.4695, 1.2908,
         0.9494, 1.4832, 1.4646, 1.4402, 1.0617, 1.4751, 0.7234, 1.4511, 1.4564],
        [1.2934, 1.3253, 1.4001, 1.3564, 1.2728, 1.2971, 1.2723, 1.2898, 1.2898,
         1.3313, 1.3268, 1.3636, 1.3684, 1.3209, 1.2220, 1.3398, 1.2879, 1.2657,
         1.8728, 1.9847, 2.0914, 1.9892, 1.7304, 1.7480, 1.8742, 1.7013, 1.7013,
         1.3414, 1.3641, 1.3488, 1.3830, 1.3391, 1.3694, 1.3789, 1.3604, 1.3543,
         1.3998, 1.4321, 1.4177, 1.3658, 1.4260, 1.4319, 1.4043, 1.2120, 1.2279,
         1.3171, 1.3783, 1.3703, 1.3311, 1.2934, 1.3733, 1.3783, 1.3423, 1.3479],
        [1.3115, 1.3436, 1.2665, 1.2227, 1.3369, 1.3100, 1.3268, 1.3079, 1.3079,
         1.3735, 1.2872, 1.3565, 1.2961, 1.3634, 1.3163, 1.3807, 1.3708, 1.0376,
         1.3731, 1.2645, 1.4238, 1.3842, 1.3253, 1.2877, 1.3605, 1.3285, 1.3285,
         2.1115, 1.7898, 1.6585, 1.7478, 2.0696, 1.6517, 2.0480, 1.6714, 1.6439,
         1.4087, 1.3743, 1.3340, 1.3643, 1.4285, 1.3084, 1.3698, 1.1009, 1.3495,
         1.4483, 1.3068, 1.1940, 1.3027, 1.4365, 1.2072, 1.4912, 1.3136, 1.3726],
        [1.6227, 1.3297, 0.4612, 0.6923, 1.1240, 1.5236, 1.4386, 1.6193, 1.6193,
         1.5908, 1.3953, 1.3251, 0.9639, 1.6462, 0.2617, 1.4888, 1.6459, 1.2285,
         1.1986, 0.8124, 0.8086, 1.0368, 1.5080, 1.5646, 1.2089, 1.6139, 1.6139,
         0.6484, 0.6712, 1.6159, 1.3763, 0.8311, 1.6179, 1.0841, 1.6491, 1.5985,
         1.3287, 1.0160, 0.9676, 1.2424, 1.6218, 1.7538, 1.2056, 3.0247, 2.8348,
         0.7704, 1.1641, 1.2773, 1.5904, 0.9324, 1.5384, 0.4127, 1.5127, 1.6852],
        [1.3548, 1.3884, 1.4630, 1.4282, 1.3741, 1.3366, 1.3280, 1.3514, 1.3514,
         1.3342, 1.3712, 1.3144, 1.4333, 1.4345, 1.4542, 1.3423, 1.4431, 1.3710,
         1.4294, 1.4483, 1.4075, 1.4147, 1.4007, 1.3896, 1.3577, 1.3861, 1.3861,
         1.4248, 1.4312, 1.3980, 1.2318, 1.2974, 1.1873, 1.4187, 1.2712, 1.4036,
         1.5182, 1.2270, 1.5338, 1.5168, 1.1203, 1.0312, 1.5204, 1.3385, 0.8814,
         2.3690, 1.8049, 2.0166, 1.9794, 1.7720, 1.3582, 2.3345, 1.8741, 1.3406]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 38 : 184.28115954355079
Test loss for epoch 38 : 184.19113256348905
Test Precision for epoch 38 : 0.26153846153846155
Test Recall for epoch 38 : 0.26153846153846155
Test F1 for epoch 38 : 0.26153846153846155


theta for epoch 39 : tensor([[1.8034, 1.9034, 2.0109, 1.9948, 1.9957, 1.8282, 1.8804, 1.8011, 1.8011,
         1.3476, 1.3637, 1.3788, 1.3802, 1.3373, 1.4124, 1.3560, 1.3460, 1.3444,
         1.3403, 1.3332, 1.3493, 1.3506, 1.3135, 1.3046, 1.3313, 1.2990, 1.2990,
         1.3086, 1.4021, 1.2954, 1.3305, 1.3857, 1.3153, 1.3266, 1.2659, 1.3011,
         1.4026, 1.4348, 1.4195, 1.4156, 1.4296, 1.3778, 1.4025, 1.4413, 1.3969,
         1.3989, 1.3544, 1.3460, 1.3098, 1.4036, 1.3508, 1.4087, 1.3202, 1.3259],
        [1.3405, 1.1552, 1.0271, 1.2819, 1.3135, 1.3928, 1.3162, 1.3864, 1.3864,
         1.5613, 1.7428, 1.4521, 2.0554, 1.5244, 2.5583, 1.5542, 1.4082, 2.3287,
         1.1649, 1.2316, 0.8589, 1.1769, 1.3247, 1.4095, 1.3825, 1.4051, 1.4051,
         1.3790, 1.0958, 1.4449, 1.4065, 1.1342, 1.4648, 1.4540, 1.4342, 1.3991,
         1.3861, 1.5389, 1.4977, 1.4089, 1.3268, 1.4939, 1.4814, 0.4704, 1.2878,
         0.9554, 1.4791, 1.4607, 1.4360, 1.0640, 1.4712, 0.7275, 1.4468, 1.4524],
        [1.2951, 1.3272, 1.4015, 1.3601, 1.2780, 1.2987, 1.2784, 1.2915, 1.2915,
         1.3332, 1.3303, 1.3655, 1.3709, 1.3228, 1.2360, 1.3418, 1.2916, 1.2694,
         1.8810, 1.9951, 2.1035, 2.0002, 1.7375, 1.7565, 1.8842, 1.7086, 1.7086,
         1.3393, 1.3612, 1.3425, 1.3768, 1.3375, 1.3628, 1.3729, 1.3540, 1.3480,
         1.3953, 1.4283, 1.4135, 1.3623, 1.4219, 1.4277, 1.3996, 1.2182, 1.2332,
         1.3197, 1.3768, 1.3687, 1.3303, 1.2985, 1.3721, 1.3830, 1.3413, 1.3471],
        [1.3081, 1.3402, 1.2651, 1.2233, 1.3343, 1.3073, 1.3238, 1.3045, 1.3045,
         1.3697, 1.2837, 1.3552, 1.2943, 1.3596, 1.3139, 1.3772, 1.3671, 1.0375,
         1.3663, 1.2625, 1.4164, 1.3774, 1.3196, 1.2815, 1.3538, 1.3219, 1.3219,
         2.1333, 1.8050, 1.6708, 1.7619, 2.0910, 1.6640, 2.0687, 1.6842, 1.6561,
         1.4022, 1.3699, 1.3287, 1.3580, 1.4230, 1.3059, 1.3640, 1.0997, 1.3466,
         1.4441, 1.3035, 1.1920, 1.2979, 1.4335, 1.2047, 1.4866, 1.3088, 1.3677],
        [1.6254, 1.3317, 0.4714, 0.7009, 1.1244, 1.5240, 1.4400, 1.6221, 1.6221,
         1.5934, 1.3950, 1.3296, 0.9652, 1.6493, 0.2578, 1.4931, 1.6491, 1.2312,
         1.1991, 0.8124, 0.8033, 1.0348, 1.5079, 1.5671, 1.2137, 1.6162, 1.6162,
         0.6532, 0.6750, 1.6135, 1.3737, 0.8334, 1.6156, 1.0855, 1.6476, 1.5968,
         1.3205, 1.0023, 0.9533, 1.2334, 1.6201, 1.7565, 1.1949, 3.0765, 2.8796,
         0.7675, 1.1719, 1.2821, 1.5897, 0.9336, 1.5394, 0.4130, 1.5157, 1.6860],
        [1.3526, 1.3862, 1.4619, 1.4265, 1.3755, 1.3371, 1.3263, 1.3493, 1.3493,
         1.3304, 1.3707, 1.3115, 1.4347, 1.4291, 1.4630, 1.3385, 1.4377, 1.3684,
         1.4219, 1.4448, 1.4115, 1.4124, 1.3937, 1.3825, 1.3510, 1.3788, 1.3788,
         1.4145, 1.4295, 1.3863, 1.2250, 1.2881, 1.1790, 1.4086, 1.2612, 1.3919,
         1.5089, 1.2187, 1.5249, 1.5090, 1.1135, 1.0254, 1.5110, 1.3448, 0.8848,
         2.3831, 1.8195, 2.0351, 1.9962, 1.7760, 1.3700, 2.3466, 1.8909, 1.3523]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 39 : 184.22830805148652
Test loss for epoch 39 : 184.1350911491001
Test Precision for epoch 39 : 0.26153846153846155
Test Recall for epoch 39 : 0.26153846153846155
Test F1 for epoch 39 : 0.26153846153846155


theta for epoch 40 : tensor([[1.8085, 1.9072, 2.0136, 2.0001, 1.9997, 1.8325, 1.8858, 1.8061, 1.8061,
         1.3428, 1.3585, 1.3739, 1.3762, 1.3326, 1.4088, 1.3512, 1.3413, 1.3391,
         1.3387, 1.3307, 1.3445, 1.3483, 1.3105, 1.3017, 1.3278, 1.2963, 1.2963,
         1.3045, 1.3949, 1.2903, 1.3245, 1.3792, 1.3093, 1.3213, 1.2610, 1.2959,
         1.4002, 1.4330, 1.4173, 1.4130, 1.4272, 1.3764, 1.4001, 1.4433, 1.3983,
         1.4025, 1.3573, 1.3488, 1.3135, 1.4064, 1.3539, 1.4139, 1.3236, 1.3295],
        [1.3415, 1.1609, 1.0326, 1.2833, 1.3167, 1.3929, 1.3171, 1.3864, 1.3864,
         1.5650, 1.7506, 1.4541, 2.0712, 1.5277, 2.5889, 1.5584, 1.4096, 2.3538,
         1.1668, 1.2322, 0.8658, 1.1792, 1.3249, 1.4068, 1.3803, 1.4025, 1.4025,
         1.3735, 1.0928, 1.4386, 1.4007, 1.1311, 1.4581, 1.4486, 1.4273, 1.3931,
         1.3842, 1.5374, 1.4953, 1.4068, 1.3268, 1.4925, 1.4787, 0.4753, 1.2886,
         0.9654, 1.4788, 1.4607, 1.4359, 1.0704, 1.4712, 0.7354, 1.4465, 1.4523],
        [1.2949, 1.3272, 1.4008, 1.3616, 1.2811, 1.2986, 1.2826, 1.2915, 1.2915,
         1.3297, 1.3284, 1.3619, 1.3677, 1.3193, 1.2440, 1.3382, 1.2897, 1.2674,
         1.8906, 2.0067, 2.1166, 2.0124, 1.7462, 1.7665, 1.8956, 1.7175, 1.7175,
         1.3365, 1.3575, 1.3357, 1.3700, 1.3353, 1.3558, 1.3665, 1.3472, 1.3413,
         1.3930, 1.4266, 1.4115, 1.3611, 1.4198, 1.4254, 1.3970, 1.2260, 1.2406,
         1.3238, 1.3769, 1.3688, 1.3313, 1.3048, 1.3726, 1.3888, 1.3421, 1.3481],
        [1.3022, 1.3343, 1.2609, 1.2210, 1.3291, 1.3021, 1.3182, 1.2987, 1.2987,
         1.3607, 1.2748, 1.3485, 1.2871, 1.3504, 1.3060, 1.3684, 1.3581, 1.0319,
         1.3560, 1.2566, 1.4053, 1.3671, 1.3106, 1.2719, 1.3436, 1.3119, 1.3119,
         2.1577, 1.8231, 1.6860, 1.7788, 2.1151, 1.6792, 2.0922, 1.6998, 1.6712,
         1.3970, 1.3669, 1.3249, 1.3530, 1.4187, 1.3046, 1.3595, 1.0992, 1.3448,
         1.4400, 1.3002, 1.1900, 1.2933, 1.4304, 1.2021, 1.4819, 1.3042, 1.3630],
        [1.6279, 1.3338, 0.4817, 0.7096, 1.1253, 1.5242, 1.4414, 1.6246, 1.6246,
         1.5930, 1.3918, 1.3318, 0.9643, 1.6496, 0.2525, 1.4948, 1.6494, 1.2315,
         1.1995, 0.8126, 0.7978, 1.0328, 1.5073, 1.5691, 1.2183, 1.6179, 1.6179,
         0.6590, 0.6798, 1.6116, 1.3720, 0.8366, 1.6138, 1.0881, 1.6466, 1.5957,
         1.3125, 0.9891, 0.9396, 1.2246, 1.6183, 1.7592, 1.1844, 3.1290, 2.9249,
         0.7672, 1.1822, 1.2894, 1.5914, 0.9376, 1.5428, 0.4156, 1.5211, 1.6889],
        [1.3528, 1.3861, 1.4623, 1.4267, 1.3788, 1.3400, 1.3268, 1.3496, 1.3496,
         1.3242, 1.3674, 1.3060, 1.4329, 1.4210, 1.4680, 1.3322, 1.4296, 1.3627,
         1.4153, 1.4417, 1.4155, 1.4108, 1.3878, 1.3767, 1.3455, 1.3729, 1.3729,
         1.4065, 1.4298, 1.3774, 1.2211, 1.2813, 1.1736, 1.4010, 1.2542, 1.3830,
         1.5039, 1.2154, 1.5202, 1.5055, 1.1119, 1.0248, 1.5058, 1.3549, 0.8926,
         2.3941, 1.8316, 2.0510, 2.0103, 1.7773, 1.3798, 2.3555, 1.9052, 1.3621]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 40 : 184.18665063064378
Test loss for epoch 40 : 184.09057583152114
Test Precision for epoch 40 : 0.26153846153846155
Test Recall for epoch 40 : 0.26153846153846155
Test F1 for epoch 40 : 0.26153846153846155


theta for epoch 41 : tensor([[1.8138, 1.9112, 2.0163, 2.0054, 2.0037, 1.8370, 1.8915, 1.8115, 1.8115,
         1.3359, 1.3511, 1.3668, 1.3697, 1.3257, 1.4025, 1.3442, 1.3344, 1.3314,
         1.3370, 1.3279, 1.3396, 1.3457, 1.3078, 1.2990, 1.3244, 1.2938, 1.2938,
         1.3008, 1.3885, 1.2861, 1.3194, 1.3733, 1.3043, 1.3168, 1.2569, 1.2917,
         1.4011, 1.4345, 1.4185, 1.4138, 1.4280, 1.3781, 1.4011, 1.4482, 1.4025,
         1.4049, 1.3592, 1.3506, 1.3164, 1.4080, 1.3560, 1.4177, 1.3262, 1.3323],
        [1.3421, 1.1659, 1.0370, 1.2839, 1.3192, 1.3925, 1.3175, 1.3861, 1.3861,
         1.5674, 1.7568, 1.4550, 2.0854, 1.5298, 2.6180, 1.5613, 1.4098, 2.3776,
         1.1695, 1.2335, 0.8733, 1.1823, 1.3262, 1.4050, 1.3790, 1.4009, 1.4009,
         1.3688, 1.0910, 1.4331, 1.3957, 1.1290, 1.4524, 1.4439, 1.4213, 1.3880,
         1.3856, 1.5391, 1.4961, 1.4079, 1.3304, 1.4942, 1.4792, 0.4835, 1.2930,
         0.9753, 1.4784, 1.4606, 1.4358, 1.0768, 1.4711, 0.7434, 1.4462, 1.4522],
        [1.2920, 1.3241, 1.3967, 1.3598, 1.2809, 1.2956, 1.2836, 1.2886, 1.2886,
         1.3232, 1.3233, 1.3552, 1.3612, 1.3128, 1.2481, 1.3316, 1.2848, 1.2619,
         1.9021, 2.0201, 2.1313, 2.0264, 1.7569, 1.7786, 1.9090, 1.7286, 1.7286,
         1.3332, 1.3531, 1.3286, 1.3627, 1.3324, 1.3483, 1.3595, 1.3399, 1.3342,
         1.3930, 1.4272, 1.4117, 1.3621, 1.4200, 1.4253, 1.3967, 1.2356, 1.2499,
         1.3252, 1.3749, 1.3667, 1.3303, 1.3082, 1.3709, 1.3917, 1.3407, 1.3469],
        [1.2975, 1.3293, 1.2573, 1.2194, 1.3248, 1.2979, 1.3136, 1.2940, 1.2940,
         1.3518, 1.2662, 1.3419, 1.2801, 1.3415, 1.2981, 1.3597, 1.3493, 1.0269,
         1.3482, 1.2530, 1.3965, 1.3591, 1.3042, 1.2650, 1.3360, 1.3047, 1.3047,
         2.1793, 1.8384, 1.6986, 1.7930, 2.1364, 1.6919, 2.1128, 1.7127, 1.6838,
         1.3964, 1.3686, 1.3258, 1.3526, 1.4189, 1.3079, 1.3597, 1.1031, 1.3474,
         1.4368, 1.2981, 1.1893, 1.2902, 1.4283, 1.2011, 1.4782, 1.3009, 1.3595],
        [1.6275, 1.3327, 0.4877, 0.7143, 1.1227, 1.5215, 1.4398, 1.6243, 1.6243,
         1.5898, 1.3856, 1.3311, 0.9601, 1.6470, 0.2435, 1.4938, 1.6469, 1.2287,
         1.1984, 0.8107, 0.7898, 1.0289, 1.5053, 1.5697, 1.2211, 1.6182, 1.6182,
         0.6620, 0.6819, 1.6085, 1.3687, 0.8375, 1.6109, 1.0890, 1.6443, 1.5934,
         1.3077, 0.9794, 0.9293, 1.2190, 1.6197, 1.7649, 1.1773, 3.1847, 2.9735,
         0.7633, 1.1891, 1.2935, 1.5904, 0.9379, 1.5435, 0.4137, 1.5238, 1.6893],
        [1.3553, 1.3881, 1.4638, 1.4285, 1.3838, 1.3452, 1.3296, 1.3523, 1.3523,
         1.3189, 1.3647, 1.3015, 1.4313, 1.4136, 1.4723, 1.3267, 1.4222, 1.3575,
         1.4126, 1.4419, 1.4224, 1.4126, 1.3859, 1.3749, 1.3441, 1.3711, 1.3711,
         1.4020, 1.4328, 1.3723, 1.2208, 1.2779, 1.1720, 1.3970, 1.2511, 1.3778,
         1.5038, 1.2181, 1.5204, 1.5068, 1.1163, 1.0304, 1.5055, 1.3695, 0.9057,
         2.3982, 1.8372, 2.0605, 2.0179, 1.7721, 1.3836, 2.3576, 1.9131, 1.3660]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 41 : 184.15353239295678
Test loss for epoch 41 : 184.06141046244483
Test Precision for epoch 41 : 0.26153846153846155
Test Recall for epoch 41 : 0.26153846153846155
Test F1 for epoch 41 : 0.26153846153846155


theta for epoch 42 : tensor([[1.8228, 1.9186, 2.0224, 2.0141, 2.0111, 1.8451, 1.9008, 1.8204, 1.8204,
         1.3295, 1.3442, 1.3600, 1.3635, 1.3195, 1.3962, 1.3376, 1.3281, 1.3239,
         1.3332, 1.3228, 1.3328, 1.3411, 1.3034, 1.2947, 1.3193, 1.2898, 1.2898,
         1.2966, 1.3817, 1.2817, 1.3141, 1.3671, 1.2990, 1.3120, 1.2525, 1.2872,
         1.4020, 1.4360, 1.4198, 1.4146, 1.4288, 1.3797, 1.4021, 1.4524, 1.4063,
         1.4036, 1.3575, 1.3489, 1.3159, 1.4059, 1.3546, 1.4174, 1.3253, 1.3317],
        [1.3407, 1.1686, 1.0385, 1.2822, 1.3196, 1.3902, 1.3159, 1.3839, 1.3839,
         1.5710, 1.7643, 1.4572, 2.1006, 1.5332, 2.6480, 1.5656, 1.4115, 2.4024,
         1.1714, 1.2338, 0.8795, 1.1845, 1.3269, 1.4028, 1.3770, 1.3987, 1.3987,
         1.3642, 1.0892, 1.4280, 1.3911, 1.1270, 1.4469, 1.4394, 1.4156, 1.3833,
         1.3877, 1.5411, 1.4975, 1.4096, 1.3346, 1.4965, 1.4803, 0.4920, 1.2981,
         0.9825, 1.4759, 1.4585, 1.4340, 1.0807, 1.4690, 0.7493, 1.4440, 1.4503],
        [1.2879, 1.3197, 1.3909, 1.3562, 1.2792, 1.2915, 1.2832, 1.2847, 1.2847,
         1.3189, 1.3204, 1.3505, 1.3565, 1.3086, 1.2531, 1.3271, 1.2820, 1.2582,
         1.9131, 2.0329, 2.1453, 2.0397, 1.7675, 1.7905, 1.9219, 1.7394, 1.7394,
         1.3307, 1.3493, 1.3224, 1.3563, 1.3304, 1.3417, 1.3533, 1.3335, 1.3279,
         1.3941, 1.4288, 1.4131, 1.3643, 1.4211, 1.4262, 1.3977, 1.2459, 1.2602,
         1.3247, 1.3713, 1.3631, 1.3279, 1.3095, 1.3678, 1.3924, 1.3379, 1.3443],
        [1.2968, 1.3282, 1.2574, 1.2214, 1.3242, 1.2978, 1.3128, 1.2934, 1.2934,
         1.3487, 1.2636, 1.3409, 1.2790, 1.3384, 1.2958, 1.3566, 1.3463, 1.0283,
         1.3459, 1.2548, 1.3927, 1.3565, 1.3034, 1.2641, 1.3338, 1.3032, 1.3032,
         2.1941, 1.8472, 1.7048, 1.8008, 2.1511, 1.6981, 2.1268, 1.7193, 1.6900,
         1.4003, 1.3749, 1.3315, 1.3569, 1.4233, 1.3159, 1.3647, 1.1121, 1.3543,
         1.4364, 1.2993, 1.1923, 1.2905, 1.4289, 1.2037, 1.4770, 1.3010, 1.3593],
        [1.6244, 1.3287, 0.4897, 0.7155, 1.1173, 1.5161, 1.4353, 1.6213, 1.6213,
         1.5864, 1.3790, 1.3302, 0.9552, 1.6443, 0.2331, 1.4926, 1.6443, 1.2257,
         1.1956, 0.8069, 0.7794, 1.0232, 1.5019, 1.5690, 1.2223, 1.6172, 1.6172,
         0.6626, 0.6816, 1.6047, 1.3644, 0.8363, 1.6071, 1.0884, 1.6412, 1.5903,
         1.3051, 0.9721, 0.9215, 1.2157, 1.6231, 1.7727, 1.1723, 3.2427, 3.0245,
         0.7557, 1.1923, 1.2941, 1.5865, 0.9343, 1.5412, 0.4073, 1.5234, 1.6868],
        [1.3568, 1.3887, 1.4634, 1.4286, 1.3871, 1.3491, 1.3312, 1.3540, 1.3540,
         1.3159, 1.3642, 1.2991, 1.4314, 1.4086, 1.4775, 1.3236, 1.4171, 1.3541,
         1.4103, 1.4419, 1.4285, 1.4144, 1.3845, 1.3736, 1.3432, 1.3700, 1.3700,
         1.3988, 1.4365, 1.3689, 1.2216, 1.2757, 1.1716, 1.3944, 1.2495, 1.3743,
         1.5049, 1.2223, 1.5219, 1.5093, 1.1222, 1.0375, 1.5065, 1.3843, 0.9193,
         2.4010, 1.8422, 2.0692, 2.0247, 1.7660, 1.3869, 2.3584, 1.9202, 1.3694]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 42 : 184.1206851201418
Test loss for epoch 42 : 184.0375110575684
Test Precision for epoch 42 : 0.26153846153846155
Test Recall for epoch 42 : 0.26153846153846155
Test F1 for epoch 42 : 0.26153846153846155


theta for epoch 43 : tensor([[1.8342, 1.9283, 2.0305, 2.0250, 2.0207, 1.8556, 1.9124, 1.8318, 1.8318,
         1.3257, 1.3399, 1.3558, 1.3597, 1.3159, 1.3923, 1.3337, 1.3244, 1.3189,
         1.3279, 1.3162, 1.3247, 1.3352, 1.2978, 1.2893, 1.3130, 1.2846, 1.2846,
         1.2944, 1.3773, 1.2797, 1.3111, 1.3631, 1.2961, 1.3095, 1.2503, 1.2850,
         1.3996, 1.4340, 1.4177, 1.4119, 1.4260, 1.3775, 1.3998, 1.4526, 1.4062,
         1.4006, 1.3543, 1.3459, 1.3142, 1.4022, 1.3519, 1.4151, 1.3231, 1.3297],
        [1.3375, 1.1689, 1.0372, 1.2782, 1.3179, 1.3862, 1.3123, 1.3800, 1.3800,
         1.5767, 1.7735, 1.4616, 2.1175, 1.5387, 2.6796, 1.5720, 1.4153, 2.4290,
         1.1720, 1.2329, 0.8841, 1.1855, 1.3266, 1.3997, 1.3741, 1.3958, 1.3958,
         1.3609, 1.0887, 1.4244, 1.3880, 1.1264, 1.4429, 1.4364, 1.4113, 1.3802,
         1.3873, 1.5405, 1.4962, 1.4087, 1.3362, 1.4959, 1.4787, 0.4981, 1.3007,
         0.9879, 1.4724, 1.4554, 1.4313, 1.0832, 1.4660, 0.7538, 1.4410, 1.4475],
        [1.2844, 1.3156, 1.3851, 1.3528, 1.2777, 1.2880, 1.2831, 1.2813, 1.2813,
         1.3196, 1.3223, 1.3506, 1.3566, 1.3094, 1.2618, 1.3276, 1.2842, 1.2591,
         1.9219, 2.0433, 2.1568, 2.0507, 1.7758, 1.8002, 1.9326, 1.7482, 1.7482,
         1.3313, 1.3485, 1.3194, 1.3530, 1.3315, 1.3383, 1.3503, 1.3303, 1.3249,
         1.3938, 1.4290, 1.4131, 1.3651, 1.4207, 1.4254, 1.3972, 1.2545, 1.2689,
         1.3252, 1.3690, 1.3609, 1.3271, 1.3115, 1.3660, 1.3935, 1.3366, 1.3433],
        [1.2991, 1.3299, 1.2602, 1.2261, 1.3266, 1.3006, 1.3151, 1.2959, 1.2959,
         1.3515, 1.2672, 1.3457, 1.2838, 1.3413, 1.2992, 1.3594, 1.3492, 1.0360,
         1.3477, 1.2606, 1.3930, 1.3580, 1.3070, 1.2675, 1.3359, 1.3061, 1.3061,
         2.2043, 1.8515, 1.7066, 1.8040, 2.1611, 1.6999, 2.1361, 1.7214, 1.6918,
         1.4045, 1.3816, 1.3379, 1.3616, 1.4278, 1.3242, 1.3701, 1.1216, 1.3612,
         1.4388, 1.3038, 1.1989, 1.2945, 1.4324, 1.2100, 1.4785, 1.3047, 1.3625],
        [1.6207, 1.3241, 0.4910, 0.7160, 1.1115, 1.5102, 1.4304, 1.6176, 1.6176,
         1.5852, 1.3746, 1.3317, 0.9525, 1.6437, 0.2248, 1.4937, 1.6439, 1.2251,
         1.1932, 0.8035, 0.7691, 1.0179, 1.4987, 1.5684, 1.2235, 1.6163, 1.6163,
         0.6651, 0.6831, 1.6031, 1.3625, 0.8372, 1.6056, 1.0904, 1.6403, 1.5894,
         1.3010, 0.9637, 0.9126, 1.2111, 1.6250, 1.7789, 1.1662, 3.3003, 3.0748,
         0.7484, 1.1954, 1.2947, 1.5826, 0.9310, 1.5389, 0.4007, 1.5230, 1.6843],
        [1.3537, 1.3847, 1.4578, 1.4240, 1.3854, 1.3484, 1.3279, 1.3511, 1.3511,
         1.3139, 1.3644, 1.2974, 1.4322, 1.4048, 1.4827, 1.3213, 1.4132, 1.3514,
         1.4049, 1.4384, 1.4303, 1.4125, 1.3801, 1.3694, 1.3390, 1.3658, 1.3658,
         1.3962, 1.4404, 1.3663, 1.2225, 1.2737, 1.1711, 1.3924, 1.2483, 1.3716,
         1.5016, 1.2219, 1.5190, 1.5073, 1.1231, 1.0394, 1.5031, 1.3939, 0.9270,
         2.4097, 1.8539, 2.0844, 2.0381, 1.7664, 1.3971, 2.3649, 1.9341, 1.3797]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 43 : 184.08125195591902
Test loss for epoch 43 : 184.00444106308854
Test Precision for epoch 43 : 0.26153846153846155
Test Recall for epoch 43 : 0.26153846153846155
Test F1 for epoch 43 : 0.26153846153846155


theta for epoch 44 : tensor([[1.8449, 1.9372, 2.0378, 2.0350, 2.0293, 1.8653, 1.9233, 1.8425, 1.8425,
         1.3248, 1.3383, 1.3543, 1.3586, 1.3152, 1.3908, 1.3325, 1.3235, 1.3165,
         1.3243, 1.3112, 1.3185, 1.3310, 1.2942, 1.2858, 1.3087, 1.2813, 1.2813,
         1.2973, 1.3781, 1.2831, 1.3135, 1.3644, 1.2986, 1.3122, 1.2534, 1.2883,
         1.3930, 1.4278, 1.4115, 1.4052, 1.4189, 1.3711, 1.3934, 1.4481, 1.4015,
         1.3971, 1.3510, 1.3427, 1.3125, 1.3981, 1.3490, 1.4122, 1.3209, 1.3277],
        [1.3346, 1.1692, 1.0356, 1.2744, 1.3163, 1.3825, 1.3090, 1.3764, 1.3764,
         1.5826, 1.7829, 1.4664, 2.1343, 1.5445, 2.7110, 1.5787, 1.4195, 2.4556,
         1.1737, 1.2331, 0.8896, 1.1876, 1.3277, 1.3980, 1.3725, 1.3943, 1.3943,
         1.3610, 1.0917, 1.4242, 1.3883, 1.1291, 1.4423, 1.4368, 1.4105, 1.3805,
         1.3835, 1.5364, 1.4914, 1.4044, 1.3345, 1.4918, 1.4737, 0.5015, 1.3001,
         0.9928, 1.4685, 1.4520, 1.4285, 1.0852, 1.4627, 0.7581, 1.4378, 1.4445],
        [1.2821, 1.3126, 1.3802, 1.3501, 1.2771, 1.2857, 1.2838, 1.2792, 1.2792,
         1.3235, 1.3274, 1.3539, 1.3596, 1.3135, 1.2727, 1.3312, 1.2897, 1.2630,
         1.9293, 2.0522, 2.1667, 2.0602, 1.7830, 1.8088, 1.9420, 1.7558, 1.7558,
         1.3360, 1.3517, 1.3207, 1.3539, 1.3366, 1.3390, 1.3514, 1.3314, 1.3262,
         1.3904, 1.4259, 1.4100, 1.3629, 1.4170, 1.4213, 1.3936, 1.2598, 1.2743,
         1.3260, 1.3672, 1.3593, 1.3269, 1.3135, 1.3648, 1.3944, 1.3360, 1.3428],
        [1.3016, 1.3317, 1.2627, 1.2305, 1.3290, 1.3036, 1.3174, 1.2985, 1.2985,
         1.3561, 1.2725, 1.3521, 1.2904, 1.3460, 1.3043, 1.3640, 1.3539, 1.0453,
         1.3508, 1.2674, 1.3944, 1.3608, 1.3119, 1.2722, 1.3392, 1.3102, 1.3102,
         2.2151, 1.8567, 1.7094, 1.8081, 2.1718, 1.7027, 2.1462, 1.7245, 1.6946,
         1.4048, 1.3844, 1.3404, 1.3625, 1.4283, 1.3285, 1.3717, 1.1270, 1.3640,
         1.4407, 1.3078, 1.2051, 1.2981, 1.4352, 1.2160, 1.4794, 1.3080, 1.3654],
        [1.6178, 1.3208, 0.4936, 0.7179, 1.1075, 1.5054, 1.4267, 1.6149, 1.6149,
         1.5859, 1.3724, 1.3355, 0.9523, 1.6452, 0.2194, 1.4971, 1.6456, 1.2269,
         1.1930, 0.8025, 0.7610, 1.0148, 1.4973, 1.5695, 1.2265, 1.6171, 1.6171,
         0.6721, 0.6893, 1.6058, 1.3653, 0.8427, 1.6083, 1.0975, 1.6436, 1.5929,
         1.2939, 0.9527, 0.9011, 1.2034, 1.6235, 1.7817, 1.1570, 3.3558, 3.1230,
         0.7427, 1.1992, 1.2960, 1.5792, 0.9290, 1.5373, 0.3956, 1.5232, 1.6821],
        [1.3481, 1.3779, 1.4493, 1.4165, 1.3807, 1.3449, 1.3219, 1.3456, 1.3456,
         1.3121, 1.3646, 1.2958, 1.4328, 1.4014, 1.4871, 1.3193, 1.4097, 1.3486,
         1.3987, 1.4335, 1.4301, 1.4092, 1.3747, 1.3642, 1.3337, 1.3608, 1.3608,
         1.3962, 1.4463, 1.3666, 1.2256, 1.2739, 1.1728, 1.3932, 1.2496, 1.3718,
         1.4927, 1.2157, 1.5105, 1.4996, 1.1180, 1.0351, 1.4942, 1.3969, 0.9277,
         2.4227, 1.8707, 2.1047, 2.0565, 1.7718, 1.4126, 2.3759, 1.9531, 1.3952]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 44 : 184.03976589661858
Test loss for epoch 44 : 183.96347407383328
Test Precision for epoch 44 : 0.26153846153846155
Test Recall for epoch 44 : 0.26153846153846155
Test F1 for epoch 44 : 0.26153846153846155


theta for epoch 45 : tensor([[1.8538, 1.9442, 2.0431, 2.0431, 2.0361, 1.8733, 1.9324, 1.8514, 1.8514,
         1.3245, 1.3374, 1.3535, 1.3579, 1.3151, 1.3898, 1.3320, 1.3234, 1.3146,
         1.3242, 1.3097, 1.3161, 1.3303, 1.2943, 1.2860, 1.3080, 1.2818, 1.2818,
         1.3044, 1.3832, 1.2911, 1.3204, 1.3699, 1.3057, 1.3194, 1.2612, 1.2962,
         1.3855, 1.4206, 1.4044, 1.3974, 1.4108, 1.3634, 1.3860, 1.4421, 1.3953,
         1.3926, 1.3465, 1.3384, 1.3098, 1.3929, 1.3450, 1.4080, 1.3177, 1.3247],
        [1.3349, 1.1724, 1.0366, 1.2736, 1.3177, 1.3821, 1.3089, 1.3761, 1.3761,
         1.5864, 1.7899, 1.4692, 2.1488, 1.5483, 2.7401, 1.5834, 1.4219, 2.4801,
         1.1788, 1.2366, 0.8984, 1.1931, 1.3322, 1.3998, 1.3743, 1.3963, 1.3963,
         1.3642, 1.0980, 1.4274, 1.3919, 1.1352, 1.4449, 1.4403, 1.4129, 1.3842,
         1.3794, 1.5315, 1.4860, 1.3997, 1.3324, 1.4869, 1.4681, 0.5051, 1.2992,
         0.9973, 1.4642, 1.4480, 1.4253, 1.0869, 1.4589, 0.7627, 1.4342, 1.4411],
        [1.2814, 1.3112, 1.3767, 1.3488, 1.2779, 1.2850, 1.2859, 1.2787, 1.2787,
         1.3269, 1.3319, 1.3566, 1.3621, 1.3172, 1.2823, 1.3344, 1.2945, 1.2661,
         1.9371, 2.0613, 2.1768, 2.0700, 1.7909, 1.8180, 1.9519, 1.7640, 1.7640,
         1.3428, 1.3568, 1.3244, 1.3570, 1.3438, 1.3421, 1.3547, 1.3347, 1.3298,
         1.3855, 1.4213, 1.4053, 1.3591, 1.4117, 1.4156, 1.3886, 1.2631, 1.2778,
         1.3242, 1.3631, 1.3553, 1.3246, 1.3126, 1.3613, 1.3926, 1.3331, 1.3402],
        [1.3028, 1.3322, 1.2636, 1.2331, 1.3300, 1.3052, 1.3183, 1.2998, 1.2998,
         1.3582, 1.2752, 1.3559, 1.2944, 1.3483, 1.3066, 1.3660, 1.3561, 1.0515,
         1.3530, 1.2728, 1.3950, 1.3626, 1.3158, 1.2759, 1.3415, 1.3135, 1.3135,
         2.2296, 1.8656, 1.7160, 1.8161, 2.1862, 1.7095, 2.1599, 1.7314, 1.7013,
         1.4019, 1.3839, 1.3397, 1.3601, 1.4254, 1.3292, 1.3700, 1.1285, 1.3630,
         1.4387, 1.3079, 1.2072, 1.2980, 1.4342, 1.2179, 1.4764, 1.3075, 1.3644],
        [1.6164, 1.3191, 0.4968, 0.7206, 1.1053, 1.5021, 1.4245, 1.6135, 1.6135,
         1.5864, 1.3699, 1.3392, 0.9520, 1.6464, 0.2143, 1.5002, 1.6470, 1.2286,
         1.1945, 0.8032, 0.7545, 1.0134, 1.4974, 1.5721, 1.2309, 1.6193, 1.6193,
         0.6811, 0.6977, 1.6111, 1.3708, 0.8504, 1.6136, 1.1072, 1.6493, 1.5990,
         1.2855, 0.9408, 0.8888, 1.1946, 1.6207, 1.7830, 1.1467, 3.4110, 3.1706,
         0.7362, 1.2013, 1.2956, 1.5745, 0.9259, 1.5342, 0.3893, 1.5219, 1.6786],
        [1.3455, 1.3742, 1.4435, 1.4119, 1.3787, 1.3443, 1.3189, 1.3432, 1.3432,
         1.3109, 1.3652, 1.2946, 1.4335, 1.3986, 1.4908, 1.3178, 1.4068, 1.3460,
         1.3961, 1.4318, 1.4327, 1.4092, 1.3730, 1.3627, 1.3322, 1.3595, 1.3595,
         1.4002, 1.4555, 1.3713, 1.2326, 1.2780, 1.1786, 1.3981, 1.2553, 1.3764,
         1.4828, 1.2088, 1.5010, 1.4907, 1.1120, 1.0298, 1.4843, 1.3979, 0.9268,
         2.4325, 1.8847, 2.1220, 2.0719, 1.7743, 1.4252, 2.3836, 1.9692, 1.4080]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 45 : 184.00458645481524
Test loss for epoch 45 : 183.92708069579942
Test Precision for epoch 45 : 0.26153846153846155
Test Recall for epoch 45 : 0.26153846153846155
Test F1 for epoch 45 : 0.26153846153846155


theta for epoch 46 : tensor([[1.8617, 1.9500, 2.0472, 2.0500, 2.0417, 1.8803, 1.9404, 1.8593, 1.8593,
         1.3236, 1.3358, 1.3519, 1.3564, 1.3144, 1.3879, 1.3308, 1.3225, 1.3120,
         1.3262, 1.3102, 1.3160, 1.3318, 1.2966, 1.2885, 1.3097, 1.2846, 1.2846,
         1.3102, 1.3871, 1.2983, 1.3263, 1.3742, 1.3119, 1.3254, 1.2679, 1.3032,
         1.3806, 1.4160, 1.3998, 1.3923, 1.4053, 1.3583, 1.3813, 1.4381, 1.3914,
         1.3889, 1.3431, 1.3351, 1.3081, 1.3888, 1.3420, 1.4046, 1.3155, 1.3228],
        [1.3392, 1.1794, 1.0412, 1.2768, 1.3231, 1.3857, 1.3129, 1.3798, 1.3798,
         1.5878, 1.7944, 1.4698, 2.1604, 1.5497, 2.7665, 1.5857, 1.4221, 2.5020,
         1.1862, 1.2424, 0.9095, 1.2010, 1.3391, 1.4039, 1.3784, 1.4006, 1.4006,
         1.3668, 1.1041, 1.4303, 1.3953, 1.1410, 1.4472, 1.4433, 1.4149, 1.3877,
         1.3778, 1.5290, 1.4830, 1.3974, 1.3329, 1.4845, 1.4649, 0.5116, 1.3012,
         1.0030, 1.4612, 1.4454, 1.4237, 1.0899, 1.4564, 0.7689, 1.4321, 1.4392],
        [1.2831, 1.3120, 1.3754, 1.3495, 1.2807, 1.2866, 1.2899, 1.2806, 1.2806,
         1.3285, 1.3344, 1.3574, 1.3625, 1.3190, 1.2893, 1.3357, 1.2975, 1.2670,
         1.9453, 2.0707, 2.1870, 2.0799, 1.7991, 1.8277, 1.9620, 1.7728, 1.7728,
         1.3478, 1.3600, 1.3266, 1.3585, 1.3492, 1.3437, 1.3564, 1.3366, 1.3319,
         1.3822, 1.4183, 1.4023, 1.3569, 1.4079, 1.4113, 1.3852, 1.2675, 1.2826,
         1.3218, 1.3587, 1.3511, 1.3219, 1.3110, 1.3574, 1.3899, 1.3299, 1.3371],
        [1.3036, 1.3322, 1.2637, 1.2347, 1.3306, 1.3063, 1.3188, 1.3007, 1.3007,
         1.3571, 1.2746, 1.3563, 1.2950, 1.3473, 1.3055, 1.3648, 1.3551, 1.0539,
         1.3536, 1.2761, 1.3939, 1.3628, 1.3180, 1.2779, 1.3423, 1.3152, 1.3152,
         2.2460, 1.8767, 1.7249, 1.8262, 2.2026, 1.7184, 2.1757, 1.7406, 1.7102,
         1.3990, 1.3835, 1.3389, 1.3576, 1.4225, 1.3296, 1.3684, 1.1291, 1.3618,
         1.4346, 1.3057, 1.2068, 1.2956, 1.4309, 1.2174, 1.4714, 1.3048, 1.3613],
        [1.6159, 1.3182, 0.4995, 0.7231, 1.1039, 1.5000, 1.4234, 1.6131, 1.6131,
         1.5849, 1.3655, 1.3411, 0.9495, 1.6457, 0.2072, 1.5016, 1.6466, 1.2283,
         1.1958, 0.8034, 0.7475, 1.0118, 1.4975, 1.5746, 1.2349, 1.6214, 1.6214,
         0.6870, 0.7030, 1.6141, 1.3739, 0.8552, 1.6167, 1.1142, 1.6528, 1.6027,
         1.2785, 0.9306, 0.8782, 1.1872, 1.6190, 1.7855, 1.1379, 3.4678, 3.2198,
         0.7284, 1.2018, 1.2938, 1.5689, 0.9213, 1.5301, 0.3811, 1.5196, 1.6741],
        [1.3489, 1.3764, 1.4433, 1.4131, 1.3822, 1.3494, 1.3218, 1.3467, 1.3467,
         1.3104, 1.3661, 1.2942, 1.4343, 1.3965, 1.4939, 1.3170, 1.4046, 1.3439,
         1.3977, 1.4338, 1.4385, 1.4128, 1.3754, 1.3654, 1.3348, 1.3623, 1.3623,
         1.4044, 1.4641, 1.3766, 1.2400, 1.2823, 1.1849, 1.4033, 1.2616, 1.3815,
         1.4762, 1.2058, 1.4947, 1.4851, 1.1099, 1.0285, 1.4777, 1.4015, 0.9290,
         2.4367, 1.8932, 2.1338, 2.0818, 1.7716, 1.4327, 2.3859, 1.9800, 1.4157]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 46 : 183.9758854177082
Test loss for epoch 46 : 183.89976197907947
Test Precision for epoch 46 : 0.26153846153846155
Test Recall for epoch 46 : 0.26153846153846155
Test F1 for epoch 46 : 0.26153846153846155


theta for epoch 47 : tensor([[1.8688, 1.9550, 2.0504, 2.0560, 2.0464, 1.8864, 1.9477, 1.8664, 1.8664,
         1.3233, 1.3348, 1.3508, 1.3553, 1.3144, 1.3864, 1.3302, 1.3223, 1.3098,
         1.3277, 1.3103, 1.3158, 1.3328, 1.2987, 1.2908, 1.3110, 1.2871, 1.2871,
         1.3095, 1.3847, 1.2991, 1.3259, 1.3721, 1.3119, 1.3251, 1.2684, 1.3039,
         1.3799, 1.4155, 1.3995, 1.3913, 1.4038, 1.3572, 1.3807, 1.4378, 1.3913,
         1.3902, 1.3446, 1.3369, 1.3114, 1.3896, 1.3440, 1.4059, 1.3183, 1.3257],
        [1.3452, 1.1877, 1.0467, 1.2816, 1.3300, 1.3911, 1.3186, 1.3853, 1.3853,
         1.5889, 1.7983, 1.4702, 2.1714, 1.5509, 2.7924, 1.5878, 1.4221, 2.5234,
         1.1923, 1.2470, 0.9192, 1.2076, 1.3450, 1.4071, 1.3816, 1.4041, 1.4041,
         1.3647, 1.1055, 1.4285, 1.3940, 1.1422, 1.4449, 1.4415, 1.4124, 1.3865,
         1.3794, 1.5294, 1.4830, 1.3983, 1.3365, 1.4849, 1.4648, 0.5205, 1.3063,
         1.0116, 1.4618, 1.4464, 1.4256, 1.0960, 1.4575, 0.7779, 1.4335, 1.4408],
        [1.2869, 1.3148, 1.3762, 1.3521, 1.2853, 1.2904, 1.2957, 1.2845, 1.2845,
         1.3303, 1.3370, 1.3584, 1.3629, 1.3210, 1.2956, 1.3372, 1.3005, 1.2679,
         1.9523, 2.0788, 2.1958, 2.0886, 1.8064, 1.8364, 1.9711, 1.7806, 1.7806,
         1.3477, 1.3581, 1.3240, 1.3552, 1.3495, 1.3405, 1.3532, 1.3337, 1.3293,
         1.3823, 1.4186, 1.4027, 1.3582, 1.4074, 1.4103, 1.3852, 1.2745, 1.2902,
         1.3236, 1.3587, 1.3512, 1.3237, 1.3131, 1.3580, 1.3911, 1.3311, 1.3385],
        [1.3052, 1.3330, 1.2643, 1.2367, 1.3319, 1.3082, 1.3200, 1.3023, 1.3023,
         1.3555, 1.2735, 1.3561, 1.2950, 1.3459, 1.3037, 1.3631, 1.3536, 1.0554,
         1.3527, 1.2775, 1.3914, 1.3615, 1.3188, 1.2784, 1.3416, 1.3154, 1.3154,
         2.2608, 1.8863, 1.7323, 1.8347, 2.2174, 1.7259, 2.1899, 1.7482, 1.7177,
         1.3990, 1.3858, 1.3411, 1.3580, 1.4223, 1.3327, 1.3697, 1.1320, 1.3631,
         1.4327, 1.3056, 1.2084, 1.2955, 1.4298, 1.2190, 1.4686, 1.3043, 1.3606],
        [1.6163, 1.3180, 0.5017, 0.7255, 1.1033, 1.4987, 1.4232, 1.6136, 1.6136,
         1.5828, 1.3605, 1.3424, 0.9462, 1.6445, 0.1996, 1.5025, 1.6457, 1.2275,
         1.1961, 0.8025, 0.7394, 1.0092, 1.4965, 1.5760, 1.2375, 1.6225, 1.6225,
         0.6868, 0.7025, 1.6117, 1.3712, 0.8541, 1.6142, 1.1150, 1.6506, 1.6009,
         1.2729, 0.9221, 0.8692, 1.1813, 1.6185, 1.7891, 1.1306, 3.5260, 3.2704,
         0.7225, 1.2040, 1.2939, 1.5657, 0.9187, 1.5283, 0.3740, 1.5195, 1.6720],
        [1.3552, 1.3815, 1.4458, 1.4171, 1.3884, 1.3573, 1.3276, 1.3532, 1.3532,
         1.3107, 1.3676, 1.2944, 1.4354, 1.3953, 1.4967, 1.3171, 1.4032, 1.3423,
         1.3991, 1.4353, 1.4432, 1.4158, 1.3777, 1.3680, 1.3374, 1.3651, 1.3651,
         1.4026, 1.4661, 1.3763, 1.2414, 1.2807, 1.1854, 1.4025, 1.2622, 1.3810,
         1.4736, 1.2072, 1.4926, 1.4834, 1.1121, 1.0314, 1.4752, 1.4080, 0.9345,
         2.4405, 1.9018, 2.1456, 2.0917, 1.7690, 1.4405, 2.3877, 1.9907, 1.4236]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 47 : 183.9393731655009
Test loss for epoch 47 : 183.86725181563642
Test Precision for epoch 47 : 0.26153846153846155
Test Recall for epoch 47 : 0.26153846153846155
Test F1 for epoch 47 : 0.26153846153846155


theta for epoch 48 : tensor([[1.8750, 1.9591, 2.0527, 2.0611, 2.0502, 1.8918, 1.9541, 1.8727, 1.8727,
         1.3246, 1.3354, 1.3513, 1.3557, 1.3160, 1.3864, 1.3312, 1.3237, 1.3092,
         1.3272, 1.3086, 1.3140, 1.3320, 1.2990, 1.2912, 1.3107, 1.2878, 1.2878,
         1.3041, 1.3778, 1.2955, 1.3211, 1.3654, 1.3075, 1.3201, 1.2644, 1.3001,
         1.3823, 1.4180, 1.4023, 1.3935, 1.4053, 1.3590, 1.3833, 1.4401, 1.3939,
         1.3959, 1.3506, 1.3431, 1.3192, 1.3949, 1.3504, 1.4116, 1.3256, 1.3332],
        [1.3490, 1.1933, 1.0496, 1.2840, 1.3345, 1.3945, 1.3220, 1.3888, 1.3888,
         1.5916, 1.8038, 1.4724, 2.1839, 1.5538, 2.8195, 1.5917, 1.4240, 2.5464,
         1.1948, 1.2482, 0.9252, 1.2107, 1.3476, 1.4073, 1.3816, 1.4045, 1.4045,
         1.3584, 1.1027, 1.4228, 1.3887, 1.1390, 1.4386, 1.4357, 1.4058, 1.3814,
         1.3826, 1.5315, 1.4847, 1.4008, 1.3418, 1.4871, 1.4663, 0.5300, 1.3133,
         1.0213, 1.4648, 1.4497, 1.4300, 1.1037, 1.4610, 0.7879, 1.4374, 1.4449],
        [1.2901, 1.3171, 1.3764, 1.3540, 1.2891, 1.2936, 1.3006, 1.2878, 1.2878,
         1.3334, 1.3409, 1.3607, 1.3646, 1.3244, 1.3023, 1.3399, 1.3048, 1.2699,
         1.9581, 2.0855, 2.2033, 2.0960, 1.8126, 1.8440, 1.9789, 1.7873, 1.7873,
         1.3442, 1.3527, 1.3183, 1.3487, 1.3463, 1.3341, 1.3468, 1.3275, 1.3234,
         1.3851, 1.4215, 1.4058, 1.3621, 1.4096, 1.4120, 1.3880, 1.2836, 1.3001,
         1.3296, 1.3631, 1.3558, 1.3298, 1.3191, 1.3628, 1.3962, 1.3366, 1.3442],
        [1.3065, 1.3336, 1.2645, 1.2381, 1.3329, 1.3098, 1.3209, 1.3038, 1.3038,
         1.3552, 1.2736, 1.3570, 1.2962, 1.3458, 1.3031, 1.3626, 1.3534, 1.0580,
         1.3506, 1.2775, 1.3877, 1.3589, 1.3182, 1.2776, 1.3396, 1.3144, 1.3144,
         2.2735, 1.8938, 1.7377, 1.8413, 2.2301, 1.7314, 2.2020, 1.7539, 1.7232,
         1.4018, 1.3909, 1.3460, 1.3613, 1.4249, 1.3384, 1.3739, 1.1372, 1.3669,
         1.4339, 1.3085, 1.2129, 1.2986, 1.4317, 1.2235, 1.4689, 1.3070, 1.3630],
        [1.6171, 1.3185, 0.5046, 0.7287, 1.1038, 1.4982, 1.4237, 1.6146, 1.6146,
         1.5822, 1.3571, 1.3454, 0.9448, 1.6446, 0.1943, 1.5049, 1.6463, 1.2283,
         1.1965, 0.8019, 0.7318, 1.0068, 1.4953, 1.5770, 1.2398, 1.6231, 1.6231,
         0.6844, 0.6999, 1.6066, 1.3660, 0.8508, 1.6091, 1.1132, 1.6458, 1.5965,
         1.2664, 0.9132, 0.8600, 1.1746, 1.6169, 1.7914, 1.1226, 3.5839, 3.3205,
         0.7212, 1.2100, 1.2981, 1.5666, 0.9208, 1.5306, 0.3712, 1.5234, 1.6739],
        [1.3601, 1.3853, 1.4469, 1.4198, 1.3929, 1.3636, 1.3319, 1.3582, 1.3582,
         1.3121, 1.3699, 1.2956, 1.4371, 1.3953, 1.4995, 1.3181, 1.4030, 1.3415,
         1.3982, 1.4339, 1.4444, 1.4159, 1.3775, 1.3681, 1.3374, 1.3654, 1.3654,
         1.3960, 1.4628, 1.3713, 1.2378, 1.2743, 1.1810, 1.3970, 1.2580, 1.3759,
         1.4737, 1.2112, 1.4931, 1.4843, 1.1167, 1.0366, 1.4754, 1.4162, 0.9413,
         2.4466, 1.9132, 2.1600, 2.1043, 1.7693, 1.4511, 2.3918, 2.0042, 1.4345]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 48 : 183.8997199530589
Test loss for epoch 48 : 183.83207329436027
Test Precision for epoch 48 : 0.26153846153846155
Test Recall for epoch 48 : 0.26153846153846155
Test F1 for epoch 48 : 0.26153846153846155


theta for epoch 49 : tensor([[1.8820, 1.9639, 2.0557, 2.0668, 2.0547, 1.8979, 1.9612, 1.8797, 1.8797,
         1.3260, 1.3361, 1.3519, 1.3562, 1.3177, 1.3865, 1.3323, 1.3252, 1.3087,
         1.3255, 1.3056, 1.3111, 1.3300, 1.2980, 1.2905, 1.3092, 1.2873, 1.2873,
         1.2997, 1.3721, 1.2929, 1.3174, 1.3598, 1.3041, 1.3162, 1.2613, 1.2972,
         1.3852, 1.4211, 1.4055, 1.3961, 1.4073, 1.3612, 1.3865, 1.4426, 1.3967,
         1.4005, 1.3555, 1.3482, 1.3257, 1.3992, 1.3555, 1.4161, 1.3316, 1.3393],
        [1.3494, 1.1950, 1.0486, 1.2829, 1.3355, 1.3945, 1.3219, 1.3889, 1.3889,
         1.5959, 1.8106, 1.4763, 2.1975, 1.5582, 2.8477, 1.5972, 1.4276, 2.5708,
         1.1951, 1.2474, 0.9289, 1.2119, 1.3485, 1.4059, 1.3800, 1.4033, 1.4033,
         1.3523, 1.0998, 1.4176, 1.3839, 1.1360, 1.4327, 1.4303, 1.3997, 1.3767,
         1.3860, 1.5337, 1.4865, 1.4034, 1.3471, 1.4892, 1.4680, 0.5389, 1.3204,
         1.0289, 1.4665, 1.4518, 1.4331, 1.1092, 1.4632, 0.7962, 1.4400, 1.4476],
        [1.2902, 1.3163, 1.3737, 1.3528, 1.2898, 1.2938, 1.3022, 1.2882, 1.2882,
         1.3364, 1.3446, 1.3628, 1.3662, 1.3277, 1.3083, 1.3426, 1.3089, 1.2716,
         1.9647, 2.0929, 2.2112, 2.1040, 1.8197, 1.8524, 1.9874, 1.7949, 1.7949,
         1.3413, 1.3478, 1.3133, 1.3429, 1.3437, 1.3285, 1.3411, 1.3222, 1.3183,
         1.3883, 1.4249, 1.4093, 1.3664, 1.4121, 1.4139, 1.3912, 1.2924, 1.3098,
         1.3342, 1.3665, 1.3592, 1.3347, 1.3236, 1.3665, 1.3999, 1.3410, 1.3487],
        [1.3061, 1.3325, 1.2630, 1.2377, 1.3322, 1.3097, 1.3202, 1.3035, 1.3035,
         1.3555, 1.2743, 1.3583, 1.2980, 1.3462, 1.3030, 1.3627, 1.3538, 1.0609,
         1.3481, 1.2770, 1.3838, 1.3561, 1.3173, 1.2764, 1.3373, 1.3130, 1.3130,
         2.2861, 1.9015, 1.7433, 1.8480, 2.2427, 1.7372, 2.2141, 1.7598, 1.7289,
         1.4054, 1.3968, 1.3517, 1.3652, 1.4280, 1.3446, 1.3789, 1.1427, 1.3713,
         1.4349, 1.3111, 1.2170, 1.3015, 1.4332, 1.2276, 1.4689, 1.3094, 1.3651],
        [1.6184, 1.3200, 0.5093, 0.7334, 1.1059, 1.4985, 1.4251, 1.6160, 1.6160,
         1.5833, 1.3560, 1.3505, 0.9459, 1.6465, 0.1928, 1.5094, 1.6487, 1.2316,
         1.1991, 0.8040, 0.7271, 1.0070, 1.4956, 1.5794, 1.2438, 1.6251, 1.6251,
         0.6857, 0.7013, 1.6045, 1.3643, 0.8512, 1.6069, 1.1150, 1.6438, 1.5950,
         1.2572, 0.9022, 0.8486, 1.1652, 1.6123, 1.7906, 1.1120, 3.6398, 3.3685,
         0.7234, 1.2180, 1.3043, 1.5695, 0.9260, 1.5348, 0.3720, 1.5291, 1.6774],
        [1.3629, 1.3869, 1.4460, 1.4204, 1.3951, 1.3676, 1.3340, 1.3611, 1.3611,
         1.3145, 1.3730, 1.2978, 1.4396, 1.3965, 1.5025, 1.3202, 1.4040, 1.3418,
         1.3974, 1.4325, 1.4450, 1.4158, 1.3774, 1.3683, 1.3375, 1.3658, 1.3658,
         1.3915, 1.4609, 1.3685, 1.2358, 1.2697, 1.1785, 1.3934, 1.2558, 1.3729,
         1.4751, 1.2165, 1.4948, 1.4863, 1.1224, 1.0428, 1.4768, 1.4247, 0.9485,
         2.4515, 1.9238, 2.1735, 2.1159, 1.7689, 1.4609, 2.3948, 2.0168, 1.4445]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 49 : 183.87137151167607
Test loss for epoch 49 : 183.80751696515512
Test Precision for epoch 49 : 0.26153846153846155
Test Recall for epoch 49 : 0.26153846153846155
Test F1 for epoch 49 : 0.26153846153846155


theta for epoch 50 : tensor([[1.8918, 1.9714, 2.0613, 2.0752, 2.0618, 1.9067, 1.9711, 1.8895, 1.8895,
         1.3256, 1.3350, 1.3508, 1.3548, 1.3175, 1.3848, 1.3315, 1.3248, 1.3063,
         1.3237, 1.3027, 1.3086, 1.3281, 1.2972, 1.2898, 1.3079, 1.2869, 1.2869,
         1.2993, 1.3706, 1.2944, 1.3178, 1.3585, 1.3049, 1.3164, 1.2622, 1.2985,
         1.3866, 1.4226, 1.4074, 1.3973, 1.4078, 1.3618, 1.3881, 1.4432, 1.3976,
         1.3996, 1.3547, 1.3476, 1.3265, 1.3979, 1.3551, 1.4151, 1.3319, 1.3397],
        [1.3488, 1.1956, 1.0466, 1.2809, 1.3355, 1.3938, 1.3210, 1.3883, 1.3883,
         1.5997, 1.8168, 1.4799, 2.2104, 1.5623, 2.8752, 1.6023, 1.4309, 2.5946,
         1.1963, 1.2478, 0.9333, 1.2140, 1.3506, 1.4058, 1.3797, 1.4035, 1.4035,
         1.3500, 1.1005, 1.4162, 1.3828, 1.1366, 1.4307, 1.4286, 1.3974, 1.3759,
         1.3890, 1.5354, 1.4878, 1.4055, 1.3519, 1.4909, 1.4691, 0.5470, 1.3271,
         1.0328, 1.4650, 1.4506, 1.4330, 1.1113, 1.4621, 0.8018, 1.4394, 1.4471],
        [1.2884, 1.3136, 1.3691, 1.3495, 1.2884, 1.2920, 1.3014, 1.2865, 1.2865,
         1.3378, 1.3466, 1.3634, 1.3662, 1.3294, 1.3121, 1.3437, 1.3112, 1.2715,
         1.9728, 2.1017, 2.2205, 2.1135, 1.8284, 1.8625, 1.9975, 1.8042, 1.8042,
         1.3416, 1.3461, 1.3117, 1.3405, 1.3442, 1.3263, 1.3387, 1.3202, 1.3166,
         1.3904, 1.4271, 1.4117, 1.3696, 1.4134, 1.4147, 1.3933, 1.2996, 1.3180,
         1.3338, 1.3649, 1.3578, 1.3347, 1.3226, 1.3653, 1.3983, 1.3403, 1.3481],
        [1.3049, 1.3306, 1.2606, 1.2363, 1.3307, 1.3087, 1.3186, 1.3025, 1.3025,
         1.3552, 1.2744, 1.3589, 1.2991, 1.3461, 1.3023, 1.3622, 1.3535, 1.0629,
         1.3470, 1.2774, 1.3812, 1.3546, 1.3175, 1.2764, 1.3362, 1.3129, 1.3129,
         2.2997, 1.9104, 1.7502, 1.8559, 2.2565, 1.7442, 2.2272, 1.7669, 1.7360,
         1.4082, 1.4019, 1.3567, 1.3685, 1.4304, 1.3499, 1.3831, 1.1471, 1.3747,
         1.4330, 1.3108, 1.2183, 1.3015, 1.4319, 1.2289, 1.4663, 1.3090, 1.3644],
        [1.6204, 1.3226, 0.5152, 0.7393, 1.1095, 1.4999, 1.4277, 1.6181, 1.6181,
         1.5850, 1.3556, 1.3563, 0.9481, 1.6489, 0.1932, 1.5144, 1.6516, 1.2356,
         1.2041, 0.8088, 0.7255, 1.0099, 1.4982, 1.5838, 1.2498, 1.6291, 1.6291,
         0.6922, 0.7079, 1.6074, 1.3680, 0.8567, 1.6099, 1.1222, 1.6468, 1.5986,
         1.2457, 0.8893, 0.8354, 1.1537, 1.6051, 1.7871, 1.0994, 3.6943, 3.4148,
         0.7256, 1.2245, 1.3089, 1.5710, 0.9307, 1.5376, 0.3731, 1.5333, 1.6794],
        [1.3653, 1.3883, 1.4448, 1.4207, 1.3967, 1.3710, 1.3359, 1.3636, 1.3636,
         1.3171, 1.3761, 1.3000, 1.4418, 1.3979, 1.5047, 1.3224, 1.4052, 1.3421,
         1.3993, 1.4334, 1.4475, 1.4179, 1.3798, 1.3710, 1.3401, 1.3687, 1.3687,
         1.3928, 1.4642, 1.3715, 1.2394, 1.2709, 1.1815, 1.3957, 1.2594, 1.3757,
         1.4763, 1.2217, 1.4964, 1.4881, 1.1279, 1.0487, 1.4781, 1.4320, 0.9546,
         2.4531, 1.9310, 2.1835, 2.1241, 1.7654, 1.4673, 2.3945, 2.0260, 1.4511]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 50 : 183.83672557104302
Test loss for epoch 50 : 183.7757798023522
Test Precision for epoch 50 : 0.26153846153846155
Test Recall for epoch 50 : 0.26153846153846155
Test F1 for epoch 50 : 0.26153846153846155


theta for epoch 51 : tensor([[1.9023, 1.9796, 2.0677, 2.0843, 2.0697, 1.9163, 1.9818, 1.9000, 1.9000,
         1.3238, 1.3326, 1.3481, 1.3519, 1.3159, 1.3816, 1.3293, 1.3230, 1.3025,
         1.3226, 1.3005, 1.3069, 1.3269, 1.2970, 1.2898, 1.3072, 1.2870, 1.2870,
         1.3031, 1.3734, 1.3000, 1.3224, 1.3614, 1.3099, 1.3208, 1.2673, 1.3039,
         1.3866, 1.4227, 1.4078, 1.3970, 1.4068, 1.3607, 1.3884, 1.4420, 1.3968,
         1.3961, 1.3515, 1.3446, 1.3247, 1.3942, 1.3521, 1.4116, 1.3296, 1.3375],
        [1.3494, 1.1972, 1.0458, 1.2801, 1.3364, 1.3943, 1.3212, 1.3888, 1.3888,
         1.6016, 1.8210, 1.4818, 2.2212, 1.5646, 2.9007, 1.6057, 1.4325, 2.6165,
         1.1992, 1.2500, 0.9395, 1.2179, 1.3544, 1.4076, 1.3813, 1.4055, 1.4055,
         1.3517, 1.1052, 1.4187, 1.3858, 1.1410, 1.4327, 1.4308, 1.3990, 1.3790,
         1.3916, 1.5366, 1.4887, 1.4073, 1.3563, 1.4920, 1.4699, 0.5551, 1.3336,
         1.0360, 1.4630, 1.4488, 1.4323, 1.1126, 1.4604, 0.8073, 1.4383, 1.4460],
        [1.2868, 1.3111, 1.3650, 1.3465, 1.2870, 1.2904, 1.3006, 1.2850, 1.2850,
         1.3381, 1.3474, 1.3628, 1.3651, 1.3299, 1.3143, 1.3436, 1.3123, 1.2701,
         1.9807, 2.1101, 2.2294, 2.1226, 1.8370, 1.8724, 2.0073, 1.8133, 1.8133,
         1.3453, 1.3477, 1.3137, 1.3416, 1.3481, 1.3276, 1.3399, 1.3217, 1.3184,
         1.3916, 1.4283, 1.4132, 1.3718, 1.4137, 1.4145, 1.3945, 1.3052, 1.3246,
         1.3314, 1.3616, 1.3546, 1.3328, 1.3195, 1.3623, 1.3947, 1.3380, 1.3458],
        [1.3046, 1.3296, 1.2590, 1.2356, 1.3300, 1.3086, 1.3179, 1.3023, 1.3023,
         1.3547, 1.2743, 1.3593, 1.3001, 1.3459, 1.3016, 1.3614, 1.3531, 1.0647,
         1.3476, 1.2794, 1.3806, 1.3549, 1.3195, 1.2781, 1.3370, 1.3145, 1.3145,
         2.3129, 1.9190, 1.7570, 1.8636, 2.2698, 1.7511, 2.2399, 1.7739, 1.7429,
         1.4105, 1.4063, 1.3612, 1.3712, 1.4321, 1.3544, 1.3869, 1.1507, 1.3772,
         1.4306, 1.3099, 1.2190, 1.3010, 1.4299, 1.2296, 1.4630, 1.3080, 1.3631],
        [1.6221, 1.3247, 0.5197, 0.7441, 1.1126, 1.5010, 1.4299, 1.6199, 1.6199,
         1.5853, 1.3540, 1.3608, 0.9487, 1.6500, 0.1925, 1.5182, 1.6533, 1.2383,
         1.2092, 0.8134, 0.7240, 1.0128, 1.5009, 1.5884, 1.2555, 1.6332, 1.6332,
         0.7001, 0.7163, 1.6133, 1.3745, 0.8641, 1.6158, 1.1317, 1.6526, 1.6050,
         1.2342, 0.8768, 0.8226, 1.1423, 1.5977, 1.7834, 1.0868, 3.7493, 3.4614,
         0.7260, 1.2285, 1.3113, 1.5708, 0.9331, 1.5385, 0.3721, 1.5355, 1.6797],
        [1.3664, 1.3884, 1.4424, 1.4198, 1.3968, 1.3728, 1.3362, 1.3648, 1.3648,
         1.3174, 1.3768, 1.3000, 1.4416, 1.3974, 1.5042, 1.3225, 1.4045, 1.3401,
         1.4011, 1.4341, 1.4494, 1.4196, 1.3821, 1.3735, 1.3426, 1.3715, 1.3715,
         1.3976, 1.4704, 1.3781, 1.2461, 1.2753, 1.1875, 1.4014, 1.2662, 1.3821,
         1.4758, 1.2249, 1.4963, 1.4881, 1.1311, 1.0522, 1.4778, 1.4367, 0.9579,
         2.4558, 1.9394, 2.1949, 2.1337, 1.7634, 1.4750, 2.3952, 2.0364, 1.4589]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 51 : 183.8060185677351
Test loss for epoch 51 : 183.7463031340129
Test Precision for epoch 51 : 0.26153846153846155
Test Recall for epoch 51 : 0.26153846153846155
Test F1 for epoch 51 : 0.26153846153846155


theta for epoch 52 : tensor([[1.9107, 1.9856, 2.0719, 2.0912, 2.0754, 1.9238, 1.9903, 1.9084, 1.9084,
         1.3230, 1.3313, 1.3466, 1.3501, 1.3154, 1.3797, 1.3282, 1.3223, 1.2999,
         1.3221, 1.2991, 1.3062, 1.3264, 1.2975, 1.2904, 1.3073, 1.2878, 1.2878,
         1.3086, 1.3781, 1.3072, 1.3287, 1.3661, 1.3165, 1.3267, 1.2739, 1.3110,
         1.3863, 1.4224, 1.4079, 1.3965, 1.4054, 1.3592, 1.3884, 1.4400, 1.3952,
         1.3948, 1.3505, 1.3438, 1.3251, 1.3928, 1.3513, 1.4102, 1.3296, 1.3375],
        [1.3512, 1.1998, 1.0462, 1.2807, 1.3385, 1.3960, 1.3227, 1.3905, 1.3905,
         1.6025, 1.8239, 1.4827, 2.2304, 1.5659, 2.9247, 1.6080, 1.4332, 2.6371,
         1.2021, 1.2523, 0.9457, 1.2218, 1.3583, 1.4096, 1.3830, 1.4078, 1.4078,
         1.3544, 1.1108, 1.4224, 1.3899, 1.1465, 1.4358, 1.4341, 1.4018, 1.3832,
         1.3939, 1.5373, 1.4892, 1.4088, 1.3602, 1.4927, 1.4704, 0.5630, 1.3397,
         1.0405, 1.4627, 1.4489, 1.4334, 1.1153, 1.4606, 0.8142, 1.4389, 1.4467],
        [1.2872, 1.3107, 1.3630, 1.3453, 1.2875, 1.2909, 1.3015, 1.2854, 1.2854,
         1.3395, 1.3493, 1.3634, 1.3651, 1.3316, 1.3170, 1.3447, 1.3145, 1.2699,
         1.9863, 2.1161, 2.2358, 2.1292, 1.8433, 1.8801, 2.0147, 1.8202, 1.8202,
         1.3503, 1.3507, 1.3172, 1.3443, 1.3533, 1.3305, 1.3426, 1.3249, 1.3218,
         1.3927, 1.4293, 1.4146, 1.3739, 1.4138, 1.4140, 1.3957, 1.3102, 1.3306,
         1.3315, 1.3609, 1.3541, 1.3335, 1.3187, 1.3620, 1.3933, 1.3382, 1.3461],
        [1.3065, 1.3308, 1.2596, 1.2368, 1.3315, 1.3106, 1.3193, 1.3043, 1.3043,
         1.3559, 1.2759, 1.3611, 1.3027, 1.3472, 1.3025, 1.3623, 1.3543, 1.0680,
         1.3498, 1.2829, 1.3817, 1.3568, 1.3229, 1.2813, 1.3393, 1.3176, 1.3176,
         2.3234, 1.9252, 1.7614, 1.8688, 2.2805, 1.7556, 2.2501, 1.7785, 1.7475,
         1.4131, 1.4110, 1.3659, 1.3742, 1.4339, 1.3589, 1.3909, 1.1545, 1.3798,
         1.4304, 1.3113, 1.2219, 1.3029, 1.4302, 1.2327, 1.4620, 1.3095, 1.3643],
        [1.6225, 1.3248, 0.5207, 0.7458, 1.1133, 1.5008, 1.4305, 1.6204, 1.6204,
         1.5842, 1.3507, 1.3635, 0.9470, 1.6498, 0.1889, 1.5204, 1.6537, 1.2391,
         1.2119, 0.8149, 0.7196, 1.0131, 1.5017, 1.5910, 1.2586, 1.6355, 1.6355,
         0.7047, 0.7215, 1.6181, 1.3794, 0.8686, 1.6207, 1.1386, 1.6575, 1.6104,
         1.2248, 0.8665, 0.8121, 1.1329, 1.5922, 1.7815, 1.0764, 3.8064, 3.5102,
         0.7239, 1.2304, 1.3118, 1.5698, 0.9332, 1.5384, 0.3678, 1.5365, 1.6793],
        [1.3656, 1.3867, 1.4386, 1.4172, 1.3950, 1.3726, 1.3347, 1.3640, 1.3640,
         1.3161, 1.3756, 1.2981, 1.4397, 1.3956, 1.5015, 1.3208, 1.4024, 1.3365,
         1.4005, 1.4321, 1.4481, 1.4185, 1.3818, 1.3735, 1.3423, 1.3716, 1.3716,
         1.4015, 1.4754, 1.3839, 1.2513, 1.2786, 1.1923, 1.4063, 1.2719, 1.3877,
         1.4734, 1.2258, 1.4943, 1.4861, 1.1318, 1.0529, 1.4756, 1.4384, 0.9578,
         2.4627, 1.9526, 2.2107, 2.1477, 1.7662, 1.4871, 2.4003, 2.0515, 1.4714]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 52 : 183.77366303253274
Test loss for epoch 52 : 183.71470604562097
Test Precision for epoch 52 : 0.26153846153846155
Test Recall for epoch 52 : 0.26153846153846155
Test F1 for epoch 52 : 0.26153846153846155


theta for epoch 53 : tensor([[1.9173, 1.9899, 2.0745, 2.0963, 2.0793, 1.9296, 1.9971, 1.9151, 1.9151,
         1.3250, 1.3328, 1.3478, 1.3510, 1.3177, 1.3805, 1.3299, 1.3244, 1.3002,
         1.3225, 1.2988, 1.3068, 1.3269, 1.2989, 1.2919, 1.3084, 1.2895, 1.2895,
         1.3123, 1.3811, 1.3126, 1.3333, 1.3692, 1.3215, 1.3309, 1.2788, 1.3162,
         1.3861, 1.4220, 1.4080, 1.3959, 1.4040, 1.3576, 1.3884, 1.4377, 1.3933,
         1.3958, 1.3517, 1.3452, 1.3276, 1.3936, 1.3528, 1.4111, 1.3317, 1.3396],
        [1.3541, 1.2032, 1.0474, 1.2823, 1.3416, 1.3990, 1.3253, 1.3935, 1.3935,
         1.6039, 1.8272, 1.4843, 2.2399, 1.5677, 2.9489, 1.6109, 1.4346, 2.6581,
         1.2041, 1.2541, 0.9510, 1.2250, 1.3616, 1.4113, 1.3844, 1.4096, 1.4096,
         1.3552, 1.1144, 1.4243, 1.3921, 1.1499, 1.4372, 1.4356, 1.4028, 1.3857,
         1.3956, 1.5374, 1.4891, 1.4096, 1.3633, 1.4926, 1.4702, 0.5698, 1.3452,
         1.0451, 1.4633, 1.4498, 1.4354, 1.1184, 1.4616, 0.8214, 1.4404, 1.4483],
        [1.2901, 1.3129, 1.3638, 1.3467, 1.2905, 1.2938, 1.3047, 1.2884, 1.2884,
         1.3433, 1.3534, 1.3663, 1.3674, 1.3356, 1.3213, 1.3481, 1.3190, 1.2720,
         1.9903, 2.1204, 2.2404, 2.1342, 1.8482, 1.8863, 2.0205, 1.8256, 1.8256,
         1.3540, 1.3524, 1.3196, 1.3458, 1.3571, 1.3323, 1.3441, 1.3269, 1.3240,
         1.3938, 1.4303, 1.4159, 1.3758, 1.4137, 1.4134, 1.3968, 1.3145, 1.3360,
         1.3336, 1.3624, 1.3557, 1.3362, 1.3197, 1.3637, 1.3938, 1.3404, 1.3484],
        [1.3107, 1.3344, 1.2625, 1.2401, 1.3353, 1.3149, 1.3231, 1.3086, 1.3086,
         1.3594, 1.2799, 1.3651, 1.3076, 1.3509, 1.3057, 1.3655, 1.3579, 1.0735,
         1.3533, 1.2874, 1.3842, 1.3600, 1.3275, 1.2857, 1.3427, 1.3219, 1.3219,
         2.3313, 1.9288, 1.7632, 1.8715, 2.2886, 1.7577, 2.2576, 1.7805, 1.7496,
         1.4159, 1.4158, 1.3709, 1.3774, 1.4359, 1.3634, 1.3952, 1.1582, 1.3824,
         1.4321, 1.3144, 1.2265, 1.3067, 1.4321, 1.2374, 1.4629, 1.3128, 1.3673],
        [1.6224, 1.3237, 0.5189, 0.7450, 1.1124, 1.5000, 1.4303, 1.6204, 1.6204,
         1.5828, 1.3468, 1.3655, 0.9438, 1.6493, 0.1833, 1.5222, 1.6539, 1.2390,
         1.2124, 0.8136, 0.7127, 1.0111, 1.5007, 1.5919, 1.2593, 1.6362, 1.6362,
         0.7038, 0.7215, 1.6195, 1.3803, 0.8681, 1.6221, 1.1406, 1.6589, 1.6122,
         1.2175, 0.8586, 0.8038, 1.1257, 1.5888, 1.7815, 1.0682, 3.8656, 3.5611,
         0.7194, 1.2301, 1.3106, 1.5679, 0.9308, 1.5372, 0.3604, 1.5363, 1.6781],
        [1.3664, 1.3869, 1.4369, 1.4166, 1.3947, 1.3738, 1.3349, 1.3649, 1.3649,
         1.3166, 1.3762, 1.2980, 1.4393, 1.3957, 1.5001, 1.3209, 1.4024, 1.3348,
         1.3999, 1.4300, 1.4464, 1.4171, 1.3814, 1.3733, 1.3418, 1.3716, 1.3716,
         1.4031, 1.4775, 1.3873, 1.2539, 1.2795, 1.1944, 1.4086, 1.2751, 1.3909,
         1.4705, 1.2261, 1.4918, 1.4835, 1.1316, 1.0527, 1.4729, 1.4386, 0.9564,
         2.4697, 1.9659, 2.2267, 2.1620, 1.7695, 1.4996, 2.4055, 2.0668, 1.4840]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 53 : 183.74067640927188
Test loss for epoch 53 : 183.68502024842684
Test Precision for epoch 53 : 0.26153846153846155
Test Recall for epoch 53 : 0.26153846153846155
Test F1 for epoch 53 : 0.26153846153846155


theta for epoch 54 : tensor([[1.9241, 1.9944, 2.0772, 2.1016, 2.0834, 1.9357, 2.0040, 1.9219, 1.9219,
         1.3288, 1.3362, 1.3509, 1.3538, 1.3217, 1.3833, 1.3333, 1.3282, 1.3023,
         1.3241, 1.2999, 1.3088, 1.3287, 1.3015, 1.2946, 1.3107, 1.2922, 1.2922,
         1.3136, 1.3818, 1.3155, 1.3355, 1.3699, 1.3240, 1.3326, 1.2812, 1.3189,
         1.3854, 1.4212, 1.4077, 1.3950, 1.4021, 1.3556, 1.3880, 1.4347, 1.3908,
         1.3970, 1.3532, 1.3468, 1.3301, 1.3948, 1.3544, 1.4124, 1.3338, 1.3418],
        [1.3578, 1.2071, 1.0493, 1.2849, 1.3454, 1.4028, 1.3287, 1.3974, 1.3974,
         1.6060, 1.8311, 1.4868, 2.2499, 1.5704, 2.9735, 1.6147, 1.4370, 2.6797,
         1.2059, 1.2558, 0.9560, 1.2280, 1.3650, 1.4131, 1.3859, 1.4116, 1.4116,
         1.3540, 1.1157, 1.4243, 1.3924, 1.1511, 1.4366, 1.4350, 1.4019, 1.3861,
         1.3965, 1.5367, 1.4882, 1.4096, 1.3656, 1.4918, 1.4693, 0.5753, 1.3499,
         1.0486, 1.4636, 1.4503, 1.4369, 1.1206, 1.4622, 0.8277, 1.4415, 1.4494],
        [1.2940, 1.3161, 1.3660, 1.3493, 1.2944, 1.2978, 1.3086, 1.2924, 1.2924,
         1.3479, 1.3582, 1.3701, 1.3707, 1.3405, 1.3260, 1.3523, 1.3241, 1.2749,
         1.9951, 2.1253, 2.2456, 2.1398, 1.8538, 1.8933, 2.0270, 1.8319, 1.8319,
         1.3553, 1.3518, 1.3199, 1.3453, 1.3585, 1.3321, 1.3434, 1.3268, 1.3241,
         1.3940, 1.4304, 1.4164, 1.3770, 1.4129, 1.4120, 1.3971, 1.3175, 1.3401,
         1.3352, 1.3633, 1.3568, 1.3383, 1.3200, 1.3649, 1.3937, 1.3420, 1.3500],
        [1.3153, 1.3385, 1.2657, 1.2437, 1.3396, 1.3196, 1.3274, 1.3133, 1.3133,
         1.3633, 1.2843, 1.3694, 1.3129, 1.3551, 1.3093, 1.3691, 1.3619, 1.0790,
         1.3567, 1.2915, 1.3867, 1.3631, 1.3318, 1.2898, 1.3461, 1.3259, 1.3259,
         2.3391, 1.9325, 1.7653, 1.8742, 2.2966, 1.7599, 2.2652, 1.7827, 1.7518,
         1.4176, 1.4194, 1.3746, 1.3794, 1.4366, 1.3665, 1.3983, 1.1603, 1.3836,
         1.4331, 1.3168, 1.2302, 1.3097, 1.4335, 1.2412, 1.4633, 1.3154, 1.3696],
        [1.6234, 1.3236, 0.5171, 0.7446, 1.1124, 1.5004, 1.4312, 1.6215, 1.6215,
         1.5820, 1.3438, 1.3680, 0.9411, 1.6495, 0.1783, 1.5246, 1.6549, 1.2396,
         1.2133, 0.8123, 0.7063, 1.0093, 1.5000, 1.5931, 1.2600, 1.6372, 1.6372,
         0.7002, 0.7190, 1.6189, 1.3791, 0.8651, 1.6215, 1.1399, 1.6583, 1.6120,
         1.2100, 0.8508, 0.7957, 1.1183, 1.5849, 1.7811, 1.0599, 3.9250, 3.6122,
         0.7147, 1.2291, 1.3087, 1.5660, 0.9281, 1.5358, 0.3526, 1.5358, 1.6769],
        [1.3714, 1.3913, 1.4396, 1.4203, 1.3986, 1.3790, 1.3393, 1.3699, 1.3699,
         1.3207, 1.3802, 1.3015, 1.4423, 1.3994, 1.5017, 1.3247, 1.4059, 1.3368,
         1.4027, 1.4313, 1.4478, 1.4190, 1.3844, 1.3764, 1.3448, 1.3749, 1.3749,
         1.4041, 1.4786, 1.3901, 1.2559, 1.2800, 1.1962, 1.4103, 1.2777, 1.3936,
         1.4685, 1.2274, 1.4902, 1.4817, 1.1325, 1.0535, 1.4711, 1.4388, 0.9555,
         2.4718, 1.9742, 2.2377, 2.1712, 1.7682, 1.5069, 2.4058, 2.0770, 1.4916]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 54 : 183.71202463349462
Test loss for epoch 54 : 183.66239132187002
Test Precision for epoch 54 : 0.26153846153846155
Test Recall for epoch 54 : 0.26153846153846155
Test F1 for epoch 54 : 0.26153846153846155


theta for epoch 55 : tensor([[1.9312, 1.9991, 2.0802, 2.1070, 2.0878, 1.9419, 2.0112, 1.9290, 1.9290,
         1.3321, 1.3391, 1.3534, 1.3561, 1.3251, 1.3858, 1.3362, 1.3315, 1.3041,
         1.3260, 1.3015, 1.3114, 1.3308, 1.3043, 1.2975, 1.3134, 1.2952, 1.2952,
         1.3143, 1.3820, 1.3176, 1.3369, 1.3700, 1.3258, 1.3336, 1.2828, 1.3208,
         1.3845, 1.4202, 1.4072, 1.3939, 1.4000, 1.3532, 1.3874, 1.4312, 1.3879,
         1.3992, 1.3554, 1.3492, 1.3331, 1.3970, 1.3566, 1.4146, 1.3365, 1.3445],
        [1.3613, 1.2108, 1.0513, 1.2874, 1.3490, 1.4066, 1.3319, 1.4011, 1.4011,
         1.6078, 1.8345, 1.4891, 2.2592, 1.5727, 2.9974, 1.6182, 1.4391, 2.7008,
         1.2079, 1.2579, 0.9612, 1.2313, 1.3686, 1.4153, 1.3878, 1.4140, 1.4140,
         1.3527, 1.1168, 1.4241, 1.3927, 1.1521, 1.4360, 1.4343, 1.4009, 1.3865,
         1.3973, 1.5359, 1.4873, 1.4096, 1.3677, 1.4909, 1.4684, 0.5805, 1.3546,
         1.0527, 1.4650, 1.4518, 1.4393, 1.1233, 1.4638, 0.8348, 1.4435, 1.4514],
        [1.2965, 1.3182, 1.3672, 1.3507, 1.2970, 1.3004, 1.3110, 1.2950, 1.2950,
         1.3510, 1.3616, 1.3725, 1.3726, 1.3438, 1.3291, 1.3551, 1.3276, 1.2762,
         2.0012, 2.1315, 2.2520, 2.1466, 1.8609, 1.9017, 2.0348, 1.8395, 1.8395,
         1.3556, 1.3502, 1.3193, 1.3438, 1.3589, 1.3310, 1.3419, 1.3259, 1.3233,
         1.3935, 1.4297, 1.4162, 1.3773, 1.4112, 1.4098, 1.3968, 1.3192, 1.3429,
         1.3367, 1.3642, 1.3578, 1.3400, 1.3200, 1.3659, 1.3936, 1.3434, 1.3514],
        [1.3174, 1.3402, 1.2666, 1.2447, 1.3414, 1.3218, 1.3291, 1.3155, 1.3155,
         1.3651, 1.2863, 1.3715, 1.3159, 1.3571, 1.3108, 1.3705, 1.3637, 1.0816,
         1.3579, 1.2934, 1.3874, 1.3641, 1.3338, 1.2915, 1.3473, 1.3277, 1.3277,
         2.3495, 1.9389, 1.7700, 1.8797, 2.3072, 1.7649, 2.2752, 1.7877, 1.7568,
         1.4175, 1.4210, 1.3763, 1.3795, 1.4355, 1.3674, 1.3995, 1.1601, 1.3828,
         1.4330, 1.3176, 1.2321, 1.3111, 1.4335, 1.2433, 1.4627, 1.3163, 1.3704],
        [1.6261, 1.3255, 0.5179, 0.7465, 1.1148, 1.5028, 1.4342, 1.6243, 1.6243,
         1.5823, 1.3422, 1.3716, 0.9401, 1.6507, 0.1762, 1.5282, 1.6569, 1.2414,
         1.2163, 0.8137, 0.7032, 1.0102, 1.5013, 1.5960, 1.2624, 1.6398, 1.6398,
         0.6987, 0.7188, 1.6196, 1.3794, 0.8640, 1.6223, 1.1406, 1.6589, 1.6130,
         1.1999, 0.8409, 0.7855, 1.1085, 1.5781, 1.7775, 1.0492, 3.9825, 3.6610,
         0.7137, 1.2307, 1.3095, 1.5667, 0.9289, 1.5369, 0.3490, 1.5378, 1.6781],
        [1.3773, 1.3969, 1.4439, 1.4253, 1.4036, 1.3850, 1.3447, 1.3758, 1.3758,
         1.3255, 1.3848, 1.3058, 1.4460, 1.4039, 1.5036, 1.3292, 1.4102, 1.3398,
         1.4073, 1.4345, 1.4508, 1.4226, 1.3891, 1.3813, 1.3496, 1.3799, 1.3799,
         1.4057, 1.4798, 1.3934, 1.2583, 1.2813, 1.1986, 1.4126, 1.2810, 1.3968,
         1.4671, 1.2293, 1.4893, 1.4804, 1.1338, 1.0548, 1.4700, 1.4390, 0.9548,
         2.4716, 1.9801, 2.2461, 2.1779, 1.7650, 1.5118, 2.4040, 2.0848, 1.4967]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 55 : 183.68387246597172
Test loss for epoch 55 : 183.6387910013833
Test Precision for epoch 55 : 0.26153846153846155
Test Recall for epoch 55 : 0.26153846153846155
Test F1 for epoch 55 : 0.26153846153846155


theta for epoch 56 : tensor([[1.9380, 2.0036, 2.0831, 2.1122, 2.0919, 1.9480, 2.0182, 1.9358, 1.9358,
         1.3336, 1.3403, 1.3543, 1.3567, 1.3267, 1.3868, 1.3373, 1.3329, 1.3042,
         1.3267, 1.3019, 1.3130, 1.3318, 1.3057, 1.2989, 1.3148, 1.2967, 1.2967,
         1.3152, 1.3825, 1.3197, 1.3386, 1.3704, 1.3279, 1.3348, 1.2845, 1.3228,
         1.3846, 1.4201, 1.4077, 1.3937, 1.3989, 1.3518, 1.3877, 1.4287, 1.3858,
         1.4031, 1.3592, 1.3531, 1.3375, 1.4009, 1.3604, 1.4187, 1.3406, 1.3486],
        [1.3635, 1.2132, 1.0525, 1.2890, 1.3514, 1.4091, 1.3340, 1.4035, 1.4035,
         1.6083, 1.8364, 1.4902, 2.2669, 1.5739, 3.0198, 1.6205, 1.4402, 2.7205,
         1.2092, 1.2597, 0.9660, 1.2341, 1.3716, 1.4171, 1.3894, 1.4159, 1.4159,
         1.3522, 1.1186, 1.4249, 1.3937, 1.1539, 1.4363, 1.4344, 1.4008, 1.3877,
         1.3993, 1.5363, 1.4875, 1.4107, 1.3709, 1.4912, 1.4686, 0.5864, 1.3604,
         1.0587, 1.4685, 1.4554, 1.4437, 1.1280, 1.4674, 0.8435, 1.4475, 1.4554],
        [1.2969, 1.3182, 1.3667, 1.3502, 1.2976, 1.3008, 1.3111, 1.2954, 1.2954,
         1.3521, 1.3628, 1.3729, 1.3727, 1.3451, 1.3301, 1.3558, 1.3290, 1.2756,
         2.0073, 2.1376, 2.2582, 2.1533, 1.8680, 1.9101, 2.0425, 1.8472, 1.8472,
         1.3560, 1.3487, 1.3189, 1.3428, 1.3594, 1.3302, 1.3407, 1.3252, 1.3229,
         1.3938, 1.4299, 1.4168, 1.3784, 1.4104, 1.4085, 1.3972, 1.3211, 1.3460,
         1.3397, 1.3667, 1.3603, 1.3432, 1.3214, 1.3683, 1.3950, 1.3462, 1.3542],
        [1.3163, 1.3387, 1.2644, 1.2426, 1.3401, 1.3207, 1.3277, 1.3144, 1.3144,
         1.3641, 1.2854, 1.3708, 1.3161, 1.3562, 1.3096, 1.3692, 1.3626, 1.0811,
         1.3563, 1.2924, 1.3854, 1.3624, 1.3329, 1.2902, 1.3457, 1.3266, 1.3266,
         2.3621, 1.9478, 1.7772, 1.8876, 2.3201, 1.7723, 2.2876, 1.7950, 1.7642,
         1.4169, 1.4222, 1.3775, 1.3792, 1.4340, 1.3677, 1.4003, 1.1589, 1.3814,
         1.4327, 1.3180, 1.2334, 1.3121, 1.4334, 1.2447, 1.4619, 1.3169, 1.3709],
        [1.6297, 1.3287, 0.5209, 0.7503, 1.1190, 1.5064, 1.4384, 1.6279, 1.6279,
         1.5830, 1.3416, 1.3759, 0.9405, 1.6523, 0.1767, 1.5322, 1.6594, 1.2441,
         1.2211, 0.8172, 0.7030, 1.0133, 1.5039, 1.6000, 1.2662, 1.6435, 1.6435,
         0.7005, 0.7222, 1.6225, 1.3824, 0.8660, 1.6252, 1.1440, 1.6617, 1.6162,
         1.1873, 0.8290, 0.7733, 1.0962, 1.5684, 1.7709, 1.0361, 4.0379, 3.7076,
         0.7178, 1.2359, 1.3139, 1.5710, 0.9346, 1.5415, 0.3509, 1.5432, 1.6826],
        [1.3800, 1.3994, 1.4455, 1.4275, 1.4054, 1.3876, 1.3470, 1.3785, 1.3785,
         1.3278, 1.3868, 1.3076, 1.4471, 1.4061, 1.5031, 1.3312, 1.4123, 1.3403,
         1.4101, 1.4358, 1.4517, 1.4241, 1.3918, 1.3840, 1.3522, 1.3827, 1.3827,
         1.4073, 1.4806, 1.3966, 1.2603, 1.2823, 1.2005, 1.4147, 1.2838, 1.3997,
         1.4666, 1.2316, 1.4891, 1.4799, 1.1353, 1.0561, 1.4697, 1.4391, 0.9537,
         2.4738, 1.9884, 2.2570, 2.1871, 1.7646, 1.5191, 2.4045, 2.0950, 1.5042]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 56 : 183.65172270552435
Test loss for epoch 56 : 183.60729965607467
Test Precision for epoch 56 : 0.26153846153846155
Test Recall for epoch 56 : 0.26153846153846155
Test F1 for epoch 56 : 0.26153846153846155


theta for epoch 57 : tensor([[1.9455, 2.0088, 2.0868, 2.1182, 2.0969, 1.9548, 2.0260, 1.9434, 1.9434,
         1.3336, 1.3402, 1.3538, 1.3561, 1.3268, 1.3867, 1.3370, 1.3329, 1.3031,
         1.3254, 1.3006, 1.3128, 1.3309, 1.3051, 1.2983, 1.3142, 1.2961, 1.2961,
         1.3154, 1.3824, 1.3209, 1.3394, 1.3702, 1.3290, 1.3351, 1.2852, 1.3239,
         1.3866, 1.4220, 1.4100, 1.3955, 1.3997, 1.3523, 1.3900, 1.4281, 1.3856,
         1.4060, 1.3619, 1.3559, 1.3407, 1.4038, 1.3631, 1.4219, 1.3435, 1.3514],
        [1.3644, 1.2143, 1.0528, 1.2895, 1.3524, 1.4104, 1.3347, 1.4047, 1.4047,
         1.6084, 1.8378, 1.4911, 2.2740, 1.5746, 3.0415, 1.6225, 1.4409, 2.7398,
         1.2091, 1.2602, 0.9694, 1.2355, 1.3733, 1.4176, 1.3897, 1.4166, 1.4166,
         1.3518, 1.1202, 1.4256, 1.3948, 1.1555, 1.4366, 1.4346, 1.4007, 1.3888,
         1.4032, 1.5386, 1.4897, 1.4137, 1.3759, 1.4934, 1.4707, 0.5934, 1.3681,
         1.0641, 1.4719, 1.4589, 1.4478, 1.1322, 1.4709, 0.8519, 1.4513, 1.4592],
        [1.2964, 1.3175, 1.3657, 1.3490, 1.2974, 1.3004, 1.3103, 1.2949, 1.2949,
         1.3526, 1.3634, 1.3728, 1.3723, 1.3456, 1.3305, 1.3560, 1.3297, 1.2744,
         2.0123, 2.1424, 2.2632, 2.1589, 1.8741, 1.9174, 2.0490, 1.8538, 1.8538,
         1.3566, 1.3475, 1.3189, 1.3420, 1.3599, 1.3297, 1.3398, 1.3249, 1.3226,
         1.3962, 1.4321, 1.4195, 1.3816, 1.4117, 1.4093, 1.3998, 1.3247, 1.3509,
         1.3430, 1.3694, 1.3631, 1.3463, 1.3229, 1.3709, 1.3966, 1.3490, 1.3570],
        [1.3144, 1.3365, 1.2616, 1.2397, 1.3380, 1.3188, 1.3255, 1.3125, 1.3125,
         1.3627, 1.2841, 1.3696, 1.3159, 1.3549, 1.3082, 1.3674, 1.3612, 1.0800,
         1.3539, 1.2905, 1.3828, 1.3600, 1.3310, 1.2879, 1.3432, 1.3244, 1.3244,
         2.3741, 1.9561, 1.7840, 1.8949, 2.3324, 1.7793, 2.2993, 1.8019, 1.7713,
         1.4185, 1.4254, 1.3807, 1.3809, 1.4345, 1.3699, 1.4031, 1.1596, 1.3821,
         1.4325, 1.3183, 1.2345, 1.3129, 1.4332, 1.2459, 1.4613, 1.3173, 1.3712],
        [1.6330, 1.3317, 0.5239, 0.7541, 1.1230, 1.5099, 1.4424, 1.6312, 1.6312,
         1.5837, 1.3412, 1.3800, 0.9409, 1.6537, 0.1779, 1.5360, 1.6618, 1.2467,
         1.2256, 0.8206, 0.7034, 1.0163, 1.5061, 1.6035, 1.2694, 1.6468, 1.6468,
         0.7026, 0.7259, 1.6258, 1.3857, 0.8682, 1.6286, 1.1474, 1.6648, 1.6197,
         1.1746, 0.8172, 0.7614, 1.0839, 1.5583, 1.7637, 1.0231, 4.0935, 3.7540,
         0.7227, 1.2413, 1.3187, 1.5759, 0.9409, 1.5466, 0.3540, 1.5489, 1.6876],
        [1.3800, 1.3995, 1.4450, 1.4274, 1.4048, 1.3875, 1.3467, 1.3785, 1.3785,
         1.3285, 1.3873, 1.3078, 1.4468, 1.4070, 1.5010, 1.3316, 1.4130, 1.3395,
         1.4106, 1.4350, 1.4503, 1.4233, 1.3921, 1.3844, 1.3525, 1.3832, 1.3832,
         1.4080, 1.4803, 1.3987, 1.2610, 1.2824, 1.2013, 1.4159, 1.2855, 1.4018,
         1.4679, 1.2354, 1.4908, 1.4812, 1.1383, 1.0587, 1.4713, 1.4404, 0.9536,
         2.4772, 1.9982, 2.2692, 2.1976, 1.7658, 1.5276, 2.4063, 2.1065, 1.5130]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 57 : 183.62493943353027
Test loss for epoch 57 : 183.5807169731168
Test Precision for epoch 57 : 0.26153846153846155
Test Recall for epoch 57 : 0.26153846153846155
Test F1 for epoch 57 : 0.26153846153846155


theta for epoch 58 : tensor([[1.9539, 2.0150, 2.0915, 2.1251, 2.1027, 1.9625, 2.0346, 1.9518, 1.9518,
         1.3338, 1.3403, 1.3534, 1.3556, 1.3271, 1.3868, 1.3369, 1.3331, 1.3022,
         1.3238, 1.2991, 1.3124, 1.3297, 1.3040, 1.2972, 1.3133, 1.2950, 1.2950,
         1.3144, 1.3812, 1.3206, 1.3389, 1.3688, 1.3286, 1.3341, 1.2845, 1.3234,
         1.3904, 1.4256, 1.4142, 1.3991, 1.4024, 1.3545, 1.3941, 1.4292, 1.3871,
         1.4051, 1.3608, 1.3549, 1.3398, 1.4030, 1.3618, 1.4215, 1.3425, 1.3503],
        [1.3643, 1.2143, 1.0522, 1.2890, 1.3525, 1.4107, 1.3345, 1.4050, 1.4050,
         1.6092, 1.8399, 1.4929, 2.2816, 1.5762, 3.0637, 1.6253, 1.4426, 2.7597,
         1.2081, 1.2600, 0.9718, 1.2360, 1.3742, 1.4175, 1.3894, 1.4166, 1.4166,
         1.3505, 1.1206, 1.4253, 1.3949, 1.1559, 1.4360, 1.4338, 1.3997, 1.3890,
         1.4083, 1.5421, 1.4931, 1.4179, 1.3819, 1.4968, 1.4742, 0.6008, 1.3770,
         1.0657, 1.4720, 1.4591, 1.4486, 1.1327, 1.4710, 0.8570, 1.4518, 1.4596],
        [1.2960, 1.3169, 1.3652, 1.3480, 1.2974, 1.3001, 1.3094, 1.2945, 1.2945,
         1.3536, 1.3645, 1.3732, 1.3726, 1.3467, 1.3311, 1.3566, 1.3309, 1.2739,
         2.0168, 2.1466, 2.2676, 2.1638, 1.8797, 1.9242, 2.0549, 1.8600, 1.8600,
         1.3567, 1.3460, 1.3184, 1.3409, 1.3600, 1.3289, 1.3386, 1.3242, 1.3220,
         1.4006, 1.4363, 1.4241, 1.3866, 1.4149, 1.4121, 1.4043, 1.3297, 1.3571,
         1.3433, 1.3692, 1.3629, 1.3464, 1.3215, 1.3706, 1.3954, 1.3488, 1.3567],
        [1.3141, 1.3360, 1.2606, 1.2386, 1.3376, 1.3185, 1.3249, 1.3123, 1.3123,
         1.3631, 1.2848, 1.3702, 1.3175, 1.3555, 1.3087, 1.3675, 1.3616, 1.0808,
         1.3536, 1.2906, 1.3824, 1.3596, 1.3311, 1.2876, 1.3428, 1.3242, 1.3242,
         2.3830, 1.9616, 1.7880, 1.8995, 2.3417, 1.7835, 2.3081, 1.8061, 1.7755,
         1.4229, 1.4313, 1.3867, 1.3855, 1.4379, 1.3749, 1.4088, 1.1631, 1.3856,
         1.4317, 1.3180, 1.2351, 1.3131, 1.4324, 1.2466, 1.4602, 1.3171, 1.3710],
        [1.6354, 1.3334, 0.5250, 0.7560, 1.1254, 1.5125, 1.4454, 1.6336, 1.6336,
         1.5839, 1.3402, 1.3833, 0.9403, 1.6548, 0.1780, 1.5393, 1.6638, 1.2485,
         1.2290, 0.8225, 0.7026, 1.0181, 1.5076, 1.6063, 1.2713, 1.6494, 1.6494,
         0.7020, 0.7272, 1.6275, 1.3872, 0.8679, 1.6305, 1.1483, 1.6665, 1.6217,
         1.1636, 0.8076, 0.7515, 1.0734, 1.5498, 1.7580, 1.0120, 4.1506, 3.8021,
         0.7240, 1.2429, 1.3197, 1.5777, 0.9433, 1.5483, 0.3534, 1.5512, 1.6896],
        [1.3800, 1.3996, 1.4448, 1.4274, 1.4042, 1.3872, 1.3464, 1.3784, 1.3784,
         1.3299, 1.3883, 1.3087, 1.4471, 1.4086, 1.4994, 1.3327, 1.4145, 1.3395,
         1.4115, 1.4346, 1.4491, 1.4228, 1.3926, 1.3850, 1.3531, 1.3838, 1.3838,
         1.4083, 1.4793, 1.4002, 1.2610, 1.2820, 1.2013, 1.4164, 1.2865, 1.4031,
         1.4715, 1.2413, 1.4947, 1.4848, 1.1432, 1.0633, 1.4752, 1.4432, 0.9551,
         2.4787, 2.0057, 2.2790, 2.2059, 1.7653, 1.5337, 2.4062, 2.1158, 1.5192]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 58 : 183.59502642431192
Test loss for epoch 58 : 183.55466506295687
Test Precision for epoch 58 : 0.26153846153846155
Test Recall for epoch 58 : 0.26153846153846155
Test F1 for epoch 58 : 0.26153846153846155


theta for epoch 59 : tensor([[1.9611, 2.0200, 2.0951, 2.1308, 2.1074, 1.9691, 2.0421, 1.9591, 1.9591,
         1.3349, 1.3413, 1.3540, 1.3561, 1.3282, 1.3880, 1.3376, 1.3340, 1.3024,
         1.3237, 1.2993, 1.3137, 1.3300, 1.3044, 1.2975, 1.3138, 1.2953, 1.2953,
         1.3139, 1.3806, 1.3205, 1.3387, 1.3680, 1.3287, 1.3335, 1.2840, 1.3232,
         1.3943, 1.4292, 1.4184, 1.4028, 1.4051, 1.3568, 1.3982, 1.4302, 1.3885,
         1.4027, 1.3581, 1.3523, 1.3372, 1.4007, 1.3590, 1.4196, 1.3397, 1.3474],
        [1.3636, 1.2136, 1.0511, 1.2880, 1.3519, 1.4105, 1.3337, 1.4047, 1.4047,
         1.6107, 1.8424, 1.4954, 2.2894, 1.5784, 3.0862, 1.6287, 1.4451, 2.7800,
         1.2070, 1.2599, 0.9740, 1.2364, 1.3751, 1.4176, 1.3894, 1.4167, 1.4167,
         1.3490, 1.1206, 1.4249, 1.3948, 1.1559, 1.4353, 1.4329, 1.3986, 1.3889,
         1.4128, 1.5452, 1.4961, 1.4217, 1.3872, 1.4997, 1.4771, 0.6072, 1.3852,
         1.0649, 1.4700, 1.4573, 1.4471, 1.1306, 1.4690, 0.8599, 1.4501, 1.4579],
        [1.2956, 1.3166, 1.3650, 1.3473, 1.2975, 1.2998, 1.3084, 1.2941, 1.2941,
         1.3548, 1.3658, 1.3739, 1.3731, 1.3480, 1.3319, 1.3575, 1.3321, 1.2737,
         2.0216, 2.1509, 2.2720, 2.1688, 1.8855, 1.9312, 2.0609, 1.8663, 1.8663,
         1.3569, 1.3445, 1.3180, 1.3400, 1.3601, 1.3283, 1.3376, 1.3236, 1.3215,
         1.4046, 1.4401, 1.4284, 1.3914, 1.4178, 1.4145, 1.4086, 1.3340, 1.3625,
         1.3417, 1.3670, 1.3607, 1.3443, 1.3181, 1.3682, 1.3922, 1.3466, 1.3544],
        [1.3153, 1.3372, 1.2614, 1.2391, 1.3388, 1.3198, 1.3260, 1.3136, 1.3136,
         1.3652, 1.2871, 1.3723, 1.3208, 1.3577, 1.3111, 1.3692, 1.3636, 1.0833,
         1.3557, 1.2933, 1.3847, 1.3618, 1.3335, 1.2897, 1.3449, 1.3264, 1.3264,
         2.3897, 1.9650, 1.7899, 1.9018, 2.3486, 1.7857, 2.3146, 1.8081, 1.7777,
         1.4281, 1.4380, 1.3935, 1.3908, 1.4419, 1.3804, 1.4151, 1.1675, 1.3899,
         1.4309, 1.3178, 1.2357, 1.3133, 1.4316, 1.2472, 1.4592, 1.3170, 1.3707],
        [1.6371, 1.3339, 0.5243, 0.7563, 1.1264, 1.5144, 1.4475, 1.6354, 1.6354,
         1.5837, 1.3388, 1.3859, 0.9388, 1.6554, 0.1769, 1.5420, 1.6654, 1.2495,
         1.2318, 0.8233, 0.7013, 1.0193, 1.5088, 1.6087, 1.2725, 1.6517, 1.6517,
         0.6995, 0.7268, 1.6286, 1.3877, 0.8660, 1.6316, 1.1474, 1.6675, 1.6229,
         1.1538, 0.7992, 0.7429, 1.0640, 1.5422, 1.7531, 1.0020, 4.2090, 3.8513,
         0.7225, 1.2415, 1.3179, 1.5773, 0.9427, 1.5477, 0.3500, 1.5511, 1.6895],
        [1.3796, 1.3995, 1.4448, 1.4274, 1.4033, 1.3865, 1.3458, 1.3780, 1.3780,
         1.3315, 1.3895, 1.3097, 1.4476, 1.4105, 1.4980, 1.3340, 1.4162, 1.3399,
         1.4131, 1.4351, 1.4487, 1.4231, 1.3938, 1.3862, 1.3543, 1.3851, 1.3851,
         1.4084, 1.4780, 1.4013, 1.2606, 1.2815, 1.2010, 1.4168, 1.2870, 1.4041,
         1.4749, 1.2466, 1.4984, 1.4880, 1.1474, 1.0671, 1.4788, 1.4452, 0.9557,
         2.4796, 2.0125, 2.2883, 2.2136, 1.7645, 1.5390, 2.4057, 2.1244, 1.5247]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 59 : 183.56805635262657
Test loss for epoch 59 : 183.53336898468547
Test Precision for epoch 59 : 0.26153846153846155
Test Recall for epoch 59 : 0.26153846153846155
Test F1 for epoch 59 : 0.26153846153846155


theta for epoch 60 : tensor([[1.9668, 2.0235, 2.0973, 2.1350, 2.1107, 1.9742, 2.0480, 1.9648, 1.9648,
         1.3361, 1.3425, 1.3548, 1.3570, 1.3294, 1.3895, 1.3385, 1.3351, 1.3029,
         1.3249, 1.3009, 1.3163, 1.3317, 1.3059, 1.2990, 1.3156, 1.2967, 1.2967,
         1.3159, 1.3824, 1.3226, 1.3408, 1.3696, 1.3309, 1.3351, 1.2858, 1.3252,
         1.3956, 1.4304, 1.4201, 1.4040, 1.4053, 1.3566, 1.3998, 1.4288, 1.3874,
         1.4023, 1.3575, 1.3517, 1.3364, 1.4004, 1.3581, 1.4198, 1.3388, 1.3465],
        [1.3636, 1.2136, 1.0511, 1.2880, 1.3521, 1.4110, 1.3337, 1.4051, 1.4051,
         1.6116, 1.8442, 1.4974, 2.2964, 1.5801, 3.1078, 1.6317, 1.4470, 2.7997,
         1.2063, 1.2604, 0.9766, 1.2373, 1.3765, 1.4183, 1.3899, 1.4174, 1.4174,
         1.3490, 1.1218, 1.4258, 1.3961, 1.1572, 1.4361, 1.4335, 1.3989, 1.3903,
         1.4150, 1.5460, 1.4968, 1.4231, 1.3901, 1.5004, 1.4779, 0.6113, 1.3910,
         1.0651, 1.4694, 1.4567, 1.4469, 1.1297, 1.4684, 0.8636, 1.4496, 1.4574],
        [1.2958, 1.3169, 1.3657, 1.3475, 1.2982, 1.3001, 1.3080, 1.2942, 1.2942,
         1.3554, 1.3664, 1.3740, 1.3733, 1.3486, 1.3321, 1.3578, 1.3327, 1.2730,
         2.0263, 2.1551, 2.2762, 2.1736, 1.8913, 1.9382, 2.0668, 1.8727, 1.8727,
         1.3583, 1.3444, 1.3190, 1.3405, 1.3613, 1.3291, 1.3379, 1.3244, 1.3223,
         1.4061, 1.4413, 1.4302, 1.3934, 1.4182, 1.4144, 1.4102, 1.3353, 1.3650,
         1.3413, 1.3661, 1.3598, 1.3433, 1.3159, 1.3671, 1.3903, 1.3455, 1.3532],
        [1.3171, 1.3389, 1.2629, 1.2402, 1.3405, 1.3215, 1.3276, 1.3153, 1.3153,
         1.3669, 1.2890, 1.3741, 1.3238, 1.3595, 1.3132, 1.3705, 1.3652, 1.0852,
         1.3582, 1.2963, 1.3875, 1.3643, 1.3361, 1.2920, 1.3472, 1.3288, 1.3288,
         2.3964, 1.9686, 1.7921, 1.9045, 2.3557, 1.7881, 2.3212, 1.8104, 1.7801,
         1.4305, 1.4418, 1.3973, 1.3935, 1.4433, 1.3831, 1.4187, 1.1691, 1.3913,
         1.4311, 1.3184, 1.2370, 1.3142, 1.4317, 1.2486, 1.4592, 1.3176, 1.3713],
        [1.6394, 1.3349, 0.5238, 0.7567, 1.1276, 1.5169, 1.4501, 1.6377, 1.6377,
         1.5832, 1.3374, 1.3880, 0.9369, 1.6559, 0.1757, 1.5444, 1.6668, 1.2501,
         1.2347, 0.8242, 0.7004, 1.0207, 1.5102, 1.6113, 1.2737, 1.6542, 1.6542,
         0.6978, 0.7273, 1.6310, 1.3894, 0.8650, 1.6341, 1.1475, 1.6698, 1.6253,
         1.1430, 0.7902, 0.7337, 1.0537, 1.5334, 1.7469, 0.9913, 4.2668, 3.8998,
         0.7218, 1.2409, 1.3169, 1.5779, 0.9430, 1.5481, 0.3475, 1.5519, 1.6904],
        [1.3785, 1.3988, 1.4445, 1.4270, 1.4019, 1.3850, 1.3445, 1.3768, 1.3768,
         1.3315, 1.3893, 1.3092, 1.4467, 1.4111, 1.4953, 1.3337, 1.4167, 1.3390,
         1.4139, 1.4349, 1.4477, 1.4226, 1.3942, 1.3865, 1.3545, 1.3854, 1.3854,
         1.4094, 1.4774, 1.4030, 1.2606, 1.2817, 1.2012, 1.4178, 1.2880, 1.4057,
         1.4749, 1.2481, 1.4988, 1.4879, 1.1477, 1.0669, 1.4792, 1.4434, 0.9524,
         2.4831, 2.0219, 2.3001, 2.2238, 1.7667, 1.5468, 2.4077, 2.1355, 1.5327]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 60 : 183.5415881256102
Test loss for epoch 60 : 183.50990229732722
Test Precision for epoch 60 : 0.26153846153846155
Test Recall for epoch 60 : 0.26153846153846155
Test F1 for epoch 60 : 0.26153846153846155


theta for epoch 61 : tensor([[1.9730, 2.0276, 2.1001, 2.1397, 2.1144, 1.9798, 2.0545, 1.9710, 1.9710,
         1.3368, 1.3433, 1.3551, 1.3573, 1.3300, 1.3908, 1.3389, 1.3357, 1.3031,
         1.3257, 1.3023, 1.3186, 1.3330, 1.3069, 1.2999, 1.3169, 1.2976, 1.2976,
         1.3196, 1.3859, 1.3261, 1.3445, 1.3730, 1.3347, 1.3384, 1.2891, 1.3286,
         1.3940, 1.4285, 1.4187, 1.4022, 1.4026, 1.3534, 1.3984, 1.4243, 1.3832,
         1.4037, 1.3586, 1.3528, 1.3373, 1.4020, 1.3589, 1.4219, 1.3396, 1.3472],
        [1.3652, 1.2153, 1.0530, 1.2898, 1.3538, 1.4131, 1.3352, 1.4070, 1.4070,
         1.6114, 1.8449, 1.4985, 2.3021, 1.5808, 3.1282, 1.6336, 1.4481, 2.8182,
         1.2058, 1.2612, 0.9794, 1.2384, 1.3779, 1.4190, 1.3905, 1.4182, 1.4182,
         1.3508, 1.1246, 1.4284, 1.3990, 1.1600, 1.4385, 1.4356, 1.4008, 1.3932,
         1.4150, 1.5446, 1.4954, 1.4223, 1.3906, 1.4989, 1.4764, 0.6134, 1.3945,
         1.0671, 1.4709, 1.4582, 1.4486, 1.1308, 1.4697, 0.8688, 1.4512, 1.4588],
        [1.2973, 1.3186, 1.3680, 1.3490, 1.3004, 1.3017, 1.3088, 1.2956, 1.2956,
         1.3554, 1.3664, 1.3737, 1.3730, 1.3486, 1.3318, 1.3575, 1.3327, 1.2719,
         2.0305, 2.1588, 2.2799, 2.1780, 1.8967, 1.9447, 2.0722, 1.8786, 1.8786,
         1.3610, 1.3458, 1.3213, 1.3424, 1.3639, 1.3312, 1.3397, 1.3266, 1.3244,
         1.4049, 1.4399, 1.4292, 1.3928, 1.4159, 1.4118, 1.4093, 1.3339, 1.3646,
         1.3429, 1.3670, 1.3607, 1.3441, 1.3157, 1.3678, 1.3904, 1.3461, 1.3538],
        [1.3185, 1.3404, 1.2642, 1.2411, 1.3420, 1.3229, 1.3289, 1.3167, 1.3167,
         1.3673, 1.2895, 1.3746, 1.3254, 1.3600, 1.3141, 1.3705, 1.3655, 1.0856,
         1.3591, 1.2978, 1.3889, 1.3654, 1.3371, 1.2926, 1.3481, 1.3296, 1.3296,
         2.4048, 1.9740, 1.7961, 1.9088, 2.3644, 1.7924, 2.3294, 1.8145, 1.7844,
         1.4295, 1.4420, 1.3975, 1.3925, 1.4411, 1.3820, 1.4187, 1.1671, 1.3892,
         1.4317, 1.3192, 1.2383, 1.3152, 1.4322, 1.2499, 1.4597, 1.3184, 1.3720],
        [1.6428, 1.3370, 0.5242, 0.7581, 1.1300, 1.5206, 1.4539, 1.6411, 1.6411,
         1.5826, 1.3360, 1.3898, 0.9350, 1.6561, 0.1748, 1.5465, 1.6680, 1.2505,
         1.2376, 0.8251, 0.7002, 1.0222, 1.5117, 1.6138, 1.2747, 1.6567, 1.6567,
         0.6976, 0.7294, 1.6348, 1.3927, 0.8653, 1.6381, 1.1488, 1.6737, 1.6292,
         1.1309, 0.7801, 0.7234, 1.0422, 1.5230, 1.7390, 0.9793, 4.3237, 3.9472,
         0.7227, 1.2416, 1.3175, 1.5802, 0.9449, 1.5500, 0.3468, 1.5542, 1.6930],
        [1.3785, 1.3994, 1.4459, 1.4280, 1.4019, 1.3846, 1.3445, 1.3768, 1.3768,
         1.3309, 1.3884, 1.3081, 1.4454, 1.4111, 1.4923, 1.3329, 1.4166, 1.3376,
         1.4143, 1.4345, 1.4463, 1.4217, 1.3941, 1.3863, 1.3543, 1.3852, 1.3852,
         1.4120, 1.4783, 1.4062, 1.2621, 1.2836, 1.2029, 1.4204, 1.2905, 1.4088,
         1.4722, 1.2465, 1.4964, 1.4849, 1.1448, 1.0635, 1.4767, 1.4385, 0.9461,
         2.4871, 2.0317, 2.3122, 2.2344, 1.7696, 1.5549, 2.4103, 2.1471, 1.5410]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 61 : 183.51216485412033
Test loss for epoch 61 : 183.48104052623196
Test Precision for epoch 61 : 0.26153846153846155
Test Recall for epoch 61 : 0.26153846153846155
Test F1 for epoch 61 : 0.26153846153846155


theta for epoch 62 : tensor([[1.9797, 2.0322, 2.1036, 2.1450, 2.1189, 1.9860, 2.0615, 1.9777, 1.9777,
         1.3375, 1.3443, 1.3556, 1.3579, 1.3307, 1.3924, 1.3393, 1.3362, 1.3035,
         1.3259, 1.3031, 1.3203, 1.3337, 1.3072, 1.3001, 1.3176, 1.2977, 1.2977,
         1.3225, 1.3887, 1.3287, 1.3473, 1.3756, 1.3376, 1.3409, 1.2915, 1.3312,
         1.3917, 1.4259, 1.4167, 1.3998, 1.3993, 1.3496, 1.3964, 1.4192, 1.3784,
         1.4052, 1.3597, 1.3538, 1.3379, 1.4037, 1.3597, 1.4242, 1.3402, 1.3477],
        [1.3669, 1.2172, 1.0553, 1.2919, 1.3558, 1.4154, 1.3370, 1.4091, 1.4091,
         1.6111, 1.8453, 1.4996, 2.3074, 1.5814, 3.1481, 1.6355, 1.4491, 2.8364,
         1.2050, 1.2617, 0.9819, 1.2390, 1.3789, 1.4194, 1.3910, 1.4186, 1.4186,
         1.3524, 1.1271, 1.4308, 1.4017, 1.1626, 1.4408, 1.4377, 1.4027, 1.3959,
         1.4146, 1.5429, 1.4936, 1.4212, 1.3907, 1.4971, 1.4747, 0.6149, 1.3975,
         1.0694, 1.4727, 1.4601, 1.4505, 1.1321, 1.4714, 0.8741, 1.4530, 1.4605],
        [1.2987, 1.3203, 1.3706, 1.3507, 1.3026, 1.3032, 1.3096, 1.2970, 1.2970,
         1.3555, 1.3665, 1.3735, 1.3729, 1.3486, 1.3316, 1.3573, 1.3326, 1.2710,
         2.0347, 2.1623, 2.2834, 2.1822, 1.9020, 1.9512, 2.0774, 1.8844, 1.8844,
         1.3632, 1.3467, 1.3232, 1.3441, 1.3660, 1.3331, 1.3412, 1.3285, 1.3263,
         1.4032, 1.4380, 1.4278, 1.3917, 1.4132, 1.4087, 1.4078, 1.3317, 1.3634,
         1.3448, 1.3682, 1.3618, 1.3449, 1.3158, 1.3686, 1.3910, 1.3469, 1.3545],
        [1.3191, 1.3412, 1.2650, 1.2413, 1.3429, 1.3236, 1.3295, 1.3174, 1.3174,
         1.3673, 1.2895, 1.3745, 1.3265, 1.3599, 1.3146, 1.3701, 1.3653, 1.0853,
         1.3588, 1.2980, 1.3892, 1.3653, 1.3367, 1.2918, 1.3476, 1.3290, 1.3290,
         2.4138, 1.9803, 1.8009, 1.9141, 2.3738, 1.7976, 2.3383, 1.8195, 1.7896,
         1.4273, 1.4410, 1.3965, 1.3904, 1.4379, 1.3798, 1.4176, 1.1639, 1.3860,
         1.4319, 1.3194, 1.2389, 1.3156, 1.4323, 1.2505, 1.4599, 1.3185, 1.3721],
        [1.6462, 1.3388, 0.5242, 0.7590, 1.1318, 1.5242, 1.4575, 1.6445, 1.6445,
         1.5821, 1.3347, 1.3914, 0.9329, 1.6565, 0.1737, 1.5485, 1.6693, 1.2507,
         1.2399, 0.8252, 0.6995, 1.0231, 1.5126, 1.6158, 1.2750, 1.6587, 1.6587,
         0.6964, 0.7307, 1.6381, 1.3952, 0.8647, 1.6415, 1.1490, 1.6770, 1.6325,
         1.1191, 0.7705, 0.7136, 1.0310, 1.5126, 1.7310, 0.9677, 4.3809, 3.9948,
         0.7232, 1.2419, 1.3176, 1.5825, 0.9465, 1.5517, 0.3459, 1.5564, 1.6955],
        [1.3805, 1.4020, 1.4493, 1.4310, 1.4038, 1.3861, 1.3465, 1.3786, 1.3786,
         1.3321, 1.3893, 1.3089, 1.4458, 1.4128, 1.4911, 1.3338, 1.4182, 1.3384,
         1.4159, 1.4355, 1.4464, 1.4222, 1.3951, 1.3872, 1.3554, 1.3861, 1.3861,
         1.4154, 1.4799, 1.4101, 1.2645, 1.2866, 1.2056, 1.4238, 1.2937, 1.4126,
         1.4701, 1.2454, 1.4946, 1.4825, 1.1426, 1.0608, 1.4749, 1.4338, 0.9406,
         2.4877, 2.0378, 2.3206, 2.2412, 1.7694, 1.5592, 2.4096, 2.1548, 1.5454]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 62 : 183.4864919064769
Test loss for epoch 62 : 183.45738423263165
Test Precision for epoch 62 : 0.26153846153846155
Test Recall for epoch 62 : 0.26153846153846155
Test F1 for epoch 62 : 0.26153846153846155


theta for epoch 63 : tensor([[1.9854, 2.0359, 2.1061, 2.1492, 2.1223, 1.9912, 2.0675, 1.9834, 1.9834,
         1.3391, 1.3461, 1.3569, 1.3595, 1.3321, 1.3949, 1.3406, 1.3376, 1.3049,
         1.3262, 1.3041, 1.3220, 1.3345, 1.3074, 1.3002, 1.3182, 1.2978, 1.2978,
         1.3229, 1.3890, 1.3284, 1.3473, 1.3757, 1.3377, 1.3406, 1.2910, 1.3308,
         1.3913, 1.4253, 1.4166, 1.3993, 1.3980, 1.3479, 1.3962, 1.4162, 1.3756,
         1.4070, 1.3610, 1.3550, 1.3386, 1.4056, 1.3606, 1.4269, 1.3410, 1.3482],
        [1.3669, 1.2176, 1.0563, 1.2925, 1.3562, 1.4159, 1.3371, 1.4096, 1.4096,
         1.6112, 1.8459, 1.5011, 2.3127, 1.5823, 3.1680, 1.6377, 1.4506, 2.8548,
         1.2037, 1.2619, 0.9839, 1.2393, 1.3794, 1.4195, 1.3911, 1.4187, 1.4187,
         1.3522, 1.1275, 1.4313, 1.4025, 1.1632, 1.4412, 1.4379, 1.4026, 1.3966,
         1.4154, 1.5426, 1.4933, 1.4214, 1.3920, 1.4967, 1.4744, 0.6171, 1.4018,
         1.0713, 1.4745, 1.4619, 1.4522, 1.1331, 1.4729, 0.8789, 1.4546, 1.4621],
        [1.2983, 1.3204, 1.3716, 1.3509, 1.3032, 1.3029, 1.3087, 1.2965, 1.2965,
         1.3560, 1.3669, 1.3737, 1.3734, 1.3490, 1.3320, 1.3575, 1.3329, 1.2706,
         2.0392, 2.1659, 2.2870, 2.1866, 1.9075, 1.9579, 2.0828, 1.8905, 1.8905,
         1.3633, 1.3457, 1.3231, 1.3436, 1.3660, 1.3329, 1.3407, 1.3283, 1.3260,
         1.4030, 1.4375, 1.4278, 1.3919, 1.4119, 1.4071, 1.4078, 1.3306, 1.3632,
         1.3466, 1.3692, 1.3628, 1.3454, 1.3158, 1.3692, 1.3915, 1.3474, 1.3548],
        [1.3188, 1.3411, 1.2649, 1.2408, 1.3427, 1.3232, 1.3292, 1.3170, 1.3170,
         1.3679, 1.2902, 1.3752, 1.3283, 1.3605, 1.3159, 1.3704, 1.3658, 1.0855,
         1.3586, 1.2984, 1.3897, 1.3653, 1.3363, 1.2911, 1.3473, 1.3284, 1.3284,
         2.4216, 1.9855, 1.8048, 1.9182, 2.3821, 1.8017, 2.3461, 1.8234, 1.7938,
         1.4268, 1.4416, 1.3970, 1.3899, 1.4363, 1.3791, 1.4180, 1.1623, 1.3845,
         1.4324, 1.3197, 1.2396, 1.3160, 1.4326, 1.2512, 1.4604, 1.3188, 1.3724],
        [1.6481, 1.3390, 0.5227, 0.7584, 1.1319, 1.5264, 1.4595, 1.6464, 1.6464,
         1.5818, 1.3337, 1.3929, 0.9308, 1.6570, 0.1725, 1.5505, 1.6708, 1.2508,
         1.2415, 0.8244, 0.6983, 1.0233, 1.5131, 1.6173, 1.2745, 1.6602, 1.6602,
         0.6927, 0.7294, 1.6390, 1.3952, 0.8614, 1.6425, 1.1463, 1.6779, 1.6334,
         1.1084, 0.7623, 0.7051, 1.0209, 1.5031, 1.7238, 0.9573, 4.4392, 4.0434,
         0.7230, 1.2415, 1.3172, 1.5845, 0.9472, 1.5530, 0.3444, 1.5580, 1.6978],
        [1.3816, 1.4038, 1.4523, 1.4334, 1.4052, 1.3867, 1.3477, 1.3796, 1.3796,
         1.3348, 1.3918, 1.3114, 1.4479, 1.4160, 1.4916, 1.3363, 1.4214, 1.3408,
         1.4182, 1.4375, 1.4476, 1.4236, 1.3969, 1.3889, 1.3572, 1.3877, 1.3877,
         1.4170, 1.4797, 1.4118, 1.2649, 1.2879, 1.2064, 1.4252, 1.2949, 1.4142,
         1.4704, 1.2466, 1.4952, 1.4825, 1.1426, 1.0604, 1.4755, 1.4311, 0.9374,
         2.4865, 2.0418, 2.3268, 2.2460, 1.7676, 1.5613, 2.4071, 2.1604, 1.5477]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 63 : 183.4604131226838
Test loss for epoch 63 : 183.43560509582812
Test Precision for epoch 63 : 0.26153846153846155
Test Recall for epoch 63 : 0.26153846153846155
Test F1 for epoch 63 : 0.26153846153846155


theta for epoch 64 : tensor([[1.9905, 2.0391, 2.1083, 2.1531, 2.1254, 1.9959, 2.0730, 1.9886, 1.9886,
         1.3404, 1.3477, 1.3581, 1.3608, 1.3333, 1.3974, 1.3417, 1.3387, 1.3061,
         1.3261, 1.3047, 1.3232, 1.3348, 1.3071, 1.2998, 1.3183, 1.2972, 1.2972,
         1.3209, 1.3869, 1.3255, 1.3448, 1.3734, 1.3352, 1.3379, 1.2881, 1.3279,
         1.3929, 1.4267, 1.4185, 1.4008, 1.3987, 1.3482, 1.3981, 1.4155, 1.3750,
         1.4089, 1.3624, 1.3563, 1.3392, 1.4076, 1.3616, 1.4297, 1.3417, 1.3488],
        [1.3656, 1.2166, 1.0563, 1.2918, 1.3551, 1.4151, 1.3358, 1.4086, 1.4086,
         1.6111, 1.8463, 1.5025, 2.3177, 1.5832, 3.1876, 1.6398, 1.4520, 2.8729,
         1.2022, 1.2618, 0.9854, 1.2391, 1.3795, 1.4192, 1.3908, 1.4184, 1.4184,
         1.3506, 1.1263, 1.4301, 1.4017, 1.1622, 1.4400, 1.4366, 1.4010, 1.3958,
         1.4179, 1.5439, 1.4946, 1.4232, 1.3948, 1.4980, 1.4757, 0.6203, 1.4075,
         1.0733, 1.4765, 1.4639, 1.4540, 1.1342, 1.4746, 0.8834, 1.4563, 1.4637],
        [1.2966, 1.3191, 1.3714, 1.3498, 1.3025, 1.3012, 1.3063, 1.2947, 1.2947,
         1.3562, 1.3671, 1.3737, 1.3737, 1.3491, 1.3322, 1.3574, 1.3329, 1.2701,
         2.0435, 2.1694, 2.2904, 2.1907, 1.9130, 1.9644, 2.0879, 1.8964, 1.8964,
         1.3618, 1.3431, 1.3212, 1.3417, 1.3642, 1.3311, 1.3386, 1.3265, 1.3241,
         1.4044, 1.4387, 1.4295, 1.3938, 1.4124, 1.4073, 1.4094, 1.3309, 1.3646,
         1.3487, 1.3704, 1.3639, 1.3460, 1.3162, 1.3700, 1.3924, 1.3480, 1.3553],
        [1.3178, 1.3404, 1.2646, 1.2398, 1.3420, 1.3222, 1.3282, 1.3160, 1.3160,
         1.3688, 1.2911, 1.3761, 1.3303, 1.3614, 1.3176, 1.3709, 1.3665, 1.0861,
         1.3586, 1.2991, 1.3904, 1.3655, 1.3361, 1.2905, 1.3472, 1.3280, 1.3280,
         2.4281, 1.9894, 1.8074, 1.9211, 2.3890, 1.8047, 2.3525, 1.8261, 1.7967,
         1.4283, 1.4441, 1.3995, 1.3915, 1.4369, 1.3804, 1.4204, 1.1628, 1.3851,
         1.4335, 1.3207, 1.2408, 1.3170, 1.4335, 1.2524, 1.4617, 1.3196, 1.3733],
        [1.6495, 1.3387, 0.5212, 0.7575, 1.1314, 1.5280, 1.4610, 1.6477, 1.6477,
         1.5817, 1.3331, 1.3944, 0.9292, 1.6577, 0.1719, 1.5526, 1.6725, 1.2511,
         1.2431, 0.8238, 0.6978, 1.0239, 1.5138, 1.6188, 1.2741, 1.6618, 1.6618,
         0.6880, 0.7273, 1.6386, 1.3938, 0.8571, 1.6422, 1.1421, 1.6776, 1.6328,
         1.0979, 0.7545, 0.6971, 1.0111, 1.4936, 1.7163, 0.9472, 4.4975, 4.0919,
         0.7236, 1.2418, 1.3175, 1.5870, 0.9489, 1.5548, 0.3442, 1.5602, 1.7007],
        [1.3800, 1.4029, 1.4527, 1.4331, 1.4039, 1.3846, 1.3463, 1.3779, 1.3779,
         1.3364, 1.3932, 1.3127, 1.4490, 1.4182, 1.4914, 1.3376, 1.4235, 1.3423,
         1.4190, 1.4381, 1.4474, 1.4236, 1.3972, 1.3890, 1.3574, 1.3878, 1.3878,
         1.4157, 1.4765, 1.4104, 1.2622, 1.2862, 1.2042, 1.4236, 1.2929, 1.4128,
         1.4723, 1.2489, 1.4972, 1.4840, 1.1437, 1.0610, 1.4776, 1.4298, 0.9352,
         2.4873, 2.0478, 2.3351, 2.2527, 1.7681, 1.5653, 2.4067, 2.1680, 1.5518]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 64 : 183.43376871207346
Test loss for epoch 64 : 183.41278155514098
Test Precision for epoch 64 : 0.26153846153846155
Test Recall for epoch 64 : 0.26153846153846155
Test F1 for epoch 64 : 0.26153846153846155


theta for epoch 65 : tensor([[1.9972, 2.0439, 2.1122, 2.1584, 2.1300, 2.0021, 2.0800, 1.9953, 1.9953,
         1.3400, 1.3475, 1.3575, 1.3606, 1.3326, 1.3982, 1.3409, 1.3380, 1.3057,
         1.3248, 1.3042, 1.3232, 1.3340, 1.3056, 1.2981, 1.3172, 1.2954, 1.2954,
         1.3189, 1.3847, 1.3224, 1.3421, 1.3711, 1.3325, 1.3351, 1.2849, 1.3247,
         1.3950, 1.4286, 1.4208, 1.4029, 1.4001, 1.3491, 1.4004, 1.4154, 1.3749,
         1.4088, 1.3618, 1.3556, 1.3378, 1.4077, 1.3606, 1.4305, 1.3403, 1.3474],
        [1.3644, 1.2159, 1.0567, 1.2914, 1.3543, 1.4143, 1.3347, 1.4077, 1.4077,
         1.6105, 1.8462, 1.5036, 2.3219, 1.5836, 3.2064, 1.6415, 1.4531, 2.8904,
         1.2003, 1.2614, 0.9866, 1.2386, 1.3791, 1.4186, 1.3903, 1.4177, 1.4177,
         1.3495, 1.1254, 1.4294, 1.4013, 1.1616, 1.4394, 1.4358, 1.3999, 1.3953,
         1.4211, 1.5461, 1.4967, 1.4258, 1.3982, 1.5002, 1.4778, 0.6238, 1.4138,
         1.0744, 1.4776, 1.4650, 1.4547, 1.1344, 1.4754, 0.8870, 1.4570, 1.4643],
        [1.2950, 1.3181, 1.3715, 1.3490, 1.3021, 1.2997, 1.3042, 1.2930, 1.2930,
         1.3553, 1.3662, 1.3726, 1.3730, 1.3480, 1.3315, 1.3562, 1.3318, 1.2686,
         2.0475, 2.1725, 2.2934, 2.1945, 1.9181, 1.9706, 2.0927, 1.9020, 1.9020,
         1.3606, 1.3410, 1.3198, 1.3402, 1.3629, 1.3297, 1.3370, 1.3251, 1.3226,
         1.4067, 1.4407, 1.4319, 1.3964, 1.4137, 1.4085, 1.4119, 1.3319, 1.3664,
         1.3496, 1.3705, 1.3639, 1.3453, 1.3156, 1.3697, 1.3923, 1.3475, 1.3547],
        [1.3167, 1.3396, 1.2642, 1.2390, 1.3412, 1.3210, 1.3272, 1.3148, 1.3148,
         1.3686, 1.2910, 1.3760, 1.3313, 1.3612, 1.3184, 1.3704, 1.3662, 1.0856,
         1.3579, 1.2993, 1.3906, 1.3651, 1.3351, 1.2892, 1.3464, 1.3268, 1.3268,
         2.4347, 1.9937, 1.8104, 1.9243, 2.3960, 1.8080, 2.3591, 1.8292, 1.8000,
         1.4304, 1.4472, 1.4024, 1.3936, 1.4380, 1.3822, 1.4233, 1.1639, 1.3864,
         1.4336, 1.3207, 1.2409, 1.3168, 1.4335, 1.2525, 1.4620, 1.3193, 1.3731],
        [1.6520, 1.3398, 0.5217, 0.7584, 1.1324, 1.5310, 1.4638, 1.6502, 1.6502,
         1.5819, 1.3331, 1.3961, 0.9283, 1.6586, 0.1727, 1.5548, 1.6743, 1.2516,
         1.2457, 0.8244, 0.6990, 1.0255, 1.5152, 1.6208, 1.2745, 1.6639, 1.6639,
         0.6856, 0.7274, 1.6395, 1.3939, 0.8548, 1.6432, 1.1396, 1.6785, 1.6336,
         1.0862, 0.7458, 0.6883, 1.0002, 1.4825, 1.7071, 0.9361, 4.5548, 4.1391,
         0.7255, 1.2427, 1.3183, 1.5899, 0.9516, 1.5569, 0.3459, 1.5627, 1.7038],
        [1.3770, 1.4008, 1.4520, 1.4317, 1.4015, 1.3813, 1.3435, 1.3749, 1.3749,
         1.3356, 1.3923, 1.3117, 1.4480, 1.4181, 1.4892, 1.3366, 1.4233, 1.3416,
         1.4180, 1.4370, 1.4456, 1.4219, 1.3955, 1.3872, 1.3558, 1.3859, 1.3859,
         1.4139, 1.4729, 1.4083, 1.2588, 1.2840, 1.2011, 1.4214, 1.2901, 1.4106,
         1.4744, 1.2510, 1.4996, 1.4858, 1.1447, 1.0615, 1.4799, 1.4286, 0.9328,
         2.4900, 2.0555, 2.3450, 2.2612, 1.7708, 1.5709, 2.4082, 2.1774, 1.5575]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 65 : 183.40794018473426
Test loss for epoch 65 : 183.3888541927234
Test Precision for epoch 65 : 0.26153846153846155
Test Recall for epoch 65 : 0.26153846153846155
Test F1 for epoch 65 : 0.26153846153846155


theta for epoch 66 : tensor([[2.0042, 2.0491, 2.1164, 2.1641, 2.1350, 2.0087, 2.0873, 2.0022, 2.0022,
         1.3385, 1.3465, 1.3560, 1.3595, 1.3309, 1.3982, 1.3393, 1.3363, 1.3044,
         1.3237, 1.3038, 1.3232, 1.3333, 1.3041, 1.2964, 1.3162, 1.2937, 1.2937,
         1.3190, 1.3847, 1.3212, 1.3415, 1.3709, 1.3317, 1.3344, 1.2836, 1.3235,
         1.3966, 1.4301, 1.4226, 1.4045, 1.4010, 1.3496, 1.4023, 1.4151, 1.3746,
         1.4062, 1.3587, 1.3524, 1.3338, 1.4052, 1.3570, 1.4290, 1.3364, 1.3433],
        [1.3633, 1.2155, 1.0573, 1.2911, 1.3537, 1.4137, 1.3338, 1.4069, 1.4069,
         1.6100, 1.8459, 1.5047, 2.3260, 1.5840, 3.2250, 1.6432, 1.4542, 2.9079,
         1.1983, 1.2609, 0.9876, 1.2379, 1.3785, 1.4177, 1.3896, 1.4168, 1.4168,
         1.3498, 1.1258, 1.4300, 1.4022, 1.1622, 1.4400, 1.4363, 1.4001, 1.3961,
         1.4236, 1.5477, 1.4982, 1.4278, 1.4010, 1.5018, 1.4794, 0.6265, 1.4194,
         1.0731, 1.4763, 1.4637, 1.4531, 1.1322, 1.4738, 0.8883, 1.4554, 1.4625],
        [1.2938, 1.3175, 1.3721, 1.3488, 1.3022, 1.2986, 1.3026, 1.2917, 1.2917,
         1.3534, 1.3642, 1.3706, 1.3715, 1.3458, 1.3302, 1.3541, 1.3296, 1.2664,
         2.0517, 2.1756, 2.2965, 2.1983, 1.9234, 1.9768, 2.0975, 1.9077, 1.9077,
         1.3610, 1.3406, 1.3199, 1.3403, 1.3631, 1.3299, 1.3370, 1.3252, 1.3226,
         1.4084, 1.4422, 1.4338, 1.3985, 1.4147, 1.4092, 1.4138, 1.3323, 1.3677,
         1.3483, 1.3681, 1.3614, 1.3422, 1.3127, 1.3668, 1.3900, 1.3444, 1.3515],
        [1.3152, 1.3386, 1.2638, 1.2379, 1.3402, 1.3196, 1.3259, 1.3133, 1.3133,
         1.3673, 1.2896, 1.3747, 1.3311, 1.3597, 1.3181, 1.3687, 1.3646, 1.0839,
         1.3567, 1.2990, 1.3903, 1.3642, 1.3335, 1.2872, 1.3451, 1.3250, 1.3250,
         2.4424, 1.9994, 1.8147, 1.9288, 2.4042, 1.8126, 2.3669, 1.8336, 1.8047,
         1.4315, 1.4493, 1.4043, 1.3948, 1.4383, 1.3831, 1.4252, 1.1642, 1.3869,
         1.4317, 1.3186, 1.2389, 1.3144, 1.4314, 1.2504, 1.4603, 1.3167, 1.3706],
        [1.6557, 1.3421, 0.5240, 0.7609, 1.1349, 1.5351, 1.4678, 1.6538, 1.6538,
         1.5822, 1.3335, 1.3978, 0.9280, 1.6596, 0.1746, 1.5570, 1.6761, 1.2523,
         1.2490, 0.8261, 0.7017, 1.0282, 1.5174, 1.6235, 1.2756, 1.6667, 1.6667,
         0.6861, 0.7304, 1.6426, 1.3965, 0.8551, 1.6463, 1.1397, 1.6817, 1.6365,
         1.0734, 0.7362, 0.6786, 0.9883, 1.4700, 1.6964, 0.9241, 4.6112, 4.1851,
         0.7273, 1.2429, 1.3184, 1.5919, 0.9539, 1.5581, 0.3481, 1.5643, 1.7059],
        [1.3745, 1.3991, 1.4519, 1.4308, 1.3996, 1.3784, 1.3413, 1.3723, 1.3723,
         1.3339, 1.3906, 1.3098, 1.4462, 1.4170, 1.4864, 1.3346, 1.4222, 1.3401,
         1.4169, 1.4360, 1.4441, 1.4203, 1.3939, 1.3854, 1.3541, 1.3839, 1.3839,
         1.4140, 1.4714, 1.4079, 1.2572, 1.2838, 1.2000, 1.4212, 1.2891, 1.4102,
         1.4761, 1.2525, 1.5015, 1.4872, 1.1450, 1.0612, 1.4819, 1.4270, 0.9301,
         2.4919, 2.0621, 2.3539, 2.2686, 1.7727, 1.5752, 2.4089, 2.1856, 1.5620]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 66 : 183.38147902446607
Test loss for epoch 66 : 183.3637387307412
Test Precision for epoch 66 : 0.26153846153846155
Test Recall for epoch 66 : 0.26153846153846155
Test F1 for epoch 66 : 0.26153846153846155


theta for epoch 67 : tensor([[2.0090, 2.0521, 2.1188, 2.1678, 2.1379, 2.0131, 2.0925, 2.0070, 2.0070,
         1.3379, 1.3462, 1.3553, 1.3592, 1.3301, 1.3990, 1.3384, 1.3354, 1.3041,
         1.3238, 1.3048, 1.3244, 1.3339, 1.3039, 1.2960, 1.3164, 1.2931, 1.2931,
         1.3209, 1.3864, 1.3216, 1.3425, 1.3725, 1.3326, 1.3354, 1.2841, 1.3239,
         1.3976, 1.4308, 1.4238, 1.4055, 1.4013, 1.3496, 1.4034, 1.4142, 1.3737,
         1.4039, 1.3558, 1.3494, 1.3301, 1.4031, 1.3538, 1.4277, 1.3328, 1.3396],
        [1.3616, 1.2144, 1.0573, 1.2903, 1.3525, 1.4124, 1.3322, 1.4055, 1.4055,
         1.6100, 1.8462, 1.5065, 2.3303, 1.5850, 3.2439, 1.6454, 1.4559, 2.9257,
         1.1961, 1.2601, 0.9880, 1.2369, 1.3777, 1.4166, 1.3887, 1.4156, 1.4156,
         1.3506, 1.1263, 1.4310, 1.4035, 1.1631, 1.4411, 1.4374, 1.4008, 1.3973,
         1.4248, 1.5482, 1.4985, 1.4284, 1.4023, 1.5023, 1.4798, 0.6276, 1.4235,
         1.0708, 1.4742, 1.4615, 1.4504, 1.1290, 1.4712, 0.8884, 1.4528, 1.4598],
        [1.2925, 1.3168, 1.3727, 1.3485, 1.3023, 1.2973, 1.3009, 1.2903, 1.2903,
         1.3514, 1.3622, 1.3686, 1.3700, 1.3436, 1.3289, 1.3518, 1.3273, 1.2642,
         2.0560, 2.1788, 2.2996, 2.2022, 1.9288, 1.9832, 2.1023, 1.9136, 1.9136,
         1.3621, 1.3410, 1.3207, 1.3412, 1.3640, 1.3308, 1.3379, 1.3261, 1.3233,
         1.4090, 1.4426, 1.4346, 1.3995, 1.4145, 1.4089, 1.4147, 1.3315, 1.3676,
         1.3463, 1.3651, 1.3583, 1.3383, 1.3093, 1.3634, 1.3871, 1.3407, 1.3477],
        [1.3137, 1.3375, 1.2634, 1.2371, 1.3391, 1.3181, 1.3245, 1.3118, 1.3118,
         1.3660, 1.2883, 1.3735, 1.3310, 1.3583, 1.3179, 1.3671, 1.3631, 1.0823,
         1.3557, 1.2990, 1.3902, 1.3635, 1.3321, 1.2855, 1.3440, 1.3234, 1.3234,
         2.4502, 2.0052, 1.8193, 1.9335, 2.4124, 1.8175, 2.3747, 1.8383, 1.8096,
         1.4315, 1.4502, 1.4049, 1.3948, 1.4375, 1.3828, 1.4259, 1.1636, 1.3863,
         1.4295, 1.3161, 1.2365, 1.3115, 1.4290, 1.2478, 1.4583, 1.3138, 1.3677],
        [1.6590, 1.3440, 0.5258, 0.7628, 1.1366, 1.5388, 1.4712, 1.6571, 1.6571,
         1.5824, 1.3338, 1.3992, 0.9275, 1.6604, 0.1760, 1.5589, 1.6778, 1.2527,
         1.2521, 0.8274, 0.7041, 1.0306, 1.5195, 1.6261, 1.2766, 1.6694, 1.6694,
         0.6869, 0.7336, 1.6461, 1.3995, 0.8557, 1.6499, 1.1400, 1.6854, 1.6399,
         1.0609, 0.7270, 0.6693, 0.9766, 1.4574, 1.6854, 0.9123, 4.6678, 4.2312,
         0.7282, 1.2424, 1.3178, 1.5931, 0.9553, 1.5586, 0.3495, 1.5651, 1.7074],
        [1.3723, 1.3976, 1.4520, 1.4302, 1.3981, 1.3757, 1.3393, 1.3699, 1.3699,
         1.3323, 1.3891, 1.3081, 1.4447, 1.4161, 1.4841, 1.3329, 1.4213, 1.3389,
         1.4164, 1.4358, 1.4433, 1.4194, 1.3927, 1.3841, 1.3530, 1.3826, 1.3826,
         1.4153, 1.4711, 1.4086, 1.2568, 1.2849, 1.2001, 1.4221, 1.2892, 1.4109,
         1.4769, 1.2528, 1.5025, 1.4877, 1.1442, 1.0600, 1.4829, 1.4244, 0.9266,
         2.4930, 2.0676, 2.3617, 2.2750, 1.7740, 1.5784, 2.4089, 2.1927, 1.5652]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 67 : 183.35725984727856
Test loss for epoch 67 : 183.34147441927107
Test Precision for epoch 67 : 0.26153846153846155
Test Recall for epoch 67 : 0.26153846153846155
Test F1 for epoch 67 : 0.26153846153846155


theta for epoch 68 : tensor([[2.0129, 2.0545, 2.1204, 2.1706, 2.1402, 2.0168, 2.0969, 2.0110, 2.0110,
         1.3380, 1.3467, 1.3554, 1.3597, 1.3299, 1.4005, 1.3383, 1.3352, 1.3045,
         1.3243, 1.3061, 1.3258, 1.3347, 1.3039, 1.2959, 1.3169, 1.2929, 1.2929,
         1.3221, 1.3873, 1.3211, 1.3426, 1.3732, 1.3326, 1.3356, 1.2837, 1.3234,
         1.3976, 1.4307, 1.4239, 1.4055, 1.4008, 1.3487, 1.4036, 1.4126, 1.3719,
         1.4039, 1.3553, 1.3488, 1.3286, 1.4031, 1.3528, 1.4286, 1.3316, 1.3382],
        [1.3601, 1.2136, 1.0574, 1.2897, 1.3514, 1.4113, 1.3308, 1.4043, 1.4043,
         1.6102, 1.8465, 1.5085, 2.3346, 1.5862, 3.2627, 1.6479, 1.4579, 2.9436,
         1.1938, 1.2592, 0.9882, 1.2357, 1.3766, 1.4154, 1.3877, 1.4143, 1.4143,
         1.3507, 1.1260, 1.4311, 1.4039, 1.1631, 1.4414, 1.4377, 1.4006, 1.3975,
         1.4250, 1.5476, 1.4979, 1.4281, 1.4024, 1.5018, 1.4792, 0.6276, 1.4264,
         1.0698, 1.4735, 1.4608, 1.4491, 1.1272, 1.4702, 0.8892, 1.4516, 1.4585],
        [1.2917, 1.3167, 1.3738, 1.3489, 1.3030, 1.2966, 1.2999, 1.2895, 1.2895,
         1.3500, 1.3608, 1.3672, 1.3692, 1.3420, 1.3283, 1.3502, 1.3257, 1.2627,
         2.0599, 2.1814, 2.3021, 2.2056, 1.9337, 1.9891, 2.1066, 1.9189, 1.9189,
         1.3626, 1.3408, 1.3209, 1.3414, 1.3642, 1.3311, 1.3381, 1.3264, 1.3233,
         1.4087, 1.4421, 1.4345, 1.3995, 1.4135, 1.4078, 1.4146, 1.3298, 1.3666,
         1.3465, 1.3643, 1.3574, 1.3366, 1.3083, 1.3621, 1.3865, 1.3392, 1.3460],
        [1.3133, 1.3376, 1.2643, 1.2374, 1.3392, 1.3177, 1.3243, 1.3113, 1.3113,
         1.3657, 1.2881, 1.3734, 1.3318, 1.3579, 1.3188, 1.3665, 1.3626, 1.0818,
         1.3556, 1.3000, 1.3911, 1.3637, 1.3316, 1.2848, 1.3439, 1.3227, 1.3227,
         2.4563, 2.0094, 1.8223, 1.9366, 2.4189, 1.8209, 2.3807, 1.8414, 1.8130,
         1.4311, 1.4505, 1.4050, 1.3944, 1.4363, 1.3821, 1.4261, 1.1628, 1.3854,
         1.4293, 1.3157, 1.2361, 1.3106, 1.4286, 1.2473, 1.4584, 1.3129, 1.3669],
        [1.6614, 1.3447, 0.5260, 0.7632, 1.1369, 1.5414, 1.4736, 1.6594, 1.6594,
         1.5821, 1.3336, 1.3997, 0.9260, 1.6608, 0.1760, 1.5601, 1.6790, 1.2522,
         1.2538, 0.8270, 0.7050, 1.0316, 1.5205, 1.6277, 1.2763, 1.6711, 1.6711,
         0.6853, 0.7345, 1.6479, 1.4004, 0.8539, 1.6516, 1.1381, 1.6874, 1.6414,
         1.0495, 0.7190, 0.6612, 0.9660, 1.4459, 1.6754, 0.9017, 4.7254, 4.2783,
         0.7283, 1.2417, 1.3172, 1.5946, 0.9562, 1.5592, 0.3499, 1.5661, 1.7092],
        [1.3704, 1.3965, 1.4524, 1.4299, 1.3970, 1.3736, 1.3377, 1.3680, 1.3680,
         1.3312, 1.3881, 1.3070, 1.4436, 1.4156, 1.4825, 1.3315, 1.4207, 1.3383,
         1.4156, 1.4355, 1.4426, 1.4185, 1.3915, 1.3827, 1.3518, 1.3811, 1.3811,
         1.4155, 1.4698, 1.4080, 1.2553, 1.2849, 1.1991, 1.4218, 1.2880, 1.4103,
         1.4766, 1.2519, 1.5024, 1.4871, 1.1422, 1.0576, 1.4829, 1.4208, 0.9223,
         2.4947, 2.0736, 2.3699, 2.2818, 1.7762, 1.5821, 2.4097, 2.2003, 1.5690]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 68 : 183.3322543074586
Test loss for epoch 68 : 183.31890101078397
Test Precision for epoch 68 : 0.26153846153846155
Test Recall for epoch 68 : 0.26153846153846155
Test F1 for epoch 68 : 0.26153846153846155


theta for epoch 69 : tensor([[2.0183, 2.0583, 2.1235, 2.1749, 2.1439, 2.0219, 2.1027, 2.0164, 2.0164,
         1.3377, 1.3468, 1.3551, 1.3598, 1.3293, 1.4016, 1.3378, 1.3346, 1.3046,
         1.3240, 1.3065, 1.3261, 1.3346, 1.3031, 1.2949, 1.3165, 1.2918, 1.2918,
         1.3213, 1.3862, 1.3186, 1.3407, 1.3721, 1.3305, 1.3338, 1.2813, 1.3209,
         1.3965, 1.4294, 1.4230, 1.4044, 1.3992, 1.3468, 1.4026, 1.4100, 1.3693,
         1.4051, 1.3562, 1.3495, 1.3285, 1.4045, 1.3533, 1.4308, 1.3316, 1.3382],
        [1.3596, 1.2139, 1.0587, 1.2901, 1.3514, 1.4111, 1.3304, 1.4040, 1.4040,
         1.6097, 1.8461, 1.5099, 2.3380, 1.5868, 3.2806, 1.6497, 1.4593, 2.9607,
         1.1920, 1.2586, 0.9887, 1.2348, 1.3757, 1.4144, 1.3869, 1.4132, 1.4132,
         1.3501, 1.1249, 1.4306, 1.4036, 1.1625, 1.4409, 1.4373, 1.3998, 1.3971,
         1.4246, 1.5467, 1.4969, 1.4273, 1.4021, 1.5009, 1.4782, 0.6272, 1.4287,
         1.0707, 1.4747, 1.4621, 1.4498, 1.1274, 1.4711, 0.8914, 1.4524, 1.4592],
        [1.2917, 1.3173, 1.3755, 1.3499, 1.3045, 1.2967, 1.2997, 1.2894, 1.2894,
         1.3489, 1.3597, 1.3662, 1.3687, 1.3407, 1.3281, 1.3490, 1.3244, 1.2617,
         2.0633, 2.1836, 2.3042, 2.2085, 1.9381, 1.9945, 2.1103, 1.9238, 1.9238,
         1.3620, 1.3398, 1.3200, 1.3408, 1.3635, 1.3305, 1.3375, 1.3257, 1.3225,
         1.4078, 1.4411, 1.4338, 1.3989, 1.4120, 1.4062, 1.4139, 1.3275, 1.3648,
         1.3487, 1.3654, 1.3584, 1.3370, 1.3094, 1.3628, 1.3880, 1.3397, 1.3464],
        [1.3140, 1.3387, 1.2663, 1.2389, 1.3403, 1.3183, 1.3251, 1.3120, 1.3120,
         1.3662, 1.2885, 1.3739, 1.3333, 1.3582, 1.3204, 1.3666, 1.3628, 1.0822,
         1.3560, 1.3016, 1.3924, 1.3644, 1.3317, 1.2846, 1.3443, 1.3225, 1.3225,
         2.4608, 2.0123, 1.8240, 1.9383, 2.4240, 1.8229, 2.3853, 1.8431, 1.8150,
         1.4303, 1.4506, 1.4047, 1.3937, 1.4348, 1.3812, 1.4259, 1.1620, 1.3843,
         1.4310, 1.3172, 1.2375, 1.3116, 1.4302, 1.2487, 1.4604, 1.3139, 1.3680],
        [1.6633, 1.3446, 0.5250, 0.7625, 1.1361, 1.5435, 1.4753, 1.6613, 1.6613,
         1.5814, 1.3328, 1.3994, 0.9237, 1.6607, 0.1746, 1.5606, 1.6796, 1.2508,
         1.2542, 0.8252, 0.7043, 1.0311, 1.5206, 1.6282, 1.2749, 1.6720, 1.6720,
         0.6814, 0.7330, 1.6478, 1.3993, 0.8498, 1.6515, 1.1338, 1.6875, 1.6411,
         1.0392, 0.7122, 0.6542, 0.9567, 1.4352, 1.6662, 0.8924, 4.7839, 4.3263,
         0.7279, 1.2411, 1.3168, 1.5964, 0.9567, 1.5601, 0.3496, 1.5675, 1.7115],
        [1.3696, 1.3964, 1.4538, 1.4305, 1.3970, 1.3725, 1.3372, 1.3671, 1.3671,
         1.3305, 1.3876, 1.3064, 1.4432, 1.4155, 1.4815, 1.3307, 1.4206, 1.3382,
         1.4150, 1.4353, 1.4422, 1.4177, 1.3904, 1.3814, 1.3507, 1.3797, 1.3797,
         1.4145, 1.4675, 1.4061, 1.2528, 1.2840, 1.1972, 1.4204, 1.2857, 1.4084,
         1.4759, 1.2503, 1.5018, 1.4861, 1.1397, 1.0547, 1.4823, 1.4168, 0.9178,
         2.4964, 2.0794, 2.3779, 2.2884, 1.7785, 1.5856, 2.4104, 2.2077, 1.5725]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 69 : 183.3063562240445
Test loss for epoch 69 : 183.29565516802708
Test Precision for epoch 69 : 0.26153846153846155
Test Recall for epoch 69 : 0.26153846153846155
Test F1 for epoch 69 : 0.26153846153846155


theta for epoch 70 : tensor([[2.0239, 2.0623, 2.1270, 2.1795, 2.1479, 2.0272, 2.1087, 2.0220, 2.0220,
         1.3372, 1.3467, 1.3546, 1.3598, 1.3286, 1.4026, 1.3371, 1.3338, 1.3045,
         1.3235, 1.3066, 1.3261, 1.3343, 1.3020, 1.2937, 1.3159, 1.2905, 1.2905,
         1.3206, 1.3853, 1.3161, 1.3389, 1.3711, 1.3285, 1.3322, 1.2790, 1.3185,
         1.3950, 1.4278, 1.4216, 1.4030, 1.3974, 1.3447, 1.4012, 1.4073, 1.3663,
         1.4061, 1.3567, 1.3499, 1.3282, 1.4056, 1.3535, 1.4327, 1.3314, 1.3379],
        [1.3590, 1.2143, 1.0600, 1.2905, 1.3513, 1.4107, 1.3300, 1.4035, 1.4035,
         1.6087, 1.8450, 1.5108, 2.3405, 1.5868, 3.2977, 1.6509, 1.4602, 2.9770,
         1.1909, 1.2586, 0.9899, 1.2345, 1.3754, 1.4140, 1.3867, 1.4127, 1.4127,
         1.3502, 1.1245, 1.4305, 1.4038, 1.1625, 1.4410, 1.4375, 1.3995, 1.3972,
         1.4243, 1.5458, 1.4959, 1.4266, 1.4017, 1.5002, 1.4773, 0.6270, 1.4308,
         1.0722, 1.4764, 1.4637, 1.4508, 1.1283, 1.4724, 0.8939, 1.4535, 1.4602],
        [1.2908, 1.3169, 1.3762, 1.3500, 1.3050, 1.2957, 1.2986, 1.2884, 1.2884,
         1.3476, 1.3584, 1.3649, 1.3680, 1.3391, 1.3279, 1.3475, 1.3229, 1.2605,
         2.0672, 2.1862, 2.3066, 2.2117, 1.9430, 2.0003, 2.1144, 1.9291, 1.9291,
         1.3616, 1.3389, 1.3193, 1.3402, 1.3628, 1.3299, 1.3369, 1.3251, 1.3217,
         1.4065, 1.4396, 1.4326, 1.3979, 1.4102, 1.4043, 1.4128, 1.3247, 1.3627,
         1.3507, 1.3662, 1.3591, 1.3369, 1.3103, 1.3632, 1.3892, 1.3399, 1.3465],
        [1.3137, 1.3388, 1.2673, 1.2395, 1.3404, 1.3179, 1.3249, 1.3115, 1.3115,
         1.3662, 1.2885, 1.3741, 1.3344, 1.3580, 1.3216, 1.3663, 1.3625, 1.0821,
         1.3559, 1.3027, 1.3931, 1.3646, 1.3312, 1.2839, 1.3442, 1.3218, 1.3218,
         2.4660, 2.0160, 1.8265, 1.9408, 2.4296, 1.8257, 2.3905, 1.8456, 1.8178,
         1.4290, 1.4499, 1.4037, 1.3924, 1.4329, 1.3797, 1.4251, 1.1607, 1.3827,
         1.4323, 1.3182, 1.2384, 1.3120, 1.4313, 1.2495, 1.4620, 1.3143, 1.3685],
        [1.6648, 1.3440, 0.5239, 0.7615, 1.1349, 1.5450, 1.4764, 1.6627, 1.6627,
         1.5807, 1.3321, 1.3991, 0.9216, 1.6607, 0.1733, 1.5611, 1.6803, 1.2494,
         1.2546, 0.8234, 0.7038, 1.0307, 1.5208, 1.6288, 1.2736, 1.6728, 1.6728,
         0.6780, 0.7320, 1.6480, 1.3984, 0.8462, 1.6516, 1.1299, 1.6880, 1.6410,
         1.0290, 0.7056, 0.6475, 0.9474, 1.4245, 1.6567, 0.8831, 4.8424, 4.3740,
         0.7274, 1.2406, 1.3165, 1.5982, 0.9572, 1.5609, 0.3495, 1.5689, 1.7138],
        [1.3689, 1.3963, 1.4550, 1.4311, 1.3971, 1.3716, 1.3369, 1.3663, 1.3663,
         1.3305, 1.3878, 1.3065, 1.4434, 1.4158, 1.4814, 1.3304, 1.4209, 1.3388,
         1.4150, 1.4359, 1.4428, 1.4179, 1.3900, 1.3809, 1.3504, 1.3790, 1.3790,
         1.4144, 1.4662, 1.4050, 1.2512, 1.2841, 1.1962, 1.4198, 1.2842, 1.4073,
         1.4753, 1.2489, 1.5014, 1.4852, 1.1375, 1.0521, 1.4819, 1.4131, 0.9140,
         2.4969, 2.0836, 2.3843, 2.2934, 1.7797, 1.5874, 2.4099, 2.2134, 1.5744]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 70 : 183.2828344919459
Test loss for epoch 70 : 183.27477825106092
Test Precision for epoch 70 : 0.26153846153846155
Test Recall for epoch 70 : 0.26153846153846155
Test F1 for epoch 70 : 0.26153846153846155


theta for epoch 71 : tensor([[2.0283, 2.0653, 2.1294, 2.1829, 2.1508, 2.0314, 2.1135, 2.0264, 2.0264,
         1.3369, 1.3468, 1.3544, 1.3600, 1.3280, 1.4037, 1.3366, 1.3332, 1.3047,
         1.3231, 1.3069, 1.3261, 1.3341, 1.3011, 1.2927, 1.3154, 1.2894, 1.2894,
         1.3212, 1.3856, 1.3149, 1.3383, 1.3714, 1.3277, 1.3319, 1.2781, 1.3173,
         1.3939, 1.4266, 1.4206, 1.4020, 1.3961, 1.3431, 1.4003, 1.4053, 1.3641,
         1.4060, 1.3563, 1.3493, 1.3268, 1.4056, 1.3526, 1.4335, 1.3303, 1.3366],
        [1.3574, 1.2138, 1.0604, 1.2897, 1.3502, 1.4092, 1.3285, 1.4019, 1.4019,
         1.6076, 1.8438, 1.5117, 2.3428, 1.5868, 3.3145, 1.6520, 1.4611, 2.9931,
         1.1900, 1.2587, 0.9910, 1.2342, 1.3750, 1.4135, 1.3866, 1.4122, 1.4122,
         1.3512, 1.1248, 1.4312, 1.4048, 1.1633, 1.4420, 1.4386, 1.4001, 1.3981,
         1.4242, 1.5453, 1.4952, 1.4261, 1.4015, 1.4997, 1.4766, 0.6268, 1.4330,
         1.0729, 1.4770, 1.4644, 1.4508, 1.1283, 1.4726, 0.8954, 1.4536, 1.4602],
        [1.2883, 1.3150, 1.3752, 1.3486, 1.3040, 1.2932, 1.2960, 1.2858, 1.2858,
         1.3462, 1.3569, 1.3635, 1.3672, 1.3374, 1.3276, 1.3458, 1.3212, 1.2593,
         2.0715, 2.1891, 2.3094, 2.2154, 1.9484, 2.0065, 2.1189, 1.9348, 1.9348,
         1.3617, 1.3387, 1.3191, 1.3403, 1.3628, 1.3300, 1.3371, 1.3251, 1.3214,
         1.4053, 1.4382, 1.4315, 1.3969, 1.4085, 1.4026, 1.4117, 1.3221, 1.3605,
         1.3512, 1.3655, 1.3583, 1.3354, 1.3098, 1.3621, 1.3891, 1.3385, 1.3451],
        [1.3113, 1.3368, 1.2665, 1.2384, 1.3385, 1.3155, 1.3227, 1.3091, 1.3091,
         1.3653, 1.2876, 1.3735, 1.3346, 1.3570, 1.3220, 1.3652, 1.3614, 1.0812,
         1.3546, 1.3026, 1.3927, 1.3636, 1.3295, 1.2820, 1.3429, 1.3199, 1.3199,
         2.4726, 2.0213, 1.8306, 1.9449, 2.4367, 1.8302, 2.3973, 1.8498, 1.8223,
         1.4272, 1.4488, 1.4022, 1.3906, 1.4306, 1.3778, 1.4237, 1.1591, 1.3808,
         1.4319, 1.3176, 1.2376, 1.3107, 1.4307, 1.2485, 1.4619, 1.3130, 1.3673],
        [1.6661, 1.3436, 0.5238, 0.7613, 1.1340, 1.5464, 1.4775, 1.6639, 1.6639,
         1.5809, 1.3326, 1.3995, 0.9208, 1.6614, 0.1737, 1.5622, 1.6816, 1.2490,
         1.2559, 0.8228, 0.7047, 1.0314, 1.5218, 1.6301, 1.2732, 1.6743, 1.6743,
         0.6773, 0.7335, 1.6498, 1.3994, 0.8449, 1.6532, 1.1283, 1.6901, 1.6426,
         1.0179, 0.6982, 0.6400, 0.9372, 1.4124, 1.6457, 0.8731, 4.8999, 4.4206,
         0.7279, 1.2406, 1.3166, 1.5999, 0.9585, 1.5618, 0.3508, 1.5704, 1.7160],
        [1.3668, 1.3948, 1.4546, 1.4301, 1.3958, 1.3693, 1.3350, 1.3641, 1.3641,
         1.3304, 1.3880, 1.3066, 1.4437, 1.4161, 1.4816, 1.3302, 1.4211, 1.3394,
         1.4148, 1.4364, 1.4432, 1.4179, 1.3895, 1.3802, 1.3499, 1.3783, 1.3783,
         1.4153, 1.4660, 1.4048, 1.2507, 1.2853, 1.1964, 1.4202, 1.2837, 1.4071,
         1.4751, 1.2475, 1.5012, 1.4846, 1.1355, 1.0498, 1.4819, 1.4099, 0.9106,
         2.4971, 2.0872, 2.3902, 2.2978, 1.7807, 1.5887, 2.4092, 2.2187, 1.5757]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 71 : 183.25871154313188
Test loss for epoch 71 : 183.25254670182346
Test Precision for epoch 71 : 0.26153846153846155
Test Recall for epoch 71 : 0.26153846153846155
Test F1 for epoch 71 : 0.26153846153846155


theta for epoch 72 : tensor([[2.0330, 2.0687, 2.1324, 2.1867, 2.1542, 2.0359, 2.1187, 2.0311, 2.0311,
         1.3364, 1.3466, 1.3539, 1.3600, 1.3272, 1.4045, 1.3359, 1.3323, 1.3047,
         1.3220, 1.3063, 1.3252, 1.3332, 1.2995, 1.2910, 1.3141, 1.2876, 1.2876,
         1.3216, 1.3856, 1.3135, 1.3375, 1.3714, 1.3266, 1.3314, 1.2768, 1.3159,
         1.3936, 1.4262, 1.4204, 1.4018, 1.3956, 1.3424, 1.4001, 1.4043, 1.3628,
         1.4047, 1.3546, 1.3475, 1.3243, 1.4043, 1.3506, 1.4329, 1.3279, 1.3342],
        [1.3555, 1.2131, 1.0604, 1.2887, 1.3489, 1.4074, 1.3267, 1.4001, 1.4001,
         1.6069, 1.8429, 1.5129, 2.3452, 1.5870, 3.3314, 1.6534, 1.4623, 3.0094,
         1.1885, 1.2581, 0.9914, 1.2333, 1.3739, 1.4124, 1.3858, 1.4109, 1.4109,
         1.3520, 1.1248, 1.4316, 1.4055, 1.1639, 1.4426, 1.4394, 1.4004, 1.3986,
         1.4245, 1.5453, 1.4951, 1.4261, 1.4018, 1.4999, 1.4766, 0.6268, 1.4356,
         1.0724, 1.4765, 1.4639, 1.4495, 1.1272, 1.4718, 0.8957, 1.4525, 1.4590],
        [1.2860, 1.3132, 1.3743, 1.3473, 1.3032, 1.2909, 1.2937, 1.2834, 1.2834,
         1.3447, 1.3554, 1.3621, 1.3664, 1.3357, 1.3276, 1.3442, 1.3196, 1.2582,
         2.0755, 2.1917, 2.3118, 2.2186, 1.9533, 2.0123, 2.1229, 1.9401, 1.9401,
         1.3618, 1.3386, 1.3188, 1.3404, 1.3627, 1.3299, 1.3372, 1.3250, 1.3212,
         1.4048, 1.4377, 1.4311, 1.3967, 1.4078, 1.4017, 1.4114, 1.3204, 1.3591,
         1.3508, 1.3640, 1.3566, 1.3331, 1.3086, 1.3602, 1.3881, 1.3364, 1.3428],
        [1.3087, 1.3347, 1.2656, 1.2371, 1.3364, 1.3130, 1.3204, 1.3065, 1.3065,
         1.3642, 1.2865, 1.3726, 1.3345, 1.3557, 1.3222, 1.3639, 1.3600, 1.0801,
         1.3527, 1.3020, 1.3914, 1.3619, 1.3271, 1.2795, 1.3409, 1.3174, 1.3174,
         2.4793, 2.0268, 1.8350, 1.9492, 2.4439, 1.8349, 2.4041, 1.8543, 1.8270,
         1.4260, 1.4483, 1.4012, 1.3894, 1.4289, 1.3765, 1.4229, 1.1582, 1.3796,
         1.4306, 1.3161, 1.2359, 1.3084, 1.4293, 1.2467, 1.4610, 1.3108, 1.3652],
        [1.6682, 1.3444, 0.5257, 0.7627, 1.1345, 1.5488, 1.4796, 1.6660, 1.6660,
         1.5819, 1.3341, 1.4007, 0.9214, 1.6629, 0.1757, 1.5640, 1.6836, 1.2494,
         1.2579, 0.8234, 0.7068, 1.0331, 1.5233, 1.6318, 1.2737, 1.6762, 1.6762,
         0.6784, 0.7367, 1.6522, 1.4015, 0.8452, 1.6554, 1.1282, 1.6928, 1.6448,
         1.0060, 0.6901, 0.6319, 0.9263, 1.3992, 1.6335, 0.8623, 4.9566, 4.4660,
         0.7295, 1.2414, 1.3173, 1.6018, 0.9608, 1.5629, 0.3536, 1.5721, 1.7183],
        [1.3637, 1.3922, 1.4532, 1.4281, 1.3936, 1.3661, 1.3323, 1.3610, 1.3610,
         1.3293, 1.3874, 1.3058, 1.4432, 1.4154, 1.4811, 1.3290, 1.4204, 1.3390,
         1.4129, 1.4353, 1.4422, 1.4164, 1.3874, 1.3780, 1.3479, 1.3759, 1.3759,
         1.4152, 1.4651, 1.4036, 1.2492, 1.2856, 1.1956, 1.4197, 1.2822, 1.4060,
         1.4752, 1.2463, 1.5014, 1.4845, 1.1336, 1.0477, 1.4821, 1.4073, 0.9076,
         2.4988, 2.0922, 2.3975, 2.3037, 1.7833, 1.5913, 2.4101, 2.2253, 1.5783]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 72 : 183.23495701597773
Test loss for epoch 72 : 183.2296278987273
Test Precision for epoch 72 : 0.26153846153846155
Test Recall for epoch 72 : 0.26153846153846155
Test F1 for epoch 72 : 0.26153846153846155


theta for epoch 73 : tensor([[2.0386, 2.0730, 2.1363, 2.1915, 2.1586, 2.0414, 2.1247, 2.0367, 2.0367,
         1.3352, 1.3458, 1.3529, 1.3594, 1.3258, 1.4046, 1.3346, 1.3309, 1.3040,
         1.3206, 1.3054, 1.3238, 1.3319, 1.2976, 1.2889, 1.3125, 1.2855, 1.2855,
         1.3203, 1.3839, 1.3104, 1.3349, 1.3697, 1.3238, 1.3292, 1.2739, 1.3128,
         1.3943, 1.4268, 1.4211, 1.4026, 1.3962, 1.3428, 1.4009, 1.4045, 1.3626,
         1.4025, 1.3522, 1.3449, 1.3211, 1.4021, 1.3479, 1.4315, 1.3249, 1.3311],
        [1.3541, 1.2129, 1.0607, 1.2881, 1.3481, 1.4062, 1.3255, 1.3988, 1.3988,
         1.6064, 1.8423, 1.5145, 2.3477, 1.5877, 3.3484, 1.6552, 1.4638, 3.0259,
         1.1867, 1.2571, 0.9913, 1.2320, 1.3725, 1.4108, 1.3845, 1.4093, 1.4093,
         1.3515, 1.1234, 1.4307, 1.4048, 1.1631, 1.4419, 1.4390, 1.3994, 1.3978,
         1.4255, 1.5460, 1.4956, 1.4268, 1.4026, 1.5008, 1.4772, 0.6271, 1.4386,
         1.0711, 1.4751, 1.4625, 1.4475, 1.1252, 1.4700, 0.8949, 1.4506, 1.4570],
        [1.2848, 1.3125, 1.3744, 1.3471, 1.3036, 1.2898, 1.2927, 1.2822, 1.2822,
         1.3432, 1.3538, 1.3607, 1.3656, 1.3338, 1.3275, 1.3425, 1.3179, 1.2571,
         2.0792, 2.1939, 2.3138, 2.2215, 1.9579, 2.0178, 2.1266, 1.9450, 1.9450,
         1.3610, 1.3376, 1.3176, 1.3395, 1.3617, 1.3290, 1.3365, 1.3240, 1.3199,
         1.4054, 1.4381, 1.4318, 1.3975, 1.4081, 1.4021, 1.4121, 1.3197, 1.3588,
         1.3500, 1.3620, 1.3546, 1.3305, 1.3071, 1.3580, 1.3868, 1.3339, 1.3403],
        [1.3075, 1.3340, 1.2660, 1.2373, 1.3357, 1.3117, 1.3194, 1.3052, 1.3052,
         1.3634, 1.2856, 1.3721, 1.3346, 1.3547, 1.3226, 1.3628, 1.3589, 1.0795,
         1.3513, 1.3021, 1.3908, 1.3608, 1.3254, 1.2777, 1.3396, 1.3155, 1.3155,
         2.4846, 2.0311, 1.8381, 1.9522, 2.4497, 1.8383, 2.4095, 1.8574, 1.8304,
         1.4261, 1.4491, 1.4015, 1.3896, 1.4288, 1.3767, 1.4234, 1.1590, 1.3799,
         1.4295, 1.3149, 1.2345, 1.3063, 1.4280, 1.2451, 1.4601, 1.3088, 1.3632],
        [1.6711, 1.3461, 0.5284, 0.7650, 1.1359, 1.5518, 1.4823, 1.6688, 1.6688,
         1.5829, 1.3356, 1.4018, 0.9222, 1.6643, 0.1778, 1.5656, 1.6855, 1.2498,
         1.2598, 0.8242, 0.7090, 1.0348, 1.5249, 1.6334, 1.2743, 1.6781, 1.6781,
         0.6791, 0.7393, 1.6537, 1.4025, 0.8448, 1.6566, 1.1272, 1.6945, 1.6460,
         0.9944, 0.6825, 0.6242, 0.9157, 1.3861, 1.6211, 0.8519, 5.0133, 4.5113,
         0.7310, 1.2420, 1.3180, 1.6033, 0.9629, 1.5638, 0.3565, 1.5736, 1.7203],
        [1.3611, 1.3900, 1.4519, 1.4264, 1.3918, 1.3635, 1.3299, 1.3584, 1.3584,
         1.3273, 1.3858, 1.3041, 1.4417, 1.4138, 1.4799, 1.3268, 1.4187, 1.3377,
         1.4103, 1.4334, 1.4405, 1.4142, 1.3845, 1.3750, 1.3451, 1.3728, 1.3728,
         1.4131, 1.4624, 1.4004, 1.2458, 1.2839, 1.1929, 1.4173, 1.2787, 1.4028,
         1.4759, 1.2455, 1.5022, 1.4850, 1.1323, 1.0461, 1.4830, 1.4056, 0.9054,
         2.5017, 2.0982, 2.4057, 2.3105, 1.7872, 1.5948, 2.4122, 2.2330, 1.5819]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 73 : 183.21107160571077
Test loss for epoch 73 : 183.20666821917936
Test Precision for epoch 73 : 0.26153846153846155
Test Recall for epoch 73 : 0.26153846153846155
Test F1 for epoch 73 : 0.26153846153846155


theta for epoch 74 : tensor([[2.0430, 2.0761, 2.1391, 2.1951, 2.1618, 2.0456, 2.1296, 2.0411, 2.0411,
         1.3341, 1.3449, 1.3518, 1.3588, 1.3244, 1.4045, 1.3333, 1.3294, 1.3033,
         1.3204, 1.3055, 1.3233, 1.3317, 1.2968, 1.2881, 1.3120, 1.2846, 1.2846,
         1.3188, 1.3819, 1.3071, 1.3322, 1.3678, 1.3207, 1.3268, 1.2708, 1.3096,
         1.3958, 1.4282, 1.4225, 1.4042, 1.3977, 1.3441, 1.4024, 1.4056, 1.3634,
         1.4006, 1.3501, 1.3428, 1.3185, 1.4002, 1.3456, 1.4303, 1.3223, 1.3285],
        [1.3527, 1.2127, 1.0607, 1.2874, 1.3472, 1.4048, 1.3241, 1.3974, 1.3974,
         1.6061, 1.8418, 1.5162, 2.3502, 1.5884, 3.3653, 1.6570, 1.4655, 3.0424,
         1.1853, 1.2563, 0.9912, 1.2309, 1.3712, 1.4096, 1.3835, 1.4079, 1.4079,
         1.3504, 1.1213, 1.4292, 1.4035, 1.1617, 1.4405, 1.4379, 1.3978, 1.3964,
         1.4266, 1.5470, 1.4964, 1.4276, 1.4036, 1.5020, 1.4780, 0.6274, 1.4417,
         1.0694, 1.4733, 1.4607, 1.4451, 1.1229, 1.4680, 0.8936, 1.4483, 1.4546],
        [1.2838, 1.3119, 1.3744, 1.3469, 1.3040, 1.2887, 1.2918, 1.2811, 1.2811,
         1.3411, 1.3518, 1.3587, 1.3642, 1.3315, 1.3271, 1.3403, 1.3157, 1.2555,
         2.0832, 2.1963, 2.3160, 2.2246, 1.9628, 2.0234, 2.1304, 1.9502, 1.9502,
         1.3596, 1.3360, 1.3158, 1.3380, 1.3601, 1.3274, 1.3352, 1.3224, 1.3181,
         1.4063, 1.4389, 1.4327, 1.3987, 1.4088, 1.4028, 1.4132, 1.3194, 1.3588,
         1.3489, 1.3599, 1.3523, 1.3277, 1.3055, 1.3555, 1.3852, 1.3313, 1.3376],
        [1.3068, 1.3337, 1.2669, 1.2381, 1.3355, 1.3110, 1.3189, 1.3044, 1.3044,
         1.3626, 1.2848, 1.3715, 1.3347, 1.3536, 1.3229, 1.3617, 1.3578, 1.0790,
         1.3508, 1.3031, 1.3909, 1.3606, 1.3246, 1.2769, 1.3392, 1.3146, 1.3146,
         2.4890, 2.0345, 1.8405, 1.9545, 2.4546, 1.8411, 2.4140, 1.8598, 1.8331,
         1.4270, 1.4505, 1.4025, 1.3905, 1.4293, 1.3777, 1.4245, 1.1607, 1.3810,
         1.4286, 1.3140, 1.2334, 1.3045, 1.4270, 1.2439, 1.4595, 1.3071, 1.3616],
        [1.6734, 1.3470, 0.5303, 0.7665, 1.1365, 1.5542, 1.4844, 1.6711, 1.6711,
         1.5832, 1.3364, 1.4020, 0.9222, 1.6651, 0.1788, 1.5665, 1.6866, 1.2493,
         1.2614, 0.8245, 0.7106, 1.0361, 1.5264, 1.6349, 1.2747, 1.6798, 1.6798,
         0.6787, 0.7407, 1.6541, 1.4025, 0.8433, 1.6567, 1.1253, 1.6953, 1.6461,
         0.9840, 0.6759, 0.6176, 0.9062, 1.3739, 1.6096, 0.8427, 5.0707, 4.5573,
         0.7314, 1.2419, 1.3180, 1.6040, 0.9640, 1.5639, 0.3582, 1.5744, 1.7216],
        [1.3591, 1.3883, 1.4510, 1.4252, 1.3906, 1.3615, 1.3282, 1.3564, 1.3564,
         1.3251, 1.3841, 1.3023, 1.4401, 1.4118, 1.4785, 1.3245, 1.4167, 1.3362,
         1.4085, 1.4324, 1.4397, 1.4129, 1.3826, 1.3730, 1.3432, 1.3708, 1.3708,
         1.4106, 1.4594, 1.3967, 1.2421, 1.2820, 1.1900, 1.4144, 1.2748, 1.3992,
         1.4773, 1.2454, 1.5036, 1.4862, 1.1317, 1.0453, 1.4845, 1.4048, 0.9042,
         2.5039, 2.1033, 2.4131, 2.3164, 1.7905, 1.5975, 2.4137, 2.2397, 1.5846]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 74 : 183.18805030509685
Test loss for epoch 74 : 183.1856877641532
Test Precision for epoch 74 : 0.26153846153846155
Test Recall for epoch 74 : 0.26153846153846155
Test F1 for epoch 74 : 0.26153846153846155


theta for epoch 75 : tensor([[2.0461, 2.0781, 2.1408, 2.1975, 2.1638, 2.0486, 2.1331, 2.0442, 2.0442,
         1.3330, 1.3441, 1.3508, 1.3581, 1.3230, 1.4044, 1.3321, 1.3280, 1.3026,
         1.3207, 1.3061, 1.3233, 1.3320, 1.2967, 1.2879, 1.3122, 1.2844, 1.2844,
         1.3185, 1.3811, 1.3052, 1.3308, 1.3671, 1.3191, 1.3258, 1.2691, 1.3077,
         1.3965, 1.4289, 1.4233, 1.4051, 1.3985, 1.3448, 1.4033, 1.4062, 1.3636,
         1.3999, 1.3493, 1.3418, 1.3171, 1.3995, 1.3446, 1.4301, 1.3211, 1.3272],
        [1.3511, 1.2123, 1.0604, 1.2863, 1.3461, 1.4031, 1.3226, 1.3957, 1.3957,
         1.6057, 1.8411, 1.5178, 2.3524, 1.5891, 3.3818, 1.6587, 1.4671, 3.0586,
         1.1843, 1.2557, 0.9914, 1.2300, 1.3703, 1.4085, 1.3828, 1.4068, 1.4068,
         1.3499, 1.1198, 1.4283, 1.4027, 1.1610, 1.4398, 1.4376, 1.3968, 1.3956,
         1.4270, 1.5473, 1.4965, 1.4277, 1.4038, 1.5025, 1.4782, 0.6270, 1.4438,
         1.0684, 1.4721, 1.4596, 1.4433, 1.1213, 1.4665, 0.8925, 1.4466, 1.4529],
        [1.2824, 1.3109, 1.3739, 1.3463, 1.3040, 1.2873, 1.2906, 1.2797, 1.2797,
         1.3389, 1.3495, 1.3566, 1.3625, 1.3290, 1.3265, 1.3380, 1.3134, 1.2537,
         2.0872, 2.1988, 2.3183, 2.2278, 1.9677, 2.0291, 2.1342, 1.9554, 1.9554,
         1.3588, 1.3352, 1.3147, 1.3373, 1.3592, 1.3265, 1.3345, 1.3215, 1.3170,
         1.4064, 1.4390, 1.4328, 1.3990, 1.4088, 1.4028, 1.4134, 1.3184, 1.3580,
         1.3486, 1.3584, 1.3508, 1.3257, 1.3047, 1.3539, 1.3845, 1.3295, 1.3357],
        [1.3055, 1.3328, 1.2673, 1.2383, 1.3347, 1.3098, 1.3178, 1.3031, 1.3031,
         1.3612, 1.2834, 1.3705, 1.3342, 1.3521, 1.3227, 1.3602, 1.3562, 1.0781,
         1.3502, 1.3039, 1.3907, 1.3601, 1.3237, 1.2759, 1.3387, 1.3135, 1.3135,
         2.4939, 2.0386, 1.8435, 1.9574, 2.4600, 1.8444, 2.4191, 1.8629, 1.8365,
         1.4268, 1.4508, 1.4024, 1.3904, 1.4289, 1.3777, 1.4246, 1.1615, 1.3811,
         1.4279, 1.3133, 1.2325, 1.3029, 1.4262, 1.2429, 1.4591, 1.3056, 1.3602],
        [1.6750, 1.3472, 0.5314, 0.7673, 1.1363, 1.5557, 1.4857, 1.6726, 1.6726,
         1.5831, 1.3367, 1.4017, 0.9217, 1.6654, 0.1790, 1.5667, 1.6873, 1.2483,
         1.2626, 0.8243, 0.7116, 1.0369, 1.5276, 1.6361, 1.2748, 1.6813, 1.6813,
         0.6785, 0.7421, 1.6549, 1.4028, 0.8420, 1.6570, 1.1237, 1.6964, 1.6467,
         0.9740, 0.6698, 0.6114, 0.8973, 1.3620, 1.5982, 0.8340, 5.1284, 4.6034,
         0.7316, 1.2419, 1.3181, 1.6048, 0.9648, 1.5641, 0.3595, 1.5753, 1.7230],
        [1.3576, 1.3871, 1.4503, 1.4242, 1.3898, 1.3601, 1.3269, 1.3549, 1.3549,
         1.3232, 1.3828, 1.3008, 1.4388, 1.4101, 1.4775, 1.3225, 1.4149, 1.3349,
         1.4076, 1.4322, 1.4399, 1.4126, 1.3817, 1.3719, 1.3423, 1.3696, 1.3696,
         1.4095, 1.4579, 1.3944, 1.2399, 1.2816, 1.1887, 1.4130, 1.2725, 1.3969,
         1.4782, 1.2447, 1.5044, 1.4869, 1.1308, 1.0442, 1.4854, 1.4037, 0.9030,
         2.5052, 2.1072, 2.4193, 2.3211, 1.7929, 1.5990, 2.4143, 2.2453, 1.5861]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 75 : 183.16575761644222
Test loss for epoch 75 : 183.16569692229882
Test Precision for epoch 75 : 0.26153846153846155
Test Recall for epoch 75 : 0.26153846153846155
Test F1 for epoch 75 : 0.26153846153846155


theta for epoch 76 : tensor([[2.0504, 2.0814, 2.1438, 2.2011, 2.1672, 2.0528, 2.1379, 2.0485, 2.0485,
         1.3317, 1.3429, 1.3495, 1.3572, 1.3215, 1.4038, 1.3307, 1.3264, 1.3016,
         1.3200, 1.3056, 1.3222, 1.3312, 1.2956, 1.2867, 1.3113, 1.2832, 1.2832,
         1.3190, 1.3812, 1.3041, 1.3302, 1.3673, 1.3182, 1.3257, 1.2684, 1.3068,
         1.3954, 1.4277, 1.4220, 1.4040, 1.3975, 1.3436, 1.4021, 1.4050, 1.3620,
         1.4000, 1.3493, 1.3417, 1.3166, 1.3995, 1.3444, 1.4306, 1.3207, 1.3268],
        [1.3501, 1.2126, 1.0606, 1.2858, 1.3456, 1.4020, 1.3216, 1.3946, 1.3946,
         1.6049, 1.8401, 1.5192, 2.3540, 1.5894, 3.3978, 1.6601, 1.4684, 3.0744,
         1.1833, 1.2551, 0.9915, 1.2292, 1.3692, 1.4075, 1.3820, 1.4057, 1.4057,
         1.3505, 1.1194, 1.4284, 1.4030, 1.1613, 1.4401, 1.4383, 1.3969, 1.3957,
         1.4260, 1.5464, 1.4954, 1.4266, 1.4027, 1.5018, 1.4771, 0.6257, 1.4445,
         1.0687, 1.4722, 1.4597, 1.4428, 1.1212, 1.4664, 0.8925, 1.4463, 1.4526],
        [1.2816, 1.3103, 1.3736, 1.3461, 1.3045, 1.2864, 1.2900, 1.2789, 1.2789,
         1.3371, 1.3477, 1.3549, 1.3613, 1.3270, 1.3264, 1.3361, 1.3117, 1.2525,
         2.0907, 2.2007, 2.3200, 2.2304, 1.9721, 2.0343, 2.1375, 1.9601, 1.9601,
         1.3590, 1.3355, 1.3145, 1.3375, 1.3593, 1.3265, 1.3350, 1.3215, 1.3169,
         1.4052, 1.4377, 1.4316, 1.3979, 1.4075, 1.4015, 1.4123, 1.3162, 1.3559,
         1.3497, 1.3584, 1.3507, 1.3253, 1.3054, 1.3537, 1.3851, 1.3292, 1.3354],
        [1.3041, 1.3317, 1.2674, 1.2384, 1.3336, 1.3083, 1.3165, 1.3016, 1.3016,
         1.3597, 1.2819, 1.3693, 1.3335, 1.3504, 1.3222, 1.3585, 1.3544, 1.0772,
         1.3487, 1.3039, 1.3897, 1.3588, 1.3220, 1.2743, 1.3373, 1.3117, 1.3117,
         2.4994, 2.0435, 1.8473, 1.9610, 2.4661, 1.8486, 2.4247, 1.8668, 1.8407,
         1.4249, 1.4495, 1.4004, 1.3886, 1.4269, 1.3761, 1.4229, 1.1608, 1.3796,
         1.4277, 1.3132, 1.2320, 1.3018, 1.4259, 1.2424, 1.4592, 1.3046, 1.3593],
        [1.6767, 1.3477, 0.5329, 0.7684, 1.1365, 1.5574, 1.4871, 1.6743, 1.6743,
         1.5833, 1.3374, 1.4015, 0.9216, 1.6661, 0.1796, 1.5672, 1.6882, 1.2475,
         1.2636, 0.8242, 0.7124, 1.0376, 1.5286, 1.6371, 1.2750, 1.6826, 1.6826,
         0.6795, 0.7447, 1.6567, 1.4042, 0.8419, 1.6583, 1.1236, 1.6985, 1.6482,
         0.9636, 0.6633, 0.6049, 0.8879, 1.3495, 1.5861, 0.8249, 5.1857, 4.6489,
         0.7326, 1.2429, 1.3193, 1.6063, 0.9667, 1.5652, 0.3616, 1.5773, 1.7252],
        [1.3568, 1.3864, 1.4499, 1.4237, 1.3896, 1.3594, 1.3263, 1.3541, 1.3541,
         1.3218, 1.3819, 1.2999, 1.4379, 1.4087, 1.4770, 1.3209, 1.4135, 1.3340,
         1.4064, 1.4318, 1.4398, 1.4120, 1.3805, 1.3707, 1.3413, 1.3684, 1.3684,
         1.4096, 1.4578, 1.3935, 1.2393, 1.2826, 1.1889, 1.4129, 1.2715, 1.3961,
         1.4776, 1.2426, 1.5038, 1.4861, 1.1285, 1.0418, 1.4848, 1.4015, 0.9009,
         2.5067, 2.1110, 2.4254, 2.3257, 1.7956, 1.6006, 2.4150, 2.2508, 1.5876]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 76 : 183.14262342180893
Test loss for epoch 76 : 183.14378021620428
Test Precision for epoch 76 : 0.26153846153846155
Test Recall for epoch 76 : 0.26153846153846155
Test F1 for epoch 76 : 0.26153846153846155


theta for epoch 77 : tensor([[2.0556, 2.0856, 2.1478, 2.2057, 2.1715, 2.0580, 2.1436, 2.0538, 2.0538,
         1.3307, 1.3422, 1.3486, 1.3566, 1.3203, 1.4035, 1.3296, 1.3252, 1.3009,
         1.3188, 1.3045, 1.3205, 1.3299, 1.2940, 1.2851, 1.3099, 1.2816, 1.2816,
         1.3191, 1.3808, 1.3029, 1.3293, 1.3671, 1.3171, 1.3252, 1.2673, 1.3056,
         1.3931, 1.4254, 1.4197, 1.4018, 1.3954, 1.3414, 1.3999, 1.4028, 1.3594,
         1.4001, 1.3493, 1.3416, 1.3163, 1.3995, 1.3443, 1.4311, 1.3205, 1.3265],
        [1.3494, 1.2132, 1.0608, 1.2855, 1.3453, 1.4012, 1.3210, 1.3938, 1.3938,
         1.6042, 1.8390, 1.5205, 2.3555, 1.5898, 3.4136, 1.6613, 1.4697, 3.0900,
         1.1828, 1.2547, 0.9919, 1.2286, 1.3685, 1.4066, 1.3814, 1.4048, 1.4048,
         1.3513, 1.1192, 1.4286, 1.4033, 1.1619, 1.4405, 1.4391, 1.3971, 1.3961,
         1.4245, 1.5449, 1.4937, 1.4249, 1.4011, 1.5006, 1.4755, 0.6240, 1.4445,
         1.0697, 1.4728, 1.4604, 1.4430, 1.1217, 1.4668, 0.8929, 1.4466, 1.4528],
        [1.2807, 1.3096, 1.3731, 1.3456, 1.3048, 1.2855, 1.2894, 1.2780, 1.2780,
         1.3361, 1.3467, 1.3540, 1.3608, 1.3258, 1.3270, 1.3350, 1.3107, 1.2521,
         2.0944, 2.2028, 2.3218, 2.2331, 1.9766, 2.0394, 2.1408, 1.9649, 1.9649,
         1.3593, 1.3357, 1.3144, 1.3378, 1.3594, 1.3266, 1.3354, 1.3216, 1.3168,
         1.4032, 1.4356, 1.4296, 1.3961, 1.4055, 1.3996, 1.4103, 1.3134, 1.3532,
         1.3511, 1.3588, 1.3511, 1.3254, 1.3065, 1.3540, 1.3862, 1.3293, 1.3356],
        [1.3028, 1.3307, 1.2677, 1.2387, 1.3327, 1.3071, 1.3154, 1.3003, 1.3003,
         1.3590, 1.2811, 1.3689, 1.3335, 1.3494, 1.3224, 1.3576, 1.3534, 1.0771,
         1.3475, 1.3041, 1.3887, 1.3577, 1.3206, 1.2729, 1.3362, 1.3101, 1.3101,
         2.5046, 2.0482, 1.8510, 1.9645, 2.4717, 1.8526, 2.4301, 1.8704, 1.8446,
         1.4224, 1.4475, 1.3979, 1.3862, 1.4244, 1.3740, 1.4205, 1.1598, 1.3776,
         1.4279, 1.3136, 1.2321, 1.3012, 1.4260, 1.2424, 1.4596, 1.3041, 1.3589],
        [1.6785, 1.3482, 0.5347, 0.7697, 1.1368, 1.5591, 1.4886, 1.6760, 1.6760,
         1.5841, 1.3387, 1.4020, 0.9222, 1.6673, 0.1807, 1.5681, 1.6896, 1.2474,
         1.2647, 0.8242, 0.7134, 1.0384, 1.5296, 1.6381, 1.2753, 1.6839, 1.6839,
         0.6810, 0.7476, 1.6585, 1.4058, 0.8421, 1.6596, 1.1238, 1.7007, 1.6498,
         0.9530, 0.6566, 0.5983, 0.8784, 1.3366, 1.5734, 0.8157, 5.2426, 4.6938,
         0.7341, 1.2445, 1.3210, 1.6082, 0.9691, 1.5668, 0.3642, 1.5796, 1.7279],
        [1.3560, 1.3856, 1.4491, 1.4230, 1.3893, 1.3587, 1.3256, 1.3533, 1.3533,
         1.3211, 1.3818, 1.2997, 1.4377, 1.4079, 1.4773, 1.3201, 1.4127, 1.3338,
         1.4051, 1.4311, 1.4396, 1.4114, 1.3793, 1.3695, 1.3401, 1.3671, 1.3671,
         1.4097, 1.4578, 1.3926, 1.2387, 1.2836, 1.1893, 1.4128, 1.2706, 1.3952,
         1.4761, 1.2395, 1.5022, 1.4844, 1.1254, 1.0387, 1.4834, 1.3988, 0.8982,
         2.5086, 2.1152, 2.4318, 2.3306, 1.7988, 1.6024, 2.4163, 2.2566, 1.5895]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 77 : 183.12051312440877
Test loss for epoch 77 : 183.12222498984008
Test Precision for epoch 77 : 0.26153846153846155
Test Recall for epoch 77 : 0.26153846153846155
Test F1 for epoch 77 : 0.26153846153846155


theta for epoch 78 : tensor([[2.0599, 2.0889, 2.1509, 2.2093, 2.1749, 2.0621, 2.1483, 2.0580, 2.0580,
         1.3307, 1.3423, 1.3486, 1.3569, 1.3201, 1.4040, 1.3295, 1.3249, 1.3011,
         1.3184, 1.3041, 1.3194, 1.3294, 1.2934, 1.2844, 1.3093, 1.2809, 1.2809,
         1.3186, 1.3798, 1.3012, 1.3279, 1.3663, 1.3154, 1.3243, 1.2658, 1.3039,
         1.3917, 1.4240, 1.4182, 1.4006, 1.3942, 1.3401, 1.3985, 1.4016, 1.3578,
         1.3995, 1.3488, 1.3411, 1.3156, 1.3989, 1.3438, 1.4308, 1.3198, 1.3259],
        [1.3482, 1.2134, 1.0606, 1.2847, 1.3446, 1.3999, 1.3199, 1.3925, 1.3925,
         1.6036, 1.8380, 1.5220, 2.3569, 1.5903, 3.4293, 1.6627, 1.4712, 3.1056,
         1.1829, 1.2549, 0.9928, 1.2287, 1.3683, 1.4063, 1.3813, 1.4044, 1.4044,
         1.3515, 1.1184, 1.4283, 1.4031, 1.1620, 1.4403, 1.4393, 1.3968, 1.3958,
         1.4236, 1.5440, 1.4926, 1.4238, 1.3999, 1.5000, 1.4745, 0.6229, 1.4449,
         1.0700, 1.4727, 1.4604, 1.4425, 1.1217, 1.4666, 0.8927, 1.4462, 1.4524],
        [1.2789, 1.3079, 1.3714, 1.3442, 1.3041, 1.2837, 1.2879, 1.2762, 1.2762,
         1.3356, 1.3461, 1.3534, 1.3607, 1.3251, 1.3280, 1.3344, 1.3102, 1.2520,
         2.0988, 2.2055, 2.3243, 2.2365, 1.9818, 2.0453, 2.1448, 1.9703, 1.9703,
         1.3586, 1.3352, 1.3134, 1.3371, 1.3587, 1.3257, 1.3349, 1.3207, 1.3158,
         1.4016, 1.4340, 1.4280, 1.3946, 1.4040, 1.3981, 1.4088, 1.3111, 1.3509,
         1.3513, 1.3580, 1.3503, 1.3244, 1.3064, 1.3532, 1.3860, 1.3284, 1.3346],
        [1.3016, 1.3297, 1.2679, 1.2390, 1.3318, 1.3059, 1.3143, 1.2991, 1.2991,
         1.3591, 1.2813, 1.3694, 1.3344, 1.3493, 1.3235, 1.3576, 1.3532, 1.0780,
         1.3471, 1.3052, 1.3886, 1.3575, 1.3202, 1.2726, 1.3360, 1.3096, 1.3096,
         2.5088, 2.0520, 1.8538, 1.9670, 2.4764, 1.8557, 2.4344, 1.8732, 1.8478,
         1.4209, 1.4464, 1.3963, 1.3847, 1.4228, 1.3729, 1.4191, 1.1598, 1.3766,
         1.4280, 1.3139, 1.2321, 1.3006, 1.4260, 1.2424, 1.4599, 1.3036, 1.3583],
        [1.6795, 1.3482, 0.5359, 0.7704, 1.1366, 1.5600, 1.4893, 1.6770, 1.6770,
         1.5852, 1.3403, 1.4027, 0.9232, 1.6689, 0.1818, 1.5693, 1.6913, 1.2476,
         1.2659, 0.8245, 0.7142, 1.0393, 1.5309, 1.6392, 1.2759, 1.6853, 1.6853,
         0.6819, 0.7498, 1.6597, 1.4067, 0.8416, 1.6600, 1.1235, 1.7022, 1.6507,
         0.9432, 0.6506, 0.5923, 0.8696, 1.3242, 1.5611, 0.8073, 5.2998, 4.7389,
         0.7349, 1.2455, 1.3221, 1.6093, 0.9706, 1.5676, 0.3659, 1.5813, 1.7297],
        [1.3546, 1.3840, 1.4476, 1.4215, 1.3883, 1.3575, 1.3243, 1.3519, 1.3519,
         1.3210, 1.3824, 1.3002, 1.4382, 1.4078, 1.4783, 1.3199, 1.4124, 1.3342,
         1.4043, 1.4309, 1.4398, 1.4112, 1.3786, 1.3687, 1.3395, 1.3663, 1.3663,
         1.4089, 1.4571, 1.3909, 1.2373, 1.2839, 1.1890, 1.4118, 1.2689, 1.3935,
         1.4753, 1.2371, 1.5013, 1.4834, 1.1229, 1.0362, 1.4825, 1.3969, 0.8964,
         2.5106, 2.1191, 2.4380, 2.3354, 1.8020, 1.6042, 2.4177, 2.2622, 1.5912]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 78 : 183.09872678803913
Test loss for epoch 78 : 183.10157527968224
Test Precision for epoch 78 : 0.26153846153846155
Test Recall for epoch 78 : 0.26153846153846155
Test F1 for epoch 78 : 0.26153846153846155


theta for epoch 79 : tensor([[2.0636, 2.0918, 2.1536, 2.2125, 2.1779, 2.0658, 2.1525, 2.0617, 2.0617,
         1.3307, 1.3423, 1.3486, 1.3571, 1.3199, 1.4043, 1.3294, 1.3247, 1.3013,
         1.3180, 1.3037, 1.3184, 1.3289, 1.2928, 1.2839, 1.3088, 1.2804, 1.2804,
         1.3179, 1.3786, 1.2994, 1.3263, 1.3653, 1.3136, 1.3232, 1.2641, 1.3021,
         1.3918, 1.4241, 1.4182, 1.4008, 1.3946, 1.3405, 1.3986, 1.4020, 1.3577,
         1.3981, 1.3474, 1.3397, 1.3142, 1.3974, 1.3425, 1.4296, 1.3184, 1.3245],
        [1.3473, 1.2139, 1.0603, 1.2839, 1.3441, 1.3988, 1.3190, 1.3915, 1.3915,
         1.6029, 1.8370, 1.5234, 2.3580, 1.5907, 3.4447, 1.6640, 1.4726, 3.1209,
         1.1830, 1.2550, 0.9937, 1.2286, 1.3681, 1.4060, 1.3812, 1.4041, 1.4041,
         1.3513, 1.1173, 1.4276, 1.4025, 1.1618, 1.4398, 1.4392, 1.3961, 1.3952,
         1.4236, 1.5443, 1.4926, 1.4237, 1.3999, 1.5005, 1.4746, 0.6226, 1.4462,
         1.0697, 1.4718, 1.4595, 1.4412, 1.1209, 1.4656, 0.8917, 1.4449, 1.4511],
        [1.2772, 1.3064, 1.3697, 1.3428, 1.3035, 1.2820, 1.2866, 1.2746, 1.2746,
         1.3349, 1.3454, 1.3528, 1.3604, 1.3242, 1.3289, 1.3336, 1.3096, 1.2519,
         2.1031, 2.2081, 2.3268, 2.2398, 1.9868, 2.0511, 2.1486, 1.9756, 1.9756,
         1.3576, 1.3343, 1.3120, 1.3361, 1.3577, 1.3245, 1.3341, 1.3195, 1.3144,
         1.4012, 1.4335, 1.4275, 1.3944, 1.4037, 1.3979, 1.4084, 1.3100, 1.3498,
         1.3504, 1.3563, 1.3484, 1.3225, 1.3053, 1.3514, 1.3847, 1.3266, 1.3328],
        [1.3006, 1.3289, 1.2683, 1.2395, 1.3311, 1.3048, 1.3134, 1.2981, 1.2981,
         1.3592, 1.2813, 1.3698, 1.3351, 1.3492, 1.3244, 1.3575, 1.3530, 1.0789,
         1.3468, 1.3063, 1.3883, 1.3572, 1.3198, 1.2724, 1.3358, 1.3091, 1.3091,
         2.5126, 2.0556, 1.8564, 1.9694, 2.4808, 1.8586, 2.4385, 1.8758, 1.8507,
         1.4206, 1.4465, 1.3960, 1.3846, 1.4226, 1.3732, 1.4189, 1.1613, 1.3769,
         1.4274, 1.3136, 1.2315, 1.2993, 1.4253, 1.2418, 1.4594, 1.3024, 1.3572],
        [1.6805, 1.3481, 0.5372, 0.7713, 1.1365, 1.5609, 1.4900, 1.6780, 1.6780,
         1.5863, 1.3417, 1.4033, 0.9241, 1.6704, 0.1829, 1.5703, 1.6929, 1.2477,
         1.2669, 0.8247, 0.7149, 1.0402, 1.5321, 1.6402, 1.2766, 1.6867, 1.6867,
         0.6826, 0.7517, 1.6604, 1.4073, 0.8410, 1.6600, 1.1231, 1.7033, 1.6512,
         0.9340, 0.6452, 0.5869, 0.8614, 1.3123, 1.5492, 0.7995, 5.3573, 4.7842,
         0.7350, 1.2457, 1.3226, 1.6094, 0.9713, 1.5676, 0.3669, 1.5822, 1.7306],
        [1.3530, 1.3824, 1.4457, 1.4197, 1.3871, 1.3562, 1.3228, 1.3504, 1.3504,
         1.3205, 1.3826, 1.3003, 1.4381, 1.4071, 1.4788, 1.3193, 1.4117, 1.3340,
         1.4030, 1.4302, 1.4395, 1.4106, 1.3775, 1.3677, 1.3385, 1.3652, 1.3652,
         1.4073, 1.4558, 1.3885, 1.2353, 1.2835, 1.1881, 1.4102, 1.2667, 1.3912,
         1.4755, 1.2357, 1.5014, 1.4836, 1.1217, 1.0350, 1.4828, 1.3965, 0.8959,
         2.5128, 2.1230, 2.4443, 2.3401, 1.8054, 1.6060, 2.4193, 2.2680, 1.5930]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 79 : 183.07714299060885
Test loss for epoch 79 : 183.0815003138231
Test Precision for epoch 79 : 0.26153846153846155
Test Recall for epoch 79 : 0.26153846153846155
Test F1 for epoch 79 : 0.26153846153846155


theta for epoch 80 : tensor([[2.0679, 2.0953, 2.1570, 2.2164, 2.1816, 2.0701, 2.1573, 2.0660, 2.0660,
         1.3296, 1.3413, 1.3475, 1.3563, 1.3187, 1.4035, 1.3283, 1.3234, 1.3003,
         1.3168, 1.3024, 1.3165, 1.3276, 1.2915, 1.2826, 1.3075, 1.2791, 1.2791,
         1.3173, 1.3775, 1.2979, 1.3250, 1.3644, 1.3120, 1.3223, 1.2628, 1.3007,
         1.3926, 1.4248, 1.4188, 1.4016, 1.3957, 1.3415, 1.3993, 1.4032, 1.3584,
         1.3963, 1.3458, 1.3380, 1.3126, 1.3955, 1.3409, 1.4279, 1.3167, 1.3229],
        [1.3471, 1.2150, 1.0605, 1.2838, 1.3443, 1.3983, 1.3187, 1.3911, 1.3911,
         1.6021, 1.8358, 1.5247, 2.3589, 1.5910, 3.4598, 1.6650, 1.4738, 3.1360,
         1.1826, 1.2544, 0.9939, 1.2281, 1.3673, 1.4051, 1.3805, 1.4031, 1.4031,
         1.3513, 1.1163, 1.4271, 1.4021, 1.1619, 1.4394, 1.4393, 1.3956, 1.3948,
         1.4243, 1.5451, 1.4932, 1.4242, 1.4003, 1.5016, 1.4753, 0.6228, 1.4480,
         1.0691, 1.4705, 1.4584, 1.4397, 1.1199, 1.4643, 0.8906, 1.4435, 1.4497],
        [1.2768, 1.3059, 1.3690, 1.3424, 1.3039, 1.2815, 1.2864, 1.2741, 1.2741,
         1.3338, 1.3443, 1.3517, 1.3596, 1.3229, 1.3294, 1.3324, 1.3086, 1.2512,
         2.1067, 2.2100, 2.3284, 2.2423, 1.9911, 2.0560, 2.1517, 1.9801, 1.9801,
         1.3571, 1.3339, 1.3112, 1.3356, 1.3571, 1.3238, 1.3338, 1.3188, 1.3136,
         1.4016, 1.4339, 1.4278, 1.3949, 1.4043, 1.3985, 1.4089, 1.3099, 1.3496,
         1.3496, 1.3546, 1.3468, 1.3209, 1.3043, 1.3498, 1.3836, 1.3249, 1.3312],
        [1.2996, 1.3281, 1.2687, 1.2401, 1.3304, 1.3039, 1.3125, 1.2971, 1.2971,
         1.3581, 1.2803, 1.3692, 1.3346, 1.3480, 1.3241, 1.3564, 1.3517, 1.0789,
         1.3454, 1.3063, 1.3869, 1.3559, 1.3183, 1.2711, 1.3346, 1.3076, 1.3076,
         2.5170, 2.0599, 1.8597, 1.9724, 2.4858, 1.8622, 2.4431, 1.8792, 1.8543,
         1.4207, 1.4470, 1.3959, 1.3848, 1.4228, 1.3738, 1.4190, 1.1631, 1.3776,
         1.4261, 1.3127, 1.2304, 1.2975, 1.4240, 1.2407, 1.4583, 1.3006, 1.3555],
        [1.6823, 1.3492, 0.5398, 0.7733, 1.1376, 1.5626, 1.4916, 1.6798, 1.6798,
         1.5872, 1.3431, 1.4038, 0.9252, 1.6717, 0.1844, 1.5711, 1.6942, 1.2478,
         1.2681, 0.8254, 0.7159, 1.0412, 1.5333, 1.6412, 1.2774, 1.6879, 1.6879,
         0.6845, 0.7546, 1.6618, 1.4087, 0.8413, 1.6605, 1.1239, 1.7050, 1.6523,
         0.9247, 0.6396, 0.5814, 0.8531, 1.3000, 1.5367, 0.7916, 5.4143, 4.8288,
         0.7358, 1.2465, 1.3235, 1.6097, 0.9728, 1.5679, 0.3687, 1.5834, 1.7318],
        [1.3520, 1.3812, 1.4441, 1.4184, 1.3862, 1.3553, 1.3218, 1.3494, 1.3494,
         1.3187, 1.3815, 1.2991, 1.4369, 1.4052, 1.4781, 1.3175, 1.4098, 1.3325,
         1.4007, 1.4283, 1.4381, 1.4088, 1.3753, 1.3655, 1.3364, 1.3631, 1.3631,
         1.4058, 1.4545, 1.3863, 1.2335, 1.2831, 1.1873, 1.4086, 1.2645, 1.3890,
         1.4762, 1.2348, 1.5020, 1.4842, 1.1210, 1.0342, 1.4834, 1.3968, 0.8960,
         2.5159, 2.1276, 2.4513, 2.3454, 1.8096, 1.6085, 2.4218, 2.2744, 1.5954]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 80 : 183.05558041216116
Test loss for epoch 80 : 183.06077460804133
Test Precision for epoch 80 : 0.26153846153846155
Test Recall for epoch 80 : 0.26153846153846155
Test F1 for epoch 80 : 0.26153846153846155


theta for epoch 81 : tensor([[2.0720, 2.0987, 2.1603, 2.2200, 2.1851, 2.0742, 2.1618, 2.0701, 2.0701,
         1.3282, 1.3398, 1.3461, 1.3550, 1.3172, 1.4021, 1.3268, 1.3218, 1.2989,
         1.3159, 1.3013, 1.3149, 1.3265, 1.2905, 1.2816, 1.3065, 1.2781, 1.2781,
         1.3171, 1.3768, 1.2970, 1.3242, 1.3640, 1.3110, 1.3219, 1.2620, 1.2998,
         1.3932, 1.4254, 1.4192, 1.4023, 1.3967, 1.3424, 1.3999, 1.4043, 1.3591,
         1.3950, 1.3446, 1.3368, 1.3115, 1.3940, 1.3398, 1.4266, 1.3156, 1.3218],
        [1.3467, 1.2158, 1.0602, 1.2834, 1.3442, 1.3976, 1.3182, 1.3905, 1.3905,
         1.6015, 1.8349, 1.5262, 2.3599, 1.5915, 3.4751, 1.6663, 1.4752, 3.1513,
         1.1821, 1.2537, 0.9940, 1.2274, 1.3664, 1.4041, 1.3797, 1.4021, 1.4021,
         1.3513, 1.1154, 1.4266, 1.4016, 1.1619, 1.4390, 1.4394, 1.3951, 1.3945,
         1.4245, 1.5456, 1.4934, 1.4243, 1.4005, 1.5024, 1.4756, 0.6227, 1.4492,
         1.0685, 1.4693, 1.4572, 1.4383, 1.1189, 1.4630, 0.8893, 1.4421, 1.4483],
        [1.2764, 1.3054, 1.3683, 1.3420, 1.3043, 1.2810, 1.2864, 1.2737, 1.2737,
         1.3323, 1.3428, 1.3502, 1.3583, 1.3213, 1.3295, 1.3309, 1.3073, 1.2502,
         2.1105, 2.2121, 2.3302, 2.2450, 1.9955, 2.0610, 2.1548, 1.9847, 1.9847,
         1.3568, 1.3337, 1.3105, 1.3352, 1.3568, 1.3233, 1.3336, 1.3183, 1.3130,
         1.4019, 1.4341, 1.4279, 1.3953, 1.4048, 1.3990, 1.4091, 1.3097, 1.3493,
         1.3492, 1.3534, 1.3455, 1.3197, 1.3038, 1.3487, 1.3828, 1.3238, 1.3300],
        [1.2983, 1.3269, 1.2686, 1.2402, 1.3293, 1.3026, 1.3113, 1.2957, 1.2957,
         1.3564, 1.2786, 1.3678, 1.3334, 1.3460, 1.3230, 1.3545, 1.3498, 1.0782,
         1.3436, 1.3059, 1.3852, 1.3542, 1.3166, 1.2695, 1.3330, 1.3057, 1.3057,
         2.5220, 2.0649, 1.8637, 1.9762, 2.4913, 1.8666, 2.4484, 1.8832, 1.8587,
         1.4203, 1.4470, 1.3954, 1.3845, 1.4227, 1.3741, 1.4187, 1.1645, 1.3778,
         1.4247, 1.3117, 1.2292, 1.2956, 1.4225, 1.2395, 1.4570, 1.2988, 1.3537],
        [1.6846, 1.3509, 0.5433, 0.7763, 1.1397, 1.5649, 1.4938, 1.6821, 1.6821,
         1.5883, 1.3448, 1.4046, 0.9269, 1.6731, 0.1866, 1.5720, 1.6956, 1.2482,
         1.2699, 0.8271, 0.7177, 1.0431, 1.5351, 1.6427, 1.2791, 1.6896, 1.6896,
         0.6877, 0.7587, 1.6639, 1.4111, 0.8429, 1.6616, 1.1259, 1.7074, 1.6542,
         0.9148, 0.6334, 0.5754, 0.8443, 1.2870, 1.5234, 0.7832, 5.4706, 4.8724,
         0.7379, 1.2483, 1.3255, 1.6107, 0.9754, 1.5691, 0.3718, 1.5855, 1.7337],
        [1.3511, 1.3801, 1.4425, 1.4171, 1.3856, 1.3547, 1.3209, 1.3486, 1.3486,
         1.3166, 1.3802, 1.2977, 1.4352, 1.4029, 1.4770, 1.3154, 1.4074, 1.3306,
         1.3987, 1.4266, 1.4368, 1.4073, 1.3735, 1.3637, 1.3346, 1.3613, 1.3613,
         1.4045, 1.4537, 1.3845, 1.2321, 1.2832, 1.1871, 1.4075, 1.2628, 1.3872,
         1.4767, 1.2337, 1.5023, 1.4846, 1.1202, 1.0334, 1.4839, 1.3972, 0.8962,
         2.5191, 2.1323, 2.4583, 2.3508, 1.8141, 1.6112, 2.4244, 2.2809, 1.5981]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 81 : 183.0345252697729
Test loss for epoch 81 : 183.0400862137349
Test Precision for epoch 81 : 0.26153846153846155
Test Recall for epoch 81 : 0.26153846153846155
Test F1 for epoch 81 : 0.26153846153846155


theta for epoch 82 : tensor([[2.0756, 2.1016, 2.1632, 2.2232, 2.1883, 2.0778, 2.1659, 2.0737, 2.0737,
         1.3273, 1.3389, 1.3451, 1.3542, 1.3162, 1.4011, 1.3259, 1.3207, 1.2980,
         1.3160, 1.3012, 1.3142, 1.3264, 1.2905, 1.2816, 1.3065, 1.2782, 1.2782,
         1.3167, 1.3760, 1.2961, 1.3233, 1.3634, 1.3099, 1.3214, 1.2612, 1.2989,
         1.3933, 1.4255, 1.4191, 1.4025, 1.3972, 1.3428, 1.4000, 1.4049, 1.3592,
         1.3944, 1.3442, 1.3363, 1.3113, 1.3932, 1.3395, 1.4260, 1.3153, 1.3215],
        [1.3455, 1.2158, 1.0590, 1.2821, 1.3434, 1.3963, 1.3171, 1.3892, 1.3892,
         1.6016, 1.8346, 1.5284, 2.3614, 1.5927, 3.4907, 1.6682, 1.4773, 3.1670,
         1.1820, 1.2533, 0.9943, 1.2270, 1.3659, 1.4035, 1.3793, 1.4015, 1.4015,
         1.3508, 1.1139, 1.4257, 1.4007, 1.1616, 1.4382, 1.4390, 1.3942, 1.3936,
         1.4241, 1.5454, 1.4929, 1.4238, 1.3999, 1.5025, 1.4753, 0.6218, 1.4496,
         1.0678, 1.4681, 1.4561, 1.4370, 1.1180, 1.4619, 0.8879, 1.4408, 1.4471],
        [1.2753, 1.3043, 1.3667, 1.3409, 1.3039, 1.2799, 1.2857, 1.2727, 1.2727,
         1.3311, 1.3415, 1.3489, 1.3572, 1.3200, 1.3297, 1.3296, 1.3063, 1.2494,
         2.1149, 2.2148, 2.3327, 2.2483, 2.0006, 2.0667, 2.1586, 1.9900, 1.9900,
         1.3560, 1.3331, 1.3095, 1.3345, 1.3560, 1.3223, 1.3331, 1.3174, 1.3120,
         1.4015, 1.4336, 1.4274, 1.3950, 1.4046, 1.3989, 1.4087, 1.3089, 1.3484,
         1.3489, 1.3524, 1.3445, 1.3188, 1.3033, 1.3477, 1.3821, 1.3228, 1.3292],
        [1.2968, 1.3255, 1.2682, 1.2402, 1.3281, 1.3011, 1.3099, 1.2943, 1.2943,
         1.3550, 1.2772, 1.3669, 1.3326, 1.3446, 1.3222, 1.3531, 1.3482, 1.0779,
         1.3427, 1.3063, 1.3841, 1.3533, 1.3157, 1.2689, 1.3323, 1.3048, 1.3048,
         2.5268, 2.0697, 1.8676, 1.9797, 2.4966, 1.8708, 2.4533, 1.8871, 1.8628,
         1.4195, 1.4466, 1.3945, 1.3839, 1.4221, 1.3740, 1.4179, 1.1655, 1.3776,
         1.4238, 1.3112, 1.2284, 1.2942, 1.4215, 1.2388, 1.4561, 1.2974, 1.3524],
        [1.6866, 1.3525, 0.5467, 0.7791, 1.1416, 1.5668, 1.4957, 1.6841, 1.6841,
         1.5897, 1.3467, 1.4056, 0.9289, 1.6749, 0.1890, 1.5732, 1.6972, 1.2490,
         1.2723, 0.8293, 0.7200, 1.0455, 1.5374, 1.6447, 1.2814, 1.6919, 1.6919,
         0.6908, 0.7626, 1.6658, 1.4134, 0.8444, 1.6625, 1.1279, 1.7096, 1.6560,
         0.9050, 0.6272, 0.5694, 0.8356, 1.2739, 1.5098, 0.7749, 5.5267, 4.9156,
         0.7402, 1.2506, 1.3279, 1.6120, 0.9783, 1.5707, 0.3750, 1.5880, 1.7358],
        [1.3506, 1.3793, 1.4412, 1.4161, 1.3851, 1.3544, 1.3203, 1.3482, 1.3482,
         1.3155, 1.3798, 1.2973, 1.4343, 1.4015, 1.4767, 1.3142, 1.4059, 1.3295,
         1.3982, 1.4264, 1.4371, 1.4073, 1.3733, 1.3635, 1.3344, 1.3611, 1.3611,
         1.4035, 1.4531, 1.3830, 1.2310, 1.2835, 1.1873, 1.4065, 1.2614, 1.3858,
         1.4769, 1.2325, 1.5023, 1.4847, 1.1194, 1.0326, 1.4840, 1.3976, 0.8965,
         2.5216, 2.1359, 2.4643, 2.3551, 1.8178, 1.6130, 2.4264, 2.2864, 1.5998]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 82 : 183.01381057659881
Test loss for epoch 82 : 183.02022510131272
Test Precision for epoch 82 : 0.26153846153846155
Test Recall for epoch 82 : 0.26153846153846155
Test F1 for epoch 82 : 0.26153846153846155


theta for epoch 83 : tensor([[2.0798, 2.1052, 2.1667, 2.2271, 2.1921, 2.0820, 2.1705, 2.0779, 2.0779,
         1.3268, 1.3382, 1.3445, 1.3536, 1.3156, 1.4003, 1.3253, 1.3200, 1.2973,
         1.3158, 1.3007, 1.3133, 1.3260, 1.2903, 1.2814, 1.3063, 1.2781, 1.2781,
         1.3156, 1.3745, 1.2947, 1.3219, 1.3621, 1.3083, 1.3203, 1.2599, 1.2975,
         1.3929, 1.4250, 1.4185, 1.4021, 1.3972, 1.3427, 1.3994, 1.4048, 1.3588,
         1.3942, 1.3442, 1.3363, 1.3115, 1.3928, 1.3396, 1.4257, 1.3154, 1.3217],
        [1.3447, 1.2162, 1.0580, 1.2811, 1.3429, 1.3953, 1.3162, 1.3882, 1.3882,
         1.6017, 1.8344, 1.5305, 2.3627, 1.5939, 3.5061, 1.6700, 1.4794, 3.1827,
         1.1820, 1.2531, 0.9948, 1.2268, 1.3656, 1.4031, 1.3790, 1.4011, 1.4011,
         1.3500, 1.1123, 1.4245, 1.3996, 1.1610, 1.4371, 1.4384, 1.3930, 1.3926,
         1.4233, 1.5449, 1.4922, 1.4229, 1.3990, 1.5023, 1.4746, 0.6207, 1.4496,
         1.0679, 1.4676, 1.4557, 1.4364, 1.1177, 1.4615, 0.8871, 1.4403, 1.4465],
        [1.2745, 1.3033, 1.3653, 1.3399, 1.3037, 1.2791, 1.2852, 1.2720, 1.2720,
         1.3305, 1.3409, 1.3483, 1.3567, 1.3193, 1.3304, 1.3290, 1.3059, 1.2492,
         2.1192, 2.2174, 2.3351, 2.2516, 2.0056, 2.0723, 2.1622, 1.9951, 1.9951,
         1.3551, 1.3323, 1.3083, 1.3335, 1.3551, 1.3211, 1.3323, 1.3162, 1.3108,
         1.4007, 1.4329, 1.4265, 1.3944, 1.4042, 1.3984, 1.4079, 1.3079, 1.3472,
         1.3493, 1.3522, 1.3443, 1.3188, 1.3036, 1.3477, 1.3822, 1.3228, 1.3291],
        [1.2959, 1.3247, 1.2684, 1.2406, 1.3273, 1.3003, 1.3090, 1.2934, 1.2934,
         1.3545, 1.2768, 1.3667, 1.3325, 1.3439, 1.3221, 1.3526, 1.3475, 1.0786,
         1.3424, 1.3072, 1.3836, 1.3530, 1.3155, 1.2689, 1.3321, 1.3045, 1.3045,
         2.5306, 2.0737, 1.8707, 1.9826, 2.5009, 1.8742, 2.4574, 1.8902, 1.8663,
         1.4187, 1.4461, 1.3936, 1.3833, 1.4216, 1.3740, 1.4170, 1.1666, 1.3774,
         1.4236, 1.3116, 1.2285, 1.2937, 1.4213, 1.2390, 1.4560, 1.2970, 1.3520],
        [1.6881, 1.3534, 0.5492, 0.7811, 1.1430, 1.5681, 1.4971, 1.6855, 1.6855,
         1.5910, 1.3484, 1.4066, 0.9306, 1.6767, 0.1908, 1.5743, 1.6988, 1.2497,
         1.2742, 0.8310, 0.7214, 1.0473, 1.5393, 1.6463, 1.2833, 1.6938, 1.6938,
         0.6928, 0.7653, 1.6670, 1.4148, 0.8448, 1.6626, 1.1291, 1.7110, 1.6570,
         0.8960, 0.6217, 0.5640, 0.8276, 1.2615, 1.4968, 0.7673, 5.5832, 4.9592,
         0.7421, 1.2526, 1.3301, 1.6131, 0.9808, 1.5722, 0.3775, 1.5904, 1.7379],
        [1.3507, 1.3790, 1.4402, 1.4155, 1.3851, 1.3547, 1.3203, 1.3483, 1.3483,
         1.3153, 1.3803, 1.2978, 1.4343, 1.4010, 1.4771, 1.3140, 1.4053, 1.3293,
         1.3981, 1.4266, 1.4377, 1.4078, 1.3735, 1.3638, 1.3347, 1.3614, 1.3614,
         1.4023, 1.4525, 1.3815, 1.2300, 1.2839, 1.1876, 1.4055, 1.2601, 1.3843,
         1.4768, 1.2311, 1.5021, 1.4847, 1.1185, 1.0318, 1.4839, 1.3980, 0.8969,
         2.5238, 2.1391, 2.4699, 2.3590, 1.8211, 1.6144, 2.4281, 2.2915, 1.6012]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 83 : 182.993257387083
Test loss for epoch 83 : 183.00089138695597
Test Precision for epoch 83 : 0.26153846153846155
Test Recall for epoch 83 : 0.26153846153846155
Test F1 for epoch 83 : 0.26153846153846155


theta for epoch 84 : tensor([[2.0842, 2.1091, 2.1706, 2.2313, 2.1962, 2.0865, 2.1755, 2.0824, 2.0824,
         1.3263, 1.3376, 1.3440, 1.3531, 1.3151, 1.3995, 1.3248, 1.3194, 1.2966,
         1.3148, 1.2994, 1.3117, 1.3248, 1.2893, 1.2805, 1.3053, 1.2772, 1.2772,
         1.3148, 1.3732, 1.2937, 1.3208, 1.3612, 1.3071, 1.3195, 1.2589, 1.2965,
         1.3922, 1.4243, 1.4176, 1.4015, 1.3969, 1.3424, 1.3987, 1.4046, 1.3582,
         1.3942, 1.3444, 1.3365, 1.3121, 1.3927, 1.3400, 1.4256, 1.3159, 1.3223],
        [1.3446, 1.2173, 1.0577, 1.2808, 1.3430, 1.3950, 1.3160, 1.3880, 1.3880,
         1.6012, 1.8335, 1.5321, 2.3633, 1.5946, 3.5208, 1.6712, 1.4809, 3.1976,
         1.1822, 1.2529, 0.9954, 1.2268, 1.3654, 1.4027, 1.3787, 1.4007, 1.4007,
         1.3499, 1.1113, 1.4240, 1.3990, 1.1612, 1.4366, 1.4383, 1.3925, 1.3922,
         1.4227, 1.5447, 1.4917, 1.4222, 1.3983, 1.5023, 1.4742, 0.6201, 1.4497,
         1.0688, 1.4679, 1.4561, 1.4368, 1.1184, 1.4619, 0.8872, 1.4405, 1.4469],
        [1.2742, 1.3028, 1.3642, 1.3392, 1.3038, 1.2788, 1.2852, 1.2717, 1.2717,
         1.3305, 1.3408, 1.3482, 1.3566, 1.3192, 1.3315, 1.3289, 1.3061, 1.2494,
         2.1230, 2.2194, 2.3369, 2.2542, 2.0099, 2.0771, 2.1652, 1.9996, 1.9996,
         1.3546, 1.3319, 1.3075, 1.3329, 1.3546, 1.3203, 1.3319, 1.3155, 1.3100,
         1.4001, 1.4322, 1.4257, 1.3938, 1.4038, 1.3981, 1.4072, 1.3071, 1.3462,
         1.3503, 1.3526, 1.3447, 1.3196, 1.3046, 1.3483, 1.3829, 1.3234, 1.3299],
        [1.2954, 1.3241, 1.2687, 1.2413, 1.3269, 1.2998, 1.3085, 1.2929, 1.2929,
         1.3543, 1.2766, 1.3668, 1.3327, 1.3435, 1.3223, 1.3523, 1.3471, 1.0796,
         1.3418, 1.3077, 1.3828, 1.3523, 1.3151, 1.2687, 1.3317, 1.3040, 1.3040,
         2.5342, 2.0776, 1.8737, 1.9852, 2.5051, 1.8775, 2.4613, 1.8932, 1.8696,
         1.4179, 1.4457, 1.3927, 1.3827, 1.4211, 1.3741, 1.4163, 1.1678, 1.3772,
         1.4238, 1.3124, 1.2290, 1.2937, 1.4215, 1.2397, 1.4562, 1.2970, 1.3521],
        [1.6891, 1.3538, 0.5509, 0.7825, 1.1438, 1.5690, 1.4980, 1.6866, 1.6866,
         1.5921, 1.3497, 1.4072, 0.9319, 1.6783, 0.1919, 1.5751, 1.7002, 1.2501,
         1.2751, 0.8317, 0.7217, 1.0481, 1.5404, 1.6472, 1.2844, 1.6949, 1.6949,
         0.6943, 0.7674, 1.6681, 1.4161, 0.8447, 1.6625, 1.1301, 1.7124, 1.6579,
         0.8878, 0.6168, 0.5593, 0.8203, 1.2498, 1.4844, 0.7606, 5.6401, 5.0031,
         0.7433, 1.2541, 1.3320, 1.6138, 0.9827, 1.5735, 0.3790, 1.5926, 1.7398],
        [1.3506, 1.3786, 1.4391, 1.4147, 1.3850, 1.3549, 1.3202, 1.3483, 1.3483,
         1.3151, 1.3808, 1.2983, 1.4343, 1.4004, 1.4775, 1.3137, 1.4047, 1.3289,
         1.3973, 1.4258, 1.4372, 1.4073, 1.3729, 1.3632, 1.3341, 1.3608, 1.3608,
         1.4013, 1.4521, 1.3803, 1.2292, 1.2845, 1.1882, 1.4047, 1.2591, 1.3831,
         1.4764, 1.2295, 1.5015, 1.4843, 1.1174, 1.0307, 1.4834, 1.3983, 0.8971,
         2.5267, 2.1429, 2.4761, 2.3634, 1.8252, 1.6166, 2.4306, 2.2973, 1.6033]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 84 : 182.97288377219235
Test loss for epoch 84 : 182.98132769450814
Test Precision for epoch 84 : 0.26153846153846155
Test Recall for epoch 84 : 0.26153846153846155
Test F1 for epoch 84 : 0.26153846153846155


theta for epoch 85 : tensor([[2.0880, 2.1124, 2.1739, 2.2348, 2.1997, 2.0903, 2.1797, 2.0861, 2.0861,
         1.3261, 1.3373, 1.3437, 1.3528, 1.3149, 1.3989, 1.3246, 1.3191, 1.2962,
         1.3140, 1.2984, 1.3103, 1.3239, 1.2887, 1.2800, 1.3045, 1.2767, 1.2767,
         1.3150, 1.3731, 1.2940, 1.3210, 1.3613, 1.3072, 1.3199, 1.2592, 1.2968,
         1.3917, 1.4238, 1.4169, 1.4011, 1.3968, 1.3422, 1.3981, 1.4046, 1.3577,
         1.3939, 1.3443, 1.3364, 1.3124, 1.3922, 1.3401, 1.4251, 1.3160, 1.3225],
        [1.3449, 1.2186, 1.0576, 1.2807, 1.3435, 1.3950, 1.3162, 1.3880, 1.3880,
         1.6004, 1.8323, 1.5333, 2.3634, 1.5948, 3.5350, 1.6719, 1.4820, 3.2120,
         1.1828, 1.2530, 0.9965, 1.2271, 1.3655, 1.4027, 1.3788, 1.4007, 1.4007,
         1.3505, 1.1113, 1.4243, 1.3993, 1.1623, 1.4369, 1.4390, 1.3928, 1.3926,
         1.4224, 1.5446, 1.4913, 1.4217, 1.3978, 1.5024, 1.4739, 0.6199, 1.4499,
         1.0697, 1.4680, 1.4562, 1.4370, 1.1190, 1.4621, 0.8873, 1.4406, 1.4471],
        [1.2736, 1.3020, 1.3628, 1.3383, 1.3036, 1.2782, 1.2849, 1.2712, 1.2712,
         1.3304, 1.3407, 1.3480, 1.3565, 1.3191, 1.3325, 1.3289, 1.3063, 1.2496,
         2.1269, 2.2216, 2.3389, 2.2570, 2.0143, 2.0822, 2.1684, 2.0042, 2.0042,
         1.3546, 1.3321, 1.3073, 1.3329, 1.3547, 1.3201, 1.3320, 1.3153, 1.3099,
         1.3994, 1.4314, 1.4248, 1.3932, 1.4035, 1.3977, 1.4065, 1.3062, 1.3451,
         1.3504, 1.3523, 1.3444, 1.3196, 1.3047, 1.3482, 1.3828, 1.3233, 1.3298],
        [1.2946, 1.3233, 1.2687, 1.2416, 1.3261, 1.2990, 1.3077, 1.2921, 1.2921,
         1.3539, 1.2763, 1.3668, 1.3327, 1.3431, 1.3222, 1.3519, 1.3466, 1.0805,
         1.3409, 1.3079, 1.3817, 1.3515, 1.3144, 1.2683, 1.3310, 1.3033, 1.3033,
         2.5383, 2.0820, 1.8772, 1.9884, 2.5096, 1.8813, 2.4655, 1.8967, 1.8734,
         1.4171, 1.4451, 1.3918, 1.3821, 1.4206, 1.3741, 1.4154, 1.1689, 1.3768,
         1.4234, 1.3126, 1.2290, 1.2932, 1.4210, 1.2399, 1.4557, 1.2965, 1.3515],
        [1.6901, 1.3542, 0.5525, 0.7838, 1.1445, 1.5698, 1.4987, 1.6876, 1.6876,
         1.5932, 1.3510, 1.4080, 0.9332, 1.6799, 0.1931, 1.5759, 1.7016, 1.2507,
         1.2761, 0.8326, 0.7220, 1.0491, 1.5415, 1.6480, 1.2856, 1.6959, 1.6959,
         0.6964, 0.7701, 1.6699, 1.4181, 0.8453, 1.6630, 1.1318, 1.7144, 1.6595,
         0.8798, 0.6120, 0.5546, 0.8133, 1.2382, 1.4719, 0.7540, 5.6969, 5.0467,
         0.7441, 1.2553, 1.3335, 1.6141, 0.9842, 1.5744, 0.3801, 1.5943, 1.7411],
        [1.3502, 1.3778, 1.4375, 1.4136, 1.3843, 1.3546, 1.3196, 1.3479, 1.3479,
         1.3147, 1.3811, 1.2987, 1.4340, 1.3997, 1.4777, 1.3133, 1.4038, 1.3284,
         1.3961, 1.4247, 1.4364, 1.4064, 1.3720, 1.3624, 1.3332, 1.3600, 1.3600,
         1.4009, 1.4523, 1.3798, 1.2290, 1.2857, 1.1896, 1.4045, 1.2587, 1.3826,
         1.4759, 1.2278, 1.5008, 1.4837, 1.1162, 1.0295, 1.4828, 1.3988, 0.8972,
         2.5300, 2.1469, 2.4825, 2.3681, 1.8297, 1.6191, 2.4334, 2.3034, 1.6057]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 85 : 182.95293362297744
Test loss for epoch 85 : 182.96178130243655
Test Precision for epoch 85 : 0.26153846153846155
Test Recall for epoch 85 : 0.26153846153846155
Test F1 for epoch 85 : 0.26153846153846155


theta for epoch 86 : tensor([[2.0917, 2.1157, 2.1772, 2.2383, 2.2032, 2.0940, 2.1839, 2.0898, 2.0898,
         1.3261, 1.3371, 1.3435, 1.3527, 1.3149, 1.3984, 1.3246, 1.3190, 1.2959,
         1.3137, 1.2978, 1.3095, 1.3235, 1.2885, 1.2798, 1.3043, 1.2766, 1.2766,
         1.3155, 1.3733, 1.2946, 1.3214, 1.3617, 1.3075, 1.3206, 1.2598, 1.2974,
         1.3914, 1.4235, 1.4163, 1.4008, 1.3970, 1.3423, 1.3977, 1.4046, 1.3574,
         1.3926, 1.3432, 1.3354, 1.3117, 1.3907, 1.3392, 1.4236, 1.3152, 1.3218],
        [1.3451, 1.2199, 1.0574, 1.2807, 1.3439, 1.3950, 1.3164, 1.3881, 1.3881,
         1.5998, 1.8315, 1.5347, 2.3637, 1.5954, 3.5493, 1.6729, 1.4834, 3.2266,
         1.1835, 1.2533, 0.9978, 1.2275, 1.3658, 1.4028, 1.3790, 1.4009, 1.4009,
         1.3510, 1.1112, 1.4246, 1.3995, 1.1634, 1.4371, 1.4397, 1.3930, 1.3930,
         1.4220, 1.5445, 1.4910, 1.4212, 1.3973, 1.5026, 1.4737, 0.6196, 1.4499,
         1.0695, 1.4670, 1.4553, 1.4362, 1.1186, 1.4612, 0.8866, 1.4398, 1.4462],
        [1.2729, 1.3011, 1.3613, 1.3372, 1.3032, 1.2774, 1.2844, 1.2705, 1.2705,
         1.3302, 1.3404, 1.3477, 1.3562, 1.3189, 1.3333, 1.3286, 1.3064, 1.2496,
         2.1315, 2.2245, 2.3415, 2.2605, 2.0194, 2.0878, 2.1722, 2.0095, 2.0095,
         1.3545, 1.3322, 1.3070, 1.3327, 1.3547, 1.3198, 1.3321, 1.3151, 1.3096,
         1.3986, 1.4307, 1.4238, 1.3926, 1.4031, 1.3973, 1.4056, 1.3054, 1.3441,
         1.3492, 1.3507, 1.3428, 1.3184, 1.3034, 1.3468, 1.3813, 1.3219, 1.3285],
        [1.2938, 1.3224, 1.2687, 1.2419, 1.3254, 1.2982, 1.3069, 1.2913, 1.2913,
         1.3535, 1.2760, 1.3667, 1.3326, 1.3426, 1.3220, 1.3515, 1.3460, 1.0814,
         1.3403, 1.3083, 1.3808, 1.3508, 1.3139, 1.2681, 1.3305, 1.3028, 1.3028,
         2.5425, 2.0867, 1.8810, 1.9919, 2.5144, 1.8854, 2.4700, 1.9005, 1.8775,
         1.4163, 1.4446, 1.3909, 1.3815, 1.4202, 1.3742, 1.4146, 1.1700, 1.3765,
         1.4222, 1.3120, 1.2282, 1.2919, 1.4197, 1.2393, 1.4545, 1.2952, 1.3502],
        [1.6916, 1.3553, 0.5551, 0.7860, 1.1463, 1.5712, 1.5002, 1.6891, 1.6891,
         1.5948, 1.3528, 1.4093, 0.9352, 1.6819, 0.1952, 1.5772, 1.7034, 1.2519,
         1.2780, 0.8345, 0.7232, 1.0509, 1.5433, 1.6495, 1.2877, 1.6976, 1.6976,
         0.6994, 0.7737, 1.6722, 1.4209, 0.8467, 1.6640, 1.1346, 1.7169, 1.6617,
         0.8715, 0.6068, 0.5496, 0.8059, 1.2260, 1.4588, 0.7470, 5.7530, 5.0893,
         0.7453, 1.2564, 1.3349, 1.6140, 0.9858, 1.5751, 0.3816, 1.5959, 1.7422],
        [1.3498, 1.3772, 1.4361, 1.4126, 1.3838, 1.3545, 1.3191, 1.3476, 1.3476,
         1.3144, 1.3815, 1.2991, 1.4338, 1.3990, 1.4778, 1.3129, 1.4031, 1.3278,
         1.3954, 1.4239, 1.4359, 1.4059, 1.3714, 1.3619, 1.3327, 1.3596, 1.3596,
         1.4007, 1.4526, 1.3796, 1.2290, 1.2871, 1.1911, 1.4045, 1.2586, 1.3824,
         1.4754, 1.2262, 1.5001, 1.4833, 1.1151, 1.0284, 1.4822, 1.3995, 0.8975,
         2.5333, 2.1507, 2.4888, 2.3724, 1.8340, 1.6214, 2.4363, 2.3093, 1.6080]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 86 : 182.93323459383973
Test loss for epoch 86 : 182.94242909783628
Test Precision for epoch 86 : 0.26153846153846155
Test Recall for epoch 86 : 0.26153846153846155
Test F1 for epoch 86 : 0.26153846153846155


theta for epoch 87 : tensor([[2.0961, 2.1196, 2.1812, 2.2426, 2.2075, 2.0985, 2.1887, 2.0942, 2.0942,
         1.3259, 1.3367, 1.3432, 1.3523, 1.3147, 1.3976, 1.3244, 1.3187, 1.2954,
         1.3132, 1.2970, 1.3086, 1.3229, 1.2881, 1.2795, 1.3038, 1.2764, 1.2764,
         1.3150, 1.3725, 1.2943, 1.3209, 1.3611, 1.3070, 1.3203, 1.2595, 1.2972,
         1.3914, 1.4234, 1.4161, 1.4008, 1.3974, 1.3426, 1.3976, 1.4050, 1.3574,
         1.3912, 1.3420, 1.3342, 1.3111, 1.3891, 1.3383, 1.4220, 1.3143, 1.3210],
        [1.3451, 1.2210, 1.0569, 1.2804, 1.3441, 1.3949, 1.3163, 1.3881, 1.3881,
         1.5999, 1.8313, 1.5368, 2.3645, 1.5966, 3.5641, 1.6745, 1.4854, 3.2418,
         1.1837, 1.2531, 0.9984, 1.2275, 1.3657, 1.4026, 1.3788, 1.4006, 1.4006,
         1.3507, 1.1103, 1.4240, 1.3989, 1.1637, 1.4365, 1.4394, 1.3924, 1.3926,
         1.4217, 1.5445, 1.4907, 1.4208, 1.3969, 1.5028, 1.4736, 0.6192, 1.4500,
         1.0689, 1.4658, 1.4541, 1.4351, 1.1177, 1.4601, 0.8856, 1.4386, 1.4451],
        [1.2726, 1.3006, 1.3602, 1.3365, 1.3031, 1.2771, 1.2843, 1.2703, 1.2703,
         1.3301, 1.3403, 1.3475, 1.3559, 1.3188, 1.3340, 1.3285, 1.3066, 1.2496,
         2.1360, 2.2274, 2.3441, 2.2639, 2.0244, 2.0933, 2.1759, 2.0146, 2.0146,
         1.3539, 1.3317, 1.3062, 1.3321, 1.3542, 1.3190, 1.3315, 1.3143, 1.3088,
         1.3983, 1.4303, 1.4233, 1.3923, 1.4031, 1.3972, 1.4052, 1.3051, 1.3435,
         1.3482, 1.3493, 1.3414, 1.3175, 1.3022, 1.3456, 1.3800, 1.3207, 1.3275],
        [1.2934, 1.3219, 1.2689, 1.2425, 1.3250, 1.2978, 1.3065, 1.2909, 1.2909,
         1.3532, 1.2757, 1.3667, 1.3326, 1.3421, 1.3219, 1.3512, 1.3456, 1.0824,
         1.3397, 1.3087, 1.3799, 1.3502, 1.3136, 1.2680, 1.3301, 1.3025, 1.3025,
         2.5463, 2.0910, 1.8846, 1.9951, 2.5187, 1.8892, 2.4741, 1.9040, 1.8813,
         1.4160, 1.4445, 1.3905, 1.3814, 1.4203, 1.3748, 1.4142, 1.1715, 1.3766,
         1.4211, 1.3116, 1.2276, 1.2908, 1.4185, 1.2388, 1.4533, 1.2940, 1.3491],
        [1.6937, 1.3573, 0.5586, 0.7891, 1.1490, 1.5732, 1.5024, 1.6912, 1.6912,
         1.5967, 1.3549, 1.4110, 0.9378, 1.6843, 0.1980, 1.5788, 1.7055, 1.2536,
         1.2803, 0.8371, 0.7252, 1.0533, 1.5455, 1.6513, 1.2903, 1.6997, 1.6997,
         0.7026, 0.7773, 1.6744, 1.4236, 0.8482, 1.6647, 1.1373, 1.7192, 1.6637,
         0.8629, 0.6012, 0.5442, 0.7982, 1.2136, 1.4453, 0.7398, 5.8085, 5.1313,
         0.7472, 1.2582, 1.3369, 1.6144, 0.9882, 1.5764, 0.3839, 1.5980, 1.7437],
        [1.3497, 1.3768, 1.4350, 1.4118, 1.3834, 1.3546, 1.3189, 1.3475, 1.3475,
         1.3140, 1.3819, 1.2994, 1.4334, 1.3983, 1.4776, 1.3125, 1.4023, 1.3270,
         1.3945, 1.4229, 1.4352, 1.4053, 1.3708, 1.3613, 1.3320, 1.3591, 1.3591,
         1.3996, 1.4521, 1.3786, 1.2282, 1.2877, 1.1919, 1.4037, 1.2577, 1.3814,
         1.4752, 1.2249, 1.4996, 1.4831, 1.1144, 1.0277, 1.4819, 1.4006, 0.8981,
         2.5370, 2.1549, 2.4955, 2.3772, 1.8387, 1.6242, 2.4396, 2.3156, 1.6108]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 87 : 182.91373968132388
Test loss for epoch 87 : 182.9232108795286
Test Precision for epoch 87 : 0.26153846153846155
Test Recall for epoch 87 : 0.26153846153846155
Test F1 for epoch 87 : 0.26153846153846155


theta for epoch 88 : tensor([[2.1001, 2.1234, 2.1850, 2.2465, 2.2115, 2.1026, 2.1932, 2.0982, 2.0982,
         1.3255, 1.3361, 1.3426, 1.3516, 1.3142, 1.3966, 1.3239, 1.3182, 1.2946,
         1.3126, 1.2961, 1.3076, 1.3222, 1.2877, 1.2791, 1.3033, 1.2760, 1.2760,
         1.3140, 1.3711, 1.2936, 1.3200, 1.3600, 1.3060, 1.3195, 1.2587, 1.2964,
         1.3920, 1.4240, 1.4164, 1.4014, 1.3984, 1.3435, 1.3981, 1.4058, 1.3579,
         1.3909, 1.3418, 1.3340, 1.3113, 1.3885, 1.3383, 1.4214, 1.3143, 1.3211],
        [1.3448, 1.2216, 1.0559, 1.2797, 1.3439, 1.3944, 1.3159, 1.3876, 1.3876,
         1.6003, 1.8314, 1.5391, 2.3655, 1.5981, 3.5790, 1.6763, 1.4876, 3.2571,
         1.1833, 1.2524, 0.9986, 1.2270, 1.3652, 1.4019, 1.3781, 1.4000, 1.4000,
         1.3497, 1.1087, 1.4229, 1.3976, 1.1633, 1.4353, 1.4386, 1.3912, 1.3916,
         1.4217, 1.5448, 1.4908, 1.4207, 1.3967, 1.5034, 1.4737, 0.6190, 1.4503,
         1.0686, 1.4650, 1.4533, 1.4346, 1.1171, 1.4595, 0.8848, 1.4378, 1.4445],
        [1.2725, 1.3002, 1.3593, 1.3359, 1.3031, 1.2770, 1.2844, 1.2702, 1.2702,
         1.3300, 1.3401, 1.3472, 1.3556, 1.3187, 1.3347, 1.3284, 1.3067, 1.2495,
         2.1402, 2.2298, 2.3463, 2.2669, 2.0290, 2.0983, 2.1792, 2.0193, 2.0193,
         1.3531, 1.3309, 1.3052, 1.3311, 1.3534, 1.3179, 1.3307, 1.3132, 1.3078,
         1.3986, 1.4305, 1.4234, 1.3927, 1.4038, 1.3979, 1.4054, 1.3054, 1.3435,
         1.3481, 1.3489, 1.3411, 1.3176, 1.3021, 1.3454, 1.3798, 1.3207, 1.3275],
        [1.2929, 1.3213, 1.2690, 1.2429, 1.3244, 1.2973, 1.3059, 1.2904, 1.2904,
         1.3526, 1.2752, 1.3664, 1.3322, 1.3415, 1.3214, 1.3506, 1.3448, 1.0832,
         1.3390, 1.3089, 1.3790, 1.3495, 1.3131, 1.2678, 1.3296, 1.3019, 1.3019,
         2.5500, 2.0953, 1.8880, 1.9982, 2.5229, 1.8929, 2.4781, 1.9074, 1.8850,
         1.4162, 1.4449, 1.3906, 1.3818, 1.4209, 1.3759, 1.4143, 1.1734, 1.3771,
         1.4205, 1.3117, 1.2275, 1.2903, 1.4179, 1.2390, 1.4526, 1.2934, 1.3486],
        [1.6956, 1.3590, 0.5618, 0.7919, 1.1516, 1.5751, 1.5044, 1.6931, 1.6931,
         1.5983, 1.3568, 1.4126, 0.9400, 1.6865, 0.2006, 1.5802, 1.7074, 1.2551,
         1.2825, 0.8396, 0.7269, 1.0556, 1.5475, 1.6530, 1.2929, 1.7016, 1.7016,
         0.7052, 0.7804, 1.6760, 1.4258, 0.8491, 1.6648, 1.1396, 1.7211, 1.6652,
         0.8547, 0.5958, 0.5392, 0.7909, 1.2014, 1.4319, 0.7330, 5.8641, 5.1731,
         0.7496, 1.2604, 1.3394, 1.6152, 0.9910, 1.5782, 0.3866, 1.6007, 1.7457],
        [1.3495, 1.3763, 1.4339, 1.4111, 1.3829, 1.3545, 1.3185, 1.3474, 1.3474,
         1.3133, 1.3820, 1.2996, 1.4326, 1.3973, 1.4771, 1.3118, 1.4012, 1.3260,
         1.3936, 1.4219, 1.4344, 1.4045, 1.3701, 1.3607, 1.3312, 1.3584, 1.3584,
         1.3979, 1.4511, 1.3772, 1.2269, 1.2878, 1.1922, 1.4023, 1.2564, 1.3800,
         1.4756, 1.2242, 1.4997, 1.4834, 1.1143, 1.0276, 1.4821, 1.4024, 0.8993,
         2.5410, 2.1592, 2.5023, 2.3820, 1.8437, 1.6273, 2.4432, 2.3222, 1.6138]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 88 : 182.8945009936778
Test loss for epoch 88 : 182.90441596677516
Test Precision for epoch 88 : 0.26153846153846155
Test Recall for epoch 88 : 0.26153846153846155
Test F1 for epoch 88 : 0.26153846153846155


theta for epoch 89 : tensor([[2.1038, 2.1267, 2.1885, 2.2501, 2.2151, 2.1063, 2.1973, 2.1019, 2.1019,
         1.3247, 1.3351, 1.3417, 1.3506, 1.3135, 1.3952, 1.3232, 1.3174, 1.2935,
         1.3122, 1.2955, 1.3070, 1.3218, 1.2874, 1.2790, 1.3030, 1.2759, 1.2759,
         1.3132, 1.3701, 1.2933, 1.3194, 1.3592, 1.3054, 1.3189, 1.2582, 1.2961,
         1.3929, 1.4248, 1.4170, 1.4022, 1.3996, 1.3446, 1.3988, 1.4068, 1.3586,
         1.3910, 1.3421, 1.3343, 1.3121, 1.3885, 1.3387, 1.4213, 1.3149, 1.3217],
        [1.3443, 1.2220, 1.0548, 1.2788, 1.3435, 1.3938, 1.3153, 1.3870, 1.3870,
         1.6004, 1.8313, 1.5412, 2.3662, 1.5993, 3.5936, 1.6778, 1.4895, 3.2722,
         1.1832, 1.2520, 0.9991, 1.2267, 1.3649, 1.4015, 1.3777, 1.3995, 1.3995,
         1.3488, 1.1074, 1.4219, 1.3966, 1.1632, 1.4344, 1.4379, 1.3902, 1.3908,
         1.4219, 1.5453, 1.4910, 1.4208, 1.3969, 1.5041, 1.4741, 0.6190, 1.4508,
         1.0687, 1.4646, 1.4529, 1.4345, 1.1170, 1.4592, 0.8846, 1.4376, 1.4443],
        [1.2721, 1.2996, 1.3581, 1.3351, 1.3027, 1.2766, 1.2841, 1.2698, 1.2698,
         1.3295, 1.3395, 1.3466, 1.3549, 1.3182, 1.3348, 1.3279, 1.3065, 1.2490,
         2.1443, 2.2323, 2.3486, 2.2700, 2.0335, 2.1034, 2.1824, 2.0239, 2.0239,
         1.3523, 1.3303, 1.3043, 1.3302, 1.3527, 1.3169, 1.3300, 1.3123, 1.3070,
         1.3991, 1.4310, 1.4236, 1.3932, 1.4046, 1.3986, 1.4058, 1.3059, 1.3438,
         1.3485, 1.3490, 1.3412, 1.3181, 1.3023, 1.3457, 1.3799, 1.3210, 1.3279],
        [1.2918, 1.3202, 1.2685, 1.2427, 1.3234, 1.2964, 1.3048, 1.2894, 1.2894,
         1.3515, 1.2742, 1.3655, 1.3314, 1.3403, 1.3203, 1.3495, 1.3436, 1.0834,
         1.3381, 1.3088, 1.3778, 1.3485, 1.3124, 1.2673, 1.3288, 1.3012, 1.3012,
         2.5540, 2.1000, 1.8919, 2.0017, 2.5275, 1.8970, 2.4824, 1.9113, 1.8892,
         1.4164, 1.4453, 1.3907, 1.3822, 1.4215, 1.3770, 1.4144, 1.1752, 1.3775,
         1.4199, 1.3118, 1.2274, 1.2898, 1.4173, 1.2391, 1.4520, 1.2929, 1.3480],
        [1.6970, 1.3602, 0.5644, 0.7942, 1.1535, 1.5765, 1.5059, 1.6946, 1.6946,
         1.5995, 1.3580, 1.4136, 0.9417, 1.6882, 0.2026, 1.5811, 1.7088, 1.2561,
         1.2845, 0.8418, 0.7283, 1.0577, 1.5494, 1.6546, 1.2952, 1.7033, 1.7033,
         0.7073, 0.7830, 1.6776, 1.4278, 0.8497, 1.6649, 1.1416, 1.7228, 1.6667,
         0.8471, 0.5910, 0.5346, 0.7842, 1.1899, 1.4191, 0.7268, 5.9199, 5.2150,
         0.7516, 1.2623, 1.3417, 1.6159, 0.9936, 1.5800, 0.3887, 1.6033, 1.7477],
        [1.3495, 1.3761, 1.4331, 1.4105, 1.3827, 1.3546, 1.3184, 1.3474, 1.3474,
         1.3127, 1.3821, 1.2998, 1.4319, 1.3964, 1.4766, 1.3112, 1.4002, 1.3250,
         1.3935, 1.4216, 1.4343, 1.4044, 1.3700, 1.3607, 1.3312, 1.3585, 1.3585,
         1.3970, 1.4506, 1.3765, 1.2263, 1.2886, 1.1934, 1.4017, 1.2558, 1.3793,
         1.4763, 1.2242, 1.5002, 1.4842, 1.1149, 1.0282, 1.4828, 1.4049, 0.9011,
         2.5442, 2.1625, 2.5082, 2.3858, 1.8478, 1.6296, 2.4460, 2.3278, 1.6160]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 89 : 182.87552684857877
Test loss for epoch 89 : 182.88631734625358
Test Precision for epoch 89 : 0.26153846153846155
Test Recall for epoch 89 : 0.26153846153846155
Test F1 for epoch 89 : 0.26153846153846155


theta for epoch 90 : tensor([[2.1079, 2.1306, 2.1924, 2.2542, 2.2193, 2.1105, 2.2018, 2.1060, 2.1060,
         1.3239, 1.3341, 1.3407, 1.3495, 1.3127, 1.3937, 1.3223, 1.3165, 1.2922,
         1.3118, 1.2948, 1.3064, 1.3213, 1.2872, 1.2787, 1.3027, 1.2757, 1.2757,
         1.3127, 1.3694, 1.2933, 1.3191, 1.3587, 1.3051, 1.3188, 1.2582, 1.2961,
         1.3931, 1.4250, 1.4170, 1.4024, 1.4002, 1.3451, 1.3989, 1.4072, 1.3587,
         1.3909, 1.3422, 1.3344, 1.3126, 1.3882, 1.3390, 1.4210, 1.3151, 1.3221],
        [1.3442, 1.2228, 1.0541, 1.2784, 1.3436, 1.3936, 1.3152, 1.3869, 1.3869,
         1.6002, 1.8309, 1.5430, 2.3665, 1.6003, 3.6077, 1.6789, 1.4912, 3.2868,
         1.1834, 1.2519, 1.0000, 1.2269, 1.3650, 1.4014, 1.3776, 1.3996, 1.3996,
         1.3485, 1.1067, 1.4216, 1.3961, 1.1637, 1.4339, 1.4377, 1.3897, 1.3906,
         1.4219, 1.5455, 1.4910, 1.4206, 1.3968, 1.5045, 1.4742, 0.6190, 1.4509,
         1.0691, 1.4645, 1.4528, 1.4346, 1.1172, 1.4593, 0.8847, 1.4376, 1.4444],
        [1.2717, 1.2990, 1.3570, 1.3342, 1.3023, 1.2762, 1.2839, 1.2695, 1.2695,
         1.3290, 1.3390, 1.3459, 1.3541, 1.3177, 1.3349, 1.3274, 1.3062, 1.2485,
         2.1487, 2.2351, 2.3512, 2.2733, 2.0383, 2.1086, 2.1859, 2.0288, 2.0288,
         1.3519, 1.3299, 1.3037, 1.3297, 1.3524, 1.3162, 1.3295, 1.3117, 1.3064,
         1.3991, 1.4309, 1.4234, 1.3933, 1.4050, 1.3989, 1.4057, 1.3059, 1.3436,
         1.3487, 1.3490, 1.3411, 1.3185, 1.3023, 1.3459, 1.3798, 1.3211, 1.3282],
        [1.2909, 1.3191, 1.2680, 1.2425, 1.3224, 1.2955, 1.3038, 1.2885, 1.2885,
         1.3503, 1.2732, 1.3646, 1.3305, 1.3391, 1.3191, 1.3483, 1.3424, 1.0835,
         1.3373, 1.3087, 1.3767, 1.3477, 1.3118, 1.2670, 1.3281, 1.3006, 1.3006,
         2.5583, 2.1050, 1.8961, 2.0056, 2.5322, 1.9014, 2.4869, 1.9154, 1.8936,
         1.4162, 1.4452, 1.3904, 1.3822, 1.4216, 1.3776, 1.4141, 1.1764, 1.3774,
         1.4192, 1.3118, 1.2271, 1.2893, 1.4165, 1.2392, 1.4512, 1.2923, 1.3474],
        [1.6984, 1.3614, 0.5667, 0.7963, 1.1555, 1.5779, 1.5075, 1.6960, 1.6960,
         1.6006, 1.3591, 1.4147, 0.9432, 1.6899, 0.2044, 1.5820, 1.7102, 1.2572,
         1.2865, 0.8441, 0.7296, 1.0597, 1.5512, 1.6562, 1.2975, 1.7051, 1.7051,
         0.7096, 0.7857, 1.6795, 1.4302, 0.8504, 1.6651, 1.1438, 1.7248, 1.6685,
         0.8397, 0.5861, 0.5300, 0.7776, 1.1784, 1.4062, 0.7206, 5.9756, 5.2565,
         0.7534, 1.2641, 1.3437, 1.6165, 0.9960, 1.5817, 0.3906, 1.6057, 1.7495],
        [1.3498, 1.3762, 1.4327, 1.4104, 1.3827, 1.3550, 1.3186, 1.3478, 1.3478,
         1.3124, 1.3826, 1.3003, 1.4314, 1.3957, 1.4762, 1.3109, 1.3995, 1.3242,
         1.3937, 1.4216, 1.4344, 1.4046, 1.3704, 1.3611, 1.3315, 1.3589, 1.3589,
         1.3966, 1.4508, 1.3765, 1.2263, 1.2901, 1.1953, 1.4016, 1.2559, 1.3793,
         1.4767, 1.2239, 1.5004, 1.4846, 1.1152, 1.0284, 1.4830, 1.4070, 0.9025,
         2.5472, 2.1655, 2.5136, 2.3891, 1.8516, 1.6315, 2.4485, 2.3330, 1.6179]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 90 : 182.85695841890436
Test loss for epoch 90 : 182.86844559693714
Test Precision for epoch 90 : 0.26153846153846155
Test Recall for epoch 90 : 0.26153846153846155
Test F1 for epoch 90 : 0.26153846153846155


theta for epoch 91 : tensor([[2.1123, 2.1348, 2.1967, 2.2586, 2.2237, 2.1149, 2.2066, 2.1104, 2.1104,
         1.3237, 1.3337, 1.3403, 1.3491, 1.3126, 1.3930, 1.3222, 1.3163, 1.2916,
         1.3112, 1.2941, 1.3057, 1.3208, 1.2868, 1.2784, 1.3022, 1.2754, 1.2754,
         1.3123, 1.3689, 1.2935, 1.3191, 1.3584, 1.3051, 1.3187, 1.2582, 1.2963,
         1.3926, 1.4244, 1.4162, 1.4019, 1.4000, 1.3448, 1.3983, 1.4066, 1.3579,
         1.3907, 1.3421, 1.3343, 1.3130, 1.3878, 1.3390, 1.4207, 1.3152, 1.3223],
        [1.3444, 1.2238, 1.0538, 1.2782, 1.3439, 1.3937, 1.3153, 1.3870, 1.3870,
         1.6002, 1.8308, 1.5449, 2.3669, 1.6014, 3.6219, 1.6802, 1.4930, 3.3015,
         1.1836, 1.2519, 1.0010, 1.2271, 1.3652, 1.4014, 1.3776, 1.3996, 1.3996,
         1.3483, 1.1062, 1.4213, 1.3958, 1.1644, 1.4336, 1.4376, 1.3895, 1.3906,
         1.4213, 1.5453, 1.4905, 1.4199, 1.3961, 1.5044, 1.4737, 0.6186, 1.4505,
         1.0695, 1.4644, 1.4528, 1.4349, 1.1174, 1.4594, 0.8850, 1.4376, 1.4446],
        [1.2714, 1.2985, 1.3561, 1.3336, 1.3020, 1.2760, 1.2837, 1.2693, 1.2693,
         1.3291, 1.3391, 1.3459, 1.3540, 1.3179, 1.3355, 1.3275, 1.3066, 1.2486,
         2.1532, 2.2380, 2.3538, 2.2768, 2.0431, 2.1138, 2.1895, 2.0337, 2.0337,
         1.3516, 1.3296, 1.3033, 1.3292, 1.3522, 1.3157, 1.3292, 1.3112, 1.3060,
         1.3985, 1.4303, 1.4226, 1.3928, 1.4048, 1.3986, 1.4050, 1.3054, 1.3428,
         1.3487, 1.3489, 1.3410, 1.3188, 1.3022, 1.3459, 1.3797, 1.3212, 1.3283],
        [1.2904, 1.3184, 1.2678, 1.2426, 1.3218, 1.2950, 1.3033, 1.2880, 1.2880,
         1.3500, 1.2730, 1.3644, 1.3303, 1.3387, 1.3187, 1.3480, 1.3419, 1.0844,
         1.3367, 1.3088, 1.3759, 1.3471, 1.3114, 1.2669, 1.3276, 1.3002, 1.3002,
         2.5622, 2.1096, 1.9000, 2.0091, 2.5366, 1.9056, 2.4911, 1.9193, 1.8978,
         1.4155, 1.4446, 1.3898, 1.3817, 1.4213, 1.3778, 1.4134, 1.1772, 1.3768,
         1.4187, 1.3120, 1.2272, 1.2891, 1.4160, 1.2394, 1.4506, 1.2919, 1.3471],
        [1.7001, 1.3629, 0.5693, 0.7987, 1.1577, 1.5796, 1.5093, 1.6977, 1.6977,
         1.6022, 1.3607, 1.4163, 0.9453, 1.6921, 0.2068, 1.5834, 1.7121, 1.2588,
         1.2886, 0.8465, 0.7311, 1.0619, 1.5532, 1.6578, 1.3000, 1.7069, 1.7069,
         0.7120, 0.7885, 1.6816, 1.4329, 0.8512, 1.6656, 1.1463, 1.7270, 1.6705,
         0.8321, 0.5808, 0.5251, 0.7708, 1.1668, 1.3931, 0.7143, 6.0307, 5.2975,
         0.7553, 1.2658, 1.3459, 1.6170, 0.9984, 1.5835, 0.3926, 1.6083, 1.7514],
        [1.3498, 1.3759, 1.4320, 1.4099, 1.3824, 1.3550, 1.3184, 1.3477, 1.3477,
         1.3123, 1.3833, 1.3010, 1.4313, 1.3953, 1.4761, 1.3108, 1.3991, 1.3237,
         1.3934, 1.4211, 1.4340, 1.4043, 1.3701, 1.3609, 1.3311, 1.3588, 1.3588,
         1.3961, 1.4507, 1.3763, 1.2261, 1.2915, 1.1969, 1.4014, 1.2558, 1.3791,
         1.4761, 1.2225, 1.4995, 1.4840, 1.1144, 1.0276, 1.4822, 1.4083, 0.9029,
         2.5512, 2.1695, 2.5202, 2.3935, 1.8564, 1.6346, 2.4521, 2.3394, 1.6209]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 91 : 182.83845256799918
Test loss for epoch 91 : 182.84993024085958
Test Precision for epoch 91 : 0.26153846153846155
Test Recall for epoch 91 : 0.26153846153846155
Test F1 for epoch 91 : 0.26153846153846155


theta for epoch 92 : tensor([[2.1163, 2.1386, 2.2006, 2.2627, 2.2279, 2.1190, 2.2111, 2.1144, 2.1144,
         1.3243, 1.3341, 1.3407, 1.3495, 1.3132, 1.3930, 1.3228, 1.3169, 1.2918,
         1.3108, 1.2935, 1.3053, 1.3203, 1.2865, 1.2781, 1.3019, 1.2752, 1.2752,
         1.3122, 1.3685, 1.2939, 1.3192, 1.3583, 1.3053, 1.3188, 1.2585, 1.2967,
         1.3921, 1.4238, 1.4155, 1.4013, 1.3999, 1.3444, 1.3977, 1.4060, 1.3571,
         1.3903, 1.3418, 1.3340, 1.3130, 1.3872, 1.3388, 1.4201, 1.3151, 1.3223],
        [1.3445, 1.2247, 1.0534, 1.2780, 1.3441, 1.3937, 1.3153, 1.3871, 1.3871,
         1.6005, 1.8309, 1.5470, 2.3674, 1.6029, 3.6362, 1.6817, 1.4950, 3.3164,
         1.1836, 1.2517, 1.0019, 1.2271, 1.3652, 1.4013, 1.3774, 1.3995, 1.3995,
         1.3480, 1.1057, 1.4211, 1.3954, 1.1651, 1.4332, 1.4374, 1.3891, 1.3905,
         1.4207, 1.5448, 1.4898, 1.4191, 1.3954, 1.5041, 1.4732, 0.6181, 1.4499,
         1.0695, 1.4640, 1.4523, 1.4348, 1.1171, 1.4590, 0.8850, 1.4373, 1.4443],
        [1.2711, 1.2980, 1.3552, 1.3329, 1.3016, 1.2757, 1.2834, 1.2690, 1.2690,
         1.3298, 1.3397, 1.3464, 1.3544, 1.3186, 1.3365, 1.3282, 1.3075, 1.2491,
         2.1577, 2.2410, 2.3566, 2.2803, 2.0480, 2.1191, 2.1932, 2.0386, 2.0386,
         1.3513, 1.3293, 1.3028, 1.3288, 1.3520, 1.3151, 1.3287, 1.3107, 1.3055,
         1.3978, 1.4295, 1.4216, 1.3921, 1.4044, 1.3981, 1.4042, 1.3047, 1.3420,
         1.3482, 1.3483, 1.3404, 1.3186, 1.3015, 1.3454, 1.3790, 1.3207, 1.3280],
        [1.2902, 1.3181, 1.2679, 1.2430, 1.3215, 1.2948, 1.3030, 1.2878, 1.2878,
         1.3503, 1.2734, 1.3649, 1.3308, 1.3390, 1.3189, 1.3483, 1.3422, 1.0860,
         1.3364, 1.3091, 1.3754, 1.3467, 1.3113, 1.2670, 1.3274, 1.3001, 1.3001,
         2.5657, 2.1140, 1.9036, 2.0124, 2.5406, 1.9094, 2.4949, 1.9229, 1.9016,
         1.4150, 1.4442, 1.3892, 1.3814, 1.4212, 1.3781, 1.4128, 1.1780, 1.3762,
         1.4182, 1.3122, 1.2272, 1.2888, 1.4154, 1.2397, 1.4500, 1.2915, 1.3467],
        [1.7017, 1.3643, 0.5718, 0.8009, 1.1599, 1.5812, 1.5111, 1.6994, 1.6994,
         1.6041, 1.3625, 1.4182, 0.9475, 1.6946, 0.2094, 1.5852, 1.7143, 1.2608,
         1.2906, 0.8487, 0.7325, 1.0641, 1.5550, 1.6594, 1.3024, 1.7086, 1.7086,
         0.7142, 0.7912, 1.6837, 1.4354, 0.8518, 1.6659, 1.1486, 1.7292, 1.6724,
         0.8247, 0.5757, 0.5203, 0.7642, 1.1553, 1.3800, 0.7081, 6.0858, 5.3381,
         0.7569, 1.2672, 1.3475, 1.6172, 1.0005, 1.5849, 0.3941, 1.6104, 1.7530],
        [1.3493, 1.3754, 1.4311, 1.4092, 1.3817, 1.3546, 1.3178, 1.3473, 1.3473,
         1.3126, 1.3844, 1.3021, 1.4314, 1.3954, 1.4762, 1.3111, 1.3990, 1.3235,
         1.3927, 1.4202, 1.4331, 1.4035, 1.3695, 1.3603, 1.3304, 1.3582, 1.3582,
         1.3954, 1.4505, 1.3761, 1.2256, 1.2926, 1.1983, 1.4009, 1.2555, 1.3788,
         1.4752, 1.2210, 1.4984, 1.4831, 1.1134, 1.0264, 1.4812, 1.4094, 0.9030,
         2.5557, 2.1739, 2.5271, 2.3982, 1.8616, 1.6382, 2.4562, 2.3463, 1.6244]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 92 : 182.8202706126917
Test loss for epoch 92 : 182.83173146938822
Test Precision for epoch 92 : 0.26153846153846155
Test Recall for epoch 92 : 0.26153846153846155
Test F1 for epoch 92 : 0.26153846153846155


theta for epoch 93 : tensor([[2.1202, 2.1425, 2.2046, 2.2667, 2.2320, 2.1231, 2.2155, 2.1183, 2.1183,
         1.3246, 1.3342, 1.3408, 1.3495, 1.3135, 1.3928, 1.3231, 1.3172, 1.2916,
         1.3103, 1.2930, 1.3050, 1.3200, 1.2862, 1.2779, 1.3015, 1.2749, 1.2749,
         1.3121, 1.3683, 1.2944, 1.3194, 1.3582, 1.3055, 1.3190, 1.2588, 1.2971,
         1.3921, 1.4237, 1.4152, 1.4012, 1.4002, 1.3446, 1.3976, 1.4058, 1.3567,
         1.3895, 1.3410, 1.3332, 1.3126, 1.3862, 1.3382, 1.4191, 1.3144, 1.3217],
        [1.3446, 1.2256, 1.0531, 1.2780, 1.3444, 1.3939, 1.3154, 1.3872, 1.3872,
         1.6008, 1.8311, 1.5491, 2.3679, 1.6042, 3.6503, 1.6831, 1.4970, 3.3312,
         1.1836, 1.2515, 1.0028, 1.2270, 1.3652, 1.4012, 1.3772, 1.3994, 1.3994,
         1.3478, 1.1053, 1.4209, 1.3951, 1.1658, 1.4329, 1.4373, 1.3888, 1.3905,
         1.4205, 1.5448, 1.4896, 1.4187, 1.3951, 1.5042, 1.4731, 0.6180, 1.4497,
         1.0691, 1.4632, 1.4515, 1.4343, 1.1165, 1.4583, 0.8848, 1.4366, 1.4437],
        [1.2708, 1.2976, 1.3545, 1.3323, 1.3013, 1.2754, 1.2832, 1.2687, 1.2687,
         1.3302, 1.3401, 1.3465, 1.3545, 1.3190, 1.3372, 1.3286, 1.3081, 1.2493,
         2.1623, 2.2441, 2.3595, 2.2839, 2.0529, 2.1244, 2.1968, 2.0436, 2.0436,
         1.3510, 1.3290, 1.3024, 1.3283, 1.3518, 1.3146, 1.3283, 1.3102, 1.3051,
         1.3975, 1.4292, 1.4211, 1.3919, 1.4045, 1.3980, 1.4038, 1.3045, 1.3415,
         1.3472, 1.3472, 1.3393, 1.3180, 1.3004, 1.3445, 1.3780, 1.3198, 1.3271],
        [1.2900, 1.3178, 1.2681, 1.2434, 1.3213, 1.2947, 1.3028, 1.2877, 1.2877,
         1.3504, 1.2737, 1.3651, 1.3311, 1.3390, 1.3189, 1.3484, 1.3422, 1.0873,
         1.3361, 1.3093, 1.3749, 1.3464, 1.3111, 1.2671, 1.3271, 1.2999, 1.2999,
         2.5692, 2.1184, 1.9073, 2.0157, 2.5446, 1.9133, 2.4987, 1.9265, 1.9055,
         1.4149, 1.4442, 1.3892, 1.3816, 1.4214, 1.3789, 1.4127, 1.1791, 1.3760,
         1.4173, 1.3120, 1.2269, 1.2883, 1.4144, 1.2397, 1.4490, 1.2908, 1.3460],
        [1.7033, 1.3655, 0.5739, 0.8028, 1.1619, 1.5827, 1.5128, 1.7009, 1.7009,
         1.6056, 1.3638, 1.4198, 0.9492, 1.6968, 0.2115, 1.5866, 1.7162, 1.2624,
         1.2925, 0.8507, 0.7337, 1.0659, 1.5567, 1.6608, 1.3045, 1.7102, 1.7102,
         0.7160, 0.7935, 1.6856, 1.4378, 0.8521, 1.6661, 1.1505, 1.7312, 1.6743,
         0.8178, 0.5709, 0.5158, 0.7581, 1.1444, 1.3675, 0.7024, 6.1410, 5.3787,
         0.7578, 1.2678, 1.3485, 1.6168, 1.0019, 1.5859, 0.3950, 1.6120, 1.7540],
        [1.3491, 1.3752, 1.4307, 1.4089, 1.3813, 1.3545, 1.3175, 1.3471, 1.3471,
         1.3128, 1.3854, 1.3031, 1.4314, 1.3953, 1.4761, 1.3112, 1.3989, 1.3233,
         1.3923, 1.4195, 1.4325, 1.4029, 1.3691, 1.3599, 1.3298, 1.3578, 1.3578,
         1.3950, 1.4504, 1.3760, 1.2254, 1.2940, 1.2000, 1.4007, 1.2555, 1.3788,
         1.4749, 1.2201, 1.4978, 1.4828, 1.1130, 1.0259, 1.4807, 1.4111, 0.9036,
         2.5596, 2.1776, 2.5334, 2.4021, 1.8662, 1.6411, 2.4598, 2.3525, 1.6274]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 93 : 182.80242176640624
Test loss for epoch 93 : 182.81437444259245
Test Precision for epoch 93 : 0.26153846153846155
Test Recall for epoch 93 : 0.26153846153846155
Test F1 for epoch 93 : 0.26153846153846155


theta for epoch 94 : tensor([[2.1243, 2.1465, 2.2087, 2.2710, 2.2363, 2.1273, 2.2200, 2.1224, 2.1224,
         1.3240, 1.3335, 1.3401, 1.3487, 1.3130, 1.3917, 1.3225, 1.3166, 1.2907,
         1.3098, 1.2924, 1.3046, 1.3195, 1.2858, 1.2775, 1.3011, 1.2745, 1.2745,
         1.3118, 1.3680, 1.2947, 1.3195, 1.3580, 1.3057, 1.3190, 1.2590, 1.2974,
         1.3925, 1.4241, 1.4154, 1.4016, 1.4008, 1.3451, 1.3979, 1.4059, 1.3567,
         1.3890, 1.3406, 1.3328, 1.3125, 1.3856, 1.3378, 1.4185, 1.3141, 1.3214],
        [1.3448, 1.2265, 1.0529, 1.2779, 1.3446, 1.3941, 1.3155, 1.3874, 1.3874,
         1.6009, 1.8311, 1.5510, 2.3681, 1.6054, 3.6642, 1.6842, 1.4987, 3.3457,
         1.1834, 1.2513, 1.0036, 1.2270, 1.3651, 1.4010, 1.3770, 1.3992, 1.3992,
         1.3475, 1.1048, 1.4207, 1.3948, 1.1665, 1.4326, 1.4371, 1.3885, 1.3904,
         1.4206, 1.5452, 1.4897, 1.4187, 1.3952, 1.5047, 1.4733, 0.6182, 1.4499,
         1.0690, 1.4627, 1.4510, 1.4342, 1.1162, 1.4580, 0.8850, 1.4362, 1.4435],
        [1.2706, 1.2973, 1.3540, 1.3318, 1.3010, 1.2753, 1.2830, 1.2686, 1.2686,
         1.3298, 1.3397, 1.3460, 1.3539, 1.3186, 1.3371, 1.3282, 1.3079, 1.2488,
         2.1668, 2.2471, 2.3623, 2.2874, 2.0576, 2.1296, 2.2004, 2.0483, 2.0483,
         1.3507, 1.3287, 1.3020, 1.3278, 1.3516, 1.3141, 1.3279, 1.3097, 1.3047,
         1.3977, 1.4293, 1.4211, 1.3922, 1.4050, 1.3984, 1.4038, 1.3047, 1.3415,
         1.3467, 1.3467, 1.3388, 1.3178, 1.2997, 1.3440, 1.3774, 1.3194, 1.3268],
        [1.2896, 1.3172, 1.2680, 1.2434, 1.3208, 1.2943, 1.3023, 1.2873, 1.2873,
         1.3496, 1.2731, 1.3645, 1.3305, 1.3382, 1.3180, 1.3477, 1.3414, 1.0878,
         1.3355, 1.3091, 1.3741, 1.3457, 1.3106, 1.2668, 1.3265, 1.2994, 1.2994,
         2.5731, 2.1232, 1.9114, 2.0195, 2.5490, 1.9176, 2.5029, 1.9306, 1.9098,
         1.4151, 1.4445, 1.3894, 1.3820, 1.4219, 1.3798, 1.4128, 1.1802, 1.3760,
         1.4165, 1.3118, 1.2266, 1.2878, 1.4135, 1.2397, 1.4481, 1.2901, 1.3453],
        [1.7049, 1.3668, 0.5760, 0.8048, 1.1639, 1.5843, 1.5146, 1.7026, 1.7026,
         1.6067, 1.3646, 1.4209, 0.9505, 1.6986, 0.2134, 1.5876, 1.7176, 1.2637,
         1.2944, 0.8528, 0.7350, 1.0679, 1.5584, 1.6622, 1.3067, 1.7118, 1.7118,
         0.7178, 0.7957, 1.6876, 1.4403, 0.8524, 1.6663, 1.1524, 1.7332, 1.6761,
         0.8111, 0.5661, 0.5114, 0.7521, 1.1336, 1.3550, 0.6968, 6.1960, 5.4190,
         0.7590, 1.2688, 1.3498, 1.6167, 1.0037, 1.5872, 0.3962, 1.6140, 1.7554],
        [1.3490, 1.3750, 1.4304, 1.4086, 1.3809, 1.3543, 1.3173, 1.3470, 1.3470,
         1.3122, 1.3857, 1.3033, 1.4307, 1.3946, 1.4753, 1.3107, 1.3981, 1.3223,
         1.3919, 1.4189, 1.4319, 1.4024, 1.3686, 1.3595, 1.3293, 1.3574, 1.3574,
         1.3946, 1.4502, 1.3761, 1.2251, 1.2955, 1.2017, 1.4006, 1.2555, 1.3788,
         1.4750, 1.2198, 1.4978, 1.4830, 1.1131, 1.0260, 1.4808, 1.4133, 0.9046,
         2.5635, 2.1813, 2.5397, 2.4060, 1.8707, 1.6442, 2.4633, 2.3588, 1.6303]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 94 : 182.78476954003924
Test loss for epoch 94 : 182.79709905781203
Test Precision for epoch 94 : 0.26153846153846155
Test Recall for epoch 94 : 0.26153846153846155
Test F1 for epoch 94 : 0.26153846153846155


theta for epoch 95 : tensor([[2.1284, 2.1505, 2.2129, 2.2752, 2.2407, 2.1314, 2.2245, 2.1266, 2.1266,
         1.3232, 1.3325, 1.3391, 1.3477, 1.3122, 1.3905, 1.3217, 1.3158, 1.2895,
         1.3093, 1.2918, 1.3044, 1.3191, 1.2854, 1.2771, 1.3007, 1.2741, 1.2741,
         1.3113, 1.3673, 1.2947, 1.3192, 1.3575, 1.3055, 1.3187, 1.2588, 1.2974,
         1.3929, 1.4244, 1.4156, 1.4019, 1.4015, 1.3456, 1.3982, 1.4060, 1.3566,
         1.3892, 1.3408, 1.3330, 1.3130, 1.3857, 1.3380, 1.4186, 1.3143, 1.3217],
        [1.3444, 1.2268, 1.0522, 1.2774, 1.3444, 1.3937, 1.3151, 1.3870, 1.3870,
         1.6012, 1.8315, 1.5531, 2.3685, 1.6069, 3.6782, 1.6856, 1.5006, 3.3604,
         1.1829, 1.2508, 1.0042, 1.2267, 1.3648, 1.4006, 1.3766, 1.3988, 1.3988,
         1.3468, 1.1040, 1.4201, 1.3942, 1.1669, 1.4319, 1.4365, 1.3878, 1.3901,
         1.4207, 1.5454, 1.4898, 1.4186, 1.3952, 1.5051, 1.4734, 0.6183, 1.4500,
         1.0691, 1.4627, 1.4509, 1.4344, 1.1161, 1.4580, 0.8854, 1.4362, 1.4436],
        [1.2703, 1.2968, 1.3533, 1.3312, 1.3005, 1.2749, 1.2826, 1.2682, 1.2682,
         1.3293, 1.3391, 1.3453, 1.3531, 1.3181, 1.3368, 1.3277, 1.3076, 1.2480,
         2.1713, 2.2501, 2.3652, 2.2910, 2.0623, 2.1347, 2.2040, 2.0531, 2.0531,
         1.3503, 1.3282, 1.3015, 1.3272, 1.3512, 1.3134, 1.3273, 1.3091, 1.3042,
         1.3980, 1.4295, 1.4211, 1.3925, 1.4056, 1.3988, 1.4040, 1.3049, 1.3416,
         1.3469, 1.3468, 1.3389, 1.3182, 1.2996, 1.3442, 1.3775, 1.3195, 1.3270],
        [1.2888, 1.3163, 1.2675, 1.2431, 1.3199, 1.2935, 1.3015, 1.2865, 1.2865,
         1.3486, 1.2722, 1.3635, 1.3297, 1.3371, 1.3168, 1.3467, 1.3403, 1.0879,
         1.3346, 1.3088, 1.3732, 1.3449, 1.3100, 1.2664, 1.3257, 1.2987, 1.2987,
         2.5771, 2.1283, 1.9157, 2.0234, 2.5535, 1.9221, 2.5072, 1.9348, 1.9144,
         1.4152, 1.4446, 1.3896, 1.3823, 1.4224, 1.3807, 1.4128, 1.1812, 1.3758,
         1.4159, 1.3119, 1.2265, 1.2876, 1.4129, 1.2399, 1.4474, 1.2897, 1.3449],
        [1.7066, 1.3684, 0.5785, 0.8071, 1.1662, 1.5861, 1.5166, 1.7043, 1.7043,
         1.6078, 1.3655, 1.4222, 0.9520, 1.7004, 0.2157, 1.5887, 1.7191, 1.2651,
         1.2966, 0.8554, 0.7368, 1.0703, 1.5604, 1.6640, 1.3092, 1.7137, 1.7137,
         0.7197, 0.7982, 1.6896, 1.4428, 0.8528, 1.6665, 1.1544, 1.7353, 1.6780,
         0.8042, 0.5610, 0.5067, 0.7458, 1.1227, 1.3422, 0.6910, 6.2505, 5.4586,
         0.7611, 1.2705, 1.3519, 1.6174, 1.0063, 1.5892, 0.3984, 1.6167, 1.7575],
        [1.3485, 1.3745, 1.4299, 1.4082, 1.3803, 1.3538, 1.3168, 1.3465, 1.3465,
         1.3115, 1.3857, 1.3034, 1.4297, 1.3936, 1.4742, 1.3099, 1.3971, 1.3211,
         1.3916, 1.4184, 1.4313, 1.4019, 1.3682, 1.3591, 1.3288, 1.3571, 1.3571,
         1.3939, 1.4498, 1.3758, 1.2245, 1.2967, 1.2032, 1.4001, 1.2552, 1.3785,
         1.4752, 1.2195, 1.4977, 1.4832, 1.1133, 1.0260, 1.4808, 1.4155, 0.9056,
         2.5679, 2.1853, 2.5463, 2.4101, 1.8756, 1.6476, 2.4673, 2.3654, 1.6337]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 95 : 182.7673347381512
Test loss for epoch 95 : 182.77974672782653
Test Precision for epoch 95 : 0.26153846153846155
Test Recall for epoch 95 : 0.26153846153846155
Test F1 for epoch 95 : 0.26153846153846155


theta for epoch 96 : tensor([[2.1327, 2.1548, 2.2172, 2.2797, 2.2453, 2.1358, 2.2292, 2.1309, 2.1309,
         1.3228, 1.3320, 1.3385, 1.3471, 1.3118, 1.3897, 1.3213, 1.3153, 1.2887,
         1.3089, 1.2914, 1.3042, 1.3188, 1.2850, 1.2768, 1.3004, 1.2738, 1.2738,
         1.3104, 1.3664, 1.2943, 1.3186, 1.3567, 1.3050, 1.3179, 1.2582, 1.2969,
         1.3931, 1.4245, 1.4156, 1.4020, 1.4019, 1.3458, 1.3983, 1.4057, 1.3563,
         1.3893, 1.3408, 1.3329, 1.3132, 1.3856, 1.3380, 1.4186, 1.3142, 1.3217],
        [1.3437, 1.2267, 1.0512, 1.2765, 1.3438, 1.3931, 1.3143, 1.3863, 1.3863,
         1.6021, 1.8324, 1.5557, 2.3694, 1.6089, 3.6927, 1.6874, 1.5031, 3.3756,
         1.1822, 1.2502, 1.0045, 1.2261, 1.3643, 1.4000, 1.3759, 1.3983, 1.3983,
         1.3457, 1.1028, 1.4191, 1.3931, 1.1668, 1.4309, 1.4355, 1.3867, 1.3893,
         1.4205, 1.5454, 1.4895, 1.4181, 1.3950, 1.5051, 1.4732, 0.6179, 1.4498,
         1.0688, 1.4623, 1.4505, 1.4343, 1.1156, 1.4576, 0.8855, 1.4359, 1.4433],
        [1.2697, 1.2962, 1.3527, 1.3305, 1.2999, 1.2744, 1.2821, 1.2677, 1.2677,
         1.3291, 1.3389, 1.3449, 1.3527, 1.3179, 1.3367, 1.3275, 1.3075, 1.2476,
         2.1760, 2.2534, 2.3683, 2.2947, 2.0672, 2.1400, 2.2078, 2.0580, 2.0580,
         1.3496, 1.3274, 1.3006, 1.3263, 1.3506, 1.3124, 1.3264, 1.3082, 1.3033,
         1.3981, 1.4295, 1.4210, 1.3926, 1.4060, 1.3991, 1.4040, 1.3050, 1.3415,
         1.3470, 1.3468, 1.3388, 1.3184, 1.2994, 1.3442, 1.3774, 1.3195, 1.3270],
        [1.2880, 1.3154, 1.2669, 1.2427, 1.3191, 1.2928, 1.3006, 1.2858, 1.2858,
         1.3478, 1.2716, 1.3628, 1.3292, 1.3364, 1.3160, 1.3460, 1.3395, 1.0882,
         1.3340, 1.3085, 1.3725, 1.3442, 1.3094, 1.2660, 1.3251, 1.2981, 1.2981,
         2.5811, 2.1333, 1.9200, 2.0274, 2.5580, 1.9266, 2.5115, 1.9391, 1.9189,
         1.4151, 1.4446, 1.3896, 1.3824, 1.4226, 1.3814, 1.4127, 1.1819, 1.3754,
         1.4153, 1.3120, 1.2263, 1.2873, 1.4122, 1.2400, 1.4468, 1.2892, 1.3445],
        [1.7085, 1.3701, 0.5812, 0.8096, 1.1687, 1.5881, 1.5188, 1.7062, 1.7062,
         1.6093, 1.3668, 1.4239, 0.9539, 1.7025, 0.2185, 1.5902, 1.7210, 1.2669,
         1.2992, 0.8581, 0.7390, 1.0730, 1.5627, 1.6659, 1.3120, 1.7158, 1.7158,
         0.7217, 0.8006, 1.6915, 1.4452, 0.8531, 1.6665, 1.1562, 1.7372, 1.6798,
         0.7972, 0.5556, 0.5017, 0.7394, 1.1116, 1.3293, 0.6849, 6.3046, 5.4975,
         0.7633, 1.2723, 1.3539, 1.6181, 1.0092, 1.5913, 0.4008, 1.6194, 1.7597],
        [1.3482, 1.3743, 1.4297, 1.4079, 1.3799, 1.3535, 1.3164, 1.3462, 1.3462,
         1.3113, 1.3865, 1.3040, 1.4294, 1.3933, 1.4737, 1.3097, 1.3968, 1.3205,
         1.3917, 1.4184, 1.4312, 1.4019, 1.3682, 1.3591, 1.3287, 1.3571, 1.3571,
         1.3932, 1.4492, 1.3755, 1.2238, 1.2979, 1.2045, 1.3996, 1.2548, 1.3782,
         1.4753, 1.2192, 1.4976, 1.4833, 1.1134, 1.0260, 1.4808, 1.4178, 0.9066,
         2.5718, 2.1887, 2.5524, 2.4137, 1.8800, 1.6506, 2.4708, 2.3716, 1.6367]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 96 : 182.75014858017292
Test loss for epoch 96 : 182.76294527913325
Test Precision for epoch 96 : 0.26153846153846155
Test Recall for epoch 96 : 0.26153846153846155
Test F1 for epoch 96 : 0.26153846153846155


theta for epoch 97 : tensor([[2.1371, 2.1591, 2.2217, 2.2843, 2.2499, 2.1402, 2.2340, 2.1352, 2.1352,
         1.3227, 1.3317, 1.3382, 1.3469, 1.3116, 1.3893, 1.3211, 1.3151, 1.2882,
         1.3085, 1.2911, 1.3042, 1.3185, 1.2847, 1.2764, 1.3000, 1.2734, 1.2734,
         1.3096, 1.3656, 1.2939, 1.3180, 1.3559, 1.3045, 1.3173, 1.2577, 1.2965,
         1.3932, 1.4245, 1.4155, 1.4020, 1.4022, 1.3459, 1.3983, 1.4052, 1.3557,
         1.3890, 1.3405, 1.3326, 1.3130, 1.3852, 1.3375, 1.4184, 1.3138, 1.3214],
        [1.3431, 1.2268, 1.0505, 1.2759, 1.3434, 1.3926, 1.3137, 1.3859, 1.3859,
         1.6030, 1.8334, 1.5583, 2.3703, 1.6109, 3.7070, 1.6892, 1.5055, 3.3908,
         1.1815, 1.2496, 1.0050, 1.2257, 1.3639, 1.3996, 1.3754, 1.3978, 1.3978,
         1.3448, 1.1018, 1.4183, 1.3922, 1.1668, 1.4299, 1.4347, 1.3857, 1.3887,
         1.4203, 1.5453, 1.4892, 1.4177, 1.3947, 1.5051, 1.4730, 0.6176, 1.4495,
         1.0684, 1.4617, 1.4499, 1.4340, 1.1149, 1.4571, 0.8855, 1.4353, 1.4428],
        [1.2693, 1.2957, 1.3522, 1.3300, 1.2993, 1.2740, 1.2816, 1.2672, 1.2672,
         1.3291, 1.3389, 1.3447, 1.3526, 1.3179, 1.3368, 1.3275, 1.3077, 1.2474,
         2.1808, 2.2568, 2.3715, 2.2986, 2.0721, 2.1452, 2.2116, 2.0630, 2.0630,
         1.3489, 1.3266, 1.2999, 1.3254, 1.3500, 1.3116, 1.3255, 1.3073, 1.3025,
         1.3980, 1.4294, 1.4208, 1.3926, 1.4062, 1.3991, 1.4038, 1.3048, 1.3413,
         1.3466, 1.3465, 1.3384, 1.3182, 1.2989, 1.3438, 1.3770, 1.3190, 1.3267],
        [1.2874, 1.3147, 1.2666, 1.2425, 1.3184, 1.2922, 1.2999, 1.2852, 1.2852,
         1.3474, 1.2714, 1.3624, 1.3290, 1.3359, 1.3154, 1.3455, 1.3390, 1.0888,
         1.3334, 1.3083, 1.3719, 1.3436, 1.3089, 1.2657, 1.3245, 1.2976, 1.2976,
         2.5850, 2.1383, 1.9243, 2.0314, 2.5623, 1.9310, 2.5157, 1.9433, 1.9233,
         1.4150, 1.4445, 1.3896, 1.3825, 1.4228, 1.3820, 1.4126, 1.1824, 1.3748,
         1.4146, 1.3118, 1.2260, 1.2869, 1.4114, 1.2399, 1.4459, 1.2885, 1.3439],
        [1.7103, 1.3716, 0.5835, 0.8118, 1.1709, 1.5900, 1.5208, 1.7081, 1.7081,
         1.6108, 1.3680, 1.4256, 0.9557, 1.7047, 0.2211, 1.5917, 1.7230, 1.2686,
         1.3015, 0.8606, 0.7409, 1.0754, 1.5647, 1.6678, 1.3145, 1.7178, 1.7178,
         0.7232, 0.8027, 1.6932, 1.4474, 0.8531, 1.6664, 1.1577, 1.7390, 1.6814,
         0.7905, 0.5504, 0.4969, 0.7333, 1.1010, 1.3167, 0.6792, 6.3587, 5.5363,
         0.7650, 1.2734, 1.3554, 1.6183, 1.0114, 1.5930, 0.4026, 1.6217, 1.7615],
        [1.3480, 1.3741, 1.4297, 1.4079, 1.3796, 1.3532, 1.3161, 1.3459, 1.3459,
         1.3114, 1.3875, 1.3050, 1.4294, 1.3933, 1.4735, 1.3099, 1.3968, 1.3203,
         1.3917, 1.4183, 1.4311, 1.4017, 1.3682, 1.3590, 1.3285, 1.3570, 1.3570,
         1.3926, 1.4487, 1.3753, 1.2231, 1.2991, 1.2060, 1.3991, 1.2544, 1.3779,
         1.4752, 1.2189, 1.4974, 1.4833, 1.1134, 1.0259, 1.4806, 1.4198, 0.9073,
         2.5756, 2.1921, 2.5584, 2.4170, 1.8843, 1.6535, 2.4742, 2.3777, 1.6396]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 97 : 182.73333036050337
Test loss for epoch 97 : 182.74662571048214
Test Precision for epoch 97 : 0.26153846153846155
Test Recall for epoch 97 : 0.26153846153846155
Test F1 for epoch 97 : 0.26153846153846155


theta for epoch 98 : tensor([[2.1411, 2.1632, 2.2259, 2.2886, 2.2543, 2.1444, 2.2385, 2.1392, 2.1392,
         1.3225, 1.3315, 1.3378, 1.3466, 1.3115, 1.3890, 1.3209, 1.3149, 1.2877,
         1.3080, 1.2906, 1.3040, 1.3181, 1.2842, 1.2759, 1.2996, 1.2730, 1.2730,
         1.3093, 1.3652, 1.2940, 1.3180, 1.3556, 1.3045, 1.3171, 1.2576, 1.2965,
         1.3933, 1.4245, 1.4154, 1.4020, 1.4024, 1.3460, 1.3982, 1.4046, 1.3551,
         1.3888, 1.3402, 1.3323, 1.3129, 1.3849, 1.3372, 1.4182, 1.3134, 1.3211],
        [1.3431, 1.2274, 1.0504, 1.2759, 1.3436, 1.3927, 1.3137, 1.3859, 1.3859,
         1.6033, 1.8338, 1.5603, 2.3705, 1.6123, 3.7208, 1.6904, 1.5074, 3.4053,
         1.1812, 1.2494, 1.0058, 1.2255, 1.3638, 1.3993, 1.3751, 1.3976, 1.3976,
         1.3444, 1.1015, 1.4180, 1.3919, 1.1675, 1.4296, 1.4343, 1.3853, 1.3886,
         1.4203, 1.5453, 1.4890, 1.4174, 1.3946, 1.5053, 1.4730, 0.6177, 1.4494,
         1.0684, 1.4616, 1.4497, 1.4342, 1.1147, 1.4569, 0.8861, 1.4352, 1.4428],
        [1.2689, 1.2954, 1.3519, 1.3296, 1.2989, 1.2737, 1.2812, 1.2669, 1.2669,
         1.3290, 1.3388, 1.3444, 1.3523, 1.3178, 1.3368, 1.3274, 1.3076, 1.2470,
         2.1854, 2.2601, 2.3747, 2.3024, 2.0769, 2.1504, 2.2154, 2.0678, 2.0678,
         1.3486, 1.3262, 1.2994, 1.3248, 1.3497, 1.3110, 1.3250, 1.3068, 1.3021,
         1.3980, 1.4293, 1.4205, 1.3926, 1.4064, 1.3992, 1.4036, 1.3047, 1.3410,
         1.3463, 1.3461, 1.3380, 1.3180, 1.2983, 1.3433, 1.3766, 1.3186, 1.3263],
        [1.2869, 1.3141, 1.2664, 1.2424, 1.3179, 1.2917, 1.2994, 1.2847, 1.2847,
         1.3469, 1.2711, 1.3620, 1.3288, 1.3354, 1.3148, 1.3451, 1.3385, 1.0894,
         1.3327, 1.3081, 1.3712, 1.3430, 1.3083, 1.2653, 1.3238, 1.2970, 1.2970,
         2.5889, 2.1432, 1.9286, 2.0353, 2.5667, 1.9355, 2.5198, 1.9475, 1.9278,
         1.4148, 1.4444, 1.3897, 1.3826, 1.4230, 1.3826, 1.4125, 1.1828, 1.3742,
         1.4140, 1.3118, 1.2258, 1.2865, 1.4107, 1.2400, 1.4452, 1.2880, 1.3433],
        [1.7119, 1.3728, 0.5854, 0.8135, 1.1726, 1.5917, 1.5226, 1.7097, 1.7097,
         1.6119, 1.3687, 1.4269, 0.9569, 1.7066, 0.2231, 1.5930, 1.7246, 1.2700,
         1.3034, 0.8625, 0.7422, 1.0773, 1.5663, 1.6692, 1.3165, 1.7194, 1.7194,
         0.7244, 0.8045, 1.6950, 1.4495, 0.8528, 1.6664, 1.1590, 1.7409, 1.6831,
         0.7842, 0.5455, 0.4924, 0.7276, 1.0908, 1.3046, 0.6738, 6.4129, 5.5750,
         0.7661, 1.2742, 1.3565, 1.6182, 1.0131, 1.5943, 0.4038, 1.6236, 1.7630],
        [1.3473, 1.3736, 1.4294, 1.4074, 1.3789, 1.3524, 1.3155, 1.3452, 1.3452,
         1.3111, 1.3880, 1.3054, 1.4289, 1.3929, 1.4728, 1.3094, 1.3963, 1.3196,
         1.3911, 1.4176, 1.4303, 1.4010, 1.3674, 1.3583, 1.3276, 1.3563, 1.3563,
         1.3921, 1.4482, 1.3751, 1.2224, 1.3005, 1.2074, 1.3987, 1.2541, 1.3777,
         1.4749, 1.2182, 1.4968, 1.4829, 1.1130, 1.0253, 1.4802, 1.4216, 0.9076,
         2.5801, 2.1962, 2.5652, 2.4211, 1.8892, 1.6573, 2.4784, 2.3846, 1.6433]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 98 : 182.7165720264546
Test loss for epoch 98 : 182.72988573299378
Test Precision for epoch 98 : 0.26153846153846155
Test Recall for epoch 98 : 0.26153846153846155
Test F1 for epoch 98 : 0.26153846153846155


theta for epoch 99 : tensor([[2.1452, 2.1673, 2.2301, 2.2930, 2.2588, 2.1486, 2.2430, 2.1434, 2.1434,
         1.3223, 1.3312, 1.3375, 1.3463, 1.3112, 1.3886, 1.3207, 1.3147, 1.2872,
         1.3074, 1.2902, 1.3038, 1.3177, 1.2837, 1.2754, 1.2991, 1.2724, 1.2724,
         1.3093, 1.3652, 1.2943, 1.3182, 1.3557, 1.3047, 1.3172, 1.2578, 1.2968,
         1.3932, 1.4243, 1.4151, 1.4018, 1.4025, 1.3459, 1.3981, 1.4039, 1.3543,
         1.3884, 1.3398, 1.3318, 1.3125, 1.3844, 1.3367, 1.4179, 1.3129, 1.3205],
        [1.3433, 1.2282, 1.0507, 1.2761, 1.3439, 1.3929, 1.3139, 1.3861, 1.3861,
         1.6036, 1.8342, 1.5621, 2.3706, 1.6136, 3.7343, 1.6914, 1.5091, 3.4196,
         1.1808, 1.2492, 1.0067, 1.2254, 1.3637, 1.3991, 1.3749, 1.3975, 1.3975,
         1.3443, 1.1015, 1.4180, 1.3918, 1.1684, 1.4295, 1.4343, 1.3852, 1.3888,
         1.4203, 1.5453, 1.4889, 1.4172, 1.3946, 1.5054, 1.4729, 0.6178, 1.4494,
         1.0685, 1.4615, 1.4495, 1.4342, 1.1145, 1.4568, 0.8867, 1.4350, 1.4427],
        [1.2686, 1.2951, 1.3517, 1.3293, 1.2985, 1.2734, 1.2808, 1.2665, 1.2665,
         1.3288, 1.3386, 1.3440, 1.3520, 1.3176, 1.3366, 1.3271, 1.3075, 1.2466,
         2.1901, 2.2635, 2.3779, 2.3062, 2.0817, 2.1556, 2.2192, 2.0726, 2.0726,
         1.3485, 1.3259, 1.2991, 1.3244, 1.3497, 1.3106, 1.3246, 1.3064, 1.3018,
         1.3978, 1.4290, 1.4201, 1.3924, 1.4065, 1.3991, 1.4033, 1.3043, 1.3406,
         1.3457, 1.3456, 1.3374, 1.3176, 1.2975, 1.3427, 1.3760, 1.3179, 1.3256],
        [1.2866, 1.3137, 1.2663, 1.2424, 1.3175, 1.2914, 1.2991, 1.2844, 1.2844,
         1.3465, 1.2709, 1.3615, 1.3286, 1.3349, 1.3143, 1.3447, 1.3380, 1.0900,
         1.3321, 1.3078, 1.3707, 1.3424, 1.3077, 1.2649, 1.3231, 1.2964, 1.2964,
         2.5927, 2.1482, 1.9328, 2.0393, 2.5710, 1.9399, 2.5240, 1.9517, 1.9323,
         1.4147, 1.4443, 1.3897, 1.3827, 1.4231, 1.3831, 1.4123, 1.1832, 1.3735,
         1.4133, 1.3116, 1.2256, 1.2862, 1.4099, 1.2400, 1.4445, 1.2874, 1.3428],
        [1.7134, 1.3739, 0.5869, 0.8150, 1.1742, 1.5933, 1.5244, 1.7112, 1.7112,
         1.6129, 1.3692, 1.4281, 0.9578, 1.7083, 0.2248, 1.5940, 1.7261, 1.2711,
         1.3051, 0.8641, 0.7433, 1.0790, 1.5678, 1.6705, 1.3183, 1.7208, 1.7208,
         0.7255, 0.8063, 1.6969, 1.4517, 0.8525, 1.6664, 1.1601, 1.7428, 1.6848,
         0.7782, 0.5407, 0.4881, 0.7221, 1.0810, 1.2928, 0.6687, 6.4670, 5.6135,
         0.7668, 1.2745, 1.3571, 1.6179, 1.0144, 1.5954, 0.4046, 1.6253, 1.7642],
        [1.3466, 1.3730, 1.4290, 1.4070, 1.3782, 1.3516, 1.3147, 1.3445, 1.3445,
         1.3105, 1.3884, 1.3057, 1.4283, 1.3923, 1.4720, 1.3089, 1.3957, 1.3188,
         1.3904, 1.4167, 1.4294, 1.4001, 1.3665, 1.3574, 1.3265, 1.3553, 1.3553,
         1.3919, 1.4480, 1.3751, 1.2218, 1.3020, 1.2089, 1.3985, 1.2539, 1.3776,
         1.4744, 1.2174, 1.4962, 1.4824, 1.1124, 1.0246, 1.4796, 1.4232, 0.9077,
         2.5848, 2.2003, 2.5720, 2.4252, 1.8942, 1.6611, 2.4827, 2.3917, 1.6471]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 99 : 182.70015772335032
Test loss for epoch 99 : 182.7134022918944
Test Precision for epoch 99 : 0.26153846153846155
Test Recall for epoch 99 : 0.26153846153846155
Test F1 for epoch 99 : 0.26153846153846155


theta for epoch 100 : tensor([[2.1496, 2.1717, 2.2347, 2.2976, 2.2636, 2.1530, 2.2477, 2.1477, 2.1477,
         1.3222, 1.3311, 1.3372, 1.3462, 1.3110, 1.3885, 1.3206, 1.3145, 1.2869,
         1.3069, 1.2898, 1.3037, 1.3173, 1.2832, 1.2749, 1.2987, 1.2719, 1.2719,
         1.3092, 1.3651, 1.2943, 1.3181, 1.3556, 1.3048, 1.3171, 1.2577, 1.2968,
         1.3929, 1.4240, 1.4147, 1.4014, 1.4024, 1.3455, 1.3978, 1.4028, 1.3533,
         1.3879, 1.3391, 1.3311, 1.3119, 1.3837, 1.3358, 1.4174, 1.3120, 1.3197],
        [1.3429, 1.2285, 1.0504, 1.2759, 1.3438, 1.3927, 1.3135, 1.3859, 1.3859,
         1.6043, 1.8351, 1.5644, 2.3712, 1.6155, 3.7482, 1.6930, 1.5112, 3.4345,
         1.1802, 1.2488, 1.0073, 1.2250, 1.3633, 1.3987, 1.3745, 1.3971, 1.3971,
         1.3439, 1.1011, 1.4177, 1.3915, 1.1690, 1.4291, 1.4339, 1.3848, 1.3888,
         1.4200, 1.5451, 1.4885, 1.4166, 1.3943, 1.5052, 1.4725, 0.6175, 1.4491,
         1.0680, 1.4610, 1.4489, 1.4339, 1.1139, 1.4562, 0.8869, 1.4344, 1.4422],
        [1.2681, 1.2946, 1.3514, 1.3288, 1.2980, 1.2729, 1.2802, 1.2660, 1.2660,
         1.3287, 1.3385, 1.3438, 1.3519, 1.3174, 1.3366, 1.3270, 1.3074, 1.2463,
         2.1950, 2.2672, 2.3814, 2.3103, 2.0866, 2.1609, 2.2232, 2.0775, 2.0775,
         1.3483, 1.3256, 1.2987, 1.3240, 1.3495, 1.3102, 1.3242, 1.3060, 1.3014,
         1.3975, 1.4286, 1.4197, 1.3922, 1.4064, 1.3988, 1.4029, 1.3038, 1.3400,
         1.3450, 1.3448, 1.3366, 1.3169, 1.2966, 1.3418, 1.3753, 1.3170, 1.3248],
        [1.2862, 1.3133, 1.2663, 1.2423, 1.3171, 1.2911, 1.2987, 1.2840, 1.2840,
         1.3462, 1.2708, 1.3612, 1.3286, 1.3346, 1.3140, 1.3444, 1.3377, 1.0907,
         1.3317, 1.3077, 1.3703, 1.3420, 1.3073, 1.2646, 1.3227, 1.2960, 1.2960,
         2.5965, 2.1532, 1.9371, 2.0433, 2.5752, 1.9444, 2.5281, 1.9559, 1.9367,
         1.4145, 1.4440, 1.3897, 1.3827, 1.4231, 1.3835, 1.4121, 1.1833, 1.3727,
         1.4126, 1.3115, 1.2252, 1.2858, 1.4091, 1.2399, 1.4437, 1.2867, 1.3421],
        [1.7151, 1.3751, 0.5887, 0.8166, 1.1759, 1.5950, 1.5262, 1.7129, 1.7129,
         1.6141, 1.3699, 1.4294, 0.9590, 1.7101, 0.2269, 1.5954, 1.7278, 1.2724,
         1.3070, 0.8659, 0.7448, 1.0809, 1.5695, 1.6720, 1.3202, 1.7225, 1.7225,
         0.7268, 0.8081, 1.6987, 1.4539, 0.8522, 1.6664, 1.1613, 1.7447, 1.6865,
         0.7720, 0.5357, 0.4835, 0.7164, 1.0712, 1.2809, 0.6633, 6.5207, 5.6515,
         0.7676, 1.2749, 1.3578, 1.6177, 1.0159, 1.5964, 0.4056, 1.6269, 1.7655],
        [1.3460, 1.3726, 1.4289, 1.4067, 1.3777, 1.3510, 1.3142, 1.3439, 1.3439,
         1.3104, 1.3893, 1.3064, 1.4281, 1.3921, 1.4716, 1.3088, 1.3956, 1.3185,
         1.3900, 1.4163, 1.4289, 1.3996, 1.3660, 1.3569, 1.3259, 1.3548, 1.3548,
         1.3918, 1.4477, 1.3751, 1.2214, 1.3037, 1.2106, 1.3984, 1.2538, 1.3777,
         1.4739, 1.2167, 1.4956, 1.4820, 1.1119, 1.0239, 1.4790, 1.4248, 0.9077,
         2.5890, 2.2039, 2.5783, 2.4286, 1.8987, 1.6645, 2.4864, 2.3983, 1.6504]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 100 : 182.683976834857
Test loss for epoch 100 : 182.69751385154893
Test Precision for epoch 100 : 0.26153846153846155
Test Recall for epoch 100 : 0.26153846153846155
Test F1 for epoch 100 : 0.26153846153846155


theta for epoch 101 : tensor([[2.1539, 2.1761, 2.2392, 2.3022, 2.2683, 2.1574, 2.2525, 2.1520, 2.1520,
         1.3220, 1.3308, 1.3368, 1.3460, 1.3107, 1.3882, 1.3203, 1.3142, 1.2864,
         1.3065, 1.2895, 1.3036, 1.3170, 1.2827, 1.2743, 1.2983, 1.2713, 1.2713,
         1.3087, 1.3646, 1.2939, 1.3177, 1.3551, 1.3044, 1.3167, 1.2572, 1.2964,
         1.3927, 1.4237, 1.4144, 1.4011, 1.4023, 1.3453, 1.3975, 1.4018, 1.3523,
         1.3877, 1.3389, 1.3308, 1.3116, 1.3835, 1.3354, 1.4173, 1.3115, 1.3192],
        [1.3421, 1.2282, 1.0497, 1.2751, 1.3432, 1.3920, 1.3127, 1.3851, 1.3851,
         1.6055, 1.8366, 1.5671, 2.3722, 1.6177, 3.7625, 1.6948, 1.5138, 3.4497,
         1.1793, 1.2481, 1.0075, 1.2243, 1.3627, 1.3981, 1.3738, 1.3964, 1.3964,
         1.3431, 1.1004, 1.4170, 1.3908, 1.1692, 1.4284, 1.4332, 1.3840, 1.3883,
         1.4197, 1.5447, 1.4879, 1.4160, 1.3938, 1.5049, 1.4721, 0.6170, 1.4487,
         1.0676, 1.4606, 1.4484, 1.4336, 1.1131, 1.4556, 0.8870, 1.4339, 1.4417],
        [1.2674, 1.2940, 1.3510, 1.3282, 1.2973, 1.2723, 1.2795, 1.2653, 1.2653,
         1.3285, 1.3383, 1.3434, 1.3516, 1.3171, 1.3364, 1.3268, 1.3072, 1.2458,
         2.1999, 2.2709, 2.3849, 2.3144, 2.0915, 2.1661, 2.2272, 2.0825, 2.0825,
         1.3479, 1.3250, 1.2981, 1.3233, 1.3491, 1.3095, 1.3235, 1.3054, 1.3008,
         1.3973, 1.4283, 1.4193, 1.3920, 1.4063, 1.3987, 1.4026, 1.3034, 1.3396,
         1.3448, 1.3446, 1.3363, 1.3166, 1.2961, 1.3414, 1.3750, 1.3165, 1.3243],
        [1.2856, 1.3127, 1.2661, 1.2421, 1.3165, 1.2905, 1.2981, 1.2835, 1.2835,
         1.3458, 1.2707, 1.3607, 1.3286, 1.3342, 1.3135, 1.3440, 1.3372, 1.0913,
         1.3312, 1.3076, 1.3700, 1.3415, 1.3068, 1.2643, 1.3221, 1.2954, 1.2954,
         2.6003, 2.1582, 1.9415, 2.0474, 2.5795, 1.9489, 2.5322, 1.9602, 1.9412,
         1.4142, 1.4438, 1.3897, 1.3827, 1.4231, 1.3839, 1.4120, 1.1834, 1.3718,
         1.4121, 1.3115, 1.2251, 1.2856, 1.4085, 1.2399, 1.4432, 1.2862, 1.3417],
        [1.7168, 1.3764, 0.5907, 0.8184, 1.1776, 1.5969, 1.5281, 1.7146, 1.7146,
         1.6154, 1.3707, 1.4309, 0.9603, 1.7121, 0.2293, 1.5968, 1.7296, 1.2738,
         1.3091, 0.8680, 0.7466, 1.0831, 1.5714, 1.6736, 1.3224, 1.7243, 1.7243,
         0.7281, 0.8101, 1.7005, 1.4560, 0.8520, 1.6664, 1.1624, 1.7466, 1.6882,
         0.7658, 0.5304, 0.4786, 0.7106, 1.0613, 1.2689, 0.6578, 6.5740, 5.6887,
         0.7691, 1.2759, 1.3590, 1.6179, 1.0180, 1.5980, 0.4073, 1.6291, 1.7673],
        [1.3452, 1.3720, 1.4287, 1.4063, 1.3770, 1.3501, 1.3134, 1.3431, 1.3431,
         1.3102, 1.3900, 1.3070, 1.4279, 1.3919, 1.4712, 1.3085, 1.3953, 1.3181,
         1.3897, 1.4160, 1.4285, 1.3992, 1.3656, 1.3564, 1.3253, 1.3543, 1.3543,
         1.3914, 1.4472, 1.3749, 1.2206, 1.3051, 1.2119, 1.3981, 1.2533, 1.3774,
         1.4735, 1.2161, 1.4950, 1.4816, 1.1114, 1.0233, 1.4785, 1.4264, 0.9078,
         2.5933, 2.2077, 2.5847, 2.4321, 1.9032, 1.6680, 2.4903, 2.4050, 1.6539]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 101 : 182.66800164421755
Test loss for epoch 101 : 182.68180516595515
Test Precision for epoch 101 : 0.26153846153846155
Test Recall for epoch 101 : 0.26153846153846155
Test F1 for epoch 101 : 0.26153846153846155


theta for epoch 102 : tensor([[2.1583, 2.1805, 2.2437, 2.3069, 2.2731, 2.1618, 2.2572, 2.1564, 2.1564,
         1.3213, 1.3301, 1.3360, 1.3453, 1.3100, 1.3876, 1.3196, 1.3134, 1.2855,
         1.3060, 1.2891, 1.3034, 1.3166, 1.2821, 1.2737, 1.2978, 1.2707, 1.2707,
         1.3081, 1.3639, 1.2933, 1.3171, 1.3544, 1.3039, 1.3160, 1.2565, 1.2957,
         1.3928, 1.4237, 1.4144, 1.4011, 1.4024, 1.3453, 1.3975, 1.4010, 1.3516,
         1.3879, 1.3389, 1.3307, 1.3115, 1.3835, 1.3352, 1.4175, 1.3113, 1.3190],
        [1.3413, 1.2280, 1.0491, 1.2744, 1.3426, 1.3913, 1.3119, 1.3844, 1.3844,
         1.6065, 1.8378, 1.5697, 2.3730, 1.6198, 3.7766, 1.6965, 1.5161, 3.4647,
         1.1783, 1.2474, 1.0077, 1.2236, 1.3620, 1.3974, 1.3731, 1.3957, 1.3957,
         1.3423, 1.0996, 1.4163, 1.3900, 1.1692, 1.4276, 1.4324, 1.3831, 1.3878,
         1.4196, 1.5446, 1.4877, 1.4156, 1.3937, 1.5049, 1.4718, 0.6168, 1.4486,
         1.0674, 1.4605, 1.4483, 1.4336, 1.1127, 1.4554, 0.8874, 1.4337, 1.4415],
        [1.2668, 1.2935, 1.3507, 1.3278, 1.2968, 1.2717, 1.2788, 1.2647, 1.2647,
         1.3279, 1.3377, 1.3426, 1.3510, 1.3164, 1.3358, 1.3261, 1.3066, 1.2450,
         2.2046, 2.2745, 2.3884, 2.3185, 2.0963, 2.1713, 2.2311, 2.0873, 2.0873,
         1.3474, 1.3243, 1.2975, 1.3225, 1.3486, 1.3088, 1.3228, 1.3046, 1.3001,
         1.3973, 1.4283, 1.4192, 1.3921, 1.4066, 1.3988, 1.4026, 1.3032, 1.3394,
         1.3449, 1.3447, 1.3363, 1.3167, 1.2960, 1.3413, 1.3751, 1.3164, 1.3242],
        [1.2849, 1.3119, 1.2657, 1.2417, 1.3157, 1.2898, 1.2973, 1.2827, 1.2827,
         1.3450, 1.2700, 1.3598, 1.3280, 1.3333, 1.3126, 1.3432, 1.3363, 1.0913,
         1.3304, 1.3073, 1.3694, 1.3409, 1.3060, 1.2637, 1.3214, 1.2947, 1.2947,
         2.6044, 2.1634, 1.9460, 2.0517, 2.5839, 1.9536, 2.5365, 1.9647, 1.9459,
         1.4142, 1.4438, 1.3899, 1.3828, 1.4232, 1.3845, 1.4119, 1.1836, 1.3710,
         1.4117, 1.3116, 1.2250, 1.2854, 1.4080, 1.2401, 1.4427, 1.2858, 1.3413],
        [1.7186, 1.3777, 0.5926, 0.8202, 1.1794, 1.5987, 1.5301, 1.7164, 1.7164,
         1.6164, 1.3712, 1.4321, 0.9614, 1.7137, 0.2315, 1.5980, 1.7311, 1.2749,
         1.3112, 0.8700, 0.7484, 1.0853, 1.5732, 1.6753, 1.3245, 1.7261, 1.7261,
         0.7293, 0.8120, 1.7022, 1.4579, 0.8517, 1.6662, 1.1633, 1.7483, 1.6897,
         0.7596, 0.5252, 0.4739, 0.7049, 1.0516, 1.2571, 0.6523, 6.6271, 5.7257,
         0.7707, 1.2770, 1.3604, 1.6184, 1.0203, 1.5997, 0.4093, 1.6314, 1.7693],
        [1.3444, 1.3713, 1.4284, 1.4058, 1.3763, 1.3492, 1.3126, 1.3422, 1.3422,
         1.3095, 1.3903, 1.3071, 1.4272, 1.3912, 1.4703, 1.3078, 1.3946, 1.3173,
         1.3893, 1.4156, 1.4281, 1.3987, 1.3650, 1.3558, 1.3246, 1.3537, 1.3537,
         1.3908, 1.4465, 1.3744, 1.2195, 1.3063, 1.2130, 1.3975, 1.2527, 1.3769,
         1.4734, 1.2157, 1.4948, 1.4814, 1.1111, 1.0229, 1.4783, 1.4283, 0.9081,
         2.5978, 2.2116, 2.5913, 2.4357, 1.9079, 1.6717, 2.4944, 2.4120, 1.6576]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 102 : 182.65225068763073
Test loss for epoch 102 : 182.6661782210062
Test Precision for epoch 102 : 0.26153846153846155
Test Recall for epoch 102 : 0.26153846153846155
Test F1 for epoch 102 : 0.26153846153846155


theta for epoch 103 : tensor([[2.1626, 2.1850, 2.2483, 2.3117, 2.2779, 2.1663, 2.2620, 2.1608, 2.1608,
         1.3205, 1.3293, 1.3350, 1.3445, 1.3090, 1.3869, 1.3187, 1.3125, 1.2846,
         1.3055, 1.2888, 1.3032, 1.3162, 1.2815, 1.2731, 1.2973, 1.2701, 1.2701,
         1.3075, 1.3633, 1.2926, 1.3165, 1.3538, 1.3033, 1.3154, 1.2558, 1.2951,
         1.3931, 1.4239, 1.4146, 1.4013, 1.4028, 1.3455, 1.3977, 1.4004, 1.3511,
         1.3877, 1.3386, 1.3303, 1.3111, 1.3833, 1.3347, 1.4175, 1.3107, 1.3184],
        [1.3408, 1.2281, 1.0489, 1.2741, 1.3424, 1.3909, 1.3114, 1.3839, 1.3839,
         1.6073, 1.8390, 1.5719, 2.3736, 1.6217, 3.7904, 1.6980, 1.5182, 3.4794,
         1.1776, 1.2469, 1.0081, 1.2230, 1.3615, 1.3969, 1.3725, 1.3952, 1.3952,
         1.3416, 1.0989, 1.4156, 1.3894, 1.1694, 1.4269, 1.4317, 1.3823, 1.3874,
         1.4198, 1.5448, 1.4877, 1.4156, 1.3939, 1.5051, 1.4719, 0.6169, 1.4488,
         1.0672, 1.4603, 1.4480, 1.4335, 1.1123, 1.4551, 0.8878, 1.4333, 1.4412],
        [1.2663, 1.2931, 1.3505, 1.3274, 1.2963, 1.2712, 1.2782, 1.2642, 1.2642,
         1.3271, 1.3369, 1.3417, 1.3503, 1.3156, 1.3351, 1.3253, 1.3057, 1.2441,
         2.2094, 2.2782, 2.3920, 2.3226, 2.1011, 2.1764, 2.2351, 2.0921, 2.0921,
         1.3469, 1.3237, 1.2968, 1.3217, 1.3482, 1.3081, 1.3220, 1.3039, 1.2994,
         1.3976, 1.4285, 1.4194, 1.3924, 1.4070, 1.3991, 1.4027, 1.3031, 1.3394,
         1.3447, 1.3444, 1.3360, 1.3164, 1.2956, 1.3408, 1.3749, 1.3159, 1.3237],
        [1.2841, 1.3111, 1.2653, 1.2413, 1.3149, 1.2890, 1.2965, 1.2819, 1.2819,
         1.3439, 1.2692, 1.3586, 1.3273, 1.3321, 1.3116, 1.3421, 1.3352, 1.0912,
         1.3296, 1.3068, 1.3687, 1.3400, 1.3051, 1.2630, 1.3204, 1.2937, 1.2937,
         2.6086, 2.1689, 1.9508, 2.0562, 2.5885, 1.9585, 2.5410, 1.9694, 1.9508,
         1.4142, 1.4438, 1.3902, 1.3831, 1.4234, 1.3851, 1.4120, 1.1838, 1.3704,
         1.4110, 1.3114, 1.2246, 1.2849, 1.4072, 1.2398, 1.4420, 1.2851, 1.3406],
        [1.7203, 1.3789, 0.5944, 0.8219, 1.1810, 1.6006, 1.5320, 1.7181, 1.7181,
         1.6171, 1.3714, 1.4330, 0.9622, 1.7152, 0.2333, 1.5989, 1.7324, 1.2757,
         1.3131, 0.8717, 0.7500, 1.0872, 1.5749, 1.6768, 1.3264, 1.7278, 1.7278,
         0.7303, 0.8137, 1.7037, 1.4597, 0.8513, 1.6659, 1.1639, 1.7499, 1.6910,
         0.7538, 0.5201, 0.4693, 0.6995, 1.0424, 1.2458, 0.6472, 6.6802, 5.7624,
         0.7719, 1.2777, 1.3614, 1.6186, 1.0221, 1.6011, 0.4107, 1.6334, 1.7709],
        [1.3438, 1.3709, 1.4283, 1.4056, 1.3758, 1.3486, 1.3121, 1.3416, 1.3416,
         1.3087, 1.3905, 1.3071, 1.4265, 1.3904, 1.4693, 1.3070, 1.3939, 1.3164,
         1.3890, 1.4153, 1.4277, 1.3983, 1.3645, 1.3553, 1.3240, 1.3532, 1.3532,
         1.3904, 1.4458, 1.3740, 1.2186, 1.3076, 1.2141, 1.3970, 1.2521, 1.3764,
         1.4735, 1.2156, 1.4948, 1.4815, 1.1112, 1.0228, 1.4784, 1.4303, 0.9086,
         2.6019, 2.2151, 2.5976, 2.4389, 1.9121, 1.6751, 2.4981, 2.4186, 1.6610]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 103 : 182.63673823169205
Test loss for epoch 103 : 182.6509776221335
Test Precision for epoch 103 : 0.26153846153846155
Test Recall for epoch 103 : 0.26153846153846155
Test F1 for epoch 103 : 0.26153846153846155


theta for epoch 104 : tensor([[2.1668, 2.1892, 2.2527, 2.3162, 2.2825, 2.1705, 2.2666, 2.1649, 2.1649,
         1.3201, 1.3290, 1.3346, 1.3443, 1.3086, 1.3867, 1.3184, 1.3121, 1.2841,
         1.3050, 1.2885, 1.3031, 1.3159, 1.2810, 1.2726, 1.2969, 1.2695, 1.2695,
         1.3070, 1.3628, 1.2920, 1.3159, 1.3534, 1.3028, 1.3149, 1.2551, 1.2945,
         1.3933, 1.4240, 1.4147, 1.4014, 1.4031, 1.3456, 1.3979, 1.3997, 1.3505,
         1.3873, 1.3381, 1.3298, 1.3105, 1.3828, 1.3339, 1.4172, 1.3099, 1.3176],
        [1.3402, 1.2282, 1.0487, 1.2737, 1.3421, 1.3904, 1.3109, 1.3834, 1.3834,
         1.6083, 1.8403, 1.5743, 2.3742, 1.6237, 3.8043, 1.6995, 1.5204, 3.4943,
         1.1768, 1.2464, 1.0085, 1.2225, 1.3610, 1.3963, 1.3720, 1.3947, 1.3947,
         1.3410, 1.0984, 1.4150, 1.3888, 1.1696, 1.4262, 1.4311, 1.3816, 1.3870,
         1.4200, 1.5449, 1.4876, 1.4154, 1.3941, 1.5053, 1.4719, 0.6169, 1.4489,
         1.0668, 1.4599, 1.4475, 1.4331, 1.1116, 1.4544, 0.8879, 1.4327, 1.4406],
        [1.2657, 1.2926, 1.3503, 1.3270, 1.2958, 1.2706, 1.2776, 1.2636, 1.2636,
         1.3266, 1.3364, 1.3411, 1.3499, 1.3150, 1.3347, 1.3248, 1.3052, 1.2434,
         2.2143, 2.2820, 2.3958, 2.3268, 2.1060, 2.1816, 2.2392, 2.0969, 2.0969,
         1.3465, 1.3230, 1.2961, 1.3210, 1.3477, 1.3074, 1.3214, 1.3032, 1.2987,
         1.3977, 1.4286, 1.4193, 1.3925, 1.4073, 1.3992, 1.4028, 1.3029, 1.3392,
         1.3442, 1.3438, 1.3353, 1.3157, 1.2949, 1.3399, 1.3743, 1.3150, 1.3228],
        [1.2834, 1.3104, 1.2650, 1.2410, 1.3142, 1.2883, 1.2958, 1.2812, 1.2812,
         1.3432, 1.2688, 1.3579, 1.3270, 1.3314, 1.3109, 1.3414, 1.3344, 1.0914,
         1.3288, 1.3064, 1.3680, 1.3393, 1.3042, 1.2623, 1.3196, 1.2929, 1.2929,
         2.6127, 2.1743, 1.9555, 2.0607, 2.5931, 1.9633, 2.5454, 1.9740, 1.9557,
         1.4141, 1.4438, 1.3905, 1.3833, 1.4236, 1.3856, 1.4120, 1.1838, 1.3696,
         1.4102, 1.3110, 1.2241, 1.2842, 1.4062, 1.2395, 1.4411, 1.2842, 1.3398],
        [1.7220, 1.3801, 0.5961, 0.8234, 1.1824, 1.6023, 1.5338, 1.7197, 1.7197,
         1.6181, 1.3718, 1.4341, 0.9631, 1.7168, 0.2353, 1.6001, 1.7339, 1.2766,
         1.3149, 0.8733, 0.7515, 1.0891, 1.5765, 1.6782, 1.3281, 1.7294, 1.7294,
         0.7313, 0.8153, 1.7052, 1.4614, 0.8508, 1.6657, 1.1645, 1.7514, 1.6923,
         0.7481, 0.5151, 0.4647, 0.6942, 1.0334, 1.2347, 0.6421, 6.7331, 5.7988,
         0.7729, 1.2782, 1.3620, 1.6185, 1.0236, 1.6021, 0.4120, 1.6350, 1.7723],
        [1.3431, 1.3702, 1.4280, 1.4052, 1.3752, 1.3477, 1.3114, 1.3408, 1.3408,
         1.3082, 1.3910, 1.3073, 1.4260, 1.3899, 1.4686, 1.3064, 1.3934, 1.3158,
         1.3884, 1.4149, 1.4272, 1.3976, 1.3638, 1.3546, 1.3232, 1.3524, 1.3524,
         1.3899, 1.4451, 1.3734, 1.2175, 1.3088, 1.2151, 1.3965, 1.2513, 1.3759,
         1.4734, 1.2153, 1.4947, 1.4814, 1.1109, 1.0224, 1.4782, 1.4321, 0.9089,
         2.6063, 2.2188, 2.6040, 2.4422, 1.9165, 1.6786, 2.5020, 2.4255, 1.6645]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 104 : 182.62148028462164
Test loss for epoch 104 : 182.6360041709918
Test Precision for epoch 104 : 0.26153846153846155
Test Recall for epoch 104 : 0.26153846153846155
Test F1 for epoch 104 : 0.26153846153846155


theta for epoch 105 : tensor([[2.1711, 2.1937, 2.2572, 2.3209, 2.2873, 2.1749, 2.2713, 2.1692, 2.1692,
         1.3201, 1.3290, 1.3344, 1.3444, 1.3084, 1.3869, 1.3183, 1.3119, 1.2840,
         1.3045, 1.2882, 1.3028, 1.3155, 1.2804, 1.2720, 1.2964, 1.2689, 1.2689,
         1.3066, 1.3624, 1.2914, 1.3154, 1.3529, 1.3023, 1.3144, 1.2545, 1.2938,
         1.3931, 1.4237, 1.4144, 1.4011, 1.4029, 1.3453, 1.3976, 1.3986, 1.3494,
         1.3868, 1.3375, 1.3291, 1.3098, 1.3822, 1.3331, 1.4168, 1.3090, 1.3167],
        [1.3397, 1.2282, 1.0485, 1.2734, 1.3419, 1.3900, 1.3103, 1.3830, 1.3830,
         1.6094, 1.8418, 1.5768, 2.3751, 1.6259, 3.8182, 1.7012, 1.5227, 3.5092,
         1.1760, 1.2458, 1.0089, 1.2219, 1.3604, 1.3957, 1.3714, 1.3941, 1.3941,
         1.3404, 1.0979, 1.4145, 1.3883, 1.1698, 1.4257, 1.4305, 1.3809, 1.3867,
         1.4198, 1.5446, 1.4872, 1.4149, 1.3939, 1.5051, 1.4715, 0.6166, 1.4488,
         1.0664, 1.4594, 1.4470, 1.4327, 1.1109, 1.4538, 0.8881, 1.4321, 1.4400],
        [1.2652, 1.2921, 1.3501, 1.3267, 1.2953, 1.2700, 1.2769, 1.2630, 1.2630,
         1.3264, 1.3363, 1.3408, 1.3498, 1.3147, 1.3345, 1.3246, 1.3050, 1.2432,
         2.2192, 2.2859, 2.3996, 2.3311, 2.1109, 2.1868, 2.2433, 2.1018, 2.1018,
         1.3461, 1.3224, 1.2955, 1.3203, 1.3473, 1.3067, 1.3207, 1.3026, 1.2981,
         1.3975, 1.4283, 1.4190, 1.3923, 1.4072, 1.3990, 1.4025, 1.3023, 1.3387,
         1.3436, 1.3432, 1.3347, 1.3150, 1.2941, 1.3391, 1.3737, 1.3141, 1.3219],
        [1.2828, 1.3099, 1.2650, 1.2409, 1.3137, 1.2877, 1.2953, 1.2807, 1.2807,
         1.3429, 1.2688, 1.3575, 1.3272, 1.3311, 1.3107, 1.3411, 1.3341, 1.0920,
         1.3281, 1.3062, 1.3676, 1.3387, 1.3035, 1.2618, 1.3189, 1.2921, 1.2921,
         2.6166, 2.1794, 1.9600, 2.0650, 2.5974, 1.9679, 2.5497, 1.9784, 1.9603,
         1.4139, 1.4435, 1.3906, 1.3833, 1.4235, 1.3859, 1.4119, 1.1837, 1.3686,
         1.4096, 1.3109, 1.2237, 1.2838, 1.4055, 1.2393, 1.4405, 1.2835, 1.3391],
        [1.7237, 1.3813, 0.5978, 0.8249, 1.1839, 1.6041, 1.5356, 1.7214, 1.7214,
         1.6193, 1.3725, 1.4355, 0.9642, 1.7186, 0.2375, 1.6015, 1.7357, 1.2777,
         1.3167, 0.8748, 0.7530, 1.0909, 1.5781, 1.6796, 1.3299, 1.7310, 1.7310,
         0.7324, 0.8170, 1.7067, 1.4632, 0.8504, 1.6655, 1.1651, 1.7530, 1.6937,
         0.7423, 0.5099, 0.4600, 0.6887, 1.0244, 1.2236, 0.6368, 6.7857, 5.8346,
         0.7739, 1.2787, 1.3627, 1.6185, 1.0252, 1.6031, 0.4133, 1.6367, 1.7738],
        [1.3420, 1.3694, 1.4274, 1.4045, 1.3743, 1.3466, 1.3104, 1.3397, 1.3397,
         1.3078, 1.3916, 1.3077, 1.4258, 1.3896, 1.4682, 1.3060, 1.3930, 1.3154,
         1.3875, 1.4140, 1.4263, 1.3967, 1.3628, 1.3535, 1.3220, 1.3514, 1.3514,
         1.3893, 1.4442, 1.3727, 1.2163, 1.3098, 1.2159, 1.3959, 1.2504, 1.3751,
         1.4728, 1.2145, 1.4940, 1.4808, 1.1100, 1.0214, 1.4776, 1.4333, 0.9085,
         2.6112, 2.2230, 2.6109, 2.4460, 1.9214, 1.6827, 2.5064, 2.4330, 1.6686]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 105 : 182.60638682071857
Test loss for epoch 105 : 182.62089173472697
Test Precision for epoch 105 : 0.26153846153846155
Test Recall for epoch 105 : 0.26153846153846155
Test F1 for epoch 105 : 0.26153846153846155


theta for epoch 106 : tensor([[2.1757, 2.1984, 2.2620, 2.3259, 2.2924, 2.1795, 2.2763, 2.1738, 2.1738,
         1.3199, 1.3288, 1.3341, 1.3443, 1.3081, 1.3869, 1.3180, 1.3116, 1.2837,
         1.3040, 1.2877, 1.3024, 1.3150, 1.2797, 1.2713, 1.2958, 1.2682, 1.2682,
         1.3064, 1.3621, 1.2909, 1.3150, 1.3526, 1.3019, 1.3140, 1.2539, 1.2933,
         1.3926, 1.4232, 1.4139, 1.4005, 1.4025, 1.3448, 1.3971, 1.3972, 1.3482,
         1.3862, 1.3369, 1.3284, 1.3090, 1.3816, 1.3322, 1.4164, 1.3080, 1.3157],
        [1.3392, 1.2283, 1.0484, 1.2731, 1.3417, 1.3896, 1.3099, 1.3825, 1.3825,
         1.6105, 1.8433, 1.5792, 2.3759, 1.6280, 3.8321, 1.7028, 1.5250, 3.5242,
         1.1754, 1.2454, 1.0093, 1.2214, 1.3599, 1.3953, 1.3709, 1.3936, 1.3936,
         1.3401, 1.0976, 1.4141, 1.3880, 1.1702, 1.4253, 1.4301, 1.3804, 1.3866,
         1.4196, 1.5442, 1.4867, 1.4144, 1.3936, 1.5048, 1.4710, 0.6163, 1.4485,
         1.0661, 1.4591, 1.4466, 1.4324, 1.1104, 1.4533, 0.8883, 1.4316, 1.4395],
        [1.2645, 1.2916, 1.3498, 1.3263, 1.2948, 1.2694, 1.2763, 1.2623, 1.2623,
         1.3261, 1.3359, 1.3403, 1.3496, 1.3143, 1.3343, 1.3242, 1.3046, 1.2427,
         2.2242, 2.2899, 2.4035, 2.3355, 2.1158, 2.1921, 2.2475, 2.1067, 2.1067,
         1.3459, 1.3220, 1.2950, 1.3198, 1.3471, 1.3062, 1.3203, 1.3021, 1.2976,
         1.3971, 1.4279, 1.4185, 1.3920, 1.4069, 1.3987, 1.4020, 1.3015, 1.3380,
         1.3431, 1.3426, 1.3340, 1.3143, 1.2934, 1.3383, 1.3732, 1.3132, 1.3211],
        [1.2824, 1.3094, 1.2650, 1.2409, 1.3133, 1.2873, 1.2948, 1.2802, 1.2802,
         1.3426, 1.2687, 1.3571, 1.3273, 1.3307, 1.3105, 1.3408, 1.3337, 1.0926,
         1.3276, 1.3061, 1.3672, 1.3383, 1.3030, 1.2615, 1.3184, 1.2915, 1.2915,
         2.6205, 2.1847, 1.9645, 2.0694, 2.6017, 1.9726, 2.5539, 1.9829, 1.9650,
         1.4135, 1.4431, 1.3905, 1.3831, 1.4232, 1.3861, 1.4116, 1.1835, 1.3675,
         1.4091, 1.3108, 1.2234, 1.2834, 1.4048, 1.2392, 1.4399, 1.2828, 1.3385],
        [1.7254, 1.3824, 0.5994, 0.8264, 1.1853, 1.6059, 1.5374, 1.7231, 1.7231,
         1.6204, 1.3729, 1.4367, 0.9652, 1.7203, 0.2395, 1.6028, 1.7373, 1.2786,
         1.3184, 0.8763, 0.7545, 1.0926, 1.5796, 1.6810, 1.3315, 1.7326, 1.7326,
         0.7335, 0.8188, 1.7083, 1.4650, 0.8501, 1.6655, 1.1657, 1.7547, 1.6951,
         0.7366, 0.5048, 0.4553, 0.6833, 1.0156, 1.2128, 0.6316, 6.8382, 5.8701,
         0.7748, 1.2791, 1.3634, 1.6185, 1.0267, 1.6041, 0.4145, 1.6383, 1.7752],
        [1.3411, 1.3686, 1.4270, 1.4039, 1.3736, 1.3457, 1.3095, 1.3388, 1.3388,
         1.3074, 1.3922, 1.3080, 1.4255, 1.3892, 1.4677, 1.3056, 1.3927, 1.3150,
         1.3868, 1.4134, 1.4257, 1.3960, 1.3620, 1.3527, 1.3210, 1.3505, 1.3505,
         1.3890, 1.4436, 1.3722, 1.2153, 1.3111, 1.2168, 1.3955, 1.2497, 1.3747,
         1.4722, 1.2136, 1.4933, 1.4801, 1.1091, 1.0204, 1.4769, 1.4344, 0.9080,
         2.6158, 2.2270, 2.6177, 2.4496, 1.9260, 1.6866, 2.5105, 2.4402, 1.6725]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 106 : 182.59156412289153
Test loss for epoch 106 : 182.60609079218625
Test Precision for epoch 106 : 0.26153846153846155
Test Recall for epoch 106 : 0.26153846153846155
Test F1 for epoch 106 : 0.26153846153846155


theta for epoch 107 : tensor([[2.1801, 2.2028, 2.2666, 2.3307, 2.2973, 2.1839, 2.2810, 2.1782, 2.1782,
         1.3193, 1.3284, 1.3334, 1.3439, 1.3074, 1.3866, 1.3174, 1.3109, 1.2831,
         1.3035, 1.2874, 1.3021, 1.3146, 1.2792, 1.2707, 1.2953, 1.2676, 1.2676,
         1.3063, 1.3619, 1.2904, 1.3147, 1.3525, 1.3016, 1.3138, 1.2535, 1.2928,
         1.3923, 1.4229, 1.4136, 1.4002, 1.4023, 1.3445, 1.3968, 1.3960, 1.3471,
         1.3859, 1.3365, 1.3280, 1.3085, 1.3812, 1.3316, 1.4162, 1.3074, 1.3150],
        [1.3386, 1.2282, 1.0482, 1.2727, 1.3414, 1.3890, 1.3093, 1.3819, 1.3819,
         1.6116, 1.8448, 1.5816, 2.3766, 1.6301, 3.8459, 1.7043, 1.5272, 3.5390,
         1.1748, 1.2450, 1.0097, 1.2210, 1.3594, 1.3948, 1.3704, 1.3931, 1.3931,
         1.3398, 1.0974, 1.4138, 1.3877, 1.1706, 1.4250, 1.4299, 1.3800, 1.3865,
         1.4194, 1.5440, 1.4863, 1.4139, 1.3935, 1.5047, 1.4706, 0.6161, 1.4485,
         1.0659, 1.4589, 1.4464, 1.4322, 1.1100, 1.4529, 0.8885, 1.4312, 1.4391],
        [1.2638, 1.2909, 1.3494, 1.3257, 1.2942, 1.2686, 1.2755, 1.2615, 1.2615,
         1.3254, 1.3353, 1.3396, 1.3491, 1.3135, 1.3337, 1.3235, 1.3038, 1.2420,
         2.2292, 2.2940, 2.4075, 2.3400, 2.1207, 2.1974, 2.2518, 2.1117, 2.1117,
         1.3457, 1.3216, 1.2946, 1.3194, 1.3469, 1.3058, 1.3199, 1.3017, 1.2972,
         1.3968, 1.4276, 1.4182, 1.3918, 1.4068, 1.3985, 1.4017, 1.3008, 1.3374,
         1.3427, 1.3422, 1.3335, 1.3138, 1.2930, 1.3376, 1.3728, 1.3125, 1.3204],
        [1.2817, 1.3087, 1.2649, 1.2407, 1.3126, 1.2866, 1.2942, 1.2795, 1.2795,
         1.3420, 1.2684, 1.3563, 1.3271, 1.3300, 1.3099, 1.3401, 1.3330, 1.0929,
         1.3270, 1.3060, 1.3668, 1.3377, 1.3023, 1.2610, 1.3178, 1.2909, 1.2909,
         2.6246, 2.1901, 1.9693, 2.0740, 2.6062, 1.9775, 2.5582, 1.9876, 1.9699,
         1.4132, 1.4428, 1.3906, 1.3831, 1.4230, 1.3863, 1.4113, 1.1833, 1.3664,
         1.4086, 1.3108, 1.2232, 1.2830, 1.4042, 1.2391, 1.4394, 1.2822, 1.3379],
        [1.7268, 1.3833, 0.6006, 0.8275, 1.1863, 1.6073, 1.5389, 1.7245, 1.7245,
         1.6211, 1.3730, 1.4375, 0.9659, 1.7216, 0.2411, 1.6038, 1.7386, 1.2790,
         1.3200, 0.8775, 0.7557, 1.0942, 1.5811, 1.6823, 1.3330, 1.7341, 1.7341,
         0.7345, 0.8205, 1.7099, 1.4668, 0.8498, 1.6654, 1.1663, 1.7563, 1.6964,
         0.7312, 0.4998, 0.4509, 0.6782, 1.0073, 1.2024, 0.6267, 6.8906, 5.9055,
         0.7756, 1.2795, 1.3640, 1.6186, 1.0281, 1.6049, 0.4156, 1.6399, 1.7766],
        [1.3404, 1.3679, 1.4265, 1.4034, 1.3730, 1.3449, 1.3088, 1.3380, 1.3380,
         1.3069, 1.3926, 1.3081, 1.4251, 1.3887, 1.4671, 1.3050, 1.3921, 1.3145,
         1.3864, 1.4131, 1.4254, 1.3956, 1.3615, 1.3521, 1.3204, 1.3499, 1.3499,
         1.3889, 1.4433, 1.3720, 1.2146, 1.3126, 1.2181, 1.3954, 1.2493, 1.3744,
         1.4718, 1.2130, 1.4929, 1.4797, 1.1084, 1.0196, 1.4765, 1.4356, 0.9079,
         2.6201, 2.2306, 2.6240, 2.4527, 1.9302, 1.6901, 2.5143, 2.4472, 1.6760]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 107 : 182.57693805471507
Test loss for epoch 107 : 182.59172849755186
Test Precision for epoch 107 : 0.26153846153846155
Test Recall for epoch 107 : 0.26153846153846155
Test F1 for epoch 107 : 0.26153846153846155


theta for epoch 108 : tensor([[2.1844, 2.2072, 2.2711, 2.3354, 2.3021, 2.1883, 2.2857, 2.1825, 2.1825,
         1.3187, 1.3278, 1.3327, 1.3434, 1.3066, 1.3862, 1.3167, 1.3101, 1.2825,
         1.3030, 1.2870, 1.3016, 1.3142, 1.2786, 1.2701, 1.2948, 1.2669, 1.2669,
         1.3060, 1.3615, 1.2898, 1.3141, 1.3521, 1.3010, 1.3134, 1.2528, 1.2922,
         1.3922, 1.4228, 1.4135, 1.4000, 1.4022, 1.3444, 1.3967, 1.3950, 1.3463,
         1.3859, 1.3364, 1.3278, 1.3082, 1.3811, 1.3312, 1.4162, 1.3070, 1.3146],
        [1.3378, 1.2280, 1.0478, 1.2721, 1.3410, 1.3883, 1.3085, 1.3812, 1.3812,
         1.6128, 1.8464, 1.5841, 2.3775, 1.6323, 3.8598, 1.7059, 1.5295, 3.5540,
         1.1740, 1.2444, 1.0098, 1.2203, 1.3588, 1.3941, 1.3698, 1.3924, 1.3924,
         1.3393, 1.0970, 1.4132, 1.3872, 1.1708, 1.4244, 1.4294, 1.3794, 1.3862,
         1.4195, 1.5438, 1.4860, 1.4136, 1.3935, 1.5047, 1.4704, 0.6159, 1.4485,
         1.0658, 1.4588, 1.4463, 1.4321, 1.1096, 1.4526, 0.8888, 1.4309, 1.4388],
        [1.2631, 1.2904, 1.3490, 1.3253, 1.2937, 1.2680, 1.2748, 1.2609, 1.2609,
         1.3247, 1.3346, 1.3387, 1.3485, 1.3126, 1.3331, 1.3227, 1.3030, 1.2412,
         2.2340, 2.2980, 2.4114, 2.3443, 2.1255, 2.2024, 2.2559, 2.1164, 2.1164,
         1.3455, 1.3212, 1.2941, 1.3189, 1.3466, 1.3053, 1.3194, 1.3012, 1.2966,
         1.3968, 1.4275, 1.4181, 1.3918, 1.4069, 1.3985, 1.4016, 1.3003, 1.3371,
         1.3428, 1.3421, 1.3334, 1.3136, 1.2929, 1.3373, 1.3728, 1.3122, 1.3200],
        [1.2810, 1.3080, 1.2647, 1.2405, 1.3120, 1.2858, 1.2934, 1.2788, 1.2788,
         1.3412, 1.2678, 1.3554, 1.3268, 1.3291, 1.3093, 1.3393, 1.3321, 1.0930,
         1.3263, 1.3058, 1.3663, 1.3371, 1.3015, 1.2604, 1.3170, 1.2901, 1.2901,
         2.6287, 2.1955, 1.9740, 2.0786, 2.6107, 1.9823, 2.5626, 1.9922, 1.9747,
         1.4130, 1.4427, 1.3908, 1.3831, 1.4230, 1.3867, 1.4113, 1.1833, 1.3655,
         1.4082, 1.3109, 1.2231, 1.2828, 1.4038, 1.2391, 1.4390, 1.2817, 1.3374],
        [1.7282, 1.3842, 0.6019, 0.8286, 1.1873, 1.6088, 1.5403, 1.7259, 1.7259,
         1.6218, 1.3731, 1.4383, 0.9664, 1.7228, 0.2426, 1.6047, 1.7398, 1.2793,
         1.3215, 0.8787, 0.7570, 1.0957, 1.5825, 1.6835, 1.3344, 1.7356, 1.7356,
         0.7354, 0.8221, 1.7112, 1.4683, 0.8494, 1.6652, 1.1666, 1.7578, 1.6976,
         0.7259, 0.4949, 0.4464, 0.6732, 0.9992, 1.1923, 0.6218, 6.9428, 5.9404,
         0.7767, 1.2802, 1.3648, 1.6188, 1.0297, 1.6060, 0.4169, 1.6416, 1.7781],
        [1.3396, 1.3672, 1.4260, 1.4028, 1.3724, 1.3440, 1.3081, 1.3372, 1.3372,
         1.3061, 1.3928, 1.3081, 1.4245, 1.3879, 1.4664, 1.3042, 1.3914, 1.3138,
         1.3857, 1.4126, 1.4249, 1.3950, 1.3608, 1.3514, 1.3196, 1.3492, 1.3492,
         1.3887, 1.4427, 1.3715, 1.2137, 1.3139, 1.2190, 1.3951, 1.2486, 1.3739,
         1.4715, 1.2125, 1.4926, 1.4795, 1.1079, 1.0190, 1.4762, 1.4370, 0.9078,
         2.6245, 2.2344, 2.6306, 2.4559, 1.9345, 1.6937, 2.5182, 2.4543, 1.6796]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 108 : 182.56254230918967
Test loss for epoch 108 : 182.57762019472744
Test Precision for epoch 108 : 0.26153846153846155
Test Recall for epoch 108 : 0.26153846153846155
Test F1 for epoch 108 : 0.26153846153846155


theta for epoch 109 : tensor([[2.1889, 2.2119, 2.2759, 2.3404, 2.3071, 2.1929, 2.2907, 2.1870, 2.1870,
         1.3181, 1.3272, 1.3320, 1.3430, 1.3059, 1.3859, 1.3161, 1.3094, 1.2819,
         1.3024, 1.2865, 1.3011, 1.3136, 1.2779, 1.2694, 1.2942, 1.2663, 1.2663,
         1.3053, 1.3608, 1.2887, 1.3132, 1.3514, 1.3001, 1.3126, 1.2518, 1.2911,
         1.3921, 1.4227, 1.4134, 1.3999, 1.4022, 1.3443, 1.3967, 1.3941, 1.3455,
         1.3856, 1.3360, 1.3274, 1.3078, 1.3808, 1.3307, 1.4160, 1.3064, 1.3140],
        [1.3371, 1.2279, 1.0474, 1.2716, 1.3406, 1.3876, 1.3078, 1.3805, 1.3805,
         1.6142, 1.8484, 1.5867, 2.3786, 1.6347, 3.8739, 1.7078, 1.5319, 3.5692,
         1.1731, 1.2438, 1.0099, 1.2196, 1.3580, 1.3934, 1.3691, 1.3917, 1.3917,
         1.3386, 1.0962, 1.4124, 1.3865, 1.1706, 1.4236, 1.4287, 1.3785, 1.3856,
         1.4195, 1.5437, 1.4857, 1.4133, 1.3935, 1.5046, 1.4701, 0.6157, 1.4486,
         1.0655, 1.4585, 1.4459, 1.4318, 1.1091, 1.4521, 0.8888, 1.4304, 1.4382],
        [1.2627, 1.2900, 1.3488, 1.3250, 1.2934, 1.2675, 1.2743, 1.2604, 1.2604,
         1.3241, 1.3340, 1.3380, 1.3481, 1.3119, 1.3326, 1.3220, 1.3023, 1.2406,
         2.2389, 2.3020, 2.4154, 2.3488, 2.1302, 2.2075, 2.2601, 2.1211, 2.1211,
         1.3450, 1.3205, 1.2934, 1.3181, 1.3461, 1.3046, 1.3188, 1.3005, 1.2959,
         1.3968, 1.4275, 1.4181, 1.3918, 1.4070, 1.3986, 1.4016, 1.2999, 1.3368,
         1.3426, 1.3419, 1.3331, 1.3133, 1.2926, 1.3368, 1.3726, 1.3117, 1.3195],
        [1.2803, 1.3075, 1.2647, 1.2404, 1.3114, 1.2852, 1.2928, 1.2781, 1.2781,
         1.3405, 1.2675, 1.3546, 1.3266, 1.3283, 1.3087, 1.3386, 1.3313, 1.0933,
         1.3256, 1.3056, 1.3658, 1.3364, 1.3007, 1.2599, 1.3163, 1.2893, 1.2893,
         2.6328, 2.2009, 1.9788, 2.0832, 2.6151, 1.9872, 2.5670, 1.9969, 1.9796,
         1.4128, 1.4426, 1.3911, 1.3832, 1.4229, 1.3871, 1.4112, 1.1833, 1.3646,
         1.4078, 1.3109, 1.2228, 1.2824, 1.4032, 1.2390, 1.4386, 1.2811, 1.3368],
        [1.7299, 1.3854, 0.6036, 0.8301, 1.1887, 1.6106, 1.5421, 1.7276, 1.7276,
         1.6227, 1.3734, 1.4392, 0.9673, 1.7242, 0.2445, 1.6058, 1.7412, 1.2797,
         1.3232, 0.8801, 0.7584, 1.0973, 1.5840, 1.6848, 1.3360, 1.7371, 1.7371,
         0.7364, 0.8238, 1.7125, 1.4698, 0.8492, 1.6649, 1.1670, 1.7592, 1.6986,
         0.7205, 0.4899, 0.4418, 0.6681, 0.9912, 1.1822, 0.6167, 6.9946, 5.9747,
         0.7780, 1.2810, 1.3658, 1.6192, 1.0315, 1.6071, 0.4185, 1.6434, 1.7797],
        [1.3389, 1.3666, 1.4255, 1.4023, 1.3718, 1.3433, 1.3074, 1.3366, 1.3366,
         1.3054, 1.3930, 1.3080, 1.4240, 1.3873, 1.4657, 1.3035, 1.3907, 1.3132,
         1.3851, 1.4121, 1.4243, 1.3944, 1.3600, 1.3507, 1.3187, 1.3484, 1.3484,
         1.3880, 1.4418, 1.3706, 1.2124, 1.3147, 1.2195, 1.3944, 1.2476, 1.3730,
         1.4713, 1.2121, 1.4924, 1.4792, 1.1073, 1.0185, 1.4760, 1.4383, 0.9077,
         2.6291, 2.2383, 2.6372, 2.4592, 1.9389, 1.6975, 2.5223, 2.4616, 1.6834]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 109 : 182.54834771855184
Test loss for epoch 109 : 182.56367819342398
Test Precision for epoch 109 : 0.26153846153846155
Test Recall for epoch 109 : 0.26153846153846155
Test F1 for epoch 109 : 0.26153846153846155


theta for epoch 110 : tensor([[2.1933, 2.2164, 2.2805, 2.3453, 2.3121, 2.1973, 2.2955, 2.1915, 2.1915,
         1.3177, 1.3270, 1.3316, 1.3428, 1.3054, 1.3858, 1.3157, 1.3089, 1.2815,
         1.3021, 1.2863, 1.3007, 1.3133, 1.2775, 1.2690, 1.2939, 1.2658, 1.2658,
         1.3048, 1.3602, 1.2878, 1.3125, 1.3508, 1.2993, 1.3120, 1.2509, 1.2901,
         1.3921, 1.4227, 1.4134, 1.3998, 1.4022, 1.3442, 1.3966, 1.3932, 1.3447,
         1.3850, 1.3354, 1.3267, 1.3071, 1.3801, 1.3298, 1.4155, 1.3055, 1.3131],
        [1.3364, 1.2277, 1.0471, 1.2710, 1.3402, 1.3870, 1.3072, 1.3799, 1.3799,
         1.6157, 1.8503, 1.5894, 2.3798, 1.6371, 3.8880, 1.7096, 1.5344, 3.5843,
         1.1725, 1.2433, 1.0101, 1.2190, 1.3574, 1.3929, 1.3686, 1.3911, 1.3911,
         1.3380, 1.0956, 1.4117, 1.3859, 1.1705, 1.4229, 1.4281, 1.3777, 1.3851,
         1.4195, 1.5436, 1.4854, 1.4130, 1.3936, 1.5047, 1.4698, 0.6156, 1.4487,
         1.0650, 1.4580, 1.4454, 1.4311, 1.1083, 1.4513, 0.8887, 1.4296, 1.4374],
        [1.2620, 1.2894, 1.3484, 1.3245, 1.2929, 1.2668, 1.2736, 1.2597, 1.2597,
         1.3235, 1.3334, 1.3374, 1.3477, 1.3111, 1.3322, 1.3214, 1.3016, 1.2401,
         2.2440, 2.3064, 2.4197, 2.3534, 2.1352, 2.2128, 2.2645, 2.1261, 2.1261,
         1.3445, 1.3198, 1.2926, 1.3174, 1.3455, 1.3039, 1.3181, 1.2997, 1.2951,
         1.3967, 1.4275, 1.4180, 1.3918, 1.4070, 1.3986, 1.4015, 1.2993, 1.3364,
         1.3420, 1.3412, 1.3324, 1.3125, 1.2919, 1.3359, 1.3719, 1.3108, 1.3185],
        [1.2796, 1.3068, 1.2646, 1.2403, 1.3108, 1.2845, 1.2921, 1.2774, 1.2774,
         1.3399, 1.2671, 1.3538, 1.3265, 1.3276, 1.3082, 1.3380, 1.3306, 1.0936,
         1.3249, 1.3055, 1.3653, 1.3358, 1.3000, 1.2594, 1.3157, 1.2885, 1.2885,
         2.6369, 2.2065, 1.9836, 2.0879, 2.6196, 1.9921, 2.5715, 2.0017, 1.9845,
         1.4126, 1.4424, 1.3913, 1.3833, 1.4228, 1.3874, 1.4111, 1.1833, 1.3637,
         1.4071, 1.3106, 1.2223, 1.2817, 1.4024, 1.2387, 1.4379, 1.2802, 1.3360],
        [1.7316, 1.3867, 0.6054, 0.8317, 1.1902, 1.6124, 1.5439, 1.7293, 1.7293,
         1.6237, 1.3739, 1.4404, 0.9684, 1.7257, 0.2466, 1.6071, 1.7427, 1.2803,
         1.3250, 0.8816, 0.7601, 1.0992, 1.5857, 1.6863, 1.3377, 1.7388, 1.7388,
         0.7376, 0.8256, 1.7138, 1.4714, 0.8492, 1.6649, 1.1676, 1.7606, 1.6998,
         0.7151, 0.4847, 0.4371, 0.6628, 0.9832, 1.1722, 0.6116, 7.0462, 6.0085,
         0.7793, 1.2817, 1.3666, 1.6195, 1.0332, 1.6080, 0.4201, 1.6450, 1.7812],
        [1.3381, 1.3659, 1.4249, 1.4017, 1.3712, 1.3426, 1.3067, 1.3358, 1.3358,
         1.3049, 1.3933, 1.3081, 1.4236, 1.3867, 1.4652, 1.3028, 1.3902, 1.3127,
         1.3844, 1.4116, 1.4239, 1.3939, 1.3594, 1.3501, 1.3180, 1.3478, 1.3478,
         1.3874, 1.4409, 1.3697, 1.2111, 1.3155, 1.2199, 1.3937, 1.2465, 1.3720,
         1.4711, 1.2115, 1.4922, 1.4790, 1.1067, 1.0178, 1.4758, 1.4395, 0.9076,
         2.6337, 2.2422, 2.6439, 2.4625, 1.9432, 1.7012, 2.5263, 2.4689, 1.6871]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 110 : 182.5343696768182
Test loss for epoch 110 : 182.5499224850829
Test Precision for epoch 110 : 0.26153846153846155
Test Recall for epoch 110 : 0.26153846153846155
Test F1 for epoch 110 : 0.26153846153846155


theta for epoch 111 : tensor([[2.1977, 2.2209, 2.2850, 2.3500, 2.3169, 2.2017, 2.3002, 2.1958, 2.1958,
         1.3173, 1.3267, 1.3312, 1.3427, 1.3049, 1.3857, 1.3153, 1.3084, 1.2812,
         1.3017, 1.2859, 1.3003, 1.3129, 1.2770, 1.2685, 1.2935, 1.2653, 1.2653,
         1.3045, 1.3598, 1.2871, 1.3119, 1.3505, 1.2987, 1.3116, 1.2502, 1.2894,
         1.3920, 1.4226, 1.4133, 1.3997, 1.4022, 1.3442, 1.3966, 1.3923, 1.3440,
         1.3844, 1.3348, 1.3261, 1.3064, 1.3794, 1.3290, 1.4149, 1.3046, 1.3122],
        [1.3359, 1.2277, 1.0469, 1.2707, 1.3401, 1.3865, 1.3067, 1.3794, 1.3794,
         1.6170, 1.8521, 1.5918, 2.3807, 1.6394, 3.9018, 1.7113, 1.5366, 3.5993,
         1.1721, 1.2430, 1.0104, 1.2186, 1.3570, 1.3924, 1.3682, 1.3906, 1.3906,
         1.3377, 1.0953, 1.4112, 1.3855, 1.1707, 1.4225, 1.4277, 1.3771, 1.3850,
         1.4197, 1.5435, 1.4853, 1.4128, 1.3938, 1.5048, 1.4697, 0.6156, 1.4490,
         1.0648, 1.4576, 1.4449, 1.4307, 1.1077, 1.4507, 0.8887, 1.4289, 1.4368],
        [1.2613, 1.2888, 1.3479, 1.3240, 1.2924, 1.2662, 1.2730, 1.2590, 1.2590,
         1.3229, 1.3328, 1.3367, 1.3473, 1.3104, 1.3318, 1.3208, 1.3009, 1.2395,
         2.2491, 2.3107, 2.4240, 2.3581, 2.1401, 2.2180, 2.2689, 2.1310, 2.1310,
         1.3442, 1.3193, 1.2921, 1.3168, 1.3452, 1.3034, 1.3177, 1.2992, 1.2945,
         1.3966, 1.4274, 1.4179, 1.3918, 1.4070, 1.3986, 1.4014, 1.2988, 1.3360,
         1.3414, 1.3405, 1.3316, 1.3117, 1.2913, 1.3350, 1.3713, 1.3099, 1.3176],
        [1.2788, 1.3061, 1.2645, 1.2401, 1.3101, 1.2837, 1.2914, 1.2766, 1.2766,
         1.3393, 1.2668, 1.3531, 1.3264, 1.3269, 1.3078, 1.3373, 1.3299, 1.0939,
         1.3242, 1.3054, 1.3646, 1.3351, 1.2992, 1.2588, 1.3149, 1.2877, 1.2877,
         2.6412, 2.2121, 1.9886, 2.0928, 2.6243, 1.9972, 2.5760, 2.0066, 1.9896,
         1.4123, 1.4423, 1.3915, 1.3833, 1.4227, 1.3877, 1.4110, 1.1833, 1.3628,
         1.4063, 1.3103, 1.2218, 1.2810, 1.4015, 1.2383, 1.4371, 1.2793, 1.3350],
        [1.7332, 1.3879, 0.6070, 0.8332, 1.1915, 1.6140, 1.5454, 1.7309, 1.7309,
         1.6247, 1.3743, 1.4414, 0.9693, 1.7271, 0.2484, 1.6083, 1.7441, 1.2807,
         1.3265, 0.8830, 0.7616, 1.1008, 1.5872, 1.6875, 1.3393, 1.7404, 1.7404,
         0.7389, 0.8275, 1.7152, 1.4730, 0.8493, 1.6649, 1.1682, 1.7621, 1.7009,
         0.7098, 0.4797, 0.4326, 0.6578, 0.9755, 1.1626, 0.6066, 7.0976, 6.0420,
         0.7804, 1.2823, 1.3674, 1.6197, 1.0347, 1.6087, 0.4214, 1.6465, 1.7825],
        [1.3373, 1.3650, 1.4241, 1.4009, 1.3705, 1.3417, 1.3059, 1.3349, 1.3349,
         1.3042, 1.3935, 1.3080, 1.4231, 1.3860, 1.4647, 1.3021, 1.3895, 1.3122,
         1.3836, 1.4109, 1.4232, 1.3931, 1.3586, 1.3492, 1.3171, 1.3469, 1.3469,
         1.3869, 1.4401, 1.3689, 1.2099, 1.3163, 1.2204, 1.3932, 1.2456, 1.3712,
         1.4708, 1.2109, 1.4919, 1.4786, 1.1060, 1.0171, 1.4755, 1.4405, 0.9074,
         2.6384, 2.2463, 2.6507, 2.4659, 1.9476, 1.7051, 2.5305, 2.4764, 1.6909]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 111 : 182.5206098571167
Test loss for epoch 111 : 182.53625661704547
Test Precision for epoch 111 : 0.26153846153846155
Test Recall for epoch 111 : 0.26153846153846155
Test F1 for epoch 111 : 0.26153846153846155


theta for epoch 112 : tensor([[2.2023, 2.2256, 2.2898, 2.3551, 2.3220, 2.2063, 2.3052, 2.2004, 2.2004,
         1.3169, 1.3263, 1.3306, 1.3424, 1.3043, 1.3855, 1.3148, 1.3078, 1.2808,
         1.3010, 1.2853, 1.2995, 1.3122, 1.2763, 1.2677, 1.2928, 1.2645, 1.2645,
         1.3042, 1.3594, 1.2863, 1.3113, 1.3501, 1.2981, 1.3113, 1.2495, 1.2887,
         1.3918, 1.4225, 1.4132, 1.3995, 1.4021, 1.3441, 1.3964, 1.3914, 1.3432,
         1.3839, 1.3342, 1.3255, 1.3058, 1.3788, 1.3283, 1.4144, 1.3039, 1.3114],
        [1.3355, 1.2279, 1.0469, 1.2705, 1.3401, 1.3861, 1.3063, 1.3790, 1.3790,
         1.6182, 1.8539, 1.5941, 2.3816, 1.6415, 3.9155, 1.7128, 1.5388, 3.6142,
         1.1716, 1.2426, 1.0107, 1.2182, 1.3565, 1.3919, 1.3677, 1.3901, 1.3901,
         1.3375, 1.0951, 1.4109, 1.3853, 1.1709, 1.4222, 1.4276, 1.3767, 1.3849,
         1.4198, 1.5435, 1.4851, 1.4127, 1.3940, 1.5049, 1.4695, 0.6156, 1.4492,
         1.0647, 1.4574, 1.4447, 1.4304, 1.1075, 1.4503, 0.8888, 1.4285, 1.4363],
        [1.2608, 1.2884, 1.3475, 1.3236, 1.2921, 1.2656, 1.2725, 1.2585, 1.2585,
         1.3224, 1.3324, 1.3362, 1.3471, 1.3098, 1.3314, 1.3203, 1.3004, 1.2391,
         2.2539, 2.3148, 2.4281, 2.3626, 2.1448, 2.2231, 2.2732, 2.1357, 2.1357,
         1.3440, 1.3189, 1.2916, 1.3164, 1.3449, 1.3030, 1.3174, 1.2987, 1.2941,
         1.3965, 1.4273, 1.4178, 1.3918, 1.4070, 1.3986, 1.4013, 1.2982, 1.3356,
         1.3411, 1.3400, 1.3312, 1.3112, 1.2909, 1.3344, 1.3709, 1.3092, 1.3169],
        [1.2782, 1.3055, 1.2646, 1.2401, 1.3095, 1.2830, 1.2907, 1.2759, 1.2759,
         1.3388, 1.2666, 1.3524, 1.3263, 1.3263, 1.3074, 1.3367, 1.3293, 1.0944,
         1.3234, 1.3052, 1.3640, 1.3344, 1.2984, 1.2582, 1.3142, 1.2868, 1.2868,
         2.6454, 2.2177, 1.9935, 2.0976, 2.6288, 2.0022, 2.5805, 2.0114, 1.9946,
         1.4121, 1.4421, 1.3917, 1.3834, 1.4225, 1.3881, 1.4109, 1.1834, 1.3619,
         1.4058, 1.3102, 1.2215, 1.2805, 1.4009, 1.2381, 1.4365, 1.2786, 1.3343],
        [1.7346, 1.3888, 0.6084, 0.8343, 1.1925, 1.6154, 1.5469, 1.7323, 1.7323,
         1.6255, 1.3745, 1.4422, 0.9701, 1.7283, 0.2500, 1.6094, 1.7454, 1.2808,
         1.3278, 0.8840, 0.7626, 1.1021, 1.5884, 1.6886, 1.3405, 1.7416, 1.7416,
         0.7400, 0.8292, 1.7165, 1.4745, 0.8493, 1.6649, 1.1687, 1.7635, 1.7020,
         0.7048, 0.4749, 0.4283, 0.6530, 0.9682, 1.1535, 0.6019, 7.1490, 6.0753,
         0.7814, 1.2829, 1.3681, 1.6200, 1.0361, 1.6093, 0.4226, 1.6479, 1.7838],
        [1.3365, 1.3643, 1.4234, 1.4001, 1.3698, 1.3410, 1.3051, 1.3342, 1.3342,
         1.3036, 1.3937, 1.3079, 1.4226, 1.3854, 1.4642, 1.3015, 1.3889, 1.3116,
         1.3827, 1.4101, 1.4224, 1.3923, 1.3577, 1.3483, 1.3160, 1.3460, 1.3460,
         1.3865, 1.4395, 1.3681, 1.2089, 1.3172, 1.2210, 1.3928, 1.2447, 1.3705,
         1.4704, 1.2103, 1.4916, 1.4783, 1.1052, 1.0163, 1.4752, 1.4415, 0.9071,
         2.6432, 2.2504, 2.6576, 2.4693, 1.9519, 1.7089, 2.5346, 2.4840, 1.6948]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 112 : 182.5070500115839
Test loss for epoch 112 : 182.52281350610622
Test Precision for epoch 112 : 0.26153846153846155
Test Recall for epoch 112 : 0.26153846153846155
Test F1 for epoch 112 : 0.26153846153846155


theta for epoch 113 : tensor([[2.2068, 2.2302, 2.2945, 2.3600, 2.3270, 2.2108, 2.3101, 2.2049, 2.2049,
         1.3165, 1.3260, 1.3302, 1.3422, 1.3038, 1.3853, 1.3144, 1.3073, 1.2805,
         1.3005, 1.2848, 1.2988, 1.3117, 1.2757, 1.2672, 1.2923, 1.2640, 1.2640,
         1.3039, 1.3589, 1.2856, 1.3107, 1.3498, 1.2975, 1.3109, 1.2488, 1.2880,
         1.3915, 1.4222, 1.4129, 1.3992, 1.4019, 1.3438, 1.3961, 1.3903, 1.3423,
         1.3835, 1.3339, 1.3251, 1.3054, 1.3784, 1.3278, 1.4140, 1.3034, 1.3109],
        [1.3350, 1.2278, 1.0466, 1.2700, 1.3398, 1.3855, 1.3058, 1.3784, 1.3784,
         1.6197, 1.8559, 1.5966, 2.3828, 1.6439, 3.9295, 1.7146, 1.5411, 3.6292,
         1.1712, 1.2422, 1.0109, 1.2177, 1.3560, 1.3915, 1.3673, 1.3896, 1.3896,
         1.3372, 1.0948, 1.4104, 1.3849, 1.1710, 1.4218, 1.4273, 1.3762, 1.3847,
         1.4198, 1.5433, 1.4847, 1.4123, 1.3940, 1.5048, 1.4691, 0.6155, 1.4493,
         1.0647, 1.4572, 1.4445, 1.4302, 1.1071, 1.4499, 0.8889, 1.4281, 1.4359],
        [1.2602, 1.2878, 1.3469, 1.3230, 1.2916, 1.2650, 1.2719, 1.2578, 1.2578,
         1.3219, 1.3319, 1.3356, 1.3468, 1.3092, 1.3311, 1.3198, 1.2998, 1.2387,
         2.2589, 2.3192, 2.4325, 2.3673, 2.1496, 2.2282, 2.2776, 2.1405, 2.1405,
         1.3437, 1.3184, 1.2911, 1.3159, 1.3446, 1.3025, 1.3170, 1.2982, 1.2935,
         1.3963, 1.4272, 1.4176, 1.3916, 1.4069, 1.3984, 1.4011, 1.2975, 1.3350,
         1.3408, 1.3397, 1.3308, 1.3108, 1.2906, 1.3338, 1.3706, 1.3087, 1.3164],
        [1.2776, 1.3049, 1.2647, 1.2402, 1.3090, 1.2824, 1.2902, 1.2753, 1.2753,
         1.3384, 1.2665, 1.3519, 1.3265, 1.3258, 1.3072, 1.3363, 1.3288, 1.0951,
         1.3229, 1.3053, 1.3636, 1.3339, 1.2978, 1.2579, 1.3137, 1.2863, 1.2863,
         2.6494, 2.2231, 1.9982, 2.1023, 2.6331, 2.0070, 2.5848, 2.0160, 1.9994,
         1.4118, 1.4419, 1.3918, 1.3834, 1.4224, 1.3883, 1.4108, 1.1835, 1.3610,
         1.4055, 1.3103, 1.2214, 1.2802, 1.4005, 1.2382, 1.4362, 1.2781, 1.3338],
        [1.7359, 1.3897, 0.6096, 0.8354, 1.1935, 1.6167, 1.5481, 1.7336, 1.7336,
         1.6264, 1.3747, 1.4431, 0.9708, 1.7296, 0.2515, 1.6104, 1.7467, 1.2809,
         1.3291, 0.8850, 0.7637, 1.1034, 1.5897, 1.6896, 1.3418, 1.7430, 1.7430,
         0.7409, 0.8308, 1.7177, 1.4759, 0.8492, 1.6649, 1.1691, 1.7648, 1.7030,
         0.6999, 0.4702, 0.4240, 0.6483, 0.9611, 1.1446, 0.5972, 7.2003, 6.1082,
         0.7824, 1.2835, 1.3688, 1.6203, 1.0375, 1.6100, 0.4238, 1.6494, 1.7851],
        [1.3359, 1.3636, 1.4226, 1.3995, 1.3693, 1.3403, 1.3045, 1.3335, 1.3335,
         1.3031, 1.3941, 1.3080, 1.4224, 1.3849, 1.4638, 1.3010, 1.3884, 1.3113,
         1.3821, 1.4096, 1.4219, 1.3918, 1.3571, 1.3477, 1.3153, 1.3454, 1.3454,
         1.3861, 1.4389, 1.3675, 1.2079, 1.3181, 1.2216, 1.3924, 1.2440, 1.3698,
         1.4700, 1.2096, 1.4912, 1.4779, 1.1044, 1.0156, 1.4748, 1.4423, 0.9068,
         2.6478, 2.2543, 2.6642, 2.4725, 1.9561, 1.7126, 2.5386, 2.4914, 1.6984]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 113 : 182.49369135965657
Test loss for epoch 113 : 182.50977430888253
Test Precision for epoch 113 : 0.26153846153846155
Test Recall for epoch 113 : 0.26153846153846155
Test F1 for epoch 113 : 0.26153846153846155


theta for epoch 114 : tensor([[2.2112, 2.2347, 2.2991, 2.3649, 2.3320, 2.2153, 2.3149, 2.2093, 2.2093,
         1.3161, 1.3256, 1.3298, 1.3419, 1.3033, 1.3851, 1.3140, 1.3068, 1.2801,
         1.3001, 1.2844, 1.2984, 1.3113, 1.2754, 1.2668, 1.2919, 1.2636, 1.2636,
         1.3036, 1.3585, 1.2849, 1.3101, 1.3494, 1.2968, 1.3105, 1.2482, 1.2873,
         1.3911, 1.4219, 1.4126, 1.3988, 1.4016, 1.3435, 1.3958, 1.3893, 1.3413,
         1.3832, 1.3336, 1.3248, 1.3051, 1.3780, 1.3274, 1.4138, 1.3029, 1.3104],
        [1.3343, 1.2276, 1.0462, 1.2695, 1.3395, 1.3848, 1.3051, 1.3777, 1.3777,
         1.6213, 1.8581, 1.5992, 2.3841, 1.6464, 3.9435, 1.7165, 1.5435, 3.6445,
         1.1708, 1.2419, 1.0111, 1.2173, 1.3556, 1.3910, 1.3669, 1.3892, 1.3892,
         1.3368, 1.0944, 1.4099, 1.3845, 1.1709, 1.4213, 1.4269, 1.3756, 1.3844,
         1.4197, 1.5430, 1.4843, 1.4119, 1.3939, 1.5047, 1.4686, 0.6152, 1.4492,
         1.0645, 1.4569, 1.4443, 1.4299, 1.1068, 1.4494, 0.8889, 1.4277, 1.4354],
        [1.2595, 1.2871, 1.3463, 1.3225, 1.2911, 1.2643, 1.2712, 1.2572, 1.2572,
         1.3214, 1.3313, 1.3350, 1.3464, 1.3086, 1.3308, 1.3192, 1.2992, 1.2383,
         2.2640, 2.3236, 2.4369, 2.3721, 2.1546, 2.2334, 2.2821, 2.1453, 2.1453,
         1.3434, 1.3180, 1.2905, 1.3153, 1.3442, 1.3020, 1.3166, 1.2977, 1.2930,
         1.3960, 1.4269, 1.4173, 1.3913, 1.4067, 1.3982, 1.4008, 1.2966, 1.3344,
         1.3406, 1.3393, 1.3304, 1.3105, 1.2903, 1.3334, 1.3703, 1.3082, 1.3159],
        [1.2770, 1.3044, 1.2648, 1.2403, 1.3085, 1.2818, 1.2896, 1.2747, 1.2747,
         1.3379, 1.2663, 1.3513, 1.3265, 1.3252, 1.3069, 1.3358, 1.3282, 1.0957,
         1.3225, 1.3055, 1.3633, 1.3336, 1.2973, 1.2577, 1.3133, 1.2858, 1.2858,
         2.6534, 2.2286, 2.0030, 2.1070, 2.6375, 2.0118, 2.5891, 2.0207, 2.0042,
         1.4114, 1.4416, 1.3919, 1.3833, 1.4221, 1.3885, 1.4105, 1.1835, 1.3600,
         1.4052, 1.3105, 1.2213, 1.2799, 1.4000, 1.2383, 1.4359, 1.2776, 1.3334],
        [1.7373, 1.3907, 0.6109, 0.8366, 1.1946, 1.6181, 1.5495, 1.7349, 1.7349,
         1.6273, 1.3751, 1.4440, 0.9717, 1.7308, 0.2532, 1.6115, 1.7480, 1.2810,
         1.3306, 0.8862, 0.7650, 1.1049, 1.5911, 1.6908, 1.3432, 1.7444, 1.7444,
         0.7420, 0.8325, 1.7190, 1.4774, 0.8494, 1.6650, 1.1697, 1.7662, 1.7040,
         0.6949, 0.4654, 0.4196, 0.6435, 0.9541, 1.1359, 0.5924, 7.2512, 6.1406,
         0.7837, 1.2844, 1.3698, 1.6209, 1.0390, 1.6108, 0.4252, 1.6510, 1.7865],
        [1.3353, 1.3630, 1.4219, 1.3989, 1.3688, 1.3398, 1.3039, 1.3330, 1.3330,
         1.3027, 1.3944, 1.3080, 1.4221, 1.3844, 1.4635, 1.3005, 1.3879, 1.3109,
         1.3816, 1.4092, 1.4216, 1.3915, 1.3567, 1.3473, 1.3148, 1.3450, 1.3450,
         1.3858, 1.4383, 1.3668, 1.2070, 1.3189, 1.2221, 1.3921, 1.2432, 1.3692,
         1.4696, 1.2089, 1.4908, 1.4774, 1.1036, 1.0147, 1.4744, 1.4429, 0.9064,
         2.6524, 2.2582, 2.6709, 2.4756, 1.9601, 1.7161, 2.5426, 2.4988, 1.7020]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 114 : 182.48054444841196
Test loss for epoch 114 : 182.4969562317224
Test Precision for epoch 114 : 0.26153846153846155
Test Recall for epoch 114 : 0.26153846153846155
Test F1 for epoch 114 : 0.26153846153846155


theta for epoch 115 : tensor([[2.2158, 2.2394, 2.3038, 2.3700, 2.3371, 2.2199, 2.3199, 2.2139, 2.2139,
         1.3156, 1.3251, 1.3292, 1.3415, 1.3026, 1.3847, 1.3134, 1.3061, 1.2796,
         1.2996, 1.2839, 1.2977, 1.3108, 1.2748, 1.2663, 1.2914, 1.2631, 1.2631,
         1.3033, 1.3580, 1.2842, 1.3096, 1.3491, 1.2962, 1.3102, 1.2476, 1.2866,
         1.3908, 1.4217, 1.4123, 1.3985, 1.4013, 1.3433, 1.3955, 1.3883, 1.3405,
         1.3828, 1.3332, 1.3244, 1.3047, 1.3776, 1.3269, 1.4134, 1.3025, 1.3099],
        [1.3339, 1.2276, 1.0459, 1.2691, 1.3394, 1.3843, 1.3047, 1.3773, 1.3773,
         1.6229, 1.8602, 1.6018, 2.3853, 1.6489, 3.9576, 1.7183, 1.5459, 3.6597,
         1.1703, 1.2414, 1.0112, 1.2168, 1.3550, 1.3905, 1.3664, 1.3886, 1.3886,
         1.3366, 1.0941, 1.4094, 1.3842, 1.1709, 1.4209, 1.4267, 1.3751, 1.3842,
         1.4197, 1.5428, 1.4839, 1.4116, 1.3940, 1.5046, 1.4683, 0.6150, 1.4493,
         1.0644, 1.4566, 1.4440, 1.4295, 1.1064, 1.4490, 0.8889, 1.4272, 1.4349],
        [1.2591, 1.2868, 1.3459, 1.3221, 1.2908, 1.2639, 1.2709, 1.2568, 1.2568,
         1.3208, 1.3307, 1.3344, 1.3460, 1.3078, 1.3304, 1.3186, 1.2985, 1.2378,
         2.2689, 2.3280, 2.4413, 2.3768, 2.1593, 2.2385, 2.2865, 2.1501, 2.1501,
         1.3432, 1.3176, 1.2901, 1.3149, 1.3439, 1.3016, 1.3164, 1.2973, 1.2925,
         1.3958, 1.4267, 1.4171, 1.3912, 1.4066, 1.3982, 1.4006, 1.2959, 1.3338,
         1.3404, 1.3390, 1.3301, 1.3102, 1.2901, 1.3329, 1.3700, 1.3078, 1.3154],
        [1.2764, 1.3038, 1.2650, 1.2405, 1.3079, 1.2812, 1.2890, 1.2741, 1.2741,
         1.3373, 1.2660, 1.3506, 1.3264, 1.3245, 1.3064, 1.3351, 1.3275, 1.0962,
         1.3218, 1.3055, 1.3627, 1.3329, 1.2967, 1.2573, 1.3127, 1.2851, 1.2851,
         2.6577, 2.2343, 2.0080, 2.1120, 2.6421, 2.0169, 2.5936, 2.0256, 2.0093,
         1.4110, 1.4413, 1.3920, 1.3833, 1.4218, 1.3887, 1.4103, 1.1837, 1.3591,
         1.4048, 1.3105, 1.2211, 1.2794, 1.3995, 1.2383, 1.4354, 1.2770, 1.3327],
        [1.7388, 1.3920, 0.6125, 0.8380, 1.1959, 1.6196, 1.5510, 1.7364, 1.7364,
         1.6283, 1.3754, 1.4449, 0.9726, 1.7320, 0.2549, 1.6126, 1.7492, 1.2810,
         1.3320, 0.8875, 0.7663, 1.1064, 1.5925, 1.6919, 1.3447, 1.7458, 1.7458,
         0.7434, 0.8345, 1.7203, 1.4790, 0.8498, 1.6653, 1.1705, 1.7677, 1.7051,
         0.6899, 0.4606, 0.4152, 0.6387, 0.9472, 1.1272, 0.5876, 7.3018, 6.1724,
         0.7851, 1.2854, 1.3709, 1.6216, 1.0407, 1.6116, 0.4268, 1.6526, 1.7879],
        [1.3348, 1.3625, 1.4213, 1.3983, 1.3684, 1.3393, 1.3035, 1.3325, 1.3325,
         1.3020, 1.3944, 1.3078, 1.4215, 1.3837, 1.4630, 1.2998, 1.3872, 1.3104,
         1.3810, 1.4087, 1.4211, 1.3909, 1.3561, 1.3467, 1.3141, 1.3444, 1.3444,
         1.3854, 1.4377, 1.3661, 1.2061, 1.3196, 1.2225, 1.3917, 1.2425, 1.3685,
         1.4692, 1.2082, 1.4905, 1.4770, 1.1027, 1.0140, 1.4741, 1.4436, 0.9060,
         2.6571, 2.2623, 2.6777, 2.4790, 1.9643, 1.7198, 2.5467, 2.5064, 1.7057]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 115 : 182.46759273820385
Test loss for epoch 115 : 182.48420106557114
Test Precision for epoch 115 : 0.26153846153846155
Test Recall for epoch 115 : 0.26153846153846155
Test F1 for epoch 115 : 0.26153846153846155


theta for epoch 116 : tensor([[2.2202, 2.2440, 2.3084, 2.3749, 2.3421, 2.2243, 2.3248, 2.2183, 2.2183,
         1.3151, 1.3246, 1.3286, 1.3412, 1.3020, 1.3843, 1.3128, 1.3055, 1.2791,
         1.2991, 1.2834, 1.2970, 1.3103, 1.2743, 1.2658, 1.2910, 1.2626, 1.2626,
         1.3030, 1.3576, 1.2835, 1.3090, 1.3487, 1.2956, 1.3099, 1.2470, 1.2860,
         1.3908, 1.4218, 1.4124, 1.3985, 1.4014, 1.3434, 1.3956, 1.3877, 1.3400,
         1.3823, 1.3327, 1.3239, 1.3043, 1.3770, 1.3263, 1.4128, 1.3019, 1.3094],
        [1.3335, 1.2277, 1.0457, 1.2688, 1.3393, 1.3839, 1.3043, 1.3768, 1.3768,
         1.6245, 1.8623, 1.6042, 2.3866, 1.6512, 3.9715, 1.7201, 1.5482, 3.6748,
         1.1699, 1.2411, 1.0114, 1.2165, 1.3546, 1.3900, 1.3660, 1.3882, 1.3882,
         1.3363, 1.0937, 1.4089, 1.3838, 1.1709, 1.4204, 1.4265, 1.3746, 1.3840,
         1.4200, 1.5428, 1.4838, 1.4115, 1.3943, 1.5049, 1.4681, 0.6150, 1.4496,
         1.0643, 1.4562, 1.4437, 1.4291, 1.1060, 1.4484, 0.8888, 1.4266, 1.4344],
        [1.2587, 1.2863, 1.3454, 1.3217, 1.2905, 1.2634, 1.2705, 1.2564, 1.2564,
         1.3202, 1.3302, 1.3338, 1.3456, 1.3072, 1.3300, 1.3179, 1.2979, 1.2374,
         2.2739, 2.3324, 2.4457, 2.3815, 2.1640, 2.2436, 2.2910, 2.1548, 2.1548,
         1.3429, 1.3172, 1.2896, 1.3145, 1.3436, 1.3011, 1.3161, 1.2968, 1.2920,
         1.3958, 1.4268, 1.4172, 1.3912, 1.4066, 1.3983, 1.4006, 1.2955, 1.3335,
         1.3400, 1.3385, 1.3296, 1.3097, 1.2897, 1.3324, 1.3695, 1.3072, 1.3148],
        [1.2757, 1.3031, 1.2650, 1.2405, 1.3073, 1.2805, 1.2883, 1.2734, 1.2734,
         1.3366, 1.2657, 1.3498, 1.3262, 1.3237, 1.3060, 1.3344, 1.3267, 1.0966,
         1.3211, 1.3055, 1.3620, 1.3322, 1.2959, 1.2569, 1.3120, 1.2843, 1.2843,
         2.6619, 2.2400, 2.0130, 2.1170, 2.6467, 2.0220, 2.5982, 2.0306, 2.0144,
         1.4108, 1.4412, 1.3922, 1.3834, 1.4217, 1.3891, 1.4103, 1.1840, 1.3583,
         1.4041, 1.3104, 1.2207, 1.2788, 1.3988, 1.2381, 1.4348, 1.2762, 1.3319],
        [1.7402, 1.3931, 0.6141, 0.8394, 1.1972, 1.6211, 1.5524, 1.7379, 1.7379,
         1.6292, 1.3758, 1.4458, 0.9735, 1.7332, 0.2565, 1.6136, 1.7505, 1.2810,
         1.3334, 0.8887, 0.7676, 1.1079, 1.5939, 1.6930, 1.3461, 1.7472, 1.7472,
         0.7446, 0.8363, 1.7216, 1.4806, 0.8503, 1.6656, 1.1712, 1.7691, 1.7061,
         0.6851, 0.4559, 0.4110, 0.6340, 0.9406, 1.1190, 0.5829, 7.3524, 6.2040,
         0.7864, 1.2862, 1.3719, 1.6221, 1.0422, 1.6122, 0.4282, 1.6541, 1.7892],
        [1.3343, 1.3619, 1.4206, 1.3977, 1.3679, 1.3389, 1.3030, 1.3320, 1.3320,
         1.3013, 1.3944, 1.3075, 1.4210, 1.3830, 1.4624, 1.2991, 1.3864, 1.3098,
         1.3802, 1.4080, 1.4205, 1.3903, 1.3554, 1.3461, 1.3133, 1.3437, 1.3437,
         1.3848, 1.4371, 1.3653, 1.2052, 1.3202, 1.2228, 1.3912, 1.2416, 1.3677,
         1.4691, 1.2077, 1.4904, 1.4769, 1.1021, 1.0134, 1.4739, 1.4444, 0.9059,
         2.6620, 2.2664, 2.6846, 2.4824, 1.9685, 1.7235, 2.5508, 2.5140, 1.7094]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 116 : 182.45483198021432
Test loss for epoch 116 : 182.47169426172528
Test Precision for epoch 116 : 0.26153846153846155
Test Recall for epoch 116 : 0.26153846153846155
Test F1 for epoch 116 : 0.26153846153846155


theta for epoch 117 : tensor([[2.2246, 2.2484, 2.3129, 2.3798, 2.3470, 2.2287, 2.3296, 2.2227, 2.2227,
         1.3147, 1.3243, 1.3282, 1.3410, 1.3016, 1.3841, 1.3125, 1.3051, 1.2789,
         1.2987, 1.2830, 1.2965, 1.3099, 1.2739, 1.2654, 1.2906, 1.2622, 1.2622,
         1.3025, 1.3570, 1.2828, 1.3083, 1.3482, 1.2949, 1.3094, 1.2462, 1.2852,
         1.3909, 1.4220, 1.4125, 1.3986, 1.4016, 1.3437, 1.3957, 1.3873, 1.3397,
         1.3816, 1.3321, 1.3233, 1.3038, 1.3762, 1.3257, 1.4121, 1.3012, 1.3087],
        [1.3330, 1.2276, 1.0454, 1.2684, 1.3393, 1.3834, 1.3039, 1.3764, 1.3764,
         1.6260, 1.8645, 1.6067, 2.3878, 1.6536, 3.9854, 1.7218, 1.5504, 3.6899,
         1.1697, 1.2409, 1.0117, 1.2162, 1.3543, 1.3897, 1.3657, 1.3878, 1.3878,
         1.3360, 1.0933, 1.4084, 1.3834, 1.1708, 1.4200, 1.4262, 1.3740, 1.3837,
         1.4203, 1.5429, 1.4838, 1.4115, 1.3947, 1.5052, 1.4681, 0.6152, 1.4500,
         1.0641, 1.4558, 1.4433, 1.4287, 1.1056, 1.4479, 0.8887, 1.4260, 1.4337],
        [1.2581, 1.2857, 1.3447, 1.3211, 1.2901, 1.2628, 1.2699, 1.2558, 1.2558,
         1.3197, 1.3297, 1.3333, 1.3452, 1.3066, 1.3297, 1.3175, 1.2973, 1.2371,
         2.2789, 2.3369, 2.4503, 2.3864, 2.1689, 2.2487, 2.2955, 2.1596, 2.1596,
         1.3425, 1.3166, 1.2889, 1.3139, 1.3431, 1.3005, 1.3156, 1.2962, 1.2913,
         1.3958, 1.4270, 1.4173, 1.3913, 1.4068, 1.3985, 1.4007, 1.2950, 1.3333,
         1.3394, 1.3379, 1.3289, 1.3091, 1.2891, 1.3316, 1.3689, 1.3065, 1.3141],
        [1.2750, 1.3025, 1.2651, 1.2407, 1.3067, 1.2798, 1.2877, 1.2727, 1.2727,
         1.3361, 1.2655, 1.3492, 1.3263, 1.3231, 1.3056, 1.3339, 1.3261, 1.0973,
         1.3205, 1.3056, 1.3614, 1.3317, 1.2953, 1.2566, 1.3115, 1.2837, 1.2837,
         2.6661, 2.2456, 2.0179, 2.1219, 2.6512, 2.0270, 2.6026, 2.0354, 2.0194,
         1.4107, 1.4413, 1.3926, 1.3836, 1.4217, 1.3896, 1.4103, 1.1846, 1.3578,
         1.4035, 1.3103, 1.2203, 1.2782, 1.3981, 1.2379, 1.4342, 1.2754, 1.3311],
        [1.7416, 1.3942, 0.6155, 0.8406, 1.1984, 1.6224, 1.5537, 1.7392, 1.7392,
         1.6302, 1.3762, 1.4468, 0.9745, 1.7344, 0.2582, 1.6147, 1.7517, 1.2810,
         1.3348, 0.8899, 0.7689, 1.1093, 1.5952, 1.6940, 1.3475, 1.7486, 1.7486,
         0.7457, 0.8379, 1.7227, 1.4820, 0.8506, 1.6658, 1.1718, 1.7703, 1.7070,
         0.6804, 0.4514, 0.4069, 0.6295, 0.9343, 1.1111, 0.5783, 7.4027, 6.2352,
         0.7876, 1.2870, 1.3728, 1.6226, 1.0436, 1.6127, 0.4296, 1.6555, 1.7903],
        [1.3337, 1.3612, 1.4198, 1.3970, 1.3673, 1.3383, 1.3023, 1.3314, 1.3314,
         1.3008, 1.3945, 1.3074, 1.4206, 1.3824, 1.4621, 1.2985, 1.3858, 1.3093,
         1.3796, 1.4074, 1.4199, 1.3897, 1.3548, 1.3455, 1.3126, 1.3431, 1.3431,
         1.3842, 1.4363, 1.3644, 1.2041, 1.3205, 1.2229, 1.3906, 1.2407, 1.3668,
         1.4690, 1.2072, 1.4904, 1.4768, 1.1016, 1.0129, 1.4739, 1.4452, 0.9057,
         2.6668, 2.2705, 2.6915, 2.4857, 1.9725, 1.7271, 2.5549, 2.5216, 1.7130]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 117 : 182.44226915514633
Test loss for epoch 117 : 182.45947188905083
Test Precision for epoch 117 : 0.26153846153846155
Test Recall for epoch 117 : 0.26153846153846155
Test F1 for epoch 117 : 0.26153846153846155


theta for epoch 118 : tensor([[2.2293, 2.2532, 2.3177, 2.3849, 2.3522, 2.2334, 2.3346, 2.2274, 2.2274,
         1.3144, 1.3240, 1.3279, 1.3407, 1.3012, 1.3838, 1.3121, 1.3046, 1.2785,
         1.2982, 1.2824, 1.2957, 1.3093, 1.2734, 1.2649, 1.2901, 1.2617, 1.2617,
         1.3020, 1.3563, 1.2820, 1.3076, 1.3476, 1.2941, 1.3089, 1.2454, 1.2844,
         1.3907, 1.4220, 1.4124, 1.3984, 1.4015, 1.3436, 1.3956, 1.3866, 1.3391,
         1.3810, 1.3316, 1.3227, 1.3033, 1.3756, 1.3251, 1.4115, 1.3006, 1.3081],
        [1.3327, 1.2277, 1.0452, 1.2681, 1.3392, 1.3830, 1.3035, 1.3760, 1.3760,
         1.6277, 1.8667, 1.6091, 2.3892, 1.6560, 3.9994, 1.7236, 1.5527, 3.7051,
         1.1695, 1.2406, 1.0120, 1.2159, 1.3539, 1.3893, 1.3654, 1.3874, 1.3874,
         1.3357, 1.0930, 1.4079, 1.3830, 1.1707, 1.4195, 1.4259, 1.3735, 1.3835,
         1.4206, 1.5430, 1.4837, 1.4114, 1.3950, 1.5054, 1.4680, 0.6152, 1.4503,
         1.0640, 1.4554, 1.4430, 1.4283, 1.1053, 1.4474, 0.8887, 1.4256, 1.4333],
        [1.2576, 1.2852, 1.3441, 1.3206, 1.2897, 1.2623, 1.2695, 1.2553, 1.2553,
         1.3194, 1.3293, 1.3329, 1.3450, 1.3062, 1.3296, 1.3171, 1.2970, 1.2369,
         2.2839, 2.3415, 2.4549, 2.3912, 2.1736, 2.2538, 2.3001, 2.1643, 2.1643,
         1.3421, 1.3161, 1.2883, 1.3133, 1.3426, 1.3000, 1.3152, 1.2957, 1.2907,
         1.3957, 1.4270, 1.4172, 1.3913, 1.4068, 1.3986, 1.4006, 1.2945, 1.3329,
         1.3390, 1.3374, 1.3284, 1.3087, 1.2887, 1.3311, 1.3684, 1.3059, 1.3135],
        [1.2744, 1.3019, 1.2653, 1.2409, 1.3062, 1.2791, 1.2871, 1.2721, 1.2721,
         1.3357, 1.2655, 1.3488, 1.3264, 1.3227, 1.3054, 1.3335, 1.3256, 1.0981,
         1.3200, 1.3057, 1.3609, 1.3311, 1.2947, 1.2563, 1.3110, 1.2831, 1.2831,
         2.6702, 2.2512, 2.0228, 2.1269, 2.6556, 2.0320, 2.6070, 2.0402, 2.0243,
         1.4105, 1.4412, 1.3929, 1.3838, 1.4216, 1.3900, 1.4103, 1.1851, 1.3571,
         1.4030, 1.3103, 1.2201, 1.2777, 1.3975, 1.2379, 1.4337, 1.2748, 1.3305],
        [1.7429, 1.3954, 0.6170, 0.8420, 1.1997, 1.6238, 1.5550, 1.7405, 1.7405,
         1.6313, 1.3768, 1.4478, 0.9756, 1.7357, 0.2600, 1.6159, 1.7531, 1.2811,
         1.3361, 0.8912, 0.7701, 1.1107, 1.5965, 1.6951, 1.3490, 1.7499, 1.7499,
         0.7469, 0.8396, 1.7239, 1.4834, 0.8511, 1.6661, 1.1725, 1.7715, 1.7079,
         0.6757, 0.4469, 0.4028, 0.6249, 0.9280, 1.1033, 0.5738, 7.4529, 6.2659,
         0.7891, 1.2879, 1.3738, 1.6233, 1.0451, 1.6133, 0.4311, 1.6570, 1.7916],
        [1.3331, 1.3606, 1.4190, 1.3963, 1.3667, 1.3378, 1.3018, 1.3309, 1.3309,
         1.3003, 1.3946, 1.3073, 1.4203, 1.3819, 1.4618, 1.2981, 1.3853, 1.3090,
         1.3789, 1.4068, 1.4194, 1.3892, 1.3542, 1.3449, 1.3119, 1.3426, 1.3426,
         1.3835, 1.4355, 1.3635, 1.2030, 1.3207, 1.2230, 1.3900, 1.2397, 1.3660,
         1.4688, 1.2067, 1.4902, 1.4766, 1.1009, 1.0123, 1.4737, 1.4458, 0.9055,
         2.6717, 2.2747, 2.6985, 2.4892, 1.9767, 1.7308, 2.5591, 2.5293, 1.7167]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 118 : 182.42990315261778
Test loss for epoch 118 : 182.44734791547984
Test Precision for epoch 118 : 0.26153846153846155
Test Recall for epoch 118 : 0.26153846153846155
Test F1 for epoch 118 : 0.26153846153846155


theta for epoch 119 : tensor([[2.2339, 2.2579, 2.3224, 2.3900, 2.3573, 2.2380, 2.3396, 2.2320, 2.2320,
         1.3140, 1.3237, 1.3275, 1.3404, 1.3007, 1.3835, 1.3117, 1.3042, 1.2782,
         1.2977, 1.2818, 1.2950, 1.3087, 1.2729, 1.2643, 1.2895, 1.2612, 1.2612,
         1.3017, 1.3558, 1.2814, 1.3071, 1.3473, 1.2936, 1.3086, 1.2449, 1.2839,
         1.3904, 1.4218, 1.4121, 1.3981, 1.4013, 1.3435, 1.3953, 1.3858, 1.3384,
         1.3806, 1.3312, 1.3223, 1.3031, 1.3751, 1.3247, 1.4110, 1.3002, 1.3077],
        [1.3323, 1.2277, 1.0449, 1.2677, 1.3392, 1.3826, 1.3032, 1.3756, 1.3756,
         1.6293, 1.8689, 1.6116, 2.3905, 1.6585, 4.0134, 1.7255, 1.5550, 3.7203,
         1.1693, 1.2404, 1.0123, 1.2157, 1.3536, 1.3890, 1.3650, 1.3871, 1.3871,
         1.3356, 1.0927, 1.4076, 1.3828, 1.1707, 1.4192, 1.4259, 1.3731, 1.3834,
         1.4206, 1.5428, 1.4834, 1.4112, 1.3951, 1.5055, 1.4677, 0.6151, 1.4504,
         1.0641, 1.4552, 1.4428, 1.4281, 1.1051, 1.4472, 0.8888, 1.4253, 1.4329],
        [1.2571, 1.2847, 1.3435, 1.3201, 1.2892, 1.2618, 1.2690, 1.2548, 1.2548,
         1.3190, 1.3289, 1.3325, 1.3448, 1.3057, 1.3294, 1.3167, 1.2965, 1.2367,
         2.2889, 2.3460, 2.4595, 2.3961, 2.1784, 2.2588, 2.3046, 2.1690, 2.1690,
         1.3418, 1.3157, 1.2879, 1.3130, 1.3424, 1.2996, 1.3150, 1.2953, 1.2903,
         1.3955, 1.4268, 1.4170, 1.3911, 1.4066, 1.3985, 1.4004, 1.2937, 1.3323,
         1.3388, 1.3370, 1.3281, 1.3085, 1.2885, 1.3307, 1.3681, 1.3056, 1.3131],
        [1.2737, 1.3013, 1.2654, 1.2410, 1.3056, 1.2785, 1.2864, 1.2714, 1.2714,
         1.3353, 1.2653, 1.3483, 1.3264, 1.3221, 1.3051, 1.3330, 1.3251, 1.0989,
         1.3194, 1.3058, 1.3603, 1.3305, 1.2941, 1.2560, 1.3104, 1.2825, 1.2825,
         2.6745, 2.2569, 2.0278, 2.1319, 2.6601, 2.0370, 2.6115, 2.0452, 2.0294,
         1.4101, 1.4410, 1.3930, 1.3837, 1.4213, 1.3902, 1.4101, 1.1855, 1.3563,
         1.4026, 1.3104, 1.2200, 1.2772, 1.3970, 1.2380, 1.4333, 1.2742, 1.3299],
        [1.7442, 1.3965, 0.6185, 0.8433, 1.2009, 1.6251, 1.5563, 1.7418, 1.7418,
         1.6323, 1.3773, 1.4489, 0.9767, 1.7369, 0.2617, 1.6171, 1.7544, 1.2811,
         1.3375, 0.8924, 0.7714, 1.1121, 1.5978, 1.6960, 1.3504, 1.7512, 1.7512,
         0.7482, 0.8415, 1.7252, 1.4850, 0.8517, 1.6667, 1.1733, 1.7730, 1.7090,
         0.6710, 0.4423, 0.3986, 0.6204, 0.9218, 1.0957, 0.5692, 7.5028, 6.2962,
         0.7906, 1.2889, 1.3750, 1.6242, 1.0467, 1.6140, 0.4326, 1.6585, 1.7929],
        [1.3326, 1.3600, 1.4182, 1.3957, 1.3662, 1.3373, 1.3012, 1.3304, 1.3304,
         1.2999, 1.3948, 1.3072, 1.4200, 1.3814, 1.4615, 1.2976, 1.3848, 1.3086,
         1.3783, 1.4063, 1.4189, 1.3887, 1.3537, 1.3444, 1.3113, 1.3420, 1.3420,
         1.3831, 1.4350, 1.3630, 1.2023, 1.3212, 1.2233, 1.3897, 1.2391, 1.3654,
         1.4684, 1.2059, 1.4899, 1.4762, 1.1001, 1.0115, 1.4734, 1.4462, 0.9050,
         2.6766, 2.2789, 2.7055, 2.4926, 1.9807, 1.7343, 2.5633, 2.5370, 1.7202]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 119 : 182.41771384224475
Test loss for epoch 119 : 182.43538701684122
Test Precision for epoch 119 : 0.26153846153846155
Test Recall for epoch 119 : 0.26153846153846155
Test F1 for epoch 119 : 0.26153846153846155


theta for epoch 120 : tensor([[2.2383, 2.2624, 2.3270, 2.3949, 2.3622, 2.2425, 2.3445, 2.2364, 2.2364,
         1.3136, 1.3232, 1.3270, 1.3401, 1.3003, 1.3831, 1.3113, 1.3037, 1.2778,
         1.2973, 1.2813, 1.2945, 1.3083, 1.2725, 1.2640, 1.2892, 1.2608, 1.2608,
         1.3015, 1.3555, 1.2811, 1.3068, 1.3471, 1.2932, 1.3085, 1.2446, 1.2835,
         1.3901, 1.4216, 1.4119, 1.3978, 1.4011, 1.3433, 1.3951, 1.3851, 1.3378,
         1.3802, 1.3309, 1.3220, 1.3029, 1.3747, 1.3244, 1.4106, 1.2999, 1.3074],
        [1.3320, 1.2276, 1.0446, 1.2674, 1.3391, 1.3822, 1.3028, 1.3752, 1.3752,
         1.6310, 1.8711, 1.6140, 2.3920, 1.6609, 4.0274, 1.7273, 1.5573, 3.7355,
         1.1691, 1.2401, 1.0125, 1.2154, 1.3533, 1.3887, 1.3648, 1.3867, 1.3867,
         1.3355, 1.0926, 1.4074, 1.3826, 1.1708, 1.4190, 1.4258, 1.3728, 1.3834,
         1.4207, 1.5427, 1.4831, 1.4109, 1.3952, 1.5055, 1.4674, 0.6150, 1.4504,
         1.0641, 1.4550, 1.4426, 1.4279, 1.1049, 1.4468, 0.8889, 1.4249, 1.4326],
        [1.2566, 1.2842, 1.3428, 1.3195, 1.2888, 1.2613, 1.2686, 1.2543, 1.2543,
         1.3185, 1.3285, 1.3320, 1.3444, 1.3052, 1.3291, 1.3162, 1.2961, 1.2364,
         2.2938, 2.3506, 2.4642, 2.4010, 2.1831, 2.2639, 2.3092, 2.1738, 2.1738,
         1.3416, 1.3154, 1.2876, 1.3126, 1.3421, 1.2993, 1.3148, 1.2950, 1.2900,
         1.3952, 1.4267, 1.4168, 1.3909, 1.4065, 1.3984, 1.4002, 1.2930, 1.3317,
         1.3385, 1.3367, 1.3277, 1.3082, 1.2882, 1.3304, 1.3678, 1.3052, 1.3128],
        [1.2731, 1.3007, 1.2656, 1.2412, 1.3051, 1.2778, 1.2858, 1.2708, 1.2708,
         1.3348, 1.2652, 1.3477, 1.3264, 1.3215, 1.3048, 1.3324, 1.3245, 1.0997,
         1.3188, 1.3059, 1.3597, 1.3300, 1.2936, 1.2558, 1.3099, 1.2820, 1.2820,
         2.6787, 2.2627, 2.0328, 2.1370, 2.6647, 2.0421, 2.6161, 2.0501, 2.0345,
         1.4097, 1.4407, 1.3930, 1.3837, 1.4209, 1.3904, 1.4098, 1.1859, 1.3555,
         1.4022, 1.3105, 1.2198, 1.2768, 1.3965, 1.2382, 1.4329, 1.2736, 1.3294],
        [1.7454, 1.3976, 0.6198, 0.8444, 1.2021, 1.6263, 1.5575, 1.7430, 1.7430,
         1.6333, 1.3777, 1.4498, 0.9776, 1.7380, 0.2632, 1.6181, 1.7555, 1.2809,
         1.3387, 0.8936, 0.7725, 1.1135, 1.5991, 1.6970, 1.3518, 1.7524, 1.7524,
         0.7494, 0.8432, 1.7265, 1.4866, 0.8523, 1.6673, 1.1741, 1.7744, 1.7101,
         0.6664, 0.4380, 0.3947, 0.6160, 0.9160, 1.0884, 0.5647, 7.5525, 6.3261,
         0.7919, 1.2899, 1.3762, 1.6249, 1.0481, 1.6146, 0.4340, 1.6600, 1.7942],
        [1.3323, 1.3596, 1.4177, 1.3952, 1.3658, 1.3370, 1.3009, 1.3301, 1.3301,
         1.2995, 1.3948, 1.3071, 1.4197, 1.3809, 1.4612, 1.2972, 1.3843, 1.3082,
         1.3779, 1.4059, 1.4185, 1.3883, 1.3534, 1.3441, 1.3108, 1.3417, 1.3417,
         1.3829, 1.4347, 1.3625, 1.2017, 1.3218, 1.2237, 1.3895, 1.2387, 1.3650,
         1.4681, 1.2052, 1.4897, 1.4759, 1.0993, 1.0109, 1.4732, 1.4465, 0.9046,
         2.6813, 2.2829, 2.7123, 2.4959, 1.9845, 1.7377, 2.5673, 2.5446, 1.7236]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 120 : 182.40571791177507
Test loss for epoch 120 : 182.42376669308578
Test Precision for epoch 120 : 0.26153846153846155
Test Recall for epoch 120 : 0.26153846153846155
Test F1 for epoch 120 : 0.26153846153846155


theta for epoch 121 : tensor([[2.2429, 2.2670, 2.3316, 2.4000, 2.3673, 2.2470, 2.3495, 2.2410, 2.2410,
         1.3131, 1.3228, 1.3265, 1.3397, 1.2997, 1.3826, 1.3108, 1.3032, 1.2773,
         1.2968, 1.2809, 1.2939, 1.3078, 1.2721, 1.2636, 1.2888, 1.2604, 1.2604,
         1.3011, 1.3550, 1.2806, 1.3063, 1.3467, 1.2927, 1.3082, 1.2441, 1.2830,
         1.3899, 1.4215, 1.4117, 1.3976, 1.4010, 1.3433, 1.3949, 1.3845, 1.3372,
         1.3798, 1.3306, 1.3217, 1.3027, 1.3742, 1.3241, 1.4102, 1.2996, 1.3071],
        [1.3317, 1.2277, 1.0444, 1.2672, 1.3392, 1.3819, 1.3026, 1.3749, 1.3749,
         1.6327, 1.8734, 1.6164, 2.3934, 1.6633, 4.0414, 1.7291, 1.5595, 3.7507,
         1.1689, 1.2399, 1.0128, 1.2152, 1.3530, 1.3884, 1.3645, 1.3864, 1.3864,
         1.3353, 1.0922, 1.4070, 1.3823, 1.1707, 1.4187, 1.4257, 1.3724, 1.3833,
         1.4209, 1.5427, 1.4828, 1.4108, 1.3954, 1.5056, 1.4672, 0.6150, 1.4505,
         1.0641, 1.4547, 1.4424, 1.4276, 1.1047, 1.4465, 0.8889, 1.4246, 1.4322],
        [1.2563, 1.2838, 1.3424, 1.3192, 1.2886, 1.2610, 1.2683, 1.2540, 1.2540,
         1.3181, 1.3280, 1.3315, 1.3440, 1.3047, 1.3289, 1.3157, 1.2956, 1.2361,
         2.2988, 2.3552, 2.4688, 2.4058, 2.1878, 2.2689, 2.3137, 2.1784, 2.1784,
         1.3413, 1.3150, 1.2871, 1.3122, 1.3418, 1.2989, 1.3146, 1.2946, 1.2895,
         1.3950, 1.4266, 1.4167, 1.3908, 1.4064, 1.3984, 1.4001, 1.2924, 1.3312,
         1.3382, 1.3364, 1.3274, 1.3080, 1.2880, 1.3300, 1.3675, 1.3049, 1.3124],
        [1.2727, 1.3003, 1.2659, 1.2416, 1.3047, 1.2774, 1.2854, 1.2704, 1.2704,
         1.3343, 1.2651, 1.3472, 1.3265, 1.3210, 1.3045, 1.3319, 1.3239, 1.1005,
         1.3184, 1.3062, 1.3593, 1.3296, 1.2932, 1.2557, 1.3095, 1.2815, 1.2815,
         2.6828, 2.2682, 2.0377, 2.1419, 2.6690, 2.0470, 2.6204, 2.0549, 2.0394,
         1.4094, 1.4406, 1.3933, 1.3838, 1.4208, 1.3907, 1.4097, 1.1866, 1.3549,
         1.4018, 1.3106, 1.2198, 1.2765, 1.3961, 1.2384, 1.4325, 1.2731, 1.3289],
        [1.7466, 1.3988, 0.6212, 0.8456, 1.2033, 1.6275, 1.5587, 1.7442, 1.7442,
         1.6342, 1.3781, 1.4507, 0.9784, 1.7391, 0.2646, 1.6191, 1.7566, 1.2807,
         1.3399, 0.8947, 0.7736, 1.1148, 1.6003, 1.6979, 1.3531, 1.7536, 1.7536,
         0.7504, 0.8447, 1.7277, 1.4881, 0.8528, 1.6678, 1.1748, 1.7756, 1.7110,
         0.6620, 0.4337, 0.3908, 0.6117, 0.9103, 1.0815, 0.5604, 7.6022, 6.3557,
         0.7933, 1.2908, 1.3772, 1.6257, 1.0495, 1.6152, 0.4354, 1.6615, 1.7954],
        [1.3320, 1.3593, 1.4172, 1.3948, 1.3655, 1.3368, 1.3006, 1.3298, 1.3298,
         1.2990, 1.3947, 1.3068, 1.4192, 1.3803, 1.4608, 1.2967, 1.3837, 1.3078,
         1.3775, 1.4054, 1.4181, 1.3879, 1.3530, 1.3437, 1.3103, 1.3413, 1.3413,
         1.3824, 1.4342, 1.3619, 1.2009, 1.3220, 1.2239, 1.3892, 1.2381, 1.3644,
         1.4678, 1.2046, 1.4895, 1.4756, 1.0986, 1.0102, 1.4730, 1.4468, 0.9043,
         2.6862, 2.2870, 2.7192, 2.4993, 1.9884, 1.7411, 2.5714, 2.5522, 1.7270]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 121 : 182.39390352591457
Test loss for epoch 121 : 182.41234230332051
Test Precision for epoch 121 : 0.26153846153846155
Test Recall for epoch 121 : 0.26153846153846155
Test F1 for epoch 121 : 0.26153846153846155


theta for epoch 122 : tensor([[2.2474, 2.2716, 2.3362, 2.4050, 2.3723, 2.2515, 2.3544, 2.2455, 2.2455,
         1.3128, 1.3224, 1.3261, 1.3393, 1.2993, 1.3822, 1.3105, 1.3027, 1.2770,
         1.2964, 1.2804, 1.2934, 1.3074, 1.2717, 1.2632, 1.2884, 1.2601, 1.2601,
         1.3007, 1.3544, 1.2801, 1.3058, 1.3463, 1.2921, 1.3079, 1.2436, 1.2825,
         1.3898, 1.4216, 1.4117, 1.3976, 1.4011, 1.3433, 1.3949, 1.3841, 1.3369,
         1.3794, 1.3302, 1.3213, 1.3024, 1.3737, 1.3237, 1.4096, 1.2992, 1.3067],
        [1.3315, 1.2277, 1.0441, 1.2669, 1.3392, 1.3816, 1.3023, 1.3746, 1.3746,
         1.6344, 1.8757, 1.6188, 2.3950, 1.6657, 4.0555, 1.7310, 1.5618, 3.7660,
         1.1687, 1.2396, 1.0130, 1.2149, 1.3527, 1.3880, 1.3642, 1.3861, 1.3861,
         1.3351, 1.0919, 1.4065, 1.3820, 1.1705, 1.4183, 1.4255, 1.3719, 1.3831,
         1.4211, 1.5427, 1.4827, 1.4107, 1.3957, 1.5059, 1.4670, 0.6150, 1.4507,
         1.0640, 1.4543, 1.4421, 1.4273, 1.1044, 1.4461, 0.8889, 1.4241, 1.4318],
        [1.2559, 1.2834, 1.3418, 1.3188, 1.2883, 1.2607, 1.2680, 1.2537, 1.2537,
         1.3177, 1.3276, 1.3311, 1.3437, 1.3043, 1.3287, 1.3154, 1.2952, 1.2359,
         2.3037, 2.3598, 2.4735, 2.4107, 2.1925, 2.2739, 2.3183, 2.1830, 2.1830,
         1.3410, 1.3146, 1.2866, 1.3118, 1.3414, 1.2984, 1.3143, 1.2941, 1.2890,
         1.3950, 1.4267, 1.4167, 1.3907, 1.4064, 1.3985, 1.4001, 1.2919, 1.3309,
         1.3379, 1.3360, 1.3270, 1.3077, 1.2877, 1.3296, 1.3672, 1.3045, 1.3120],
        [1.2722, 1.2998, 1.2662, 1.2420, 1.3043, 1.2769, 1.2850, 1.2699, 1.2699,
         1.3339, 1.2650, 1.3467, 1.3265, 1.3205, 1.3042, 1.3315, 1.3234, 1.1015,
         1.3179, 1.3064, 1.3588, 1.3291, 1.2927, 1.2556, 1.3091, 1.2811, 1.2811,
         2.6868, 2.2738, 2.0426, 2.1469, 2.6734, 2.0520, 2.6248, 2.0597, 2.0443,
         1.4092, 1.4406, 1.3935, 1.3840, 1.4207, 1.3911, 1.4097, 1.1873, 1.3544,
         1.4014, 1.3107, 1.2196, 1.2760, 1.3956, 1.2386, 1.4320, 1.2726, 1.3283],
        [1.7479, 1.3999, 0.6226, 0.8469, 1.2046, 1.6288, 1.5600, 1.7455, 1.7455,
         1.6353, 1.3786, 1.4517, 0.9795, 1.7403, 0.2662, 1.6201, 1.7578, 1.2806,
         1.3412, 0.8960, 0.7749, 1.1161, 1.6016, 1.6988, 1.3546, 1.7549, 1.7549,
         0.7514, 0.8463, 1.7288, 1.4895, 0.8534, 1.6683, 1.1755, 1.7768, 1.7119,
         0.6576, 0.4295, 0.3870, 0.6075, 0.9047, 1.0747, 0.5561, 7.6516, 6.3848,
         0.7947, 1.2918, 1.3784, 1.6266, 1.0509, 1.6157, 0.4368, 1.6629, 1.7965],
        [1.3316, 1.3588, 1.4166, 1.3943, 1.3651, 1.3364, 1.3002, 1.3294, 1.3294,
         1.2985, 1.3947, 1.3066, 1.4188, 1.3798, 1.4604, 1.2962, 1.3831, 1.3073,
         1.3769, 1.4049, 1.4176, 1.3874, 1.3525, 1.3432, 1.3096, 1.3408, 1.3408,
         1.3818, 1.4335, 1.3612, 1.2001, 1.3221, 1.2238, 1.3886, 1.2373, 1.3636,
         1.4676, 1.2040, 1.4893, 1.4754, 1.0979, 1.0096, 1.4728, 1.4471, 0.9039,
         2.6914, 2.2914, 2.7264, 2.5030, 1.9924, 1.7446, 2.5758, 2.5601, 1.7305]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 122 : 182.38227145399574
Test loss for epoch 122 : 182.40103807086163
Test Precision for epoch 122 : 0.26153846153846155
Test Recall for epoch 122 : 0.26153846153846155
Test F1 for epoch 122 : 0.26153846153846155


theta for epoch 123 : tensor([[2.2519, 2.2762, 2.3408, 2.4100, 2.3773, 2.2561, 2.3593, 2.2500, 2.2500,
         1.3124, 1.3221, 1.3258, 1.3390, 1.2990, 1.3819, 1.3101, 1.3023, 1.2766,
         1.2960, 1.2799, 1.2928, 1.3069, 1.2713, 1.2628, 1.2880, 1.2597, 1.2597,
         1.3003, 1.3539, 1.2796, 1.3053, 1.3459, 1.2917, 1.3076, 1.2432, 1.2821,
         1.3897, 1.4216, 1.4117, 1.3975, 1.4011, 1.3434, 1.3948, 1.3837, 1.3365,
         1.3787, 1.3296, 1.3207, 1.3020, 1.3730, 1.3232, 1.4090, 1.2986, 1.3061],
        [1.3311, 1.2277, 1.0438, 1.2665, 1.3392, 1.3813, 1.3020, 1.3743, 1.3743,
         1.6361, 1.8779, 1.6212, 2.3965, 1.6681, 4.0696, 1.7329, 1.5640, 3.7813,
         1.1685, 1.2394, 1.0133, 1.2148, 1.3525, 1.3878, 1.3639, 1.3858, 1.3858,
         1.3349, 1.0916, 1.4062, 1.3817, 1.1704, 1.4179, 1.4254, 1.3715, 1.3830,
         1.4214, 1.5428, 1.4826, 1.4107, 1.3960, 1.5061, 1.4669, 0.6151, 1.4510,
         1.0638, 1.4539, 1.4417, 1.4269, 1.1040, 1.4457, 0.8889, 1.4236, 1.4313],
        [1.2555, 1.2829, 1.3412, 1.3182, 1.2878, 1.2602, 1.2676, 1.2532, 1.2532,
         1.3174, 1.3273, 1.3307, 1.3434, 1.3039, 1.3285, 1.3150, 1.2949, 1.2357,
         2.3086, 2.3645, 2.4783, 2.4157, 2.1972, 2.2789, 2.3229, 2.1877, 2.1877,
         1.3406, 1.3142, 1.2862, 1.3114, 1.3410, 1.2980, 1.3140, 1.2937, 1.2886,
         1.3949, 1.4268, 1.4167, 1.3907, 1.4064, 1.3986, 1.4001, 1.2914, 1.3305,
         1.3373, 1.3354, 1.3264, 1.3073, 1.2872, 1.3291, 1.3666, 1.3039, 1.3115],
        [1.2715, 1.2992, 1.2664, 1.2422, 1.3036, 1.2762, 1.2843, 1.2692, 1.2692,
         1.3334, 1.2649, 1.3462, 1.3265, 1.3200, 1.3039, 1.3310, 1.3229, 1.1023,
         1.3173, 1.3065, 1.3582, 1.3285, 1.2921, 1.2553, 1.3086, 1.2805, 1.2805,
         2.6911, 2.2796, 2.0477, 2.1521, 2.6779, 2.0571, 2.6293, 2.0647, 2.0494,
         1.4090, 1.4405, 1.3938, 1.3841, 1.4205, 1.3915, 1.4096, 1.1881, 1.3539,
         1.4007, 1.3106, 1.2193, 1.2754, 1.3949, 1.2386, 1.4314, 1.2718, 1.3275],
        [1.7491, 1.4012, 0.6241, 0.8482, 1.2060, 1.6300, 1.5613, 1.7467, 1.7467,
         1.6364, 1.3793, 1.4529, 0.9806, 1.7415, 0.2680, 1.6213, 1.7591, 1.2807,
         1.3426, 0.8974, 0.7762, 1.1176, 1.6029, 1.6997, 1.3561, 1.7561, 1.7561,
         0.7526, 0.8481, 1.7301, 1.4911, 0.8542, 1.6691, 1.1763, 1.7782, 1.7130,
         0.6532, 0.4253, 0.3832, 0.6032, 0.8992, 1.0680, 0.5517, 7.7007, 6.4134,
         0.7962, 1.2927, 1.3795, 1.6274, 1.0523, 1.6162, 0.4384, 1.6643, 1.7976],
        [1.3311, 1.3583, 1.4159, 1.3937, 1.3645, 1.3360, 1.2997, 1.3290, 1.3290,
         1.2981, 1.3946, 1.3064, 1.4184, 1.3793, 1.4601, 1.2958, 1.3826, 1.3069,
         1.3764, 1.4044, 1.4171, 1.3870, 1.3520, 1.3428, 1.3091, 1.3404, 1.3404,
         1.3813, 1.4330, 1.3606, 1.1993, 1.3222, 1.2239, 1.3882, 1.2367, 1.3631,
         1.4675, 1.2035, 1.4893, 1.4753, 1.0974, 1.0091, 1.4728, 1.4474, 0.9036,
         2.6964, 2.2956, 2.7334, 2.5065, 1.9962, 1.7480, 2.5800, 2.5678, 1.7339]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 123 : 182.37080879348065
Test loss for epoch 123 : 182.38991673183182
Test Precision for epoch 123 : 0.26153846153846155
Test Recall for epoch 123 : 0.26153846153846155
Test F1 for epoch 123 : 0.26153846153846155


theta for epoch 124 : tensor([[2.2565, 2.2809, 2.3455, 2.4151, 2.3825, 2.2607, 2.3644, 2.2546, 2.2546,
         1.3120, 1.3216, 1.3253, 1.3386, 1.2985, 1.3814, 1.3097, 1.3019, 1.2762,
         1.2954, 1.2793, 1.2922, 1.3064, 1.2708, 1.2623, 1.2875, 1.2592, 1.2592,
         1.2999, 1.3534, 1.2792, 1.3048, 1.3455, 1.2911, 1.3072, 1.2427, 1.2816,
         1.3896, 1.4216, 1.4116, 1.3974, 1.4011, 1.3435, 1.3948, 1.3833, 1.3362,
         1.3782, 1.3291, 1.3202, 1.3016, 1.3724, 1.3227, 1.4084, 1.2981, 1.3057],
        [1.3309, 1.2277, 1.0436, 1.2663, 1.3392, 1.3810, 1.3018, 1.3740, 1.3740,
         1.6378, 1.8802, 1.6235, 2.3980, 1.6705, 4.0836, 1.7347, 1.5661, 3.7965,
         1.1684, 1.2392, 1.0135, 1.2146, 1.3522, 1.3875, 1.3637, 1.3856, 1.3856,
         1.3348, 1.0914, 1.4059, 1.3815, 1.1704, 1.4177, 1.4254, 1.3712, 1.3830,
         1.4217, 1.5429, 1.4826, 1.4107, 1.3964, 1.5064, 1.4669, 0.6152, 1.4512,
         1.0638, 1.4536, 1.4414, 1.4266, 1.1038, 1.4453, 0.8890, 1.4232, 1.4309],
        [1.2550, 1.2824, 1.3406, 1.3177, 1.2874, 1.2597, 1.2672, 1.2528, 1.2528,
         1.3170, 1.3269, 1.3304, 1.3431, 1.3035, 1.3283, 1.3147, 1.2946, 1.2355,
         2.3136, 2.3692, 2.4831, 2.4207, 2.2019, 2.2839, 2.3276, 2.1924, 2.1924,
         1.3403, 1.3138, 1.2857, 1.3110, 1.3407, 1.2975, 1.3137, 1.2933, 1.2881,
         1.3948, 1.4268, 1.4166, 1.3906, 1.4064, 1.3986, 1.4000, 1.2910, 1.3301,
         1.3369, 1.3349, 1.3259, 1.3069, 1.2868, 1.3286, 1.3662, 1.3034, 1.3110],
        [1.2708, 1.2985, 1.2665, 1.2424, 1.3030, 1.2756, 1.2836, 1.2685, 1.2685,
         1.3328, 1.2648, 1.3457, 1.3265, 1.3194, 1.3035, 1.3305, 1.3223, 1.1032,
         1.3167, 1.3065, 1.3575, 1.3279, 1.2915, 1.2550, 1.3080, 1.2799, 1.2799,
         2.6954, 2.2855, 2.0528, 2.1573, 2.6825, 2.0622, 2.6338, 2.0697, 2.0546,
         1.4087, 1.4404, 1.3940, 1.3842, 1.4204, 1.3918, 1.4095, 1.1889, 1.3533,
         1.4001, 1.3106, 1.2190, 1.2748, 1.3942, 1.2387, 1.4308, 1.2711, 1.3268],
        [1.7503, 1.4024, 0.6256, 0.8495, 1.2073, 1.6313, 1.5625, 1.7479, 1.7479,
         1.6376, 1.3800, 1.4540, 0.9818, 1.7427, 0.2698, 1.6225, 1.7603, 1.2807,
         1.3439, 0.8987, 0.7776, 1.1191, 1.6042, 1.7007, 1.3576, 1.7574, 1.7574,
         0.7538, 0.8498, 1.7314, 1.4927, 0.8549, 1.6699, 1.1772, 1.7795, 1.7140,
         0.6488, 0.4212, 0.3794, 0.5989, 0.8938, 1.0615, 0.5474, 7.7495, 6.4415,
         0.7977, 1.2938, 1.3807, 1.6284, 1.0538, 1.6168, 0.4400, 1.6658, 1.7988],
        [1.3307, 1.3579, 1.4153, 1.3932, 1.3641, 1.3356, 1.2992, 1.3285, 1.3285,
         1.2977, 1.3946, 1.3062, 1.4181, 1.3788, 1.4598, 1.2954, 1.3821, 1.3066,
         1.3760, 1.4039, 1.4167, 1.3865, 1.3516, 1.3423, 1.3085, 1.3399, 1.3399,
         1.3808, 1.4326, 1.3601, 1.1986, 1.3223, 1.2239, 1.3879, 1.2362, 1.3625,
         1.4674, 1.2030, 1.4892, 1.4752, 1.0968, 1.0086, 1.4727, 1.4477, 0.9032,
         2.7014, 2.2998, 2.7405, 2.5101, 2.0000, 1.7513, 2.5842, 2.5755, 1.7372]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 124 : 182.3595314956022
Test loss for epoch 124 : 182.37894831918277
Test Precision for epoch 124 : 0.26153846153846155
Test Recall for epoch 124 : 0.26153846153846155
Test F1 for epoch 124 : 0.26153846153846155


theta for epoch 125 : tensor([[2.2611, 2.2855, 2.3501, 2.4202, 2.3875, 2.2652, 2.3694, 2.2592, 2.2592,
         1.3116, 1.3212, 1.3249, 1.3383, 1.2981, 1.3809, 1.3093, 1.3015, 1.2758,
         1.2949, 1.2787, 1.2917, 1.3059, 1.2703, 1.2619, 1.2870, 1.2587, 1.2587,
         1.2994, 1.3528, 1.2787, 1.3043, 1.3450, 1.2906, 1.3068, 1.2422, 1.2811,
         1.3894, 1.4217, 1.4115, 1.3973, 1.4011, 1.3435, 1.3947, 1.3829, 1.3358,
         1.3778, 1.3288, 1.3199, 1.3014, 1.3720, 1.3224, 1.4080, 1.2978, 1.3054],
        [1.3307, 1.2276, 1.0434, 1.2660, 1.3392, 1.3807, 1.3015, 1.3738, 1.3738,
         1.6395, 1.8824, 1.6258, 2.3996, 1.6728, 4.0976, 1.7365, 1.5682, 3.8118,
         1.1682, 1.2390, 1.0138, 1.2144, 1.3520, 1.3873, 1.3634, 1.3853, 1.3853,
         1.3346, 1.0911, 1.4056, 1.3812, 1.1702, 1.4173, 1.4253, 1.3708, 1.3829,
         1.4220, 1.5430, 1.4825, 1.4106, 1.3967, 1.5067, 1.4668, 0.6152, 1.4513,
         1.0639, 1.4534, 1.4413, 1.4265, 1.1037, 1.4452, 0.8891, 1.4230, 1.4307],
        [1.2546, 1.2819, 1.3400, 1.3171, 1.2869, 1.2593, 1.2668, 1.2524, 1.2524,
         1.3167, 1.3266, 1.3300, 1.3428, 1.3032, 1.3282, 1.3143, 1.2942, 1.2353,
         2.3185, 2.3739, 2.4879, 2.4256, 2.2065, 2.2889, 2.3322, 2.1970, 2.1970,
         1.3399, 1.3134, 1.2853, 1.3105, 1.3403, 1.2971, 1.3134, 1.2928, 1.2876,
         1.3947, 1.4268, 1.4166, 1.3906, 1.4064, 1.3987, 1.4000, 1.2905, 1.3297,
         1.3366, 1.3346, 1.3256, 1.3067, 1.2865, 1.3284, 1.3659, 1.3031, 1.3108],
        [1.2702, 1.2979, 1.2667, 1.2427, 1.3025, 1.2750, 1.2831, 1.2680, 1.2680,
         1.3324, 1.2648, 1.3452, 1.3265, 1.3189, 1.3032, 1.3300, 1.3218, 1.1041,
         1.3161, 1.3066, 1.3569, 1.3274, 1.2910, 1.2549, 1.3075, 1.2793, 1.2793,
         2.6995, 2.2912, 2.0577, 2.1624, 2.6869, 2.0672, 2.6383, 2.0746, 2.0596,
         1.4085, 1.4404, 1.3942, 1.3843, 1.4202, 1.3921, 1.4094, 1.1898, 1.3528,
         1.3997, 1.3107, 1.2189, 1.2744, 1.3938, 1.2390, 1.4304, 1.2706, 1.3264],
        [1.7515, 1.4036, 0.6269, 0.8507, 1.2086, 1.6324, 1.5637, 1.7491, 1.7491,
         1.6387, 1.3805, 1.4551, 0.9828, 1.7438, 0.2714, 1.6236, 1.7615, 1.2806,
         1.3452, 0.9000, 0.7788, 1.1204, 1.6054, 1.7015, 1.3591, 1.7585, 1.7585,
         0.7548, 0.8512, 1.7325, 1.4942, 0.8555, 1.6706, 1.1778, 1.7807, 1.7149,
         0.6446, 0.4172, 0.3758, 0.5949, 0.8886, 1.0553, 0.5433, 7.7983, 6.4693,
         0.7992, 1.2948, 1.3820, 1.6294, 1.0553, 1.6175, 0.4415, 1.6673, 1.8000],
        [1.3303, 1.3574, 1.4148, 1.3928, 1.3636, 1.3352, 1.2988, 1.3281, 1.3281,
         1.2973, 1.3945, 1.3060, 1.4178, 1.3784, 1.4595, 1.2950, 1.3816, 1.3062,
         1.3755, 1.4034, 1.4162, 1.3861, 1.3511, 1.3419, 1.3079, 1.3395, 1.3395,
         1.3802, 1.4320, 1.3595, 1.1978, 1.3223, 1.2239, 1.3874, 1.2356, 1.3620,
         1.4672, 1.2024, 1.4891, 1.4750, 1.0962, 1.0080, 1.4726, 1.4479, 0.9028,
         2.7066, 2.3041, 2.7477, 2.5138, 2.0038, 1.7546, 2.5885, 2.5832, 1.7405]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 125 : 182.34842045614573
Test loss for epoch 125 : 182.36818186519758
Test Precision for epoch 125 : 0.26153846153846155
Test Recall for epoch 125 : 0.26153846153846155
Test F1 for epoch 125 : 0.26153846153846155


theta for epoch 126 : tensor([[2.2656, 2.2900, 2.3547, 2.4251, 2.3925, 2.2697, 2.3743, 2.2637, 2.2637,
         1.3112, 1.3208, 1.3245, 1.3379, 1.2978, 1.3805, 1.3090, 1.3011, 1.2754,
         1.2945, 1.2783, 1.2913, 1.3055, 1.2700, 1.2615, 1.2866, 1.2583, 1.2583,
         1.2990, 1.3522, 1.2783, 1.3038, 1.3446, 1.2901, 1.3065, 1.2417, 1.2807,
         1.3892, 1.4216, 1.4113, 1.3971, 1.4010, 1.3434, 1.3946, 1.3825, 1.3354,
         1.3775, 1.3285, 1.3196, 1.3012, 1.3716, 1.3221, 1.4076, 1.2976, 1.3051],
        [1.3304, 1.2276, 1.0431, 1.2657, 1.3392, 1.3804, 1.3013, 1.3735, 1.3735,
         1.6413, 1.8847, 1.6281, 2.4012, 1.6752, 4.1117, 1.7384, 1.5704, 3.8271,
         1.1680, 1.2388, 1.0140, 1.2142, 1.3518, 1.3870, 1.3632, 1.3850, 1.3850,
         1.3344, 1.0908, 1.4052, 1.3809, 1.1701, 1.4170, 1.4251, 1.3704, 1.3828,
         1.4222, 1.5430, 1.4823, 1.4105, 1.3969, 1.5068, 1.4666, 0.6151, 1.4513,
         1.0639, 1.4531, 1.4410, 1.4263, 1.1035, 1.4449, 0.8893, 1.4227, 1.4304],
        [1.2542, 1.2815, 1.3395, 1.3167, 1.2866, 1.2590, 1.2665, 1.2520, 1.2520,
         1.3163, 1.3262, 1.3296, 1.3425, 1.3028, 1.3280, 1.3140, 1.2939, 1.2351,
         2.3234, 2.3786, 2.4927, 2.4306, 2.2111, 2.2938, 2.3369, 2.2016, 2.2016,
         1.3395, 1.3130, 1.2848, 1.3101, 1.3399, 1.2966, 1.3131, 1.2923, 1.2872,
         1.3945, 1.4268, 1.4164, 1.3904, 1.4063, 1.3987, 1.3998, 1.2899, 1.3292,
         1.3364, 1.3343, 1.3252, 1.3065, 1.2863, 1.3281, 1.3656, 1.3028, 1.3105],
        [1.2697, 1.2974, 1.2670, 1.2431, 1.3020, 1.2745, 1.2826, 1.2675, 1.2675,
         1.3320, 1.2648, 1.3448, 1.3265, 1.3184, 1.3029, 1.3296, 1.3213, 1.1052,
         1.3157, 1.3068, 1.3565, 1.3269, 1.2906, 1.2548, 1.3071, 1.2789, 1.2789,
         2.7036, 2.2968, 2.0626, 2.1675, 2.6912, 2.0721, 2.6426, 2.0794, 2.0645,
         1.4082, 1.4403, 1.3944, 1.3845, 1.4200, 1.3924, 1.4093, 1.1907, 1.3523,
         1.3993, 1.3109, 1.2189, 1.2740, 1.3933, 1.2393, 1.4300, 1.2701, 1.3259],
        [1.7526, 1.4047, 0.6281, 0.8518, 1.2097, 1.6335, 1.5648, 1.7502, 1.7502,
         1.6397, 1.3811, 1.4562, 0.9837, 1.7449, 0.2729, 1.6246, 1.7626, 1.2805,
         1.3463, 0.9012, 0.7799, 1.1217, 1.6065, 1.7023, 1.3604, 1.7597, 1.7597,
         0.7556, 0.8526, 1.7336, 1.4956, 0.8560, 1.6713, 1.1784, 1.7819, 1.7158,
         0.6405, 0.4133, 0.3723, 0.5909, 0.8836, 1.0493, 0.5392, 7.8470, 6.4968,
         0.8006, 1.2957, 1.3831, 1.6303, 1.0566, 1.6180, 0.4428, 1.6687, 1.8012],
        [1.3300, 1.3571, 1.4145, 1.3924, 1.3633, 1.3349, 1.2985, 1.3279, 1.3279,
         1.2970, 1.3944, 1.3058, 1.4175, 1.3780, 1.4592, 1.2947, 1.3812, 1.3058,
         1.3752, 1.4031, 1.4159, 1.3858, 1.3508, 1.3416, 1.3074, 1.3392, 1.3392,
         1.3798, 1.4316, 1.3590, 1.1972, 1.3223, 1.2239, 1.3871, 1.2351, 1.3615,
         1.4670, 1.2019, 1.4889, 1.4748, 1.0956, 1.0075, 1.4725, 1.4480, 0.9024,
         2.7116, 2.3082, 2.7547, 2.5174, 2.0074, 1.7577, 2.5927, 2.5908, 1.7436]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 126 : 182.3374797456365
Test loss for epoch 126 : 182.3577312481128
Test Precision for epoch 126 : 0.26153846153846155
Test Recall for epoch 126 : 0.26153846153846155
Test F1 for epoch 126 : 0.26153846153846155


theta for epoch 127 : tensor([[2.2701, 2.2946, 2.3593, 2.4302, 2.3975, 2.2743, 2.3792, 2.2682, 2.2682,
         1.3108, 1.3204, 1.3241, 1.3375, 1.2973, 1.3800, 1.3085, 1.3006, 1.2750,
         1.2941, 1.2778, 1.2908, 1.3051, 1.2696, 1.2611, 1.2862, 1.2580, 1.2580,
         1.2987, 1.3518, 1.2780, 1.3035, 1.3443, 1.2898, 1.3063, 1.2415, 1.2805,
         1.3890, 1.4215, 1.4111, 1.3969, 1.4009, 1.3433, 1.3944, 1.3820, 1.3349,
         1.3771, 1.3281, 1.3192, 1.3009, 1.3711, 1.3218, 1.4072, 1.2972, 1.3048],
        [1.3302, 1.2275, 1.0429, 1.2655, 1.3393, 1.3802, 1.3011, 1.3733, 1.3733,
         1.6430, 1.8870, 1.6304, 2.4029, 1.6775, 4.1259, 1.7403, 1.5725, 3.8424,
         1.1678, 1.2386, 1.0142, 1.2140, 1.3515, 1.3867, 1.3629, 1.3847, 1.3847,
         1.3343, 1.0906, 1.4050, 1.3806, 1.1700, 1.4168, 1.4251, 1.3701, 1.3828,
         1.4223, 1.5430, 1.4821, 1.4104, 1.3971, 1.5070, 1.4664, 0.6150, 1.4513,
         1.0638, 1.4528, 1.4408, 1.4261, 1.1032, 1.4446, 0.8894, 1.4224, 1.4301],
        [1.2539, 1.2812, 1.3391, 1.3163, 1.2863, 1.2587, 1.2662, 1.2517, 1.2517,
         1.3160, 1.3259, 1.3293, 1.3422, 1.3024, 1.3278, 1.3137, 1.2936, 1.2349,
         2.3282, 2.3833, 2.4976, 2.4356, 2.2157, 2.2987, 2.3415, 2.2061, 2.2061,
         1.3392, 1.3127, 1.2845, 1.3098, 1.3396, 1.2963, 1.3129, 1.2920, 1.2869,
         1.3943, 1.4267, 1.4163, 1.3902, 1.4062, 1.3986, 1.3997, 1.2893, 1.3287,
         1.3360, 1.3339, 1.3248, 1.3063, 1.2860, 1.3277, 1.3653, 1.3024, 1.3101],
        [1.2693, 1.2970, 1.2673, 1.2434, 1.3016, 1.2741, 1.2822, 1.2670, 1.2670,
         1.3315, 1.2647, 1.3443, 1.3265, 1.3179, 1.3025, 1.3291, 1.3208, 1.1061,
         1.3152, 1.3069, 1.3560, 1.3264, 1.2902, 1.2547, 1.3066, 1.2785, 1.2785,
         2.7078, 2.3025, 2.0676, 2.1726, 2.6956, 2.0772, 2.6470, 2.0843, 2.0695,
         1.4079, 1.4401, 1.3945, 1.3845, 1.4198, 1.3926, 1.4091, 1.1915, 1.3518,
         1.3989, 1.3110, 1.2187, 1.2735, 1.3928, 1.2396, 1.4295, 1.2696, 1.3253],
        [1.7537, 1.4059, 0.6294, 0.8529, 1.2110, 1.6347, 1.5660, 1.7513, 1.7513,
         1.6408, 1.3816, 1.4572, 0.9847, 1.7460, 0.2744, 1.6256, 1.7637, 1.2804,
         1.3476, 0.9024, 0.7811, 1.1230, 1.6077, 1.7031, 1.3619, 1.7608, 1.7608,
         0.7565, 0.8541, 1.7348, 1.4971, 0.8566, 1.6722, 1.1790, 1.7832, 1.7168,
         0.6364, 0.4095, 0.3688, 0.5869, 0.8786, 1.0435, 0.5352, 7.8954, 6.5237,
         0.8020, 1.2966, 1.3842, 1.6313, 1.0579, 1.6184, 0.4442, 1.6701, 1.8022],
        [1.3297, 1.3569, 1.4142, 1.3922, 1.3630, 1.3347, 1.2982, 1.3276, 1.3276,
         1.2966, 1.3943, 1.3056, 1.4171, 1.3775, 1.4589, 1.2943, 1.3808, 1.3054,
         1.3749, 1.4027, 1.4156, 1.3854, 1.3505, 1.3413, 1.3069, 1.3389, 1.3389,
         1.3795, 1.4313, 1.3587, 1.1966, 1.3224, 1.2240, 1.3868, 1.2347, 1.3612,
         1.4668, 1.2012, 1.4887, 1.4746, 1.0949, 1.0068, 1.4723, 1.4479, 0.9019,
         2.7168, 2.3124, 2.7618, 2.5211, 2.0111, 1.7608, 2.5970, 2.5985, 1.7467]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 127 : 182.32670591972396
Test loss for epoch 127 : 182.34737829203144
Test Precision for epoch 127 : 0.26153846153846155
Test Recall for epoch 127 : 0.26153846153846155
Test F1 for epoch 127 : 0.26153846153846155


theta for epoch 128 : tensor([[2.2746, 2.2991, 2.3638, 2.4352, 2.4025, 2.2788, 2.3842, 2.2727, 2.2727,
         1.3104, 1.3200, 1.3236, 1.3371, 1.2969, 1.3795, 1.3081, 1.3002, 1.2745,
         1.2937, 1.2774, 1.2904, 1.3047, 1.2692, 1.2607, 1.2858, 1.2576, 1.2576,
         1.2985, 1.3515, 1.2778, 1.3032, 1.3441, 1.2895, 1.3061, 1.2412, 1.2803,
         1.3888, 1.4214, 1.4109, 1.3967, 1.4008, 1.3432, 1.3942, 1.3815, 1.3345,
         1.3767, 1.3277, 1.3187, 1.3006, 1.3707, 1.3214, 1.4068, 1.2967, 1.3044],
        [1.3300, 1.2275, 1.0427, 1.2653, 1.3393, 1.3800, 1.3008, 1.3731, 1.3731,
         1.6448, 1.8892, 1.6325, 2.4045, 1.6798, 4.1400, 1.7421, 1.5746, 3.8577,
         1.1676, 1.2384, 1.0145, 1.2138, 1.3513, 1.3865, 1.3627, 1.3845, 1.3845,
         1.3343, 1.0904, 1.4048, 1.3805, 1.1700, 1.4166, 1.4251, 1.3698, 1.3828,
         1.4225, 1.5430, 1.4819, 1.4103, 1.3973, 1.5071, 1.4663, 0.6150, 1.4513,
         1.0637, 1.4525, 1.4405, 1.4258, 1.1030, 1.4443, 0.8895, 1.4220, 1.4298],
        [1.2535, 1.2808, 1.3386, 1.3159, 1.2859, 1.2583, 1.2659, 1.2513, 1.2513,
         1.3156, 1.3255, 1.3289, 1.3418, 1.3021, 1.3276, 1.3133, 1.2933, 1.2347,
         2.3331, 2.3880, 2.5024, 2.4405, 2.2203, 2.3036, 2.3461, 2.2107, 2.2107,
         1.3390, 1.3124, 1.2841, 1.3094, 1.3394, 1.2960, 1.3127, 1.2917, 1.2866,
         1.3941, 1.4267, 1.4161, 1.3900, 1.4061, 1.3985, 1.3996, 1.2888, 1.3282,
         1.3356, 1.3335, 1.3244, 1.3060, 1.2856, 1.3274, 1.3649, 1.3020, 1.3098],
        [1.2687, 1.2964, 1.2676, 1.2438, 1.3011, 1.2736, 1.2816, 1.2665, 1.2665,
         1.3310, 1.2646, 1.3438, 1.3264, 1.3174, 1.3021, 1.3286, 1.3202, 1.1071,
         1.3147, 1.3070, 1.3554, 1.3259, 1.2897, 1.2545, 1.3062, 1.2780, 1.2780,
         2.7119, 2.3083, 2.0726, 2.1778, 2.7000, 2.0822, 2.6514, 2.0892, 2.0745,
         1.4075, 1.4399, 1.3946, 1.3846, 1.4195, 1.3929, 1.4089, 1.1924, 1.3513,
         1.3983, 1.3111, 1.2186, 1.2730, 1.3923, 1.2398, 1.4290, 1.2690, 1.3248],
        [1.7548, 1.4071, 0.6307, 0.8541, 1.2122, 1.6359, 1.5673, 1.7525, 1.7525,
         1.6419, 1.3822, 1.4583, 0.9857, 1.7471, 0.2760, 1.6267, 1.7648, 1.2804,
         1.3488, 0.9037, 0.7824, 1.1244, 1.6089, 1.7040, 1.3634, 1.7620, 1.7620,
         0.7575, 0.8556, 1.7361, 1.4987, 0.8573, 1.6732, 1.1797, 1.7845, 1.7179,
         0.6323, 0.4057, 0.3653, 0.5830, 0.8737, 1.0378, 0.5312, 7.9435, 6.5502,
         0.8034, 1.2975, 1.3853, 1.6323, 1.0592, 1.6190, 0.4457, 1.6715, 1.8033],
        [1.3293, 1.3564, 1.4137, 1.3917, 1.3625, 1.3342, 1.2977, 1.3271, 1.3271,
         1.2961, 1.3940, 1.3052, 1.4166, 1.3770, 1.4584, 1.2938, 1.3802, 1.3050,
         1.3744, 1.4022, 1.4151, 1.3850, 1.3500, 1.3408, 1.3063, 1.3384, 1.3384,
         1.3791, 1.4309, 1.3583, 1.1960, 1.3224, 1.2240, 1.3865, 1.2343, 1.3608,
         1.4665, 1.2006, 1.4885, 1.4743, 1.0942, 1.0061, 1.4720, 1.4478, 0.9012,
         2.7221, 2.3168, 2.7691, 2.5250, 2.0148, 1.7640, 2.6014, 2.6063, 1.7499]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 128 : 182.3160983721068
Test loss for epoch 128 : 182.3370634846851
Test Precision for epoch 128 : 0.26153846153846155
Test Recall for epoch 128 : 0.26153846153846155
Test F1 for epoch 128 : 0.26153846153846155


theta for epoch 129 : tensor([[2.2792, 2.3037, 2.3684, 2.4402, 2.4076, 2.2833, 2.3892, 2.2773, 2.2773,
         1.3100, 1.3196, 1.3232, 1.3367, 1.2965, 1.3791, 1.3077, 1.2998, 1.2741,
         1.2932, 1.2769, 1.2900, 1.3043, 1.2687, 1.2603, 1.2854, 1.2571, 1.2571,
         1.2980, 1.3509, 1.2774, 1.3028, 1.3437, 1.2891, 1.3057, 1.2407, 1.2798,
         1.3886, 1.4215, 1.4108, 1.3966, 1.4008, 1.3432, 1.3941, 1.3812, 1.3342,
         1.3761, 1.3272, 1.3182, 1.3002, 1.3701, 1.3209, 1.4062, 1.2962, 1.3039],
        [1.3297, 1.2274, 1.0425, 1.2650, 1.3393, 1.3798, 1.3006, 1.3728, 1.3728,
         1.6465, 1.8914, 1.6347, 2.4062, 1.6820, 4.1541, 1.7439, 1.5766, 3.8731,
         1.1674, 1.2382, 1.0147, 1.2137, 1.3511, 1.3863, 1.3624, 1.3843, 1.3843,
         1.3341, 1.0901, 1.4045, 1.3802, 1.1698, 1.4163, 1.4250, 1.3695, 1.3828,
         1.4228, 1.5432, 1.4819, 1.4103, 1.3976, 1.5074, 1.4663, 0.6150, 1.4513,
         1.0636, 1.4521, 1.4402, 1.4255, 1.1027, 1.4440, 0.8896, 1.4216, 1.4295],
        [1.2531, 1.2803, 1.3381, 1.3154, 1.2854, 1.2579, 1.2654, 1.2509, 1.2509,
         1.3153, 1.3252, 1.3286, 1.3415, 1.3018, 1.3274, 1.3130, 1.2930, 1.2345,
         2.3379, 2.3928, 2.5073, 2.4456, 2.2248, 2.3086, 2.3508, 2.2152, 2.2152,
         1.3386, 1.3120, 1.2837, 1.3090, 1.3390, 1.2955, 1.3124, 1.2913, 1.2861,
         1.3940, 1.4267, 1.4160, 1.3899, 1.4061, 1.3986, 1.3995, 1.2884, 1.3278,
         1.3352, 1.3330, 1.3239, 1.3056, 1.2852, 1.3269, 1.3645, 1.3015, 1.3093],
        [1.2682, 1.2959, 1.2678, 1.2441, 1.3006, 1.2730, 1.2811, 1.2660, 1.2660,
         1.3305, 1.2646, 1.3434, 1.3265, 1.3169, 1.3018, 1.3281, 1.3198, 1.1081,
         1.3142, 1.3071, 1.3549, 1.3255, 1.2892, 1.2544, 1.3057, 1.2775, 1.2775,
         2.7160, 2.3140, 2.0776, 2.1829, 2.7044, 2.0872, 2.6558, 2.0941, 2.0795,
         1.4073, 1.4399, 1.3948, 1.3847, 1.4194, 1.3932, 1.4088, 1.1934, 1.3509,
         1.3978, 1.3111, 1.2184, 1.2725, 1.3917, 1.2401, 1.4285, 1.2684, 1.3242],
        [1.7559, 1.4083, 0.6320, 0.8552, 1.2134, 1.6370, 1.5684, 1.7536, 1.7536,
         1.6430, 1.3829, 1.4595, 0.9867, 1.7482, 0.2777, 1.6278, 1.7660, 1.2804,
         1.3501, 0.9050, 0.7837, 1.1258, 1.6101, 1.7048, 1.3648, 1.7631, 1.7631,
         0.7584, 0.8570, 1.7372, 1.5002, 0.8579, 1.6741, 1.1803, 1.7858, 1.7188,
         0.6283, 0.4020, 0.3619, 0.5791, 0.8689, 1.0322, 0.5272, 7.9915, 6.5763,
         0.8048, 1.2983, 1.3864, 1.6332, 1.0605, 1.6194, 0.4471, 1.6729, 1.8044],
        [1.3288, 1.3560, 1.4133, 1.3913, 1.3620, 1.3338, 1.2972, 1.3267, 1.3267,
         1.2957, 1.3939, 1.3050, 1.4163, 1.3766, 1.4581, 1.2935, 1.3798, 1.3046,
         1.3741, 1.4018, 1.4148, 1.3846, 1.3496, 1.3405, 1.3057, 1.3380, 1.3380,
         1.3786, 1.4304, 1.3579, 1.1953, 1.3223, 1.2239, 1.3861, 1.2338, 1.3603,
         1.4664, 1.2000, 1.4884, 1.4742, 1.0937, 1.0056, 1.4720, 1.4478, 0.9008,
         2.7274, 2.3211, 2.7762, 2.5288, 2.0184, 1.7670, 2.6058, 2.6139, 1.7529]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 129 : 182.30564783384173
Test loss for epoch 129 : 182.32702474255098
Test Precision for epoch 129 : 0.26153846153846155
Test Recall for epoch 129 : 0.26153846153846155
Test F1 for epoch 129 : 0.26153846153846155


theta for epoch 130 : tensor([[2.2837, 2.3083, 2.3730, 2.4453, 2.4126, 2.2879, 2.3942, 2.2818, 2.2818,
         1.3096, 1.3192, 1.3228, 1.3363, 1.2962, 1.3786, 1.3074, 1.2994, 1.2737,
         1.2927, 1.2764, 1.2896, 1.3038, 1.2683, 1.2598, 1.2849, 1.2566, 1.2566,
         1.2975, 1.3503, 1.2769, 1.3022, 1.3431, 1.2885, 1.3053, 1.2402, 1.2794,
         1.3886, 1.4215, 1.4108, 1.3966, 1.4008, 1.3432, 1.3941, 1.3810, 1.3340,
         1.3757, 1.3268, 1.3177, 1.2998, 1.3696, 1.3205, 1.4058, 1.2957, 1.3035],
        [1.3295, 1.2272, 1.0423, 1.2648, 1.3392, 1.3795, 1.3003, 1.3725, 1.3725,
         1.6482, 1.8936, 1.6369, 2.4079, 1.6843, 4.1682, 1.7457, 1.5787, 3.8884,
         1.1672, 1.2379, 1.0149, 1.2135, 1.3509, 1.3860, 1.3621, 1.3840, 1.3840,
         1.3339, 1.0898, 1.4041, 1.3799, 1.1696, 1.4159, 1.4248, 1.3690, 1.3826,
         1.4231, 1.5433, 1.4819, 1.4103, 1.3979, 1.5077, 1.4663, 0.6150, 1.4514,
         1.0635, 1.4518, 1.4399, 1.4253, 1.1025, 1.4437, 0.8897, 1.4213, 1.4292],
        [1.2526, 1.2799, 1.3376, 1.3149, 1.2849, 1.2574, 1.2650, 1.2505, 1.2505,
         1.3150, 1.3249, 1.3282, 1.3412, 1.3015, 1.3272, 1.3127, 1.2927, 1.2343,
         2.3428, 2.3975, 2.5123, 2.4506, 2.2294, 2.3134, 2.3555, 2.2198, 2.2198,
         1.3381, 1.3116, 1.2832, 1.3085, 1.3385, 1.2950, 1.3120, 1.2907, 1.2856,
         1.3939, 1.4268, 1.4160, 1.3899, 1.4061, 1.3986, 1.3995, 1.2880, 1.3274,
         1.3348, 1.3326, 1.3235, 1.3052, 1.2848, 1.3265, 1.3641, 1.3011, 1.3089],
        [1.2676, 1.2953, 1.2680, 1.2443, 1.3000, 1.2725, 1.2805, 1.2654, 1.2654,
         1.3301, 1.2647, 1.3429, 1.3264, 1.3165, 1.3014, 1.3277, 1.3193, 1.1092,
         1.3137, 1.3072, 1.3544, 1.3249, 1.2887, 1.2542, 1.3052, 1.2770, 1.2770,
         2.7201, 2.3197, 2.0825, 2.1881, 2.7087, 2.0922, 2.6601, 2.0990, 2.0845,
         1.4072, 1.4399, 1.3951, 1.3850, 1.4193, 1.3935, 1.4088, 1.1945, 1.3505,
         1.3973, 1.3111, 1.2182, 1.2720, 1.3912, 1.2404, 1.4279, 1.2678, 1.3236],
        [1.7570, 1.4094, 0.6332, 0.8563, 1.2146, 1.6381, 1.5696, 1.7546, 1.7546,
         1.6441, 1.3835, 1.4607, 0.9877, 1.7493, 0.2793, 1.6289, 1.7671, 1.2804,
         1.3513, 0.9062, 0.7849, 1.1271, 1.6113, 1.7056, 1.3663, 1.7642, 1.7642,
         0.7591, 0.8583, 1.7383, 1.5016, 0.8584, 1.6749, 1.1807, 1.7869, 1.7197,
         0.6244, 0.3984, 0.3587, 0.5753, 0.8643, 1.0269, 0.5234, 8.0393, 6.6019,
         0.8061, 1.2992, 1.3874, 1.6342, 1.0618, 1.6199, 0.4485, 1.6742, 1.8054],
        [1.3284, 1.3556, 1.4130, 1.3909, 1.3616, 1.3333, 1.2968, 1.3262, 1.3262,
         1.2954, 1.3938, 1.3048, 1.4160, 1.3762, 1.4579, 1.2932, 1.3794, 1.3043,
         1.3737, 1.4015, 1.4144, 1.3842, 1.3493, 1.3401, 1.3052, 1.3376, 1.3376,
         1.3781, 1.4300, 1.3574, 1.1946, 1.3221, 1.2237, 1.3857, 1.2333, 1.3598,
         1.4663, 1.1996, 1.4883, 1.4742, 1.0932, 1.0051, 1.4720, 1.4479, 0.9003,
         2.7327, 2.3253, 2.7834, 2.5326, 2.0219, 1.7699, 2.6101, 2.6215, 1.7558]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 130 : 182.29535794478707
Test loss for epoch 130 : 182.31720724145612
Test Precision for epoch 130 : 0.26153846153846155
Test Recall for epoch 130 : 0.26153846153846155
Test F1 for epoch 130 : 0.26153846153846155


theta for epoch 131 : tensor([[2.2882, 2.3128, 2.3775, 2.4503, 2.4176, 2.2924, 2.3991, 2.2863, 2.2863,
         1.3092, 1.3187, 1.3224, 1.3359, 1.2957, 1.3782, 1.3069, 1.2990, 1.2732,
         1.2923, 1.2759, 1.2891, 1.3033, 1.2678, 1.2593, 1.2844, 1.2562, 1.2562,
         1.2970, 1.3497, 1.2765, 1.3017, 1.3427, 1.2881, 1.3049, 1.2397, 1.2790,
         1.3885, 1.4215, 1.4107, 1.3965, 1.4008, 1.3432, 1.3941, 1.3806, 1.3337,
         1.3754, 1.3264, 1.3174, 1.2995, 1.3693, 1.3202, 1.4055, 1.2954, 1.3032],
        [1.3292, 1.2271, 1.0421, 1.2645, 1.3392, 1.3793, 1.3001, 1.3723, 1.3723,
         1.6499, 1.8958, 1.6390, 2.4096, 1.6865, 4.1824, 1.7475, 1.5806, 3.9037,
         1.1669, 1.2376, 1.0151, 1.2132, 1.3506, 1.3858, 1.3618, 1.3837, 1.3837,
         1.3337, 1.0895, 1.4038, 1.3796, 1.1695, 1.4156, 1.4247, 1.3687, 1.3825,
         1.4234, 1.5435, 1.4818, 1.4103, 1.3982, 1.5079, 1.4662, 0.6150, 1.4514,
         1.0635, 1.4517, 1.4398, 1.4251, 1.1023, 1.4435, 0.8900, 1.4211, 1.4290],
        [1.2522, 1.2794, 1.3372, 1.3145, 1.2845, 1.2570, 1.2646, 1.2501, 1.2501,
         1.3146, 1.3245, 1.3278, 1.3409, 1.3011, 1.3270, 1.3124, 1.2923, 1.2340,
         2.3476, 2.4022, 2.5172, 2.4555, 2.2339, 2.3183, 2.3601, 2.2242, 2.2242,
         1.3377, 1.3112, 1.2827, 1.3080, 1.3381, 1.2945, 1.3117, 1.2903, 1.2852,
         1.3938, 1.4268, 1.4159, 1.3898, 1.4061, 1.3986, 1.3995, 1.2876, 1.3270,
         1.3345, 1.3323, 1.3231, 1.3050, 1.2846, 1.3262, 1.3639, 1.3008, 1.3086],
        [1.2670, 1.2947, 1.2682, 1.2446, 1.2995, 1.2719, 1.2799, 1.2648, 1.2648,
         1.3295, 1.2646, 1.3424, 1.3263, 1.3159, 1.3010, 1.3271, 1.3187, 1.1101,
         1.3131, 1.3071, 1.3538, 1.3243, 1.2881, 1.2539, 1.3046, 1.2764, 1.2764,
         2.7243, 2.3255, 2.0876, 2.1933, 2.7131, 2.0972, 2.6645, 2.1039, 2.0895,
         1.4069, 1.4398, 1.3952, 1.3851, 1.4191, 1.3938, 1.4086, 1.1955, 1.3501,
         1.3968, 1.3112, 1.2180, 1.2715, 1.3906, 1.2407, 1.4275, 1.2673, 1.3231],
        [1.7581, 1.4105, 0.6344, 0.8574, 1.2158, 1.6392, 1.5707, 1.7557, 1.7557,
         1.6452, 1.3841, 1.4618, 0.9886, 1.7504, 0.2809, 1.6299, 1.7682, 1.2804,
         1.3525, 0.9075, 0.7862, 1.1284, 1.6124, 1.7064, 1.3677, 1.7653, 1.7653,
         0.7599, 0.8597, 1.7394, 1.5030, 0.8589, 1.6758, 1.1812, 1.7880, 1.7206,
         0.6205, 0.3948, 0.3554, 0.5716, 0.8597, 1.0216, 0.5196, 8.0869, 6.6271,
         0.8076, 1.3001, 1.3886, 1.6352, 1.0632, 1.6204, 0.4500, 1.6756, 1.8065],
        [1.3280, 1.3552, 1.4126, 1.3906, 1.3611, 1.3329, 1.2964, 1.3258, 1.3258,
         1.2950, 1.3935, 1.3045, 1.4156, 1.3758, 1.4575, 1.2928, 1.3790, 1.3039,
         1.3733, 1.4010, 1.4140, 1.3838, 1.3488, 1.3396, 1.3045, 1.3372, 1.3372,
         1.3777, 1.4295, 1.3570, 1.1939, 1.3220, 1.2235, 1.3853, 1.2328, 1.3594,
         1.4662, 1.1991, 1.4882, 1.4741, 1.0927, 1.0046, 1.4719, 1.4478, 0.8998,
         2.7380, 2.3296, 2.7906, 2.5365, 2.0254, 1.7729, 2.6146, 2.6292, 1.7587]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 131 : 182.28522383747034
Test loss for epoch 131 : 182.30746428856256
Test Precision for epoch 131 : 0.26153846153846155
Test Recall for epoch 131 : 0.26153846153846155
Test F1 for epoch 131 : 0.26153846153846155


theta for epoch 132 : tensor([[2.2928, 2.3174, 2.3821, 2.4553, 2.4226, 2.2969, 2.4041, 2.2909, 2.2909,
         1.3087, 1.3182, 1.3219, 1.3354, 1.2953, 1.3777, 1.3065, 1.2985, 1.2728,
         1.2918, 1.2755, 1.2888, 1.3030, 1.2674, 1.2589, 1.2840, 1.2557, 1.2557,
         1.2967, 1.3493, 1.2762, 1.3014, 1.3424, 1.2877, 1.3046, 1.2394, 1.2786,
         1.3883, 1.4215, 1.4104, 1.3963, 1.4007, 1.3430, 1.3939, 1.3802, 1.3333,
         1.3750, 1.3261, 1.3170, 1.2992, 1.3689, 1.3198, 1.4051, 1.2950, 1.3028],
        [1.3290, 1.2270, 1.0419, 1.2643, 1.3392, 1.3791, 1.2998, 1.3721, 1.3721,
         1.6516, 1.8980, 1.6410, 2.4114, 1.6886, 4.1965, 1.7493, 1.5826, 3.9191,
         1.1666, 1.2374, 1.0152, 1.2130, 1.3504, 1.3855, 1.3616, 1.3835, 1.3835,
         1.3336, 1.0893, 1.4036, 1.3793, 1.1694, 1.4153, 1.4246, 1.3684, 1.3825,
         1.4236, 1.5435, 1.4817, 1.4102, 1.3983, 1.5080, 1.4661, 0.6149, 1.4513,
         1.0635, 1.4514, 1.4395, 1.4249, 1.1021, 1.4433, 0.8901, 1.4208, 1.4288],
        [1.2518, 1.2791, 1.3368, 1.3141, 1.2841, 1.2567, 1.2643, 1.2497, 1.2497,
         1.3142, 1.3242, 1.3274, 1.3405, 1.3007, 1.3267, 1.3120, 1.2919, 1.2337,
         2.3524, 2.4070, 2.5221, 2.4606, 2.2384, 2.3231, 2.3648, 2.2287, 2.2287,
         1.3374, 1.3108, 1.2823, 1.3076, 1.3378, 1.2941, 1.3114, 1.2899, 1.2848,
         1.3936, 1.4267, 1.4157, 1.3896, 1.4059, 1.3985, 1.3993, 1.2871, 1.3265,
         1.3341, 1.3319, 1.3227, 1.3046, 1.2842, 1.3258, 1.3636, 1.3003, 1.3083],
        [1.2665, 1.2942, 1.2684, 1.2449, 1.2989, 1.2714, 1.2794, 1.2643, 1.2643,
         1.3290, 1.2645, 1.3419, 1.3262, 1.3153, 1.3005, 1.3266, 1.3181, 1.1110,
         1.3125, 1.3071, 1.3532, 1.3238, 1.2876, 1.2537, 1.3040, 1.2759, 1.2759,
         2.7284, 2.3313, 2.0926, 2.1986, 2.7174, 2.1023, 2.6689, 2.1088, 2.0946,
         1.4066, 1.4396, 1.3953, 1.3851, 1.4189, 1.3940, 1.4084, 1.1964, 1.3496,
         1.3962, 1.3112, 1.2178, 1.2710, 1.3901, 1.2410, 1.4269, 1.2667, 1.3226],
        [1.7592, 1.4117, 0.6356, 0.8584, 1.2169, 1.6404, 1.5719, 1.7568, 1.7568,
         1.6463, 1.3846, 1.4629, 0.9895, 1.7515, 0.2825, 1.6310, 1.7693, 1.2804,
         1.3538, 0.9087, 0.7874, 1.1298, 1.6136, 1.7072, 1.3691, 1.7664, 1.7664,
         0.7607, 0.8610, 1.7405, 1.5045, 0.8594, 1.6768, 1.1817, 1.7892, 1.7216,
         0.6166, 0.3913, 0.3522, 0.5679, 0.8552, 1.0165, 0.5158, 8.1342, 6.6519,
         0.8089, 1.3009, 1.3896, 1.6362, 1.0644, 1.6209, 0.4514, 1.6770, 1.8076],
        [1.3276, 1.3549, 1.4124, 1.3903, 1.3608, 1.3326, 1.2960, 1.3255, 1.3255,
         1.2946, 1.3933, 1.3042, 1.4153, 1.3754, 1.4571, 1.2924, 1.3786, 1.3035,
         1.3730, 1.4007, 1.4137, 1.3835, 1.3485, 1.3393, 1.3040, 1.3369, 1.3369,
         1.3773, 1.4292, 1.3566, 1.1933, 1.3220, 1.2234, 1.3850, 1.2324, 1.3591,
         1.4660, 1.1985, 1.4880, 1.4739, 1.0921, 1.0040, 1.4718, 1.4477, 0.8992,
         2.7434, 2.3338, 2.7978, 2.5404, 2.0288, 1.7757, 2.6189, 2.6367, 1.7615]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 132 : 182.27524117113012
Test loss for epoch 132 : 182.297906011338
Test Precision for epoch 132 : 0.26153846153846155
Test Recall for epoch 132 : 0.26153846153846155
Test F1 for epoch 132 : 0.26153846153846155


theta for epoch 133 : tensor([[2.2972, 2.3218, 2.3866, 2.4602, 2.4276, 2.3013, 2.4090, 2.2953, 2.2953,
         1.3083, 1.3178, 1.3215, 1.3350, 1.2949, 1.3773, 1.3061, 1.2981, 1.2723,
         1.2915, 1.2751, 1.2885, 1.3026, 1.2670, 1.2585, 1.2836, 1.2554, 1.2554,
         1.2964, 1.3489, 1.2759, 1.3010, 1.3421, 1.2873, 1.3043, 1.2390, 1.2783,
         1.3880, 1.4213, 1.4102, 1.3961, 1.4005, 1.3428, 1.3937, 1.3798, 1.3329,
         1.3746, 1.3257, 1.3166, 1.2988, 1.3685, 1.3194, 1.4048, 1.2945, 1.3024],
        [1.3287, 1.2268, 1.0417, 1.2641, 1.3392, 1.3788, 1.2996, 1.3718, 1.3718,
         1.6534, 1.9001, 1.6431, 2.4132, 1.6908, 4.2108, 1.7512, 1.5845, 3.9345,
         1.1663, 1.2371, 1.0154, 1.2128, 1.3501, 1.3853, 1.3613, 1.3832, 1.3832,
         1.3334, 1.0891, 1.4033, 1.3791, 1.1693, 1.4150, 1.4245, 1.3680, 1.3825,
         1.4237, 1.5435, 1.4815, 1.4101, 1.3985, 1.5081, 1.4660, 0.6147, 1.4511,
         1.0633, 1.4511, 1.4392, 1.4246, 1.1018, 1.4430, 0.8903, 1.4205, 1.4285],
        [1.2515, 1.2787, 1.3364, 1.3138, 1.2837, 1.2563, 1.2639, 1.2493, 1.2493,
         1.3139, 1.3238, 1.3271, 1.3402, 1.3004, 1.3265, 1.3116, 1.2916, 1.2335,
         2.3571, 2.4118, 2.5271, 2.4656, 2.2429, 2.3279, 2.3695, 2.2332, 2.2332,
         1.3370, 1.3105, 1.2819, 1.3072, 1.3374, 1.2937, 1.3111, 1.2895, 1.2844,
         1.3934, 1.4266, 1.4155, 1.3893, 1.4058, 1.3984, 1.3991, 1.2866, 1.3260,
         1.3337, 1.3315, 1.3223, 1.3043, 1.2839, 1.3254, 1.3632, 1.2999, 1.3078],
        [1.2660, 1.2937, 1.2687, 1.2452, 1.2985, 1.2709, 1.2790, 1.2638, 1.2638,
         1.3285, 1.2645, 1.3414, 1.3262, 1.3148, 1.3001, 1.3261, 1.3177, 1.1121,
         1.3121, 1.3072, 1.3528, 1.3233, 1.2872, 1.2536, 1.3036, 1.2754, 1.2754,
         2.7325, 2.3370, 2.0975, 2.2037, 2.7217, 2.1072, 2.6732, 2.1137, 2.0995,
         1.4062, 1.4394, 1.3954, 1.3852, 1.4186, 1.3941, 1.4082, 1.1974, 1.3491,
         1.3957, 1.3113, 1.2177, 1.2705, 1.3896, 1.2414, 1.4264, 1.2662, 1.3220],
        [1.7602, 1.4128, 0.6367, 0.8594, 1.2180, 1.6415, 1.5731, 1.7579, 1.7579,
         1.6473, 1.3851, 1.4640, 0.9904, 1.7525, 0.2840, 1.6320, 1.7704, 1.2803,
         1.3550, 0.9099, 0.7886, 1.1310, 1.6147, 1.7079, 1.3705, 1.7675, 1.7675,
         0.7614, 0.8623, 1.7417, 1.5059, 0.8598, 1.6777, 1.1820, 1.7904, 1.7225,
         0.6128, 0.3878, 0.3491, 0.5643, 0.8507, 1.0116, 0.5122, 8.1814, 6.6762,
         0.8102, 1.3016, 1.3906, 1.6371, 1.0656, 1.6213, 0.4527, 1.6783, 1.8086],
        [1.3273, 1.3545, 1.4121, 1.3900, 1.3605, 1.3322, 1.2956, 1.3251, 1.3251,
         1.2942, 1.3931, 1.3039, 1.4150, 1.3750, 1.4568, 1.2921, 1.3782, 1.3031,
         1.3727, 1.4004, 1.4134, 1.3832, 1.3481, 1.3390, 1.3035, 1.3365, 1.3365,
         1.3770, 1.4288, 1.3563, 1.1927, 1.3219, 1.2233, 1.3847, 1.2320, 1.3588,
         1.4658, 1.1979, 1.4878, 1.4737, 1.0915, 1.0033, 1.4716, 1.4474, 0.8985,
         2.7488, 2.3380, 2.8050, 2.5444, 2.0322, 1.7784, 2.6234, 2.6442, 1.7643]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 133 : 182.26540824419735
Test loss for epoch 133 : 182.28852805990144
Test Precision for epoch 133 : 0.26153846153846155
Test Recall for epoch 133 : 0.26153846153846155
Test F1 for epoch 133 : 0.26153846153846155


theta for epoch 134 : tensor([[2.3017, 2.3263, 2.3911, 2.4652, 2.4325, 2.3058, 2.4140, 2.2998, 2.2998,
         1.3079, 1.3174, 1.3210, 1.3346, 1.2945, 1.3768, 1.3057, 1.2977, 1.2719,
         1.2910, 1.2747, 1.2881, 1.3022, 1.2665, 1.2581, 1.2832, 1.2549, 1.2549,
         1.2960, 1.3484, 1.2755, 1.3006, 1.3417, 1.2869, 1.3040, 1.2386, 1.2780,
         1.3879, 1.4213, 1.4100, 1.3959, 1.4004, 1.3427, 1.3936, 1.3794, 1.3325,
         1.3742, 1.3253, 1.3161, 1.2984, 1.3681, 1.3189, 1.4044, 1.2940, 1.3019],
        [1.3284, 1.2267, 1.0415, 1.2638, 1.3391, 1.3786, 1.2993, 1.3716, 1.3716,
         1.6551, 1.9022, 1.6451, 2.4150, 1.6930, 4.2250, 1.7530, 1.5864, 3.9499,
         1.1660, 1.2369, 1.0155, 1.2125, 1.3499, 1.3850, 1.3610, 1.3829, 1.3829,
         1.3333, 1.0888, 1.4030, 1.3788, 1.1692, 1.4147, 1.4244, 1.3677, 1.3824,
         1.4239, 1.5436, 1.4814, 1.4100, 1.3987, 1.5083, 1.4659, 0.6146, 1.4510,
         1.0632, 1.4508, 1.4390, 1.4244, 1.1015, 1.4427, 0.8904, 1.4201, 1.4282],
        [1.2511, 1.2783, 1.3361, 1.3134, 1.2833, 1.2560, 1.2635, 1.2489, 1.2489,
         1.3135, 1.3235, 1.3267, 1.3399, 1.3001, 1.3263, 1.3113, 1.2913, 1.2333,
         2.3618, 2.4165, 2.5320, 2.4705, 2.2473, 2.3327, 2.3741, 2.2376, 2.2376,
         1.3367, 1.3102, 1.2816, 1.3068, 1.3371, 1.2933, 1.3108, 1.2891, 1.2840,
         1.3933, 1.4266, 1.4154, 1.3892, 1.4057, 1.3983, 1.3990, 1.2862, 1.3256,
         1.3334, 1.3311, 1.3219, 1.3039, 1.2836, 1.3251, 1.3629, 1.2995, 1.3075],
        [1.2656, 1.2932, 1.2690, 1.2456, 1.2980, 1.2705, 1.2785, 1.2634, 1.2634,
         1.3281, 1.2646, 1.3410, 1.3262, 1.3144, 1.2998, 1.3257, 1.3172, 1.1132,
         1.3116, 1.3073, 1.3523, 1.3229, 1.2867, 1.2535, 1.3032, 1.2750, 1.2750,
         2.7364, 2.3426, 2.1024, 2.2089, 2.7259, 2.1121, 2.6774, 2.1185, 2.1044,
         1.4060, 1.4393, 1.3956, 1.3854, 1.4184, 1.3944, 1.4081, 1.1985, 1.3487,
         1.3953, 1.3114, 1.2176, 1.2701, 1.3891, 1.2418, 1.4260, 1.2657, 1.3216],
        [1.7612, 1.4138, 0.6377, 0.8603, 1.2190, 1.6425, 1.5742, 1.7589, 1.7589,
         1.6484, 1.3856, 1.4651, 0.9912, 1.7536, 0.2854, 1.6330, 1.7714, 1.2803,
         1.3561, 0.9109, 0.7898, 1.1322, 1.6158, 1.7087, 1.3719, 1.7685, 1.7685,
         0.7620, 0.8635, 1.7427, 1.5072, 0.8602, 1.6786, 1.1823, 1.7915, 1.7234,
         0.6092, 0.3845, 0.3461, 0.5607, 0.8464, 1.0068, 0.5086, 8.2285, 6.7002,
         0.8114, 1.3023, 1.3915, 1.6380, 1.0667, 1.6216, 0.4539, 1.6796, 1.8096],
        [1.3268, 1.3541, 1.4118, 1.3896, 1.3600, 1.3317, 1.2952, 1.3246, 1.3246,
         1.2938, 1.3929, 1.3036, 1.4146, 1.3746, 1.4564, 1.2917, 1.3778, 1.3027,
         1.3723, 1.4000, 1.4130, 1.3827, 1.3477, 1.3385, 1.3028, 1.3360, 1.3360,
         1.3766, 1.4284, 1.3559, 1.1920, 1.3218, 1.2232, 1.3844, 1.2316, 1.3584,
         1.4656, 1.1973, 1.4876, 1.4735, 1.0909, 1.0027, 1.4714, 1.4472, 0.8978,
         2.7543, 2.3424, 2.8124, 2.5485, 2.0356, 1.7813, 2.6279, 2.6518, 1.7671]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 134 : 182.2557231197008
Test loss for epoch 134 : 182.27926367986083
Test Precision for epoch 134 : 0.26153846153846155
Test Recall for epoch 134 : 0.26153846153846155
Test F1 for epoch 134 : 0.26153846153846155


theta for epoch 135 : tensor([[2.3062, 2.3309, 2.3956, 2.4702, 2.4375, 2.3103, 2.4190, 2.3043, 2.3043,
         1.3074, 1.3170, 1.3206, 1.3342, 1.2940, 1.3764, 1.3053, 1.2972, 1.2714,
         1.2906, 1.2742, 1.2877, 1.3018, 1.2660, 1.2576, 1.2827, 1.2544, 1.2544,
         1.2956, 1.3480, 1.2751, 1.3002, 1.3414, 1.2865, 1.3036, 1.2382, 1.2776,
         1.3877, 1.4212, 1.4098, 1.3957, 1.4003, 1.3425, 1.3934, 1.3790, 1.3322,
         1.3738, 1.3248, 1.3156, 1.2979, 1.3677, 1.3184, 1.4040, 1.2935, 1.3014],
        [1.3282, 1.2265, 1.0414, 1.2636, 1.3391, 1.3783, 1.2990, 1.3713, 1.3713,
         1.6567, 1.9043, 1.6471, 2.4167, 1.6950, 4.2392, 1.7547, 1.5882, 3.9652,
         1.1657, 1.2366, 1.0157, 1.2123, 1.3497, 1.3848, 1.3607, 1.3827, 1.3827,
         1.3332, 1.0886, 1.4028, 1.3786, 1.1691, 1.4145, 1.4244, 1.3674, 1.3824,
         1.4242, 1.5437, 1.4813, 1.4100, 1.3989, 1.5085, 1.4659, 0.6145, 1.4509,
         1.0631, 1.4506, 1.4387, 1.4242, 1.1013, 1.4424, 0.8906, 1.4198, 1.4279],
        [1.2506, 1.2779, 1.3357, 1.3129, 1.2829, 1.2555, 1.2631, 1.2485, 1.2485,
         1.3132, 1.3232, 1.3263, 1.3395, 1.2997, 1.3260, 1.3110, 1.2909, 1.2330,
         2.3666, 2.4212, 2.5369, 2.4755, 2.2517, 2.3374, 2.3788, 2.2420, 2.2420,
         1.3363, 1.3098, 1.2812, 1.3064, 1.3368, 1.2929, 1.3105, 1.2887, 1.2836,
         1.3931, 1.4265, 1.4153, 1.3890, 1.4056, 1.3983, 1.3989, 1.2858, 1.3252,
         1.3330, 1.3307, 1.3215, 1.3035, 1.2832, 1.3246, 1.3625, 1.2990, 1.3070],
        [1.2650, 1.2927, 1.2693, 1.2458, 1.2975, 1.2699, 1.2780, 1.2628, 1.2628,
         1.3275, 1.2646, 1.3405, 1.3261, 1.3139, 1.2993, 1.3252, 1.3167, 1.1142,
         1.3111, 1.3073, 1.3518, 1.3224, 1.2862, 1.2534, 1.3026, 1.2745, 1.2745,
         2.7405, 2.3484, 2.1073, 2.2141, 2.7301, 2.1171, 2.6817, 2.1233, 2.1094,
         1.4058, 1.4392, 1.3958, 1.3855, 1.4183, 1.3946, 1.4079, 1.1996, 1.3483,
         1.3947, 1.3114, 1.2174, 1.2696, 1.3886, 1.2421, 1.4254, 1.2651, 1.3210],
        [1.7622, 1.4149, 0.6388, 0.8611, 1.2200, 1.6435, 1.5753, 1.7599, 1.7599,
         1.6494, 1.3861, 1.4662, 0.9921, 1.7546, 0.2869, 1.6340, 1.7725, 1.2802,
         1.3573, 0.9120, 0.7909, 1.1334, 1.6169, 1.7094, 1.3732, 1.7695, 1.7695,
         0.7627, 0.8648, 1.7438, 1.5085, 0.8606, 1.6795, 1.1826, 1.7926, 1.7243,
         0.6055, 0.3812, 0.3432, 0.5573, 0.8422, 1.0021, 0.5051, 8.2753, 6.7237,
         0.8126, 1.3029, 1.3924, 1.6389, 1.0679, 1.6219, 0.4552, 1.6808, 1.8105],
        [1.3263, 1.3536, 1.4114, 1.3892, 1.3596, 1.3312, 1.2947, 1.3241, 1.3241,
         1.2935, 1.3927, 1.3033, 1.4143, 1.3742, 1.4561, 1.2913, 1.3774, 1.3023,
         1.3719, 1.3996, 1.4126, 1.3824, 1.3473, 1.3381, 1.3022, 1.3356, 1.3356,
         1.3763, 1.4281, 1.3556, 1.1913, 1.3217, 1.2230, 1.3841, 1.2312, 1.3580,
         1.4655, 1.1968, 1.4875, 1.4733, 1.0903, 1.0021, 1.4713, 1.4470, 0.8972,
         2.7598, 2.3466, 2.8196, 2.5525, 2.0389, 1.7839, 2.6324, 2.6593, 1.7698]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 135 : 182.24618222238058
Test loss for epoch 135 : 182.270158312094
Test Precision for epoch 135 : 0.26153846153846155
Test Recall for epoch 135 : 0.26153846153846155
Test F1 for epoch 135 : 0.26153846153846155


theta for epoch 136 : tensor([[2.3107, 2.3353, 2.4001, 2.4752, 2.4425, 2.3148, 2.4239, 2.3088, 2.3088,
         1.3070, 1.3166, 1.3201, 1.3338, 1.2936, 1.3760, 1.3048, 1.2968, 1.2710,
         1.2901, 1.2738, 1.2873, 1.3014, 1.2656, 1.2572, 1.2823, 1.2540, 1.2540,
         1.2952, 1.3475, 1.2747, 1.2997, 1.3410, 1.2861, 1.3033, 1.2377, 1.2771,
         1.3876, 1.4211, 1.4097, 1.3956, 1.4003, 1.3424, 1.3933, 1.3786, 1.3319,
         1.3734, 1.3244, 1.3152, 1.2974, 1.3673, 1.3180, 1.4036, 1.2930, 1.3010],
        [1.3279, 1.2263, 1.0412, 1.2633, 1.3390, 1.3781, 1.2987, 1.3710, 1.3710,
         1.6583, 1.9063, 1.6490, 2.4185, 1.6970, 4.2534, 1.7565, 1.5900, 3.9806,
         1.1655, 1.2364, 1.0158, 1.2121, 1.3494, 1.3845, 1.3605, 1.3825, 1.3825,
         1.3330, 1.0884, 1.4025, 1.3783, 1.1690, 1.4142, 1.4243, 1.3671, 1.3823,
         1.4244, 1.5438, 1.4812, 1.4099, 1.3991, 1.5086, 1.4658, 0.6144, 1.4507,
         1.0630, 1.4503, 1.4385, 1.4240, 1.1010, 1.4422, 0.8908, 1.4196, 1.4277],
        [1.2502, 1.2774, 1.3353, 1.3125, 1.2824, 1.2550, 1.2626, 1.2480, 1.2480,
         1.3128, 1.3228, 1.3259, 1.3392, 1.2993, 1.3257, 1.3106, 1.2905, 1.2327,
         2.3713, 2.4260, 2.5420, 2.4805, 2.2562, 2.3422, 2.3835, 2.2464, 2.2464,
         1.3359, 1.3095, 1.2807, 1.3060, 1.3364, 1.2924, 1.3102, 1.2882, 1.2831,
         1.3930, 1.4265, 1.4151, 1.3888, 1.4055, 1.3982, 1.3988, 1.2854, 1.3248,
         1.3326, 1.3303, 1.3210, 1.3031, 1.2828, 1.3242, 1.3622, 1.2985, 1.3066],
        [1.2644, 1.2921, 1.2694, 1.2461, 1.2969, 1.2694, 1.2774, 1.2622, 1.2622,
         1.3270, 1.2646, 1.3400, 1.3260, 1.3133, 1.2989, 1.3247, 1.3161, 1.1151,
         1.3105, 1.3072, 1.3513, 1.3218, 1.2856, 1.2531, 1.3020, 1.2739, 1.2739,
         2.7445, 2.3542, 2.1123, 2.2193, 2.7344, 2.1221, 2.6860, 2.1282, 2.1144,
         1.4055, 1.4390, 1.3959, 1.3856, 1.4180, 1.3947, 1.4078, 1.2006, 1.3479,
         1.3941, 1.3114, 1.2172, 1.2691, 1.3880, 1.2424, 1.4249, 1.2645, 1.3205],
        [1.7633, 1.4159, 0.6398, 0.8620, 1.2211, 1.6446, 1.5764, 1.7609, 1.7609,
         1.6504, 1.3866, 1.4673, 0.9929, 1.7556, 0.2884, 1.6350, 1.7736, 1.2802,
         1.3585, 0.9131, 0.7921, 1.1347, 1.6180, 1.7101, 1.3746, 1.7706, 1.7706,
         0.7634, 0.8660, 1.7448, 1.5099, 0.8610, 1.6805, 1.1829, 1.7938, 1.7251,
         0.6019, 0.3780, 0.3402, 0.5538, 0.8379, 0.9974, 0.5015, 8.3219, 6.7467,
         0.8139, 1.3037, 1.3934, 1.6398, 1.0691, 1.6223, 0.4565, 1.6821, 1.8115],
        [1.3258, 1.3532, 1.4111, 1.3888, 1.3591, 1.3307, 1.2942, 1.3236, 1.3236,
         1.2931, 1.3925, 1.3031, 1.4139, 1.3738, 1.4557, 1.2910, 1.3770, 1.3020,
         1.3716, 1.3993, 1.4123, 1.3820, 1.3469, 1.3377, 1.3016, 1.3352, 1.3352,
         1.3760, 1.4277, 1.3552, 1.1907, 1.3217, 1.2229, 1.3838, 1.2307, 1.3577,
         1.4654, 1.1963, 1.4873, 1.4732, 1.0898, 1.0015, 1.4713, 1.4468, 0.8966,
         2.7653, 2.3508, 2.8269, 2.5566, 2.0421, 1.7865, 2.6368, 2.6667, 1.7724]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 136 : 182.23678128394164
Test loss for epoch 136 : 182.26118896761346
Test Precision for epoch 136 : 0.26153846153846155
Test Recall for epoch 136 : 0.26153846153846155
Test F1 for epoch 136 : 0.26153846153846155


theta for epoch 137 : tensor([[2.3152, 2.3398, 2.4045, 2.4802, 2.4474, 2.3193, 2.4288, 2.3133, 2.3133,
         1.3066, 1.3162, 1.3197, 1.3335, 1.2932, 1.3756, 1.3044, 1.2964, 1.2706,
         1.2897, 1.2733, 1.2869, 1.3009, 1.2651, 1.2567, 1.2818, 1.2535, 1.2535,
         1.2948, 1.3470, 1.2742, 1.2992, 1.3406, 1.2856, 1.3028, 1.2372, 1.2766,
         1.3874, 1.4211, 1.4095, 1.3954, 1.4002, 1.3422, 1.3932, 1.3782, 1.3315,
         1.3730, 1.3240, 1.3148, 1.2971, 1.3669, 1.3176, 1.4033, 1.2925, 1.3005],
        [1.3276, 1.2261, 1.0410, 1.2631, 1.3390, 1.3778, 1.2984, 1.3708, 1.3708,
         1.6600, 1.9083, 1.6509, 2.4204, 1.6990, 4.2677, 1.7582, 1.5918, 3.9960,
         1.1651, 1.2361, 1.0159, 1.2118, 1.3491, 1.3842, 1.3601, 1.3821, 1.3821,
         1.3328, 1.0881, 1.4022, 1.3779, 1.1688, 1.4138, 1.4241, 1.3667, 1.3822,
         1.4246, 1.5439, 1.4811, 1.4099, 1.3992, 1.5088, 1.4658, 0.6143, 1.4506,
         1.0629, 1.4501, 1.4383, 1.4238, 1.1008, 1.4420, 0.8909, 1.4193, 1.4275],
        [1.2498, 1.2770, 1.3349, 1.3121, 1.2820, 1.2547, 1.2622, 1.2476, 1.2476,
         1.3124, 1.3225, 1.3255, 1.3388, 1.2989, 1.3254, 1.3102, 1.2901, 1.2324,
         2.3760, 2.4308, 2.5469, 2.4855, 2.2606, 2.3470, 2.3881, 2.2508, 2.2508,
         1.3355, 1.3090, 1.2802, 1.3055, 1.3360, 1.2919, 1.3098, 1.2877, 1.2827,
         1.3929, 1.4264, 1.4150, 1.3886, 1.4055, 1.3981, 1.3987, 1.2850, 1.3244,
         1.3323, 1.3300, 1.3207, 1.3027, 1.2826, 1.3238, 1.3619, 1.2981, 1.3062],
        [1.2639, 1.2915, 1.2697, 1.2463, 1.2964, 1.2688, 1.2769, 1.2617, 1.2617,
         1.3265, 1.2646, 1.3395, 1.3259, 1.3128, 1.2984, 1.3242, 1.3156, 1.1161,
         1.3100, 1.3072, 1.3507, 1.3212, 1.2850, 1.2529, 1.3015, 1.2733, 1.2733,
         2.7485, 2.3599, 2.1173, 2.2246, 2.7386, 2.1270, 2.6902, 2.1331, 2.1193,
         1.4052, 1.4388, 1.3960, 1.3858, 1.4178, 1.3949, 1.4076, 1.2016, 1.3474,
         1.3936, 1.3115, 1.2170, 1.2686, 1.3875, 1.2428, 1.4244, 1.2640, 1.3199],
        [1.7643, 1.4170, 0.6409, 0.8630, 1.2222, 1.6457, 1.5775, 1.7620, 1.7620,
         1.6515, 1.3871, 1.4685, 0.9938, 1.7567, 0.2900, 1.6360, 1.7746, 1.2801,
         1.3596, 0.9142, 0.7933, 1.1359, 1.6191, 1.7109, 1.3760, 1.7716, 1.7716,
         0.7640, 0.8673, 1.7458, 1.5112, 0.8613, 1.6813, 1.1831, 1.7948, 1.7260,
         0.5983, 0.3747, 0.3373, 0.5504, 0.8337, 0.9928, 0.4981, 8.3684, 6.7693,
         0.8152, 1.3044, 1.3944, 1.6408, 1.0703, 1.6227, 0.4579, 1.6834, 1.8126],
        [1.3254, 1.3528, 1.4108, 1.3885, 1.3588, 1.3303, 1.2938, 1.3232, 1.3232,
         1.2927, 1.3923, 1.3028, 1.4136, 1.3734, 1.4554, 1.2906, 1.3766, 1.3016,
         1.3712, 1.3989, 1.4119, 1.3816, 1.3464, 1.3373, 1.3010, 1.3348, 1.3348,
         1.3756, 1.4273, 1.3548, 1.1899, 1.3215, 1.2226, 1.3835, 1.2302, 1.3572,
         1.4653, 1.1958, 1.4872, 1.4731, 1.0893, 1.0009, 1.4712, 1.4466, 0.8960,
         2.7709, 2.3550, 2.8342, 2.5607, 2.0453, 1.7891, 2.6414, 2.6742, 1.7750]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 137 : 182.2275200821244
Test loss for epoch 137 : 182.25236904438825
Test Precision for epoch 137 : 0.26153846153846155
Test Recall for epoch 137 : 0.26153846153846155
Test F1 for epoch 137 : 0.26153846153846155


theta for epoch 138 : tensor([[2.3196, 2.3442, 2.4090, 2.4851, 2.4523, 2.3237, 2.4337, 2.3177, 2.3177,
         1.3061, 1.3158, 1.3192, 1.3331, 1.2927, 1.3752, 1.3040, 1.2960, 1.2701,
         1.2893, 1.2730, 1.2866, 1.3005, 1.2647, 1.2563, 1.2814, 1.2530, 1.2530,
         1.2944, 1.3465, 1.2737, 1.2987, 1.3402, 1.2851, 1.3024, 1.2366, 1.2762,
         1.3873, 1.4210, 1.4093, 1.3953, 1.4001, 1.3421, 1.3931, 1.3779, 1.3312,
         1.3727, 1.3236, 1.3144, 1.2966, 1.3666, 1.3171, 1.4030, 1.2920, 1.3001],
        [1.3273, 1.2259, 1.0409, 1.2629, 1.3389, 1.3776, 1.2982, 1.3705, 1.3705,
         1.6617, 1.9103, 1.6528, 2.4222, 1.7010, 4.2820, 1.7600, 1.5936, 4.0114,
         1.1647, 1.2358, 1.0159, 1.2115, 1.3488, 1.3840, 1.3598, 1.3819, 1.3819,
         1.3326, 1.0878, 1.4018, 1.3776, 1.1687, 1.4135, 1.4239, 1.3663, 1.3821,
         1.4248, 1.5439, 1.4810, 1.4098, 1.3994, 1.5089, 1.4657, 0.6142, 1.4504,
         1.0627, 1.4499, 1.4380, 1.4235, 1.1005, 1.4417, 0.8911, 1.4190, 1.4272],
        [1.2494, 1.2767, 1.3346, 1.3118, 1.2816, 1.2543, 1.2618, 1.2472, 1.2472,
         1.3120, 1.3221, 1.3251, 1.3385, 1.2985, 1.3251, 1.3098, 1.2897, 1.2321,
         2.3806, 2.4355, 2.5519, 2.4904, 2.2649, 2.3517, 2.3928, 2.2551, 2.2551,
         1.3351, 1.3086, 1.2797, 1.3050, 1.3356, 1.2914, 1.3094, 1.2872, 1.2822,
         1.3927, 1.4264, 1.4148, 1.3885, 1.4054, 1.3980, 1.3987, 1.2847, 1.3240,
         1.3320, 1.3296, 1.3203, 1.3023, 1.2822, 1.3234, 1.3616, 1.2976, 1.3058],
        [1.2634, 1.2910, 1.2700, 1.2466, 1.2959, 1.2683, 1.2764, 1.2612, 1.2612,
         1.3259, 1.2646, 1.3390, 1.3258, 1.3123, 1.2980, 1.3237, 1.3151, 1.1171,
         1.3094, 1.3072, 1.3502, 1.3207, 1.2845, 1.2527, 1.3009, 1.2728, 1.2728,
         2.7525, 2.3656, 2.1222, 2.2298, 2.7427, 2.1319, 2.6944, 2.1379, 2.1242,
         1.4050, 1.4387, 1.3962, 1.3859, 1.4176, 1.3951, 1.4074, 1.2027, 1.3470,
         1.3931, 1.3115, 1.2168, 1.2681, 1.3870, 1.2432, 1.4239, 1.2634, 1.3194],
        [1.7653, 1.4181, 0.6419, 0.8638, 1.2231, 1.6468, 1.5786, 1.7630, 1.7630,
         1.6525, 1.3875, 1.4695, 0.9945, 1.7577, 0.2914, 1.6370, 1.7757, 1.2800,
         1.3608, 0.9152, 0.7944, 1.1371, 1.6201, 1.7116, 1.3773, 1.7726, 1.7726,
         0.7646, 0.8684, 1.7468, 1.5124, 0.8616, 1.6821, 1.1833, 1.7958, 1.7267,
         0.5948, 0.3716, 0.3345, 0.5471, 0.8297, 0.9884, 0.4947, 8.4146, 6.7914,
         0.8164, 1.3050, 1.3953, 1.6416, 1.0714, 1.6230, 0.4591, 1.6846, 1.8135],
        [1.3251, 1.3525, 1.4105, 1.3882, 1.3584, 1.3299, 1.2934, 1.3228, 1.3228,
         1.2923, 1.3920, 1.3025, 1.4133, 1.3730, 1.4551, 1.2902, 1.3762, 1.3013,
         1.3708, 1.3985, 1.4116, 1.3812, 1.3461, 1.3369, 1.3004, 1.3344, 1.3344,
         1.3753, 1.4269, 1.3544, 1.1892, 1.3214, 1.2224, 1.3831, 1.2297, 1.3568,
         1.4652, 1.1953, 1.4871, 1.4730, 1.0888, 1.0003, 1.4711, 1.4464, 0.8953,
         2.7764, 2.3591, 2.8414, 2.5648, 2.0484, 1.7916, 2.6458, 2.6815, 1.7774]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 138 : 182.2183947459552
Test loss for epoch 138 : 182.24373558116463
Test Precision for epoch 138 : 0.26153846153846155
Test Recall for epoch 138 : 0.26153846153846155
Test F1 for epoch 138 : 0.26153846153846155


theta for epoch 139 : tensor([[2.3240, 2.3486, 2.4133, 2.4900, 2.4572, 2.3280, 2.4386, 2.3221, 2.3221,
         1.3057, 1.3153, 1.3188, 1.3327, 1.2923, 1.3748, 1.3036, 1.2955, 1.2697,
         1.2889, 1.2726, 1.2862, 1.3002, 1.2643, 1.2559, 1.2810, 1.2527, 1.2527,
         1.2941, 1.3461, 1.2733, 1.2983, 1.3399, 1.2847, 1.3022, 1.2362, 1.2758,
         1.3871, 1.4209, 1.4092, 1.3951, 1.4000, 1.3419, 1.3930, 1.3774, 1.3309,
         1.3723, 1.3232, 1.3139, 1.2962, 1.3662, 1.3167, 1.4026, 1.2915, 1.2996],
        [1.3270, 1.2257, 1.0407, 1.2626, 1.3389, 1.3773, 1.2979, 1.3702, 1.3702,
         1.6632, 1.9122, 1.6546, 2.4240, 1.7029, 4.2962, 1.7617, 1.5953, 4.0268,
         1.1645, 1.2356, 1.0160, 1.2113, 1.3486, 1.3837, 1.3595, 1.3816, 1.3816,
         1.3324, 1.0876, 1.4016, 1.3774, 1.1686, 1.4132, 1.4238, 1.3660, 1.3820,
         1.4250, 1.5440, 1.4809, 1.4098, 1.3996, 1.5090, 1.4657, 0.6140, 1.4502,
         1.0626, 1.4496, 1.4378, 1.4233, 1.1003, 1.4414, 0.8912, 1.4186, 1.4269],
        [1.2490, 1.2763, 1.3343, 1.3114, 1.2812, 1.2539, 1.2614, 1.2468, 1.2468,
         1.3116, 1.3217, 1.3247, 1.3381, 1.2981, 1.3248, 1.3094, 1.2893, 1.2318,
         2.3853, 2.4402, 2.5568, 2.4954, 2.2692, 2.3563, 2.3974, 2.2594, 2.2594,
         1.3348, 1.3083, 1.2794, 1.3046, 1.3352, 1.2910, 1.3091, 1.2868, 1.2818,
         1.3926, 1.4263, 1.4147, 1.3883, 1.4053, 1.3979, 1.3985, 1.2843, 1.3236,
         1.3316, 1.3292, 1.3198, 1.3019, 1.2819, 1.3230, 1.3612, 1.2972, 1.3054],
        [1.2629, 1.2905, 1.2702, 1.2469, 1.2954, 1.2678, 1.2759, 1.2607, 1.2607,
         1.3254, 1.2647, 1.3385, 1.3257, 1.3117, 1.2975, 1.3231, 1.3145, 1.1181,
         1.3090, 1.3072, 1.3498, 1.3202, 1.2840, 1.2525, 1.3004, 1.2723, 1.2723,
         2.7564, 2.3713, 2.1271, 2.2350, 2.7468, 2.1369, 2.6986, 2.1427, 2.1291,
         1.4047, 1.4385, 1.3963, 1.3860, 1.4174, 1.3952, 1.4073, 1.2037, 1.3466,
         1.3926, 1.3115, 1.2167, 1.2676, 1.3864, 1.2436, 1.4233, 1.2628, 1.3189],
        [1.7663, 1.4190, 0.6427, 0.8646, 1.2240, 1.6478, 1.5797, 1.7640, 1.7640,
         1.6534, 1.3878, 1.4705, 0.9952, 1.7586, 0.2928, 1.6379, 1.7766, 1.2799,
         1.3619, 0.9162, 0.7955, 1.1382, 1.6212, 1.7122, 1.3786, 1.7736, 1.7736,
         0.7651, 0.8696, 1.7478, 1.5137, 0.8619, 1.6830, 1.1834, 1.7969, 1.7276,
         0.5914, 0.3686, 0.3318, 0.5438, 0.8257, 0.9841, 0.4915, 8.4607, 6.8132,
         0.8175, 1.3056, 1.3961, 1.6424, 1.0725, 1.6232, 0.4602, 1.6858, 1.8144],
        [1.3246, 1.3520, 1.4102, 1.3878, 1.3580, 1.3295, 1.2930, 1.3224, 1.3224,
         1.2919, 1.3918, 1.3022, 1.4130, 1.3726, 1.4547, 1.2898, 1.3758, 1.3009,
         1.3705, 1.3982, 1.4113, 1.3809, 1.3457, 1.3366, 1.2999, 1.3340, 1.3340,
         1.3750, 1.4265, 1.3541, 1.1885, 1.3213, 1.2222, 1.3829, 1.2293, 1.3565,
         1.4650, 1.1948, 1.4869, 1.4728, 1.0882, 0.9997, 1.4710, 1.4462, 0.8947,
         2.7820, 2.3633, 2.8487, 2.5690, 2.0516, 1.7941, 2.6504, 2.6888, 1.7799]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 139 : 182.20940202708027
Test loss for epoch 139 : 182.23519802766918
Test Precision for epoch 139 : 0.26153846153846155
Test Recall for epoch 139 : 0.26153846153846155
Test F1 for epoch 139 : 0.26153846153846155


theta for epoch 140 : tensor([[2.3284, 2.3531, 2.4178, 2.4949, 2.4621, 2.3325, 2.4435, 2.3265, 2.3265,
         1.3052, 1.3149, 1.3183, 1.3323, 1.2918, 1.3744, 1.3031, 1.2950, 1.2692,
         1.2885, 1.2722, 1.2858, 1.2998, 1.2639, 1.2554, 1.2806, 1.2522, 1.2522,
         1.2938, 1.3457, 1.2729, 1.2979, 1.3396, 1.2844, 1.3019, 1.2358, 1.2754,
         1.3869, 1.4208, 1.4089, 1.3949, 1.3998, 1.3416, 1.3928, 1.3769, 1.3304,
         1.3719, 1.3228, 1.3134, 1.2957, 1.3658, 1.3162, 1.4022, 1.2910, 1.2991],
        [1.3268, 1.2256, 1.0405, 1.2624, 1.3388, 1.3770, 1.2976, 1.3699, 1.3699,
         1.6648, 1.9141, 1.6563, 2.4258, 1.7048, 4.3105, 1.7634, 1.5969, 4.0422,
         1.1642, 1.2353, 1.0161, 1.2110, 1.3483, 1.3835, 1.3592, 1.3814, 1.3814,
         1.3324, 1.0874, 1.4013, 1.3772, 1.1686, 1.4130, 1.4237, 1.3657, 1.3820,
         1.4252, 1.5441, 1.4808, 1.4097, 1.3997, 1.5091, 1.4656, 0.6139, 1.4500,
         1.0625, 1.4494, 1.4375, 1.4230, 1.1000, 1.4412, 0.8913, 1.4183, 1.4267],
        [1.2486, 1.2759, 1.3339, 1.3110, 1.2809, 1.2535, 1.2610, 1.2464, 1.2464,
         1.3112, 1.3214, 1.3243, 1.3378, 1.2977, 1.3245, 1.3091, 1.2889, 1.2315,
         2.3898, 2.4449, 2.5618, 2.5003, 2.2735, 2.3610, 2.4020, 2.2637, 2.2637,
         1.3345, 1.3080, 1.2790, 1.3042, 1.3350, 1.2906, 1.3089, 1.2865, 1.2814,
         1.3924, 1.4262, 1.4145, 1.3880, 1.4052, 1.3977, 1.3984, 1.2839, 1.3231,
         1.3313, 1.3288, 1.3194, 1.3015, 1.2816, 1.3225, 1.3609, 1.2967, 1.3050],
        [1.2624, 1.2900, 1.2705, 1.2472, 1.2949, 1.2673, 1.2754, 1.2602, 1.2602,
         1.3249, 1.2647, 1.3380, 1.3257, 1.3112, 1.2971, 1.3226, 1.3140, 1.1191,
         1.3085, 1.3072, 1.3493, 1.3198, 1.2836, 1.2524, 1.2999, 1.2718, 1.2718,
         2.7603, 2.3770, 2.1319, 2.2401, 2.7509, 2.1418, 2.7027, 2.1475, 2.1340,
         1.4044, 1.4383, 1.3964, 1.3861, 1.4172, 1.3953, 1.4071, 1.2048, 1.3462,
         1.3921, 1.3116, 1.2165, 1.2671, 1.3859, 1.2440, 1.4228, 1.2623, 1.3184],
        [1.7673, 1.4200, 0.6436, 0.8653, 1.2250, 1.6488, 1.5807, 1.7649, 1.7649,
         1.6543, 1.3882, 1.4715, 0.9959, 1.7596, 0.2941, 1.6389, 1.7776, 1.2797,
         1.3629, 0.9172, 0.7966, 1.1393, 1.6222, 1.7129, 1.3798, 1.7746, 1.7746,
         0.7657, 0.8708, 1.7488, 1.5150, 0.8623, 1.6838, 1.1836, 1.7980, 1.7284,
         0.5880, 0.3656, 0.3291, 0.5406, 0.8217, 0.9798, 0.4882, 8.5067, 6.8345,
         0.8187, 1.3062, 1.3969, 1.6433, 1.0735, 1.6234, 0.4614, 1.6870, 1.8154],
        [1.3241, 1.3516, 1.4098, 1.3874, 1.3576, 1.3290, 1.2925, 1.3219, 1.3219,
         1.2915, 1.3915, 1.3019, 1.4126, 1.3722, 1.4543, 1.2894, 1.3754, 1.3005,
         1.3701, 1.3978, 1.4109, 1.3805, 1.3453, 1.3361, 1.2992, 1.3336, 1.3336,
         1.3748, 1.4262, 1.3537, 1.1879, 1.3213, 1.2221, 1.3827, 1.2289, 1.3562,
         1.4648, 1.1942, 1.4867, 1.4726, 1.0876, 0.9990, 1.4708, 1.4459, 0.8940,
         2.7877, 2.3674, 2.8561, 2.5732, 2.0547, 1.7966, 2.6550, 2.6962, 1.7824]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 140 : 182.20054038592536
Test loss for epoch 140 : 182.22674896959907
Test Precision for epoch 140 : 0.26153846153846155
Test Recall for epoch 140 : 0.26153846153846155
Test F1 for epoch 140 : 0.26153846153846155


theta for epoch 141 : tensor([[2.3328, 2.3575, 2.4222, 2.4998, 2.4670, 2.3369, 2.4484, 2.3309, 2.3309,
         1.3048, 1.3146, 1.3179, 1.3320, 1.2914, 1.3741, 1.3027, 1.2947, 1.2688,
         1.2881, 1.2718, 1.2854, 1.2994, 1.2634, 1.2550, 1.2802, 1.2517, 1.2517,
         1.2935, 1.3453, 1.2725, 1.2975, 1.3393, 1.2839, 1.3016, 1.2353, 1.2749,
         1.3867, 1.4206, 1.4087, 1.3947, 1.3996, 1.3414, 1.3926, 1.3765, 1.3300,
         1.3715, 1.3224, 1.3130, 1.2952, 1.3653, 1.3157, 1.4018, 1.2905, 1.2986],
        [1.3264, 1.2253, 1.0404, 1.2621, 1.3387, 1.3767, 1.2973, 1.3696, 1.3696,
         1.6664, 1.9160, 1.6581, 2.4277, 1.7067, 4.3248, 1.7651, 1.5986, 4.0576,
         1.1639, 1.2351, 1.0162, 1.2107, 1.3481, 1.3832, 1.3589, 1.3811, 1.3811,
         1.3322, 1.0872, 1.4011, 1.3769, 1.1685, 1.4127, 1.4236, 1.3654, 1.3819,
         1.4254, 1.5441, 1.4807, 1.4096, 1.3998, 1.5091, 1.4655, 0.6137, 1.4498,
         1.0623, 1.4492, 1.4373, 1.4228, 1.0997, 1.4409, 0.8914, 1.4180, 1.4264],
        [1.2481, 1.2754, 1.3335, 1.3106, 1.2804, 1.2530, 1.2605, 1.2459, 1.2459,
         1.3109, 1.3210, 1.3239, 1.3375, 1.2974, 1.3242, 1.3087, 1.2885, 1.2312,
         2.3944, 2.4497, 2.5668, 2.5052, 2.2778, 2.3656, 2.4066, 2.2680, 2.2680,
         1.3341, 1.3077, 1.2786, 1.3038, 1.3346, 1.2902, 1.3086, 1.2860, 1.2810,
         1.3922, 1.4261, 1.4143, 1.3878, 1.4050, 1.3975, 1.3982, 1.2835, 1.3227,
         1.3309, 1.3284, 1.3190, 1.3011, 1.2813, 1.3221, 1.3606, 1.2962, 1.3045],
        [1.2619, 1.2894, 1.2708, 1.2475, 1.2945, 1.2668, 1.2749, 1.2597, 1.2597,
         1.3244, 1.2649, 1.3375, 1.3257, 1.3107, 1.2967, 1.3222, 1.3136, 1.1201,
         1.3080, 1.3072, 1.3488, 1.3193, 1.2831, 1.2522, 1.2994, 1.2713, 1.2713,
         2.7642, 2.3827, 2.1368, 2.2453, 2.7550, 2.1466, 2.7068, 2.1523, 2.1389,
         1.4042, 1.4381, 1.3966, 1.3863, 1.4170, 1.3954, 1.4069, 1.2058, 1.3458,
         1.3916, 1.3116, 1.2163, 1.2666, 1.3854, 1.2444, 1.4223, 1.2618, 1.3179],
        [1.7682, 1.4209, 0.6445, 0.8661, 1.2259, 1.6498, 1.5817, 1.7659, 1.7659,
         1.6553, 1.3885, 1.4726, 0.9967, 1.7606, 0.2955, 1.6399, 1.7787, 1.2796,
         1.3640, 0.9181, 0.7976, 1.1404, 1.6232, 1.7136, 1.3811, 1.7756, 1.7756,
         0.7663, 0.8720, 1.7498, 1.5162, 0.8626, 1.6847, 1.1838, 1.7990, 1.7292,
         0.5847, 0.3626, 0.3264, 0.5375, 0.8177, 0.9756, 0.4850, 8.5524, 6.8554,
         0.8198, 1.3068, 1.3977, 1.6441, 1.0746, 1.6236, 0.4626, 1.6882, 1.8163],
        [1.3237, 1.3512, 1.4094, 1.3870, 1.3572, 1.3285, 1.2921, 1.3215, 1.3215,
         1.2912, 1.3914, 1.3016, 1.4124, 1.3719, 1.4541, 1.2891, 1.3751, 1.3002,
         1.3697, 1.3975, 1.4105, 1.3801, 1.3449, 1.3358, 1.2986, 1.3332, 1.3332,
         1.3745, 1.4259, 1.3534, 1.1872, 1.3213, 1.2219, 1.3825, 1.2285, 1.3558,
         1.4646, 1.1937, 1.4865, 1.4724, 1.0870, 0.9984, 1.4706, 1.4456, 0.8933,
         2.7934, 2.3715, 2.8633, 2.5775, 2.0577, 1.7990, 2.6595, 2.7034, 1.7847]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 141 : 182.1918061575979
Test loss for epoch 141 : 182.21847847949368
Test Precision for epoch 141 : 0.26153846153846155
Test Recall for epoch 141 : 0.26153846153846155
Test F1 for epoch 141 : 0.26153846153846155


theta for epoch 142 : tensor([[2.3372, 2.3618, 2.4266, 2.5047, 2.4718, 2.3413, 2.4533, 2.3353, 2.3353,
         1.3045, 1.3142, 1.3175, 1.3317, 1.2910, 1.3738, 1.3024, 1.2943, 1.2685,
         1.2877, 1.2714, 1.2850, 1.2990, 1.2630, 1.2546, 1.2798, 1.2513, 1.2513,
         1.2931, 1.3449, 1.2720, 1.2970, 1.3389, 1.2834, 1.3012, 1.2348, 1.2744,
         1.3866, 1.4205, 1.4085, 1.3945, 1.3995, 1.3412, 1.3925, 1.3760, 1.3297,
         1.3711, 1.3220, 1.3126, 1.2948, 1.3650, 1.3153, 1.4015, 1.2900, 1.2982],
        [1.3261, 1.2252, 1.0402, 1.2619, 1.3387, 1.3765, 1.2970, 1.3694, 1.3694,
         1.6679, 1.9178, 1.6598, 2.4295, 1.7085, 4.3392, 1.7667, 1.6002, 4.0730,
         1.1636, 1.2348, 1.0163, 1.2105, 1.3478, 1.3830, 1.3586, 1.3808, 1.3808,
         1.3320, 1.0870, 1.4008, 1.3766, 1.1684, 1.4124, 1.4235, 1.3650, 1.3818,
         1.4256, 1.5442, 1.4806, 1.4095, 1.3999, 1.5092, 1.4655, 0.6136, 1.4496,
         1.0623, 1.4490, 1.4371, 1.4226, 1.0995, 1.4407, 0.8916, 1.4178, 1.4262],
        [1.2477, 1.2750, 1.3331, 1.3102, 1.2800, 1.2526, 1.2601, 1.2455, 1.2455,
         1.3105, 1.3207, 1.3235, 1.3372, 1.2970, 1.3239, 1.3083, 1.2880, 1.2309,
         2.3990, 2.4544, 2.5717, 2.5101, 2.2821, 2.3702, 2.4112, 2.2722, 2.2722,
         1.3337, 1.3073, 1.2781, 1.3033, 1.3342, 1.2897, 1.3082, 1.2856, 1.2805,
         1.3921, 1.4261, 1.4141, 1.3876, 1.4049, 1.3974, 1.3981, 1.2831, 1.3223,
         1.3306, 1.3281, 1.3186, 1.3007, 1.2810, 1.3217, 1.3602, 1.2958, 1.3041],
        [1.2614, 1.2889, 1.2711, 1.2478, 1.2939, 1.2663, 1.2743, 1.2592, 1.2592,
         1.3239, 1.2650, 1.3370, 1.3256, 1.3102, 1.2963, 1.3217, 1.3131, 1.1211,
         1.3075, 1.3071, 1.3483, 1.3188, 1.2825, 1.2520, 1.2989, 1.2708, 1.2708,
         2.7681, 2.3884, 2.1417, 2.2505, 2.7590, 2.1515, 2.7109, 2.1571, 2.1438,
         1.4039, 1.4379, 1.3967, 1.3864, 1.4168, 1.3955, 1.4067, 1.2069, 1.3454,
         1.3911, 1.3117, 1.2162, 1.2661, 1.3849, 1.2449, 1.4218, 1.2612, 1.3174],
        [1.7692, 1.4219, 0.6453, 0.8668, 1.2267, 1.6508, 1.5828, 1.7668, 1.7668,
         1.6563, 1.3888, 1.4736, 0.9974, 1.7615, 0.2969, 1.6408, 1.7797, 1.2794,
         1.3651, 0.9190, 0.7987, 1.1415, 1.6242, 1.7142, 1.3823, 1.7765, 1.7765,
         0.7668, 0.8731, 1.7507, 1.5174, 0.8629, 1.6854, 1.1839, 1.8000, 1.7299,
         0.5815, 0.3597, 0.3238, 0.5344, 0.8138, 0.9715, 0.4819, 8.5979, 6.8759,
         0.8210, 1.3074, 1.3986, 1.6449, 1.0757, 1.6238, 0.4638, 1.6894, 1.8172],
        [1.3233, 1.3508, 1.4090, 1.3867, 1.3568, 1.3281, 1.2917, 1.3211, 1.3211,
         1.2909, 1.3912, 1.3014, 1.4121, 1.3716, 1.4538, 1.2887, 1.3748, 1.2999,
         1.3694, 1.3971, 1.4102, 1.3798, 1.3445, 1.3354, 1.2981, 1.3328, 1.3328,
         1.3742, 1.4255, 1.3530, 1.1864, 1.3212, 1.2217, 1.3822, 1.2280, 1.3554,
         1.4645, 1.1932, 1.4863, 1.4723, 1.0865, 0.9978, 1.4705, 1.4453, 0.8926,
         2.7990, 2.3756, 2.8706, 2.5817, 2.0607, 1.8013, 2.6640, 2.7106, 1.7871]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 142 : 182.1831966091463
Test loss for epoch 142 : 182.21035271169123
Test Precision for epoch 142 : 0.26153846153846155
Test Recall for epoch 142 : 0.26153846153846155
Test F1 for epoch 142 : 0.26153846153846155


theta for epoch 143 : tensor([[2.3416, 2.3662, 2.4309, 2.5095, 2.4767, 2.3456, 2.4581, 2.3397, 2.3397,
         1.3040, 1.3138, 1.3170, 1.3313, 1.2905, 1.3734, 1.3019, 1.2938, 1.2680,
         1.2872, 1.2709, 1.2846, 1.2985, 1.2626, 1.2541, 1.2793, 1.2509, 1.2509,
         1.2928, 1.3444, 1.2715, 1.2965, 1.3385, 1.2830, 1.3009, 1.2343, 1.2739,
         1.3865, 1.4205, 1.4083, 1.3944, 1.3995, 1.3411, 1.3924, 1.3756, 1.3294,
         1.3707, 1.3217, 1.3122, 1.2944, 1.3646, 1.3149, 1.4011, 1.2896, 1.2978],
        [1.3259, 1.2250, 1.0401, 1.2617, 1.3387, 1.3762, 1.2968, 1.3691, 1.3691,
         1.6694, 1.9195, 1.6614, 2.4313, 1.7103, 4.3535, 1.7683, 1.6018, 4.0884,
         1.1633, 1.2346, 1.0163, 1.2102, 1.3476, 1.3827, 1.3584, 1.3806, 1.3806,
         1.3319, 1.0868, 1.4005, 1.3763, 1.1682, 1.4121, 1.4234, 1.3646, 1.3817,
         1.4258, 1.5443, 1.4806, 1.4095, 1.4001, 1.5094, 1.4655, 0.6135, 1.4494,
         1.0622, 1.4488, 1.4369, 1.4224, 1.0993, 1.4404, 0.8917, 1.4175, 1.4260],
        [1.2473, 1.2747, 1.3328, 1.3099, 1.2797, 1.2522, 1.2597, 1.2451, 1.2451,
         1.3100, 1.3203, 1.3231, 1.3369, 1.2965, 1.3236, 1.3079, 1.2876, 1.2306,
         2.4035, 2.4591, 2.5767, 2.5150, 2.2863, 2.3748, 2.4158, 2.2765, 2.2765,
         1.3334, 1.3069, 1.2776, 1.3028, 1.3338, 1.2892, 1.3078, 1.2851, 1.2801,
         1.3920, 1.4260, 1.4140, 1.3875, 1.4049, 1.3973, 1.3981, 1.2828, 1.3220,
         1.3303, 1.3278, 1.3182, 1.3004, 1.2808, 1.3213, 1.3600, 1.2954, 1.3037],
        [1.2608, 1.2884, 1.2714, 1.2481, 1.2934, 1.2658, 1.2738, 1.2586, 1.2586,
         1.3233, 1.2650, 1.3365, 1.3255, 1.3097, 1.2958, 1.3211, 1.3125, 1.1221,
         1.3069, 1.3071, 1.3478, 1.3182, 1.2820, 1.2518, 1.2983, 1.2702, 1.2702,
         2.7719, 2.3941, 2.1466, 2.2557, 2.7630, 2.1564, 2.7150, 2.1619, 2.1487,
         1.4037, 1.4378, 1.3969, 1.3866, 1.4166, 1.3957, 1.4066, 1.2079, 1.3450,
         1.3906, 1.3117, 1.2160, 1.2657, 1.3844, 1.2453, 1.4213, 1.2607, 1.3169],
        [1.7702, 1.4228, 0.6462, 0.8675, 1.2277, 1.6518, 1.5838, 1.7678, 1.7678,
         1.6571, 1.3891, 1.4745, 0.9980, 1.7624, 0.2982, 1.6417, 1.7806, 1.2792,
         1.3661, 0.9199, 0.7997, 1.1426, 1.6252, 1.7149, 1.3835, 1.7775, 1.7775,
         0.7674, 0.8743, 1.7515, 1.5185, 0.8631, 1.6861, 1.1840, 1.8009, 1.7306,
         0.5783, 0.3568, 0.3212, 0.5313, 0.8100, 0.9674, 0.4788, 8.6433, 6.8959,
         0.8222, 1.3080, 1.3994, 1.6457, 1.0767, 1.6240, 0.4649, 1.6905, 1.8182],
        [1.3230, 1.3504, 1.4087, 1.3863, 1.3565, 1.3278, 1.2914, 1.3207, 1.3207,
         1.2904, 1.3910, 1.3011, 1.4118, 1.3712, 1.4534, 1.2883, 1.3744, 1.2996,
         1.3690, 1.3968, 1.4098, 1.3794, 1.3441, 1.3350, 1.2975, 1.3324, 1.3324,
         1.3739, 1.4251, 1.3526, 1.1857, 1.3211, 1.2214, 1.3819, 1.2275, 1.3550,
         1.4645, 1.1927, 1.4862, 1.4722, 1.0860, 0.9973, 1.4705, 1.4451, 0.8920,
         2.8047, 2.3796, 2.8779, 2.5860, 2.0636, 1.8036, 2.6686, 2.7178, 1.7893]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 143 : 182.17470954001797
Test loss for epoch 143 : 182.20232435024369
Test Precision for epoch 143 : 0.26153846153846155
Test Recall for epoch 143 : 0.26153846153846155
Test F1 for epoch 143 : 0.26153846153846155


theta for epoch 144 : tensor([[2.3459, 2.3705, 2.4352, 2.5143, 2.4815, 2.3499, 2.4629, 2.3440, 2.3440,
         1.3036, 1.3134, 1.3166, 1.3310, 1.2901, 1.3731, 1.3015, 1.2934, 1.2676,
         1.2869, 1.2706, 1.2842, 1.2982, 1.2622, 1.2538, 1.2790, 1.2505, 1.2505,
         1.2925, 1.3440, 1.2710, 1.2961, 1.3382, 1.2825, 1.3006, 1.2338, 1.2735,
         1.3864, 1.4204, 1.4082, 1.3943, 1.3994, 1.3409, 1.3923, 1.3752, 1.3291,
         1.3704, 1.3213, 1.3118, 1.2940, 1.3642, 1.3145, 1.4008, 1.2891, 1.2974],
        [1.3256, 1.2248, 1.0399, 1.2615, 1.3386, 1.3759, 1.2965, 1.3688, 1.3688,
         1.6709, 1.9213, 1.6630, 2.4332, 1.7120, 4.3678, 1.7700, 1.6033, 4.1038,
         1.1630, 1.2343, 1.0164, 1.2100, 1.3473, 1.3825, 1.3581, 1.3803, 1.3803,
         1.3317, 1.0865, 1.4002, 1.3760, 1.1681, 1.4118, 1.4232, 1.3643, 1.3816,
         1.4261, 1.5443, 1.4805, 1.4094, 1.4002, 1.5095, 1.4654, 0.6134, 1.4492,
         1.0621, 1.4486, 1.4367, 1.4221, 1.0991, 1.4402, 0.8918, 1.4172, 1.4257],
        [1.2469, 1.2743, 1.3325, 1.3095, 1.2793, 1.2518, 1.2593, 1.2447, 1.2447,
         1.3096, 1.3199, 1.3227, 1.3366, 1.2961, 1.3232, 1.3075, 1.2871, 1.2303,
         2.4080, 2.4637, 2.5816, 2.5199, 2.2905, 2.3794, 2.4204, 2.2806, 2.2806,
         1.3330, 1.3066, 1.2772, 1.3024, 1.3335, 1.2888, 1.3075, 1.2847, 1.2797,
         1.3919, 1.4260, 1.4138, 1.3873, 1.4048, 1.3972, 1.3980, 1.2825, 1.3216,
         1.3300, 1.3274, 1.3179, 1.3000, 1.2805, 1.3209, 1.3596, 1.2949, 1.3033],
        [1.2603, 1.2879, 1.2717, 1.2484, 1.2929, 1.2652, 1.2733, 1.2581, 1.2581,
         1.3228, 1.2651, 1.3359, 1.3254, 1.3091, 1.2953, 1.3206, 1.3119, 1.1231,
         1.3064, 1.3071, 1.3473, 1.3177, 1.2814, 1.2516, 1.2978, 1.2697, 1.2697,
         2.7757, 2.3998, 2.1514, 2.2609, 2.7670, 2.1613, 2.7190, 2.1667, 2.1535,
         1.4034, 1.4376, 1.3971, 1.3867, 1.4164, 1.3958, 1.4064, 1.2090, 1.3446,
         1.3900, 1.3117, 1.2158, 1.2651, 1.3839, 1.2457, 1.4208, 1.2601, 1.3164],
        [1.7711, 1.4238, 0.6470, 0.8683, 1.2285, 1.6528, 1.5848, 1.7688, 1.7688,
         1.6580, 1.3894, 1.4755, 0.9987, 1.7633, 0.2995, 1.6426, 1.7816, 1.2789,
         1.3671, 0.9208, 0.8007, 1.1436, 1.6262, 1.7155, 1.3847, 1.7784, 1.7784,
         0.7679, 0.8754, 1.7525, 1.5197, 0.8635, 1.6869, 1.1841, 1.8019, 1.7314,
         0.5751, 0.3540, 0.3187, 0.5283, 0.8062, 0.9634, 0.4758, 8.6885, 6.9155,
         0.8234, 1.3086, 1.4002, 1.6465, 1.0778, 1.6241, 0.4661, 1.6917, 1.8191],
        [1.3226, 1.3501, 1.4083, 1.3860, 1.3562, 1.3274, 1.2910, 1.3203, 1.3203,
         1.2901, 1.3908, 1.3008, 1.4115, 1.3708, 1.4531, 1.2880, 1.3740, 1.2992,
         1.3686, 1.3964, 1.4095, 1.3791, 1.3438, 1.3347, 1.2969, 1.3321, 1.3321,
         1.3737, 1.4247, 1.3522, 1.1850, 1.3211, 1.2212, 1.3817, 1.2270, 1.3546,
         1.4644, 1.1922, 1.4860, 1.4721, 1.0855, 0.9967, 1.4704, 1.4449, 0.8914,
         2.8105, 2.3836, 2.8852, 2.5902, 2.0665, 1.8058, 2.6732, 2.7249, 1.7916]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 144 : 182.16634217654607
Test loss for epoch 144 : 182.19443342238733
Test Precision for epoch 144 : 0.26153846153846155
Test Recall for epoch 144 : 0.26153846153846155
Test F1 for epoch 144 : 0.26153846153846155


theta for epoch 145 : tensor([[2.3502, 2.3748, 2.4395, 2.5191, 2.4863, 2.3542, 2.4677, 2.3483, 2.3483,
         1.3032, 1.3131, 1.3162, 1.3307, 1.2897, 1.3728, 1.3011, 1.2930, 1.2673,
         1.2865, 1.2702, 1.2838, 1.2978, 1.2618, 1.2534, 1.2786, 1.2501, 1.2501,
         1.2922, 1.3436, 1.2706, 1.2956, 1.3379, 1.2821, 1.3003, 1.2334, 1.2730,
         1.3862, 1.4202, 1.4080, 1.3941, 1.3992, 1.3407, 1.3921, 1.3747, 1.3287,
         1.3699, 1.3209, 1.3113, 1.2936, 1.3638, 1.3140, 1.4003, 1.2886, 1.2969],
        [1.3253, 1.2246, 1.0398, 1.2612, 1.3386, 1.3756, 1.2961, 1.3685, 1.3685,
         1.6724, 1.9230, 1.6647, 2.4351, 1.7137, 4.3822, 1.7716, 1.6049, 4.1192,
         1.1628, 1.2341, 1.0165, 1.2097, 1.3471, 1.3823, 1.3578, 1.3801, 1.3801,
         1.3316, 1.0863, 1.3999, 1.3758, 1.1681, 1.4115, 1.4231, 1.3640, 1.3816,
         1.4262, 1.5444, 1.4804, 1.4094, 1.4004, 1.5096, 1.4654, 0.6133, 1.4490,
         1.0619, 1.4483, 1.4365, 1.4218, 1.0988, 1.4399, 0.8919, 1.4169, 1.4254],
        [1.2465, 1.2739, 1.3321, 1.3091, 1.2790, 1.2514, 1.2589, 1.2443, 1.2443,
         1.3093, 1.3196, 1.3223, 1.3363, 1.2958, 1.3229, 1.3072, 1.2867, 1.2301,
         2.4125, 2.4684, 2.5865, 2.5247, 2.2947, 2.3839, 2.4250, 2.2848, 2.2848,
         1.3327, 1.3063, 1.2768, 1.3020, 1.3332, 1.2884, 1.3072, 1.2843, 1.2793,
         1.3918, 1.4259, 1.4137, 1.3871, 1.4047, 1.3971, 1.3979, 1.2822, 1.3213,
         1.3296, 1.3270, 1.3174, 1.2996, 1.2802, 1.3205, 1.3593, 1.2945, 1.3029],
        [1.2598, 1.2874, 1.2720, 1.2488, 1.2925, 1.2648, 1.2728, 1.2576, 1.2576,
         1.3223, 1.2653, 1.3355, 1.3254, 1.3086, 1.2949, 1.3201, 1.3115, 1.1241,
         1.3059, 1.3071, 1.3469, 1.3173, 1.2810, 1.2515, 1.2973, 1.2692, 1.2692,
         2.7795, 2.4055, 2.1562, 2.2661, 2.7709, 2.1661, 2.7229, 2.1714, 2.1584,
         1.4032, 1.4374, 1.3972, 1.3868, 1.4162, 1.3959, 1.4062, 1.2100, 1.3442,
         1.3895, 1.3117, 1.2156, 1.2647, 1.3834, 1.2462, 1.4203, 1.2596, 1.3159],
        [1.7721, 1.4247, 0.6479, 0.8690, 1.2294, 1.6538, 1.5858, 1.7697, 1.7697,
         1.6589, 1.3896, 1.4765, 0.9994, 1.7643, 0.3008, 1.6436, 1.7826, 1.2787,
         1.3681, 0.9217, 0.8017, 1.1447, 1.6272, 1.7162, 1.3859, 1.7794, 1.7794,
         0.7685, 0.8766, 1.7534, 1.5209, 0.8638, 1.6876, 1.1842, 1.8029, 1.7321,
         0.5720, 0.3511, 0.3162, 0.5254, 0.8024, 0.9594, 0.4729, 8.7335, 6.9346,
         0.8245, 1.3092, 1.4010, 1.6473, 1.0788, 1.6242, 0.4672, 1.6928, 1.8199],
        [1.3222, 1.3497, 1.4079, 1.3856, 1.3558, 1.3270, 1.2906, 1.3199, 1.3199,
         1.2897, 1.3906, 1.3005, 1.4113, 1.3705, 1.4528, 1.2876, 1.3737, 1.2990,
         1.3683, 1.3961, 1.4092, 1.3788, 1.3434, 1.3343, 1.2964, 1.3317, 1.3317,
         1.3734, 1.4243, 1.3518, 1.1843, 1.3210, 1.2210, 1.3814, 1.2266, 1.3542,
         1.4642, 1.1917, 1.4859, 1.4720, 1.0850, 0.9961, 1.4703, 1.4447, 0.8908,
         2.8162, 2.3876, 2.8925, 2.5945, 2.0693, 1.8081, 2.6777, 2.7319, 1.7938]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 145 : 182.15809199296524
Test loss for epoch 145 : 182.18665820659635
Test Precision for epoch 145 : 0.26153846153846155
Test Recall for epoch 145 : 0.26153846153846155
Test F1 for epoch 145 : 0.26153846153846155


theta for epoch 146 : tensor([[2.3545, 2.3791, 2.4439, 2.5240, 2.4911, 2.3586, 2.4725, 2.3526, 2.3526,
         1.3028, 1.3127, 1.3158, 1.3303, 1.2893, 1.3725, 1.3007, 1.2926, 1.2669,
         1.2861, 1.2698, 1.2833, 1.2974, 1.2614, 1.2530, 1.2782, 1.2497, 1.2497,
         1.2919, 1.3432, 1.2701, 1.2952, 1.3376, 1.2817, 1.3000, 1.2329, 1.2725,
         1.3860, 1.4201, 1.4078, 1.3939, 1.3991, 1.3404, 1.3920, 1.3742, 1.3283,
         1.3695, 1.3205, 1.3109, 1.2931, 1.3634, 1.3136, 1.3999, 1.2881, 1.2964],
        [1.3250, 1.2245, 1.0396, 1.2610, 1.3386, 1.3754, 1.2959, 1.3683, 1.3683,
         1.6739, 1.9247, 1.6662, 2.4369, 1.7154, 4.3966, 1.7731, 1.6063, 4.1347,
         1.1625, 1.2339, 1.0166, 1.2095, 1.3468, 1.3820, 1.3576, 1.3799, 1.3799,
         1.3315, 1.0861, 1.3996, 1.3756, 1.1680, 1.4112, 1.4230, 1.3637, 1.3815,
         1.4264, 1.5444, 1.4803, 1.4093, 1.4005, 1.5096, 1.4653, 0.6131, 1.4488,
         1.0618, 1.4481, 1.4363, 1.4216, 1.0986, 1.4397, 0.8920, 1.4166, 1.4252],
        [1.2461, 1.2735, 1.3317, 1.3088, 1.2786, 1.2510, 1.2585, 1.2439, 1.2439,
         1.3089, 1.3193, 1.3220, 1.3360, 1.2954, 1.3226, 1.3068, 1.2863, 1.2298,
         2.4169, 2.4731, 2.5915, 2.5295, 2.2989, 2.3884, 2.4295, 2.2890, 2.2890,
         1.3324, 1.3060, 1.2764, 1.3016, 1.3329, 1.2880, 1.3070, 1.2839, 1.2789,
         1.3916, 1.4258, 1.4135, 1.3869, 1.4046, 1.3969, 1.3977, 1.2818, 1.3209,
         1.3293, 1.3267, 1.3171, 1.2992, 1.2800, 1.3201, 1.3590, 1.2940, 1.3025],
        [1.2593, 1.2869, 1.2723, 1.2491, 1.2920, 1.2643, 1.2723, 1.2571, 1.2571,
         1.3219, 1.2655, 1.3350, 1.3254, 1.3082, 1.2945, 1.3197, 1.3110, 1.1252,
         1.3055, 1.3071, 1.3465, 1.3168, 1.2805, 1.2514, 1.2969, 1.2688, 1.2688,
         2.7832, 2.4111, 2.1610, 2.2712, 2.7747, 2.1709, 2.7268, 2.1761, 2.1631,
         1.4030, 1.4372, 1.3974, 1.3870, 1.4160, 1.3960, 1.4061, 1.2111, 1.3438,
         1.3890, 1.3118, 1.2155, 1.2642, 1.3829, 1.2467, 1.4198, 1.2591, 1.3154],
        [1.7730, 1.4256, 0.6486, 0.8696, 1.2302, 1.6547, 1.5867, 1.7706, 1.7706,
         1.6598, 1.3898, 1.4774, 1.0000, 1.7651, 0.3020, 1.6444, 1.7835, 1.2784,
         1.3691, 0.9226, 0.8026, 1.1457, 1.6281, 1.7168, 1.3871, 1.7803, 1.7803,
         0.7690, 0.8777, 1.7542, 1.5221, 0.8641, 1.6884, 1.1844, 1.8038, 1.7328,
         0.5690, 0.3484, 0.3138, 0.5225, 0.7987, 0.9556, 0.4700, 8.7783, 6.9533,
         0.8256, 1.3098, 1.4018, 1.6481, 1.0797, 1.6243, 0.4683, 1.6939, 1.8208],
        [1.3218, 1.3493, 1.4075, 1.3852, 1.3554, 1.3266, 1.2902, 1.3195, 1.3195,
         1.2894, 1.3904, 1.3003, 1.4110, 1.3701, 1.4525, 1.2873, 1.3734, 1.2986,
         1.3679, 1.3958, 1.4088, 1.3784, 1.3431, 1.3340, 1.2958, 1.3314, 1.3314,
         1.3732, 1.4240, 1.3514, 1.1836, 1.3210, 1.2209, 1.3812, 1.2261, 1.3539,
         1.4641, 1.1912, 1.4857, 1.4718, 1.0845, 0.9955, 1.4701, 1.4444, 0.8901,
         2.8220, 2.3916, 2.8998, 2.5989, 2.0722, 1.8103, 2.6823, 2.7390, 1.7960]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 146 : 182.1499558047073
Test loss for epoch 146 : 182.17897221428476
Test Precision for epoch 146 : 0.26153846153846155
Test Recall for epoch 146 : 0.26153846153846155
Test F1 for epoch 146 : 0.26153846153846155


theta for epoch 147 : tensor([[2.3588, 2.3834, 2.4481, 2.5287, 2.4958, 2.3628, 2.4773, 2.3569, 2.3569,
         1.3025, 1.3124, 1.3154, 1.3300, 1.2889, 1.3722, 1.3003, 1.2922, 1.2665,
         1.2857, 1.2694, 1.2829, 1.2970, 1.2610, 1.2526, 1.2778, 1.2493, 1.2493,
         1.2916, 1.3429, 1.2697, 1.2948, 1.3374, 1.2813, 1.2998, 1.2325, 1.2721,
         1.3859, 1.4200, 1.4076, 1.3937, 1.3990, 1.3402, 1.3919, 1.3738, 1.3280,
         1.3691, 1.3201, 1.3105, 1.2928, 1.3630, 1.3132, 1.3996, 1.2877, 1.2961],
        [1.3248, 1.2243, 1.0395, 1.2609, 1.3386, 1.3751, 1.2956, 1.3680, 1.3680,
         1.6753, 1.9262, 1.6677, 2.4387, 1.7170, 4.4110, 1.7747, 1.6077, 4.1500,
         1.1623, 1.2337, 1.0166, 1.2093, 1.3466, 1.3818, 1.3573, 1.3796, 1.3796,
         1.3314, 1.0860, 1.3994, 1.3754, 1.1680, 1.4110, 1.4230, 1.3634, 1.3815,
         1.4266, 1.5445, 1.4802, 1.4092, 1.4006, 1.5097, 1.4653, 0.6131, 1.4486,
         1.0618, 1.4480, 1.4361, 1.4214, 1.0985, 1.4395, 0.8922, 1.4163, 1.4250],
        [1.2457, 1.2731, 1.3313, 1.3084, 1.2782, 1.2506, 1.2581, 1.2435, 1.2435,
         1.3086, 1.3189, 1.3216, 1.3357, 1.2950, 1.3223, 1.3064, 1.2858, 1.2296,
         2.4214, 2.4777, 2.5964, 2.5344, 2.3030, 2.3929, 2.4340, 2.2931, 2.2931,
         1.3321, 1.3057, 1.2760, 1.3012, 1.3326, 1.2876, 1.3067, 1.2835, 1.2785,
         1.3915, 1.4257, 1.4133, 1.3867, 1.4045, 1.3968, 1.3976, 1.2815, 1.3206,
         1.3290, 1.3263, 1.3167, 1.2988, 1.2797, 1.3197, 1.3586, 1.2936, 1.3021],
        [1.2588, 1.2864, 1.2727, 1.2495, 1.2915, 1.2638, 1.2718, 1.2566, 1.2566,
         1.3214, 1.2657, 1.3345, 1.3254, 1.3077, 1.2941, 1.3192, 1.3105, 1.1262,
         1.3050, 1.3072, 1.3460, 1.3163, 1.2800, 1.2512, 1.2964, 1.2683, 1.2683,
         2.7869, 2.4168, 2.1658, 2.2764, 2.7786, 2.1757, 2.7307, 2.1809, 2.1679,
         1.4027, 1.4370, 1.3976, 1.3872, 1.4158, 1.3961, 1.4059, 1.2122, 1.3434,
         1.3886, 1.3119, 1.2154, 1.2638, 1.3824, 1.2472, 1.4193, 1.2586, 1.3150],
        [1.7738, 1.4264, 0.6493, 0.8702, 1.2310, 1.6556, 1.5876, 1.7715, 1.7715,
         1.6606, 1.3900, 1.4783, 1.0006, 1.7660, 0.3032, 1.6453, 1.7844, 1.2780,
         1.3700, 0.9233, 0.8035, 1.1466, 1.6290, 1.7173, 1.3882, 1.7812, 1.7812,
         0.7695, 0.8788, 1.7551, 1.5232, 0.8644, 1.6891, 1.1845, 1.8048, 1.7335,
         0.5660, 0.3457, 0.3115, 0.5197, 0.7951, 0.9518, 0.4672, 8.8231, 6.9717,
         0.8267, 1.3103, 1.4026, 1.6488, 1.0807, 1.6243, 0.4693, 1.6950, 1.8217],
        [1.3214, 1.3489, 1.4071, 1.3848, 1.3551, 1.3262, 1.2898, 1.3192, 1.3192,
         1.2891, 1.3903, 1.3000, 1.4108, 1.3698, 1.4522, 1.2869, 1.3730, 1.2984,
         1.3676, 1.3954, 1.4085, 1.3781, 1.3427, 1.3336, 1.2952, 1.3310, 1.3310,
         1.3730, 1.4237, 1.3511, 1.1830, 1.3210, 1.2207, 1.3811, 1.2257, 1.3535,
         1.4640, 1.1907, 1.4855, 1.4717, 1.0839, 0.9950, 1.4700, 1.4442, 0.8895,
         2.8278, 2.3955, 2.9070, 2.6032, 2.0749, 1.8124, 2.6869, 2.7459, 1.7981]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 147 : 182.14193068230168
Test loss for epoch 147 : 182.17143502731076
Test Precision for epoch 147 : 0.26153846153846155
Test Recall for epoch 147 : 0.26153846153846155
Test F1 for epoch 147 : 0.26153846153846155


theta for epoch 148 : tensor([[2.3630, 2.3876, 2.4524, 2.5334, 2.5005, 2.3671, 2.4820, 2.3611, 2.3611,
         1.3021, 1.3121, 1.3151, 1.3298, 1.2885, 1.3719, 1.3000, 1.2918, 1.2662,
         1.2853, 1.2690, 1.2824, 1.2966, 1.2606, 1.2522, 1.2774, 1.2489, 1.2489,
         1.2913, 1.3425, 1.2692, 1.2944, 1.3371, 1.2808, 1.2995, 1.2321, 1.2717,
         1.3857, 1.4199, 1.4074, 1.3936, 1.3989, 1.3401, 1.3917, 1.3733, 1.3277,
         1.3688, 1.3197, 1.3101, 1.2924, 1.3626, 1.3128, 1.3992, 1.2873, 1.2957],
        [1.3246, 1.2242, 1.0394, 1.2607, 1.3386, 1.3749, 1.2954, 1.3678, 1.3678,
         1.6766, 1.9278, 1.6692, 2.4405, 1.7186, 4.4254, 1.7762, 1.6091, 4.1654,
         1.1621, 1.2335, 1.0167, 1.2091, 1.3464, 1.3816, 1.3570, 1.3794, 1.3794,
         1.3313, 1.0858, 1.3991, 1.3751, 1.1679, 1.4107, 1.4229, 1.3631, 1.3814,
         1.4269, 1.5445, 1.4801, 1.4092, 1.4008, 1.5098, 1.4653, 0.6130, 1.4484,
         1.0617, 1.4478, 1.4359, 1.4212, 1.0983, 1.4393, 0.8923, 1.4161, 1.4248],
        [1.2453, 1.2727, 1.3309, 1.3080, 1.2779, 1.2502, 1.2578, 1.2431, 1.2431,
         1.3082, 1.3186, 1.3212, 1.3354, 1.2946, 1.3220, 1.3061, 1.2854, 1.2293,
         2.4258, 2.4823, 2.6013, 2.5391, 2.3071, 2.3973, 2.4386, 2.2972, 2.2972,
         1.3317, 1.3054, 1.2756, 1.3008, 1.3322, 1.2872, 1.3064, 1.2831, 1.2781,
         1.3914, 1.4256, 1.4131, 1.3864, 1.4045, 1.3967, 1.3975, 1.2812, 1.3202,
         1.3287, 1.3260, 1.3163, 1.2985, 1.2795, 1.3194, 1.3583, 1.2932, 1.3017],
        [1.2583, 1.2859, 1.2731, 1.2499, 1.2911, 1.2633, 1.2713, 1.2561, 1.2561,
         1.3209, 1.2659, 1.3340, 1.3254, 1.3072, 1.2937, 1.3187, 1.3100, 1.1273,
         1.3045, 1.3072, 1.3455, 1.3158, 1.2795, 1.2510, 1.2959, 1.2678, 1.2678,
         2.7905, 2.4224, 2.1706, 2.2815, 2.7824, 2.1805, 2.7346, 2.1856, 2.1727,
         1.4025, 1.4368, 1.3977, 1.3873, 1.4156, 1.3962, 1.4058, 1.2133, 1.3430,
         1.3881, 1.3119, 1.2152, 1.2633, 1.3819, 1.2477, 1.4188, 1.2581, 1.3145],
        [1.7747, 1.4273, 0.6501, 0.8709, 1.2319, 1.6565, 1.5885, 1.7724, 1.7724,
         1.6615, 1.3901, 1.4792, 1.0012, 1.7669, 0.3044, 1.6462, 1.7854, 1.2777,
         1.3710, 0.9242, 0.8044, 1.1476, 1.6299, 1.7179, 1.3893, 1.7821, 1.7821,
         0.7699, 0.8799, 1.7560, 1.5243, 0.8646, 1.6898, 1.1845, 1.8057, 1.7342,
         0.5631, 0.3431, 0.3091, 0.5170, 0.7915, 0.9480, 0.4644, 8.8676, 6.9896,
         0.8278, 1.3109, 1.4034, 1.6496, 1.0817, 1.6244, 0.4704, 1.6961, 1.8225],
        [1.3211, 1.3486, 1.4067, 1.3845, 1.3548, 1.3259, 1.2895, 1.3189, 1.3189,
         1.2888, 1.3901, 1.2998, 1.4105, 1.3695, 1.4520, 1.2866, 1.3727, 1.2981,
         1.3672, 1.3951, 1.4082, 1.3778, 1.3424, 1.3333, 1.2947, 1.3307, 1.3307,
         1.3728, 1.4233, 1.3507, 1.1824, 1.3210, 1.2205, 1.3809, 1.2253, 1.3532,
         1.4638, 1.1902, 1.4854, 1.4716, 1.0834, 0.9944, 1.4699, 1.4440, 0.8889,
         2.8335, 2.3994, 2.9143, 2.6074, 2.0776, 1.8145, 2.6914, 2.7528, 1.8002]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 148 : 182.13401561667087
Test loss for epoch 148 : 182.16401968002273
Test Precision for epoch 148 : 0.26153846153846155
Test Recall for epoch 148 : 0.26153846153846155
Test F1 for epoch 148 : 0.26153846153846155


theta for epoch 149 : tensor([[2.3672, 2.3918, 2.4566, 2.5382, 2.5053, 2.3713, 2.4868, 2.3653, 2.3653,
         1.3018, 1.3118, 1.3147, 1.3295, 1.2882, 1.3717, 1.2996, 1.2914, 1.2659,
         1.2850, 1.2686, 1.2820, 1.2963, 1.2602, 1.2518, 1.2770, 1.2486, 1.2486,
         1.2910, 1.3421, 1.2688, 1.2940, 1.3368, 1.2804, 1.2992, 1.2316, 1.2712,
         1.3856, 1.4198, 1.4072, 1.3934, 1.3988, 1.3399, 1.3916, 1.3729, 1.3274,
         1.3684, 1.3194, 1.3098, 1.2921, 1.3623, 1.3125, 1.3988, 1.2869, 1.2953],
        [1.3243, 1.2241, 1.0393, 1.2605, 1.3386, 1.3746, 1.2952, 1.3675, 1.3675,
         1.6780, 1.9293, 1.6707, 2.4423, 1.7201, 4.4398, 1.7777, 1.6105, 4.1809,
         1.1619, 1.2334, 1.0168, 1.2089, 1.3462, 1.3814, 1.3568, 1.3792, 1.3792,
         1.3311, 1.0856, 1.3988, 1.3749, 1.1678, 1.4104, 1.4228, 1.3628, 1.3813,
         1.4271, 1.5446, 1.4800, 1.4091, 1.4009, 1.5099, 1.4652, 0.6129, 1.4483,
         1.0617, 1.4476, 1.4357, 1.4210, 1.0981, 1.4390, 0.8924, 1.4158, 1.4245],
        [1.2450, 1.2724, 1.3306, 1.3077, 1.2776, 1.2498, 1.2574, 1.2428, 1.2428,
         1.3079, 1.3183, 1.3209, 1.3352, 1.2942, 1.3217, 1.3057, 1.2850, 1.2291,
         2.4301, 2.4869, 2.6062, 2.5439, 2.3112, 2.4018, 2.4431, 2.3013, 2.3013,
         1.3314, 1.3050, 1.2752, 1.3004, 1.3319, 1.2868, 1.3061, 1.2827, 1.2777,
         1.3913, 1.4255, 1.4130, 1.3863, 1.4044, 1.3966, 1.3974, 1.2809, 1.3199,
         1.3284, 1.3257, 1.3160, 1.2982, 1.2792, 1.3190, 1.3580, 1.2928, 1.3014],
        [1.2578, 1.2854, 1.2734, 1.2503, 1.2906, 1.2628, 1.2708, 1.2556, 1.2556,
         1.3204, 1.2661, 1.3336, 1.3253, 1.3067, 1.2933, 1.3183, 1.3096, 1.1283,
         1.3040, 1.3072, 1.3450, 1.3154, 1.2790, 1.2509, 1.2954, 1.2673, 1.2673,
         2.7941, 2.4281, 2.1754, 2.2867, 2.7861, 2.1853, 2.7384, 2.1903, 2.1775,
         1.4023, 1.4367, 1.3979, 1.3875, 1.4154, 1.3963, 1.4056, 1.2144, 1.3426,
         1.3876, 1.3119, 1.2151, 1.2629, 1.3815, 1.2483, 1.4184, 1.2575, 1.3140],
        [1.7756, 1.4282, 0.6509, 0.8715, 1.2327, 1.6574, 1.5895, 1.7733, 1.7733,
         1.6623, 1.3903, 1.4801, 1.0018, 1.7677, 0.3056, 1.6470, 1.7863, 1.2773,
         1.3719, 0.9250, 0.8054, 1.1486, 1.6308, 1.7185, 1.3905, 1.7830, 1.7830,
         0.7704, 0.8810, 1.7568, 1.5254, 0.8650, 1.6905, 1.1846, 1.8066, 1.7348,
         0.5602, 0.3404, 0.3068, 0.5142, 0.7879, 0.9442, 0.4616, 8.9119, 7.0070,
         0.8290, 1.3116, 1.4043, 1.6504, 1.0827, 1.6244, 0.4715, 1.6973, 1.8234],
        [1.3208, 1.3483, 1.4064, 1.3842, 1.3545, 1.3256, 1.2892, 1.3186, 1.3186,
         1.2884, 1.3900, 1.2995, 1.4103, 1.3691, 1.4517, 1.2863, 1.3724, 1.2978,
         1.3669, 1.3948, 1.4079, 1.3775, 1.3421, 1.3330, 1.2941, 1.3304, 1.3304,
         1.3725, 1.4229, 1.3503, 1.1816, 1.3209, 1.2203, 1.3806, 1.2248, 1.3528,
         1.4637, 1.1898, 1.4852, 1.4715, 1.0829, 0.9939, 1.4698, 1.4438, 0.8883,
         2.8394, 2.4032, 2.9215, 2.6118, 2.0804, 1.8166, 2.6960, 2.7597, 1.8023]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 149 : 182.12620731948735
Test loss for epoch 149 : 182.15668098480006
Test Precision for epoch 149 : 0.26153846153846155
Test Recall for epoch 149 : 0.26153846153846155
Test F1 for epoch 149 : 0.26153846153846155


theta for epoch 150 : tensor([[2.3714, 2.3960, 2.4608, 2.5429, 2.5099, 2.3755, 2.4914, 2.3695, 2.3695,
         1.3014, 1.3115, 1.3144, 1.3292, 1.2878, 1.3713, 1.2993, 1.2910, 1.2655,
         1.2846, 1.2683, 1.2816, 1.2959, 1.2599, 1.2515, 1.2767, 1.2482, 1.2482,
         1.2907, 1.3417, 1.2683, 1.2935, 1.3365, 1.2799, 1.2989, 1.2311, 1.2707,
         1.3855, 1.4197, 1.4071, 1.3933, 1.3987, 1.3398, 1.3915, 1.3724, 1.3271,
         1.3680, 1.3190, 1.3094, 1.2917, 1.3619, 1.3121, 1.3984, 1.2864, 1.2949],
        [1.3241, 1.2239, 1.0392, 1.2603, 1.3386, 1.3744, 1.2949, 1.3673, 1.3673,
         1.6794, 1.9308, 1.6721, 2.4441, 1.7216, 4.4542, 1.7792, 1.6119, 4.1963,
         1.1617, 1.2332, 1.0169, 1.2087, 1.3460, 1.3812, 1.3566, 1.3790, 1.3790,
         1.3310, 1.0854, 1.3986, 1.3746, 1.1677, 1.4102, 1.4227, 1.3625, 1.3813,
         1.4273, 1.5446, 1.4799, 1.4091, 1.4011, 1.5100, 1.4652, 0.6129, 1.4481,
         1.0616, 1.4474, 1.4355, 1.4208, 1.0979, 1.4388, 0.8925, 1.4155, 1.4243],
        [1.2446, 1.2720, 1.3302, 1.3073, 1.2772, 1.2495, 1.2570, 1.2424, 1.2424,
         1.3075, 1.3180, 1.3205, 1.3349, 1.2939, 1.3214, 1.3054, 1.2846, 1.2289,
         2.4345, 2.4915, 2.6110, 2.5486, 2.3153, 2.4062, 2.4475, 2.3053, 2.3053,
         1.3311, 1.3047, 1.2748, 1.3000, 1.3315, 1.2864, 1.3059, 1.2823, 1.2773,
         1.3912, 1.4255, 1.4129, 1.3861, 1.4044, 1.3965, 1.3973, 1.2806, 1.3196,
         1.3280, 1.3253, 1.3156, 1.2978, 1.2790, 1.3187, 1.3577, 1.2924, 1.3010],
        [1.2573, 1.2849, 1.2738, 1.2506, 1.2901, 1.2623, 1.2703, 1.2551, 1.2551,
         1.3199, 1.2663, 1.3331, 1.3253, 1.3062, 1.2929, 1.3178, 1.3091, 1.1294,
         1.3036, 1.3072, 1.3446, 1.3149, 1.2785, 1.2508, 1.2949, 1.2668, 1.2668,
         2.7977, 2.4337, 2.1802, 2.2918, 2.7899, 2.1901, 2.7422, 2.1950, 2.1823,
         1.4021, 1.4365, 1.3981, 1.3876, 1.4153, 1.3964, 1.4054, 1.2155, 1.3422,
         1.3871, 1.3120, 1.2149, 1.2624, 1.3810, 1.2488, 1.4178, 1.2570, 1.3135],
        [1.7765, 1.4291, 0.6516, 0.8722, 1.2336, 1.6583, 1.5904, 1.7741, 1.7741,
         1.6632, 1.3904, 1.4809, 1.0024, 1.7686, 0.3068, 1.6479, 1.7872, 1.2769,
         1.3729, 0.9259, 0.8063, 1.1495, 1.6318, 1.7190, 1.3916, 1.7839, 1.7839,
         0.7709, 0.8821, 1.7576, 1.5266, 0.8653, 1.6912, 1.1847, 1.8075, 1.7355,
         0.5574, 0.3378, 0.3045, 0.5115, 0.7844, 0.9405, 0.4589, 8.9561, 7.0240,
         0.8301, 1.3121, 1.4051, 1.6512, 1.0836, 1.6244, 0.4725, 1.6983, 1.8243],
        [1.3204, 1.3479, 1.4060, 1.3838, 1.3542, 1.3253, 1.2888, 1.3182, 1.3182,
         1.2881, 1.3898, 1.2993, 1.4100, 1.3688, 1.4515, 1.2860, 1.3721, 1.2976,
         1.3666, 1.3945, 1.4076, 1.3772, 1.3418, 1.3327, 1.2936, 1.3301, 1.3301,
         1.3722, 1.4226, 1.3500, 1.1810, 1.3209, 1.2201, 1.3804, 1.2244, 1.3524,
         1.4637, 1.1893, 1.4851, 1.4714, 1.0825, 0.9934, 1.4698, 1.4436, 0.8878,
         2.8452, 2.4070, 2.9288, 2.6161, 2.0830, 1.8186, 2.7005, 2.7665, 1.8043]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 150 : 182.1185026809691
Test loss for epoch 150 : 182.14946988097995
Test Precision for epoch 150 : 0.26153846153846155
Test Recall for epoch 150 : 0.26153846153846155
Test F1 for epoch 150 : 0.26153846153846155


theta for epoch 151 : tensor([[2.3756, 2.4002, 2.4650, 2.5476, 2.5146, 2.3797, 2.4961, 2.3737, 2.3737,
         1.3010, 1.3111, 1.3140, 1.3289, 1.2874, 1.3710, 1.2989, 1.2906, 1.2652,
         1.2843, 1.2679, 1.2812, 1.2956, 1.2595, 1.2511, 1.2763, 1.2478, 1.2478,
         1.2904, 1.3413, 1.2679, 1.2932, 1.3362, 1.2796, 1.2987, 1.2307, 1.2703,
         1.3854, 1.4196, 1.4069, 1.3932, 1.3986, 1.3396, 1.3914, 1.3720, 1.3268,
         1.3675, 1.3186, 1.3089, 1.2913, 1.3614, 1.3117, 1.3980, 1.2860, 1.2945],
        [1.3238, 1.2238, 1.0391, 1.2601, 1.3386, 1.3741, 1.2947, 1.3671, 1.3671,
         1.6807, 1.9322, 1.6734, 2.4458, 1.7231, 4.4686, 1.7806, 1.6132, 4.2117,
         1.1616, 1.2331, 1.0171, 1.2085, 1.3458, 1.3810, 1.3564, 1.3787, 1.3787,
         1.3309, 1.0852, 1.3983, 1.3744, 1.1677, 1.4099, 1.4227, 1.3622, 1.3813,
         1.4276, 1.5447, 1.4799, 1.4091, 1.4013, 1.5101, 1.4652, 0.6128, 1.4480,
         1.0615, 1.4472, 1.4353, 1.4206, 1.0977, 1.4386, 0.8926, 1.4152, 1.4240],
        [1.2442, 1.2717, 1.3298, 1.3070, 1.2769, 1.2491, 1.2567, 1.2420, 1.2420,
         1.3072, 1.3177, 1.3201, 1.3346, 1.2935, 1.3212, 1.3050, 1.2842, 1.2287,
         2.4388, 2.4961, 2.6158, 2.5533, 2.3193, 2.4105, 2.4520, 2.3093, 2.3093,
         1.3308, 1.3044, 1.2745, 1.2996, 1.3312, 1.2860, 1.3057, 1.2820, 1.2769,
         1.3911, 1.4255, 1.4128, 1.3859, 1.4043, 1.3964, 1.3973, 1.2804, 1.3193,
         1.3277, 1.3250, 1.3152, 1.2975, 1.2788, 1.3183, 1.3574, 1.2921, 1.3007],
        [1.2568, 1.2844, 1.2742, 1.2510, 1.2896, 1.2618, 1.2698, 1.2546, 1.2546,
         1.3195, 1.2666, 1.3326, 1.3253, 1.3057, 1.2925, 1.3173, 1.3086, 1.1305,
         1.3031, 1.3073, 1.3441, 1.3145, 1.2781, 1.2507, 1.2945, 1.2663, 1.2663,
         2.8013, 2.4393, 2.1849, 2.2970, 2.7935, 2.1948, 2.7460, 2.1997, 2.1870,
         1.4019, 1.4363, 1.3983, 1.3878, 1.4151, 1.3965, 1.4053, 1.2166, 1.3419,
         1.3866, 1.3120, 1.2148, 1.2619, 1.3805, 1.2494, 1.4174, 1.2565, 1.3130],
        [1.7773, 1.4299, 0.6523, 0.8727, 1.2343, 1.6592, 1.5912, 1.7750, 1.7750,
         1.6639, 1.3905, 1.4818, 1.0030, 1.7694, 0.3079, 1.6487, 1.7881, 1.2765,
         1.3737, 0.9267, 0.8072, 1.1504, 1.6326, 1.7196, 1.3927, 1.7848, 1.7848,
         0.7714, 0.8831, 1.7585, 1.5277, 0.8656, 1.6919, 1.1848, 1.8084, 1.7361,
         0.5546, 0.3353, 0.3023, 0.5089, 0.7809, 0.9368, 0.4563, 9.0002, 7.0407,
         0.8312, 1.3127, 1.4058, 1.6519, 1.0845, 1.6244, 0.4736, 1.6994, 1.8251],
        [1.3201, 1.3476, 1.4056, 1.3835, 1.3539, 1.3250, 1.2885, 1.3179, 1.3179,
         1.2878, 1.3896, 1.2990, 1.4098, 1.3685, 1.4512, 1.2856, 1.3718, 1.2973,
         1.3663, 1.3942, 1.4073, 1.3769, 1.3415, 1.3324, 1.2931, 1.3298, 1.3298,
         1.3720, 1.4223, 1.3496, 1.1804, 1.3208, 1.2200, 1.3803, 1.2240, 1.3521,
         1.4636, 1.1889, 1.4850, 1.4713, 1.0820, 0.9929, 1.4697, 1.4434, 0.8872,
         2.8510, 2.4108, 2.9360, 2.6204, 2.0856, 1.8206, 2.7050, 2.7733, 1.8063]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 151 : 182.11089975923653
Test loss for epoch 151 : 182.1423609838059
Test Precision for epoch 151 : 0.26153846153846155
Test Recall for epoch 151 : 0.26153846153846155
Test F1 for epoch 151 : 0.26153846153846155


theta for epoch 152 : tensor([[2.3798, 2.4043, 2.4691, 2.5522, 2.5193, 2.3838, 2.5008, 2.3779, 2.3779,
         1.3007, 1.3108, 1.3136, 1.3286, 1.2870, 1.3707, 1.2985, 1.2903, 1.2649,
         1.2839, 1.2675, 1.2808, 1.2952, 1.2592, 1.2508, 1.2760, 1.2475, 1.2475,
         1.2902, 1.3409, 1.2675, 1.2928, 1.3359, 1.2792, 1.2985, 1.2303, 1.2699,
         1.3853, 1.4195, 1.4068, 1.3930, 1.3985, 1.3395, 1.3913, 1.3716, 1.3265,
         1.3672, 1.3183, 1.3086, 1.2910, 1.3611, 1.3114, 1.3976, 1.2856, 1.2942],
        [1.3236, 1.2237, 1.0390, 1.2600, 1.3387, 1.3739, 1.2945, 1.3668, 1.3668,
         1.6820, 1.9336, 1.6748, 2.4476, 1.7245, 4.4831, 1.7821, 1.6145, 4.2271,
         1.1614, 1.2329, 1.0172, 1.2083, 1.3456, 1.3808, 1.3561, 1.3785, 1.3785,
         1.3309, 1.0851, 1.3981, 1.3743, 1.1676, 1.4097, 1.4226, 1.3620, 1.3813,
         1.4278, 1.5448, 1.4798, 1.4091, 1.4014, 1.5102, 1.4651, 0.6128, 1.4478,
         1.0615, 1.4470, 1.4352, 1.4204, 1.0976, 1.4384, 0.8928, 1.4150, 1.4238],
        [1.2439, 1.2713, 1.3294, 1.3066, 1.2766, 1.2487, 1.2563, 1.2417, 1.2417,
         1.3068, 1.3174, 1.3198, 1.3344, 1.2932, 1.3209, 1.3047, 1.2838, 1.2285,
         2.4430, 2.5006, 2.6207, 2.5580, 2.3233, 2.4149, 2.4564, 2.3133, 2.3133,
         1.3305, 1.3042, 1.2741, 1.2993, 1.3309, 1.2857, 1.3054, 1.2816, 1.2765,
         1.3910, 1.4254, 1.4126, 1.3857, 1.4043, 1.3963, 1.3972, 1.2801, 1.3190,
         1.3274, 1.3246, 1.3149, 1.2972, 1.2786, 1.3180, 1.3571, 1.2917, 1.3003],
        [1.2564, 1.2840, 1.2746, 1.2515, 1.2892, 1.2613, 1.2694, 1.2542, 1.2542,
         1.3190, 1.2669, 1.3321, 1.3253, 1.3053, 1.2922, 1.3169, 1.3081, 1.1316,
         1.3027, 1.3073, 1.3437, 1.3140, 1.2776, 1.2506, 1.2940, 1.2659, 1.2659,
         2.8047, 2.4449, 2.1896, 2.3020, 2.7971, 2.1995, 2.7496, 2.2043, 2.1917,
         1.4017, 1.4362, 1.3985, 1.3880, 1.4150, 1.3966, 1.4052, 1.2177, 1.3415,
         1.3862, 1.3121, 1.2147, 1.2615, 1.3800, 1.2500, 1.4169, 1.2560, 1.3126],
        [1.7782, 1.4308, 0.6530, 0.8733, 1.2351, 1.6600, 1.5921, 1.7758, 1.7758,
         1.6647, 1.3906, 1.4826, 1.0036, 1.7702, 0.3090, 1.6495, 1.7890, 1.2760,
         1.3746, 0.9274, 0.8081, 1.1513, 1.6335, 1.7201, 1.3938, 1.7856, 1.7856,
         0.7718, 0.8841, 1.7593, 1.5288, 0.8658, 1.6925, 1.1849, 1.8093, 1.7368,
         0.5519, 0.3327, 0.3001, 0.5063, 0.7775, 0.9332, 0.4537, 9.0441, 7.0569,
         0.8323, 1.3133, 1.4066, 1.6527, 1.0854, 1.6243, 0.4746, 1.7005, 1.8259],
        [1.3198, 1.3472, 1.4052, 1.3831, 1.3535, 1.3247, 1.2881, 1.3176, 1.3176,
         1.2875, 1.3895, 1.2988, 1.4095, 1.3682, 1.4509, 1.2853, 1.3714, 1.2970,
         1.3659, 1.3939, 1.4070, 1.3766, 1.3411, 1.3321, 1.2925, 1.3295, 1.3295,
         1.3718, 1.4219, 1.3493, 1.1797, 1.3208, 1.2198, 1.3801, 1.2236, 1.3517,
         1.4635, 1.1884, 1.4848, 1.4712, 1.0815, 0.9923, 1.4696, 1.4433, 0.8866,
         2.8568, 2.4145, 2.9432, 2.6248, 2.0882, 1.8226, 2.7095, 2.7801, 1.8083]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 152 : 182.10339658557797
Test loss for epoch 152 : 182.13534502967127
Test Precision for epoch 152 : 0.26153846153846155
Test Recall for epoch 152 : 0.26153846153846155
Test F1 for epoch 152 : 0.26153846153846155


theta for epoch 153 : tensor([[2.3839, 2.4085, 2.4733, 2.5568, 2.5239, 2.3880, 2.5054, 2.3820, 2.3820,
         1.3004, 1.3106, 1.3133, 1.3283, 1.2867, 1.3705, 1.2982, 1.2900, 1.2646,
         1.2835, 1.2671, 1.2804, 1.2948, 1.2588, 1.2504, 1.2756, 1.2471, 1.2471,
         1.2899, 1.3406, 1.2671, 1.2924, 1.3357, 1.2788, 1.2983, 1.2300, 1.2696,
         1.3851, 1.4194, 1.4066, 1.3928, 1.3984, 1.3393, 1.3911, 1.3711, 1.3261,
         1.3668, 1.3179, 1.3082, 1.2906, 1.3607, 1.3110, 1.3972, 1.2852, 1.2938],
        [1.3234, 1.2236, 1.0389, 1.2598, 1.3387, 1.3737, 1.2943, 1.3666, 1.3666,
         1.6833, 1.9349, 1.6761, 2.4493, 1.7260, 4.4975, 1.7835, 1.6157, 4.2425,
         1.1612, 1.2327, 1.0173, 1.2082, 1.3454, 1.3806, 1.3559, 1.3783, 1.3783,
         1.3308, 1.0849, 1.3979, 1.3741, 1.1676, 1.4095, 1.4226, 1.3617, 1.3812,
         1.4280, 1.5448, 1.4797, 1.4090, 1.4016, 1.5103, 1.4651, 0.6128, 1.4477,
         1.0614, 1.4468, 1.4350, 1.4202, 1.0975, 1.4382, 0.8929, 1.4148, 1.4236],
        [1.2435, 1.2709, 1.3290, 1.3062, 1.2762, 1.2484, 1.2560, 1.2413, 1.2413,
         1.3065, 1.3171, 1.3195, 1.3341, 1.2928, 1.3206, 1.3044, 1.2834, 1.2284,
         2.4473, 2.5052, 2.6255, 2.5627, 2.3273, 2.4192, 2.4609, 2.3173, 2.3173,
         1.3302, 1.3039, 1.2737, 1.2989, 1.3306, 1.2853, 1.3052, 1.2813, 1.2762,
         1.3909, 1.4253, 1.4124, 1.3855, 1.4042, 1.3962, 1.3971, 1.2798, 1.3187,
         1.3271, 1.3243, 1.3145, 1.2968, 1.2783, 1.3177, 1.3568, 1.2913, 1.3000],
        [1.2559, 1.2835, 1.2751, 1.2520, 1.2888, 1.2608, 1.2689, 1.2537, 1.2537,
         1.3186, 1.2672, 1.3317, 1.3254, 1.3049, 1.2918, 1.3165, 1.3077, 1.1327,
         1.3022, 1.3074, 1.3433, 1.3136, 1.2772, 1.2505, 1.2936, 1.2655, 1.2655,
         2.8082, 2.4505, 2.1943, 2.3071, 2.8007, 2.2042, 2.7532, 2.2089, 2.1964,
         1.4014, 1.4360, 1.3987, 1.3882, 1.4148, 1.3967, 1.4050, 1.2189, 1.3411,
         1.3857, 1.3121, 1.2146, 1.2611, 1.3796, 1.2506, 1.4165, 1.2555, 1.3122],
        [1.7790, 1.4316, 0.6537, 0.8739, 1.2359, 1.6609, 1.5929, 1.7766, 1.7766,
         1.6655, 1.3907, 1.4834, 1.0042, 1.7710, 0.3101, 1.6503, 1.7899, 1.2756,
         1.3755, 0.9282, 0.8089, 1.1522, 1.6343, 1.7206, 1.3949, 1.7865, 1.7865,
         0.7722, 0.8852, 1.7601, 1.5299, 0.8661, 1.6932, 1.1850, 1.8102, 1.7374,
         0.5492, 0.3302, 0.2979, 0.5038, 0.7741, 0.9296, 0.4511, 9.0879, 7.0727,
         0.8334, 1.3139, 1.4074, 1.6534, 1.0863, 1.6243, 0.4756, 1.7015, 1.8267],
        [1.3195, 1.3470, 1.4049, 1.3829, 1.3533, 1.3244, 1.2879, 1.3173, 1.3173,
         1.2872, 1.3893, 1.2986, 1.4094, 1.3679, 1.4507, 1.2851, 1.3712, 1.2968,
         1.3656, 1.3936, 1.4067, 1.3763, 1.3409, 1.3318, 1.2920, 1.3292, 1.3292,
         1.3716, 1.4216, 1.3490, 1.1791, 1.3207, 1.2196, 1.3799, 1.2232, 1.3514,
         1.4634, 1.1879, 1.4847, 1.4710, 1.0810, 0.9918, 1.4695, 1.4431, 0.8861,
         2.8626, 2.4182, 2.9504, 2.6290, 2.0907, 1.8246, 2.7140, 2.7867, 1.8102]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 153 : 182.09598949994893
Test loss for epoch 153 : 182.12845487124088
Test Precision for epoch 153 : 0.26153846153846155
Test Recall for epoch 153 : 0.26153846153846155
Test F1 for epoch 153 : 0.26153846153846155


theta for epoch 154 : tensor([[2.3880, 2.4126, 2.4773, 2.5614, 2.5285, 2.3920, 2.5100, 2.3861, 2.3861,
         1.3001, 1.3103, 1.3130, 1.3281, 1.2864, 1.3702, 1.2979, 1.2896, 1.2643,
         1.2832, 1.2668, 1.2800, 1.2945, 1.2585, 1.2501, 1.2753, 1.2468, 1.2468,
         1.2897, 1.3402, 1.2667, 1.2921, 1.3354, 1.2784, 1.2981, 1.2296, 1.2692,
         1.3849, 1.4193, 1.4064, 1.3927, 1.3983, 1.3392, 1.3910, 1.3706, 1.3258,
         1.3664, 1.3176, 1.3079, 1.2903, 1.3603, 1.3107, 1.3969, 1.2849, 1.2935],
        [1.3232, 1.2235, 1.0388, 1.2597, 1.3388, 1.3735, 1.2941, 1.3664, 1.3664,
         1.6845, 1.9362, 1.6774, 2.4510, 1.7273, 4.5120, 1.7848, 1.6169, 4.2579,
         1.1611, 1.2326, 1.0175, 1.2080, 1.3452, 1.3804, 1.3557, 1.3781, 1.3781,
         1.3307, 1.0848, 1.3977, 1.3739, 1.1675, 1.4093, 1.4225, 1.3615, 1.3812,
         1.4282, 1.5448, 1.4796, 1.4090, 1.4018, 1.5104, 1.4650, 0.6128, 1.4475,
         1.0614, 1.4467, 1.4348, 1.4200, 1.0974, 1.4381, 0.8931, 1.4145, 1.4234],
        [1.2432, 1.2706, 1.3287, 1.3059, 1.2759, 1.2480, 1.2557, 1.2410, 1.2410,
         1.3062, 1.3168, 1.3192, 1.3339, 1.2925, 1.3204, 1.3041, 1.2830, 1.2282,
         2.4515, 2.5097, 2.6303, 2.5674, 2.3313, 2.4235, 2.4653, 2.3213, 2.3213,
         1.3298, 1.3036, 1.2734, 1.2986, 1.3303, 1.2849, 1.3050, 1.2809, 1.2758,
         1.3908, 1.4252, 1.4123, 1.3853, 1.4041, 1.3961, 1.3969, 1.2795, 1.3184,
         1.3268, 1.3240, 1.3142, 1.2965, 1.2781, 1.3174, 1.3565, 1.2910, 1.2997],
        [1.2554, 1.2830, 1.2755, 1.2524, 1.2883, 1.2604, 1.2685, 1.2532, 1.2532,
         1.3182, 1.2676, 1.3313, 1.3254, 1.3044, 1.2915, 1.3160, 1.3073, 1.1339,
         1.3018, 1.3074, 1.3428, 1.3132, 1.2767, 1.2504, 1.2932, 1.2650, 1.2650,
         2.8116, 2.4561, 2.1990, 2.3122, 2.8043, 2.2089, 2.7569, 2.2135, 2.2012,
         1.4012, 1.4358, 1.3989, 1.3883, 1.4146, 1.3968, 1.4048, 1.2200, 1.3407,
         1.3853, 1.3122, 1.2144, 1.2606, 1.3791, 1.2512, 1.4160, 1.2551, 1.3117],
        [1.7798, 1.4325, 0.6543, 0.8744, 1.2367, 1.6617, 1.5937, 1.7774, 1.7774,
         1.6663, 1.3908, 1.4843, 1.0047, 1.7718, 0.3112, 1.6511, 1.7908, 1.2751,
         1.3763, 0.9290, 0.8098, 1.1531, 1.6352, 1.7211, 1.3959, 1.7873, 1.7873,
         0.7726, 0.8862, 1.7609, 1.5310, 0.8664, 1.6939, 1.1850, 1.8110, 1.7380,
         0.5466, 0.3278, 0.2958, 0.5013, 0.7708, 0.9261, 0.4486, 9.1315, 7.0880,
         0.8344, 1.3144, 1.4083, 1.6542, 1.0872, 1.6242, 0.4766, 1.7026, 1.8275],
        [1.3192, 1.3467, 1.4046, 1.3826, 1.3530, 1.3241, 1.2876, 1.3171, 1.3171,
         1.2870, 1.3892, 1.2984, 1.4091, 1.3676, 1.4505, 1.2848, 1.3709, 1.2966,
         1.3653, 1.3933, 1.4064, 1.3760, 1.3406, 1.3315, 1.2915, 1.3289, 1.3289,
         1.3713, 1.4213, 1.3486, 1.1785, 1.3207, 1.2195, 1.3798, 1.2229, 1.3511,
         1.4632, 1.1874, 1.4846, 1.4709, 1.0805, 0.9913, 1.4694, 1.4429, 0.8855,
         2.8685, 2.4218, 2.9576, 2.6333, 2.0932, 1.8265, 2.7185, 2.7934, 1.8122]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 154 : 182.08867727161655
Test loss for epoch 154 : 182.1216400048698
Test Precision for epoch 154 : 0.26153846153846155
Test Recall for epoch 154 : 0.26153846153846155
Test F1 for epoch 154 : 0.26153846153846155


theta for epoch 155 : tensor([[2.3921, 2.4166, 2.4814, 2.5660, 2.5330, 2.3961, 2.5146, 2.3902, 2.3902,
         1.2997, 1.3100, 1.3127, 1.3278, 1.2860, 1.3699, 1.2976, 1.2893, 1.2640,
         1.2828, 1.2664, 1.2796, 1.2941, 1.2581, 1.2497, 1.2749, 1.2464, 1.2464,
         1.2894, 1.3398, 1.2664, 1.2917, 1.3351, 1.2780, 1.2978, 1.2292, 1.2688,
         1.3848, 1.4192, 1.4063, 1.3925, 1.3983, 1.3391, 1.3909, 1.3702, 1.3256,
         1.3661, 1.3173, 1.3075, 1.2900, 1.3600, 1.3104, 1.3965, 1.2845, 1.2932],
        [1.3231, 1.2234, 1.0388, 1.2595, 1.3388, 1.3733, 1.2939, 1.3662, 1.3662,
         1.6857, 1.9375, 1.6786, 2.4527, 1.7286, 4.5264, 1.7862, 1.6181, 4.2733,
         1.1609, 1.2325, 1.0176, 1.2079, 1.3451, 1.3803, 1.3555, 1.3780, 1.3780,
         1.3306, 1.0846, 1.3975, 1.3737, 1.1675, 1.4091, 1.4225, 1.3612, 1.3812,
         1.4285, 1.5449, 1.4796, 1.4090, 1.4020, 1.5106, 1.4650, 0.6128, 1.4475,
         1.0614, 1.4465, 1.4347, 1.4198, 1.0973, 1.4379, 0.8933, 1.4143, 1.4233],
        [1.2429, 1.2703, 1.3283, 1.3056, 1.2756, 1.2477, 1.2554, 1.2407, 1.2407,
         1.3059, 1.3165, 1.3189, 1.3336, 1.2922, 1.3201, 1.3037, 1.2827, 1.2281,
         2.4557, 2.5141, 2.6351, 2.5720, 2.3352, 2.4278, 2.4696, 2.3252, 2.3252,
         1.3295, 1.3033, 1.2730, 1.2982, 1.3300, 1.2846, 1.3047, 1.2806, 1.2755,
         1.3907, 1.4252, 1.4122, 1.3852, 1.4041, 1.3961, 1.3969, 1.2792, 1.3181,
         1.3266, 1.3237, 1.3139, 1.2962, 1.2780, 1.3171, 1.3563, 1.2906, 1.2994],
        [1.2550, 1.2826, 1.2760, 1.2529, 1.2879, 1.2599, 1.2680, 1.2527, 1.2527,
         1.3177, 1.2679, 1.3308, 1.3254, 1.3040, 1.2911, 1.3156, 1.3068, 1.1350,
         1.3013, 1.3075, 1.3424, 1.3127, 1.2763, 1.2503, 1.2927, 1.2645, 1.2645,
         2.8150, 2.4617, 2.2037, 2.3173, 2.8078, 2.2136, 2.7604, 2.2181, 2.2058,
         1.4010, 1.4357, 1.3991, 1.3885, 1.4145, 1.3969, 1.4047, 1.2212, 1.3404,
         1.3848, 1.3122, 1.2143, 1.2602, 1.3787, 1.2518, 1.4156, 1.2546, 1.3113],
        [1.7806, 1.4333, 0.6550, 0.8750, 1.2375, 1.6625, 1.5946, 1.7782, 1.7782,
         1.6671, 1.3908, 1.4851, 1.0053, 1.7726, 0.3123, 1.6519, 1.7916, 1.2745,
         1.3772, 0.9298, 0.8106, 1.1540, 1.6360, 1.7215, 1.3970, 1.7881, 1.7881,
         0.7730, 0.8871, 1.7617, 1.5321, 0.8666, 1.6945, 1.1851, 1.8119, 1.7386,
         0.5440, 0.3253, 0.2937, 0.4988, 0.7675, 0.9225, 0.4461, 9.1750, 7.1030,
         0.8355, 1.3150, 1.4090, 1.6549, 1.0881, 1.6241, 0.4775, 1.7036, 1.8283],
        [1.3190, 1.3464, 1.4043, 1.3823, 1.3527, 1.3239, 1.2873, 1.3168, 1.3168,
         1.2867, 1.3890, 1.2982, 1.4089, 1.3673, 1.4503, 1.2845, 1.3706, 1.2963,
         1.3651, 1.3930, 1.4062, 1.3758, 1.3403, 1.3313, 1.2910, 1.3286, 1.3286,
         1.3711, 1.4210, 1.3483, 1.1779, 1.3206, 1.2193, 1.3796, 1.2225, 1.3507,
         1.4632, 1.1870, 1.4845, 1.4709, 1.0800, 0.9908, 1.4693, 1.4427, 0.8850,
         2.8743, 2.4254, 2.9648, 2.6376, 2.0956, 1.8284, 2.7230, 2.8000, 1.8141]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 155 : 182.08145624287118
Test loss for epoch 155 : 182.11491796304202
Test Precision for epoch 155 : 0.26153846153846155
Test Recall for epoch 155 : 0.26153846153846155
Test F1 for epoch 155 : 0.26153846153846155


theta for epoch 156 : tensor([[2.3961, 2.4207, 2.4855, 2.5706, 2.5376, 2.4002, 2.5192, 2.3942, 2.3942,
         1.2994, 1.3097, 1.3123, 1.3275, 1.2857, 1.3696, 1.2972, 1.2889, 1.2636,
         1.2825, 1.2660, 1.2793, 1.2938, 1.2578, 1.2494, 1.2746, 1.2461, 1.2461,
         1.2891, 1.3394, 1.2660, 1.2913, 1.3348, 1.2776, 1.2976, 1.2288, 1.2684,
         1.3847, 1.4192, 1.4061, 1.3924, 1.3983, 1.3390, 1.3908, 1.3698, 1.3253,
         1.3657, 1.3169, 1.3071, 1.2897, 1.3596, 1.3101, 1.3961, 1.2841, 1.2928],
        [1.3228, 1.2232, 1.0387, 1.2594, 1.3389, 1.3731, 1.2937, 1.3660, 1.3660,
         1.6869, 1.9387, 1.6798, 2.4544, 1.7299, 4.5409, 1.7875, 1.6193, 4.2886,
         1.1608, 1.2324, 1.0178, 1.2078, 1.3449, 1.3801, 1.3553, 1.3778, 1.3778,
         1.3306, 1.0844, 1.3972, 1.3735, 1.1674, 1.4088, 1.4225, 1.3609, 1.3812,
         1.4288, 1.5450, 1.4795, 1.4090, 1.4022, 1.5107, 1.4650, 0.6128, 1.4474,
         1.0614, 1.4463, 1.4345, 1.4196, 1.0971, 1.4377, 0.8935, 1.4140, 1.4230],
        [1.2425, 1.2699, 1.3279, 1.3052, 1.2753, 1.2474, 1.2550, 1.2403, 1.2403,
         1.3056, 1.3162, 1.3186, 1.3333, 1.2919, 1.3199, 1.3034, 1.2823, 1.2279,
         2.4599, 2.5186, 2.6398, 2.5765, 2.3391, 2.4320, 2.4740, 2.3291, 2.3291,
         1.3292, 1.3030, 1.2727, 1.2978, 1.3297, 1.2842, 1.3045, 1.2802, 1.2751,
         1.3906, 1.4252, 1.4121, 1.3850, 1.4041, 1.3961, 1.3968, 1.2790, 1.3178,
         1.3262, 1.3233, 1.3135, 1.2959, 1.2778, 1.3168, 1.3560, 1.2903, 1.2991],
        [1.2545, 1.2821, 1.2764, 1.2533, 1.2874, 1.2594, 1.2675, 1.2523, 1.2523,
         1.3173, 1.2682, 1.3304, 1.3254, 1.3035, 1.2908, 1.3152, 1.3064, 1.1362,
         1.3009, 1.3076, 1.3420, 1.3123, 1.2759, 1.2502, 1.2923, 1.2641, 1.2641,
         2.8183, 2.4672, 2.2084, 2.3224, 2.8112, 2.2183, 2.7639, 2.2227, 2.2105,
         1.4008, 1.4355, 1.3993, 1.3887, 1.4144, 1.3970, 1.4046, 1.2224, 1.3400,
         1.3843, 1.3123, 1.2142, 1.2598, 1.3782, 1.2525, 1.4151, 1.2541, 1.3108],
        [1.7814, 1.4341, 0.6556, 0.8755, 1.2382, 1.6633, 1.5954, 1.7790, 1.7790,
         1.6679, 1.3908, 1.4858, 1.0058, 1.7733, 0.3133, 1.6527, 1.7925, 1.2740,
         1.3780, 0.9306, 0.8115, 1.1549, 1.6368, 1.7220, 1.3981, 1.7889, 1.7889,
         0.7733, 0.8881, 1.7624, 1.5332, 0.8668, 1.6952, 1.1851, 1.8127, 1.7392,
         0.5415, 0.3229, 0.2916, 0.4964, 0.7642, 0.9191, 0.4436, 9.2183, 7.1175,
         0.8365, 1.3155, 1.4098, 1.6556, 1.0889, 1.6240, 0.4785, 1.7047, 1.8290],
        [1.3187, 1.3461, 1.4040, 1.3820, 1.3524, 1.3236, 1.2870, 1.3165, 1.3165,
         1.2864, 1.3889, 1.2980, 1.4087, 1.3671, 1.4501, 1.2842, 1.3703, 1.2961,
         1.3648, 1.3928, 1.4059, 1.3755, 1.3401, 1.3310, 1.2905, 1.3284, 1.3284,
         1.3708, 1.4206, 1.3480, 1.1773, 1.3205, 1.2191, 1.3794, 1.2221, 1.3504,
         1.4631, 1.1866, 1.4844, 1.4708, 1.0796, 0.9904, 1.4693, 1.4426, 0.8844,
         2.8801, 2.4290, 2.9719, 2.6419, 2.0980, 1.8303, 2.7274, 2.8065, 1.8159]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 156 : 182.07432549473816
Test loss for epoch 156 : 182.10831263463444
Test Precision for epoch 156 : 0.26153846153846155
Test Recall for epoch 156 : 0.26153846153846155
Test F1 for epoch 156 : 0.26153846153846155


theta for epoch 157 : tensor([[2.4002, 2.4247, 2.4895, 2.5751, 2.5421, 2.4042, 2.5237, 2.3983, 2.3983,
         1.2991, 1.3094, 1.3120, 1.3272, 1.2853, 1.3693, 1.2969, 1.2886, 1.2633,
         1.2822, 1.2657, 1.2789, 1.2935, 1.2575, 1.2491, 1.2743, 1.2458, 1.2458,
         1.2888, 1.3390, 1.2656, 1.2909, 1.3346, 1.2773, 1.2973, 1.2284, 1.2681,
         1.3846, 1.4191, 1.4060, 1.3923, 1.3982, 1.3389, 1.3907, 1.3694, 1.3250,
         1.3653, 1.3165, 1.3067, 1.2893, 1.3592, 1.3098, 1.3957, 1.2837, 1.2925],
        [1.3226, 1.2231, 1.0386, 1.2592, 1.3389, 1.3729, 1.2935, 1.3658, 1.3658,
         1.6880, 1.9398, 1.6810, 2.4561, 1.7312, 4.5553, 1.7888, 1.6204, 4.3040,
         1.1607, 1.2323, 1.0179, 1.2076, 1.3447, 1.3800, 1.3551, 1.3776, 1.3776,
         1.3305, 1.0843, 1.3970, 1.3733, 1.1674, 1.4086, 1.4224, 1.3607, 1.3812,
         1.4290, 1.5451, 1.4795, 1.4090, 1.4024, 1.5108, 1.4650, 0.6129, 1.4473,
         1.0613, 1.4461, 1.4343, 1.4194, 1.0970, 1.4375, 0.8937, 1.4138, 1.4228],
        [1.2422, 1.2696, 1.3276, 1.3049, 1.2749, 1.2470, 1.2547, 1.2400, 1.2400,
         1.3053, 1.3160, 1.3183, 1.3331, 1.2916, 1.3196, 1.3031, 1.2819, 1.2278,
         2.4640, 2.5230, 2.6446, 2.5811, 2.3429, 2.4362, 2.4783, 2.3329, 2.3329,
         1.3289, 1.3028, 1.2723, 1.2975, 1.3294, 1.2839, 1.3043, 1.2799, 1.2748,
         1.3905, 1.4251, 1.4120, 1.3848, 1.4041, 1.3960, 1.3968, 1.2788, 1.3175,
         1.3260, 1.3230, 1.3132, 1.2956, 1.2776, 1.3165, 1.3557, 1.2899, 1.2988],
        [1.2540, 1.2816, 1.2769, 1.2538, 1.2870, 1.2589, 1.2671, 1.2518, 1.2518,
         1.3169, 1.2686, 1.3299, 1.3254, 1.3031, 1.2904, 1.3147, 1.3060, 1.1373,
         1.3005, 1.3076, 1.3416, 1.3119, 1.2754, 1.2501, 1.2919, 1.2637, 1.2637,
         2.8216, 2.4727, 2.2130, 2.3274, 2.8146, 2.2229, 2.7674, 2.2273, 2.2152,
         1.4006, 1.4354, 1.3995, 1.3889, 1.4143, 1.3971, 1.4044, 1.2236, 1.3397,
         1.3839, 1.3123, 1.2140, 1.2593, 1.3778, 1.2531, 1.4146, 1.2536, 1.3104],
        [1.7821, 1.4349, 0.6562, 0.8760, 1.2390, 1.6641, 1.5962, 1.7798, 1.7798,
         1.6686, 1.3909, 1.4866, 1.0064, 1.7741, 0.3144, 1.6535, 1.7934, 1.2735,
         1.3788, 0.9314, 0.8123, 1.1558, 1.6377, 1.7225, 1.3992, 1.7897, 1.7897,
         0.7737, 0.8890, 1.7632, 1.5342, 0.8671, 1.6959, 1.1851, 1.8135, 1.7398,
         0.5390, 0.3206, 0.2895, 0.4940, 0.7610, 0.9156, 0.4412, 9.2614, 7.1316,
         0.8376, 1.3161, 1.4106, 1.6564, 1.0898, 1.6239, 0.4794, 1.7057, 1.8298],
        [1.3183, 1.3458, 1.4037, 1.3817, 1.3521, 1.3233, 1.2867, 1.3162, 1.3162,
         1.2862, 1.3887, 1.2977, 1.4084, 1.3668, 1.4499, 1.2840, 1.3700, 1.2959,
         1.3645, 1.3925, 1.4056, 1.3753, 1.3398, 1.3308, 1.2900, 1.3281, 1.3281,
         1.3706, 1.4203, 1.3477, 1.1767, 1.3204, 1.2189, 1.3792, 1.2217, 1.3501,
         1.4630, 1.1861, 1.4843, 1.4707, 1.0791, 0.9899, 1.4692, 1.4424, 0.8839,
         2.8860, 2.4325, 2.9791, 2.6461, 2.1005, 1.8322, 2.7319, 2.8130, 1.8178]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 157 : 182.06728272367286
Test loss for epoch 157 : 182.10177802542614
Test Precision for epoch 157 : 0.26153846153846155
Test Recall for epoch 157 : 0.26153846153846155
Test F1 for epoch 157 : 0.26153846153846155


theta for epoch 158 : tensor([[2.4042, 2.4287, 2.4935, 2.5796, 2.5466, 2.4082, 2.5282, 2.4023, 2.4023,
         1.2987, 1.3091, 1.3117, 1.3269, 1.2850, 1.3690, 1.2966, 1.2883, 1.2630,
         1.2818, 1.2653, 1.2785, 1.2931, 1.2571, 1.2487, 1.2739, 1.2454, 1.2454,
         1.2886, 1.3387, 1.2653, 1.2906, 1.3343, 1.2769, 1.2972, 1.2281, 1.2677,
         1.3845, 1.4191, 1.4058, 1.3921, 1.3981, 1.3388, 1.3906, 1.3690, 1.3248,
         1.3649, 1.3162, 1.3064, 1.2890, 1.3589, 1.3095, 1.3954, 1.2834, 1.2921],
        [1.3225, 1.2230, 1.0386, 1.2591, 1.3390, 1.3727, 1.2934, 1.3656, 1.3656,
         1.6892, 1.9410, 1.6822, 2.4577, 1.7324, 4.5698, 1.7901, 1.6215, 4.3194,
         1.1605, 1.2321, 1.0181, 1.2075, 1.3446, 1.3798, 1.3549, 1.3774, 1.3774,
         1.3305, 1.0842, 1.3968, 1.3732, 1.1673, 1.4085, 1.4224, 1.3605, 1.3813,
         1.4293, 1.5451, 1.4794, 1.4089, 1.4026, 1.5110, 1.4649, 0.6129, 1.4472,
         1.0613, 1.4460, 1.4342, 1.4192, 1.0969, 1.4374, 0.8939, 1.4136, 1.4226],
        [1.2418, 1.2693, 1.3272, 1.3046, 1.2746, 1.2467, 1.2544, 1.2397, 1.2397,
         1.3050, 1.3157, 1.3180, 1.3328, 1.2913, 1.3194, 1.3028, 1.2816, 1.2277,
         2.4681, 2.5275, 2.6493, 2.5856, 2.3468, 2.4404, 2.4827, 2.3368, 2.3368,
         1.3286, 1.3025, 1.2720, 1.2972, 1.3291, 1.2836, 1.3041, 1.2796, 1.2745,
         1.3904, 1.4251, 1.4118, 1.3846, 1.4041, 1.3959, 1.3967, 1.2785, 1.3172,
         1.3257, 1.3227, 1.3128, 1.2953, 1.2774, 1.3162, 1.3554, 1.2896, 1.2985],
        [1.2536, 1.2812, 1.2774, 1.2544, 1.2865, 1.2585, 1.2666, 1.2513, 1.2513,
         1.3165, 1.2690, 1.3295, 1.3254, 1.3027, 1.2901, 1.3143, 1.3055, 1.1385,
         1.3000, 1.3077, 1.3411, 1.3114, 1.2750, 1.2500, 1.2914, 1.2632, 1.2632,
         2.8248, 2.4783, 2.2177, 2.3325, 2.8179, 2.2276, 2.7708, 2.2319, 2.2198,
         1.4004, 1.4352, 1.3997, 1.3890, 1.4141, 1.3972, 1.4043, 1.2247, 1.3393,
         1.3834, 1.3124, 1.2139, 1.2589, 1.3773, 1.2538, 1.4142, 1.2531, 1.3099],
        [1.7829, 1.4357, 0.6568, 0.8765, 1.2397, 1.6649, 1.5970, 1.7805, 1.7805,
         1.6694, 1.3909, 1.4874, 1.0069, 1.7748, 0.3154, 1.6542, 1.7942, 1.2729,
         1.3796, 0.9321, 0.8131, 1.1566, 1.6384, 1.7229, 1.4002, 1.7905, 1.7905,
         0.7740, 0.8900, 1.7640, 1.5353, 0.8673, 1.6965, 1.1851, 1.8144, 1.7404,
         0.5365, 0.3182, 0.2875, 0.4917, 0.7579, 0.9122, 0.4388, 9.3045, 7.1453,
         0.8386, 1.3167, 1.4114, 1.6571, 1.0906, 1.6237, 0.4804, 1.7067, 1.8306],
        [1.3181, 1.3455, 1.4034, 1.3814, 1.3518, 1.3230, 1.2864, 1.3159, 1.3159,
         1.2859, 1.3886, 1.2975, 1.4082, 1.3665, 1.4496, 1.2837, 1.3698, 1.2957,
         1.3643, 1.3922, 1.4054, 1.3750, 1.3395, 1.3305, 1.2895, 1.3278, 1.3278,
         1.3704, 1.4201, 1.3474, 1.1761, 1.3203, 1.2188, 1.3791, 1.2214, 1.3498,
         1.4629, 1.1857, 1.4841, 1.4706, 1.0786, 0.9894, 1.4691, 1.4422, 0.8833,
         2.8918, 2.4360, 2.9862, 2.6503, 2.1028, 1.8340, 2.7363, 2.8194, 1.8196]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 158 : 182.06032455401515
Test loss for epoch 158 : 182.09533976628543
Test Precision for epoch 158 : 0.26153846153846155
Test Recall for epoch 158 : 0.26153846153846155
Test F1 for epoch 158 : 0.26153846153846155


theta for epoch 159 : tensor([[2.4081, 2.4327, 2.4975, 2.5841, 2.5511, 2.4122, 2.5327, 2.4062, 2.4062,
         1.2984, 1.3088, 1.3114, 1.3266, 1.2847, 1.3687, 1.2963, 1.2879, 1.2627,
         1.2815, 1.2650, 1.2782, 1.2928, 1.2568, 1.2484, 1.2736, 1.2451, 1.2451,
         1.2883, 1.3383, 1.2650, 1.2903, 1.3341, 1.2766, 1.2969, 1.2278, 1.2674,
         1.3843, 1.4190, 1.4057, 1.3920, 1.3981, 1.3387, 1.3905, 1.3686, 1.3245,
         1.3646, 1.3159, 1.3060, 1.2887, 1.3585, 1.3092, 1.3950, 1.2830, 1.2918],
        [1.3223, 1.2229, 1.0386, 1.2590, 1.3391, 1.3725, 1.2932, 1.3655, 1.3655,
         1.6903, 1.9420, 1.6833, 2.4593, 1.7336, 4.5842, 1.7913, 1.6226, 4.3347,
         1.1604, 1.2320, 1.0183, 1.2074, 1.3444, 1.3796, 1.3547, 1.3773, 1.3773,
         1.3305, 1.0841, 1.3967, 1.3730, 1.1673, 1.4083, 1.4224, 1.3603, 1.3813,
         1.4296, 1.5452, 1.4793, 1.4089, 1.4028, 1.5111, 1.4649, 0.6129, 1.4471,
         1.0613, 1.4458, 1.4340, 1.4191, 1.0968, 1.4373, 0.8941, 1.4134, 1.4225],
        [1.2415, 1.2689, 1.3269, 1.3042, 1.2743, 1.2464, 1.2541, 1.2393, 1.2393,
         1.3047, 1.3154, 1.3177, 1.3326, 1.2910, 1.3191, 1.3025, 1.2812, 1.2275,
         2.4722, 2.5319, 2.6540, 2.5901, 2.3506, 2.4446, 2.4870, 2.3406, 2.3406,
         1.3283, 1.3023, 1.2717, 1.2969, 1.3288, 1.2833, 1.3039, 1.2793, 1.2741,
         1.3903, 1.4250, 1.4117, 1.3844, 1.4040, 1.3959, 1.3966, 1.2782, 1.3169,
         1.3254, 1.3224, 1.3125, 1.2950, 1.2772, 1.3159, 1.3552, 1.2893, 1.2982],
        [1.2531, 1.2808, 1.2779, 1.2549, 1.2861, 1.2580, 1.2662, 1.2509, 1.2509,
         1.3161, 1.2694, 1.3291, 1.3255, 1.3023, 1.2898, 1.3139, 1.3051, 1.1397,
         1.2996, 1.3077, 1.3407, 1.3110, 1.2746, 1.2499, 1.2910, 1.2628, 1.2628,
         2.8280, 2.4838, 2.2223, 2.3375, 2.8212, 2.2322, 2.7741, 2.2364, 2.2244,
         1.4002, 1.4351, 1.3999, 1.3892, 1.4140, 1.3973, 1.4041, 1.2259, 1.3390,
         1.3830, 1.3125, 1.2138, 1.2585, 1.3769, 1.2545, 1.4138, 1.2527, 1.3095],
        [1.7836, 1.4365, 0.6574, 0.8770, 1.2404, 1.6656, 1.5977, 1.7813, 1.7813,
         1.6701, 1.3908, 1.4882, 1.0074, 1.7756, 0.3164, 1.6549, 1.7950, 1.2723,
         1.3804, 0.9329, 0.8139, 1.1574, 1.6392, 1.7233, 1.4012, 1.7913, 1.7913,
         0.7743, 0.8908, 1.7648, 1.5364, 0.8675, 1.6972, 1.1851, 1.8152, 1.7409,
         0.5342, 0.3159, 0.2855, 0.4894, 0.7548, 0.9089, 0.4365, 9.3474, 7.1587,
         0.8396, 1.3172, 1.4122, 1.6579, 1.0914, 1.6236, 0.4813, 1.7077, 1.8313],
        [1.3178, 1.3453, 1.4031, 1.3812, 1.3516, 1.3228, 1.2861, 1.3157, 1.3157,
         1.2857, 1.3884, 1.2973, 1.4080, 1.3663, 1.4495, 1.2835, 1.3695, 1.2954,
         1.3640, 1.3919, 1.4052, 1.3748, 1.3393, 1.3302, 1.2890, 1.3276, 1.3276,
         1.3702, 1.4198, 1.3471, 1.1755, 1.3202, 1.2186, 1.3789, 1.2211, 1.3496,
         1.4628, 1.1852, 1.4840, 1.4705, 1.0782, 0.9889, 1.4691, 1.4421, 0.8828,
         2.8976, 2.4394, 2.9933, 2.6545, 2.1051, 1.8358, 2.7406, 2.8258, 1.8214]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 159 : 182.05344936074977
Test loss for epoch 159 : 182.0889995881196
Test Precision for epoch 159 : 0.26153846153846155
Test Recall for epoch 159 : 0.26153846153846155
Test F1 for epoch 159 : 0.26153846153846155


theta for epoch 160 : tensor([[2.4121, 2.4366, 2.5015, 2.5885, 2.5555, 2.4161, 2.5371, 2.4102, 2.4102,
         1.2981, 1.3086, 1.3111, 1.3264, 1.2844, 1.3684, 1.2960, 1.2876, 1.2625,
         1.2812, 1.2646, 1.2779, 1.2925, 1.2565, 1.2481, 1.2733, 1.2448, 1.2448,
         1.2880, 1.3380, 1.2646, 1.2899, 1.3338, 1.2762, 1.2967, 1.2274, 1.2671,
         1.3842, 1.4189, 1.4055, 1.3918, 1.3980, 1.3386, 1.3904, 1.3682, 1.3242,
         1.3642, 1.3156, 1.3057, 1.2884, 1.3582, 1.3089, 1.3947, 1.2827, 1.2915],
        [1.3222, 1.2228, 1.0385, 1.2589, 1.3392, 1.3724, 1.2931, 1.3653, 1.3653,
         1.6913, 1.9430, 1.6844, 2.4608, 1.7348, 4.5987, 1.7925, 1.6237, 4.3501,
         1.1603, 1.2319, 1.0185, 1.2073, 1.3443, 1.3795, 1.3546, 1.3771, 1.3771,
         1.3304, 1.0840, 1.3965, 1.3729, 1.1672, 1.4081, 1.4224, 1.3600, 1.3813,
         1.4298, 1.5452, 1.4792, 1.4089, 1.4030, 1.5112, 1.4649, 0.6130, 1.4470,
         1.0613, 1.4457, 1.4339, 1.4189, 1.0967, 1.4371, 0.8944, 1.4132, 1.4223],
        [1.2412, 1.2686, 1.3265, 1.3039, 1.2740, 1.2461, 1.2538, 1.2390, 1.2390,
         1.3045, 1.3152, 1.3174, 1.3324, 1.2907, 1.3189, 1.3023, 1.2809, 1.2274,
         2.4762, 2.5362, 2.6587, 2.5946, 2.3544, 2.4487, 2.4912, 2.3444, 2.3444,
         1.3280, 1.3020, 1.2714, 1.2965, 1.3284, 1.2830, 1.3037, 1.2789, 1.2738,
         1.3902, 1.4250, 1.4116, 1.3842, 1.4040, 1.3958, 1.3965, 1.2780, 1.3167,
         1.3251, 1.3221, 1.3122, 1.2948, 1.2770, 1.3156, 1.3550, 1.2890, 1.2979],
        [1.2527, 1.2803, 1.2784, 1.2554, 1.2857, 1.2576, 1.2657, 1.2505, 1.2505,
         1.3157, 1.2698, 1.3287, 1.3255, 1.3019, 1.2894, 1.3135, 1.3047, 1.1409,
         1.2992, 1.3078, 1.3403, 1.3106, 1.2742, 1.2499, 1.2906, 1.2624, 1.2624,
         2.8311, 2.4893, 2.2269, 2.3425, 2.8244, 2.2368, 2.7774, 2.2409, 2.2290,
         1.3999, 1.4349, 1.4001, 1.3893, 1.4138, 1.3974, 1.4040, 1.2272, 1.3386,
         1.3826, 1.3125, 1.2137, 1.2581, 1.3765, 1.2553, 1.4134, 1.2522, 1.3091],
        [1.7844, 1.4373, 0.6579, 0.8774, 1.2411, 1.6664, 1.5985, 1.7820, 1.7820,
         1.6708, 1.3908, 1.4889, 1.0078, 1.7763, 0.3173, 1.6557, 1.7958, 1.2717,
         1.3812, 0.9336, 0.8147, 1.1582, 1.6400, 1.7237, 1.4023, 1.7920, 1.7920,
         0.7746, 0.8917, 1.7655, 1.5374, 0.8677, 1.6978, 1.1850, 1.8160, 1.7415,
         0.5318, 0.3136, 0.2835, 0.4872, 0.7517, 0.9055, 0.4342, 9.3902, 7.1716,
         0.8405, 1.3177, 1.4129, 1.6586, 1.0922, 1.6234, 0.4821, 1.7087, 1.8320],
        [1.3176, 1.3450, 1.4029, 1.3809, 1.3513, 1.3225, 1.2859, 1.3154, 1.3154,
         1.2854, 1.3883, 1.2971, 1.4078, 1.3660, 1.4493, 1.2832, 1.3692, 1.2952,
         1.3638, 1.3917, 1.4049, 1.3745, 1.3390, 1.3300, 1.2885, 1.3273, 1.3273,
         1.3700, 1.4195, 1.3468, 1.1749, 1.3201, 1.2184, 1.3788, 1.2207, 1.3493,
         1.4627, 1.1847, 1.4839, 1.4704, 1.0777, 0.9884, 1.4690, 1.4419, 0.8822,
         2.9034, 2.4428, 3.0003, 2.6587, 2.1074, 1.8376, 2.7450, 2.8322, 1.8232]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 160 : 182.0466550657863
Test loss for epoch 160 : 182.08272935837888
Test Precision for epoch 160 : 0.26153846153846155
Test Recall for epoch 160 : 0.26153846153846155
Test F1 for epoch 160 : 0.26153846153846155


theta for epoch 161 : tensor([[2.4160, 2.4405, 2.5054, 2.5929, 2.5599, 2.4201, 2.5415, 2.4141, 2.4141,
         1.2978, 1.3083, 1.3108, 1.3261, 1.2841, 1.3682, 1.2956, 1.2873, 1.2622,
         1.2809, 1.2643, 1.2775, 1.2922, 1.2561, 1.2478, 1.2729, 1.2444, 1.2444,
         1.2878, 1.3376, 1.2643, 1.2895, 1.3335, 1.2759, 1.2965, 1.2270, 1.2667,
         1.3840, 1.4188, 1.4054, 1.3917, 1.3980, 1.3385, 1.3902, 1.3678, 1.3240,
         1.3639, 1.3152, 1.3053, 1.2881, 1.3579, 1.3086, 1.3943, 1.2823, 1.2912],
        [1.3220, 1.2227, 1.0385, 1.2588, 1.3393, 1.3722, 1.2929, 1.3651, 1.3651,
         1.6924, 1.9440, 1.6855, 2.4624, 1.7359, 4.6131, 1.7937, 1.6247, 4.3654,
         1.1602, 1.2318, 1.0187, 1.2072, 1.3442, 1.3794, 1.3544, 1.3770, 1.3770,
         1.3304, 1.0839, 1.3963, 1.3727, 1.1672, 1.4079, 1.4224, 1.3598, 1.3814,
         1.4301, 1.5453, 1.4792, 1.4089, 1.4033, 1.5114, 1.4648, 0.6131, 1.4469,
         1.0613, 1.4455, 1.4337, 1.4187, 1.0966, 1.4370, 0.8946, 1.4130, 1.4221],
        [1.2409, 1.2683, 1.3262, 1.3036, 1.2737, 1.2458, 1.2535, 1.2387, 1.2387,
         1.3042, 1.3150, 1.3172, 1.3321, 1.2904, 1.3187, 1.3020, 1.2805, 1.2273,
         2.4802, 2.5406, 2.6633, 2.5990, 2.3582, 2.4528, 2.4955, 2.3481, 2.3481,
         1.3277, 1.3018, 1.2711, 1.2962, 1.3281, 1.2826, 1.3035, 1.2786, 1.2735,
         1.3901, 1.4250, 1.4115, 1.3841, 1.4040, 1.3958, 1.3964, 1.2778, 1.3164,
         1.3249, 1.3218, 1.3118, 1.2945, 1.2769, 1.3154, 1.3547, 1.2886, 1.2976],
        [1.2522, 1.2799, 1.2790, 1.2560, 1.2853, 1.2571, 1.2653, 1.2500, 1.2500,
         1.3153, 1.2703, 1.3283, 1.3255, 1.3015, 1.2891, 1.3131, 1.3043, 1.1421,
         1.2988, 1.3078, 1.3399, 1.3102, 1.2738, 1.2498, 1.2902, 1.2620, 1.2620,
         2.8342, 2.4948, 2.2315, 2.3475, 2.8276, 2.2414, 2.7807, 2.2454, 2.2336,
         1.3997, 1.4347, 1.4003, 1.3895, 1.4137, 1.3974, 1.4038, 1.2284, 1.3383,
         1.3821, 1.3126, 1.2136, 1.2576, 1.3761, 1.2560, 1.4129, 1.2517, 1.3086],
        [1.7851, 1.4380, 0.6584, 0.8779, 1.2418, 1.6671, 1.5993, 1.7827, 1.7827,
         1.6715, 1.3908, 1.4897, 1.0083, 1.7770, 0.3183, 1.6564, 1.7967, 1.2711,
         1.3819, 0.9344, 0.8155, 1.1590, 1.6408, 1.7242, 1.4033, 1.7928, 1.7928,
         0.7749, 0.8926, 1.7662, 1.5384, 0.8678, 1.6985, 1.1850, 1.8168, 1.7420,
         0.5295, 0.3113, 0.2816, 0.4849, 0.7487, 0.9022, 0.4319, 9.4329, 7.1840,
         0.8415, 1.3182, 1.4137, 1.6593, 1.0929, 1.6232, 0.4830, 1.7097, 1.8328],
        [1.3173, 1.3447, 1.4026, 1.3807, 1.3510, 1.3222, 1.2856, 1.3151, 1.3151,
         1.2852, 1.3881, 1.2969, 1.4076, 1.3658, 1.4491, 1.2830, 1.3690, 1.2950,
         1.3635, 1.3914, 1.4047, 1.3743, 1.3388, 1.3298, 1.2880, 1.3271, 1.3271,
         1.3697, 1.4192, 1.3465, 1.1744, 1.3200, 1.2182, 1.3786, 1.2204, 1.3490,
         1.4626, 1.1843, 1.4838, 1.4703, 1.0772, 0.9880, 1.4689, 1.4417, 0.8817,
         2.9092, 2.4461, 3.0074, 2.6629, 2.1096, 1.8393, 2.7493, 2.8385, 1.8249]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 161 : 182.03993959683987
Test loss for epoch 161 : 182.07654124154143
Test Precision for epoch 161 : 0.26153846153846155
Test Recall for epoch 161 : 0.26153846153846155
Test F1 for epoch 161 : 0.26153846153846155


theta for epoch 162 : tensor([[2.4199, 2.4444, 2.5093, 2.5973, 2.5643, 2.4240, 2.5459, 2.4180, 2.4180,
         1.2975, 1.3080, 1.3105, 1.3258, 1.2838, 1.3678, 1.2953, 1.2870, 1.2619,
         1.2805, 1.2639, 1.2772, 1.2918, 1.2558, 1.2475, 1.2726, 1.2441, 1.2441,
         1.2875, 1.3373, 1.2639, 1.2892, 1.3333, 1.2756, 1.2963, 1.2267, 1.2664,
         1.3839, 1.4188, 1.4052, 1.3916, 1.3979, 1.3384, 1.3901, 1.3674, 1.3237,
         1.3635, 1.3149, 1.3049, 1.2877, 1.3575, 1.3082, 1.3940, 1.2820, 1.2909],
        [1.3218, 1.2226, 1.0385, 1.2587, 1.3393, 1.3720, 1.2927, 1.3649, 1.3649,
         1.6934, 1.9450, 1.6865, 2.4639, 1.7370, 4.6276, 1.7949, 1.6257, 4.3807,
         1.1600, 1.2317, 1.0189, 1.2071, 1.3440, 1.3792, 1.3542, 1.3768, 1.3768,
         1.3304, 1.0838, 1.3961, 1.3726, 1.1672, 1.4077, 1.4224, 1.3596, 1.3814,
         1.4304, 1.5454, 1.4791, 1.4090, 1.4035, 1.5115, 1.4648, 0.6132, 1.4468,
         1.0613, 1.4453, 1.4335, 1.4185, 1.0965, 1.4368, 0.8949, 1.4127, 1.4220],
        [1.2406, 1.2680, 1.3258, 1.3033, 1.2734, 1.2455, 1.2532, 1.2384, 1.2384,
         1.3039, 1.3147, 1.3169, 1.3319, 1.2901, 1.3185, 1.3017, 1.2802, 1.2272,
         2.4842, 2.5449, 2.6679, 2.6034, 2.3619, 2.4569, 2.4997, 2.3519, 2.3519,
         1.3274, 1.3016, 1.2708, 1.2959, 1.3278, 1.2823, 1.3033, 1.2783, 1.2732,
         1.3900, 1.4249, 1.4114, 1.3839, 1.4040, 1.3958, 1.3963, 1.2775, 1.3161,
         1.3246, 1.3215, 1.3115, 1.2942, 1.2767, 1.3151, 1.3545, 1.2883, 1.2973],
        [1.2517, 1.2794, 1.2795, 1.2565, 1.2848, 1.2567, 1.2648, 1.2495, 1.2495,
         1.3149, 1.2707, 1.3279, 1.3256, 1.3010, 1.2888, 1.3127, 1.3038, 1.1433,
         1.2984, 1.3079, 1.3395, 1.3098, 1.2733, 1.2497, 1.2898, 1.2616, 1.2616,
         2.8373, 2.5003, 2.2361, 2.3525, 2.8308, 2.2460, 2.7839, 2.2500, 2.2382,
         1.3995, 1.4346, 1.4005, 1.3897, 1.4136, 1.3975, 1.4037, 1.2296, 1.3379,
         1.3817, 1.3126, 1.2135, 1.2572, 1.3756, 1.2567, 1.4125, 1.2513, 1.3082],
        [1.7858, 1.4388, 0.6589, 0.8783, 1.2425, 1.6679, 1.6000, 1.7834, 1.7834,
         1.6723, 1.3907, 1.4904, 1.0088, 1.7777, 0.3193, 1.6571, 1.7975, 1.2705,
         1.3827, 0.9351, 0.8163, 1.1599, 1.6415, 1.7246, 1.4044, 1.7935, 1.7935,
         0.7751, 0.8934, 1.7670, 1.5395, 0.8680, 1.6992, 1.1849, 1.8176, 1.7426,
         0.5272, 0.3091, 0.2796, 0.4827, 0.7457, 0.8989, 0.4297, 9.4754, 7.1961,
         0.8425, 1.3187, 1.4144, 1.6600, 1.0937, 1.6230, 0.4839, 1.7107, 1.8335],
        [1.3170, 1.3444, 1.4024, 1.3804, 1.3507, 1.3219, 1.2853, 1.3148, 1.3148,
         1.2849, 1.3880, 1.2967, 1.4074, 1.3655, 1.4489, 1.2827, 1.3687, 1.2948,
         1.3633, 1.3912, 1.4045, 1.3741, 1.3385, 1.3295, 1.2874, 1.3268, 1.3268,
         1.3695, 1.4189, 1.3462, 1.1738, 1.3199, 1.2180, 1.3784, 1.2201, 1.3487,
         1.4626, 1.1838, 1.4837, 1.4702, 1.0768, 0.9875, 1.4689, 1.4416, 0.8811,
         2.9150, 2.4494, 3.0144, 2.6670, 2.1118, 1.8410, 2.7536, 2.8447, 1.8266]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 162 : 182.0333014140318
Test loss for epoch 162 : 182.07043433469568
Test Precision for epoch 162 : 0.26153846153846155
Test Recall for epoch 162 : 0.26153846153846155
Test F1 for epoch 162 : 0.26153846153846155


theta for epoch 163 : tensor([[2.4237, 2.4483, 2.5132, 2.6017, 2.5687, 2.4278, 2.5503, 2.4219, 2.4219,
         1.2972, 1.3077, 1.3102, 1.3255, 1.2835, 1.3675, 1.2950, 1.2867, 1.2616,
         1.2802, 1.2636, 1.2769, 1.2915, 1.2555, 1.2471, 1.2723, 1.2438, 1.2438,
         1.2872, 1.3369, 1.2636, 1.2888, 1.3330, 1.2752, 1.2960, 1.2263, 1.2661,
         1.3838, 1.4188, 1.4051, 1.3915, 1.3979, 1.3383, 1.3901, 1.3671, 1.3235,
         1.3632, 1.3146, 1.3046, 1.2874, 1.3572, 1.3079, 1.3937, 1.2816, 1.2906],
        [1.3216, 1.2225, 1.0385, 1.2586, 1.3394, 1.3719, 1.2926, 1.3648, 1.3648,
         1.6944, 1.9459, 1.6875, 2.4654, 1.7381, 4.6420, 1.7960, 1.6267, 4.3960,
         1.1599, 1.2316, 1.0190, 1.2069, 1.3439, 1.3791, 1.3540, 1.3766, 1.3766,
         1.3303, 1.0837, 1.3959, 1.3724, 1.1671, 1.4075, 1.4224, 1.3594, 1.3814,
         1.4307, 1.5455, 1.4791, 1.4090, 1.4038, 1.5117, 1.4648, 0.6133, 1.4468,
         1.0614, 1.4452, 1.4334, 1.4184, 1.0964, 1.4367, 0.8951, 1.4125, 1.4218],
        [1.2403, 1.2677, 1.3255, 1.3029, 1.2731, 1.2452, 1.2529, 1.2381, 1.2381,
         1.3036, 1.3144, 1.3166, 1.3316, 1.2899, 1.3182, 1.3014, 1.2798, 1.2271,
         2.4882, 2.5492, 2.6725, 2.6078, 2.3656, 2.4609, 2.5039, 2.3556, 2.3556,
         1.3271, 1.3013, 1.2704, 1.2956, 1.3275, 1.2820, 1.3031, 1.2780, 1.2729,
         1.3900, 1.4249, 1.4113, 1.3837, 1.4040, 1.3958, 1.3963, 1.2773, 1.3158,
         1.3243, 1.3212, 1.3112, 1.2939, 1.2765, 1.3148, 1.3542, 1.2880, 1.2970],
        [1.2513, 1.2790, 1.2800, 1.2571, 1.2844, 1.2562, 1.2644, 1.2491, 1.2491,
         1.3145, 1.2712, 1.3275, 1.3256, 1.3006, 1.2884, 1.3123, 1.3034, 1.1446,
         1.2980, 1.3079, 1.3390, 1.3094, 1.2729, 1.2496, 1.2894, 1.2611, 1.2611,
         2.8402, 2.5057, 2.2406, 2.3575, 2.8339, 2.2505, 2.7871, 2.2544, 2.2427,
         1.3993, 1.4345, 1.4008, 1.3898, 1.4134, 1.3976, 1.4035, 1.2309, 1.3376,
         1.3812, 1.3126, 1.2133, 1.2568, 1.3752, 1.2575, 1.4121, 1.2508, 1.3078],
        [1.7865, 1.4396, 0.6594, 0.8787, 1.2432, 1.6686, 1.6008, 1.7841, 1.7841,
         1.6730, 1.3906, 1.4912, 1.0093, 1.7784, 0.3202, 1.6578, 1.7983, 1.2698,
         1.3835, 0.9358, 0.8170, 1.1607, 1.6423, 1.7250, 1.4054, 1.7942, 1.7942,
         0.7754, 0.8942, 1.7677, 1.5405, 0.8681, 1.6998, 1.1848, 1.8183, 1.7431,
         0.5249, 0.3069, 0.2777, 0.4805, 0.7427, 0.8957, 0.4275, 9.5178, 7.2078,
         0.8434, 1.3192, 1.4152, 1.6607, 1.0945, 1.6228, 0.4847, 1.7117, 1.8342],
        [1.3167, 1.3442, 1.4021, 1.3802, 1.3505, 1.3217, 1.2850, 1.3145, 1.3145,
         1.2847, 1.3878, 1.2965, 1.4072, 1.3653, 1.4487, 1.2825, 1.3685, 1.2946,
         1.3631, 1.3909, 1.4042, 1.3738, 1.3383, 1.3293, 1.2869, 1.3265, 1.3265,
         1.3693, 1.4186, 1.3460, 1.1732, 1.3197, 1.2178, 1.3783, 1.2198, 1.3484,
         1.4625, 1.1834, 1.4836, 1.4702, 1.0763, 0.9870, 1.4688, 1.4414, 0.8806,
         2.9208, 2.4527, 3.0215, 2.6711, 2.1140, 1.8428, 2.7579, 2.8510, 1.8283]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 163 : 182.02673660149043
Test loss for epoch 163 : 182.06441436479537
Test Precision for epoch 163 : 0.26153846153846155
Test Recall for epoch 163 : 0.26153846153846155
Test F1 for epoch 163 : 0.26153846153846155


theta for epoch 164 : tensor([[2.4276, 2.4521, 2.5170, 2.6060, 2.5730, 2.4317, 2.5546, 2.4257, 2.4257,
         1.2969, 1.3074, 1.3099, 1.3252, 1.2832, 1.3673, 1.2947, 1.2864, 1.2613,
         1.2799, 1.2633, 1.2766, 1.2912, 1.2552, 1.2468, 1.2719, 1.2435, 1.2435,
         1.2870, 1.3365, 1.2633, 1.2885, 1.3327, 1.2749, 1.2958, 1.2260, 1.2657,
         1.3837, 1.4187, 1.4050, 1.3913, 1.3978, 1.3383, 1.3899, 1.3667, 1.3233,
         1.3628, 1.3143, 1.3043, 1.2871, 1.3569, 1.3077, 1.3934, 1.2813, 1.2903],
        [1.3215, 1.2224, 1.0385, 1.2584, 1.3395, 1.3717, 1.2924, 1.3646, 1.3646,
         1.6954, 1.9468, 1.6885, 2.4668, 1.7391, 4.6565, 1.7971, 1.6276, 4.4113,
         1.1597, 1.2315, 1.0192, 1.2068, 1.3437, 1.3789, 1.3538, 1.3765, 1.3765,
         1.3303, 1.0836, 1.3957, 1.3723, 1.1671, 1.4074, 1.4224, 1.3592, 1.3815,
         1.4310, 1.5456, 1.4790, 1.4090, 1.4040, 1.5118, 1.4648, 0.6134, 1.4467,
         1.0614, 1.4451, 1.4332, 1.4182, 1.0964, 1.4366, 0.8954, 1.4123, 1.4216],
        [1.2399, 1.2673, 1.3252, 1.3026, 1.2727, 1.2449, 1.2526, 1.2378, 1.2378,
         1.3033, 1.3142, 1.3163, 1.3314, 1.2896, 1.3180, 1.3011, 1.2795, 1.2270,
         2.4921, 2.5535, 2.6771, 2.6121, 2.3693, 2.4650, 2.5081, 2.3593, 2.3593,
         1.3268, 1.3011, 1.2701, 1.2953, 1.3272, 1.2817, 1.3029, 1.2777, 1.2726,
         1.3899, 1.4249, 1.4111, 1.3835, 1.4040, 1.3957, 1.3962, 1.2771, 1.3155,
         1.3240, 1.3209, 1.3108, 1.2936, 1.2764, 1.3145, 1.3540, 1.2876, 1.2967],
        [1.2509, 1.2785, 1.2806, 1.2577, 1.2840, 1.2558, 1.2640, 1.2487, 1.2487,
         1.3141, 1.2717, 1.3271, 1.3256, 1.3002, 1.2881, 1.3119, 1.3030, 1.1458,
         1.2976, 1.3079, 1.3386, 1.3090, 1.2725, 1.2496, 1.2890, 1.2607, 1.2607,
         2.8432, 2.5112, 2.2451, 2.3624, 2.8369, 2.2550, 2.7902, 2.2589, 2.2473,
         1.3991, 1.4343, 1.4010, 1.3900, 1.4133, 1.3977, 1.4034, 1.2322, 1.3373,
         1.3808, 1.3127, 1.2132, 1.2564, 1.3748, 1.2582, 1.4117, 1.2504, 1.3074],
        [1.7872, 1.4403, 0.6599, 0.8791, 1.2439, 1.6693, 1.6015, 1.7848, 1.7848,
         1.6737, 1.3905, 1.4919, 1.0097, 1.7791, 0.3211, 1.6585, 1.7990, 1.2692,
         1.3842, 0.9365, 0.8178, 1.1614, 1.6430, 1.7253, 1.4064, 1.7949, 1.7949,
         0.7756, 0.8950, 1.7684, 1.5415, 0.8683, 1.7005, 1.1847, 1.8191, 1.7436,
         0.5227, 0.3047, 0.2759, 0.4784, 0.7398, 0.8925, 0.4253, 9.5601, 7.2191,
         0.8443, 1.3197, 1.4159, 1.6614, 1.0952, 1.6225, 0.4855, 1.7127, 1.8348],
        [1.3165, 1.3439, 1.4019, 1.3799, 1.3502, 1.3214, 1.2848, 1.3143, 1.3143,
         1.2844, 1.3877, 1.2963, 1.4070, 1.3650, 1.4485, 1.2822, 1.3682, 1.2944,
         1.3628, 1.3907, 1.4040, 1.3736, 1.3380, 1.3290, 1.2864, 1.3263, 1.3263,
         1.3691, 1.4184, 1.3457, 1.1726, 1.3196, 1.2176, 1.3781, 1.2194, 1.3482,
         1.4624, 1.1830, 1.4835, 1.4701, 1.0759, 0.9866, 1.4688, 1.4412, 0.8800,
         2.9266, 2.4559, 3.0284, 2.6752, 2.1162, 1.8444, 2.7621, 2.8571, 1.8300]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 164 : 182.02024460658234
Test loss for epoch 164 : 182.05848349548717
Test Precision for epoch 164 : 0.26153846153846155
Test Recall for epoch 164 : 0.26153846153846155
Test F1 for epoch 164 : 0.26153846153846155


theta for epoch 165 : tensor([[2.4314, 2.4559, 2.5209, 2.6103, 2.5773, 2.4355, 2.5590, 2.4295, 2.4295,
         1.2966, 1.3072, 1.3096, 1.3249, 1.2829, 1.3670, 1.2944, 1.2860, 1.2610,
         1.2796, 1.2629, 1.2763, 1.2909, 1.2548, 1.2465, 1.2716, 1.2431, 1.2431,
         1.2867, 1.3362, 1.2630, 1.2882, 1.3325, 1.2746, 1.2956, 1.2257, 1.2654,
         1.3835, 1.4187, 1.4048, 1.3912, 1.3978, 1.3382, 1.3898, 1.3663, 1.3230,
         1.3625, 1.3140, 1.3039, 1.2868, 1.3566, 1.3074, 1.3931, 1.2809, 1.2900],
        [1.3213, 1.2223, 1.0385, 1.2584, 1.3396, 1.3716, 1.2923, 1.3645, 1.3645,
         1.6964, 1.9476, 1.6894, 2.4682, 1.7401, 4.6709, 1.7982, 1.6285, 4.4265,
         1.1596, 1.2314, 1.0194, 1.2067, 1.3436, 1.3788, 1.3536, 1.3763, 1.3763,
         1.3303, 1.0835, 1.3956, 1.3721, 1.1671, 1.4072, 1.4224, 1.3590, 1.3815,
         1.4313, 1.5456, 1.4790, 1.4090, 1.4043, 1.5120, 1.4647, 0.6135, 1.4466,
         1.0614, 1.4449, 1.4331, 1.4180, 1.0963, 1.4365, 0.8957, 1.4121, 1.4215],
        [1.2396, 1.2670, 1.3249, 1.3023, 1.2724, 1.2446, 1.2523, 1.2375, 1.2375,
         1.3031, 1.3140, 1.3161, 1.3311, 1.2893, 1.3178, 1.3009, 1.2791, 1.2269,
         2.4960, 2.5578, 2.6817, 2.6164, 2.3730, 2.4689, 2.5123, 2.3629, 2.3629,
         1.3265, 1.3009, 1.2698, 1.2950, 1.3269, 1.2814, 1.3027, 1.2774, 1.2723,
         1.3897, 1.4249, 1.4110, 1.3833, 1.4039, 1.3957, 1.3961, 1.2768, 1.3152,
         1.3238, 1.3206, 1.3105, 1.2933, 1.2762, 1.3142, 1.3538, 1.2873, 1.2965],
        [1.2504, 1.2781, 1.2812, 1.2582, 1.2836, 1.2554, 1.2636, 1.2482, 1.2482,
         1.3137, 1.2722, 1.3267, 1.3256, 1.2998, 1.2878, 1.3115, 1.3026, 1.1470,
         1.2972, 1.3079, 1.3382, 1.3086, 1.2721, 1.2495, 1.2886, 1.2603, 1.2603,
         2.8461, 2.5166, 2.2497, 2.3674, 2.8399, 2.2596, 2.7932, 2.2634, 2.2518,
         1.3988, 1.4342, 1.4011, 1.3901, 1.4132, 1.3978, 1.4032, 1.2334, 1.3369,
         1.3804, 1.3127, 1.2131, 1.2560, 1.3744, 1.2590, 1.4112, 1.2499, 1.3070],
        [1.7879, 1.4410, 0.6603, 0.8795, 1.2445, 1.6700, 1.6022, 1.7855, 1.7855,
         1.6743, 1.3904, 1.4926, 1.0101, 1.7797, 0.3220, 1.6591, 1.7998, 1.2685,
         1.3849, 0.9372, 0.8185, 1.1622, 1.6437, 1.7257, 1.4074, 1.7956, 1.7956,
         0.7758, 0.8958, 1.7691, 1.5424, 0.8684, 1.7011, 1.1846, 1.8198, 1.7441,
         0.5205, 0.3025, 0.2740, 0.4763, 0.7370, 0.8894, 0.4231, 9.6023, 7.2299,
         0.8452, 1.3202, 1.4166, 1.6621, 1.0959, 1.6223, 0.4863, 1.7136, 1.8355],
        [1.3162, 1.3437, 1.4017, 1.3797, 1.3500, 1.3211, 1.2845, 1.3140, 1.3140,
         1.2842, 1.3875, 1.2961, 1.4068, 1.3648, 1.4483, 1.2820, 1.3680, 1.2942,
         1.3626, 1.3905, 1.4038, 1.3734, 1.3378, 1.3288, 1.2859, 1.3260, 1.3260,
         1.3689, 1.4181, 1.3454, 1.1720, 1.3195, 1.2175, 1.3780, 1.2192, 1.3479,
         1.4623, 1.1825, 1.4834, 1.4700, 1.0754, 0.9861, 1.4687, 1.4410, 0.8795,
         2.9323, 2.4591, 3.0354, 2.6792, 2.1183, 1.8461, 2.7664, 2.8633, 1.8317]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 165 : 182.01382282341328
Test loss for epoch 165 : 182.05260464804215
Test Precision for epoch 165 : 0.26153846153846155
Test Recall for epoch 165 : 0.26153846153846155
Test F1 for epoch 165 : 0.26153846153846155


theta for epoch 166 : tensor([[2.4352, 2.4597, 2.5247, 2.6146, 2.5816, 2.4393, 2.5633, 2.4333, 2.4333,
         1.2963, 1.3069, 1.3093, 1.3246, 1.2826, 1.3667, 1.2941, 1.2857, 1.2607,
         1.2793, 1.2626, 1.2760, 1.2906, 1.2545, 1.2462, 1.2713, 1.2428, 1.2428,
         1.2865, 1.3359, 1.2627, 1.2878, 1.3323, 1.2742, 1.2954, 1.2253, 1.2651,
         1.3833, 1.4186, 1.4047, 1.3910, 1.3977, 1.3381, 1.3897, 1.3659, 1.3228,
         1.3622, 1.3137, 1.3036, 1.2865, 1.3563, 1.3071, 1.3928, 1.2806, 1.2896],
        [1.3212, 1.2222, 1.0385, 1.2583, 1.3397, 1.3714, 1.2921, 1.3643, 1.3643,
         1.6973, 1.9483, 1.6904, 2.4696, 1.7411, 4.6853, 1.7992, 1.6294, 4.4417,
         1.1595, 1.2313, 1.0197, 1.2066, 1.3435, 1.3787, 1.3535, 1.3762, 1.3762,
         1.3303, 1.0835, 1.3954, 1.3720, 1.1671, 1.4071, 1.4225, 1.3588, 1.3816,
         1.4316, 1.5457, 1.4789, 1.4091, 1.4045, 1.5121, 1.4647, 0.6136, 1.4466,
         1.0614, 1.4448, 1.4329, 1.4179, 1.0963, 1.4363, 0.8960, 1.4119, 1.4214],
        [1.2393, 1.2667, 1.3246, 1.3020, 1.2721, 1.2443, 1.2520, 1.2372, 1.2372,
         1.3028, 1.3137, 1.3158, 1.3309, 1.2891, 1.3176, 1.3006, 1.2788, 1.2268,
         2.4998, 2.5620, 2.6862, 2.6207, 2.3766, 2.4729, 2.5164, 2.3666, 2.3666,
         1.3262, 1.3007, 1.2695, 1.2947, 1.3266, 1.2811, 1.3026, 1.2771, 1.2720,
         1.3896, 1.4248, 1.4109, 1.3831, 1.4039, 1.3956, 1.3960, 1.2766, 1.3149,
         1.3236, 1.3204, 1.3102, 1.2930, 1.2761, 1.3140, 1.3536, 1.2870, 1.2962],
        [1.2500, 1.2777, 1.2817, 1.2588, 1.2831, 1.2549, 1.2631, 1.2478, 1.2478,
         1.3133, 1.2727, 1.3263, 1.3256, 1.2994, 1.2875, 1.3111, 1.3022, 1.1483,
         1.2968, 1.3080, 1.3378, 1.3082, 1.2717, 1.2494, 1.2882, 1.2599, 1.2599,
         2.8489, 2.5221, 2.2542, 2.3723, 2.8428, 2.2641, 2.7963, 2.2678, 2.2563,
         1.3986, 1.4340, 1.4013, 1.3903, 1.4130, 1.3978, 1.4031, 1.2347, 1.3366,
         1.3799, 1.3128, 1.2130, 1.2556, 1.3740, 1.2598, 1.4108, 1.2495, 1.3065],
        [1.7886, 1.4417, 0.6608, 0.8798, 1.2451, 1.6707, 1.6029, 1.7862, 1.7862,
         1.6750, 1.3903, 1.4933, 1.0106, 1.7804, 0.3229, 1.6598, 1.8006, 1.2678,
         1.3857, 0.9379, 0.8192, 1.1629, 1.6444, 1.7261, 1.4085, 1.7963, 1.7963,
         0.7760, 0.8966, 1.7697, 1.5434, 0.8685, 1.7018, 1.1844, 1.8205, 1.7446,
         0.5184, 0.3004, 0.2722, 0.4742, 0.7342, 0.8863, 0.4210, 9.6443, 7.2404,
         0.8461, 1.3206, 1.4173, 1.6628, 1.0966, 1.6220, 0.4870, 1.7146, 1.8362],
        [1.3159, 1.3434, 1.4014, 1.3794, 1.3497, 1.3209, 1.2842, 1.3137, 1.3137,
         1.2839, 1.3874, 1.2959, 1.4066, 1.3645, 1.4481, 1.2818, 1.3677, 1.2940,
         1.3624, 1.3902, 1.4036, 1.3732, 1.3375, 1.3286, 1.2854, 1.3258, 1.3258,
         1.3687, 1.4179, 1.3452, 1.1714, 1.3194, 1.2173, 1.3778, 1.2188, 1.3477,
         1.4622, 1.1820, 1.4833, 1.4699, 1.0749, 0.9856, 1.4686, 1.4408, 0.8789,
         2.9381, 2.4622, 3.0424, 2.6833, 2.1204, 1.8478, 2.7705, 2.8694, 1.8333]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 166 : 182.00746956946563
Test loss for epoch 166 : 182.04678776201132
Test Precision for epoch 166 : 0.26153846153846155
Test Recall for epoch 166 : 0.26153846153846155
Test F1 for epoch 166 : 0.26153846153846155


theta for epoch 167 : tensor([[2.4389, 2.4635, 2.5284, 2.6189, 2.5858, 2.4430, 2.5675, 2.4370, 2.4370,
         1.2960, 1.3066, 1.3090, 1.3244, 1.2823, 1.3664, 1.2938, 1.2854, 1.2604,
         1.2790, 1.2623, 1.2757, 1.2903, 1.2542, 1.2459, 1.2710, 1.2425, 1.2425,
         1.2862, 1.3355, 1.2623, 1.2875, 1.3320, 1.2739, 1.2952, 1.2250, 1.2648,
         1.3832, 1.4185, 1.4045, 1.3909, 1.3977, 1.3380, 1.3896, 1.3656, 1.3225,
         1.3618, 1.3134, 1.3032, 1.2862, 1.3560, 1.3067, 1.3924, 1.2802, 1.2893],
        [1.3210, 1.2221, 1.0385, 1.2582, 1.3398, 1.3713, 1.2920, 1.3641, 1.3641,
         1.6982, 1.9491, 1.6913, 2.4710, 1.7421, 4.6997, 1.8003, 1.6303, 4.4570,
         1.1594, 1.2313, 1.0199, 1.2065, 1.3434, 1.3786, 1.3533, 1.3761, 1.3761,
         1.3303, 1.0834, 1.3953, 1.3719, 1.1670, 1.4069, 1.4225, 1.3586, 1.3817,
         1.4319, 1.5458, 1.4788, 1.4091, 1.4048, 1.5123, 1.4647, 0.6137, 1.4465,
         1.0615, 1.4446, 1.4328, 1.4177, 1.0962, 1.4362, 0.8964, 1.4117, 1.4212],
        [1.2390, 1.2664, 1.3243, 1.3017, 1.2718, 1.2440, 1.2517, 1.2369, 1.2369,
         1.3025, 1.3135, 1.3155, 1.3307, 1.2888, 1.3174, 1.3004, 1.2784, 1.2268,
         2.5037, 2.5662, 2.6907, 2.6249, 2.3802, 2.4768, 2.5205, 2.3702, 2.3702,
         1.3259, 1.3004, 1.2692, 1.2944, 1.3263, 1.2808, 1.3024, 1.2768, 1.2717,
         1.3895, 1.4248, 1.4108, 1.3829, 1.4039, 1.3956, 1.3959, 1.2764, 1.3146,
         1.3233, 1.3201, 1.3099, 1.2927, 1.2760, 1.3137, 1.3533, 1.2867, 1.2959],
        [1.2496, 1.2772, 1.2823, 1.2594, 1.2827, 1.2545, 1.2627, 1.2474, 1.2474,
         1.3129, 1.2732, 1.3259, 1.3257, 1.2990, 1.2872, 1.3107, 1.3018, 1.1495,
         1.2964, 1.3080, 1.3374, 1.3078, 1.2713, 1.2493, 1.2878, 1.2595, 1.2595,
         2.8517, 2.5275, 2.2587, 2.3773, 2.8457, 2.2686, 2.7992, 2.2722, 2.2608,
         1.3984, 1.4339, 1.4015, 1.3904, 1.4129, 1.3979, 1.4029, 1.2360, 1.3363,
         1.3795, 1.3128, 1.2129, 1.2552, 1.3735, 1.2606, 1.4104, 1.2490, 1.3061],
        [1.7892, 1.4424, 0.6612, 0.8801, 1.2457, 1.6714, 1.6036, 1.7868, 1.7868,
         1.6757, 1.3902, 1.4940, 1.0110, 1.7810, 0.3238, 1.6604, 1.8014, 1.2671,
         1.3864, 0.9386, 0.8199, 1.1637, 1.6452, 1.7264, 1.4095, 1.7970, 1.7970,
         0.7762, 0.8974, 1.7704, 1.5444, 0.8686, 1.7024, 1.1843, 1.8213, 1.7451,
         0.5163, 0.2983, 0.2704, 0.4722, 0.7314, 0.8832, 0.4189, 9.6863, 7.2505,
         0.8470, 1.3211, 1.4180, 1.6634, 1.0973, 1.6218, 0.4878, 1.7155, 1.8368],
        [1.3156, 1.3432, 1.4012, 1.3792, 1.3494, 1.3206, 1.2839, 1.3135, 1.3135,
         1.2837, 1.3872, 1.2957, 1.4064, 1.3643, 1.4479, 1.2816, 1.3675, 1.2938,
         1.3622, 1.3900, 1.4033, 1.3729, 1.3373, 1.3283, 1.2849, 1.3256, 1.3256,
         1.3685, 1.4176, 1.3449, 1.1709, 1.3193, 1.2171, 1.3776, 1.2185, 1.3474,
         1.4621, 1.1816, 1.4832, 1.4698, 1.0744, 0.9851, 1.4686, 1.4406, 0.8783,
         2.9438, 2.4653, 3.0493, 2.6872, 2.1224, 1.8494, 2.7747, 2.8754, 1.8349]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 167 : 182.00118315510565
Test loss for epoch 167 : 182.04106806535208
Test Precision for epoch 167 : 0.26153846153846155
Test Recall for epoch 167 : 0.26153846153846155
Test F1 for epoch 167 : 0.26153846153846155


theta for epoch 168 : tensor([[2.4427, 2.4672, 2.5322, 2.6231, 2.5901, 2.4468, 2.5717, 2.4408, 2.4408,
         1.2957, 1.3064, 1.3087, 1.3241, 1.2820, 1.3661, 1.2935, 1.2851, 1.2601,
         1.2787, 1.2620, 1.2753, 1.2900, 1.2539, 1.2456, 1.2707, 1.2422, 1.2422,
         1.2860, 1.3352, 1.2620, 1.2871, 1.3318, 1.2736, 1.2949, 1.2246, 1.2645,
         1.3831, 1.4185, 1.4044, 1.3908, 1.3976, 1.3380, 1.3895, 1.3652, 1.3223,
         1.3615, 1.3131, 1.3029, 1.2858, 1.3557, 1.3064, 1.3921, 1.2798, 1.2890],
        [1.3209, 1.2219, 1.0385, 1.2581, 1.3398, 1.3711, 1.2918, 1.3640, 1.3640,
         1.6991, 1.9498, 1.6922, 2.4723, 1.7430, 4.7141, 1.8013, 1.6312, 4.4722,
         1.1593, 1.2312, 1.0201, 1.2064, 1.3433, 1.3785, 1.3531, 1.3759, 1.3759,
         1.3303, 1.0833, 1.3951, 1.3717, 1.1670, 1.4067, 1.4225, 1.3584, 1.3817,
         1.4323, 1.5459, 1.4788, 1.4091, 1.4051, 1.5124, 1.4646, 0.6138, 1.4465,
         1.0615, 1.4445, 1.4326, 1.4176, 1.0961, 1.4361, 0.8967, 1.4115, 1.4210],
        [1.2387, 1.2661, 1.3240, 1.3014, 1.2715, 1.2437, 1.2514, 1.2366, 1.2366,
         1.3023, 1.3133, 1.3153, 1.3304, 1.2885, 1.3172, 1.3001, 1.2781, 1.2267,
         2.5075, 2.5704, 2.6951, 2.6292, 2.3838, 2.4807, 2.5246, 2.3738, 2.3738,
         1.3256, 1.3002, 1.2689, 1.2940, 1.3260, 1.2805, 1.3022, 1.2765, 1.2714,
         1.3894, 1.4248, 1.4107, 1.3827, 1.4039, 1.3956, 1.3959, 1.2762, 1.3144,
         1.3231, 1.3198, 1.3096, 1.2924, 1.2758, 1.3134, 1.3531, 1.2863, 1.2956],
        [1.2491, 1.2768, 1.2829, 1.2600, 1.2823, 1.2541, 1.2623, 1.2469, 1.2469,
         1.3125, 1.2737, 1.3255, 1.3257, 1.2986, 1.2868, 1.3103, 1.3014, 1.1508,
         1.2960, 1.3080, 1.3370, 1.3074, 1.2709, 1.2493, 1.2873, 1.2591, 1.2591,
         2.8544, 2.5329, 2.2631, 2.3822, 2.8485, 2.2731, 2.8021, 2.2766, 2.2653,
         1.3981, 1.4338, 1.4017, 1.3906, 1.4127, 1.3980, 1.4028, 1.2372, 1.3359,
         1.3791, 1.3129, 1.2128, 1.2547, 1.3731, 1.2614, 1.4100, 1.2486, 1.3057],
        [1.7899, 1.4432, 0.6616, 0.8805, 1.2463, 1.6721, 1.6043, 1.7875, 1.7875,
         1.6764, 1.3900, 1.4947, 1.0114, 1.7817, 0.3246, 1.6611, 1.8021, 1.2664,
         1.3871, 0.9392, 0.8206, 1.1644, 1.6459, 1.7268, 1.4105, 1.7977, 1.7977,
         0.7764, 0.8981, 1.7711, 1.5453, 0.8687, 1.7030, 1.1841, 1.8220, 1.7455,
         0.5142, 0.2962, 0.2686, 0.4701, 0.7287, 0.8802, 0.4168, 9.7281, 7.2602,
         0.8478, 1.3215, 1.4187, 1.6641, 1.0979, 1.6215, 0.4885, 1.7165, 1.8375],
        [1.3154, 1.3429, 1.4009, 1.3789, 1.3492, 1.3203, 1.2837, 1.3132, 1.3132,
         1.2835, 1.3871, 1.2955, 1.4062, 1.3641, 1.4477, 1.2813, 1.3672, 1.2936,
         1.3619, 1.3898, 1.4031, 1.3727, 1.3371, 1.3281, 1.2843, 1.3253, 1.3253,
         1.3684, 1.4174, 1.3447, 1.1703, 1.3192, 1.2168, 1.3775, 1.2182, 1.3471,
         1.4620, 1.1812, 1.4832, 1.4697, 1.0740, 0.9847, 1.4685, 1.4404, 0.8778,
         2.9495, 2.4683, 3.0562, 2.6912, 2.1245, 1.8510, 2.7788, 2.8814, 1.8366]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 168 : 181.9949615621689
Test loss for epoch 168 : 182.03541065369726
Test Precision for epoch 168 : 0.26153846153846155
Test Recall for epoch 168 : 0.26153846153846155
Test F1 for epoch 168 : 0.26153846153846155


theta for epoch 169 : tensor([[2.4464, 2.4709, 2.5359, 2.6273, 2.5943, 2.4505, 2.5759, 2.4445, 2.4445,
         1.2953, 1.3061, 1.3083, 1.3238, 1.2816, 1.3658, 1.2932, 1.2848, 1.2598,
         1.2784, 1.2617, 1.2750, 1.2897, 1.2536, 1.2453, 1.2704, 1.2419, 1.2419,
         1.2857, 1.3348, 1.2617, 1.2868, 1.3315, 1.2732, 1.2947, 1.2243, 1.2642,
         1.3829, 1.4185, 1.4043, 1.3906, 1.3976, 1.3379, 1.3894, 1.3649, 1.3221,
         1.3612, 1.3128, 1.3025, 1.2855, 1.3554, 1.3061, 1.3918, 1.2795, 1.2887],
        [1.3207, 1.2218, 1.0385, 1.2580, 1.3399, 1.3710, 1.2917, 1.3638, 1.3638,
         1.6999, 1.9504, 1.6930, 2.4736, 1.7439, 4.7285, 1.8022, 1.6320, 4.4873,
         1.1591, 1.2311, 1.0203, 1.2063, 1.3431, 1.3783, 1.3529, 1.3758, 1.3758,
         1.3303, 1.0833, 1.3949, 1.3716, 1.1670, 1.4066, 1.4225, 1.3582, 1.3818,
         1.4326, 1.5460, 1.4788, 1.4092, 1.4054, 1.5126, 1.4646, 0.6140, 1.4464,
         1.0616, 1.4444, 1.4325, 1.4174, 1.0961, 1.4360, 0.8970, 1.4114, 1.4209],
        [1.2384, 1.2658, 1.3237, 1.3011, 1.2712, 1.2434, 1.2511, 1.2363, 1.2363,
         1.3020, 1.3130, 1.3150, 1.3302, 1.2883, 1.3169, 1.2998, 1.2777, 1.2266,
         2.5112, 2.5746, 2.6996, 2.6333, 2.3874, 2.4846, 2.5286, 2.3773, 2.3773,
         1.3253, 1.3000, 1.2686, 1.2937, 1.3257, 1.2802, 1.3020, 1.2762, 1.2711,
         1.3893, 1.4248, 1.4106, 1.3825, 1.4039, 1.3956, 1.3958, 1.2760, 1.3141,
         1.3228, 1.3195, 1.3093, 1.2922, 1.2757, 1.3131, 1.3529, 1.2860, 1.2953],
        [1.2487, 1.2764, 1.2834, 1.2606, 1.2819, 1.2537, 1.2619, 1.2465, 1.2465,
         1.3121, 1.2742, 1.3251, 1.3257, 1.2982, 1.2865, 1.3099, 1.3010, 1.1520,
         1.2955, 1.3080, 1.3366, 1.3070, 1.2705, 1.2492, 1.2869, 1.2587, 1.2587,
         2.8571, 2.5383, 2.2676, 2.3871, 2.8513, 2.2775, 2.8050, 2.2810, 2.2697,
         1.3979, 1.4336, 1.4019, 1.3907, 1.4126, 1.3980, 1.4026, 1.2385, 1.3356,
         1.3787, 1.3129, 1.2126, 1.2543, 1.3727, 1.2622, 1.4096, 1.2481, 1.3053],
        [1.7905, 1.4439, 0.6620, 0.8808, 1.2470, 1.6728, 1.6050, 1.7882, 1.7882,
         1.6770, 1.3899, 1.4954, 1.0118, 1.7823, 0.3254, 1.6617, 1.8029, 1.2657,
         1.3878, 0.9399, 0.8212, 1.1651, 1.6465, 1.7271, 1.4115, 1.7984, 1.7984,
         0.7766, 0.8989, 1.7717, 1.5463, 0.8688, 1.7036, 1.1840, 1.8227, 1.7460,
         0.5121, 0.2941, 0.2668, 0.4681, 0.7260, 0.8772, 0.4148, 9.7699, 7.2695,
         0.8487, 1.3220, 1.4194, 1.6647, 1.0986, 1.6212, 0.4892, 1.7174, 1.8381],
        [1.3151, 1.3426, 1.4007, 1.3787, 1.3489, 1.3201, 1.2834, 1.3129, 1.3129,
         1.2832, 1.3869, 1.2953, 1.4060, 1.3638, 1.4475, 1.2811, 1.3670, 1.2934,
         1.3617, 1.3895, 1.4029, 1.3725, 1.3368, 1.3279, 1.2838, 1.3251, 1.3251,
         1.3682, 1.4171, 1.3444, 1.1697, 1.3190, 1.2166, 1.3774, 1.2179, 1.3469,
         1.4620, 1.1807, 1.4831, 1.4696, 1.0735, 0.9842, 1.4685, 1.4402, 0.8772,
         2.9552, 2.4713, 3.0631, 2.6951, 2.1265, 1.8526, 2.7829, 2.8874, 1.8381]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 169 : 181.98880211873
Test loss for epoch 169 : 182.02981521527983
Test Precision for epoch 169 : 0.26153846153846155
Test Recall for epoch 169 : 0.26153846153846155
Test F1 for epoch 169 : 0.26153846153846155


theta for epoch 170 : tensor([[2.4500, 2.4746, 2.5396, 2.6315, 2.5985, 2.4542, 2.5801, 2.4481, 2.4481,
         1.2950, 1.3058, 1.3081, 1.3236, 1.2813, 1.3656, 1.2929, 1.2845, 1.2595,
         1.2781, 1.2613, 1.2747, 1.2894, 1.2533, 1.2450, 1.2701, 1.2416, 1.2416,
         1.2855, 1.3345, 1.2614, 1.2865, 1.3313, 1.2729, 1.2945, 1.2240, 1.2638,
         1.3828, 1.4184, 1.4041, 1.3905, 1.3975, 1.3378, 1.3893, 1.3645, 1.3219,
         1.3609, 1.3125, 1.3022, 1.2852, 1.3551, 1.3058, 1.3915, 1.2791, 1.2884],
        [1.3205, 1.2217, 1.0386, 1.2579, 1.3400, 1.3708, 1.2915, 1.3637, 1.3637,
         1.7008, 1.9511, 1.6939, 2.4748, 1.7448, 4.7429, 1.8032, 1.6328, 4.5025,
         1.1590, 1.2310, 1.0205, 1.2062, 1.3430, 1.3782, 1.3528, 1.3757, 1.3757,
         1.3304, 1.0833, 1.3948, 1.3715, 1.1670, 1.4064, 1.4226, 1.3580, 1.3818,
         1.4329, 1.5461, 1.4787, 1.4092, 1.4057, 1.5128, 1.4646, 0.6141, 1.4463,
         1.0616, 1.4443, 1.4323, 1.4172, 1.0960, 1.4359, 0.8973, 1.4112, 1.4208],
        [1.2381, 1.2655, 1.3234, 1.3008, 1.2710, 1.2431, 1.2508, 1.2360, 1.2360,
         1.3017, 1.3128, 1.3147, 1.3300, 1.2880, 1.3167, 1.2995, 1.2774, 1.2265,
         2.5150, 2.5787, 2.7040, 2.6375, 2.3909, 2.4885, 2.5327, 2.3809, 2.3809,
         1.3250, 1.2998, 1.2683, 1.2934, 1.3254, 1.2799, 1.3018, 1.2759, 1.2708,
         1.3892, 1.4248, 1.4105, 1.3822, 1.4038, 1.3956, 1.3957, 1.2758, 1.3138,
         1.3226, 1.3192, 1.3090, 1.2919, 1.2756, 1.3129, 1.3527, 1.2857, 1.2950],
        [1.2483, 1.2760, 1.2840, 1.2612, 1.2815, 1.2533, 1.2614, 1.2461, 1.2461,
         1.3117, 1.2748, 1.3248, 1.3257, 1.2979, 1.2862, 1.3095, 1.3006, 1.1533,
         1.2952, 1.3080, 1.3362, 1.3066, 1.2701, 1.2491, 1.2865, 1.2583, 1.2583,
         2.8598, 2.5437, 2.2721, 2.3920, 2.8540, 2.2820, 2.8078, 2.2854, 2.2742,
         1.3977, 1.4335, 1.4021, 1.3908, 1.4124, 1.3981, 1.4025, 1.2398, 1.3353,
         1.3782, 1.3129, 1.2125, 1.2539, 1.3723, 1.2630, 1.4092, 1.2477, 1.3049],
        [1.7912, 1.4445, 0.6623, 0.8811, 1.2475, 1.6734, 1.6057, 1.7888, 1.7888,
         1.6777, 1.3897, 1.4961, 1.0121, 1.7829, 0.3263, 1.6623, 1.8036, 1.2650,
         1.3884, 0.9406, 0.8219, 1.1658, 1.6472, 1.7275, 1.4124, 1.7990, 1.7990,
         0.7768, 0.8996, 1.7724, 1.5472, 0.8689, 1.7043, 1.1838, 1.8234, 1.7465,
         0.5101, 0.2921, 0.2651, 0.4662, 0.7234, 0.8742, 0.4128, 9.8115, 7.2784,
         0.8495, 1.3224, 1.4200, 1.6654, 1.0993, 1.6209, 0.4899, 1.7183, 1.8388],
        [1.3149, 1.3424, 1.4005, 1.3785, 1.3487, 1.3198, 1.2831, 1.3127, 1.3127,
         1.2830, 1.3867, 1.2951, 1.4058, 1.3636, 1.4473, 1.2809, 1.3668, 1.2932,
         1.3615, 1.3893, 1.4027, 1.3723, 1.3366, 1.3277, 1.2833, 1.3249, 1.3249,
         1.3680, 1.4169, 1.3442, 1.1691, 1.3189, 1.2164, 1.3772, 1.2176, 1.3466,
         1.4619, 1.1803, 1.4830, 1.4696, 1.0731, 0.9837, 1.4684, 1.4400, 0.8766,
         2.9609, 2.4743, 3.0699, 2.6990, 2.1284, 1.8542, 2.7869, 2.8933, 1.8397]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 170 : 181.98270418519064
Test loss for epoch 170 : 182.02429541442567
Test Precision for epoch 170 : 0.26153846153846155
Test Recall for epoch 170 : 0.26153846153846155
Test F1 for epoch 170 : 0.26153846153846155


theta for epoch 171 : tensor([[2.4537, 2.4783, 2.5433, 2.6356, 2.6026, 2.4578, 2.5843, 2.4518, 2.4518,
         1.2948, 1.3056, 1.3078, 1.3233, 1.2811, 1.3653, 1.2926, 1.2842, 1.2593,
         1.2778, 1.2610, 1.2744, 1.2891, 1.2530, 1.2447, 1.2698, 1.2413, 1.2413,
         1.2852, 1.3342, 1.2610, 1.2861, 1.3311, 1.2726, 1.2943, 1.2236, 1.2635,
         1.3827, 1.4184, 1.4040, 1.3903, 1.3975, 1.3377, 1.3892, 1.3641, 1.3217,
         1.3606, 1.3122, 1.3019, 1.2849, 1.3548, 1.3055, 1.3912, 1.2788, 1.2881],
        [1.3204, 1.2216, 1.0386, 1.2578, 1.3401, 1.3707, 1.2913, 1.3635, 1.3635,
         1.7016, 1.9517, 1.6947, 2.4760, 1.7456, 4.7573, 1.8041, 1.6336, 4.5176,
         1.1589, 1.2309, 1.0207, 1.2061, 1.3429, 1.3781, 1.3526, 1.3755, 1.3755,
         1.3304, 1.0832, 1.3946, 1.3713, 1.1670, 1.4063, 1.4226, 1.3578, 1.3819,
         1.4333, 1.5461, 1.4787, 1.4093, 1.4060, 1.5129, 1.4646, 0.6143, 1.4463,
         1.0617, 1.4442, 1.4322, 1.4171, 1.0960, 1.4358, 0.8977, 1.4110, 1.4206],
        [1.2379, 1.2652, 1.3231, 1.3006, 1.2707, 1.2428, 1.2505, 1.2357, 1.2357,
         1.3015, 1.3126, 1.3145, 1.3298, 1.2878, 1.3165, 1.2993, 1.2770, 1.2264,
         2.5187, 2.5828, 2.7084, 2.6416, 2.3944, 2.4923, 2.5367, 2.3844, 2.3844,
         1.3247, 1.2996, 1.2680, 1.2931, 1.3251, 1.2796, 1.3017, 1.2756, 1.2705,
         1.3891, 1.4248, 1.4104, 1.3820, 1.4038, 1.3956, 1.3956, 1.2756, 1.3135,
         1.3224, 1.3190, 1.3087, 1.2916, 1.2755, 1.3126, 1.3525, 1.2854, 1.2948],
        [1.2479, 1.2755, 1.2846, 1.2619, 1.2811, 1.2528, 1.2610, 1.2457, 1.2457,
         1.3113, 1.2753, 1.3244, 1.3257, 1.2975, 1.2859, 1.3091, 1.3002, 1.1546,
         1.2948, 1.3080, 1.3358, 1.3062, 1.2697, 1.2490, 1.2861, 1.2579, 1.2579,
         2.8624, 2.5490, 2.2765, 2.3968, 2.8567, 2.2864, 2.8105, 2.2898, 2.2786,
         1.3974, 1.4334, 1.4022, 1.3910, 1.4123, 1.3981, 1.4023, 1.2411, 1.3350,
         1.3778, 1.3130, 1.2124, 1.2535, 1.3719, 1.2638, 1.4088, 1.2473, 1.3045],
        [1.7918, 1.4452, 0.6626, 0.8813, 1.2481, 1.6741, 1.6064, 1.7894, 1.7894,
         1.6783, 1.3895, 1.4967, 1.0125, 1.7835, 0.3271, 1.6630, 1.8043, 1.2642,
         1.3891, 0.9412, 0.8225, 1.1665, 1.6479, 1.7278, 1.4134, 1.7997, 1.7997,
         0.7770, 0.9003, 1.7730, 1.5481, 0.8689, 1.7049, 1.1836, 1.8240, 1.7469,
         0.5081, 0.2901, 0.2634, 0.4642, 0.7208, 0.8713, 0.4108, 9.8531, 7.2869,
         0.8503, 1.3228, 1.4207, 1.6660, 1.0999, 1.6206, 0.4906, 1.7193, 1.8394],
        [1.3146, 1.3421, 1.4002, 1.3782, 1.3484, 1.3195, 1.2829, 1.3124, 1.3124,
         1.2828, 1.3866, 1.2949, 1.4056, 1.3634, 1.4471, 1.2806, 1.3665, 1.2930,
         1.3613, 1.3891, 1.4025, 1.3721, 1.3364, 1.3274, 1.2828, 1.3246, 1.3246,
         1.3678, 1.4166, 1.3439, 1.1685, 1.3188, 1.2162, 1.3771, 1.2173, 1.3464,
         1.4618, 1.1798, 1.4829, 1.4695, 1.0726, 0.9833, 1.4684, 1.4397, 0.8761,
         2.9666, 2.4772, 3.0768, 2.7029, 2.1304, 1.8557, 2.7910, 2.8992, 1.8413]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 171 : 181.9766651747838
Test loss for epoch 171 : 182.0188240583528
Test Precision for epoch 171 : 0.26153846153846155
Test Recall for epoch 171 : 0.26153846153846155
Test F1 for epoch 171 : 0.26153846153846155


theta for epoch 172 : tensor([[2.4573, 2.4819, 2.5469, 2.6398, 2.6067, 2.4614, 2.5884, 2.4554, 2.4554,
         1.2945, 1.3053, 1.3075, 1.3230, 1.2808, 1.3650, 1.2923, 1.2839, 1.2590,
         1.2775, 1.2607, 1.2741, 1.2889, 1.2527, 1.2444, 1.2695, 1.2410, 1.2410,
         1.2850, 1.3338, 1.2607, 1.2858, 1.3308, 1.2722, 1.2941, 1.2233, 1.2632,
         1.3825, 1.4183, 1.4038, 1.3902, 1.3974, 1.3377, 1.3891, 1.3638, 1.3215,
         1.3603, 1.3119, 1.3015, 1.2846, 1.3545, 1.3052, 1.3909, 1.2784, 1.2877],
        [1.3202, 1.2215, 1.0387, 1.2578, 1.3402, 1.3705, 1.2912, 1.3634, 1.3634,
         1.7023, 1.9522, 1.6954, 2.4771, 1.7465, 4.7716, 1.8050, 1.6344, 4.5327,
         1.1588, 1.2309, 1.0210, 1.2060, 1.3428, 1.3780, 1.3525, 1.3754, 1.3754,
         1.3304, 1.0832, 1.3945, 1.3712, 1.1670, 1.4061, 1.4226, 1.3576, 1.3820,
         1.4336, 1.5462, 1.4786, 1.4094, 1.4063, 1.5131, 1.4645, 0.6144, 1.4462,
         1.0618, 1.4440, 1.4321, 1.4170, 1.0959, 1.4357, 0.8981, 1.4108, 1.4205],
        [1.2376, 1.2650, 1.3229, 1.3003, 1.2704, 1.2425, 1.2503, 1.2354, 1.2354,
         1.3012, 1.3124, 1.3142, 1.3295, 1.2875, 1.3163, 1.2991, 1.2767, 1.2264,
         2.5224, 2.5869, 2.7128, 2.6457, 2.3979, 2.4960, 2.5407, 2.3878, 2.3878,
         1.3244, 1.2994, 1.2677, 1.2928, 1.3248, 1.2793, 1.3015, 1.2753, 1.2702,
         1.3890, 1.4248, 1.4103, 1.3818, 1.4038, 1.3955, 1.3956, 1.2754, 1.3132,
         1.3221, 1.3187, 1.3084, 1.2913, 1.2754, 1.3123, 1.3523, 1.2851, 1.2945],
        [1.2475, 1.2751, 1.2852, 1.2625, 1.2807, 1.2524, 1.2606, 1.2453, 1.2453,
         1.3109, 1.2759, 1.3240, 1.3257, 1.2971, 1.2855, 1.3087, 1.2998, 1.1558,
         1.2944, 1.3080, 1.3354, 1.3058, 1.2693, 1.2490, 1.2857, 1.2575, 1.2575,
         2.8649, 2.5544, 2.2809, 2.4017, 2.8593, 2.2908, 2.8132, 2.2941, 2.2830,
         1.3972, 1.4332, 1.4024, 1.3911, 1.4122, 1.3982, 1.4021, 1.2424, 1.3347,
         1.3774, 1.3130, 1.2123, 1.2531, 1.3715, 1.2646, 1.4084, 1.2468, 1.3041],
        [1.7924, 1.4458, 0.6630, 0.8816, 1.2487, 1.6747, 1.6070, 1.7901, 1.7901,
         1.6790, 1.3893, 1.4974, 1.0128, 1.7841, 0.3278, 1.6636, 1.8051, 1.2635,
         1.3898, 0.9418, 0.8231, 1.1672, 1.6486, 1.7281, 1.4144, 1.8003, 1.8003,
         0.7772, 0.9010, 1.7736, 1.5491, 0.8690, 1.7055, 1.1834, 1.8247, 1.7473,
         0.5062, 0.2881, 0.2617, 0.4623, 0.7183, 0.8684, 0.4088, 9.8945, 7.2950,
         0.8511, 1.3232, 1.4214, 1.6666, 1.1005, 1.6202, 0.4912, 1.7202, 1.8400],
        [1.3144, 1.3419, 1.4000, 1.3780, 1.3482, 1.3193, 1.2826, 1.3122, 1.3122,
         1.2826, 1.3865, 1.2947, 1.4055, 1.3632, 1.4470, 1.2804, 1.3663, 1.2928,
         1.3611, 1.3889, 1.4023, 1.3719, 1.3362, 1.3272, 1.2823, 1.3244, 1.3244,
         1.3677, 1.4164, 1.3437, 1.1679, 1.3187, 1.2160, 1.3769, 1.2170, 1.3461,
         1.4617, 1.1794, 1.4828, 1.4694, 1.0721, 0.9828, 1.4683, 1.4395, 0.8755,
         2.9723, 2.4801, 3.0836, 2.7067, 2.1323, 1.8573, 2.7950, 2.9051, 1.8428]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 172 : 181.97068378723475
Test loss for epoch 172 : 182.01341873316267
Test Precision for epoch 172 : 0.26153846153846155
Test Recall for epoch 172 : 0.26153846153846155
Test F1 for epoch 172 : 0.26153846153846155


theta for epoch 173 : tensor([[2.4609, 2.4855, 2.5505, 2.6438, 2.6108, 2.4650, 2.5925, 2.4590, 2.4590,
         1.2942, 1.3051, 1.3072, 1.3228, 1.2805, 1.3648, 1.2920, 1.2836, 1.2587,
         1.2772, 1.2605, 1.2738, 1.2886, 1.2524, 1.2441, 1.2692, 1.2407, 1.2407,
         1.2848, 1.3335, 1.2604, 1.2855, 1.3306, 1.2719, 1.2939, 1.2230, 1.2629,
         1.3824, 1.4183, 1.4037, 1.3901, 1.3973, 1.3376, 1.3890, 1.3634, 1.3212,
         1.3600, 1.3116, 1.3012, 1.2842, 1.3542, 1.3049, 1.3906, 1.2781, 1.2874],
        [1.3201, 1.2214, 1.0387, 1.2577, 1.3403, 1.3704, 1.2911, 1.3632, 1.3632,
         1.7031, 1.9527, 1.6962, 2.4783, 1.7473, 4.7859, 1.8058, 1.6351, 4.5478,
         1.1587, 1.2308, 1.0212, 1.2059, 1.3427, 1.3779, 1.3523, 1.3753, 1.3753,
         1.3304, 1.0832, 1.3943, 1.3711, 1.1670, 1.4060, 1.4227, 1.3575, 1.3820,
         1.4340, 1.5463, 1.4786, 1.4094, 1.4066, 1.5132, 1.4645, 0.6146, 1.4462,
         1.0618, 1.4439, 1.4319, 1.4168, 1.0959, 1.4356, 0.8984, 1.4106, 1.4204],
        [1.2373, 1.2647, 1.3226, 1.3000, 1.2701, 1.2422, 1.2500, 1.2351, 1.2351,
         1.3010, 1.3122, 1.3140, 1.3293, 1.2873, 1.3161, 1.2988, 1.2763, 1.2263,
         2.5260, 2.5910, 2.7171, 2.6497, 2.4014, 2.4998, 2.5446, 2.3913, 2.3913,
         1.3241, 1.2992, 1.2675, 1.2925, 1.3245, 1.2790, 1.3013, 1.2750, 1.2699,
         1.3889, 1.4247, 1.4101, 1.3816, 1.4038, 1.3955, 1.3955, 1.2752, 1.3129,
         1.3219, 1.3185, 1.3081, 1.2910, 1.2753, 1.3121, 1.3521, 1.2848, 1.2942],
        [1.2470, 1.2747, 1.2858, 1.2631, 1.2803, 1.2520, 1.2602, 1.2449, 1.2449,
         1.3106, 1.2765, 1.3236, 1.3257, 1.2967, 1.2852, 1.3084, 1.2995, 1.1571,
         1.2940, 1.3080, 1.3350, 1.3055, 1.2689, 1.2489, 1.2853, 1.2571, 1.2571,
         2.8674, 2.5597, 2.2853, 2.4065, 2.8619, 2.2952, 2.8158, 2.2984, 2.2874,
         1.3970, 1.4331, 1.4026, 1.3912, 1.4120, 1.3982, 1.4020, 1.2437, 1.3344,
         1.3770, 1.3130, 1.2122, 1.2527, 1.3711, 1.2655, 1.4080, 1.2464, 1.3037],
        [1.7931, 1.4465, 0.6633, 0.8819, 1.2492, 1.6754, 1.6077, 1.7907, 1.7907,
         1.6796, 1.3891, 1.4980, 1.0132, 1.7847, 0.3286, 1.6642, 1.8058, 1.2627,
         1.3904, 0.9424, 0.8238, 1.1678, 1.6492, 1.7284, 1.4153, 1.8010, 1.8010,
         0.7773, 0.9017, 1.7742, 1.5500, 0.8691, 1.7061, 1.1833, 1.8254, 1.7478,
         0.5042, 0.2862, 0.2600, 0.4604, 0.7158, 0.8656, 0.4068, 9.9359, 7.3027,
         0.8519, 1.3237, 1.4220, 1.6672, 1.1011, 1.6199, 0.4919, 1.7211, 1.8406],
        [1.3141, 1.3416, 1.3997, 1.3777, 1.3480, 1.3190, 1.2824, 1.3119, 1.3119,
         1.2823, 1.3863, 1.2945, 1.4053, 1.3629, 1.4468, 1.2802, 1.3661, 1.2926,
         1.3609, 1.3887, 1.4020, 1.3716, 1.3359, 1.3270, 1.2818, 1.3242, 1.3242,
         1.3675, 1.4162, 1.3434, 1.1674, 1.3186, 1.2158, 1.3768, 1.2167, 1.3459,
         1.4616, 1.1789, 1.4827, 1.4693, 1.0716, 0.9823, 1.4683, 1.4393, 0.8749,
         2.9779, 2.4830, 3.0904, 2.7105, 2.1342, 1.8588, 2.7989, 2.9109, 1.8443]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 173 : 181.96475795039984
Test loss for epoch 173 : 182.00807279014873
Test Precision for epoch 173 : 0.26153846153846155
Test Recall for epoch 173 : 0.26153846153846155
Test F1 for epoch 173 : 0.26153846153846155


theta for epoch 174 : tensor([[2.4645, 2.4891, 2.5541, 2.6479, 2.6149, 2.4686, 2.5965, 2.4626, 2.4626,
         1.2939, 1.3048, 1.3069, 1.3225, 1.2802, 1.3645, 1.2917, 1.2833, 1.2585,
         1.2769, 1.2601, 1.2735, 1.2883, 1.2521, 1.2438, 1.2689, 1.2404, 1.2404,
         1.2846, 1.3332, 1.2601, 1.2852, 1.3304, 1.2716, 1.2937, 1.2226, 1.2625,
         1.3822, 1.4183, 1.4036, 1.3899, 1.3973, 1.3375, 1.3889, 1.3631, 1.3210,
         1.3597, 1.3113, 1.3009, 1.2839, 1.3539, 1.3046, 1.3904, 1.2778, 1.2871],
        [1.3200, 1.2213, 1.0387, 1.2576, 1.3404, 1.3702, 1.2909, 1.3631, 1.3631,
         1.7039, 1.9532, 1.6969, 2.4793, 1.7480, 4.8002, 1.8067, 1.6359, 4.5629,
         1.1586, 1.2307, 1.0214, 1.2058, 1.3426, 1.3778, 1.3521, 1.3752, 1.3752,
         1.3305, 1.0832, 1.3942, 1.3710, 1.1670, 1.4058, 1.4227, 1.3573, 1.3821,
         1.4343, 1.5464, 1.4786, 1.4095, 1.4069, 1.5134, 1.4645, 0.6148, 1.4461,
         1.0619, 1.4438, 1.4318, 1.4167, 1.0959, 1.4355, 0.8988, 1.4105, 1.4202],
        [1.2370, 1.2644, 1.3223, 1.2997, 1.2698, 1.2419, 1.2497, 1.2348, 1.2348,
         1.3007, 1.3120, 1.3137, 1.3291, 1.2870, 1.3159, 1.2985, 1.2759, 1.2262,
         2.5296, 2.5950, 2.7214, 2.6537, 2.4048, 2.5035, 2.5486, 2.3947, 2.3947,
         1.3238, 1.2991, 1.2672, 1.2922, 1.3242, 1.2787, 1.3011, 1.2747, 1.2696,
         1.3888, 1.4247, 1.4100, 1.3814, 1.4037, 1.3955, 1.3954, 1.2750, 1.3126,
         1.3217, 1.3182, 1.3078, 1.2908, 1.2752, 1.3118, 1.3519, 1.2844, 1.2940],
        [1.2466, 1.2743, 1.2865, 1.2637, 1.2799, 1.2516, 1.2598, 1.2444, 1.2444,
         1.3102, 1.2771, 1.3233, 1.3257, 1.2963, 1.2849, 1.3080, 1.2991, 1.1583,
         1.2936, 1.3080, 1.3347, 1.3051, 1.2686, 1.2488, 1.2849, 1.2567, 1.2567,
         2.8698, 2.5650, 2.2897, 2.4113, 2.8644, 2.2996, 2.8184, 2.3028, 2.2918,
         1.3967, 1.4330, 1.4027, 1.3913, 1.4119, 1.3982, 1.4018, 1.2450, 1.3341,
         1.3766, 1.3130, 1.2120, 1.2524, 1.3708, 1.2663, 1.4076, 1.2460, 1.3033],
        [1.7937, 1.4471, 0.6636, 0.8821, 1.2498, 1.6760, 1.6083, 1.7913, 1.7913,
         1.6802, 1.3889, 1.4987, 1.0135, 1.7853, 0.3293, 1.6647, 1.8065, 1.2620,
         1.3911, 0.9430, 0.8244, 1.1685, 1.6499, 1.7288, 1.4163, 1.8016, 1.8016,
         0.7775, 0.9024, 1.7748, 1.5509, 0.8692, 1.7067, 1.1831, 1.8260, 1.7482,
         0.5023, 0.2842, 0.2583, 0.4585, 0.7133, 0.8628, 0.4049, 9.9771, 7.3101,
         0.8527, 1.3241, 1.4227, 1.6679, 1.1017, 1.6196, 0.4925, 1.7220, 1.8412],
        [1.3139, 1.3414, 1.3995, 1.3775, 1.3477, 1.3188, 1.2821, 1.3117, 1.3117,
         1.2821, 1.3862, 1.2943, 1.4051, 1.3627, 1.4466, 1.2800, 1.3659, 1.2924,
         1.3606, 1.3884, 1.4018, 1.3714, 1.3357, 1.3268, 1.2813, 1.3239, 1.3239,
         1.3674, 1.4159, 1.3432, 1.1668, 1.3185, 1.2156, 1.3767, 1.2164, 1.3456,
         1.4615, 1.1785, 1.4826, 1.4692, 1.0712, 0.9819, 1.4682, 1.4390, 0.8744,
         2.9835, 2.4858, 3.0972, 2.7142, 2.1361, 1.8603, 2.8028, 2.9167, 1.8458]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 174 : 181.95888693612414
Test loss for epoch 174 : 182.00279144638407
Test Precision for epoch 174 : 0.26153846153846155
Test Recall for epoch 174 : 0.26153846153846155
Test F1 for epoch 174 : 0.26153846153846155


theta for epoch 175 : tensor([[ 2.4680,  2.4927,  2.5577,  2.6519,  2.6189,  2.4722,  2.6006,  2.4661,
          2.4661,  1.2936,  1.3046,  1.3066,  1.3223,  1.2799,  1.3643,  1.2915,
          1.2830,  1.2582,  1.2766,  1.2599,  1.2732,  1.2880,  1.2518,  1.2435,
          1.2686,  1.2401,  1.2401,  1.2843,  1.3329,  1.2598,  1.2848,  1.3302,
          1.2713,  1.2935,  1.2223,  1.2622,  1.3821,  1.4182,  1.4034,  1.3898,
          1.3972,  1.3374,  1.3888,  1.3627,  1.3209,  1.3594,  1.3110,  1.3006,
          1.2836,  1.3536,  1.3044,  1.3901,  1.2774,  1.2868],
        [ 1.3198,  1.2213,  1.0388,  1.2576,  1.3405,  1.3701,  1.2908,  1.3629,
          1.3629,  1.7046,  1.9537,  1.6977,  2.4804,  1.7488,  4.8145,  1.8075,
          1.6366,  4.5779,  1.1585,  1.2307,  1.0216,  1.2057,  1.3425,  1.3777,
          1.3519,  1.3750,  1.3750,  1.3305,  1.0832,  1.3940,  1.3708,  1.1671,
          1.4056,  1.4227,  1.3571,  1.3822,  1.4347,  1.5465,  1.4785,  1.4096,
          1.4072,  1.5136,  1.4645,  0.6150,  1.4461,  1.0620,  1.4437,  1.4317,
          1.4165,  1.0958,  1.4354,  0.8992,  1.4103,  1.4201],
        [ 1.2367,  1.2641,  1.3220,  1.2994,  1.2696,  1.2416,  1.2494,  1.2345,
          1.2345,  1.3004,  1.3117,  1.3135,  1.3289,  1.2867,  1.3156,  1.2983,
          1.2756,  1.2262,  2.5332,  2.5991,  2.7257,  2.6577,  2.4082,  2.5072,
          2.5525,  2.3982,  2.3982,  1.3235,  1.2989,  1.2669,  1.2919,  1.3239,
          1.2784,  1.3010,  1.2744,  1.2693,  1.3887,  1.4247,  1.4100,  1.3812,
          1.4037,  1.3955,  1.3954,  1.2748,  1.3123,  1.3215,  1.3179,  1.3075,
          1.2905,  1.2751,  1.3115,  1.3517,  1.2841,  1.2937],
        [ 1.2462,  1.2739,  1.2871,  1.2643,  1.2795,  1.2512,  1.2594,  1.2440,
          1.2440,  1.3098,  1.2777,  1.3229,  1.3257,  1.2960,  1.2846,  1.3076,
          1.2987,  1.1596,  1.2932,  1.3079,  1.3343,  1.3047,  1.2682,  1.2487,
          1.2846,  1.2564,  1.2564,  2.8722,  2.5704,  2.2941,  2.4161,  2.8669,
          2.3040,  2.8209,  2.3071,  2.2962,  1.3965,  1.4328,  1.4029,  1.3914,
          1.4117,  1.3983,  1.4017,  1.2463,  1.3338,  1.3762,  1.3131,  1.2119,
          1.2520,  1.3704,  1.2671,  1.4072,  1.2456,  1.3029],
        [ 1.7943,  1.4478,  0.6639,  0.8824,  1.2503,  1.6766,  1.6090,  1.7919,
          1.7919,  1.6809,  1.3887,  1.4993,  1.0138,  1.7859,  0.3301,  1.6653,
          1.8072,  1.2612,  1.3917,  0.9436,  0.8249,  1.1691,  1.6505,  1.7291,
          1.4173,  1.8022,  1.8022,  0.7777,  0.9030,  1.7754,  1.5517,  0.8692,
          1.7072,  1.1829,  1.8266,  1.7486,  0.5005,  0.2823,  0.2567,  0.4567,
          0.7109,  0.8600,  0.4030, 10.0183,  7.3170,  0.8535,  1.3245,  1.4233,
          1.6685,  1.1023,  1.6192,  0.4932,  1.7228,  1.8418],
        [ 1.3136,  1.3412,  1.3993,  1.3773,  1.3475,  1.3186,  1.2819,  1.3114,
          1.3114,  1.2819,  1.3860,  1.2941,  1.4050,  1.3625,  1.4464,  1.2798,
          1.3657,  1.2922,  1.3604,  1.3882,  1.4016,  1.3712,  1.3355,  1.3266,
          1.2808,  1.3237,  1.3237,  1.3672,  1.4157,  1.3429,  1.1662,  1.3184,
          1.2154,  1.3766,  1.2162,  1.3454,  1.4615,  1.1781,  1.4826,  1.4692,
          1.0707,  0.9814,  1.4682,  1.4388,  0.8738,  2.9891,  2.4886,  3.1039,
          2.7179,  2.1380,  1.8618,  2.8067,  2.9225,  1.8473]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 175 : 181.9530667505615
Test loss for epoch 175 : 181.997570985136
Test Precision for epoch 175 : 0.26153846153846155
Test Recall for epoch 175 : 0.26153846153846155
Test F1 for epoch 175 : 0.26153846153846155


theta for epoch 176 : tensor([[ 2.4715,  2.4962,  2.5613,  2.6560,  2.6229,  2.4757,  2.6046,  2.4696,
          2.4696,  1.2933,  1.3044,  1.3063,  1.3221,  1.2796,  1.3640,  1.2912,
          1.2828,  1.2579,  1.2764,  1.2596,  1.2730,  1.2878,  1.2515,  1.2433,
          1.2683,  1.2398,  1.2398,  1.2841,  1.3326,  1.2594,  1.2845,  1.3300,
          1.2710,  1.2933,  1.2219,  1.2619,  1.3820,  1.4182,  1.4033,  1.3897,
          1.3972,  1.3374,  1.3887,  1.3624,  1.3207,  1.3591,  1.3108,  1.3003,
          1.2833,  1.3533,  1.3041,  1.3898,  1.2771,  1.2865],
        [ 1.3197,  1.2212,  1.0389,  1.2575,  1.3406,  1.3700,  1.2906,  1.3628,
          1.3628,  1.7053,  1.9541,  1.6984,  2.4814,  1.7495,  4.8288,  1.8083,
          1.6373,  4.5929,  1.1584,  1.2306,  1.0219,  1.2056,  1.3424,  1.3776,
          1.3518,  1.3749,  1.3749,  1.3305,  1.0832,  1.3939,  1.3707,  1.1671,
          1.4055,  1.4228,  1.3569,  1.3822,  1.4350,  1.5466,  1.4785,  1.4097,
          1.4075,  1.5138,  1.4645,  0.6152,  1.4460,  1.0621,  1.4436,  1.4316,
          1.4164,  1.0958,  1.4353,  0.8995,  1.4101,  1.4200],
        [ 1.2364,  1.2638,  1.3217,  1.2992,  1.2693,  1.2414,  1.2491,  1.2343,
          1.2343,  1.3002,  1.3115,  1.3132,  1.3287,  1.2865,  1.3154,  1.2980,
          1.2752,  1.2261,  2.5368,  2.6030,  2.7300,  2.6616,  2.4116,  2.5109,
          2.5564,  2.4015,  2.4015,  1.3232,  1.2987,  1.2666,  1.2917,  1.3236,
          1.2781,  1.3008,  1.2742,  1.2690,  1.3886,  1.4247,  1.4099,  1.3809,
          1.4037,  1.3955,  1.3953,  1.2746,  1.3120,  1.3213,  1.3177,  1.3072,
          1.2902,  1.2750,  1.3113,  1.3515,  1.2838,  1.2934],
        [ 1.2458,  1.2735,  1.2877,  1.2650,  1.2791,  1.2508,  1.2590,  1.2436,
          1.2436,  1.3094,  1.2782,  1.3225,  1.3257,  1.2956,  1.2843,  1.3072,
          1.2983,  1.1608,  1.2929,  1.3079,  1.3339,  1.3043,  1.2678,  1.2486,
          1.2842,  1.2560,  1.2560,  2.8746,  2.5757,  2.2984,  2.4209,  2.8693,
          2.3083,  2.8234,  2.3114,  2.3005,  1.3963,  1.4327,  1.4031,  1.3916,
          1.4116,  1.3983,  1.4015,  1.2476,  1.3335,  1.3758,  1.3131,  1.2118,
          1.2516,  1.3700,  1.2680,  1.4068,  1.2452,  1.3025],
        [ 1.7949,  1.4484,  0.6642,  0.8826,  1.2509,  1.6773,  1.6096,  1.7925,
          1.7925,  1.6815,  1.3884,  1.4999,  1.0141,  1.7865,  0.3308,  1.6659,
          1.8079,  1.2604,  1.3923,  0.9442,  0.8255,  1.1698,  1.6512,  1.7294,
          1.4182,  1.8029,  1.8029,  0.7779,  0.9037,  1.7760,  1.5526,  0.8693,
          1.7078,  1.1828,  1.8273,  1.7490,  0.4986,  0.2804,  0.2551,  0.4549,
          0.7085,  0.8573,  0.4011, 10.0594,  7.3236,  0.8542,  1.3249,  1.4240,
          1.6690,  1.1029,  1.6189,  0.4937,  1.7237,  1.8424],
        [ 1.3134,  1.3409,  1.3990,  1.3770,  1.3473,  1.3183,  1.2816,  1.3112,
          1.3112,  1.2817,  1.3859,  1.2939,  1.4048,  1.3623,  1.4462,  1.2795,
          1.3654,  1.2921,  1.3602,  1.3880,  1.4014,  1.3710,  1.3353,  1.3264,
          1.2802,  1.3235,  1.3235,  1.3671,  1.4154,  1.3427,  1.1656,  1.3183,
          1.2152,  1.3765,  1.2159,  1.3452,  1.4614,  1.1777,  1.4825,  1.4691,
          1.0703,  0.9810,  1.4682,  1.4386,  0.8733,  2.9947,  2.4913,  3.1106,
          2.7216,  2.1398,  1.8632,  2.8106,  2.9282,  1.8487]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 176 : 181.9472991940806
Test loss for epoch 176 : 181.99239231619595
Test Precision for epoch 176 : 0.26153846153846155
Test Recall for epoch 176 : 0.26153846153846155
Test F1 for epoch 176 : 0.26153846153846155


theta for epoch 177 : tensor([[ 2.4750,  2.4997,  2.5648,  2.6599,  2.6269,  2.4792,  2.6086,  2.4731,
          2.4731,  1.2930,  1.3041,  1.3061,  1.3218,  1.2793,  1.3638,  1.2909,
          1.2825,  1.2577,  1.2761,  1.2593,  1.2727,  1.2875,  1.2513,  1.2430,
          1.2681,  1.2396,  1.2396,  1.2839,  1.3323,  1.2591,  1.2842,  1.3298,
          1.2707,  1.2932,  1.2216,  1.2616,  1.3818,  1.4181,  1.4032,  1.3896,
          1.3971,  1.3373,  1.3886,  1.3620,  1.3205,  1.3587,  1.3105,  1.2999,
          1.2830,  1.3531,  1.3038,  1.3895,  1.2767,  1.2862],
        [ 1.3195,  1.2211,  1.0389,  1.2574,  1.3408,  1.3698,  1.2905,  1.3627,
          1.3627,  1.7060,  1.9544,  1.6990,  2.4823,  1.7503,  4.8430,  1.8090,
          1.6380,  4.6078,  1.1583,  1.2306,  1.0222,  1.2056,  1.3423,  1.3775,
          1.3516,  1.3748,  1.3748,  1.3306,  1.0832,  1.3937,  1.3706,  1.1671,
          1.4054,  1.4228,  1.3568,  1.3823,  1.4354,  1.5467,  1.4785,  1.4097,
          1.4078,  1.5139,  1.4645,  0.6154,  1.4459,  1.0622,  1.4435,  1.4314,
          1.4163,  1.0958,  1.4352,  0.8999,  1.4099,  1.4199],
        [ 1.2362,  1.2636,  1.3214,  1.2989,  1.2690,  1.2411,  1.2489,  1.2340,
          1.2340,  1.3000,  1.3113,  1.3130,  1.3285,  1.2863,  1.3152,  1.2978,
          1.2749,  1.2261,  2.5403,  2.6070,  2.7342,  2.6655,  2.4150,  2.5145,
          2.5602,  2.4049,  2.4049,  1.3229,  1.2985,  1.2663,  1.2914,  1.3233,
          1.2779,  1.3007,  1.2739,  1.2688,  1.3885,  1.4247,  1.4098,  1.3807,
          1.4037,  1.3955,  1.3952,  1.2745,  1.3117,  1.3211,  1.3175,  1.3069,
          1.2900,  1.2749,  1.3110,  1.3513,  1.2835,  1.2932],
        [ 1.2454,  1.2731,  1.2883,  1.2656,  1.2787,  1.2504,  1.2586,  1.2432,
          1.2432,  1.3091,  1.2789,  1.3222,  1.3257,  1.2952,  1.2840,  1.3069,
          1.2979,  1.1620,  1.2925,  1.3079,  1.3335,  1.3040,  1.2674,  1.2485,
          1.2838,  1.2556,  1.2556,  2.8768,  2.5809,  2.3028,  2.4257,  2.8716,
          2.3127,  2.8259,  2.3156,  2.3049,  1.3961,  1.4326,  1.4032,  1.3917,
          1.4114,  1.3983,  1.4014,  1.2489,  1.3332,  1.3754,  1.3131,  1.2116,
          1.2512,  1.3696,  1.2688,  1.4064,  1.2447,  1.3022],
        [ 1.7955,  1.4490,  0.6644,  0.8828,  1.2514,  1.6779,  1.6102,  1.7931,
          1.7931,  1.6821,  1.3882,  1.5006,  1.0144,  1.7870,  0.3315,  1.6665,
          1.8086,  1.2596,  1.3929,  0.9448,  0.8261,  1.1704,  1.6518,  1.7297,
          1.4191,  1.8035,  1.8035,  0.7780,  0.9043,  1.7766,  1.5535,  0.8694,
          1.7084,  1.1826,  1.8279,  1.7494,  0.4968,  0.2786,  0.2535,  0.4531,
          0.7062,  0.8546,  0.3993, 10.1004,  7.3298,  0.8550,  1.3253,  1.4246,
          1.6696,  1.1034,  1.6185,  0.4943,  1.7246,  1.8430],
        [ 1.3131,  1.3407,  1.3988,  1.3768,  1.3471,  1.3181,  1.2814,  1.3110,
          1.3110,  1.2815,  1.3858,  1.2937,  1.4046,  1.3621,  1.4461,  1.2793,
          1.3652,  1.2919,  1.3600,  1.3878,  1.4012,  1.3708,  1.3351,  1.3262,
          1.2798,  1.3233,  1.3233,  1.3669,  1.4152,  1.3424,  1.1651,  1.3183,
          1.2150,  1.3763,  1.2156,  1.3449,  1.4613,  1.1772,  1.4824,  1.4690,
          1.0698,  0.9805,  1.4681,  1.4383,  0.8727,  3.0003,  2.4941,  3.1173,
          2.7252,  2.1416,  1.8647,  2.8144,  2.9339,  1.8502]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 177 : 181.94157939414112
Test loss for epoch 177 : 181.98726646417524
Test Precision for epoch 177 : 0.26153846153846155
Test Recall for epoch 177 : 0.26153846153846155
Test F1 for epoch 177 : 0.26153846153846155


theta for epoch 178 : tensor([[ 2.4785,  2.5032,  2.5683,  2.6639,  2.6309,  2.4827,  2.6125,  2.4766,
          2.4766,  1.2928,  1.3039,  1.3058,  1.3216,  1.2791,  1.3636,  1.2906,
          1.2822,  1.2574,  1.2759,  1.2590,  1.2724,  1.2872,  1.2510,  1.2427,
          1.2678,  1.2393,  1.2393,  1.2837,  1.3320,  1.2588,  1.2839,  1.3296,
          1.2703,  1.2930,  1.2213,  1.2613,  1.3817,  1.4181,  1.4030,  1.3894,
          1.3971,  1.3372,  1.3885,  1.3617,  1.3203,  1.3584,  1.3102,  1.2996,
          1.2828,  1.3528,  1.3035,  1.3892,  1.2764,  1.2860],
        [ 1.3194,  1.2210,  1.0390,  1.2574,  1.3409,  1.3697,  1.2904,  1.3625,
          1.3625,  1.7067,  1.9548,  1.6997,  2.4832,  1.7510,  4.8572,  1.8098,
          1.6387,  4.6227,  1.1582,  1.2305,  1.0224,  1.2055,  1.3422,  1.3774,
          1.3515,  1.3747,  1.3747,  1.3306,  1.0833,  1.3936,  1.3705,  1.1671,
          1.4052,  1.4229,  1.3566,  1.3824,  1.4358,  1.5468,  1.4784,  1.4098,
          1.4082,  1.5141,  1.4645,  0.6156,  1.4459,  1.0623,  1.4434,  1.4313,
          1.4161,  1.0958,  1.4351,  0.9003,  1.4098,  1.4197],
        [ 1.2359,  1.2633,  1.3212,  1.2986,  1.2688,  1.2408,  1.2486,  1.2337,
          1.2337,  1.2997,  1.3111,  1.3128,  1.3283,  1.2860,  1.3150,  1.2976,
          1.2745,  1.2261,  2.5438,  2.6110,  2.7384,  2.6694,  2.4183,  2.5182,
          2.5641,  2.4082,  2.4082,  1.3226,  1.2984,  1.2660,  1.2911,  1.3230,
          1.2776,  1.3005,  1.2736,  1.2685,  1.3884,  1.4247,  1.4096,  1.3805,
          1.4036,  1.3955,  1.3952,  1.2743,  1.3114,  1.3209,  1.3172,  1.3066,
          1.2897,  1.2748,  1.3107,  1.3511,  1.2832,  1.2929],
        [ 1.2450,  1.2727,  1.2889,  1.2662,  1.2783,  1.2500,  1.2582,  1.2429,
          1.2429,  1.3087,  1.2795,  1.3218,  1.3257,  1.2949,  1.2837,  1.3065,
          1.2976,  1.1633,  1.2922,  1.3079,  1.3332,  1.3036,  1.2671,  1.2485,
          1.2834,  1.2553,  1.2553,  2.8791,  2.5862,  2.3071,  2.4305,  2.8739,
          2.3170,  2.8282,  2.3199,  2.3092,  1.3958,  1.4325,  1.4034,  1.3918,
          1.4113,  1.3983,  1.4012,  1.2502,  1.3329,  1.3750,  1.3131,  1.2115,
          1.2508,  1.3692,  1.2697,  1.4060,  1.2443,  1.3018],
        [ 1.7961,  1.4496,  0.6647,  0.8830,  1.2519,  1.6785,  1.6109,  1.7937,
          1.7937,  1.6827,  1.3879,  1.5012,  1.0147,  1.7876,  0.3322,  1.6670,
          1.8094,  1.2588,  1.3935,  0.9454,  0.8266,  1.1710,  1.6524,  1.7300,
          1.4201,  1.8041,  1.8041,  0.7782,  0.9049,  1.7772,  1.5544,  0.8695,
          1.7089,  1.1824,  1.8285,  1.7498,  0.4950,  0.2767,  0.2520,  0.4513,
          0.7039,  0.8520,  0.3975, 10.1414,  7.3356,  0.8557,  1.3257,  1.4252,
          1.6702,  1.1040,  1.6181,  0.4949,  1.7254,  1.8435],
        [ 1.3129,  1.3404,  1.3985,  1.3766,  1.3468,  1.3178,  1.2811,  1.3107,
          1.3107,  1.2813,  1.3856,  1.2935,  1.4045,  1.3619,  1.4459,  1.2791,
          1.3650,  1.2917,  1.3598,  1.3876,  1.4010,  1.3707,  1.3349,  1.3260,
          1.2793,  1.3231,  1.3231,  1.3668,  1.4150,  1.3422,  1.1645,  1.3182,
          1.2148,  1.3762,  1.2153,  1.3447,  1.4612,  1.1768,  1.4823,  1.4689,
          1.0693,  0.9800,  1.4681,  1.4380,  0.8722,  3.0058,  2.4967,  3.1240,
          2.7289,  2.1434,  1.8661,  2.8181,  2.9396,  1.8516]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 178 : 181.93590835563367
Test loss for epoch 178 : 181.98219793386556
Test Precision for epoch 178 : 0.26153846153846155
Test Recall for epoch 178 : 0.26153846153846155
Test F1 for epoch 178 : 0.26153846153846155


theta for epoch 179 : tensor([[ 2.4819,  2.5066,  2.5717,  2.6678,  2.6348,  2.4861,  2.6165,  2.4801,
          2.4801,  1.2925,  1.3037,  1.3055,  1.3214,  1.2788,  1.3633,  1.2904,
          1.2819,  1.2572,  1.2756,  1.2587,  1.2721,  1.2870,  1.2507,  1.2425,
          1.2675,  1.2390,  1.2390,  1.2835,  1.3317,  1.2585,  1.2836,  1.3294,
          1.2700,  1.2928,  1.2210,  1.2610,  1.3816,  1.4181,  1.4029,  1.3893,
          1.3970,  1.3371,  1.3884,  1.3613,  1.3201,  1.3581,  1.3099,  1.2993,
          1.2825,  1.3525,  1.3032,  1.3889,  1.2761,  1.2857],
        [ 1.3193,  1.2209,  1.0391,  1.2574,  1.3410,  1.3695,  1.2903,  1.3624,
          1.3624,  1.7073,  1.9551,  1.7003,  2.4841,  1.7516,  4.8714,  1.8105,
          1.6393,  4.6376,  1.1581,  1.2305,  1.0227,  1.2054,  1.3421,  1.3773,
          1.3513,  1.3746,  1.3746,  1.3306,  1.0833,  1.3934,  1.3704,  1.1672,
          1.4051,  1.4229,  1.3564,  1.3825,  1.4361,  1.5469,  1.4784,  1.4099,
          1.4085,  1.5143,  1.4645,  0.6159,  1.4458,  1.0624,  1.4433,  1.4312,
          1.4160,  1.0958,  1.4350,  0.9007,  1.4096,  1.4196],
        [ 1.2356,  1.2630,  1.3209,  1.2984,  1.2685,  1.2405,  1.2483,  1.2334,
          1.2334,  1.2995,  1.3109,  1.3125,  1.3281,  1.2858,  1.3148,  1.2973,
          1.2741,  1.2260,  2.5473,  2.6149,  2.7426,  2.6732,  2.4216,  2.5217,
          2.5679,  2.4115,  2.4115,  1.3223,  1.2982,  1.2657,  1.2908,  1.3227,
          1.2773,  1.3003,  1.2733,  1.2682,  1.3883,  1.4247,  1.4096,  1.3802,
          1.4036,  1.3954,  1.3951,  1.2741,  1.3111,  1.3207,  1.3170,  1.3063,
          1.2894,  1.2748,  1.3105,  1.3509,  1.2829,  1.2926],
        [ 1.2447,  1.2723,  1.2895,  1.2669,  1.2779,  1.2496,  1.2578,  1.2425,
          1.2425,  1.3083,  1.2801,  1.3215,  1.3257,  1.2945,  1.2834,  1.3062,
          1.2972,  1.1645,  1.2918,  1.3078,  1.3328,  1.3033,  1.2667,  1.2484,
          1.2831,  1.2549,  1.2549,  2.8813,  2.5915,  2.3114,  2.4352,  2.8762,
          2.3213,  2.8305,  2.3241,  2.3135,  1.3956,  1.4323,  1.4035,  1.3919,
          1.4111,  1.3984,  1.4011,  1.2515,  1.3326,  1.3746,  1.3131,  1.2114,
          1.2505,  1.3689,  1.2705,  1.4056,  1.2439,  1.3014],
        [ 1.7966,  1.4502,  0.6650,  0.8832,  1.2524,  1.6791,  1.6115,  1.7943,
          1.7943,  1.6833,  1.3876,  1.5018,  1.0150,  1.7882,  0.3328,  1.6676,
          1.8101,  1.2580,  1.3941,  0.9459,  0.8271,  1.1716,  1.6530,  1.7303,
          1.4210,  1.8047,  1.8047,  0.7784,  0.9055,  1.7778,  1.5552,  0.8696,
          1.7095,  1.1823,  1.8291,  1.7502,  0.4933,  0.2749,  0.2504,  0.4496,
          0.7016,  0.8494,  0.3957, 10.1822,  7.3411,  0.8564,  1.3261,  1.4259,
          1.6708,  1.1045,  1.6178,  0.4954,  1.7263,  1.8441],
        [ 1.3127,  1.3402,  1.3983,  1.3764,  1.3466,  1.3176,  1.2809,  1.3105,
          1.3105,  1.2811,  1.3855,  1.2934,  1.4043,  1.3617,  1.4458,  1.2789,
          1.3648,  1.2916,  1.3596,  1.3874,  1.4008,  1.3705,  1.3347,  1.3258,
          1.2788,  1.3229,  1.3229,  1.3666,  1.4148,  1.3420,  1.1639,  1.3181,
          1.2146,  1.3761,  1.2150,  1.3445,  1.4611,  1.1764,  1.4822,  1.4689,
          1.0689,  0.9796,  1.4680,  1.4378,  0.8716,  3.0114,  2.4994,  3.1307,
          2.7324,  2.1452,  1.8675,  2.8219,  2.9452,  1.8530]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 179 : 181.93028308128746
Test loss for epoch 179 : 181.97717827940784
Test Precision for epoch 179 : 0.26153846153846155
Test Recall for epoch 179 : 0.26153846153846155
Test F1 for epoch 179 : 0.26153846153846155


theta for epoch 180 : tensor([[ 2.4853,  2.5100,  2.5752,  2.6717,  2.6387,  2.4895,  2.6204,  2.4835,
          2.4835,  1.2922,  1.3035,  1.3053,  1.3212,  1.2785,  1.3631,  1.2901,
          1.2817,  1.2570,  1.2753,  1.2584,  1.2718,  1.2867,  1.2505,  1.2422,
          1.2672,  1.2388,  1.2388,  1.2833,  1.3314,  1.2582,  1.2833,  1.3292,
          1.2697,  1.2927,  1.2207,  1.2607,  1.3814,  1.4180,  1.4028,  1.3892,
          1.3969,  1.3371,  1.3883,  1.3610,  1.3199,  1.3579,  1.3097,  1.2990,
          1.2822,  1.3522,  1.3030,  1.3886,  1.2758,  1.2854],
        [ 1.3191,  1.2209,  1.0392,  1.2573,  1.3411,  1.3694,  1.2901,  1.3623,
          1.3623,  1.7080,  1.9554,  1.7010,  2.4849,  1.7523,  4.8855,  1.8112,
          1.6399,  4.6525,  1.1581,  1.2305,  1.0230,  1.2054,  1.3420,  1.3772,
          1.3511,  1.3745,  1.3745,  1.3307,  1.0833,  1.3933,  1.3703,  1.1672,
          1.4049,  1.4230,  1.3563,  1.3826,  1.4365,  1.5470,  1.4784,  1.4100,
          1.4088,  1.5144,  1.4645,  0.6161,  1.4458,  1.0626,  1.4432,  1.4311,
          1.4159,  1.0958,  1.4349,  0.9012,  1.4094,  1.4195],
        [ 1.2353,  1.2627,  1.3206,  1.2981,  1.2682,  1.2403,  1.2480,  1.2332,
          1.2332,  1.2992,  1.3107,  1.3123,  1.3279,  1.2855,  1.3146,  1.2971,
          1.2738,  1.2260,  2.5507,  2.6188,  2.7467,  2.6770,  2.4249,  2.5253,
          2.5717,  2.4148,  2.4148,  1.3220,  1.2980,  1.2655,  1.2905,  1.3224,
          1.2770,  1.3002,  1.2731,  1.2679,  1.3882,  1.4247,  1.4095,  1.3800,
          1.4036,  1.3954,  1.3951,  1.2740,  1.3108,  1.3205,  1.3167,  1.3061,
          1.2892,  1.2747,  1.3102,  1.3508,  1.2827,  1.2924],
        [ 1.2443,  1.2719,  1.2901,  1.2675,  1.2776,  1.2492,  1.2574,  1.2421,
          1.2421,  1.3080,  1.2807,  1.3211,  1.3257,  1.2941,  1.2830,  1.3058,
          1.2968,  1.1657,  1.2914,  1.3078,  1.3325,  1.3029,  1.2663,  1.2483,
          1.2827,  1.2545,  1.2545,  2.8834,  2.5967,  2.3157,  2.4399,  2.8784,
          2.3256,  2.8328,  2.3283,  2.3178,  1.3954,  1.4322,  1.4037,  1.3920,
          1.4110,  1.3984,  1.4009,  1.2528,  1.3324,  1.3742,  1.3131,  1.2113,
          1.2501,  1.3685,  1.2713,  1.4052,  1.2435,  1.3010],
        [ 1.7972,  1.4508,  0.6652,  0.8835,  1.2529,  1.6797,  1.6121,  1.7948,
          1.7948,  1.6839,  1.3873,  1.5023,  1.0153,  1.7887,  0.3335,  1.6681,
          1.8107,  1.2571,  1.3947,  0.9465,  0.8276,  1.1722,  1.6536,  1.7306,
          1.4219,  1.8053,  1.8053,  0.7785,  0.9061,  1.7783,  1.5561,  0.8696,
          1.7100,  1.1821,  1.8297,  1.7506,  0.4915,  0.2731,  0.2489,  0.4478,
          0.6994,  0.8468,  0.3939, 10.2230,  7.3461,  0.8571,  1.3266,  1.4265,
          1.6713,  1.1050,  1.6174,  0.4960,  1.7271,  1.8447],
        [ 1.3125,  1.3400,  1.3981,  1.3761,  1.3464,  1.3174,  1.2807,  1.3103,
          1.3103,  1.2809,  1.3854,  1.2932,  1.4042,  1.3615,  1.4456,  1.2787,
          1.3646,  1.2914,  1.3594,  1.3872,  1.4006,  1.3703,  1.3345,  1.3256,
          1.2783,  1.3227,  1.3227,  1.3665,  1.4145,  1.3417,  1.1634,  1.3180,
          1.2145,  1.3760,  1.2148,  1.3442,  1.4611,  1.1759,  1.4822,  1.4688,
          1.0685,  0.9792,  1.4680,  1.4375,  0.8711,  3.0169,  2.5020,  3.1373,
          2.7360,  2.1469,  1.8689,  2.8256,  2.9508,  1.8544]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 180 : 181.9247024663552
Test loss for epoch 180 : 181.97221106941603
Test Precision for epoch 180 : 0.26153846153846155
Test Recall for epoch 180 : 0.26153846153846155
Test F1 for epoch 180 : 0.26153846153846155


theta for epoch 181 : tensor([[ 2.4888,  2.5135,  2.5786,  2.6756,  2.6426,  2.4929,  2.6242,  2.4869,
          2.4869,  1.2920,  1.3033,  1.3050,  1.3209,  1.2783,  1.3629,  1.2899,
          1.2814,  1.2567,  1.2751,  1.2582,  1.2715,  1.2864,  1.2502,  1.2419,
          1.2670,  1.2385,  1.2385,  1.2831,  1.3311,  1.2579,  1.2830,  1.3290,
          1.2694,  1.2925,  1.2204,  1.2604,  1.3813,  1.4180,  1.4027,  1.3891,
          1.3969,  1.3370,  1.3882,  1.3606,  1.3197,  1.3576,  1.3094,  1.2987,
          1.2819,  1.3519,  1.3027,  1.3883,  1.2755,  1.2851],
        [ 1.3190,  1.2208,  1.0393,  1.2573,  1.3412,  1.3693,  1.2900,  1.3621,
          1.3621,  1.7086,  1.9557,  1.7016,  2.4857,  1.7529,  4.8997,  1.8119,
          1.6406,  4.6673,  1.1580,  1.2305,  1.0233,  1.2053,  1.3419,  1.3771,
          1.3510,  1.3744,  1.3744,  1.3307,  1.0834,  1.3931,  1.3702,  1.1672,
          1.4048,  1.4230,  1.3561,  1.3826,  1.4369,  1.5471,  1.4784,  1.4101,
          1.4092,  1.5146,  1.4645,  0.6164,  1.4457,  1.0627,  1.4431,  1.4310,
          1.4157,  1.0958,  1.4348,  0.9016,  1.4093,  1.4194],
        [ 1.2351,  1.2625,  1.3203,  1.2978,  1.2680,  1.2400,  1.2478,  1.2329,
          1.2329,  1.2990,  1.3106,  1.3120,  1.3277,  1.2853,  1.3144,  1.2969,
          1.2734,  1.2260,  2.5541,  2.6227,  2.7508,  2.6808,  2.4282,  2.5288,
          2.5755,  2.4181,  2.4181,  1.3217,  1.2979,  1.2652,  1.2902,  1.3221,
          1.2767,  1.3000,  1.2728,  1.2677,  1.3881,  1.4247,  1.4094,  1.3798,
          1.4036,  1.3954,  1.3950,  1.2738,  1.3105,  1.3203,  1.3165,  1.3058,
          1.2889,  1.2747,  1.3100,  1.3506,  1.2824,  1.2921],
        [ 1.2439,  1.2715,  1.2907,  1.2681,  1.2772,  1.2489,  1.2571,  1.2417,
          1.2417,  1.3076,  1.2813,  1.3208,  1.3257,  1.2938,  1.2827,  1.3055,
          1.2965,  1.1669,  1.2911,  1.3078,  1.3321,  1.3026,  1.2660,  1.2482,
          1.2823,  1.2542,  1.2542,  2.8855,  2.6019,  2.3199,  2.4447,  2.8805,
          2.3299,  2.8351,  2.3325,  2.3220,  1.3952,  1.4321,  1.4038,  1.3921,
          1.4108,  1.3984,  1.4008,  1.2540,  1.3321,  1.3738,  1.3131,  1.2111,
          1.2497,  1.3681,  1.2722,  1.4049,  1.2431,  1.3007],
        [ 1.7978,  1.4514,  0.6655,  0.8837,  1.2534,  1.6803,  1.6127,  1.7954,
          1.7954,  1.6844,  1.3871,  1.5029,  1.0156,  1.7892,  0.3341,  1.6686,
          1.8114,  1.2563,  1.3953,  0.9471,  0.8282,  1.1727,  1.6543,  1.7309,
          1.4228,  1.8059,  1.8059,  0.7787,  0.9067,  1.7789,  1.5569,  0.8697,
          1.7105,  1.1820,  1.8303,  1.7509,  0.4898,  0.2714,  0.2474,  0.4461,
          0.6972,  0.8443,  0.3921, 10.2637,  7.3508,  0.8578,  1.3270,  1.4271,
          1.6719,  1.1055,  1.6171,  0.4965,  1.7280,  1.8452],
        [ 1.3122,  1.3398,  1.3978,  1.3759,  1.3462,  1.3172,  1.2805,  1.3101,
          1.3101,  1.2807,  1.3853,  1.2930,  1.4040,  1.3613,  1.4454,  1.2786,
          1.3644,  1.2913,  1.3592,  1.3870,  1.4005,  1.3701,  1.3343,  1.3254,
          1.2778,  1.3225,  1.3225,  1.3663,  1.4143,  1.3415,  1.1628,  1.3179,
          1.2143,  1.3759,  1.2145,  1.3440,  1.4610,  1.1755,  1.4821,  1.4688,
          1.0680,  0.9787,  1.4680,  1.4373,  0.8706,  3.0224,  2.5046,  3.1439,
          2.7394,  2.1486,  1.8703,  2.8293,  2.9564,  1.8557]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 181 : 181.91916506064996
Test loss for epoch 181 : 181.96728624686116
Test Precision for epoch 181 : 0.26153846153846155
Test Recall for epoch 181 : 0.26153846153846155
Test F1 for epoch 181 : 0.26153846153846155


theta for epoch 182 : tensor([[ 2.4921,  2.5168,  2.5820,  2.6795,  2.6465,  2.4963,  2.6281,  2.4902,
          2.4902,  1.2917,  1.3031,  1.3048,  1.3207,  1.2780,  1.3627,  1.2896,
          1.2811,  1.2565,  1.2748,  1.2579,  1.2713,  1.2862,  1.2499,  1.2417,
          1.2667,  1.2382,  1.2382,  1.2829,  1.3308,  1.2576,  1.2827,  1.3288,
          1.2691,  1.2923,  1.2201,  1.2601,  1.3812,  1.4180,  1.4025,  1.3890,
          1.3968,  1.3369,  1.3881,  1.3603,  1.3195,  1.3573,  1.3091,  1.2984,
          1.2816,  1.3517,  1.3024,  1.3881,  1.2752,  1.2848],
        [ 1.3188,  1.2207,  1.0394,  1.2572,  1.3414,  1.3691,  1.2899,  1.3620,
          1.3620,  1.7092,  1.9559,  1.7022,  2.4865,  1.7535,  4.9138,  1.8125,
          1.6412,  4.6820,  1.1579,  1.2304,  1.0236,  1.2052,  1.3418,  1.3771,
          1.3508,  1.3743,  1.3743,  1.3308,  1.0834,  1.3930,  1.3701,  1.1673,
          1.4046,  1.4231,  1.3560,  1.3827,  1.4373,  1.5472,  1.4784,  1.4103,
          1.4095,  1.5148,  1.4645,  0.6166,  1.4457,  1.0629,  1.4430,  1.4309,
          1.4156,  1.0958,  1.4347,  0.9020,  1.4091,  1.4192],
        [ 1.2348,  1.2622,  1.3201,  1.2976,  1.2677,  1.2397,  1.2475,  1.2326,
          1.2326,  1.2988,  1.3104,  1.3118,  1.3275,  1.2851,  1.3141,  1.2966,
          1.2731,  1.2260,  2.5575,  2.6265,  2.7549,  2.6845,  2.4314,  2.5323,
          2.5792,  2.4213,  2.4213,  1.3214,  1.2977,  1.2649,  1.2900,  1.3218,
          1.2765,  1.2999,  1.2725,  1.2674,  1.3880,  1.4247,  1.4093,  1.3796,
          1.4035,  1.3954,  1.3950,  1.2737,  1.3102,  1.3201,  1.3162,  1.3055,
          1.2887,  1.2746,  1.3098,  1.3504,  1.2821,  1.2919],
        [ 1.2435,  1.2711,  1.2913,  1.2687,  1.2768,  1.2485,  1.2567,  1.2413,
          1.2413,  1.3073,  1.2819,  1.3204,  1.3257,  1.2934,  1.2825,  1.3051,
          1.2961,  1.1680,  1.2907,  1.3077,  1.3318,  1.3022,  1.2656,  1.2482,
          1.2820,  1.2538,  1.2538,  2.8876,  2.6071,  2.3242,  2.4494,  2.8827,
          2.3341,  2.8372,  2.3367,  2.3263,  1.3950,  1.4320,  1.4039,  1.3922,
          1.4107,  1.3984,  1.4006,  1.2553,  1.3318,  1.3734,  1.3131,  1.2110,
          1.2494,  1.3678,  1.2730,  1.4045,  1.2427,  1.3003],
        [ 1.7983,  1.4520,  0.6657,  0.8839,  1.2539,  1.6808,  1.6132,  1.7960,
          1.7960,  1.6850,  1.3868,  1.5035,  1.0159,  1.7898,  0.3347,  1.6692,
          1.8121,  1.2555,  1.3958,  0.9477,  0.8287,  1.1733,  1.6549,  1.7312,
          1.4237,  1.8064,  1.8064,  0.7789,  0.9073,  1.7794,  1.5578,  0.8698,
          1.7111,  1.1818,  1.8309,  1.7513,  0.4881,  0.2696,  0.2459,  0.4444,
          0.6951,  0.8418,  0.3904, 10.3044,  7.3551,  0.8585,  1.3274,  1.4278,
          1.6725,  1.1060,  1.6167,  0.4970,  1.7288,  1.8458],
        [ 1.3120,  1.3396,  1.3976,  1.3757,  1.3460,  1.3170,  1.2802,  1.3098,
          1.3098,  1.2805,  1.3852,  1.2928,  1.4039,  1.3611,  1.4453,  1.2784,
          1.3642,  1.2911,  1.3591,  1.3868,  1.4003,  1.3699,  1.3341,  1.3252,
          1.2773,  1.3223,  1.3223,  1.3662,  1.4141,  1.3413,  1.1623,  1.3178,
          1.2141,  1.3758,  1.2142,  1.3438,  1.4609,  1.1751,  1.4820,  1.4687,
          1.0676,  0.9783,  1.4679,  1.4370,  0.8701,  3.0278,  2.5072,  3.1505,
          2.7429,  2.1503,  1.8717,  2.8329,  2.9619,  1.8571]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 182 : 181.91367018164553
Test loss for epoch 182 : 181.9624010766966
Test Precision for epoch 182 : 0.26153846153846155
Test Recall for epoch 182 : 0.26153846153846155
Test F1 for epoch 182 : 0.26153846153846155


theta for epoch 183 : tensor([[ 2.4955,  2.5202,  2.5853,  2.6833,  2.6503,  2.4996,  2.6319,  2.4936,
          2.4936,  1.2915,  1.3029,  1.3045,  1.3205,  1.2778,  1.3625,  1.2894,
          1.2809,  1.2563,  1.2746,  1.2576,  1.2710,  1.2859,  1.2497,  1.2414,
          1.2665,  1.2380,  1.2380,  1.2827,  1.3305,  1.2573,  1.2824,  1.3286,
          1.2688,  1.2922,  1.2198,  1.2598,  1.3811,  1.4179,  1.4024,  1.3889,
          1.3968,  1.3369,  1.3881,  1.3600,  1.3194,  1.3570,  1.3089,  1.2981,
          1.2814,  1.3514,  1.3022,  1.3878,  1.2749,  1.2846],
        [ 1.3187,  1.2207,  1.0395,  1.2572,  1.3415,  1.3690,  1.2898,  1.3619,
          1.3619,  1.7098,  1.9561,  1.7027,  2.4872,  1.7541,  4.9278,  1.8132,
          1.6418,  4.6968,  1.1579,  1.2304,  1.0239,  1.2052,  1.3417,  1.3770,
          1.3507,  1.3742,  1.3742,  1.3308,  1.0835,  1.3929,  1.3700,  1.1673,
          1.4045,  1.4231,  1.3558,  1.3828,  1.4377,  1.5473,  1.4784,  1.4104,
          1.4099,  1.5149,  1.4645,  0.6169,  1.4456,  1.0630,  1.4429,  1.4307,
          1.4155,  1.0958,  1.4347,  0.9025,  1.4089,  1.4191],
        [ 1.2345,  1.2619,  1.3198,  1.2973,  1.2675,  1.2395,  1.2473,  1.2324,
          1.2324,  1.2985,  1.3102,  1.3116,  1.3274,  1.2848,  1.3139,  1.2964,
          1.2727,  1.2260,  2.5608,  2.6304,  2.7590,  2.6882,  2.4346,  2.5358,
          2.5829,  2.4245,  2.4245,  1.3211,  1.2976,  1.2646,  1.2897,  1.3215,
          1.2762,  1.2997,  1.2722,  1.2671,  1.3879,  1.4247,  1.4092,  1.3793,
          1.4035,  1.3954,  1.3949,  1.2736,  1.3099,  1.3199,  1.3160,  1.3052,
          1.2884,  1.2746,  1.3095,  1.3503,  1.2818,  1.2916],
        [ 1.2431,  1.2708,  1.2919,  1.2693,  1.2764,  1.2481,  1.2563,  1.2409,
          1.2409,  1.3069,  1.2825,  1.3201,  1.3257,  1.2931,  1.2822,  1.3048,
          1.2958,  1.1692,  1.2904,  1.3077,  1.3314,  1.3019,  1.2653,  1.2481,
          1.2816,  1.2535,  1.2535,  2.8896,  2.6123,  2.3284,  2.4540,  2.8847,
          2.3383,  2.8394,  2.3409,  2.3305,  1.3947,  1.4319,  1.4041,  1.3923,
          1.4105,  1.3984,  1.4005,  1.2565,  1.3316,  1.3730,  1.3131,  1.2109,
          1.2490,  1.3674,  1.2738,  1.4041,  1.2424,  1.3000],
        [ 1.7989,  1.4525,  0.6660,  0.8841,  1.2544,  1.6814,  1.6138,  1.7965,
          1.7965,  1.6856,  1.3865,  1.5041,  1.0161,  1.7903,  0.3353,  1.6697,
          1.8128,  1.2547,  1.3964,  0.9482,  0.8291,  1.1739,  1.6554,  1.7315,
          1.4246,  1.8070,  1.8070,  0.7790,  0.9078,  1.7800,  1.5586,  0.8699,
          1.7116,  1.1817,  1.8315,  1.7517,  0.4865,  0.2679,  0.2445,  0.4428,
          0.6930,  0.8394,  0.3887, 10.3450,  7.3591,  0.8592,  1.3278,  1.4284,
          1.6730,  1.1065,  1.6164,  0.4975,  1.7296,  1.8463],
        [ 1.3118,  1.3394,  1.3974,  1.3755,  1.3458,  1.3168,  1.2800,  1.3096,
          1.3096,  1.2803,  1.3851,  1.2927,  1.4038,  1.3609,  1.4451,  1.2782,
          1.3640,  1.2910,  1.3589,  1.3866,  1.4001,  1.3698,  1.3339,  1.3251,
          1.2768,  1.3221,  1.3221,  1.3661,  1.4139,  1.3411,  1.1618,  1.3178,
          1.2139,  1.3757,  1.2140,  1.3436,  1.4608,  1.1747,  1.4820,  1.4686,
          1.0671,  0.9779,  1.4679,  1.4368,  0.8695,  3.0333,  2.5097,  3.1571,
          2.7463,  2.1520,  1.8730,  2.8365,  2.9674,  1.8584]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 183 : 181.90821492909896
Test loss for epoch 183 : 181.9575665258052
Test Precision for epoch 183 : 0.26153846153846155
Test Recall for epoch 183 : 0.26153846153846155
Test F1 for epoch 183 : 0.26153846153846155


theta for epoch 184 : tensor([[ 2.4988,  2.5235,  2.5887,  2.6871,  2.6541,  2.5030,  2.6357,  2.4969,
          2.4969,  1.2912,  1.3027,  1.3043,  1.3203,  1.2775,  1.3623,  1.2891,
          1.2806,  1.2560,  1.2743,  1.2574,  1.2707,  1.2857,  1.2494,  1.2412,
          1.2662,  1.2377,  1.2377,  1.2825,  1.3302,  1.2570,  1.2821,  1.3284,
          1.2686,  1.2920,  1.2195,  1.2595,  1.3809,  1.4179,  1.4023,  1.3887,
          1.3967,  1.3368,  1.3880,  1.3596,  1.3192,  1.3567,  1.3086,  1.2978,
          1.2811,  1.3511,  1.3019,  1.3875,  1.2746,  1.2843],
        [ 1.3186,  1.2206,  1.0396,  1.2572,  1.3416,  1.3689,  1.2896,  1.3617,
          1.3617,  1.7103,  1.9563,  1.7033,  2.4878,  1.7547,  4.9418,  1.8138,
          1.6423,  4.7115,  1.1578,  1.2304,  1.0242,  1.2051,  1.3416,  1.3769,
          1.3505,  1.3741,  1.3741,  1.3309,  1.0836,  1.3928,  1.3699,  1.1674,
          1.4044,  1.4232,  1.3557,  1.3829,  1.4381,  1.5474,  1.4784,  1.4105,
          1.4102,  1.5151,  1.4645,  0.6172,  1.4456,  1.0632,  1.4428,  1.4306,
          1.4154,  1.0958,  1.4346,  0.9029,  1.4088,  1.4190],
        [ 1.2343,  1.2617,  1.3195,  1.2970,  1.2672,  1.2392,  1.2470,  1.2321,
          1.2321,  1.2983,  1.3100,  1.3114,  1.3272,  1.2846,  1.3137,  1.2962,
          1.2723,  1.2260,  2.5641,  2.6342,  2.7630,  2.6918,  2.4378,  2.5392,
          2.5866,  2.4277,  2.4277,  1.3208,  1.2974,  1.2644,  1.2894,  1.3212,
          1.2759,  1.2996,  1.2720,  1.2669,  1.3878,  1.4247,  1.4091,  1.3791,
          1.4035,  1.3954,  1.3948,  1.2735,  1.3096,  1.3198,  1.3158,  1.3050,
          1.2882,  1.2746,  1.3093,  1.3501,  1.2815,  1.2914],
        [ 1.2428,  1.2704,  1.2925,  1.2699,  1.2761,  1.2477,  1.2560,  1.2406,
          1.2406,  1.3066,  1.2832,  1.3197,  1.3257,  1.2928,  1.2819,  1.3044,
          1.2954,  1.1704,  1.2901,  1.3077,  1.3311,  1.3016,  1.2649,  1.2480,
          1.2813,  1.2531,  1.2531,  2.8915,  2.6175,  2.3326,  2.4587,  2.8867,
          2.3426,  2.8415,  2.3451,  2.3347,  1.3945,  1.4317,  1.4042,  1.3924,
          1.4104,  1.3985,  1.4004,  1.2577,  1.3313,  1.3726,  1.3131,  1.2107,
          1.2487,  1.3670,  1.2746,  1.4038,  1.2420,  1.2996],
        [ 1.7994,  1.4531,  0.6662,  0.8843,  1.2549,  1.6820,  1.6144,  1.7970,
          1.7970,  1.6861,  1.3862,  1.5046,  1.0163,  1.7908,  0.3359,  1.6702,
          1.8135,  1.2538,  1.3969,  0.9487,  0.8296,  1.1744,  1.6560,  1.7317,
          1.4255,  1.8076,  1.8076,  0.7792,  0.9084,  1.7805,  1.5594,  0.8700,
          1.7121,  1.1816,  1.8321,  1.7520,  0.4848,  0.2662,  0.2431,  0.4411,
          0.6909,  0.8370,  0.3870, 10.3855,  7.3627,  0.8598,  1.3282,  1.4290,
          1.6735,  1.1070,  1.6160,  0.4980,  1.7305,  1.8469],
        [ 1.3116,  1.3391,  1.3972,  1.3753,  1.3456,  1.3166,  1.2798,  1.3094,
          1.3094,  1.2801,  1.3850,  1.2925,  1.4036,  1.3608,  1.4450,  1.2780,
          1.3639,  1.2908,  1.3587,  1.3864,  1.3999,  1.3696,  1.3337,  1.3249,
          1.2763,  1.3219,  1.3219,  1.3659,  1.4137,  1.3408,  1.1612,  1.3177,
          1.2137,  1.3756,  1.2137,  1.3433,  1.4608,  1.1743,  1.4819,  1.4686,
          1.0667,  0.9774,  1.4679,  1.4365,  0.8690,  3.0387,  2.5122,  3.1636,
          2.7497,  2.1537,  1.8744,  2.8400,  2.9729,  1.8598]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 184 : 181.90279976096073
Test loss for epoch 184 : 181.95276829511553
Test Precision for epoch 184 : 0.26153846153846155
Test Recall for epoch 184 : 0.26153846153846155
Test F1 for epoch 184 : 0.26153846153846155


theta for epoch 185 : tensor([[ 2.5021,  2.5268,  2.5920,  2.6909,  2.6579,  2.5063,  2.6395,  2.5002,
          2.5002,  1.2910,  1.3025,  1.3040,  1.3201,  1.2773,  1.3620,  1.2889,
          1.2804,  1.2558,  1.2741,  1.2571,  1.2704,  1.2855,  1.2492,  1.2409,
          1.2659,  1.2375,  1.2375,  1.2823,  1.3299,  1.2567,  1.2818,  1.3282,
          1.2683,  1.2918,  1.2192,  1.2592,  1.3808,  1.4178,  1.4022,  1.3886,
          1.3966,  1.3367,  1.3879,  1.3593,  1.3190,  1.3564,  1.3083,  1.2975,
          1.2809,  1.3509,  1.3017,  1.3872,  1.2743,  1.2840],
        [ 1.3185,  1.2205,  1.0397,  1.2572,  1.3418,  1.3688,  1.2895,  1.3616,
          1.3616,  1.7109,  1.9564,  1.7038,  2.4884,  1.7553,  4.9558,  1.8144,
          1.6429,  4.7261,  1.1578,  1.2304,  1.0245,  1.2051,  1.3415,  1.3768,
          1.3504,  1.3740,  1.3740,  1.3309,  1.0836,  1.3926,  1.3698,  1.1674,
          1.4043,  1.4233,  1.3555,  1.3829,  1.4385,  1.5475,  1.4783,  1.4106,
          1.4106,  1.5152,  1.4646,  0.6175,  1.4455,  1.0633,  1.4427,  1.4305,
          1.4152,  1.0959,  1.4345,  0.9034,  1.4086,  1.4189],
        [ 1.2340,  1.2614,  1.3193,  1.2968,  1.2670,  1.2389,  1.2468,  1.2319,
          1.2319,  1.2981,  1.3098,  1.3111,  1.3270,  1.2844,  1.3135,  1.2960,
          1.2720,  1.2260,  2.5674,  2.6380,  2.7670,  2.6955,  2.4410,  2.5427,
          2.5903,  2.4309,  2.4309,  1.3205,  1.2973,  1.2641,  1.2892,  1.3208,
          1.2757,  1.2994,  1.2717,  1.2666,  1.3877,  1.4247,  1.4090,  1.3788,
          1.4034,  1.3954,  1.3948,  1.2733,  1.3093,  1.3196,  1.3155,  1.3047,
          1.2880,  1.2745,  1.3091,  1.3500,  1.2813,  1.2912],
        [ 1.2424,  1.2701,  1.2931,  1.2705,  1.2757,  1.2474,  1.2556,  1.2402,
          1.2402,  1.3063,  1.2838,  1.3194,  1.3257,  1.2924,  1.2816,  1.3041,
          1.2951,  1.1715,  1.2897,  1.3076,  1.3308,  1.3012,  1.2646,  1.2479,
          1.2809,  1.2528,  1.2528,  2.8934,  2.6226,  2.3368,  2.4633,  2.8887,
          2.3467,  2.8435,  2.3492,  2.3389,  1.3943,  1.4316,  1.4043,  1.3924,
          1.4103,  1.3985,  1.4002,  1.2589,  1.3311,  1.3723,  1.3131,  1.2106,
          1.2483,  1.3667,  1.2754,  1.4034,  1.2416,  1.2993],
        [ 1.8000,  1.4537,  0.6664,  0.8845,  1.2553,  1.6825,  1.6149,  1.7976,
          1.7976,  1.6867,  1.3859,  1.5052,  1.0166,  1.7913,  0.3364,  1.6707,
          1.8142,  1.2530,  1.3974,  0.9493,  0.8301,  1.1749,  1.6566,  1.7320,
          1.4263,  1.8081,  1.8081,  0.7794,  0.9089,  1.7810,  1.5602,  0.8701,
          1.7126,  1.1814,  1.8326,  1.7524,  0.4832,  0.2646,  0.2416,  0.4395,
          0.6888,  0.8346,  0.3854, 10.4260,  7.3659,  0.8605,  1.3286,  1.4296,
          1.6741,  1.1074,  1.6157,  0.4984,  1.7313,  1.8474],
        [ 1.3114,  1.3389,  1.3970,  1.3751,  1.3454,  1.3164,  1.2796,  1.3092,
          1.3092,  1.2799,  1.3849,  1.2924,  1.4035,  1.3606,  1.4448,  1.2778,
          1.3637,  1.2907,  1.3585,  1.3862,  1.3998,  1.3694,  1.3335,  1.3247,
          1.2759,  1.3218,  1.3218,  1.3658,  1.4134,  1.3406,  1.1607,  1.3176,
          1.2136,  1.3755,  1.2135,  1.3431,  1.4607,  1.1739,  1.4818,  1.4685,
          1.0662,  0.9770,  1.4678,  1.4363,  0.8685,  3.0441,  2.5146,  3.1702,
          2.7531,  2.1553,  1.8757,  2.8436,  2.9784,  1.8611]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 185 : 181.89742184434874
Test loss for epoch 185 : 181.948018268852
Test Precision for epoch 185 : 0.26153846153846155
Test Recall for epoch 185 : 0.26153846153846155
Test F1 for epoch 185 : 0.26153846153846155


theta for epoch 186 : tensor([[ 2.5053,  2.5301,  2.5953,  2.6946,  2.6616,  2.5095,  2.6432,  2.5034,
          2.5034,  1.2907,  1.3023,  1.3038,  1.3199,  1.2770,  1.3618,  1.2886,
          1.2801,  1.2556,  1.2738,  1.2568,  1.2702,  1.2852,  1.2489,  1.2407,
          1.2657,  1.2372,  1.2372,  1.2821,  1.3297,  1.2564,  1.2816,  1.3280,
          1.2680,  1.2917,  1.2189,  1.2589,  1.3807,  1.4178,  1.4021,  1.3885,
          1.3966,  1.3366,  1.3878,  1.3590,  1.3189,  1.3561,  1.3081,  1.2973,
          1.2806,  1.3506,  1.3015,  1.3870,  1.2740,  1.2838],
        [ 1.3183,  1.2205,  1.0399,  1.2571,  1.3419,  1.3686,  1.2894,  1.3615,
          1.3615,  1.7115,  1.9565,  1.7044,  2.4890,  1.7559,  4.9698,  1.8150,
          1.6435,  4.7407,  1.1577,  1.2304,  1.0248,  1.2050,  1.3415,  1.3767,
          1.3502,  1.3739,  1.3739,  1.3310,  1.0837,  1.3925,  1.3697,  1.1675,
          1.4041,  1.4233,  1.3554,  1.3830,  1.4389,  1.5476,  1.4783,  1.4107,
          1.4110,  1.5154,  1.4646,  0.6178,  1.4454,  1.0635,  1.4426,  1.4304,
          1.4151,  1.0959,  1.4344,  0.9039,  1.4085,  1.4188],
        [ 1.2338,  1.2612,  1.3190,  1.2965,  1.2667,  1.2387,  1.2465,  1.2316,
          1.2316,  1.2979,  1.3096,  1.3109,  1.3268,  1.2842,  1.3133,  1.2958,
          1.2716,  1.2261,  2.5707,  2.6417,  2.7710,  2.6990,  2.4442,  2.5460,
          2.5940,  2.4340,  2.4340,  1.3202,  1.2972,  1.2639,  1.2889,  1.3205,
          1.2754,  1.2993,  1.2715,  1.2663,  1.3876,  1.4247,  1.4089,  1.3786,
          1.4034,  1.3953,  1.3947,  1.2732,  1.3090,  1.3194,  1.3153,  1.3044,
          1.2877,  1.2745,  1.3088,  1.3498,  1.2810,  1.2909],
        [ 1.2420,  1.2697,  1.2937,  1.2711,  1.2754,  1.2470,  1.2552,  1.2398,
          1.2398,  1.3059,  1.2844,  1.3191,  1.3257,  1.2921,  1.2813,  1.3038,
          1.2948,  1.1726,  1.2894,  1.3076,  1.3305,  1.3009,  1.2643,  1.2478,
          1.2806,  1.2525,  1.2525,  2.8953,  2.6278,  2.3410,  2.4680,  2.8906,
          2.3509,  2.8455,  2.3533,  2.3431,  1.3941,  1.4315,  1.4045,  1.3925,
          1.4101,  1.3985,  1.4001,  1.2601,  1.3309,  1.3719,  1.3130,  1.2104,
          1.2480,  1.3663,  1.2762,  1.4030,  1.2412,  1.2989],
        [ 1.8005,  1.4542,  0.6666,  0.8847,  1.2558,  1.6831,  1.6155,  1.7981,
          1.7981,  1.6872,  1.3856,  1.5057,  1.0168,  1.7918,  0.3370,  1.6712,
          1.8149,  1.2521,  1.3980,  0.9498,  0.8305,  1.1754,  1.6571,  1.7323,
          1.4272,  1.8087,  1.8087,  0.7795,  0.9094,  1.7816,  1.5610,  0.8702,
          1.7131,  1.1813,  1.8332,  1.7527,  0.4816,  0.2629,  0.2402,  0.4379,
          0.6868,  0.8323,  0.3837, 10.4663,  7.3687,  0.8611,  1.3290,  1.4302,
          1.6746,  1.1079,  1.6154,  0.4989,  1.7321,  1.8479],
        [ 1.3112,  1.3387,  1.3968,  1.3749,  1.3451,  1.3161,  1.2794,  1.3090,
          1.3090,  1.2798,  1.3847,  1.2922,  1.4034,  1.3604,  1.4447,  1.2776,
          1.3635,  1.2905,  1.3583,  1.3861,  1.3996,  1.3693,  1.3333,  1.3245,
          1.2754,  1.3216,  1.3216,  1.3657,  1.4132,  1.3404,  1.1602,  1.3175,
          1.2134,  1.3755,  1.2133,  1.3429,  1.4606,  1.1735,  1.4817,  1.4685,
          1.0658,  0.9766,  1.4678,  1.4360,  0.8680,  3.0495,  2.5171,  3.1767,
          2.7564,  2.1569,  1.8770,  2.8471,  2.9838,  1.8624]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 186 : 181.8920811217423
Test loss for epoch 186 : 181.9433011624847
Test Precision for epoch 186 : 0.26153846153846155
Test Recall for epoch 186 : 0.26153846153846155
Test F1 for epoch 186 : 0.26153846153846155


theta for epoch 187 : tensor([[ 2.5086,  2.5334,  2.5986,  2.6983,  2.6654,  2.5128,  2.6469,  2.5067,
          2.5067,  1.2905,  1.3021,  1.3036,  1.3197,  1.2768,  1.3616,  1.2884,
          1.2799,  1.2554,  1.2736,  1.2566,  1.2699,  1.2850,  1.2487,  1.2405,
          1.2654,  1.2370,  1.2370,  1.2819,  1.3294,  1.2562,  1.2813,  1.3278,
          1.2677,  1.2915,  1.2186,  1.2586,  1.3806,  1.4178,  1.4020,  1.3884,
          1.3965,  1.3366,  1.3877,  1.3586,  1.3187,  1.3558,  1.3078,  1.2970,
          1.2803,  1.3503,  1.3012,  1.3867,  1.2737,  1.2835],
        [ 1.3182,  1.2204,  1.0400,  1.2571,  1.3420,  1.3685,  1.2893,  1.3614,
          1.3614,  1.7120,  1.9566,  1.7049,  2.4895,  1.7564,  4.9837,  1.8155,
          1.6440,  4.7553,  1.1577,  1.2304,  1.0251,  1.2050,  1.3414,  1.3767,
          1.3501,  1.3738,  1.3738,  1.3310,  1.0838,  1.3924,  1.3696,  1.1675,
          1.4040,  1.4234,  1.3552,  1.3831,  1.4393,  1.5477,  1.4783,  1.4109,
          1.4114,  1.5156,  1.4646,  0.6182,  1.4454,  1.0637,  1.4425,  1.4303,
          1.4150,  1.0959,  1.4344,  0.9044,  1.4083,  1.4187],
        [ 1.2335,  1.2609,  1.3187,  1.2963,  1.2665,  1.2384,  1.2463,  1.2314,
          1.2314,  1.2976,  1.3095,  1.3107,  1.3266,  1.2839,  1.3131,  1.2955,
          1.2712,  1.2261,  2.5739,  2.6455,  2.7749,  2.7026,  2.4473,  2.5494,
          2.5976,  2.4372,  2.4372,  1.3199,  1.2970,  1.2636,  1.2886,  1.3202,
          1.2751,  1.2991,  1.2712,  1.2661,  1.3875,  1.4247,  1.4089,  1.3784,
          1.4034,  1.3953,  1.3947,  1.2731,  1.3087,  1.3192,  1.3150,  1.3042,
          1.2875,  1.2745,  1.3086,  1.3497,  1.2807,  1.2907],
        [ 1.2417,  1.2693,  1.2943,  1.2717,  1.2750,  1.2467,  1.2549,  1.2395,
          1.2395,  1.3056,  1.2850,  1.3188,  1.3256,  1.2918,  1.2811,  1.3035,
          1.2944,  1.1737,  1.2891,  1.3075,  1.3301,  1.3006,  1.2639,  1.2477,
          1.2803,  1.2521,  1.2521,  2.8971,  2.6329,  2.3452,  2.4726,  2.8925,
          2.3551,  2.8474,  2.3574,  2.3473,  1.3939,  1.4314,  1.4046,  1.3926,
          1.4100,  1.3985,  1.4000,  1.2613,  1.3306,  1.3715,  1.3130,  1.2103,
          1.2477,  1.3660,  1.2770,  1.4027,  1.2409,  1.2986],
        [ 1.8010,  1.4548,  0.6668,  0.8849,  1.2563,  1.6836,  1.6160,  1.7986,
          1.7986,  1.6878,  1.3853,  1.5062,  1.0170,  1.7923,  0.3375,  1.6717,
          1.8155,  1.2513,  1.3985,  0.9504,  0.8310,  1.1760,  1.6577,  1.7326,
          1.4281,  1.8092,  1.8092,  0.7797,  0.9099,  1.7821,  1.5618,  0.8703,
          1.7136,  1.1812,  1.8338,  1.7531,  0.4801,  0.2613,  0.2389,  0.4363,
          0.6848,  0.8300,  0.3821, 10.5067,  7.3712,  0.8617,  1.3294,  1.4309,
          1.6751,  1.1083,  1.6150,  0.4993,  1.7329,  1.8484],
        [ 1.3110,  1.3385,  1.3966,  1.3747,  1.3450,  1.3160,  1.2792,  1.3088,
          1.3088,  1.2796,  1.3846,  1.2920,  1.4032,  1.3602,  1.4446,  1.2775,
          1.3633,  1.2904,  1.3582,  1.3859,  1.3994,  1.3691,  1.3332,  1.3244,
          1.2749,  1.3214,  1.3214,  1.3655,  1.4130,  1.3402,  1.1596,  1.3175,
          1.2132,  1.3754,  1.2130,  1.3427,  1.4606,  1.1731,  1.4817,  1.4684,
          1.0654,  0.9762,  1.4678,  1.4358,  0.8676,  3.0549,  2.5195,  3.1831,
          2.7597,  2.1586,  1.8783,  2.8505,  2.9892,  1.8636]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 187 : 181.88677506698912
Test loss for epoch 187 : 181.9386210461111
Test Precision for epoch 187 : 0.26153846153846155
Test Recall for epoch 187 : 0.26153846153846155
Test F1 for epoch 187 : 0.26153846153846155


theta for epoch 188 : tensor([[ 2.5118,  2.5366,  2.6018,  2.7020,  2.6690,  2.5160,  2.6506,  2.5099,
          2.5099,  1.2903,  1.3019,  1.3033,  1.3196,  1.2766,  1.3614,  1.2882,
          1.2796,  1.2552,  1.2734,  1.2563,  1.2697,  1.2848,  1.2484,  1.2402,
          1.2652,  1.2367,  1.2367,  1.2817,  1.3291,  1.2559,  1.2810,  1.3276,
          1.2674,  1.2914,  1.2183,  1.2584,  1.3805,  1.4177,  1.4019,  1.3883,
          1.3965,  1.3365,  1.3877,  1.3583,  1.3186,  1.3555,  1.3076,  1.2967,
          1.2801,  1.3501,  1.3010,  1.3864,  1.2734,  1.2833],
        [ 1.3181,  1.2203,  1.0401,  1.2571,  1.3422,  1.3684,  1.2892,  1.3612,
          1.3612,  1.7125,  1.9567,  1.7054,  2.4900,  1.7569,  4.9976,  1.8161,
          1.6446,  4.7698,  1.1576,  1.2304,  1.0255,  1.2050,  1.3413,  1.3766,
          1.3500,  1.3737,  1.3737,  1.3311,  1.0839,  1.3922,  1.3696,  1.1676,
          1.4039,  1.4234,  1.3551,  1.3832,  1.4397,  1.5478,  1.4783,  1.4110,
          1.4117,  1.5157,  1.4646,  0.6185,  1.4453,  1.0639,  1.4424,  1.4302,
          1.4149,  1.0960,  1.4343,  0.9049,  1.4081,  1.4185],
        [ 1.2333,  1.2607,  1.3185,  1.2960,  1.2662,  1.2382,  1.2460,  1.2311,
          1.2311,  1.2974,  1.3093,  1.3105,  1.3265,  1.2837,  1.3129,  1.2953,
          1.2709,  1.2262,  2.5771,  2.6492,  2.7789,  2.7061,  2.4504,  2.5527,
          2.6012,  2.4403,  2.4403,  1.3195,  1.2969,  1.2633,  1.2884,  1.3199,
          1.2749,  1.2990,  1.2710,  1.2658,  1.3874,  1.4246,  1.4088,  1.3781,
          1.4033,  1.3953,  1.3946,  1.2731,  1.3084,  1.3191,  1.3148,  1.3039,
          1.2873,  1.2745,  1.3084,  1.3495,  1.2804,  1.2905],
        [ 1.2413,  1.2690,  1.2948,  1.2723,  1.2747,  1.2463,  1.2545,  1.2391,
          1.2391,  1.3053,  1.2856,  1.3185,  1.3256,  1.2915,  1.2808,  1.3031,
          1.2941,  1.1748,  1.2888,  1.3075,  1.3298,  1.3003,  1.2636,  1.2477,
          1.2799,  1.2518,  1.2518,  2.8989,  2.6380,  2.3493,  2.4772,  2.8943,
          2.3592,  2.8494,  2.3615,  2.3514,  1.3937,  1.4313,  1.4047,  1.3927,
          1.4099,  1.3985,  1.3998,  1.2624,  1.3304,  1.3712,  1.3130,  1.2102,
          1.2473,  1.3657,  1.2777,  1.4023,  1.2405,  1.2982],
        [ 1.8015,  1.4553,  0.6671,  0.8850,  1.2567,  1.6842,  1.6166,  1.7992,
          1.7992,  1.6883,  1.3850,  1.5068,  1.0173,  1.7928,  0.3380,  1.6722,
          1.8162,  1.2504,  1.3990,  0.9509,  0.8314,  1.1765,  1.6582,  1.7328,
          1.4289,  1.8098,  1.8098,  0.7799,  0.9103,  1.7826,  1.5626,  0.8704,
          1.7141,  1.1811,  1.8343,  1.7534,  0.4785,  0.2597,  0.2375,  0.4348,
          0.6829,  0.8277,  0.3805, 10.5470,  7.3733,  0.8623,  1.3298,  1.4315,
          1.6757,  1.1087,  1.6147,  0.4997,  1.7337,  1.8489],
        [ 1.3108,  1.3383,  1.3964,  1.3745,  1.3447,  1.3158,  1.2790,  1.3086,
          1.3086,  1.2794,  1.3845,  1.2919,  1.4031,  1.3601,  1.4444,  1.2773,
          1.3631,  1.2903,  1.3580,  1.3857,  1.3993,  1.3690,  1.3330,  1.3242,
          1.2745,  1.3212,  1.3212,  1.3654,  1.4128,  1.3400,  1.1591,  1.3174,
          1.2131,  1.3753,  1.2128,  1.3425,  1.4605,  1.1727,  1.4816,  1.4684,
          1.0650,  0.9758,  1.4678,  1.4355,  0.8671,  3.0602,  2.5219,  3.1896,
          2.7629,  2.1601,  1.8795,  2.8539,  2.9946,  1.8649]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 188 : 181.8815032297052
Test loss for epoch 188 : 181.93397792401205
Test Precision for epoch 188 : 0.26153846153846155
Test Recall for epoch 188 : 0.26153846153846155
Test F1 for epoch 188 : 0.26153846153846155


theta for epoch 189 : tensor([[ 2.5150,  2.5398,  2.6050,  2.7057,  2.6727,  2.5192,  2.6543,  2.5131,
          2.5131,  1.2900,  1.3017,  1.3031,  1.3194,  1.2763,  1.3612,  1.2879,
          1.2794,  1.2550,  1.2731,  1.2561,  1.2694,  1.2845,  1.2482,  1.2400,
          1.2649,  1.2365,  1.2365,  1.2815,  1.3288,  1.2556,  1.2807,  1.3275,
          1.2672,  1.2912,  1.2181,  1.2581,  1.3803,  1.4177,  1.4017,  1.3882,
          1.3964,  1.3364,  1.3876,  1.3580,  1.3184,  1.3553,  1.3073,  1.2964,
          1.2798,  1.3498,  1.3007,  1.3862,  1.2731,  1.2830],
        [ 1.3180,  1.2203,  1.0403,  1.2571,  1.3423,  1.3683,  1.2891,  1.3611,
          1.3611,  1.7130,  1.9568,  1.7059,  2.4904,  1.7575,  5.0114,  1.8166,
          1.6451,  4.7842,  1.1576,  1.2304,  1.0258,  1.2049,  1.3412,  1.3765,
          1.3498,  1.3736,  1.3736,  1.3312,  1.0840,  1.3921,  1.3695,  1.1677,
          1.4037,  1.4235,  1.3549,  1.3833,  1.4401,  1.5479,  1.4783,  1.4112,
          1.4121,  1.5159,  1.4646,  0.6189,  1.4453,  1.0641,  1.4424,  1.4300,
          1.4147,  1.0960,  1.4342,  0.9054,  1.4080,  1.4184],
        [ 1.2330,  1.2604,  1.3182,  1.2958,  1.2660,  1.2380,  1.2458,  1.2309,
          1.2309,  1.2972,  1.3091,  1.3103,  1.3263,  1.2835,  1.3127,  1.2951,
          1.2705,  1.2262,  2.5803,  2.6529,  2.7828,  2.7096,  2.4535,  2.5560,
          2.6048,  2.4433,  2.4433,  1.3192,  1.2968,  1.2631,  1.2881,  1.3196,
          1.2746,  1.2988,  1.2707,  1.2656,  1.3873,  1.4246,  1.4087,  1.3779,
          1.4033,  1.3953,  1.3946,  1.2730,  1.3081,  1.3189,  1.3146,  1.3036,
          1.2870,  1.2745,  1.3082,  1.3494,  1.2802,  1.2902],
        [ 1.2410,  1.2686,  1.2954,  1.2729,  1.2744,  1.2460,  1.2542,  1.2388,
          1.2388,  1.3050,  1.2862,  1.3181,  1.3256,  1.2911,  1.2805,  1.3028,
          1.2938,  1.1759,  1.2885,  1.3074,  1.3295,  1.3000,  1.2633,  1.2476,
          1.2796,  1.2515,  1.2515,  2.9007,  2.6431,  2.3534,  2.4817,  2.8961,
          2.3633,  2.8512,  2.3655,  2.3555,  1.3935,  1.4312,  1.4048,  1.3928,
          1.4097,  1.3985,  1.3997,  1.2636,  1.3302,  1.3708,  1.3130,  1.2100,
          1.2470,  1.3653,  1.2785,  1.4020,  1.2401,  1.2979],
        [ 1.8021,  1.4558,  0.6673,  0.8852,  1.2571,  1.6847,  1.6171,  1.7997,
          1.7997,  1.6888,  1.3847,  1.5073,  1.0175,  1.7933,  0.3386,  1.6726,
          1.8169,  1.2496,  1.3994,  0.9514,  0.8318,  1.1769,  1.6588,  1.7331,
          1.4298,  1.8103,  1.8103,  0.7801,  0.9108,  1.7831,  1.5634,  0.8706,
          1.7146,  1.1810,  1.8348,  1.7538,  0.4770,  0.2581,  0.2362,  0.4332,
          0.6809,  0.8255,  0.3790, 10.5872,  7.3750,  0.8628,  1.3302,  1.4321,
          1.6762,  1.1091,  1.6144,  0.5001,  1.7344,  1.8494],
        [ 1.3106,  1.3381,  1.3962,  1.3743,  1.3446,  1.3156,  1.2788,  1.3084,
          1.3084,  1.2792,  1.3845,  1.2917,  1.4030,  1.3599,  1.4443,  1.2771,
          1.3630,  1.2901,  1.3578,  1.3855,  1.3991,  1.3688,  1.3328,  1.3241,
          1.2740,  1.3211,  1.3211,  1.3653,  1.4126,  1.3398,  1.1586,  1.3173,
          1.2129,  1.3752,  1.2125,  1.3423,  1.4604,  1.1723,  1.4815,  1.4683,
          1.0645,  0.9754,  1.4677,  1.4353,  0.8666,  3.0655,  2.5242,  3.1960,
          2.7662,  2.1617,  1.8808,  2.8573,  2.9999,  1.8661]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 189 : 181.87626490606453
Test loss for epoch 189 : 181.92937064951798
Test Precision for epoch 189 : 0.26153846153846155
Test Recall for epoch 189 : 0.26153846153846155
Test F1 for epoch 189 : 0.26153846153846155


theta for epoch 190 : tensor([[ 2.5181,  2.5430,  2.6082,  2.7093,  2.6764,  2.5224,  2.6579,  2.5163,
          2.5163,  1.2898,  1.3015,  1.3029,  1.3192,  1.2761,  1.3610,  1.2877,
          1.2792,  1.2548,  1.2729,  1.2558,  1.2692,  1.2843,  1.2480,  1.2398,
          1.2647,  1.2363,  1.2363,  1.2814,  1.3286,  1.2554,  1.2805,  1.3273,
          1.2669,  1.2911,  1.2178,  1.2579,  1.3802,  1.4177,  1.4016,  1.3881,
          1.3963,  1.3364,  1.3875,  1.3577,  1.3182,  1.3550,  1.3071,  1.2961,
          1.2796,  1.3496,  1.3005,  1.3859,  1.2728,  1.2828],
        [ 1.3179,  1.2202,  1.0404,  1.2571,  1.3424,  1.3681,  1.2890,  1.3610,
          1.3610,  1.7135,  1.9568,  1.7063,  2.4908,  1.7580,  5.0252,  1.8171,
          1.6456,  4.7986,  1.1575,  1.2304,  1.0262,  1.2049,  1.3411,  1.3764,
          1.3497,  1.3735,  1.3735,  1.3312,  1.0842,  1.3920,  1.3694,  1.1677,
          1.4036,  1.4235,  1.3548,  1.3834,  1.4405,  1.5480,  1.4783,  1.4113,
          1.4125,  1.5160,  1.4646,  0.6193,  1.4452,  1.0643,  1.4423,  1.4299,
          1.4146,  1.0961,  1.4342,  0.9059,  1.4078,  1.4183],
        [ 1.2328,  1.2602,  1.3179,  1.2955,  1.2657,  1.2377,  1.2455,  1.2306,
          1.2306,  1.2970,  1.3089,  1.3101,  1.3261,  1.2833,  1.3125,  1.2949,
          1.2701,  1.2263,  2.5835,  2.6566,  2.7866,  2.7130,  2.4565,  2.5593,
          2.6084,  2.4464,  2.4464,  1.3189,  1.2967,  1.2628,  1.2879,  1.3193,
          1.2744,  1.2987,  1.2705,  1.2653,  1.3872,  1.4246,  1.4086,  1.3776,
          1.4033,  1.3953,  1.3945,  1.2729,  1.3078,  1.3188,  1.3144,  1.3034,
          1.2868,  1.2745,  1.3079,  1.3493,  1.2799,  1.2900],
        [ 1.2406,  1.2683,  1.2959,  1.2734,  1.2740,  1.2456,  1.2538,  1.2384,
          1.2384,  1.3047,  1.2868,  1.3178,  1.3256,  1.2908,  1.2803,  1.3025,
          1.2935,  1.1770,  1.2882,  1.3074,  1.3292,  1.2997,  1.2630,  1.2475,
          1.2793,  1.2512,  1.2512,  2.9024,  2.6481,  2.3575,  2.4863,  2.8979,
          2.3674,  2.8530,  2.3696,  2.3596,  1.3933,  1.4311,  1.4050,  1.3929,
          1.4096,  1.3985,  1.3996,  1.2647,  1.3299,  1.3705,  1.3129,  1.2099,
          1.2467,  1.3650,  1.2793,  1.4017,  1.2398,  1.2976],
        [ 1.8026,  1.4563,  0.6674,  0.8854,  1.2576,  1.6852,  1.6176,  1.8002,
          1.8002,  1.6894,  1.3845,  1.5078,  1.0177,  1.7938,  0.3390,  1.6731,
          1.8176,  1.2487,  1.3999,  0.9519,  0.8322,  1.1774,  1.6593,  1.7333,
          1.4306,  1.8109,  1.8109,  0.7802,  0.9112,  1.7836,  1.5642,  0.8707,
          1.7151,  1.1809,  1.8354,  1.7541,  0.4755,  0.2566,  0.2348,  0.4317,
          0.6791,  0.8233,  0.3774, 10.6274,  7.3764,  0.8634,  1.3305,  1.4327,
          1.6767,  1.1095,  1.6141,  0.5005,  1.7352,  1.8499],
        [ 1.3104,  1.3379,  1.3960,  1.3741,  1.3444,  1.3154,  1.2786,  1.3082,
          1.3082,  1.2791,  1.3844,  1.2916,  1.4029,  1.3597,  1.4442,  1.2770,
          1.3628,  1.2900,  1.3577,  1.3853,  1.3990,  1.3686,  1.3327,  1.3239,
          1.2735,  1.3209,  1.3209,  1.3651,  1.4124,  1.3396,  1.1581,  1.3172,
          1.2128,  1.3751,  1.2123,  1.3421,  1.4603,  1.1719,  1.4815,  1.4683,
          1.0641,  0.9750,  1.4677,  1.4351,  0.8661,  3.0708,  2.5265,  3.2024,
          2.7693,  2.1633,  1.8820,  2.8606,  3.0053,  1.8674]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 190 : 181.87105779434367
Test loss for epoch 190 : 181.92479150937783
Test Precision for epoch 190 : 0.26153846153846155
Test Recall for epoch 190 : 0.26153846153846155
Test F1 for epoch 190 : 0.26153846153846155


theta for epoch 191 : tensor([[ 2.5213,  2.5461,  2.6114,  2.7130,  2.6800,  2.5255,  2.6616,  2.5194,
          2.5194,  1.2896,  1.3014,  1.3026,  1.3190,  1.2759,  1.3608,  1.2875,
          1.2789,  1.2546,  1.2726,  1.2556,  1.2689,  1.2841,  1.2477,  1.2395,
          1.2645,  1.2360,  1.2360,  1.2812,  1.3283,  1.2551,  1.2802,  1.3271,
          1.2666,  1.2909,  1.2175,  1.2576,  1.3801,  1.4176,  1.4015,  1.3880,
          1.3963,  1.3363,  1.3874,  1.3573,  1.3181,  1.3547,  1.3068,  1.2958,
          1.2793,  1.3493,  1.3003,  1.3857,  1.2725,  1.2825],
        [ 1.3178,  1.2202,  1.0406,  1.2571,  1.3426,  1.3680,  1.2889,  1.3609,
          1.3609,  1.7140,  1.9568,  1.7068,  2.4912,  1.7585,  5.0389,  1.8176,
          1.6461,  4.8130,  1.1575,  1.2305,  1.0265,  1.2049,  1.3411,  1.3763,
          1.3495,  1.3734,  1.3734,  1.3313,  1.0843,  1.3919,  1.3693,  1.1678,
          1.4035,  1.4236,  1.3546,  1.3834,  1.4409,  1.5481,  1.4783,  1.4115,
          1.4129,  1.5162,  1.4646,  0.6196,  1.4452,  1.0645,  1.4422,  1.4298,
          1.4145,  1.0961,  1.4341,  0.9064,  1.4077,  1.4182],
        [ 1.2325,  1.2599,  1.3177,  1.2953,  1.2655,  1.2375,  1.2453,  1.2304,
          1.2304,  1.2968,  1.3088,  1.3099,  1.3260,  1.2831,  1.3123,  1.2947,
          1.2698,  1.2263,  2.5866,  2.6603,  2.7905,  2.7164,  2.4596,  2.5625,
          2.6119,  2.4494,  2.4494,  1.3186,  1.2965,  1.2626,  1.2876,  1.3189,
          1.2741,  1.2985,  1.2702,  1.2651,  1.3871,  1.4246,  1.4085,  1.3774,
          1.4032,  1.3953,  1.3945,  1.2728,  1.3075,  1.3186,  1.3141,  1.3031,
          1.2866,  1.2745,  1.3077,  1.3492,  1.2796,  1.2898],
        [ 1.2403,  1.2680,  1.2965,  1.2740,  1.2737,  1.2453,  1.2535,  1.2381,
          1.2381,  1.3043,  1.2874,  1.3175,  1.3256,  1.2905,  1.2800,  1.3022,
          1.2931,  1.1780,  1.2879,  1.3073,  1.3289,  1.2994,  1.2627,  1.2474,
          1.2790,  1.2509,  1.2509,  2.9040,  2.6532,  2.3616,  2.4908,  2.8996,
          2.3715,  2.8548,  2.3736,  2.3637,  1.3932,  1.4310,  1.4051,  1.3929,
          1.4095,  1.3985,  1.3995,  1.2658,  1.3297,  1.3701,  1.3129,  1.2097,
          1.2464,  1.3647,  1.2800,  1.4013,  1.2394,  1.2973],
        [ 1.8031,  1.4569,  0.6676,  0.8856,  1.2580,  1.6857,  1.6181,  1.8007,
          1.8007,  1.6899,  1.3842,  1.5083,  1.0179,  1.7943,  0.3395,  1.6735,
          1.8182,  1.2479,  1.4004,  0.9525,  0.8326,  1.1779,  1.6598,  1.7336,
          1.4315,  1.8114,  1.8114,  0.7804,  0.9117,  1.7841,  1.5649,  0.8708,
          1.7156,  1.1808,  1.8359,  1.7544,  0.4741,  0.2550,  0.2335,  0.4302,
          0.6772,  0.8211,  0.3759, 10.6675,  7.3775,  0.8639,  1.3309,  1.4333,
          1.6772,  1.1098,  1.6138,  0.5008,  1.7360,  1.8504],
        [ 1.3102,  1.3378,  1.3958,  1.3740,  1.3442,  1.3152,  1.2784,  1.3080,
          1.3080,  1.2789,  1.3843,  1.2915,  1.4028,  1.3596,  1.4441,  1.2768,
          1.3626,  1.2899,  1.3575,  1.3852,  1.3988,  1.3685,  1.3325,  1.3237,
          1.2731,  1.3207,  1.3207,  1.3650,  1.4122,  1.3394,  1.1576,  1.3171,
          1.2126,  1.3750,  1.2121,  1.3419,  1.4603,  1.1716,  1.4814,  1.4682,
          1.0637,  0.9746,  1.4677,  1.4348,  0.8656,  3.0761,  2.5288,  3.2088,
          2.7725,  2.1648,  1.8832,  2.8639,  3.0105,  1.8686]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 191 : 181.86588098710405
Test loss for epoch 191 : 181.92025334363643
Test Precision for epoch 191 : 0.26153846153846155
Test Recall for epoch 191 : 0.26153846153846155
Test F1 for epoch 191 : 0.26153846153846155


theta for epoch 192 : tensor([[ 2.5244,  2.5492,  2.6145,  2.7165,  2.6836,  2.5286,  2.6651,  2.5225,
          2.5225,  1.2894,  1.3012,  1.3024,  1.3188,  1.2757,  1.3607,  1.2873,
          1.2787,  1.2544,  1.2724,  1.2553,  1.2687,  1.2839,  1.2475,  1.2393,
          1.2642,  1.2358,  1.2358,  1.2810,  1.3281,  1.2549,  1.2799,  1.3269,
          1.2664,  1.2908,  1.2173,  1.2573,  1.3800,  1.4176,  1.4014,  1.3879,
          1.3962,  1.3363,  1.3874,  1.3570,  1.3180,  1.3545,  1.3066,  1.2956,
          1.2791,  1.3491,  1.3000,  1.3854,  1.2723,  1.2823],
        [ 1.3176,  1.2201,  1.0407,  1.2571,  1.3427,  1.3679,  1.2888,  1.3607,
          1.3607,  1.7145,  1.9568,  1.7072,  2.4915,  1.7590,  5.0526,  1.8181,
          1.6466,  4.8273,  1.1575,  1.2305,  1.0269,  1.2048,  1.3410,  1.3763,
          1.3494,  1.3733,  1.3733,  1.3314,  1.0844,  1.3917,  1.3692,  1.1678,
          1.4034,  1.4236,  1.3545,  1.3835,  1.4413,  1.5482,  1.4783,  1.4116,
          1.4133,  1.5163,  1.4646,  0.6200,  1.4451,  1.0648,  1.4421,  1.4297,
          1.4144,  1.0962,  1.4340,  0.9070,  1.4075,  1.4181],
        [ 1.2323,  1.2597,  1.3174,  1.2950,  1.2653,  1.2372,  1.2451,  1.2301,
          1.2301,  1.2966,  1.3086,  1.3097,  1.3258,  1.2829,  1.3121,  1.2945,
          1.2694,  1.2264,  2.5897,  2.6639,  2.7943,  2.7198,  2.4626,  2.5658,
          2.6155,  2.4525,  2.4525,  1.3183,  1.2964,  1.2624,  1.2874,  1.3186,
          1.2739,  1.2984,  1.2700,  1.2648,  1.3871,  1.4246,  1.4084,  1.3771,
          1.4032,  1.3953,  1.3944,  1.2728,  1.3072,  1.3185,  1.3139,  1.3029,
          1.2864,  1.2745,  1.3075,  1.3490,  1.2794,  1.2896],
        [ 1.2399,  1.2676,  1.2970,  1.2745,  1.2734,  1.2449,  1.2532,  1.2378,
          1.2378,  1.3040,  1.2879,  1.3172,  1.3256,  1.2902,  1.2798,  1.3019,
          1.2928,  1.1790,  1.2876,  1.3073,  1.3286,  1.2991,  1.2624,  1.2473,
          1.2787,  1.2506,  1.2506,  2.9057,  2.6582,  2.3656,  2.4953,  2.9013,
          2.3756,  2.8566,  2.3776,  2.3678,  1.3930,  1.4309,  1.4052,  1.3930,
          1.4093,  1.3985,  1.3993,  1.2668,  1.3295,  1.3698,  1.3129,  1.2096,
          1.2461,  1.3644,  1.2807,  1.4010,  1.2391,  1.2969],
        [ 1.8035,  1.4574,  0.6678,  0.8858,  1.2584,  1.6862,  1.6186,  1.8012,
          1.8012,  1.6904,  1.3839,  1.5088,  1.0180,  1.7947,  0.3400,  1.6740,
          1.8189,  1.2470,  1.4008,  0.9530,  0.8329,  1.1783,  1.6604,  1.7338,
          1.4323,  1.8119,  1.8119,  0.7806,  0.9121,  1.7846,  1.5657,  0.8709,
          1.7160,  1.1807,  1.8364,  1.7547,  0.4726,  0.2535,  0.2322,  0.4288,
          0.6754,  0.8190,  0.3744, 10.7076,  7.3781,  0.8645,  1.3313,  1.4339,
          1.6777,  1.1102,  1.6135,  0.5012,  1.7368,  1.8509],
        [ 1.3100,  1.3376,  1.3956,  1.3738,  1.3440,  1.3150,  1.2782,  1.3078,
          1.3078,  1.2787,  1.3842,  1.2913,  1.4026,  1.3594,  1.4439,  1.2767,
          1.3624,  1.2898,  1.3574,  1.3850,  1.3986,  1.3683,  1.3323,  1.3236,
          1.2726,  1.3205,  1.3205,  1.3649,  1.4120,  1.3392,  1.1571,  1.3170,
          1.2124,  1.3749,  1.2119,  1.3417,  1.4602,  1.1712,  1.4814,  1.4682,
          1.0633,  0.9742,  1.4677,  1.4346,  0.8652,  3.0814,  2.5311,  3.2152,
          2.7756,  2.1663,  1.8844,  2.8672,  3.0158,  1.8698]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 192 : 181.8607338080295
Test loss for epoch 192 : 181.91573203056433
Test Precision for epoch 192 : 0.26153846153846155
Test Recall for epoch 192 : 0.26153846153846155
Test F1 for epoch 192 : 0.26153846153846155


theta for epoch 193 : tensor([[ 2.5275,  2.5524,  2.6177,  2.7201,  2.6872,  2.5318,  2.6687,  2.5257,
          2.5257,  1.2891,  1.3010,  1.3022,  1.3186,  1.2754,  1.3604,  1.2870,
          1.2785,  1.2542,  1.2722,  1.2551,  1.2684,  1.2836,  1.2473,  1.2391,
          1.2640,  1.2355,  1.2355,  1.2808,  1.3278,  1.2546,  1.2797,  1.3267,
          1.2661,  1.2906,  1.2170,  1.2571,  1.3799,  1.4176,  1.4013,  1.3878,
          1.3962,  1.3362,  1.3873,  1.3567,  1.3178,  1.3542,  1.3064,  1.2953,
          1.2788,  1.3488,  1.2998,  1.3852,  1.2720,  1.2820],
        [ 1.3175,  1.2201,  1.0409,  1.2571,  1.3429,  1.3678,  1.2887,  1.3607,
          1.3607,  1.7150,  1.9568,  1.7077,  2.4917,  1.7594,  5.0663,  1.8185,
          1.6471,  4.8416,  1.1574,  1.2305,  1.0273,  1.2048,  1.3409,  1.3762,
          1.3492,  1.3732,  1.3732,  1.3314,  1.0846,  1.3916,  1.3692,  1.1679,
          1.4032,  1.4237,  1.3544,  1.3836,  1.4417,  1.5483,  1.4783,  1.4118,
          1.4138,  1.5165,  1.4647,  0.6205,  1.4451,  1.0650,  1.4420,  1.4296,
          1.4142,  1.0962,  1.4339,  0.9075,  1.4073,  1.4180],
        [ 1.2321,  1.2595,  1.3172,  1.2948,  1.2650,  1.2370,  1.2449,  1.2299,
          1.2299,  1.2964,  1.3085,  1.3095,  1.3257,  1.2827,  1.3119,  1.2943,
          1.2690,  1.2265,  2.5927,  2.6675,  2.7981,  2.7231,  2.4656,  2.5689,
          2.6190,  2.4554,  2.4554,  1.3179,  1.2963,  1.2621,  1.2871,  1.3183,
          1.2736,  1.2982,  1.2697,  1.2646,  1.3870,  1.4246,  1.4083,  1.3768,
          1.4032,  1.3952,  1.3944,  1.2727,  1.3069,  1.3183,  1.3137,  1.3026,
          1.2861,  1.2745,  1.3073,  1.3489,  1.2791,  1.2893],
        [ 1.2396,  1.2673,  1.2975,  1.2750,  1.2731,  1.2446,  1.2529,  1.2375,
          1.2375,  1.3037,  1.2885,  1.3169,  1.3256,  1.2899,  1.2795,  1.3016,
          1.2925,  1.1800,  1.2873,  1.3072,  1.3283,  1.2988,  1.2621,  1.2472,
          1.2784,  1.2503,  1.2503,  2.9073,  2.6632,  2.3697,  2.4998,  2.9029,
          2.3796,  2.8583,  2.3816,  2.3718,  1.3928,  1.4308,  1.4053,  1.3931,
          1.4092,  1.3985,  1.3992,  1.2679,  1.3293,  1.3694,  1.3128,  1.2094,
          1.2458,  1.3640,  1.2814,  1.4007,  1.2387,  1.2966],
        [ 1.8040,  1.4579,  0.6680,  0.8860,  1.2588,  1.6867,  1.6191,  1.8017,
          1.8017,  1.6909,  1.3836,  1.5092,  1.0182,  1.7952,  0.3404,  1.6744,
          1.8195,  1.2461,  1.4013,  0.9535,  0.8333,  1.1788,  1.6609,  1.7341,
          1.4331,  1.8124,  1.8124,  0.7808,  0.9125,  1.7851,  1.5664,  0.8711,
          1.7165,  1.1806,  1.8369,  1.7550,  0.4712,  0.2520,  0.2310,  0.4273,
          0.6736,  0.8169,  0.3729, 10.7477,  7.3785,  0.8650,  1.3317,  1.4344,
          1.6781,  1.1106,  1.6132,  0.5015,  1.7375,  1.8514],
        [ 1.3098,  1.3374,  1.3955,  1.3736,  1.3438,  1.3148,  1.2780,  1.3077,
          1.3077,  1.2786,  1.3841,  1.2912,  1.4025,  1.3592,  1.4438,  1.2765,
          1.3623,  1.2896,  1.3572,  1.3848,  1.3985,  1.3682,  1.3322,  1.3234,
          1.2722,  1.3204,  1.3204,  1.3648,  1.4118,  1.3390,  1.1566,  1.3169,
          1.2123,  1.3748,  1.2117,  1.3415,  1.4601,  1.1708,  1.4813,  1.4682,
          1.0629,  0.9738,  1.4676,  1.4344,  0.8647,  3.0866,  2.5333,  3.2215,
          2.7787,  2.1678,  1.8856,  2.8705,  3.0210,  1.8709]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 193 : 181.85561543480566
Test loss for epoch 193 : 181.91125554327832
Test Precision for epoch 193 : 0.26153846153846155
Test Recall for epoch 193 : 0.26153846153846155
Test F1 for epoch 193 : 0.26153846153846155


theta for epoch 194 : tensor([[ 2.5306,  2.5554,  2.6207,  2.7236,  2.6907,  2.5348,  2.6722,  2.5287,
          2.5287,  1.2889,  1.3009,  1.3020,  1.3185,  1.2752,  1.3603,  1.2869,
          1.2782,  1.2541,  1.2720,  1.2549,  1.2682,  1.2834,  1.2470,  1.2389,
          1.2638,  1.2353,  1.2353,  1.2806,  1.3275,  1.2543,  1.2794,  1.3266,
          1.2659,  1.2905,  1.2167,  1.2568,  1.3798,  1.4175,  1.4012,  1.3878,
          1.3961,  1.3362,  1.3872,  1.3564,  1.3177,  1.3540,  1.3062,  1.2951,
          1.2786,  1.3486,  1.2996,  1.3850,  1.2717,  1.2818],
        [ 1.3174,  1.2200,  1.0411,  1.2571,  1.3430,  1.3677,  1.2886,  1.3605,
          1.3605,  1.7155,  1.9568,  1.7081,  2.4920,  1.7599,  5.0799,  1.8190,
          1.6476,  4.8558,  1.1574,  1.2305,  1.0277,  1.2048,  1.3409,  1.3761,
          1.3491,  1.3731,  1.3731,  1.3315,  1.0847,  1.3915,  1.3691,  1.1679,
          1.4031,  1.4237,  1.3542,  1.3837,  1.4421,  1.5483,  1.4783,  1.4119,
          1.4142,  1.5166,  1.4647,  0.6209,  1.4450,  1.0652,  1.4419,  1.4295,
          1.4141,  1.0963,  1.4339,  0.9081,  1.4072,  1.4179],
        [ 1.2318,  1.2592,  1.3169,  1.2946,  1.2648,  1.2367,  1.2446,  1.2296,
          1.2296,  1.2962,  1.3083,  1.3093,  1.3255,  1.2825,  1.3118,  1.2941,
          1.2686,  1.2266,  2.5958,  2.6712,  2.8018,  2.7264,  2.4686,  2.5721,
          2.6225,  2.4584,  2.4584,  1.3176,  1.2962,  1.2619,  1.2869,  1.3180,
          1.2734,  1.2981,  1.2695,  1.2644,  1.3869,  1.4246,  1.4083,  1.3766,
          1.4031,  1.3952,  1.3943,  1.2727,  1.3066,  1.3182,  1.3135,  1.3024,
          1.2859,  1.2746,  1.3071,  1.3488,  1.2789,  1.2891],
        [ 1.2393,  1.2669,  1.2980,  1.2755,  1.2727,  1.2443,  1.2525,  1.2371,
          1.2371,  1.3034,  1.2891,  1.3166,  1.3256,  1.2896,  1.2793,  1.3014,
          1.2922,  1.1810,  1.2870,  1.3071,  1.3280,  1.2985,  1.2618,  1.2471,
          1.2781,  1.2500,  1.2500,  2.9088,  2.6682,  2.3737,  2.5042,  2.9046,
          2.3836,  2.8600,  2.3855,  2.3758,  1.3926,  1.4307,  1.4054,  1.3931,
          1.4091,  1.3985,  1.3991,  1.2689,  1.3291,  1.3691,  1.3128,  1.2093,
          1.2455,  1.3637,  1.2821,  1.4004,  1.2384,  1.2963],
        [ 1.8045,  1.4583,  0.6682,  0.8861,  1.2592,  1.6872,  1.6196,  1.8021,
          1.8021,  1.6914,  1.3833,  1.5097,  1.0184,  1.7956,  0.3408,  1.6748,
          1.8202,  1.2453,  1.4017,  0.9540,  0.8336,  1.1792,  1.6614,  1.7343,
          1.4340,  1.8129,  1.8129,  0.7810,  0.9129,  1.7856,  1.5671,  0.8712,
          1.7170,  1.1805,  1.8374,  1.7553,  0.4698,  0.2505,  0.2297,  0.4258,
          0.6718,  0.8148,  0.3714, 10.7877,  7.3784,  0.8655,  1.3321,  1.4350,
          1.6786,  1.1109,  1.6130,  0.5018,  1.7382,  1.8519],
        [ 1.3096,  1.3372,  1.3952,  1.3734,  1.3436,  1.3146,  1.2778,  1.3074,
          1.3074,  1.2784,  1.3840,  1.2910,  1.4024,  1.3591,  1.4437,  1.2763,
          1.3621,  1.2895,  1.3571,  1.3847,  1.3983,  1.3681,  1.3320,  1.3233,
          1.2717,  1.3202,  1.3202,  1.3646,  1.4116,  1.3388,  1.1561,  1.3169,
          1.2121,  1.3747,  1.2114,  1.3413,  1.4601,  1.1704,  1.4812,  1.4681,
          1.0625,  0.9734,  1.4676,  1.4341,  0.8643,  3.0918,  2.5356,  3.2278,
          2.7817,  2.1693,  1.8868,  2.8737,  3.0263,  1.8721]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 194 : 181.8505233176513
Test loss for epoch 194 : 181.90678425502003
Test Precision for epoch 194 : 0.26153846153846155
Test Recall for epoch 194 : 0.26153846153846155
Test F1 for epoch 194 : 0.26153846153846155


theta for epoch 195 : tensor([[ 2.5337,  2.5586,  2.6238,  2.7272,  2.6943,  2.5379,  2.6758,  2.5318,
          2.5318,  1.2887,  1.3007,  1.3018,  1.3183,  1.2750,  1.3601,  1.2866,
          1.2780,  1.2538,  1.2717,  1.2546,  1.2680,  1.2832,  1.2468,  1.2386,
          1.2635,  1.2351,  1.2351,  1.2804,  1.3273,  1.2541,  1.2791,  1.3264,
          1.2656,  1.2903,  1.2164,  1.2566,  1.3796,  1.4175,  1.4011,  1.3877,
          1.3960,  1.3361,  1.3871,  1.3561,  1.3175,  1.3537,  1.3059,  1.2947,
          1.2783,  1.3483,  1.2993,  1.3847,  1.2714,  1.2816],
        [ 1.3173,  1.2200,  1.0413,  1.2571,  1.3431,  1.3676,  1.2885,  1.3604,
          1.3604,  1.7159,  1.9567,  1.7085,  2.4921,  1.7603,  5.0934,  1.8194,
          1.6481,  4.8699,  1.1574,  1.2306,  1.0281,  1.2048,  1.3408,  1.3760,
          1.3489,  1.3730,  1.3730,  1.3316,  1.0849,  1.3914,  1.3690,  1.1680,
          1.4030,  1.4238,  1.3541,  1.3838,  1.4426,  1.5484,  1.4783,  1.4121,
          1.4146,  1.5167,  1.4647,  0.6213,  1.4450,  1.0655,  1.4418,  1.4293,
          1.4140,  1.0964,  1.4338,  0.9087,  1.4070,  1.4177],
        [ 1.2316,  1.2590,  1.3167,  1.2944,  1.2646,  1.2365,  1.2444,  1.2294,
          1.2294,  1.2960,  1.3081,  1.3091,  1.3253,  1.2823,  1.3116,  1.2939,
          1.2683,  1.2267,  2.5988,  2.6747,  2.8056,  2.7297,  2.4715,  2.5752,
          2.6259,  2.4614,  2.4614,  1.3173,  1.2961,  1.2616,  1.2866,  1.3176,
          1.2731,  1.2980,  1.2693,  1.2641,  1.3868,  1.4246,  1.4082,  1.3763,
          1.4031,  1.3952,  1.3943,  1.2726,  1.3062,  1.3181,  1.3132,  1.3021,
          1.2857,  1.2746,  1.3068,  1.3487,  1.2786,  1.2889],
        [ 1.2390,  1.2667,  1.2985,  1.2760,  1.2724,  1.2440,  1.2522,  1.2368,
          1.2368,  1.3032,  1.2896,  1.3164,  1.3255,  1.2894,  1.2791,  1.3011,
          1.2919,  1.1819,  1.2867,  1.3071,  1.3277,  1.2982,  1.2615,  1.2471,
          1.2778,  1.2497,  1.2497,  2.9104,  2.6731,  2.3777,  2.5087,  2.9061,
          2.3876,  2.8616,  2.3895,  2.3798,  1.3924,  1.4306,  1.4055,  1.3932,
          1.4090,  1.3985,  1.3990,  1.2699,  1.3289,  1.3688,  1.3127,  1.2091,
          1.2452,  1.3634,  1.2827,  1.4001,  1.2381,  1.2960],
        [ 1.8050,  1.4589,  0.6684,  0.8863,  1.2596,  1.6877,  1.6201,  1.8026,
          1.8026,  1.6919,  1.3831,  1.5102,  1.0185,  1.7961,  0.3412,  1.6753,
          1.8208,  1.2444,  1.4021,  0.9544,  0.8339,  1.1796,  1.6619,  1.7346,
          1.4348,  1.8134,  1.8134,  0.7812,  0.9132,  1.7860,  1.5679,  0.8713,
          1.7174,  1.1805,  1.8379,  1.7556,  0.4684,  0.2491,  0.2285,  0.4244,
          0.6700,  0.8127,  0.3700, 10.8277,  7.3780,  0.8659,  1.3324,  1.4356,
          1.6791,  1.1112,  1.6127,  0.5021,  1.7390,  1.8523],
        [ 1.3095,  1.3371,  1.3951,  1.3733,  1.3435,  1.3145,  1.2777,  1.3073,
          1.3073,  1.2783,  1.3839,  1.2909,  1.4023,  1.3589,  1.4436,  1.2762,
          1.3620,  1.2894,  1.3569,  1.3845,  1.3982,  1.3679,  1.3318,  1.3231,
          1.2713,  1.3201,  1.3201,  1.3645,  1.4114,  1.3386,  1.1556,  1.3168,
          1.2120,  1.3746,  1.2112,  1.3412,  1.4600,  1.1701,  1.4812,  1.4681,
          1.0621,  0.9730,  1.4676,  1.4339,  0.8638,  3.0969,  2.5377,  3.2341,
          2.7847,  2.1707,  1.8879,  2.8768,  3.0314,  1.8732]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 195 : 181.84545892925098
Test loss for epoch 195 : 181.9023731153463
Test Precision for epoch 195 : 0.26153846153846155
Test Recall for epoch 195 : 0.26153846153846155
Test F1 for epoch 195 : 0.26153846153846155


theta for epoch 196 : tensor([[ 2.5366,  2.5615,  2.6268,  2.7306,  2.6977,  2.5408,  2.6791,  2.5347,
          2.5347,  1.2885,  1.3005,  1.3016,  1.3181,  1.2748,  1.3599,  1.2864,
          1.2778,  1.2537,  1.2716,  1.2544,  1.2678,  1.2830,  1.2466,  1.2385,
          1.2633,  1.2349,  1.2349,  1.2803,  1.3270,  1.2539,  1.2789,  1.3262,
          1.2654,  1.2902,  1.2162,  1.2564,  1.3795,  1.4175,  1.4010,  1.3876,
          1.3960,  1.3361,  1.3871,  1.3558,  1.3174,  1.3535,  1.3057,  1.2945,
          1.2782,  1.3482,  1.2992,  1.3845,  1.2712,  1.2814],
        [ 1.3172,  1.2199,  1.0414,  1.2570,  1.3432,  1.3674,  1.2883,  1.3603,
          1.3603,  1.7164,  1.9566,  1.7089,  2.4923,  1.7608,  5.1069,  1.8199,
          1.6485,  4.8840,  1.1574,  1.2306,  1.0285,  1.2047,  1.3407,  1.3760,
          1.3488,  1.3729,  1.3729,  1.3316,  1.0851,  1.3913,  1.3689,  1.1681,
          1.4029,  1.4238,  1.3540,  1.3839,  1.4430,  1.5485,  1.4783,  1.4122,
          1.4150,  1.5169,  1.4647,  0.6218,  1.4449,  1.0658,  1.4417,  1.4292,
          1.4139,  1.0965,  1.4338,  0.9093,  1.4069,  1.4177],
        [ 1.2313,  1.2587,  1.3164,  1.2941,  1.2643,  1.2363,  1.2441,  1.2292,
          1.2292,  1.2958,  1.3080,  1.3089,  1.3252,  1.2821,  1.3114,  1.2937,
          1.2679,  1.2268,  2.6017,  2.6783,  2.8093,  2.7329,  2.4745,  2.5784,
          2.6294,  2.4643,  2.4643,  1.3169,  1.2960,  1.2614,  1.2864,  1.3173,
          1.2729,  1.2978,  1.2690,  1.2639,  1.3867,  1.4246,  1.4081,  1.3760,
          1.4030,  1.3952,  1.3942,  1.2726,  1.3059,  1.3180,  1.3130,  1.3019,
          1.2855,  1.2747,  1.3066,  1.3486,  1.2784,  1.2887],
        [ 1.2386,  1.2663,  1.2989,  1.2765,  1.2721,  1.2436,  1.2519,  1.2365,
          1.2365,  1.3029,  1.2901,  1.3161,  1.3255,  1.2891,  1.2789,  1.3008,
          1.2916,  1.1828,  1.2864,  1.3070,  1.3274,  1.2980,  1.2612,  1.2470,
          1.2775,  1.2494,  1.2494,  2.9119,  2.6781,  2.3816,  2.5131,  2.9077,
          2.3916,  2.8632,  2.3934,  2.3838,  1.3922,  1.4305,  1.4056,  1.3932,
          1.4088,  1.3985,  1.3989,  1.2708,  1.3287,  1.3685,  1.3127,  1.2090,
          1.2449,  1.3631,  1.2834,  1.3998,  1.2378,  1.2957],
        [ 1.8054,  1.4593,  0.6685,  0.8865,  1.2600,  1.6882,  1.6206,  1.8030,
          1.8030,  1.6923,  1.3828,  1.5106,  1.0187,  1.7965,  0.3416,  1.6757,
          1.8215,  1.2435,  1.4025,  0.9549,  0.8343,  1.1800,  1.6624,  1.7348,
          1.4356,  1.8139,  1.8139,  0.7814,  0.9136,  1.7865,  1.5686,  0.8715,
          1.7179,  1.1804,  1.8384,  1.7559,  0.4671,  0.2476,  0.2272,  0.4230,
          0.6683,  0.8107,  0.3686, 10.8676,  7.3773,  0.8664,  1.3328,  1.4362,
          1.6796,  1.1115,  1.6125,  0.5023,  1.7397,  1.8528],
        [ 1.3092,  1.3368,  1.3949,  1.3730,  1.3432,  1.3142,  1.2774,  1.3071,
          1.3071,  1.2781,  1.3838,  1.2907,  1.4022,  1.3588,  1.4435,  1.2760,
          1.3618,  1.2893,  1.3568,  1.3843,  1.3981,  1.3678,  1.3317,  1.3230,
          1.2708,  1.3199,  1.3199,  1.3644,  1.4112,  1.3384,  1.1551,  1.3167,
          1.2118,  1.3745,  1.2110,  1.3410,  1.4599,  1.1697,  1.4811,  1.4680,
          1.0616,  0.9726,  1.4676,  1.4337,  0.8633,  3.1022,  2.5399,  3.2404,
          2.7877,  2.1722,  1.8891,  2.8800,  3.0367,  1.8744]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 196 : 181.8404189926041
Test loss for epoch 196 : 181.8979433613136
Test Precision for epoch 196 : 0.26153846153846155
Test Recall for epoch 196 : 0.26153846153846155
Test F1 for epoch 196 : 0.26153846153846155


theta for epoch 197 : tensor([[ 2.5398,  2.5647,  2.6300,  2.7342,  2.7013,  2.5440,  2.6828,  2.5379,
          2.5379,  1.2882,  1.3003,  1.3013,  1.3179,  1.2745,  1.3597,  1.2862,
          1.2775,  1.2535,  1.2713,  1.2541,  1.2675,  1.2827,  1.2463,  1.2382,
          1.2630,  1.2346,  1.2346,  1.2801,  1.3267,  1.2536,  1.2786,  1.3260,
          1.2651,  1.2900,  1.2159,  1.2561,  1.3794,  1.4174,  1.4009,  1.3875,
          1.3959,  1.3360,  1.3870,  1.3554,  1.3172,  1.3531,  1.3054,  1.2942,
          1.2778,  1.3478,  1.2988,  1.3842,  1.2708,  1.2810],
        [ 1.3171,  1.2199,  1.0417,  1.2571,  1.3434,  1.3674,  1.2883,  1.3602,
          1.3602,  1.7168,  1.9565,  1.7093,  2.4924,  1.7612,  5.1204,  1.8203,
          1.6490,  4.8980,  1.1573,  1.2306,  1.0289,  1.2047,  1.3406,  1.3759,
          1.3486,  1.3728,  1.3728,  1.3317,  1.0853,  1.3911,  1.3689,  1.1681,
          1.4028,  1.4238,  1.3538,  1.3839,  1.4434,  1.5486,  1.4783,  1.4124,
          1.4155,  1.5170,  1.4647,  0.6223,  1.4448,  1.0660,  1.4416,  1.4291,
          1.4137,  1.0965,  1.4337,  0.9099,  1.4067,  1.4175],
        [ 1.2312,  1.2586,  1.3163,  1.2939,  1.2642,  1.2361,  1.2440,  1.2290,
          1.2290,  1.2956,  1.3078,  1.3087,  1.3250,  1.2819,  1.3112,  1.2935,
          1.2675,  1.2269,  2.6047,  2.6818,  2.8129,  2.7361,  2.4774,  2.5814,
          2.6328,  2.4672,  2.4672,  1.3166,  1.2959,  1.2612,  1.2861,  1.3170,
          1.2727,  1.2977,  1.2688,  1.2637,  1.3866,  1.4246,  1.4080,  1.3758,
          1.4030,  1.3952,  1.3942,  1.2726,  1.3056,  1.3178,  1.3128,  1.3016,
          1.2852,  1.2747,  1.3064,  1.3485,  1.2781,  1.2884],
        [ 1.2384,  1.2661,  1.2995,  1.2770,  1.2718,  1.2434,  1.2516,  1.2362,
          1.2362,  1.3026,  1.2907,  1.3158,  1.3255,  1.2888,  1.2786,  1.3005,
          1.2914,  1.1837,  1.2861,  1.3069,  1.3271,  1.2977,  1.2609,  1.2469,
          1.2772,  1.2491,  1.2491,  2.9133,  2.6830,  2.3856,  2.5175,  2.9092,
          2.3955,  2.8648,  2.3973,  2.3877,  1.3921,  1.4304,  1.4057,  1.3933,
          1.4087,  1.3985,  1.3988,  1.2718,  1.3285,  1.3681,  1.3126,  1.2088,
          1.2446,  1.3628,  1.2840,  1.3994,  1.2374,  1.2954],
        [ 1.8060,  1.4598,  0.6687,  0.8867,  1.2604,  1.6887,  1.6211,  1.8036,
          1.8036,  1.6928,  1.3825,  1.5111,  1.0188,  1.7969,  0.3420,  1.6761,
          1.8221,  1.2427,  1.4029,  0.9554,  0.8346,  1.1804,  1.6628,  1.7350,
          1.4364,  1.8144,  1.8144,  0.7816,  0.9139,  1.7870,  1.5693,  0.8716,
          1.7183,  1.1804,  1.8389,  1.7562,  0.4657,  0.2462,  0.2260,  0.4216,
          0.6666,  0.8087,  0.3671, 10.9075,  7.3762,  0.8668,  1.3331,  1.4367,
          1.6800,  1.1118,  1.6122,  0.5026,  1.7404,  1.8532],
        [ 1.3092,  1.3367,  1.3948,  1.3730,  1.3432,  1.3142,  1.2774,  1.3070,
          1.3070,  1.2780,  1.3837,  1.2906,  1.4021,  1.3586,  1.4434,  1.2759,
          1.3616,  1.2892,  1.3567,  1.3842,  1.3979,  1.3677,  1.3315,  1.3229,
          1.2704,  1.3198,  1.3198,  1.3643,  1.4111,  1.3383,  1.1547,  1.3166,
          1.2117,  1.3744,  1.2108,  1.3408,  1.4599,  1.1693,  1.4811,  1.4680,
          1.0613,  0.9723,  1.4675,  1.4335,  0.8629,  3.1072,  2.5420,  3.2466,
          2.7906,  2.1735,  1.8901,  2.8830,  3.0417,  1.8754]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 197 : 181.8354043925913
Test loss for epoch 197 : 181.89359259828626
Test Precision for epoch 197 : 0.26153846153846155
Test Recall for epoch 197 : 0.26153846153846155
Test F1 for epoch 197 : 0.26153846153846155


theta for epoch 198 : tensor([[ 2.5425,  2.5674,  2.6327,  2.7374,  2.7045,  2.5467,  2.6859,  2.5406,
          2.5406,  1.2881,  1.3002,  1.3012,  1.3178,  1.2744,  1.3596,  1.2861,
          1.2774,  1.2534,  1.2712,  1.2540,  1.2674,  1.2827,  1.2462,  1.2381,
          1.2629,  1.2345,  1.2345,  1.2800,  1.3266,  1.2534,  1.2785,  1.3259,
          1.2649,  1.2899,  1.2158,  1.2559,  1.3793,  1.4174,  1.4009,  1.3874,
          1.3959,  1.3360,  1.3870,  1.3552,  1.3171,  1.3530,  1.3053,  1.2941,
          1.2778,  1.3478,  1.2988,  1.3841,  1.2707,  1.2810],
        [ 1.3169,  1.2197,  1.0417,  1.2570,  1.3435,  1.3672,  1.2881,  1.3600,
          1.3600,  1.7173,  1.9565,  1.7097,  2.4925,  1.7617,  5.1338,  1.8207,
          1.6495,  4.9120,  1.1573,  1.2307,  1.0293,  1.2047,  1.3406,  1.3758,
          1.3485,  1.3727,  1.3727,  1.3318,  1.0855,  1.3910,  1.3688,  1.1682,
          1.4026,  1.4239,  1.3537,  1.3840,  1.4438,  1.5487,  1.4783,  1.4126,
          1.4159,  1.5171,  1.4647,  0.6228,  1.4448,  1.0664,  1.4415,  1.4290,
          1.4137,  1.0967,  1.4336,  0.9105,  1.4066,  1.4174],
        [ 1.2308,  1.2582,  1.3159,  1.2936,  1.2638,  1.2358,  1.2436,  1.2287,
          1.2287,  1.2954,  1.3077,  1.3085,  1.3249,  1.2817,  1.3110,  1.2933,
          1.2671,  1.2270,  2.6076,  2.6854,  2.8166,  2.7393,  2.4803,  2.5845,
          2.6362,  2.4701,  2.4701,  1.3163,  1.2959,  1.2609,  1.2859,  1.3166,
          1.2724,  1.2975,  1.2686,  1.2634,  1.3865,  1.4245,  1.4079,  1.3755,
          1.4030,  1.3951,  1.3941,  1.2726,  1.3053,  1.3177,  1.3126,  1.3014,
          1.2850,  1.2748,  1.3062,  1.3484,  1.2779,  1.2882],
        [ 1.2380,  1.2657,  1.2998,  1.2774,  1.2715,  1.2430,  1.2512,  1.2358,
          1.2358,  1.3023,  1.2912,  1.3155,  1.3255,  1.2885,  1.2784,  1.3003,
          1.2911,  1.1846,  1.2859,  1.3069,  1.3269,  1.2974,  1.2607,  1.2468,
          1.2769,  1.2488,  1.2488,  2.9148,  2.6879,  2.3895,  2.5219,  2.9107,
          2.3994,  2.8663,  2.4011,  2.3916,  1.3919,  1.4303,  1.4058,  1.3933,
          1.4086,  1.3985,  1.3986,  1.2727,  1.3283,  1.3678,  1.3126,  1.2087,
          1.2443,  1.3625,  1.2846,  1.3992,  1.2371,  1.2951],
        [ 1.8063,  1.4602,  0.6688,  0.8868,  1.2607,  1.6891,  1.6215,  1.8039,
          1.8039,  1.6933,  1.3823,  1.5115,  1.0190,  1.7974,  0.3423,  1.6765,
          1.8228,  1.2418,  1.4034,  0.9559,  0.8349,  1.1808,  1.6633,  1.7352,
          1.4372,  1.8149,  1.8149,  0.7819,  0.9142,  1.7874,  1.5700,  0.8718,
          1.7188,  1.1803,  1.8394,  1.7565,  0.4644,  0.2448,  0.2248,  0.4203,
          0.6650,  0.8068,  0.3658, 10.9474,  7.3748,  0.8673,  1.3335,  1.4373,
          1.6805,  1.1121,  1.6121,  0.5028,  1.7412,  1.8537],
        [ 1.3088,  1.3364,  1.3945,  1.3726,  1.3428,  1.3138,  1.2770,  1.3066,
          1.3066,  1.2778,  1.3836,  1.2905,  1.4020,  1.3585,  1.4432,  1.2757,
          1.3614,  1.2891,  1.3565,  1.3840,  1.3978,  1.3675,  1.3314,  1.3227,
          1.2699,  1.3196,  1.3196,  1.3641,  1.4109,  1.3381,  1.1541,  1.3165,
          1.2115,  1.3743,  1.2106,  1.3406,  1.4598,  1.1689,  1.4810,  1.4679,
          1.0608,  0.9719,  1.4675,  1.4332,  0.8624,  3.1124,  2.5442,  3.2529,
          2.7936,  2.1751,  1.8914,  2.8862,  3.0470,  1.8767]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 198 : 181.83041521170892
Test loss for epoch 198 : 181.8891910411078
Test Precision for epoch 198 : 0.26153846153846155
Test Recall for epoch 198 : 0.26153846153846155
Test F1 for epoch 198 : 0.26153846153846155


theta for epoch 199 : tensor([[ 2.5459,  2.5708,  2.6361,  2.7412,  2.7083,  2.5501,  2.6898,  2.5440,
          2.5440,  1.2878,  1.2999,  1.3009,  1.3175,  1.2741,  1.3593,  1.2857,
          1.2770,  1.2531,  1.2708,  1.2536,  1.2670,  1.2823,  1.2458,  1.2377,
          1.2625,  1.2341,  1.2341,  1.2797,  1.3262,  1.2530,  1.2781,  1.3256,
          1.2645,  1.2896,  1.2154,  1.2555,  1.3791,  1.4173,  1.4007,  1.3873,
          1.3958,  1.3358,  1.3868,  1.3548,  1.3169,  1.3525,  1.3048,  1.2936,
          1.2773,  1.3473,  1.2983,  1.3836,  1.2702,  1.2805],
        [ 1.3170,  1.2199,  1.0421,  1.2572,  1.3438,  1.3672,  1.2882,  1.3601,
          1.3601,  1.7177,  1.9563,  1.7101,  2.4924,  1.7621,  5.1471,  1.8211,
          1.6499,  4.9259,  1.1573,  1.2307,  1.0297,  1.2047,  1.3405,  1.3757,
          1.3483,  1.3726,  1.3726,  1.3318,  1.0857,  1.3909,  1.3687,  1.1683,
          1.4025,  1.4239,  1.3535,  1.3841,  1.4442,  1.5487,  1.4783,  1.4128,
          1.4164,  1.5173,  1.4647,  0.6233,  1.4447,  1.0666,  1.4414,  1.4288,
          1.4135,  1.0967,  1.4335,  0.9111,  1.4064,  1.4173],
        [ 1.2308,  1.2582,  1.3159,  1.2935,  1.2638,  1.2357,  1.2436,  1.2286,
          1.2286,  1.2952,  1.3075,  1.3083,  1.3247,  1.2815,  1.3108,  1.2932,
          1.2668,  1.2272,  2.6105,  2.6889,  2.8202,  2.7423,  2.4831,  2.5875,
          2.6396,  2.4730,  2.4730,  1.3159,  1.2958,  1.2607,  1.2857,  1.3163,
          1.2722,  1.2974,  1.2683,  1.2632,  1.3864,  1.4245,  1.4079,  1.3752,
          1.4029,  1.3951,  1.3941,  1.2726,  1.3050,  1.3176,  1.3123,  1.3011,
          1.2848,  1.2748,  1.3060,  1.3483,  1.2775,  1.2880],
        [ 1.2378,  1.2655,  1.3004,  1.2780,  1.2713,  1.2428,  1.2511,  1.2357,
          1.2357,  1.3021,  1.2917,  1.3153,  1.3255,  1.2883,  1.2782,  1.3000,
          1.2908,  1.1855,  1.2856,  1.3067,  1.3266,  1.2971,  1.2604,  1.2467,
          1.2766,  1.2485,  1.2485,  2.9162,  2.6927,  2.3934,  2.5262,  2.9121,
          2.4033,  2.8678,  2.4050,  2.3955,  1.3917,  1.4302,  1.4058,  1.3934,
          1.4085,  1.3985,  1.3985,  1.2736,  1.3281,  1.3675,  1.3125,  1.2085,
          1.2440,  1.3622,  1.2852,  1.3988,  1.2368,  1.2948],
        [ 1.8069,  1.4608,  0.6691,  0.8871,  1.2612,  1.6897,  1.6221,  1.8045,
          1.8045,  1.6937,  1.3820,  1.5119,  1.0191,  1.7978,  0.3426,  1.6768,
          1.8234,  1.2409,  1.4037,  0.9563,  0.8351,  1.1812,  1.6638,  1.7354,
          1.4379,  1.8153,  1.8153,  0.7821,  0.9145,  1.7879,  1.5707,  0.8720,
          1.7192,  1.1803,  1.8399,  1.7568,  0.4631,  0.2434,  0.2236,  0.4189,
          0.6633,  0.8048,  0.3644, 10.9872,  7.3730,  0.8676,  1.3338,  1.4378,
          1.6809,  1.1123,  1.6118,  0.5030,  1.7418,  1.8541],
        [ 1.3089,  1.3365,  1.3946,  1.3727,  1.3429,  1.3139,  1.2771,  1.3067,
          1.3067,  1.2777,  1.3836,  1.2904,  1.4019,  1.3584,  1.4432,  1.2756,
          1.3613,  1.2890,  1.3564,  1.3839,  1.3977,  1.3674,  1.3312,  1.3226,
          1.2695,  1.3195,  1.3195,  1.3641,  1.4107,  1.3379,  1.1537,  1.3164,
          1.2114,  1.3743,  1.2104,  1.3404,  1.4598,  1.1686,  1.4810,  1.4679,
          1.0605,  0.9716,  1.4675,  1.4330,  0.8621,  3.1173,  2.5461,  3.2589,
          2.7963,  2.1763,  1.8923,  2.8891,  3.0518,  1.8776]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 199 : 181.8254529186832
Test loss for epoch 199 : 181.88493162236816
Test Precision for epoch 199 : 0.26153846153846155
Test Recall for epoch 199 : 0.26153846153846155
Test F1 for epoch 199 : 0.26153846153846155


theta for epoch 200 : tensor([[ 2.5482,  2.5731,  2.6384,  2.7440,  2.7111,  2.5524,  2.6925,  2.5463,
          2.5463,  1.2878,  1.3000,  1.3009,  1.3176,  1.2741,  1.3593,  1.2857,
          1.2770,  1.2531,  1.2709,  1.2536,  1.2671,  1.2824,  1.2459,  1.2378,
          1.2626,  1.2342,  1.2342,  1.2797,  1.3262,  1.2530,  1.2780,  1.3256,
          1.2645,  1.2897,  1.2153,  1.2555,  1.3792,  1.4174,  1.4007,  1.3873,
          1.3958,  1.3359,  1.3869,  1.3546,  1.3169,  1.3526,  1.3050,  1.2937,
          1.2774,  1.3474,  1.2984,  1.3837,  1.2703,  1.2806],
        [ 1.3166,  1.2195,  1.0421,  1.2570,  1.3436,  1.3669,  1.2878,  1.3597,
          1.3597,  1.7182,  1.9562,  1.7105,  2.4925,  1.7625,  5.1604,  1.8215,
          1.6504,  4.9397,  1.1573,  1.2308,  1.0301,  1.2047,  1.3405,  1.3757,
          1.3482,  1.3725,  1.3725,  1.3319,  1.0859,  1.3908,  1.3687,  1.1683,
          1.4024,  1.4240,  1.3534,  1.3842,  1.4447,  1.5488,  1.4782,  1.4129,
          1.4169,  1.5174,  1.4647,  0.6238,  1.4447,  1.0670,  1.4414,  1.4288,
          1.4134,  1.0969,  1.4335,  0.9119,  1.4063,  1.4172],
        [ 1.2303,  1.2576,  1.3154,  1.2930,  1.2633,  1.2352,  1.2431,  1.2281,
          1.2281,  1.2950,  1.3074,  1.3081,  1.3246,  1.2813,  1.3106,  1.2930,
          1.2664,  1.2273,  2.6134,  2.6924,  2.8239,  2.7455,  2.4861,  2.5906,
          2.6430,  2.4759,  2.4759,  1.3156,  1.2957,  1.2605,  1.2854,  1.3159,
          1.2720,  1.2973,  1.2681,  1.2630,  1.3863,  1.4245,  1.4078,  1.3749,
          1.4029,  1.3951,  1.3940,  1.2725,  1.3046,  1.3176,  1.3122,  1.3009,
          1.2846,  1.2750,  1.3058,  1.3483,  1.2774,  1.2878],
        [ 1.2373,  1.2650,  1.3006,  1.2782,  1.2708,  1.2423,  1.2506,  1.2351,
          1.2351,  1.3018,  1.2921,  1.3150,  1.3255,  1.2880,  1.2780,  1.2997,
          1.2905,  1.1863,  1.2854,  1.3067,  1.3263,  1.2969,  1.2601,  1.2466,
          1.2764,  1.2483,  1.2483,  2.9176,  2.6976,  2.3973,  2.5305,  2.9136,
          2.4072,  2.8693,  2.4088,  2.3994,  1.3916,  1.4301,  1.4059,  1.3934,
          1.4084,  1.3985,  1.3984,  1.2744,  1.3279,  1.3673,  1.3125,  1.2084,
          1.2438,  1.3620,  1.2858,  1.3986,  1.2365,  1.2946],
        [ 1.8072,  1.4610,  0.6691,  0.8871,  1.2614,  1.6900,  1.6224,  1.8048,
          1.8048,  1.6942,  1.3818,  1.5124,  1.0192,  1.7982,  0.3430,  1.6772,
          1.8241,  1.2400,  1.4041,  0.9568,  0.8354,  1.1816,  1.6643,  1.7357,
          1.4388,  1.8158,  1.8158,  0.7823,  0.9148,  1.7883,  1.5714,  0.8721,
          1.7196,  1.1803,  1.8404,  1.7571,  0.4618,  0.2420,  0.2225,  0.4176,
          0.6617,  0.8029,  0.3631, 11.0270,  7.3709,  0.8681,  1.3343,  1.4385,
          1.6815,  1.1126,  1.6117,  0.5033,  1.7426,  1.8546],
        [ 1.3083,  1.3359,  1.3940,  1.3721,  1.3423,  1.3133,  1.2765,  1.3062,
          1.3062,  1.2775,  1.3834,  1.2902,  1.4018,  1.3581,  1.4430,  1.2754,
          1.3611,  1.2888,  1.3562,  1.3837,  1.3975,  1.3672,  1.3310,  1.3224,
          1.2690,  1.3192,  1.3192,  1.3639,  1.4105,  1.3377,  1.1532,  1.3163,
          1.2111,  1.3741,  1.2101,  1.3402,  1.4597,  1.1682,  1.4809,  1.4678,
          1.0600,  0.9711,  1.4674,  1.4328,  0.8615,  3.1227,  2.5485,  3.2654,
          2.7995,  2.1779,  1.8936,  2.8923,  3.0572,  1.8789]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 200 : 181.82052463071147
Test loss for epoch 200 : 181.8805282304686
Test Precision for epoch 200 : 0.26153846153846155
Test Recall for epoch 200 : 0.26153846153846155
Test F1 for epoch 200 : 0.26153846153846155


theta for epoch 201 : tensor([[ 2.5520,  2.5770,  2.6423,  2.7483,  2.7154,  2.5563,  2.6968,  2.5502,
          2.5502,  1.2872,  1.2995,  1.3004,  1.3171,  1.2736,  1.3588,  1.2852,
          1.2765,  1.2526,  1.2702,  1.2530,  1.2664,  1.2817,  1.2452,  1.2371,
          1.2619,  1.2335,  1.2335,  1.2792,  1.3256,  1.2524,  1.2775,  1.3252,
          1.2640,  1.2892,  1.2148,  1.2549,  1.3788,  1.4172,  1.4004,  1.3870,
          1.3956,  1.3357,  1.3866,  1.3541,  1.3166,  1.3519,  1.3042,  1.2929,
          1.2766,  1.3467,  1.2977,  1.3830,  1.2695,  1.2799],
        [ 1.3169,  1.2199,  1.0427,  1.2574,  1.3442,  1.3671,  1.2881,  1.3600,
          1.3600,  1.7186,  1.9560,  1.7108,  2.4923,  1.7629,  5.1736,  1.8218,
          1.6508,  4.9534,  1.1572,  1.2308,  1.0306,  1.2046,  1.3403,  1.3756,
          1.3480,  1.3724,  1.3724,  1.3320,  1.0861,  1.3907,  1.3686,  1.1684,
          1.4023,  1.4240,  1.3533,  1.3842,  1.4451,  1.5489,  1.4782,  1.4131,
          1.4173,  1.5175,  1.4647,  0.6244,  1.4446,  1.0672,  1.4411,  1.4285,
          1.4132,  1.0969,  1.4333,  0.9124,  1.4060,  1.4170],
        [ 1.2305,  1.2579,  1.3156,  1.2933,  1.2635,  1.2355,  1.2433,  1.2283,
          1.2283,  1.2948,  1.3072,  1.3080,  1.3245,  1.2811,  1.3105,  1.2928,
          1.2660,  1.2275,  2.6161,  2.6958,  2.8273,  2.7484,  2.4888,  2.5934,
          2.6462,  2.4786,  2.4786,  1.3153,  1.2956,  1.2603,  1.2852,  1.3156,
          1.2718,  1.2971,  1.2679,  1.2627,  1.3862,  1.4245,  1.4077,  1.3747,
          1.4029,  1.3951,  1.3940,  1.2726,  1.3043,  1.3173,  1.3119,  1.3005,
          1.2843,  1.2749,  1.3055,  1.3481,  1.2770,  1.2875],
        [ 1.2374,  1.2650,  1.3013,  1.2789,  1.2708,  1.2424,  1.2506,  1.2352,
          1.2352,  1.3015,  1.2926,  1.3148,  1.3254,  1.2877,  1.2778,  1.2995,
          1.2903,  1.1871,  1.2851,  1.3066,  1.3260,  1.2966,  1.2598,  1.2465,
          1.2760,  1.2480,  1.2480,  2.9189,  2.7023,  2.4010,  2.5348,  2.9149,
          2.4110,  2.8708,  2.4125,  2.4032,  1.3914,  1.4301,  1.4060,  1.3935,
          1.4083,  1.3985,  1.3983,  1.2752,  1.3278,  1.3668,  1.3123,  1.2082,
          1.2434,  1.3616,  1.2863,  1.3982,  1.2361,  1.2942],
        [ 1.8079,  1.4618,  0.6695,  0.8875,  1.2620,  1.6907,  1.6231,  1.8055,
          1.8055,  1.6946,  1.3815,  1.5128,  1.0193,  1.7986,  0.3433,  1.6776,
          1.8247,  1.2391,  1.4044,  0.9572,  0.8356,  1.1819,  1.6647,  1.7358,
          1.4395,  1.8162,  1.8162,  0.7826,  0.9151,  1.7887,  1.5720,  0.8723,
          1.7200,  1.1802,  1.8408,  1.7573,  0.4606,  0.2407,  0.2213,  0.4162,
          0.6601,  0.8010,  0.3617, 11.0668,  7.3684,  0.8683,  1.3345,  1.4388,
          1.6818,  1.1127,  1.6114,  0.5033,  1.7431,  1.8549],
        [ 1.3088,  1.3364,  1.3944,  1.3726,  1.3428,  1.3138,  1.2770,  1.3066,
          1.3066,  1.2774,  1.3834,  1.2902,  1.4018,  1.3581,  1.4430,  1.2754,
          1.3611,  1.2889,  1.3561,  1.3836,  1.3974,  1.3672,  1.3310,  1.3223,
          1.2687,  1.3192,  1.3192,  1.3639,  1.4104,  1.3376,  1.1528,  1.3163,
          1.2111,  1.3741,  1.2101,  1.3401,  1.4597,  1.1680,  1.4809,  1.4679,
          1.0597,  0.9709,  1.4675,  1.4326,  0.8612,  3.1273,  2.5501,  3.2711,
          2.8018,  2.1788,  1.8942,  2.8949,  3.0618,  1.8795]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 201 : 181.81564606105275
Test loss for epoch 201 : 181.87644300471726
Test Precision for epoch 201 : 0.26153846153846155
Test Recall for epoch 201 : 0.26153846153846155
Test F1 for epoch 201 : 0.26153846153846155


theta for epoch 202 : tensor([[ 2.5535,  2.5784,  2.6437,  2.7502,  2.7173,  2.5577,  2.6987,  2.5516,
          2.5516,  1.2875,  1.2998,  1.3007,  1.3174,  1.2739,  1.3592,  1.2855,
          1.2768,  1.2530,  1.2707,  1.2534,  1.2669,  1.2822,  1.2457,  1.2376,
          1.2624,  1.2340,  1.2340,  1.2795,  1.3258,  1.2527,  1.2777,  1.3255,
          1.2642,  1.2896,  1.2150,  1.2552,  1.3790,  1.4175,  1.4007,  1.3872,
          1.3958,  1.3359,  1.3868,  1.3541,  1.3168,  1.3524,  1.3048,  1.2935,
          1.2772,  1.3473,  1.2983,  1.3836,  1.2701,  1.2805],
        [ 1.3161,  1.2192,  1.0423,  1.2568,  1.3437,  1.3664,  1.2874,  1.3592,
          1.3592,  1.7191,  1.9560,  1.7113,  2.4923,  1.7634,  5.1868,  1.8223,
          1.6513,  4.9672,  1.1573,  1.2309,  1.0311,  1.2047,  1.3403,  1.3756,
          1.3479,  1.3724,  1.3724,  1.3320,  1.0864,  1.3905,  1.3685,  1.1685,
          1.4022,  1.4240,  1.3531,  1.3843,  1.4455,  1.5490,  1.4782,  1.4133,
          1.4178,  1.5176,  1.4647,  0.6249,  1.4445,  1.0677,  1.4413,  1.4286,
          1.4133,  1.0972,  1.4335,  0.9132,  1.4061,  1.4171],
        [ 1.2296,  1.2570,  1.3147,  1.2923,  1.2626,  1.2345,  1.2424,  1.2274,
          1.2274,  1.2946,  1.3071,  1.3077,  1.3243,  1.2809,  1.3103,  1.2926,
          1.2656,  1.2276,  2.6191,  2.6994,  2.8310,  2.7516,  2.4918,  2.5965,
          2.6498,  2.4816,  2.4816,  1.3149,  1.2956,  1.2600,  1.2849,  1.3152,
          1.2715,  1.2970,  1.2676,  1.2625,  1.3861,  1.4245,  1.4076,  1.3743,
          1.4028,  1.3950,  1.3939,  1.2726,  1.3040,  1.3174,  1.3119,  1.3005,
          1.2843,  1.2752,  1.3055,  1.3482,  1.2769,  1.2875],
        [ 1.2366,  1.2642,  1.3012,  1.2789,  1.2701,  1.2416,  1.2498,  1.2344,
          1.2344,  1.3013,  1.2931,  1.3145,  1.3254,  1.2875,  1.2776,  1.2992,
          1.2900,  1.1879,  1.2849,  1.3066,  1.3258,  1.2964,  1.2596,  1.2465,
          1.2758,  1.2478,  1.2478,  2.9203,  2.7072,  2.4049,  2.5391,  2.9163,
          2.4149,  2.8723,  2.4164,  2.4071,  1.3912,  1.4300,  1.4061,  1.3935,
          1.4081,  1.3984,  1.3982,  1.2760,  1.3276,  1.3667,  1.3124,  1.2082,
          1.2433,  1.3615,  1.2870,  1.3981,  1.2360,  1.2941],
        [ 1.8079,  1.4617,  0.6693,  0.8873,  1.2619,  1.6907,  1.6231,  1.8055,
          1.8055,  1.6951,  1.3813,  1.5132,  1.0194,  1.7990,  0.3436,  1.6780,
          1.8254,  1.2383,  1.4049,  0.9577,  0.8359,  1.1823,  1.6652,  1.7361,
          1.4403,  1.8167,  1.8167,  0.7828,  0.9154,  1.7892,  1.5727,  0.8725,
          1.7205,  1.1803,  1.8413,  1.7576,  0.4594,  0.2393,  0.2202,  0.4150,
          0.6586,  0.7991,  0.3604, 11.1066,  7.3656,  0.8689,  1.3351,  1.4396,
          1.6824,  1.1132,  1.6114,  0.5037,  1.7441,  1.8555],
        [ 1.3076,  1.3352,  1.3933,  1.3715,  1.3417,  1.3126,  1.2758,  1.3055,
          1.3055,  1.2771,  1.3832,  1.2899,  1.4015,  1.3578,  1.4428,  1.2751,
          1.3608,  1.2886,  1.3559,  1.3833,  1.3971,  1.3669,  1.3307,  1.3221,
          1.2681,  1.3189,  1.3189,  1.3636,  1.4101,  1.3373,  1.1522,  1.3161,
          1.2108,  1.3739,  1.2097,  1.3398,  1.4595,  1.1675,  1.4807,  1.4677,
          1.0592,  0.9703,  1.4674,  1.4323,  0.8606,  3.1329,  2.5528,  3.2779,
          2.8053,  2.1808,  1.8960,  2.8984,  3.0675,  1.8813]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 202 : 181.81086294743326
Test loss for epoch 202 : 181.87203698151004
Test Precision for epoch 202 : 0.26153846153846155
Test Recall for epoch 202 : 0.26153846153846155
Test F1 for epoch 202 : 0.26153846153846155


theta for epoch 203 : tensor([[ 2.5586,  2.5836,  2.6488,  2.7557,  2.7229,  2.5629,  2.7043,  2.5567,
          2.5567,  1.2865,  1.2989,  1.2997,  1.3165,  1.2729,  1.3582,  1.2846,
          1.2758,  1.2520,  1.2695,  1.2522,  1.2656,  1.2810,  1.2444,  1.2363,
          1.2611,  1.2327,  1.2327,  1.2786,  1.3249,  1.2517,  1.2767,  1.3246,
          1.2632,  1.2886,  1.2140,  1.2542,  1.3784,  1.4170,  1.4001,  1.3867,
          1.3953,  1.3354,  1.3863,  1.3534,  1.3162,  1.3509,  1.3033,  1.2919,
          1.2757,  1.3458,  1.2968,  1.3821,  1.2685,  1.2789],
        [ 1.3170,  1.2201,  1.0434,  1.2577,  1.3448,  1.3673,  1.2883,  1.3601,
          1.3601,  1.7194,  1.9557,  1.7115,  2.4921,  1.7637,  5.1998,  1.8225,
          1.6517,  4.9807,  1.1572,  1.2308,  1.0314,  1.2046,  1.3402,  1.3754,
          1.3477,  1.3722,  1.3722,  1.3321,  1.0866,  1.3904,  1.3685,  1.1685,
          1.4020,  1.4241,  1.3530,  1.3844,  1.4460,  1.5490,  1.4782,  1.4135,
          1.4183,  1.5178,  1.4647,  0.6255,  1.4445,  1.0678,  1.4408,  1.4281,
          1.4128,  1.0970,  1.4330,  0.9137,  1.4055,  1.4166],
        [ 1.2305,  1.2579,  1.3155,  1.2932,  1.2635,  1.2354,  1.2433,  1.2283,
          1.2283,  1.2945,  1.3070,  1.3076,  1.3242,  1.2808,  1.3102,  1.2925,
          1.2652,  1.2278,  2.6216,  2.7026,  2.8343,  2.7542,  2.4943,  2.5991,
          2.6528,  2.4841,  2.4841,  1.3146,  1.2955,  1.2598,  1.2848,  1.3149,
          1.2713,  1.2969,  1.2675,  1.2623,  1.3861,  1.4245,  1.4076,  1.3741,
          1.4028,  1.3951,  1.3939,  1.2727,  1.3037,  1.3171,  1.3113,  1.2999,
          1.2837,  1.2750,  1.3049,  1.3479,  1.2764,  1.2870],
        [ 1.2371,  1.2647,  1.3023,  1.2800,  1.2706,  1.2421,  1.2503,  1.2349,
          1.2349,  1.3010,  1.2935,  1.3143,  1.3254,  1.2872,  1.2774,  1.2990,
          1.2897,  1.1887,  1.2845,  1.3064,  1.3255,  1.2961,  1.2593,  1.2463,
          1.2755,  1.2474,  1.2474,  2.9215,  2.7118,  2.4086,  2.5432,  2.9176,
          2.4185,  2.8736,  2.4200,  2.4107,  1.3911,  1.4299,  1.4062,  1.3936,
          1.4081,  1.3985,  1.3982,  1.2768,  1.3274,  1.3661,  1.3121,  1.2078,
          1.2428,  1.3609,  1.2872,  1.3975,  1.2354,  1.2935],
        [ 1.8090,  1.4629,  0.6700,  0.8881,  1.2630,  1.6918,  1.6243,  1.8066,
          1.8066,  1.6955,  1.3810,  1.5136,  1.0194,  1.7993,  0.3438,  1.6783,
          1.8259,  1.2373,  1.4051,  0.9580,  0.8360,  1.1825,  1.6655,  1.7362,
          1.4410,  1.8171,  1.8171,  0.7830,  0.9156,  1.7896,  1.5733,  0.8727,
          1.7209,  1.1802,  1.8417,  1.7578,  0.4581,  0.2380,  0.2190,  0.4137,
          0.6570,  0.7973,  0.3591, 11.1463,  7.3625,  0.8689,  1.3351,  1.4398,
          1.6825,  1.1130,  1.6109,  0.5035,  1.7444,  1.8556],
        [ 1.3090,  1.3366,  1.3946,  1.3728,  1.3430,  1.3140,  1.2772,  1.3068,
          1.3068,  1.2772,  1.3834,  1.2900,  1.4017,  1.3579,  1.4429,  1.2752,
          1.3609,  1.2888,  1.3559,  1.3833,  1.3972,  1.3670,  1.3307,  1.3221,
          1.2679,  1.3190,  1.3190,  1.3637,  1.4102,  1.3374,  1.1520,  1.3162,
          1.2109,  1.3740,  1.2098,  1.3399,  1.4596,  1.1674,  1.4808,  1.4679,
          1.0591,  0.9703,  1.4675,  1.4323,  0.8605,  3.1369,  2.5537,  3.2829,
          2.8070,  2.1811,  1.8959,  2.9003,  3.0714,  1.8812]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 203 : 181.80628561522394
Test loss for epoch 203 : 181.86848267301696
Test Precision for epoch 203 : 0.26153846153846155
Test Recall for epoch 203 : 0.26153846153846155
Test F1 for epoch 203 : 0.26153846153846155


theta for epoch 204 : tensor([[ 2.5578,  2.5828,  2.6482,  2.7555,  2.7226,  2.5621,  2.7040,  2.5559,
          2.5559,  1.2876,  1.3000,  1.3008,  1.3176,  1.2739,  1.3593,  1.2856,
          1.2768,  1.2531,  1.2709,  1.2536,  1.2671,  1.2824,  1.2459,  1.2378,
          1.2626,  1.2342,  1.2342,  1.2797,  1.3258,  1.2527,  1.2777,  1.3256,
          1.2642,  1.2897,  1.2150,  1.2552,  1.3791,  1.4177,  1.4008,  1.3874,
          1.3960,  1.3361,  1.3870,  1.3538,  1.3168,  1.3527,  1.3052,  1.2937,
          1.2776,  1.3476,  1.2986,  1.3839,  1.2704,  1.2808],
        [ 1.3153,  1.2186,  1.0422,  1.2562,  1.3434,  1.3656,  1.2866,  1.3584,
          1.3584,  1.7200,  1.9557,  1.7120,  2.4921,  1.7642,  5.2130,  1.8230,
          1.6523,  4.9945,  1.1573,  1.2311,  1.0320,  1.2047,  1.3403,  1.3755,
          1.3477,  1.3723,  1.3723,  1.3322,  1.0869,  1.3903,  1.3684,  1.1686,
          1.4019,  1.4241,  1.3529,  1.3845,  1.4464,  1.5491,  1.4782,  1.4137,
          1.4188,  1.5178,  1.4647,  0.6260,  1.4444,  1.0686,  1.4413,  1.4285,
          1.4132,  1.0976,  1.4335,  0.9148,  1.4059,  1.4171],
        [ 1.2284,  1.2559,  1.3136,  1.2912,  1.2615,  1.2334,  1.2413,  1.2263,
          1.2263,  1.2942,  1.3068,  1.3074,  1.3240,  1.2805,  1.3099,  1.2922,
          1.2648,  1.2279,  2.6248,  2.7064,  2.8382,  2.7576,  2.4975,  2.6025,
          2.6566,  2.4874,  2.4874,  1.3142,  1.2954,  1.2595,  1.2845,  1.3145,
          1.2710,  1.2967,  1.2672,  1.2620,  1.3859,  1.4244,  1.4074,  1.3737,
          1.4026,  1.3950,  1.3937,  1.2726,  1.3033,  1.3175,  1.3116,  1.3002,
          1.2840,  1.2756,  1.3052,  1.3483,  1.2766,  1.2872],
        [ 1.2355,  1.2632,  1.3015,  1.2792,  1.2690,  1.2405,  1.2488,  1.2334,
          1.2334,  1.3008,  1.2940,  1.3141,  1.3254,  1.2870,  1.2772,  1.2988,
          1.2895,  1.1895,  1.2844,  1.3064,  1.3254,  1.2960,  1.2592,  1.2464,
          1.2754,  1.2474,  1.2474,  2.9230,  2.7167,  2.4125,  2.5476,  2.9191,
          2.4225,  2.8751,  2.4239,  2.4147,  1.3909,  1.4298,  1.4062,  1.3936,
          1.4079,  1.3984,  1.3980,  1.2775,  1.3272,  1.3663,  1.3124,  1.2081,
          1.2430,  1.3611,  1.2882,  1.3977,  1.2355,  1.2937],
        [ 1.8083,  1.4622,  0.6692,  0.8873,  1.2622,  1.6912,  1.6236,  1.8059,
          1.8059,  1.6960,  1.3809,  1.5141,  1.0196,  1.7998,  0.3441,  1.6787,
          1.8267,  1.2365,  1.4056,  0.9586,  0.8364,  1.1830,  1.6662,  1.7366,
          1.4419,  1.8177,  1.8177,  0.7834,  0.9159,  1.7901,  1.5741,  0.8730,
          1.7214,  1.1804,  1.8422,  1.7582,  0.4570,  0.2367,  0.2179,  0.4124,
          0.6555,  0.7955,  0.3578, 11.1860,  7.3590,  0.8698,  1.3360,  1.4409,
          1.6835,  1.1138,  1.6113,  0.5041,  1.7456,  1.8566],
        [ 1.3064,  1.3340,  1.3921,  1.3703,  1.3404,  1.3114,  1.2745,  1.3042,
          1.3042,  1.2767,  1.3829,  1.2895,  1.4012,  1.3574,  1.4424,  1.2747,
          1.3603,  1.2883,  1.3555,  1.3829,  1.3968,  1.3666,  1.3303,  1.3217,
          1.2671,  1.3185,  1.3185,  1.3633,  1.4096,  1.3368,  1.1511,  1.3158,
          1.2103,  1.3736,  1.2092,  1.3393,  1.4592,  1.1666,  1.4805,  1.4676,
          1.0582,  0.9694,  1.4672,  1.4317,  0.8596,  3.1434,  2.5574,  3.2906,
          2.8114,  2.1840,  1.8987,  2.9048,  3.0780,  1.8839]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 204 : 181.80224242651698
Test loss for epoch 204 : 181.86444129807143
Test Precision for epoch 204 : 0.26153846153846155
Test Recall for epoch 204 : 0.26153846153846155
Test F1 for epoch 204 : 0.26153846153846155


theta for epoch 205 : tensor([[ 2.5664,  2.5913,  2.6566,  2.7643,  2.7315,  2.5707,  2.7130,  2.5645,
          2.5645,  1.2854,  1.2979,  1.2986,  1.3155,  1.2718,  1.3572,  1.2835,
          1.2747,  1.2510,  1.2681,  1.2507,  1.2642,  1.2796,  1.2430,  1.2350,
          1.2597,  1.2313,  1.2313,  1.2775,  1.3237,  1.2505,  1.2755,  1.3235,
          1.2620,  1.2876,  1.2127,  1.2530,  1.3778,  1.4165,  1.3995,  1.3861,
          1.3948,  1.3349,  1.3857,  1.3523,  1.3155,  1.3492,  1.3016,  1.2902,
          1.2740,  1.3441,  1.2951,  1.3805,  1.2668,  1.2772],
        [ 1.3176,  1.2209,  1.0447,  1.2587,  1.3459,  1.3679,  1.2890,  1.3607,
          1.3607,  1.7202,  1.9552,  1.7121,  2.4915,  1.7643,  5.2256,  1.8231,
          1.6525,  5.0077,  1.1571,  1.2309,  1.0323,  1.2045,  1.3399,  1.3751,
          1.3473,  1.3719,  1.3719,  1.3322,  1.0872,  1.3902,  1.3683,  1.1687,
          1.4018,  1.4241,  1.3527,  1.3845,  1.4469,  1.5492,  1.4782,  1.4139,
          1.4194,  1.5180,  1.4647,  0.6268,  1.4444,  1.0682,  1.4403,  1.4275,
          1.4122,  1.0969,  1.4326,  0.9149,  1.4049,  1.4161],
        [ 1.2311,  1.2584,  1.3161,  1.2938,  1.2640,  1.2360,  1.2439,  1.2289,
          1.2289,  1.2942,  1.3068,  1.3073,  1.3240,  1.2805,  1.3099,  1.2922,
          1.2645,  1.2282,  2.6268,  2.7091,  2.8409,  2.7598,  2.4995,  2.6046,
          2.6591,  2.4894,  2.4894,  1.3139,  1.2955,  1.2594,  1.2844,  1.3142,
          1.2709,  1.2967,  1.2671,  1.2619,  1.3859,  1.4246,  1.4075,  1.3736,
          1.4028,  1.3951,  1.3939,  1.2728,  1.3031,  1.3166,  1.3106,  1.2992,
          1.2830,  1.2749,  1.3042,  1.3475,  1.2756,  1.2862],
        [ 1.2372,  1.2649,  1.3037,  1.2813,  1.2707,  1.2422,  1.2505,  1.2351,
          1.2351,  1.3005,  1.2943,  1.3138,  1.3253,  1.2867,  1.2770,  1.2985,
          1.2892,  1.1902,  1.2839,  1.3061,  1.3249,  1.2955,  1.2587,  1.2460,
          1.2748,  1.2468,  1.2468,  2.9240,  2.7211,  2.4160,  2.5515,  2.9201,
          2.4259,  2.8762,  2.4273,  2.4181,  1.3908,  1.4298,  1.4064,  1.3937,
          1.4079,  1.3985,  1.3980,  1.2783,  1.3271,  1.3653,  1.3117,  1.2072,
          1.2420,  1.3601,  1.2880,  1.3967,  1.2345,  1.2927],
        [ 1.8105,  1.4644,  0.6708,  0.8890,  1.2643,  1.6934,  1.6258,  1.8081,
          1.8081,  1.6963,  1.3805,  1.5143,  1.0195,  1.8000,  0.3442,  1.6789,
          1.8271,  1.2355,  1.4056,  0.9587,  0.8362,  1.1830,  1.6663,  1.7365,
          1.4424,  1.8178,  1.8178,  0.7835,  0.9160,  1.7903,  1.5745,  0.8730,
          1.7216,  1.1802,  1.8425,  1.7583,  0.4557,  0.2354,  0.2168,  0.4111,
          0.6540,  0.7936,  0.3566, 11.2257,  7.3552,  0.8693,  1.3354,  1.4405,
          1.6830,  1.1130,  1.6102,  0.5035,  1.7453,  1.8561],
        [ 1.3101,  1.3376,  1.3956,  1.3739,  1.3441,  1.3151,  1.2782,  1.3079,
          1.3079,  1.2772,  1.3835,  1.2900,  1.4018,  1.3579,  1.4430,  1.2753,
          1.3608,  1.2889,  1.3559,  1.3832,  1.3972,  1.3669,  1.3307,  1.3221,
          1.2673,  1.3189,  1.3189,  1.3638,  1.4101,  1.3373,  1.1514,  1.3163,
          1.2108,  1.3741,  1.2097,  1.3398,  1.4597,  1.1670,  1.4809,  1.4680,
          1.0586,  0.9699,  1.4677,  1.4320,  0.8600,  3.1458,  2.5566,  3.2939,
          2.8114,  2.1827,  1.8969,  2.9051,  3.0802,  1.8822]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 205 : 181.79943440066353
Test loss for epoch 205 : 181.86326119340416
Test Precision for epoch 205 : 0.26153846153846155
Test Recall for epoch 205 : 0.26153846153846155
Test F1 for epoch 205 : 0.26153846153846155


theta for epoch 206 : tensor([[ 2.5599,  2.5850,  2.6504,  2.7585,  2.7257,  2.5642,  2.7069,  2.5580,
          2.5580,  1.2884,  1.3009,  1.3016,  1.3185,  1.2748,  1.3602,  1.2864,
          1.2777,  1.2541,  1.2722,  1.2549,  1.2683,  1.2837,  1.2471,  1.2391,
          1.2638,  1.2354,  1.2354,  1.2806,  1.3266,  1.2535,  1.2785,  1.3265,
          1.2650,  1.2907,  1.2158,  1.2560,  1.3796,  1.4184,  1.4013,  1.3880,
          1.3966,  1.3368,  1.3876,  1.3540,  1.3174,  1.3542,  1.3068,  1.2953,
          1.2792,  1.3491,  1.3002,  1.3853,  1.2719,  1.2824],
        [ 1.3134,  1.2169,  1.0412,  1.2547,  1.3421,  1.3637,  1.2848,  1.3565,
          1.3565,  1.7211,  1.9555,  1.7129,  2.4918,  1.7652,  5.2390,  1.8239,
          1.6534,  5.0216,  1.1575,  1.2314,  1.0332,  1.2049,  1.3403,  1.3755,
          1.3476,  1.3723,  1.3723,  1.3324,  1.0875,  1.3901,  1.3683,  1.1688,
          1.4018,  1.4242,  1.3527,  1.3846,  1.4472,  1.5492,  1.4781,  1.4141,
          1.4198,  1.5180,  1.4646,  0.6272,  1.4443,  1.0698,  1.4416,  1.4288,
          1.4135,  1.0983,  1.4339,  0.9166,  1.4061,  1.4174],
        [ 1.2262,  1.2536,  1.3114,  1.2890,  1.2593,  1.2311,  1.2390,  1.2240,
          1.2240,  1.2938,  1.3064,  1.3070,  1.3237,  1.2801,  1.3095,  1.2918,
          1.2639,  1.2282,  2.6307,  2.7137,  2.8456,  2.7638,  2.5035,  2.6086,
          2.6636,  2.4933,  2.4933,  1.3134,  1.2953,  1.2591,  1.2840,  1.3137,
          1.2706,  1.2964,  1.2667,  1.2616,  1.3856,  1.4243,  1.4072,  1.3730,
          1.4025,  1.3949,  1.3936,  1.2726,  1.3025,  1.3178,  1.3117,  1.3002,
          1.2841,  1.2763,  1.3053,  1.3486,  1.2766,  1.2873],
        [ 1.2337,  1.2614,  1.3010,  1.2787,  1.2672,  1.2387,  1.2470,  1.2315,
          1.2315,  1.3004,  1.2948,  1.3136,  1.3254,  1.2866,  1.2769,  1.2984,
          1.2891,  1.1910,  1.2842,  1.3064,  1.3251,  1.2958,  1.2589,  1.2464,
          1.2751,  1.2471,  1.2471,  2.9257,  2.7263,  2.4201,  2.5561,  2.9219,
          2.4301,  2.8780,  2.4314,  2.4223,  1.3906,  1.4297,  1.4064,  1.3936,
          1.4077,  1.3984,  1.3978,  1.2789,  1.3269,  1.3661,  1.3127,  1.2082,
          1.2429,  1.3610,  1.2895,  1.3975,  1.2354,  1.2936],
        [ 1.8080,  1.4618,  0.6686,  0.8867,  1.2616,  1.6908,  1.6232,  1.8056,
          1.8056,  1.6970,  1.3806,  1.5149,  1.0198,  1.8006,  0.3446,  1.6795,
          1.8280,  1.2348,  1.4065,  0.9597,  0.8369,  1.1838,  1.6673,  1.7372,
          1.4436,  1.8188,  1.8188,  0.7840,  0.9165,  1.7911,  1.5755,  0.8735,
          1.7223,  1.1806,  1.8432,  1.7589,  0.4546,  0.2342,  0.2158,  0.4099,
          0.6526,  0.7919,  0.3554, 11.2655,  7.3511,  0.8709,  1.3373,  1.4425,
          1.6849,  1.1147,  1.6116,  0.5047,  1.7475,  1.8579],
        [ 1.3036,  1.3312,  1.3894,  1.3675,  1.3377,  1.3086,  1.2717,  1.3014,
          1.3014,  1.2760,  1.3824,  1.2888,  1.4007,  1.3568,  1.4419,  1.2740,
          1.3597,  1.2877,  1.3550,  1.3823,  1.3962,  1.3660,  1.3297,  1.3212,
          1.2660,  1.3179,  1.3179,  1.3627,  1.4090,  1.3362,  1.1498,  1.3152,
          1.2096,  1.3731,  1.2084,  1.3387,  1.4588,  1.1656,  1.4801,  1.4672,
          1.0571,  0.9683,  1.4669,  1.4310,  0.8583,  3.1548,  2.5629,  3.3043,
          2.8184,  2.1882,  1.9023,  2.9119,  3.0895,  1.8875]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 206 : 181.8003296224411
Test loss for epoch 206 : 181.86317096321645
Test Precision for epoch 206 : 0.26153846153846155
Test Recall for epoch 206 : 0.26153846153846155
Test F1 for epoch 206 : 0.26153846153846155


theta for epoch 207 : tensor([[ 2.5772,  2.6021,  2.6673,  2.7759,  2.7431,  2.5814,  2.7246,  2.5753,
          2.5753,  1.2832,  1.2958,  1.2965,  1.3134,  1.2696,  1.3551,  1.2813,
          1.2725,  1.2488,  1.2652,  1.2478,  1.2613,  1.2768,  1.2402,  1.2321,
          1.2569,  1.2284,  1.2284,  1.2753,  1.3215,  1.2482,  1.2733,  1.3214,
          1.2597,  1.2855,  1.2104,  1.2507,  1.3764,  1.4154,  1.3982,  1.3848,
          1.3935,  1.3336,  1.3845,  1.3506,  1.3141,  1.3457,  1.2981,  1.2865,
          1.2704,  1.3406,  1.2915,  1.3770,  1.2631,  1.2736],
        [ 1.3195,  1.2229,  1.0471,  1.2608,  1.3483,  1.3698,  1.2909,  1.3626,
          1.3626,  1.7207,  1.9546,  1.7125,  2.4907,  1.7649,  5.2510,  1.8235,
          1.6531,  5.0341,  1.1569,  1.2308,  1.0332,  1.2043,  1.3396,  1.3748,
          1.3467,  1.3715,  1.3715,  1.3324,  1.0879,  1.3900,  1.3683,  1.1689,
          1.4016,  1.4242,  1.3525,  1.3847,  1.4479,  1.5495,  1.4783,  1.4145,
          1.4206,  1.5184,  1.4648,  0.6282,  1.4444,  1.0682,  1.4392,  1.4264,
          1.4110,  1.0964,  1.4315,  0.9158,  1.4037,  1.4149],
        [ 1.2331,  1.2604,  1.3180,  1.2957,  1.2660,  1.2380,  1.2459,  1.2309,
          1.2309,  1.2940,  1.3067,  1.3072,  1.3240,  1.2804,  1.3098,  1.2921,
          1.2640,  1.2289,  2.6315,  2.7151,  2.8471,  2.7647,  2.5043,  2.6095,
          2.6649,  2.4941,  2.4941,  1.3134,  1.2956,  1.2592,  1.2841,  1.3137,
          1.2707,  1.2966,  1.2668,  1.2617,  1.3860,  1.4248,  1.4076,  1.3732,
          1.4029,  1.3954,  1.3940,  1.2732,  1.3027,  1.3157,  1.3094,  1.2979,
          1.2817,  1.2744,  1.3030,  1.3466,  1.2743,  1.2850],
        [ 1.2384,  1.2660,  1.3059,  1.2835,  1.2718,  1.2434,  1.2517,  1.2362,
          1.2362,  1.3001,  1.2952,  1.3134,  1.3253,  1.2863,  1.2767,  1.2981,
          1.2888,  1.1917,  1.2833,  1.3057,  1.3242,  1.2949,  1.2580,  1.2456,
          1.2741,  1.2461,  1.2461,  2.9262,  2.7302,  2.4231,  2.5595,  2.9224,
          2.4330,  2.8786,  2.4343,  2.4252,  1.3906,  1.4298,  1.4066,  1.3939,
          1.4078,  1.3986,  1.3980,  1.2798,  1.3270,  1.3640,  1.3108,  1.2063,
          1.2408,  1.3589,  1.2882,  1.3955,  1.2333,  1.2914],
        [ 1.8128,  1.4667,  0.6722,  0.8906,  1.2665,  1.6957,  1.6281,  1.8104,
          1.8104,  1.6971,  1.3800,  1.5150,  1.0195,  1.8007,  0.3446,  1.6795,
          1.8283,  1.2335,  1.4060,  0.9593,  0.8363,  1.1833,  1.6669,  1.7366,
          1.4436,  1.8184,  1.8184,  0.7840,  0.9163,  1.7911,  1.5757,  0.8734,
          1.7223,  1.1802,  1.8433,  1.7587,  0.4535,  0.2329,  0.2146,  0.4087,
          0.6511,  0.7901,  0.3541, 11.3051,  7.3466,  0.8690,  1.3352,  1.4406,
          1.6829,  1.1124,  1.6091,  0.5029,  1.7457,  1.8559],
        [ 1.3132,  1.3407,  1.3986,  1.3769,  1.3472,  1.3182,  1.2814,  1.3110,
          1.3110,  1.2778,  1.3841,  1.2906,  1.4024,  1.3583,  1.4435,  1.2758,
          1.3613,  1.2895,  1.3562,  1.3835,  1.3975,  1.3673,  1.3310,  1.3224,
          1.2671,  1.3192,  1.3192,  1.3643,  1.4104,  1.3376,  1.1513,  1.3169,
          1.2113,  1.3746,  1.2101,  1.3401,  1.4601,  1.1671,  1.4814,  1.4685,
          1.0586,  0.9701,  1.4682,  1.4322,  0.8600,  3.1531,  2.5578,  3.3032,
          2.8140,  2.1825,  1.8962,  2.9081,  3.0872,  1.8814]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 207 : 181.80810038968622
Test loss for epoch 207 : 181.87420277365976
Test Precision for epoch 207 : 0.26153846153846155
Test Recall for epoch 207 : 0.26153846153846155
Test F1 for epoch 207 : 0.26153846153846155


theta for epoch 208 : tensor([[ 2.5573,  2.5824,  2.6480,  2.7568,  2.7240,  2.5616,  2.7052,  2.5554,
          2.5554,  1.2911,  1.3037,  1.3043,  1.3213,  1.2775,  1.3629,  1.2892,
          1.2804,  1.2570,  1.2759,  1.2587,  1.2720,  1.2874,  1.2509,  1.2429,
          1.2675,  1.2392,  1.2392,  1.2834,  1.3292,  1.2562,  1.2811,  1.3292,
          1.2676,  1.2935,  1.2186,  1.2587,  1.3813,  1.4202,  1.4031,  1.3897,
          1.3984,  1.3387,  1.3894,  1.3554,  1.3191,  1.3585,  1.3112,  1.2997,
          1.2837,  1.3535,  1.3047,  1.3896,  1.2764,  1.2870],
        [ 1.3088,  1.2126,  1.0377,  1.2504,  1.3380,  1.3592,  1.2802,  1.3519,
          1.3519,  1.7224,  1.9556,  1.7141,  2.4916,  1.7665,  5.2650,  1.8251,
          1.6548,  5.0486,  1.1581,  1.2321,  1.0347,  1.2055,  1.3408,  1.3760,
          1.3479,  1.3727,  1.3727,  1.3327,  1.0883,  1.3901,  1.3684,  1.1691,
          1.4018,  1.4245,  1.3526,  1.3850,  1.4482,  1.5494,  1.4782,  1.4146,
          1.4210,  1.5183,  1.4647,  0.6285,  1.4442,  1.0717,  1.4427,  1.4298,
          1.4145,  1.0998,  1.4351,  0.9190,  1.4071,  1.4185],
        [ 1.2209,  1.2483,  1.3062,  1.2838,  1.2540,  1.2258,  1.2338,  1.2187,
          1.2187,  1.2934,  1.3062,  1.3066,  1.3235,  1.2798,  1.3092,  1.2915,
          1.2632,  1.2286,  2.6372,  2.7215,  2.8534,  2.7705,  2.5101,  2.6154,
          2.6712,  2.4999,  2.4999,  1.3127,  1.2952,  1.2587,  1.2836,  1.3130,
          1.2702,  1.2962,  1.2663,  1.2612,  1.3853,  1.4242,  1.4070,  1.3723,
          1.4023,  1.3948,  1.3934,  1.2726,  1.3017,  1.3188,  1.3125,  1.3009,
          1.2848,  1.2776,  1.3061,  1.3496,  1.2773,  1.2881],
        [ 1.2296,  1.2573,  1.2983,  1.2760,  1.2632,  1.2346,  1.2429,  1.2274,
          1.2274,  1.3001,  1.2958,  1.3134,  1.3256,  1.2864,  1.2768,  1.2982,
          1.2888,  1.1926,  1.2843,  1.3068,  1.3252,  1.2959,  1.2590,  1.2468,
          1.2752,  1.2472,  1.2472,  2.9286,  2.7360,  2.4279,  2.5648,  2.9248,
          2.4379,  2.8811,  2.4391,  2.4301,  1.3904,  1.4297,  1.4066,  1.3938,
          1.4076,  1.3985,  1.3978,  1.2803,  1.3266,  1.3666,  1.3136,  1.2089,
          1.2434,  1.3615,  1.2914,  1.3980,  1.2359,  1.2941],
        [ 1.8056,  1.4594,  0.6664,  0.8845,  1.2591,  1.6885,  1.6208,  1.8032,
          1.8032,  1.6983,  1.3806,  1.5161,  1.0203,  1.8018,  0.3453,  1.6805,
          1.8297,  1.2333,  1.4077,  0.9611,  0.8378,  1.1850,  1.6688,  1.7383,
          1.4457,  1.8204,  1.8204,  0.7850,  0.9173,  1.7924,  1.5772,  0.8744,
          1.7236,  1.1812,  1.8445,  1.7598,  0.4525,  0.2318,  0.2137,  0.4076,
          0.6498,  0.7884,  0.3530, 11.3448,  7.3418,  0.8726,  1.3394,  1.4450,
          1.6871,  1.1163,  1.6128,  0.5060,  1.7502,  1.8601],
        [ 1.2970,  1.3246,  1.3829,  1.3610,  1.3312,  1.3020,  1.2651,  1.2949,
          1.2949,  1.2748,  1.3815,  1.2877,  1.3998,  1.3557,  1.4409,  1.2729,
          1.3586,  1.2866,  1.3541,  1.3814,  1.3953,  1.3652,  1.3288,  1.3203,
          1.2644,  1.3170,  1.3170,  1.3617,  1.4080,  1.3351,  1.1480,  1.3143,
          1.2085,  1.3722,  1.2072,  1.3376,  1.4581,  1.1641,  1.4794,  1.4666,
          1.0554,  0.9666,  1.4663,  1.4300,  0.8565,  3.1683,  2.5708,  3.3202,
          2.8276,  2.1947,  1.9083,  2.9212,  3.1033,  1.8936]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 208 : 181.83762505327238
Test loss for epoch 208 : 181.90013518460796
Test Precision for epoch 208 : 0.26153846153846155
Test Recall for epoch 208 : 0.26153846153846155
Test F1 for epoch 208 : 0.26153846153846155


theta for epoch 209 : tensor([[ 2.5903,  2.6152,  2.6803,  2.7898,  2.7570,  2.5946,  2.7385,  2.5884,
          2.5884,  1.2796,  1.2923,  1.2929,  1.3100,  1.2660,  1.3516,  1.2777,
          1.2688,  1.2452,  1.2604,  1.2428,  1.2564,  1.2720,  1.2353,  1.2273,
          1.2520,  1.2235,  1.2235,  1.2717,  1.3178,  1.2445,  1.2696,  1.3179,
          1.2560,  1.2820,  1.2066,  1.2470,  1.3743,  1.4134,  1.3961,  1.3827,
          1.3914,  1.3314,  1.3824,  1.3480,  1.3118,  1.3391,  1.2916,  1.2800,
          1.2639,  1.3341,  1.2850,  1.3705,  1.2565,  1.2671],
        [ 1.3221,  1.2255,  1.0502,  1.2635,  1.3513,  1.3723,  1.2935,  1.3651,
          1.3651,  1.7212,  1.9537,  1.7127,  2.4896,  1.7652,  5.2760,  1.8237,
          1.6536,  5.0601,  1.1569,  1.2309,  1.0342,  1.2042,  1.3393,  1.3744,
          1.3463,  1.3711,  1.3711,  1.3330,  1.0890,  1.3901,  1.3685,  1.1695,
          1.4018,  1.4246,  1.3526,  1.3852,  1.4494,  1.5502,  1.4789,  1.4155,
          1.4223,  1.5192,  1.4654,  0.6303,  1.4450,  1.0672,  1.4368,  1.4240,
          1.4086,  1.0947,  1.4292,  0.9158,  1.4012,  1.4125],
        [ 1.2361,  1.2634,  1.3207,  1.2986,  1.2689,  1.2411,  1.2489,  1.2340,
          1.2340,  1.2947,  1.3075,  1.3079,  1.3247,  1.2810,  1.3103,  1.2927,
          1.2642,  1.2303,  2.6353,  2.7203,  2.8523,  2.7688,  2.5082,  2.6135,
          2.6698,  2.4980,  2.4980,  1.3134,  1.2963,  1.2595,  1.2844,  1.3137,
          1.2710,  1.2970,  1.2671,  1.2620,  1.3867,  1.4257,  1.4084,  1.3735,
          1.4038,  1.3963,  1.3948,  1.2742,  1.3030,  1.3136,  1.3070,  1.2954,
          1.2793,  1.2727,  1.3005,  1.3446,  1.2717,  1.2825],
        [ 1.2401,  1.2677,  1.3084,  1.2862,  1.2735,  1.2451,  1.2534,  1.2380,
          1.2380,  1.3001,  1.2963,  1.3134,  1.3257,  1.2863,  1.2768,  1.2981,
          1.2887,  1.1934,  1.2826,  1.3053,  1.3235,  1.2942,  1.2573,  1.2453,
          1.2735,  1.2455,  1.2455,  2.9283,  2.7390,  2.4300,  2.5673,  2.9246,
          2.4399,  2.8809,  2.4411,  2.4321,  1.3910,  1.4304,  1.4074,  1.3946,
          1.4083,  1.3993,  1.3984,  1.2817,  1.3274,  1.3618,  1.3089,  1.2043,
          1.2385,  1.3567,  1.2873,  1.3933,  1.2310,  1.2892],
        [ 1.8154,  1.4694,  0.6739,  0.8926,  1.2690,  1.6984,  1.6308,  1.8130,
          1.8130,  1.6981,  1.3797,  1.5158,  1.0197,  1.8015,  0.3449,  1.6802,
          1.8297,  1.2317,  1.4061,  0.9597,  0.8361,  1.1834,  1.6673,  1.7365,
          1.4446,  1.8188,  1.8188,  0.7846,  0.9167,  1.7920,  1.5770,  0.8739,
          1.7233,  1.1804,  1.8442,  1.7593,  0.4514,  0.2306,  0.2127,  0.4064,
          0.6486,  0.7868,  0.3519, 11.3846,  7.3368,  0.8675,  1.3336,  1.4394,
          1.6815,  1.1105,  1.6066,  0.5011,  1.7448,  1.8545],
        [ 1.3183,  1.3458,  1.4033,  1.3817,  1.3522,  1.3233,  1.2865,  1.3162,
          1.3162,  1.2798,  1.3861,  1.2927,  1.4044,  1.3602,  1.4455,  1.2779,
          1.3631,  1.2917,  1.3577,  1.3850,  1.3991,  1.3689,  1.3324,  1.3239,
          1.2682,  1.3206,  1.3206,  1.3661,  1.4121,  1.3393,  1.1528,  1.3189,
          1.2133,  1.3765,  1.2119,  1.3419,  1.4617,  1.1686,  1.4830,  1.4702,
          1.0602,  0.9718,  1.4699,  1.4335,  0.8616,  3.1570,  2.5555,  3.3089,
          2.8132,  2.1792,  1.8921,  2.9079,  3.0907,  1.8774]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 209 : 181.86618372284804
Test loss for epoch 209 : 181.93609630997037
Test Precision for epoch 209 : 0.26153846153846155
Test Recall for epoch 209 : 0.26153846153846155
Test F1 for epoch 209 : 0.26153846153846155


theta for epoch 210 : tensor([[ 2.5576,  2.5828,  2.6484,  2.7579,  2.7251,  2.5619,  2.7063,  2.5557,
          2.5557,  1.2938,  1.3065,  1.3070,  1.3241,  1.2802,  1.3657,  1.2919,
          1.2831,  1.2599,  1.2797,  1.2624,  1.2757,  1.2911,  1.2546,  1.2466,
          1.2712,  1.2429,  1.2429,  1.2863,  1.3318,  1.2589,  1.2838,  1.3320,
          1.2703,  1.2964,  1.2213,  1.2614,  1.3831,  1.4221,  1.4049,  1.3916,
          1.4001,  1.3406,  1.3912,  1.3568,  1.3208,  1.3627,  1.3157,  1.3041,
          1.2882,  1.3578,  1.3093,  1.3936,  1.2809,  1.2915],
        [ 1.3032,  1.2072,  1.0333,  1.2452,  1.3329,  1.3535,  1.2747,  1.3463,
          1.3463,  1.7235,  1.9554,  1.7149,  2.4910,  1.7675,  5.2903,  1.8259,
          1.6559,  5.0750,  1.1596,  1.2337,  1.0370,  1.2069,  1.3422,  1.3773,
          1.3490,  1.3740,  1.3740,  1.3336,  1.0897,  1.3907,  1.3691,  1.1701,
          1.4023,  1.4253,  1.3532,  1.3859,  1.4497,  1.5501,  1.4788,  1.4156,
          1.4227,  1.5192,  1.4653,  0.6304,  1.4447,  1.0744,  1.4444,  1.4315,
          1.4162,  1.1020,  1.4368,  0.9221,  1.4087,  1.4201],
        [ 1.2146,  1.2421,  1.2999,  1.2775,  1.2478,  1.2196,  1.2276,  1.2125,
          1.2125,  1.2936,  1.3065,  1.3068,  1.3238,  1.2800,  1.3093,  1.2917,
          1.2629,  1.2295,  2.6435,  2.7292,  2.8612,  2.7771,  2.5166,  2.6219,
          2.6787,  2.5064,  2.5064,  1.3124,  1.2956,  1.2587,  1.2836,  1.3127,
          1.2702,  1.2963,  1.2663,  1.2612,  1.3855,  1.4246,  1.4072,  1.3721,
          1.4025,  1.3951,  1.3937,  1.2731,  1.3014,  1.3201,  1.3136,  1.3020,
          1.2859,  1.2794,  1.3072,  1.3510,  1.2784,  1.2892],
        [ 1.2244,  1.2522,  1.2944,  1.2723,  1.2581,  1.2295,  1.2378,  1.2223,
          1.2223,  1.3005,  1.2973,  1.3138,  1.3263,  1.2867,  1.2772,  1.2985,
          1.2891,  1.1946,  1.2852,  1.3079,  1.3261,  1.2968,  1.2599,  1.2480,
          1.2760,  1.2481,  1.2481,  2.9312,  2.7453,  2.4353,  2.5731,  2.9275,
          2.4453,  2.8839,  2.4464,  2.4375,  1.3908,  1.4302,  1.4074,  1.3945,
          1.4080,  1.3991,  1.3983,  1.2821,  1.3270,  1.3675,  1.3149,  1.2100,
          1.2445,  1.3625,  1.2937,  1.3989,  1.2369,  1.2952],
        [ 1.8020,  1.4559,  0.6637,  0.8816,  1.2556,  1.6850,  1.6174,  1.7997,
          1.7997,  1.7001,  1.3812,  1.5178,  1.0214,  1.8034,  0.3467,  1.6821,
          1.8318,  1.2325,  1.4097,  0.9632,  0.8395,  1.1870,  1.6710,  1.7400,
          1.4485,  1.8225,  1.8225,  0.7870,  0.9188,  1.7943,  1.5796,  0.8762,
          1.7255,  1.1827,  1.8465,  1.7615,  0.4500,  0.2291,  0.2114,  0.4050,
          0.6469,  0.7848,  0.3504, 11.4238,  7.3308,  0.8753,  1.3423,  1.4483,
          1.6901,  1.1189,  1.6148,  0.5082,  1.7535,  1.8629],
        [ 1.2900,  1.3175,  1.3756,  1.3538,  1.3240,  1.2950,  1.2581,  1.2879,
          1.2879,  1.2731,  1.3800,  1.2860,  1.3984,  1.3542,  1.4395,  1.2712,
          1.3571,  1.2850,  1.3525,  1.3798,  1.3938,  1.3636,  1.3272,  1.3187,
          1.2622,  1.3154,  1.3154,  1.3603,  1.4066,  1.3336,  1.1456,  1.3129,
          1.2068,  1.3709,  1.2054,  1.3361,  1.4572,  1.1623,  1.4786,  1.4657,
          1.0533,  0.9646,  1.4655,  1.4288,  0.8543,  3.1827,  2.5798,  3.3369,
          2.8379,  2.2023,  1.9156,  2.9315,  3.1179,  1.9008]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 210 : 181.90830936173103
Test loss for epoch 210 : 181.96926335757877
Test Precision for epoch 210 : 0.26153846153846155
Test Recall for epoch 210 : 0.26153846153846155
Test F1 for epoch 210 : 0.26153846153846155


theta for epoch 211 : tensor([[ 2.5902,  2.6152,  2.6805,  2.7905,  2.7577,  2.5945,  2.7391,  2.5884,
          2.5884,  1.2811,  1.2939,  1.2943,  1.3115,  1.2674,  1.3531,  1.2791,
          1.2703,  1.2467,  1.2622,  1.2446,  1.2581,  1.2738,  1.2372,  1.2292,
          1.2538,  1.2254,  1.2254,  1.2732,  1.3191,  1.2458,  1.2708,  1.3193,
          1.2573,  1.2835,  1.2079,  1.2483,  1.3751,  1.4144,  1.3971,  1.3837,
          1.3923,  1.3323,  1.3834,  1.3484,  1.3124,  1.3395,  1.2924,  1.2807,
          1.2648,  1.3346,  1.2860,  1.3707,  1.2574,  1.2682],
        [ 1.3180,  1.2218,  1.0472,  1.2598,  1.3477,  1.3682,  1.2895,  1.3611,
          1.3611,  1.7226,  1.9538,  1.7139,  2.4892,  1.7665,  5.3015,  1.8248,
          1.6550,  5.0866,  1.1578,  1.2319,  1.0360,  1.2051,  1.3401,  1.3752,
          1.3469,  1.3718,  1.3718,  1.3341,  1.0907,  1.3909,  1.3695,  1.1707,
          1.4026,  1.4257,  1.3535,  1.3864,  1.4515,  1.5515,  1.4801,  1.4172,
          1.4247,  1.5206,  1.4666,  0.6327,  1.4461,  1.0663,  1.4348,  1.4219,
          1.4065,  1.0933,  1.4272,  0.9160,  1.3990,  1.4104],
        [ 1.2321,  1.2593,  1.3166,  1.2944,  1.2649,  1.2370,  1.2448,  1.2300,
          1.2300,  1.2960,  1.3088,  1.3092,  1.3261,  1.2823,  1.3115,  1.2941,
          1.2650,  1.2324,  2.6406,  2.7271,  2.8591,  2.7743,  2.5137,  2.6191,
          2.6763,  2.5035,  2.5035,  1.3138,  1.2974,  1.2603,  1.2852,  1.3141,
          1.2718,  1.2980,  1.2680,  1.2628,  1.3878,  1.4270,  1.4096,  1.3742,
          1.4050,  1.3976,  1.3960,  1.2757,  1.3037,  1.3114,  1.3044,  1.2928,
          1.2767,  1.2709,  1.2979,  1.3425,  1.2690,  1.2798],
        [ 1.2365,  1.2640,  1.3059,  1.2837,  1.2699,  1.2415,  1.2497,  1.2343,
          1.2343,  1.3008,  1.2982,  1.3141,  1.3268,  1.2871,  1.2776,  1.2989,
          1.2895,  1.1958,  1.2831,  1.3059,  1.3239,  1.2947,  1.2577,  1.2460,
          1.2739,  1.2459,  1.2459,  2.9311,  2.7485,  2.4376,  2.5758,  2.9274,
          2.4475,  2.8839,  2.4486,  2.4397,  1.3920,  1.4316,  1.4088,  1.3959,
          1.4094,  1.4006,  1.3996,  1.2841,  1.3284,  1.3598,  1.3073,  1.2026,
          1.2366,  1.3547,  1.2867,  1.3913,  1.2290,  1.2872],
        [ 1.8130,  1.4669,  0.6716,  0.8903,  1.2664,  1.6960,  1.6284,  1.8106,
          1.8106,  1.6999,  1.3802,  1.5175,  1.0205,  1.8032,  0.3457,  1.6818,
          1.8319,  1.2307,  1.4072,  0.9608,  0.8367,  1.1844,  1.6687,  1.7375,
          1.4466,  1.8203,  1.8203,  0.7859,  0.9177,  1.7939,  1.5793,  0.8752,
          1.7251,  1.1816,  1.8462,  1.7609,  0.4499,  0.2289,  0.2113,  0.4048,
          0.6465,  0.7841,  0.3502, 11.4643,  7.3260,  0.8665,  1.3328,  1.4389,
          1.6808,  1.1091,  1.6049,  0.4997,  1.7445,  1.8538],
        [ 1.3155,  1.3428,  1.4000,  1.3785,  1.3491,  1.3204,  1.2837,  1.3134,
          1.3134,  1.2818,  1.3882,  1.2947,  1.4065,  1.3622,  1.4475,  1.2799,
          1.3650,  1.2939,  1.3592,  1.3865,  1.4007,  1.3705,  1.3339,  1.3254,
          1.2693,  1.3221,  1.3221,  1.3680,  1.4138,  1.3411,  1.1542,  1.3208,
          1.2151,  1.3784,  1.2137,  1.3436,  1.4634,  1.1700,  1.4847,  1.4720,
          1.0616,  0.9733,  1.4716,  1.4348,  0.8630,  3.1644,  2.5575,  3.3182,
          2.8165,  2.1799,  1.8924,  2.9114,  3.0980,  1.8777]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 211 : 181.8302119441428
Test loss for epoch 211 : 181.90302759162947
Test Precision for epoch 211 : 0.26153846153846155
Test Recall for epoch 211 : 0.26153846153846155
Test F1 for epoch 211 : 0.26153846153846155


theta for epoch 212 : tensor([[ 2.5834,  2.6085,  2.6738,  2.7841,  2.7513,  2.5877,  2.7326,  2.5815,
          2.5815,  1.2834,  1.2963,  1.2967,  1.3139,  1.2698,  1.3555,  1.2815,
          1.2727,  1.2493,  1.2677,  1.2502,  1.2637,  1.2793,  1.2427,  1.2347,
          1.2592,  1.2310,  1.2310,  1.2760,  1.3217,  1.2485,  1.2734,  1.3220,
          1.2599,  1.2862,  1.2107,  1.2510,  1.3763,  1.4155,  1.3983,  1.3848,
          1.3933,  1.3335,  1.3846,  1.3494,  1.3134,  1.3522,  1.3054,  1.2938,
          1.2780,  1.3474,  1.2991,  1.3831,  1.2707,  1.2815],
        [ 1.3165,  1.2204,  1.0465,  1.2586,  1.3465,  1.3667,  1.2880,  1.3595,
          1.3595,  1.7216,  1.9523,  1.7129,  2.4873,  1.7655,  5.3125,  1.8238,
          1.6541,  5.0981,  1.1590,  1.2331,  1.0378,  1.2062,  1.3411,  1.3762,
          1.3478,  1.3728,  1.3728,  1.3337,  1.0906,  1.3903,  1.3689,  1.1703,
          1.4019,  1.4251,  1.3528,  1.3859,  1.4512,  1.5508,  1.4793,  1.4167,
          1.4245,  1.5199,  1.4659,  0.6331,  1.4452,  1.0744,  1.4426,  1.4297,
          1.4144,  1.1013,  1.4351,  0.9232,  1.4069,  1.4183],
        [ 1.2292,  1.2565,  1.3138,  1.2917,  1.2621,  1.2341,  1.2419,  1.2270,
          1.2270,  1.2933,  1.3063,  1.3066,  1.3236,  1.2797,  1.3090,  1.2914,
          1.2622,  1.2302,  2.6443,  2.7315,  2.8635,  2.7781,  2.5175,  2.6229,
          2.6807,  2.5073,  2.5073,  1.3118,  1.2957,  1.2585,  1.2834,  1.3121,
          1.2700,  1.2962,  1.2661,  1.2610,  1.3862,  1.4254,  1.4079,  1.3723,
          1.4033,  1.3960,  1.3944,  1.2743,  1.3017,  1.3187,  1.3116,  1.3000,
          1.2840,  1.2784,  1.3052,  1.3496,  1.2763,  1.2872],
        [ 1.2349,  1.2626,  1.3051,  1.2829,  1.2684,  1.2399,  1.2482,  1.2328,
          1.2328,  1.2998,  1.2977,  1.3131,  1.3260,  1.2861,  1.2767,  1.2979,
          1.2884,  1.1957,  1.2838,  1.3068,  1.3246,  1.2954,  1.2585,  1.2469,
          1.2746,  1.2467,  1.2467,  2.9311,  2.7518,  2.4399,  2.5786,  2.9275,
          2.4499,  2.8839,  2.4509,  2.4421,  1.3911,  1.4307,  1.4080,  1.3951,
          1.4084,  1.3997,  1.3987,  1.2839,  1.3274,  1.3658,  1.3135,  1.2087,
          1.2429,  1.3608,  1.2932,  1.3972,  1.2352,  1.2934],
        [ 1.8126,  1.4669,  0.6726,  0.8910,  1.2667,  1.6957,  1.6282,  1.8102,
          1.8102,  1.7003,  1.3804,  1.5180,  1.0213,  1.8035,  0.3473,  1.6821,
          1.8325,  1.2303,  1.4094,  0.9636,  0.8393,  1.1868,  1.6708,  1.7392,
          1.4491,  1.8222,  1.8222,  0.7877,  0.9191,  1.7944,  1.5802,  0.8767,
          1.7257,  1.1826,  1.8466,  1.7613,  0.4467,  0.2257,  0.2082,  0.4015,
          0.6430,  0.7801,  0.3469, 11.5019,  7.3175,  0.8750,  1.3417,  1.4479,
          1.6892,  1.1181,  1.6131,  0.5080,  1.7531,  1.8619],
        [ 1.3070,  1.3343,  1.3915,  1.3701,  1.3407,  1.3120,  1.2750,  1.3049,
          1.3049,  1.2725,  1.3794,  1.2854,  1.3977,  1.3534,  1.4389,  1.2706,
          1.3563,  1.2845,  1.3507,  1.3779,  1.3920,  1.3618,  1.3253,  1.3168,
          1.2599,  1.3134,  1.3134,  1.3598,  1.4059,  1.3329,  1.1448,  1.3125,
          1.2064,  1.3704,  1.2049,  1.3354,  1.4576,  1.1627,  1.4790,  1.4662,
          1.0538,  0.9652,  1.4659,  1.4289,  0.8549,  3.1857,  2.5771,  3.3413,
          2.8365,  2.1987,  1.9113,  2.9308,  3.1203,  1.8965]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 212 : 181.77232680095983
Test loss for epoch 212 : 181.83571089360623
Test Precision for epoch 212 : 0.26153846153846155
Test Recall for epoch 212 : 0.26153846153846155
Test F1 for epoch 212 : 0.26153846153846155


theta for epoch 213 : tensor([[ 2.5728,  2.5980,  2.6635,  2.7740,  2.7412,  2.5772,  2.7224,  2.5710,
          2.5710,  1.2906,  1.3035,  1.3039,  1.3211,  1.2771,  1.3626,  1.2888,
          1.2799,  1.2568,  1.2772,  1.2598,  1.2731,  1.2886,  1.2522,  1.2442,
          1.2686,  1.2405,  1.2405,  1.2829,  1.3284,  1.2554,  1.2802,  1.3287,
          1.2668,  1.2931,  1.2178,  1.2579,  1.3799,  1.4191,  1.4019,  1.3885,
          1.3968,  1.3373,  1.3882,  1.3528,  1.3170,  1.3579,  1.3114,  1.2998,
          1.2841,  1.3532,  1.3051,  1.3886,  1.2767,  1.2875],
        [ 1.3111,  1.2152,  1.0416,  1.2535,  1.3415,  1.3614,  1.2826,  1.3542,
          1.3542,  1.7248,  1.9548,  1.7160,  2.4896,  1.7687,  5.3275,  1.8269,
          1.6573,  5.1137,  1.1590,  1.2333,  1.0380,  1.2063,  1.3414,  1.3766,
          1.3480,  1.3732,  1.3732,  1.3331,  1.0901,  1.3897,  1.3683,  1.1696,
          1.4014,  1.4247,  1.3522,  1.3855,  1.4506,  1.5498,  1.4782,  1.4158,
          1.4240,  1.5190,  1.4648,  0.6322,  1.4441,  1.0716,  1.4397,  1.4268,
          1.4115,  1.0982,  1.4322,  0.9211,  1.4039,  1.4154],
        [ 1.2233,  1.2507,  1.3082,  1.2860,  1.2564,  1.2283,  1.2362,  1.2212,
          1.2212,  1.2923,  1.3053,  1.3056,  1.3226,  1.2787,  1.3079,  1.2905,
          1.2609,  1.2295,  2.6512,  2.7391,  2.8710,  2.7850,  2.5245,  2.6300,
          2.6882,  2.5143,  2.5143,  1.3105,  1.2947,  1.2574,  1.2823,  1.3108,
          1.2689,  1.2952,  1.2651,  1.2599,  1.3846,  1.4240,  1.4064,  1.3705,
          1.4018,  1.3945,  1.3929,  1.2728,  1.2999,  1.3147,  1.3075,  1.2958,
          1.2798,  1.2745,  1.3010,  1.3457,  1.2721,  1.2830],
        [ 1.2306,  1.2583,  1.3016,  1.2794,  1.2642,  1.2357,  1.2439,  1.2285,
          1.2285,  1.2996,  1.2980,  1.3129,  1.3259,  1.2859,  1.2764,  1.2977,
          1.2883,  1.1961,  1.2843,  1.3073,  1.3251,  1.2959,  1.2590,  1.2476,
          1.2751,  1.2473,  1.2473,  2.9343,  2.7583,  2.4455,  2.5846,  2.9307,
          2.4554,  2.8872,  2.4565,  2.4476,  1.3899,  1.4296,  1.4071,  1.3942,
          1.4074,  1.3987,  1.3976,  1.2833,  1.3263,  1.3635,  1.3114,  1.2065,
          1.2406,  1.3585,  1.2916,  1.3950,  1.2329,  1.2912],
        [ 1.8095,  1.4635,  0.6692,  0.8876,  1.2630,  1.6925,  1.6249,  1.8071,
          1.8071,  1.7013,  1.3807,  1.5188,  1.0214,  1.8044,  0.3471,  1.6829,
          1.8337,  1.2296,  1.4106,  0.9645,  0.8398,  1.1878,  1.6723,  1.7406,
          1.4508,  1.8239,  1.8239,  0.7876,  0.9189,  1.7952,  1.5811,  0.8767,
          1.7265,  1.1827,  1.8475,  1.7620,  0.4465,  0.2252,  0.2080,  0.4011,
          0.6425,  0.7793,  0.3465, 11.5423,  7.3119,  0.8733,  1.3404,  1.4468,
          1.6882,  1.1162,  1.6115,  0.5058,  1.7523,  1.8610],
        [ 1.3057,  1.3330,  1.3901,  1.3687,  1.3393,  1.3107,  1.2738,  1.3036,
          1.3036,  1.2751,  1.3819,  1.2880,  1.4001,  1.3558,  1.4412,  1.2732,
          1.3587,  1.2871,  1.3545,  1.3818,  1.3959,  1.3657,  1.3292,  1.3207,
          1.2637,  1.3174,  1.3174,  1.3617,  1.4077,  1.3349,  1.1467,  1.3145,
          1.2085,  1.3723,  1.2070,  1.3374,  1.4581,  1.1633,  1.4795,  1.4667,
          1.0544,  0.9659,  1.4665,  1.4291,  0.8555,  3.1872,  2.5760,  3.3436,
          2.8360,  2.1971,  1.9094,  2.9305,  3.1216,  1.8946]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 213 : 181.79176567857718
Test loss for epoch 213 : 181.85953641597652
Test Precision for epoch 213 : 0.26153846153846155
Test Recall for epoch 213 : 0.26153846153846155
Test F1 for epoch 213 : 0.26153846153846155


theta for epoch 214 : tensor([[ 2.5958,  2.6208,  2.6861,  2.7970,  2.7643,  2.6001,  2.7456,  2.5939,
          2.5939,  1.2811,  1.2941,  1.2944,  1.3117,  1.2675,  1.3532,  1.2792,
          1.2704,  1.2470,  1.2617,  1.2441,  1.2576,  1.2732,  1.2367,  1.2288,
          1.2532,  1.2250,  1.2250,  1.2734,  1.3191,  1.2459,  1.2708,  1.3194,
          1.2573,  1.2837,  1.2080,  1.2484,  1.3741,  1.4135,  1.3962,  1.3828,
          1.3911,  1.3313,  1.3825,  1.3466,  1.3109,  1.3451,  1.2985,  1.2869,
          1.2712,  1.3404,  1.2923,  1.3760,  1.2638,  1.2747],
        [ 1.3227,  1.2265,  1.0526,  1.2649,  1.3531,  1.3729,  1.2942,  1.3657,
          1.3657,  1.7240,  1.9533,  1.7150,  2.4877,  1.7678,  5.3385,  1.8259,
          1.6565,  5.1250,  1.1547,  1.2290,  1.0347,  1.2019,  1.3368,  1.3719,
          1.3433,  1.3685,  1.3685,  1.3334,  1.0908,  1.3898,  1.3685,  1.1699,
          1.4014,  1.4248,  1.3523,  1.3857,  1.4520,  1.5508,  1.4792,  1.4170,
          1.4256,  1.5201,  1.4658,  0.6342,  1.4451,  1.0691,  1.4361,  1.4231,
          1.4078,  1.0953,  1.4286,  0.9196,  1.4002,  1.4117],
        [ 1.2386,  1.2657,  1.3228,  1.3008,  1.2713,  1.2435,  1.2512,  1.2364,
          1.2364,  1.2952,  1.3082,  1.3084,  1.3254,  1.2816,  1.3106,  1.2934,
          1.2636,  1.2329,  2.6458,  2.7345,  2.8665,  2.7797,  2.5192,  2.6246,
          2.6834,  2.5090,  2.5090,  1.3125,  1.2972,  1.2597,  1.2845,  1.3128,
          1.2712,  1.2974,  1.2673,  1.2622,  1.3873,  1.4268,  1.4092,  1.3731,
          1.4046,  1.3974,  1.3957,  1.2758,  1.3025,  1.3141,  1.3065,  1.2949,
          1.2789,  1.2742,  1.3000,  1.3452,  1.2711,  1.2820],
        [ 1.2399,  1.2675,  1.3106,  1.2884,  1.2734,  1.2449,  1.2532,  1.2378,
          1.2378,  1.2994,  1.2983,  1.3127,  1.3259,  1.2857,  1.2762,  1.2975,
          1.2881,  1.1967,  1.2796,  1.3029,  1.3204,  1.2912,  1.2543,  1.2430,
          1.2704,  1.2426,  1.2426,  2.9344,  2.7617,  2.4479,  2.5874,  2.9308,
          2.4578,  2.8874,  2.4588,  2.4500,  1.3908,  1.4306,  1.4082,  1.3952,
          1.4083,  1.3998,  1.3986,  1.2848,  1.3272,  1.3604,  1.3084,  1.2036,
          1.2374,  1.3554,  1.2891,  1.3920,  1.2297,  1.2879],
        [ 1.8178,  1.4717,  0.6748,  0.8939,  1.2710,  1.7009,  1.6332,  1.8154,
          1.8154,  1.7006,  1.3792,  1.5180,  1.0199,  1.8037,  0.3454,  1.6822,
          1.8334,  1.2272,  1.4062,  0.9602,  0.8352,  1.1834,  1.6682,  1.7363,
          1.4470,  1.8198,  1.8198,  0.7860,  0.9172,  1.7945,  1.5804,  0.8751,
          1.7257,  1.1811,  1.8468,  1.7611,  0.4466,  0.2252,  0.2080,  0.4011,
          0.6424,  0.7789,  0.3465, 11.5829,  7.3063,  0.8687,  1.3359,  1.4425,
          1.6840,  1.1113,  1.6069,  0.5010,  1.7484,  1.8570],
        [ 1.3228,  1.3499,  1.4066,  1.3854,  1.3562,  1.3277,  1.2909,  1.3207,
          1.3207,  1.2793,  1.3858,  1.2922,  1.4041,  1.3597,  1.4450,  1.2774,
          1.3625,  1.2914,  1.3537,  1.3809,  1.3951,  1.3649,  1.3283,  1.3199,
          1.2630,  1.3165,  1.3165,  1.3656,  1.4113,  1.3386,  1.1510,  1.3185,
          1.2127,  1.3761,  1.2113,  1.3412,  1.4616,  1.1676,  1.4830,  1.4703,
          1.0590,  0.9708,  1.4701,  1.4325,  0.8604,  3.1798,  2.5655,  3.3365,
          2.8262,  2.1862,  1.8982,  2.9214,  3.1134,  1.8834]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 214 : 181.8159087655115
Test loss for epoch 214 : 181.8901577749956
Test Precision for epoch 214 : 0.26153846153846155
Test Recall for epoch 214 : 0.26153846153846155
Test F1 for epoch 214 : 0.26153846153846155


theta for epoch 215 : tensor([[ 2.5810,  2.6062,  2.6716,  2.7827,  2.7500,  2.5853,  2.7312,  2.5791,
          2.5791,  1.2872,  1.3002,  1.3005,  1.3178,  1.2736,  1.3594,  1.2853,
          1.2765,  1.2533,  1.2742,  1.2567,  1.2700,  1.2857,  1.2492,  1.2413,
          1.2657,  1.2376,  1.2376,  1.2802,  1.3256,  1.2525,  1.2773,  1.3260,
          1.2639,  1.2904,  1.2148,  1.2550,  1.3782,  1.4176,  1.4003,  1.3869,
          1.3952,  1.3356,  1.3867,  1.3507,  1.3150,  1.3599,  1.3137,  1.3020,
          1.2865,  1.3553,  1.3075,  1.3906,  1.2791,  1.2900],
        [ 1.3071,  1.2115,  1.0391,  1.2498,  1.3378,  1.3572,  1.2786,  1.3500,
          1.3500,  1.7231,  1.9517,  1.7140,  2.4858,  1.7668,  5.3492,  1.8248,
          1.6556,  5.1362,  1.1619,  1.2362,  1.0420,  1.2090,  1.3438,  1.3789,
          1.3502,  1.3754,  1.3754,  1.3353,  1.0932,  1.3914,  1.3702,  1.1719,
          1.4030,  1.4265,  1.3539,  1.3875,  1.4537,  1.5519,  1.4803,  1.4185,
          1.4274,  1.5212,  1.4669,  0.6364,  1.4461,  1.0792,  1.4459,  1.4329,
          1.4176,  1.1054,  1.4384,  0.9287,  1.4100,  1.4216],
        [ 1.2188,  1.2460,  1.3033,  1.2812,  1.2517,  1.2238,  1.2316,  1.2167,
          1.2167,  1.2930,  1.3060,  1.3062,  1.3233,  1.2794,  1.3086,  1.2911,
          1.2611,  1.2311,  2.6544,  2.7438,  2.8757,  2.7883,  2.5280,  2.6334,
          2.6927,  2.5178,  2.5178,  1.3110,  1.2961,  1.2583,  1.2832,  1.3114,
          1.2698,  1.2962,  1.2660,  1.2608,  1.3862,  1.4257,  1.4081,  1.3716,
          1.4035,  1.3962,  1.3946,  1.2748,  1.3009,  1.3208,  1.3132,  1.3015,
          1.2856,  1.2811,  1.3068,  1.3518,  1.2778,  1.2887],
        [ 1.2265,  1.2541,  1.2983,  1.2762,  1.2600,  1.2315,  1.2397,  1.2243,
          1.2243,  1.3005,  1.2999,  1.3138,  1.3272,  1.2867,  1.2774,  1.2986,
          1.2891,  1.1985,  1.2859,  1.3091,  1.3266,  1.2975,  1.2606,  1.2494,
          1.2767,  1.2489,  1.2489,  2.9347,  2.7652,  2.4504,  2.5904,  2.9312,
          2.4604,  2.8878,  2.4613,  2.4526,  1.3918,  1.4316,  1.4093,  1.3963,
          1.4093,  1.4008,  1.3996,  1.2865,  1.3282,  1.3679,  1.3161,  1.2110,
          1.2451,  1.3629,  1.2970,  1.3993,  1.2374,  1.2957],
        [ 1.8056,  1.4599,  0.6666,  0.8848,  1.2595,  1.6888,  1.6212,  1.8032,
          1.8032,  1.7025,  1.3808,  1.5200,  1.0220,  1.8055,  0.3480,  1.6839,
          1.8354,  1.2281,  1.4120,  0.9663,  0.8410,  1.1892,  1.6740,  1.7418,
          1.4530,  1.8255,  1.8255,  0.7894,  0.9202,  1.7969,  1.5832,  0.8784,
          1.7282,  1.1840,  1.8492,  1.7635,  0.4441,  0.2226,  0.2057,  0.3985,
          0.6396,  0.7756,  0.3439, 11.6209,  7.2973,  0.8781,  1.3459,  1.4526,
          1.6936,  1.1212,  1.6162,  0.5101,  1.7581,  1.8662],
        [ 1.2991,  1.3261,  1.3829,  1.3616,  1.3325,  1.3040,  1.2670,  1.2970,
          1.2970,  1.2724,  1.3794,  1.2853,  1.3977,  1.3533,  1.4389,  1.2705,
          1.3561,  1.2845,  1.3517,  1.3789,  1.3931,  1.3629,  1.3263,  1.3178,
          1.2602,  1.3144,  1.3144,  1.3600,  1.4060,  1.3330,  1.1441,  1.3127,
          1.2065,  1.3706,  1.2049,  1.3355,  1.4576,  1.1621,  1.4792,  1.4664,
          1.0529,  0.9645,  1.4662,  1.4284,  0.8539,  3.2015,  2.5855,  3.3598,
          2.8466,  2.2055,  1.9175,  2.9411,  3.1360,  1.9027]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 215 : 181.80308911731882
Test loss for epoch 215 : 181.866873978386
Test Precision for epoch 215 : 0.26153846153846155
Test Recall for epoch 215 : 0.26153846153846155
Test F1 for epoch 215 : 0.26153846153846155


theta for epoch 216 : tensor([[ 2.5958,  2.6209,  2.6863,  2.7977,  2.7650,  2.6001,  2.7462,  2.5939,
          2.5939,  1.2833,  1.2964,  1.2966,  1.3141,  1.2697,  1.3557,  1.2814,
          1.2726,  1.2493,  1.2678,  1.2501,  1.2635,  1.2793,  1.2427,  1.2348,
          1.2592,  1.2311,  1.2311,  1.2756,  1.3211,  1.2478,  1.2727,  1.3216,
          1.2592,  1.2859,  1.2099,  1.2504,  1.3748,  1.4144,  1.3970,  1.3836,
          1.3918,  1.3321,  1.3834,  1.3470,  1.3114,  1.3446,  1.2983,  1.2866,
          1.2711,  1.3399,  1.2921,  1.3753,  1.2636,  1.2746],
        [ 1.3112,  1.2156,  1.0431,  1.2539,  1.3421,  1.3613,  1.2828,  1.3542,
          1.3542,  1.7246,  1.9526,  1.7154,  2.4862,  1.7683,  5.3622,  1.8262,
          1.6572,  5.1497,  1.1616,  1.2359,  1.0422,  1.2087,  1.3434,  1.3785,
          1.3498,  1.3750,  1.3750,  1.3362,  1.0944,  1.3922,  1.3711,  1.1728,
          1.4038,  1.4275,  1.3547,  1.3885,  1.4549,  1.5528,  1.4811,  1.4195,
          1.4288,  1.5222,  1.4677,  0.6377,  1.4469,  1.0702,  1.4357,  1.4227,
          1.4074,  1.0957,  1.4282,  0.9214,  1.3997,  1.4113],
        [ 1.2245,  1.2516,  1.3086,  1.2866,  1.2572,  1.2294,  1.2372,  1.2224,
          1.2224,  1.2961,  1.3091,  1.3093,  1.3264,  1.2825,  1.3114,  1.2942,
          1.2640,  1.2346,  2.6554,  2.7455,  2.8774,  2.7893,  2.5291,  2.6345,
          2.6943,  2.5189,  2.5189,  1.3126,  1.2980,  1.2601,  1.2849,  1.3129,
          1.2716,  1.2980,  1.2677,  1.2626,  1.3876,  1.4273,  1.4096,  1.3729,
          1.4050,  1.3978,  1.3961,  1.2765,  1.3022,  1.3103,  1.3024,  1.2907,
          1.2747,  1.2708,  1.2959,  1.3415,  1.2669,  1.2778],
        [ 1.2301,  1.2576,  1.3020,  1.2799,  1.2636,  1.2351,  1.2433,  1.2279,
          1.2279,  1.3022,  1.3021,  1.3155,  1.3290,  1.2885,  1.2791,  1.3003,
          1.2908,  1.2008,  1.2859,  1.3091,  1.3266,  1.2975,  1.2606,  1.2495,
          1.2766,  1.2488,  1.2488,  2.9361,  2.7699,  2.4542,  2.5946,  2.9326,
          2.4641,  2.8893,  2.4650,  2.4563,  1.3927,  1.4327,  1.4104,  1.3974,
          1.4103,  1.4020,  1.4006,  1.2879,  1.3292,  1.3598,  1.3082,  1.2033,
          1.2370,  1.3548,  1.2896,  1.3913,  1.2292,  1.2874],
        [ 1.8097,  1.4641,  0.6698,  0.8884,  1.2637,  1.6930,  1.6254,  1.8073,
          1.8073,  1.7046,  1.3823,  1.5219,  1.0234,  1.8074,  0.3493,  1.6858,
          1.8376,  1.2287,  1.4123,  0.9667,  0.8411,  1.1895,  1.6745,  1.7421,
          1.4539,  1.8261,  1.8261,  0.7909,  0.9214,  1.7986,  1.5852,  0.8798,
          1.7299,  1.1855,  1.8509,  1.7650,  0.4433,  0.2218,  0.2049,  0.3976,
          0.6386,  0.7743,  0.3430, 11.6606,  7.2899,  0.8708,  1.3379,  1.4446,
          1.6856,  1.1130,  1.6077,  0.5032,  1.7503,  1.8583],
        [ 1.3098,  1.3367,  1.3931,  1.3719,  1.3430,  1.3147,  1.2778,  1.3077,
          1.3077,  1.2804,  1.3872,  1.2934,  1.4055,  1.3609,  1.4465,  1.2786,
          1.3637,  1.2928,  1.3583,  1.3856,  1.4000,  1.3697,  1.3329,  1.3244,
          1.2670,  1.3210,  1.3210,  1.3667,  1.4123,  1.3395,  1.1512,  1.3195,
          1.2135,  1.3772,  1.2120,  1.3421,  1.4621,  1.1674,  1.4836,  1.4709,
          1.0586,  0.9705,  1.4707,  1.4327,  0.8598,  3.1910,  2.5718,  3.3494,
          2.8336,  2.1915,  1.9030,  2.9289,  3.1246,  1.8882]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 216 : 181.76282254765044
Test loss for epoch 216 : 181.8357458025556
Test Precision for epoch 216 : 0.26153846153846155
Test Recall for epoch 216 : 0.26153846153846155
Test F1 for epoch 216 : 0.26153846153846155


theta for epoch 217 : tensor([[ 2.6012,  2.6263,  2.6916,  2.8034,  2.7706,  2.6055,  2.7519,  2.5993,
          2.5993,  1.2807,  1.2939,  1.2941,  1.3116,  1.2672,  1.3532,  1.2789,
          1.2700,  1.2468,  1.2621,  1.2444,  1.2578,  1.2736,  1.2370,  1.2291,
          1.2535,  1.2253,  1.2253,  1.2734,  1.3189,  1.2456,  1.2704,  1.3194,
          1.2570,  1.2837,  1.2077,  1.2481,  1.3739,  1.4135,  1.3961,  1.3827,
          1.3908,  1.3311,  1.3824,  1.3459,  1.3103,  1.3473,  1.3011,  1.2894,
          1.2740,  1.3427,  1.2950,  1.3780,  1.2665,  1.2775],
        [ 1.3194,  1.2237,  1.0512,  1.2623,  1.3506,  1.3695,  1.2910,  1.3623,
          1.3623,  1.7240,  1.9512,  1.7146,  2.4844,  1.7676,  5.3731,  1.8254,
          1.6565,  5.1610,  1.1564,  1.2309,  1.0381,  1.2036,  1.3380,  1.3731,
          1.3443,  1.3696,  1.3696,  1.3351,  1.0937,  1.3908,  1.3697,  1.1717,
          1.4025,  1.4262,  1.3533,  1.3872,  1.4550,  1.5525,  1.4807,  1.4194,
          1.4291,  1.5219,  1.4673,  0.6384,  1.4465,  1.0736,  1.4386,  1.4255,
          1.4103,  1.0989,  1.4311,  0.9248,  1.4026,  1.4142],
        [ 1.2352,  1.2623,  1.3193,  1.2973,  1.2679,  1.2401,  1.2478,  1.2330,
          1.2330,  1.2959,  1.3090,  1.3092,  1.3263,  1.2824,  1.3113,  1.2941,
          1.2636,  1.2350,  2.6520,  2.7429,  2.8747,  2.7859,  2.5257,  2.6311,
          2.6915,  2.5155,  2.5155,  1.3124,  1.2983,  1.2602,  1.2850,  1.3128,
          1.2717,  1.2981,  1.2678,  1.2627,  1.3885,  1.4282,  1.4104,  1.3735,
          1.4059,  1.3988,  1.3970,  1.2777,  1.3028,  1.3161,  1.3080,  1.2963,
          1.2804,  1.2769,  1.3015,  1.3472,  1.2726,  1.2835],
        [ 1.2366,  1.2642,  1.3087,  1.2866,  1.2702,  1.2416,  1.2499,  1.2345,
          1.2345,  1.3002,  1.3006,  1.3135,  1.3273,  1.2865,  1.2772,  1.2984,
          1.2888,  1.1997,  1.2804,  1.3039,  1.3212,  1.2921,  1.2551,  1.2441,
          1.2711,  1.2433,  1.2433,  2.9365,  2.7734,  2.4568,  2.5976,  2.9330,
          2.4667,  2.8898,  2.4676,  2.4589,  1.3921,  1.4321,  1.4100,  1.3969,
          1.4097,  1.4015,  1.4001,  1.2879,  1.3286,  1.3617,  1.3103,  1.2053,
          1.2391,  1.3568,  1.2921,  1.3932,  1.2313,  1.2895],
        [ 1.8168,  1.4714,  0.6757,  0.8945,  1.2710,  1.7002,  1.6326,  1.8145,
          1.8145,  1.7038,  1.3810,  1.5211,  1.0224,  1.8065,  0.3488,  1.6849,
          1.8371,  1.2266,  1.4092,  0.9641,  0.8383,  1.1865,  1.6714,  1.7387,
          1.4512,  1.8229,  1.8229,  0.7904,  0.9206,  1.7978,  1.5845,  0.8792,
          1.7291,  1.1845,  1.8501,  1.7641,  0.4415,  0.2199,  0.2032,  0.3957,
          0.6365,  0.7718,  0.3412, 11.6995,  7.2813,  0.8739,  1.3413,  1.4481,
          1.6889,  1.1161,  1.6107,  0.5060,  1.7538,  1.8614],
        [ 1.3147,  1.3417,  1.3982,  1.3770,  1.3480,  1.3196,  1.2826,  1.3126,
          1.3126,  1.2743,  1.3813,  1.2873,  1.3996,  1.3551,  1.4407,  1.2725,
          1.3579,  1.2866,  1.3471,  1.3742,  1.3885,  1.3583,  1.3216,  1.3131,
          1.2552,  1.3097,  1.3097,  1.3612,  1.4070,  1.3341,  1.1451,  1.3141,
          1.2079,  1.3718,  1.2063,  1.3367,  1.4592,  1.1637,  1.4808,  1.4681,
          1.0545,  0.9663,  1.4678,  1.4296,  0.8556,  3.2026,  2.5814,  3.3622,
          2.8437,  2.2004,  1.9119,  2.9388,  3.1366,  1.8971]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 217 : 181.76540157075272
Test loss for epoch 217 : 181.83497268313707
Test Precision for epoch 217 : 0.26153846153846155
Test Recall for epoch 217 : 0.26153846153846155
Test F1 for epoch 217 : 0.26153846153846155


theta for epoch 218 : tensor([[ 2.5821,  2.6073,  2.6729,  2.7848,  2.7521,  2.5865,  2.7331,  2.5802,
          2.5802,  1.2899,  1.3031,  1.3032,  1.3207,  1.2764,  1.3622,  1.2880,
          1.2792,  1.2564,  1.2793,  1.2618,  1.2751,  1.2908,  1.2543,  1.2465,
          1.2707,  1.2427,  1.2427,  1.2830,  1.3281,  1.2551,  1.2798,  1.3286,
          1.2664,  1.2931,  1.2174,  1.2576,  1.3802,  1.4197,  1.4024,  1.3890,
          1.3971,  1.3378,  1.3888,  1.3522,  1.3168,  1.3619,  1.3158,  1.3041,
          1.2887,  1.3573,  1.3097,  1.3924,  1.2813,  1.2922],
        [ 1.3103,  1.2149,  1.0432,  1.2537,  1.3419,  1.3605,  1.2820,  1.3533,
          1.3533,  1.7255,  1.9521,  1.7160,  2.4849,  1.7691,  5.3860,  1.8268,
          1.6581,  5.1744,  1.1607,  1.2352,  1.0424,  1.2078,  1.3425,  1.3776,
          1.3487,  1.3741,  1.3741,  1.3338,  1.0926,  1.3895,  1.3684,  1.1703,
          1.4011,  1.4249,  1.3519,  1.3861,  1.4544,  1.5515,  1.4797,  1.4186,
          1.4286,  1.5209,  1.4662,  0.6378,  1.4453,  1.0770,  1.4420,  1.4289,
          1.4137,  1.1022,  1.4346,  0.9280,  1.4060,  1.4176],
        [ 1.2221,  1.2494,  1.3068,  1.2847,  1.2551,  1.2271,  1.2349,  1.2200,
          1.2200,  1.2896,  1.3027,  1.3029,  1.3201,  1.2760,  1.3053,  1.2878,
          1.2569,  1.2289,  2.6642,  2.7558,  2.8875,  2.7981,  2.5382,  2.6435,
          2.7044,  2.5280,  2.5280,  1.3076,  1.2938,  1.2556,  1.2804,  1.3079,
          1.2671,  1.2936,  1.2632,  1.2581,  1.3848,  1.4247,  1.4068,  1.3696,
          1.4023,  1.3952,  1.3934,  1.2741,  1.2988,  1.3154,  1.3073,  1.2955,
          1.2796,  1.2762,  1.3008,  1.3466,  1.2717,  1.2827],
        [ 1.2288,  1.2565,  1.3020,  1.2799,  1.2625,  1.2339,  1.2421,  1.2266,
          1.2266,  1.2983,  1.2992,  1.3117,  1.3255,  1.2847,  1.2753,  1.2965,
          1.2870,  1.1985,  1.2844,  1.3079,  1.3251,  1.2960,  1.2592,  1.2483,
          1.2751,  1.2474,  1.2474,  2.9388,  2.7789,  2.4613,  2.6026,  2.9354,
          2.4713,  2.8922,  2.4721,  2.4635,  1.3908,  1.4309,  1.4089,  1.3958,
          1.4084,  1.4002,  1.3988,  1.2870,  1.3272,  1.3642,  1.3129,  1.2078,
          1.2416,  1.3593,  1.2951,  1.3957,  1.2338,  1.2921],
        [ 1.8100,  1.4642,  0.6692,  0.8878,  1.2635,  1.6932,  1.6256,  1.8076,
          1.8076,  1.7030,  1.3794,  1.5201,  1.0208,  1.8057,  0.3470,  1.6840,
          1.8366,  1.2241,  1.4126,  0.9670,  0.8407,  1.1896,  1.6753,  1.7424,
          1.4551,  1.8269,  1.8269,  0.7888,  0.9188,  1.7971,  1.5837,  0.8775,
          1.7283,  1.1828,  1.8495,  1.7632,  0.4413,  0.2195,  0.2029,  0.3954,
          0.6362,  0.7711,  0.3408, 11.7398,  7.2740,  0.8759,  1.3444,  1.4516,
          1.6925,  1.1186,  1.6138,  0.5072,  1.7576,  1.8651],
        [ 1.3053,  1.3324,  1.3892,  1.3679,  1.3388,  1.3103,  1.2732,  1.3032,
          1.3032,  1.2717,  1.3788,  1.2847,  1.3971,  1.3526,  1.4381,  1.2699,
          1.3554,  1.2839,  1.3521,  1.3792,  1.3935,  1.3634,  1.3266,  1.3182,
          1.2599,  1.3148,  1.3148,  1.3590,  1.4048,  1.3320,  1.1425,  1.3119,
          1.2056,  1.3697,  1.2040,  1.3345,  1.4576,  1.1617,  1.4792,  1.4665,
          1.0523,  0.9641,  1.4663,  1.4278,  0.8533,  3.2113,  2.5880,  3.3720,
          2.8508,  2.2064,  1.9178,  2.9457,  3.1455,  1.9030]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 218 : 181.79473478809635
Test loss for epoch 218 : 181.8637970672283
Test Precision for epoch 218 : 0.26153846153846155
Test Recall for epoch 218 : 0.26153846153846155
Test F1 for epoch 218 : 0.26153846153846155


theta for epoch 219 : tensor([[ 2.6026,  2.6278,  2.6931,  2.8054,  2.7727,  2.6069,  2.7539,  2.6007,
          2.6007,  1.2821,  1.2953,  1.2954,  1.3130,  1.2686,  1.3546,  1.2803,
          1.2713,  1.2483,  1.2658,  1.2481,  1.2615,  1.2773,  1.2408,  1.2330,
          1.2573,  1.2292,  1.2292,  1.2743,  1.3196,  1.2464,  1.2712,  1.3203,
          1.2578,  1.2846,  1.2086,  1.2489,  1.3737,  1.4134,  1.3960,  1.3825,
          1.3907,  1.3311,  1.3823,  1.3453,  1.3101,  1.3478,  1.3015,  1.2898,
          1.2743,  1.3432,  1.2954,  1.3785,  1.2668,  1.2778],
        [ 1.3191,  1.2235,  1.0515,  1.2624,  1.3508,  1.3693,  1.2907,  1.3621,
          1.3621,  1.7267,  1.9526,  1.7171,  2.4848,  1.7702,  5.3984,  1.8278,
          1.6593,  5.1873,  1.1561,  1.2307,  1.0387,  1.2032,  1.3377,  1.3728,
          1.3438,  1.3693,  1.3693,  1.3337,  1.0928,  1.3893,  1.3683,  1.1702,
          1.4009,  1.4248,  1.3517,  1.3860,  1.4545,  1.5511,  1.4792,  1.4184,
          1.4289,  1.5206,  1.4658,  0.6382,  1.4449,  1.0716,  1.4356,  1.4225,
          1.4072,  1.0962,  1.4282,  0.9239,  1.3995,  1.4112],
        [ 1.2348,  1.2620,  1.3190,  1.2970,  1.2676,  1.2398,  1.2475,  1.2327,
          1.2327,  1.2937,  1.3069,  1.3070,  1.3242,  1.2802,  1.3092,  1.2920,
          1.2609,  1.2336,  2.6598,  2.7523,  2.8839,  2.7937,  2.5339,  2.6392,
          2.7007,  2.5237,  2.5237,  1.3098,  1.2965,  1.2581,  1.2829,  1.3102,
          1.2696,  1.2961,  1.2657,  1.2606,  1.3865,  1.4264,  1.4085,  1.3710,
          1.4040,  1.3970,  1.3951,  1.2761,  1.3003,  1.3125,  1.3039,  1.2921,
          1.2762,  1.2736,  1.2974,  1.3437,  1.2683,  1.2793],
        [ 1.2365,  1.2641,  1.3094,  1.2873,  1.2700,  1.2415,  1.2498,  1.2343,
          1.2343,  1.2990,  1.3002,  1.3123,  1.3263,  1.2853,  1.2760,  1.2972,
          1.2876,  1.1998,  1.2802,  1.3038,  1.3209,  1.2918,  1.2549,  1.2442,
          1.2709,  1.2431,  1.2431,  2.9398,  2.7830,  2.4645,  2.6062,  2.9364,
          2.4744,  2.8932,  2.4752,  2.4666,  1.3905,  1.4307,  1.4087,  1.3955,
          1.4081,  1.4001,  1.3985,  1.2872,  1.3269,  1.3593,  1.3081,  1.2030,
          1.2365,  1.3544,  1.2907,  1.3909,  1.2287,  1.2870],
        [ 1.8174,  1.4715,  0.6741,  0.8935,  1.2706,  1.7007,  1.6330,  1.8151,
          1.8151,  1.7035,  1.3791,  1.5204,  1.0203,  1.8062,  0.3461,  1.6843,
          1.8374,  1.2227,  1.4089,  0.9634,  0.8366,  1.1858,  1.6719,  1.7389,
          1.4520,  1.8237,  1.8237,  0.7877,  0.9175,  1.7970,  1.5836,  0.8765,
          1.7281,  1.1819,  1.8494,  1.7629,  0.4411,  0.2191,  0.2026,  0.3950,
          0.6358,  0.7703,  0.3404, 11.7801,  7.2664,  0.8698,  1.3383,  1.4457,
          1.6867,  1.1120,  1.6076,  0.5010,  1.7522,  1.8595],
        [ 1.3213,  1.3483,  1.4048,  1.3836,  1.3546,  1.3262,  1.2893,  1.3192,
          1.3192,  1.2799,  1.3866,  1.2929,  1.4049,  1.3603,  1.4457,  1.2781,
          1.3631,  1.2923,  1.3554,  1.3825,  1.3969,  1.3668,  1.3300,  1.3216,
          1.2636,  1.3181,  1.3181,  1.3656,  1.4111,  1.3385,  1.1498,  1.3187,
          1.2128,  1.3762,  1.2112,  1.3410,  1.4616,  1.1668,  1.4832,  1.4705,
          1.0578,  0.9700,  1.4703,  1.4316,  0.8592,  3.1998,  2.5734,  3.3605,
          2.8368,  2.1916,  1.9025,  2.9325,  3.1331,  1.8877]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 219 : 181.76420585024636
Test loss for epoch 219 : 181.842740737763
Test Precision for epoch 219 : 0.26153846153846155
Test Recall for epoch 219 : 0.26153846153846155
Test F1 for epoch 219 : 0.26153846153846155


theta for epoch 220 : tensor([[ 2.6040,  2.6292,  2.6946,  2.8071,  2.7744,  2.6083,  2.7555,  2.6021,
          2.6021,  1.2807,  1.2941,  1.2941,  1.3118,  1.2672,  1.3534,  1.2789,
          1.2699,  1.2471,  1.2655,  1.2477,  1.2612,  1.2771,  1.2404,  1.2326,
          1.2569,  1.2288,  1.2288,  1.2737,  1.3191,  1.2457,  1.2705,  1.3197,
          1.2571,  1.2840,  1.2078,  1.2482,  1.3721,  1.4120,  1.3945,  1.3811,
          1.3892,  1.3296,  1.3809,  1.3436,  1.3085,  1.3526,  1.3064,  1.2946,
          1.2792,  1.3481,  1.3003,  1.3833,  1.2716,  1.2827],
        [ 1.3134,  1.2182,  1.0471,  1.2570,  1.3454,  1.3636,  1.2851,  1.3564,
          1.3564,  1.7249,  1.9500,  1.7151,  2.4817,  1.7683,  5.4077,  1.8258,
          1.6575,  5.1969,  1.1591,  1.2338,  1.0424,  1.2062,  1.3403,  1.3754,
          1.3464,  1.3718,  1.3718,  1.3356,  1.0954,  1.3908,  1.3699,  1.1723,
          1.4024,  1.4265,  1.3532,  1.3877,  1.4555,  1.5516,  1.4797,  1.4192,
          1.4301,  1.5211,  1.4663,  0.6402,  1.4453,  1.0804,  1.4436,  1.4305,
          1.4152,  1.1049,  1.4362,  0.9320,  1.4075,  1.4192],
        [ 1.2286,  1.2557,  1.3127,  1.2907,  1.2614,  1.2335,  1.2413,  1.2265,
          1.2265,  1.2946,  1.3078,  1.3079,  1.3252,  1.2810,  1.3101,  1.2928,
          1.2615,  1.2351,  2.6607,  2.7539,  2.8855,  2.7945,  2.5350,  2.6401,
          2.7023,  2.5248,  2.5248,  1.3108,  1.2979,  1.2592,  1.2840,  1.3112,
          1.2707,  1.2973,  1.2668,  1.2617,  1.3865,  1.4265,  1.4086,  1.3708,
          1.4040,  1.3971,  1.3952,  1.2765,  1.3001,  1.3211,  1.3124,  1.3006,
          1.2847,  1.2825,  1.3059,  1.3523,  1.2768,  1.2878],
        [ 1.2313,  1.2590,  1.3049,  1.2828,  1.2649,  1.2363,  1.2446,  1.2292,
          1.2292,  1.2999,  1.3016,  1.3133,  1.3275,  1.2863,  1.2771,  1.2981,
          1.2885,  1.2014,  1.2823,  1.3060,  1.3231,  1.2940,  1.2570,  1.2463,
          1.2730,  1.2452,  1.2452,  2.9393,  2.7856,  2.4660,  2.6082,  2.9359,
          2.4760,  2.8927,  2.4768,  2.4682,  1.3908,  1.4310,  1.4091,  1.3960,
          1.4084,  1.4004,  1.3989,  1.2881,  1.3272,  1.3654,  1.3144,  1.2091,
          1.2429,  1.3605,  1.2972,  1.3969,  1.2350,  1.2933],
        [ 1.8134,  1.4680,  0.6727,  0.8916,  1.2675,  1.6969,  1.6293,  1.8110,
          1.8110,  1.7052,  1.3806,  1.5222,  1.0223,  1.8077,  0.3489,  1.6858,
          1.8392,  1.2235,  1.4115,  0.9666,  0.8397,  1.1887,  1.6743,  1.7411,
          1.4550,  1.8260,  1.8260,  0.7914,  0.9206,  1.7993,  1.5863,  0.8800,
          1.7305,  1.1849,  1.8516,  1.7651,  0.4377,  0.2157,  0.1994,  0.3916,
          0.6321,  0.7662,  0.3370, 11.8174,  7.2548,  0.8779,  1.3467,  1.4540,
          1.6946,  1.1203,  1.6153,  0.5090,  1.7601,  1.8670],
        [ 1.3081,  1.3351,  1.3917,  1.3705,  1.3414,  1.3130,  1.2759,  1.3060,
          1.3060,  1.2736,  1.3808,  1.2867,  1.3991,  1.3544,  1.4401,  1.2718,
          1.3572,  1.2861,  1.3491,  1.3763,  1.3906,  1.3604,  1.3236,  1.3152,
          1.2565,  1.3117,  1.3117,  1.3607,  1.4064,  1.3335,  1.1437,  1.3136,
          1.2072,  1.3713,  1.2055,  1.3360,  1.4572,  1.1610,  1.4789,  1.4662,
          1.0516,  0.9635,  1.4660,  1.4271,  0.8527,  3.2174,  2.5892,  3.3794,
          2.8530,  2.2067,  1.9176,  2.9483,  3.1512,  1.9028]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 220 : 181.73683031940428
Test loss for epoch 220 : 181.8059527247626
Test Precision for epoch 220 : 0.26153846153846155
Test Recall for epoch 220 : 0.26153846153846155
Test F1 for epoch 220 : 0.26153846153846155


theta for epoch 221 : tensor([[ 2.5983,  2.6235,  2.6890,  2.8017,  2.7691,  2.6026,  2.7501,  2.5964,
          2.5964,  1.2851,  1.2986,  1.2985,  1.3163,  1.2716,  1.3579,  1.2834,
          1.2744,  1.2517,  1.2745,  1.2568,  1.2701,  1.2860,  1.2495,  1.2416,
          1.2659,  1.2378,  1.2378,  1.2785,  1.3237,  1.2504,  1.2752,  1.3244,
          1.2618,  1.2888,  1.2126,  1.2529,  1.3758,  1.4157,  1.3982,  1.3847,
          1.3928,  1.3334,  1.3846,  1.3472,  1.3122,  1.3510,  1.3048,  1.2931,
          1.2776,  1.3465,  1.2987,  1.3818,  1.2701,  1.2811],
        [ 1.3071,  1.2122,  1.0418,  1.2510,  1.3394,  1.3573,  1.2789,  1.3501,
          1.3501,  1.7258,  1.9502,  1.7158,  2.4812,  1.7691,  5.4195,  1.8265,
          1.6584,  5.2092,  1.1645,  1.2393,  1.0480,  1.2115,  1.3458,  1.3808,
          1.3516,  1.3772,  1.3772,  1.3369,  1.0970,  1.3918,  1.3710,  1.1735,
          1.4035,  1.4277,  1.3543,  1.3889,  1.4571,  1.5529,  1.4809,  1.4207,
          1.4320,  1.5224,  1.4675,  0.6421,  1.4464,  1.0769,  1.4392,  1.4261,
          1.4108,  1.1009,  1.4318,  0.9295,  1.4031,  1.4148],
        [ 1.2191,  1.2463,  1.3034,  1.2814,  1.2520,  1.2241,  1.2319,  1.2170,
          1.2170,  1.2924,  1.3057,  1.3057,  1.3232,  1.2788,  1.3081,  1.2907,
          1.2590,  1.2333,  2.6699,  2.7639,  2.8953,  2.8037,  2.5444,  2.6495,
          2.7122,  2.5342,  2.5342,  1.3092,  1.2966,  1.2577,  1.2825,  1.3095,
          1.2692,  1.2959,  1.2654,  1.2602,  1.3857,  1.4258,  1.4078,  1.3697,
          1.4033,  1.3964,  1.3944,  1.2759,  1.2989,  1.3123,  1.3035,  1.2916,
          1.2758,  1.2739,  1.2970,  1.3436,  1.2678,  1.2789],
        [ 1.2259,  1.2536,  1.3002,  1.2781,  1.2595,  1.2309,  1.2392,  1.2237,
          1.2237,  1.3007,  1.3029,  1.3141,  1.3285,  1.2871,  1.2780,  1.2990,
          1.2893,  1.2028,  1.2874,  1.3110,  1.3280,  1.2990,  1.2620,  1.2514,
          1.2780,  1.2502,  1.2502,  2.9408,  2.7902,  2.4697,  2.6124,  2.9374,
          2.4797,  2.8943,  2.4804,  2.4719,  1.3919,  1.4323,  1.4105,  1.3973,
          1.4096,  1.4017,  1.4001,  1.2897,  1.3284,  1.3616,  1.3107,  1.2056,
          1.2391,  1.3567,  1.2939,  1.3931,  1.2312,  1.2895],
        [ 1.8087,  1.4631,  0.6685,  0.8873,  1.2625,  1.6921,  1.6245,  1.8063,
          1.8063,  1.7063,  1.3811,  1.5231,  1.0226,  1.8087,  0.3490,  1.6868,
          1.8406,  1.2229,  1.4152,  0.9701,  0.8428,  1.1922,  1.6785,  1.7450,
          1.4591,  1.8302,  1.8302,  0.7923,  0.9212,  1.8007,  1.5878,  0.8809,
          1.7319,  1.1859,  1.8531,  1.7664,  0.4374,  0.2153,  0.1991,  0.3912,
          0.6316,  0.7653,  0.3366, 11.8574,  7.2462,  0.8742,  1.3430,  1.4505,
          1.6910,  1.1163,  1.6114,  0.5053,  1.7568,  1.8636],
        [ 1.3020,  1.3290,  1.3858,  1.3645,  1.3353,  1.3069,  1.2699,  1.2999,
          1.2999,  1.2754,  1.3827,  1.2885,  1.4010,  1.3562,  1.4419,  1.2736,
          1.3590,  1.2880,  1.3564,  1.3835,  1.3981,  1.3678,  1.3309,  1.3225,
          1.2636,  1.3190,  1.3190,  1.3626,  1.4082,  1.3354,  1.1454,  1.3155,
          1.2092,  1.3733,  1.2074,  1.3379,  1.4589,  1.1626,  1.4805,  1.4679,
          1.0531,  0.9651,  1.4677,  1.4285,  0.8541,  3.2188,  2.5881,  3.3815,
          2.8525,  2.2051,  1.9158,  2.9480,  3.1524,  1.9010]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 221 : 181.7470016716576
Test loss for epoch 221 : 181.81876132366787
Test Precision for epoch 221 : 0.26153846153846155
Test Recall for epoch 221 : 0.26153846153846155
Test F1 for epoch 221 : 0.26153846153846155


theta for epoch 222 : tensor([[ 2.6110,  2.6362,  2.7016,  2.8147,  2.7820,  2.6153,  2.7631,  2.6091,
          2.6091,  1.2811,  1.2946,  1.2946,  1.3124,  1.2676,  1.3540,  1.2794,
          1.2703,  1.2476,  1.2611,  1.2433,  1.2568,  1.2727,  1.2360,  1.2282,
          1.2525,  1.2244,  1.2244,  1.2736,  1.3189,  1.2455,  1.2704,  1.3197,
          1.2569,  1.2840,  1.2076,  1.2480,  1.3742,  1.4142,  1.3967,  1.3832,
          1.3913,  1.3318,  1.3830,  1.3453,  1.3106,  1.3441,  1.2977,  1.2859,
          1.2705,  1.3395,  1.2916,  1.3750,  1.2628,  1.2739],
        [ 1.3166,  1.2215,  1.0509,  1.2606,  1.3491,  1.3668,  1.2884,  1.3596,
          1.3596,  1.7270,  1.9507,  1.7169,  2.4811,  1.7702,  5.4316,  1.8275,
          1.6597,  5.2217,  1.1547,  1.2296,  1.0395,  1.2018,  1.3357,  1.3707,
          1.3416,  1.3671,  1.3671,  1.3359,  1.0964,  1.3907,  1.3700,  1.1725,
          1.4023,  1.4266,  1.3531,  1.3879,  1.4583,  1.5536,  1.4815,  1.4216,
          1.4334,  1.5232,  1.4681,  0.6433,  1.4470,  1.0742,  1.4359,  1.4227,
          1.4074,  1.0978,  1.4285,  0.9277,  1.3996,  1.4114],
        [ 1.2330,  1.2602,  1.3171,  1.2952,  1.2658,  1.2380,  1.2458,  1.2309,
          1.2309,  1.2962,  1.3095,  1.3095,  1.3270,  1.2826,  1.3116,  1.2944,
          1.2625,  1.2377,  2.6629,  2.7578,  2.8891,  2.7967,  2.5376,  2.6425,
          2.7059,  2.5273,  2.5273,  1.3111,  1.2990,  1.2599,  1.2847,  1.3114,
          1.2714,  1.2981,  1.2675,  1.2624,  1.3891,  1.4292,  1.4112,  1.3728,
          1.4066,  1.3998,  1.3978,  1.2795,  1.3020,  1.3138,  1.3047,  1.2929,
          1.2770,  1.2757,  1.2982,  1.3451,  1.2691,  1.2801],
        [ 1.2341,  1.2618,  1.3083,  1.2862,  1.2677,  1.2392,  1.2474,  1.2320,
          1.2320,  1.3003,  1.3029,  1.3137,  1.3283,  1.2867,  1.2777,  1.2986,
          1.2889,  1.2031,  1.2780,  1.3019,  1.3187,  1.2897,  1.2526,  1.2421,
          1.2686,  1.2408,  1.2408,  2.9419,  2.7943,  2.4730,  2.6160,  2.9386,
          2.4829,  2.8955,  2.4836,  2.4751,  1.3927,  1.4332,  1.4115,  1.3982,
          1.4105,  1.4027,  1.4010,  1.2909,  1.3292,  1.3589,  1.3082,  1.2031,
          1.2365,  1.3541,  1.2918,  1.3905,  1.2285,  1.2868],
        [ 1.8170,  1.4713,  0.6741,  0.8935,  1.2704,  1.7004,  1.6327,  1.8146,
          1.8146,  1.7061,  1.3802,  1.5228,  1.0216,  1.8086,  0.3477,  1.6865,
          1.8408,  1.2210,  1.4082,  0.9634,  0.8356,  1.1851,  1.6716,  1.7379,
          1.4527,  1.8234,  1.8234,  0.7907,  0.9194,  1.7998,  1.5869,  0.8793,
          1.7310,  1.1842,  1.8523,  1.7654,  0.4376,  0.2153,  0.1992,  0.3912,
          0.6317,  0.7650,  0.3367, 11.8979,  7.2378,  0.8707,  1.3400,  1.4477,
          1.6883,  1.1126,  1.6082,  0.5016,  1.7543,  1.8610],
        [ 1.3134,  1.3405,  1.3974,  1.3761,  1.3469,  1.3183,  1.2813,  1.3113,
          1.3113,  1.2776,  1.3848,  1.2907,  1.4031,  1.3582,  1.4439,  1.2759,
          1.3610,  1.2903,  1.3479,  1.3749,  1.3893,  1.3592,  1.3224,  1.3140,
          1.2551,  1.3105,  1.3105,  1.3637,  1.4092,  1.3365,  1.1465,  1.3167,
          1.2104,  1.3744,  1.2087,  1.3390,  1.4613,  1.1652,  1.4830,  1.4704,
          1.0558,  0.9679,  1.4702,  1.4308,  0.8568,  3.2178,  2.5846,  3.3811,
          2.8495,  2.2012,  1.9115,  2.9453,  3.1511,  1.8967]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 222 : 181.74165504405806
Test loss for epoch 222 : 181.81869935372697
Test Precision for epoch 222 : 0.26153846153846155
Test Recall for epoch 222 : 0.26153846153846155
Test F1 for epoch 222 : 0.26153846153846155


theta for epoch 223 : tensor([[ 2.6043,  2.6295,  2.6950,  2.8083,  2.7756,  2.6086,  2.7567,  2.6024,
          2.6024,  1.2829,  1.2964,  1.2963,  1.3142,  1.2694,  1.3558,  1.2812,
          1.2721,  1.2497,  1.2696,  1.2518,  1.2652,  1.2811,  1.2445,  1.2367,
          1.2609,  1.2329,  1.2329,  1.2761,  1.3212,  1.2479,  1.2728,  1.3220,
          1.2593,  1.2864,  1.2101,  1.2504,  1.3757,  1.4157,  1.3982,  1.3847,
          1.3928,  1.3336,  1.3846,  1.3468,  1.3122,  1.3538,  1.3074,  1.2956,
          1.2801,  1.3493,  1.3012,  1.3847,  1.2725,  1.2836],
        [ 1.3152,  1.2203,  1.0503,  1.2596,  1.3481,  1.3654,  1.2870,  1.3582,
          1.3582,  1.7263,  1.9493,  1.7160,  2.4791,  1.7695,  5.4417,  1.8266,
          1.6590,  5.2323,  1.1583,  1.2332,  1.0434,  1.2053,  1.3392,  1.3741,
          1.3449,  1.3705,  1.3705,  1.3343,  1.0953,  1.3889,  1.3682,  1.1710,
          1.4005,  1.4249,  1.3512,  1.3862,  1.4573,  1.5522,  1.4800,  1.4204,
          1.4326,  1.5218,  1.4666,  0.6431,  1.4454,  1.0806,  1.4417,  1.4285,
          1.4133,  1.1039,  1.4344,  0.9336,  1.4055,  1.4173],
        [ 1.2280,  1.2552,  1.3124,  1.2904,  1.2609,  1.2329,  1.2408,  1.2258,
          1.2258,  1.2892,  1.3027,  1.3026,  1.3202,  1.2757,  1.3053,  1.2875,
          1.2553,  1.2312,  2.6717,  2.7673,  2.8984,  2.8053,  2.5465,  2.6514,
          2.7153,  2.5363,  2.5363,  1.3061,  1.2944,  1.2550,  1.2798,  1.3064,
          1.2665,  1.2934,  1.2627,  1.2575,  1.3851,  1.4254,  1.4073,  1.3686,
          1.4027,  1.3959,  1.3939,  1.2759,  1.2977,  1.3166,  1.3074,  1.2955,
          1.2796,  1.2786,  1.3009,  1.3479,  1.2716,  1.2828],
        [ 1.2326,  1.2603,  1.3074,  1.2853,  1.2663,  1.2376,  1.2459,  1.2304,
          1.2304,  1.2975,  1.3005,  1.3110,  1.3257,  1.2839,  1.2750,  1.2958,
          1.2861,  1.2010,  1.2807,  1.3047,  1.3214,  1.2924,  1.2554,  1.2450,
          1.2713,  1.2436,  1.2436,  2.9425,  2.7979,  2.4755,  2.6190,  2.9392,
          2.4855,  2.8961,  2.4862,  2.4777,  1.3908,  1.4313,  1.4097,  1.3964,
          1.4085,  1.4008,  1.3991,  1.2894,  1.3273,  1.3633,  1.3127,  1.2074,
          1.2409,  1.3585,  1.2965,  1.3948,  1.2329,  1.2913],
        [ 1.8168,  1.4712,  0.6744,  0.8938,  1.2703,  1.7002,  1.6326,  1.8144,
          1.8144,  1.7050,  1.3787,  1.5217,  1.0204,  1.8073,  0.3473,  1.6852,
          1.8399,  1.2185,  1.4115,  0.9670,  0.8389,  1.1885,  1.6750,  1.7411,
          1.4564,  1.8268,  1.8268,  0.7905,  0.9186,  1.7989,  1.5861,  0.8789,
          1.7300,  1.1834,  1.8513,  1.7643,  0.4350,  0.2127,  0.1967,  0.3886,
          0.6289,  0.7618,  0.3340, 11.9361,  7.2264,  0.8763,  1.3462,  1.4540,
          1.6944,  1.1185,  1.6141,  0.5068,  1.7605,  1.8669],
        [ 1.3085,  1.3357,  1.3930,  1.3715,  1.3421,  1.3134,  1.2764,  1.3063,
          1.3063,  1.2714,  1.3788,  1.2845,  1.3971,  1.3523,  1.4380,  1.2696,
          1.3550,  1.2840,  1.3485,  1.3755,  1.3899,  1.3598,  1.3230,  1.3147,
          1.2552,  1.3111,  1.3111,  1.3585,  1.4041,  1.3312,  1.1407,  1.3114,
          1.2050,  1.3693,  1.2032,  1.3338,  1.4576,  1.1607,  1.4793,  1.4667,
          1.0510,  0.9630,  1.4666,  1.4269,  0.8520,  3.2293,  2.5941,  3.3937,
          2.8595,  2.2101,  1.9204,  2.9551,  3.1629,  1.9056]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 223 : 181.71908074747893
Test loss for epoch 223 : 181.79174923704784
Test Precision for epoch 223 : 0.26153846153846155
Test Recall for epoch 223 : 0.26153846153846155
Test F1 for epoch 223 : 0.26153846153846155


theta for epoch 224 : tensor([[ 2.6054,  2.6307,  2.6962,  2.8097,  2.7771,  2.6098,  2.7581,  2.6036,
          2.6036,  1.2838,  1.2974,  1.2973,  1.3152,  1.2703,  1.3567,  1.2821,
          1.2730,  1.2507,  1.2735,  1.2557,  1.2691,  1.2851,  1.2484,  1.2406,
          1.2648,  1.2367,  1.2367,  1.2767,  1.3218,  1.2485,  1.2734,  1.3226,
          1.2599,  1.2870,  1.2107,  1.2510,  1.3745,  1.4147,  1.3971,  1.3836,
          1.3918,  1.3326,  1.3835,  1.3455,  1.3112,  1.3514,  1.3048,  1.2929,
          1.2774,  1.3467,  1.2985,  1.3824,  1.2697,  1.2808],
        [ 1.3130,  1.2181,  1.0484,  1.2575,  1.3462,  1.3633,  1.2848,  1.3560,
          1.3560,  1.7286,  1.9509,  1.7182,  2.4800,  1.7717,  5.4546,  1.8287,
          1.6613,  5.2457,  1.1604,  1.2355,  1.0459,  1.2074,  1.3414,  1.3764,
          1.3470,  1.3727,  1.3727,  1.3335,  1.0949,  1.3880,  1.3674,  1.1702,
          1.3997,  1.4242,  1.3504,  1.3855,  1.4558,  1.5503,  1.4781,  1.4187,
          1.4314,  1.5200,  1.4646,  0.6419,  1.4434,  1.0775,  1.4381,  1.4249,
          1.4096,  1.1004,  1.4308,  0.9314,  1.4017,  1.4136],
        [ 1.2261,  1.2533,  1.3106,  1.2886,  1.2590,  1.2310,  1.2389,  1.2239,
          1.2239,  1.2887,  1.3022,  1.3021,  1.3197,  1.2752,  1.3048,  1.2870,
          1.2545,  1.2312,  2.6765,  2.7729,  2.9039,  2.8100,  2.5516,  2.6564,
          2.7209,  2.5414,  2.5414,  1.3051,  1.2939,  1.2543,  1.2791,  1.3055,
          1.2658,  1.2927,  1.2620,  1.2568,  1.3831,  1.4235,  1.4054,  1.3663,
          1.4008,  1.3941,  1.3920,  1.2742,  1.2955,  1.3130,  1.3035,  1.2915,
          1.2757,  1.2752,  1.2970,  1.3444,  1.2677,  1.2788],
        [ 1.2309,  1.2586,  1.3062,  1.2840,  1.2646,  1.2359,  1.2442,  1.2287,
          1.2287,  1.2970,  1.3004,  1.3105,  1.3253,  1.2834,  1.2745,  1.2953,
          1.2856,  1.2011,  1.2830,  1.3070,  1.3237,  1.2947,  1.2576,  1.2473,
          1.2736,  1.2458,  1.2458,  2.9448,  2.8032,  2.4799,  2.6239,  2.9415,
          2.4899,  2.8986,  2.4905,  2.4821,  1.3888,  1.4294,  1.4078,  1.3945,
          1.4065,  1.3989,  1.3971,  1.2877,  1.3252,  1.3604,  1.3099,  1.2045,
          1.2379,  1.3556,  1.2941,  1.3920,  1.2299,  1.2883],
        [ 1.8164,  1.4706,  0.6735,  0.8930,  1.2696,  1.6998,  1.6322,  1.8140,
          1.8140,  1.7056,  1.3786,  1.5221,  1.0202,  1.8078,  0.3468,  1.6856,
          1.8407,  1.2173,  1.4137,  0.9690,  0.8404,  1.1906,  1.6777,  1.7435,
          1.4592,  1.8295,  1.8295,  0.7904,  0.9181,  1.7992,  1.5865,  0.8788,
          1.7303,  1.1832,  1.8516,  1.7644,  0.4340,  0.2115,  0.1956,  0.3874,
          0.6278,  0.7602,  0.3328, 11.9757,  7.2162,  0.8736,  1.3438,  1.4518,
          1.6922,  1.1156,  1.6115,  0.5039,  1.7586,  1.8649],
        [ 1.3100,  1.3373,  1.3947,  1.3732,  1.3438,  1.3150,  1.2780,  1.3079,
          1.3079,  1.2754,  1.3827,  1.2885,  1.4010,  1.3561,  1.4418,  1.2737,
          1.3588,  1.2882,  1.3571,  1.3841,  1.3987,  1.3686,  1.3316,  1.3233,
          1.2639,  1.3197,  1.3197,  1.3619,  1.4072,  1.3345,  1.1442,  1.3149,
          1.2086,  1.3726,  1.2068,  1.3371,  1.4582,  1.1617,  1.4799,  1.4674,
          1.0521,  0.9644,  1.4672,  1.4274,  0.8534,  3.2262,  2.5884,  3.3911,
          2.8544,  2.2041,  1.9140,  2.9503,  3.1594,  1.8992]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 224 : 181.71865810202172
Test loss for epoch 224 : 181.79616480638632
Test Precision for epoch 224 : 0.26153846153846155
Test Recall for epoch 224 : 0.26153846153846155
Test F1 for epoch 224 : 0.26153846153846155


theta for epoch 225 : tensor([[ 2.6171,  2.6422,  2.7077,  2.8216,  2.7889,  2.6214,  2.7700,  2.6152,
          2.6152,  1.2800,  1.2936,  1.2935,  1.3115,  1.2664,  1.3530,  1.2783,
          1.2691,  1.2467,  1.2611,  1.2432,  1.2567,  1.2727,  1.2359,  1.2281,
          1.2524,  1.2242,  1.2242,  1.2725,  1.3177,  1.2443,  1.2692,  1.3186,
          1.2557,  1.2829,  1.2064,  1.2468,  1.3715,  1.4118,  1.3941,  1.3806,
          1.3888,  1.3295,  1.3805,  1.3422,  1.3081,  1.3465,  1.2998,  1.2879,
          1.2723,  1.3419,  1.2935,  1.3777,  1.2646,  1.2757],
        [ 1.3156,  1.2207,  1.0513,  1.2602,  1.3489,  1.3658,  1.2874,  1.3586,
          1.3586,  1.7291,  1.9507,  1.7185,  2.4790,  1.7721,  5.4656,  1.8290,
          1.6619,  5.2570,  1.1538,  1.2291,  1.0406,  1.2009,  1.3344,  1.3694,
          1.3401,  1.3657,  1.3657,  1.3346,  1.0964,  1.3888,  1.3683,  1.1712,
          1.4004,  1.4250,  1.3511,  1.3864,  1.4568,  1.5508,  1.4785,  1.4195,
          1.4326,  1.5205,  1.4651,  0.6434,  1.4438,  1.0794,  1.4391,  1.4258,
          1.4105,  1.1019,  1.4318,  0.9335,  1.4027,  1.4146],
        [ 1.2341,  1.2613,  1.3183,  1.2964,  1.2669,  1.2390,  1.2469,  1.2320,
          1.2320,  1.2959,  1.3094,  1.3092,  1.3269,  1.2823,  1.3115,  1.2942,
          1.2614,  1.2391,  2.6671,  2.7643,  2.8953,  2.8005,  2.5423,  2.6469,
          2.7122,  2.5321,  2.5321,  1.3101,  1.2993,  1.2594,  1.2842,  1.3104,
          1.2709,  1.2979,  1.2671,  1.2619,  1.3870,  1.4274,  1.4093,  1.3700,
          1.4046,  1.3980,  1.3959,  1.2785,  1.2991,  1.3210,  1.3112,  1.2993,
          1.2835,  1.2837,  1.3048,  1.3523,  1.2755,  1.2867],
        [ 1.2332,  1.2609,  1.3086,  1.2864,  1.2668,  1.2382,  1.2465,  1.2310,
          1.2310,  1.2982,  1.3020,  1.3117,  1.3267,  1.2846,  1.2758,  1.2965,
          1.2868,  1.2028,  1.2765,  1.3008,  1.3174,  1.2883,  1.2510,  1.2409,
          1.2670,  1.2392,  1.2392,  2.9455,  2.8069,  2.4827,  2.6270,  2.9423,
          2.4926,  2.8993,  2.4932,  2.4848,  1.3893,  1.4300,  1.4085,  1.3952,
          1.4071,  1.3996,  1.3978,  1.2887,  1.3258,  1.3613,  1.3109,  1.2055,
          1.2388,  1.3565,  1.2953,  1.3929,  1.2308,  1.2892],
        [ 1.8186,  1.4726,  0.6744,  0.8943,  1.2714,  1.7020,  1.6343,  1.8162,
          1.8162,  1.7063,  1.3787,  1.5227,  1.0200,  1.8086,  0.3463,  1.6862,
          1.8419,  1.2162,  1.4082,  0.9638,  0.8347,  1.1850,  1.6723,  1.7380,
          1.4543,  1.8243,  1.8243,  0.7904,  0.9178,  1.7998,  1.5872,  0.8788,
          1.7309,  1.1833,  1.8523,  1.7650,  0.4338,  0.2111,  0.1954,  0.3871,
          0.6275,  0.7595,  0.3325, 12.0159,  7.2064,  0.8731,  1.3441,  1.4522,
          1.6927,  1.1152,  1.6117,  0.5030,  1.7594,  1.8655],
        [ 1.3107,  1.3381,  1.3955,  1.3740,  1.3445,  1.3157,  1.2787,  1.3086,
          1.3086,  1.2760,  1.3834,  1.2891,  1.4017,  1.3567,  1.4425,  1.2743,
          1.3594,  1.2889,  1.3480,  1.3750,  1.3895,  1.3594,  1.3224,  1.3142,
          1.2544,  1.3106,  1.3106,  1.3621,  1.4075,  1.3348,  1.1441,  1.3151,
          1.2087,  1.3729,  1.2069,  1.3373,  1.4582,  1.1613,  1.4799,  1.4673,
          1.0515,  0.9638,  1.4672,  1.4271,  0.8527,  3.2318,  2.5918,  3.3976,
          2.8582,  2.2069,  1.9167,  2.9542,  3.1650,  1.9019]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 225 : 181.72673532528813
Test loss for epoch 225 : 181.80403000343577
Test Precision for epoch 225 : 0.26153846153846155
Test Recall for epoch 225 : 0.26153846153846155
Test F1 for epoch 225 : 0.26153846153846155


theta for epoch 226 : tensor([[ 2.6109,  2.6362,  2.7017,  2.8158,  2.7831,  2.6153,  2.7641,  2.6090,
          2.6090,  1.2822,  1.2959,  1.2957,  1.3138,  1.2686,  1.3554,  1.2805,
          1.2713,  1.2492,  1.2707,  1.2528,  1.2663,  1.2823,  1.2455,  1.2377,
          1.2620,  1.2338,  1.2338,  1.2760,  1.3211,  1.2476,  1.2726,  1.3221,
          1.2591,  1.2864,  1.2098,  1.2502,  1.3749,  1.4153,  1.3975,  1.3840,
          1.3922,  1.3331,  1.3839,  1.3456,  1.3117,  1.3490,  1.3022,  1.2903,
          1.2747,  1.3444,  1.2959,  1.3803,  1.2670,  1.2781],
        [ 1.3093,  1.2149,  1.0466,  1.2544,  1.3430,  1.3595,  1.2813,  1.3523,
          1.3523,  1.7270,  1.9478,  1.7162,  2.4753,  1.7698,  5.4738,  1.8266,
          1.6597,  5.2656,  1.1628,  1.2380,  1.0498,  1.2096,  1.3430,  1.3779,
          1.3485,  1.3741,  1.3741,  1.3363,  1.0989,  1.3901,  1.3697,  1.1731,
          1.4018,  1.4265,  1.3525,  1.3879,  1.4592,  1.5527,  1.4804,  1.4217,
          1.4353,  1.5224,  1.4670,  0.6469,  1.4456,  1.0826,  1.4410,  1.4277,
          1.4124,  1.1047,  1.4338,  0.9370,  1.4046,  1.4166],
        [ 1.2213,  1.2485,  1.3057,  1.2837,  1.2542,  1.2262,  1.2341,  1.2191,
          1.2191,  1.2898,  1.3034,  1.3032,  1.3211,  1.2762,  1.3060,  1.2881,
          1.2550,  1.2335,  2.6789,  2.7769,  2.9076,  2.8122,  2.5545,  2.6589,
          2.7248,  2.5443,  2.5443,  1.3062,  1.2958,  1.2556,  1.2805,  1.3065,
          1.2671,  1.2942,  1.2633,  1.2581,  1.3848,  1.4254,  1.4072,  1.3675,
          1.4025,  1.3959,  1.3938,  1.2765,  1.2965,  1.3159,  1.3060,  1.2940,
          1.2782,  1.2787,  1.2995,  1.3472,  1.2702,  1.2814],
        [ 1.2275,  1.2552,  1.3036,  1.2815,  1.2612,  1.2325,  1.2409,  1.2253,
          1.2253,  1.2984,  1.3026,  1.3119,  1.3271,  1.2848,  1.2762,  1.2967,
          1.2869,  1.2037,  1.2841,  1.3082,  1.3249,  1.2959,  1.2586,  1.2486,
          1.2746,  1.2468,  1.2468,  2.9449,  2.8091,  2.4840,  2.6287,  2.9417,
          2.4939,  2.8988,  2.4945,  2.4861,  1.3910,  1.4318,  1.4104,  1.3970,
          1.4088,  1.4014,  1.3995,  1.2908,  1.3275,  1.3624,  1.3122,  1.2068,
          1.2401,  1.3576,  1.2969,  1.3940,  1.2320,  1.2904],
        [ 1.8126,  1.4665,  0.6695,  0.8891,  1.2653,  1.6960,  1.6283,  1.8103,
          1.8103,  1.7061,  1.3779,  1.5223,  1.0192,  1.8082,  0.3457,  1.6857,
          1.8418,  1.2143,  1.4130,  0.9685,  0.8390,  1.1897,  1.6776,  1.7430,
          1.4595,  1.8296,  1.8296,  0.7910,  0.9179,  1.8004,  1.5879,  0.8793,
          1.7315,  1.1837,  1.8529,  1.7654,  0.4330,  0.2102,  0.1946,  0.3862,
          0.6266,  0.7581,  0.3316, 12.0555,  7.1956,  0.8734,  1.3448,  1.4530,
          1.6934,  1.1154,  1.6121,  0.5030,  1.7602,  1.8662],
        [ 1.3001,  1.3275,  1.3852,  1.3636,  1.3339,  1.3050,  1.2680,  1.2979,
          1.2979,  1.2730,  1.3806,  1.2861,  1.3990,  1.3539,  1.4398,  1.2713,
          1.3566,  1.2859,  1.3538,  1.3808,  1.3954,  1.3653,  1.3283,  1.3200,
          1.2599,  1.3164,  1.3164,  1.3606,  1.4061,  1.3332,  1.1419,  1.3136,
          1.2070,  1.3714,  1.2051,  1.3357,  1.4579,  1.1604,  1.4797,  1.4672,
          1.0504,  0.9627,  1.4670,  1.4267,  0.8514,  3.2394,  2.5972,  3.4061,
          2.8641,  2.2118,  1.9214,  2.9600,  3.1727,  1.9066]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 226 : 181.7102507767294
Test loss for epoch 226 : 181.7847256558668
Test Precision for epoch 226 : 0.26153846153846155
Test Recall for epoch 226 : 0.26153846153846155
Test F1 for epoch 226 : 0.26153846153846155


theta for epoch 227 : tensor([[ 2.6173,  2.6425,  2.7080,  2.8224,  2.7898,  2.6217,  2.7708,  2.6154,
          2.6154,  1.2814,  1.2952,  1.2949,  1.3131,  1.2678,  1.3547,  1.2797,
          1.2705,  1.2484,  1.2663,  1.2484,  1.2619,  1.2780,  1.2411,  1.2334,
          1.2576,  1.2295,  1.2295,  1.2745,  1.3195,  1.2460,  1.2710,  1.3205,
          1.2575,  1.2849,  1.2081,  1.2485,  1.3738,  1.4144,  1.3965,  1.3831,
          1.3913,  1.3322,  1.3829,  1.3444,  1.3108,  1.3434,  1.2965,  1.2845,
          1.2688,  1.3387,  1.2901,  1.3748,  1.2611,  1.2721],
        [ 1.3123,  1.2179,  1.0497,  1.2575,  1.3462,  1.3625,  1.2843,  1.3553,
          1.3553,  1.7288,  1.9488,  1.7178,  2.4755,  1.7716,  5.4857,  1.8282,
          1.6616,  5.2779,  1.1597,  1.2350,  1.0475,  1.2065,  1.3397,  1.3746,
          1.3451,  1.3708,  1.3708,  1.3359,  1.0990,  1.3895,  1.3692,  1.1727,
          1.4012,  1.4260,  1.3519,  1.3874,  1.4592,  1.5523,  1.4799,  1.4216,
          1.4357,  1.5221,  1.4665,  0.6473,  1.4451,  1.0794,  1.4369,  1.4235,
          1.4082,  1.1009,  1.4296,  0.9348,  1.4003,  1.4124],
        [ 1.2245,  1.2518,  1.3090,  1.2870,  1.2575,  1.2295,  1.2374,  1.2224,
          1.2224,  1.2904,  1.3041,  1.3039,  1.3218,  1.2769,  1.3066,  1.2888,
          1.2553,  1.2347,  2.6805,  2.7794,  2.9099,  2.8137,  2.5563,  2.6606,
          2.7271,  2.5461,  2.5461,  1.3057,  1.2959,  1.2554,  1.2802,  1.3060,
          1.2669,  1.2941,  1.2630,  1.2579,  1.3846,  1.4252,  1.4070,  1.3670,
          1.4023,  1.3957,  1.3936,  1.2766,  1.2960,  1.3121,  1.3019,  1.2898,
          1.2741,  1.2752,  1.2954,  1.3435,  1.2660,  1.2773],
        [ 1.2304,  1.2581,  1.3067,  1.2845,  1.2641,  1.2354,  1.2438,  1.2282,
          1.2282,  1.2987,  1.3033,  1.3123,  1.3276,  1.2851,  1.2766,  1.2971,
          1.2873,  1.2046,  1.2813,  1.3056,  1.3221,  1.2931,  1.2558,  1.2458,
          1.2718,  1.2440,  1.2440,  2.9463,  2.8133,  2.4873,  2.6325,  2.9431,
          2.4973,  2.9002,  2.4978,  2.4895,  1.3907,  1.4316,  1.4102,  1.3968,
          1.4086,  1.4013,  1.3993,  1.2909,  1.3272,  1.3593,  1.3092,  1.2038,
          1.2369,  1.3545,  1.2943,  1.3910,  1.2288,  1.2872],
        [ 1.8170,  1.4710,  0.6733,  0.8932,  1.2698,  1.7004,  1.6327,  1.8146,
          1.8146,  1.7076,  1.3790,  1.5238,  1.0205,  1.8096,  0.3471,  1.6871,
          1.8436,  1.2143,  1.4121,  0.9682,  0.8383,  1.1890,  1.6767,  1.7419,
          1.4591,  1.8287,  1.8287,  0.7927,  0.9190,  1.8014,  1.5892,  0.8809,
          1.7325,  1.1850,  1.8539,  1.7663,  0.4312,  0.2083,  0.1928,  0.3843,
          0.6246,  0.7556,  0.3297, 12.0942,  7.1833,  0.8717,  1.3430,  1.4513,
          1.6914,  1.1133,  1.6098,  0.5016,  1.7584,  1.8641],
        [ 1.3045,  1.3320,  1.3899,  1.3682,  1.3385,  1.3095,  1.2725,  1.3023,
          1.3023,  1.2757,  1.3833,  1.2889,  1.4018,  1.3565,  1.4425,  1.2740,
          1.3592,  1.2888,  1.3531,  1.3799,  1.3946,  1.3645,  1.3276,  1.3193,
          1.2590,  1.3157,  1.3157,  1.3624,  1.4077,  1.3349,  1.1436,  1.3154,
          1.2088,  1.3732,  1.2069,  1.3374,  1.4590,  1.1615,  1.4807,  1.4683,
          1.0516,  0.9640,  1.4681,  1.4276,  0.8527,  3.2389,  2.5942,  3.4062,
          2.8616,  2.2083,  1.9176,  2.9578,  3.1719,  1.9028]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 227 : 181.69588291994606
Test loss for epoch 227 : 181.77428370184225
Test Precision for epoch 227 : 0.26153846153846155
Test Recall for epoch 227 : 0.26153846153846155
Test F1 for epoch 227 : 0.26153846153846155


theta for epoch 228 : tensor([[ 2.6215,  2.6468,  2.7123,  2.8269,  2.7943,  2.6259,  2.7753,  2.6196,
          2.6196,  1.2806,  1.2944,  1.2941,  1.3124,  1.2670,  1.3539,  1.2790,
          1.2697,  1.2477,  1.2607,  1.2428,  1.2564,  1.2724,  1.2355,  1.2277,
          1.2520,  1.2238,  1.2238,  1.2730,  1.3181,  1.2446,  1.2696,  1.3191,
          1.2561,  1.2835,  1.2067,  1.2471,  1.3730,  1.4137,  1.3957,  1.3823,
          1.3906,  1.3315,  1.3822,  1.3434,  1.3101,  1.3450,  1.2979,  1.2859,
          1.2702,  1.3403,  1.2915,  1.3765,  1.2624,  1.2735],
        [ 1.3159,  1.2214,  1.0534,  1.2612,  1.3501,  1.3662,  1.2879,  1.3589,
          1.3589,  1.7308,  1.9501,  1.7197,  2.4760,  1.7735,  5.4978,  1.8300,
          1.6636,  5.2905,  1.1529,  1.2285,  1.0420,  1.1998,  1.3329,  1.3677,
          1.3382,  1.3639,  1.3639,  1.3341,  1.0976,  1.3875,  1.3673,  1.1709,
          1.3992,  1.4241,  1.3498,  1.3856,  1.4582,  1.5509,  1.4784,  1.4204,
          1.4350,  1.5207,  1.4650,  0.6467,  1.4435,  1.0810,  1.4380,  1.4246,
          1.4093,  1.1022,  1.4308,  0.9366,  1.4014,  1.4135],
        [ 1.2320,  1.2593,  1.3166,  1.2945,  1.2649,  1.2370,  1.2448,  1.2299,
          1.2299,  1.2927,  1.3064,  1.3061,  1.3241,  1.2791,  1.3087,  1.2910,
          1.2574,  1.2377,  2.6762,  2.7759,  2.9063,  2.8092,  2.5522,  2.6562,
          2.7235,  2.5420,  2.5420,  1.3066,  1.2972,  1.2565,  1.2813,  1.3069,
          1.2680,  1.2952,  1.2642,  1.2590,  1.3855,  1.4262,  1.4079,  1.3677,
          1.4032,  1.3967,  1.3946,  1.2780,  1.2966,  1.3187,  1.3082,  1.2962,
          1.2805,  1.2821,  1.3018,  1.3500,  1.2723,  1.2837],
        [ 1.2335,  1.2612,  1.3100,  1.2878,  1.2672,  1.2385,  1.2469,  1.2313,
          1.2313,  1.2971,  1.3020,  1.3106,  1.3262,  1.2834,  1.2750,  1.2954,
          1.2856,  1.2035,  1.2748,  1.2993,  1.3156,  1.2866,  1.2492,  1.2393,
          1.2651,  1.2373,  1.2373,  2.9485,  2.8183,  2.4914,  2.6370,  2.9452,
          2.5013,  2.9024,  2.5018,  2.4935,  1.3891,  1.4301,  1.4088,  1.3953,
          1.4070,  1.3997,  1.3978,  1.2896,  1.3256,  1.3602,  1.3102,  1.2046,
          1.2378,  1.3555,  1.2955,  1.3919,  1.2297,  1.2882],
        [ 1.8220,  1.4760,  0.6773,  0.8974,  1.2748,  1.7055,  1.6378,  1.8196,
          1.8196,  1.7079,  1.3789,  1.5240,  1.0204,  1.8097,  0.3472,  1.6871,
          1.8441,  1.2130,  1.4088,  0.9654,  0.8352,  1.1858,  1.6734,  1.7383,
          1.4563,  1.8254,  1.8254,  0.7929,  0.9186,  1.8011,  1.5891,  0.8810,
          1.7322,  1.1849,  1.8536,  1.7659,  0.4295,  0.2065,  0.1911,  0.3824,
          0.6227,  0.7533,  0.3278, 12.1331,  7.1709,  0.8740,  1.3459,  1.4543,
          1.6943,  1.1158,  1.6124,  0.5037,  1.7614,  1.8669],
        [ 1.3074,  1.3350,  1.3932,  1.3714,  1.3415,  1.3124,  1.2754,  1.3052,
          1.3052,  1.2738,  1.3816,  1.2870,  1.4000,  1.3547,  1.4408,  1.2722,
          1.3574,  1.2870,  1.3455,  1.3722,  1.3867,  1.3568,  1.3199,  1.3117,
          1.2511,  1.3080,  1.3080,  1.3601,  1.4054,  1.3325,  1.1409,  1.3130,
          1.2064,  1.3709,  1.2045,  1.3351,  1.4574,  1.1595,  1.4792,  1.4667,
          1.0494,  0.9618,  1.4666,  1.4259,  0.8504,  3.2458,  2.5989,  3.4140,
          2.8668,  2.2125,  1.9217,  2.9630,  3.1789,  1.9069]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 228 : 181.70357909429396
Test loss for epoch 228 : 181.7818751970035
Test Precision for epoch 228 : 0.26153846153846155
Test Recall for epoch 228 : 0.26153846153846155
Test F1 for epoch 228 : 0.26153846153846155


theta for epoch 229 : tensor([[ 2.6139,  2.6392,  2.7047,  2.8196,  2.7870,  2.6182,  2.7680,  2.6120,
          2.6120,  1.2831,  1.2969,  1.2966,  1.3149,  1.2695,  1.3563,  1.2815,
          1.2721,  1.2504,  1.2725,  1.2546,  1.2681,  1.2842,  1.2473,  1.2395,
          1.2637,  1.2356,  1.2356,  1.2765,  1.3214,  1.2481,  1.2730,  1.3225,
          1.2596,  1.2869,  1.2103,  1.2506,  1.3764,  1.4172,  1.3992,  1.3857,
          1.3940,  1.3352,  1.3856,  1.3467,  1.3138,  1.3499,  1.3027,  1.2907,
          1.2750,  1.3451,  1.2962,  1.3814,  1.2671,  1.2782],
        [ 1.3107,  1.2165,  1.0493,  1.2564,  1.3453,  1.3610,  1.2828,  1.3538,
          1.3538,  1.7304,  1.9490,  1.7190,  2.4739,  1.7730,  5.5073,  1.8293,
          1.6632,  5.3004,  1.1609,  1.2364,  1.0500,  1.2076,  1.3406,  1.3754,
          1.3458,  1.3716,  1.3716,  1.3334,  1.0976,  1.3866,  1.3665,  1.1703,
          1.3983,  1.4233,  1.3489,  1.3848,  1.4588,  1.5510,  1.4785,  1.4208,
          1.4359,  1.5208,  1.4651,  0.6481,  1.4435,  1.0832,  1.4393,  1.4259,
          1.4105,  1.1039,  1.4321,  0.9391,  1.4026,  1.4147],
        [ 1.2227,  1.2501,  1.3075,  1.2854,  1.2558,  1.2277,  1.2356,  1.2206,
          1.2206,  1.2863,  1.3001,  1.2998,  1.3179,  1.2728,  1.3028,  1.2847,
          1.2507,  1.2319,  2.6867,  2.7871,  2.9173,  2.8195,  2.5630,  2.6669,
          2.7348,  2.5528,  2.5528,  1.3022,  1.2933,  1.2523,  1.2772,  1.3025,
          1.2638,  1.2911,  1.2600,  1.2548,  1.3829,  1.4237,  1.4054,  1.3648,
          1.4006,  1.3942,  1.3921,  1.2757,  1.2936,  1.3159,  1.3051,  1.2931,
          1.2774,  1.2795,  1.2987,  1.3472,  1.2692,  1.2806],
        [ 1.2286,  1.2563,  1.3057,  1.2836,  1.2623,  1.2336,  1.2419,  1.2264,
          1.2264,  1.2947,  1.3001,  1.3083,  1.3240,  1.2811,  1.2728,  1.2931,
          1.2833,  1.2018,  1.2814,  1.3057,  1.3221,  1.2932,  1.2558,  1.2460,
          1.2717,  1.2440,  1.2440,  2.9496,  2.8223,  2.4944,  2.6404,  2.9464,
          2.5043,  2.9036,  2.5048,  2.4966,  1.3887,  1.4298,  1.4085,  1.3950,
          1.4066,  1.3994,  1.3974,  1.2895,  1.3251,  1.3607,  1.3107,  1.2051,
          1.2382,  1.3559,  1.2963,  1.3924,  1.2301,  1.2886],
        [ 1.8172,  1.4706,  0.6719,  0.8921,  1.2691,  1.7005,  1.6327,  1.8148,
          1.8148,  1.7058,  1.3760,  1.5218,  1.0173,  1.8076,  0.3438,  1.6849,
          1.8424,  1.2088,  1.4128,  0.9689,  0.8380,  1.1895,  1.6781,  1.7428,
          1.4609,  1.8302,  1.8302,  0.7905,  0.9158,  1.7995,  1.5874,  0.8786,
          1.7306,  1.1825,  1.8521,  1.7642,  0.4300,  0.2068,  0.1915,  0.3828,
          0.6232,  0.7533,  0.3281, 12.1741,  7.1606,  0.8726,  1.3455,  1.4541,
          1.6943,  1.1145,  1.6121,  0.5016,  1.7617,  1.8672],
        [ 1.3023,  1.3300,  1.3883,  1.3665,  1.3365,  1.3073,  1.2703,  1.3001,
          1.3001,  1.2725,  1.3802,  1.2857,  1.3987,  1.3534,  1.4394,  1.2708,
          1.3560,  1.2858,  1.3558,  1.3825,  1.3972,  1.3673,  1.3302,  1.3221,
          1.2612,  1.3184,  1.3184,  1.3597,  1.4050,  1.3322,  1.1405,  1.3127,
          1.2061,  1.3706,  1.2042,  1.3347,  1.4579,  1.1600,  1.4797,  1.4673,
          1.0499,  0.9624,  1.4672,  1.4262,  0.8510,  3.2484,  2.5991,  3.4173,
          2.8675,  2.2123,  1.9212,  2.9638,  3.1813,  1.9064]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 229 : 181.69985971874485
Test loss for epoch 229 : 181.7789371885853
Test Precision for epoch 229 : 0.26153846153846155
Test Recall for epoch 229 : 0.26153846153846155
Test F1 for epoch 229 : 0.26153846153846155


theta for epoch 230 : tensor([[ 2.6249,  2.6501,  2.7156,  2.8309,  2.7982,  2.6292,  2.7792,  2.6230,
          2.6230,  1.2792,  1.2930,  1.2927,  1.3110,  1.2656,  1.3525,  1.2776,
          1.2682,  1.2465,  1.2642,  1.2462,  1.2599,  1.2759,  1.2389,  1.2312,
          1.2555,  1.2272,  1.2272,  1.2720,  1.3169,  1.2435,  1.2685,  1.3181,
          1.2550,  1.2825,  1.2056,  1.2460,  1.3729,  1.4139,  1.3957,  1.3823,
          1.3906,  1.3317,  1.3822,  1.3430,  1.3104,  1.3440,  1.2966,  1.2846,
          1.2688,  1.3392,  1.2901,  1.3757,  1.2609,  1.2720],
        [ 1.3143,  1.2202,  1.0531,  1.2601,  1.3491,  1.3646,  1.2864,  1.3574,
          1.3574,  1.7310,  1.9488,  1.7195,  2.4728,  1.7735,  5.5177,  1.8297,
          1.6639,  5.3111,  1.1579,  1.2335,  1.0481,  1.2046,  1.3373,  1.3720,
          1.3424,  1.3681,  1.3681,  1.3337,  1.0985,  1.3866,  1.3666,  1.1706,
          1.3982,  1.4234,  1.3489,  1.3849,  1.4589,  1.5507,  1.4781,  1.4207,
          1.4363,  1.5205,  1.4647,  0.6492,  1.4430,  1.0834,  1.4384,  1.4249,
          1.4096,  1.1036,  1.4312,  0.9400,  1.4016,  1.4138],
        [ 1.2289,  1.2562,  1.3135,  1.2914,  1.2618,  1.2338,  1.2417,  1.2267,
          1.2267,  1.2901,  1.3039,  1.3035,  1.3217,  1.2766,  1.3064,  1.2885,
          1.2542,  1.2364,  2.6828,  2.7841,  2.9140,  2.8154,  2.5594,  2.6630,
          2.7317,  2.5491,  2.5491,  1.3043,  1.2959,  1.2546,  1.2794,  1.3046,
          1.2661,  1.2935,  1.2623,  1.2571,  1.3842,  1.4251,  1.4067,  1.3658,
          1.4019,  1.3955,  1.3934,  1.2774,  1.2946,  1.3188,  1.3077,  1.2956,
          1.2800,  1.2827,  1.3013,  1.3501,  1.2718,  1.2832],
        [ 1.2321,  1.2597,  1.3092,  1.2870,  1.2657,  1.2371,  1.2454,  1.2299,
          1.2299,  1.2956,  1.3013,  1.3092,  1.3251,  1.2820,  1.2738,  1.2940,
          1.2842,  1.2033,  1.2786,  1.3031,  1.3194,  1.2904,  1.2530,  1.2433,
          1.2689,  1.2411,  1.2411,  2.9498,  2.8252,  2.4964,  2.6429,  2.9467,
          2.5064,  2.9039,  2.5068,  2.4986,  1.3885,  1.4297,  1.4085,  1.3950,
          1.4064,  1.3994,  1.3973,  1.2896,  1.3250,  1.3604,  1.3105,  1.2048,
          1.2379,  1.3556,  1.2964,  1.3920,  1.2297,  1.2882],
        [ 1.8205,  1.4738,  0.6739,  0.8946,  1.2721,  1.7039,  1.6360,  1.8182,
          1.8182,  1.7064,  1.3760,  1.5222,  1.0171,  1.8081,  0.3434,  1.6853,
          1.8433,  1.2075,  1.4100,  0.9663,  0.8349,  1.1866,  1.6756,  1.7400,
          1.4587,  1.8277,  1.8277,  0.7905,  0.9152,  1.7997,  1.5876,  0.8785,
          1.7308,  1.1824,  1.8523,  1.7643,  0.4293,  0.2059,  0.1907,  0.3819,
          0.6224,  0.7520,  0.3273, 12.2140,  7.1486,  0.8711,  1.3446,  1.4533,
          1.6935,  1.1129,  1.6110,  0.4998,  1.7611,  1.8664],
        [ 1.3059,  1.3336,  1.3920,  1.3701,  1.3401,  1.3109,  1.2740,  1.3037,
          1.3037,  1.2742,  1.3820,  1.2874,  1.4005,  1.3550,  1.4411,  1.2726,
          1.3576,  1.2876,  1.3531,  1.3798,  1.3945,  1.3645,  1.3275,  1.3193,
          1.2583,  1.3156,  1.3156,  1.3608,  1.4060,  1.3332,  1.1414,  1.3138,
          1.2072,  1.3716,  1.2052,  1.3357,  1.4580,  1.1601,  1.4798,  1.4675,
          1.0499,  0.9626,  1.4674,  1.4262,  0.8512,  3.2500,  2.5984,  3.4196,
          2.8673,  2.2111,  1.9198,  2.9638,  3.1828,  1.9049]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 230 : 181.68180909828712
Test loss for epoch 230 : 181.7624656914476
Test Precision for epoch 230 : 0.26153846153846155
Test Recall for epoch 230 : 0.26153846153846155
Test F1 for epoch 230 : 0.26153846153846155


theta for epoch 231 : tensor([[ 2.6271,  2.6524,  2.7179,  2.8334,  2.8008,  2.6315,  2.7818,  2.6252,
          2.6252,  1.2803,  1.2942,  1.2938,  1.3123,  1.2667,  1.3537,  1.2787,
          1.2693,  1.2477,  1.2626,  1.2445,  1.2582,  1.2743,  1.2372,  1.2295,
          1.2538,  1.2255,  1.2255,  1.2730,  1.3179,  1.2445,  1.2695,  1.3191,
          1.2560,  1.2835,  1.2066,  1.2470,  1.3720,  1.4130,  1.3948,  1.3814,
          1.3897,  1.3309,  1.3813,  1.3419,  1.3095,  1.3430,  1.2956,  1.2835,
          1.2677,  1.3382,  1.2890,  1.3747,  1.2598,  1.2709],
        [ 1.3120,  1.2180,  1.0516,  1.2580,  1.3470,  1.3623,  1.2841,  1.3550,
          1.3550,  1.7321,  1.9492,  1.7204,  2.4721,  1.7745,  5.5283,  1.8306,
          1.6650,  5.3221,  1.1573,  1.2331,  1.0485,  1.2040,  1.3364,  1.3711,
          1.3415,  1.3672,  1.3672,  1.3350,  1.1005,  1.3876,  1.3677,  1.1720,
          1.3992,  1.4245,  1.3499,  1.3860,  1.4587,  1.5500,  1.4774,  1.4203,
          1.4365,  1.5199,  1.4639,  0.6500,  1.4423,  1.0846,  1.4384,  1.4249,
          1.4096,  1.1043,  1.4312,  0.9416,  1.4016,  1.4138],
        [ 1.2267,  1.2540,  1.3113,  1.2893,  1.2597,  1.2317,  1.2396,  1.2246,
          1.2246,  1.2921,  1.3061,  1.3056,  1.3238,  1.2786,  1.3084,  1.2905,
          1.2560,  1.2392,  2.6839,  2.7861,  2.9158,  2.8163,  2.5608,  2.6641,
          2.7336,  2.5506,  2.5506,  1.3055,  1.2976,  1.2560,  1.2808,  1.3058,
          1.2675,  1.2949,  1.2636,  1.2585,  1.3836,  1.4246,  1.4062,  1.3650,
          1.4013,  1.3950,  1.3929,  1.2773,  1.2938,  1.3197,  1.3084,  1.2963,
          1.2807,  1.2840,  1.3020,  1.3510,  1.2725,  1.2839],
        [ 1.2304,  1.2580,  1.3078,  1.2857,  1.2640,  1.2354,  1.2437,  1.2282,
          1.2282,  1.2971,  1.3032,  1.3107,  1.3268,  1.2835,  1.2755,  1.2956,
          1.2856,  1.2052,  1.2781,  1.3026,  1.3189,  1.2899,  1.2524,  1.2428,
          1.2683,  1.2406,  1.2406,  2.9508,  2.8289,  2.4992,  2.6461,  2.9477,
          2.5092,  2.9050,  2.5096,  2.5014,  1.3880,  1.4292,  1.4081,  1.3945,
          1.4059,  1.3989,  1.3968,  1.2894,  1.3244,  1.3606,  1.3109,  1.2052,
          1.2383,  1.3559,  1.2970,  1.3923,  1.2301,  1.2886],
        [ 1.8201,  1.4735,  0.6741,  0.8948,  1.2719,  1.7035,  1.6356,  1.8177,
          1.8177,  1.7087,  1.3780,  1.5244,  1.0192,  1.8101,  0.3455,  1.6873,
          1.8457,  1.2082,  1.4104,  0.9673,  0.8355,  1.1872,  1.6760,  1.7402,
          1.4596,  1.8281,  1.8281,  0.7938,  0.9178,  1.8021,  1.5904,  0.8817,
          1.7332,  1.1855,  1.8547,  1.7666,  0.4270,  0.2035,  0.1884,  0.3795,
          0.6199,  0.7491,  0.3249, 12.2524,  7.1345,  0.8727,  1.3464,  1.4552,
          1.6950,  1.1144,  1.6123,  0.5015,  1.7627,  1.8678],
        [ 1.3012,  1.3289,  1.3874,  1.3655,  1.3355,  1.3062,  1.2693,  1.2990,
          1.2990,  1.2739,  1.3819,  1.2872,  1.4005,  1.3549,  1.4412,  1.2723,
          1.3575,  1.2875,  1.3500,  1.3766,  1.3913,  1.3614,  1.3244,  1.3162,
          1.2548,  1.3125,  1.3125,  1.3606,  1.4059,  1.3330,  1.1406,  1.3136,
          1.2067,  1.3715,  1.2048,  1.3355,  1.4561,  1.1576,  1.4780,  1.4656,
          1.0472,  0.9598,  1.4655,  1.4242,  0.8484,  3.2574,  2.6036,  3.4280,
          2.8730,  2.2157,  1.9242,  2.9694,  3.1903,  1.9094]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 231 : 181.67739832072013
Test loss for epoch 231 : 181.75633314273492
Test Precision for epoch 231 : 0.26153846153846155
Test Recall for epoch 231 : 0.26153846153846155
Test F1 for epoch 231 : 0.26153846153846155


theta for epoch 232 : tensor([[ 2.6237,  2.6490,  2.7145,  2.8303,  2.7977,  2.6280,  2.7786,  2.6218,
          2.6218,  1.2822,  1.2962,  1.2958,  1.3143,  1.2687,  1.3556,  1.2807,
          1.2712,  1.2498,  1.2690,  1.2509,  1.2646,  1.2807,  1.2436,  1.2360,
          1.2601,  1.2319,  1.2319,  1.2760,  1.3208,  1.2474,  1.2725,  1.3220,
          1.2590,  1.2865,  1.2096,  1.2500,  1.3749,  1.4160,  1.3977,  1.3843,
          1.3927,  1.3340,  1.3842,  1.3447,  1.3127,  1.3432,  1.2958,  1.2836,
          1.2679,  1.3384,  1.2892,  1.3749,  1.2599,  1.2710],
        [ 1.3095,  1.2158,  1.0502,  1.2560,  1.3449,  1.3598,  1.2817,  1.3526,
          1.3526,  1.7319,  1.9481,  1.7199,  2.4700,  1.7741,  5.5375,  1.8301,
          1.6648,  5.3316,  1.1623,  1.2381,  1.0539,  1.2088,  1.3411,  1.3757,
          1.3460,  1.3718,  1.3718,  1.3357,  1.1019,  1.3880,  1.3682,  1.1728,
          1.3996,  1.4250,  1.3503,  1.3866,  1.4602,  1.5509,  1.4783,  1.4216,
          1.4384,  1.5208,  1.4648,  0.6524,  1.4431,  1.0843,  1.4368,  1.4233,
          1.4080,  1.1035,  1.4296,  0.9421,  1.3999,  1.4122],
        [ 1.2201,  1.2474,  1.3049,  1.2828,  1.2532,  1.2251,  1.2330,  1.2180,
          1.2180,  1.2876,  1.3017,  1.3012,  1.3195,  1.2741,  1.3043,  1.2861,
          1.2512,  1.2353,  2.6927,  2.7956,  2.9250,  2.8248,  2.5699,  2.6730,
          2.7431,  2.5597,  2.5597,  1.3025,  1.2951,  1.2532,  1.2780,  1.3028,
          1.2647,  1.2922,  1.2609,  1.2557,  1.3820,  1.4231,  1.4046,  1.3630,
          1.3997,  1.3935,  1.3913,  1.2760,  1.2917,  1.3136,  1.3021,  1.2900,
          1.2743,  1.2781,  1.2957,  1.3450,  1.2661,  1.2776],
        [ 1.2279,  1.2556,  1.3058,  1.2837,  1.2616,  1.2329,  1.2413,  1.2257,
          1.2257,  1.2964,  1.3028,  1.3100,  1.3262,  1.2828,  1.2748,  1.2948,
          1.2849,  1.2051,  1.2819,  1.3064,  1.3227,  1.2938,  1.2563,  1.2467,
          1.2722,  1.2444,  1.2444,  2.9519,  2.8326,  2.5020,  2.6493,  2.9487,
          2.5120,  2.9061,  2.5124,  2.5042,  1.3886,  1.4299,  1.4088,  1.3953,
          1.4065,  1.3997,  1.3975,  1.2903,  1.3251,  1.3589,  1.3092,  1.2036,
          1.2365,  1.3542,  1.2957,  1.3906,  1.2283,  1.2868],
        [ 1.8181,  1.4712,  0.6720,  0.8927,  1.2696,  1.7014,  1.6335,  1.8157,
          1.8157,  1.7083,  1.3771,  1.5240,  1.0182,  1.8097,  0.3445,  1.6867,
          1.8457,  1.2060,  1.4132,  0.9700,  0.8377,  1.1899,  1.6792,  1.7431,
          1.4628,  1.8313,  1.8313,  0.7942,  0.9176,  1.8025,  1.5910,  0.8821,
          1.7337,  1.1858,  1.8551,  1.7669,  0.4265,  0.2030,  0.1879,  0.3790,
          0.6194,  0.7481,  0.3243, 12.2925,  7.1220,  0.8707,  1.3449,  1.4537,
          1.6935,  1.1122,  1.6105,  0.4993,  1.7614,  1.8663],
        [ 1.2981,  1.3259,  1.3845,  1.3626,  1.3325,  1.3031,  1.2662,  1.2959,
          1.2959,  1.2733,  1.3815,  1.2867,  1.4001,  1.3543,  1.4407,  1.2718,
          1.3569,  1.2871,  1.3553,  1.3819,  1.3967,  1.3668,  1.3297,  1.3216,
          1.2600,  1.3179,  1.3179,  1.3612,  1.4063,  1.3334,  1.1410,  1.3142,
          1.2073,  1.3720,  1.2053,  1.3360,  1.4570,  1.1585,  1.4789,  1.4666,
          1.0480,  0.9607,  1.4665,  1.4249,  0.8491,  3.2599,  2.6037,  3.4312,
          2.8736,  2.2153,  1.9236,  2.9701,  3.1927,  1.9088]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 232 : 181.68085624332164
Test loss for epoch 232 : 181.7608963645152
Test Precision for epoch 232 : 0.26153846153846155
Test Recall for epoch 232 : 0.26153846153846155
Test F1 for epoch 232 : 0.26153846153846155


theta for epoch 233 : tensor([[ 2.6318,  2.6571,  2.7227,  2.8387,  2.8061,  2.6362,  2.7871,  2.6300,
          2.6300,  1.2792,  1.2932,  1.2928,  1.3113,  1.2656,  1.3526,  1.2777,
          1.2682,  1.2468,  1.2600,  1.2420,  1.2557,  1.2718,  1.2347,  1.2270,
          1.2512,  1.2229,  1.2229,  1.2719,  1.3168,  1.2434,  1.2685,  1.3181,
          1.2550,  1.2825,  1.2055,  1.2460,  1.3743,  1.4156,  1.3972,  1.3838,
          1.3922,  1.3335,  1.3837,  1.3439,  1.3122,  1.3417,  1.2942,  1.2820,
          1.2662,  1.3369,  1.2875,  1.3735,  1.2582,  1.2694],
        [ 1.3151,  1.2214,  1.0559,  1.2617,  1.3507,  1.3654,  1.2873,  1.3582,
          1.3582,  1.7329,  1.9484,  1.7207,  2.4692,  1.7750,  5.5477,  1.8308,
          1.6658,  5.3422,  1.1556,  1.2315,  1.0486,  1.2021,  1.3340,  1.3686,
          1.3389,  1.3646,  1.3646,  1.3342,  1.1012,  1.3862,  1.3666,  1.1714,
          1.3979,  1.4234,  1.3485,  1.3849,  1.4611,  1.5514,  1.4787,  1.4224,
          1.4397,  1.5213,  1.4652,  0.6541,  1.4434,  1.0859,  1.4374,  1.4239,
          1.4085,  1.1046,  1.4303,  0.9441,  1.4005,  1.4128],
        [ 1.2289,  1.2562,  1.3136,  1.2915,  1.2619,  1.2338,  1.2418,  1.2268,
          1.2268,  1.2902,  1.3043,  1.3038,  1.3222,  1.2768,  1.3068,  1.2887,
          1.2536,  1.2388,  2.6873,  2.7911,  2.9203,  2.8192,  2.5648,  2.6676,
          2.7385,  2.5546,  2.5546,  1.3034,  1.2965,  1.2543,  1.2791,  1.3037,
          1.2658,  1.2934,  1.2620,  1.2569,  1.3847,  1.4258,  1.4074,  1.3655,
          1.4024,  1.3962,  1.3941,  1.2792,  1.2941,  1.3192,  1.3073,  1.2952,
          1.2796,  1.2841,  1.3009,  1.3505,  1.2713,  1.2828],
        [ 1.2328,  1.2605,  1.3107,  1.2886,  1.2664,  1.2378,  1.2462,  1.2307,
          1.2307,  1.2955,  1.3022,  1.3091,  1.3255,  1.2819,  1.2740,  1.2940,
          1.2840,  1.2047,  1.2753,  1.3000,  1.3161,  1.2872,  1.2496,  1.2402,
          1.2655,  1.2378,  1.2378,  2.9527,  2.8360,  2.5045,  2.6523,  2.9496,
          2.5145,  2.9069,  2.5148,  2.5067,  1.3892,  1.4306,  1.4095,  1.3959,
          1.4071,  1.4004,  1.3981,  1.2911,  1.3257,  1.3596,  1.3100,  1.2043,
          1.2372,  1.3549,  1.2967,  1.3913,  1.2290,  1.2875],
        [ 1.8233,  1.4761,  0.6752,  0.8965,  1.2743,  1.7066,  1.6386,  1.8209,
          1.8209,  1.7079,  1.3761,  1.5234,  1.0170,  1.8091,  0.3431,  1.6861,
          1.8455,  1.2035,  1.4081,  0.9654,  0.8324,  1.1848,  1.6743,  1.7380,
          1.4584,  1.8265,  1.8265,  0.7928,  0.9156,  1.8012,  1.5897,  0.8806,
          1.7323,  1.1842,  1.8538,  1.7655,  0.4265,  0.2027,  0.1878,  0.3788,
          0.6193,  0.7475,  0.3241, 12.3329,  7.1095,  0.8706,  1.3457,  1.4547,
          1.6944,  1.1122,  1.6111,  0.4988,  1.7625,  1.8672],
        [ 1.3037,  1.3316,  1.3902,  1.3683,  1.3381,  1.3088,  1.2718,  1.3015,
          1.3015,  1.2727,  1.3809,  1.2860,  1.3995,  1.3537,  1.4401,  1.2712,
          1.3563,  1.2866,  1.3477,  1.3742,  1.3889,  1.3591,  1.3221,  1.3141,
          1.2522,  1.3103,  1.3103,  1.3596,  1.4047,  1.3319,  1.1392,  1.3127,
          1.2057,  1.3705,  1.2037,  1.3344,  1.4580,  1.1593,  1.4799,  1.4676,
          1.0487,  0.9615,  1.4675,  1.4257,  0.8498,  3.2639,  2.6054,  3.4360,
          2.8758,  2.2166,  1.9246,  2.9724,  3.1967,  1.9098]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 233 : 181.67285032779176
Test loss for epoch 233 : 181.7543558430682
Test Precision for epoch 233 : 0.26153846153846155
Test Recall for epoch 233 : 0.26153846153846155
Test F1 for epoch 233 : 0.26153846153846155


theta for epoch 234 : tensor([[ 2.6294,  2.6547,  2.7202,  2.8366,  2.8040,  2.6337,  2.7849,  2.6275,
          2.6275,  1.2812,  1.2952,  1.2948,  1.3134,  1.2677,  1.3546,  1.2797,
          1.2702,  1.2490,  1.2652,  1.2471,  1.2608,  1.2769,  1.2398,  1.2322,
          1.2563,  1.2280,  1.2280,  1.2735,  1.3183,  1.2450,  1.2701,  1.3196,
          1.2566,  1.2841,  1.2072,  1.2476,  1.3752,  1.4165,  1.3981,  1.3847,
          1.3931,  1.3346,  1.3846,  1.3446,  1.3132,  1.3446,  1.2970,  1.2848,
          1.2691,  1.3398,  1.2904,  1.3764,  1.2611,  1.2722],
        [ 1.3118,  1.2182,  1.0533,  1.2586,  1.3477,  1.3621,  1.2840,  1.3549,
          1.3549,  1.7347,  1.9494,  1.7223,  2.4691,  1.7767,  5.5586,  1.8323,
          1.6676,  5.3535,  1.1581,  1.2341,  1.0516,  1.2044,  1.3363,  1.3709,
          1.3411,  1.3669,  1.3669,  1.3331,  1.1007,  1.3849,  1.3654,  1.1703,
          1.3966,  1.4221,  1.3472,  1.3838,  1.4603,  1.5501,  1.4773,  1.4214,
          1.4393,  1.5201,  1.4639,  0.6541,  1.4420,  1.0869,  1.4375,  1.4239,
          1.4086,  1.1050,  1.4303,  0.9455,  1.4005,  1.4128],
        [ 1.2247,  1.2520,  1.3095,  1.2874,  1.2577,  1.2296,  1.2376,  1.2225,
          1.2225,  1.2881,  1.3022,  1.3017,  1.3201,  1.2746,  1.3048,  1.2866,
          1.2511,  1.2373,  2.6929,  2.7976,  2.9265,  2.8245,  2.5708,  2.6733,
          2.7450,  2.5605,  2.5605,  1.3011,  1.2947,  1.2523,  1.2771,  1.3014,
          1.2638,  1.2914,  1.2599,  1.2548,  1.3826,  1.4239,  1.4054,  1.3632,
          1.4004,  1.3943,  1.3921,  1.2776,  1.2918,  1.3188,  1.3066,  1.2944,
          1.2788,  1.2839,  1.3002,  1.3501,  1.2705,  1.2821],
        [ 1.2301,  1.2577,  1.3084,  1.2863,  1.2637,  1.2351,  1.2434,  1.2279,
          1.2279,  1.2945,  1.3015,  1.3081,  1.3246,  1.2809,  1.2730,  1.2929,
          1.2829,  1.2042,  1.2775,  1.3021,  1.3182,  1.2893,  1.2518,  1.2424,
          1.2677,  1.2399,  1.2399,  2.9545,  2.8405,  2.5081,  2.6562,  2.9515,
          2.5181,  2.9088,  2.5184,  2.5103,  1.3877,  1.4292,  1.4082,  1.3946,
          1.4057,  1.3990,  1.3968,  1.2899,  1.3242,  1.3597,  1.3102,  1.2044,
          1.2373,  1.3550,  1.2971,  1.3914,  1.2290,  1.2876],
        [ 1.8221,  1.4748,  0.6741,  0.8954,  1.2730,  1.7054,  1.6373,  1.8197,
          1.8197,  1.7083,  1.3761,  1.5238,  1.0170,  1.8094,  0.3431,  1.6863,
          1.8462,  1.2021,  1.4106,  0.9681,  0.8347,  1.1874,  1.6773,  1.7406,
          1.4615,  1.8294,  1.8294,  0.7934,  0.9155,  1.8014,  1.5900,  0.8811,
          1.7325,  1.1846,  1.8539,  1.7655,  0.4250,  0.2011,  0.1863,  0.3772,
          0.6178,  0.7454,  0.3225, 12.3723,  7.0954,  0.8715,  1.3473,  1.4564,
          1.6959,  1.1132,  1.6124,  0.4995,  1.7642,  1.8687],
        [ 1.3016,  1.3295,  1.3883,  1.3663,  1.3361,  1.3067,  1.2698,  1.2995,
          1.2995,  1.2729,  1.3811,  1.2863,  1.3998,  1.3539,  1.4404,  1.2714,
          1.3564,  1.2869,  1.3523,  1.3788,  1.3936,  1.3638,  1.3267,  1.3187,
          1.2566,  1.3149,  1.3149,  1.3595,  1.4046,  1.3317,  1.1390,  1.3126,
          1.2056,  1.3704,  1.2036,  1.3343,  1.4574,  1.1587,  1.4794,  1.4671,
          1.0481,  0.9610,  1.4670,  1.4250,  0.8493,  3.2670,  2.6062,  3.4399,
          2.8771,  2.2169,  1.9247,  2.9738,  3.1997,  1.9099]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 234 : 181.65980536476337
Test loss for epoch 234 : 181.74218578889887
Test Precision for epoch 234 : 0.26153846153846155
Test Recall for epoch 234 : 0.26153846153846155
Test F1 for epoch 234 : 0.26153846153846155


theta for epoch 235 : tensor([[ 2.6315,  2.6568,  2.7224,  2.8390,  2.8064,  2.6359,  2.7873,  2.6296,
          2.6296,  1.2805,  1.2946,  1.2941,  1.3127,  1.2670,  1.3539,  1.2790,
          1.2695,  1.2484,  1.2675,  1.2494,  1.2631,  1.2793,  1.2420,  1.2344,
          1.2586,  1.2303,  1.2303,  1.2735,  1.3182,  1.2450,  1.2701,  1.3196,
          1.2566,  1.2841,  1.2072,  1.2476,  1.3740,  1.4154,  1.3970,  1.3836,
          1.3919,  1.3335,  1.3835,  1.3432,  1.3121,  1.3436,  1.2961,  1.2838,
          1.2681,  1.3388,  1.2894,  1.3755,  1.2600,  1.2712],
        [ 1.3108,  1.2174,  1.0531,  1.2579,  1.3470,  1.3611,  1.2831,  1.3539,
          1.3539,  1.7351,  1.9490,  1.7225,  2.4675,  1.7770,  5.5679,  1.8324,
          1.6680,  5.3631,  1.1616,  1.2377,  1.0558,  1.2078,  1.3395,  1.3740,
          1.3441,  1.3700,  1.3700,  1.3336,  1.1020,  1.3851,  1.3657,  1.1709,
          1.3967,  1.4224,  1.3473,  1.3840,  1.4599,  1.5492,  1.4763,  1.4208,
          1.4394,  1.5192,  1.4629,  0.6550,  1.4409,  1.0878,  1.4371,  1.4235,
          1.4081,  1.1054,  1.4299,  0.9470,  1.4000,  1.4124],
        [ 1.2226,  1.2500,  1.3075,  1.2854,  1.2557,  1.2276,  1.2356,  1.2205,
          1.2205,  1.2869,  1.3011,  1.3005,  1.3191,  1.2735,  1.3038,  1.2854,
          1.2496,  1.2369,  2.6969,  2.8023,  2.9309,  2.8281,  2.5751,  2.6773,
          2.7497,  2.5648,  2.5648,  1.3004,  1.2946,  1.2518,  1.2766,  1.3007,
          1.2633,  1.2910,  1.2595,  1.2544,  1.3811,  1.4224,  1.4039,  1.3613,
          1.3988,  1.3928,  1.3906,  1.2765,  1.2899,  1.3178,  1.3053,  1.2931,
          1.2775,  1.2832,  1.2989,  1.3492,  1.2692,  1.2808],
        [ 1.2290,  1.2566,  1.3076,  1.2855,  1.2626,  1.2340,  1.2423,  1.2268,
          1.2268,  1.2939,  1.3013,  1.3076,  1.3242,  1.2803,  1.2726,  1.2924,
          1.2823,  1.2042,  1.2802,  1.3048,  1.3210,  1.2921,  1.2545,  1.2452,
          1.2704,  1.2427,  1.2427,  2.9557,  2.8443,  2.5110,  2.6595,  2.9527,
          2.5209,  2.9101,  2.5212,  2.5132,  1.3865,  1.4281,  1.4071,  1.3935,
          1.4045,  1.3979,  1.3956,  1.2889,  1.3230,  1.3591,  1.3097,  1.2039,
          1.2367,  1.3544,  1.2969,  1.3909,  1.2284,  1.2870],
        [ 1.8219,  1.4745,  0.6739,  0.8953,  1.2727,  1.7052,  1.6371,  1.8195,
          1.8195,  1.7086,  1.3760,  1.5240,  1.0168,  1.8095,  0.3429,  1.6864,
          1.8467,  1.2005,  1.4130,  0.9707,  0.8367,  1.1898,  1.6800,  1.7430,
          1.4644,  1.8321,  1.8321,  0.7947,  0.9160,  1.8022,  1.5911,  0.8822,
          1.7334,  1.1857,  1.8548,  1.7663,  0.4234,  0.1995,  0.1847,  0.3755,
          0.6162,  0.7433,  0.3208, 12.4116,  7.0808,  0.8714,  1.3477,  1.4568,
          1.6962,  1.1130,  1.6125,  0.4993,  1.7646,  1.8689],
        [ 1.3006,  1.3284,  1.3872,  1.3652,  1.3350,  1.3056,  1.2688,  1.2984,
          1.2984,  1.2727,  1.3809,  1.2861,  1.3996,  1.3536,  1.4402,  1.2712,
          1.3562,  1.2868,  1.3562,  1.3827,  1.3976,  1.3678,  1.3306,  1.3226,
          1.2603,  1.3188,  1.3188,  1.3600,  1.4050,  1.3322,  1.1393,  1.3131,
          1.2061,  1.3709,  1.2041,  1.3347,  1.4564,  1.1576,  1.4784,  1.4661,
          1.0469,  0.9599,  1.4661,  1.4238,  0.8482,  3.2702,  2.6070,  3.4438,
          2.8784,  2.2173,  1.9248,  2.9752,  3.2028,  1.9100]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 235 : 181.6590354821126
Test loss for epoch 235 : 181.7412406857842
Test Precision for epoch 235 : 0.26153846153846155
Test Recall for epoch 235 : 0.26153846153846155
Test F1 for epoch 235 : 0.26153846153846155


theta for epoch 236 : tensor([[ 2.6391,  2.6644,  2.7299,  2.8468,  2.8142,  2.6434,  2.7952,  2.6372,
          2.6372,  1.2786,  1.2928,  1.2922,  1.3110,  1.2651,  1.3522,  1.2772,
          1.2676,  1.2465,  1.2594,  1.2413,  1.2551,  1.2712,  1.2339,  1.2264,
          1.2505,  1.2222,  1.2222,  1.2714,  1.3163,  1.2430,  1.2680,  1.3176,
          1.2545,  1.2822,  1.2051,  1.2455,  1.3727,  1.4143,  1.3958,  1.3824,
          1.3907,  1.3323,  1.3823,  1.3417,  1.3109,  1.3407,  1.2931,  1.2809,
          1.2651,  1.3359,  1.2864,  1.3725,  1.2571,  1.2682],
        [ 1.3135,  1.2203,  1.0564,  1.2609,  1.3499,  1.3638,  1.2859,  1.3566,
          1.3566,  1.7357,  1.9488,  1.7228,  2.4660,  1.7774,  5.5771,  1.8327,
          1.6687,  5.3727,  1.1572,  1.2334,  1.0528,  1.2034,  1.3347,  1.3690,
          1.3392,  1.3650,  1.3650,  1.3346,  1.1039,  1.3857,  1.3665,  1.1720,
          1.3974,  1.4231,  1.3480,  1.3848,  1.4610,  1.5498,  1.4769,  1.4218,
          1.4410,  1.5198,  1.4635,  0.6574,  1.4414,  1.0893,  1.4371,  1.4235,
          1.4082,  1.1063,  1.4301,  0.9490,  1.4001,  1.4125],
        [ 1.2280,  1.2553,  1.3127,  1.2906,  1.2610,  1.2329,  1.2409,  1.2259,
          1.2259,  1.2913,  1.3055,  1.3049,  1.3235,  1.2779,  1.3080,  1.2899,
          1.2538,  1.2422,  2.6917,  2.7981,  2.9264,  2.8227,  2.5703,  2.6721,
          2.7454,  2.5600,  2.5600,  1.3033,  1.2980,  1.2550,  1.2798,  1.3036,
          1.2665,  1.2942,  1.2626,  1.2575,  1.3836,  1.4249,  1.4064,  1.3636,
          1.4013,  1.3953,  1.3931,  1.2795,  1.2921,  1.3219,  1.3091,  1.2969,
          1.2814,  1.2877,  1.3027,  1.3532,  1.2730,  1.2846],
        [ 1.2316,  1.2592,  1.3102,  1.2882,  1.2652,  1.2366,  1.2450,  1.2295,
          1.2295,  1.2951,  1.3028,  1.3088,  1.3256,  1.2816,  1.2740,  1.2937,
          1.2836,  1.2059,  1.2759,  1.3007,  1.3167,  1.2878,  1.2502,  1.2409,
          1.2660,  1.2383,  1.2383,  2.9561,  2.8471,  2.5129,  2.6619,  2.9531,
          2.5229,  2.9105,  2.5231,  2.5151,  1.3874,  1.4291,  1.4082,  1.3945,
          1.4053,  1.3989,  1.3966,  1.2900,  1.3239,  1.3595,  1.3102,  1.2044,
          1.2372,  1.3548,  1.2976,  1.3913,  1.2289,  1.2875],
        [ 1.8240,  1.4763,  0.6746,  0.8964,  1.2744,  1.7073,  1.6391,  1.8216,
          1.8216,  1.7092,  1.3759,  1.5244,  1.0164,  1.8100,  0.3421,  1.6867,
          1.8476,  1.1989,  1.4087,  0.9667,  0.8321,  1.1855,  1.6760,  1.7388,
          1.4608,  1.8283,  1.8283,  0.7948,  0.9155,  1.8028,  1.5917,  0.8823,
          1.7340,  1.1860,  1.8554,  1.7668,  0.4235,  0.1993,  0.1846,  0.3754,
          0.6162,  0.7428,  0.3206, 12.4523,  7.0675,  0.8702,  1.3475,  1.4567,
          1.6961,  1.1119,  1.6121,  0.4976,  1.7647,  1.8688],
        [ 1.3019,  1.3297,  1.3883,  1.3664,  1.3363,  1.3069,  1.2700,  1.2997,
          1.2997,  1.2725,  1.3809,  1.2859,  1.3996,  1.3536,  1.4402,  1.2711,
          1.3560,  1.2868,  1.3488,  1.3751,  1.3899,  1.3602,  1.3231,  1.3151,
          1.2526,  1.3113,  1.3113,  1.3598,  1.4048,  1.3320,  1.1387,  1.3129,
          1.2058,  1.3707,  1.2037,  1.3345,  1.4563,  1.1572,  1.4783,  1.4661,
          1.0463,  0.9593,  1.4660,  1.4235,  0.8476,  3.2759,  2.6104,  3.4504,
          2.8823,  2.2201,  1.9275,  2.9791,  3.2085,  1.9127]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 236 : 181.65971930715855
Test loss for epoch 236 : 181.74176206006194
Test Precision for epoch 236 : 0.26153846153846155
Test Recall for epoch 236 : 0.26153846153846155
Test F1 for epoch 236 : 0.26153846153846155


theta for epoch 237 : tensor([[ 2.6349,  2.6602,  2.7258,  2.8430,  2.8104,  2.6393,  2.7913,  2.6330,
          2.6330,  1.2819,  1.2961,  1.2955,  1.3143,  1.2684,  1.3555,  1.2805,
          1.2709,  1.2500,  1.2659,  1.2478,  1.2615,  1.2777,  1.2404,  1.2328,
          1.2569,  1.2286,  1.2286,  1.2748,  1.3195,  1.2464,  1.2714,  1.3209,
          1.2579,  1.2855,  1.2085,  1.2489,  1.3757,  1.4174,  1.3988,  1.3854,
          1.3937,  1.3355,  1.3854,  1.3446,  1.3141,  1.3417,  1.2941,  1.2819,
          1.2662,  1.3369,  1.2875,  1.3735,  1.2581,  1.2693],
        [ 1.3096,  1.2166,  1.0536,  1.2573,  1.3463,  1.3598,  1.2820,  1.3526,
          1.3526,  1.7364,  1.9486,  1.7233,  2.4646,  1.7779,  5.5862,  1.8331,
          1.6693,  5.3822,  1.1617,  1.2378,  1.0578,  1.2076,  1.3388,  1.3731,
          1.3432,  1.3690,  1.3690,  1.3353,  1.1054,  1.3861,  1.3669,  1.1728,
          1.3977,  1.4235,  1.3483,  1.3853,  1.4623,  1.5505,  1.4777,  1.4229,
          1.4428,  1.5206,  1.4642,  0.6599,  1.4421,  1.0891,  1.4354,  1.4218,
          1.4065,  1.1055,  1.4284,  0.9496,  1.3983,  1.4107],
        [ 1.2205,  1.2478,  1.3053,  1.2832,  1.2536,  1.2254,  1.2334,  1.2184,
          1.2184,  1.2881,  1.3024,  1.3017,  1.3204,  1.2747,  1.3050,  1.2867,
          1.2503,  1.2397,  2.7001,  2.8073,  2.9353,  2.8307,  2.5791,  2.6805,
          2.7546,  2.5688,  2.5688,  1.3006,  1.2959,  1.2525,  1.2773,  1.3009,
          1.2640,  1.2917,  1.2601,  1.2550,  1.3821,  1.4236,  1.4050,  1.3618,
          1.3998,  1.3939,  1.3917,  1.2784,  1.2902,  1.3162,  1.3030,  1.2908,
          1.2753,  1.2823,  1.2967,  1.3476,  1.2669,  1.2786],
        [ 1.2285,  1.2561,  1.3075,  1.2855,  1.2621,  1.2335,  1.2418,  1.2263,
          1.2263,  1.2957,  1.3036,  1.3094,  1.3263,  1.2821,  1.2746,  1.2942,
          1.2841,  1.2069,  1.2800,  1.3046,  1.3207,  1.2919,  1.2543,  1.2451,
          1.2701,  1.2424,  1.2424,  2.9567,  2.8502,  2.5151,  2.6645,  2.9537,
          2.5251,  2.9112,  2.5253,  2.5173,  1.3883,  1.4301,  1.4092,  1.3955,
          1.4063,  1.4000,  1.3976,  1.2911,  1.3249,  1.3583,  1.3091,  1.2033,
          1.2361,  1.3536,  1.2967,  1.3900,  1.2277,  1.2863],
        [ 1.8207,  1.4727,  0.6712,  0.8931,  1.2706,  1.7039,  1.6356,  1.8183,
          1.8183,  1.7096,  1.3757,  1.5246,  1.0159,  1.8101,  0.3411,  1.6868,
          1.8482,  1.1970,  1.4111,  0.9690,  0.8337,  1.1878,  1.6789,  1.7414,
          1.4638,  1.8313,  1.8313,  0.7950,  0.9150,  1.8033,  1.5923,  0.8825,
          1.7345,  1.1862,  1.8559,  1.7672,  0.4234,  0.1991,  0.1845,  0.3752,
          0.6161,  0.7422,  0.3204, 12.4930,  7.0537,  0.8679,  1.3460,  1.4553,
          1.6946,  1.1095,  1.6104,  0.4951,  1.7634,  1.8674],
        [ 1.2982,  1.3260,  1.3847,  1.3627,  1.3326,  1.3032,  1.2664,  1.2960,
          1.2960,  1.2732,  1.3816,  1.2866,  1.4004,  1.3542,  1.4409,  1.2718,
          1.3567,  1.2876,  1.3537,  1.3800,  1.3949,  1.3653,  1.3281,  1.3202,
          1.2573,  1.3163,  1.3163,  1.3606,  1.4056,  1.3327,  1.1393,  1.3137,
          1.2066,  1.3715,  1.2045,  1.3353,  1.4574,  1.1582,  1.4794,  1.4672,
          1.0472,  0.9604,  1.4672,  1.4244,  0.8485,  3.2783,  2.6104,  3.4535,
          2.8828,  2.2196,  1.9268,  2.9798,  3.2109,  1.9119]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 237 : 181.65010267726097
Test loss for epoch 237 : 181.73358967253506
Test Precision for epoch 237 : 0.26153846153846155
Test Recall for epoch 237 : 0.26153846153846155
Test F1 for epoch 237 : 0.26153846153846155


theta for epoch 238 : tensor([[ 2.6399,  2.6652,  2.7308,  2.8483,  2.8157,  2.6443,  2.7966,  2.6380,
          2.6380,  1.2799,  1.2942,  1.2935,  1.3124,  1.2664,  1.3535,  1.2785,
          1.2689,  1.2481,  1.2630,  1.2449,  1.2587,  1.2749,  1.2375,  1.2300,
          1.2541,  1.2258,  1.2258,  1.2728,  1.3175,  1.2444,  1.2694,  1.3190,
          1.2559,  1.2836,  1.2065,  1.2469,  1.3744,  1.4161,  1.3975,  1.3841,
          1.3924,  1.3342,  1.3841,  1.3430,  1.3128,  1.3415,  1.2941,  1.2818,
          1.2661,  1.3368,  1.2874,  1.3734,  1.2580,  1.2692],
        [ 1.3121,  1.2193,  1.0568,  1.2602,  1.3492,  1.3624,  1.2846,  1.3552,
          1.3552,  1.7372,  1.9485,  1.7238,  2.4632,  1.7786,  5.5953,  1.8335,
          1.6701,  5.3916,  1.1604,  1.2367,  1.0576,  1.2062,  1.3371,  1.3714,
          1.3414,  1.3673,  1.3673,  1.3347,  1.1057,  1.3852,  1.3662,  1.1723,
          1.3969,  1.4227,  1.3475,  1.3845,  1.4622,  1.5499,  1.4769,  1.4226,
          1.4431,  1.5199,  1.4635,  0.6610,  1.4413,  1.0912,  1.4362,  1.4226,
          1.4073,  1.1070,  1.4292,  0.9522,  1.3991,  1.4115],
        [ 1.2232,  1.2506,  1.3080,  1.2860,  1.2563,  1.2282,  1.2362,  1.2211,
          1.2211,  1.2875,  1.3019,  1.3012,  1.3200,  1.2741,  1.3046,  1.2862,
          1.2494,  1.2400,  2.7009,  2.8089,  2.9365,  2.8310,  2.5802,  2.6813,
          2.7562,  2.5699,  2.5699,  1.2998,  1.2957,  1.2520,  1.2768,  1.3001,
          1.2635,  1.2913,  1.2597,  1.2546,  1.3817,  1.4232,  1.4046,  1.3610,
          1.3993,  1.3936,  1.3913,  1.2785,  1.2895,  1.3181,  1.3046,  1.2924,
          1.2769,  1.2845,  1.2982,  1.3495,  1.2685,  1.2802],
        [ 1.2305,  1.2581,  1.3096,  1.2876,  1.2640,  1.2355,  1.2438,  1.2283,
          1.2283,  1.2946,  1.3028,  1.3083,  1.3254,  1.2811,  1.2737,  1.2932,
          1.2830,  1.2064,  1.2781,  1.3028,  1.3188,  1.2900,  1.2524,  1.2433,
          1.2682,  1.2406,  1.2406,  2.9580,  2.8539,  2.5179,  2.6677,  2.9550,
          2.5279,  2.9125,  2.5281,  2.5201,  1.3875,  1.4293,  1.4085,  1.3947,
          1.4054,  1.3992,  1.3968,  1.2905,  1.3240,  1.3588,  1.3096,  1.2039,
          1.2366,  1.3542,  1.2975,  1.3906,  1.2282,  1.2868],
        [ 1.8242,  1.4763,  0.6747,  0.8968,  1.2745,  1.7075,  1.6392,  1.8219,
          1.8219,  1.7102,  1.3760,  1.5252,  1.0163,  1.8105,  0.3419,  1.6871,
          1.8490,  1.1959,  1.4111,  0.9696,  0.8338,  1.1879,  1.6790,  1.7412,
          1.4644,  1.8313,  1.8313,  0.7967,  0.9157,  1.8039,  1.5932,  0.8840,
          1.7352,  1.1875,  1.8564,  1.7678,  0.4212,  0.1968,  0.1823,  0.3728,
          0.6138,  0.7393,  0.3181, 12.5318,  7.0373,  0.8701,  1.3486,  1.4580,
          1.6970,  1.1116,  1.6126,  0.4973,  1.7658,  1.8695],
        [ 1.3005,  1.3283,  1.3869,  1.3650,  1.3349,  1.3055,  1.2687,  1.2983,
          1.2983,  1.2717,  1.3802,  1.2851,  1.3991,  1.3528,  1.4396,  1.2703,
          1.3552,  1.2863,  1.3512,  1.3774,  1.3924,  1.3627,  1.3256,  1.3176,
          1.2546,  1.3137,  1.3137,  1.3592,  1.4043,  1.3314,  1.1378,  1.3124,
          1.2053,  1.3702,  1.2032,  1.3339,  1.4564,  1.1570,  1.4784,  1.4662,
          1.0459,  0.9591,  1.4662,  1.4232,  0.8472,  3.2834,  2.6133,  3.4595,
          2.8861,  2.2220,  1.9290,  2.9831,  3.2160,  1.9141]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 238 : 181.64027771168256
Test loss for epoch 238 : 181.72305710736592
Test Precision for epoch 238 : 0.26153846153846155
Test Recall for epoch 238 : 0.26153846153846155
Test F1 for epoch 238 : 0.26153846153846155


theta for epoch 239 : tensor([[ 2.6439,  2.6692,  2.7348,  2.8526,  2.8200,  2.6483,  2.8009,  2.6420,
          2.6420,  1.2791,  1.2934,  1.2927,  1.3117,  1.2657,  1.3527,  1.2777,
          1.2681,  1.2474,  1.2605,  1.2424,  1.2561,  1.2723,  1.2349,  1.2274,
          1.2515,  1.2232,  1.2232,  1.2714,  1.3161,  1.2430,  1.2680,  1.3176,
          1.2546,  1.2822,  1.2051,  1.2456,  1.3737,  1.4156,  1.3969,  1.3835,
          1.3918,  1.3336,  1.3835,  1.3421,  1.3122,  1.3414,  1.2939,  1.2816,
          1.2659,  1.3366,  1.2873,  1.3732,  1.2578,  1.2690],
        [ 1.3129,  1.2202,  1.0581,  1.2612,  1.3502,  1.3632,  1.2854,  1.3560,
          1.3560,  1.7393,  1.9499,  1.7257,  2.4632,  1.7806,  5.6056,  1.8354,
          1.6723,  5.4022,  1.1579,  1.2344,  1.0562,  1.2037,  1.3344,  1.3686,
          1.3386,  1.3644,  1.3644,  1.3337,  1.1055,  1.3839,  1.3650,  1.1714,
          1.3956,  1.4215,  1.3462,  1.3833,  1.4619,  1.5491,  1.4761,  1.4222,
          1.4434,  1.5192,  1.4626,  0.6619,  1.4404,  1.0918,  1.4357,  1.4220,
          1.4067,  1.1070,  1.4286,  0.9533,  1.3985,  1.4109],
        [ 1.2265,  1.2538,  1.3112,  1.2892,  1.2595,  1.2314,  1.2394,  1.2243,
          1.2243,  1.2892,  1.3036,  1.3028,  1.3217,  1.2758,  1.3062,  1.2879,
          1.2508,  1.2425,  2.6995,  2.8084,  2.9357,  2.8292,  2.5791,  2.6798,
          2.7556,  2.5689,  2.5689,  1.3003,  1.2968,  1.2529,  1.2776,  1.3006,
          1.2643,  1.2921,  1.2605,  1.2554,  1.3825,  1.4241,  1.4055,  1.3616,
          1.4001,  1.3945,  1.3922,  1.2799,  1.2900,  1.3210,  1.3071,  1.2949,
          1.2794,  1.2877,  1.3007,  1.3524,  1.2710,  1.2826],
        [ 1.2311,  1.2587,  1.3104,  1.2884,  1.2647,  1.2361,  1.2445,  1.2290,
          1.2290,  1.2937,  1.3022,  1.3074,  1.3247,  1.2802,  1.2728,  1.2923,
          1.2821,  1.2059,  1.2754,  1.3003,  1.3162,  1.2874,  1.2497,  1.2407,
          1.2655,  1.2379,  1.2379,  2.9601,  2.8584,  2.5216,  2.6717,  2.9571,
          2.5315,  2.9146,  2.5317,  2.5237,  1.3866,  1.4286,  1.4078,  1.3940,
          1.4046,  1.3984,  1.3960,  1.2897,  1.3232,  1.3583,  1.3092,  1.2034,
          1.2361,  1.3537,  1.2973,  1.3901,  1.2276,  1.2863],
        [ 1.8262,  1.4782,  0.6760,  0.8984,  1.2764,  1.7095,  1.6412,  1.8239,
          1.8239,  1.7107,  1.3760,  1.5256,  1.0161,  1.8108,  0.3415,  1.6873,
          1.8497,  1.1943,  1.4099,  0.9688,  0.8324,  1.1868,  1.6782,  1.7401,
          1.4639,  1.8305,  1.8305,  0.7970,  0.9152,  1.8040,  1.5935,  0.8841,
          1.7353,  1.1876,  1.8566,  1.7678,  0.4202,  0.1957,  0.1812,  0.3717,
          0.6128,  0.7377,  0.3169, 12.5718,  7.0219,  0.8703,  1.3496,  1.4591,
          1.6979,  1.1118,  1.6134,  0.4971,  1.7669,  1.8704],
        [ 1.3032,  1.3310,  1.3895,  1.3676,  1.3376,  1.3082,  1.2714,  1.3010,
          1.3010,  1.2724,  1.3809,  1.2859,  1.3998,  1.3534,  1.4403,  1.2710,
          1.3558,  1.2871,  1.3500,  1.3762,  1.3912,  1.3615,  1.3243,  1.3164,
          1.2532,  1.3125,  1.3125,  1.3594,  1.4043,  1.3315,  1.1379,  1.3125,
          1.2055,  1.3703,  1.2034,  1.3341,  1.4567,  1.1574,  1.4787,  1.4666,
          1.0462,  0.9595,  1.4666,  1.4233,  0.8476,  3.2859,  2.6134,  3.4628,
          2.8868,  2.2217,  1.9285,  2.9839,  3.2184,  1.9136]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 239 : 181.63954368365327
Test loss for epoch 239 : 181.72392012494953
Test Precision for epoch 239 : 0.26153846153846155
Test Recall for epoch 239 : 0.26153846153846155
Test F1 for epoch 239 : 0.26153846153846155


theta for epoch 240 : tensor([[ 2.6402,  2.6656,  2.7312,  2.8492,  2.8166,  2.6446,  2.7975,  2.6383,
          2.6383,  1.2813,  1.2957,  1.2950,  1.3140,  1.2679,  1.3549,  1.2800,
          1.2703,  1.2498,  1.2671,  1.2490,  1.2627,  1.2790,  1.2416,  1.2341,
          1.2581,  1.2298,  1.2298,  1.2737,  1.3183,  1.2453,  1.2703,  1.3198,
          1.2568,  1.2845,  1.2075,  1.2479,  1.3762,  1.4181,  1.3994,  1.3860,
          1.3942,  1.3362,  1.3860,  1.3443,  1.3148,  1.3437,  1.2963,  1.2841,
          1.2684,  1.3390,  1.2897,  1.3755,  1.2603,  1.2715],
        [ 1.3085,  1.2161,  1.0549,  1.2572,  1.3462,  1.3588,  1.2811,  1.3516,
          1.3516,  1.7401,  1.9498,  1.7262,  2.4617,  1.7812,  5.6142,  1.8358,
          1.6731,  5.4112,  1.1627,  1.2392,  1.0616,  1.2083,  1.3388,  1.3730,
          1.3429,  1.3688,  1.3688,  1.3337,  1.1064,  1.3836,  1.3649,  1.1715,
          1.3953,  1.4212,  1.3459,  1.3831,  1.4629,  1.5496,  1.4765,  1.4231,
          1.4449,  1.5197,  1.4631,  0.6642,  1.4408,  1.0930,  1.4354,  1.4217,
          1.4063,  1.1076,  1.4283,  0.9551,  1.3981,  1.4106],
        [ 1.2203,  1.2476,  1.3051,  1.2831,  1.2534,  1.2252,  1.2332,  1.2182,
          1.2182,  1.2869,  1.3013,  1.3005,  1.3195,  1.2735,  1.3041,  1.2856,
          1.2482,  1.2410,  2.7056,  2.8153,  2.9422,  2.8349,  2.5857,  2.6860,
          2.7626,  2.5754,  2.5754,  1.2983,  1.2953,  1.2511,  1.2758,  1.2985,
          1.2625,  1.2903,  1.2587,  1.2536,  1.3817,  1.4235,  1.4048,  1.3605,
          1.3994,  1.3938,  1.3915,  1.2796,  1.2889,  1.3189,  1.3045,  1.2923,
          1.2769,  1.2859,  1.2982,  1.3503,  1.2684,  1.2801],
        [ 1.2274,  1.2550,  1.3071,  1.2851,  1.2610,  1.2324,  1.2408,  1.2253,
          1.2253,  1.2934,  1.3022,  1.3072,  1.3245,  1.2799,  1.2726,  1.2921,
          1.2818,  1.2061,  1.2797,  1.3045,  1.3204,  1.2917,  1.2540,  1.2451,
          1.2698,  1.2422,  1.2422,  2.9610,  2.8617,  2.5239,  2.6745,  2.9581,
          2.5339,  2.9156,  2.5341,  2.5261,  1.3871,  1.4292,  1.4084,  1.3946,
          1.4051,  1.3991,  1.3966,  1.2903,  1.3237,  1.3581,  1.3091,  1.2032,
          1.2359,  1.3535,  1.2974,  1.3899,  1.2274,  1.2861],
        [ 1.8223,  1.4739,  0.6717,  0.8943,  1.2719,  1.7056,  1.6371,  1.8200,
          1.8200,  1.7102,  1.3748,  1.5249,  1.0145,  1.8102,  0.3394,  1.6866,
          1.8496,  1.1913,  1.4121,  0.9707,  0.8335,  1.1888,  1.6811,  1.7427,
          1.4667,  1.8335,  1.8335,  0.7959,  0.9134,  1.8036,  1.5930,  0.8829,
          1.7349,  1.1866,  1.8562,  1.7673,  0.4206,  0.1959,  0.1815,  0.3720,
          0.6132,  0.7376,  0.3171, 12.6132,  7.0077,  0.8683,  1.3489,  1.4585,
          1.6974,  1.1100,  1.6126,  0.4946,  1.7666,  1.8700],
        [ 1.2995,  1.3273,  1.3858,  1.3639,  1.3339,  1.3046,  1.2678,  1.2974,
          1.2974,  1.2724,  1.3810,  1.2859,  1.3999,  1.3535,  1.4404,  1.2711,
          1.3559,  1.2873,  1.3556,  1.3818,  1.3969,  1.3672,  1.3299,  1.3221,
          1.2587,  1.3181,  1.3181,  1.3595,  1.4044,  1.3316,  1.1379,  1.3127,
          1.2057,  1.3705,  1.2035,  1.3342,  1.4575,  1.1582,  1.4796,  1.4675,
          1.0469,  0.9604,  1.4675,  1.4239,  0.8484,  3.2888,  2.6139,  3.4664,
          2.8878,  2.2217,  1.9283,  2.9850,  3.2212,  1.9134]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 240 : 181.63717304927013
Test loss for epoch 240 : 181.722403110994
Test Precision for epoch 240 : 0.26153846153846155
Test Recall for epoch 240 : 0.26153846153846155
Test F1 for epoch 240 : 0.26153846153846155


theta for epoch 241 : tensor([[ 2.6480,  2.6733,  2.7389,  2.8572,  2.8247,  2.6523,  2.8055,  2.6461,
          2.6461,  1.2785,  1.2929,  1.2921,  1.3113,  1.2651,  1.3522,  1.2772,
          1.2675,  1.2470,  1.2610,  1.2429,  1.2567,  1.2729,  1.2354,  1.2280,
          1.2520,  1.2237,  1.2237,  1.2712,  1.3158,  1.2428,  1.2677,  1.3173,
          1.2543,  1.2820,  1.2048,  1.2453,  1.3740,  1.4160,  1.3973,  1.3838,
          1.3920,  1.3339,  1.3839,  1.3418,  1.3125,  1.3412,  1.2939,  1.2816,
          1.2660,  1.3365,  1.2873,  1.3730,  1.2579,  1.2692],
        [ 1.3120,  1.2198,  1.0592,  1.2611,  1.3500,  1.3622,  1.2847,  1.3550,
          1.3550,  1.7402,  1.9489,  1.7260,  2.4594,  1.7811,  5.6219,  1.8355,
          1.6732,  5.4191,  1.1607,  1.2373,  1.0609,  1.2062,  1.3362,  1.3703,
          1.3403,  1.3661,  1.3661,  1.3347,  1.1084,  1.3842,  1.3656,  1.1727,
          1.3959,  1.4219,  1.3465,  1.3838,  1.4636,  1.5496,  1.4766,  1.4236,
          1.4461,  1.5198,  1.4631,  0.6666,  1.4408,  1.0954,  1.4361,  1.4224,
          1.4071,  1.1094,  1.4291,  0.9580,  1.3988,  1.4114],
        [ 1.2247,  1.2520,  1.3094,  1.2873,  1.2577,  1.2296,  1.2376,  1.2225,
          1.2225,  1.2888,  1.3033,  1.3024,  1.3215,  1.2754,  1.3060,  1.2875,
          1.2498,  1.2438,  2.7034,  2.8140,  2.9405,  2.8323,  2.5839,  2.6837,
          2.7613,  2.5737,  2.5737,  1.2996,  1.2972,  1.2527,  1.2774,  1.2999,
          1.2642,  1.2920,  1.2603,  1.2552,  1.3825,  1.4243,  1.4057,  1.3611,
          1.4002,  1.3947,  1.3924,  1.2810,  1.2894,  1.3214,  1.3067,  1.2945,
          1.2791,  1.2888,  1.3004,  1.3528,  1.2706,  1.2823],
        [ 1.2306,  1.2581,  1.3101,  1.2882,  1.2641,  1.2356,  1.2439,  1.2284,
          1.2284,  1.2941,  1.3031,  1.3079,  1.3253,  1.2806,  1.2735,  1.2928,
          1.2825,  1.2073,  1.2774,  1.3022,  1.3181,  1.2894,  1.2517,  1.2429,
          1.2674,  1.2399,  1.2399,  2.9611,  2.8640,  2.5254,  2.6764,  2.9581,
          2.5354,  2.9157,  2.5355,  2.5276,  1.3873,  1.4295,  1.4088,  1.3949,
          1.4053,  1.3994,  1.3969,  1.2907,  1.3240,  1.3588,  1.3099,  1.2041,
          1.2367,  1.3542,  1.2984,  1.3906,  1.2283,  1.2869],
        [ 1.8254,  1.4768,  0.6740,  0.8969,  1.2749,  1.7086,  1.6401,  1.8230,
          1.8230,  1.7108,  1.3750,  1.5254,  1.0144,  1.8106,  0.3392,  1.6869,
          1.8504,  1.1897,  1.4099,  0.9690,  0.8312,  1.1867,  1.6793,  1.7406,
          1.4653,  1.8317,  1.8317,  0.7969,  0.9136,  1.8045,  1.5940,  0.8839,
          1.7358,  1.1876,  1.8571,  1.7681,  0.4194,  0.1945,  0.1803,  0.3707,
          0.6120,  0.7359,  0.3158, 12.6532,  6.9914,  0.8685,  1.3499,  1.4596,
          1.6983,  1.1102,  1.6134,  0.4946,  1.7677,  1.8708],
        [ 1.3015,  1.3292,  1.3876,  1.3658,  1.3358,  1.3065,  1.2697,  1.2993,
          1.2993,  1.2711,  1.3799,  1.2847,  1.3988,  1.3523,  1.4393,  1.2699,
          1.3546,  1.2862,  1.3501,  1.3762,  1.3913,  1.3617,  1.3244,  1.3166,
          1.2529,  1.3126,  1.3126,  1.3586,  1.4036,  1.3308,  1.1367,  1.3118,
          1.2047,  1.3696,  1.2025,  1.3333,  1.4565,  1.1568,  1.4785,  1.4664,
          1.0453,  0.9589,  1.4665,  1.4226,  0.8468,  3.2948,  2.6177,  3.4734,
          2.8921,  2.2250,  1.9313,  2.9892,  3.2274,  1.9164]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 241 : 181.6278786650342
Test loss for epoch 241 : 181.71175481735196
Test Precision for epoch 241 : 0.26153846153846155
Test Recall for epoch 241 : 0.26153846153846155
Test F1 for epoch 241 : 0.26153846153846155


theta for epoch 242 : tensor([[ 2.6491,  2.6745,  2.7401,  2.8587,  2.8261,  2.6535,  2.8070,  2.6472,
          2.6472,  1.2801,  1.2946,  1.2938,  1.3130,  1.2667,  1.3540,  1.2788,
          1.2691,  1.2488,  1.2618,  1.2437,  1.2575,  1.2737,  1.2362,  1.2288,
          1.2528,  1.2245,  1.2245,  1.2729,  1.3175,  1.2445,  1.2694,  1.3190,
          1.2560,  1.2837,  1.2066,  1.2470,  1.3738,  1.4159,  1.3972,  1.3838,
          1.3918,  1.3339,  1.3838,  1.3414,  1.3125,  1.3397,  1.2925,  1.2802,
          1.2646,  1.3350,  1.2859,  1.3714,  1.2565,  1.2678],
        [ 1.3108,  1.2188,  1.0589,  1.2603,  1.3491,  1.3610,  1.2835,  1.3538,
          1.3538,  1.7421,  1.9500,  1.7276,  2.4589,  1.7828,  5.6312,  1.8371,
          1.6751,  5.4288,  1.1612,  1.2379,  1.0623,  1.2065,  1.3364,  1.3703,
          1.3403,  1.3661,  1.3661,  1.3356,  1.1102,  1.3848,  1.3663,  1.1736,
          1.3964,  1.4225,  1.3471,  1.3845,  1.4635,  1.5490,  1.4759,  1.4233,
          1.4466,  1.5191,  1.4624,  0.6679,  1.4400,  1.0943,  1.4334,  1.4197,
          1.4044,  1.1077,  1.4265,  0.9580,  1.3961,  1.4087],
        [ 1.2228,  1.2501,  1.3075,  1.2855,  1.2558,  1.2277,  1.2357,  1.2206,
          1.2206,  1.2888,  1.3034,  1.3025,  1.3217,  1.2755,  1.3062,  1.2876,
          1.2495,  1.2447,  2.7070,  2.8185,  2.9446,  2.8354,  2.5880,  2.6873,
          2.7658,  2.5777,  2.5777,  1.2995,  1.2976,  1.2528,  1.2775,  1.2998,
          1.2643,  1.2921,  1.2604,  1.2553,  1.3814,  1.4233,  1.4046,  1.3597,
          1.3990,  1.3936,  1.3914,  1.2804,  1.2880,  1.3180,  1.3028,  1.2906,
          1.2752,  1.2856,  1.2965,  1.3494,  1.2667,  1.2784],
        [ 1.2298,  1.2573,  1.3096,  1.2877,  1.2633,  1.2348,  1.2431,  1.2276,
          1.2276,  1.2949,  1.3042,  1.3087,  1.3263,  1.2815,  1.2744,  1.2937,
          1.2833,  1.2085,  1.2778,  1.3026,  1.3185,  1.2898,  1.2520,  1.2433,
          1.2678,  1.2402,  1.2402,  2.9627,  2.8679,  2.5285,  2.6798,  2.9598,
          2.5384,  2.9174,  2.5385,  2.5306,  1.3868,  1.4291,  1.4084,  1.3945,
          1.4048,  1.3990,  1.3964,  1.2903,  1.3235,  1.3569,  1.3081,  1.2023,
          1.2348,  1.3523,  1.2967,  1.3887,  1.2263,  1.2850],
        [ 1.8255,  1.4769,  0.6742,  0.8973,  1.2751,  1.7088,  1.6402,  1.8232,
          1.8232,  1.7125,  1.3761,  1.5269,  1.0153,  1.8120,  0.3399,  1.6883,
          1.8523,  1.1891,  1.4107,  0.9700,  0.8316,  1.1876,  1.6804,  1.7415,
          1.4667,  1.8329,  1.8329,  0.7990,  0.9149,  1.8064,  1.5961,  0.8859,
          1.7377,  1.1897,  1.8590,  1.7700,  0.4179,  0.1930,  0.1788,  0.3691,
          0.6106,  0.7338,  0.3142, 12.6931,  6.9745,  0.8672,  1.3492,  1.4588,
          1.6974,  1.1086,  1.6124,  0.4932,  1.7669,  1.8698],
        [ 1.3015,  1.3293,  1.3875,  1.3658,  1.3358,  1.3065,  1.2698,  1.2994,
          1.2994,  1.2729,  1.3817,  1.2865,  1.4007,  1.3540,  1.4412,  1.2717,
          1.3564,  1.2881,  1.3512,  1.3772,  1.3924,  1.3628,  1.3254,  1.3177,
          1.2538,  1.3136,  1.3136,  1.3605,  1.4054,  1.3326,  1.1384,  1.3137,
          1.2065,  1.3715,  1.2044,  1.3351,  1.4564,  1.1567,  1.4784,  1.4664,
          1.0451,  0.9588,  1.4664,  1.4223,  0.8468,  3.2968,  2.6173,  3.4761,
          2.8921,  2.2241,  1.9302,  2.9894,  3.2292,  1.9153]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 242 : 181.62118069384059
Test loss for epoch 242 : 181.70670104311517
Test Precision for epoch 242 : 0.26153846153846155
Test Recall for epoch 242 : 0.26153846153846155
Test F1 for epoch 242 : 0.26153846153846155


theta for epoch 243 : tensor([[ 2.6475,  2.6729,  2.7385,  2.8574,  2.8249,  2.6519,  2.8057,  2.6456,
          2.6456,  1.2813,  1.2958,  1.2950,  1.3143,  1.2680,  1.3552,  1.2801,
          1.2703,  1.2502,  1.2649,  1.2468,  1.2606,  1.2768,  1.2393,  1.2320,
          1.2558,  1.2276,  1.2276,  1.2740,  1.3185,  1.2456,  1.2705,  1.3201,
          1.2571,  1.2848,  1.2077,  1.2481,  1.3755,  1.4176,  1.3989,  1.3855,
          1.3934,  1.3357,  1.3855,  1.3429,  1.3142,  1.3427,  1.2956,  1.2833,
          1.2678,  1.3381,  1.2891,  1.3744,  1.2596,  1.2709],
        [ 1.3087,  1.2171,  1.0580,  1.2587,  1.3474,  1.3590,  1.2816,  1.3518,
          1.3518,  1.7432,  1.9501,  1.7284,  2.4575,  1.7837,  5.6395,  1.8378,
          1.6762,  5.4373,  1.1629,  1.2396,  1.0649,  1.2080,  1.3376,  1.3715,
          1.3414,  1.3673,  1.3673,  1.3352,  1.1108,  1.3840,  1.3657,  1.1733,
          1.3957,  1.4218,  1.3463,  1.3839,  1.4642,  1.5491,  1.4760,  1.4239,
          1.4479,  1.5193,  1.4625,  0.6701,  1.4401,  1.0967,  1.4343,  1.4205,
          1.4053,  1.1094,  1.4273,  0.9608,  1.3970,  1.4096],
        [ 1.2199,  1.2473,  1.3047,  1.2827,  1.2531,  1.2249,  1.2329,  1.2178,
          1.2178,  1.2871,  1.3017,  1.3008,  1.3200,  1.2738,  1.3046,  1.2858,
          1.2475,  1.2438,  2.7108,  2.8231,  2.9488,  2.8387,  2.5922,  2.6910,
          2.7705,  2.5819,  2.5819,  1.2977,  1.2965,  1.2514,  1.2761,  1.2980,
          1.2628,  1.2907,  1.2590,  1.2539,  1.3810,  1.4230,  1.4043,  1.3590,
          1.3986,  1.3933,  1.3911,  1.2806,  1.2873,  1.3183,  1.3028,  1.2905,
          1.2751,  1.2863,  1.2964,  1.3498,  1.2666,  1.2784],
        [ 1.2281,  1.2557,  1.3082,  1.2863,  1.2617,  1.2331,  1.2414,  1.2260,
          1.2260,  1.2943,  1.3039,  1.3081,  1.3259,  1.2809,  1.2739,  1.2931,
          1.2827,  1.2084,  1.2790,  1.3038,  1.3197,  1.2910,  1.2533,  1.2446,
          1.2690,  1.2415,  1.2415,  2.9637,  2.8711,  2.5308,  2.6826,  2.9608,
          2.5408,  2.9184,  2.5409,  2.5330,  1.3870,  1.4294,  1.4087,  1.3948,
          1.4050,  1.3993,  1.3967,  1.2906,  1.3237,  1.3577,  1.3089,  1.2030,
          1.2356,  1.3531,  1.2977,  1.3895,  1.2271,  1.2857],
        [ 1.8243,  1.4755,  0.6728,  0.8960,  1.2737,  1.7076,  1.6390,  1.8220,
          1.8220,  1.7124,  1.3755,  1.5267,  1.0143,  1.8117,  0.3388,  1.6879,
          1.8525,  1.1866,  1.4115,  0.9709,  0.8318,  1.1883,  1.6818,  1.7426,
          1.4682,  1.8343,  1.8343,  0.7988,  0.9138,  1.8063,  1.5960,  0.8855,
          1.7376,  1.1893,  1.8588,  1.7697,  0.4174,  0.1923,  0.1781,  0.3684,
          0.6100,  0.7327,  0.3135, 12.7338,  6.9582,  0.8674,  1.3505,  1.4603,
          1.6988,  1.1089,  1.6136,  0.4930,  1.7684,  1.8712],
        [ 1.2995,  1.3273,  1.3855,  1.3637,  1.3338,  1.3046,  1.2678,  1.2974,
          1.2974,  1.2717,  1.3805,  1.2853,  1.3996,  1.3528,  1.4401,  1.2705,
          1.3551,  1.2870,  1.3520,  1.3780,  1.3933,  1.3637,  1.3263,  1.3185,
          1.2544,  1.3145,  1.3145,  1.3592,  1.4041,  1.3313,  1.1369,  1.3124,
          1.2053,  1.3702,  1.2031,  1.3338,  1.4563,  1.1565,  1.4784,  1.4664,
          1.0447,  0.9585,  1.4665,  1.4220,  0.8464,  3.3020,  2.6202,  3.4821,
          2.8955,  2.2265,  1.9324,  2.9928,  3.2344,  1.9175]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 243 : 181.6187075520454
Test loss for epoch 243 : 181.70387011585606
Test Precision for epoch 243 : 0.26153846153846155
Test Recall for epoch 243 : 0.26153846153846155
Test F1 for epoch 243 : 0.26153846153846155


theta for epoch 244 : tensor([[ 2.6544,  2.6797,  2.7453,  2.8645,  2.8320,  2.6587,  2.8128,  2.6525,
          2.6525,  1.2780,  1.2926,  1.2917,  1.3111,  1.2647,  1.3520,  1.2768,
          1.2670,  1.2470,  1.2603,  1.2421,  1.2560,  1.2722,  1.2347,  1.2273,
          1.2512,  1.2230,  1.2230,  1.2704,  1.3150,  1.2420,  1.2669,  1.3165,
          1.2535,  1.2813,  1.2041,  1.2445,  1.3744,  1.4167,  1.3979,  1.3845,
          1.3924,  1.3346,  1.3845,  1.3415,  1.3131,  1.3415,  1.2944,  1.2821,
          1.2666,  1.3369,  1.2879,  1.3732,  1.2584,  1.2698],
        [ 1.3119,  1.2204,  1.0619,  1.2623,  1.3509,  1.3621,  1.2848,  1.3549,
          1.3549,  1.7441,  1.9502,  1.7290,  2.4559,  1.7844,  5.6474,  1.8383,
          1.6771,  5.4456,  1.1607,  1.2375,  1.0640,  1.2057,  1.3349,  1.3687,
          1.3387,  1.3644,  1.3644,  1.3342,  1.1109,  1.3828,  1.3646,  1.1726,
          1.3944,  1.4205,  1.3450,  1.3827,  1.4650,  1.5494,  1.4762,  1.4246,
          1.4493,  1.5196,  1.4628,  0.6725,  1.4403,  1.0987,  1.4347,  1.4210,
          1.4057,  1.1108,  1.4278,  0.9634,  1.3974,  1.4100],
        [ 1.2252,  1.2525,  1.3098,  1.2879,  1.2583,  1.2301,  1.2381,  1.2230,
          1.2230,  1.2882,  1.3028,  1.3019,  1.3212,  1.2749,  1.3058,  1.2870,
          1.2483,  1.2459,  2.7083,  2.8215,  2.9467,  2.8356,  2.5901,  2.6884,
          2.7689,  2.5799,  2.5799,  1.2980,  1.2974,  1.2520,  1.2766,  1.2983,
          1.2634,  1.2913,  1.2596,  1.2545,  1.3828,  1.4248,  1.4061,  1.3605,
          1.4003,  1.3952,  1.3929,  1.2829,  1.2888,  1.3219,  1.3059,  1.2937,
          1.2783,  1.2902,  1.2996,  1.3534,  1.2697,  1.2815],
        [ 1.2307,  1.2583,  1.3108,  1.2889,  1.2643,  1.2357,  1.2441,  1.2286,
          1.2286,  1.2932,  1.3030,  1.3070,  1.3250,  1.2798,  1.2729,  1.2920,
          1.2816,  1.2078,  1.2764,  1.3012,  1.3170,  1.2884,  1.2506,  1.2420,
          1.2663,  1.2388,  1.2388,  2.9647,  2.8743,  2.5331,  2.6853,  2.9619,
          2.5431,  2.9195,  2.5432,  2.5353,  1.3873,  1.4297,  1.4091,  1.3951,
          1.4052,  1.3997,  1.3971,  1.2909,  1.3241,  1.3579,  1.3092,  1.2033,
          1.2359,  1.3534,  1.2982,  1.3898,  1.2274,  1.2860],
        [ 1.8272,  1.4783,  0.6745,  0.8982,  1.2764,  1.7105,  1.6418,  1.8249,
          1.8249,  1.7119,  1.3743,  1.5260,  1.0128,  1.8110,  0.3370,  1.6871,
          1.8523,  1.1835,  1.4092,  0.9689,  0.8290,  1.1860,  1.6800,  1.7405,
          1.4667,  1.8327,  1.8327,  0.7976,  0.9118,  1.8054,  1.5951,  0.8842,
          1.7367,  1.1881,  1.8580,  1.7688,  0.4171,  0.1918,  0.1777,  0.3680,
          0.6098,  0.7319,  0.3130, 12.7749,  6.9419,  0.8668,  1.3511,  1.4610,
          1.6995,  1.1085,  1.6141,  0.4920,  1.7693,  1.8719],
        [ 1.3038,  1.3315,  1.3896,  1.3679,  1.3380,  1.3088,  1.2720,  1.3016,
          1.3016,  1.2712,  1.3800,  1.2848,  1.3991,  1.3523,  1.4396,  1.2700,
          1.3546,  1.2867,  1.3496,  1.3756,  1.3909,  1.3613,  1.3238,  1.3161,
          1.2519,  1.3120,  1.3120,  1.3584,  1.4033,  1.3305,  1.1360,  1.3116,
          1.2045,  1.3694,  1.2024,  1.3330,  1.4572,  1.1574,  1.4793,  1.4673,
          1.0456,  0.9595,  1.4674,  1.4226,  0.8473,  3.3047,  2.6206,  3.4857,
          2.8965,  2.2264,  1.9322,  2.9938,  3.2372,  1.9173]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 244 : 181.6144952646651
Test loss for epoch 244 : 181.70063881406418
Test Precision for epoch 244 : 0.26153846153846155
Test Recall for epoch 244 : 0.26153846153846155
Test F1 for epoch 244 : 0.26153846153846155


theta for epoch 245 : tensor([[ 2.6530,  2.6784,  2.7440,  2.8635,  2.8310,  2.6574,  2.8118,  2.6511,
          2.6511,  1.2799,  1.2946,  1.2937,  1.3132,  1.2667,  1.3541,  1.2788,
          1.2689,  1.2492,  1.2644,  1.2462,  1.2600,  1.2763,  1.2388,  1.2315,
          1.2553,  1.2270,  1.2270,  1.2724,  1.3169,  1.2440,  1.2688,  1.3185,
          1.2554,  1.2832,  1.2061,  1.2465,  1.3751,  1.4174,  1.3986,  1.3852,
          1.3930,  1.3354,  1.3852,  1.3419,  1.3138,  1.3423,  1.2953,  1.2830,
          1.2675,  1.3377,  1.2888,  1.3740,  1.2593,  1.2707],
        [ 1.3083,  1.2171,  1.0595,  1.2591,  1.3477,  1.3586,  1.2813,  1.3514,
          1.3514,  1.7463,  1.9514,  1.7309,  2.4555,  1.7864,  5.6563,  1.8401,
          1.6793,  5.4547,  1.1631,  1.2401,  1.0673,  1.2079,  1.3370,  1.3708,
          1.3406,  1.3664,  1.3664,  1.3344,  1.1120,  1.3826,  1.3646,  1.1728,
          1.3942,  1.4204,  1.3448,  1.3826,  1.4649,  1.5487,  1.4755,  1.4243,
          1.4498,  1.5189,  1.4620,  0.6739,  1.4394,  1.0988,  1.4332,  1.4194,
          1.4041,  1.1102,  1.4263,  0.9643,  1.3958,  1.4084],
        [ 1.2211,  1.2484,  1.3058,  1.2838,  1.2542,  1.2260,  1.2340,  1.2189,
          1.2189,  1.2872,  1.3019,  1.3009,  1.3203,  1.2739,  1.3050,  1.2860,
          1.2470,  1.2458,  2.7130,  2.8271,  2.9519,  2.8398,  2.5954,  2.6932,
          2.7746,  2.5852,  2.5852,  1.2970,  1.2969,  1.2512,  1.2759,  1.2973,
          1.2627,  1.2906,  1.2589,  1.2538,  1.3816,  1.4237,  1.4049,  1.3589,
          1.3991,  1.3941,  1.3917,  1.2823,  1.2872,  1.3196,  1.3032,  1.2909,
          1.2756,  1.2883,  1.2968,  1.3512,  1.2669,  1.2788],
        [ 1.2277,  1.2553,  1.3081,  1.2863,  1.2613,  1.2327,  1.2411,  1.2256,
          1.2256,  1.2931,  1.3031,  1.3069,  1.3250,  1.2797,  1.2729,  1.2919,
          1.2815,  1.2081,  1.2784,  1.3032,  1.3190,  1.2904,  1.2526,  1.2441,
          1.2683,  1.2408,  1.2408,  2.9668,  2.8785,  2.5365,  2.6890,  2.9639,
          2.5465,  2.9215,  2.5465,  2.5387,  1.3866,  1.4291,  1.4085,  1.3945,
          1.4045,  1.3991,  1.3964,  1.2902,  1.3233,  1.3567,  1.3080,  1.2021,
          1.2346,  1.3521,  1.2972,  1.3885,  1.2261,  1.2848],
        [ 1.8255,  1.4765,  0.6731,  0.8969,  1.2747,  1.7089,  1.6401,  1.8232,
          1.8232,  1.7130,  1.3749,  1.5269,  1.0130,  1.8118,  0.3370,  1.6878,
          1.8536,  1.1821,  1.4114,  0.9712,  0.8306,  1.1882,  1.6828,  1.7430,
          1.4696,  1.8355,  1.8355,  0.7990,  0.9122,  1.8067,  1.5964,  0.8854,
          1.7380,  1.1894,  1.8592,  1.7699,  0.4157,  0.1903,  0.1763,  0.3665,
          0.6085,  0.7300,  0.3115, 12.8152,  6.9242,  0.8661,  1.3513,  1.4612,
          1.6996,  1.1077,  1.6141,  0.4911,  1.7696,  1.8719],
        [ 1.3019,  1.3296,  1.3877,  1.3660,  1.3362,  1.3070,  1.2702,  1.2998,
          1.2998,  1.2724,  1.3812,  1.2860,  1.4004,  1.3534,  1.4408,  1.2712,
          1.3557,  1.2880,  1.3535,  1.3795,  1.3949,  1.3653,  1.3277,  1.3200,
          1.2556,  1.3159,  1.3159,  1.3595,  1.4043,  1.3316,  1.1370,  1.3128,
          1.2057,  1.3705,  1.2035,  1.3341,  1.4572,  1.1575,  1.4794,  1.4674,
          1.0455,  0.9596,  1.4675,  1.4224,  0.8474,  3.3070,  2.6205,  3.4887,
          2.8968,  2.2258,  1.9313,  2.9943,  3.2393,  1.9164]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 245 : 181.6067226363876
Test loss for epoch 245 : 181.69404046270068
Test Precision for epoch 245 : 0.26153846153846155
Test Recall for epoch 245 : 0.26153846153846155
Test F1 for epoch 245 : 0.26153846153846155


theta for epoch 246 : tensor([[ 2.6557,  2.6811,  2.7467,  2.8665,  2.8340,  2.6601,  2.8148,  2.6538,
          2.6538,  1.2797,  1.2944,  1.2935,  1.3131,  1.2664,  1.3540,  1.2786,
          1.2687,  1.2491,  1.2632,  1.2450,  1.2589,  1.2752,  1.2376,  1.2303,
          1.2541,  1.2259,  1.2259,  1.2722,  1.3167,  1.2438,  1.2686,  1.3184,
          1.2552,  1.2831,  1.2059,  1.2463,  1.3743,  1.4167,  1.3980,  1.3845,
          1.3922,  1.3347,  1.3846,  1.3409,  1.3130,  1.3425,  1.2956,  1.2832,
          1.2679,  1.3380,  1.2891,  1.3741,  1.2597,  1.2711],
        [ 1.3084,  1.2175,  1.0608,  1.2598,  1.3482,  1.3587,  1.2815,  1.3514,
          1.3514,  1.7472,  1.9514,  1.7314,  2.4537,  1.7871,  5.6637,  1.8406,
          1.6802,  5.4624,  1.1632,  1.2403,  1.0686,  1.2078,  1.3365,  1.3701,
          1.3400,  1.3658,  1.3658,  1.3351,  1.1138,  1.3828,  1.3650,  1.1737,
          1.3945,  1.4207,  1.3451,  1.3830,  1.4652,  1.5484,  1.4752,  1.4245,
          1.4507,  1.5187,  1.4617,  0.6761,  1.4391,  1.1012,  1.4338,  1.4200,
          1.4047,  1.1119,  1.4269,  0.9673,  1.3964,  1.4091],
        [ 1.2211,  1.2485,  1.3058,  1.2838,  1.2542,  1.2261,  1.2340,  1.2190,
          1.2190,  1.2874,  1.3023,  1.3012,  1.3208,  1.2742,  1.3054,  1.2863,
          1.2470,  1.2470,  2.7142,  2.8292,  2.9534,  2.8404,  2.5971,  2.6943,
          2.7767,  2.5868,  2.5868,  1.2970,  1.2976,  1.2515,  1.2762,  1.2973,
          1.2629,  1.2909,  1.2592,  1.2540,  1.3813,  1.4235,  1.4047,  1.3584,
          1.3988,  1.3938,  1.3915,  1.2826,  1.2866,  1.3206,  1.3037,  1.2915,
          1.2761,  1.2896,  1.2974,  1.3521,  1.2674,  1.2793],
        [ 1.2281,  1.2557,  1.3086,  1.2868,  1.2617,  1.2331,  1.2414,  1.2260,
          1.2260,  1.2937,  1.3040,  1.3076,  1.3258,  1.2803,  1.2737,  1.2926,
          1.2821,  1.2091,  1.2782,  1.3031,  1.3189,  1.2903,  1.2524,  1.2440,
          1.2681,  1.2406,  1.2406,  2.9673,  2.8811,  2.5382,  2.6911,  2.9645,
          2.5482,  2.9221,  2.5482,  2.5404,  1.3866,  1.4291,  1.4086,  1.3945,
          1.4044,  1.3991,  1.3964,  1.2903,  1.3233,  1.3574,  1.3088,  1.2030,
          1.2355,  1.3529,  1.2982,  1.3893,  1.2269,  1.2856],
        [ 1.8263,  1.4772,  0.6737,  0.8978,  1.2755,  1.7097,  1.6409,  1.8239,
          1.8239,  1.7139,  1.3753,  1.5277,  1.0131,  1.8125,  0.3369,  1.6884,
          1.8547,  1.1806,  1.4111,  0.9713,  0.8301,  1.1881,  1.6830,  1.7429,
          1.4701,  1.8358,  1.8358,  0.8003,  0.9125,  1.8077,  1.5975,  0.8866,
          1.7391,  1.1905,  1.8603,  1.7709,  0.4142,  0.1887,  0.1747,  0.3649,
          0.6070,  0.7279,  0.3099, 12.8554,  6.9059,  0.8667,  1.3529,  1.4628,
          1.7010,  1.1083,  1.6154,  0.4915,  1.7711,  1.8732],
        [ 1.3008,  1.3284,  1.3865,  1.3648,  1.3350,  1.3058,  1.2690,  1.2986,
          1.2986,  1.2710,  1.3801,  1.2847,  1.3993,  1.3522,  1.4398,  1.2699,
          1.3544,  1.2869,  1.3508,  1.3767,  1.3921,  1.3625,  1.3249,  1.3173,
          1.2526,  1.3131,  1.3131,  1.3584,  1.4033,  1.3305,  1.1355,  1.3117,
          1.2045,  1.3695,  1.2022,  1.3330,  1.4559,  1.1558,  1.4781,  1.4661,
          1.0436,  0.9577,  1.4662,  1.4208,  0.8454,  3.3135,  2.6248,  3.4961,
          2.9016,  2.2296,  1.9349,  2.9990,  3.2460,  1.9200]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 246 : 181.60106527851133
Test loss for epoch 246 : 181.68679021947412
Test Precision for epoch 246 : 0.26153846153846155
Test Recall for epoch 246 : 0.26153846153846155
Test F1 for epoch 246 : 0.26153846153846155


theta for epoch 247 : tensor([[ 2.6605,  2.6859,  2.7515,  2.8716,  2.8391,  2.6649,  2.8199,  2.6586,
          2.6586,  1.2784,  1.2933,  1.2922,  1.3120,  1.2652,  1.3529,  1.2774,
          1.2674,  1.2480,  1.2604,  1.2422,  1.2561,  1.2724,  1.2348,  1.2275,
          1.2513,  1.2230,  1.2230,  1.2711,  1.3157,  1.2427,  1.2675,  1.3173,
          1.2541,  1.2820,  1.2047,  1.2452,  1.3740,  1.4164,  1.3977,  1.3841,
          1.3918,  1.3343,  1.3843,  1.3401,  1.3126,  1.3396,  1.2928,  1.2804,
          1.2651,  1.3352,  1.2864,  1.3713,  1.2569,  1.2683],
        [ 1.3105,  1.2199,  1.0639,  1.2623,  1.3506,  1.3607,  1.2837,  1.3535,
          1.3535,  1.7481,  1.9513,  1.7320,  2.4519,  1.7878,  5.6708,  1.8411,
          1.6811,  5.4697,  1.1625,  1.2397,  1.0691,  1.2069,  1.3352,  1.3687,
          1.3386,  1.3643,  1.3643,  1.3357,  1.1156,  1.3830,  1.3654,  1.1745,
          1.3947,  1.4210,  1.3453,  1.3833,  1.4664,  1.5490,  1.4757,  1.4256,
          1.4525,  1.5193,  1.4622,  0.6792,  1.4396,  1.1015,  1.4321,  1.4182,
          1.4030,  1.1115,  1.4252,  0.9685,  1.3946,  1.4074],
        [ 1.2234,  1.2507,  1.3080,  1.2861,  1.2565,  1.2283,  1.2363,  1.2212,
          1.2212,  1.2880,  1.3029,  1.3018,  1.3215,  1.2748,  1.3062,  1.2869,
          1.2472,  1.2486,  2.7145,  2.8304,  2.9541,  2.8401,  2.5979,  2.6945,
          2.7779,  2.5876,  2.5876,  1.2973,  1.2985,  1.2521,  1.2767,  1.2976,
          1.2635,  1.2915,  1.2597,  1.2546,  1.3822,  1.4244,  1.4056,  1.3589,
          1.3996,  1.3948,  1.3924,  1.2840,  1.2872,  1.3194,  1.3021,  1.2898,
          1.2745,  1.2888,  1.2957,  1.3510,  1.2658,  1.2777],
        [ 1.2301,  1.2577,  1.3106,  1.2888,  1.2637,  1.2351,  1.2434,  1.2280,
          1.2280,  1.2942,  1.3047,  1.3081,  1.3264,  1.2809,  1.2743,  1.2931,
          1.2825,  1.2100,  1.2772,  1.3021,  1.3178,  1.2893,  1.2514,  1.2430,
          1.2671,  1.2396,  1.2396,  2.9678,  2.8836,  2.5400,  2.6933,  2.9650,
          2.5499,  2.9226,  2.5499,  2.5421,  1.3874,  1.4301,  1.4096,  1.3955,
          1.4052,  1.4001,  1.3974,  1.2911,  1.3243,  1.3563,  1.3077,  1.2019,
          1.2344,  1.3517,  1.2973,  1.3881,  1.2257,  1.2844],
        [ 1.8277,  1.4784,  0.6739,  0.8984,  1.2766,  1.7111,  1.6422,  1.8254,
          1.8254,  1.7139,  1.3745,  1.5275,  1.0117,  1.8124,  0.3350,  1.6881,
          1.8551,  1.1776,  1.4091,  0.9694,  0.8273,  1.1860,  1.6817,  1.7414,
          1.4690,  1.8347,  1.8347,  0.7997,  0.9111,  1.8079,  1.5976,  0.8859,
          1.7392,  1.1901,  1.8605,  1.7710,  0.4143,  0.1886,  0.1747,  0.3648,
          0.6072,  0.7274,  0.3097, 12.8972,  6.8890,  0.8635,  1.3510,  1.4610,
          1.6993,  1.1051,  1.6135,  0.4879,  1.7696,  1.8716],
        [ 1.3036,  1.3312,  1.3891,  1.3675,  1.3378,  1.3086,  1.2718,  1.3014,
          1.3014,  1.2719,  1.3809,  1.2856,  1.4003,  1.3530,  1.4407,  1.2708,
          1.3552,  1.2879,  1.3497,  1.3755,  1.3910,  1.3614,  1.3237,  1.3161,
          1.2513,  1.3119,  1.3119,  1.3593,  1.4042,  1.3314,  1.1364,  1.3126,
          1.2054,  1.3704,  1.2032,  1.3339,  1.4569,  1.1569,  1.4791,  1.4672,
          1.0446,  0.9589,  1.4673,  1.4215,  0.8465,  3.3151,  2.6239,  3.4984,
          2.9013,  2.2283,  1.9334,  2.9989,  3.2474,  1.9185]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 247 : 181.59770350802623
Test loss for epoch 247 : 181.68524884830055
Test Precision for epoch 247 : 0.26153846153846155
Test Recall for epoch 247 : 0.26153846153846155
Test F1 for epoch 247 : 0.26153846153846155


theta for epoch 248 : tensor([[ 2.6578,  2.6832,  2.7488,  2.8692,  2.8367,  2.6622,  2.8175,  2.6559,
          2.6559,  1.2806,  1.2955,  1.2944,  1.3143,  1.2674,  1.3552,  1.2796,
          1.2696,  1.2504,  1.2644,  1.2462,  1.2600,  1.2764,  1.2387,  1.2315,
          1.2552,  1.2270,  1.2270,  1.2735,  1.3180,  1.2450,  1.2698,  1.3196,
          1.2565,  1.2844,  1.2071,  1.2476,  1.3755,  1.4180,  1.3993,  1.3857,
          1.3933,  1.3360,  1.3859,  1.3414,  1.3142,  1.3427,  1.2959,  1.2836,
          1.2683,  1.3383,  1.2896,  1.3743,  1.2601,  1.2715],
        [ 1.3069,  1.2167,  1.0617,  1.2593,  1.3475,  1.3572,  1.2802,  1.3499,
          1.3499,  1.7499,  1.9522,  1.7335,  2.4509,  1.7894,  5.6786,  1.8425,
          1.6829,  5.4778,  1.1643,  1.2416,  1.0720,  1.2085,  1.3365,  1.3700,
          1.3398,  1.3655,  1.3655,  1.3358,  1.1167,  1.3827,  1.3652,  1.1747,
          1.3943,  1.4207,  1.3449,  1.3830,  1.4667,  1.5487,  1.4754,  1.4257,
          1.4535,  1.5190,  1.4619,  0.6813,  1.4392,  1.1035,  1.4324,  1.4185,
          1.4032,  1.1128,  1.4255,  0.9712,  1.3949,  1.4076],
        [ 1.2193,  1.2467,  1.3040,  1.2821,  1.2525,  1.2243,  1.2323,  1.2172,
          1.2172,  1.2866,  1.3016,  1.3005,  1.3203,  1.2734,  1.3050,  1.2856,
          1.2456,  1.2481,  2.7186,  2.8353,  2.9585,  2.8435,  2.6025,  2.6985,
          2.7829,  2.5923,  2.5923,  1.2961,  1.2979,  1.2511,  1.2758,  1.2964,
          1.2626,  1.2906,  1.2588,  1.2537,  1.3814,  1.4238,  1.4049,  1.3579,
          1.3988,  1.3941,  1.3917,  1.2838,  1.2861,  1.3192,  1.3014,  1.2891,
          1.2738,  1.2889,  1.2951,  1.3508,  1.2651,  1.2770],
        [ 1.2272,  1.2548,  1.3080,  1.2863,  1.2608,  1.2322,  1.2405,  1.2250,
          1.2250,  1.2938,  1.3046,  1.3077,  1.3263,  1.2805,  1.2741,  1.2928,
          1.2822,  1.2101,  1.2785,  1.3034,  1.3191,  1.2906,  1.2527,  1.2444,
          1.2683,  1.2409,  1.2409,  2.9695,  2.8873,  2.5428,  2.6965,  2.9667,
          2.5528,  2.9243,  2.5528,  2.5450,  1.3872,  1.4299,  1.4095,  1.3953,
          1.4050,  1.4000,  1.3972,  1.2909,  1.3240,  1.3565,  1.3081,  1.2022,
          1.2346,  1.3520,  1.2977,  1.3884,  1.2260,  1.2847],
        [ 1.8256,  1.4761,  0.6717,  0.8964,  1.2743,  1.7090,  1.6400,  1.8233,
          1.8233,  1.7144,  1.3743,  1.5277,  1.0110,  1.8126,  0.3340,  1.6882,
          1.8558,  1.1753,  1.4101,  0.9705,  0.8276,  1.1870,  1.6834,  1.7428,
          1.4708,  1.8365,  1.8365,  0.8000,  0.9105,  1.8085,  1.5981,  0.8861,
          1.7398,  1.1905,  1.8611,  1.7715,  0.4135,  0.1876,  0.1738,  0.3639,
          0.6065,  0.7261,  0.3088, 12.9383,  6.8708,  0.8634,  1.3521,  1.4622,
          1.7005,  1.1051,  1.6145,  0.4873,  1.7709,  1.8728],
        [ 1.3006,  1.3282,  1.3861,  1.3645,  1.3347,  1.3056,  1.2688,  1.2984,
          1.2984,  1.2715,  1.3806,  1.2852,  1.4000,  1.3526,  1.4404,  1.2704,
          1.3548,  1.2877,  1.3512,  1.3770,  1.3926,  1.3630,  1.3253,  1.3177,
          1.2527,  1.3135,  1.3135,  1.3591,  1.4040,  1.3311,  1.1359,  1.3124,
          1.2052,  1.3701,  1.2029,  1.3337,  1.4567,  1.1566,  1.4789,  1.4670,
          1.0440,  0.9584,  1.4672,  1.4210,  0.8460,  3.3197,  2.6263,  3.5039,
          2.9041,  2.2301,  1.9350,  3.0017,  3.2521,  1.9201]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 248 : 181.5925733146838
Test loss for epoch 248 : 181.68005981221705
Test Precision for epoch 248 : 0.26153846153846155
Test Recall for epoch 248 : 0.26153846153846155
Test F1 for epoch 248 : 0.26153846153846155


theta for epoch 249 : tensor([[ 2.6631,  2.6885,  2.7542,  2.8749,  2.8423,  2.6675,  2.8231,  2.6612,
          2.6612,  1.2784,  1.2934,  1.2923,  1.3123,  1.2653,  1.3531,  1.2774,
          1.2674,  1.2484,  1.2618,  1.2435,  1.2574,  1.2738,  1.2361,  1.2289,
          1.2526,  1.2244,  1.2244,  1.2710,  1.3155,  1.2425,  1.2673,  1.3171,
          1.2539,  1.2819,  1.2045,  1.2450,  1.3737,  1.4164,  1.3976,  1.3840,
          1.3915,  1.3342,  1.3842,  1.3393,  1.3124,  1.3421,  1.2953,  1.2829,
          1.2676,  1.3376,  1.2889,  1.3736,  1.2594,  1.2709],
        [ 1.3085,  1.2186,  1.0643,  1.2614,  1.3495,  1.3588,  1.2819,  1.3515,
          1.3515,  1.7517,  1.9529,  1.7349,  2.4498,  1.7910,  5.6860,  1.8438,
          1.6847,  5.4854,  1.1633,  1.2408,  1.0723,  1.2073,  1.3349,  1.3683,
          1.3382,  1.3638,  1.3638,  1.3350,  1.1170,  1.3815,  1.3642,  1.1741,
          1.3932,  1.4195,  1.3438,  1.3819,  1.4665,  1.5479,  1.4746,  1.4254,
          1.4539,  1.5182,  1.4610,  0.6830,  1.4383,  1.1055,  1.4325,  1.4186,
          1.4034,  1.1141,  1.4257,  0.9739,  1.3950,  1.4078],
        [ 1.2223,  1.2497,  1.3070,  1.2851,  1.2555,  1.2273,  1.2353,  1.2202,
          1.2202,  1.2871,  1.3021,  1.3009,  1.3208,  1.2739,  1.3057,  1.2861,
          1.2457,  1.2496,  2.7182,  2.8359,  2.9585,  2.8425,  2.6027,  2.6981,
          2.7835,  2.5925,  2.5925,  1.2958,  1.2982,  1.2512,  1.2758,  1.2961,
          1.2626,  1.2906,  1.2588,  1.2537,  1.3815,  1.4240,  1.4051,  1.3577,
          1.3989,  1.3943,  1.3919,  1.2846,  1.2860,  1.3216,  1.3033,  1.2910,
          1.2757,  1.2917,  1.2970,  1.3532,  1.2669,  1.2789],
        [ 1.2287,  1.2563,  1.3096,  1.2878,  1.2623,  1.2337,  1.2420,  1.2265,
          1.2265,  1.2931,  1.3041,  1.3070,  1.3257,  1.2798,  1.2735,  1.2921,
          1.2814,  1.2099,  1.2771,  1.3020,  1.3178,  1.2892,  1.2512,  1.2430,
          1.2669,  1.2394,  1.2394,  2.9708,  2.8906,  2.5452,  2.6993,  2.9680,
          2.5552,  2.9256,  2.5552,  2.5474,  1.3864,  1.4293,  1.4088,  1.3946,
          1.4042,  1.3993,  1.3966,  1.2901,  1.3233,  1.3568,  1.3083,  1.2025,
          1.2349,  1.3523,  1.2981,  1.3886,  1.2262,  1.2849],
        [ 1.8283,  1.4788,  0.6740,  0.8991,  1.2772,  1.7118,  1.6428,  1.8260,
          1.8260,  1.7149,  1.3743,  1.5281,  1.0108,  1.8129,  0.3337,  1.6884,
          1.8566,  1.1732,  1.4096,  0.9705,  0.8269,  1.1867,  1.6834,  1.7426,
          1.4711,  1.8366,  1.8366,  0.8007,  0.9101,  1.8087,  1.5984,  0.8866,
          1.7400,  1.1910,  1.8613,  1.7717,  0.4117,  0.1857,  0.1719,  0.3620,
          0.6047,  0.7237,  0.3068, 12.9787,  6.8513,  0.8641,  1.3539,  1.4641,
          1.7021,  1.1058,  1.6161,  0.4878,  1.7727,  1.8743],
        [ 1.3030,  1.3306,  1.3885,  1.3669,  1.3372,  1.3080,  1.2712,  1.3009,
          1.3009,  1.2710,  1.3802,  1.2847,  1.3997,  1.3522,  1.4401,  1.2700,
          1.3544,  1.2875,  1.3501,  1.3758,  1.3915,  1.3619,  1.3241,  1.3165,
          1.2513,  1.3122,  1.3122,  1.3583,  1.4031,  1.3303,  1.1350,  1.3116,
          1.2044,  1.3694,  1.2021,  1.3328,  1.4562,  1.1560,  1.4784,  1.4665,
          1.0433,  0.9578,  1.4667,  1.4202,  0.8454,  3.3233,  2.6276,  3.5083,
          2.9059,  2.2310,  1.9357,  3.0035,  3.2557,  1.9208]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 249 : 181.58548523434766
Test loss for epoch 249 : 181.67299923950242
Test Precision for epoch 249 : 0.26153846153846155
Test Recall for epoch 249 : 0.26153846153846155
Test F1 for epoch 249 : 0.26153846153846155


theta for epoch 250 : tensor([[ 2.6652,  2.6906,  2.7562,  2.8772,  2.8447,  2.6695,  2.8255,  2.6633,
          2.6633,  1.2782,  1.2933,  1.2921,  1.3122,  1.2651,  1.3531,  1.2773,
          1.2672,  1.2484,  1.2624,  1.2441,  1.2580,  1.2745,  1.2367,  1.2295,
          1.2532,  1.2249,  1.2249,  1.2707,  1.3151,  1.2421,  1.2669,  1.3168,
          1.2536,  1.2816,  1.2042,  1.2447,  1.3739,  1.4166,  1.3978,  1.3842,
          1.3916,  1.3344,  1.3844,  1.3391,  1.3126,  1.3411,  1.2944,  1.2820,
          1.2667,  1.3367,  1.2880,  1.3727,  1.2584,  1.2700],
        [ 1.3079,  1.2183,  1.0650,  1.2614,  1.3493,  1.3582,  1.2814,  1.3509,
          1.3509,  1.7535,  1.9538,  1.7364,  2.4486,  1.7925,  5.6932,  1.8452,
          1.6865,  5.4929,  1.1642,  1.2418,  1.0744,  1.2079,  1.3352,  1.3685,
          1.3384,  1.3639,  1.3639,  1.3349,  1.1180,  1.3809,  1.3638,  1.1741,
          1.3926,  1.4190,  1.3432,  1.3814,  1.4670,  1.5478,  1.4745,  1.4258,
          1.4552,  1.5182,  1.4610,  0.6855,  1.4382,  1.1061,  1.4310,  1.4171,
          1.4018,  1.1138,  1.4242,  0.9754,  1.3934,  1.4063],
        [ 1.2220,  1.2494,  1.3066,  1.2847,  1.2551,  1.2269,  1.2349,  1.2198,
          1.2198,  1.2866,  1.3018,  1.3005,  1.3206,  1.2735,  1.3055,  1.2857,
          1.2450,  1.2502,  2.7204,  2.8389,  2.9610,  2.8440,  2.6055,  2.7001,
          2.7866,  2.5952,  2.5952,  1.2951,  1.2982,  1.2508,  1.2754,  1.2954,
          1.2622,  1.2902,  1.2584,  1.2533,  1.3816,  1.4242,  1.4053,  1.3575,
          1.3990,  1.3945,  1.3921,  1.2853,  1.2858,  1.3206,  1.3018,  1.2894,
          1.2741,  1.2910,  1.2954,  1.3522,  1.2653,  1.2773],
        [ 1.2283,  1.2559,  1.3094,  1.2876,  1.2619,  1.2333,  1.2417,  1.2262,
          1.2262,  1.2928,  1.3040,  1.3068,  1.3256,  1.2795,  1.2733,  1.2918,
          1.2811,  1.2100,  1.2775,  1.3024,  1.3182,  1.2896,  1.2516,  1.2435,
          1.2673,  1.2398,  1.2398,  2.9722,  2.8939,  2.5477,  2.7021,  2.9694,
          2.5577,  2.9271,  2.5576,  2.5499,  1.3866,  1.4295,  1.4091,  1.3948,
          1.4043,  1.3996,  1.3967,  1.2902,  1.3235,  1.3557,  1.3073,  1.2014,
          1.2338,  1.3512,  1.2972,  1.3876,  1.2251,  1.2838],
        [ 1.8285,  1.4788,  0.6736,  0.8991,  1.2773,  1.7121,  1.6430,  1.8262,
          1.8262,  1.7153,  1.3739,  1.5282,  1.0098,  1.8129,  0.3323,  1.6883,
          1.8572,  1.1705,  1.4097,  0.9707,  0.8262,  1.1868,  1.6842,  1.7431,
          1.4720,  1.8375,  1.8375,  0.8007,  0.9091,  1.8090,  1.5986,  0.8864,
          1.7402,  1.1910,  1.8615,  1.7718,  0.4110,  0.1849,  0.1711,  0.3612,
          0.6041,  0.7224,  0.3059, 13.0202,  6.8325,  0.8623,  1.3533,  1.4636,
          1.7016,  1.1040,  1.6154,  0.4857,  1.7723,  1.8738],
        [ 1.3038,  1.3314,  1.3893,  1.3677,  1.3380,  1.3088,  1.2720,  1.3017,
          1.3017,  1.2718,  1.3810,  1.2855,  1.4005,  1.3529,  1.4409,  1.2708,
          1.3550,  1.2884,  1.3518,  1.3775,  1.3933,  1.3637,  1.3258,  1.3183,
          1.2529,  1.3139,  1.3139,  1.3589,  1.4036,  1.3308,  1.1355,  1.3122,
          1.2050,  1.3699,  1.2027,  1.3334,  1.4569,  1.1568,  1.4792,  1.4674,
          1.0440,  0.9587,  1.4676,  1.4207,  0.8462,  3.3250,  2.6269,  3.5108,
          2.9057,  2.2298,  1.9343,  3.0035,  3.2573,  1.9194]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 250 : 181.5803771455743
Test loss for epoch 250 : 181.6694142152512
Test Precision for epoch 250 : 0.26153846153846155
Test Recall for epoch 250 : 0.26153846153846155
Test F1 for epoch 250 : 0.26153846153846155


theta for epoch 251 : tensor([[ 2.6638,  2.6893,  2.7550,  2.8762,  2.8437,  2.6682,  2.8245,  2.6619,
          2.6619,  1.2797,  1.2949,  1.2936,  1.3139,  1.2666,  1.3548,  1.2788,
          1.2687,  1.2502,  1.2641,  1.2458,  1.2597,  1.2762,  1.2383,  1.2312,
          1.2548,  1.2266,  1.2266,  1.2726,  1.3169,  1.2439,  1.2687,  1.3187,
          1.2554,  1.2834,  1.2060,  1.2465,  1.3753,  1.4181,  1.3993,  1.3857,
          1.3929,  1.3360,  1.3859,  1.3403,  1.3140,  1.3432,  1.2965,  1.2841,
          1.2689,  1.3388,  1.2902,  1.3748,  1.2606,  1.2722],
        [ 1.3055,  1.2163,  1.0641,  1.2596,  1.3474,  1.3558,  1.2792,  1.3485,
          1.3485,  1.7549,  1.9541,  1.7374,  2.4469,  1.7937,  5.6996,  1.8461,
          1.6879,  5.4995,  1.1652,  1.2429,  1.0766,  1.2086,  1.3354,  1.3686,
          1.3385,  1.3640,  1.3640,  1.3355,  1.1199,  1.3811,  1.3642,  1.1750,
          1.3927,  1.4192,  1.3433,  1.3817,  1.4680,  1.5482,  1.4748,  1.4267,
          1.4569,  1.5186,  1.4613,  0.6886,  1.4384,  1.1087,  1.4316,  1.4177,
          1.4024,  1.1158,  1.4248,  0.9788,  1.3940,  1.4069],
        [ 1.2193,  1.2467,  1.3040,  1.2821,  1.2525,  1.2243,  1.2323,  1.2172,
          1.2172,  1.2862,  1.3014,  1.3001,  1.3203,  1.2730,  1.3053,  1.2853,
          1.2442,  1.2508,  2.7227,  2.8421,  2.9636,  2.8456,  2.6084,  2.7023,
          2.7900,  2.5981,  2.5981,  1.2947,  1.2984,  1.2506,  1.2752,  1.2950,
          1.2621,  1.2901,  1.2583,  1.2532,  1.3817,  1.4244,  1.4055,  1.3573,
          1.3991,  1.3947,  1.3923,  1.2860,  1.2856,  1.3211,  1.3019,  1.2895,
          1.2742,  1.2920,  1.2955,  1.3528,  1.2654,  1.2774],
        [ 1.2265,  1.2541,  1.3078,  1.2861,  1.2601,  1.2315,  1.2398,  1.2243,
          1.2243,  1.2930,  1.3044,  1.3070,  1.3260,  1.2798,  1.2737,  1.2921,
          1.2814,  1.2107,  1.2779,  1.3028,  1.3185,  1.2900,  1.2519,  1.2439,
          1.2676,  1.2401,  1.2401,  2.9731,  2.8968,  2.5498,  2.7046,  2.9704,
          2.5597,  2.9281,  2.5597,  2.5520,  1.3871,  1.4302,  1.4098,  1.3955,
          1.4049,  1.4002,  1.3974,  1.2907,  1.3241,  1.3563,  1.3080,  1.2021,
          1.2345,  1.3518,  1.2980,  1.3882,  1.2257,  1.2845],
        [ 1.8269,  1.4769,  0.6716,  0.8974,  1.2754,  1.7104,  1.6412,  1.8246,
          1.8246,  1.7156,  1.3736,  1.5284,  1.0088,  1.8131,  0.3309,  1.6883,
          1.8579,  1.1677,  1.4093,  0.9705,  0.8251,  1.1864,  1.6846,  1.7432,
          1.4725,  1.8381,  1.8381,  0.8010,  0.9083,  1.8096,  1.5992,  0.8865,
          1.7409,  1.1914,  1.8622,  1.7724,  0.4105,  0.1842,  0.1705,  0.3605,
          0.6037,  0.7213,  0.3052, 13.0619,  6.8136,  0.8617,  1.3542,  1.4645,
          1.7025,  1.1035,  1.6162,  0.4846,  1.7734,  1.8748],
        [ 1.3004,  1.3281,  1.3859,  1.3643,  1.3346,  1.3055,  1.2686,  1.2983,
          1.2983,  1.2705,  1.3799,  1.2843,  1.3995,  1.3518,  1.4399,  1.2696,
          1.3539,  1.2874,  1.3505,  1.3761,  1.3919,  1.3624,  1.3244,  1.3169,
          1.2513,  1.3125,  1.3125,  1.3580,  1.4028,  1.3299,  1.1342,  1.3113,
          1.2040,  1.3691,  1.2017,  1.3325,  1.4566,  1.1561,  1.4788,  1.4671,
          1.0431,  0.9578,  1.4673,  1.4200,  0.8452,  3.3312,  2.6309,  3.5179,
          2.9101,  2.2333,  1.9376,  3.0079,  3.2636,  1.9227]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 251 : 181.57649828329284
Test loss for epoch 251 : 181.6645147436166
Test Precision for epoch 251 : 0.26153846153846155
Test Recall for epoch 251 : 0.26153846153846155
Test F1 for epoch 251 : 0.26153846153846155


theta for epoch 252 : tensor([[ 2.6698,  2.6953,  2.7609,  2.8825,  2.8500,  2.6742,  2.8308,  2.6680,
          2.6680,  1.2779,  1.2932,  1.2919,  1.3123,  1.2648,  1.3531,  1.2770,
          1.2669,  1.2485,  1.2608,  1.2424,  1.2564,  1.2729,  1.2350,  1.2279,
          1.2515,  1.2232,  1.2232,  1.2708,  1.3152,  1.2421,  1.2669,  1.3169,
          1.2535,  1.2817,  1.2041,  1.2446,  1.3737,  1.4166,  1.3978,  1.3841,
          1.3913,  1.3343,  1.3843,  1.3383,  1.3123,  1.3398,  1.2931,  1.2807,
          1.2655,  1.3354,  1.2868,  1.3714,  1.2572,  1.2688],
        [ 1.3079,  1.2191,  1.0678,  1.2626,  1.3502,  1.3581,  1.2817,  1.3509,
          1.3509,  1.7564,  1.9545,  1.7385,  2.4452,  1.7949,  5.7059,  1.8471,
          1.6894,  5.5060,  1.1645,  1.2423,  1.0774,  1.2077,  1.3340,  1.3670,
          1.3370,  1.3624,  1.3624,  1.3360,  1.1216,  1.3811,  1.3644,  1.1757,
          1.3927,  1.4193,  1.3433,  1.3817,  1.4684,  1.5479,  1.4745,  1.4269,
          1.4580,  1.5184,  1.4610,  0.6914,  1.4381,  1.1093,  1.4299,  1.4159,
          1.4006,  1.1155,  1.4230,  0.9805,  1.3922,  1.4051],
        [ 1.2221,  1.2495,  1.3067,  1.2848,  1.2552,  1.2271,  1.2350,  1.2199,
          1.2199,  1.2868,  1.3020,  1.3007,  1.3210,  1.2736,  1.3061,  1.2859,
          1.2445,  1.2525,  2.7231,  2.8433,  2.9643,  2.8452,  2.6093,  2.7025,
          2.7913,  2.5990,  2.5990,  1.2949,  1.2993,  1.2511,  1.2757,  1.2952,
          1.2625,  1.2906,  1.2587,  1.2536,  1.3818,  1.4246,  1.4056,  1.3571,
          1.3991,  1.3949,  1.3925,  1.2867,  1.2854,  1.3202,  1.3005,  1.2881,
          1.2728,  1.2915,  1.2941,  1.3519,  1.2639,  1.2760],
        [ 1.2289,  1.2565,  1.3102,  1.2885,  1.2625,  1.2339,  1.2423,  1.2268,
          1.2268,  1.2935,  1.3051,  1.3075,  1.3267,  1.2803,  1.2744,  1.2926,
          1.2818,  1.2116,  1.2768,  1.3018,  1.3175,  1.2890,  1.2509,  1.2429,
          1.2665,  1.2391,  1.2391,  2.9739,  2.8993,  2.5515,  2.7067,  2.9711,
          2.5615,  2.9288,  2.5614,  2.5537,  1.3872,  1.4303,  1.4100,  1.3956,
          1.4049,  1.4004,  1.3975,  1.2907,  1.3242,  1.3552,  1.3069,  1.2011,
          1.2334,  1.3507,  1.2971,  1.3871,  1.2246,  1.2834],
        [ 1.8295,  1.4794,  0.6733,  0.8995,  1.2779,  1.7131,  1.6438,  1.8272,
          1.8272,  1.7163,  1.3735,  1.5288,  1.0082,  1.8135,  0.3299,  1.6886,
          1.8589,  1.1652,  1.4079,  0.9695,  0.8232,  1.1852,  1.6839,  1.7423,
          1.4721,  1.8376,  1.8376,  0.8016,  0.9079,  1.8103,  1.5998,  0.8869,
          1.7415,  1.1920,  1.8629,  1.7730,  0.4094,  0.1829,  0.1693,  0.3593,
          0.6026,  0.7196,  0.3039, 13.1033,  6.7937,  0.8597,  1.3534,  1.4637,
          1.7016,  1.1014,  1.6152,  0.4823,  1.7727,  1.8739],
        [ 1.3035,  1.3311,  1.3889,  1.3673,  1.3376,  1.3085,  1.2716,  1.3014,
          1.3014,  1.2713,  1.3807,  1.2851,  1.4004,  1.3525,  1.4408,  1.2704,
          1.3546,  1.2884,  1.3494,  1.3749,  1.3909,  1.3613,  1.3233,  1.3159,
          1.2501,  1.3114,  1.3114,  1.3588,  1.4035,  1.3306,  1.1348,  1.3121,
          1.2047,  1.3698,  1.2024,  1.3332,  1.4567,  1.1563,  1.4790,  1.4672,
          1.0431,  0.9580,  1.4675,  1.4198,  0.8454,  3.3331,  2.6303,  3.5205,
          2.9101,  2.2322,  1.9363,  3.0079,  3.2654,  1.9214]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 252 : 181.57067486354526
Test loss for epoch 252 : 181.65989846518409
Test Precision for epoch 252 : 0.26153846153846155
Test Recall for epoch 252 : 0.26153846153846155
Test F1 for epoch 252 : 0.26153846153846155


theta for epoch 253 : tensor([[ 2.6694,  2.6948,  2.7605,  2.8824,  2.8499,  2.6738,  2.8306,  2.6675,
          2.6675,  1.2790,  1.2944,  1.2930,  1.3136,  1.2660,  1.3544,  1.2782,
          1.2680,  1.2499,  1.2629,  1.2446,  1.2586,  1.2751,  1.2371,  1.2301,
          1.2536,  1.2254,  1.2254,  1.2720,  1.3163,  1.2432,  1.2680,  1.3181,
          1.2547,  1.2828,  1.2053,  1.2458,  1.3739,  1.4169,  1.3980,  1.3844,
          1.3914,  1.3346,  1.3846,  1.3382,  1.3126,  1.3414,  1.2947,  1.2823,
          1.2671,  1.3371,  1.2884,  1.3730,  1.2588,  1.2704],
        [ 1.3056,  1.2172,  1.0670,  1.2610,  1.3483,  1.3558,  1.2795,  1.3486,
          1.3486,  1.7586,  1.9557,  1.7403,  2.4442,  1.7969,  5.7125,  1.8489,
          1.6916,  5.5129,  1.1659,  1.2438,  1.0800,  1.2087,  1.3346,  1.3675,
          1.3375,  1.3628,  1.3628,  1.3360,  1.1229,  1.3806,  1.3641,  1.1759,
          1.3922,  1.4188,  1.3428,  1.3813,  1.4682,  1.5472,  1.4737,  1.4266,
          1.4586,  1.5176,  1.4602,  0.6935,  1.4372,  1.1114,  1.4298,  1.4158,
          1.4006,  1.1169,  1.4230,  0.9834,  1.3921,  1.4050],
        [ 1.2197,  1.2471,  1.3044,  1.2825,  1.2529,  1.2247,  1.2326,  1.2175,
          1.2175,  1.2859,  1.3013,  1.2999,  1.3204,  1.2728,  1.3055,  1.2851,
          1.2433,  1.2527,  2.7262,  2.8473,  2.9677,  2.8476,  2.6131,  2.7056,
          2.7954,  2.6028,  2.6028,  1.2940,  1.2990,  1.2504,  1.2750,  1.2943,
          1.2619,  1.2900,  1.2581,  1.2529,  1.3809,  1.4238,  1.4047,  1.3559,
          1.3982,  1.3940,  1.3916,  1.2864,  1.2841,  1.3204,  1.3001,  1.2877,
          1.2724,  1.2920,  1.2937,  1.3521,  1.2635,  1.2756],
        [ 1.2272,  1.2549,  1.3088,  1.2870,  1.2609,  1.2323,  1.2406,  1.2251,
          1.2251,  1.2933,  1.3052,  1.3074,  1.3268,  1.2802,  1.2744,  1.2925,
          1.2817,  1.2119,  1.2777,  1.3026,  1.3183,  1.2898,  1.2517,  1.2437,
          1.2673,  1.2399,  1.2399,  2.9753,  2.9026,  2.5540,  2.7095,  2.9726,
          2.5639,  2.9303,  2.5639,  2.5562,  1.3866,  1.4299,  1.4095,  1.3951,
          1.4043,  1.4000,  1.3971,  1.2901,  1.3237,  1.3554,  1.3072,  1.2013,
          1.2336,  1.3510,  1.2975,  1.3873,  1.2248,  1.2836],
        [ 1.8288,  1.4786,  0.6724,  0.8989,  1.2772,  1.7125,  1.6431,  1.8266,
          1.8266,  1.7171,  1.3736,  1.5294,  1.0078,  1.8139,  0.3291,  1.6889,
          1.8599,  1.1628,  1.4086,  0.9704,  0.8233,  1.1859,  1.6853,  1.7435,
          1.4737,  1.8391,  1.8391,  0.8025,  0.9076,  1.8111,  1.6006,  0.8876,
          1.7423,  1.1929,  1.8637,  1.7737,  0.4079,  0.1814,  0.1677,  0.3577,
          0.6013,  0.7176,  0.3023, 13.1446,  6.7732,  0.8596,  1.3547,  1.4651,
          1.7029,  1.1014,  1.6164,  0.4819,  1.7741,  1.8751],
        [ 1.3016,  1.3293,  1.3871,  1.3655,  1.3358,  1.3067,  1.2698,  1.2995,
          1.2995,  1.2711,  1.3807,  1.2849,  1.4005,  1.3524,  1.4408,  1.2702,
          1.3544,  1.2884,  1.3504,  1.3759,  1.3919,  1.3624,  1.3243,  1.3169,
          1.2509,  1.3124,  1.3124,  1.3586,  1.4034,  1.3304,  1.1344,  1.3119,
          1.2045,  1.3697,  1.2022,  1.3330,  1.4560,  1.1555,  1.4783,  1.4666,
          1.0421,  0.9571,  1.4669,  1.4188,  0.8444,  3.3373,  2.6323,  3.5255,
          2.9125,  2.2337,  1.9376,  3.0104,  3.2696,  1.9227]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 253 : 181.5639850507336
Test loss for epoch 253 : 181.6530048908793
Test Precision for epoch 253 : 0.26153846153846155
Test Recall for epoch 253 : 0.26153846153846155
Test F1 for epoch 253 : 0.26153846153846155


theta for epoch 254 : tensor([[ 2.6709,  2.6963,  2.7620,  2.8842,  2.8517,  2.6753,  2.8325,  2.6690,
          2.6690,  1.2787,  1.2941,  1.2927,  1.3134,  1.2656,  1.3542,  1.2779,
          1.2676,  1.2498,  1.2629,  1.2445,  1.2585,  1.2751,  1.2370,  1.2300,
          1.2535,  1.2253,  1.2253,  1.2716,  1.3159,  1.2428,  1.2676,  1.3177,
          1.2543,  1.2825,  1.2049,  1.2454,  1.3742,  1.4172,  1.3984,  1.3847,
          1.3917,  1.3350,  1.3850,  1.3381,  1.3129,  1.3424,  1.2957,  1.2833,
          1.2681,  1.3380,  1.2894,  1.3740,  1.2597,  1.2714],
        [ 1.3049,  1.2169,  1.0678,  1.2610,  1.3482,  1.3552,  1.2790,  1.3479,
          1.3479,  1.7606,  1.9566,  1.7419,  2.4429,  1.7986,  5.7186,  1.8504,
          1.6936,  5.5192,  1.1660,  1.2440,  1.0815,  1.2085,  1.3339,  1.3666,
          1.3367,  1.3619,  1.3619,  1.3356,  1.1237,  1.3796,  1.3634,  1.1758,
          1.3913,  1.4180,  1.3418,  1.3805,  1.4687,  1.5470,  1.4735,  1.4270,
          1.4598,  1.5175,  1.4600,  0.6964,  1.4370,  1.1139,  1.4301,  1.4161,
          1.4008,  1.1186,  1.4233,  0.9868,  1.3923,  1.4053],
        [ 1.2200,  1.2474,  1.3046,  1.2828,  1.2531,  1.2249,  1.2329,  1.2178,
          1.2178,  1.2857,  1.3012,  1.2997,  1.3204,  1.2727,  1.3057,  1.2850,
          1.2429,  1.2537,  2.7270,  2.8490,  2.9687,  2.8475,  2.6145,  2.7062,
          2.7972,  2.6042,  2.6042,  1.2936,  1.2992,  1.2502,  1.2748,  1.2939,
          1.2617,  1.2898,  1.2579,  1.2528,  1.3813,  1.4243,  1.4053,  1.3560,
          1.3986,  1.3946,  1.3921,  1.2875,  1.2843,  1.3223,  1.3015,  1.2890,
          1.2737,  1.2943,  1.2951,  1.3541,  1.2648,  1.2770],
        [ 1.2268,  1.2544,  1.3085,  1.2868,  1.2605,  1.2318,  1.2402,  1.2247,
          1.2247,  1.2926,  1.3047,  1.3067,  1.3263,  1.2795,  1.2738,  1.2918,
          1.2809,  1.2116,  1.2770,  1.3020,  1.3177,  1.2893,  1.2510,  1.2431,
          1.2666,  1.2392,  1.2392,  2.9767,  2.9058,  2.5564,  2.7122,  2.9740,
          2.5663,  2.9317,  2.5662,  2.5585,  1.3867,  1.4300,  1.4096,  1.3952,
          1.4043,  1.4001,  1.3971,  1.2900,  1.3237,  1.3558,  1.3076,  1.2016,
          1.2339,  1.3513,  1.2980,  1.3877,  1.2251,  1.2839],
        [ 1.8291,  1.4785,  0.6717,  0.8987,  1.2770,  1.7127,  1.6432,  1.8268,
          1.8268,  1.7170,  1.3727,  1.5291,  1.0063,  1.8136,  0.3271,  1.6884,
          1.8602,  1.1592,  1.4076,  0.9697,  0.8217,  1.1851,  1.6853,  1.7432,
          1.4738,  1.8392,  1.8392,  0.8021,  0.9061,  1.8109,  1.6003,  0.8870,
          1.7422,  1.1925,  1.8635,  1.7735,  0.4073,  0.1806,  0.1670,  0.3570,
          0.6008,  0.7164,  0.3015, 13.1868,  6.7531,  0.8588,  1.3555,  1.4660,
          1.7038,  1.1007,  1.6172,  0.4805,  1.7752,  1.8761],
        [ 1.3016,  1.3292,  1.3871,  1.3655,  1.3358,  1.3066,  1.2697,  1.2995,
          1.2995,  1.2706,  1.3803,  1.2845,  1.4002,  1.3519,  1.4405,  1.2698,
          1.3539,  1.2882,  1.3503,  1.3757,  1.3918,  1.3623,  1.3241,  1.3167,
          1.2506,  1.3122,  1.3122,  1.3582,  1.4029,  1.3299,  1.1338,  1.3115,
          1.2041,  1.3692,  1.2017,  1.3325,  1.4563,  1.1557,  1.4786,  1.4669,
          1.0421,  0.9573,  1.4672,  1.4187,  0.8445,  3.3409,  2.6336,  3.5299,
          2.9143,  2.2346,  1.9383,  3.0122,  3.2732,  1.9234]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 254 : 181.55855897166293
Test loss for epoch 254 : 181.64795171688132
Test Precision for epoch 254 : 0.26153846153846155
Test Recall for epoch 254 : 0.26153846153846155
Test F1 for epoch 254 : 0.26153846153846155


theta for epoch 255 : tensor([[ 2.6749,  2.7004,  2.7660,  2.8885,  2.8560,  2.6793,  2.8368,  2.6730,
          2.6730,  1.2772,  1.2928,  1.2913,  1.3122,  1.2642,  1.3529,  1.2765,
          1.2661,  1.2486,  1.2615,  1.2431,  1.2572,  1.2737,  1.2356,  1.2287,
          1.2522,  1.2239,  1.2239,  1.2700,  1.3144,  1.2413,  1.2661,  1.3162,
          1.2527,  1.2809,  1.2033,  1.2438,  1.3737,  1.4169,  1.3980,  1.3843,
          1.3912,  1.3346,  1.3846,  1.3373,  1.3124,  1.3404,  1.2936,  1.2812,
          1.2660,  1.3360,  1.2873,  1.3720,  1.2576,  1.2693],
        [ 1.3061,  1.2185,  1.0705,  1.2628,  1.3498,  1.3563,  1.2803,  1.3491,
          1.3491,  1.7625,  1.9573,  1.7434,  2.4413,  1.8002,  5.7243,  1.8517,
          1.6954,  5.5250,  1.1663,  1.2444,  1.0832,  1.2083,  1.3333,  1.3658,
          1.3359,  1.3611,  1.3611,  1.3354,  1.1248,  1.3788,  1.3628,  1.1758,
          1.3905,  1.4172,  1.3410,  1.3798,  1.4693,  1.5470,  1.4735,  1.4275,
          1.4612,  1.5176,  1.4600,  0.6996,  1.4369,  1.1150,  1.4286,  1.4146,
          1.3993,  1.1187,  1.4218,  0.9890,  1.3908,  1.4038],
        [ 1.2217,  1.2492,  1.3064,  1.2845,  1.2549,  1.2267,  1.2347,  1.2196,
          1.2196,  1.2856,  1.3011,  1.2996,  1.3204,  1.2726,  1.3058,  1.2849,
          1.2425,  1.2548,  2.7278,  2.8507,  2.9697,  2.8475,  2.6160,  2.7069,
          2.7990,  2.6057,  2.6057,  1.2931,  1.2994,  1.2500,  1.2746,  1.2934,
          1.2615,  1.2896,  1.2577,  1.2525,  1.3818,  1.4248,  1.4058,  1.3562,
          1.3990,  1.3951,  1.3926,  1.2886,  1.2845,  1.3220,  1.3006,  1.2882,
          1.2729,  1.2945,  1.2942,  1.3538,  1.2639,  1.2761],
        [ 1.2281,  1.2557,  1.3098,  1.2881,  1.2617,  1.2331,  1.2415,  1.2259,
          1.2259,  1.2922,  1.3045,  1.3063,  1.3261,  1.2791,  1.2736,  1.2915,
          1.2805,  1.2117,  1.2766,  1.3016,  1.3173,  1.2889,  1.2505,  1.2427,
          1.2662,  1.2387,  1.2387,  2.9778,  2.9085,  2.5583,  2.7146,  2.9751,
          2.5683,  2.9328,  2.5682,  2.5605,  1.3869,  1.4303,  1.4100,  1.3955,
          1.4045,  1.4005,  1.3975,  1.2901,  1.3240,  1.3548,  1.3066,  1.2007,
          1.2330,  1.3504,  1.2972,  1.3867,  1.2241,  1.2830],
        [ 1.8308,  1.4799,  0.6723,  0.8998,  1.2785,  1.7145,  1.6449,  1.8285,
          1.8285,  1.7171,  1.3720,  1.5289,  1.0049,  1.8134,  0.3252,  1.6881,
          1.8606,  1.1558,  1.4067,  0.9691,  0.8200,  1.1843,  1.6852,  1.7429,
          1.4739,  1.8394,  1.8394,  0.8019,  0.9047,  1.8109,  1.6002,  0.8866,
          1.7421,  1.1923,  1.8635,  1.7734,  0.4065,  0.1797,  0.1661,  0.3561,
          0.6001,  0.7151,  0.3006, 13.2291,  6.7325,  0.8567,  1.3549,  1.4654,
          1.7032,  1.0985,  1.6165,  0.4780,  1.7748,  1.8755],
        [ 1.3038,  1.3314,  1.3893,  1.3677,  1.3380,  1.3088,  1.2719,  1.3017,
          1.3017,  1.2710,  1.3807,  1.2849,  1.4007,  1.3523,  1.4409,  1.2702,
          1.3542,  1.2889,  1.3508,  1.3762,  1.3923,  1.3628,  1.3246,  1.3172,
          1.2509,  1.3127,  1.3127,  1.3583,  1.4030,  1.3301,  1.1339,  1.3117,
          1.2043,  1.3694,  1.2019,  1.3326,  1.4570,  1.1566,  1.4794,  1.4677,
          1.0428,  0.9581,  1.4681,  1.4191,  0.8453,  3.3426,  2.6328,  3.5323,
          2.9141,  2.2334,  1.9369,  3.0121,  3.2748,  1.9220]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 255 : 181.5541799541122
Test loss for epoch 255 : 181.64494458027949
Test Precision for epoch 255 : 0.26153846153846155
Test Recall for epoch 255 : 0.26153846153846155
Test F1 for epoch 255 : 0.26153846153846155


theta for epoch 256 : tensor([[ 2.6737,  2.6992,  2.7649,  2.8877,  2.8552,  2.6781,  2.8360,  2.6718,
          2.6718,  1.2789,  1.2946,  1.2930,  1.3141,  1.2659,  1.3548,  1.2782,
          1.2678,  1.2506,  1.2636,  1.2452,  1.2593,  1.2758,  1.2377,  1.2307,
          1.2542,  1.2259,  1.2259,  1.2718,  1.3162,  1.2430,  1.2678,  1.3180,
          1.2544,  1.2827,  1.2050,  1.2455,  1.3744,  1.4176,  1.3988,  1.3850,
          1.3918,  1.3354,  1.3854,  1.3377,  1.3131,  1.3421,  1.2954,  1.2830,
          1.2678,  1.3378,  1.2891,  1.3737,  1.2594,  1.2711],
        [ 1.3033,  1.2163,  1.0696,  1.2609,  1.3476,  1.3536,  1.2777,  1.3463,
          1.3463,  1.7649,  1.9585,  1.7453,  2.4401,  1.8023,  5.7300,  1.8536,
          1.6978,  5.5309,  1.1676,  1.2459,  1.0859,  1.2092,  1.3337,  1.3660,
          1.3362,  1.3612,  1.3612,  1.3358,  1.1266,  1.3787,  1.3629,  1.1765,
          1.3903,  1.4171,  1.3408,  1.3796,  1.4695,  1.5465,  1.4730,  1.4275,
          1.4621,  1.5171,  1.4594,  0.7025,  1.4363,  1.1175,  1.4286,  1.4146,
          1.3993,  1.1204,  1.4218,  0.9925,  1.3908,  1.4038],
        [ 1.2188,  1.2462,  1.3035,  1.2816,  1.2520,  1.2238,  1.2318,  1.2166,
          1.2166,  1.2850,  1.3007,  1.2991,  1.3201,  1.2720,  1.3056,  1.2843,
          1.2416,  1.2554,  2.7309,  2.8546,  2.9729,  2.8497,  2.6198,  2.7098,
          2.8031,  2.6095,  2.6095,  1.2924,  1.2994,  1.2496,  1.2742,  1.2927,
          1.2610,  1.2892,  1.2572,  1.2521,  1.3810,  1.4242,  1.4051,  1.3551,
          1.3982,  1.3945,  1.3920,  1.2885,  1.2834,  1.3221,  1.3002,  1.2877,
          1.2725,  1.2950,  1.2938,  1.3539,  1.2634,  1.2757],
        [ 1.2262,  1.2538,  1.3081,  1.2864,  1.2598,  1.2312,  1.2395,  1.2240,
          1.2240,  1.2925,  1.3050,  1.3066,  1.3266,  1.2794,  1.2741,  1.2918,
          1.2808,  1.2124,  1.2773,  1.3023,  1.3180,  1.2895,  1.2512,  1.2434,
          1.2668,  1.2394,  1.2394,  2.9791,  2.9116,  2.5606,  2.7172,  2.9764,
          2.5705,  2.9341,  2.5704,  2.5628,  1.3867,  1.4302,  1.4100,  1.3954,
          1.4043,  1.4004,  1.3974,  1.2898,  1.3239,  1.3551,  1.3070,  1.2011,
          1.2334,  1.3507,  1.2977,  1.3871,  1.2245,  1.2833],
        [ 1.8299,  1.4788,  0.6714,  0.8992,  1.2776,  1.7137,  1.6440,  1.8276,
          1.8276,  1.7183,  1.3724,  1.5299,  1.0049,  1.8142,  0.3248,  1.6888,
          1.8619,  1.1535,  1.4072,  0.9701,  0.8201,  1.1851,  1.6865,  1.7439,
          1.4754,  1.8408,  1.8408,  0.8036,  0.9051,  1.8121,  1.6015,  0.8879,
          1.7434,  1.1939,  1.8648,  1.7746,  0.4048,  0.1779,  0.1643,  0.3543,
          0.5985,  0.7127,  0.2987, 13.2706,  6.7105,  0.8570,  1.3567,  1.4672,
          1.7048,  1.0988,  1.6179,  0.4779,  1.7764,  1.8769],
        [ 1.3004,  1.3280,  1.3859,  1.3643,  1.3345,  1.3054,  1.2684,  1.2982,
          1.2982,  1.2700,  1.3799,  1.2840,  1.4000,  1.3514,  1.4403,  1.2693,
          1.3534,  1.2882,  1.3502,  1.3755,  1.3918,  1.3623,  1.3240,  1.3167,
          1.2501,  1.3121,  1.3121,  1.3576,  1.4023,  1.3293,  1.1327,  1.3109,
          1.2033,  1.3686,  1.2010,  1.3318,  1.4560,  1.1552,  1.4783,  1.4667,
          1.0411,  0.9565,  1.4671,  1.4177,  0.8436,  3.3486,  2.6367,  3.5392,
          2.9184,  2.2367,  1.9401,  3.0163,  3.2809,  1.9251]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 256 : 181.5486074993616
Test loss for epoch 256 : 181.63807895379213
Test Precision for epoch 256 : 0.26153846153846155
Test Recall for epoch 256 : 0.26153846153846155
Test F1 for epoch 256 : 0.26153846153846155


theta for epoch 257 : tensor([[ 2.6779,  2.7034,  2.7691,  2.8922,  2.8597,  2.6823,  2.8404,  2.6760,
          2.6760,  1.2779,  1.2936,  1.2920,  1.3132,  1.2649,  1.3540,  1.2772,
          1.2668,  1.2498,  1.2614,  1.2429,  1.2570,  1.2736,  1.2354,  1.2285,
          1.2519,  1.2237,  1.2237,  1.2709,  1.3153,  1.2421,  1.2669,  1.3171,
          1.2535,  1.2819,  1.2041,  1.2446,  1.3737,  1.4170,  1.3982,  1.3844,
          1.3910,  1.3347,  1.3847,  1.3365,  1.3124,  1.3396,  1.2929,  1.2804,
          1.2652,  1.3353,  1.2865,  1.3713,  1.2568,  1.2685],
        [ 1.3043,  1.2177,  1.0723,  1.2627,  1.3491,  1.3546,  1.2789,  1.3473,
          1.3473,  1.7670,  1.9594,  1.7470,  2.4385,  1.8040,  5.7351,  1.8551,
          1.6999,  5.5362,  1.1674,  1.2458,  1.0873,  1.2086,  1.3325,  1.3646,
          1.3348,  1.3598,  1.3598,  1.3363,  1.1285,  1.3785,  1.3630,  1.1773,
          1.3902,  1.4170,  1.3407,  1.3796,  1.4700,  1.5464,  1.4728,  1.4280,
          1.4635,  1.5170,  1.4592,  0.7059,  1.4361,  1.1186,  1.4270,  1.4129,
          1.3976,  1.1206,  1.4202,  0.9948,  1.3890,  1.4021],
        [ 1.2203,  1.2477,  1.3049,  1.2831,  1.2535,  1.2253,  1.2333,  1.2181,
          1.2181,  1.2855,  1.3012,  1.2996,  1.3207,  1.2725,  1.3063,  1.2848,
          1.2418,  1.2571,  2.7315,  2.8561,  2.9737,  2.8494,  2.6211,  2.7102,
          2.8048,  2.6108,  2.6108,  1.2925,  1.3002,  1.2500,  1.2746,  1.2928,
          1.2614,  1.2897,  1.2576,  1.2525,  1.3813,  1.4246,  1.4055,  1.3551,
          1.3985,  1.3949,  1.3923,  1.2895,  1.2834,  1.3215,  1.2990,  1.2865,
          1.2713,  1.2949,  1.2926,  1.3533,  1.2622,  1.2745],
        [ 1.2274,  1.2550,  1.3093,  1.2876,  1.2610,  1.2324,  1.2408,  1.2252,
          1.2252,  1.2928,  1.3055,  1.3069,  1.3271,  1.2797,  1.2745,  1.2921,
          1.2810,  1.2131,  1.2764,  1.3014,  1.3171,  1.2887,  1.2502,  1.2426,
          1.2658,  1.2384,  1.2384,  2.9802,  2.9143,  2.5625,  2.7194,  2.9775,
          2.5724,  2.9352,  2.5723,  2.5647,  1.3870,  1.4306,  1.4103,  1.3957,
          1.4045,  1.4007,  1.3977,  1.2899,  1.3241,  1.3541,  1.3060,  1.2002,
          1.2323,  1.3497,  1.2968,  1.3861,  1.2234,  1.2823],
        [ 1.8315,  1.4801,  0.6717,  0.9002,  1.2789,  1.7153,  1.6454,  1.8292,
          1.8292,  1.7188,  1.3721,  1.5301,  1.0038,  1.8144,  0.3232,  1.6888,
          1.8628,  1.1503,  1.4057,  0.9689,  0.8180,  1.1838,  1.6859,  1.7431,
          1.4750,  1.8404,  1.8404,  0.8040,  0.9043,  1.8128,  1.6021,  0.8881,
          1.7440,  1.1945,  1.8654,  1.7752,  0.4040,  0.1769,  0.1634,  0.3533,
          0.5977,  0.7113,  0.2976, 13.3131,  6.6891,  0.8546,  1.3559,  1.4664,
          1.7040,  1.0964,  1.6170,  0.4751,  1.7758,  1.8762],
        [ 1.3021,  1.3298,  1.3877,  1.3661,  1.3363,  1.3072,  1.2702,  1.3000,
          1.3000,  1.2708,  1.3809,  1.2849,  1.4010,  1.3523,  1.4413,  1.2702,
          1.3541,  1.2893,  1.3497,  1.3749,  1.3913,  1.3618,  1.3234,  1.3162,
          1.2494,  1.3115,  1.3115,  1.3585,  1.4032,  1.3301,  1.1335,  1.3118,
          1.2043,  1.3695,  1.2019,  1.3327,  1.4565,  1.1558,  1.4789,  1.4673,
          1.0416,  0.9571,  1.4677,  1.4179,  0.8441,  3.3503,  2.6360,  3.5417,
          2.9182,  2.2356,  1.9388,  3.0163,  3.2826,  1.9239]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 257 : 181.54203763575347
Test loss for epoch 257 : 181.63284169268
Test Precision for epoch 257 : 0.26153846153846155
Test Recall for epoch 257 : 0.26153846153846155
Test F1 for epoch 257 : 0.26153846153846155


theta for epoch 258 : tensor([[ 2.6792,  2.7047,  2.7704,  2.8938,  2.8613,  2.6836,  2.8421,  2.6773,
          2.6773,  1.2776,  1.2934,  1.2917,  1.3132,  1.2646,  1.3539,  1.2770,
          1.2665,  1.2498,  1.2617,  1.2432,  1.2573,  1.2739,  1.2357,  1.2288,
          1.2522,  1.2240,  1.2240,  1.2707,  1.3151,  1.2419,  1.2667,  1.3169,
          1.2533,  1.2817,  1.2039,  1.2444,  1.3739,  1.4173,  1.3984,  1.3846,
          1.3912,  1.3350,  1.3850,  1.3364,  1.3126,  1.3403,  1.2935,  1.2811,
          1.2659,  1.3360,  1.2872,  1.3720,  1.2574,  1.2692],
        [ 1.3037,  1.2176,  1.0735,  1.2628,  1.3490,  1.3539,  1.2784,  1.3467,
          1.3467,  1.7689,  1.9601,  1.7485,  2.4367,  1.8057,  5.7397,  1.8565,
          1.7018,  5.5409,  1.1685,  1.2470,  1.0899,  1.2092,  1.3326,  1.3644,
          1.3347,  1.3596,  1.3596,  1.3363,  1.1299,  1.3778,  1.3626,  1.1777,
          1.3895,  1.4164,  1.3400,  1.3790,  1.4705,  1.5463,  1.4727,  1.4284,
          1.4648,  1.5169,  1.4591,  0.7095,  1.4359,  1.1217,  1.4273,  1.4132,
          1.3979,  1.1228,  1.4205,  0.9989,  1.3893,  1.4024],
        [ 1.2198,  1.2472,  1.3044,  1.2826,  1.2530,  1.2248,  1.2328,  1.2177,
          1.2177,  1.2848,  1.3007,  1.2989,  1.3202,  1.2719,  1.3061,  1.2842,
          1.2408,  1.2577,  2.7332,  2.8586,  2.9755,  2.8501,  2.6235,  2.7117,
          2.8074,  2.6132,  2.6132,  1.2918,  1.3001,  1.2495,  1.2741,  1.2921,
          1.2609,  1.2892,  1.2571,  1.2520,  1.3813,  1.4247,  1.4055,  1.3548,
          1.3984,  1.3949,  1.3924,  1.2902,  1.2831,  1.3227,  1.2996,  1.2871,
          1.2719,  1.2965,  1.2932,  1.3545,  1.2628,  1.2751],
        [ 1.2272,  1.2548,  1.3092,  1.2876,  1.2608,  1.2322,  1.2406,  1.2250,
          1.2250,  1.2925,  1.3054,  1.3066,  1.3270,  1.2794,  1.2744,  1.2918,
          1.2807,  1.2133,  1.2766,  1.3016,  1.3173,  1.2889,  1.2504,  1.2428,
          1.2660,  1.2386,  1.2386,  2.9811,  2.9168,  2.5642,  2.7215,  2.9784,
          2.5742,  2.9361,  2.5740,  2.5664,  1.3872,  1.4309,  1.4106,  1.3960,
          1.4047,  1.4010,  1.3980,  1.2899,  1.3244,  1.3547,  1.3067,  1.2008,
          1.2329,  1.3503,  1.2975,  1.3866,  1.2240,  1.2829],
        [ 1.8315,  1.4797,  0.6707,  0.8997,  1.2785,  1.7153,  1.6453,  1.8293,
          1.8293,  1.7188,  1.3712,  1.5299,  1.0021,  1.8141,  0.3209,  1.6883,
          1.8631,  1.1463,  1.4049,  0.9684,  0.8164,  1.1832,  1.6861,  1.7430,
          1.4754,  1.8409,  1.8409,  0.8037,  0.9028,  1.8128,  1.6019,  0.8875,
          1.7440,  1.1944,  1.8655,  1.7751,  0.4032,  0.1760,  0.1625,  0.3524,
          0.5971,  0.7099,  0.2967, 13.3560,  6.6675,  0.8535,  1.3567,  1.4673,
          1.7048,  1.0954,  1.6178,  0.4734,  1.7768,  1.8771],
        [ 1.3015,  1.3292,  1.3872,  1.3655,  1.3357,  1.3066,  1.2696,  1.2994,
          1.2994,  1.2702,  1.3803,  1.2842,  1.4006,  1.3517,  1.4408,  1.2696,
          1.3535,  1.2890,  1.3497,  1.3749,  1.3913,  1.3619,  1.3234,  1.3162,
          1.2493,  1.3116,  1.3116,  1.3580,  1.4026,  1.3296,  1.1328,  1.3113,
          1.2037,  1.3690,  1.2013,  1.3321,  1.4565,  1.1557,  1.4789,  1.4673,
          1.0412,  0.9569,  1.4678,  1.4175,  0.8439,  3.3542,  2.6376,  3.5464,
          2.9203,  2.2368,  1.9398,  3.0184,  3.2865,  1.9249]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 258 : 181.5360575208961
Test loss for epoch 258 : 181.62679507903147
Test Precision for epoch 258 : 0.26153846153846155
Test Recall for epoch 258 : 0.26153846153846155
Test F1 for epoch 258 : 0.26153846153846155


theta for epoch 259 : tensor([[ 2.6793,  2.7048,  2.7705,  2.8942,  2.8617,  2.6837,  2.8425,  2.6774,
          2.6774,  1.2784,  1.2943,  1.2925,  1.3141,  1.2654,  1.3548,  1.2778,
          1.2672,  1.2509,  1.2631,  1.2446,  1.2588,  1.2754,  1.2371,  1.2303,
          1.2536,  1.2253,  1.2253,  1.2714,  1.3157,  1.2425,  1.2673,  1.3175,
          1.2539,  1.2823,  1.2045,  1.2450,  1.3742,  1.4177,  1.3988,  1.3849,
          1.3914,  1.3354,  1.3854,  1.3363,  1.3130,  1.3415,  1.2947,  1.2822,
          1.2670,  1.3371,  1.2883,  1.3732,  1.2586,  1.2703],
        [ 1.3018,  1.2163,  1.0736,  1.2618,  1.3477,  1.3521,  1.2768,  1.3448,
          1.3448,  1.7719,  1.9618,  1.7510,  2.4358,  1.8083,  5.7449,  1.8589,
          1.7048,  5.5463,  1.1695,  1.2482,  1.0924,  1.2097,  1.3325,  1.3642,
          1.3345,  1.3592,  1.3592,  1.3360,  1.1310,  1.3769,  1.3620,  1.1777,
          1.3886,  1.4155,  1.3391,  1.3781,  1.4704,  1.5455,  1.4718,  1.4281,
          1.4654,  1.5161,  1.4582,  0.7124,  1.4350,  1.1241,  1.4269,  1.4128,
          1.3975,  1.1242,  1.4201,  1.0025,  1.3889,  1.4020],
        [ 1.2186,  1.2460,  1.3033,  1.2814,  1.2518,  1.2236,  1.2316,  1.2165,
          1.2165,  1.2844,  1.3004,  1.2986,  1.3201,  1.2715,  1.3060,  1.2839,
          1.2402,  1.2587,  2.7352,  2.8616,  2.9776,  2.8511,  2.6263,  2.7136,
          2.8106,  2.6160,  2.6160,  1.2911,  1.3001,  1.2490,  1.2736,  1.2914,
          1.2605,  1.2888,  1.2567,  1.2515,  1.3809,  1.4243,  1.4051,  1.3541,
          1.3979,  1.3946,  1.3920,  1.2904,  1.2823,  1.3236,  1.2999,  1.2874,
          1.2721,  1.2978,  1.2935,  1.3554,  1.2630,  1.2754],
        [ 1.2260,  1.2537,  1.3083,  1.2866,  1.2597,  1.2311,  1.2394,  1.2239,
          1.2239,  1.2921,  1.3052,  1.3063,  1.3268,  1.2791,  1.2742,  1.2915,
          1.2803,  1.2134,  1.2768,  1.3018,  1.3175,  1.2892,  1.2506,  1.2431,
          1.2662,  1.2388,  1.2388,  2.9827,  2.9200,  2.5666,  2.7243,  2.9800,
          2.5766,  2.9377,  2.5764,  2.5688,  1.3867,  1.4305,  1.4103,  1.3955,
          1.4041,  1.4006,  1.3976,  1.2892,  1.3239,  1.3548,  1.3067,  1.2008,
          1.2330,  1.3504,  1.2977,  1.3867,  1.2240,  1.2829],
        [ 1.8315,  1.4792,  0.6699,  0.8994,  1.2782,  1.7153,  1.6451,  1.8292,
          1.8292,  1.7194,  1.3709,  1.5302,  1.0012,  1.8143,  0.3194,  1.6884,
          1.8639,  1.1430,  1.4048,  0.9687,  0.8157,  1.1834,  1.6870,  1.7437,
          1.4765,  1.8420,  1.8420,  0.8043,  0.9021,  1.8133,  1.6024,  0.8878,
          1.7446,  1.1951,  1.8660,  1.7756,  0.4019,  0.1745,  0.1611,  0.3510,
          0.5959,  0.7080,  0.2952, 13.3985,  6.6448,  0.8529,  1.3578,  1.4685,
          1.7059,  1.0948,  1.6188,  0.4723,  1.7781,  1.8781],
        [ 1.3005,  1.3281,  1.3862,  1.3645,  1.3347,  1.3055,  1.2685,  1.2983,
          1.2983,  1.2701,  1.3804,  1.2842,  1.4008,  1.3516,  1.4410,  1.2696,
          1.3534,  1.2892,  1.3506,  1.3756,  1.3922,  1.3628,  1.3242,  1.3171,
          1.2499,  1.3123,  1.3123,  1.3578,  1.4024,  1.3294,  1.1325,  1.3111,
          1.2035,  1.3688,  1.2011,  1.3319,  1.4562,  1.1553,  1.4786,  1.4671,
          1.0406,  0.9565,  1.4675,  1.4167,  0.8434,  3.3578,  2.6390,  3.5508,
          2.9221,  2.2377,  1.9405,  3.0202,  3.2901,  1.9256]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 259 : 181.53087901139992
Test loss for epoch 259 : 181.62177988061455
Test Precision for epoch 259 : 0.26153846153846155
Test Recall for epoch 259 : 0.26153846153846155
Test F1 for epoch 259 : 0.26153846153846155


theta for epoch 260 : tensor([[ 2.6835,  2.7090,  2.7747,  2.8987,  2.8662,  2.6879,  2.8470,  2.6816,
          2.6816,  1.2771,  1.2931,  1.2913,  1.3130,  1.2642,  1.3537,  1.2766,
          1.2659,  1.2499,  1.2612,  1.2427,  1.2568,  1.2735,  1.2352,  1.2284,
          1.2517,  1.2234,  1.2234,  1.2701,  1.3144,  1.2412,  1.2660,  1.3163,
          1.2526,  1.2810,  1.2032,  1.2437,  1.3733,  1.4169,  1.3980,  1.3841,
          1.3905,  1.3346,  1.3846,  1.3350,  1.3121,  1.3393,  1.2925,  1.2800,
          1.2648,  1.3350,  1.2861,  1.3711,  1.2563,  1.2681],
        [ 1.3030,  1.2180,  1.0766,  1.2638,  1.3494,  1.3532,  1.2781,  1.3460,
          1.3460,  1.7746,  1.9631,  1.7532,  2.4344,  1.8106,  5.7493,  1.8609,
          1.7074,  5.5509,  1.1694,  1.2483,  1.0941,  1.2091,  1.3313,  1.3627,
          1.3331,  1.3577,  1.3577,  1.3360,  1.1325,  1.3761,  1.3615,  1.1781,
          1.3878,  1.4148,  1.3383,  1.3774,  1.4705,  1.5450,  1.4713,  1.4282,
          1.4665,  1.5157,  1.4577,  0.7160,  1.4344,  1.1255,  1.4252,  1.4111,
          1.3958,  1.1246,  1.4185,  1.0053,  1.3872,  1.4004],
        [ 1.2207,  1.2481,  1.3053,  1.2835,  1.2539,  1.2257,  1.2337,  1.2186,
          1.2186,  1.2847,  1.3008,  1.2989,  1.3206,  1.2719,  1.3067,  1.2843,
          1.2402,  1.2603,  2.7356,  2.8628,  2.9781,  2.8505,  2.6274,  2.7137,
          2.8120,  2.6171,  2.6171,  1.2910,  1.3007,  1.2492,  1.2738,  1.2913,
          1.2606,  1.2890,  1.2569,  1.2517,  1.3811,  1.4247,  1.4054,  1.3540,
          1.3981,  1.3949,  1.3923,  1.2913,  1.2823,  1.3236,  1.2994,  1.2869,
          1.2716,  1.2984,  1.2930,  1.3555,  1.2624,  1.2749],
        [ 1.2274,  1.2550,  1.3096,  1.2880,  1.2610,  1.2324,  1.2408,  1.2252,
          1.2252,  1.2918,  1.3051,  1.3060,  1.3268,  1.2788,  1.2741,  1.2912,
          1.2800,  1.2136,  1.2758,  1.3009,  1.3166,  1.2882,  1.2496,  1.2421,
          1.2652,  1.2378,  1.2378,  2.9841,  2.9229,  2.5688,  2.7268,  2.9814,
          2.5787,  2.9391,  2.5785,  2.5710,  1.3866,  1.4305,  1.4102,  1.3955,
          1.4040,  1.4006,  1.3975,  1.2888,  1.3238,  1.3538,  1.3058,  1.1999,
          1.2320,  1.3494,  1.2968,  1.3857,  1.2229,  1.2819],
        [ 1.8337,  1.4811,  0.6709,  0.9010,  1.2802,  1.7176,  1.6472,  1.8315,
          1.8315,  1.7200,  1.3706,  1.5306,  1.0002,  1.8144,  0.3178,  1.6884,
          1.8647,  1.1395,  1.4036,  0.9681,  0.8140,  1.1825,  1.6868,  1.7433,
          1.4765,  1.8420,  1.8420,  0.8049,  0.9014,  1.8138,  1.6029,  0.8881,
          1.7451,  1.1958,  1.8665,  1.7761,  0.4005,  0.1730,  0.1596,  0.3496,
          0.5947,  0.7060,  0.2937, 13.4413,  6.6218,  0.8511,  1.3578,  1.4684,
          1.7058,  1.0930,  1.6185,  0.4701,  1.7781,  1.8779],
        [ 1.3026,  1.3302,  1.3883,  1.3666,  1.3368,  1.3076,  1.2707,  1.3004,
          1.3004,  1.2705,  1.3809,  1.2847,  1.4014,  1.3520,  1.4415,  1.2701,
          1.3538,  1.2900,  1.3504,  1.3753,  1.3920,  1.3626,  1.3240,  1.3169,
          1.2495,  1.3121,  1.3121,  1.3581,  1.4028,  1.3297,  1.1327,  1.3115,
          1.2039,  1.3692,  1.2015,  1.3323,  1.4565,  1.1556,  1.4789,  1.4674,
          1.0408,  0.9568,  1.4679,  1.4166,  0.8436,  3.3597,  2.6385,  3.5534,
          2.9222,  2.2368,  1.9395,  3.0204,  3.2920,  1.9246]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 260 : 181.52536175143408
Test loss for epoch 260 : 181.6173209138746
Test Precision for epoch 260 : 0.26153846153846155
Test Recall for epoch 260 : 0.26153846153846155
Test F1 for epoch 260 : 0.26153846153846155


theta for epoch 261 : tensor([[ 2.6831,  2.7086,  2.7743,  2.8986,  2.8661,  2.6875,  2.8469,  2.6812,
          2.6812,  1.2778,  1.2940,  1.2920,  1.3140,  1.2650,  1.3547,  1.2774,
          1.2666,  1.2510,  1.2626,  1.2441,  1.2583,  1.2750,  1.2366,  1.2298,
          1.2531,  1.2248,  1.2248,  1.2710,  1.3153,  1.2420,  1.2669,  1.3171,
          1.2535,  1.2819,  1.2040,  1.2446,  1.3744,  1.4181,  1.3992,  1.3852,
          1.3915,  1.3358,  1.3857,  1.3356,  1.3132,  1.3406,  1.2938,  1.2812,
          1.2661,  1.3363,  1.2874,  1.3723,  1.2576,  1.2693],
        [ 1.3011,  1.2168,  1.0770,  1.2630,  1.3482,  1.3513,  1.2765,  1.3441,
          1.3441,  1.7769,  1.9641,  1.7550,  2.4325,  1.8125,  5.7529,  1.8626,
          1.7096,  5.5546,  1.1712,  1.2501,  1.0974,  1.2102,  1.3318,  1.3629,
          1.3335,  1.3579,  1.3579,  1.3363,  1.1344,  1.3757,  1.3614,  1.1788,
          1.3874,  1.4144,  1.3378,  1.3770,  1.4713,  1.5451,  1.4713,  1.4289,
          1.4681,  1.5158,  1.4577,  0.7203,  1.4344,  1.1288,  1.4254,  1.4113,
          1.3960,  1.1270,  1.4187,  1.0098,  1.3873,  1.4005],
        [ 1.2186,  1.2460,  1.3032,  1.2814,  1.2518,  1.2236,  1.2316,  1.2165,
          1.2165,  1.2838,  1.3000,  1.2981,  1.3199,  1.2710,  1.3063,  1.2834,
          1.2391,  1.2608,  2.7381,  2.8662,  2.9806,  2.8520,  2.6307,  2.7160,
          2.8155,  2.6204,  2.6204,  1.2901,  1.3006,  1.2485,  1.2731,  1.2904,
          1.2600,  1.2884,  1.2562,  1.2511,  1.3810,  1.4247,  1.4055,  1.3537,
          1.3980,  1.3949,  1.3923,  1.2919,  1.2819,  1.3241,  1.2993,  1.2867,
          1.2715,  1.2993,  1.2929,  1.3559,  1.2623,  1.2748],
        [ 1.2263,  1.2539,  1.3086,  1.2870,  1.2599,  1.2313,  1.2396,  1.2241,
          1.2241,  1.2917,  1.3053,  1.3060,  1.3270,  1.2788,  1.2743,  1.2913,
          1.2800,  1.2141,  1.2766,  1.3016,  1.3173,  1.2890,  1.2503,  1.2429,
          1.2658,  1.2385,  1.2385,  2.9849,  2.9253,  2.5704,  2.7287,  2.9823,
          2.5804,  2.9400,  2.5801,  2.5726,  1.3871,  1.4311,  1.4109,  1.3960,
          1.4044,  1.4012,  1.3981,  1.2891,  1.3243,  1.3543,  1.3064,  1.2005,
          1.2326,  1.3499,  1.2975,  1.3863,  1.2235,  1.2825],
        [ 1.8330,  1.4800,  0.6694,  0.9001,  1.2792,  1.7170,  1.6464,  1.8308,
          1.8308,  1.7204,  1.3701,  1.5307,  0.9989,  1.8144,  0.3158,  1.6883,
          1.8654,  1.1357,  1.4032,  0.9681,  0.8130,  1.1825,  1.6875,  1.7438,
          1.4775,  1.8430,  1.8430,  0.8054,  0.9005,  1.8144,  1.6033,  0.8882,
          1.7456,  1.1964,  1.8670,  1.7766,  0.3995,  0.1719,  0.1585,  0.3484,
          0.5937,  0.7043,  0.2924, 13.4845,  6.5986,  0.8503,  1.3590,  1.4696,
          1.7069,  1.0922,  1.6196,  0.4686,  1.7793,  1.8790],
        [ 1.3000,  1.3277,  1.3858,  1.3641,  1.3342,  1.3050,  1.2681,  1.2979,
          1.2979,  1.2693,  1.3798,  1.2835,  1.4004,  1.3509,  1.4406,  1.2689,
          1.3526,  1.2891,  1.3499,  1.3748,  1.3915,  1.3621,  1.3235,  1.3164,
          1.2488,  1.3116,  1.3116,  1.3571,  1.4018,  1.3287,  1.1314,  1.3105,
          1.2028,  1.3682,  1.2004,  1.3313,  1.4562,  1.1551,  1.4786,  1.4672,
          1.0400,  0.9561,  1.4677,  1.4159,  0.8428,  3.3650,  2.6416,  3.5596,
          2.9257,  2.2395,  1.9420,  3.0239,  3.2974,  1.9270]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 261 : 181.51896662199275
Test loss for epoch 261 : 181.6099924064152
Test Precision for epoch 261 : 0.26153846153846155
Test Recall for epoch 261 : 0.26153846153846155
Test F1 for epoch 261 : 0.26153846153846155


theta for epoch 262 : tensor([[ 2.6856,  2.7111,  2.7768,  2.9014,  2.8690,  2.6900,  2.8497,  2.6837,
          2.6837,  1.2777,  1.2939,  1.2919,  1.3141,  1.2649,  1.3547,  1.2773,
          1.2665,  1.2511,  1.2617,  1.2431,  1.2573,  1.2741,  1.2356,  1.2289,
          1.2521,  1.2238,  1.2238,  1.2708,  1.3151,  1.2418,  1.2667,  1.3170,
          1.2533,  1.2817,  1.2038,  1.2444,  1.3744,  1.4182,  1.3993,  1.3853,
          1.3915,  1.3359,  1.3858,  1.3352,  1.3133,  1.3390,  1.2921,  1.2796,
          1.2644,  1.3347,  1.2858,  1.3707,  1.2559,  1.2677],
        [ 1.3008,  1.2171,  1.0789,  1.2636,  1.3485,  1.3509,  1.2764,  1.3437,
          1.3437,  1.7799,  1.9656,  1.7575,  2.4312,  1.8151,  5.7568,  1.8649,
          1.7126,  5.5586,  1.1717,  1.2507,  1.0996,  1.2101,  1.3310,  1.3618,
          1.3325,  1.3568,  1.3568,  1.3366,  1.1362,  1.3752,  1.3613,  1.1796,
          1.3869,  1.4140,  1.3374,  1.3766,  1.4717,  1.5449,  1.4711,  1.4292,
          1.4694,  1.5156,  1.4575,  0.7245,  1.4341,  1.1304,  1.4237,  1.4095,
          1.3942,  1.1276,  1.4170,  1.0130,  1.3855,  1.3988],
        [ 1.2188,  1.2462,  1.3034,  1.2816,  1.2520,  1.2238,  1.2318,  1.2167,
          1.2167,  1.2841,  1.3004,  1.2984,  1.3205,  1.2713,  1.3069,  1.2838,
          1.2391,  1.2625,  2.7393,  2.8682,  2.9818,  2.8521,  2.6327,  2.7170,
          2.8178,  2.6224,  2.6224,  1.2900,  1.3011,  1.2486,  1.2732,  1.2903,
          1.2601,  1.2885,  1.2563,  1.2512,  1.3812,  1.4250,  1.4058,  1.3536,
          1.3982,  1.3952,  1.3926,  1.2929,  1.2818,  1.3235,  1.2981,  1.2855,
          1.2703,  1.2992,  1.2917,  1.3554,  1.2610,  1.2736],
        [ 1.2265,  1.2541,  1.3089,  1.2873,  1.2601,  1.2315,  1.2399,  1.2244,
          1.2244,  1.2920,  1.3058,  1.3063,  1.3275,  1.2791,  1.2748,  1.2916,
          1.2802,  1.2149,  1.2761,  1.3011,  1.3169,  1.2886,  1.2498,  1.2425,
          1.2654,  1.2380,  1.2380,  2.9861,  2.9280,  2.5723,  2.7310,  2.9835,
          2.5823,  2.9412,  2.5820,  2.5745,  1.3874,  1.4315,  1.4113,  1.3964,
          1.4047,  1.4017,  1.3985,  1.2892,  1.3247,  1.3534,  1.3055,  1.1996,
          1.2317,  1.3491,  1.2968,  1.3854,  1.2226,  1.2816],
        [ 1.8338,  1.4802,  0.6689,  0.9003,  1.2796,  1.7177,  1.6470,  1.8316,
          1.8316,  1.7211,  1.3697,  1.5311,  0.9977,  1.8147,  0.3138,  1.6884,
          1.8664,  1.1319,  1.4019,  0.9672,  0.8110,  1.1816,  1.6874,  1.7434,
          1.4775,  1.8431,  1.8431,  0.8058,  0.8997,  1.8151,  1.6039,  0.8882,
          1.7463,  1.1971,  1.8677,  1.7772,  0.3985,  0.1708,  0.1574,  0.3474,
          0.5929,  0.7027,  0.2913, 13.5280,  6.5752,  0.8479,  1.3585,  1.4692,
          1.7064,  1.0897,  1.6190,  0.4656,  1.7790,  1.8785],
        [ 1.3007,  1.3284,  1.3865,  1.3647,  1.3349,  1.3057,  1.2688,  1.2985,
          1.2985,  1.2702,  1.3808,  1.2844,  1.4016,  1.3518,  1.4417,  1.2699,
          1.3535,  1.2904,  1.3501,  1.3748,  1.3917,  1.3623,  1.3236,  1.3166,
          1.2488,  1.3117,  1.3117,  1.3579,  1.4026,  1.3295,  1.1322,  1.3114,
          1.2037,  1.3690,  1.2012,  1.3321,  1.4569,  1.1558,  1.4792,  1.4679,
          1.0405,  0.9568,  1.4684,  1.4161,  0.8434,  3.3668,  2.6411,  3.5621,
          2.9257,  2.2385,  1.9409,  3.0240,  3.2991,  1.9259]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 262 : 181.5126170473857
Test loss for epoch 262 : 181.60497298496497
Test Precision for epoch 262 : 0.26153846153846155
Test Recall for epoch 262 : 0.26153846153846155
Test F1 for epoch 262 : 0.26153846153846155


theta for epoch 263 : tensor([[ 2.6881,  2.7136,  2.7793,  2.9042,  2.8718,  2.6925,  2.8525,  2.6862,
          2.6862,  1.2770,  1.2934,  1.2913,  1.3137,  1.2642,  1.3543,  1.2767,
          1.2658,  1.2508,  1.2609,  1.2423,  1.2565,  1.2733,  1.2347,  1.2280,
          1.2513,  1.2230,  1.2230,  1.2702,  1.3145,  1.2413,  1.2661,  1.3164,
          1.2527,  1.2812,  1.2032,  1.2438,  1.3737,  1.4176,  1.3987,  1.3847,
          1.3908,  1.3354,  1.3852,  1.3340,  1.3126,  1.3389,  1.2921,  1.2795,
          1.2643,  1.3346,  1.2857,  1.3707,  1.2558,  1.2676],
        [ 1.3006,  1.2176,  1.0810,  1.2645,  1.3490,  1.3508,  1.2765,  1.3436,
          1.3436,  1.7828,  1.9670,  1.7598,  2.4296,  1.8176,  5.7600,  1.8671,
          1.7154,  5.5619,  1.1724,  1.2516,  1.1021,  1.2100,  1.3303,  1.3608,
          1.3315,  1.3557,  1.3557,  1.3367,  1.1379,  1.3745,  1.3609,  1.1802,
          1.3862,  1.4134,  1.3366,  1.3759,  1.4716,  1.5441,  1.4703,  1.4290,
          1.4701,  1.5148,  1.4566,  0.7284,  1.4332,  1.1336,  1.4236,  1.4094,
          1.3941,  1.1299,  1.4168,  1.0176,  1.3854,  1.3987],
        [ 1.2194,  1.2468,  1.3039,  1.2822,  1.2525,  1.2244,  1.2324,  1.2173,
          1.2173,  1.2840,  1.3005,  1.2984,  1.3206,  1.2713,  1.3073,  1.2838,
          1.2387,  1.2639,  2.7403,  2.8700,  2.9827,  2.8519,  2.6345,  2.7177,
          2.8198,  2.6241,  2.6241,  1.2897,  1.3016,  1.2486,  1.2732,  1.2900,
          1.2600,  1.2885,  1.2563,  1.2511,  1.3810,  1.4249,  1.4056,  1.3530,
          1.3978,  1.3950,  1.3924,  1.2933,  1.2812,  1.3249,  1.2989,  1.2863,
          1.2711,  1.3011,  1.2925,  1.3568,  1.2618,  1.2744],
        [ 1.2269,  1.2545,  1.3093,  1.2877,  1.2605,  1.2319,  1.2402,  1.2247,
          1.2247,  1.2917,  1.3057,  1.3061,  1.3275,  1.2788,  1.2748,  1.2914,
          1.2799,  1.2151,  1.2757,  1.3007,  1.3164,  1.2882,  1.2494,  1.2421,
          1.2649,  1.2375,  1.2375,  2.9874,  2.9306,  2.5742,  2.7332,  2.9848,
          2.5842,  2.9424,  2.5839,  2.5764,  1.3870,  1.4312,  1.4111,  1.3961,
          1.4043,  1.4014,  1.3982,  1.2885,  1.3243,  1.3537,  1.3059,  1.2000,
          1.2320,  1.3494,  1.2972,  1.3857,  1.2229,  1.2819],
        [ 1.8351,  1.4810,  0.6691,  0.9011,  1.2806,  1.7191,  1.6481,  1.8329,
          1.8329,  1.7217,  1.3694,  1.5315,  0.9966,  1.8148,  0.3121,  1.6884,
          1.8672,  1.1281,  1.4010,  0.9669,  0.8096,  1.1811,  1.6876,  1.7434,
          1.4780,  1.8435,  1.8435,  0.8067,  0.8991,  1.8158,  1.6045,  0.8886,
          1.7471,  1.1980,  1.8684,  1.7779,  0.3969,  0.1691,  0.1557,  0.3456,
          0.5913,  0.7004,  0.2895, 13.5712,  6.5507,  0.8473,  1.3600,  1.4706,
          1.7077,  1.0891,  1.6202,  0.4644,  1.7805,  1.8798],
        [ 1.3008,  1.3285,  1.3866,  1.3649,  1.3350,  1.3058,  1.2689,  1.2986,
          1.2986,  1.2697,  1.3805,  1.2840,  1.4013,  1.3514,  1.4414,  1.2695,
          1.3530,  1.2902,  1.3493,  1.3740,  1.3910,  1.3616,  1.3229,  1.3159,
          1.2479,  1.3110,  1.3110,  1.3576,  1.4022,  1.3291,  1.1316,  1.3110,
          1.2033,  1.3687,  1.2008,  1.3317,  1.4563,  1.1552,  1.4787,  1.4674,
          1.0397,  0.9560,  1.4680,  1.4151,  0.8426,  3.3707,  2.6428,  3.5668,
          2.9278,  2.2398,  1.9419,  3.0261,  3.3030,  1.9270]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 263 : 181.50665035964298
Test loss for epoch 263 : 181.59865916980803
Test Precision for epoch 263 : 0.26153846153846155
Test Recall for epoch 263 : 0.26153846153846155
Test F1 for epoch 263 : 0.26153846153846155


theta for epoch 264 : tensor([[ 2.6879,  2.7134,  2.7792,  2.9044,  2.8719,  2.6923,  2.8526,  2.6860,
          2.6860,  1.2776,  1.2941,  1.2920,  1.3145,  1.2649,  1.3551,  1.2774,
          1.2664,  1.2518,  1.2627,  1.2441,  1.2583,  1.2751,  1.2366,  1.2299,
          1.2531,  1.2248,  1.2248,  1.2708,  1.3151,  1.2419,  1.2668,  1.3170,
          1.2534,  1.2818,  1.2039,  1.2445,  1.3743,  1.4183,  1.3994,  1.3853,
          1.3914,  1.3361,  1.3859,  1.3342,  1.3133,  1.3399,  1.2930,  1.2804,
          1.2653,  1.3356,  1.2866,  1.3717,  1.2567,  1.2685],
        [ 1.2988,  1.2166,  1.0817,  1.2638,  1.3479,  1.3490,  1.2749,  1.3417,
          1.3417,  1.7860,  1.9687,  1.7625,  2.4282,  1.8204,  5.7632,  1.8696,
          1.7186,  5.5652,  1.1744,  1.2537,  1.1058,  1.2113,  1.3309,  1.3611,
          1.3319,  1.3559,  1.3559,  1.3366,  1.1394,  1.3735,  1.3604,  1.1806,
          1.3852,  1.4124,  1.3356,  1.3750,  1.4717,  1.5435,  1.4696,  1.4290,
          1.4710,  1.5142,  1.4560,  0.7325,  1.4325,  1.1365,  1.4230,  1.4087,
          1.3935,  1.1318,  1.4163,  1.0220,  1.3847,  1.3980],
        [ 1.2179,  1.2452,  1.3024,  1.2806,  1.2510,  1.2228,  1.2308,  1.2157,
          1.2157,  1.2832,  1.2997,  1.2975,  1.3200,  1.2705,  1.3069,  1.2830,
          1.2376,  1.2645,  2.7428,  2.8734,  2.9852,  2.8533,  2.6379,  2.7200,
          2.8234,  2.6276,  2.6276,  1.2887,  1.3013,  1.2479,  1.2724,  1.2890,
          1.2593,  1.2878,  1.2555,  1.2504,  1.3805,  1.4245,  1.4052,  1.3523,
          1.3973,  1.3947,  1.3920,  1.2936,  1.2804,  1.3252,  1.2985,  1.2859,
          1.2708,  1.3019,  1.2922,  1.3571,  1.2614,  1.2741],
        [ 1.2259,  1.2534,  1.3085,  1.2869,  1.2595,  1.2309,  1.2392,  1.2237,
          1.2237,  1.2913,  1.3055,  1.3057,  1.3274,  1.2785,  1.2746,  1.2910,
          1.2795,  1.2152,  1.2765,  1.3015,  1.3172,  1.2890,  1.2502,  1.2429,
          1.2657,  1.2383,  1.2383,  2.9887,  2.9334,  2.5762,  2.7356,  2.9862,
          2.5862,  2.9438,  2.5860,  2.5784,  1.3869,  1.4312,  1.4110,  1.3960,
          1.4041,  1.4014,  1.3982,  1.2881,  1.3242,  1.3537,  1.3059,  1.2000,
          1.2320,  1.3494,  1.2973,  1.3857,  1.2228,  1.2819],
        [ 1.8349,  1.4802,  0.6677,  0.9004,  1.2799,  1.7189,  1.6477,  1.8327,
          1.8327,  1.7221,  1.3687,  1.5317,  0.9950,  1.8147,  0.3097,  1.6882,
          1.8678,  1.1237,  1.4007,  0.9671,  0.8086,  1.1813,  1.6886,  1.7443,
          1.4793,  1.8448,  1.8448,  0.8069,  0.8979,  1.8162,  1.6048,  0.8884,
          1.7475,  1.1985,  1.8688,  1.7783,  0.3957,  0.1677,  0.1544,  0.3443,
          0.5902,  0.6986,  0.2881, 13.6151,  6.5262,  0.8459,  1.3608,  1.4714,
          1.7085,  1.0877,  1.6209,  0.4623,  1.7814,  1.8805],
        [ 1.2998,  1.3275,  1.3856,  1.3639,  1.3340,  1.3048,  1.2679,  1.2976,
          1.2976,  1.2695,  1.3804,  1.2838,  1.4014,  1.3512,  1.4415,  1.2693,
          1.3528,  1.2904,  1.3508,  1.3753,  1.3924,  1.3631,  1.3243,  1.3174,
          1.2491,  1.3124,  1.3124,  1.3574,  1.4021,  1.3290,  1.1313,  1.3109,
          1.2032,  1.3685,  1.2007,  1.3315,  1.4563,  1.1551,  1.4787,  1.4674,
          1.0394,  0.9559,  1.4681,  1.4146,  0.8424,  3.3739,  2.6437,  3.5707,
          2.9291,  2.2403,  1.9423,  3.0275,  3.3062,  1.9273]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 264 : 181.50070892055965
Test loss for epoch 264 : 181.59300014636958
Test Precision for epoch 264 : 0.26153846153846155
Test Recall for epoch 264 : 0.26153846153846155
Test F1 for epoch 264 : 0.26153846153846155


theta for epoch 265 : tensor([[ 2.6910,  2.7165,  2.7823,  2.9078,  2.8754,  2.6954,  2.8561,  2.6891,
          2.6891,  1.2769,  1.2935,  1.2912,  1.3140,  1.2642,  1.3546,  1.2767,
          1.2657,  1.2514,  1.2610,  1.2423,  1.2566,  1.2734,  1.2348,  1.2282,
          1.2514,  1.2230,  1.2230,  1.2699,  1.3142,  1.2411,  1.2659,  1.3162,
          1.2525,  1.2810,  1.2030,  1.2436,  1.3742,  1.4183,  1.3994,  1.3853,
          1.3912,  1.3361,  1.3859,  1.3335,  1.3132,  1.3385,  1.2916,  1.2790,
          1.2639,  1.3342,  1.2852,  1.3703,  1.2553,  1.2671],
        [ 1.2992,  1.2178,  1.0847,  1.2654,  1.3491,  1.3494,  1.2756,  1.3422,
          1.3422,  1.7893,  1.9705,  1.7653,  2.4267,  1.8232,  5.7659,  1.8723,
          1.7219,  5.5679,  1.1745,  1.2539,  1.1077,  1.2105,  1.3294,  1.3592,
          1.3302,  1.3540,  1.3540,  1.3366,  1.1411,  1.3726,  1.3599,  1.1812,
          1.3843,  1.4116,  1.3347,  1.3742,  1.4721,  1.5433,  1.4693,  1.4294,
          1.4723,  1.5140,  1.4557,  0.7373,  1.4321,  1.1388,  1.4215,  1.4073,
          1.3920,  1.1330,  1.4149,  1.0260,  1.3833,  1.3966],
        [ 1.2196,  1.2469,  1.3040,  1.2823,  1.2527,  1.2245,  1.2325,  1.2174,
          1.2174,  1.2838,  1.3004,  1.2981,  1.3208,  1.2711,  1.3079,  1.2836,
          1.2379,  1.2666,  2.7428,  2.8742,  2.9851,  2.8521,  2.6387,  2.7197,
          2.8244,  2.6284,  2.6284,  1.2887,  1.3021,  1.2481,  1.2727,  1.2890,
          1.2596,  1.2880,  1.2558,  1.2507,  1.3812,  1.4253,  1.4059,  1.3527,
          1.3979,  1.3954,  1.3928,  1.2949,  1.2808,  1.3258,  1.2986,  1.2860,
          1.2708,  1.3031,  1.2923,  1.3578,  1.2615,  1.2741],
        [ 1.2269,  1.2544,  1.3095,  1.2879,  1.2604,  1.2318,  1.2402,  1.2247,
          1.2247,  1.2912,  1.3057,  1.3056,  1.3275,  1.2784,  1.2748,  1.2910,
          1.2794,  1.2157,  1.2755,  1.3004,  1.3162,  1.2880,  1.2491,  1.2419,
          1.2645,  1.2372,  1.2372,  2.9899,  2.9359,  2.5780,  2.7377,  2.9874,
          2.5880,  2.9450,  2.5877,  2.5802,  1.3872,  1.4316,  1.4115,  1.3964,
          1.4044,  1.4018,  1.3986,  1.2881,  1.3245,  1.3531,  1.3053,  1.1995,
          1.2314,  1.3488,  1.2969,  1.3851,  1.2222,  1.2814],
        [ 1.8364,  1.4811,  0.6676,  0.9011,  1.2809,  1.7204,  1.6490,  1.8343,
          1.8343,  1.7225,  1.3680,  1.5318,  0.9933,  1.8147,  0.3071,  1.6880,
          1.8685,  1.1192,  1.3988,  0.9656,  0.8059,  1.1799,  1.6880,  1.7434,
          1.4789,  1.8445,  1.8445,  0.8069,  0.8966,  1.8165,  1.6049,  0.8880,
          1.7479,  1.1988,  1.8692,  1.7786,  0.3947,  0.1667,  0.1533,  0.3433,
          0.5894,  0.6970,  0.2870, 13.6594,  6.5015,  0.8436,  1.3607,  1.4714,
          1.7084,  1.0854,  1.6208,  0.4592,  1.7815,  1.8805],
        [ 1.3012,  1.3289,  1.3870,  1.3653,  1.3354,  1.3062,  1.2693,  1.2990,
          1.2990,  1.2698,  1.3808,  1.2842,  1.4019,  1.3515,  1.4420,  1.2697,
          1.3530,  1.2911,  1.3499,  1.3744,  1.3916,  1.3623,  1.3234,  1.3165,
          1.2481,  1.3115,  1.3115,  1.3576,  1.4022,  1.3291,  1.1313,  1.3110,
          1.2033,  1.3687,  1.2009,  1.3317,  1.4569,  1.1557,  1.4792,  1.4680,
          1.0398,  0.9565,  1.4687,  1.4146,  0.8429,  3.3762,  2.6437,  3.5737,
          2.9296,  2.2399,  1.9418,  3.0281,  3.3085,  1.9268]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 265 : 181.49428883451935
Test loss for epoch 265 : 181.58766453521818
Test Precision for epoch 265 : 0.26153846153846155
Test Recall for epoch 265 : 0.26153846153846155
Test F1 for epoch 265 : 0.26153846153846155


theta for epoch 266 : tensor([[ 2.6917,  2.7172,  2.7830,  2.9088,  2.8764,  2.6961,  2.8571,  2.6898,
          2.6898,  1.2771,  1.2939,  1.2915,  1.3145,  1.2645,  1.3550,  1.2770,
          1.2659,  1.2521,  1.2618,  1.2431,  1.2574,  1.2742,  1.2355,  1.2290,
          1.2521,  1.2237,  1.2237,  1.2704,  1.3147,  1.2415,  1.2663,  1.3166,
          1.2529,  1.2814,  1.2035,  1.2440,  1.3746,  1.4188,  1.3998,  1.3857,
          1.3916,  1.3366,  1.3864,  1.3334,  1.3137,  1.3389,  1.2920,  1.2794,
          1.2643,  1.3346,  1.2857,  1.3707,  1.2557,  1.2676],
        [ 1.2979,  1.2173,  1.0862,  1.2653,  1.3485,  1.3480,  1.2746,  1.3408,
          1.3408,  1.7925,  1.9719,  1.7679,  2.4249,  1.8259,  5.7678,  1.8746,
          1.7250,  5.5699,  1.1764,  1.2559,  1.1115,  1.2115,  1.3297,  1.3591,
          1.3302,  1.3538,  1.3538,  1.3370,  1.1431,  1.3720,  1.3597,  1.1822,
          1.3837,  1.4110,  1.3341,  1.3737,  1.4724,  1.5429,  1.4689,  1.4296,
          1.4735,  1.5136,  1.4552,  0.7423,  1.4316,  1.1422,  1.4211,  1.4069,
          1.3916,  1.1354,  1.4145,  1.0312,  1.3829,  1.3962],
        [ 1.2183,  1.2456,  1.3027,  1.2810,  1.2514,  1.2232,  1.2312,  1.2161,
          1.2161,  1.2830,  1.2998,  1.2974,  1.3204,  1.2704,  1.3077,  1.2829,
          1.2369,  1.2674,  2.7450,  2.8773,  2.9872,  2.8531,  2.6418,  2.7217,
          2.8278,  2.6315,  2.6315,  1.2880,  1.3021,  1.2477,  1.2722,  1.2883,
          1.2591,  1.2876,  1.2553,  1.2502,  1.3809,  1.4251,  1.4057,  1.3521,
          1.3976,  1.3952,  1.3926,  1.2953,  1.2802,  1.3260,  1.2982,  1.2856,
          1.2704,  1.3038,  1.2918,  1.3580,  1.2610,  1.2737],
        [ 1.2263,  1.2538,  1.3090,  1.2874,  1.2599,  1.2313,  1.2396,  1.2241,
          1.2241,  1.2911,  1.3058,  1.3056,  1.3277,  1.2784,  1.2749,  1.2910,
          1.2793,  1.2161,  1.2760,  1.3009,  1.3167,  1.2885,  1.2495,  1.2425,
          1.2650,  1.2377,  1.2377,  2.9910,  2.9383,  2.5797,  2.7397,  2.9885,
          2.5897,  2.9460,  2.5894,  2.5819,  1.3874,  1.4319,  1.4118,  1.3966,
          1.4045,  1.4021,  1.3988,  1.2879,  1.3247,  1.3533,  1.3055,  1.1997,
          1.2316,  1.3490,  1.2972,  1.3853,  1.2224,  1.2816],
        [ 1.8367,  1.4808,  0.6669,  0.9011,  1.2810,  1.7208,  1.6491,  1.8346,
          1.8346,  1.7232,  1.3676,  1.5323,  0.9921,  1.8149,  0.3052,  1.6881,
          1.8695,  1.1150,  1.3983,  0.9659,  0.8049,  1.1801,  1.6888,  1.7442,
          1.4801,  1.8457,  1.8457,  0.8079,  0.8961,  1.8175,  1.6058,  0.8884,
          1.7488,  1.2000,  1.8701,  1.7795,  0.3930,  0.1649,  0.1516,  0.3415,
          0.5878,  0.6946,  0.2851, 13.7034,  6.4757,  0.8427,  1.3621,  1.4727,
          1.7096,  1.0844,  1.6219,  0.4577,  1.7828,  1.8815],
        [ 1.2997,  1.3274,  1.3856,  1.3638,  1.3339,  1.3047,  1.2678,  1.2975,
          1.2975,  1.2689,  1.3801,  1.2833,  1.4013,  1.3507,  1.4414,  1.2689,
          1.3521,  1.2906,  1.3496,  1.3740,  1.3913,  1.3620,  1.3231,  1.3163,
          1.2476,  1.3112,  1.3112,  1.3569,  1.4016,  1.3285,  1.1305,  1.3104,
          1.2027,  1.3681,  1.2002,  1.3310,  1.4565,  1.1551,  1.4788,  1.4677,
          1.0389,  0.9557,  1.4684,  1.4137,  0.8420,  3.3808,  2.6460,  3.5790,
          2.9324,  2.2418,  1.9435,  3.0308,  3.3131,  1.9286]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 266 : 181.4875471846947
Test loss for epoch 266 : 181.58019894178986
Test Precision for epoch 266 : 0.26153846153846155
Test Recall for epoch 266 : 0.26153846153846155
Test F1 for epoch 266 : 0.26153846153846155


theta for epoch 267 : tensor([[ 2.6935,  2.7190,  2.7847,  2.9109,  2.8784,  2.6979,  2.8591,  2.6916,
          2.6916,  1.2772,  1.2941,  1.2916,  1.3148,  1.2646,  1.3553,  1.2771,
          1.2660,  1.2525,  1.2616,  1.2429,  1.2572,  1.2741,  1.2354,  1.2289,
          1.2520,  1.2236,  1.2236,  1.2704,  1.3147,  1.2415,  1.2664,  1.3166,
          1.2530,  1.2814,  1.2035,  1.2441,  1.3747,  1.4190,  1.4000,  1.3858,
          1.3916,  1.3368,  1.3865,  1.3329,  1.3138,  1.3379,  1.2910,  1.2784,
          1.2632,  1.3336,  1.2846,  1.3697,  1.2546,  1.2665],
        [ 1.2969,  1.2172,  1.0880,  1.2656,  1.3483,  1.3470,  1.2739,  1.3398,
          1.3398,  1.7963,  1.9740,  1.7711,  2.4235,  1.8291,  5.7698,  1.8776,
          1.7287,  5.5720,  1.1778,  1.2574,  1.1147,  1.2119,  1.3294,  1.3584,
          1.3296,  1.3530,  1.3530,  1.3373,  1.1451,  1.3713,  1.3595,  1.1833,
          1.3830,  1.4104,  1.3334,  1.3730,  1.4726,  1.5424,  1.4683,  1.4297,
          1.4745,  1.5131,  1.4546,  0.7473,  1.4310,  1.1446,  1.4194,  1.4052,
          1.3899,  1.1366,  1.4128,  1.0354,  1.3811,  1.3945],
        [ 1.2178,  1.2451,  1.3022,  1.2805,  1.2509,  1.2227,  1.2307,  1.2156,
          1.2156,  1.2829,  1.2999,  1.2974,  1.3206,  1.2704,  1.3081,  1.2829,
          1.2366,  1.2689,  2.7468,  2.8799,  2.9888,  2.8535,  2.6445,  2.7232,
          2.8306,  2.6342,  2.6342,  1.2876,  1.3025,  1.2475,  1.2721,  1.2879,
          1.2590,  1.2875,  1.2552,  1.2501,  1.3807,  1.4251,  1.4057,  1.3517,
          1.3974,  1.3952,  1.3925,  1.2959,  1.2798,  1.3254,  1.2969,  1.2843,
          1.2692,  1.3037,  1.2906,  1.3574,  1.2597,  1.2725],
        [ 1.2261,  1.2536,  1.3088,  1.2873,  1.2597,  1.2311,  1.2394,  1.2239,
          1.2239,  1.2912,  1.3061,  1.3057,  1.3281,  1.2785,  1.2753,  1.2912,
          1.2794,  1.2168,  1.2760,  1.3009,  1.3167,  1.2886,  1.2496,  1.2426,
          1.2650,  1.2377,  1.2377,  2.9923,  2.9410,  2.5816,  2.7419,  2.9898,
          2.5916,  2.9474,  2.5913,  2.5838,  1.3875,  1.4321,  1.4120,  1.3967,
          1.4046,  1.4023,  1.3990,  1.2876,  1.3248,  1.3525,  1.3048,  1.1990,
          1.2309,  1.3483,  1.2966,  1.3846,  1.2216,  1.2808],
        [ 1.8374,  1.4809,  0.6662,  0.9012,  1.2812,  1.7215,  1.6495,  1.8353,
          1.8353,  1.7241,  1.3673,  1.5330,  0.9908,  1.8152,  0.3031,  1.6883,
          1.8706,  1.1107,  1.3974,  0.9655,  0.8034,  1.1797,  1.6893,  1.7445,
          1.4809,  1.8464,  1.8464,  0.8087,  0.8955,  1.8184,  1.6066,  0.8887,
          1.7498,  1.2010,  1.8711,  1.7804,  0.3916,  0.1634,  0.1501,  0.3400,
          0.5864,  0.6924,  0.2835, 13.7479,  6.4496,  0.8406,  1.3623,  1.4729,
          1.7097,  1.0823,  1.6220,  0.4549,  1.7831,  1.8816],
        [ 1.2998,  1.3275,  1.3857,  1.3639,  1.3340,  1.3048,  1.2679,  1.2976,
          1.2976,  1.2696,  1.3808,  1.2840,  1.4022,  1.3514,  1.4422,  1.2696,
          1.3527,  1.2917,  1.3502,  1.3744,  1.3918,  1.3626,  1.3236,  1.3169,
          1.2480,  1.3117,  1.3117,  1.3575,  1.4022,  1.3290,  1.1309,  1.3110,
          1.2033,  1.3686,  1.2008,  1.3316,  1.4568,  1.1555,  1.4792,  1.4681,
          1.0391,  0.9560,  1.4688,  1.4135,  0.8422,  3.3829,  2.6459,  3.5819,
          2.9327,  2.2413,  1.9429,  3.0312,  3.3152,  1.9279]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 267 : 181.48102852987967
Test loss for epoch 267 : 181.5745854283565
Test Precision for epoch 267 : 0.26153846153846155
Test Recall for epoch 267 : 0.26153846153846155
Test F1 for epoch 267 : 0.26153846153846155


theta for epoch 268 : tensor([[ 2.6958,  2.7213,  2.7871,  2.9136,  2.8811,  2.7002,  2.8618,  2.6939,
          2.6939,  1.2766,  1.2936,  1.2910,  1.3145,  1.2640,  1.3550,  1.2766,
          1.2653,  1.2523,  1.2604,  1.2416,  1.2560,  1.2729,  1.2341,  1.2276,
          1.2506,  1.2223,  1.2223,  1.2697,  1.3140,  1.2409,  1.2657,  1.3160,
          1.2523,  1.2808,  1.2028,  1.2434,  1.3746,  1.4191,  1.4000,  1.3858,
          1.3915,  1.3368,  1.3865,  1.3323,  1.3138,  1.3379,  1.2910,  1.2784,
          1.2632,  1.3336,  1.2846,  1.3697,  1.2546,  1.2665],
        [ 1.2965,  1.2178,  1.0907,  1.2666,  1.3488,  1.3467,  1.2740,  1.3394,
          1.3394,  1.7999,  1.9758,  1.7741,  2.4218,  1.8323,  5.7711,  1.8805,
          1.7323,  5.5733,  1.1784,  1.2581,  1.1173,  1.2115,  1.3282,  1.3567,
          1.3280,  1.3513,  1.3513,  1.3374,  1.1469,  1.3703,  1.3590,  1.1841,
          1.3820,  1.4094,  1.3324,  1.3721,  1.4728,  1.5419,  1.4679,  1.4298,
          1.4756,  1.5127,  1.4541,  0.7526,  1.4304,  1.1484,  1.4191,  1.4049,
          1.3896,  1.1394,  1.4125,  1.0411,  1.3808,  1.3942],
        [ 1.2187,  1.2460,  1.3031,  1.2814,  1.2518,  1.2236,  1.2316,  1.2165,
          1.2165,  1.2833,  1.3004,  1.2978,  1.3212,  1.2708,  1.3089,  1.2833,
          1.2367,  1.2708,  2.7469,  2.8808,  2.9887,  2.8523,  2.6455,  2.7230,
          2.8318,  2.6352,  2.6352,  1.2875,  1.3031,  1.2477,  1.2722,  1.2878,
          1.2591,  1.2876,  1.2553,  1.2502,  1.3812,  1.4256,  1.4062,  1.3519,
          1.3978,  1.3957,  1.3930,  1.2970,  1.2799,  1.3272,  1.2981,  1.2855,
          1.2704,  1.3061,  1.2918,  1.3592,  1.2609,  1.2737],
        [ 1.2265,  1.2541,  1.3093,  1.2878,  1.2601,  1.2315,  1.2399,  1.2244,
          1.2244,  1.2910,  1.3062,  1.3056,  1.3283,  1.2784,  1.2754,  1.2911,
          1.2792,  1.2172,  1.2752,  1.3001,  1.3159,  1.2878,  1.2487,  1.2418,
          1.2642,  1.2369,  1.2369,  2.9934,  2.9433,  2.5832,  2.7438,  2.9909,
          2.5932,  2.9484,  2.5929,  2.5854,  1.3877,  1.4324,  1.4123,  1.3970,
          1.4047,  1.4026,  1.3993,  1.2873,  1.3250,  1.3529,  1.3053,  1.1994,
          1.2313,  1.3487,  1.2971,  1.3850,  1.2220,  1.2812],
        [ 1.8384,  1.4811,  0.6656,  0.9015,  1.2818,  1.7225,  1.6502,  1.8363,
          1.8363,  1.7246,  1.3665,  1.5332,  0.9890,  1.8151,  0.3003,  1.6881,
          1.8713,  1.1058,  1.3954,  0.9642,  0.8007,  1.1785,  1.6888,  1.7439,
          1.4808,  1.8464,  1.8464,  0.8088,  0.8941,  1.8189,  1.6068,  0.8882,
          1.7503,  1.2015,  1.8715,  1.7808,  0.3903,  0.1620,  0.1487,  0.3387,
          0.5853,  0.6905,  0.2821, 13.7929,  6.4234,  0.8392,  1.3634,  1.4740,
          1.7107,  1.0808,  1.6230,  0.4525,  1.7843,  1.8827],
        [ 1.3000,  1.3277,  1.3859,  1.3642,  1.3343,  1.3050,  1.2681,  1.2979,
          1.2979,  1.2692,  1.3806,  1.2836,  1.4021,  1.3510,  1.4421,  1.2692,
          1.3523,  1.2917,  1.3489,  1.3730,  1.3906,  1.3614,  1.3223,  1.3156,
          1.2465,  1.3104,  1.3104,  1.3571,  1.4017,  1.3286,  1.1303,  1.3106,
          1.2029,  1.3682,  1.2004,  1.3312,  1.4569,  1.1555,  1.4792,  1.4682,
          1.0388,  0.9559,  1.4690,  1.4129,  0.8420,  3.3865,  2.6473,  3.5862,
          2.9346,  2.2423,  1.9437,  3.0331,  3.3188,  1.9288]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 268 : 181.4745351753872
Test loss for epoch 268 : 181.568261215975
Test Precision for epoch 268 : 0.26153846153846155
Test Recall for epoch 268 : 0.26153846153846155
Test F1 for epoch 268 : 0.26153846153846155


theta for epoch 269 : tensor([[ 2.6959,  2.7215,  2.7872,  2.9140,  2.8815,  2.7003,  2.8622,  2.6940,
          2.6940,  1.2769,  1.2941,  1.2914,  1.3151,  1.2644,  1.3555,  1.2770,
          1.2657,  1.2531,  1.2621,  1.2434,  1.2577,  1.2747,  1.2358,  1.2294,
          1.2524,  1.2240,  1.2240,  1.2702,  1.3145,  1.2414,  1.2662,  1.3164,
          1.2528,  1.2813,  1.2034,  1.2439,  1.3752,  1.4197,  1.4007,  1.3864,
          1.3920,  1.3375,  1.3872,  1.3322,  1.3144,  1.3383,  1.2915,  1.2788,
          1.2637,  1.3341,  1.2851,  1.3702,  1.2551,  1.2670],
        [ 1.2949,  1.2173,  1.0923,  1.2664,  1.3480,  1.3450,  1.2727,  1.3378,
          1.3378,  1.8038,  1.9778,  1.7774,  2.4201,  1.8355,  5.7720,  1.8835,
          1.7361,  5.5742,  1.1811,  1.2609,  1.1219,  1.2131,  1.3290,  1.3571,
          1.3285,  1.3516,  1.3516,  1.3375,  1.1488,  1.3693,  1.3585,  1.1850,
          1.3810,  1.4084,  1.3314,  1.3711,  1.4728,  1.5413,  1.4672,  1.4298,
          1.4765,  1.5121,  1.4534,  0.7581,  1.4296,  1.1517,  1.4181,  1.4038,
          1.3886,  1.1416,  1.4115,  1.0464,  1.3798,  1.3932],
        [ 1.2172,  1.2446,  1.3016,  1.2799,  1.2503,  1.2222,  1.2302,  1.2151,
          1.2151,  1.2821,  1.2994,  1.2967,  1.3203,  1.2697,  1.3084,  1.2823,
          1.2353,  1.2713,  2.7496,  2.8844,  2.9912,  2.8537,  2.6492,  2.7255,
          2.8356,  2.6389,  2.6389,  1.2864,  1.3029,  1.2469,  1.2714,  1.2867,
          1.2583,  1.2868,  1.2546,  1.2494,  1.3807,  1.4252,  1.4058,  1.3511,
          1.3972,  1.3953,  1.3926,  1.2972,  1.2791,  1.3269,  1.2972,  1.2845,
          1.2694,  1.3063,  1.2908,  1.3589,  1.2598,  1.2727],
        [ 1.2258,  1.2533,  1.3087,  1.2872,  1.2593,  1.2308,  1.2391,  1.2236,
          1.2236,  1.2906,  1.3060,  1.3052,  1.3282,  1.2781,  1.2753,  1.2907,
          1.2788,  1.2174,  1.2762,  1.3011,  1.3169,  1.2888,  1.2497,  1.2429,
          1.2652,  1.2379,  1.2379,  2.9947,  2.9458,  2.5851,  2.7459,  2.9922,
          2.5950,  2.9497,  2.5947,  2.5872,  1.3876,  1.4325,  1.4124,  1.3970,
          1.4047,  1.4026,  1.3993,  1.2869,  1.3250,  1.3527,  1.3050,  1.1992,
          1.2311,  1.3485,  1.2970,  1.3847,  1.2217,  1.2810],
        [ 1.8385,  1.4804,  0.6642,  0.9010,  1.2813,  1.7226,  1.6499,  1.8364,
          1.8364,  1.7250,  1.3656,  1.5333,  0.9870,  1.8149,  0.2973,  1.6878,
          1.8720,  1.1006,  1.3949,  0.9643,  0.7995,  1.1787,  1.6900,  1.7450,
          1.4822,  1.8479,  1.8479,  0.8090,  0.8929,  1.8195,  1.6071,  0.8878,
          1.7509,  1.2020,  1.8721,  1.7814,  0.3889,  0.1606,  0.1472,  0.3372,
          0.5839,  0.6884,  0.2805, 13.8381,  6.3965,  0.8372,  1.3640,  1.4747,
          1.7113,  1.0788,  1.6235,  0.4496,  1.7851,  1.8832],
        [ 1.2994,  1.3271,  1.3854,  1.3636,  1.3337,  1.3044,  1.2676,  1.2973,
          1.2973,  1.2690,  1.3805,  1.2835,  1.4022,  1.3509,  1.4422,  1.2691,
          1.3521,  1.2920,  1.3506,  1.3746,  1.3923,  1.3631,  1.3239,  1.3173,
          1.2480,  1.3120,  1.3120,  1.3571,  1.4017,  1.3286,  1.1302,  1.3106,
          1.2029,  1.3682,  1.2004,  1.3312,  1.4570,  1.1556,  1.4793,  1.4683,
          1.0387,  0.9560,  1.4692,  1.4124,  0.8419,  3.3892,  2.6477,  3.5896,
          2.9355,  2.2424,  1.9437,  3.0340,  3.3215,  1.9287]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 269 : 181.46773892135482
Test loss for epoch 269 : 181.56195486802585
Test Precision for epoch 269 : 0.26153846153846155
Test Recall for epoch 269 : 0.26153846153846155
Test F1 for epoch 269 : 0.26153846153846155


theta for epoch 270 : tensor([[ 2.6986,  2.7241,  2.7899,  2.9169,  2.8845,  2.7030,  2.8652,  2.6967,
          2.6967,  1.2765,  1.2938,  1.2910,  1.3150,  1.2641,  1.3554,  1.2767,
          1.2653,  1.2532,  1.2607,  1.2420,  1.2563,  1.2733,  1.2344,  1.2280,
          1.2510,  1.2226,  1.2226,  1.2697,  1.3140,  1.2409,  1.2658,  1.3160,
          1.2524,  1.2808,  1.2029,  1.2435,  1.3749,  1.4195,  1.4004,  1.3861,
          1.3917,  1.3373,  1.3869,  1.3313,  1.3141,  1.3375,  1.2906,  1.2780,
          1.2629,  1.3333,  1.2843,  1.3694,  1.2542,  1.2662],
        [ 1.2947,  1.2181,  1.0954,  1.2677,  1.3487,  1.3448,  1.2729,  1.3376,
          1.3376,  1.8081,  1.9802,  1.7812,  2.4187,  1.8393,  5.7728,  1.8870,
          1.7404,  5.5750,  1.1816,  1.2615,  1.1245,  1.2124,  1.3275,  1.3551,
          1.3266,  1.3496,  1.3496,  1.3376,  1.1507,  1.3684,  1.3581,  1.1860,
          1.3800,  1.4075,  1.3304,  1.3702,  1.4727,  1.5405,  1.4663,  1.4296,
          1.4772,  1.5113,  1.4526,  0.7636,  1.4287,  1.1547,  1.4167,  1.4024,
          1.3872,  1.1435,  1.4101,  1.0517,  1.3784,  1.3918],
        [ 1.2184,  1.2458,  1.3028,  1.2811,  1.2516,  1.2234,  1.2314,  1.2163,
          1.2163,  1.2827,  1.3001,  1.2973,  1.3212,  1.2703,  1.3095,  1.2829,
          1.2356,  1.2735,  2.7498,  2.8854,  2.9911,  2.8525,  2.6504,  2.7253,
          2.8368,  2.6400,  2.6400,  1.2865,  1.3037,  1.2472,  1.2717,  1.2868,
          1.2587,  1.2872,  1.2549,  1.2498,  1.3809,  1.4256,  1.4061,  1.3510,
          1.3974,  1.3956,  1.3929,  1.2981,  1.2790,  1.3277,  1.2973,  1.2847,
          1.2696,  1.3077,  1.2910,  1.3597,  1.2600,  1.2729],
        [ 1.2264,  1.2540,  1.3093,  1.2879,  1.2600,  1.2314,  1.2398,  1.2243,
          1.2243,  1.2906,  1.3062,  1.3052,  1.3285,  1.2781,  1.2756,  1.2908,
          1.2787,  1.2179,  1.2753,  1.3001,  1.3160,  1.2879,  1.2487,  1.2419,
          1.2641,  1.2369,  1.2369,  2.9961,  2.9484,  2.5869,  2.7481,  2.9935,
          2.5969,  2.9510,  2.5965,  2.5891,  1.3876,  1.4325,  1.4124,  1.3969,
          1.4046,  1.4027,  1.3994,  1.2863,  1.3249,  1.3523,  1.3047,  1.1989,
          1.2307,  1.3481,  1.2967,  1.3844,  1.2213,  1.2807],
        [ 1.8402,  1.4813,  0.6642,  0.9019,  1.2826,  1.7243,  1.6513,  1.8381,
          1.8381,  1.7259,  1.3652,  1.5340,  0.9856,  1.8152,  0.2949,  1.6880,
          1.8731,  1.0959,  1.3930,  0.9633,  0.7972,  1.1777,  1.6897,  1.7447,
          1.4824,  1.8481,  1.8481,  0.8098,  0.8922,  1.8204,  1.6078,  0.8879,
          1.7518,  1.2031,  1.8730,  1.7823,  0.3872,  0.1588,  0.1454,  0.3354,
          0.5822,  0.6859,  0.2786, 13.8833,  6.3688,  0.8355,  1.3649,  1.4755,
          1.7120,  1.0770,  1.6242,  0.4471,  1.7860,  1.8839],
        [ 1.3002,  1.3279,  1.3861,  1.3644,  1.3345,  1.3052,  1.2683,  1.2980,
          1.2980,  1.2690,  1.3808,  1.2836,  1.4026,  1.3510,  1.4426,  1.2693,
          1.3522,  1.2925,  1.3494,  1.3733,  1.3911,  1.3619,  1.3227,  1.3161,
          1.2466,  1.3108,  1.3108,  1.3571,  1.4017,  1.3286,  1.1300,  1.3106,
          1.2029,  1.3682,  1.2003,  1.3312,  1.4569,  1.1554,  1.4792,  1.4683,
          1.0383,  0.9557,  1.4692,  1.4117,  0.8416,  3.3923,  2.6486,  3.5934,
          2.9367,  2.2428,  1.9440,  3.0353,  3.3246,  1.9291]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 270 : 181.46055147911443
Test loss for epoch 270 : 181.555241302418
Test Precision for epoch 270 : 0.26153846153846155
Test Recall for epoch 270 : 0.26153846153846155
Test F1 for epoch 270 : 0.26153846153846155


theta for epoch 271 : tensor([[ 2.6996,  2.7251,  2.7909,  2.9182,  2.8858,  2.7040,  2.8665,  2.6977,
          2.6977,  1.2766,  1.2941,  1.2911,  1.3154,  1.2642,  1.3558,  1.2769,
          1.2653,  1.2537,  1.2611,  1.2423,  1.2567,  1.2737,  1.2347,  1.2284,
          1.2513,  1.2230,  1.2230,  1.2698,  1.3141,  1.2411,  1.2659,  1.3161,
          1.2525,  1.2809,  1.2030,  1.2436,  1.3754,  1.4201,  1.4010,  1.3866,
          1.3921,  1.3379,  1.3875,  1.3311,  1.3146,  1.3374,  1.2906,  1.2779,
          1.2628,  1.3332,  1.2842,  1.3693,  1.2542,  1.2661],
        [ 1.2934,  1.2180,  1.0976,  1.2679,  1.3484,  1.3435,  1.2721,  1.3363,
          1.3363,  1.8123,  1.9822,  1.7847,  2.4169,  1.8429,  5.7726,  1.8903,
          1.7444,  5.5748,  1.1838,  1.2637,  1.1286,  1.2132,  1.3275,  1.3545,
          1.3262,  1.3490,  1.3490,  1.3380,  1.1528,  1.3675,  1.3578,  1.1874,
          1.3792,  1.4066,  1.3295,  1.3694,  1.4730,  1.5401,  1.4659,  1.4299,
          1.4783,  1.5109,  1.4521,  0.7699,  1.4282,  1.1583,  1.4157,  1.4014,
          1.3861,  1.1460,  1.4091,  1.0575,  1.3773,  1.3908],
        [ 1.2176,  1.2450,  1.3019,  1.2803,  1.2507,  1.2225,  1.2306,  1.2155,
          1.2155,  1.2823,  1.2998,  1.2968,  1.3211,  1.2699,  1.3096,  1.2825,
          1.2349,  1.2747,  2.7515,  2.8879,  2.9926,  2.8529,  2.6531,  2.7268,
          2.8397,  2.6428,  2.6428,  1.2859,  1.3039,  1.2469,  1.2713,  1.2862,
          1.2583,  1.2868,  1.2545,  1.2494,  1.3809,  1.4257,  1.4062,  1.3508,
          1.3974,  1.3957,  1.3931,  1.2988,  1.2787,  1.3277,  1.2967,  1.2840,
          1.2690,  1.3082,  1.2904,  1.3597,  1.2593,  1.2723],
        [ 1.2261,  1.2536,  1.3091,  1.2876,  1.2597,  1.2311,  1.2394,  1.2240,
          1.2240,  1.2906,  1.3064,  1.3052,  1.3288,  1.2781,  1.2759,  1.2908,
          1.2787,  1.2185,  1.2756,  1.3004,  1.3163,  1.2883,  1.2490,  1.2423,
          1.2644,  1.2372,  1.2372,  2.9971,  2.9506,  2.5884,  2.7499,  2.9946,
          2.5984,  2.9521,  2.5980,  2.5906,  1.3880,  1.4330,  1.4129,  1.3974,
          1.4049,  1.4032,  1.3998,  1.2862,  1.3253,  1.3522,  1.3046,  1.1988,
          1.2306,  1.3480,  1.2967,  1.3842,  1.2212,  1.2805],
        [ 1.8406,  1.4808,  0.6630,  0.9017,  1.2825,  1.7248,  1.6513,  1.8385,
          1.8385,  1.7266,  1.3645,  1.5344,  0.9837,  1.8152,  0.2920,  1.6879,
          1.8740,  1.0907,  1.3918,  0.9628,  0.7954,  1.1774,  1.6903,  1.7452,
          1.4833,  1.8490,  1.8490,  0.8103,  0.8913,  1.8212,  1.6083,  0.8876,
          1.7527,  1.2040,  1.8738,  1.7831,  0.3856,  0.1572,  0.1438,  0.3338,
          0.5807,  0.6836,  0.2769, 13.9290,  6.3409,  0.8336,  1.3656,  1.4762,
          1.7127,  1.0750,  1.6248,  0.4442,  1.7868,  1.8845],
        [ 1.2995,  1.3272,  1.3854,  1.3637,  1.3338,  1.3045,  1.2676,  1.2973,
          1.2973,  1.2687,  1.3806,  1.2832,  1.4025,  1.3507,  1.4425,  1.2690,
          1.3518,  1.2926,  1.3494,  1.3731,  1.3911,  1.3619,  1.3227,  1.3161,
          1.2463,  1.3107,  1.3107,  1.3568,  1.4014,  1.3283,  1.1295,  1.3103,
          1.2026,  1.3679,  1.2001,  1.3309,  1.4570,  1.1555,  1.4793,  1.4685,
          1.0380,  0.9556,  1.4694,  1.4111,  0.8414,  3.3957,  2.6498,  3.5975,
          2.9384,  2.2436,  1.9447,  3.0370,  3.3280,  1.9297]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 271 : 181.45326450805717
Test loss for epoch 271 : 181.54816490292694
Test Precision for epoch 271 : 0.26153846153846155
Test Recall for epoch 271 : 0.26153846153846155
Test F1 for epoch 271 : 0.26153846153846155


theta for epoch 272 : tensor([[ 2.7009,  2.7264,  2.7922,  2.9199,  2.8874,  2.7053,  2.8681,  2.6990,
          2.6990,  1.2764,  1.2941,  1.2910,  1.3156,  1.2642,  1.3560,  1.2768,
          1.2652,  1.2541,  1.2613,  1.2425,  1.2569,  1.2739,  1.2349,  1.2286,
          1.2515,  1.2231,  1.2231,  1.2698,  1.3141,  1.2411,  1.2659,  1.3161,
          1.2525,  1.2809,  1.2030,  1.2436,  1.3758,  1.4207,  1.4016,  1.3871,
          1.3926,  1.3385,  1.3880,  1.3308,  1.3151,  1.3371,  1.2902,  1.2775,
          1.2625,  1.3329,  1.2839,  1.3690,  1.2538,  1.2658],
        [ 1.2921,  1.2180,  1.1001,  1.2683,  1.3481,  1.3422,  1.2713,  1.3350,
          1.3350,  1.8166,  1.9844,  1.7883,  2.4150,  1.8466,  5.7720,  1.8937,
          1.7487,  5.5741,  1.1860,  1.2659,  1.1328,  1.2140,  1.3275,  1.3539,
          1.3257,  1.3482,  1.3482,  1.3383,  1.1549,  1.3666,  1.3576,  1.1888,
          1.3783,  1.4058,  1.3286,  1.3685,  1.4733,  1.5397,  1.4655,  1.4301,
          1.4794,  1.5106,  1.4517,  0.7764,  1.4277,  1.1619,  1.4144,  1.4001,
          1.3849,  1.1484,  1.4078,  1.0635,  1.3760,  1.3895],
        [ 1.2169,  1.2443,  1.3012,  1.2796,  1.2501,  1.2218,  1.2299,  1.2148,
          1.2148,  1.2818,  1.2995,  1.2965,  1.3210,  1.2695,  1.3098,  1.2822,
          1.2342,  1.2760,  2.7531,  2.8904,  2.9939,  2.8531,  2.6558,  2.7281,
          2.8424,  2.6455,  2.6455,  1.2853,  1.3041,  1.2466,  1.2710,  1.2856,
          1.2580,  1.2865,  1.2542,  1.2491,  1.3811,  1.4259,  1.4064,  1.3506,
          1.3975,  1.3959,  1.3933,  1.2995,  1.2785,  1.3276,  1.2959,  1.2833,
          1.2682,  1.3087,  1.2897,  1.3597,  1.2585,  1.2716],
        [ 1.2258,  1.2533,  1.3088,  1.2874,  1.2593,  1.2308,  1.2391,  1.2237,
          1.2237,  1.2905,  1.3065,  1.3052,  1.3290,  1.2781,  1.2761,  1.2908,
          1.2786,  1.2191,  1.2759,  1.3006,  1.3166,  1.2885,  1.2493,  1.2426,
          1.2646,  1.2374,  1.2374,  2.9982,  2.9529,  2.5900,  2.7518,  2.9958,
          2.6000,  2.9532,  2.5996,  2.5922,  1.3884,  1.4335,  1.4135,  1.3978,
          1.4053,  1.4037,  1.4003,  1.2861,  1.3257,  1.3519,  1.3043,  1.1986,
          1.2303,  1.3477,  1.2965,  1.3839,  1.2209,  1.2803],
        [ 1.8410,  1.4803,  0.6616,  0.9014,  1.2824,  1.7252,  1.6513,  1.8390,
          1.8390,  1.7272,  1.3636,  1.5348,  0.9816,  1.8151,  0.2889,  1.6878,
          1.8749,  1.0851,  1.3904,  0.9621,  0.7933,  1.1769,  1.6906,  1.7456,
          1.4841,  1.8499,  1.8499,  0.8106,  0.8901,  1.8220,  1.6088,  0.8872,
          1.7535,  1.2048,  1.8746,  1.7838,  0.3842,  0.1557,  0.1423,  0.3323,
          0.5793,  0.6814,  0.2753, 13.9752,  6.3126,  0.8314,  1.3661,  1.4768,
          1.7132,  1.0727,  1.6253,  0.4409,  1.7875,  1.8850],
        [ 1.2992,  1.3270,  1.3851,  1.3634,  1.3335,  1.3042,  1.2674,  1.2971,
          1.2971,  1.2686,  1.3807,  1.2832,  1.4028,  1.3507,  1.4428,  1.2691,
          1.3518,  1.2931,  1.3498,  1.3733,  1.3915,  1.3623,  1.3230,  1.3165,
          1.2465,  1.3111,  1.3111,  1.3569,  1.4015,  1.3284,  1.1295,  1.3105,
          1.2027,  1.3680,  1.2002,  1.3310,  1.4575,  1.1559,  1.4797,  1.4690,
          1.0382,  0.9560,  1.4699,  1.4109,  0.8416,  3.3984,  2.6502,  3.6008,
          2.9392,  2.2437,  1.9447,  3.0379,  3.3307,  1.9297]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 272 : 181.44609010157572
Test loss for epoch 272 : 181.5417217780681
Test Precision for epoch 272 : 0.26153846153846155
Test Recall for epoch 272 : 0.26153846153846155
Test F1 for epoch 272 : 0.26153846153846155


theta for epoch 273 : tensor([[ 2.7032,  2.7287,  2.7945,  2.9225,  2.8900,  2.7076,  2.8707,  2.7013,
          2.7013,  1.2760,  1.2938,  1.2907,  1.3155,  1.2638,  1.3559,  1.2765,
          1.2648,  1.2542,  1.2601,  1.2412,  1.2557,  1.2727,  1.2336,  1.2274,
          1.2503,  1.2219,  1.2219,  1.2693,  1.3136,  1.2406,  1.2654,  1.3156,
          1.2520,  1.2804,  1.2025,  1.2431,  1.3756,  1.4205,  1.4014,  1.3869,
          1.3923,  1.3383,  1.3879,  1.3299,  1.3149,  1.3368,  1.2900,  1.2773,
          1.2622,  1.3327,  1.2836,  1.3687,  1.2535,  1.2655],
        [ 1.2914,  1.2187,  1.1032,  1.2693,  1.3484,  1.3415,  1.2711,  1.3342,
          1.3342,  1.8215,  1.9871,  1.7926,  2.4135,  1.8508,  5.7712,  1.8976,
          1.7535,  5.5733,  1.1870,  1.2670,  1.1359,  1.2135,  1.3261,  1.3519,
          1.3239,  1.3462,  1.3462,  1.3385,  1.1568,  1.3654,  1.3571,  1.1901,
          1.3771,  1.4046,  1.3274,  1.3674,  1.4731,  1.5388,  1.4645,  1.4299,
          1.4800,  1.5097,  1.4507,  0.7828,  1.4267,  1.1658,  1.4134,  1.3991,
          1.3839,  1.1512,  1.4069,  1.0699,  1.3750,  1.3885],
        [ 1.2177,  1.2451,  1.3020,  1.2804,  1.2508,  1.2226,  1.2307,  1.2156,
          1.2156,  1.2823,  1.3001,  1.2969,  1.3218,  1.2701,  1.3108,  1.2827,
          1.2344,  1.2781,  2.7533,  2.8914,  2.9938,  2.8518,  2.6570,  2.7280,
          2.8437,  2.6467,  2.6467,  1.2853,  1.3049,  1.2468,  1.2712,  1.2856,
          1.2582,  1.2867,  1.2545,  1.2493,  1.3813,  1.4263,  1.4067,  1.3506,
          1.3976,  1.3962,  1.3936,  1.3004,  1.2784,  1.3289,  1.2966,  1.2839,
          1.2689,  1.3106,  1.2903,  1.3610,  1.2591,  1.2722],
        [ 1.2261,  1.2536,  1.3091,  1.2878,  1.2596,  1.2311,  1.2394,  1.2240,
          1.2240,  1.2904,  1.3067,  1.3051,  1.3292,  1.2781,  1.2764,  1.2908,
          1.2785,  1.2196,  1.2750,  1.2997,  1.3157,  1.2877,  1.2483,  1.2417,
          1.2637,  1.2365,  1.2365,  2.9996,  2.9553,  2.5917,  2.7538,  2.9971,
          2.6017,  2.9545,  2.6014,  2.5939,  1.3883,  1.4336,  1.4135,  1.3978,
          1.4052,  1.4038,  1.4004,  1.2854,  1.3256,  1.3519,  1.3044,  1.1986,
          1.2304,  1.3478,  1.2966,  1.3840,  1.2208,  1.2803],
        [ 1.8423,  1.4807,  0.6612,  0.9021,  1.2833,  1.7266,  1.6523,  1.8404,
          1.8404,  1.7282,  1.3630,  1.5355,  0.9799,  1.8153,  0.2860,  1.6879,
          1.8760,  1.0798,  1.3883,  0.9609,  0.7908,  1.1759,  1.6904,  1.7454,
          1.4844,  1.8502,  1.8502,  0.8112,  0.8893,  1.8230,  1.6093,  0.8870,
          1.7544,  1.2058,  1.8755,  1.7847,  0.3823,  0.1538,  0.1404,  0.3304,
          0.5774,  0.6788,  0.2733, 14.0213,  6.2833,  0.8299,  1.3674,  1.4780,
          1.7144,  1.0711,  1.6264,  0.4384,  1.7889,  1.8861],
        [ 1.2996,  1.3274,  1.3855,  1.3638,  1.3339,  1.3046,  1.2678,  1.2974,
          1.2974,  1.2686,  1.3808,  1.2832,  1.4031,  1.3507,  1.4431,  1.2691,
          1.3517,  1.2936,  1.3487,  1.3721,  1.3904,  1.3613,  1.3218,  1.3155,
          1.2452,  1.3099,  1.3099,  1.3567,  1.4014,  1.3283,  1.1291,  1.3103,
          1.2025,  1.3679,  1.2000,  1.3308,  1.4574,  1.1558,  1.4796,  1.4689,
          1.0378,  0.9557,  1.4699,  1.4100,  0.8412,  3.4016,  2.6512,  3.6048,
          2.9407,  2.2444,  1.9452,  3.0394,  3.3339,  1.9303]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 273 : 181.4387735139998
Test loss for epoch 273 : 181.53481735690204
Test Precision for epoch 273 : 0.26153846153846155
Test Recall for epoch 273 : 0.26153846153846155
Test F1 for epoch 273 : 0.26153846153846155


theta for epoch 274 : tensor([[ 2.7036,  2.7291,  2.7949,  2.9232,  2.8907,  2.7080,  2.8714,  2.7017,
          2.7017,  1.2763,  1.2943,  1.2910,  1.3161,  1.2642,  1.3564,  1.2768,
          1.2651,  1.2550,  1.2616,  1.2427,  1.2571,  1.2742,  1.2351,  1.2289,
          1.2517,  1.2233,  1.2233,  1.2696,  1.3139,  1.2410,  1.2657,  1.3159,
          1.2524,  1.2808,  1.2029,  1.2435,  1.3760,  1.4211,  1.4020,  1.3874,
          1.3927,  1.3389,  1.3884,  1.3296,  1.3154,  1.3370,  1.2902,  1.2775,
          1.2625,  1.3329,  1.2839,  1.3689,  1.2537,  1.2658],
        [ 1.2898,  1.2184,  1.1056,  1.2694,  1.3477,  1.3398,  1.2700,  1.3325,
          1.3325,  1.8265,  1.9896,  1.7969,  2.4118,  1.8550,  5.7697,  1.9016,
          1.7584,  5.5717,  1.1901,  1.2700,  1.1410,  1.2149,  1.3267,  1.3518,
          1.3239,  1.3460,  1.3460,  1.3387,  1.1588,  1.3642,  1.3566,  1.1915,
          1.3759,  1.4034,  1.3262,  1.3662,  1.4729,  1.5380,  1.4637,  1.4297,
          1.4807,  1.5089,  1.4498,  0.7896,  1.4257,  1.1695,  1.4120,  1.3977,
          1.3825,  1.1536,  1.4054,  1.0763,  1.3735,  1.3871],
        [ 1.2165,  1.2439,  1.3008,  1.2792,  1.2496,  1.2214,  1.2295,  1.2143,
          1.2143,  1.2813,  1.2993,  1.2960,  1.3211,  1.2691,  1.3105,  1.2818,
          1.2331,  1.2789,  2.7558,  2.8947,  2.9959,  2.8528,  2.6606,  2.7302,
          2.8473,  2.6503,  2.6503,  1.2843,  1.3047,  1.2461,  1.2705,  1.2846,
          1.2575,  1.2860,  1.2537,  1.2486,  1.3809,  1.4260,  1.4064,  1.3499,
          1.3971,  1.3959,  1.3932,  1.3005,  1.2776,  1.3284,  1.2954,  1.2827,
          1.2677,  1.3106,  1.2892,  1.3605,  1.2579,  1.2711],
        [ 1.2256,  1.2531,  1.3086,  1.2873,  1.2591,  1.2305,  1.2389,  1.2234,
          1.2234,  1.2901,  1.3067,  1.3049,  1.3293,  1.2779,  1.2764,  1.2906,
          1.2782,  1.2200,  1.2759,  1.3005,  1.3166,  1.2886,  1.2492,  1.2427,
          1.2645,  1.2374,  1.2374,  3.0008,  2.9576,  2.5934,  2.7557,  2.9983,
          2.6033,  2.9557,  2.6030,  2.5956,  1.3884,  1.4337,  1.4137,  1.3979,
          1.4052,  1.4039,  1.4005,  1.2849,  1.3256,  1.3516,  1.3041,  1.1983,
          1.2300,  1.3474,  1.2964,  1.3836,  1.2204,  1.2800],
        [ 1.8427,  1.4800,  0.6597,  0.9018,  1.2832,  1.7271,  1.6522,  1.8408,
          1.8408,  1.7288,  1.3620,  1.5359,  0.9777,  1.8152,  0.2826,  1.6877,
          1.8769,  1.0740,  1.3873,  0.9608,  0.7892,  1.1761,  1.6915,  1.7466,
          1.4859,  1.8518,  1.8518,  0.8116,  0.8882,  1.8237,  1.6097,  0.8864,
          1.7552,  1.2066,  1.8763,  1.7855,  0.3805,  0.1520,  0.1386,  0.3286,
          0.5757,  0.6763,  0.2714, 14.0680,  6.2537,  0.8277,  1.3681,  1.4787,
          1.7150,  1.0688,  1.6270,  0.4351,  1.7897,  1.8867],
        [ 1.2993,  1.3270,  1.3852,  1.3634,  1.3336,  1.3043,  1.2674,  1.2971,
          1.2971,  1.2685,  1.3809,  1.2832,  1.4034,  1.3507,  1.4433,  1.2691,
          1.3515,  1.2941,  1.3501,  1.3734,  1.3919,  1.3627,  1.3232,  1.3169,
          1.2464,  1.3113,  1.3113,  1.3567,  1.4014,  1.3283,  1.1290,  1.3103,
          1.2026,  1.3679,  1.2000,  1.3309,  1.4575,  1.1559,  1.4797,  1.4691,
          1.0377,  0.9557,  1.4702,  1.4094,  0.8411,  3.4041,  2.6515,  3.6079,
          2.9414,  2.2444,  1.9451,  3.0402,  3.3365,  1.9301]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 274 : 181.43111974471233
Test loss for epoch 274 : 181.52792966041648
Test Precision for epoch 274 : 0.26153846153846155
Test Recall for epoch 274 : 0.26153846153846155
Test F1 for epoch 274 : 0.26153846153846155


theta for epoch 275 : tensor([[ 2.7056,  2.7312,  2.7970,  2.9256,  2.8931,  2.7100,  2.8738,  2.7037,
          2.7037,  1.2758,  1.2940,  1.2906,  1.3160,  1.2638,  1.3563,  1.2765,
          1.2646,  1.2551,  1.2605,  1.2415,  1.2560,  1.2731,  1.2339,  1.2278,
          1.2505,  1.2221,  1.2221,  1.2692,  1.3136,  1.2406,  1.2654,  1.3156,
          1.2520,  1.2804,  1.2025,  1.2431,  1.3762,  1.4214,  1.4022,  1.3876,
          1.3929,  1.3392,  1.3887,  1.3289,  1.3156,  1.3367,  1.2899,  1.2772,
          1.2622,  1.3326,  1.2836,  1.3686,  1.2535,  1.2655],
        [ 1.2892,  1.2194,  1.1092,  1.2707,  1.3483,  1.3392,  1.2701,  1.3320,
          1.3320,  1.8316,  1.9922,  1.8012,  2.4099,  1.8594,  5.7675,  1.9056,
          1.7634,  5.5695,  1.1915,  1.2714,  1.1446,  1.2146,  1.3255,  1.3498,
          1.3221,  1.3440,  1.3440,  1.3390,  1.1608,  1.3630,  1.3562,  1.1932,
          1.3747,  1.4023,  1.3251,  1.3651,  1.4730,  1.5374,  1.4630,  1.4298,
          1.4815,  1.5083,  1.4492,  0.7968,  1.4249,  1.1736,  1.4109,  1.3966,
          1.3814,  1.1566,  1.4043,  1.0832,  1.3724,  1.3860],
        [ 1.2174,  1.2448,  1.3016,  1.2801,  1.2505,  1.2223,  1.2303,  1.2152,
          1.2152,  1.2815,  1.2998,  1.2963,  1.3218,  1.2695,  1.3114,  1.2822,
          1.2332,  1.2809,  2.7559,  2.8956,  2.9956,  2.8514,  2.6618,  2.7300,
          2.8485,  2.6515,  2.6515,  1.2842,  1.3055,  1.2463,  1.2707,  1.2846,
          1.2577,  1.2862,  1.2540,  1.2488,  1.3814,  1.4266,  1.4069,  1.3501,
          1.3976,  1.3965,  1.3938,  1.3016,  1.2778,  1.3294,  1.2959,  1.2832,
          1.2682,  1.3122,  1.2896,  1.3616,  1.2583,  1.2716],
        [ 1.2261,  1.2536,  1.3091,  1.2878,  1.2596,  1.2310,  1.2394,  1.2239,
          1.2239,  1.2900,  1.3068,  1.3048,  1.3296,  1.2778,  1.2767,  1.2906,
          1.2781,  1.2205,  1.2751,  1.2997,  1.3158,  1.2879,  1.2484,  1.2419,
          1.2637,  1.2366,  1.2366,  3.0019,  2.9598,  2.5948,  2.7575,  2.9995,
          2.6048,  2.9568,  2.6045,  2.5970,  1.3887,  1.4342,  1.4142,  1.3982,
          1.4055,  1.4043,  1.4009,  1.2845,  1.3260,  1.3515,  1.3041,  1.1983,
          1.2300,  1.3474,  1.2964,  1.3836,  1.2204,  1.2800],
        [ 1.8440,  1.4801,  0.6589,  0.9021,  1.2839,  1.7284,  1.6530,  1.8421,
          1.8421,  1.7295,  1.3609,  1.5362,  0.9753,  1.8151,  0.2791,  1.6874,
          1.8778,  1.0680,  1.3848,  0.9592,  0.7862,  1.1748,  1.6910,  1.7463,
          1.4860,  1.8519,  1.8519,  0.8118,  0.8870,  1.8245,  1.6100,  0.8857,
          1.7560,  1.2074,  1.8771,  1.7863,  0.3789,  0.1503,  0.1369,  0.3269,
          0.5740,  0.6739,  0.2696, 14.1152,  6.2237,  0.8256,  1.3690,  1.4796,
          1.7158,  1.0666,  1.6278,  0.4318,  1.7908,  1.8875],
        [ 1.2996,  1.3274,  1.3855,  1.3638,  1.3339,  1.3046,  1.2678,  1.2974,
          1.2974,  1.2681,  1.3807,  1.2828,  1.4033,  1.3503,  1.4433,  1.2687,
          1.3511,  1.2942,  1.3488,  1.3719,  1.3905,  1.3614,  1.3218,  1.3155,
          1.2448,  1.3099,  1.3099,  1.3564,  1.4011,  1.3280,  1.1284,  1.3100,
          1.2022,  1.3675,  1.1997,  1.3305,  1.4577,  1.1560,  1.4797,  1.4693,
          1.0374,  0.9556,  1.4704,  1.4087,  0.8409,  3.4075,  2.6527,  3.6120,
          2.9430,  2.2452,  1.9458,  3.0418,  3.3399,  1.9309]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 275 : 181.42314033851304
Test loss for epoch 275 : 181.52055081454586
Test Precision for epoch 275 : 0.26153846153846155
Test Recall for epoch 275 : 0.26153846153846155
Test F1 for epoch 275 : 0.26153846153846155


theta for epoch 276 : tensor([[ 2.7068,  2.7324,  2.7982,  2.9270,  2.8946,  2.7112,  2.8752,  2.7049,
          2.7049,  1.2759,  1.2943,  1.2907,  1.3165,  1.2640,  1.3568,  1.2767,
          1.2647,  1.2557,  1.2608,  1.2418,  1.2563,  1.2735,  1.2342,  1.2281,
          1.2508,  1.2224,  1.2224,  1.2694,  1.3137,  1.2407,  1.2655,  1.3157,
          1.2521,  1.2806,  1.2027,  1.2433,  1.3766,  1.4219,  1.4027,  1.3881,
          1.3932,  1.3397,  1.3892,  1.3285,  1.3160,  1.3362,  1.2894,  1.2767,
          1.2617,  1.3321,  1.2831,  1.3681,  1.2530,  1.2651],
        [ 1.2877,  1.2195,  1.1121,  1.2711,  1.3478,  1.3377,  1.2693,  1.3304,
          1.3304,  1.8370,  1.9951,  1.8060,  2.4082,  1.8640,  5.7650,  1.9100,
          1.7687,  5.5668,  1.1941,  1.2739,  1.1492,  1.2154,  1.3254,  1.3489,
          1.3213,  1.3431,  1.3431,  1.3394,  1.1630,  1.3620,  1.3559,  1.1951,
          1.3736,  1.4013,  1.3240,  1.3641,  1.4730,  1.5367,  1.4623,  1.4297,
          1.4822,  1.5076,  1.4484,  0.8043,  1.4241,  1.1773,  1.4091,  1.3948,
          1.3796,  1.1590,  1.4026,  1.0898,  1.3706,  1.3842],
        [ 1.2167,  1.2441,  1.3009,  1.2794,  1.2499,  1.2216,  1.2297,  1.2146,
          1.2146,  1.2812,  1.2997,  1.2960,  1.3218,  1.2692,  1.3118,  1.2820,
          1.2326,  1.2823,  2.7575,  2.8981,  2.9967,  2.8515,  2.6646,  2.7313,
          2.8513,  2.6542,  2.6542,  1.2838,  1.3058,  1.2461,  1.2705,  1.2841,
          1.2575,  1.2860,  1.2537,  1.2486,  1.3814,  1.4267,  1.4071,  1.3499,
          1.3976,  1.3966,  1.3939,  1.3021,  1.2775,  1.3290,  1.2948,  1.2821,
          1.2671,  1.3123,  1.2886,  1.3612,  1.2571,  1.2705],
        [ 1.2258,  1.2533,  1.3089,  1.2876,  1.2593,  1.2307,  1.2391,  1.2236,
          1.2236,  1.2900,  1.3071,  1.3048,  1.3300,  1.2779,  1.2771,  1.2907,
          1.2781,  1.2213,  1.2754,  1.2999,  1.3161,  1.2882,  1.2486,  1.2422,
          1.2639,  1.2368,  1.2368,  3.0031,  2.9620,  2.5964,  2.7593,  3.0007,
          2.6064,  2.9579,  2.6060,  2.5986,  1.3890,  1.4346,  1.4146,  1.3986,
          1.4058,  1.4048,  1.4013,  1.2842,  1.3262,  1.3510,  1.3036,  1.1979,
          1.2295,  1.3469,  1.2960,  1.3831,  1.2198,  1.2795],
        [ 1.8446,  1.4796,  0.6575,  0.9020,  1.2840,  1.7290,  1.6531,  1.8427,
          1.8427,  1.7304,  1.3601,  1.5369,  0.9732,  1.8152,  0.2757,  1.6874,
          1.8789,  1.0621,  1.3831,  0.9585,  0.7841,  1.1744,  1.6915,  1.7469,
          1.4871,  1.8530,  1.8530,  0.8123,  0.8861,  1.8256,  1.6106,  0.8852,
          1.7571,  1.2084,  1.8781,  1.7873,  0.3771,  0.1485,  0.1351,  0.3250,
          0.5722,  0.6713,  0.2677, 14.1626,  6.1929,  0.8232,  1.3695,  1.4801,
          1.7163,  1.0641,  1.6283,  0.4282,  1.7914,  1.8879],
        [ 1.2994,  1.3272,  1.3853,  1.3635,  1.3337,  1.3044,  1.2676,  1.2972,
          1.2972,  1.2682,  1.3810,  1.2829,  1.4039,  1.3505,  1.4438,  1.2690,
          1.3512,  1.2950,  1.3492,  1.3721,  1.3910,  1.3619,  1.3222,  1.3160,
          1.2450,  1.3103,  1.3103,  1.3566,  1.4012,  1.3281,  1.1284,  1.3102,
          1.2024,  1.3677,  1.1999,  1.3307,  1.4580,  1.1563,  1.4800,  1.4696,
          1.0374,  0.9558,  1.4708,  1.4082,  0.8409,  3.4101,  2.6530,  3.6151,
          2.9437,  2.2452,  1.9457,  3.0426,  3.3424,  1.9307]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 276 : 181.41501471959594
Test loss for epoch 276 : 181.51341812547042
Test Precision for epoch 276 : 0.26153846153846155
Test Recall for epoch 276 : 0.26153846153846155
Test F1 for epoch 276 : 0.26153846153846155


theta for epoch 277 : tensor([[ 2.7081,  2.7337,  2.7995,  2.9286,  2.8962,  2.7125,  2.8768,  2.7062,
          2.7062,  1.2758,  1.2944,  1.2906,  1.3168,  1.2639,  1.3570,  1.2766,
          1.2645,  1.2562,  1.2609,  1.2419,  1.2564,  1.2736,  1.2342,  1.2282,
          1.2509,  1.2225,  1.2225,  1.2693,  1.3136,  1.2406,  1.2654,  1.3156,
          1.2520,  1.2805,  1.2026,  1.2432,  1.3768,  1.4222,  1.4030,  1.3883,
          1.3934,  1.3400,  1.3894,  1.3278,  1.3162,  1.3363,  1.2895,  1.2767,
          1.2618,  1.3322,  1.2832,  1.3682,  1.2530,  1.2651],
        [ 1.2862,  1.2198,  1.1152,  1.2715,  1.3474,  1.3361,  1.2685,  1.3289,
          1.3289,  1.8425,  1.9979,  1.8108,  2.4063,  1.8688,  5.7617,  1.9144,
          1.7742,  5.5634,  1.1968,  1.2765,  1.1540,  1.2161,  1.3252,  1.3479,
          1.3205,  1.3420,  1.3420,  1.3398,  1.1650,  1.3607,  1.3556,  1.1970,
          1.3724,  1.4001,  1.3227,  1.3629,  1.4728,  1.5359,  1.4614,  1.4296,
          1.4828,  1.5068,  1.4475,  0.8121,  1.4232,  1.1817,  1.4080,  1.3936,
          1.3785,  1.1622,  1.4015,  1.0972,  1.3695,  1.3831],
        [ 1.2161,  1.2435,  1.3003,  1.2788,  1.2493,  1.2210,  1.2291,  1.2140,
          1.2140,  1.2808,  1.2995,  1.2956,  1.3218,  1.2689,  1.3121,  1.2817,
          1.2319,  1.2837,  2.7589,  2.9003,  2.9977,  2.8513,  2.6671,  2.7324,
          2.8538,  2.6568,  2.6568,  1.2832,  1.3060,  1.2458,  1.2701,  1.2836,
          1.2572,  1.2857,  1.2534,  1.2483,  1.3814,  1.4268,  1.4071,  1.3496,
          1.3975,  1.3967,  1.3940,  1.3026,  1.2771,  1.3293,  1.2946,  1.2819,
          1.2669,  1.3133,  1.2883,  1.3616,  1.2568,  1.2703],
        [ 1.2255,  1.2530,  1.3086,  1.2874,  1.2590,  1.2304,  1.2388,  1.2233,
          1.2233,  1.2899,  1.3072,  1.3048,  1.3303,  1.2779,  1.2774,  1.2907,
          1.2780,  1.2219,  1.2755,  1.3001,  1.3162,  1.2883,  1.2487,  1.2424,
          1.2640,  1.2369,  1.2369,  3.0042,  2.9641,  2.5979,  2.7610,  3.0018,
          2.6078,  2.9590,  2.6075,  2.6000,  1.3892,  1.4349,  1.4149,  1.3988,
          1.4059,  1.4051,  1.4016,  1.2836,  1.3264,  1.3510,  1.3036,  1.1979,
          1.2295,  1.3470,  1.2961,  1.3831,  1.2198,  1.2795],
        [ 1.8453,  1.4791,  0.6564,  0.9021,  1.2843,  1.7298,  1.6533,  1.8435,
          1.8435,  1.7313,  1.3592,  1.5375,  0.9711,  1.8153,  0.2724,  1.6874,
          1.8800,  1.0562,  1.3813,  0.9579,  0.7820,  1.1741,  1.6919,  1.7476,
          1.4882,  1.8542,  1.8542,  0.8130,  0.8854,  1.8266,  1.6111,  0.8848,
          1.7581,  1.2096,  1.8791,  1.7883,  0.3749,  0.1464,  0.1329,  0.3229,
          0.5700,  0.6684,  0.2654, 14.2102,  6.1614,  0.8216,  1.3708,  1.4814,
          1.7175,  1.0623,  1.6294,  0.4254,  1.7928,  1.8891],
        [ 1.2989,  1.3267,  1.3848,  1.3630,  1.3332,  1.3039,  1.2670,  1.2967,
          1.2967,  1.2678,  1.3809,  1.2826,  1.4039,  1.3502,  1.4438,  1.2687,
          1.3508,  1.2952,  1.3490,  1.3718,  1.3909,  1.3618,  1.3220,  1.3158,
          1.2446,  1.3101,  1.3101,  1.3563,  1.4010,  1.3278,  1.1279,  1.3100,
          1.2021,  1.3674,  1.1995,  1.3304,  1.4580,  1.1562,  1.4799,  1.4697,
          1.0370,  0.9555,  1.4709,  1.4073,  0.8405,  3.4134,  2.6542,  3.6191,
          2.9453,  2.2461,  1.9464,  3.0441,  3.3458,  1.9315]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 277 : 181.40682548326583
Test loss for epoch 277 : 181.50564091968067
Test Precision for epoch 277 : 0.26153846153846155
Test Recall for epoch 277 : 0.26153846153846155
Test F1 for epoch 277 : 0.26153846153846155


theta for epoch 278 : tensor([[ 2.7101,  2.7357,  2.8015,  2.9309,  2.8985,  2.7145,  2.8791,  2.7082,
          2.7082,  1.2753,  1.2942,  1.2902,  1.3167,  1.2635,  1.3570,  1.2763,
          1.2641,  1.2563,  1.2600,  1.2410,  1.2556,  1.2727,  1.2333,  1.2274,
          1.2500,  1.2216,  1.2216,  1.2689,  1.3132,  1.2402,  1.2650,  1.3152,
          1.2516,  1.2800,  1.2021,  1.2427,  1.3770,  1.4224,  1.4033,  1.3885,
          1.3935,  1.3402,  1.3897,  1.3270,  1.3164,  1.3358,  1.2890,  1.2762,
          1.2613,  1.3317,  1.2827,  1.3677,  1.2525,  1.2647],
        [ 1.2853,  1.2207,  1.1189,  1.2726,  1.3476,  1.3352,  1.2683,  1.3279,
          1.3279,  1.8485,  2.0010,  1.8160,  2.4045,  1.8738,  5.7579,  1.9192,
          1.7800,  5.5595,  1.1988,  1.2783,  1.1581,  1.2160,  1.3242,  1.3460,
          1.3187,  1.3400,  1.3400,  1.3401,  1.1670,  1.3594,  1.3552,  1.1990,
          1.3711,  1.3988,  1.3214,  1.3616,  1.4727,  1.5351,  1.4606,  1.4295,
          1.4834,  1.5061,  1.4467,  0.8201,  1.4223,  1.1858,  1.4064,  1.3921,
          1.3769,  1.1650,  1.3999,  1.1045,  1.3679,  1.3816],
        [ 1.2167,  1.2441,  1.3008,  1.2794,  1.2498,  1.2216,  1.2296,  1.2145,
          1.2145,  1.2810,  1.2998,  1.2958,  1.3224,  1.2691,  1.3129,  1.2819,
          1.2318,  1.2856,  2.7594,  2.9015,  2.9976,  2.8501,  2.6687,  2.7325,
          2.8553,  2.6583,  2.6583,  1.2830,  1.3067,  1.2459,  1.2702,  1.2834,
          1.2573,  1.2858,  1.2535,  1.2484,  1.3818,  1.4273,  1.4076,  1.3498,
          1.3979,  1.3972,  1.3945,  1.3034,  1.2772,  1.3300,  1.2946,  1.2819,
          1.2669,  1.3145,  1.2884,  1.3622,  1.2568,  1.2703],
        [ 1.2257,  1.2533,  1.3089,  1.2877,  1.2592,  1.2307,  1.2390,  1.2236,
          1.2236,  1.2897,  1.3073,  1.3046,  1.3305,  1.2778,  1.2776,  1.2906,
          1.2778,  1.2224,  1.2749,  1.2994,  1.3156,  1.2877,  1.2481,  1.2418,
          1.2633,  1.2362,  1.2362,  3.0055,  2.9663,  2.5994,  2.7628,  3.0031,
          2.6094,  2.9602,  2.6090,  2.6016,  1.3896,  1.4353,  1.4153,  1.3991,
          1.4062,  1.4055,  1.4020,  1.2832,  1.3267,  1.3508,  1.3033,  1.1977,
          1.2292,  1.3467,  1.2959,  1.3829,  1.2195,  1.2792],
        [ 1.8465,  1.4790,  0.6552,  0.9023,  1.2848,  1.7311,  1.6538,  1.8447,
          1.8447,  1.7320,  1.3581,  1.5380,  0.9687,  1.8152,  0.2685,  1.6871,
          1.8810,  1.0498,  1.3787,  0.9565,  0.7791,  1.1730,  1.6916,  1.7476,
          1.4886,  1.8546,  1.8546,  0.8133,  0.8843,  1.8274,  1.6114,  0.8838,
          1.7590,  1.2104,  1.8800,  1.7891,  0.3731,  0.1446,  0.1311,  0.3210,
          0.5681,  0.6658,  0.2635, 14.2585,  6.1296,  0.8192,  1.3716,  1.4821,
          1.7182,  1.0599,  1.6301,  0.4218,  1.7938,  1.8897],
        [ 1.2995,  1.3273,  1.3854,  1.3636,  1.3338,  1.3045,  1.2677,  1.2973,
          1.2973,  1.2679,  1.3812,  1.2827,  1.4044,  1.3504,  1.4443,  1.2689,
          1.3509,  1.2960,  1.3486,  1.3712,  1.3905,  1.3614,  1.3215,  1.3154,
          1.2439,  1.3096,  1.3096,  1.3564,  1.4010,  1.3279,  1.1278,  1.3101,
          1.2022,  1.3675,  1.1996,  1.3305,  1.4584,  1.1566,  1.4803,  1.4702,
          1.0372,  0.9558,  1.4714,  1.4068,  0.8406,  3.4158,  2.6544,  3.6221,
          2.9459,  2.2460,  1.9463,  3.0448,  3.3482,  1.9313]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 278 : 181.3984374522138
Test loss for epoch 278 : 181.49860418462
Test Precision for epoch 278 : 0.26153846153846155
Test Recall for epoch 278 : 0.26153846153846155
Test F1 for epoch 278 : 0.26153846153846155


theta for epoch 279 : tensor([[ 2.7105,  2.7360,  2.8019,  2.9316,  2.8991,  2.7149,  2.8798,  2.7086,
          2.7086,  1.2756,  1.2946,  1.2905,  1.3174,  1.2639,  1.3576,  1.2767,
          1.2643,  1.2573,  1.2610,  1.2420,  1.2566,  1.2738,  1.2343,  1.2284,
          1.2510,  1.2226,  1.2226,  1.2692,  1.3135,  1.2406,  1.2653,  1.3156,
          1.2520,  1.2804,  1.2025,  1.2431,  1.3776,  1.4232,  1.4040,  1.3892,
          1.3941,  1.3410,  1.3904,  1.3267,  1.3170,  1.3361,  1.2894,  1.2766,
          1.2617,  1.3321,  1.2831,  1.3681,  1.2529,  1.2651],
        [ 1.2835,  1.2208,  1.1220,  1.2728,  1.3470,  1.3333,  1.2674,  1.3261,
          1.3261,  1.8546,  2.0042,  1.8213,  2.4026,  1.8791,  5.7535,  1.9241,
          1.7860,  5.5549,  1.2021,  1.2813,  1.1635,  1.2171,  1.3244,  1.3452,
          1.3181,  1.3392,  1.3392,  1.3405,  1.1689,  1.3580,  1.3547,  1.2011,
          1.3697,  1.3974,  1.3200,  1.3602,  1.4725,  1.5343,  1.4597,  1.4293,
          1.4839,  1.5053,  1.4458,  0.8284,  1.4213,  1.1900,  1.4050,  1.3907,
          1.3755,  1.1681,  1.3985,  1.1121,  1.3664,  1.3801],
        [ 1.2157,  1.2431,  1.2998,  1.2784,  1.2489,  1.2206,  1.2287,  1.2136,
          1.2136,  1.2802,  1.2993,  1.2951,  1.3221,  1.2685,  1.3130,  1.2813,
          1.2308,  1.2866,  2.7612,  2.9042,  2.9989,  2.8503,  2.6717,  2.7340,
          2.8583,  2.6614,  2.6614,  1.2823,  1.3067,  1.2453,  1.2697,  1.2826,
          1.2567,  1.2853,  1.2530,  1.2479,  1.3817,  1.4274,  1.4076,  1.3494,
          1.3977,  1.3972,  1.3945,  1.3037,  1.2768,  1.3299,  1.2939,  1.2812,
          1.2662,  1.3149,  1.2877,  1.3621,  1.2560,  1.2696],
        [ 1.2252,  1.2528,  1.3084,  1.2873,  1.2588,  1.2302,  1.2386,  1.2231,
          1.2231,  1.2895,  1.3074,  1.3044,  1.3307,  1.2777,  1.2778,  1.2905,
          1.2776,  1.2230,  1.2754,  1.2998,  1.3161,  1.2883,  1.2486,  1.2424,
          1.2638,  1.2367,  1.2367,  3.0067,  2.9684,  2.6009,  2.7645,  3.0043,
          2.6108,  2.9614,  2.6105,  2.6031,  1.3898,  1.4357,  1.4157,  1.3994,
          1.4065,  1.4058,  1.4024,  1.2826,  1.3269,  1.3506,  1.3032,  1.1976,
          1.2291,  1.3465,  1.2959,  1.3827,  1.2193,  1.2791],
        [ 1.8469,  1.4780,  0.6535,  0.9019,  1.2847,  1.7316,  1.6536,  1.8452,
          1.8452,  1.7327,  1.3569,  1.5384,  0.9661,  1.8151,  0.2646,  1.6868,
          1.8820,  1.0433,  1.3768,  0.9558,  0.7769,  1.1727,  1.6922,  1.7485,
          1.4898,  1.8559,  1.8559,  0.8135,  0.8832,  1.8283,  1.6116,  0.8829,
          1.7598,  1.2113,  1.8808,  1.7899,  0.3712,  0.1427,  0.1292,  0.3191,
          0.5661,  0.6630,  0.2615, 14.3072,  6.0971,  0.8171,  1.3725,  1.4829,
          1.7190,  1.0576,  1.6309,  0.4182,  1.7949,  1.8906],
        [ 1.2990,  1.3268,  1.3849,  1.3631,  1.3333,  1.3040,  1.2672,  1.2968,
          1.2968,  1.2676,  1.3811,  1.2825,  1.4046,  1.3502,  1.4444,  1.2687,
          1.3506,  1.2963,  1.3492,  1.3716,  1.3911,  1.3621,  1.3221,  1.3160,
          1.2443,  1.3101,  1.3101,  1.3562,  1.4008,  1.3277,  1.1274,  1.3099,
          1.2020,  1.3673,  1.1994,  1.3303,  1.4586,  1.1567,  1.4804,  1.4704,
          1.0370,  0.9558,  1.4717,  1.4060,  0.8405,  3.4187,  2.6551,  3.6255,
          2.9470,  2.2464,  1.9466,  3.0459,  3.3511,  1.9316]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 279 : 181.38976835117896
Test loss for epoch 279 : 181.49096116010384
Test Precision for epoch 279 : 0.26153846153846155
Test Recall for epoch 279 : 0.26153846153846155
Test F1 for epoch 279 : 0.26153846153846155


theta for epoch 280 : tensor([[ 2.7125,  2.7381,  2.8040,  2.9339,  2.9015,  2.7169,  2.8821,  2.7106,
          2.7106,  1.2752,  1.2944,  1.2901,  1.3174,  1.2635,  1.3576,  1.2763,
          1.2639,  1.2575,  1.2602,  1.2411,  1.2558,  1.2730,  1.2334,  1.2276,
          1.2501,  1.2217,  1.2217,  1.2688,  1.3131,  1.2402,  1.2649,  1.3152,
          1.2516,  1.2800,  1.2021,  1.2427,  1.3775,  1.4232,  1.4041,  1.3892,
          1.3941,  1.3411,  1.3904,  1.3256,  1.3169,  1.3357,  1.2889,  1.2762,
          1.2613,  1.3317,  1.2826,  1.3676,  1.2524,  1.2646],
        [ 1.2827,  1.2221,  1.1261,  1.2741,  1.3473,  1.3325,  1.2675,  1.3252,
          1.3252,  1.8609,  2.0075,  1.8269,  2.4007,  1.8845,  5.7484,  1.9292,
          1.7922,  5.5496,  1.2045,  1.2834,  1.1679,  1.2172,  1.3235,  1.3433,
          1.3164,  1.3372,  1.3372,  1.3409,  1.1708,  1.3566,  1.3544,  1.2034,
          1.3683,  1.3961,  1.3186,  1.3589,  1.4722,  1.5333,  1.4587,  1.4290,
          1.4841,  1.5043,  1.4448,  0.8368,  1.4201,  1.1943,  1.4035,  1.3891,
          1.3739,  1.1711,  1.3970,  1.1198,  1.3649,  1.3786],
        [ 1.2164,  1.2438,  1.3005,  1.2791,  1.2495,  1.2213,  1.2294,  1.2142,
          1.2142,  1.2803,  1.2996,  1.2952,  1.3226,  1.2686,  1.3137,  1.2815,
          1.2307,  1.2884,  2.7617,  2.9055,  2.9988,  2.8492,  2.6734,  2.7341,
          2.8598,  2.6630,  2.6630,  1.2821,  1.3073,  1.2454,  1.2697,  1.2825,
          1.2568,  1.2854,  1.2531,  1.2479,  1.3819,  1.4277,  1.4080,  1.3493,
          1.3979,  1.3975,  1.3948,  1.3043,  1.2767,  1.3304,  1.2939,  1.2812,
          1.2662,  1.3160,  1.2877,  1.3627,  1.2560,  1.2696],
        [ 1.2257,  1.2533,  1.3089,  1.2878,  1.2592,  1.2307,  1.2390,  1.2236,
          1.2236,  1.2894,  1.3076,  1.3044,  1.3311,  1.2777,  1.2782,  1.2905,
          1.2775,  1.2237,  1.2750,  1.2993,  1.3157,  1.2878,  1.2480,  1.2419,
          1.2632,  1.2362,  1.2362,  3.0078,  2.9704,  2.6022,  2.7662,  3.0054,
          2.6122,  2.9624,  2.6118,  2.6044,  1.3900,  1.4360,  1.4160,  1.3996,
          1.4066,  1.4061,  1.4026,  1.2820,  1.3270,  1.3504,  1.3030,  1.1975,
          1.2289,  1.3464,  1.2957,  1.3825,  1.2190,  1.2789],
        [ 1.8484,  1.4780,  0.6527,  0.9025,  1.2857,  1.7331,  1.6544,  1.8467,
          1.8467,  1.7336,  1.3558,  1.5390,  0.9638,  1.8151,  0.2609,  1.6867,
          1.8831,  1.0370,  1.3743,  0.9546,  0.7742,  1.1718,  1.6920,  1.7488,
          1.4904,  1.8566,  1.8566,  0.8141,  0.8825,  1.8293,  1.6121,  0.8821,
          1.7609,  1.2124,  1.8819,  1.7910,  0.3690,  0.1405,  0.1270,  0.3169,
          0.5638,  0.6600,  0.2592, 14.3560,  6.0638,  0.8152,  1.3735,  1.4839,
          1.7200,  1.0555,  1.6318,  0.4150,  1.7961,  1.8915],
        [ 1.2994,  1.3272,  1.3853,  1.3635,  1.3337,  1.3044,  1.2675,  1.2972,
          1.2972,  1.2673,  1.3811,  1.2822,  1.4047,  1.3500,  1.4446,  1.2685,
          1.3503,  1.2967,  1.3484,  1.3706,  1.3903,  1.3613,  1.3212,  1.3152,
          1.2432,  1.3093,  1.3093,  1.3560,  1.4006,  1.3275,  1.1270,  1.3097,
          1.2018,  1.3671,  1.1992,  1.3300,  1.4586,  1.1567,  1.4803,  1.4704,
          1.0366,  0.9555,  1.4718,  1.4050,  0.8400,  3.4218,  2.6560,  3.6292,
          2.9483,  2.2470,  1.9471,  3.0473,  3.3542,  1.9321]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 280 : 181.38081114407782
Test loss for epoch 280 : 181.48295585827645
Test Precision for epoch 280 : 0.26153846153846155
Test Recall for epoch 280 : 0.26153846153846155
Test F1 for epoch 280 : 0.26153846153846155


theta for epoch 281 : tensor([[ 2.7135,  2.7391,  2.8050,  2.9353,  2.9028,  2.7180,  2.8835,  2.7116,
          2.7116,  1.2752,  1.2948,  1.2902,  1.3180,  1.2637,  1.3581,  1.2765,
          1.2640,  1.2582,  1.2605,  1.2414,  1.2561,  1.2733,  1.2337,  1.2279,
          1.2504,  1.2219,  1.2219,  1.2690,  1.3133,  1.2404,  1.2652,  1.3154,
          1.2518,  1.2802,  1.2023,  1.2429,  1.3780,  1.4238,  1.4046,  1.3897,
          1.3945,  1.3416,  1.3910,  1.3251,  1.3174,  1.3353,  1.2885,  1.2758,
          1.2609,  1.3313,  1.2823,  1.3672,  1.2520,  1.2642],
        [ 1.2810,  1.2225,  1.1295,  1.2745,  1.3467,  1.3307,  1.2667,  1.3235,
          1.3235,  1.8676,  2.0109,  1.8328,  2.3988,  1.8902,  5.7427,  1.9346,
          1.7988,  5.5437,  1.2077,  1.2862,  1.1732,  1.2179,  1.3233,  1.3421,
          1.3154,  1.3360,  1.3360,  1.3415,  1.1728,  1.3554,  1.3542,  1.2060,
          1.3671,  1.3949,  1.3173,  1.3577,  1.4720,  1.5325,  1.4578,  1.4289,
          1.4845,  1.5035,  1.4439,  0.8457,  1.4192,  1.1983,  1.4015,  1.3872,
          1.3720,  1.1738,  1.3951,  1.1274,  1.3630,  1.3767],
        [ 1.2157,  1.2432,  1.2998,  1.2784,  1.2489,  1.2207,  1.2287,  1.2136,
          1.2136,  1.2800,  1.2996,  1.2950,  1.3228,  1.2684,  1.3142,  1.2813,
          1.2301,  1.2899,  2.7630,  2.9077,  2.9996,  2.8489,  2.6760,  2.7352,
          2.8623,  2.6656,  2.6656,  1.2817,  1.3077,  1.2453,  1.2696,  1.2821,
          1.2567,  1.2852,  1.2529,  1.2478,  1.3821,  1.4280,  1.4082,  1.3492,
          1.3980,  1.3977,  1.3951,  1.3047,  1.2765,  1.3300,  1.2930,  1.2803,
          1.2653,  1.3163,  1.2868,  1.3624,  1.2550,  1.2687],
        [ 1.2254,  1.2529,  1.3085,  1.2875,  1.2589,  1.2303,  1.2387,  1.2232,
          1.2232,  1.2894,  1.3079,  1.3044,  1.3315,  1.2777,  1.2786,  1.2906,
          1.2774,  1.2244,  1.2751,  1.2994,  1.3158,  1.2880,  1.2482,  1.2421,
          1.2633,  1.2363,  1.2363,  3.0090,  2.9725,  2.6037,  2.7679,  3.0066,
          2.6137,  2.9636,  2.6133,  2.6059,  1.3904,  1.4365,  1.4165,  1.4000,
          1.4070,  1.4066,  1.4031,  1.2814,  1.3274,  1.3499,  1.3026,  1.1970,
          1.2284,  1.3459,  1.2953,  1.3821,  1.2185,  1.2784],
        [ 1.8489,  1.4770,  0.6510,  0.9023,  1.2858,  1.7338,  1.6543,  1.8474,
          1.8474,  1.7344,  1.3547,  1.5396,  0.9614,  1.8151,  0.2570,  1.6865,
          1.8843,  1.0306,  1.3720,  0.9536,  0.7717,  1.1712,  1.6922,  1.7495,
          1.4914,  1.8577,  1.8577,  0.8145,  0.8817,  1.8304,  1.6125,  0.8812,
          1.7620,  1.2135,  1.8830,  1.7920,  0.3670,  0.1386,  0.1250,  0.3149,
          0.5616,  0.6572,  0.2571, 14.4055,  6.0301,  0.8128,  1.3741,  1.4845,
          1.7205,  1.0530,  1.6323,  0.4112,  1.7969,  1.8920],
        [ 1.2991,  1.3270,  1.3850,  1.3633,  1.3334,  1.3042,  1.2673,  1.2970,
          1.2970,  1.2674,  1.3814,  1.2824,  1.4053,  1.3502,  1.4452,  1.2688,
          1.3504,  1.2976,  1.3488,  1.3708,  1.3907,  1.3617,  1.3215,  1.3156,
          1.2433,  1.3096,  1.3096,  1.3563,  1.4009,  1.3277,  1.1270,  1.3100,
          1.2020,  1.3674,  1.1994,  1.3303,  1.4590,  1.1570,  1.4806,  1.4709,
          1.0367,  0.9557,  1.4723,  1.4043,  0.8401,  3.4242,  2.6562,  3.6320,
          2.9488,  2.2469,  1.9468,  3.0479,  3.3565,  1.9319]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 281 : 181.37165167848238
Test loss for epoch 281 : 181.4753423762776
Test Precision for epoch 281 : 0.26153846153846155
Test Recall for epoch 281 : 0.26153846153846155
Test F1 for epoch 281 : 0.26153846153846155


theta for epoch 282 : tensor([[ 2.7147,  2.7403,  2.8062,  2.9367,  2.9043,  2.7191,  2.8849,  2.7128,
          2.7128,  1.2750,  1.2948,  1.2900,  1.3182,  1.2636,  1.3583,  1.2764,
          1.2637,  1.2587,  1.2604,  1.2413,  1.2560,  1.2733,  1.2336,  1.2278,
          1.2503,  1.2218,  1.2218,  1.2689,  1.3132,  1.2403,  1.2650,  1.3153,
          1.2516,  1.2801,  1.2021,  1.2428,  1.3785,  1.4244,  1.4052,  1.3901,
          1.3949,  1.3422,  1.3915,  1.3244,  1.3178,  1.3355,  1.2888,  1.2760,
          1.2611,  1.3315,  1.2825,  1.3674,  1.2523,  1.2645],
        [ 1.2794,  1.2233,  1.1331,  1.2750,  1.3463,  1.3291,  1.2662,  1.3218,
          1.3218,  1.8743,  2.0143,  1.8387,  2.3967,  1.8959,  5.7362,  1.9400,
          1.8053,  5.5370,  1.2109,  1.2889,  1.1783,  1.2186,  1.3230,  1.3407,
          1.3141,  1.3345,  1.3345,  1.3419,  1.1746,  1.3539,  1.3539,  1.2087,
          1.3656,  1.3935,  1.3159,  1.3562,  1.4718,  1.5317,  1.4570,  1.4288,
          1.4850,  1.5028,  1.4430,  0.8548,  1.4183,  1.2031,  1.4004,  1.3861,
          1.3709,  1.1773,  1.3940,  1.1357,  1.3618,  1.3756],
        [ 1.2153,  1.2428,  1.2994,  1.2781,  1.2485,  1.2203,  1.2283,  1.2132,
          1.2132,  1.2796,  1.2995,  1.2947,  1.3229,  1.2682,  1.3146,  1.2810,
          1.2295,  1.2913,  2.7640,  2.9095,  3.0000,  2.8481,  2.6782,  2.7359,
          2.8644,  2.6678,  2.6678,  1.2812,  1.3080,  1.2450,  1.2693,  1.2816,
          1.2564,  1.2850,  1.2527,  1.2475,  1.3824,  1.4284,  1.4086,  1.3492,
          1.3983,  1.3981,  1.3955,  1.3053,  1.2764,  1.3307,  1.2932,  1.2804,
          1.2655,  1.3175,  1.2869,  1.3631,  1.2550,  1.2689],
        [ 1.2252,  1.2527,  1.3083,  1.2873,  1.2587,  1.2301,  1.2385,  1.2230,
          1.2230,  1.2893,  1.3080,  1.3043,  1.3318,  1.2777,  1.2790,  1.2906,
          1.2773,  1.2251,  1.2751,  1.2994,  1.3158,  1.2880,  1.2481,  1.2421,
          1.2632,  1.2363,  1.2363,  3.0100,  2.9743,  2.6049,  2.7693,  3.0076,
          2.6149,  2.9645,  2.6145,  2.6071,  1.3909,  1.4370,  1.4171,  1.4004,
          1.4074,  1.4072,  1.4036,  1.2810,  1.3278,  1.3501,  1.3028,  1.1973,
          1.2286,  1.3461,  1.2956,  1.3823,  1.2186,  1.2786],
        [ 1.8496,  1.4761,  0.6494,  0.9021,  1.2860,  1.7346,  1.6542,  1.8481,
          1.8481,  1.7352,  1.3534,  1.5401,  0.9588,  1.8149,  0.2529,  1.6861,
          1.8852,  1.0240,  1.3694,  0.9525,  0.7691,  1.1705,  1.6922,  1.7500,
          1.4923,  1.8586,  1.8586,  0.8148,  0.8809,  1.8313,  1.6126,  0.8801,
          1.7629,  1.2144,  1.8838,  1.7929,  0.3649,  0.1365,  0.1229,  0.3128,
          0.5594,  0.6543,  0.2549, 14.4554,  5.9957,  0.8111,  1.3754,  1.4857,
          1.7217,  1.0512,  1.6335,  0.4081,  1.7983,  1.8931],
        [ 1.2986,  1.3264,  1.3845,  1.3627,  1.3329,  1.3036,  1.2668,  1.2965,
          1.2965,  1.2669,  1.3812,  1.2819,  1.4053,  1.3497,  1.4451,  1.2684,
          1.3499,  1.2978,  1.3484,  1.3702,  1.3904,  1.3613,  1.3211,  1.3152,
          1.2426,  1.3091,  1.3091,  1.3558,  1.4005,  1.3273,  1.1263,  1.3096,
          1.2016,  1.3670,  1.1990,  1.3298,  1.4592,  1.1571,  1.4807,  1.4711,
          1.0365,  0.9556,  1.4725,  1.4034,  0.8398,  3.4275,  2.6574,  3.6359,
          2.9504,  2.2478,  1.9477,  3.0494,  3.3599,  1.9327]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 282 : 181.36232722472096
Test loss for epoch 282 : 181.4670445867293
Test Precision for epoch 282 : 0.26153846153846155
Test Recall for epoch 282 : 0.26153846153846155
Test F1 for epoch 282 : 0.26153846153846155


theta for epoch 283 : tensor([[ 2.7166,  2.7422,  2.8080,  2.9389,  2.9064,  2.7210,  2.8870,  2.7147,
          2.7147,  1.2747,  1.2947,  1.2897,  1.3183,  1.2633,  1.3584,  1.2762,
          1.2633,  1.2591,  1.2600,  1.2408,  1.2555,  1.2728,  1.2330,  1.2274,
          1.2497,  1.2213,  1.2213,  1.2685,  1.3128,  1.2399,  1.2647,  1.3150,
          1.2513,  1.2798,  1.2018,  1.2424,  1.3786,  1.4246,  1.4054,  1.3903,
          1.3951,  1.3424,  1.3917,  1.3234,  1.3179,  1.3347,  1.2880,  1.2752,
          1.2604,  1.3308,  1.2818,  1.3667,  1.2515,  1.2638],
        [ 1.2784,  1.2246,  1.1372,  1.2760,  1.3463,  1.3280,  1.2662,  1.3207,
          1.3207,  1.8815,  2.0180,  1.8451,  2.3949,  1.9021,  5.7293,  1.9458,
          1.8125,  5.5298,  1.2138,  1.2914,  1.1832,  1.2189,  1.3224,  1.3389,
          1.3125,  1.3327,  1.3327,  1.3424,  1.1763,  1.3524,  1.3536,  1.2113,
          1.3641,  1.3920,  1.3144,  1.3547,  1.4714,  1.5307,  1.4560,  1.4285,
          1.4851,  1.5018,  1.4420,  0.8640,  1.4171,  1.2069,  1.3984,  1.3841,
          1.3689,  1.1798,  1.3920,  1.1434,  1.3598,  1.3735],
        [ 1.2157,  1.2432,  1.2997,  1.2784,  1.2489,  1.2206,  1.2287,  1.2136,
          1.2136,  1.2795,  1.2997,  1.2946,  1.3233,  1.2682,  1.3153,  1.2811,
          1.2292,  1.2930,  2.7648,  2.9111,  3.0001,  2.8472,  2.6802,  2.7363,
          2.8663,  2.6699,  2.6699,  1.2809,  1.3084,  1.2449,  1.2692,  1.2813,
          1.2563,  1.2849,  1.2526,  1.2475,  1.3826,  1.4287,  1.4089,  1.3492,
          1.3985,  1.3984,  1.3958,  1.3057,  1.2763,  1.3307,  1.2926,  1.2798,
          1.2649,  1.3180,  1.2864,  1.3631,  1.2544,  1.2683],
        [ 1.2254,  1.2530,  1.3086,  1.2876,  1.2589,  1.2304,  1.2387,  1.2233,
          1.2233,  1.2891,  1.3082,  1.3042,  1.3321,  1.2776,  1.2793,  1.2905,
          1.2771,  1.2258,  1.2748,  1.2990,  1.3155,  1.2877,  1.2477,  1.2418,
          1.2628,  1.2359,  1.2359,  3.0112,  2.9764,  2.6064,  2.7710,  3.0089,
          2.6163,  2.9657,  2.6160,  2.6086,  1.3911,  1.4374,  1.4175,  1.4007,
          1.4077,  1.4076,  1.4040,  1.2803,  1.3280,  1.3496,  1.3023,  1.1968,
          1.2281,  1.3456,  1.2951,  1.3817,  1.2180,  1.2781],
        [ 1.8509,  1.4757,  0.6483,  0.9025,  1.2868,  1.7360,  1.6546,  1.8495,
          1.8495,  1.7360,  1.3522,  1.5407,  0.9564,  1.8148,  0.2490,  1.6858,
          1.8864,  1.0176,  1.3667,  0.9514,  0.7664,  1.1697,  1.6921,  1.7504,
          1.4931,  1.8594,  1.8594,  0.8152,  0.8802,  1.8323,  1.6129,  0.8790,
          1.7639,  1.2155,  1.8848,  1.7939,  0.3628,  0.1344,  0.1208,  0.3106,
          0.5571,  0.6513,  0.2527, 14.5057,  5.9607,  0.8088,  1.3761,  1.4863,
          1.7223,  1.0488,  1.6341,  0.4045,  1.7992,  1.8937],
        [ 1.2993,  1.3271,  1.3852,  1.3634,  1.3336,  1.3043,  1.2675,  1.2972,
          1.2972,  1.2672,  1.3817,  1.2822,  1.4060,  1.3501,  1.4458,  1.2687,
          1.3501,  1.2988,  1.3485,  1.3701,  1.3905,  1.3615,  1.3212,  1.3153,
          1.2425,  1.3092,  1.3092,  1.3561,  1.4007,  1.3275,  1.1264,  1.3099,
          1.2019,  1.3672,  1.1993,  1.3301,  1.4597,  1.1576,  1.4810,  1.4716,
          1.0366,  0.9559,  1.4731,  1.4027,  0.8400,  3.4295,  2.6571,  3.6384,
          2.9505,  2.2473,  1.9471,  3.0496,  3.3619,  1.9321]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 283 : 181.35278187459787
Test loss for epoch 283 : 181.45945326448916
Test Precision for epoch 283 : 0.26153846153846155
Test Recall for epoch 283 : 0.26153846153846155
Test F1 for epoch 283 : 0.26153846153846155


theta for epoch 284 : tensor([[ 2.7169,  2.7425,  2.8084,  2.9395,  2.9071,  2.7213,  2.8877,  2.7150,
          2.7150,  1.2749,  1.2952,  1.2900,  1.3191,  1.2637,  1.3591,  1.2766,
          1.2636,  1.2601,  1.2606,  1.2414,  1.2562,  1.2735,  1.2336,  1.2280,
          1.2504,  1.2219,  1.2219,  1.2689,  1.3132,  1.2403,  1.2651,  1.3154,
          1.2517,  1.2802,  1.2022,  1.2428,  1.3792,  1.4253,  1.4061,  1.3909,
          1.3956,  1.3431,  1.3924,  1.3229,  1.3185,  1.3353,  1.2886,  1.2758,
          1.2610,  1.3314,  1.2824,  1.3673,  1.2521,  1.2644],
        [ 1.2765,  1.2252,  1.1406,  1.2762,  1.3454,  1.3260,  1.2654,  1.3187,
          1.3187,  1.8889,  2.0218,  1.8516,  2.3929,  1.9084,  5.7216,  1.9517,
          1.8197,  5.5218,  1.2173,  1.2942,  1.1886,  1.2197,  1.3223,  1.3376,
          1.3114,  1.3313,  1.3313,  1.3428,  1.1780,  1.3509,  1.3533,  1.2142,
          1.3626,  1.3906,  1.3129,  1.3533,  1.4709,  1.5297,  1.4549,  1.4281,
          1.4851,  1.5008,  1.4409,  0.8733,  1.4159,  1.2114,  1.3971,  1.3828,
          1.3676,  1.1830,  1.3906,  1.1516,  1.3584,  1.3722],
        [ 1.2150,  1.2425,  1.2989,  1.2777,  1.2482,  1.2199,  1.2280,  1.2128,
          1.2128,  1.2791,  1.2994,  1.2941,  1.3233,  1.2678,  1.3156,  1.2807,
          1.2285,  1.2942,  2.7661,  2.9133,  3.0008,  2.8468,  2.6828,  2.7373,
          2.8687,  2.6725,  2.6725,  1.2803,  1.3086,  1.2446,  1.2689,  1.2808,
          1.2560,  1.2846,  1.2523,  1.2472,  1.3827,  1.4289,  1.4090,  1.3490,
          1.3985,  1.3985,  1.3959,  1.3058,  1.2760,  1.3310,  1.2925,  1.2797,
          1.2648,  1.3189,  1.2862,  1.3634,  1.2542,  1.2682],
        [ 1.2250,  1.2525,  1.3081,  1.2872,  1.2585,  1.2299,  1.2383,  1.2228,
          1.2228,  1.2889,  1.3083,  1.3040,  1.3324,  1.2775,  1.2796,  1.2905,
          1.2769,  1.2264,  1.2750,  1.2991,  1.3157,  1.2879,  1.2478,  1.2419,
          1.2629,  1.2360,  1.2360,  3.0124,  2.9784,  2.6078,  2.7726,  3.0101,
          2.6177,  2.9668,  2.6173,  2.6099,  1.3914,  1.4378,  1.4178,  1.4009,
          1.4079,  1.4079,  1.4043,  1.2795,  1.3282,  1.3496,  1.3023,  1.1969,
          1.2281,  1.3456,  1.2952,  1.3818,  1.2180,  1.2781],
        [ 1.8515,  1.4745,  0.6468,  0.9024,  1.2869,  1.7367,  1.6543,  1.8501,
          1.8501,  1.7368,  1.3509,  1.5412,  0.9540,  1.8147,  0.2452,  1.6854,
          1.8874,  1.0112,  1.3644,  0.9506,  0.7641,  1.1693,  1.6923,  1.7513,
          1.4943,  1.8606,  1.8606,  0.8156,  0.8796,  1.8333,  1.6132,  0.8779,
          1.7649,  1.2166,  1.8859,  1.7949,  0.3605,  0.1323,  0.1185,  0.3084,
          0.5546,  0.6482,  0.2504, 14.5563,  5.9249,  0.8073,  1.3774,  1.4876,
          1.7235,  1.0472,  1.6353,  0.4016,  1.8007,  1.8949],
        [ 1.2986,  1.3264,  1.3845,  1.3627,  1.3329,  1.3036,  1.2668,  1.2964,
          1.2964,  1.2667,  1.3815,  1.2818,  1.4060,  1.3497,  1.4458,  1.2683,
          1.3495,  1.2990,  1.3484,  1.3697,  1.3904,  1.3614,  1.3210,  1.3152,
          1.2421,  1.3090,  1.3090,  1.3558,  1.4004,  1.3272,  1.1258,  1.3095,
          1.2015,  1.3669,  1.1989,  1.3297,  1.4597,  1.1575,  1.4809,  1.4716,
          1.0362,  0.9556,  1.4732,  1.4016,  0.8394,  3.4328,  2.6583,  3.6422,
          2.9521,  2.2482,  1.9479,  3.0512,  3.3653,  1.9329]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 284 : 181.34297191956404
Test loss for epoch 284 : 181.4507935267051
Test Precision for epoch 284 : 0.26153846153846155
Test Recall for epoch 284 : 0.26153846153846155
Test F1 for epoch 284 : 0.26153846153846155


theta for epoch 285 : tensor([[ 2.7188,  2.7445,  2.8103,  2.9417,  2.9093,  2.7232,  2.8899,  2.7169,
          2.7169,  1.2744,  1.2950,  1.2895,  1.3191,  1.2633,  1.3591,  1.2762,
          1.2631,  1.2603,  1.2601,  1.2408,  1.2556,  1.2729,  1.2330,  1.2274,
          1.2498,  1.2213,  1.2213,  1.2685,  1.3128,  1.2399,  1.2647,  1.3150,
          1.2513,  1.2798,  1.2018,  1.2424,  1.3794,  1.4256,  1.4064,  1.3912,
          1.3959,  1.3434,  1.3927,  1.3219,  1.3187,  1.3345,  1.2878,  1.2750,
          1.2602,  1.3306,  1.2816,  1.3665,  1.2513,  1.2636],
        [ 1.2757,  1.2269,  1.1450,  1.2774,  1.3456,  1.3251,  1.2658,  1.3178,
          1.3178,  1.8963,  2.0256,  1.8583,  2.3909,  1.9148,  5.7131,  1.9577,
          1.8271,  5.5130,  1.2205,  1.2968,  1.1937,  1.2201,  1.3219,  1.3359,
          1.3099,  1.3296,  1.3296,  1.3434,  1.1796,  1.3494,  1.3531,  1.2172,
          1.3611,  1.3891,  1.3114,  1.3518,  1.4707,  1.5288,  1.4540,  1.4279,
          1.4853,  1.5000,  1.4399,  0.8829,  1.4149,  1.2153,  1.3952,  1.3809,
          1.3657,  1.1856,  1.3887,  1.1594,  1.3565,  1.3703],
        [ 1.2155,  1.2430,  1.2994,  1.2782,  1.2487,  1.2204,  1.2285,  1.2134,
          1.2134,  1.2789,  1.2996,  1.2940,  1.3236,  1.2677,  1.3162,  1.2807,
          1.2281,  1.2958,  2.7666,  2.9147,  3.0007,  2.8457,  2.6847,  2.7376,
          2.8705,  2.6743,  2.6743,  1.2800,  1.3091,  1.2446,  1.2688,  1.2805,
          1.2560,  1.2846,  1.2523,  1.2471,  1.3831,  1.4294,  1.4095,  1.3491,
          1.3989,  1.3990,  1.3964,  1.3063,  1.2760,  1.3310,  1.2920,  1.2792,
          1.2643,  1.3194,  1.2857,  1.3634,  1.2536,  1.2677],
        [ 1.2255,  1.2530,  1.3086,  1.2877,  1.2589,  1.2304,  1.2388,  1.2233,
          1.2233,  1.2888,  1.3085,  1.3039,  1.3328,  1.2775,  1.2800,  1.2905,
          1.2768,  1.2271,  1.2748,  1.2988,  1.3155,  1.2877,  1.2476,  1.2418,
          1.2626,  1.2358,  1.2358,  3.0134,  2.9801,  2.6089,  2.7739,  3.0111,
          2.6189,  2.9678,  2.6185,  2.6111,  1.3919,  1.4384,  1.4184,  1.4014,
          1.4084,  1.4085,  1.4049,  1.2790,  1.3286,  1.3492,  1.3019,  1.1966,
          1.2277,  1.3452,  1.2949,  1.3814,  1.2175,  1.2778],
        [ 1.8527,  1.4739,  0.6455,  0.9027,  1.2877,  1.7380,  1.6546,  1.8515,
          1.8515,  1.7374,  1.3495,  1.5415,  0.9513,  1.8143,  0.2410,  1.6848,
          1.8884,  1.0047,  1.3614,  0.9493,  0.7612,  1.1683,  1.6919,  1.7516,
          1.4949,  1.8612,  1.8612,  0.8157,  0.8788,  1.8342,  1.6132,  0.8765,
          1.7657,  1.2174,  1.8867,  1.7957,  0.3585,  0.1303,  0.1166,  0.3064,
          0.5523,  0.6453,  0.2483, 14.6076,  5.8887,  0.8050,  1.3778,  1.4880,
          1.7239,  1.0448,  1.6357,  0.3979,  1.8015,  1.8953],
        [ 1.2993,  1.3271,  1.3851,  1.3634,  1.3335,  1.3043,  1.2674,  1.2971,
          1.2971,  1.2666,  1.3817,  1.2818,  1.4065,  1.3497,  1.4463,  1.2685,
          1.3495,  1.2998,  1.3484,  1.3694,  1.3904,  1.3613,  1.3209,  1.3151,
          1.2417,  1.3089,  1.3089,  1.3558,  1.4004,  1.3272,  1.1256,  1.3097,
          1.2016,  1.3670,  1.1990,  1.3298,  1.4601,  1.1579,  1.4812,  1.4721,
          1.0363,  0.9558,  1.4737,  1.4008,  0.8395,  3.4350,  2.6583,  3.6448,
          2.9525,  2.2480,  1.9476,  3.0516,  3.3674,  1.9326]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 285 : 181.3328806880616
Test loss for epoch 285 : 181.44285062588693
Test Precision for epoch 285 : 0.26153846153846155
Test Recall for epoch 285 : 0.26153846153846155
Test F1 for epoch 285 : 0.26153846153846155


theta for epoch 286 : tensor([[ 2.7196,  2.7452,  2.8111,  2.9427,  2.9103,  2.7240,  2.8909,  2.7177,
          2.7177,  1.2745,  1.2954,  1.2896,  1.3197,  1.2635,  1.3597,  1.2764,
          1.2632,  1.2612,  1.2603,  1.2410,  1.2558,  1.2732,  1.2332,  1.2276,
          1.2499,  1.2214,  1.2214,  1.2688,  1.3131,  1.2402,  1.2649,  1.3153,
          1.2515,  1.2801,  1.2020,  1.2427,  1.3799,  1.4262,  1.4070,  1.3917,
          1.3964,  1.3440,  1.3933,  1.3212,  1.3192,  1.3346,  1.2880,  1.2752,
          1.2603,  1.3308,  1.2817,  1.3666,  1.2514,  1.2637],
        [ 1.2739,  1.2277,  1.1483,  1.2776,  1.3447,  1.3231,  1.2652,  1.3159,
          1.3159,  1.9042,  2.0296,  1.8652,  2.3889,  1.9215,  5.7040,  1.9640,
          1.8348,  5.5036,  1.2240,  1.2995,  1.1990,  1.2208,  1.3217,  1.3345,
          1.3086,  1.3281,  1.3281,  1.3440,  1.1811,  1.3480,  1.3530,  1.2205,
          1.3597,  1.3877,  1.3099,  1.3504,  1.4702,  1.5278,  1.4530,  1.4276,
          1.4853,  1.4991,  1.4389,  0.8925,  1.4138,  1.2195,  1.3937,  1.3794,
          1.3642,  1.1885,  1.3872,  1.1674,  1.3550,  1.3688],
        [ 1.2149,  1.2424,  1.2988,  1.2776,  1.2481,  1.2198,  1.2279,  1.2128,
          1.2128,  1.2787,  1.2996,  1.2939,  1.3239,  1.2676,  1.3167,  1.2806,
          1.2276,  1.2973,  2.7677,  2.9166,  3.0010,  2.8449,  2.6870,  2.7384,
          2.8726,  2.6767,  2.6767,  1.2797,  1.3095,  1.2445,  1.2687,  1.2801,
          1.2559,  1.2845,  1.2522,  1.2470,  1.3833,  1.4297,  1.4098,  1.3490,
          1.3991,  1.3993,  1.3967,  1.3065,  1.2759,  1.3312,  1.2918,  1.2790,
          1.2641,  1.3201,  1.2856,  1.3637,  1.2533,  1.2675],
        [ 1.2251,  1.2526,  1.3082,  1.2873,  1.2585,  1.2300,  1.2384,  1.2229,
          1.2229,  1.2887,  1.3088,  1.3039,  1.3333,  1.2776,  1.2805,  1.2906,
          1.2767,  1.2280,  1.2748,  1.2988,  1.3155,  1.2878,  1.2476,  1.2418,
          1.2626,  1.2358,  1.2358,  3.0145,  2.9819,  2.6102,  2.7754,  3.0122,
          2.6201,  2.9688,  2.6198,  2.6124,  1.3923,  1.4388,  1.4189,  1.4018,
          1.4088,  1.4090,  1.4053,  1.2783,  1.3289,  1.3491,  1.3019,  1.1965,
          1.2276,  1.3452,  1.2949,  1.3813,  1.2174,  1.2777],
        [ 1.8532,  1.4725,  0.6440,  0.9025,  1.2878,  1.7387,  1.6542,  1.8521,
          1.8521,  1.7382,  1.3482,  1.5421,  0.9491,  1.8142,  0.2372,  1.6844,
          1.8895,  0.9986,  1.3589,  0.9484,  0.7588,  1.1677,  1.6919,  1.7522,
          1.4960,  1.8622,  1.8622,  0.8161,  0.8784,  1.8353,  1.6135,  0.8754,
          1.7668,  1.2185,  1.8878,  1.7968,  0.3562,  0.1282,  0.1144,  0.3042,
          0.5498,  0.6422,  0.2460, 14.6592,  5.8517,  0.8035,  1.3789,  1.4890,
          1.7249,  1.0431,  1.6366,  0.3950,  1.8028,  1.8963],
        [ 1.2986,  1.3265,  1.3845,  1.3627,  1.3329,  1.3036,  1.2668,  1.2965,
          1.2965,  1.2664,  1.3818,  1.2816,  1.4068,  1.3496,  1.4466,  1.2684,
          1.3493,  1.3003,  1.3482,  1.3690,  1.3902,  1.3612,  1.3207,  1.3149,
          1.2412,  1.3087,  1.3087,  1.3558,  1.4004,  1.3271,  1.1253,  1.3096,
          1.2015,  1.3669,  1.1989,  1.3297,  1.4603,  1.1580,  1.4812,  1.4724,
          1.0361,  0.9557,  1.4740,  1.3998,  0.8392,  3.4380,  2.6591,  3.6482,
          2.9536,  2.2485,  1.9480,  3.0528,  3.3705,  1.9331]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 286 : 181.32255602568551
Test loss for epoch 286 : 181.43413925965348
Test Precision for epoch 286 : 0.26153846153846155
Test Recall for epoch 286 : 0.26153846153846155
Test F1 for epoch 286 : 0.26153846153846155


theta for epoch 287 : tensor([[ 2.7209,  2.7466,  2.8124,  2.9443,  2.9119,  2.7253,  2.8925,  2.7190,
          2.7190,  1.2743,  1.2954,  1.2894,  1.3199,  1.2633,  1.3599,  1.2763,
          1.2629,  1.2617,  1.2602,  1.2408,  1.2557,  1.2731,  1.2331,  1.2275,
          1.2498,  1.2213,  1.2213,  1.2687,  1.3129,  1.2401,  1.2648,  1.3152,
          1.2514,  1.2800,  1.2019,  1.2426,  1.3802,  1.4266,  1.4074,  1.3920,
          1.3967,  1.3444,  1.3936,  1.3202,  1.3194,  1.3343,  1.2877,  1.2749,
          1.2601,  1.3305,  1.2814,  1.3663,  1.2511,  1.2635],
        [ 1.2726,  1.2290,  1.1521,  1.2781,  1.3442,  1.3217,  1.2652,  1.3144,
          1.3144,  1.9122,  2.0337,  1.8723,  2.3869,  1.9283,  5.6942,  1.9704,
          1.8427,  5.4935,  1.2274,  1.3021,  1.2042,  1.2215,  1.3215,  1.3330,
          1.3073,  1.3266,  1.3266,  1.3446,  1.1825,  1.3465,  1.3528,  1.2237,
          1.3582,  1.3863,  1.3085,  1.3489,  1.4698,  1.5268,  1.4520,  1.4273,
          1.4852,  1.4981,  1.4378,  0.9022,  1.4126,  1.2234,  1.3920,  1.3777,
          1.3626,  1.1912,  1.3856,  1.1751,  1.3533,  1.3671],
        [ 1.2147,  1.2422,  1.2985,  1.2774,  1.2479,  1.2197,  1.2278,  1.2126,
          1.2126,  1.2784,  1.2996,  1.2936,  1.3241,  1.2674,  1.3171,  1.2804,
          1.2271,  1.2987,  2.7686,  2.9185,  3.0013,  2.8441,  2.6893,  2.7390,
          2.8747,  2.6789,  2.6789,  1.2793,  1.3098,  1.2443,  1.2685,  1.2797,
          1.2557,  1.2843,  1.2520,  1.2469,  1.3835,  1.4300,  1.4101,  1.3490,
          1.3993,  1.3996,  1.3970,  1.3066,  1.2757,  1.3312,  1.2915,  1.2786,
          1.2637,  1.3207,  1.2852,  1.3638,  1.2528,  1.2671],
        [ 1.2250,  1.2526,  1.3081,  1.2873,  1.2585,  1.2300,  1.2384,  1.2229,
          1.2229,  1.2886,  1.3089,  1.3038,  1.3336,  1.2775,  1.2808,  1.2906,
          1.2766,  1.2287,  1.2748,  1.2987,  1.3155,  1.2878,  1.2475,  1.2418,
          1.2625,  1.2357,  1.2357,  3.0156,  2.9837,  2.6114,  2.7768,  3.0133,
          2.6214,  2.9698,  2.6210,  2.6136,  1.3926,  1.4393,  1.4194,  1.4021,
          1.4092,  1.4094,  1.4058,  1.2775,  1.3292,  1.3489,  1.3017,  1.1964,
          1.2274,  1.3450,  1.2947,  1.3811,  1.2171,  1.2775],
        [ 1.8541,  1.4715,  0.6428,  0.9027,  1.2884,  1.7397,  1.6541,  1.8531,
          1.8531,  1.7389,  1.3470,  1.5426,  0.9468,  1.8140,  0.2335,  1.6838,
          1.8905,  0.9926,  1.3563,  0.9476,  0.7565,  1.1671,  1.6918,  1.7529,
          1.4970,  1.8632,  1.8632,  0.8166,  0.8780,  1.8363,  1.6137,  0.8742,
          1.7678,  1.2196,  1.8888,  1.7978,  0.3540,  0.1261,  0.1121,  0.3020,
          0.5473,  0.6391,  0.2437, 14.7112,  5.8140,  0.8019,  1.3799,  1.4899,
          1.7258,  1.0414,  1.6375,  0.3921,  1.8040,  1.8971],
        [ 1.2987,  1.3265,  1.3845,  1.3628,  1.3329,  1.3037,  1.2668,  1.2965,
          1.2965,  1.2663,  1.3820,  1.2816,  1.4072,  1.3496,  1.4470,  1.2684,
          1.3491,  1.3010,  1.3483,  1.3688,  1.3903,  1.3614,  1.3207,  1.3150,
          1.2410,  1.3087,  1.3087,  1.3558,  1.4004,  1.3272,  1.1251,  1.3097,
          1.2015,  1.3669,  1.1989,  1.3297,  1.4606,  1.1583,  1.4814,  1.4727,
          1.0360,  0.9557,  1.4744,  1.3988,  0.8390,  3.4405,  2.6594,  3.6511,
          2.9542,  2.2486,  1.9480,  3.0535,  3.3729,  1.9330]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 287 : 181.31204382055205
Test loss for epoch 287 : 181.42556960925697
Test Precision for epoch 287 : 0.26153846153846155
Test Recall for epoch 287 : 0.26153846153846155
Test F1 for epoch 287 : 0.26153846153846155


theta for epoch 288 : tensor([[ 2.7223,  2.7479,  2.8138,  2.9460,  2.9136,  2.7267,  2.8942,  2.7204,
          2.7204,  1.2740,  1.2954,  1.2892,  1.3202,  1.2632,  1.3601,  1.2762,
          1.2626,  1.2622,  1.2599,  1.2405,  1.2554,  1.2728,  1.2327,  1.2272,
          1.2494,  1.2209,  1.2209,  1.2684,  1.3127,  1.2399,  1.2646,  1.3150,
          1.2512,  1.2798,  1.2017,  1.2424,  1.3806,  1.4271,  1.4079,  1.3924,
          1.3971,  1.3449,  1.3941,  1.3193,  1.3197,  1.3341,  1.2874,  1.2746,
          1.2598,  1.3302,  1.2812,  1.3661,  1.2508,  1.2632],
        [ 1.2715,  1.2306,  1.1559,  1.2788,  1.3439,  1.3204,  1.2654,  1.3132,
          1.3132,  1.9203,  2.0378,  1.8796,  2.3849,  1.9353,  5.6837,  1.9769,
          1.8507,  5.4827,  1.2306,  1.3045,  1.2092,  1.2220,  1.3211,  1.3313,
          1.3058,  1.3248,  1.3248,  1.3451,  1.1837,  1.3449,  1.3526,  1.2269,
          1.3566,  1.3848,  1.3069,  1.3474,  1.4693,  1.5259,  1.4510,  1.4271,
          1.4852,  1.4972,  1.4368,  0.9119,  1.4116,  1.2272,  1.3904,  1.3762,
          1.3610,  1.1937,  1.3840,  1.1827,  1.3517,  1.3655],
        [ 1.2149,  1.2424,  1.2987,  1.2776,  1.2481,  1.2199,  1.2280,  1.2128,
          1.2128,  1.2782,  1.2997,  1.2934,  1.3245,  1.2673,  1.3177,  1.2804,
          1.2267,  1.3001,  2.7692,  2.9200,  3.0012,  2.8430,  2.6912,  2.7394,
          2.8764,  2.6808,  2.6808,  1.2789,  1.3101,  1.2442,  1.2684,  1.2794,
          1.2556,  1.2842,  1.2519,  1.2467,  1.3839,  1.4305,  1.4106,  1.3491,
          1.3997,  1.4000,  1.3975,  1.3068,  1.2757,  1.3315,  1.2914,  1.2785,
          1.2636,  1.3214,  1.2851,  1.3641,  1.2526,  1.2670],
        [ 1.2252,  1.2528,  1.3083,  1.2875,  1.2586,  1.2302,  1.2385,  1.2231,
          1.2231,  1.2884,  1.3091,  1.3037,  1.3340,  1.2774,  1.2812,  1.2905,
          1.2763,  1.2294,  1.2746,  1.2984,  1.3152,  1.2876,  1.2473,  1.2416,
          1.2621,  1.2354,  1.2354,  3.0166,  2.9854,  2.6126,  2.7782,  3.0143,
          2.6225,  2.9708,  2.6222,  2.6148,  1.3931,  1.4399,  1.4200,  1.4026,
          1.4097,  1.4100,  1.4063,  1.2769,  1.3295,  1.3487,  1.3015,  1.1963,
          1.2272,  1.3448,  1.2946,  1.3809,  1.2168,  1.2773],
        [ 1.8550,  1.4706,  0.6416,  0.9029,  1.2890,  1.7408,  1.6540,  1.8542,
          1.8542,  1.7394,  1.3456,  1.5429,  0.9445,  1.8136,  0.2297,  1.6831,
          1.8915,  0.9867,  1.3535,  0.9466,  0.7540,  1.1663,  1.6914,  1.7533,
          1.4977,  1.8639,  1.8639,  0.8167,  0.8774,  1.8371,  1.6137,  0.8728,
          1.7687,  1.2204,  1.8896,  1.7986,  0.3519,  0.1241,  0.1101,  0.2999,
          0.5449,  0.6361,  0.2416, 14.7639,  5.7759,  0.8003,  1.3807,  1.4906,
          1.7265,  1.0396,  1.6382,  0.3893,  1.8051,  1.8979],
        [ 1.2989,  1.3268,  1.3848,  1.3630,  1.3332,  1.3039,  1.2671,  1.2967,
          1.2967,  1.2662,  1.3821,  1.2815,  1.4076,  1.3495,  1.4473,  1.2684,
          1.3489,  1.3017,  1.3482,  1.3683,  1.3902,  1.3612,  1.3205,  1.3148,
          1.2405,  1.3085,  1.3085,  1.3557,  1.4003,  1.3271,  1.1247,  1.3096,
          1.2015,  1.3669,  1.1988,  1.3296,  1.4611,  1.1587,  1.4816,  1.4731,
          1.0360,  0.9559,  1.4749,  1.3979,  0.8390,  3.4430,  2.6597,  3.6539,
          2.9549,  2.2486,  1.9480,  3.0541,  3.3754,  1.9330]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 288 : 181.30133327118494
Test loss for epoch 288 : 181.41707303975795
Test Precision for epoch 288 : 0.26153846153846155
Test Recall for epoch 288 : 0.26153846153846155
Test F1 for epoch 288 : 0.26153846153846155


theta for epoch 289 : tensor([[ 2.7227,  2.7484,  2.8143,  2.9467,  2.9143,  2.7271,  2.8949,  2.7208,
          2.7208,  1.2742,  1.2959,  1.2894,  1.3209,  1.2635,  1.3608,  1.2765,
          1.2628,  1.2631,  1.2604,  1.2409,  1.2559,  1.2733,  1.2332,  1.2277,
          1.2499,  1.2214,  1.2214,  1.2688,  1.3130,  1.2402,  1.2650,  1.3153,
          1.2515,  1.2801,  1.2021,  1.2427,  1.3812,  1.4278,  1.4086,  1.3931,
          1.3977,  1.3457,  1.3948,  1.3187,  1.3204,  1.3343,  1.2877,  1.2749,
          1.2601,  1.3305,  1.2815,  1.3663,  1.2511,  1.2635],
        [ 1.2699,  1.2318,  1.1591,  1.2789,  1.3429,  1.3186,  1.2651,  1.3114,
          1.3114,  1.9288,  2.0421,  1.8872,  2.3830,  1.9426,  5.6726,  1.9837,
          1.8591,  5.4712,  1.2341,  1.3070,  1.2143,  1.2228,  1.3211,  1.3300,
          1.3047,  1.3235,  1.3235,  1.3457,  1.1848,  1.3434,  1.3525,  1.2302,
          1.3551,  1.3833,  1.3053,  1.3459,  1.4688,  1.5249,  1.4500,  1.4268,
          1.4850,  1.4963,  1.4358,  0.9215,  1.4104,  1.2309,  1.3889,  1.3746,
          1.3595,  1.1962,  1.3825,  1.1900,  1.3502,  1.3640],
        [ 1.2144,  1.2420,  1.2981,  1.2771,  1.2476,  1.2194,  1.2275,  1.2123,
          1.2123,  1.2778,  1.2996,  1.2931,  1.3246,  1.2670,  1.3180,  1.2801,
          1.2260,  1.3013,  2.7703,  2.9219,  3.0015,  2.8423,  2.6936,  2.7401,
          2.8786,  2.6832,  2.6832,  1.2784,  1.3103,  1.2440,  1.2682,  1.2789,
          1.2554,  1.2840,  1.2517,  1.2465,  1.3841,  1.4308,  1.4109,  1.3490,
          1.3999,  1.4003,  1.3978,  1.3068,  1.2755,  1.3316,  1.2911,  1.2782,
          1.2634,  1.3219,  1.2848,  1.3642,  1.2522,  1.2668],
        [ 1.2249,  1.2525,  1.3080,  1.2873,  1.2583,  1.2299,  1.2383,  1.2228,
          1.2228,  1.2882,  1.3092,  1.3035,  1.3343,  1.2774,  1.2816,  1.2905,
          1.2761,  1.2301,  1.2747,  1.2984,  1.3154,  1.2877,  1.2473,  1.2417,
          1.2622,  1.2355,  1.2355,  3.0177,  2.9872,  2.6138,  2.7796,  3.0154,
          2.6237,  2.9718,  2.6234,  2.6160,  1.3935,  1.4404,  1.4204,  1.4029,
          1.4101,  1.4104,  1.4067,  1.2761,  1.3298,  1.3485,  1.3014,  1.1963,
          1.2271,  1.3447,  1.2945,  1.3808,  1.2166,  1.2772],
        [ 1.8555,  1.4691,  0.6402,  0.9029,  1.2892,  1.7415,  1.6534,  1.8549,
          1.8549,  1.7400,  1.3443,  1.5432,  0.9423,  1.8133,  0.2261,  1.6824,
          1.8924,  0.9810,  1.3511,  0.9459,  0.7518,  1.1657,  1.6914,  1.7540,
          1.4988,  1.8649,  1.8649,  0.8169,  0.8770,  1.8380,  1.6138,  0.8715,
          1.7696,  1.2212,  1.8905,  1.7995,  0.3497,  0.1221,  0.1080,  0.2978,
          0.5424,  0.6332,  0.2394, 14.8169,  5.7370,  0.7989,  1.3816,  1.4915,
          1.7274,  1.0381,  1.6391,  0.3867,  1.8063,  1.8987],
        [ 1.2985,  1.3264,  1.3844,  1.3626,  1.3327,  1.3035,  1.2667,  1.2963,
          1.2963,  1.2659,  1.3822,  1.2812,  1.4079,  1.3494,  1.4475,  1.2683,
          1.3486,  1.3021,  1.3482,  1.3680,  1.3902,  1.3613,  1.3205,  1.3149,
          1.2402,  1.3085,  1.3085,  1.3556,  1.4002,  1.3269,  1.1243,  1.3095,
          1.2013,  1.3667,  1.1987,  1.3295,  1.4613,  1.1588,  1.4816,  1.4734,
          1.0359,  0.9558,  1.4752,  1.3968,  0.8387,  3.4458,  2.6603,  3.6570,
          2.9558,  2.2490,  1.9483,  3.0551,  3.3782,  1.9333]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 289 : 181.29040511262542
Test loss for epoch 289 : 181.4081979874681
Test Precision for epoch 289 : 0.26153846153846155
Test Recall for epoch 289 : 0.26153846153846155
Test F1 for epoch 289 : 0.26153846153846155


theta for epoch 290 : tensor([[ 2.7244,  2.7501,  2.8160,  2.9487,  2.9163,  2.7289,  2.8969,  2.7225,
          2.7225,  1.2737,  1.2957,  1.2890,  1.3209,  1.2631,  1.3608,  1.2762,
          1.2623,  1.2634,  1.2599,  1.2404,  1.2553,  1.2728,  1.2326,  1.2272,
          1.2494,  1.2208,  1.2208,  1.2685,  1.3127,  1.2399,  1.2647,  1.3150,
          1.2513,  1.2798,  1.2018,  1.2424,  1.3813,  1.4280,  1.4089,  1.3932,
          1.3979,  1.3459,  1.3950,  1.3175,  1.3204,  1.3336,  1.2870,  1.2742,
          1.2594,  1.3298,  1.2808,  1.3657,  1.2504,  1.2628],
        [ 1.2692,  1.2338,  1.1629,  1.2797,  1.3428,  1.3177,  1.2657,  1.3104,
          1.3104,  1.9373,  2.0465,  1.8948,  2.3811,  1.9498,  5.6608,  1.9905,
          1.8675,  5.4589,  1.2372,  1.3091,  1.2191,  1.2233,  1.3208,  1.3284,
          1.3032,  1.3218,  1.3218,  1.3463,  1.1859,  1.3420,  1.3524,  1.2336,
          1.3537,  1.3819,  1.3039,  1.3444,  1.4683,  1.5239,  1.4490,  1.4265,
          1.4848,  1.4953,  1.4347,  0.9310,  1.4093,  1.2341,  1.3871,  1.3729,
          1.3577,  1.1983,  1.3807,  1.1969,  1.3484,  1.3622],
        [ 1.2149,  1.2424,  1.2985,  1.2775,  1.2480,  1.2198,  1.2279,  1.2128,
          1.2128,  1.2777,  1.2998,  1.2930,  1.3250,  1.2670,  1.3186,  1.2801,
          1.2257,  1.3027,  2.7708,  2.9233,  3.0013,  2.8411,  2.6954,  2.7404,
          2.8802,  2.6851,  2.6851,  1.2782,  1.3107,  1.2440,  1.2682,  1.2787,
          1.2554,  1.2840,  1.2517,  1.2465,  1.3844,  1.4313,  1.4112,  1.3490,
          1.4002,  1.4007,  1.3981,  1.3068,  1.2755,  1.3316,  1.2908,  1.2779,
          1.2631,  1.3224,  1.2845,  1.3642,  1.2518,  1.2665],
        [ 1.2253,  1.2529,  1.3083,  1.2876,  1.2587,  1.2303,  1.2387,  1.2232,
          1.2232,  1.2881,  1.3094,  1.3034,  1.3347,  1.2773,  1.2820,  1.2905,
          1.2760,  1.2309,  1.2746,  1.2981,  1.3152,  1.2876,  1.2471,  1.2415,
          1.2619,  1.2353,  1.2353,  3.0187,  2.9888,  2.6149,  2.7808,  3.0164,
          2.6248,  2.9727,  2.6244,  2.6170,  1.3938,  1.4408,  1.4209,  1.4033,
          1.4105,  1.4109,  1.4072,  1.2753,  1.3301,  1.3482,  1.3011,  1.1960,
          1.2268,  1.3444,  1.2943,  1.3804,  1.2162,  1.2769],
        [ 1.8566,  1.4683,  0.6395,  0.9034,  1.2902,  1.7428,  1.6535,  1.8561,
          1.8561,  1.7405,  1.3430,  1.5435,  0.9403,  1.8129,  0.2228,  1.6817,
          1.8933,  0.9757,  1.3485,  0.9451,  0.7495,  1.1650,  1.6910,  1.7545,
          1.4996,  1.8656,  1.8656,  0.8172,  0.8767,  1.8389,  1.6140,  0.8703,
          1.7705,  1.2222,  1.8915,  1.8004,  0.3476,  0.1200,  0.1059,  0.2957,
          0.5399,  0.6301,  0.2372, 14.8703,  5.6975,  0.7974,  1.3822,  1.4920,
          1.7280,  1.0365,  1.6396,  0.3842,  1.8073,  1.8993],
        [ 1.2990,  1.3269,  1.3849,  1.3631,  1.3332,  1.3040,  1.2672,  1.2968,
          1.2968,  1.2658,  1.3824,  1.2812,  1.4083,  1.3494,  1.4480,  1.2684,
          1.3485,  1.3029,  1.3482,  1.3676,  1.3901,  1.3612,  1.3204,  1.3148,
          1.2397,  1.3083,  1.3083,  1.3557,  1.4003,  1.3270,  1.1242,  1.3096,
          1.2015,  1.3669,  1.1988,  1.3296,  1.4616,  1.1591,  1.4817,  1.4738,
          1.0358,  0.9558,  1.4756,  1.3958,  0.8386,  3.4480,  2.6603,  3.6595,
          2.9561,  2.2488,  1.9480,  3.0555,  3.3805,  1.9331]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 290 : 181.27922841716736
Test loss for epoch 290 : 181.39942341822007
Test Precision for epoch 290 : 0.26153846153846155
Test Recall for epoch 290 : 0.26153846153846155
Test F1 for epoch 290 : 0.26153846153846155


theta for epoch 291 : tensor([[ 2.7250,  2.7507,  2.8166,  2.9495,  2.9171,  2.7294,  2.8977,  2.7231,
          2.7231,  1.2738,  1.2962,  1.2891,  1.3215,  1.2633,  1.3614,  1.2764,
          1.2624,  1.2642,  1.2602,  1.2407,  1.2556,  1.2731,  1.2329,  1.2275,
          1.2496,  1.2211,  1.2211,  1.2687,  1.3130,  1.2402,  1.2650,  1.3153,
          1.2515,  1.2801,  1.2020,  1.2427,  1.3819,  1.4286,  1.4095,  1.3938,
          1.3985,  1.3465,  1.3956,  1.3167,  1.3209,  1.3339,  1.2873,  1.2745,
          1.2597,  1.3301,  1.2811,  1.3659,  1.2506,  1.2631],
        [ 1.2675,  1.2349,  1.1657,  1.2795,  1.3416,  1.3158,  1.2654,  1.3086,
          1.3086,  1.9460,  2.0509,  1.9026,  2.3792,  1.9573,  5.6483,  1.9974,
          1.8761,  5.4460,  1.2405,  1.3114,  1.2240,  1.2241,  1.3207,  1.3271,
          1.3021,  1.3205,  1.3205,  1.3469,  1.1869,  1.3406,  1.3524,  1.2370,
          1.3523,  1.3805,  1.3025,  1.3430,  1.4678,  1.5229,  1.4480,  1.4263,
          1.4845,  1.4944,  1.4337,  0.9404,  1.4082,  1.2376,  1.3859,  1.3716,
          1.3565,  1.2006,  1.3794,  1.2038,  1.3471,  1.3609],
        [ 1.2143,  1.2418,  1.2979,  1.2769,  1.2474,  1.2192,  1.2274,  1.2122,
          1.2122,  1.2774,  1.2998,  1.2928,  1.3252,  1.2668,  1.3190,  1.2800,
          1.2252,  1.3039,  2.7716,  2.9251,  3.0015,  2.8402,  2.6977,  2.7410,
          2.8823,  2.6873,  2.6873,  1.2778,  1.3110,  1.2439,  1.2680,  1.2784,
          1.2553,  1.2839,  1.2516,  1.2464,  1.3847,  1.4316,  1.4115,  1.3489,
          1.4005,  1.4009,  1.3984,  1.3067,  1.2753,  1.3318,  1.2908,  1.2779,
          1.2630,  1.3230,  1.2845,  1.3645,  1.2517,  1.2664],
        [ 1.2250,  1.2526,  1.3079,  1.2873,  1.2584,  1.2299,  1.2383,  1.2228,
          1.2228,  1.2880,  1.3097,  1.3034,  1.3351,  1.2774,  1.2825,  1.2906,
          1.2759,  1.2317,  1.2747,  1.2981,  1.3153,  1.2877,  1.2472,  1.2417,
          1.2619,  1.2353,  1.2353,  3.0197,  2.9904,  2.6159,  2.7820,  3.0174,
          2.6259,  2.9736,  2.6255,  2.6181,  1.3943,  1.4413,  1.4214,  1.4037,
          1.4109,  1.4114,  1.4077,  1.2746,  1.3304,  1.3482,  1.3012,  1.1962,
          1.2268,  1.3445,  1.2944,  1.3805,  1.2162,  1.2770],
        [ 1.8569,  1.4666,  0.6382,  0.9033,  1.2903,  1.7433,  1.6527,  1.8566,
          1.8566,  1.7410,  1.3419,  1.5438,  0.9384,  1.8125,  0.2196,  1.6809,
          1.8943,  0.9707,  1.3462,  0.9447,  0.7475,  1.1645,  1.6909,  1.7551,
          1.5007,  1.8665,  1.8665,  0.8175,  0.8765,  1.8398,  1.6142,  0.8692,
          1.7714,  1.2230,  1.8924,  1.8013,  0.3455,  0.1181,  0.1038,  0.2937,
          0.5374,  0.6272,  0.2351, 14.9243,  5.6574,  0.7964,  1.3832,  1.4929,
          1.7289,  1.0354,  1.6406,  0.3821,  1.8086,  1.9002],
        [ 1.2984,  1.3263,  1.3843,  1.3625,  1.3326,  1.3033,  1.2665,  1.2962,
          1.2962,  1.2656,  1.3824,  1.2810,  1.4086,  1.3492,  1.4482,  1.2683,
          1.3482,  1.3033,  1.3481,  1.3672,  1.3901,  1.3612,  1.3203,  1.3147,
          1.2393,  1.3082,  1.3082,  1.3556,  1.4002,  1.3269,  1.1237,  1.3096,
          1.2014,  1.3668,  1.1987,  1.3295,  1.4618,  1.1592,  1.4817,  1.4740,
          1.0355,  0.9556,  1.4759,  1.3946,  0.8382,  3.4509,  2.6610,  3.6627,
          2.9572,  2.2493,  1.9485,  3.0565,  3.3834,  1.9335]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 291 : 181.2678169768394
Test loss for epoch 291 : 181.3901100746371
Test Precision for epoch 291 : 0.26153846153846155
Test Recall for epoch 291 : 0.26153846153846155
Test F1 for epoch 291 : 0.26153846153846155


theta for epoch 292 : tensor([[ 2.7263,  2.7520,  2.8179,  2.9511,  2.9187,  2.7307,  2.8993,  2.7244,
          2.7244,  1.2735,  1.2962,  1.2889,  1.3217,  1.2631,  1.3616,  1.2763,
          1.2621,  1.2647,  1.2600,  1.2404,  1.2554,  1.2729,  1.2326,  1.2273,
          1.2493,  1.2208,  1.2208,  1.2686,  1.3128,  1.2400,  1.2649,  1.3152,
          1.2514,  1.2799,  1.2019,  1.2426,  1.3822,  1.4291,  1.4100,  1.3941,
          1.3989,  1.3470,  1.3960,  1.3157,  1.3212,  1.3334,  1.2869,  1.2740,
          1.2593,  1.3297,  1.2806,  1.3654,  1.2501,  1.2627],
        [ 1.2666,  1.2367,  1.1689,  1.2799,  1.3411,  1.3146,  1.2658,  1.3074,
          1.3074,  1.9549,  2.0554,  1.9105,  2.3773,  1.9648,  5.6351,  2.0044,
          1.8849,  5.4324,  1.2434,  1.3133,  1.2285,  1.2247,  1.3205,  1.3256,
          1.3009,  1.3190,  1.3190,  1.3474,  1.1878,  1.3391,  1.3523,  1.2403,
          1.3508,  1.3792,  1.3011,  1.3416,  1.4673,  1.5221,  1.4471,  1.4261,
          1.4843,  1.4936,  1.4327,  0.9498,  1.4072,  1.2406,  1.3842,  1.3700,
          1.3549,  1.2025,  1.3778,  1.2101,  1.3455,  1.3593],
        [ 1.2144,  1.2419,  1.2979,  1.2770,  1.2475,  1.2193,  1.2275,  1.2123,
          1.2123,  1.2772,  1.2999,  1.2926,  1.3255,  1.2667,  1.3194,  1.2800,
          1.2247,  1.3051,  2.7723,  2.9267,  3.0014,  2.8391,  2.6996,  2.7414,
          2.8840,  2.6893,  2.6893,  1.2775,  1.3113,  1.2438,  1.2679,  1.2780,
          1.2552,  1.2839,  1.2515,  1.2463,  1.3850,  1.4321,  1.4120,  1.3490,
          1.4009,  1.4014,  1.3989,  1.3067,  1.2753,  1.3317,  1.2904,  1.2775,
          1.2627,  1.3234,  1.2842,  1.3644,  1.2512,  1.2661],
        [ 1.2251,  1.2527,  1.3080,  1.2875,  1.2585,  1.2301,  1.2385,  1.2230,
          1.2230,  1.2879,  1.3099,  1.3033,  1.3355,  1.2774,  1.2829,  1.2906,
          1.2757,  1.2324,  1.2746,  1.2979,  1.3152,  1.2876,  1.2471,  1.2416,
          1.2617,  1.2352,  1.2352,  3.0206,  2.9919,  2.6170,  2.7832,  3.0184,
          2.6269,  2.9744,  2.6266,  2.6191,  1.3947,  1.4419,  1.4220,  1.4041,
          1.4115,  1.4119,  1.4082,  1.2739,  1.3308,  1.3479,  1.3009,  1.1960,
          1.2266,  1.3442,  1.2942,  1.3802,  1.2158,  1.2768],
        [ 1.8575,  1.4654,  0.6372,  0.9035,  1.2909,  1.7442,  1.6524,  1.8576,
          1.8576,  1.7413,  1.3406,  1.5439,  0.9365,  1.8119,  0.2164,  1.6800,
          1.8951,  0.9658,  1.3439,  0.9440,  0.7454,  1.1637,  1.6905,  1.7556,
          1.5014,  1.8672,  1.8672,  0.8177,  0.8761,  1.8406,  1.6142,  0.8680,
          1.7721,  1.2237,  1.8931,  1.8020,  0.3435,  0.1163,  0.1019,  0.2918,
          0.5351,  0.6244,  0.2332, 14.9787,  5.6168,  0.7950,  1.3837,  1.4933,
          1.7294,  1.0338,  1.6410,  0.3798,  1.8095,  1.9007],
        [ 1.2987,  1.3266,  1.3846,  1.3628,  1.3329,  1.3037,  1.2669,  1.2965,
          1.2965,  1.2656,  1.3828,  1.2811,  1.4091,  1.3494,  1.4487,  1.2685,
          1.3483,  1.3042,  1.3483,  1.3669,  1.3902,  1.3614,  1.3204,  1.3149,
          1.2391,  1.3083,  1.3083,  1.3558,  1.4003,  1.3271,  1.1236,  1.3098,
          1.2016,  1.3670,  1.1989,  1.3297,  1.4624,  1.1597,  1.4819,  1.4745,
          1.0357,  0.9559,  1.4765,  1.3938,  0.8383,  3.4529,  2.6608,  3.6649,
          2.9572,  2.2489,  1.9480,  3.0566,  3.3854,  1.9330]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 292 : 181.25619985998276
Test loss for epoch 292 : 181.38129551008916
Test Precision for epoch 292 : 0.26153846153846155
Test Recall for epoch 292 : 0.26153846153846155
Test F1 for epoch 292 : 0.26153846153846155


theta for epoch 293 : tensor([[ 2.7272,  2.7529,  2.8188,  2.9523,  2.9198,  2.7316,  2.9004,  2.7253,
          2.7253,  1.2734,  1.2963,  1.2888,  1.3221,  1.2631,  1.3619,  1.2763,
          1.2619,  1.2652,  1.2599,  1.2403,  1.2553,  1.2728,  1.2325,  1.2272,
          1.2492,  1.2207,  1.2207,  1.2685,  1.3128,  1.2400,  1.2649,  1.3151,
          1.2514,  1.2799,  1.2019,  1.2426,  1.3826,  1.4295,  1.4104,  1.3945,
          1.3993,  1.3475,  1.3965,  1.3148,  1.3216,  1.3335,  1.2870,  1.2742,
          1.2594,  1.3298,  1.2808,  1.3656,  1.2503,  1.2628],
        [ 1.2656,  1.2384,  1.1718,  1.2801,  1.3403,  1.3133,  1.2661,  1.3061,
          1.3061,  1.9638,  2.0600,  1.9185,  2.3755,  1.9725,  5.6213,  2.0115,
          1.8938,  5.4182,  1.2460,  1.3150,  1.2327,  1.2251,  1.3202,  1.3242,
          1.2996,  1.3175,  1.3175,  1.3479,  1.1884,  1.3377,  1.3521,  1.2435,
          1.3494,  1.3777,  1.2996,  1.3402,  1.4667,  1.5211,  1.4461,  1.4259,
          1.4839,  1.4926,  1.4317,  0.9588,  1.4061,  1.2438,  1.3830,  1.3688,
          1.3537,  1.2046,  1.3766,  1.2163,  1.3443,  1.3581],
        [ 1.2144,  1.2420,  1.2978,  1.2771,  1.2475,  1.2194,  1.2275,  1.2123,
          1.2123,  1.2770,  1.3000,  1.2924,  1.3258,  1.2666,  1.3198,  1.2799,
          1.2243,  1.3062,  2.7728,  2.9282,  3.0012,  2.8379,  2.7015,  2.7418,
          2.8857,  2.6912,  2.6912,  1.2771,  1.3115,  1.2437,  1.2678,  1.2777,
          1.2551,  1.2838,  1.2514,  1.2462,  1.3853,  1.4324,  1.4123,  1.3490,
          1.4011,  1.4017,  1.3992,  1.3065,  1.2751,  1.3321,  1.2906,  1.2777,
          1.2628,  1.3241,  1.2843,  1.3648,  1.2512,  1.2663],
        [ 1.2252,  1.2528,  1.3080,  1.2875,  1.2585,  1.2301,  1.2385,  1.2230,
          1.2230,  1.2877,  1.3100,  1.3031,  1.3358,  1.2773,  1.2832,  1.2905,
          1.2755,  1.2331,  1.2745,  1.2977,  1.3150,  1.2875,  1.2469,  1.2414,
          1.2615,  1.2350,  1.2350,  3.0216,  2.9934,  2.6180,  2.7844,  3.0194,
          2.6279,  2.9753,  2.6276,  2.6202,  1.3951,  1.4423,  1.4225,  1.4044,
          1.4119,  1.4123,  1.4086,  1.2731,  1.3310,  1.3480,  1.3010,  1.1962,
          1.2266,  1.3442,  1.2943,  1.3802,  1.2158,  1.2768],
        [ 1.8582,  1.4643,  0.6366,  0.9038,  1.2916,  1.7451,  1.6521,  1.8585,
          1.8585,  1.7417,  1.3395,  1.5441,  0.9349,  1.8114,  0.2136,  1.6791,
          1.8959,  0.9613,  1.3419,  0.9437,  0.7437,  1.1632,  1.6903,  1.7561,
          1.5024,  1.8679,  1.8679,  0.8180,  0.8759,  1.8414,  1.6144,  0.8670,
          1.7729,  1.2245,  1.8939,  1.8028,  0.3414,  0.1143,  0.0999,  0.2898,
          0.5326,  0.6215,  0.2311, 15.0335,  5.5754,  0.7942,  1.3847,  1.4943,
          1.7303,  1.0329,  1.6420,  0.3783,  1.8109,  1.9016],
        [ 1.2986,  1.3265,  1.3845,  1.3627,  1.3328,  1.3035,  1.2668,  1.2964,
          1.2964,  1.2653,  1.3827,  1.2807,  1.4092,  1.3491,  1.4488,  1.2683,
          1.3478,  1.3045,  1.3479,  1.3662,  1.3899,  1.3610,  1.3200,  1.3145,
          1.2383,  1.3079,  1.3079,  1.3556,  1.4001,  1.3269,  1.1231,  1.3095,
          1.2013,  1.3667,  1.1986,  1.3295,  1.4625,  1.1598,  1.4818,  1.4747,
          1.0354,  0.9556,  1.4767,  1.3926,  0.8378,  3.4557,  2.6615,  3.6679,
          2.9582,  2.2494,  1.9484,  3.0576,  3.3883,  1.9334]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 293 : 181.24438763543856
Test loss for epoch 293 : 181.3716847386866
Test Precision for epoch 293 : 0.26153846153846155
Test Recall for epoch 293 : 0.26153846153846155
Test F1 for epoch 293 : 0.26153846153846155


theta for epoch 294 : tensor([[ 2.7278,  2.7536,  2.8195,  2.9532,  2.9208,  2.7323,  2.9014,  2.7259,
          2.7259,  1.2735,  1.2966,  1.2889,  1.3226,  1.2633,  1.3624,  1.2765,
          1.2619,  1.2659,  1.2603,  1.2406,  1.2556,  1.2732,  1.2328,  1.2275,
          1.2495,  1.2210,  1.2210,  1.2687,  1.3129,  1.2403,  1.2651,  1.3153,
          1.2516,  1.2802,  1.2021,  1.2428,  1.3831,  1.4301,  1.4110,  1.3950,
          1.3998,  1.3481,  1.3970,  1.3139,  1.3220,  1.3333,  1.2868,  1.2739,
          1.2592,  1.3296,  1.2806,  1.3653,  1.2500,  1.2626],
        [ 1.2645,  1.2398,  1.1744,  1.2800,  1.3394,  1.3119,  1.2662,  1.3047,
          1.3047,  1.9730,  2.0647,  1.9267,  2.3739,  1.9803,  5.6070,  2.0187,
          1.9029,  5.4034,  1.2488,  1.3166,  1.2370,  1.2259,  1.3202,  1.3230,
          1.2986,  1.3163,  1.3163,  1.3483,  1.1890,  1.3363,  1.3520,  1.2465,
          1.3480,  1.3764,  1.2983,  1.3388,  1.4661,  1.5201,  1.4451,  1.4257,
          1.4835,  1.4917,  1.4307,  0.9675,  1.4050,  1.2462,  1.3813,  1.3672,
          1.3520,  1.2061,  1.3749,  1.2216,  1.3426,  1.3564],
        [ 1.2142,  1.2417,  1.2975,  1.2768,  1.2473,  1.2191,  1.2273,  1.2120,
          1.2120,  1.2767,  1.3000,  1.2921,  1.3260,  1.2664,  1.3200,  1.2798,
          1.2237,  1.3072,  2.7737,  2.9300,  3.0014,  2.8371,  2.7038,  2.7424,
          2.8877,  2.6934,  2.6934,  1.2767,  1.3117,  1.2436,  1.2677,  1.2773,
          1.2550,  1.2836,  1.2513,  1.2461,  1.3855,  1.4327,  1.4126,  1.3489,
          1.4014,  1.4019,  1.3995,  1.3062,  1.2750,  1.3317,  1.2900,  1.2771,
          1.2623,  1.3241,  1.2838,  1.3645,  1.2505,  1.2657],
        [ 1.2251,  1.2527,  1.3078,  1.2875,  1.2584,  1.2300,  1.2384,  1.2229,
          1.2229,  1.2876,  1.3102,  1.3030,  1.3361,  1.2772,  1.2836,  1.2905,
          1.2753,  1.2337,  1.2747,  1.2977,  1.3152,  1.2877,  1.2470,  1.2416,
          1.2615,  1.2351,  1.2351,  3.0226,  2.9950,  2.6190,  2.7855,  3.0204,
          2.6290,  2.9762,  2.6286,  2.6212,  1.3955,  1.4428,  1.4229,  1.4047,
          1.4123,  1.4128,  1.4090,  1.2723,  1.3313,  1.3476,  1.3007,  1.1959,
          1.2262,  1.3439,  1.2940,  1.3799,  1.2153,  1.2765],
        [ 1.8586,  1.4629,  0.6357,  0.9040,  1.2921,  1.7458,  1.6515,  1.8591,
          1.8591,  1.7419,  1.3384,  1.5441,  0.9334,  1.8108,  0.2109,  1.6782,
          1.8967,  0.9571,  1.3401,  0.9436,  0.7421,  1.1628,  1.6902,  1.7567,
          1.5034,  1.8687,  1.8687,  0.8183,  0.8757,  1.8422,  1.6146,  0.8661,
          1.7737,  1.2252,  1.8947,  1.8036,  0.3395,  0.1126,  0.0980,  0.2880,
          0.5303,  0.6187,  0.2292, 15.0888,  5.5335,  0.7930,  1.3851,  1.4946,
          1.7307,  1.0316,  1.6423,  0.3764,  1.8118,  1.9020],
        [ 1.2986,  1.3266,  1.3845,  1.3627,  1.3328,  1.3036,  1.2668,  1.2964,
          1.2964,  1.2653,  1.3831,  1.2809,  1.4098,  1.3493,  1.4494,  1.2685,
          1.3479,  1.3052,  1.3484,  1.3662,  1.3903,  1.3615,  1.3204,  1.3150,
          1.2383,  1.3083,  1.3083,  1.3557,  1.4003,  1.3271,  1.1229,  1.3097,
          1.2015,  1.3669,  1.1988,  1.3296,  1.4629,  1.1601,  1.4819,  1.4751,
          1.0354,  0.9557,  1.4772,  1.3916,  0.8377,  3.4578,  2.6613,  3.6701,
          2.9583,  2.2490,  1.9480,  3.0577,  3.3903,  1.9330]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 294 : 181.23238405780927
Test loss for epoch 294 : 181.36252718179304
Test Precision for epoch 294 : 0.26153846153846155
Test Recall for epoch 294 : 0.26153846153846155
Test F1 for epoch 294 : 0.26153846153846155


theta for epoch 295 : tensor([[ 2.7291,  2.7548,  2.8208,  2.9547,  2.9223,  2.7335,  2.9029,  2.7272,
          2.7272,  1.2731,  1.2965,  1.2885,  1.3227,  1.2630,  1.3624,  1.2763,
          1.2615,  1.2662,  1.2598,  1.2400,  1.2551,  1.2727,  1.2323,  1.2270,
          1.2490,  1.2205,  1.2205,  1.2685,  1.3127,  1.2401,  1.2649,  1.3151,
          1.2514,  1.2800,  1.2019,  1.2426,  1.3833,  1.4304,  1.4114,  1.3953,
          1.4002,  1.3485,  1.3973,  1.3129,  1.3223,  1.3331,  1.2867,  1.2739,
          1.2591,  1.3295,  1.2805,  1.3652,  1.2499,  1.2626],
        [ 1.2639,  1.2417,  1.1771,  1.2802,  1.3388,  1.3109,  1.2667,  1.3037,
          1.3037,  1.9821,  2.0694,  1.9348,  2.3721,  1.9880,  5.5919,  2.0258,
          1.9120,  5.3878,  1.2509,  1.3177,  1.2406,  1.2262,  1.3197,  1.3215,
          1.2973,  1.3148,  1.3148,  1.3488,  1.1896,  1.3350,  1.3519,  1.2495,
          1.3467,  1.3751,  1.2970,  1.3375,  1.4656,  1.5192,  1.4442,  1.4256,
          1.4831,  1.4909,  1.4298,  0.9761,  1.4040,  1.2491,  1.3803,  1.3661,
          1.3510,  1.2080,  1.3739,  1.2270,  1.3415,  1.3554],
        [ 1.2146,  1.2421,  1.2978,  1.2772,  1.2477,  1.2195,  1.2276,  1.2124,
          1.2124,  1.2767,  1.3002,  1.2922,  1.3264,  1.2665,  1.3205,  1.2799,
          1.2235,  1.3084,  2.7738,  2.9311,  3.0008,  2.8355,  2.7052,  2.7423,
          2.8890,  2.6948,  2.6948,  1.2765,  1.3121,  1.2437,  1.2677,  1.2771,
          1.2551,  1.2838,  1.2513,  1.2462,  1.3860,  1.4333,  1.4131,  1.3490,
          1.4018,  1.4024,  1.4000,  1.3061,  1.2750,  1.3323,  1.2904,  1.2775,
          1.2627,  1.3250,  1.2842,  1.3651,  1.2507,  1.2661],
        [ 1.2253,  1.2529,  1.3080,  1.2877,  1.2587,  1.2302,  1.2387,  1.2232,
          1.2232,  1.2874,  1.3104,  1.3029,  1.3365,  1.2772,  1.2840,  1.2906,
          1.2752,  1.2344,  1.2744,  1.2973,  1.3149,  1.2874,  1.2468,  1.2414,
          1.2612,  1.2349,  1.2349,  3.0234,  2.9963,  2.6199,  2.7865,  3.0212,
          2.6298,  2.9769,  2.6295,  2.6221,  1.3959,  1.4433,  1.4234,  1.4050,
          1.4128,  1.4133,  1.4095,  1.2716,  1.3316,  1.3477,  1.3008,  1.1962,
          1.2264,  1.3440,  1.2941,  1.3800,  1.2153,  1.2766],
        [ 1.8591,  1.4618,  0.6351,  0.9044,  1.2928,  1.7466,  1.6512,  1.8600,
          1.8600,  1.7421,  1.3373,  1.5441,  0.9318,  1.8101,  0.2083,  1.6771,
          1.8974,  0.9531,  1.3382,  0.9433,  0.7404,  1.1620,  1.6897,  1.7569,
          1.5041,  1.8691,  1.8691,  0.8185,  0.8754,  1.8428,  1.6147,  0.8652,
          1.7744,  1.2258,  1.8954,  1.8042,  0.3376,  0.1109,  0.0962,  0.2862,
          0.5280,  0.6161,  0.2273, 15.1445,  5.4910,  0.7922,  1.3860,  1.4953,
          1.7315,  1.0306,  1.6431,  0.3750,  1.8130,  1.9028],
        [ 1.2986,  1.3266,  1.3845,  1.3627,  1.3329,  1.3036,  1.2669,  1.2965,
          1.2965,  1.2650,  1.3830,  1.2805,  1.4099,  1.3490,  1.4494,  1.2683,
          1.3474,  1.3055,  1.3478,  1.3652,  1.3898,  1.3610,  1.3198,  1.3144,
          1.2373,  1.3077,  1.3077,  1.3555,  1.4001,  1.3269,  1.1224,  1.3096,
          1.2014,  1.3668,  1.1987,  1.3295,  1.4631,  1.1602,  1.4818,  1.4754,
          1.0351,  0.9555,  1.4775,  1.3905,  0.8374,  3.4605,  2.6618,  3.6730,
          2.9591,  2.2494,  1.9483,  3.0586,  3.3931,  1.9333]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 295 : 181.22017006506806
Test loss for epoch 295 : 181.35282128550767
Test Precision for epoch 295 : 0.26153846153846155
Test Recall for epoch 295 : 0.26153846153846155
Test F1 for epoch 295 : 0.26153846153846155


theta for epoch 296 : tensor([[ 2.7296,  2.7553,  2.8213,  2.9555,  2.9231,  2.7340,  2.9037,  2.7277,
          2.7277,  1.2732,  1.2969,  1.2886,  1.3232,  1.2632,  1.3629,  1.2766,
          1.2616,  1.2669,  1.2603,  1.2405,  1.2555,  1.2732,  1.2327,  1.2275,
          1.2495,  1.2209,  1.2209,  1.2687,  1.3129,  1.2403,  1.2651,  1.3154,
          1.2516,  1.2802,  1.2021,  1.2428,  1.3838,  1.4309,  1.4119,  1.3957,
          1.4007,  1.3490,  1.3978,  1.3121,  1.3227,  1.3330,  1.2866,  1.2737,
          1.2590,  1.3293,  1.2804,  1.3650,  1.2497,  1.2624],
        [ 1.2628,  1.2430,  1.1791,  1.2798,  1.3375,  1.3094,  1.2666,  1.3021,
          1.3021,  1.9914,  2.0742,  1.9431,  2.3706,  1.9959,  5.5763,  2.0331,
          1.9212,  5.3718,  1.2533,  1.3191,  1.2446,  1.2270,  1.3197,  1.3207,
          1.2967,  1.3139,  1.3139,  1.3492,  1.1902,  1.3337,  1.3518,  1.2523,
          1.3454,  1.3740,  1.2957,  1.3363,  1.4650,  1.5183,  1.4433,  1.4255,
          1.4826,  1.4900,  1.4288,  0.9843,  1.4030,  1.2514,  1.3788,  1.3647,
          1.3495,  1.2094,  1.3724,  1.2316,  1.3400,  1.3539],
        [ 1.2140,  1.2416,  1.2971,  1.2766,  1.2471,  1.2189,  1.2271,  1.2118,
          1.2118,  1.2763,  1.3001,  1.2918,  1.3265,  1.2663,  1.3207,  1.2797,
          1.2229,  1.3092,  2.7748,  2.9331,  3.0011,  2.8348,  2.7076,  2.7431,
          2.8912,  2.6972,  2.6972,  1.2761,  1.3122,  1.2435,  1.2675,  1.2767,
          1.2549,  1.2836,  1.2512,  1.2460,  1.3861,  1.4335,  1.4133,  1.3488,
          1.4020,  1.4025,  1.4002,  1.3056,  1.2747,  1.3319,  1.2898,  1.2769,
          1.2621,  1.3249,  1.2836,  1.3647,  1.2500,  1.2655],
        [ 1.2251,  1.2527,  1.3077,  1.2875,  1.2584,  1.2300,  1.2384,  1.2229,
          1.2229,  1.2873,  1.3106,  1.3029,  1.3368,  1.2772,  1.2845,  1.2907,
          1.2751,  1.2351,  1.2748,  1.2975,  1.3152,  1.2878,  1.2471,  1.2417,
          1.2614,  1.2352,  1.2352,  3.0243,  2.9977,  2.6208,  2.7875,  3.0221,
          2.6308,  2.9776,  2.6304,  2.6230,  1.3962,  1.4437,  1.4239,  1.4053,
          1.4132,  1.4137,  1.4099,  1.2708,  1.3319,  1.3474,  1.3006,  1.1960,
          1.2261,  1.3438,  1.2939,  1.3797,  1.2149,  1.2764],
        [ 1.8592,  1.4603,  0.6343,  0.9044,  1.2931,  1.7470,  1.6504,  1.8604,
          1.8604,  1.7422,  1.3363,  1.5441,  0.9305,  1.8094,  0.2059,  1.6761,
          1.8981,  0.9495,  1.3369,  0.9436,  0.7392,  1.1618,  1.6898,  1.7577,
          1.5052,  1.8700,  1.8700,  0.8189,  0.8752,  1.8436,  1.6150,  0.8645,
          1.7751,  1.2265,  1.8961,  1.8050,  0.3358,  0.1092,  0.0944,  0.2845,
          0.5257,  0.6134,  0.2255, 15.2006,  5.4480,  0.7912,  1.3864,  1.4956,
          1.7319,  1.0294,  1.6435,  0.3735,  1.8140,  1.9032],
        [ 1.2985,  1.3264,  1.3844,  1.3626,  1.3327,  1.3035,  1.2667,  1.2963,
          1.2963,  1.2651,  1.3834,  1.2807,  1.4104,  1.3492,  1.4500,  1.2686,
          1.3475,  1.3063,  1.3485,  1.3654,  1.3904,  1.3616,  1.3204,  1.3150,
          1.2375,  1.3083,  1.3083,  1.3558,  1.4003,  1.3272,  1.1223,  1.3098,
          1.2016,  1.3670,  1.1989,  1.3297,  1.4635,  1.1606,  1.4818,  1.4757,
          1.0351,  0.9555,  1.4779,  1.3896,  0.8372,  3.4625,  2.6615,  3.6750,
          2.9591,  2.2489,  1.9478,  3.0586,  3.3951,  1.9328]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 296 : 181.20774205897396
Test loss for epoch 296 : 181.34333383251303
Test Precision for epoch 296 : 0.26153846153846155
Test Recall for epoch 296 : 0.26153846153846155
Test F1 for epoch 296 : 0.26153846153846155


theta for epoch 297 : tensor([[ 2.7307,  2.7565,  2.8225,  2.9569,  2.9245,  2.7352,  2.9050,  2.7288,
          2.7288,  1.2729,  1.2969,  1.2884,  1.3233,  1.2630,  1.3630,  1.2765,
          1.2613,  1.2672,  1.2597,  1.2399,  1.2550,  1.2727,  1.2322,  1.2270,
          1.2489,  1.2203,  1.2203,  1.2686,  1.3128,  1.2402,  1.2650,  1.3152,
          1.2515,  1.2801,  1.2020,  1.2427,  1.3840,  1.4312,  1.4122,  1.3959,
          1.4009,  1.3493,  1.3981,  1.3110,  1.3228,  1.3329,  1.2866,  1.2737,
          1.2590,  1.3293,  1.2804,  1.3650,  1.2497,  1.2624],
        [ 1.2622,  1.2448,  1.1814,  1.2799,  1.3368,  1.3084,  1.2670,  1.3012,
          1.3012,  2.0007,  2.0790,  1.9515,  2.3691,  2.0038,  5.5602,  2.0404,
          1.9306,  5.3551,  1.2547,  1.3196,  1.2475,  1.2271,  1.3190,  1.3191,
          1.2953,  1.3122,  1.3122,  1.3494,  1.1906,  1.3325,  1.3515,  1.2549,
          1.3442,  1.3727,  1.2945,  1.3350,  1.4644,  1.5174,  1.4424,  1.4254,
          1.4821,  1.4892,  1.4278,  0.9922,  1.4020,  1.2539,  1.3778,  1.3637,
          1.3486,  1.2111,  1.3714,  1.2362,  1.3390,  1.3529],
        [ 1.2143,  1.2419,  1.2974,  1.2769,  1.2474,  1.2193,  1.2274,  1.2122,
          1.2122,  1.2764,  1.3005,  1.2919,  1.3270,  1.2664,  1.3212,  1.2799,
          1.2227,  1.3103,  2.7749,  2.9341,  3.0004,  2.8332,  2.7089,  2.7430,
          2.8924,  2.6985,  2.6985,  1.2759,  1.3126,  1.2436,  1.2676,  1.2765,
          1.2550,  1.2837,  1.2513,  1.2461,  1.3864,  1.4339,  1.4137,  1.3488,
          1.4024,  1.4029,  1.4006,  1.3054,  1.2747,  1.3324,  1.2902,  1.2773,
          1.2625,  1.3258,  1.2840,  1.3652,  1.2502,  1.2659],
        [ 1.2253,  1.2529,  1.3078,  1.2877,  1.2586,  1.2302,  1.2386,  1.2231,
          1.2231,  1.2872,  1.3108,  1.3028,  1.3372,  1.2772,  1.2849,  1.2907,
          1.2749,  1.2358,  1.2744,  1.2970,  1.3148,  1.2874,  1.2467,  1.2413,
          1.2609,  1.2347,  1.2347,  3.0252,  2.9990,  2.6217,  2.7885,  3.0230,
          2.6316,  2.9784,  2.6313,  2.6239,  1.3966,  1.4441,  1.4243,  1.4056,
          1.4136,  1.4140,  1.4102,  1.2700,  1.3321,  1.3475,  1.3007,  1.1963,
          1.2262,  1.3439,  1.2941,  1.3798,  1.2149,  1.2765],
        [ 1.8597,  1.4593,  0.6340,  0.9049,  1.2939,  1.7479,  1.6502,  1.8613,
          1.8613,  1.7423,  1.3355,  1.5440,  0.9294,  1.8086,  0.2039,  1.6752,
          1.8988,  0.9462,  1.3354,  0.9436,  0.7379,  1.1612,  1.6895,  1.7579,
          1.5059,  1.8704,  1.8704,  0.8193,  0.8750,  1.8443,  1.6154,  0.8640,
          1.7758,  1.2271,  1.8968,  1.8057,  0.3339,  0.1075,  0.0925,  0.2828,
          0.5234,  0.6108,  0.2237, 15.2571,  5.4042,  0.7907,  1.3873,  1.4964,
          1.7327,  1.0287,  1.6443,  0.3725,  1.8153,  1.9040],
        [ 1.2985,  1.3265,  1.3844,  1.3626,  1.3328,  1.3035,  1.2668,  1.2963,
          1.2963,  1.2649,  1.3834,  1.2805,  1.4106,  1.3491,  1.4501,  1.2685,
          1.3472,  1.3066,  1.3478,  1.3643,  1.3898,  1.3610,  1.3197,  1.3144,
          1.2364,  1.3076,  1.3076,  1.3557,  1.4002,  1.3270,  1.1217,  1.3097,
          1.2015,  1.3669,  1.1988,  1.3296,  1.4637,  1.1606,  1.4816,  1.4759,
          1.0347,  0.9552,  1.4781,  1.3884,  0.8368,  3.4652,  2.6620,  3.6777,
          2.9598,  2.2492,  1.9480,  3.0594,  3.3978,  1.9331]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 297 : 181.19510677685741
Test loss for epoch 297 : 181.33327849051295
Test Precision for epoch 297 : 0.26153846153846155
Test Recall for epoch 297 : 0.26153846153846155
Test F1 for epoch 297 : 0.26153846153846155


theta for epoch 298 : tensor([[ 2.7313,  2.7571,  2.8230,  2.9577,  2.9253,  2.7357,  2.9059,  2.7294,
          2.7294,  1.2729,  1.2971,  1.2884,  1.3237,  1.2631,  1.3634,  1.2766,
          1.2612,  1.2677,  1.2601,  1.2402,  1.2554,  1.2731,  1.2326,  1.2274,
          1.2493,  1.2207,  1.2207,  1.2686,  1.3128,  1.2403,  1.2651,  1.3153,
          1.2516,  1.2802,  1.2021,  1.2428,  1.3845,  1.4318,  1.4127,  1.3964,
          1.4015,  1.3499,  1.3986,  1.3103,  1.3233,  1.3327,  1.2864,  1.2735,
          1.2588,  1.3291,  1.2802,  1.3648,  1.2495,  1.2622],
        [ 1.2615,  1.2462,  1.1833,  1.2796,  1.3358,  1.3072,  1.2671,  1.3000,
          1.3000,  2.0100,  2.0839,  1.9598,  2.3677,  2.0116,  5.5435,  2.0477,
          1.9400,  5.3379,  1.2566,  1.3205,  1.2508,  1.2278,  1.3189,  1.3182,
          1.2947,  1.3114,  1.3114,  1.3496,  1.1909,  1.3312,  1.3513,  1.2572,
          1.3429,  1.3715,  1.2932,  1.3338,  1.4639,  1.5165,  1.4416,  1.4254,
          1.4817,  1.4884,  1.4270,  0.9999,  1.4012,  1.2559,  1.3764,  1.3623,
          1.3472,  1.2123,  1.3700,  1.2400,  1.3375,  1.3515],
        [ 1.2141,  1.2417,  1.2971,  1.2767,  1.2472,  1.2190,  1.2272,  1.2119,
          1.2119,  1.2760,  1.3003,  1.2916,  1.3270,  1.2661,  1.3212,  1.2797,
          1.2221,  1.3108,  2.7757,  2.9360,  3.0006,  2.8324,  2.7111,  2.7437,
          2.8943,  2.7007,  2.7007,  1.2754,  1.3126,  1.2434,  1.2674,  1.2760,
          1.2548,  1.2835,  1.2511,  1.2459,  1.3866,  1.4342,  1.4139,  1.3486,
          1.4026,  1.4031,  1.4008,  1.3050,  1.2745,  1.3320,  1.2897,  1.2767,
          1.2619,  1.3256,  1.2834,  1.3648,  1.2495,  1.2654],
        [ 1.2252,  1.2529,  1.3077,  1.2876,  1.2585,  1.2301,  1.2386,  1.2231,
          1.2231,  1.2871,  1.3109,  1.3027,  1.3374,  1.2772,  1.2852,  1.2907,
          1.2747,  1.2364,  1.2747,  1.2972,  1.3151,  1.2877,  1.2469,  1.2416,
          1.2610,  1.2350,  1.2350,  3.0260,  3.0002,  2.6225,  2.7894,  3.0239,
          2.6325,  2.9791,  2.6322,  2.6247,  1.3970,  1.4446,  1.4247,  1.4058,
          1.4141,  1.4145,  1.4106,  1.2694,  1.3323,  1.3472,  1.3005,  1.1961,
          1.2259,  1.3436,  1.2939,  1.3795,  1.2145,  1.2763],
        [ 1.8598,  1.4580,  0.6333,  0.9051,  1.2944,  1.7485,  1.6497,  1.8619,
          1.8619,  1.7422,  1.3345,  1.5438,  0.9282,  1.8077,  0.2017,  1.6740,
          1.8994,  0.9428,  1.3345,  0.9440,  0.7369,  1.1610,  1.6896,  1.7585,
          1.5069,  1.8711,  1.8711,  0.8196,  0.8747,  1.8448,  1.6156,  0.8634,
          1.7763,  1.2276,  1.8974,  1.8062,  0.3323,  0.1060,  0.0909,  0.2813,
          0.5214,  0.6084,  0.2221, 15.3141,  5.3601,  0.7896,  1.3876,  1.4966,
          1.7330,  1.0274,  1.6446,  0.3711,  1.8162,  1.9043],
        [ 1.2986,  1.3267,  1.3846,  1.3628,  1.3329,  1.3036,  1.2669,  1.2965,
          1.2965,  1.2649,  1.3836,  1.2806,  1.4110,  1.3492,  1.4505,  1.2687,
          1.3472,  1.3072,  1.3484,  1.3644,  1.3903,  1.3616,  1.3203,  1.3150,
          1.2365,  1.3082,  1.3082,  1.3558,  1.4003,  1.3272,  1.1215,  1.3098,
          1.2017,  1.3671,  1.1989,  1.3297,  1.4641,  1.1610,  1.4816,  1.4763,
          1.0347,  0.9553,  1.4786,  1.3876,  0.8367,  3.4671,  2.6615,  3.6795,
          2.9596,  2.2487,  1.9475,  3.0592,  3.3997,  1.9325]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 298 : 181.18227117191776
Test loss for epoch 298 : 181.3236611647956
Test Precision for epoch 298 : 0.26153846153846155
Test Recall for epoch 298 : 0.26153846153846155
Test F1 for epoch 298 : 0.26153846153846155


theta for epoch 299 : tensor([[ 2.7320,  2.7578,  2.8238,  2.9587,  2.9262,  2.7364,  2.9068,  2.7301,
          2.7301,  1.2728,  1.2972,  1.2884,  1.3240,  1.2631,  1.3636,  1.2767,
          1.2611,  1.2682,  1.2600,  1.2400,  1.2552,  1.2729,  1.2324,  1.2272,
          1.2491,  1.2205,  1.2205,  1.2686,  1.3128,  1.2403,  1.2651,  1.3153,
          1.2516,  1.2802,  1.2021,  1.2428,  1.3848,  1.4321,  1.4131,  1.3967,
          1.4019,  1.3503,  1.3989,  1.3095,  1.3236,  1.3329,  1.2866,  1.2737,
          1.2590,  1.3293,  1.2804,  1.3649,  1.2496,  1.2624],
        [ 1.2608,  1.2477,  1.1851,  1.2793,  1.3348,  1.3061,  1.2672,  1.2988,
          1.2988,  2.0195,  2.0889,  1.9682,  2.3665,  2.0196,  5.5263,  2.0550,
          1.9495,  5.3202,  1.2576,  1.3206,  1.2533,  1.2278,  1.3182,  1.3169,
          1.2936,  1.3100,  1.3100,  1.3497,  1.1913,  1.3300,  1.3509,  1.2593,
          1.3417,  1.3703,  1.2920,  1.3325,  1.4633,  1.5156,  1.4407,  1.4254,
          1.4811,  1.4876,  1.4260,  1.0071,  1.4002,  1.2582,  1.3754,  1.3613,
          1.3462,  1.2139,  1.3690,  1.2438,  1.3366,  1.3505],
        [ 1.2142,  1.2419,  1.2971,  1.2768,  1.2473,  1.2191,  1.2274,  1.2121,
          1.2121,  1.2760,  1.3006,  1.2917,  1.3274,  1.2663,  1.3216,  1.2799,
          1.2218,  1.3118,  2.7758,  2.9371,  3.0000,  2.8309,  2.7125,  2.7436,
          2.8956,  2.7020,  2.7020,  1.2752,  1.3128,  1.2435,  1.2674,  1.2758,
          1.2549,  1.2836,  1.2511,  1.2460,  1.3870,  1.4346,  1.4143,  1.3486,
          1.4030,  1.4034,  1.4012,  1.3047,  1.2744,  1.3325,  1.2900,  1.2771,
          1.2623,  1.3263,  1.2838,  1.3653,  1.2497,  1.2657],
        [ 1.2252,  1.2529,  1.3076,  1.2877,  1.2586,  1.2302,  1.2386,  1.2231,
          1.2231,  1.2870,  1.3110,  1.3026,  1.3377,  1.2772,  1.2856,  1.2907,
          1.2745,  1.2369,  1.2745,  1.2968,  1.3149,  1.2875,  1.2467,  1.2414,
          1.2607,  1.2347,  1.2347,  3.0268,  3.0014,  2.6233,  2.7903,  3.0247,
          2.6333,  2.9797,  2.6330,  2.6255,  1.3973,  1.4449,  1.4251,  1.4060,
          1.4144,  1.4148,  1.4110,  1.2687,  1.3325,  1.3473,  1.3006,  1.1964,
          1.2260,  1.3437,  1.2940,  1.3796,  1.2145,  1.2764],
        [ 1.8600,  1.4569,  0.6329,  0.9055,  1.2950,  1.7491,  1.6494,  1.8625,
          1.8625,  1.7422,  1.3337,  1.5436,  0.9272,  1.8067,  0.1999,  1.6730,
          1.9000,  0.9399,  1.3335,  0.9444,  0.7359,  1.1606,  1.6895,  1.7588,
          1.5077,  1.8715,  1.8715,  0.8201,  0.8744,  1.8454,  1.6161,  0.8631,
          1.7770,  1.2282,  1.8980,  1.8068,  0.3305,  0.1045,  0.0892,  0.2797,
          0.5192,  0.6059,  0.2204, 15.3714,  5.3152,  0.7892,  1.3885,  1.4973,
          1.7338,  1.0267,  1.6454,  0.3703,  1.8175,  1.9050],
        [ 1.2984,  1.3265,  1.3844,  1.3626,  1.3327,  1.3034,  1.2667,  1.2963,
          1.2963,  1.2646,  1.3835,  1.2803,  1.4111,  1.3490,  1.4506,  1.2685,
          1.3468,  1.3073,  1.3479,  1.3634,  1.3898,  1.3611,  1.3198,  1.3144,
          1.2355,  1.3076,  1.3076,  1.3556,  1.4001,  1.3269,  1.1208,  1.3096,
          1.2014,  1.3669,  1.1987,  1.3295,  1.4642,  1.1610,  1.4813,  1.4764,
          1.0343,  0.9549,  1.4787,  1.3865,  0.8362,  3.4699,  2.6621,  3.6822,
          2.9604,  2.2490,  1.9478,  3.0600,  3.4025,  1.9328]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 299 : 181.16924987321022
Test loss for epoch 299 : 181.313310913901
Test Precision for epoch 299 : 0.26153846153846155
Test Recall for epoch 299 : 0.26153846153846155
Test F1 for epoch 299 : 0.26153846153846155


theta for epoch 300 : tensor([[ 2.7330,  2.7588,  2.8247,  2.9599,  2.9274,  2.7374,  2.9080,  2.7311,
          2.7311,  1.2726,  1.2973,  1.2882,  1.3241,  1.2631,  1.3638,  1.2766,
          1.2608,  1.2684,  1.2600,  1.2400,  1.2552,  1.2730,  1.2324,  1.2272,
          1.2491,  1.2205,  1.2205,  1.2686,  1.3128,  1.2402,  1.2650,  1.3152,
          1.2515,  1.2802,  1.2020,  1.2427,  1.3850,  1.4324,  1.4134,  1.3969,
          1.4022,  1.3506,  1.3992,  1.3085,  1.3238,  1.3324,  1.2861,  1.2732,
          1.2585,  1.3288,  1.2799,  1.3644,  1.2491,  1.2619],
        [ 1.2603,  1.2492,  1.1869,  1.2791,  1.3338,  1.3050,  1.2673,  1.2978,
          1.2978,  2.0289,  2.0939,  1.9766,  2.3654,  2.0275,  5.5086,  2.0623,
          1.9590,  5.3020,  1.2588,  1.3208,  1.2558,  1.2283,  1.3178,  1.3159,
          1.2928,  1.3090,  1.3090,  1.3498,  1.1917,  1.3289,  1.3506,  1.2612,
          1.3405,  1.3692,  1.2909,  1.3314,  1.4626,  1.5148,  1.4398,  1.4254,
          1.4806,  1.4868,  1.4251,  1.0141,  1.3993,  1.2600,  1.3739,  1.3599,
          1.3448,  1.2150,  1.3676,  1.2469,  1.3351,  1.3490],
        [ 1.2142,  1.2419,  1.2970,  1.2768,  1.2473,  1.2191,  1.2273,  1.2121,
          1.2121,  1.2759,  1.3006,  1.2915,  1.3276,  1.2662,  1.3217,  1.2799,
          1.2214,  1.3124,  2.7764,  2.9387,  2.9999,  2.8299,  2.7143,  2.7440,
          2.8973,  2.7039,  2.7039,  1.2749,  1.3130,  1.2434,  1.2673,  1.2755,
          1.2548,  1.2836,  1.2511,  1.2460,  1.3872,  1.4348,  1.4145,  1.3485,
          1.4032,  1.4036,  1.4014,  1.3042,  1.2742,  1.3320,  1.2895,  1.2765,
          1.2618,  1.3262,  1.2833,  1.3649,  1.2490,  1.2652],
        [ 1.2253,  1.2530,  1.3076,  1.2878,  1.2586,  1.2302,  1.2387,  1.2232,
          1.2232,  1.2869,  1.3112,  1.3025,  1.3379,  1.2772,  1.2860,  1.2908,
          1.2744,  1.2375,  1.2746,  1.2968,  1.3150,  1.2877,  1.2468,  1.2415,
          1.2607,  1.2349,  1.2349,  3.0276,  3.0026,  2.6241,  2.7911,  3.0255,
          2.6341,  2.9804,  2.6338,  2.6263,  1.3975,  1.4453,  1.4255,  1.4062,
          1.4148,  1.4151,  1.4113,  1.2680,  1.3327,  1.3470,  1.3003,  1.1962,
          1.2257,  1.3434,  1.2938,  1.3792,  1.2140,  1.2761],
        [ 1.8602,  1.4559,  0.6325,  0.9058,  1.2957,  1.7498,  1.6492,  1.8631,
          1.8631,  1.7420,  1.3330,  1.5433,  0.9262,  1.8057,  0.1981,  1.6719,
          1.9006,  0.9370,  1.3328,  0.9451,  0.7353,  1.1605,  1.6896,  1.7594,
          1.5088,  1.8722,  1.8722,  0.8206,  0.8742,  1.8460,  1.6166,  0.8630,
          1.7776,  1.2288,  1.8986,  1.8074,  0.3289,  0.1030,  0.0876,  0.2782,
          0.5171,  0.6035,  0.2188, 15.4291,  5.2699,  0.7882,  1.3887,  1.4975,
          1.7340,  1.0254,  1.6456,  0.3691,  1.8184,  1.9053],
        [ 1.2988,  1.3268,  1.3847,  1.3629,  1.3330,  1.3038,  1.2671,  1.2966,
          1.2966,  1.2648,  1.3840,  1.2806,  1.4116,  1.3493,  1.4511,  1.2689,
          1.3470,  1.3080,  1.3484,  1.3634,  1.3903,  1.3616,  1.3202,  1.3149,
          1.2355,  1.3081,  1.3081,  1.3559,  1.4004,  1.3272,  1.1207,  1.3099,
          1.2018,  1.3672,  1.1990,  1.3298,  1.4646,  1.1613,  1.4812,  1.4768,
          1.0342,  0.9549,  1.4792,  1.3857,  0.8361,  3.4716,  2.6614,  3.6837,
          2.9600,  2.2483,  1.9470,  3.0597,  3.4042,  1.9320]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 300 : 181.15604401192257
Test loss for epoch 300 : 181.30348853798858
Test Precision for epoch 300 : 0.26153846153846155
Test Recall for epoch 300 : 0.26153846153846155
Test F1 for epoch 300 : 0.26153846153846155


theta for epoch 301 : tensor([[ 2.7333,  2.7592,  2.8251,  2.9605,  2.9281,  2.7378,  2.9086,  2.7314,
          2.7314,  1.2727,  1.2975,  1.2883,  1.3245,  1.2632,  1.3641,  1.2768,
          1.2608,  1.2689,  1.2600,  1.2400,  1.2552,  1.2730,  1.2324,  1.2272,
          1.2491,  1.2205,  1.2205,  1.2687,  1.3129,  1.2403,  1.2652,  1.3153,
          1.2517,  1.2803,  1.2021,  1.2429,  1.3853,  1.4328,  1.4138,  1.3972,
          1.4026,  1.3511,  1.3995,  1.3078,  1.3242,  1.3328,  1.2866,  1.2736,
          1.2589,  1.3293,  1.2804,  1.3648,  1.2495,  1.2624],
        [ 1.2596,  1.2504,  1.1884,  1.2786,  1.3325,  1.3037,  1.2671,  1.2965,
          1.2965,  2.0383,  2.0989,  1.9849,  2.3643,  2.0353,  5.4903,  2.0696,
          1.9686,  5.2832,  1.2595,  1.3207,  1.2580,  1.2284,  1.3171,  1.3148,
          1.2920,  1.3078,  1.3078,  1.3497,  1.1921,  1.3277,  1.3501,  1.2628,
          1.3394,  1.3681,  1.2898,  1.3303,  1.4620,  1.5139,  1.4390,  1.4255,
          1.4800,  1.4861,  1.4243,  1.0208,  1.3985,  1.2623,  1.3732,  1.3592,
          1.3441,  1.2168,  1.3668,  1.2503,  1.3343,  1.3483],
        [ 1.2140,  1.2416,  1.2966,  1.2766,  1.2471,  1.2189,  1.2271,  1.2118,
          1.2118,  1.2758,  1.3007,  1.2915,  1.3279,  1.2662,  1.3219,  1.2799,
          1.2211,  1.3131,  2.7767,  2.9400,  2.9995,  2.8286,  2.7158,  2.7441,
          2.8988,  2.7054,  2.7054,  1.2746,  1.3132,  1.2434,  1.2673,  1.2752,
          1.2548,  1.2836,  1.2511,  1.2460,  1.3874,  1.4351,  1.4148,  1.3483,
          1.4035,  1.4038,  1.4017,  1.3038,  1.2740,  1.3325,  1.2899,  1.2769,
          1.2622,  1.3269,  1.2837,  1.3654,  1.2492,  1.2656],
        [ 1.2251,  1.2528,  1.3073,  1.2876,  1.2585,  1.2301,  1.2385,  1.2230,
          1.2230,  1.2868,  1.3114,  1.3025,  1.3382,  1.2772,  1.2863,  1.2909,
          1.2743,  1.2381,  1.2746,  1.2966,  1.3150,  1.2877,  1.2468,  1.2415,
          1.2605,  1.2348,  1.2348,  3.0283,  3.0036,  2.6248,  2.7918,  3.0262,
          2.6347,  2.9809,  2.6345,  2.6270,  1.3978,  1.4456,  1.4258,  1.4064,
          1.4152,  1.4154,  1.4116,  1.2674,  1.3328,  1.3472,  1.3006,  1.1967,
          1.2260,  1.3437,  1.2941,  1.3795,  1.2141,  1.2764],
        [ 1.8600,  1.4547,  0.6320,  0.9060,  1.2961,  1.7501,  1.6487,  1.8635,
          1.8635,  1.7418,  1.3323,  1.5431,  0.9253,  1.8047,  0.1965,  1.6709,
          1.9012,  0.9343,  1.3323,  0.9458,  0.7346,  1.1602,  1.6897,  1.7598,
          1.5097,  1.8727,  1.8727,  0.8212,  0.8739,  1.8466,  1.6172,  0.8629,
          1.7782,  1.2294,  1.8992,  1.8080,  0.3273,  0.1016,  0.0859,  0.2768,
          0.5150,  0.6011,  0.2172, 15.4871,  5.2240,  0.7878,  1.3897,  1.4983,
          1.7348,  1.0248,  1.6465,  0.3685,  1.8199,  1.9061],
        [ 1.2982,  1.3263,  1.3842,  1.3624,  1.3325,  1.3032,  1.2666,  1.2961,
          1.2961,  1.2645,  1.3838,  1.2802,  1.4116,  1.3490,  1.4511,  1.2687,
          1.3466,  1.3081,  1.3480,  1.3624,  1.3899,  1.3613,  1.3198,  1.3145,
          1.2345,  1.3077,  1.3077,  1.3556,  1.4001,  1.3270,  1.1199,  1.3096,
          1.2015,  1.3669,  1.1987,  1.3296,  1.4646,  1.1613,  1.4808,  1.4768,
          1.0337,  0.9544,  1.4792,  1.3846,  0.8355,  3.4745,  2.6620,  3.6864,
          2.9608,  2.2488,  1.9475,  3.0605,  3.4072,  1.9325]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 301 : 181.14265102651
Test loss for epoch 301 : 181.2928297919065
Test Precision for epoch 301 : 0.26153846153846155
Test Recall for epoch 301 : 0.26153846153846155
Test F1 for epoch 301 : 0.26153846153846155


theta for epoch 302 : tensor([[ 2.7344,  2.7602,  2.8262,  2.9617,  2.9293,  2.7388,  2.9099,  2.7324,
          2.7324,  1.2725,  1.2975,  1.2881,  1.3246,  1.2631,  1.3642,  1.2768,
          1.2606,  1.2691,  1.2599,  1.2398,  1.2550,  1.2729,  1.2322,  1.2271,
          1.2489,  1.2203,  1.2203,  1.2685,  1.3127,  1.2402,  1.2650,  1.3151,
          1.2515,  1.2802,  1.2019,  1.2427,  1.3855,  1.4330,  1.4141,  1.3974,
          1.4029,  1.3514,  1.3998,  1.3070,  1.3244,  1.3321,  1.2859,  1.2730,
          1.2583,  1.3287,  1.2797,  1.3642,  1.2488,  1.2618],
        [ 1.2594,  1.2519,  1.1903,  1.2784,  1.3316,  1.3028,  1.2672,  1.2956,
          1.2956,  2.0478,  2.1041,  1.9934,  2.3635,  2.0432,  5.4717,  2.0769,
          1.9783,  5.2640,  1.2601,  1.3203,  1.2598,  1.2286,  1.3164,  1.3137,
          1.2911,  1.3067,  1.3067,  1.3495,  1.1925,  1.3266,  1.3496,  1.2642,
          1.3383,  1.3671,  1.2887,  1.3292,  1.4614,  1.5131,  1.4382,  1.4257,
          1.4795,  1.4854,  1.4234,  1.0272,  1.3977,  1.2639,  1.3717,  1.3576,
          1.3425,  1.2178,  1.3653,  1.2528,  1.3327,  1.3467],
        [ 1.2142,  1.2419,  1.2967,  1.2768,  1.2473,  1.2191,  1.2273,  1.2120,
          1.2120,  1.2758,  1.3009,  1.2915,  1.3281,  1.2663,  1.3221,  1.2801,
          1.2208,  1.3138,  2.7770,  2.9414,  2.9992,  2.8273,  2.7174,  2.7443,
          2.9002,  2.7070,  2.7070,  1.2743,  1.3133,  1.2434,  1.2672,  1.2749,
          1.2548,  1.2836,  1.2511,  1.2459,  1.3877,  1.4355,  1.4151,  1.3482,
          1.4038,  1.4041,  1.4020,  1.3034,  1.2739,  1.3320,  1.2894,  1.2764,
          1.2616,  1.3266,  1.2832,  1.3650,  1.2484,  1.2651],
        [ 1.2253,  1.2530,  1.3074,  1.2878,  1.2587,  1.2303,  1.2387,  1.2232,
          1.2232,  1.2868,  1.3115,  1.3025,  1.3385,  1.2773,  1.2867,  1.2910,
          1.2742,  1.2387,  1.2746,  1.2964,  1.3149,  1.2877,  1.2467,  1.2415,
          1.2604,  1.2348,  1.2348,  3.0291,  3.0047,  2.6255,  2.7925,  3.0270,
          2.6355,  2.9815,  2.6352,  2.6277,  1.3981,  1.4460,  1.4262,  1.4065,
          1.4156,  1.4158,  1.4119,  1.2669,  1.3330,  1.3468,  1.3002,  1.1964,
          1.2255,  1.3433,  1.2937,  1.3790,  1.2135,  1.2760],
        [ 1.8601,  1.4538,  0.6316,  0.9064,  1.2969,  1.7509,  1.6487,  1.8642,
          1.8642,  1.7416,  1.3316,  1.5427,  0.9243,  1.8035,  0.1947,  1.6698,
          1.9018,  0.9315,  1.3318,  0.9465,  0.7340,  1.1600,  1.6899,  1.7602,
          1.5106,  1.8731,  1.8731,  0.8217,  0.8734,  1.8471,  1.6178,  0.8628,
          1.7787,  1.2299,  1.8997,  1.8085,  0.3259,  0.1003,  0.0845,  0.2755,
          0.5131,  0.5989,  0.2158, 15.5456,  5.1776,  0.7867,  1.3898,  1.4982,
          1.7349,  1.0233,  1.6466,  0.3671,  1.8206,  1.9062],
        [ 1.2988,  1.3269,  1.3848,  1.3630,  1.3331,  1.3038,  1.2672,  1.2966,
          1.2966,  1.2648,  1.3843,  1.2806,  1.4122,  1.3495,  1.4517,  1.2692,
          1.3468,  1.3088,  1.3484,  1.3623,  1.3903,  1.3617,  1.3202,  1.3149,
          1.2344,  1.3080,  1.3080,  1.3560,  1.4005,  1.3273,  1.1198,  1.3099,
          1.2019,  1.3673,  1.1991,  1.3299,  1.4651,  1.1617,  1.4807,  1.4773,
          1.0338,  0.9545,  1.4797,  1.3841,  0.8355,  3.4760,  2.6611,  3.6876,
          2.9601,  2.2477,  1.9464,  3.0598,  3.4086,  1.9314]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 302 : 181.12907000258383
Test loss for epoch 302 : 181.28305726754218
Test Precision for epoch 302 : 0.26153846153846155
Test Recall for epoch 302 : 0.26153846153846155
Test F1 for epoch 302 : 0.26153846153846155


theta for epoch 303 : tensor([[ 2.7346,  2.7604,  2.8264,  2.9622,  2.9298,  2.7390,  2.9103,  2.7327,
          2.7327,  1.2726,  1.2977,  1.2882,  1.3250,  1.2633,  1.3645,  1.2770,
          1.2606,  1.2696,  1.2600,  1.2400,  1.2552,  1.2731,  1.2324,  1.2273,
          1.2490,  1.2205,  1.2205,  1.2686,  1.3129,  1.2403,  1.2651,  1.3152,
          1.2516,  1.2803,  1.2021,  1.2428,  1.3858,  1.4334,  1.4145,  1.3977,
          1.4033,  1.3518,  1.4001,  1.3064,  1.3247,  1.3327,  1.2865,  1.2736,
          1.2589,  1.3292,  1.2803,  1.3647,  1.2493,  1.2623],
        [ 1.2588,  1.2530,  1.1917,  1.2779,  1.3303,  1.3015,  1.2668,  1.2943,
          1.2943,  2.0572,  2.1092,  2.0017,  2.3628,  2.0510,  5.4526,  2.0842,
          1.9879,  5.2443,  1.2605,  1.3198,  1.2614,  1.2287,  1.3156,  1.3126,
          1.2903,  1.3056,  1.3056,  1.3491,  1.1929,  1.3254,  1.3489,  1.2652,
          1.3371,  1.3659,  1.2875,  1.3280,  1.4607,  1.5122,  1.4374,  1.4258,
          1.4788,  1.4846,  1.4225,  1.0333,  1.3968,  1.2663,  1.3710,  1.3570,
          1.3419,  1.2197,  1.3646,  1.2557,  1.3320,  1.3461],
        [ 1.2140,  1.2416,  1.2964,  1.2766,  1.2471,  1.2189,  1.2271,  1.2118,
          1.2118,  1.2756,  1.3009,  1.2914,  1.3283,  1.2663,  1.3222,  1.2801,
          1.2205,  1.3143,  2.7773,  2.9427,  2.9989,  2.8261,  2.7189,  2.7444,
          2.9017,  2.7084,  2.7084,  1.2739,  1.3134,  1.2433,  1.2671,  1.2745,
          1.2547,  1.2835,  1.2510,  1.2459,  1.3878,  1.4357,  1.4153,  1.3480,
          1.4040,  1.4042,  1.4022,  1.3029,  1.2737,  1.3325,  1.2898,  1.2768,
          1.2620,  1.3273,  1.2836,  1.3655,  1.2486,  1.2655],
        [ 1.2251,  1.2528,  1.3071,  1.2877,  1.2585,  1.2301,  1.2386,  1.2230,
          1.2230,  1.2866,  1.3116,  1.3024,  1.3386,  1.2772,  1.2870,  1.2910,
          1.2740,  1.2391,  1.2746,  1.2962,  1.3149,  1.2877,  1.2467,  1.2415,
          1.2602,  1.2347,  1.2347,  3.0298,  3.0057,  2.6262,  2.7932,  3.0277,
          2.6361,  2.9820,  2.6359,  2.6284,  1.3983,  1.4462,  1.4265,  1.4066,
          1.4159,  1.4159,  1.4121,  1.2664,  1.3331,  1.3471,  1.3006,  1.1969,
          1.2258,  1.3436,  1.2940,  1.3793,  1.2137,  1.2763],
        [ 1.8599,  1.4527,  0.6312,  0.9068,  1.2975,  1.7513,  1.6485,  1.8647,
          1.8647,  1.7413,  1.3310,  1.5424,  0.9236,  1.8023,  0.1933,  1.6688,
          1.9024,  0.9289,  1.3316,  0.9476,  0.7337,  1.1600,  1.6903,  1.7607,
          1.5116,  1.8737,  1.8737,  0.8225,  0.8732,  1.8477,  1.6185,  0.8630,
          1.7793,  1.2305,  1.9003,  1.8091,  0.3242,  0.0988,  0.0828,  0.2740,
          0.5110,  0.5965,  0.2142, 15.6043,  5.1305,  0.7865,  1.3909,  1.4992,
          1.7359,  1.0229,  1.6477,  0.3668,  1.8223,  1.9071],
        [ 1.2982,  1.3264,  1.3842,  1.3625,  1.3326,  1.3033,  1.2666,  1.2961,
          1.2961,  1.2643,  1.3840,  1.2802,  1.4120,  1.3491,  1.4515,  1.2688,
          1.3463,  1.3087,  1.3480,  1.3612,  1.3899,  1.3612,  1.3197,  1.3145,
          1.2333,  1.3075,  1.3075,  1.3555,  1.4001,  1.3269,  1.1188,  1.3095,
          1.2014,  1.3669,  1.1986,  1.3295,  1.4650,  1.1615,  1.4801,  1.4771,
          1.0330,  0.9538,  1.4797,  1.3830,  0.8347,  3.4791,  2.6618,  3.6904,
          2.9611,  2.2484,  1.9471,  3.0608,  3.4118,  1.9321]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 303 : 181.11529821071346
Test loss for epoch 303 : 181.2719601326928
Test Precision for epoch 303 : 0.26153846153846155
Test Recall for epoch 303 : 0.26153846153846155
Test F1 for epoch 303 : 0.26153846153846155


theta for epoch 304 : tensor([[ 2.7355,  2.7614,  2.8274,  2.9634,  2.9310,  2.7399,  2.9115,  2.7336,
          2.7336,  1.2724,  1.2977,  1.2881,  1.3250,  1.2632,  1.3645,  1.2769,
          1.2604,  1.2697,  1.2600,  1.2398,  1.2551,  1.2730,  1.2323,  1.2272,
          1.2489,  1.2204,  1.2204,  1.2684,  1.3127,  1.2402,  1.2650,  1.3150,
          1.2515,  1.2802,  1.2019,  1.2427,  1.3860,  1.4336,  1.4148,  1.3978,
          1.4036,  1.3521,  1.4003,  1.3057,  1.3249,  1.3319,  1.2858,  1.2728,
          1.2581,  1.3285,  1.2795,  1.3639,  1.2485,  1.2615],
        [ 1.2586,  1.2544,  1.1935,  1.2777,  1.3293,  1.3006,  1.2667,  1.2933,
          1.2933,  2.0667,  2.1145,  2.0101,  2.3624,  2.0589,  5.4331,  2.0916,
          1.9977,  5.2243,  1.2607,  1.3192,  1.2628,  1.2288,  1.3148,  1.3115,
          1.2896,  1.3045,  1.3045,  1.3487,  1.1935,  1.3243,  1.3483,  1.2660,
          1.3360,  1.3649,  1.2864,  1.3269,  1.4601,  1.5114,  1.4366,  1.4260,
          1.4783,  1.4839,  1.4217,  1.0392,  1.3960,  1.2677,  1.3692,  1.3553,
          1.3401,  1.2207,  1.3628,  1.2577,  1.3303,  1.3443],
        [ 1.2141,  1.2418,  1.2965,  1.2768,  1.2473,  1.2191,  1.2273,  1.2120,
          1.2120,  1.2756,  1.3011,  1.2914,  1.3285,  1.2664,  1.3224,  1.2802,
          1.2202,  1.3148,  2.7776,  2.9441,  2.9986,  2.8249,  2.7204,  2.7446,
          2.9032,  2.7099,  2.7099,  1.2736,  1.3135,  1.2434,  1.2671,  1.2742,
          1.2547,  1.2836,  1.2510,  1.2459,  1.3881,  1.4360,  1.4156,  1.3479,
          1.4043,  1.4044,  1.4025,  1.3026,  1.2735,  1.3319,  1.2891,  1.2761,
          1.2613,  1.3269,  1.2829,  1.3649,  1.2476,  1.2648],
        [ 1.2253,  1.2530,  1.3071,  1.2878,  1.2586,  1.2302,  1.2387,  1.2231,
          1.2231,  1.2866,  1.3118,  1.3024,  1.3388,  1.2773,  1.2874,  1.2911,
          1.2739,  1.2396,  1.2746,  1.2961,  1.3149,  1.2878,  1.2468,  1.2416,
          1.2601,  1.2348,  1.2348,  3.0306,  3.0067,  2.6269,  2.7939,  3.0284,
          2.6368,  2.9826,  2.6366,  2.6291,  1.3986,  1.4465,  1.4268,  1.4066,
          1.4162,  1.4162,  1.4123,  1.2659,  1.3332,  1.3465,  1.3000,  1.1965,
          1.2253,  1.3431,  1.2935,  1.3788,  1.2129,  1.2758],
        [ 1.8599,  1.4519,  0.6307,  0.9072,  1.2983,  1.7520,  1.6485,  1.8654,
          1.8654,  1.7410,  1.3304,  1.5420,  0.9227,  1.8010,  0.1916,  1.6677,
          1.9030,  0.9262,  1.3314,  0.9485,  0.7334,  1.1599,  1.6906,  1.7612,
          1.5126,  1.8743,  1.8743,  0.8231,  0.8727,  1.8483,  1.6192,  0.8631,
          1.7798,  1.2311,  1.9008,  1.8097,  0.3228,  0.0975,  0.0814,  0.2729,
          0.5092,  0.5944,  0.2129, 15.6635,  5.0831,  0.7853,  1.3910,  1.4990,
          1.7359,  1.0212,  1.6476,  0.3653,  1.8230,  1.9071],
        [ 1.2989,  1.3270,  1.3848,  1.3631,  1.3332,  1.3039,  1.2672,  1.2967,
          1.2967,  1.2648,  1.3846,  1.2807,  1.4127,  1.3496,  1.4521,  1.2695,
          1.3467,  1.3095,  1.3486,  1.3613,  1.3905,  1.3619,  1.3204,  1.3151,
          1.2334,  1.3082,  1.3082,  1.3560,  1.4005,  1.3273,  1.1188,  1.3099,
          1.2019,  1.3674,  1.1991,  1.3299,  1.4655,  1.1620,  1.4801,  1.4776,
          1.0331,  0.9539,  1.4802,  1.3826,  0.8348,  3.4803,  2.6606,  3.6911,
          2.9600,  2.2471,  1.9458,  3.0598,  3.4130,  1.9308]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 304 : 181.10134289247824
Test loss for epoch 304 : 181.26214495744108
Test Precision for epoch 304 : 0.26153846153846155
Test Recall for epoch 304 : 0.26153846153846155
Test F1 for epoch 304 : 0.26153846153846155


theta for epoch 305 : tensor([[ 2.7358,  2.7616,  2.8276,  2.9638,  2.9314,  2.7402,  2.9120,  2.7338,
          2.7338,  1.2725,  1.2979,  1.2882,  1.3253,  1.2634,  1.3648,  1.2771,
          1.2604,  1.2701,  1.2599,  1.2397,  1.2550,  1.2730,  1.2322,  1.2271,
          1.2488,  1.2203,  1.2203,  1.2685,  1.3128,  1.2402,  1.2650,  1.3150,
          1.2515,  1.2802,  1.2019,  1.2427,  1.3862,  1.4339,  1.4151,  1.3980,
          1.4039,  1.3525,  1.4006,  1.3051,  1.3252,  1.3325,  1.2864,  1.2734,
          1.2588,  1.3292,  1.2802,  1.3646,  1.2491,  1.2622],
        [ 1.2580,  1.2554,  1.1951,  1.2771,  1.3279,  1.2992,  1.2661,  1.2919,
          1.2919,  2.0760,  2.1198,  2.0184,  2.3619,  2.0665,  5.4131,  2.0988,
          2.0075,  5.2037,  1.2606,  1.3182,  1.2638,  1.2287,  1.3137,  1.3103,
          1.2887,  1.3032,  1.3032,  1.3482,  1.1940,  1.3232,  1.3475,  1.2666,
          1.3349,  1.3638,  1.2853,  1.3257,  1.4594,  1.5105,  1.4358,  1.4262,
          1.4776,  1.4831,  1.4208,  1.0450,  1.3952,  1.2703,  1.3687,  1.3548,
          1.3396,  1.2229,  1.3623,  1.2606,  1.3297,  1.3438],
        [ 1.2140,  1.2417,  1.2962,  1.2766,  1.2471,  1.2189,  1.2272,  1.2118,
          1.2118,  1.2757,  1.3013,  1.2915,  1.3288,  1.2665,  1.3226,  1.2804,
          1.2200,  1.3154,  2.7775,  2.9451,  2.9979,  2.8234,  2.7215,  2.7445,
          2.9043,  2.7111,  2.7111,  1.2734,  1.3137,  1.2434,  1.2670,  1.2739,
          1.2548,  1.2836,  1.2510,  1.2459,  1.3883,  1.4363,  1.4159,  1.3477,
          1.4046,  1.4046,  1.4027,  1.3023,  1.2734,  1.3327,  1.2899,  1.2768,
          1.2621,  1.3279,  1.2836,  1.3658,  1.2482,  1.2655],
        [ 1.2251,  1.2528,  1.3068,  1.2877,  1.2584,  1.2300,  1.2385,  1.2229,
          1.2229,  1.2866,  1.3119,  1.3024,  1.3391,  1.2774,  1.2878,  1.2912,
          1.2738,  1.2401,  1.2745,  1.2958,  1.3148,  1.2877,  1.2466,  1.2414,
          1.2598,  1.2346,  1.2346,  3.0311,  3.0075,  2.6274,  2.7943,  3.0290,
          2.6374,  2.9829,  2.6372,  2.6296,  1.3988,  1.4468,  1.4271,  1.4067,
          1.4166,  1.4164,  1.4126,  1.2655,  1.3334,  1.3470,  1.3005,  1.1972,
          1.2257,  1.3436,  1.2940,  1.3792,  1.2132,  1.2763],
        [ 1.8596,  1.4508,  0.6301,  0.9074,  1.2988,  1.7524,  1.6484,  1.8657,
          1.8657,  1.7406,  1.3299,  1.5416,  0.9219,  1.7996,  0.1901,  1.6667,
          1.9036,  0.9235,  1.3313,  0.9496,  0.7332,  1.1598,  1.6910,  1.7616,
          1.5136,  1.8747,  1.8747,  0.8240,  0.8723,  1.8488,  1.6201,  0.8634,
          1.7804,  1.2317,  1.9013,  1.8103,  0.3212,  0.0961,  0.0797,  0.2715,
          0.5071,  0.5921,  0.2113, 15.7229,  5.0349,  0.7852,  1.3922,  1.5001,
          1.7370,  1.0208,  1.6488,  0.3651,  1.8249,  1.9082],
        [ 1.2981,  1.3263,  1.3841,  1.3624,  1.3325,  1.3032,  1.2665,  1.2960,
          1.2960,  1.2643,  1.3842,  1.2802,  1.4124,  1.3492,  1.4518,  1.2690,
          1.3461,  1.3093,  1.3478,  1.3598,  1.3897,  1.3611,  1.3195,  1.3143,
          1.2319,  1.3073,  1.3073,  1.3555,  1.4001,  1.3268,  1.1177,  1.3094,
          1.2014,  1.3669,  1.1986,  1.3294,  1.4654,  1.1617,  1.4793,  1.4774,
          1.0323,  0.9531,  1.4801,  1.3815,  0.8339,  3.4836,  2.6615,  3.6940,
          2.9612,  2.2480,  1.9467,  3.0610,  3.4164,  1.9317]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 305 : 181.08721282255158
Test loss for epoch 305 : 181.25081658970564
Test Precision for epoch 305 : 0.26153846153846155
Test Recall for epoch 305 : 0.26153846153846155
Test F1 for epoch 305 : 0.26153846153846155


theta for epoch 306 : tensor([[ 2.7366,  2.7625,  2.8285,  2.9649,  2.9325,  2.7410,  2.9130,  2.7347,
          2.7347,  1.2724,  1.2979,  1.2881,  1.3255,  1.2634,  1.3649,  1.2771,
          1.2602,  1.2703,  1.2600,  1.2399,  1.2552,  1.2732,  1.2323,  1.2273,
          1.2489,  1.2204,  1.2204,  1.2684,  1.3127,  1.2401,  1.2649,  1.3149,
          1.2515,  1.2802,  1.2018,  1.2427,  1.3864,  1.4341,  1.4153,  1.3981,
          1.4042,  1.3527,  1.4007,  1.3045,  1.3254,  1.3316,  1.2855,  1.2725,
          1.2578,  1.3283,  1.2793,  1.3637,  1.2481,  1.2613],
        [ 1.2578,  1.2567,  1.1970,  1.2768,  1.3268,  1.2981,  1.2658,  1.2909,
          1.2909,  2.0855,  2.1252,  2.0268,  2.3618,  2.0742,  5.3929,  2.1061,
          2.0174,  5.1829,  1.2609,  1.3176,  1.2650,  1.2290,  1.3130,  1.3094,
          1.2882,  1.3023,  1.3023,  1.3476,  1.1948,  1.3221,  1.3466,  1.2671,
          1.3338,  1.3627,  1.2842,  1.3247,  1.4587,  1.5097,  1.4350,  1.4265,
          1.4770,  1.4824,  1.4200,  1.0506,  1.3944,  1.2716,  1.3668,  1.3528,
          1.3377,  1.2238,  1.3604,  1.2623,  1.3277,  1.3418],
        [ 1.2139,  1.2416,  1.2959,  1.2765,  1.2470,  1.2188,  1.2271,  1.2117,
          1.2117,  1.2755,  1.3012,  1.2914,  1.3289,  1.2665,  1.3226,  1.2803,
          1.2196,  1.3158,  2.7782,  2.9469,  2.9980,  2.8226,  2.7233,  2.7450,
          2.9061,  2.7128,  2.7128,  1.2730,  1.3137,  1.2433,  1.2669,  1.2734,
          1.2547,  1.2835,  1.2509,  1.2458,  1.3884,  1.4364,  1.4160,  1.3474,
          1.4047,  1.4046,  1.4028,  1.3018,  1.2731,  1.3316,  1.2887,  1.2756,
          1.2609,  1.3269,  1.2825,  1.3647,  1.2467,  1.2643],
        [ 1.2252,  1.2529,  1.3068,  1.2877,  1.2585,  1.2301,  1.2386,  1.2230,
          1.2230,  1.2866,  1.3120,  1.3024,  1.3393,  1.2775,  1.2881,  1.2913,
          1.2737,  1.2407,  1.2748,  1.2959,  1.3151,  1.2880,  1.2469,  1.2417,
          1.2599,  1.2349,  1.2349,  3.0318,  3.0085,  2.6281,  2.7949,  3.0297,
          2.6380,  2.9834,  2.6379,  2.6303,  1.3990,  1.4471,  1.4274,  1.4067,
          1.4169,  1.4166,  1.4128,  1.2652,  1.3335,  1.3463,  1.2998,  1.1967,
          1.2250,  1.3429,  1.2934,  1.3786,  1.2123,  1.2756],
        [ 1.8594,  1.4498,  0.6294,  0.9078,  1.2996,  1.7531,  1.6484,  1.8664,
          1.8664,  1.7402,  1.3293,  1.5411,  0.9210,  1.7981,  0.1883,  1.6657,
          1.9042,  0.9207,  1.3314,  0.9508,  0.7331,  1.1599,  1.6916,  1.7623,
          1.5148,  1.8755,  1.8755,  0.8247,  0.8718,  1.8494,  1.6210,  0.8636,
          1.7811,  1.2323,  1.9019,  1.8109,  0.3198,  0.0949,  0.0783,  0.2703,
          0.5053,  0.5901,  0.2100, 15.7827,  4.9865,  0.7838,  1.3921,  1.4998,
          1.7368,  1.0190,  1.6486,  0.3635,  1.8255,  1.9080],
        [ 1.2988,  1.3270,  1.3848,  1.3631,  1.3332,  1.3038,  1.2672,  1.2966,
          1.2966,  1.2650,  1.3850,  1.2809,  1.4133,  1.3499,  1.4527,  1.2698,
          1.3466,  1.3103,  1.3489,  1.3603,  1.3908,  1.3623,  1.3206,  1.3154,
          1.2324,  1.3084,  1.3084,  1.3561,  1.4007,  1.3275,  1.1178,  1.3100,
          1.2020,  1.3675,  1.1992,  1.3300,  1.4659,  1.1623,  1.4793,  1.4779,
          1.0324,  0.9533,  1.4807,  1.3813,  0.8340,  3.4845,  2.6599,  3.6943,
          2.9597,  2.2463,  1.9450,  3.0596,  3.4172,  1.9299]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 306 : 181.07292654608935
Test loss for epoch 306 : 181.241065522475
Test Precision for epoch 306 : 0.26153846153846155
Test Recall for epoch 306 : 0.26153846153846155
Test F1 for epoch 306 : 0.26153846153846155


theta for epoch 307 : tensor([[ 2.7368,  2.7627,  2.8287,  2.9654,  2.9330,  2.7413,  2.9135,  2.7349,
          2.7349,  1.2724,  1.2981,  1.2882,  1.3257,  1.2635,  1.3652,  1.2773,
          1.2602,  1.2706,  1.2596,  1.2394,  1.2548,  1.2728,  1.2319,  1.2269,
          1.2485,  1.2200,  1.2200,  1.2684,  1.3127,  1.2401,  1.2649,  1.3148,
          1.2515,  1.2802,  1.2018,  1.2427,  1.3866,  1.4343,  1.4156,  1.3983,
          1.4045,  1.3530,  1.4009,  1.3040,  1.3256,  1.3324,  1.2864,  1.2734,
          1.2587,  1.3291,  1.2801,  1.3645,  1.2489,  1.2621],
        [ 1.2574,  1.2578,  1.1989,  1.2763,  1.3255,  1.2968,  1.2652,  1.2895,
          1.2895,  2.0948,  2.1307,  2.0350,  2.3618,  2.0818,  5.3722,  2.1133,
          2.0272,  5.1616,  1.2603,  1.3161,  1.2653,  1.2285,  1.3113,  1.3077,
          1.2869,  1.3006,  1.3006,  1.3468,  1.1955,  1.3209,  1.3456,  1.2673,
          1.3326,  1.3616,  1.2830,  1.3235,  1.4579,  1.5088,  1.4342,  1.4267,
          1.4762,  1.4816,  1.4191,  1.0561,  1.3935,  1.2745,  1.3664,  1.3525,
          1.3374,  1.2263,  1.3600,  1.2652,  1.3273,  1.3415],
        [ 1.2140,  1.2417,  1.2959,  1.2767,  1.2472,  1.2189,  1.2272,  1.2118,
          1.2118,  1.2758,  1.3016,  1.2917,  1.3294,  1.2669,  1.3230,  1.2807,
          1.2196,  1.3166,  2.7777,  2.9475,  2.9970,  2.8208,  2.7239,  2.7444,
          2.9068,  2.7135,  2.7135,  1.2728,  1.3140,  1.2435,  1.2670,  1.2733,
          1.2548,  1.2837,  1.2511,  1.2460,  1.3887,  1.4367,  1.4163,  1.3473,
          1.4051,  1.4048,  1.4032,  1.3016,  1.2730,  1.3328,  1.2899,  1.2769,
          1.2621,  1.3284,  1.2837,  1.3661,  1.2477,  1.2656],
        [ 1.2250,  1.2528,  1.3065,  1.2877,  1.2584,  1.2300,  1.2385,  1.2229,
          1.2229,  1.2865,  1.3121,  1.3024,  1.3395,  1.2775,  1.2885,  1.2914,
          1.2736,  1.2412,  1.2743,  1.2952,  1.3146,  1.2875,  1.2464,  1.2413,
          1.2593,  1.2344,  1.2344,  3.0324,  3.0092,  2.6286,  2.7953,  3.0303,
          2.6385,  2.9837,  2.6384,  2.6307,  1.3992,  1.4472,  1.4276,  1.4066,
          1.4171,  1.4167,  1.4129,  1.2648,  1.3335,  1.3469,  1.3005,  1.1976,
          1.2256,  1.3436,  1.2941,  1.3792,  1.2127,  1.2762],
        [ 1.8591,  1.4489,  0.6289,  0.9082,  1.3004,  1.7537,  1.6485,  1.8670,
          1.8670,  1.7398,  1.3289,  1.5407,  0.9202,  1.7966,  0.1869,  1.6647,
          1.9049,  0.9180,  1.3312,  0.9519,  0.7329,  1.1597,  1.6919,  1.7626,
          1.5157,  1.8758,  1.8758,  0.8258,  0.8714,  1.8501,  1.6220,  0.8641,
          1.7817,  1.2331,  1.9026,  1.8115,  0.3182,  0.0934,  0.0766,  0.2689,
          0.5032,  0.5877,  0.2084, 15.8426,  4.9372,  0.7841,  1.3937,  1.5012,
          1.7383,  1.0189,  1.6501,  0.3635,  1.8278,  1.9094],
        [ 1.2980,  1.3262,  1.3840,  1.3623,  1.3324,  1.3031,  1.2664,  1.2959,
          1.2959,  1.2642,  1.3844,  1.2802,  1.4128,  1.3493,  1.4522,  1.2692,
          1.3459,  1.3099,  1.3474,  1.3582,  1.3894,  1.3608,  1.3192,  1.3140,
          1.2303,  1.3069,  1.3069,  1.3553,  1.4000,  1.3267,  1.1164,  1.3092,
          1.2012,  1.3668,  1.1984,  1.3293,  1.4656,  1.1618,  1.4783,  1.4775,
          1.0313,  0.9522,  1.4804,  1.3802,  0.8329,  3.4883,  2.6613,  3.6975,
          2.9612,  2.2476,  1.9463,  3.0611,  3.4211,  1.9313]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 307 : 181.05849590756168
Test loss for epoch 307 : 181.22935100770155
Test Precision for epoch 307 : 0.26153846153846155
Test Recall for epoch 307 : 0.26153846153846155
Test F1 for epoch 307 : 0.26153846153846155


theta for epoch 308 : tensor([[ 2.7375,  2.7634,  2.8294,  2.9662,  2.9338,  2.7419,  2.9144,  2.7356,
          2.7356,  1.2724,  1.2981,  1.2882,  1.3259,  1.2636,  1.3653,  1.2774,
          1.2601,  1.2709,  1.2602,  1.2400,  1.2554,  1.2734,  1.2325,  1.2275,
          1.2491,  1.2206,  1.2206,  1.2683,  1.3127,  1.2401,  1.2649,  1.3148,
          1.2514,  1.2801,  1.2018,  1.2426,  1.3868,  1.4346,  1.4160,  1.3985,
          1.4048,  1.3534,  1.4012,  1.3035,  1.3260,  1.3312,  1.2851,  1.2721,
          1.2574,  1.3279,  1.2789,  1.3633,  1.2476,  1.2609],
        [ 1.2572,  1.2590,  1.2011,  1.2761,  1.3243,  1.2956,  1.2647,  1.2884,
          1.2884,  2.1043,  2.1363,  2.0433,  2.3621,  2.0894,  5.3512,  2.1207,
          2.0373,  5.1401,  1.2608,  1.3156,  1.2665,  1.2292,  1.3108,  1.3072,
          1.2868,  1.3001,  1.3001,  1.3459,  1.1965,  1.3198,  1.3446,  1.2673,
          1.3314,  1.3605,  1.2819,  1.3223,  1.4572,  1.5080,  1.4334,  1.4271,
          1.4756,  1.4809,  1.4182,  1.0616,  1.3928,  1.2755,  1.3640,  1.3500,
          1.3349,  1.2269,  1.3576,  1.2666,  1.3248,  1.3390],
        [ 1.2137,  1.2414,  1.2955,  1.2764,  1.2469,  1.2186,  1.2269,  1.2115,
          1.2115,  1.2755,  1.3014,  1.2913,  1.3292,  1.2666,  1.3227,  1.2805,
          1.2190,  1.3167,  2.7786,  2.9496,  2.9974,  2.8204,  2.7260,  2.7453,
          2.9090,  2.7155,  2.7155,  1.2722,  1.3138,  1.2432,  1.2667,  1.2727,
          1.2546,  1.2835,  1.2508,  1.2457,  1.3888,  1.4368,  1.4164,  1.3469,
          1.4052,  1.4048,  1.4032,  1.3011,  1.2727,  1.3311,  1.2881,  1.2750,
          1.2603,  1.3268,  1.2819,  1.3644,  1.2455,  1.2637],
        [ 1.2251,  1.2528,  1.3064,  1.2877,  1.2584,  1.2300,  1.2385,  1.2229,
          1.2229,  1.2865,  1.3122,  1.3024,  1.3396,  1.2776,  1.2889,  1.2915,
          1.2735,  1.2416,  1.2749,  1.2956,  1.3152,  1.2881,  1.2470,  1.2419,
          1.2597,  1.2350,  1.2350,  3.0331,  3.0100,  2.6292,  2.7958,  3.0310,
          2.6391,  2.9842,  2.6390,  2.6314,  1.3994,  1.4475,  1.4279,  1.4067,
          1.4175,  1.4170,  1.4131,  1.2647,  1.3336,  1.3459,  1.2995,  1.1967,
          1.2246,  1.3426,  1.2930,  1.3782,  1.2114,  1.2752],
        [ 1.8588,  1.4479,  0.6280,  0.9084,  1.3010,  1.7543,  1.6486,  1.8675,
          1.8675,  1.7392,  1.3283,  1.5401,  0.9191,  1.7948,  0.1848,  1.6636,
          1.9054,  0.9148,  1.3315,  0.9534,  0.7331,  1.1600,  1.6929,  1.7636,
          1.5171,  1.8768,  1.8768,  0.8264,  0.8706,  1.8506,  1.6229,  0.8641,
          1.7823,  1.2336,  1.9031,  1.8120,  0.3169,  0.0923,  0.0752,  0.2679,
          0.5015,  0.5857,  0.2072, 15.9033,  4.8878,  0.7822,  1.3932,  1.5005,
          1.7377,  1.0165,  1.6496,  0.3614,  1.8281,  1.9088],
        [ 1.2990,  1.3271,  1.3849,  1.3632,  1.3333,  1.3040,  1.2674,  1.2968,
          1.2968,  1.2652,  1.3854,  1.2812,  1.4140,  1.3504,  1.4533,  1.2703,
          1.3467,  1.3112,  1.3493,  1.3594,  1.3913,  1.3628,  1.3210,  1.3158,
          1.2316,  1.3088,  1.3088,  1.3562,  1.4009,  1.3276,  1.1168,  1.3101,
          1.2022,  1.3677,  1.1994,  1.3302,  1.4664,  1.1627,  1.4784,  1.4783,
          1.0318,  0.9528,  1.4812,  1.3803,  0.8334,  3.4885,  2.6588,  3.6969,
          2.9590,  2.2452,  1.9439,  3.0589,  3.4212,  1.9288]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 308 : 181.04396627396812
Test loss for epoch 308 : 181.22011589256263
Test Precision for epoch 308 : 0.26153846153846155
Test Recall for epoch 308 : 0.26153846153846155
Test F1 for epoch 308 : 0.26153846153846155


theta for epoch 309 : tensor([[ 2.7377,  2.7637,  2.8297,  2.9667,  2.9343,  2.7422,  2.9148,  2.7358,
          2.7358,  1.2724,  1.2982,  1.2882,  1.3261,  1.2637,  1.3655,  1.2774,
          1.2600,  1.2712,  1.2594,  1.2392,  1.2546,  1.2726,  1.2317,  1.2267,
          1.2483,  1.2198,  1.2198,  1.2682,  1.3127,  1.2400,  1.2648,  1.3146,
          1.2513,  1.2801,  1.2017,  1.2425,  1.3869,  1.4347,  1.4161,  1.3985,
          1.4050,  1.3536,  1.4013,  1.3030,  1.3261,  1.3325,  1.2864,  1.2734,
          1.2587,  1.3292,  1.2802,  1.3646,  1.2488,  1.2622],
        [ 1.2568,  1.2601,  1.2033,  1.2756,  1.3228,  1.2942,  1.2640,  1.2869,
          1.2869,  2.1136,  2.1419,  2.0515,  2.3625,  2.0968,  5.3297,  2.1278,
          2.0472,  5.1180,  1.2598,  1.3136,  1.2662,  1.2284,  1.3087,  1.3051,
          1.2851,  1.2979,  1.2979,  1.3449,  1.1974,  1.3185,  1.3434,  1.2672,
          1.3302,  1.3592,  1.2806,  1.3211,  1.4563,  1.5070,  1.4325,  1.4273,
          1.4748,  1.4800,  1.4173,  1.0670,  1.3919,  1.2790,  1.3640,  1.3501,
          1.3350,  1.2301,  1.3576,  1.2700,  1.3248,  1.3391],
        [ 1.2141,  1.2418,  1.2957,  1.2767,  1.2472,  1.2190,  1.2273,  1.2119,
          1.2119,  1.2760,  1.3020,  1.2919,  1.3300,  1.2673,  1.3234,  1.2811,
          1.2193,  1.3177,  2.7776,  2.9497,  2.9959,  2.8180,  2.7260,  2.7441,
          2.9091,  2.7155,  2.7155,  1.2722,  1.3142,  1.2435,  1.2669,  1.2727,
          1.2549,  1.2838,  1.2511,  1.2461,  1.3892,  1.4373,  1.4168,  1.3469,
          1.4056,  1.4051,  1.4037,  1.3010,  1.2728,  1.3332,  1.2902,  1.2771,
          1.2624,  1.3291,  1.2840,  1.3665,  1.2474,  1.2659],
        [ 1.2249,  1.2527,  1.3061,  1.2876,  1.2583,  1.2299,  1.2384,  1.2228,
          1.2228,  1.2865,  1.3123,  1.3024,  1.3398,  1.2777,  1.2893,  1.2916,
          1.2734,  1.2422,  1.2741,  1.2946,  1.3144,  1.2874,  1.2462,  1.2411,
          1.2587,  1.2342,  1.2342,  3.0335,  3.0106,  2.6296,  2.7961,  3.0314,
          2.6395,  2.9843,  2.6395,  2.6318,  1.3995,  1.4477,  1.4281,  1.4065,
          1.4177,  1.4170,  1.4132,  1.2644,  1.3336,  1.3470,  1.3006,  1.1980,
          1.2256,  1.3437,  1.2941,  1.3793,  1.2122,  1.2763],
        [ 1.8585,  1.4470,  0.6275,  0.9089,  1.3019,  1.7550,  1.6488,  1.8682,
          1.8682,  1.7388,  1.3280,  1.5397,  0.9185,  1.7932,  0.1833,  1.6627,
          1.9062,  0.9121,  1.3311,  0.9544,  0.7330,  1.1596,  1.6931,  1.7637,
          1.5179,  1.8769,  1.8769,  0.8276,  0.8702,  1.8513,  1.6241,  0.8648,
          1.7830,  1.2345,  1.9038,  1.8128,  0.3151,  0.0906,  0.0734,  0.2664,
          0.4992,  0.5832,  0.2055, 15.9637,  4.8374,  0.7831,  1.3954,  1.5025,
          1.7397,  1.0170,  1.6517,  0.3621,  1.8310,  1.9107],
        [ 1.2978,  1.3260,  1.3838,  1.3620,  1.3321,  1.3028,  1.2661,  1.2956,
          1.2956,  1.2640,  1.3844,  1.2800,  1.4131,  1.3494,  1.4524,  1.2692,
          1.3455,  1.3103,  1.3470,  1.3563,  1.3889,  1.3604,  1.3187,  1.3135,
          1.2284,  1.3064,  1.3064,  1.3550,  1.3998,  1.3264,  1.1148,  1.3088,
          1.2009,  1.3665,  1.1981,  1.3290,  1.4658,  1.1618,  1.4771,  1.4776,
          1.0302,  0.9512,  1.4806,  1.3789,  0.8318,  3.4932,  2.6611,  3.7010,
          2.9614,  2.2474,  1.9462,  3.0613,  3.4261,  1.9311]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 309 : 181.02937087084624
Test loss for epoch 309 : 181.207826310255
Test Precision for epoch 309 : 0.26153846153846155
Test Recall for epoch 309 : 0.26153846153846155
Test F1 for epoch 309 : 0.26153846153846155


theta for epoch 310 : tensor([[ 2.7384,  2.7644,  2.8304,  2.9676,  2.9352,  2.7429,  2.9157,  2.7365,
          2.7365,  1.2724,  1.2983,  1.2882,  1.3263,  1.2639,  1.3657,  1.2776,
          1.2599,  1.2715,  1.2604,  1.2401,  1.2555,  1.2736,  1.2326,  1.2276,
          1.2492,  1.2207,  1.2207,  1.2682,  1.3127,  1.2400,  1.2648,  1.3146,
          1.2513,  1.2801,  1.2017,  1.2425,  1.3871,  1.4350,  1.4165,  1.3987,
          1.4054,  1.3540,  1.4016,  1.3026,  1.3265,  1.3305,  1.2844,  1.2714,
          1.2567,  1.3273,  1.2782,  1.3627,  1.2467,  1.2602],
        [ 1.2567,  1.2614,  1.2058,  1.2754,  1.3216,  1.2929,  1.2635,  1.2856,
          1.2856,  2.1230,  2.1478,  2.0598,  2.3633,  2.1043,  5.3081,  2.1352,
          2.0575,  5.0959,  1.2607,  1.3134,  1.2675,  1.2295,  1.3085,  1.3049,
          1.2854,  1.2977,  1.2977,  1.3440,  1.1987,  1.3174,  1.3424,  1.2671,
          1.3291,  1.3582,  1.2795,  1.3200,  1.4555,  1.5062,  1.4318,  1.4278,
          1.4742,  1.4793,  1.4164,  1.0725,  1.3912,  1.2794,  1.3607,  1.3468,
          1.3317,  1.2301,  1.3543,  1.2708,  1.3215,  1.3358],
        [ 1.2135,  1.2412,  1.2949,  1.2761,  1.2466,  1.2184,  1.2267,  1.2113,
          1.2113,  1.2755,  1.3015,  1.2914,  1.3296,  1.2669,  1.3230,  1.2807,
          1.2185,  1.3176,  2.7791,  2.9524,  2.9969,  2.8182,  2.7286,  2.7455,
          2.9119,  2.7181,  2.7181,  1.2715,  1.3139,  1.2431,  1.2665,  1.2719,
          1.2545,  1.2834,  1.2507,  1.2457,  1.3891,  1.4372,  1.4168,  1.3464,
          1.4056,  1.4049,  1.4036,  1.3005,  1.2723,  1.3302,  1.2872,  1.2741,
          1.2593,  1.3264,  1.2809,  1.3637,  1.2440,  1.2628],
        [ 1.2249,  1.2526,  1.3059,  1.2875,  1.2582,  1.2298,  1.2383,  1.2227,
          1.2227,  1.2866,  1.3125,  1.3025,  1.3400,  1.2779,  1.2897,  1.2917,
          1.2734,  1.2427,  1.2751,  1.2953,  1.3154,  1.2884,  1.2472,  1.2421,
          1.2595,  1.2352,  1.2352,  3.0343,  3.0114,  2.6302,  2.7966,  3.0322,
          2.6402,  2.9848,  2.6402,  2.6324,  1.3998,  1.4480,  1.4284,  1.4065,
          1.4181,  1.4172,  1.4135,  1.2643,  1.3337,  1.3453,  1.2989,  1.1966,
          1.2239,  1.3420,  1.2925,  1.3776,  1.2103,  1.2745],
        [ 1.8580,  1.4458,  0.6263,  0.9089,  1.3025,  1.7556,  1.6488,  1.8687,
          1.8687,  1.7381,  1.3274,  1.5390,  0.9173,  1.7913,  0.1810,  1.6616,
          1.9068,  0.9086,  1.3317,  0.9561,  0.7334,  1.1600,  1.6945,  1.7650,
          1.5196,  1.8782,  1.8782,  0.8283,  0.8693,  1.8519,  1.6251,  0.8648,
          1.7837,  1.2350,  1.9044,  1.8134,  0.3139,  0.0896,  0.0721,  0.2655,
          0.4976,  0.5813,  0.2043, 16.0250,  4.7871,  0.7805,  1.3942,  1.5010,
          1.7385,  1.0139,  1.6504,  0.3593,  1.8307,  1.9095],
        [ 1.2992,  1.3274,  1.3852,  1.3635,  1.3336,  1.3042,  1.2676,  1.2970,
          1.2970,  1.2657,  1.3861,  1.2818,  1.4149,  1.3511,  1.4542,  1.2710,
          1.3470,  1.3123,  1.3500,  1.3587,  1.3921,  1.3636,  1.3217,  1.3166,
          1.2309,  1.3095,  1.3095,  1.3566,  1.4013,  1.3280,  1.1160,  1.3104,
          1.2026,  1.3681,  1.1998,  1.3305,  1.4670,  1.1633,  1.4776,  1.4787,
          1.0312,  0.9523,  1.4818,  1.3795,  0.8328,  3.4921,  2.6572,  3.6988,
          2.9576,  2.2436,  1.9423,  3.0577,  3.4248,  1.9273]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 310 : 181.01487439661673
Test loss for epoch 310 : 181.19975016210861
Test Precision for epoch 310 : 0.26153846153846155
Test Recall for epoch 310 : 0.26153846153846155
Test F1 for epoch 310 : 0.26153846153846155


theta for epoch 311 : tensor([[ 2.7385,  2.7644,  2.8304,  2.9678,  2.9354,  2.7429,  2.9160,  2.7365,
          2.7365,  1.2725,  1.2984,  1.2883,  1.3265,  1.2640,  1.3659,  1.2777,
          1.2598,  1.2719,  1.2591,  1.2388,  1.2543,  1.2723,  1.2314,  1.2264,
          1.2479,  1.2194,  1.2194,  1.2681,  1.3126,  1.2399,  1.2647,  1.3145,
          1.2512,  1.2800,  1.2016,  1.2424,  1.3873,  1.4351,  1.4167,  1.3987,
          1.4056,  1.3542,  1.4017,  1.3022,  1.3266,  1.3328,  1.2867,  1.2737,
          1.2590,  1.3296,  1.2805,  1.3650,  1.2490,  1.2625],
        [ 1.2563,  1.2624,  1.2084,  1.2750,  1.3200,  1.2913,  1.2627,  1.2841,
          1.2841,  2.1321,  2.1534,  2.0677,  2.3640,  2.1114,  5.2859,  2.1423,
          2.0675,  5.0731,  1.2592,  1.3108,  1.2665,  1.2282,  1.3058,  1.3021,
          1.2833,  1.2949,  1.2949,  1.3427,  1.1999,  1.3160,  1.3410,  1.2668,
          1.3277,  1.3568,  1.2782,  1.3186,  1.4546,  1.5052,  1.4308,  1.4281,
          1.4733,  1.4784,  1.4154,  1.0780,  1.3902,  1.2840,  1.3618,  1.3479,
          1.3328,  1.2344,  1.3554,  1.2752,  1.3225,  1.3368],
        [ 1.2140,  1.2418,  1.2953,  1.2767,  1.2472,  1.2189,  1.2272,  1.2119,
          1.2119,  1.2763,  1.3024,  1.2922,  1.3306,  1.2678,  1.3238,  1.2815,
          1.2190,  1.3189,  2.7773,  2.9518,  2.9947,  2.8152,  2.7278,  2.7436,
          2.9113,  2.7172,  2.7172,  1.2717,  1.3145,  1.2436,  1.2669,  1.2721,
          1.2550,  1.2839,  1.2512,  1.2462,  1.3897,  1.4378,  1.4174,  1.3465,
          1.4062,  1.4053,  1.4042,  1.3006,  1.2725,  1.3338,  1.2908,  1.2777,
          1.2630,  1.3301,  1.2846,  1.3673,  1.2474,  1.2665],
        [ 1.2248,  1.2525,  1.3056,  1.2874,  1.2581,  1.2297,  1.2382,  1.2226,
          1.2226,  1.2866,  1.3126,  1.3025,  1.3402,  1.2781,  1.2902,  1.2919,
          1.2733,  1.2433,  1.2738,  1.2938,  1.3141,  1.2871,  1.2459,  1.2408,
          1.2580,  1.2339,  1.2339,  3.0345,  3.0117,  2.6304,  2.7966,  3.0324,
          2.6404,  2.9847,  2.6404,  2.6326,  1.3999,  1.4481,  1.4286,  1.4064,
          1.4183,  1.4172,  1.4136,  1.2642,  1.3337,  1.3472,  1.3008,  1.1988,
          1.2259,  1.3440,  1.2944,  1.3796,  1.2120,  1.2766],
        [ 1.8576,  1.4449,  0.6257,  0.9096,  1.3035,  1.7564,  1.6491,  1.8695,
          1.8695,  1.7376,  1.3272,  1.5386,  0.9167,  1.7895,  0.1796,  1.6607,
          1.9076,  0.9058,  1.3309,  0.9570,  0.7331,  1.1593,  1.6944,  1.7648,
          1.5200,  1.8780,  1.8780,  0.8297,  0.8689,  1.8527,  1.6263,  0.8655,
          1.7845,  1.2360,  1.9051,  1.8142,  0.3119,  0.0878,  0.0700,  0.2637,
          0.4951,  0.5786,  0.2024, 16.0859,  4.7354,  0.7825,  1.3975,  1.5041,
          1.7416,  1.0155,  1.6536,  0.3610,  1.8347,  1.9125],
        [ 1.2972,  1.3254,  1.3832,  1.3615,  1.3315,  1.3022,  1.2655,  1.2949,
          1.2949,  1.2637,  1.3842,  1.2797,  1.4131,  1.3493,  1.4525,  1.2690,
          1.3449,  1.3106,  1.3461,  1.3539,  1.3880,  1.3596,  1.3177,  1.3126,
          1.2260,  1.3055,  1.3055,  1.3545,  1.3994,  1.3259,  1.1130,  1.3083,
          1.2004,  1.3661,  1.1976,  1.3285,  1.4658,  1.1617,  1.4757,  1.4775,
          1.0289,  0.9499,  1.4806,  1.3777,  0.8304,  3.4986,  2.6613,  3.7047,
          2.9619,  2.2477,  1.9465,  3.0618,  3.4316,  1.9314]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 311 : 181.00056254042843
Test loss for epoch 311 : 181.18685779807325
Test Precision for epoch 311 : 0.26153846153846155
Test Recall for epoch 311 : 0.26153846153846155
Test F1 for epoch 311 : 0.26153846153846155


theta for epoch 312 : tensor([[ 2.7394,  2.7653,  2.8314,  2.9690,  2.9365,  2.7438,  2.9171,  2.7375,
          2.7375,  1.2725,  1.2985,  1.2884,  1.3268,  1.2642,  1.3662,  1.2778,
          1.2598,  1.2722,  1.2606,  1.2403,  1.2557,  1.2739,  1.2329,  1.2279,
          1.2494,  1.2209,  1.2209,  1.2681,  1.3127,  1.2399,  1.2647,  1.3146,
          1.2513,  1.2800,  1.2016,  1.2425,  1.3875,  1.4354,  1.4170,  1.3989,
          1.4060,  1.3546,  1.4020,  1.3019,  1.3270,  1.3293,  1.2832,  1.2702,
          1.2555,  1.3262,  1.2770,  1.3616,  1.2454,  1.2590],
        [ 1.2564,  1.2640,  1.2115,  1.2750,  1.3189,  1.2902,  1.2623,  1.2829,
          1.2829,  2.1417,  2.1597,  2.0761,  2.3653,  2.1189,  5.2638,  2.1497,
          2.0780,  5.0504,  1.2608,  1.3112,  1.2682,  1.2301,  1.3062,  1.3025,
          1.2843,  1.2953,  1.2953,  1.3417,  1.2015,  1.3149,  1.3399,  1.2666,
          1.3266,  1.3557,  1.2771,  1.3175,  1.4539,  1.5044,  1.4301,  1.4287,
          1.4726,  1.4778,  1.4146,  1.0838,  1.3895,  1.2831,  1.3569,  1.3430,
          1.3279,  1.2331,  1.3505,  1.2750,  1.3175,  1.3319],
        [ 1.2133,  1.2410,  1.2943,  1.2759,  1.2464,  1.2182,  1.2265,  1.2111,
          1.2111,  1.2755,  1.3016,  1.2914,  1.3300,  1.2671,  1.3232,  1.2808,
          1.2179,  1.3186,  2.7796,  2.9553,  2.9966,  2.8164,  2.7311,  2.7460,
          2.9148,  2.7206,  2.7206,  1.2707,  1.3140,  1.2430,  1.2662,  1.2711,
          1.2544,  1.2833,  1.2506,  1.2455,  1.3894,  1.4376,  1.4172,  1.3458,
          1.4060,  1.4050,  1.4040,  1.2999,  1.2719,  1.3288,  1.2857,  1.2725,
          1.2578,  1.3253,  1.2794,  1.3625,  1.2418,  1.2613],
        [ 1.2249,  1.2526,  1.3055,  1.2875,  1.2582,  1.2298,  1.2383,  1.2227,
          1.2227,  1.2867,  1.3128,  1.3026,  1.3404,  1.2783,  1.2907,  1.2920,
          1.2733,  1.2439,  1.2754,  1.2951,  1.3157,  1.2887,  1.2475,  1.2424,
          1.2593,  1.2355,  1.2355,  3.0354,  3.0127,  2.6312,  2.7972,  3.0333,
          2.6412,  2.9853,  2.6412,  2.6334,  1.4002,  1.4484,  1.4289,  1.4064,
          1.4188,  1.4175,  1.4138,  1.2642,  1.3339,  1.3443,  1.2979,  1.1962,
          1.2229,  1.3411,  1.2915,  1.3767,  1.2087,  1.2735],
        [ 1.8571,  1.4436,  0.6242,  0.9095,  1.3041,  1.7570,  1.6491,  1.8701,
          1.8701,  1.7368,  1.3264,  1.5377,  0.9153,  1.7873,  0.1768,  1.6595,
          1.9083,  0.9019,  1.3317,  0.9590,  0.7338,  1.1599,  1.6962,  1.7665,
          1.5221,  1.8798,  1.8798,  0.8301,  0.8676,  1.8534,  1.6273,  0.8652,
          1.7851,  1.2364,  1.9058,  1.8149,  0.3110,  0.0869,  0.0689,  0.2631,
          0.4937,  0.5769,  0.2015, 16.1480,  4.6845,  0.7784,  1.3948,  1.5011,
          1.7389,  1.0108,  1.6509,  0.3568,  1.8331,  1.9099],
        [ 1.2999,  1.3281,  1.3859,  1.3641,  1.3342,  1.3049,  1.2683,  1.2977,
          1.2977,  1.2667,  1.3871,  1.2827,  1.4161,  1.3522,  1.4554,  1.2720,
          1.3476,  1.3139,  1.3513,  1.3584,  1.3933,  1.3649,  1.3230,  1.3179,
          1.2308,  1.3107,  1.3107,  1.3572,  1.4021,  1.3286,  1.1155,  1.3111,
          1.2033,  1.3688,  1.2005,  1.3312,  1.4678,  1.1641,  1.4769,  1.4794,
          1.0310,  0.9522,  1.4826,  1.3792,  0.8326,  3.4950,  2.6548,  3.6997,
          2.9554,  2.2412,  1.9400,  3.0556,  3.4277,  1.9249]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 312 : 180.98708993212517
Test loss for epoch 312 : 181.18182582423074
Test Precision for epoch 312 : 0.26153846153846155
Test Recall for epoch 312 : 0.26153846153846155
Test F1 for epoch 312 : 0.26153846153846155


theta for epoch 313 : tensor([[ 2.7389,  2.7648,  2.8309,  2.9687,  2.9362,  2.7433,  2.9168,  2.7369,
          2.7369,  1.2727,  1.2988,  1.2885,  1.3271,  1.2645,  1.3665,  1.2780,
          1.2598,  1.2727,  1.2587,  1.2384,  1.2539,  1.2720,  1.2309,  1.2260,
          1.2474,  1.2190,  1.2190,  1.2681,  1.3127,  1.2399,  1.2647,  1.3145,
          1.2512,  1.2800,  1.2016,  1.2424,  1.3876,  1.4355,  1.4173,  1.3990,
          1.4062,  1.3548,  1.4021,  1.3015,  1.3272,  1.3335,  1.2875,  1.2744,
          1.2598,  1.3304,  1.2813,  1.3658,  1.2496,  1.2633],
        [ 1.2558,  1.2649,  1.2142,  1.2744,  1.3170,  1.2882,  1.2612,  1.2810,
          1.2810,  2.1506,  2.1655,  2.0839,  2.3664,  2.1257,  5.2408,  2.1567,
          2.0881,  5.0269,  1.2585,  1.3077,  1.2662,  1.2282,  1.3024,  1.2987,
          1.2812,  1.2915,  1.2915,  1.3402,  1.2030,  1.3133,  1.3383,  1.2661,
          1.3250,  1.3542,  1.2755,  1.3159,  1.4527,  1.5032,  1.4290,  1.4289,
          1.4716,  1.4767,  1.4134,  1.0894,  1.3884,  1.2894,  1.3597,  1.3458,
          1.3307,  1.2392,  1.3533,  1.2810,  1.3203,  1.3347],
        [ 1.2141,  1.2419,  1.2950,  1.2768,  1.2473,  1.2190,  1.2273,  1.2120,
          1.2120,  1.2767,  1.3030,  1.2927,  1.3315,  1.2685,  1.3245,  1.2821,
          1.2190,  1.3203,  2.7766,  2.9534,  2.9931,  2.8121,  2.7290,  2.7428,
          2.9130,  2.7184,  2.7184,  1.2712,  1.3149,  1.2438,  1.2670,  1.2716,
          1.2552,  1.2842,  1.2515,  1.2464,  1.3902,  1.4384,  1.4180,  1.3462,
          1.4068,  1.4056,  1.4048,  1.3003,  1.2724,  1.3351,  1.2920,  1.2789,
          1.2642,  1.3317,  1.2858,  1.3687,  1.2479,  1.2677],
        [ 1.2245,  1.2523,  1.3050,  1.2872,  1.2578,  1.2294,  1.2379,  1.2223,
          1.2223,  1.2867,  1.3129,  1.3027,  1.3406,  1.2784,  1.2912,  1.2921,
          1.2732,  1.2446,  1.2733,  1.2928,  1.3136,  1.2866,  1.2453,  1.2403,
          1.2570,  1.2333,  1.2333,  3.0354,  3.0127,  2.6312,  2.7970,  3.0334,
          2.6412,  2.9850,  2.6412,  2.6334,  1.4002,  1.4485,  1.4290,  1.4061,
          1.4189,  1.4174,  1.4138,  1.2640,  1.3338,  1.3477,  1.3014,  1.1999,
          1.2264,  1.3446,  1.2950,  1.3801,  1.2120,  1.2771],
        [ 1.8567,  1.4428,  0.6239,  0.9103,  1.3053,  1.7579,  1.6493,  1.8709,
          1.8709,  1.7363,  1.3264,  1.5374,  0.9151,  1.7855,  0.1757,  1.6587,
          1.9092,  0.8993,  1.3306,  0.9597,  0.7335,  1.1589,  1.6957,  1.7660,
          1.5222,  1.8792,  1.8792,  0.8319,  0.8675,  1.8543,  1.6288,  0.8663,
          1.7861,  1.2377,  1.9067,  1.8158,  0.3085,  0.0846,  0.0664,  0.2609,
          0.4907,  0.5736,  0.1991, 16.2091,  4.6314,  0.7824,  1.4001,  1.5062,
          1.7439,  1.0146,  1.6560,  0.3605,  1.8391,  1.9147],
        [ 1.2961,  1.3243,  1.3822,  1.3604,  1.3305,  1.3011,  1.2644,  1.2939,
          1.2939,  1.2629,  1.3836,  1.2790,  1.4128,  1.3488,  1.4522,  1.2683,
          1.3440,  1.3105,  1.3445,  1.3508,  1.3865,  1.3581,  1.3161,  1.3111,
          1.2229,  1.3039,  1.3039,  1.3536,  1.3986,  1.3250,  1.1107,  1.3074,
          1.1995,  1.3652,  1.1966,  1.3276,  1.4655,  1.1612,  1.4738,  1.4771,
          1.0271,  0.9482,  1.4804,  1.3762,  0.8286,  3.5049,  2.6624,  3.7089,
          2.9631,  2.2487,  1.9476,  3.0630,  3.4380,  1.9326]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 313 : 180.97442341562092
Test loss for epoch 313 : 181.16848416325445
Test Precision for epoch 313 : 0.26153846153846155
Test Recall for epoch 313 : 0.26153846153846155
Test F1 for epoch 313 : 0.26153846153846155


theta for epoch 314 : tensor([[ 2.7405,  2.7665,  2.8325,  2.9705,  2.9380,  2.7449,  2.9186,  2.7386,
          2.7386,  1.2726,  1.2987,  1.2885,  1.3272,  1.2645,  1.3666,  1.2780,
          1.2596,  1.2730,  1.2611,  1.2407,  1.2562,  1.2744,  1.2333,  1.2284,
          1.2498,  1.2214,  1.2214,  1.2680,  1.3127,  1.2399,  1.2647,  1.3145,
          1.2512,  1.2800,  1.2016,  1.2424,  1.3880,  1.4359,  1.4177,  1.3992,
          1.4067,  1.3553,  1.4024,  1.3012,  1.3277,  1.3272,  1.2811,  1.2681,
          1.2534,  1.3241,  1.2749,  1.3596,  1.2432,  1.2569],
        [ 1.2564,  1.2668,  1.2181,  1.2749,  1.3162,  1.2874,  1.2613,  1.2801,
          1.2801,  2.1603,  2.1721,  2.0924,  2.3683,  2.1331,  5.2182,  2.1643,
          2.0989,  5.0037,  1.2614,  1.3094,  1.2689,  1.2314,  1.3040,  1.3003,
          1.2835,  1.2931,  1.2931,  1.3392,  1.2051,  1.3123,  1.3372,  1.2661,
          1.3240,  1.3532,  1.2745,  1.3149,  1.4521,  1.5026,  1.4284,  1.4297,
          1.4711,  1.4762,  1.4127,  1.0957,  1.3879,  1.2861,  1.3521,  1.3382,
          1.3231,  1.2354,  1.3457,  1.2789,  1.3126,  1.3271],
        [ 1.2130,  1.2407,  1.2937,  1.2756,  1.2461,  1.2179,  1.2262,  1.2108,
          1.2108,  1.2753,  1.3016,  1.2913,  1.3302,  1.2672,  1.3233,  1.2808,
          1.2172,  1.3195,  2.7805,  2.9586,  2.9966,  2.8149,  2.7339,  2.7467,
          2.9182,  2.7233,  2.7233,  1.2698,  1.3139,  1.2428,  1.2659,  1.2702,
          1.2542,  1.2831,  1.2504,  1.2453,  1.3898,  1.4380,  1.4176,  1.3452,
          1.4065,  1.4050,  1.4043,  1.2994,  1.2715,  1.3263,  1.2831,  1.2700,
          1.2553,  1.3231,  1.2769,  1.3601,  1.2386,  1.2588],
        [ 1.2249,  1.2526,  1.3051,  1.2875,  1.2582,  1.2298,  1.2383,  1.2227,
          1.2227,  1.2869,  1.3131,  1.3029,  1.3409,  1.2787,  1.2918,  1.2924,
          1.2733,  1.2453,  1.2760,  1.2952,  1.3163,  1.2894,  1.2481,  1.2431,
          1.2594,  1.2361,  1.2361,  3.0365,  3.0138,  2.6322,  2.7977,  3.0344,
          2.6422,  2.9857,  2.6423,  2.6344,  1.4007,  1.4490,  1.4296,  1.4063,
          1.4195,  1.4178,  1.4143,  1.2643,  1.3341,  1.3425,  1.2962,  1.1951,
          1.2211,  1.3395,  1.2899,  1.3751,  1.2064,  1.2718],
        [ 1.8562,  1.4414,  0.6219,  0.9099,  1.3057,  1.7586,  1.6493,  1.8716,
          1.8716,  1.7352,  1.3254,  1.5362,  0.9132,  1.7829,  0.1721,  1.6572,
          1.9098,  0.8948,  1.3318,  0.9621,  0.7345,  1.1598,  1.6982,  1.7684,
          1.5249,  1.8817,  1.8817,  0.8319,  0.8655,  1.8549,  1.6297,  0.8655,
          1.7867,  1.2377,  1.9073,  1.8164,  0.3080,  0.0843,  0.0657,  0.2607,
          0.4898,  0.5725,  0.1987, 16.2723,  4.5800,  0.7757,  1.3947,  1.5005,
          1.7387,  1.0069,  1.6507,  0.3536,  1.8349,  1.9096],
        [ 1.3012,  1.3294,  1.3871,  1.3654,  1.3355,  1.3062,  1.2696,  1.2990,
          1.2990,  1.2682,  1.3886,  1.2843,  1.4180,  1.3539,  1.4573,  1.2737,
          1.3488,  1.3162,  1.3536,  1.3592,  1.3957,  1.3673,  1.3253,  1.3202,
          1.2317,  1.3131,  1.3131,  1.3585,  1.4034,  1.3299,  1.1156,  1.3124,
          1.2047,  1.3700,  1.2019,  1.3325,  1.4691,  1.1656,  1.4766,  1.4805,
          1.0312,  0.9526,  1.4839,  1.3793,  0.8330,  3.4967,  2.6510,  3.6991,
          2.9519,  2.2376,  1.9364,  3.0522,  3.4294,  1.9213]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 314 : 180.96518474065823
Test loss for epoch 314 : 181.17117436562762
Test Precision for epoch 314 : 0.26153846153846155
Test Recall for epoch 314 : 0.26153846153846155
Test F1 for epoch 314 : 0.26153846153846155


theta for epoch 315 : tensor([[ 2.7390,  2.7650,  2.8311,  2.9692,  2.9367,  2.7434,  2.9173,  2.7371,
          2.7371,  1.2731,  1.2993,  1.2890,  1.3279,  1.2652,  1.3674,  1.2786,
          1.2600,  1.2739,  1.2579,  1.2375,  1.2531,  1.2712,  1.2301,  1.2252,
          1.2465,  1.2182,  1.2182,  1.2682,  1.3129,  1.2401,  1.2648,  1.3147,
          1.2514,  1.2802,  1.2018,  1.2426,  1.3882,  1.4361,  1.4180,  1.3994,
          1.4069,  1.3556,  1.4026,  1.3009,  1.3279,  1.3347,  1.2887,  1.2756,
          1.2610,  1.3317,  1.2825,  1.3670,  1.2508,  1.2646],
        [ 1.2554,  1.2673,  1.2209,  1.2739,  1.3138,  1.2849,  1.2599,  1.2776,
          1.2776,  2.1690,  2.1780,  2.1000,  2.3696,  2.1396,  5.1945,  2.1711,
          2.1090,  4.9795,  1.2575,  1.3042,  1.2652,  1.2280,  1.2985,  1.2947,
          1.2788,  1.2875,  1.2875,  1.3376,  1.2068,  1.3106,  1.3354,  1.2656,
          1.3223,  1.3516,  1.2728,  1.3132,  1.4508,  1.5012,  1.4271,  1.4298,
          1.4699,  1.4749,  1.4113,  1.1016,  1.3865,  1.2953,  1.3579,  1.3440,
          1.3290,  1.2445,  1.3515,  1.2874,  1.3184,  1.3330],
        [ 1.2144,  1.2421,  1.2948,  1.2769,  1.2474,  1.2192,  1.2275,  1.2122,
          1.2122,  1.2776,  1.3039,  1.2936,  1.3327,  1.2697,  1.3257,  1.2831,
          1.2193,  1.3222,  2.7752,  2.9545,  2.9910,  2.8086,  2.7294,  2.7413,
          2.9141,  2.7188,  2.7188,  1.2711,  1.3155,  1.2443,  1.2674,  1.2715,
          1.2557,  1.2847,  1.2519,  1.2469,  1.3911,  1.4393,  1.4189,  1.3461,
          1.4077,  1.4061,  1.4056,  1.3002,  1.2725,  1.3371,  1.2941,  1.2810,
          1.2664,  1.3341,  1.2879,  1.3709,  1.2494,  1.2699],
        [ 1.2242,  1.2520,  1.3043,  1.2869,  1.2575,  1.2291,  1.2376,  1.2220,
          1.2220,  1.2870,  1.3133,  1.3030,  1.3412,  1.2790,  1.2924,  1.2925,
          1.2733,  1.2461,  1.2723,  1.2913,  1.3127,  1.2857,  1.2444,  1.2394,
          1.2555,  1.2324,  1.2324,  3.0362,  3.0134,  2.6318,  2.7970,  3.0341,
          2.6418,  2.9851,  2.6419,  2.6340,  1.4007,  1.4490,  1.4296,  1.4059,
          1.4195,  1.4176,  1.4143,  1.2642,  1.3339,  1.3486,  1.3023,  1.2014,
          1.2273,  1.3456,  1.2959,  1.3811,  1.2123,  1.2781],
        [ 1.8556,  1.4406,  0.6219,  0.9110,  1.3070,  1.7594,  1.6494,  1.8723,
          1.8723,  1.7349,  1.3259,  1.5362,  0.9137,  1.7812,  0.1717,  1.6567,
          1.9110,  0.8927,  1.3298,  0.9622,  0.7339,  1.1579,  1.6968,  1.7669,
          1.5241,  1.8802,  1.8802,  0.8344,  0.8660,  1.8561,  1.6315,  0.8672,
          1.7879,  1.2395,  1.9084,  1.8176,  0.3048,  0.0813,  0.0625,  0.2578,
          0.4860,  0.5684,  0.1956, 16.3334,  4.5253,  0.7832,  1.4034,  1.5088,
          1.7469,  1.0143,  1.6591,  0.3608,  1.8442,  1.9175],
        [ 1.2944,  1.3226,  1.3805,  1.3587,  1.3288,  1.2994,  1.2627,  1.2922,
          1.2922,  1.2616,  1.3825,  1.2777,  1.4121,  1.3479,  1.4516,  1.2672,
          1.3425,  1.3101,  1.3419,  1.3465,  1.3838,  1.3554,  1.3135,  1.3084,
          1.2186,  1.3013,  1.3013,  1.3522,  1.3974,  1.3237,  1.1077,  1.3061,
          1.1980,  1.3639,  1.1951,  1.3262,  1.4650,  1.1603,  1.4717,  1.4764,
          1.0249,  0.9460,  1.4799,  1.3745,  0.8263,  3.5124,  2.6645,  3.7141,
          2.9654,  2.2510,  1.9500,  3.0653,  3.4457,  1.9349]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 315 : 180.95674454976833
Test loss for epoch 315 : 181.15840366269822
Test Precision for epoch 315 : 0.26153846153846155
Test Recall for epoch 315 : 0.26153846153846155
Test F1 for epoch 315 : 0.26153846153846155


theta for epoch 316 : tensor([[ 2.7417,  2.7677,  2.8338,  2.9721,  2.9396,  2.7462,  2.9202,  2.7398,
          2.7398,  1.2728,  1.2990,  1.2887,  1.3277,  1.2650,  1.3672,  1.2783,
          1.2595,  1.2739,  1.2618,  1.2414,  1.2569,  1.2751,  1.2340,  1.2291,
          1.2505,  1.2221,  1.2221,  1.2681,  1.3128,  1.2400,  1.2648,  1.3146,
          1.2513,  1.2801,  1.2016,  1.2425,  1.3886,  1.4366,  1.4185,  1.3996,
          1.4075,  1.3562,  1.4030,  1.3006,  1.3285,  1.3240,  1.2779,  1.2649,
          1.2503,  1.3210,  1.2718,  1.3565,  1.2399,  1.2538],
        [ 1.2568,  1.2701,  1.2258,  1.2752,  1.3138,  1.2848,  1.2609,  1.2776,
          1.2776,  2.1787,  2.1850,  2.1086,  2.3722,  2.1470,  5.1714,  2.1789,
          2.1202,  4.9559,  1.2627,  1.3080,  1.2697,  1.2336,  1.3023,  1.2984,
          1.2833,  1.2912,  1.2912,  1.3368,  1.2094,  1.3098,  1.3346,  1.2659,
          1.3215,  1.3507,  1.2720,  1.3124,  1.4504,  1.5008,  1.4268,  1.4309,
          1.4697,  1.4747,  1.4109,  1.1084,  1.3863,  1.2880,  1.3461,  1.3322,
          1.3171,  1.2367,  1.3397,  1.2821,  1.3065,  1.3211],
        [ 1.2127,  1.2404,  1.2928,  1.2752,  1.2457,  1.2175,  1.2258,  1.2104,
          1.2104,  1.2750,  1.3014,  1.2910,  1.3303,  1.2672,  1.3234,  1.2806,
          1.2163,  1.3202,  2.7820,  2.9625,  2.9973,  2.8142,  2.7371,  2.7480,
          2.9221,  2.7265,  2.7265,  1.2688,  1.3138,  1.2425,  1.2655,  1.2692,
          1.2539,  1.2828,  1.2501,  1.2450,  1.3901,  1.4384,  1.4179,  1.3445,
          1.4068,  1.4049,  1.4046,  1.2987,  1.2710,  1.3223,  1.2792,  1.2661,
          1.2514,  1.3195,  1.2730,  1.3564,  1.2340,  1.2549],
        [ 1.2252,  1.2529,  1.3049,  1.2878,  1.2584,  1.2300,  1.2385,  1.2230,
          1.2230,  1.2873,  1.3135,  1.3033,  1.3415,  1.2794,  1.2931,  1.2929,
          1.2734,  1.2470,  1.2770,  1.2955,  1.3173,  1.2904,  1.2491,  1.2441,
          1.2599,  1.2371,  1.2371,  3.0375,  3.0147,  2.6332,  2.7981,  3.0355,
          2.6431,  2.9861,  2.6433,  2.6354,  1.4015,  1.4498,  1.4304,  1.4063,
          1.4205,  1.4183,  1.4150,  1.2647,  1.3346,  1.3399,  1.2936,  1.1932,
          1.2185,  1.3369,  1.2874,  1.3725,  1.2031,  1.2692],
        [ 1.8553,  1.4392,  0.6194,  0.9103,  1.3075,  1.7604,  1.6494,  1.8734,
          1.8734,  1.7334,  1.3244,  1.5346,  0.9113,  1.7783,  0.1671,  1.6549,
          1.9115,  0.8875,  1.3319,  0.9653,  0.7355,  1.1595,  1.7004,  1.7706,
          1.5278,  1.8839,  1.8839,  0.8338,  0.8633,  1.8566,  1.6322,  0.8658,
          1.7885,  1.2391,  1.9090,  1.8182,  0.3050,  0.0817,  0.0625,  0.2584,
          0.4859,  0.5680,  0.1959, 16.3979,  4.4739,  0.7723,  1.3937,  1.4989,
          1.7375,  1.0022,  1.6496,  0.3499,  1.8361,  1.9084],
        [ 1.3033,  1.3315,  1.3892,  1.3674,  1.3375,  1.3082,  1.2717,  1.3011,
          1.3011,  1.2705,  1.3910,  1.2866,  1.4206,  1.3564,  1.4599,  1.2761,
          1.3507,  1.3194,  1.3571,  1.3611,  1.3992,  1.3708,  1.3288,  1.3238,
          1.2338,  1.3166,  1.3166,  1.3605,  1.4054,  1.3319,  1.1165,  1.3145,
          1.2069,  1.3721,  1.2041,  1.3345,  1.4709,  1.1678,  1.4768,  1.4822,
          1.0323,  0.9539,  1.4858,  1.3799,  0.8341,  3.4973,  2.6460,  3.6969,
          2.9470,  2.2328,  1.9316,  3.0476,  3.4298,  1.9165]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 316 : 180.9577688044081
Test loss for epoch 316 : 181.17653107025046
Test Precision for epoch 316 : 0.26153846153846155
Test Recall for epoch 316 : 0.26153846153846155
Test F1 for epoch 316 : 0.26153846153846155


theta for epoch 317 : tensor([[ 2.7389,  2.7650,  2.8311,  2.9695,  2.9371,  2.7434,  2.9176,  2.7370,
          2.7370,  1.2739,  1.3002,  1.2899,  1.3291,  1.2663,  1.3687,  1.2795,
          1.2605,  1.2756,  1.2567,  1.2364,  1.2520,  1.2701,  1.2289,  1.2240,
          1.2453,  1.2170,  1.2170,  1.2687,  1.3135,  1.2406,  1.2654,  1.3152,
          1.2519,  1.2807,  1.2023,  1.2431,  1.3890,  1.4369,  1.4190,  1.4000,
          1.4079,  1.3566,  1.4034,  1.3005,  1.3289,  1.3355,  1.2897,  1.2766,
          1.2621,  1.3327,  1.2836,  1.3679,  1.2517,  1.2656],
        [ 1.2552,  1.2700,  1.2284,  1.2737,  1.3107,  1.2816,  1.2589,  1.2744,
          1.2744,  2.1874,  2.1911,  2.1161,  2.3740,  2.1533,  5.1472,  2.1857,
          2.1305,  4.9310,  1.2563,  1.3003,  1.2635,  1.2279,  1.2941,  1.2902,
          1.2761,  1.2829,  1.2829,  1.3350,  1.2113,  1.3079,  1.3326,  1.2654,
          1.3196,  1.3489,  1.2701,  1.3105,  1.4489,  1.4992,  1.4253,  1.4309,
          1.4681,  1.4731,  1.4093,  1.1146,  1.3847,  1.3006,  1.3556,  1.3417,
          1.3268,  1.2494,  1.3493,  1.2935,  1.3161,  1.3308],
        [ 1.2150,  1.2427,  1.2949,  1.2775,  1.2480,  1.2198,  1.2281,  1.2128,
          1.2128,  1.2790,  1.3055,  1.2951,  1.3345,  1.2714,  1.3274,  1.2847,
          1.2202,  1.3247,  2.7732,  2.9550,  2.9884,  2.8046,  2.7291,  2.7392,
          2.9146,  2.7185,  2.7185,  1.2712,  1.3165,  1.2452,  1.2681,  1.2717,
          1.2566,  1.2855,  1.2528,  1.2477,  1.3922,  1.4404,  1.4200,  1.3462,
          1.4088,  1.4067,  1.4067,  1.3004,  1.2728,  1.3390,  1.2962,  1.2831,
          1.2685,  1.3363,  1.2901,  1.3728,  1.2508,  1.2721],
        [ 1.2241,  1.2518,  1.3037,  1.2868,  1.2574,  1.2290,  1.2375,  1.2219,
          1.2219,  1.2876,  1.3139,  1.3036,  1.3420,  1.2798,  1.2941,  1.2932,
          1.2735,  1.2480,  1.2710,  1.2894,  1.3114,  1.2844,  1.2430,  1.2381,
          1.2535,  1.2310,  1.2310,  3.0369,  3.0139,  2.6325,  2.7970,  3.0348,
          2.6424,  2.9850,  2.6427,  2.6346,  1.4014,  1.4497,  1.4304,  1.4059,
          1.4204,  1.4180,  1.4148,  1.2645,  1.3342,  1.3490,  1.3029,  1.2027,
          1.2279,  1.3461,  1.2965,  1.3816,  1.2123,  1.2787],
        [ 1.8546,  1.4387,  0.6201,  0.9119,  1.3091,  1.7613,  1.6495,  1.8741,
          1.8741,  1.7334,  1.3256,  1.5351,  0.9128,  1.7769,  0.1680,  1.6548,
          1.9132,  0.8864,  1.3286,  0.9647,  0.7343,  1.1565,  1.6976,  1.7676,
          1.5257,  1.8809,  1.8809,  0.8372,  0.8645,  1.8582,  1.6344,  0.8684,
          1.7901,  1.2416,  1.9105,  1.8198,  0.3009,  0.0778,  0.0584,  0.2546,
          0.4811,  0.5628,  0.1919, 16.4587,  4.4173,  0.7841,  1.4066,  1.5114,
          1.7498,  1.0141,  1.6620,  0.3614,  1.8493,  1.9202],
        [ 1.2927,  1.3209,  1.3788,  1.3570,  1.3270,  1.2977,  1.2609,  1.2905,
          1.2905,  1.2603,  1.3815,  1.2765,  1.4113,  1.3470,  1.4509,  1.2661,
          1.3410,  1.3097,  1.3390,  1.3418,  1.3808,  1.3525,  1.3106,  1.3056,
          1.2140,  1.2984,  1.2984,  1.3507,  1.3961,  1.3222,  1.1047,  1.3046,
          1.1965,  1.3625,  1.1936,  1.3248,  1.4645,  1.1595,  1.4695,  1.4756,
          1.0225,  0.9438,  1.4794,  1.3726,  0.8239,  3.5201,  2.6668,  3.7191,
          2.9677,  2.2534,  1.9525,  3.0676,  3.4535,  1.9374]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 317 : 180.94774689930398
Test loss for epoch 317 : 181.1574290060176
Test Precision for epoch 317 : 0.26153846153846155
Test Recall for epoch 317 : 0.26153846153846155
Test F1 for epoch 317 : 0.26153846153846155


theta for epoch 318 : tensor([[ 2.7425,  2.7686,  2.8347,  2.9732,  2.9408,  2.7470,  2.9213,  2.7406,
          2.7406,  1.2730,  1.2993,  1.2890,  1.3283,  1.2655,  1.3679,  1.2787,
          1.2594,  1.2750,  1.2625,  1.2420,  1.2576,  1.2758,  1.2347,  1.2298,
          1.2510,  1.2228,  1.2228,  1.2682,  1.3130,  1.2402,  1.2650,  1.3148,
          1.2515,  1.2802,  1.2018,  1.2427,  1.3894,  1.4375,  1.4196,  1.4003,
          1.4086,  1.3573,  1.4039,  1.3002,  1.3295,  1.3217,  1.2758,  1.2627,
          1.2482,  1.3188,  1.2696,  1.3542,  1.2377,  1.2517],
        [ 1.2575,  1.2735,  1.2343,  1.2759,  1.3114,  1.2823,  1.2608,  1.2751,
          1.2751,  2.1967,  2.1981,  2.1243,  2.3768,  2.1602,  5.1233,  2.1933,
          2.1417,  4.9066,  1.2641,  1.3066,  1.2702,  1.2363,  1.3005,  1.2965,
          1.2834,  1.2892,  1.2892,  1.3343,  1.2145,  1.3073,  1.3320,  1.2661,
          1.3190,  1.3483,  1.2695,  1.3099,  1.4489,  1.4992,  1.4254,  1.4324,
          1.4684,  1.4733,  1.4093,  1.1222,  1.3849,  1.2906,  1.3409,  1.3271,
          1.3121,  1.2388,  1.3346,  1.2859,  1.3013,  1.3160],
        [ 1.2122,  1.2399,  1.2919,  1.2747,  1.2452,  1.2171,  1.2254,  1.2100,
          1.2100,  1.2746,  1.3011,  1.2907,  1.3303,  1.2671,  1.3234,  1.2803,
          1.2153,  1.3210,  2.7831,  2.9661,  2.9979,  2.8134,  2.7399,  2.7491,
          2.9258,  2.7293,  2.7293,  1.2677,  1.3136,  1.2421,  1.2650,  1.2682,
          1.2535,  1.2825,  1.2498,  1.2447,  1.3905,  1.4388,  1.4184,  1.3439,
          1.4073,  1.4049,  1.4051,  1.2981,  1.2706,  1.3198,  1.2769,  1.2638,
          1.2492,  1.3174,  1.2707,  1.3539,  1.2310,  1.2527],
        [ 1.2256,  1.2532,  1.3047,  1.2881,  1.2587,  1.2304,  1.2389,  1.2233,
          1.2233,  1.2877,  1.3140,  1.3037,  1.3422,  1.2801,  1.2947,  1.2934,
          1.2735,  1.2488,  1.2779,  1.2958,  1.3182,  1.2913,  1.2500,  1.2451,
          1.2602,  1.2380,  1.2380,  3.0383,  3.0152,  2.6338,  2.7980,  3.0362,
          2.6438,  2.9860,  2.6441,  2.6360,  1.4025,  1.4508,  1.4316,  1.4065,
          1.4216,  1.4190,  1.4159,  1.2653,  1.3352,  1.3378,  1.2917,  1.1922,
          1.2166,  1.3349,  1.2855,  1.3706,  1.2006,  1.2673],
        [ 1.8543,  1.4372,  0.6170,  0.9108,  1.3094,  1.7623,  1.6493,  1.8752,
          1.8752,  1.7312,  1.3234,  1.5328,  0.9095,  1.7734,  0.1622,  1.6523,
          1.9131,  0.8803,  1.3318,  0.9687,  0.7367,  1.1589,  1.7025,  1.7726,
          1.5305,  1.8861,  1.8861,  0.8357,  0.8608,  1.8584,  1.6346,  0.8661,
          1.7903,  1.2405,  1.9108,  1.8200,  0.3019,  0.0789,  0.0591,  0.2559,
          0.4817,  0.5631,  0.1929, 16.5244,  4.3659,  0.7701,  1.3937,  1.4982,
          1.7374,  0.9988,  1.6494,  0.3474,  1.8382,  1.9082],
        [ 1.3048,  1.3329,  1.3905,  1.3688,  1.3389,  1.3097,  1.2732,  1.3025,
          1.3025,  1.2719,  1.3923,  1.2881,  1.4222,  1.3580,  1.4617,  1.2777,
          1.3517,  1.3216,  1.3597,  1.3620,  1.4017,  1.3734,  1.3314,  1.3265,
          1.2350,  1.3193,  1.3193,  1.3617,  1.4067,  1.3332,  1.1166,  1.3159,
          1.2083,  1.3733,  1.2055,  1.3358,  1.4725,  1.1696,  1.4767,  1.4836,
          1.0329,  0.9546,  1.4874,  1.3801,  0.8347,  3.4999,  2.6432,  3.6967,
          2.9443,  2.2302,  1.9291,  3.0449,  3.4325,  1.9140]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 318 : 180.9455619627114
Test loss for epoch 318 : 181.1764799836397
Test Precision for epoch 318 : 0.26153846153846155
Test Recall for epoch 318 : 0.26153846153846155
Test F1 for epoch 318 : 0.26153846153846155


theta for epoch 319 : tensor([[ 2.7395,  2.7656,  2.8317,  2.9704,  2.9380,  2.7439,  2.9185,  2.7376,
          2.7376,  1.2747,  1.3011,  1.2907,  1.3303,  1.2675,  1.3700,  1.2805,
          1.2610,  1.2772,  1.2560,  1.2356,  1.2513,  1.2694,  1.2281,  1.2233,
          1.2445,  1.2162,  1.2162,  1.2692,  1.3140,  1.2411,  1.2659,  1.3157,
          1.2524,  1.2812,  1.2027,  1.2436,  1.3898,  1.4377,  1.4200,  1.4006,
          1.4089,  1.3576,  1.4042,  1.2999,  1.3299,  1.3344,  1.2887,  1.2756,
          1.2611,  1.3316,  1.2826,  1.3668,  1.2506,  1.2647],
        [ 1.2553,  1.2727,  1.2365,  1.2738,  1.3077,  1.2785,  1.2584,  1.2712,
          1.2712,  2.2060,  2.2052,  2.1324,  2.3797,  2.1670,  5.0990,  2.2007,
          2.1529,  4.8819,  1.2560,  1.2972,  1.2622,  1.2290,  1.2904,  1.2863,
          1.2744,  1.2790,  1.2790,  1.3324,  1.2165,  1.3052,  1.3299,  1.2656,
          1.3169,  1.3463,  1.2675,  1.3078,  1.4469,  1.4972,  1.4235,  1.4321,
          1.4664,  1.4714,  1.4073,  1.1284,  1.3829,  1.3037,  1.3512,  1.3374,
          1.3224,  1.2521,  1.3449,  1.2979,  1.3116,  1.3264],
        [ 1.2153,  1.2430,  1.2947,  1.2778,  1.2483,  1.2201,  1.2284,  1.2130,
          1.2130,  1.2802,  1.3067,  1.2963,  1.3360,  1.2729,  1.3289,  1.2859,
          1.2208,  1.3270,  2.7725,  2.9567,  2.9870,  2.8019,  2.7298,  2.7383,
          2.9163,  2.7193,  2.7193,  1.2711,  1.3173,  1.2458,  1.2686,  1.2716,
          1.2572,  1.2862,  1.2534,  1.2484,  1.3930,  1.4412,  1.4209,  1.3460,
          1.4097,  1.4070,  1.4076,  1.3002,  1.2728,  1.3385,  1.2959,  1.2829,
          1.2684,  1.3361,  1.2899,  1.3723,  1.2500,  1.2720],
        [ 1.2242,  1.2519,  1.3031,  1.2867,  1.2573,  1.2290,  1.2375,  1.2219,
          1.2219,  1.2883,  1.3147,  1.3043,  1.3429,  1.2808,  1.2959,  1.2940,
          1.2739,  1.2502,  1.2703,  1.2880,  1.3107,  1.2837,  1.2422,  1.2374,
          1.2522,  1.2303,  1.2303,  3.0379,  3.0146,  2.6334,  2.7971,  3.0358,
          2.6433,  2.9851,  2.6437,  2.6356,  1.4021,  1.4504,  1.4313,  1.4058,
          1.4213,  1.4184,  1.4155,  1.2649,  1.3345,  1.3478,  1.3018,  1.2025,
          1.2268,  1.3450,  1.2954,  1.3805,  1.2106,  1.2777],
        [ 1.8535,  1.4367,  0.6179,  0.9125,  1.3111,  1.7632,  1.6493,  1.8759,
          1.8759,  1.7316,  1.3253,  1.5338,  0.9119,  1.7724,  0.1638,  1.6528,
          1.9154,  0.8800,  1.3276,  0.9672,  0.7349,  1.1548,  1.6986,  1.7687,
          1.5273,  1.8820,  1.8820,  0.8397,  0.8625,  1.8604,  1.6372,  0.8692,
          1.7923,  1.2434,  1.9127,  1.8220,  0.2974,  0.0747,  0.0547,  0.2517,
          0.4765,  0.5576,  0.1885, 16.5853,  4.3081,  0.7832,  1.4078,  1.5120,
          1.7509,  1.0121,  1.6632,  0.3603,  1.8527,  1.9212],
        [ 1.2935,  1.3217,  1.3794,  1.3576,  1.3277,  1.2984,  1.2617,  1.2912,
          1.2912,  1.2616,  1.3828,  1.2778,  1.4128,  1.3486,  1.4526,  1.2675,
          1.3419,  1.3118,  1.3404,  1.3415,  1.3820,  1.3538,  1.3120,  1.3070,
          1.2141,  1.2999,  1.2999,  1.3516,  1.3970,  1.3232,  1.1044,  1.3056,
          1.1975,  1.3634,  1.1947,  1.3258,  1.4655,  1.1607,  1.4688,  1.4765,
          1.0225,  0.9439,  1.4805,  1.3721,  0.8239,  3.5232,  2.6645,  3.7192,
          2.9656,  2.2513,  1.9505,  3.0656,  3.4566,  1.9355]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 319 : 180.90861515454276
Test loss for epoch 319 : 181.12994948344533
Test Precision for epoch 319 : 0.26153846153846155
Test Recall for epoch 319 : 0.26153846153846155
Test F1 for epoch 319 : 0.26153846153846155


theta for epoch 320 : tensor([[ 2.7419,  2.7680,  2.8341,  2.9729,  2.9405,  2.7463,  2.9210,  2.7400,
          2.7400,  1.2730,  1.2994,  1.2890,  1.3287,  1.2659,  1.3684,  1.2788,
          1.2591,  1.2759,  1.2620,  1.2414,  1.2571,  1.2753,  1.2340,  1.2292,
          1.2504,  1.2221,  1.2221,  1.2681,  1.3130,  1.2401,  1.2650,  1.3148,
          1.2514,  1.2802,  1.2018,  1.2426,  1.3901,  1.4381,  1.4204,  1.4007,
          1.4093,  1.3581,  1.4045,  1.2994,  1.3303,  1.3254,  1.2797,  1.2667,
          1.2522,  1.3226,  1.2736,  1.3579,  1.2416,  1.2557],
        [ 1.2573,  1.2759,  1.2424,  1.2757,  1.3081,  1.2789,  1.2602,  1.2716,
          1.2716,  2.2140,  2.2112,  2.1392,  2.3818,  2.1724,  5.0734,  2.2070,
          2.1630,  4.8557,  1.2641,  1.3038,  1.2691,  1.2381,  1.2971,  1.2929,
          1.2822,  1.2856,  1.2856,  1.3315,  1.2196,  1.3043,  1.3290,  1.2661,
          1.3159,  1.3453,  1.2665,  1.3068,  1.4468,  1.4971,  1.4235,  1.4335,
          1.4665,  1.4715,  1.4072,  1.1364,  1.3829,  1.2983,  1.3417,  1.3279,
          1.3130,  1.2464,  1.3354,  1.2942,  1.3021,  1.3169],
        [ 1.2118,  1.2395,  1.2909,  1.2743,  1.2448,  1.2166,  1.2249,  1.2095,
          1.2095,  1.2746,  1.3012,  1.2907,  1.3307,  1.2674,  1.3239,  1.2804,
          1.2148,  1.3221,  2.7818,  2.9673,  2.9960,  2.8103,  2.7400,  2.7477,
          2.9270,  2.7294,  2.7294,  1.2670,  1.3137,  1.2421,  1.2649,  1.2675,
          1.2535,  1.2825,  1.2497,  1.2446,  1.3910,  1.4392,  1.4190,  1.3433,
          1.4077,  1.4047,  1.4056,  1.2975,  1.2702,  1.3251,  1.2825,  1.2695,
          1.2550,  1.3229,  1.2765,  1.3591,  1.2361,  1.2586],
        [ 1.2253,  1.2530,  1.3038,  1.2877,  1.2584,  1.2301,  1.2386,  1.2231,
          1.2231,  1.2878,  1.3142,  1.3038,  1.3425,  1.2805,  1.2960,  1.2936,
          1.2733,  1.2506,  1.2775,  1.2946,  1.3177,  1.2909,  1.2495,  1.2446,
          1.2591,  1.2375,  1.2375,  3.0382,  3.0146,  2.6337,  2.7969,  3.0362,
          2.6436,  2.9849,  2.6440,  2.6359,  1.4031,  1.4515,  1.4323,  1.4063,
          1.4225,  1.4192,  1.4165,  1.2656,  1.3354,  1.3407,  1.2947,  1.1961,
          1.2197,  1.3379,  1.2885,  1.3735,  1.2031,  1.2705],
        [ 1.8528,  1.4351,  0.6150,  0.9114,  1.3111,  1.7638,  1.6487,  1.8767,
          1.8767,  1.7287,  1.3226,  1.5310,  0.9086,  1.7682,  0.1583,  1.6497,
          1.9147,  0.8737,  1.3311,  0.9717,  0.7380,  1.1575,  1.7036,  1.7738,
          1.5322,  1.8872,  1.8872,  0.8381,  0.8587,  1.8602,  1.6369,  0.8669,
          1.7920,  1.2420,  1.9125,  1.8217,  0.2975,  0.0750,  0.0547,  0.2522,
          0.4763,  0.5571,  0.1887, 16.6509,  4.2551,  0.7739,  1.3997,  1.5035,
          1.7430,  1.0017,  1.6551,  0.3509,  1.8462,  1.9135],
        [ 1.3021,  1.3301,  1.3877,  1.3660,  1.3361,  1.3069,  1.2704,  1.2998,
          1.2998,  1.2689,  1.3895,  1.2851,  1.4197,  1.3554,  1.4593,  1.2748,
          1.3484,  1.3195,  1.3571,  1.3577,  1.3989,  1.3707,  1.3289,  1.3240,
          1.2308,  1.3168,  1.3168,  1.3589,  1.4040,  1.3305,  1.1123,  1.3131,
          1.2055,  1.3706,  1.2027,  1.3330,  1.4714,  1.1681,  1.4738,  1.4822,
          1.0299,  0.9517,  1.4863,  1.3772,  0.8316,  3.5101,  2.6483,  3.7041,
          2.9495,  2.2354,  1.9345,  3.0499,  3.4429,  1.9194]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 320 : 180.87285991492737
Test loss for epoch 320 : 181.1108432511583
Test Precision for epoch 320 : 0.26153846153846155
Test Recall for epoch 320 : 0.26153846153846155
Test F1 for epoch 320 : 0.26153846153846155


theta for epoch 321 : tensor([[ 2.7413,  2.7674,  2.8335,  2.9725,  2.9400,  2.7457,  2.9205,  2.7393,
          2.7393,  1.2744,  1.3007,  1.2904,  1.3302,  1.2674,  1.3700,  1.2802,
          1.2603,  1.2777,  1.2571,  1.2366,  1.2523,  1.2705,  1.2291,  1.2243,
          1.2455,  1.2172,  1.2172,  1.2686,  1.3135,  1.2406,  1.2654,  1.3152,
          1.2518,  1.2807,  1.2022,  1.2431,  1.3899,  1.4378,  1.4204,  1.4005,
          1.4092,  1.3580,  1.4044,  1.2984,  1.3302,  1.3311,  1.2855,  1.2725,
          1.2580,  1.3284,  1.2794,  1.3637,  1.2474,  1.2616],
        [ 1.2557,  1.2755,  1.2450,  1.2741,  1.3049,  1.2756,  1.2585,  1.2684,
          1.2684,  2.2244,  2.2198,  2.1486,  2.3865,  2.1803,  5.0499,  2.2158,
          2.1757,  4.8317,  1.2582,  1.2966,  1.2629,  1.2332,  1.2894,  1.2851,
          1.2757,  1.2778,  1.2778,  1.3295,  1.2218,  1.3022,  1.3269,  1.2657,
          1.3139,  1.3432,  1.2645,  1.3048,  1.4446,  1.4949,  1.4215,  1.4330,
          1.4644,  1.4694,  1.4050,  1.1427,  1.3808,  1.3048,  1.3451,  1.3313,
          1.3163,  1.2528,  1.3388,  1.3005,  1.3054,  1.3203],
        [ 1.2143,  1.2420,  1.2931,  1.2768,  1.2473,  1.2191,  1.2274,  1.2120,
          1.2120,  1.2792,  1.3058,  1.2953,  1.3353,  1.2722,  1.3283,  1.2850,
          1.2192,  1.3271,  2.7749,  2.9617,  2.9889,  2.8026,  2.7337,  2.7407,
          2.9213,  2.7231,  2.7231,  1.2695,  1.3165,  1.2449,  1.2676,  1.2700,
          1.2563,  1.2853,  1.2525,  1.2475,  1.3927,  1.4409,  1.4207,  1.3446,
          1.4093,  1.4061,  1.4073,  1.2986,  1.2715,  1.3351,  1.2928,  1.2797,
          1.2653,  1.3330,  1.2867,  1.3690,  1.2461,  1.2689],
        [ 1.2243,  1.2519,  1.3025,  1.2867,  1.2574,  1.2291,  1.2376,  1.2220,
          1.2220,  1.2884,  1.3148,  1.3044,  1.3431,  1.2813,  1.2972,  1.2942,
          1.2737,  1.2520,  1.2719,  1.2888,  1.3122,  1.2854,  1.2438,  1.2390,
          1.2531,  1.2319,  1.2319,  3.0390,  3.0152,  2.6345,  2.7972,  3.0370,
          2.6445,  2.9853,  2.6449,  2.6367,  1.4026,  1.4509,  1.4319,  1.4054,
          1.4220,  1.4184,  1.4159,  1.2649,  1.3346,  1.3450,  1.2991,  1.2008,
          1.2241,  1.3423,  1.2928,  1.3778,  1.2071,  1.2749],
        [ 1.8520,  1.4343,  0.6146,  0.9120,  1.3121,  1.7646,  1.6483,  1.8774,
          1.8774,  1.7285,  1.3237,  1.5313,  0.9097,  1.7669,  0.1578,  1.6497,
          1.9167,  0.8722,  1.3276,  0.9704,  0.7360,  1.1536,  1.7008,  1.7710,
          1.5298,  1.8844,  1.8844,  0.8404,  0.8586,  1.8617,  1.6388,  0.8684,
          1.7936,  1.2437,  1.9140,  1.8233,  0.2947,  0.0724,  0.0518,  0.2497,
          0.4729,  0.5533,  0.1860, 16.7140,  4.1985,  0.7796,  1.4065,  1.5100,
          1.7497,  1.0072,  1.6619,  0.3564,  1.8540,  1.9200],
        [ 1.2984,  1.3265,  1.3840,  1.3623,  1.3324,  1.3033,  1.2667,  1.2961,
          1.2961,  1.2665,  1.3873,  1.2827,  1.4177,  1.3534,  1.4575,  1.2724,
          1.3461,  1.3176,  1.3486,  1.3482,  1.3902,  1.3622,  1.3204,  1.3155,
          1.2213,  1.3083,  1.3083,  1.3559,  1.4012,  1.3276,  1.1082,  1.3101,
          1.2023,  1.3677,  1.1995,  1.3301,  1.4690,  1.1652,  1.4705,  1.4797,
          1.0260,  0.9478,  1.4839,  1.3739,  0.8276,  3.5197,  2.6556,  3.7124,
          2.9567,  2.2426,  1.9419,  3.0569,  3.4528,  1.9269]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 321 : 180.8401570947799
Test loss for epoch 321 : 181.07856122932606
Test Precision for epoch 321 : 0.26153846153846155
Test Recall for epoch 321 : 0.26153846153846155
Test F1 for epoch 321 : 0.26153846153846155


theta for epoch 322 : tensor([[ 2.7405,  2.7666,  2.8328,  2.9718,  2.9394,  2.7449,  2.9199,  2.7386,
          2.7386,  1.2737,  1.3001,  1.2897,  1.3296,  1.2669,  1.3696,  1.2795,
          1.2594,  1.2775,  1.2602,  1.2396,  1.2554,  1.2736,  1.2322,  1.2274,
          1.2485,  1.2203,  1.2203,  1.2684,  1.3133,  1.2404,  1.2652,  1.3150,
          1.2516,  1.2805,  1.2020,  1.2429,  1.3903,  1.4382,  1.4209,  1.4007,
          1.4096,  1.3585,  1.4047,  1.2980,  1.3307,  1.3314,  1.2859,  1.2729,
          1.2585,  1.3287,  1.2798,  1.3640,  1.2477,  1.2620],
        [ 1.2558,  1.2768,  1.2493,  1.2744,  1.3035,  1.2741,  1.2586,  1.2669,
          1.2669,  2.2320,  2.2258,  2.1551,  2.3888,  2.1853,  5.0236,  2.2219,
          2.1858,  4.8049,  1.2619,  1.2989,  1.2656,  1.2383,  1.2916,  1.2872,
          1.2791,  1.2799,  1.2799,  1.3281,  1.2247,  1.3007,  1.3255,  1.2660,
          1.3124,  1.3418,  1.2630,  1.3033,  1.4437,  1.4940,  1.4207,  1.4337,
          1.4637,  1.4686,  1.4041,  1.1504,  1.3800,  1.3071,  1.3441,  1.3304,
          1.3154,  1.2552,  1.3378,  1.3033,  1.3044,  1.3194],
        [ 1.2122,  1.2400,  1.2908,  1.2748,  1.2452,  1.2170,  1.2253,  1.2100,
          1.2100,  1.2765,  1.3031,  1.2926,  1.3329,  1.2697,  1.3261,  1.2824,
          1.2161,  1.3251,  2.7779,  2.9659,  2.9916,  2.8048,  2.7373,  2.7436,
          2.9255,  2.7267,  2.7267,  1.2674,  1.3149,  1.2433,  1.2659,  1.2680,
          1.2546,  1.2837,  1.2508,  1.2458,  1.3918,  1.4400,  1.4199,  1.3431,
          1.4084,  1.4049,  1.4064,  1.2971,  1.2701,  1.3338,  1.2916,  1.2786,
          1.2642,  1.3319,  1.2856,  1.3677,  1.2445,  1.2678],
        [ 1.2242,  1.2518,  1.3021,  1.2866,  1.2572,  1.2289,  1.2374,  1.2219,
          1.2219,  1.2879,  1.3143,  1.3039,  1.3427,  1.2809,  1.2974,  1.2937,
          1.2730,  1.2524,  1.2752,  1.2915,  1.3154,  1.2886,  1.2470,  1.2422,
          1.2560,  1.2351,  1.2351,  3.0385,  3.0144,  2.6340,  2.7962,  3.0365,
          2.6440,  2.9843,  2.6445,  2.6362,  1.4030,  1.4513,  1.4323,  1.4053,
          1.4225,  1.4186,  1.4162,  1.2651,  1.3347,  1.3451,  1.2993,  1.2015,
          1.2244,  1.3425,  1.2930,  1.3779,  1.2070,  1.2752],
        [ 1.8510,  1.4330,  0.6132,  0.9118,  1.3125,  1.7650,  1.6474,  1.8777,
          1.8777,  1.7262,  1.3224,  1.5294,  0.9086,  1.7635,  0.1551,  1.6475,
          1.9167,  0.8682,  1.3296,  0.9740,  0.7387,  1.1549,  1.7037,  1.7739,
          1.5327,  1.8874,  1.8874,  0.8409,  0.8568,  1.8621,  1.6394,  0.8681,
          1.7939,  1.2437,  1.9144,  1.8236,  0.2926,  0.0706,  0.0497,  0.2480,
          0.4703,  0.5503,  0.1841, 16.7781,  4.1424,  0.7798,  1.4075,  1.5106,
          1.7506,  1.0067,  1.6628,  0.3566,  1.8562,  1.9209],
        [ 1.2979,  1.3259,  1.3834,  1.3617,  1.3318,  1.3027,  1.2661,  1.2956,
          1.2956,  1.2652,  1.3860,  1.2814,  1.4165,  1.3523,  1.4564,  1.2712,
          1.3446,  1.3167,  1.3520,  1.3508,  1.3935,  1.3655,  1.3237,  1.3189,
          1.2239,  1.3117,  1.3117,  1.3552,  1.4005,  1.3268,  1.1068,  1.3094,
          1.2016,  1.3669,  1.1988,  1.3294,  1.4690,  1.1652,  1.4697,  1.4796,
          1.0253,  0.9472,  1.4840,  1.3730,  0.8270,  3.5221,  2.6553,  3.7131,
          2.9565,  2.2425,  1.9418,  3.0567,  3.4553,  1.9268]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 322 : 180.8209380055968
Test loss for epoch 322 : 181.0647349172298
Test Precision for epoch 322 : 0.26153846153846155
Test Recall for epoch 322 : 0.26153846153846155
Test F1 for epoch 322 : 0.26153846153846155


theta for epoch 323 : tensor([[ 2.7431,  2.7692,  2.8354,  2.9746,  2.9422,  2.7476,  2.9227,  2.7412,
          2.7412,  1.2737,  1.3001,  1.2897,  1.3298,  1.2671,  1.3698,  1.2796,
          1.2592,  1.2779,  1.2599,  1.2393,  1.2551,  1.2733,  1.2319,  1.2271,
          1.2481,  1.2200,  1.2200,  1.2682,  1.3131,  1.2402,  1.2651,  1.3149,
          1.2515,  1.2803,  1.2018,  1.2427,  1.3905,  1.4385,  1.4213,  1.4009,
          1.4100,  1.3589,  1.4050,  1.2973,  1.3310,  1.3250,  1.2796,  1.2665,
          1.2521,  1.3224,  1.2735,  1.3576,  1.2413,  1.2557],
        [ 1.2574,  1.2794,  1.2549,  1.2760,  1.3036,  1.2742,  1.2603,  1.2670,
          1.2670,  2.2415,  2.2339,  2.1637,  2.3934,  2.1923,  4.9989,  2.2300,
          2.1980,  4.7797,  1.2626,  1.2983,  1.2655,  1.2404,  1.2908,  1.2863,
          1.2797,  1.2790,  1.2790,  1.3273,  1.2280,  1.2997,  1.3245,  1.2668,
          1.3113,  1.3408,  1.2620,  1.3023,  1.4431,  1.4933,  1.4201,  1.4346,
          1.4631,  1.4681,  1.4034,  1.1582,  1.3794,  1.3033,  1.3367,  1.3229,
          1.3080,  1.2512,  1.3304,  1.3007,  1.2969,  1.3119],
        [ 1.2137,  1.2415,  1.2919,  1.2762,  1.2467,  1.2185,  1.2268,  1.2115,
          1.2115,  1.2775,  1.3041,  1.2936,  1.3339,  1.2708,  1.3272,  1.2834,
          1.2168,  1.3265,  2.7783,  2.9677,  2.9919,  2.8045,  2.7384,  2.7441,
          2.9273,  2.7278,  2.7278,  1.2676,  1.3156,  1.2439,  1.2665,  1.2682,
          1.2552,  1.2843,  1.2514,  1.2464,  1.3926,  1.4408,  1.4207,  1.3433,
          1.4092,  1.4054,  1.4072,  1.2971,  1.2705,  1.3277,  1.2856,  1.2726,
          1.2582,  1.3260,  1.2796,  1.3617,  1.2381,  1.2618],
        [ 1.2254,  1.2531,  1.3029,  1.2877,  1.2584,  1.2302,  1.2387,  1.2231,
          1.2231,  1.2885,  1.3149,  1.3046,  1.3434,  1.2817,  1.2987,  1.2944,
          1.2734,  1.2539,  1.2756,  1.2916,  1.3158,  1.2891,  1.2475,  1.2427,
          1.2560,  1.2355,  1.2355,  3.0396,  3.0152,  2.6351,  2.7966,  3.0375,
          2.6450,  2.9847,  2.6456,  2.6373,  1.4037,  1.4521,  1.4332,  1.4056,
          1.4233,  1.4192,  1.4169,  1.2655,  1.3352,  1.3401,  1.2943,  1.1971,
          1.2193,  1.3374,  1.2881,  1.3729,  1.2015,  1.2701],
        [ 1.8514,  1.4330,  0.6122,  0.9122,  1.3140,  1.7667,  1.6479,  1.8796,
          1.8796,  1.7249,  1.3219,  1.5285,  0.9080,  1.7612,  0.1523,  1.6463,
          1.9177,  0.8648,  1.3293,  0.9751,  0.7387,  1.1537,  1.7044,  1.7747,
          1.5335,  1.8883,  1.8883,  0.8414,  0.8549,  1.8631,  1.6405,  0.8678,
          1.7950,  1.2440,  1.9155,  1.8247,  0.2918,  0.0699,  0.0488,  0.2474,
          0.4690,  0.5486,  0.1833, 16.8435,  4.0872,  0.7742,  1.4027,  1.5054,
          1.7459,  1.0001,  1.6581,  0.3512,  1.8529,  1.9164],
        [ 1.3027,  1.3307,  1.3881,  1.3664,  1.3366,  1.3075,  1.2710,  1.3004,
          1.3004,  1.2697,  1.3903,  1.2859,  1.4209,  1.3567,  1.4609,  1.2757,
          1.3486,  1.3216,  1.3565,  1.3545,  1.3981,  1.3701,  1.3282,  1.3234,
          1.2279,  1.3162,  1.3162,  1.3592,  1.4043,  1.3308,  1.1106,  1.3135,
          1.2058,  1.3709,  1.2030,  1.3334,  1.4721,  1.1689,  1.4719,  1.4826,
          1.0286,  0.9506,  1.4870,  1.3751,  0.8303,  3.5173,  2.6475,  3.7063,
          2.9487,  2.2349,  1.9342,  3.0492,  3.4502,  1.9192]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 323 : 180.81313033219632
Test loss for epoch 323 : 181.0683980142716
Test Precision for epoch 323 : 0.26153846153846155
Test Recall for epoch 323 : 0.26153846153846155
Test F1 for epoch 323 : 0.26153846153846155


theta for epoch 324 : tensor([[ 2.7394,  2.7655,  2.8317,  2.9710,  2.9386,  2.7438,  2.9191,  2.7374,
          2.7374,  1.2758,  1.3022,  1.2918,  1.3320,  1.2693,  1.3722,  1.2817,
          1.2611,  1.2804,  1.2580,  1.2373,  1.2532,  1.2714,  1.2299,  1.2251,
          1.2461,  1.2179,  1.2179,  1.2698,  1.3147,  1.2418,  1.2667,  1.3165,
          1.2530,  1.2819,  1.2034,  1.2443,  1.3918,  1.4397,  1.4226,  1.4020,
          1.4113,  1.3602,  1.4063,  1.2976,  1.3324,  1.3328,  1.2875,  1.2745,
          1.2601,  1.3303,  1.2815,  1.3654,  1.2493,  1.2637],
        [ 1.2547,  1.2777,  1.2565,  1.2736,  1.2995,  1.2700,  1.2578,  1.2628,
          1.2628,  2.2503,  2.2414,  2.1715,  2.3975,  2.1985,  4.9734,  2.2374,
          2.2096,  4.7537,  1.2588,  1.2933,  1.2613,  1.2382,  1.2854,  1.2808,
          1.2757,  1.2735,  1.2735,  1.3258,  1.2308,  1.2980,  1.3229,  1.2670,
          1.3096,  1.3391,  1.2603,  1.3006,  1.4417,  1.4919,  1.4189,  1.4347,
          1.4618,  1.4668,  1.4020,  1.1655,  1.3781,  1.3110,  1.3418,  1.3281,
          1.3132,  1.2593,  1.3356,  1.3079,  1.3020,  1.3171],
        [ 1.2134,  1.2411,  1.2912,  1.2759,  1.2463,  1.2181,  1.2264,  1.2111,
          1.2111,  1.2800,  1.3066,  1.2961,  1.3366,  1.2735,  1.3298,  1.2860,
          1.2190,  1.3295,  2.7737,  2.9643,  2.9871,  2.7991,  2.7343,  2.7393,
          2.9239,  2.7237,  2.7237,  1.2688,  1.3172,  1.2454,  1.2680,  1.2695,
          1.2567,  1.2858,  1.2529,  1.2480,  1.3940,  1.4421,  1.4221,  1.3442,
          1.4106,  1.4064,  1.4086,  1.2978,  1.2714,  1.3369,  1.2950,  1.2820,
          1.2676,  1.3352,  1.2890,  1.3708,  1.2471,  1.2713],
        [ 1.2234,  1.2510,  1.3007,  1.2858,  1.2564,  1.2281,  1.2366,  1.2211,
          1.2211,  1.2890,  1.3154,  1.3051,  1.3440,  1.2824,  1.3000,  1.2950,
          1.2737,  1.2553,  1.2721,  1.2877,  1.3123,  1.2855,  1.2439,  1.2391,
          1.2521,  1.2319,  1.2319,  3.0394,  3.0146,  2.6349,  2.7959,  3.0374,
          2.6449,  2.9840,  2.6455,  2.6371,  1.4040,  1.4523,  1.4335,  1.4053,
          1.4236,  1.4191,  1.4171,  1.2655,  1.3351,  1.3456,  1.2999,  1.2032,
          1.2250,  1.3430,  1.2936,  1.3784,  1.2069,  1.2759],
        [ 1.8495,  1.4315,  0.6116,  0.9122,  1.3141,  1.7663,  1.6463,  1.8790,
          1.8790,  1.7242,  1.3228,  1.5286,  0.9096,  1.7597,  0.1527,  1.6461,
          1.9194,  0.8638,  1.3276,  0.9756,  0.7387,  1.1514,  1.7031,  1.7734,
          1.5325,  1.8869,  1.8869,  0.8441,  0.8554,  1.8647,  1.6423,  0.8698,
          1.7965,  1.2459,  1.9169,  1.8262,  0.2884,  0.0668,  0.0454,  0.2443,
          0.4650,  0.5442,  0.1801, 16.9069,  4.0290,  0.7816,  1.4108,  1.5130,
          1.7537,  1.0072,  1.6660,  0.3586,  1.8618,  1.9239],
        [ 1.2947,  1.3227,  1.3802,  1.3585,  1.3286,  1.2995,  1.2628,  1.2923,
          1.2923,  1.2637,  1.3847,  1.2799,  1.4154,  1.3513,  1.4557,  1.2698,
          1.3428,  1.3160,  1.3461,  1.3431,  1.3874,  1.3595,  1.3177,  1.3129,
          1.2161,  1.3057,  1.3057,  1.3533,  1.3987,  1.3249,  1.1031,  1.3075,
          1.1995,  1.3651,  1.1966,  1.3275,  1.4683,  1.1639,  1.4673,  1.4787,
          1.0224,  0.9443,  1.4833,  1.3703,  0.8239,  3.5315,  2.6594,  3.7191,
          2.9605,  2.2468,  1.9463,  3.0606,  3.4649,  1.9312]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 324 : 180.80453109181266
Test loss for epoch 324 : 181.05705394056798
Test Precision for epoch 324 : 0.26153846153846155
Test Recall for epoch 324 : 0.26153846153846155
Test F1 for epoch 324 : 0.26153846153846155


theta for epoch 325 : tensor([[ 2.7441,  2.7702,  2.8364,  2.9758,  2.9434,  2.7485,  2.9239,  2.7421,
          2.7421,  1.2728,  1.2992,  1.2888,  1.3291,  1.2665,  1.3695,  1.2788,
          1.2578,  1.2778,  1.2610,  1.2402,  1.2560,  1.2744,  1.2329,  1.2281,
          1.2491,  1.2210,  1.2210,  1.2675,  1.3125,  1.2395,  1.2645,  1.3143,
          1.2508,  1.2797,  1.2011,  1.2420,  1.3912,  1.4393,  1.4222,  1.4014,
          1.4109,  1.3599,  1.4058,  1.2960,  1.3320,  1.3232,  1.2779,  1.2648,
          1.2504,  1.3206,  1.2718,  1.3559,  1.2395,  1.2540],
        [ 1.2582,  1.2819,  1.2637,  1.2772,  1.3016,  1.2721,  1.2616,  1.2649,
          1.2649,  2.2578,  2.2479,  2.1781,  2.4007,  2.2034,  4.9465,  2.2436,
          2.2201,  4.7264,  1.2650,  1.2982,  1.2662,  1.2461,  1.2903,  1.2857,
          1.2822,  1.2783,  1.2783,  1.3249,  1.2342,  1.2970,  1.3220,  1.2679,
          1.3086,  1.3381,  1.2594,  1.2995,  1.4415,  1.4917,  1.4189,  1.4361,
          1.4619,  1.4668,  1.4019,  1.1739,  1.3781,  1.3056,  1.3330,  1.3192,
          1.3043,  1.2537,  1.3266,  1.3038,  1.2930,  1.3082],
        [ 1.2124,  1.2402,  1.2899,  1.2749,  1.2453,  1.2172,  1.2255,  1.2101,
          1.2101,  1.2755,  1.3021,  1.2916,  1.3322,  1.2691,  1.3257,  1.2815,
          1.2140,  1.3256,  2.7807,  2.9727,  2.9939,  2.8054,  2.7420,  2.7464,
          2.9323,  2.7314,  2.7314,  1.2654,  1.3143,  1.2425,  1.2650,  1.2661,
          1.2538,  1.2829,  1.2500,  1.2450,  1.3926,  1.4408,  1.4208,  1.3421,
          1.4093,  1.4048,  1.4072,  1.2956,  1.2696,  1.3246,  1.2827,  1.2696,
          1.2553,  1.3231,  1.2767,  1.3588,  1.2342,  1.2589],
        [ 1.2258,  1.2535,  1.3025,  1.2881,  1.2588,  1.2306,  1.2391,  1.2235,
          1.2235,  1.2885,  1.3149,  1.3045,  1.3435,  1.2820,  1.3003,  1.2945,
          1.2729,  1.2558,  1.2775,  1.2924,  1.3176,  1.2909,  1.2493,  1.2445,
          1.2571,  1.2373,  1.2373,  3.0395,  3.0143,  2.6351,  2.7953,  3.0375,
          2.6450,  2.9835,  2.6458,  2.6373,  1.4050,  1.4533,  1.4345,  1.4057,
          1.4248,  1.4199,  1.4180,  1.2662,  1.3359,  1.3388,  1.2932,  1.1972,
          1.2183,  1.3363,  1.2870,  1.3718,  1.1996,  1.2690],
        [ 1.8504,  1.4320,  0.6105,  0.9126,  1.3157,  1.7684,  1.6469,  1.8812,
          1.8812,  1.7210,  1.3204,  1.5259,  0.9071,  1.7558,  0.1481,  1.6432,
          1.9187,  0.8585,  1.3303,  0.9793,  0.7413,  1.1529,  1.7070,  1.7773,
          1.5361,  1.8909,  1.8909,  0.8428,  0.8519,  1.8644,  1.6420,  0.8678,
          1.7962,  1.2445,  1.9168,  1.8259,  0.2881,  0.0667,  0.0450,  0.2442,
          0.4642,  0.5431,  0.1799, 16.9734,  3.9739,  0.7730,  1.4030,  1.5047,
          1.7461,  0.9975,  1.6583,  0.3503,  1.8558,  1.9166],
        [ 1.3038,  1.3318,  1.3891,  1.3675,  1.3376,  1.3086,  1.2721,  1.3015,
          1.3015,  1.2702,  1.3907,  1.2863,  1.4215,  1.3574,  1.4618,  1.2762,
          1.3485,  1.3229,  1.3590,  1.3554,  1.4005,  1.3726,  1.3307,  1.3259,
          1.2288,  1.3187,  1.3187,  1.3598,  1.4050,  1.3314,  1.1100,  1.3142,
          1.2065,  1.3715,  1.2037,  1.3340,  1.4737,  1.1705,  1.4718,  1.4839,
          1.0289,  0.9512,  1.4886,  1.3747,  0.8308,  3.5199,  2.6446,  3.7052,
          2.9457,  2.2323,  1.9317,  3.0463,  3.4528,  1.9167]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 325 : 180.79240174429563
Test loss for epoch 325 : 181.0612762968508
Test Precision for epoch 325 : 0.26153846153846155
Test Recall for epoch 325 : 0.26153846153846155
Test F1 for epoch 325 : 0.26153846153846155


theta for epoch 326 : tensor([[ 2.7402,  2.7663,  2.8325,  2.9721,  2.9396,  2.7446,  2.9201,  2.7382,
          2.7382,  1.2762,  1.3026,  1.2922,  1.3326,  1.2700,  1.3731,  1.2822,
          1.2610,  1.2816,  1.2565,  1.2357,  1.2517,  1.2699,  1.2283,  1.2236,
          1.2445,  1.2164,  1.2164,  1.2698,  1.3148,  1.2418,  1.2668,  1.3166,
          1.2530,  1.2820,  1.2034,  1.2443,  1.3920,  1.4400,  1.4231,  1.4021,
          1.4117,  1.3608,  1.4065,  1.2958,  1.3329,  1.3324,  1.2872,  1.2742,
          1.2598,  1.3300,  1.2812,  1.3650,  1.2488,  1.2634],
        [ 1.2540,  1.2785,  1.2636,  1.2732,  1.2961,  1.2665,  1.2577,  1.2592,
          1.2592,  2.2686,  2.2577,  2.1879,  2.4075,  2.2116,  4.9225,  2.2532,
          2.2341,  4.7021,  1.2571,  1.2893,  1.2581,  1.2402,  1.2810,  1.2763,
          1.2744,  1.2689,  1.2689,  1.3231,  1.2364,  1.2948,  1.3200,  1.2677,
          1.3065,  1.3361,  1.2573,  1.2974,  1.4390,  1.4892,  1.4164,  1.4350,
          1.4594,  1.4644,  1.3994,  1.1800,  1.3756,  1.3132,  1.3384,  1.3246,
          1.3097,  1.2617,  1.3321,  1.3107,  1.2983,  1.3136],
        [ 1.2137,  1.2414,  1.2908,  1.2761,  1.2466,  1.2184,  1.2267,  1.2113,
          1.2113,  1.2813,  1.3078,  1.2973,  1.3379,  1.2751,  1.3312,  1.2873,
          1.2196,  1.3316,  2.7724,  2.9657,  2.9855,  2.7965,  2.7341,  2.7379,
          2.9252,  2.7235,  2.7235,  1.2687,  1.3179,  1.2461,  1.2686,  1.2694,
          1.2574,  1.2866,  1.2536,  1.2486,  1.3947,  1.4429,  1.4229,  1.3438,
          1.4114,  1.4065,  1.4093,  1.2969,  1.2714,  1.3370,  1.2952,  1.2822,
          1.2678,  1.3356,  1.2893,  1.3710,  1.2463,  1.2715],
        [ 1.2228,  1.2505,  1.2993,  1.2852,  1.2558,  1.2275,  1.2360,  1.2205,
          1.2205,  1.2893,  1.3156,  1.3053,  1.3443,  1.2829,  1.3018,  1.2953,
          1.2735,  1.2575,  1.2704,  1.2851,  1.3106,  1.2839,  1.2421,  1.2374,
          1.2496,  1.2302,  1.2302,  3.0407,  3.0151,  2.6363,  2.7958,  3.0387,
          2.6463,  2.9840,  2.6471,  2.6385,  1.4042,  1.4525,  1.4338,  1.4044,
          1.4240,  1.4188,  1.4172,  1.2651,  1.3348,  1.3449,  1.2992,  1.2038,
          1.2244,  1.3424,  1.2930,  1.3778,  1.2053,  1.2752],
        [ 1.8483,  1.4303,  0.6096,  0.9122,  1.3153,  1.7676,  1.6449,  1.8803,
          1.8803,  1.7211,  1.3221,  1.5268,  0.9096,  1.7553,  0.1491,  1.6438,
          1.9211,  0.8585,  1.3267,  0.9777,  0.7392,  1.1484,  1.7034,  1.7738,
          1.5329,  1.8874,  1.8874,  0.8458,  0.8527,  1.8664,  1.6442,  0.8701,
          1.7982,  1.2467,  1.9186,  1.8279,  0.2848,  0.0637,  0.0417,  0.2411,
          0.4603,  0.5387,  0.1767, 17.0373,  3.9152,  0.7811,  1.4118,  1.5132,
          1.7548,  1.0055,  1.6671,  0.3584,  1.8656,  1.9251],
        [ 1.2962,  1.3242,  1.3816,  1.3599,  1.3300,  1.3009,  1.2644,  1.2938,
          1.2938,  1.2660,  1.3869,  1.2822,  1.4178,  1.3538,  1.4584,  1.2721,
          1.3445,  1.3191,  1.3464,  1.3418,  1.3877,  1.3598,  1.3180,  1.3132,
          1.2150,  1.3060,  1.3060,  1.3551,  1.4005,  1.3267,  1.1038,  1.3093,
          1.2013,  1.3669,  1.1985,  1.3293,  1.4698,  1.1655,  1.4670,  1.4799,
          1.0228,  0.9449,  1.4848,  1.3697,  0.8245,  3.5335,  2.6558,  3.7172,
          2.9569,  2.2435,  1.9432,  3.0572,  3.4669,  1.9282]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 326 : 180.76678868303856
Test loss for epoch 326 : 181.03339083451368
Test Precision for epoch 326 : 0.26153846153846155
Test Recall for epoch 326 : 0.26153846153846155
Test F1 for epoch 326 : 0.26153846153846155


theta for epoch 327 : tensor([[ 2.7428,  2.7690,  2.8352,  2.9748,  2.9424,  2.7472,  2.9229,  2.7409,
          2.7409,  1.2729,  1.2992,  1.2889,  1.3293,  1.2669,  1.3700,  1.2789,
          1.2574,  1.2787,  1.2610,  1.2401,  1.2560,  1.2744,  1.2328,  1.2280,
          1.2489,  1.2209,  1.2209,  1.2675,  1.3125,  1.2395,  1.2645,  1.3143,
          1.2507,  1.2798,  1.2011,  1.2420,  1.3916,  1.4397,  1.4229,  1.4016,
          1.4115,  1.3606,  1.4062,  1.2942,  1.3326,  1.3270,  1.2819,  1.2689,
          1.2544,  1.3246,  1.2758,  1.3598,  1.2433,  1.2580],
        [ 1.2570,  1.2821,  1.2701,  1.2765,  1.2979,  1.2683,  1.2612,  1.2611,
          1.2611,  2.2746,  2.2631,  2.1931,  2.4100,  2.2151,  4.8942,  2.2582,
          2.2435,  4.6732,  1.2643,  1.2953,  1.2640,  1.2493,  1.2872,  1.2824,
          1.2821,  1.2750,  1.2750,  1.3220,  1.2394,  1.2935,  1.3188,  1.2684,
          1.3052,  1.3349,  1.2561,  1.2961,  1.4387,  1.4890,  1.4164,  1.4362,
          1.4594,  1.4644,  1.3992,  1.1882,  1.3756,  1.3113,  1.3337,  1.3199,
          1.3050,  1.2600,  1.3274,  1.3094,  1.2935,  1.3089],
        [ 1.2120,  1.2398,  1.2887,  1.2744,  1.2449,  1.2167,  1.2251,  1.2097,
          1.2097,  1.2756,  1.3022,  1.2917,  1.3324,  1.2696,  1.3262,  1.2817,
          1.2134,  1.3265,  2.7791,  2.9738,  2.9920,  2.8025,  2.7414,  2.7447,
          2.9333,  2.7308,  2.7308,  1.2646,  1.3144,  1.2425,  1.2650,  1.2653,
          1.2538,  1.2830,  1.2500,  1.2450,  1.3931,  1.4413,  1.4213,  1.3414,
          1.4098,  1.4046,  1.4077,  1.2943,  1.2692,  1.3288,  1.2869,  1.2739,
          1.2595,  1.3274,  1.2810,  1.3629,  1.2374,  1.2632],
        [ 1.2250,  1.2527,  1.3010,  1.2873,  1.2580,  1.2297,  1.2382,  1.2227,
          1.2227,  1.2881,  1.3145,  1.3042,  1.3432,  1.2819,  1.3015,  1.2941,
          1.2721,  1.2575,  1.2769,  1.2910,  1.3170,  1.2904,  1.2487,  1.2439,
          1.2557,  1.2368,  1.2368,  3.0396,  3.0135,  2.6353,  2.7940,  3.0376,
          2.6452,  2.9823,  2.6461,  2.6374,  1.4051,  1.4534,  1.4347,  1.4048,
          1.4251,  1.4195,  1.4181,  1.2657,  1.3355,  1.3416,  1.2960,  1.2013,
          1.2211,  1.3391,  1.2898,  1.3745,  1.2016,  1.2719],
        [ 1.8488,  1.4306,  0.6087,  0.9124,  1.3165,  1.7690,  1.6451,  1.8819,
          1.8819,  1.7171,  1.3191,  1.5235,  0.9070,  1.7509,  0.1447,  1.6403,
          1.9196,  0.8532,  1.3302,  0.9821,  0.7426,  1.1507,  1.7079,  1.7784,
          1.5370,  1.8920,  1.8920,  0.8443,  0.8491,  1.8654,  1.6431,  0.8680,
          1.7972,  1.2448,  1.9178,  1.8270,  0.2840,  0.0630,  0.0408,  0.2404,
          0.4590,  0.5370,  0.1759, 17.1037,  3.8590,  0.7761,  1.4075,  1.5083,
          1.7507,  0.9995,  1.6629,  0.3535,  1.8629,  1.9211],
        [ 1.3014,  1.3294,  1.3867,  1.3650,  1.3352,  1.3061,  1.2696,  1.2990,
          1.2990,  1.2677,  1.3883,  1.2838,  1.4192,  1.3553,  1.4600,  1.2738,
          1.3456,  1.3211,  1.3562,  1.3509,  1.3976,  1.3698,  1.3278,  1.3230,
          1.2242,  1.3158,  1.3158,  1.3575,  1.4028,  1.3291,  1.1061,  1.3119,
          1.2040,  1.3693,  1.2012,  1.3316,  1.4726,  1.1689,  1.4690,  1.4826,
          1.0259,  0.9482,  1.4876,  1.3715,  0.8278,  3.5283,  2.6476,  3.7098,
          2.9486,  2.2356,  1.9352,  3.0491,  3.4614,  1.9202]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 327 : 180.73891962666926
Test loss for epoch 327 : 181.01753978815697
Test Precision for epoch 327 : 0.26153846153846155
Test Recall for epoch 327 : 0.26153846153846155
Test F1 for epoch 327 : 0.26153846153846155


theta for epoch 328 : tensor([[ 2.7422,  2.7684,  2.8346,  2.9743,  2.9419,  2.7466,  2.9224,  2.7402,
          2.7402,  1.2750,  1.3012,  1.2909,  1.3314,  1.2690,  1.3722,  1.2810,
          1.2593,  1.2810,  1.2580,  1.2372,  1.2532,  1.2715,  1.2298,  1.2251,
          1.2460,  1.2179,  1.2179,  1.2688,  1.3138,  1.2407,  1.2658,  1.3156,
          1.2520,  1.2811,  1.2023,  1.2433,  1.3919,  1.4399,  1.4232,  1.4018,
          1.4118,  1.3609,  1.4064,  1.2934,  1.3330,  1.3286,  1.2835,  1.2704,
          1.2560,  1.3262,  1.2774,  1.3613,  1.2448,  1.2596],
        [ 1.2550,  1.2806,  1.2718,  1.2748,  1.2948,  1.2652,  1.2597,  1.2579,
          1.2579,  2.2851,  2.2730,  2.2029,  2.4173,  2.2231,  4.8698,  2.2677,
          2.2575,  4.6485,  1.2596,  1.2898,  1.2590,  1.2468,  1.2814,  1.2766,
          1.2780,  1.2691,  1.2691,  1.3206,  1.2419,  1.2920,  1.3174,  1.2687,
          1.3036,  1.3333,  1.2545,  1.2946,  1.4367,  1.4870,  1.4145,  1.4355,
          1.4575,  1.4626,  1.3972,  1.1946,  1.3737,  1.3125,  1.3326,  1.3188,
          1.3039,  1.2614,  1.3263,  1.3106,  1.2923,  1.3078],
        [ 1.2138,  1.2415,  1.2901,  1.2761,  1.2466,  1.2185,  1.2268,  1.2114,
          1.2114,  1.2799,  1.3064,  1.2960,  1.3366,  1.2740,  1.3302,  1.2860,
          1.2175,  1.3310,  2.7743,  2.9703,  2.9872,  2.7972,  2.7370,  2.7398,
          2.9298,  2.7264,  2.7264,  1.2669,  1.3171,  1.2452,  1.2677,  1.2677,
          1.2565,  1.2858,  1.2527,  1.2478,  1.3946,  1.4428,  1.4230,  1.3424,
          1.4114,  1.4058,  1.4093,  1.2949,  1.2704,  1.3324,  1.2906,  1.2775,
          1.2632,  1.3311,  1.2846,  1.3665,  1.2406,  1.2668],
        [ 1.2237,  1.2514,  1.2994,  1.2861,  1.2567,  1.2284,  1.2370,  1.2214,
          1.2214,  1.2889,  1.3152,  1.3049,  1.3439,  1.2828,  1.3031,  1.2949,
          1.2726,  1.2591,  1.2729,  1.2865,  1.3130,  1.2864,  1.2446,  1.2399,
          1.2512,  1.2327,  1.2327,  3.0411,  3.0145,  2.6369,  2.7948,  3.0391,
          2.6468,  2.9831,  2.6478,  2.6391,  1.4046,  1.4530,  1.4344,  1.4038,
          1.4247,  1.4187,  1.4176,  1.2650,  1.3347,  1.3419,  1.2964,  1.2023,
          1.2215,  1.3396,  1.2902,  1.3750,  1.2015,  1.2724],
        [ 1.8481,  1.4302,  0.6081,  0.9124,  1.3169,  1.7693,  1.6442,  1.8822,
          1.8822,  1.7166,  1.3201,  1.5239,  0.9086,  1.7502,  0.1445,  1.6406,
          1.9215,  0.8525,  1.3282,  0.9816,  0.7414,  1.1475,  1.7061,  1.7767,
          1.5354,  1.8903,  1.8903,  0.8462,  0.8491,  1.8671,  1.6448,  0.8693,
          1.7989,  1.2463,  1.9194,  1.8286,  0.2818,  0.0611,  0.0386,  0.2384,
          0.4563,  0.5339,  0.1739, 17.1691,  3.8011,  0.7776,  1.4095,  1.5098,
          1.7526,  1.0005,  1.6649,  0.3553,  1.8662,  1.9231],
        [ 1.2998,  1.3279,  1.3851,  1.3635,  1.3337,  1.3046,  1.2681,  1.2975,
          1.2975,  1.2683,  1.3890,  1.2844,  1.4200,  1.3562,  1.4609,  1.2744,
          1.3461,  1.3221,  1.3514,  1.3453,  1.3928,  1.3649,  1.3229,  1.3181,
          1.2186,  1.3109,  1.3109,  1.3574,  1.4028,  1.3290,  1.1052,  1.3117,
          1.2038,  1.3693,  1.2010,  1.3315,  1.4720,  1.1680,  1.4676,  1.4819,
          1.0242,  0.9465,  1.4870,  1.3697,  0.8262,  3.5326,  2.6492,  3.7120,
          2.9501,  2.2373,  1.9370,  3.0506,  3.4658,  1.9220]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 328 : 180.7158251353763
Test loss for epoch 328 : 180.9991069726235
Test Precision for epoch 328 : 0.26153846153846155
Test Recall for epoch 328 : 0.26153846153846155
Test F1 for epoch 328 : 0.26153846153846155


theta for epoch 329 : tensor([[ 2.7410,  2.7672,  2.8334,  2.9732,  2.9408,  2.7454,  2.9213,  2.7390,
          2.7390,  1.2747,  1.3009,  1.2906,  1.3311,  1.2689,  1.3721,  1.2807,
          1.2587,  1.2811,  1.2596,  1.2386,  1.2547,  1.2730,  1.2314,  1.2266,
          1.2475,  1.2194,  1.2194,  1.2686,  1.3137,  1.2406,  1.2657,  1.3154,
          1.2518,  1.2809,  1.2022,  1.2431,  1.3924,  1.4404,  1.4238,  1.4022,
          1.4124,  1.3616,  1.4069,  1.2927,  1.3336,  1.3305,  1.2855,  1.2724,
          1.2580,  1.3282,  1.2794,  1.3632,  1.2467,  1.2616],
        [ 1.2540,  1.2801,  1.2743,  1.2743,  1.2929,  1.2633,  1.2594,  1.2560,
          1.2560,  2.2924,  2.2800,  2.2095,  2.4218,  2.2280,  4.8426,  2.2742,
          2.2685,  4.6209,  1.2609,  1.2903,  1.2596,  1.2504,  1.2819,  1.2770,
          1.2801,  1.2695,  1.2695,  1.3194,  1.2444,  1.2904,  1.3160,  1.2691,
          1.3021,  1.3319,  1.2530,  1.2930,  1.4358,  1.4861,  1.4137,  1.4359,
          1.4567,  1.4618,  1.3963,  1.2018,  1.3729,  1.3154,  1.3335,  1.3197,
          1.3047,  1.2647,  1.3271,  1.3131,  1.2931,  1.3086],
        [ 1.2121,  1.2399,  1.2880,  1.2745,  1.2450,  1.2168,  1.2252,  1.2098,
          1.2098,  1.2786,  1.3050,  1.2946,  1.3353,  1.2728,  1.3291,  1.2847,
          1.2158,  1.3300,  2.7752,  2.9725,  2.9879,  2.7975,  2.7383,  2.7406,
          2.9320,  2.7277,  2.7277,  1.2656,  1.3162,  1.2443,  1.2668,  1.2663,
          1.2556,  1.2849,  1.2518,  1.2469,  1.3945,  1.4427,  1.4229,  1.3417,
          1.4113,  1.4053,  1.4092,  1.2939,  1.2699,  1.3332,  1.2915,  1.2784,
          1.2640,  1.3320,  1.2855,  1.3674,  1.2409,  1.2677],
        [ 1.2230,  1.2506,  1.2983,  1.2854,  1.2559,  1.2277,  1.2362,  1.2206,
          1.2206,  1.2885,  1.3148,  1.3045,  1.3435,  1.2825,  1.3036,  1.2945,
          1.2719,  1.2598,  1.2742,  1.2873,  1.3143,  1.2877,  1.2460,  1.2412,
          1.2521,  1.2340,  1.2340,  3.0406,  3.0135,  2.6366,  2.7936,  3.0386,
          2.6465,  2.9819,  2.6476,  2.6387,  1.4050,  1.4534,  1.4348,  1.4036,
          1.4252,  1.4188,  1.4179,  1.2651,  1.3348,  1.3434,  1.2980,  1.2046,
          1.2231,  1.3411,  1.2918,  1.3764,  1.2026,  1.2739],
        [ 1.8470,  1.4295,  0.6074,  0.9121,  1.3169,  1.7692,  1.6429,  1.8820,
          1.8820,  1.7144,  1.3192,  1.5226,  0.9086,  1.7478,  0.1433,  1.6391,
          1.9216,  0.8503,  1.3295,  0.9842,  0.7434,  1.1477,  1.7078,  1.7783,
          1.5369,  1.8920,  1.8920,  0.8470,  0.8480,  1.8673,  1.6451,  0.8695,
          1.7991,  1.2463,  1.9197,  1.8289,  0.2796,  0.0591,  0.0364,  0.2363,
          0.4535,  0.5307,  0.1718, 17.2347,  3.7431,  0.7793,  1.4117,  1.5115,
          1.7548,  1.0017,  1.6671,  0.3573,  1.8697,  1.9252],
        [ 1.2975,  1.3255,  1.3827,  1.3612,  1.3313,  1.3022,  1.2657,  1.2951,
          1.2951,  1.2660,  1.3868,  1.2821,  1.4178,  1.3541,  1.4590,  1.2722,
          1.3437,  1.3201,  1.3507,  1.3438,  1.3921,  1.3643,  1.3222,  1.3174,
          1.2169,  1.3101,  1.3101,  1.3555,  1.4009,  1.3270,  1.1024,  1.3098,
          1.2017,  1.3674,  1.1988,  1.3296,  1.4713,  1.1668,  1.4661,  1.4812,
          1.0223,  0.9447,  1.4864,  1.3679,  0.8243,  3.5374,  2.6513,  3.7148,
          2.9521,  2.2395,  1.9394,  3.0525,  3.4708,  1.9243]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 329 : 180.69975805876442
Test loss for epoch 329 : 180.98736463878882
Test Precision for epoch 329 : 0.26153846153846155
Test Recall for epoch 329 : 0.26153846153846155
Test F1 for epoch 329 : 0.26153846153846155


theta for epoch 330 : tensor([[ 2.7444,  2.7706,  2.8368,  2.9767,  2.9443,  2.7488,  2.9248,  2.7424,
          2.7424,  1.2730,  1.2991,  1.2888,  1.3293,  1.2672,  1.3706,  1.2790,
          1.2567,  1.2796,  1.2596,  1.2386,  1.2546,  1.2731,  1.2314,  1.2267,
          1.2475,  1.2195,  1.2195,  1.2670,  1.3121,  1.2389,  1.2641,  1.3138,
          1.2502,  1.2794,  1.2005,  1.2415,  1.3920,  1.4401,  1.4236,  1.4017,
          1.4122,  1.3614,  1.4066,  1.2912,  1.3335,  1.3250,  1.2800,  1.2669,
          1.2524,  1.3227,  1.2739,  1.3578,  1.2410,  1.2560],
        [ 1.2560,  1.2824,  1.2793,  1.2767,  1.2940,  1.2644,  1.2620,  1.2572,
          1.2572,  2.3001,  2.2875,  2.2166,  2.4270,  2.2333,  4.8156,  2.2812,
          2.2800,  4.5936,  1.2626,  1.2912,  1.2605,  1.2543,  1.2828,  1.2778,
          1.2826,  1.2704,  1.2704,  1.3186,  1.2471,  1.2894,  1.3151,  1.2699,
          1.3011,  1.3309,  1.2520,  1.2920,  1.4353,  1.4856,  1.4134,  1.4366,
          1.4564,  1.4616,  1.3959,  1.2090,  1.3727,  1.3124,  1.3283,  1.3145,
          1.2995,  1.2620,  1.3219,  1.3105,  1.2877,  1.3034],
        [ 1.2131,  1.2408,  1.2885,  1.2754,  1.2459,  1.2177,  1.2261,  1.2107,
          1.2107,  1.2775,  1.3038,  1.2934,  1.3341,  1.2717,  1.3281,  1.2835,
          1.2142,  1.3292,  2.7771,  2.9758,  2.9897,  2.7988,  2.7407,  2.7425,
          2.9352,  2.7300,  2.7300,  1.2643,  1.3154,  1.2435,  1.2660,  1.2651,
          1.2548,  1.2842,  1.2510,  1.2461,  1.3947,  1.4429,  1.4231,  1.3412,
          1.4115,  1.4052,  1.4093,  1.2930,  1.2696,  1.3274,  1.2856,  1.2725,
          1.2580,  1.3263,  1.2796,  1.3617,  1.2344,  1.2617],
        [ 1.2247,  1.2523,  1.2994,  1.2869,  1.2575,  1.2293,  1.2379,  1.2223,
          1.2223,  1.2884,  1.3146,  1.3043,  1.3433,  1.2825,  1.3043,  1.2944,
          1.2715,  1.2607,  1.2758,  1.2884,  1.3159,  1.2893,  1.2476,  1.2429,
          1.2533,  1.2357,  1.2357,  3.0408,  3.0131,  2.6369,  2.7930,  3.0389,
          2.6469,  2.9813,  2.6480,  2.6391,  1.4057,  1.4541,  1.4355,  1.4038,
          1.4260,  1.4192,  1.4185,  1.2655,  1.3352,  1.3398,  1.2944,  1.2018,
          1.2194,  1.3375,  1.2882,  1.3729,  1.1984,  1.2703],
        [ 1.8480,  1.4305,  0.6073,  0.9128,  1.3185,  1.7709,  1.6435,  1.8838,
          1.8838,  1.7120,  1.3179,  1.5211,  0.9079,  1.7454,  0.1408,  1.6374,
          1.9215,  0.8472,  1.3304,  0.9860,  0.7443,  1.1473,  1.7092,  1.7798,
          1.5382,  1.8934,  1.8934,  0.8467,  0.8460,  1.8674,  1.6451,  0.8686,
          1.7992,  1.2457,  1.9198,  1.8289,  0.2787,  0.0585,  0.0355,  0.2356,
          0.4522,  0.5290,  0.1710, 17.3016,  3.6863,  0.7749,  1.4077,  1.5069,
          1.7509,  0.9965,  1.6631,  0.3532,  1.8672,  1.9215],
        [ 1.3023,  1.3303,  1.3875,  1.3660,  1.3362,  1.3071,  1.2706,  1.2999,
          1.2999,  1.2694,  1.3898,  1.2854,  1.4209,  1.3573,  1.4622,  1.2755,
          1.3465,  1.3237,  1.3553,  1.3478,  1.3968,  1.3690,  1.3268,  1.3220,
          1.2211,  1.3147,  1.3147,  1.3586,  1.4040,  1.3301,  1.1053,  1.3129,
          1.2050,  1.3706,  1.2022,  1.3327,  1.4742,  1.1701,  1.4681,  1.4839,
          1.0253,  0.9478,  1.4892,  1.3696,  0.8275,  3.5329,  2.6437,  3.7079,
          2.9445,  2.2322,  1.9321,  3.0451,  3.4661,  1.9171]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 330 : 180.68835067161757
Test loss for epoch 330 : 180.98770500971315
Test Precision for epoch 330 : 0.26153846153846155
Test Recall for epoch 330 : 0.26153846153846155
Test F1 for epoch 330 : 0.26153846153846155


theta for epoch 331 : tensor([[ 2.7399,  2.7661,  2.8324,  2.9724,  2.9399,  2.7443,  2.9204,  2.7379,
          2.7379,  1.2765,  1.3025,  1.2923,  1.3327,  1.2708,  1.3741,  1.2824,
          1.2599,  1.2833,  1.2578,  1.2369,  1.2529,  1.2714,  1.2297,  1.2249,
          1.2457,  1.2177,  1.2177,  1.2698,  1.3149,  1.2417,  1.2669,  1.3166,
          1.2529,  1.2822,  1.2033,  1.2442,  1.3933,  1.4414,  1.4250,  1.4029,
          1.4135,  1.3629,  1.4078,  1.2914,  1.3350,  1.3319,  1.2870,  1.2739,
          1.2594,  1.3297,  1.2809,  1.3647,  1.2479,  1.2630],
        [ 1.2515,  1.2782,  1.2782,  1.2728,  1.2888,  1.2591,  1.2582,  1.2519,
          1.2519,  2.3099,  2.2972,  2.2259,  2.4346,  2.2408,  4.7907,  2.2904,
          2.2938,  4.5683,  1.2571,  1.2851,  1.2549,  1.2511,  1.2765,  1.2716,
          1.2780,  1.2641,  1.2641,  1.3173,  1.2491,  1.2878,  1.3136,  1.2701,
          1.2995,  1.3294,  1.2505,  1.2904,  1.4333,  1.4836,  1.4116,  1.4357,
          1.4545,  1.4597,  1.3939,  1.2146,  1.3708,  1.3172,  1.3316,  1.3178,
          1.3028,  1.2672,  1.3253,  1.3143,  1.2910,  1.3067],
        [ 1.2124,  1.2401,  1.2874,  1.2747,  1.2452,  1.2171,  1.2255,  1.2100,
          1.2100,  1.2812,  1.3074,  1.2971,  1.3377,  1.2755,  1.3316,  1.2872,
          1.2176,  1.3330,  2.7722,  2.9723,  2.9848,  2.7934,  2.7361,  2.7375,
          2.9317,  2.7255,  2.7255,  1.2662,  1.3177,  1.2459,  1.2683,  1.2670,
          1.2572,  1.2865,  1.2534,  1.2484,  1.3960,  1.4443,  1.4245,  1.3420,
          1.4129,  1.4062,  1.4107,  1.2934,  1.2707,  1.3348,  1.2931,  1.2800,
          1.2655,  1.3337,  1.2871,  1.3690,  1.2413,  1.2692],
        [ 1.2215,  1.2491,  1.2960,  1.2839,  1.2544,  1.2261,  1.2347,  1.2191,
          1.2191,  1.2890,  1.3151,  1.3049,  1.3438,  1.2832,  1.3058,  1.2950,
          1.2719,  1.2622,  1.2713,  1.2834,  1.3114,  1.2848,  1.2430,  1.2383,
          1.2483,  1.2311,  1.2311,  3.0419,  3.0135,  2.6382,  2.7932,  3.0399,
          2.6481,  2.9816,  2.6494,  2.6404,  1.4052,  1.4536,  1.4351,  1.4027,
          1.4256,  1.4184,  1.4179,  1.2647,  1.3343,  1.3437,  1.2984,  1.2064,
          1.2234,  1.3415,  1.2922,  1.3768,  1.2019,  1.2743],
        [ 1.8460,  1.4290,  0.6065,  0.9120,  1.3176,  1.7696,  1.6412,  1.8824,
          1.8824,  1.7118,  1.3193,  1.5220,  0.9103,  1.7454,  0.1420,  1.6381,
          1.9234,  0.8478,  1.3287,  0.9858,  0.7436,  1.1446,  1.7074,  1.7780,
          1.5365,  1.8916,  1.8916,  0.8493,  0.8470,  1.8691,  1.6469,  0.8707,
          1.8010,  1.2476,  1.9215,  1.8307,  0.2759,  0.0559,  0.0327,  0.2328,
          0.4489,  0.5251,  0.1684, 17.3669,  3.6273,  0.7807,  1.4137,  1.5124,
          1.7567,  1.0021,  1.6691,  0.3591,  1.8744,  1.9273],
        [ 1.2956,  1.3237,  1.3809,  1.3594,  1.3295,  1.3004,  1.2639,  1.2932,
          1.2932,  1.2664,  1.3871,  1.2825,  1.4183,  1.3548,  1.4598,  1.2725,
          1.3436,  1.3211,  1.3464,  1.3381,  1.3878,  1.3600,  1.3178,  1.3130,
          1.2111,  1.3057,  1.3057,  1.3553,  1.4009,  1.3268,  1.1008,  1.3095,
          1.2014,  1.3674,  1.1985,  1.3294,  1.4714,  1.1664,  1.4646,  1.4811,
          1.0206,  0.9431,  1.4865,  1.3657,  0.8228,  3.5433,  2.6515,  3.7163,
          2.9522,  2.2401,  1.9402,  3.0526,  3.4768,  1.9251]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 331 : 180.67482006496004
Test loss for epoch 331 : 180.97420262539504
Test Precision for epoch 331 : 0.26153846153846155
Test Recall for epoch 331 : 0.26153846153846155
Test F1 for epoch 331 : 0.26153846153846155


theta for epoch 332 : tensor([[ 2.7450,  2.7712,  2.8374,  2.9775,  2.9450,  2.7493,  2.9256,  2.7430,
          2.7430,  1.2720,  1.2980,  1.2878,  1.3282,  1.2664,  1.3698,  1.2780,
          1.2552,  1.2790,  1.2602,  1.2391,  1.2552,  1.2737,  1.2321,  1.2273,
          1.2481,  1.2201,  1.2201,  1.2664,  1.3115,  1.2382,  1.2635,  1.3132,
          1.2495,  1.2788,  1.1998,  1.2407,  1.3922,  1.4404,  1.4240,  1.4018,
          1.4126,  1.3620,  1.4067,  1.2890,  1.3341,  1.3250,  1.2800,  1.2669,
          1.2524,  1.3228,  1.2739,  1.3578,  1.2408,  1.2560],
        [ 1.2558,  1.2825,  1.2849,  1.2776,  1.2924,  1.2629,  1.2633,  1.2556,
          1.2556,  2.3153,  2.3028,  2.2308,  2.4384,  2.2440,  4.7617,  2.2953,
          2.3034,  4.5389,  1.2628,  1.2902,  1.2598,  1.2591,  1.2819,  1.2769,
          1.2849,  1.2695,  1.2695,  1.3165,  1.2514,  1.2868,  1.3128,  1.2708,
          1.2985,  1.3285,  1.2496,  1.2894,  1.4333,  1.4837,  1.4118,  1.4367,
          1.4547,  1.4600,  1.3939,  1.2217,  1.3711,  1.3141,  1.3267,  1.3129,
          1.2978,  1.2644,  1.3203,  1.3114,  1.2859,  1.3017],
        [ 1.2127,  1.2404,  1.2872,  1.2750,  1.2455,  1.2174,  1.2258,  1.2103,
          1.2103,  1.2761,  1.3022,  1.2919,  1.3326,  1.2705,  1.3268,  1.2821,
          1.2120,  1.3282,  2.7779,  2.9793,  2.9902,  2.7985,  2.7421,  2.7431,
          2.9387,  2.7315,  2.7315,  1.2625,  1.3146,  1.2427,  1.2652,  1.2633,
          1.2540,  1.2834,  1.2502,  1.2452,  1.3948,  1.4431,  1.4234,  1.3400,
          1.4118,  1.4047,  1.4094,  1.2912,  1.2690,  1.3262,  1.2844,  1.2713,
          1.2567,  1.3252,  1.2783,  1.3606,  1.2319,  1.2604],
        [ 1.2250,  1.2526,  1.2988,  1.2872,  1.2579,  1.2296,  1.2382,  1.2226,
          1.2226,  1.2878,  1.3140,  1.3037,  1.3426,  1.2822,  1.3056,  1.2938,
          1.2704,  1.2622,  1.2768,  1.2883,  1.3168,  1.2903,  1.2486,  1.2439,
          1.2534,  1.2367,  1.2367,  3.0407,  3.0116,  2.6372,  2.7911,  3.0388,
          2.6471,  2.9796,  2.6485,  2.6393,  1.4061,  1.4546,  1.4360,  1.4031,
          1.4267,  1.4191,  1.4188,  1.2655,  1.3351,  1.3400,  1.2947,  1.2036,
          1.2197,  1.3378,  1.2885,  1.3732,  1.1977,  1.2705],
        [ 1.8481,  1.4311,  0.6072,  0.9134,  1.3200,  1.7722,  1.6429,  1.8851,
          1.8851,  1.7079,  1.3163,  1.5190,  0.9080,  1.7418,  0.1384,  1.6351,
          1.9217,  0.8434,  1.3319,  0.9895,  0.7463,  1.1464,  1.7110,  1.7816,
          1.5399,  1.8953,  1.8953,  0.8478,  0.8440,  1.8681,  1.6456,  0.8687,
          1.7998,  1.2456,  1.9204,  1.8296,  0.2753,  0.0555,  0.0320,  0.2322,
          0.4478,  0.5236,  0.1678, 17.4344,  3.5706,  0.7754,  1.4087,  1.5067,
          1.7518,  0.9959,  1.6641,  0.3541,  1.8709,  1.9226],
        [ 1.3025,  1.3305,  1.3877,  1.3662,  1.3364,  1.3072,  1.2708,  1.3001,
          1.3001,  1.2687,  1.3890,  1.2846,  1.4201,  1.3568,  1.4618,  1.2747,
          1.3453,  1.3234,  1.3552,  1.3463,  1.3968,  1.3689,  1.3266,  1.3218,
          1.2194,  1.3145,  1.3145,  1.3582,  1.4036,  1.3296,  1.1037,  1.3125,
          1.2045,  1.3703,  1.2016,  1.3322,  1.4745,  1.1701,  1.4670,  1.4841,
          1.0241,  0.9468,  1.4896,  1.3678,  0.8267,  3.5371,  2.6422,  3.7075,
          2.9428,  2.2311,  1.9312,  3.0435,  3.4703,  1.9161]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 332 : 180.65702666482355
Test loss for epoch 332 : 180.9696140464328
Test Precision for epoch 332 : 0.26153846153846155
Test Recall for epoch 332 : 0.26153846153846155
Test F1 for epoch 332 : 0.26153846153846155


theta for epoch 333 : tensor([[ 2.7406,  2.7668,  2.8331,  2.9733,  2.9408,  2.7450,  2.9213,  2.7386,
          2.7386,  1.2763,  1.3021,  1.2920,  1.3323,  1.2707,  1.3741,  1.2822,
          1.2592,  1.2834,  1.2580,  1.2369,  1.2531,  1.2716,  1.2299,  1.2251,
          1.2458,  1.2179,  1.2179,  1.2696,  1.3147,  1.2414,  1.2667,  1.3163,
          1.2527,  1.2821,  1.2030,  1.2440,  1.3934,  1.4416,  1.4253,  1.4030,
          1.4139,  1.3634,  1.4080,  1.2892,  1.3355,  1.3309,  1.2860,  1.2729,
          1.2584,  1.3288,  1.2799,  1.3638,  1.2467,  1.2620],
        [ 1.2505,  1.2775,  1.2825,  1.2729,  1.2866,  1.2570,  1.2587,  1.2498,
          1.2498,  2.3259,  2.3136,  2.2410,  2.4475,  2.2525,  4.7376,  2.3056,
          2.3182,  4.5146,  1.2563,  1.2833,  1.2534,  1.2548,  1.2748,  1.2698,
          1.2794,  1.2624,  1.2624,  1.3152,  1.2529,  1.2853,  1.3114,  1.2708,
          1.2970,  1.3271,  1.2481,  1.2879,  1.4311,  1.4815,  1.4097,  1.4354,
          1.4526,  1.4579,  1.3917,  1.2264,  1.3690,  1.3172,  1.3287,  1.3149,
          1.2998,  1.2679,  1.3223,  1.3136,  1.2878,  1.3037],
        [ 1.2126,  1.2403,  1.2866,  1.2749,  1.2454,  1.2173,  1.2257,  1.2102,
          1.2102,  1.2814,  1.3073,  1.2971,  1.3376,  1.2758,  1.3316,  1.2873,
          1.2170,  1.3334,  2.7719,  2.9748,  2.9843,  2.7921,  2.7365,  2.7371,
          2.9341,  2.7258,  2.7258,  1.2654,  1.3178,  1.2460,  1.2685,  1.2661,
          1.2573,  1.2868,  1.2535,  1.2486,  1.3966,  1.4449,  1.4252,  1.3413,
          1.4136,  1.4061,  1.4112,  1.2920,  1.2706,  1.3334,  1.2916,  1.2784,
          1.2639,  1.3323,  1.2855,  1.3676,  1.2386,  1.2676],
        [ 1.2213,  1.2489,  1.2949,  1.2837,  1.2542,  1.2259,  1.2345,  1.2189,
          1.2189,  1.2888,  1.3148,  1.3046,  1.3433,  1.2831,  1.3073,  1.2947,
          1.2711,  1.2640,  1.2715,  1.2825,  1.3115,  1.2850,  1.2432,  1.2385,
          1.2476,  1.2313,  1.2313,  3.0426,  3.0128,  2.6392,  2.7921,  3.0406,
          2.6492,  2.9806,  2.6506,  2.6414,  1.4053,  1.4538,  1.4353,  1.4017,
          1.4260,  1.4179,  1.4179,  1.2645,  1.3339,  1.3429,  1.2976,  1.2072,
          1.2225,  1.3407,  1.2913,  1.3760,  1.2000,  1.2734],
        [ 1.8459,  1.4294,  0.6060,  0.9121,  1.3186,  1.7705,  1.6404,  1.8833,
          1.8833,  1.7082,  1.3181,  1.5205,  0.9108,  1.7425,  0.1398,  1.6363,
          1.9239,  0.8445,  1.3296,  0.9886,  0.7448,  1.1433,  1.7087,  1.7793,
          1.5378,  1.8930,  1.8930,  0.8504,  0.8453,  1.8700,  1.6476,  0.8708,
          1.8018,  1.2477,  1.9223,  1.8315,  0.2729,  0.0533,  0.0297,  0.2298,
          0.4449,  0.5203,  0.1656, 17.5004,  3.5120,  0.7801,  1.4136,  1.5110,
          1.7566,  1.0004,  1.6690,  0.3589,  1.8769,  1.9273],
        [ 1.2966,  1.3247,  1.3819,  1.3604,  1.3305,  1.3014,  1.2649,  1.2942,
          1.2942,  1.2676,  1.3881,  1.2835,  1.4192,  1.3560,  1.4611,  1.2736,
          1.3441,  1.3225,  1.3470,  1.3374,  1.3886,  1.3607,  1.3184,  1.3136,
          1.2104,  1.3062,  1.3062,  1.3563,  1.4019,  1.3278,  1.1008,  1.3105,
          1.2024,  1.3685,  1.1994,  1.3304,  1.4724,  1.1672,  1.4641,  1.4820,
          1.0204,  0.9431,  1.4875,  1.3645,  0.8230,  3.5457,  2.6480,  3.7138,
          2.9485,  2.2371,  1.9373,  3.0490,  3.4791,  1.9223]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 333 : 180.63472737140842
Test loss for epoch 333 : 180.94869028927357
Test Precision for epoch 333 : 0.26153846153846155
Test Recall for epoch 333 : 0.26153846153846155
Test F1 for epoch 333 : 0.26153846153846155


theta for epoch 334 : tensor([[ 2.7440,  2.7702,  2.8365,  2.9768,  2.9443,  2.7484,  2.9248,  2.7420,
          2.7420,  1.2728,  1.2986,  1.2884,  1.3287,  1.2672,  1.3707,  1.2786,
          1.2554,  1.2801,  1.2597,  1.2385,  1.2547,  1.2733,  1.2316,  1.2269,
          1.2475,  1.2196,  1.2196,  1.2667,  1.3119,  1.2386,  1.2639,  1.3134,
          1.2498,  1.2793,  1.2001,  1.2411,  1.3925,  1.4407,  1.4246,  1.4020,
          1.4132,  1.3627,  1.4071,  1.2872,  1.3349,  1.3274,  1.2824,  1.2693,
          1.2548,  1.3253,  1.2763,  1.3602,  1.2430,  1.2584],
        [ 1.2532,  1.2801,  1.2874,  1.2763,  1.2890,  1.2594,  1.2621,  1.2521,
          1.2521,  2.3313,  2.3194,  2.2461,  2.4519,  2.2558,  4.7088,  2.3108,
          2.3280,  4.4855,  1.2604,  1.2870,  1.2568,  1.2610,  1.2786,  1.2737,
          1.2846,  1.2662,  1.2662,  1.3144,  1.2546,  1.2842,  1.3104,  1.2713,
          1.2959,  1.3261,  1.2471,  1.2868,  1.4309,  1.4813,  1.4097,  1.4361,
          1.4525,  1.4579,  1.3916,  1.2325,  1.3692,  1.3165,  1.3267,  1.3129,
          1.2978,  1.2676,  1.3203,  1.3125,  1.2857,  1.3016],
        [ 1.2127,  1.2403,  1.2862,  1.2749,  1.2455,  1.2174,  1.2258,  1.2103,
          1.2103,  1.2776,  1.3035,  1.2933,  1.3337,  1.2720,  1.3281,  1.2835,
          1.2127,  1.3298,  2.7755,  2.9798,  2.9878,  2.7953,  2.7404,  2.7406,
          2.9391,  2.7298,  2.7298,  1.2625,  1.3153,  1.2436,  1.2661,  1.2632,
          1.2549,  1.2844,  1.2511,  1.2461,  1.3958,  1.4442,  1.4245,  1.3398,
          1.4129,  1.4050,  1.4104,  1.2902,  1.2694,  1.3289,  1.2871,  1.2739,
          1.2593,  1.3279,  1.2810,  1.3632,  1.2334,  1.2630],
        [ 1.2236,  1.2511,  1.2966,  1.2858,  1.2565,  1.2282,  1.2368,  1.2212,
          1.2212,  1.2877,  1.3137,  1.3035,  1.3422,  1.2821,  1.3072,  1.2936,
          1.2698,  1.2640,  1.2755,  1.2859,  1.3154,  1.2891,  1.2473,  1.2426,
          1.2512,  1.2353,  1.2353,  3.0415,  3.0109,  2.6383,  2.7900,  3.0395,
          2.6483,  2.9786,  2.6499,  2.6405,  1.4059,  1.4545,  1.4359,  1.4018,
          1.4267,  1.4183,  1.4185,  1.2650,  1.3343,  1.3415,  1.2962,  1.2067,
          1.2211,  1.3394,  1.2900,  1.3747,  1.1981,  1.2720],
        [ 1.8475,  1.4311,  0.6069,  0.9134,  1.3206,  1.7724,  1.6416,  1.8852,
          1.8852,  1.7051,  1.3160,  1.5184,  0.9095,  1.7399,  0.1375,  1.6340,
          1.9226,  0.8415,  1.3323,  0.9919,  0.7473,  1.1448,  1.7116,  1.7822,
          1.5406,  1.8959,  1.8959,  0.8496,  0.8433,  1.8691,  1.6466,  0.8695,
          1.8009,  1.2463,  1.9215,  1.8306,  0.2718,  0.0524,  0.0285,  0.2285,
          0.4433,  0.5183,  0.1645, 17.5676,  3.4547,  0.7781,  1.4117,  1.5085,
          1.7547,  0.9978,  1.6671,  0.3572,  1.8764,  1.9254],
        [ 1.3002,  1.3282,  1.3853,  1.3639,  1.3341,  1.3049,  1.2684,  1.2977,
          1.2977,  1.2676,  1.3879,  1.2835,  1.4189,  1.3560,  1.4610,  1.2736,
          1.3438,  1.3227,  1.3520,  1.3419,  1.3937,  1.3658,  1.3234,  1.3186,
          1.2149,  1.3112,  1.3112,  1.3569,  1.4024,  1.3283,  1.1011,  1.3111,
          1.2030,  1.3691,  1.2001,  1.3309,  1.4738,  1.1688,  1.4649,  1.4833,
          1.0217,  0.9445,  1.4889,  1.3649,  0.8246,  3.5440,  2.6434,  3.7097,
          2.9438,  2.2327,  1.9330,  3.0444,  3.4774,  1.9180]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 334 : 180.61210046334205
Test loss for epoch 334 : 180.93566661148523
Test Precision for epoch 334 : 0.26153846153846155
Test Recall for epoch 334 : 0.26153846153846155
Test F1 for epoch 334 : 0.26153846153846155


theta for epoch 335 : tensor([[ 2.7426,  2.7689,  2.8352,  2.9755,  2.9430,  2.7470,  2.9235,  2.7406,
          2.7406,  1.2746,  1.3003,  1.2902,  1.3304,  1.2691,  1.3725,  1.2804,
          1.2570,  1.2820,  1.2593,  1.2381,  1.2542,  1.2728,  1.2312,  1.2265,
          1.2471,  1.2192,  1.2192,  1.2681,  1.3132,  1.2399,  1.2653,  1.3147,
          1.2512,  1.2806,  1.2015,  1.2424,  1.3931,  1.4414,  1.4253,  1.4027,
          1.4139,  1.3635,  1.4077,  1.2868,  1.3358,  1.3284,  1.2835,  1.2703,
          1.2558,  1.3263,  1.2774,  1.3613,  1.2440,  1.2594],
        [ 1.2509,  1.2779,  1.2874,  1.2747,  1.2863,  1.2568,  1.2605,  1.2495,
          1.2495,  2.3401,  2.3287,  2.2547,  2.4600,  2.2627,  4.6832,  2.3194,
          2.3413,  4.4598,  1.2579,  1.2843,  1.2543,  1.2605,  1.2759,  1.2709,
          1.2831,  1.2635,  1.2635,  1.3135,  1.2559,  1.2831,  1.3095,  1.2716,
          1.2948,  1.3251,  1.2461,  1.2857,  1.4296,  1.4800,  1.4085,  1.4355,
          1.4513,  1.4568,  1.3904,  1.2372,  1.3681,  1.3165,  1.3256,  1.3118,
          1.2967,  1.2678,  1.3192,  1.3119,  1.2845,  1.3006],
        [ 1.2124,  1.2400,  1.2854,  1.2746,  1.2452,  1.2171,  1.2255,  1.2100,
          1.2100,  1.2795,  1.3052,  1.2951,  1.3354,  1.2739,  1.3296,  1.2853,
          1.2143,  1.3316,  2.7739,  2.9796,  2.9862,  2.7933,  2.7391,  2.7389,
          2.9389,  2.7284,  2.7284,  1.2630,  1.3163,  1.2447,  1.2672,  1.2637,
          1.2560,  1.2855,  1.2521,  1.2472,  1.3965,  1.4449,  1.4252,  1.3400,
          1.4137,  1.4054,  1.4111,  1.2900,  1.2698,  1.3297,  1.2879,  1.2747,
          1.2601,  1.3287,  1.2818,  1.3641,  1.2336,  1.2637],
        [ 1.2221,  1.2497,  1.2947,  1.2844,  1.2550,  1.2268,  1.2353,  1.2197,
          1.2197,  1.2881,  1.3139,  1.3038,  1.3423,  1.2825,  1.3084,  1.2939,
          1.2699,  1.2653,  1.2737,  1.2836,  1.3137,  1.2873,  1.2456,  1.2408,
          1.2490,  1.2336,  1.2336,  3.0426,  3.0112,  2.6397,  2.7902,  3.0406,
          2.6497,  2.9787,  2.6514,  2.6419,  1.4057,  1.4543,  1.4357,  1.4010,
          1.4266,  1.4177,  1.4181,  1.2647,  1.3338,  1.3414,  1.2962,  1.2075,
          1.2210,  1.3393,  1.2899,  1.3746,  1.1975,  1.2719],
        [ 1.8469,  1.4308,  0.6066,  0.9130,  1.3204,  1.7721,  1.6406,  1.8849,
          1.8849,  1.7045,  1.3165,  1.5189,  0.9108,  1.7399,  0.1378,  1.6343,
          1.9238,  0.8414,  1.3321,  0.9925,  0.7473,  1.1437,  1.7113,  1.7819,
          1.5405,  1.8956,  1.8956,  0.8510,  0.8437,  1.8702,  1.6475,  0.8704,
          1.8020,  1.2472,  1.9226,  1.8317,  0.2702,  0.0510,  0.0269,  0.2268,
          0.4413,  0.5157,  0.1630, 17.6344,  3.3970,  0.7790,  1.4126,  1.5088,
          1.7555,  0.9984,  1.6679,  0.3582,  1.8785,  1.9263],
        [ 1.2989,  1.3269,  1.3840,  1.3626,  1.3328,  1.3036,  1.2671,  1.2964,
          1.2964,  1.2685,  1.3887,  1.2843,  1.4197,  1.3569,  1.4619,  1.2744,
          1.3444,  1.3237,  1.3502,  1.3395,  1.3918,  1.3640,  1.3215,  1.3167,
          1.2124,  1.3093,  1.3093,  1.3572,  1.4028,  1.3286,  1.1009,  1.3113,
          1.2033,  1.3695,  1.2003,  1.3312,  1.4738,  1.1685,  1.4642,  1.4833,
          1.0209,  0.9438,  1.4889,  1.3639,  0.8240,  3.5467,  2.6432,  3.7099,
          2.9435,  2.2327,  1.9332,  3.0441,  3.4801,  1.9181]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 335 : 180.5928463089868
Test loss for epoch 335 : 180.92233482479662
Test Precision for epoch 335 : 0.26153846153846155
Test Recall for epoch 335 : 0.26153846153846155
Test F1 for epoch 335 : 0.26153846153846155


theta for epoch 336 : tensor([[ 2.7425,  2.7687,  2.8350,  2.9754,  2.9429,  2.7468,  2.9234,  2.7404,
          2.7404,  1.2748,  1.3004,  1.2903,  1.3304,  1.2692,  1.3727,  1.2805,
          1.2570,  1.2823,  1.2584,  1.2372,  1.2534,  1.2720,  1.2303,  1.2256,
          1.2462,  1.2184,  1.2184,  1.2681,  1.3132,  1.2399,  1.2654,  1.3148,
          1.2512,  1.2808,  1.2015,  1.2425,  1.3933,  1.4416,  1.4256,  1.4029,
          1.4142,  1.3639,  1.4079,  1.2861,  1.3363,  1.3297,  1.2849,  1.2717,
          1.2572,  1.3277,  1.2787,  1.3626,  1.2453,  1.2608],
        [ 1.2500,  1.2770,  1.2885,  1.2746,  1.2853,  1.2558,  1.2603,  1.2485,
          1.2485,  2.3475,  2.3367,  2.2621,  2.4671,  2.2684,  4.6565,  2.3269,
          2.3533,  4.4329,  1.2561,  1.2823,  1.2524,  1.2605,  1.2739,  1.2689,
          1.2823,  1.2615,  1.2615,  1.3126,  1.2570,  1.2821,  1.3085,  1.2719,
          1.2938,  1.3241,  1.2451,  1.2847,  1.4286,  1.4791,  1.4077,  1.4352,
          1.4505,  1.4561,  1.3895,  1.2417,  1.3675,  1.3178,  1.3262,  1.3124,
          1.2973,  1.2695,  1.3198,  1.3124,  1.2850,  1.3011],
        [ 1.2129,  1.2405,  1.2854,  1.2750,  1.2457,  1.2176,  1.2260,  1.2105,
          1.2105,  1.2802,  1.3057,  1.2956,  1.3358,  1.2746,  1.3301,  1.2859,
          1.2146,  1.3323,  2.7724,  2.9795,  2.9846,  2.7914,  2.7378,  2.7373,
          2.9388,  2.7271,  2.7271,  1.2630,  1.3167,  1.2451,  1.2676,  1.2637,
          1.2564,  1.2860,  1.2526,  1.2476,  1.3971,  1.4455,  1.4259,  1.3400,
          1.4144,  1.4056,  1.4118,  1.2897,  1.2702,  1.3315,  1.2897,  1.2765,
          1.2618,  1.3304,  1.2835,  1.3658,  1.2348,  1.2654],
        [ 1.2219,  1.2494,  1.2940,  1.2842,  1.2548,  1.2265,  1.2351,  1.2195,
          1.2195,  1.2881,  1.3138,  1.3037,  1.3421,  1.2825,  1.3092,  1.2938,
          1.2696,  1.2662,  1.2726,  1.2820,  1.3126,  1.2862,  1.2445,  1.2398,
          1.2475,  1.2325,  1.2325,  3.0427,  3.0105,  2.6402,  2.7893,  3.0407,
          2.6501,  2.9779,  2.6519,  2.6423,  1.4057,  1.4544,  1.4358,  1.4005,
          1.4268,  1.4174,  1.4181,  1.2648,  1.3336,  1.3425,  1.2973,  1.2095,
          1.2221,  1.3405,  1.2911,  1.3757,  1.1981,  1.2731],
        [ 1.8473,  1.4313,  0.6071,  0.9134,  1.3212,  1.7726,  1.6406,  1.8853,
          1.8853,  1.7034,  1.3164,  1.5189,  0.9117,  1.7394,  0.1378,  1.6340,
          1.9241,  0.8408,  1.3320,  0.9934,  0.7476,  1.1429,  1.7112,  1.7818,
          1.5407,  1.8955,  1.8955,  0.8520,  0.8437,  1.8707,  1.6480,  0.8710,
          1.8026,  1.2476,  1.9231,  1.8322,  0.2685,  0.0495,  0.0252,  0.2249,
          0.4392,  0.5131,  0.1614, 17.7013,  3.3393,  0.7809,  1.4145,  1.5100,
          1.7573,  1.0000,  1.6698,  0.3603,  1.8815,  1.9280],
        [ 1.2976,  1.3256,  1.3827,  1.3614,  1.3315,  1.3023,  1.2658,  1.2951,
          1.2951,  1.2674,  1.3876,  1.2831,  1.4185,  1.3558,  1.4609,  1.2732,
          1.3432,  1.3227,  1.3476,  1.3363,  1.3893,  1.3614,  1.3189,  1.3140,
          1.2092,  1.3067,  1.3067,  1.3560,  1.4017,  1.3275,  1.0992,  1.3101,
          1.2020,  1.3684,  1.1990,  1.3301,  1.4732,  1.1676,  1.4629,  1.4827,
          1.0194,  0.9423,  1.4883,  1.3623,  0.8227,  3.5510,  2.6446,  3.7117,
          2.9447,  2.2344,  1.9350,  3.0453,  3.4845,  1.9199]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 336 : 180.57745244051404
Test loss for epoch 336 : 180.9119741228551
Test Precision for epoch 336 : 0.26153846153846155
Test Recall for epoch 336 : 0.26153846153846155
Test F1 for epoch 336 : 0.26153846153846155


theta for epoch 337 : tensor([[ 2.7444,  2.7706,  2.8370,  2.9774,  2.9449,  2.7488,  2.9254,  2.7424,
          2.7424,  1.2730,  1.2984,  1.2884,  1.3284,  1.2674,  1.3709,  1.2786,
          1.2549,  1.2805,  1.2603,  1.2390,  1.2552,  1.2739,  1.2323,  1.2276,
          1.2481,  1.2203,  1.2203,  1.2669,  1.3120,  1.2387,  1.2642,  1.3135,
          1.2500,  1.2795,  1.2002,  1.2412,  1.3931,  1.4415,  1.4254,  1.4026,
          1.4141,  1.3639,  1.4077,  1.2849,  1.3364,  1.3263,  1.2814,  1.2682,
          1.2537,  1.3243,  1.2752,  1.3592,  1.2417,  1.2573],
        [ 1.2512,  1.2781,  1.2914,  1.2766,  1.2864,  1.2569,  1.2621,  1.2496,
          1.2496,  2.3536,  2.3435,  2.2681,  2.4731,  2.2728,  4.6288,  2.3330,
          2.3641,  4.4049,  1.2589,  1.2850,  1.2549,  1.2649,  1.2766,  1.2717,
          1.2861,  1.2643,  1.2643,  1.3121,  1.2582,  1.2814,  1.3079,  1.2724,
          1.2931,  1.3234,  1.2445,  1.2840,  1.4284,  1.4788,  1.4076,  1.4355,
          1.4504,  1.4561,  1.3893,  1.2464,  1.3676,  1.3158,  1.3233,  1.3095,
          1.2943,  1.2678,  1.3169,  1.3100,  1.2820,  1.2982],
        [ 1.2124,  1.2399,  1.2844,  1.2745,  1.2451,  1.2171,  1.2255,  1.2100,
          1.2100,  1.2775,  1.3029,  1.2928,  1.3330,  1.2718,  1.3275,  1.2831,
          1.2114,  1.3296,  2.7756,  2.9842,  2.9878,  2.7942,  2.7413,  2.7405,
          2.9434,  2.7306,  2.7306,  1.2608,  1.3150,  1.2434,  1.2660,  1.2615,
          1.2547,  1.2844,  1.2509,  1.2460,  1.3965,  1.4450,  1.4254,  1.3388,
          1.4140,  1.4048,  1.4112,  1.2882,  1.2693,  1.3266,  1.2848,  1.2716,
          1.2569,  1.3256,  1.2786,  1.3610,  1.2293,  1.2605],
        [ 1.2232,  1.2507,  1.2948,  1.2854,  1.2561,  1.2278,  1.2364,  1.2207,
          1.2207,  1.2875,  1.3131,  1.3030,  1.3413,  1.2819,  1.3095,  1.2932,
          1.2688,  1.2666,  1.2757,  1.2844,  1.3156,  1.2893,  1.2476,  1.2429,
          1.2501,  1.2356,  1.2356,  3.0423,  3.0092,  2.6401,  2.7879,  3.0404,
          2.6501,  2.9765,  2.6520,  2.6423,  1.4062,  1.4549,  1.4363,  1.4005,
          1.4274,  1.4176,  1.4185,  1.2654,  1.3340,  1.3404,  1.2953,  1.2084,
          1.2201,  1.3385,  1.2891,  1.3737,  1.1955,  1.2710],
        [ 1.8484,  1.4324,  0.6076,  0.9140,  1.3223,  1.7738,  1.6414,  1.8865,
          1.8865,  1.7013,  1.3150,  1.5177,  0.9110,  1.7380,  0.1363,  1.6326,
          1.9234,  0.8388,  1.3343,  0.9961,  0.7496,  1.1444,  1.7137,  1.7842,
          1.5432,  1.8979,  1.8979,  0.8518,  0.8426,  1.8705,  1.6475,  0.8702,
          1.8024,  1.2469,  1.9229,  1.8320,  0.2676,  0.0487,  0.0243,  0.2239,
          0.4379,  0.5114,  0.1606, 17.7690,  3.2827,  0.7785,  1.4121,  1.5069,
          1.7548,  0.9972,  1.6673,  0.3581,  1.8803,  1.9257],
        [ 1.3005,  1.3285,  1.3856,  1.3643,  1.3344,  1.3052,  1.2688,  1.2980,
          1.2980,  1.2686,  1.3885,  1.2842,  1.4194,  1.3569,  1.4620,  1.2743,
          1.3440,  1.3239,  1.3523,  1.3405,  1.3941,  1.3662,  1.3236,  1.3188,
          1.2136,  1.3114,  1.3114,  1.3576,  1.4032,  1.3290,  1.1006,  1.3117,
          1.2037,  1.3700,  1.2007,  1.3316,  1.4749,  1.1694,  1.4640,  1.4843,
          1.0210,  0.9441,  1.4899,  1.3631,  0.8247,  3.5490,  2.6395,  3.7069,
          2.9395,  2.2296,  1.9302,  3.0402,  3.4824,  1.9152]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 337 : 180.56381672811642
Test loss for epoch 337 : 180.90823140530674
Test Precision for epoch 337 : 0.26153846153846155
Test Recall for epoch 337 : 0.26153846153846155
Test F1 for epoch 337 : 0.26153846153846155


theta for epoch 338 : tensor([[ 2.7418,  2.7681,  2.8344,  2.9749,  2.9424,  2.7462,  2.9229,  2.7398,
          2.7398,  1.2760,  1.3013,  1.2912,  1.3312,  1.2703,  1.3738,  1.2815,
          1.2577,  1.2835,  1.2578,  1.2365,  1.2528,  1.2714,  1.2298,  1.2251,
          1.2456,  1.2178,  1.2178,  1.2690,  1.3141,  1.2408,  1.2664,  1.3156,
          1.2521,  1.2818,  1.2024,  1.2434,  1.3938,  1.4422,  1.4263,  1.4034,
          1.4150,  1.3649,  1.4084,  1.2848,  1.3376,  1.3306,  1.2858,  1.2726,
          1.2580,  1.3286,  1.2796,  1.3635,  1.2460,  1.2616],
        [ 1.2473,  1.2742,  1.2894,  1.2735,  1.2824,  1.2529,  1.2588,  1.2456,
          1.2456,  2.3628,  2.3535,  2.2774,  2.4826,  2.2805,  4.6041,  2.3424,
          2.3781,  4.3802,  1.2532,  1.2792,  1.2494,  1.2607,  1.2707,  1.2658,
          1.2811,  1.2583,  1.2583,  1.3112,  1.2586,  1.2803,  1.3069,  1.2725,
          1.2920,  1.3225,  1.2435,  1.2829,  1.4267,  1.4772,  1.4061,  1.4343,
          1.4488,  1.4546,  1.3877,  1.2494,  1.3663,  1.3179,  1.3250,  1.3112,
          1.2961,  1.2702,  1.3186,  1.3111,  1.2837,  1.2999],
        [ 1.2130,  1.2405,  1.2845,  1.2750,  1.2457,  1.2176,  1.2260,  1.2105,
          1.2105,  1.2817,  1.3070,  1.2969,  1.3369,  1.2760,  1.3312,  1.2872,
          1.2154,  1.3337,  2.7706,  2.9806,  2.9828,  2.7888,  2.7363,  2.7353,
          2.9398,  2.7257,  2.7257,  1.2631,  1.3176,  1.2461,  1.2687,  1.2637,
          1.2574,  1.2871,  1.2536,  1.2487,  1.3981,  1.4466,  1.4269,  1.3399,
          1.4156,  1.4060,  1.4127,  1.2889,  1.2707,  1.3324,  1.2907,  1.2774,
          1.2628,  1.3313,  1.2844,  1.3667,  1.2346,  1.2663],
        [ 1.2207,  1.2482,  1.2920,  1.2831,  1.2536,  1.2254,  1.2340,  1.2183,
          1.2183,  1.2882,  1.3138,  1.3036,  1.3417,  1.2826,  1.3110,  1.2939,
          1.2693,  1.2682,  1.2711,  1.2794,  1.3111,  1.2847,  1.2430,  1.2383,
          1.2450,  1.2310,  1.2310,  3.0437,  3.0097,  2.6419,  2.7882,  3.0418,
          2.6519,  2.9769,  2.6539,  2.6441,  1.4056,  1.4543,  1.4356,  1.3993,
          1.4269,  1.4167,  1.4178,  1.2649,  1.3331,  1.3427,  1.2976,  1.2115,
          1.2224,  1.3408,  1.2914,  1.3759,  1.1973,  1.2734],
        [ 1.8476,  1.4319,  0.6077,  0.9136,  1.3220,  1.7731,  1.6404,  1.8857,
          1.8857,  1.7019,  1.3166,  1.5195,  0.9135,  1.7394,  0.1381,  1.6340,
          1.9253,  0.8403,  1.3325,  0.9954,  0.7484,  1.1422,  1.7117,  1.7822,
          1.5417,  1.8959,  1.8959,  0.8542,  0.8443,  1.8722,  1.6492,  0.8722,
          1.8041,  1.2487,  1.9245,  1.8337,  0.2655,  0.0468,  0.0223,  0.2215,
          0.4354,  0.5085,  0.1586, 17.8357,  3.2251,  0.7828,  1.4163,  1.5105,
          1.7588,  1.0014,  1.6714,  0.3626,  1.8854,  1.9295],
        [ 1.2960,  1.3240,  1.3812,  1.3599,  1.3300,  1.3008,  1.2643,  1.2936,
          1.2936,  1.2676,  1.3876,  1.2831,  1.4184,  1.3560,  1.4611,  1.2732,
          1.3430,  1.3230,  1.3454,  1.3331,  1.3871,  1.3592,  1.3166,  1.3118,
          1.2060,  1.3044,  1.3044,  1.3559,  1.4016,  1.3274,  1.0982,  1.3099,
          1.2019,  1.3685,  1.1989,  1.3300,  1.4731,  1.1670,  1.4616,  1.4826,
          1.0180,  0.9410,  1.4881,  1.3603,  0.8218,  3.5564,  2.6442,  3.7119,
          2.9440,  2.2345,  1.9353,  3.0446,  3.4901,  1.9202]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 338 : 180.54905173519532
Test loss for epoch 338 : 180.8956264075153
Test Precision for epoch 338 : 0.26153846153846155
Test Recall for epoch 338 : 0.26153846153846155
Test F1 for epoch 338 : 0.26153846153846155


theta for epoch 339 : tensor([[ 2.7453,  2.7715,  2.8378,  2.9784,  2.9459,  2.7496,  2.9264,  2.7432,
          2.7432,  1.2725,  1.2977,  1.2877,  1.3276,  1.2668,  1.3704,  1.2780,
          1.2540,  1.2801,  1.2603,  1.2389,  1.2551,  1.2738,  1.2323,  1.2276,
          1.2480,  1.2203,  1.2203,  1.2664,  1.3115,  1.2382,  1.2638,  1.3129,
          1.2495,  1.2792,  1.1997,  1.2407,  1.3932,  1.4416,  1.4257,  1.4028,
          1.4145,  1.3644,  1.4078,  1.2834,  1.3373,  1.3259,  1.2811,  1.2679,
          1.2533,  1.3240,  1.2749,  1.3589,  1.2412,  1.2569],
        [ 1.2501,  1.2769,  1.2935,  1.2772,  1.2852,  1.2557,  1.2620,  1.2485,
          1.2485,  2.3675,  2.3591,  2.2822,  2.4878,  2.2837,  4.5754,  2.3473,
          2.3875,  4.3513,  1.2579,  1.2838,  1.2538,  1.2666,  1.2754,  1.2706,
          1.2866,  1.2631,  1.2631,  1.3108,  1.2593,  1.2797,  1.3064,  1.2730,
          1.2914,  1.3219,  1.2430,  1.2823,  1.4270,  1.4775,  1.4066,  1.4350,
          1.4492,  1.4551,  1.3881,  1.2537,  1.3670,  1.3157,  1.3221,  1.3084,
          1.2932,  1.2682,  1.3157,  1.3087,  1.2808,  1.2970],
        [ 1.2125,  1.2400,  1.2836,  1.2745,  1.2452,  1.2172,  1.2256,  1.2101,
          1.2101,  1.2772,  1.3024,  1.2923,  1.3323,  1.2714,  1.3269,  1.2826,
          1.2105,  1.3293,  2.7754,  2.9869,  2.9875,  2.7933,  2.7414,  2.7401,
          2.9461,  2.7308,  2.7308,  1.2596,  1.3146,  1.2432,  1.2659,  1.2602,
          1.2546,  1.2843,  1.2507,  1.2458,  1.3970,  1.4456,  1.4260,  1.3382,
          1.4147,  1.4046,  1.4117,  1.2870,  1.2694,  1.3262,  1.2845,  1.2712,
          1.2565,  1.3252,  1.2782,  1.3606,  1.2278,  1.2601],
        [ 1.2231,  1.2506,  1.2938,  1.2853,  1.2560,  1.2277,  1.2364,  1.2207,
          1.2207,  1.2872,  1.3126,  1.3025,  1.3404,  1.2815,  1.3109,  1.2927,
          1.2680,  1.2681,  1.2757,  1.2834,  1.3157,  1.2894,  1.2477,  1.2430,
          1.2493,  1.2357,  1.2357,  3.0427,  3.0077,  2.6412,  2.7861,  3.0408,
          2.6512,  2.9748,  2.6534,  2.6434,  1.4064,  1.4551,  1.4364,  1.3996,
          1.4278,  1.4171,  1.4184,  1.2660,  1.3337,  1.3404,  1.2953,  1.2102,
          1.2201,  1.3385,  1.2891,  1.3737,  1.1945,  1.2710],
        [ 1.8495,  1.4337,  0.6087,  0.9147,  1.3238,  1.7750,  1.6420,  1.8876,
          1.8876,  1.6993,  1.3145,  1.5178,  0.9120,  1.7375,  0.1360,  1.6319,
          1.9238,  0.8376,  1.3356,  0.9988,  0.7511,  1.1447,  1.7150,  1.7855,
          1.5452,  1.8992,  1.8992,  0.8532,  0.8426,  1.8713,  1.6480,  0.8707,
          1.8032,  1.2472,  1.9236,  1.8328,  0.2648,  0.0464,  0.0216,  0.2207,
          0.4344,  0.5071,  0.1580, 17.9037,  3.1693,  0.7799,  1.4133,  1.5068,
          1.7558,  0.9980,  1.6683,  0.3597,  1.8836,  1.9266],
        [ 1.3004,  1.3284,  1.3854,  1.3642,  1.3344,  1.3051,  1.2687,  1.2979,
          1.2979,  1.2686,  1.3882,  1.2839,  1.4189,  1.3567,  1.4618,  1.2741,
          1.3435,  1.3239,  1.3521,  1.3395,  1.3940,  1.3661,  1.3235,  1.3186,
          1.2126,  1.3112,  1.3112,  1.3574,  1.4030,  1.3288,  1.0998,  1.3115,
          1.2036,  1.3700,  1.2006,  1.3314,  1.4751,  1.1694,  1.4632,  1.4847,
          1.0203,  0.9436,  1.4902,  1.3617,  0.8246,  3.5532,  2.6379,  3.7059,
          2.9376,  2.2285,  1.9294,  3.0383,  3.4867,  1.9143]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 339 : 180.53165171182602
Test loss for epoch 339 : 180.88928391640795
Test Precision for epoch 339 : 0.26153846153846155
Test Recall for epoch 339 : 0.26153846153846155
Test F1 for epoch 339 : 0.26153846153846155


theta for epoch 340 : tensor([[ 2.7424,  2.7686,  2.8350,  2.9756,  2.9431,  2.7467,  2.9236,  2.7403,
          2.7403,  1.2757,  1.3008,  1.2908,  1.3305,  1.2699,  1.3735,  1.2811,
          1.2570,  1.2833,  1.2584,  1.2371,  1.2533,  1.2720,  1.2304,  1.2257,
          1.2461,  1.2185,  1.2185,  1.2687,  1.3138,  1.2406,  1.2662,  1.3152,
          1.2518,  1.2816,  1.2021,  1.2431,  1.3941,  1.4425,  1.4266,  1.4038,
          1.4154,  1.3655,  1.4087,  1.2836,  1.3386,  1.3300,  1.2852,  1.2720,
          1.2575,  1.3281,  1.2791,  1.3630,  1.2452,  1.2610],
        [ 1.2460,  1.2729,  1.2912,  1.2741,  1.2812,  1.2518,  1.2584,  1.2445,
          1.2445,  2.3765,  2.3690,  2.2915,  2.4976,  2.2915,  4.5509,  2.3567,
          2.4014,  4.3269,  1.2527,  1.2786,  1.2488,  1.2624,  1.2700,  1.2652,
          1.2819,  1.2578,  1.2578,  1.3099,  1.2593,  1.2787,  1.3055,  1.2731,
          1.2904,  1.3210,  1.2421,  1.2814,  1.4254,  1.4759,  1.4052,  1.4338,
          1.4478,  1.4538,  1.3866,  1.2559,  1.3659,  1.3172,  1.3234,  1.3097,
          1.2945,  1.2700,  1.3170,  1.3093,  1.2820,  1.2983],
        [ 1.2126,  1.2401,  1.2832,  1.2746,  1.2453,  1.2173,  1.2257,  1.2102,
          1.2102,  1.2810,  1.3061,  1.2961,  1.3359,  1.2752,  1.3303,  1.2864,
          1.2141,  1.3330,  2.7711,  2.9841,  2.9833,  2.7888,  2.7372,  2.7357,
          2.9432,  2.7266,  2.7266,  1.2616,  1.3169,  1.2456,  1.2683,  1.2621,
          1.2569,  1.2867,  1.2531,  1.2482,  1.3983,  1.4469,  1.4273,  1.3390,
          1.4160,  1.4055,  1.4130,  1.2876,  1.2706,  1.3313,  1.2896,  1.2764,
          1.2617,  1.3302,  1.2834,  1.3655,  1.2325,  1.2652],
        [ 1.2205,  1.2480,  1.2909,  1.2829,  1.2535,  1.2252,  1.2338,  1.2181,
          1.2181,  1.2879,  1.3132,  1.3031,  1.3409,  1.2822,  1.3123,  1.2934,
          1.2685,  1.2696,  1.2716,  1.2788,  1.3115,  1.2852,  1.2435,  1.2388,
          1.2446,  1.2315,  1.2315,  3.0442,  3.0082,  2.6432,  2.7865,  3.0423,
          2.6531,  2.9752,  2.6555,  2.6454,  1.4057,  1.4545,  1.4357,  1.3985,
          1.4272,  1.4161,  1.4177,  1.2656,  1.3329,  1.3423,  1.2973,  1.2130,
          1.2220,  1.3404,  1.2910,  1.3756,  1.1959,  1.2729],
        [ 1.8487,  1.4331,  0.6087,  0.9142,  1.3234,  1.7742,  1.6411,  1.8868,
          1.8868,  1.7002,  1.3162,  1.5197,  0.9146,  1.7392,  0.1379,  1.6334,
          1.9257,  0.8392,  1.3342,  0.9984,  0.7503,  1.1431,  1.7134,  1.7838,
          1.5442,  1.8975,  1.8975,  0.8556,  0.8443,  1.8729,  1.6496,  0.8726,
          1.8049,  1.2490,  1.9252,  1.8345,  0.2628,  0.0446,  0.0197,  0.2184,
          0.4321,  0.5043,  0.1561, 17.9706,  3.1124,  0.7839,  1.4172,  1.5101,
          1.7594,  1.0020,  1.6721,  0.3638,  1.8883,  1.9301],
        [ 1.2962,  1.3242,  1.3813,  1.3601,  1.3302,  1.3010,  1.2645,  1.2937,
          1.2937,  1.2679,  1.3877,  1.2832,  1.4183,  1.3562,  1.4613,  1.2733,
          1.3428,  1.3233,  1.3462,  1.3331,  1.3881,  1.3601,  1.3175,  1.3127,
          1.2062,  1.3053,  1.3053,  1.3560,  1.4017,  1.3275,  1.0978,  1.3100,
          1.2021,  1.3687,  1.1990,  1.3301,  1.4735,  1.1673,  1.4611,  1.4831,
          1.0176,  0.9409,  1.4886,  1.3593,  0.8221,  3.5600,  2.6419,  3.7102,
          2.9415,  2.2328,  1.9338,  3.0421,  3.4937,  1.9188]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 340 : 180.51253622040315
Test loss for epoch 340 : 180.8726985560374
Test Precision for epoch 340 : 0.26153846153846155
Test Recall for epoch 340 : 0.26153846153846155
Test F1 for epoch 340 : 0.26153846153846155


theta for epoch 341 : tensor([[ 2.7451,  2.7713,  2.8377,  2.9784,  2.9458,  2.7494,  2.9264,  2.7430,
          2.7430,  1.2734,  1.2984,  1.2884,  1.3281,  1.2676,  1.3711,  1.2787,
          1.2545,  1.2811,  1.2594,  1.2380,  1.2542,  1.2729,  1.2314,  1.2267,
          1.2471,  1.2195,  1.2195,  1.2669,  1.3121,  1.2387,  1.2645,  1.3134,
          1.2500,  1.2798,  1.2003,  1.2413,  1.3935,  1.4420,  1.4261,  1.4033,
          1.4150,  1.3651,  1.4081,  1.2823,  1.3385,  1.3269,  1.2821,  1.2689,
          1.2544,  1.3250,  1.2760,  1.3600,  1.2421,  1.2579],
        [ 1.2478,  1.2746,  1.2940,  1.2768,  1.2830,  1.2536,  1.2605,  1.2463,
          1.2463,  2.3819,  2.3754,  2.2972,  2.5042,  2.2958,  4.5234,  2.3625,
          2.4117,  4.2993,  1.2550,  1.2809,  1.2510,  1.2655,  1.2723,  1.2676,
          1.2847,  1.2601,  1.2601,  1.3095,  1.2595,  1.2782,  1.3050,  1.2735,
          1.2899,  1.3205,  1.2417,  1.2808,  1.4253,  1.4758,  1.4053,  1.4340,
          1.4478,  1.4539,  1.3866,  1.2590,  1.3663,  1.3156,  1.3214,  1.3077,
          1.2925,  1.2685,  1.3150,  1.3074,  1.2800,  1.2963],
        [ 1.2130,  1.2404,  1.2831,  1.2750,  1.2457,  1.2177,  1.2261,  1.2106,
          1.2106,  1.2786,  1.3036,  1.2935,  1.3333,  1.2727,  1.3279,  1.2838,
          1.2113,  1.3306,  2.7735,  2.9879,  2.9856,  2.7908,  2.7398,  2.7380,
          2.9470,  2.7291,  2.7291,  1.2596,  1.3153,  1.2441,  1.2668,  1.2601,
          1.2554,  1.2852,  1.2515,  1.2466,  1.3978,  1.4465,  1.4269,  1.3380,
          1.4157,  1.4047,  1.4125,  1.2865,  1.2699,  1.3279,  1.2861,  1.2729,
          1.2582,  1.3267,  1.2799,  1.3621,  1.2285,  1.2617],
        [ 1.2223,  1.2498,  1.2921,  1.2845,  1.2552,  1.2269,  1.2355,  1.2199,
          1.2199,  1.2872,  1.3125,  1.3024,  1.3399,  1.2815,  1.3125,  1.2926,
          1.2677,  1.2699,  1.2740,  1.2807,  1.3140,  1.2877,  1.2460,  1.2413,
          1.2467,  1.2340,  1.2340,  3.0438,  3.0067,  2.6431,  2.7848,  3.0418,
          2.6531,  2.9736,  2.6555,  2.6453,  1.4061,  1.4549,  1.4360,  1.3984,
          1.4277,  1.4162,  1.4179,  1.2664,  1.3332,  1.3409,  1.2958,  1.2125,
          1.2205,  1.3390,  1.2896,  1.3742,  1.1939,  1.2715],
        [ 1.8506,  1.4349,  0.6099,  0.9154,  1.3252,  1.7760,  1.6427,  1.8885,
          1.8885,  1.6986,  1.3149,  1.5190,  0.9140,  1.7384,  0.1368,  1.6322,
          1.9250,  0.8376,  1.3361,  1.0008,  0.7520,  1.1447,  1.7154,  1.7858,
          1.5466,  1.8995,  1.8995,  0.8554,  0.8435,  1.8727,  1.6490,  0.8719,
          1.8047,  1.2483,  1.9250,  1.8343,  0.2618,  0.0438,  0.0187,  0.2172,
          0.4308,  0.5026,  0.1552, 18.0384,  3.0571,  0.7825,  1.4157,  1.5079,
          1.7578,  1.0003,  1.6705,  0.3626,  1.8878,  1.9285],
        [ 1.2991,  1.3271,  1.3841,  1.3629,  1.3331,  1.3038,  1.2674,  1.2966,
          1.2966,  1.2684,  1.3879,  1.2835,  1.4184,  1.3564,  1.4615,  1.2737,
          1.3430,  1.3238,  1.3500,  1.3366,  1.3919,  1.3639,  1.3213,  1.3165,
          1.2097,  1.3091,  1.3091,  1.3568,  1.4025,  1.3283,  1.0986,  1.3109,
          1.2030,  1.3695,  1.1999,  1.3309,  1.4747,  1.1686,  1.4618,  1.4843,
          1.0188,  0.9422,  1.4897,  1.3598,  0.8237,  3.5592,  2.6381,  3.7065,
          2.9375,  2.2293,  1.9304,  3.0382,  3.4928,  1.9153]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 341 : 180.49359691873929
Test loss for epoch 341 : 180.86289353491753
Test Precision for epoch 341 : 0.26153846153846155
Test Recall for epoch 341 : 0.26153846153846155
Test F1 for epoch 341 : 0.26153846153846155


theta for epoch 342 : tensor([[2.7437e+00, 2.7700e+00, 2.8364e+00, 2.9771e+00, 2.9446e+00, 2.7481e+00,
         2.9251e+00, 2.7417e+00, 2.7417e+00, 1.2746e+00, 1.2995e+00, 1.2894e+00,
         1.3291e+00, 1.2686e+00, 1.3722e+00, 1.2797e+00, 1.2555e+00, 1.2822e+00,
         1.2597e+00, 1.2383e+00, 1.2546e+00, 1.2733e+00, 1.2318e+00, 1.2271e+00,
         1.2474e+00, 1.2199e+00, 1.2199e+00, 1.2679e+00, 1.3130e+00, 1.2397e+00,
         1.2655e+00, 1.3144e+00, 1.2510e+00, 1.2808e+00, 1.2013e+00, 1.2423e+00,
         1.3940e+00, 1.4425e+00, 1.4267e+00, 1.4039e+00, 1.4156e+00, 1.3658e+00,
         1.4086e+00, 1.2824e+00, 1.3395e+00, 1.3283e+00, 1.2836e+00, 1.2704e+00,
         1.2558e+00, 1.3265e+00, 1.2774e+00, 1.3614e+00, 1.2435e+00, 1.2594e+00],
        [1.2456e+00, 1.2725e+00, 1.2932e+00, 1.2757e+00, 1.2809e+00, 1.2515e+00,
         1.2586e+00, 1.2442e+00, 1.2442e+00, 2.3891e+00, 2.3837e+00, 2.3049e+00,
         2.5127e+00, 2.3020e+00, 4.4977e+00, 2.3702e+00, 2.4239e+00, 4.2737e+00,
         1.2536e+00, 1.2796e+00, 1.2497e+00, 1.2648e+00, 1.2709e+00, 1.2662e+00,
         1.2837e+00, 1.2587e+00, 1.2587e+00, 1.3089e+00, 1.2594e+00, 1.2775e+00,
         1.3043e+00, 1.2738e+00, 1.2892e+00, 1.3199e+00, 1.2411e+00, 1.2801e+00,
         1.4245e+00, 1.4750e+00, 1.4046e+00, 1.4334e+00, 1.4470e+00, 1.4532e+00,
         1.3859e+00, 1.2610e+00, 1.3659e+00, 1.3158e+00, 1.3215e+00, 1.3077e+00,
         1.2926e+00, 1.2689e+00, 1.3151e+00, 1.3070e+00, 1.2800e+00, 1.2964e+00],
        [1.2122e+00, 1.2396e+00, 1.2819e+00, 1.2742e+00, 1.2449e+00, 1.2169e+00,
         1.2253e+00, 1.2098e+00, 1.2098e+00, 1.2793e+00, 1.3042e+00, 1.2941e+00,
         1.3338e+00, 1.2733e+00, 1.3283e+00, 1.2844e+00, 1.2117e+00, 1.3312e+00,
         2.7728e+00, 2.9887e+00, 2.9850e+00, 2.7899e+00, 2.7392e+00, 2.7372e+00,
         2.9478e+00, 2.7286e+00, 2.7286e+00, 1.2595e+00, 1.3156e+00, 1.2445e+00,
         1.2673e+00, 1.2601e+00, 1.2558e+00, 1.2857e+00, 1.2519e+00, 1.2471e+00,
         1.3981e+00, 1.4468e+00, 1.4272e+00, 1.3378e+00, 1.4160e+00, 1.4047e+00,
         1.4128e+00, 1.2862e+00, 1.2701e+00, 1.3290e+00, 1.2873e+00, 1.2741e+00,
         1.2594e+00, 1.3278e+00, 1.2811e+00, 1.3632e+00, 1.2293e+00, 1.2630e+00],
        [1.2210e+00, 1.2485e+00, 1.2905e+00, 1.2833e+00, 1.2539e+00, 1.2257e+00,
         1.2343e+00, 1.2186e+00, 1.2186e+00, 1.2873e+00, 1.3125e+00, 1.3023e+00,
         1.3397e+00, 1.2815e+00, 1.3133e+00, 1.2926e+00, 1.2676e+00, 1.2708e+00,
         1.2734e+00, 1.2795e+00, 1.3134e+00, 1.2870e+00, 1.2453e+00, 1.2406e+00,
         1.2455e+00, 1.2334e+00, 1.2334e+00, 3.0444e+00, 3.0062e+00, 2.6442e+00,
         2.7843e+00, 3.0424e+00, 2.6542e+00, 2.9730e+00, 2.6568e+00, 2.6464e+00,
         1.4059e+00, 1.4548e+00, 1.4358e+00, 1.3978e+00, 1.4276e+00, 1.4156e+00,
         1.4176e+00, 1.2667e+00, 1.3329e+00, 1.3414e+00, 1.2964e+00, 1.2140e+00,
         1.2211e+00, 1.3396e+00, 1.2902e+00, 1.3747e+00, 1.1940e+00, 1.2720e+00],
        [1.8504e+00, 1.4346e+00, 6.0989e-01, 9.1501e-01, 1.3251e+00, 1.7757e+00,
         1.6423e+00, 1.8882e+00, 1.8882e+00, 1.6985e+00, 1.3153e+00, 1.5198e+00,
         9.1511e-01, 1.7392e+00, 1.3747e-01, 1.6325e+00, 1.9257e+00, 8.3780e-01,
         1.3365e+00, 1.0019e+00, 7.5275e-01, 1.1450e+00, 1.7159e+00, 1.7862e+00,
         1.5476e+00, 1.8998e+00, 1.8998e+00, 8.5662e-01, 8.4421e-01, 1.8736e+00,
         1.6497e+00, 8.7260e-01, 1.8056e+00, 1.2490e+00, 1.9258e+00, 1.8352e+00,
         2.6035e-01, 4.2434e-02, 1.7302e-02, 2.1543e-01, 4.2900e-01, 5.0035e-01,
         1.5381e-01, 1.8106e+01, 3.0017e+00, 7.8424e-01, 1.4173e+00, 1.5089e+00,
         1.7593e+00, 1.0019e+00, 1.6720e+00, 3.6440e-01, 1.8903e+00, 1.9299e+00],
        [1.2972e+00, 1.3252e+00, 1.3823e+00, 1.3611e+00, 1.3312e+00, 1.3019e+00,
         1.2655e+00, 1.2947e+00, 1.2947e+00, 1.2680e+00, 1.3875e+00, 1.2831e+00,
         1.4179e+00, 1.3560e+00, 1.4612e+00, 1.2733e+00, 1.3425e+00, 1.3235e+00,
         1.3489e+00, 1.3351e+00, 1.3908e+00, 1.3628e+00, 1.3202e+00, 1.3154e+00,
         1.2082e+00, 1.3079e+00, 1.3079e+00, 1.3563e+00, 1.4020e+00, 1.3278e+00,
         1.0978e+00, 1.3103e+00, 1.2024e+00, 1.3691e+00, 1.1994e+00, 1.3304e+00,
         1.4742e+00, 1.1679e+00, 1.4609e+00, 1.4839e+00, 1.0177e+00, 9.4124e-01,
         1.4892e+00, 1.3587e+00, 8.2301e-01, 3.5630e+00, 2.6390e+00, 3.7076e+00,
         2.9382e+00, 2.2305e+00, 1.9317e+00, 3.0389e+00, 3.4967e+00, 1.9166e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 342 : 180.47643815355383
Test loss for epoch 342 : 180.85087808562534
Test Precision for epoch 342 : 0.26153846153846155
Test Recall for epoch 342 : 0.26153846153846155
Test F1 for epoch 342 : 0.26153846153846155


theta for epoch 343 : tensor([[2.7449e+00, 2.7711e+00, 2.8375e+00, 2.9783e+00, 2.9457e+00, 2.7492e+00,
         2.9263e+00, 2.7428e+00, 2.7428e+00, 1.2745e+00, 1.2993e+00, 1.2892e+00,
         1.3288e+00, 1.2685e+00, 1.3721e+00, 1.2796e+00, 1.2553e+00, 1.2822e+00,
         1.2581e+00, 1.2367e+00, 1.2530e+00, 1.2717e+00, 1.2302e+00, 1.2255e+00,
         1.2458e+00, 1.2183e+00, 1.2183e+00, 1.2676e+00, 1.3128e+00, 1.2395e+00,
         1.2653e+00, 1.3142e+00, 1.2508e+00, 1.2806e+00, 1.2010e+00, 1.2420e+00,
         1.3938e+00, 1.4424e+00, 1.4266e+00, 1.4038e+00, 1.4155e+00, 1.3658e+00,
         1.4084e+00, 1.2817e+00, 1.3397e+00, 1.3281e+00, 1.2834e+00, 1.2702e+00,
         1.2556e+00, 1.3263e+00, 1.2772e+00, 1.3613e+00, 1.2432e+00, 1.2592e+00],
        [1.2451e+00, 1.2720e+00, 1.2939e+00, 1.2762e+00, 1.2805e+00, 1.2511e+00,
         1.2584e+00, 1.2438e+00, 1.2438e+00, 2.3961e+00, 2.3917e+00, 2.3123e+00,
         2.5212e+00, 2.3081e+00, 4.4721e+00, 2.3777e+00, 2.4358e+00, 4.2482e+00,
         1.2516e+00, 1.2775e+00, 1.2478e+00, 1.2631e+00, 1.2688e+00, 1.2640e+00,
         1.2818e+00, 1.2565e+00, 1.2565e+00, 1.3084e+00, 1.2591e+00, 1.2768e+00,
         1.3037e+00, 1.2741e+00, 1.2885e+00, 1.3193e+00, 1.2405e+00, 1.2794e+00,
         1.4238e+00, 1.4743e+00, 1.4041e+00, 1.4329e+00, 1.4464e+00, 1.4527e+00,
         1.3853e+00, 1.2627e+00, 1.3657e+00, 1.3154e+00, 1.3209e+00, 1.3072e+00,
         1.2921e+00, 1.2686e+00, 1.3145e+00, 1.3062e+00, 1.2794e+00, 1.2958e+00],
        [1.2134e+00, 1.2408e+00, 1.2827e+00, 1.2753e+00, 1.2461e+00, 1.2181e+00,
         1.2265e+00, 1.2110e+00, 1.2110e+00, 1.2803e+00, 1.3052e+00, 1.2951e+00,
         1.3348e+00, 1.2743e+00, 1.3292e+00, 1.2854e+00, 1.2126e+00, 1.3322e+00,
         2.7713e+00, 2.9886e+00, 2.9835e+00, 2.7881e+00, 2.7377e+00, 2.7355e+00,
         2.9477e+00, 2.7271e+00, 2.7271e+00, 1.2598e+00, 1.3163e+00, 1.2452e+00,
         1.2680e+00, 1.2603e+00, 1.2566e+00, 1.2864e+00, 1.2526e+00, 1.2478e+00,
         1.3987e+00, 1.4474e+00, 1.4278e+00, 1.3380e+00, 1.4167e+00, 1.4050e+00,
         1.4134e+00, 1.2862e+00, 1.2706e+00, 1.3300e+00, 1.2884e+00, 1.2752e+00,
         1.2605e+00, 1.3287e+00, 1.2821e+00, 1.3641e+00, 1.2298e+00, 1.2640e+00],
        [1.2212e+00, 1.2487e+00, 1.2902e+00, 1.2835e+00, 1.2541e+00, 1.2259e+00,
         1.2344e+00, 1.2188e+00, 1.2188e+00, 1.2874e+00, 1.3125e+00, 1.3023e+00,
         1.3395e+00, 1.2815e+00, 1.3142e+00, 1.2926e+00, 1.2675e+00, 1.2717e+00,
         1.2719e+00, 1.2775e+00, 1.3119e+00, 1.2855e+00, 1.2438e+00, 1.2391e+00,
         1.2436e+00, 1.2319e+00, 1.2319e+00, 3.0450e+00, 3.0057e+00, 2.6453e+00,
         2.7836e+00, 3.0430e+00, 2.6552e+00, 2.9724e+00, 2.6580e+00, 2.6475e+00,
         1.4058e+00, 1.4546e+00, 1.4355e+00, 1.3972e+00, 1.4276e+00, 1.4152e+00,
         1.4173e+00, 1.2670e+00, 1.3327e+00, 1.3414e+00, 1.2964e+00, 1.2149e+00,
         1.2211e+00, 1.3396e+00, 1.2902e+00, 1.3748e+00, 1.1935e+00, 1.2721e+00],
        [1.8516e+00, 1.4358e+00, 6.1097e-01, 9.1581e-01, 1.3263e+00, 1.7768e+00,
         1.6434e+00, 1.8893e+00, 1.8893e+00, 1.6985e+00, 1.3157e+00, 1.5206e+00,
         9.1615e-01, 1.7400e+00, 1.3805e-01, 1.6327e+00, 1.9264e+00, 8.3797e-01,
         1.3363e+00, 1.0024e+00, 7.5281e-01, 1.1447e+00, 1.7156e+00, 1.7859e+00,
         1.5480e+00, 1.8995e+00, 1.8995e+00, 8.5772e-01, 8.4479e-01, 1.8743e+00,
         1.6502e+00, 8.7318e-01, 1.8064e+00, 1.2496e+00, 1.9266e+00, 1.8360e+00,
         2.5889e-01, 4.1148e-02, 1.5911e-02, 2.1370e-01, 4.2726e-01, 4.9820e-01,
         1.5243e-01, 1.8173e+01, 2.9469e+00, 7.8543e-01, 1.4183e+00, 1.5094e+00,
         1.7603e+00, 1.0029e+00, 1.6730e+00, 3.6570e-01, 1.8922e+00, 1.9308e+00],
        [1.2973e+00, 1.3253e+00, 1.3824e+00, 1.3612e+00, 1.3314e+00, 1.3021e+00,
         1.2656e+00, 1.2949e+00, 1.2949e+00, 1.2682e+00, 1.3876e+00, 1.2831e+00,
         1.4179e+00, 1.3561e+00, 1.4613e+00, 1.2733e+00, 1.3425e+00, 1.3237e+00,
         1.3474e+00, 1.3333e+00, 1.3893e+00, 1.3613e+00, 1.3188e+00, 1.3140e+00,
         1.2065e+00, 1.3065e+00, 1.3065e+00, 1.3562e+00, 1.4020e+00, 1.3278e+00,
         1.0975e+00, 1.3102e+00, 1.2024e+00, 1.3691e+00, 1.1993e+00, 1.3304e+00,
         1.4740e+00, 1.1677e+00, 1.4604e+00, 1.4839e+00, 1.0172e+00, 9.4083e-01,
         1.4891e+00, 1.3581e+00, 8.2292e-01, 3.5657e+00, 2.6389e+00, 3.7075e+00,
         2.9378e+00, 2.2306e+00, 1.9320e+00, 3.0386e+00, 3.4995e+00, 1.9169e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 343 : 180.46130149850316
Test loss for epoch 343 : 180.84191453399268
Test Precision for epoch 343 : 0.26153846153846155
Test Recall for epoch 343 : 0.26153846153846155
Test F1 for epoch 343 : 0.26153846153846155


theta for epoch 344 : tensor([[2.7451e+00, 2.7714e+00, 2.8378e+00, 2.9786e+00, 2.9461e+00, 2.7495e+00,
         2.9266e+00, 2.7431e+00, 2.7431e+00, 1.2736e+00, 1.2984e+00, 1.2883e+00,
         1.3279e+00, 1.2675e+00, 1.3713e+00, 1.2786e+00, 1.2543e+00, 1.2814e+00,
         1.2605e+00, 1.2390e+00, 1.2553e+00, 1.2740e+00, 1.2326e+00, 1.2279e+00,
         1.2481e+00, 1.2207e+00, 1.2207e+00, 1.2672e+00, 1.3124e+00, 1.2391e+00,
         1.2650e+00, 1.3138e+00, 1.2504e+00, 1.2802e+00, 1.2006e+00, 1.2416e+00,
         1.3940e+00, 1.4426e+00, 1.4269e+00, 1.4042e+00, 1.4158e+00, 1.3662e+00,
         1.4087e+00, 1.2815e+00, 1.3405e+00, 1.3268e+00, 1.2821e+00, 1.2689e+00,
         1.2543e+00, 1.3250e+00, 1.2759e+00, 1.3600e+00, 1.2419e+00, 1.2579e+00],
        [1.2450e+00, 1.2719e+00, 1.2950e+00, 1.2772e+00, 1.2804e+00, 1.2511e+00,
         1.2584e+00, 1.2438e+00, 1.2438e+00, 2.4015e+00, 2.3982e+00, 2.3184e+00,
         2.5285e+00, 2.3128e+00, 4.4454e+00, 2.3837e+00, 2.4462e+00, 4.2215e+00,
         1.2539e+00, 1.2799e+00, 1.2500e+00, 1.2658e+00, 1.2711e+00, 1.2664e+00,
         1.2843e+00, 1.2589e+00, 1.2589e+00, 1.3080e+00, 1.2589e+00, 1.2763e+00,
         1.3033e+00, 1.2746e+00, 1.2880e+00, 1.3188e+00, 1.2401e+00, 1.2790e+00,
         1.4237e+00, 1.4743e+00, 1.4042e+00, 1.4329e+00, 1.4464e+00, 1.4528e+00,
         1.3854e+00, 1.2647e+00, 1.3662e+00, 1.3142e+00, 1.3195e+00, 1.3058e+00,
         1.2907e+00, 1.2675e+00, 1.3131e+00, 1.3048e+00, 1.2780e+00, 1.2945e+00],
        [1.2118e+00, 1.2392e+00, 1.2806e+00, 1.2737e+00, 1.2444e+00, 1.2164e+00,
         1.2248e+00, 1.2094e+00, 1.2094e+00, 1.2777e+00, 1.3025e+00, 1.2923e+00,
         1.3320e+00, 1.2716e+00, 1.3266e+00, 1.2827e+00, 1.2096e+00, 1.3296e+00,
         2.7745e+00, 2.9933e+00, 2.9867e+00, 2.7911e+00, 2.7410e+00, 2.7386e+00,
         2.9524e+00, 2.7304e+00, 2.7304e+00, 1.2576e+00, 1.3145e+00, 1.2435e+00,
         1.2664e+00, 1.2581e+00, 1.2548e+00, 1.2848e+00, 1.2509e+00, 1.2460e+00,
         1.3979e+00, 1.4467e+00, 1.4271e+00, 1.3367e+00, 1.4161e+00, 1.4039e+00,
         1.4126e+00, 1.2850e+00, 1.2697e+00, 1.3270e+00, 1.2853e+00, 1.2721e+00,
         1.2575e+00, 1.3256e+00, 1.2791e+00, 1.3610e+00, 1.2263e+00, 1.2610e+00],
        [1.2213e+00, 1.2488e+00, 1.2899e+00, 1.2836e+00, 1.2542e+00, 1.2260e+00,
         1.2346e+00, 1.2189e+00, 1.2189e+00, 1.2868e+00, 1.3118e+00, 1.3016e+00,
         1.3387e+00, 1.2808e+00, 1.3144e+00, 1.2920e+00, 1.2668e+00, 1.2720e+00,
         1.2744e+00, 1.2794e+00, 1.3144e+00, 1.2880e+00, 1.2464e+00, 1.2417e+00,
         1.2457e+00, 1.2344e+00, 1.2344e+00, 3.0449e+00, 3.0044e+00, 2.6457e+00,
         2.7823e+00, 3.0429e+00, 2.6556e+00, 2.9711e+00, 2.6586e+00, 2.6479e+00,
         1.4060e+00, 1.4549e+00, 1.4357e+00, 1.3971e+00, 1.4279e+00, 1.4151e+00,
         1.4175e+00, 1.2679e+00, 1.3330e+00, 1.3404e+00, 1.2955e+00, 1.2148e+00,
         1.2201e+00, 1.3386e+00, 1.2893e+00, 1.3738e+00, 1.1921e+00, 1.2711e+00],
        [1.8522e+00, 1.4362e+00, 6.1129e-01, 9.1587e-01, 1.3269e+00, 1.7774e+00,
         1.6439e+00, 1.8898e+00, 1.8898e+00, 1.6974e+00, 1.3149e+00, 1.5205e+00,
         9.1602e-01, 1.7398e+00, 1.3755e-01, 1.6319e+00, 1.9261e+00, 8.3690e-01,
         1.3386e+00, 1.0052e+00, 7.5509e-01, 1.1469e+00, 1.7180e+00, 1.7882e+00,
         1.5509e+00, 1.9018e+00, 1.9018e+00, 8.5793e-01, 8.4450e-01, 1.8744e+00,
         1.6501e+00, 8.7284e-01, 1.8065e+00, 1.2493e+00, 1.9267e+00, 1.8361e+00,
         2.5776e-01, 4.0172e-02, 1.4833e-02, 2.1228e-01, 4.2589e-01, 4.9643e-01,
         1.5138e-01, 1.8241e+01, 2.8932e+00, 7.8494e-01, 1.4177e+00, 1.5081e+00,
         1.7596e+00, 1.0021e+00, 1.6723e+00, 3.6534e-01, 1.8924e+00, 1.9300e+00],
        [1.2981e+00, 1.3261e+00, 1.3832e+00, 1.3620e+00, 1.3321e+00, 1.3029e+00,
         1.2664e+00, 1.2956e+00, 1.2956e+00, 1.2683e+00, 1.3876e+00, 1.2831e+00,
         1.4178e+00, 1.3561e+00, 1.4613e+00, 1.2734e+00, 1.3424e+00, 1.3238e+00,
         1.3509e+00, 1.3366e+00, 1.3929e+00, 1.3649e+00, 1.3223e+00, 1.3175e+00,
         1.2098e+00, 1.3101e+00, 1.3101e+00, 1.3567e+00, 1.4024e+00, 1.3282e+00,
         1.0980e+00, 1.3107e+00, 1.2029e+00, 1.3696e+00, 1.1999e+00, 1.3308e+00,
         1.4748e+00, 1.1685e+00, 1.4608e+00, 1.4847e+00, 1.0180e+00, 9.4171e-01,
         1.4898e+00, 1.3584e+00, 8.2412e-01, 3.5661e+00, 2.6364e+00, 3.7051e+00,
         2.9352e+00, 2.2284e+00, 1.9299e+00, 3.0359e+00, 3.4999e+00, 1.9148e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 344 : 180.44723736408724
Test loss for epoch 344 : 180.83576762004913
Test Precision for epoch 344 : 0.26153846153846155
Test Recall for epoch 344 : 0.26153846153846155
Test F1 for epoch 344 : 0.26153846153846155


theta for epoch 345 : tensor([[2.7451e+00, 2.7714e+00, 2.8378e+00, 2.9786e+00, 2.9461e+00, 2.7494e+00,
         2.9266e+00, 2.7430e+00, 2.7430e+00, 1.2749e+00, 1.2997e+00, 1.2895e+00,
         1.3290e+00, 1.2688e+00, 1.3726e+00, 1.2799e+00, 1.2555e+00, 1.2828e+00,
         1.2573e+00, 1.2358e+00, 1.2522e+00, 1.2708e+00, 1.2293e+00, 1.2247e+00,
         1.2448e+00, 1.2174e+00, 1.2174e+00, 1.2679e+00, 1.3131e+00, 1.2398e+00,
         1.2657e+00, 1.3144e+00, 1.2510e+00, 1.2810e+00, 1.2012e+00, 1.2423e+00,
         1.3941e+00, 1.4428e+00, 1.4270e+00, 1.4044e+00, 1.4160e+00, 1.3664e+00,
         1.4088e+00, 1.2813e+00, 1.3411e+00, 1.3287e+00, 1.2841e+00, 1.2709e+00,
         1.2563e+00, 1.3269e+00, 1.2779e+00, 1.3620e+00, 1.2438e+00, 1.2598e+00],
        [1.2432e+00, 1.2703e+00, 1.2945e+00, 1.2765e+00, 1.2787e+00, 1.2493e+00,
         1.2567e+00, 1.2421e+00, 1.2421e+00, 2.4093e+00, 2.4071e+00, 2.3269e+00,
         2.5383e+00, 2.3200e+00, 4.4211e+00, 2.3921e+00, 2.4590e+00, 4.1975e+00,
         1.2491e+00, 1.2751e+00, 1.2455e+00, 1.2611e+00, 1.2661e+00, 1.2613e+00,
         1.2794e+00, 1.2539e+00, 1.2539e+00, 1.3073e+00, 1.2581e+00, 1.2756e+00,
         1.3025e+00, 1.2748e+00, 1.2872e+00, 1.3181e+00, 1.2394e+00, 1.2782e+00,
         1.4227e+00, 1.4732e+00, 1.4033e+00, 1.4320e+00, 1.4454e+00, 1.4519e+00,
         1.3844e+00, 1.2655e+00, 1.3657e+00, 1.3149e+00, 1.3202e+00, 1.3065e+00,
         1.2914e+00, 1.2683e+00, 1.3138e+00, 1.3051e+00, 1.2786e+00, 1.2952e+00],
        [1.2136e+00, 1.2410e+00, 1.2820e+00, 1.2755e+00, 1.2462e+00, 1.2183e+00,
         1.2266e+00, 1.2112e+00, 1.2112e+00, 1.2809e+00, 1.3057e+00, 1.2955e+00,
         1.3352e+00, 1.2747e+00, 1.3295e+00, 1.2859e+00, 1.2127e+00, 1.3328e+00,
         2.7703e+00, 2.9907e+00, 2.9826e+00, 2.7867e+00, 2.7369e+00, 2.7342e+00,
         2.9497e+00, 2.7262e+00, 2.7262e+00, 1.2593e+00, 1.3164e+00, 1.2456e+00,
         1.2685e+00, 1.2598e+00, 1.2569e+00, 1.2868e+00, 1.2530e+00, 1.2481e+00,
         1.3993e+00, 1.4480e+00, 1.4285e+00, 1.3377e+00, 1.4174e+00, 1.4048e+00,
         1.4139e+00, 1.2859e+00, 1.2711e+00, 1.3311e+00, 1.2896e+00, 1.2764e+00,
         1.2617e+00, 1.3297e+00, 1.2833e+00, 1.3651e+00, 1.2302e+00, 1.2652e+00],
        [1.2206e+00, 1.2481e+00, 1.2888e+00, 1.2829e+00, 1.2535e+00, 1.2252e+00,
         1.2338e+00, 1.2182e+00, 1.2182e+00, 1.2873e+00, 1.3123e+00, 1.3020e+00,
         1.3389e+00, 1.2812e+00, 1.3156e+00, 1.2924e+00, 1.2671e+00, 1.2732e+00,
         1.2704e+00, 1.2750e+00, 1.3104e+00, 1.2840e+00, 1.2423e+00, 1.2376e+00,
         1.2413e+00, 1.2303e+00, 1.2303e+00, 3.0460e+00, 3.0044e+00, 2.6474e+00,
         2.7821e+00, 3.0441e+00, 2.6574e+00, 2.9710e+00, 2.6605e+00, 2.6496e+00,
         1.4056e+00, 1.4545e+00, 1.4352e+00, 1.3963e+00, 1.4275e+00, 1.4143e+00,
         1.4169e+00, 1.2681e+00, 1.3325e+00, 1.3417e+00, 1.2967e+00, 1.2169e+00,
         1.2214e+00, 1.3399e+00, 1.2905e+00, 1.3751e+00, 1.1929e+00, 1.2724e+00],
        [1.8530e+00, 1.4370e+00, 6.1236e-01, 9.1654e-01, 1.3279e+00, 1.7782e+00,
         1.6448e+00, 1.8905e+00, 1.8905e+00, 1.6984e+00, 1.3162e+00, 1.5222e+00,
         9.1806e-01, 1.7415e+00, 1.3919e-01, 1.6329e+00, 1.9276e+00, 8.3817e-01,
         1.3370e+00, 1.0045e+00, 7.5410e-01, 1.1455e+00, 1.7162e+00, 1.7864e+00,
         1.5499e+00, 1.9000e+00, 1.9000e+00, 8.5981e-01, 8.4590e-01, 1.8758e+00,
         1.6512e+00, 8.7417e-01, 1.8079e+00, 1.2507e+00, 1.9280e+00, 1.8375e+00,
         2.5591e-01, 3.8506e-02, 1.3091e-02, 2.1017e-01, 4.2378e-01, 4.9392e-01,
         1.4962e-01, 1.8308e+01, 2.8393e+00, 7.8804e-01, 1.4207e+00, 1.5105e+00,
         1.7624e+00, 1.0052e+00, 1.6752e+00, 3.6854e-01, 1.8960e+00, 1.9327e+00],
        [1.2963e+00, 1.3243e+00, 1.3813e+00, 1.3602e+00, 1.3303e+00, 1.3010e+00,
         1.2645e+00, 1.2938e+00, 1.2938e+00, 1.2678e+00, 1.3871e+00, 1.2825e+00,
         1.4173e+00, 1.3555e+00, 1.4609e+00, 1.2728e+00, 1.3419e+00, 1.3234e+00,
         1.3458e+00, 1.3311e+00, 1.3877e+00, 1.3597e+00, 1.3171e+00, 1.3124e+00,
         1.2043e+00, 1.3049e+00, 1.3049e+00, 1.3556e+00, 1.4014e+00, 1.3272e+00,
         1.0965e+00, 1.3096e+00, 1.2018e+00, 1.3685e+00, 1.1987e+00, 1.3298e+00,
         1.4736e+00, 1.1671e+00, 1.4593e+00, 1.4837e+00, 1.0161e+00, 9.3989e-01,
         1.4887e+00, 1.3568e+00, 8.2265e-01, 3.5718e+00, 2.6393e+00, 3.7081e+00,
         2.9378e+00, 2.2316e+00, 1.9332e+00, 3.0386e+00, 3.5057e+00, 1.9181e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 345 : 180.43326106116604
Test loss for epoch 345 : 180.82562465916365
Test Precision for epoch 345 : 0.26153846153846155
Test Recall for epoch 345 : 0.26153846153846155
Test F1 for epoch 345 : 0.26153846153846155


theta for epoch 346 : tensor([[2.7461e+00, 2.7723e+00, 2.8388e+00, 2.9796e+00, 2.9471e+00, 2.7504e+00,
         2.9276e+00, 2.7440e+00, 2.7440e+00, 1.2734e+00, 1.2982e+00, 1.2879e+00,
         1.3275e+00, 1.2672e+00, 1.3711e+00, 1.2784e+00, 1.2539e+00, 1.2814e+00,
         1.2606e+00, 1.2390e+00, 1.2554e+00, 1.2741e+00, 1.2327e+00, 1.2280e+00,
         1.2481e+00, 1.2208e+00, 1.2208e+00, 1.2672e+00, 1.3124e+00, 1.2390e+00,
         1.2650e+00, 1.3137e+00, 1.2503e+00, 1.2802e+00, 1.2005e+00, 1.2415e+00,
         1.3942e+00, 1.4429e+00, 1.4271e+00, 1.4047e+00, 1.4162e+00, 1.3667e+00,
         1.4089e+00, 1.2811e+00, 1.3418e+00, 1.3259e+00, 1.2812e+00, 1.2681e+00,
         1.2535e+00, 1.3241e+00, 1.2750e+00, 1.3592e+00, 1.2409e+00, 1.2570e+00],
        [1.2436e+00, 1.2708e+00, 1.2960e+00, 1.2780e+00, 1.2792e+00, 1.2498e+00,
         1.2571e+00, 1.2425e+00, 1.2425e+00, 2.4142e+00, 2.4131e+00, 2.3325e+00,
         2.5455e+00, 2.3245e+00, 4.3944e+00, 2.3976e+00, 2.4688e+00, 4.1710e+00,
         1.2530e+00, 1.2789e+00, 1.2491e+00, 1.2650e+00, 1.2699e+00, 1.2652e+00,
         1.2832e+00, 1.2577e+00, 1.2577e+00, 1.3071e+00, 1.2578e+00, 1.2752e+00,
         1.3022e+00, 1.2755e+00, 1.2869e+00, 1.3178e+00, 1.2392e+00, 1.2778e+00,
         1.4228e+00, 1.4734e+00, 1.4036e+00, 1.4322e+00, 1.4456e+00, 1.4523e+00,
         1.3847e+00, 1.2672e+00, 1.3664e+00, 1.3125e+00, 1.3176e+00, 1.3039e+00,
         1.2889e+00, 1.2660e+00, 1.3112e+00, 1.3028e+00, 1.2760e+00, 1.2926e+00],
        [1.2116e+00, 1.2390e+00, 1.2797e+00, 1.2735e+00, 1.2442e+00, 1.2163e+00,
         1.2246e+00, 1.2092e+00, 1.2092e+00, 1.2773e+00, 1.3021e+00, 1.2918e+00,
         1.3315e+00, 1.2710e+00, 1.3261e+00, 1.2822e+00, 1.2088e+00, 1.3293e+00,
         2.7750e+00, 2.9968e+00, 2.9872e+00, 2.7911e+00, 2.7416e+00, 2.7388e+00,
         2.9558e+00, 2.7309e+00, 2.7309e+00, 1.2565e+00, 1.3141e+00, 1.2433e+00,
         1.2662e+00, 1.2571e+00, 1.2546e+00, 1.2846e+00, 1.2507e+00, 1.2458e+00,
         1.3981e+00, 1.4469e+00, 1.4273e+00, 1.3360e+00, 1.4164e+00, 1.4034e+00,
         1.4128e+00, 1.2843e+00, 1.2699e+00, 1.3261e+00, 1.2846e+00, 1.2714e+00,
         1.2567e+00, 1.3247e+00, 1.2784e+00, 1.3601e+00, 1.2247e+00, 1.2603e+00],
        [1.2211e+00, 1.2486e+00, 1.2889e+00, 1.2833e+00, 1.2540e+00, 1.2257e+00,
         1.2343e+00, 1.2187e+00, 1.2187e+00, 1.2865e+00, 1.3114e+00, 1.3011e+00,
         1.3379e+00, 1.2804e+00, 1.3156e+00, 1.2915e+00, 1.2662e+00, 1.2733e+00,
         1.2742e+00, 1.2782e+00, 1.3143e+00, 1.2878e+00, 1.2462e+00, 1.2415e+00,
         1.2447e+00, 1.2342e+00, 1.2342e+00, 3.0459e+00, 3.0030e+00, 2.6478e+00,
         2.7807e+00, 3.0439e+00, 2.6578e+00, 2.9695e+00, 2.6611e+00, 2.6500e+00,
         1.4060e+00, 1.4549e+00, 1.4355e+00, 1.3963e+00, 1.4280e+00, 1.4144e+00,
         1.4171e+00, 1.2692e+00, 1.3329e+00, 1.3396e+00, 1.2947e+00, 1.2158e+00,
         1.2193e+00, 1.3378e+00, 1.2885e+00, 1.3731e+00, 1.1904e+00, 1.2703e+00],
        [1.8537e+00, 1.4375e+00, 6.1252e-01, 9.1651e-01, 1.3285e+00, 1.7788e+00,
         1.6454e+00, 1.8911e+00, 1.8911e+00, 1.6971e+00, 1.3150e+00, 1.5217e+00,
         9.1743e-01, 1.7410e+00, 1.3817e-01, 1.6317e+00, 1.9270e+00, 8.3659e-01,
         1.3400e+00, 1.0078e+00, 7.5696e-01, 1.1484e+00, 1.7194e+00, 1.7896e+00,
         1.5536e+00, 1.9032e+00, 1.9032e+00, 8.5963e-01, 8.4525e-01, 1.8757e+00,
         1.6508e+00, 8.7342e-01, 1.8079e+00, 1.2501e+00, 1.9279e+00, 1.8374e+00,
         2.5499e-01, 3.7727e-02, 1.2224e-02, 2.0897e-01, 4.2266e-01, 4.9243e-01,
         1.4876e-01, 1.8376e+01, 2.7873e+00, 7.8616e-01, 1.4187e+00, 1.5080e+00,
         1.7604e+00, 1.0030e+00, 1.6732e+00, 3.6682e-01, 1.8949e+00, 1.9307e+00],
        [1.2982e+00, 1.3262e+00, 1.3832e+00, 1.3621e+00, 1.3322e+00, 1.3029e+00,
         1.2665e+00, 1.2957e+00, 1.2957e+00, 1.2685e+00, 1.3876e+00, 1.2831e+00,
         1.4178e+00, 1.3560e+00, 1.4615e+00, 1.2735e+00, 1.3424e+00, 1.3242e+00,
         1.3516e+00, 1.3367e+00, 1.3935e+00, 1.3655e+00, 1.3229e+00, 1.3181e+00,
         1.2100e+00, 1.3107e+00, 1.3107e+00, 1.3569e+00, 1.4026e+00, 1.3284e+00,
         1.0979e+00, 1.3110e+00, 1.2032e+00, 1.3698e+00, 1.2001e+00, 1.3310e+00,
         1.4750e+00, 1.1688e+00, 1.4604e+00, 1.4852e+00, 1.0178e+00, 9.4175e-01,
         1.4901e+00, 1.3579e+00, 8.2487e-01, 3.5704e+00, 2.6350e+00, 3.7038e+00,
         2.9334e+00, 2.2277e+00, 1.9294e+00, 3.0342e+00, 3.5044e+00, 1.9142e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 346 : 180.41827722840105
Test loss for epoch 346 : 180.8199930233196
Test Precision for epoch 346 : 0.26153846153846155
Test Recall for epoch 346 : 0.26153846153846155
Test F1 for epoch 346 : 0.26153846153846155


theta for epoch 347 : tensor([[2.7463e+00, 2.7726e+00, 2.8390e+00, 2.9799e+00, 2.9474e+00, 2.7506e+00,
         2.9279e+00, 2.7442e+00, 2.7442e+00, 1.2744e+00, 1.2991e+00, 1.2887e+00,
         1.3283e+00, 1.2680e+00, 1.3721e+00, 1.2792e+00, 1.2548e+00, 1.2824e+00,
         1.2574e+00, 1.2358e+00, 1.2523e+00, 1.2709e+00, 1.2294e+00, 1.2248e+00,
         1.2449e+00, 1.2175e+00, 1.2175e+00, 1.2675e+00, 1.3127e+00, 1.2393e+00,
         1.2654e+00, 1.3141e+00, 1.2506e+00, 1.2806e+00, 1.2008e+00, 1.2419e+00,
         1.3941e+00, 1.4427e+00, 1.4270e+00, 1.4046e+00, 1.4161e+00, 1.3667e+00,
         1.4087e+00, 1.2808e+00, 1.3422e+00, 1.3282e+00, 1.2836e+00, 1.2704e+00,
         1.2559e+00, 1.3265e+00, 1.2774e+00, 1.3615e+00, 1.2433e+00, 1.2594e+00],
        [1.2419e+00, 1.2692e+00, 1.2956e+00, 1.2775e+00, 1.2775e+00, 1.2481e+00,
         1.2554e+00, 1.2408e+00, 1.2408e+00, 2.4215e+00, 2.4216e+00, 2.3408e+00,
         2.5552e+00, 2.3316e+00, 4.3704e+00, 2.4057e+00, 2.4812e+00, 4.1472e+00,
         1.2485e+00, 1.2744e+00, 1.2449e+00, 1.2604e+00, 1.2651e+00, 1.2604e+00,
         1.2784e+00, 1.2529e+00, 1.2529e+00, 1.3063e+00, 1.2569e+00, 1.2744e+00,
         1.3014e+00, 1.2757e+00, 1.2861e+00, 1.3170e+00, 1.2385e+00, 1.2770e+00,
         1.4217e+00, 1.4723e+00, 1.4026e+00, 1.4312e+00, 1.4445e+00, 1.4513e+00,
         1.3837e+00, 1.2674e+00, 1.3659e+00, 1.3138e+00, 1.3189e+00, 1.3052e+00,
         1.2902e+00, 1.2674e+00, 1.3125e+00, 1.3037e+00, 1.2773e+00, 1.2939e+00],
        [1.2134e+00, 1.2408e+00, 1.2812e+00, 1.2753e+00, 1.2460e+00, 1.2181e+00,
         1.2264e+00, 1.2110e+00, 1.2110e+00, 1.2804e+00, 1.3051e+00, 1.2947e+00,
         1.3345e+00, 1.2740e+00, 1.3288e+00, 1.2853e+00, 1.2117e+00, 1.3323e+00,
         2.7708e+00, 2.9942e+00, 2.9832e+00, 2.7868e+00, 2.7374e+00, 2.7345e+00,
         2.9531e+00, 2.7268e+00, 2.7268e+00, 1.2581e+00, 1.3160e+00, 1.2452e+00,
         1.2682e+00, 1.2587e+00, 1.2565e+00, 1.2866e+00, 1.2526e+00, 1.2477e+00,
         1.3993e+00, 1.4481e+00, 1.4285e+00, 1.3369e+00, 1.4176e+00, 1.4042e+00,
         1.4139e+00, 1.2852e+00, 1.2711e+00, 1.3309e+00, 1.2894e+00, 1.2763e+00,
         1.2616e+00, 1.3294e+00, 1.2832e+00, 1.3647e+00, 1.2293e+00, 1.2652e+00],
        [1.2204e+00, 1.2479e+00, 1.2879e+00, 1.2827e+00, 1.2533e+00, 1.2250e+00,
         1.2336e+00, 1.2180e+00, 1.2180e+00, 1.2869e+00, 1.3118e+00, 1.3014e+00,
         1.3380e+00, 1.2806e+00, 1.3166e+00, 1.2919e+00, 1.2665e+00, 1.2744e+00,
         1.2705e+00, 1.2741e+00, 1.3106e+00, 1.2841e+00, 1.2424e+00, 1.2377e+00,
         1.2405e+00, 1.2304e+00, 1.2304e+00, 3.0469e+00, 3.0028e+00, 2.6494e+00,
         2.7804e+00, 3.0450e+00, 2.6594e+00, 2.9692e+00, 2.6629e+00, 2.6516e+00,
         1.4054e+00, 1.4544e+00, 1.4348e+00, 1.3954e+00, 1.4275e+00, 1.4135e+00,
         1.4164e+00, 1.2694e+00, 1.3324e+00, 1.3413e+00, 1.2964e+00, 1.2183e+00,
         1.2211e+00, 1.3396e+00, 1.2902e+00, 1.3748e+00, 1.1918e+00, 1.2721e+00],
        [1.8546e+00, 1.4384e+00, 6.1372e-01, 9.1728e-01, 1.3296e+00, 1.7797e+00,
         1.6463e+00, 1.8919e+00, 1.8919e+00, 1.6980e+00, 1.3162e+00, 1.5235e+00,
         9.1949e-01, 1.7428e+00, 1.3993e-01, 1.6327e+00, 1.9285e+00, 8.3789e-01,
         1.3387e+00, 1.0073e+00, 7.5628e-01, 1.1473e+00, 1.7179e+00, 1.7881e+00,
         1.5528e+00, 1.9016e+00, 1.9016e+00, 8.6152e-01, 8.4671e-01, 1.8771e+00,
         1.6519e+00, 8.7476e-01, 1.8092e+00, 1.2515e+00, 1.9292e+00, 1.8388e+00,
         2.5290e-01, 3.5820e-02, 1.0262e-02, 2.0663e-01, 4.2032e-01, 4.8972e-01,
         1.4677e-01, 1.8443e+01, 2.7349e+00, 7.8988e-01, 1.4223e+00, 1.5110e+00,
         1.7638e+00, 1.0067e+00, 1.6767e+00, 3.7064e-01, 1.8991e+00, 1.9340e+00],
        [1.2959e+00, 1.3240e+00, 1.3810e+00, 1.3599e+00, 1.3299e+00, 1.3007e+00,
         1.2642e+00, 1.2935e+00, 1.2935e+00, 1.2672e+00, 1.3865e+00, 1.2818e+00,
         1.4166e+00, 1.3549e+00, 1.4604e+00, 1.2722e+00, 1.3411e+00, 1.3231e+00,
         1.3462e+00, 1.3310e+00, 1.3881e+00, 1.3601e+00, 1.3176e+00, 1.3128e+00,
         1.2042e+00, 1.3053e+00, 1.3053e+00, 1.3552e+00, 1.4011e+00, 1.3268e+00,
         1.0958e+00, 1.3093e+00, 1.2014e+00, 1.3682e+00, 1.1983e+00, 1.3294e+00,
         1.4734e+00, 1.1668e+00, 1.4585e+00, 1.4838e+00, 1.0155e+00, 9.3941e-01,
         1.4885e+00, 1.3560e+00, 8.2293e-01, 3.5770e+00, 2.6389e+00, 3.7077e+00,
         2.9370e+00, 2.2318e+00, 1.9336e+00, 3.0378e+00, 3.5111e+00, 1.9185e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 347 : 180.40270328103566
Test loss for epoch 347 : 180.8075059349765
Test Precision for epoch 347 : 0.26153846153846155
Test Recall for epoch 347 : 0.26153846153846155
Test F1 for epoch 347 : 0.26153846153846155


theta for epoch 348 : tensor([[2.7467e+00, 2.7730e+00, 2.8395e+00, 2.9804e+00, 2.9478e+00, 2.7510e+00,
         2.9284e+00, 2.7446e+00, 2.7446e+00, 1.2738e+00, 1.2984e+00, 1.2880e+00,
         1.3277e+00, 1.2674e+00, 1.3715e+00, 1.2786e+00, 1.2541e+00, 1.2820e+00,
         1.2600e+00, 1.2384e+00, 1.2549e+00, 1.2735e+00, 1.2321e+00, 1.2275e+00,
         1.2475e+00, 1.2202e+00, 1.2202e+00, 1.2674e+00, 1.3126e+00, 1.2392e+00,
         1.2653e+00, 1.3140e+00, 1.2504e+00, 1.2805e+00, 1.2006e+00, 1.2417e+00,
         1.3944e+00, 1.4431e+00, 1.4273e+00, 1.4051e+00, 1.4164e+00, 1.3671e+00,
         1.4090e+00, 1.2809e+00, 1.3431e+00, 1.3260e+00, 1.2813e+00, 1.2682e+00,
         1.2536e+00, 1.3242e+00, 1.2751e+00, 1.3593e+00, 1.2410e+00, 1.2571e+00],
        [1.2415e+00, 1.2689e+00, 1.2964e+00, 1.2783e+00, 1.2770e+00, 1.2477e+00,
         1.2550e+00, 1.2404e+00, 1.2404e+00, 2.4270e+00, 2.4282e+00, 2.3472e+00,
         2.5633e+00, 2.3370e+00, 4.3449e+00, 2.4119e+00, 2.4916e+00, 4.1220e+00,
         1.2510e+00, 1.2769e+00, 1.2472e+00, 1.2629e+00, 1.2676e+00, 1.2629e+00,
         1.2808e+00, 1.2554e+00, 1.2554e+00, 1.3060e+00, 1.2564e+00, 1.2740e+00,
         1.3010e+00, 1.2764e+00, 1.2857e+00, 1.3167e+00, 1.2382e+00, 1.2766e+00,
         1.4217e+00, 1.4722e+00, 1.4027e+00, 1.4312e+00, 1.4445e+00, 1.4514e+00,
         1.3838e+00, 1.2684e+00, 1.3665e+00, 1.3114e+00, 1.3163e+00, 1.3026e+00,
         1.2876e+00, 1.2650e+00, 1.3099e+00, 1.3015e+00, 1.2747e+00, 1.2913e+00],
        [1.2115e+00, 1.2390e+00, 1.2790e+00, 1.2735e+00, 1.2441e+00, 1.2162e+00,
         1.2245e+00, 1.2092e+00, 1.2092e+00, 1.2779e+00, 1.3027e+00, 1.2922e+00,
         1.3320e+00, 1.2715e+00, 1.3265e+00, 1.2828e+00, 1.2090e+00, 1.3300e+00,
         2.7745e+00, 2.9993e+00, 2.9868e+00, 2.7903e+00, 2.7411e+00, 2.7380e+00,
         2.9582e+00, 2.7304e+00, 2.7304e+00, 1.2561e+00, 1.3144e+00, 1.2436e+00,
         1.2667e+00, 1.2567e+00, 1.2549e+00, 1.2850e+00, 1.2510e+00, 1.2461e+00,
         1.3984e+00, 1.4473e+00, 1.4277e+00, 1.3356e+00, 1.4168e+00, 1.4030e+00,
         1.4131e+00, 1.2841e+00, 1.2703e+00, 1.3269e+00, 1.2854e+00, 1.2722e+00,
         1.2576e+00, 1.3253e+00, 1.2792e+00, 1.3607e+00, 1.2248e+00, 1.2611e+00],
        [1.2202e+00, 1.2477e+00, 1.2874e+00, 1.2825e+00, 1.2531e+00, 1.2249e+00,
         1.2334e+00, 1.2178e+00, 1.2178e+00, 1.2864e+00, 1.3112e+00, 1.3008e+00,
         1.3373e+00, 1.2800e+00, 1.3168e+00, 1.2913e+00, 1.2659e+00, 1.2746e+00,
         1.2731e+00, 1.2761e+00, 1.3131e+00, 1.2867e+00, 1.2450e+00, 1.2403e+00,
         1.2428e+00, 1.2330e+00, 1.2330e+00, 3.0473e+00, 3.0019e+00, 2.6504e+00,
         2.7794e+00, 3.0454e+00, 2.6604e+00, 2.9682e+00, 2.6641e+00, 2.6526e+00,
         1.4056e+00, 1.4546e+00, 1.4349e+00, 1.3953e+00, 1.4277e+00, 1.4134e+00,
         1.4164e+00, 1.2703e+00, 1.3327e+00, 1.3393e+00, 1.2944e+00, 1.2172e+00,
         1.2191e+00, 1.3376e+00, 1.2882e+00, 1.3729e+00, 1.1894e+00, 1.2700e+00],
        [1.8549e+00, 1.4385e+00, 6.1359e-01, 9.1695e-01, 1.3299e+00, 1.7801e+00,
         1.6466e+00, 1.8923e+00, 1.8923e+00, 1.6973e+00, 1.3155e+00, 1.5235e+00,
         9.1935e-01, 1.7428e+00, 1.3932e-01, 1.6319e+00, 1.9284e+00, 8.3683e-01,
         1.3410e+00, 1.0100e+00, 7.5854e-01, 1.1496e+00, 1.7204e+00, 1.7906e+00,
         1.5559e+00, 1.9041e+00, 1.9041e+00, 8.6164e-01, 8.4639e-01, 1.8774e+00,
         1.6519e+00, 8.7430e-01, 1.8095e+00, 1.2512e+00, 1.9295e+00, 1.8391e+00,
         2.5189e-01, 3.4950e-02, 9.3203e-03, 2.0536e-01, 4.1913e-01, 4.8819e-01,
         1.4582e-01, 1.8510e+01, 2.6845e+00, 7.8830e-01, 1.4207e+00, 1.5089e+00,
         1.7622e+00, 1.0048e+00, 1.6750e+00, 3.6923e-01, 1.8983e+00, 1.9324e+00],
        [1.2973e+00, 1.3254e+00, 1.3824e+00, 1.3613e+00, 1.3313e+00, 1.3021e+00,
         1.2657e+00, 1.2949e+00, 1.2949e+00, 1.2685e+00, 1.3876e+00, 1.2830e+00,
         1.4177e+00, 1.3559e+00, 1.4615e+00, 1.2734e+00, 1.3422e+00, 1.3245e+00,
         1.3509e+00, 1.3355e+00, 1.3928e+00, 1.3648e+00, 1.3223e+00, 1.3175e+00,
         1.2088e+00, 1.3101e+00, 1.3101e+00, 1.3567e+00, 1.4025e+00, 1.3283e+00,
         1.0975e+00, 1.3108e+00, 1.2030e+00, 1.3697e+00, 1.1999e+00, 1.3309e+00,
         1.4747e+00, 1.1684e+00, 1.4596e+00, 1.4852e+00, 1.0171e+00, 9.4117e-01,
         1.4898e+00, 1.3570e+00, 8.2510e-01, 3.5761e+00, 2.6351e+00, 3.7039e+00,
         2.9331e+00, 2.2283e+00, 1.9302e+00, 3.0339e+00, 3.5102e+00, 1.9151e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 348 : 180.38690496871965
Test loss for epoch 348 : 180.8006487364984
Test Precision for epoch 348 : 0.26153846153846155
Test Recall for epoch 348 : 0.26153846153846155
Test F1 for epoch 348 : 0.26153846153846155


theta for epoch 349 : tensor([[2.7480e+00, 2.7743e+00, 2.8408e+00, 2.9817e+00, 2.9491e+00, 2.7523e+00,
         2.9297e+00, 2.7459e+00, 2.7459e+00, 1.2733e+00, 1.2980e+00, 1.2875e+00,
         1.3272e+00, 1.2669e+00, 1.3712e+00, 1.2782e+00, 1.2536e+00, 1.2817e+00,
         1.2578e+00, 1.2362e+00, 1.2526e+00, 1.2713e+00, 1.2298e+00, 1.2252e+00,
         1.2452e+00, 1.2179e+00, 1.2179e+00, 1.2667e+00, 1.3121e+00, 1.2385e+00,
         1.2647e+00, 1.3134e+00, 1.2498e+00, 1.2799e+00, 1.2000e+00, 1.2411e+00,
         1.3940e+00, 1.4427e+00, 1.4270e+00, 1.4048e+00, 1.4161e+00, 1.3668e+00,
         1.4086e+00, 1.2803e+00, 1.3433e+00, 1.3271e+00, 1.2825e+00, 1.2693e+00,
         1.2548e+00, 1.3253e+00, 1.2763e+00, 1.3605e+00, 1.2421e+00, 1.2583e+00],
        [1.2412e+00, 1.2687e+00, 1.2973e+00, 1.2791e+00, 1.2766e+00, 1.2472e+00,
         1.2546e+00, 1.2400e+00, 1.2400e+00, 2.4331e+00, 2.4355e+00, 2.3544e+00,
         2.5723e+00, 2.3432e+00, 4.3204e+00, 2.4188e+00, 2.5027e+00, 4.0979e+00,
         1.2485e+00, 1.2744e+00, 1.2449e+00, 1.2602e+00, 1.2648e+00, 1.2601e+00,
         1.2780e+00, 1.2526e+00, 1.2526e+00, 1.3053e+00, 1.2555e+00, 1.2732e+00,
         1.3002e+00, 1.2768e+00, 1.2848e+00, 1.3159e+00, 1.2375e+00, 1.2758e+00,
         1.4210e+00, 1.4716e+00, 1.4023e+00, 1.4306e+00, 1.4439e+00, 1.4509e+00,
         1.3833e+00, 1.2687e+00, 1.3665e+00, 1.3122e+00, 1.3172e+00, 1.3035e+00,
         1.2885e+00, 1.2660e+00, 1.3108e+00, 1.3023e+00, 1.2756e+00, 1.2922e+00],
        [1.2130e+00, 1.2405e+00, 1.2801e+00, 1.2749e+00, 1.2456e+00, 1.2177e+00,
         1.2260e+00, 1.2106e+00, 1.2106e+00, 1.2790e+00, 1.3038e+00, 1.2932e+00,
         1.3330e+00, 1.2725e+00, 1.3275e+00, 1.2839e+00, 1.2099e+00, 1.3311e+00,
         2.7725e+00, 2.9988e+00, 2.9849e+00, 2.7881e+00, 2.7391e+00, 2.7358e+00,
         2.9577e+00, 2.7284e+00, 2.7284e+00, 1.2564e+00, 1.3150e+00, 1.2442e+00,
         1.2673e+00, 1.2570e+00, 1.2556e+00, 1.2857e+00, 1.2516e+00, 1.2468e+00,
         1.3990e+00, 1.4478e+00, 1.4283e+00, 1.3359e+00, 1.4174e+00, 1.4033e+00,
         1.4136e+00, 1.2844e+00, 1.2710e+00, 1.3297e+00, 1.2883e+00, 1.2751e+00,
         1.2605e+00, 1.3280e+00, 1.2821e+00, 1.3634e+00, 1.2274e+00, 1.2641e+00],
        [1.2204e+00, 1.2479e+00, 1.2873e+00, 1.2827e+00, 1.2533e+00, 1.2251e+00,
         1.2336e+00, 1.2180e+00, 1.2180e+00, 1.2863e+00, 1.3111e+00, 1.3006e+00,
         1.3369e+00, 1.2798e+00, 1.3174e+00, 1.2912e+00, 1.2657e+00, 1.2753e+00,
         1.2711e+00, 1.2736e+00, 1.3111e+00, 1.2846e+00, 1.2429e+00, 1.2382e+00,
         1.2403e+00, 1.2309e+00, 1.2309e+00, 3.0479e+00, 3.0011e+00, 2.6516e+00,
         2.7786e+00, 3.0459e+00, 2.6616e+00, 2.9674e+00, 2.6655e+00, 2.6538e+00,
         1.4053e+00, 1.4544e+00, 1.4345e+00, 1.3947e+00, 1.4275e+00, 1.4128e+00,
         1.4160e+00, 1.2708e+00, 1.3326e+00, 1.3405e+00, 1.2957e+00, 1.2192e+00,
         1.2203e+00, 1.3388e+00, 1.2894e+00, 1.3741e+00, 1.1903e+00, 1.2713e+00],
        [1.8563e+00, 1.4399e+00, 6.1506e-01, 9.1806e-01, 1.3315e+00, 1.7815e+00,
         1.6480e+00, 1.8937e+00, 1.8937e+00, 1.6975e+00, 1.3160e+00, 1.5245e+00,
         9.2063e-01, 1.7438e+00, 1.4039e-01, 1.6320e+00, 1.9292e+00, 8.3733e-01,
         1.3406e+00, 1.0104e+00, 7.5870e-01, 1.1493e+00, 1.7199e+00, 1.7900e+00,
         1.5561e+00, 1.9035e+00, 1.9035e+00, 8.6290e-01, 8.4724e-01, 1.8782e+00,
         1.6524e+00, 8.7499e-01, 1.8104e+00, 1.2520e+00, 1.9303e+00, 1.8399e+00,
         2.4989e-01, 3.3133e-02, 7.4594e-03, 2.0313e-01, 4.1692e-01, 4.8563e-01,
         1.4391e-01, 1.8577e+01, 2.6342e+00, 7.9110e-01, 1.4234e+00, 1.5110e+00,
         1.7647e+00, 1.0075e+00, 1.6776e+00, 3.7216e-01, 1.9015e+00, 1.9348e+00],
        [1.2964e+00, 1.3245e+00, 1.3815e+00, 1.3604e+00, 1.3304e+00, 1.3012e+00,
         1.2647e+00, 1.2940e+00, 1.2940e+00, 1.2671e+00, 1.3863e+00, 1.2815e+00,
         1.4163e+00, 1.3545e+00, 1.4603e+00, 1.2720e+00, 1.3407e+00, 1.3232e+00,
         1.3477e+00, 1.3321e+00, 1.3895e+00, 1.3615e+00, 1.3191e+00, 1.3143e+00,
         1.2054e+00, 1.3069e+00, 1.3069e+00, 1.3552e+00, 1.4011e+00, 1.3267e+00,
         1.0957e+00, 1.3093e+00, 1.2014e+00, 1.3683e+00, 1.1983e+00, 1.3293e+00,
         1.4737e+00, 1.1671e+00, 1.4584e+00, 1.4843e+00, 1.0155e+00, 9.3964e-01,
         1.4887e+00, 1.3558e+00, 8.2400e-01, 3.5814e+00, 2.6377e+00, 3.7064e+00,
         2.9354e+00, 2.2312e+00, 1.9332e+00, 3.0362e+00, 3.5156e+00, 1.9181e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 349 : 180.37166022729502
Test loss for epoch 349 : 180.78973571351747
Test Precision for epoch 349 : 0.26153846153846155
Test Recall for epoch 349 : 0.26153846153846155
Test F1 for epoch 349 : 0.26153846153846155


theta for epoch 350 : tensor([[2.7473e+00, 2.7736e+00, 2.8401e+00, 2.9811e+00, 2.9485e+00, 2.7516e+00,
         2.9291e+00, 2.7452e+00, 2.7452e+00, 1.2742e+00, 1.2988e+00, 1.2883e+00,
         1.3280e+00, 1.2676e+00, 1.3721e+00, 1.2790e+00, 1.2543e+00, 1.2827e+00,
         1.2592e+00, 1.2375e+00, 1.2540e+00, 1.2727e+00, 1.2312e+00, 1.2266e+00,
         1.2465e+00, 1.2193e+00, 1.2193e+00, 1.2676e+00, 1.3130e+00, 1.2394e+00,
         1.2656e+00, 1.3143e+00, 1.2507e+00, 1.2808e+00, 1.2008e+00, 1.2419e+00,
         1.3946e+00, 1.4433e+00, 1.4276e+00, 1.4056e+00, 1.4167e+00, 1.3675e+00,
         1.4092e+00, 1.2808e+00, 1.3444e+00, 1.3266e+00, 1.2820e+00, 1.2689e+00,
         1.2543e+00, 1.3249e+00, 1.2758e+00, 1.3600e+00, 1.2416e+00, 1.2578e+00],
        [1.2393e+00, 1.2670e+00, 1.2968e+00, 1.2784e+00, 1.2747e+00, 1.2453e+00,
         1.2527e+00, 1.2381e+00, 1.2381e+00, 2.4395e+00, 2.4430e+00, 2.3619e+00,
         2.5816e+00, 2.3498e+00, 4.2965e+00, 2.4260e+00, 2.5141e+00, 4.0744e+00,
         1.2487e+00, 1.2745e+00, 1.2449e+00, 1.2602e+00, 1.2647e+00, 1.2600e+00,
         1.2778e+00, 1.2525e+00, 1.2525e+00, 1.3049e+00, 1.2549e+00, 1.2726e+00,
         1.2997e+00, 1.2774e+00, 1.2843e+00, 1.3154e+00, 1.2370e+00, 1.2752e+00,
         1.4205e+00, 1.4711e+00, 1.4019e+00, 1.4301e+00, 1.4434e+00, 1.4505e+00,
         1.3829e+00, 1.2690e+00, 1.3666e+00, 1.3105e+00, 1.3153e+00, 1.3016e+00,
         1.2866e+00, 1.2643e+00, 1.3089e+00, 1.3008e+00, 1.2737e+00, 1.2903e+00],
        [1.2114e+00, 1.2389e+00, 1.2782e+00, 1.2733e+00, 1.2440e+00, 1.2161e+00,
         1.2244e+00, 1.2090e+00, 1.2090e+00, 1.2785e+00, 1.3033e+00, 1.2927e+00,
         1.3326e+00, 1.2720e+00, 1.3270e+00, 1.2834e+00, 1.2092e+00, 1.3308e+00,
         2.7741e+00, 3.0018e+00, 2.9865e+00, 2.7896e+00, 2.7406e+00, 2.7372e+00,
         2.9607e+00, 2.7299e+00, 2.7299e+00, 1.2557e+00, 1.3146e+00, 1.2439e+00,
         1.2670e+00, 1.2564e+00, 1.2552e+00, 1.2854e+00, 1.2512e+00, 1.2464e+00,
         1.3987e+00, 1.4476e+00, 1.4280e+00, 1.3352e+00, 1.4171e+00, 1.4027e+00,
         1.4133e+00, 1.2839e+00, 1.2708e+00, 1.3281e+00, 1.2867e+00, 1.2735e+00,
         1.2590e+00, 1.3264e+00, 1.2805e+00, 1.3617e+00, 1.2255e+00, 1.2625e+00],
        [1.2192e+00, 1.2467e+00, 1.2858e+00, 1.2816e+00, 1.2521e+00, 1.2239e+00,
         1.2324e+00, 1.2168e+00, 1.2168e+00, 1.2861e+00, 1.3110e+00, 1.3004e+00,
         1.3366e+00, 1.2796e+00, 1.3180e+00, 1.2910e+00, 1.2655e+00, 1.2759e+00,
         1.2715e+00, 1.2736e+00, 1.3115e+00, 1.2851e+00, 1.2433e+00, 1.2387e+00,
         1.2404e+00, 1.2313e+00, 1.2313e+00, 3.0490e+00, 3.0009e+00, 2.6534e+00,
         2.7783e+00, 3.0471e+00, 2.6634e+00, 2.9671e+00, 2.6675e+00, 2.6556e+00,
         1.4052e+00, 1.4542e+00, 1.4342e+00, 1.3943e+00, 1.4274e+00, 1.4123e+00,
         1.4157e+00, 1.2714e+00, 1.3326e+00, 1.3393e+00, 1.2945e+00, 1.2188e+00,
         1.2191e+00, 1.3376e+00, 1.2883e+00, 1.3729e+00, 1.1887e+00, 1.2701e+00],
        [1.8561e+00, 1.4397e+00, 6.1486e-01, 9.1756e-01, 1.3314e+00, 1.7814e+00,
         1.6479e+00, 1.8936e+00, 1.8936e+00, 1.6976e+00, 1.3162e+00, 1.5253e+00,
         9.2153e-01, 1.7447e+00, 1.4084e-01, 1.6320e+00, 1.9300e+00, 8.3740e-01,
         1.3420e+00, 1.0121e+00, 7.6017e-01, 1.1506e+00, 1.7213e+00, 1.7914e+00,
         1.5580e+00, 1.9048e+00, 1.9048e+00, 8.6389e-01, 8.4783e-01, 1.8791e+00,
         1.6531e+00, 8.7539e-01, 1.8113e+00, 1.2526e+00, 1.9312e+00, 1.8408e+00,
         2.4843e-01, 3.1826e-02, 6.1034e-03, 2.0145e-01, 4.1527e-01, 4.8365e-01,
         1.4252e-01, 1.8644e+01, 2.5854e+00, 7.9111e-01, 1.4233e+00, 1.5104e+00,
         1.7646e+00, 1.0073e+00, 1.6775e+00, 3.7235e-01, 1.9021e+00, 1.9347e+00],
        [1.2960e+00, 1.3242e+00, 1.3812e+00, 1.3600e+00, 1.3301e+00, 1.3008e+00,
         1.2644e+00, 1.2936e+00, 1.2936e+00, 1.2680e+00, 1.3871e+00, 1.2823e+00,
         1.4171e+00, 1.3553e+00, 1.4612e+00, 1.2729e+00, 1.3415e+00, 1.3243e+00,
         1.3494e+00, 1.3335e+00, 1.3911e+00, 1.3632e+00, 1.3207e+00, 1.3160e+00,
         1.2068e+00, 1.3085e+00, 1.3085e+00, 1.3560e+00, 1.4020e+00, 1.3276e+00,
         1.0965e+00, 1.3102e+00, 1.2023e+00, 1.3692e+00, 1.1992e+00, 1.3302e+00,
         1.4741e+00, 1.1677e+00, 1.4586e+00, 1.4849e+00, 1.0160e+00, 9.4023e-01,
         1.4892e+00, 1.3560e+00, 8.2504e-01, 3.5828e+00, 2.6364e+00, 3.7050e+00,
         2.9339e+00, 2.2301e+00, 1.9323e+00, 3.0347e+00, 3.5171e+00, 1.9171e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 350 : 180.35736203751526
Test loss for epoch 350 : 180.78227696357888
Test Precision for epoch 350 : 0.26153846153846155
Test Recall for epoch 350 : 0.26153846153846155
Test F1 for epoch 350 : 0.26153846153846155


theta for epoch 351 : tensor([[2.7501e+00, 2.7763e+00, 2.8429e+00, 2.9839e+00, 2.9513e+00, 2.7544e+00,
         2.9319e+00, 2.7480e+00, 2.7480e+00, 1.2723e+00, 1.2970e+00, 1.2864e+00,
         1.3261e+00, 1.2657e+00, 1.3704e+00, 1.2772e+00, 1.2524e+00, 1.2810e+00,
         1.2581e+00, 1.2364e+00, 1.2529e+00, 1.2715e+00, 1.2301e+00, 1.2255e+00,
         1.2453e+00, 1.2182e+00, 1.2182e+00, 1.2660e+00, 1.3114e+00, 1.2377e+00,
         1.2640e+00, 1.3127e+00, 1.2490e+00, 1.2793e+00, 1.1991e+00, 1.2403e+00,
         1.3939e+00, 1.4426e+00, 1.4269e+00, 1.4050e+00, 1.4160e+00, 1.3669e+00,
         1.4085e+00, 1.2799e+00, 1.3443e+00, 1.3255e+00, 1.2809e+00, 1.2678e+00,
         1.2532e+00, 1.3238e+00, 1.2747e+00, 1.3590e+00, 1.2404e+00, 1.2567e+00],
        [1.2403e+00, 1.2681e+00, 1.2990e+00, 1.2806e+00, 1.2756e+00, 1.2462e+00,
         1.2536e+00, 1.2390e+00, 1.2390e+00, 2.4446e+00, 2.4492e+00, 2.3683e+00,
         2.5898e+00, 2.3552e+00, 4.2718e+00, 2.4318e+00, 2.5241e+00, 4.0501e+00,
         1.2485e+00, 1.2743e+00, 1.2447e+00, 1.2599e+00, 1.2644e+00, 1.2596e+00,
         1.2774e+00, 1.2521e+00, 1.2521e+00, 1.3044e+00, 1.2541e+00, 1.2719e+00,
         1.2990e+00, 1.2780e+00, 1.2836e+00, 1.3147e+00, 1.2365e+00, 1.2745e+00,
         1.4203e+00, 1.4708e+00, 1.4019e+00, 1.4299e+00, 1.4432e+00, 1.4504e+00,
         1.3828e+00, 1.2695e+00, 1.3671e+00, 1.3102e+00, 1.3149e+00, 1.3012e+00,
         1.2862e+00, 1.2641e+00, 1.3085e+00, 1.3006e+00, 1.2732e+00, 1.2899e+00],
        [1.2126e+00, 1.2401e+00, 1.2791e+00, 1.2745e+00, 1.2452e+00, 1.2173e+00,
         1.2256e+00, 1.2102e+00, 1.2102e+00, 1.2778e+00, 1.3026e+00, 1.2919e+00,
         1.3318e+00, 1.2712e+00, 1.3263e+00, 1.2827e+00, 1.2083e+00, 1.3301e+00,
         2.7743e+00, 3.0035e+00, 2.9868e+00, 2.7896e+00, 2.7407e+00, 2.7373e+00,
         2.9624e+00, 2.7301e+00, 2.7301e+00, 1.2550e+00, 1.3141e+00, 1.2435e+00,
         1.2667e+00, 1.2557e+00, 1.2548e+00, 1.2851e+00, 1.2508e+00, 1.2460e+00,
         1.3987e+00, 1.4476e+00, 1.4281e+00, 1.3350e+00, 1.4172e+00, 1.4024e+00,
         1.4134e+00, 1.2838e+00, 1.2710e+00, 1.3281e+00, 1.2868e+00, 1.2736e+00,
         1.2590e+00, 1.3263e+00, 1.2805e+00, 1.3616e+00, 1.2252e+00, 1.2625e+00],
        [1.2203e+00, 1.2479e+00, 1.2866e+00, 1.2826e+00, 1.2532e+00, 1.2250e+00,
         1.2335e+00, 1.2179e+00, 1.2179e+00, 1.2856e+00, 1.3104e+00, 1.2998e+00,
         1.3359e+00, 1.2790e+00, 1.3181e+00, 1.2905e+00, 1.2649e+00, 1.2761e+00,
         1.2715e+00, 1.2732e+00, 1.3116e+00, 1.2851e+00, 1.2434e+00, 1.2387e+00,
         1.2401e+00, 1.2314e+00, 1.2314e+00, 3.0492e+00, 2.9998e+00, 2.6543e+00,
         2.7771e+00, 3.0473e+00, 2.6642e+00, 2.9659e+00, 2.6686e+00, 2.6564e+00,
         1.4052e+00, 1.4543e+00, 1.4341e+00, 1.3941e+00, 1.4275e+00, 1.4121e+00,
         1.4156e+00, 1.2723e+00, 1.3329e+00, 1.3393e+00, 1.2944e+00, 1.2195e+00,
         1.2191e+00, 1.3376e+00, 1.2882e+00, 1.3729e+00, 1.1883e+00, 1.2701e+00],
        [1.8579e+00, 1.4415e+00, 6.1637e-01, 9.1884e-01, 1.3333e+00, 1.7833e+00,
         1.6497e+00, 1.8954e+00, 1.8954e+00, 1.6971e+00, 1.3158e+00, 1.5255e+00,
         9.2191e-01, 1.7449e+00, 1.4099e-01, 1.6314e+00, 1.9302e+00, 8.3695e-01,
         1.3427e+00, 1.0134e+00, 7.6116e-01, 1.1514e+00, 1.7220e+00, 1.7921e+00,
         1.5593e+00, 1.9055e+00, 1.9055e+00, 8.6441e-01, 8.4798e-01, 1.8795e+00,
         1.6531e+00, 8.7533e-01, 1.8117e+00, 1.2527e+00, 1.9315e+00, 1.8412e+00,
         2.4672e-01, 3.0292e-02, 4.5306e-03, 1.9954e-01, 4.1338e-01, 4.8145e-01,
         1.4090e-01, 1.8711e+01, 2.5375e+00, 7.9199e-01, 1.4240e+00, 1.5107e+00,
         1.7653e+00, 1.0081e+00, 1.6782e+00, 3.7340e-01, 1.9034e+00, 1.9353e+00],
        [1.2971e+00, 1.3252e+00, 1.3822e+00, 1.3610e+00, 1.3311e+00, 1.3018e+00,
         1.2654e+00, 1.2946e+00, 1.2946e+00, 1.2671e+00, 1.3863e+00, 1.2814e+00,
         1.4162e+00, 1.3544e+00, 1.4605e+00, 1.2721e+00, 1.3406e+00, 1.3236e+00,
         1.3493e+00, 1.3333e+00, 1.3910e+00, 1.3631e+00, 1.3207e+00, 1.3159e+00,
         1.2065e+00, 1.3085e+00, 1.3085e+00, 1.3555e+00, 1.4015e+00, 1.3270e+00,
         1.0959e+00, 1.3097e+00, 1.2017e+00, 1.3686e+00, 1.1986e+00, 1.3296e+00,
         1.4741e+00, 1.1676e+00, 1.4584e+00, 1.4849e+00, 1.0158e+00, 9.4008e-01,
         1.4891e+00, 1.3558e+00, 8.2536e-01, 3.5856e+00, 2.6365e+00, 3.7050e+00,
         2.9338e+00, 2.2305e+00, 1.9327e+00, 3.0346e+00, 3.5200e+00, 1.9175e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 351 : 180.3440266274833
Test loss for epoch 351 : 180.77542965778062
Test Precision for epoch 351 : 0.26153846153846155
Test Recall for epoch 351 : 0.26153846153846155
Test F1 for epoch 351 : 0.26153846153846155


theta for epoch 352 : tensor([[2.7483e+00, 2.7746e+00, 2.8411e+00, 2.9822e+00, 2.9496e+00, 2.7526e+00,
         2.9301e+00, 2.7462e+00, 2.7462e+00, 1.2742e+00, 1.2989e+00, 1.2882e+00,
         1.3280e+00, 1.2676e+00, 1.3723e+00, 1.2791e+00, 1.2542e+00, 1.2831e+00,
         1.2586e+00, 1.2369e+00, 1.2535e+00, 1.2721e+00, 1.2306e+00, 1.2260e+00,
         1.2458e+00, 1.2187e+00, 1.2187e+00, 1.2677e+00, 1.3131e+00, 1.2394e+00,
         1.2657e+00, 1.3144e+00, 1.2506e+00, 1.2809e+00, 1.2008e+00, 1.2419e+00,
         1.3947e+00, 1.4434e+00, 1.4277e+00, 1.4059e+00, 1.4168e+00, 1.3678e+00,
         1.4093e+00, 1.2807e+00, 1.3458e+00, 1.3272e+00, 1.2826e+00, 1.2695e+00,
         1.2550e+00, 1.3255e+00, 1.2764e+00, 1.3607e+00, 1.2422e+00, 1.2584e+00],
        [1.2372e+00, 1.2652e+00, 1.2975e+00, 1.2787e+00, 1.2724e+00, 1.2430e+00,
         1.2504e+00, 1.2357e+00, 1.2357e+00, 2.4515e+00, 2.4572e+00, 2.3765e+00,
         2.5999e+00, 2.3626e+00, 4.2491e+00, 2.4395e+00, 2.5359e+00, 4.0280e+00,
         1.2469e+00, 1.2726e+00, 1.2430e+00, 1.2581e+00, 1.2624e+00, 1.2577e+00,
         1.2754e+00, 1.2502e+00, 1.2502e+00, 1.3038e+00, 1.2534e+00, 1.2712e+00,
         1.2983e+00, 1.2786e+00, 1.2829e+00, 1.3141e+00, 1.2359e+00, 1.2738e+00,
         1.4194e+00, 1.4700e+00, 1.4012e+00, 1.4291e+00, 1.4424e+00, 1.4497e+00,
         1.3821e+00, 1.2693e+00, 1.3669e+00, 1.3098e+00, 1.3144e+00, 1.3008e+00,
         1.2858e+00, 1.2638e+00, 1.3080e+00, 1.3003e+00, 1.2727e+00, 1.2894e+00],
        [1.2110e+00, 1.2386e+00, 1.2773e+00, 1.2730e+00, 1.2436e+00, 1.2157e+00,
         1.2240e+00, 1.2087e+00, 1.2087e+00, 1.2788e+00, 1.3036e+00, 1.2928e+00,
         1.3328e+00, 1.2721e+00, 1.3272e+00, 1.2837e+00, 1.2091e+00, 1.3312e+00,
         2.7742e+00, 3.0049e+00, 2.9868e+00, 2.7894e+00, 2.7406e+00, 2.7370e+00,
         2.9637e+00, 2.7299e+00, 2.7299e+00, 1.2552e+00, 1.3146e+00, 1.2440e+00,
         1.2672e+00, 1.2559e+00, 1.2553e+00, 1.2856e+00, 1.2513e+00, 1.2465e+00,
         1.3988e+00, 1.4477e+00, 1.4282e+00, 1.3348e+00, 1.4173e+00, 1.4022e+00,
         1.4135e+00, 1.2838e+00, 1.2712e+00, 1.3292e+00, 1.2879e+00, 1.2747e+00,
         1.2601e+00, 1.3273e+00, 1.2816e+00, 1.3626e+00, 1.2260e+00, 1.2636e+00],
        [1.2181e+00, 1.2458e+00, 1.2843e+00, 1.2806e+00, 1.2511e+00, 1.2228e+00,
         1.2314e+00, 1.2158e+00, 1.2158e+00, 1.2858e+00, 1.3106e+00, 1.2999e+00,
         1.3358e+00, 1.2791e+00, 1.3189e+00, 1.2906e+00, 1.2650e+00, 1.2769e+00,
         1.2704e+00, 1.2716e+00, 1.3104e+00, 1.2839e+00, 1.2422e+00, 1.2375e+00,
         1.2386e+00, 1.2302e+00, 1.2302e+00, 3.0508e+00, 2.9999e+00, 2.6565e+00,
         2.7772e+00, 3.0488e+00, 2.6665e+00, 2.9660e+00, 2.6711e+00, 2.6587e+00,
         1.4048e+00, 1.4539e+00, 1.4335e+00, 1.3934e+00, 1.4271e+00, 1.4114e+00,
         1.4150e+00, 1.2726e+00, 1.3327e+00, 1.3394e+00, 1.2946e+00, 1.2203e+00,
         1.2192e+00, 1.3377e+00, 1.2883e+00, 1.3731e+00, 1.1881e+00, 1.2702e+00],
        [1.8572e+00, 1.4408e+00, 6.1601e-01, 9.1808e-01, 1.3328e+00, 1.7826e+00,
         1.6491e+00, 1.8948e+00, 1.8948e+00, 1.6977e+00, 1.3167e+00, 1.5270e+00,
         9.2356e-01, 1.7463e+00, 1.4226e-01, 1.6320e+00, 1.9316e+00, 8.3787e-01,
         1.3433e+00, 1.0145e+00, 7.6205e-01, 1.1520e+00, 1.7225e+00, 1.7926e+00,
         1.5603e+00, 1.9059e+00, 1.9059e+00, 8.6599e-01, 8.4923e-01, 1.8808e+00,
         1.6542e+00, 8.7636e-01, 1.8130e+00, 1.2539e+00, 1.9329e+00, 1.8425e+00,
         2.4480e-01, 2.8552e-02, 2.7611e-03, 1.9744e-01, 4.1126e-01, 4.7903e-01,
         1.3907e-01, 1.8778e+01, 2.4906e+00, 7.9386e-01, 1.4258e+00, 1.5120e+00,
         1.7670e+00, 1.0098e+00, 1.6800e+00, 3.7543e-01, 1.9057e+00, 1.9370e+00],
        [1.2946e+00, 1.3228e+00, 1.3798e+00, 1.3587e+00, 1.3287e+00, 1.2994e+00,
         1.2630e+00, 1.2922e+00, 1.2922e+00, 1.2672e+00, 1.3864e+00, 1.2814e+00,
         1.4163e+00, 1.3544e+00, 1.4607e+00, 1.2722e+00, 1.3406e+00, 1.3238e+00,
         1.3480e+00, 1.3318e+00, 1.3897e+00, 1.3618e+00, 1.3194e+00, 1.3146e+00,
         1.2050e+00, 1.3072e+00, 1.3072e+00, 1.3552e+00, 1.4013e+00, 1.3268e+00,
         1.0954e+00, 1.3095e+00, 1.2014e+00, 1.3684e+00, 1.1983e+00, 1.3294e+00,
         1.4735e+00, 1.1669e+00, 1.4577e+00, 1.4845e+00, 1.0149e+00, 9.3925e-01,
         1.4886e+00, 1.3551e+00, 8.2500e-01, 3.5899e+00, 2.6381e+00, 3.7065e+00,
         2.9352e+00, 2.2323e+00, 1.9346e+00, 3.0359e+00, 3.5243e+00, 1.9195e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 352 : 180.33144631250366
Test loss for epoch 352 : 180.76734167377475
Test Precision for epoch 352 : 0.26153846153846155
Test Recall for epoch 352 : 0.26153846153846155
Test F1 for epoch 352 : 0.26153846153846155


theta for epoch 353 : tensor([[2.7523e+00, 2.7786e+00, 2.8452e+00, 2.9863e+00, 2.9537e+00, 2.7566e+00,
         2.9342e+00, 2.7502e+00, 2.7502e+00, 1.2716e+00, 1.2964e+00, 1.2855e+00,
         1.3254e+00, 1.2649e+00, 1.3699e+00, 1.2765e+00, 1.2515e+00, 1.2807e+00,
         1.2578e+00, 1.2360e+00, 1.2526e+00, 1.2713e+00, 1.2298e+00, 1.2252e+00,
         1.2450e+00, 1.2179e+00, 1.2179e+00, 1.2654e+00, 1.3110e+00, 1.2371e+00,
         1.2635e+00, 1.3122e+00, 1.2484e+00, 1.2787e+00, 1.1985e+00, 1.2396e+00,
         1.3937e+00, 1.4425e+00, 1.4268e+00, 1.4051e+00, 1.4159e+00, 1.3669e+00,
         1.4083e+00, 1.2795e+00, 1.3454e+00, 1.3242e+00, 1.2796e+00, 1.2664e+00,
         1.2519e+00, 1.3224e+00, 1.2733e+00, 1.3577e+00, 1.2390e+00, 1.2553e+00],
        [1.2392e+00, 1.2673e+00, 1.3007e+00, 1.2819e+00, 1.2744e+00, 1.2449e+00,
         1.2524e+00, 1.2377e+00, 1.2377e+00, 2.4562e+00, 2.4630e+00, 2.3826e+00,
         2.6079e+00, 2.3679e+00, 4.2247e+00, 2.4450e+00, 2.5455e+00, 4.0041e+00,
         1.2478e+00, 1.2734e+00, 1.2438e+00, 1.2590e+00, 1.2632e+00, 1.2584e+00,
         1.2761e+00, 1.2509e+00, 1.2509e+00, 1.3033e+00, 1.2528e+00, 1.2706e+00,
         1.2977e+00, 1.2794e+00, 1.2822e+00, 1.3135e+00, 1.2353e+00, 1.2732e+00,
         1.4194e+00, 1.4700e+00, 1.4013e+00, 1.4291e+00, 1.4424e+00, 1.4498e+00,
         1.3823e+00, 1.2698e+00, 1.3675e+00, 1.3082e+00, 1.3126e+00, 1.2989e+00,
         1.2839e+00, 1.2622e+00, 1.3061e+00, 1.2991e+00, 1.2709e+00, 1.2876e+00],
        [1.2123e+00, 1.2399e+00, 1.2784e+00, 1.2743e+00, 1.2449e+00, 1.2170e+00,
         1.2253e+00, 1.2100e+00, 1.2100e+00, 1.2772e+00, 1.3020e+00, 1.2911e+00,
         1.3312e+00, 1.2704e+00, 1.3257e+00, 1.2821e+00, 1.2072e+00, 1.3297e+00,
         2.7759e+00, 3.0080e+00, 2.9885e+00, 2.7909e+00, 2.7421e+00, 2.7385e+00,
         2.9668e+00, 2.7315e+00, 2.7315e+00, 1.2539e+00, 1.3136e+00, 1.2429e+00,
         1.2663e+00, 1.2546e+00, 1.2542e+00, 1.2847e+00, 1.2502e+00, 1.2455e+00,
         1.3985e+00, 1.4475e+00, 1.4279e+00, 1.3342e+00, 1.4170e+00, 1.4016e+00,
         1.4132e+00, 1.2833e+00, 1.2711e+00, 1.3269e+00, 1.2856e+00, 1.2724e+00,
         1.2578e+00, 1.3249e+00, 1.2793e+00, 1.3602e+00, 1.2234e+00, 1.2613e+00],
        [1.2200e+00, 1.2477e+00, 1.2858e+00, 1.2824e+00, 1.2529e+00, 1.2247e+00,
         1.2333e+00, 1.2177e+00, 1.2177e+00, 1.2851e+00, 1.3099e+00, 1.2991e+00,
         1.3350e+00, 1.2784e+00, 1.3189e+00, 1.2900e+00, 1.2642e+00, 1.2770e+00,
         1.2714e+00, 1.2721e+00, 1.3114e+00, 1.2849e+00, 1.2432e+00, 1.2385e+00,
         1.2393e+00, 1.2312e+00, 1.2312e+00, 3.0510e+00, 2.9988e+00, 2.6574e+00,
         2.7760e+00, 3.0491e+00, 2.6674e+00, 2.9648e+00, 2.6723e+00, 2.6596e+00,
         1.4050e+00, 1.4541e+00, 1.4335e+00, 1.3934e+00, 1.4273e+00, 1.4113e+00,
         1.4150e+00, 1.2735e+00, 1.3331e+00, 1.3381e+00, 1.2933e+00, 1.2197e+00,
         1.2179e+00, 1.3364e+00, 1.2870e+00, 1.3718e+00, 1.1865e+00, 1.2688e+00],
        [1.8595e+00, 1.4432e+00, 6.1776e-01, 9.1969e-01, 1.3352e+00, 1.7851e+00,
         1.6514e+00, 1.8972e+00, 1.8972e+00, 1.6968e+00, 1.3159e+00, 1.5268e+00,
         9.2352e-01, 1.7461e+00, 1.4196e-01, 1.6310e+00, 1.9315e+00, 8.3701e-01,
         1.3445e+00, 1.0161e+00, 7.6337e-01, 1.1531e+00, 1.7238e+00, 1.7939e+00,
         1.5620e+00, 1.9072e+00, 1.9072e+00, 8.6613e-01, 8.4904e-01, 1.8810e+00,
         1.6540e+00, 8.7593e-01, 1.8132e+00, 1.2536e+00, 1.9330e+00, 1.8427e+00,
         2.4326e-01, 2.7179e-02, 1.3533e-03, 1.9573e-01, 4.0956e-01, 4.7704e-01,
         1.3761e-01, 1.8844e+01, 2.4453e+00, 7.9316e-01, 1.4250e+00, 1.5107e+00,
         1.7662e+00, 1.0089e+00, 1.6791e+00, 3.7495e-01, 1.9055e+00, 1.9361e+00],
        [1.2976e+00, 1.3258e+00, 1.3827e+00, 1.3616e+00, 1.3316e+00, 1.3024e+00,
         1.2660e+00, 1.2952e+00, 1.2952e+00, 1.2674e+00, 1.3866e+00, 1.2816e+00,
         1.4164e+00, 1.3545e+00, 1.4609e+00, 1.2725e+00, 1.3407e+00, 1.3243e+00,
         1.3501e+00, 1.3337e+00, 1.3918e+00, 1.3639e+00, 1.3215e+00, 1.3167e+00,
         1.2070e+00, 1.3093e+00, 1.3093e+00, 1.3558e+00, 1.4019e+00, 1.3273e+00,
         1.0961e+00, 1.3101e+00, 1.2020e+00, 1.3690e+00, 1.1989e+00, 1.3299e+00,
         1.4743e+00, 1.1680e+00, 1.4584e+00, 1.4855e+00, 1.0160e+00, 9.4039e-01,
         1.4894e+00, 1.3558e+00, 8.2664e-01, 3.5903e+00, 2.6358e+00, 3.7041e+00,
         2.9327e+00, 2.2303e+00, 1.9327e+00, 3.0335e+00, 3.5248e+00, 1.9175e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 353 : 180.31924849473464
Test loss for epoch 353 : 180.76349579443922
Test Precision for epoch 353 : 0.26153846153846155
Test Recall for epoch 353 : 0.26153846153846155
Test F1 for epoch 353 : 0.26153846153846155


theta for epoch 354 : tensor([[ 2.7496e+00,  2.7759e+00,  2.8425e+00,  2.9836e+00,  2.9510e+00,
          2.7539e+00,  2.9315e+00,  2.7475e+00,  2.7475e+00,  1.2740e+00,
          1.2988e+00,  1.2879e+00,  1.3278e+00,  1.2673e+00,  1.3724e+00,
          1.2790e+00,  1.2539e+00,  1.2834e+00,  1.2584e+00,  1.2366e+00,
          1.2532e+00,  1.2719e+00,  1.2304e+00,  1.2258e+00,  1.2455e+00,
          1.2185e+00,  1.2185e+00,  1.2675e+00,  1.3131e+00,  1.2392e+00,
          1.2656e+00,  1.3143e+00,  1.2504e+00,  1.2808e+00,  1.2005e+00,
          1.2417e+00,  1.3948e+00,  1.4435e+00,  1.4278e+00,  1.4063e+00,
          1.4169e+00,  1.3680e+00,  1.4094e+00,  1.2805e+00,  1.3471e+00,
          1.3275e+00,  1.2829e+00,  1.2698e+00,  1.2553e+00,  1.3258e+00,
          1.2767e+00,  1.3610e+00,  1.2424e+00,  1.2587e+00],
        [ 1.2354e+00,  1.2636e+00,  1.2986e+00,  1.2793e+00,  1.2704e+00,
          1.2409e+00,  1.2485e+00,  1.2337e+00,  1.2337e+00,  2.4631e+00,
          2.4709e+00,  2.3909e+00,  2.6182e+00,  2.3755e+00,  4.2027e+00,
          2.4527e+00,  2.5573e+00,  3.9828e+00,  1.2456e+00,  1.2712e+00,
          1.2417e+00,  1.2568e+00,  1.2607e+00,  1.2559e+00,  1.2736e+00,
          1.2484e+00,  1.2484e+00,  1.3027e+00,  1.2521e+00,  1.2697e+00,
          1.2969e+00,  1.2799e+00,  1.2814e+00,  1.3127e+00,  1.2346e+00,
          1.2723e+00,  1.4184e+00,  1.4690e+00,  1.4005e+00,  1.4282e+00,
          1.4414e+00,  1.4489e+00,  1.3814e+00,  1.2695e+00,  1.3672e+00,
          1.3090e+00,  1.3133e+00,  1.2996e+00,  1.2846e+00,  1.2631e+00,
          1.3068e+00,  1.2998e+00,  1.2715e+00,  1.2883e+00],
        [ 1.2103e+00,  1.2379e+00,  1.2762e+00,  1.2723e+00,  1.2429e+00,
          1.2150e+00,  1.2233e+00,  1.2079e+00,  1.2079e+00,  1.2784e+00,
          1.3032e+00,  1.2923e+00,  1.3323e+00,  1.2716e+00,  1.3268e+00,
          1.2833e+00,  1.2082e+00,  1.3310e+00,  2.7754e+00,  3.0090e+00,
          2.9881e+00,  2.7904e+00,  2.7416e+00,  2.7379e+00,  2.9678e+00,
          2.7309e+00,  2.7309e+00,  1.2543e+00,  1.3142e+00,  1.2436e+00,
          1.2669e+00,  1.2550e+00,  1.2549e+00,  1.2854e+00,  1.2508e+00,
          1.2461e+00,  1.3987e+00,  1.4477e+00,  1.4281e+00,  1.3342e+00,
          1.4172e+00,  1.4015e+00,  1.4134e+00,  1.2834e+00,  1.2715e+00,
          1.3294e+00,  1.2881e+00,  1.2749e+00,  1.2604e+00,  1.3273e+00,
          1.2819e+00,  1.3626e+00,  1.2257e+00,  1.2639e+00],
        [ 1.2172e+00,  1.2449e+00,  1.2830e+00,  1.2798e+00,  1.2502e+00,
          1.2219e+00,  1.2305e+00,  1.2149e+00,  1.2149e+00,  1.2852e+00,
          1.3101e+00,  1.2992e+00,  1.3349e+00,  1.2784e+00,  1.3195e+00,
          1.2901e+00,  1.2643e+00,  1.2777e+00,  1.2697e+00,  1.2701e+00,
          1.3097e+00,  1.2833e+00,  1.2415e+00,  1.2368e+00,  1.2374e+00,
          1.2295e+00,  1.2295e+00,  3.0527e+00,  2.9990e+00,  2.6598e+00,
          2.7763e+00,  3.0508e+00,  2.6698e+00,  2.9650e+00,  2.6749e+00,
          2.6620e+00,  1.4045e+00,  1.4536e+00,  1.4328e+00,  1.3927e+00,
          1.4268e+00,  1.4106e+00,  1.4143e+00,  1.2737e+00,  1.3329e+00,
          1.3392e+00,  1.2944e+00,  1.2214e+00,  1.2190e+00,  1.3375e+00,
          1.2881e+00,  1.3729e+00,  1.1874e+00,  1.2700e+00],
        [ 1.8583e+00,  1.4421e+00,  6.1728e-01,  9.1875e-01,  1.3343e+00,
          1.7840e+00,  1.6503e+00,  1.8961e+00,  1.8961e+00,  1.6976e+00,
          1.3170e+00,  1.5284e+00,  9.2546e-01,  1.7476e+00,  1.4367e-01,
          1.6317e+00,  1.9330e+00,  8.3833e-01,  1.3449e+00,  1.0171e+00,
          7.6424e-01,  1.1536e+00,  1.7241e+00,  1.7941e+00,  1.5628e+00,
          1.9075e+00,  1.9075e+00,  8.6801e-01,  8.5063e-01,  1.8824e+00,
          1.6553e+00,  8.7727e-01,  1.8147e+00,  1.2551e+00,  1.9344e+00,
          1.8442e+00,  2.4101e-01,  2.5130e-02, -7.0998e-04,  1.9335e-01,
          4.0710e-01,  4.7431e-01,  1.3547e-01,  1.8910e+01,  2.4006e+00,
          7.9634e-01,  1.4280e+00,  1.5134e+00,  1.7691e+00,  1.0120e+00,
          1.6821e+00,  3.7827e-01,  1.9089e+00,  1.9390e+00],
        [ 1.2937e+00,  1.3219e+00,  1.3789e+00,  1.3577e+00,  1.3277e+00,
          1.2985e+00,  1.2620e+00,  1.2913e+00,  1.2913e+00,  1.2664e+00,
          1.3857e+00,  1.2805e+00,  1.4155e+00,  1.3535e+00,  1.4602e+00,
          1.2715e+00,  1.3397e+00,  1.3235e+00,  1.3473e+00,  1.3307e+00,
          1.3889e+00,  1.3611e+00,  1.3187e+00,  1.3139e+00,  1.2039e+00,
          1.3065e+00,  1.3065e+00,  1.3546e+00,  1.4008e+00,  1.3260e+00,
          1.0945e+00,  1.3089e+00,  1.2007e+00,  1.3679e+00,  1.1975e+00,
          1.3286e+00,  1.4731e+00,  1.1665e+00,  1.4571e+00,  1.4844e+00,
          1.0142e+00,  9.3858e-01,  1.4882e+00,  1.3544e+00,  8.2532e-01,
          3.5966e+00,  2.6396e+00,  3.7077e+00,  2.9362e+00,  2.2343e+00,
          1.9367e+00,  3.0370e+00,  3.5313e+00,  1.9215e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 354 : 180.30723496227222
Test loss for epoch 354 : 180.7542795818636
Test Precision for epoch 354 : 0.26153846153846155
Test Recall for epoch 354 : 0.26153846153846155
Test F1 for epoch 354 : 0.26153846153846155


theta for epoch 355 : tensor([[ 2.7548e+00,  2.7811e+00,  2.8477e+00,  2.9889e+00,  2.9562e+00,
          2.7591e+00,  2.9368e+00,  2.7527e+00,  2.7527e+00,  1.2710e+00,
          1.2958e+00,  1.2848e+00,  1.3248e+00,  1.2642e+00,  1.3696e+00,
          1.2760e+00,  1.2508e+00,  1.2805e+00,  1.2571e+00,  1.2352e+00,
          1.2518e+00,  1.2705e+00,  1.2291e+00,  1.2244e+00,  1.2442e+00,
          1.2171e+00,  1.2171e+00,  1.2648e+00,  1.3105e+00,  1.2364e+00,
          1.2630e+00,  1.3117e+00,  1.2477e+00,  1.2782e+00,  1.1978e+00,
          1.2390e+00,  1.3935e+00,  1.4423e+00,  1.4266e+00,  1.4052e+00,
          1.4157e+00,  1.3668e+00,  1.4082e+00,  1.2791e+00,  1.3465e+00,
          1.3233e+00,  1.2787e+00,  1.2656e+00,  1.2510e+00,  1.3215e+00,
          1.2724e+00,  1.3568e+00,  1.2381e+00,  1.2544e+00],
        [ 1.2380e+00,  1.2663e+00,  1.3023e+00,  1.2831e+00,  1.2729e+00,
          1.2434e+00,  1.2511e+00,  1.2362e+00,  1.2362e+00,  2.4678e+00,
          2.4766e+00,  2.3972e+00,  2.6265e+00,  2.3811e+00,  4.1791e+00,
          2.4581e+00,  2.5668e+00,  3.9598e+00,  1.2465e+00,  1.2720e+00,
          1.2424e+00,  1.2577e+00,  1.2614e+00,  1.2566e+00,  1.2743e+00,
          1.2491e+00,  1.2491e+00,  1.3022e+00,  1.2515e+00,  1.2690e+00,
          1.2963e+00,  1.2807e+00,  1.2807e+00,  1.3121e+00,  1.2341e+00,
          1.2717e+00,  1.4184e+00,  1.4690e+00,  1.4007e+00,  1.4283e+00,
          1.4414e+00,  1.4490e+00,  1.3816e+00,  1.2700e+00,  1.3679e+00,
          1.3066e+00,  1.3106e+00,  1.2969e+00,  1.2819e+00,  1.2608e+00,
          1.3041e+00,  1.2979e+00,  1.2688e+00,  1.2855e+00],
        [ 1.2123e+00,  1.2399e+00,  1.2779e+00,  1.2743e+00,  1.2449e+00,
          1.2170e+00,  1.2253e+00,  1.2100e+00,  1.2100e+00,  1.2770e+00,
          1.3019e+00,  1.2908e+00,  1.3309e+00,  1.2701e+00,  1.3255e+00,
          1.2820e+00,  1.2066e+00,  1.3297e+00,  2.7771e+00,  3.0120e+00,
          2.9898e+00,  2.7919e+00,  2.7431e+00,  2.7393e+00,  2.9708e+00,
          2.7324e+00,  2.7324e+00,  1.2532e+00,  1.3133e+00,  1.2427e+00,
          1.2661e+00,  1.2539e+00,  1.2540e+00,  1.2845e+00,  1.2499e+00,
          1.2452e+00,  1.3986e+00,  1.4476e+00,  1.4280e+00,  1.3338e+00,
          1.4171e+00,  1.4012e+00,  1.4133e+00,  1.2831e+00,  1.2717e+00,
          1.3264e+00,  1.2850e+00,  1.2719e+00,  1.2573e+00,  1.3242e+00,
          1.2788e+00,  1.3595e+00,  1.2223e+00,  1.2608e+00],
        [ 1.2196e+00,  1.2473e+00,  1.2850e+00,  1.2820e+00,  1.2526e+00,
          1.2243e+00,  1.2329e+00,  1.2173e+00,  1.2173e+00,  1.2846e+00,
          1.3094e+00,  1.2985e+00,  1.3340e+00,  1.2777e+00,  1.3195e+00,
          1.2895e+00,  1.2636e+00,  1.2777e+00,  1.2706e+00,  1.2705e+00,
          1.3107e+00,  1.2842e+00,  1.2424e+00,  1.2377e+00,  1.2381e+00,
          1.2304e+00,  1.2304e+00,  3.0532e+00,  2.9980e+00,  2.6610e+00,
          2.7753e+00,  3.0513e+00,  2.6710e+00,  2.9639e+00,  2.6764e+00,
          2.6632e+00,  1.4047e+00,  1.4539e+00,  1.4329e+00,  1.3927e+00,
          1.4271e+00,  1.4106e+00,  1.4143e+00,  1.2746e+00,  1.3335e+00,
          1.3371e+00,  1.2923e+00,  1.2200e+00,  1.2170e+00,  1.3355e+00,
          1.2861e+00,  1.3709e+00,  1.1851e+00,  1.2679e+00],
        [ 1.8611e+00,  1.4449e+00,  6.1932e-01,  9.2071e-01,  1.3371e+00,
          1.7869e+00,  1.6530e+00,  1.8990e+00,  1.8990e+00,  1.6966e+00,
          1.3162e+00,  1.5282e+00,  9.2537e-01,  1.7474e+00,  1.4331e-01,
          1.6307e+00,  1.9329e+00,  8.3749e-01,  1.3461e+00,  1.0185e+00,
          7.6538e-01,  1.1546e+00,  1.7253e+00,  1.7954e+00,  1.5643e+00,
          1.9087e+00,  1.9087e+00,  8.6804e-01,  8.5040e-01,  1.8825e+00,
          1.6551e+00,  8.7676e-01,  1.8148e+00,  1.2548e+00,  1.9345e+00,
          1.8443e+00,  2.3951e-01,  2.3812e-02, -2.0597e-03,  1.9172e-01,
          4.0544e-01,  4.7239e-01,  1.3406e-01,  1.8977e+01,  2.3580e+00,
          7.9487e-01,  1.4264e+00,  1.5113e+00,  1.7675e+00,  1.0103e+00,
          1.6804e+00,  3.7702e-01,  1.9078e+00,  1.9374e+00],
        [ 1.2978e+00,  1.3260e+00,  1.3829e+00,  1.3618e+00,  1.3318e+00,
          1.3026e+00,  1.2661e+00,  1.2954e+00,  1.2954e+00,  1.2674e+00,
          1.3865e+00,  1.2814e+00,  1.4163e+00,  1.3543e+00,  1.4611e+00,
          1.2725e+00,  1.3404e+00,  1.3246e+00,  1.3499e+00,  1.3331e+00,
          1.3915e+00,  1.3637e+00,  1.3212e+00,  1.3165e+00,  1.2064e+00,
          1.3090e+00,  1.3090e+00,  1.3557e+00,  1.4019e+00,  1.3271e+00,
          1.0959e+00,  1.3101e+00,  1.2019e+00,  1.3690e+00,  1.1987e+00,
          1.3297e+00,  1.4744e+00,  1.1681e+00,  1.4583e+00,  1.4858e+00,
          1.0158e+00,  9.4036e-01,  1.4895e+00,  1.3556e+00,  8.2763e-01,
          3.5960e+00,  2.6363e+00,  3.7043e+00,  2.9328e+00,  2.2313e+00,
          1.9337e+00,  3.0336e+00,  3.5306e+00,  1.9185e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 355 : 180.29528350194227
Test loss for epoch 355 : 180.75151697788783
Test Precision for epoch 355 : 0.26153846153846155
Test Recall for epoch 355 : 0.26153846153846155
Test F1 for epoch 355 : 0.26153846153846155


theta for epoch 356 : tensor([[ 2.7513e+00,  2.7776e+00,  2.8443e+00,  2.9854e+00,  2.9528e+00,
          2.7556e+00,  2.9333e+00,  2.7492e+00,  2.7492e+00,  1.2737e+00,
          1.2985e+00,  1.2874e+00,  1.3274e+00,  1.2669e+00,  1.3723e+00,
          1.2787e+00,  1.2534e+00,  1.2834e+00,  1.2587e+00,  1.2369e+00,
          1.2535e+00,  1.2722e+00,  1.2307e+00,  1.2260e+00,  1.2457e+00,
          1.2188e+00,  1.2188e+00,  1.2674e+00,  1.3130e+00,  1.2389e+00,
          1.2655e+00,  1.3141e+00,  1.2502e+00,  1.2807e+00,  1.2003e+00,
          1.2414e+00,  1.3948e+00,  1.4436e+00,  1.4279e+00,  1.4065e+00,
          1.4170e+00,  1.3682e+00,  1.4094e+00,  1.2803e+00,  1.3484e+00,
          1.3273e+00,  1.2827e+00,  1.2696e+00,  1.2551e+00,  1.3256e+00,
          1.2765e+00,  1.3607e+00,  1.2422e+00,  1.2585e+00],
        [ 1.2335e+00,  1.2620e+00,  1.2996e+00,  1.2798e+00,  1.2683e+00,
          1.2388e+00,  1.2466e+00,  1.2316e+00,  1.2316e+00,  2.4745e+00,
          2.4842e+00,  2.4055e+00,  2.6368e+00,  2.3888e+00,  4.1578e+00,
          2.4656e+00,  2.5783e+00,  3.9392e+00,  1.2450e+00,  1.2705e+00,
          1.2409e+00,  1.2563e+00,  1.2597e+00,  1.2549e+00,  1.2726e+00,
          1.2474e+00,  1.2474e+00,  1.3015e+00,  1.2509e+00,  1.2682e+00,
          1.2955e+00,  1.2813e+00,  1.2799e+00,  1.3113e+00,  1.2334e+00,
          1.2708e+00,  1.4174e+00,  1.4681e+00,  1.3999e+00,  1.4274e+00,
          1.4405e+00,  1.4481e+00,  1.3808e+00,  1.2696e+00,  1.3676e+00,
          1.3076e+00,  1.3116e+00,  1.2980e+00,  1.2830e+00,  1.2620e+00,
          1.3051e+00,  1.2990e+00,  1.2698e+00,  1.2866e+00],
        [ 1.2092e+00,  1.2368e+00,  1.2747e+00,  1.2712e+00,  1.2419e+00,
          1.2139e+00,  1.2222e+00,  1.2068e+00,  1.2068e+00,  1.2777e+00,
          1.3026e+00,  1.2915e+00,  1.3316e+00,  1.2708e+00,  1.3261e+00,
          1.2827e+00,  1.2071e+00,  1.3305e+00,  2.7776e+00,  3.0140e+00,
          2.9904e+00,  2.7924e+00,  2.7435e+00,  2.7396e+00,  2.9727e+00,
          2.7328e+00,  2.7328e+00,  1.2533e+00,  1.3136e+00,  1.2430e+00,
          1.2665e+00,  1.2541e+00,  1.2543e+00,  1.2849e+00,  1.2502e+00,
          1.2455e+00,  1.3985e+00,  1.4474e+00,  1.4279e+00,  1.3334e+00,
          1.4170e+00,  1.4008e+00,  1.4132e+00,  1.2829e+00,  1.2718e+00,
          1.3288e+00,  1.2875e+00,  1.2743e+00,  1.2598e+00,  1.3265e+00,
          1.2812e+00,  1.3618e+00,  1.2245e+00,  1.2632e+00],
        [ 1.2162e+00,  1.2439e+00,  1.2816e+00,  1.2788e+00,  1.2492e+00,
          1.2209e+00,  1.2295e+00,  1.2139e+00,  1.2139e+00,  1.2846e+00,
          1.3095e+00,  1.2984e+00,  1.3338e+00,  1.2776e+00,  1.3200e+00,
          1.2895e+00,  1.2635e+00,  1.2783e+00,  1.2697e+00,  1.2692e+00,
          1.3097e+00,  1.2833e+00,  1.2414e+00,  1.2368e+00,  1.2369e+00,
          1.2294e+00,  1.2294e+00,  3.0550e+00,  2.9984e+00,  2.6635e+00,
          2.7756e+00,  3.0531e+00,  2.6735e+00,  2.9642e+00,  2.6792e+00,
          2.6657e+00,  1.4042e+00,  1.4533e+00,  1.4322e+00,  1.3920e+00,
          1.4265e+00,  1.4098e+00,  1.4136e+00,  1.2747e+00,  1.3332e+00,
          1.3385e+00,  1.2937e+00,  1.2220e+00,  1.2184e+00,  1.3368e+00,
          1.2874e+00,  1.3722e+00,  1.1862e+00,  1.2693e+00],
        [ 1.8593e+00,  1.4434e+00,  6.1850e-01,  9.1938e-01,  1.3357e+00,
          1.7852e+00,  1.6513e+00,  1.8974e+00,  1.8974e+00,  1.6973e+00,
          1.3173e+00,  1.5297e+00,  9.2732e-01,  1.7488e+00,  1.4513e-01,
          1.6314e+00,  1.9344e+00,  8.3890e-01,  1.3472e+00,  1.0200e+00,
          7.6681e-01,  1.1556e+00,  1.7262e+00,  1.7963e+00,  1.5656e+00,
          1.9095e+00,  1.9095e+00,  8.7003e-01,  8.5216e-01,  1.8840e+00,
          1.6564e+00,  8.7824e-01,  1.8163e+00,  1.2564e+00,  1.9360e+00,
          1.8458e+00,  2.3708e-01,  2.1600e-02, -4.2766e-03,  1.8919e-01,
          4.0279e-01,  4.6949e-01,  1.3174e-01,  1.9043e+01,  2.3159e+00,
          7.9841e-01,  1.4297e+00,  1.5143e+00,  1.7708e+00,  1.0138e+00,
          1.6837e+00,  3.8070e-01,  1.9115e+00,  1.9406e+00],
        [ 1.2930e+00,  1.3212e+00,  1.3782e+00,  1.3570e+00,  1.3270e+00,
          1.2978e+00,  1.2614e+00,  1.2906e+00,  1.2906e+00,  1.2660e+00,
          1.3853e+00,  1.2799e+00,  1.4150e+00,  1.3530e+00,  1.4600e+00,
          1.2711e+00,  1.3390e+00,  1.3234e+00,  1.3475e+00,  1.3305e+00,
          1.3891e+00,  1.3613e+00,  1.3188e+00,  1.3141e+00,  1.2037e+00,
          1.3066e+00,  1.3066e+00,  1.3543e+00,  1.4006e+00,  1.3257e+00,
          1.0940e+00,  1.3086e+00,  1.2003e+00,  1.3676e+00,  1.1971e+00,
          1.3283e+00,  1.4731e+00,  1.1663e+00,  1.4568e+00,  1.4845e+00,
          1.0138e+00,  9.3827e-01,  1.4882e+00,  1.3540e+00,  8.2605e-01,
          3.6029e+00,  2.6407e+00,  3.7086e+00,  2.9370e+00,  2.2358e+00,
          1.9383e+00,  3.0377e+00,  3.5377e+00,  1.9232e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 356 : 180.28357176141827
Test loss for epoch 356 : 180.74188201586114
Test Precision for epoch 356 : 0.26153846153846155
Test Recall for epoch 356 : 0.26153846153846155
Test F1 for epoch 356 : 0.26153846153846155


theta for epoch 357 : tensor([[ 2.7578e+00,  2.7841e+00,  2.8507e+00,  2.9920e+00,  2.9593e+00,
          2.7621e+00,  2.9399e+00,  2.7557e+00,  2.7557e+00,  1.2704e+00,
          1.2951e+00,  1.2840e+00,  1.3240e+00,  1.2634e+00,  1.3691e+00,
          1.2754e+00,  1.2499e+00,  1.2802e+00,  1.2558e+00,  1.2339e+00,
          1.2505e+00,  1.2693e+00,  1.2278e+00,  1.2231e+00,  1.2428e+00,
          1.2158e+00,  1.2158e+00,  1.2641e+00,  1.3099e+00,  1.2356e+00,
          1.2622e+00,  1.3109e+00,  1.2469e+00,  1.2775e+00,  1.1969e+00,
          1.2381e+00,  1.3932e+00,  1.4420e+00,  1.4263e+00,  1.4050e+00,
          1.4154e+00,  1.3665e+00,  1.4078e+00,  1.2783e+00,  1.3473e+00,
          1.3229e+00,  1.2783e+00,  1.2652e+00,  1.2506e+00,  1.3212e+00,
          1.2720e+00,  1.3564e+00,  1.2377e+00,  1.2541e+00],
        [ 1.2369e+00,  1.2652e+00,  1.3039e+00,  1.2842e+00,  1.2715e+00,
          1.2420e+00,  1.2500e+00,  1.2348e+00,  1.2348e+00,  2.4792e+00,
          2.4899e+00,  2.4119e+00,  2.6453e+00,  2.3946e+00,  4.1350e+00,
          2.4711e+00,  2.5878e+00,  3.9172e+00,  1.2448e+00,  1.2702e+00,
          1.2405e+00,  1.2561e+00,  1.2593e+00,  1.2544e+00,  1.2723e+00,
          1.2469e+00,  1.2469e+00,  1.3010e+00,  1.2504e+00,  1.2674e+00,
          1.2948e+00,  1.2820e+00,  1.2791e+00,  1.3106e+00,  1.2327e+00,
          1.2700e+00,  1.4173e+00,  1.4680e+00,  1.4000e+00,  1.4274e+00,
          1.4404e+00,  1.4481e+00,  1.3809e+00,  1.2701e+00,  1.3682e+00,
          1.3055e+00,  1.3091e+00,  1.2955e+00,  1.2805e+00,  1.2599e+00,
          1.3026e+00,  1.2973e+00,  1.2673e+00,  1.2841e+00],
        [ 1.2125e+00,  1.2401e+00,  1.2777e+00,  1.2745e+00,  1.2452e+00,
          1.2172e+00,  1.2255e+00,  1.2102e+00,  1.2102e+00,  1.2771e+00,
          1.3020e+00,  1.2908e+00,  1.3309e+00,  1.2702e+00,  1.3256e+00,
          1.2822e+00,  1.2062e+00,  1.3300e+00,  2.7781e+00,  3.0159e+00,
          2.9910e+00,  2.7928e+00,  2.7438e+00,  2.7398e+00,  2.9746e+00,
          2.7331e+00,  2.7331e+00,  1.2527e+00,  1.3132e+00,  1.2426e+00,
          1.2661e+00,  1.2535e+00,  1.2539e+00,  1.2846e+00,  1.2498e+00,
          1.2451e+00,  1.3987e+00,  1.4477e+00,  1.4282e+00,  1.3335e+00,
          1.4173e+00,  1.4008e+00,  1.4134e+00,  1.2830e+00,  1.2724e+00,
          1.3266e+00,  1.2854e+00,  1.2722e+00,  1.2576e+00,  1.3243e+00,
          1.2791e+00,  1.3596e+00,  1.2221e+00,  1.2611e+00],
        [ 1.2192e+00,  1.2469e+00,  1.2842e+00,  1.2816e+00,  1.2522e+00,
          1.2239e+00,  1.2325e+00,  1.2169e+00,  1.2169e+00,  1.2841e+00,
          1.3089e+00,  1.2978e+00,  1.3331e+00,  1.2771e+00,  1.3200e+00,
          1.2890e+00,  1.2628e+00,  1.2784e+00,  1.2696e+00,  1.2687e+00,
          1.3096e+00,  1.2832e+00,  1.2413e+00,  1.2367e+00,  1.2366e+00,
          1.2293e+00,  1.2293e+00,  3.0557e+00,  2.9976e+00,  2.6649e+00,
          2.7748e+00,  3.0538e+00,  2.6749e+00,  2.9633e+00,  2.6808e+00,
          2.6671e+00,  1.4044e+00,  1.4536e+00,  1.4322e+00,  1.3920e+00,
          1.4267e+00,  1.4098e+00,  1.4136e+00,  1.2755e+00,  1.3339e+00,
          1.3367e+00,  1.2919e+00,  1.2208e+00,  1.2166e+00,  1.3350e+00,
          1.2856e+00,  1.3705e+00,  1.1842e+00,  1.2674e+00],
        [ 1.8627e+00,  1.4469e+00,  6.2114e-01,  9.2198e-01,  1.3392e+00,
          1.7888e+00,  1.6547e+00,  1.9009e+00,  1.9009e+00,  1.6964e+00,
          1.3167e+00,  1.5296e+00,  9.2738e-01,  1.7486e+00,  1.4499e-01,
          1.6305e+00,  1.9345e+00,  8.3832e-01,  1.3476e+00,  1.0207e+00,
          7.6724e-01,  1.1559e+00,  1.7267e+00,  1.7967e+00,  1.5663e+00,
          1.9100e+00,  1.9100e+00,  8.7011e-01,  8.5202e-01,  1.8842e+00,
          1.6562e+00,  8.7781e-01,  1.8164e+00,  1.2562e+00,  1.9361e+00,
          1.8459e+00,  2.3545e-01,  2.0163e-02, -5.7383e-03,  1.8748e-01,
          4.0099e-01,  4.6746e-01,  1.3020e-01,  1.9109e+01,  2.2761e+00,
          7.9724e-01,  1.4284e+00,  1.5126e+00,  1.7694e+00,  1.0124e+00,
          1.6824e+00,  3.7976e-01,  1.9107e+00,  1.9393e+00],
        [ 1.2977e+00,  1.3259e+00,  1.3828e+00,  1.3617e+00,  1.3317e+00,
          1.3025e+00,  1.2660e+00,  1.2953e+00,  1.2953e+00,  1.2670e+00,
          1.3862e+00,  1.2808e+00,  1.4158e+00,  1.3538e+00,  1.4609e+00,
          1.2721e+00,  1.3398e+00,  1.3246e+00,  1.3488e+00,  1.3317e+00,
          1.3904e+00,  1.3626e+00,  1.3202e+00,  1.3154e+00,  1.2050e+00,
          1.3080e+00,  1.3080e+00,  1.3553e+00,  1.4016e+00,  1.3266e+00,
          1.0952e+00,  1.3096e+00,  1.2014e+00,  1.3686e+00,  1.1981e+00,
          1.3292e+00,  1.4743e+00,  1.1678e+00,  1.4579e+00,  1.4858e+00,
          1.0153e+00,  9.3991e-01,  1.4894e+00,  1.3551e+00,  8.2822e-01,
          3.6028e+00,  2.6380e+00,  3.7056e+00,  2.9340e+00,  2.2333e+00,
          1.9358e+00,  3.0348e+00,  3.5376e+00,  1.9206e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 357 : 180.27214322008138
Test loss for epoch 357 : 180.73944349334698
Test Precision for epoch 357 : 0.26153846153846155
Test Recall for epoch 357 : 0.26153846153846155
Test F1 for epoch 357 : 0.26153846153846155


theta for epoch 358 : tensor([[ 2.7531e+00,  2.7794e+00,  2.8461e+00,  2.9873e+00,  2.9547e+00,
          2.7573e+00,  2.9352e+00,  2.7509e+00,  2.7509e+00,  1.2737e+00,
          1.2985e+00,  1.2873e+00,  1.3273e+00,  1.2667e+00,  1.3725e+00,
          1.2788e+00,  1.2532e+00,  1.2838e+00,  1.2594e+00,  1.2375e+00,
          1.2541e+00,  1.2729e+00,  1.2314e+00,  1.2267e+00,  1.2464e+00,
          1.2194e+00,  1.2194e+00,  1.2674e+00,  1.3131e+00,  1.2389e+00,
          1.2655e+00,  1.3142e+00,  1.2501e+00,  1.2808e+00,  1.2002e+00,
          1.2414e+00,  1.3950e+00,  1.4438e+00,  1.4281e+00,  1.4069e+00,
          1.4172e+00,  1.3685e+00,  1.4096e+00,  1.2801e+00,  1.3498e+00,
          1.3270e+00,  1.2825e+00,  1.2694e+00,  1.2548e+00,  1.3253e+00,
          1.2762e+00,  1.3604e+00,  1.2419e+00,  1.2582e+00],
        [ 1.2315e+00,  1.2601e+00,  1.3004e+00,  1.2800e+00,  1.2661e+00,
          1.2366e+00,  1.2447e+00,  1.2293e+00,  1.2293e+00,  2.4858e+00,
          2.4974e+00,  2.4202e+00,  2.6556e+00,  2.4025e+00,  4.1144e+00,
          2.4785e+00,  2.5991e+00,  3.8974e+00,  1.2446e+00,  1.2700e+00,
          1.2402e+00,  1.2561e+00,  1.2589e+00,  1.2541e+00,  1.2720e+00,
          1.2466e+00,  1.2466e+00,  1.3004e+00,  1.2500e+00,  1.2667e+00,
          1.2941e+00,  1.2827e+00,  1.2783e+00,  1.3099e+00,  1.2321e+00,
          1.2693e+00,  1.4164e+00,  1.4671e+00,  1.3993e+00,  1.4265e+00,
          1.4395e+00,  1.4472e+00,  1.3802e+00,  1.2699e+00,  1.3680e+00,
          1.3061e+00,  1.3097e+00,  1.2960e+00,  1.2810e+00,  1.2607e+00,
          1.3031e+00,  1.2979e+00,  1.2678e+00,  1.2846e+00],
        [ 1.2077e+00,  1.2353e+00,  1.2727e+00,  1.2697e+00,  1.2403e+00,
          1.2123e+00,  1.2207e+00,  1.2053e+00,  1.2053e+00,  1.2768e+00,
          1.3017e+00,  1.2904e+00,  1.3306e+00,  1.2698e+00,  1.3252e+00,
          1.2819e+00,  1.2056e+00,  1.3298e+00,  2.7806e+00,  3.0198e+00,
          2.9936e+00,  2.7953e+00,  2.7462e+00,  2.7422e+00,  2.9785e+00,
          2.7355e+00,  2.7355e+00,  1.2521e+00,  1.3128e+00,  1.2422e+00,
          1.2658e+00,  1.2529e+00,  1.2535e+00,  1.2843e+00,  1.2494e+00,
          1.2448e+00,  1.3981e+00,  1.4471e+00,  1.4276e+00,  1.3326e+00,
          1.4166e+00,  1.4000e+00,  1.4128e+00,  1.2822e+00,  1.2720e+00,
          1.3275e+00,  1.2862e+00,  1.2731e+00,  1.2585e+00,  1.3250e+00,
          1.2799e+00,  1.3603e+00,  1.2227e+00,  1.2619e+00],
        [ 1.2150e+00,  1.2428e+00,  1.2801e+00,  1.2777e+00,  1.2480e+00,
          1.2197e+00,  1.2283e+00,  1.2127e+00,  1.2127e+00,  1.2840e+00,
          1.3089e+00,  1.2976e+00,  1.3328e+00,  1.2769e+00,  1.3203e+00,
          1.2890e+00,  1.2627e+00,  1.2788e+00,  1.2698e+00,  1.2686e+00,
          1.3098e+00,  1.2834e+00,  1.2416e+00,  1.2369e+00,  1.2366e+00,
          1.2296e+00,  1.2296e+00,  3.0578e+00,  2.9982e+00,  2.6677e+00,
          2.7754e+00,  3.0559e+00,  2.6777e+00,  2.9639e+00,  2.6840e+00,
          2.6699e+00,  1.4039e+00,  1.4531e+00,  1.4315e+00,  1.3914e+00,
          1.4262e+00,  1.4091e+00,  1.4129e+00,  1.2755e+00,  1.3337e+00,
          1.3376e+00,  1.2928e+00,  1.2221e+00,  1.2174e+00,  1.3359e+00,
          1.2865e+00,  1.3713e+00,  1.1849e+00,  1.2683e+00],
        [ 1.8601e+00,  1.4445e+00,  6.1958e-01,  9.1991e-01,  1.3369e+00,
          1.7863e+00,  1.6522e+00,  1.8984e+00,  1.8984e+00,  1.6970e+00,
          1.3177e+00,  1.5310e+00,  9.2917e-01,  1.7499e+00,  1.4668e-01,
          1.6312e+00,  1.9359e+00,  8.3966e-01,  1.3495e+00,  1.0230e+00,
          7.6943e-01,  1.1578e+00,  1.7285e+00,  1.7986e+00,  1.5684e+00,
          1.9118e+00,  1.9118e+00,  8.7200e-01,  8.5374e-01,  1.8857e+00,
          1.6576e+00,  8.7924e-01,  1.8179e+00,  1.2578e+00,  1.9376e+00,
          1.8474e+00,  2.3309e-01,  1.8036e-02, -7.8696e-03,  1.8505e-01,
          3.9842e-01,  4.6465e-01,  1.2796e-01,  1.9174e+01,  2.2370e+00,
          8.0017e-01,  1.4311e+00,  1.5150e+00,  1.7721e+00,  1.0153e+00,
          1.6851e+00,  3.8281e-01,  1.9137e+00,  1.9419e+00],
        [ 1.2926e+00,  1.3208e+00,  1.3777e+00,  1.3566e+00,  1.3266e+00,
          1.2974e+00,  1.2610e+00,  1.2902e+00,  1.2902e+00,  1.2661e+00,
          1.3853e+00,  1.2798e+00,  1.4149e+00,  1.3529e+00,  1.4602e+00,
          1.2712e+00,  1.3388e+00,  1.3238e+00,  1.3482e+00,  1.3309e+00,
          1.3897e+00,  1.3620e+00,  1.3195e+00,  1.3148e+00,  1.2040e+00,
          1.3073e+00,  1.3073e+00,  1.3543e+00,  1.4008e+00,  1.3257e+00,
          1.0940e+00,  1.3087e+00,  1.2003e+00,  1.3678e+00,  1.1971e+00,
          1.3283e+00,  1.4733e+00,  1.1665e+00,  1.4568e+00,  1.4849e+00,
          1.0138e+00,  9.3836e-01,  1.4884e+00,  1.3538e+00,  8.2719e-01,
          3.6089e+00,  2.6416e+00,  3.7091e+00,  2.9375e+00,  2.2371e+00,
          1.9396e+00,  3.0382e+00,  3.5439e+00,  1.9244e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 358 : 180.26185557100362
Test loss for epoch 358 : 180.73154488285599
Test Precision for epoch 358 : 0.26153846153846155
Test Recall for epoch 358 : 0.26153846153846155
Test F1 for epoch 358 : 0.26153846153846155


theta for epoch 359 : tensor([[ 2.7615e+00,  2.7878e+00,  2.8545e+00,  2.9958e+00,  2.9631e+00,
          2.7658e+00,  2.9437e+00,  2.7594e+00,  2.7594e+00,  1.2694e+00,
          1.2942e+00,  1.2829e+00,  1.3230e+00,  1.2624e+00,  1.3684e+00,
          1.2745e+00,  1.2487e+00,  1.2796e+00,  1.2539e+00,  1.2320e+00,
          1.2487e+00,  1.2675e+00,  1.2259e+00,  1.2213e+00,  1.2409e+00,
          1.2140e+00,  1.2140e+00,  1.2631e+00,  1.3090e+00,  1.2345e+00,
          1.2613e+00,  1.3100e+00,  1.2458e+00,  1.2766e+00,  1.1958e+00,
          1.2371e+00,  1.3927e+00,  1.4415e+00,  1.4258e+00,  1.4046e+00,
          1.4149e+00,  1.3661e+00,  1.4073e+00,  1.2773e+00,  1.3480e+00,
          1.3226e+00,  1.2781e+00,  1.2650e+00,  1.2504e+00,  1.3210e+00,
          1.2718e+00,  1.3561e+00,  1.2374e+00,  1.2538e+00],
        [ 1.2360e+00,  1.2644e+00,  1.3057e+00,  1.2855e+00,  1.2705e+00,
          1.2410e+00,  1.2492e+00,  1.2337e+00,  1.2337e+00,  2.4905e+00,
          2.5030e+00,  2.4267e+00,  2.6641e+00,  2.4084e+00,  4.0923e+00,
          2.4839e+00,  2.6085e+00,  3.8762e+00,  1.2427e+00,  1.2681e+00,
          1.2384e+00,  1.2545e+00,  1.2568e+00,  1.2520e+00,  1.2700e+00,
          1.2444e+00,  1.2444e+00,  1.2997e+00,  1.2495e+00,  1.2657e+00,
          1.2932e+00,  1.2833e+00,  1.2774e+00,  1.3090e+00,  1.2313e+00,
          1.2684e+00,  1.4163e+00,  1.4669e+00,  1.3993e+00,  1.4265e+00,
          1.4393e+00,  1.4471e+00,  1.3802e+00,  1.2704e+00,  1.3685e+00,
          1.3048e+00,  1.3081e+00,  1.2945e+00,  1.2795e+00,  1.2595e+00,
          1.3016e+00,  1.2969e+00,  1.2662e+00,  1.2830e+00],
        [ 1.2132e+00,  1.2408e+00,  1.2780e+00,  1.2752e+00,  1.2458e+00,
          1.2179e+00,  1.2262e+00,  1.2108e+00,  1.2108e+00,  1.2774e+00,
          1.3022e+00,  1.2909e+00,  1.3310e+00,  1.2703e+00,  1.3257e+00,
          1.2824e+00,  1.2060e+00,  1.3303e+00,  2.7791e+00,  3.0197e+00,
          2.9922e+00,  2.7937e+00,  2.7445e+00,  2.7404e+00,  2.9783e+00,
          2.7338e+00,  2.7338e+00,  1.2523e+00,  1.3131e+00,  1.2426e+00,
          1.2662e+00,  1.2531e+00,  1.2539e+00,  1.2847e+00,  1.2498e+00,
          1.2451e+00,  1.3990e+00,  1.4480e+00,  1.4285e+00,  1.3333e+00,
          1.4175e+00,  1.4006e+00,  1.4137e+00,  1.2830e+00,  1.2733e+00,
          1.3273e+00,  1.2861e+00,  1.2729e+00,  1.2583e+00,  1.3248e+00,
          1.2797e+00,  1.3600e+00,  1.2224e+00,  1.2617e+00],
        [ 1.2191e+00,  1.2468e+00,  1.2838e+00,  1.2815e+00,  1.2521e+00,
          1.2238e+00,  1.2324e+00,  1.2168e+00,  1.2168e+00,  1.2835e+00,
          1.3084e+00,  1.2971e+00,  1.3321e+00,  1.2764e+00,  1.3203e+00,
          1.2885e+00,  1.2621e+00,  1.2788e+00,  1.2681e+00,  1.2666e+00,
          1.3081e+00,  1.2818e+00,  1.2399e+00,  1.2352e+00,  1.2348e+00,
          1.2279e+00,  1.2279e+00,  3.0585e+00,  2.9973e+00,  2.6691e+00,
          2.7745e+00,  3.0566e+00,  2.6790e+00,  2.9630e+00,  2.6856e+00,
          2.6713e+00,  1.4041e+00,  1.4533e+00,  1.4315e+00,  1.3914e+00,
          1.4265e+00,  1.4092e+00,  1.4129e+00,  1.2761e+00,  1.3344e+00,
          1.3366e+00,  1.2918e+00,  1.2217e+00,  1.2165e+00,  1.3349e+00,
          1.2855e+00,  1.3703e+00,  1.1837e+00,  1.2673e+00],
        [ 1.8647e+00,  1.4493e+00,  6.2346e-01,  9.2375e-01,  1.3417e+00,
          1.7910e+00,  1.6568e+00,  1.9030e+00,  1.9030e+00,  1.6963e+00,
          1.3173e+00,  1.5311e+00,  9.2950e-01,  1.7499e+00,  1.4702e-01,
          1.6305e+00,  1.9360e+00,  8.3949e-01,  1.3489e+00,  1.0227e+00,
          7.6899e-01,  1.1571e+00,  1.7278e+00,  1.7979e+00,  1.5680e+00,
          1.9111e+00,  1.9111e+00,  8.7232e-01,  8.5388e-01,  1.8858e+00,
          1.6575e+00,  8.7909e-01,  1.8180e+00,  1.2578e+00,  1.9378e+00,
          1.8475e+00,  2.3112e-01,  1.6285e-02, -9.6360e-03,  1.8303e-01,
          3.9626e-01,  4.6227e-01,  1.2610e-01,  1.9239e+01,  2.1998e+00,
          8.0008e-01,  1.4308e+00,  1.5143e+00,  1.7717e+00,  1.0150e+00,
          1.6847e+00,  3.8295e-01,  1.9137e+00,  1.9415e+00],
        [ 1.2977e+00,  1.3258e+00,  1.3827e+00,  1.3616e+00,  1.3317e+00,
          1.3024e+00,  1.2660e+00,  1.2952e+00,  1.2952e+00,  1.2663e+00,
          1.3854e+00,  1.2800e+00,  1.4149e+00,  1.3530e+00,  1.4604e+00,
          1.2714e+00,  1.3388e+00,  1.3241e+00,  1.3470e+00,  1.3296e+00,
          1.3885e+00,  1.3608e+00,  1.3183e+00,  1.3136e+00,  1.2028e+00,
          1.3061e+00,  1.3061e+00,  1.3545e+00,  1.4009e+00,  1.3258e+00,
          1.0942e+00,  1.3088e+00,  1.2005e+00,  1.3679e+00,  1.1972e+00,
          1.3284e+00,  1.4740e+00,  1.1674e+00,  1.4574e+00,  1.4857e+00,
          1.0146e+00,  9.3924e-01,  1.4891e+00,  1.3543e+00,  8.2860e-01,
          3.6103e+00,  2.6405e+00,  3.7078e+00,  2.9362e+00,  2.2361e+00,
          1.9386e+00,  3.0370e+00,  3.5453e+00,  1.9234e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 359 : 180.25224492743183
Test loss for epoch 359 : 180.72992051038665
Test Precision for epoch 359 : 0.26153846153846155
Test Recall for epoch 359 : 0.26153846153846155
Test F1 for epoch 359 : 0.26153846153846155


theta for epoch 360 : tensor([[ 2.7547e+00,  2.7810e+00,  2.8477e+00,  2.9891e+00,  2.9564e+00,
          2.7590e+00,  2.9369e+00,  2.7526e+00,  2.7526e+00,  1.2741e+00,
          1.2988e+00,  1.2875e+00,  1.3275e+00,  1.2670e+00,  1.3730e+00,
          1.2791e+00,  1.2533e+00,  1.2844e+00,  1.2606e+00,  1.2387e+00,
          1.2553e+00,  1.2741e+00,  1.2326e+00,  1.2280e+00,  1.2475e+00,
          1.2207e+00,  1.2207e+00,  1.2678e+00,  1.3136e+00,  1.2392e+00,
          1.2660e+00,  1.3146e+00,  1.2505e+00,  1.2813e+00,  1.2006e+00,
          1.2418e+00,  1.3954e+00,  1.4442e+00,  1.4286e+00,  1.4074e+00,
          1.4176e+00,  1.3690e+00,  1.4101e+00,  1.2800e+00,  1.3514e+00,
          1.3267e+00,  1.2822e+00,  1.2691e+00,  1.2546e+00,  1.3250e+00,
          1.2759e+00,  1.3601e+00,  1.2416e+00,  1.2579e+00],
        [ 1.2290e+00,  1.2576e+00,  1.3005e+00,  1.2796e+00,  1.2634e+00,
          1.2339e+00,  1.2423e+00,  1.2266e+00,  1.2266e+00,  2.4972e+00,
          2.5106e+00,  2.4353e+00,  2.6748e+00,  2.4166e+00,  4.0727e+00,
          2.4913e+00,  2.6199e+00,  3.8575e+00,  1.2444e+00,  1.2698e+00,
          1.2399e+00,  1.2564e+00,  1.2584e+00,  1.2536e+00,  1.2718e+00,
          1.2461e+00,  1.2461e+00,  1.2994e+00,  1.2493e+00,  1.2651e+00,
          1.2927e+00,  1.2841e+00,  1.2768e+00,  1.3085e+00,  1.2309e+00,
          1.2678e+00,  1.4154e+00,  1.4661e+00,  1.3987e+00,  1.4258e+00,
          1.4385e+00,  1.4464e+00,  1.3795e+00,  1.2703e+00,  1.3683e+00,
          1.3043e+00,  1.3075e+00,  1.2939e+00,  1.2788e+00,  1.2592e+00,
          1.3010e+00,  1.2965e+00,  1.2656e+00,  1.2824e+00],
        [ 1.2055e+00,  1.2331e+00,  1.2703e+00,  1.2676e+00,  1.2382e+00,
          1.2102e+00,  1.2186e+00,  1.2032e+00,  1.2032e+00,  1.2759e+00,
          1.3008e+00,  1.2894e+00,  1.3295e+00,  1.2688e+00,  1.3242e+00,
          1.2810e+00,  1.2041e+00,  1.3289e+00,  2.7845e+00,  3.0263e+00,
          2.9976e+00,  2.7989e+00,  2.7497e+00,  2.7455e+00,  2.9850e+00,
          2.7390e+00,  2.7390e+00,  1.2509e+00,  1.3119e+00,  1.2414e+00,
          1.2651e+00,  1.2517e+00,  1.2527e+00,  1.2836e+00,  1.2486e+00,
          1.2439e+00,  1.3978e+00,  1.4467e+00,  1.4272e+00,  1.3318e+00,
          1.4163e+00,  1.3992e+00,  1.4125e+00,  1.2815e+00,  1.2723e+00,
          1.3258e+00,  1.2845e+00,  1.2714e+00,  1.2568e+00,  1.3231e+00,
          1.2782e+00,  1.3583e+00,  1.2205e+00,  1.2601e+00],
        [ 1.2134e+00,  1.2411e+00,  1.2782e+00,  1.2761e+00,  1.2464e+00,
          1.2181e+00,  1.2267e+00,  1.2110e+00,  1.2110e+00,  1.2835e+00,
          1.3083e+00,  1.2969e+00,  1.3318e+00,  1.2762e+00,  1.3205e+00,
          1.2885e+00,  1.2619e+00,  1.2792e+00,  1.2702e+00,  1.2682e+00,
          1.3101e+00,  1.2838e+00,  1.2420e+00,  1.2373e+00,  1.2367e+00,
          1.2300e+00,  1.2300e+00,  3.0611e+00,  2.9985e+00,  2.6724e+00,
          2.7756e+00,  3.0592e+00,  2.6824e+00,  2.9640e+00,  2.6893e+00,
          2.6746e+00,  1.4037e+00,  1.4529e+00,  1.4309e+00,  1.3909e+00,
          1.4261e+00,  1.4086e+00,  1.4123e+00,  1.2761e+00,  1.3343e+00,
          1.3364e+00,  1.2916e+00,  1.2220e+00,  1.2163e+00,  1.3348e+00,
          1.2853e+00,  1.3701e+00,  1.1833e+00,  1.2671e+00],
        [ 1.8605e+00,  1.4453e+00,  6.2050e-01,  9.2027e-01,  1.3378e+00,
          1.7869e+00,  1.6527e+00,  1.8990e+00,  1.8990e+00,  1.6969e+00,
          1.3183e+00,  1.5325e+00,  9.3117e-01,  1.7511e+00,  1.4856e-01,
          1.6312e+00,  1.9375e+00,  8.4078e-01,  1.3522e+00,  1.0261e+00,
          7.7233e-01,  1.1603e+00,  1.7311e+00,  1.8011e+00,  1.5714e+00,
          1.9143e+00,  1.9143e+00,  8.7418e-01,  8.5560e-01,  1.8874e+00,
          1.6590e+00,  8.8053e-01,  1.8197e+00,  1.2595e+00,  1.9394e+00,
          1.8492e+00,  2.2897e-01,  1.4368e-02, -1.1558e-02,  1.8084e-01,
          3.9389e-01,  4.5970e-01,  1.2407e-01,  1.9304e+01,  2.1640e+00,
          8.0188e-01,  1.4324e+00,  1.5157e+00,  1.7733e+00,  1.0168e+00,
          1.6862e+00,  3.8488e-01,  1.9156e+00,  1.9430e+00],
        [ 1.2918e+00,  1.3199e+00,  1.3768e+00,  1.3557e+00,  1.3258e+00,
          1.2965e+00,  1.2601e+00,  1.2893e+00,  1.2893e+00,  1.2664e+00,
          1.3856e+00,  1.2800e+00,  1.4150e+00,  1.3530e+00,  1.4606e+00,
          1.2715e+00,  1.3388e+00,  1.3244e+00,  1.3491e+00,  1.3317e+00,
          1.3907e+00,  1.3630e+00,  1.3205e+00,  1.3158e+00,  1.2048e+00,
          1.3083e+00,  1.3083e+00,  1.3546e+00,  1.4011e+00,  1.3259e+00,
          1.0941e+00,  1.3089e+00,  1.2006e+00,  1.3681e+00,  1.1973e+00,
          1.3285e+00,  1.4737e+00,  1.1669e+00,  1.4571e+00,  1.4854e+00,
          1.0140e+00,  9.3860e-01,  1.4888e+00,  1.3538e+00,  8.2847e-01,
          3.6150e+00,  2.6428e+00,  3.7100e+00,  2.9383e+00,  2.2385e+00,
          1.9409e+00,  3.0390e+00,  3.5501e+00,  1.9257e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 360 : 180.24528978694744
Test loss for epoch 360 : 180.72588658232598
Test Precision for epoch 360 : 0.26153846153846155
Test Recall for epoch 360 : 0.26153846153846155
Test F1 for epoch 360 : 0.26153846153846155


theta for epoch 361 : tensor([[ 2.7663e+00,  2.7926e+00,  2.8593e+00,  3.0007e+00,  2.9681e+00,
          2.7706e+00,  2.9487e+00,  2.7642e+00,  2.7642e+00,  1.2681e+00,
          1.2929e+00,  1.2814e+00,  1.3215e+00,  1.2609e+00,  1.3672e+00,
          1.2732e+00,  1.2471e+00,  1.2785e+00,  1.2515e+00,  1.2295e+00,
          1.2462e+00,  1.2651e+00,  1.2235e+00,  1.2189e+00,  1.2385e+00,
          1.2116e+00,  1.2116e+00,  1.2616e+00,  1.3076e+00,  1.2330e+00,
          1.2599e+00,  1.3085e+00,  1.2443e+00,  1.2752e+00,  1.1942e+00,
          1.2356e+00,  1.3919e+00,  1.4408e+00,  1.4252e+00,  1.4040e+00,
          1.4142e+00,  1.3654e+00,  1.4066e+00,  1.2760e+00,  1.3485e+00,
          1.3220e+00,  1.2776e+00,  1.2645e+00,  1.2499e+00,  1.3204e+00,
          1.2712e+00,  1.3555e+00,  1.2369e+00,  1.2533e+00],
        [ 1.2356e+00,  1.2639e+00,  1.3076e+00,  1.2869e+00,  1.2698e+00,
          1.2404e+00,  1.2489e+00,  1.2331e+00,  1.2331e+00,  2.5016e+00,
          2.5157e+00,  2.4415e+00,  2.6830e+00,  2.4225e+00,  4.0512e+00,
          2.4964e+00,  2.6288e+00,  3.8370e+00,  1.2404e+00,  1.2658e+00,
          1.2361e+00,  1.2527e+00,  1.2541e+00,  1.2493e+00,  1.2677e+00,
          1.2418e+00,  1.2418e+00,  1.2986e+00,  1.2488e+00,  1.2641e+00,
          1.2917e+00,  1.2845e+00,  1.2757e+00,  1.3075e+00,  1.2300e+00,
          1.2667e+00,  1.4153e+00,  1.4660e+00,  1.3987e+00,  1.4257e+00,
          1.4384e+00,  1.4463e+00,  1.3796e+00,  1.2709e+00,  1.3689e+00,
          1.3042e+00,  1.3074e+00,  1.2938e+00,  1.2787e+00,  1.2593e+00,
          1.3008e+00,  1.2966e+00,  1.2654e+00,  1.2821e+00],
        [ 1.2144e+00,  1.2420e+00,  1.2788e+00,  1.2763e+00,  1.2470e+00,
          1.2191e+00,  1.2274e+00,  1.2121e+00,  1.2121e+00,  1.2779e+00,
          1.3026e+00,  1.2912e+00,  1.3313e+00,  1.2706e+00,  1.3259e+00,
          1.2829e+00,  1.2059e+00,  1.3308e+00,  2.7801e+00,  3.0233e+00,
          2.9934e+00,  2.7946e+00,  2.7451e+00,  2.7409e+00,  2.9820e+00,
          2.7344e+00,  2.7344e+00,  1.2522e+00,  1.3131e+00,  1.2427e+00,
          1.2664e+00,  1.2530e+00,  1.2540e+00,  1.2849e+00,  1.2499e+00,
          1.2453e+00,  1.3995e+00,  1.4485e+00,  1.4290e+00,  1.3334e+00,
          1.4180e+00,  1.4008e+00,  1.4142e+00,  1.2831e+00,  1.2745e+00,
          1.3283e+00,  1.2870e+00,  1.2739e+00,  1.2593e+00,  1.3255e+00,
          1.2806e+00,  1.3606e+00,  1.2229e+00,  1.2626e+00],
        [ 1.2193e+00,  1.2470e+00,  1.2836e+00,  1.2816e+00,  1.2522e+00,
          1.2240e+00,  1.2326e+00,  1.2169e+00,  1.2169e+00,  1.2830e+00,
          1.3079e+00,  1.2964e+00,  1.3311e+00,  1.2757e+00,  1.3205e+00,
          1.2880e+00,  1.2613e+00,  1.2792e+00,  1.2664e+00,  1.2642e+00,
          1.3064e+00,  1.2801e+00,  1.2383e+00,  1.2336e+00,  1.2328e+00,
          1.2262e+00,  1.2262e+00,  3.0615e+00,  2.9974e+00,  2.6735e+00,
          2.7745e+00,  3.0597e+00,  2.6835e+00,  2.9629e+00,  2.6907e+00,
          2.6757e+00,  1.4040e+00,  1.4532e+00,  1.4310e+00,  1.3910e+00,
          1.4264e+00,  1.4088e+00,  1.4124e+00,  1.2767e+00,  1.3351e+00,
          1.3366e+00,  1.2918e+00,  1.2226e+00,  1.2165e+00,  1.3349e+00,
          1.2854e+00,  1.3703e+00,  1.1834e+00,  1.2673e+00],
        [ 1.8669e+00,  1.4520e+00,  6.2610e-01,  9.2588e-01,  1.3445e+00,
          1.7934e+00,  1.6591e+00,  1.9054e+00,  1.9054e+00,  1.6962e+00,
          1.3181e+00,  1.5326e+00,  9.3165e-01,  1.7511e+00,  1.4927e-01,
          1.6307e+00,  1.9376e+00,  8.4089e-01,  1.3500e+00,  1.0244e+00,
          7.7054e-01,  1.1581e+00,  1.7288e+00,  1.7988e+00,  1.5693e+00,
          1.9120e+00,  1.9120e+00,  8.7456e-01,  8.5584e-01,  1.8874e+00,
          1.6589e+00,  8.8050e-01,  1.8197e+00,  1.2594e+00,  1.9394e+00,
          1.8492e+00,  2.2668e-01,  1.2326e-02, -1.3608e-02,  1.7853e-01,
          3.9139e-01,  4.5699e-01,  1.2191e-01,  1.9369e+01,  2.1297e+00,
          8.0303e-01,  1.4333e+00,  1.5162e+00,  1.7741e+00,  1.0178e+00,
          1.6870e+00,  3.8624e-01,  1.9167e+00,  1.9438e+00],
        [ 1.2978e+00,  1.3259e+00,  1.3827e+00,  1.3617e+00,  1.3318e+00,
          1.3026e+00,  1.2661e+00,  1.2954e+00,  1.2954e+00,  1.2655e+00,
          1.3847e+00,  1.2790e+00,  1.4140e+00,  1.3521e+00,  1.4598e+00,
          1.2707e+00,  1.3378e+00,  1.3236e+00,  1.3447e+00,  1.3271e+00,
          1.3862e+00,  1.3586e+00,  1.3161e+00,  1.3114e+00,  1.2003e+00,
          1.3039e+00,  1.3039e+00,  1.3536e+00,  1.4002e+00,  1.3249e+00,
          1.0931e+00,  1.3080e+00,  1.1996e+00,  1.3671e+00,  1.1963e+00,
          1.3275e+00,  1.4738e+00,  1.1670e+00,  1.4571e+00,  1.4856e+00,
          1.0140e+00,  9.3861e-01,  1.4889e+00,  1.3536e+00,  8.2902e-01,
          3.6181e+00,  2.6435e+00,  3.7105e+00,  2.9389e+00,  2.2393e+00,
          1.9417e+00,  3.0396e+00,  3.5534e+00,  1.9265e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 361 : 180.23914648887816
Test loss for epoch 361 : 180.7268599292688
Test Precision for epoch 361 : 0.26153846153846155
Test Recall for epoch 361 : 0.26153846153846155
Test F1 for epoch 361 : 0.26153846153846155


theta for epoch 362 : tensor([[ 2.7560e+00,  2.7823e+00,  2.8491e+00,  2.9905e+00,  2.9578e+00,
          2.7603e+00,  2.9384e+00,  2.7538e+00,  2.7538e+00,  1.2750e+00,
          1.2997e+00,  1.2882e+00,  1.3281e+00,  1.2677e+00,  1.3740e+00,
          1.2800e+00,  1.2539e+00,  1.2856e+00,  1.2624e+00,  1.2404e+00,
          1.2571e+00,  1.2759e+00,  1.2344e+00,  1.2298e+00,  1.2493e+00,
          1.2225e+00,  1.2225e+00,  1.2687e+00,  1.3146e+00,  1.2401e+00,
          1.2670e+00,  1.3154e+00,  1.2514e+00,  1.2823e+00,  1.2014e+00,
          1.2427e+00,  1.3961e+00,  1.4449e+00,  1.4293e+00,  1.4081e+00,
          1.4183e+00,  1.3697e+00,  1.4107e+00,  1.2801e+00,  1.3533e+00,
          1.3269e+00,  1.2825e+00,  1.2694e+00,  1.2548e+00,  1.3252e+00,
          1.2761e+00,  1.3602e+00,  1.2418e+00,  1.2581e+00],
        [ 1.2259e+00,  1.2545e+00,  1.2998e+00,  1.2783e+00,  1.2602e+00,
          1.2306e+00,  1.2394e+00,  1.2234e+00,  1.2234e+00,  2.5087e+00,
          2.5237e+00,  2.4506e+00,  2.6941e+00,  2.4312e+00,  4.0327e+00,
          2.5042e+00,  2.6406e+00,  3.8196e+00,  1.2443e+00,  1.2697e+00,
          1.2396e+00,  1.2568e+00,  1.2581e+00,  1.2533e+00,  1.2718e+00,
          1.2457e+00,  1.2457e+00,  1.2984e+00,  1.2488e+00,  1.2637e+00,
          1.2914e+00,  1.2854e+00,  1.2754e+00,  1.3072e+00,  1.2298e+00,
          1.2664e+00,  1.4145e+00,  1.4651e+00,  1.3981e+00,  1.4250e+00,
          1.4375e+00,  1.4455e+00,  1.3789e+00,  1.2709e+00,  1.3686e+00,
          1.3026e+00,  1.3056e+00,  1.2920e+00,  1.2769e+00,  1.2579e+00,
          1.2990e+00,  1.2953e+00,  1.2636e+00,  1.2804e+00],
        [ 1.2028e+00,  1.2304e+00,  1.2671e+00,  1.2648e+00,  1.2355e+00,
          1.2075e+00,  1.2159e+00,  1.2004e+00,  1.2004e+00,  1.2749e+00,
          1.2996e+00,  1.2881e+00,  1.3282e+00,  1.2676e+00,  1.3230e+00,
          1.2799e+00,  1.2025e+00,  1.3278e+00,  2.7891e+00,  3.0336e+00,
          3.0024e+00,  2.8035e+00,  2.7539e+00,  2.7497e+00,  2.9923e+00,
          2.7432e+00,  2.7432e+00,  1.2497e+00,  1.3108e+00,  1.2405e+00,
          1.2642e+00,  1.2504e+00,  1.2518e+00,  1.2828e+00,  1.2476e+00,
          1.2430e+00,  1.3972e+00,  1.4463e+00,  1.4268e+00,  1.3308e+00,
          1.4157e+00,  1.3983e+00,  1.4120e+00,  1.2805e+00,  1.2724e+00,
          1.3240e+00,  1.2827e+00,  1.2696e+00,  1.2549e+00,  1.3210e+00,
          1.2763e+00,  1.3562e+00,  1.2183e+00,  1.2582e+00],
        [ 1.2112e+00,  1.2389e+00,  1.2758e+00,  1.2740e+00,  1.2443e+00,
          1.2159e+00,  1.2245e+00,  1.2088e+00,  1.2088e+00,  1.2830e+00,
          1.3079e+00,  1.2963e+00,  1.3308e+00,  1.2757e+00,  1.3207e+00,
          1.2880e+00,  1.2612e+00,  1.2795e+00,  1.2706e+00,  1.2680e+00,
          1.3106e+00,  1.2843e+00,  1.2425e+00,  1.2378e+00,  1.2369e+00,
          1.2305e+00,  1.2305e+00,  3.0649e+00,  2.9992e+00,  2.6776e+00,
          2.7764e+00,  3.0630e+00,  2.6876e+00,  2.9646e+00,  2.6952e+00,
          2.6798e+00,  1.4035e+00,  1.4528e+00,  1.4303e+00,  1.3904e+00,
          1.4259e+00,  1.4082e+00,  1.4117e+00,  1.2764e+00,  1.3350e+00,
          1.3354e+00,  1.2907e+00,  1.2218e+00,  1.2153e+00,  1.3338e+00,
          1.2843e+00,  1.3691e+00,  1.1820e+00,  1.2661e+00],
        [ 1.8606e+00,  1.4457e+00,  6.2124e-01,  9.2043e-01,  1.3383e+00,
          1.7872e+00,  1.6528e+00,  1.8992e+00,  1.8992e+00,  1.6971e+00,
          1.3193e+00,  1.5341e+00,  9.3336e-01,  1.7525e+00,  1.5083e-01,
          1.6317e+00,  1.9392e+00,  8.4231e-01,  1.3551e+00,  1.0294e+00,
          7.7540e-01,  1.1630e+00,  1.7339e+00,  1.8039e+00,  1.5744e+00,
          1.9171e+00,  1.9171e+00,  8.7657e-01,  8.5774e-01,  1.8894e+00,
          1.6607e+00,  8.8216e-01,  1.8217e+00,  1.2614e+00,  1.9413e+00,
          1.8511e+00,  2.2469e-01,  1.0581e-02, -1.5362e-02,  1.7653e-01,
          3.8919e-01,  4.5459e-01,  1.2004e-01,  1.9433e+01,  2.0973e+00,
          8.0383e-01,  1.4340e+00,  1.5166e+00,  1.7747e+00,  1.0185e+00,
          1.6876e+00,  3.8719e-01,  1.9177e+00,  1.9444e+00],
        [ 1.2903e+00,  1.3184e+00,  1.3752e+00,  1.3542e+00,  1.3243e+00,
          1.2950e+00,  1.2587e+00,  1.2878e+00,  1.2878e+00,  1.2668e+00,
          1.3859e+00,  1.2802e+00,  1.4151e+00,  1.3533e+00,  1.4611e+00,
          1.2719e+00,  1.3389e+00,  1.3250e+00,  1.3502e+00,  1.3325e+00,
          1.3918e+00,  1.3641e+00,  1.3216e+00,  1.3169e+00,  1.2056e+00,
          1.3094e+00,  1.3094e+00,  1.3550e+00,  1.4015e+00,  1.3263e+00,
          1.0944e+00,  1.3093e+00,  1.2009e+00,  1.3685e+00,  1.1976e+00,
          1.3289e+00,  1.4741e+00,  1.1673e+00,  1.4573e+00,  1.4859e+00,
          1.0141e+00,  9.3881e-01,  1.4893e+00,  1.3536e+00,  8.2970e-01,
          3.6215e+00,  2.6444e+00,  3.7114e+00,  2.9397e+00,  2.2403e+00,
          1.9427e+00,  3.0404e+00,  3.5569e+00,  1.9275e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 362 : 180.23771082478328
Test loss for epoch 362 : 180.72850895354156
Test Precision for epoch 362 : 0.26153846153846155
Test Recall for epoch 362 : 0.26153846153846155
Test F1 for epoch 362 : 0.26153846153846155


theta for epoch 363 : tensor([[ 2.7720e+00,  2.7983e+00,  2.8650e+00,  3.0065e+00,  2.9738e+00,
          2.7762e+00,  2.9545e+00,  2.7699e+00,  2.7699e+00,  1.2667e+00,
          1.2914e+00,  1.2798e+00,  1.3198e+00,  1.2593e+00,  1.3659e+00,
          1.2717e+00,  1.2454e+00,  1.2773e+00,  1.2486e+00,  1.2266e+00,
          1.2433e+00,  1.2623e+00,  1.2207e+00,  1.2161e+00,  1.2356e+00,
          1.2088e+00,  1.2088e+00,  1.2600e+00,  1.3060e+00,  1.2314e+00,
          1.2583e+00,  1.3069e+00,  1.2426e+00,  1.2737e+00,  1.1925e+00,
          1.2339e+00,  1.3911e+00,  1.4400e+00,  1.4244e+00,  1.4032e+00,
          1.4133e+00,  1.3646e+00,  1.4058e+00,  1.2744e+00,  1.3487e+00,
          1.3211e+00,  1.2767e+00,  1.2636e+00,  1.2490e+00,  1.3195e+00,
          1.2703e+00,  1.3546e+00,  1.2359e+00,  1.2523e+00],
        [ 1.2354e+00,  1.2637e+00,  1.3094e+00,  1.2884e+00,  1.2696e+00,
          1.2401e+00,  1.2490e+00,  1.2329e+00,  1.2329e+00,  2.5127e+00,
          2.5283e+00,  2.4565e+00,  2.7021e+00,  2.4368e+00,  4.0117e+00,
          2.5088e+00,  2.6489e+00,  3.7996e+00,  1.2377e+00,  1.2632e+00,
          1.2334e+00,  1.2505e+00,  1.2512e+00,  1.2463e+00,  1.2651e+00,
          1.2388e+00,  1.2388e+00,  1.2975e+00,  1.2482e+00,  1.2625e+00,
          1.2903e+00,  1.2856e+00,  1.2742e+00,  1.3061e+00,  1.2288e+00,
          1.2652e+00,  1.4144e+00,  1.4651e+00,  1.3983e+00,  1.4251e+00,
          1.4375e+00,  1.4455e+00,  1.3791e+00,  1.2716e+00,  1.3693e+00,
          1.3037e+00,  1.3067e+00,  1.2931e+00,  1.2780e+00,  1.2592e+00,
          1.3001e+00,  1.2963e+00,  1.2647e+00,  1.2814e+00],
        [ 1.2161e+00,  1.2436e+00,  1.2800e+00,  1.2779e+00,  1.2487e+00,
          1.2208e+00,  1.2291e+00,  1.2137e+00,  1.2137e+00,  1.2785e+00,
          1.3032e+00,  1.2917e+00,  1.3317e+00,  1.2711e+00,  1.3263e+00,
          1.2835e+00,  1.2060e+00,  1.3313e+00,  2.7813e+00,  3.0271e+00,
          2.9949e+00,  2.7957e+00,  2.7458e+00,  2.7416e+00,  2.9857e+00,
          2.7351e+00,  2.7351e+00,  1.2521e+00,  1.3132e+00,  1.2430e+00,
          1.2668e+00,  1.2529e+00,  1.2542e+00,  1.2853e+00,  1.2501e+00,
          1.2455e+00,  1.4001e+00,  1.4491e+00,  1.4296e+00,  1.3337e+00,
          1.4186e+00,  1.4011e+00,  1.4149e+00,  1.2832e+00,  1.2759e+00,
          1.3293e+00,  1.2881e+00,  1.2750e+00,  1.2603e+00,  1.3262e+00,
          1.2816e+00,  1.3614e+00,  1.2236e+00,  1.2636e+00],
        [ 1.2197e+00,  1.2474e+00,  1.2837e+00,  1.2819e+00,  1.2527e+00,
          1.2244e+00,  1.2330e+00,  1.2173e+00,  1.2173e+00,  1.2826e+00,
          1.3075e+00,  1.2959e+00,  1.3301e+00,  1.2752e+00,  1.3206e+00,
          1.2877e+00,  1.2607e+00,  1.2795e+00,  1.2644e+00,  1.2616e+00,
          1.3044e+00,  1.2781e+00,  1.2362e+00,  1.2316e+00,  1.2305e+00,
          1.2242e+00,  1.2242e+00,  3.0650e+00,  2.9978e+00,  2.6783e+00,
          2.7750e+00,  3.0632e+00,  2.6883e+00,  2.9632e+00,  2.6963e+00,
          2.6805e+00,  1.4040e+00,  1.4533e+00,  1.4306e+00,  1.3908e+00,
          1.4264e+00,  1.4086e+00,  1.4119e+00,  1.2771e+00,  1.3360e+00,
          1.3366e+00,  1.2919e+00,  1.2234e+00,  1.2166e+00,  1.3350e+00,
          1.2854e+00,  1.3703e+00,  1.1832e+00,  1.2673e+00],
        [ 1.8694e+00,  1.4550e+00,  6.2906e-01,  9.2836e-01,  1.3475e+00,
          1.7961e+00,  1.6618e+00,  1.9080e+00,  1.9080e+00,  1.6965e+00,
          1.3191e+00,  1.5342e+00,  9.3388e-01,  1.7524e+00,  1.5178e-01,
          1.6312e+00,  1.9392e+00,  8.4257e-01,  1.3508e+00,  1.0258e+00,
          7.7181e-01,  1.1589e+00,  1.7294e+00,  1.7994e+00,  1.5703e+00,
          1.9126e+00,  1.9126e+00,  8.7685e-01,  8.5791e-01,  1.8891e+00,
          1.6604e+00,  8.8208e-01,  1.8214e+00,  1.2612e+00,  1.9410e+00,
          1.8509e+00,  2.2217e-01,  8.3302e-03, -1.7612e-02,  1.7402e-01,
          3.8643e-01,  4.5165e-01,  1.1766e-01,  1.9497e+01,  2.0659e+00,
          8.0597e-01,  1.4358e+00,  1.5182e+00,  1.7764e+00,  1.0205e+00,
          1.6894e+00,  3.8954e-01,  1.9196e+00,  1.9460e+00],
        [ 1.2982e+00,  1.3263e+00,  1.3830e+00,  1.3620e+00,  1.3322e+00,
          1.3029e+00,  1.2665e+00,  1.2957e+00,  1.2957e+00,  1.2651e+00,
          1.3841e+00,  1.2784e+00,  1.4133e+00,  1.3515e+00,  1.4594e+00,
          1.2702e+00,  1.3371e+00,  1.3233e+00,  1.3423e+00,  1.3244e+00,
          1.3837e+00,  1.3561e+00,  1.3137e+00,  1.3089e+00,  1.1977e+00,
          1.3014e+00,  1.3014e+00,  1.3529e+00,  1.3995e+00,  1.3242e+00,
          1.0923e+00,  1.3073e+00,  1.1989e+00,  1.3666e+00,  1.1955e+00,
          1.3268e+00,  1.4738e+00,  1.1668e+00,  1.4570e+00,  1.4857e+00,
          1.0135e+00,  9.3821e-01,  1.4890e+00,  1.3530e+00,  8.2962e-01,
          3.6261e+00,  2.6467e+00,  3.7135e+00,  2.9418e+00,  2.2426e+00,
          1.9449e+00,  3.0424e+00,  3.5616e+00,  1.9296e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 363 : 180.23496870807918
Test loss for epoch 363 : 180.73253872411834
Test Precision for epoch 363 : 0.26153846153846155
Test Recall for epoch 363 : 0.26153846153846155
Test F1 for epoch 363 : 0.26153846153846155


theta for epoch 364 : tensor([[ 2.7577e+00,  2.7840e+00,  2.8508e+00,  2.9924e+00,  2.9597e+00,
          2.7620e+00,  2.9403e+00,  2.7556e+00,  2.7556e+00,  1.2761e+00,
          1.3006e+00,  1.2891e+00,  1.3289e+00,  1.2686e+00,  1.3751e+00,
          1.2810e+00,  1.2547e+00,  1.2868e+00,  1.2642e+00,  1.2422e+00,
          1.2588e+00,  1.2777e+00,  1.2363e+00,  1.2317e+00,  1.2511e+00,
          1.2244e+00,  1.2244e+00,  1.2698e+00,  1.3156e+00,  1.2412e+00,
          1.2681e+00,  1.3164e+00,  1.2524e+00,  1.2834e+00,  1.2025e+00,
          1.2437e+00,  1.3969e+00,  1.4457e+00,  1.4301e+00,  1.4089e+00,
          1.4191e+00,  1.3706e+00,  1.4115e+00,  1.2802e+00,  1.3552e+00,
          1.3272e+00,  1.2828e+00,  1.2698e+00,  1.2551e+00,  1.3255e+00,
          1.2764e+00,  1.3605e+00,  1.2421e+00,  1.2584e+00],
        [ 1.2228e+00,  1.2513e+00,  1.2986e+00,  1.2767e+00,  1.2570e+00,
          1.2274e+00,  1.2364e+00,  1.2202e+00,  1.2202e+00,  2.5202e+00,
          2.5366e+00,  2.4660e+00,  2.7136e+00,  2.4461e+00,  3.9944e+00,
          2.5170e+00,  2.6610e+00,  3.7836e+00,  1.2440e+00,  1.2695e+00,
          1.2392e+00,  1.2571e+00,  1.2576e+00,  1.2528e+00,  1.2716e+00,
          1.2453e+00,  1.2453e+00,  1.2977e+00,  1.2485e+00,  1.2625e+00,
          1.2903e+00,  1.2867e+00,  1.2741e+00,  1.3061e+00,  1.2289e+00,
          1.2651e+00,  1.4136e+00,  1.4643e+00,  1.3976e+00,  1.4244e+00,
          1.4367e+00,  1.4447e+00,  1.3785e+00,  1.2717e+00,  1.3691e+00,
          1.3013e+00,  1.3042e+00,  1.2906e+00,  1.2754e+00,  1.2569e+00,
          1.2975e+00,  1.2942e+00,  1.2621e+00,  1.2789e+00],
        [ 1.2002e+00,  1.2277e+00,  1.2641e+00,  1.2621e+00,  1.2329e+00,
          1.2049e+00,  1.2133e+00,  1.1978e+00,  1.1978e+00,  1.2738e+00,
          1.2985e+00,  1.2869e+00,  1.3269e+00,  1.2663e+00,  1.3217e+00,
          1.2788e+00,  1.2007e+00,  1.3267e+00,  2.7942e+00,  3.0412e+00,
          3.0078e+00,  2.8085e+00,  2.7586e+00,  2.7543e+00,  2.9999e+00,
          2.7479e+00,  2.7479e+00,  1.2484e+00,  1.3097e+00,  1.2395e+00,
          1.2634e+00,  1.2492e+00,  1.2508e+00,  1.2819e+00,  1.2466e+00,
          1.2420e+00,  1.3968e+00,  1.4458e+00,  1.4263e+00,  1.3299e+00,
          1.4153e+00,  1.3976e+00,  1.4115e+00,  1.2795e+00,  1.2727e+00,
          1.3223e+00,  1.2811e+00,  1.2680e+00,  1.2533e+00,  1.3192e+00,
          1.2746e+00,  1.3543e+00,  1.2163e+00,  1.2565e+00],
        [ 1.2089e+00,  1.2366e+00,  1.2733e+00,  1.2718e+00,  1.2420e+00,
          1.2136e+00,  1.2222e+00,  1.2065e+00,  1.2065e+00,  1.2827e+00,
          1.3075e+00,  1.2958e+00,  1.3299e+00,  1.2752e+00,  1.3208e+00,
          1.2877e+00,  1.2606e+00,  1.2797e+00,  1.2709e+00,  1.2676e+00,
          1.3108e+00,  1.2846e+00,  1.2428e+00,  1.2381e+00,  1.2369e+00,
          1.2308e+00,  1.2308e+00,  3.0691e+00,  3.0004e+00,  2.6831e+00,
          2.7776e+00,  3.0673e+00,  2.6931e+00,  2.9657e+00,  2.7015e+00,
          2.6854e+00,  1.4035e+00,  1.4528e+00,  1.4299e+00,  1.3901e+00,
          1.4259e+00,  1.4080e+00,  1.4112e+00,  1.2767e+00,  1.3359e+00,
          1.3346e+00,  1.2899e+00,  1.2218e+00,  1.2146e+00,  1.3330e+00,
          1.2835e+00,  1.3683e+00,  1.1811e+00,  1.2653e+00],
        [ 1.8606e+00,  1.4460e+00,  6.2205e-01,  9.2068e-01,  1.3387e+00,
          1.7873e+00,  1.6528e+00,  1.8993e+00,  1.8993e+00,  1.6976e+00,
          1.3206e+00,  1.5359e+00,  9.3571e-01,  1.7541e+00,  1.5345e-01,
          1.6325e+00,  1.9410e+00,  8.4419e-01,  1.3578e+00,  1.0326e+00,
          7.7849e-01,  1.1657e+00,  1.7365e+00,  1.8065e+00,  1.5773e+00,
          1.9197e+00,  1.9197e+00,  8.7918e-01,  8.6012e-01,  1.8915e+00,
          1.6627e+00,  8.8409e-01,  1.8238e+00,  1.2636e+00,  1.9434e+00,
          1.8533e+00,  2.2030e-01,  6.7092e-03, -1.9243e-02,  1.7215e-01,
          3.8434e-01,  4.4938e-01,  1.1591e-01,  1.9561e+01,  2.0368e+00,
          8.0609e-01,  1.4358e+00,  1.5180e+00,  1.7763e+00,  1.0205e+00,
          1.6893e+00,  3.8981e-01,  1.9199e+00,  1.9460e+00],
        [ 1.2883e+00,  1.3164e+00,  1.3732e+00,  1.3522e+00,  1.3223e+00,
          1.2931e+00,  1.2568e+00,  1.2859e+00,  1.2859e+00,  1.2672e+00,
          1.3862e+00,  1.2804e+00,  1.4152e+00,  1.3535e+00,  1.4615e+00,
          1.2723e+00,  1.3390e+00,  1.3255e+00,  1.3509e+00,  1.3331e+00,
          1.3925e+00,  1.3649e+00,  1.3224e+00,  1.3177e+00,  1.2062e+00,
          1.3102e+00,  1.3102e+00,  1.3553e+00,  1.4019e+00,  1.3266e+00,
          1.0947e+00,  1.3096e+00,  1.2013e+00,  1.3690e+00,  1.1979e+00,
          1.3292e+00,  1.4746e+00,  1.1676e+00,  1.4577e+00,  1.4865e+00,
          1.0143e+00,  9.3903e-01,  1.4898e+00,  1.3535e+00,  8.3089e-01,
          3.6287e+00,  2.6468e+00,  3.7136e+00,  2.9418e+00,  2.2428e+00,
          1.9449e+00,  3.0425e+00,  3.5642e+00,  1.9297e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 364 : 180.23701583016066
Test loss for epoch 364 : 180.73732884118758
Test Precision for epoch 364 : 0.26153846153846155
Test Recall for epoch 364 : 0.26153846153846155
Test F1 for epoch 364 : 0.26153846153846155


theta for epoch 365 : tensor([[ 2.7772e+00,  2.8035e+00,  2.8702e+00,  3.0119e+00,  2.9792e+00,
          2.7815e+00,  2.9598e+00,  2.7751e+00,  2.7751e+00,  1.2658e+00,
          1.2903e+00,  1.2787e+00,  1.3186e+00,  1.2582e+00,  1.3650e+00,
          1.2707e+00,  1.2442e+00,  1.2765e+00,  1.2471e+00,  1.2250e+00,
          1.2417e+00,  1.2607e+00,  1.2193e+00,  1.2147e+00,  1.2341e+00,
          1.2074e+00,  1.2074e+00,  1.2588e+00,  1.3049e+00,  1.2302e+00,
          1.2572e+00,  1.3057e+00,  1.2415e+00,  1.2726e+00,  1.1913e+00,
          1.2328e+00,  1.3905e+00,  1.4395e+00,  1.4239e+00,  1.4027e+00,
          1.4128e+00,  1.3641e+00,  1.4053e+00,  1.2729e+00,  1.3492e+00,
          1.3202e+00,  1.2758e+00,  1.2627e+00,  1.2481e+00,  1.3186e+00,
          1.2694e+00,  1.3537e+00,  1.2350e+00,  1.2514e+00],
        [ 1.2346e+00,  1.2627e+00,  1.3101e+00,  1.2889e+00,  1.2687e+00,
          1.2393e+00,  1.2483e+00,  1.2320e+00,  1.2320e+00,  2.5239e+00,
          2.5409e+00,  2.4717e+00,  2.7212e+00,  2.4515e+00,  3.9740e+00,
          2.5212e+00,  2.6690e+00,  3.7643e+00,  1.2354e+00,  1.2610e+00,
          1.2313e+00,  1.2488e+00,  1.2487e+00,  1.2438e+00,  1.2629e+00,
          1.2363e+00,  1.2363e+00,  1.2966e+00,  1.2477e+00,  1.2612e+00,
          1.2890e+00,  1.2866e+00,  1.2728e+00,  1.3048e+00,  1.2278e+00,
          1.2638e+00,  1.4137e+00,  1.4644e+00,  1.3980e+00,  1.4246e+00,
          1.4368e+00,  1.4449e+00,  1.3788e+00,  1.2726e+00,  1.3698e+00,
          1.3031e+00,  1.3060e+00,  1.2925e+00,  1.2774e+00,  1.2590e+00,
          1.2994e+00,  1.2958e+00,  1.2640e+00,  1.2807e+00],
        [ 1.2171e+00,  1.2445e+00,  1.2805e+00,  1.2787e+00,  1.2495e+00,
          1.2217e+00,  1.2301e+00,  1.2147e+00,  1.2147e+00,  1.2790e+00,
          1.3036e+00,  1.2919e+00,  1.3319e+00,  1.2714e+00,  1.3265e+00,
          1.2839e+00,  1.2059e+00,  1.3317e+00,  2.7836e+00,  3.0318e+00,
          2.9974e+00,  2.7979e+00,  2.7476e+00,  2.7433e+00,  2.9904e+00,
          2.7369e+00,  2.7369e+00,  1.2520e+00,  1.3131e+00,  1.2430e+00,
          1.2669e+00,  1.2527e+00,  1.2543e+00,  1.2854e+00,  1.2501e+00,
          1.2456e+00,  1.4007e+00,  1.4497e+00,  1.4302e+00,  1.3340e+00,
          1.4192e+00,  1.4014e+00,  1.4154e+00,  1.2832e+00,  1.2773e+00,
          1.3300e+00,  1.2888e+00,  1.2757e+00,  1.2610e+00,  1.3266e+00,
          1.2823e+00,  1.3617e+00,  1.2240e+00,  1.2642e+00],
        [ 1.2196e+00,  1.2471e+00,  1.2831e+00,  1.2816e+00,  1.2525e+00,
          1.2242e+00,  1.2328e+00,  1.2172e+00,  1.2172e+00,  1.2824e+00,
          1.3072e+00,  1.2955e+00,  1.3293e+00,  1.2748e+00,  1.3208e+00,
          1.2874e+00,  1.2602e+00,  1.2797e+00,  1.2627e+00,  1.2594e+00,
          1.3027e+00,  1.2765e+00,  1.2346e+00,  1.2299e+00,  1.2287e+00,
          1.2226e+00,  1.2226e+00,  3.0690e+00,  2.9987e+00,  2.6836e+00,
          2.7759e+00,  3.0672e+00,  2.6936e+00,  2.9639e+00,  2.7023e+00,
          2.6858e+00,  1.4042e+00,  1.4534e+00,  1.4303e+00,  1.3907e+00,
          1.4266e+00,  1.4086e+00,  1.4116e+00,  1.2775e+00,  1.3371e+00,
          1.3366e+00,  1.2919e+00,  1.2241e+00,  1.2166e+00,  1.3349e+00,
          1.2854e+00,  1.3702e+00,  1.1830e+00,  1.2673e+00],
        [ 1.8714e+00,  1.4574e+00,  6.3169e-01,  9.3051e-01,  1.3500e+00,
          1.7982e+00,  1.6639e+00,  1.9101e+00,  1.9101e+00,  1.6971e+00,
          1.3205e+00,  1.5361e+00,  9.3630e-01,  1.7540e+00,  1.5463e-01,
          1.6321e+00,  1.9410e+00,  8.4459e-01,  1.3520e+00,  1.0276e+00,
          7.7350e-01,  1.1601e+00,  1.7304e+00,  1.8004e+00,  1.5716e+00,
          1.9135e+00,  1.9135e+00,  8.7934e-01,  8.6019e-01,  1.8910e+00,
          1.6621e+00,  8.8395e-01,  1.8233e+00,  1.2632e+00,  1.9428e+00,
          1.8528e+00,  2.1761e-01,  4.3060e-03, -2.1641e-02,  1.6948e-01,
          3.8140e-01,  4.4625e-01,  1.1337e-01,  1.9624e+01,  2.0085e+00,
          8.0891e-01,  1.4384e+00,  1.5203e+00,  1.7787e+00,  1.0233e+00,
          1.6917e+00,  3.9283e-01,  1.9225e+00,  1.9483e+00],
        [ 1.2978e+00,  1.3258e+00,  1.3825e+00,  1.3616e+00,  1.3317e+00,
          1.3025e+00,  1.2661e+00,  1.2953e+00,  1.2953e+00,  1.2649e+00,
          1.3839e+00,  1.2780e+00,  1.4128e+00,  1.3511e+00,  1.4593e+00,
          1.2699e+00,  1.3366e+00,  1.3232e+00,  1.3405e+00,  1.3225e+00,
          1.3819e+00,  1.3543e+00,  1.3119e+00,  1.3071e+00,  1.1957e+00,
          1.2997e+00,  1.2997e+00,  1.3525e+00,  1.3991e+00,  1.3238e+00,
          1.0918e+00,  1.3068e+00,  1.1984e+00,  1.3662e+00,  1.1950e+00,
          1.3264e+00,  1.4741e+00,  1.1668e+00,  1.4571e+00,  1.4859e+00,
          1.0134e+00,  9.3803e-01,  1.4892e+00,  1.3526e+00,  8.3039e-01,
          3.6343e+00,  2.6501e+00,  3.7168e+00,  2.9450e+00,  2.2460e+00,
          1.9481e+00,  3.0456e+00,  3.5700e+00,  1.9329e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 365 : 180.22830042243118
Test loss for epoch 365 : 180.73516438374713
Test Precision for epoch 365 : 0.26153846153846155
Test Recall for epoch 365 : 0.26153846153846155
Test F1 for epoch 365 : 0.26153846153846155


theta for epoch 366 : tensor([[ 2.7624e+00,  2.7887e+00,  2.8555e+00,  2.9972e+00,  2.9645e+00,
          2.7666e+00,  2.9451e+00,  2.7602e+00,  2.7602e+00,  1.2757e+00,
          1.3002e+00,  1.2885e+00,  1.3283e+00,  1.2681e+00,  1.3747e+00,
          1.2806e+00,  1.2541e+00,  1.2866e+00,  1.2642e+00,  1.2422e+00,
          1.2587e+00,  1.2778e+00,  1.2365e+00,  1.2319e+00,  1.2513e+00,
          1.2247e+00,  1.2247e+00,  1.2695e+00,  1.3153e+00,  1.2409e+00,
          1.2678e+00,  1.3160e+00,  1.2521e+00,  1.2831e+00,  1.2022e+00,
          1.2434e+00,  1.3967e+00,  1.4456e+00,  1.4300e+00,  1.4088e+00,
          1.4190e+00,  1.3705e+00,  1.4114e+00,  1.2791e+00,  1.3561e+00,
          1.3263e+00,  1.2819e+00,  1.2689e+00,  1.2542e+00,  1.3246e+00,
          1.2755e+00,  1.3596e+00,  1.2411e+00,  1.2574e+00],
        [ 1.2217e+00,  1.2501e+00,  1.2990e+00,  1.2769e+00,  1.2559e+00,
          1.2264e+00,  1.2356e+00,  1.2191e+00,  1.2191e+00,  2.5315e+00,
          2.5490e+00,  2.4813e+00,  2.7327e+00,  2.4609e+00,  3.9576e+00,
          2.5294e+00,  2.6809e+00,  3.7493e+00,  1.2430e+00,  1.2686e+00,
          1.2382e+00,  1.2565e+00,  1.2564e+00,  1.2516e+00,  1.2707e+00,
          1.2440e+00,  1.2440e+00,  1.2969e+00,  1.2482e+00,  1.2613e+00,
          1.2892e+00,  1.2876e+00,  1.2729e+00,  1.3050e+00,  1.2280e+00,
          1.2639e+00,  1.4128e+00,  1.4636e+00,  1.3973e+00,  1.4239e+00,
          1.4360e+00,  1.4441e+00,  1.3781e+00,  1.2726e+00,  1.3695e+00,
          1.3002e+00,  1.3029e+00,  1.2894e+00,  1.2742e+00,  1.2560e+00,
          1.2962e+00,  1.2932e+00,  1.2609e+00,  1.2776e+00],
        [ 1.2006e+00,  1.2280e+00,  1.2639e+00,  1.2623e+00,  1.2332e+00,
          1.2053e+00,  1.2136e+00,  1.1982e+00,  1.1982e+00,  1.2731e+00,
          1.2977e+00,  1.2860e+00,  1.3260e+00,  1.2654e+00,  1.3209e+00,
          1.2780e+00,  1.1995e+00,  1.3259e+00,  2.7984e+00,  3.0477e+00,
          3.0121e+00,  2.8125e+00,  2.7622e+00,  2.7578e+00,  3.0063e+00,
          2.7515e+00,  2.7515e+00,  1.2475e+00,  1.3089e+00,  1.2388e+00,
          1.2628e+00,  1.2482e+00,  1.2501e+00,  1.2814e+00,  1.2459e+00,
          1.2414e+00,  1.3966e+00,  1.4457e+00,  1.4262e+00,  1.3294e+00,
          1.4152e+00,  1.3972e+00,  1.4114e+00,  1.2787e+00,  1.2732e+00,
          1.3215e+00,  1.2803e+00,  1.2672e+00,  1.2525e+00,  1.3180e+00,
          1.2738e+00,  1.3532e+00,  1.2152e+00,  1.2557e+00],
        [ 1.2084e+00,  1.2361e+00,  1.2725e+00,  1.2712e+00,  1.2414e+00,
          1.2131e+00,  1.2217e+00,  1.2060e+00,  1.2060e+00,  1.2823e+00,
          1.3070e+00,  1.2952e+00,  1.3288e+00,  1.2746e+00,  1.3207e+00,
          1.2872e+00,  1.2599e+00,  1.2797e+00,  1.2702e+00,  1.2664e+00,
          1.3102e+00,  1.2840e+00,  1.2422e+00,  1.2375e+00,  1.2361e+00,
          1.2302e+00,  1.2302e+00,  3.0735e+00,  3.0018e+00,  2.6888e+00,
          2.7789e+00,  3.0717e+00,  2.6988e+00,  2.9669e+00,  2.7079e+00,
          2.6910e+00,  1.4035e+00,  1.4528e+00,  1.4294e+00,  1.3900e+00,
          1.4260e+00,  1.4078e+00,  1.4108e+00,  1.2769e+00,  1.3368e+00,
          1.3340e+00,  1.2894e+00,  1.2219e+00,  1.2140e+00,  1.3324e+00,
          1.2829e+00,  1.3677e+00,  1.1803e+00,  1.2647e+00],
        [ 1.8623e+00,  1.4482e+00,  6.2444e-01,  9.2261e-01,  1.3409e+00,
          1.7891e+00,  1.6547e+00,  1.9010e+00,  1.9010e+00,  1.6983e+00,
          1.3220e+00,  1.5378e+00,  9.3806e-01,  1.7557e+00,  1.5630e-01,
          1.6335e+00,  1.9427e+00,  8.4621e-01,  1.3600e+00,  1.0352e+00,
          7.8107e-01,  1.1680e+00,  1.7385e+00,  1.8084e+00,  1.5795e+00,
          1.9215e+00,  1.9215e+00,  8.8174e-01,  8.6249e-01,  1.8935e+00,
          1.6646e+00,  8.8609e-01,  1.8258e+00,  1.2657e+00,  1.9453e+00,
          1.8553e+00,  2.1569e-01,  2.6537e-03, -2.3303e-02,  1.6758e-01,
          3.7925e-01,  4.4394e-01,  1.1158e-01,  1.9687e+01,  1.9826e+00,
          8.0852e-01,  1.4378e+00,  1.5195e+00,  1.7781e+00,  1.0227e+00,
          1.6911e+00,  3.9264e-01,  1.9221e+00,  1.9477e+00],
        [ 1.2879e+00,  1.3159e+00,  1.3726e+00,  1.3517e+00,  1.3219e+00,
          1.2926e+00,  1.2563e+00,  1.2854e+00,  1.2854e+00,  1.2673e+00,
          1.3862e+00,  1.2803e+00,  1.4150e+00,  1.3534e+00,  1.4615e+00,
          1.2723e+00,  1.3389e+00,  1.3257e+00,  1.3508e+00,  1.3328e+00,
          1.3924e+00,  1.3648e+00,  1.3223e+00,  1.3175e+00,  1.2060e+00,
          1.3101e+00,  1.3101e+00,  1.3553e+00,  1.4019e+00,  1.3267e+00,
          1.0947e+00,  1.3096e+00,  1.2013e+00,  1.3691e+00,  1.1979e+00,
          1.3293e+00,  1.4751e+00,  1.1679e+00,  1.4580e+00,  1.4869e+00,
          1.0144e+00,  9.3915e-01,  1.4902e+00,  1.3532e+00,  8.3192e-01,
          3.6362e+00,  2.6497e+00,  3.7163e+00,  2.9444e+00,  2.2456e+00,
          1.9475e+00,  3.0451e+00,  3.5720e+00,  1.9322e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 366 : 180.2177616859419
Test loss for epoch 366 : 180.72741538227365
Test Precision for epoch 366 : 0.26153846153846155
Test Recall for epoch 366 : 0.26153846153846155
Test F1 for epoch 366 : 0.26153846153846155


theta for epoch 367 : tensor([[ 2.7795e+00,  2.8057e+00,  2.8725e+00,  3.0144e+00,  2.9816e+00,
          2.7837e+00,  2.9623e+00,  2.7773e+00,  2.7773e+00,  1.2668e+00,
          1.2913e+00,  1.2796e+00,  1.3194e+00,  1.2591e+00,  1.3661e+00,
          1.2717e+00,  1.2450e+00,  1.2777e+00,  1.2495e+00,  1.2274e+00,
          1.2440e+00,  1.2631e+00,  1.2219e+00,  1.2172e+00,  1.2366e+00,
          1.2100e+00,  1.2100e+00,  1.2598e+00,  1.3058e+00,  1.2312e+00,
          1.2583e+00,  1.3066e+00,  1.2425e+00,  1.2736e+00,  1.1923e+00,
          1.2338e+00,  1.3911e+00,  1.4401e+00,  1.4245e+00,  1.4032e+00,
          1.4134e+00,  1.3648e+00,  1.4058e+00,  1.2727e+00,  1.3508e+00,
          1.3207e+00,  1.2763e+00,  1.2632e+00,  1.2486e+00,  1.3190e+00,
          1.2698e+00,  1.3541e+00,  1.2354e+00,  1.2518e+00],
        [ 1.2323e+00,  1.2604e+00,  1.3092e+00,  1.2879e+00,  1.2665e+00,
          1.2370e+00,  1.2462e+00,  1.2298e+00,  1.2298e+00,  2.5356e+00,
          2.5537e+00,  2.4873e+00,  2.7408e+00,  2.4668e+00,  3.9385e+00,
          2.5340e+00,  2.6892e+00,  3.7314e+00,  1.2347e+00,  1.2605e+00,
          1.2306e+00,  1.2485e+00,  1.2478e+00,  1.2430e+00,  1.2623e+00,
          1.2354e+00,  1.2354e+00,  1.2957e+00,  1.2471e+00,  1.2597e+00,
          1.2877e+00,  1.2871e+00,  1.2714e+00,  1.3035e+00,  1.2267e+00,
          1.2624e+00,  1.4127e+00,  1.4634e+00,  1.3974e+00,  1.4238e+00,
          1.4358e+00,  1.4439e+00,  1.3782e+00,  1.2734e+00,  1.3699e+00,
          1.3021e+00,  1.3050e+00,  1.2915e+00,  1.2763e+00,  1.2582e+00,
          1.2983e+00,  1.2948e+00,  1.2629e+00,  1.2796e+00],
        [ 1.2161e+00,  1.2434e+00,  1.2789e+00,  1.2775e+00,  1.2484e+00,
          1.2207e+00,  1.2290e+00,  1.2137e+00,  1.2137e+00,  1.2780e+00,
          1.3025e+00,  1.2908e+00,  1.3307e+00,  1.2703e+00,  1.3254e+00,
          1.2829e+00,  1.2044e+00,  1.3306e+00,  2.7889e+00,  3.0394e+00,
          3.0029e+00,  2.8031e+00,  2.7523e+00,  2.7480e+00,  2.9979e+00,
          2.7416e+00,  2.7416e+00,  1.2507e+00,  1.3119e+00,  1.2420e+00,
          1.2660e+00,  1.2514e+00,  1.2533e+00,  1.2845e+00,  1.2490e+00,
          1.2445e+00,  1.4002e+00,  1.4492e+00,  1.4298e+00,  1.3331e+00,
          1.4187e+00,  1.4007e+00,  1.4149e+00,  1.2820e+00,  1.2774e+00,
          1.3291e+00,  1.2880e+00,  1.2749e+00,  1.2602e+00,  1.3255e+00,
          1.2815e+00,  1.3606e+00,  1.2230e+00,  1.2634e+00],
        [ 1.2182e+00,  1.2457e+00,  1.2815e+00,  1.2802e+00,  1.2510e+00,
          1.2228e+00,  1.2314e+00,  1.2157e+00,  1.2157e+00,  1.2820e+00,
          1.3067e+00,  1.2949e+00,  1.3283e+00,  1.2743e+00,  1.3206e+00,
          1.2869e+00,  1.2596e+00,  1.2797e+00,  1.2626e+00,  1.2587e+00,
          1.3026e+00,  1.2763e+00,  1.2345e+00,  1.2298e+00,  1.2283e+00,
          1.2224e+00,  1.2224e+00,  3.0738e+00,  3.0004e+00,  2.6896e+00,
          2.7776e+00,  3.0720e+00,  2.6996e+00,  2.9655e+00,  2.7091e+00,
          2.6918e+00,  1.4040e+00,  1.4533e+00,  1.4297e+00,  1.3904e+00,
          1.4265e+00,  1.4083e+00,  1.4110e+00,  1.2774e+00,  1.3378e+00,
          1.3362e+00,  1.2915e+00,  1.2244e+00,  1.2163e+00,  1.3345e+00,
          1.2850e+00,  1.3697e+00,  1.1825e+00,  1.2669e+00],
        [ 1.8724e+00,  1.4587e+00,  6.3345e-01,  9.3178e-01,  1.3514e+00,
          1.7992e+00,  1.6650e+00,  1.9110e+00,  1.9110e+00,  1.6980e+00,
          1.3221e+00,  1.5380e+00,  9.3872e-01,  1.7558e+00,  1.5759e-01,
          1.6333e+00,  1.9428e+00,  8.4674e-01,  1.3546e+00,  1.0306e+00,
          7.7649e-01,  1.1628e+00,  1.7328e+00,  1.8027e+00,  1.5743e+00,
          1.9158e+00,  1.9158e+00,  8.8184e-01,  8.6249e-01,  1.8929e+00,
          1.6640e+00,  8.8592e-01,  1.8253e+00,  1.2653e+00,  1.9447e+00,
          1.8547e+00,  2.1296e-01,  2.0798e-04, -2.5740e-02,  1.6488e-01,
          3.7625e-01,  4.4077e-01,  1.0899e-01,  1.9749e+01,  1.9575e+00,
          8.1159e-01,  1.4407e+00,  1.5222e+00,  1.7808e+00,  1.0258e+00,
          1.6939e+00,  3.9589e-01,  1.9250e+00,  1.9503e+00],
        [ 1.2960e+00,  1.3241e+00,  1.3807e+00,  1.3598e+00,  1.3300e+00,
          1.3008e+00,  1.2643e+00,  1.2935e+00,  1.2935e+00,  1.2646e+00,
          1.3835e+00,  1.2775e+00,  1.4123e+00,  1.3508e+00,  1.4590e+00,
          1.2696e+00,  1.3362e+00,  1.3230e+00,  1.3407e+00,  1.3225e+00,
          1.3821e+00,  1.3545e+00,  1.3121e+00,  1.3074e+00,  1.1958e+00,
          1.2999e+00,  1.2999e+00,  1.3520e+00,  1.3987e+00,  1.3234e+00,
          1.0913e+00,  1.3063e+00,  1.1980e+00,  1.3659e+00,  1.1946e+00,
          1.3261e+00,  1.4742e+00,  1.1666e+00,  1.4569e+00,  1.4860e+00,
          1.0130e+00,  9.3762e-01,  1.4893e+00,  1.3519e+00,  8.3086e-01,
          3.6428e+00,  2.6540e+00,  3.7206e+00,  2.9486e+00,  2.2497e+00,
          1.9515e+00,  3.0492e+00,  3.5788e+00,  1.9363e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 367 : 180.1946194772678
Test loss for epoch 367 : 180.70979459417055
Test Precision for epoch 367 : 0.26153846153846155
Test Recall for epoch 367 : 0.26153846153846155
Test F1 for epoch 367 : 0.26153846153846155


theta for epoch 368 : tensor([[ 2.7711e+00,  2.7974e+00,  2.8642e+00,  3.0061e+00,  2.9734e+00,
          2.7753e+00,  2.9540e+00,  2.7689e+00,  2.7689e+00,  1.2730e+00,
          1.2973e+00,  1.2856e+00,  1.3253e+00,  1.2652e+00,  1.3721e+00,
          1.2778e+00,  1.2511e+00,  1.2839e+00,  1.2616e+00,  1.2394e+00,
          1.2559e+00,  1.2751e+00,  1.2340e+00,  1.2294e+00,  1.2486e+00,
          1.2222e+00,  1.2222e+00,  1.2666e+00,  1.3125e+00,  1.2381e+00,
          1.2651e+00,  1.3132e+00,  1.2493e+00,  1.2804e+00,  1.1993e+00,
          1.2406e+00,  1.3949e+00,  1.4439e+00,  1.4283e+00,  1.4070e+00,
          1.4173e+00,  1.3688e+00,  1.4097e+00,  1.2764e+00,  1.3552e+00,
          1.3234e+00,  1.2790e+00,  1.2660e+00,  1.2513e+00,  1.3217e+00,
          1.2725e+00,  1.3568e+00,  1.2381e+00,  1.2545e+00],
        [ 1.2241e+00,  1.2523e+00,  1.3022e+00,  1.2803e+00,  1.2583e+00,
          1.2288e+00,  1.2381e+00,  1.2216e+00,  1.2216e+00,  2.5424e+00,
          2.5611e+00,  2.4962e+00,  2.7516e+00,  2.4755e+00,  3.9223e+00,
          2.5414e+00,  2.7003e+00,  3.7166e+00,  1.2407e+00,  1.2665e+00,
          1.2360e+00,  1.2546e+00,  1.2538e+00,  1.2490e+00,  1.2683e+00,
          1.2415e+00,  1.2415e+00,  1.2958e+00,  1.2474e+00,  1.2597e+00,
          1.2877e+00,  1.2879e+00,  1.2713e+00,  1.3035e+00,  1.2268e+00,
          1.2623e+00,  1.4119e+00,  1.4627e+00,  1.3968e+00,  1.4232e+00,
          1.4351e+00,  1.4432e+00,  1.3777e+00,  1.2735e+00,  1.3697e+00,
          1.2990e+00,  1.3017e+00,  1.2882e+00,  1.2731e+00,  1.2551e+00,
          1.2950e+00,  1.2921e+00,  1.2597e+00,  1.2764e+00],
        [ 1.2055e+00,  1.2327e+00,  1.2681e+00,  1.2668e+00,  1.2378e+00,
          1.2101e+00,  1.2184e+00,  1.2031e+00,  1.2031e+00,  1.2734e+00,
          1.2979e+00,  1.2861e+00,  1.3260e+00,  1.2655e+00,  1.3209e+00,
          1.2782e+00,  1.1992e+00,  1.3260e+00,  2.8003e+00,  3.0519e+00,
          3.0144e+00,  2.8145e+00,  2.7636e+00,  2.7592e+00,  3.0105e+00,
          2.7528e+00,  2.7528e+00,  1.2473e+00,  1.3086e+00,  1.2388e+00,
          1.2628e+00,  1.2480e+00,  1.2501e+00,  1.2814e+00,  1.2459e+00,
          1.2414e+00,  1.3971e+00,  1.4462e+00,  1.4267e+00,  1.3297e+00,
          1.4157e+00,  1.3975e+00,  1.4119e+00,  1.2785e+00,  1.2745e+00,
          1.3220e+00,  1.2809e+00,  1.2678e+00,  1.2531e+00,  1.3183e+00,
          1.2744e+00,  1.3534e+00,  1.2156e+00,  1.2563e+00],
        [ 1.2109e+00,  1.2385e+00,  1.2745e+00,  1.2734e+00,  1.2439e+00,
          1.2156e+00,  1.2242e+00,  1.2085e+00,  1.2085e+00,  1.2816e+00,
          1.3062e+00,  1.2943e+00,  1.3275e+00,  1.2738e+00,  1.3202e+00,
          1.2865e+00,  1.2590e+00,  1.2794e+00,  1.2684e+00,  1.2640e+00,
          1.3084e+00,  1.2821e+00,  1.2403e+00,  1.2356e+00,  1.2341e+00,
          1.2283e+00,  1.2283e+00,  3.0779e+00,  3.0031e+00,  2.6943e+00,
          2.7803e+00,  3.0761e+00,  2.7043e+00,  2.9681e+00,  2.7142e+00,
          2.6965e+00,  1.4034e+00,  1.4528e+00,  1.4289e+00,  1.3897e+00,
          1.4259e+00,  1.4076e+00,  1.4102e+00,  1.2767e+00,  1.3376e+00,
          1.3334e+00,  1.2888e+00,  1.2220e+00,  1.2135e+00,  1.3317e+00,
          1.2823e+00,  1.3670e+00,  1.1796e+00,  1.2641e+00],
        [ 1.8670e+00,  1.4531e+00,  6.2913e-01,  9.2702e-01,  1.3459e+00,
          1.7937e+00,  1.6595e+00,  1.9055e+00,  1.9055e+00,  1.6988e+00,
          1.3232e+00,  1.5393e+00,  9.3998e-01,  1.7569e+00,  1.5890e-01,
          1.6343e+00,  1.9440e+00,  8.4786e-01,  1.3609e+00,  1.0367e+00,
          7.8252e-01,  1.1690e+00,  1.7392e+00,  1.8091e+00,  1.5805e+00,
          1.9222e+00,  1.9222e+00,  8.8370e-01,  8.6425e-01,  1.8949e+00,
          1.6659e+00,  8.8755e-01,  1.8272e+00,  1.2672e+00,  1.9467e+00,
          1.8567e+00,  2.1097e-01, -1.5059e-03, -2.7464e-02,  1.6292e-01,
          3.7404e-01,  4.3840e-01,  1.0714e-01,  1.9812e+01,  1.9347e+00,
          8.1071e-01,  1.4396e+00,  1.5209e+00,  1.7797e+00,  1.0247e+00,
          1.6928e+00,  3.9524e-01,  1.9241e+00,  1.9492e+00],
        [ 1.2902e+00,  1.3183e+00,  1.3750e+00,  1.3541e+00,  1.3243e+00,
          1.2950e+00,  1.2587e+00,  1.2877e+00,  1.2877e+00,  1.2667e+00,
          1.3855e+00,  1.2795e+00,  1.4142e+00,  1.3527e+00,  1.4609e+00,
          1.2716e+00,  1.3381e+00,  1.3251e+00,  1.3492e+00,  1.3311e+00,
          1.3908e+00,  1.3632e+00,  1.3208e+00,  1.3160e+00,  1.2044e+00,
          1.3085e+00,  1.3085e+00,  1.3546e+00,  1.4012e+00,  1.3261e+00,
          1.0940e+00,  1.3088e+00,  1.2007e+00,  1.3685e+00,  1.1973e+00,
          1.3287e+00,  1.4752e+00,  1.1678e+00,  1.4579e+00,  1.4870e+00,
          1.0142e+00,  9.3891e-01,  1.4903e+00,  1.3526e+00,  8.3253e-01,
          3.6442e+00,  2.6529e+00,  3.7195e+00,  2.9476e+00,  2.2486e+00,
          1.9502e+00,  3.0482e+00,  3.5802e+00,  1.9350e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 368 : 180.17188968873657
Test loss for epoch 368 : 180.6911878658269
Test Precision for epoch 368 : 0.26153846153846155
Test Recall for epoch 368 : 0.26153846153846155
Test F1 for epoch 368 : 0.26153846153846155


theta for epoch 369 : tensor([[ 2.7794e+00,  2.8057e+00,  2.8726e+00,  3.0146e+00,  2.9818e+00,
          2.7837e+00,  2.9625e+00,  2.7773e+00,  2.7773e+00,  1.2693e+00,
          1.2937e+00,  1.2819e+00,  1.3216e+00,  1.2615e+00,  1.3685e+00,
          1.2741e+00,  1.2473e+00,  1.2803e+00,  1.2549e+00,  1.2327e+00,
          1.2493e+00,  1.2684e+00,  1.2273e+00,  1.2227e+00,  1.2420e+00,
          1.2155e+00,  1.2155e+00,  1.2624e+00,  1.3084e+00,  1.2339e+00,
          1.2610e+00,  1.3091e+00,  1.2451e+00,  1.2763e+00,  1.1950e+00,
          1.2364e+00,  1.3924e+00,  1.4415e+00,  1.4258e+00,  1.4045e+00,
          1.4148e+00,  1.3663e+00,  1.4072e+00,  1.2733e+00,  1.3531e+00,
          1.3221e+00,  1.2777e+00,  1.2647e+00,  1.2500e+00,  1.3204e+00,
          1.2712e+00,  1.3555e+00,  1.2368e+00,  1.2531e+00],
        [ 1.2283e+00,  1.2563e+00,  1.3064e+00,  1.2848e+00,  1.2625e+00,
          1.2330e+00,  1.2423e+00,  1.2258e+00,  1.2258e+00,  2.5477e+00,
          2.5668e+00,  2.5035e+00,  2.7607e+00,  2.4826e+00,  3.9050e+00,
          2.5471e+00,  2.7096e+00,  3.7008e+00,  1.2359e+00,  1.2619e+00,
          1.2316e+00,  1.2500e+00,  1.2489e+00,  1.2440e+00,  1.2635e+00,
          1.2365e+00,  1.2365e+00,  1.2948e+00,  1.2465e+00,  1.2584e+00,
          1.2864e+00,  1.2875e+00,  1.2700e+00,  1.3022e+00,  1.2257e+00,
          1.2610e+00,  1.4113e+00,  1.4621e+00,  1.3965e+00,  1.4227e+00,
          1.4345e+00,  1.4427e+00,  1.3773e+00,  1.2738e+00,  1.3696e+00,
          1.3005e+00,  1.3034e+00,  1.2899e+00,  1.2748e+00,  1.2569e+00,
          1.2967e+00,  1.2934e+00,  1.2614e+00,  1.2780e+00],
        [ 1.2127e+00,  1.2398e+00,  1.2750e+00,  1.2738e+00,  1.2449e+00,
          1.2173e+00,  1.2255e+00,  1.2103e+00,  1.2103e+00,  1.2758e+00,
          1.3003e+00,  1.2884e+00,  1.3284e+00,  1.2679e+00,  1.3231e+00,
          1.2806e+00,  1.2016e+00,  1.3283e+00,  2.7967e+00,  3.0494e+00,
          3.0110e+00,  2.8109e+00,  2.7596e+00,  2.7552e+00,  3.0080e+00,
          2.7489e+00,  2.7489e+00,  1.2487e+00,  1.3099e+00,  1.2402e+00,
          1.2643e+00,  1.2494e+00,  1.2515e+00,  1.2829e+00,  1.2472e+00,
          1.2428e+00,  1.3987e+00,  1.4478e+00,  1.4283e+00,  1.3312e+00,
          1.4173e+00,  1.3990e+00,  1.4135e+00,  1.2798e+00,  1.2765e+00,
          1.3269e+00,  1.2858e+00,  1.2728e+00,  1.2581e+00,  1.3230e+00,
          1.2793e+00,  1.3581e+00,  1.2206e+00,  1.2612e+00],
        [ 1.2151e+00,  1.2426e+00,  1.2783e+00,  1.2772e+00,  1.2480e+00,
          1.2197e+00,  1.2284e+00,  1.2127e+00,  1.2127e+00,  1.2813e+00,
          1.3059e+00,  1.2940e+00,  1.3270e+00,  1.2735e+00,  1.3201e+00,
          1.2862e+00,  1.2587e+00,  1.2793e+00,  1.2641e+00,  1.2597e+00,
          1.3042e+00,  1.2779e+00,  1.2360e+00,  1.2314e+00,  1.2298e+00,
          1.2240e+00,  1.2240e+00,  3.0795e+00,  3.0031e+00,  2.6964e+00,
          2.7803e+00,  3.0777e+00,  2.7064e+00,  2.9680e+00,  2.7167e+00,
          2.6986e+00,  1.4034e+00,  1.4528e+00,  1.4286e+00,  1.3896e+00,
          1.4259e+00,  1.4076e+00,  1.4099e+00,  1.2766e+00,  1.3380e+00,
          1.3352e+00,  1.2907e+00,  1.2240e+00,  1.2154e+00,  1.3336e+00,
          1.2841e+00,  1.3688e+00,  1.1815e+00,  1.2660e+00],
        [ 1.8721e+00,  1.4585e+00,  6.3408e-01,  9.3188e-01,  1.3513e+00,
          1.7988e+00,  1.6647e+00,  1.9105e+00,  1.9105e+00,  1.6992e+00,
          1.3239e+00,  1.5401e+00,  9.4118e-01,  1.7576e+00,  1.6067e-01,
          1.6348e+00,  1.9447e+00,  8.4899e-01,  1.3588e+00,  1.0350e+00,
          7.8099e-01,  1.1671e+00,  1.7368e+00,  1.8067e+00,  1.5785e+00,
          1.9197e+00,  1.9197e+00,  8.8453e-01,  8.6500e-01,  1.8951e+00,
          1.6661e+00,  8.8817e-01,  1.8275e+00,  1.2676e+00,  1.9469e+00,
          1.8569e+00,  2.0816e-01, -4.0230e-03, -2.9971e-02,  1.6014e-01,
          3.7096e-01,  4.3516e-01,  1.0448e-01,  1.9873e+01,  1.9126e+00,
          8.1400e-01,  1.4427e+00,  1.5239e+00,  1.7827e+00,  1.0280e+00,
          1.6957e+00,  3.9871e-01,  1.9272e+00,  1.9521e+00],
        [ 1.2926e+00,  1.3207e+00,  1.3774e+00,  1.3565e+00,  1.3267e+00,
          1.2974e+00,  1.2610e+00,  1.2901e+00,  1.2901e+00,  1.2643e+00,
          1.3832e+00,  1.2771e+00,  1.4118e+00,  1.3503e+00,  1.4587e+00,
          1.2692e+00,  1.3357e+00,  1.3228e+00,  1.3430e+00,  1.3247e+00,
          1.3845e+00,  1.3569e+00,  1.3145e+00,  1.3098e+00,  1.1980e+00,
          1.3023e+00,  1.3023e+00,  1.3518e+00,  1.3985e+00,  1.3233e+00,
          1.0910e+00,  1.3060e+00,  1.1978e+00,  1.3658e+00,  1.1944e+00,
          1.3259e+00,  1.4739e+00,  1.1660e+00,  1.4565e+00,  1.4857e+00,
          1.0123e+00,  9.3692e-01,  1.4891e+00,  1.3509e+00,  8.3094e-01,
          3.6516e+00,  2.6581e+00,  3.7248e+00,  2.9527e+00,  2.2536e+00,
          1.9551e+00,  3.0532e+00,  3.5878e+00,  1.9398e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 369 : 180.15344587798575
Test loss for epoch 369 : 180.67580039303294
Test Precision for epoch 369 : 0.26153846153846155
Test Recall for epoch 369 : 0.26153846153846155
Test F1 for epoch 369 : 0.26153846153846155


theta for epoch 370 : tensor([[ 2.7811e+00,  2.8074e+00,  2.8742e+00,  3.0163e+00,  2.9836e+00,
          2.7853e+00,  2.9642e+00,  2.7789e+00,  2.7789e+00,  1.2696e+00,
          1.2939e+00,  1.2821e+00,  1.3218e+00,  1.2616e+00,  1.3687e+00,
          1.2743e+00,  1.2475e+00,  1.2806e+00,  1.2572e+00,  1.2349e+00,
          1.2515e+00,  1.2706e+00,  1.2296e+00,  1.2250e+00,  1.2443e+00,
          1.2178e+00,  1.2178e+00,  1.2630e+00,  1.3090e+00,  1.2345e+00,
          1.2616e+00,  1.3097e+00,  1.2458e+00,  1.2769e+00,  1.1957e+00,
          1.2371e+00,  1.3929e+00,  1.4420e+00,  1.4263e+00,  1.4050e+00,
          1.4154e+00,  1.3668e+00,  1.4076e+00,  1.2733e+00,  1.3540e+00,
          1.3203e+00,  1.2759e+00,  1.2629e+00,  1.2481e+00,  1.3186e+00,
          1.2693e+00,  1.3537e+00,  1.2349e+00,  1.2513e+00],
        [ 1.2270e+00,  1.2550e+00,  1.3056e+00,  1.2840e+00,  1.2612e+00,
          1.2318e+00,  1.2411e+00,  1.2246e+00,  1.2246e+00,  2.5535e+00,
          2.5731e+00,  2.5113e+00,  2.7704e+00,  2.4903e+00,  3.8888e+00,
          2.5534e+00,  2.7195e+00,  3.6859e+00,  1.2375e+00,  1.2635e+00,
          1.2331e+00,  1.2516e+00,  1.2503e+00,  1.2455e+00,  1.2650e+00,
          1.2380e+00,  1.2380e+00,  1.2947e+00,  1.2465e+00,  1.2581e+00,
          1.2862e+00,  1.2879e+00,  1.2697e+00,  1.3019e+00,  1.2256e+00,
          1.2607e+00,  1.4111e+00,  1.4619e+00,  1.3965e+00,  1.4226e+00,
          1.4343e+00,  1.4425e+00,  1.3773e+00,  1.2744e+00,  1.3699e+00,
          1.2981e+00,  1.3008e+00,  1.2874e+00,  1.2722e+00,  1.2545e+00,
          1.2941e+00,  1.2913e+00,  1.2588e+00,  1.2755e+00],
        [ 1.2109e+00,  1.2381e+00,  1.2731e+00,  1.2721e+00,  1.2432e+00,
          1.2155e+00,  1.2238e+00,  1.2085e+00,  1.2085e+00,  1.2743e+00,
          1.2987e+00,  1.2868e+00,  1.3268e+00,  1.2663e+00,  1.3215e+00,
          1.2791e+00,  1.1997e+00,  1.3267e+00,  2.8016e+00,  3.0553e+00,
          3.0159e+00,  2.8157e+00,  2.7642e+00,  2.7598e+00,  3.0139e+00,
          2.7535e+00,  2.7535e+00,  1.2476e+00,  1.3088e+00,  1.2392e+00,
          1.2633e+00,  1.2482e+00,  1.2505e+00,  1.2819e+00,  1.2462e+00,
          1.2417e+00,  1.3981e+00,  1.4472e+00,  1.4277e+00,  1.3304e+00,
          1.4167e+00,  1.3983e+00,  1.4128e+00,  1.2787e+00,  1.2761e+00,
          1.3235e+00,  1.2824e+00,  1.2694e+00,  1.2547e+00,  1.3194e+00,
          1.2758e+00,  1.3545e+00,  1.2170e+00,  1.2578e+00],
        [ 1.2140e+00,  1.2416e+00,  1.2772e+00,  1.2762e+00,  1.2469e+00,
          1.2187e+00,  1.2273e+00,  1.2116e+00,  1.2116e+00,  1.2809e+00,
          1.3055e+00,  1.2935e+00,  1.3262e+00,  1.2730e+00,  1.3197e+00,
          1.2858e+00,  1.2582e+00,  1.2789e+00,  1.2656e+00,  1.2608e+00,
          1.3057e+00,  1.2793e+00,  1.2375e+00,  1.2328e+00,  1.2311e+00,
          1.2255e+00,  1.2255e+00,  3.0827e+00,  3.0047e+00,  2.7000e+00,
          2.7819e+00,  3.0809e+00,  2.7100e+00,  2.9696e+00,  2.7208e+00,
          2.7022e+00,  1.4035e+00,  1.4528e+00,  1.4284e+00,  1.3895e+00,
          1.4260e+00,  1.4076e+00,  1.4097e+00,  1.2765e+00,  1.3384e+00,
          1.3331e+00,  1.2886e+00,  1.2222e+00,  1.2133e+00,  1.3314e+00,
          1.2820e+00,  1.3667e+00,  1.1793e+00,  1.2639e+00],
        [ 1.8721e+00,  1.4585e+00,  6.3414e-01,  9.3182e-01,  1.3513e+00,
          1.7988e+00,  1.6647e+00,  1.9105e+00,  1.9105e+00,  1.6995e+00,
          1.3243e+00,  1.5407e+00,  9.4175e-01,  1.7582e+00,  1.6140e-01,
          1.6352e+00,  1.9453e+00,  8.4941e-01,  1.3609e+00,  1.0372e+00,
          7.8307e-01,  1.1692e+00,  1.7390e+00,  1.8089e+00,  1.5807e+00,
          1.9219e+00,  1.9219e+00,  8.8533e-01,  8.6570e-01,  1.8960e+00,
          1.6669e+00,  8.8876e-01,  1.8284e+00,  1.2683e+00,  1.9478e+00,
          1.8579e+00,  2.0634e-01, -5.5835e-03, -3.1544e-02,  1.5834e-01,
          3.6892e-01,  4.3297e-01,  1.0278e-01,  1.9935e+01,  1.8930e+00,
          8.1292e-01,  1.4415e+00,  1.5225e+00,  1.7815e+00,  1.0267e+00,
          1.6945e+00,  3.9784e-01,  1.9262e+00,  1.9509e+00],
        [ 1.2929e+00,  1.3210e+00,  1.3777e+00,  1.3569e+00,  1.3270e+00,
          1.2977e+00,  1.2614e+00,  1.2905e+00,  1.2905e+00,  1.2658e+00,
          1.3845e+00,  1.2784e+00,  1.4130e+00,  1.3516e+00,  1.4600e+00,
          1.2706e+00,  1.3370e+00,  1.3243e+00,  1.3464e+00,  1.3282e+00,
          1.3880e+00,  1.3604e+00,  1.3180e+00,  1.3132e+00,  1.2016e+00,
          1.3058e+00,  1.3058e+00,  1.3534e+00,  1.4000e+00,  1.3250e+00,
          1.0929e+00,  1.3077e+00,  1.1996e+00,  1.3674e+00,  1.1961e+00,
          1.3276e+00,  1.4752e+00,  1.1674e+00,  1.4577e+00,  1.4870e+00,
          1.0137e+00,  9.3846e-01,  1.4903e+00,  1.3518e+00,  8.3282e-01,
          3.6530e+00,  2.6571e+00,  3.7239e+00,  2.9517e+00,  2.2524e+00,
          1.9536e+00,  3.0522e+00,  3.5892e+00,  1.9384e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 370 : 180.14224963305534
Test loss for epoch 370 : 180.67083770955165
Test Precision for epoch 370 : 0.26153846153846155
Test Recall for epoch 370 : 0.26153846153846155
Test F1 for epoch 370 : 0.26153846153846155


theta for epoch 371 : tensor([[ 2.7801e+00,  2.8064e+00,  2.8732e+00,  3.0155e+00,  2.9827e+00,
          2.7843e+00,  2.9633e+00,  2.7779e+00,  2.7779e+00,  1.2714e+00,
          1.2957e+00,  1.2838e+00,  1.3235e+00,  1.2634e+00,  1.3706e+00,
          1.2761e+00,  1.2493e+00,  1.2825e+00,  1.2592e+00,  1.2369e+00,
          1.2534e+00,  1.2726e+00,  1.2316e+00,  1.2270e+00,  1.2462e+00,
          1.2198e+00,  1.2198e+00,  1.2648e+00,  1.3107e+00,  1.2363e+00,
          1.2634e+00,  1.3114e+00,  1.2475e+00,  1.2787e+00,  1.1974e+00,
          1.2388e+00,  1.3939e+00,  1.4430e+00,  1.4273e+00,  1.4059e+00,
          1.4164e+00,  1.3679e+00,  1.4086e+00,  1.2740e+00,  1.3555e+00,
          1.3233e+00,  1.2789e+00,  1.2659e+00,  1.2512e+00,  1.3216e+00,
          1.2723e+00,  1.3567e+00,  1.2379e+00,  1.2542e+00],
        [ 1.2232e+00,  1.2513e+00,  1.3024e+00,  1.2807e+00,  1.2575e+00,
          1.2280e+00,  1.2373e+00,  1.2208e+00,  1.2208e+00,  2.5598e+00,
          2.5798e+00,  2.5196e+00,  2.7805e+00,  2.4986e+00,  3.8734e+00,
          2.5602e+00,  2.7298e+00,  3.6721e+00,  1.2373e+00,  1.2634e+00,
          1.2329e+00,  1.2515e+00,  1.2501e+00,  1.2453e+00,  1.2648e+00,
          1.2377e+00,  1.2377e+00,  1.2943e+00,  1.2462e+00,  1.2575e+00,
          1.2856e+00,  1.2880e+00,  1.2691e+00,  1.3014e+00,  1.2251e+00,
          1.2601e+00,  1.4103e+00,  1.4611e+00,  1.3960e+00,  1.4219e+00,
          1.4336e+00,  1.4418e+00,  1.3768e+00,  1.2744e+00,  1.3696e+00,
          1.2991e+00,  1.3020e+00,  1.2886e+00,  1.2734e+00,  1.2557e+00,
          1.2952e+00,  1.2921e+00,  1.2599e+00,  1.2766e+00],
        [ 1.2076e+00,  1.2347e+00,  1.2697e+00,  1.2687e+00,  1.2399e+00,
          1.2122e+00,  1.2205e+00,  1.2052e+00,  1.2052e+00,  1.2738e+00,
          1.2982e+00,  1.2863e+00,  1.3263e+00,  1.2658e+00,  1.3210e+00,
          1.2786e+00,  1.1990e+00,  1.3262e+00,  2.8051e+00,  3.0599e+00,
          3.0196e+00,  2.8192e+00,  2.7674e+00,  2.7630e+00,  3.0184e+00,
          2.7567e+00,  2.7567e+00,  1.2469e+00,  1.3081e+00,  1.2387e+00,
          1.2628e+00,  1.2476e+00,  1.2499e+00,  1.2814e+00,  1.2456e+00,
          1.2412e+00,  1.3975e+00,  1.4466e+00,  1.4271e+00,  1.3296e+00,
          1.4161e+00,  1.3976e+00,  1.4123e+00,  1.2778e+00,  1.2758e+00,
          1.3247e+00,  1.2836e+00,  1.2706e+00,  1.2559e+00,  1.3204e+00,
          1.2770e+00,  1.3555e+00,  1.2181e+00,  1.2589e+00],
        [ 1.2111e+00,  1.2386e+00,  1.2743e+00,  1.2734e+00,  1.2440e+00,
          1.2157e+00,  1.2243e+00,  1.2086e+00,  1.2086e+00,  1.2808e+00,
          1.3054e+00,  1.2934e+00,  1.3259e+00,  1.2728e+00,  1.3197e+00,
          1.2856e+00,  1.2580e+00,  1.2789e+00,  1.2657e+00,  1.2607e+00,
          1.3058e+00,  1.2794e+00,  1.2376e+00,  1.2329e+00,  1.2312e+00,
          1.2256e+00,  1.2256e+00,  3.0858e+00,  3.0064e+00,  2.7036e+00,
          2.7836e+00,  3.0840e+00,  2.7136e+00,  2.9711e+00,  2.7249e+00,
          2.7059e+00,  1.4031e+00,  1.4525e+00,  1.4279e+00,  1.3891e+00,
          1.4257e+00,  1.4072e+00,  1.4091e+00,  1.2761e+00,  1.3384e+00,
          1.3343e+00,  1.2898e+00,  1.2236e+00,  1.2146e+00,  1.3326e+00,
          1.2832e+00,  1.3679e+00,  1.1805e+00,  1.2651e+00],
        [ 1.8708e+00,  1.4573e+00,  6.3389e-01,  9.3116e-01,  1.3503e+00,
          1.7975e+00,  1.6635e+00,  1.9092e+00,  1.9092e+00,  1.7007e+00,
          1.3258e+00,  1.5422e+00,  9.4361e-01,  1.7596e+00,  1.6375e-01,
          1.6364e+00,  1.9466e+00,  8.5128e-01,  1.3628e+00,  1.0393e+00,
          7.8531e-01,  1.1712e+00,  1.7407e+00,  1.8105e+00,  1.5825e+00,
          1.9235e+00,  1.9235e+00,  8.8726e-01,  8.6757e-01,  1.8974e+00,
          1.6683e+00,  8.9053e-01,  1.8298e+00,  1.2700e+00,  1.9491e+00,
          1.8593e+00,  2.0353e-01, -8.0921e-03, -3.4045e-02,  1.5557e-01,
          3.6584e-01,  4.2973e-01,  1.0012e-01,  1.9996e+01,  1.8739e+00,
          8.1620e-01,  1.4445e+00,  1.5254e+00,  1.7844e+00,  1.0299e+00,
          1.6975e+00,  4.0133e-01,  1.9292e+00,  1.9537e+00],
        [ 1.2885e+00,  1.3166e+00,  1.3734e+00,  1.3525e+00,  1.3226e+00,
          1.2933e+00,  1.2570e+00,  1.2861e+00,  1.2861e+00,  1.2644e+00,
          1.3832e+00,  1.2770e+00,  1.4117e+00,  1.3503e+00,  1.4588e+00,
          1.2692e+00,  1.3357e+00,  1.3230e+00,  1.3454e+00,  1.3271e+00,
          1.3870e+00,  1.3593e+00,  1.3170e+00,  1.3122e+00,  1.2004e+00,
          1.3048e+00,  1.3048e+00,  1.3521e+00,  1.3987e+00,  1.3236e+00,
          1.0912e+00,  1.3062e+00,  1.1981e+00,  1.3661e+00,  1.1946e+00,
          1.3262e+00,  1.4741e+00,  1.1659e+00,  1.4565e+00,  1.4859e+00,
          1.0120e+00,  9.3670e-01,  1.4892e+00,  1.3503e+00,  8.3137e-01,
          3.6604e+00,  2.6623e+00,  3.7292e+00,  2.9569e+00,  2.2574e+00,
          1.9584e+00,  3.0573e+00,  3.5969e+00,  1.9431e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 371 : 180.13736648714402
Test loss for epoch 371 : 180.66674848806784
Test Precision for epoch 371 : 0.26153846153846155
Test Recall for epoch 371 : 0.26153846153846155
Test F1 for epoch 371 : 0.26153846153846155


theta for epoch 372 : tensor([[ 2.7903e+00,  2.8166e+00,  2.8834e+00,  3.0258e+00,  2.9930e+00,
          2.7945e+00,  2.9737e+00,  2.7881e+00,  2.7881e+00,  1.2668e+00,
          1.2910e+00,  1.2791e+00,  1.3189e+00,  1.2587e+00,  1.3661e+00,
          1.2715e+00,  1.2445e+00,  1.2779e+00,  1.2525e+00,  1.2302e+00,
          1.2467e+00,  1.2659e+00,  1.2249e+00,  1.2203e+00,  1.2396e+00,
          1.2131e+00,  1.2131e+00,  1.2600e+00,  1.3060e+00,  1.2315e+00,
          1.2586e+00,  1.3067e+00,  1.2427e+00,  1.2740e+00,  1.1925e+00,
          1.2340e+00,  1.3913e+00,  1.4405e+00,  1.4248e+00,  1.4034e+00,
          1.4139e+00,  1.3653e+00,  1.4061e+00,  1.2709e+00,  1.3532e+00,
          1.3181e+00,  1.2737e+00,  1.2607e+00,  1.2459e+00,  1.3164e+00,
          1.2671e+00,  1.3516e+00,  1.2326e+00,  1.2490e+00],
        [ 1.2281e+00,  1.2561e+00,  1.3072e+00,  1.2858e+00,  1.2624e+00,
          1.2330e+00,  1.2422e+00,  1.2258e+00,  1.2258e+00,  2.5648e+00,
          2.5853e+00,  2.5266e+00,  2.7894e+00,  2.5055e+00,  3.8573e+00,
          2.5656e+00,  2.7387e+00,  3.6575e+00,  1.2344e+00,  1.2606e+00,
          1.2302e+00,  1.2485e+00,  1.2469e+00,  1.2421e+00,  1.2617e+00,
          1.2346e+00,  1.2346e+00,  1.2938e+00,  1.2457e+00,  1.2568e+00,
          1.2849e+00,  1.2879e+00,  1.2684e+00,  1.3007e+00,  1.2246e+00,
          1.2594e+00,  1.4104e+00,  1.4612e+00,  1.3963e+00,  1.4221e+00,
          1.4337e+00,  1.4419e+00,  1.3770e+00,  1.2751e+00,  1.3701e+00,
          1.2976e+00,  1.3005e+00,  1.2871e+00,  1.2719e+00,  1.2544e+00,
          1.2937e+00,  1.2909e+00,  1.2584e+00,  1.2750e+00],
        [ 1.2137e+00,  1.2408e+00,  1.2756e+00,  1.2748e+00,  1.2459e+00,
          1.2183e+00,  1.2265e+00,  1.2113e+00,  1.2113e+00,  1.2751e+00,
          1.2995e+00,  1.2875e+00,  1.3275e+00,  1.2670e+00,  1.3221e+00,
          1.2798e+00,  1.2002e+00,  1.3274e+00,  2.8040e+00,  3.0598e+00,
          3.0187e+00,  2.8181e+00,  2.7659e+00,  2.7615e+00,  3.0183e+00,
          2.7552e+00,  2.7552e+00,  1.2477e+00,  1.3088e+00,  1.2395e+00,
          1.2637e+00,  1.2484e+00,  1.2508e+00,  1.2823e+00,  1.2465e+00,
          1.2421e+00,  1.3989e+00,  1.4480e+00,  1.4285e+00,  1.3309e+00,
          1.4175e+00,  1.3990e+00,  1.4136e+00,  1.2788e+00,  1.2775e+00,
          1.3249e+00,  1.2838e+00,  1.2709e+00,  1.2561e+00,  1.3205e+00,
          1.2773e+00,  1.3556e+00,  1.2183e+00,  1.2592e+00],
        [ 1.2155e+00,  1.2430e+00,  1.2784e+00,  1.2776e+00,  1.2484e+00,
          1.2202e+00,  1.2288e+00,  1.2131e+00,  1.2131e+00,  1.2805e+00,
          1.3050e+00,  1.2930e+00,  1.3253e+00,  1.2724e+00,  1.3194e+00,
          1.2853e+00,  1.2576e+00,  1.2787e+00,  1.2629e+00,  1.2576e+00,
          1.3030e+00,  1.2766e+00,  1.2348e+00,  1.2301e+00,  1.2283e+00,
          1.2227e+00,  1.2227e+00,  3.0880e+00,  3.0071e+00,  2.7062e+00,
          2.7843e+00,  3.0863e+00,  2.7163e+00,  2.9718e+00,  2.7280e+00,
          2.7085e+00,  1.4035e+00,  1.4529e+00,  1.4280e+00,  1.3895e+00,
          1.4261e+00,  1.4076e+00,  1.4093e+00,  1.2763e+00,  1.3391e+00,
          1.3332e+00,  1.2887e+00,  1.2228e+00,  1.2135e+00,  1.3315e+00,
          1.2821e+00,  1.3668e+00,  1.1793e+00,  1.2640e+00],
        [ 1.8759e+00,  1.4625e+00,  6.3823e-01,  9.3560e-01,  1.3554e+00,
          1.8027e+00,  1.6687e+00,  1.9143e+00,  1.9143e+00,  1.7008e+00,
          1.3259e+00,  1.5425e+00,  9.4396e-01,  1.7599e+00,  1.6441e-01,
          1.6366e+00,  1.9468e+00,  8.5149e-01,  1.3611e+00,  1.0380e+00,
          7.8389e-01,  1.1696e+00,  1.7389e+00,  1.8088e+00,  1.5811e+00,
          1.9218e+00,  1.9218e+00,  8.8741e-01,  8.6764e-01,  1.8975e+00,
          1.6684e+00,  8.9050e-01,  1.8299e+00,  1.2699e+00,  1.9492e+00,
          1.8594e+00,  2.0156e-01, -9.7870e-03, -3.5750e-02,  1.5364e-01,
          3.6366e-01,  4.2740e-01,  9.8288e-02,  2.0056e+01,  1.8571e+00,
          8.1572e-01,  1.4439e+00,  1.5247e+00,  1.7837e+00,  1.0293e+00,
          1.6968e+00,  4.0107e-01,  1.9287e+00,  1.9530e+00],
        [ 1.2941e+00,  1.3222e+00,  1.3788e+00,  1.3580e+00,  1.3282e+00,
          1.2988e+00,  1.2625e+00,  1.2916e+00,  1.2916e+00,  1.2650e+00,
          1.3837e+00,  1.2775e+00,  1.4121e+00,  1.3507e+00,  1.4593e+00,
          1.2697e+00,  1.3361e+00,  1.3237e+00,  1.3434e+00,  1.3251e+00,
          1.3849e+00,  1.3573e+00,  1.3149e+00,  1.3102e+00,  1.1984e+00,
          1.3027e+00,  1.3027e+00,  1.3524e+00,  1.3990e+00,  1.3239e+00,
          1.0918e+00,  1.3066e+00,  1.1985e+00,  1.3665e+00,  1.1950e+00,
          1.3265e+00,  1.4751e+00,  1.1670e+00,  1.4575e+00,  1.4868e+00,
          1.0132e+00,  9.3787e-01,  1.4902e+00,  1.3510e+00,  8.3282e-01,
          3.6627e+00,  2.6622e+00,  3.7293e+00,  2.9568e+00,  2.2571e+00,
          1.9578e+00,  3.0573e+00,  3.5992e+00,  1.9425e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 372 : 180.13505351908168
Test loss for epoch 372 : 180.6716630141113
Test Precision for epoch 372 : 0.26153846153846155
Test Recall for epoch 372 : 0.26153846153846155
Test F1 for epoch 372 : 0.26153846153846155


theta for epoch 373 : tensor([[ 2.7829e+00,  2.8092e+00,  2.8761e+00,  3.0186e+00,  2.9859e+00,
          2.7871e+00,  2.9665e+00,  2.7807e+00,  2.7807e+00,  1.2724e+00,
          1.2966e+00,  1.2846e+00,  1.3243e+00,  1.2642e+00,  1.3716e+00,
          1.2770e+00,  1.2501e+00,  1.2837e+00,  1.2609e+00,  1.2386e+00,
          1.2552e+00,  1.2743e+00,  1.2334e+00,  1.2288e+00,  1.2479e+00,
          1.2215e+00,  1.2215e+00,  1.2659e+00,  1.3118e+00,  1.2374e+00,
          1.2645e+00,  1.3125e+00,  1.2486e+00,  1.2799e+00,  1.1985e+00,
          1.2399e+00,  1.3949e+00,  1.4440e+00,  1.4283e+00,  1.4069e+00,
          1.4174e+00,  1.3690e+00,  1.4096e+00,  1.2743e+00,  1.3572e+00,
          1.3236e+00,  1.2792e+00,  1.2662e+00,  1.2515e+00,  1.3218e+00,
          1.2726e+00,  1.3570e+00,  1.2382e+00,  1.2545e+00],
        [ 1.2197e+00,  1.2479e+00,  1.2997e+00,  1.2779e+00,  1.2541e+00,
          1.2246e+00,  1.2338e+00,  1.2173e+00,  1.2173e+00,  2.5718e+00,
          2.5926e+00,  2.5355e+00,  2.8001e+00,  2.5144e+00,  3.8434e+00,
          2.5730e+00,  2.7496e+00,  3.6452e+00,  1.2378e+00,  1.2640e+00,
          1.2333e+00,  1.2519e+00,  1.2503e+00,  1.2455e+00,  1.2650e+00,
          1.2379e+00,  1.2379e+00,  1.2938e+00,  1.2457e+00,  1.2565e+00,
          1.2847e+00,  1.2882e+00,  1.2682e+00,  1.3005e+00,  1.2246e+00,
          1.2592e+00,  1.4095e+00,  1.4604e+00,  1.3957e+00,  1.4213e+00,
          1.4329e+00,  1.4411e+00,  1.3764e+00,  1.2750e+00,  1.3697e+00,
          1.2975e+00,  1.3004e+00,  1.2870e+00,  1.2718e+00,  1.2544e+00,
          1.2936e+00,  1.2907e+00,  1.2584e+00,  1.2750e+00],
        [ 1.2038e+00,  1.2310e+00,  1.2657e+00,  1.2650e+00,  1.2361e+00,
          1.2084e+00,  1.2167e+00,  1.2014e+00,  1.2014e+00,  1.2722e+00,
          1.2966e+00,  1.2846e+00,  1.3246e+00,  1.2640e+00,  1.3192e+00,
          1.2769e+00,  1.1970e+00,  1.3246e+00,  2.8128e+00,  3.0696e+00,
          3.0276e+00,  2.8268e+00,  2.7744e+00,  2.7700e+00,  3.0281e+00,
          2.7637e+00,  2.7637e+00,  1.2455e+00,  1.3066e+00,  1.2374e+00,
          1.2616e+00,  1.2461e+00,  1.2487e+00,  1.2803e+00,  1.2444e+00,
          1.2400e+00,  1.3967e+00,  1.4459e+00,  1.4264e+00,  1.3285e+00,
          1.4155e+00,  1.3968e+00,  1.4115e+00,  1.2762e+00,  1.2754e+00,
          1.3226e+00,  1.2815e+00,  1.2685e+00,  1.2538e+00,  1.3180e+00,
          1.2749e+00,  1.3532e+00,  1.2158e+00,  1.2568e+00],
        [ 1.2083e+00,  1.2359e+00,  1.2716e+00,  1.2708e+00,  1.2413e+00,
          1.2130e+00,  1.2216e+00,  1.2059e+00,  1.2059e+00,  1.2802e+00,
          1.3047e+00,  1.2926e+00,  1.3247e+00,  1.2721e+00,  1.3192e+00,
          1.2850e+00,  1.2573e+00,  1.2785e+00,  1.2663e+00,  1.2607e+00,
          1.3063e+00,  1.2800e+00,  1.2382e+00,  1.2335e+00,  1.2316e+00,
          1.2261e+00,  1.2261e+00,  3.0924e+00,  3.0099e+00,  2.7110e+00,
          2.7871e+00,  3.0906e+00,  2.7210e+00,  2.9745e+00,  2.7332e+00,
          2.7133e+00,  1.4029e+00,  1.4523e+00,  1.4272e+00,  1.3888e+00,
          1.4256e+00,  1.4070e+00,  1.4084e+00,  1.2755e+00,  1.3388e+00,
          1.3333e+00,  1.2888e+00,  1.2230e+00,  1.2135e+00,  1.3316e+00,
          1.2822e+00,  1.3669e+00,  1.1793e+00,  1.2640e+00],
        [ 1.8707e+00,  1.4572e+00,  6.3442e-01,  9.3127e-01,  1.3502e+00,
          1.7974e+00,  1.6634e+00,  1.9090e+00,  1.9090e+00,  1.7021e+00,
          1.3274e+00,  1.5441e+00,  9.4568e-01,  1.7614e+00,  1.6644e-01,
          1.6379e+00,  1.9482e+00,  8.5322e-01,  1.3657e+00,  1.0425e+00,
          7.8850e-01,  1.1742e+00,  1.7435e+00,  1.8133e+00,  1.5856e+00,
          1.9262e+00,  1.9262e+00,  8.8951e-01,  8.6968e-01,  1.8994e+00,
          1.6702e+00,  8.9247e-01,  1.8318e+00,  1.2719e+00,  1.9510e+00,
          1.8612e+00,  1.9912e-01, -1.1951e-02, -3.7910e-02,  1.5122e-01,
          3.6097e-01,  4.2457e-01,  9.5982e-02,  2.0116e+01,  1.8411e+00,
          8.1789e-01,  1.4459e+00,  1.5266e+00,  1.7857e+00,  1.0314e+00,
          1.6987e+00,  4.0341e-01,  1.9308e+00,  1.9549e+00],
        [ 1.2862e+00,  1.3143e+00,  1.3711e+00,  1.3502e+00,  1.3203e+00,
          1.2910e+00,  1.2547e+00,  1.2838e+00,  1.2838e+00,  1.2644e+00,
          1.3832e+00,  1.2769e+00,  1.4116e+00,  1.3502e+00,  1.4589e+00,
          1.2692e+00,  1.3356e+00,  1.3233e+00,  1.3467e+00,  1.3283e+00,
          1.3883e+00,  1.3606e+00,  1.3183e+00,  1.3135e+00,  1.2016e+00,
          1.3060e+00,  1.3060e+00,  1.3523e+00,  1.3989e+00,  1.3238e+00,
          1.0914e+00,  1.3064e+00,  1.1983e+00,  1.3664e+00,  1.1947e+00,
          1.3264e+00,  1.4744e+00,  1.1660e+00,  1.4567e+00,  1.4861e+00,
          1.0120e+00,  9.3669e-01,  1.4895e+00,  1.3499e+00,  8.3187e-01,
          3.6694e+00,  2.6666e+00,  3.7339e+00,  2.9612e+00,  2.2611e+00,
          1.9616e+00,  3.0616e+00,  3.6061e+00,  1.9463e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 373 : 180.13372079626106
Test loss for epoch 373 : 180.67058701214387
Test Precision for epoch 373 : 0.26153846153846155
Test Recall for epoch 373 : 0.26153846153846155
Test F1 for epoch 373 : 0.26153846153846155


theta for epoch 374 : tensor([[ 2.7970e+00,  2.8233e+00,  2.8901e+00,  3.0328e+00,  3.0000e+00,
          2.8012e+00,  2.9807e+00,  2.7948e+00,  2.7948e+00,  1.2654e+00,
          1.2897e+00,  1.2777e+00,  1.3175e+00,  1.2572e+00,  1.3649e+00,
          1.2701e+00,  1.2431e+00,  1.2768e+00,  1.2501e+00,  1.2278e+00,
          1.2444e+00,  1.2635e+00,  1.2225e+00,  1.2179e+00,  1.2371e+00,
          1.2107e+00,  1.2107e+00,  1.2586e+00,  1.3046e+00,  1.2300e+00,
          1.2573e+00,  1.3053e+00,  1.2413e+00,  1.2726e+00,  1.1910e+00,
          1.2325e+00,  1.3906e+00,  1.4399e+00,  1.4241e+00,  1.4027e+00,
          1.4133e+00,  1.3647e+00,  1.4054e+00,  1.2695e+00,  1.3532e+00,
          1.3176e+00,  1.2732e+00,  1.2602e+00,  1.2454e+00,  1.3158e+00,
          1.2665e+00,  1.3511e+00,  1.2321e+00,  1.2484e+00],
        [ 1.2274e+00,  1.2554e+00,  1.3071e+00,  1.2858e+00,  1.2618e+00,
          1.2324e+00,  1.2416e+00,  1.2251e+00,  1.2251e+00,  2.5767e+00,
          2.5978e+00,  2.5423e+00,  2.8087e+00,  2.5211e+00,  3.8280e+00,
          2.5783e+00,  2.7582e+00,  3.6315e+00,  1.2325e+00,  1.2588e+00,
          1.2284e+00,  1.2466e+00,  1.2448e+00,  1.2400e+00,  1.2595e+00,
          1.2324e+00,  1.2324e+00,  1.2930e+00,  1.2449e+00,  1.2555e+00,
          1.2837e+00,  1.2876e+00,  1.2671e+00,  1.2995e+00,  1.2237e+00,
          1.2581e+00,  1.4094e+00,  1.4603e+00,  1.3958e+00,  1.4212e+00,
          1.4328e+00,  1.4410e+00,  1.3765e+00,  1.2755e+00,  1.3699e+00,
          1.2971e+00,  1.2999e+00,  1.2866e+00,  1.2713e+00,  1.2540e+00,
          1.2931e+00,  1.2903e+00,  1.2579e+00,  1.2744e+00],
        [ 1.2140e+00,  1.2411e+00,  1.2758e+00,  1.2751e+00,  1.2462e+00,
          1.2186e+00,  1.2268e+00,  1.2116e+00,  1.2116e+00,  1.2753e+00,
          1.2996e+00,  1.2876e+00,  1.3276e+00,  1.2670e+00,  1.3220e+00,
          1.2799e+00,  1.2000e+00,  1.3275e+00,  2.8083e+00,  3.0661e+00,
          3.0234e+00,  2.8224e+00,  2.7696e+00,  2.7651e+00,  3.0246e+00,
          2.7588e+00,  2.7588e+00,  1.2475e+00,  1.3084e+00,  1.2394e+00,
          1.2636e+00,  1.2481e+00,  1.2507e+00,  1.2822e+00,  1.2463e+00,
          1.2420e+00,  1.3991e+00,  1.4483e+00,  1.4287e+00,  1.3309e+00,
          1.4178e+00,  1.3991e+00,  1.4138e+00,  1.2783e+00,  1.2782e+00,
          1.3257e+00,  1.2845e+00,  1.2716e+00,  1.2568e+00,  1.3208e+00,
          1.2779e+00,  1.3560e+00,  1.2189e+00,  1.2598e+00],
        [ 1.2154e+00,  1.2430e+00,  1.2782e+00,  1.2775e+00,  1.2483e+00,
          1.2201e+00,  1.2287e+00,  1.2130e+00,  1.2130e+00,  1.2799e+00,
          1.3044e+00,  1.2922e+00,  1.3241e+00,  1.2717e+00,  1.3189e+00,
          1.2846e+00,  1.2569e+00,  1.2783e+00,  1.2613e+00,  1.2555e+00,
          1.3014e+00,  1.2750e+00,  1.2331e+00,  1.2285e+00,  1.2265e+00,
          1.2211e+00,  1.2211e+00,  3.0943e+00,  3.0103e+00,  2.7132e+00,
          2.7875e+00,  3.0925e+00,  2.7232e+00,  2.9749e+00,  2.7359e+00,
          2.7155e+00,  1.4033e+00,  1.4527e+00,  1.4273e+00,  1.3891e+00,
          1.4259e+00,  1.4074e+00,  1.4085e+00,  1.2757e+00,  1.3394e+00,
          1.3332e+00,  1.2887e+00,  1.2231e+00,  1.2134e+00,  1.3314e+00,
          1.2820e+00,  1.3668e+00,  1.1791e+00,  1.2638e+00],
        [ 1.8783e+00,  1.4650e+00,  6.4097e-01,  9.3801e-01,  1.3579e+00,
          1.8050e+00,  1.6711e+00,  1.9166e+00,  1.9166e+00,  1.7021e+00,
          1.3275e+00,  1.5443e+00,  9.4602e-01,  1.7615e+00,  1.6722e-01,
          1.6380e+00,  1.9483e+00,  8.5346e-01,  1.3622e+00,  1.0395e+00,
          7.8549e-01,  1.1709e+00,  1.7399e+00,  1.8097e+00,  1.5823e+00,
          1.9226e+00,  1.9226e+00,  8.8943e-01,  8.6954e-01,  1.8990e+00,
          1.6698e+00,  8.9222e-01,  1.8315e+00,  1.2715e+00,  1.9507e+00,
          1.8609e+00,  1.9690e-01, -1.3894e-02, -3.9858e-02,  1.4904e-01,
          3.5853e-01,  4.2199e-01,  9.3899e-02,  2.0176e+01,  1.8267e+00,
          8.1839e-01,  1.4462e+00,  1.5267e+00,  1.7859e+00,  1.0317e+00,
          1.6990e+00,  4.0413e-01,  1.9312e+00,  1.9551e+00],
        [ 1.2937e+00,  1.3218e+00,  1.3785e+00,  1.3577e+00,  1.3278e+00,
          1.2985e+00,  1.2621e+00,  1.2912e+00,  1.2912e+00,  1.2638e+00,
          1.3825e+00,  1.2762e+00,  1.4109e+00,  1.3494e+00,  1.4584e+00,
          1.2685e+00,  1.3349e+00,  1.3228e+00,  1.3413e+00,  1.3228e+00,
          1.3828e+00,  1.3551e+00,  1.3128e+00,  1.3080e+00,  1.1962e+00,
          1.3006e+00,  1.3006e+00,  1.3512e+00,  1.3979e+00,  1.3227e+00,
          1.0904e+00,  1.3054e+00,  1.1973e+00,  1.3653e+00,  1.1937e+00,
          1.3253e+00,  1.4745e+00,  1.1661e+00,  1.4568e+00,  1.4863e+00,
          1.0121e+00,  9.3681e-01,  1.4897e+00,  1.3497e+00,  8.3222e-01,
          3.6734e+00,  2.6682e+00,  3.7359e+00,  2.9630e+00,  2.2624e+00,
          1.9626e+00,  3.0633e+00,  3.6102e+00,  1.9473e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 374 : 180.12596834461704
Test loss for epoch 374 : 180.66940444595645
Test Precision for epoch 374 : 0.26153846153846155
Test Recall for epoch 374 : 0.26153846153846155
Test F1 for epoch 374 : 0.26153846153846155


theta for epoch 375 : tensor([[ 2.7895e+00,  2.8158e+00,  2.8827e+00,  3.0256e+00,  2.9928e+00,
          2.7938e+00,  2.9734e+00,  2.7873e+00,  2.7873e+00,  1.2711e+00,
          1.2954e+00,  1.2833e+00,  1.3231e+00,  1.2629e+00,  1.3706e+00,
          1.2758e+00,  1.2488e+00,  1.2827e+00,  1.2597e+00,  1.2375e+00,
          1.2541e+00,  1.2731e+00,  1.2322e+00,  1.2276e+00,  1.2468e+00,
          1.2203e+00,  1.2203e+00,  1.2648e+00,  1.3107e+00,  1.2362e+00,
          1.2635e+00,  1.3114e+00,  1.2475e+00,  1.2788e+00,  1.1973e+00,
          1.2388e+00,  1.3943e+00,  1.4434e+00,  1.4277e+00,  1.4063e+00,
          1.4170e+00,  1.3685e+00,  1.4090e+00,  1.2731e+00,  1.3573e+00,
          1.3221e+00,  1.2777e+00,  1.2648e+00,  1.2500e+00,  1.3203e+00,
          1.2711e+00,  1.3556e+00,  1.2367e+00,  1.2529e+00],
        [ 1.2190e+00,  1.2472e+00,  1.2995e+00,  1.2778e+00,  1.2535e+00,
          1.2240e+00,  1.2331e+00,  1.2167e+00,  1.2167e+00,  2.5838e+00,
          2.6052e+00,  2.5512e+00,  2.8193e+00,  2.5301e+00,  3.8150e+00,
          2.5857e+00,  2.7689e+00,  3.6202e+00,  1.2373e+00,  1.2636e+00,
          1.2328e+00,  1.2513e+00,  1.2495e+00,  1.2448e+00,  1.2642e+00,
          1.2372e+00,  1.2372e+00,  1.2931e+00,  1.2449e+00,  1.2554e+00,
          1.2836e+00,  1.2879e+00,  1.2670e+00,  1.2994e+00,  1.2238e+00,
          1.2580e+00,  1.4086e+00,  1.4595e+00,  1.3952e+00,  1.4205e+00,
          1.4320e+00,  1.4403e+00,  1.3759e+00,  1.2753e+00,  1.3694e+00,
          1.2957e+00,  1.2986e+00,  1.2852e+00,  1.2700e+00,  1.2528e+00,
          1.2917e+00,  1.2892e+00,  1.2565e+00,  1.2731e+00],
        [ 1.2032e+00,  1.2304e+00,  1.2651e+00,  1.2645e+00,  1.2356e+00,
          1.2078e+00,  1.2162e+00,  1.2008e+00,  1.2008e+00,  1.2714e+00,
          1.2958e+00,  1.2837e+00,  1.3237e+00,  1.2631e+00,  1.3182e+00,
          1.2761e+00,  1.1957e+00,  1.3237e+00,  2.8189e+00,  3.0776e+00,
          3.0341e+00,  2.8329e+00,  2.7799e+00,  2.7754e+00,  3.0361e+00,
          2.7691e+00,  2.7691e+00,  1.2446e+00,  1.3056e+00,  1.2367e+00,
          1.2610e+00,  1.2452e+00,  1.2480e+00,  1.2796e+00,  1.2436e+00,
          1.2393e+00,  1.3964e+00,  1.4456e+00,  1.4261e+00,  1.3279e+00,
          1.4152e+00,  1.3964e+00,  1.4112e+00,  1.2752e+00,  1.2755e+00,
          1.3212e+00,  1.2800e+00,  1.2670e+00,  1.2522e+00,  1.3161e+00,
          1.2733e+00,  1.3514e+00,  1.2141e+00,  1.2552e+00],
        [ 1.2081e+00,  1.2357e+00,  1.2713e+00,  1.2706e+00,  1.2411e+00,
          1.2128e+00,  1.2214e+00,  1.2057e+00,  1.2057e+00,  1.2794e+00,
          1.3039e+00,  1.2917e+00,  1.3234e+00,  1.2712e+00,  1.3185e+00,
          1.2842e+00,  1.2564e+00,  1.2779e+00,  1.2659e+00,  1.2598e+00,
          1.3060e+00,  1.2796e+00,  1.2378e+00,  1.2331e+00,  1.2311e+00,
          1.2258e+00,  1.2258e+00,  3.0991e+00,  3.0136e+00,  2.7183e+00,
          2.7908e+00,  3.0973e+00,  2.7284e+00,  2.9781e+00,  2.7415e+00,
          2.7206e+00,  1.4026e+00,  1.4520e+00,  1.4263e+00,  1.3883e+00,
          1.4253e+00,  1.4067e+00,  1.4075e+00,  1.2748e+00,  1.3389e+00,
          1.3321e+00,  1.2875e+00,  1.2221e+00,  1.2122e+00,  1.3303e+00,
          1.2809e+00,  1.3657e+00,  1.1778e+00,  1.2627e+00],
        [ 1.8728e+00,  1.4593e+00,  6.3681e-01,  9.3336e-01,  1.3524e+00,
          1.7995e+00,  1.6656e+00,  1.9110e+00,  1.9110e+00,  1.7033e+00,
          1.3287e+00,  1.5456e+00,  9.4747e-01,  1.7629e+00,  1.6890e-01,
          1.6392e+00,  1.9496e+00,  8.5491e-01,  1.3677e+00,  1.0449e+00,
          7.9084e-01,  1.1763e+00,  1.7454e+00,  1.8151e+00,  1.5878e+00,
          1.9280e+00,  1.9280e+00,  8.9136e-01,  8.7144e-01,  1.9009e+00,
          1.6717e+00,  8.9405e-01,  1.8333e+00,  1.2734e+00,  1.9525e+00,
          1.8627e+00,  1.9467e-01, -1.5863e-02, -4.1829e-02,  1.4683e-01,
          3.5606e-01,  4.1938e-01,  9.1791e-02,  2.0235e+01,  1.8135e+00,
          8.1925e-01,  1.4469e+00,  1.5273e+00,  1.7865e+00,  1.0325e+00,
          1.6996e+00,  4.0520e-01,  1.9319e+00,  1.9557e+00],
        [ 1.2867e+00,  1.3148e+00,  1.3715e+00,  1.3507e+00,  1.3208e+00,
          1.2915e+00,  1.2551e+00,  1.2842e+00,  1.2842e+00,  1.2641e+00,
          1.3829e+00,  1.2765e+00,  1.4113e+00,  1.3497e+00,  1.4588e+00,
          1.2688e+00,  1.3352e+00,  1.3232e+00,  1.3468e+00,  1.3284e+00,
          1.3884e+00,  1.3607e+00,  1.3184e+00,  1.3136e+00,  1.2016e+00,
          1.3061e+00,  1.3061e+00,  1.3521e+00,  1.3987e+00,  1.3235e+00,
          1.0912e+00,  1.3062e+00,  1.1981e+00,  1.3662e+00,  1.1945e+00,
          1.3261e+00,  1.4744e+00,  1.1658e+00,  1.4565e+00,  1.4861e+00,
          1.0118e+00,  9.3647e-01,  1.4895e+00,  1.3492e+00,  8.3204e-01,
          3.6784e+00,  2.6708e+00,  3.7389e+00,  2.9657e+00,  2.2647e+00,
          1.9645e+00,  3.0660e+00,  3.6153e+00,  1.9492e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 375 : 180.1162140386382
Test loss for epoch 375 : 180.66089222044593
Test Precision for epoch 375 : 0.26153846153846155
Test Recall for epoch 375 : 0.26153846153846155
Test F1 for epoch 375 : 0.26153846153846155


theta for epoch 376 : tensor([[ 2.8010e+00,  2.8273e+00,  2.8942e+00,  3.0372e+00,  3.0044e+00,
          2.8053e+00,  2.9851e+00,  2.7989e+00,  2.7989e+00,  1.2658e+00,
          1.2900e+00,  1.2779e+00,  1.3178e+00,  1.2575e+00,  1.3655e+00,
          1.2704e+00,  1.2434e+00,  1.2774e+00,  1.2504e+00,  1.2281e+00,
          1.2447e+00,  1.2638e+00,  1.2228e+00,  1.2182e+00,  1.2374e+00,
          1.2109e+00,  1.2109e+00,  1.2590e+00,  1.3050e+00,  1.2304e+00,
          1.2577e+00,  1.3057e+00,  1.2416e+00,  1.2731e+00,  1.1913e+00,
          1.2329e+00,  1.3910e+00,  1.4402e+00,  1.4245e+00,  1.4030e+00,
          1.4137e+00,  1.3651e+00,  1.4057e+00,  1.2692e+00,  1.3541e+00,
          1.3187e+00,  1.2742e+00,  1.2613e+00,  1.2465e+00,  1.3168e+00,
          1.2675e+00,  1.3521e+00,  1.2332e+00,  1.2494e+00],
        [ 1.2250e+00,  1.2530e+00,  1.3052e+00,  1.2839e+00,  1.2594e+00,
          1.2300e+00,  1.2391e+00,  1.2227e+00,  1.2227e+00,  2.5890e+00,
          2.6107e+00,  2.5583e+00,  2.8281e+00,  2.5371e+00,  3.8009e+00,
          2.5912e+00,  2.7778e+00,  3.6077e+00,  1.2320e+00,  1.2585e+00,
          1.2279e+00,  1.2460e+00,  1.2440e+00,  1.2392e+00,  1.2587e+00,
          1.2317e+00,  1.2317e+00,  1.2923e+00,  1.2440e+00,  1.2543e+00,
          1.2825e+00,  1.2873e+00,  1.2659e+00,  1.2984e+00,  1.2228e+00,
          1.2569e+00,  1.4083e+00,  1.4593e+00,  1.3952e+00,  1.4203e+00,
          1.4318e+00,  1.4401e+00,  1.3759e+00,  1.2755e+00,  1.3695e+00,
          1.2963e+00,  1.2992e+00,  1.2859e+00,  1.2706e+00,  1.2535e+00,
          1.2924e+00,  1.2897e+00,  1.2571e+00,  1.2737e+00],
        [ 1.2116e+00,  1.2388e+00,  1.2734e+00,  1.2729e+00,  1.2439e+00,
          1.2162e+00,  1.2245e+00,  1.2092e+00,  1.2092e+00,  1.2743e+00,
          1.2987e+00,  1.2865e+00,  1.3266e+00,  1.2660e+00,  1.3208e+00,
          1.2790e+00,  1.1987e+00,  1.3265e+00,  2.8151e+00,  3.0748e+00,
          3.0306e+00,  2.8291e+00,  2.7756e+00,  2.7712e+00,  3.0332e+00,
          2.7649e+00,  2.7649e+00,  1.2464e+00,  1.3073e+00,  1.2386e+00,
          1.2629e+00,  1.2471e+00,  1.2499e+00,  1.2815e+00,  1.2455e+00,
          1.2411e+00,  1.3985e+00,  1.4477e+00,  1.4282e+00,  1.3301e+00,
          1.4174e+00,  1.3985e+00,  1.4133e+00,  1.2770e+00,  1.2779e+00,
          1.3253e+00,  1.2841e+00,  1.2712e+00,  1.2564e+00,  1.3200e+00,
          1.2774e+00,  1.3553e+00,  1.2182e+00,  1.2593e+00],
        [ 1.2137e+00,  1.2412e+00,  1.2765e+00,  1.2758e+00,  1.2466e+00,
          1.2183e+00,  1.2270e+00,  1.2113e+00,  1.2113e+00,  1.2791e+00,
          1.3036e+00,  1.2914e+00,  1.3229e+00,  1.2708e+00,  1.3182e+00,
          1.2838e+00,  1.2560e+00,  1.2776e+00,  1.2610e+00,  1.2547e+00,
          1.3011e+00,  1.2746e+00,  1.2329e+00,  1.2282e+00,  1.2261e+00,
          1.2208e+00,  1.2208e+00,  3.1015e+00,  3.0145e+00,  2.7209e+00,
          2.7916e+00,  3.0997e+00,  2.7309e+00,  2.9789e+00,  2.7446e+00,
          2.7232e+00,  1.4027e+00,  1.4522e+00,  1.4262e+00,  1.3884e+00,
          1.4255e+00,  1.4068e+00,  1.4074e+00,  1.2748e+00,  1.3393e+00,
          1.3330e+00,  1.2884e+00,  1.2231e+00,  1.2131e+00,  1.3312e+00,
          1.2817e+00,  1.3665e+00,  1.1787e+00,  1.2635e+00],
        [ 1.8791e+00,  1.4658e+00,  6.4239e-01,  9.3903e-01,  1.3588e+00,
          1.8058e+00,  1.6720e+00,  1.9173e+00,  1.9173e+00,  1.7036e+00,
          1.3291e+00,  1.5460e+00,  9.4808e-01,  1.7632e+00,  1.6998e-01,
          1.6394e+00,  1.9499e+00,  8.5547e-01,  1.3645e+00,  1.0421e+00,
          7.8813e-01,  1.1732e+00,  1.7420e+00,  1.8118e+00,  1.5848e+00,
          1.9246e+00,  1.9246e+00,  8.9156e-01,  8.7159e-01,  1.9007e+00,
          1.6715e+00,  8.9410e-01,  1.8332e+00,  1.2733e+00,  1.9523e+00,
          1.8626e+00,  1.9235e-01, -1.7908e-02, -4.3871e-02,  1.4455e-01,
          3.5352e-01,  4.1671e-01,  8.9611e-02,  2.0294e+01,  1.8014e+00,
          8.2099e-01,  1.4484e+00,  1.5288e+00,  1.7881e+00,  1.0342e+00,
          1.7012e+00,  4.0710e-01,  1.9335e+00,  1.9572e+00],
        [ 1.2918e+00,  1.3199e+00,  1.3766e+00,  1.3558e+00,  1.3259e+00,
          1.2965e+00,  1.2602e+00,  1.2893e+00,  1.2893e+00,  1.2625e+00,
          1.3813e+00,  1.2748e+00,  1.4096e+00,  1.3481e+00,  1.4573e+00,
          1.2672e+00,  1.3335e+00,  1.3217e+00,  1.3405e+00,  1.3220e+00,
          1.3820e+00,  1.3543e+00,  1.3120e+00,  1.3073e+00,  1.1953e+00,
          1.2998e+00,  1.2998e+00,  1.3501e+00,  1.3968e+00,  1.3215e+00,
          1.0891e+00,  1.3043e+00,  1.1960e+00,  1.3642e+00,  1.1924e+00,
          1.3241e+00,  1.4738e+00,  1.1650e+00,  1.4558e+00,  1.4855e+00,
          1.0108e+00,  9.3550e-01,  1.4889e+00,  1.3482e+00,  8.3123e-01,
          3.6847e+00,  2.6748e+00,  3.7433e+00,  2.9698e+00,  2.2683e+00,
          1.9678e+00,  3.0701e+00,  3.6218e+00,  1.9525e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 376 : 180.10279450797947
Test loss for epoch 376 : 180.6519205108272
Test Precision for epoch 376 : 0.26153846153846155
Test Recall for epoch 376 : 0.26153846153846155
Test F1 for epoch 376 : 0.26153846153846155


theta for epoch 377 : tensor([[ 2.7989e+00,  2.8252e+00,  2.8921e+00,  3.0353e+00,  3.0025e+00,
          2.8031e+00,  2.9831e+00,  2.7967e+00,  2.7967e+00,  1.2684e+00,
          1.2927e+00,  1.2805e+00,  1.3204e+00,  1.2601e+00,  1.3682e+00,
          1.2730e+00,  1.2461e+00,  1.2803e+00,  1.2563e+00,  1.2340e+00,
          1.2506e+00,  1.2697e+00,  1.2287e+00,  1.2240e+00,  1.2432e+00,
          1.2168e+00,  1.2168e+00,  1.2621e+00,  1.3081e+00,  1.2335e+00,
          1.2608e+00,  1.3087e+00,  1.2447e+00,  1.2762e+00,  1.1944e+00,
          1.2360e+00,  1.3929e+00,  1.4421e+00,  1.4264e+00,  1.4049e+00,
          1.4157e+00,  1.3672e+00,  1.4076e+00,  1.2710e+00,  1.3563e+00,
          1.3195e+00,  1.2750e+00,  1.2621e+00,  1.2473e+00,  1.3176e+00,
          1.2683e+00,  1.3529e+00,  1.2340e+00,  1.2502e+00],
        [ 1.2205e+00,  1.2488e+00,  1.3013e+00,  1.2798e+00,  1.2551e+00,
          1.2255e+00,  1.2347e+00,  1.2183e+00,  1.2183e+00,  2.5955e+00,
          2.6175e+00,  2.5666e+00,  2.8382e+00,  2.5455e+00,  3.7883e+00,
          2.5981e+00,  2.7878e+00,  3.5969e+00,  1.2358e+00,  1.2623e+00,
          1.2314e+00,  1.2496e+00,  1.2477e+00,  1.2429e+00,  1.2623e+00,
          1.2354e+00,  1.2354e+00,  1.2922e+00,  1.2438e+00,  1.2540e+00,
          1.2823e+00,  1.2874e+00,  1.2657e+00,  1.2982e+00,  1.2228e+00,
          1.2567e+00,  1.4078e+00,  1.4587e+00,  1.3949e+00,  1.4198e+00,
          1.4313e+00,  1.4396e+00,  1.3756e+00,  1.2754e+00,  1.3692e+00,
          1.2939e+00,  1.2966e+00,  1.2834e+00,  1.2681e+00,  1.2511e+00,
          1.2898e+00,  1.2877e+00,  1.2546e+00,  1.2711e+00],
        [ 1.2051e+00,  1.2324e+00,  1.2670e+00,  1.2666e+00,  1.2376e+00,
          1.2097e+00,  1.2181e+00,  1.2027e+00,  1.2027e+00,  1.2712e+00,
          1.2956e+00,  1.2834e+00,  1.3235e+00,  1.2628e+00,  1.3178e+00,
          1.2759e+00,  1.1952e+00,  1.3234e+00,  2.8238e+00,  3.0844e+00,
          3.0394e+00,  2.8378e+00,  2.7841e+00,  2.7796e+00,  3.0429e+00,
          2.7733e+00,  2.7733e+00,  1.2441e+00,  1.3050e+00,  1.2364e+00,
          1.2607e+00,  1.2448e+00,  1.2477e+00,  1.2794e+00,  1.2433e+00,
          1.2390e+00,  1.3966e+00,  1.4459e+00,  1.4263e+00,  1.3279e+00,
          1.4155e+00,  1.3966e+00,  1.4114e+00,  1.2748e+00,  1.2760e+00,
          1.3203e+00,  1.2791e+00,  1.2662e+00,  1.2514e+00,  1.3150e+00,
          1.2724e+00,  1.3503e+00,  1.2131e+00,  1.2543e+00],
        [ 1.2098e+00,  1.2374e+00,  1.2728e+00,  1.2722e+00,  1.2428e+00,
          1.2145e+00,  1.2231e+00,  1.2074e+00,  1.2074e+00,  1.2786e+00,
          1.3030e+00,  1.2908e+00,  1.3221e+00,  1.2702e+00,  1.3176e+00,
          1.2832e+00,  1.2554e+00,  1.2771e+00,  1.2645e+00,  1.2579e+00,
          1.3046e+00,  1.2782e+00,  1.2365e+00,  1.2318e+00,  1.2296e+00,
          1.2244e+00,  1.2244e+00,  3.1059e+00,  3.0175e+00,  2.7256e+00,
          2.7946e+00,  3.1042e+00,  2.7356e+00,  2.9818e+00,  2.7498e+00,
          2.7278e+00,  1.4023e+00,  1.4518e+00,  1.4255e+00,  1.3879e+00,
          1.4251e+00,  1.4064e+00,  1.4067e+00,  1.2742e+00,  1.3391e+00,
          1.3308e+00,  1.2862e+00,  1.2212e+00,  1.2109e+00,  1.3290e+00,
          1.2796e+00,  1.3644e+00,  1.1764e+00,  1.2613e+00],
        [ 1.8767e+00,  1.4632e+00,  6.4051e-01,  9.3689e-01,  1.3562e+00,
          1.8033e+00,  1.6695e+00,  1.9149e+00,  1.9149e+00,  1.7043e+00,
          1.3298e+00,  1.5468e+00,  9.4894e-01,  1.7641e+00,  1.7103e-01,
          1.6401e+00,  1.9506e+00,  8.5630e-01,  1.3686e+00,  1.0461e+00,
          7.9208e-01,  1.1773e+00,  1.7462e+00,  1.8159e+00,  1.5889e+00,
          1.9288e+00,  1.9288e+00,  8.9276e-01,  8.7276e-01,  1.9019e+00,
          1.6726e+00,  8.9520e-01,  1.8344e+00,  1.2745e+00,  1.9535e+00,
          1.8638e+00,  1.9043e-01, -1.9582e-02, -4.5553e-02,  1.4265e-01,
          3.5139e-01,  4.1445e-01,  8.7803e-02,  2.0353e+01,  1.7908e+00,
          8.2032e-01,  1.4475e+00,  1.5278e+00,  1.7871e+00,  1.0333e+00,
          1.7002e+00,  4.0667e-01,  1.9327e+00,  1.9562e+00],
        [ 1.2892e+00,  1.3174e+00,  1.3741e+00,  1.3533e+00,  1.3234e+00,
          1.2940e+00,  1.2576e+00,  1.2867e+00,  1.2867e+00,  1.2635e+00,
          1.3823e+00,  1.2758e+00,  1.4106e+00,  1.3490e+00,  1.4584e+00,
          1.2682e+00,  1.3345e+00,  1.3230e+00,  1.3457e+00,  1.3272e+00,
          1.3873e+00,  1.3595e+00,  1.3172e+00,  1.3125e+00,  1.2005e+00,
          1.3050e+00,  1.3050e+00,  1.3515e+00,  1.3981e+00,  1.3229e+00,
          1.0906e+00,  1.3057e+00,  1.1975e+00,  1.3656e+00,  1.1938e+00,
          1.3255e+00,  1.4743e+00,  1.1657e+00,  1.4564e+00,  1.4861e+00,
          1.0116e+00,  9.3630e-01,  1.4895e+00,  1.3485e+00,  8.3213e-01,
          3.6877e+00,  2.6754e+00,  3.7443e+00,  2.9706e+00,  2.2684e+00,
          1.9675e+00,  3.0708e+00,  3.6249e+00,  1.9522e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 377 : 180.09038144013311
Test loss for epoch 377 : 180.6432302012216
Test Precision for epoch 377 : 0.26153846153846155
Test Recall for epoch 377 : 0.26153846153846155
Test F1 for epoch 377 : 0.26153846153846155


theta for epoch 378 : tensor([[ 2.8040,  2.8303,  2.8972,  3.0406,  3.0078,  2.8082,  2.9884,  2.8018,
          2.8018,  1.2669,  1.2912,  1.2790,  1.3189,  1.2585,  1.3668,  1.2715,
          1.2445,  1.2788,  1.2523,  1.2301,  1.2467,  1.2658,  1.2247,  1.2200,
          1.2393,  1.2128,  1.2128,  1.2603,  1.3063,  1.2316,  1.2590,  1.3070,
          1.2428,  1.2744,  1.1925,  1.2341,  1.3918,  1.4410,  1.4253,  1.4039,
          1.4146,  1.3661,  1.4065,  1.2696,  1.3554,  1.3203,  1.2758,  1.2630,
          1.2481,  1.3184,  1.2691,  1.3537,  1.2348,  1.2510],
        [ 1.2214,  1.2496,  1.3023,  1.2809,  1.2560,  1.2264,  1.2355,  1.2191,
          1.2191,  2.6016,  2.6238,  2.5745,  2.8477,  2.5533,  3.7758,  2.6044,
          2.7974,  3.5862,  1.2327,  1.2593,  1.2285,  1.2465,  1.2445,  1.2397,
          1.2590,  1.2321,  1.2321,  1.2915,  1.2430,  1.2531,  1.2814,  1.2869,
          1.2647,  1.2973,  1.2220,  1.2557,  1.4071,  1.4581,  1.3945,  1.4191,
          1.4307,  1.4389,  1.3751,  1.2752,  1.3687,  1.2953,  1.2982,  1.2849,
          1.2696,  1.2527,  1.2913,  1.2889,  1.2561,  1.2726],
        [ 1.2076,  1.2349,  1.2695,  1.2691,  1.2400,  1.2122,  1.2205,  1.2052,
          1.2052,  1.2728,  1.2972,  1.2850,  1.3251,  1.2644,  1.3192,  1.2775,
          1.1968,  1.3250,  2.8235,  3.0850,  3.0394,  2.8375,  2.7834,  2.7789,
          3.0434,  2.7726,  2.7726,  1.2451,  1.3058,  1.2374,  1.2617,  1.2457,
          1.2487,  1.2803,  1.2442,  1.2399,  1.3974,  1.4467,  1.4272,  1.3287,
          1.4164,  1.3974,  1.4122,  1.2753,  1.2770,  1.3240,  1.2828,  1.2699,
          1.2551,  1.3185,  1.2761,  1.3538,  1.2168,  1.2580],
        [ 1.2109,  1.2385,  1.2738,  1.2733,  1.2439,  1.2156,  1.2242,  1.2085,
          1.2085,  1.2782,  1.3027,  1.2904,  1.3215,  1.2698,  1.3173,  1.2829,
          1.2551,  1.2768,  1.2618,  1.2550,  1.3019,  1.2754,  1.2337,  1.2290,
          1.2268,  1.2216,  1.2216,  3.1093,  3.0194,  2.7291,  2.7965,  3.1076,
          2.7392,  2.9836,  2.7539,  2.7314,  1.4019,  1.4514,  1.4249,  1.3875,
          1.4248,  1.4060,  1.4061,  1.2737,  1.3388,  1.3324,  1.2878,  1.2228,
          1.2125,  1.3306,  1.2811,  1.3660,  1.1779,  1.2628],
        [ 1.8791,  1.4657,  0.6432,  0.9394,  1.3588,  1.8057,  1.6719,  1.9172,
          1.9172,  1.7052,  1.3308,  1.5478,  0.9503,  1.7650,  0.1729,  1.6410,
          1.9514,  0.8577,  1.3678,  1.0456,  0.7917,  1.1766,  1.7451,  1.8148,
          1.5881,  1.9277,  1.9277,  0.8939,  0.8739,  1.9025,  1.6732,  0.8963,
          1.8350,  1.2753,  1.9541,  1.8644,  0.1878, -0.0219, -0.0479,  0.1401,
          0.3485,  0.4115,  0.0853, 20.4101,  1.7805,  0.8236,  1.4506,  1.5307,
          1.7900,  1.0366,  1.7032,  0.4101,  1.9357,  1.9590],
        [ 1.2889,  1.3171,  1.3738,  1.3529,  1.3230,  1.2936,  1.2573,  1.2864,
          1.2864,  1.2611,  1.3800,  1.2734,  1.4084,  1.3467,  1.4563,  1.2658,
          1.3322,  1.3208,  1.3410,  1.3224,  1.3825,  1.3548,  1.3125,  1.3077,
          1.1955,  1.3002,  1.3002,  1.3490,  1.3958,  1.3204,  1.0879,  1.3032,
          1.1948,  1.3632,  1.1911,  1.3230,  1.4728,  1.1637,  1.4547,  1.4845,
          1.0094,  0.9340,  1.4879,  1.3466,  0.8300,  3.6966,  2.6819,  3.7514,
          2.9772,  2.2743,  1.9731,  3.0774,  3.6340,  1.9578]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 378 : 180.08090855795143
Test loss for epoch 378 : 180.6347505231061
Test Precision for epoch 378 : 0.26153846153846155
Test Recall for epoch 378 : 0.26153846153846155
Test F1 for epoch 378 : 0.26153846153846155


theta for epoch 379 : tensor([[ 2.8088,  2.8351,  2.9020,  3.0456,  3.0128,  2.8130,  2.9934,  2.8066,
          2.8066,  1.2655,  1.2898,  1.2776,  1.3176,  1.2571,  1.3655,  1.2701,
          1.2431,  1.2776,  1.2522,  1.2299,  1.2466,  1.2657,  1.2245,  1.2199,
          1.2391,  1.2126,  1.2126,  1.2592,  1.3053,  1.2305,  1.2579,  1.3059,
          1.2417,  1.2733,  1.1913,  1.2330,  1.3914,  1.4407,  1.4249,  1.4035,
          1.4143,  1.3657,  1.4062,  1.2690,  1.3552,  1.3168,  1.2723,  1.2595,
          1.2446,  1.3149,  1.2656,  1.3502,  1.2313,  1.2475],
        [ 1.2220,  1.2502,  1.3030,  1.2817,  1.2566,  1.2270,  1.2361,  1.2197,
          1.2197,  2.6075,  2.6299,  2.5820,  2.8569,  2.5609,  3.7634,  2.6105,
          2.8066,  3.5757,  1.2340,  1.2607,  1.2297,  1.2477,  1.2457,  1.2409,
          1.2602,  1.2333,  1.2333,  1.2914,  1.2428,  1.2528,  1.2811,  1.2869,
          1.2644,  1.2970,  1.2219,  1.2554,  1.4071,  1.4581,  1.3947,  1.4191,
          1.4307,  1.4390,  1.3754,  1.2754,  1.3689,  1.2923,  1.2950,  1.2818,
          1.2664,  1.2497,  1.2881,  1.2864,  1.2529,  1.2694],
        [ 1.2071,  1.2345,  1.2691,  1.2687,  1.2396,  1.2117,  1.2201,  1.2047,
          1.2047,  1.2716,  1.2960,  1.2837,  1.3238,  1.2631,  1.3179,  1.2762,
          1.1953,  1.3237,  2.8285,  3.0908,  3.0445,  2.8424,  2.7879,  2.7834,
          3.0492,  2.7771,  2.7771,  1.2441,  1.3048,  1.2365,  1.2609,  1.2447,
          1.2478,  1.2796,  1.2434,  1.2391,  1.3971,  1.4465,  1.4269,  1.3283,
          1.4162,  1.3971,  1.4119,  1.2747,  1.2767,  1.3202,  1.2789,  1.2661,
          1.2512,  1.3145,  1.2722,  1.3499,  1.2128,  1.2541],
        [ 1.2114,  1.2391,  1.2743,  1.2738,  1.2444,  1.2161,  1.2247,  1.2090,
          1.2090,  1.2777,  1.3022,  1.2899,  1.3208,  1.2692,  1.3168,  1.2824,
          1.2545,  1.2764,  1.2629,  1.2559,  1.3030,  1.2766,  1.2348,  1.2301,
          1.2279,  1.2228,  1.2228,  3.1132,  3.0219,  2.7332,  2.7988,  3.1115,
          2.7432,  2.9860,  2.7585,  2.7354,  1.4020,  1.4516,  1.4248,  1.3876,
          1.4249,  1.4062,  1.4060,  1.2736,  1.3391,  1.3298,  1.2851,  1.2204,
          1.2098,  1.3279,  1.2784,  1.3633,  1.1752,  1.2601],
        [ 1.8803,  1.4668,  0.6440,  0.9402,  1.3599,  1.8070,  1.6731,  1.9185,
          1.9185,  1.7053,  1.3308,  1.5480,  0.9503,  1.7652,  0.1730,  1.6410,
          1.9516,  0.8576,  1.3691,  1.0470,  0.7929,  1.1779,  1.7466,  1.8163,
          1.5897,  1.9292,  1.9292,  0.8940,  0.8740,  1.9028,  1.6735,  0.8963,
          1.8353,  1.2755,  1.9544,  1.8647,  0.1865, -0.0230, -0.0490,  0.1387,
          0.3470,  0.4098,  0.0841, 20.4682,  1.7725,  0.8215,  1.4483,  1.5283,
          1.7878,  1.0343,  1.7009,  0.4081,  1.9336,  1.9569],
        [ 1.2915,  1.3197,  1.3763,  1.3556,  1.3257,  1.2963,  1.2599,  1.2891,
          1.2891,  1.2628,  1.3816,  1.2751,  1.4100,  1.3482,  1.4579,  1.2676,
          1.3338,  1.3226,  1.3442,  1.3256,  1.3857,  1.3580,  1.3157,  1.3109,
          1.1989,  1.3034,  1.3034,  1.3508,  1.3975,  1.3221,  1.0900,  1.3051,
          1.1968,  1.3650,  1.1931,  1.3247,  1.4742,  1.1655,  1.4562,  1.4860,
          1.0113,  0.9361,  1.4894,  1.3478,  0.8320,  3.6978,  2.6806,  3.7508,
          2.9762,  2.2726,  1.9709,  3.0764,  3.6353,  1.9556]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 379 : 180.07456159047211
Test loss for epoch 379 : 180.63510117966524
Test Precision for epoch 379 : 0.26153846153846155
Test Recall for epoch 379 : 0.26153846153846155
Test F1 for epoch 379 : 0.26153846153846155


theta for epoch 380 : tensor([[ 2.8079,  2.8343,  2.9012,  3.0450,  3.0122,  2.8122,  2.9928,  2.8058,
          2.8058,  1.2676,  1.2919,  1.2796,  1.3196,  1.2592,  1.3677,  1.2722,
          1.2452,  1.2799,  1.2536,  1.2314,  1.2481,  1.2671,  1.2259,  1.2212,
          1.2405,  1.2140,  1.2140,  1.2611,  1.3072,  1.2324,  1.2598,  1.3078,
          1.2436,  1.2753,  1.1933,  1.2350,  1.3925,  1.4418,  1.4260,  1.4046,
          1.4154,  1.3669,  1.4072,  1.2700,  1.3564,  1.3214,  1.2769,  1.2641,
          1.2493,  1.3195,  1.2702,  1.3547,  1.2360,  1.2521],
        [ 1.2178,  1.2462,  1.2993,  1.2779,  1.2525,  1.2229,  1.2319,  1.2156,
          1.2156,  2.6142,  2.6368,  2.5904,  2.8669,  2.5693,  3.7524,  2.6175,
          2.8166,  3.5664,  1.2336,  1.2602,  1.2292,  1.2472,  1.2451,  1.2403,
          1.2595,  1.2327,  1.2327,  1.2911,  1.2423,  1.2522,  1.2805,  1.2866,
          1.2638,  1.2965,  1.2215,  1.2548,  1.4062,  1.4572,  1.3940,  1.4183,
          1.4298,  1.4382,  1.3747,  1.2748,  1.3682,  1.2944,  1.2973,  1.2841,
          1.2687,  1.2520,  1.2903,  1.2882,  1.2552,  1.2716],
        [ 1.2033,  1.2307,  1.2653,  1.2650,  1.2359,  1.2079,  1.2163,  1.2009,
          1.2009,  1.2714,  1.2958,  1.2835,  1.3237,  1.2630,  1.3177,  1.2761,
          1.1950,  1.3236,  2.8323,  3.0955,  3.0486,  2.8463,  2.7913,  2.7869,
          3.0539,  2.7806,  2.7806,  1.2438,  1.3044,  1.2363,  1.2607,  1.2444,
          1.2476,  1.2793,  1.2431,  1.2388,  1.3966,  1.4459,  1.4263,  1.3276,
          1.4156,  1.3965,  1.4113,  1.2739,  1.2762,  1.3228,  1.2815,  1.2687,
          1.2538,  1.3169,  1.2748,  1.3522,  1.2153,  1.2566],
        [ 1.2081,  1.2358,  1.2711,  1.2707,  1.2412,  1.2128,  1.2214,  1.2057,
          1.2057,  1.2775,  1.3020,  1.2896,  1.3204,  1.2690,  1.3167,  1.2822,
          1.2543,  1.2762,  1.2627,  1.2554,  1.3027,  1.2763,  1.2346,  1.2299,
          1.2276,  1.2225,  1.2225,  3.1175,  3.0247,  2.7375,  2.8016,  3.1158,
          2.7475,  2.9887,  2.7633,  2.7397,  1.4014,  1.4510,  1.4239,  1.3870,
          1.4244,  1.4055,  1.4051,  1.2729,  1.3385,  1.3319,  1.2872,  1.2226,
          1.2119,  1.3300,  1.2805,  1.3655,  1.1773,  1.2622],
        [ 1.8787,  1.4654,  0.6436,  0.9394,  1.3586,  1.8054,  1.6716,  1.9169,
          1.9169,  1.7067,  1.3324,  1.5495,  0.9523,  1.7666,  0.1755,  1.6424,
          1.9529,  0.8598,  1.3708,  1.0489,  0.7950,  1.1796,  1.7480,  1.8177,
          1.5912,  1.9305,  1.9305,  0.8962,  0.8761,  1.9042,  1.6749,  0.8983,
          1.8367,  1.2773,  1.9557,  1.8661,  0.1837, -0.0256, -0.0515,  0.1360,
          0.3440,  0.4067,  0.0814, 20.5245,  1.7639,  0.8260,  1.4525,  1.5325,
          1.7918,  1.0388,  1.7050,  0.4128,  1.9376,  1.9607],
        [ 1.2861,  1.3143,  1.3710,  1.3502,  1.3203,  1.2909,  1.2545,  1.2836,
          1.2836,  1.2602,  1.3792,  1.2725,  1.4076,  1.3457,  1.4557,  1.2649,
          1.3313,  1.3202,  1.3416,  1.3230,  1.3832,  1.3554,  1.3131,  1.3084,
          1.1960,  1.3009,  1.3009,  1.3483,  1.3951,  1.3196,  1.0871,  1.3025,
          1.1940,  1.3625,  1.1903,  1.3222,  1.4721,  1.1628,  1.4540,  1.4839,
          1.0084,  0.9331,  1.4873,  1.3454,  0.8290,  3.7084,  2.6888,  3.7597,
          2.9846,  2.2801,  1.9781,  3.0847,  3.6461,  1.9628]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 380 : 180.07005675364314
Test loss for epoch 380 : 180.62874468255382
Test Precision for epoch 380 : 0.26153846153846155
Test Recall for epoch 380 : 0.26153846153846155
Test F1 for epoch 380 : 0.26153846153846155


theta for epoch 381 : tensor([[ 2.8179,  2.8442,  2.9112,  3.0552,  3.0223,  2.8221,  3.0030,  2.8157,
          2.8157,  1.2634,  1.2878,  1.2754,  1.3155,  1.2549,  1.3637,  1.2680,
          1.2410,  1.2758,  1.2486,  1.2264,  1.2431,  1.2621,  1.2209,  1.2162,
          1.2355,  1.2089,  1.2089,  1.2571,  1.3033,  1.2283,  1.2558,  1.3039,
          1.2396,  1.2713,  1.1891,  1.2309,  1.3904,  1.4397,  1.4239,  1.4026,
          1.4133,  1.3647,  1.4051,  1.2676,  1.3544,  1.3151,  1.2706,  1.2578,
          1.2429,  1.3131,  1.2638,  1.3485,  1.2296,  1.2457],
        [ 1.2223,  1.2506,  1.3036,  1.2825,  1.2569,  1.2273,  1.2364,  1.2201,
          1.2201,  2.6197,  2.6424,  2.5975,  2.8757,  2.5765,  3.7406,  2.6232,
          2.8254,  3.5565,  1.2324,  1.2591,  1.2281,  1.2460,  1.2438,  1.2390,
          1.2582,  1.2314,  1.2314,  1.2909,  1.2420,  1.2518,  1.2802,  1.2865,
          1.2634,  1.2961,  1.2213,  1.2544,  1.4064,  1.4575,  1.3945,  1.4185,
          1.4301,  1.4385,  1.3752,  1.2751,  1.3686,  1.2912,  1.2938,  1.2806,
          1.2652,  1.2488,  1.2868,  1.2855,  1.2517,  1.2681],
        [ 1.2076,  1.2350,  1.2696,  1.2694,  1.2402,  1.2122,  1.2206,  1.2052,
          1.2052,  1.2718,  1.2962,  1.2839,  1.3240,  1.2633,  1.3179,  1.2765,
          1.1953,  1.3239,  2.8341,  3.0981,  3.0507,  2.8481,  2.7928,  2.7883,
          3.0565,  2.7820,  2.7820,  1.2440,  1.3046,  1.2366,  1.2610,  1.2447,
          1.2479,  1.2797,  1.2434,  1.2392,  1.3974,  1.4468,  1.4272,  1.3284,
          1.4166,  1.3974,  1.4122,  1.2745,  1.2771,  1.3202,  1.2788,  1.2660,
          1.2511,  1.3141,  1.2720,  1.3494,  1.2126,  1.2539],
        [ 1.2120,  1.2396,  1.2748,  1.2743,  1.2450,  1.2167,  1.2253,  1.2096,
          1.2096,  1.2770,  1.3015,  1.2892,  1.3197,  1.2685,  1.3162,  1.2817,
          1.2539,  1.2758,  1.2614,  1.2539,  1.3015,  1.2750,  1.2333,  1.2286,
          1.2263,  1.2213,  1.2213,  3.1212,  3.0269,  2.7412,  2.8038,  3.1195,
          2.7512,  2.9908,  2.7676,  2.7434,  1.4017,  1.4514,  1.4240,  1.3873,
          1.4248,  1.4059,  1.4052,  1.2731,  1.3389,  1.3290,  1.2843,  1.2198,
          1.2089,  1.3271,  1.2776,  1.3626,  1.1743,  1.2592],
        [ 1.8831,  1.4696,  0.6469,  0.9429,  1.3628,  1.8097,  1.6759,  1.9212,
          1.9212,  1.7065,  1.3321,  1.5494,  0.9521,  1.7666,  0.1754,  1.6423,
          1.9530,  0.8595,  1.3700,  1.0481,  0.7940,  1.1788,  1.7473,  1.8170,
          1.5906,  1.9298,  1.9298,  0.8959,  0.8759,  1.9042,  1.6748,  0.8980,
          1.8367,  1.2770,  1.9557,  1.8661,  0.1825, -0.0265, -0.0525,  0.1348,
          0.3427,  0.4052,  0.0803, 20.5818,  1.7577,  0.8233,  1.4497,  1.5295,
          1.7891,  1.0359,  1.7021,  0.4103,  1.9350,  1.9580],
        [ 1.2926,  1.3208,  1.3774,  1.3566,  1.3267,  1.2974,  1.2610,  1.2901,
          1.2901,  1.2623,  1.3811,  1.2745,  1.4095,  1.3476,  1.4576,  1.2670,
          1.3332,  1.3224,  1.3425,  1.3239,  1.3841,  1.3563,  1.3140,  1.3093,
          1.1972,  1.3018,  1.3018,  1.3503,  1.3970,  1.3215,  1.0894,  1.3046,
          1.1962,  1.3645,  1.1924,  1.3241,  1.4739,  1.1651,  1.4558,  1.4858,
          1.0109,  0.9357,  1.4891,  1.3471,  0.8317,  3.7090,  2.6868,  3.7584,
          2.9829,  2.2775,  1.9750,  3.0830,  3.6467,  1.9597]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 381 : 180.06549075941618
Test loss for epoch 381 : 180.63245147534747
Test Precision for epoch 381 : 0.26153846153846155
Test Recall for epoch 381 : 0.26153846153846155
Test F1 for epoch 381 : 0.26153846153846155


theta for epoch 382 : tensor([[ 2.8137,  2.8401,  2.9071,  3.0513,  3.0184,  2.8180,  2.9991,  2.8116,
          2.8116,  1.2674,  1.2918,  1.2794,  1.3195,  1.2589,  1.3677,  1.2721,
          1.2451,  1.2800,  1.2535,  1.2314,  1.2481,  1.2670,  1.2257,  1.2211,
          1.2404,  1.2138,  1.2138,  1.2611,  1.3072,  1.2323,  1.2597,  1.3078,
          1.2435,  1.2752,  1.1931,  1.2348,  1.3928,  1.4421,  1.4263,  1.4050,
          1.4158,  1.3672,  1.4076,  1.2701,  1.3570,  1.3216,  1.2771,  1.2644,
          1.2495,  1.3196,  1.2704,  1.3549,  1.2362,  1.2523],
        [ 1.2159,  1.2444,  1.2979,  1.2764,  1.2506,  1.2209,  1.2300,  1.2136,
          1.2136,  2.6266,  2.6495,  2.6060,  2.8857,  2.5850,  3.7305,  2.6303,
          2.8355,  3.5484,  1.2338,  1.2606,  1.2294,  1.2473,  1.2451,  1.2403,
          1.2594,  1.2327,  1.2327,  1.2905,  1.2415,  1.2512,  1.2796,  1.2862,
          1.2628,  1.2956,  1.2209,  1.2539,  1.4056,  1.4566,  1.3939,  1.4177,
          1.4293,  1.4376,  1.3746,  1.2745,  1.3678,  1.2934,  1.2962,  1.2830,
          1.2676,  1.2512,  1.2892,  1.2875,  1.2541,  1.2705],
        [ 1.2006,  1.2281,  1.2628,  1.2625,  1.2333,  1.2052,  1.2137,  1.1982,
          1.1982,  1.2703,  1.2947,  1.2823,  1.3225,  1.2618,  1.3164,  1.2750,
          1.1935,  1.3224,  2.8406,  3.1054,  3.0575,  2.8546,  2.7989,  2.7944,
          3.0639,  2.7881,  2.7881,  1.2427,  1.3032,  1.2353,  1.2598,  1.2433,
          1.2466,  1.2784,  1.2421,  1.2379,  1.3961,  1.4455,  1.4259,  1.3269,
          1.4153,  1.3960,  1.4109,  1.2730,  1.2757,  1.3216,  1.2802,  1.2675,
          1.2525,  1.3153,  1.2734,  1.3507,  1.2139,  1.2553],
        [ 1.2066,  1.2343,  1.2697,  1.2693,  1.2398,  1.2113,  1.2200,  1.2042,
          1.2042,  1.2768,  1.3013,  1.2889,  1.3192,  1.2682,  1.3160,  1.2814,
          1.2536,  1.2756,  1.2630,  1.2552,  1.3030,  1.2766,  1.2349,  1.2303,
          1.2279,  1.2229,  1.2229,  3.1258,  3.0301,  2.7458,  2.8069,  3.1241,
          2.7558,  2.9940,  2.7728,  2.7481,  1.4011,  1.4507,  1.4231,  1.3866,
          1.4241,  1.4053,  1.4043,  1.2723,  1.3383,  1.3312,  1.2865,  1.2221,
          1.2111,  1.3293,  1.2797,  1.3648,  1.1764,  1.2614],
        [ 1.8794,  1.4661,  0.6448,  0.9403,  1.3593,  1.8061,  1.6722,  1.9176,
          1.9176,  1.7079,  1.3337,  1.5509,  0.9540,  1.7679,  0.1779,  1.6436,
          1.9542,  0.8616,  1.3730,  1.0513,  0.7974,  1.1819,  1.7502,  1.8199,
          1.5936,  1.9326,  1.9326,  0.8980,  0.8780,  1.9055,  1.6763,  0.9000,
          1.8381,  1.2789,  1.9570,  1.8674,  0.1799, -0.0289, -0.0548,  0.1323,
          0.3398,  0.4023,  0.0779, 20.6372,  1.7509,  0.8278,  1.4540,  1.5338,
          1.7931,  1.0406,  1.7063,  0.4149,  1.9390,  1.9619],
        [ 1.2850,  1.3132,  1.3699,  1.3491,  1.3192,  1.2898,  1.2534,  1.2825,
          1.2825,  1.2594,  1.3784,  1.2717,  1.4068,  1.3449,  1.4552,  1.2642,
          1.3305,  1.3197,  1.3417,  1.3230,  1.3833,  1.3556,  1.3133,  1.3085,
          1.1961,  1.3010,  1.3010,  1.3477,  1.3945,  1.3189,  1.0864,  1.3019,
          1.1933,  1.3619,  1.1896,  1.3215,  1.4717,  1.1624,  1.4535,  1.4836,
          1.0079,  0.9326,  1.4869,  1.3445,  0.8285,  3.7201,  2.6955,  3.7680,
          2.9919,  2.2855,  1.9826,  3.0919,  3.6582,  1.9673]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 382 : 180.06043673926197
Test loss for epoch 382 : 180.62457342245875
Test Precision for epoch 382 : 0.26153846153846155
Test Recall for epoch 382 : 0.26153846153846155
Test F1 for epoch 382 : 0.26153846153846155


theta for epoch 383 : tensor([[ 2.8253,  2.8516,  2.9186,  3.0631,  3.0302,  2.8295,  3.0109,  2.8231,
          2.8231,  1.2626,  1.2870,  1.2746,  1.3147,  1.2541,  1.3631,  1.2672,
          1.2402,  1.2753,  1.2469,  1.2248,  1.2416,  1.2605,  1.2191,  1.2145,
          1.2338,  1.2072,  1.2072,  1.2562,  1.3025,  1.2274,  1.2549,  1.3030,
          1.2387,  1.2705,  1.1881,  1.2300,  1.3901,  1.4394,  1.4236,  1.4023,
          1.4130,  1.3644,  1.4048,  1.2669,  1.3542,  1.3148,  1.2703,  1.2576,
          1.2427,  1.3128,  1.2635,  1.3481,  1.2294,  1.2454],
        [ 1.2215,  1.2498,  1.3032,  1.2820,  1.2560,  1.2264,  1.2355,  1.2192,
          1.2192,  2.6323,  2.6553,  2.6132,  2.8945,  2.5922,  3.7197,  2.6361,
          2.8442,  3.5395,  1.2315,  1.2583,  1.2272,  1.2450,  1.2426,  1.2377,
          1.2569,  1.2302,  1.2302,  1.2903,  1.2411,  1.2508,  1.2792,  1.2861,
          1.2624,  1.2951,  1.2206,  1.2534,  1.4057,  1.4567,  1.3943,  1.4178,
          1.4294,  1.4378,  1.3749,  1.2745,  1.3680,  1.2903,  1.2928,  1.2797,
          1.2642,  1.2481,  1.2858,  1.2849,  1.2507,  1.2671],
        [ 1.2068,  1.2343,  1.2690,  1.2688,  1.2395,  1.2114,  1.2199,  1.2044,
          1.2044,  1.2717,  1.2961,  1.2837,  1.3239,  1.2632,  1.3175,  1.2764,
          1.1949,  1.3237,  2.8410,  3.1066,  3.0581,  2.8549,  2.7988,  2.7943,
          3.0650,  2.7880,  2.7880,  1.2437,  1.3041,  1.2364,  1.2609,  1.2443,
          1.2477,  1.2795,  1.2432,  1.2390,  1.3975,  1.4468,  1.4273,  1.3283,
          1.4167,  1.3974,  1.4122,  1.2741,  1.2771,  1.3200,  1.2786,  1.2659,
          1.2509,  1.3136,  1.2718,  1.3490,  1.2123,  1.2536],
        [ 1.2115,  1.2392,  1.2743,  1.2739,  1.2446,  1.2162,  1.2248,  1.2091,
          1.2091,  1.2763,  1.3009,  1.2884,  1.3186,  1.2678,  1.3156,  1.2810,
          1.2532,  1.2752,  1.2606,  1.2526,  1.3006,  1.2742,  1.2325,  1.2279,
          1.2254,  1.2205,  1.2205,  3.1298,  3.0326,  2.7496,  2.8093,  3.1281,
          2.7597,  2.9964,  2.7772,  2.7519,  1.4013,  1.4510,  1.4231,  1.3868,
          1.4244,  1.4055,  1.4042,  1.2724,  1.3385,  1.3284,  1.2837,  1.2195,
          1.2083,  1.3265,  1.2769,  1.3620,  1.1736,  1.2585],
        [ 1.8847,  1.4713,  0.6490,  0.9447,  1.3645,  1.8114,  1.6775,  1.9229,
          1.9229,  1.7078,  1.3335,  1.5509,  0.9540,  1.7680,  0.1779,  1.6435,
          1.9543,  0.8614,  1.3713,  1.0498,  0.7957,  1.1802,  1.7486,  1.8183,
          1.5921,  1.9311,  1.9311,  0.8978,  0.8777,  1.9055,  1.6762,  0.8997,
          1.8381,  1.2786,  1.9570,  1.8674,  0.1787, -0.0298, -0.0558,  0.1311,
          0.3385,  0.4009,  0.0768, 20.6935,  1.7461,  0.8254,  1.4514,  1.5311,
          1.7906,  1.0379,  1.7037,  0.4127,  1.9366,  1.9594],
        [ 1.2924,  1.3206,  1.3772,  1.3564,  1.3266,  1.2972,  1.2609,  1.2900,
          1.2900,  1.2614,  1.3803,  1.2737,  1.4087,  1.3467,  1.4570,  1.2662,
          1.3323,  1.3219,  1.3414,  1.3227,  1.3829,  1.3552,  1.3129,  1.3081,
          1.1959,  1.3006,  1.3006,  1.3495,  1.3963,  1.3206,  1.0886,  1.3038,
          1.1953,  1.3637,  1.1915,  1.3232,  1.4734,  1.1645,  1.4552,  1.4853,
          1.0102,  0.9350,  1.4886,  1.3460,  0.8309,  3.7212,  2.6939,  3.7674,
          2.9907,  2.2832,  1.9798,  3.0907,  3.6593,  1.9645]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 383 : 180.05237003962293
Test loss for epoch 383 : 180.62459622516246
Test Precision for epoch 383 : 0.26153846153846155
Test Recall for epoch 383 : 0.26153846153846155
Test F1 for epoch 383 : 0.26153846153846155


theta for epoch 384 : tensor([[ 2.8220,  2.8484,  2.9154,  3.0601,  3.0272,  2.8262,  3.0079,  2.8198,
          2.8198,  1.2660,  1.2904,  1.2780,  1.3181,  1.2575,  1.3665,  1.2707,
          1.2437,  1.2789,  1.2521,  1.2300,  1.2467,  1.2656,  1.2242,  1.2196,
          1.2389,  1.2123,  1.2123,  1.2598,  1.3060,  1.2309,  1.2584,  1.3065,
          1.2421,  1.2740,  1.1917,  1.2335,  1.3922,  1.4415,  1.4257,  1.4044,
          1.4151,  1.3666,  1.4069,  1.2691,  1.3563,  1.3205,  1.2761,  1.2634,
          1.2485,  1.3185,  1.2693,  1.3537,  1.2352,  1.2512],
        [ 1.2158,  1.2443,  1.2981,  1.2766,  1.2504,  1.2207,  1.2298,  1.2134,
          1.2134,  2.6388,  2.6619,  2.6212,  2.9041,  2.6003,  3.7102,  2.6429,
          2.8538,  3.5320,  1.2336,  1.2605,  1.2291,  1.2471,  1.2446,  1.2398,
          1.2589,  1.2323,  1.2323,  1.2900,  1.2407,  1.2503,  1.2787,  1.2859,
          1.2619,  1.2947,  1.2203,  1.2529,  1.4049,  1.4560,  1.3938,  1.4171,
          1.4287,  1.4371,  1.3744,  1.2739,  1.3672,  1.2922,  1.2949,  1.2818,
          1.2664,  1.2503,  1.2879,  1.2866,  1.2529,  1.2692],
        [ 1.2000,  1.2277,  1.2624,  1.2622,  1.2329,  1.2047,  1.2132,  1.1977,
          1.1977,  1.2696,  1.2940,  1.2816,  1.3218,  1.2610,  1.3155,  1.2743,
          1.1925,  1.3216,  2.8482,  3.1146,  3.0656,  2.8622,  2.8056,  2.8012,
          3.0730,  2.7949,  2.7949,  1.2420,  1.3024,  1.2348,  1.2593,  1.2426,
          1.2461,  1.2779,  1.2416,  1.2374,  1.3959,  1.4453,  1.4257,  1.3266,
          1.4152,  1.3958,  1.4107,  1.2724,  1.2754,  1.3206,  1.2792,  1.2665,
          1.2515,  1.3140,  1.2724,  1.3494,  1.2129,  1.2542],
        [ 1.2067,  1.2344,  1.2698,  1.2694,  1.2398,  1.2114,  1.2200,  1.2042,
          1.2042,  1.2760,  1.3005,  1.2880,  1.3180,  1.2674,  1.3152,  1.2806,
          1.2528,  1.2749,  1.2628,  1.2545,  1.3028,  1.2764,  1.2348,  1.2301,
          1.2276,  1.2228,  1.2228,  3.1344,  3.0359,  2.7541,  2.8124,  3.1327,
          2.7642,  2.9995,  2.7823,  2.7564,  1.4007,  1.4504,  1.4223,  1.3862,
          1.4238,  1.4049,  1.4034,  1.2718,  1.3378,  1.3303,  1.2855,  1.2214,
          1.2102,  1.3283,  1.2787,  1.3639,  1.1754,  1.2604],
        [ 1.8813,  1.4681,  0.6470,  0.9423,  1.3614,  1.8080,  1.6742,  1.9195,
          1.9195,  1.7088,  1.3348,  1.5521,  0.9556,  1.7690,  0.1800,  1.6445,
          1.9553,  0.8632,  1.3747,  1.0532,  0.7993,  1.1836,  1.7519,  1.8215,
          1.5954,  1.9343,  1.9343,  0.8997,  0.8796,  1.9067,  1.6775,  0.9015,
          1.8393,  1.2803,  1.9582,  1.8686,  0.1763, -0.0320, -0.0580,  0.1287,
          0.3359,  0.3981,  0.0745, 20.7481,  1.7407,  0.8294,  1.4551,  1.5348,
          1.7941,  1.0420,  1.7073,  0.4168,  1.9402,  1.9629],
        [ 1.2857,  1.3139,  1.3705,  1.3498,  1.3199,  1.2905,  1.2541,  1.2833,
          1.2833,  1.2588,  1.3779,  1.2711,  1.4062,  1.3442,  1.4548,  1.2637,
          1.3298,  1.3195,  1.3415,  1.3228,  1.3831,  1.3554,  1.3131,  1.3083,
          1.1958,  1.3008,  1.3008,  1.3473,  1.3941,  1.3184,  1.0860,  1.3015,
          1.1929,  1.3615,  1.1891,  1.3210,  1.4714,  1.1621,  1.4532,  1.4834,
          1.0076,  0.9323,  1.4866,  1.3438,  0.8281,  3.7317,  2.7019,  3.7764,
          2.9990,  2.2904,  1.9866,  3.0989,  3.6700,  1.9712]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 384 : 180.04383086485365
Test loss for epoch 384 : 180.61383610655827
Test Precision for epoch 384 : 0.26153846153846155
Test Recall for epoch 384 : 0.26153846153846155
Test F1 for epoch 384 : 0.26153846153846155


theta for epoch 385 : tensor([[ 2.8314,  2.8577,  2.9247,  3.0697,  3.0368,  2.8356,  3.0175,  2.8292,
          2.8292,  1.2628,  1.2873,  1.2748,  1.3150,  1.2543,  1.3635,  1.2675,
          1.2405,  1.2758,  1.2468,  1.2247,  1.2415,  1.2604,  1.2190,  1.2143,
          1.2337,  1.2070,  1.2070,  1.2564,  1.3027,  1.2276,  1.2552,  1.3033,
          1.2388,  1.2707,  1.1883,  1.2301,  1.3903,  1.4396,  1.4238,  1.4026,
          1.4133,  1.3646,  1.4050,  1.2669,  1.3544,  1.3157,  1.2712,  1.2586,
          1.2436,  1.3137,  1.2644,  1.3489,  1.2304,  1.2463],
        [ 1.2195,  1.2480,  1.3017,  1.2804,  1.2541,  1.2245,  1.2336,  1.2172,
          1.2172,  2.6450,  2.6682,  2.6288,  2.9133,  2.6080,  3.7008,  2.6492,
          2.8630,  3.5245,  1.2311,  1.2580,  1.2267,  1.2446,  1.2419,  1.2371,
          1.2562,  1.2296,  1.2296,  1.2898,  1.2404,  1.2498,  1.2783,  1.2858,
          1.2615,  1.2943,  1.2200,  1.2525,  1.4049,  1.4561,  1.3940,  1.4171,
          1.4288,  1.4372,  1.3746,  1.2738,  1.3673,  1.2897,  1.2923,  1.2792,
          1.2637,  1.2479,  1.2852,  1.2845,  1.2502,  1.2665],
        [ 1.2047,  1.2323,  1.2670,  1.2669,  1.2375,  1.2094,  1.2179,  1.2023,
          1.2023,  1.2711,  1.2956,  1.2831,  1.3233,  1.2626,  1.3168,  1.2759,
          1.1940,  1.3231,  2.8491,  3.1163,  3.0669,  2.8631,  2.8061,  2.8016,
          3.0747,  2.7953,  2.7953,  1.2430,  1.3033,  1.2359,  1.2604,  1.2437,
          1.2471,  1.2790,  1.2426,  1.2384,  1.3971,  1.4466,  1.4270,  1.3278,
          1.4164,  1.3971,  1.4119,  1.2735,  1.2766,  1.3197,  1.2782,  1.2655,
          1.2505,  1.3129,  1.2714,  1.3483,  1.2119,  1.2532],
        [ 1.2100,  1.2378,  1.2729,  1.2726,  1.2432,  1.2147,  1.2234,  1.2076,
          1.2076,  1.2758,  1.3004,  1.2878,  1.3177,  1.2672,  1.3150,  1.2805,
          1.2527,  1.2747,  1.2603,  1.2519,  1.3004,  1.2740,  1.2324,  1.2277,
          1.2252,  1.2203,  1.2203,  3.1388,  3.0388,  2.7583,  2.8153,  3.1371,
          2.7684,  3.0024,  2.7871,  2.7606,  1.4009,  1.4506,  1.4222,  1.3864,
          1.4240,  1.4051,  1.4033,  1.2719,  1.3380,  1.3282,  1.2834,  1.2195,
          1.2081,  1.3262,  1.2766,  1.3618,  1.1733,  1.2582],
        [ 1.8853,  1.4720,  0.6502,  0.9456,  1.3653,  1.8120,  1.6781,  1.9235,
          1.9235,  1.7091,  1.3350,  1.5524,  0.9559,  1.7694,  0.1804,  1.6448,
          1.9557,  0.8635,  1.3732,  1.0518,  0.7978,  1.1820,  1.7504,  1.8201,
          1.5940,  1.9328,  1.9328,  0.8998,  0.8797,  1.9070,  1.6777,  0.9015,
          1.8396,  1.2804,  1.9584,  1.8689,  0.1752, -0.0330, -0.0589,  0.1276,
          0.3346,  0.3967,  0.0735, 20.8034,  1.7371,  0.8278,  1.4534,  1.5330,
          1.7924,  1.0402,  1.7056,  0.4154,  1.9386,  1.9612],
        [ 1.2911,  1.3193,  1.3758,  1.3551,  1.3252,  1.2959,  1.2595,  1.2886,
          1.2886,  1.2606,  1.3795,  1.2728,  1.4079,  1.3458,  1.4564,  1.2655,
          1.3315,  1.3214,  1.3406,  1.3219,  1.3821,  1.3544,  1.3121,  1.3074,
          1.1950,  1.2999,  1.2999,  1.3487,  1.3955,  1.3198,  1.0877,  1.3030,
          1.1944,  1.3629,  1.1906,  1.3224,  1.4727,  1.1637,  1.4544,  1.4847,
          1.0094,  0.9341,  1.4879,  1.3450,  0.8299,  3.7343,  2.7018,  3.7774,
          2.9993,  2.2895,  1.9851,  3.0993,  3.6727,  1.9698]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 385 : 180.03428937384166
Test loss for epoch 385 : 180.610831292263
Test Precision for epoch 385 : 0.26153846153846155
Test Recall for epoch 385 : 0.26153846153846155
Test F1 for epoch 385 : 0.26153846153846155


theta for epoch 386 : tensor([[ 2.8317,  2.8580,  2.9250,  3.0704,  3.0374,  2.8359,  3.0181,  2.8295,
          2.8295,  1.2640,  1.2884,  1.2760,  1.3161,  1.2554,  1.3648,  1.2687,
          1.2416,  1.2771,  1.2497,  1.2276,  1.2444,  1.2633,  1.2219,  1.2172,
          1.2365,  1.2099,  1.2099,  1.2579,  1.3042,  1.2290,  1.2566,  1.3047,
          1.2402,  1.2721,  1.1897,  1.2316,  1.3913,  1.4406,  1.4248,  1.4036,
          1.4143,  1.3657,  1.4060,  1.2679,  1.3554,  1.3187,  1.2742,  1.2616,
          1.2467,  1.3166,  1.2674,  1.3519,  1.2335,  1.2494],
        [ 1.2168,  1.2453,  1.2993,  1.2779,  1.2514,  1.2217,  1.2309,  1.2144,
          1.2144,  2.6509,  2.6742,  2.6360,  2.9221,  2.6153,  3.6915,  2.6552,
          2.8717,  3.5172,  1.2328,  1.2597,  1.2283,  1.2463,  1.2435,  1.2387,
          1.2578,  1.2312,  1.2312,  1.2895,  1.2400,  1.2494,  1.2779,  1.2857,
          1.2610,  1.2939,  1.2198,  1.2520,  1.4046,  1.4557,  1.3939,  1.4168,
          1.4284,  1.4368,  1.3745,  1.2734,  1.3669,  1.2910,  1.2936,  1.2806,
          1.2651,  1.2493,  1.2866,  1.2857,  1.2516,  1.2678],
        [ 1.2009,  1.2286,  1.2633,  1.2632,  1.2338,  1.2056,  1.2141,  1.1985,
          1.1985,  1.2691,  1.2936,  1.2811,  1.3213,  1.2606,  1.3148,  1.2739,
          1.1918,  1.3211,  2.8555,  3.1234,  3.0735,  2.8694,  2.8120,  2.8075,
          3.0818,  2.8012,  2.8012,  1.2415,  1.3018,  1.2345,  1.2590,  1.2422,
          1.2457,  1.2776,  1.2412,  1.2370,  1.3961,  1.4455,  1.4259,  1.3266,
          1.4154,  1.3960,  1.4108,  1.2722,  1.2754,  1.3198,  1.2783,  1.2656,
          1.2506,  1.3128,  1.2714,  1.3482,  1.2119,  1.2532],
        [ 1.2077,  1.2354,  1.2707,  1.2704,  1.2409,  1.2124,  1.2211,  1.2053,
          1.2053,  1.2752,  1.2998,  1.2873,  1.3169,  1.2666,  1.3145,  1.2799,
          1.2521,  1.2742,  1.2620,  1.2533,  1.3020,  1.2756,  1.2340,  1.2293,
          1.2268,  1.2220,  1.2220,  3.1432,  3.0418,  2.7624,  2.8182,  3.1416,
          2.7725,  3.0053,  2.7919,  2.7647,  1.4006,  1.4503,  1.4217,  1.3861,
          1.4238,  1.4048,  1.4028,  1.2716,  1.3376,  1.3293,  1.2845,  1.2207,
          1.2092,  1.3273,  1.2777,  1.3629,  1.1744,  1.2594],
        [ 1.8840,  1.4709,  0.6498,  0.9449,  1.3642,  1.8107,  1.6769,  1.9222,
          1.9222,  1.7096,  1.3358,  1.5531,  0.9569,  1.7700,  0.1819,  1.6453,
          1.9562,  0.8646,  1.3757,  1.0544,  0.8005,  1.1846,  1.7528,  1.8225,
          1.5965,  1.9352,  1.9352,  0.9011,  0.8810,  1.9077,  1.6785,  0.9027,
          1.8403,  1.2815,  1.9592,  1.8697,  0.1731, -0.0348, -0.0608,  0.1255,
          0.3323,  0.3944,  0.0715, 20.8574,  1.7331,  0.8306,  1.4560,  1.5355,
          1.7948,  1.0430,  1.7080,  0.4182,  1.9410,  1.9635],
        [ 1.2875,  1.3157,  1.3722,  1.3515,  1.3216,  1.2923,  1.2559,  1.2851,
          1.2851,  1.2585,  1.3775,  1.2707,  1.4058,  1.3438,  1.4546,  1.2634,
          1.3294,  1.3194,  1.3408,  1.3220,  1.3823,  1.3547,  1.3123,  1.3076,
          1.1951,  1.3001,  1.3001,  1.3470,  1.3939,  1.3180,  1.0858,  1.3013,
          1.1926,  1.3613,  1.1888,  1.3207,  1.4715,  1.1622,  1.4531,  1.4835,
          1.0077,  0.9325,  1.4867,  1.3435,  0.8281,  3.7433,  2.7081,  3.7849,
          3.0060,  2.2950,  1.9901,  3.1059,  3.6819,  1.9747]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 386 : 180.02560743812757
Test loss for epoch 386 : 180.60191825186075
Test Precision for epoch 386 : 0.26153846153846155
Test Recall for epoch 386 : 0.26153846153846155
Test F1 for epoch 386 : 0.26153846153846155


theta for epoch 387 : tensor([[ 2.8371,  2.8634,  2.9304,  3.0761,  3.0431,  2.8413,  3.0238,  2.8349,
          2.8349,  1.2635,  1.2879,  1.2754,  1.3156,  1.2549,  1.3643,  1.2682,
          1.2411,  1.2767,  1.2477,  1.2256,  1.2424,  1.2613,  1.2199,  1.2152,
          1.2345,  1.2079,  1.2079,  1.2570,  1.3034,  1.2282,  1.2558,  1.3039,
          1.2394,  1.2714,  1.1889,  1.2307,  1.3908,  1.4400,  1.4242,  1.4031,
          1.4137,  1.3651,  1.4055,  1.2672,  1.3548,  1.3168,  1.2724,  1.2598,
          1.2449,  1.3148,  1.2656,  1.3500,  1.2316,  1.2475],
        [ 1.2172,  1.2457,  1.2998,  1.2784,  1.2517,  1.2221,  1.2312,  1.2148,
          1.2148,  2.6578,  2.6812,  2.6443,  2.9318,  2.6236,  3.6835,  2.6623,
          2.8815,  3.5113,  1.2311,  1.2581,  1.2267,  1.2447,  1.2417,  1.2369,
          1.2561,  1.2294,  1.2294,  1.2892,  1.2396,  1.2489,  1.2774,  1.2855,
          1.2605,  1.2934,  1.2195,  1.2515,  1.4042,  1.4553,  1.3937,  1.4164,
          1.4281,  1.4365,  1.3744,  1.2729,  1.3665,  1.2893,  1.2918,  1.2788,
          1.2633,  1.2477,  1.2847,  1.2843,  1.2498,  1.2660],
        [ 1.2023,  1.2299,  1.2646,  1.2645,  1.2352,  1.2069,  1.2154,  1.1999,
          1.1999,  1.2703,  1.2948,  1.2823,  1.3224,  1.2617,  1.3158,  1.2750,
          1.1929,  1.3222,  2.8581,  3.1267,  3.0765,  2.8720,  2.8141,  2.8097,
          3.0851,  2.8034,  2.8034,  1.2421,  1.3023,  1.2351,  1.2597,  1.2428,
          1.2464,  1.2783,  1.2418,  1.2377,  1.3966,  1.4460,  1.4265,  1.3271,
          1.4160,  1.3965,  1.4114,  1.2726,  1.2758,  1.3192,  1.2777,  1.2651,
          1.2500,  1.3121,  1.2708,  1.3475,  1.2113,  1.2527],
        [ 1.2082,  1.2360,  1.2711,  1.2709,  1.2414,  1.2129,  1.2216,  1.2058,
          1.2058,  1.2752,  1.2998,  1.2873,  1.3167,  1.2666,  1.3144,  1.2800,
          1.2521,  1.2742,  1.2605,  1.2516,  1.3005,  1.2742,  1.2326,  1.2279,
          1.2253,  1.2205,  1.2205,  3.1483,  3.0455,  2.7672,  2.8217,  3.1466,
          2.7773,  3.0088,  2.7972,  2.7695,  1.4004,  1.4502,  1.4213,  1.3859,
          1.4236,  1.4046,  1.4024,  1.2713,  1.3373,  1.3280,  1.2832,  1.2195,
          1.2079,  1.3260,  1.2763,  1.3616,  1.1730,  1.2580],
        [ 1.8854,  1.4724,  0.6512,  0.9463,  1.3657,  1.8122,  1.6784,  1.9237,
          1.9237,  1.7105,  1.3367,  1.5540,  0.9579,  1.7709,  0.1831,  1.6462,
          1.9571,  0.8657,  1.3754,  1.0543,  0.8004,  1.1844,  1.7526,  1.8222,
          1.5963,  1.9350,  1.9350,  0.9019,  0.8818,  1.9085,  1.6793,  0.9035,
          1.8411,  1.2823,  1.9599,  1.8704,  0.1717, -0.0361, -0.0620,  0.1242,
          0.3308,  0.3927,  0.0702, 20.9115,  1.7301,  0.8304,  1.4556,  1.5351,
          1.7944,  1.0426,  1.7076,  0.4182,  1.9407,  1.9630],
        [ 1.2891,  1.3173,  1.3738,  1.3531,  1.3232,  1.2939,  1.2575,  1.2867,
          1.2867,  1.2598,  1.3787,  1.2719,  1.4070,  1.3449,  1.4558,  1.2646,
          1.3306,  1.3207,  1.3402,  1.3215,  1.3818,  1.3541,  1.3118,  1.3070,
          1.1946,  1.2995,  1.2995,  1.3478,  1.3947,  1.3188,  1.0867,  1.3021,
          1.1935,  1.3621,  1.1897,  1.3215,  1.4719,  1.1628,  1.4536,  1.4839,
          1.0084,  0.9332,  1.4871,  1.3438,  0.8287,  3.7481,  2.7101,  3.7882,
          3.0085,  2.2961,  1.9907,  3.1084,  3.6868,  1.9753]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 387 : 180.01814489658523
Test loss for epoch 387 : 180.59822774368024
Test Precision for epoch 387 : 0.26153846153846155
Test Recall for epoch 387 : 0.26153846153846155
Test F1 for epoch 387 : 0.26153846153846155


theta for epoch 388 : tensor([[ 2.8416,  2.8680,  2.9350,  3.0810,  3.0480,  2.8459,  3.0287,  2.8395,
          2.8395,  1.2621,  1.2865,  1.2740,  1.3142,  1.2535,  1.3630,  1.2668,
          1.2397,  1.2754,  1.2474,  1.2254,  1.2422,  1.2611,  1.2196,  1.2149,
          1.2343,  1.2076,  1.2076,  1.2560,  1.3024,  1.2271,  1.2547,  1.3028,
          1.2384,  1.2703,  1.1878,  1.2297,  1.3904,  1.4397,  1.4239,  1.4028,
          1.4134,  1.3647,  1.4052,  1.2668,  1.3543,  1.3167,  1.2723,  1.2597,
          1.2448,  1.3146,  1.2655,  1.3499,  1.2315,  1.2474],
        [ 1.2177,  1.2462,  1.3005,  1.2791,  1.2522,  1.2226,  1.2318,  1.2153,
          1.2153,  2.6631,  2.6865,  2.6507,  2.9398,  2.6301,  3.6744,  2.6676,
          2.8895,  3.5042,  1.2319,  1.2589,  1.2274,  1.2454,  1.2423,  1.2375,
          1.2567,  1.2300,  1.2300,  1.2891,  1.2395,  1.2486,  1.2771,  1.2855,
          1.2602,  1.2931,  1.2193,  1.2512,  1.4043,  1.4554,  1.3941,  1.4165,
          1.4282,  1.4366,  1.3747,  1.2729,  1.3665,  1.2898,  1.2924,  1.2794,
          1.2638,  1.2484,  1.2853,  1.2848,  1.2504,  1.2666],
        [ 1.2021,  1.2298,  1.2644,  1.2644,  1.2350,  1.2068,  1.2153,  1.1997,
          1.1997,  1.2691,  1.2935,  1.2810,  1.3212,  1.2605,  1.3146,  1.2738,
          1.1914,  1.3210,  2.8626,  3.1320,  3.0813,  2.8765,  2.8182,  2.8137,
          3.0903,  2.8074,  2.8074,  1.2413,  1.3014,  1.2344,  1.2590,  1.2420,
          1.2456,  1.2775,  1.2411,  1.2369,  1.3965,  1.4459,  1.4263,  1.3269,
          1.4158,  1.3963,  1.4112,  1.2723,  1.2755,  1.3192,  1.2777,  1.2651,
          1.2500,  1.3119,  1.2708,  1.3474,  1.2113,  1.2526],
        [ 1.2085,  1.2363,  1.2714,  1.2712,  1.2418,  1.2132,  1.2220,  1.2061,
          1.2061,  1.2746,  1.2992,  1.2866,  1.3158,  1.2659,  1.3138,  1.2793,
          1.2514,  1.2736,  1.2611,  1.2519,  1.3011,  1.2747,  1.2331,  1.2285,
          1.2258,  1.2211,  1.2211,  3.1524,  3.0482,  2.7710,  2.8243,  3.1508,
          2.7811,  3.0115,  2.8016,  2.7733,  1.4006,  1.4503,  1.4211,  1.3860,
          1.4237,  1.4047,  1.4023,  1.2714,  1.3373,  1.3284,  1.2835,  1.2200,
          1.2082,  1.3263,  1.2766,  1.3619,  1.1734,  1.2584],
        [ 1.8864,  1.4734,  0.6523,  0.9473,  1.3668,  1.8132,  1.6793,  1.9247,
          1.9247,  1.7103,  1.3366,  1.5540,  0.9581,  1.7708,  0.1837,  1.6460,
          1.9571,  0.8658,  1.3764,  1.0553,  0.8014,  1.1854,  1.7536,  1.8232,
          1.5973,  1.9360,  1.9360,  0.9023,  0.8822,  1.9087,  1.6795,  0.9038,
          1.8413,  1.2825,  1.9601,  1.8706,  0.1702, -0.0374, -0.0633,  0.1227,
          0.3291,  0.3910,  0.0687, 20.9650,  1.7273,  0.8315,  1.4567,  1.5361,
          1.7954,  1.0437,  1.7086,  0.4194,  1.9417,  1.9640],
        [ 1.2890,  1.3172,  1.3737,  1.3530,  1.3232,  1.2938,  1.2575,  1.2866,
          1.2866,  1.2584,  1.3774,  1.2706,  1.4056,  1.3436,  1.4545,  1.2633,
          1.3292,  1.3194,  1.3401,  1.3213,  1.3817,  1.3540,  1.3117,  1.3069,
          1.1944,  1.2994,  1.2994,  1.3468,  1.3937,  1.3179,  1.0857,  1.3012,
          1.1926,  1.3611,  1.1887,  1.3205,  1.4716,  1.1625,  1.4532,  1.4836,
          1.0079,  0.9327,  1.4868,  1.3434,  0.8282,  3.7552,  2.7144,  3.7939,
          3.0133,  2.2995,  1.9936,  3.1132,  3.6941,  1.9782]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 388 : 180.01194490284928
Test loss for epoch 388 : 180.59441758641447
Test Precision for epoch 388 : 0.26153846153846155
Test Recall for epoch 388 : 0.26153846153846155
Test F1 for epoch 388 : 0.26153846153846155


theta for epoch 389 : tensor([[ 2.8433,  2.8697,  2.9368,  3.0830,  3.0501,  2.8476,  3.0308,  2.8412,
          2.8412,  1.2639,  1.2884,  1.2758,  1.3160,  1.2553,  1.3649,  1.2686,
          1.2415,  1.2773,  1.2485,  1.2265,  1.2433,  1.2622,  1.2207,  1.2160,
          1.2354,  1.2087,  1.2087,  1.2575,  1.3039,  1.2286,  1.2562,  1.3043,
          1.2398,  1.2718,  1.1893,  1.2312,  1.3911,  1.4404,  1.4246,  1.4035,
          1.4141,  1.3655,  1.4058,  1.2674,  1.3550,  1.3177,  1.2733,  1.2608,
          1.2458,  1.3156,  1.2665,  1.3508,  1.2326,  1.2484],
        [ 1.2150,  1.2435,  1.2981,  1.2765,  1.2495,  1.2198,  1.2291,  1.2125,
          1.2125,  2.6704,  2.6939,  2.6593,  2.9499,  2.6387,  3.6677,  2.6751,
          2.8996,  3.4995,  1.2313,  1.2584,  1.2268,  1.2449,  1.2417,  1.2369,
          1.2560,  1.2293,  1.2293,  1.2889,  1.2391,  1.2482,  1.2766,  1.2854,
          1.2598,  1.2927,  1.2190,  1.2508,  1.4037,  1.4548,  1.3937,  1.4159,
          1.4275,  1.4360,  1.3743,  1.2721,  1.3658,  1.2891,  1.2916,  1.2786,
          1.2631,  1.2477,  1.2845,  1.2843,  1.2496,  1.2658],
        [ 1.2000,  1.2277,  1.2623,  1.2623,  1.2329,  1.2047,  1.2132,  1.1976,
          1.1976,  1.2694,  1.2939,  1.2813,  1.3215,  1.2608,  1.3148,  1.2742,
          1.1916,  1.3213,  2.8673,  3.1374,  3.0864,  2.8812,  2.8225,  2.8180,
          3.0958,  2.8117,  2.8117,  1.2412,  1.3013,  1.2344,  1.2590,  1.2419,
          1.2456,  1.2775,  1.2410,  1.2369,  1.3962,  1.4456,  1.4260,  1.3265,
          1.4156,  1.3960,  1.4109,  1.2719,  1.2751,  1.3189,  1.2773,  1.2647,
          1.2497,  1.3114,  1.2704,  1.3469,  1.2109,  1.2523],
        [ 1.2065,  1.2342,  1.2694,  1.2692,  1.2397,  1.2112,  1.2199,  1.2040,
          1.2040,  1.2748,  1.2994,  1.2868,  1.3158,  1.2661,  1.3139,  1.2795,
          1.2517,  1.2738,  1.2608,  1.2515,  1.3008,  1.2745,  1.2329,  1.2282,
          1.2256,  1.2209,  1.2209,  3.1579,  3.0523,  2.7760,  2.8282,  3.1562,
          2.7861,  3.0155,  2.8073,  2.7783,  1.4002,  1.4499,  1.4205,  1.3855,
          1.4233,  1.4043,  1.4016,  1.2710,  1.3368,  1.3280,  1.2832,  1.2197,
          1.2079,  1.3260,  1.2763,  1.3616,  1.1730,  1.2580],
        [ 1.8855,  1.4726,  0.6521,  0.9469,  1.3660,  1.8123,  1.6785,  1.9238,
          1.9238,  1.7116,  1.3381,  1.5554,  0.9597,  1.7721,  0.1855,  1.6473,
          1.9584,  0.8675,  1.3775,  1.0565,  0.8027,  1.1865,  1.7546,  1.8242,
          1.5984,  1.9369,  1.9369,  0.9037,  0.8836,  1.9099,  1.6807,  0.9052,
          1.8425,  1.2839,  1.9612,  1.8718,  0.1685, -0.0389, -0.0648,  0.1210,
          0.3273,  0.3890,  0.0672, 21.0179,  1.7247,  0.8327,  1.4576,  1.5370,
          1.7963,  1.0448,  1.7095,  0.4207,  1.9426,  1.9648],
        [ 1.2870,  1.3152,  1.3717,  1.3510,  1.3212,  1.2918,  1.2555,  1.2846,
          1.2846,  1.2590,  1.3780,  1.2711,  1.4062,  1.3441,  1.4552,  1.2639,
          1.3298,  1.3201,  1.3400,  1.3212,  1.3816,  1.3540,  1.3116,  1.3069,
          1.1943,  1.2994,  1.2994,  1.3471,  1.3940,  1.3181,  1.0859,  1.3014,
          1.1928,  1.3614,  1.1889,  1.3207,  1.4713,  1.1622,  1.4529,  1.4834,
          1.0076,  0.9324,  1.4865,  1.3429,  0.8278,  3.7621,  2.7184,  3.7995,
          3.0179,  2.3026,  1.9961,  3.1177,  3.7011,  1.9807]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 389 : 180.0066480350439
Test loss for epoch 389 : 180.59035561463477
Test Precision for epoch 389 : 0.26153846153846155
Test Recall for epoch 389 : 0.26153846153846155
Test F1 for epoch 389 : 0.26153846153846155


theta for epoch 390 : tensor([[ 2.8512,  2.8776,  2.9447,  3.0913,  3.0583,  2.8555,  3.0390,  2.8490,
          2.8490,  1.2608,  1.2853,  1.2727,  1.3129,  1.2522,  1.3619,  1.2656,
          1.2384,  1.2743,  1.2456,  1.2235,  1.2403,  1.2592,  1.2178,  1.2131,
          1.2325,  1.2058,  1.2058,  1.2547,  1.3012,  1.2259,  1.2535,  1.3016,
          1.2371,  1.2691,  1.1865,  1.2284,  1.3898,  1.4390,  1.4233,  1.4022,
          1.4127,  1.3640,  1.4045,  1.2659,  1.3535,  1.3150,  1.2706,  1.2581,
          1.2431,  1.3130,  1.2638,  1.3482,  1.2299,  1.2457],
        [ 1.2180,  1.2465,  1.3010,  1.2796,  1.2525,  1.2229,  1.2321,  1.2156,
          1.2156,  2.6754,  2.6989,  2.6654,  2.9575,  2.6449,  3.6592,  2.6801,
          2.9072,  3.4930,  1.2308,  1.2580,  1.2263,  1.2444,  1.2410,  1.2362,
          1.2554,  1.2286,  1.2286,  1.2888,  1.2390,  1.2479,  1.2764,  1.2855,
          1.2595,  1.2924,  1.2190,  1.2505,  1.4040,  1.4551,  1.3942,  1.4162,
          1.4279,  1.4363,  1.3748,  1.2722,  1.3660,  1.2888,  1.2913,  1.2783,
          1.2628,  1.2476,  1.2842,  1.2841,  1.2493,  1.2654],
        [ 1.2028,  1.2305,  1.2650,  1.2651,  1.2357,  1.2075,  1.2160,  1.2004,
          1.2004,  1.2690,  1.2934,  1.2809,  1.3210,  1.2603,  1.3143,  1.2737,
          1.1911,  1.3208,  2.8703,  3.1411,  3.0897,  2.8842,  2.8250,  2.8205,
          3.0995,  2.8142,  2.8142,  1.2411,  1.3011,  1.2343,  1.2589,  1.2418,
          1.2455,  1.2774,  1.2409,  1.2368,  1.3966,  1.4461,  1.4265,  1.3270,
          1.4161,  1.3965,  1.4114,  1.2723,  1.2754,  1.3187,  1.2771,  1.2645,
          1.2494,  1.3111,  1.2702,  1.3465,  1.2107,  1.2520],
        [ 1.2090,  1.2367,  1.2718,  1.2716,  1.2422,  1.2137,  1.2224,  1.2066,
          1.2066,  1.2741,  1.2988,  1.2861,  1.3150,  1.2654,  1.3133,  1.2789,
          1.2510,  1.2732,  1.2600,  1.2505,  1.3000,  1.2737,  1.2321,  1.2274,
          1.2248,  1.2201,  1.2201,  3.1621,  3.0551,  2.7797,  2.8308,  3.1604,
          2.7898,  3.0182,  2.8117,  2.7820,  1.4005,  1.4502,  1.4206,  1.3858,
          1.4236,  1.4046,  1.4017,  1.2713,  1.3370,  1.3276,  1.2827,  1.2194,
          1.2074,  1.3255,  1.2758,  1.3611,  1.1725,  1.2575],
        [ 1.8883,  1.4755,  0.6546,  0.9494,  1.3689,  1.8152,  1.6813,  1.9267,
          1.9267,  1.7113,  1.3378,  1.5552,  0.9595,  1.7719,  0.1857,  1.6470,
          1.9582,  0.8674,  1.3772,  1.0563,  0.8024,  1.1862,  1.7543,  1.8239,
          1.5981,  1.9367,  1.9367,  0.9038,  0.8836,  1.9099,  1.6807,  0.9052,
          1.8425,  1.2838,  1.9612,  1.8718,  0.1673, -0.0399, -0.0658,  0.1198,
          0.3260,  0.3876,  0.0660, 21.0708,  1.7228,  0.8326,  1.4575,  1.5368,
          1.7962,  1.0446,  1.7094,  0.4208,  1.9425,  1.9647],
        [ 1.2898,  1.3180,  1.3745,  1.3538,  1.3240,  1.2946,  1.2583,  1.2874,
          1.2874,  1.2585,  1.3774,  1.2706,  1.4057,  1.3436,  1.4547,  1.2634,
          1.3292,  1.3197,  1.3394,  1.3206,  1.3810,  1.3533,  1.3110,  1.3062,
          1.1937,  1.2987,  1.2987,  1.3469,  1.3938,  1.3179,  1.0858,  1.3013,
          1.1926,  1.3612,  1.1887,  1.3205,  1.4717,  1.1626,  1.4533,  1.4838,
          1.0081,  0.9329,  1.4869,  1.3432,  0.8282,  3.7677,  2.7211,  3.8037,
          3.0211,  2.3043,  1.9971,  3.1209,  3.7068,  1.9817]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 390 : 180.00161317369498
Test loss for epoch 390 : 180.5895852025409
Test Precision for epoch 390 : 0.26153846153846155
Test Recall for epoch 390 : 0.26153846153846155
Test F1 for epoch 390 : 0.26153846153846155


theta for epoch 391 : tensor([[ 2.8506,  2.8769,  2.9440,  3.0910,  3.0580,  2.8548,  3.0387,  2.8484,
          2.8484,  1.2639,  1.2884,  1.2758,  1.3159,  1.2553,  1.3650,  1.2686,
          1.2415,  1.2775,  1.2489,  1.2269,  1.2437,  1.2626,  1.2211,  1.2165,
          1.2358,  1.2091,  1.2091,  1.2575,  1.3039,  1.2287,  1.2563,  1.3043,
          1.2399,  1.2719,  1.1893,  1.2312,  1.3914,  1.4406,  1.4249,  1.4038,
          1.4143,  1.3657,  1.4061,  1.2675,  1.3551,  1.3180,  1.2736,  1.2611,
          1.2461,  1.3159,  1.2667,  1.3511,  1.2329,  1.2487],
        [ 1.2137,  1.2422,  1.2971,  1.2754,  1.2482,  1.2185,  1.2278,  1.2112,
          1.2112,  2.6827,  2.7062,  2.6737,  2.9673,  2.6533,  3.6532,  2.6875,
          2.9170,  3.4891,  1.2313,  1.2585,  1.2268,  1.2450,  1.2414,  1.2366,
          1.2559,  1.2291,  1.2291,  1.2885,  1.2387,  1.2474,  1.2759,  1.2853,
          1.2590,  1.2920,  1.2187,  1.2501,  1.4034,  1.4545,  1.3938,  1.4156,
          1.4273,  1.4357,  1.3744,  1.2715,  1.3653,  1.2889,  1.2914,  1.2785,
          1.2629,  1.2478,  1.2843,  1.2843,  1.2495,  1.2656],
        [ 1.1986,  1.2263,  1.2609,  1.2609,  1.2315,  1.2033,  1.2118,  1.1962,
          1.1962,  1.2685,  1.2929,  1.2803,  1.3205,  1.2598,  1.3138,  1.2732,
          1.1903,  1.3203,  2.8764,  3.1479,  3.0962,  2.8903,  2.8306,  2.8262,
          3.1063,  2.8199,  2.8199,  1.2403,  1.3003,  1.2336,  1.2582,  1.2410,
          1.2448,  1.2768,  1.2402,  1.2361,  1.3959,  1.4453,  1.4258,  1.3261,
          1.4153,  1.3957,  1.4106,  1.2714,  1.2745,  1.3186,  1.2770,  1.2644,
          1.2493,  1.3108,  1.2700,  1.3462,  1.2105,  1.2519],
        [ 1.2054,  1.2332,  1.2684,  1.2682,  1.2387,  1.2101,  1.2189,  1.2030,
          1.2030,  1.2743,  1.2989,  1.2862,  1.3149,  1.2656,  1.3134,  1.2790,
          1.2511,  1.2732,  1.2608,  1.2510,  1.3008,  1.2745,  1.2329,  1.2282,
          1.2255,  1.2209,  1.2209,  3.1676,  3.0593,  2.7847,  2.8348,  3.1660,
          2.7948,  3.0222,  2.8174,  2.7870,  1.4001,  1.4498,  1.4199,  1.3854,
          1.4233,  1.4042,  1.4011,  1.2709,  1.3364,  1.3280,  1.2831,  1.2198,
          1.2078,  1.3259,  1.2762,  1.3615,  1.1729,  1.2579],
        [ 1.8860,  1.4733,  0.6532,  0.9478,  1.3667,  1.8129,  1.6790,  1.9243,
          1.9243,  1.7125,  1.3392,  1.5565,  0.9611,  1.7731,  0.1875,  1.6483,
          1.9595,  0.8690,  1.3791,  1.0582,  0.8045,  1.1881,  1.7561,  1.8258,
          1.6000,  1.9385,  1.9385,  0.9052,  0.8851,  1.9110,  1.6819,  0.9066,
          1.8437,  1.2852,  1.9623,  1.8730,  0.1656, -0.0414, -0.0673,  0.1182,
          0.3241,  0.3857,  0.0645, 21.1229,  1.7207,  0.8345,  1.4593,  1.5386,
          1.7979,  1.0465,  1.7111,  0.4228,  1.9442,  1.9663],
        [ 1.2856,  1.3137,  1.3702,  1.3495,  1.3197,  1.2903,  1.2540,  1.2831,
          1.2831,  1.2583,  1.3772,  1.2703,  1.4054,  1.3433,  1.4546,  1.2631,
          1.3290,  1.3195,  1.3397,  1.3209,  1.3813,  1.3537,  1.3114,  1.3066,
          1.1939,  1.2991,  1.2991,  1.3463,  1.3933,  1.3174,  1.0851,  1.3007,
          1.1920,  1.3607,  1.1881,  1.3200,  1.4710,  1.1617,  1.4525,  1.4831,
          1.0071,  0.9318,  1.4862,  1.3423,  0.8270,  3.7761,  2.7266,  3.8109,
          3.0272,  2.3088,  2.0011,  3.1269,  3.7155,  1.9857]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 391 : 179.9967106309007
Test loss for epoch 391 : 180.58441487988276
Test Precision for epoch 391 : 0.26153846153846155
Test Recall for epoch 391 : 0.26153846153846155
Test F1 for epoch 391 : 0.26153846153846155


theta for epoch 392 : tensor([[ 2.8600,  2.8864,  2.9535,  3.1008,  3.0678,  2.8643,  3.0485,  2.8578,
          2.8578,  1.2603,  1.2847,  1.2721,  1.3123,  1.2516,  1.3615,  1.2650,
          1.2378,  1.2739,  1.2448,  1.2227,  1.2395,  1.2584,  1.2170,  1.2123,
          1.2316,  1.2050,  1.2050,  1.2540,  1.3005,  1.2252,  1.2529,  1.3009,
          1.2364,  1.2685,  1.1858,  1.2278,  1.3895,  1.4387,  1.4230,  1.4019,
          1.4124,  1.3637,  1.4042,  1.2654,  1.3530,  1.3139,  1.2695,  1.2570,
          1.2419,  1.3118,  1.2626,  1.3471,  1.2287,  1.2445],
        [ 1.2176,  1.2460,  1.3008,  1.2794,  1.2521,  1.2224,  1.2317,  1.2151,
          1.2151,  2.6879,  2.7114,  2.6800,  2.9751,  2.6597,  3.6457,  2.6928,
          2.9248,  3.4836,  1.2299,  1.2572,  1.2255,  1.2437,  1.2399,  1.2351,
          1.2544,  1.2275,  1.2275,  1.2884,  1.2386,  1.2471,  1.2757,  1.2854,
          1.2587,  1.2917,  1.2185,  1.2498,  1.4036,  1.4547,  1.3943,  1.4158,
          1.4275,  1.4360,  1.3749,  1.2715,  1.3655,  1.2878,  1.2902,  1.2773,
          1.2617,  1.2468,  1.2831,  1.2834,  1.2483,  1.2644],
        [ 1.2030,  1.2306,  1.2651,  1.2652,  1.2359,  1.2077,  1.2162,  1.2006,
          1.2006,  1.2689,  1.2934,  1.2807,  1.3209,  1.2602,  1.3141,  1.2737,
          1.1907,  1.3206,  2.8784,  3.1506,  3.0987,  2.8924,  2.8322,  2.8277,
          3.1090,  2.8214,  2.8214,  1.2408,  1.3006,  1.2340,  1.2587,  1.2415,
          1.2453,  1.2773,  1.2407,  1.2366,  1.3967,  1.4462,  1.4266,  1.3270,
          1.4162,  1.3966,  1.4115,  1.2721,  1.2752,  1.3183,  1.2766,  1.2641,
          1.2490,  1.3103,  1.2697,  1.3458,  1.2102,  1.2515],
        [ 1.2088,  1.2365,  1.2715,  1.2714,  1.2420,  1.2135,  1.2222,  1.2064,
          1.2064,  1.2738,  1.2984,  1.2857,  1.3142,  1.2650,  1.3129,  1.2785,
          1.2506,  1.2727,  1.2592,  1.2493,  1.2992,  1.2729,  1.2313,  1.2266,
          1.2239,  1.2193,  1.2193,  3.1721,  3.0624,  2.7886,  2.8377,  3.1705,
          2.7987,  3.0253,  2.8219,  2.7909,  1.4003,  1.4501,  1.4200,  1.3856,
          1.4235,  1.4044,  1.4011,  1.2711,  1.3365,  1.3269,  1.2819,  1.2188,
          1.2067,  1.3247,  1.2750,  1.3604,  1.1718,  1.2567],
        [ 1.8897,  1.4770,  0.6563,  0.9510,  1.3705,  1.8166,  1.6828,  1.9280,
          1.9280,  1.7122,  1.3390,  1.5563,  0.9609,  1.7729,  0.1877,  1.6480,
          1.9593,  0.8689,  1.3781,  1.0574,  0.8036,  1.1871,  1.7551,  1.8248,
          1.5991,  1.9375,  1.9375,  0.9051,  0.8849,  1.9110,  1.6818,  0.9064,
          1.8436,  1.2850,  1.9623,  1.8729,  0.1646, -0.0423, -0.0682,  0.1172,
          0.3230,  0.3845,  0.0635, 21.1750,  1.7193,  0.8337,  1.4584,  1.5376,
          1.7970,  1.0455,  1.7102,  0.4221,  1.9434,  1.9654],
        [ 1.2898,  1.3180,  1.3744,  1.3537,  1.3240,  1.2946,  1.2582,  1.2874,
          1.2874,  1.2587,  1.3775,  1.2707,  1.4057,  1.3436,  1.4549,  1.2635,
          1.3293,  1.3200,  1.3390,  1.3201,  1.3806,  1.3529,  1.3106,  1.3058,
          1.1933,  1.2983,  1.2983,  1.3468,  1.3938,  1.3179,  1.0858,  1.3012,
          1.1926,  1.3612,  1.1887,  1.3205,  1.4717,  1.1627,  1.4533,  1.4838,
          1.0081,  0.9329,  1.4869,  1.3430,  0.8280,  3.7808,  2.7281,  3.8142,
          3.0294,  2.3092,  2.0009,  3.1291,  3.7202,  1.9855]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 392 : 179.99105186597356
Test loss for epoch 392 : 180.58392761462312
Test Precision for epoch 392 : 0.26153846153846155
Test Recall for epoch 392 : 0.26153846153846155
Test F1 for epoch 392 : 0.26153846153846155


theta for epoch 393 : tensor([[ 2.8589,  2.8853,  2.9525,  3.1002,  3.0672,  2.8632,  3.0479,  2.8568,
          2.8568,  1.2632,  1.2877,  1.2750,  1.3152,  1.2545,  1.3644,  1.2680,
          1.2408,  1.2770,  1.2488,  1.2268,  1.2435,  1.2624,  1.2210,  1.2164,
          1.2357,  1.2090,  1.2090,  1.2570,  1.3034,  1.2281,  1.2558,  1.3038,
          1.2393,  1.2714,  1.1887,  1.2307,  1.3912,  1.4404,  1.4246,  1.4036,
          1.4141,  1.3655,  1.4059,  1.2671,  1.3546,  1.3176,  1.2732,  1.2607,
          1.2457,  1.3155,  1.2663,  1.3507,  1.2325,  1.2482],
        [ 1.2131,  1.2416,  1.2968,  1.2751,  1.2476,  1.2179,  1.2273,  1.2106,
          1.2106,  2.6946,  2.7181,  2.6877,  2.9843,  2.6675,  3.6400,  2.6995,
          2.9340,  3.4800,  1.2311,  1.2585,  1.2266,  1.2449,  1.2410,  1.2362,
          1.2555,  1.2287,  1.2287,  1.2882,  1.2384,  1.2468,  1.2753,  1.2853,
          1.2583,  1.2914,  1.2183,  1.2494,  1.4031,  1.4542,  1.3939,  1.4153,
          1.4270,  1.4355,  1.3746,  1.2708,  1.3648,  1.2887,  1.2912,  1.2783,
          1.2627,  1.2479,  1.2841,  1.2843,  1.2493,  1.2654],
        [ 1.1982,  1.2259,  1.2604,  1.2605,  1.2312,  1.2029,  1.2115,  1.1958,
          1.1958,  1.2677,  1.2921,  1.2795,  1.3197,  1.2589,  1.3129,  1.2724,
          1.1892,  1.3194,  2.8853,  3.1582,  3.1059,  2.8992,  2.8385,  2.8341,
          3.1165,  2.8278,  2.8278,  1.2396,  1.2995,  1.2329,  1.2577,  1.2403,
          1.2442,  1.2762,  1.2396,  1.2355,  1.3957,  1.4451,  1.4256,  1.3258,
          1.4151,  1.3954,  1.4104,  1.2710,  1.2739,  1.3184,  1.2768,  1.2643,
          1.2491,  1.3103,  1.2698,  1.3458,  1.2103,  1.2517],
        [ 1.2050,  1.2328,  1.2679,  1.2678,  1.2383,  1.2097,  1.2185,  1.2026,
          1.2026,  1.2737,  1.2983,  1.2856,  1.3140,  1.2649,  1.3128,  1.2785,
          1.2506,  1.2727,  1.2606,  1.2505,  1.3006,  1.2743,  1.2327,  1.2280,
          1.2253,  1.2207,  1.2207,  3.1775,  3.0664,  2.7934,  2.8415,  3.1759,
          2.8035,  3.0292,  2.8274,  2.7957,  1.3999,  1.4497,  1.4194,  1.3852,
          1.4231,  1.4040,  1.4005,  1.2707,  1.3360,  1.3279,  1.2830,  1.2199,
          1.2077,  1.3257,  1.2760,  1.3614,  1.1728,  1.2578],
        [ 1.8870,  1.4745,  0.6547,  0.9491,  1.3680,  1.8139,  1.6802,  1.9254,
          1.9254,  1.7132,  1.3402,  1.5574,  0.9623,  1.7739,  0.1894,  1.6490,
          1.9603,  0.8703,  1.3804,  1.0598,  0.8061,  1.1895,  1.7574,  1.8270,
          1.6013,  1.9397,  1.9397,  0.9065,  0.8863,  1.9120,  1.6829,  0.9078,
          1.8447,  1.2863,  1.9633,  1.8740,  0.1629, -0.0439, -0.0697,  0.1155,
          0.3211,  0.3826,  0.0619, 21.2262,  1.7173,  0.8361,  1.4607,  1.5399,
          1.7992,  1.0480,  1.7124,  0.4246,  1.9457,  1.9676],
        [ 1.2848,  1.3130,  1.3695,  1.3488,  1.3190,  1.2896,  1.2532,  1.2823,
          1.2823,  1.2575,  1.3765,  1.2695,  1.4046,  1.3426,  1.4539,  1.2624,
          1.3282,  1.3189,  1.3394,  1.3205,  1.3810,  1.3534,  1.3111,  1.3063,
          1.1936,  1.2988,  1.2988,  1.3457,  1.3927,  1.3168,  1.0845,  1.3001,
          1.1914,  1.3602,  1.1875,  1.3194,  1.4706,  1.1613,  1.4521,  1.4828,
          1.0066,  0.9314,  1.4858,  1.3418,  0.8264,  3.7902,  2.7345,  3.8225,
          3.0365,  2.3145,  2.0056,  3.1361,  3.7299,  1.9902]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 393 : 179.98532925961575
Test loss for epoch 393 : 180.57719778202386
Test Precision for epoch 393 : 0.26153846153846155
Test Recall for epoch 393 : 0.26153846153846155
Test F1 for epoch 393 : 0.26153846153846155


theta for epoch 394 : tensor([[ 2.8681,  2.8945,  2.9616,  3.1097,  3.0767,  2.8723,  3.0574,  2.8659,
          2.8659,  1.2604,  1.2848,  1.2721,  1.3123,  1.2516,  1.3617,  1.2651,
          1.2378,  1.2741,  1.2446,  1.2226,  1.2394,  1.2583,  1.2169,  1.2122,
          1.2315,  1.2049,  1.2049,  1.2540,  1.3005,  1.2252,  1.2529,  1.3009,
          1.2364,  1.2685,  1.1857,  1.2277,  1.3895,  1.4388,  1.4230,  1.4019,
          1.4124,  1.3638,  1.4042,  1.2652,  1.3528,  1.3134,  1.2689,  1.2565,
          1.2414,  1.3112,  1.2620,  1.3466,  1.2282,  1.2439],
        [ 1.2166,  1.2450,  1.3001,  1.2786,  1.2511,  1.2214,  1.2308,  1.2141,
          1.2141,  2.7003,  2.7239,  2.6944,  2.9924,  2.6742,  3.6337,  2.7053,
          2.9422,  3.4758,  1.2291,  1.2566,  1.2248,  1.2430,  1.2389,  1.2341,
          1.2535,  1.2265,  1.2265,  1.2881,  1.2383,  1.2465,  1.2750,  1.2854,
          1.2580,  1.2911,  1.2182,  1.2491,  1.4033,  1.4544,  1.3943,  1.4155,
          1.4271,  1.4357,  1.3750,  1.2708,  1.3649,  1.2870,  1.2894,  1.2765,
          1.2609,  1.2462,  1.2822,  1.2828,  1.2474,  1.2635],
        [ 1.2025,  1.2301,  1.2646,  1.2647,  1.2354,  1.2072,  1.2157,  1.2001,
          1.2001,  1.2687,  1.2931,  1.2805,  1.3207,  1.2599,  1.3138,  1.2734,
          1.1901,  1.3203,  2.8872,  3.1607,  3.1083,  2.9011,  2.8399,  2.8355,
          3.1191,  2.8291,  2.8291,  1.2404,  1.3001,  1.2337,  1.2584,  1.2411,
          1.2449,  1.2769,  1.2403,  1.2362,  1.3966,  1.4461,  1.4266,  1.3268,
          1.4161,  1.3964,  1.4114,  1.2719,  1.2748,  1.3178,  1.2761,  1.2637,
          1.2485,  1.3095,  1.2692,  1.3450,  1.2097,  1.2510],
        [ 1.2081,  1.2358,  1.2707,  1.2707,  1.2413,  1.2128,  1.2216,  1.2057,
          1.2057,  1.2735,  1.2982,  1.2854,  1.3136,  1.2648,  1.3126,  1.2783,
          1.2504,  1.2725,  1.2585,  1.2483,  1.2986,  1.2723,  1.2307,  1.2260,
          1.2233,  1.2186,  1.2186,  3.1823,  3.0698,  2.7975,  2.8447,  3.1807,
          2.8076,  3.0326,  2.8322,  2.7998,  1.4002,  1.4499,  1.4194,  1.3855,
          1.4234,  1.4043,  1.4005,  1.2710,  1.3362,  1.3263,  1.2814,  1.2185,
          1.2062,  1.3242,  1.2745,  1.3598,  1.1712,  1.2562],
        [ 1.8904,  1.4778,  0.6574,  0.9519,  1.3713,  1.8173,  1.6835,  1.9287,
          1.9287,  1.7132,  1.3402,  1.5575,  0.9623,  1.7740,  0.1895,  1.6491,
          1.9605,  0.8703,  1.3790,  1.0585,  0.8048,  1.1881,  1.7560,  1.8257,
          1.6000,  1.9384,  1.9384,  0.9064,  0.8862,  1.9121,  1.6829,  0.9076,
          1.8447,  1.2861,  1.9633,  1.8741,  0.1621, -0.0445, -0.0704,  0.1147,
          0.3203,  0.3816,  0.0611, 21.2777,  1.7164,  0.8347,  1.4592,  1.5384,
          1.7978,  1.0464,  1.7110,  0.4233,  1.9444,  1.9662],
        [ 1.2891,  1.3172,  1.3738,  1.3531,  1.3233,  1.2939,  1.2575,  1.2866,
          1.2866,  1.2588,  1.3777,  1.2708,  1.4058,  1.3437,  1.4551,  1.2636,
          1.3294,  1.3203,  1.3387,  1.3198,  1.3803,  1.3526,  1.3103,  1.3056,
          1.1930,  1.2981,  1.2981,  1.3468,  1.3938,  1.3179,  1.0858,  1.3012,
          1.1926,  1.3612,  1.1886,  1.3205,  1.4717,  1.1627,  1.4532,  1.4839,
          1.0080,  0.9329,  1.4869,  1.3428,  0.8278,  3.7943,  2.7354,  3.8254,
          3.0380,  2.3143,  2.0048,  3.1377,  3.7341,  1.9893]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 394 : 179.97893785256971
Test loss for epoch 394 : 180.5763216592351
Test Precision for epoch 394 : 0.26153846153846155
Test Recall for epoch 394 : 0.26153846153846155
Test F1 for epoch 394 : 0.26153846153846155


theta for epoch 395 : tensor([[ 2.8681,  2.8945,  2.9617,  3.1102,  3.0772,  2.8723,  3.0578,  2.8659,
          2.8659,  1.2622,  1.2866,  1.2740,  1.3142,  1.2535,  1.3635,  1.2669,
          1.2397,  1.2761,  1.2481,  1.2261,  1.2428,  1.2617,  1.2204,  1.2157,
          1.2350,  1.2084,  1.2084,  1.2561,  1.3025,  1.2273,  1.2549,  1.3029,
          1.2385,  1.2705,  1.1878,  1.2298,  1.3907,  1.4400,  1.4242,  1.4032,
          1.4137,  1.3651,  1.4055,  1.2664,  1.3540,  1.3169,  1.2723,  1.2599,
          1.2448,  1.3147,  1.2655,  1.3500,  1.2316,  1.2474],
        [ 1.2133,  1.2418,  1.2972,  1.2755,  1.2478,  1.2181,  1.2275,  1.2108,
          1.2108,  2.7063,  2.7298,  2.7012,  3.0007,  2.6811,  3.6280,  2.7113,
          2.9505,  3.4721,  1.2306,  1.2581,  1.2262,  1.2445,  1.2403,  1.2355,
          1.2549,  1.2279,  1.2279,  1.2880,  1.2381,  1.2461,  1.2747,  1.2854,
          1.2577,  1.2908,  1.2180,  1.2488,  1.4029,  1.4540,  1.3942,  1.4151,
          1.4268,  1.4353,  1.3748,  1.2703,  1.3644,  1.2885,  1.2910,  1.2782,
          1.2625,  1.2479,  1.2839,  1.2842,  1.2491,  1.2652],
        [ 1.1986,  1.2262,  1.2606,  1.2608,  1.2316,  1.2033,  1.2119,  1.1962,
          1.1962,  1.2669,  1.2913,  1.2787,  1.3189,  1.2581,  1.3120,  1.2716,
          1.1881,  1.3185,  2.8939,  3.1682,  3.1155,  2.9078,  2.8462,  2.8418,
          3.1265,  2.8354,  2.8354,  1.2390,  1.2987,  1.2323,  1.2571,  1.2397,
          1.2436,  1.2757,  1.2389,  1.2349,  1.3956,  1.4450,  1.4255,  1.3256,
          1.4150,  1.3953,  1.4103,  1.2707,  1.2735,  1.3183,  1.2766,  1.2641,
          1.2490,  1.3099,  1.2697,  1.3453,  1.2102,  1.2515],
        [ 1.2053,  1.2330,  1.2680,  1.2680,  1.2385,  1.2100,  1.2187,  1.2029,
          1.2029,  1.2732,  1.2978,  1.2850,  1.3131,  1.2644,  1.3122,  1.2779,
          1.2500,  1.2721,  1.2600,  1.2495,  1.3001,  1.2737,  1.2321,  1.2274,
          1.2247,  1.2201,  1.2201,  3.1875,  3.0736,  2.8019,  2.8482,  3.1859,
          2.8120,  3.0363,  2.8372,  2.8042,  1.3999,  1.4497,  1.4189,  1.3852,
          1.4231,  1.4039,  1.4000,  1.2707,  1.3357,  1.3277,  1.2828,  1.2199,
          1.2076,  1.3256,  1.2758,  1.3612,  1.1726,  1.2576],
        [ 1.8885,  1.4761,  0.6565,  0.9507,  1.3696,  1.8154,  1.6817,  1.9268,
          1.9268,  1.7137,  1.3409,  1.5582,  0.9632,  1.7746,  0.1909,  1.6497,
          1.9610,  0.8713,  1.3813,  1.0609,  0.8073,  1.1905,  1.7582,  1.8278,
          1.6022,  1.9405,  1.9405,  0.9075,  0.8873,  1.9128,  1.6837,  0.9087,
          1.8455,  1.2871,  1.9641,  1.8748,  0.1604, -0.0461, -0.0720,  0.1130,
          0.3184,  0.3797,  0.0595, 21.3280,  1.7145,  0.8374,  1.4618,  1.5409,
          1.8003,  1.0492,  1.7135,  0.4262,  1.9468,  1.9686],
        [ 1.2847,  1.3128,  1.3694,  1.3487,  1.3189,  1.2894,  1.2531,  1.2822,
          1.2822,  1.2568,  1.3757,  1.2688,  1.4039,  1.3418,  1.4533,  1.2616,
          1.3275,  1.3183,  1.3388,  1.3199,  1.3804,  1.3528,  1.3104,  1.3057,
          1.1930,  1.2982,  1.2982,  1.3452,  1.3922,  1.3162,  1.0838,  1.2995,
          1.1909,  1.3596,  1.1868,  1.3189,  1.4705,  1.1611,  1.4519,  1.4826,
          1.0063,  0.9310,  1.4857,  1.3414,  0.8259,  3.8043,  2.7423,  3.8343,
          3.0456,  2.3200,  2.0099,  3.1452,  3.7444,  1.9944]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 395 : 179.97263850974372
Test loss for epoch 395 : 180.5689361612009
Test Precision for epoch 395 : 0.26153846153846155
Test Recall for epoch 395 : 0.26153846153846155
Test F1 for epoch 395 : 0.26153846153846155


theta for epoch 396 : tensor([[ 2.8757,  2.9021,  2.9693,  3.1182,  3.0852,  2.8800,  3.0659,  2.8735,
          2.8735,  1.2608,  1.2852,  1.2725,  1.3127,  1.2520,  1.3622,  1.2655,
          1.2382,  1.2746,  1.2451,  1.2231,  1.2398,  1.2588,  1.2174,  1.2128,
          1.2321,  1.2054,  1.2054,  1.2543,  1.3008,  1.2255,  1.2532,  1.3011,
          1.2367,  1.2688,  1.1860,  1.2280,  1.3896,  1.4389,  1.4231,  1.4021,
          1.4126,  1.3639,  1.4044,  1.2651,  1.3528,  1.3132,  1.2686,  1.2562,
          1.2411,  1.3110,  1.2617,  1.3463,  1.2279,  1.2436],
        [ 1.2152,  1.2436,  1.2990,  1.2774,  1.2497,  1.2200,  1.2294,  1.2127,
          1.2127,  2.7127,  2.7362,  2.7085,  3.0094,  2.6884,  3.6232,  2.7178,
          2.9593,  3.4694,  1.2286,  1.2562,  1.2243,  1.2426,  1.2382,  1.2333,
          1.2528,  1.2258,  1.2258,  1.2878,  1.2379,  1.2458,  1.2743,  1.2853,
          1.2573,  1.2904,  1.2178,  1.2484,  1.4028,  1.4539,  1.3943,  1.4150,
          1.4267,  1.4352,  1.3749,  1.2701,  1.3643,  1.2861,  1.2884,  1.2756,
          1.2600,  1.2455,  1.2813,  1.2822,  1.2465,  1.2626],
        [ 1.2018,  1.2294,  1.2637,  1.2639,  1.2346,  1.2064,  1.2150,  1.1994,
          1.1994,  1.2683,  1.2928,  1.2801,  1.3203,  1.2595,  1.3133,  1.2731,
          1.1895,  1.3199,  2.8963,  3.1713,  3.1183,  2.9102,  2.8481,  2.8437,
          3.1296,  2.8373,  2.8373,  1.2399,  1.2994,  1.2332,  1.2580,  1.2405,
          1.2444,  1.2765,  1.2398,  1.2357,  1.3964,  1.4458,  1.4263,  1.3264,
          1.4159,  1.3962,  1.4111,  1.2714,  1.2743,  1.3172,  1.2755,  1.2631,
          1.2479,  1.3087,  1.2686,  1.3442,  1.2091,  1.2504],
        [ 1.2071,  1.2348,  1.2697,  1.2697,  1.2403,  1.2118,  1.2206,  1.2047,
          1.2047,  1.2733,  1.2979,  1.2851,  1.3130,  1.2644,  1.3122,  1.2780,
          1.2501,  1.2721,  1.2581,  1.2476,  1.2983,  1.2719,  1.2303,  1.2256,
          1.2228,  1.2182,  1.2182,  3.1928,  3.0777,  2.8065,  2.8520,  3.1913,
          2.8166,  3.0402,  2.8425,  2.8088,  1.4000,  1.4497,  1.4187,  1.3852,
          1.4232,  1.4040,  1.3999,  1.2708,  1.3357,  1.3258,  1.2808,  1.2181,
          1.2056,  1.3236,  1.2739,  1.3593,  1.1706,  1.2556],
        [ 1.8908,  1.4784,  0.6583,  0.9527,  1.3719,  1.8178,  1.6841,  1.9292,
          1.9292,  1.7142,  1.3414,  1.5587,  0.9637,  1.7751,  0.1914,  1.6501,
          1.9616,  0.8718,  1.3802,  1.0599,  0.8062,  1.1894,  1.7571,  1.8268,
          1.6012,  1.9395,  1.9395,  0.9077,  0.8875,  1.9132,  1.6840,  0.9088,
          1.8458,  1.2873,  1.9644,  1.8751,  0.1596, -0.0467, -0.0726,  0.1123,
          0.3176,  0.3788,  0.0588, 21.3788,  1.7136,  0.8358,  1.4601,  1.5392,
          1.7986,  1.0474,  1.7118,  0.4247,  1.9453,  1.9670],
        [ 1.2880,  1.3162,  1.3728,  1.3521,  1.3223,  1.2928,  1.2565,  1.2856,
          1.2856,  1.2589,  1.3777,  1.2708,  1.4058,  1.3437,  1.4553,  1.2637,
          1.3294,  1.3204,  1.3387,  1.3198,  1.3803,  1.3526,  1.3104,  1.3056,
          1.1930,  1.2981,  1.2981,  1.3467,  1.3937,  1.3178,  1.0856,  1.3011,
          1.1925,  1.3612,  1.1885,  1.3204,  1.4717,  1.1625,  1.4531,  1.4838,
          1.0078,  0.9327,  1.4869,  1.3425,  0.8275,  3.8083,  2.7428,  3.8371,
          3.0470,  2.3194,  2.0086,  3.1466,  3.7483,  1.9931]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 396 : 179.966380278574
Test loss for epoch 396 : 180.56776313214976
Test Precision for epoch 396 : 0.26153846153846155
Test Recall for epoch 396 : 0.26153846153846155
Test F1 for epoch 396 : 0.26153846153846155


theta for epoch 397 : tensor([[ 2.8776,  2.9040,  2.9712,  3.1206,  3.0876,  2.8819,  3.0682,  2.8754,
          2.8754,  1.2610,  1.2854,  1.2727,  1.3129,  1.2522,  1.3624,  1.2657,
          1.2384,  1.2750,  1.2473,  1.2252,  1.2419,  1.2609,  1.2196,  1.2149,
          1.2342,  1.2076,  1.2076,  1.2549,  1.3014,  1.2261,  1.2538,  1.3018,
          1.2374,  1.2694,  1.1866,  1.2287,  1.3903,  1.4395,  1.4237,  1.4027,
          1.4132,  1.3646,  1.4050,  1.2657,  1.3534,  1.3160,  1.2714,  1.2590,
          1.2439,  1.3137,  1.2645,  1.3491,  1.2307,  1.2464],
        [ 1.2137,  1.2421,  1.2976,  1.2760,  1.2482,  1.2185,  1.2279,  1.2112,
          1.2112,  2.7177,  2.7412,  2.7143,  3.0167,  2.6943,  3.6173,  2.7228,
          2.9665,  3.4656,  1.2301,  1.2578,  1.2257,  1.2441,  1.2395,  1.2347,
          1.2542,  1.2272,  1.2272,  1.2877,  1.2378,  1.2455,  1.2741,  1.2854,
          1.2571,  1.2902,  1.2176,  1.2481,  1.4028,  1.4539,  1.3945,  1.4150,
          1.4267,  1.4352,  1.3751,  1.2699,  1.3641,  1.2883,  1.2908,  1.2780,
          1.2623,  1.2479,  1.2837,  1.2842,  1.2489,  1.2649],
        [ 1.1994,  1.2270,  1.2613,  1.2616,  1.2323,  1.2041,  1.2127,  1.1970,
          1.1970,  1.2664,  1.2908,  1.2781,  1.3184,  1.2576,  1.3114,  1.2711,
          1.1873,  1.3180,  2.9023,  3.1779,  3.1247,  2.9162,  2.8536,  2.8491,
          3.1362,  2.8428,  2.8428,  1.2386,  1.2981,  1.2319,  1.2567,  1.2393,
          1.2432,  1.2753,  1.2385,  1.2345,  1.3956,  1.4451,  1.4256,  1.3256,
          1.4152,  1.3954,  1.4104,  1.2706,  1.2734,  1.3184,  1.2767,  1.2643,
          1.2491,  1.3097,  1.2698,  1.3452,  1.2103,  1.2516],
        [ 1.2057,  1.2334,  1.2683,  1.2683,  1.2389,  1.2104,  1.2191,  1.2032,
          1.2032,  1.2726,  1.2972,  1.2844,  1.3121,  1.2637,  1.3115,  1.2774,
          1.2494,  1.2715,  1.2594,  1.2486,  1.2995,  1.2731,  1.2315,  1.2268,
          1.2240,  1.2194,  1.2194,  3.1975,  3.0810,  2.8104,  2.8550,  3.1960,
          2.8205,  3.0434,  2.8471,  2.8127,  1.3999,  1.4497,  1.4185,  1.3852,
          1.4231,  1.4039,  1.3996,  1.2707,  1.3355,  1.3276,  1.2827,  1.2200,
          1.2075,  1.3254,  1.2757,  1.3611,  1.1725,  1.2575],
        [ 1.8899,  1.4776,  0.6581,  0.9523,  1.3712,  1.8169,  1.6832,  1.9283,
          1.9283,  1.7141,  1.3414,  1.5587,  0.9640,  1.7751,  0.1922,  1.6501,
          1.9615,  0.8721,  1.3819,  1.0617,  0.8081,  1.1912,  1.7587,  1.8283,
          1.6028,  1.9410,  1.9410,  0.9083,  0.8881,  1.9134,  1.6843,  0.9094,
          1.8461,  1.2877,  1.9646,  1.8754,  0.1581, -0.0481, -0.0740,  0.1108,
          0.3159,  0.3771,  0.0573, 21.4285,  1.7119,  0.8385,  1.4627,  1.5418,
          1.8012,  1.0502,  1.7144,  0.4274,  1.9478,  1.9695],
        [ 1.2847,  1.3129,  1.3695,  1.3488,  1.3189,  1.2895,  1.2532,  1.2822,
          1.2822,  1.2560,  1.3750,  1.2679,  1.4031,  1.3410,  1.4527,  1.2608,
          1.3267,  1.3177,  1.3381,  1.3192,  1.3798,  1.3521,  1.3098,  1.3050,
          1.1923,  1.2975,  1.2975,  1.3446,  1.3916,  1.3156,  1.0832,  1.2989,
          1.1902,  1.3590,  1.1862,  1.3182,  1.4704,  1.1609,  1.4518,  1.4826,
          1.0060,  0.9307,  1.4856,  1.3411,  0.8255,  3.8186,  2.7499,  3.8465,
          3.0548,  2.3252,  2.0139,  3.1544,  3.7590,  1.9984]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 397 : 179.96041098202522
Test loss for epoch 397 : 180.56118551438672
Test Precision for epoch 397 : 0.26153846153846155
Test Recall for epoch 397 : 0.26153846153846155
Test F1 for epoch 397 : 0.26153846153846155


theta for epoch 398 : tensor([[ 2.8833,  2.9097,  2.9769,  3.1267,  3.0937,  2.8875,  3.0744,  2.8811,
          2.8811,  1.2612,  1.2856,  1.2729,  1.3131,  1.2524,  1.3627,  1.2659,
          1.2386,  1.2752,  1.2458,  1.2238,  1.2405,  1.2594,  1.2181,  1.2135,
          1.2328,  1.2062,  1.2062,  1.2547,  1.3012,  1.2259,  1.2536,  1.3015,
          1.2371,  1.2692,  1.1864,  1.2284,  1.3898,  1.4391,  1.4233,  1.4023,
          1.4128,  1.3642,  1.4046,  1.2651,  1.3529,  1.3131,  1.2684,  1.2561,
          1.2409,  1.3108,  1.2615,  1.3462,  1.2277,  1.2434],
        [ 1.2137,  1.2421,  1.2977,  1.2761,  1.2482,  1.2185,  1.2279,  1.2112,
          1.2112,  2.7249,  2.7483,  2.7222,  3.0260,  2.7022,  3.6139,  2.7299,
          2.9759,  3.4642,  1.2283,  1.2561,  1.2240,  1.2424,  1.2377,  1.2329,
          1.2524,  1.2253,  1.2253,  1.2875,  1.2377,  1.2452,  1.2738,  1.2853,
          1.2567,  1.2899,  1.2174,  1.2478,  1.4024,  1.4535,  1.3942,  1.4146,
          1.4263,  1.4348,  1.3749,  1.2694,  1.3637,  1.2853,  1.2876,  1.2748,
          1.2591,  1.2449,  1.2805,  1.2817,  1.2457,  1.2617],
        [ 1.2007,  1.2283,  1.2625,  1.2628,  1.2336,  1.2054,  1.2140,  1.1983,
          1.1983,  1.2679,  1.2923,  1.2796,  1.3199,  1.2590,  1.3127,  1.2726,
          1.1887,  1.3194,  2.9057,  3.1820,  3.1287,  2.9197,  2.8565,  2.8521,
          3.1403,  2.8457,  2.8457,  1.2393,  1.2987,  1.2327,  1.2575,  1.2400,
          1.2439,  1.2760,  1.2392,  1.2352,  1.3960,  1.4455,  1.4260,  1.3260,
          1.4156,  1.3958,  1.4108,  1.2709,  1.2737,  1.3166,  1.2748,  1.2624,
          1.2472,  1.3077,  1.2678,  1.3432,  1.2084,  1.2497],
        [ 1.2060,  1.2337,  1.2685,  1.2686,  1.2392,  1.2107,  1.2195,  1.2036,
          1.2036,  1.2730,  1.2976,  1.2848,  1.3124,  1.2642,  1.3119,  1.2778,
          1.2498,  1.2718,  1.2579,  1.2470,  1.2981,  1.2716,  1.2300,  1.2253,
          1.2225,  1.2180,  1.2180,  3.2035,  3.0856,  2.8154,  2.8594,  3.2019,
          2.8255,  3.0479,  2.8528,  2.8178,  1.3998,  1.4495,  1.4181,  1.3850,
          1.4230,  1.4038,  1.3992,  1.2706,  1.3353,  1.3253,  1.2803,  1.2177,
          1.2051,  1.3231,  1.2734,  1.3587,  1.1700,  1.2550],
        [ 1.8910,  1.4787,  0.6590,  0.9531,  1.3722,  1.8180,  1.6843,  1.9293,
          1.9293,  1.7151,  1.3424,  1.5597,  0.9649,  1.7761,  0.1930,  1.6511,
          1.9626,  0.8731,  1.3814,  1.0613,  0.8077,  1.1907,  1.7583,  1.8279,
          1.6024,  1.9406,  1.9406,  0.9089,  0.8887,  1.9142,  1.6850,  0.9100,
          1.8469,  1.2884,  1.9654,  1.8762,  0.1574, -0.0488, -0.0746,  0.1101,
          0.3151,  0.3762,  0.0566, 21.4785,  1.7110,  0.8368,  1.4608,  1.5399,
          1.7993,  1.0482,  1.7126,  0.4259,  1.9461,  1.9677],
        [ 1.2869,  1.3151,  1.3717,  1.3510,  1.3211,  1.2917,  1.2554,  1.2844,
          1.2844,  1.2590,  1.3778,  1.2708,  1.4059,  1.3438,  1.4555,  1.2637,
          1.3295,  1.3206,  1.3389,  1.3200,  1.3805,  1.3528,  1.3105,  1.3058,
          1.1932,  1.2982,  1.2982,  1.3468,  1.3937,  1.3178,  1.0856,  1.3011,
          1.1925,  1.3612,  1.1885,  1.3204,  1.4716,  1.1624,  1.4530,  1.4838,
          1.0076,  0.9325,  1.4868,  1.3423,  0.8272,  3.8223,  2.7501,  3.8490,
          3.0559,  2.3242,  2.0122,  3.1555,  3.7627,  1.9967]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 398 : 179.95490115178285
Test loss for epoch 398 : 180.56020869979534
Test Precision for epoch 398 : 0.26153846153846155
Test Recall for epoch 398 : 0.26153846153846155
Test F1 for epoch 398 : 0.26153846153846155


theta for epoch 399 : tensor([[ 2.8872,  2.9136,  2.9808,  3.1311,  3.0980,  2.8914,  3.0787,  2.8850,
          2.8850,  1.2599,  1.2842,  1.2715,  1.3118,  1.2510,  1.3614,  1.2645,
          1.2372,  1.2739,  1.2462,  1.2241,  1.2408,  1.2598,  1.2185,  1.2138,
          1.2331,  1.2065,  1.2065,  1.2539,  1.3004,  1.2251,  1.2528,  1.3008,
          1.2363,  1.2685,  1.1856,  1.2277,  1.3897,  1.4390,  1.4232,  1.4022,
          1.4127,  1.3640,  1.4044,  1.2649,  1.3527,  1.3152,  1.2706,  1.2582,
          1.2430,  1.3130,  1.2637,  1.3484,  1.2298,  1.2455],
        [ 1.2140,  1.2424,  1.2980,  1.2765,  1.2485,  1.2188,  1.2282,  1.2115,
          1.2115,  2.7290,  2.7525,  2.7270,  3.0323,  2.7071,  3.6080,  2.7341,
          2.9822,  3.4603,  1.2293,  1.2571,  1.2250,  1.2433,  1.2385,  1.2337,
          1.2533,  1.2262,  1.2262,  1.2875,  1.2376,  1.2449,  1.2735,  1.2854,
          1.2565,  1.2896,  1.2173,  1.2475,  1.4026,  1.4537,  1.3946,  1.4149,
          1.4265,  1.4350,  1.3753,  1.2695,  1.3638,  1.2882,  1.2907,  1.2779,
          1.2622,  1.2480,  1.2835,  1.2842,  1.2488,  1.2648],
        [ 1.2002,  1.2278,  1.2620,  1.2623,  1.2331,  1.2049,  1.2134,  1.1978,
          1.1978,  1.2660,  1.2904,  1.2777,  1.3180,  1.2571,  1.3110,  1.2707,
          1.1867,  1.3175,  2.9106,  3.1875,  3.1341,  2.9245,  2.8609,  2.8565,
          3.1458,  2.8501,  2.8501,  1.2382,  1.2976,  1.2316,  1.2564,  1.2389,
          1.2428,  1.2750,  1.2381,  1.2341,  1.3956,  1.4451,  1.4256,  1.3255,
          1.4152,  1.3954,  1.4104,  1.2704,  1.2732,  1.3186,  1.2768,  1.2645,
          1.2492,  1.3097,  1.2699,  1.3452,  1.2104,  1.2517],
        [ 1.2061,  1.2338,  1.2686,  1.2687,  1.2393,  1.2108,  1.2195,  1.2036,
          1.2036,  1.2721,  1.2968,  1.2839,  1.3113,  1.2632,  1.3110,  1.2769,
          1.2489,  1.2710,  1.2585,  1.2474,  1.2987,  1.2722,  1.2306,  1.2260,
          1.2231,  1.2186,  1.2186,  3.2077,  3.0884,  2.8187,  2.8619,  3.2062,
          2.8288,  3.0507,  2.8568,  2.8210,  1.3999,  1.4497,  1.4181,  1.3851,
          1.4231,  1.4039,  1.3992,  1.2707,  1.3353,  1.3277,  1.2827,  1.2201,
          1.2075,  1.3254,  1.2757,  1.3611,  1.1724,  1.2574],
        [ 1.8914,  1.4792,  0.6598,  0.9538,  1.3728,  1.8184,  1.6847,  1.9297,
          1.9297,  1.7146,  1.3421,  1.5594,  0.9648,  1.7756,  0.1935,  1.6507,
          1.9621,  0.8730,  1.3824,  1.0624,  0.8089,  1.1917,  1.7591,  1.8287,
          1.6033,  1.9414,  1.9414,  0.9092,  0.8890,  1.9140,  1.6849,  0.9102,
          1.8467,  1.2884,  1.9652,  1.8760,  0.1559, -0.0501, -0.0759,  0.1086,
          0.3135,  0.3746,  0.0552, 21.5275,  1.7092,  0.8397,  1.4637,  1.5427,
          1.8021,  1.0513,  1.7154,  0.4288,  1.9489,  1.9705],
        [ 1.2847,  1.3129,  1.3696,  1.3489,  1.3190,  1.2895,  1.2532,  1.2823,
          1.2823,  1.2553,  1.3743,  1.2672,  1.4023,  1.3403,  1.4521,  1.2601,
          1.3259,  1.3171,  1.3372,  1.3182,  1.3788,  1.3511,  1.3088,  1.3040,
          1.1913,  1.2965,  1.2965,  1.3440,  1.3910,  1.3150,  1.0825,  1.2983,
          1.1896,  1.3585,  1.1855,  1.3176,  1.4702,  1.1606,  1.4515,  1.4824,
          1.0056,  0.9303,  1.4854,  1.3407,  0.8250,  3.8332,  2.7576,  3.8590,
          3.0642,  2.3305,  2.0178,  3.1637,  3.7739,  2.0023]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 399 : 179.9497420458603
Test loss for epoch 399 : 180.55468654509343
Test Precision for epoch 399 : 0.26153846153846155
Test Recall for epoch 399 : 0.26153846153846155
Test F1 for epoch 399 : 0.26153846153846155


Max Test F1 is for epoch 0 : 0.26153846153846155
