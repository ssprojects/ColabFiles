theta for epoch 0 : tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 0 : 1368.949645704203
Test loss for epoch 0 : 192.7837013905804
Test Precision for epoch 0 : 0.26153846153846155
Test Recall for epoch 0 : 0.26153846153846155
Test F1 for epoch 0 : 0.26153846153846155


theta for epoch 1 : tensor([[1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,
         0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,
         0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,
         0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 0.9000, 1.1000, 0.9000, 0.9000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 1 : 2011.1480223795265
Test loss for epoch 1 : 191.32827861157708
Test Precision for epoch 1 : 0.26153846153846155
Test Recall for epoch 1 : 0.26153846153846155
Test F1 for epoch 1 : 0.26153846153846155


theta for epoch 2 : tensor([[1.1985, 1.1984, 1.1985, 1.1984, 1.1984, 1.1983, 1.1983, 1.1981, 1.1981,
         1.0302, 1.0297, 1.0296, 1.0295, 1.0306, 1.0288, 1.0287, 1.0306, 1.0293,
         1.1819, 1.1811, 1.1819, 1.1815, 1.1817, 1.1817, 1.1820, 1.1818, 1.1818,
         1.1863, 1.1869, 1.1864, 1.1876, 1.1860, 1.1886, 1.1877, 1.1873, 1.1864,
         1.1826, 1.1833, 1.1829, 1.1825, 1.1825, 1.1823, 1.1835, 1.1799, 1.1803,
         1.1894, 1.1922, 1.1911, 1.1925, 1.1899, 1.1898, 1.1874, 1.1934, 1.1917],
        [0.9685, 0.9603, 0.9578, 0.9623, 0.9629, 0.9645, 0.9640, 0.9586, 0.9585,
         1.1249, 1.1244, 1.1230, 1.1263, 1.1260, 1.1281, 1.1197, 1.1255, 1.1264,
         0.9664, 0.9657, 0.9647, 0.9655, 0.9663, 0.9666, 0.9670, 0.9668, 0.9668,
         0.9624, 0.9605, 0.9616, 0.9641, 0.9595, 0.9662, 0.9646, 0.9638, 0.9613,
         0.9643, 0.9660, 0.9651, 0.9642, 0.9638, 0.9650, 0.9662, 0.9556, 0.9618,
         0.9560, 0.9656, 0.9637, 0.9663, 0.9575, 0.9599, 0.9481, 0.9682, 0.9644],
        [1.1999, 1.1997, 1.1996, 1.1997, 1.1997, 1.1998, 1.1997, 1.1995, 1.1995,
         1.0464, 1.0456, 1.0457, 1.0455, 1.0470, 1.0437, 1.0444, 1.0468, 1.0450,
         1.1745, 1.1748, 1.1754, 0.9739, 0.9732, 0.9732, 0.9743, 0.9730, 0.9730,
         1.1985, 1.1985, 1.1985, 1.1987, 1.1984, 1.1988, 1.1987, 1.1986, 1.1985,
         1.1958, 1.1960, 1.1959, 1.1957, 1.1957, 1.1958, 1.1961, 1.1948, 1.1950,
         1.1995, 1.1998, 1.1997, 1.1998, 1.1996, 1.1996, 1.1994, 1.1999, 1.1998],
        [1.1985, 1.1976, 1.1973, 1.1975, 1.1978, 1.1979, 1.1979, 1.1973, 1.1973,
         1.0373, 1.0366, 1.0365, 1.0364, 1.0379, 1.0356, 1.0355, 1.0378, 1.0356,
         1.1900, 1.1893, 1.1899, 1.1897, 1.1897, 1.1897, 1.1899, 1.1898, 1.1898,
         1.1942, 1.1938, 1.1931, 1.1938, 1.1940, 1.1938, 1.1942, 1.1935, 1.1931,
         1.1912, 1.1915, 1.1912, 1.1911, 1.1911, 1.1909, 1.1916, 1.1893, 1.1900,
         1.1973, 1.1980, 1.1976, 1.1981, 1.1974, 1.1973, 1.1969, 1.1984, 1.1979],
        [1.1995, 1.1990, 1.1986, 1.1989, 1.1990, 1.1992, 1.1992, 1.1989, 1.1989,
         1.0450, 1.0439, 1.0436, 1.0429, 1.0457, 1.0405, 1.0425, 1.0457, 1.0432,
         1.1933, 1.1928, 1.1929, 1.1930, 1.1933, 1.1933, 1.1932, 1.1934, 1.1934,
         1.1972, 1.1971, 1.1976, 1.1977, 1.1971, 1.1980, 1.1976, 1.1978, 1.1976,
         1.1801, 1.1798, 1.1787, 1.1798, 1.1815, 1.1819, 1.1805, 1.1850, 1.1845,
         1.1986, 1.1992, 1.1990, 1.1993, 1.1988, 1.1989, 1.1982, 1.1994, 1.1992],
        [1.1855, 1.1790, 1.1771, 1.1795, 1.1795, 1.1811, 1.1810, 1.1768, 1.1767,
         1.0270, 1.0265, 1.0265, 1.0263, 1.0275, 0.8254, 1.0257, 1.0275, 1.0261,
         1.1757, 1.1745, 0.9741, 1.1747, 1.1752, 1.1752, 1.1755, 1.1754, 1.1754,
         1.1763, 1.1745, 1.1761, 1.1763, 0.9743, 1.1781, 1.1780, 1.1770, 1.1760,
         1.1750, 1.1748, 1.1754, 1.1746, 0.9732, 0.9731, 1.1763, 0.9700, 0.9686,
         1.1993, 1.1993, 1.1993, 1.1993, 1.1992, 1.1991, 1.1993, 1.1993, 1.1992]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 2 : 1995.2182289315635
Test loss for epoch 2 : 186.23760739985326
Test Precision for epoch 2 : 0.26153846153846155
Test Recall for epoch 2 : 0.26153846153846155
Test F1 for epoch 2 : 0.26153846153846155


theta for epoch 3 : tensor([[1.2885, 1.2877, 1.2881, 1.2880, 1.2880, 1.2878, 1.2878, 1.2869, 1.2869,
         1.0113, 1.0099, 1.0098, 1.0097, 1.0126, 1.0082, 1.0068, 1.0126, 1.0089,
         1.2715, 1.2702, 1.2716, 1.2708, 1.2713, 1.2712, 1.2717, 1.2714, 1.2714,
         1.2296, 1.2318, 1.2301, 1.2336, 1.2294, 1.2362, 1.2339, 1.2324, 1.2300,
         1.2712, 1.2724, 1.2718, 1.2711, 1.2711, 1.2708, 1.2727, 1.2668, 1.2676,
         1.1595, 1.1648, 1.1629, 1.1657, 1.1602, 1.1598, 1.1553, 1.1679, 1.1638],
        [0.9675, 0.9400, 0.9358, 0.9458, 0.9471, 0.9503, 0.9491, 0.9313, 0.9312,
         1.1884, 1.1876, 1.1856, 1.1904, 1.1899, 1.1930, 1.1808, 1.1892, 1.1907,
         1.0451, 1.0438, 1.0422, 1.0434, 1.0449, 1.0454, 1.0461, 1.0456, 1.0456,
         0.9928, 0.9872, 0.9862, 0.9975, 0.9836, 1.0049, 1.0001, 0.9954, 0.9853,
         1.0378, 1.0411, 1.0393, 1.0377, 1.0371, 1.0393, 1.0415, 1.0220, 1.0336,
         0.9232, 0.9449, 0.9400, 0.9478, 0.9246, 0.9277, 0.9081, 0.9557, 0.9401],
        [1.2387, 1.2364, 1.2360, 1.2362, 1.2361, 1.2372, 1.2365, 1.2357, 1.2357,
         1.0495, 1.0481, 1.0482, 1.0479, 1.0505, 1.0443, 1.0458, 1.0502, 1.0469,
         1.2597, 1.2603, 1.2611, 1.0590, 1.0578, 1.0578, 1.0595, 1.0575, 1.0575,
         1.2796, 1.2795, 1.2798, 1.2802, 1.2793, 1.2805, 1.2803, 1.2801, 1.2797,
         1.2927, 1.2930, 1.2929, 1.2926, 1.2926, 1.2928, 1.2932, 1.2912, 1.2915,
         1.2206, 1.2234, 1.2227, 1.2236, 1.2203, 1.2217, 1.2192, 1.2243, 1.2229],
        [1.2155, 1.2106, 1.2084, 1.2086, 1.2113, 1.2117, 1.2118, 1.2084, 1.2084,
         1.0300, 1.0281, 1.0279, 1.0278, 1.0313, 1.0263, 1.0251, 1.0313, 1.0258,
         1.2843, 1.2832, 1.2841, 1.2838, 1.2839, 1.2838, 1.2842, 1.2840, 1.2840,
         1.2853, 1.2845, 1.2831, 1.2845, 1.2848, 1.2846, 1.2854, 1.2839, 1.2830,
         1.2855, 1.2859, 1.2855, 1.2852, 1.2853, 1.2850, 1.2862, 1.2824, 1.2835,
         1.1958, 1.1981, 1.1958, 1.1991, 1.1956, 1.1941, 1.1941, 1.2006, 1.1981],
        [1.2417, 1.2373, 1.2292, 1.2315, 1.2373, 1.2393, 1.2388, 1.2372, 1.2371,
         1.0487, 1.0465, 1.0456, 1.0443, 1.0504, 1.0390, 1.0430, 1.0504, 1.0450,
         1.2895, 1.2888, 1.2889, 1.2891, 1.2896, 1.2896, 1.2894, 1.2897, 1.2897,
         1.2772, 1.2772, 1.2801, 1.2802, 1.2775, 1.2812, 1.2797, 1.2806, 1.2799,
         1.2672, 1.2666, 1.2649, 1.2666, 1.2696, 1.2703, 1.2679, 1.2753, 1.2746,
         1.2182, 1.2215, 1.2218, 1.2253, 1.2194, 1.2221, 1.2134, 1.2257, 1.2247],
        [1.1565, 1.1448, 1.1415, 1.1456, 1.1452, 1.1480, 1.1479, 1.1408, 1.1407,
         1.0032, 1.0013, 1.0012, 1.0010, 1.0051, 0.8054, 0.9979, 1.0050, 1.0002,
         1.2618, 1.2599, 1.0593, 1.2600, 1.2609, 1.2609, 1.2614, 1.2612, 1.2612,
         1.2014, 1.1953, 1.2001, 1.2000, 1.0237, 1.2047, 1.2058, 1.2021, 1.1999,
         1.2586, 1.2583, 1.2593, 1.2580, 1.0565, 1.0564, 1.2609, 1.0511, 1.0488,
         1.2884, 1.2882, 1.2882, 1.2884, 1.2879, 1.2871, 1.2882, 1.2886, 1.2876]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 3 : 1987.9809457275292
Test loss for epoch 3 : 185.27893114991235
Test Precision for epoch 3 : 0.26153846153846155
Test Recall for epoch 3 : 0.26153846153846155
Test F1 for epoch 3 : 0.26153846153846155


theta for epoch 4 : tensor([[1.3822, 1.3810, 1.3815, 1.3814, 1.3814, 1.3811, 1.3812, 1.3797, 1.3798,
         1.0220, 1.0196, 1.0195, 1.0194, 1.0241, 1.0170, 1.0142, 1.0241, 1.0179,
         1.3219, 1.3198, 1.3222, 1.3207, 1.3215, 1.3215, 1.3224, 1.3217, 1.3217,
         1.2297, 1.2338, 1.2305, 1.2367, 1.2298, 1.2410, 1.2373, 1.2343, 1.2304,
         1.2579, 1.2597, 1.2586, 1.2578, 1.2580, 1.2573, 1.2601, 1.2517, 1.2528,
         1.1792, 1.1864, 1.1840, 1.1878, 1.1799, 1.1792, 1.1732, 1.1910, 1.1848],
        [1.0056, 0.9633, 0.9579, 0.9723, 0.9740, 0.9786, 0.9767, 0.9484, 0.9483,
         1.2657, 1.2647, 1.2623, 1.2680, 1.2674, 1.2711, 1.2565, 1.2666, 1.2683,
         1.0862, 1.0838, 1.0811, 1.0818, 1.0846, 1.0857, 1.0881, 1.0860, 1.0860,
         0.9881, 0.9784, 0.9740, 0.9962, 0.9719, 1.0103, 1.0016, 0.9918, 0.9726,
         1.0192, 1.0255, 1.0213, 1.0192, 1.0188, 1.0228, 1.0265, 0.9968, 1.0141,
         0.9353, 0.9678, 0.9604, 0.9726, 0.9365, 0.9399, 0.9129, 0.9855, 0.9598],
        [1.3022, 1.2989, 1.2982, 1.2986, 1.2984, 1.3001, 1.2989, 1.2979, 1.2979,
         1.0808, 1.0790, 1.0792, 1.0788, 1.0822, 1.0735, 1.0758, 1.0818, 1.0772,
         1.3294, 1.3301, 1.3316, 1.1335, 1.1317, 1.1317, 1.1343, 1.1313, 1.1313,
         1.3376, 1.3374, 1.3382, 1.3390, 1.3370, 1.3397, 1.3392, 1.3389, 1.3382,
         1.3098, 1.3104, 1.3101, 1.3094, 1.3097, 1.3099, 1.3107, 1.3056, 1.3064,
         1.2738, 1.2779, 1.2770, 1.2782, 1.2732, 1.2755, 1.2717, 1.2793, 1.2772],
        [1.2674, 1.2603, 1.2571, 1.2571, 1.2613, 1.2618, 1.2619, 1.2570, 1.2569,
         1.0523, 1.0494, 1.0489, 1.0490, 1.0544, 1.0468, 1.0444, 1.0543, 1.0457,
         1.3494, 1.3471, 1.3491, 1.3485, 1.3485, 1.3484, 1.3491, 1.3488, 1.3488,
         1.3708, 1.3691, 1.3668, 1.3693, 1.3699, 1.3696, 1.3710, 1.3683, 1.3667,
         1.2891, 1.2896, 1.2888, 1.2886, 1.2889, 1.2877, 1.2903, 1.2826, 1.2853,
         1.2360, 1.2393, 1.2358, 1.2408, 1.2356, 1.2332, 1.2336, 1.2432, 1.2393],
        [1.3078, 1.3012, 1.2887, 1.2921, 1.3012, 1.3041, 1.3033, 1.3010, 1.3010,
         1.0812, 1.0779, 1.0766, 1.0747, 1.0837, 1.0669, 1.0727, 1.0836, 1.0757,
         1.3625, 1.3609, 1.3611, 1.3616, 1.3630, 1.3630, 1.3621, 1.3633, 1.3633,
         1.3335, 1.3337, 1.3416, 1.3417, 1.3348, 1.3441, 1.3401, 1.3429, 1.3414,
         1.2811, 1.2799, 1.2765, 1.2798, 1.2858, 1.2877, 1.2829, 1.2982, 1.2968,
         1.2714, 1.2761, 1.2766, 1.2821, 1.2730, 1.2772, 1.2639, 1.2825, 1.2811],
        [1.1796, 1.1632, 1.1588, 1.1643, 1.1636, 1.1673, 1.1672, 1.1571, 1.1570,
         1.0087, 1.0051, 1.0050, 1.0048, 1.0121, 0.8164, 0.9985, 1.0121, 1.0032,
         1.3048, 1.3015, 1.1130, 1.3011, 1.3031, 1.3031, 1.3041, 1.3035, 1.3035,
         1.1835, 1.1734, 1.1810, 1.1808, 1.0395, 1.1880, 1.1904, 1.1842, 1.1809,
         1.2381, 1.2373, 1.2391, 1.2372, 1.0474, 1.0471, 1.2415, 1.0392, 1.0351,
         1.3816, 1.3812, 1.3812, 1.3816, 1.3807, 1.3796, 1.3813, 1.3819, 1.3803]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 4 : 1974.2012552674069
Test loss for epoch 4 : 183.70096209477688
Test Precision for epoch 4 : 0.26153846153846155
Test Recall for epoch 4 : 0.26153846153846155
Test F1 for epoch 4 : 0.26153846153846155


theta for epoch 5 : tensor([[1.4778, 1.4763, 1.4769, 1.4769, 1.4769, 1.4765, 1.4765, 1.4748, 1.4748,
         1.0517, 1.0483, 1.0482, 1.0481, 1.0546, 1.0449, 1.0406, 1.0546, 1.0460,
         1.2895, 1.2869, 1.2899, 1.2880, 1.2891, 1.2891, 1.2902, 1.2893, 1.2893,
         1.2413, 1.2473, 1.2422, 1.2511, 1.2417, 1.2569, 1.2521, 1.2476, 1.2421,
         1.2669, 1.2693, 1.2678, 1.2669, 1.2673, 1.2661, 1.2699, 1.2591, 1.2605,
         1.2210, 1.2297, 1.2268, 1.2315, 1.2216, 1.2206, 1.2136, 1.2357, 1.2277],
        [1.0575, 1.0022, 0.9957, 1.0141, 1.0162, 1.0219, 1.0195, 0.9816, 0.9814,
         1.3499, 1.3488, 1.3461, 1.3525, 1.3519, 1.3560, 1.3396, 1.3509, 1.3529,
         1.0522, 1.0492, 1.0459, 1.0461, 1.0497, 1.0510, 1.0546, 1.0514, 1.0514,
         0.9917, 0.9778, 0.9697, 1.0032, 0.9684, 1.0241, 1.0114, 0.9962, 0.9677,
         1.0215, 1.0310, 1.0244, 1.0216, 1.0215, 1.0275, 1.0326, 0.9923, 1.0156,
         0.9693, 1.0111, 1.0015, 1.0174, 0.9702, 0.9737, 0.9404, 1.0344, 1.0002],
        [1.3741, 1.3703, 1.3694, 1.3697, 1.3694, 1.3716, 1.3701, 1.3690, 1.3690,
         1.1286, 1.1264, 1.1266, 1.1262, 1.1303, 1.1196, 1.1226, 1.1297, 1.1242,
         1.3216, 1.3225, 1.3249, 1.1374, 1.1346, 1.1346, 1.1388, 1.1340, 1.1340,
         1.3996, 1.3994, 1.4008, 1.4019, 1.3989, 1.4027, 1.4021, 1.4017, 1.4008,
         1.3456, 1.3465, 1.3459, 1.3449, 1.3455, 1.3458, 1.3468, 1.3391, 1.3403,
         1.3405, 1.3455, 1.3444, 1.3459, 1.3397, 1.3426, 1.3380, 1.3472, 1.3447],
        [1.3308, 1.3221, 1.3179, 1.3178, 1.3233, 1.3238, 1.3239, 1.3178, 1.3177,
         1.0924, 1.0885, 1.0879, 1.0881, 1.0951, 1.0853, 1.0820, 1.0951, 1.0836,
         1.3275, 1.3242, 1.3272, 1.3263, 1.3263, 1.3262, 1.3272, 1.3267, 1.3267,
         1.4590, 1.4568, 1.4536, 1.4570, 1.4578, 1.4574, 1.4594, 1.4557, 1.4535,
         1.3138, 1.3143, 1.3130, 1.3129, 1.3135, 1.3115, 1.3153, 1.3041, 1.3085,
         1.2936, 1.2974, 1.2930, 1.2994, 1.2929, 1.2897, 1.2906, 1.3024, 1.2975],
        [1.3816, 1.3736, 1.3577, 1.3619, 1.3735, 1.3771, 1.3762, 1.3735, 1.3734,
         1.1298, 1.1257, 1.1240, 1.1217, 1.1329, 1.1118, 1.1191, 1.1328, 1.1230,
         1.3496, 1.3469, 1.3472, 1.3481, 1.3507, 1.3507, 1.3488, 1.3511, 1.3511,
         1.3939, 1.3944, 1.4070, 1.4068, 1.3961, 1.4103, 1.4043, 1.4088, 1.4066,
         1.3172, 1.3153, 1.3105, 1.3151, 1.3238, 1.3267, 1.3198, 1.3414, 1.3395,
         1.3381, 1.3438, 1.3446, 1.3513, 1.3401, 1.3454, 1.3288, 1.3518, 1.3501],
        [1.2205, 1.1996, 1.1943, 1.2010, 1.2000, 1.2045, 1.2044, 1.1914, 1.1912,
         1.0335, 1.0282, 1.0281, 1.0279, 1.0386, 0.8468, 1.0181, 1.0385, 1.0254,
         1.2686, 1.2646, 1.0839, 1.2640, 1.2665, 1.2665, 1.2677, 1.2670, 1.2670,
         1.1793, 1.1651, 1.1749, 1.1751, 1.0699, 1.1851, 1.1887, 1.1796, 1.1747,
         1.2404, 1.2390, 1.2415, 1.2391, 1.0621, 1.0617, 1.2449, 1.0512, 1.0453,
         1.4773, 1.4767, 1.4768, 1.4771, 1.4761, 1.4747, 1.4768, 1.4776, 1.4756]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 5 : 1956.9911030249898
Test loss for epoch 5 : 183.07964886396704
Test Precision for epoch 5 : 0.26153846153846155
Test Recall for epoch 5 : 0.26153846153846155
Test F1 for epoch 5 : 0.26153846153846155


theta for epoch 6 : tensor([[1.5480, 1.5452, 1.5463, 1.5462, 1.5462, 1.5454, 1.5456, 1.5423, 1.5423,
         1.0944, 1.0901, 1.0899, 1.0900, 1.0981, 1.0860, 1.0801, 1.0981, 1.0872,
         1.2751, 1.2721, 1.2757, 1.2733, 1.2747, 1.2747, 1.2761, 1.2750, 1.2750,
         1.2336, 1.2414, 1.2346, 1.2461, 1.2343, 1.2534, 1.2474, 1.2414, 1.2344,
         1.2947, 1.2977, 1.2958, 1.2948, 1.2953, 1.2938, 1.2983, 1.2854, 1.2871,
         1.2446, 1.2550, 1.2516, 1.2573, 1.2450, 1.2436, 1.2355, 1.2626, 1.2523],
        [1.0463, 0.9804, 0.9732, 0.9944, 0.9967, 1.0032, 1.0004, 0.9556, 0.9554,
         1.4383, 1.4372, 1.4342, 1.4412, 1.4404, 1.4449, 1.4272, 1.4394, 1.4416,
         1.0356, 1.0319, 1.0279, 1.0276, 1.0320, 1.0338, 1.0386, 1.0342, 1.0342,
         0.9794, 0.9615, 0.9497, 0.9943, 0.9493, 1.0219, 1.0054, 0.9848, 0.9472,
         1.0423, 1.0548, 1.0459, 1.0426, 1.0426, 1.0505, 1.0569, 1.0067, 1.0358,
         0.9835, 1.0357, 1.0236, 1.0439, 0.9839, 0.9874, 0.9474, 1.0660, 1.0215],
        [1.3801, 1.3755, 1.3744, 1.3747, 1.3744, 1.3771, 1.3752, 1.3741, 1.3740,
         1.1868, 1.1843, 1.1846, 1.1841, 1.1887, 1.1764, 1.1800, 1.1880, 1.1818,
         1.3342, 1.3352, 1.3384, 1.1612, 1.1576, 1.1576, 1.1631, 1.1569, 1.1569,
         1.4443, 1.4440, 1.4461, 1.4475, 1.4433, 1.4485, 1.4478, 1.4472, 1.4461,
         1.3954, 1.3964, 1.3958, 1.3946, 1.3954, 1.3956, 1.3968, 1.3871, 1.3887,
         1.3904, 1.3964, 1.3952, 1.3968, 1.3894, 1.3931, 1.3876, 1.3983, 1.3955],
        [1.3272, 1.3169, 1.3119, 1.3115, 1.3182, 1.3188, 1.3190, 1.3118, 1.3117,
         1.1441, 1.1394, 1.1387, 1.1390, 1.1474, 1.1357, 1.1315, 1.1473, 1.1335,
         1.3236, 1.3192, 1.3232, 1.3219, 1.3220, 1.3218, 1.3231, 1.3224, 1.3224,
         1.5435, 1.5404, 1.5363, 1.5407, 1.5418, 1.5412, 1.5440, 1.5390, 1.5361,
         1.3548, 1.3552, 1.3537, 1.3537, 1.3545, 1.3517, 1.3566, 1.3424, 1.3481,
         1.3336, 1.3380, 1.3326, 1.3405, 1.3326, 1.3285, 1.3301, 1.3441, 1.3381],
        [1.3895, 1.3796, 1.3593, 1.3645, 1.3794, 1.3841, 1.3828, 1.3797, 1.3797,
         1.1886, 1.1838, 1.1818, 1.1792, 1.1921, 1.1675, 1.1762, 1.1921, 1.1807,
         1.3538, 1.3501, 1.3505, 1.3519, 1.3556, 1.3556, 1.3527, 1.3561, 1.3561,
         1.4352, 1.4359, 1.4550, 1.4543, 1.4386, 1.4591, 1.4503, 1.4572, 1.4543,
         1.3692, 1.3668, 1.3610, 1.3666, 1.3774, 1.3810, 1.3725, 1.3991, 1.3968,
         1.3878, 1.3943, 1.3956, 1.4038, 1.3902, 1.3968, 1.3765, 1.4042, 1.4024],
        [1.1998, 1.1756, 1.1699, 1.1774, 1.1760, 1.1811, 1.1809, 1.1658, 1.1657,
         1.0718, 1.0647, 1.0646, 1.0645, 1.0785, 0.8906, 1.0510, 1.0785, 1.0612,
         1.2505, 1.2458, 1.0742, 1.2448, 1.2479, 1.2479, 1.2494, 1.2485, 1.2485,
         1.1580, 1.1400, 1.1515, 1.1526, 1.0837, 1.1653, 1.1699, 1.1579, 1.1513,
         1.2621, 1.2603, 1.2635, 1.2605, 1.0958, 1.0953, 1.2679, 1.0825, 1.0750,
         1.5686, 1.5678, 1.5679, 1.5684, 1.5671, 1.5652, 1.5681, 1.5689, 1.5663]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 6 : 1945.1047200934452
Test loss for epoch 6 : 183.89248841480028
Test Precision for epoch 6 : 0.26153846153846155
Test Recall for epoch 6 : 0.26153846153846155
Test F1 for epoch 6 : 0.26153846153846155


theta for epoch 7 : tensor([[1.6225, 1.6186, 1.6202, 1.6200, 1.6200, 1.6189, 1.6193, 1.6146, 1.6146,
         1.1462, 1.1410, 1.1408, 1.1409, 1.1506, 1.1363, 1.1290, 1.1505, 1.1376,
         1.2775, 1.2740, 1.2783, 1.2754, 1.2770, 1.2771, 1.2787, 1.2773, 1.2773,
         1.2307, 1.2403, 1.2318, 1.2457, 1.2318, 1.2542, 1.2473, 1.2399, 1.2317,
         1.3341, 1.3375, 1.3352, 1.3342, 1.3349, 1.3329, 1.3382, 1.3234, 1.3254,
         1.2114, 1.2227, 1.2191, 1.2253, 1.2118, 1.2101, 1.2015, 1.2312, 1.2198],
        [1.0437, 0.9669, 0.9590, 0.9831, 0.9856, 0.9929, 0.9898, 0.9377, 0.9376,
         1.5292, 1.5280, 1.5248, 1.5323, 1.5315, 1.5363, 1.5175, 1.5304, 1.5328,
         1.0359, 1.0316, 1.0269, 1.0260, 1.0313, 1.0334, 1.0395, 1.0339, 1.0339,
         0.9737, 0.9521, 0.9367, 0.9919, 0.9372, 1.0260, 1.0057, 0.9799, 0.9338,
         1.0755, 1.0908, 1.0797, 1.0759, 1.0761, 1.0857, 1.0934, 1.0338, 1.0684,
         0.9461, 1.0038, 0.9904, 1.0131, 0.9462, 0.9497, 0.9066, 1.0384, 0.9877],
        [1.3921, 1.3869, 1.3855, 1.3858, 1.3854, 1.3887, 1.3863, 1.3853, 1.3852,
         1.2520, 1.2492, 1.2496, 1.2491, 1.2540, 1.2405, 1.2446, 1.2533, 1.2465,
         1.3636, 1.3647, 1.3686, 1.2008, 1.1965, 1.1964, 1.2032, 1.1956, 1.1956,
         1.4874, 1.4870, 1.4900, 1.4916, 1.4863, 1.4927, 1.4919, 1.4913, 1.4900,
         1.4535, 1.4547, 1.4540, 1.4525, 1.4535, 1.4538, 1.4551, 1.4437, 1.4456,
         1.3739, 1.3806, 1.3792, 1.3811, 1.3726, 1.3769, 1.3707, 1.3827, 1.3796],
        [1.3303, 1.3186, 1.3127, 1.3121, 1.3201, 1.3207, 1.3209, 1.3127, 1.3126,
         1.2037, 1.1984, 1.1975, 1.1980, 1.2075, 1.1942, 1.1893, 1.2074, 1.1916,
         1.3357, 1.3303, 1.3352, 1.3338, 1.3338, 1.3335, 1.3352, 1.3343, 1.3343,
         1.6292, 1.6253, 1.6204, 1.6257, 1.6272, 1.6263, 1.6298, 1.6236, 1.6202,
         1.4055, 1.4059, 1.4041, 1.4042, 1.4053, 1.4017, 1.4076, 1.3908, 1.3977,
         1.3098, 1.3146, 1.3086, 1.3174, 1.3087, 1.3040, 1.3060, 1.3215, 1.3148],
        [1.4030, 1.3917, 1.3669, 1.3730, 1.3913, 1.3969, 1.3954, 1.3921, 1.3920,
         1.2543, 1.2490, 1.2467, 1.2437, 1.2582, 1.2305, 1.2406, 1.2581, 1.2456,
         1.3733, 1.3687, 1.3692, 1.3710, 1.3758, 1.3757, 1.3718, 1.3764, 1.3764,
         1.4746, 1.4758, 1.5012, 1.4998, 1.4793, 1.5058, 1.4945, 1.5038, 1.5002,
         1.4310, 1.4282, 1.4215, 1.4279, 1.4404, 1.4446, 1.4349, 1.4655, 1.4628,
         1.3709, 1.3779, 1.3797, 1.3891, 1.3735, 1.3813, 1.3580, 1.3893, 1.3875],
        [1.1881, 1.1601, 1.1539, 1.1623, 1.1607, 1.1663, 1.1661, 1.1485, 1.1483,
         1.1199, 1.1110, 1.1108, 1.1109, 1.1282, 0.9435, 1.0935, 1.1281, 1.1066,
         1.2496, 1.2441, 1.0820, 1.2426, 1.2464, 1.2463, 1.2483, 1.2470, 1.2470,
         1.1455, 1.1240, 1.1366, 1.1390, 1.1043, 1.1546, 1.1599, 1.1450, 1.1364,
         1.2963, 1.2941, 1.2979, 1.2944, 1.1411, 1.1405, 1.3033, 1.1256, 1.1167,
         1.6252, 1.6235, 1.6237, 1.6246, 1.6222, 1.6186, 1.6242, 1.6256, 1.6206]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 7 : 1923.4528614606304
Test loss for epoch 7 : 184.3465367097762
Test Precision for epoch 7 : 0.26153846153846155
Test Recall for epoch 7 : 0.26153846153846155
Test F1 for epoch 7 : 0.26153846153846155


theta for epoch 8 : tensor([[1.7003, 1.6955, 1.6975, 1.6973, 1.6973, 1.6959, 1.6963, 1.6906, 1.6906,
         1.2042, 1.1982, 1.1980, 1.1982, 1.2092, 1.1930, 1.1843, 1.2092, 1.1943,
         1.2928, 1.2888, 1.2938, 1.2905, 1.2924, 1.2924, 1.2942, 1.2927, 1.2927,
         1.1874, 1.1978, 1.1887, 1.2037, 1.1887, 1.2127, 1.2054, 1.1973, 1.1885,
         1.3529, 1.3569, 1.3542, 1.3531, 1.3540, 1.3515, 1.3576, 1.3409, 1.3432,
         1.1808, 1.1929, 1.1891, 1.1958, 1.1811, 1.1792, 1.1701, 1.2023, 1.1897],
        [1.0499, 0.9618, 0.9532, 0.9802, 0.9830, 0.9911, 0.9875, 0.9280, 0.9278,
         1.6212, 1.6200, 1.6166, 1.6245, 1.6236, 1.6287, 1.6089, 1.6224, 1.6250,
         1.0505, 1.0454, 1.0400, 1.0386, 1.0448, 1.0472, 1.0546, 1.0477, 1.0477,
         0.9330, 0.9091, 0.8916, 0.9533, 0.8926, 0.9915, 0.9688, 0.9397, 0.8883,
         1.0912, 1.1097, 1.0962, 1.0918, 1.0922, 1.1038, 1.1128, 1.0432, 1.0836,
         0.9129, 0.9763, 0.9614, 0.9868, 0.9126, 0.9159, 0.8696, 1.0154, 0.9582],
        [1.4082, 1.4026, 1.4011, 1.4013, 1.4008, 1.4046, 1.4018, 1.4010, 1.4009,
         1.3219, 1.3190, 1.3193, 1.3188, 1.3240, 1.3094, 1.3141, 1.3232, 1.3160,
         1.4053, 1.4064, 1.4110, 1.2515, 1.2465, 1.2465, 1.2542, 1.2456, 1.2456,
         1.4769, 1.4764, 1.4802, 1.4820, 1.4755, 1.4834, 1.4825, 1.4817, 1.4801,
         1.4926, 1.4938, 1.4931, 1.4914, 1.4926, 1.4929, 1.4942, 1.4811, 1.4833,
         1.3592, 1.3666, 1.3652, 1.3672, 1.3578, 1.3628, 1.3558, 1.3689, 1.3656],
        [1.3381, 1.3253, 1.3186, 1.3177, 1.3270, 1.3275, 1.3277, 1.3188, 1.3187,
         1.2688, 1.2628, 1.2618, 1.2624, 1.2729, 1.2583, 1.2526, 1.2728, 1.2552,
         1.3602, 1.3539, 1.3597, 1.3580, 1.3579, 1.3577, 1.3596, 1.3586, 1.3586,
         1.6889, 1.6830, 1.6761, 1.6836, 1.6858, 1.6845, 1.6898, 1.6806, 1.6758,
         1.4363, 1.4366, 1.4346, 1.4348, 1.4361, 1.4316, 1.4386, 1.4189, 1.4272,
         1.2884, 1.2933, 1.2867, 1.2964, 1.2869, 1.2818, 1.2842, 1.3009, 1.2936],
        [1.4205, 1.4080, 1.3790, 1.3858, 1.4074, 1.4139, 1.4122, 1.4088, 1.4087,
         1.3246, 1.3189, 1.3163, 1.3131, 1.3288, 1.2986, 1.3098, 1.3287, 1.3152,
         1.4044, 1.3991, 1.3995, 1.4017, 1.4076, 1.4075, 1.4026, 1.4083, 1.4083,
         1.4596, 1.4611, 1.4925, 1.4905, 1.4653, 1.4978, 1.4838, 1.4955, 1.4913,
         1.4794, 1.4760, 1.4683, 1.4757, 1.4901, 1.4950, 1.4839, 1.5189, 1.5159,
         1.3559, 1.3632, 1.3656, 1.3761, 1.3588, 1.3676, 1.3415, 1.3761, 1.3744],
        [1.1825, 1.1507, 1.1440, 1.1533, 1.1513, 1.1575, 1.1572, 1.1371, 1.1370,
         1.1744, 1.1638, 1.1636, 1.1638, 1.1843, 1.0026, 1.1425, 1.1842, 1.1586,
         1.2618, 1.2555, 1.1029, 1.2535, 1.2580, 1.2579, 1.2603, 1.2587, 1.2587,
         1.0976, 1.0744, 1.0875, 1.0905, 1.0731, 1.1075, 1.1130, 1.0968, 1.0874,
         1.3100, 1.3074, 1.3117, 1.3077, 1.1671, 1.1664, 1.3182, 1.1492, 1.1387,
         1.6860, 1.6834, 1.6837, 1.6850, 1.6815, 1.6762, 1.6845, 1.6864, 1.6792]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 8 : 1910.6905843279749
Test loss for epoch 8 : 186.52374550319124
Test Precision for epoch 8 : 0.26153846153846155
Test Recall for epoch 8 : 0.26153846153846155
Test F1 for epoch 8 : 0.26153846153846155


theta for epoch 9 : tensor([[1.7800, 1.7744, 1.7768, 1.7766, 1.7765, 1.7749, 1.7754, 1.7687, 1.7687,
         1.2625, 1.2558, 1.2554, 1.2558, 1.2683, 1.2500, 1.2397, 1.2683, 1.2513,
         1.3180, 1.3136, 1.3192, 1.3154, 1.3176, 1.3177, 1.3197, 1.3179, 1.3179,
         1.1721, 1.1832, 1.1736, 1.1892, 1.1736, 1.1986, 1.1910, 1.1825, 1.1735,
         1.3280, 1.3323, 1.3293, 1.3282, 1.3292, 1.3264, 1.3330, 1.3150, 1.3174,
         1.1650, 1.1777, 1.1738, 1.1809, 1.1652, 1.1630, 1.1535, 1.1879, 1.1742],
        [1.0626, 0.9631, 0.9540, 0.9838, 0.9868, 0.9956, 0.9916, 0.9244, 0.9243,
         1.7114, 1.7103, 1.7067, 1.7150, 1.7139, 1.7195, 1.6987, 1.7127, 1.7156,
         1.0770, 1.0713, 1.0652, 1.0631, 1.0702, 1.0730, 1.0816, 1.0735, 1.0735,
         0.9284, 0.9027, 0.8834, 0.9502, 0.8850, 0.9917, 0.9671, 0.9354, 0.8799,
         1.0661, 1.0870, 1.0717, 1.0668, 1.0674, 1.0805, 1.0906, 1.0136, 1.0582,
         0.8977, 0.9671, 0.9507, 0.9788, 0.8970, 0.9002, 0.8508, 1.0109, 0.9468],
        [1.4251, 1.4192, 1.4175, 1.4176, 1.4171, 1.4213, 1.4181, 1.4175, 1.4175,
         1.3917, 1.3887, 1.3891, 1.3886, 1.3939, 1.3784, 1.3837, 1.3931, 1.3855,
         1.4559, 1.4570, 1.4622, 1.3102, 1.3047, 1.3046, 1.3132, 1.3036, 1.3036,
         1.4858, 1.4852, 1.4897, 1.4917, 1.4844, 1.4932, 1.4922, 1.4913, 1.4897,
         1.4836, 1.4849, 1.4841, 1.4822, 1.4836, 1.4839, 1.4853, 1.4706, 1.4730,
         1.3585, 1.3664, 1.3649, 1.3670, 1.3568, 1.3624, 1.3549, 1.3687, 1.3653],
        [1.3468, 1.3331, 1.3256, 1.3242, 1.3349, 1.3353, 1.3356, 1.3261, 1.3260,
         1.3339, 1.3273, 1.3262, 1.3269, 1.3384, 1.3224, 1.3162, 1.3383, 1.3189,
         1.3939, 1.3867, 1.3933, 1.3915, 1.3914, 1.3911, 1.3933, 1.3922, 1.3922,
         1.7588, 1.7514, 1.7431, 1.7521, 1.7550, 1.7532, 1.7599, 1.7484, 1.7426,
         1.4201, 1.4203, 1.4181, 1.4183, 1.4199, 1.4146, 1.4225, 1.4006, 1.4099,
         1.2811, 1.2861, 1.2790, 1.2895, 1.2794, 1.2738, 1.2767, 1.2943, 1.2865],
        [1.4385, 1.4249, 1.3919, 1.3994, 1.4242, 1.4315, 1.4295, 1.4262, 1.4262,
         1.3947, 1.3887, 1.3859, 1.3824, 1.3991, 1.3666, 1.3791, 1.3991, 1.3848,
         1.4442, 1.4382, 1.4386, 1.4412, 1.4480, 1.4479, 1.4421, 1.4488, 1.4488,
         1.4646, 1.4665, 1.5028, 1.5002, 1.4712, 1.5085, 1.4924, 1.5061, 1.5014,
         1.4820, 1.4781, 1.4696, 1.4778, 1.4941, 1.4998, 1.4873, 1.5269, 1.5236,
         1.3547, 1.3622, 1.3651, 1.3766, 1.3578, 1.3676, 1.3389, 1.3763, 1.3749],
        [1.1781, 1.1427, 1.1357, 1.1457, 1.1434, 1.1501, 1.1499, 1.1275, 1.1273,
         1.2291, 1.2166, 1.2164, 1.2168, 1.2406, 1.0617, 1.1912, 1.2405, 1.2107,
         1.2839, 1.2769, 1.1334, 1.2743, 1.2795, 1.2794, 1.2822, 1.2803, 1.2803,
         1.0789, 1.0545, 1.0681, 1.0714, 1.0682, 1.0893, 1.0951, 1.0779, 1.0679,
         1.2814, 1.2785, 1.2833, 1.2789, 1.1475, 1.1467, 1.2905, 1.1278, 1.1161,
         1.7552, 1.7518, 1.7522, 1.7538, 1.7495, 1.7429, 1.7534, 1.7555, 1.7465]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 9 : 1906.8886870523188
Test loss for epoch 9 : 188.99668040683173
Test Precision for epoch 9 : 0.26153846153846155
Test Recall for epoch 9 : 0.26153846153846155
Test F1 for epoch 9 : 0.26153846153846155


theta for epoch 10 : tensor([[1.8629, 1.8567, 1.8595, 1.8592, 1.8591, 1.8572, 1.8579, 1.8503, 1.8504,
         1.2682, 1.2605, 1.2601, 1.2607, 1.2747, 1.2542, 1.2423, 1.2747, 1.2555,
         1.3508, 1.3459, 1.3521, 1.3479, 1.3504, 1.3505, 1.3526, 1.3507, 1.3507,
         1.1846, 1.1963, 1.1865, 1.2024, 1.1864, 1.2118, 1.2043, 1.1954, 1.1864,
         1.3131, 1.3178, 1.3146, 1.3134, 1.3146, 1.3113, 1.3184, 1.2992, 1.3018,
         1.1646, 1.1780, 1.1739, 1.1814, 1.1647, 1.1624, 1.1525, 1.1888, 1.1743],
        [1.0873, 0.9768, 0.9672, 0.9997, 1.0029, 1.0125, 1.0081, 0.9334, 0.9333,
         1.7705, 1.7694, 1.7652, 1.7748, 1.7732, 1.7801, 1.7564, 1.7719, 1.7756,
         1.1131, 1.1067, 1.1001, 1.0974, 1.1052, 1.1084, 1.1183, 1.1090, 1.1090,
         0.9539, 0.9269, 0.9063, 0.9768, 0.9084, 1.0206, 0.9947, 0.9611, 0.9027,
         1.0549, 1.0784, 1.0611, 1.0558, 1.0565, 1.0711, 1.0823, 0.9980, 1.0466,
         0.9015, 0.9765, 0.9587, 0.9894, 0.9003, 0.9033, 0.8509, 1.0248, 0.9542],
        [1.4479, 1.4419, 1.4400, 1.4400, 1.4394, 1.4440, 1.4405, 1.4402, 1.4402,
         1.4096, 1.4065, 1.4069, 1.4064, 1.4119, 1.3955, 1.4014, 1.4110, 1.4032,
         1.5131, 1.5142, 1.5199, 1.3745, 1.3686, 1.3685, 1.3779, 1.3674, 1.3674,
         1.5151, 1.5145, 1.5195, 1.5216, 1.5137, 1.5231, 1.5220, 1.5211, 1.5195,
         1.4841, 1.4855, 1.4847, 1.4827, 1.4842, 1.4844, 1.4859, 1.4699, 1.4725,
         1.3720, 1.3804, 1.3789, 1.3810, 1.3702, 1.3763, 1.3684, 1.3827, 1.3793],
        [1.3618, 1.3475, 1.3391, 1.3374, 1.3493, 1.3496, 1.3500, 1.3401, 1.3400,
         1.3465, 1.3394, 1.3382, 1.3389, 1.3514, 1.3342, 1.3275, 1.3513, 1.3302,
         1.4346, 1.4266, 1.4340, 1.4319, 1.4318, 1.4316, 1.4339, 1.4327, 1.4327,
         1.8370, 1.8285, 1.8191, 1.8293, 1.8326, 1.8306, 1.8383, 1.8251, 1.8186,
         1.4137, 1.4137, 1.4114, 1.4117, 1.4134, 1.4074, 1.4161, 1.3921, 1.4025,
         1.2886, 1.2937, 1.2860, 1.2973, 1.2867, 1.2807, 1.2842, 1.3023, 1.2942],
        [1.4620, 1.4477, 1.4109, 1.4190, 1.4468, 1.4549, 1.4527, 1.4496, 1.4495,
         1.4131, 1.4068, 1.4037, 1.3999, 1.4177, 1.3828, 1.3969, 1.4176, 1.4027,
         1.4905, 1.4838, 1.4843, 1.4873, 1.4949, 1.4947, 1.4881, 1.4957, 1.4957,
         1.4908, 1.4930, 1.5331, 1.5299, 1.4981, 1.5388, 1.5213, 1.5365, 1.5315,
         1.4961, 1.4917, 1.4823, 1.4913, 1.5093, 1.5158, 1.5020, 1.5457, 1.5422,
         1.3679, 1.3753, 1.3788, 1.3911, 1.3711, 1.3818, 1.3509, 1.3905, 1.3894],
        [1.1806, 1.1420, 1.1345, 1.1453, 1.1426, 1.1499, 1.1496, 1.1252, 1.1251,
         1.2311, 1.2167, 1.2164, 1.2172, 1.2444, 1.0683, 1.1870, 1.2443, 1.2099,
         1.3134, 1.3057, 1.1709, 1.3026, 1.3085, 1.3084, 1.3115, 1.3093, 1.3093,
         1.0890, 1.0638, 1.0777, 1.0812, 1.0887, 1.0997, 1.1058, 1.0879, 1.0776,
         1.2627, 1.2594, 1.2647, 1.2600, 1.1377, 1.1368, 1.2726, 1.1163, 1.1034,
         1.8315, 1.8275, 1.8281, 1.8298, 1.8250, 1.8172, 1.8295, 1.8317, 1.8213]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 10 : 1897.2382025572995
Test loss for epoch 10 : 187.1227082706068
Test Precision for epoch 10 : 0.26153846153846155
Test Recall for epoch 10 : 0.26153846153846155
Test F1 for epoch 10 : 0.26153846153846155


theta for epoch 11 : tensor([[1.9463, 1.9396, 1.9427, 1.9424, 1.9423, 1.9402, 1.9409, 1.9327, 1.9327,
         1.2473, 1.2388, 1.2384, 1.2391, 1.2545, 1.2320, 1.2185, 1.2545, 1.2333,
         1.3876, 1.3823, 1.3891, 1.3846, 1.3873, 1.3874, 1.3897, 1.3877, 1.3877,
         1.2140, 1.2262, 1.2162, 1.2323, 1.2160, 1.2418, 1.2342, 1.2251, 1.2160,
         1.3111, 1.3161, 1.3127, 1.3114, 1.3128, 1.3091, 1.3167, 1.2962, 1.2990,
         1.1774, 1.1912, 1.1871, 1.1948, 1.1773, 1.1748, 1.1646, 1.2027, 1.1873],
        [1.1161, 0.9949, 0.9848, 1.0199, 1.0231, 1.0334, 1.0287, 0.9467, 0.9466,
         1.8082, 1.8072, 1.8023, 1.8135, 1.8112, 1.8198, 1.7925, 1.8097, 1.8145,
         1.1545, 1.1475, 1.1402, 1.1369, 1.1456, 1.1490, 1.1602, 1.1497, 1.1497,
         0.9954, 0.9674, 0.9458, 1.0193, 0.9483, 1.0649, 1.0379, 1.0028, 0.9421,
         1.0585, 1.0846, 1.0653, 1.0595, 1.0604, 1.0766, 1.0889, 0.9973, 1.0498,
         0.9195, 0.9998, 0.9807, 1.0138, 0.9178, 0.9205, 0.8654, 1.0522, 0.9756],
        [1.4707, 1.4648, 1.4627, 1.4625, 1.4619, 1.4668, 1.4630, 1.4631, 1.4631,
         1.3995, 1.3963, 1.3968, 1.3963, 1.4017, 1.3846, 1.3912, 1.4008, 1.3928,
         1.5738, 1.5749, 1.5811, 1.4419, 1.4355, 1.4355, 1.4455, 1.4343, 1.4343,
         1.5567, 1.5559, 1.5614, 1.5635, 1.5552, 1.5650, 1.5639, 1.5630, 1.5614,
         1.4964, 1.4978, 1.4970, 1.4948, 1.4964, 1.4967, 1.4982, 1.4809, 1.4838,
         1.3972, 1.4059, 1.4044, 1.4064, 1.3953, 1.4018, 1.3935, 1.4082, 1.4047],
        [1.3770, 1.3623, 1.3533, 1.3511, 1.3642, 1.3643, 1.3648, 1.3547, 1.3546,
         1.3317, 1.3241, 1.3227, 1.3236, 1.3369, 1.3186, 1.3114, 1.3368, 1.3141,
         1.4789, 1.4701, 1.4782, 1.4761, 1.4759, 1.4757, 1.4782, 1.4769, 1.4769,
         1.9204, 1.9110, 1.9008, 1.9119, 1.9156, 1.9132, 1.9218, 1.9073, 1.9002,
         1.4195, 1.4193, 1.4169, 1.4174, 1.4192, 1.4124, 1.4220, 1.3959, 1.4072,
         1.3084, 1.3134, 1.3053, 1.3172, 1.3063, 1.2999, 1.3039, 1.3223, 1.3141],
        [1.4853, 1.4705, 1.4302, 1.4387, 1.4694, 1.4781, 1.4758, 1.4729, 1.4729,
         1.4034, 1.3969, 1.3936, 1.3895, 1.4081, 1.3711, 1.3868, 1.4081, 1.3927,
         1.5400, 1.5328, 1.5333, 1.5367, 1.5450, 1.5448, 1.5374, 1.5459, 1.5459,
         1.5297, 1.5323, 1.5753, 1.5716, 1.5376, 1.5809, 1.5622, 1.5787, 1.5736,
         1.5225, 1.5176, 1.5076, 1.5172, 1.5368, 1.5440, 1.5291, 1.5762, 1.5726,
         1.3927, 1.3998, 1.4040, 1.4170, 1.3961, 1.4075, 1.3747, 1.4160, 1.4153],
        [1.1841, 1.1426, 1.1347, 1.1462, 1.1432, 1.1510, 1.1506, 1.1244, 1.1243,
         1.2071, 1.1910, 1.1906, 1.1916, 1.2220, 1.0482, 1.1576, 1.2219, 1.1835,
         1.3471, 1.3386, 1.2125, 1.3351, 1.3417, 1.3416, 1.3450, 1.3426, 1.3426,
         1.1167, 1.0907, 1.1049, 1.1085, 1.1246, 1.1275, 1.1337, 1.1154, 1.1048,
         1.2569, 1.2532, 1.2590, 1.2539, 1.1406, 1.1395, 1.2675, 1.1176, 1.1033,
         1.9129, 1.9083, 1.9090, 1.9109, 1.9056, 1.8969, 1.9107, 1.9129, 1.9014]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 11 : 1883.2359003197666
Test loss for epoch 11 : 183.62161922463065
Test Precision for epoch 11 : 0.26153846153846155
Test Recall for epoch 11 : 0.26153846153846155
Test F1 for epoch 11 : 0.26153846153846155


theta for epoch 12 : tensor([[2.0224, 2.0151, 2.0187, 2.0183, 2.0182, 2.0157, 2.0166, 2.0075, 2.0075,
         1.2277, 1.2183, 1.2178, 1.2187, 1.2357, 1.2111, 1.1960, 1.2357, 1.2124,
         1.4149, 1.4091, 1.4166, 1.4117, 1.4146, 1.4148, 1.4172, 1.4150, 1.4150,
         1.2322, 1.2448, 1.2347, 1.2510, 1.2343, 1.2604, 1.2528, 1.2436, 1.2346,
         1.3209, 1.3262, 1.3225, 1.3213, 1.3227, 1.3186, 1.3268, 1.3051, 1.3080,
         1.1997, 1.2141, 1.2099, 1.2179, 1.1996, 1.1969, 1.1864, 1.2263, 1.2100],
        [1.1307, 0.9990, 0.9885, 1.0260, 1.0294, 1.0403, 1.0353, 0.9462, 0.9461,
         1.8486, 1.8476, 1.8420, 1.8549, 1.8518, 1.8623, 1.8312, 1.8501, 1.8561,
         1.1867, 1.1791, 1.1711, 1.1672, 1.1767, 1.1805, 1.1929, 1.1811, 1.1811,
         1.0269, 0.9979, 0.9755, 1.0516, 0.9784, 1.0988, 1.0709, 1.0345, 0.9718,
         1.0737, 1.1021, 1.0811, 1.0748, 1.0758, 1.0935, 1.1068, 1.0082, 1.0646,
         0.9460, 1.0313, 1.0110, 1.0464, 0.9439, 0.9464, 0.8886, 1.0877, 1.0053],
        [1.4781, 1.4723, 1.4701, 1.4697, 1.4691, 1.4744, 1.4702, 1.4707, 1.4707,
         1.3902, 1.3870, 1.3875, 1.3869, 1.3924, 1.3745, 1.3819, 1.3914, 1.3833,
         1.6266, 1.6278, 1.6345, 1.5020, 1.4951, 1.4951, 1.5058, 1.4939, 1.4939,
         1.5840, 1.5832, 1.5892, 1.5911, 1.5826, 1.5926, 1.5916, 1.5907, 1.5891,
         1.5188, 1.5202, 1.5194, 1.5171, 1.5189, 1.5192, 1.5207, 1.5023, 1.5054,
         1.4304, 1.4393, 1.4379, 1.4399, 1.4284, 1.4353, 1.4268, 1.4416, 1.4382],
        [1.3773, 1.3624, 1.3525, 1.3499, 1.3642, 1.3642, 1.3647, 1.3545, 1.3544,
         1.3179, 1.3098, 1.3083, 1.3092, 1.3234, 1.3040, 1.2964, 1.3232, 1.2991,
         1.5134, 1.5037, 1.5127, 1.5103, 1.5101, 1.5099, 1.5126, 1.5112, 1.5112,
         1.9962, 1.9856, 1.9745, 1.9867, 1.9909, 1.9880, 1.9978, 1.9815, 1.9738,
         1.4361, 1.4357, 1.4333, 1.4338, 1.4358, 1.4283, 1.4386, 1.4106, 1.4229,
         1.3369, 1.3417, 1.3333, 1.3457, 1.3346, 1.3278, 1.3323, 1.3510, 1.3426],
        [1.4931, 1.4779, 1.4343, 1.4431, 1.4766, 1.4859, 1.4834, 1.4808, 1.4808,
         1.3945, 1.3879, 1.3842, 1.3799, 1.3993, 1.3603, 1.3776, 1.3992, 1.3835,
         1.5797, 1.5720, 1.5725, 1.5762, 1.5853, 1.5851, 1.5768, 1.5863, 1.5863,
         1.5544, 1.5573, 1.6030, 1.5987, 1.5628, 1.6085, 1.5888, 1.6064, 1.6011,
         1.5592, 1.5539, 1.5433, 1.5535, 1.5744, 1.5822, 1.5663, 1.6164, 1.6127,
         1.4255, 1.4324, 1.4371, 1.4507, 1.4291, 1.4412, 1.4068, 1.4493, 1.4490],
        [1.1742, 1.1300, 1.1216, 1.1338, 1.1304, 1.1387, 1.1383, 1.1105, 1.1104,
         1.1843, 1.1665, 1.1660, 1.1674, 1.2009, 1.0294, 1.1293, 1.2008, 1.1583,
         1.3711, 1.3619, 1.2446, 1.3579, 1.3652, 1.3650, 1.3688, 1.3661, 1.3661,
         1.1336, 1.1072, 1.1216, 1.1251, 1.1484, 1.1446, 1.1509, 1.1322, 1.1215,
         1.2629, 1.2588, 1.2652, 1.2597, 1.1550, 1.1538, 1.2743, 1.1304, 1.1150,
         1.9971, 1.9920, 1.9927, 1.9947, 1.9891, 1.9796, 1.9947, 1.9969, 1.9845]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 12 : 1880.2743748734258
Test loss for epoch 12 : 182.6025761353016
Test Precision for epoch 12 : 0.26153846153846155
Test Recall for epoch 12 : 0.26153846153846155
Test F1 for epoch 12 : 0.26153846153846155


theta for epoch 13 : tensor([[2.0985, 2.0907, 2.0947, 2.0943, 2.0941, 2.0913, 2.0923, 2.0824, 2.0824,
         1.2171, 1.2069, 1.2064, 1.2074, 1.2259, 1.1993, 1.1824, 1.2259, 1.2005,
         1.4213, 1.4150, 1.4232, 1.4179, 1.4210, 1.4212, 1.4239, 1.4215, 1.4215,
         1.2263, 1.2392, 1.2290, 1.2454, 1.2286, 1.2547, 1.2472, 1.2379, 1.2289,
         1.3410, 1.3465, 1.3427, 1.3414, 1.3430, 1.3385, 1.3471, 1.3243, 1.3274,
         1.2277, 1.2426, 1.2383, 1.2467, 1.2274, 1.2245, 1.2138, 1.2555, 1.2383],
        [1.1469, 1.0054, 0.9944, 1.0343, 1.0378, 1.0494, 1.0440, 0.9484, 0.9483,
         1.8967, 1.8959, 1.8896, 1.9041, 1.9002, 1.9125, 1.8780, 1.8983, 1.9055,
         1.1979, 1.1896, 1.1809, 1.1764, 1.1868, 1.1909, 1.2046, 1.1916, 1.1916,
         1.0340, 1.0041, 0.9814, 1.0593, 0.9844, 1.1078, 1.0791, 1.0417, 0.9776,
         1.0979, 1.1287, 1.1060, 1.0993, 1.1003, 1.1195, 1.1336, 1.0285, 1.0885,
         0.9762, 1.0663, 1.0448, 1.0825, 0.9737, 0.9760, 0.9156, 1.1266, 1.0386],
        [1.4883, 1.4826, 1.4803, 1.4797, 1.4790, 1.4846, 1.4802, 1.4811, 1.4810,
         1.3891, 1.3859, 1.3865, 1.3859, 1.3914, 1.3728, 1.3810, 1.3904, 1.3821,
         1.6606, 1.6618, 1.6689, 1.5442, 1.5368, 1.5368, 1.5483, 1.5355, 1.5355,
         1.5847, 1.5838, 1.5902, 1.5922, 1.5833, 1.5936, 1.5926, 1.5917, 1.5902,
         1.5499, 1.5513, 1.5505, 1.5481, 1.5499, 1.5502, 1.5517, 1.5324, 1.5357,
         1.4679, 1.4769, 1.4755, 1.4775, 1.4657, 1.4730, 1.4643, 1.4792, 1.4759],
        [1.3812, 1.3662, 1.3557, 1.3526, 1.3680, 1.3678, 1.3685, 1.3582, 1.3581,
         1.3127, 1.3042, 1.3024, 1.3035, 1.3184, 1.2981, 1.2902, 1.3182, 1.2927,
         1.5265, 1.5160, 1.5257, 1.5233, 1.5230, 1.5228, 1.5257, 1.5243, 1.5243,
         2.0536, 2.0413, 2.0288, 2.0424, 2.0474, 2.0438, 2.0553, 2.0365, 2.0279,
         1.4622, 1.4616, 1.4590, 1.4597, 1.4619, 1.4536, 1.4647, 1.4349, 1.4480,
         1.3702, 1.3749, 1.3661, 1.3790, 1.3676, 1.3606, 1.3656, 1.3844, 1.3759],
        [1.5032, 1.4878, 1.4414, 1.4504, 1.4864, 1.4962, 1.4936, 1.4913, 1.4913,
         1.3938, 1.3870, 1.3832, 1.3786, 1.3987, 1.3579, 1.3767, 1.3986, 1.3826,
         1.5980, 1.5898, 1.5902, 1.5943, 1.6043, 1.6040, 1.5948, 1.6053, 1.6053,
         1.5524, 1.5557, 1.6038, 1.5990, 1.5612, 1.6090, 1.5885, 1.6071, 1.6017,
         1.6043, 1.5987, 1.5876, 1.5982, 1.6203, 1.6286, 1.6119, 1.6646, 1.6608,
         1.4626, 1.4691, 1.4744, 1.4884, 1.4662, 1.4789, 1.4432, 1.4867, 1.4868],
        [1.1706, 1.1231, 1.1145, 1.1274, 1.1236, 1.1324, 1.1319, 1.1021, 1.1020,
         1.1708, 1.1511, 1.1505, 1.1522, 1.1891, 1.0197, 1.1099, 1.1890, 1.1422,
         1.3744, 1.3645, 1.2562, 1.3599, 1.3680, 1.3678, 1.3719, 1.3690, 1.3690,
         1.1270, 1.1003, 1.1147, 1.1184, 1.1467, 1.1382, 1.1445, 1.1255, 1.1147,
         1.2796, 1.2752, 1.2820, 1.2762, 1.1795, 1.1783, 1.2918, 1.1536, 1.1370,
         2.0820, 2.0763, 2.0772, 2.0793, 2.0733, 2.0631, 2.0795, 2.0816, 2.0682]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 13 : 1873.9190083468843
Test loss for epoch 13 : 182.9499513628796
Test Precision for epoch 13 : 0.26153846153846155
Test Recall for epoch 13 : 0.26153846153846155
Test F1 for epoch 13 : 0.26153846153846155


theta for epoch 14 : tensor([[2.1746, 2.1664, 2.1709, 2.1704, 2.1701, 2.1670, 2.1681, 2.1574, 2.1574,
         1.2158, 1.2046, 1.2041, 1.2053, 1.2253, 1.1966, 1.1780, 1.2253, 1.1978,
         1.4143, 1.4076, 1.4165, 1.4107, 1.4141, 1.4143, 1.4171, 1.4146, 1.4146,
         1.2183, 1.2315, 1.2212, 1.2377, 1.2207, 1.2470, 1.2396, 1.2301, 1.2211,
         1.3695, 1.3754, 1.3713, 1.3699, 1.3717, 1.3668, 1.3759, 1.3520, 1.3552,
         1.2443, 1.2598, 1.2553, 1.2642, 1.2438, 1.2406, 1.2297, 1.2737, 1.2551],
        [1.1646, 1.0143, 1.0028, 1.0449, 1.0485, 1.0608, 1.0550, 0.9538, 0.9537,
         1.9522, 1.9516, 1.9446, 1.9605, 1.9559, 1.9699, 1.9324, 1.9539, 1.9622,
         1.1950, 1.1861, 1.1765, 1.1717, 1.1829, 1.1873, 1.2022, 1.1881, 1.1881,
         1.0361, 1.0054, 0.9827, 1.0619, 0.9858, 1.1113, 1.0821, 1.0440, 0.9790,
         1.1294, 1.1623, 1.1381, 1.1309, 1.1319, 1.1525, 1.1674, 1.0562, 1.1196,
         0.9935, 1.0883, 1.0657, 1.1055, 0.9905, 0.9927, 0.9298, 1.1523, 1.0589],
        [1.5017, 1.4963, 1.4939, 1.4931, 1.4925, 1.4983, 1.4936, 1.4949, 1.4949,
         1.3963, 1.3931, 1.3937, 1.3932, 1.3986, 1.3794, 1.3883, 1.3975, 1.3892,
         1.6817, 1.6830, 1.6907, 1.5742, 1.5663, 1.5662, 1.5787, 1.5649, 1.5649,
         1.5803, 1.5793, 1.5862, 1.5881, 1.5789, 1.5895, 1.5885, 1.5877, 1.5861,
         1.5879, 1.5893, 1.5885, 1.5860, 1.5879, 1.5882, 1.5897, 1.5696, 1.5730,
         1.4930, 1.5022, 1.5009, 1.5028, 1.4907, 1.4985, 1.4895, 1.5044, 1.5012],
        [1.3895, 1.3745, 1.3633, 1.3597, 1.3762, 1.3759, 1.3766, 1.3664, 1.3664,
         1.3160, 1.3071, 1.3052, 1.3064, 1.3219, 1.3008, 1.2927, 1.3218, 1.2949,
         1.5257, 1.5144, 1.5249, 1.5224, 1.5221, 1.5219, 1.5248, 1.5234, 1.5234,
         2.1074, 2.0932, 2.0792, 2.0944, 2.1003, 2.0958, 2.1092, 2.0877, 2.0782,
         1.4958, 1.4949, 1.4924, 1.4932, 1.4954, 1.4865, 1.4983, 1.4668, 1.4807,
         1.3915, 1.3959, 1.3868, 1.4003, 1.3887, 1.3814, 1.3868, 1.4057, 1.3971],
        [1.5165, 1.5011, 1.4521, 1.4613, 1.4995, 1.5098, 1.5071, 1.5052, 1.5052,
         1.4012, 1.3944, 1.3903, 1.3855, 1.4061, 1.3638, 1.3841, 1.4060, 1.3900,
         1.6022, 1.5934, 1.5939, 1.5984, 1.6091, 1.6088, 1.5987, 1.6101, 1.6101,
         1.5455, 1.5492, 1.5994, 1.5941, 1.5547, 1.6043, 1.5830, 1.6025, 1.5971,
         1.6560, 1.6500, 1.6385, 1.6495, 1.6726, 1.6815, 1.6641, 1.7189, 1.7151,
         1.4874, 1.4933, 1.4993, 1.5137, 1.4911, 1.5043, 1.4674, 1.5116, 1.5122],
        [1.1746, 1.1232, 1.1143, 1.1280, 1.1239, 1.1331, 1.1325, 1.1001, 1.1000,
         1.1667, 1.1451, 1.1445, 1.1465, 1.1867, 1.0193, 1.0997, 1.1866, 1.1354,
         1.3648, 1.3542, 1.2546, 1.3489, 1.3578, 1.3575, 1.3621, 1.3588, 1.3588,
         1.1196, 1.0927, 1.1067, 1.1109, 1.1429, 1.1312, 1.1373, 1.1179, 1.1067,
         1.3052, 1.3005, 1.3077, 1.3015, 1.2125, 1.2112, 1.3181, 1.1852, 1.1676,
         2.1594, 2.1530, 2.1540, 2.1562, 2.1499, 2.1387, 2.1568, 2.1586, 2.1441]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 14 : 1869.3327065784792
Test loss for epoch 14 : 183.85227793348756
Test Precision for epoch 14 : 0.26153846153846155
Test Recall for epoch 14 : 0.26153846153846155
Test F1 for epoch 14 : 0.26153846153846155


theta for epoch 15 : tensor([[2.2498, 2.2412, 2.2462, 2.2456, 2.2452, 2.2417, 2.2430, 2.2316, 2.2316,
         1.2227, 1.2107, 1.2102, 1.2116, 1.2330, 1.2022, 1.1821, 1.2330, 1.2034,
         1.4092, 1.4019, 1.4116, 1.4053, 1.4090, 1.4092, 1.4122, 1.4094, 1.4094,
         1.2226, 1.2359, 1.2254, 1.2421, 1.2249, 1.2515, 1.2441, 1.2344, 1.2254,
         1.4041, 1.4102, 1.4059, 1.4046, 1.4065, 1.4012, 1.4108, 1.3858, 1.3892,
         1.2315, 1.2478, 1.2431, 1.2524, 1.2308, 1.2273, 1.2163, 1.2625, 1.2427],
        [1.1814, 1.0236, 1.0115, 1.0557, 1.0593, 1.0722, 1.0661, 0.9603, 0.9602,
         2.0140, 2.0135, 2.0060, 2.0232, 2.0179, 2.0334, 1.9932, 2.0157, 2.0251,
         1.1926, 1.1831, 1.1726, 1.1675, 1.1796, 1.1844, 1.2004, 1.1852, 1.1852,
         1.0456, 1.0142, 0.9921, 1.0718, 0.9948, 1.1217, 1.0922, 1.0537, 0.9883,
         1.1659, 1.2006, 1.1751, 1.1676, 1.1684, 1.1903, 1.2059, 1.0890, 1.1557,
         0.9813, 1.0801, 1.0565, 1.0982, 0.9780, 0.9802, 0.9150, 1.1474, 1.0493],
        [1.5164, 1.5113, 1.5088, 1.5078, 1.5072, 1.5132, 1.5083, 1.5100, 1.5100,
         1.4110, 1.4078, 1.4084, 1.4078, 1.4131, 1.3934, 1.4030, 1.4120, 1.4037,
         1.7041, 1.7054, 1.7136, 1.6051, 1.5967, 1.5967, 1.6099, 1.5952, 1.5952,
         1.5843, 1.5832, 1.5905, 1.5923, 1.5830, 1.5937, 1.5926, 1.5919, 1.5904,
         1.6306, 1.6320, 1.6312, 1.6286, 1.6306, 1.6309, 1.6324, 1.6116, 1.6151,
         1.4876, 1.4969, 1.4956, 1.4974, 1.4851, 1.4933, 1.4841, 1.4990, 1.4959],
        [1.3998, 1.3849, 1.3731, 1.3690, 1.3866, 1.3861, 1.3869, 1.3768, 1.3768,
         1.3270, 1.3178, 1.3157, 1.3170, 1.3331, 1.3112, 1.3030, 1.3329, 1.3049,
         1.5261, 1.5139, 1.5253, 1.5226, 1.5222, 1.5221, 1.5252, 1.5237, 1.5237,
         2.1657, 2.1497, 2.1345, 2.1510, 2.1578, 2.1524, 2.1676, 2.1436, 2.1333,
         1.5347, 1.5336, 1.5310, 1.5319, 1.5343, 1.5247, 1.5371, 1.5041, 1.5187,
         1.3825, 1.3868, 1.3774, 1.3913, 1.3795, 1.3720, 1.3779, 1.3968, 1.3882],
        [1.5309, 1.5157, 1.4644, 1.4735, 1.5138, 1.5245, 1.5217, 1.5202, 1.5202,
         1.4160, 1.4092, 1.4049, 1.3998, 1.4209, 1.3772, 1.3990, 1.4208, 1.4047,
         1.6072, 1.5980, 1.5984, 1.6032, 1.6148, 1.6143, 1.6033, 1.6158, 1.6158,
         1.5473, 1.5513, 1.6031, 1.5974, 1.5568, 1.6077, 1.5859, 1.6061, 1.6006,
         1.7122, 1.7059, 1.6940, 1.7054, 1.7294, 1.7387, 1.7207, 1.7775, 1.7736,
         1.4816, 1.4870, 1.4936, 1.5084, 1.4854, 1.4990, 1.4610, 1.5059, 1.5069],
        [1.1840, 1.1279, 1.1190, 1.1334, 1.1290, 1.1386, 1.1379, 1.1023, 1.1022,
         1.1714, 1.1479, 1.1471, 1.1496, 1.1932, 1.0276, 1.0982, 1.1931, 1.1374,
         1.3575, 1.3461, 1.2552, 1.3401, 1.3497, 1.3494, 1.3545, 1.3507, 1.3507,
         1.1260, 1.0989, 1.1121, 1.1173, 1.1513, 1.1383, 1.1441, 1.1241, 1.1121,
         1.3372, 1.3324, 1.3399, 1.3333, 1.2517, 1.2504, 1.3511, 1.2230, 1.2044,
         2.2153, 2.2077, 2.2090, 2.2113, 2.2044, 2.1917, 2.2124, 2.2139, 2.1977]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 15 : 1859.5329843811003
Test loss for epoch 15 : 183.54481994000628
Test Precision for epoch 15 : 0.26153846153846155
Test Recall for epoch 15 : 0.26153846153846155
Test F1 for epoch 15 : 0.26153846153846155


theta for epoch 16 : tensor([[2.3168, 2.3077, 2.3134, 2.3126, 2.3122, 2.3083, 2.3097, 2.2974, 2.2974,
         1.2369, 1.2240, 1.2234, 1.2250, 1.2479, 1.2151, 1.1933, 1.2479, 1.2162,
         1.4091, 1.4013, 1.4118, 1.4049, 1.4088, 1.4091, 1.4124, 1.4093, 1.4093,
         1.2351, 1.2486, 1.2378, 1.2549, 1.2374, 1.2643, 1.2570, 1.2470, 1.2378,
         1.4366, 1.4431, 1.4385, 1.4371, 1.4392, 1.4335, 1.4436, 1.4175, 1.4210,
         1.2090, 1.2260, 1.2211, 1.2310, 1.2081, 1.2043, 1.1931, 1.2418, 1.2206],
        [1.1833, 1.0192, 1.0065, 1.0525, 1.0562, 1.0696, 1.0633, 0.9537, 0.9537,
         2.0809, 2.0806, 2.0726, 2.0909, 2.0849, 2.1019, 2.0592, 2.0825, 2.0930,
         1.1937, 1.1836, 1.1722, 1.1671, 1.1800, 1.1852, 1.2021, 1.1860, 1.1860,
         1.0594, 1.0275, 1.0064, 1.0859, 1.0085, 1.1360, 1.1064, 1.0678, 1.0025,
         1.1991, 1.2356, 1.2089, 1.2009, 1.2017, 1.2248, 1.2410, 1.1185, 1.1886,
         0.9586, 1.0611, 1.0367, 1.0800, 0.9551, 0.9572, 0.8900, 1.1314, 1.0290],
        [1.5181, 1.5133, 1.5107, 1.5095, 1.5089, 1.5151, 1.5099, 1.5121, 1.5121,
         1.4319, 1.4287, 1.4293, 1.4288, 1.4340, 1.4138, 1.4241, 1.4328, 1.4246,
         1.7303, 1.7316, 1.7404, 1.6394, 1.6305, 1.6304, 1.6445, 1.6289, 1.6289,
         1.5932, 1.5921, 1.5998, 1.6014, 1.5920, 1.6028, 1.6018, 1.6011, 1.5997,
         1.6702, 1.6716, 1.6708, 1.6682, 1.6703, 1.6705, 1.6720, 1.6505, 1.6542,
         1.4716, 1.4810, 1.4798, 1.4815, 1.4690, 1.4775, 1.4682, 1.4831, 1.4800],
        [1.3975, 1.3827, 1.3704, 1.3658, 1.3843, 1.3836, 1.3846, 1.3747, 1.3746,
         1.3445, 1.3350, 1.3328, 1.3342, 1.3507, 1.3283, 1.3200, 1.3506, 1.3215,
         1.5307, 1.5176, 1.5298, 1.5271, 1.5266, 1.5265, 1.5297, 1.5282, 1.5282,
         2.2264, 2.2087, 2.1924, 2.2100, 2.2177, 2.2114, 2.2284, 2.2020, 2.1911,
         1.5707, 1.5694, 1.5668, 1.5678, 1.5703, 1.5600, 1.5731, 1.5386, 1.5539,
         1.3633, 1.3674, 1.3577, 1.3720, 1.3601, 1.3524, 1.3587, 1.3775, 1.3689],
        [1.5321, 1.5171, 1.4637, 1.4729, 1.5151, 1.5260, 1.5232, 1.5221, 1.5221,
         1.4369, 1.4302, 1.4257, 1.4204, 1.4418, 1.3970, 1.4201, 1.4418, 1.4257,
         1.6159, 1.6063, 1.6067, 1.6119, 1.6241, 1.6237, 1.6118, 1.6252, 1.6252,
         1.5543, 1.5587, 1.6117, 1.6056, 1.5640, 1.6159, 1.5937, 1.6146, 1.6091,
         1.7659, 1.7594, 1.7471, 1.7589, 1.7838, 1.7935, 1.7748, 1.8335, 1.8296,
         1.4653, 1.4701, 1.4773, 1.4923, 1.4691, 1.4831, 1.4442, 1.4895, 1.4909],
        [1.1833, 1.1218, 1.1130, 1.1281, 1.1234, 1.1334, 1.1327, 1.0933, 1.0932,
         1.1835, 1.1581, 1.1573, 1.1601, 1.2071, 1.0431, 1.1042, 1.2070, 1.1469,
         1.3555, 1.3433, 1.2609, 1.3364, 1.3469, 1.3464, 1.3523, 1.3479, 1.3479,
         1.1414, 1.1143, 1.1263, 1.1328, 1.1676, 1.1546, 1.1600, 1.1393, 1.1262,
         1.3674, 1.3626, 1.3702, 1.3633, 1.2887, 1.2875, 1.3823, 1.2588, 1.2393,
         2.2632, 2.2542, 2.2558, 2.2583, 2.2508, 2.2362, 2.2600, 2.2610, 2.2428]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 16 : 1855.4573436854973
Test loss for epoch 16 : 183.2982007943731
Test Precision for epoch 16 : 0.26153846153846155
Test Recall for epoch 16 : 0.26153846153846155
Test F1 for epoch 16 : 0.26153846153846155


theta for epoch 17 : tensor([[2.3805, 2.3710, 2.3773, 2.3764, 2.3759, 2.3715, 2.3732, 2.3599, 2.3599,
         1.2570, 1.2433, 1.2426, 1.2443, 1.2688, 1.2338, 1.2104, 1.2687, 1.2349,
         1.4160, 1.4077, 1.4189, 1.4114, 1.4155, 1.4159, 1.4194, 1.4161, 1.4161,
         1.2515, 1.2651, 1.2539, 1.2714, 1.2536, 1.2810, 1.2737, 1.2634, 1.2539,
         1.4431, 1.4500, 1.4451, 1.4437, 1.4460, 1.4400, 1.4506, 1.4234, 1.4270,
         1.1941, 1.2120, 1.2069, 1.2173, 1.1929, 1.1887, 1.1775, 1.2291, 1.2061],
        [1.1810, 1.0115, 0.9981, 1.0458, 1.0496, 1.0635, 1.0568, 0.9443, 0.9443,
         2.1517, 2.1516, 2.1431, 2.1625, 2.1558, 2.1742, 2.1293, 2.1533, 2.1648,
         1.2002, 1.1897, 1.1773, 1.1722, 1.1860, 1.1915, 1.2092, 1.1923, 1.1923,
         1.0740, 1.0416, 1.0217, 1.1007, 1.0231, 1.1506, 1.1211, 1.0826, 1.0179,
         1.2051, 1.2433, 1.2155, 1.2071, 1.2076, 1.2320, 1.2487, 1.1210, 1.1942,
         0.9419, 1.0478, 1.0226, 1.0674, 0.9381, 0.9403, 0.8711, 1.1208, 1.0145],
        [1.5170, 1.5125, 1.5098, 1.5084, 1.5078, 1.5142, 1.5088, 1.5115, 1.5115,
         1.4578, 1.4547, 1.4553, 1.4548, 1.4598, 1.4393, 1.4503, 1.4587, 1.4505,
         1.7618, 1.7630, 1.7723, 1.6782, 1.6688, 1.6688, 1.6835, 1.6672, 1.6672,
         1.6033, 1.6021, 1.6101, 1.6116, 1.6022, 1.6128, 1.6119, 1.6113, 1.6100,
         1.6831, 1.6844, 1.6836, 1.6809, 1.6831, 1.6833, 1.6847, 1.6626, 1.6664,
         1.4621, 1.4716, 1.4704, 1.4721, 1.4594, 1.4682, 1.4589, 1.4736, 1.4707],
        [1.3929, 1.3784, 1.3656, 1.3606, 1.3800, 1.3791, 1.3801, 1.3705, 1.3705,
         1.3674, 1.3576, 1.3553, 1.3567, 1.3737, 1.3507, 1.3425, 1.3735, 1.3435,
         1.5413, 1.5275, 1.5404, 1.5376, 1.5371, 1.5369, 1.5403, 1.5388, 1.5388,
         2.2868, 2.2675, 2.2501, 2.2688, 2.2775, 2.2701, 2.2889, 2.2601, 2.2487,
         1.5801, 1.5786, 1.5760, 1.5771, 1.5797, 1.5687, 1.5825, 1.5465, 1.5625,
         1.3510, 1.3548, 1.3449, 1.3596, 1.3476, 1.3397, 1.3464, 1.3651, 1.3565],
        [1.5304, 1.5157, 1.4605, 1.4696, 1.5135, 1.5247, 1.5219, 1.5212, 1.5212,
         1.4629, 1.4562, 1.4515, 1.4460, 1.4678, 1.4218, 1.4463, 1.4677, 1.4518,
         1.6302, 1.6202, 1.6205, 1.6261, 1.6390, 1.6385, 1.6258, 1.6401, 1.6401,
         1.5625, 1.5673, 1.6213, 1.6148, 1.5725, 1.6250, 1.6026, 1.6240, 1.6186,
         1.7943, 1.7874, 1.7748, 1.7869, 1.8128, 1.8230, 1.8036, 1.8644, 1.8605,
         1.4554, 1.4597, 1.4674, 1.4827, 1.4593, 1.4736, 1.4339, 1.4796, 1.4814],
        [1.1821, 1.1149, 1.1064, 1.1223, 1.1173, 1.1276, 1.1268, 1.0834, 1.0834,
         1.2016, 1.1743, 1.1734, 1.1766, 1.2269, 1.0645, 1.1162, 1.2268, 1.1624,
         1.3605, 1.3475, 1.2733, 1.3398, 1.3510, 1.3504, 1.3570, 1.3520, 1.3520,
         1.1608, 1.1336, 1.1442, 1.1524, 1.1868, 1.1749, 1.1798, 1.1584, 1.1442,
         1.3718, 1.3671, 1.3748, 1.3676, 1.2998, 1.2986, 1.3879, 1.2686, 1.2482,
         2.3147, 2.3043, 2.3062, 2.3088, 2.3007, 2.2845, 2.3112, 2.3117, 2.2916]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 17 : 1850.085883219616
Test loss for epoch 17 : 183.28623480992854
Test Precision for epoch 17 : 0.26153846153846155
Test Recall for epoch 17 : 0.26153846153846155
Test F1 for epoch 17 : 0.26153846153846155


theta for epoch 18 : tensor([[2.4439, 2.4341, 2.4410, 2.4400, 2.4394, 2.4344, 2.4364, 2.4222, 2.4222,
         1.2805, 1.2659, 1.2652, 1.2671, 1.2931, 1.2560, 1.2308, 1.2930, 1.2571,
         1.4289, 1.4201, 1.4321, 1.4240, 1.4283, 1.4287, 1.4325, 1.4288, 1.4288,
         1.2597, 1.2733, 1.2615, 1.2797, 1.2615, 1.2895, 1.2821, 1.2714, 1.2615,
         1.4311, 1.4384, 1.4331, 1.4316, 1.4341, 1.4279, 1.4389, 1.4106, 1.4144,
         1.1898, 1.2087, 1.2032, 1.2144, 1.1882, 1.1835, 1.1724, 1.2271, 1.2022],
        [1.1807, 1.0066, 0.9926, 1.0419, 1.0457, 1.0601, 1.0531, 0.9383, 0.9382,
         2.2250, 2.2250, 2.2161, 2.2364, 2.2291, 2.2489, 2.2019, 2.2265, 2.2390,
         1.2117, 1.2008, 1.1873, 1.1824, 1.1970, 1.2028, 1.2213, 1.2037, 1.2037,
         1.0789, 1.0461, 1.0277, 1.1056, 1.0282, 1.1553, 1.1259, 1.0878, 1.0239,
         1.1918, 1.2315, 1.2028, 1.1940, 1.1943, 1.2198, 1.2368, 1.1044, 1.1806,
         0.9341, 1.0432, 1.0173, 1.0635, 0.9301, 0.9323, 0.8612, 1.1187, 1.0088],
        [1.5191, 1.5150, 1.5123, 1.5107, 1.5101, 1.5165, 1.5110, 1.5141, 1.5141,
         1.4864, 1.4833, 1.4840, 1.4835, 1.4884, 1.4675, 1.4791, 1.4872, 1.4791,
         1.7976, 1.7989, 1.8085, 1.7208, 1.7110, 1.7109, 1.7263, 1.7093, 1.7093,
         1.6033, 1.6021, 1.6103, 1.6117, 1.6022, 1.6128, 1.6119, 1.6114, 1.6102,
         1.6764, 1.6776, 1.6769, 1.6741, 1.6764, 1.6766, 1.6780, 1.6552, 1.6591,
         1.4620, 1.4715, 1.4704, 1.4720, 1.4592, 1.4683, 1.4589, 1.4734, 1.4706],
        [1.3925, 1.3783, 1.3650, 1.3596, 1.3798, 1.3788, 1.3799, 1.3705, 1.3705,
         1.3931, 1.3831, 1.3807, 1.3821, 1.3995, 1.3761, 1.3680, 1.3993, 1.3685,
         1.5572, 1.5426, 1.5562, 1.5534, 1.5528, 1.5527, 1.5561, 1.5547, 1.5547,
         2.3394, 2.3182, 2.2996, 2.3196, 2.3293, 2.3207, 2.3416, 2.3101, 2.2980,
         1.5703, 1.5685, 1.5659, 1.5671, 1.5698, 1.5582, 1.5726, 1.5352, 1.5519,
         1.3485, 1.3521, 1.3419, 1.3569, 1.3449, 1.3368, 1.3440, 1.3624, 1.3540],
        [1.5319, 1.5175, 1.4608, 1.4698, 1.5152, 1.5266, 1.5237, 1.5235, 1.5234,
         1.4915, 1.4848, 1.4800, 1.4744, 1.4963, 1.4494, 1.4752, 1.4962, 1.4805,
         1.6493, 1.6389, 1.6392, 1.6451, 1.6587, 1.6581, 1.6446, 1.6598, 1.6598,
         1.5608, 1.5658, 1.6207, 1.6138, 1.5709, 1.6239, 1.6014, 1.6231, 1.6178,
         1.8034, 1.7961, 1.7832, 1.7956, 1.8225, 1.8332, 1.8132, 1.8760, 1.8721,
         1.4550, 1.4586, 1.4669, 1.4824, 1.4588, 1.4735, 1.4331, 1.4789, 1.4811],
        [1.1866, 1.1137, 1.1054, 1.1220, 1.1167, 1.1273, 1.1264, 1.0790, 1.0790,
         1.2230, 1.1940, 1.1929, 1.1965, 1.2500, 1.0891, 1.1317, 1.2499, 1.1813,
         1.3715, 1.3578, 1.2915, 1.3492, 1.3611, 1.3605, 1.3679, 1.3622, 1.3622,
         1.1717, 1.1446, 1.1537, 1.1634, 1.1966, 1.1868, 1.1911, 1.1690, 1.1537,
         1.3577, 1.3531, 1.3608, 1.3533, 1.2919, 1.2907, 1.3749, 1.2595, 1.2382,
         2.3712, 2.3595, 2.3616, 2.3643, 2.3559, 2.3381, 2.3676, 2.3674, 2.3456]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 18 : 1842.7676731688678
Test loss for epoch 18 : 183.62264281368303
Test Precision for epoch 18 : 0.26153846153846155
Test Recall for epoch 18 : 0.26153846153846155
Test F1 for epoch 18 : 0.26153846153846155


theta for epoch 19 : tensor([[2.5063, 2.4962, 2.5039, 2.5026, 2.5019, 2.4965, 2.4986, 2.4836, 2.4836,
         1.2988, 1.2833, 1.2825, 1.2847, 1.3122, 1.2730, 1.2460, 1.3122, 1.2740,
         1.4447, 1.4353, 1.4482, 1.4394, 1.4438, 1.4443, 1.4485, 1.4444, 1.4444,
         1.2547, 1.2683, 1.2559, 1.2747, 1.2562, 1.2848, 1.2774, 1.2663, 1.2559,
         1.4184, 1.4262, 1.4205, 1.4190, 1.4217, 1.4152, 1.4267, 1.3973, 1.4012,
         1.1952, 1.2151, 1.2093, 1.2212, 1.1932, 1.1881, 1.1770, 1.2350, 1.2080],
        [1.1817, 1.0036, 0.9890, 1.0398, 1.0435, 1.0583, 1.0511, 0.9344, 0.9344,
         2.2960, 2.2962, 2.2868, 2.3083, 2.3002, 2.3215, 2.2724, 2.2975, 2.3110,
         1.2251, 1.2138, 1.1993, 1.1947, 1.2101, 1.2162, 1.2353, 1.2171, 1.2171,
         1.0705, 1.0373, 1.0205, 1.0972, 1.0202, 1.1464, 1.1173, 1.0796, 1.0166,
         1.1773, 1.2184, 1.1888, 1.1796, 1.1797, 1.2063, 1.2238, 1.0868, 1.1657,
         0.9347, 1.0469, 1.0203, 1.0678, 0.9306, 0.9330, 0.8599, 1.1247, 1.0115],
        [1.5231, 1.5194, 1.5167, 1.5149, 1.5143, 1.5208, 1.5152, 1.5187, 1.5186,
         1.5092, 1.5062, 1.5069, 1.5064, 1.5111, 1.4899, 1.5022, 1.5099, 1.5019,
         1.8350, 1.8363, 1.8463, 1.7645, 1.7543, 1.7542, 1.7703, 1.7526, 1.7526,
         1.5893, 1.5881, 1.5965, 1.5978, 1.5884, 1.5989, 1.5980, 1.5976, 1.5965,
         1.6682, 1.6695, 1.6688, 1.6659, 1.6683, 1.6685, 1.6698, 1.6465, 1.6504,
         1.4705, 1.4800, 1.4789, 1.4804, 1.4676, 1.4770, 1.4675, 1.4817, 1.4791],
        [1.3946, 1.3809, 1.3672, 1.3613, 1.3823, 1.3810, 1.3823, 1.3733, 1.3733,
         1.4132, 1.4031, 1.4005, 1.4020, 1.4196, 1.3958, 1.3879, 1.4195, 1.3879,
         1.5752, 1.5599, 1.5742, 1.5713, 1.5707, 1.5706, 1.5741, 1.5727, 1.5727,
         2.3807, 2.3573, 2.3374, 2.3587, 2.3697, 2.3597, 2.3830, 2.3484, 2.3356,
         1.5593, 1.5573, 1.5547, 1.5561, 1.5588, 1.5465, 1.5616, 1.5228, 1.5401,
         1.3550, 1.3583, 1.3480, 1.3633, 1.3512, 1.3430, 1.3506, 1.3688, 1.3604],
        [1.5350, 1.5212, 1.4633, 1.4721, 1.5187, 1.5303, 1.5274, 1.5276, 1.5276,
         1.5143, 1.5077, 1.5027, 1.4969, 1.5190, 1.4712, 1.4983, 1.5189, 1.5034,
         1.6701, 1.6594, 1.6597, 1.6659, 1.6801, 1.6794, 1.6652, 1.6812, 1.6812,
         1.5453, 1.5505, 1.6061, 1.5989, 1.5554, 1.6089, 1.5863, 1.6084, 1.6031,
         1.8113, 1.8036, 1.7904, 1.8031, 1.8311, 1.8422, 1.8215, 1.8864, 1.8825,
         1.4631, 1.4660, 1.4749, 1.4906, 1.4670, 1.4819, 1.4410, 1.4867, 1.4894],
        [1.1946, 1.1163, 1.1083, 1.1255, 1.1200, 1.1308, 1.1298, 1.0786, 1.0786,
         1.2392, 1.2084, 1.2072, 1.2112, 1.2678, 1.1085, 1.1421, 1.2677, 1.1950,
         1.3854, 1.3709, 1.3120, 1.3614, 1.3741, 1.3734, 1.3815, 1.3752, 1.3752,
         1.1689, 1.1419, 1.1496, 1.1608, 1.1921, 1.1849, 1.1886, 1.1660, 1.1497,
         1.3430, 1.3385, 1.3462, 1.3384, 1.2830, 1.2820, 1.3613, 1.2495, 1.2274,
         2.4323, 2.4193, 2.4218, 2.4245, 2.4157, 2.3965, 2.4286, 2.4276, 2.4044]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 19 : 1841.1837421792607
Test loss for epoch 19 : 184.68161438075288
Test Precision for epoch 19 : 0.26153846153846155
Test Recall for epoch 19 : 0.26153846153846155
Test F1 for epoch 19 : 0.26153846153846155


theta for epoch 20 : tensor([[2.5688, 2.5585, 2.5669, 2.5655, 2.5646, 2.5587, 2.5611, 2.5452, 2.5452,
         1.2998, 1.2833, 1.2825, 1.2849, 1.3140, 1.2726, 1.2437, 1.3140, 1.2736,
         1.4604, 1.4505, 1.4642, 1.4546, 1.4593, 1.4598, 1.4644, 1.4600, 1.4600,
         1.2583, 1.2717, 1.2587, 1.2783, 1.2593, 1.2886, 1.2812, 1.2697, 1.2587,
         1.4133, 1.4215, 1.4155, 1.4140, 1.4169, 1.4101, 1.4221, 1.3917, 1.3957,
         1.2091, 1.2301, 1.2240, 1.2366, 1.2068, 1.2012, 1.1901, 1.2514, 1.2224],
        [1.1862, 1.0049, 0.9897, 1.0417, 1.0454, 1.0606, 1.0531, 0.9350, 0.9350,
         2.3568, 2.3573, 2.3473, 2.3701, 2.3611, 2.3842, 2.3325, 2.3583, 2.3731,
         1.2380, 1.2264, 1.2108, 1.2064, 1.2226, 1.2291, 1.2488, 1.2300, 1.2300,
         1.0685, 1.0349, 1.0198, 1.0951, 1.0186, 1.1438, 1.1150, 1.0778, 1.0159,
         1.1699, 1.2125, 1.1821, 1.1725, 1.1723, 1.1999, 1.2178, 1.0763, 1.1580,
         0.9431, 1.0580, 1.0308, 1.0795, 0.9388, 0.9414, 0.8665, 1.1380, 1.0217],
        [1.5308, 1.5277, 1.5249, 1.5229, 1.5224, 1.5289, 1.5231, 1.5271, 1.5270,
         1.5140, 1.5110, 1.5118, 1.5113, 1.5158, 1.4944, 1.5073, 1.5146, 1.5067,
         1.8714, 1.8727, 1.8832, 1.8070, 1.7964, 1.7963, 1.8129, 1.7946, 1.7946,
         1.5818, 1.5805, 1.5892, 1.5903, 1.5809, 1.5913, 1.5905, 1.5901, 1.5891,
         1.6668, 1.6679, 1.6673, 1.6644, 1.6668, 1.6670, 1.6683, 1.6444, 1.6485,
         1.4865, 1.4960, 1.4950, 1.4964, 1.4836, 1.4931, 1.4838, 1.4976, 1.4952],
        [1.4011, 1.3879, 1.3739, 1.3676, 1.3893, 1.3878, 1.3891, 1.3806, 1.3806,
         1.4155, 1.4052, 1.4024, 1.4039, 1.4219, 1.3978, 1.3901, 1.4217, 1.3895,
         1.5925, 1.5765, 1.5915, 1.5886, 1.5878, 1.5878, 1.5914, 1.5899, 1.5899,
         2.4256, 2.4001, 2.3789, 2.4015, 2.4138, 2.4024, 2.4279, 2.3905, 2.3770,
         1.5553, 1.5530, 1.5504, 1.5519, 1.5548, 1.5418, 1.5575, 1.5174, 1.5353,
         1.3694, 1.3724, 1.3619, 1.3774, 1.3654, 1.3570, 1.3650, 1.3829, 1.3746],
        [1.5420, 1.5287, 1.4699, 1.4785, 1.5261, 1.5377, 1.5349, 1.5355, 1.5355,
         1.5191, 1.5126, 1.5074, 1.5014, 1.5237, 1.4751, 1.5034, 1.5236, 1.5083,
         1.6900, 1.6790, 1.6792, 1.6858, 1.7005, 1.6998, 1.6848, 1.7016, 1.7016,
         1.5365, 1.5420, 1.5979, 1.5904, 1.5467, 1.6002, 1.5776, 1.5999, 1.5948,
         1.8255, 1.8175, 1.8040, 1.8171, 1.8459, 1.8575, 1.8361, 1.9029, 1.8991,
         1.4789, 1.4811, 1.4905, 1.5062, 1.4828, 1.4978, 1.4565, 1.5020, 1.5051],
        [1.2080, 1.1247, 1.1171, 1.1348, 1.1290, 1.1401, 1.1390, 1.0843, 1.0843,
         1.2381, 1.2055, 1.2043, 1.2086, 1.2683, 1.1105, 1.1355, 1.2682, 1.1915,
         1.3991, 1.3839, 1.3322, 1.3735, 1.3869, 1.3862, 1.3950, 1.3881, 1.3881,
         1.1744, 1.1476, 1.1539, 1.1665, 1.1951, 1.1911, 1.1943, 1.1712, 1.1539,
         1.3359, 1.3315, 1.3392, 1.3312, 1.2814, 1.2805, 1.3552, 1.2468, 1.2240,
         2.4974, 2.4831, 2.4859, 2.4887, 2.4796, 2.4590, 2.4935, 2.4918, 2.4673]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 20 : 1837.9417556577846
Test loss for epoch 20 : 185.36337810565786
Test Precision for epoch 20 : 0.26153846153846155
Test Recall for epoch 20 : 0.26153846153846155
Test F1 for epoch 20 : 0.26153846153846155


theta for epoch 21 : tensor([[2.6301, 2.6197, 2.6287, 2.6272, 2.6262, 2.6197, 2.6223, 2.6057, 2.6057,
         1.2876, 1.2702, 1.2693, 1.2720, 1.3026, 1.2590, 1.2283, 1.3026, 1.2600,
         1.4718, 1.4615, 1.4760, 1.4656, 1.4705, 1.4710, 1.4759, 1.4712, 1.4712,
         1.2742, 1.2875, 1.2739, 1.2942, 1.2749, 1.3049, 1.2974, 1.2854, 1.2740,
         1.4169, 1.4256, 1.4192, 1.4176, 1.4208, 1.4137, 1.4262, 1.3948, 1.3989,
         1.2290, 1.2510, 1.2446, 1.2579, 1.2263, 1.2203, 1.2093, 1.2738, 1.2427],
        [1.1917, 1.0075, 0.9919, 1.0449, 1.0485, 1.0640, 1.0564, 0.9372, 0.9372,
         2.4095, 2.4103, 2.3997, 2.4239, 2.4139, 2.4390, 2.3844, 2.4109, 2.4272,
         1.2464, 1.2344, 1.2177, 1.2137, 1.2306, 1.2374, 1.2577, 1.2383, 1.2383,
         1.0769, 1.0429, 1.0295, 1.1034, 1.0274, 1.1514, 1.1230, 1.0864, 1.0256,
         1.1709, 1.2147, 1.1835, 1.1736, 1.1731, 1.2018, 1.2200, 1.0743, 1.1586,
         0.9568, 1.0743, 1.0466, 1.0964, 0.9523, 0.9551, 0.8785, 1.1563, 1.0372],
        [1.5396, 1.5369, 1.5342, 1.5320, 1.5315, 1.5380, 1.5322, 1.5365, 1.5365,
         1.5051, 1.5022, 1.5030, 1.5025, 1.5068, 1.4851, 1.4987, 1.5056, 1.4978,
         1.9031, 1.9044, 1.9153, 1.8446, 1.8336, 1.8336, 1.8508, 1.8318, 1.8318,
         1.5850, 1.5837, 1.5925, 1.5935, 1.5843, 1.5944, 1.5937, 1.5933, 1.5925,
         1.6730, 1.6741, 1.6735, 1.6705, 1.6730, 1.6732, 1.6744, 1.6501, 1.6543,
         1.5077, 1.5170, 1.5161, 1.5174, 1.5047, 1.5144, 1.5051, 1.5185, 1.5163],
        [1.4090, 1.3965, 1.3822, 1.3755, 1.3977, 1.3961, 1.3975, 1.3895, 1.3895,
         1.4042, 1.3937, 1.3908, 1.3924, 1.4106, 1.3862, 1.3788, 1.4104, 1.3775,
         1.6049, 1.5882, 1.6039, 1.6009, 1.6001, 1.6001, 1.6038, 1.6023, 1.6023,
         2.4767, 2.4492, 2.4270, 2.4506, 2.4641, 2.4512, 2.4790, 2.4389, 2.4249,
         1.5593, 1.5568, 1.5542, 1.5558, 1.5587, 1.5452, 1.5613, 1.5201, 1.5386,
         1.3891, 1.3918, 1.3811, 1.3969, 1.3850, 1.3765, 1.3848, 1.4022, 1.3942],
        [1.5498, 1.5372, 1.4779, 1.4861, 1.5345, 1.5461, 1.5433, 1.5443, 1.5443,
         1.5102, 1.5038, 1.4984, 1.4923, 1.5147, 1.4653, 1.4949, 1.5147, 1.4996,
         1.7048, 1.6937, 1.6938, 1.7006, 1.7159, 1.7151, 1.6994, 1.7170, 1.7170,
         1.5388, 1.5446, 1.6004, 1.5926, 1.5490, 1.6021, 1.5798, 1.6022, 1.5972,
         1.8471, 1.8386, 1.8250, 1.8383, 1.8680, 1.8799, 1.8580, 1.9265, 1.9227,
         1.4998, 1.5012, 1.5112, 1.5269, 1.5036, 1.5188, 1.4773, 1.5224, 1.5259],
        [1.2236, 1.1358, 1.1286, 1.1467, 1.1407, 1.1519, 1.1508, 1.0929, 1.0929,
         1.2239, 1.1897, 1.1884, 1.1931, 1.2556, 1.0992, 1.1161, 1.2555, 1.1751,
         1.4085, 1.3926, 1.3477, 1.3814, 1.3954, 1.3946, 1.4041, 1.3966, 1.3966,
         1.1920, 1.1654, 1.1705, 1.1842, 1.2099, 1.2094, 1.2121, 1.1886, 1.1705,
         1.3374, 1.3332, 1.3409, 1.3326, 1.2881, 1.2873, 1.3577, 1.2525, 1.2289,
         2.5650, 2.5495, 2.5525, 2.5553, 2.5461, 2.5242, 2.5610, 2.5585, 2.5328]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 21 : 1832.267308025498
Test loss for epoch 21 : 185.5838230871763
Test Precision for epoch 21 : 0.26153846153846155
Test Recall for epoch 21 : 0.26153846153846155
Test F1 for epoch 21 : 0.26153846153846155


theta for epoch 22 : tensor([[2.6865, 2.6759, 2.6858, 2.6840, 2.6829, 2.6758, 2.6786, 2.6612, 2.6612,
         1.2733, 1.2549, 1.2540, 1.2569, 1.2891, 1.2433, 1.2108, 1.2891, 1.2442,
         1.4757, 1.4648, 1.4801, 1.4691, 1.4741, 1.4747, 1.4800, 1.4748, 1.4748,
         1.2980, 1.3112, 1.2969, 1.3180, 1.2983, 1.3290, 1.3214, 1.3090, 1.2970,
         1.4286, 1.4378, 1.4310, 1.4293, 1.4327, 1.4255, 1.4384, 1.4059, 1.4101,
         1.2485, 1.2715, 1.2647, 1.2788, 1.2454, 1.2389, 1.2279, 1.2957, 1.2626],
        [1.1907, 1.0042, 0.9882, 1.0421, 1.0457, 1.0615, 1.0537, 0.9338, 0.9338,
         2.4616, 2.4626, 2.4514, 2.4770, 2.4660, 2.4933, 2.4357, 2.4628, 2.4807,
         1.2470, 1.2347, 1.2169, 1.2132, 1.2309, 1.2380, 1.2589, 1.2389, 1.2389,
         1.0914, 1.0570, 1.0454, 1.1177, 1.0425, 1.1650, 1.1370, 1.1011, 1.0416,
         1.1795, 1.2246, 1.1927, 1.1823, 1.1815, 1.2113, 1.2297, 1.0801, 1.1668,
         0.9694, 1.0894, 1.0612, 1.1120, 0.9648, 0.9679, 0.8896, 1.1732, 1.0515],
        [1.5423, 1.5400, 1.5373, 1.5349, 1.5344, 1.5409, 1.5350, 1.5397, 1.5397,
         1.4935, 1.4907, 1.4915, 1.4910, 1.4952, 1.4731, 1.4874, 1.4939, 1.4863,
         1.9269, 1.9283, 1.9395, 1.8745, 1.8631, 1.8630, 1.8808, 1.8612, 1.8612,
         1.5949, 1.5935, 1.6025, 1.6033, 1.5943, 1.6040, 1.6034, 1.6032, 1.6025,
         1.6864, 1.6875, 1.6869, 1.6839, 1.6864, 1.6866, 1.6878, 1.6631, 1.6673,
         1.5276, 1.5369, 1.5360, 1.5373, 1.5246, 1.5345, 1.5253, 1.5383, 1.5362],
        [1.4109, 1.3991, 1.3846, 1.3775, 1.4002, 1.3984, 1.3999, 1.3925, 1.3925,
         1.3903, 1.3797, 1.3767, 1.3783, 1.3967, 1.3721, 1.3650, 1.3965, 1.3630,
         1.6092, 1.5919, 1.6081, 1.6052, 1.6043, 1.6043, 1.6080, 1.6067, 1.6067,
         2.5312, 2.5019, 2.4789, 2.5032, 2.5179, 2.5036, 2.5335, 2.4909, 2.4766,
         1.5707, 1.5680, 1.5654, 1.5671, 1.5702, 1.5560, 1.5727, 1.5303, 1.5494,
         1.4078, 1.4101, 1.3993, 1.4152, 1.4034, 1.3949, 1.4036, 1.4205, 1.4127],
        [1.5515, 1.5396, 1.4799, 1.4879, 1.5368, 1.5483, 1.5456, 1.5470, 1.5470,
         1.4986, 1.4923, 1.4868, 1.4805, 1.5030, 1.4530, 1.4837, 1.5030, 1.4882,
         1.7115, 1.7001, 1.7003, 1.7074, 1.7232, 1.7223, 1.7059, 1.7242, 1.7242,
         1.5481, 1.5541, 1.6095, 1.6015, 1.5582, 1.6107, 1.5887, 1.6110, 1.6062,
         1.8752, 1.8664, 1.8526, 1.8661, 1.8965, 1.9089, 1.8864, 1.9564, 1.9527,
         1.5195, 1.5202, 1.5306, 1.5464, 1.5233, 1.5386, 1.4969, 1.5415, 1.5455],
        [1.2340, 1.1420, 1.1352, 1.1537, 1.1475, 1.1589, 1.1577, 1.0969, 1.0969,
         1.2076, 1.1719, 1.1705, 1.1755, 1.2407, 1.0858, 1.0948, 1.2406, 1.1566,
         1.4103, 1.3938, 1.3554, 1.3817, 1.3964, 1.3955, 1.4057, 1.3977, 1.3977,
         1.2172, 1.1909, 1.1948, 1.2096, 1.2320, 1.2353, 1.2376, 1.2136, 1.1948,
         1.3472, 1.3430, 1.3507, 1.3422, 1.3026, 1.3018, 1.3684, 1.2660, 1.2418,
         2.6314, 2.6146, 2.6180, 2.6208, 2.6114, 2.5882, 2.6274, 2.6239, 2.5970]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 22 : 1829.0135146454206
Test loss for epoch 22 : 185.88933902800292
Test Precision for epoch 22 : 0.26153846153846155
Test Recall for epoch 22 : 0.26153846153846155
Test F1 for epoch 22 : 0.26153846153846155


theta for epoch 23 : tensor([[2.7396, 2.7288, 2.7396, 2.7376, 2.7363, 2.7285, 2.7317, 2.7134, 2.7134,
         1.2635, 1.2443, 1.2433, 1.2464, 1.2802, 1.2322, 1.1980, 1.2802, 1.2331,
         1.4773, 1.4659, 1.4820, 1.4702, 1.4754, 1.4761, 1.4817, 1.4762, 1.4762,
         1.3203, 1.3333, 1.3184, 1.3402, 1.3201, 1.3515, 1.3439, 1.3311, 1.3184,
         1.4474, 1.4570, 1.4498, 1.4482, 1.4518, 1.4443, 1.4577, 1.4243, 1.4285,
         1.2567, 1.2807, 1.2736, 1.2884, 1.2532, 1.2462, 1.2354, 1.3064, 1.2712],
        [1.1862, 0.9980, 0.9815, 1.0362, 1.0397, 1.0558, 1.0478, 0.9277, 0.9277,
         2.5171, 2.5185, 2.5066, 2.5337, 2.5215, 2.5509, 2.4905, 2.5182, 2.5376,
         1.2450, 1.2323, 1.2134, 1.2101, 1.2286, 1.2360, 1.2574, 1.2369, 1.2369,
         1.1035, 1.0689, 1.0591, 1.1296, 1.0553, 1.1761, 1.1486, 1.1134, 1.0553,
         1.1948, 1.2410, 1.2086, 1.1978, 1.1967, 1.2274, 1.2461, 1.0927, 1.1818,
         0.9707, 1.0930, 1.0643, 1.1161, 0.9661, 0.9694, 0.8895, 1.1787, 1.0544],
        [1.5417, 1.5399, 1.5372, 1.5346, 1.5342, 1.5407, 1.5347, 1.5397, 1.5397,
         1.4860, 1.4832, 1.4840, 1.4836, 1.4875, 1.4653, 1.4801, 1.4863, 1.4788,
         1.9477, 1.9491, 1.9607, 1.9011, 1.8893, 1.8892, 1.9076, 1.8873, 1.8873,
         1.6026, 1.6012, 1.6102, 1.6109, 1.6021, 1.6115, 1.6110, 1.6108, 1.6102,
         1.7062, 1.7072, 1.7067, 1.7036, 1.7062, 1.7064, 1.7074, 1.6824, 1.6867,
         1.5358, 1.5450, 1.5442, 1.5453, 1.5327, 1.5428, 1.5336, 1.5462, 1.5444],
        [1.4099, 1.3988, 1.3841, 1.3767, 1.3998, 1.3979, 1.3994, 1.3926, 1.3926,
         1.3806, 1.3699, 1.3668, 1.3684, 1.3869, 1.3622, 1.3555, 1.3867, 1.3528,
         1.6107, 1.5927, 1.6095, 1.6066, 1.6057, 1.6057, 1.6095, 1.6081, 1.6081,
         2.5834, 2.5523, 2.5283, 2.5535, 2.5694, 2.5536, 2.5857, 2.5406, 2.5258,
         1.5888, 1.5858, 1.5833, 1.5851, 1.5882, 1.5735, 1.5907, 1.5472, 1.5668,
         1.4147, 1.4167, 1.4058, 1.4219, 1.4103, 1.4016, 1.4107, 1.4270, 1.4195],
        [1.5500, 1.5389, 1.4791, 1.4866, 1.5359, 1.5473, 1.5447, 1.5464, 1.5464,
         1.4910, 1.4849, 1.4792, 1.4728, 1.4954, 1.4447, 1.4765, 1.4953, 1.4808,
         1.7153, 1.7037, 1.7038, 1.7111, 1.7274, 1.7265, 1.7094, 1.7284, 1.7284,
         1.5553, 1.5616, 1.6163, 1.6083, 1.5653, 1.6171, 1.5955, 1.6177, 1.6130,
         1.9090, 1.8999, 1.8860, 1.8997, 1.9308, 1.9435, 1.9205, 1.9919, 1.9882,
         1.5274, 1.5274, 1.5383, 1.5540, 1.5313, 1.5465, 1.5049, 1.5489, 1.5532],
        [1.2423, 1.1464, 1.1400, 1.1589, 1.1525, 1.1639, 1.1627, 1.0992, 1.0992,
         1.1959, 1.1587, 1.1572, 1.1625, 1.2305, 1.0769, 1.0782, 1.2304, 1.1428,
         1.4100, 1.3928, 1.3605, 1.3798, 1.3953, 1.3942, 1.4051, 1.3965, 1.3965,
         1.2409, 1.2149, 1.2176, 1.2335, 1.2522, 1.2596, 1.2614, 1.2372, 1.2177,
         1.3641, 1.3601, 1.3678, 1.3590, 1.3239, 1.3231, 1.3863, 1.2865, 1.2615,
         2.6900, 2.6717, 2.6754, 2.6782, 2.6686, 2.6440, 2.6858, 2.6813, 2.6530]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 23 : 1826.642406638643
Test loss for epoch 23 : 186.19329573827733
Test Precision for epoch 23 : 0.26153846153846155
Test Recall for epoch 23 : 0.26153846153846155
Test F1 for epoch 23 : 0.26153846153846155


theta for epoch 24 : tensor([[2.7920, 2.7812, 2.7928, 2.7905, 2.7891, 2.7807, 2.7841, 2.7650, 2.7650,
         1.2603, 1.2401, 1.2391, 1.2424, 1.2778, 1.2276, 1.1916, 1.2778, 1.2285,
         1.4812, 1.4693, 1.4862, 1.4737, 1.4790, 1.4797, 1.4857, 1.4798, 1.4798,
         1.3289, 1.3418, 1.3263, 1.3488, 1.3284, 1.3605, 1.3528, 1.3395, 1.3264,
         1.4719, 1.4819, 1.4743, 1.4726, 1.4764, 1.4688, 1.4826, 1.4483, 1.4526,
         1.2519, 1.2768, 1.2694, 1.2849, 1.2480, 1.2406, 1.2299, 1.3039, 1.2668],
        [1.1831, 0.9938, 0.9770, 1.0322, 1.0356, 1.0519, 1.0439, 0.9239, 0.9239,
         2.5768, 2.5785, 2.5660, 2.5945, 2.5813, 2.6128, 2.5497, 2.5778, 2.5987,
         1.2446, 1.2316, 1.2116, 1.2089, 1.2280, 1.2357, 1.2576, 1.2367, 1.2367,
         1.1028, 1.0678, 1.0599, 1.1287, 1.0552, 1.1743, 1.1474, 1.1128, 1.0561,
         1.2154, 1.2627, 1.2297, 1.2187, 1.2172, 1.2488, 1.2677, 1.1108, 1.2021,
         0.9592, 1.0836, 1.0545, 1.1072, 0.9545, 0.9581, 0.8767, 1.1709, 1.0444],
        [1.5430, 1.5416, 1.5389, 1.5362, 1.5358, 1.5422, 1.5362, 1.5415, 1.5415,
         1.4844, 1.4817, 1.4826, 1.4821, 1.4859, 1.4635, 1.4789, 1.4846, 1.4773,
         1.9695, 1.9709, 1.9829, 1.9284, 1.9161, 1.9160, 1.9350, 1.9141, 1.9141,
         1.5972, 1.5958, 1.6049, 1.6055, 1.5968, 1.6059, 1.6055, 1.6054, 1.6049,
         1.7309, 1.7318, 1.7313, 1.7282, 1.7309, 1.7310, 1.7321, 1.7068, 1.7111,
         1.5305, 1.5396, 1.5389, 1.5399, 1.5273, 1.5375, 1.5285, 1.5407, 1.5390],
        [1.4110, 1.4008, 1.3859, 1.3781, 1.4016, 1.3995, 1.4012, 1.3950, 1.3950,
         1.3769, 1.3663, 1.3630, 1.3646, 1.3832, 1.3584, 1.3521, 1.3830, 1.3487,
         1.6139, 1.5952, 1.6127, 1.6098, 1.6088, 1.6088, 1.6126, 1.6114, 1.6114,
         2.6251, 2.5918, 2.5668, 2.5930, 2.6103, 2.5928, 2.6273, 2.5794, 2.5642,
         1.6121, 1.6088, 1.6064, 1.6083, 1.6114, 1.5961, 1.6138, 1.5694, 1.5894,
         1.4083, 1.4099, 1.3989, 1.4151, 1.4037, 1.3950, 1.4044, 1.4201, 1.4129],
        [1.5503, 1.5399, 1.4803, 1.4874, 1.5369, 1.5482, 1.5456, 1.5476, 1.5476,
         1.4894, 1.4834, 1.4775, 1.4711, 1.4936, 1.4425, 1.4753, 1.4935, 1.4794,
         1.7205, 1.7087, 1.7088, 1.7163, 1.7330, 1.7321, 1.7144, 1.7340, 1.7340,
         1.5496, 1.5562, 1.6102, 1.6020, 1.5595, 1.6105, 1.5894, 1.6113, 1.6068,
         1.9472, 1.9378, 1.9239, 1.9377, 1.9694, 1.9824, 1.9590, 2.0316, 2.0280,
         1.5219, 1.5211, 1.5325, 1.5482, 1.5257, 1.5410, 1.4993, 1.5427, 1.5475],
        [1.2536, 1.1541, 1.1480, 1.1672, 1.1607, 1.1722, 1.1709, 1.1050, 1.1050,
         1.1908, 1.1521, 1.1505, 1.1562, 1.2268, 1.0743, 1.0683, 1.2267, 1.1356,
         1.4120, 1.3942, 1.3678, 1.3804, 1.3965, 1.3954, 1.4070, 1.3978, 1.3978,
         1.2511, 1.2253, 1.2269, 1.2438, 1.2585, 1.2702, 1.2717, 1.2471, 1.2270,
         1.3869, 1.3830, 1.3906, 1.3816, 1.3505, 1.3499, 1.4099, 1.3124, 1.2868,
         2.7390, 2.7191, 2.7232, 2.7259, 2.7162, 2.6898, 2.7348, 2.7290, 2.6991]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 24 : 1821.6090069250413
Test loss for epoch 24 : 186.43074962381417
Test Precision for epoch 24 : 0.26153846153846155
Test Recall for epoch 24 : 0.26153846153846155
Test F1 for epoch 24 : 0.26153846153846155


theta for epoch 25 : tensor([[2.8420, 2.8312, 2.8438, 2.8412, 2.8397, 2.8305, 2.8342, 2.8142, 2.8142,
         1.2629, 1.2419, 1.2408, 1.2444, 1.2813, 1.2290, 1.1912, 1.2813, 1.2299,
         1.4875, 1.4751, 1.4928, 1.4795, 1.4851, 1.4858, 1.4921, 1.4858, 1.4858,
         1.3248, 1.3374, 1.3214, 1.3446, 1.3238, 1.3565, 1.3487, 1.3352, 1.3215,
         1.4980, 1.5085, 1.5006, 1.4988, 1.5028, 1.4950, 1.5093, 1.4740, 1.4784,
         1.2406, 1.2665, 1.2587, 1.2749, 1.2364, 1.2285, 1.2180, 1.2949, 1.2558],
        [1.1784, 0.9885, 0.9714, 1.0271, 1.0304, 1.0468, 1.0387, 0.9192, 0.9192,
         2.6401, 2.6421, 2.6291, 2.6588, 2.6446, 2.6781, 2.6126, 2.6410, 2.6634,
         1.2463, 1.2330, 1.2119, 1.2096, 1.2295, 1.2375, 1.2598, 1.2384, 1.2384,
         1.0902, 1.0550, 1.0487, 1.1159, 1.0433, 1.1608, 1.1343, 1.1004, 1.0450,
         1.2376, 1.2859, 1.2524, 1.2410, 1.2391, 1.2716, 1.2907, 1.1305, 1.2239,
         0.9413, 1.0677, 1.0382, 1.0916, 0.9365, 0.9403, 0.8576, 1.1565, 1.0278],
        [1.5427, 1.5417, 1.5390, 1.5362, 1.5359, 1.5422, 1.5362, 1.5418, 1.5418,
         1.4882, 1.4857, 1.4865, 1.4861, 1.4896, 1.4671, 1.4830, 1.4883, 1.4812,
         1.9925, 1.9939, 2.0062, 1.9563, 1.9437, 1.9435, 1.9631, 1.9416, 1.9416,
         1.5798, 1.5784, 1.5876, 1.5880, 1.5795, 1.5884, 1.5880, 1.5879, 1.5875,
         1.7567, 1.7577, 1.7572, 1.7541, 1.7568, 1.7569, 1.7579, 1.7324, 1.7367,
         1.5183, 1.5273, 1.5266, 1.5275, 1.5151, 1.5254, 1.5165, 1.5283, 1.5267],
        [1.4108, 1.4014, 1.3864, 1.3783, 1.4021, 1.3999, 1.4016, 1.3960, 1.3961,
         1.3788, 1.3681, 1.3648, 1.3664, 1.3850, 1.3602, 1.3544, 1.3848, 1.3502,
         1.6189, 1.5997, 1.6177, 1.6148, 1.6137, 1.6138, 1.6177, 1.6164, 1.6164,
         2.6566, 2.6209, 2.5947, 2.6220, 2.6409, 2.6215, 2.6588, 2.6076, 2.5919,
         1.6367, 1.6332, 1.6308, 1.6328, 1.6360, 1.6202, 1.6383, 1.5929, 1.6134,
         1.3950, 1.3963, 1.3852, 1.4015, 1.3903, 1.3816, 1.3913, 1.4063, 1.3994],
        [1.5491, 1.5394, 1.4802, 1.4869, 1.5363, 1.5474, 1.5450, 1.5473, 1.5473,
         1.4931, 1.4873, 1.4813, 1.4747, 1.4972, 1.4458, 1.4795, 1.4971, 1.4834,
         1.7273, 1.7153, 1.7154, 1.7232, 1.7403, 1.7393, 1.7210, 1.7413, 1.7413,
         1.5320, 1.5388, 1.5921, 1.5838, 1.5417, 1.5919, 1.5712, 1.5930, 1.5886,
         1.9863, 1.9766, 1.9626, 1.9766, 2.0088, 2.0222, 1.9983, 2.0720, 2.0685,
         1.5095, 1.5080, 1.5198, 1.5355, 1.5133, 1.5286, 1.4869, 1.5297, 1.5349],
        [1.2638, 1.1612, 1.1556, 1.1750, 1.1684, 1.1799, 1.1786, 1.1106, 1.1106,
         1.1916, 1.1514, 1.1497, 1.1558, 1.2289, 1.0775, 1.0645, 1.2288, 1.1344,
         1.4167, 1.3983, 1.3771, 1.3836, 1.4004, 1.3992, 1.4114, 1.4016, 1.4016,
         1.2481, 1.2226, 1.2232, 1.2410, 1.2516, 1.2677, 1.2688, 1.2440, 1.2233,
         1.4114, 1.4077, 1.4153, 1.4061, 1.3787, 1.3782, 1.4354, 1.3398, 1.3137,
         2.7831, 2.7614, 2.7659, 2.7687, 2.7586, 2.7304, 2.7788, 2.7717, 2.7401]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 25 : 1817.6925565630838
Test loss for epoch 25 : 187.1195607617024
Test Precision for epoch 25 : 0.26153846153846155
Test Recall for epoch 25 : 0.26153846153846155
Test F1 for epoch 25 : 0.26153846153846155


theta for epoch 26 : tensor([[2.8885, 2.8776, 2.8911, 2.8883, 2.8866, 2.8767, 2.8807, 2.8598, 2.8598,
         1.2699, 1.2479, 1.2468, 1.2506, 1.2890, 1.2346, 1.1952, 1.2890, 1.2355,
         1.4950, 1.4821, 1.5006, 1.4866, 1.4923, 1.4930, 1.4997, 1.4931, 1.4931,
         1.3237, 1.3361, 1.3197, 1.3434, 1.3224, 1.3557, 1.3478, 1.3339, 1.3197,
         1.5142, 1.5251, 1.5168, 1.5151, 1.5193, 1.5113, 1.5259, 1.4898, 1.4943,
         1.2312, 1.2580, 1.2500, 1.2667, 1.2267, 1.2184, 1.2080, 1.2876, 1.2468],
        [1.1701, 0.9797, 0.9624, 1.0184, 1.0216, 1.0382, 1.0299, 0.9110, 0.9111,
         2.7056, 2.7080, 2.6944, 2.7254, 2.7101, 2.7456, 2.6778, 2.7064, 2.7303,
         1.2490, 1.2355, 1.2134, 1.2116, 1.2321, 1.2403, 1.2631, 1.2413, 1.2413,
         1.0808, 1.0453, 1.0405, 1.1061, 1.0345, 1.1503, 1.1243, 1.0910, 1.0368,
         1.2497, 1.2990, 1.2650, 1.2532, 1.2511, 1.2844, 1.3037, 1.1403, 1.2357,
         0.9252, 1.0535, 1.0236, 1.0778, 0.9203, 0.9244, 0.8404, 1.1438, 1.0130],
        [1.5380, 1.5374, 1.5347, 1.5318, 1.5315, 1.5377, 1.5317, 1.5375, 1.5375,
         1.4959, 1.4935, 1.4943, 1.4939, 1.4973, 1.4746, 1.4911, 1.4959, 1.4890,
         2.0155, 2.0169, 2.0295, 1.9840, 1.9710, 1.9708, 1.9908, 1.9689, 1.9689,
         1.5654, 1.5640, 1.5732, 1.5735, 1.5652, 1.5738, 1.5735, 1.5735, 1.5732,
         1.7723, 1.7732, 1.7728, 1.7696, 1.7724, 1.7725, 1.7734, 1.7477, 1.7521,
         1.5075, 1.5163, 1.5157, 1.5166, 1.5042, 1.5147, 1.5059, 1.5172, 1.5158],
        [1.4061, 1.3976, 1.3825, 1.3742, 1.3982, 1.3959, 1.3977, 1.3928, 1.3928,
         1.3847, 1.3740, 1.3706, 1.3721, 1.3908, 1.3660, 1.3608, 1.3906, 1.3557,
         1.6247, 1.6049, 1.6235, 1.6206, 1.6195, 1.6196, 1.6234, 1.6223, 1.6223,
         2.6895, 2.6515, 2.6242, 2.6525, 2.6730, 2.6517, 2.6917, 2.6373, 2.6211,
         1.6511, 1.6473, 1.6450, 1.6471, 1.6503, 1.6340, 1.6526, 1.6063, 1.6272,
         1.3832, 1.3841, 1.3730, 1.3893, 1.3784, 1.3697, 1.3797, 1.3940, 1.3875],
        [1.5435, 1.5346, 1.4757, 1.4821, 1.5314, 1.5423, 1.5399, 1.5425, 1.5425,
         1.5007, 1.4950, 1.4890, 1.4823, 1.5047, 1.4531, 1.4876, 1.5046, 1.4914,
         1.7347, 1.7226, 1.7227, 1.7306, 1.7481, 1.7470, 1.7282, 1.7490, 1.7490,
         1.5176, 1.5246, 1.5770, 1.5687, 1.5271, 1.5765, 1.5563, 1.5777, 1.5735,
         2.0152, 2.0052, 1.9912, 2.0053, 2.0382, 2.0518, 2.0275, 2.1024, 2.0990,
         1.4985, 1.4963, 1.5085, 1.5241, 1.5023, 1.5175, 1.4760, 1.5181, 1.5236],
        [1.2694, 1.1645, 1.1592, 1.1788, 1.1720, 1.1836, 1.1822, 1.1127, 1.1127,
         1.1966, 1.1551, 1.1533, 1.1597, 1.2352, 1.0848, 1.0651, 1.2351, 1.1376,
         1.4226, 1.4036, 1.3873, 1.3882, 1.4056, 1.4042, 1.4171, 1.4068, 1.4068,
         1.2481, 1.2229, 1.2227, 1.2410, 1.2476, 1.2680, 1.2688, 1.2438, 1.2228,
         1.4261, 1.4226, 1.4301, 1.4207, 1.3968, 1.3963, 1.4509, 1.3572, 1.3305,
         2.8281, 2.8045, 2.8095, 2.8122, 2.8020, 2.7720, 2.8236, 2.8153, 2.7820]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 26 : 1816.7342205076948
Test loss for epoch 26 : 188.3976003405987
Test Precision for epoch 26 : 0.26153846153846155
Test Recall for epoch 26 : 0.26153846153846155
Test F1 for epoch 26 : 0.26153846153846155


theta for epoch 27 : tensor([[2.9349, 2.9241, 2.9386, 2.9354, 2.9336, 2.9229, 2.9272, 2.9055, 2.9055,
         1.2788, 1.2560, 1.2548, 1.2588, 1.2987, 1.2422, 1.2011, 1.2987, 1.2431,
         1.5034, 1.4901, 1.5092, 1.4946, 1.5004, 1.5012, 1.5082, 1.5013, 1.5013,
         1.3334, 1.3456, 1.3288, 1.3531, 1.3318, 1.3655, 1.3576, 1.3434, 1.3289,
         1.5122, 1.5236, 1.5149, 1.5131, 1.5175, 1.5094, 1.5244, 1.4874, 1.4920,
         1.2286, 1.2561, 1.2478, 1.2652, 1.2238, 1.2152, 1.2049, 1.2869, 1.2445],
        [1.1648, 0.9742, 0.9567, 1.0128, 1.0159, 1.0325, 1.0243, 0.9060, 0.9061,
         2.7716, 2.7744, 2.7603, 2.7925, 2.7761, 2.8137, 2.7435, 2.7722, 2.7976,
         1.2532, 1.2394, 1.2162, 1.2149, 1.2360, 1.2445, 1.2677, 1.2454, 1.2454,
         1.0826, 1.0469, 1.0434, 1.1077, 1.0369, 1.1512, 1.1256, 1.0928, 1.0397,
         1.2440, 1.2944, 1.2598, 1.2478, 1.2452, 1.2795, 1.2989, 1.1325, 1.2297,
         0.9162, 1.0461, 1.0159, 1.0709, 0.9113, 0.9156, 0.8304, 1.1379, 1.0052],
        [1.5347, 1.5344, 1.5319, 1.5288, 1.5286, 1.5347, 1.5287, 1.5347, 1.5347,
         1.5055, 1.5031, 1.5040, 1.5036, 1.5067, 1.4840, 1.5010, 1.5054, 1.4986,
         2.0385, 2.0399, 2.0528, 2.0112, 1.9978, 1.9977, 2.0182, 1.9957, 1.9957,
         1.5621, 1.5606, 1.5698, 1.5700, 1.5619, 1.5703, 1.5700, 1.5700, 1.5698,
         1.7697, 1.7705, 1.7701, 1.7670, 1.7697, 1.7699, 1.7707, 1.7448, 1.7492,
         1.5029, 1.5116, 1.5111, 1.5118, 1.4996, 1.5101, 1.5015, 1.5124, 1.5112],
        [1.4030, 1.3954, 1.3802, 1.3717, 1.3958, 1.3934, 1.3953, 1.3910, 1.3911,
         1.3924, 1.3818, 1.3782, 1.3798, 1.3984, 1.3738, 1.3690, 1.3982, 1.3631,
         1.6311, 1.6108, 1.6298, 1.6270, 1.6258, 1.6260, 1.6298, 1.6287, 1.6287,
         2.7291, 2.6890, 2.6608, 2.6899, 2.7119, 2.6887, 2.7313, 2.6740, 2.6575,
         1.6471, 1.6431, 1.6409, 1.6431, 1.6464, 1.6295, 1.6485, 1.6014, 1.6227,
         1.3778, 1.3783, 1.3671, 1.3835, 1.3728, 1.3641, 1.3744, 1.3880, 1.3818],
        [1.5393, 1.5311, 1.4729, 1.4788, 1.5280, 1.5385, 1.5363, 1.5390, 1.5390,
         1.5101, 1.5046, 1.4985, 1.4918, 1.5140, 1.4622, 1.4975, 1.5139, 1.5011,
         1.7425, 1.7303, 1.7304, 1.7385, 1.7563, 1.7552, 1.7358, 1.7572, 1.7572,
         1.5144, 1.5216, 1.5729, 1.5646, 1.5238, 1.5720, 1.5524, 1.5734, 1.5694,
         2.0259, 2.0156, 2.0014, 2.0158, 2.0492, 2.0632, 2.0384, 2.1147, 2.1113,
         1.4937, 1.4908, 1.5034, 1.5189, 1.4975, 1.5126, 1.4713, 1.5127, 1.5185],
        [1.2760, 1.1697, 1.1647, 1.1843, 1.1774, 1.1889, 1.1876, 1.1172, 1.1172,
         1.2035, 1.1608, 1.1589, 1.1656, 1.2434, 1.0939, 1.0679, 1.2433, 1.1428,
         1.4294, 1.4099, 1.3980, 1.3938, 1.4118, 1.4103, 1.4238, 1.4130, 1.4130,
         1.2585, 1.2337, 1.2328, 1.2515, 1.2542, 1.2786, 1.2792, 1.2542, 1.2329,
         1.4227, 1.4193, 1.4268, 1.4173, 1.3965, 1.3961, 1.4482, 1.3563, 1.3290,
         2.8773, 2.8519, 2.8573, 2.8600, 2.8496, 2.8178, 2.8727, 2.8629, 2.8281]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 27 : 1812.8383964458048
Test loss for epoch 27 : 189.7122430025243
Test Precision for epoch 27 : 0.26153846153846155
Test Recall for epoch 27 : 0.26153846153846155
Test F1 for epoch 27 : 0.26153846153846155


theta for epoch 28 : tensor([[2.9819, 2.9712, 2.9867, 2.9832, 2.9812, 2.9697, 2.9744, 2.9520, 2.9519,
         1.2845, 1.2607, 1.2595, 1.2638, 1.3052, 1.2466, 1.2037, 1.3052, 1.2475,
         1.5104, 1.4968, 1.5165, 1.5013, 1.5072, 1.5081, 1.5153, 1.5081, 1.5081,
         1.3508, 1.3629, 1.3458, 1.3704, 1.3490, 1.3830, 1.3751, 1.3607, 1.3459,
         1.5021, 1.5138, 1.5049, 1.5030, 1.5076, 1.4993, 1.5147, 1.4770, 1.4815,
         1.2327, 1.2609, 1.2524, 1.2702, 1.2277, 1.2188, 1.2086, 1.2926, 1.2488],
        [1.1632, 0.9725, 0.9552, 1.0112, 1.0141, 1.0308, 1.0225, 0.9049, 0.9049,
         2.8344, 2.8377, 2.8229, 2.8565, 2.8389, 2.8787, 2.8060, 2.8349, 2.8619,
         1.2570, 1.2430, 1.2189, 1.2178, 1.2395, 1.2483, 1.2719, 1.2492, 1.2492,
         1.0938, 1.0579, 1.0554, 1.1186, 1.0486, 1.1616, 1.1364, 1.1040, 1.0517,
         1.2310, 1.2824, 1.2473, 1.2349, 1.2321, 1.2671, 1.2868, 1.1175, 1.2164,
         0.9149, 1.0464, 1.0159, 1.0715, 0.9099, 0.9145, 0.8283, 1.1394, 1.0049],
        [1.5327, 1.5328, 1.5303, 1.5271, 1.5270, 1.5329, 1.5269, 1.5331, 1.5331,
         1.5117, 1.5095, 1.5103, 1.5100, 1.5129, 1.4901, 1.5075, 1.5115, 1.5050,
         2.0595, 2.0610, 2.0742, 2.0363, 2.0225, 2.0223, 2.0433, 2.0203, 2.0203,
         1.5673, 1.5658, 1.5750, 1.5750, 1.5672, 1.5752, 1.5750, 1.5750, 1.5750,
         1.7589, 1.7597, 1.7593, 1.7561, 1.7590, 1.7591, 1.7599, 1.7337, 1.7382,
         1.5048, 1.5133, 1.5128, 1.5135, 1.5014, 1.5120, 1.5035, 1.5140, 1.5129],
        [1.4012, 1.3946, 1.3794, 1.3707, 1.3948, 1.3923, 1.3942, 1.3907, 1.3907,
         1.3969, 1.3863, 1.3827, 1.3842, 1.4027, 1.3782, 1.3741, 1.4025, 1.3673,
         1.6360, 1.6152, 1.6347, 1.6320, 1.6306, 1.6308, 1.6347, 1.6337, 1.6337,
         2.7739, 2.7318, 2.7028, 2.7326, 2.7560, 2.7310, 2.7760, 2.7161, 2.6994,
         1.6351, 1.6308, 1.6287, 1.6310, 1.6343, 1.6169, 1.6364, 1.5883, 1.6101,
         1.3789, 1.3790, 1.3678, 1.3842, 1.3739, 1.3652, 1.3757, 1.3885, 1.3828],
        [1.5365, 1.5290, 1.4715, 1.4771, 1.5258, 1.5361, 1.5340, 1.5369, 1.5369,
         1.5163, 1.5109, 1.5047, 1.4979, 1.5199, 1.4680, 1.5042, 1.5199, 1.5075,
         1.7487, 1.7364, 1.7365, 1.7448, 1.7629, 1.7617, 1.7419, 1.7638, 1.7638,
         1.5199, 1.5273, 1.5774, 1.5691, 1.5291, 1.5762, 1.5571, 1.5778, 1.5739,
         2.0282, 2.0176, 2.0034, 2.0179, 2.0520, 2.0663, 2.0410, 2.1186, 2.1154,
         1.4954, 1.4918, 1.5048, 1.5202, 1.4992, 1.5142, 1.4731, 1.5137, 1.5198],
        [1.2829, 1.1761, 1.1714, 1.1909, 1.1840, 1.1955, 1.1940, 1.1236, 1.1236,
         1.2072, 1.1632, 1.1613, 1.1683, 1.2483, 1.0997, 1.0677, 1.2482, 1.1448,
         1.4349, 1.4150, 1.4070, 1.3983, 1.4168, 1.4152, 1.4291, 1.4180, 1.4180,
         1.2765, 1.2519, 1.2507, 1.2695, 1.2685, 1.2965, 1.2971, 1.2721, 1.2508,
         1.4113, 1.4079, 1.4155, 1.4058, 1.3880, 1.3875, 1.4374, 1.3471, 1.3193,
         2.9309, 2.9038, 2.9097, 2.9122, 2.9018, 2.8684, 2.9263, 2.9151, 2.8789]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 28 : 1809.783451517872
Test loss for epoch 28 : 190.89785200445087
Test Precision for epoch 28 : 0.26153846153846155
Test Recall for epoch 28 : 0.26153846153846155
Test F1 for epoch 28 : 0.26153846153846155


theta for epoch 29 : tensor([[3.0299, 3.0194, 3.0358, 3.0321, 3.0300, 3.0177, 3.0227, 2.9995, 2.9995,
         1.2823, 1.2577, 1.2564, 1.2609, 1.3038, 1.2431, 1.1987, 1.3038, 1.2440,
         1.5157, 1.5017, 1.5220, 1.5063, 1.5123, 1.5132, 1.5207, 1.5133, 1.5133,
         1.3680, 1.3799, 1.3627, 1.3875, 1.3660, 1.4002, 1.3923, 1.3778, 1.3628,
         1.4947, 1.5067, 1.4975, 1.4956, 1.5004, 1.4919, 1.5076, 1.4692, 1.4738,
         1.2423, 1.2710, 1.2623, 1.2805, 1.2371, 1.2279, 1.2178, 1.3035, 1.2586],
        [1.1659, 0.9754, 0.9582, 1.0139, 1.0167, 1.0333, 1.0251, 0.9081, 0.9081,
         2.8908, 2.8945, 2.8791, 2.9142, 2.8952, 2.9375, 2.8621, 2.8911, 2.9199,
         1.2605, 1.2462, 1.2213, 1.2205, 1.2426, 1.2516, 1.2758, 1.2526, 1.2526,
         1.1077, 1.0716, 1.0698, 1.1322, 1.0629, 1.1748, 1.1500, 1.1178, 1.0662,
         1.2217, 1.2741, 1.2384, 1.2257, 1.2226, 1.2585, 1.2784, 1.1064, 1.2068,
         0.9205, 1.0533, 1.0225, 1.0787, 0.9154, 0.9201, 0.8331, 1.1476, 1.0113],
        [1.5321, 1.5324, 1.5300, 1.5267, 1.5266, 1.5324, 1.5265, 1.5328, 1.5328,
         1.5103, 1.5081, 1.5090, 1.5086, 1.5113, 1.4885, 1.5064, 1.5100, 1.5036,
         2.0782, 2.0798, 2.0932, 2.0588, 2.0447, 2.0445, 2.0659, 2.0425, 2.0425,
         1.5735, 1.5720, 1.5811, 1.5811, 1.5735, 1.5811, 1.5810, 1.5811, 1.5811,
         1.7507, 1.7514, 1.7511, 1.7479, 1.7507, 1.7508, 1.7516, 1.7252, 1.7297,
         1.5119, 1.5203, 1.5199, 1.5204, 1.5085, 1.5191, 1.5109, 1.5209, 1.5199],
        [1.4007, 1.3950, 1.3798, 1.3709, 1.3951, 1.3925, 1.3945, 1.3917, 1.3917,
         1.3936, 1.3832, 1.3794, 1.3809, 1.3993, 1.3750, 1.3715, 1.3991, 1.3638,
         1.6391, 1.6179, 1.6378, 1.6351, 1.6337, 1.6339, 1.6378, 1.6369, 1.6369,
         2.8188, 2.7746, 2.7449, 2.7753, 2.8002, 2.7732, 2.8207, 2.7582, 2.7413,
         1.6256, 1.6212, 1.6191, 1.6214, 1.6248, 1.6070, 1.6268, 1.5780, 1.6001,
         1.3854, 1.3851, 1.3739, 1.3902, 1.3803, 1.3716, 1.3824, 1.3943, 1.3890],
        [1.5351, 1.5283, 1.4716, 1.4768, 1.5250, 1.5350, 1.5330, 1.5361, 1.5361,
         1.5147, 1.5095, 1.5032, 1.4963, 1.5182, 1.4662, 1.5031, 1.5181, 1.5062,
         1.7531, 1.7408, 1.7408, 1.7493, 1.7676, 1.7664, 1.7461, 1.7685, 1.7685,
         1.5266, 1.5341, 1.5830, 1.5747, 1.5355, 1.5814, 1.5630, 1.5832, 1.5795,
         2.0327, 2.0217, 2.0075, 2.0221, 2.0568, 2.0716, 2.0457, 2.1246, 2.1215,
         1.5024, 1.4981, 1.5115, 1.5267, 1.5062, 1.5211, 1.4803, 1.5200, 1.5264],
        [1.2897, 1.1836, 1.1789, 1.1983, 1.1913, 1.2027, 1.2013, 1.1315, 1.1316,
         1.2031, 1.1580, 1.1559, 1.1633, 1.2453, 1.0976, 1.0599, 1.2452, 1.1392,
         1.4387, 1.4183, 1.4139, 1.4011, 1.4201, 1.4184, 1.4327, 1.4214, 1.4214,
         1.2940, 1.2697, 1.2684, 1.2869, 1.2825, 1.3137, 1.3142, 1.2895, 1.2685,
         1.4026, 1.3992, 1.4069, 1.3970, 1.3818, 1.3813, 1.4293, 1.3404, 1.3120,
         2.9885, 2.9597, 2.9660, 2.9685, 2.9580, 2.9232, 2.9839, 2.9712, 2.9338]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 29 : 1807.7369438503918
Test loss for epoch 29 : 191.59930142418835
Test Precision for epoch 29 : 0.26153846153846155
Test Recall for epoch 29 : 0.26153846153846155
Test F1 for epoch 29 : 0.26153846153846155


theta for epoch 30 : tensor([[3.0787, 3.0685, 3.0859, 3.0818, 3.0795, 3.0665, 3.0718, 3.0480, 3.0480,
         1.2746, 1.2492, 1.2478, 1.2526, 1.2969, 1.2342, 1.1881, 1.2969, 1.2351,
         1.5207, 1.5064, 1.5273, 1.5112, 1.5173, 1.5182, 1.5259, 1.5182, 1.5182,
         1.3742, 1.3861, 1.3689, 1.3936, 1.3722, 1.4063, 1.3985, 1.3839, 1.3689,
         1.4937, 1.5060, 1.4965, 1.4946, 1.4995, 1.4908, 1.5068, 1.4678, 1.4724,
         1.2546, 1.2836, 1.2749, 1.2933, 1.2492, 1.2398, 1.2298, 1.3168, 1.2710],
        [1.1723, 0.9820, 0.9651, 1.0204, 1.0230, 1.0395, 1.0314, 0.9150, 0.9150,
         2.9422, 2.9464, 2.9303, 2.9670, 2.9466, 2.9915, 2.9131, 2.9422, 2.9731,
         1.2651, 1.2506, 1.2250, 1.2242, 1.2468, 1.2560, 1.2807, 1.2570, 1.2570,
         1.1146, 1.0783, 1.0768, 1.1389, 1.0702, 1.1812, 1.1566, 1.1245, 1.0733,
         1.2198, 1.2732, 1.2369, 1.2240, 1.2206, 1.2573, 1.2775, 1.1030, 1.2047,
         0.9302, 1.0642, 1.0331, 1.0898, 0.9250, 0.9299, 0.8422, 1.1596, 1.0218],
        [1.5322, 1.5328, 1.5304, 1.5271, 1.5270, 1.5327, 1.5268, 1.5332, 1.5332,
         1.5033, 1.5013, 1.5022, 1.5018, 1.5043, 1.4815, 1.4998, 1.5030, 1.4968,
         2.0962, 2.0977, 2.1114, 2.0803, 2.0658, 2.0655, 2.0874, 2.0635, 2.0635,
         1.5707, 1.5693, 1.5783, 1.5781, 1.5708, 1.5781, 1.5780, 1.5782, 1.5783,
         1.7487, 1.7494, 1.7491, 1.7458, 1.7487, 1.7488, 1.7495, 1.7230, 1.7275,
         1.5217, 1.5299, 1.5295, 1.5300, 1.5183, 1.5289, 1.5209, 1.5304, 1.5296],
        [1.4010, 1.3962, 1.3811, 1.3720, 1.3962, 1.3935, 1.3955, 1.3934, 1.3934,
         1.3850, 1.3746, 1.3707, 1.3722, 1.3905, 1.3664, 1.3635, 1.3903, 1.3550,
         1.6420, 1.6204, 1.6407, 1.6381, 1.6367, 1.6369, 1.6407, 1.6399, 1.6399,
         2.8562, 2.8099, 2.7793, 2.8105, 2.8370, 2.8080, 2.8581, 2.7927, 2.7756,
         1.6226, 1.6179, 1.6159, 1.6183, 1.6217, 1.6034, 1.6236, 1.5741, 1.5966,
         1.3946, 1.3938, 1.3827, 1.3989, 1.3894, 1.3808, 1.3918, 1.4028, 1.3980],
        [1.5344, 1.5283, 1.4727, 1.4775, 1.5251, 1.5348, 1.5328, 1.5360, 1.5360,
         1.5076, 1.5026, 1.4963, 1.4894, 1.5110, 1.4590, 1.4965, 1.5110, 1.4995,
         1.7573, 1.7449, 1.7450, 1.7535, 1.7721, 1.7708, 1.7501, 1.7729, 1.7729,
         1.5244, 1.5321, 1.5797, 1.5715, 1.5331, 1.5778, 1.5600, 1.5797, 1.5762,
         2.0428, 2.0315, 2.0173, 2.0321, 2.0673, 2.0824, 2.0559, 2.1361, 2.1331,
         1.5121, 1.5071, 1.5208, 1.5359, 1.5158, 1.5305, 1.4902, 1.5289, 1.5357],
        [1.2959, 1.1913, 1.1867, 1.2059, 1.1988, 1.2102, 1.2087, 1.1403, 1.1403,
         1.1935, 1.1473, 1.1451, 1.1529, 1.2368, 1.0898, 1.0467, 1.2367, 1.1281,
         1.4423, 1.4216, 1.4202, 1.4039, 1.4234, 1.4216, 1.4362, 1.4247, 1.4247,
         1.3002, 1.2762, 1.2751, 1.2930, 1.2854, 1.3195, 1.3201, 1.2957, 1.2752,
         1.4004, 1.3970, 1.4048, 1.3947, 1.3818, 1.3813, 1.4275, 1.3399, 1.3110,
         3.0483, 3.0179, 3.0246, 3.0270, 3.0166, 2.9803, 3.0437, 3.0295, 2.9910]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 30 : 1805.5607393565538
Test loss for epoch 30 : 191.98832545010924
Test Precision for epoch 30 : 0.26153846153846155
Test Recall for epoch 30 : 0.26153846153846155
Test F1 for epoch 30 : 0.26153846153846155


theta for epoch 31 : tensor([[3.1262, 3.1164, 3.1347, 3.1303, 3.1279, 3.1141, 3.1198, 3.0954, 3.0954,
         1.2659, 1.2396, 1.2382, 1.2432, 1.2889, 1.2243, 1.1768, 1.2889, 1.2252,
         1.5264, 1.5117, 1.5331, 1.5167, 1.5229, 1.5238, 1.5316, 1.5239, 1.5239,
         1.3707, 1.3824, 1.3654, 1.3900, 1.3687, 1.4026, 1.3948, 1.3804, 1.3655,
         1.4996, 1.5121, 1.5025, 1.5005, 1.5055, 1.4967, 1.5130, 1.4733, 1.4780,
         1.2637, 1.2929, 1.2841, 1.3027, 1.2581, 1.2486, 1.2387, 1.3265, 1.2802],
        [1.1784, 0.9884, 0.9719, 1.0267, 1.0291, 1.0455, 1.0374, 0.9216, 0.9216,
         2.9919, 2.9965, 2.9797, 3.0180, 2.9962, 3.0438, 2.9624, 2.9917, 3.0246,
         1.2713, 1.2566, 1.2303, 1.2296, 1.2526, 1.2620, 1.2872, 1.2629, 1.2629,
         1.1149, 1.0784, 1.0770, 1.1389, 1.0707, 1.1811, 1.1568, 1.1246, 1.0734,
         1.2256, 1.2800, 1.2431, 1.2300, 1.2263, 1.2638, 1.2842, 1.1075, 1.2103,
         0.9379, 1.0730, 1.0417, 1.0990, 0.9326, 0.9377, 0.8495, 1.1695, 1.0303],
        [1.5297, 1.5305, 1.5282, 1.5249, 1.5249, 1.5304, 1.5246, 1.5310, 1.5310,
         1.4954, 1.4935, 1.4944, 1.4940, 1.4963, 1.4735, 1.4922, 1.4950, 1.4890,
         2.1140, 2.1156, 2.1295, 2.1012, 2.0864, 2.0862, 2.1084, 2.0841, 2.0841,
         1.5600, 1.5586, 1.5675, 1.5673, 1.5601, 1.5672, 1.5672, 1.5673, 1.5675,
         1.7535, 1.7541, 1.7538, 1.7506, 1.7535, 1.7535, 1.7542, 1.7276, 1.7321,
         1.5282, 1.5362, 1.5359, 1.5363, 1.5248, 1.5354, 1.5276, 1.5366, 1.5360],
        [1.3986, 1.3947, 1.3796, 1.3704, 1.3945, 1.3918, 1.3938, 1.3924, 1.3924,
         1.3754, 1.3651, 1.3611, 1.3626, 1.3807, 1.3569, 1.3546, 1.3805, 1.3452,
         1.6455, 1.6235, 1.6442, 1.6417, 1.6402, 1.6405, 1.6442, 1.6435, 1.6435,
         2.8869, 2.8383, 2.8068, 2.8387, 2.8669, 2.8358, 2.8888, 2.8202, 2.8028,
         1.6264, 1.6215, 1.6196, 1.6221, 1.6255, 1.6068, 1.6273, 1.5771, 1.5999,
         1.4005, 1.3993, 1.3882, 1.4044, 1.3952, 1.3867, 1.3979, 1.4080, 1.4037],
        [1.5314, 1.5258, 1.4712, 1.4757, 1.5226, 1.5320, 1.5301, 1.5334, 1.5334,
         1.4996, 1.4948, 1.4884, 1.4814, 1.5028, 1.4509, 1.4890, 1.5028, 1.4917,
         1.7619, 1.7495, 1.7496, 1.7582, 1.7770, 1.7757, 1.7546, 1.7778, 1.7778,
         1.5143, 1.5222, 1.5684, 1.5604, 1.5228, 1.5663, 1.5491, 1.5683, 1.5649,
         2.0589, 2.0474, 2.0332, 2.0480, 2.0838, 2.0991, 2.0722, 2.1535, 2.1506,
         1.5185, 1.5129, 1.5269, 1.5417, 1.5222, 1.5368, 1.4968, 1.5347, 1.5416],
        [1.2982, 1.1958, 1.1911, 1.2101, 1.2030, 1.2143, 1.2128, 1.1463, 1.1464,
         1.1829, 1.1356, 1.1333, 1.1414, 1.2272, 1.0809, 1.0327, 1.2271, 1.1160,
         1.4467, 1.4257, 1.4269, 1.4076, 1.4276, 1.4257, 1.4404, 1.4288, 1.4288,
         1.2965, 1.2728, 1.2721, 1.2891, 1.2787, 1.3152, 1.3160, 1.2921, 1.2722,
         1.4052, 1.4017, 1.4096, 1.3995, 1.3884, 1.3879, 1.4327, 1.3461, 1.3167,
         3.1066, 3.0745, 3.0816, 3.0839, 3.0736, 3.0357, 3.1020, 3.0863, 3.0466]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 31 : 1803.7837617038817
Test loss for epoch 31 : 192.4518103203332
Test Precision for epoch 31 : 0.26153846153846155
Test Recall for epoch 31 : 0.26153846153846155
Test F1 for epoch 31 : 0.26153846153846155


theta for epoch 32 : tensor([[3.1712, 3.1617, 3.1810, 3.1763, 3.1737, 3.1591, 3.1651, 3.1401, 3.1401,
         1.2592, 1.2323, 1.2308, 1.2360, 1.2829, 1.2165, 1.1676, 1.2829, 1.2175,
         1.5326, 1.5176, 1.5395, 1.5227, 1.5290, 1.5300, 1.5379, 1.5300, 1.5300,
         1.3679, 1.3795, 1.3628, 1.3870, 1.3659, 1.3995, 1.3918, 1.3775, 1.3629,
         1.5118, 1.5245, 1.5148, 1.5127, 1.5179, 1.5089, 1.5254, 1.4852, 1.4899,
         1.2619, 1.2913, 1.2824, 1.3012, 1.2563, 1.2467, 1.2369, 1.3251, 1.2784],
        [1.1816, 0.9919, 0.9759, 1.0300, 1.0323, 1.0485, 1.0406, 0.9252, 0.9252,
         3.0420, 3.0472, 3.0297, 3.0696, 3.0462, 3.0967, 3.0123, 3.0415, 3.0765,
         1.2787, 1.2638, 1.2370, 1.2361, 1.2596, 1.2691, 1.2948, 1.2700, 1.2700,
         1.1175, 1.0808, 1.0792, 1.1413, 1.0735, 1.1835, 1.1593, 1.1269, 1.0757,
         1.2382, 1.2936, 1.2562, 1.2428, 1.2389, 1.2771, 1.2977, 1.1190, 1.2228,
         0.9362, 1.0723, 1.0408, 1.0985, 0.9308, 0.9360, 0.8474, 1.1699, 1.0291],
        [1.5227, 1.5237, 1.5214, 1.5181, 1.5181, 1.5235, 1.5177, 1.5242, 1.5242,
         1.4895, 1.4877, 1.4886, 1.4883, 1.4903, 1.4675, 1.4866, 1.4890, 1.4833,
         2.1314, 2.1331, 2.1473, 2.1216, 2.1064, 2.1061, 2.1288, 2.1041, 2.1041,
         1.5512, 1.5497, 1.5586, 1.5583, 1.5514, 1.5581, 1.5582, 1.5584, 1.5586,
         1.7643, 1.7649, 1.7647, 1.7614, 1.7643, 1.7644, 1.7650, 1.7384, 1.7429,
         1.5240, 1.5318, 1.5316, 1.5319, 1.5206, 1.5312, 1.5235, 1.5321, 1.5316],
        [1.3913, 1.3883, 1.3732, 1.3640, 1.3880, 1.3853, 1.3873, 1.3865, 1.3865,
         1.3678, 1.3576, 1.3536, 1.3550, 1.3729, 1.3495, 1.3478, 1.3727, 1.3375,
         1.6495, 1.6271, 1.6481, 1.6458, 1.6442, 1.6445, 1.6482, 1.6476, 1.6476,
         2.9183, 2.8673, 2.8349, 2.8676, 2.8975, 2.8642, 2.9200, 2.8484, 2.8308,
         1.6365, 1.6313, 1.6295, 1.6321, 1.6355, 1.6164, 1.6373, 1.5864, 1.6096,
         1.3956, 1.3941, 1.3830, 1.3991, 1.3903, 1.3819, 1.3932, 1.4024, 1.3987],
        [1.5238, 1.5188, 1.4653, 1.4694, 1.5156, 1.5246, 1.5229, 1.5262, 1.5262,
         1.4936, 1.4889, 1.4825, 1.4755, 1.4967, 1.4449, 1.4834, 1.4966, 1.4861,
         1.7669, 1.7544, 1.7546, 1.7633, 1.7822, 1.7808, 1.7594, 1.7830, 1.7830,
         1.5062, 1.5143, 1.5591, 1.5512, 1.5144, 1.5568, 1.5401, 1.5589, 1.5557,
         2.0805, 2.0687, 2.0545, 2.0695, 2.1056, 2.1213, 2.0940, 2.1762, 2.1734,
         1.5143, 1.5081, 1.5223, 1.5370, 1.5180, 1.5323, 1.4928, 1.5297, 1.5369],
        [1.2948, 1.1952, 1.1904, 1.2091, 1.2020, 1.2132, 1.2117, 1.1475, 1.1475,
         1.1744, 1.1261, 1.1237, 1.1321, 1.2197, 1.0739, 1.0209, 1.2196, 1.1061,
         1.4517, 1.4304, 1.4338, 1.4120, 1.4324, 1.4304, 1.4453, 1.4336, 1.4336,
         1.2935, 1.2700, 1.2699, 1.2859, 1.2729, 1.3115, 1.3126, 1.2891, 1.2700,
         1.4165, 1.4128, 1.4210, 1.4106, 1.4012, 1.4006, 1.4442, 1.3585, 1.3286,
         3.1582, 3.1242, 3.1318, 3.1340, 3.1237, 3.0842, 3.1536, 3.1362, 3.0951]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 32 : 1801.1664854177022
Test loss for epoch 32 : 192.92805922110543
Test Precision for epoch 32 : 0.26153846153846155
Test Recall for epoch 32 : 0.26153846153846155
Test F1 for epoch 32 : 0.26153846153846155


theta for epoch 33 : tensor([[3.2138, 3.2048, 3.2251, 3.2200, 3.2173, 3.2018, 3.2082, 3.1825, 3.1825,
         1.2554, 1.2278, 1.2262, 1.2317, 1.2798, 1.2117, 1.1616, 1.2798, 1.2127,
         1.5375, 1.5223, 1.5445, 1.5276, 1.5339, 1.5349, 1.5429, 1.5349, 1.5349,
         1.3694, 1.3810, 1.3646, 1.3884, 1.3676, 1.4007, 1.3932, 1.3791, 1.3647,
         1.5286, 1.5415, 1.5317, 1.5296, 1.5348, 1.5257, 1.5423, 1.5018, 1.5065,
         1.2499, 1.2792, 1.2704, 1.2892, 1.2443, 1.2347, 1.2248, 1.3132, 1.2664],
        [1.1825, 0.9931, 0.9776, 1.0310, 1.0331, 1.0491, 1.0414, 0.9263, 0.9264,
         3.0932, 3.0989, 3.0806, 3.1223, 3.0973, 3.1507, 3.0632, 3.0924, 3.1296,
         1.2856, 1.2704, 1.2431, 1.2422, 1.2659, 1.2756, 1.3019, 1.2765, 1.2765,
         1.1254, 1.0886, 1.0866, 1.1490, 1.0815, 1.1913, 1.1672, 1.1345, 1.0831,
         1.2559, 1.3121, 1.2742, 1.2606, 1.2566, 1.2955, 1.3163, 1.1357, 1.2404,
         0.9253, 1.0622, 1.0305, 1.0887, 0.9198, 0.9250, 0.8361, 1.1609, 1.0187],
        [1.5121, 1.5132, 1.5110, 1.5076, 1.5077, 1.5129, 1.5073, 1.5138, 1.5138,
         1.4864, 1.4847, 1.4855, 1.4853, 1.4871, 1.4643, 1.4838, 1.4859, 1.4803,
         2.1470, 2.1487, 2.1631, 2.1399, 2.1243, 2.1240, 2.1471, 2.1219, 2.1219,
         1.5477, 1.5463, 1.5550, 1.5547, 1.5479, 1.5545, 1.5545, 1.5547, 1.5550,
         1.7797, 1.7802, 1.7800, 1.7768, 1.7797, 1.7797, 1.7803, 1.7537, 1.7581,
         1.5096, 1.5173, 1.5171, 1.5173, 1.5061, 1.5168, 1.5093, 1.5175, 1.5171],
        [1.3803, 1.3781, 1.3631, 1.3538, 1.3777, 1.3749, 1.3770, 1.3767, 1.3768,
         1.3631, 1.3530, 1.3489, 1.3503, 1.3680, 1.3448, 1.3439, 1.3678, 1.3327,
         1.6521, 1.6294, 1.6507, 1.6485, 1.6469, 1.6472, 1.6508, 1.6503, 1.6503,
         2.9527, 2.8994, 2.8663, 2.8995, 2.9311, 2.8956, 2.9542, 2.8797, 2.8619,
         1.6511, 1.6457, 1.6440, 1.6467, 1.6501, 1.6306, 1.6517, 1.6004, 1.6238,
         1.3805, 1.3785, 1.3675, 1.3835, 1.3751, 1.3668, 1.3783, 1.3866, 1.3834],
        [1.5128, 1.5082, 1.4558, 1.4596, 1.5051, 1.5138, 1.5121, 1.5154, 1.5154,
         1.4904, 1.4858, 1.4794, 1.4724, 1.4933, 1.4417, 1.4807, 1.4932, 1.4831,
         1.7705, 1.7580, 1.7582, 1.7670, 1.7861, 1.7846, 1.7629, 1.7868, 1.7868,
         1.5035, 1.5118, 1.5553, 1.5475, 1.5115, 1.5527, 1.5367, 1.5550, 1.5518,
         2.1059, 2.0938, 2.0797, 2.0947, 2.1313, 2.1473, 2.1195, 2.2027, 2.2000,
         1.4998, 1.4931, 1.5075, 1.5220, 1.5035, 1.5176, 1.4785, 1.5146, 1.5220],
        [1.2868, 1.1904, 1.1854, 1.2038, 1.1967, 1.2078, 1.2063, 1.1448, 1.1448,
         1.1687, 1.1195, 1.1170, 1.1258, 1.2151, 1.0696, 1.0121, 1.2150, 1.0992,
         1.4556, 1.4340, 1.4393, 1.4154, 1.4362, 1.4340, 1.4491, 1.4374, 1.4374,
         1.2948, 1.2716, 1.2721, 1.2871, 1.2718, 1.3121, 1.3135, 1.2905, 1.2722,
         1.4324, 1.4286, 1.4370, 1.4266, 1.4184, 1.4177, 1.4604, 1.3754, 1.3450,
         3.2030, 3.1670, 3.1751, 3.1771, 3.1669, 3.1256, 3.1984, 3.1792, 3.1367]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 33 : 1797.6680547805797
Test loss for epoch 33 : 193.3759655720251
Test Precision for epoch 33 : 0.26153846153846155
Test Recall for epoch 33 : 0.26153846153846155
Test F1 for epoch 33 : 0.26153846153846155


theta for epoch 34 : tensor([[3.2557, 3.2471, 3.2685, 3.2631, 3.2602, 3.2438, 3.2505, 3.2242, 3.2242,
         1.2535, 1.2252, 1.2237, 1.2293, 1.2785, 1.2088, 1.1576, 1.2785, 1.2099,
         1.5387, 1.5233, 1.5459, 1.5288, 1.5352, 1.5363, 1.5442, 1.5363, 1.5363,
         1.3720, 1.3836, 1.3677, 1.3910, 1.3704, 1.4029, 1.3956, 1.3817, 1.3678,
         1.5459, 1.5590, 1.5490, 1.5468, 1.5522, 1.5429, 1.5597, 1.5187, 1.5235,
         1.2355, 1.2647, 1.2559, 1.2747, 1.2299, 1.2203, 1.2105, 1.2986, 1.2519],
        [1.1838, 0.9948, 0.9800, 1.0326, 1.0345, 1.0503, 1.0427, 0.9280, 0.9280,
         3.1446, 3.1509, 3.1320, 3.1753, 3.1487, 3.2050, 3.1145, 3.1437, 3.1830,
         1.2896, 1.2743, 1.2465, 1.2454, 1.2694, 1.2792, 1.3061, 1.2801, 1.2801,
         1.1358, 1.0988, 1.0962, 1.1591, 1.0919, 1.2017, 1.1776, 1.1445, 1.0928,
         1.2745, 1.3316, 1.2932, 1.2794, 1.2751, 1.3147, 1.3357, 1.1535, 1.2589,
         0.9128, 1.0505, 1.0186, 1.0773, 0.9072, 0.9124, 0.8234, 1.1502, 1.0066],
        [1.5010, 1.5021, 1.5000, 1.4966, 1.4967, 1.5018, 1.4962, 1.5027, 1.5027,
         1.4852, 1.4835, 1.4844, 1.4841, 1.4858, 1.4631, 1.4828, 1.4845, 1.4791,
         2.1586, 2.1603, 2.1749, 2.1540, 2.1381, 2.1378, 2.1613, 2.1357, 2.1357,
         1.5466, 1.5451, 1.5537, 1.5534, 1.5468, 1.5531, 1.5532, 1.5534, 1.5537,
         1.7954, 1.7958, 1.7957, 1.7924, 1.7954, 1.7954, 1.7959, 1.7693, 1.7738,
         1.4929, 1.5003, 1.5002, 1.5004, 1.4894, 1.5000, 1.4927, 1.5005, 1.5002],
        [1.3686, 1.3671, 1.3522, 1.3429, 1.3666, 1.3638, 1.3659, 1.3662, 1.3662,
         1.3602, 1.3503, 1.3462, 1.3475, 1.3649, 1.3422, 1.3419, 1.3647, 1.3298,
         1.6512, 1.6282, 1.6498, 1.6477, 1.6460, 1.6463, 1.6499, 1.6495, 1.6495,
         2.9878, 2.9323, 2.8984, 2.9323, 2.9656, 2.9278, 2.9893, 2.9118, 2.8939,
         1.6662, 1.6606, 1.6590, 1.6617, 1.6651, 1.6452, 1.6667, 1.6148, 1.6384,
         1.3631, 1.3607, 1.3497, 1.3656, 1.3576, 1.3494, 1.3610, 1.3684, 1.3657],
        [1.5013, 1.4971, 1.4458, 1.4493, 1.4940, 1.5024, 1.5008, 1.5041, 1.5041,
         1.4890, 1.4846, 1.4782, 1.4712, 1.4917, 1.4404, 1.4797, 1.4917, 1.4820,
         1.7705, 1.7581, 1.7583, 1.7671, 1.7863, 1.7848, 1.7629, 1.7869, 1.7869,
         1.5033, 1.5117, 1.5538, 1.5461, 1.5110, 1.5511, 1.5356, 1.5534, 1.5503,
         2.1312, 2.1189, 2.1049, 2.1200, 2.1569, 2.1732, 2.1449, 2.2290, 2.2265,
         1.4830, 1.4757, 1.4904, 1.5048, 1.4867, 1.5006, 1.4620, 1.4972, 1.5048],
        [1.2772, 1.1844, 1.1792, 1.1973, 1.1901, 1.2011, 1.1997, 1.1410, 1.1411,
         1.1650, 1.1149, 1.1123, 1.1214, 1.2124, 1.0671, 1.0054, 1.2123, 1.0943,
         1.4559, 1.4342, 1.4409, 1.4153, 1.4365, 1.4342, 1.4494, 1.4377, 1.4377,
         1.2973, 1.2742, 1.2755, 1.2893, 1.2720, 1.3137, 1.3155, 1.2931, 1.2756,
         1.4489, 1.4450, 1.4536, 1.4430, 1.4359, 1.4351, 1.4771, 1.3926, 1.3618,
         3.2465, 3.2084, 3.2170, 3.2189, 3.2087, 3.1655, 3.2418, 3.2208, 3.1767]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 34 : 1795.961955331128
Test loss for epoch 34 : 193.98242547109624
Test Precision for epoch 34 : 0.26153846153846155
Test Recall for epoch 34 : 0.26153846153846155
Test F1 for epoch 34 : 0.26153846153846155


theta for epoch 35 : tensor([[3.2996, 3.2915, 3.3138, 3.3080, 3.3050, 3.2877, 3.2948, 3.2679, 3.2679,
         1.2526, 1.2237, 1.2221, 1.2279, 1.2781, 1.2070, 1.1548, 1.2781, 1.2082,
         1.5380, 1.5225, 1.5454, 1.5282, 1.5346, 1.5357, 1.5436, 1.5357, 1.5357,
         1.3723, 1.3839, 1.3686, 1.3912, 1.3710, 1.4029, 1.3957, 1.3822, 1.3687,
         1.5561, 1.5693, 1.5593, 1.5571, 1.5625, 1.5531, 1.5700, 1.5287, 1.5334,
         1.2258, 1.2547, 1.2461, 1.2647, 1.2202, 1.2107, 1.2009, 1.2885, 1.2421],
        [1.1906, 1.0022, 0.9880, 1.0398, 1.0415, 1.0571, 1.0497, 0.9353, 0.9353,
         3.1958, 3.2026, 3.1829, 3.2280, 3.1997, 3.2590, 3.1654, 3.1945, 3.2360,
         1.2925, 1.2769, 1.2488, 1.2474, 1.2717, 1.2816, 1.3090, 1.2825, 1.2825,
         1.1454, 1.1082, 1.1049, 1.1686, 1.1015, 1.2114, 1.1873, 1.1538, 1.1016,
         1.2866, 1.3446, 1.3056, 1.2916, 1.2872, 1.3274, 1.3487, 1.1649, 1.2709,
         0.9057, 1.0440, 1.0119, 1.0710, 0.8999, 0.9052, 0.8161, 1.1447, 0.9998],
        [1.4943, 1.4955, 1.4935, 1.4901, 1.4902, 1.4952, 1.4897, 1.4961, 1.4961,
         1.4849, 1.4833, 1.4842, 1.4839, 1.4854, 1.4627, 1.4828, 1.4841, 1.4789,
         2.1677, 2.1695, 2.1843, 2.1655, 2.1493, 2.1490, 2.1728, 2.1468, 2.1468,
         1.5444, 1.5430, 1.5515, 1.5511, 1.5447, 1.5508, 1.5509, 1.5512, 1.5515,
         1.8041, 1.8045, 1.8044, 1.8012, 1.8041, 1.8042, 1.8046, 1.7780, 1.7824,
         1.4808, 1.4881, 1.4880, 1.4881, 1.4772, 1.4878, 1.4808, 1.4881, 1.4880],
        [1.3615, 1.3607, 1.3458, 1.3365, 1.3600, 1.3573, 1.3594, 1.3602, 1.3602,
         1.3584, 1.3487, 1.3444, 1.3457, 1.3628, 1.3405, 1.3409, 1.3626, 1.3279,
         1.6483, 1.6251, 1.6469, 1.6450, 1.6432, 1.6435, 1.6471, 1.6468, 1.6468,
         3.0213, 2.9636, 2.9289, 2.9633, 2.9984, 2.9584, 3.0226, 2.9422, 2.9241,
         1.6743, 1.6685, 1.6670, 1.6697, 1.6732, 1.6529, 1.6746, 1.6222, 1.6462,
         1.3503, 1.3475, 1.3365, 1.3523, 1.3448, 1.3366, 1.3484, 1.3549, 1.3527],
        [1.4944, 1.4906, 1.4404, 1.4436, 1.4875, 1.4956, 1.4940, 1.4973, 1.4973,
         1.4885, 1.4843, 1.4779, 1.4709, 1.4911, 1.4401, 1.4797, 1.4910, 1.4819,
         1.7686, 1.7562, 1.7565, 1.7652, 1.7845, 1.7830, 1.7609, 1.7852, 1.7852,
         1.5020, 1.5107, 1.5514, 1.5439, 1.5096, 1.5486, 1.5336, 1.5509, 1.5480,
         2.1494, 2.1368, 2.1229, 2.1380, 2.1754, 2.1920, 2.1632, 2.2483, 2.2459,
         1.4709, 1.4631, 1.4779, 1.4921, 1.4746, 1.4882, 1.4501, 1.4845, 1.4922],
        [1.2713, 1.1824, 1.1769, 1.1947, 1.1875, 1.1985, 1.1971, 1.1415, 1.1415,
         1.1623, 1.1113, 1.1086, 1.1180, 1.2106, 1.0655, 0.9998, 1.2105, 1.0904,
         1.4544, 1.4325, 1.4404, 1.4135, 1.4351, 1.4326, 1.4478, 1.4362, 1.4362,
         1.2973, 1.2745, 1.2766, 1.2891, 1.2701, 1.3130, 1.3151, 1.2932, 1.2767,
         1.4585, 1.4544, 1.4632, 1.4525, 1.4463, 1.4454, 1.4868, 1.4027, 1.3715,
         3.2931, 3.2529, 3.2621, 3.2638, 3.2537, 3.2087, 3.2885, 3.2655, 3.2201]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 35 : 1795.069351630752
Test loss for epoch 35 : 194.6366636765388
Test Precision for epoch 35 : 0.26153846153846155
Test Recall for epoch 35 : 0.26153846153846155
Test F1 for epoch 35 : 0.26153846153846155


theta for epoch 36 : tensor([[3.3455, 3.3381, 3.3614, 3.3552, 3.3520, 3.3340, 3.3414, 3.3140, 3.3140,
         1.2519, 1.2225, 1.2209, 1.2268, 1.2779, 1.2054, 1.1524, 1.2779, 1.2067,
         1.5387, 1.5230, 1.5461, 1.5289, 1.5354, 1.5365, 1.5443, 1.5365, 1.5365,
         1.3703, 1.3819, 1.3673, 1.3891, 1.3693, 1.4004, 1.3934, 1.3803, 1.3673,
         1.5553, 1.5686, 1.5585, 1.5563, 1.5617, 1.5522, 1.5692, 1.5276, 1.5323,
         1.2233, 1.2519, 1.2434, 1.2618, 1.2177, 1.2084, 1.1986, 1.2855, 1.2394],
        [1.2035, 1.0157, 1.0021, 1.0530, 1.0547, 1.0700, 1.0627, 0.9486, 0.9486,
         3.2461, 3.2535, 3.2331, 3.2798, 3.2499, 3.3122, 3.2156, 3.2445, 3.2883,
         1.2973, 1.2815, 1.2532, 1.2515, 1.2759, 1.2860, 1.3139, 1.2868, 1.2868,
         1.1541, 1.1168, 1.1125, 1.1772, 1.1101, 1.2204, 1.1962, 1.1621, 1.1092,
         1.2881, 1.3469, 1.3073, 1.2932, 1.2886, 1.3295, 1.3510, 1.1658, 1.2722,
         0.9063, 1.0451, 1.0128, 1.0723, 0.9004, 0.9056, 0.8167, 1.1466, 1.0006],
        [1.4931, 1.4943, 1.4923, 1.4890, 1.4892, 1.4940, 1.4885, 1.4949, 1.4949,
         1.4848, 1.4833, 1.4841, 1.4839, 1.4852, 1.4626, 1.4830, 1.4840, 1.4790,
         2.1773, 2.1791, 2.1941, 2.1772, 2.1607, 2.1603, 2.1845, 2.1582, 2.1582,
         1.5412, 1.5398, 1.5482, 1.5477, 1.5416, 1.5474, 1.5476, 1.5478, 1.5482,
         1.8019, 1.8023, 1.8022, 1.7990, 1.8019, 1.8019, 1.8023, 1.7758, 1.7802,
         1.4758, 1.4830, 1.4829, 1.4830, 1.4723, 1.4828, 1.4760, 1.4830, 1.4829],
        [1.3598, 1.3597, 1.3449, 1.3356, 1.3589, 1.3562, 1.3584, 1.3596, 1.3596,
         1.3568, 1.3472, 1.3429, 1.3442, 1.3610, 1.3391, 1.3402, 1.3608, 1.3264,
         1.6469, 1.6234, 1.6454, 1.6436, 1.6418, 1.6421, 1.6456, 1.6454, 1.6454,
         3.0531, 2.9930, 2.9576, 2.9926, 3.0294, 2.9871, 3.0542, 2.9708, 2.9527,
         1.6714, 1.6654, 1.6639, 1.6668, 1.6702, 1.6496, 1.6716, 1.6187, 1.6429,
         1.3447, 1.3416, 1.3307, 1.3464, 1.3392, 1.3312, 1.3431, 1.3487, 1.3470],
        [1.4929, 1.4894, 1.4404, 1.4435, 1.4865, 1.4942, 1.4927, 1.4959, 1.4959,
         1.4883, 1.4842, 1.4778, 1.4709, 1.4907, 1.4401, 1.4799, 1.4907, 1.4820,
         1.7679, 1.7555, 1.7559, 1.7646, 1.7840, 1.7825, 1.7601, 1.7846, 1.7846,
         1.4998, 1.5085, 1.5479, 1.5407, 1.5071, 1.5451, 1.5307, 1.5475, 1.5446,
         2.1565, 2.1436, 2.1297, 2.1450, 2.1828, 2.1996, 2.1704, 2.2565, 2.2542,
         1.4660, 1.4577, 1.4727, 1.4867, 1.4696, 1.4830, 1.4455, 1.4790, 1.4868],
        [1.2702, 1.1853, 1.1795, 1.1970, 1.1898, 1.2007, 1.1993, 1.1469, 1.1470,
         1.1598, 1.1080, 1.1052, 1.1149, 1.2090, 1.0639, 0.9946, 1.2089, 1.0868,
         1.4543, 1.4323, 1.4409, 1.4132, 1.4350, 1.4325, 1.4477, 1.4362, 1.4362,
         1.2949, 1.2722, 1.2753, 1.2864, 1.2661, 1.3097, 1.3122, 1.2909, 1.2754,
         1.4570, 1.4527, 1.4618, 1.4510, 1.4455, 1.4445, 1.4854, 1.4016, 1.3700,
         3.3443, 3.3022, 3.3119, 3.3134, 3.3034, 3.2567, 3.3398, 3.3149, 3.2682]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 36 : 1792.6397915457076
Test loss for epoch 36 : 195.14243886029737
Test Precision for epoch 36 : 0.26153846153846155
Test Recall for epoch 36 : 0.26153846153846155
Test F1 for epoch 36 : 0.26153846153846155


theta for epoch 37 : tensor([[3.3901, 3.3832, 3.4076, 3.4010, 3.3977, 3.3787, 3.3865, 3.3587, 3.3587,
         1.2499, 1.2201, 1.2184, 1.2245, 1.2764, 1.2027, 1.1490, 1.2764, 1.2041,
         1.5418, 1.5259, 1.5493, 1.5321, 1.5387, 1.5398, 1.5475, 1.5398, 1.5398,
         1.3664, 1.3780, 1.3640, 1.3851, 1.3657, 1.3960, 1.3892, 1.3764, 1.3641,
         1.5484, 1.5617, 1.5517, 1.5494, 1.5549, 1.5452, 1.5623, 1.5204, 1.5251,
         1.2272, 1.2555, 1.2471, 1.2653, 1.2218, 1.2126, 1.2028, 1.2887, 1.2432],
        [1.2152, 1.0280, 1.0151, 1.0652, 1.0667, 1.0818, 1.0747, 0.9607, 0.9607,
         3.2949, 3.3030, 3.2818, 3.3303, 3.2986, 3.3641, 3.2643, 3.2930, 3.3392,
         1.3048, 1.2889, 1.2604, 1.2583, 1.2829, 1.2930, 1.3215, 1.2939, 1.2939,
         1.1617, 1.1243, 1.1189, 1.1847, 1.1175, 1.2283, 1.2041, 1.1693, 1.1157,
         1.2838, 1.3435, 1.3033, 1.2890, 1.2843, 1.3258, 1.3476, 1.1610, 1.2679,
         0.9137, 1.0527, 1.0204, 1.0801, 0.9076, 0.9128, 0.8241, 1.1550, 1.0081],
        [1.4905, 1.4918, 1.4898, 1.4865, 1.4867, 1.4914, 1.4860, 1.4923, 1.4923,
         1.4834, 1.4820, 1.4828, 1.4826, 1.4838, 1.4613, 1.4818, 1.4825, 1.4777,
         2.1884, 2.1903, 2.2054, 2.1901, 2.1733, 2.1728, 2.1974, 2.1707, 2.1707,
         1.5372, 1.5358, 1.5440, 1.5436, 1.5375, 1.5432, 1.5434, 1.5436, 1.5440,
         1.7937, 1.7941, 1.7940, 1.7908, 1.7937, 1.7937, 1.7941, 1.7675, 1.7719,
         1.4773, 1.4843, 1.4843, 1.4843, 1.4738, 1.4842, 1.4776, 1.4842, 1.4843],
        [1.3567, 1.3572, 1.3425, 1.3332, 1.3563, 1.3536, 1.3558, 1.3574, 1.3574,
         1.3539, 1.3446, 1.3402, 1.3414, 1.3579, 1.3364, 1.3383, 1.3577, 1.3236,
         1.6478, 1.6242, 1.6464, 1.6446, 1.6428, 1.6432, 1.6466, 1.6465, 1.6465,
         3.0833, 3.0209, 2.9847, 3.0202, 3.0589, 3.0142, 3.0843, 2.9978, 2.9795,
         1.6624, 1.6562, 1.6549, 1.6578, 1.6612, 1.6403, 1.6625, 1.6092, 1.6336,
         1.3457, 1.3422, 1.3314, 1.3469, 1.3402, 1.3322, 1.3442, 1.3489, 1.3477],
        [1.4902, 1.4870, 1.4391, 1.4419, 1.4841, 1.4915, 1.4901, 1.4932, 1.4932,
         1.4867, 1.4829, 1.4765, 1.4696, 1.4890, 1.4388, 1.4788, 1.4890, 1.4807,
         1.7696, 1.7572, 1.7577, 1.7664, 1.7858, 1.7842, 1.7617, 1.7863, 1.7863,
         1.4966, 1.5055, 1.5437, 1.5367, 1.5037, 1.5408, 1.5269, 1.5432, 1.5404,
         2.1573, 2.1442, 2.1304, 2.1457, 2.1839, 2.2011, 2.1714, 2.2585, 2.2563,
         1.4675, 1.4588, 1.4739, 1.4877, 1.4711, 1.4842, 1.4473, 1.4799, 1.4879],
        [1.2667, 1.1861, 1.1800, 1.1971, 1.1899, 1.2007, 1.1993, 1.1502, 1.1503,
         1.1561, 1.1035, 1.1006, 1.1107, 1.2061, 1.0610, 0.9883, 1.2061, 1.0820,
         1.4568, 1.4346, 1.4436, 1.4155, 1.4376, 1.4349, 1.4501, 1.4387, 1.4387,
         1.2904, 1.2678, 1.2719, 1.2817, 1.2603, 1.3043, 1.3073, 1.2866, 1.2720,
         1.4495, 1.4450, 1.4543, 1.4435, 1.4385, 1.4375, 1.4779, 1.3944, 1.3624,
         3.3994, 3.3553, 3.3656, 3.3669, 3.3571, 3.3088, 3.3949, 3.3681, 3.3202]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 37 : 1790.1169752451742
Test loss for epoch 37 : 195.6340498177093
Test Precision for epoch 37 : 0.26153846153846155
Test Recall for epoch 37 : 0.26153846153846155
Test F1 for epoch 37 : 0.26153846153846155


theta for epoch 38 : tensor([[3.4296, 3.4233, 3.4488, 3.4418, 3.4383, 3.4185, 3.4266, 3.3982, 3.3982,
         1.2458, 1.2155, 1.2138, 1.2200, 1.2726, 1.1978, 1.1436, 1.2726, 1.1994,
         1.5471, 1.5311, 1.5547, 1.5376, 1.5441, 1.5453, 1.5529, 1.5453, 1.5453,
         1.3623, 1.3739, 1.3607, 1.3809, 1.3619, 1.3914, 1.3848, 1.3725, 1.3608,
         1.5423, 1.5557, 1.5457, 1.5433, 1.5489, 1.5390, 1.5562, 1.5140, 1.5188,
         1.2344, 1.2622, 1.2540, 1.2719, 1.2290, 1.2200, 1.2102, 1.2950, 1.2502],
        [1.2192, 1.0324, 1.0202, 1.0695, 1.0708, 1.0856, 1.0787, 0.9648, 0.9648,
         3.3420, 3.3507, 3.3287, 3.3791, 3.3456, 3.4143, 3.3112, 3.3398, 3.3884,
         1.3146, 1.2986, 1.2698, 1.2674, 1.2922, 1.3023, 1.3313, 1.3031, 1.3031,
         1.1692, 1.1316, 1.1251, 1.1920, 1.1247, 1.2362, 1.2118, 1.1764, 1.1219,
         1.2804, 1.3409, 1.3002, 1.2857, 1.2809, 1.3230, 1.3450, 1.1573, 1.2644,
         0.9242, 1.0635, 1.0310, 1.0911, 0.9180, 0.9231, 0.8346, 1.1665, 1.0186],
        [1.4805, 1.4817, 1.4799, 1.4766, 1.4768, 1.4814, 1.4761, 1.4822, 1.4822,
         1.4796, 1.4784, 1.4792, 1.4790, 1.4800, 1.4576, 1.4784, 1.4788, 1.4741,
         2.2007, 2.2026, 2.2179, 2.2039, 2.1867, 2.1862, 2.2111, 2.1841, 2.1841,
         1.5339, 1.5325, 1.5405, 1.5401, 1.5342, 1.5397, 1.5399, 1.5402, 1.5405,
         1.7863, 1.7866, 1.7865, 1.7833, 1.7863, 1.7863, 1.7866, 1.7600, 1.7644,
         1.4820, 1.4887, 1.4887, 1.4887, 1.4784, 1.4888, 1.4824, 1.4886, 1.4887],
        [1.3459, 1.3468, 1.3322, 1.3230, 1.3459, 1.3432, 1.3453, 1.3473, 1.3473,
         1.3488, 1.3396, 1.3352, 1.3363, 1.3525, 1.3315, 1.3341, 1.3523, 1.3185,
         1.6509, 1.6271, 1.6494, 1.6478, 1.6459, 1.6463, 1.6496, 1.6497, 1.6497,
         3.1130, 3.0482, 3.0113, 3.0474, 3.0879, 3.0408, 3.1139, 3.0243, 3.0060,
         1.6543, 1.6479, 1.6467, 1.6497, 1.6531, 1.6318, 1.6542, 1.6005, 1.6251,
         1.3498, 1.3459, 1.3352, 1.3505, 1.3443, 1.3364, 1.3485, 1.3524, 1.3517],
        [1.4801, 1.4771, 1.4302, 1.4329, 1.4743, 1.4814, 1.4801, 1.4830, 1.4830,
         1.4829, 1.4792, 1.4728, 1.4659, 1.4850, 1.4352, 1.4754, 1.4850, 1.4772,
         1.7732, 1.7609, 1.7614, 1.7701, 1.7895, 1.7879, 1.7653, 1.7900, 1.7900,
         1.4942, 1.5032, 1.5403, 1.5334, 1.5011, 1.5373, 1.5238, 1.5397, 1.5370,
         2.1584, 2.1450, 2.1313, 2.1467, 2.1853, 2.2028, 2.1726, 2.2607, 2.2586,
         1.4722, 1.4631, 1.4782, 1.4918, 1.4758, 1.4886, 1.4523, 1.4840, 1.4921],
        [1.2550, 1.1784, 1.1720, 1.1888, 1.1816, 1.1924, 1.1910, 1.1450, 1.1451,
         1.1503, 1.0969, 1.0939, 1.1043, 1.2011, 1.0558, 0.9801, 1.2010, 1.0752,
         1.4616, 1.4393, 1.4484, 1.4201, 1.4426, 1.4397, 1.4548, 1.4436, 1.4436,
         1.2858, 1.2633, 1.2684, 1.2768, 1.2546, 1.2989, 1.3023, 1.2821, 1.2685,
         1.4429, 1.4382, 1.4478, 1.4368, 1.4323, 1.4311, 1.4714, 1.3879, 1.3556,
         3.4561, 3.4101, 3.4208, 3.4219, 3.4124, 3.3625, 3.4517, 3.4229, 3.3739]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 38 : 1788.346611934505
Test loss for epoch 38 : 196.22821266165732
Test Precision for epoch 38 : 0.26153846153846155
Test Recall for epoch 38 : 0.26153846153846155
Test F1 for epoch 38 : 0.26153846153846155


theta for epoch 39 : tensor([[3.4672, 3.4615, 3.4881, 3.4807, 3.4770, 3.4562, 3.4648, 3.4358, 3.4358,
         1.2398, 1.2092, 1.2075, 1.2137, 1.2669, 1.1913, 1.1366, 1.2669, 1.1929,
         1.5531, 1.5371, 1.5608, 1.5439, 1.5504, 1.5516, 1.5590, 1.5516, 1.5516,
         1.3595, 1.3711, 1.3586, 1.3780, 1.3594, 1.3880, 1.3817, 1.3697, 1.3587,
         1.5406, 1.5540, 1.5440, 1.5416, 1.5472, 1.5371, 1.5544, 1.5120, 1.5168,
         1.2382, 1.2655, 1.2575, 1.2751, 1.2329, 1.2241, 1.2143, 1.2978, 1.2537],
        [1.2207, 1.0345, 1.0228, 1.0713, 1.0726, 1.0872, 1.0804, 0.9665, 0.9665,
         3.3879, 3.3972, 3.3745, 3.4267, 3.3913, 3.4634, 3.3570, 3.3854, 3.4365,
         1.3250, 1.3088, 1.2799, 1.2772, 1.3020, 1.3122, 1.3417, 1.3130, 1.3130,
         1.1773, 1.1396, 1.1320, 1.2001, 1.1326, 1.2448, 1.2203, 1.1842, 1.1288,
         1.2812, 1.3426, 1.3013, 1.2867, 1.2818, 1.3244, 1.3466, 1.1578, 1.2652,
         0.9313, 1.0708, 1.0382, 1.0985, 0.9250, 0.9301, 0.8419, 1.1745, 1.0257],
        [1.4692, 1.4703, 1.4685, 1.4652, 1.4655, 1.4700, 1.4647, 1.4707, 1.4708,
         1.4740, 1.4728, 1.4736, 1.4734, 1.4742, 1.4520, 1.4729, 1.4731, 1.4686,
         2.2130, 2.2149, 2.2304, 2.2173, 2.1999, 2.1994, 2.2246, 2.1973, 2.1973,
         1.5324, 1.5311, 1.5390, 1.5385, 1.5328, 1.5382, 1.5384, 1.5386, 1.5390,
         1.7830, 1.7833, 1.7832, 1.7800, 1.7830, 1.7830, 1.7833, 1.7568, 1.7611,
         1.4833, 1.4899, 1.4899, 1.4898, 1.4798, 1.4900, 1.4838, 1.4897, 1.4899],
        [1.3335, 1.3349, 1.3204, 1.3112, 1.3339, 1.3313, 1.3334, 1.3356, 1.3356,
         1.3417, 1.3328, 1.3284, 1.3294, 1.3452, 1.3247, 1.3280, 1.3451, 1.3116,
         1.6546, 1.6307, 1.6532, 1.6517, 1.6498, 1.6502, 1.6534, 1.6536, 1.6536,
         3.1432, 3.0760, 3.0384, 3.0750, 3.1174, 3.0677, 3.1438, 3.0512, 3.0328,
         1.6504, 1.6439, 1.6427, 1.6457, 1.6492, 1.6276, 1.6502, 1.5961, 1.6209,
         1.3506, 1.3464, 1.3357, 1.3509, 1.3451, 1.3373, 1.3495, 1.3525, 1.3523],
        [1.4688, 1.4659, 1.4199, 1.4225, 1.4632, 1.4701, 1.4687, 1.4715, 1.4716,
         1.4771, 1.4735, 1.4672, 1.4604, 1.4791, 1.4297, 1.4700, 1.4790, 1.4717,
         1.7775, 1.7652, 1.7659, 1.7745, 1.7938, 1.7922, 1.7695, 1.7943, 1.7943,
         1.4937, 1.5027, 1.5388, 1.5321, 1.5004, 1.5359, 1.5228, 1.5382, 1.5355,
         2.1631, 2.1494, 2.1358, 2.1513, 2.1903, 2.2081, 2.1774, 2.2664, 2.2645,
         1.4736, 1.4641, 1.4793, 1.4927, 1.4772, 1.4897, 1.4540, 1.4848, 1.4930],
        [1.2419, 1.1691, 1.1623, 1.1788, 1.1716, 1.1824, 1.1810, 1.1379, 1.1380,
         1.1428, 1.0887, 1.0856, 1.0963, 1.1944, 1.0488, 0.9703, 1.1943, 1.0667,
         1.4674, 1.4450, 1.4539, 1.4258, 1.4485, 1.4456, 1.4606, 1.4495, 1.4495,
         1.2827, 1.2602, 1.2662, 1.2735, 1.2507, 1.2951, 1.2988, 1.2791, 1.2663,
         1.4408, 1.4358, 1.4457, 1.4347, 1.4303, 1.4290, 1.4693, 1.3857, 1.3531,
         3.5100, 3.4619, 3.4732, 3.4741, 3.4647, 3.4132, 3.5056, 3.4748, 3.4246]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 39 : 1787.3826745620318
Test loss for epoch 39 : 196.8957970109622
Test Precision for epoch 39 : 0.26153846153846155
Test Recall for epoch 39 : 0.26153846153846155
Test F1 for epoch 39 : 0.26153846153846155


theta for epoch 40 : tensor([[3.5067, 3.5016, 3.5293, 3.5215, 3.5176, 3.4959, 3.5048, 3.4753, 3.4753,
         1.2336, 1.2029, 1.2011, 1.2074, 1.2610, 1.1847, 1.1299, 1.2610, 1.1865,
         1.5584, 1.5424, 1.5662, 1.5494, 1.5559, 1.5572, 1.5644, 1.5572, 1.5572,
         1.3582, 1.3698, 1.3582, 1.3766, 1.3585, 1.3862, 1.3801, 1.3686, 1.3582,
         1.5442, 1.5577, 1.5477, 1.5453, 1.5509, 1.5407, 1.5580, 1.5155, 1.5202,
         1.2330, 1.2598, 1.2520, 1.2692, 1.2279, 1.2193, 1.2094, 1.2914, 1.2483],
        [1.2265, 1.0411, 1.0299, 1.0778, 1.0789, 1.0933, 1.0867, 0.9729, 0.9729,
         3.4338, 3.4439, 3.4203, 3.4744, 3.4372, 3.5127, 3.4029, 3.4310, 3.4847,
         1.3343, 1.3180, 1.2891, 1.2860, 1.3109, 1.3211, 1.3511, 1.3219, 1.3219,
         1.1860, 1.1480, 1.1394, 1.2087, 1.1410, 1.2539, 1.2293, 1.1925, 1.1362,
         1.2873, 1.3494, 1.3076, 1.2929, 1.2879, 1.3310, 1.3534, 1.1637, 1.2713,
         0.9293, 1.0690, 1.0363, 1.0969, 0.9229, 0.9279, 0.8401, 1.1733, 1.0237],
        [1.4639, 1.4649, 1.4631, 1.4599, 1.4602, 1.4646, 1.4595, 1.4653, 1.4653,
         1.4680, 1.4669, 1.4677, 1.4675, 1.4682, 1.4461, 1.4672, 1.4670, 1.4628,
         2.2238, 2.2258, 2.2414, 2.2292, 2.2115, 2.2110, 2.2364, 2.2089, 2.2089,
         1.5331, 1.5318, 1.5395, 1.5391, 1.5335, 1.5388, 1.5390, 1.5392, 1.5395,
         1.7850, 1.7852, 1.7852, 1.7820, 1.7850, 1.7850, 1.7852, 1.7588, 1.7631,
         1.4758, 1.4822, 1.4823, 1.4822, 1.4723, 1.4824, 1.4765, 1.4820, 1.4823],
        [1.3274, 1.3290, 1.3146, 1.3056, 1.3280, 1.3254, 1.3275, 1.3300, 1.3300,
         1.3344, 1.3257, 1.3212, 1.3222, 1.3377, 1.3177, 1.3216, 1.3375, 1.3044,
         1.6577, 1.6336, 1.6562, 1.6548, 1.6529, 1.6533, 1.6565, 1.6567, 1.6567,
         3.1740, 3.1044, 3.0661, 3.1031, 3.1474, 3.0953, 3.1744, 3.0787, 3.0603,
         1.6519, 1.6452, 1.6441, 1.6472, 1.6506, 1.6287, 1.6516, 1.5971, 1.6221,
         1.3425, 1.3380, 1.3274, 1.3424, 1.3369, 1.3293, 1.3416, 1.3438, 1.3440],
        [1.4636, 1.4608, 1.4157, 1.4182, 1.4582, 1.4648, 1.4635, 1.4661, 1.4662,
         1.4710, 1.4675, 1.4613, 1.4545, 1.4728, 1.4240, 1.4642, 1.4728, 1.4659,
         1.7810, 1.7688, 1.7695, 1.7780, 1.7974, 1.7957, 1.7730, 1.7978, 1.7978,
         1.4953, 1.5045, 1.5395, 1.5330, 1.5019, 1.5366, 1.5239, 1.5389, 1.5363,
         2.1724, 2.1585, 2.1450, 2.1605, 2.1999, 2.2179, 2.1868, 2.2767, 2.2749,
         1.4662, 1.4564, 1.4716, 1.4848, 1.4697, 1.4819, 1.4468, 1.4769, 1.4851],
        [1.2357, 1.1661, 1.1590, 1.1753, 1.1682, 1.1789, 1.1775, 1.1369, 1.1369,
         1.1354, 1.0805, 1.0774, 1.0884, 1.1877, 1.0417, 0.9606, 1.1877, 1.0584,
         1.4727, 1.4503, 1.4587, 1.4310, 1.4540, 1.4509, 1.4659, 1.4550, 1.4550,
         1.2817, 1.2592, 1.2659, 1.2722, 1.2491, 1.2935, 1.2976, 1.2781, 1.2660,
         1.4442, 1.4391, 1.4492, 1.4381, 1.4337, 1.4323, 1.4728, 1.3890, 1.3560,
         3.5570, 3.5066, 3.5185, 3.5192, 3.5101, 3.4567, 3.5527, 3.5196, 3.4681]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 40 : 1785.6101891486435
Test loss for epoch 40 : 197.42672022679358
Test Precision for epoch 40 : 0.26153846153846155
Test Recall for epoch 40 : 0.26153846153846155
Test F1 for epoch 40 : 0.26153846153846155


theta for epoch 41 : tensor([[3.5473, 3.5430, 3.5718, 3.5636, 3.5596, 3.5369, 3.5462, 3.5162, 3.5162,
         1.2283, 1.1974, 1.1957, 1.2020, 1.2557, 1.1790, 1.1243, 1.2558, 1.1810,
         1.5614, 1.5454, 1.5692, 1.5526, 1.5592, 1.5605, 1.5674, 1.5604, 1.5604,
         1.3557, 1.3675, 1.3566, 1.3741, 1.3565, 1.3833, 1.3774, 1.3664, 1.3567,
         1.5527, 1.5661, 1.5563, 1.5538, 1.5594, 1.5491, 1.5664, 1.5237, 1.5284,
         1.2214, 1.2476, 1.2400, 1.2568, 1.2164, 1.2081, 1.1982, 1.2786, 1.2364],
        [1.2355, 1.0510, 1.0403, 1.0875, 1.0885, 1.1027, 1.0963, 0.9828, 0.9828,
         3.4806, 3.4913, 3.4670, 3.5230, 3.4838, 3.5627, 3.4496, 3.4774, 3.5337,
         1.3411, 1.3247, 1.2956, 1.2922, 1.3172, 1.3275, 1.3578, 1.3282, 1.3282,
         1.1926, 1.1544, 1.1448, 1.2152, 1.1473, 1.2610, 1.2362, 1.1987, 1.1416,
         1.2980, 1.3607, 1.3186, 1.3037, 1.2986, 1.3421, 1.3647, 1.1742, 1.2819,
         0.9207, 1.0605, 1.0277, 1.0885, 0.9141, 0.9191, 0.8316, 1.1655, 1.0150],
        [1.4636, 1.4646, 1.4629, 1.4597, 1.4600, 1.4643, 1.4592, 1.4650, 1.4650,
         1.4627, 1.4617, 1.4624, 1.4623, 1.4628, 1.4408, 1.4621, 1.4617, 1.4576,
         2.2318, 2.2338, 2.2495, 2.2382, 2.2202, 2.2196, 2.2454, 2.2176, 2.2176,
         1.5333, 1.5320, 1.5396, 1.5392, 1.5336, 1.5389, 1.5390, 1.5393, 1.5396,
         1.7917, 1.7919, 1.7919, 1.7887, 1.7917, 1.7917, 1.7919, 1.7655, 1.7698,
         1.4620, 1.4683, 1.4684, 1.4683, 1.4586, 1.4686, 1.4628, 1.4681, 1.4684],
        [1.3264, 1.3283, 1.3140, 1.3050, 1.3272, 1.3247, 1.3268, 1.3294, 1.3294,
         1.3278, 1.3193, 1.3148, 1.3157, 1.3309, 1.3113, 1.3160, 1.3307, 1.2980,
         1.6583, 1.6342, 1.6568, 1.6556, 1.6536, 1.6540, 1.6571, 1.6575, 1.6575,
         3.2034, 3.1314, 3.0925, 3.1299, 3.1762, 3.1215, 3.2037, 3.1048, 3.0864,
         1.6582, 1.6513, 1.6503, 1.6534, 1.6568, 1.6347, 1.6577, 1.6029, 1.6281,
         1.3281, 1.3233, 1.3128, 1.3277, 1.3226, 1.3150, 1.3273, 1.3288, 1.3295],
        [1.4635, 1.4608, 1.4167, 1.4191, 1.4582, 1.4646, 1.4633, 1.4658, 1.4658,
         1.4656, 1.4622, 1.4560, 1.4494, 1.4673, 1.4189, 1.4591, 1.4672, 1.4607,
         1.7822, 1.7700, 1.7708, 1.7793, 1.7985, 1.7969, 1.7741, 1.7989, 1.7989,
         1.4964, 1.5056, 1.5397, 1.5334, 1.5028, 1.5369, 1.5245, 1.5392, 1.5365,
         2.1859, 2.1718, 2.1583, 2.1739, 2.2136, 2.2319, 2.2003, 2.2910, 2.2893,
         1.4525, 1.4424, 1.4577, 1.4707, 1.4561, 1.4680, 1.4335, 1.4628, 1.4710],
        [1.2355, 1.1684, 1.1611, 1.1773, 1.1702, 1.1809, 1.1795, 1.1409, 1.1409,
         1.1291, 1.0735, 1.0703, 1.0816, 1.1822, 1.0356, 0.9521, 1.1821, 1.0512,
         1.4760, 1.4536, 1.4613, 1.4342, 1.4574, 1.4542, 1.4692, 1.4584, 1.4584,
         1.2801, 1.2574, 1.2648, 1.2704, 1.2471, 1.2915, 1.2958, 1.2766, 1.2649,
         1.4527, 1.4475, 1.4577, 1.4466, 1.4420, 1.4406, 1.4813, 1.3971, 1.3638,
         3.5986, 3.5459, 3.5584, 3.5588, 3.5499, 3.4946, 3.5944, 3.5591, 3.5061]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 41 : 1783.4504033415906
Test loss for epoch 41 : 197.92602636367337
Test Precision for epoch 41 : 0.26153846153846155
Test Recall for epoch 41 : 0.26153846153846155
Test F1 for epoch 41 : 0.26153846153846155


theta for epoch 42 : tensor([[3.5854, 3.5818, 3.6117, 3.6030, 3.5988, 3.5752, 3.5849, 3.5544, 3.5544,
         1.2239, 1.1930, 1.1913, 1.1976, 1.2514, 1.1744, 1.1200, 1.2514, 1.1765,
         1.5618, 1.5457, 1.5696, 1.5533, 1.5598, 1.5612, 1.5679, 1.5611, 1.5611,
         1.3501, 1.3619, 1.3518, 1.3684, 1.3512, 1.3772, 1.3715, 1.3609, 1.3518,
         1.5642, 1.5776, 1.5678, 1.5652, 1.5709, 1.5604, 1.5778, 1.5350, 1.5397,
         1.2103, 1.2359, 1.2286, 1.2449, 1.2055, 1.1974, 1.1875, 1.2662, 1.2251],
        [1.2403, 1.0567, 1.0464, 1.0931, 1.0940, 1.1081, 1.1017, 0.9885, 0.9885,
         3.5281, 3.5395, 3.5144, 3.5723, 3.5311, 3.6135, 3.4971, 3.5245, 3.5834,
         1.3449, 1.3285, 1.2994, 1.2956, 1.3207, 1.3310, 1.3617, 1.3317, 1.3317,
         1.1950, 1.1566, 1.1461, 1.2176, 1.1493, 1.2638, 1.2389, 1.2008, 1.1429,
         1.3113, 1.3747, 1.3322, 1.3172, 1.3120, 1.3559, 1.3787, 1.1875, 1.2953,
         0.9121, 1.0519, 1.0191, 1.0801, 0.9054, 0.9102, 0.8232, 1.1575, 1.0063],
        [1.4609, 1.4618, 1.4601, 1.4570, 1.4573, 1.4615, 1.4565, 1.4621, 1.4621,
         1.4581, 1.4573, 1.4580, 1.4578, 1.4582, 1.4364, 1.4577, 1.4571, 1.4532,
         2.2368, 2.2389, 2.2547, 2.2441, 2.2259, 2.2253, 2.2514, 2.2232, 2.2232,
         1.5308, 1.5294, 1.5369, 1.5365, 1.5311, 1.5362, 1.5364, 1.5366, 1.5369,
         1.8013, 1.8014, 1.8014, 1.7983, 1.8013, 1.8012, 1.8014, 1.7752, 1.7794,
         1.4488, 1.4549, 1.4551, 1.4549, 1.4454, 1.4553, 1.4497, 1.4547, 1.4550],
        [1.3228, 1.3249, 1.3106, 1.3017, 1.3238, 1.3213, 1.3234, 1.3261, 1.3261,
         1.3221, 1.3137, 1.3092, 1.3101, 1.3249, 1.3059, 1.3111, 1.3247, 1.2924,
         1.6565, 1.6322, 1.6550, 1.6539, 1.6519, 1.6523, 1.6553, 1.6557, 1.6557,
         3.2299, 3.1554, 3.1157, 3.1536, 3.2019, 3.1446, 3.2299, 3.1279, 3.1095,
         1.6674, 1.6604, 1.6595, 1.6626, 1.6660, 1.6436, 1.6668, 1.6117, 1.6370,
         1.3142, 1.3092, 1.2988, 1.3135, 1.3087, 1.3013, 1.3136, 1.3144, 1.3155],
        [1.4609, 1.4583, 1.4151, 1.4173, 1.4558, 1.4619, 1.4607, 1.4631, 1.4631,
         1.4609, 1.4577, 1.4516, 1.4450, 1.4625, 1.4148, 1.4548, 1.4625, 1.4563,
         1.7808, 1.7687, 1.7696, 1.7780, 1.7971, 1.7955, 1.7727, 1.7975, 1.7975,
         1.4946, 1.5040, 1.5372, 1.5312, 1.5009, 1.5345, 1.5223, 1.5367, 1.5341,
         2.2017, 2.1873, 2.1740, 2.1896, 2.2296, 2.2481, 2.2161, 2.3076, 2.3060,
         1.4394, 1.4291, 1.4444, 1.4572, 1.4430, 1.4546, 1.4207, 1.4493, 1.4575],
        [1.2331, 1.1681, 1.1605, 1.1767, 1.1695, 1.1803, 1.1789, 1.1418, 1.1418,
         1.1239, 1.0677, 1.0644, 1.0760, 1.1777, 1.0305, 0.9449, 1.1777, 1.0452,
         1.4770, 1.4545, 1.4614, 1.4351, 1.4584, 1.4551, 1.4701, 1.4594, 1.4594,
         1.2755, 1.2528, 1.2606, 1.2657, 1.2424, 1.2867, 1.2912, 1.2721, 1.2607,
         1.4643, 1.4590, 1.4694, 1.4581, 1.4532, 1.4518, 1.4930, 1.4081, 1.3747,
         3.6397, 3.5845, 3.5976, 3.5978, 3.5892, 3.5318, 3.6355, 3.5978, 3.5434]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 42 : 1781.873759425994
Test loss for epoch 42 : 198.6496271426604
Test Precision for epoch 42 : 0.26153846153846155
Test Recall for epoch 42 : 0.26153846153846155
Test F1 for epoch 42 : 0.26153846153846155


theta for epoch 43 : tensor([[3.6159, 3.6130, 3.6442, 3.6350, 3.6306, 3.6059, 3.6160, 3.5849, 3.5848,
         1.2204, 1.1898, 1.1881, 1.1943, 1.2478, 1.1711, 1.1175, 1.2478, 1.1734,
         1.5618, 1.5458, 1.5696, 1.5536, 1.5601, 1.5615, 1.5679, 1.5615, 1.5615,
         1.3443, 1.3562, 1.3468, 1.3626, 1.3458, 1.3709, 1.3654, 1.3552, 1.3469,
         1.5754, 1.5887, 1.5791, 1.5765, 1.5821, 1.5715, 1.5888, 1.5460, 1.5507,
         1.2045, 1.2294, 1.2223, 1.2382, 1.1998, 1.1920, 1.1820, 1.2589, 1.2189],
        [1.2586, 1.0792, 1.0693, 1.1149, 1.1156, 1.1294, 1.1232, 1.0123, 1.0123,
         3.5515, 3.5635, 3.5374, 3.5976, 3.5544, 3.6406, 3.5199, 3.5476, 3.6093,
         1.3596, 1.3432, 1.3143, 1.3104, 1.3352, 1.3454, 1.3761, 1.3461, 1.3461,
         1.2155, 1.1775, 1.1664, 1.2378, 1.1702, 1.2838, 1.2591, 1.2210, 1.1633,
         1.3335, 1.3970, 1.3544, 1.3394, 1.3341, 1.3781, 1.4009, 1.2106, 1.3176,
         0.9208, 1.0594, 1.0268, 1.0874, 0.9140, 0.9187, 0.8329, 1.1646, 1.0140],
        [1.4515, 1.4523, 1.4506, 1.4476, 1.4480, 1.4521, 1.4471, 1.4526, 1.4526,
         1.4540, 1.4532, 1.4538, 1.4537, 1.4540, 1.4324, 1.4537, 1.4529, 1.4491,
         2.2404, 2.2424, 2.2584, 2.2485, 2.2300, 2.2293, 2.2557, 2.2273, 2.2273,
         1.5275, 1.5261, 1.5335, 1.5331, 1.5277, 1.5329, 1.5330, 1.5332, 1.5335,
         1.8102, 1.8103, 1.8103, 1.8072, 1.8102, 1.8102, 1.8103, 1.7842, 1.7884,
         1.4403, 1.4463, 1.4464, 1.4462, 1.4369, 1.4467, 1.4413, 1.4460, 1.4464],
        [1.3124, 1.3146, 1.3004, 1.2916, 1.3135, 1.3111, 1.3131, 1.3159, 1.3159,
         1.3168, 1.3086, 1.3041, 1.3049, 1.3193, 1.3008, 1.3068, 1.3191, 1.2873,
         1.6537, 1.6294, 1.6522, 1.6512, 1.6492, 1.6496, 1.6526, 1.6531, 1.6531,
         3.2548, 3.1778, 3.1373, 3.1758, 3.2261, 3.1661, 3.2547, 3.1494, 3.1309,
         1.6760, 1.6688, 1.6680, 1.6712, 1.6745, 1.6519, 1.6753, 1.6199, 1.6454,
         1.3051, 1.2998, 1.2895, 1.3041, 1.2996, 1.2923, 1.3047, 1.3047, 1.3063],
        [1.4518, 1.4492, 1.4067, 1.4089, 1.4467, 1.4527, 1.4515, 1.4537, 1.4537,
         1.4567, 1.4536, 1.4475, 1.4410, 1.4581, 1.4110, 1.4509, 1.4581, 1.4523,
         1.7785, 1.7665, 1.7674, 1.7758, 1.7948, 1.7932, 1.7704, 1.7951, 1.7951,
         1.4921, 1.5015, 1.5340, 1.5282, 1.4983, 1.5314, 1.5195, 1.5335, 1.5309,
         2.2164, 2.2019, 2.1887, 2.2043, 2.2446, 2.2633, 2.2309, 2.3231, 2.3216,
         1.4311, 1.4205, 1.4357, 1.4483, 1.4346, 1.4459, 1.4127, 1.4405, 1.4486],
        [1.2274, 1.1641, 1.1563, 1.1724, 1.1654, 1.1760, 1.1746, 1.1387, 1.1387,
         1.1209, 1.0645, 1.0611, 1.0729, 1.1749, 1.0279, 0.9416, 1.1748, 1.0420,
         1.4789, 1.4563, 1.4622, 1.4369, 1.4604, 1.4570, 1.4720, 1.4614, 1.4614,
         1.2732, 1.2503, 1.2585, 1.2632, 1.2402, 1.2842, 1.2888, 1.2698, 1.2586,
         1.4765, 1.4712, 1.4817, 1.4704, 1.4651, 1.4636, 1.5054, 1.4198, 1.3862,
         3.6786, 3.6208, 3.6346, 3.6346, 3.6262, 3.5667, 3.6745, 3.6343, 3.5783]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 43 : 1781.3676582508813
Test loss for epoch 43 : 198.27918770208362
Test Precision for epoch 43 : 0.26153846153846155
Test Recall for epoch 43 : 0.26153846153846155
Test F1 for epoch 43 : 0.26153846153846155


theta for epoch 44 : tensor([[3.6402, 3.6378, 3.6703, 3.6607, 3.6561, 3.6302, 3.6408, 3.6088, 3.6088,
         1.2198, 1.1897, 1.1879, 1.1940, 1.2468, 1.1708, 1.1186, 1.2468, 1.1734,
         1.5629, 1.5469, 1.5707, 1.5550, 1.5615, 1.5629, 1.5691, 1.5629, 1.5629,
         1.3383, 1.3502, 1.3416, 1.3565, 1.3401, 1.3644, 1.3592, 1.3494, 1.3416,
         1.5813, 1.5945, 1.5850, 1.5823, 1.5879, 1.5773, 1.5945, 1.5516, 1.5563,
         1.2046, 1.2289, 1.2221, 1.2376, 1.2002, 1.1927, 1.1829, 1.2577, 1.2188],
        [1.2820, 1.1086, 1.0991, 1.1431, 1.1438, 1.1571, 1.1512, 1.0436, 1.0436,
         3.5643, 3.5769, 3.5498, 3.6125, 3.5672, 3.6574, 3.5319, 3.5602, 3.6247,
         1.3803, 1.3642, 1.3356, 1.3316, 1.3560, 1.3662, 1.3966, 1.3668, 1.3668,
         1.2438, 1.2064, 1.1950, 1.2656, 1.1992, 1.3109, 1.2867, 1.2490, 1.1919,
         1.3547, 1.4180, 1.3756, 1.3607, 1.3553, 1.3992, 1.4219, 1.2332, 1.3390,
         0.9407, 1.0774, 1.0451, 1.1051, 0.9338, 0.9383, 0.8551, 1.1817, 1.0325],
        [1.4384, 1.4390, 1.4373, 1.4344, 1.4347, 1.4388, 1.4339, 1.4392, 1.4392,
         1.4520, 1.4513, 1.4519, 1.4518, 1.4520, 1.4305, 1.4519, 1.4509, 1.4473,
         2.2438, 2.2459, 2.2619, 2.2525, 2.2338, 2.2331, 2.2598, 2.2311, 2.2311,
         1.5232, 1.5218, 1.5291, 1.5288, 1.5234, 1.5285, 1.5287, 1.5289, 1.5291,
         1.8134, 1.8135, 1.8135, 1.8104, 1.8133, 1.8133, 1.8135, 1.7875, 1.7916,
         1.4374, 1.4431, 1.4433, 1.4431, 1.4339, 1.4436, 1.4384, 1.4428, 1.4433],
        [1.2980, 1.3002, 1.2861, 1.2774, 1.2991, 1.2968, 1.2987, 1.3015, 1.3015,
         1.3137, 1.3058, 1.3013, 1.3020, 1.3160, 1.2981, 1.3046, 1.3158, 1.2844,
         1.6515, 1.6272, 1.6500, 1.6491, 1.6471, 1.6475, 1.6504, 1.6510, 1.6510,
         3.2780, 3.1984, 3.1572, 3.1961, 3.2485, 3.1858, 3.2777, 3.1690, 3.1505,
         1.6788, 1.6715, 1.6707, 1.6740, 1.6773, 1.6545, 1.6780, 1.6223, 1.6479,
         1.3016, 1.2960, 1.2859, 1.3002, 1.2961, 1.2889, 1.3013, 1.3007, 1.3026],
        [1.4390, 1.4362, 1.3943, 1.3964, 1.4338, 1.4396, 1.4384, 1.4404, 1.4404,
         1.4546, 1.4516, 1.4457, 1.4392, 1.4559, 1.4094, 1.4491, 1.4559, 1.4505,
         1.7767, 1.7648, 1.7658, 1.7740, 1.7929, 1.7913, 1.7686, 1.7933, 1.7933,
         1.4885, 1.4980, 1.5299, 1.5242, 1.4946, 1.5274, 1.5156, 1.5295, 1.5268,
         2.2252, 2.2104, 2.1974, 2.2130, 2.2535, 2.2725, 2.2398, 2.3326, 2.3312,
         1.4283, 1.4174, 1.4327, 1.4451, 1.4317, 1.4427, 1.4102, 1.4372, 1.4454],
        [1.2229, 1.1608, 1.1529, 1.1690, 1.1620, 1.1726, 1.1712, 1.1360, 1.1360,
         1.1222, 1.0663, 1.0629, 1.0746, 1.1760, 1.0302, 0.9445, 1.1760, 1.0439,
         1.4838, 1.4613, 1.4659, 1.4418, 1.4654, 1.4619, 1.4769, 1.4663, 1.4663,
         1.2742, 1.2513, 1.2596, 1.2643, 1.2417, 1.2853, 1.2899, 1.2709, 1.2596,
         1.4849, 1.4795, 1.4901, 1.4788, 1.4729, 1.4714, 1.5138, 1.4276, 1.3939,
         3.7136, 3.6533, 3.6677, 3.6674, 3.6593, 3.5976, 3.7096, 3.6669, 3.6092]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 44 : 1781.283201359653
Test loss for epoch 44 : 198.02027087712676
Test Precision for epoch 44 : 0.26153846153846155
Test Recall for epoch 44 : 0.26153846153846155
Test F1 for epoch 44 : 0.26153846153846155


theta for epoch 45 : tensor([[3.6598, 3.6578, 3.6918, 3.6817, 3.6769, 3.6498, 3.6608, 3.6278, 3.6278,
         1.2235, 1.1941, 1.1923, 1.1982, 1.2499, 1.1751, 1.1247, 1.2499, 1.1779,
         1.5657, 1.5497, 1.5735, 1.5581, 1.5645, 1.5660, 1.5719, 1.5659, 1.5659,
         1.3314, 1.3434, 1.3354, 1.3496, 1.3335, 1.3572, 1.3521, 1.3427, 1.3354,
         1.5796, 1.5928, 1.5834, 1.5806, 1.5862, 1.5755, 1.5927, 1.5497, 1.5544,
         1.2100, 1.2335, 1.2269, 1.2419, 1.2058, 1.1985, 1.1889, 1.2613, 1.2238],
        [1.3086, 1.1420, 1.1329, 1.1754, 1.1759, 1.1888, 1.1831, 1.0796, 1.0796,
         3.5745, 3.5877, 3.5596, 3.6248, 3.5775, 3.6716, 3.5412, 3.5701, 3.6374,
         1.4038, 1.3879, 1.3597, 1.3558, 1.3798, 1.3898, 1.4198, 1.3904, 1.3904,
         1.2721, 1.2354, 1.2241, 1.2934, 1.2285, 1.3378, 1.3141, 1.2771, 1.2211,
         1.3696, 1.4326, 1.3904, 1.3756, 1.3702, 1.4139, 1.4363, 1.2498, 1.3541,
         0.9669, 1.1009, 1.0693, 1.1281, 0.9602, 0.9648, 0.8842, 1.2033, 1.0569],
        [1.4272, 1.4276, 1.4260, 1.4231, 1.4235, 1.4275, 1.4226, 1.4277, 1.4277,
         1.4535, 1.4528, 1.4535, 1.4534, 1.4535, 1.4322, 1.4536, 1.4524, 1.4489,
         2.2473, 2.2494, 2.2656, 2.2565, 2.2376, 2.2368, 2.2638, 2.2348, 2.2348,
         1.5166, 1.5152, 1.5225, 1.5222, 1.5168, 1.5220, 1.5221, 1.5223, 1.5225,
         1.8085, 1.8086, 1.8086, 1.8056, 1.8085, 1.8085, 1.8086, 1.7827, 1.7868,
         1.4386, 1.4442, 1.4443, 1.4441, 1.4351, 1.4446, 1.4397, 1.4438, 1.4443],
        [1.2857, 1.2879, 1.2738, 1.2651, 1.2868, 1.2845, 1.2864, 1.2892, 1.2892,
         1.3142, 1.3065, 1.3019, 1.3026, 1.3163, 1.2988, 1.3060, 1.3161, 1.2851,
         1.6502, 1.6258, 1.6487, 1.6479, 1.6458, 1.6463, 1.6491, 1.6498, 1.6498,
         3.2984, 3.2161, 3.1741, 3.2136, 3.2681, 3.2027, 3.2979, 3.1858, 3.1672,
         1.6736, 1.6661, 1.6654, 1.6687, 1.6720, 1.6490, 1.6727, 1.6167, 1.6425,
         1.3023, 1.2965, 1.2864, 1.3006, 1.2969, 1.2897, 1.3021, 1.3009, 1.3032],
        [1.4281, 1.4253, 1.3838, 1.3859, 1.4229, 1.4286, 1.4274, 1.4292, 1.4292,
         1.4560, 1.4531, 1.4472, 1.4409, 1.4572, 1.4113, 1.4507, 1.4572, 1.4521,
         1.7756, 1.7638, 1.7649, 1.7730, 1.7918, 1.7902, 1.7676, 1.7921, 1.7921,
         1.4826, 1.4920, 1.5235, 1.5180, 1.4886, 1.5212, 1.5095, 1.5231, 1.5204,
         2.2257, 2.2108, 2.1978, 2.2135, 2.2543, 2.2736, 2.2404, 2.3340, 2.3327,
         1.4296, 1.4186, 1.4338, 1.4460, 1.4331, 1.4437, 1.4118, 1.4382, 1.4463],
        [1.2363, 1.1748, 1.1671, 1.1830, 1.1762, 1.1866, 1.1853, 1.1502, 1.1502,
         1.1332, 1.0783, 1.0749, 1.0864, 1.1862, 1.0428, 0.9591, 1.1862, 1.0562,
         1.4970, 1.4746, 1.4778, 1.4551, 1.4786, 1.4750, 1.4901, 1.4795, 1.4795,
         1.2869, 1.2640, 1.2719, 1.2770, 1.2550, 1.2981, 1.3026, 1.2835, 1.2719,
         1.4905, 1.4853, 1.4958, 1.4845, 1.4781, 1.4766, 1.5196, 1.4329, 1.3994,
         3.7291, 3.6659, 3.6810, 3.6806, 3.6724, 3.6082, 3.7249, 3.6798, 3.6201]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 45 : 1780.9191889685746
Test loss for epoch 45 : 197.45887176634218
Test Precision for epoch 45 : 0.26153846153846155
Test Recall for epoch 45 : 0.26153846153846155
Test F1 for epoch 45 : 0.26153846153846155


theta for epoch 46 : tensor([[3.6728, 3.6712, 3.7067, 3.6960, 3.6911, 3.6627, 3.6742, 3.6401, 3.6400,
         1.2314, 1.2029, 1.2012, 1.2068, 1.2573, 1.1839, 1.1356, 1.2573, 1.1870,
         1.5692, 1.5534, 1.5770, 1.5619, 1.5683, 1.5698, 1.5755, 1.5697, 1.5697,
         1.3226, 1.3346, 1.3270, 1.3407, 1.3249, 1.3480, 1.3430, 1.3339, 1.3270,
         1.5744, 1.5875, 1.5782, 1.5754, 1.5810, 1.5702, 1.5873, 1.5444, 1.5490,
         1.2191, 1.2416, 1.2354, 1.2497, 1.2151, 1.2083, 1.1988, 1.2683, 1.2325],
        [1.3369, 1.1781, 1.1692, 1.2101, 1.2105, 1.2230, 1.2175, 1.1187, 1.1187,
         3.5824, 3.5962, 3.5670, 3.6348, 3.5854, 3.6835, 3.5481, 3.5777, 3.6480,
         1.4284, 1.4129, 1.3851, 1.3813, 1.4049, 1.4147, 1.4442, 1.4153, 1.4153,
         1.2980, 1.2622, 1.2513, 1.3187, 1.2555, 1.3618, 1.3388, 1.3028, 1.2484,
         1.3817, 1.4440, 1.4024, 1.3877, 1.3823, 1.4255, 1.4476, 1.2636, 1.3664,
         0.9976, 1.1279, 1.0973, 1.1545, 0.9912, 0.9962, 0.9179, 1.2276, 1.0853],
        [1.4178, 1.4181, 1.4165, 1.4137, 1.4141, 1.4180, 1.4133, 1.4182, 1.4182,
         1.4582, 1.4576, 1.4582, 1.4581, 1.4581, 1.4370, 1.4584, 1.4571, 1.4537,
         2.2500, 2.2521, 2.2684, 2.2596, 2.2404, 2.2396, 2.2668, 2.2376, 2.2376,
         1.5060, 1.5047, 1.5118, 1.5116, 1.5062, 1.5114, 1.5115, 1.5116, 1.5118,
         1.7994, 1.7994, 1.7995, 1.7964, 1.7994, 1.7993, 1.7994, 1.7737, 1.7777,
         1.4423, 1.4477, 1.4479, 1.4476, 1.4388, 1.4482, 1.4434, 1.4474, 1.4479],
        [1.2754, 1.2775, 1.2634, 1.2549, 1.2764, 1.2742, 1.2761, 1.2787, 1.2787,
         1.3179, 1.3104, 1.3059, 1.3065, 1.3198, 1.3029, 1.3107, 1.3196, 1.2891,
         1.6486, 1.6242, 1.6470, 1.6464, 1.6443, 1.6447, 1.6475, 1.6483, 1.6483,
         3.3146, 3.2294, 3.1866, 3.2267, 3.2834, 3.2151, 3.3138, 3.1981, 3.1795,
         1.6641, 1.6565, 1.6559, 1.6592, 1.6625, 1.6393, 1.6631, 1.6069, 1.6327,
         1.3055, 1.2996, 1.2896, 1.3036, 1.3001, 1.2931, 1.3055, 1.3037, 1.3064],
        [1.4190, 1.4161, 1.3751, 1.3772, 1.4138, 1.4194, 1.4182, 1.4199, 1.4199,
         1.4606, 1.4578, 1.4520, 1.4458, 1.4616, 1.4165, 1.4556, 1.4616, 1.4569,
         1.7742, 1.7625, 1.7637, 1.7717, 1.7904, 1.7888, 1.7662, 1.7906, 1.7906,
         1.4725, 1.4819, 1.5131, 1.5078, 1.4785, 1.5109, 1.4993, 1.5128, 1.5101,
         2.2218, 2.2065, 2.1937, 2.2094, 2.2506, 2.2701, 2.2365, 2.3308, 2.3296,
         1.4335, 1.4223, 1.4375, 1.4494, 1.4369, 1.4472, 1.4160, 1.4417, 1.4497],
        [1.2667, 1.2053, 1.1979, 1.2136, 1.2070, 1.2172, 1.2159, 1.1803, 1.1803,
         1.1537, 1.1004, 1.0971, 1.1081, 1.2059, 1.0654, 0.9849, 1.2059, 1.0788,
         1.5175, 1.4954, 1.4971, 1.4759, 1.4992, 1.4955, 1.5107, 1.5001, 1.5001,
         1.3096, 1.2870, 1.2942, 1.3000, 1.2789, 1.3213, 1.3255, 1.3063, 1.2942,
         1.4978, 1.4928, 1.5030, 1.4918, 1.4849, 1.4835, 1.5268, 1.4400, 1.4068,
         3.7233, 3.6571, 3.6729, 3.6724, 3.6641, 3.5970, 3.7190, 3.6716, 3.6093]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 46 : 1780.9140929558316
Test loss for epoch 46 : 196.43439847801787
Test Precision for epoch 46 : 0.26153846153846155
Test Recall for epoch 46 : 0.26153846153846155
Test F1 for epoch 46 : 0.26153846153846155


theta for epoch 47 : tensor([[3.6822, 3.6809, 3.7181, 3.7068, 3.7016, 3.6719, 3.6839, 3.6486, 3.6485,
         1.2414, 1.2136, 1.2120, 1.2174, 1.2669, 1.1947, 1.1484, 1.2669, 1.1981,
         1.5709, 1.5551, 1.5787, 1.5638, 1.5701, 1.5716, 1.5771, 1.5715, 1.5715,
         1.3110, 1.3230, 1.3155, 1.3291, 1.3134, 1.3364, 1.3314, 1.3223, 1.3155,
         1.5698, 1.5829, 1.5737, 1.5708, 1.5765, 1.5656, 1.5827, 1.5397, 1.5444,
         1.2297, 1.2516, 1.2456, 1.2595, 1.2260, 1.2194, 1.2101, 1.2774, 1.2428],
        [1.3535, 1.2019, 1.1930, 1.2327, 1.2330, 1.2451, 1.2398, 1.1455, 1.1455,
         3.5973, 3.6117, 3.5815, 3.6518, 3.6002, 3.7023, 3.5622, 3.5923, 3.6654,
         1.4474, 1.4322, 1.4046, 1.4012, 1.4244, 1.4341, 1.4629, 1.4346, 1.4346,
         1.3135, 1.2784, 1.2682, 1.3336, 1.2721, 1.3754, 1.3532, 1.3182, 1.2653,
         1.3916, 1.4534, 1.4122, 1.3976, 1.3921, 1.4350, 1.4567, 1.2751, 1.3765,
         1.0256, 1.1528, 1.1230, 1.1786, 1.0196, 1.0251, 0.9488, 1.2498, 1.1115],
        [1.4065, 1.4067, 1.4051, 1.4023, 1.4027, 1.4066, 1.4019, 1.4067, 1.4067,
         1.4646, 1.4641, 1.4647, 1.4646, 1.4645, 1.4436, 1.4649, 1.4635, 1.4603,
         2.2503, 2.2524, 2.2687, 2.2602, 2.2408, 2.2399, 2.2674, 2.2380, 2.2380,
         1.4926, 1.4912, 1.4983, 1.4981, 1.4927, 1.4980, 1.4981, 1.4982, 1.4983,
         1.7909, 1.7910, 1.7910, 1.7880, 1.7909, 1.7908, 1.7909, 1.7653, 1.7693,
         1.4478, 1.4531, 1.4533, 1.4530, 1.4444, 1.4536, 1.4490, 1.4528, 1.4532],
        [1.2632, 1.2651, 1.2510, 1.2426, 1.2640, 1.2619, 1.2637, 1.2663, 1.2663,
         1.3235, 1.3162, 1.3117, 1.3122, 1.3251, 1.3087, 1.3171, 1.3250, 1.2950,
         1.6451, 1.6207, 1.6435, 1.6429, 1.6409, 1.6413, 1.6440, 1.6449, 1.6449,
         3.3272, 3.2392, 3.1954, 3.2361, 3.2951, 3.2239, 3.3262, 3.2069, 3.1881,
         1.6553, 1.6476, 1.6470, 1.6504, 1.6536, 1.6302, 1.6542, 1.5977, 1.6237,
         1.3107, 1.3045, 1.2947, 1.3086, 1.3053, 1.2984, 1.3107, 1.3084, 1.3114],
        [1.4081, 1.4050, 1.3644, 1.3665, 1.4028, 1.4083, 1.4071, 1.4086, 1.4086,
         1.4669, 1.4642, 1.4585, 1.4524, 1.4679, 1.4233, 1.4621, 1.4678, 1.4634,
         1.7709, 1.7593, 1.7605, 1.7685, 1.7870, 1.7854, 1.7630, 1.7872, 1.7872,
         1.4594, 1.4688, 1.4998, 1.4947, 1.4654, 1.4979, 1.4863, 1.4996, 1.4969,
         2.2180, 2.2026, 2.1899, 2.2057, 2.2471, 2.2668, 2.2328, 2.3279, 2.3268,
         1.4392, 1.4279, 1.4430, 1.4547, 1.4426, 1.4526, 1.4220, 1.4471, 1.4550],
        [1.2907, 1.2282, 1.2212, 1.2368, 1.2305, 1.2404, 1.2391, 1.2021, 1.2021,
         1.1749, 1.1230, 1.1197, 1.1304, 1.2263, 1.0884, 1.0110, 1.2263, 1.1019,
         1.5343, 1.5123, 1.5124, 1.4928, 1.5159, 1.5122, 1.5274, 1.5167, 1.5167,
         1.3255, 1.3029, 1.3091, 1.3162, 1.2958, 1.3378, 1.3415, 1.3220, 1.3092,
         1.5043, 1.4996, 1.5095, 1.4984, 1.4908, 1.4896, 1.5335, 1.4463, 1.4133,
         3.7221, 3.6530, 3.6695, 3.6689, 3.6604, 3.5906, 3.7177, 3.6680, 3.6033]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 47 : 1780.9651778205696
Test loss for epoch 47 : 195.93359174658278
Test Precision for epoch 47 : 0.26153846153846155
Test Recall for epoch 47 : 0.26153846153846155
Test F1 for epoch 47 : 0.26153846153846155


theta for epoch 48 : tensor([[3.6889, 3.6878, 3.7267, 3.7149, 3.7095, 3.6783, 3.6909, 3.6543, 3.6543,
         1.2499, 1.2228, 1.2213, 1.2264, 1.2750, 1.2038, 1.1593, 1.2750, 1.2075,
         1.5704, 1.5547, 1.5783, 1.5634, 1.5697, 1.5712, 1.5767, 1.5711, 1.5711,
         1.3034, 1.3153, 1.3076, 1.3215, 1.3056, 1.3289, 1.3239, 1.3147, 1.3076,
         1.5687, 1.5819, 1.5727, 1.5697, 1.5754, 1.5645, 1.5817, 1.5385, 1.5432,
         1.2394, 1.2608, 1.2550, 1.2686, 1.2358, 1.2294, 1.2202, 1.2862, 1.2523],
        [1.3613, 1.2160, 1.2070, 1.2457, 1.2460, 1.2579, 1.2527, 1.1622, 1.1622,
         3.6165, 3.6315, 3.6003, 3.6730, 3.6194, 3.7254, 3.5807, 3.6112, 3.6872,
         1.4607, 1.4458, 1.4184, 1.4155, 1.4383, 1.4479, 1.4760, 1.4484, 1.4484,
         1.3246, 1.2902, 1.2808, 1.3442, 1.2842, 1.3848, 1.3633, 1.3293, 1.2779,
         1.4023, 1.4635, 1.4228, 1.4083, 1.4026, 1.4452, 1.4666, 1.2870, 1.3873,
         1.0492, 1.1734, 1.1444, 1.1985, 1.0435, 1.0494, 0.9749, 1.2678, 1.1332],
        [1.3958, 1.3958, 1.3942, 1.3915, 1.3919, 1.3958, 1.3911, 1.3958, 1.3958,
         1.4692, 1.4687, 1.4693, 1.4693, 1.4691, 1.4484, 1.4697, 1.4681, 1.4650,
         2.2481, 2.2502, 2.2666, 2.2583, 2.2387, 2.2378, 2.2656, 2.2359, 2.2359,
         1.4826, 1.4812, 1.4883, 1.4881, 1.4827, 1.4880, 1.4881, 1.4882, 1.4883,
         1.7858, 1.7859, 1.7859, 1.7829, 1.7858, 1.7858, 1.7858, 1.7603, 1.7642,
         1.4527, 1.4579, 1.4581, 1.4578, 1.4493, 1.4584, 1.4540, 1.4575, 1.4580],
        [1.2517, 1.2534, 1.2393, 1.2309, 1.2523, 1.2502, 1.2520, 1.2544, 1.2544,
         1.3274, 1.3203, 1.3158, 1.3162, 1.3288, 1.3129, 1.3218, 1.3286, 1.2991,
         1.6395, 1.6151, 1.6379, 1.6374, 1.6354, 1.6358, 1.6384, 1.6394, 1.6394,
         3.3410, 3.2500, 3.2053, 3.2467, 3.3080, 3.2338, 3.3396, 3.2166, 3.1977,
         1.6500, 1.6422, 1.6417, 1.6451, 1.6483, 1.6247, 1.6488, 1.5921, 1.6182,
         1.3153, 1.3090, 1.2992, 1.3129, 1.3099, 1.3030, 1.3154, 1.3127, 1.3159],
        [1.3977, 1.3944, 1.3540, 1.3562, 1.3922, 1.3977, 1.3965, 1.3979, 1.3979,
         1.4714, 1.4688, 1.4632, 1.4572, 1.4723, 1.4284, 1.4668, 1.4723, 1.4681,
         1.7655, 1.7540, 1.7552, 1.7631, 1.7815, 1.7799, 1.7576, 1.7817, 1.7817,
         1.4498, 1.4590, 1.4900, 1.4851, 1.4557, 1.4883, 1.4767, 1.4899, 1.4871,
         2.2172, 2.2016, 2.1890, 2.2048, 2.2465, 2.2664, 2.2321, 2.3279, 2.3268,
         1.4443, 1.4329, 1.4479, 1.4594, 1.4476, 1.4574, 1.4273, 1.4519, 1.4597],
        [1.3101, 1.2454, 1.2390, 1.2546, 1.2484, 1.2581, 1.2568, 1.2177, 1.2177,
         1.1932, 1.1425, 1.1394, 1.1497, 1.2439, 1.1083, 1.0338, 1.2439, 1.1220,
         1.5469, 1.5250, 1.5236, 1.5054, 1.5283, 1.5246, 1.5401, 1.5292, 1.5292,
         1.3404, 1.3178, 1.3230, 1.3313, 1.3116, 1.3534, 1.3568, 1.3368, 1.3230,
         1.5129, 1.5085, 1.5181, 1.5071, 1.4988, 1.4977, 1.5423, 1.4544, 1.4218,
         3.7242, 3.6521, 3.6693, 3.6686, 3.6600, 3.5874, 3.7197, 3.6676, 3.6005]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 48 : 1781.3571409233348
Test loss for epoch 48 : 195.63140690297263
Test Precision for epoch 48 : 0.26153846153846155
Test Recall for epoch 48 : 0.26153846153846155
Test F1 for epoch 48 : 0.26153846153846155


theta for epoch 49 : tensor([[3.6959, 3.6952, 3.7358, 3.7233, 3.7178, 3.6852, 3.6983, 3.6604, 3.6604,
         1.2530, 1.2264, 1.2249, 1.2298, 1.2777, 1.2074, 1.1643, 1.2777, 1.2112,
         1.5702, 1.5544, 1.5781, 1.5631, 1.5693, 1.5708, 1.5764, 1.5708, 1.5708,
         1.3033, 1.3151, 1.3069, 1.3215, 1.3053, 1.3293, 1.3241, 1.3145, 1.3069,
         1.5720, 1.5854, 1.5761, 1.5731, 1.5788, 1.5680, 1.5852, 1.5418, 1.5464,
         1.2460, 1.2673, 1.2615, 1.2750, 1.2424, 1.2360, 1.2270, 1.2925, 1.2589],
        [1.3664, 1.2262, 1.2171, 1.2552, 1.2554, 1.2671, 1.2619, 1.1747, 1.1747,
         3.6371, 3.6528, 3.6206, 3.6957, 3.6400, 3.7499, 3.6006, 3.6315, 3.7104,
         1.4706, 1.4561, 1.4287, 1.4263, 1.4488, 1.4583, 1.4859, 1.4588, 1.4588,
         1.3349, 1.3009, 1.2925, 1.3540, 1.2953, 1.3934, 1.3726, 1.3396, 1.2897,
         1.4147, 1.4754, 1.4352, 1.4208, 1.4150, 1.4572, 1.4783, 1.3005, 1.3999,
         1.0664, 1.1878, 1.1597, 1.2124, 1.0611, 1.0674, 0.9944, 1.2799, 1.1488],
        [1.3914, 1.3913, 1.3897, 1.3871, 1.3874, 1.3913, 1.3867, 1.3912, 1.3912,
         1.4681, 1.4677, 1.4682, 1.4682, 1.4679, 1.4474, 1.4686, 1.4670, 1.4640,
         2.2454, 2.2475, 2.2641, 2.2559, 2.2361, 2.2351, 2.2632, 2.2333, 2.2333,
         1.4795, 1.4781, 1.4852, 1.4851, 1.4796, 1.4850, 1.4850, 1.4851, 1.4852,
         1.7851, 1.7851, 1.7852, 1.7821, 1.7851, 1.7850, 1.7851, 1.7597, 1.7635,
         1.4548, 1.4598, 1.4600, 1.4597, 1.4514, 1.4603, 1.4561, 1.4594, 1.4599],
        [1.2469, 1.2483, 1.2342, 1.2260, 1.2473, 1.2453, 1.2470, 1.2492, 1.2492,
         1.3256, 1.3187, 1.3143, 1.3146, 1.3269, 1.3114, 1.3208, 1.3267, 1.2976,
         1.6342, 1.6097, 1.6325, 1.6321, 1.6301, 1.6305, 1.6330, 1.6341, 1.6341,
         3.3582, 3.2644, 3.2189, 3.2608, 3.3243, 3.2473, 3.3566, 3.2300, 3.2111,
         1.6491, 1.6412, 1.6408, 1.6442, 1.6474, 1.6237, 1.6478, 1.5909, 1.6171,
         1.3170, 1.3106, 1.3009, 1.3145, 1.3117, 1.3049, 1.3172, 1.3141, 1.3176],
        [1.3936, 1.3902, 1.3500, 1.3523, 1.3881, 1.3935, 1.3923, 1.3935, 1.3935,
         1.4702, 1.4677, 1.4622, 1.4562, 1.4710, 1.4276, 1.4658, 1.4710, 1.4671,
         1.7601, 1.7488, 1.7500, 1.7578, 1.7761, 1.7745, 1.7523, 1.7763, 1.7763,
         1.4471, 1.4561, 1.4872, 1.4823, 1.4530, 1.4856, 1.4740, 1.4871, 1.4843,
         2.2203, 2.2044, 2.1919, 2.2077, 2.2498, 2.2698, 2.2351, 2.3317, 2.3306,
         1.4465, 1.4351, 1.4500, 1.4613, 1.4498, 1.4593, 1.4297, 1.4539, 1.4616],
        [1.3302, 1.2626, 1.2567, 1.2723, 1.2664, 1.2758, 1.2746, 1.2328, 1.2328,
         1.2046, 1.1552, 1.1522, 1.1621, 1.2546, 1.1211, 1.0496, 1.2546, 1.1351,
         1.5576, 1.5358, 1.5328, 1.5161, 1.5389, 1.5351, 1.5508, 1.5397, 1.5397,
         1.3576, 1.3349, 1.3391, 1.3488, 1.3298, 1.3714, 1.3744, 1.3538, 1.3391,
         1.5245, 1.5203, 1.5297, 1.5187, 1.5096, 1.5087, 1.5541, 1.4655, 1.4331,
         3.7280, 3.6528, 3.6707, 3.6699, 3.6613, 3.5860, 3.7233, 3.6688, 3.5993]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 49 : 1781.2663251066333
Test loss for epoch 49 : 195.3742920537253
Test Precision for epoch 49 : 0.26153846153846155
Test Recall for epoch 49 : 0.26153846153846155
Test F1 for epoch 49 : 0.26153846153846155


theta for epoch 50 : tensor([[3.7040, 3.7037, 3.7459, 3.7328, 3.7271, 3.6931, 3.7067, 3.6676, 3.6676,
         1.2500, 1.2239, 1.2224, 1.2272, 1.2746, 1.2047, 1.1627, 1.2746, 1.2088,
         1.5723, 1.5566, 1.5803, 1.5650, 1.5713, 1.5728, 1.5785, 1.5727, 1.5727,
         1.3085, 1.3201, 1.3110, 1.3268, 1.3100, 1.3352, 1.3296, 1.3195, 1.3110,
         1.5793, 1.5929, 1.5834, 1.5803, 1.5862, 1.5754, 1.5927, 1.5490, 1.5537,
         1.2494, 1.2708, 1.2650, 1.2785, 1.2458, 1.2394, 1.2304, 1.2961, 1.2623],
        [1.3702, 1.2338, 1.2245, 1.2623, 1.2625, 1.2741, 1.2689, 1.1840, 1.1840,
         3.6586, 3.6749, 3.6416, 3.7192, 3.6613, 3.7751, 3.6215, 3.6525, 3.7343,
         1.4794, 1.4652, 1.4378, 1.4360, 1.4582, 1.4677, 1.4946, 1.4681, 1.4681,
         1.3427, 1.3090, 1.3017, 1.3614, 1.3038, 1.3998, 1.3796, 1.3474, 1.2989,
         1.4286, 1.4888, 1.4491, 1.4347, 1.4288, 1.4707, 1.4915, 1.3152, 1.4139,
         1.0775, 1.1964, 1.1690, 1.2204, 1.0725, 1.0792, 1.0074, 1.2863, 1.1585],
        [1.3943, 1.3940, 1.3925, 1.3899, 1.3903, 1.3941, 1.3896, 1.3940, 1.3940,
         1.4609, 1.4605, 1.4610, 1.4610, 1.4607, 1.4403, 1.4615, 1.4597, 1.4569,
         2.2445, 2.2465, 2.2632, 2.2549, 2.2350, 2.2339, 2.2622, 2.2321, 2.2321,
         1.4811, 1.4798, 1.4868, 1.4867, 1.4812, 1.4867, 1.4867, 1.4867, 1.4868,
         1.7883, 1.7883, 1.7883, 1.7853, 1.7882, 1.7882, 1.7882, 1.7630, 1.7668,
         1.4539, 1.4588, 1.4590, 1.4587, 1.4505, 1.4593, 1.4552, 1.4584, 1.4589],
        [1.2497, 1.2509, 1.2368, 1.2286, 1.2499, 1.2479, 1.2496, 1.2516, 1.2516,
         1.3178, 1.3111, 1.3066, 1.3069, 1.3189, 1.3038, 1.3137, 1.3187, 1.2900,
         1.6312, 1.6068, 1.6296, 1.6292, 1.6272, 1.6276, 1.6301, 1.6312, 1.6312,
         3.3773, 3.2807, 3.2343, 3.2768, 3.3426, 3.2626, 3.3754, 3.2453, 3.2263,
         1.6523, 1.6443, 1.6439, 1.6473, 1.6505, 1.6267, 1.6509, 1.5938, 1.6201,
         1.3158, 1.3093, 1.2997, 1.3132, 1.3106, 1.3038, 1.3161, 1.3127, 1.3164],
        [1.3968, 1.3932, 1.3532, 1.3556, 1.3911, 1.3965, 1.3953, 1.3965, 1.3965,
         1.4629, 1.4605, 1.4550, 1.4491, 1.4636, 1.4207, 1.4587, 1.4636, 1.4599,
         1.7571, 1.7459, 1.7471, 1.7548, 1.7730, 1.7714, 1.7494, 1.7732, 1.7732,
         1.4491, 1.4578, 1.4891, 1.4843, 1.4549, 1.4876, 1.4760, 1.4891, 1.4862,
         2.2268, 2.2106, 2.1982, 2.2142, 2.2565, 2.2766, 2.2416, 2.3389, 2.3378,
         1.4457, 1.4343, 1.4491, 1.4603, 1.4490, 1.4583, 1.4291, 1.4529, 1.4606],
        [1.3515, 1.2808, 1.2753, 1.2911, 1.2853, 1.2946, 1.2934, 1.2487, 1.2487,
         1.2087, 1.1605, 1.1576, 1.1672, 1.2581, 1.1266, 1.0579, 1.2581, 1.1408,
         1.5686, 1.5469, 1.5423, 1.5272, 1.5497, 1.5459, 1.5618, 1.5505, 1.5505,
         1.3749, 1.3521, 1.3553, 1.3662, 1.3480, 1.3894, 1.3921, 1.3710, 1.3553,
         1.5387, 1.5348, 1.5439, 1.5330, 1.5230, 1.5223, 1.5685, 1.4791, 1.4470,
         3.7332, 3.6549, 3.6736, 3.6727, 3.6640, 3.5860, 3.7285, 3.6714, 3.5997]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 50 : 1780.5124419478384
Test loss for epoch 50 : 195.1806387149671
Test Precision for epoch 50 : 0.26153846153846155
Test Recall for epoch 50 : 0.26153846153846155
Test F1 for epoch 50 : 0.26153846153846155


theta for epoch 51 : tensor([[3.7108, 3.7109, 3.7547, 3.7411, 3.7352, 3.6997, 3.7139, 3.6736, 3.6735,
         1.2446, 1.2187, 1.2172, 1.2220, 1.2691, 1.1995, 1.1582, 1.2692, 1.2037,
         1.5776, 1.5618, 1.5856, 1.5700, 1.5762, 1.5778, 1.5837, 1.5777, 1.5777,
         1.3125, 1.3239, 1.3136, 1.3309, 1.3134, 1.3401, 1.3341, 1.3233, 1.3136,
         1.5887, 1.6026, 1.5929, 1.5898, 1.5958, 1.5850, 1.6025, 1.5584, 1.5631,
         1.2516, 1.2733, 1.2673, 1.2811, 1.2479, 1.2414, 1.2325, 1.2989, 1.2646],
        [1.3691, 1.2350, 1.2256, 1.2633, 1.2635, 1.2751, 1.2699, 1.1863, 1.1863,
         3.6824, 3.6994, 3.6652, 3.7451, 3.6851, 3.8029, 3.6448, 3.6760, 3.7608,
         1.4880, 1.4742, 1.4466, 1.4453, 1.4674, 1.4769, 1.5033, 1.4772, 1.4772,
         1.3431, 1.3096, 1.3034, 1.3615, 1.3047, 1.3990, 1.3793, 1.3479, 1.3005,
         1.4425, 1.5022, 1.4629, 1.4486, 1.4425, 1.4842, 1.5047, 1.3296, 1.4278,
         1.0844, 1.2012, 1.1744, 1.2246, 1.0797, 1.0869, 1.0160, 1.2890, 1.1642],
        [1.3997, 1.3995, 1.3980, 1.3954, 1.3957, 1.3996, 1.3951, 1.3994, 1.3994,
         1.4510, 1.4507, 1.4512, 1.4512, 1.4509, 1.4306, 1.4517, 1.4499, 1.4472,
         2.2459, 2.2480, 2.2647, 2.2561, 2.2360, 2.2349, 2.2634, 2.2331, 2.2331,
         1.4815, 1.4801, 1.4871, 1.4871, 1.4815, 1.4871, 1.4871, 1.4871, 1.4871,
         1.7937, 1.7937, 1.7937, 1.7907, 1.7936, 1.7936, 1.7936, 1.7685, 1.7722,
         1.4519, 1.4568, 1.4569, 1.4567, 1.4485, 1.4573, 1.4533, 1.4564, 1.4569],
        [1.2554, 1.2563, 1.2421, 1.2341, 1.2553, 1.2534, 1.2550, 1.2569, 1.2568,
         1.3076, 1.3009, 1.2966, 1.2967, 1.3085, 1.2937, 1.3040, 1.3083, 1.2799,
         1.6315, 1.6070, 1.6298, 1.6296, 1.6276, 1.6279, 1.6304, 1.6316, 1.6316,
         3.3938, 3.2943, 3.2471, 3.2901, 3.3583, 3.2752, 3.3915, 3.2579, 3.2389,
         1.6577, 1.6497, 1.6493, 1.6527, 1.6559, 1.6320, 1.6563, 1.5990, 1.6253,
         1.3137, 1.3071, 1.2976, 1.3110, 1.3085, 1.3017, 1.3140, 1.3104, 1.3143],
        [1.4025, 1.3988, 1.3589, 1.3615, 1.3968, 1.4022, 1.4009, 1.4021, 1.4021,
         1.4531, 1.4506, 1.4453, 1.4394, 1.4537, 1.4112, 1.4489, 1.4537, 1.4501,
         1.7571, 1.7461, 1.7472, 1.7549, 1.7730, 1.7714, 1.7495, 1.7731, 1.7731,
         1.4497, 1.4580, 1.4897, 1.4849, 1.4555, 1.4882, 1.4767, 1.4897, 1.4868,
         2.2351, 2.2186, 2.2064, 2.2224, 2.2650, 2.2851, 2.2499, 2.3479, 2.3469,
         1.4438, 1.4325, 1.4472, 1.4582, 1.4471, 1.4563, 1.4274, 1.4510, 1.4585],
        [1.3696, 1.2956, 1.2907, 1.3067, 1.3009, 1.3101, 1.3090, 1.2612, 1.2612,
         1.2091, 1.1620, 1.1592, 1.1684, 1.2577, 1.1281, 1.0623, 1.2577, 1.1428,
         1.5807, 1.5592, 1.5528, 1.5393, 1.5617, 1.5579, 1.5739, 1.5625, 1.5625,
         1.3862, 1.3632, 1.3656, 1.3776, 1.3603, 1.4012, 1.4037, 1.3821, 1.3656,
         1.5539, 1.5502, 1.5590, 1.5482, 1.5373, 1.5367, 1.5838, 1.4936, 1.4616,
         3.7409, 3.6596, 3.6789, 3.6778, 3.6693, 3.5885, 3.7361, 3.6764, 3.6024]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 51 : 1779.8688829295293
Test loss for epoch 51 : 195.18291658416226
Test Precision for epoch 51 : 0.26153846153846155
Test Recall for epoch 51 : 0.26153846153846155
Test F1 for epoch 51 : 0.26153846153846155


theta for epoch 52 : tensor([[3.7093, 3.7097, 3.7553, 3.7410, 3.7350, 3.6980, 3.7127, 3.6709, 3.6709,
         1.2412, 1.2157, 1.2142, 1.2188, 1.2654, 1.1964, 1.1562, 1.2654, 1.2009,
         1.5862, 1.5703, 1.5943, 1.5781, 1.5844, 1.5859, 1.5922, 1.5859, 1.5859,
         1.3152, 1.3263, 1.3146, 1.3337, 1.3154, 1.3438, 1.3374, 1.3257, 1.3146,
         1.5981, 1.6123, 1.6023, 1.5992, 1.6053, 1.5947, 1.6123, 1.5679, 1.5725,
         1.2556, 1.2778, 1.2716, 1.2857, 1.2518, 1.2451, 1.2362, 1.3039, 1.2688],
        [1.3716, 1.2397, 1.2301, 1.2678, 1.2680, 1.2795, 1.2743, 1.1917, 1.1917,
         3.6963, 3.7139, 3.6786, 3.7610, 3.6989, 3.8207, 3.6579, 3.6895, 3.7773,
         1.5026, 1.4891, 1.4616, 1.4609, 1.4827, 1.4920, 1.5178, 1.4924, 1.4924,
         1.3463, 1.3131, 1.3079, 1.3643, 1.3085, 1.4009, 1.3817, 1.3512, 1.3050,
         1.4590, 1.5181, 1.4794, 1.4651, 1.4589, 1.5002, 1.5204, 1.3470, 1.4445,
         1.0964, 1.2108, 1.1847, 1.2336, 1.0919, 1.0995, 1.0297, 1.2964, 1.1748],
        [1.4030, 1.4027, 1.4012, 1.3987, 1.3990, 1.4028, 1.3984, 1.4026, 1.4026,
         1.4423, 1.4420, 1.4425, 1.4425, 1.4421, 1.4220, 1.4431, 1.4412, 1.4385,
         2.2490, 2.2511, 2.2679, 2.2589, 2.2386, 2.2374, 2.2662, 2.2357, 2.2357,
         1.4787, 1.4773, 1.4843, 1.4843, 1.4787, 1.4843, 1.4843, 1.4843, 1.4843,
         1.7985, 1.7984, 1.7985, 1.7955, 1.7984, 1.7984, 1.7984, 1.7734, 1.7771,
         1.4509, 1.4557, 1.4559, 1.4556, 1.4475, 1.4562, 1.4523, 1.4553, 1.4558],
        [1.2592, 1.2597, 1.2454, 1.2374, 1.2587, 1.2568, 1.2584, 1.2600, 1.2600,
         1.2985, 1.2921, 1.2877, 1.2878, 1.2993, 1.2848, 1.2956, 1.2991, 1.2710,
         1.6344, 1.6098, 1.6326, 1.6324, 1.6304, 1.6308, 1.6332, 1.6344, 1.6344,
         3.4062, 3.3036, 3.2555, 3.2992, 3.3697, 3.2836, 3.4035, 3.2662, 3.2471,
         1.6626, 1.6546, 1.6541, 1.6576, 1.6607, 1.6367, 1.6611, 1.6036, 1.6301,
         1.3127, 1.3060, 1.2965, 1.3099, 1.3075, 1.3008, 1.3130, 1.3092, 1.3132],
        [1.4060, 1.4022, 1.3622, 1.3651, 1.4003, 1.4057, 1.4044, 1.4055, 1.4055,
         1.4443, 1.4419, 1.4367, 1.4309, 1.4449, 1.4028, 1.4403, 1.4449, 1.4414,
         1.7595, 1.7486, 1.7496, 1.7573, 1.7753, 1.7737, 1.7520, 1.7754, 1.7754,
         1.4470, 1.4550, 1.4871, 1.4824, 1.4528, 1.4858, 1.4742, 1.4871, 1.4842,
         2.2424, 2.2258, 2.2136, 2.2297, 2.2725, 2.2927, 2.2572, 2.3560, 2.3549,
         1.4429, 1.4317, 1.4463, 1.4572, 1.4462, 1.4552, 1.4266, 1.4500, 1.4574],
        [1.3813, 1.3043, 1.2998, 1.3159, 1.3103, 1.3193, 1.3182, 1.2678, 1.2678,
         1.2098, 1.1642, 1.1614, 1.1702, 1.2575, 1.1302, 1.0680, 1.2574, 1.1454,
         1.5940, 1.5726, 1.5645, 1.5527, 1.5749, 1.5711, 1.5872, 1.5758, 1.5758,
         1.3911, 1.3679, 1.3697, 1.3825, 1.3662, 1.4065, 1.4088, 1.3868, 1.3697,
         1.5677, 1.5641, 1.5728, 1.5621, 1.5502, 1.5497, 1.5977, 1.5067, 1.4749,
         3.7499, 3.6656, 3.6857, 3.6845, 3.6759, 3.5925, 3.7451, 3.6828, 3.6067]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 52 : 1779.9193083733178
Test loss for epoch 52 : 194.94995620706283
Test Precision for epoch 52 : 0.26153846153846155
Test Recall for epoch 52 : 0.26153846153846155
Test F1 for epoch 52 : 0.26153846153846155


theta for epoch 53 : tensor([[3.7006, 3.7011, 3.7486, 3.7336, 3.7275, 3.6888, 3.7041, 3.6607, 3.6607,
         1.2424, 1.2175, 1.2161, 1.2205, 1.2662, 1.1982, 1.1596, 1.2662, 1.2029,
         1.5953, 1.5794, 1.6035, 1.5868, 1.5930, 1.5946, 1.6012, 1.5945, 1.5945,
         1.3188, 1.3297, 1.3164, 1.3374, 1.3182, 1.3485, 1.3416, 1.3289, 1.3164,
         1.6039, 1.6184, 1.6082, 1.6050, 1.6112, 1.6008, 1.6185, 1.5737, 1.5784,
         1.2618, 1.2845, 1.2781, 1.2926, 1.2579, 1.2509, 1.2421, 1.3114, 1.2753],
        [1.3796, 1.2495, 1.2400, 1.2775, 1.2777, 1.2890, 1.2838, 1.2021, 1.2021,
         3.7008, 3.7190, 3.6826, 3.7677, 3.7034, 3.8293, 3.6614, 3.6937, 3.7845,
         1.5213, 1.5081, 1.4807, 1.4805, 1.5020, 1.5113, 1.5364, 1.5115, 1.5115,
         1.3555, 1.3228, 1.3185, 1.3731, 1.3185, 1.4086, 1.3900, 1.3604, 1.3156,
         1.4750, 1.5334, 1.4953, 1.4812, 1.4749, 1.5157, 1.5355, 1.3644, 1.4608,
         1.1142, 1.2261, 1.2007, 1.2483, 1.1101, 1.1180, 1.0492, 1.3094, 1.1911],
        [1.4045, 1.4042, 1.4026, 1.4001, 1.4004, 1.4043, 1.3999, 1.4041, 1.4041,
         1.4376, 1.4373, 1.4379, 1.4379, 1.4374, 1.4174, 1.4384, 1.4364, 1.4339,
         2.2516, 2.2537, 2.2706, 2.2610, 2.2406, 2.2394, 2.2683, 2.2376, 2.2376,
         1.4751, 1.4738, 1.4808, 1.4809, 1.4751, 1.4809, 1.4809, 1.4809, 1.4808,
         1.7991, 1.7991, 1.7992, 1.7962, 1.7991, 1.7991, 1.7991, 1.7742, 1.7778,
         1.4514, 1.4561, 1.4562, 1.4560, 1.4480, 1.4566, 1.4527, 1.4557, 1.4562],
        [1.2613, 1.2614, 1.2471, 1.2391, 1.2605, 1.2586, 1.2602, 1.2615, 1.2614,
         1.2936, 1.2873, 1.2830, 1.2830, 1.2942, 1.2801, 1.2913, 1.2941, 1.2663,
         1.6371, 1.6126, 1.6353, 1.6352, 1.6333, 1.6336, 1.6360, 1.6372, 1.6372,
         3.4163, 3.3107, 3.2616, 3.3059, 3.3789, 3.2896, 3.4133, 3.2722, 3.2530,
         1.6635, 1.6554, 1.6549, 1.6584, 1.6615, 1.6375, 1.6619, 1.6042, 1.6307,
         1.3132, 1.3065, 1.2971, 1.3104, 1.3081, 1.3013, 1.3135, 1.3096, 1.3137],
        [1.4077, 1.4037, 1.3635, 1.3667, 1.4018, 1.4073, 1.4059, 1.4070, 1.4070,
         1.4396, 1.4372, 1.4320, 1.4262, 1.4401, 1.3983, 1.4356, 1.4401, 1.4367,
         1.7617, 1.7510, 1.7519, 1.7595, 1.7775, 1.7758, 1.7543, 1.7776, 1.7776,
         1.4436, 1.4511, 1.4838, 1.4791, 1.4493, 1.4825, 1.4709, 1.4839, 1.4809,
         2.2456, 2.2286, 2.2165, 2.2327, 2.2759, 2.2961, 2.2603, 2.3599, 2.3588,
         1.4434, 1.4323, 1.4468, 1.4576, 1.4467, 1.4556, 1.4271, 1.4505, 1.4578],
        [1.3871, 1.3077, 1.3035, 1.3197, 1.3142, 1.3231, 1.3220, 1.2693, 1.2693,
         1.2138, 1.1698, 1.1671, 1.1754, 1.2602, 1.1358, 1.0776, 1.2602, 1.1516,
         1.6060, 1.5847, 1.5749, 1.5649, 1.5868, 1.5830, 1.5992, 1.5877, 1.5877,
         1.3923, 1.3689, 1.3704, 1.3837, 1.3684, 1.4080, 1.4102, 1.3878, 1.3704,
         1.5766, 1.5732, 1.5817, 1.5710, 1.5583, 1.5578, 1.6067, 1.5150, 1.4833,
         3.7605, 3.6731, 3.6939, 3.6925, 3.6841, 3.5980, 3.7556, 3.6907, 3.6124]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 53 : 1780.4100999668406
Test loss for epoch 53 : 194.44709337904578
Test Precision for epoch 53 : 0.26153846153846155
Test Recall for epoch 53 : 0.26153846153846155
Test F1 for epoch 53 : 0.26153846153846155


theta for epoch 54 : tensor([[3.6926, 3.6932, 3.7425, 3.7269, 3.7207, 3.6804, 3.6963, 3.6513, 3.6513,
         1.2486, 1.2242, 1.2227, 1.2270, 1.2721, 1.2048, 1.1673, 1.2721, 1.2097,
         1.6007, 1.5847, 1.6089, 1.5916, 1.5978, 1.5994, 1.6065, 1.5994, 1.5994,
         1.3233, 1.3340, 1.3190, 1.3421, 1.3220, 1.3543, 1.3468, 1.3332, 1.3190,
         1.6040, 1.6189, 1.6084, 1.6052, 1.6116, 1.6012, 1.6192, 1.5740, 1.5786,
         1.2678, 1.2912, 1.2845, 1.2995, 1.2637, 1.2565, 1.2476, 1.3188, 1.2815],
        [1.3820, 1.2522, 1.2427, 1.2803, 1.2805, 1.2918, 1.2866, 1.2046, 1.2046,
         3.7140, 3.7328, 3.6953, 3.7830, 3.7165, 3.8465, 3.6738, 3.7066, 3.8003,
         1.5330, 1.5201, 1.4928, 1.4930, 1.5142, 1.5234, 1.5480, 1.5237, 1.5237,
         1.3591, 1.3267, 1.3232, 1.3764, 1.3226, 1.4112, 1.3930, 1.3641, 1.3203,
         1.4827, 1.5405, 1.5029, 1.4889, 1.4825, 1.5229, 1.5425, 1.3731, 1.4687,
         1.1283, 1.2381, 1.2133, 1.2598, 1.1245, 1.1327, 1.0646, 1.3194, 1.2040],
        [1.4082, 1.4078, 1.4063, 1.4037, 1.4040, 1.4079, 1.4035, 1.4077, 1.4077,
         1.4382, 1.4379, 1.4384, 1.4384, 1.4380, 1.4180, 1.4390, 1.4370, 1.4345,
         2.2508, 2.2530, 2.2700, 2.2599, 2.2393, 2.2381, 2.2672, 2.2364, 2.2364,
         1.4733, 1.4720, 1.4790, 1.4791, 1.4733, 1.4791, 1.4791, 1.4791, 1.4790,
         1.7946, 1.7946, 1.7947, 1.7917, 1.7946, 1.7946, 1.7946, 1.7697, 1.7733,
         1.4521, 1.4568, 1.4569, 1.4567, 1.4488, 1.4572, 1.4534, 1.4565, 1.4569],
        [1.2658, 1.2655, 1.2511, 1.2433, 1.2646, 1.2629, 1.2643, 1.2653, 1.2653,
         1.2941, 1.2879, 1.2836, 1.2836, 1.2946, 1.2807, 1.2923, 1.2944, 1.2670,
         1.6368, 1.6122, 1.6349, 1.6348, 1.6329, 1.6332, 1.6356, 1.6369, 1.6369,
         3.4260, 3.3173, 3.2674, 3.3123, 3.3877, 3.2953, 3.4226, 3.2778, 3.2585,
         1.6592, 1.6511, 1.6506, 1.6541, 1.6572, 1.6330, 1.6576, 1.5997, 1.6262,
         1.3141, 1.3074, 1.2980, 1.3113, 1.3090, 1.3023, 1.3144, 1.3105, 1.3146],
        [1.4115, 1.4073, 1.3669, 1.3704, 1.4055, 1.4111, 1.4097, 1.4108, 1.4108,
         1.4401, 1.4378, 1.4326, 1.4269, 1.4406, 1.3990, 1.4362, 1.4406, 1.4372,
         1.7608, 1.7501, 1.7510, 1.7585, 1.7765, 1.7748, 1.7534, 1.7766, 1.7766,
         1.4418, 1.4488, 1.4822, 1.4774, 1.4475, 1.4810, 1.4693, 1.4823, 1.4793,
         2.2434, 2.2261, 2.2141, 2.2304, 2.2739, 2.2941, 2.2580, 2.3586, 2.3574,
         1.4441, 1.4332, 1.4477, 1.4583, 1.4474, 1.4563, 1.4279, 1.4513, 1.4586],
        [1.3900, 1.3083, 1.3044, 1.3207, 1.3153, 1.3241, 1.3230, 1.2682, 1.2682,
         1.2216, 1.1791, 1.1765, 1.1843, 1.2668, 1.1449, 1.0905, 1.2668, 1.1614,
         1.6127, 1.5915, 1.5802, 1.5718, 1.5936, 1.5898, 1.6060, 1.5945, 1.5945,
         1.3910, 1.3674, 1.3687, 1.3824, 1.3681, 1.4068, 1.4090, 1.3864, 1.3687,
         1.5790, 1.5756, 1.5840, 1.5734, 1.5597, 1.5594, 1.6090, 1.5166, 1.4850,
         3.7740, 3.6835, 3.7050, 3.7036, 3.6952, 3.6065, 3.7690, 3.7015, 3.6211]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 54 : 1779.945780278972
Test loss for epoch 54 : 194.2877495868106
Test Precision for epoch 54 : 0.26153846153846155
Test Recall for epoch 54 : 0.26153846153846155
Test F1 for epoch 54 : 0.26153846153846155


theta for epoch 55 : tensor([[3.6812, 3.6820, 3.7332, 3.7169, 3.7105, 3.6686, 3.6851, 3.6385, 3.6385,
         1.2593, 1.2355, 1.2340, 1.2381, 1.2825, 1.2160, 1.1800, 1.2825, 1.2212,
         1.6027, 1.5867, 1.6110, 1.5931, 1.5993, 1.6009, 1.6084, 1.6009, 1.6009,
         1.3321, 1.3425, 1.3260, 1.3510, 1.3300, 1.3642, 1.3561, 1.3416, 1.3260,
         1.6020, 1.6173, 1.6064, 1.6031, 1.6097, 1.5995, 1.6177, 1.5720, 1.5767,
         1.2723, 1.2965, 1.2895, 1.3049, 1.2680, 1.2606, 1.2517, 1.3249, 1.2864],
        [1.4000, 1.2708, 1.2615, 1.2990, 1.2992, 1.3104, 1.3051, 1.2232, 1.2232,
         3.7125, 3.7320, 3.6934, 3.7837, 3.7151, 3.8491, 3.6713, 3.7048, 3.8016,
         1.5476, 1.5351, 1.5080, 1.5086, 1.5293, 1.5385, 1.5624, 1.5387, 1.5387,
         1.3760, 1.3441, 1.3412, 1.3929, 1.3401, 1.4267, 1.4090, 1.3809, 1.3383,
         1.4934, 1.5502, 1.5133, 1.4994, 1.4931, 1.5329, 1.5521, 1.3852, 1.4796,
         1.1475, 1.2549, 1.2307, 1.2760, 1.1439, 1.1523, 1.0852, 1.3340, 1.2217],
        [1.4159, 1.4155, 1.4140, 1.4115, 1.4117, 1.4157, 1.4113, 1.4154, 1.4154,
         1.4427, 1.4424, 1.4429, 1.4429, 1.4425, 1.4226, 1.4435, 1.4415, 1.4391,
         2.2463, 2.2484, 2.2655, 2.2552, 2.2344, 2.2331, 2.2624, 2.2314, 2.2314,
         1.4744, 1.4731, 1.4801, 1.4802, 1.4744, 1.4803, 1.4802, 1.4802, 1.4801,
         1.7876, 1.7875, 1.7876, 1.7846, 1.7875, 1.7875, 1.7875, 1.7627, 1.7662,
         1.4509, 1.4555, 1.4557, 1.4555, 1.4475, 1.4560, 1.4522, 1.4552, 1.4556],
        [1.2748, 1.2741, 1.2596, 1.2518, 1.2732, 1.2715, 1.2729, 1.2737, 1.2737,
         1.2987, 1.2926, 1.2883, 1.2882, 1.2990, 1.2854, 1.2973, 1.2988, 1.2717,
         1.6328, 1.6081, 1.6308, 1.6307, 1.6290, 1.6292, 1.6316, 1.6329, 1.6329,
         3.4361, 3.3243, 3.2734, 3.3190, 3.3969, 3.3013, 3.4323, 3.2837, 3.2643,
         1.6524, 1.6442, 1.6437, 1.6473, 1.6503, 1.6261, 1.6507, 1.5926, 1.6193,
         1.3131, 1.3065, 1.2971, 1.3103, 1.3081, 1.3014, 1.3135, 1.3095, 1.3137],
        [1.4194, 1.4150, 1.3742, 1.3781, 1.4133, 1.4189, 1.4175, 1.4186, 1.4186,
         1.4445, 1.4422, 1.4371, 1.4314, 1.4450, 1.4036, 1.4407, 1.4450, 1.4416,
         1.7561, 1.7456, 1.7463, 1.7538, 1.7718, 1.7702, 1.7489, 1.7719, 1.7719,
         1.4428, 1.4493, 1.4834, 1.4786, 1.4485, 1.4823, 1.4706, 1.4836, 1.4805,
         2.2384, 2.2208, 2.2089, 2.2254, 2.2691, 2.2893, 2.2530, 2.3545, 2.3533,
         1.4429, 1.4322, 1.4465, 1.4571, 1.4462, 1.4550, 1.4267, 1.4502, 1.4573],
        [1.3947, 1.3110, 1.3074, 1.3238, 1.3184, 1.3270, 1.3261, 1.2695, 1.2695,
         1.2329, 1.1920, 1.1896, 1.1969, 1.2770, 1.1577, 1.1075, 1.2770, 1.1750,
         1.6149, 1.5939, 1.5810, 1.5742, 1.5958, 1.5920, 1.6082, 1.5967, 1.5967,
         1.3910, 1.3672, 1.3683, 1.3823, 1.3690, 1.4068, 1.4091, 1.3862, 1.3684,
         1.5783, 1.5749, 1.5834, 1.5728, 1.5582, 1.5579, 1.6084, 1.5152, 1.4837,
         3.7853, 3.6917, 3.7140, 3.7124, 3.7041, 3.6128, 3.7803, 3.7100, 3.6276]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 55 : 1780.0354651220766
Test loss for epoch 55 : 193.81932675291466
Test Precision for epoch 55 : 0.26153846153846155
Test Recall for epoch 55 : 0.26153846153846155
Test F1 for epoch 55 : 0.26153846153846155


theta for epoch 56 : tensor([[3.6709, 3.6719, 3.7248, 3.7079, 3.7015, 3.6579, 3.6749, 3.6268, 3.6268,
         1.2720, 1.2486, 1.2472, 1.2512, 1.2951, 1.2292, 1.1942, 1.2951, 1.2345,
         1.6030, 1.5869, 1.6113, 1.5928, 1.5991, 1.6006, 1.6086, 1.6006, 1.6006,
         1.3391, 1.3491, 1.3311, 1.3580, 1.3362, 1.3722, 1.3636, 1.3481, 1.3311,
         1.6005, 1.6162, 1.6049, 1.6017, 1.6084, 1.5984, 1.6167, 1.5707, 1.5753,
         1.2733, 1.2982, 1.2909, 1.3069, 1.2689, 1.2611, 1.2522, 1.3275, 1.2878],
        [1.4105, 1.2807, 1.2715, 1.3092, 1.3094, 1.3205, 1.3152, 1.2325, 1.2325,
         3.7191, 3.7392, 3.6995, 3.7924, 3.7216, 3.8597, 3.6770, 3.7110, 3.8108,
         1.5567, 1.5446, 1.5177, 1.5186, 1.5390, 1.5481, 1.5715, 1.5482, 1.5482,
         1.3847, 1.3531, 1.3507, 1.4013, 1.3492, 1.4344, 1.4171, 1.3896, 1.3478,
         1.5015, 1.5576, 1.5212, 1.5075, 1.5011, 1.5404, 1.5594, 1.3945, 1.4880,
         1.1594, 1.2648, 1.2411, 1.2854, 1.1560, 1.1646, 1.0981, 1.3421, 1.2324],
        [1.4241, 1.4237, 1.4221, 1.4196, 1.4198, 1.4238, 1.4195, 1.4236, 1.4236,
         1.4497, 1.4494, 1.4499, 1.4499, 1.4494, 1.4297, 1.4505, 1.4484, 1.4461,
         2.2404, 2.2426, 2.2597, 2.2491, 2.2281, 2.2268, 2.2563, 2.2251, 2.2251,
         1.4750, 1.4737, 1.4807, 1.4808, 1.4749, 1.4809, 1.4808, 1.4808, 1.4807,
         1.7815, 1.7814, 1.7815, 1.7785, 1.7814, 1.7814, 1.7814, 1.7567, 1.7602,
         1.4469, 1.4515, 1.4517, 1.4515, 1.4436, 1.4519, 1.4482, 1.4512, 1.4516],
        [1.2844, 1.2833, 1.2687, 1.2610, 1.2825, 1.2808, 1.2822, 1.2827, 1.2826,
         1.3059, 1.2998, 1.2957, 1.2955, 1.3061, 1.2927, 1.3049, 1.3059, 1.2790,
         1.6278, 1.6031, 1.6258, 1.6257, 1.6240, 1.6243, 1.6266, 1.6279, 1.6279,
         3.4441, 3.3292, 3.2774, 3.3236, 3.4040, 3.3052, 3.4399, 3.2876, 3.2680,
         1.6467, 1.6385, 1.6379, 1.6415, 1.6445, 1.6203, 1.6449, 1.5866, 1.6133,
         1.3095, 1.3029, 1.2936, 1.3068, 1.3046, 1.2978, 1.3098, 1.3060, 1.3102],
        [1.4277, 1.4231, 1.3819, 1.3862, 1.4215, 1.4272, 1.4257, 1.4269, 1.4269,
         1.4514, 1.4491, 1.4441, 1.4384, 1.4519, 1.4107, 1.4476, 1.4518, 1.4485,
         1.7505, 1.7401, 1.7405, 1.7481, 1.7662, 1.7645, 1.7433, 1.7662, 1.7662,
         1.4433, 1.4492, 1.4842, 1.4792, 1.4489, 1.4830, 1.4714, 1.4844, 1.4813,
         2.2341, 2.2162, 2.2043, 2.2210, 2.2651, 2.2852, 2.2486, 2.3511, 2.3498,
         1.4388, 1.4284, 1.4427, 1.4532, 1.4422, 1.4510, 1.4226, 1.4464, 1.4534],
        [1.3958, 1.3101, 1.3068, 1.3232, 1.3178, 1.3264, 1.3255, 1.2672, 1.2672,
         1.2454, 1.2060, 1.2037, 1.2105, 1.2886, 1.1714, 1.1250, 1.2886, 1.1894,
         1.6143, 1.5933, 1.5791, 1.5738, 1.5952, 1.5914, 1.6076, 1.5961, 1.5961,
         1.3869, 1.3628, 1.3639, 1.3780, 1.3657, 1.4027, 1.4050, 1.3819, 1.3639,
         1.5775, 1.5741, 1.5825, 1.5719, 1.5564, 1.5562, 1.6075, 1.5136, 1.4822,
         3.7973, 3.7006, 3.7236, 3.7218, 3.7137, 3.6197, 3.7922, 3.7192, 3.6347]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 56 : 1779.956769606829
Test loss for epoch 56 : 193.73672924164703
Test Precision for epoch 56 : 0.26153846153846155
Test Recall for epoch 56 : 0.26153846153846155
Test F1 for epoch 56 : 0.26153846153846155


theta for epoch 57 : tensor([[3.6608, 3.6619, 3.7166, 3.6990, 3.6926, 3.6474, 3.6649, 3.6152, 3.6152,
         1.2830, 1.2599, 1.2586, 1.2624, 1.3060, 1.2405, 1.2063, 1.3060, 1.2459,
         1.6047, 1.5885, 1.6130, 1.5939, 1.6002, 1.6018, 1.6102, 1.6017, 1.6017,
         1.3437, 1.3535, 1.3341, 1.3628, 1.3402, 1.3777, 1.3687, 1.3524, 1.3341,
         1.6016, 1.6177, 1.6061, 1.6029, 1.6097, 1.5998, 1.6184, 1.5719, 1.5766,
         1.2720, 1.2976, 1.2900, 1.3065, 1.2673, 1.2592, 1.2503, 1.3278, 1.2867],
        [1.4121, 1.2807, 1.2716, 1.3096, 1.3099, 1.3210, 1.3156, 1.2315, 1.2315,
         3.7310, 3.7516, 3.7109, 3.8063, 3.7334, 3.8755, 3.6880, 3.7225, 3.8253,
         1.5638, 1.5519, 1.5251, 1.5262, 1.5464, 1.5554, 1.5785, 1.5555, 1.5555,
         1.3856, 1.3543, 1.3521, 1.4020, 1.3503, 1.4347, 1.4176, 1.3905, 1.3492,
         1.5094, 1.5650, 1.5290, 1.5154, 1.5090, 1.5479, 1.5667, 1.4033, 1.4962,
         1.1654, 1.2693, 1.2460, 1.2896, 1.1621, 1.1709, 1.1049, 1.3452, 1.2375],
        [1.4303, 1.4299, 1.4283, 1.4258, 1.4260, 1.4301, 1.4258, 1.4299, 1.4299,
         1.4555, 1.4552, 1.4557, 1.4557, 1.4552, 1.4355, 1.4563, 1.4542, 1.4519,
         2.2362, 2.2384, 2.2556, 2.2446, 2.2234, 2.2221, 2.2518, 2.2204, 2.2204,
         1.4748, 1.4735, 1.4806, 1.4807, 1.4747, 1.4808, 1.4807, 1.4807, 1.4806,
         1.7785, 1.7784, 1.7785, 1.7754, 1.7784, 1.7784, 1.7784, 1.7537, 1.7572,
         1.4414, 1.4460, 1.4462, 1.4460, 1.4381, 1.4464, 1.4426, 1.4458, 1.4461],
        [1.2923, 1.2907, 1.2760, 1.2683, 1.2899, 1.2883, 1.2896, 1.2898, 1.2898,
         1.3120, 1.3060, 1.3019, 1.3016, 1.3121, 1.2989, 1.3113, 1.3119, 1.2852,
         1.6251, 1.6003, 1.6230, 1.6230, 1.6213, 1.6215, 1.6239, 1.6252, 1.6252,
         3.4500, 3.3319, 3.2791, 3.3260, 3.4090, 3.3070, 3.4454, 3.2893, 3.2695,
         1.6441, 1.6359, 1.6353, 1.6389, 1.6419, 1.6176, 1.6423, 1.5838, 1.6106,
         1.3044, 1.2979, 1.2886, 1.3018, 1.2995, 1.2927, 1.3047, 1.3010, 1.3052],
        [1.4340, 1.4292, 1.3874, 1.3922, 1.4276, 1.4335, 1.4319, 1.4332, 1.4332,
         1.4572, 1.4549, 1.4499, 1.4442, 1.4576, 1.4165, 1.4534, 1.4576, 1.4542,
         1.7469, 1.7366, 1.7369, 1.7445, 1.7626, 1.7609, 1.7398, 1.7627, 1.7627,
         1.4430, 1.4483, 1.4841, 1.4791, 1.4485, 1.4830, 1.4713, 1.4844, 1.4813,
         2.2326, 2.2143, 2.2025, 2.2193, 2.2637, 2.2838, 2.2469, 2.3505, 2.3491,
         1.4333, 1.4231, 1.4373, 1.4477, 1.4366, 1.4455, 1.4169, 1.4410, 1.4479],
        [1.3916, 1.3039, 1.3008, 1.3173, 1.3119, 1.3205, 1.3196, 1.2596, 1.2596,
         1.2556, 1.2174, 1.2152, 1.2216, 1.2979, 1.1825, 1.1393, 1.2979, 1.2013,
         1.6140, 1.5931, 1.5776, 1.5737, 1.5949, 1.5911, 1.6073, 1.5958, 1.5958,
         1.3788, 1.3545, 1.3555, 1.3698, 1.3582, 1.3946, 1.3970, 1.3737, 1.3555,
         1.5785, 1.5751, 1.5835, 1.5730, 1.5565, 1.5565, 1.6085, 1.5139, 1.4825,
         3.8104, 3.7107, 3.7344, 3.7324, 3.7244, 3.6278, 3.8053, 3.7296, 3.6430]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 57 : 1779.9929585544412
Test loss for epoch 57 : 193.95247250110063
Test Precision for epoch 57 : 0.26153846153846155
Test Recall for epoch 57 : 0.26153846153846155
Test F1 for epoch 57 : 0.26153846153846155


theta for epoch 58 : tensor([[3.6525, 3.6539, 3.7104, 3.6921, 3.6856, 3.6388, 3.6569, 3.6057, 3.6057,
         1.2871, 1.2644, 1.2630, 1.2667, 1.3101, 1.2448, 1.2113, 1.3101, 1.2505,
         1.6091, 1.5929, 1.6175, 1.5978, 1.6042, 1.6058, 1.6146, 1.6057, 1.6057,
         1.3492, 1.3588, 1.3382, 1.3683, 1.3451, 1.3840, 1.3746, 1.3576, 1.3382,
         1.6058, 1.6222, 1.6103, 1.6070, 1.6140, 1.6043, 1.6230, 1.5762, 1.5809,
         1.2703, 1.2968, 1.2889, 1.3058, 1.2655, 1.2572, 1.2481, 1.3277, 1.2854],
        [1.4082, 1.2742, 1.2652, 1.3039, 1.3042, 1.3154, 1.3099, 1.2239, 1.2238,
         3.7444, 3.7657, 3.7239, 3.8218, 3.7468, 3.8928, 3.7007, 3.7356, 3.8413,
         1.5703, 1.5586, 1.5319, 1.5332, 1.5532, 1.5622, 1.5851, 1.5623, 1.5623,
         1.3823, 1.3510, 1.3490, 1.3986, 1.3469, 1.4312, 1.4142, 1.3872, 1.3460,
         1.5178, 1.5730, 1.5373, 1.5239, 1.5175, 1.5560, 1.5746, 1.4124, 1.5048,
         1.1678, 1.2707, 1.2476, 1.2906, 1.1645, 1.1734, 1.1076, 1.3455, 1.2392],
        [1.4369, 1.4366, 1.4350, 1.4325, 1.4326, 1.4368, 1.4325, 1.4366, 1.4366,
         1.4550, 1.4548, 1.4553, 1.4553, 1.4548, 1.4352, 1.4559, 1.4538, 1.4515,
         2.2350, 2.2372, 2.2545, 2.2428, 2.2216, 2.2202, 2.2500, 2.2185, 2.2185,
         1.4770, 1.4758, 1.4829, 1.4830, 1.4770, 1.4831, 1.4830, 1.4830, 1.4829,
         1.7790, 1.7789, 1.7790, 1.7759, 1.7789, 1.7789, 1.7789, 1.7543, 1.7576,
         1.4365, 1.4411, 1.4413, 1.4411, 1.4332, 1.4415, 1.4376, 1.4409, 1.4412],
        [1.3007, 1.2987, 1.2838, 1.2762, 1.2980, 1.2964, 1.2976, 1.2976, 1.2976,
         1.3120, 1.3060, 1.3020, 1.3016, 1.3121, 1.2989, 1.3115, 1.3118, 1.2853,
         1.6261, 1.6012, 1.6239, 1.6239, 1.6223, 1.6225, 1.6248, 1.6261, 1.6261,
         3.4563, 3.3351, 3.2812, 3.3288, 3.4143, 3.3091, 3.4512, 3.2913, 3.2715,
         1.6452, 1.6369, 1.6363, 1.6399, 1.6429, 1.6186, 1.6433, 1.5846, 1.6115,
         1.3000, 1.2935, 1.2843, 1.2975, 1.2952, 1.2883, 1.3003, 1.2968, 1.3008],
        [1.4407, 1.4357, 1.3934, 1.3985, 1.4342, 1.4402, 1.4386, 1.4400, 1.4400,
         1.4567, 1.4544, 1.4495, 1.4437, 1.4571, 1.4160, 1.4529, 1.4571, 1.4537,
         1.7468, 1.7367, 1.7367, 1.7444, 1.7625, 1.7608, 1.7398, 1.7626, 1.7626,
         1.4451, 1.4498, 1.4865, 1.4814, 1.4506, 1.4853, 1.4736, 1.4867, 1.4836,
         2.2342, 2.2156, 2.2038, 2.2208, 2.2655, 2.2854, 2.2484, 2.3529, 2.3514,
         1.4282, 1.4184, 1.4325, 1.4429, 1.4316, 1.4406, 1.4118, 1.4363, 1.4431],
        [1.3852, 1.2954, 1.2925, 1.3092, 1.3038, 1.3123, 1.3115, 1.2497, 1.2497,
         1.2587, 1.2213, 1.2193, 1.2253, 1.3003, 1.1860, 1.1455, 1.3003, 1.2056,
         1.6158, 1.5948, 1.5780, 1.5754, 1.5965, 1.5928, 1.6090, 1.5975, 1.5975,
         1.3704, 1.3458, 1.3466, 1.3613, 1.3504, 1.3863, 1.3888, 1.3651, 1.3467,
         1.5820, 1.5786, 1.5869, 1.5765, 1.5591, 1.5591, 1.6121, 1.5166, 1.4852,
         3.8258, 3.7229, 3.7474, 3.7453, 3.7374, 3.6383, 3.8207, 3.7422, 3.6536]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 58 : 1779.7279568187143
Test loss for epoch 58 : 194.34457293034936
Test Precision for epoch 58 : 0.26153846153846155
Test Recall for epoch 58 : 0.26153846153846155
Test F1 for epoch 58 : 0.26153846153846155


theta for epoch 59 : tensor([[3.6451, 3.6467, 3.7049, 3.6860, 3.6794, 3.6310, 3.6497, 3.5971, 3.5970,
         1.2835, 1.2612, 1.2598, 1.2634, 1.3062, 1.2416, 1.2092, 1.3062, 1.2474,
         1.6163, 1.6001, 1.6246, 1.6046, 1.6110, 1.6126, 1.6217, 1.6125, 1.6125,
         1.3580, 1.3675, 1.3461, 1.3771, 1.3536, 1.3933, 1.3837, 1.3662, 1.3461,
         1.6124, 1.6290, 1.6170, 1.6137, 1.6208, 1.6112, 1.6300, 1.5829, 1.5876,
         1.2703, 1.2974, 1.2892, 1.3066, 1.2653, 1.2567, 1.2476, 1.3291, 1.2857],
        [1.4180, 1.2824, 1.2735, 1.3125, 1.3128, 1.3240, 1.3184, 1.2311, 1.2311,
         3.7387, 3.7605, 3.7176, 3.8182, 3.7410, 3.8911, 3.6940, 3.7295, 3.8383,
         1.5849, 1.5735, 1.5470, 1.5484, 1.5681, 1.5771, 1.5996, 1.5772, 1.5772,
         1.3918, 1.3608, 1.3587, 1.4079, 1.3564, 1.4403, 1.4234, 1.3966, 1.3557,
         1.5334, 1.5879, 1.5527, 1.5394, 1.5330, 1.5710, 1.5895, 1.4289, 1.5207,
         1.1772, 1.2790, 1.2561, 1.2987, 1.1739, 1.1827, 1.1173, 1.3528, 1.2478],
        [1.4466, 1.4463, 1.4447, 1.4421, 1.4422, 1.4464, 1.4421, 1.4463, 1.4463,
         1.4470, 1.4467, 1.4472, 1.4473, 1.4468, 1.4272, 1.4478, 1.4457, 1.4435,
         2.2363, 2.2386, 2.2559, 2.2434, 2.2220, 2.2206, 2.2506, 2.2190, 2.2190,
         1.4832, 1.4819, 1.4891, 1.4892, 1.4831, 1.4893, 1.4892, 1.4892, 1.4891,
         1.7820, 1.7819, 1.7820, 1.7789, 1.7819, 1.7819, 1.7819, 1.7574, 1.7607,
         1.4335, 1.4381, 1.4382, 1.4381, 1.4302, 1.4384, 1.4346, 1.4379, 1.4382],
        [1.3123, 1.3099, 1.2949, 1.2873, 1.3092, 1.3076, 1.3088, 1.3086, 1.3086,
         1.3044, 1.2985, 1.2945, 1.2941, 1.3045, 1.2913, 1.3042, 1.3042, 1.2778,
         1.6301, 1.6051, 1.6279, 1.6278, 1.6263, 1.6265, 1.6288, 1.6302, 1.6302,
         3.4641, 3.3397, 3.2850, 3.3332, 3.4212, 3.3127, 3.4585, 3.2949, 3.2750,
         1.6488, 1.6406, 1.6399, 1.6435, 1.6465, 1.6222, 1.6469, 1.5880, 1.6150,
         1.2976, 1.2912, 1.2820, 1.2953, 1.2928, 1.2859, 1.2978, 1.2946, 1.2985],
        [1.4503, 1.4451, 1.4023, 1.4078, 1.4437, 1.4499, 1.4482, 1.4497, 1.4497,
         1.4487, 1.4464, 1.4415, 1.4357, 1.4491, 1.4079, 1.4449, 1.4491, 1.4456,
         1.7497, 1.7397, 1.7395, 1.7472, 1.7654, 1.7637, 1.7428, 1.7655, 1.7655,
         1.4511, 1.4552, 1.4927, 1.4875, 1.4565, 1.4915, 1.4798, 1.4930, 1.4898,
         2.2380, 2.2191, 2.2073, 2.2245, 2.2695, 2.2893, 2.2521, 2.3576, 2.3559,
         1.4251, 1.4155, 1.4296, 1.4400, 1.4285, 1.4376, 1.4085, 1.4334, 1.4401],
        [1.3825, 1.2908, 1.2881, 1.3049, 1.2994, 1.3080, 1.3072, 1.2439, 1.2439,
         1.2544, 1.2182, 1.2162, 1.2219, 1.2951, 1.1826, 1.1453, 1.2951, 1.2029,
         1.6205, 1.5995, 1.5816, 1.5801, 1.6011, 1.5974, 1.6137, 1.6021, 1.6021,
         1.3665, 1.3416, 1.3422, 1.3572, 1.3468, 1.3825, 1.3850, 1.3609, 1.3422,
         1.5881, 1.5848, 1.5930, 1.5826, 1.5644, 1.5645, 1.6183, 1.5220, 1.4905,
         3.8397, 3.7337, 3.7589, 3.7567, 3.7490, 3.6472, 3.8346, 3.7533, 3.6627]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 59 : 1779.443369478099
Test loss for epoch 59 : 194.20579321409565
Test Precision for epoch 59 : 0.26153846153846155
Test Recall for epoch 59 : 0.26153846153846155
Test F1 for epoch 59 : 0.26153846153846155


theta for epoch 60 : tensor([[3.6394, 3.6413, 3.7012, 3.6816, 3.6751, 3.6251, 3.6443, 3.5903, 3.5903,
         1.2787, 1.2569, 1.2556, 1.2590, 1.3012, 1.2373, 1.2059, 1.3012, 1.2433,
         1.6227, 1.6065, 1.6311, 1.6107, 1.6172, 1.6187, 1.6281, 1.6187, 1.6187,
         1.3638, 1.3731, 1.3512, 1.3829, 1.3591, 1.3994, 1.3896, 1.3718, 1.3512,
         1.6185, 1.6354, 1.6232, 1.6199, 1.6271, 1.6176, 1.6365, 1.5892, 1.5939,
         1.2710, 1.2987, 1.2903, 1.3081, 1.2659, 1.2571, 1.2478, 1.3310, 1.2867],
        [1.4202, 1.2825, 1.2737, 1.3131, 1.3135, 1.3247, 1.3190, 1.2302, 1.2302,
         3.7388, 3.7613, 3.7173, 3.8205, 3.7411, 3.8953, 3.6933, 3.7293, 3.8412,
         1.5957, 1.5844, 1.5581, 1.5595, 1.5790, 1.5880, 1.6104, 1.5881, 1.5881,
         1.3937, 1.3627, 1.3605, 1.4097, 1.3581, 1.4420, 1.4252, 1.3984, 1.3575,
         1.5457, 1.5998, 1.5649, 1.5517, 1.5454, 1.5830, 1.6014, 1.4420, 1.5333,
         1.1833, 1.2846, 1.2618, 1.3041, 1.1800, 1.1887, 1.1235, 1.3578, 1.2535],
        [1.4547, 1.4544, 1.4528, 1.4502, 1.4503, 1.4546, 1.4503, 1.4544, 1.4544,
         1.4386, 1.4383, 1.4388, 1.4388, 1.4384, 1.4188, 1.4394, 1.4373, 1.4352,
         2.2377, 2.2400, 2.2573, 2.2440, 2.2225, 2.2211, 2.2512, 2.2195, 2.2195,
         1.4881, 1.4869, 1.4941, 1.4942, 1.4881, 1.4943, 1.4942, 1.4942, 1.4941,
         1.7852, 1.7851, 1.7852, 1.7821, 1.7851, 1.7851, 1.7851, 1.7606, 1.7639,
         1.4322, 1.4369, 1.4369, 1.4368, 1.4289, 1.4371, 1.4332, 1.4367, 1.4369],
        [1.3224, 1.3197, 1.3044, 1.2968, 1.3189, 1.3174, 1.3186, 1.3181, 1.3181,
         1.2966, 1.2907, 1.2867, 1.2863, 1.2966, 1.2835, 1.2965, 1.2964, 1.2699,
         1.6344, 1.6094, 1.6322, 1.6321, 1.6306, 1.6308, 1.6331, 1.6345, 1.6345,
         3.4699, 3.3423, 3.2866, 3.3355, 3.4261, 3.3144, 3.4638, 3.2965, 3.2764,
         1.6527, 1.6445, 1.6438, 1.6474, 1.6503, 1.6260, 1.6508, 1.5917, 1.6187,
         1.2969, 1.2907, 1.2814, 1.2948, 1.2923, 1.2852, 1.2971, 1.2941, 1.2980],
        [1.4584, 1.4531, 1.4095, 1.4155, 1.4517, 1.4581, 1.4563, 1.4579, 1.4579,
         1.4403, 1.4379, 1.4331, 1.4272, 1.4407, 1.3994, 1.4364, 1.4407, 1.4370,
         1.7529, 1.7430, 1.7426, 1.7503, 1.7686, 1.7668, 1.7460, 1.7687, 1.7687,
         1.4558, 1.4594, 1.4978, 1.4924, 1.4612, 1.4965, 1.4849, 1.4980, 1.4949,
         2.2417, 2.2225, 2.2108, 2.2282, 2.2735, 2.2930, 2.2557, 2.3622, 2.3604,
         1.4236, 1.4144, 1.4284, 1.4388, 1.4271, 1.4363, 1.4069, 1.4323, 1.4389],
        [1.3771, 1.2833, 1.2807, 1.2976, 1.2922, 1.3007, 1.3000, 1.2350, 1.2350,
         1.2488, 1.2134, 1.2116, 1.2168, 1.2888, 1.1774, 1.1426, 1.2888, 1.1984,
         1.6240, 1.6031, 1.5841, 1.5835, 1.6044, 1.6007, 1.6172, 1.6054, 1.6054,
         1.3595, 1.3343, 1.3346, 1.3502, 1.3400, 1.3759, 1.3784, 1.3538, 1.3346,
         1.5933, 1.5901, 1.5982, 1.5878, 1.5688, 1.5690, 1.6237, 1.5264, 1.4950,
         3.8562, 3.7470, 3.7730, 3.7705, 3.7631, 3.6587, 3.8510, 3.7669, 3.6743]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 60 : 1779.6240737643207
Test loss for epoch 60 : 194.5462064009845
Test Precision for epoch 60 : 0.26153846153846155
Test Recall for epoch 60 : 0.26153846153846155
Test F1 for epoch 60 : 0.26153846153846155


theta for epoch 61 : tensor([[3.6356, 3.6378, 3.6992, 3.6790, 3.6725, 3.6210, 3.6407, 3.5854, 3.5854,
         1.2772, 1.2557, 1.2544, 1.2577, 1.2993, 1.2362, 1.2058, 1.2993, 1.2423,
         1.6260, 1.6099, 1.6344, 1.6138, 1.6203, 1.6218, 1.6314, 1.6218, 1.6218,
         1.3661, 1.3753, 1.3531, 1.3850, 1.3613, 1.4016, 1.3918, 1.3739, 1.3531,
         1.6219, 1.6390, 1.6266, 1.6233, 1.6305, 1.6212, 1.6401, 1.5926, 1.5973,
         1.2716, 1.2997, 1.2911, 1.3093, 1.2664, 1.2574, 1.2480, 1.3326, 1.2875],
        [1.4149, 1.2749, 1.2660, 1.3061, 1.3065, 1.3178, 1.3120, 1.2217, 1.2217,
         3.7469, 3.7700, 3.7249, 3.8306, 3.7491, 3.9072, 3.7005, 3.7369, 3.8518,
         1.6006, 1.5894, 1.5632, 1.5647, 1.5840, 1.5930, 1.6153, 1.5931, 1.5931,
         1.3882, 1.3572, 1.3548, 1.4042, 1.3524, 1.4366, 1.4197, 1.3928, 1.3518,
         1.5528, 1.6065, 1.5718, 1.5588, 1.5525, 1.5898, 1.6081, 1.4495, 1.5407,
         1.1858, 1.2869, 1.2640, 1.3063, 1.1823, 1.1909, 1.1256, 1.3600, 1.2557],
        [1.4608, 1.4606, 1.4589, 1.4563, 1.4563, 1.4607, 1.4564, 1.4606, 1.4606,
         1.4341, 1.4337, 1.4343, 1.4343, 1.4338, 1.4143, 1.4349, 1.4328, 1.4306,
         2.2369, 2.2392, 2.2566, 2.2426, 2.2210, 2.2195, 2.2497, 2.2179, 2.2179,
         1.4915, 1.4903, 1.4975, 1.4976, 1.4915, 1.4977, 1.4976, 1.4976, 1.4975,
         1.7862, 1.7862, 1.7863, 1.7831, 1.7862, 1.7862, 1.7862, 1.7617, 1.7649,
         1.4317, 1.4365, 1.4365, 1.4364, 1.4284, 1.4367, 1.4327, 1.4363, 1.4365],
        [1.3304, 1.3273, 1.3119, 1.3043, 1.3266, 1.3251, 1.3262, 1.3256, 1.3256,
         1.2927, 1.2868, 1.2829, 1.2824, 1.2927, 1.2795, 1.2926, 1.2924, 1.2660,
         1.6367, 1.6115, 1.6344, 1.6343, 1.6329, 1.6330, 1.6353, 1.6367, 1.6367,
         3.4736, 3.3429, 3.2862, 3.3357, 3.4289, 3.3139, 3.4670, 3.2960, 3.2757,
         1.6544, 1.6463, 1.6454, 1.6491, 1.6520, 1.6277, 1.6525, 1.5932, 1.6203,
         1.2972, 1.2911, 1.2818, 1.2953, 1.2926, 1.2855, 1.2973, 1.2947, 1.2983],
        [1.4645, 1.4590, 1.4147, 1.4211, 1.4576, 1.4642, 1.4624, 1.4640, 1.4640,
         1.4357, 1.4334, 1.4285, 1.4226, 1.4361, 1.3947, 1.4318, 1.4361, 1.4324,
         1.7540, 1.7442, 1.7436, 1.7513, 1.7697, 1.7679, 1.7472, 1.7698, 1.7698,
         1.4590, 1.4620, 1.5012, 1.4957, 1.4643, 1.4999, 1.4883, 1.5014, 1.4983,
         2.2432, 2.2236, 2.2119, 2.2296, 2.2751, 2.2945, 2.2570, 2.3645, 2.3626,
         1.4231, 1.4141, 1.4281, 1.4385, 1.4265, 1.4358, 1.4062, 1.4320, 1.4386],
        [1.3695, 1.2730, 1.2706, 1.2878, 1.2822, 1.2909, 1.2901, 1.2232, 1.2232,
         1.2462, 1.2113, 1.2096, 1.2146, 1.2859, 1.1748, 1.1417, 1.2859, 1.1965,
         1.6243, 1.6033, 1.5834, 1.5835, 1.6043, 1.6007, 1.6175, 1.6053, 1.6053,
         1.3499, 1.3243, 1.3240, 1.3405, 1.3302, 1.3667, 1.3691, 1.3439, 1.3240,
         1.5955, 1.5924, 1.6002, 1.5899, 1.5701, 1.5705, 1.6261, 1.5278, 1.4963,
         3.8740, 3.7617, 3.7884, 3.7858, 3.7785, 3.6716, 3.8688, 3.7818, 3.6873]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 61 : 1779.4827017102411
Test loss for epoch 61 : 195.25435670314334
Test Precision for epoch 61 : 0.26153846153846155
Test Recall for epoch 61 : 0.26153846153846155
Test F1 for epoch 61 : 0.26153846153846155


theta for epoch 62 : tensor([[3.6311, 3.6336, 3.6967, 3.6758, 3.6693, 3.6163, 3.6365, 3.5799, 3.5799,
         1.2800, 1.2590, 1.2577, 1.2608, 1.3018, 1.2396, 1.2104, 1.3018, 1.2457,
         1.6264, 1.6103, 1.6347, 1.6140, 1.6206, 1.6221, 1.6318, 1.6221, 1.6221,
         1.3693, 1.3785, 1.3564, 1.3881, 1.3646, 1.4046, 1.3949, 1.3770, 1.3565,
         1.6219, 1.6391, 1.6266, 1.6233, 1.6306, 1.6213, 1.6403, 1.5927, 1.5974,
         1.2714, 1.2997, 1.2910, 1.3092, 1.2661, 1.2572, 1.2475, 1.3326, 1.2873],
        [1.4144, 1.2731, 1.2641, 1.3046, 1.3050, 1.3164, 1.3106, 1.2195, 1.2195,
         3.7509, 3.7746, 3.7285, 3.8367, 3.7531, 3.9151, 3.7037, 3.7406, 3.8585,
         1.6048, 1.5938, 1.5677, 1.5693, 1.5884, 1.5974, 1.6195, 1.5974, 1.5974,
         1.3877, 1.3568, 1.3542, 1.4036, 1.3516, 1.4360, 1.4191, 1.3923, 1.3511,
         1.5582, 1.6114, 1.5771, 1.5641, 1.5579, 1.5948, 1.6130, 1.4555, 1.5464,
         1.1901, 1.2903, 1.2677, 1.3095, 1.1868, 1.1954, 1.1301, 1.3625, 1.2595],
        [1.4668, 1.4666, 1.4649, 1.4623, 1.4623, 1.4667, 1.4625, 1.4667, 1.4667,
         1.4341, 1.4337, 1.4343, 1.4343, 1.4338, 1.4143, 1.4348, 1.4327, 1.4306,
         2.2336, 2.2359, 2.2533, 2.2387, 2.2171, 2.2155, 2.2458, 2.2140, 2.2140,
         1.4963, 1.4951, 1.5023, 1.5024, 1.4962, 1.5025, 1.5024, 1.5024, 1.5023,
         1.7840, 1.7840, 1.7841, 1.7809, 1.7840, 1.7840, 1.7840, 1.7595, 1.7627,
         1.4304, 1.4352, 1.4353, 1.4352, 1.4271, 1.4354, 1.4313, 1.4350, 1.4353],
        [1.3383, 1.3350, 1.3194, 1.3117, 1.3343, 1.3328, 1.3338, 1.3331, 1.3331,
         1.2934, 1.2875, 1.2836, 1.2831, 1.2934, 1.2802, 1.2934, 1.2931, 1.2667,
         1.6364, 1.6111, 1.6340, 1.6339, 1.6326, 1.6327, 1.6350, 1.6364, 1.6364,
         3.4773, 3.3433, 3.2857, 3.3359, 3.4316, 3.3135, 3.4702, 3.2955, 3.2751,
         1.6529, 1.6448, 1.6439, 1.6475, 1.6504, 1.6261, 1.6509, 1.5915, 1.6186,
         1.2967, 1.2907, 1.2814, 1.2949, 1.2921, 1.2849, 1.2968, 1.2944, 1.2979],
        [1.4705, 1.4647, 1.4198, 1.4265, 1.4634, 1.4702, 1.4683, 1.4701, 1.4701,
         1.4357, 1.4333, 1.4285, 1.4225, 1.4361, 1.3945, 1.4318, 1.4361, 1.4322,
         1.7525, 1.7428, 1.7419, 1.7498, 1.7683, 1.7665, 1.7458, 1.7684, 1.7684,
         1.4634, 1.4659, 1.5060, 1.5003, 1.4687, 1.5046, 1.4929, 1.5062, 1.5030,
         2.2414, 2.2214, 2.2097, 2.2276, 2.2734, 2.2926, 2.2550, 2.3635, 2.3614,
         1.4216, 1.4130, 1.4269, 1.4373, 1.4251, 1.4346, 1.4046, 1.4309, 1.4374],
        [1.3846, 1.2868, 1.2846, 1.3018, 1.2962, 1.3049, 1.3041, 1.2362, 1.2362,
         1.2567, 1.2221, 1.2204, 1.2253, 1.2959, 1.1857, 1.1550, 1.2959, 1.2075,
         1.6326, 1.6115, 1.5911, 1.5917, 1.6121, 1.6087, 1.6257, 1.6132, 1.6132,
         1.3633, 1.3377, 1.3365, 1.3540, 1.3435, 1.3806, 1.3827, 1.3570, 1.3365,
         1.6024, 1.5996, 1.6071, 1.5969, 1.5765, 1.5771, 1.6332, 1.5345, 1.5032,
         3.8583, 3.7428, 3.7702, 3.7676, 3.7602, 3.6505, 3.8530, 3.7634, 3.6666]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 62 : 1779.6023961596916
Test loss for epoch 62 : 194.61636834148106
Test Precision for epoch 62 : 0.26153846153846155
Test Recall for epoch 62 : 0.26153846153846155
Test F1 for epoch 62 : 0.26153846153846155


theta for epoch 63 : tensor([[3.6272, 3.6300, 3.6946, 3.6732, 3.6667, 3.6121, 3.6329, 3.5750, 3.5750,
         1.2856, 1.2651, 1.2638, 1.2668, 1.3070, 1.2458, 1.2178, 1.3070, 1.2519,
         1.6240, 1.6080, 1.6323, 1.6116, 1.6182, 1.6197, 1.6295, 1.6197, 1.6197,
         1.3680, 1.3772, 1.3556, 1.3867, 1.3636, 1.4029, 1.3933, 1.3758, 1.3556,
         1.6188, 1.6361, 1.6236, 1.6203, 1.6275, 1.6183, 1.6373, 1.5897, 1.5944,
         1.2732, 1.3016, 1.2929, 1.3111, 1.2680, 1.2590, 1.2491, 1.3345, 1.2892],
        [1.4048, 1.2618, 1.2527, 1.2937, 1.2941, 1.3057, 1.2997, 1.2077, 1.2077,
         3.7624, 3.7868, 3.7396, 3.8502, 3.7645, 3.9303, 3.7145, 3.7517, 3.8726,
         1.6037, 1.5928, 1.5668, 1.5684, 1.5874, 1.5965, 1.6185, 1.5964, 1.5964,
         1.3795, 1.3486, 1.3458, 1.3954, 1.3431, 1.4280, 1.4110, 1.3840, 1.3426,
         1.5581, 1.6110, 1.5769, 1.5640, 1.5579, 1.5945, 1.6126, 1.4557, 1.5466,
         1.1928, 1.2926, 1.2700, 1.3117, 1.1894, 1.1980, 1.1325, 1.3643, 1.2620],
        [1.4679, 1.4678, 1.4660, 1.4633, 1.4633, 1.4679, 1.4636, 1.4678, 1.4678,
         1.4376, 1.4372, 1.4378, 1.4378, 1.4374, 1.4178, 1.4383, 1.4363, 1.4342,
         2.2286, 2.2309, 2.2483, 2.2332, 2.2115, 2.2099, 2.2403, 2.2083, 2.2083,
         1.4983, 1.4972, 1.5044, 1.5045, 1.4983, 1.5046, 1.5045, 1.5045, 1.5044,
         1.7794, 1.7794, 1.7795, 1.7763, 1.7794, 1.7794, 1.7794, 1.7549, 1.7581,
         1.4321, 1.4369, 1.4370, 1.4369, 1.4288, 1.4371, 1.4329, 1.4368, 1.4370],
        [1.3410, 1.3375, 1.3217, 1.3140, 1.3368, 1.3353, 1.3364, 1.3355, 1.3355,
         1.2977, 1.2919, 1.2880, 1.2874, 1.2977, 1.2844, 1.2977, 1.2974, 1.2710,
         1.6344, 1.6089, 1.6319, 1.6317, 1.6305, 1.6306, 1.6329, 1.6343, 1.6343,
         3.4784, 3.3412, 3.2826, 3.3335, 3.4317, 3.3104, 3.4707, 3.2923, 3.2717,
         1.6490, 1.6409, 1.6400, 1.6436, 1.6465, 1.6222, 1.6470, 1.5874, 1.6146,
         1.2992, 1.2933, 1.2840, 1.2976, 1.2946, 1.2873, 1.2992, 1.2972, 1.3005],
        [1.4715, 1.4656, 1.4199, 1.4270, 1.4643, 1.4713, 1.4694, 1.4712, 1.4712,
         1.4392, 1.4368, 1.4320, 1.4260, 1.4397, 1.3978, 1.4352, 1.4396, 1.4356,
         1.7493, 1.7398, 1.7386, 1.7466, 1.7652, 1.7634, 1.7427, 1.7653, 1.7653,
         1.4652, 1.4672, 1.5080, 1.5023, 1.4705, 1.5067, 1.4950, 1.5083, 1.5051,
         2.2370, 2.2167, 2.2050, 2.2231, 2.2692, 2.2882, 2.2504, 2.3600, 2.3578,
         1.4231, 1.4149, 1.4287, 1.4391, 1.4266, 1.4363, 1.4059, 1.4328, 1.4392],
        [1.3926, 1.2933, 1.2913, 1.3085, 1.3030, 1.3116, 1.3109, 1.2418, 1.2418,
         1.2689, 1.2343, 1.2327, 1.2375, 1.3080, 1.1979, 1.1687, 1.3080, 1.2197,
         1.6369, 1.6158, 1.5949, 1.5958, 1.6160, 1.6126, 1.6299, 1.6171, 1.6171,
         1.3710, 1.3454, 1.3433, 1.3620, 1.3510, 1.3889, 1.3908, 1.3646, 1.3434,
         1.6052, 1.6027, 1.6098, 1.5997, 1.5788, 1.5796, 1.6363, 1.5370, 1.5059,
         3.8481, 3.7296, 3.7577, 3.7550, 3.7476, 3.6352, 3.8427, 3.7507, 3.6515]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 63 : 1779.1974809352182
Test loss for epoch 63 : 194.72897993712445
Test Precision for epoch 63 : 0.26153846153846155
Test Recall for epoch 63 : 0.26153846153846155
Test F1 for epoch 63 : 0.26153846153846155


theta for epoch 64 : tensor([[3.6222, 3.6254, 3.6915, 3.6694, 3.6630, 3.6069, 3.6282, 3.5690, 3.5690,
         1.2906, 1.2707, 1.2694, 1.2722, 1.3115, 1.2516, 1.2251, 1.3115, 1.2577,
         1.6213, 1.6054, 1.6295, 1.6090, 1.6157, 1.6171, 1.6269, 1.6171, 1.6171,
         1.3641, 1.3734, 1.3524, 1.3826, 1.3600, 1.3983, 1.3890, 1.3719, 1.3524,
         1.6151, 1.6323, 1.6199, 1.6166, 1.6238, 1.6146, 1.6336, 1.5860, 1.5907,
         1.2779, 1.3063, 1.2976, 1.3158, 1.2727, 1.2638, 1.2537, 1.3391, 1.2939],
        [1.4100, 1.2668, 1.2577, 1.2988, 1.2992, 1.3108, 1.3047, 1.2128, 1.2128,
         3.7536, 3.7785, 3.7303, 3.8434, 3.7557, 3.9254, 3.7046, 3.7425, 3.8664,
         1.6108, 1.6001, 1.5743, 1.5758, 1.5946, 1.6036, 1.6256, 1.6036, 1.6036,
         1.3847, 1.3541, 1.3508, 1.4006, 1.3483, 1.4331, 1.4161, 1.3891, 1.3477,
         1.5643, 1.6167, 1.5829, 1.5702, 1.5642, 1.6003, 1.6183, 1.4628, 1.5532,
         1.2066, 1.3060, 1.2834, 1.3249, 1.2032, 1.2116, 1.1461, 1.3772, 1.2754],
        [1.4662, 1.4661, 1.4643, 1.4616, 1.4616, 1.4662, 1.4619, 1.4661, 1.4661,
         1.4408, 1.4404, 1.4410, 1.4410, 1.4407, 1.4211, 1.4415, 1.4395, 1.4374,
         2.2236, 2.2259, 2.2434, 2.2277, 2.2059, 2.2043, 2.2348, 2.2027, 2.2027,
         1.4984, 1.4972, 1.5045, 1.5046, 1.4983, 1.5047, 1.5046, 1.5046, 1.5045,
         1.7744, 1.7744, 1.7745, 1.7712, 1.7744, 1.7744, 1.7744, 1.7499, 1.7530,
         1.4370, 1.4418, 1.4419, 1.4418, 1.4337, 1.4420, 1.4377, 1.4417, 1.4419],
        [1.3408, 1.3371, 1.3211, 1.3133, 1.3364, 1.3349, 1.3359, 1.3350, 1.3350,
         1.3018, 1.2959, 1.2921, 1.2914, 1.3018, 1.2884, 1.3018, 1.3015, 1.2751,
         1.6325, 1.6069, 1.6299, 1.6297, 1.6286, 1.6286, 1.6309, 1.6323, 1.6323,
         3.4771, 3.3368, 3.2771, 3.3288, 3.4295, 3.3050, 3.4689, 3.2868, 3.2661,
         1.6447, 1.6367, 1.6356, 1.6392, 1.6421, 1.6178, 1.6427, 1.5829, 1.6101,
         1.3049, 1.2991, 1.2898, 1.3035, 1.3004, 1.2930, 1.3048, 1.3032, 1.3063],
        [1.4698, 1.4637, 1.4172, 1.4245, 1.4624, 1.4695, 1.4676, 1.4695, 1.4695,
         1.4424, 1.4400, 1.4352, 1.4291, 1.4429, 1.4008, 1.4384, 1.4429, 1.4387,
         1.7463, 1.7368, 1.7354, 1.7435, 1.7622, 1.7604, 1.7397, 1.7623, 1.7623,
         1.4650, 1.4665, 1.5081, 1.5022, 1.4702, 1.5066, 1.4949, 1.5083, 1.5051,
         2.2321, 2.2114, 2.1997, 2.2180, 2.2645, 2.2832, 2.2453, 2.3560, 2.3535,
         1.4278, 1.4199, 1.4337, 1.4441, 1.4313, 1.4412, 1.4104, 1.4378, 1.4442],
        [1.3981, 1.2978, 1.2960, 1.3131, 1.3076, 1.3162, 1.3155, 1.2458, 1.2458,
         1.2804, 1.2461, 1.2445, 1.2493, 1.3190, 1.2097, 1.1826, 1.3190, 1.2317,
         1.6408, 1.6197, 1.5984, 1.5994, 1.6194, 1.6161, 1.6338, 1.6206, 1.6206,
         1.3768, 1.3511, 1.3482, 1.3678, 1.3564, 1.3952, 1.3968, 1.3702, 1.3482,
         1.6072, 1.6050, 1.6117, 1.6017, 1.5804, 1.5813, 1.6386, 1.5387, 1.5078,
         3.8392, 3.7176, 3.7464, 3.7436, 3.7362, 3.6211, 3.8337, 3.7391, 3.6377]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 64 : 1779.6735920213225
Test loss for epoch 64 : 194.3247634728798
Test Precision for epoch 64 : 0.26153846153846155
Test Recall for epoch 64 : 0.26153846153846155
Test F1 for epoch 64 : 0.26153846153846155


theta for epoch 65 : tensor([[3.6198, 3.6233, 3.6908, 3.6682, 3.6618, 3.6043, 3.6260, 3.5657, 3.5657,
         1.2931, 1.2736, 1.2724, 1.2750, 1.3135, 1.2547, 1.2295, 1.3135, 1.2608,
         1.6190, 1.6032, 1.6271, 1.6068, 1.6135, 1.6150, 1.6246, 1.6149, 1.6149,
         1.3578, 1.3672, 1.3471, 1.3761, 1.3542, 1.3912, 1.3822, 1.3656, 1.3471,
         1.6120, 1.6292, 1.6168, 1.6135, 1.6207, 1.6115, 1.6305, 1.5829, 1.5876,
         1.2828, 1.3111, 1.3024, 1.3205, 1.2776, 1.2688, 1.2585, 1.3437, 1.2988],
        [1.4091, 1.2650, 1.2559, 1.2971, 1.2976, 1.3091, 1.3031, 1.2108, 1.2108,
         3.7501, 3.7756, 3.7263, 3.8420, 3.7522, 3.9258, 3.7002, 3.7387, 3.8656,
         1.6149, 1.6043, 1.5788, 1.5800, 1.5987, 1.6077, 1.6297, 1.6077, 1.6077,
         1.3832, 1.3527, 1.3489, 1.3991, 1.3465, 1.4319, 1.4147, 1.3875, 1.3457,
         1.5683, 1.6203, 1.5867, 1.5741, 1.5683, 1.6040, 1.6221, 1.4674, 1.5575,
         1.2168, 1.3162, 1.2935, 1.3351, 1.2133, 1.2215, 1.1558, 1.3874, 1.2854],
        [1.4636, 1.4635, 1.4616, 1.4589, 1.4589, 1.4636, 1.4593, 1.4635, 1.4635,
         1.4423, 1.4418, 1.4424, 1.4424, 1.4421, 1.4225, 1.4429, 1.4409, 1.4388,
         2.2197, 2.2220, 2.2395, 2.2232, 2.2013, 2.1997, 2.2303, 2.1982, 2.1982,
         1.4975, 1.4963, 1.5037, 1.5038, 1.4974, 1.5038, 1.5038, 1.5037, 1.5037,
         1.7706, 1.7706, 1.7707, 1.7674, 1.7706, 1.7706, 1.7706, 1.7461, 1.7492,
         1.4429, 1.4477, 1.4478, 1.4477, 1.4395, 1.4479, 1.4435, 1.4476, 1.4478],
        [1.3395, 1.3357, 1.3195, 1.3116, 1.3349, 1.3335, 1.3345, 1.3334, 1.3334,
         1.3040, 1.2981, 1.2943, 1.2936, 1.3040, 1.2906, 1.3040, 1.3037, 1.2773,
         1.6318, 1.6060, 1.6291, 1.6289, 1.6278, 1.6279, 1.6302, 1.6316, 1.6316,
         3.4747, 3.3311, 3.2704, 3.3229, 3.4261, 3.2984, 3.4660, 3.2801, 3.2592,
         1.6417, 1.6336, 1.6325, 1.6361, 1.6390, 1.6147, 1.6396, 1.5797, 1.6069,
         1.3116, 1.3060, 1.2966, 1.3104, 1.3071, 1.2997, 1.3114, 1.3102, 1.3132],
        [1.4671, 1.4608, 1.4136, 1.4212, 1.4595, 1.4669, 1.4649, 1.4669, 1.4669,
         1.4438, 1.4413, 1.4365, 1.4304, 1.4443, 1.4019, 1.4397, 1.4443, 1.4399,
         1.7445, 1.7351, 1.7334, 1.7416, 1.7605, 1.7586, 1.7380, 1.7606, 1.7606,
         1.4638, 1.4649, 1.5072, 1.5012, 1.4689, 1.5057, 1.4940, 1.5074, 1.5042,
         2.2282, 2.2071, 2.1955, 2.2140, 2.2607, 2.2792, 2.2413, 2.3529, 2.3503,
         1.4335, 1.4259, 1.4397, 1.4501, 1.4370, 1.4470, 1.4159, 1.4439, 1.4502],
        [1.3994, 1.2984, 1.2966, 1.3138, 1.3082, 1.3168, 1.3161, 1.2460, 1.2460,
         1.2883, 1.2540, 1.2525, 1.2571, 1.3267, 1.2175, 1.1916, 1.3267, 1.2396,
         1.6436, 1.6224, 1.6009, 1.6019, 1.6218, 1.6185, 1.6366, 1.6230, 1.6230,
         1.3782, 1.3526, 1.3489, 1.3694, 1.3575, 1.3972, 1.3985, 1.3715, 1.3489,
         1.6086, 1.6067, 1.6131, 1.6032, 1.5814, 1.5825, 1.6404, 1.5399, 1.5091,
         3.8352, 3.7104, 3.7399, 3.7370, 3.7297, 3.6119, 3.8296, 3.7323, 3.6288]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 65 : 1780.0091884638614
Test loss for epoch 65 : 194.25715571785042
Test Precision for epoch 65 : 0.26153846153846155
Test Recall for epoch 65 : 0.26153846153846155
Test F1 for epoch 65 : 0.26153846153846155


theta for epoch 66 : tensor([[3.6213, 3.6253, 3.6943, 3.6710, 3.6647, 3.6058, 3.6280, 3.5666, 3.5666,
         1.2918, 1.2728, 1.2716, 1.2740, 1.3118, 1.2540, 1.2298, 1.3118, 1.2601,
         1.6176, 1.6020, 1.6257, 1.6055, 1.6124, 1.6138, 1.6233, 1.6138, 1.6138,
         1.3536, 1.3631, 1.3441, 1.3718, 1.3506, 1.3862, 1.3776, 1.3616, 1.3441,
         1.6104, 1.6276, 1.6153, 1.6120, 1.6192, 1.6100, 1.6289, 1.5814, 1.5861,
         1.2843, 1.3125, 1.3038, 1.3218, 1.2792, 1.2705, 1.2599, 1.3447, 1.3002],
        [1.4057, 1.2598, 1.2507, 1.2923, 1.2928, 1.3044, 1.2983, 1.2051, 1.2051,
         3.7507, 3.7769, 3.7265, 3.8446, 3.7527, 3.9302, 3.7001, 3.7389, 3.8688,
         1.6168, 1.6062, 1.5810, 1.5819, 1.6005, 1.6095, 1.6317, 1.6095, 1.6095,
         1.3790, 1.3486, 1.3439, 1.3950, 1.3419, 1.4283, 1.4109, 1.3832, 1.3407,
         1.5712, 1.6230, 1.5894, 1.5770, 1.5713, 1.6067, 1.6249, 1.4705, 1.5607,
         1.2206, 1.3204, 1.2975, 1.3394, 1.2169, 1.2247, 1.1588, 1.3920, 1.2893],
        [1.4637, 1.4636, 1.4617, 1.4589, 1.4589, 1.4637, 1.4593, 1.4637, 1.4637,
         1.4406, 1.4401, 1.4408, 1.4408, 1.4404, 1.4209, 1.4412, 1.4392, 1.4372,
         2.2173, 2.2196, 2.2371, 2.2201, 2.1982, 2.1966, 2.2272, 2.1950, 2.1950,
         1.4998, 1.4986, 1.5060, 1.5061, 1.4998, 1.5061, 1.5061, 1.5061, 1.5060,
         1.7689, 1.7689, 1.7690, 1.7657, 1.7689, 1.7689, 1.7689, 1.7444, 1.7475,
         1.4461, 1.4510, 1.4511, 1.4510, 1.4428, 1.4511, 1.4466, 1.4509, 1.4511],
        [1.3409, 1.3369, 1.3205, 1.3126, 1.3361, 1.3347, 1.3357, 1.3346, 1.3346,
         1.3032, 1.2973, 1.2935, 1.2928, 1.3033, 1.2896, 1.3030, 1.3029, 1.2764,
         1.6328, 1.6069, 1.6300, 1.6298, 1.6288, 1.6288, 1.6312, 1.6325, 1.6325,
         3.4742, 3.3275, 3.2659, 3.3190, 3.4247, 3.2939, 3.4649, 3.2756, 3.2544,
         1.6407, 1.6327, 1.6315, 1.6351, 1.6380, 1.6138, 1.6386, 1.5785, 1.6058,
         1.3156, 1.3102, 1.3008, 1.3147, 1.3112, 1.3036, 1.3154, 1.3145, 1.3173],
        [1.4671, 1.4606, 1.4128, 1.4207, 1.4594, 1.4669, 1.4649, 1.4669, 1.4669,
         1.4422, 1.4397, 1.4348, 1.4286, 1.4427, 1.4000, 1.4380, 1.4427, 1.4381,
         1.7444, 1.7351, 1.7331, 1.7414, 1.7604, 1.7585, 1.7379, 1.7605, 1.7605,
         1.4658, 1.4666, 1.5094, 1.5034, 1.4709, 1.5079, 1.4962, 1.5096, 1.5065,
         2.2262, 2.2047, 2.1931, 2.2119, 2.2588, 2.2771, 2.2391, 2.3517, 2.3489,
         1.4366, 1.4292, 1.4430, 1.4535, 1.4401, 1.4503, 1.4187, 1.4473, 1.4535],
        [1.4001, 1.2985, 1.2967, 1.3140, 1.3083, 1.3170, 1.3163, 1.2459, 1.2459,
         1.2915, 1.2569, 1.2554, 1.2601, 1.3299, 1.2202, 1.1950, 1.3299, 1.2425,
         1.6460, 1.6247, 1.6030, 1.6040, 1.6237, 1.6206, 1.6389, 1.6250, 1.6250,
         1.3796, 1.3539, 1.3495, 1.3709, 1.3584, 1.3990, 1.4002, 1.3727, 1.3495,
         1.6106, 1.6090, 1.6150, 1.6052, 1.5830, 1.5843, 1.6427, 1.5416, 1.5109,
         3.8335, 3.7057, 3.7358, 3.7329, 3.7256, 3.6052, 3.8278, 3.7279, 3.6224]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 66 : 1780.088778441492
Test loss for epoch 66 : 194.32807342503722
Test Precision for epoch 66 : 0.26153846153846155
Test Recall for epoch 66 : 0.26153846153846155
Test F1 for epoch 66 : 0.26153846153846155


theta for epoch 67 : tensor([[3.6270, 3.6315, 3.7018, 3.6780, 3.6717, 3.6114, 3.6341, 3.5718, 3.5718,
         1.2874, 1.2687, 1.2675, 1.2698, 1.3069, 1.2500, 1.2267, 1.3069, 1.2561,
         1.6172, 1.6016, 1.6252, 1.6053, 1.6122, 1.6136, 1.6230, 1.6136, 1.6136,
         1.3532, 1.3629, 1.3449, 1.3712, 1.3507, 1.3848, 1.3766, 1.3613, 1.3450,
         1.6106, 1.6276, 1.6155, 1.6122, 1.6193, 1.6101, 1.6289, 1.5815, 1.5863,
         1.2809, 1.3089, 1.3003, 1.3181, 1.2760, 1.2673, 1.2565, 1.3408, 1.2968],
        [1.4008, 1.2524, 1.2433, 1.2853, 1.2858, 1.2976, 1.2913, 1.1967, 1.1967,
         3.7552, 3.7819, 3.7305, 3.8511, 3.7571, 3.9384, 3.7037, 3.7429, 3.8759,
         1.6168, 1.6062, 1.5811, 1.5816, 1.6002, 1.6093, 1.6317, 1.6092, 1.6092,
         1.3739, 1.3432, 1.3375, 1.3900, 1.3360, 1.4241, 1.4062, 1.3779, 1.3343,
         1.5732, 1.6251, 1.5914, 1.5790, 1.5735, 1.6087, 1.6270, 1.4726, 1.5631,
         1.2170, 1.3176, 1.2943, 1.3368, 1.2130, 1.2205, 1.1542, 1.3900, 1.2860],
        [1.4670, 1.4669, 1.4650, 1.4622, 1.4622, 1.4670, 1.4626, 1.4670, 1.4670,
         1.4365, 1.4359, 1.4366, 1.4366, 1.4363, 1.4167, 1.4370, 1.4351, 1.4330,
         2.2163, 2.2186, 2.2362, 2.2185, 2.1965, 2.1949, 2.2255, 2.1933, 2.1933,
         1.5066, 1.5054, 1.5128, 1.5128, 1.5065, 1.5129, 1.5128, 1.5128, 1.5128,
         1.7694, 1.7694, 1.7694, 1.7661, 1.7693, 1.7693, 1.7694, 1.7449, 1.7479,
         1.4451, 1.4501, 1.4502, 1.4501, 1.4418, 1.4502, 1.4456, 1.4501, 1.4502],
        [1.3453, 1.3412, 1.3247, 1.3167, 1.3405, 1.3390, 1.3400, 1.3389, 1.3389,
         1.2999, 1.2939, 1.2901, 1.2894, 1.3000, 1.2862, 1.2995, 1.2996, 1.2730,
         1.6354, 1.6094, 1.6326, 1.6323, 1.6314, 1.6314, 1.6337, 1.6351, 1.6351,
         3.4768, 3.3271, 3.2645, 3.3182, 3.4264, 3.2926, 3.4669, 3.2742, 3.2529,
         1.6419, 1.6340, 1.6327, 1.6363, 1.6392, 1.6149, 1.6398, 1.5796, 1.6069,
         1.3154, 1.3101, 1.3007, 1.3147, 1.3110, 1.3034, 1.3151, 1.3146, 1.3172],
        [1.4703, 1.4637, 1.4154, 1.4234, 1.4625, 1.4701, 1.4681, 1.4702, 1.4702,
         1.4380, 1.4355, 1.4306, 1.4243, 1.4386, 1.3955, 1.4337, 1.4386, 1.4338,
         1.7459, 1.7367, 1.7345, 1.7429, 1.7620, 1.7601, 1.7395, 1.7621, 1.7621,
         1.4723, 1.4729, 1.5161, 1.5100, 1.4774, 1.5145, 1.5028, 1.5163, 1.5131,
         2.2261, 2.2043, 2.1927, 2.2117, 2.2589, 2.2768, 2.2388, 2.3524, 2.3494,
         1.4354, 1.4284, 1.4422, 1.4526, 1.4390, 1.4494, 1.4173, 1.4465, 1.4527],
        [1.4008, 1.2989, 1.2971, 1.3144, 1.3087, 1.3175, 1.3168, 1.2464, 1.2464,
         1.2905, 1.2555, 1.2540, 1.2588, 1.3291, 1.2185, 1.1934, 1.3291, 1.2410,
         1.6481, 1.6267, 1.6048, 1.6057, 1.6253, 1.6222, 1.6409, 1.6266, 1.6266,
         1.3823, 1.3565, 1.3517, 1.3737, 1.3606, 1.4021, 1.4031, 1.3753, 1.3517,
         1.6133, 1.6118, 1.6176, 1.6078, 1.5852, 1.5867, 1.6457, 1.5439, 1.5132,
         3.8331, 3.7022, 3.7331, 3.7300, 3.7228, 3.5999, 3.8274, 3.7249, 3.6172]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 67 : 1779.741519603387
Test loss for epoch 67 : 194.4892490549505
Test Precision for epoch 67 : 0.26153846153846155
Test Recall for epoch 67 : 0.26153846153846155
Test F1 for epoch 67 : 0.26153846153846155


theta for epoch 68 : tensor([[3.6350, 3.6400, 3.7116, 3.6872, 3.6810, 3.6194, 3.6425, 3.5793, 3.5793,
         1.2815, 1.2631, 1.2620, 1.2641, 1.3007, 1.2444, 1.2218, 1.3008, 1.2506,
         1.6171, 1.6016, 1.6249, 1.6054, 1.6123, 1.6138, 1.6230, 1.6137, 1.6137,
         1.3535, 1.3634, 1.3466, 1.3713, 1.3517, 1.3842, 1.3764, 1.3619, 1.3467,
         1.6116, 1.6286, 1.6165, 1.6133, 1.6203, 1.6111, 1.6298, 1.5826, 1.5873,
         1.2751, 1.3028, 1.2943, 1.3119, 1.2702, 1.2617, 1.2507, 1.3343, 1.2909],
        [1.3922, 1.2406, 1.2315, 1.2742, 1.2747, 1.2866, 1.2802, 1.1838, 1.1838,
         3.7637, 3.7911, 3.7386, 3.8616, 3.7656, 3.9507, 3.7116, 3.7511, 3.8870,
         1.6146, 1.6038, 1.5789, 1.5789, 1.5975, 1.6066, 1.6296, 1.6066, 1.6066,
         1.3659, 1.3350, 1.3281, 1.3823, 1.3271, 1.4173, 1.3989, 1.3698, 1.3249,
         1.5740, 1.6260, 1.5921, 1.5797, 1.5743, 1.6096, 1.6281, 1.4732, 1.5641,
         1.2084, 1.3103, 1.2865, 1.3297, 1.2042, 1.2113, 1.1446, 1.3838, 1.2780],
        [1.4703, 1.4702, 1.4682, 1.4654, 1.4654, 1.4703, 1.4659, 1.4703, 1.4703,
         1.4315, 1.4309, 1.4316, 1.4316, 1.4313, 1.4117, 1.4320, 1.4301, 1.4280,
         2.2162, 2.2185, 2.2360, 2.2176, 2.1956, 2.1940, 2.2246, 2.1925, 2.1925,
         1.5147, 1.5135, 1.5209, 1.5210, 1.5147, 1.5210, 1.5210, 1.5210, 1.5209,
         1.7712, 1.7712, 1.7713, 1.7680, 1.7712, 1.7712, 1.7712, 1.7467, 1.7497,
         1.4422, 1.4473, 1.4473, 1.4473, 1.4389, 1.4473, 1.4426, 1.4473, 1.4473],
        [1.3494, 1.3453, 1.3286, 1.3205, 1.3445, 1.3431, 1.3441, 1.3431, 1.3431,
         1.2957, 1.2896, 1.2859, 1.2851, 1.2958, 1.2818, 1.2951, 1.2955, 1.2687,
         1.6388, 1.6127, 1.6359, 1.6357, 1.6348, 1.6348, 1.6371, 1.6385, 1.6385,
         3.4803, 3.3277, 3.2643, 3.3185, 3.4290, 3.2923, 3.4698, 3.2739, 3.2525,
         1.6445, 1.6366, 1.6352, 1.6388, 1.6417, 1.6175, 1.6424, 1.5820, 1.6093,
         1.3132, 1.3080, 1.2986, 1.3127, 1.3089, 1.3011, 1.3128, 1.3128, 1.3151],
        [1.4735, 1.4668, 1.4180, 1.4261, 1.4655, 1.4733, 1.4712, 1.4734, 1.4734,
         1.4330, 1.4304, 1.4256, 1.4192, 1.4337, 1.3902, 1.4287, 1.4336, 1.4287,
         1.7483, 1.7391, 1.7367, 1.7452, 1.7645, 1.7625, 1.7419, 1.7646, 1.7646,
         1.4802, 1.4805, 1.5242, 1.5180, 1.4853, 1.5225, 1.5108, 1.5243, 1.5212,
         2.2272, 2.2051, 2.1934, 2.2127, 2.2601, 2.2778, 2.2397, 2.3543, 2.3511,
         1.4323, 1.4256, 1.4394, 1.4499, 1.4359, 1.4465, 1.4140, 1.4437, 1.4499],
        [1.3985, 1.2968, 1.2948, 1.3121, 1.3063, 1.3152, 1.3145, 1.2445, 1.2445,
         1.2872, 1.2515, 1.2501, 1.2549, 1.3261, 1.2142, 1.1887, 1.3261, 1.2369,
         1.6491, 1.6276, 1.6056, 1.6064, 1.6260, 1.6230, 1.6419, 1.6273, 1.6273,
         1.3838, 1.3578, 1.3527, 1.3751, 1.3615, 1.4038, 1.4047, 1.3766, 1.3527,
         1.6159, 1.6146, 1.6202, 1.6104, 1.5874, 1.5890, 1.6486, 1.5461, 1.5154,
         3.8352, 3.7012, 3.7327, 3.7295, 3.7224, 3.5970, 3.8294, 3.7242, 3.6145]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 68 : 1779.318619856238
Test loss for epoch 68 : 194.88875735446334
Test Precision for epoch 68 : 0.26153846153846155
Test Recall for epoch 68 : 0.26153846153846155
Test F1 for epoch 68 : 0.26153846153846155


theta for epoch 69 : tensor([[3.6394, 3.6449, 3.7178, 3.6928, 3.6867, 3.6238, 3.6474, 3.5832, 3.5832,
         1.2765, 1.2585, 1.2574, 1.2594, 1.2953, 1.2400, 1.2183, 1.2953, 1.2461,
         1.6172, 1.6019, 1.6250, 1.6058, 1.6128, 1.6142, 1.6232, 1.6142, 1.6142,
         1.3527, 1.3627, 1.3472, 1.3703, 1.3515, 1.3824, 1.3750, 1.3612, 1.3473,
         1.6130, 1.6298, 1.6179, 1.6147, 1.6217, 1.6123, 1.6310, 1.5839, 1.5887,
         1.2709, 1.2983, 1.2900, 1.3073, 1.2662, 1.2579, 1.2466, 1.3294, 1.2866],
        [1.4091, 1.2567, 1.2478, 1.2903, 1.2908, 1.3027, 1.2964, 1.1995, 1.1995,
         3.7419, 3.7698, 3.7163, 3.8417, 3.7437, 3.9326, 3.6888, 3.7289, 3.8678,
         1.6263, 1.6155, 1.5910, 1.5904, 1.6089, 1.6180, 1.6412, 1.6179, 1.6179,
         1.3814, 1.3507, 1.3427, 1.3979, 1.3423, 1.4334, 1.4147, 1.3851, 1.3394,
         1.5863, 1.6381, 1.6042, 1.5920, 1.5869, 1.6217, 1.6404, 1.4863, 1.5769,
         1.2159, 1.3181, 1.2941, 1.3377, 1.2114, 1.2179, 1.1513, 1.3924, 1.2855],
        [1.4711, 1.4710, 1.4691, 1.4662, 1.4662, 1.4711, 1.4667, 1.4712, 1.4712,
         1.4272, 1.4266, 1.4273, 1.4273, 1.4270, 1.4073, 1.4276, 1.4258, 1.4237,
         2.2162, 2.2184, 2.2360, 2.2168, 2.1948, 2.1932, 2.2238, 2.1916, 2.1916,
         1.5205, 1.5193, 1.5267, 1.5267, 1.5204, 1.5268, 1.5267, 1.5267, 1.5267,
         1.7731, 1.7732, 1.7732, 1.7699, 1.7731, 1.7731, 1.7731, 1.7487, 1.7516,
         1.4405, 1.4457, 1.4457, 1.4457, 1.4372, 1.4457, 1.4408, 1.4456, 1.4457],
        [1.3508, 1.3469, 1.3300, 1.3218, 1.3460, 1.3445, 1.3455, 1.3446, 1.3446,
         1.2922, 1.2860, 1.2824, 1.2815, 1.2924, 1.2781, 1.2914, 1.2920, 1.2650,
         1.6423, 1.6160, 1.6393, 1.6390, 1.6382, 1.6381, 1.6405, 1.6419, 1.6419,
         3.4818, 3.3263, 3.2620, 3.3169, 3.4297, 3.2900, 3.4708, 3.2716, 3.2500,
         1.6471, 1.6393, 1.6378, 1.6413, 1.6443, 1.6201, 1.6450, 1.5845, 1.6118,
         1.3122, 1.3072, 1.2977, 1.3119, 1.3079, 1.3001, 1.3118, 1.3121, 1.3142],
        [1.4742, 1.4675, 1.4183, 1.4265, 1.4662, 1.4741, 1.4720, 1.4742, 1.4742,
         1.4287, 1.4261, 1.4212, 1.4148, 1.4294, 1.3856, 1.4243, 1.4294, 1.4242,
         1.7507, 1.7417, 1.7390, 1.7476, 1.7670, 1.7650, 1.7444, 1.7671, 1.7671,
         1.4858, 1.4859, 1.5299, 1.5236, 1.4908, 1.5281, 1.5165, 1.5300, 1.5268,
         2.2283, 2.2059, 2.1942, 2.2137, 2.2614, 2.2787, 2.2407, 2.3561, 2.3527,
         1.4304, 1.4240, 1.4378, 1.4483, 1.4341, 1.4449, 1.4119, 1.4422, 1.4484],
        [1.3944, 1.2936, 1.2914, 1.3087, 1.3028, 1.3118, 1.3111, 1.2421, 1.2421,
         1.2844, 1.2485, 1.2470, 1.2519, 1.3233, 1.2108, 1.1855, 1.3233, 1.2338,
         1.6502, 1.6285, 1.6065, 1.6072, 1.6267, 1.6238, 1.6429, 1.6280, 1.6280,
         1.3837, 1.3577, 1.3525, 1.3750, 1.3611, 1.4038, 1.4047, 1.3765, 1.3525,
         1.6186, 1.6174, 1.6228, 1.6131, 1.5897, 1.5914, 1.6515, 1.5484, 1.5177,
         3.8365, 3.6994, 3.7317, 3.7284, 3.7214, 3.5934, 3.8306, 3.7228, 3.6111]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 69 : 1780.4108728432302
Test loss for epoch 69 : 194.02148716239495
Test Precision for epoch 69 : 0.26153846153846155
Test Recall for epoch 69 : 0.26153846153846155
Test F1 for epoch 69 : 0.26153846153846155


theta for epoch 70 : tensor([[3.6419, 3.6479, 3.7221, 3.6965, 3.6905, 3.6263, 3.6503, 3.5852, 3.5852,
         1.2761, 1.2584, 1.2573, 1.2592, 1.2945, 1.2399, 1.2188, 1.2945, 1.2461,
         1.6156, 1.6003, 1.6233, 1.6044, 1.6115, 1.6129, 1.6217, 1.6129, 1.6129,
         1.3443, 1.3545, 1.3402, 1.3618, 1.3437, 1.3731, 1.3661, 1.3530, 1.3402,
         1.6126, 1.6292, 1.6175, 1.6143, 1.6212, 1.6119, 1.6304, 1.5835, 1.5882,
         1.2688, 1.2960, 1.2877, 1.3049, 1.2642, 1.2560, 1.2445, 1.3266, 1.2844],
        [1.4142, 1.2607, 1.2520, 1.2944, 1.2949, 1.3067, 1.3004, 1.2029, 1.2029,
         3.7299, 3.7584, 3.7038, 3.8317, 3.7317, 3.9243, 3.6760, 3.7166, 3.8583,
         1.6324, 1.6215, 1.5974, 1.5962, 1.6146, 1.6237, 1.6473, 1.6236, 1.6236,
         1.3849, 1.3542, 1.3451, 1.4015, 1.3454, 1.4375, 1.4186, 1.3883, 1.3418,
         1.5935, 1.6452, 1.6113, 1.5992, 1.5943, 1.6289, 1.6477, 1.4940, 1.5845,
         1.2209, 1.3240, 1.2996, 1.3438, 1.2161, 1.2221, 1.1554, 1.3992, 1.2908],
        [1.4658, 1.4657, 1.4637, 1.4608, 1.4608, 1.4658, 1.4614, 1.4658, 1.4658,
         1.4278, 1.4272, 1.4279, 1.4279, 1.4277, 1.4080, 1.4282, 1.4264, 1.4243,
         2.2149, 2.2171, 2.2347, 2.2149, 2.1929, 2.1912, 2.2218, 2.1897, 2.1897,
         1.5190, 1.5178, 1.5253, 1.5253, 1.5190, 1.5253, 1.5253, 1.5253, 1.5253,
         1.7737, 1.7737, 1.7738, 1.7704, 1.7737, 1.7737, 1.7737, 1.7492, 1.7522,
         1.4414, 1.4466, 1.4465, 1.4466, 1.4380, 1.4465, 1.4416, 1.4465, 1.4466],
        [1.3457, 1.3418, 1.3248, 1.3165, 1.3409, 1.3394, 1.3404, 1.3396, 1.3396,
         1.2936, 1.2874, 1.2838, 1.2829, 1.2939, 1.2794, 1.2926, 1.2935, 1.2664,
         1.6443, 1.6178, 1.6412, 1.6409, 1.6401, 1.6401, 1.6425, 1.6438, 1.6438,
         3.4779, 3.3194, 3.2542, 3.3097, 3.4248, 3.2823, 3.4663, 3.2638, 3.2421,
         1.6483, 1.6405, 1.6390, 1.6425, 1.6454, 1.6213, 1.6462, 1.5856, 1.6129,
         1.3137, 1.3088, 1.2992, 1.3136, 1.3094, 1.3015, 1.3132, 1.3138, 1.3158],
        [1.4688, 1.4620, 1.4124, 1.4207, 1.4607, 1.4687, 1.4666, 1.4688, 1.4688,
         1.4294, 1.4267, 1.4218, 1.4153, 1.4301, 1.3859, 1.4249, 1.4301, 1.4247,
         1.7518, 1.7428, 1.7399, 1.7487, 1.7682, 1.7662, 1.7456, 1.7683, 1.7683,
         1.4841, 1.4841, 1.5283, 1.5220, 1.4891, 1.5265, 1.5149, 1.5284, 1.5253,
         2.2280, 2.2053, 2.1936, 2.2133, 2.2612, 2.2782, 2.2402, 2.3565, 2.3529,
         1.4311, 1.4249, 1.4387, 1.4493, 1.4347, 1.4457, 1.4124, 1.4431, 1.4493],
        [1.3820, 1.2823, 1.2800, 1.2972, 1.2913, 1.3003, 1.2996, 1.2317, 1.2317,
         1.2851, 1.2486, 1.2472, 1.2522, 1.3241, 1.2106, 1.1850, 1.3241, 1.2338,
         1.6482, 1.6264, 1.6044, 1.6050, 1.6244, 1.6216, 1.6409, 1.6258, 1.6258,
         1.3745, 1.3485, 1.3433, 1.3658, 1.3515, 1.3946, 1.3955, 1.3673, 1.3434,
         1.6186, 1.6175, 1.6228, 1.6131, 1.5894, 1.5912, 1.6517, 1.5481, 1.5173,
         3.8425, 3.7024, 3.7353, 3.7319, 3.7250, 3.5946, 3.8365, 3.7260, 3.6124]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 70 : 1780.6649013760386
Test loss for epoch 70 : 193.94655338412193
Test Precision for epoch 70 : 0.26153846153846155
Test Recall for epoch 70 : 0.26153846153846155
Test F1 for epoch 70 : 0.26153846153846155


theta for epoch 71 : tensor([[3.6449, 3.6514, 3.7269, 3.7007, 3.6948, 3.6292, 3.6537, 3.5876, 3.5876,
         1.2801, 1.2625, 1.2614, 1.2633, 1.2982, 1.2440, 1.2232, 1.2982, 1.2503,
         1.6108, 1.5957, 1.6184, 1.5999, 1.6070, 1.6084, 1.6170, 1.6084, 1.6084,
         1.3347, 1.3451, 1.3319, 1.3522, 1.3347, 1.3628, 1.3561, 1.3437, 1.3319,
         1.6089, 1.6254, 1.6138, 1.6106, 1.6175, 1.6081, 1.6266, 1.5797, 1.5845,
         1.2666, 1.2935, 1.2853, 1.3023, 1.2620, 1.2540, 1.2423, 1.3238, 1.2820],
        [1.4121, 1.2571, 1.2485, 1.2910, 1.2915, 1.3033, 1.2970, 1.1988, 1.1988,
         3.7271, 3.7562, 3.7006, 3.8308, 3.7290, 3.9251, 3.6725, 3.7135, 3.8580,
         1.6319, 1.6210, 1.5971, 1.5953, 1.6136, 1.6228, 1.6468, 1.6227, 1.6227,
         1.3815, 1.3509, 1.3406, 1.3982, 1.3415, 1.4349, 1.4156, 1.3848, 1.3374,
         1.5943, 1.6461, 1.6119, 1.5999, 1.5952, 1.6298, 1.6488, 1.4949, 1.5856,
         1.2218, 1.3260, 1.3011, 1.3461, 1.2167, 1.2222, 1.1553, 1.4023, 1.2921],
        [1.4595, 1.4594, 1.4574, 1.4545, 1.4545, 1.4595, 1.4551, 1.4595, 1.4595,
         1.4332, 1.4325, 1.4333, 1.4333, 1.4331, 1.4133, 1.4336, 1.4318, 1.4297,
         2.2111, 2.2133, 2.2309, 2.2106, 2.1886, 2.1869, 2.2175, 2.1853, 2.1853,
         1.5162, 1.5150, 1.5226, 1.5226, 1.5162, 1.5226, 1.5225, 1.5226, 1.5226,
         1.7713, 1.7713, 1.7713, 1.7680, 1.7712, 1.7712, 1.7713, 1.7468, 1.7497,
         1.4423, 1.4476, 1.4476, 1.4476, 1.4390, 1.4476, 1.4425, 1.4476, 1.4476],
        [1.3395, 1.3356, 1.3185, 1.3102, 1.3347, 1.3332, 1.3342, 1.3334, 1.3334,
         1.2998, 1.2935, 1.2899, 1.2890, 1.3001, 1.2854, 1.2985, 1.2997, 1.2724,
         1.6434, 1.6168, 1.6403, 1.6399, 1.6392, 1.6392, 1.6416, 1.6429, 1.6429,
         3.4731, 3.3116, 3.2455, 3.3017, 3.4191, 3.2738, 3.4609, 3.2552, 3.2333,
         1.6465, 1.6388, 1.6371, 1.6407, 1.6436, 1.6195, 1.6444, 1.5836, 1.6110,
         1.3153, 1.3105, 1.3009, 1.3154, 1.3110, 1.3030, 1.3147, 1.3157, 1.3175],
        [1.4625, 1.4555, 1.4057, 1.4140, 1.4543, 1.4623, 1.4602, 1.4625, 1.4625,
         1.4347, 1.4320, 1.4271, 1.4205, 1.4355, 1.3910, 1.4302, 1.4355, 1.4300,
         1.7502, 1.7413, 1.7381, 1.7470, 1.7667, 1.7647, 1.7440, 1.7668, 1.7668,
         1.4811, 1.4810, 1.5255, 1.5191, 1.4862, 1.5237, 1.5120, 1.5256, 1.5224,
         2.2248, 2.2017, 2.1900, 2.2099, 2.2580, 2.2747, 2.2367, 2.3538, 2.3501,
         1.4319, 1.4259, 1.4397, 1.4504, 1.4355, 1.4467, 1.4129, 1.4443, 1.4504],
        [1.3670, 1.2683, 1.2657, 1.2829, 1.2769, 1.2861, 1.2853, 1.2185, 1.2185,
         1.2891, 1.2520, 1.2506, 1.2557, 1.3284, 1.2135, 1.1872, 1.3284, 1.2370,
         1.6421, 1.6202, 1.5982, 1.5985, 1.6180, 1.6152, 1.6347, 1.6194, 1.6194,
         1.3625, 1.3365, 1.3313, 1.3537, 1.3390, 1.3825, 1.3835, 1.3552, 1.3314,
         1.6144, 1.6134, 1.6186, 1.6089, 1.5849, 1.5868, 1.6478, 1.5435, 1.5126,
         3.8512, 3.7081, 3.7417, 3.7382, 3.7314, 3.5986, 3.8452, 3.7320, 3.6166]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 71 : 1780.3868711295422
Test loss for epoch 71 : 194.28144466905016
Test Precision for epoch 71 : 0.26153846153846155
Test Recall for epoch 71 : 0.26153846153846155
Test F1 for epoch 71 : 0.26153846153846155


theta for epoch 72 : tensor([[3.6514, 3.6585, 3.7352, 3.7084, 3.7026, 3.6358, 3.6606, 3.5938, 3.5938,
         1.2853, 1.2678, 1.2667, 1.2685, 1.3033, 1.2493, 1.2285, 1.3033, 1.2555,
         1.6042, 1.5891, 1.6118, 1.5935, 1.6006, 1.6020, 1.6105, 1.6020, 1.6020,
         1.3310, 1.3416, 1.3292, 1.3484, 1.3314, 1.3584, 1.3521, 1.3402, 1.3292,
         1.6024, 1.6189, 1.6074, 1.6042, 1.6110, 1.6016, 1.6200, 1.5732, 1.5780,
         1.2607, 1.2875, 1.2794, 1.2963, 1.2562, 1.2483, 1.2363, 1.3176, 1.2762],
        [1.4079, 1.2513, 1.2428, 1.2854, 1.2859, 1.2978, 1.2914, 1.1923, 1.1923,
         3.7314, 3.7610, 3.7044, 3.8369, 3.7331, 3.9328, 3.6761, 3.7173, 3.8646,
         1.6262, 1.6152, 1.5916, 1.5892, 1.6075, 1.6167, 1.6411, 1.6166, 1.6166,
         1.3770, 1.3462, 1.3350, 1.3939, 1.3365, 1.4313, 1.4116, 1.3802, 1.3318,
         1.5895, 1.6414, 1.6071, 1.5951, 1.5906, 1.6251, 1.6443, 1.4901, 1.5811,
         1.2159, 1.3214, 1.2960, 1.3418, 1.2105, 1.2155, 1.1483, 1.3991, 1.2868],
        [1.4583, 1.4582, 1.4562, 1.4533, 1.4533, 1.4583, 1.4539, 1.4583, 1.4583,
         1.4400, 1.4393, 1.4401, 1.4401, 1.4399, 1.4201, 1.4403, 1.4386, 1.4365,
         2.2059, 2.2081, 2.2257, 2.2050, 2.1830, 2.1813, 2.2119, 2.1797, 2.1797,
         1.5187, 1.5175, 1.5250, 1.5250, 1.5187, 1.5250, 1.5250, 1.5250, 1.5250,
         1.7664, 1.7665, 1.7665, 1.7631, 1.7664, 1.7664, 1.7665, 1.7420, 1.7448,
         1.4401, 1.4454, 1.4454, 1.4454, 1.4367, 1.4454, 1.4402, 1.4454, 1.4454],
        [1.3382, 1.3344, 1.3172, 1.3088, 1.3335, 1.3320, 1.3330, 1.3323, 1.3323,
         1.3073, 1.3009, 1.2973, 1.2965, 1.3077, 1.2928, 1.3057, 1.3073, 1.2798,
         1.6408, 1.6141, 1.6376, 1.6373, 1.6366, 1.6365, 1.6389, 1.6403, 1.6403,
         3.4724, 3.3082, 3.2413, 3.2980, 3.4176, 3.2696, 3.4596, 3.2509, 3.2289,
         1.6422, 1.6345, 1.6328, 1.6363, 1.6392, 1.6152, 1.6401, 1.5792, 1.6066,
         1.3136, 1.3089, 1.2992, 1.3138, 1.3093, 1.3012, 1.3129, 1.3142, 1.3158],
        [1.4612, 1.4543, 1.4043, 1.4126, 1.4529, 1.4611, 1.4590, 1.4612, 1.4612,
         1.4415, 1.4388, 1.4339, 1.4271, 1.4423, 1.3975, 1.4369, 1.4423, 1.4366,
         1.7471, 1.7382, 1.7347, 1.7438, 1.7636, 1.7616, 1.7409, 1.7637, 1.7637,
         1.4834, 1.4833, 1.5279, 1.5214, 1.4885, 1.5260, 1.5144, 1.5279, 1.5248,
         2.2191, 2.1957, 2.1839, 2.2041, 2.2524, 2.2688, 2.2308, 2.3488, 2.3448,
         1.4294, 1.4237, 1.4376, 1.4483, 1.4331, 1.4445, 1.4103, 1.4421, 1.4483],
        [1.3555, 1.2573, 1.2546, 1.2718, 1.2657, 1.2750, 1.2742, 1.2081, 1.2081,
         1.2935, 1.2556, 1.2542, 1.2595, 1.3332, 1.2165, 1.1891, 1.3332, 1.2404,
         1.6332, 1.6111, 1.5893, 1.5892, 1.6087, 1.6060, 1.6257, 1.6102, 1.6102,
         1.3543, 1.3282, 1.3231, 1.3455, 1.3303, 1.3744, 1.3754, 1.3470, 1.3232,
         1.6067, 1.6058, 1.6108, 1.6012, 1.5769, 1.5789, 1.6404, 1.5354, 1.5044,
         3.8604, 3.7142, 3.7485, 3.7449, 3.7383, 3.6030, 3.8543, 3.7385, 3.6212]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 72 : 1780.0194391466107
Test loss for epoch 72 : 194.73391163989382
Test Precision for epoch 72 : 0.26153846153846155
Test Recall for epoch 72 : 0.26153846153846155
Test F1 for epoch 72 : 0.26153846153846155


theta for epoch 73 : tensor([[3.6617, 3.6693, 3.7472, 3.7199, 3.7142, 3.6461, 3.6714, 3.6038, 3.6038,
         1.2864, 1.2688, 1.2676, 1.2695, 1.3042, 1.2502, 1.2293, 1.3042, 1.2565,
         1.5993, 1.5842, 1.6068, 1.5887, 1.5959, 1.5973, 1.6056, 1.5973, 1.5973,
         1.3338, 1.3445, 1.3329, 1.3511, 1.3345, 1.3607, 1.3546, 1.3431, 1.3329,
         1.5964, 1.6128, 1.6014, 1.5982, 1.6050, 1.5955, 1.6139, 1.5672, 1.5719,
         1.2518, 1.2786, 1.2705, 1.2873, 1.2473, 1.2395, 1.2274, 1.3086, 1.2673],
        [1.4027, 1.2444, 1.2359, 1.2787, 1.2793, 1.2912, 1.2848, 1.1848, 1.1848,
         3.7392, 3.7694, 3.7119, 3.8465, 3.7409, 3.9441, 3.6833, 3.7248, 3.8749,
         1.6188, 1.6077, 1.5842, 1.5814, 1.5998, 1.6090, 1.6339, 1.6089, 1.6089,
         1.3725, 1.3415, 1.3295, 1.3896, 1.3314, 1.4277, 1.4076, 1.3755, 1.3262,
         1.5825, 1.6346, 1.6000, 1.5881, 1.5837, 1.6182, 1.6377, 1.4827, 1.5743,
         1.2041, 1.3111, 1.2851, 1.3318, 1.1984, 1.2030, 1.1353, 1.3901, 1.2757],
        [1.4627, 1.4626, 1.4606, 1.4577, 1.4577, 1.4627, 1.4582, 1.4628, 1.4628,
         1.4429, 1.4421, 1.4429, 1.4429, 1.4428, 1.4230, 1.4431, 1.4414, 1.4393,
         2.2025, 2.2047, 2.2223, 2.2011, 2.1791, 2.1774, 2.2080, 2.1758, 2.1758,
         1.5270, 1.5257, 1.5333, 1.5332, 1.5270, 1.5332, 1.5332, 1.5333, 1.5333,
         1.7622, 1.7623, 1.7623, 1.7589, 1.7622, 1.7622, 1.7623, 1.7377, 1.7406,
         1.4351, 1.4405, 1.4405, 1.4405, 1.4317, 1.4405, 1.4352, 1.4405, 1.4405],
        [1.3423, 1.3387, 1.3214, 1.3130, 1.3378, 1.3362, 1.3372, 1.3367, 1.3367,
         1.3108, 1.3044, 1.3008, 1.2999, 1.3112, 1.2961, 1.3089, 1.3108, 1.2832,
         1.6400, 1.6131, 1.6367, 1.6364, 1.6357, 1.6357, 1.6381, 1.6394, 1.6394,
         3.4765, 3.3097, 3.2421, 3.2993, 3.4209, 3.2703, 3.4631, 3.2517, 3.2296,
         1.6385, 1.6308, 1.6290, 1.6325, 1.6354, 1.6114, 1.6363, 1.5754, 1.6027,
         1.3090, 1.3044, 1.2947, 1.3094, 1.3047, 1.2966, 1.3082, 1.3099, 1.3113],
        [1.4655, 1.4586, 1.4086, 1.4169, 1.4573, 1.4654, 1.4633, 1.4656, 1.4656,
         1.4444, 1.4416, 1.4367, 1.4298, 1.4452, 1.4000, 1.4396, 1.4452, 1.4393,
         1.7457, 1.7369, 1.7332, 1.7424, 1.7623, 1.7603, 1.7396, 1.7625, 1.7625,
         1.4916, 1.4915, 1.5360, 1.5296, 1.4966, 1.5341, 1.5225, 1.5361, 1.5330,
         2.2139, 2.1902, 2.1785, 2.1988, 2.2473, 2.2635, 2.2255, 2.3442, 2.3401,
         1.4243, 1.4188, 1.4327, 1.4434, 1.4280, 1.4396, 1.4050, 1.4373, 1.4434],
        [1.3483, 1.2504, 1.2475, 1.2648, 1.2587, 1.2680, 1.2672, 1.2016, 1.2016,
         1.2932, 1.2544, 1.2530, 1.2584, 1.3334, 1.2148, 1.1858, 1.3334, 1.2389,
         1.6251, 1.6028, 1.5813, 1.5807, 1.6003, 1.5976, 1.6175, 1.6017, 1.6017,
         1.3509, 1.3246, 1.3196, 1.3420, 1.3264, 1.3711, 1.3721, 1.3436, 1.3197,
         1.5987, 1.5980, 1.6028, 1.5931, 1.5687, 1.5708, 1.6327, 1.5270, 1.4959,
         3.8700, 3.7208, 3.7559, 3.7521, 3.7457, 3.6079, 3.8640, 3.7454, 3.6263]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 73 : 1779.7222839765009
Test loss for epoch 73 : 195.17464566645668
Test Precision for epoch 73 : 0.26153846153846155
Test Recall for epoch 73 : 0.26153846153846155
Test F1 for epoch 73 : 0.26153846153846155


theta for epoch 74 : tensor([[3.6732, 3.6815, 3.7606, 3.7327, 3.7271, 3.6578, 3.6835, 3.6152, 3.6152,
         1.2801, 1.2624, 1.2613, 1.2631, 1.2980, 1.2438, 1.2225, 1.2980, 1.2501,
         1.5986, 1.5835, 1.6060, 1.5881, 1.5954, 1.5968, 1.6050, 1.5968, 1.5968,
         1.3381, 1.3490, 1.3380, 1.3555, 1.3392, 1.3647, 1.3588, 1.3477, 1.3380,
         1.5935, 1.6098, 1.5985, 1.5953, 1.6021, 1.5926, 1.6109, 1.5642, 1.5690,
         1.2439, 1.2707, 1.2626, 1.2795, 1.2395, 1.2316, 1.2194, 1.3007, 1.2594],
        [1.3936, 1.2335, 1.2249, 1.2681, 1.2687, 1.2807, 1.2743, 1.1734, 1.1734,
         3.7485, 3.7793, 3.7208, 3.8577, 3.7502, 3.9568, 3.6921, 3.7338, 3.8866,
         1.6124, 1.6010, 1.5775, 1.5743, 1.5929, 1.6022, 1.6275, 1.6021, 1.6021,
         1.3647, 1.3335, 1.3208, 1.3822, 1.3230, 1.4210, 1.4005, 1.3678, 1.3176,
         1.5761, 1.6285, 1.5936, 1.5817, 1.5774, 1.6120, 1.6317, 1.4757, 1.5681,
         1.1902, 1.2988, 1.2723, 1.3199, 1.1842, 1.1884, 1.1201, 1.3794, 1.2626],
        [1.4681, 1.4681, 1.4661, 1.4632, 1.4632, 1.4682, 1.4637, 1.4682, 1.4682,
         1.4387, 1.4378, 1.4387, 1.4387, 1.4386, 1.4187, 1.4389, 1.4372, 1.4351,
         2.2031, 2.2053, 2.2229, 2.2010, 2.1790, 2.1774, 2.2079, 2.1758, 2.1758,
         1.5362, 1.5350, 1.5425, 1.5425, 1.5363, 1.5425, 1.5425, 1.5425, 1.5425,
         1.7613, 1.7614, 1.7614, 1.7580, 1.7613, 1.7613, 1.7614, 1.7369, 1.7397,
         1.4314, 1.4368, 1.4368, 1.4368, 1.4279, 1.4367, 1.4313, 1.4368, 1.4368],
        [1.3473, 1.3439, 1.3266, 1.3181, 1.3429, 1.3413, 1.3423, 1.3420, 1.3420,
         1.3071, 1.3006, 1.2970, 1.2961, 1.3076, 1.2922, 1.3050, 1.3072, 1.2794,
         1.6433, 1.6163, 1.6400, 1.6396, 1.6390, 1.6389, 1.6413, 1.6426, 1.6426,
         3.4820, 3.3127, 3.2445, 3.3020, 3.4256, 3.2726, 3.4680, 3.2539, 3.2318,
         1.6380, 1.6304, 1.6285, 1.6320, 1.6349, 1.6110, 1.6358, 1.5748, 1.6022,
         1.3055, 1.3010, 1.2912, 1.3060, 1.3012, 1.2930, 1.3047, 1.3066, 1.3079],
        [1.4708, 1.4641, 1.4143, 1.4223, 1.4627, 1.4708, 1.4688, 1.4710, 1.4710,
         1.4402, 1.4373, 1.4324, 1.4255, 1.4411, 1.3955, 1.4354, 1.4410, 1.4350,
         1.7486, 1.7398, 1.7359, 1.7452, 1.7652, 1.7632, 1.7424, 1.7654, 1.7654,
         1.5009, 1.5008, 1.5452, 1.5388, 1.5059, 1.5433, 1.5317, 1.5452, 1.5421,
         2.2119, 2.1880, 2.1762, 2.1967, 2.2453, 2.2612, 2.2233, 2.3427, 2.3384,
         1.4204, 1.4150, 1.4289, 1.4397, 1.4241, 1.4359, 1.4009, 1.4336, 1.4397],
        [1.3416, 1.2436, 1.2406, 1.2580, 1.2518, 1.2613, 1.2604, 1.1951, 1.1951,
         1.2853, 1.2455, 1.2440, 1.2497, 1.3261, 1.2053, 1.1746, 1.3261, 1.2297,
         1.6204, 1.5978, 1.5765, 1.5755, 1.5952, 1.5925, 1.6127, 1.5967, 1.5967,
         1.3479, 1.3215, 1.3166, 1.3390, 1.3228, 1.3682, 1.3693, 1.3407, 1.3166,
         1.5933, 1.5927, 1.5973, 1.5877, 1.5631, 1.5653, 1.6276, 1.5212, 1.4899,
         3.8823, 3.7301, 3.7658, 3.7618, 3.7556, 3.6155, 3.8762, 3.7549, 3.6339]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 74 : 1779.0987916126019
Test loss for epoch 74 : 195.63203183154354
Test Precision for epoch 74 : 0.26153846153846155
Test Recall for epoch 74 : 0.26153846153846155
Test F1 for epoch 74 : 0.26153846153846155


theta for epoch 75 : tensor([[3.6800, 3.6889, 3.7691, 3.7407, 3.7352, 3.6646, 3.6907, 3.6217, 3.6217,
         1.2697, 1.2521, 1.2510, 1.2528, 1.2873, 1.2335, 1.2122, 1.2873, 1.2397,
         1.6023, 1.5873, 1.6098, 1.5920, 1.5994, 1.6008, 1.6088, 1.6008, 1.6008,
         1.3389, 1.3499, 1.3394, 1.3563, 1.3402, 1.3653, 1.3595, 1.3487, 1.3394,
         1.5950, 1.6112, 1.6000, 1.5968, 1.6035, 1.5940, 1.6123, 1.5656, 1.5705,
         1.2399, 1.2667, 1.2586, 1.2755, 1.2354, 1.2275, 1.2152, 1.2968, 1.2554],
        [1.3886, 1.2280, 1.2194, 1.2627, 1.2633, 1.2753, 1.2688, 1.1679, 1.1679,
         3.7467, 3.7780, 3.7186, 3.8577, 3.7483, 3.9585, 3.6895, 3.7316, 3.8872,
         1.6134, 1.6019, 1.5785, 1.5750, 1.5936, 1.6030, 1.6286, 1.6029, 1.6029,
         1.3607, 1.3293, 1.3162, 1.3782, 1.3186, 1.4175, 1.3967, 1.3637, 1.3129,
         1.5768, 1.6294, 1.5943, 1.5824, 1.5783, 1.6129, 1.6328, 1.4761, 1.5691,
         1.1833, 1.2933, 1.2663, 1.3147, 1.1770, 1.1808, 1.1122, 1.3752, 1.2564],
        [1.4693, 1.4692, 1.4672, 1.4643, 1.4643, 1.4693, 1.4648, 1.4694, 1.4694,
         1.4299, 1.4291, 1.4300, 1.4299, 1.4299, 1.4099, 1.4301, 1.4285, 1.4263,
         2.2074, 2.2095, 2.2271, 2.2044, 2.1825, 2.1808, 2.2113, 2.1793, 2.1793,
         1.5402, 1.5389, 1.5465, 1.5465, 1.5403, 1.5464, 1.5464, 1.5465, 1.5465,
         1.7644, 1.7645, 1.7645, 1.7611, 1.7644, 1.7644, 1.7645, 1.7399, 1.7428,
         1.4309, 1.4363, 1.4363, 1.4364, 1.4274, 1.4362, 1.4308, 1.4364, 1.4363],
        [1.3475, 1.3443, 1.3271, 1.3185, 1.3433, 1.3417, 1.3428, 1.3426, 1.3426,
         1.2988, 1.2923, 1.2887, 1.2878, 1.2994, 1.2838, 1.2964, 1.2989, 1.2710,
         1.6503, 1.6233, 1.6470, 1.6466, 1.6460, 1.6459, 1.6483, 1.6496, 1.6496,
         3.4841, 3.3124, 3.2434, 3.3014, 3.4270, 3.2715, 3.4696, 3.2529, 3.2306,
         1.6414, 1.6338, 1.6319, 1.6354, 1.6383, 1.6144, 1.6393, 1.5782, 1.6055,
         1.3052, 1.3007, 1.2910, 1.3058, 1.3009, 1.2926, 1.3043, 1.3065, 1.3076],
        [1.4719, 1.4652, 1.4157, 1.4235, 1.4638, 1.4719, 1.4699, 1.4721, 1.4721,
         1.4314, 1.4286, 1.4236, 1.4166, 1.4324, 1.3865, 1.4266, 1.4324, 1.4261,
         1.7552, 1.7465, 1.7425, 1.7518, 1.7719, 1.7698, 1.7491, 1.7721, 1.7721,
         1.5048, 1.5049, 1.5492, 1.5427, 1.5098, 1.5472, 1.5356, 1.5491, 1.5460,
         2.2137, 2.1895, 2.1777, 2.1984, 2.2471, 2.2627, 2.2249, 2.3449, 2.3404,
         1.4198, 1.4145, 1.4285, 1.4393, 1.4235, 1.4354, 1.4002, 1.4332, 1.4393],
        [1.3329, 1.2350, 1.2318, 1.2493, 1.2431, 1.2526, 1.2518, 1.1867, 1.1867,
         1.2734, 1.2330, 1.2315, 1.2373, 1.3144, 1.1923, 1.1608, 1.3144, 1.2170,
         1.6201, 1.5974, 1.5763, 1.5748, 1.5946, 1.5919, 1.6124, 1.5961, 1.5961,
         1.3421, 1.3156, 1.3107, 1.3331, 1.3165, 1.3625, 1.3636, 1.3349, 1.3108,
         1.5922, 1.5917, 1.5962, 1.5865, 1.5618, 1.5641, 1.6269, 1.5197, 1.4883,
         3.8945, 3.7393, 3.7757, 3.7716, 3.7656, 3.6231, 3.8884, 3.7644, 3.6417]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 75 : 1778.5769189115217
Test loss for epoch 75 : 195.87810794978836
Test Precision for epoch 75 : 0.26153846153846155
Test Recall for epoch 75 : 0.26153846153846155
Test F1 for epoch 75 : 0.26153846153846155


theta for epoch 76 : tensor([[3.6785, 3.6878, 3.7693, 3.7403, 3.7349, 3.6630, 3.6895, 3.6195, 3.6195,
         1.2616, 1.2441, 1.2430, 1.2447, 1.2788, 1.2255, 1.2048, 1.2788, 1.2319,
         1.6070, 1.5920, 1.6145, 1.5969, 1.6042, 1.6056, 1.6136, 1.6056, 1.6056,
         1.3352, 1.3463, 1.3361, 1.3526, 1.3366, 1.3614, 1.3557, 1.3451, 1.3361,
         1.5994, 1.6156, 1.6044, 1.6013, 1.6080, 1.5984, 1.6167, 1.5700, 1.5749,
         1.2396, 1.2662, 1.2582, 1.2749, 1.2352, 1.2275, 1.2150, 1.2959, 1.2550],
        [1.3866, 1.2269, 1.2183, 1.2613, 1.2619, 1.2739, 1.2675, 1.1674, 1.1674,
         3.7371, 3.7690, 3.7085, 3.8500, 3.7388, 3.9525, 3.6791, 3.7217, 3.8801,
         1.6181, 1.6066, 1.5832, 1.5795, 1.5982, 1.6076, 1.6334, 1.6075, 1.6075,
         1.3585, 1.3272, 1.3140, 1.3761, 1.3165, 1.4154, 1.3947, 1.3615, 1.3108,
         1.5829, 1.6355, 1.6003, 1.5884, 1.5844, 1.6189, 1.6389, 1.4820, 1.5753,
         1.1835, 1.2937, 1.2666, 1.3151, 1.1772, 1.1810, 1.1120, 1.3757, 1.2568],
        [1.4649, 1.4648, 1.4628, 1.4599, 1.4599, 1.4649, 1.4604, 1.4650, 1.4650,
         1.4226, 1.4217, 1.4226, 1.4226, 1.4226, 1.4026, 1.4227, 1.4211, 1.4189,
         2.2115, 2.2136, 2.2312, 2.2078, 2.1860, 2.1843, 2.2147, 2.1828, 2.1828,
         1.5370, 1.5357, 1.5433, 1.5432, 1.5370, 1.5432, 1.5432, 1.5432, 1.5433,
         1.7696, 1.7697, 1.7697, 1.7663, 1.7696, 1.7696, 1.7697, 1.7452, 1.7481,
         1.4325, 1.4380, 1.4380, 1.4380, 1.4291, 1.4379, 1.4324, 1.4381, 1.4380],
        [1.3419, 1.3390, 1.3217, 1.3131, 1.3380, 1.3363, 1.3374, 1.3373, 1.3373,
         1.2919, 1.2853, 1.2817, 1.2808, 1.2925, 1.2767, 1.2893, 1.2920, 1.2640,
         1.6570, 1.6299, 1.6536, 1.6532, 1.6527, 1.6526, 1.6550, 1.6563, 1.6563,
         3.4813, 3.3071, 3.2375, 3.2959, 3.4234, 3.2656, 3.4662, 3.2469, 3.2245,
         1.6470, 1.6394, 1.6375, 1.6409, 1.6438, 1.6200, 1.6448, 1.5837, 1.6110,
         1.3070, 1.3026, 1.2928, 1.3077, 1.3027, 1.2944, 1.3061, 1.3084, 1.3095],
        [1.4675, 1.4609, 1.4116, 1.4192, 1.4595, 1.4674, 1.4655, 1.4676, 1.4676,
         1.4241, 1.4212, 1.4162, 1.4092, 1.4251, 1.3790, 1.4192, 1.4251, 1.4187,
         1.7616, 1.7530, 1.7488, 1.7582, 1.7784, 1.7763, 1.7556, 1.7785, 1.7785,
         1.5016, 1.5018, 1.5459, 1.5394, 1.5066, 1.5439, 1.5323, 1.5458, 1.5427,
         2.2175, 2.1931, 2.1813, 2.2021, 2.2510, 2.2663, 2.2286, 2.3490, 2.3443,
         1.4214, 1.4162, 1.4302, 1.4410, 1.4251, 1.4371, 1.4017, 1.4349, 1.4410],
        [1.3336, 1.2365, 1.2332, 1.2507, 1.2444, 1.2540, 1.2531, 1.1888, 1.1888,
         1.2679, 1.2275, 1.2261, 1.2318, 1.3087, 1.1865, 1.1550, 1.3087, 1.2115,
         1.6265, 1.6036, 1.5829, 1.5809, 1.6007, 1.5981, 1.6187, 1.6023, 1.6023,
         1.3434, 1.3170, 1.3122, 1.3344, 1.3175, 1.3637, 1.3648, 1.3362, 1.3123,
         1.5984, 1.5981, 1.6024, 1.5928, 1.5679, 1.5704, 1.6333, 1.5258, 1.4945,
         3.8892, 3.7309, 3.7679, 3.7637, 3.7578, 3.6128, 3.8830, 3.7563, 3.6316]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 76 : 1779.0707879112965
Test loss for epoch 76 : 195.6396609104706
Test Precision for epoch 76 : 0.26153846153846155
Test Recall for epoch 76 : 0.26153846153846155
Test F1 for epoch 76 : 0.26153846153846155


theta for epoch 77 : tensor([[3.6738, 3.6834, 3.7663, 3.7368, 3.7314, 3.6582, 3.6851, 3.6141, 3.6141,
         1.2588, 1.2418, 1.2407, 1.2423, 1.2755, 1.2232, 1.2032, 1.2755, 1.2296,
         1.6059, 1.5909, 1.6134, 1.5959, 1.6033, 1.6047, 1.6125, 1.6046, 1.6046,
         1.3304, 1.3416, 1.3316, 1.3479, 1.3319, 1.3566, 1.3510, 1.3404, 1.3316,
         1.6026, 1.6188, 1.6076, 1.6045, 1.6111, 1.6016, 1.6198, 1.5732, 1.5781,
         1.2417, 1.2681, 1.2602, 1.2767, 1.2373, 1.2296, 1.2178, 1.2976, 1.2570],
        [1.3874, 1.2295, 1.2208, 1.2634, 1.2641, 1.2759, 1.2696, 1.1708, 1.1708,
         3.7258, 3.7581, 3.6967, 3.8405, 3.7274, 3.9447, 3.6669, 3.7101, 3.8712,
         1.6191, 1.6076, 1.5843, 1.5805, 1.5991, 1.6086, 1.6345, 1.6085, 1.6085,
         1.3584, 1.3272, 1.3142, 1.3760, 1.3166, 1.4151, 1.3944, 1.3614, 1.3109,
         1.5889, 1.6414, 1.6062, 1.5944, 1.5905, 1.6249, 1.6449, 1.4879, 1.5815,
         1.1873, 1.2975, 1.2704, 1.3190, 1.1809, 1.1847, 1.1168, 1.3796, 1.2605],
        [1.4593, 1.4592, 1.4573, 1.4544, 1.4544, 1.4593, 1.4548, 1.4593, 1.4593,
         1.4204, 1.4194, 1.4204, 1.4203, 1.4203, 1.4004, 1.4205, 1.4189, 1.4167,
         2.2101, 2.2121, 2.2296, 2.2058, 2.1841, 2.1824, 2.2127, 2.1809, 2.1809,
         1.5311, 1.5297, 1.5373, 1.5373, 1.5311, 1.5373, 1.5372, 1.5373, 1.5373,
         1.7733, 1.7734, 1.7734, 1.7700, 1.7733, 1.7733, 1.7734, 1.7490, 1.7518,
         1.4360, 1.4415, 1.4415, 1.4415, 1.4325, 1.4414, 1.4359, 1.4416, 1.4415],
        [1.3350, 1.3322, 1.3150, 1.3064, 1.3312, 1.3296, 1.3306, 1.3307, 1.3307,
         1.2900, 1.2833, 1.2797, 1.2788, 1.2906, 1.2747, 1.2872, 1.2901, 1.2620,
         1.6573, 1.6301, 1.6538, 1.6534, 1.6529, 1.6528, 1.6552, 1.6565, 1.6565,
         3.4771, 3.3005, 3.2301, 3.2891, 3.4184, 3.2583, 3.4615, 3.2396, 3.2171,
         1.6509, 1.6434, 1.6414, 1.6448, 1.6477, 1.6239, 1.6488, 1.5876, 1.6149,
         1.3105, 1.3061, 1.2963, 1.3112, 1.3062, 1.2979, 1.3096, 1.3120, 1.3130],
        [1.4619, 1.4554, 1.4065, 1.4138, 1.4539, 1.4618, 1.4599, 1.4620, 1.4620,
         1.4219, 1.4190, 1.4140, 1.4069, 1.4229, 1.3766, 1.4169, 1.4229, 1.4164,
         1.7619, 1.7533, 1.7490, 1.7585, 1.7787, 1.7766, 1.7559, 1.7788, 1.7788,
         1.4956, 1.4960, 1.5399, 1.5335, 1.5007, 1.5379, 1.5263, 1.5398, 1.5367,
         2.2198, 2.1953, 2.1834, 2.2044, 2.2533, 2.2684, 2.2308, 2.3516, 2.3467,
         1.4248, 1.4197, 1.4337, 1.4445, 1.4285, 1.4406, 1.4050, 1.4384, 1.4445],
        [1.3367, 1.2403, 1.2370, 1.2544, 1.2482, 1.2577, 1.2568, 1.1932, 1.1932,
         1.2682, 1.2281, 1.2268, 1.2323, 1.3083, 1.1869, 1.1562, 1.3083, 1.2123,
         1.6279, 1.6050, 1.5847, 1.5821, 1.6019, 1.5994, 1.6201, 1.6035, 1.6035,
         1.3455, 1.3192, 1.3146, 1.3366, 1.3194, 1.3657, 1.3668, 1.3384, 1.3146,
         1.6039, 1.6038, 1.6080, 1.5983, 1.5735, 1.5760, 1.6391, 1.5313, 1.5001,
         3.8811, 3.7197, 3.7574, 3.7532, 3.7473, 3.5998, 3.8747, 3.7455, 3.6188]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 77 : 1779.77178907703
Test loss for epoch 77 : 195.38473838014346
Test Precision for epoch 77 : 0.26153846153846155
Test Recall for epoch 77 : 0.26153846153846155
Test F1 for epoch 77 : 0.26153846153846155


theta for epoch 78 : tensor([[3.6719, 3.6819, 3.7661, 3.7360, 3.7306, 3.6561, 3.6835, 3.6116, 3.6116,
         1.2617, 1.2449, 1.2439, 1.2453, 1.2780, 1.2263, 1.2067, 1.2780, 1.2328,
         1.5982, 1.5832, 1.6056, 1.5882, 1.5956, 1.5970, 1.6048, 1.5970, 1.5970,
         1.3285, 1.3397, 1.3297, 1.3461, 1.3299, 1.3548, 1.3491, 1.3386, 1.3297,
         1.6003, 1.6164, 1.6053, 1.6022, 1.6088, 1.5992, 1.6175, 1.5708, 1.5757,
         1.2438, 1.2701, 1.2622, 1.2788, 1.2394, 1.2317, 1.2204, 1.2996, 1.2591],
        [1.3841, 1.2277, 1.2189, 1.2613, 1.2619, 1.2738, 1.2674, 1.1699, 1.1699,
         3.7242, 3.7571, 3.6946, 3.8407, 3.7259, 3.9465, 3.6645, 3.7082, 3.8720,
         1.6108, 1.5992, 1.5759, 1.5721, 1.5908, 1.6002, 1.6262, 1.6001, 1.6001,
         1.3548, 1.3237, 1.3110, 1.3724, 1.3132, 1.4114, 1.3907, 1.3580, 1.3077,
         1.5866, 1.6391, 1.6040, 1.5921, 1.5883, 1.6226, 1.6427, 1.4854, 1.5793,
         1.1874, 1.2980, 1.2708, 1.3195, 1.1810, 1.1847, 1.1178, 1.3803, 1.2609],
        [1.4566, 1.4565, 1.4546, 1.4517, 1.4517, 1.4566, 1.4521, 1.4566, 1.4566,
         1.4239, 1.4229, 1.4239, 1.4239, 1.4239, 1.4039, 1.4240, 1.4224, 1.4202,
         2.2028, 2.2048, 2.2224, 2.1985, 2.1768, 2.1751, 2.2054, 2.1736, 2.1736,
         1.5276, 1.5262, 1.5338, 1.5338, 1.5276, 1.5338, 1.5338, 1.5338, 1.5339,
         1.7718, 1.7719, 1.7719, 1.7685, 1.7718, 1.7718, 1.7719, 1.7475, 1.7503,
         1.4398, 1.4453, 1.4453, 1.4453, 1.4363, 1.4452, 1.4397, 1.4454, 1.4453],
        [1.3308, 1.3283, 1.3112, 1.3025, 1.3273, 1.3256, 1.3267, 1.3270, 1.3270,
         1.2937, 1.2870, 1.2835, 1.2826, 1.2944, 1.2784, 1.2908, 1.2939, 1.2658,
         1.6510, 1.6237, 1.6475, 1.6471, 1.6466, 1.6466, 1.6490, 1.6503, 1.6503,
         3.4753, 3.2964, 3.2254, 3.2848, 3.4158, 3.2536, 3.4592, 3.2349, 3.2122,
         1.6495, 1.6420, 1.6400, 1.6434, 1.6463, 1.6225, 1.6474, 1.5862, 1.6134,
         1.3142, 1.3099, 1.3000, 1.3150, 1.3099, 1.3016, 1.3133, 1.3157, 1.3168],
        [1.4591, 1.4528, 1.4043, 1.4114, 1.4513, 1.4591, 1.4572, 1.4592, 1.4592,
         1.4255, 1.4225, 1.4174, 1.4103, 1.4265, 1.3800, 1.4204, 1.4265, 1.4199,
         1.7559, 1.7473, 1.7428, 1.7525, 1.7727, 1.7706, 1.7499, 1.7729, 1.7729,
         1.4922, 1.4928, 1.5363, 1.5300, 1.4972, 1.5344, 1.5228, 1.5363, 1.5332,
         2.2171, 2.1923, 2.1805, 2.2015, 2.2506, 2.2654, 2.2280, 2.3491, 2.3441,
         1.4286, 1.4234, 1.4375, 1.4484, 1.4322, 1.4444, 1.4087, 1.4422, 1.4484],
        [1.3401, 1.2441, 1.2407, 1.2581, 1.2520, 1.2615, 1.2606, 1.1973, 1.1973,
         1.2728, 1.2328, 1.2316, 1.2369, 1.3125, 1.1913, 1.1608, 1.3125, 1.2170,
         1.6215, 1.5985, 1.5787, 1.5755, 1.5953, 1.5928, 1.6137, 1.5969, 1.5969,
         1.3479, 1.3217, 1.3172, 1.3390, 1.3216, 1.3681, 1.3691, 1.3409, 1.3172,
         1.6029, 1.6029, 1.6069, 1.5973, 1.5725, 1.5751, 1.6383, 1.5303, 1.4990,
         3.8772, 3.7127, 3.7511, 3.7468, 3.7410, 3.5910, 3.8707, 3.7389, 3.6102]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 78 : 1779.4116500981415
Test loss for epoch 78 : 195.3646930641957
Test Precision for epoch 78 : 0.26153846153846155
Test Recall for epoch 78 : 0.26153846153846155
Test F1 for epoch 78 : 0.26153846153846155


theta for epoch 79 : tensor([[3.6723, 3.6828, 3.7682, 3.7376, 3.7323, 3.6565, 3.6843, 3.6115, 3.6115,
         1.2676, 1.2509, 1.2499, 1.2513, 1.2837, 1.2323, 1.2127, 1.2837, 1.2388,
         1.5903, 1.5752, 1.5978, 1.5803, 1.5877, 1.5891, 1.5969, 1.5891, 1.5891,
         1.3302, 1.3415, 1.3313, 1.3480, 1.3316, 1.3568, 1.3511, 1.3404, 1.3313,
         1.5932, 1.6094, 1.5983, 1.5951, 1.6018, 1.5922, 1.6105, 1.5637, 1.5687,
         1.2432, 1.2696, 1.2617, 1.2783, 1.2388, 1.2311, 1.2202, 1.2993, 1.2585],
        [1.3771, 1.2219, 1.2129, 1.2552, 1.2559, 1.2677, 1.2614, 1.1649, 1.1649,
         3.7304, 3.7637, 3.7004, 3.8486, 3.7320, 3.9560, 3.6700, 3.7140, 3.8805,
         1.5992, 1.5876, 1.5642, 1.5603, 1.5791, 1.5887, 1.6147, 1.5886, 1.5886,
         1.3491, 1.3179, 1.3055, 1.3667, 1.3076, 1.4056, 1.3850, 1.3523, 1.3023,
         1.5772, 1.6298, 1.5946, 1.5827, 1.5789, 1.6132, 1.6334, 1.4755, 1.5700,
         1.1819, 1.2931, 1.2657, 1.3147, 1.1756, 1.1793, 1.1130, 1.3757, 1.2558],
        [1.4564, 1.4563, 1.4544, 1.4515, 1.4516, 1.4564, 1.4519, 1.4564, 1.4564,
         1.4306, 1.4296, 1.4306, 1.4306, 1.4306, 1.4106, 1.4307, 1.4292, 1.4269,
         2.1957, 2.1977, 2.2152, 2.1912, 2.1696, 2.1679, 2.1982, 2.1664, 2.1664,
         1.5275, 1.5261, 1.5338, 1.5337, 1.5275, 1.5337, 1.5337, 1.5337, 1.5338,
         1.7659, 1.7660, 1.7660, 1.7626, 1.7659, 1.7659, 1.7660, 1.7416, 1.7444,
         1.4411, 1.4467, 1.4466, 1.4467, 1.4376, 1.4466, 1.4410, 1.4467, 1.4467],
        [1.3292, 1.3269, 1.3098, 1.3011, 1.3258, 1.3241, 1.3252, 1.3257, 1.3257,
         1.3006, 1.2939, 1.2903, 1.2894, 1.3013, 1.2852, 1.2975, 1.3008, 1.2726,
         1.6446, 1.6172, 1.6411, 1.6407, 1.6402, 1.6401, 1.6425, 1.6439, 1.6439,
         3.4766, 3.2955, 3.2240, 3.2837, 3.4164, 3.2522, 3.4599, 3.2334, 3.2107,
         1.6436, 1.6361, 1.6340, 1.6375, 1.6403, 1.6166, 1.6415, 1.5802, 1.6074,
         1.3154, 1.3111, 1.3012, 1.3162, 1.3111, 1.3027, 1.3145, 1.3170, 1.3179],
        [1.4589, 1.4528, 1.4048, 1.4115, 1.4512, 1.4589, 1.4570, 1.4591, 1.4591,
         1.4322, 1.4292, 1.4241, 1.4170, 1.4333, 1.3866, 1.4271, 1.4332, 1.4266,
         1.7498, 1.7412, 1.7367, 1.7464, 1.7667, 1.7646, 1.7439, 1.7669, 1.7669,
         1.4921, 1.4930, 1.5362, 1.5299, 1.4972, 1.5343, 1.5226, 1.5362, 1.5331,
         2.2100, 2.1852, 2.1733, 2.1944, 2.2435, 2.2581, 2.2208, 2.3422, 2.3371,
         1.4299, 1.4248, 1.4389, 1.4497, 1.4335, 1.4458, 1.4100, 1.4436, 1.4497],
        [1.3435, 1.2476, 1.2442, 1.2616, 1.2555, 1.2650, 1.2640, 1.2009, 1.2009,
         1.2792, 1.2392, 1.2380, 1.2433, 1.3187, 1.1972, 1.1667, 1.3187, 1.2234,
         1.6138, 1.5906, 1.5713, 1.5674, 1.5873, 1.5848, 1.6059, 1.5890, 1.5890,
         1.3515, 1.3253, 1.3209, 1.3426, 1.3250, 1.3717, 1.3727, 1.3446, 1.3210,
         1.5961, 1.5963, 1.6002, 1.5905, 1.5658, 1.5686, 1.6319, 1.5235, 1.4923,
         3.8757, 3.7082, 3.7472, 3.7428, 3.7371, 3.5846, 3.8691, 3.7347, 3.6041]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 79 : 1778.9556587582056
Test loss for epoch 79 : 195.55249016467621
Test Precision for epoch 79 : 0.26153846153846155
Test Recall for epoch 79 : 0.26153846153846155
Test F1 for epoch 79 : 0.26153846153846155


theta for epoch 80 : tensor([[3.6703, 3.6812, 3.7679, 3.7367, 3.7314, 3.6544, 3.6826, 3.6089, 3.6089,
         1.2717, 1.2553, 1.2542, 1.2556, 1.2874, 1.2366, 1.2175, 1.2874, 1.2432,
         1.5882, 1.5731, 1.5957, 1.5782, 1.5856, 1.5870, 1.5948, 1.5870, 1.5870,
         1.3350, 1.3463, 1.3357, 1.3529, 1.3361, 1.3620, 1.3561, 1.3452, 1.3358,
         1.5870, 1.6032, 1.5921, 1.5889, 1.5956, 1.5860, 1.6043, 1.5575, 1.5624,
         1.2406, 1.2672, 1.2593, 1.2760, 1.2362, 1.2284, 1.2181, 1.2971, 1.2561],
        [1.3791, 1.2258, 1.2167, 1.2587, 1.2594, 1.2712, 1.2649, 1.1698, 1.1698,
         3.7263, 3.7602, 3.6959, 3.8463, 3.7280, 3.9554, 3.6651, 3.7097, 3.8788,
         1.5966, 1.5850, 1.5615, 1.5578, 1.5766, 1.5861, 1.6121, 1.5861, 1.5861,
         1.3527, 1.3215, 1.3097, 1.3702, 1.3114, 1.4088, 1.3883, 1.3560, 1.3064,
         1.5717, 1.6242, 1.5890, 1.5772, 1.5734, 1.6077, 1.6279, 1.4698, 1.5646,
         1.1791, 1.2904, 1.2630, 1.3120, 1.1727, 1.1764, 1.1109, 1.3732, 1.2530],
        [1.4571, 1.4571, 1.4552, 1.4523, 1.4524, 1.4571, 1.4527, 1.4572, 1.4572,
         1.4352, 1.4341, 1.4351, 1.4351, 1.4351, 1.4152, 1.4352, 1.4337, 1.4314,
         2.1934, 2.1953, 2.2128, 2.1885, 2.1669, 2.1653, 2.1955, 2.1638, 2.1638,
         1.5287, 1.5273, 1.5350, 1.5349, 1.5288, 1.5349, 1.5349, 1.5349, 1.5350,
         1.7604, 1.7605, 1.7605, 1.7570, 1.7604, 1.7604, 1.7605, 1.7361, 1.7389,
         1.4399, 1.4454, 1.4454, 1.4454, 1.4363, 1.4453, 1.4397, 1.4455, 1.4454],
        [1.3284, 1.3264, 1.3094, 1.3007, 1.3253, 1.3236, 1.3247, 1.3253, 1.3253,
         1.3052, 1.2985, 1.2949, 1.2940, 1.3059, 1.2897, 1.3020, 1.3054, 1.2772,
         1.6432, 1.6157, 1.6396, 1.6392, 1.6388, 1.6387, 1.6411, 1.6424, 1.6424,
         3.4792, 3.2961, 3.2241, 3.2840, 3.4183, 3.2522, 3.4620, 3.2335, 3.2107,
         1.6380, 1.6306, 1.6284, 1.6319, 1.6348, 1.6110, 1.6359, 1.5746, 1.6018,
         1.3139, 1.3095, 1.2996, 1.3147, 1.3095, 1.3012, 1.3130, 1.3154, 1.3164],
        [1.4597, 1.4537, 1.4063, 1.4127, 1.4521, 1.4596, 1.4578, 1.4598, 1.4598,
         1.4367, 1.4337, 1.4286, 1.4214, 1.4378, 1.3910, 1.4316, 1.4378, 1.4310,
         1.7487, 1.7401, 1.7356, 1.7453, 1.7656, 1.7635, 1.7428, 1.7658, 1.7658,
         1.4935, 1.4946, 1.5374, 1.5312, 1.4986, 1.5355, 1.5238, 1.5374, 1.5342,
         2.2034, 2.1784, 2.1665, 2.1877, 2.2369, 2.2513, 2.2141, 2.3357, 2.3305,
         1.4286, 1.4235, 1.4376, 1.4485, 1.4322, 1.4445, 1.4087, 1.4423, 1.4485],
        [1.3478, 1.2520, 1.2485, 1.2660, 1.2599, 1.2694, 1.2684, 1.2054, 1.2054,
         1.2834, 1.2437, 1.2425, 1.2476, 1.3224, 1.2014, 1.1714, 1.3224, 1.2280,
         1.6110, 1.5878, 1.5689, 1.5645, 1.5844, 1.5819, 1.6031, 1.5861, 1.5861,
         1.3566, 1.3305, 1.3263, 1.3477, 1.3300, 1.3767, 1.3777, 1.3498, 1.3263,
         1.5897, 1.5901, 1.5938, 1.5841, 1.5595, 1.5624, 1.6257, 1.5170, 1.4858,
         3.8728, 3.7021, 3.7419, 3.7373, 3.7318, 3.5768, 3.8660, 3.7290, 3.5965]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 80 : 1779.3271388534117
Test loss for epoch 80 : 195.46280101008207
Test Precision for epoch 80 : 0.26153846153846155
Test Recall for epoch 80 : 0.26153846153846155
Test F1 for epoch 80 : 0.26153846153846155


theta for epoch 81 : tensor([[3.6646, 3.6757, 3.7638, 3.7320, 3.7268, 3.6485, 3.6770, 3.6024, 3.6024,
         1.2716, 1.2555, 1.2545, 1.2557, 1.2868, 1.2369, 1.2186, 1.2868, 1.2436,
         1.5928, 1.5776, 1.6003, 1.5828, 1.5901, 1.5916, 1.5994, 1.5916, 1.5916,
         1.3374, 1.3487, 1.3378, 1.3555, 1.3383, 1.3649, 1.3588, 1.3477, 1.3378,
         1.5851, 1.6014, 1.5903, 1.5871, 1.5938, 1.5842, 1.6025, 1.5556, 1.5606,
         1.2389, 1.2657, 1.2577, 1.2745, 1.2344, 1.2265, 1.2166, 1.2958, 1.2544],
        [1.3879, 1.2371, 1.2279, 1.2695, 1.2702, 1.2818, 1.2756, 1.1822, 1.1822,
         3.7112, 3.7455, 3.6803, 3.8330, 3.7129, 3.9438, 3.6490, 3.6943, 3.8661,
         1.6036, 1.5921, 1.5686, 1.5650, 1.5838, 1.5933, 1.6192, 1.5932, 1.5932,
         1.3612, 1.3302, 1.3190, 1.3786, 1.3204, 1.4166, 1.3965, 1.3646, 1.3158,
         1.5735, 1.6258, 1.5907, 1.5789, 1.5751, 1.6093, 1.6294, 1.4716, 1.5664,
         1.1810, 1.2923, 1.2648, 1.3138, 1.1747, 1.1784, 1.1136, 1.3749, 1.2549],
        [1.4563, 1.4562, 1.4544, 1.4515, 1.4516, 1.4563, 1.4519, 1.4563, 1.4563,
         1.4349, 1.4339, 1.4349, 1.4349, 1.4349, 1.4150, 1.4349, 1.4335, 1.4312,
         2.1965, 2.1984, 2.2159, 2.1911, 2.1696, 2.1680, 2.1981, 2.1665, 2.1665,
         1.5263, 1.5249, 1.5325, 1.5325, 1.5263, 1.5325, 1.5324, 1.5325, 1.5325,
         1.7588, 1.7589, 1.7589, 1.7554, 1.7588, 1.7588, 1.7589, 1.7345, 1.7373,
         1.4387, 1.4442, 1.4442, 1.4442, 1.4351, 1.4441, 1.4385, 1.4442, 1.4442],
        [1.3261, 1.3243, 1.3075, 1.2987, 1.3232, 1.3215, 1.3226, 1.3233, 1.3233,
         1.3051, 1.2983, 1.2947, 1.2938, 1.3058, 1.2895, 1.3018, 1.3053, 1.2770,
         1.6475, 1.6200, 1.6439, 1.6435, 1.6431, 1.6430, 1.6454, 1.6467, 1.6467,
         3.4792, 3.2942, 3.2216, 3.2819, 3.4177, 3.2497, 3.4616, 3.2310, 3.2082,
         1.6363, 1.6289, 1.6267, 1.6301, 1.6330, 1.6093, 1.6342, 1.5729, 1.6000,
         1.3123, 1.3080, 1.2981, 1.3132, 1.3080, 1.2997, 1.3115, 1.3139, 1.3149],
        [1.4588, 1.4530, 1.4062, 1.4122, 1.4514, 1.4588, 1.4570, 1.4589, 1.4589,
         1.4365, 1.4335, 1.4284, 1.4212, 1.4376, 1.3908, 1.4313, 1.4376, 1.4308,
         1.7534, 1.7448, 1.7402, 1.7500, 1.7702, 1.7682, 1.7474, 1.7704, 1.7704,
         1.4911, 1.4926, 1.5349, 1.5288, 1.4963, 1.5331, 1.5214, 1.5349, 1.5318,
         2.2004, 2.1754, 2.1635, 2.1847, 2.2339, 2.2481, 2.2111, 2.3329, 2.3275,
         1.4275, 1.4222, 1.4364, 1.4473, 1.4310, 1.4433, 1.4075, 1.4411, 1.4473],
        [1.3504, 1.2549, 1.2514, 1.2689, 1.2628, 1.2723, 1.2713, 1.2085, 1.2085,
         1.2828, 1.2438, 1.2427, 1.2475, 1.3210, 1.2012, 1.1725, 1.3210, 1.2282,
         1.6142, 1.5908, 1.5722, 1.5674, 1.5875, 1.5850, 1.6063, 1.5891, 1.5891,
         1.3583, 1.3322, 1.3283, 1.3494, 1.3316, 1.3782, 1.3793, 1.3516, 1.3284,
         1.5871, 1.5876, 1.5912, 1.5815, 1.5570, 1.5600, 1.6233, 1.5144, 1.4832,
         3.8701, 3.6964, 3.7368, 3.7321, 3.7267, 3.5693, 3.8632, 3.7236, 3.5891]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 81 : 1779.7198145283674
Test loss for epoch 81 : 195.09128209651334
Test Precision for epoch 81 : 0.26153846153846155
Test Recall for epoch 81 : 0.26153846153846155
Test F1 for epoch 81 : 0.26153846153846155


theta for epoch 82 : tensor([[3.6583, 3.6697, 3.7591, 3.7268, 3.7216, 3.6420, 3.6710, 3.5953, 3.5953,
         1.2690, 1.2531, 1.2521, 1.2532, 1.2838, 1.2344, 1.2165, 1.2838, 1.2412,
         1.5995, 1.5843, 1.6071, 1.5894, 1.5968, 1.5982, 1.6061, 1.5982, 1.5982,
         1.3337, 1.3449, 1.3334, 1.3520, 1.3343, 1.3617, 1.3555, 1.3440, 1.3334,
         1.5872, 1.6036, 1.5924, 1.5892, 1.5959, 1.5864, 1.6047, 1.5577, 1.5626,
         1.2382, 1.2653, 1.2571, 1.2742, 1.2336, 1.2256, 1.2160, 1.2958, 1.2538],
        [1.3870, 1.2383, 1.2290, 1.2702, 1.2709, 1.2825, 1.2763, 1.1843, 1.1843,
         3.7023, 3.7371, 3.6709, 3.8259, 3.7040, 3.9383, 3.6393, 3.6851, 3.8595,
         1.6090, 1.5974, 1.5739, 1.5704, 1.5893, 1.5988, 1.6246, 1.5987, 1.5987,
         1.3590, 1.3282, 1.3176, 1.3764, 1.3187, 1.4139, 1.3940, 1.3626, 1.3144,
         1.5760, 1.6282, 1.5932, 1.5813, 1.5776, 1.6117, 1.6318, 1.4739, 1.5689,
         1.1801, 1.2914, 1.2640, 1.3130, 1.1738, 1.1774, 1.1132, 1.3741, 1.2540],
        [1.4521, 1.4520, 1.4502, 1.4474, 1.4474, 1.4521, 1.4477, 1.4521, 1.4521,
         1.4325, 1.4315, 1.4325, 1.4324, 1.4325, 1.4126, 1.4325, 1.4311, 1.4288,
         2.2019, 2.2037, 2.2212, 2.1958, 2.1745, 2.1728, 2.2028, 2.1714, 2.1714,
         1.5183, 1.5168, 1.5245, 1.5244, 1.5183, 1.5244, 1.5244, 1.5244, 1.5245,
         1.7613, 1.7614, 1.7614, 1.7579, 1.7613, 1.7613, 1.7614, 1.7370, 1.7398,
         1.4387, 1.4443, 1.4442, 1.4443, 1.4351, 1.4441, 1.4386, 1.4443, 1.4442],
        [1.3204, 1.3187, 1.3020, 1.2933, 1.3177, 1.3159, 1.3170, 1.3179, 1.3179,
         1.3026, 1.2958, 1.2923, 1.2913, 1.3033, 1.2870, 1.2992, 1.3028, 1.2746,
         1.6541, 1.6266, 1.6505, 1.6501, 1.6497, 1.6496, 1.6520, 1.6533, 1.6533,
         3.4752, 3.2882, 3.2151, 3.2756, 3.4130, 3.2432, 3.4571, 3.2245, 3.2015,
         1.6387, 1.6313, 1.6291, 1.6325, 1.6354, 1.6117, 1.6366, 1.5753, 1.6024,
         1.3120, 1.3077, 1.2977, 1.3128, 1.3077, 1.2994, 1.3112, 1.3136, 1.3146],
        [1.4547, 1.4490, 1.4027, 1.4084, 1.4474, 1.4546, 1.4529, 1.4547, 1.4547,
         1.4341, 1.4310, 1.4259, 1.4187, 1.4353, 1.3884, 1.4289, 1.4352, 1.4283,
         1.7603, 1.7517, 1.7471, 1.7569, 1.7771, 1.7751, 1.7544, 1.7773, 1.7773,
         1.4832, 1.4849, 1.5269, 1.5208, 1.4884, 1.5251, 1.5133, 1.5269, 1.5237,
         2.2016, 2.1764, 2.1645, 2.1858, 2.2350, 2.2490, 2.2122, 2.3340, 2.3285,
         1.4275, 1.4222, 1.4365, 1.4473, 1.4310, 1.4434, 1.4076, 1.4412, 1.4473],
        [1.3471, 1.2517, 1.2482, 1.2658, 1.2597, 1.2691, 1.2681, 1.2054, 1.2054,
         1.2790, 1.2404, 1.2394, 1.2439, 1.3166, 1.1976, 1.1697, 1.3166, 1.2250,
         1.6184, 1.5949, 1.5766, 1.5714, 1.5916, 1.5890, 1.6104, 1.5932, 1.5932,
         1.3521, 1.3261, 1.3225, 1.3432, 1.3254, 1.3719, 1.3730, 1.3456, 1.3225,
         1.5877, 1.5882, 1.5917, 1.5820, 1.5576, 1.5607, 1.6240, 1.5148, 1.4836,
         3.8717, 3.6949, 3.7360, 3.7312, 3.7260, 3.5662, 3.8648, 3.7224, 3.5862]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 82 : 1779.764072018249
Test loss for epoch 82 : 195.00232654693343
Test Precision for epoch 82 : 0.26153846153846155
Test Recall for epoch 82 : 0.26153846153846155
Test F1 for epoch 82 : 0.26153846153846155


theta for epoch 83 : tensor([[3.6538, 3.6656, 3.7563, 3.7234, 3.7183, 3.6375, 3.6668, 3.5902, 3.5902,
         1.2659, 1.2501, 1.2491, 1.2502, 1.2805, 1.2313, 1.2134, 1.2805, 1.2381,
         1.6014, 1.5861, 1.6091, 1.5912, 1.5985, 1.6000, 1.6079, 1.6000, 1.6000,
         1.3321, 1.3433, 1.3311, 1.3506, 1.3323, 1.3608, 1.3543, 1.3423, 1.3311,
         1.5912, 1.6077, 1.5964, 1.5932, 1.6000, 1.5904, 1.6088, 1.5616, 1.5666,
         1.2374, 1.2648, 1.2566, 1.2739, 1.2327, 1.2245, 1.2152, 1.2959, 1.2532],
        [1.3807, 1.2335, 1.2241, 1.2651, 1.2659, 1.2774, 1.2713, 1.1804, 1.1804,
         3.6999, 3.7352, 3.6680, 3.8252, 3.7016, 3.9392, 3.6361, 3.6824, 3.8594,
         1.6068, 1.5952, 1.5715, 1.5682, 1.5872, 1.5968, 1.6224, 1.5967, 1.5967,
         1.3530, 1.3222, 1.3124, 1.3704, 1.3131, 1.4075, 1.3878, 1.3567, 1.3092,
         1.5775, 1.6298, 1.5948, 1.5829, 1.5791, 1.6133, 1.6334, 1.4750, 1.5705,
         1.1756, 1.2873, 1.2597, 1.3089, 1.1693, 1.1730, 1.1090, 1.3702, 1.2498],
        [1.4492, 1.4491, 1.4474, 1.4445, 1.4446, 1.4492, 1.4448, 1.4492, 1.4492,
         1.4298, 1.4287, 1.4297, 1.4297, 1.4298, 1.4098, 1.4297, 1.4283, 1.4260,
         2.2032, 2.2049, 2.2224, 2.1967, 2.1754, 2.1738, 2.2037, 2.1724, 2.1724,
         1.5127, 1.5112, 1.5189, 1.5188, 1.5127, 1.5188, 1.5188, 1.5189, 1.5189,
         1.7658, 1.7660, 1.7660, 1.7625, 1.7658, 1.7659, 1.7660, 1.7417, 1.7445,
         1.4389, 1.4444, 1.4444, 1.4445, 1.4353, 1.4443, 1.4388, 1.4445, 1.4444],
        [1.3160, 1.3146, 1.2980, 1.2892, 1.3135, 1.3117, 1.3129, 1.3139, 1.3139,
         1.2998, 1.2930, 1.2894, 1.2885, 1.3005, 1.2841, 1.2963, 1.3000, 1.2717,
         1.6560, 1.6285, 1.6524, 1.6520, 1.6516, 1.6515, 1.6539, 1.6552, 1.6552,
         3.4731, 3.2843, 3.2107, 3.2715, 3.4103, 3.2389, 3.4546, 3.2201, 3.1971,
         1.6432, 1.6358, 1.6336, 1.6370, 1.6399, 1.6162, 1.6411, 1.5798, 1.6069,
         1.3119, 1.3074, 1.2975, 1.3126, 1.3075, 1.2992, 1.3110, 1.3133, 1.3144],
        [1.4518, 1.4463, 1.4005, 1.4059, 1.4446, 1.4517, 1.4500, 1.4518, 1.4518,
         1.4313, 1.4283, 1.4231, 1.4160, 1.4326, 1.3856, 1.4261, 1.4325, 1.4256,
         1.7626, 1.7541, 1.7495, 1.7593, 1.7795, 1.7774, 1.7568, 1.7796, 1.7796,
         1.4778, 1.4798, 1.5213, 1.5153, 1.4830, 1.5196, 1.5078, 1.5213, 1.5181,
         2.2047, 2.1795, 2.1676, 2.1889, 2.2381, 2.2519, 2.2153, 2.3371, 2.3315,
         1.4278, 1.4224, 1.4367, 1.4475, 1.4313, 1.4436, 1.4079, 1.4414, 1.4475],
        [1.3428, 1.2470, 1.2435, 1.2612, 1.2551, 1.2646, 1.2635, 1.2006, 1.2006,
         1.2739, 1.2356, 1.2346, 1.2389, 1.3111, 1.1924, 1.1649, 1.3111, 1.2202,
         1.6168, 1.5933, 1.5753, 1.5697, 1.5900, 1.5874, 1.6089, 1.5917, 1.5917,
         1.3461, 1.3201, 1.3168, 1.3372, 1.3194, 1.3659, 1.3670, 1.3397, 1.3168,
         1.5893, 1.5900, 1.5934, 1.5837, 1.5593, 1.5625, 1.6259, 1.5163, 1.4851,
         3.8766, 3.6968, 3.7386, 3.7336, 3.7286, 3.5665, 3.8696, 3.7246, 3.5866]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 83 : 1779.8041101089113
Test loss for epoch 83 : 195.10473855102683
Test Precision for epoch 83 : 0.26153846153846155
Test Recall for epoch 83 : 0.26153846153846155
Test F1 for epoch 83 : 0.26153846153846155


theta for epoch 84 : tensor([[3.6535, 3.6657, 3.7577, 3.7242, 3.7191, 3.6371, 3.6668, 3.5894, 3.5894,
         1.2634, 1.2476, 1.2466, 1.2477, 1.2781, 1.2287, 1.2105, 1.2781, 1.2356,
         1.5965, 1.5810, 1.6042, 1.5861, 1.5934, 1.5949, 1.6029, 1.5949, 1.5949,
         1.3375, 1.3486, 1.3356, 1.3561, 1.3372, 1.3669, 1.3601, 1.3476, 1.3357,
         1.5939, 1.6106, 1.5992, 1.5959, 1.6028, 1.5933, 1.6117, 1.5643, 1.5694,
         1.2355, 1.2633, 1.2549, 1.2726, 1.2306, 1.2223, 1.2131, 1.2950, 1.2515],
        [1.3732, 1.2270, 1.2174, 1.2584, 1.2592, 1.2707, 1.2646, 1.1745, 1.1745,
         3.7039, 3.7397, 3.6716, 3.8310, 3.7057, 3.9466, 3.6394, 3.6861, 3.8658,
         1.5957, 1.5842, 1.5602, 1.5571, 1.5763, 1.5858, 1.6115, 1.5858, 1.5858,
         1.3476, 1.3167, 1.3076, 1.3649, 1.3079, 1.4018, 1.3822, 1.3515, 1.3044,
         1.5754, 1.6277, 1.5927, 1.5808, 1.5770, 1.6112, 1.6314, 1.4721, 1.5683,
         1.1670, 1.2792, 1.2516, 1.3009, 1.1607, 1.1645, 1.1005, 1.3625, 1.2416],
        [1.4518, 1.4517, 1.4500, 1.4472, 1.4472, 1.4518, 1.4474, 1.4518, 1.4518,
         1.4279, 1.4268, 1.4278, 1.4277, 1.4279, 1.4079, 1.4278, 1.4264, 1.4241,
         2.1985, 2.2002, 2.2177, 2.1919, 2.1708, 2.1692, 2.1990, 2.1677, 2.1677,
         1.5143, 1.5128, 1.5204, 1.5204, 1.5143, 1.5204, 1.5204, 1.5204, 1.5204,
         1.7694, 1.7695, 1.7695, 1.7660, 1.7694, 1.7694, 1.7695, 1.7453, 1.7481,
         1.4382, 1.4437, 1.4437, 1.4437, 1.4346, 1.4436, 1.4381, 1.4438, 1.4437],
        [1.3175, 1.3162, 1.2997, 1.2910, 1.3151, 1.3133, 1.3145, 1.3155, 1.3155,
         1.2977, 1.2910, 1.2874, 1.2864, 1.2985, 1.2820, 1.2942, 1.2980, 1.2697,
         1.6512, 1.6237, 1.6476, 1.6472, 1.6468, 1.6468, 1.6491, 1.6505, 1.6505,
         3.4766, 3.2860, 3.2121, 3.2731, 3.4131, 3.2402, 3.4575, 3.2215, 3.1984,
         1.6466, 1.6392, 1.6370, 1.6403, 1.6432, 1.6196, 1.6445, 1.5832, 1.6102,
         1.3107, 1.3063, 1.2963, 1.3114, 1.3063, 1.2980, 1.3099, 1.3121, 1.3132],
        [1.4544, 1.4491, 1.4038, 1.4090, 1.4474, 1.4543, 1.4527, 1.4544, 1.4544,
         1.4294, 1.4264, 1.4212, 1.4141, 1.4307, 1.3837, 1.4242, 1.4307, 1.4237,
         1.7585, 1.7500, 1.7454, 1.7552, 1.7753, 1.7733, 1.7527, 1.7755, 1.7755,
         1.4795, 1.4818, 1.5229, 1.5170, 1.4848, 1.5212, 1.5094, 1.5229, 1.5197,
         2.2069, 2.1817, 2.1698, 2.1911, 2.2402, 2.2539, 2.2174, 2.3391, 2.3334,
         1.4272, 1.4217, 1.4359, 1.4468, 1.4306, 1.4429, 1.4073, 1.4406, 1.4468],
        [1.3416, 1.2452, 1.2418, 1.2596, 1.2535, 1.2630, 1.2619, 1.1984, 1.1984,
         1.2689, 1.2305, 1.2295, 1.2338, 1.3058, 1.1869, 1.1594, 1.3058, 1.2150,
         1.6079, 1.5842, 1.5666, 1.5605, 1.5809, 1.5784, 1.5999, 1.5826, 1.5826,
         1.3452, 1.3191, 1.3160, 1.3362, 1.3184, 1.3649, 1.3661, 1.3389, 1.3161,
         1.5891, 1.5898, 1.5932, 1.5835, 1.5591, 1.5624, 1.6259, 1.5159, 1.4846,
         3.8839, 3.7010, 3.7434, 3.7383, 3.7336, 3.5691, 3.8768, 3.7291, 3.5894]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 84 : 1779.3150851496323
Test loss for epoch 84 : 195.30296986080657
Test Precision for epoch 84 : 0.26153846153846155
Test Recall for epoch 84 : 0.26153846153846155
Test F1 for epoch 84 : 0.26153846153846155


theta for epoch 85 : tensor([[3.6562, 3.6689, 3.7620, 3.7280, 3.7229, 3.6397, 3.6698, 3.5917, 3.5917,
         1.2618, 1.2457, 1.2447, 1.2458, 1.2765, 1.2267, 1.2079, 1.2765, 1.2336,
         1.5910, 1.5754, 1.5988, 1.5805, 1.5878, 1.5893, 1.5974, 1.5893, 1.5893,
         1.3459, 1.3569, 1.3433, 1.3647, 1.3453, 1.3760, 1.3689, 1.3560, 1.3433,
         1.5933, 1.6101, 1.5985, 1.5953, 1.6022, 1.5927, 1.6112, 1.5637, 1.5687,
         1.2326, 1.2609, 1.2523, 1.2703, 1.2276, 1.2190, 1.2100, 1.2931, 1.2487],
        [1.3633, 1.2177, 1.2079, 1.2489, 1.2498, 1.2613, 1.2552, 1.1656, 1.1656,
         3.7138, 3.7501, 3.6811, 3.8426, 3.7155, 3.9597, 3.6487, 3.6957, 3.8779,
         1.5817, 1.5701, 1.5459, 1.5430, 1.5623, 1.5719, 1.5976, 1.5719, 1.5719,
         1.3404, 1.3093, 1.3009, 1.3579, 1.3008, 1.3946, 1.3750, 1.3445, 1.2977,
         1.5677, 1.6203, 1.5852, 1.5731, 1.5693, 1.6037, 1.6239, 1.4636, 1.5606,
         1.1548, 1.2677, 1.2399, 1.2895, 1.1485, 1.1523, 1.0881, 1.3514, 1.2298],
        [1.4575, 1.4574, 1.4558, 1.4530, 1.4530, 1.4575, 1.4531, 1.4575, 1.4575,
         1.4269, 1.4258, 1.4269, 1.4268, 1.4269, 1.4070, 1.4268, 1.4255, 1.4231,
         2.1937, 2.1953, 2.2127, 2.1870, 2.1659, 2.1644, 2.1942, 2.1629, 2.1629,
         1.5195, 1.5180, 1.5256, 1.5256, 1.5195, 1.5256, 1.5256, 1.5256, 1.5256,
         1.7698, 1.7699, 1.7699, 1.7664, 1.7698, 1.7698, 1.7699, 1.7457, 1.7485,
         1.4367, 1.4422, 1.4422, 1.4422, 1.4331, 1.4421, 1.4367, 1.4422, 1.4422],
        [1.3223, 1.3211, 1.3048, 1.2961, 1.3200, 1.3183, 1.3194, 1.3205, 1.3205,
         1.2966, 1.2898, 1.2862, 1.2853, 1.2974, 1.2808, 1.2930, 1.2969, 1.2686,
         1.6461, 1.6185, 1.6425, 1.6421, 1.6417, 1.6416, 1.6439, 1.6453, 1.6453,
         3.4828, 3.2908, 3.2166, 3.2777, 3.4189, 3.2445, 3.4634, 3.2259, 3.2029,
         1.6467, 1.6394, 1.6371, 1.6405, 1.6434, 1.6198, 1.6446, 1.5834, 1.6104,
         1.3087, 1.3042, 1.2943, 1.3094, 1.3043, 1.2960, 1.3079, 1.3101, 1.3112],
        [1.4601, 1.4550, 1.4103, 1.4152, 1.4533, 1.4601, 1.4585, 1.4602, 1.4602,
         1.4285, 1.4254, 1.4203, 1.4131, 1.4298, 1.3829, 1.4233, 1.4297, 1.4227,
         1.7540, 1.7455, 1.7409, 1.7508, 1.7709, 1.7688, 1.7482, 1.7710, 1.7710,
         1.4850, 1.4875, 1.5281, 1.5223, 1.4902, 1.5264, 1.5146, 1.5281, 1.5249,
         2.2060, 2.1808, 2.1689, 2.1902, 2.2393, 2.2528, 2.2166, 2.3381, 2.3323,
         1.4258, 1.4201, 1.4344, 1.4453, 1.4292, 1.4414, 1.4060, 1.4391, 1.4453],
        [1.3418, 1.2445, 1.2411, 1.2591, 1.2530, 1.2625, 1.2614, 1.1972, 1.1972,
         1.2639, 1.2253, 1.2244, 1.2286, 1.3009, 1.1814, 1.1533, 1.3009, 1.2098,
         1.5978, 1.5740, 1.5568, 1.5501, 1.5708, 1.5681, 1.5898, 1.5724, 1.5724,
         1.3462, 1.3199, 1.3170, 1.3371, 1.3193, 1.3659, 1.3671, 1.3399, 1.3171,
         1.5849, 1.5857, 1.5891, 1.5793, 1.5550, 1.5584, 1.6220, 1.5115, 1.4802,
         3.8932, 3.7074, 3.7504, 3.7452, 3.7406, 3.5739, 3.8861, 3.7357, 3.5942]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 85 : 1778.7730292773876
Test loss for epoch 85 : 195.67046921391307
Test Precision for epoch 85 : 0.26153846153846155
Test Recall for epoch 85 : 0.26153846153846155
Test F1 for epoch 85 : 0.26153846153846155


theta for epoch 86 : tensor([[3.6559, 3.6690, 3.7633, 3.7288, 3.7237, 3.6394, 3.6698, 3.5910, 3.5910,
         1.2606, 1.2445, 1.2435, 1.2447, 1.2752, 1.2255, 1.2066, 1.2752, 1.2325,
         1.5910, 1.5753, 1.5988, 1.5804, 1.5876, 1.5891, 1.5974, 1.5891, 1.5891,
         1.3514, 1.3624, 1.3481, 1.3704, 1.3505, 1.3822, 1.3749, 1.3615, 1.3481,
         1.5911, 1.6080, 1.5964, 1.5931, 1.6000, 1.5906, 1.6091, 1.5614, 1.5665,
         1.2308, 1.2595, 1.2507, 1.2690, 1.2256, 1.2168, 1.2080, 1.2923, 1.2471],
        [1.3609, 1.2165, 1.2065, 1.2475, 1.2483, 1.2599, 1.2538, 1.1650, 1.1650,
         3.7146, 3.7514, 3.6814, 3.8450, 3.7163, 3.9638, 3.6486, 3.6962, 3.8809,
         1.5769, 1.5653, 1.5409, 1.5383, 1.5577, 1.5673, 1.5929, 1.5673, 1.5673,
         1.3391, 1.3079, 1.3002, 1.3565, 1.2997, 1.3929, 1.3735, 1.3433, 1.2971,
         1.5622, 1.6148, 1.5797, 1.5676, 1.5637, 1.5982, 1.6184, 1.4576, 1.5550,
         1.1483, 1.2615, 1.2337, 1.2835, 1.1419, 1.1458, 1.0816, 1.3456, 1.2236],
        [1.4613, 1.4612, 1.4596, 1.4568, 1.4569, 1.4613, 1.4570, 1.4613, 1.4613,
         1.4262, 1.4251, 1.4261, 1.4261, 1.4262, 1.4063, 1.4261, 1.4247, 1.4224,
         2.1934, 2.1950, 2.2124, 2.1865, 2.1656, 2.1640, 2.1937, 2.1626, 2.1626,
         1.5214, 1.5199, 1.5275, 1.5275, 1.5214, 1.5275, 1.5275, 1.5275, 1.5275,
         1.7683, 1.7684, 1.7684, 1.7649, 1.7683, 1.7683, 1.7684, 1.7443, 1.7471,
         1.4357, 1.4412, 1.4412, 1.4412, 1.4321, 1.4411, 1.4357, 1.4412, 1.4412],
        [1.3252, 1.3242, 1.3080, 1.2993, 1.3231, 1.3213, 1.3225, 1.3237, 1.3237,
         1.2957, 1.2889, 1.2852, 1.2843, 1.2964, 1.2799, 1.2920, 1.2959, 1.2676,
         1.6458, 1.6183, 1.6422, 1.6418, 1.6414, 1.6413, 1.6436, 1.6451, 1.6451,
         3.4867, 3.2932, 3.2187, 3.2799, 3.4222, 3.2465, 3.4668, 3.2279, 3.2049,
         1.6450, 1.6376, 1.6354, 1.6387, 1.6416, 1.6180, 1.6429, 1.5817, 1.6086,
         1.3072, 1.3027, 1.2927, 1.3078, 1.3028, 1.2946, 1.3065, 1.3085, 1.3096],
        [1.4639, 1.4590, 1.4148, 1.4194, 1.4572, 1.4639, 1.4623, 1.4640, 1.4640,
         1.4278, 1.4247, 1.4195, 1.4124, 1.4291, 1.3822, 1.4225, 1.4290, 1.4220,
         1.7544, 1.7459, 1.7413, 1.7512, 1.7712, 1.7692, 1.7486, 1.7713, 1.7713,
         1.4871, 1.4899, 1.5300, 1.5243, 1.4923, 1.5284, 1.5166, 1.5300, 1.5268,
         2.2034, 2.1782, 2.1663, 2.1876, 2.2366, 2.2500, 2.2139, 2.3353, 2.3295,
         1.4249, 1.4191, 1.4334, 1.4442, 1.4282, 1.4404, 1.4052, 1.4381, 1.4443],
        [1.3415, 1.2435, 1.2401, 1.2582, 1.2521, 1.2616, 1.2605, 1.1957, 1.1957,
         1.2596, 1.2212, 1.2203, 1.2244, 1.2963, 1.1770, 1.1490, 1.2963, 1.2057,
         1.5934, 1.5695, 1.5525, 1.5454, 1.5663, 1.5636, 1.5854, 1.5680, 1.5680,
         1.3452, 1.3188, 1.3160, 1.3360, 1.3182, 1.3649, 1.3661, 1.3389, 1.3161,
         1.5794, 1.5803, 1.5836, 1.5737, 1.5495, 1.5530, 1.6167, 1.5058, 1.4744,
         3.9013, 3.7125, 3.7562, 3.7508, 3.7465, 3.5775, 3.8942, 3.7410, 3.5979]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 86 : 1778.6702754562557
Test loss for epoch 86 : 195.85402374223375
Test Precision for epoch 86 : 0.26153846153846155
Test Recall for epoch 86 : 0.26153846153846155
Test F1 for epoch 86 : 0.26153846153846155


theta for epoch 87 : tensor([[3.6512, 3.6646, 3.7602, 3.7251, 3.7201, 3.6346, 3.6654, 3.5857, 3.5857,
         1.2604, 1.2445, 1.2435, 1.2446, 1.2748, 1.2254, 1.2068, 1.2748, 1.2325,
         1.5966, 1.5809, 1.6046, 1.5860, 1.5932, 1.5947, 1.6030, 1.5947, 1.5947,
         1.3499, 1.3609, 1.3460, 1.3691, 1.3487, 1.3812, 1.3737, 1.3600, 1.3460,
         1.5896, 1.6065, 1.5948, 1.5916, 1.5985, 1.5891, 1.6077, 1.5599, 1.5650,
         1.2305, 1.2595, 1.2506, 1.2692, 1.2252, 1.2162, 1.2075, 1.2928, 1.2469],
        [1.3620, 1.2194, 1.2094, 1.2501, 1.2510, 1.2625, 1.2564, 1.1687, 1.1687,
         3.7075, 3.7448, 3.6739, 3.8397, 3.7093, 3.9601, 3.6407, 3.6889, 3.8762,
         1.5812, 1.5696, 1.5450, 1.5427, 1.5622, 1.5718, 1.5971, 1.5718, 1.5718,
         1.3396, 1.3085, 1.3016, 1.3569, 1.3007, 1.3928, 1.3737, 1.3439, 1.2984,
         1.5605, 1.6130, 1.5780, 1.5659, 1.5620, 1.5964, 1.6165, 1.4557, 1.5532,
         1.1473, 1.2607, 1.2328, 1.2827, 1.1410, 1.1449, 1.0806, 1.3449, 1.2227],
        [1.4593, 1.4593, 1.4577, 1.4549, 1.4550, 1.4594, 1.4550, 1.4594, 1.4594,
         1.4261, 1.4251, 1.4261, 1.4260, 1.4262, 1.4063, 1.4260, 1.4247, 1.4224,
         2.1981, 2.1996, 2.2170, 2.1907, 2.1699, 2.1683, 2.1980, 2.1669, 2.1669,
         1.5163, 1.5148, 1.5224, 1.5224, 1.5163, 1.5224, 1.5224, 1.5224, 1.5224,
         1.7672, 1.7673, 1.7673, 1.7638, 1.7672, 1.7672, 1.7673, 1.7432, 1.7460,
         1.4357, 1.4412, 1.4412, 1.4412, 1.4321, 1.4411, 1.4358, 1.4412, 1.4412],
        [1.3225, 1.3215, 1.3054, 1.2967, 1.3204, 1.3186, 1.3198, 1.3210, 1.3210,
         1.2954, 1.2886, 1.2850, 1.2840, 1.2961, 1.2796, 1.2917, 1.2956, 1.2674,
         1.6507, 1.6232, 1.6471, 1.6467, 1.6463, 1.6463, 1.6486, 1.6500, 1.6500,
         3.4853, 3.2902, 3.2154, 3.2768, 3.4203, 3.2433, 3.4650, 3.2246, 3.2016,
         1.6435, 1.6362, 1.6339, 1.6373, 1.6402, 1.6166, 1.6415, 1.5803, 1.6072,
         1.3068, 1.3022, 1.2922, 1.3073, 1.3023, 1.2941, 1.3060, 1.3079, 1.3091],
        [1.4620, 1.4572, 1.4133, 1.4178, 1.4554, 1.4620, 1.4604, 1.4621, 1.4621,
         1.4277, 1.4247, 1.4195, 1.4124, 1.4290, 1.3823, 1.4225, 1.4290, 1.4220,
         1.7598, 1.7513, 1.7468, 1.7567, 1.7766, 1.7746, 1.7540, 1.7767, 1.7767,
         1.4822, 1.4852, 1.5249, 1.5193, 1.4874, 1.5233, 1.5115, 1.5249, 1.5218,
         2.2012, 2.1760, 2.1641, 2.1853, 2.2343, 2.2476, 2.2117, 2.3329, 2.3270,
         1.4250, 1.4191, 1.4334, 1.4442, 1.4283, 1.4404, 1.4054, 1.4380, 1.4442],
        [1.3374, 1.2386, 1.2353, 1.2536, 1.2474, 1.2570, 1.2558, 1.1904, 1.1904,
         1.2564, 1.2185, 1.2177, 1.2215, 1.2925, 1.1740, 1.1471, 1.2925, 1.2032,
         1.5950, 1.5710, 1.5542, 1.5468, 1.5678, 1.5651, 1.5870, 1.5695, 1.5695,
         1.3386, 1.3121, 1.3095, 1.3294, 1.3116, 1.3583, 1.3595, 1.3323, 1.3095,
         1.5746, 1.5756, 1.5789, 1.5690, 1.5449, 1.5485, 1.6122, 1.5009, 1.4696,
         3.9085, 3.7167, 3.7610, 3.7555, 3.7514, 3.5801, 3.9014, 3.7455, 3.6007]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 87 : 1778.6043676695633
Test loss for epoch 87 : 195.92666913489705
Test Precision for epoch 87 : 0.26153846153846155
Test Recall for epoch 87 : 0.26153846153846155
Test F1 for epoch 87 : 0.26153846153846155


theta for epoch 88 : tensor([[3.6413, 3.6549, 3.7518, 3.7161, 3.7111, 3.6245, 3.6556, 3.5750, 3.5750,
         1.2618, 1.2462, 1.2453, 1.2463, 1.2758, 1.2272, 1.2091, 1.2758, 1.2343,
         1.6039, 1.5881, 1.6119, 1.5932, 1.6004, 1.6019, 1.6102, 1.6019, 1.6019,
         1.3478, 1.3587, 1.3434, 1.3670, 1.3463, 1.3794, 1.3717, 1.3578, 1.3434,
         1.5897, 1.6067, 1.5950, 1.5917, 1.5987, 1.5893, 1.6079, 1.5600, 1.5651,
         1.2309, 1.2598, 1.2508, 1.2696, 1.2256, 1.2167, 1.2079, 1.2936, 1.2470],
        [1.3685, 1.2285, 1.2183, 1.2587, 1.2595, 1.2710, 1.2649, 1.1788, 1.1788,
         3.6932, 3.7309, 3.6590, 3.8271, 3.6950, 3.9491, 3.6254, 3.6743, 3.8641,
         1.5903, 1.5787, 1.5541, 1.5522, 1.5716, 1.5812, 1.6062, 1.5812, 1.5812,
         1.3459, 1.3150, 1.3089, 1.3630, 1.3076, 1.3982, 1.3795, 1.3503, 1.3058,
         1.5633, 1.6155, 1.5808, 1.5687, 1.5646, 1.5990, 1.6190, 1.4585, 1.5560,
         1.1515, 1.2635, 1.2357, 1.2855, 1.1454, 1.1496, 1.0853, 1.3477, 1.2256],
        [1.4545, 1.4544, 1.4529, 1.4501, 1.4502, 1.4545, 1.4502, 1.4545, 1.4545,
         1.4271, 1.4260, 1.4271, 1.4270, 1.4272, 1.4073, 1.4270, 1.4257, 1.4233,
         2.2036, 2.2050, 2.2223, 2.1957, 2.1750, 2.1734, 2.2030, 2.1721, 2.1721,
         1.5095, 1.5080, 1.5156, 1.5156, 1.5096, 1.5156, 1.5156, 1.5156, 1.5156,
         1.7671, 1.7672, 1.7672, 1.7637, 1.7671, 1.7671, 1.7672, 1.7432, 1.7460,
         1.4351, 1.4405, 1.4405, 1.4405, 1.4315, 1.4404, 1.4352, 1.4405, 1.4405],
        [1.3169, 1.3160, 1.3000, 1.2913, 1.3149, 1.3131, 1.3143, 1.3155, 1.3155,
         1.2961, 1.2893, 1.2857, 1.2848, 1.2968, 1.2803, 1.2925, 1.2963, 1.2681,
         1.6563, 1.6288, 1.6527, 1.6524, 1.6520, 1.6519, 1.6542, 1.6557, 1.6557,
         3.4825, 3.2860, 3.2108, 3.2724, 3.4169, 3.2387, 3.4618, 3.2200, 3.1970,
         1.6431, 1.6358, 1.6336, 1.6369, 1.6398, 1.6162, 1.6411, 1.5800, 1.6068,
         1.3056, 1.3010, 1.2910, 1.3060, 1.3011, 1.2930, 1.3049, 1.3066, 1.3079],
        [1.4572, 1.4525, 1.4089, 1.4132, 1.4507, 1.4572, 1.4556, 1.4572, 1.4572,
         1.4287, 1.4257, 1.4205, 1.4134, 1.4300, 1.3834, 1.4235, 1.4300, 1.4230,
         1.7660, 1.7575, 1.7531, 1.7629, 1.7826, 1.7807, 1.7602, 1.7828, 1.7828,
         1.4755, 1.4787, 1.5181, 1.5126, 1.4808, 1.5166, 1.5048, 1.5182, 1.5150,
         2.2000, 2.1749, 2.1629, 2.1841, 2.2330, 2.2463, 2.2105, 2.3314, 2.3254,
         1.4245, 1.4184, 1.4328, 1.4435, 1.4278, 1.4398, 1.4050, 1.4374, 1.4435],
        [1.3445, 1.2460, 1.2427, 1.2610, 1.2549, 1.2644, 1.2632, 1.1978, 1.1978,
         1.2597, 1.2227, 1.2220, 1.2254, 1.2947, 1.1782, 1.1529, 1.2947, 1.2076,
         1.6045, 1.5805, 1.5640, 1.5564, 1.5774, 1.5747, 1.5965, 1.5791, 1.5791,
         1.3437, 1.3173, 1.3148, 1.3346, 1.3170, 1.3633, 1.3646, 1.3375, 1.3148,
         1.5765, 1.5776, 1.5808, 1.5709, 1.5470, 1.5506, 1.6141, 1.5030, 1.4718,
         3.8966, 3.7018, 3.7468, 3.7411, 3.7372, 3.5634, 3.8894, 3.7309, 3.5843]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 88 : 1779.3316866879918
Test loss for epoch 88 : 195.34432300787614
Test Precision for epoch 88 : 0.26153846153846155
Test Recall for epoch 88 : 0.26153846153846155
Test F1 for epoch 88 : 0.26153846153846155


theta for epoch 89 : tensor([[3.6340, 3.6478, 3.7459, 3.7098, 3.7047, 3.6170, 3.6484, 3.5669, 3.5669,
         1.2646, 1.2492, 1.2482, 1.2492, 1.2783, 1.2301, 1.2124, 1.2783, 1.2373,
         1.6040, 1.5882, 1.6121, 1.5933, 1.6004, 1.6020, 1.6103, 1.6020, 1.6020,
         1.3457, 1.3565, 1.3409, 1.3650, 1.3441, 1.3776, 1.3698, 1.3557, 1.3409,
         1.5902, 1.6073, 1.5956, 1.5922, 1.5993, 1.5899, 1.6085, 1.5605, 1.5657,
         1.2325, 1.2613, 1.2522, 1.2712, 1.2272, 1.2182, 1.2095, 1.2955, 1.2484],
        [1.3689, 1.2308, 1.2205, 1.2607, 1.2615, 1.2729, 1.2669, 1.1820, 1.1820,
         3.6870, 3.7251, 3.6524, 3.8226, 3.6889, 3.9463, 3.6184, 3.6679, 3.8602,
         1.5899, 1.5784, 1.5536, 1.5520, 1.5715, 1.5811, 1.6058, 1.5811, 1.5811,
         1.3467, 1.3159, 1.3106, 1.3637, 1.3089, 1.3984, 1.3799, 1.3513, 1.3074,
         1.5635, 1.6157, 1.5810, 1.5689, 1.5648, 1.5992, 1.6190, 1.4586, 1.5561,
         1.1527, 1.2639, 1.2360, 1.2859, 1.1469, 1.1514, 1.0868, 1.3482, 1.2259],
        [1.4504, 1.4503, 1.4488, 1.4460, 1.4461, 1.4504, 1.4461, 1.4504, 1.4504,
         1.4297, 1.4287, 1.4297, 1.4296, 1.4298, 1.4100, 1.4296, 1.4283, 1.4259,
         2.2030, 2.2043, 2.2217, 2.1950, 2.1744, 2.1728, 2.2023, 2.1715, 2.1715,
         1.5041, 1.5025, 1.5101, 1.5101, 1.5041, 1.5101, 1.5101, 1.5101, 1.5101,
         1.7677, 1.7678, 1.7678, 1.7644, 1.7677, 1.7677, 1.7678, 1.7439, 1.7466,
         1.4361, 1.4415, 1.4414, 1.4415, 1.4324, 1.4414, 1.4362, 1.4415, 1.4414],
        [1.3123, 1.3114, 1.2954, 1.2868, 1.3103, 1.3085, 1.3097, 1.3109, 1.3109,
         1.2984, 1.2917, 1.2880, 1.2871, 1.2991, 1.2826, 1.2948, 1.2986, 1.2705,
         1.6553, 1.6278, 1.6517, 1.6514, 1.6509, 1.6509, 1.6532, 1.6546, 1.6546,
         3.4806, 3.2828, 3.2073, 3.2690, 3.4145, 3.2352, 3.4596, 3.2165, 3.1934,
         1.6434, 1.6361, 1.6339, 1.6372, 1.6401, 1.6165, 1.6414, 1.5803, 1.6071,
         1.3061, 1.3014, 1.2914, 1.3064, 1.3016, 1.2935, 1.3054, 1.3070, 1.3083],
        [1.4532, 1.4485, 1.4051, 1.4093, 1.4467, 1.4531, 1.4516, 1.4531, 1.4531,
         1.4313, 1.4283, 1.4231, 1.4161, 1.4327, 1.3862, 1.4261, 1.4326, 1.4257,
         1.7656, 1.7570, 1.7528, 1.7625, 1.7822, 1.7803, 1.7598, 1.7824, 1.7824,
         1.4702, 1.4736, 1.5127, 1.5072, 1.4755, 1.5112, 1.4994, 1.5127, 1.5096,
         2.1995, 2.1745, 2.1626, 2.1837, 2.2325, 2.2457, 2.2101, 2.3306, 2.3246,
         1.4256, 1.4193, 1.4337, 1.4445, 1.4288, 1.4407, 1.4062, 1.4383, 1.4445],
        [1.3496, 1.2509, 1.2477, 1.2659, 1.2599, 1.2693, 1.2682, 1.2024, 1.2024,
         1.2633, 1.2270, 1.2263, 1.2295, 1.2977, 1.1823, 1.1580, 1.2977, 1.2120,
         1.6061, 1.5821, 1.5658, 1.5580, 1.5791, 1.5763, 1.5982, 1.5807, 1.5807,
         1.3471, 1.3208, 1.3182, 1.3380, 1.3206, 1.3667, 1.3679, 1.3410, 1.3183,
         1.5779, 1.5791, 1.5822, 1.5723, 1.5486, 1.5523, 1.6156, 1.5045, 1.4734,
         3.8898, 3.6920, 3.7376, 3.7318, 3.7280, 3.5519, 3.8825, 3.7214, 3.5731]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 89 : 1779.6036610604442
Test loss for epoch 89 : 195.07550399700685
Test Precision for epoch 89 : 0.26153846153846155
Test Recall for epoch 89 : 0.26153846153846155
Test F1 for epoch 89 : 0.26153846153846155


theta for epoch 90 : tensor([[3.6306, 3.6447, 3.7440, 3.7074, 3.7023, 3.6135, 3.6453, 3.5630, 3.5630,
         1.2671, 1.2518, 1.2508, 1.2518, 1.2807, 1.2327, 1.2151, 1.2807, 1.2399,
         1.5972, 1.5814, 1.6053, 1.5865, 1.5936, 1.5951, 1.6034, 1.5951, 1.5951,
         1.3463, 1.3570, 1.3412, 1.3655, 1.3445, 1.3783, 1.3705, 1.3562, 1.3412,
         1.5905, 1.6077, 1.5959, 1.5925, 1.5996, 1.5902, 1.6088, 1.5608, 1.5659,
         1.2354, 1.2641, 1.2549, 1.2741, 1.2301, 1.2211, 1.2122, 1.2987, 1.2510],
        [1.3662, 1.2293, 1.2189, 1.2590, 1.2598, 1.2712, 1.2652, 1.1811, 1.1811,
         3.6876, 3.7262, 3.6525, 3.8249, 3.6894, 3.9501, 3.6182, 3.6682, 3.8630,
         1.5805, 1.5690, 1.5441, 1.5428, 1.5623, 1.5719, 1.5964, 1.5719, 1.5719,
         1.3444, 1.3136, 1.3089, 1.3614, 1.3069, 1.3957, 1.3774, 1.3491, 1.3058,
         1.5609, 1.6131, 1.5785, 1.5663, 1.5621, 1.5966, 1.6163, 1.4556, 1.5534,
         1.1516, 1.2623, 1.2343, 1.2844, 1.1459, 1.1507, 1.0857, 1.3470, 1.2242],
        [1.4501, 1.4500, 1.4485, 1.4457, 1.4458, 1.4501, 1.4458, 1.4501, 1.4501,
         1.4324, 1.4313, 1.4323, 1.4323, 1.4325, 1.4127, 1.4323, 1.4310, 1.4286,
         2.1965, 2.1978, 2.2151, 2.1886, 2.1681, 2.1666, 2.1960, 2.1652, 2.1652,
         1.5024, 1.5008, 1.5084, 1.5084, 1.5024, 1.5084, 1.5084, 1.5084, 1.5084,
         1.7683, 1.7684, 1.7684, 1.7650, 1.7683, 1.7683, 1.7684, 1.7445, 1.7473,
         1.4387, 1.4440, 1.4440, 1.4440, 1.4351, 1.4440, 1.4389, 1.4440, 1.4440],
        [1.3118, 1.3109, 1.2949, 1.2863, 1.3098, 1.3080, 1.3092, 1.3104, 1.3104,
         1.3008, 1.2941, 1.2904, 1.2895, 1.3015, 1.2851, 1.2972, 1.3010, 1.2729,
         1.6477, 1.6203, 1.6442, 1.6438, 1.6434, 1.6433, 1.6456, 1.6471, 1.6471,
         3.4814, 3.2823, 3.2066, 3.2684, 3.4149, 3.2344, 3.4600, 3.2158, 3.1927,
         1.6437, 1.6364, 1.6342, 1.6375, 1.6403, 1.6168, 1.6417, 1.5806, 1.6074,
         1.3083, 1.3035, 1.2935, 1.3085, 1.3037, 1.2956, 1.3076, 1.3090, 1.3104],
        [1.4529, 1.4483, 1.4051, 1.4092, 1.4465, 1.4528, 1.4513, 1.4529, 1.4529,
         1.4340, 1.4310, 1.4258, 1.4188, 1.4353, 1.3891, 1.4288, 1.4353, 1.4284,
         1.7587, 1.7502, 1.7460, 1.7557, 1.7753, 1.7734, 1.7530, 1.7755, 1.7755,
         1.4686, 1.4723, 1.5110, 1.5055, 1.4739, 1.5095, 1.4977, 1.5110, 1.5079,
         2.1991, 2.1741, 2.1622, 2.1833, 2.2320, 2.2451, 2.2097, 2.3299, 2.3239,
         1.4284, 1.4219, 1.4363, 1.4470, 1.4316, 1.4433, 1.4091, 1.4409, 1.4470],
        [1.3553, 1.2561, 1.2529, 1.2713, 1.2653, 1.2747, 1.2735, 1.2072, 1.2072,
         1.2660, 1.2299, 1.2292, 1.2323, 1.3000, 1.1850, 1.1610, 1.3000, 1.2150,
         1.5999, 1.5759, 1.5599, 1.5517, 1.5729, 1.5701, 1.5920, 1.5746, 1.5746,
         1.3511, 1.3248, 1.3221, 1.3420, 1.3247, 1.3708, 1.3719, 1.3450, 1.3221,
         1.5782, 1.5795, 1.5825, 1.5726, 1.5491, 1.5529, 1.6161, 1.5049, 1.4738,
         3.8878, 3.6870, 3.7333, 3.7274, 3.7237, 3.5454, 3.8805, 3.7167, 3.5668]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 90 : 1779.4344429520381
Test loss for epoch 90 : 195.05912889774362
Test Precision for epoch 90 : 0.26153846153846155
Test Recall for epoch 90 : 0.26153846153846155
Test F1 for epoch 90 : 0.26153846153846155


theta for epoch 91 : tensor([[3.6303, 3.6448, 3.7452, 3.7080, 3.7030, 3.6131, 3.6452, 3.5623, 3.5623,
         1.2670, 1.2516, 1.2507, 1.2516, 1.2805, 1.2325, 1.2147, 1.2805, 1.2397,
         1.5912, 1.5753, 1.5994, 1.5805, 1.5876, 1.5892, 1.5974, 1.5891, 1.5891,
         1.3484, 1.3592, 1.3431, 1.3677, 1.3465, 1.3806, 1.3727, 1.3583, 1.3432,
         1.5903, 1.6075, 1.5957, 1.5923, 1.5994, 1.5900, 1.6086, 1.5606, 1.5657,
         1.2382, 1.2668, 1.2575, 1.2769, 1.2328, 1.2238, 1.2148, 1.3017, 1.2536],
        [1.3601, 1.2237, 1.2131, 1.2533, 1.2541, 1.2656, 1.2596, 1.1758, 1.1758,
         3.6929, 3.7320, 3.6574, 3.8319, 3.6948, 3.9587, 3.6228, 3.6732, 3.8706,
         1.5691, 1.5577, 1.5325, 1.5315, 1.5511, 1.5608, 1.5851, 1.5608, 1.5608,
         1.3389, 1.3079, 1.3038, 1.3559, 1.3015, 1.3900, 1.3718, 1.3437, 1.3007,
         1.5554, 1.6077, 1.5731, 1.5608, 1.5566, 1.5912, 1.6109, 1.4495, 1.5478,
         1.1473, 1.2578, 1.2297, 1.2801, 1.1417, 1.1467, 1.0811, 1.3431, 1.2195],
        [1.4522, 1.4522, 1.4506, 1.4479, 1.4480, 1.4522, 1.4479, 1.4522, 1.4522,
         1.4327, 1.4317, 1.4327, 1.4326, 1.4328, 1.4130, 1.4326, 1.4313, 1.4289,
         2.1911, 2.1923, 2.2097, 2.1834, 2.1630, 2.1615, 2.1909, 2.1601, 2.1601,
         1.5034, 1.5018, 1.5093, 1.5094, 1.5034, 1.5094, 1.5093, 1.5094, 1.5093,
         1.7686, 1.7687, 1.7687, 1.7653, 1.7686, 1.7686, 1.7687, 1.7449, 1.7477,
         1.4415, 1.4468, 1.4468, 1.4468, 1.4378, 1.4467, 1.4417, 1.4468, 1.4468],
        [1.3139, 1.3130, 1.2971, 1.2885, 1.3119, 1.3102, 1.3113, 1.3125, 1.3125,
         1.3008, 1.2941, 1.2904, 1.2895, 1.3015, 1.2851, 1.2972, 1.3010, 1.2730,
         1.6413, 1.6138, 1.6377, 1.6374, 1.6369, 1.6369, 1.6392, 1.6407, 1.6407,
         3.4840, 3.2838, 3.2079, 3.2697, 3.4170, 3.2357, 3.4623, 3.2171, 3.1940,
         1.6437, 1.6364, 1.6341, 1.6375, 1.6403, 1.6168, 1.6417, 1.5807, 1.6074,
         1.3106, 1.3057, 1.2958, 1.3107, 1.3060, 1.2980, 1.3100, 1.3112, 1.3127],
        [1.4551, 1.4506, 1.4074, 1.4115, 1.4487, 1.4550, 1.4535, 1.4550, 1.4550,
         1.4343, 1.4313, 1.4261, 1.4192, 1.4357, 1.3896, 1.4291, 1.4356, 1.4288,
         1.7530, 1.7444, 1.7404, 1.7501, 1.7696, 1.7677, 1.7473, 1.7698, 1.7698,
         1.4698, 1.4736, 1.5120, 1.5066, 1.4751, 1.5106, 1.4988, 1.5121, 1.5089,
         2.1985, 2.1736, 2.1617, 2.1827, 2.2312, 2.2444, 2.2092, 2.3289, 2.3228,
         1.4313, 1.4246, 1.4391, 1.4497, 1.4345, 1.4461, 1.4122, 1.4436, 1.4498],
        [1.3603, 1.2605, 1.2574, 1.2758, 1.2698, 1.2792, 1.2781, 1.2112, 1.2112,
         1.2652, 1.2292, 1.2285, 1.2315, 1.2992, 1.1841, 1.1598, 1.2991, 1.2143,
         1.5936, 1.5696, 1.5539, 1.5453, 1.5666, 1.5638, 1.5857, 1.5683, 1.5683,
         1.3547, 1.3284, 1.3256, 1.3457, 1.3284, 1.3746, 1.3757, 1.3486, 1.3256,
         1.5772, 1.5786, 1.5816, 1.5716, 1.5483, 1.5521, 1.6153, 1.5039, 1.4729,
         3.8896, 3.6859, 3.7328, 3.7268, 3.7232, 3.5426, 3.8822, 3.7158, 3.5643]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 91 : 1779.3225992102243
Test loss for epoch 91 : 195.26099144367635
Test Precision for epoch 91 : 0.26153846153846155
Test Recall for epoch 91 : 0.26153846153846155
Test F1 for epoch 91 : 0.26153846153846155


theta for epoch 92 : tensor([[3.6318, 3.6466, 3.7481, 3.7105, 3.7054, 3.6146, 3.6470, 3.5635, 3.5635,
         1.2633, 1.2478, 1.2468, 1.2478, 1.2769, 1.2286, 1.2104, 1.2769, 1.2359,
         1.5911, 1.5752, 1.5993, 1.5804, 1.5874, 1.5890, 1.5972, 1.5890, 1.5890,
         1.3502, 1.3610, 1.3449, 1.3695, 1.3483, 1.3824, 1.3745, 1.3601, 1.3449,
         1.5903, 1.6074, 1.5956, 1.5922, 1.5993, 1.5899, 1.6085, 1.5605, 1.5656,
         1.2395, 1.2680, 1.2587, 1.2782, 1.2342, 1.2252, 1.2160, 1.3032, 1.2547],
        [1.3494, 1.2128, 1.2021, 1.2425, 1.2433, 1.2548, 1.2488, 1.1649, 1.1649,
         3.7020, 3.7415, 3.6661, 3.8426, 3.7038, 3.9710, 3.6312, 3.6820, 3.8819,
         1.5606, 1.5491, 1.5237, 1.5229, 1.5427, 1.5523, 1.5767, 1.5523, 1.5523,
         1.3293, 1.2981, 1.2944, 1.3464, 1.2919, 1.3806, 1.3624, 1.3343, 1.2913,
         1.5480, 1.6005, 1.5658, 1.5534, 1.5491, 1.5839, 1.6036, 1.4413, 1.5402,
         1.1392, 1.2499, 1.2215, 1.2723, 1.1337, 1.1389, 1.0726, 1.3359, 1.2112],
        [1.4542, 1.4542, 1.4526, 1.4499, 1.4500, 1.4542, 1.4499, 1.4542, 1.4542,
         1.4298, 1.4287, 1.4297, 1.4296, 1.4298, 1.4101, 1.4296, 1.4284, 1.4260,
         2.1914, 2.1925, 2.2098, 2.1835, 2.1633, 2.1617, 2.1911, 2.1604, 2.1604,
         1.5052, 1.5036, 1.5111, 1.5112, 1.5052, 1.5112, 1.5111, 1.5111, 1.5111,
         1.7692, 1.7694, 1.7694, 1.7659, 1.7692, 1.7693, 1.7694, 1.7456, 1.7484,
         1.4432, 1.4484, 1.4484, 1.4484, 1.4395, 1.4484, 1.4434, 1.4484, 1.4484],
        [1.3161, 1.3151, 1.2992, 1.2907, 1.3140, 1.3123, 1.3134, 1.3145, 1.3145,
         1.2975, 1.2908, 1.2871, 1.2862, 1.2982, 1.2818, 1.2939, 1.2977, 1.2697,
         1.6409, 1.6135, 1.6374, 1.6371, 1.6366, 1.6366, 1.6388, 1.6403, 1.6403,
         3.4871, 3.2858, 3.2098, 3.2716, 3.4197, 3.2375, 3.4650, 3.2189, 3.1958,
         1.6440, 1.6367, 1.6345, 1.6378, 1.6407, 1.6171, 1.6420, 1.5811, 1.6077,
         1.3119, 1.3069, 1.2969, 1.3119, 1.3072, 1.2992, 1.3112, 1.3123, 1.3139],
        [1.4571, 1.4526, 1.4096, 1.4136, 1.4507, 1.4570, 1.4555, 1.4571, 1.4571,
         1.4314, 1.4283, 1.4232, 1.4163, 1.4327, 1.3868, 1.4262, 1.4327, 1.4259,
         1.7532, 1.7446, 1.7407, 1.7503, 1.7697, 1.7679, 1.7475, 1.7699, 1.7699,
         1.4718, 1.4757, 1.5138, 1.5085, 1.4771, 1.5124, 1.5007, 1.5139, 1.5107,
         2.1982, 2.1735, 2.1616, 2.1825, 2.2309, 2.2440, 2.2090, 2.3283, 2.3222,
         1.4331, 1.4263, 1.4407, 1.4513, 1.4362, 1.4477, 1.4141, 1.4452, 1.4514],
        [1.3623, 1.2619, 1.2589, 1.2774, 1.2713, 1.2808, 1.2797, 1.2122, 1.2122,
         1.2603, 1.2240, 1.2234, 1.2264, 1.2944, 1.1788, 1.1537, 1.2944, 1.2091,
         1.5922, 1.5681, 1.5526, 1.5438, 1.5652, 1.5623, 1.5843, 1.5668, 1.5668,
         1.3563, 1.3298, 1.3269, 1.3473, 1.3300, 1.3763, 1.3773, 1.3501, 1.3270,
         1.5756, 1.5772, 1.5801, 1.5700, 1.5468, 1.5508, 1.6139, 1.5023, 1.4713,
         3.8943, 3.6877, 3.7353, 3.7290, 3.7257, 3.5429, 3.8869, 3.7178, 3.5647]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 92 : 1778.9067380098359
Test loss for epoch 92 : 195.64334180980308
Test Precision for epoch 92 : 0.26153846153846155
Test Recall for epoch 92 : 0.26153846153846155
Test F1 for epoch 92 : 0.26153846153846155


theta for epoch 93 : tensor([[3.6306, 3.6458, 3.7483, 3.7102, 3.7052, 3.6133, 3.6461, 3.5619, 3.5619,
         1.2576, 1.2422, 1.2412, 1.2422, 1.2711, 1.2230, 1.2048, 1.2711, 1.2303,
         1.5976, 1.5817, 1.6058, 1.5870, 1.5939, 1.5956, 1.6037, 1.5955, 1.5955,
         1.3519, 1.3626, 1.3466, 1.3711, 1.3500, 1.3840, 1.3761, 1.3617, 1.3466,
         1.5914, 1.6085, 1.5967, 1.5933, 1.6004, 1.5910, 1.6096, 1.5616, 1.5667,
         1.2397, 1.2680, 1.2587, 1.2782, 1.2344, 1.2254, 1.2161, 1.3033, 1.2547],
        [1.3555, 1.2193, 1.2086, 1.2489, 1.2497, 1.2613, 1.2553, 1.1714, 1.1714,
         3.6922, 3.7322, 3.6559, 3.8346, 3.6941, 3.9646, 3.6207, 3.6720, 3.8744,
         1.5669, 1.5554, 1.5299, 1.5293, 1.5491, 1.5588, 1.5829, 1.5588, 1.5588,
         1.3355, 1.3042, 1.3008, 1.3525, 1.2982, 1.3865, 1.3684, 1.3404, 1.2976,
         1.5492, 1.6017, 1.5671, 1.5547, 1.5503, 1.5851, 1.6048, 1.4425, 1.5413,
         1.1400, 1.2503, 1.2219, 1.2728, 1.1345, 1.1398, 1.0731, 1.3365, 1.2116],
        [1.4551, 1.4550, 1.4535, 1.4508, 1.4509, 1.4551, 1.4508, 1.4551, 1.4551,
         1.4245, 1.4234, 1.4244, 1.4243, 1.4245, 1.4049, 1.4243, 1.4231, 1.4207,
         2.1973, 2.1984, 2.2157, 2.1891, 2.1690, 2.1674, 2.1967, 2.1661, 2.1661,
         1.5065, 1.5050, 1.5125, 1.5125, 1.5065, 1.5125, 1.5125, 1.5125, 1.5125,
         1.7707, 1.7708, 1.7708, 1.7674, 1.7707, 1.7707, 1.7708, 1.7471, 1.7499,
         1.4430, 1.4482, 1.4482, 1.4482, 1.4393, 1.4482, 1.4433, 1.4482, 1.4482],
        [1.3172, 1.3162, 1.3003, 1.2918, 1.3151, 1.3134, 1.3145, 1.3156, 1.3156,
         1.2919, 1.2852, 1.2815, 1.2806, 1.2926, 1.2762, 1.2883, 1.2921, 1.2641,
         1.6467, 1.6194, 1.6432, 1.6429, 1.6424, 1.6424, 1.6446, 1.6461, 1.6461,
         3.4896, 3.2872, 3.2111, 3.2729, 3.4217, 3.2387, 3.4671, 3.2202, 3.1971,
         1.6452, 1.6378, 1.6356, 1.6389, 1.6418, 1.6182, 1.6432, 1.5822, 1.6089,
         1.3113, 1.3062, 1.2963, 1.3112, 1.3066, 1.2987, 1.3107, 1.3116, 1.3133],
        [1.4580, 1.4536, 1.4105, 1.4146, 1.4516, 1.4579, 1.4564, 1.4580, 1.4580,
         1.4261, 1.4231, 1.4179, 1.4111, 1.4275, 1.3817, 1.4209, 1.4274, 1.4207,
         1.7594, 1.7508, 1.7470, 1.7566, 1.7759, 1.7741, 1.7537, 1.7760, 1.7760,
         1.4733, 1.4773, 1.5152, 1.5099, 1.4786, 1.5138, 1.5021, 1.5153, 1.5121,
         2.1988, 2.1742, 2.1623, 2.1831, 2.2314, 2.2445, 2.2096, 2.3284, 2.3224,
         1.4331, 1.4261, 1.4405, 1.4511, 1.4362, 1.4476, 1.4142, 1.4450, 1.4511],
        [1.3637, 1.2633, 1.2603, 1.2789, 1.2728, 1.2823, 1.2811, 1.2135, 1.2135,
         1.2537, 1.2175, 1.2169, 1.2198, 1.2876, 1.1722, 1.1472, 1.2875, 1.2026,
         1.5975, 1.5734, 1.5579, 1.5490, 1.5706, 1.5676, 1.5896, 1.5722, 1.5722,
         1.3580, 1.3315, 1.3286, 1.3490, 1.3318, 1.3780, 1.3790, 1.3518, 1.3286,
         1.5754, 1.5770, 1.5799, 1.5699, 1.5468, 1.5508, 1.6137, 1.5021, 1.4711,
         3.8966, 3.6871, 3.7353, 3.7289, 3.7258, 3.5408, 3.8892, 3.7175, 3.5628]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 93 : 1779.0528357823716
Test loss for epoch 93 : 195.28368151446386
Test Precision for epoch 93 : 0.26153846153846155
Test Recall for epoch 93 : 0.26153846153846155
Test F1 for epoch 93 : 0.26153846153846155


theta for epoch 94 : tensor([[3.6248, 3.6402, 3.7438, 3.7053, 3.7002, 3.6074, 3.6404, 3.5555, 3.5555,
         1.2553, 1.2401, 1.2392, 1.2401, 1.2688, 1.2209, 1.2032, 1.2689, 1.2283,
         1.6061, 1.5902, 1.6143, 1.5956, 1.6025, 1.6042, 1.6122, 1.6041, 1.6041,
         1.3496, 1.3603, 1.3446, 1.3688, 1.3479, 1.3815, 1.3737, 1.3595, 1.3446,
         1.5933, 1.6103, 1.5986, 1.5952, 1.6023, 1.5928, 1.6114, 1.5634, 1.5686,
         1.2393, 1.2674, 1.2581, 1.2776, 1.2340, 1.2251, 1.2156, 1.3027, 1.2541],
        [1.3732, 1.2382, 1.2276, 1.2677, 1.2684, 1.2799, 1.2739, 1.1906, 1.1906,
         3.6689, 3.7093, 3.6321, 3.8129, 3.6708, 3.9446, 3.5964, 3.6484, 3.8533,
         1.5826, 1.5712, 1.5458, 1.5453, 1.5651, 1.5746, 1.5985, 1.5746, 1.5746,
         1.3518, 1.3208, 1.3175, 1.3687, 1.3149, 1.4024, 1.3845, 1.3567, 1.3144,
         1.5576, 1.6099, 1.5754, 1.5631, 1.5587, 1.5934, 1.6129, 1.4514, 1.5497,
         1.1487, 1.2582, 1.2299, 1.2807, 1.1432, 1.1485, 1.0818, 1.3443, 1.2196],
        [1.4521, 1.4520, 1.4505, 1.4477, 1.4479, 1.4521, 1.4478, 1.4521, 1.4521,
         1.4222, 1.4211, 1.4221, 1.4220, 1.4222, 1.4026, 1.4220, 1.4208, 1.4184,
         2.2047, 2.2057, 2.2230, 2.1961, 2.1760, 2.1745, 2.2037, 2.1732, 2.1732,
         1.5036, 1.5020, 1.5095, 1.5095, 1.5036, 1.5096, 1.5095, 1.5095, 1.5095,
         1.7724, 1.7726, 1.7726, 1.7692, 1.7724, 1.7724, 1.7726, 1.7489, 1.7517,
         1.4416, 1.4468, 1.4468, 1.4468, 1.4380, 1.4467, 1.4419, 1.4467, 1.4468],
        [1.3146, 1.3135, 1.2976, 1.2891, 1.3124, 1.3107, 1.3118, 1.3128, 1.3128,
         1.2892, 1.2826, 1.2789, 1.2780, 1.2900, 1.2736, 1.2857, 1.2894, 1.2615,
         1.6540, 1.6267, 1.6505, 1.6502, 1.6497, 1.6497, 1.6519, 1.6535, 1.6535,
         3.4884, 3.2850, 3.2087, 3.2706, 3.4201, 3.2363, 3.4657, 3.2178, 3.1947,
         1.6467, 1.6393, 1.6371, 1.6404, 1.6433, 1.6197, 1.6447, 1.5838, 1.6104,
         1.3096, 1.3044, 1.2945, 1.3094, 1.3049, 1.2969, 1.3089, 1.3098, 1.3115],
        [1.4550, 1.4506, 1.4074, 1.4115, 1.4486, 1.4549, 1.4534, 1.4550, 1.4550,
         1.4238, 1.4208, 1.4156, 1.4089, 1.4252, 1.3796, 1.4186, 1.4251, 1.4184,
         1.7670, 1.7584, 1.7548, 1.7642, 1.7834, 1.7816, 1.7613, 1.7836, 1.7836,
         1.4704, 1.4746, 1.5123, 1.5070, 1.4757, 1.5109, 1.4992, 1.5124, 1.5092,
         2.1998, 2.1753, 2.1634, 2.1841, 2.2323, 2.2454, 2.2107, 2.3290, 2.3229,
         1.4318, 1.4246, 1.4391, 1.4497, 1.4349, 1.4462, 1.4131, 1.4435, 1.4497],
        [1.3626, 1.2624, 1.2594, 1.2780, 1.2719, 1.2814, 1.2803, 1.2128, 1.2128,
         1.2504, 1.2148, 1.2143, 1.2170, 1.2843, 1.1695, 1.1452, 1.2843, 1.2000,
         1.6051, 1.5811, 1.5655, 1.5567, 1.5783, 1.5753, 1.5973, 1.5799, 1.5799,
         1.3565, 1.3300, 1.3272, 1.3475, 1.3305, 1.3764, 1.3775, 1.3504, 1.3272,
         1.5762, 1.5779, 1.5808, 1.5707, 1.5477, 1.5518, 1.6146, 1.5030, 1.4720,
         3.8964, 3.6839, 3.7327, 3.7262, 3.7233, 3.5361, 3.8889, 3.7145, 3.5583]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 94 : 1780.306028654744
Test loss for epoch 94 : 194.72740545304538
Test Precision for epoch 94 : 0.26153846153846155
Test Recall for epoch 94 : 0.26153846153846155
Test F1 for epoch 94 : 0.26153846153846155


theta for epoch 95 : tensor([[3.6197, 3.6353, 3.7400, 3.7010, 3.6959, 3.6022, 3.6355, 3.5499, 3.5499,
         1.2593, 1.2442, 1.2432, 1.2441, 1.2729, 1.2249, 1.2074, 1.2729, 1.2323,
         1.6075, 1.5916, 1.6158, 1.5972, 1.6040, 1.6056, 1.6136, 1.6056, 1.6056,
         1.3433, 1.3541, 1.3385, 1.3625, 1.3417, 1.3750, 1.3673, 1.3532, 1.3385,
         1.5943, 1.6113, 1.5997, 1.5962, 1.6033, 1.5938, 1.6124, 1.5645, 1.5696,
         1.2386, 1.2666, 1.2573, 1.2768, 1.2333, 1.2245, 1.2148, 1.3019, 1.2533],
        [1.3814, 1.2471, 1.2366, 1.2765, 1.2772, 1.2886, 1.2827, 1.1997, 1.1997,
         3.6568, 3.6977, 3.6196, 3.8025, 3.6587, 3.9357, 3.5835, 3.6360, 3.8435,
         1.5883, 1.5770, 1.5516, 1.5513, 1.5710, 1.5805, 1.6042, 1.5805, 1.5805,
         1.3583, 1.3274, 1.3242, 1.3751, 1.3216, 1.4085, 1.3907, 1.3632, 1.3211,
         1.5619, 1.6140, 1.5797, 1.5674, 1.5629, 1.5976, 1.6170, 1.4559, 1.5539,
         1.1528, 1.2619, 1.2336, 1.2843, 1.1473, 1.1526, 1.0857, 1.3480, 1.2233],
        [1.4472, 1.4471, 1.4455, 1.4428, 1.4430, 1.4472, 1.4429, 1.4471, 1.4471,
         1.4263, 1.4252, 1.4262, 1.4261, 1.4263, 1.4067, 1.4261, 1.4249, 1.4225,
         2.2059, 2.2069, 2.2241, 2.1972, 2.1773, 2.1758, 2.2049, 2.1745, 2.1745,
         1.4978, 1.4963, 1.5037, 1.5038, 1.4978, 1.5038, 1.5037, 1.5038, 1.5037,
         1.7736, 1.7737, 1.7737, 1.7703, 1.7736, 1.7736, 1.7737, 1.7501, 1.7529,
         1.4403, 1.4455, 1.4455, 1.4455, 1.4367, 1.4455, 1.4407, 1.4454, 1.4455],
        [1.3101, 1.3089, 1.2930, 1.2846, 1.3078, 1.3062, 1.3073, 1.3082, 1.3082,
         1.2931, 1.2864, 1.2827, 1.2819, 1.2938, 1.2775, 1.2896, 1.2933, 1.2654,
         1.6546, 1.6274, 1.6512, 1.6509, 1.6504, 1.6504, 1.6526, 1.6541, 1.6541,
         3.4847, 3.2803, 3.2038, 3.2658, 3.4160, 3.2315, 3.4617, 3.2129, 3.1899,
         1.6475, 1.6402, 1.6380, 1.6413, 1.6442, 1.6206, 1.6455, 1.5847, 1.6113,
         1.3080, 1.3028, 1.2929, 1.3077, 1.3033, 1.2954, 1.3074, 1.3081, 1.3099],
        [1.4501, 1.4457, 1.4023, 1.4065, 1.4437, 1.4500, 1.4485, 1.4500, 1.4500,
         1.4279, 1.4249, 1.4198, 1.4131, 1.4293, 1.3840, 1.4228, 1.4292, 1.4226,
         1.7681, 1.7594, 1.7559, 1.7653, 1.7844, 1.7826, 1.7623, 1.7846, 1.7846,
         1.4647, 1.4689, 1.5065, 1.5013, 1.4700, 1.5052, 1.4934, 1.5066, 1.5035,
         2.2002, 2.1759, 2.1640, 2.1846, 2.2326, 2.2458, 2.2112, 2.3290, 2.3230,
         1.4307, 1.4233, 1.4378, 1.4483, 1.4337, 1.4449, 1.4121, 1.4422, 1.4484],
        [1.3571, 1.2569, 1.2538, 1.2725, 1.2664, 1.2759, 1.2748, 1.2072, 1.2072,
         1.2525, 1.2171, 1.2166, 1.2192, 1.2867, 1.1716, 1.1475, 1.2867, 1.2024,
         1.6050, 1.5810, 1.5655, 1.5566, 1.5783, 1.5753, 1.5972, 1.5799, 1.5799,
         1.3497, 1.3231, 1.3202, 1.3406, 1.3238, 1.3697, 1.3707, 1.3435, 1.3203,
         1.5755, 1.5772, 1.5801, 1.5700, 1.5472, 1.5512, 1.6140, 1.5023, 1.4713,
         3.8994, 3.6841, 3.7335, 3.7268, 3.7241, 3.5348, 3.8919, 3.7149, 3.5571]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 95 : 1780.7219962227698
Test loss for epoch 95 : 194.72126969164162
Test Precision for epoch 95 : 0.26153846153846155
Test Recall for epoch 95 : 0.26153846153846155
Test F1 for epoch 95 : 0.26153846153846155


theta for epoch 96 : tensor([[3.6176, 3.6335, 3.7392, 3.6998, 3.6947, 3.6000, 3.6336, 3.5474, 3.5474,
         1.2680, 1.2529, 1.2520, 1.2529, 1.2818, 1.2337, 1.2160, 1.2818, 1.2411,
         1.5995, 1.5836, 1.6078, 1.5893, 1.5961, 1.5977, 1.6056, 1.5977, 1.5977,
         1.3398, 1.3505, 1.3352, 1.3588, 1.3383, 1.3712, 1.3635, 1.3496, 1.3352,
         1.5932, 1.6102, 1.5986, 1.5951, 1.6022, 1.5927, 1.6112, 1.5634, 1.5685,
         1.2371, 1.2650, 1.2557, 1.2753, 1.2318, 1.2230, 1.2131, 1.3004, 1.2518],
        [1.3841, 1.2502, 1.2396, 1.2795, 1.2801, 1.2916, 1.2857, 1.2028, 1.2028,
         3.6547, 3.6960, 3.6170, 3.8020, 3.6565, 3.9367, 3.5806, 3.6336, 3.8435,
         1.5824, 1.5712, 1.5457, 1.5456, 1.5653, 1.5748, 1.5983, 1.5748, 1.5748,
         1.3603, 1.3294, 1.3264, 1.3771, 1.3238, 1.4103, 1.3927, 1.3652, 1.3233,
         1.5611, 1.6131, 1.5790, 1.5666, 1.5621, 1.5968, 1.6160, 1.4551, 1.5530,
         1.1522, 1.2611, 1.2328, 1.2836, 1.1467, 1.1520, 1.0847, 1.3475, 1.2224],
        [1.4451, 1.4450, 1.4434, 1.4406, 1.4408, 1.4450, 1.4407, 1.4450, 1.4450,
         1.4354, 1.4344, 1.4353, 1.4353, 1.4354, 1.4159, 1.4352, 1.4340, 1.4317,
         2.1989, 2.1999, 2.2170, 2.1905, 2.1707, 2.1691, 2.1982, 2.1679, 2.1679,
         1.4956, 1.4941, 1.5015, 1.5015, 1.4956, 1.5016, 1.5015, 1.5015, 1.5015,
         1.7728, 1.7730, 1.7729, 1.7696, 1.7728, 1.7728, 1.7730, 1.7494, 1.7522,
         1.4388, 1.4438, 1.4438, 1.4438, 1.4351, 1.4438, 1.4392, 1.4438, 1.4438],
        [1.3086, 1.3073, 1.2914, 1.2830, 1.3062, 1.3046, 1.3057, 1.3065, 1.3065,
         1.3020, 1.2954, 1.2916, 1.2908, 1.3027, 1.2865, 1.2986, 1.3022, 1.2744,
         1.6463, 1.6191, 1.6429, 1.6426, 1.6421, 1.6421, 1.6443, 1.6458, 1.6458,
         3.4833, 3.2781, 3.2014, 3.2634, 3.4143, 3.2291, 3.4600, 3.2105, 3.1875,
         1.6466, 1.6392, 1.6371, 1.6403, 1.6432, 1.6196, 1.6446, 1.5837, 1.6103,
         1.3061, 1.3009, 1.2910, 1.3058, 1.3014, 1.2935, 1.3055, 1.3061, 1.3080],
        [1.4480, 1.4435, 1.4000, 1.4043, 1.4415, 1.4479, 1.4464, 1.4479, 1.4479,
         1.4371, 1.4341, 1.4289, 1.4223, 1.4384, 1.3933, 1.4319, 1.4383, 1.4318,
         1.7602, 1.7516, 1.7482, 1.7575, 1.7765, 1.7748, 1.7545, 1.7767, 1.7767,
         1.4626, 1.4667, 1.5043, 1.4991, 1.4678, 1.5030, 1.4913, 1.5044, 1.5013,
         2.1989, 2.1747, 2.1629, 2.1833, 2.2312, 2.2444, 2.2100, 2.3273, 2.3213,
         1.4292, 1.4217, 1.4361, 1.4467, 1.4322, 1.4433, 1.4107, 1.4406, 1.4467],
        [1.3523, 1.2513, 1.2483, 1.2671, 1.2609, 1.2705, 1.2694, 1.2012, 1.2012,
         1.2588, 1.2233, 1.2227, 1.2254, 1.2935, 1.1776, 1.1529, 1.2935, 1.2085,
         1.5952, 1.5710, 1.5557, 1.5466, 1.5684, 1.5653, 1.5873, 1.5700, 1.5700,
         1.3440, 1.3174, 1.3142, 1.3350, 1.3181, 1.3643, 1.3653, 1.3378, 1.3143,
         1.5722, 1.5739, 1.5768, 1.5666, 1.5439, 1.5480, 1.6108, 1.4989, 1.4679,
         3.9050, 3.6868, 3.7368, 3.7300, 3.7275, 3.5360, 3.8975, 3.7178, 3.5585]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 96 : 1780.261750758407
Test loss for epoch 96 : 194.9240477592909
Test Precision for epoch 96 : 0.26153846153846155
Test Recall for epoch 96 : 0.26153846153846155
Test F1 for epoch 96 : 0.26153846153846155


theta for epoch 97 : tensor([[3.6188, 3.6351, 3.7417, 3.7018, 3.6967, 3.6012, 3.6351, 3.5483, 3.5483,
         1.2762, 1.2610, 1.2601, 1.2610, 1.2902, 1.2417, 1.2237, 1.2902, 1.2491,
         1.5907, 1.5749, 1.5990, 1.5806, 1.5874, 1.5890, 1.5968, 1.5890, 1.5890,
         1.3402, 1.3510, 1.3359, 1.3592, 1.3389, 1.3714, 1.3638, 1.3501, 1.3359,
         1.5902, 1.6071, 1.5956, 1.5921, 1.5991, 1.5896, 1.6081, 1.5603, 1.5654,
         1.2341, 1.2620, 1.2527, 1.2723, 1.2288, 1.2199, 1.2098, 1.2974, 1.2487],
        [1.3821, 1.2483, 1.2376, 1.2776, 1.2783, 1.2898, 1.2839, 1.2011, 1.2011,
         3.6592, 3.7009, 3.6211, 3.8080, 3.6610, 3.9443, 3.5845, 3.6378, 3.8501,
         1.5727, 1.5615, 1.5359, 1.5360, 1.5558, 1.5652, 1.5885, 1.5653, 1.5653,
         1.3594, 1.3284, 1.3257, 1.3762, 1.3229, 1.4094, 1.3917, 1.3644, 1.3226,
         1.5557, 1.6078, 1.5737, 1.5612, 1.5566, 1.5914, 1.6106, 1.4495, 1.5475,
         1.1466, 1.2556, 1.2273, 1.2783, 1.1411, 1.1464, 1.0787, 1.3423, 1.2169],
        [1.4461, 1.4460, 1.4444, 1.4417, 1.4419, 1.4461, 1.4418, 1.4461, 1.4461,
         1.4441, 1.4431, 1.4440, 1.4439, 1.4441, 1.4246, 1.4439, 1.4427, 1.4404,
         2.1915, 2.1924, 2.2096, 2.1834, 2.1637, 2.1621, 2.1913, 2.1609, 2.1609,
         1.4982, 1.4966, 1.5040, 1.5041, 1.4982, 1.5041, 1.5040, 1.5041, 1.5040,
         1.7704, 1.7705, 1.7705, 1.7671, 1.7704, 1.7704, 1.7705, 1.7470, 1.7498,
         1.4361, 1.4412, 1.4412, 1.4412, 1.4325, 1.4412, 1.4366, 1.4411, 1.4412],
        [1.3105, 1.3090, 1.2931, 1.2847, 1.3080, 1.3063, 1.3075, 1.3082, 1.3082,
         1.3104, 1.3038, 1.3001, 1.2993, 1.3111, 1.2950, 1.3071, 1.3106, 1.2829,
         1.6376, 1.6104, 1.6342, 1.6339, 1.6334, 1.6334, 1.6355, 1.6371, 1.6371,
         3.4853, 3.2792, 3.2025, 3.2645, 3.4159, 3.2301, 3.4617, 3.2116, 3.1886,
         1.6439, 1.6365, 1.6344, 1.6377, 1.6406, 1.6169, 1.6419, 1.5811, 1.6076,
         1.3033, 1.2980, 1.2881, 1.3029, 1.2985, 1.2906, 1.3027, 1.3032, 1.3051],
        [1.4491, 1.4445, 1.4008, 1.4052, 1.4425, 1.4489, 1.4474, 1.4490, 1.4490,
         1.4457, 1.4428, 1.4376, 1.4311, 1.4470, 1.4022, 1.4406, 1.4470, 1.4405,
         1.7519, 1.7432, 1.7400, 1.7493, 1.7682, 1.7665, 1.7462, 1.7684, 1.7684,
         1.4652, 1.4693, 1.5069, 1.5016, 1.4704, 1.5055, 1.4938, 1.5070, 1.5038,
         2.1960, 2.1720, 2.1601, 2.1805, 2.2282, 2.2414, 2.2071, 2.3240, 2.3180,
         1.4267, 1.4190, 1.4335, 1.4440, 1.4297, 1.4406, 1.4083, 1.4379, 1.4441],
        [1.3489, 1.2465, 1.2436, 1.2626, 1.2564, 1.2660, 1.2649, 1.1956, 1.1955,
         1.2642, 1.2283, 1.2277, 1.2304, 1.2996, 1.1823, 1.1564, 1.2996, 1.2133,
         1.5841, 1.5599, 1.5447, 1.5353, 1.5572, 1.5541, 1.5762, 1.5588, 1.5588,
         1.3412, 1.3143, 1.3107, 1.3321, 1.3150, 1.3618, 1.3627, 1.3348, 1.3108,
         1.5664, 1.5683, 1.5711, 1.5609, 1.5383, 1.5425, 1.6053, 1.4931, 1.4621,
         3.9124, 3.6912, 3.7419, 3.7349, 3.7327, 3.5391, 3.9049, 3.7225, 3.5617]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 97 : 1780.3193280293926
Test loss for epoch 97 : 195.2373138547135
Test Precision for epoch 97 : 0.26153846153846155
Test Recall for epoch 97 : 0.26153846153846155
Test F1 for epoch 97 : 0.26153846153846155


theta for epoch 98 : tensor([[3.6231, 3.6397, 3.7472, 3.7069, 3.7018, 3.6055, 3.6396, 3.5524, 3.5524,
         1.2765, 1.2612, 1.2602, 1.2612, 1.2908, 1.2419, 1.2235, 1.2908, 1.2493,
         1.5884, 1.5726, 1.5967, 1.5784, 1.5851, 1.5868, 1.5945, 1.5867, 1.5867,
         1.3429, 1.3537, 1.3388, 1.3618, 1.3417, 1.3737, 1.3663, 1.3527, 1.3389,
         1.5880, 1.6049, 1.5934, 1.5899, 1.5969, 1.5874, 1.6058, 1.5581, 1.5632,
         1.2314, 1.2594, 1.2501, 1.2697, 1.2260, 1.2171, 1.2069, 1.2950, 1.2461],
        [1.3758, 1.2420, 1.2312, 1.2714, 1.2720, 1.2837, 1.2777, 1.1950, 1.1950,
         3.6663, 3.7085, 3.6279, 3.8167, 3.6681, 3.9545, 3.5910, 3.6446, 3.8593,
         1.5656, 1.5544, 1.5286, 1.5291, 1.5489, 1.5584, 1.5815, 1.5584, 1.5584,
         1.3549, 1.3237, 1.3213, 1.3717, 1.3183, 1.4049, 1.3872, 1.3599, 1.3182,
         1.5487, 1.6008, 1.5667, 1.5542, 1.5495, 1.5844, 1.6035, 1.4420, 1.5403,
         1.1381, 1.2475, 1.2190, 1.2702, 1.1325, 1.1379, 1.0695, 1.3346, 1.2086],
        [1.4499, 1.4498, 1.4482, 1.4454, 1.4456, 1.4499, 1.4456, 1.4498, 1.4498,
         1.4451, 1.4442, 1.4451, 1.4450, 1.4452, 1.4257, 1.4450, 1.4438, 1.4414,
         2.1903, 2.1912, 2.2083, 2.1823, 2.1626, 2.1611, 2.1902, 2.1599, 2.1599,
         1.5036, 1.5021, 1.5095, 1.5095, 1.5037, 1.5095, 1.5095, 1.5095, 1.5095,
         1.7690, 1.7691, 1.7691, 1.7657, 1.7690, 1.7690, 1.7691, 1.7456, 1.7484,
         1.4343, 1.4393, 1.4393, 1.4393, 1.4307, 1.4393, 1.4348, 1.4393, 1.4393],
        [1.3151, 1.3135, 1.2976, 1.2892, 1.3125, 1.3109, 1.3120, 1.3126, 1.3126,
         1.3113, 1.3047, 1.3010, 1.3001, 1.3120, 1.2959, 1.3079, 1.3115, 1.2838,
         1.6356, 1.6085, 1.6323, 1.6320, 1.6314, 1.6314, 1.6336, 1.6352, 1.6352,
         3.4893, 3.2826, 3.2059, 3.2677, 3.4196, 3.2333, 3.4654, 3.2149, 3.1919,
         1.6422, 1.6348, 1.6328, 1.6360, 1.6389, 1.6152, 1.6402, 1.5795, 1.6060,
         1.3013, 1.2960, 1.2861, 1.3008, 1.2965, 1.2886, 1.3007, 1.3011, 1.3030],
        [1.4528, 1.4482, 1.4044, 1.4089, 1.4462, 1.4527, 1.4512, 1.4528, 1.4528,
         1.4468, 1.4438, 1.4387, 1.4322, 1.4481, 1.4035, 1.4417, 1.4480, 1.4416,
         1.7502, 1.7415, 1.7384, 1.7476, 1.7665, 1.7648, 1.7445, 1.7667, 1.7667,
         1.4707, 1.4749, 1.5124, 1.5071, 1.4760, 1.5110, 1.4994, 1.5124, 1.5093,
         2.1942, 2.1703, 2.1584, 2.1787, 2.2263, 2.2396, 2.2054, 2.3217, 2.3158,
         1.4250, 1.4172, 1.4317, 1.4422, 1.4280, 1.4388, 1.4067, 1.4360, 1.4422],
        [1.3468, 1.2425, 1.2397, 1.2589, 1.2526, 1.2624, 1.2612, 1.1904, 1.1904,
         1.2619, 1.2253, 1.2247, 1.2276, 1.2982, 1.1790, 1.1516, 1.2981, 1.2101,
         1.5790, 1.5546, 1.5395, 1.5298, 1.5519, 1.5487, 1.5711, 1.5535, 1.5535,
         1.3397, 1.3125, 1.3084, 1.3307, 1.3132, 1.3609, 1.3616, 1.3332, 1.3084,
         1.5611, 1.5632, 1.5658, 1.5556, 1.5331, 1.5374, 1.6003, 1.4877, 1.4566,
         3.9222, 3.6983, 3.7495, 3.7423, 3.7404, 3.5448, 3.9148, 3.7297, 3.5675]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 98 : 1780.183904444387
Test loss for epoch 98 : 195.5794890600602
Test Precision for epoch 98 : 0.26153846153846155
Test Recall for epoch 98 : 0.26153846153846155
Test F1 for epoch 98 : 0.26153846153846155


theta for epoch 99 : tensor([[3.6290, 3.6460, 3.7544, 3.7137, 3.7086, 3.6116, 3.6459, 3.5583, 3.5583,
         1.2680, 1.2526, 1.2516, 1.2527, 1.2826, 1.2333, 1.2145, 1.2826, 1.2406,
         1.5939, 1.5781, 1.6022, 1.5840, 1.5906, 1.5923, 1.6000, 1.5923, 1.5923,
         1.3440, 1.3548, 1.3403, 1.3628, 1.3430, 1.3745, 1.3672, 1.3538, 1.3403,
         1.5886, 1.6055, 1.5940, 1.5905, 1.5975, 1.5880, 1.6064, 1.5587, 1.5638,
         1.2306, 1.2587, 1.2493, 1.2690, 1.2252, 1.2162, 1.2057, 1.2943, 1.2453],
        [1.3642, 1.2302, 1.2191, 1.2597, 1.2603, 1.2721, 1.2661, 1.1833, 1.1833,
         3.6750, 3.7177, 3.6362, 3.8270, 3.6767, 3.9663, 3.5991, 3.6530, 3.8701,
         1.5626, 1.5514, 1.5254, 1.5261, 1.5461, 1.5556, 1.5786, 1.5557, 1.5557,
         1.3446, 1.3132, 1.3111, 1.3614, 1.3079, 1.3947, 1.3770, 1.3497, 1.3079,
         1.5421, 1.5944, 1.5603, 1.5477, 1.5429, 1.5780, 1.5970, 1.4348, 1.5336,
         1.1281, 1.2382, 1.2095, 1.2610, 1.1225, 1.1278, 1.0587, 1.3259, 1.1990],
        [1.4537, 1.4537, 1.4521, 1.4493, 1.4495, 1.4537, 1.4495, 1.4537, 1.4537,
         1.4376, 1.4367, 1.4376, 1.4375, 1.4377, 1.4183, 1.4375, 1.4363, 1.4340,
         2.1964, 2.1973, 2.2144, 2.1882, 2.1686, 2.1671, 2.1961, 2.1659, 2.1659,
         1.5083, 1.5068, 1.5142, 1.5142, 1.5084, 1.5142, 1.5142, 1.5142, 1.5142,
         1.7705, 1.7706, 1.7706, 1.7673, 1.7705, 1.7705, 1.7706, 1.7472, 1.7500,
         1.4347, 1.4397, 1.4397, 1.4397, 1.4311, 1.4397, 1.4352, 1.4397, 1.4397],
        [1.3198, 1.3182, 1.3022, 1.2938, 1.3171, 1.3155, 1.3166, 1.3172, 1.3172,
         1.3036, 1.2970, 1.2932, 1.2924, 1.3043, 1.2882, 1.3002, 1.3038, 1.2761,
         1.6416, 1.6145, 1.6383, 1.6380, 1.6374, 1.6374, 1.6396, 1.6412, 1.6412,
         3.4927, 3.2853, 3.2086, 3.2703, 3.4227, 3.2360, 3.4685, 3.2176, 3.1946,
         1.6436, 1.6362, 1.6341, 1.6374, 1.6403, 1.6166, 1.6416, 1.5809, 1.6074,
         1.3015, 1.2961, 1.2863, 1.3010, 1.2967, 1.2888, 1.3009, 1.3013, 1.3032],
        [1.4567, 1.4521, 1.4081, 1.4126, 1.4501, 1.4566, 1.4550, 1.4567, 1.4567,
         1.4393, 1.4364, 1.4312, 1.4248, 1.4406, 1.3962, 1.4342, 1.4406, 1.4342,
         1.7563, 1.7476, 1.7447, 1.7538, 1.7725, 1.7709, 1.7506, 1.7727, 1.7727,
         1.4755, 1.4796, 1.5171, 1.5118, 1.4807, 1.5157, 1.5041, 1.5171, 1.5141,
         2.1952, 2.1715, 2.1597, 2.1799, 2.2272, 2.2406, 2.2066, 2.3224, 2.3164,
         1.4255, 1.4176, 1.4320, 1.4425, 1.4285, 1.4392, 1.4073, 1.4364, 1.4425],
        [1.3440, 1.2373, 1.2347, 1.2542, 1.2478, 1.2577, 1.2565, 1.1838, 1.1838,
         1.2510, 1.2136, 1.2129, 1.2161, 1.2883, 1.1671, 1.1377, 1.2883, 1.1981,
         1.5812, 1.5567, 1.5415, 1.5316, 1.5538, 1.5506, 1.5732, 1.5554, 1.5554,
         1.3362, 1.3088, 1.3039, 1.3273, 1.3093, 1.3581, 1.3586, 1.3295, 1.3039,
         1.5583, 1.5607, 1.5631, 1.5528, 1.5305, 1.5349, 1.5979, 1.4848, 1.4537,
         3.9352, 3.7083, 3.7602, 3.7528, 3.7512, 3.5536, 3.9278, 3.7399, 3.5764]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 99 : 1779.1536884514173
Test loss for epoch 99 : 195.9660019643682
Test Precision for epoch 99 : 0.26153846153846155
Test Recall for epoch 99 : 0.26153846153846155
Test F1 for epoch 99 : 0.26153846153846155


theta for epoch 100 : tensor([[3.6307, 3.6480, 3.7573, 3.7162, 3.7111, 3.6133, 3.6478, 3.5598, 3.5598,
         1.2572, 1.2416, 1.2406, 1.2417, 1.2721, 1.2222, 1.2030, 1.2721, 1.2296,
         1.6041, 1.5883, 1.6123, 1.5943, 1.6009, 1.6026, 1.6101, 1.6026, 1.6026,
         1.3431, 1.3540, 1.3398, 1.3618, 1.3424, 1.3733, 1.3661, 1.3530, 1.3399,
         1.5923, 1.6090, 1.5976, 1.5941, 1.6011, 1.5915, 1.6099, 1.5623, 1.5674,
         1.2316, 1.2593, 1.2502, 1.2695, 1.2262, 1.2174, 1.2067, 1.2949, 1.2462],
        [1.3498, 1.2158, 1.2045, 1.2454, 1.2459, 1.2578, 1.2518, 1.1692, 1.1692,
         3.6829, 3.7261, 3.6438, 3.8366, 3.6846, 3.9774, 3.6065, 3.6606, 3.8802,
         1.5631, 1.5520, 1.5255, 1.5267, 1.5469, 1.5564, 1.5793, 1.5565, 1.5565,
         1.3317, 1.3001, 1.2983, 1.3486, 1.2949, 1.3819, 1.3642, 1.3369, 1.2952,
         1.5380, 1.5903, 1.5563, 1.5436, 1.5386, 1.5739, 1.5928, 1.4299, 1.5293,
         1.1198, 1.2293, 1.2012, 1.2523, 1.1143, 1.1200, 1.0500, 1.3177, 1.1908],
        [1.4545, 1.4545, 1.4528, 1.4501, 1.4503, 1.4545, 1.4502, 1.4545, 1.4545,
         1.4273, 1.4264, 1.4272, 1.4272, 1.4273, 1.4079, 1.4272, 1.4260, 1.4236,
         2.2063, 2.2072, 2.2242, 2.1977, 2.1782, 2.1767, 2.2056, 2.1755, 2.1755,
         1.5102, 1.5087, 1.5161, 1.5161, 1.5102, 1.5160, 1.5160, 1.5161, 1.5161,
         1.7745, 1.7747, 1.7746, 1.7713, 1.7745, 1.7745, 1.7747, 1.7513, 1.7541,
         1.4359, 1.4408, 1.4408, 1.4408, 1.4322, 1.4408, 1.4364, 1.4407, 1.4408],
        [1.3214, 1.3196, 1.3036, 1.2952, 1.3186, 1.3170, 1.3181, 1.3186, 1.3186,
         1.2930, 1.2864, 1.2827, 1.2819, 1.2937, 1.2777, 1.2896, 1.2933, 1.2655,
         1.6518, 1.6247, 1.6485, 1.6482, 1.6476, 1.6476, 1.6497, 1.6513, 1.6513,
         3.4938, 3.2858, 3.2091, 3.2708, 3.4235, 3.2364, 3.4695, 3.2180, 3.1951,
         1.6475, 1.6400, 1.6380, 1.6413, 1.6442, 1.6205, 1.6455, 1.5848, 1.6113,
         1.3025, 1.2971, 1.2873, 1.3020, 1.2977, 1.2899, 1.3019, 1.3023, 1.3042],
        [1.4574, 1.4528, 1.4087, 1.4132, 1.4508, 1.4574, 1.4558, 1.4574, 1.4574,
         1.4290, 1.4261, 1.4209, 1.4146, 1.4303, 1.3861, 1.4239, 1.4302, 1.4239,
         1.7665, 1.7577, 1.7549, 1.7640, 1.7826, 1.7809, 1.7607, 1.7828, 1.7828,
         1.4774, 1.4814, 1.5189, 1.5137, 1.4826, 1.5175, 1.5060, 1.5190, 1.5159,
         2.1988, 2.1752, 2.1634, 2.1835, 2.2307, 2.2441, 2.2102, 2.3254, 2.3195,
         1.4268, 1.4187, 1.4331, 1.4436, 1.4297, 1.4403, 1.4086, 1.4375, 1.4436],
        [1.3590, 1.2514, 1.2490, 1.2685, 1.2622, 1.2720, 1.2709, 1.1974, 1.1974,
         1.2459, 1.2076, 1.2069, 1.2103, 1.2841, 1.1611, 1.1294, 1.2841, 1.1918,
         1.5980, 1.5736, 1.5584, 1.5483, 1.5705, 1.5673, 1.5901, 1.5721, 1.5721,
         1.3501, 1.3228, 1.3172, 1.3413, 1.3232, 1.3724, 1.3727, 1.3433, 1.3172,
         1.5666, 1.5692, 1.5714, 1.5612, 1.5390, 1.5436, 1.6064, 1.4934, 1.4625,
         3.9207, 3.6911, 3.7435, 3.7360, 3.7345, 3.5347, 3.9132, 3.7229, 3.5578]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 100 : 1778.884156460258
Test loss for epoch 100 : 195.51942265045216
Test Precision for epoch 100 : 0.26153846153846155
Test Recall for epoch 100 : 0.26153846153846155
Test F1 for epoch 100 : 0.26153846153846155


theta for epoch 101 : tensor([[3.6285, 3.6460, 3.7562, 3.7147, 3.7095, 3.6109, 3.6457, 3.5572, 3.5572,
         1.2497, 1.2340, 1.2331, 1.2342, 1.2646, 1.2147, 1.1955, 1.2646, 1.2220,
         1.6095, 1.5938, 1.6177, 1.5999, 1.6065, 1.6081, 1.6156, 1.6081, 1.6081,
         1.3390, 1.3499, 1.3362, 1.3576, 1.3385, 1.3688, 1.3618, 1.3489, 1.3362,
         1.5965, 1.6131, 1.6018, 1.5983, 1.6053, 1.5957, 1.6140, 1.5665, 1.5716,
         1.2371, 1.2643, 1.2555, 1.2746, 1.2318, 1.2230, 1.2122, 1.2999, 1.2516],
        [1.3435, 1.2099, 1.1985, 1.2394, 1.2400, 1.2519, 1.2459, 1.1637, 1.1637,
         3.6811, 3.7246, 3.6415, 3.8363, 3.6827, 3.9787, 3.6040, 3.6584, 3.8805,
         1.5654, 1.5543, 1.5277, 1.5292, 1.5494, 1.5590, 1.5816, 1.5590, 1.5590,
         1.3263, 1.2946, 1.2931, 1.3432, 1.2896, 1.3764, 1.3587, 1.3315, 1.2899,
         1.5393, 1.5917, 1.5578, 1.5450, 1.5399, 1.5752, 1.5941, 1.4310, 1.5305,
         1.1216, 1.2305, 1.2030, 1.2536, 1.1163, 1.1222, 1.0516, 1.3192, 1.1927],
        [1.4510, 1.4509, 1.4493, 1.4465, 1.4467, 1.4510, 1.4467, 1.4510, 1.4510,
         1.4199, 1.4190, 1.4199, 1.4198, 1.4200, 1.4006, 1.4198, 1.4186, 1.4163,
         2.2116, 2.2124, 2.2295, 2.2027, 2.1834, 2.1819, 2.2108, 2.1807, 2.1807,
         1.5082, 1.5067, 1.5140, 1.5140, 1.5082, 1.5140, 1.5140, 1.5140, 1.5140,
         1.7788, 1.7789, 1.7789, 1.7756, 1.7788, 1.7788, 1.7789, 1.7556, 1.7584,
         1.4410, 1.4459, 1.4459, 1.4459, 1.4373, 1.4459, 1.4415, 1.4458, 1.4459],
        [1.3184, 1.3165, 1.3005, 1.2921, 1.3155, 1.3139, 1.3150, 1.3155, 1.3155,
         1.2855, 1.2789, 1.2751, 1.2743, 1.2862, 1.2701, 1.2821, 1.2857, 1.2580,
         1.6569, 1.6299, 1.6536, 1.6533, 1.6527, 1.6527, 1.6549, 1.6565, 1.6565,
         3.4921, 3.2834, 3.2066, 3.2683, 3.4214, 3.2339, 3.4675, 3.2156, 3.1927,
         1.6516, 1.6442, 1.6422, 1.6454, 1.6483, 1.6246, 1.6496, 1.5890, 1.6155,
         1.3076, 1.3021, 1.2923, 1.3070, 1.3027, 1.2949, 1.3070, 1.3072, 1.3092],
        [1.4539, 1.4492, 1.4049, 1.4095, 1.4472, 1.4538, 1.4522, 1.4539, 1.4539,
         1.4217, 1.4187, 1.4136, 1.4073, 1.4229, 1.3789, 1.4166, 1.4229, 1.4166,
         1.7716, 1.7629, 1.7602, 1.7692, 1.7877, 1.7861, 1.7658, 1.7879, 1.7879,
         1.4753, 1.4794, 1.5169, 1.5117, 1.4806, 1.5155, 1.5040, 1.5170, 1.5139,
         2.2027, 2.1792, 2.1675, 2.1874, 2.2344, 2.2480, 2.2142, 2.3288, 2.3230,
         1.4320, 1.4238, 1.4382, 1.4486, 1.4349, 1.4453, 1.4139, 1.4425, 1.4487],
        [1.3694, 1.2614, 1.2592, 1.2786, 1.2723, 1.2821, 1.2809, 1.2071, 1.2071,
         1.2435, 1.2048, 1.2041, 1.2076, 1.2822, 1.1583, 1.1255, 1.2822, 1.1889,
         1.6098, 1.5855, 1.5703, 1.5602, 1.5823, 1.5790, 1.6019, 1.5839, 1.5839,
         1.3599, 1.3327, 1.3265, 1.3513, 1.3330, 1.3825, 1.3826, 1.3531, 1.3266,
         1.5752, 1.5780, 1.5800, 1.5698, 1.5478, 1.5524, 1.6151, 1.5023, 1.4716,
         3.9089, 3.6765, 3.7294, 3.7219, 3.7205, 3.5185, 3.9014, 3.7086, 3.5418]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 101 : 1779.5333952133929
Test loss for epoch 101 : 195.26584371387307
Test Precision for epoch 101 : 0.26153846153846155
Test Recall for epoch 101 : 0.26153846153846155
Test F1 for epoch 101 : 0.26153846153846155


theta for epoch 102 : tensor([[3.6242, 3.6419, 3.7530, 3.7111, 3.7059, 3.6066, 3.6416, 3.5525, 3.5525,
         1.2490, 1.2336, 1.2326, 1.2337, 1.2639, 1.2143, 1.1954, 1.2639, 1.2216,
         1.6038, 1.5881, 1.6120, 1.5944, 1.6009, 1.6026, 1.6099, 1.6026, 1.6026,
         1.3361, 1.3471, 1.3338, 1.3546, 1.3358, 1.3654, 1.3586, 1.3461, 1.3338,
         1.5985, 1.6150, 1.6038, 1.6003, 1.6072, 1.5976, 1.6158, 1.5686, 1.5736,
         1.2463, 1.2731, 1.2646, 1.2833, 1.2411, 1.2325, 1.2214, 1.3085, 1.2608],
        [1.3526, 1.2199, 1.2084, 1.2492, 1.2497, 1.2617, 1.2556, 1.1740, 1.1740,
         3.6677, 3.7116, 3.6277, 3.8245, 3.6693, 3.9684, 3.5898, 3.6448, 3.8692,
         1.5657, 1.5547, 1.5281, 1.5298, 1.5499, 1.5594, 1.5818, 1.5594, 1.5594,
         1.3346, 1.3031, 1.3016, 1.3515, 1.2981, 1.3845, 1.3669, 1.3399, 1.2985,
         1.5451, 1.5972, 1.5635, 1.5507, 1.5455, 1.5808, 1.5995, 1.4371, 1.5361,
         1.1349, 1.2429, 1.2160, 1.2660, 1.1297, 1.1357, 1.0648, 1.3316, 1.2058],
        [1.4483, 1.4483, 1.4466, 1.4438, 1.4441, 1.4483, 1.4440, 1.4483, 1.4483,
         1.4190, 1.4181, 1.4190, 1.4189, 1.4190, 1.3997, 1.4189, 1.4177, 1.4154,
         2.2064, 2.2071, 2.2241, 2.1978, 2.1785, 2.1769, 2.2059, 2.1758, 2.1758,
         1.5063, 1.5048, 1.5121, 1.5121, 1.5063, 1.5121, 1.5121, 1.5121, 1.5121,
         1.7805, 1.7806, 1.7806, 1.7773, 1.7805, 1.7805, 1.7806, 1.7573, 1.7601,
         1.4491, 1.4540, 1.4540, 1.4540, 1.4455, 1.4540, 1.4497, 1.4539, 1.4540],
        [1.3163, 1.3144, 1.2983, 1.2898, 1.3133, 1.3118, 1.3128, 1.3133, 1.3133,
         1.2844, 1.2778, 1.2741, 1.2733, 1.2851, 1.2691, 1.2811, 1.2846, 1.2569,
         1.6506, 1.6236, 1.6473, 1.6470, 1.6464, 1.6464, 1.6486, 1.6502, 1.6502,
         3.4903, 3.2810, 3.2042, 3.2658, 3.4194, 3.2315, 3.4655, 3.2131, 3.1903,
         1.6531, 1.6457, 1.6437, 1.6470, 1.6499, 1.6261, 1.6512, 1.5905, 1.6170,
         1.3157, 1.3103, 1.3005, 1.3151, 1.3109, 1.3031, 1.3152, 1.3154, 1.3174],
        [1.4513, 1.4465, 1.4020, 1.4067, 1.4445, 1.4512, 1.4496, 1.4512, 1.4512,
         1.4208, 1.4179, 1.4127, 1.4065, 1.4220, 1.3782, 1.4157, 1.4220, 1.4158,
         1.7655, 1.7567, 1.7542, 1.7631, 1.7816, 1.7799, 1.7597, 1.7817, 1.7817,
         1.4734, 1.4774, 1.5150, 1.5098, 1.4786, 1.5136, 1.5021, 1.5151, 1.5120,
         2.2040, 2.1808, 2.1690, 2.1889, 2.2357, 2.2493, 2.2157, 2.3297, 2.3239,
         1.4403, 1.4319, 1.4464, 1.4567, 1.4431, 1.4535, 1.4223, 1.4507, 1.4568],
        [1.3793, 1.2716, 1.2695, 1.2888, 1.2825, 1.2923, 1.2911, 1.2175, 1.2175,
         1.2471, 1.2085, 1.2077, 1.2112, 1.2859, 1.1621, 1.1289, 1.2859, 1.1925,
         1.6102, 1.5860, 1.5708, 1.5606, 1.5827, 1.5794, 1.6024, 1.5843, 1.5843,
         1.3691, 1.3420, 1.3355, 1.3606, 1.3422, 1.3918, 1.3918, 1.3622, 1.3356,
         1.5811, 1.5840, 1.5860, 1.5758, 1.5539, 1.5586, 1.6210, 1.5085, 1.4780,
         3.8993, 3.6642, 3.7176, 3.7100, 3.7087, 3.5047, 3.8918, 3.6965, 3.5282]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 102 : 1780.127090511993
Test loss for epoch 102 : 194.73775201022107
Test Precision for epoch 102 : 0.26153846153846155
Test Recall for epoch 102 : 0.26153846153846155
Test F1 for epoch 102 : 0.26153846153846155


theta for epoch 103 : tensor([[3.6216, 3.6394, 3.7514, 3.7092, 3.7039, 3.6038, 3.6391, 3.5495, 3.5495,
         1.2554, 1.2399, 1.2390, 1.2401, 1.2702, 1.2207, 1.2018, 1.2703, 1.2280,
         1.5939, 1.5783, 1.6022, 1.5847, 1.5912, 1.5929, 1.6000, 1.5928, 1.5928,
         1.3322, 1.3431, 1.3303, 1.3505, 1.3321, 1.3611, 1.3544, 1.3422, 1.3303,
         1.5961, 1.6125, 1.6014, 1.5978, 1.6047, 1.5950, 1.6132, 1.5661, 1.5711,
         1.2533, 1.2797, 1.2715, 1.2899, 1.2482, 1.2397, 1.2284, 1.3149, 1.2677],
        [1.3555, 1.2226, 1.2112, 1.2520, 1.2525, 1.2645, 1.2584, 1.1766, 1.1766,
         3.6648, 3.7092, 3.6244, 3.8231, 3.6664, 3.9686, 3.5862, 3.6416, 3.8684,
         1.5590, 1.5480, 1.5215, 1.5232, 1.5434, 1.5528, 1.5750, 1.5528, 1.5528,
         1.3363, 1.3048, 1.3032, 1.3531, 1.2997, 1.3861, 1.3686, 1.3415, 1.3000,
         1.5436, 1.5956, 1.5620, 1.5493, 1.5440, 1.5793, 1.5978, 1.4358, 1.5346,
         1.1426, 1.2502, 1.2237, 1.2733, 1.1375, 1.1436, 1.0723, 1.3390, 1.2136],
        [1.4459, 1.4458, 1.4441, 1.4413, 1.4416, 1.4459, 1.4416, 1.4459, 1.4459,
         1.4254, 1.4245, 1.4253, 1.4253, 1.4254, 1.4061, 1.4253, 1.4241, 1.4217,
         2.1975, 2.1983, 2.2153, 2.1894, 2.1702, 2.1686, 2.1976, 2.1675, 2.1675,
         1.5038, 1.5023, 1.5097, 1.5097, 1.5038, 1.5097, 1.5096, 1.5097, 1.5097,
         1.7780, 1.7781, 1.7781, 1.7747, 1.7779, 1.7780, 1.7781, 1.7548, 1.7576,
         1.4554, 1.4602, 1.4602, 1.4602, 1.4517, 1.4602, 1.4560, 1.4601, 1.4602],
        [1.3143, 1.3123, 1.2962, 1.2877, 1.3113, 1.3097, 1.3108, 1.3112, 1.3112,
         1.2907, 1.2841, 1.2803, 1.2795, 1.2913, 1.2754, 1.2874, 1.2909, 1.2632,
         1.6405, 1.6135, 1.6372, 1.6369, 1.6363, 1.6363, 1.6385, 1.6401, 1.6401,
         3.4880, 3.2782, 3.2013, 3.2629, 3.4168, 3.2287, 3.4630, 3.2103, 3.1874,
         1.6505, 1.6430, 1.6411, 1.6443, 1.6473, 1.6235, 1.6485, 1.5879, 1.6144,
         1.3220, 1.3165, 1.3067, 1.3214, 1.3172, 1.3094, 1.3215, 1.3216, 1.3236],
        [1.4488, 1.4440, 1.3993, 1.4041, 1.4420, 1.4487, 1.4471, 1.4488, 1.4488,
         1.4271, 1.4242, 1.4191, 1.4130, 1.4283, 1.3847, 1.4221, 1.4283, 1.4222,
         1.7556, 1.7468, 1.7444, 1.7532, 1.7717, 1.7701, 1.7498, 1.7718, 1.7718,
         1.4709, 1.4749, 1.5126, 1.5073, 1.4761, 1.5111, 1.4996, 1.5126, 1.5095,
         2.2014, 2.1783, 2.1666, 2.1863, 2.2330, 2.2468, 2.2132, 2.3267, 2.3210,
         1.4466, 1.4382, 1.4526, 1.4629, 1.4494, 1.4597, 1.4287, 1.4569, 1.4630],
        [1.3847, 1.2776, 1.2754, 1.2946, 1.2883, 1.2981, 1.2970, 1.2237, 1.2237,
         1.2561, 1.2172, 1.2164, 1.2201, 1.2952, 1.1708, 1.1370, 1.2952, 1.2012,
         1.6049, 1.5808, 1.5657, 1.5555, 1.5776, 1.5742, 1.5971, 1.5791, 1.5791,
         1.3736, 1.3466, 1.3400, 1.3651, 1.3468, 1.3963, 1.3962, 1.3667, 1.3400,
         1.5814, 1.5844, 1.5863, 1.5761, 1.5544, 1.5591, 1.6213, 1.5091, 1.4787,
         3.8938, 3.6560, 3.7100, 3.7023, 3.7011, 3.4951, 3.8863, 3.6885, 3.5188]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 103 : 1780.056345774572
Test loss for epoch 103 : 194.6729614768374
Test Precision for epoch 103 : 0.26153846153846155
Test Recall for epoch 103 : 0.26153846153846155
Test F1 for epoch 103 : 0.26153846153846155


theta for epoch 104 : tensor([[3.6204, 3.6385, 3.7512, 3.7087, 3.7033, 3.6026, 3.6381, 3.5480, 3.5480,
         1.2654, 1.2498, 1.2488, 1.2500, 1.2804, 1.2305, 1.2112, 1.2804, 1.2378,
         1.5884, 1.5729, 1.5967, 1.5793, 1.5858, 1.5875, 1.5945, 1.5874, 1.5874,
         1.3289, 1.3398, 1.3273, 1.3471, 1.3289, 1.3575, 1.3510, 1.3389, 1.3273,
         1.5912, 1.6075, 1.5965, 1.5930, 1.5998, 1.5901, 1.6082, 1.5612, 1.5663,
         1.2527, 1.2788, 1.2707, 1.2889, 1.2476, 1.2392, 1.2278, 1.3137, 1.2670],
        [1.3527, 1.2187, 1.2074, 1.2483, 1.2488, 1.2608, 1.2547, 1.1722, 1.1722,
         3.6701, 3.7149, 3.6293, 3.8300, 3.6717, 3.9769, 3.5909, 3.6466, 3.8758,
         1.5530, 1.5420, 1.5154, 1.5172, 1.5373, 1.5468, 1.5689, 1.5468, 1.5468,
         1.3329, 1.3013, 1.2994, 1.3498, 1.2962, 1.3831, 1.3654, 1.3381, 1.2963,
         1.5371, 1.5892, 1.5556, 1.5428, 1.5375, 1.5728, 1.5914, 1.4293, 1.5280,
         1.1407, 1.2480, 1.2219, 1.2712, 1.1356, 1.1418, 1.0701, 1.3371, 1.2119],
        [1.4436, 1.4435, 1.4418, 1.4390, 1.4393, 1.4436, 1.4393, 1.4436, 1.4436,
         1.4356, 1.4348, 1.4356, 1.4355, 1.4356, 1.4164, 1.4355, 1.4343, 1.4320,
         2.1929, 2.1936, 2.2107, 2.1851, 2.1659, 2.1644, 2.1933, 2.1632, 2.1632,
         1.5023, 1.5008, 1.5082, 1.5082, 1.5023, 1.5082, 1.5082, 1.5082, 1.5082,
         1.7733, 1.7734, 1.7734, 1.7700, 1.7732, 1.7733, 1.7734, 1.7501, 1.7529,
         1.4542, 1.4590, 1.4590, 1.4590, 1.4506, 1.4591, 1.4548, 1.4590, 1.4590],
        [1.3125, 1.3104, 1.2942, 1.2858, 1.3094, 1.3078, 1.3089, 1.3092, 1.3092,
         1.3008, 1.2942, 1.2905, 1.2897, 1.3015, 1.2856, 1.2976, 1.3010, 1.2734,
         1.6350, 1.6081, 1.6318, 1.6314, 1.6308, 1.6308, 1.6330, 1.6346, 1.6346,
         3.4864, 3.2760, 3.1992, 3.2607, 3.4149, 3.2265, 3.4612, 3.2081, 3.1853,
         1.6456, 1.6382, 1.6363, 1.6395, 1.6424, 1.6186, 1.6437, 1.5831, 1.6096,
         1.3209, 1.3154, 1.3056, 1.3202, 1.3161, 1.3083, 1.3203, 1.3205, 1.3225],
        [1.4465, 1.4417, 1.3968, 1.4016, 1.4396, 1.4464, 1.4448, 1.4465, 1.4465,
         1.4373, 1.4345, 1.4294, 1.4233, 1.4386, 1.3952, 1.4323, 1.4385, 1.4325,
         1.7502, 1.7414, 1.7391, 1.7479, 1.7663, 1.7647, 1.7444, 1.7664, 1.7664,
         1.4693, 1.4733, 1.5111, 1.5057, 1.4745, 1.5096, 1.4981, 1.5111, 1.5080,
         2.1968, 2.1738, 2.1621, 2.1817, 2.2283, 2.2421, 2.2086, 2.3217, 2.3160,
         1.4455, 1.4370, 1.4514, 1.4618, 1.4483, 1.4586, 1.4277, 1.4557, 1.4618],
        [1.3855, 1.2793, 1.2770, 1.2962, 1.2899, 1.2996, 1.2985, 1.2261, 1.2261,
         1.2673, 1.2281, 1.2272, 1.2310, 1.3068, 1.1816, 1.1466, 1.3068, 1.2120,
         1.6023, 1.5782, 1.5631, 1.5530, 1.5751, 1.5717, 1.5945, 1.5766, 1.5766,
         1.3750, 1.3481, 1.3416, 1.3665, 1.3483, 1.3975, 1.3975, 1.3681, 1.3416,
         1.5782, 1.5812, 1.5831, 1.5729, 1.5514, 1.5561, 1.6181, 1.5060, 1.4757,
         3.8892, 3.6487, 3.7032, 3.6954, 3.6944, 3.4864, 3.8817, 3.6815, 3.5103]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 104 : 1779.8790238372974
Test loss for epoch 104 : 194.9258774568209
Test Precision for epoch 104 : 0.26153846153846155
Test Recall for epoch 104 : 0.26153846153846155
Test F1 for epoch 104 : 0.26153846153846155


theta for epoch 105 : tensor([[3.6219, 3.6403, 3.7538, 3.7110, 3.7055, 3.6042, 3.6398, 3.5494, 3.5493,
         1.2710, 1.2551, 1.2541, 1.2554, 1.2863, 1.2358, 1.2158, 1.2864, 1.2430,
         1.5899, 1.5744, 1.5981, 1.5809, 1.5873, 1.5890, 1.5960, 1.5890, 1.5890,
         1.3282, 1.3392, 1.3268, 1.3464, 1.3283, 1.3566, 1.3501, 1.3382, 1.3268,
         1.5875, 1.6037, 1.5927, 1.5892, 1.5960, 1.5863, 1.6044, 1.5575, 1.5625,
         1.2472, 1.2730, 1.2651, 1.2830, 1.2421, 1.2339, 1.2223, 1.3076, 1.2615],
        [1.3468, 1.2106, 1.1994, 1.2407, 1.2411, 1.2532, 1.2471, 1.1632, 1.1632,
         3.6790, 3.7243, 3.6379, 3.8405, 3.6806, 3.9889, 3.5993, 3.6553, 3.8868,
         1.5503, 1.5393, 1.5127, 1.5143, 1.5345, 1.5440, 1.5663, 1.5440, 1.5440,
         1.3269, 1.2951, 1.2927, 1.3439, 1.2898, 1.3777, 1.3598, 1.3320, 1.2895,
         1.5293, 1.5817, 1.5480, 1.5351, 1.5298, 1.5653, 1.5839, 1.4213, 1.5201,
         1.1320, 1.2394, 1.2135, 1.2627, 1.1269, 1.1331, 1.0610, 1.3288, 1.2036],
        [1.4436, 1.4435, 1.4418, 1.4390, 1.4393, 1.4436, 1.4393, 1.4436, 1.4436,
         1.4418, 1.4410, 1.4418, 1.4417, 1.4418, 1.4226, 1.4417, 1.4405, 1.4382,
         2.1949, 2.1956, 2.2126, 2.1871, 2.1680, 2.1664, 2.1954, 2.1653, 2.1653,
         1.5038, 1.5023, 1.5096, 1.5096, 1.5038, 1.5096, 1.5096, 1.5096, 1.5096,
         1.7699, 1.7700, 1.7700, 1.7667, 1.7699, 1.7699, 1.7700, 1.7468, 1.7495,
         1.4485, 1.4533, 1.4533, 1.4533, 1.4449, 1.4533, 1.4491, 1.4533, 1.4533],
        [1.3128, 1.3107, 1.2945, 1.2861, 1.3097, 1.3081, 1.3092, 1.3095, 1.3095,
         1.3069, 1.3003, 1.2965, 1.2958, 1.3076, 1.2917, 1.3037, 1.3071, 1.2795,
         1.6367, 1.6098, 1.6335, 1.6332, 1.6325, 1.6326, 1.6347, 1.6363, 1.6363,
         3.4870, 3.2762, 3.1994, 3.2608, 3.4152, 3.2267, 3.4616, 3.2083, 3.1855,
         1.6422, 1.6347, 1.6328, 1.6360, 1.6390, 1.6151, 1.6402, 1.5796, 1.6061,
         1.3152, 1.3097, 1.2999, 1.3145, 1.3104, 1.3026, 1.3146, 1.3147, 1.3168],
        [1.4465, 1.4417, 1.3967, 1.4016, 1.4396, 1.4464, 1.4448, 1.4465, 1.4465,
         1.4435, 1.4407, 1.4356, 1.4296, 1.4447, 1.4016, 1.4385, 1.4447, 1.4388,
         1.7519, 1.7430, 1.7408, 1.7496, 1.7679, 1.7663, 1.7461, 1.7680, 1.7680,
         1.4707, 1.4746, 1.5125, 1.5071, 1.4759, 1.5110, 1.4995, 1.5125, 1.5095,
         2.1934, 2.1706, 2.1589, 2.1784, 2.2249, 2.2388, 2.2054, 2.3180, 2.3124,
         1.4398, 1.4313, 1.4457, 1.4560, 1.4427, 1.4528, 1.4221, 1.4500, 1.4561],
        [1.3837, 1.2790, 1.2766, 1.2956, 1.2893, 1.2991, 1.2979, 1.2267, 1.2267,
         1.2731, 1.2334, 1.2325, 1.2365, 1.3131, 1.1868, 1.1506, 1.3131, 1.2171,
         1.6049, 1.5809, 1.5656, 1.5558, 1.5779, 1.5745, 1.5972, 1.5794, 1.5794,
         1.3753, 1.3484, 1.3423, 1.3667, 1.3488, 1.3975, 1.3976, 1.3685, 1.3424,
         1.5751, 1.5781, 1.5800, 1.5698, 1.5483, 1.5530, 1.6148, 1.5030, 1.4727,
         3.8867, 3.6436, 3.6986, 3.6907, 3.6898, 3.4799, 3.8792, 3.6765, 3.5039]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 105 : 1780.0431023307021
Test loss for epoch 105 : 195.40248665864908
Test Precision for epoch 105 : 0.26153846153846155
Test Recall for epoch 105 : 0.26153846153846155
Test F1 for epoch 105 : 0.26153846153846155


theta for epoch 106 : tensor([[3.6203, 3.6388, 3.7532, 3.7100, 3.7045, 3.6025, 3.6383, 3.5474, 3.5474,
         1.2662, 1.2502, 1.2492, 1.2505, 1.2818, 1.2310, 1.2108, 1.2818, 1.2381,
         1.5982, 1.5827, 1.6064, 1.5892, 1.5957, 1.5973, 1.6043, 1.5973, 1.5973,
         1.3335, 1.3445, 1.3323, 1.3516, 1.3337, 1.3617, 1.3553, 1.3435, 1.3323,
         1.5884, 1.6046, 1.5937, 1.5902, 1.5969, 1.5872, 1.6052, 1.5584, 1.5634,
         1.2455, 1.2710, 1.2634, 1.2809, 1.2405, 1.2324, 1.2207, 1.3053, 1.2599],
        [1.3741, 1.2369, 1.2260, 1.2671, 1.2675, 1.2795, 1.2735, 1.1886, 1.1886,
         3.6521, 3.6977, 3.6106, 3.8151, 3.6536, 3.9650, 3.5716, 3.6281, 3.8619,
         1.5698, 1.5588, 1.5325, 1.5339, 1.5540, 1.5634, 1.5856, 1.5634, 1.5634,
         1.3522, 1.3205, 1.3174, 1.3691, 1.3149, 1.4031, 1.3851, 1.3571, 1.3142,
         1.5403, 1.5924, 1.5588, 1.5461, 1.5408, 1.5761, 1.5946, 1.4332, 1.5311,
         1.1447, 1.2513, 1.2258, 1.2745, 1.1395, 1.1456, 1.0738, 1.3402, 1.2160],
        [1.4476, 1.4476, 1.4459, 1.4431, 1.4433, 1.4476, 1.4433, 1.4476, 1.4476,
         1.4367, 1.4359, 1.4367, 1.4366, 1.4368, 1.4176, 1.4367, 1.4354, 1.4331,
         2.2022, 2.2029, 2.2198, 2.1941, 2.1751, 2.1735, 2.2024, 2.1724, 2.1724,
         1.5087, 1.5072, 1.5146, 1.5146, 1.5087, 1.5146, 1.5145, 1.5146, 1.5146,
         1.7703, 1.7704, 1.7704, 1.7671, 1.7703, 1.7703, 1.7704, 1.7472, 1.7500,
         1.4453, 1.4501, 1.4501, 1.4501, 1.4417, 1.4501, 1.4460, 1.4501, 1.4501],
        [1.3173, 1.3152, 1.2989, 1.2905, 1.3141, 1.3126, 1.3136, 1.3140, 1.3140,
         1.3017, 1.2952, 1.2914, 1.2907, 1.3024, 1.2866, 1.2985, 1.3019, 1.2743,
         1.6442, 1.6173, 1.6410, 1.6407, 1.6400, 1.6401, 1.6422, 1.6438, 1.6438,
         3.4899, 3.2788, 3.2021, 3.2634, 3.4180, 3.2293, 3.4644, 3.2110, 3.1882,
         1.6426, 1.6351, 1.6332, 1.6364, 1.6394, 1.6155, 1.6406, 1.5800, 1.6065,
         1.3121, 1.3066, 1.2968, 1.3114, 1.3073, 1.2995, 1.3116, 1.3116, 1.3137],
        [1.4505, 1.4456, 1.4006, 1.4055, 1.4436, 1.4504, 1.4488, 1.4505, 1.4505,
         1.4385, 1.4356, 1.4305, 1.4246, 1.4397, 1.3966, 1.4335, 1.4396, 1.4338,
         1.7592, 1.7503, 1.7482, 1.7569, 1.7751, 1.7736, 1.7533, 1.7753, 1.7753,
         1.4756, 1.4795, 1.5174, 1.5120, 1.4808, 1.5159, 1.5044, 1.5175, 1.5144,
         2.1939, 2.1712, 2.1595, 2.1789, 2.2252, 2.2393, 2.2058, 2.3180, 2.3124,
         1.4367, 1.4281, 1.4425, 1.4529, 1.4395, 1.4496, 1.4189, 1.4468, 1.4529],
        [1.3849, 1.2826, 1.2800, 1.2988, 1.2925, 1.3022, 1.3011, 1.2318, 1.2318,
         1.2684, 1.2287, 1.2277, 1.2318, 1.3087, 1.1822, 1.1458, 1.3087, 1.2124,
         1.6134, 1.5895, 1.5739, 1.5646, 1.5867, 1.5833, 1.6057, 1.5882, 1.5882,
         1.3790, 1.3522, 1.3468, 1.3703, 1.3529, 1.4005, 1.4010, 1.3723, 1.3469,
         1.5763, 1.5790, 1.5812, 1.5710, 1.5495, 1.5541, 1.6157, 1.5043, 1.4739,
         3.8847, 3.6389, 3.6945, 3.6864, 3.6858, 3.4740, 3.8772, 3.6721, 3.4981]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 106 : 1780.5535973707968
Test loss for epoch 106 : 194.16129189402614
Test Precision for epoch 106 : 0.26153846153846155
Test Recall for epoch 106 : 0.26153846153846155
Test F1 for epoch 106 : 0.26153846153846155


theta for epoch 107 : tensor([[3.6159, 3.6345, 3.7497, 3.7062, 3.7007, 3.5980, 3.6340, 3.5426, 3.5426,
         1.2619, 1.2457, 1.2447, 1.2461, 1.2780, 1.2265, 1.2057, 1.2780, 1.2336,
         1.6050, 1.5895, 1.6131, 1.5960, 1.6025, 1.6041, 1.6110, 1.6041, 1.6041,
         1.3293, 1.3403, 1.3282, 1.3475, 1.3296, 1.3575, 1.3511, 1.3393, 1.3282,
         1.5925, 1.6086, 1.5977, 1.5942, 1.6009, 1.5912, 1.6092, 1.5625, 1.5675,
         1.2481, 1.2734, 1.2660, 1.2833, 1.2432, 1.2351, 1.2233, 1.3074, 1.2625],
        [1.3880, 1.2492, 1.2386, 1.2796, 1.2801, 1.2920, 1.2860, 1.1999, 1.1999,
         3.6336, 3.6797, 3.5918, 3.7981, 3.6352, 3.9496, 3.5525, 3.6094, 3.8455,
         1.5838, 1.5727, 1.5466, 1.5478, 1.5678, 1.5771, 1.5994, 1.5772, 1.5772,
         1.3633, 1.3316, 1.3278, 1.3802, 1.3258, 1.4145, 1.3964, 1.3680, 1.3247,
         1.5504, 1.6025, 1.5689, 1.5562, 1.5509, 1.5862, 1.6047, 1.4439, 1.5412,
         1.1561, 1.2625, 1.2373, 1.2856, 1.1510, 1.1570, 1.0852, 1.3511, 1.2275],
        [1.4445, 1.4444, 1.4427, 1.4399, 1.4401, 1.4445, 1.4402, 1.4445, 1.4445,
         1.4324, 1.4316, 1.4324, 1.4323, 1.4325, 1.4133, 1.4324, 1.4312, 1.4288,
         2.2083, 2.2090, 2.2259, 2.2000, 2.1810, 2.1794, 2.2083, 2.1783, 2.1783,
         1.5048, 1.5033, 1.5107, 1.5107, 1.5049, 1.5107, 1.5107, 1.5107, 1.5107,
         1.7740, 1.7741, 1.7741, 1.7708, 1.7740, 1.7740, 1.7741, 1.7509, 1.7537,
         1.4467, 1.4515, 1.4515, 1.4515, 1.4431, 1.4515, 1.4473, 1.4514, 1.4515],
        [1.3144, 1.3122, 1.2959, 1.2874, 1.3112, 1.3096, 1.3107, 1.3110, 1.3110,
         1.2974, 1.2908, 1.2870, 1.2863, 1.2981, 1.2823, 1.2942, 1.2976, 1.2700,
         1.6505, 1.6237, 1.6473, 1.6470, 1.6463, 1.6464, 1.6485, 1.6501, 1.6501,
         3.4859, 3.2744, 3.1976, 3.2589, 3.4137, 3.2249, 3.4602, 3.2065, 3.1837,
         1.6463, 1.6388, 1.6369, 1.6401, 1.6431, 1.6192, 1.6443, 1.5837, 1.6102,
         1.3137, 1.3082, 1.2984, 1.3130, 1.3089, 1.3011, 1.3131, 1.3132, 1.3153],
        [1.4474, 1.4424, 1.3973, 1.4023, 1.4404, 1.4473, 1.4456, 1.4473, 1.4473,
         1.4342, 1.4314, 1.4263, 1.4204, 1.4354, 1.3925, 1.4292, 1.4353, 1.4295,
         1.7652, 1.7564, 1.7543, 1.7629, 1.7811, 1.7796, 1.7594, 1.7813, 1.7813,
         1.4716, 1.4755, 1.5135, 1.5081, 1.4768, 1.5120, 1.5005, 1.5136, 1.5105,
         2.1974, 2.1749, 2.1632, 2.1826, 2.2287, 2.2429, 2.2095, 2.3212, 2.3157,
         1.4381, 1.4295, 1.4439, 1.4542, 1.4409, 1.4510, 1.4204, 1.4482, 1.4543],
        [1.3756, 1.2758, 1.2729, 1.2915, 1.2852, 1.2949, 1.2938, 1.2265, 1.2265,
         1.2632, 1.2233, 1.2223, 1.2264, 1.3039, 1.1769, 1.1400, 1.3039, 1.2070,
         1.6190, 1.5952, 1.5793, 1.5706, 1.5926, 1.5892, 1.6113, 1.5941, 1.5941,
         1.3709, 1.3443, 1.3397, 1.3620, 1.3451, 1.3917, 1.3924, 1.3643, 1.3397,
         1.5795, 1.5820, 1.5845, 1.5743, 1.5526, 1.5571, 1.6186, 1.5075, 1.4771,
         3.8892, 3.6409, 3.6970, 3.6888, 3.6883, 3.4747, 3.8818, 3.6742, 3.4990]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 107 : 1781.3862004701025
Test loss for epoch 107 : 193.83038319005018
Test Precision for epoch 107 : 0.26153846153846155
Test Recall for epoch 107 : 0.26153846153846155
Test F1 for epoch 107 : 0.26153846153846155


theta for epoch 108 : tensor([[3.6113, 3.6300, 3.7460, 3.7022, 3.6966, 3.5932, 3.6295, 3.5376, 3.5376,
         1.2632, 1.2465, 1.2455, 1.2471, 1.2798, 1.2272, 1.2056, 1.2798, 1.2343,
         1.6020, 1.5865, 1.6101, 1.5930, 1.5994, 1.6011, 1.6080, 1.6010, 1.6010,
         1.3235, 1.3345, 1.3222, 1.3417, 1.3237, 1.3519, 1.3454, 1.3335, 1.3222,
         1.5966, 1.6127, 1.6019, 1.5983, 1.6051, 1.5953, 1.6134, 1.5667, 1.5716,
         1.2519, 1.2773, 1.2699, 1.2871, 1.2471, 1.2390, 1.2271, 1.3112, 1.2665],
        [1.3925, 1.2520, 1.2416, 1.2827, 1.2831, 1.2950, 1.2890, 1.2016, 1.2016,
         3.6253, 3.6718, 3.5831, 3.7913, 3.6267, 3.9442, 3.5436, 3.6007, 3.8391,
         1.5854, 1.5743, 1.5483, 1.5493, 1.5692, 1.5785, 1.6009, 1.5785, 1.5785,
         1.3658, 1.3342, 1.3297, 1.3828, 1.3282, 1.4174, 1.3991, 1.3704, 1.3266,
         1.5571, 1.6093, 1.5756, 1.5629, 1.5577, 1.5930, 1.6115, 1.4509, 1.5479,
         1.1642, 1.2706, 1.2456, 1.2937, 1.1589, 1.1649, 1.0930, 1.3590, 1.2358],
        [1.4398, 1.4397, 1.4380, 1.4352, 1.4354, 1.4398, 1.4354, 1.4398, 1.4398,
         1.4337, 1.4329, 1.4336, 1.4336, 1.4337, 1.4145, 1.4336, 1.4324, 1.4301,
         2.2056, 2.2063, 2.2232, 2.1976, 2.1786, 2.1770, 2.2059, 2.1759, 2.1759,
         1.4994, 1.4979, 1.5053, 1.5053, 1.4994, 1.5053, 1.5053, 1.5053, 1.5053,
         1.7779, 1.7780, 1.7780, 1.7748, 1.7779, 1.7779, 1.7780, 1.7549, 1.7576,
         1.4497, 1.4545, 1.4545, 1.4545, 1.4461, 1.4546, 1.4504, 1.4545, 1.4545],
        [1.3099, 1.3076, 1.2913, 1.2828, 1.3066, 1.3050, 1.3061, 1.3064, 1.3064,
         1.2986, 1.2921, 1.2883, 1.2876, 1.2993, 1.2835, 1.2954, 1.2989, 1.2712,
         1.6473, 1.6205, 1.6442, 1.6438, 1.6432, 1.6432, 1.6454, 1.6469, 1.6469,
         3.4804, 3.2684, 3.1916, 3.2529, 3.4079, 3.2189, 3.4545, 3.2005, 3.1777,
         1.6503, 1.6428, 1.6409, 1.6442, 1.6471, 1.6232, 1.6483, 1.5877, 1.6142,
         1.3170, 1.3114, 1.3017, 1.3163, 1.3121, 1.3043, 1.3164, 1.3165, 1.3186],
        [1.4427, 1.4376, 1.3925, 1.3975, 1.4357, 1.4425, 1.4409, 1.4426, 1.4426,
         1.4354, 1.4326, 1.4275, 1.4217, 1.4366, 1.3938, 1.4304, 1.4365, 1.4308,
         1.7620, 1.7531, 1.7511, 1.7596, 1.7779, 1.7763, 1.7561, 1.7780, 1.7780,
         1.4661, 1.4699, 1.5081, 1.5026, 1.4713, 1.5066, 1.4951, 1.5082, 1.5051,
         2.2013, 2.1790, 2.1673, 2.1865, 2.2325, 2.2468, 2.2135, 2.3247, 2.3193,
         1.4411, 1.4325, 1.4469, 1.4572, 1.4440, 1.4541, 1.4234, 1.4512, 1.4573],
        [1.3618, 1.2641, 1.2609, 1.2794, 1.2730, 1.2827, 1.2817, 1.2160, 1.2160,
         1.2622, 1.2220, 1.2210, 1.2253, 1.3034, 1.1756, 1.1380, 1.3034, 1.2056,
         1.6139, 1.5902, 1.5742, 1.5658, 1.5879, 1.5845, 1.6063, 1.5894, 1.5894,
         1.3586, 1.3320, 1.3282, 1.3495, 1.3331, 1.3787, 1.3797, 1.3520, 1.3283,
         1.5820, 1.5842, 1.5869, 1.5767, 1.5550, 1.5594, 1.6207, 1.5098, 1.4794,
         3.8981, 3.6472, 3.7038, 3.6955, 3.6953, 3.4799, 3.8907, 3.6808, 3.5043]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 108 : 1781.6544307268712
Test loss for epoch 108 : 194.01313340815932
Test Precision for epoch 108 : 0.26153846153846155
Test Recall for epoch 108 : 0.26153846153846155
Test F1 for epoch 108 : 0.26153846153846155


theta for epoch 109 : tensor([[3.6110, 3.6299, 3.7467, 3.7024, 3.6968, 3.5929, 3.6293, 3.5371, 3.5371,
         1.2694, 1.2522, 1.2511, 1.2529, 1.2866, 1.2328, 1.2100, 1.2866, 1.2398,
         1.5927, 1.5772, 1.6009, 1.5836, 1.5901, 1.5917, 1.5988, 1.5917, 1.5917,
         1.3251, 1.3360, 1.3234, 1.3433, 1.3252, 1.3538, 1.3471, 1.3350, 1.3234,
         1.5967, 1.6128, 1.6019, 1.5984, 1.6052, 1.5954, 1.6135, 1.5668, 1.5717,
         1.2506, 1.2762, 1.2688, 1.2860, 1.2457, 1.2376, 1.2256, 1.3101, 1.2654],
        [1.3942, 1.2517, 1.2415, 1.2827, 1.2832, 1.2951, 1.2891, 1.2003, 1.2003,
         3.6261, 3.6730, 3.5836, 3.7935, 3.6275, 3.9478, 3.5438, 3.6013, 3.8418,
         1.5779, 1.5668, 1.5409, 1.5417, 1.5617, 1.5709, 1.5934, 1.5709, 1.5709,
         1.3668, 1.3350, 1.3301, 1.3838, 1.3289, 1.4188, 1.4003, 1.3713, 1.3270,
         1.5569, 1.6092, 1.5754, 1.5627, 1.5575, 1.5929, 1.6114, 1.4508, 1.5477,
         1.1640, 1.2706, 1.2457, 1.2937, 1.1587, 1.1646, 1.0925, 1.3589, 1.2360],
        [1.4418, 1.4417, 1.4399, 1.4372, 1.4374, 1.4418, 1.4374, 1.4418, 1.4418,
         1.4399, 1.4391, 1.4398, 1.4398, 1.4399, 1.4207, 1.4398, 1.4386, 1.4363,
         2.1974, 2.1980, 2.2150, 2.1898, 2.1708, 2.1692, 2.1982, 2.1681, 2.1681,
         1.5012, 1.4997, 1.5071, 1.5071, 1.5013, 1.5071, 1.5071, 1.5071, 1.5071,
         1.7780, 1.7781, 1.7781, 1.7748, 1.7780, 1.7780, 1.7781, 1.7550, 1.7577,
         1.4481, 1.4529, 1.4529, 1.4529, 1.4445, 1.4529, 1.4487, 1.4528, 1.4529],
        [1.3122, 1.3099, 1.2936, 1.2851, 1.3089, 1.3073, 1.3084, 1.3087, 1.3087,
         1.3049, 1.2983, 1.2945, 1.2938, 1.3056, 1.2898, 1.3016, 1.3052, 1.2775,
         1.6383, 1.6115, 1.6351, 1.6348, 1.6341, 1.6342, 1.6363, 1.6379, 1.6379,
         3.4800, 3.2678, 3.1910, 3.2523, 3.4074, 3.2184, 3.4541, 3.2000, 3.1772,
         1.6504, 1.6429, 1.6411, 1.6443, 1.6473, 1.6234, 1.6485, 1.5879, 1.6144,
         1.3156, 1.3101, 1.3003, 1.3149, 1.3108, 1.3029, 1.3150, 1.3151, 1.3172],
        [1.4446, 1.4396, 1.3945, 1.3995, 1.4376, 1.4445, 1.4428, 1.4446, 1.4446,
         1.4416, 1.4388, 1.4337, 1.4279, 1.4427, 1.4001, 1.4366, 1.4427, 1.4370,
         1.7528, 1.7439, 1.7420, 1.7505, 1.7687, 1.7672, 1.7470, 1.7689, 1.7689,
         1.4678, 1.4716, 1.5099, 1.5044, 1.4730, 1.5084, 1.4969, 1.5100, 1.5069,
         2.2015, 2.1793, 2.1676, 2.1867, 2.2327, 2.2470, 2.2137, 2.3246, 2.3192,
         1.4395, 1.4309, 1.4452, 1.4556, 1.4424, 1.4524, 1.4218, 1.4495, 1.4557],
        [1.3520, 1.2555, 1.2521, 1.2705, 1.2641, 1.2739, 1.2728, 1.2082, 1.2082,
         1.2653, 1.2246, 1.2236, 1.2280, 1.3071, 1.1781, 1.1394, 1.3071, 1.2081,
         1.6018, 1.5782, 1.5620, 1.5540, 1.5761, 1.5726, 1.5943, 1.5776, 1.5776,
         1.3509, 1.3243, 1.3212, 1.3417, 1.3256, 1.3705, 1.3718, 1.3444, 1.3213,
         1.5796, 1.5817, 1.5846, 1.5743, 1.5525, 1.5568, 1.6181, 1.5074, 1.4768,
         3.9074, 3.6540, 3.7111, 3.7027, 3.7026, 3.4855, 3.9000, 3.6877, 3.5100]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 109 : 1781.2432629195603
Test loss for epoch 109 : 194.319600397786
Test Precision for epoch 109 : 0.26153846153846155
Test Recall for epoch 109 : 0.26153846153846155
Test F1 for epoch 109 : 0.26153846153846155


theta for epoch 110 : tensor([[3.6144, 3.6336, 3.7511, 3.7065, 3.7009, 3.5964, 3.6330, 3.5405, 3.5405,
         1.2765, 1.2587, 1.2576, 1.2595, 1.2943, 1.2393, 1.2152, 1.2943, 1.2461,
         1.5868, 1.5713, 1.5950, 1.5776, 1.5840, 1.5857, 1.5929, 1.5856, 1.5856,
         1.3324, 1.3433, 1.3302, 1.3507, 1.3323, 1.3614, 1.3547, 1.3423, 1.3302,
         1.5926, 1.6088, 1.5978, 1.5942, 1.6011, 1.5913, 1.6095, 1.5627, 1.5676,
         1.2432, 1.2691, 1.2616, 1.2789, 1.2382, 1.2299, 1.2179, 1.3031, 1.2582],
        [1.3926, 1.2482, 1.2382, 1.2796, 1.2801, 1.2920, 1.2860, 1.1959, 1.1959,
         3.6336, 3.6809, 3.5908, 3.8025, 3.6350, 3.9582, 3.5509, 3.6085, 3.8513,
         1.5699, 1.5588, 1.5329, 1.5336, 1.5536, 1.5628, 1.5854, 1.5629, 1.5629,
         1.3657, 1.3338, 1.3285, 1.3829, 1.3275, 1.4182, 1.3995, 1.3702, 1.3254,
         1.5500, 1.6024, 1.5685, 1.5558, 1.5505, 1.5861, 1.6046, 1.4437, 1.5407,
         1.1552, 1.2622, 1.2373, 1.2852, 1.1499, 1.1558, 1.0834, 1.3503, 1.2276],
        [1.4490, 1.4489, 1.4472, 1.4444, 1.4446, 1.4490, 1.4447, 1.4490, 1.4490,
         1.4470, 1.4463, 1.4470, 1.4470, 1.4471, 1.4279, 1.4470, 1.4458, 1.4435,
         2.1924, 2.1930, 2.2100, 2.1851, 2.1661, 2.1645, 2.1935, 2.1634, 2.1634,
         1.5088, 1.5072, 1.5146, 1.5146, 1.5088, 1.5146, 1.5146, 1.5146, 1.5146,
         1.7741, 1.7742, 1.7742, 1.7710, 1.7741, 1.7741, 1.7742, 1.7511, 1.7538,
         1.4409, 1.4457, 1.4457, 1.4457, 1.4373, 1.4457, 1.4415, 1.4456, 1.4457],
        [1.3198, 1.3175, 1.3013, 1.2928, 1.3165, 1.3149, 1.3160, 1.3163, 1.3163,
         1.3122, 1.3056, 1.3018, 1.3011, 1.3129, 1.2971, 1.3089, 1.3125, 1.2848,
         1.6328, 1.6060, 1.6297, 1.6293, 1.6286, 1.6286, 1.6308, 1.6324, 1.6324,
         3.4839, 3.2715, 3.1949, 3.2560, 3.4112, 3.2221, 3.4578, 3.2038, 3.1811,
         1.6466, 1.6391, 1.6373, 1.6405, 1.6435, 1.6195, 1.6447, 1.5841, 1.6106,
         1.3086, 1.3031, 1.2933, 1.3079, 1.3037, 1.2959, 1.3080, 1.3082, 1.3102],
        [1.4518, 1.4468, 1.4017, 1.4068, 1.4449, 1.4517, 1.4501, 1.4519, 1.4519,
         1.4488, 1.4460, 1.4409, 1.4352, 1.4499, 1.4073, 1.4438, 1.4499, 1.4442,
         1.7472, 1.7382, 1.7363, 1.7448, 1.7631, 1.7615, 1.7413, 1.7632, 1.7632,
         1.4753, 1.4790, 1.5174, 1.5119, 1.4805, 1.5158, 1.5044, 1.5175, 1.5144,
         2.1979, 2.1757, 2.1641, 2.1832, 2.2290, 2.2435, 2.2102, 2.3208, 2.3154,
         1.4322, 1.4236, 1.4380, 1.4484, 1.4351, 1.4452, 1.4145, 1.4423, 1.4485],
        [1.3456, 1.2494, 1.2459, 1.2643, 1.2579, 1.2677, 1.2666, 1.2024, 1.2024,
         1.2687, 1.2274, 1.2263, 1.2310, 1.3113, 1.1808, 1.1407, 1.3113, 1.2106,
         1.5922, 1.5685, 1.5522, 1.5445, 1.5666, 1.5631, 1.5846, 1.5681, 1.5681,
         1.3470, 1.3204, 1.3177, 1.3377, 1.3218, 1.3663, 1.3678, 1.3405, 1.3178,
         1.5724, 1.5743, 1.5774, 1.5671, 1.5453, 1.5495, 1.6108, 1.5001, 1.4694,
         3.9162, 3.6603, 3.7178, 3.7093, 3.7095, 3.4906, 3.9088, 3.6941, 3.5152]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 110 : 1780.8714979363156
Test loss for epoch 110 : 194.62119266721518
Test Precision for epoch 110 : 0.26153846153846155
Test Recall for epoch 110 : 0.26153846153846155
Test F1 for epoch 110 : 0.26153846153846155


theta for epoch 111 : tensor([[3.6183, 3.6378, 3.7559, 3.7110, 3.7054, 3.6003, 3.6371, 3.5443, 3.5443,
         1.2784, 1.2600, 1.2589, 1.2611, 1.2968, 1.2406, 1.2152, 1.2968, 1.2473,
         1.5887, 1.5731, 1.5969, 1.5793, 1.5857, 1.5874, 1.5947, 1.5873, 1.5873,
         1.3377, 1.3486, 1.3350, 1.3561, 1.3373, 1.3671, 1.3602, 1.3475, 1.3350,
         1.5888, 1.6051, 1.5940, 1.5905, 1.5973, 1.5876, 1.6058, 1.5589, 1.5639,
         1.2363, 1.2626, 1.2550, 1.2726, 1.2312, 1.2228, 1.2108, 1.2969, 1.2516],
        [1.3839, 1.2379, 1.2278, 1.2696, 1.2700, 1.2821, 1.2760, 1.1849, 1.1849,
         3.6447, 3.6924, 3.6016, 3.8149, 3.6460, 3.9720, 3.5615, 3.6193, 3.8642,
         1.5654, 1.5543, 1.5282, 1.5289, 1.5490, 1.5583, 1.5810, 1.5583, 1.5583,
         1.3580, 1.3259, 1.3204, 1.3753, 1.3195, 1.4109, 1.3921, 1.3625, 1.3173,
         1.5409, 1.5935, 1.5596, 1.5468, 1.5414, 1.5772, 1.5957, 1.4343, 1.5315,
         1.1436, 1.2511, 1.2262, 1.2741, 1.1382, 1.1441, 1.0714, 1.3392, 1.2165],
        [1.4548, 1.4548, 1.4531, 1.4503, 1.4505, 1.4548, 1.4505, 1.4549, 1.4549,
         1.4492, 1.4485, 1.4492, 1.4491, 1.4492, 1.4301, 1.4492, 1.4480, 1.4457,
         2.1946, 2.1953, 2.2122, 2.1874, 2.1684, 2.1668, 2.1958, 2.1657, 2.1657,
         1.5146, 1.5131, 1.5205, 1.5205, 1.5146, 1.5205, 1.5204, 1.5205, 1.5205,
         1.7708, 1.7709, 1.7709, 1.7676, 1.7708, 1.7708, 1.7709, 1.7477, 1.7505,
         1.4347, 1.4395, 1.4395, 1.4395, 1.4311, 1.4395, 1.4353, 1.4394, 1.4395],
        [1.3259, 1.3236, 1.3073, 1.2988, 1.3226, 1.3210, 1.3221, 1.3223, 1.3223,
         1.3145, 1.3079, 1.3041, 1.3034, 1.3152, 1.2994, 1.3111, 1.3148, 1.2870,
         1.6352, 1.6084, 1.6321, 1.6317, 1.6310, 1.6310, 1.6332, 1.6348, 1.6348,
         3.4866, 3.2740, 3.1975, 3.2585, 3.4137, 3.2247, 3.4603, 3.2064, 3.1838,
         1.6433, 1.6359, 1.6340, 1.6372, 1.6402, 1.6163, 1.6414, 1.5808, 1.6073,
         1.3026, 1.2971, 1.2874, 1.3020, 1.2978, 1.2899, 1.3020, 1.3023, 1.3043],
        [1.4576, 1.4526, 1.4076, 1.4127, 1.4507, 1.4575, 1.4559, 1.4577, 1.4577,
         1.4509, 1.4482, 1.4431, 1.4374, 1.4521, 1.4096, 1.4460, 1.4520, 1.4464,
         1.7492, 1.7403, 1.7384, 1.7469, 1.7652, 1.7636, 1.7434, 1.7653, 1.7653,
         1.4812, 1.4847, 1.5233, 1.5177, 1.4863, 1.5217, 1.5102, 1.5233, 1.5202,
         2.1948, 2.1728, 2.1611, 2.1801, 2.2259, 2.2404, 2.2072, 2.3175, 2.3122,
         1.4260, 1.4174, 1.4318, 1.4422, 1.4289, 1.4390, 1.4082, 1.4361, 1.4423],
        [1.3371, 1.2404, 1.2369, 1.2554, 1.2489, 1.2587, 1.2577, 1.1932, 1.1932,
         1.2669, 1.2247, 1.2236, 1.2285, 1.3101, 1.1779, 1.1362, 1.3101, 1.2077,
         1.5894, 1.5657, 1.5492, 1.5416, 1.5639, 1.5604, 1.5818, 1.5653, 1.5653,
         1.3404, 1.3136, 1.3112, 1.3309, 1.3150, 1.3596, 1.3612, 1.3339, 1.3112,
         1.5651, 1.5669, 1.5701, 1.5598, 1.5379, 1.5421, 1.6035, 1.4925, 1.4618,
         3.9276, 3.6692, 3.7273, 3.7186, 3.7190, 3.4985, 3.9203, 3.7032, 3.5232]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 111 : 1780.58711448437
Test loss for epoch 111 : 195.06189356379912
Test Precision for epoch 111 : 0.26153846153846155
Test Recall for epoch 111 : 0.26153846153846155
Test F1 for epoch 111 : 0.26153846153846155


theta for epoch 112 : tensor([[3.6219, 3.6416, 3.7603, 3.7152, 3.7095, 3.6039, 3.6409, 3.5478, 3.5478,
         1.2720, 1.2530, 1.2518, 1.2542, 1.2910, 1.2335, 1.2068, 1.2910, 1.2401,
         1.5972, 1.5815, 1.6054, 1.5876, 1.5941, 1.5957, 1.6031, 1.5957, 1.5957,
         1.3384, 1.3492, 1.3352, 1.3569, 1.3378, 1.3683, 1.3611, 1.3482, 1.3352,
         1.5886, 1.6050, 1.5938, 1.5903, 1.5972, 1.5875, 1.6057, 1.5588, 1.5637,
         1.2340, 1.2609, 1.2531, 1.2709, 1.2288, 1.2202, 1.2083, 1.2955, 1.2496],
        [1.3679, 1.2204, 1.2103, 1.2524, 1.2529, 1.2650, 1.2589, 1.1669, 1.1669,
         3.6573, 3.7054, 3.6139, 3.8289, 3.6585, 3.9874, 3.5737, 3.6316, 3.8787,
         1.5639, 1.5527, 1.5265, 1.5272, 1.5474, 1.5568, 1.5796, 1.5569, 1.5569,
         1.3428, 1.3104, 1.3049, 1.3602, 1.3039, 1.3961, 1.3771, 1.3472, 1.3017,
         1.5330, 1.5858, 1.5517, 1.5389, 1.5334, 1.5694, 1.5880, 1.4258, 1.5234,
         1.1327, 1.2410, 1.2160, 1.2640, 1.1272, 1.1331, 1.0599, 1.3293, 1.2063],
        [1.4574, 1.4573, 1.4556, 1.4528, 1.4530, 1.4574, 1.4531, 1.4574, 1.4574,
         1.4432, 1.4424, 1.4432, 1.4431, 1.4432, 1.4241, 1.4432, 1.4419, 1.4396,
         2.2031, 2.2038, 2.2207, 2.1956, 2.1766, 2.1750, 2.2040, 2.1739, 2.1739,
         1.5163, 1.5148, 1.5222, 1.5222, 1.5164, 1.5222, 1.5222, 1.5222, 1.5222,
         1.7712, 1.7712, 1.7712, 1.7680, 1.7711, 1.7711, 1.7712, 1.7480, 1.7508,
         1.4335, 1.4384, 1.4384, 1.4384, 1.4299, 1.4384, 1.4341, 1.4383, 1.4384],
        [1.3285, 1.3262, 1.3099, 1.3014, 1.3252, 1.3236, 1.3247, 1.3249, 1.3249,
         1.3086, 1.3019, 1.2981, 1.2975, 1.3093, 1.2934, 1.3051, 1.3089, 1.2811,
         1.6444, 1.6176, 1.6413, 1.6408, 1.6402, 1.6402, 1.6424, 1.6439, 1.6439,
         3.4864, 3.2737, 3.1973, 3.2582, 3.4134, 3.2244, 3.4601, 3.2061, 3.1835,
         1.6438, 1.6363, 1.6344, 1.6377, 1.6407, 1.6167, 1.6419, 1.5812, 1.6078,
         1.3017, 1.2962, 1.2865, 1.3011, 1.2968, 1.2890, 1.3011, 1.3014, 1.3034],
        [1.4601, 1.4551, 1.4102, 1.4153, 1.4532, 1.4601, 1.4584, 1.4602, 1.4602,
         1.4449, 1.4422, 1.4371, 1.4314, 1.4461, 1.4036, 1.4400, 1.4460, 1.4404,
         1.7580, 1.7491, 1.7472, 1.7557, 1.7739, 1.7724, 1.7522, 1.7741, 1.7741,
         1.4828, 1.4863, 1.5250, 1.5194, 1.4880, 1.5234, 1.5119, 1.5250, 1.5220,
         2.1953, 2.1734, 2.1617, 2.1807, 2.2263, 2.2410, 2.2077, 2.3177, 2.3125,
         1.4248, 1.4163, 1.4306, 1.4411, 1.4277, 1.4379, 1.4070, 1.4350, 1.4411],
        [1.3254, 1.2276, 1.2241, 1.2428, 1.2362, 1.2461, 1.2451, 1.1799, 1.1799,
         1.2567, 1.2136, 1.2124, 1.2176, 1.3008, 1.1667, 1.1232, 1.3008, 1.1964,
         1.5926, 1.5689, 1.5521, 1.5447, 1.5670, 1.5635, 1.5850, 1.5685, 1.5685,
         1.3292, 1.3022, 1.2999, 1.3196, 1.3036, 1.3485, 1.3502, 1.3226, 1.2999,
         1.5609, 1.5627, 1.5659, 1.5556, 1.5336, 1.5378, 1.5994, 1.4881, 1.4572,
         3.9436, 3.6827, 3.7413, 3.7325, 3.7332, 3.5110, 3.9363, 3.7168, 3.5357]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 112 : 1779.4670104361626
Test loss for epoch 112 : 195.68465964864188
Test Precision for epoch 112 : 0.26153846153846155
Test Recall for epoch 112 : 0.26153846153846155
Test F1 for epoch 112 : 0.26153846153846155


theta for epoch 113 : tensor([[3.6272, 3.6472, 3.7666, 3.7212, 3.7154, 3.6094, 3.6465, 3.5532, 3.5532,
         1.2602, 1.2407, 1.2395, 1.2420, 1.2798, 1.2211, 1.1933, 1.2798, 1.2276,
         1.6053, 1.5896, 1.6135, 1.5956, 1.6021, 1.6037, 1.6112, 1.6037, 1.6037,
         1.3388, 1.3496, 1.3352, 1.3574, 1.3380, 1.3690, 1.3618, 1.3485, 1.3352,
         1.5916, 1.6080, 1.5968, 1.5932, 1.6001, 1.5904, 1.6088, 1.5617, 1.5667,
         1.2346, 1.2620, 1.2541, 1.2721, 1.2293, 1.2205, 1.2086, 1.2968, 1.2505],
        [1.3477, 1.1989, 1.1888, 1.2312, 1.2316, 1.2438, 1.2377, 1.1450, 1.1450,
         3.6721, 3.7207, 3.6285, 3.8452, 3.6733, 4.0051, 3.5882, 3.6461, 3.8955,
         1.5600, 1.5487, 1.5222, 1.5231, 1.5435, 1.5529, 1.5758, 1.5530, 1.5530,
         1.3239, 1.2912, 1.2857, 1.3414, 1.2847, 1.3776, 1.3585, 1.3284, 1.2825,
         1.5261, 1.5793, 1.5450, 1.5320, 1.5265, 1.5627, 1.5814, 1.4181, 1.5164,
         1.1213, 1.2308, 1.2056, 1.2540, 1.1158, 1.1216, 1.0479, 1.3195, 1.1959],
        [1.4596, 1.4596, 1.4579, 1.4551, 1.4553, 1.4597, 1.4554, 1.4597, 1.4597,
         1.4321, 1.4313, 1.4320, 1.4320, 1.4321, 1.4129, 1.4320, 1.4308, 1.4285,
         2.2116, 2.2123, 2.2291, 2.2037, 2.1848, 2.1832, 2.2121, 2.1821, 2.1821,
         1.5183, 1.5167, 1.5242, 1.5242, 1.5183, 1.5241, 1.5241, 1.5242, 1.5242,
         1.7748, 1.7749, 1.7749, 1.7716, 1.7748, 1.7748, 1.7749, 1.7517, 1.7545,
         1.4356, 1.4404, 1.4404, 1.4404, 1.4320, 1.4404, 1.4362, 1.4404, 1.4404],
        [1.3306, 1.3283, 1.3121, 1.3036, 1.3273, 1.3257, 1.3268, 1.3271, 1.3271,
         1.2975, 1.2908, 1.2870, 1.2863, 1.2983, 1.2823, 1.2940, 1.2978, 1.2699,
         1.6535, 1.6268, 1.6504, 1.6499, 1.6493, 1.6493, 1.6515, 1.6530, 1.6530,
         3.4870, 3.2741, 3.1978, 3.2586, 3.4138, 3.2249, 3.4605, 3.2066, 3.1841,
         1.6475, 1.6400, 1.6382, 1.6414, 1.6444, 1.6205, 1.6456, 1.5850, 1.6116,
         1.3039, 1.2985, 1.2887, 1.3034, 1.2991, 1.2912, 1.3033, 1.3037, 1.3056],
        [1.4624, 1.4574, 1.4126, 1.4176, 1.4555, 1.4623, 1.4607, 1.4625, 1.4625,
         1.4338, 1.4311, 1.4260, 1.4203, 1.4349, 1.3924, 1.4289, 1.4349, 1.4293,
         1.7668, 1.7579, 1.7560, 1.7644, 1.7827, 1.7811, 1.7609, 1.7828, 1.7828,
         1.4847, 1.4882, 1.5269, 1.5213, 1.4899, 1.5253, 1.5138, 1.5270, 1.5239,
         2.1991, 2.1772, 2.1655, 2.1845, 2.2300, 2.2448, 2.2115, 2.3212, 2.3160,
         1.4269, 1.4184, 1.4327, 1.4432, 1.4298, 1.4399, 1.4091, 1.4371, 1.4432],
        [1.3140, 1.2146, 1.2112, 1.2300, 1.2234, 1.2334, 1.2323, 1.1661, 1.1661,
         1.2413, 1.1972, 1.1959, 1.2014, 1.2863, 1.1501, 1.1047, 1.2863, 1.1796,
         1.5954, 1.5715, 1.5545, 1.5472, 1.5696, 1.5661, 1.5877, 1.5711, 1.5711,
         1.3181, 1.2909, 1.2884, 1.3085, 1.2922, 1.3376, 1.3393, 1.3115, 1.2885,
         1.5597, 1.5614, 1.5647, 1.5543, 1.5322, 1.5364, 1.5982, 1.4865, 1.4555,
         3.9627, 3.6994, 3.7584, 3.7495, 3.7505, 3.5267, 3.9555, 3.7336, 3.5514]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 113 : 1778.591725512322
Test loss for epoch 113 : 196.51870795646252
Test Precision for epoch 113 : 0.26153846153846155
Test Recall for epoch 113 : 0.26153846153846155
Test F1 for epoch 113 : 0.26153846153846155


theta for epoch 114 : tensor([[3.6311, 3.6514, 3.7714, 3.7257, 3.7198, 3.6133, 3.6506, 3.5571, 3.5571,
         1.2504, 1.2305, 1.2293, 1.2319, 1.2701, 1.2109, 1.1826, 1.2701, 1.2174,
         1.6058, 1.5901, 1.6141, 1.5961, 1.6025, 1.6041, 1.6117, 1.6041, 1.6041,
         1.3461, 1.3569, 1.3423, 1.3647, 1.3452, 1.3764, 1.3691, 1.3558, 1.3423,
         1.5966, 1.6130, 1.6018, 1.5982, 1.6051, 1.5955, 1.6138, 1.5668, 1.5717,
         1.2355, 1.2629, 1.2550, 1.2729, 1.2301, 1.2214, 1.2095, 1.2974, 1.2514],
        [1.3416, 1.1926, 1.1823, 1.2249, 1.2254, 1.2376, 1.2314, 1.1387, 1.1387,
         3.6767, 3.7257, 3.6328, 3.8513, 3.6778, 4.0126, 3.5923, 3.6505, 3.9021,
         1.5553, 1.5440, 1.5173, 1.5183, 1.5387, 1.5482, 1.5712, 1.5483, 1.5483,
         1.3193, 1.2865, 1.2811, 1.3369, 1.2800, 1.3732, 1.3540, 1.3239, 1.2779,
         1.5260, 1.5794, 1.5451, 1.5320, 1.5264, 1.5628, 1.5815, 1.4177, 1.5163,
         1.1171, 1.2265, 1.2014, 1.2493, 1.1117, 1.1178, 1.0438, 1.3141, 1.1918],
        [1.4658, 1.4659, 1.4642, 1.4614, 1.4615, 1.4659, 1.4616, 1.4660, 1.4660,
         1.4222, 1.4215, 1.4222, 1.4222, 1.4222, 1.4031, 1.4222, 1.4210, 1.4187,
         2.2123, 2.2130, 2.2299, 2.2045, 2.1856, 2.1840, 2.2129, 2.1829, 2.1829,
         1.5251, 1.5236, 1.5310, 1.5310, 1.5251, 1.5310, 1.5310, 1.5310, 1.5310,
         1.7798, 1.7799, 1.7799, 1.7766, 1.7798, 1.7798, 1.7799, 1.7567, 1.7595,
         1.4366, 1.4414, 1.4414, 1.4414, 1.4330, 1.4414, 1.4372, 1.4413, 1.4414],
        [1.3367, 1.3344, 1.3182, 1.3097, 1.3334, 1.3318, 1.3329, 1.3332, 1.3332,
         1.2876, 1.2810, 1.2771, 1.2765, 1.2884, 1.2725, 1.2841, 1.2880, 1.2601,
         1.6542, 1.6275, 1.6511, 1.6507, 1.6500, 1.6501, 1.6523, 1.6538, 1.6538,
         3.4918, 3.2790, 3.2028, 3.2634, 3.4186, 3.2298, 3.4653, 3.2116, 3.1891,
         1.6526, 1.6451, 1.6433, 1.6465, 1.6495, 1.6256, 1.6507, 1.5901, 1.6167,
         1.3050, 1.2996, 1.2899, 1.3045, 1.3002, 1.2923, 1.3044, 1.3048, 1.3067],
        [1.4686, 1.4637, 1.4191, 1.4239, 1.4618, 1.4686, 1.4669, 1.4687, 1.4687,
         1.4240, 1.4212, 1.4162, 1.4105, 1.4251, 1.3826, 1.4191, 1.4251, 1.4195,
         1.7674, 1.7585, 1.7566, 1.7650, 1.7833, 1.7817, 1.7615, 1.7834, 1.7834,
         1.4916, 1.4951, 1.5338, 1.5282, 1.4968, 1.5321, 1.5207, 1.5338, 1.5307,
         2.2041, 2.1824, 2.1707, 2.1896, 2.2350, 2.2499, 2.2166, 2.3259, 2.3208,
         1.4279, 1.4194, 1.4337, 1.4441, 1.4308, 1.4409, 1.4101, 1.4380, 1.4442],
        [1.3288, 1.2292, 1.2258, 1.2446, 1.2381, 1.2480, 1.2469, 1.1805, 1.1805,
         1.2357, 1.1914, 1.1901, 1.1957, 1.2809, 1.1445, 1.0985, 1.2809, 1.1738,
         1.6007, 1.5768, 1.5598, 1.5526, 1.5749, 1.5714, 1.5930, 1.5764, 1.5764,
         1.3331, 1.3059, 1.3033, 1.3235, 1.3071, 1.3526, 1.3542, 1.3264, 1.3033,
         1.5685, 1.5703, 1.5736, 1.5632, 1.5411, 1.5453, 1.6070, 1.4955, 1.4646,
         3.9533, 3.6875, 3.7470, 3.7380, 3.7390, 3.5135, 3.9461, 3.7220, 3.5385]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 114 : 1778.687983332281
Test loss for epoch 114 : 196.14595881015072
Test Precision for epoch 114 : 0.26153846153846155
Test Recall for epoch 114 : 0.26153846153846155
Test F1 for epoch 114 : 0.26153846153846155


theta for epoch 115 : tensor([[3.6289, 3.6492, 3.7699, 3.7239, 3.7180, 3.6110, 3.6484, 3.5546, 3.5546,
         1.2477, 1.2278, 1.2266, 1.2293, 1.2674, 1.2083, 1.1800, 1.2674, 1.2147,
         1.6006, 1.5849, 1.6089, 1.5909, 1.5973, 1.5989, 1.6065, 1.5989, 1.5989,
         1.3501, 1.3609, 1.3463, 1.3688, 1.3492, 1.3805, 1.3732, 1.3598, 1.3463,
         1.6008, 1.6172, 1.6059, 1.6024, 1.6093, 1.5996, 1.6180, 1.5710, 1.5759,
         1.2401, 1.2671, 1.2592, 1.2770, 1.2349, 1.2263, 1.2144, 1.3013, 1.2557],
        [1.3469, 1.1987, 1.1884, 1.2309, 1.2314, 1.2436, 1.2374, 1.1453, 1.1453,
         3.6699, 3.7193, 3.6257, 3.8459, 3.6710, 4.0086, 3.5850, 3.6435, 3.8972,
         1.5534, 1.5421, 1.5155, 1.5165, 1.5369, 1.5464, 1.5692, 1.5464, 1.5464,
         1.3254, 1.2927, 1.2874, 1.3429, 1.2862, 1.3791, 1.3600, 1.3300, 1.2842,
         1.5319, 1.5851, 1.5509, 1.5379, 1.5323, 1.5686, 1.5872, 1.4237, 1.5221,
         1.1250, 1.2328, 1.2079, 1.2553, 1.1200, 1.1267, 1.0525, 1.3191, 1.1985],
        [1.4671, 1.4671, 1.4655, 1.4626, 1.4628, 1.4672, 1.4629, 1.4672, 1.4672,
         1.4189, 1.4182, 1.4189, 1.4189, 1.4189, 1.3998, 1.4189, 1.4177, 1.4154,
         2.2072, 2.2079, 2.2247, 2.1997, 2.1808, 2.1792, 2.2081, 2.1781, 2.1781,
         1.5273, 1.5257, 1.5332, 1.5332, 1.5273, 1.5332, 1.5331, 1.5332, 1.5332,
         1.7834, 1.7835, 1.7835, 1.7802, 1.7834, 1.7834, 1.7835, 1.7603, 1.7631,
         1.4400, 1.4449, 1.4449, 1.4449, 1.4364, 1.4449, 1.4406, 1.4448, 1.4449],
        [1.3375, 1.3353, 1.3191, 1.3106, 1.3343, 1.3327, 1.3338, 1.3341, 1.3341,
         1.2844, 1.2777, 1.2739, 1.2733, 1.2852, 1.2692, 1.2809, 1.2847, 1.2568,
         1.6486, 1.6219, 1.6455, 1.6450, 1.6444, 1.6444, 1.6466, 1.6481, 1.6481,
         3.4936, 3.2807, 3.2046, 3.2650, 3.4202, 3.2316, 3.4669, 3.2134, 3.1909,
         1.6562, 1.6488, 1.6469, 1.6502, 1.6531, 1.6292, 1.6543, 1.5937, 1.6203,
         1.3087, 1.3033, 1.2935, 1.3081, 1.3038, 1.2960, 1.3080, 1.3084, 1.3104],
        [1.4699, 1.4650, 1.4205, 1.4253, 1.4631, 1.4699, 1.4682, 1.4700, 1.4700,
         1.4207, 1.4180, 1.4129, 1.4073, 1.4218, 1.3794, 1.4158, 1.4218, 1.4163,
         1.7617, 1.7528, 1.7509, 1.7594, 1.7776, 1.7760, 1.7559, 1.7777, 1.7777,
         1.4937, 1.4973, 1.5359, 1.5304, 1.4989, 1.5343, 1.5228, 1.5360, 1.5329,
         2.2078, 2.1861, 2.1745, 2.1933, 2.2386, 2.2536, 2.2204, 2.3293, 2.3242,
         1.4314, 1.4229, 1.4372, 1.4476, 1.4343, 1.4444, 1.4136, 1.4415, 1.4477],
        [1.3515, 1.2526, 1.2493, 1.2679, 1.2615, 1.2713, 1.2702, 1.2042, 1.2042,
         1.2412, 1.1973, 1.1960, 1.2015, 1.2859, 1.1507, 1.1054, 1.2859, 1.1798,
         1.6056, 1.5820, 1.5650, 1.5579, 1.5801, 1.5766, 1.5981, 1.5815, 1.5815,
         1.3554, 1.3285, 1.3258, 1.3460, 1.3296, 1.3749, 1.3764, 1.3489, 1.3259,
         1.5808, 1.5826, 1.5858, 1.5755, 1.5535, 1.5577, 1.6191, 1.5082, 1.4776,
         3.9302, 3.6619, 3.7219, 3.7129, 3.7139, 3.4865, 3.9229, 3.6968, 3.5118]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 115 : 1779.7787999374045
Test loss for epoch 115 : 195.42794823379108
Test Precision for epoch 115 : 0.26153846153846155
Test Recall for epoch 115 : 0.26153846153846155
Test F1 for epoch 115 : 0.26153846153846155


theta for epoch 116 : tensor([[3.6182, 3.6385, 3.7599, 3.7137, 3.7077, 3.6002, 3.6377, 3.5434, 3.5434,
         1.2536, 1.2340, 1.2327, 1.2353, 1.2730, 1.2145, 1.1867, 1.2731, 1.2209,
         1.5967, 1.5810, 1.6049, 1.5870, 1.5934, 1.5950, 1.6026, 1.5950, 1.5950,
         1.3411, 1.3519, 1.3374, 1.3597, 1.3402, 1.3714, 1.3641, 1.3509, 1.3374,
         1.6013, 1.6177, 1.6064, 1.6029, 1.6098, 1.6001, 1.6184, 1.5715, 1.5764,
         1.2504, 1.2770, 1.2691, 1.2868, 1.2453, 1.2369, 1.2249, 1.3106, 1.2657],
        [1.3593, 1.2130, 1.2027, 1.2447, 1.2452, 1.2573, 1.2512, 1.1603, 1.1603,
         3.6521, 3.7018, 3.6074, 3.8294, 3.6532, 3.9936, 3.5664, 3.6254, 3.8812,
         1.5606, 1.5494, 1.5230, 1.5239, 1.5442, 1.5536, 1.5763, 1.5536, 1.5536,
         1.3358, 1.3034, 1.2982, 1.3532, 1.2970, 1.3889, 1.3700, 1.3403, 1.2951,
         1.5414, 1.5942, 1.5603, 1.5473, 1.5418, 1.5778, 1.5963, 1.4340, 1.5316,
         1.1458, 1.2519, 1.2273, 1.2742, 1.1411, 1.1482, 1.0742, 1.3369, 1.2180],
        [1.4572, 1.4572, 1.4555, 1.4527, 1.4529, 1.4573, 1.4530, 1.4573, 1.4573,
         1.4238, 1.4231, 1.4238, 1.4238, 1.4238, 1.4047, 1.4238, 1.4226, 1.4203,
         2.2027, 2.2034, 2.2203, 2.1955, 2.1765, 2.1749, 2.2039, 2.1739, 2.1739,
         1.5159, 1.5143, 1.5218, 1.5218, 1.5159, 1.5218, 1.5217, 1.5218, 1.5218,
         1.7829, 1.7830, 1.7830, 1.7797, 1.7829, 1.7829, 1.7830, 1.7598, 1.7626,
         1.4485, 1.4533, 1.4533, 1.4533, 1.4449, 1.4533, 1.4491, 1.4533, 1.4533],
        [1.3268, 1.3247, 1.3085, 1.2999, 1.3237, 1.3221, 1.3232, 1.3236, 1.3236,
         1.2893, 1.2826, 1.2788, 1.2782, 1.2901, 1.2742, 1.2859, 1.2896, 1.2618,
         1.6437, 1.6170, 1.6406, 1.6401, 1.6395, 1.6395, 1.6417, 1.6432, 1.6432,
         3.4852, 3.2720, 3.1959, 3.2564, 3.4116, 3.2230, 3.4585, 3.2047, 3.1822,
         1.6558, 1.6483, 1.6465, 1.6497, 1.6527, 1.6287, 1.6539, 1.5933, 1.6198,
         1.3173, 1.3119, 1.3021, 1.3167, 1.3124, 1.3046, 1.3166, 1.3170, 1.3190],
        [1.4600, 1.4552, 1.4107, 1.4153, 1.4532, 1.4600, 1.4583, 1.4601, 1.4601,
         1.4256, 1.4228, 1.4178, 1.4122, 1.4267, 1.3844, 1.4207, 1.4267, 1.4212,
         1.7568, 1.7479, 1.7460, 1.7545, 1.7727, 1.7711, 1.7509, 1.7728, 1.7728,
         1.4822, 1.4859, 1.5245, 1.5189, 1.4874, 1.5229, 1.5113, 1.5245, 1.5214,
         2.2076, 2.1860, 2.1743, 2.1931, 2.2383, 2.2534, 2.2202, 2.3288, 2.3238,
         1.4398, 1.4313, 1.4456, 1.4560, 1.4427, 1.4528, 1.4220, 1.4500, 1.4561],
        [1.3631, 1.2654, 1.2621, 1.2805, 1.2742, 1.2839, 1.2828, 1.2177, 1.2177,
         1.2540, 1.2108, 1.2096, 1.2149, 1.2978, 1.1645, 1.1207, 1.2978, 1.1936,
         1.6108, 1.5873, 1.5703, 1.5634, 1.5854, 1.5819, 1.6032, 1.5868, 1.5868,
         1.3641, 1.3376, 1.3349, 1.3549, 1.3386, 1.3835, 1.3849, 1.3577, 1.3350,
         1.5887, 1.5904, 1.5936, 1.5834, 1.5614, 1.5656, 1.6266, 1.5165, 1.4860,
         3.9112, 3.6406, 3.7010, 3.6919, 3.6929, 3.4638, 3.9039, 3.6756, 3.4894]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 116 : 1780.3287531661238
Test loss for epoch 116 : 194.65705654989515
Test Precision for epoch 116 : 0.26153846153846155
Test Recall for epoch 116 : 0.26153846153846155
Test F1 for epoch 116 : 0.26153846153846155


theta for epoch 117 : tensor([[3.6082, 3.6284, 3.7505, 3.7041, 3.6979, 3.5899, 3.6276, 3.5328, 3.5328,
         1.2653, 1.2458, 1.2446, 1.2472, 1.2847, 1.2263, 1.1988, 1.2847, 1.2328,
         1.5943, 1.5787, 1.6025, 1.5847, 1.5911, 1.5927, 1.6002, 1.5927, 1.5927,
         1.3285, 1.3394, 1.3249, 1.3472, 1.3276, 1.3589, 1.3516, 1.3383, 1.3249,
         1.5952, 1.6115, 1.6003, 1.5968, 1.6037, 1.5940, 1.6123, 1.5654, 1.5703,
         1.2593, 1.2856, 1.2778, 1.2953, 1.2544, 1.2461, 1.2342, 1.3188, 1.2744],
        [1.3627, 1.2175, 1.2073, 1.2491, 1.2495, 1.2616, 1.2555, 1.1653, 1.1653,
         3.6445, 3.6946, 3.5995, 3.8232, 3.6456, 3.9888, 3.5582, 3.6176, 3.8754,
         1.5651, 1.5539, 1.5277, 1.5286, 1.5488, 1.5581, 1.5807, 1.5581, 1.5581,
         1.3373, 1.3053, 1.3000, 1.3546, 1.2989, 1.3902, 1.3714, 1.3419, 1.2969,
         1.5412, 1.5938, 1.5600, 1.5471, 1.5416, 1.5775, 1.5959, 1.4345, 1.5315,
         1.1611, 1.2661, 1.2416, 1.2881, 1.1567, 1.1642, 1.0901, 1.3500, 1.2324],
        [1.4446, 1.4445, 1.4428, 1.4400, 1.4402, 1.4446, 1.4402, 1.4446, 1.4446,
         1.4349, 1.4342, 1.4349, 1.4349, 1.4349, 1.4158, 1.4349, 1.4337, 1.4314,
         2.2000, 2.2007, 2.2176, 2.1930, 2.1740, 2.1724, 2.2014, 2.1713, 2.1713,
         1.5017, 1.5002, 1.5077, 1.5077, 1.5018, 1.5077, 1.5077, 1.5077, 1.5077,
         1.7762, 1.7763, 1.7763, 1.7730, 1.7762, 1.7762, 1.7763, 1.7531, 1.7559,
         1.4561, 1.4609, 1.4609, 1.4609, 1.4525, 1.4609, 1.4567, 1.4608, 1.4609],
        [1.3133, 1.3113, 1.2951, 1.2864, 1.3102, 1.3086, 1.3097, 1.3101, 1.3101,
         1.3004, 1.2938, 1.2900, 1.2894, 1.3012, 1.2854, 1.2971, 1.3008, 1.2730,
         1.6407, 1.6140, 1.6376, 1.6371, 1.6365, 1.6365, 1.6387, 1.6402, 1.6402,
         3.4748, 3.2614, 3.1852, 3.2458, 3.4010, 3.2125, 3.4480, 3.1941, 3.1716,
         1.6491, 1.6416, 1.6397, 1.6430, 1.6460, 1.6220, 1.6472, 1.5865, 1.6131,
         1.3250, 1.3196, 1.3098, 1.3245, 1.3202, 1.3123, 1.3244, 1.3247, 1.3267],
        [1.4474, 1.4425, 1.3980, 1.4026, 1.4405, 1.4473, 1.4457, 1.4474, 1.4474,
         1.4367, 1.4340, 1.4289, 1.4233, 1.4378, 1.3956, 1.4318, 1.4378, 1.4323,
         1.7537, 1.7449, 1.7430, 1.7514, 1.7696, 1.7681, 1.7479, 1.7698, 1.7698,
         1.4679, 1.4717, 1.5104, 1.5048, 1.4732, 1.5089, 1.4972, 1.5104, 1.5073,
         2.2013, 2.1798, 2.1681, 2.1868, 2.2320, 2.2472, 2.2140, 2.3223, 2.3174,
         1.4474, 1.4389, 1.4532, 1.4636, 1.4503, 1.4604, 1.4296, 1.4575, 1.4637],
        [1.3671, 1.2708, 1.2674, 1.2857, 1.2794, 1.2890, 1.2879, 1.2238, 1.2238,
         1.2706, 1.2280, 1.2268, 1.2319, 1.3138, 1.1819, 1.1391, 1.3138, 1.2109,
         1.6153, 1.5920, 1.5750, 1.5683, 1.5901, 1.5867, 1.6078, 1.5916, 1.5916,
         1.3657, 1.3394, 1.3369, 1.3565, 1.3405, 1.3848, 1.3862, 1.3594, 1.3370,
         1.5884, 1.5901, 1.5933, 1.5832, 1.5612, 1.5653, 1.6260, 1.5165, 1.4862,
         3.8979, 3.6249, 3.6858, 3.6766, 3.6777, 3.4469, 3.8906, 3.6603, 3.4728]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 117 : 1780.6300546719895
Test loss for epoch 117 : 194.4332281088581
Test Precision for epoch 117 : 0.26153846153846155
Test Recall for epoch 117 : 0.26153846153846155
Test F1 for epoch 117 : 0.26153846153846155


theta for epoch 118 : tensor([[3.6051, 3.6254, 3.7481, 3.7014, 3.6952, 3.5867, 3.6246, 3.5294, 3.5294,
         1.2761, 1.2565, 1.2553, 1.2579, 1.2954, 1.2370, 1.2093, 1.2954, 1.2434,
         1.5929, 1.5773, 1.6011, 1.5833, 1.5896, 1.5913, 1.5988, 1.5912, 1.5912,
         1.3267, 1.3376, 1.3231, 1.3454, 1.3258, 1.3571, 1.3498, 1.3366, 1.3232,
         1.5869, 1.6032, 1.5920, 1.5885, 1.5953, 1.5856, 1.6039, 1.5571, 1.5620,
         1.2591, 1.2851, 1.2773, 1.2947, 1.2542, 1.2461, 1.2342, 1.3180, 1.2739],
        [1.3666, 1.2215, 1.2113, 1.2530, 1.2534, 1.2654, 1.2594, 1.1691, 1.1691,
         3.6435, 3.6940, 3.5982, 3.8236, 3.6446, 3.9905, 3.5566, 3.6164, 3.8763,
         1.5668, 1.5556, 1.5295, 1.5302, 1.5503, 1.5597, 1.5823, 1.5597, 1.5597,
         1.3404, 1.3084, 1.3030, 1.3577, 1.3020, 1.3933, 1.3745, 1.3449, 1.2999,
         1.5357, 1.5883, 1.5545, 1.5416, 1.5361, 1.5720, 1.5904, 1.4294, 1.5260,
         1.1651, 1.2693, 1.2448, 1.2911, 1.1609, 1.1686, 1.0947, 1.3524, 1.2356],
        [1.4418, 1.4417, 1.4400, 1.4372, 1.4374, 1.4418, 1.4374, 1.4417, 1.4417,
         1.4454, 1.4447, 1.4454, 1.4454, 1.4454, 1.4263, 1.4454, 1.4442, 1.4419,
         2.1985, 2.1991, 2.2160, 2.1916, 2.1726, 2.1710, 2.2001, 2.1699, 2.1699,
         1.4986, 1.4971, 1.5046, 1.5046, 1.4986, 1.5046, 1.5046, 1.5046, 1.5046,
         1.7676, 1.7677, 1.7677, 1.7644, 1.7676, 1.7676, 1.7677, 1.7444, 1.7472,
         1.4549, 1.4597, 1.4597, 1.4597, 1.4513, 1.4598, 1.4555, 1.4597, 1.4597],
        [1.3099, 1.3079, 1.2917, 1.2831, 1.3069, 1.3052, 1.3064, 1.3068, 1.3068,
         1.3109, 1.3043, 1.3005, 1.2999, 1.3117, 1.2959, 1.3076, 1.3113, 1.2835,
         1.6390, 1.6123, 1.6359, 1.6354, 1.6348, 1.6348, 1.6370, 1.6385, 1.6385,
         3.4727, 3.2593, 3.1832, 3.2437, 3.3989, 3.2105, 3.4460, 3.1921, 3.1696,
         1.6404, 1.6329, 1.6311, 1.6343, 1.6373, 1.6133, 1.6385, 1.5778, 1.6044,
         1.3239, 1.3185, 1.3088, 1.3234, 1.3191, 1.3112, 1.3233, 1.3237, 1.3256],
        [1.4446, 1.4397, 1.3952, 1.3998, 1.4377, 1.4445, 1.4429, 1.4446, 1.4446,
         1.4471, 1.4444, 1.4394, 1.4338, 1.4482, 1.4061, 1.4423, 1.4482, 1.4428,
         1.7520, 1.7431, 1.7412, 1.7497, 1.7679, 1.7663, 1.7462, 1.7680, 1.7680,
         1.4648, 1.4686, 1.5073, 1.5017, 1.4701, 1.5058, 1.4940, 1.5073, 1.5042,
         2.1931, 2.1717, 2.1601, 2.1787, 2.2239, 2.2392, 2.2059, 2.3141, 2.3093,
         1.4463, 1.4378, 1.4521, 1.4625, 1.4491, 1.4593, 1.4284, 1.4564, 1.4625],
        [1.3746, 1.2797, 1.2763, 1.2944, 1.2881, 1.2977, 1.2966, 1.2336, 1.2336,
         1.2847, 1.2425, 1.2412, 1.2463, 1.3275, 1.1965, 1.1544, 1.3275, 1.2255,
         1.6188, 1.5956, 1.5785, 1.5721, 1.5938, 1.5904, 1.6113, 1.5953, 1.5953,
         1.3728, 1.3467, 1.3445, 1.3636, 1.3478, 1.3915, 1.3930, 1.3665, 1.3445,
         1.5843, 1.5859, 1.5893, 1.5792, 1.5573, 1.5613, 1.6217, 1.5127, 1.4825,
         3.8858, 3.6106, 3.6719, 3.6626, 3.6637, 3.4313, 3.8785, 3.6461, 3.4574]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 118 : 1781.1756503547372
Test loss for epoch 118 : 194.40084696450236
Test Precision for epoch 118 : 0.26153846153846155
Test Recall for epoch 118 : 0.26153846153846155
Test F1 for epoch 118 : 0.26153846153846155


theta for epoch 119 : tensor([[3.6089, 3.6294, 3.7527, 3.7058, 3.6995, 3.5906, 3.6286, 3.5332, 3.5332,
         1.2768, 1.2569, 1.2557, 1.2584, 1.2963, 1.2375, 1.2092, 1.2963, 1.2438,
         1.5931, 1.5775, 1.6013, 1.5835, 1.5898, 1.5914, 1.5990, 1.5914, 1.5914,
         1.3355, 1.3464, 1.3319, 1.3542, 1.3346, 1.3659, 1.3586, 1.3454, 1.3319,
         1.5826, 1.5989, 1.5877, 1.5842, 1.5910, 1.5813, 1.5996, 1.5528, 1.5577,
         1.2548, 1.2806, 1.2728, 1.2901, 1.2500, 1.2420, 1.2301, 1.3131, 1.2694],
        [1.3718, 1.2254, 1.2153, 1.2571, 1.2576, 1.2696, 1.2635, 1.1724, 1.1724,
         3.6444, 3.6953, 3.5988, 3.8259, 3.6455, 3.9942, 3.5570, 3.6171, 3.8790,
         1.5666, 1.5553, 1.5294, 1.5298, 1.5499, 1.5592, 1.5821, 1.5592, 1.5592,
         1.3456, 1.3135, 1.3077, 1.3631, 1.3069, 1.3989, 1.3799, 1.3501, 1.3046,
         1.5310, 1.5839, 1.5499, 1.5370, 1.5315, 1.5675, 1.5860, 1.4248, 1.5214,
         1.1623, 1.2662, 1.2416, 1.2878, 1.1583, 1.1663, 1.0923, 1.3486, 1.2324],
        [1.4488, 1.4487, 1.4471, 1.4442, 1.4444, 1.4488, 1.4445, 1.4488, 1.4488,
         1.4462, 1.4455, 1.4462, 1.4462, 1.4462, 1.4271, 1.4462, 1.4450, 1.4427,
         2.1987, 2.1994, 2.2163, 2.1919, 2.1729, 2.1713, 2.2004, 2.1702, 2.1702,
         1.5064, 1.5048, 1.5124, 1.5124, 1.5064, 1.5124, 1.5123, 1.5124, 1.5124,
         1.7632, 1.7633, 1.7633, 1.7601, 1.7632, 1.7632, 1.7633, 1.7401, 1.7429,
         1.4501, 1.4549, 1.4549, 1.4549, 1.4465, 1.4549, 1.4507, 1.4549, 1.4549],
        [1.3166, 1.3147, 1.2986, 1.2899, 1.3137, 1.3121, 1.3132, 1.3137, 1.3137,
         1.3118, 1.3051, 1.3013, 1.3007, 1.3125, 1.2967, 1.3084, 1.3121, 1.2843,
         1.6393, 1.6126, 1.6362, 1.6357, 1.6351, 1.6351, 1.6373, 1.6388, 1.6388,
         3.4789, 3.2656, 3.1897, 3.2499, 3.4050, 3.2168, 3.4520, 3.1985, 3.1761,
         1.6361, 1.6286, 1.6267, 1.6300, 1.6330, 1.6090, 1.6342, 1.5735, 1.6001,
         1.3192, 1.3138, 1.3040, 1.3186, 1.3143, 1.3065, 1.3185, 1.3189, 1.3208],
        [1.4516, 1.4468, 1.4025, 1.4069, 1.4448, 1.4515, 1.4499, 1.4516, 1.4516,
         1.4479, 1.4452, 1.4402, 1.4346, 1.4490, 1.4069, 1.4431, 1.4490, 1.4436,
         1.7522, 1.7434, 1.7414, 1.7499, 1.7681, 1.7665, 1.7464, 1.7683, 1.7683,
         1.4726, 1.4765, 1.5150, 1.5095, 1.4779, 1.5135, 1.5018, 1.5151, 1.5120,
         2.1892, 2.1678, 2.1562, 2.1748, 2.2199, 2.2353, 2.2020, 2.3100, 2.3052,
         1.4414, 1.4330, 1.4472, 1.4577, 1.4443, 1.4544, 1.4236, 1.4516, 1.4577],
        [1.3856, 1.2924, 1.2887, 1.3067, 1.3005, 1.3100, 1.3089, 1.2472, 1.2472,
         1.2877, 1.2457, 1.2445, 1.2496, 1.3300, 1.1999, 1.1584, 1.3300, 1.2289,
         1.6219, 1.5988, 1.5816, 1.5755, 1.5973, 1.5939, 1.6145, 1.5987, 1.5987,
         1.3852, 1.3593, 1.3576, 1.3760, 1.3605, 1.4035, 1.4052, 1.3791, 1.3577,
         1.5829, 1.5842, 1.5878, 1.5777, 1.5558, 1.5597, 1.6199, 1.5114, 1.4812,
         3.8773, 3.5997, 3.6615, 3.6521, 3.6533, 3.4193, 3.8699, 3.6356, 3.4456]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 119 : 1781.327246665731
Test loss for epoch 119 : 194.37087723855643
Test Precision for epoch 119 : 0.26153846153846155
Test Recall for epoch 119 : 0.26153846153846155
Test F1 for epoch 119 : 0.26153846153846155


theta for epoch 120 : tensor([[3.6130, 3.6337, 3.7575, 3.7104, 3.7040, 3.5948, 3.6328, 3.5374, 3.5374,
         1.2687, 1.2484, 1.2471, 1.2499, 1.2884, 1.2289, 1.1997, 1.2885, 1.2351,
         1.5955, 1.5799, 1.6038, 1.5858, 1.5922, 1.5938, 1.6014, 1.5938, 1.5938,
         1.3419, 1.3528, 1.3381, 1.3606, 1.3409, 1.3724, 1.3651, 1.3517, 1.3382,
         1.5848, 1.6012, 1.5899, 1.5864, 1.5933, 1.5836, 1.6020, 1.5551, 1.5599,
         1.2545, 1.2802, 1.2723, 1.2897, 1.2498, 1.2418, 1.2299, 1.3124, 1.2690],
        [1.3701, 1.2216, 1.2117, 1.2537, 1.2542, 1.2662, 1.2601, 1.1675, 1.1675,
         3.6471, 3.6983, 3.6012, 3.8300, 3.6482, 3.9997, 3.5592, 3.6196, 3.8836,
         1.5654, 1.5540, 1.5281, 1.5281, 1.5483, 1.5576, 1.5809, 1.5577, 1.5577,
         1.3444, 1.3121, 1.3058, 1.3620, 1.3053, 1.3984, 1.3792, 1.3488, 1.3026,
         1.5299, 1.5831, 1.5488, 1.5359, 1.5305, 1.5667, 1.5853, 1.4235, 1.5203,
         1.1596, 1.2635, 1.2387, 1.2851, 1.1557, 1.1638, 1.0897, 1.3458, 1.2296],
        [1.4536, 1.4535, 1.4518, 1.4490, 1.4492, 1.4536, 1.4492, 1.4536, 1.4536,
         1.4385, 1.4378, 1.4385, 1.4385, 1.4385, 1.4194, 1.4386, 1.4373, 1.4350,
         2.2013, 2.2020, 2.2189, 2.1945, 2.1755, 2.1738, 2.2029, 2.1728, 2.1728,
         1.5125, 1.5109, 1.5185, 1.5184, 1.5125, 1.5185, 1.5184, 1.5185, 1.5185,
         1.7657, 1.7658, 1.7658, 1.7625, 1.7656, 1.7656, 1.7658, 1.7425, 1.7453,
         1.4495, 1.4544, 1.4544, 1.4544, 1.4459, 1.4544, 1.4501, 1.4543, 1.4544],
        [1.3211, 1.3193, 1.3032, 1.2945, 1.3183, 1.3166, 1.3177, 1.3183, 1.3183,
         1.3041, 1.2975, 1.2936, 1.2930, 1.3049, 1.2891, 1.3007, 1.3044, 1.2766,
         1.6422, 1.6155, 1.6390, 1.6386, 1.6379, 1.6380, 1.6402, 1.6417, 1.6417,
         3.4835, 3.2703, 3.1946, 3.2547, 3.4096, 3.2217, 3.4566, 3.2034, 3.1810,
         1.6386, 1.6311, 1.6293, 1.6325, 1.6355, 1.6115, 1.6367, 1.5760, 1.6026,
         1.3187, 1.3133, 1.3035, 1.3182, 1.3139, 1.3060, 1.3181, 1.3184, 1.3204],
        [1.4564, 1.4516, 1.4074, 1.4118, 1.4496, 1.4563, 1.4547, 1.4564, 1.4564,
         1.4403, 1.4376, 1.4326, 1.4270, 1.4414, 1.3992, 1.4354, 1.4413, 1.4359,
         1.7549, 1.7461, 1.7441, 1.7526, 1.7708, 1.7692, 1.7491, 1.7710, 1.7710,
         1.4787, 1.4826, 1.5211, 1.5156, 1.4840, 1.5196, 1.5079, 1.5212, 1.5181,
         2.1917, 2.1704, 2.1588, 2.1774, 2.2225, 2.2379, 2.2046, 2.3124, 2.3077,
         1.4408, 1.4324, 1.4467, 1.4571, 1.4437, 1.4539, 1.4229, 1.4510, 1.4572],
        [1.3893, 1.2982, 1.2944, 1.3122, 1.3059, 1.3155, 1.3144, 1.2543, 1.2543,
         1.2809, 1.2391, 1.2379, 1.2429, 1.3228, 1.1934, 1.1525, 1.3228, 1.2223,
         1.6253, 1.6023, 1.5849, 1.5794, 1.6011, 1.5977, 1.6180, 1.6025, 1.6025,
         1.3916, 1.3658, 1.3649, 1.3823, 1.3673, 1.4093, 1.4112, 1.3857, 1.3650,
         1.5866, 1.5876, 1.5915, 1.5814, 1.5593, 1.5631, 1.6231, 1.5150, 1.4849,
         3.8760, 3.5962, 3.6584, 3.6490, 3.6503, 3.4148, 3.8687, 3.6323, 3.4412]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 120 : 1781.0841090085748
Test loss for epoch 120 : 194.43835668519154
Test Precision for epoch 120 : 0.26153846153846155
Test Recall for epoch 120 : 0.26153846153846155
Test F1 for epoch 120 : 0.26153846153846155


theta for epoch 121 : tensor([[3.6135, 3.6343, 3.7588, 3.7114, 3.7049, 3.5953, 3.6335, 3.5378, 3.5378,
         1.2595, 1.2385, 1.2372, 1.2402, 1.2797, 1.2189, 1.1884, 1.2797, 1.2251,
         1.5984, 1.5827, 1.6067, 1.5886, 1.5950, 1.5966, 1.6043, 1.5966, 1.5966,
         1.3356, 1.3465, 1.3317, 1.3545, 1.3345, 1.3664, 1.3590, 1.3455, 1.3317,
         1.5922, 1.6086, 1.5973, 1.5938, 1.6007, 1.5910, 1.6094, 1.5625, 1.5673,
         1.2594, 1.2850, 1.2771, 1.2944, 1.2546, 1.2467, 1.2349, 1.3171, 1.2738],
        [1.3571, 1.2060, 1.1963, 1.2385, 1.2390, 1.2511, 1.2450, 1.1505, 1.1505,
         3.6542, 3.7059, 3.6081, 3.8386, 3.6553, 4.0097, 3.5659, 3.6265, 3.8927,
         1.5620, 1.5504, 1.5245, 1.5241, 1.5444, 1.5538, 1.5775, 1.5538, 1.5538,
         1.3305, 1.2979, 1.2909, 1.3482, 1.2908, 1.3853, 1.3657, 1.3348, 1.2877,
         1.5313, 1.5851, 1.5503, 1.5373, 1.5320, 1.5685, 1.5874, 1.4245, 1.5217,
         1.1583, 1.2628, 1.2377, 1.2844, 1.1544, 1.1627, 1.0881, 1.3452, 1.2285],
        [1.4488, 1.4487, 1.4470, 1.4442, 1.4444, 1.4488, 1.4444, 1.4487, 1.4487,
         1.4301, 1.4294, 1.4301, 1.4301, 1.4301, 1.4110, 1.4301, 1.4289, 1.4266,
         2.2046, 2.2053, 2.2222, 2.1977, 2.1786, 2.1770, 2.2061, 2.1759, 2.1759,
         1.5072, 1.5056, 1.5131, 1.5131, 1.5072, 1.5131, 1.5131, 1.5131, 1.5131,
         1.7735, 1.7735, 1.7735, 1.7703, 1.7734, 1.7734, 1.7735, 1.7503, 1.7531,
         1.4543, 1.4592, 1.4592, 1.4592, 1.4507, 1.4592, 1.4549, 1.4592, 1.4592],
        [1.3159, 1.3141, 1.2980, 1.2893, 1.3131, 1.3114, 1.3125, 1.3131, 1.3131,
         1.2957, 1.2890, 1.2852, 1.2846, 1.2965, 1.2806, 1.2922, 1.2961, 1.2682,
         1.6458, 1.6191, 1.6427, 1.6422, 1.6416, 1.6416, 1.6438, 1.6453, 1.6453,
         3.4791, 3.2659, 3.1902, 3.2502, 3.4051, 3.2173, 3.4522, 3.1990, 3.1766,
         1.6465, 1.6390, 1.6372, 1.6404, 1.6434, 1.6194, 1.6446, 1.5839, 1.6105,
         1.3237, 1.3183, 1.3085, 1.3232, 1.3189, 1.3110, 1.3231, 1.3234, 1.3254],
        [1.4516, 1.4468, 1.4026, 1.4070, 1.4448, 1.4515, 1.4499, 1.4516, 1.4516,
         1.4319, 1.4291, 1.4242, 1.4186, 1.4330, 1.3908, 1.4270, 1.4329, 1.4275,
         1.7584, 1.7496, 1.7476, 1.7560, 1.7743, 1.7727, 1.7526, 1.7744, 1.7744,
         1.4733, 1.4773, 1.5158, 1.5102, 1.4786, 1.5143, 1.5025, 1.5158, 1.5127,
         2.1995, 2.1782, 2.1666, 2.1852, 2.2302, 2.2457, 2.2124, 2.3200, 2.3153,
         1.4456, 1.4373, 1.4515, 1.4620, 1.4485, 1.4587, 1.4277, 1.4559, 1.4620],
        [1.3796, 1.2913, 1.2871, 1.3047, 1.2985, 1.3080, 1.3069, 1.2489, 1.2489,
         1.2717, 1.2301, 1.2288, 1.2338, 1.3133, 1.1846, 1.1441, 1.3133, 1.2134,
         1.6274, 1.6046, 1.5869, 1.5820, 1.6037, 1.6003, 1.6202, 1.6051, 1.6051,
         1.3833, 1.3577, 1.3577, 1.3739, 1.3594, 1.4002, 1.4024, 1.3775, 1.3578,
         1.5942, 1.5948, 1.5991, 1.5890, 1.5667, 1.5703, 1.6302, 1.5225, 1.4922,
         3.8822, 3.6003, 3.6629, 3.6534, 3.6548, 3.4179, 3.8749, 3.6366, 3.4445]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 121 : 1780.2471882180625
Test loss for epoch 121 : 194.82336947913444
Test Precision for epoch 121 : 0.26153846153846155
Test Recall for epoch 121 : 0.26153846153846155
Test F1 for epoch 121 : 0.26153846153846155


theta for epoch 122 : tensor([[3.6167, 3.6377, 3.7627, 3.7150, 3.7085, 3.5985, 3.6368, 3.5410, 3.5410,
         1.2524, 1.2307, 1.2293, 1.2326, 1.2732, 1.2109, 1.1788, 1.2733, 1.2170,
         1.5971, 1.5813, 1.6054, 1.5871, 1.5935, 1.5951, 1.6030, 1.5951, 1.5951,
         1.3299, 1.3408, 1.3258, 1.3489, 1.3287, 1.3610, 1.3535, 1.3398, 1.3258,
         1.5985, 1.6150, 1.6036, 1.6001, 1.6070, 1.5973, 1.6158, 1.5687, 1.5736,
         1.2629, 1.2886, 1.2806, 1.2980, 1.2582, 1.2503, 1.2385, 1.3204, 1.2773],
        [1.3416, 1.1871, 1.1776, 1.2201, 1.2206, 1.2328, 1.2267, 1.1298, 1.1298,
         3.6666, 3.7187, 3.6202, 3.8523, 3.6676, 4.0249, 3.5779, 3.6386, 3.9069,
         1.5531, 1.5412, 1.5154, 1.5144, 1.5348, 1.5443, 1.5686, 1.5443, 1.5443,
         1.3139, 1.2811, 1.2731, 1.3319, 1.2737, 1.3698, 1.3498, 1.3181, 1.2699,
         1.5298, 1.5843, 1.5489, 1.5359, 1.5306, 1.5675, 1.5868, 1.4224, 1.5202,
         1.1539, 1.2593, 1.2338, 1.2810, 1.1500, 1.1583, 1.0833, 1.3421, 1.2245],
        [1.4453, 1.4452, 1.4435, 1.4407, 1.4409, 1.4453, 1.4409, 1.4453, 1.4453,
         1.4244, 1.4236, 1.4243, 1.4243, 1.4243, 1.4052, 1.4244, 1.4231, 1.4208,
         2.2043, 2.2051, 2.2220, 2.1975, 2.1784, 2.1768, 2.2059, 2.1757, 2.1757,
         1.5032, 1.5016, 1.5091, 1.5091, 1.5032, 1.5091, 1.5091, 1.5091, 1.5091,
         1.7804, 1.7805, 1.7805, 1.7772, 1.7804, 1.7804, 1.7805, 1.7572, 1.7601,
         1.4582, 1.4631, 1.4631, 1.4631, 1.4546, 1.4631, 1.4587, 1.4631, 1.4631],
        [1.3121, 1.3103, 1.2942, 1.2855, 1.3093, 1.3076, 1.3087, 1.3093, 1.3093,
         1.2900, 1.2833, 1.2794, 1.2788, 1.2908, 1.2748, 1.2864, 1.2904, 1.2624,
         1.6456, 1.6189, 1.6425, 1.6420, 1.6414, 1.6414, 1.6436, 1.6451, 1.6451,
         3.4757, 3.2626, 3.1869, 3.2470, 3.4017, 3.2141, 3.4488, 3.1957, 3.1734,
         1.6536, 1.6460, 1.6443, 1.6475, 1.6505, 1.6265, 1.6517, 1.5910, 1.6176,
         1.3277, 1.3223, 1.3125, 1.3272, 1.3229, 1.3150, 1.3271, 1.3275, 1.3294],
        [1.4481, 1.4433, 1.3991, 1.4035, 1.4414, 1.4480, 1.4464, 1.4481, 1.4481,
         1.4261, 1.4234, 1.4184, 1.4128, 1.4272, 1.3850, 1.4212, 1.4272, 1.4218,
         1.7581, 1.7493, 1.7473, 1.7557, 1.7740, 1.7724, 1.7523, 1.7742, 1.7742,
         1.4694, 1.4734, 1.5118, 1.5062, 1.4747, 1.5103, 1.4986, 1.5119, 1.5087,
         2.2065, 2.1852, 2.1736, 2.1921, 2.2371, 2.2527, 2.2193, 2.3268, 2.3222,
         1.4494, 1.4411, 1.4554, 1.4659, 1.4524, 1.4626, 1.4315, 1.4598, 1.4659],
        [1.3669, 1.2816, 1.2771, 1.2945, 1.2882, 1.2977, 1.2966, 1.2411, 1.2411,
         1.2635, 1.2219, 1.2207, 1.2257, 1.3049, 1.1765, 1.1363, 1.3049, 1.2053,
         1.6240, 1.6014, 1.5834, 1.5792, 1.6009, 1.5975, 1.6168, 1.6023, 1.6023,
         1.3726, 1.3471, 1.3483, 1.3629, 1.3492, 1.3885, 1.3912, 1.3670, 1.3484,
         1.5996, 1.5997, 1.6045, 1.5944, 1.5718, 1.5752, 1.6349, 1.5277, 1.4973,
         3.8923, 3.6084, 3.6714, 3.6618, 3.6633, 3.4250, 3.8850, 3.6448, 3.4518]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 122 : 1780.1619044650843
Test loss for epoch 122 : 195.6170882361826
Test Precision for epoch 122 : 0.26153846153846155
Test Recall for epoch 122 : 0.26153846153846155
Test F1 for epoch 122 : 0.26153846153846155


theta for epoch 123 : tensor([[3.6268, 3.6481, 3.7735, 3.7257, 3.7191, 3.6088, 3.6472, 3.5514, 3.5514,
         1.2490, 1.2263, 1.2249, 1.2285, 1.2705, 1.2071, 1.1723, 1.2705, 1.2124,
         1.5933, 1.5775, 1.6016, 1.5832, 1.5896, 1.5912, 1.5991, 1.5912, 1.5912,
         1.3356, 1.3465, 1.3314, 1.3547, 1.3344, 1.3669, 1.3593, 1.3455, 1.3314,
         1.5973, 1.6138, 1.6024, 1.5989, 1.6059, 1.5962, 1.6147, 1.5675, 1.5723,
         1.2593, 1.2850, 1.2770, 1.2943, 1.2546, 1.2468, 1.2350, 1.3166, 1.2737],
        [1.3373, 1.1786, 1.1695, 1.2124, 1.2129, 1.2251, 1.2190, 1.1192, 1.1192,
         3.6777, 3.7302, 3.6310, 3.8648, 3.6786, 4.0386, 3.5886, 3.6494, 3.9198,
         1.5440, 1.5319, 1.5063, 1.5045, 1.5250, 1.5346, 1.5595, 1.5346, 1.5346,
         1.3088, 1.2756, 1.2665, 1.3271, 1.2678, 1.3660, 1.3455, 1.3128, 1.2634,
         1.5230, 1.5782, 1.5422, 1.5291, 1.5240, 1.5612, 1.5809, 1.4152, 1.5134,
         1.1458, 1.2522, 1.2263, 1.2740, 1.1419, 1.1501, 1.0749, 1.3354, 1.2169],
        [1.4522, 1.4521, 1.4504, 1.4476, 1.4478, 1.4522, 1.4478, 1.4522, 1.4522,
         1.4225, 1.4217, 1.4224, 1.4224, 1.4224, 1.4033, 1.4225, 1.4212, 1.4189,
         2.2020, 2.2028, 2.2197, 2.1953, 2.1762, 2.1746, 2.2037, 2.1735, 2.1735,
         1.5106, 1.5090, 1.5165, 1.5165, 1.5106, 1.5165, 1.5165, 1.5165, 1.5165,
         1.7802, 1.7803, 1.7803, 1.7770, 1.7802, 1.7802, 1.7803, 1.7570, 1.7598,
         1.4551, 1.4600, 1.4600, 1.4600, 1.4515, 1.4601, 1.4556, 1.4600, 1.4600],
        [1.3189, 1.3171, 1.3010, 1.2924, 1.3161, 1.3144, 1.3155, 1.3162, 1.3162,
         1.2881, 1.2813, 1.2775, 1.2769, 1.2889, 1.2729, 1.2844, 1.2885, 1.2605,
         1.6432, 1.6165, 1.6401, 1.6396, 1.6390, 1.6390, 1.6412, 1.6427, 1.6427,
         3.4815, 3.2685, 3.1930, 3.2529, 3.4074, 3.2201, 3.4545, 3.2018, 3.1795,
         1.6534, 1.6459, 1.6441, 1.6473, 1.6503, 1.6263, 1.6515, 1.5908, 1.6174,
         1.3247, 1.3193, 1.3095, 1.3242, 1.3199, 1.3120, 1.3240, 1.3244, 1.3264],
        [1.4550, 1.4502, 1.4061, 1.4105, 1.4483, 1.4549, 1.4533, 1.4550, 1.4550,
         1.4242, 1.4215, 1.4165, 1.4109, 1.4253, 1.3830, 1.4194, 1.4253, 1.4199,
         1.7557, 1.7469, 1.7448, 1.7533, 1.7716, 1.7700, 1.7499, 1.7718, 1.7718,
         1.4768, 1.4808, 1.5192, 1.5136, 1.4821, 1.5177, 1.5060, 1.5193, 1.5161,
         2.2064, 2.1853, 2.1736, 2.1922, 2.2371, 2.2527, 2.2193, 2.3267, 2.3222,
         1.4463, 1.4381, 1.4523, 1.4628, 1.4492, 1.4595, 1.4283, 1.4567, 1.4629],
        [1.3600, 1.2782, 1.2732, 1.2904, 1.2841, 1.2936, 1.2926, 1.2397, 1.2397,
         1.2577, 1.2161, 1.2148, 1.2200, 1.2989, 1.1716, 1.1307, 1.2990, 1.1995,
         1.6171, 1.5945, 1.5763, 1.5729, 1.5945, 1.5912, 1.6099, 1.5959, 1.5959,
         1.3696, 1.3442, 1.3468, 1.3597, 1.3467, 1.3844, 1.3876, 1.3641, 1.3468,
         1.5969, 1.5963, 1.6017, 1.5916, 1.5688, 1.5719, 1.6315, 1.5247, 1.4941,
         3.9024, 3.6163, 3.6797, 3.6701, 3.6717, 3.4321, 3.8950, 3.6529, 3.4590]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 123 : 1779.3319531294717
Test loss for epoch 123 : 196.1654305063144
Test Precision for epoch 123 : 0.26153846153846155
Test Recall for epoch 123 : 0.26153846153846155
Test F1 for epoch 123 : 0.26153846153846155


theta for epoch 124 : tensor([[3.6320, 3.6535, 3.7794, 3.7314, 3.7247, 3.6141, 3.6525, 3.5566, 3.5566,
         1.2501, 1.2269, 1.2254, 1.2292, 1.2720, 1.2082, 1.1716, 1.2720, 1.2128,
         1.5928, 1.5770, 1.6011, 1.5826, 1.5891, 1.5907, 1.5986, 1.5906, 1.5906,
         1.3481, 1.3590, 1.3438, 1.3672, 1.3468, 1.3794, 1.3718, 1.3580, 1.3438,
         1.5919, 1.6084, 1.5970, 1.5934, 1.6004, 1.5907, 1.6093, 1.5620, 1.5669,
         1.2527, 1.2783, 1.2703, 1.2876, 1.2482, 1.2404, 1.2286, 1.3096, 1.2671],
        [1.3726, 1.2123, 1.2035, 1.2463, 1.2468, 1.2589, 1.2528, 1.1515, 1.1515,
         3.6505, 3.7034, 3.6035, 3.8390, 3.6514, 4.0141, 3.5609, 3.6220, 3.8945,
         1.5603, 1.5482, 1.5230, 1.5206, 1.5409, 1.5503, 1.5756, 1.5503, 1.5503,
         1.3435, 1.3102, 1.3004, 1.3618, 1.3022, 1.4011, 1.3804, 1.3473, 1.2972,
         1.5322, 1.5873, 1.5512, 1.5383, 1.5333, 1.5704, 1.5902, 1.4257, 1.5228,
         1.1598, 1.2658, 1.2399, 1.2875, 1.1557, 1.1637, 1.0892, 1.3484, 1.2305],
        [1.4608, 1.4607, 1.4591, 1.4563, 1.4564, 1.4608, 1.4565, 1.4608, 1.4608,
         1.4241, 1.4234, 1.4241, 1.4240, 1.4241, 1.4049, 1.4241, 1.4228, 1.4205,
         2.2016, 2.2024, 2.2193, 2.1950, 2.1759, 2.1743, 2.2033, 2.1731, 2.1731,
         1.5223, 1.5207, 1.5282, 1.5282, 1.5223, 1.5282, 1.5282, 1.5282, 1.5282,
         1.7749, 1.7750, 1.7750, 1.7717, 1.7749, 1.7749, 1.7750, 1.7516, 1.7545,
         1.4477, 1.4527, 1.4527, 1.4527, 1.4441, 1.4527, 1.4482, 1.4526, 1.4527],
        [1.3275, 1.3258, 1.3097, 1.3011, 1.3247, 1.3231, 1.3242, 1.3249, 1.3249,
         1.2897, 1.2829, 1.2791, 1.2786, 1.2906, 1.2746, 1.2860, 1.2901, 1.2621,
         1.6428, 1.6162, 1.6397, 1.6392, 1.6386, 1.6386, 1.6409, 1.6423, 1.6423,
         3.4906, 3.2779, 3.2027, 3.2623, 3.4166, 3.2296, 3.4636, 3.2113, 3.1892,
         1.6480, 1.6405, 1.6388, 1.6420, 1.6450, 1.6210, 1.6462, 1.5855, 1.6121,
         1.3173, 1.3119, 1.3021, 1.3168, 1.3125, 1.3046, 1.3166, 1.3170, 1.3190],
        [1.4636, 1.4588, 1.4148, 1.4192, 1.4570, 1.4635, 1.4619, 1.4636, 1.4636,
         1.4259, 1.4231, 1.4182, 1.4125, 1.4269, 1.3847, 1.4210, 1.4269, 1.4215,
         1.7553, 1.7465, 1.7444, 1.7529, 1.7713, 1.7696, 1.7495, 1.7714, 1.7714,
         1.4886, 1.4927, 1.5309, 1.5253, 1.4939, 1.5293, 1.5177, 1.5310, 1.5278,
         2.2015, 2.1803, 2.1687, 2.1872, 2.2322, 2.2478, 2.2143, 2.3218, 2.3173,
         1.4388, 1.4306, 1.4449, 1.4555, 1.4418, 1.4522, 1.4208, 1.4493, 1.4555],
        [1.3550, 1.2771, 1.2717, 1.2886, 1.2823, 1.2918, 1.2907, 1.2410, 1.2410,
         1.2556, 1.2145, 1.2132, 1.2182, 1.2963, 1.1707, 1.1301, 1.2963, 1.1980,
         1.6124, 1.5901, 1.5715, 1.5690, 1.5907, 1.5873, 1.6054, 1.5921, 1.5921,
         1.3711, 1.3457, 1.3499, 1.3608, 1.3488, 1.3847, 1.3884, 1.3658, 1.3499,
         1.5893, 1.5881, 1.5941, 1.5840, 1.5609, 1.5638, 1.6231, 1.5170, 1.4862,
         3.9093, 3.6212, 3.6850, 3.6753, 3.6770, 3.4361, 3.9020, 3.6579, 3.4631]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 124 : 1780.8272441154472
Test loss for epoch 124 : 194.57423627091657
Test Precision for epoch 124 : 0.26153846153846155
Test Recall for epoch 124 : 0.26153846153846155
Test F1 for epoch 124 : 0.26153846153846155


theta for epoch 125 : tensor([[3.6296, 3.6512, 3.7776, 3.7294, 3.7226, 3.6116, 3.6502, 3.5540, 3.5540,
         1.2584, 1.2345, 1.2330, 1.2370, 1.2807, 1.2163, 1.1777, 1.2807, 1.2202,
         1.5959, 1.5801, 1.6042, 1.5856, 1.5921, 1.5937, 1.6017, 1.5937, 1.5937,
         1.3408, 1.3518, 1.3365, 1.3600, 1.3396, 1.3724, 1.3646, 1.3508, 1.3365,
         1.5880, 1.6047, 1.5932, 1.5896, 1.5967, 1.5870, 1.6056, 1.5582, 1.5630,
         1.2486, 1.2742, 1.2662, 1.2834, 1.2440, 1.2363, 1.2245, 1.3053, 1.2630],
        [1.3890, 1.2271, 1.2187, 1.2614, 1.2619, 1.2739, 1.2679, 1.1652, 1.1652,
         3.6346, 3.6878, 3.5873, 3.8244, 3.6355, 4.0008, 3.5445, 3.6059, 3.8803,
         1.5749, 1.5626, 1.5380, 1.5348, 1.5550, 1.5643, 1.5900, 1.5644, 1.5644,
         1.3578, 1.3247, 1.3140, 1.3762, 1.3165, 1.4157, 1.3949, 1.3615, 1.3109,
         1.5387, 1.5940, 1.5576, 1.5448, 1.5401, 1.5771, 1.5970, 1.4332, 1.5295,
         1.1704, 1.2766, 1.2505, 1.2982, 1.1662, 1.1739, 1.1000, 1.3589, 1.2410],
        [1.4534, 1.4533, 1.4517, 1.4489, 1.4490, 1.4534, 1.4490, 1.4534, 1.4534,
         1.4331, 1.4323, 1.4331, 1.4330, 1.4331, 1.4139, 1.4331, 1.4318, 1.4295,
         2.2047, 2.2055, 2.2225, 2.1980, 2.1788, 2.1773, 2.2063, 2.1761, 2.1761,
         1.5154, 1.5138, 1.5213, 1.5213, 1.5154, 1.5213, 1.5213, 1.5213, 1.5213,
         1.7714, 1.7715, 1.7715, 1.7682, 1.7714, 1.7714, 1.7715, 1.7481, 1.7509,
         1.4430, 1.4480, 1.4480, 1.4480, 1.4394, 1.4480, 1.4435, 1.4480, 1.4480],
        [1.3198, 1.3180, 1.3019, 1.2933, 1.3170, 1.3153, 1.3165, 1.3171, 1.3171,
         1.2987, 1.2919, 1.2881, 1.2876, 1.2996, 1.2836, 1.2949, 1.2992, 1.2711,
         1.6463, 1.6196, 1.6431, 1.6426, 1.6420, 1.6421, 1.6443, 1.6458, 1.6458,
         3.4853, 3.2727, 3.1975, 3.2571, 3.4113, 3.2245, 3.4584, 3.2062, 3.1840,
         1.6445, 1.6370, 1.6352, 1.6385, 1.6414, 1.6174, 1.6427, 1.5819, 1.6086,
         1.3126, 1.3072, 1.2974, 1.3121, 1.3078, 1.3000, 1.3120, 1.3124, 1.3143],
        [1.4562, 1.4514, 1.4073, 1.4118, 1.4496, 1.4561, 1.4545, 1.4562, 1.4562,
         1.4348, 1.4321, 1.4271, 1.4215, 1.4359, 1.3936, 1.4300, 1.4359, 1.4305,
         1.7587, 1.7499, 1.7477, 1.7562, 1.7746, 1.7730, 1.7529, 1.7748, 1.7748,
         1.4817, 1.4857, 1.5240, 1.5184, 1.4870, 1.5225, 1.5108, 1.5241, 1.5209,
         2.1982, 2.1771, 2.1655, 2.1840, 2.2290, 2.2447, 2.2111, 2.3185, 2.3141,
         1.4341, 1.4260, 1.4402, 1.4508, 1.4371, 1.4475, 1.4160, 1.4446, 1.4508],
        [1.3337, 1.2595, 1.2536, 1.2703, 1.2640, 1.2735, 1.2724, 1.2255, 1.2255,
         1.2595, 1.2187, 1.2174, 1.2224, 1.2999, 1.1755, 1.1350, 1.2999, 1.2023,
         1.6103, 1.5881, 1.5692, 1.5675, 1.5892, 1.5859, 1.6033, 1.5906, 1.5906,
         1.3534, 1.3282, 1.3337, 1.3429, 1.3317, 1.3659, 1.3702, 1.3483, 1.3338,
         1.5825, 1.5807, 1.5873, 1.5772, 1.5539, 1.5564, 1.6156, 1.5100, 1.4790,
         3.9207, 3.6307, 3.6949, 3.6850, 3.6869, 3.4448, 3.9134, 3.6675, 3.4718]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 125 : 1780.666767428271
Test loss for epoch 125 : 194.27326354220367
Test Precision for epoch 125 : 0.26153846153846155
Test Recall for epoch 125 : 0.26153846153846155
Test F1 for epoch 125 : 0.26153846153846155


theta for epoch 126 : tensor([[3.6248, 3.6464, 3.7734, 3.7249, 3.7181, 3.6067, 3.6454, 3.5489, 3.5489,
         1.2705, 1.2460, 1.2444, 1.2487, 1.2934, 1.2280, 1.1874, 1.2934, 1.2314,
         1.5968, 1.5808, 1.6051, 1.5862, 1.5928, 1.5944, 1.6025, 1.5944, 1.5944,
         1.3260, 1.3369, 1.3214, 1.3452, 1.3246, 1.3578, 1.3499, 1.3359, 1.3214,
         1.5865, 1.6033, 1.5916, 1.5881, 1.5952, 1.5855, 1.6042, 1.5567, 1.5615,
         1.2446, 1.2705, 1.2624, 1.2797, 1.2401, 1.2323, 1.2205, 1.3016, 1.2592],
        [1.3936, 1.2306, 1.2226, 1.2650, 1.2655, 1.2774, 1.2714, 1.1678, 1.1678,
         3.6280, 3.6817, 3.5805, 3.8192, 3.6289, 3.9968, 3.5376, 3.5991, 3.8755,
         1.5830, 1.5706, 1.5462, 1.5425, 1.5626, 1.5719, 1.5979, 1.5719, 1.5719,
         1.3599, 1.3269, 1.3155, 1.3782, 1.3185, 1.4180, 1.3970, 1.3634, 1.3124,
         1.5435, 1.5989, 1.5623, 1.5495, 1.5449, 1.5820, 1.6021, 1.4385, 1.5343,
         1.1761, 1.2826, 1.2564, 1.3042, 1.1717, 1.1793, 1.1057, 1.3649, 1.2469],
        [1.4408, 1.4407, 1.4391, 1.4363, 1.4364, 1.4408, 1.4365, 1.4408, 1.4408,
         1.4459, 1.4451, 1.4458, 1.4458, 1.4459, 1.4267, 1.4459, 1.4446, 1.4423,
         2.2058, 2.2066, 2.2236, 2.1991, 2.1799, 2.1783, 2.2074, 2.1772, 2.1772,
         1.5013, 1.4997, 1.5072, 1.5072, 1.5013, 1.5072, 1.5072, 1.5072, 1.5072,
         1.7702, 1.7703, 1.7703, 1.7671, 1.7702, 1.7702, 1.7703, 1.7469, 1.7498,
         1.4389, 1.4440, 1.4440, 1.4440, 1.4354, 1.4440, 1.4394, 1.4439, 1.4440],
        [1.3068, 1.3051, 1.2890, 1.2804, 1.3040, 1.3024, 1.3035, 1.3041, 1.3041,
         1.3116, 1.3048, 1.3009, 1.3004, 1.3124, 1.2964, 1.3077, 1.3120, 1.2839,
         1.6475, 1.6209, 1.6444, 1.6439, 1.6433, 1.6433, 1.6456, 1.6470, 1.6470,
         3.4744, 3.2617, 3.1863, 3.2461, 3.4002, 3.2135, 3.4475, 3.1951, 3.1729,
         1.6434, 1.6359, 1.6341, 1.6374, 1.6403, 1.6163, 1.6416, 1.5808, 1.6075,
         1.3086, 1.3032, 1.2934, 1.3081, 1.3038, 1.2959, 1.3079, 1.3083, 1.3103],
        [1.4437, 1.4388, 1.3945, 1.3991, 1.4370, 1.4436, 1.4419, 1.4436, 1.4436,
         1.4476, 1.4449, 1.4399, 1.4343, 1.4487, 1.4064, 1.4427, 1.4486, 1.4433,
         1.7599, 1.7511, 1.7489, 1.7574, 1.7758, 1.7742, 1.7541, 1.7760, 1.7760,
         1.4675, 1.4716, 1.5099, 1.5042, 1.4728, 1.5084, 1.4967, 1.5100, 1.5068,
         2.1973, 2.1762, 2.1645, 2.1830, 2.2280, 2.2438, 2.2102, 2.3176, 2.3132,
         1.4299, 1.4219, 1.4361, 1.4468, 1.4329, 1.4435, 1.4118, 1.4406, 1.4468],
        [1.3069, 1.2353, 1.2291, 1.2456, 1.2392, 1.2488, 1.2477, 1.2029, 1.2029,
         1.2665, 1.2257, 1.2243, 1.2294, 1.3066, 1.1829, 1.1422, 1.3066, 1.2093,
         1.6051, 1.5830, 1.5637, 1.5628, 1.5846, 1.5812, 1.5981, 1.5860, 1.5860,
         1.3277, 1.3026, 1.3092, 1.3170, 1.3065, 1.3394, 1.3440, 1.3228, 1.3093,
         1.5773, 1.5749, 1.5821, 1.5719, 1.5483, 1.5506, 1.6097, 1.5044, 1.4732,
         3.9350, 3.6429, 3.7075, 3.6975, 3.6995, 3.4562, 3.9277, 3.6799, 3.4833]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 126 : 1780.9911616487755
Test loss for epoch 126 : 194.67683003630555
Test Precision for epoch 126 : 0.26153846153846155
Test Recall for epoch 126 : 0.26153846153846155
Test F1 for epoch 126 : 0.26153846153846155


theta for epoch 127 : tensor([[3.6278, 3.6496, 3.7771, 3.7284, 3.7215, 3.6097, 3.6485, 3.5519, 3.5519,
         1.2773, 1.2521, 1.2505, 1.2550, 1.3007, 1.2344, 1.1919, 1.3007, 1.2373,
         1.5911, 1.5751, 1.5995, 1.5804, 1.5869, 1.5885, 1.5969, 1.5885, 1.5885,
         1.3249, 1.3358, 1.3200, 1.3442, 1.3234, 1.3570, 1.3490, 1.3348, 1.3200,
         1.5861, 1.6030, 1.5912, 1.5877, 1.5948, 1.5852, 1.6040, 1.5563, 1.5611,
         1.2376, 1.2638, 1.2556, 1.2731, 1.2329, 1.2250, 1.2133, 1.2951, 1.2523],
        [1.3992, 1.2350, 1.2271, 1.2696, 1.2701, 1.2820, 1.2760, 1.1714, 1.1714,
         3.6264, 3.6805, 3.5787, 3.8189, 3.6273, 3.9978, 3.5356, 3.5974, 3.8757,
         1.5816, 1.5691, 1.5449, 1.5408, 1.5608, 1.5701, 1.5964, 1.5701, 1.5701,
         1.3642, 1.3312, 1.3194, 1.3825, 1.3227, 1.4226, 1.4015, 1.3676, 1.3163,
         1.5457, 1.6013, 1.5644, 1.5517, 1.5472, 1.5843, 1.6046, 1.4410, 1.5366,
         1.1747, 1.2818, 1.2553, 1.3033, 1.1702, 1.1775, 1.1042, 1.3640, 1.2457],
        [1.4414, 1.4413, 1.4397, 1.4369, 1.4370, 1.4414, 1.4371, 1.4414, 1.4414,
         1.4533, 1.4526, 1.4533, 1.4533, 1.4533, 1.4342, 1.4533, 1.4521, 1.4497,
         2.2010, 2.2019, 2.2188, 2.1946, 2.1753, 2.1738, 2.2029, 2.1726, 2.1726,
         1.5007, 1.4991, 1.5066, 1.5066, 1.5007, 1.5066, 1.5066, 1.5066, 1.5066,
         1.7703, 1.7704, 1.7704, 1.7672, 1.7703, 1.7703, 1.7704, 1.7470, 1.7499,
         1.4323, 1.4374, 1.4374, 1.4374, 1.4287, 1.4374, 1.4328, 1.4374, 1.4374],
        [1.3074, 1.3057, 1.2896, 1.2810, 1.3046, 1.3030, 1.3041, 1.3047, 1.3047,
         1.3190, 1.3122, 1.3084, 1.3079, 1.3199, 1.3039, 1.3151, 1.3195, 1.2914,
         1.6425, 1.6158, 1.6394, 1.6389, 1.6383, 1.6383, 1.6405, 1.6420, 1.6420,
         3.4739, 3.2614, 3.1861, 3.2458, 3.3997, 3.2133, 3.4470, 3.1949, 3.1727,
         1.6435, 1.6360, 1.6343, 1.6375, 1.6405, 1.6164, 1.6417, 1.5809, 1.6076,
         1.3019, 1.2966, 1.2867, 1.3015, 1.2972, 1.2893, 1.3013, 1.3017, 1.3037],
        [1.4443, 1.4394, 1.3952, 1.3997, 1.4376, 1.4442, 1.4425, 1.4442, 1.4442,
         1.4550, 1.4523, 1.4474, 1.4417, 1.4561, 1.4138, 1.4502, 1.4561, 1.4507,
         1.7549, 1.7462, 1.7439, 1.7524, 1.7709, 1.7692, 1.7492, 1.7711, 1.7711,
         1.4669, 1.4710, 1.5093, 1.5036, 1.4722, 1.5077, 1.4961, 1.5094, 1.5062,
         2.1975, 2.1765, 2.1648, 2.1833, 2.2283, 2.2441, 2.2104, 2.3178, 2.3135,
         1.4233, 1.4153, 1.4295, 1.4402, 1.4263, 1.4369, 1.4051, 1.4340, 1.4402],
        [1.2919, 1.2212, 1.2148, 1.2314, 1.2250, 1.2345, 1.2335, 1.1895, 1.1895,
         1.2679, 1.2271, 1.2257, 1.2308, 1.3080, 1.1846, 1.1434, 1.3080, 1.2107,
         1.5930, 1.5710, 1.5515, 1.5511, 1.5730, 1.5696, 1.5861, 1.5744, 1.5744,
         1.3139, 1.2887, 1.2960, 1.3030, 1.2928, 1.3251, 1.3300, 1.3090, 1.2961,
         1.5725, 1.5697, 1.5773, 1.5671, 1.5433, 1.5454, 1.6045, 1.4993, 1.4678,
         3.9498, 3.6557, 3.7207, 3.7106, 3.7128, 3.4682, 3.9425, 3.6928, 3.4954]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 127 : 1781.247543384255
Test loss for epoch 127 : 195.20796120759059
Test Precision for epoch 127 : 0.26153846153846155
Test Recall for epoch 127 : 0.26153846153846155
Test F1 for epoch 127 : 0.26153846153846155


theta for epoch 128 : tensor([[3.6385, 3.6606, 3.7885, 3.7396, 3.7327, 3.6207, 3.6595, 3.5630, 3.5630,
         1.2727, 1.2468, 1.2452, 1.2498, 1.2965, 1.2293, 1.1852, 1.2965, 1.2319,
         1.5859, 1.5698, 1.5943, 1.5749, 1.5815, 1.5831, 1.5916, 1.5831, 1.5831,
         1.3381, 1.3489, 1.3328, 1.3575, 1.3364, 1.3704, 1.3624, 1.3480, 1.3328,
         1.5866, 1.6037, 1.5917, 1.5882, 1.5954, 1.5858, 1.6047, 1.5568, 1.5616,
         1.2300, 1.2568, 1.2484, 1.2662, 1.2253, 1.2172, 1.2055, 1.2886, 1.2450],
        [1.4056, 1.2406, 1.2327, 1.2753, 1.2759, 1.2878, 1.2818, 1.1765, 1.1765,
         3.6267, 3.6811, 3.5787, 3.8205, 3.6276, 4.0006, 3.5355, 3.5974, 3.8777,
         1.5767, 1.5641, 1.5401, 1.5357, 1.5557, 1.5650, 1.5915, 1.5651, 1.5651,
         1.3719, 1.3387, 1.3269, 1.3903, 1.3302, 1.4305, 1.4094, 1.3753, 1.3238,
         1.5456, 1.6014, 1.5643, 1.5516, 1.5472, 1.5844, 1.6048, 1.4408, 1.5365,
         1.1688, 1.2765, 1.2498, 1.2980, 1.1642, 1.1713, 1.0981, 1.3587, 1.2401],
        [1.4543, 1.4542, 1.4526, 1.4498, 1.4499, 1.4543, 1.4499, 1.4543, 1.4543,
         1.4493, 1.4486, 1.4493, 1.4492, 1.4493, 1.4301, 1.4493, 1.4481, 1.4457,
         2.1968, 2.1977, 2.2147, 2.1907, 2.1713, 2.1698, 2.1989, 2.1686, 2.1686,
         1.5142, 1.5126, 1.5201, 1.5201, 1.5142, 1.5201, 1.5200, 1.5201, 1.5201,
         1.7715, 1.7716, 1.7716, 1.7683, 1.7715, 1.7715, 1.7716, 1.7481, 1.7510,
         1.4260, 1.4311, 1.4310, 1.4311, 1.4224, 1.4310, 1.4265, 1.4310, 1.4311],
        [1.3206, 1.3188, 1.3027, 1.2942, 1.3178, 1.3161, 1.3173, 1.3179, 1.3179,
         1.3150, 1.3082, 1.3043, 1.3038, 1.3159, 1.2999, 1.3110, 1.3155, 1.2873,
         1.6380, 1.6114, 1.6349, 1.6344, 1.6338, 1.6338, 1.6361, 1.6375, 1.6375,
         3.4847, 3.2724, 3.1974, 3.2569, 3.4105, 3.2244, 3.4577, 3.2061, 3.1840,
         1.6447, 1.6372, 1.6355, 1.6387, 1.6416, 1.6176, 1.6429, 1.5821, 1.6088,
         1.2955, 1.2902, 1.2803, 1.2951, 1.2908, 1.2829, 1.2949, 1.2953, 1.2973],
        [1.4571, 1.4523, 1.4082, 1.4127, 1.4505, 1.4570, 1.4554, 1.4571, 1.4571,
         1.4510, 1.4483, 1.4434, 1.4377, 1.4521, 1.4098, 1.4462, 1.4521, 1.4467,
         1.7506, 1.7418, 1.7395, 1.7481, 1.7666, 1.7649, 1.7448, 1.7667, 1.7667,
         1.4805, 1.4846, 1.5228, 1.5171, 1.4858, 1.5212, 1.5096, 1.5228, 1.5197,
         2.1988, 2.1777, 2.1661, 2.1845, 2.2296, 2.2454, 2.2117, 2.3190, 2.3148,
         1.4169, 1.4090, 1.4232, 1.4339, 1.4199, 1.4305, 1.3987, 1.4276, 1.4339],
        [1.2888, 1.2172, 1.2108, 1.2275, 1.2210, 1.2307, 1.2296, 1.1851, 1.1851,
         1.2583, 1.2172, 1.2158, 1.2210, 1.2984, 1.1750, 1.1333, 1.2984, 1.2007,
         1.5811, 1.5590, 1.5394, 1.5393, 1.5612, 1.5578, 1.5742, 1.5626, 1.5626,
         1.3131, 1.2877, 1.2952, 1.3020, 1.2919, 1.3243, 1.3293, 1.3082, 1.2953,
         1.5682, 1.5651, 1.5730, 1.5627, 1.5387, 1.5407, 1.5999, 1.4945, 1.4629,
         3.9661, 3.6700, 3.7353, 3.7252, 3.7275, 3.4817, 3.9588, 3.7072, 3.5090]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 128 : 1780.5077264653692
Test loss for epoch 128 : 195.62427482738985
Test Precision for epoch 128 : 0.26153846153846155
Test Recall for epoch 128 : 0.26153846153846155
Test F1 for epoch 128 : 0.26153846153846155


theta for epoch 129 : tensor([[3.6474, 3.6698, 3.7981, 3.7490, 3.7420, 3.6297, 3.6686, 3.5721, 3.5721,
         1.2636, 1.2372, 1.2356, 1.2404, 1.2878, 1.2199, 1.1744, 1.2878, 1.2221,
         1.5866, 1.5705, 1.5951, 1.5755, 1.5821, 1.5837, 1.5924, 1.5837, 1.5837,
         1.3482, 1.3591, 1.3426, 1.3677, 1.3464, 1.3809, 1.3727, 1.3581, 1.3427,
         1.5882, 1.6054, 1.5933, 1.5898, 1.5971, 1.5875, 1.6065, 1.5584, 1.5632,
         1.2256, 1.2532, 1.2445, 1.2628, 1.2206, 1.2122, 1.2007, 1.2856, 1.2410],
        [1.4014, 1.2366, 1.2286, 1.2713, 1.2719, 1.2838, 1.2778, 1.1726, 1.1726,
         3.6311, 3.6859, 3.5829, 3.8262, 3.6319, 4.0076, 3.5396, 3.6016, 3.8839,
         1.5735, 1.5608, 1.5367, 1.5323, 1.5524, 1.5617, 1.5883, 1.5618, 1.5618,
         1.3722, 1.3389, 1.3274, 1.3907, 1.3304, 1.4308, 1.4097, 1.3757, 1.3243,
         1.5438, 1.5997, 1.5626, 1.5498, 1.5454, 1.5827, 1.6032, 1.4387, 1.5347,
         1.1615, 1.2700, 1.2431, 1.2916, 1.1568, 1.1638, 1.0906, 1.3524, 1.2334],
        [1.4612, 1.4612, 1.4596, 1.4568, 1.4569, 1.4612, 1.4569, 1.4613, 1.4613,
         1.4409, 1.4401, 1.4409, 1.4408, 1.4409, 1.4217, 1.4409, 1.4397, 1.4373,
         2.1983, 2.1992, 2.2162, 2.1921, 2.1728, 2.1712, 2.2003, 2.1700, 2.1700,
         1.5251, 1.5236, 1.5311, 1.5310, 1.5252, 1.5310, 1.5310, 1.5310, 1.5311,
         1.7740, 1.7741, 1.7741, 1.7708, 1.7739, 1.7740, 1.7741, 1.7506, 1.7535,
         1.4235, 1.4286, 1.4286, 1.4286, 1.4200, 1.4286, 1.4240, 1.4286, 1.4286],
        [1.3277, 1.3259, 1.3099, 1.3013, 1.3248, 1.3232, 1.3243, 1.3250, 1.3250,
         1.3066, 1.2997, 1.2959, 1.2954, 1.3075, 1.2914, 1.3026, 1.3071, 1.2789,
         1.6397, 1.6131, 1.6366, 1.6361, 1.6355, 1.6355, 1.6378, 1.6392, 1.6392,
         3.4937, 3.2817, 3.2070, 3.2662, 3.4196, 3.2338, 3.4668, 3.2156, 3.1936,
         1.6472, 1.6397, 1.6379, 1.6412, 1.6441, 1.6201, 1.6454, 1.5846, 1.6113,
         1.2930, 1.2876, 1.2778, 1.2925, 1.2882, 1.2803, 1.2923, 1.2928, 1.2948],
        [1.4641, 1.4593, 1.4153, 1.4198, 1.4575, 1.4640, 1.4623, 1.4641, 1.4641,
         1.4426, 1.4399, 1.4349, 1.4292, 1.4437, 1.4013, 1.4378, 1.4437, 1.4383,
         1.7523, 1.7436, 1.7412, 1.7498, 1.7683, 1.7666, 1.7466, 1.7685, 1.7685,
         1.4917, 1.4957, 1.5338, 1.5282, 1.4969, 1.5322, 1.5206, 1.5338, 1.5307,
         2.2013, 2.1803, 2.1686, 2.1871, 2.2321, 2.2479, 2.2142, 2.3215, 2.3173,
         1.4145, 1.4066, 1.4207, 1.4314, 1.4175, 1.4281, 1.3963, 1.4252, 1.4315],
        [1.2819, 1.2077, 1.2015, 1.2185, 1.2120, 1.2217, 1.2206, 1.1742, 1.1742,
         1.2446, 1.2031, 1.2017, 1.2069, 1.2850, 1.1610, 1.1184, 1.2850, 1.1865,
         1.5750, 1.5528, 1.5331, 1.5329, 1.5550, 1.5516, 1.5681, 1.5565, 1.5565,
         1.3104, 1.2847, 1.2919, 1.2993, 1.2888, 1.3221, 1.3270, 1.3054, 1.2919,
         1.5647, 1.5615, 1.5695, 1.5592, 1.5350, 1.5370, 1.5964, 1.4906, 1.4588,
         3.9854, 3.6872, 3.7530, 3.7427, 3.7453, 3.4983, 3.9782, 3.7246, 3.5256]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 129 : 1780.3809814554781
Test loss for epoch 129 : 196.24556104218732
Test Precision for epoch 129 : 0.26153846153846155
Test Recall for epoch 129 : 0.26153846153846155
Test F1 for epoch 129 : 0.26153846153846155


theta for epoch 130 : tensor([[3.6432, 3.6656, 3.7944, 3.7452, 3.7380, 3.6254, 3.6644, 3.5676, 3.5676,
         1.2590, 1.2322, 1.2305, 1.2354, 1.2835, 1.2149, 1.1683, 1.2835, 1.2169,
         1.5953, 1.5791, 1.6038, 1.5840, 1.5906, 1.5922, 1.6010, 1.5922, 1.5922,
         1.3435, 1.3543, 1.3376, 1.3630, 1.3415, 1.3764, 1.3681, 1.3533, 1.3376,
         1.5920, 1.6094, 1.5972, 1.5936, 1.6009, 1.5914, 1.6105, 1.5622, 1.5671,
         1.2275, 1.2553, 1.2465, 1.2649, 1.2224, 1.2139, 1.2024, 1.2879, 1.2430],
        [1.3869, 1.2239, 1.2157, 1.2583, 1.2589, 1.2708, 1.2648, 1.1609, 1.1609,
         3.6384, 3.6935, 3.5900, 3.8347, 3.6391, 4.0174, 3.5466, 3.6086, 3.8929,
         1.5746, 1.5620, 1.5376, 1.5335, 1.5537, 1.5631, 1.5895, 1.5631, 1.5631,
         1.3593, 1.3261, 1.3153, 1.3777, 1.3178, 1.4174, 1.3965, 1.3629, 1.3121,
         1.5424, 1.5984, 1.5612, 1.5484, 1.5439, 1.5813, 1.6017, 1.4369, 1.5332,
         1.1572, 1.2657, 1.2389, 1.2871, 1.1526, 1.1599, 1.0864, 1.3473, 1.2293],
        [1.4566, 1.4565, 1.4549, 1.4521, 1.4522, 1.4566, 1.4523, 1.4566, 1.4566,
         1.4357, 1.4349, 1.4356, 1.4356, 1.4357, 1.4164, 1.4357, 1.4344, 1.4321,
         2.2058, 2.2067, 2.2237, 2.1993, 2.1799, 2.1784, 2.2075, 2.1772, 2.1772,
         1.5193, 1.5177, 1.5252, 1.5252, 1.5193, 1.5252, 1.5251, 1.5252, 1.5252,
         1.7775, 1.7776, 1.7776, 1.7744, 1.7775, 1.7775, 1.7776, 1.7542, 1.7571,
         1.4254, 1.4305, 1.4305, 1.4305, 1.4218, 1.4304, 1.4259, 1.4304, 1.4305],
        [1.3229, 1.3212, 1.3051, 1.2966, 1.3201, 1.3185, 1.3196, 1.3202, 1.3202,
         1.3014, 1.2945, 1.2907, 1.2901, 1.3023, 1.2862, 1.2973, 1.3018, 1.2736,
         1.6479, 1.6213, 1.6448, 1.6443, 1.6437, 1.6437, 1.6459, 1.6474, 1.6474,
         3.4896, 3.2777, 3.2029, 3.2622, 3.4155, 3.2298, 3.4627, 3.2115, 3.1896,
         1.6508, 1.6433, 1.6415, 1.6448, 1.6477, 1.6238, 1.6490, 1.5883, 1.6149,
         1.2947, 1.2894, 1.2795, 1.2943, 1.2900, 1.2821, 1.2941, 1.2945, 1.2965],
        [1.4594, 1.4547, 1.4106, 1.4151, 1.4528, 1.4593, 1.4577, 1.4594, 1.4594,
         1.4374, 1.4346, 1.4297, 1.4240, 1.4385, 1.3960, 1.4325, 1.4385, 1.4331,
         1.7604, 1.7517, 1.7493, 1.7579, 1.7764, 1.7747, 1.7546, 1.7765, 1.7765,
         1.4858, 1.4898, 1.5279, 1.5223, 1.4911, 1.5264, 1.5147, 1.5280, 1.5249,
         2.2049, 2.1839, 2.1722, 2.1906, 2.2357, 2.2515, 2.2178, 2.3251, 2.3209,
         1.4163, 1.4084, 1.4226, 1.4333, 1.4193, 1.4300, 1.3981, 1.4271, 1.4333],
        [1.3001, 1.2234, 1.2175, 1.2347, 1.2282, 1.2379, 1.2368, 1.1882, 1.1882,
         1.2480, 1.2062, 1.2047, 1.2101, 1.2884, 1.1644, 1.1209, 1.2884, 1.1895,
         1.5927, 1.5705, 1.5509, 1.5506, 1.5726, 1.5692, 1.5857, 1.5740, 1.5740,
         1.3246, 1.2989, 1.3051, 1.3138, 1.3027, 1.3370, 1.3415, 1.3195, 1.3051,
         1.5762, 1.5730, 1.5810, 1.5707, 1.5466, 1.5486, 1.6078, 1.5024, 1.4709,
         3.9638, 3.6637, 3.7298, 3.7195, 3.7221, 3.4737, 3.9566, 3.7014, 3.5013]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 130 : 1780.0577787158436
Test loss for epoch 130 : 195.19368765847656
Test Precision for epoch 130 : 0.26153846153846155
Test Recall for epoch 130 : 0.26153846153846155
Test F1 for epoch 130 : 0.26153846153846155


theta for epoch 131 : tensor([[3.6378, 3.6602, 3.7896, 3.7401, 3.7329, 3.6198, 3.6590, 3.5619, 3.5619,
         1.2581, 1.2309, 1.2291, 1.2342, 1.2828, 1.2137, 1.1661, 1.2828, 1.2155,
         1.6014, 1.5852, 1.6100, 1.5899, 1.5965, 1.5981, 1.6071, 1.5981, 1.5981,
         1.3304, 1.3412, 1.3242, 1.3500, 1.3283, 1.3635, 1.3552, 1.3402, 1.3242,
         1.5927, 1.6102, 1.5978, 1.5943, 1.6017, 1.5922, 1.6114, 1.5629, 1.5678,
         1.2352, 1.2634, 1.2545, 1.2731, 1.2300, 1.2213, 1.2099, 1.2963, 1.2509],
        [1.3641, 1.2033, 1.1949, 1.2374, 1.2380, 1.2499, 1.2439, 1.1416, 1.1416,
         3.6523, 3.7079, 3.6037, 3.8499, 3.6531, 4.0338, 3.5603, 3.6223, 3.9085,
         1.5708, 1.5582, 1.5335, 1.5298, 1.5501, 1.5596, 1.5859, 1.5596, 1.5596,
         1.3366, 1.3035, 1.2935, 1.3548, 1.2955, 1.3940, 1.3733, 1.3404, 1.2904,
         1.5357, 1.5917, 1.5546, 1.5417, 1.5372, 1.5746, 1.5950, 1.4296, 1.5265,
         1.1542, 1.2630, 1.2362, 1.2843, 1.1496, 1.1571, 1.0832, 1.3440, 1.2267],
        [1.4473, 1.4472, 1.4456, 1.4428, 1.4430, 1.4473, 1.4430, 1.4473, 1.4473,
         1.4342, 1.4334, 1.4342, 1.4341, 1.4342, 1.4150, 1.4342, 1.4330, 1.4306,
         2.2112, 2.2120, 2.2290, 2.2044, 2.1850, 2.1835, 2.2125, 2.1823, 2.1823,
         1.5058, 1.5042, 1.5117, 1.5117, 1.5058, 1.5117, 1.5116, 1.5117, 1.5117,
         1.7782, 1.7783, 1.7783, 1.7751, 1.7782, 1.7782, 1.7783, 1.7549, 1.7578,
         1.4336, 1.4387, 1.4387, 1.4387, 1.4301, 1.4387, 1.4341, 1.4387, 1.4387],
        [1.3135, 1.3117, 1.2957, 1.2871, 1.3106, 1.3090, 1.3101, 1.3107, 1.3107,
         1.2999, 1.2930, 1.2892, 1.2887, 1.3008, 1.2847, 1.2958, 1.3004, 1.2721,
         1.6537, 1.6271, 1.6505, 1.6501, 1.6495, 1.6495, 1.6517, 1.6532, 1.6532,
         3.4796, 3.2677, 3.1929, 3.2522, 3.4055, 3.2200, 3.4528, 3.2016, 3.1796,
         1.6515, 1.6440, 1.6422, 1.6454, 1.6484, 1.6244, 1.6497, 1.5889, 1.6155,
         1.3029, 1.2976, 1.2877, 1.3025, 1.2982, 1.2903, 1.3023, 1.3027, 1.3047],
        [1.4502, 1.4454, 1.4013, 1.4058, 1.4435, 1.4501, 1.4485, 1.4502, 1.4502,
         1.4360, 1.4332, 1.4282, 1.4225, 1.4370, 1.3946, 1.4311, 1.4370, 1.4316,
         1.7662, 1.7575, 1.7551, 1.7636, 1.7821, 1.7804, 1.7604, 1.7823, 1.7823,
         1.4723, 1.4763, 1.5144, 1.5088, 1.4775, 1.5129, 1.5012, 1.5145, 1.5113,
         2.2056, 2.1846, 2.1729, 2.1914, 2.2364, 2.2523, 2.2186, 2.3258, 2.3216,
         1.4246, 1.4167, 1.4309, 1.4415, 1.4276, 1.4382, 1.4064, 1.4353, 1.4416],
        [1.3116, 1.2312, 1.2259, 1.2432, 1.2368, 1.2464, 1.2453, 1.1938, 1.1938,
         1.2534, 1.2111, 1.2097, 1.2152, 1.2940, 1.1694, 1.1248, 1.2940, 1.1943,
         1.6061, 1.5839, 1.5644, 1.5639, 1.5857, 1.5824, 1.5991, 1.5872, 1.5872,
         1.3285, 1.3028, 1.3077, 1.3180, 1.3062, 1.3418, 1.3458, 1.3233, 1.3077,
         1.5830, 1.5800, 1.5878, 1.5776, 1.5535, 1.5556, 1.6147, 1.5094, 1.4781,
         3.9506, 3.6486, 3.7150, 3.7047, 3.7072, 3.4576, 3.9434, 3.6865, 3.4853]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 131 : 1779.825205233941
Test loss for epoch 131 : 195.1514175386331
Test Precision for epoch 131 : 0.26153846153846155
Test Recall for epoch 131 : 0.26153846153846155
Test F1 for epoch 131 : 0.26153846153846155


theta for epoch 132 : tensor([[3.6388, 3.6614, 3.7913, 3.7416, 3.7343, 3.6209, 3.6601, 3.5629, 3.5629,
         1.2576, 1.2300, 1.2283, 1.2335, 1.2826, 1.2128, 1.1644, 1.2826, 1.2145,
         1.5956, 1.5793, 1.6043, 1.5840, 1.5906, 1.5922, 1.6013, 1.5922, 1.5922,
         1.3295, 1.3403, 1.3230, 1.3491, 1.3273, 1.3628, 1.3544, 1.3393, 1.3231,
         1.5885, 1.6062, 1.5937, 1.5902, 1.5976, 1.5882, 1.6075, 1.5588, 1.5637,
         1.2447, 1.2734, 1.2643, 1.2832, 1.2394, 1.2305, 1.2192, 1.3067, 1.2607],
        [1.3438, 1.1847, 1.1759, 1.2185, 1.2191, 1.2310, 1.2250, 1.1240, 1.1240,
         3.6709, 3.7269, 3.6221, 3.8698, 3.6716, 4.0549, 3.5786, 3.6407, 3.9288,
         1.5549, 1.5423, 1.5174, 1.5140, 1.5344, 1.5439, 1.5702, 1.5440, 1.5440,
         1.3184, 1.2853, 1.2761, 1.3367, 1.2775, 1.3754, 1.3549, 1.3224, 1.2729,
         1.5224, 1.5786, 1.5415, 1.5285, 1.5239, 1.5615, 1.5818, 1.4156, 1.5132,
         1.1497, 1.2592, 1.2323, 1.2804, 1.1452, 1.1528, 1.0784, 1.3400, 1.2229],
        [1.4476, 1.4475, 1.4459, 1.4431, 1.4433, 1.4476, 1.4433, 1.4476, 1.4476,
         1.4334, 1.4326, 1.4334, 1.4333, 1.4334, 1.4142, 1.4334, 1.4322, 1.4298,
         2.2058, 2.2067, 2.2237, 2.1992, 2.1798, 2.1783, 2.2074, 2.1771, 2.1771,
         1.5044, 1.5029, 1.5104, 1.5104, 1.5045, 1.5104, 1.5103, 1.5104, 1.5104,
         1.7743, 1.7744, 1.7744, 1.7712, 1.7743, 1.7743, 1.7744, 1.7510, 1.7539,
         1.4440, 1.4491, 1.4491, 1.4491, 1.4405, 1.4491, 1.4445, 1.4491, 1.4491],
        [1.3138, 1.3120, 1.2960, 1.2874, 1.3109, 1.3093, 1.3104, 1.3110, 1.3110,
         1.2991, 1.2922, 1.2884, 1.2878, 1.3000, 1.2839, 1.2950, 1.2995, 1.2713,
         1.6479, 1.6213, 1.6447, 1.6443, 1.6437, 1.6437, 1.6459, 1.6474, 1.6474,
         3.4796, 3.2678, 3.1930, 3.2523, 3.4054, 3.2201, 3.4527, 3.2017, 3.1797,
         1.6475, 1.6400, 1.6382, 1.6415, 1.6444, 1.6205, 1.6457, 1.5850, 1.6116,
         1.3132, 1.3079, 1.2981, 1.3128, 1.3085, 1.3006, 1.3126, 1.3130, 1.3150],
        [1.4505, 1.4457, 1.4017, 1.4061, 1.4438, 1.4504, 1.4488, 1.4504, 1.4504,
         1.4352, 1.4324, 1.4274, 1.4217, 1.4362, 1.3938, 1.4303, 1.4362, 1.4308,
         1.7606, 1.7519, 1.7495, 1.7581, 1.7765, 1.7749, 1.7549, 1.7767, 1.7767,
         1.4710, 1.4750, 1.5131, 1.5076, 1.4763, 1.5116, 1.4999, 1.5132, 1.5100,
         2.2019, 2.1809, 2.1692, 2.1877, 2.2328, 2.2486, 2.2149, 2.3221, 2.3179,
         1.4351, 1.4271, 1.4413, 1.4519, 1.4380, 1.4486, 1.4169, 1.4457, 1.4519],
        [1.3277, 1.2436, 1.2387, 1.2563, 1.2499, 1.2595, 1.2584, 1.2039, 1.2039,
         1.2577, 1.2149, 1.2134, 1.2191, 1.2987, 1.1732, 1.1274, 1.2987, 1.1979,
         1.6063, 1.5842, 1.5649, 1.5639, 1.5857, 1.5824, 1.5994, 1.5871, 1.5871,
         1.3401, 1.3144, 1.3180, 1.3299, 1.3174, 1.3545, 1.3580, 1.3348, 1.3180,
         1.5836, 1.5808, 1.5883, 1.5781, 1.5542, 1.5564, 1.6155, 1.5102, 1.4791,
         3.9436, 3.6395, 3.7063, 3.6959, 3.6985, 3.4477, 3.9363, 3.6777, 3.4756]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 132 : 1779.0345229468583
Test loss for epoch 132 : 195.76545130600343
Test Precision for epoch 132 : 0.26153846153846155
Test Recall for epoch 132 : 0.26153846153846155
Test F1 for epoch 132 : 0.26153846153846155


theta for epoch 133 : tensor([[3.6398, 3.6625, 3.7929, 3.7430, 3.7356, 3.6219, 3.6612, 3.5639, 3.5639,
         1.2547, 1.2271, 1.2254, 1.2306, 1.2796, 1.2099, 1.1616, 1.2796, 1.2117,
         1.5884, 1.5721, 1.5971, 1.5767, 1.5832, 1.5849, 1.5941, 1.5848, 1.5848,
         1.3431, 1.3539, 1.3366, 1.3627, 1.3408, 1.3764, 1.3680, 1.3528, 1.3366,
         1.5849, 1.6027, 1.5901, 1.5866, 1.5940, 1.5847, 1.6040, 1.5552, 1.5601,
         1.2508, 1.2798, 1.2707, 1.2897, 1.2454, 1.2364, 1.2251, 1.3134, 1.2670],
        [1.3506, 1.1937, 1.1847, 1.2272, 1.2277, 1.2397, 1.2336, 1.1343, 1.1343,
         3.6663, 3.7226, 3.6172, 3.8664, 3.6670, 4.0527, 3.5736, 3.6359, 3.9259,
         1.5502, 1.5377, 1.5128, 1.5097, 1.5300, 1.5395, 1.5655, 1.5396, 1.5396,
         1.3285, 1.2955, 1.2872, 1.3467, 1.2880, 1.3850, 1.3648, 1.3327, 1.2840,
         1.5207, 1.5766, 1.5398, 1.5268, 1.5221, 1.5595, 1.5798, 1.4141, 1.5115,
         1.1557, 1.2652, 1.2385, 1.2863, 1.1513, 1.1589, 1.0846, 1.3454, 1.2291],
        [1.4564, 1.4563, 1.4547, 1.4519, 1.4521, 1.4564, 1.4521, 1.4564, 1.4564,
         1.4295, 1.4287, 1.4294, 1.4294, 1.4295, 1.4102, 1.4294, 1.4282, 1.4258,
         2.1982, 2.1991, 2.2161, 2.1920, 2.1726, 2.1710, 2.2002, 2.1699, 2.1699,
         1.5154, 1.5139, 1.5213, 1.5213, 1.5154, 1.5213, 1.5213, 1.5213, 1.5213,
         1.7702, 1.7703, 1.7703, 1.7670, 1.7702, 1.7702, 1.7703, 1.7469, 1.7497,
         1.4498, 1.4549, 1.4549, 1.4549, 1.4462, 1.4549, 1.4503, 1.4548, 1.4549],
        [1.3227, 1.3209, 1.3050, 1.2964, 1.3199, 1.3183, 1.3194, 1.3200, 1.3200,
         1.2951, 1.2882, 1.2844, 1.2838, 1.2959, 1.2799, 1.2910, 1.2955, 1.2673,
         1.6397, 1.6131, 1.6366, 1.6361, 1.6355, 1.6355, 1.6378, 1.6392, 1.6392,
         3.4893, 3.2778, 3.2033, 3.2623, 3.4151, 3.2301, 3.4624, 3.2118, 3.1899,
         1.6433, 1.6358, 1.6340, 1.6372, 1.6402, 1.6162, 1.6415, 1.5808, 1.6073,
         1.3189, 1.3136, 1.3037, 1.3184, 1.3141, 1.3063, 1.3183, 1.3186, 1.3206],
        [1.4592, 1.4546, 1.4107, 1.4150, 1.4526, 1.4591, 1.4575, 1.4592, 1.4592,
         1.4312, 1.4284, 1.4235, 1.4177, 1.4323, 1.3898, 1.4263, 1.4323, 1.4268,
         1.7527, 1.7440, 1.7415, 1.7502, 1.7687, 1.7670, 1.7470, 1.7688, 1.7688,
         1.4821, 1.4862, 1.5241, 1.5186, 1.4874, 1.5226, 1.5109, 1.5241, 1.5210,
         2.1980, 2.1769, 2.1653, 2.1837, 2.2288, 2.2447, 2.2109, 2.3181, 2.3140,
         1.4409, 1.4329, 1.4471, 1.4577, 1.4438, 1.4544, 1.4228, 1.4515, 1.4577],
        [1.3503, 1.2631, 1.2586, 1.2763, 1.2701, 1.2796, 1.2785, 1.2215, 1.2215,
         1.2588, 1.2160, 1.2145, 1.2201, 1.2996, 1.1743, 1.1284, 1.2996, 1.1990,
         1.6041, 1.5819, 1.5628, 1.5615, 1.5832, 1.5799, 1.5971, 1.5847, 1.5847,
         1.3625, 1.3366, 1.3392, 1.3525, 1.3394, 1.3777, 1.3808, 1.3570, 1.3392,
         1.5838, 1.5811, 1.5885, 1.5783, 1.5545, 1.5568, 1.6157, 1.5105, 1.4796,
         3.9349, 3.6290, 3.6961, 3.6857, 3.6883, 3.4363, 3.9277, 3.6674, 3.4643]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 133 : 1779.3360680291235
Test loss for epoch 133 : 195.40450404513223
Test Precision for epoch 133 : 0.26153846153846155
Test Recall for epoch 133 : 0.26153846153846155
Test F1 for epoch 133 : 0.26153846153846155


theta for epoch 134 : tensor([[3.6317, 3.6543, 3.7852, 3.7351, 3.7277, 3.6136, 3.6530, 3.5554, 3.5554,
         1.2549, 1.2277, 1.2260, 1.2311, 1.2794, 1.2105, 1.1631, 1.2794, 1.2123,
         1.5890, 1.5726, 1.5977, 1.5771, 1.5837, 1.5853, 1.5946, 1.5853, 1.5853,
         1.3508, 1.3615, 1.3442, 1.3703, 1.3485, 1.3839, 1.3756, 1.3605, 1.3442,
         1.5862, 1.6041, 1.5914, 1.5878, 1.5954, 1.5860, 1.6054, 1.5565, 1.5614,
         1.2532, 1.2824, 1.2732, 1.2924, 1.2477, 1.2385, 1.2273, 1.3162, 1.2695],
        [1.3718, 1.2181, 1.2089, 1.2510, 1.2516, 1.2635, 1.2575, 1.1601, 1.1601,
         3.6426, 3.6992, 3.5932, 3.8439, 3.6432, 4.0315, 3.5494, 3.6120, 3.9038,
         1.5631, 1.5509, 1.5260, 1.5232, 1.5434, 1.5528, 1.5783, 1.5528, 1.5528,
         1.3516, 1.3190, 1.3114, 1.3696, 1.3118, 1.4071, 1.3872, 1.3559, 1.3082,
         1.5336, 1.5889, 1.5525, 1.5396, 1.5350, 1.5720, 1.5920, 1.4279, 1.5244,
         1.1711, 1.2799, 1.2534, 1.3008, 1.1666, 1.1742, 1.1004, 1.3591, 1.2442],
        [1.4579, 1.4578, 1.4562, 1.4534, 1.4536, 1.4579, 1.4536, 1.4579, 1.4579,
         1.4277, 1.4270, 1.4277, 1.4277, 1.4277, 1.4085, 1.4277, 1.4265, 1.4241,
         2.1968, 2.1977, 2.2147, 2.1907, 2.1712, 2.1697, 2.1989, 2.1685, 2.1685,
         1.5189, 1.5173, 1.5248, 1.5248, 1.5189, 1.5248, 1.5247, 1.5248, 1.5248,
         1.7700, 1.7701, 1.7701, 1.7669, 1.7700, 1.7700, 1.7701, 1.7467, 1.7496,
         1.4506, 1.4556, 1.4556, 1.4556, 1.4470, 1.4556, 1.4511, 1.4555, 1.4556],
        [1.3243, 1.3225, 1.3066, 1.2980, 1.3215, 1.3198, 1.3210, 1.3216, 1.3216,
         1.2933, 1.2865, 1.2826, 1.2821, 1.2942, 1.2782, 1.2893, 1.2937, 1.2656,
         1.6382, 1.6116, 1.6351, 1.6346, 1.6340, 1.6340, 1.6363, 1.6377, 1.6377,
         3.4929, 3.2817, 3.2072, 3.2661, 3.4188, 3.2340, 3.4661, 3.2158, 3.1939,
         1.6431, 1.6356, 1.6338, 1.6370, 1.6400, 1.6160, 1.6413, 1.5806, 1.6072,
         1.3195, 1.3141, 1.3043, 1.3190, 1.3147, 1.3069, 1.3189, 1.3192, 1.3212],
        [1.4607, 1.4561, 1.4123, 1.4165, 1.4541, 1.4606, 1.4591, 1.4607, 1.4607,
         1.4295, 1.4267, 1.4217, 1.4160, 1.4306, 1.3881, 1.4246, 1.4306, 1.4251,
         1.7513, 1.7426, 1.7402, 1.7488, 1.7673, 1.7656, 1.7456, 1.7674, 1.7674,
         1.4856, 1.4897, 1.5275, 1.5221, 1.4909, 1.5260, 1.5144, 1.5276, 1.5245,
         2.1979, 2.1768, 2.1652, 2.1836, 2.2287, 2.2447, 2.2109, 2.3180, 2.3139,
         1.4417, 1.4336, 1.4478, 1.4584, 1.4446, 1.4551, 1.4236, 1.4522, 1.4584],
        [1.3647, 1.2754, 1.2712, 1.2891, 1.2828, 1.2924, 1.2913, 1.2325, 1.2325,
         1.2616, 1.2192, 1.2178, 1.2232, 1.3019, 1.1776, 1.1328, 1.3019, 1.2023,
         1.6078, 1.5856, 1.5666, 1.5651, 1.5868, 1.5835, 1.6008, 1.5882, 1.5882,
         1.3767, 1.3508, 1.3526, 1.3668, 1.3533, 1.3925, 1.3953, 1.3711, 1.3526,
         1.5876, 1.5850, 1.5923, 1.5822, 1.5584, 1.5607, 1.6195, 1.5144, 1.4837,
         3.9250, 3.6171, 3.6845, 3.6741, 3.6768, 3.4235, 3.9177, 3.6557, 3.4516]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 134 : 1781.1492930041202
Test loss for epoch 134 : 194.36494821192366
Test Precision for epoch 134 : 0.26153846153846155
Test Recall for epoch 134 : 0.26153846153846155
Test F1 for epoch 134 : 0.26153846153846155


theta for epoch 135 : tensor([[3.6189, 3.6414, 3.7729, 3.7226, 3.7150, 3.6006, 3.6401, 3.5420, 3.5420,
         1.2617, 1.2347, 1.2330, 1.2380, 1.2859, 1.2174, 1.1706, 1.2859, 1.2194,
         1.5963, 1.5799, 1.6050, 1.5844, 1.5909, 1.5926, 1.6019, 1.5925, 1.5925,
         1.3349, 1.3456, 1.3282, 1.3544, 1.3326, 1.3681, 1.3597, 1.3446, 1.3283,
         1.5913, 1.6093, 1.5965, 1.5929, 1.6005, 1.5912, 1.6107, 1.5617, 1.5666,
         1.2536, 1.2832, 1.2739, 1.2932, 1.2480, 1.2387, 1.2276, 1.3172, 1.2702],
        [1.3781, 1.2271, 1.2178, 1.2595, 1.2601, 1.2719, 1.2659, 1.1704, 1.1704,
         3.6295, 3.6864, 3.5799, 3.8320, 3.6302, 4.0209, 3.5358, 3.5988, 3.8923,
         1.5771, 1.5649, 1.5401, 1.5375, 1.5576, 1.5670, 1.5922, 1.5670, 1.5670,
         1.3527, 1.3205, 1.3135, 1.3705, 1.3135, 1.4072, 1.3877, 1.3570, 1.3104,
         1.5459, 1.6008, 1.5647, 1.5519, 1.5472, 1.5840, 1.6038, 1.4408, 1.5367,
         1.1801, 1.2886, 1.2623, 1.3092, 1.1756, 1.1830, 1.1097, 1.3670, 1.2531],
        [1.4477, 1.4476, 1.4460, 1.4433, 1.4434, 1.4477, 1.4434, 1.4477, 1.4477,
         1.4330, 1.4322, 1.4330, 1.4329, 1.4330, 1.4138, 1.4330, 1.4317, 1.4294,
         2.2020, 2.2029, 2.2199, 2.1956, 2.1762, 2.1747, 2.2038, 2.1735, 2.1735,
         1.5005, 1.4989, 1.5064, 1.5064, 1.5005, 1.5064, 1.5064, 1.5064, 1.5064,
         1.7740, 1.7741, 1.7741, 1.7708, 1.7740, 1.7740, 1.7741, 1.7507, 1.7536,
         1.4498, 1.4548, 1.4548, 1.4548, 1.4462, 1.4548, 1.4503, 1.4548, 1.4548],
        [1.3140, 1.3122, 1.2963, 1.2877, 1.3112, 1.3096, 1.3107, 1.3113, 1.3113,
         1.2986, 1.2917, 1.2879, 1.2874, 1.2994, 1.2834, 1.2946, 1.2990, 1.2709,
         1.6438, 1.6172, 1.6407, 1.6402, 1.6396, 1.6396, 1.6419, 1.6433, 1.6433,
         3.4789, 3.2676, 3.1930, 3.2521, 3.4047, 3.2200, 3.4522, 3.2016, 3.1797,
         1.6470, 1.6395, 1.6378, 1.6410, 1.6439, 1.6200, 1.6452, 1.5846, 1.6111,
         1.3186, 1.3133, 1.3034, 1.3181, 1.3138, 1.3060, 1.3180, 1.3183, 1.3203],
        [1.4506, 1.4460, 1.4020, 1.4062, 1.4440, 1.4505, 1.4489, 1.4506, 1.4506,
         1.4347, 1.4320, 1.4270, 1.4213, 1.4358, 1.3934, 1.4299, 1.4358, 1.4304,
         1.7569, 1.7483, 1.7458, 1.7545, 1.7729, 1.7712, 1.7513, 1.7730, 1.7730,
         1.4672, 1.4713, 1.5092, 1.5037, 1.4725, 1.5077, 1.4960, 1.5092, 1.5061,
         2.2017, 2.1807, 2.1690, 2.1875, 2.2326, 2.2485, 2.2147, 2.3218, 2.3177,
         1.4409, 1.4329, 1.4470, 1.4576, 1.4438, 1.4543, 1.4229, 1.4514, 1.4577],
        [1.3641, 1.2731, 1.2692, 1.2871, 1.2809, 1.2904, 1.2893, 1.2292, 1.2292,
         1.2692, 1.2271, 1.2257, 1.2311, 1.3091, 1.1855, 1.1414, 1.3092, 1.2103,
         1.6162, 1.5940, 1.5750, 1.5735, 1.5951, 1.5918, 1.6092, 1.5966, 1.5966,
         1.3663, 1.3404, 1.3415, 1.3566, 1.3427, 1.3826, 1.3851, 1.3606, 1.3416,
         1.5939, 1.5913, 1.5986, 1.5884, 1.5646, 1.5670, 1.6258, 1.5207, 1.4900,
         3.9192, 3.6094, 3.6772, 3.6667, 3.6695, 3.4151, 3.9119, 3.6482, 3.4433]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 135 : 1780.8928416106367
Test loss for epoch 135 : 193.97538763615054
Test Precision for epoch 135 : 0.26153846153846155
Test Recall for epoch 135 : 0.26153846153846155
Test F1 for epoch 135 : 0.26153846153846155


theta for epoch 136 : tensor([[3.6078, 3.6302, 3.7623, 3.7118, 3.7041, 3.5894, 3.6290, 3.5305, 3.5305,
         1.2715, 1.2446, 1.2429, 1.2479, 1.2956, 1.2273, 1.1807, 1.2957, 1.2294,
         1.6009, 1.5844, 1.6096, 1.5888, 1.5953, 1.5970, 1.6064, 1.5969, 1.5969,
         1.3245, 1.3352, 1.3177, 1.3441, 1.3221, 1.3578, 1.3494, 1.3342, 1.3178,
         1.5937, 1.6118, 1.5989, 1.5953, 1.6029, 1.5937, 1.6132, 1.5641, 1.5690,
         1.2499, 1.2798, 1.2705, 1.2899, 1.2442, 1.2348, 1.2237, 1.3142, 1.2667],
        [1.3778, 1.2288, 1.2194, 1.2609, 1.2614, 1.2731, 1.2672, 1.1730, 1.1730,
         3.6250, 3.6823, 3.5752, 3.8287, 3.6257, 4.0188, 3.5309, 3.5941, 3.8895,
         1.5845, 1.5724, 1.5476, 1.5452, 1.5653, 1.5746, 1.5996, 1.5746, 1.5746,
         1.3512, 1.3192, 1.3127, 1.3687, 1.3125, 1.4049, 1.3858, 1.3556, 1.3096,
         1.5519, 1.6066, 1.5706, 1.5579, 1.5532, 1.5898, 1.6096, 1.4470, 1.5428,
         1.1812, 1.2896, 1.2634, 1.3101, 1.1767, 1.1840, 1.1110, 1.3675, 1.2542],
        [1.4383, 1.4382, 1.4366, 1.4338, 1.4340, 1.4383, 1.4339, 1.4382, 1.4382,
         1.4416, 1.4409, 1.4416, 1.4416, 1.4416, 1.4224, 1.4416, 1.4404, 1.4380,
         2.2050, 2.2058, 2.2229, 2.1984, 2.1790, 2.1775, 2.2066, 2.1763, 2.1763,
         1.4882, 1.4866, 1.4941, 1.4941, 1.4882, 1.4942, 1.4941, 1.4941, 1.4941,
         1.7755, 1.7756, 1.7756, 1.7724, 1.7755, 1.7755, 1.7756, 1.7523, 1.7551,
         1.4453, 1.4503, 1.4503, 1.4503, 1.4417, 1.4503, 1.4458, 1.4502, 1.4503],
        [1.3046, 1.3028, 1.2868, 1.2783, 1.3018, 1.3001, 1.3012, 1.3018, 1.3018,
         1.3072, 1.3004, 1.2966, 1.2961, 1.3081, 1.2921, 1.3034, 1.3076, 1.2796,
         1.6471, 1.6205, 1.6439, 1.6435, 1.6429, 1.6429, 1.6451, 1.6466, 1.6466,
         3.4693, 3.2579, 3.1833, 3.2425, 3.3950, 3.2105, 3.4426, 3.1920, 3.1700,
         1.6486, 1.6411, 1.6393, 1.6426, 1.6455, 1.6216, 1.6468, 1.5861, 1.6127,
         1.3140, 1.3086, 1.2988, 1.3135, 1.3092, 1.3014, 1.3134, 1.3137, 1.3157],
        [1.4412, 1.4365, 1.3925, 1.3967, 1.4345, 1.4410, 1.4395, 1.4411, 1.4411,
         1.4434, 1.4406, 1.4356, 1.4299, 1.4444, 1.4020, 1.4385, 1.4444, 1.4390,
         1.7602, 1.7515, 1.7490, 1.7577, 1.7761, 1.7744, 1.7545, 1.7763, 1.7763,
         1.4548, 1.4590, 1.4969, 1.4914, 1.4602, 1.4954, 1.4837, 1.4970, 1.4938,
         2.2033, 2.1822, 2.1706, 2.1890, 2.2341, 2.2501, 2.2163, 2.3233, 2.3193,
         1.4364, 1.4283, 1.4425, 1.4531, 1.4393, 1.4498, 1.4184, 1.4469, 1.4531],
        [1.3597, 1.2672, 1.2635, 1.2815, 1.2753, 1.2848, 1.2837, 1.2224, 1.2224,
         1.2784, 1.2365, 1.2351, 1.2404, 1.3181, 1.1947, 1.1512, 1.3181, 1.2198,
         1.6203, 1.5981, 1.5792, 1.5775, 1.5992, 1.5959, 1.6133, 1.6006, 1.6006,
         1.3577, 1.3318, 1.3324, 1.3481, 1.3339, 1.3744, 1.3767, 1.3520, 1.3324,
         1.5962, 1.5936, 1.6009, 1.5908, 1.5669, 1.5693, 1.6281, 1.5230, 1.4923,
         3.9161, 3.6044, 3.6725, 3.6620, 3.6648, 3.4093, 3.9088, 3.6434, 3.4376]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 136 : 1781.7264506459032
Test loss for epoch 136 : 193.90099268419252
Test Precision for epoch 136 : 0.26153846153846155
Test Recall for epoch 136 : 0.26153846153846155
Test F1 for epoch 136 : 0.26153846153846155


theta for epoch 137 : tensor([[3.6058, 3.6282, 3.7607, 3.7101, 3.7023, 3.5873, 3.6270, 3.5283, 3.5283,
         1.2780, 1.2511, 1.2494, 1.2543, 1.3021, 1.2335, 1.1870, 1.3021, 1.2358,
         1.5962, 1.5797, 1.6050, 1.5840, 1.5905, 1.5922, 1.6017, 1.5922, 1.5922,
         1.3317, 1.3423, 1.3247, 1.3512, 1.3292, 1.3650, 1.3566, 1.3413, 1.3247,
         1.5903, 1.6086, 1.5955, 1.5919, 1.5996, 1.5904, 1.6100, 1.5607, 1.5656,
         1.2462, 1.2765, 1.2670, 1.2867, 1.2404, 1.2307, 1.2198, 1.3113, 1.2632],
        [1.3802, 1.2320, 1.2225, 1.2640, 1.2645, 1.2762, 1.2703, 1.1767, 1.1767,
         3.6259, 3.6835, 3.5758, 3.8307, 3.6266, 4.0221, 3.5314, 3.5948, 3.8919,
         1.5807, 1.5687, 1.5439, 1.5416, 1.5616, 1.5710, 1.5958, 1.5710, 1.5710,
         1.3554, 1.3235, 1.3174, 1.3729, 1.3168, 1.4088, 1.3897, 1.3598, 1.3143,
         1.5493, 1.6038, 1.5679, 1.5552, 1.5505, 1.5871, 1.6067, 1.4445, 1.5401,
         1.1782, 1.2866, 1.2605, 1.3071, 1.1736, 1.1808, 1.1079, 1.3643, 1.2514],
        [1.4427, 1.4427, 1.4411, 1.4383, 1.4384, 1.4427, 1.4384, 1.4427, 1.4427,
         1.4472, 1.4464, 1.4472, 1.4471, 1.4472, 1.4280, 1.4472, 1.4459, 1.4436,
         2.1998, 2.2006, 2.2177, 2.1935, 2.1740, 2.1725, 2.2016, 2.1713, 2.1713,
         1.4936, 1.4921, 1.4995, 1.4995, 1.4936, 1.4996, 1.4995, 1.4995, 1.4995,
         1.7717, 1.7718, 1.7718, 1.7685, 1.7716, 1.7716, 1.7717, 1.7484, 1.7512,
         1.4411, 1.4461, 1.4461, 1.4461, 1.4375, 1.4461, 1.4416, 1.4461, 1.4461],
        [1.3094, 1.3076, 1.2917, 1.2831, 1.3066, 1.3049, 1.3061, 1.3066, 1.3066,
         1.3128, 1.3060, 1.3022, 1.3016, 1.3137, 1.2977, 1.3090, 1.3132, 1.2852,
         1.6416, 1.6150, 1.6385, 1.6380, 1.6374, 1.6374, 1.6397, 1.6411, 1.6411,
         3.4733, 3.2621, 3.1876, 3.2467, 3.3990, 3.2147, 3.4466, 3.1963, 3.1743,
         1.6447, 1.6372, 1.6354, 1.6387, 1.6416, 1.6177, 1.6429, 1.5823, 1.6088,
         1.3098, 1.3044, 1.2946, 1.3093, 1.3050, 1.2972, 1.3092, 1.3095, 1.3115],
        [1.4456, 1.4410, 1.3970, 1.4012, 1.4390, 1.4455, 1.4439, 1.4456, 1.4456,
         1.4489, 1.4461, 1.4411, 1.4354, 1.4500, 1.4076, 1.4440, 1.4500, 1.4445,
         1.7548, 1.7461, 1.7437, 1.7523, 1.7708, 1.7691, 1.7491, 1.7709, 1.7709,
         1.4603, 1.4644, 1.5023, 1.4969, 1.4656, 1.5008, 1.4891, 1.5024, 1.4992,
         2.1995, 2.1785, 2.1668, 2.1853, 2.2304, 2.2464, 2.2125, 2.3196, 2.3156,
         1.4323, 1.4242, 1.4383, 1.4489, 1.4351, 1.4456, 1.4142, 1.4427, 1.4490],
        [1.3633, 1.2695, 1.2659, 1.2840, 1.2778, 1.2873, 1.2862, 1.2239, 1.2239,
         1.2833, 1.2414, 1.2401, 1.2453, 1.3229, 1.1994, 1.1563, 1.3229, 1.2247,
         1.6143, 1.5921, 1.5732, 1.5714, 1.5931, 1.5898, 1.6073, 1.5946, 1.5946,
         1.3619, 1.3359, 1.3362, 1.3523, 1.3379, 1.3789, 1.3811, 1.3561, 1.3362,
         1.5917, 1.5891, 1.5965, 1.5863, 1.5624, 1.5648, 1.6236, 1.5184, 1.4878,
         3.9171, 3.6036, 3.6720, 3.6614, 3.6644, 3.4077, 3.9098, 3.6427, 3.4361]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 137 : 1781.375233966277
Test loss for epoch 137 : 193.86174496672007
Test Precision for epoch 137 : 0.26153846153846155
Test Recall for epoch 137 : 0.26153846153846155
Test F1 for epoch 137 : 0.26153846153846155


theta for epoch 138 : tensor([[3.6093, 3.6319, 3.7648, 3.7140, 3.7061, 3.5908, 3.6306, 3.5319, 3.5319,
         1.2758, 1.2488, 1.2471, 1.2521, 1.3000, 1.2310, 1.1845, 1.3000, 1.2334,
         1.5903, 1.5738, 1.5991, 1.5779, 1.5844, 1.5861, 1.5958, 1.5861, 1.5861,
         1.3478, 1.3585, 1.3406, 1.3673, 1.3453, 1.3813, 1.3728, 1.3574, 1.3407,
         1.5856, 1.6040, 1.5908, 1.5872, 1.5949, 1.5858, 1.6055, 1.5560, 1.5610,
         1.2462, 1.2769, 1.2673, 1.2873, 1.2402, 1.2304, 1.2195, 1.3122, 1.2634],
        [1.3818, 1.2336, 1.2240, 1.2656, 1.2661, 1.2779, 1.2719, 1.1784, 1.1784,
         3.6293, 3.6873, 3.5790, 3.8354, 3.6300, 4.0279, 3.5345, 3.5981, 3.8970,
         1.5724, 1.5604, 1.5356, 1.5334, 1.5535, 1.5628, 1.5876, 1.5628, 1.5628,
         1.3605, 1.3284, 1.3227, 1.3780, 1.3219, 1.4138, 1.3948, 1.3650, 1.3195,
         1.5423, 1.5968, 1.5610, 1.5483, 1.5436, 1.5801, 1.5997, 1.4374, 1.5332,
         1.1741, 1.2831, 1.2569, 1.3036, 1.1695, 1.1766, 1.1037, 1.3609, 1.2478],
        [1.4548, 1.4547, 1.4531, 1.4503, 1.4505, 1.4548, 1.4504, 1.4548, 1.4548,
         1.4444, 1.4436, 1.4444, 1.4443, 1.4444, 1.4252, 1.4444, 1.4431, 1.4408,
         2.1937, 2.1946, 2.2117, 2.1877, 2.1681, 2.1666, 2.1958, 2.1655, 2.1655,
         1.5085, 1.5070, 1.5144, 1.5144, 1.5085, 1.5144, 1.5144, 1.5144, 1.5144,
         1.7667, 1.7668, 1.7668, 1.7636, 1.7667, 1.7667, 1.7668, 1.7434, 1.7463,
         1.4410, 1.4460, 1.4460, 1.4460, 1.4374, 1.4460, 1.4416, 1.4460, 1.4460],
        [1.3221, 1.3202, 1.3043, 1.2958, 1.3192, 1.3176, 1.3187, 1.3192, 1.3192,
         1.3101, 1.3033, 1.2995, 1.2989, 1.3109, 1.2950, 1.3063, 1.3105, 1.2825,
         1.6352, 1.6087, 1.6321, 1.6316, 1.6310, 1.6310, 1.6333, 1.6347, 1.6347,
         3.4844, 3.2736, 3.1993, 3.2582, 3.4103, 3.2262, 3.4578, 3.2079, 3.1860,
         1.6398, 1.6323, 1.6305, 1.6338, 1.6367, 1.6128, 1.6380, 1.5774, 1.6039,
         1.3097, 1.3044, 1.2946, 1.3092, 1.3049, 1.2971, 1.3091, 1.3094, 1.3115],
        [1.4576, 1.4530, 1.4091, 1.4133, 1.4510, 1.4575, 1.4559, 1.4576, 1.4576,
         1.4461, 1.4433, 1.4384, 1.4326, 1.4472, 1.4048, 1.4413, 1.4472, 1.4417,
         1.7485, 1.7398, 1.7374, 1.7460, 1.7645, 1.7628, 1.7429, 1.7646, 1.7646,
         1.4753, 1.4793, 1.5172, 1.5118, 1.4806, 1.5157, 1.5040, 1.5172, 1.5141,
         2.1947, 2.1737, 2.1620, 2.1805, 2.2257, 2.2416, 2.2078, 2.3150, 2.3109,
         1.4322, 1.4241, 1.4383, 1.4488, 1.4351, 1.4455, 1.4141, 1.4427, 1.4489],
        [1.3698, 1.2749, 1.2713, 1.2896, 1.2834, 1.2929, 1.2918, 1.2287, 1.2287,
         1.2789, 1.2371, 1.2357, 1.2409, 1.3185, 1.1948, 1.1520, 1.3185, 1.2203,
         1.6058, 1.5835, 1.5647, 1.5629, 1.5845, 1.5812, 1.5988, 1.5860, 1.5860,
         1.3717, 1.3455, 1.3456, 1.3621, 1.3476, 1.3890, 1.3911, 1.3658, 1.3457,
         1.5850, 1.5823, 1.5897, 1.5795, 1.5556, 1.5580, 1.6169, 1.5115, 1.4808,
         3.9237, 3.6084, 3.6771, 3.6665, 3.6695, 3.4119, 3.9164, 3.6477, 3.4404]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 138 : 1781.2047259035687
Test loss for epoch 138 : 193.9097455388175
Test Precision for epoch 138 : 0.26153846153846155
Test Recall for epoch 138 : 0.26153846153846155
Test F1 for epoch 138 : 0.26153846153846155


theta for epoch 139 : tensor([[3.6100, 3.6326, 3.7659, 3.7150, 3.7070, 3.5915, 3.6313, 3.5325, 3.5325,
         1.2698, 1.2426, 1.2409, 1.2459, 1.2942, 1.2246, 1.1778, 1.2942, 1.2272,
         1.5912, 1.5746, 1.6001, 1.5787, 1.5852, 1.5869, 1.5967, 1.5868, 1.5868,
         1.3508, 1.3614, 1.3434, 1.3703, 1.3482, 1.3843, 1.3758, 1.3603, 1.3434,
         1.5852, 1.6038, 1.5904, 1.5869, 1.5946, 1.5856, 1.6054, 1.5557, 1.5606,
         1.2508, 1.2820, 1.2723, 1.2924, 1.2447, 1.2347, 1.2239, 1.3177, 1.2682],
        [1.3735, 1.2249, 1.2153, 1.2570, 1.2575, 1.2694, 1.2634, 1.1697, 1.1697,
         3.6367, 3.6950, 3.5862, 3.8440, 3.6374, 4.0377, 3.5415, 3.6052, 3.9060,
         1.5667, 1.5547, 1.5296, 1.5276, 1.5477, 1.5571, 1.5819, 1.5571, 1.5571,
         1.3526, 1.3204, 1.3148, 1.3701, 1.3139, 1.4059, 1.3869, 1.3571, 1.3117,
         1.5365, 1.5912, 1.5553, 1.5425, 1.5378, 1.5744, 1.5941, 1.4312, 1.5274,
         1.1703, 1.2801, 1.2537, 1.3007, 1.1655, 1.1725, 1.0994, 1.3582, 1.2445],
        [1.4591, 1.4590, 1.4574, 1.4546, 1.4548, 1.4591, 1.4548, 1.4591, 1.4591,
         1.4381, 1.4373, 1.4381, 1.4380, 1.4381, 1.4189, 1.4381, 1.4368, 1.4345,
         2.1943, 2.1951, 2.2122, 2.1882, 2.1686, 2.1671, 2.1963, 2.1660, 2.1660,
         1.5114, 1.5099, 1.5173, 1.5173, 1.5114, 1.5173, 1.5173, 1.5173, 1.5173,
         1.7664, 1.7665, 1.7665, 1.7632, 1.7664, 1.7664, 1.7665, 1.7431, 1.7460,
         1.4459, 1.4509, 1.4509, 1.4509, 1.4423, 1.4509, 1.4464, 1.4509, 1.4509],
        [1.3270, 1.3250, 1.3091, 1.3006, 1.3240, 1.3224, 1.3235, 1.3240, 1.3240,
         1.3039, 1.2971, 1.2933, 1.2927, 1.3047, 1.2888, 1.3000, 1.3043, 1.2763,
         1.6361, 1.6095, 1.6329, 1.6324, 1.6318, 1.6318, 1.6341, 1.6355, 1.6355,
         3.4856, 3.2750, 3.2007, 3.2595, 3.4115, 3.2276, 3.4590, 3.2093, 3.1874,
         1.6395, 1.6321, 1.6303, 1.6335, 1.6364, 1.6125, 1.6378, 1.5771, 1.6036,
         1.3147, 1.3094, 1.2995, 1.3142, 1.3099, 1.3021, 1.3141, 1.3144, 1.3164],
        [1.4619, 1.4573, 1.4134, 1.4176, 1.4553, 1.4618, 1.4602, 1.4619, 1.4619,
         1.4398, 1.4370, 1.4320, 1.4263, 1.4409, 1.3984, 1.4350, 1.4409, 1.4354,
         1.7492, 1.7405, 1.7381, 1.7467, 1.7652, 1.7636, 1.7436, 1.7654, 1.7654,
         1.4782, 1.4822, 1.5201, 1.5147, 1.4835, 1.5186, 1.5070, 1.5202, 1.5171,
         2.1944, 2.1733, 2.1616, 2.1801, 2.2254, 2.2413, 2.2074, 2.3147, 2.3107,
         1.4370, 1.4289, 1.4431, 1.4537, 1.4399, 1.4504, 1.4190, 1.4475, 1.4537],
        [1.3662, 1.2705, 1.2670, 1.2854, 1.2791, 1.2887, 1.2876, 1.2239, 1.2239,
         1.2701, 1.2281, 1.2268, 1.2320, 1.3097, 1.1856, 1.1430, 1.3097, 1.2113,
         1.6027, 1.5804, 1.5615, 1.5596, 1.5814, 1.5781, 1.5957, 1.5829, 1.5829,
         1.3675, 1.3412, 1.3412, 1.3579, 1.3433, 1.3849, 1.3871, 1.3616, 1.3413,
         1.5816, 1.5789, 1.5863, 1.5761, 1.5521, 1.5545, 1.6135, 1.5079, 1.4771,
         3.9360, 3.6189, 3.6880, 3.6773, 3.6805, 3.4218, 3.9288, 3.6584, 3.4504]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 139 : 1780.6649313640573
Test loss for epoch 139 : 194.2585759840387
Test Precision for epoch 139 : 0.26153846153846155
Test Recall for epoch 139 : 0.26153846153846155
Test F1 for epoch 139 : 0.26153846153846155


theta for epoch 140 : tensor([[3.6074, 3.6301, 3.7638, 3.7127, 3.7047, 3.5889, 3.6288, 3.5298, 3.5298,
         1.2642, 1.2367, 1.2349, 1.2401, 1.2887, 1.2184, 1.1713, 1.2887, 1.2212,
         1.5987, 1.5821, 1.6076, 1.5860, 1.5926, 1.5942, 1.6042, 1.5942, 1.5942,
         1.3414, 1.3520, 1.3339, 1.3609, 1.3387, 1.3751, 1.3665, 1.3509, 1.3339,
         1.5896, 1.6083, 1.5948, 1.5913, 1.5991, 1.5901, 1.6099, 1.5601, 1.5651,
         1.2542, 1.2858, 1.2759, 1.2963, 1.2480, 1.2379, 1.2270, 1.3219, 1.2718],
        [1.3553, 1.2062, 1.1966, 1.2384, 1.2389, 1.2508, 1.2448, 1.1508, 1.1508,
         3.6490, 3.7077, 3.5983, 3.8575, 3.6497, 4.0525, 3.5536, 3.6174, 3.9199,
         1.5636, 1.5515, 1.5263, 1.5243, 1.5446, 1.5540, 1.5789, 1.5541, 1.5541,
         1.3330, 1.3008, 1.2953, 1.3506, 1.2943, 1.3864, 1.3674, 1.3376, 1.2921,
         1.5326, 1.5876, 1.5515, 1.5386, 1.5339, 1.5707, 1.5905, 1.4266, 1.5234,
         1.1624, 1.2733, 1.2467, 1.2941, 1.1575, 1.1645, 1.0910, 1.3521, 1.2375],
        [1.4545, 1.4544, 1.4528, 1.4500, 1.4502, 1.4545, 1.4502, 1.4545, 1.4545,
         1.4325, 1.4317, 1.4324, 1.4324, 1.4325, 1.4132, 1.4325, 1.4312, 1.4289,
         2.2012, 2.2020, 2.2191, 2.1948, 2.1752, 2.1737, 2.2029, 2.1725, 2.1725,
         1.5032, 1.5017, 1.5091, 1.5091, 1.5032, 1.5091, 1.5091, 1.5091, 1.5091,
         1.7710, 1.7711, 1.7711, 1.7678, 1.7710, 1.7710, 1.7711, 1.7477, 1.7505,
         1.4499, 1.4549, 1.4549, 1.4549, 1.4463, 1.4549, 1.4504, 1.4548, 1.4549],
        [1.3227, 1.3207, 1.3048, 1.2963, 1.3197, 1.3181, 1.3192, 1.3196, 1.3196,
         1.2984, 1.2915, 1.2877, 1.2872, 1.2992, 1.2832, 1.2944, 1.2988, 1.2707,
         1.6437, 1.6171, 1.6405, 1.6401, 1.6395, 1.6395, 1.6417, 1.6432, 1.6432,
         3.4777, 3.2671, 3.1928, 3.2517, 3.4036, 3.2198, 3.4512, 3.2014, 3.1795,
         1.6442, 1.6368, 1.6350, 1.6382, 1.6411, 1.6173, 1.6425, 1.5818, 1.6084,
         1.3188, 1.3135, 1.3036, 1.3183, 1.3140, 1.3062, 1.3182, 1.3185, 1.3205],
        [1.4573, 1.4527, 1.4086, 1.4129, 1.4506, 1.4572, 1.4556, 1.4573, 1.4573,
         1.4342, 1.4314, 1.4264, 1.4206, 1.4353, 1.3927, 1.4293, 1.4353, 1.4298,
         1.7566, 1.7480, 1.7455, 1.7542, 1.7726, 1.7710, 1.7510, 1.7728, 1.7728,
         1.4700, 1.4739, 1.5119, 1.5065, 1.4753, 1.5104, 1.4988, 1.5120, 1.5089,
         2.1988, 2.1777, 2.1660, 2.1845, 2.2298, 2.2457, 2.2118, 2.3192, 2.3151,
         1.4410, 1.4329, 1.4471, 1.4577, 1.4439, 1.4544, 1.4230, 1.4515, 1.4577],
        [1.3523, 1.2561, 1.2526, 1.2711, 1.2648, 1.2744, 1.2733, 1.2093, 1.2093,
         1.2608, 1.2186, 1.2173, 1.2225, 1.3005, 1.1758, 1.1331, 1.3005, 1.2017,
         1.6049, 1.5825, 1.5636, 1.5617, 1.5835, 1.5802, 1.5979, 1.5850, 1.5850,
         1.3507, 1.3243, 1.3242, 1.3411, 1.3263, 1.3682, 1.3703, 1.3448, 1.3243,
         1.5820, 1.5793, 1.5868, 1.5766, 1.5525, 1.5548, 1.6140, 1.5081, 1.4772,
         3.9508, 3.6320, 3.7014, 3.6906, 3.6939, 3.4343, 3.9436, 3.6716, 3.4629]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 140 : 1779.7979361179835
Test loss for epoch 140 : 194.9873525773933
Test Precision for epoch 140 : 0.26153846153846155
Test Recall for epoch 140 : 0.26153846153846155
Test F1 for epoch 140 : 0.26153846153846155


theta for epoch 141 : tensor([[3.6102, 3.6330, 3.7671, 3.7158, 3.7077, 3.5917, 3.6317, 3.5326, 3.5326,
         1.2593, 1.2315, 1.2298, 1.2350, 1.2840, 1.2130, 1.1657, 1.2840, 1.2160,
         1.6053, 1.5887, 1.6142, 1.5926, 1.5991, 1.6008, 1.6108, 1.6007, 1.6007,
         1.3396, 1.3502, 1.3321, 1.3591, 1.3369, 1.3732, 1.3646, 1.3490, 1.3321,
         1.5946, 1.6134, 1.5999, 1.5963, 1.6042, 1.5952, 1.6151, 1.5652, 1.5701,
         1.2473, 1.2790, 1.2691, 1.2897, 1.2410, 1.2307, 1.2199, 1.3155, 1.2650],
        [1.3376, 1.1873, 1.1777, 1.2197, 1.2203, 1.2322, 1.2261, 1.1316, 1.1316,
         3.6658, 3.7248, 3.6148, 3.8754, 3.6664, 4.0716, 3.5700, 3.6339, 3.9383,
         1.5579, 1.5457, 1.5203, 1.5183, 1.5387, 1.5482, 1.5733, 1.5482, 1.5482,
         1.3158, 1.2834, 1.2778, 1.3334, 1.2768, 1.3695, 1.3504, 1.3203, 1.2746,
         1.5274, 1.5828, 1.5464, 1.5334, 1.5286, 1.5658, 1.5858, 1.4205, 1.5182,
         1.1443, 1.2562, 1.2294, 1.2772, 1.1392, 1.1461, 1.0723, 1.3358, 1.2201],
        [1.4550, 1.4550, 1.4534, 1.4506, 1.4508, 1.4550, 1.4507, 1.4550, 1.4550,
         1.4280, 1.4272, 1.4280, 1.4280, 1.4280, 1.4088, 1.4280, 1.4268, 1.4244,
         2.2077, 2.2086, 2.2257, 2.2010, 2.1815, 2.1800, 2.2091, 2.1788, 2.1788,
         1.5033, 1.5018, 1.5092, 1.5092, 1.5033, 1.5092, 1.5092, 1.5092, 1.5092,
         1.7765, 1.7766, 1.7766, 1.7733, 1.7765, 1.7765, 1.7766, 1.7532, 1.7561,
         1.4439, 1.4489, 1.4489, 1.4489, 1.4403, 1.4489, 1.4445, 1.4489, 1.4489],
        [1.3237, 1.3216, 1.3057, 1.2971, 1.3206, 1.3190, 1.3201, 1.3205, 1.3205,
         1.2940, 1.2871, 1.2833, 1.2828, 1.2949, 1.2788, 1.2900, 1.2944, 1.2663,
         1.6509, 1.6243, 1.6478, 1.6473, 1.6467, 1.6467, 1.6490, 1.6504, 1.6504,
         3.4767, 3.2662, 3.1919, 3.2508, 3.4026, 3.2190, 3.4502, 3.2005, 3.1786,
         1.6499, 1.6424, 1.6406, 1.6438, 1.6468, 1.6229, 1.6481, 1.5875, 1.6140,
         1.3128, 1.3075, 1.2977, 1.3124, 1.3080, 1.3002, 1.3122, 1.3126, 1.3146],
        [1.4579, 1.4532, 1.4091, 1.4134, 1.4512, 1.4578, 1.4562, 1.4579, 1.4579,
         1.4298, 1.4270, 1.4220, 1.4162, 1.4309, 1.3882, 1.4249, 1.4309, 1.4253,
         1.7637, 1.7550, 1.7525, 1.7612, 1.7797, 1.7780, 1.7581, 1.7798, 1.7798,
         1.4700, 1.4740, 1.5120, 1.5065, 1.4753, 1.5105, 1.4989, 1.5120, 1.5089,
         2.2042, 2.1830, 2.1714, 2.1899, 2.2352, 2.2511, 2.2172, 2.3245, 2.3205,
         1.4351, 1.4269, 1.4411, 1.4517, 1.4379, 1.4484, 1.4170, 1.4455, 1.4518],
        [1.3411, 1.2446, 1.2411, 1.2596, 1.2532, 1.2629, 1.2618, 1.1977, 1.1977,
         1.2517, 1.2091, 1.2077, 1.2130, 1.2917, 1.1659, 1.1229, 1.2917, 1.1921,
         1.6058, 1.5833, 1.5642, 1.5623, 1.5843, 1.5810, 1.5988, 1.5858, 1.5858,
         1.3398, 1.3132, 1.3132, 1.3300, 1.3153, 1.3573, 1.3595, 1.3338, 1.3132,
         1.5826, 1.5798, 1.5873, 1.5771, 1.5528, 1.5552, 1.6146, 1.5083, 1.4772,
         3.9635, 3.6429, 3.7126, 3.7017, 3.7052, 3.4447, 3.9563, 3.6827, 3.4733]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 141 : 1779.1487124905236
Test loss for epoch 141 : 195.8785012984055
Test Precision for epoch 141 : 0.26153846153846155
Test Recall for epoch 141 : 0.26153846153846155
Test F1 for epoch 141 : 0.26153846153846155


theta for epoch 142 : tensor([[3.6157, 3.6387, 3.7730, 3.7216, 3.7135, 3.5973, 3.6373, 3.5383, 3.5383,
         1.2559, 1.2283, 1.2265, 1.2317, 1.2804, 1.2095, 1.1628, 1.2804, 1.2128,
         1.6050, 1.5884, 1.6139, 1.5924, 1.5989, 1.6005, 1.6105, 1.6005, 1.6005,
         1.3510, 1.3617, 1.3439, 1.3705, 1.3485, 1.3844, 1.3759, 1.3605, 1.3439,
         1.5968, 1.6156, 1.6021, 1.5985, 1.6063, 1.5973, 1.6172, 1.5673, 1.5723,
         1.2374, 1.2692, 1.2593, 1.2798, 1.2311, 1.2209, 1.2101, 1.3056, 1.2552],
        [1.3493, 1.1985, 1.1889, 1.2311, 1.2316, 1.2436, 1.2375, 1.1426, 1.1426,
         3.6589, 3.7182, 3.6077, 3.8697, 3.6595, 4.0671, 3.5628, 3.6269, 3.9330,
         1.5607, 1.5486, 1.5232, 1.5211, 1.5415, 1.5510, 1.5762, 1.5511, 1.5511,
         1.3281, 1.2956, 1.2899, 1.3459, 1.2890, 1.3821, 1.3629, 1.3327, 1.2868,
         1.5322, 1.5876, 1.5512, 1.5383, 1.5335, 1.5706, 1.5906, 1.4255, 1.5231,
         1.1394, 1.2516, 1.2247, 1.2726, 1.1342, 1.1407, 1.0674, 1.3314, 1.2153],
        [1.4647, 1.4647, 1.4631, 1.4603, 1.4605, 1.4648, 1.4605, 1.4648, 1.4648,
         1.4247, 1.4239, 1.4247, 1.4246, 1.4247, 1.4054, 1.4247, 1.4234, 1.4211,
         2.2074, 2.2083, 2.2254, 2.2007, 2.1812, 2.1797, 2.2088, 2.1785, 2.1785,
         1.5155, 1.5140, 1.5214, 1.5214, 1.5155, 1.5214, 1.5213, 1.5214, 1.5214,
         1.7787, 1.7788, 1.7788, 1.7755, 1.7787, 1.7787, 1.7788, 1.7554, 1.7583,
         1.4343, 1.4393, 1.4393, 1.4393, 1.4307, 1.4393, 1.4349, 1.4393, 1.4393],
        [1.3339, 1.3318, 1.3159, 1.3073, 1.3308, 1.3292, 1.3303, 1.3306, 1.3306,
         1.2907, 1.2838, 1.2800, 1.2795, 1.2916, 1.2755, 1.2867, 1.2911, 1.2630,
         1.6508, 1.6242, 1.6476, 1.6471, 1.6465, 1.6466, 1.6488, 1.6502, 1.6502,
         3.4857, 3.2755, 3.2014, 3.2601, 3.4117, 3.2283, 3.4592, 3.2099, 3.1881,
         1.6521, 1.6447, 1.6429, 1.6461, 1.6490, 1.6252, 1.6504, 1.5897, 1.6163,
         1.3032, 1.2979, 1.2881, 1.3027, 1.2984, 1.2906, 1.3026, 1.3030, 1.3049],
        [1.4675, 1.4629, 1.4189, 1.4232, 1.4609, 1.4675, 1.4659, 1.4676, 1.4676,
         1.4264, 1.4236, 1.4186, 1.4128, 1.4275, 1.3849, 1.4215, 1.4275, 1.4220,
         1.7635, 1.7549, 1.7524, 1.7610, 1.7795, 1.7778, 1.7579, 1.7796, 1.7796,
         1.4823, 1.4862, 1.5242, 1.5187, 1.4876, 1.5226, 1.5111, 1.5242, 1.5211,
         2.2062, 2.1851, 2.1734, 2.1920, 2.2372, 2.2531, 2.2192, 2.3266, 2.3226,
         1.4254, 1.4173, 1.4315, 1.4421, 1.4283, 1.4388, 1.4074, 1.4359, 1.4421],
        [1.3404, 1.2443, 1.2405, 1.2591, 1.2527, 1.2625, 1.2614, 1.1977, 1.1977,
         1.2445, 1.2021, 1.2008, 1.2060, 1.2845, 1.1586, 1.1163, 1.2845, 1.1852,
         1.6009, 1.5782, 1.5592, 1.5573, 1.5793, 1.5760, 1.5938, 1.5809, 1.5809,
         1.3424, 1.3157, 1.3159, 1.3326, 1.3178, 1.3599, 1.3622, 1.3364, 1.3159,
         1.5809, 1.5780, 1.5856, 1.5754, 1.5510, 1.5534, 1.6129, 1.5062, 1.4751,
         3.9715, 3.6492, 3.7192, 3.7082, 3.7119, 3.4503, 3.9644, 3.6891, 3.4790]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 142 : 1779.1675786558003
Test loss for epoch 142 : 195.43642095387574
Test Precision for epoch 142 : 0.26153846153846155
Test Recall for epoch 142 : 0.26153846153846155
Test F1 for epoch 142 : 0.26153846153846155


theta for epoch 143 : tensor([[3.6159, 3.6389, 3.7736, 3.7221, 3.7139, 3.5975, 3.6375, 3.5384, 3.5384,
         1.2580, 1.2310, 1.2293, 1.2343, 1.2821, 1.2120, 1.1667, 1.2821, 1.2156,
         1.6008, 1.5842, 1.6097, 1.5883, 1.5948, 1.5965, 1.6063, 1.5965, 1.5965,
         1.3592, 1.3699, 1.3525, 1.3785, 1.3569, 1.3921, 1.3838, 1.3687, 1.3526,
         1.5955, 1.6142, 1.6008, 1.5972, 1.6050, 1.5960, 1.6158, 1.5661, 1.5710,
         1.2338, 1.2654, 1.2556, 1.2760, 1.2275, 1.2173, 1.2065, 1.3017, 1.2515],
        [1.3711, 1.2206, 1.2110, 1.2531, 1.2536, 1.2656, 1.2595, 1.1648, 1.1648,
         3.6399, 3.6995, 3.5884, 3.8518, 3.6405, 4.0505, 3.5432, 3.6077, 3.9155,
         1.5690, 1.5569, 1.5318, 1.5296, 1.5498, 1.5593, 1.5843, 1.5593, 1.5593,
         1.3504, 1.3181, 1.3122, 1.3681, 1.3114, 1.4043, 1.3851, 1.3550, 1.3091,
         1.5415, 1.5965, 1.5603, 1.5475, 1.5428, 1.5797, 1.5996, 1.4356, 1.5324,
         1.1483, 1.2603, 1.2334, 1.2814, 1.1428, 1.1490, 1.0763, 1.3404, 1.2240],
        [1.4687, 1.4687, 1.4670, 1.4642, 1.4644, 1.4687, 1.4644, 1.4687, 1.4687,
         1.4266, 1.4258, 1.4265, 1.4265, 1.4266, 1.4073, 1.4265, 1.4253, 1.4229,
         2.2033, 2.2041, 2.2212, 2.1967, 2.1772, 2.1757, 2.2048, 2.1745, 2.1745,
         1.5238, 1.5223, 1.5297, 1.5297, 1.5238, 1.5297, 1.5296, 1.5297, 1.5297,
         1.7771, 1.7772, 1.7772, 1.7739, 1.7771, 1.7771, 1.7772, 1.7538, 1.7567,
         1.4303, 1.4353, 1.4353, 1.4353, 1.4267, 1.4353, 1.4309, 1.4353, 1.4353],
        [1.3380, 1.3360, 1.3200, 1.3114, 1.3350, 1.3333, 1.3344, 1.3348, 1.3348,
         1.2926, 1.2858, 1.2819, 1.2814, 1.2935, 1.2774, 1.2887, 1.2930, 1.2649,
         1.6463, 1.6198, 1.6432, 1.6427, 1.6421, 1.6421, 1.6444, 1.6458, 1.6458,
         3.4918, 3.2818, 3.2078, 3.2664, 3.4179, 3.2346, 3.4654, 3.2163, 3.1946,
         1.6505, 1.6431, 1.6413, 1.6445, 1.6474, 1.6236, 1.6488, 1.5881, 1.6147,
         1.2992, 1.2939, 1.2840, 1.2987, 1.2944, 1.2865, 1.2985, 1.2990, 1.3009],
        [1.4715, 1.4669, 1.4227, 1.4271, 1.4648, 1.4714, 1.4698, 1.4716, 1.4716,
         1.4283, 1.4255, 1.4205, 1.4147, 1.4294, 1.3868, 1.4234, 1.4294, 1.4239,
         1.7592, 1.7505, 1.7480, 1.7567, 1.7751, 1.7735, 1.7535, 1.7753, 1.7753,
         1.4906, 1.4946, 1.5325, 1.5270, 1.4959, 1.5309, 1.5194, 1.5325, 1.5294,
         2.2046, 2.1835, 2.1718, 2.1903, 2.2356, 2.2516, 2.2176, 2.3251, 2.3210,
         1.4215, 1.4133, 1.4275, 1.4381, 1.4243, 1.4348, 1.4034, 1.4319, 1.4381],
        [1.3370, 1.2416, 1.2378, 1.2564, 1.2499, 1.2598, 1.2586, 1.1956, 1.1956,
         1.2432, 1.2014, 1.2001, 1.2051, 1.2827, 1.1576, 1.1170, 1.2827, 1.1846,
         1.5930, 1.5703, 1.5512, 1.5493, 1.5714, 1.5680, 1.5859, 1.5729, 1.5729,
         1.3436, 1.3167, 1.3171, 1.3336, 1.3190, 1.3610, 1.3633, 1.3376, 1.3172,
         1.5763, 1.5733, 1.5810, 1.5707, 1.5463, 1.5487, 1.6083, 1.5014, 1.4702,
         3.9798, 3.6557, 3.7260, 3.7150, 3.7188, 3.4563, 3.9727, 3.6957, 3.4850]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 143 : 1780.4468294245248
Test loss for epoch 143 : 194.98754682450328
Test Precision for epoch 143 : 0.26153846153846155
Test Recall for epoch 143 : 0.26153846153846155
Test F1 for epoch 143 : 0.26153846153846155


theta for epoch 144 : tensor([[3.6113, 3.6342, 3.7693, 3.7176, 3.7093, 3.5928, 3.6329, 3.5336, 3.5336,
         1.2671, 1.2405, 1.2388, 1.2437, 1.2907, 1.2214, 1.1773, 1.2907, 1.2253,
         1.5985, 1.5820, 1.6074, 1.5863, 1.5927, 1.5944, 1.6041, 1.5944, 1.5944,
         1.3458, 1.3566, 1.3398, 1.3651, 1.3438, 1.3783, 1.3702, 1.3554, 1.3398,
         1.5932, 1.6118, 1.5985, 1.5949, 1.6027, 1.5937, 1.6134, 1.5638, 1.5687,
         1.2370, 1.2685, 1.2587, 1.2790, 1.2308, 1.2206, 1.2099, 1.3047, 1.2547],
        [1.3776, 1.2279, 1.2184, 1.2602, 1.2607, 1.2726, 1.2666, 1.1724, 1.1724,
         3.6313, 3.6912, 3.5796, 3.8443, 3.6319, 4.0442, 3.5342, 3.5990, 3.9084,
         1.5744, 1.5623, 1.5374, 1.5352, 1.5553, 1.5647, 1.5896, 1.5647, 1.5647,
         1.3528, 1.3206, 1.3147, 1.3704, 1.3140, 1.4064, 1.3873, 1.3573, 1.3115,
         1.5459, 1.6008, 1.5647, 1.5519, 1.5473, 1.5840, 1.6038, 1.4405, 1.5370,
         1.1573, 1.2698, 1.2428, 1.2910, 1.1517, 1.1576, 1.0851, 1.3504, 1.2333],
        [1.4597, 1.4596, 1.4580, 1.4552, 1.4554, 1.4597, 1.4554, 1.4597, 1.4597,
         1.4356, 1.4348, 1.4356, 1.4356, 1.4356, 1.4164, 1.4356, 1.4344, 1.4320,
         2.2012, 2.2021, 2.2192, 2.1947, 2.1752, 2.1737, 2.2029, 2.1725, 2.1725,
         1.5120, 1.5105, 1.5179, 1.5179, 1.5120, 1.5179, 1.5179, 1.5179, 1.5179,
         1.7747, 1.7748, 1.7748, 1.7716, 1.7747, 1.7747, 1.7748, 1.7515, 1.7543,
         1.4337, 1.4387, 1.4387, 1.4387, 1.4301, 1.4387, 1.4343, 1.4386, 1.4387],
        [1.3289, 1.3268, 1.3109, 1.3023, 1.3258, 1.3242, 1.3253, 1.3257, 1.3257,
         1.3017, 1.2949, 1.2911, 1.2905, 1.3025, 1.2865, 1.2978, 1.3021, 1.2740,
         1.6442, 1.6176, 1.6411, 1.6406, 1.6400, 1.6400, 1.6422, 1.6437, 1.6437,
         3.4820, 3.2719, 3.1978, 3.2565, 3.4079, 3.2248, 3.4556, 3.2064, 3.1846,
         1.6482, 1.6407, 1.6389, 1.6421, 1.6451, 1.6212, 1.6464, 1.5858, 1.6123,
         1.3026, 1.2973, 1.2875, 1.3021, 1.2978, 1.2899, 1.3020, 1.3024, 1.3043],
        [1.4625, 1.4578, 1.4136, 1.4180, 1.4558, 1.4624, 1.4608, 1.4625, 1.4625,
         1.4373, 1.4346, 1.4295, 1.4238, 1.4385, 1.3958, 1.4325, 1.4384, 1.4329,
         1.7570, 1.7484, 1.7459, 1.7546, 1.7730, 1.7714, 1.7514, 1.7732, 1.7732,
         1.4787, 1.4827, 1.5207, 1.5152, 1.4840, 1.5191, 1.5076, 1.5207, 1.5176,
         2.2023, 2.1812, 2.1695, 2.1880, 2.2334, 2.2493, 2.2153, 2.3228, 2.3188,
         1.4249, 1.4167, 1.4309, 1.4415, 1.4277, 1.4382, 1.4069, 1.4353, 1.4415],
        [1.3218, 1.2267, 1.2227, 1.2414, 1.2349, 1.2448, 1.2436, 1.1810, 1.1810,
         1.2481, 1.2065, 1.2052, 1.2101, 1.2873, 1.1623, 1.1228, 1.2873, 1.1898,
         1.5865, 1.5637, 1.5447, 1.5426, 1.5648, 1.5614, 1.5794, 1.5663, 1.5663,
         1.3252, 1.2982, 1.2986, 1.3152, 1.3004, 1.3426, 1.3450, 1.3191, 1.2986,
         1.5702, 1.5673, 1.5750, 1.5646, 1.5402, 1.5426, 1.6024, 1.4951, 1.4638,
         3.9939, 3.6680, 3.7386, 3.7275, 3.7315, 3.4681, 3.9868, 3.7081, 3.4968]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 144 : 1779.7682739147142
Test loss for epoch 144 : 195.53727486338468
Test Precision for epoch 144 : 0.26153846153846155
Test Recall for epoch 144 : 0.26153846153846155
Test F1 for epoch 144 : 0.26153846153846155


theta for epoch 145 : tensor([[3.6090, 3.6319, 3.7673, 3.7155, 3.7072, 3.5905, 3.6306, 3.5312, 3.5312,
         1.2771, 1.2510, 1.2494, 1.2541, 1.3003, 1.2318, 1.1891, 1.3003, 1.2360,
         1.5970, 1.5805, 1.6058, 1.5850, 1.5914, 1.5931, 1.6026, 1.5931, 1.5931,
         1.3330, 1.3438, 1.3276, 1.3522, 1.3313, 1.3650, 1.3571, 1.3427, 1.3277,
         1.5894, 1.6079, 1.5946, 1.5910, 1.5988, 1.5897, 1.6094, 1.5599, 1.5648,
         1.2373, 1.2686, 1.2589, 1.2791, 1.2310, 1.2209, 1.2102, 1.3046, 1.2549],
        [1.3769, 1.2283, 1.2187, 1.2604, 1.2609, 1.2728, 1.2668, 1.1733, 1.1733,
         3.6303, 3.6905, 3.5784, 3.8445, 3.6310, 4.0456, 3.5328, 3.5979, 3.9090,
         1.5764, 1.5644, 1.5395, 1.5374, 1.5575, 1.5668, 1.5916, 1.5669, 1.5669,
         1.3499, 1.3179, 1.3120, 1.3674, 1.3113, 1.4033, 1.3843, 1.3544, 1.3088,
         1.5454, 1.6001, 1.5641, 1.5514, 1.5468, 1.5833, 1.6031, 1.4402, 1.5365,
         1.1595, 1.2724, 1.2452, 1.2938, 1.1537, 1.1592, 1.0870, 1.3537, 1.2356],
        [1.4502, 1.4501, 1.4485, 1.4457, 1.4459, 1.4502, 1.4459, 1.4502, 1.4502,
         1.4460, 1.4452, 1.4460, 1.4460, 1.4460, 1.4268, 1.4460, 1.4448, 1.4424,
         2.2003, 2.2012, 2.2183, 2.1938, 2.1743, 2.1728, 2.2020, 2.1716, 2.1716,
         1.5016, 1.5001, 1.5075, 1.5075, 1.5017, 1.5075, 1.5075, 1.5075, 1.5075,
         1.7712, 1.7713, 1.7713, 1.7681, 1.7712, 1.7712, 1.7713, 1.7480, 1.7508,
         1.4349, 1.4398, 1.4398, 1.4398, 1.4313, 1.4398, 1.4355, 1.4398, 1.4398],
        [1.3192, 1.3171, 1.3011, 1.2925, 1.3161, 1.3145, 1.3156, 1.3160, 1.3160,
         1.3121, 1.3053, 1.3015, 1.3009, 1.3129, 1.2970, 1.3083, 1.3125, 1.2845,
         1.6432, 1.6167, 1.6401, 1.6396, 1.6390, 1.6390, 1.6413, 1.6427, 1.6427,
         3.4735, 3.2635, 3.1893, 3.2481, 3.3995, 3.2164, 3.4472, 3.1979, 3.1760,
         1.6446, 1.6372, 1.6354, 1.6386, 1.6415, 1.6177, 1.6429, 1.5823, 1.6088,
         1.3037, 1.2984, 1.2886, 1.3033, 1.2989, 1.2910, 1.3031, 1.3035, 1.3055],
        [1.4531, 1.4483, 1.4040, 1.4083, 1.4463, 1.4530, 1.4513, 1.4531, 1.4531,
         1.4477, 1.4449, 1.4399, 1.4342, 1.4488, 1.4063, 1.4429, 1.4488, 1.4433,
         1.7561, 1.7474, 1.7451, 1.7537, 1.7721, 1.7705, 1.7505, 1.7723, 1.7723,
         1.4683, 1.4723, 1.5103, 1.5049, 1.4736, 1.5088, 1.4972, 1.5104, 1.5073,
         2.1989, 2.1777, 2.1660, 2.1846, 2.2299, 2.2459, 2.2119, 2.3194, 2.3154,
         1.4261, 1.4179, 1.4321, 1.4426, 1.4289, 1.4393, 1.4081, 1.4365, 1.4427],
        [1.3066, 1.2109, 1.2069, 1.2257, 1.2191, 1.2291, 1.2280, 1.1649, 1.1649,
         1.2540, 1.2124, 1.2111, 1.2159, 1.2933, 1.1677, 1.1285, 1.2933, 1.1956,
         1.5808, 1.5578, 1.5389, 1.5364, 1.5588, 1.5553, 1.5737, 1.5603, 1.5603,
         1.3078, 1.2807, 1.2807, 1.2978, 1.2828, 1.3256, 1.3278, 1.3016, 1.2807,
         1.5623, 1.5596, 1.5672, 1.5568, 1.5324, 1.5349, 1.5950, 1.4870, 1.4557,
         4.0082, 3.6806, 3.7515, 3.7403, 3.7445, 3.4801, 4.0012, 3.7208, 3.5089]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 145 : 1780.4246133291958
Test loss for epoch 145 : 196.43693829737092
Test Precision for epoch 145 : 0.26153846153846155
Test Recall for epoch 145 : 0.26153846153846155
Test F1 for epoch 145 : 0.26153846153846155


theta for epoch 146 : tensor([[3.6158, 3.6389, 3.7745, 3.7226, 3.7142, 3.5974, 3.6375, 3.5382, 3.5382,
         1.2793, 1.2537, 1.2522, 1.2566, 1.3019, 1.2344, 1.1932, 1.3019, 1.2389,
         1.5966, 1.5802, 1.6054, 1.5849, 1.5913, 1.5930, 1.6022, 1.5930, 1.5930,
         1.3358, 1.3467, 1.3312, 1.3549, 1.3345, 1.3672, 1.3596, 1.3456, 1.3312,
         1.5868, 1.6051, 1.5920, 1.5884, 1.5961, 1.5870, 1.6066, 1.5572, 1.5622,
         1.2286, 1.2598, 1.2502, 1.2702, 1.2224, 1.2124, 1.2027, 1.2957, 1.2462],
        [1.3789, 1.2314, 1.2216, 1.2634, 1.2639, 1.2758, 1.2697, 1.1772, 1.1772,
         3.6321, 3.6925, 3.5799, 3.8474, 3.6327, 4.0496, 3.5342, 3.5995, 3.9122,
         1.5762, 1.5642, 1.5392, 1.5373, 1.5575, 1.5668, 1.5914, 1.5668, 1.5668,
         1.3524, 1.3204, 1.3148, 1.3699, 1.3138, 1.4057, 1.3867, 1.3569, 1.3116,
         1.5432, 1.5977, 1.5619, 1.5491, 1.5445, 1.5810, 1.6007, 1.4380, 1.5343,
         1.1511, 1.2645, 1.2372, 1.2860, 1.1451, 1.1503, 1.0804, 1.3465, 1.2275],
        [1.4539, 1.4538, 1.4522, 1.4494, 1.4496, 1.4539, 1.4496, 1.4539, 1.4539,
         1.4487, 1.4479, 1.4487, 1.4486, 1.4487, 1.4295, 1.4487, 1.4474, 1.4451,
         2.2008, 2.2016, 2.2187, 2.1943, 2.1748, 2.1732, 2.2024, 2.1721, 2.1721,
         1.5069, 1.5054, 1.5128, 1.5128, 1.5069, 1.5128, 1.5128, 1.5128, 1.5128,
         1.7691, 1.7692, 1.7692, 1.7660, 1.7691, 1.7691, 1.7692, 1.7459, 1.7487,
         1.4278, 1.4327, 1.4327, 1.4328, 1.4242, 1.4327, 1.4284, 1.4327, 1.4327],
        [1.3228, 1.3207, 1.3047, 1.2961, 1.3197, 1.3181, 1.3192, 1.3196, 1.3196,
         1.3147, 1.3080, 1.3041, 1.3036, 1.3155, 1.2996, 1.3110, 1.3151, 1.2872,
         1.6437, 1.6171, 1.6406, 1.6401, 1.6395, 1.6395, 1.6417, 1.6432, 1.6432,
         3.4781, 3.2683, 3.1942, 3.2529, 3.4041, 3.2212, 3.4518, 3.2027, 3.1809,
         1.6425, 1.6350, 1.6332, 1.6364, 1.6394, 1.6155, 1.6407, 1.5801, 1.6066,
         1.2965, 1.2912, 1.2813, 1.2960, 1.2916, 1.2838, 1.2958, 1.2963, 1.2982],
        [1.4567, 1.4520, 1.4077, 1.4120, 1.4499, 1.4566, 1.4550, 1.4567, 1.4567,
         1.4504, 1.4476, 1.4426, 1.4369, 1.4515, 1.4090, 1.4455, 1.4515, 1.4460,
         1.7567, 1.7480, 1.7456, 1.7543, 1.7726, 1.7710, 1.7510, 1.7728, 1.7728,
         1.4735, 1.4777, 1.5156, 1.5101, 1.4788, 1.5141, 1.5024, 1.5156, 1.5125,
         2.1968, 2.1756, 2.1639, 2.1825, 2.2278, 2.2438, 2.2098, 2.3173, 2.3133,
         1.4191, 1.4108, 1.4250, 1.4356, 1.4219, 1.4322, 1.4011, 1.4294, 1.4356],
        [1.3117, 1.2146, 1.2107, 1.2296, 1.2230, 1.2331, 1.2319, 1.1678, 1.1678,
         1.2559, 1.2140, 1.2127, 1.2176, 1.2954, 1.1689, 1.1296, 1.2954, 1.1971,
         1.5804, 1.5572, 1.5385, 1.5353, 1.5578, 1.5544, 1.5731, 1.5593, 1.5593,
         1.3120, 1.2848, 1.2841, 1.3022, 1.2866, 1.3305, 1.3325, 1.3058, 1.2841,
         1.5588, 1.5565, 1.5637, 1.5533, 1.5290, 1.5317, 1.5920, 1.4835, 1.4521,
         4.0095, 3.6801, 3.7513, 3.7400, 3.7444, 3.4790, 4.0024, 3.7204, 3.5078]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 146 : 1780.062183161061
Test loss for epoch 146 : 196.23946556104795
Test Precision for epoch 146 : 0.26153846153846155
Test Recall for epoch 146 : 0.26153846153846155
Test F1 for epoch 146 : 0.26153846153846155


theta for epoch 147 : tensor([[3.6262, 3.6496, 3.7854, 3.7334, 3.7248, 3.6080, 3.6482, 3.5490, 3.5490,
         1.2712, 1.2463, 1.2448, 1.2491, 1.2933, 1.2268, 1.1873, 1.2933, 1.2317,
         1.5974, 1.5811, 1.6061, 1.5861, 1.5925, 1.5941, 1.6031, 1.5941, 1.5941,
         1.3473, 1.3583, 1.3436, 1.3663, 1.3463, 1.3781, 1.3707, 1.3573, 1.3436,
         1.5873, 1.6055, 1.5926, 1.5890, 1.5966, 1.5874, 1.6068, 1.5578, 1.5627,
         1.2213, 1.2523, 1.2428, 1.2627, 1.2151, 1.2051, 1.1974, 1.2882, 1.2388],
        [1.3787, 1.2325, 1.2224, 1.2643, 1.2647, 1.2767, 1.2706, 1.1792, 1.1792,
         3.6350, 3.6958, 3.5826, 3.8514, 3.6356, 4.0549, 3.5367, 3.6022, 3.9167,
         1.5740, 1.5621, 1.5369, 1.5353, 1.5555, 1.5649, 1.5893, 1.5649, 1.5649,
         1.3563, 1.3242, 1.3190, 1.3739, 1.3178, 1.4095, 1.3906, 1.3610, 1.3159,
         1.5412, 1.5957, 1.5600, 1.5472, 1.5425, 1.5790, 1.5985, 1.4357, 1.5323,
         1.1404, 1.2543, 1.2268, 1.2760, 1.1342, 1.1391, 1.0731, 1.3371, 1.2170],
        [1.4620, 1.4619, 1.4603, 1.4575, 1.4577, 1.4620, 1.4576, 1.4620, 1.4620,
         1.4413, 1.4405, 1.4413, 1.4412, 1.4413, 1.4221, 1.4413, 1.4400, 1.4377,
         2.2026, 2.2034, 2.2204, 2.1959, 2.1764, 2.1749, 2.2041, 2.1738, 2.1738,
         1.5209, 1.5193, 1.5268, 1.5267, 1.5209, 1.5267, 1.5267, 1.5267, 1.5268,
         1.7703, 1.7704, 1.7704, 1.7671, 1.7703, 1.7703, 1.7704, 1.7471, 1.7499,
         1.4225, 1.4274, 1.4274, 1.4274, 1.4189, 1.4274, 1.4231, 1.4274, 1.4274],
        [1.3307, 1.3287, 1.3127, 1.3041, 1.3277, 1.3261, 1.3272, 1.3277, 1.3277,
         1.3073, 1.3005, 1.2967, 1.2961, 1.3081, 1.2921, 1.3035, 1.3076, 1.2797,
         1.6455, 1.6189, 1.6424, 1.6419, 1.6413, 1.6413, 1.6435, 1.6450, 1.6450,
         3.4901, 3.2805, 3.2066, 3.2651, 3.4162, 3.2335, 3.4638, 3.2151, 3.1934,
         1.6435, 1.6361, 1.6343, 1.6375, 1.6405, 1.6166, 1.6418, 1.5812, 1.6077,
         1.2909, 1.2856, 1.2758, 1.2904, 1.2860, 1.2782, 1.2904, 1.2907, 1.2926],
        [1.4648, 1.4602, 1.4158, 1.4201, 1.4580, 1.4647, 1.4631, 1.4648, 1.4648,
         1.4430, 1.4402, 1.4352, 1.4295, 1.4441, 1.4017, 1.4381, 1.4441, 1.4386,
         1.7586, 1.7498, 1.7476, 1.7562, 1.7745, 1.7729, 1.7529, 1.7747, 1.7747,
         1.4875, 1.4918, 1.5295, 1.5241, 1.4929, 1.5280, 1.5164, 1.5295, 1.5265,
         2.1978, 2.1766, 2.1650, 2.1836, 2.2289, 2.2449, 2.2109, 2.3184, 2.3143,
         1.4138, 1.4054, 1.4197, 1.4302, 1.4166, 1.4269, 1.3959, 1.4241, 1.4302],
        [1.3273, 1.2283, 1.2245, 1.2437, 1.2371, 1.2472, 1.2460, 1.1804, 1.1804,
         1.2508, 1.2085, 1.2073, 1.2122, 1.2907, 1.1630, 1.1232, 1.2907, 1.1915,
         1.5843, 1.5610, 1.5425, 1.5386, 1.5611, 1.5577, 1.5770, 1.5627, 1.5627,
         1.3300, 1.3025, 1.3009, 1.3202, 1.3041, 1.3492, 1.3509, 1.3236, 1.3010,
         1.5609, 1.5591, 1.5658, 1.5554, 1.5313, 1.5342, 1.5947, 1.4856, 1.4544,
         4.0045, 3.6732, 3.7447, 3.7333, 3.7379, 3.4715, 3.9971, 3.7136, 3.5003]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 147 : 1780.0006311238496
Test loss for epoch 147 : 195.58592129816483
Test Precision for epoch 147 : 0.26153846153846155
Test Recall for epoch 147 : 0.26153846153846155
Test F1 for epoch 147 : 0.26153846153846155


theta for epoch 148 : tensor([[3.6314, 3.6548, 3.7909, 3.7388, 3.7301, 3.6132, 3.6534, 3.5543, 3.5543,
         1.2623, 1.2380, 1.2365, 1.2406, 1.2839, 1.2184, 1.1805, 1.2839, 1.2236,
         1.5996, 1.5834, 1.6083, 1.5886, 1.5950, 1.5967, 1.6053, 1.5966, 1.5966,
         1.3453, 1.3565, 1.3424, 1.3642, 1.3447, 1.3756, 1.3685, 1.3554, 1.3424,
         1.5914, 1.6094, 1.5967, 1.5931, 1.6006, 1.5913, 1.6106, 1.5618, 1.5667,
         1.2232, 1.2541, 1.2446, 1.2646, 1.2170, 1.2070, 1.2010, 1.2900, 1.2406],
        [1.3654, 1.2211, 1.2107, 1.2525, 1.2530, 1.2650, 1.2589, 1.1690, 1.1690,
         3.6431, 3.7042, 3.5905, 3.8606, 3.6437, 4.0653, 3.5445, 3.6102, 3.9263,
         1.5698, 1.5579, 1.5325, 1.5314, 1.5517, 1.5611, 1.5852, 1.5611, 1.5611,
         1.3472, 1.3150, 1.3103, 1.3647, 1.3087, 1.4001, 1.3813, 1.3519, 1.3072,
         1.5397, 1.5941, 1.5585, 1.5457, 1.5409, 1.5774, 1.5968, 1.4336, 1.5307,
         1.1332, 1.2480, 1.2202, 1.2700, 1.1267, 1.1314, 1.0687, 1.3318, 1.2103],
        [1.4578, 1.4577, 1.4561, 1.4533, 1.4535, 1.4578, 1.4534, 1.4578, 1.4578,
         1.4332, 1.4324, 1.4332, 1.4332, 1.4332, 1.4140, 1.4332, 1.4320, 1.4296,
         2.2059, 2.2067, 2.2237, 2.1990, 2.1796, 2.1781, 2.2072, 2.1769, 2.1769,
         1.5221, 1.5205, 1.5280, 1.5280, 1.5221, 1.5280, 1.5279, 1.5280, 1.5280,
         1.7751, 1.7752, 1.7752, 1.7720, 1.7751, 1.7751, 1.7752, 1.7520, 1.7548,
         1.4268, 1.4317, 1.4317, 1.4317, 1.4232, 1.4317, 1.4274, 1.4316, 1.4317],
        [1.3260, 1.3241, 1.3081, 1.2994, 1.3231, 1.3215, 1.3226, 1.3231, 1.3231,
         1.2991, 1.2923, 1.2885, 1.2879, 1.2999, 1.2840, 1.2954, 1.2994, 1.2715,
         1.6489, 1.6224, 1.6458, 1.6453, 1.6447, 1.6447, 1.6470, 1.6484, 1.6484,
         3.4920, 3.2826, 3.2087, 3.2672, 3.4181, 3.2355, 3.4657, 3.2171, 3.1955,
         1.6483, 1.6409, 1.6391, 1.6423, 1.6452, 1.6214, 1.6466, 1.5860, 1.6125,
         1.2950, 1.2897, 1.2799, 1.2946, 1.2901, 1.2823, 1.2945, 1.2948, 1.2967],
        [1.4606, 1.4560, 1.4117, 1.4158, 1.4538, 1.4605, 1.4589, 1.4606, 1.4606,
         1.4349, 1.4322, 1.4271, 1.4215, 1.4361, 1.3936, 1.4301, 1.4361, 1.4306,
         1.7621, 1.7533, 1.7511, 1.7597, 1.7780, 1.7764, 1.7564, 1.7781, 1.7781,
         1.4888, 1.4931, 1.5307, 1.5254, 1.4941, 1.5292, 1.5176, 1.5308, 1.5277,
         2.2025, 2.1813, 2.1697, 2.1882, 2.2335, 2.2495, 2.2156, 2.3229, 2.3189,
         1.4182, 1.4098, 1.4240, 1.4345, 1.4209, 1.4312, 1.4003, 1.4284, 1.4345],
        [1.3308, 1.2293, 1.2258, 1.2452, 1.2386, 1.2487, 1.2476, 1.1801, 1.1801,
         1.2443, 1.2013, 1.2001, 1.2051, 1.2847, 1.1555, 1.1148, 1.2847, 1.1842,
         1.5887, 1.5652, 1.5469, 1.5422, 1.5648, 1.5614, 1.5813, 1.5664, 1.5664,
         1.3346, 1.3069, 1.3043, 1.3250, 1.3081, 1.3548, 1.3561, 1.3280, 1.3043,
         1.5656, 1.5644, 1.5706, 1.5602, 1.5361, 1.5394, 1.6002, 1.4903, 1.4592,
         4.0072, 3.6739, 3.7458, 3.7343, 3.7392, 3.4718, 3.9995, 3.7144, 3.5005]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 148 : 1779.3990378164403
Test loss for epoch 148 : 195.55189851286696
Test Precision for epoch 148 : 0.26153846153846155
Test Recall for epoch 148 : 0.26153846153846155
Test F1 for epoch 148 : 0.26153846153846155


theta for epoch 149 : tensor([[3.6351, 3.6586, 3.7950, 3.7428, 3.7340, 3.6170, 3.6573, 3.5581, 3.5581,
         1.2566, 1.2329, 1.2314, 1.2353, 1.2777, 1.2132, 1.1767, 1.2777, 1.2186,
         1.5999, 1.5838, 1.6086, 1.5893, 1.5956, 1.5973, 1.6057, 1.5973, 1.5973,
         1.3303, 1.3416, 1.3281, 1.3492, 1.3300, 1.3602, 1.3532, 1.3406, 1.3281,
         1.5953, 1.6130, 1.6006, 1.5970, 1.6044, 1.5951, 1.6143, 1.5656, 1.5706,
         1.2317, 1.2625, 1.2530, 1.2729, 1.2255, 1.2155, 1.2110, 1.2984, 1.2490],
        [1.3448, 1.2024, 1.1917, 1.2335, 1.2339, 1.2460, 1.2399, 1.1515, 1.1515,
         3.6573, 3.7187, 3.6045, 3.8759, 3.6579, 4.0818, 3.5584, 3.6242, 3.9420,
         1.5613, 1.5496, 1.5238, 1.5231, 1.5436, 1.5531, 1.5770, 1.5531, 1.5531,
         1.3258, 1.2937, 1.2895, 1.3433, 1.2876, 1.3784, 1.3597, 1.3306, 1.2864,
         1.5355, 1.5899, 1.5545, 1.5416, 1.5366, 1.5732, 1.5926, 1.4287, 1.5264,
         1.1278, 1.2439, 1.2157, 1.2662, 1.1212, 1.1257, 1.0655, 1.3290, 1.2057],
        [1.4488, 1.4488, 1.4471, 1.4443, 1.4446, 1.4488, 1.4445, 1.4488, 1.4488,
         1.4285, 1.4277, 1.4285, 1.4284, 1.4285, 1.4093, 1.4285, 1.4272, 1.4249,
         2.2077, 2.2084, 2.2255, 2.2007, 2.1813, 2.1798, 2.2090, 2.1787, 2.1787,
         1.5108, 1.5093, 1.5167, 1.5167, 1.5108, 1.5167, 1.5167, 1.5167, 1.5167,
         1.7800, 1.7801, 1.7801, 1.7768, 1.7800, 1.7800, 1.7801, 1.7569, 1.7597,
         1.4379, 1.4427, 1.4427, 1.4427, 1.4343, 1.4427, 1.4385, 1.4427, 1.4427],
        [1.3165, 1.3146, 1.2985, 1.2898, 1.3136, 1.3119, 1.3131, 1.3136, 1.3136,
         1.2942, 1.2875, 1.2837, 1.2831, 1.2950, 1.2791, 1.2906, 1.2946, 1.2667,
         1.6507, 1.6241, 1.6475, 1.6471, 1.6464, 1.6465, 1.6487, 1.6502, 1.6502,
         3.4841, 3.2746, 3.2006, 3.2592, 3.4101, 3.2276, 3.4578, 3.2091, 3.1874,
         1.6531, 1.6456, 1.6438, 1.6470, 1.6500, 1.6261, 1.6513, 1.5908, 1.6173,
         1.3059, 1.3006, 1.2908, 1.3055, 1.3010, 1.2932, 1.3055, 1.3058, 1.3076],
        [1.4517, 1.4471, 1.4027, 1.4068, 1.4449, 1.4516, 1.4500, 1.4517, 1.4517,
         1.4302, 1.4274, 1.4224, 1.4168, 1.4314, 1.3890, 1.4253, 1.4313, 1.4259,
         1.7640, 1.7552, 1.7531, 1.7617, 1.7799, 1.7783, 1.7583, 1.7800, 1.7800,
         1.4774, 1.4818, 1.5195, 1.5142, 1.4828, 1.5180, 1.5064, 1.5195, 1.5164,
         2.2071, 2.1859, 2.1743, 2.1928, 2.2380, 2.2541, 2.2202, 2.3274, 2.3234,
         1.4294, 1.4208, 1.4351, 1.4455, 1.4321, 1.4422, 1.4116, 1.4394, 1.4456],
        [1.3284, 1.2241, 1.2209, 1.2406, 1.2339, 1.2442, 1.2430, 1.1734, 1.1734,
         1.2401, 1.1963, 1.1951, 1.2003, 1.2812, 1.1500, 1.1080, 1.2812, 1.1789,
         1.5905, 1.5667, 1.5487, 1.5431, 1.5658, 1.5623, 1.5830, 1.5674, 1.5674,
         1.3261, 1.2983, 1.2944, 1.3168, 1.2991, 1.3474, 1.3482, 1.3194, 1.2945,
         1.5694, 1.5687, 1.5743, 1.5639, 1.5400, 1.5435, 1.6048, 1.4939, 1.4629,
         4.0160, 3.6809, 3.7531, 3.7415, 3.7466, 3.4783, 4.0082, 3.7215, 3.5070]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 149 : 1778.6612889477008
Test loss for epoch 149 : 196.1340944851227
Test Precision for epoch 149 : 0.26153846153846155
Test Recall for epoch 149 : 0.26153846153846155
Test F1 for epoch 149 : 0.26153846153846155


theta for epoch 150 : tensor([[3.6376, 3.6612, 3.7978, 3.7455, 3.7366, 3.6196, 3.6598, 3.5607, 3.5607,
         1.2544, 1.2316, 1.2302, 1.2338, 1.2748, 1.2118, 1.1774, 1.2748, 1.2176,
         1.5974, 1.5814, 1.6060, 1.5872, 1.5934, 1.5951, 1.6032, 1.5951, 1.5951,
         1.3274, 1.3387, 1.3259, 1.3461, 1.3274, 1.3567, 1.3500, 1.3377, 1.3259,
         1.5949, 1.6124, 1.6002, 1.5966, 1.6039, 1.5945, 1.6136, 1.5652, 1.5702,
         1.2373, 1.2675, 1.2583, 1.2778, 1.2312, 1.2214, 1.2181, 1.3028, 1.2543],
        [1.3392, 1.1987, 1.1877, 1.2295, 1.2299, 1.2421, 1.2359, 1.1491, 1.1491,
         3.6624, 3.7241, 3.6094, 3.8821, 3.6630, 4.0892, 3.5632, 3.6292, 3.9487,
         1.5559, 1.5443, 1.5183, 1.5181, 1.5386, 1.5481, 1.5716, 1.5481, 1.5481,
         1.3196, 1.2875, 1.2840, 1.3370, 1.2816, 1.3718, 1.3533, 1.3246, 1.2808,
         1.5323, 1.5865, 1.5513, 1.5384, 1.5333, 1.5698, 1.5890, 1.4251, 1.5231,
         1.1271, 1.2428, 1.2149, 1.2650, 1.1206, 1.1252, 1.0673, 1.3275, 1.2048],
        [1.4485, 1.4484, 1.4467, 1.4439, 1.4442, 1.4485, 1.4441, 1.4484, 1.4484,
         1.4264, 1.4256, 1.4264, 1.4263, 1.4264, 1.4072, 1.4264, 1.4251, 1.4228,
         2.2057, 2.2064, 2.2235, 2.1988, 2.1794, 2.1779, 2.2071, 2.1768, 2.1768,
         1.5090, 1.5074, 1.5149, 1.5149, 1.5090, 1.5149, 1.5149, 1.5149, 1.5149,
         1.7796, 1.7797, 1.7797, 1.7764, 1.7796, 1.7796, 1.7797, 1.7566, 1.7593,
         1.4441, 1.4489, 1.4489, 1.4489, 1.4405, 1.4489, 1.4447, 1.4489, 1.4489],
        [1.3156, 1.3139, 1.2978, 1.2891, 1.3128, 1.3111, 1.3123, 1.3129, 1.3129,
         1.2920, 1.2853, 1.2815, 1.2809, 1.2928, 1.2769, 1.2884, 1.2923, 1.2645,
         1.6483, 1.6218, 1.6452, 1.6448, 1.6441, 1.6441, 1.6464, 1.6478, 1.6478,
         3.4839, 3.2745, 3.2006, 3.2591, 3.4100, 3.2275, 3.4578, 3.2091, 3.1873,
         1.6526, 1.6451, 1.6433, 1.6465, 1.6495, 1.6257, 1.6508, 1.5903, 1.6168,
         1.3120, 1.3067, 1.2969, 1.3115, 1.3071, 1.2992, 1.3116, 1.3118, 1.3137],
        [1.4513, 1.4468, 1.4025, 1.4065, 1.4445, 1.4512, 1.4497, 1.4513, 1.4513,
         1.4281, 1.4254, 1.4203, 1.4147, 1.4293, 1.3870, 1.4232, 1.4292, 1.4238,
         1.7618, 1.7531, 1.7510, 1.7596, 1.7777, 1.7762, 1.7562, 1.7779, 1.7779,
         1.4756, 1.4801, 1.5176, 1.5123, 1.4810, 1.5162, 1.5045, 1.5177, 1.5146,
         2.2066, 2.1855, 2.1739, 2.1924, 2.2376, 2.2537, 2.2198, 2.3269, 2.3229,
         1.4357, 1.4271, 1.4413, 1.4517, 1.4384, 1.4484, 1.4180, 1.4456, 1.4518],
        [1.3496, 1.2439, 1.2409, 1.2606, 1.2541, 1.2642, 1.2630, 1.1923, 1.1923,
         1.2457, 1.2019, 1.2007, 1.2058, 1.2869, 1.1554, 1.1135, 1.2869, 1.1845,
         1.5977, 1.5738, 1.5562, 1.5498, 1.5724, 1.5689, 1.5902, 1.5740, 1.5740,
         1.3415, 1.3138, 1.3089, 1.3324, 1.3142, 1.3635, 1.3639, 1.3347, 1.3090,
         1.5757, 1.5757, 1.5807, 1.5703, 1.5467, 1.5505, 1.6118, 1.5006, 1.4699,
         4.0002, 3.6633, 3.7358, 3.7241, 3.7293, 3.4600, 3.9922, 3.7041, 3.4888]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 150 : 1778.5927323660546
Test loss for epoch 150 : 195.83332012691756
Test Precision for epoch 150 : 0.26153846153846155
Test Recall for epoch 150 : 0.26153846153846155
Test F1 for epoch 150 : 0.26153846153846155


theta for epoch 151 : tensor([[3.6387, 3.6623, 3.7991, 3.7467, 3.7378, 3.6206, 3.6609, 3.5618, 3.5617,
         1.2553, 1.2335, 1.2322, 1.2354, 1.2747, 1.2138, 1.1818, 1.2748, 1.2198,
         1.5942, 1.5783, 1.6027, 1.5844, 1.5906, 1.5923, 1.6001, 1.5922, 1.5922,
         1.3350, 1.3464, 1.3342, 1.3536, 1.3353, 1.3638, 1.3573, 1.3454, 1.3342,
         1.5908, 1.6081, 1.5961, 1.5925, 1.5997, 1.5902, 1.6091, 1.5611, 1.5660,
         1.2388, 1.2684, 1.2594, 1.2785, 1.2329, 1.2233, 1.2209, 1.3030, 1.2555],
        [1.3477, 1.2092, 1.1980, 1.2397, 1.2400, 1.2522, 1.2461, 1.1607, 1.1607,
         3.6559, 3.7178, 3.6026, 3.8767, 3.6565, 4.0849, 3.5562, 3.6225, 3.9436,
         1.5574, 1.5459, 1.5199, 1.5200, 1.5405, 1.5500, 1.5731, 1.5500, 1.5500,
         1.3303, 1.2983, 1.2952, 1.3477, 1.2925, 1.3821, 1.3638, 1.3354, 1.2920,
         1.5323, 1.5861, 1.5513, 1.5384, 1.5332, 1.5695, 1.5884, 1.4254, 1.5231,
         1.1315, 1.2464, 1.2187, 1.2684, 1.1250, 1.1298, 1.0739, 1.3304, 1.2088],
        [1.4515, 1.4514, 1.4497, 1.4469, 1.4472, 1.4514, 1.4471, 1.4514, 1.4514,
         1.4268, 1.4260, 1.4268, 1.4268, 1.4268, 1.4077, 1.4268, 1.4256, 1.4233,
         2.2025, 2.2032, 2.2203, 2.1957, 2.1764, 2.1748, 2.2040, 2.1737, 2.1737,
         1.5160, 1.5145, 1.5219, 1.5219, 1.5160, 1.5219, 1.5219, 1.5219, 1.5219,
         1.7750, 1.7751, 1.7751, 1.7719, 1.7750, 1.7750, 1.7751, 1.7520, 1.7548,
         1.4454, 1.4501, 1.4501, 1.4501, 1.4417, 1.4501, 1.4460, 1.4501, 1.4501],
        [1.3182, 1.3165, 1.3004, 1.2917, 1.3155, 1.3138, 1.3149, 1.3156, 1.3156,
         1.2923, 1.2856, 1.2818, 1.2812, 1.2930, 1.2773, 1.2888, 1.2926, 1.2649,
         1.6446, 1.6181, 1.6415, 1.6411, 1.6405, 1.6405, 1.6427, 1.6442, 1.6442,
         3.4912, 3.2820, 3.2082, 3.2666, 3.4173, 3.2350, 3.4651, 3.2166, 3.1949,
         1.6478, 1.6404, 1.6386, 1.6418, 1.6447, 1.6209, 1.6461, 1.5856, 1.6121,
         1.3130, 1.3077, 1.2979, 1.3125, 1.3081, 1.3003, 1.3127, 1.3127, 1.3147],
        [1.4543, 1.4498, 1.4056, 1.4095, 1.4475, 1.4542, 1.4527, 1.4543, 1.4543,
         1.4285, 1.4258, 1.4207, 1.4152, 1.4297, 1.3875, 1.4237, 1.4297, 1.4242,
         1.7584, 1.7497, 1.7477, 1.7562, 1.7743, 1.7728, 1.7527, 1.7745, 1.7745,
         1.4826, 1.4872, 1.5247, 1.5194, 1.4880, 1.5232, 1.5115, 1.5247, 1.5216,
         2.2021, 2.1810, 2.1694, 2.1879, 2.2331, 2.2492, 2.2154, 2.3224, 2.3184,
         1.4370, 1.4283, 1.4426, 1.4529, 1.4397, 1.4496, 1.4194, 1.4469, 1.4530],
        [1.3720, 1.2657, 1.2628, 1.2825, 1.2760, 1.2862, 1.2850, 1.2136, 1.2136,
         1.2534, 1.2100, 1.2089, 1.2138, 1.2942, 1.1634, 1.1226, 1.2942, 1.1927,
         1.6034, 1.5794, 1.5621, 1.5550, 1.5775, 1.5741, 1.5958, 1.5791, 1.5791,
         1.3641, 1.3365, 1.3309, 1.3552, 1.3367, 1.3866, 1.3867, 1.3573, 1.3310,
         1.5777, 1.5782, 1.5827, 1.5723, 1.5490, 1.5530, 1.6143, 1.5030, 1.4726,
         3.9830, 3.6443, 3.7171, 3.7054, 3.7107, 3.4403, 3.9749, 3.6853, 3.4692]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 151 : 1779.0374047196444
Test loss for epoch 151 : 195.22042440637048
Test Precision for epoch 151 : 0.26153846153846155
Test Recall for epoch 151 : 0.26153846153846155
Test F1 for epoch 151 : 0.26153846153846155


theta for epoch 152 : tensor([[3.6302, 3.6536, 3.7908, 3.7383, 3.7293, 3.6120, 3.6523, 3.5529, 3.5529,
         1.2603, 1.2398, 1.2385, 1.2414, 1.2787, 1.2201, 1.1911, 1.2787, 1.2265,
         1.5945, 1.5787, 1.6030, 1.5850, 1.5912, 1.5929, 1.6004, 1.5929, 1.5929,
         1.3373, 1.3488, 1.3370, 1.3558, 1.3378, 1.3657, 1.3594, 1.3478, 1.3370,
         1.5886, 1.6056, 1.5938, 1.5902, 1.5973, 1.5878, 1.6065, 1.5588, 1.5637,
         1.2422, 1.2712, 1.2623, 1.2811, 1.2364, 1.2271, 1.2253, 1.3051, 1.2586],
        [1.3636, 1.2273, 1.2160, 1.2574, 1.2577, 1.2698, 1.2637, 1.1799, 1.1799,
         3.6370, 3.6992, 3.5835, 3.8588, 3.6377, 4.0682, 3.5367, 3.6035, 3.9261,
         1.5695, 1.5582, 1.5322, 1.5327, 1.5531, 1.5624, 1.5852, 1.5624, 1.5624,
         1.3481, 1.3163, 1.3136, 1.3654, 1.3107, 1.3994, 1.3813, 1.3532, 1.3104,
         1.5409, 1.5941, 1.5598, 1.5469, 1.5418, 1.5777, 1.5964, 1.4349, 1.5318,
         1.1460, 1.2597, 1.2324, 1.2815, 1.1396, 1.1445, 1.0903, 1.3429, 1.2226],
        [1.4460, 1.4459, 1.4443, 1.4415, 1.4418, 1.4460, 1.4417, 1.4460, 1.4460,
         1.4307, 1.4299, 1.4307, 1.4306, 1.4307, 1.4116, 1.4307, 1.4294, 1.4272,
         2.2017, 2.2024, 2.2194, 2.1949, 2.1756, 2.1740, 2.2032, 2.1729, 2.1729,
         1.5161, 1.5145, 1.5220, 1.5220, 1.5161, 1.5220, 1.5219, 1.5220, 1.5220,
         1.7715, 1.7716, 1.7716, 1.7684, 1.7715, 1.7715, 1.7716, 1.7485, 1.7513,
         1.4473, 1.4520, 1.4520, 1.4520, 1.4436, 1.4520, 1.4479, 1.4520, 1.4520],
        [1.3122, 1.3106, 1.2946, 1.2858, 1.3096, 1.3079, 1.3090, 1.3098, 1.3098,
         1.2960, 1.2894, 1.2856, 1.2850, 1.2967, 1.2811, 1.2927, 1.2963, 1.2687,
         1.6436, 1.6171, 1.6404, 1.6400, 1.6394, 1.6394, 1.6416, 1.6431, 1.6431,
         3.4927, 3.2836, 3.2098, 3.2681, 3.4188, 3.2366, 3.4666, 3.2182, 3.1965,
         1.6442, 1.6367, 1.6350, 1.6382, 1.6411, 1.6173, 1.6424, 1.5820, 1.6084,
         1.3148, 1.3094, 1.2996, 1.3142, 1.3098, 1.3020, 1.3145, 1.3144, 1.3164],
        [1.4489, 1.4444, 1.4003, 1.4041, 1.4421, 1.4488, 1.4473, 1.4488, 1.4488,
         1.4324, 1.4297, 1.4246, 1.4191, 1.4336, 1.3915, 1.4275, 1.4335, 1.4281,
         1.7575, 1.7487, 1.7468, 1.7553, 1.7734, 1.7719, 1.7518, 1.7735, 1.7735,
         1.4827, 1.4874, 1.5247, 1.5195, 1.4881, 1.5233, 1.5116, 1.5248, 1.5217,
         2.1987, 2.1775, 2.1660, 2.1844, 2.2296, 2.2458, 2.2119, 2.3188, 2.3149,
         1.4390, 1.4302, 1.4445, 1.4548, 1.4416, 1.4515, 1.4214, 1.4487, 1.4548],
        [1.3846, 1.2785, 1.2756, 1.2953, 1.2888, 1.2989, 1.2977, 1.2264, 1.2264,
         1.2637, 1.2213, 1.2202, 1.2248, 1.3037, 1.1746, 1.1358, 1.3037, 1.2042,
         1.6108, 1.5868, 1.5697, 1.5621, 1.5846, 1.5812, 1.6032, 1.5862, 1.5862,
         1.3789, 1.3514, 1.3455, 1.3702, 1.3514, 1.4016, 1.4016, 1.3721, 1.3455,
         1.5803, 1.5813, 1.5854, 1.5751, 1.5520, 1.5562, 1.6174, 1.5060, 1.4758,
         3.9676, 3.6271, 3.7002, 3.6884, 3.6938, 3.4224, 3.9593, 3.6682, 3.4514]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 152 : 1780.2319990814174
Test loss for epoch 152 : 194.37167118463196
Test Precision for epoch 152 : 0.26153846153846155
Test Recall for epoch 152 : 0.26153846153846155
Test F1 for epoch 152 : 0.26153846153846155


theta for epoch 153 : tensor([[3.6207, 3.6441, 3.7816, 3.7290, 3.7198, 3.6024, 3.6428, 3.5431, 3.5431,
         1.2685, 1.2489, 1.2477, 1.2503, 1.2861, 1.2293, 1.2025, 1.2861, 1.2359,
         1.5963, 1.5806, 1.6047, 1.5871, 1.5932, 1.5949, 1.6022, 1.5949, 1.5949,
         1.3231, 1.3346, 1.3230, 1.3416, 1.3237, 1.3514, 1.3451, 1.3337, 1.3231,
         1.5891, 1.6059, 1.5943, 1.5907, 1.5978, 1.5882, 1.6068, 1.5593, 1.5642,
         1.2475, 1.2759, 1.2673, 1.2857, 1.2418, 1.2326, 1.2313, 1.3094, 1.2636],
        [1.3700, 1.2351, 1.2238, 1.2649, 1.2653, 1.2773, 1.2712, 1.1884, 1.1884,
         3.6271, 3.6896, 3.5734, 3.8500, 3.6279, 4.0606, 3.5264, 3.5936, 3.9177,
         1.5782, 1.5670, 1.5410, 1.5418, 1.5620, 1.5713, 1.5938, 1.5713, 1.5713,
         1.3488, 1.3173, 1.3147, 1.3659, 1.3118, 1.3996, 1.3817, 1.3539, 1.3116,
         1.5479, 1.6007, 1.5667, 1.5539, 1.5487, 1.5844, 1.6029, 1.4423, 1.5388,
         1.1571, 1.2700, 1.2429, 1.2916, 1.1509, 1.1558, 1.1028, 1.3526, 1.2332],
        [1.4370, 1.4368, 1.4352, 1.4324, 1.4327, 1.4369, 1.4326, 1.4369, 1.4369,
         1.4381, 1.4373, 1.4381, 1.4380, 1.4381, 1.4190, 1.4381, 1.4368, 1.4346,
         2.2025, 2.2031, 2.2202, 2.1956, 2.1764, 2.1748, 2.2040, 2.1737, 2.1737,
         1.5004, 1.4988, 1.5063, 1.5063, 1.5004, 1.5063, 1.5063, 1.5063, 1.5063,
         1.7711, 1.7712, 1.7712, 1.7680, 1.7711, 1.7711, 1.7712, 1.7482, 1.7509,
         1.4513, 1.4560, 1.4560, 1.4560, 1.4476, 1.4560, 1.4519, 1.4559, 1.4560],
        [1.3027, 1.3011, 1.2851, 1.2763, 1.3001, 1.2984, 1.2995, 1.3003, 1.3003,
         1.3034, 1.2968, 1.2930, 1.2924, 1.3040, 1.2885, 1.3002, 1.3036, 1.2761,
         1.6442, 1.6177, 1.6411, 1.6407, 1.6400, 1.6401, 1.6423, 1.6438, 1.6438,
         3.4810, 3.2717, 3.1978, 3.2563, 3.4070, 3.2248, 3.4549, 3.2063, 3.1845,
         1.6437, 1.6362, 1.6345, 1.6377, 1.6406, 1.6168, 1.6419, 1.5815, 1.6079,
         1.3187, 1.3133, 1.3035, 1.3181, 1.3137, 1.3059, 1.3184, 1.3183, 1.3203],
        [1.4398, 1.4353, 1.3913, 1.3950, 1.4330, 1.4397, 1.4382, 1.4397, 1.4397,
         1.4398, 1.4371, 1.4320, 1.4266, 1.4409, 1.3990, 1.4349, 1.4409, 1.4355,
         1.7583, 1.7495, 1.7476, 1.7561, 1.7741, 1.7726, 1.7526, 1.7743, 1.7743,
         1.4669, 1.4717, 1.5090, 1.5038, 1.4724, 1.5076, 1.4959, 1.5091, 1.5060,
         2.1982, 2.1771, 2.1656, 2.1840, 2.2291, 2.2453, 2.2115, 2.3183, 2.3143,
         1.4430, 1.4342, 1.4485, 1.4587, 1.4456, 1.4555, 1.4255, 1.4527, 1.4588],
        [1.3880, 1.2826, 1.2797, 1.2994, 1.2929, 1.3030, 1.3018, 1.2309, 1.2309,
         1.2753, 1.2335, 1.2325, 1.2369, 1.3147, 1.1868, 1.1495, 1.3147, 1.2167,
         1.6173, 1.5933, 1.5763, 1.5685, 1.5910, 1.5875, 1.6097, 1.5925, 1.5925,
         1.3748, 1.3475, 1.3414, 1.3662, 1.3474, 1.3975, 1.3974, 1.3680, 1.3415,
         1.5842, 1.5855, 1.5892, 1.5789, 1.5560, 1.5603, 1.6216, 1.5101, 1.4801,
         3.9589, 3.6166, 3.6900, 3.6781, 3.6837, 3.4113, 3.9505, 3.6579, 3.4404]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 153 : 1780.503256750972
Test loss for epoch 153 : 194.12730993832992
Test Precision for epoch 153 : 0.26153846153846155
Test Recall for epoch 153 : 0.26153846153846155
Test F1 for epoch 153 : 0.26153846153846155


theta for epoch 154 : tensor([[3.6152, 3.6385, 3.7763, 3.7237, 3.7144, 3.5968, 3.6373, 3.5374, 3.5374,
         1.2744, 1.2554, 1.2543, 1.2566, 1.2914, 1.2358, 1.2104, 1.2914, 1.2426,
         1.5949, 1.5792, 1.6033, 1.5858, 1.5920, 1.5936, 1.6008, 1.5936, 1.5936,
         1.3156, 1.3271, 1.3155, 1.3341, 1.3162, 1.3439, 1.3376, 1.3261, 1.3155,
         1.5904, 1.6071, 1.5956, 1.5920, 1.5990, 1.5894, 1.6079, 1.5606, 1.5655,
         1.2500, 1.2781, 1.2695, 1.2878, 1.2444, 1.2353, 1.2342, 1.3112, 1.2660],
        [1.3730, 1.2385, 1.2272, 1.2682, 1.2685, 1.2806, 1.2745, 1.1919, 1.1919,
         3.6235, 3.6862, 3.5695, 3.8475, 3.6243, 4.0593, 3.5223, 3.5898, 3.9156,
         1.5799, 1.5688, 1.5429, 1.5437, 1.5640, 1.5732, 1.5955, 1.5733, 1.5733,
         1.3478, 1.3164, 1.3139, 1.3648, 1.3109, 1.3983, 1.3805, 1.3529, 1.3107,
         1.5517, 1.6043, 1.5704, 1.5577, 1.5525, 1.5881, 1.6064, 1.4462, 1.5426,
         1.1617, 1.2740, 1.2471, 1.2955, 1.1555, 1.1606, 1.1083, 1.3562, 1.2375],
        [1.4334, 1.4332, 1.4316, 1.4288, 1.4291, 1.4333, 1.4290, 1.4333, 1.4333,
         1.4433, 1.4426, 1.4433, 1.4433, 1.4433, 1.4243, 1.4433, 1.4421, 1.4398,
         2.2006, 2.2012, 2.2182, 2.1937, 2.1745, 2.1729, 2.2022, 2.1719, 2.1719,
         1.4915, 1.4899, 1.4974, 1.4974, 1.4915, 1.4974, 1.4974, 1.4974, 1.4974,
         1.7717, 1.7718, 1.7718, 1.7685, 1.7717, 1.7717, 1.7718, 1.7488, 1.7515,
         1.4527, 1.4574, 1.4574, 1.4574, 1.4491, 1.4574, 1.4533, 1.4574, 1.4574],
        [1.2989, 1.2973, 1.2813, 1.2725, 1.2962, 1.2946, 1.2957, 1.2965, 1.2965,
         1.3086, 1.3020, 1.2982, 1.2976, 1.3092, 1.2937, 1.3054, 1.3088, 1.2813,
         1.6421, 1.6156, 1.6389, 1.6385, 1.6379, 1.6379, 1.6401, 1.6416, 1.6416,
         3.4743, 3.2651, 3.1910, 3.2496, 3.4003, 3.2181, 3.4483, 3.1995, 3.1777,
         1.6443, 1.6368, 1.6350, 1.6382, 1.6412, 1.6173, 1.6425, 1.5820, 1.6085,
         1.3201, 1.3147, 1.3049, 1.3195, 1.3151, 1.3074, 1.3198, 1.3197, 1.3217],
        [1.4362, 1.4318, 1.3878, 1.3915, 1.4294, 1.4361, 1.4346, 1.4361, 1.4361,
         1.4450, 1.4423, 1.4373, 1.4318, 1.4462, 1.4043, 1.4402, 1.4461, 1.4408,
         1.7562, 1.7474, 1.7456, 1.7541, 1.7720, 1.7706, 1.7505, 1.7722, 1.7722,
         1.4580, 1.4628, 1.5001, 1.4949, 1.4634, 1.4987, 1.4869, 1.5002, 1.4970,
         2.1987, 2.1776, 2.1661, 2.1845, 2.2296, 2.2459, 2.2121, 2.3187, 2.3148,
         1.4445, 1.4356, 1.4499, 1.4602, 1.4471, 1.4569, 1.4270, 1.4542, 1.4602],
        [1.3905, 1.2860, 1.2831, 1.3026, 1.2961, 1.3062, 1.3050, 1.2348, 1.2348,
         1.2830, 1.2417, 1.2407, 1.2449, 1.3219, 1.1948, 1.1588, 1.3219, 1.2250,
         1.6188, 1.5947, 1.5779, 1.5698, 1.5923, 1.5888, 1.6112, 1.5938, 1.5938,
         1.3725, 1.3452, 1.3393, 1.3638, 1.3452, 1.3950, 1.3949, 1.3657, 1.3394,
         1.5872, 1.5887, 1.5923, 1.5820, 1.5592, 1.5636, 1.6248, 1.5133, 1.4834,
         3.9542, 3.6101, 3.6838, 3.6719, 3.6776, 3.4043, 3.9456, 3.6516, 3.4334]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 154 : 1781.146390566734
Test loss for epoch 154 : 194.09636450150447
Test Precision for epoch 154 : 0.26153846153846155
Test Recall for epoch 154 : 0.26153846153846155
Test F1 for epoch 154 : 0.26153846153846155


theta for epoch 155 : tensor([[3.6156, 3.6388, 3.7769, 3.7242, 3.7148, 3.5971, 3.6376, 3.5377, 3.5377,
         1.2733, 1.2547, 1.2536, 1.2558, 1.2900, 1.2350, 1.2106, 1.2900, 1.2420,
         1.5919, 1.5762, 1.6003, 1.5829, 1.5890, 1.5907, 1.5978, 1.5906, 1.5906,
         1.3233, 1.3347, 1.3229, 1.3418, 1.3237, 1.3517, 1.3453, 1.3337, 1.3229,
         1.5911, 1.6078, 1.5963, 1.5927, 1.5998, 1.5901, 1.6086, 1.5613, 1.5663,
         1.2492, 1.2770, 1.2686, 1.2867, 1.2436, 1.2347, 1.2335, 1.3100, 1.2650],
        [1.3753, 1.2401, 1.2288, 1.2699, 1.2703, 1.2823, 1.2763, 1.1932, 1.1932,
         3.6237, 3.6867, 3.5695, 3.8488, 3.6245, 4.0617, 3.5221, 3.5899, 3.9172,
         1.5765, 1.5654, 1.5394, 1.5403, 1.5606, 1.5699, 1.5921, 1.5699, 1.5699,
         1.3510, 1.3195, 1.3169, 1.3681, 1.3140, 1.4017, 1.3838, 1.3561, 1.3138,
         1.5514, 1.6040, 1.5702, 1.5574, 1.5522, 1.5878, 1.6060, 1.4458, 1.5423,
         1.1597, 1.2717, 1.2449, 1.2932, 1.1536, 1.1588, 1.1068, 1.3537, 1.2354],
        [1.4387, 1.4386, 1.4369, 1.4341, 1.4345, 1.4387, 1.4343, 1.4386, 1.4386,
         1.4419, 1.4411, 1.4418, 1.4418, 1.4419, 1.4228, 1.4418, 1.4406, 1.4384,
         2.1974, 2.1980, 2.2150, 2.1907, 2.1715, 2.1699, 2.1991, 2.1688, 2.1688,
         1.4976, 1.4960, 1.5035, 1.5035, 1.4976, 1.5035, 1.5035, 1.5035, 1.5035,
         1.7720, 1.7721, 1.7721, 1.7688, 1.7720, 1.7720, 1.7721, 1.7491, 1.7518,
         1.4511, 1.4558, 1.4558, 1.4558, 1.4475, 1.4558, 1.4518, 1.4558, 1.4558],
        [1.3043, 1.3027, 1.2867, 1.2780, 1.3017, 1.3000, 1.3012, 1.3019, 1.3019,
         1.3071, 1.3005, 1.2967, 1.2961, 1.3077, 1.2922, 1.3040, 1.3073, 1.2799,
         1.6386, 1.6121, 1.6355, 1.6351, 1.6344, 1.6344, 1.6366, 1.6381, 1.6381,
         3.4795, 3.2704, 3.1964, 3.2549, 3.4055, 3.2234, 3.4535, 3.2049, 3.1831,
         1.6446, 1.6371, 1.6353, 1.6385, 1.6415, 1.6176, 1.6428, 1.5823, 1.6088,
         1.3185, 1.3131, 1.3033, 1.3179, 1.3136, 1.3058, 1.3182, 1.3181, 1.3201],
        [1.4416, 1.4371, 1.3933, 1.3969, 1.4348, 1.4414, 1.4399, 1.4415, 1.4415,
         1.4436, 1.4408, 1.4358, 1.4304, 1.4447, 1.4029, 1.4387, 1.4447, 1.4393,
         1.7528, 1.7440, 1.7422, 1.7507, 1.7686, 1.7671, 1.7471, 1.7688, 1.7688,
         1.4641, 1.4690, 1.5062, 1.5010, 1.4695, 1.5048, 1.4930, 1.5063, 1.5031,
         2.1990, 2.1779, 2.1664, 2.1848, 2.2298, 2.2461, 2.2123, 2.3190, 2.3150,
         1.4430, 1.4340, 1.4483, 1.4586, 1.4456, 1.4553, 1.4255, 1.4526, 1.4586],
        [1.3951, 1.2918, 1.2888, 1.3083, 1.3018, 1.3118, 1.3106, 1.2413, 1.2413,
         1.2825, 1.2416, 1.2406, 1.2447, 1.3211, 1.1947, 1.1596, 1.3211, 1.2250,
         1.6167, 1.5926, 1.5759, 1.5677, 1.5902, 1.5867, 1.6091, 1.5917, 1.5917,
         1.3796, 1.3524, 1.3469, 1.3709, 1.3526, 1.4018, 1.4019, 1.3729, 1.3469,
         1.5883, 1.5900, 1.5934, 1.5831, 1.5604, 1.5648, 1.6261, 1.5145, 1.4846,
         3.9527, 3.6069, 3.6808, 3.6689, 3.6747, 3.4005, 3.9440, 3.6485, 3.4297]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 155 : 1780.8346156875668
Test loss for epoch 155 : 193.99575780111437
Test Precision for epoch 155 : 0.26153846153846155
Test Recall for epoch 155 : 0.26153846153846155
Test F1 for epoch 155 : 0.26153846153846155


theta for epoch 156 : tensor([[3.6169, 3.6402, 3.7785, 3.7257, 3.7163, 3.5985, 3.6390, 3.5391, 3.5391,
         1.2674, 1.2489, 1.2478, 1.2500, 1.2840, 1.2292, 1.2050, 1.2841, 1.2363,
         1.5915, 1.5759, 1.5999, 1.5825, 1.5886, 1.5902, 1.5975, 1.5902, 1.5902,
         1.3367, 1.3480, 1.3358, 1.3552, 1.3369, 1.3654, 1.3589, 1.3471, 1.3358,
         1.5915, 1.6081, 1.5966, 1.5930, 1.6001, 1.5904, 1.6089, 1.5617, 1.5666,
         1.2484, 1.2762, 1.2678, 1.2858, 1.2429, 1.2340, 1.2327, 1.3091, 1.2642],
        [1.3723, 1.2357, 1.2244, 1.2657, 1.2661, 1.2782, 1.2721, 1.1881, 1.1881,
         3.6280, 3.6913, 3.5736, 3.8541, 3.6288, 4.0682, 3.5260, 3.5941, 3.9230,
         1.5716, 1.5604, 1.5344, 1.5353, 1.5556, 1.5649, 1.5872, 1.5650, 1.5650,
         1.3530, 1.3213, 1.3186, 1.3702, 1.3157, 1.4041, 1.3861, 1.3581, 1.3154,
         1.5475, 1.6003, 1.5664, 1.5536, 1.5483, 1.5840, 1.6023, 1.4417, 1.5384,
         1.1542, 1.2661, 1.2394, 1.2876, 1.1482, 1.1535, 1.1013, 1.3480, 1.2298],
        [1.4446, 1.4445, 1.4429, 1.4401, 1.4404, 1.4446, 1.4402, 1.4446, 1.4446,
         1.4359, 1.4351, 1.4359, 1.4358, 1.4359, 1.4169, 1.4359, 1.4346, 1.4324,
         2.1968, 2.1974, 2.2145, 2.1901, 2.1709, 2.1693, 2.1986, 2.1683, 2.1683,
         1.5096, 1.5080, 1.5155, 1.5155, 1.5096, 1.5155, 1.5155, 1.5155, 1.5155,
         1.7721, 1.7722, 1.7722, 1.7690, 1.7721, 1.7721, 1.7722, 1.7492, 1.7520,
         1.4498, 1.4544, 1.4544, 1.4544, 1.4461, 1.4544, 1.4504, 1.4544, 1.4544],
        [1.3105, 1.3089, 1.2929, 1.2842, 1.3078, 1.3061, 1.3073, 1.3080, 1.3080,
         1.3011, 1.2945, 1.2907, 1.2901, 1.3017, 1.2863, 1.2980, 1.3013, 1.2739,
         1.6380, 1.6115, 1.6349, 1.6344, 1.6338, 1.6338, 1.6360, 1.6375, 1.6375,
         3.4891, 3.2802, 3.2063, 3.2647, 3.4152, 3.2332, 3.4632, 3.2147, 3.1930,
         1.6447, 1.6372, 1.6355, 1.6387, 1.6416, 1.6177, 1.6429, 1.5825, 1.6089,
         1.3172, 1.3118, 1.3020, 1.3166, 1.3123, 1.3045, 1.3169, 1.3168, 1.3188],
        [1.4475, 1.4430, 1.3993, 1.4030, 1.4407, 1.4473, 1.4458, 1.4474, 1.4474,
         1.4376, 1.4349, 1.4298, 1.4244, 1.4388, 1.3970, 1.4328, 1.4387, 1.4334,
         1.7521, 1.7433, 1.7416, 1.7500, 1.7680, 1.7665, 1.7465, 1.7681, 1.7681,
         1.4762, 1.4810, 1.5182, 1.5130, 1.4816, 1.5168, 1.5051, 1.5183, 1.5152,
         2.1990, 2.1780, 2.1665, 2.1848, 2.2299, 2.2462, 2.2124, 2.3190, 2.3151,
         1.4416, 1.4327, 1.4469, 1.4572, 1.4442, 1.4540, 1.4241, 1.4512, 1.4573],
        [1.3953, 1.2936, 1.2904, 1.3097, 1.3032, 1.3132, 1.3120, 1.2439, 1.2439,
         1.2761, 1.2355, 1.2346, 1.2385, 1.3145, 1.1885, 1.1542, 1.3145, 1.2190,
         1.6153, 1.5913, 1.5744, 1.5663, 1.5888, 1.5854, 1.6077, 1.5904, 1.5904,
         1.3883, 1.3612, 1.3563, 1.3795, 1.3615, 1.4100, 1.4104, 1.3817, 1.3564,
         1.5878, 1.5895, 1.5929, 1.5826, 1.5598, 1.5643, 1.6256, 1.5139, 1.4840,
         3.9556, 3.6082, 3.6824, 3.6703, 3.6763, 3.4013, 3.9468, 3.6499, 3.4305]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 156 : 1780.6988189620513
Test loss for epoch 156 : 193.99034784904404
Test Precision for epoch 156 : 0.26153846153846155
Test Recall for epoch 156 : 0.26153846153846155
Test F1 for epoch 156 : 0.26153846153846155


theta for epoch 157 : tensor([[3.6169, 3.6402, 3.7787, 3.7258, 3.7163, 3.5984, 3.6390, 3.5390, 3.5390,
         1.2626, 1.2439, 1.2428, 1.2450, 1.2793, 1.2241, 1.1996, 1.2793, 1.2312,
         1.5958, 1.5801, 1.6042, 1.5866, 1.5927, 1.5944, 1.6017, 1.5943, 1.5943,
         1.3367, 1.3480, 1.3352, 1.3554, 1.3366, 1.3660, 1.3592, 1.3470, 1.3352,
         1.5928, 1.6095, 1.5979, 1.5943, 1.6014, 1.5917, 1.6103, 1.5630, 1.5679,
         1.2505, 1.2783, 1.2699, 1.2880, 1.2450, 1.2362, 1.2344, 1.3112, 1.2663],
        [1.3619, 1.2233, 1.2121, 1.2537, 1.2540, 1.2662, 1.2601, 1.1748, 1.1748,
         3.6378, 3.7014, 3.5832, 3.8650, 3.6386, 4.0803, 3.5355, 3.6038, 3.9343,
         1.5673, 1.5560, 1.5299, 1.5308, 1.5512, 1.5605, 1.5830, 1.5605, 1.5605,
         1.3422, 1.3103, 1.3073, 1.3595, 1.3046, 1.3938, 1.3756, 1.3472, 1.3041,
         1.5417, 1.5948, 1.5607, 1.5478, 1.5425, 1.5784, 1.5968, 1.4353, 1.5326,
         1.1477, 1.2598, 1.2331, 1.2814, 1.1417, 1.1471, 1.0944, 1.3420, 1.2235],
        [1.4463, 1.4463, 1.4446, 1.4418, 1.4421, 1.4463, 1.4420, 1.4463, 1.4463,
         1.4312, 1.4304, 1.4311, 1.4311, 1.4312, 1.4121, 1.4311, 1.4299, 1.4277,
         2.2007, 2.2013, 2.2183, 2.1938, 2.1747, 2.1730, 2.2023, 2.1720, 2.1720,
         1.5090, 1.5075, 1.5149, 1.5149, 1.5090, 1.5149, 1.5149, 1.5149, 1.5149,
         1.7735, 1.7736, 1.7736, 1.7703, 1.7734, 1.7734, 1.7736, 1.7506, 1.7533,
         1.4514, 1.4561, 1.4561, 1.4561, 1.4478, 1.4561, 1.4521, 1.4561, 1.4561],
        [1.3125, 1.3109, 1.2949, 1.2862, 1.3098, 1.3081, 1.3093, 1.3099, 1.3099,
         1.2964, 1.2899, 1.2861, 1.2855, 1.2971, 1.2816, 1.2933, 1.2967, 1.2692,
         1.6423, 1.6158, 1.6391, 1.6387, 1.6381, 1.6381, 1.6403, 1.6418, 1.6418,
         3.4879, 3.2790, 3.2051, 3.2635, 3.4140, 3.2320, 3.4620, 3.2135, 3.1918,
         1.6461, 1.6386, 1.6369, 1.6401, 1.6430, 1.6191, 1.6443, 1.5839, 1.6103,
         1.3190, 1.3136, 1.3038, 1.3184, 1.3141, 1.3063, 1.3187, 1.3187, 1.3206],
        [1.4492, 1.4447, 1.4010, 1.4048, 1.4425, 1.4491, 1.4476, 1.4492, 1.4492,
         1.4329, 1.4302, 1.4251, 1.4197, 1.4340, 1.3922, 1.4280, 1.4340, 1.4287,
         1.7562, 1.7474, 1.7457, 1.7541, 1.7721, 1.7706, 1.7506, 1.7722, 1.7722,
         1.4756, 1.4804, 1.5177, 1.5124, 1.4810, 1.5162, 1.5045, 1.5177, 1.5146,
         2.2003, 2.1792, 2.1677, 2.1861, 2.2311, 2.2474, 2.2137, 2.3203, 2.3163,
         1.4433, 1.4343, 1.4486, 1.4589, 1.4458, 1.4556, 1.4257, 1.4529, 1.4589],
        [1.3875, 1.2877, 1.2843, 1.3035, 1.2970, 1.3070, 1.3058, 1.2392, 1.2392,
         1.2694, 1.2290, 1.2281, 1.2320, 1.3078, 1.1819, 1.1480, 1.3078, 1.2126,
         1.6167, 1.5927, 1.5757, 1.5679, 1.5904, 1.5869, 1.6091, 1.5920, 1.5920,
         1.3822, 1.3552, 1.3511, 1.3732, 1.3558, 1.4032, 1.4039, 1.3757, 1.3511,
         1.5871, 1.5887, 1.5922, 1.5819, 1.5590, 1.5635, 1.6249, 1.5131, 1.4831,
         3.9639, 3.6149, 3.6893, 3.6772, 3.6834, 3.4076, 3.9551, 3.6567, 3.4367]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 157 : 1780.0117582960295
Test loss for epoch 157 : 194.39962634887254
Test Precision for epoch 157 : 0.26153846153846155
Test Recall for epoch 157 : 0.26153846153846155
Test F1 for epoch 157 : 0.26153846153846155


theta for epoch 158 : tensor([[3.6177, 3.6410, 3.7798, 3.7268, 3.7172, 3.5993, 3.6398, 3.5398, 3.5398,
         1.2598, 1.2408, 1.2397, 1.2420, 1.2769, 1.2209, 1.1956, 1.2769, 1.2280,
         1.6007, 1.5850, 1.6092, 1.5914, 1.5975, 1.5992, 1.6066, 1.5992, 1.5992,
         1.3298, 1.3410, 1.3275, 1.3486, 1.3294, 1.3596, 1.3526, 1.3400, 1.3275,
         1.5941, 1.6109, 1.5993, 1.5957, 1.6028, 1.5931, 1.6117, 1.5643, 1.5693,
         1.2523, 1.2801, 1.2717, 1.2898, 1.2468, 1.2380, 1.2357, 1.3131, 1.2681],
        [1.3471, 1.2058, 1.1948, 1.2366, 1.2370, 1.2492, 1.2431, 1.1560, 1.1560,
         3.6529, 3.7168, 3.5981, 3.8812, 3.6537, 4.0977, 3.5503, 3.6187, 3.9508,
         1.5611, 1.5497, 1.5234, 1.5241, 1.5447, 1.5541, 1.5769, 1.5541, 1.5541,
         1.3237, 1.2915, 1.2880, 1.3411, 1.2857, 1.3758, 1.3574, 1.3286, 1.2849,
         1.5336, 1.5871, 1.5527, 1.5398, 1.5344, 1.5707, 1.5892, 1.4265, 1.5244,
         1.1383, 1.2510, 1.2241, 1.2727, 1.1323, 1.1379, 1.0843, 1.3337, 1.2145],
        [1.4468, 1.4467, 1.4451, 1.4423, 1.4426, 1.4468, 1.4425, 1.4468, 1.4468,
         1.4289, 1.4282, 1.4289, 1.4288, 1.4289, 1.4099, 1.4289, 1.4277, 1.4254,
         2.2056, 2.2062, 2.2232, 2.1984, 2.1793, 2.1777, 2.2069, 2.1767, 2.1767,
         1.5022, 1.5006, 1.5081, 1.5081, 1.5022, 1.5081, 1.5081, 1.5081, 1.5081,
         1.7751, 1.7752, 1.7752, 1.7719, 1.7751, 1.7751, 1.7752, 1.7522, 1.7549,
         1.4530, 1.4577, 1.4577, 1.4577, 1.4493, 1.4577, 1.4536, 1.4577, 1.4577],
        [1.3133, 1.3116, 1.2957, 1.2870, 1.3106, 1.3089, 1.3100, 1.3107, 1.3107,
         1.2943, 1.2876, 1.2838, 1.2832, 1.2949, 1.2793, 1.2910, 1.2945, 1.2670,
         1.6476, 1.6211, 1.6445, 1.6440, 1.6434, 1.6434, 1.6456, 1.6471, 1.6471,
         3.4814, 3.2724, 3.1985, 3.2569, 3.4074, 3.2254, 3.4555, 3.2069, 3.1852,
         1.6478, 1.6404, 1.6386, 1.6418, 1.6447, 1.6209, 1.6461, 1.5856, 1.6120,
         1.3208, 1.3154, 1.3056, 1.3202, 1.3159, 1.3081, 1.3205, 1.3204, 1.3224],
        [1.4497, 1.4452, 1.4015, 1.4054, 1.4430, 1.4496, 1.4480, 1.4496, 1.4496,
         1.4306, 1.4279, 1.4229, 1.4175, 1.4318, 1.3900, 1.4258, 1.4317, 1.4264,
         1.7613, 1.7526, 1.7508, 1.7592, 1.7772, 1.7757, 1.7557, 1.7773, 1.7773,
         1.4688, 1.4735, 1.5108, 1.5055, 1.4741, 1.5094, 1.4977, 1.5109, 1.5078,
         2.2019, 2.1808, 2.1693, 2.1877, 2.2327, 2.2490, 2.2152, 2.3218, 2.3179,
         1.4448, 1.4359, 1.4502, 1.4605, 1.4474, 1.4572, 1.4272, 1.4544, 1.4605],
        [1.3750, 1.2774, 1.2738, 1.2928, 1.2863, 1.2963, 1.2951, 1.2302, 1.2302,
         1.2637, 1.2232, 1.2223, 1.2262, 1.3020, 1.1760, 1.1422, 1.3020, 1.2068,
         1.6175, 1.5935, 1.5763, 1.5688, 1.5914, 1.5879, 1.6099, 1.5930, 1.5930,
         1.3676, 1.3406, 1.3374, 1.3584, 1.3415, 1.3877, 1.3888, 1.3612, 1.3375,
         1.5855, 1.5869, 1.5906, 1.5803, 1.5573, 1.5617, 1.6231, 1.5113, 1.4812,
         3.9758, 3.6252, 3.6999, 3.6878, 3.6941, 3.4175, 3.9670, 3.6672, 3.4467]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 158 : 1779.363548648841
Test loss for epoch 158 : 195.28212554505473
Test Precision for epoch 158 : 0.26153846153846155
Test Recall for epoch 158 : 0.26153846153846155
Test F1 for epoch 158 : 0.26153846153846155


theta for epoch 159 : tensor([[3.6159, 3.6393, 3.7783, 3.7252, 3.7155, 3.5975, 3.6381, 3.5380, 3.5380,
         1.2585, 1.2394, 1.2383, 1.2407, 1.2757, 1.2195, 1.1941, 1.2757, 1.2266,
         1.6023, 1.5866, 1.6108, 1.5929, 1.5990, 1.6007, 1.6082, 1.6006, 1.6006,
         1.3343, 1.3454, 1.3314, 1.3532, 1.3337, 1.3645, 1.3574, 1.3444, 1.3314,
         1.5953, 1.6121, 1.6005, 1.5969, 1.6040, 1.5944, 1.6130, 1.5656, 1.5705,
         1.2508, 1.2785, 1.2701, 1.2882, 1.2454, 1.2366, 1.2336, 1.3115, 1.2666],
        [1.3589, 1.2155, 1.2049, 1.2467, 1.2471, 1.2593, 1.2532, 1.1645, 1.1645,
         3.6424, 3.7065, 3.5873, 3.8716, 3.6432, 4.0893, 3.5393, 3.6080, 3.9417,
         1.5676, 1.5562, 1.5301, 1.5305, 1.5510, 1.5604, 1.5833, 1.5605, 1.5605,
         1.3333, 1.3011, 1.2971, 1.3508, 1.2952, 1.3859, 1.3673, 1.3381, 1.2939,
         1.5394, 1.5929, 1.5584, 1.5455, 1.5402, 1.5764, 1.5951, 1.4326, 1.5302,
         1.1435, 1.2559, 1.2291, 1.2775, 1.1376, 1.1432, 1.0888, 1.3384, 1.2195],
        [1.4515, 1.4514, 1.4498, 1.4470, 1.4473, 1.4515, 1.4472, 1.4515, 1.4515,
         1.4273, 1.4265, 1.4273, 1.4272, 1.4273, 1.4083, 1.4273, 1.4260, 1.4238,
         2.2065, 2.2070, 2.2240, 2.1992, 2.1802, 2.1785, 2.2077, 2.1775, 2.1775,
         1.5050, 1.5034, 1.5108, 1.5109, 1.5050, 1.5109, 1.5108, 1.5109, 1.5108,
         1.7758, 1.7759, 1.7759, 1.7727, 1.7758, 1.7758, 1.7759, 1.7529, 1.7557,
         1.4501, 1.4548, 1.4548, 1.4548, 1.4464, 1.4548, 1.4507, 1.4547, 1.4548],
        [1.3185, 1.3167, 1.3007, 1.2921, 1.3156, 1.3140, 1.3151, 1.3157, 1.3157,
         1.2927, 1.2861, 1.2823, 1.2817, 1.2934, 1.2778, 1.2895, 1.2929, 1.2654,
         1.6486, 1.6221, 1.6455, 1.6451, 1.6444, 1.6445, 1.6467, 1.6482, 1.6482,
         3.4827, 3.2738, 3.1998, 3.2583, 3.4087, 3.2268, 3.4568, 3.2082, 3.1865,
         1.6487, 1.6412, 1.6394, 1.6426, 1.6456, 1.6217, 1.6469, 1.5864, 1.6129,
         1.3181, 1.3126, 1.3028, 1.3175, 1.3131, 1.3053, 1.3177, 1.3177, 1.3197],
        [1.4543, 1.4498, 1.4062, 1.4101, 1.4476, 1.4542, 1.4526, 1.4543, 1.4543,
         1.4290, 1.4263, 1.4212, 1.4159, 1.4302, 1.3884, 1.4242, 1.4301, 1.4248,
         1.7622, 1.7534, 1.7517, 1.7601, 1.7781, 1.7766, 1.7566, 1.7782, 1.7782,
         1.4715, 1.4762, 1.5136, 1.5083, 1.4769, 1.5121, 1.5004, 1.5136, 1.5105,
         2.2026, 2.1815, 2.1700, 2.1884, 2.2334, 2.2497, 2.2159, 2.3226, 2.3186,
         1.4418, 1.4329, 1.4472, 1.4576, 1.4444, 1.4543, 1.4242, 1.4515, 1.4576],
        [1.3664, 1.2717, 1.2678, 1.2866, 1.2800, 1.2900, 1.2888, 1.2262, 1.2262,
         1.2590, 1.2190, 1.2181, 1.2218, 1.2970, 1.1717, 1.1390, 1.2970, 1.2027,
         1.6147, 1.5907, 1.5733, 1.5664, 1.5890, 1.5855, 1.6071, 1.5906, 1.5906,
         1.3622, 1.3353, 1.3333, 1.3528, 1.3366, 1.3814, 1.3830, 1.3560, 1.3334,
         1.5836, 1.5848, 1.5887, 1.5784, 1.5553, 1.5596, 1.6210, 1.5093, 1.4790,
         3.9841, 3.6319, 3.7069, 3.6947, 3.7011, 3.4238, 3.9752, 3.6739, 3.4530]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 159 : 1779.6349705649031
Test loss for epoch 159 : 194.84730034602137
Test Precision for epoch 159 : 0.26153846153846155
Test Recall for epoch 159 : 0.26153846153846155
Test F1 for epoch 159 : 0.26153846153846155


theta for epoch 160 : tensor([[3.6160, 3.6393, 3.7785, 3.7254, 3.7157, 3.5975, 3.6381, 3.5380, 3.5380,
         1.2608, 1.2416, 1.2404, 1.2428, 1.2782, 1.2215, 1.1957, 1.2782, 1.2286,
         1.5987, 1.5829, 1.6071, 1.5891, 1.5953, 1.5969, 1.6045, 1.5969, 1.5969,
         1.3439, 1.3549, 1.3405, 1.3628, 1.3430, 1.3745, 1.3671, 1.3539, 1.3405,
         1.5949, 1.6117, 1.6001, 1.5965, 1.6036, 1.5940, 1.6126, 1.5652, 1.5701,
         1.2455, 1.2731, 1.2647, 1.2828, 1.2401, 1.2314, 1.2276, 1.3060, 1.2613],
        [1.3648, 1.2189, 1.2085, 1.2505, 1.2509, 1.2630, 1.2570, 1.1665, 1.1665,
         3.6397, 3.7041, 3.5844, 3.8700, 3.6405, 4.0888, 3.5361, 3.6052, 3.9404,
         1.5664, 1.5549, 1.5289, 1.5290, 1.5495, 1.5588, 1.5820, 1.5589, 1.5589,
         1.3415, 1.3091, 1.3045, 1.3591, 1.3030, 1.3947, 1.3758, 1.3462, 1.3013,
         1.5403, 1.5940, 1.5593, 1.5464, 1.5412, 1.5775, 1.5962, 1.4336, 1.5312,
         1.1419, 1.2541, 1.2274, 1.2758, 1.1360, 1.1415, 1.0861, 1.3368, 1.2178],
        [1.4551, 1.4551, 1.4535, 1.4507, 1.4509, 1.4552, 1.4509, 1.4552, 1.4552,
         1.4297, 1.4290, 1.4297, 1.4297, 1.4297, 1.4107, 1.4297, 1.4285, 1.4262,
         2.2029, 2.2035, 2.2205, 2.1958, 2.1768, 2.1751, 2.2043, 2.1741, 2.1741,
         1.5135, 1.5119, 1.5193, 1.5193, 1.5135, 1.5193, 1.5193, 1.5193, 1.5193,
         1.7753, 1.7754, 1.7754, 1.7721, 1.7753, 1.7753, 1.7754, 1.7524, 1.7551,
         1.4438, 1.4485, 1.4485, 1.4485, 1.4401, 1.4485, 1.4444, 1.4484, 1.4485],
        [1.3225, 1.3207, 1.3048, 1.2962, 1.3196, 1.3180, 1.3191, 1.3197, 1.3197,
         1.2952, 1.2886, 1.2848, 1.2842, 1.2959, 1.2803, 1.2919, 1.2954, 1.2679,
         1.6449, 1.6184, 1.6418, 1.6413, 1.6407, 1.6407, 1.6430, 1.6444, 1.6444,
         3.4889, 3.2801, 3.2062, 3.2646, 3.4150, 3.2331, 3.4630, 3.2146, 3.1929,
         1.6482, 1.6407, 1.6390, 1.6422, 1.6451, 1.6212, 1.6464, 1.5859, 1.6124,
         1.3119, 1.3065, 1.2967, 1.3113, 1.3070, 1.2992, 1.3115, 1.3116, 1.3135],
        [1.4580, 1.4535, 1.4098, 1.4139, 1.4513, 1.4579, 1.4563, 1.4580, 1.4580,
         1.4314, 1.4287, 1.4237, 1.4183, 1.4326, 1.3908, 1.4266, 1.4326, 1.4272,
         1.7584, 1.7496, 1.7479, 1.7563, 1.7743, 1.7728, 1.7528, 1.7744, 1.7744,
         1.4801, 1.4847, 1.5221, 1.5167, 1.4854, 1.5206, 1.5089, 1.5221, 1.5190,
         2.2020, 2.1809, 2.1694, 2.1878, 2.2328, 2.2492, 2.2154, 2.3220, 2.3181,
         1.4355, 1.4266, 1.4409, 1.4513, 1.4381, 1.4480, 1.4178, 1.4452, 1.4513],
        [1.3548, 1.2628, 1.2586, 1.2772, 1.2706, 1.2806, 1.2794, 1.2189, 1.2189,
         1.2569, 1.2171, 1.2162, 1.2199, 1.2948, 1.1698, 1.1375, 1.2948, 1.2009,
         1.6060, 1.5821, 1.5645, 1.5580, 1.5807, 1.5772, 1.5985, 1.5823, 1.5823,
         1.3599, 1.3330, 1.3323, 1.3502, 1.3348, 1.3782, 1.3802, 1.3538, 1.3323,
         1.5794, 1.5803, 1.5845, 1.5741, 1.5509, 1.5551, 1.6165, 1.5049, 1.4745,
         3.9939, 3.6402, 3.7154, 3.7031, 3.7097, 3.4317, 3.9850, 3.6823, 3.4609]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 160 : 1779.5056550289032
Test loss for epoch 160 : 194.78615766563405
Test Precision for epoch 160 : 0.26153846153846155
Test Recall for epoch 160 : 0.26153846153846155
Test F1 for epoch 160 : 0.26153846153846155


theta for epoch 161 : tensor([[3.6164, 3.6398, 3.7791, 3.7260, 3.7162, 3.5979, 3.6386, 3.5384, 3.5384,
         1.2658, 1.2463, 1.2451, 1.2477, 1.2835, 1.2262, 1.1997, 1.2835, 1.2333,
         1.5957, 1.5799, 1.6042, 1.5860, 1.5922, 1.5939, 1.6015, 1.5938, 1.5938,
         1.3454, 1.3563, 1.3414, 1.3643, 1.3443, 1.3763, 1.3688, 1.3553, 1.3415,
         1.5940, 1.6108, 1.5992, 1.5956, 1.6027, 1.5931, 1.6117, 1.5643, 1.5692,
         1.2409, 1.2684, 1.2600, 1.2780, 1.2355, 1.2268, 1.2223, 1.3011, 1.2566],
        [1.3635, 1.2151, 1.2050, 1.2471, 1.2476, 1.2597, 1.2536, 1.1613, 1.1613,
         3.6440, 3.7086, 3.5885, 3.8753, 3.6448, 4.0953, 3.5401, 3.6094, 3.9461,
         1.5623, 1.5507, 1.5248, 1.5245, 1.5450, 1.5544, 1.5779, 1.5544, 1.5544,
         1.3402, 1.3076, 1.3023, 1.3579, 1.3012, 1.3940, 1.3749, 1.3448, 1.2991,
         1.5376, 1.5916, 1.5567, 1.5437, 1.5386, 1.5751, 1.5940, 1.4308, 1.5285,
         1.1369, 1.2493, 1.2225, 1.2711, 1.1309, 1.1364, 1.0798, 1.3323, 1.2128],
        [1.4557, 1.4556, 1.4540, 1.4512, 1.4515, 1.4557, 1.4514, 1.4557, 1.4557,
         1.4352, 1.4344, 1.4352, 1.4351, 1.4352, 1.4162, 1.4352, 1.4340, 1.4317,
         2.2004, 2.2010, 2.2179, 2.1934, 2.1743, 2.1727, 2.2019, 2.1716, 2.1716,
         1.5148, 1.5132, 1.5207, 1.5206, 1.5148, 1.5206, 1.5206, 1.5206, 1.5207,
         1.7746, 1.7747, 1.7747, 1.7714, 1.7746, 1.7746, 1.7747, 1.7517, 1.7544,
         1.4386, 1.4433, 1.4433, 1.4433, 1.4349, 1.4433, 1.4392, 1.4433, 1.4433],
        [1.3234, 1.3215, 1.3056, 1.2970, 1.3204, 1.3188, 1.3199, 1.3204, 1.3204,
         1.3007, 1.2941, 1.2903, 1.2897, 1.3014, 1.2858, 1.2974, 1.3010, 1.2734,
         1.6422, 1.6157, 1.6391, 1.6387, 1.6380, 1.6381, 1.6403, 1.6418, 1.6418,
         3.4893, 3.2805, 3.2066, 3.2650, 3.4154, 3.2335, 3.4635, 3.2150, 3.1933,
         1.6475, 1.6401, 1.6383, 1.6415, 1.6444, 1.6205, 1.6458, 1.5852, 1.6117,
         1.3069, 1.3014, 1.2916, 1.3063, 1.3019, 1.2941, 1.3065, 1.3065, 1.3085],
        [1.4585, 1.4540, 1.4103, 1.4144, 1.4519, 1.4584, 1.4568, 1.4585, 1.4585,
         1.4369, 1.4342, 1.4292, 1.4238, 1.4381, 1.3963, 1.4321, 1.4380, 1.4327,
         1.7557, 1.7469, 1.7451, 1.7535, 1.7715, 1.7701, 1.7500, 1.7717, 1.7717,
         1.4814, 1.4859, 1.5234, 1.5180, 1.4867, 1.5219, 1.5103, 1.5234, 1.5203,
         2.2013, 2.1802, 2.1687, 2.1871, 2.2321, 2.2484, 2.2147, 2.3213, 2.3174,
         1.4303, 1.4214, 1.4357, 1.4461, 1.4329, 1.4429, 1.4126, 1.4401, 1.4462],
        [1.3390, 1.2496, 1.2450, 1.2635, 1.2568, 1.2668, 1.2656, 1.2071, 1.2071,
         1.2568, 1.2169, 1.2160, 1.2198, 1.2948, 1.1695, 1.1371, 1.2948, 1.2007,
         1.5972, 1.5734, 1.5556, 1.5496, 1.5723, 1.5688, 1.5897, 1.5739, 1.5739,
         1.3495, 1.3227, 1.3230, 1.3395, 1.3247, 1.3669, 1.3693, 1.3435, 1.3230,
         1.5741, 1.5747, 1.5792, 1.5688, 1.5455, 1.5495, 1.6109, 1.4994, 1.4687,
         4.0070, 3.6517, 3.7272, 3.7148, 3.7216, 3.4427, 3.9980, 3.6939, 3.4719]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 161 : 1779.1539999632926
Test loss for epoch 161 : 195.1886561286675
Test Precision for epoch 161 : 0.26153846153846155
Test Recall for epoch 161 : 0.26153846153846155
Test F1 for epoch 161 : 0.26153846153846155


theta for epoch 162 : tensor([[3.6194, 3.6428, 3.7824, 3.7292, 3.7193, 3.6010, 3.6417, 3.5416, 3.5416,
         1.2684, 1.2485, 1.2473, 1.2500, 1.2864, 1.2284, 1.2011, 1.2864, 1.2354,
         1.5964, 1.5806, 1.6048, 1.5867, 1.5928, 1.5945, 1.6022, 1.5945, 1.5945,
         1.3396, 1.3506, 1.3354, 1.3586, 1.3384, 1.3708, 1.3632, 1.3495, 1.3354,
         1.5934, 1.6102, 1.5985, 1.5949, 1.6020, 1.5924, 1.6110, 1.5637, 1.5686,
         1.2382, 1.2656, 1.2573, 1.2752, 1.2329, 1.2243, 1.2188, 1.2983, 1.2539],
        [1.3580, 1.2070, 1.1971, 1.2395, 1.2399, 1.2520, 1.2460, 1.1518, 1.1518,
         3.6528, 3.7178, 3.5972, 3.8852, 3.6537, 4.1063, 3.5486, 3.6181, 3.9564,
         1.5581, 1.5463, 1.5205, 1.5198, 1.5404, 1.5498, 1.5737, 1.5498, 1.5498,
         1.3305, 1.2977, 1.2917, 1.3483, 1.2912, 1.3850, 1.3656, 1.3350, 1.2886,
         1.5324, 1.5869, 1.5515, 1.5385, 1.5335, 1.5702, 1.5893, 1.4252, 1.5233,
         1.1299, 1.2429, 1.2158, 1.2648, 1.1238, 1.1293, 1.0712, 1.3265, 1.2061],
        [1.4567, 1.4566, 1.4550, 1.4522, 1.4525, 1.4567, 1.4524, 1.4567, 1.4567,
         1.4386, 1.4378, 1.4385, 1.4385, 1.4386, 1.4195, 1.4385, 1.4373, 1.4351,
         2.2016, 2.2021, 2.2191, 2.1945, 2.1755, 2.1738, 2.2030, 2.1728, 2.1728,
         1.5098, 1.5083, 1.5157, 1.5157, 1.5099, 1.5157, 1.5157, 1.5157, 1.5157,
         1.7744, 1.7745, 1.7745, 1.7712, 1.7744, 1.7744, 1.7745, 1.7515, 1.7542,
         1.4359, 1.4407, 1.4407, 1.4407, 1.4323, 1.4407, 1.4365, 1.4406, 1.4407],
        [1.3246, 1.3227, 1.3068, 1.2982, 1.3216, 1.3200, 1.3211, 1.3216, 1.3216,
         1.3041, 1.2975, 1.2937, 1.2931, 1.3048, 1.2892, 1.3008, 1.3044, 1.2768,
         1.6436, 1.6171, 1.6405, 1.6400, 1.6394, 1.6394, 1.6416, 1.6431, 1.6431,
         3.4849, 3.2760, 3.2021, 3.2605, 3.4109, 3.2290, 3.4591, 3.2105, 3.1888,
         1.6474, 1.6399, 1.6381, 1.6413, 1.6443, 1.6204, 1.6456, 1.5851, 1.6116,
         1.3043, 1.2989, 1.2890, 1.3037, 1.2994, 1.2915, 1.3039, 1.3040, 1.3059],
        [1.4595, 1.4549, 1.4113, 1.4154, 1.4529, 1.4594, 1.4578, 1.4595, 1.4595,
         1.4403, 1.4376, 1.4325, 1.4272, 1.4414, 1.3996, 1.4354, 1.4414, 1.4361,
         1.7569, 1.7481, 1.7464, 1.7547, 1.7728, 1.7713, 1.7512, 1.7729, 1.7729,
         1.4764, 1.4810, 1.5185, 1.5131, 1.4817, 1.5170, 1.5053, 1.5185, 1.5154,
         2.2011, 2.1800, 2.1685, 2.1869, 2.2319, 2.2482, 2.2145, 2.3211, 2.3172,
         1.4275, 1.4187, 1.4330, 1.4435, 1.4302, 1.4402, 1.4098, 1.4374, 1.4435],
        [1.3232, 1.2356, 1.2308, 1.2492, 1.2425, 1.2525, 1.2514, 1.1943, 1.1943,
         1.2540, 1.2138, 1.2129, 1.2167, 1.2923, 1.1662, 1.1332, 1.2923, 1.1975,
         1.5915, 1.5676, 1.5496, 1.5441, 1.5669, 1.5633, 1.5840, 1.5685, 1.5685,
         1.3325, 1.3056, 1.3068, 1.3222, 1.3080, 1.3491, 1.3519, 1.3265, 1.3069,
         1.5686, 1.5689, 1.5737, 1.5632, 1.5398, 1.5437, 1.6052, 1.4936, 1.4627,
         4.0233, 3.6665, 3.7422, 3.7298, 3.7367, 3.4572, 4.0144, 3.7087, 3.4864]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 162 : 1778.772050719233
Test loss for epoch 162 : 195.95320769201723
Test Precision for epoch 162 : 0.26153846153846155
Test Recall for epoch 162 : 0.26153846153846155
Test F1 for epoch 162 : 0.26153846153846155


theta for epoch 163 : tensor([[3.6229, 3.6463, 3.7860, 3.7328, 3.7228, 3.6045, 3.6452, 3.5451, 3.5451,
         1.2638, 1.2440, 1.2427, 1.2454, 1.2818, 1.2238, 1.1964, 1.2818, 1.2308,
         1.6005, 1.5846, 1.6089, 1.5907, 1.5969, 1.5986, 1.6063, 1.5985, 1.5985,
         1.3410, 1.3519, 1.3366, 1.3600, 1.3397, 1.3723, 1.3646, 1.3509, 1.3366,
         1.5939, 1.6106, 1.5990, 1.5955, 1.6025, 1.5929, 1.6115, 1.5642, 1.5691,
         1.2368, 1.2640, 1.2558, 1.2736, 1.2315, 1.2230, 1.2166, 1.2965, 1.2524],
        [1.3640, 1.2112, 1.2014, 1.2439, 1.2444, 1.2565, 1.2505, 1.1549, 1.1549,
         3.6485, 3.7137, 3.5926, 3.8819, 3.6493, 4.1042, 3.5439, 3.6136, 3.9534,
         1.5631, 1.5513, 1.5256, 1.5245, 1.5451, 1.5545, 1.5787, 1.5546, 1.5546,
         1.3339, 1.3011, 1.2945, 1.3519, 1.2943, 1.3889, 1.3693, 1.3383, 1.2914,
         1.5341, 1.5888, 1.5533, 1.5403, 1.5353, 1.5721, 1.5913, 1.4271, 1.5251,
         1.1307, 1.2439, 1.2168, 1.2660, 1.1246, 1.1299, 1.0705, 1.3280, 1.2070],
        [1.4605, 1.4605, 1.4589, 1.4561, 1.4563, 1.4605, 1.4563, 1.4606, 1.4606,
         1.4345, 1.4338, 1.4345, 1.4344, 1.4345, 1.4155, 1.4345, 1.4333, 1.4310,
         2.2056, 2.2062, 2.2231, 2.1984, 2.1793, 2.1777, 2.2069, 2.1767, 2.1767,
         1.5115, 1.5099, 1.5173, 1.5173, 1.5115, 1.5173, 1.5173, 1.5173, 1.5173,
         1.7751, 1.7752, 1.7752, 1.7719, 1.7751, 1.7751, 1.7752, 1.7522, 1.7549,
         1.4342, 1.4389, 1.4389, 1.4389, 1.4305, 1.4389, 1.4348, 1.4389, 1.4389],
        [1.3286, 1.3267, 1.3108, 1.3022, 1.3256, 1.3240, 1.3251, 1.3256, 1.3256,
         1.3001, 1.2934, 1.2896, 1.2891, 1.3008, 1.2851, 1.2967, 1.3003, 1.2727,
         1.6479, 1.6214, 1.6448, 1.6443, 1.6437, 1.6437, 1.6460, 1.6474, 1.6474,
         3.4861, 3.2773, 3.2034, 3.2618, 3.4122, 3.2303, 3.4603, 3.2117, 3.1901,
         1.6481, 1.6406, 1.6389, 1.6420, 1.6450, 1.6211, 1.6463, 1.5858, 1.6123,
         1.3026, 1.2972, 1.2874, 1.3021, 1.2977, 1.2899, 1.3022, 1.3023, 1.3043],
        [1.4633, 1.4588, 1.4151, 1.4193, 1.4567, 1.4633, 1.4617, 1.4634, 1.4634,
         1.4362, 1.4335, 1.4285, 1.4231, 1.4374, 1.3956, 1.4314, 1.4373, 1.4320,
         1.7611, 1.7524, 1.7506, 1.7589, 1.7770, 1.7755, 1.7555, 1.7771, 1.7771,
         1.4781, 1.4826, 1.5201, 1.5147, 1.4834, 1.5186, 1.5070, 1.5201, 1.5170,
         2.2018, 2.1807, 2.1692, 2.1876, 2.2325, 2.2489, 2.2151, 2.3218, 2.3178,
         1.4258, 1.4170, 1.4313, 1.4417, 1.4285, 1.4385, 1.4080, 1.4356, 1.4418],
        [1.3138, 1.2276, 1.2226, 1.2409, 1.2342, 1.2442, 1.2431, 1.1872, 1.1872,
         1.2454, 1.2054, 1.2045, 1.2082, 1.2835, 1.1578, 1.1253, 1.2835, 1.1891,
         1.5901, 1.5663, 1.5481, 1.5429, 1.5659, 1.5622, 1.5827, 1.5674, 1.5674,
         1.3241, 1.2972, 1.2991, 1.3137, 1.2998, 1.3402, 1.3432, 1.3182, 1.2992,
         1.5651, 1.5652, 1.5702, 1.5597, 1.5361, 1.5400, 1.6015, 1.4898, 1.4588,
         4.0369, 3.6785, 3.7545, 3.7420, 3.7491, 3.4688, 4.0280, 3.7208, 3.4980]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 163 : 1778.5887659718176
Test loss for epoch 163 : 196.17532764580326
Test Precision for epoch 163 : 0.26153846153846155
Test Recall for epoch 163 : 0.26153846153846155
Test F1 for epoch 163 : 0.26153846153846155


theta for epoch 164 : tensor([[3.6206, 3.6441, 3.7839, 3.7306, 3.7206, 3.6023, 3.6429, 3.5428, 3.5428,
         1.2589, 1.2393, 1.2381, 1.2407, 1.2767, 1.2193, 1.1924, 1.2767, 1.2263,
         1.6043, 1.5885, 1.6127, 1.5947, 1.6009, 1.6025, 1.6101, 1.6025, 1.6025,
         1.3494, 1.3604, 1.3451, 1.3685, 1.3482, 1.3807, 1.3730, 1.3593, 1.3451,
         1.5959, 1.6125, 1.6010, 1.5974, 1.6044, 1.5947, 1.6133, 1.5661, 1.5710,
         1.2362, 1.2628, 1.2548, 1.2722, 1.2311, 1.2229, 1.2156, 1.2945, 1.2515],
        [1.3760, 1.2224, 1.2128, 1.2553, 1.2557, 1.2679, 1.2618, 1.1656, 1.1656,
         3.6357, 3.7011, 3.5795, 3.8701, 3.6365, 4.0935, 3.5306, 3.6007, 3.9420,
         1.5725, 1.5606, 1.5351, 1.5338, 1.5544, 1.5638, 1.5880, 1.5638, 1.5638,
         1.3478, 1.3149, 1.3080, 1.3657, 1.3080, 1.4030, 1.3833, 1.3521, 1.3048,
         1.5413, 1.5959, 1.5604, 1.5474, 1.5425, 1.5792, 1.5985, 1.4346, 1.5323,
         1.1379, 1.2500, 1.2232, 1.2718, 1.1319, 1.1375, 1.0767, 1.3331, 1.2135],
        [1.4621, 1.4621, 1.4605, 1.4577, 1.4579, 1.4622, 1.4579, 1.4622, 1.4622,
         1.4294, 1.4286, 1.4294, 1.4293, 1.4294, 1.4104, 1.4294, 1.4281, 1.4259,
         2.2086, 2.2092, 2.2261, 2.2013, 2.1822, 2.1806, 2.2098, 2.1796, 2.1796,
         1.5186, 1.5170, 1.5245, 1.5244, 1.5186, 1.5244, 1.5244, 1.5244, 1.5245,
         1.7764, 1.7765, 1.7765, 1.7732, 1.7764, 1.7764, 1.7765, 1.7535, 1.7562,
         1.4318, 1.4366, 1.4366, 1.4366, 1.4282, 1.4366, 1.4324, 1.4366, 1.4366],
        [1.3303, 1.3284, 1.3125, 1.3039, 1.3273, 1.3257, 1.3268, 1.3273, 1.3273,
         1.2949, 1.2883, 1.2845, 1.2839, 1.2956, 1.2800, 1.2915, 1.2952, 1.2676,
         1.6511, 1.6246, 1.6480, 1.6475, 1.6469, 1.6469, 1.6492, 1.6506, 1.6506,
         3.4921, 3.2834, 3.2095, 3.2679, 3.4182, 3.2364, 3.4664, 3.2178, 3.1962,
         1.6494, 1.6419, 1.6402, 1.6434, 1.6463, 1.6224, 1.6477, 1.5871, 1.6136,
         1.3003, 1.2949, 1.2851, 1.2997, 1.2954, 1.2876, 1.2999, 1.3000, 1.3020],
        [1.4649, 1.4604, 1.4167, 1.4209, 1.4583, 1.4649, 1.4633, 1.4650, 1.4650,
         1.4311, 1.4284, 1.4234, 1.4180, 1.4322, 1.3905, 1.4262, 1.4322, 1.4269,
         1.7643, 1.7555, 1.7538, 1.7621, 1.7801, 1.7786, 1.7586, 1.7803, 1.7803,
         1.4852, 1.4898, 1.5272, 1.5218, 1.4905, 1.5257, 1.5141, 1.5272, 1.5241,
         2.2030, 2.1820, 2.1705, 2.1889, 2.2338, 2.2502, 2.2164, 2.3230, 2.3190,
         1.4235, 1.4146, 1.4289, 1.4394, 1.4261, 1.4361, 1.4057, 1.4333, 1.4394],
        [1.3251, 1.2407, 1.2355, 1.2537, 1.2469, 1.2570, 1.2558, 1.2012, 1.2012,
         1.2452, 1.2062, 1.2053, 1.2088, 1.2826, 1.1588, 1.1281, 1.2826, 1.1902,
         1.5997, 1.5761, 1.5578, 1.5530, 1.5758, 1.5722, 1.5924, 1.5774, 1.5774,
         1.3398, 1.3131, 1.3155, 1.3294, 1.3159, 1.3555, 1.3587, 1.3340, 1.3156,
         1.5720, 1.5720, 1.5771, 1.5667, 1.5431, 1.5469, 1.6082, 1.4971, 1.4662,
         4.0221, 3.6622, 3.7384, 3.7258, 3.7330, 3.4519, 4.0132, 3.7047, 3.4812]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 164 : 1779.576507824101
Test loss for epoch 164 : 195.2527030463841
Test Precision for epoch 164 : 0.26153846153846155
Test Recall for epoch 164 : 0.26153846153846155
Test F1 for epoch 164 : 0.26153846153846155


theta for epoch 165 : tensor([[3.6170, 3.6404, 3.7804, 3.7271, 3.7169, 3.5986, 3.6393, 3.5391, 3.5391,
         1.2594, 1.2400, 1.2388, 1.2414, 1.2770, 1.2200, 1.1936, 1.2770, 1.2270,
         1.6029, 1.5872, 1.6113, 1.5934, 1.5996, 1.6012, 1.6087, 1.6012, 1.6012,
         1.3473, 1.3582, 1.3430, 1.3663, 1.3461, 1.3784, 1.3708, 1.3572, 1.3431,
         1.5973, 1.6138, 1.6024, 1.5988, 1.6058, 1.5961, 1.6146, 1.5676, 1.5724,
         1.2407, 1.2668, 1.2590, 1.2760, 1.2358, 1.2278, 1.2195, 1.2978, 1.2558],
        [1.3772, 1.2233, 1.2138, 1.2563, 1.2567, 1.2688, 1.2628, 1.1663, 1.1663,
         3.6319, 3.6976, 3.5755, 3.8673, 3.6327, 4.0919, 3.5263, 3.5968, 3.9396,
         1.5738, 1.5618, 1.5364, 1.5350, 1.5555, 1.5649, 1.5892, 1.5649, 1.5649,
         1.3497, 1.3168, 1.3096, 1.3677, 1.3099, 1.4051, 1.3853, 1.3540, 1.3065,
         1.5444, 1.5991, 1.5635, 1.5505, 1.5456, 1.5824, 1.6017, 1.4378, 1.5354,
         1.1441, 1.2557, 1.2291, 1.2773, 1.1384, 1.1442, 1.0817, 1.3382, 1.2195],
        [1.4567, 1.4567, 1.4550, 1.4522, 1.4525, 1.4567, 1.4524, 1.4567, 1.4567,
         1.4299, 1.4292, 1.4299, 1.4299, 1.4299, 1.4110, 1.4299, 1.4287, 1.4265,
         2.2072, 2.2078, 2.2247, 2.1999, 2.1809, 2.1793, 2.2085, 2.1782, 2.1782,
         1.5162, 1.5146, 1.5220, 1.5220, 1.5162, 1.5220, 1.5220, 1.5220, 1.5220,
         1.7776, 1.7776, 1.7776, 1.7744, 1.7775, 1.7775, 1.7776, 1.7547, 1.7574,
         1.4353, 1.4401, 1.4401, 1.4401, 1.4317, 1.4401, 1.4359, 1.4401, 1.4401],
        [1.3247, 1.3228, 1.3069, 1.2983, 1.3217, 1.3202, 1.3213, 1.3217, 1.3217,
         1.2955, 1.2888, 1.2850, 1.2845, 1.2962, 1.2805, 1.2921, 1.2957, 1.2681,
         1.6496, 1.6231, 1.6465, 1.6460, 1.6454, 1.6454, 1.6476, 1.6491, 1.6491,
         3.4905, 3.2818, 3.2078, 3.2662, 3.4166, 3.2347, 3.4648, 3.2162, 3.1945,
         1.6506, 1.6431, 1.6414, 1.6445, 1.6475, 1.6236, 1.6488, 1.5882, 1.6147,
         1.3039, 1.2984, 1.2886, 1.3033, 1.2990, 1.2912, 1.3034, 1.3035, 1.3055],
        [1.4595, 1.4549, 1.4112, 1.4154, 1.4529, 1.4594, 1.4578, 1.4596, 1.4596,
         1.4317, 1.4290, 1.4239, 1.4186, 1.4328, 1.3911, 1.4268, 1.4328, 1.4275,
         1.7628, 1.7540, 1.7523, 1.7606, 1.7786, 1.7771, 1.7571, 1.7787, 1.7787,
         1.4828, 1.4874, 1.5248, 1.5194, 1.4881, 1.5233, 1.5117, 1.5248, 1.5217,
         2.2041, 2.1831, 2.1716, 2.1900, 2.2349, 2.2513, 2.2175, 2.3240, 2.3201,
         1.4270, 1.4181, 1.4324, 1.4429, 1.4296, 1.4396, 1.4092, 1.4368, 1.4429],
        [1.3287, 1.2449, 1.2398, 1.2578, 1.2511, 1.2611, 1.2600, 1.2058, 1.2058,
         1.2491, 1.2105, 1.2096, 1.2131, 1.2860, 1.1634, 1.1334, 1.2861, 1.1947,
         1.6030, 1.5795, 1.5612, 1.5565, 1.5793, 1.5757, 1.5957, 1.5808, 1.5808,
         1.3446, 1.3181, 1.3207, 1.3342, 1.3209, 1.3601, 1.3633, 1.3389, 1.3207,
         1.5772, 1.5771, 1.5823, 1.5719, 1.5484, 1.5521, 1.6132, 1.5025, 1.4716,
         4.0145, 3.6530, 3.7294, 3.7168, 3.7241, 3.4422, 4.0055, 3.6957, 3.4716]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 165 : 1779.712463094405
Test loss for epoch 165 : 194.93762355892204
Test Precision for epoch 165 : 0.26153846153846155
Test Recall for epoch 165 : 0.26153846153846155
Test F1 for epoch 165 : 0.26153846153846155


theta for epoch 166 : tensor([[3.6158, 3.6391, 3.7794, 3.7260, 3.7157, 3.5974, 3.6381, 3.5378, 3.5378,
         1.2645, 1.2452, 1.2440, 1.2465, 1.2820, 1.2253, 1.1989, 1.2820, 1.2322,
         1.5973, 1.5815, 1.6056, 1.5878, 1.5940, 1.5956, 1.6031, 1.5956, 1.5956,
         1.3366, 1.3476, 1.3326, 1.3556, 1.3355, 1.3677, 1.3601, 1.3466, 1.3326,
         1.5962, 1.6126, 1.6013, 1.5977, 1.6047, 1.5949, 1.6133, 1.5664, 1.5713,
         1.2478, 1.2735, 1.2658, 1.2826, 1.2430, 1.2352, 1.2260, 1.3040, 1.2627],
        [1.3728, 1.2188, 1.2093, 1.2517, 1.2522, 1.2643, 1.2582, 1.1615, 1.1615,
         3.6361, 3.7020, 3.5795, 3.8725, 3.6370, 4.0982, 3.5302, 3.6009, 3.9451,
         1.5679, 1.5560, 1.5306, 1.5290, 1.5495, 1.5589, 1.5833, 1.5589, 1.5589,
         1.3415, 1.3087, 1.3013, 1.3595, 1.3017, 1.3970, 1.3772, 1.3458, 1.2982,
         1.5419, 1.5968, 1.5610, 1.5481, 1.5432, 1.5800, 1.5994, 1.4352, 1.5329,
         1.1481, 1.2596, 1.2330, 1.2811, 1.1425, 1.1484, 1.0842, 1.3418, 1.2235],
        [1.4518, 1.4517, 1.4501, 1.4473, 1.4475, 1.4518, 1.4475, 1.4518, 1.4518,
         1.4354, 1.4346, 1.4353, 1.4353, 1.4354, 1.4164, 1.4353, 1.4341, 1.4319,
         2.2023, 2.2028, 2.2198, 2.1952, 2.1762, 2.1745, 2.2037, 2.1735, 2.1735,
         1.5062, 1.5046, 1.5121, 1.5121, 1.5062, 1.5121, 1.5121, 1.5121, 1.5121,
         1.7765, 1.7766, 1.7766, 1.7733, 1.7765, 1.7765, 1.7766, 1.7536, 1.7563,
         1.4421, 1.4469, 1.4469, 1.4469, 1.4385, 1.4469, 1.4427, 1.4468, 1.4469],
        [1.3196, 1.3177, 1.3018, 1.2932, 1.3167, 1.3151, 1.3162, 1.3166, 1.3166,
         1.3009, 1.2942, 1.2904, 1.2898, 1.3015, 1.2859, 1.2975, 1.3011, 1.2735,
         1.6442, 1.6177, 1.6411, 1.6406, 1.6400, 1.6400, 1.6422, 1.6437, 1.6437,
         3.4827, 3.2739, 3.1998, 3.2584, 3.4088, 3.2268, 3.4570, 3.2082, 3.1865,
         1.6495, 1.6420, 1.6403, 1.6434, 1.6464, 1.6225, 1.6477, 1.5872, 1.6137,
         1.3107, 1.3052, 1.2954, 1.3101, 1.3058, 1.2980, 1.3102, 1.3103, 1.3123],
        [1.4546, 1.4500, 1.4062, 1.4104, 1.4479, 1.4545, 1.4529, 1.4546, 1.4546,
         1.4371, 1.4344, 1.4294, 1.4241, 1.4382, 1.3966, 1.4322, 1.4382, 1.4329,
         1.7575, 1.7487, 1.7470, 1.7553, 1.7733, 1.7718, 1.7518, 1.7735, 1.7735,
         1.4728, 1.4774, 1.5148, 1.5094, 1.4781, 1.5133, 1.5017, 1.5149, 1.5118,
         2.2031, 2.1821, 2.1706, 2.1890, 2.2338, 2.2503, 2.2165, 2.3230, 2.3190,
         1.4338, 1.4249, 1.4392, 1.4496, 1.4364, 1.4464, 1.4160, 1.4436, 1.4497],
        [1.3305, 1.2466, 1.2415, 1.2596, 1.2529, 1.2628, 1.2617, 1.2074, 1.2074,
         1.2562, 1.2177, 1.2168, 1.2203, 1.2931, 1.1706, 1.1407, 1.2931, 1.2020,
         1.6008, 1.5773, 1.5591, 1.5545, 1.5772, 1.5736, 1.5935, 1.5787, 1.5787,
         1.3402, 1.3138, 1.3163, 1.3299, 1.3166, 1.3557, 1.3589, 1.3346, 1.3163,
         1.5787, 1.5786, 1.5837, 1.5734, 1.5499, 1.5536, 1.6146, 1.5041, 1.4733,
         4.0125, 3.6494, 3.7261, 3.7135, 3.7209, 3.4382, 4.0035, 3.6923, 3.4676]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 166 : 1779.4252087983687
Test loss for epoch 166 : 195.138129490185
Test Precision for epoch 166 : 0.26153846153846155
Test Recall for epoch 166 : 0.26153846153846155
Test F1 for epoch 166 : 0.26153846153846155


theta for epoch 167 : tensor([[3.6196, 3.6430, 3.7833, 3.7299, 3.7196, 3.6012, 3.6419, 3.5417, 3.5417,
         1.2680, 1.2487, 1.2476, 1.2501, 1.2855, 1.2289, 1.2026, 1.2855, 1.2358,
         1.5925, 1.5768, 1.6009, 1.5832, 1.5893, 1.5910, 1.5983, 1.5909, 1.5909,
         1.3333, 1.3443, 1.3295, 1.3522, 1.3322, 1.3641, 1.3567, 1.3432, 1.3295,
         1.5925, 1.6087, 1.5975, 1.5940, 1.6009, 1.5910, 1.6095, 1.5627, 1.5675,
         1.2497, 1.2750, 1.2675, 1.2840, 1.2450, 1.2373, 1.2273, 1.3051, 1.2644],
        [1.3666, 1.2121, 1.2025, 1.2451, 1.2455, 1.2577, 1.2517, 1.1546, 1.1546,
         3.6454, 3.7116, 3.5886, 3.8828, 3.6463, 4.1097, 3.5391, 3.6101, 3.9558,
         1.5596, 1.5476, 1.5222, 1.5205, 1.5410, 1.5504, 1.5750, 1.5505, 1.5505,
         1.3338, 1.3008, 1.2933, 1.3518, 1.2938, 1.3895, 1.3696, 1.3380, 1.2902,
         1.5342, 1.5893, 1.5534, 1.5404, 1.5355, 1.5725, 1.5919, 1.4273, 1.5252,
         1.1445, 1.2560, 1.2294, 1.2775, 1.1389, 1.1450, 1.0790, 1.3382, 1.2199],
        [1.4521, 1.4520, 1.4504, 1.4476, 1.4478, 1.4521, 1.4478, 1.4521, 1.4521,
         1.4395, 1.4388, 1.4395, 1.4395, 1.4395, 1.4206, 1.4395, 1.4383, 1.4360,
         2.1985, 2.1991, 2.2160, 2.1916, 2.1726, 2.1709, 2.2002, 2.1699, 2.1699,
         1.5040, 1.5024, 1.5099, 1.5099, 1.5040, 1.5099, 1.5099, 1.5099, 1.5099,
         1.7732, 1.7733, 1.7733, 1.7700, 1.7732, 1.7732, 1.7733, 1.7503, 1.7530,
         1.4442, 1.4490, 1.4490, 1.4490, 1.4406, 1.4490, 1.4448, 1.4489, 1.4490],
        [1.3198, 1.3179, 1.3020, 1.2934, 1.3169, 1.3153, 1.3164, 1.3169, 1.3169,
         1.3050, 1.2983, 1.2945, 1.2940, 1.3057, 1.2901, 1.3016, 1.3052, 1.2777,
         1.6400, 1.6135, 1.6370, 1.6365, 1.6358, 1.6359, 1.6381, 1.6396, 1.6396,
         3.4815, 3.2727, 3.1986, 3.2571, 3.4075, 3.2256, 3.4558, 3.2069, 3.1852,
         1.6461, 1.6386, 1.6369, 1.6401, 1.6430, 1.6191, 1.6444, 1.5838, 1.6103,
         1.3128, 1.3073, 1.2975, 1.3122, 1.3079, 1.3001, 1.3123, 1.3124, 1.3144],
        [1.4549, 1.4503, 1.4065, 1.4106, 1.4482, 1.4548, 1.4532, 1.4549, 1.4549,
         1.4412, 1.4385, 1.4335, 1.4282, 1.4424, 1.4008, 1.4364, 1.4423, 1.4371,
         1.7534, 1.7446, 1.7429, 1.7513, 1.7693, 1.7678, 1.7478, 1.7694, 1.7694,
         1.4706, 1.4752, 1.5126, 1.5072, 1.4759, 1.5111, 1.4995, 1.5127, 1.5096,
         2.1999, 2.1789, 2.1674, 2.1858, 2.2306, 2.2471, 2.2133, 2.3197, 2.3158,
         1.4359, 1.4270, 1.4413, 1.4518, 1.4386, 1.4485, 1.4182, 1.4457, 1.4518],
        [1.3344, 1.2498, 1.2448, 1.2629, 1.2562, 1.2662, 1.2650, 1.2102, 1.2102,
         1.2608, 1.2222, 1.2213, 1.2248, 1.2978, 1.1751, 1.1446, 1.2979, 1.2063,
         1.5981, 1.5747, 1.5565, 1.5518, 1.5746, 1.5710, 1.5908, 1.5761, 1.5761,
         1.3404, 1.3139, 1.3162, 1.3301, 1.3166, 1.3560, 1.3591, 1.3347, 1.3163,
         1.5764, 1.5764, 1.5815, 1.5712, 1.5477, 1.5515, 1.6123, 1.5019, 1.4711,
         4.0123, 3.6477, 3.7247, 3.7120, 3.7194, 3.4360, 4.0033, 3.6907, 3.4655]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 167 : 1779.3864582868398
Test loss for epoch 167 : 195.46484517998095
Test Precision for epoch 167 : 0.26153846153846155
Test Recall for epoch 167 : 0.26153846153846155
Test F1 for epoch 167 : 0.26153846153846155


theta for epoch 168 : tensor([[3.6267, 3.6502, 3.7906, 3.7371, 3.7267, 3.6084, 3.6492, 3.5491, 3.5491,
         1.2642, 1.2448, 1.2436, 1.2462, 1.2816, 1.2255, 1.1985, 1.2817, 1.2319,
         1.5933, 1.5776, 1.6017, 1.5841, 1.5902, 1.5919, 1.5992, 1.5918, 1.5918,
         1.3406, 1.3516, 1.3371, 1.3595, 1.3397, 1.3713, 1.3639, 1.3506, 1.3371,
         1.5902, 1.6063, 1.5952, 1.5917, 1.5985, 1.5887, 1.6070, 1.5603, 1.5652,
         1.2459, 1.2710, 1.2635, 1.2798, 1.2413, 1.2337, 1.2229, 1.3006, 1.2605],
        [1.3610, 1.2059, 1.1963, 1.2391, 1.2395, 1.2518, 1.2457, 1.1482, 1.1482,
         3.6540, 3.7204, 3.5970, 3.8924, 3.6549, 4.1203, 3.5474, 3.6185, 3.9658,
         1.5546, 1.5425, 1.5170, 1.5152, 1.5359, 1.5453, 1.5701, 1.5454, 1.5454,
         1.3315, 1.2983, 1.2907, 1.3497, 1.2912, 1.3876, 1.3676, 1.3357, 1.2875,
         1.5267, 1.5821, 1.5460, 1.5330, 1.5281, 1.5653, 1.5848, 1.4195, 1.5177,
         1.1353, 1.2469, 1.2204, 1.2685, 1.1298, 1.1360, 1.0683, 1.3293, 1.2109],
        [1.4562, 1.4561, 1.4545, 1.4517, 1.4520, 1.4562, 1.4519, 1.4562, 1.4562,
         1.4365, 1.4357, 1.4364, 1.4364, 1.4365, 1.4175, 1.4364, 1.4352, 1.4330,
         2.2000, 2.2006, 2.2175, 2.1930, 2.1741, 2.1724, 2.2016, 2.1714, 2.1714,
         1.5127, 1.5111, 1.5185, 1.5185, 1.5127, 1.5185, 1.5185, 1.5185, 1.5185,
         1.7714, 1.7715, 1.7715, 1.7683, 1.7714, 1.7714, 1.7715, 1.7485, 1.7513,
         1.4411, 1.4458, 1.4458, 1.4458, 1.4374, 1.4458, 1.4417, 1.4458, 1.4458],
        [1.3238, 1.3220, 1.3060, 1.2974, 1.3209, 1.3193, 1.3204, 1.3209, 1.3209,
         1.3018, 1.2952, 1.2914, 1.2908, 1.3025, 1.2870, 1.2985, 1.3021, 1.2745,
         1.6416, 1.6151, 1.6385, 1.6380, 1.6374, 1.6374, 1.6396, 1.6411, 1.6411,
         3.4895, 3.2807, 3.2067, 3.2651, 3.4155, 3.2336, 3.4638, 3.2150, 3.1934,
         1.6443, 1.6368, 1.6351, 1.6382, 1.6412, 1.6173, 1.6425, 1.5819, 1.6084,
         1.3096, 1.3041, 1.2942, 1.3089, 1.3047, 1.2968, 1.3090, 1.3091, 1.3112],
        [1.4590, 1.4545, 1.4106, 1.4147, 1.4523, 1.4589, 1.4573, 1.4590, 1.4590,
         1.4382, 1.4355, 1.4305, 1.4252, 1.4393, 1.3978, 1.4333, 1.4393, 1.4341,
         1.7550, 1.7462, 1.7445, 1.7529, 1.7709, 1.7694, 1.7494, 1.7710, 1.7710,
         1.4793, 1.4840, 1.5213, 1.5159, 1.4846, 1.5198, 1.5082, 1.5213, 1.5182,
         2.1982, 2.1772, 2.1657, 2.1841, 2.2288, 2.2454, 2.2116, 2.3179, 2.3141,
         1.4327, 1.4238, 1.4382, 1.4486, 1.4354, 1.4453, 1.4150, 1.4425, 1.4486],
        [1.3396, 1.2540, 1.2490, 1.2672, 1.2605, 1.2705, 1.2694, 1.2138, 1.2138,
         1.2576, 1.2185, 1.2176, 1.2212, 1.2949, 1.1722, 1.1400, 1.2949, 1.2025,
         1.5996, 1.5762, 1.5579, 1.5533, 1.5761, 1.5724, 1.5923, 1.5776, 1.5776,
         1.3482, 1.3217, 1.3238, 1.3380, 1.3244, 1.3641, 1.3671, 1.3425, 1.3238,
         1.5747, 1.5746, 1.5797, 1.5694, 1.5459, 1.5497, 1.6106, 1.5001, 1.4693,
         4.0127, 3.6466, 3.7238, 3.7111, 3.7186, 3.4344, 4.0038, 3.6897, 3.4640]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 168 : 1778.8353978658417
Test loss for epoch 168 : 195.58392333114386
Test Precision for epoch 168 : 0.26153846153846155
Test Recall for epoch 168 : 0.26153846153846155
Test F1 for epoch 168 : 0.26153846153846155


theta for epoch 169 : tensor([[3.6281, 3.6515, 3.7920, 3.7386, 3.7281, 3.6098, 3.6505, 3.5504, 3.5504,
         1.2561, 1.2370, 1.2358, 1.2383, 1.2734, 1.2182, 1.1913, 1.2734, 1.2242,
         1.5998, 1.5842, 1.6081, 1.5908, 1.5969, 1.5985, 1.6057, 1.5985, 1.5985,
         1.3483, 1.3594, 1.3452, 1.3672, 1.3476, 1.3787, 1.3715, 1.3584, 1.3452,
         1.5923, 1.6083, 1.5973, 1.5938, 1.6006, 1.5907, 1.6090, 1.5624, 1.5673,
         1.2439, 1.2686, 1.2613, 1.2774, 1.2394, 1.2319, 1.2204, 1.2979, 1.2584],
        [1.3693, 1.2145, 1.2049, 1.2477, 1.2480, 1.2603, 1.2542, 1.1569, 1.1569,
         3.6434, 3.7101, 3.5863, 3.8828, 3.6443, 4.1119, 3.5364, 3.6079, 3.9566,
         1.5648, 1.5527, 1.5273, 1.5253, 1.5460, 1.5554, 1.5802, 1.5555, 1.5555,
         1.3432, 1.3100, 1.3022, 1.3614, 1.3029, 1.3994, 1.3793, 1.3474, 1.2991,
         1.5329, 1.5883, 1.5522, 1.5391, 1.5343, 1.5714, 1.5910, 1.4259, 1.5239,
         1.1391, 1.2504, 1.2239, 1.2720, 1.1335, 1.1397, 1.0708, 1.3326, 1.2144],
        [1.4567, 1.4566, 1.4550, 1.4522, 1.4525, 1.4567, 1.4524, 1.4567, 1.4567,
         1.4286, 1.4279, 1.4286, 1.4285, 1.4286, 1.4096, 1.4286, 1.4274, 1.4251,
         2.2061, 2.2067, 2.2236, 2.1989, 2.1799, 2.1782, 2.2074, 2.1772, 2.1772,
         1.5205, 1.5189, 1.5264, 1.5264, 1.5205, 1.5263, 1.5263, 1.5264, 1.5264,
         1.7734, 1.7735, 1.7735, 1.7703, 1.7734, 1.7734, 1.7735, 1.7505, 1.7533,
         1.4388, 1.4435, 1.4435, 1.4435, 1.4352, 1.4435, 1.4394, 1.4435, 1.4435],
        [1.3241, 1.3223, 1.3064, 1.2977, 1.3213, 1.3197, 1.3208, 1.3213, 1.3213,
         1.2939, 1.2873, 1.2835, 1.2829, 1.2946, 1.2790, 1.2905, 1.2942, 1.2666,
         1.6480, 1.6215, 1.6449, 1.6444, 1.6438, 1.6438, 1.6461, 1.6475, 1.6475,
         3.4968, 3.2881, 3.2141, 3.2725, 3.4228, 3.2409, 3.4711, 3.2224, 3.2008,
         1.6463, 1.6388, 1.6370, 1.6402, 1.6432, 1.6192, 1.6445, 1.5839, 1.6104,
         1.3072, 1.3017, 1.2919, 1.3065, 1.3023, 1.2945, 1.3066, 1.3067, 1.3088],
        [1.4595, 1.4550, 1.4111, 1.4151, 1.4528, 1.4594, 1.4578, 1.4595, 1.4595,
         1.4303, 1.4276, 1.4226, 1.4174, 1.4315, 1.3900, 1.4255, 1.4314, 1.4262,
         1.7614, 1.7526, 1.7510, 1.7593, 1.7772, 1.7758, 1.7558, 1.7774, 1.7774,
         1.4872, 1.4919, 1.5291, 1.5237, 1.4925, 1.5276, 1.5160, 1.5292, 1.5260,
         2.2001, 2.1792, 2.1677, 2.1860, 2.2307, 2.2473, 2.2136, 2.3198, 2.3159,
         1.4305, 1.4216, 1.4359, 1.4463, 1.4332, 1.4431, 1.4128, 1.4403, 1.4464],
        [1.3428, 1.2563, 1.2514, 1.2697, 1.2630, 1.2730, 1.2719, 1.2157, 1.2157,
         1.2502, 1.2113, 1.2104, 1.2139, 1.2874, 1.1659, 1.1332, 1.2874, 1.1954,
         1.6063, 1.5829, 1.5646, 1.5600, 1.5828, 1.5792, 1.5990, 1.5843, 1.5843,
         1.3562, 1.3297, 1.3316, 1.3460, 1.3323, 1.3723, 1.3752, 1.3505, 1.3316,
         1.5771, 1.5770, 1.5822, 1.5718, 1.5483, 1.5521, 1.6130, 1.5025, 1.4717,
         4.0124, 3.6447, 3.7221, 3.7093, 3.7170, 3.4321, 4.0035, 3.6879, 3.4616]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 169 : 1779.4119717788126
Test loss for epoch 169 : 194.98085867960305
Test Precision for epoch 169 : 0.26153846153846155
Test Recall for epoch 169 : 0.26153846153846155
Test F1 for epoch 169 : 0.26153846153846155


theta for epoch 170 : tensor([[3.6285, 3.6519, 3.7926, 3.7391, 3.7285, 3.6102, 3.6510, 3.5509, 3.5509,
         1.2530, 1.2340, 1.2328, 1.2352, 1.2702, 1.2155, 1.1884, 1.2702, 1.2211,
         1.6046, 1.5891, 1.6130, 1.5957, 1.6018, 1.6034, 1.6105, 1.6034, 1.6034,
         1.3384, 1.3496, 1.3356, 1.3573, 1.3378, 1.3687, 1.3615, 1.3486, 1.3357,
         1.5967, 1.6127, 1.6018, 1.5982, 1.6050, 1.5950, 1.6133, 1.5669, 1.5717,
         1.2457, 1.2703, 1.2630, 1.2790, 1.2413, 1.2339, 1.2217, 1.2993, 1.2601],
        [1.3689, 1.2143, 1.2048, 1.2475, 1.2479, 1.2601, 1.2540, 1.1567, 1.1567,
         3.6411, 3.7080, 3.5837, 3.8815, 3.6420, 4.1117, 3.5337, 3.6054, 3.9556,
         1.5699, 1.5577, 1.5323, 1.5303, 1.5509, 1.5604, 1.5853, 1.5604, 1.5604,
         1.3389, 1.3058, 1.2979, 1.3571, 1.2986, 1.3952, 1.3751, 1.3431, 1.2948,
         1.5376, 1.5932, 1.5569, 1.5439, 1.5391, 1.5763, 1.5959, 1.4306, 1.5287,
         1.1415, 1.2530, 1.2264, 1.2746, 1.1359, 1.1421, 1.0718, 1.3354, 1.2169],
        [1.4524, 1.4523, 1.4507, 1.4479, 1.4482, 1.4524, 1.4481, 1.4524, 1.4524,
         1.4259, 1.4252, 1.4259, 1.4258, 1.4259, 1.4070, 1.4259, 1.4247, 1.4224,
         2.2110, 2.2115, 2.2284, 2.2035, 2.1846, 2.1829, 2.2121, 2.1819, 2.1819,
         1.5117, 1.5101, 1.5175, 1.5175, 1.5117, 1.5175, 1.5175, 1.5175, 1.5175,
         1.7780, 1.7781, 1.7781, 1.7748, 1.7780, 1.7780, 1.7781, 1.7551, 1.7579,
         1.4408, 1.4456, 1.4456, 1.4456, 1.4372, 1.4456, 1.4414, 1.4455, 1.4456],
        [1.3196, 1.3178, 1.3018, 1.2931, 1.3167, 1.3151, 1.3162, 1.3168, 1.3168,
         1.2911, 1.2845, 1.2807, 1.2801, 1.2918, 1.2763, 1.2878, 1.2914, 1.2638,
         1.6531, 1.6266, 1.6500, 1.6495, 1.6489, 1.6489, 1.6512, 1.6526, 1.6526,
         3.4903, 3.2815, 3.2074, 3.2659, 3.4163, 3.2343, 3.4646, 3.2157, 3.1941,
         1.6508, 1.6433, 1.6416, 1.6448, 1.6477, 1.6238, 1.6490, 1.5884, 1.6150,
         1.3092, 1.3037, 1.2939, 1.3085, 1.3043, 1.2965, 1.3086, 1.3087, 1.3108],
        [1.4552, 1.4507, 1.4068, 1.4108, 1.4485, 1.4551, 1.4536, 1.4552, 1.4552,
         1.4276, 1.4249, 1.4200, 1.4147, 1.4288, 1.3873, 1.4228, 1.4287, 1.4235,
         1.7665, 1.7577, 1.7561, 1.7644, 1.7823, 1.7808, 1.7609, 1.7825, 1.7825,
         1.4783, 1.4830, 1.5203, 1.5149, 1.4836, 1.5188, 1.5071, 1.5203, 1.5172,
         2.2045, 2.1836, 2.1722, 2.1905, 2.2351, 2.2518, 2.2180, 2.3241, 2.3203,
         1.4326, 1.4236, 1.4380, 1.4484, 1.4352, 1.4451, 1.4149, 1.4423, 1.4484],
        [1.3391, 1.2517, 1.2469, 1.2653, 1.2586, 1.2686, 1.2675, 1.2107, 1.2107,
         1.2464, 1.2074, 1.2064, 1.2101, 1.2838, 1.1627, 1.1289, 1.2838, 1.1914,
         1.6102, 1.5867, 1.5683, 1.5638, 1.5866, 1.5830, 1.6028, 1.5881, 1.5881,
         1.3470, 1.3204, 1.3221, 1.3368, 1.3229, 1.3633, 1.3661, 1.3412, 1.3221,
         1.5807, 1.5806, 1.5858, 1.5755, 1.5519, 1.5557, 1.6166, 1.5060, 1.4752,
         4.0177, 3.6486, 3.7262, 3.7133, 3.7212, 3.4355, 4.0089, 3.6919, 3.4651]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 170 : 1779.3763999030587
Test loss for epoch 170 : 195.06674004933768
Test Precision for epoch 170 : 0.26153846153846155
Test Recall for epoch 170 : 0.26153846153846155
Test F1 for epoch 170 : 0.26153846153846155


theta for epoch 171 : tensor([[3.6311, 3.6545, 3.7953, 3.7418, 3.7311, 3.6128, 3.6536, 3.5535, 3.5535,
         1.2557, 1.2367, 1.2355, 1.2380, 1.2730, 1.2186, 1.1911, 1.2730, 1.2239,
         1.5999, 1.5843, 1.6082, 1.5911, 1.5971, 1.5988, 1.6058, 1.5988, 1.5988,
         1.3300, 1.3412, 1.3275, 1.3488, 1.3295, 1.3600, 1.3529, 1.3402, 1.3275,
         1.5984, 1.6143, 1.6035, 1.5999, 1.6066, 1.5966, 1.6148, 1.5685, 1.5733,
         1.2473, 1.2717, 1.2645, 1.2804, 1.2428, 1.2355, 1.2228, 1.3005, 1.2616],
        [1.3639, 1.2093, 1.1997, 1.2425, 1.2428, 1.2551, 1.2490, 1.1517, 1.1517,
         3.6467, 3.7140, 3.5892, 3.8881, 3.6477, 4.1194, 3.5391, 3.6110, 3.9626,
         1.5639, 1.5517, 1.5263, 1.5241, 1.5448, 1.5543, 1.5793, 1.5543, 1.5543,
         1.3311, 1.2979, 1.2899, 1.3493, 1.2907, 1.3874, 1.3673, 1.3352, 1.2868,
         1.5368, 1.5926, 1.5562, 1.5431, 1.5383, 1.5756, 1.5953, 1.4296, 1.5278,
         1.1398, 1.2517, 1.2250, 1.2734, 1.1342, 1.1402, 1.0686, 1.3345, 1.2154],
        [1.4493, 1.4492, 1.4476, 1.4448, 1.4451, 1.4493, 1.4450, 1.4493, 1.4493,
         1.4293, 1.4286, 1.4293, 1.4293, 1.4293, 1.4104, 1.4293, 1.4281, 1.4259,
         2.2072, 2.2077, 2.2246, 2.1999, 2.1810, 2.1793, 2.2085, 2.1783, 2.1783,
         1.5046, 1.5030, 1.5104, 1.5104, 1.5046, 1.5105, 1.5104, 1.5104, 1.5104,
         1.7801, 1.7802, 1.7802, 1.7769, 1.7800, 1.7800, 1.7801, 1.7572, 1.7599,
         1.4430, 1.4477, 1.4477, 1.4477, 1.4394, 1.4477, 1.4436, 1.4477, 1.4477],
        [1.3162, 1.3145, 1.2985, 1.2898, 1.3134, 1.3118, 1.3129, 1.3135, 1.3135,
         1.2945, 1.2879, 1.2841, 1.2835, 1.2952, 1.2797, 1.2912, 1.2948, 1.2672,
         1.6490, 1.6225, 1.6459, 1.6454, 1.6448, 1.6448, 1.6470, 1.6485, 1.6485,
         3.4854, 3.2765, 3.2024, 3.2609, 3.4114, 3.2294, 3.4598, 3.2107, 3.1891,
         1.6528, 1.6454, 1.6436, 1.6468, 1.6498, 1.6258, 1.6511, 1.5905, 1.6170,
         1.3113, 1.3058, 1.2959, 1.3106, 1.3064, 1.2986, 1.3107, 1.3107, 1.3129],
        [1.4522, 1.4477, 1.4038, 1.4076, 1.4455, 1.4521, 1.4505, 1.4521, 1.4521,
         1.4311, 1.4284, 1.4234, 1.4182, 1.4322, 1.3908, 1.4262, 1.4322, 1.4270,
         1.7625, 1.7537, 1.7521, 1.7604, 1.7783, 1.7768, 1.7569, 1.7785, 1.7785,
         1.4712, 1.4760, 1.5132, 1.5079, 1.4765, 1.5117, 1.5001, 1.5132, 1.5101,
         2.2065, 2.1857, 2.1742, 2.1925, 2.2371, 2.2538, 2.2201, 2.3260, 2.3222,
         1.4348, 1.4258, 1.4401, 1.4505, 1.4374, 1.4473, 1.4171, 1.4444, 1.4506],
        [1.3342, 1.2456, 1.2408, 1.2594, 1.2526, 1.2628, 1.2616, 1.2040, 1.2040,
         1.2473, 1.2079, 1.2069, 1.2107, 1.2851, 1.1637, 1.1284, 1.2851, 1.1918,
         1.6038, 1.5803, 1.5619, 1.5574, 1.5803, 1.5766, 1.5965, 1.5818, 1.5818,
         1.3373, 1.3106, 1.3120, 1.3272, 1.3130, 1.3539, 1.3566, 1.3315, 1.3121,
         1.5807, 1.5806, 1.5859, 1.5755, 1.5519, 1.5556, 1.6167, 1.5059, 1.4750,
         4.0264, 3.6557, 3.7336, 3.7207, 3.7287, 3.4423, 4.0176, 3.6992, 3.4719]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 171 : 1779.0462360661954
Test loss for epoch 171 : 195.50181070080532
Test Precision for epoch 171 : 0.26153846153846155
Test Recall for epoch 171 : 0.26153846153846155
Test F1 for epoch 171 : 0.26153846153846155


theta for epoch 172 : tensor([[3.6333, 3.6568, 3.7977, 3.7441, 3.7334, 3.6151, 3.6559, 3.5558, 3.5558,
         1.2611, 1.2423, 1.2412, 1.2435, 1.2781, 1.2246, 1.1972, 1.2781, 1.2296,
         1.5928, 1.5772, 1.6010, 1.5840, 1.5901, 1.5917, 1.5987, 1.5917, 1.5917,
         1.3347, 1.3459, 1.3325, 1.3535, 1.3343, 1.3645, 1.3575, 1.3449, 1.3325,
         1.5955, 1.6112, 1.6005, 1.5969, 1.6037, 1.5936, 1.6118, 1.5656, 1.5704,
         1.2443, 1.2686, 1.2614, 1.2773, 1.2399, 1.2325, 1.2194, 1.2973, 1.2586],
        [1.3707, 1.2166, 1.2070, 1.2497, 1.2501, 1.2623, 1.2563, 1.1592, 1.1592,
         3.6433, 3.7108, 3.5856, 3.8856, 3.6443, 4.1180, 3.5352, 3.6074, 3.9605,
         1.5619, 1.5497, 1.5245, 1.5221, 1.5428, 1.5522, 1.5772, 1.5522, 1.5522,
         1.3390, 1.3058, 1.2978, 1.3572, 1.2986, 1.3953, 1.3752, 1.3431, 1.2947,
         1.5372, 1.5930, 1.5566, 1.5435, 1.5387, 1.5760, 1.5957, 1.4303, 1.5283,
         1.1412, 1.2531, 1.2263, 1.2748, 1.1354, 1.1414, 1.0688, 1.3361, 1.2166],
        [1.4513, 1.4512, 1.4495, 1.4467, 1.4470, 1.4512, 1.4469, 1.4512, 1.4512,
         1.4348, 1.4341, 1.4348, 1.4348, 1.4348, 1.4159, 1.4348, 1.4336, 1.4314,
         2.2007, 2.2012, 2.2181, 2.1937, 2.1748, 2.1731, 2.2023, 2.1721, 2.1721,
         1.5094, 1.5078, 1.5152, 1.5152, 1.5094, 1.5152, 1.5152, 1.5152, 1.5152,
         1.7771, 1.7772, 1.7772, 1.7740, 1.7771, 1.7771, 1.7772, 1.7542, 1.7570,
         1.4401, 1.4448, 1.4448, 1.4448, 1.4364, 1.4448, 1.4407, 1.4448, 1.4448],
        [1.3180, 1.3163, 1.3003, 1.2915, 1.3152, 1.3136, 1.3147, 1.3154, 1.3154,
         1.2999, 1.2933, 1.2895, 1.2889, 1.3006, 1.2851, 1.2966, 1.3002, 1.2727,
         1.6418, 1.6153, 1.6388, 1.6383, 1.6377, 1.6377, 1.6399, 1.6414, 1.6414,
         3.4904, 3.2816, 3.2075, 3.2659, 3.4163, 3.2344, 3.4648, 3.2157, 3.1941,
         1.6498, 1.6423, 1.6406, 1.6437, 1.6467, 1.6227, 1.6480, 1.5874, 1.6139,
         1.3082, 1.3027, 1.2929, 1.3075, 1.3033, 1.2955, 1.3076, 1.3077, 1.3098],
        [1.4541, 1.4496, 1.4058, 1.4096, 1.4474, 1.4540, 1.4525, 1.4541, 1.4541,
         1.4365, 1.4339, 1.4289, 1.4237, 1.4377, 1.3964, 1.4317, 1.4376, 1.4325,
         1.7556, 1.7468, 1.7452, 1.7535, 1.7714, 1.7699, 1.7500, 1.7716, 1.7716,
         1.4760, 1.4809, 1.5180, 1.5126, 1.4813, 1.5165, 1.5048, 1.5180, 1.5149,
         2.2036, 2.1828, 2.1714, 2.1896, 2.2342, 2.2509, 2.2172, 2.3231, 2.3193,
         1.4318, 1.4229, 1.4372, 1.4476, 1.4345, 1.4443, 1.4142, 1.4415, 1.4476],
        [1.3349, 1.2450, 1.2403, 1.2590, 1.2523, 1.2624, 1.2612, 1.2028, 1.2028,
         1.2508, 1.2115, 1.2105, 1.2142, 1.2885, 1.1678, 1.1322, 1.2885, 1.1954,
         1.5953, 1.5718, 1.5534, 1.5488, 1.5718, 1.5681, 1.5880, 1.5733, 1.5733,
         1.3394, 1.3126, 1.3137, 1.3293, 1.3149, 1.3563, 1.3588, 1.3335, 1.3138,
         1.5763, 1.5762, 1.5815, 1.5711, 1.5475, 1.5512, 1.6123, 1.5014, 1.4705,
         4.0311, 3.6589, 3.7370, 3.7240, 3.7321, 3.4451, 4.0223, 3.7024, 3.4747]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 172 : 1778.9013743043758
Test loss for epoch 172 : 195.41699950934282
Test Precision for epoch 172 : 0.26153846153846155
Test Recall for epoch 172 : 0.26153846153846155
Test F1 for epoch 172 : 0.26153846153846155


theta for epoch 173 : tensor([[3.6313, 3.6547, 3.7957, 3.7421, 3.7313, 3.6130, 3.6538, 3.5537, 3.5537,
         1.2656, 1.2473, 1.2462, 1.2484, 1.2825, 1.2299, 1.2033, 1.2825, 1.2347,
         1.5914, 1.5759, 1.5997, 1.5828, 1.5889, 1.5905, 1.5973, 1.5905, 1.5905,
         1.3441, 1.3554, 1.3422, 1.3629, 1.3439, 1.3737, 1.3668, 1.3544, 1.3422,
         1.5918, 1.6074, 1.5968, 1.5932, 1.5999, 1.5899, 1.6079, 1.5618, 1.5666,
         1.2396, 1.2639, 1.2567, 1.2726, 1.2352, 1.2278, 1.2144, 1.2926, 1.2539],
        [1.3858, 1.2329, 1.2232, 1.2658, 1.2662, 1.2784, 1.2723, 1.1760, 1.1760,
         3.6293, 3.6970, 3.5713, 3.8726, 3.6303, 4.1061, 3.5207, 3.5933, 3.9478,
         1.5703, 1.5582, 1.5331, 1.5308, 1.5513, 1.5607, 1.5856, 1.5607, 1.5607,
         1.3571, 1.3241, 1.3162, 1.3753, 1.3170, 1.4133, 1.3932, 1.3613, 1.3131,
         1.5424, 1.5978, 1.5616, 1.5487, 1.5439, 1.5810, 1.6006, 1.4361, 1.5335,
         1.1477, 1.2592, 1.2324, 1.2809, 1.1419, 1.1476, 1.0745, 1.3421, 1.2228],
        [1.4524, 1.4523, 1.4507, 1.4479, 1.4482, 1.4524, 1.4481, 1.4524, 1.4524,
         1.4388, 1.4381, 1.4388, 1.4387, 1.4388, 1.4199, 1.4388, 1.4376, 1.4353,
         2.1989, 2.1994, 2.2163, 2.1919, 2.1730, 2.1713, 2.2006, 2.1703, 2.1703,
         1.5175, 1.5159, 1.5233, 1.5233, 1.5175, 1.5233, 1.5233, 1.5233, 1.5233,
         1.7728, 1.7729, 1.7729, 1.7696, 1.7727, 1.7727, 1.7728, 1.7499, 1.7527,
         1.4347, 1.4395, 1.4395, 1.4395, 1.4311, 1.4395, 1.4354, 1.4394, 1.4395],
        [1.3190, 1.3173, 1.3013, 1.2926, 1.3162, 1.3146, 1.3157, 1.3164, 1.3164,
         1.3038, 1.2973, 1.2934, 1.2929, 1.3045, 1.2891, 1.3006, 1.3041, 1.2766,
         1.6397, 1.6132, 1.6367, 1.6362, 1.6355, 1.6356, 1.6378, 1.6393, 1.6393,
         3.4981, 3.2893, 3.2153, 3.2737, 3.4241, 3.2421, 3.4725, 3.2235, 3.2020,
         1.6454, 1.6379, 1.6362, 1.6393, 1.6423, 1.6183, 1.6436, 1.5830, 1.6095,
         1.3028, 1.2972, 1.2874, 1.3021, 1.2979, 1.2901, 1.3021, 1.3022, 1.3044],
        [1.4553, 1.4508, 1.4070, 1.4107, 1.4486, 1.4552, 1.4536, 1.4552, 1.4552,
         1.4405, 1.4378, 1.4329, 1.4277, 1.4416, 1.4004, 1.4357, 1.4416, 1.4365,
         1.7536, 1.7448, 1.7432, 1.7515, 1.7694, 1.7679, 1.7480, 1.7696, 1.7696,
         1.4841, 1.4891, 1.5261, 1.5208, 1.4895, 1.5246, 1.5130, 1.5261, 1.5230,
         2.1994, 2.1786, 2.1672, 2.1854, 2.2300, 2.2468, 2.2130, 2.3188, 2.3151,
         1.4266, 1.4176, 1.4319, 1.4423, 1.4292, 1.4390, 1.4089, 1.4362, 1.4423],
        [1.3369, 1.2457, 1.2411, 1.2599, 1.2531, 1.2633, 1.2621, 1.2027, 1.2027,
         1.2537, 1.2150, 1.2140, 1.2176, 1.2915, 1.1717, 1.1370, 1.2915, 1.1990,
         1.5926, 1.5691, 1.5508, 1.5461, 1.5691, 1.5654, 1.5853, 1.5706, 1.5706,
         1.3461, 1.3192, 1.3200, 1.3361, 1.3214, 1.3634, 1.3658, 1.3402, 1.3201,
         1.5715, 1.5713, 1.5766, 1.5662, 1.5426, 1.5463, 1.6075, 1.4965, 1.4655,
         4.0323, 3.6586, 3.7369, 3.7239, 3.7322, 3.4444, 4.0236, 3.7022, 3.4740]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 173 : 1779.708346217805
Test loss for epoch 173 : 195.03186629167627
Test Precision for epoch 173 : 0.26153846153846155
Test Recall for epoch 173 : 0.26153846153846155
Test F1 for epoch 173 : 0.26153846153846155


theta for epoch 174 : tensor([[3.6288, 3.6522, 3.7934, 3.7398, 3.7288, 3.6106, 3.6514, 3.5512, 3.5512,
         1.2692, 1.2512, 1.2501, 1.2522, 1.2860, 1.2341, 1.2081, 1.2860, 1.2387,
         1.5963, 1.5808, 1.6046, 1.5877, 1.5938, 1.5954, 1.6022, 1.5954, 1.5954,
         1.3383, 1.3496, 1.3366, 1.3570, 1.3381, 1.3677, 1.3609, 1.3486, 1.3366,
         1.5908, 1.6065, 1.5959, 1.5923, 1.5990, 1.5889, 1.6069, 1.5609, 1.5657,
         1.2378, 1.2623, 1.2550, 1.2710, 1.2333, 1.2259, 1.2122, 1.2911, 1.2522],
        [1.3912, 1.2397, 1.2299, 1.2723, 1.2727, 1.2849, 1.2788, 1.1834, 1.1834,
         3.6226, 3.6904, 3.5644, 3.8668, 3.6235, 4.1014, 3.5136, 3.5865, 3.9423,
         1.5790, 1.5669, 1.5419, 1.5396, 1.5601, 1.5694, 1.5942, 1.5695, 1.5695,
         1.3598, 1.3268, 1.3192, 1.3779, 1.3198, 1.4155, 1.3956, 1.3640, 1.3161,
         1.5460, 1.6012, 1.5652, 1.5522, 1.5475, 1.5845, 1.6039, 1.4400, 1.5371,
         1.1513, 1.2628, 1.2359, 1.2845, 1.1454, 1.1510, 1.0771, 1.3458, 1.2263],
        [1.4498, 1.4497, 1.4480, 1.4452, 1.4456, 1.4497, 1.4454, 1.4497, 1.4497,
         1.4421, 1.4414, 1.4421, 1.4420, 1.4421, 1.4232, 1.4421, 1.4409, 1.4386,
         2.2030, 2.2035, 2.2204, 2.1959, 2.1770, 2.1753, 2.2045, 2.1743, 2.1743,
         1.5112, 1.5096, 1.5171, 1.5171, 1.5112, 1.5171, 1.5170, 1.5171, 1.5171,
         1.7715, 1.7716, 1.7716, 1.7684, 1.7715, 1.7715, 1.7716, 1.7487, 1.7514,
         1.4330, 1.4377, 1.4377, 1.4377, 1.4293, 1.4377, 1.4336, 1.4377, 1.4377],
        [1.3161, 1.3145, 1.2985, 1.2897, 1.3134, 1.3118, 1.3129, 1.3136, 1.3136,
         1.3071, 1.3005, 1.2967, 1.2961, 1.3078, 1.2924, 1.3039, 1.3073, 1.2799,
         1.6441, 1.6176, 1.6410, 1.6405, 1.6399, 1.6400, 1.6422, 1.6436, 1.6436,
         3.4938, 3.2849, 3.2108, 3.2692, 3.4197, 3.2377, 3.4682, 3.2191, 3.1975,
         1.6441, 1.6366, 1.6348, 1.6380, 1.6410, 1.6170, 1.6423, 1.5817, 1.6082,
         1.3009, 1.2954, 1.2856, 1.3002, 1.2960, 1.2882, 1.3003, 1.3003, 1.3025],
        [1.4526, 1.4482, 1.4044, 1.4080, 1.4459, 1.4525, 1.4510, 1.4526, 1.4526,
         1.4438, 1.4411, 1.4362, 1.4310, 1.4449, 1.4038, 1.4390, 1.4449, 1.4398,
         1.7580, 1.7492, 1.7476, 1.7559, 1.7738, 1.7723, 1.7523, 1.7739, 1.7739,
         1.4779, 1.4828, 1.5198, 1.5145, 1.4832, 1.5184, 1.5067, 1.5199, 1.5167,
         2.1982, 2.1774, 2.1660, 2.1842, 2.2288, 2.2456, 2.2118, 2.3175, 2.3138,
         1.4248, 1.4158, 1.4301, 1.4405, 1.4274, 1.4373, 1.4072, 1.4344, 1.4405],
        [1.3338, 1.2406, 1.2362, 1.2552, 1.2484, 1.2587, 1.2575, 1.1966, 1.1966,
         1.2551, 1.2166, 1.2157, 1.2191, 1.2933, 1.1737, 1.1392, 1.2933, 1.2007,
         1.5949, 1.5712, 1.5529, 1.5481, 1.5711, 1.5675, 1.5875, 1.5726, 1.5726,
         1.3383, 1.3113, 1.3116, 1.3283, 1.3133, 1.3560, 1.3582, 1.3323, 1.3116,
         1.5684, 1.5684, 1.5736, 1.5632, 1.5396, 1.5434, 1.6046, 1.4933, 1.4624,
         4.0382, 3.6629, 3.7415, 3.7283, 3.7368, 3.4483, 4.0295, 3.7066, 3.4780]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 174 : 1779.7098963195276
Test loss for epoch 174 : 195.17292386424631
Test Precision for epoch 174 : 0.26153846153846155
Test Recall for epoch 174 : 0.26153846153846155
Test F1 for epoch 174 : 0.26153846153846155


theta for epoch 175 : tensor([[3.6278, 3.6511, 3.7924, 3.7388, 3.7278, 3.6095, 3.6503, 3.5501, 3.5501,
         1.2698, 1.2521, 1.2510, 1.2530, 1.2867, 1.2352, 1.2095, 1.2867, 1.2397,
         1.6013, 1.5858, 1.6096, 1.5928, 1.5988, 1.6004, 1.6072, 1.6004, 1.6004,
         1.3291, 1.3404, 1.3275, 1.3478, 1.3290, 1.3585, 1.3517, 1.3394, 1.3275,
         1.5926, 1.6082, 1.5976, 1.5940, 1.6007, 1.5906, 1.6087, 1.5627, 1.5675,
         1.2378, 1.2626, 1.2552, 1.2713, 1.2332, 1.2257, 1.2118, 1.2918, 1.2523],
        [1.3891, 1.2393, 1.2293, 1.2716, 1.2720, 1.2842, 1.2781, 1.1838, 1.1838,
         3.6217, 3.6898, 3.5633, 3.8669, 3.6227, 4.1026, 3.5123, 3.5855, 3.9428,
         1.5837, 1.5716, 1.5464, 1.5444, 1.5649, 1.5742, 1.5989, 1.5743, 1.5743,
         1.3547, 1.3220, 1.3147, 1.3728, 1.3151, 1.4101, 1.3903, 1.3590, 1.3116,
         1.5482, 1.6034, 1.5674, 1.5544, 1.5497, 1.5866, 1.6060, 1.4423, 1.5393,
         1.1515, 1.2633, 1.2363, 1.2851, 1.1455, 1.1510, 1.0764, 1.3466, 1.2266],
        [1.4463, 1.4463, 1.4446, 1.4418, 1.4421, 1.4463, 1.4420, 1.4463, 1.4463,
         1.4426, 1.4419, 1.4426, 1.4425, 1.4426, 1.4237, 1.4426, 1.4414, 1.4391,
         2.2077, 2.2081, 2.2250, 2.2003, 2.1815, 2.1798, 2.2090, 2.1788, 2.1788,
         1.5022, 1.5006, 1.5080, 1.5080, 1.5022, 1.5081, 1.5080, 1.5080, 1.5080,
         1.7732, 1.7733, 1.7733, 1.7701, 1.7732, 1.7732, 1.7733, 1.7504, 1.7531,
         1.4337, 1.4384, 1.4384, 1.4384, 1.4301, 1.4384, 1.4343, 1.4384, 1.4384],
        [1.3125, 1.3109, 1.2949, 1.2861, 1.3098, 1.3082, 1.3093, 1.3100, 1.3100,
         1.3076, 1.3010, 1.2972, 1.2966, 1.3082, 1.2929, 1.3044, 1.3078, 1.2804,
         1.6490, 1.6225, 1.6459, 1.6454, 1.6448, 1.6449, 1.6471, 1.6486, 1.6486,
         3.4871, 3.2781, 3.2039, 3.2624, 3.4130, 3.2308, 3.4615, 3.2122, 3.1905,
         1.6458, 1.6383, 1.6365, 1.6397, 1.6427, 1.6187, 1.6440, 1.5834, 1.6099,
         1.3016, 1.2960, 1.2862, 1.3008, 1.2966, 1.2888, 1.3009, 1.3010, 1.3031],
        [1.4492, 1.4448, 1.4010, 1.4046, 1.4425, 1.4491, 1.4476, 1.4492, 1.4492,
         1.4443, 1.4416, 1.4367, 1.4315, 1.4454, 1.4043, 1.4395, 1.4454, 1.4403,
         1.7629, 1.7541, 1.7525, 1.7608, 1.7786, 1.7772, 1.7572, 1.7788, 1.7788,
         1.4688, 1.4738, 1.5108, 1.5055, 1.4742, 1.5094, 1.4977, 1.5108, 1.5077,
         2.1999, 2.1791, 2.1677, 2.1859, 2.2304, 2.2473, 2.2135, 2.3191, 2.3154,
         1.4256, 1.4166, 1.4309, 1.4412, 1.4282, 1.4380, 1.4080, 1.4352, 1.4413],
        [1.3287, 1.2328, 1.2286, 1.2479, 1.2411, 1.2514, 1.2502, 1.1873, 1.1873,
         1.2533, 1.2147, 1.2138, 1.2172, 1.2920, 1.1719, 1.1371, 1.2920, 1.1988,
         1.5966, 1.5727, 1.5545, 1.5493, 1.5725, 1.5688, 1.5891, 1.5740, 1.5740,
         1.3266, 1.2994, 1.2990, 1.3167, 1.3012, 1.3450, 1.3470, 1.3205, 1.2990,
         1.5674, 1.5675, 1.5726, 1.5621, 1.5385, 1.5424, 1.6039, 1.4921, 1.4611,
         4.0476, 3.6708, 3.7496, 3.7364, 3.7451, 3.4559, 4.0390, 3.7146, 3.4855]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 175 : 1779.8201563760697
Test loss for epoch 175 : 195.60932912909203
Test Precision for epoch 175 : 0.26153846153846155
Test Recall for epoch 175 : 0.26153846153846155
Test F1 for epoch 175 : 0.26153846153846155


theta for epoch 176 : tensor([[3.6319, 3.6552, 3.7967, 3.7430, 3.7319, 3.6136, 3.6545, 3.5543, 3.5543,
         1.2668, 1.2492, 1.2482, 1.2502, 1.2837, 1.2325, 1.2071, 1.2837, 1.2369,
         1.5996, 1.5841, 1.6079, 1.5911, 1.5971, 1.5988, 1.6055, 1.5987, 1.5987,
         1.3307, 1.3420, 1.3292, 1.3494, 1.3306, 1.3600, 1.3533, 1.3410, 1.3292,
         1.5950, 1.6105, 1.6000, 1.5964, 1.6031, 1.5930, 1.6110, 1.5650, 1.5698,
         1.2360, 1.2612, 1.2536, 1.2701, 1.2312, 1.2235, 1.2095, 1.2910, 1.2506],
        [1.3838, 1.2357, 1.2256, 1.2678, 1.2682, 1.2804, 1.2743, 1.1813, 1.1813,
         3.6259, 3.6943, 3.5674, 3.8720, 3.6269, 4.1088, 3.5162, 3.5896, 3.9483,
         1.5793, 1.5672, 1.5420, 1.5402, 1.5608, 1.5701, 1.5946, 1.5702, 1.5702,
         1.3516, 1.3188, 1.3121, 1.3695, 1.3121, 1.4065, 1.3869, 1.3559, 1.3089,
         1.5477, 1.6028, 1.5669, 1.5539, 1.5491, 1.5860, 1.6053, 1.4414, 1.5387,
         1.1462, 1.2584, 1.2313, 1.2803, 1.1401, 1.1455, 1.0701, 1.3422, 1.2215],
        [1.4484, 1.4483, 1.4466, 1.4438, 1.4442, 1.4483, 1.4440, 1.4483, 1.4483,
         1.4397, 1.4390, 1.4397, 1.4397, 1.4397, 1.4209, 1.4397, 1.4385, 1.4363,
         2.2065, 2.2070, 2.2238, 2.1992, 2.1804, 2.1787, 2.2079, 2.1777, 2.1777,
         1.5044, 1.5028, 1.5103, 1.5103, 1.5045, 1.5103, 1.5103, 1.5103, 1.5103,
         1.7759, 1.7760, 1.7760, 1.7727, 1.7758, 1.7758, 1.7759, 1.7531, 1.7558,
         1.4334, 1.4381, 1.4381, 1.4381, 1.4298, 1.4381, 1.4340, 1.4381, 1.4381],
        [1.3144, 1.3129, 1.2969, 1.2881, 1.3118, 1.3101, 1.3113, 1.3120, 1.3120,
         1.3046, 1.2981, 1.2943, 1.2937, 1.3053, 1.2900, 1.3015, 1.3049, 1.2775,
         1.6477, 1.6212, 1.6446, 1.6441, 1.6435, 1.6435, 1.6457, 1.6472, 1.6472,
         3.4899, 3.2809, 3.2067, 3.2651, 3.4157, 3.2336, 3.4643, 3.2149, 3.1933,
         1.6484, 1.6409, 1.6391, 1.6423, 1.6453, 1.6213, 1.6466, 1.5860, 1.6125,
         1.3011, 1.2956, 1.2858, 1.3004, 1.2962, 1.2884, 1.3005, 1.3006, 1.3027],
        [1.4512, 1.4469, 1.4031, 1.4066, 1.4445, 1.4511, 1.4496, 1.4512, 1.4512,
         1.4414, 1.4388, 1.4338, 1.4287, 1.4426, 1.4015, 1.4366, 1.4425, 1.4375,
         1.7616, 1.7529, 1.7513, 1.7596, 1.7774, 1.7759, 1.7560, 1.7775, 1.7775,
         1.4711, 1.4761, 1.5130, 1.5078, 1.4765, 1.5116, 1.4999, 1.5131, 1.5100,
         2.2024, 2.1817, 2.1703, 2.1885, 2.2329, 2.2498, 2.2161, 2.3216, 2.3178,
         1.4253, 1.4163, 1.4306, 1.4409, 1.4279, 1.4377, 1.4078, 1.4349, 1.4410],
        [1.3275, 1.2280, 1.2241, 1.2437, 1.2369, 1.2473, 1.2460, 1.1804, 1.1804,
         1.2479, 1.2089, 1.2080, 1.2115, 1.2874, 1.1662, 1.1306, 1.2874, 1.1929,
         1.5915, 1.5675, 1.5494, 1.5437, 1.5670, 1.5633, 1.5840, 1.5686, 1.5686,
         1.3240, 1.2965, 1.2951, 1.3142, 1.2980, 1.3433, 1.3449, 1.3177, 1.2952,
         1.5664, 1.5668, 1.5716, 1.5611, 1.5375, 1.5415, 1.6034, 1.4909, 1.4598,
         4.0585, 3.6801, 3.7592, 3.7459, 3.7548, 3.4649, 4.0500, 3.7239, 3.4945]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 176 : 1779.4142232221432
Test loss for epoch 176 : 195.95377754381138
Test Precision for epoch 176 : 0.26153846153846155
Test Recall for epoch 176 : 0.26153846153846155
Test F1 for epoch 176 : 0.26153846153846155


theta for epoch 177 : tensor([[3.6326, 3.6559, 3.7975, 3.7438, 3.7326, 3.6143, 3.6552, 3.5550, 3.5550,
         1.2634, 1.2460, 1.2449, 1.2469, 1.2804, 1.2294, 1.2041, 1.2804, 1.2337,
         1.5962, 1.5807, 1.6045, 1.5877, 1.5937, 1.5953, 1.6021, 1.5953, 1.5953,
         1.3428, 1.3541, 1.3413, 1.3615, 1.3427, 1.3721, 1.3654, 1.3532, 1.3413,
         1.5971, 1.6126, 1.6021, 1.5985, 1.6052, 1.5951, 1.6131, 1.5672, 1.5720,
         1.2338, 1.2590, 1.2514, 1.2679, 1.2291, 1.2213, 1.2073, 1.2887, 1.2484],
        [1.3784, 1.2324, 1.2219, 1.2642, 1.2645, 1.2768, 1.2707, 1.1792, 1.1792,
         3.6312, 3.6998, 3.5725, 3.8783, 3.6321, 4.1161, 3.5212, 3.5947, 3.9549,
         1.5718, 1.5598, 1.5343, 1.5330, 1.5536, 1.5630, 1.5871, 1.5630, 1.5630,
         1.3525, 1.3197, 1.3137, 1.3705, 1.3132, 1.4071, 1.3877, 1.3571, 1.3106,
         1.5454, 1.6004, 1.5647, 1.5517, 1.5467, 1.5837, 1.6028, 1.4388, 1.5364,
         1.1395, 1.2511, 1.2242, 1.2728, 1.1336, 1.1393, 1.0632, 1.3340, 1.2145],
        [1.4534, 1.4533, 1.4517, 1.4489, 1.4493, 1.4534, 1.4491, 1.4534, 1.4534,
         1.4356, 1.4349, 1.4356, 1.4355, 1.4356, 1.4167, 1.4356, 1.4344, 1.4321,
         2.2028, 2.2033, 2.2201, 2.1957, 2.1769, 2.1751, 2.2044, 2.1742, 2.1742,
         1.5154, 1.5138, 1.5212, 1.5212, 1.5154, 1.5212, 1.5212, 1.5212, 1.5212,
         1.7775, 1.7776, 1.7776, 1.7744, 1.7775, 1.7775, 1.7776, 1.7547, 1.7574,
         1.4311, 1.4358, 1.4358, 1.4358, 1.4275, 1.4358, 1.4317, 1.4358, 1.4358],
        [1.3195, 1.3180, 1.3020, 1.2932, 1.3169, 1.3152, 1.3164, 1.3171, 1.3171,
         1.3005, 1.2939, 1.2901, 1.2895, 1.3011, 1.2858, 1.2974, 1.3007, 1.2733,
         1.6437, 1.6172, 1.6406, 1.6401, 1.6395, 1.6395, 1.6417, 1.6432, 1.6432,
         3.4998, 3.2908, 3.2167, 3.2751, 3.4256, 3.2435, 3.4742, 3.2249, 3.2034,
         1.6499, 1.6424, 1.6407, 1.6439, 1.6469, 1.6229, 1.6482, 1.5876, 1.6141,
         1.2987, 1.2932, 1.2834, 1.2980, 1.2938, 1.2860, 1.2980, 1.2981, 1.3003],
        [1.4563, 1.4519, 1.4083, 1.4118, 1.4496, 1.4562, 1.4547, 1.4562, 1.4562,
         1.4373, 1.4346, 1.4297, 1.4246, 1.4384, 1.3974, 1.4325, 1.4384, 1.4333,
         1.7577, 1.7490, 1.7474, 1.7557, 1.7735, 1.7720, 1.7521, 1.7736, 1.7736,
         1.4821, 1.4872, 1.5240, 1.5188, 1.4875, 1.5226, 1.5109, 1.5240, 1.5209,
         2.2040, 2.1833, 2.1719, 2.1901, 2.2345, 2.2514, 2.2177, 2.3230, 2.3193,
         1.4231, 1.4140, 1.4283, 1.4386, 1.4256, 1.4354, 1.4055, 1.4326, 1.4386],
        [1.3562, 1.2544, 1.2508, 1.2705, 1.2638, 1.2741, 1.2729, 1.2054, 1.2054,
         1.2543, 1.2150, 1.2140, 1.2176, 1.2944, 1.1724, 1.1356, 1.2944, 1.1988,
         1.5999, 1.5759, 1.5581, 1.5520, 1.5751, 1.5714, 1.5924, 1.5766, 1.5766,
         1.3528, 1.3254, 1.3230, 1.3433, 1.3266, 1.3728, 1.3740, 1.3464, 1.3231,
         1.5777, 1.5784, 1.5829, 1.5725, 1.5491, 1.5532, 1.6149, 1.5027, 1.4719,
         4.0319, 3.6520, 3.7313, 3.7179, 3.7269, 3.4362, 4.0234, 3.6960, 3.4659]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 177 : 1779.7409936588242
Test loss for epoch 177 : 194.79776489878222
Test Precision for epoch 177 : 0.26153846153846155
Test Recall for epoch 177 : 0.26153846153846155
Test F1 for epoch 177 : 0.26153846153846155


theta for epoch 178 : tensor([[3.6298, 3.6531, 3.7948, 3.7411, 3.7298, 3.6116, 3.6524, 3.5522, 3.5522,
         1.2615, 1.2441, 1.2430, 1.2450, 1.2787, 1.2275, 1.2022, 1.2787, 1.2318,
         1.5956, 1.5801, 1.6039, 1.5871, 1.5931, 1.5947, 1.6015, 1.5947, 1.5947,
         1.3419, 1.3532, 1.3404, 1.3606, 1.3418, 1.3712, 1.3645, 1.3522, 1.3404,
         1.5975, 1.6131, 1.6025, 1.5989, 1.6056, 1.5955, 1.6135, 1.5676, 1.5724,
         1.2403, 1.2656, 1.2580, 1.2745, 1.2355, 1.2277, 1.2137, 1.2954, 1.2549],
        [1.3629, 1.2190, 1.2082, 1.2504, 1.2507, 1.2630, 1.2569, 1.1670, 1.1670,
         3.6424, 3.7112, 3.5835, 3.8904, 3.6432, 4.1293, 3.5321, 3.6057, 3.9674,
         1.5633, 1.5514, 1.5256, 1.5247, 1.5455, 1.5549, 1.5788, 1.5549, 1.5549,
         1.3412, 1.3084, 1.3031, 1.3591, 1.3022, 1.3954, 1.3762, 1.3459, 1.3000,
         1.5388, 1.5937, 1.5582, 1.5451, 1.5400, 1.5770, 1.5960, 1.4316, 1.5296,
         1.1357, 1.2471, 1.2204, 1.2688, 1.1299, 1.1359, 1.0589, 1.3296, 1.2108],
        [1.4498, 1.4497, 1.4481, 1.4453, 1.4457, 1.4498, 1.4455, 1.4498, 1.4498,
         1.4332, 1.4325, 1.4331, 1.4331, 1.4332, 1.4143, 1.4332, 1.4320, 1.4297,
         2.2021, 2.2025, 2.2194, 2.1949, 2.1761, 2.1744, 2.2037, 2.1734, 2.1734,
         1.5140, 1.5124, 1.5199, 1.5199, 1.5140, 1.5199, 1.5198, 1.5199, 1.5199,
         1.7777, 1.7778, 1.7778, 1.7746, 1.7777, 1.7777, 1.7778, 1.7549, 1.7576,
         1.4379, 1.4425, 1.4425, 1.4425, 1.4342, 1.4425, 1.4385, 1.4425, 1.4425],
        [1.3158, 1.3143, 1.2983, 1.2895, 1.3132, 1.3115, 1.3127, 1.3134, 1.3134,
         1.2980, 1.2915, 1.2877, 1.2871, 1.2987, 1.2834, 1.2949, 1.2983, 1.2709,
         1.6428, 1.6163, 1.6397, 1.6392, 1.6386, 1.6386, 1.6408, 1.6423, 1.6423,
         3.4993, 3.2903, 3.2161, 3.2744, 3.4251, 3.2429, 3.4736, 3.2243, 3.2027,
         1.6501, 1.6426, 1.6409, 1.6441, 1.6470, 1.6230, 1.6483, 1.5877, 1.6142,
         1.3055, 1.2999, 1.2901, 1.3047, 1.3005, 1.2927, 1.3048, 1.3049, 1.3070],
        [1.4527, 1.4484, 1.4047, 1.4082, 1.4460, 1.4525, 1.4511, 1.4526, 1.4526,
         1.4349, 1.4322, 1.4273, 1.4222, 1.4360, 1.3950, 1.4301, 1.4360, 1.4309,
         1.7569, 1.7481, 1.7466, 1.7549, 1.7726, 1.7712, 1.7513, 1.7728, 1.7728,
         1.4807, 1.4858, 1.5226, 1.5174, 1.4862, 1.5212, 1.5095, 1.5227, 1.5195,
         2.2042, 2.1835, 2.1721, 2.1903, 2.2346, 2.2516, 2.2180, 2.3231, 2.3194,
         1.4299, 1.4207, 1.4350, 1.4453, 1.4324, 1.4421, 1.4124, 1.4393, 1.4454],
        [1.3727, 1.2687, 1.2655, 1.2853, 1.2786, 1.2889, 1.2876, 1.2183, 1.2183,
         1.2602, 1.2203, 1.2193, 1.2231, 1.3010, 1.1778, 1.1395, 1.3011, 1.2039,
         1.6085, 1.5846, 1.5670, 1.5604, 1.5834, 1.5798, 1.6010, 1.5849, 1.5849,
         1.3668, 1.3394, 1.3362, 1.3576, 1.3403, 1.3875, 1.3884, 1.3604, 1.3362,
         1.5854, 1.5865, 1.5905, 1.5802, 1.5570, 1.5613, 1.6228, 1.5107, 1.4803,
         4.0153, 3.6339, 3.7134, 3.7001, 3.7090, 3.4176, 4.0068, 3.6782, 3.4475]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 178 : 1779.43260292564
Test loss for epoch 178 : 194.8060357274956
Test Precision for epoch 178 : 0.26153846153846155
Test Recall for epoch 178 : 0.26153846153846155
Test F1 for epoch 178 : 0.26153846153846155


theta for epoch 179 : tensor([[3.6276, 3.6508, 3.7927, 3.7389, 3.7275, 3.6093, 3.6502, 3.5498, 3.5498,
         1.2595, 1.2418, 1.2407, 1.2427, 1.2769, 1.2252, 1.1994, 1.2769, 1.2294,
         1.5979, 1.5824, 1.6062, 1.5893, 1.5953, 1.5969, 1.6038, 1.5969, 1.5969,
         1.3294, 1.3407, 1.3278, 1.3481, 1.3293, 1.3588, 1.3520, 1.3397, 1.3278,
         1.5957, 1.6113, 1.6007, 1.5971, 1.6038, 1.5938, 1.6118, 1.5658, 1.5706,
         1.2537, 1.2791, 1.2715, 1.2881, 1.2488, 1.2409, 1.2271, 1.3091, 1.2684],
        [1.3425, 1.2000, 1.1890, 1.2312, 1.2315, 1.2438, 1.2377, 1.1489, 1.1489,
         3.6580, 3.7271, 3.5989, 3.9069, 3.6588, 4.1469, 3.5474, 3.6211, 3.9843,
         1.5545, 1.5426, 1.5166, 1.5160, 1.5369, 1.5463, 1.5701, 1.5464, 1.5464,
         1.3196, 1.2868, 1.2820, 1.3374, 1.2807, 1.3734, 1.3543, 1.3244, 1.2789,
         1.5278, 1.5829, 1.5474, 1.5342, 1.5290, 1.5661, 1.5851, 1.4200, 1.5186,
         1.1342, 1.2461, 1.2193, 1.2677, 1.1286, 1.1348, 1.0567, 1.3286, 1.2097],
        [1.4440, 1.4439, 1.4423, 1.4395, 1.4398, 1.4440, 1.4396, 1.4439, 1.4439,
         1.4309, 1.4302, 1.4309, 1.4309, 1.4309, 1.4121, 1.4309, 1.4297, 1.4275,
         2.2042, 2.2046, 2.2215, 2.1970, 2.1782, 2.1765, 2.2057, 2.1755, 2.1755,
         1.5019, 1.5003, 1.5077, 1.5077, 1.5019, 1.5077, 1.5077, 1.5077, 1.5077,
         1.7761, 1.7761, 1.7761, 1.7729, 1.7760, 1.7760, 1.7761, 1.7533, 1.7560,
         1.4518, 1.4564, 1.4564, 1.4564, 1.4481, 1.4564, 1.4524, 1.4564, 1.4564],
        [1.3099, 1.3084, 1.2924, 1.2836, 1.3073, 1.3056, 1.3068, 1.3075, 1.3075,
         1.2958, 1.2892, 1.2854, 1.2849, 1.2965, 1.2811, 1.2927, 1.2960, 1.2686,
         1.6451, 1.6186, 1.6420, 1.6415, 1.6409, 1.6409, 1.6431, 1.6446, 1.6446,
         3.4896, 3.2804, 3.2061, 3.2646, 3.4154, 3.2330, 3.4640, 3.2144, 3.1927,
         1.6485, 1.6410, 1.6393, 1.6424, 1.6454, 1.6214, 1.6467, 1.5861, 1.6126,
         1.3194, 1.3139, 1.3041, 1.3187, 1.3145, 1.3067, 1.3187, 1.3188, 1.3209],
        [1.4468, 1.4425, 1.3989, 1.4023, 1.4401, 1.4467, 1.4453, 1.4468, 1.4468,
         1.4327, 1.4300, 1.4250, 1.4199, 1.4338, 1.3928, 1.4278, 1.4338, 1.4287,
         1.7592, 1.7504, 1.7489, 1.7572, 1.7749, 1.7735, 1.7536, 1.7751, 1.7751,
         1.4686, 1.4736, 1.5105, 1.5053, 1.4740, 1.5091, 1.4974, 1.5105, 1.5074,
         2.2026, 2.1820, 2.1706, 2.1887, 2.2331, 2.2500, 2.2164, 2.3215, 2.3178,
         1.4438, 1.4347, 1.4490, 1.4592, 1.4463, 1.4560, 1.4264, 1.4532, 1.4593],
        [1.3816, 1.2761, 1.2732, 1.2930, 1.2864, 1.2965, 1.2953, 1.2248, 1.2248,
         1.2640, 1.2233, 1.2223, 1.2263, 1.3056, 1.1807, 1.1407, 1.3056, 1.2067,
         1.6175, 1.5935, 1.5760, 1.5692, 1.5921, 1.5885, 1.6100, 1.5936, 1.5936,
         1.3671, 1.3398, 1.3358, 1.3581, 1.3405, 1.3883, 1.3889, 1.3606, 1.3359,
         1.5891, 1.5904, 1.5943, 1.5839, 1.5609, 1.5653, 1.6267, 1.5148, 1.4845,
         4.0078, 3.6251, 3.7048, 3.6914, 3.7004, 3.4083, 3.9994, 3.6695, 3.4383]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 179 : 1778.8765908856337
Test loss for epoch 179 : 195.75402153824103
Test Precision for epoch 179 : 0.26153846153846155
Test Recall for epoch 179 : 0.26153846153846155
Test F1 for epoch 179 : 0.26153846153846155


theta for epoch 180 : tensor([[3.6240, 3.6472, 3.7891, 3.7354, 3.7239, 3.6056, 3.6466, 3.5461, 3.5461,
         1.2549, 1.2374, 1.2363, 1.2383, 1.2724, 1.2207, 1.1952, 1.2724, 1.2250,
         1.6006, 1.5851, 1.6090, 1.5920, 1.5980, 1.5996, 1.6065, 1.5996, 1.5996,
         1.3288, 1.3401, 1.3271, 1.3475, 1.3286, 1.3581, 1.3514, 1.3391, 1.3271,
         1.5940, 1.6096, 1.5990, 1.5954, 1.6021, 1.5921, 1.6101, 1.5641, 1.5690,
         1.2640, 1.2895, 1.2818, 1.2984, 1.2591, 1.2512, 1.2375, 1.3195, 1.2787],
        [1.3562, 1.2151, 1.2040, 1.2460, 1.2464, 1.2586, 1.2525, 1.1647, 1.1647,
         3.6410, 3.7103, 3.5817, 3.8908, 3.6418, 4.1319, 3.5300, 3.6040, 3.9685,
         1.5658, 1.5541, 1.5281, 1.5277, 1.5485, 1.5579, 1.5814, 1.5579, 1.5579,
         1.3305, 1.2979, 1.2935, 1.3482, 1.2920, 1.3838, 1.3649, 1.3353, 1.2903,
         1.5349, 1.5896, 1.5544, 1.5413, 1.5360, 1.5729, 1.5918, 1.4277, 1.5257,
         1.1523, 1.2637, 1.2370, 1.2852, 1.1468, 1.1531, 1.0750, 1.3456, 1.2276],
        [1.4454, 1.4453, 1.4436, 1.4408, 1.4412, 1.4453, 1.4410, 1.4453, 1.4453,
         1.4254, 1.4247, 1.4254, 1.4254, 1.4254, 1.4066, 1.4254, 1.4242, 1.4220,
         2.2059, 2.2063, 2.2231, 2.1986, 2.1798, 2.1781, 2.2073, 2.1771, 2.1771,
         1.4997, 1.4981, 1.5056, 1.5056, 1.4997, 1.5056, 1.5055, 1.5056, 1.5056,
         1.7737, 1.7737, 1.7737, 1.7705, 1.7736, 1.7736, 1.7737, 1.7509, 1.7536,
         1.4612, 1.4658, 1.4659, 1.4658, 1.4576, 1.4659, 1.4619, 1.4658, 1.4659],
        [1.3115, 1.3099, 1.2939, 1.2851, 1.3088, 1.3071, 1.3083, 1.3090, 1.3090,
         1.2903, 1.2837, 1.2799, 1.2794, 1.2910, 1.2756, 1.2872, 1.2906, 1.2631,
         1.6468, 1.6203, 1.6437, 1.6433, 1.6427, 1.6427, 1.6449, 1.6464, 1.6464,
         3.4881, 3.2788, 3.2045, 3.2630, 3.4138, 3.2314, 3.4625, 3.2127, 3.1911,
         1.6461, 1.6386, 1.6368, 1.6400, 1.6430, 1.6190, 1.6443, 1.5837, 1.6102,
         1.3289, 1.3234, 1.3136, 1.3282, 1.3240, 1.3162, 1.3282, 1.3283, 1.3304],
        [1.4482, 1.4439, 1.4003, 1.4038, 1.4415, 1.4481, 1.4466, 1.4482, 1.4482,
         1.4272, 1.4245, 1.4195, 1.4145, 1.4283, 1.3873, 1.4223, 1.4283, 1.4232,
         1.7609, 1.7522, 1.7506, 1.7589, 1.7767, 1.7752, 1.7553, 1.7768, 1.7768,
         1.4664, 1.4715, 1.5083, 1.5032, 1.4718, 1.5070, 1.4952, 1.5084, 1.5053,
         2.2003, 2.1796, 2.1683, 2.1864, 2.2307, 2.2477, 2.2141, 2.3191, 2.3154,
         1.4533, 1.4441, 1.4584, 1.4686, 1.4558, 1.4654, 1.4359, 1.4626, 1.4687],
        [1.3939, 1.2882, 1.2853, 1.3051, 1.2985, 1.3086, 1.3074, 1.2366, 1.2366,
         1.2642, 1.2234, 1.2223, 1.2265, 1.3061, 1.1808, 1.1404, 1.3061, 1.2068,
         1.6253, 1.6015, 1.5840, 1.5771, 1.6000, 1.5963, 1.6179, 1.6015, 1.6015,
         1.3748, 1.3476, 1.3434, 1.3659, 1.3482, 1.3961, 1.3966, 1.3683, 1.3434,
         1.5918, 1.5933, 1.5970, 1.5867, 1.5638, 1.5682, 1.6294, 1.5178, 1.4877,
         3.9993, 3.6152, 3.6951, 3.6817, 3.6908, 3.3980, 3.9910, 3.6598, 3.4280]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 180 : 1779.948316214217
Test loss for epoch 180 : 194.91615111031422
Test Precision for epoch 180 : 0.26153846153846155
Test Recall for epoch 180 : 0.26153846153846155
Test F1 for epoch 180 : 0.26153846153846155


theta for epoch 181 : tensor([[3.6238, 3.6469, 3.7890, 3.7353, 3.7237, 3.6054, 3.6464, 3.5459, 3.5459,
         1.2552, 1.2375, 1.2364, 1.2384, 1.2729, 1.2207, 1.1949, 1.2729, 1.2251,
         1.5996, 1.5841, 1.6080, 1.5910, 1.5969, 1.5985, 1.6055, 1.5985, 1.5985,
         1.3373, 1.3486, 1.3355, 1.3560, 1.3371, 1.3667, 1.3599, 1.3475, 1.3355,
         1.5935, 1.6091, 1.5985, 1.5949, 1.6016, 1.5916, 1.6096, 1.5636, 1.5684,
         1.2604, 1.2859, 1.2783, 1.2949, 1.2555, 1.2475, 1.2340, 1.3160, 1.2751],
        [1.3653, 1.2245, 1.2134, 1.2554, 1.2557, 1.2680, 1.2619, 1.1743, 1.1743,
         3.6324, 3.7020, 3.5730, 3.8832, 3.6332, 4.1254, 3.5212, 3.5953, 3.9613,
         1.5703, 1.5585, 1.5326, 1.5323, 1.5530, 1.5624, 1.5858, 1.5624, 1.5624,
         1.3421, 1.3096, 1.3052, 1.3598, 1.3037, 1.3953, 1.3765, 1.3469, 1.3021,
         1.5393, 1.5937, 1.5587, 1.5456, 1.5404, 1.5771, 1.5959, 1.4324, 1.5301,
         1.1559, 1.2667, 1.2403, 1.2881, 1.1504, 1.1567, 1.0787, 1.3482, 1.2308],
        [1.4484, 1.4483, 1.4467, 1.4439, 1.4443, 1.4484, 1.4441, 1.4484, 1.4484,
         1.4253, 1.4246, 1.4253, 1.4252, 1.4253, 1.4065, 1.4253, 1.4241, 1.4219,
         2.2045, 2.2049, 2.2218, 2.1973, 2.1785, 2.1768, 2.2061, 2.1759, 2.1759,
         1.5074, 1.5058, 1.5132, 1.5132, 1.5074, 1.5132, 1.5132, 1.5132, 1.5132,
         1.7728, 1.7729, 1.7729, 1.7697, 1.7728, 1.7728, 1.7729, 1.7501, 1.7528,
         1.4572, 1.4618, 1.4618, 1.4618, 1.4535, 1.4618, 1.4578, 1.4618, 1.4618],
        [1.3147, 1.3131, 1.2971, 1.2883, 1.3120, 1.3103, 1.3115, 1.3122, 1.3122,
         1.2902, 1.2836, 1.2798, 1.2792, 1.2909, 1.2755, 1.2871, 1.2904, 1.2630,
         1.6454, 1.6189, 1.6423, 1.6418, 1.6412, 1.6413, 1.6435, 1.6450, 1.6450,
         3.4947, 3.2854, 3.2112, 3.2696, 3.4204, 3.2380, 3.4691, 3.2193, 3.1978,
         1.6452, 1.6377, 1.6360, 1.6392, 1.6421, 1.6181, 1.6435, 1.5828, 1.6093,
         1.3249, 1.3193, 1.3095, 1.3241, 1.3199, 1.3121, 1.3242, 1.3243, 1.3264],
        [1.4512, 1.4470, 1.4034, 1.4068, 1.4446, 1.4511, 1.4497, 1.4512, 1.4512,
         1.4271, 1.4244, 1.4194, 1.4143, 1.4282, 1.3872, 1.4222, 1.4281, 1.4231,
         1.7595, 1.7507, 1.7492, 1.7575, 1.7752, 1.7738, 1.7539, 1.7754, 1.7754,
         1.4741, 1.4792, 1.5160, 1.5108, 1.4795, 1.5146, 1.5029, 1.5160, 1.5129,
         2.1995, 2.1789, 2.1675, 2.1856, 2.2299, 2.2469, 2.2133, 2.3183, 2.3146,
         1.4493, 1.4401, 1.4544, 1.4646, 1.4517, 1.4614, 1.4318, 1.4586, 1.4647],
        [1.4013, 1.2963, 1.2935, 1.3131, 1.3066, 1.3166, 1.3154, 1.2451, 1.2451,
         1.2671, 1.2260, 1.2250, 1.2292, 1.3094, 1.1834, 1.1424, 1.3094, 1.2094,
         1.6275, 1.6037, 1.5863, 1.5794, 1.6022, 1.5985, 1.6200, 1.6037, 1.6037,
         1.3866, 1.3594, 1.3552, 1.3776, 1.3600, 1.4078, 1.4083, 1.3801, 1.3553,
         1.5941, 1.5954, 1.5992, 1.5889, 1.5660, 1.5704, 1.6315, 1.5202, 1.4901,
         3.9906, 3.6051, 3.6852, 3.6717, 3.6809, 3.3875, 3.9823, 3.6498, 3.4176]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 181 : 1780.2277630461563
Test loss for epoch 181 : 194.39920259024234
Test Precision for epoch 181 : 0.26153846153846155
Test Recall for epoch 181 : 0.26153846153846155
Test F1 for epoch 181 : 0.26153846153846155


theta for epoch 182 : tensor([[3.6215, 3.6446, 3.7868, 3.7330, 3.7214, 3.6031, 3.6441, 3.5435, 3.5435,
         1.2615, 1.2434, 1.2422, 1.2444, 1.2796, 1.2265, 1.1997, 1.2796, 1.2308,
         1.5968, 1.5813, 1.6052, 1.5881, 1.5940, 1.5957, 1.6027, 1.5956, 1.5956,
         1.3400, 1.3513, 1.3380, 1.3588, 1.3397, 1.3696, 1.3628, 1.3503, 1.3380,
         1.5947, 1.6105, 1.5997, 1.5961, 1.6029, 1.5929, 1.6110, 1.5649, 1.5697,
         1.2532, 1.2789, 1.2712, 1.2879, 1.2483, 1.2403, 1.2270, 1.3091, 1.2681],
        [1.3650, 1.2239, 1.2129, 1.2548, 1.2551, 1.2673, 1.2612, 1.1735, 1.1735,
         3.6323, 3.7021, 3.5727, 3.8840, 3.6331, 4.1272, 3.5208, 3.5951, 3.9624,
         1.5695, 1.5578, 1.5319, 1.5314, 1.5521, 1.5615, 1.5850, 1.5615, 1.5615,
         1.3455, 1.3129, 1.3085, 1.3632, 1.3070, 1.3987, 1.3799, 1.3503, 1.3053,
         1.5416, 1.5961, 1.5610, 1.5479, 1.5427, 1.5795, 1.5983, 1.4348, 1.5324,
         1.1529, 1.2635, 1.2371, 1.2848, 1.1474, 1.1537, 1.0758, 1.3446, 1.2277],
        [1.4448, 1.4447, 1.4431, 1.4403, 1.4406, 1.4448, 1.4405, 1.4448, 1.4448,
         1.4316, 1.4309, 1.4316, 1.4316, 1.4316, 1.4128, 1.4316, 1.4304, 1.4282,
         2.2020, 2.2024, 2.2192, 2.1948, 2.1761, 2.1743, 2.2036, 2.1734, 2.1734,
         1.5100, 1.5084, 1.5159, 1.5159, 1.5100, 1.5159, 1.5158, 1.5159, 1.5159,
         1.7741, 1.7742, 1.7742, 1.7710, 1.7741, 1.7741, 1.7742, 1.7514, 1.7541,
         1.4500, 1.4546, 1.4546, 1.4546, 1.4463, 1.4546, 1.4506, 1.4546, 1.4546],
        [1.3112, 1.3096, 1.2936, 1.2848, 1.3085, 1.3068, 1.3080, 1.3086, 1.3086,
         1.2966, 1.2900, 1.2862, 1.2856, 1.2972, 1.2819, 1.2934, 1.2968, 1.2694,
         1.6427, 1.6162, 1.6396, 1.6391, 1.6385, 1.6385, 1.6407, 1.6422, 1.6422,
         3.4968, 3.2875, 3.2132, 3.2716, 3.4225, 3.2400, 3.4712, 3.2213, 3.1998,
         1.6466, 1.6391, 1.6374, 1.6405, 1.6435, 1.6195, 1.6448, 1.5842, 1.6107,
         1.3177, 1.3121, 1.3023, 1.3169, 1.3127, 1.3049, 1.3170, 1.3171, 1.3192],
        [1.4476, 1.4433, 1.3998, 1.4033, 1.4410, 1.4475, 1.4461, 1.4476, 1.4476,
         1.4334, 1.4307, 1.4257, 1.4207, 1.4345, 1.3935, 1.4285, 1.4344, 1.4294,
         1.7568, 1.7480, 1.7465, 1.7548, 1.7725, 1.7711, 1.7512, 1.7727, 1.7727,
         1.4768, 1.4818, 1.5186, 1.5134, 1.4822, 1.5172, 1.5055, 1.5187, 1.5155,
         2.2008, 2.1801, 2.1688, 2.1869, 2.2312, 2.2482, 2.2146, 2.3195, 2.3159,
         1.4420, 1.4328, 1.4471, 1.4574, 1.4445, 1.4542, 1.4246, 1.4514, 1.4574],
        [1.3977, 1.2942, 1.2913, 1.3107, 1.3042, 1.3142, 1.3130, 1.2438, 1.2438,
         1.2741, 1.2326, 1.2315, 1.2359, 1.3167, 1.1897, 1.1479, 1.3167, 1.2158,
         1.6259, 1.6021, 1.5847, 1.5781, 1.6008, 1.5971, 1.6184, 1.6023, 1.6023,
         1.3899, 1.3628, 1.3590, 1.3809, 1.3635, 1.4108, 1.4114, 1.3834, 1.3590,
         1.5965, 1.5977, 1.6016, 1.5913, 1.5684, 1.5727, 1.6337, 1.5226, 1.4926,
         3.9856, 3.5988, 3.6790, 3.6655, 3.6748, 3.3808, 3.9773, 3.6436, 3.4109]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 182 : 1780.1901462096034
Test loss for epoch 182 : 194.34215875045095
Test Precision for epoch 182 : 0.26153846153846155
Test Recall for epoch 182 : 0.26153846153846155
Test F1 for epoch 182 : 0.26153846153846155


theta for epoch 183 : tensor([[3.6210, 3.6441, 3.7865, 3.7327, 3.7210, 3.6026, 3.6436, 3.5430, 3.5430,
         1.2688, 1.2500, 1.2488, 1.2512, 1.2875, 1.2328, 1.2046, 1.2875, 1.2372,
         1.5947, 1.5791, 1.6032, 1.5858, 1.5918, 1.5934, 1.6006, 1.5934, 1.5934,
         1.3298, 1.3410, 1.3274, 1.3486, 1.3293, 1.3596, 1.3526, 1.3400, 1.3274,
         1.5957, 1.6115, 1.6007, 1.5971, 1.6039, 1.5939, 1.6121, 1.5658, 1.5706,
         1.2508, 1.2767, 1.2689, 1.2858, 1.2459, 1.2378, 1.2247, 1.3071, 1.2658],
        [1.3600, 1.2176, 1.2067, 1.2487, 1.2490, 1.2613, 1.2552, 1.1666, 1.1666,
         3.6382, 3.7082, 3.5785, 3.8908, 3.6389, 4.1351, 3.5264, 3.6008, 3.9695,
         1.5658, 1.5540, 1.5282, 1.5275, 1.5482, 1.5576, 1.5813, 1.5577, 1.5577,
         1.3366, 1.3040, 1.2993, 1.3543, 1.2980, 1.3900, 1.3711, 1.3413, 1.2962,
         1.5405, 1.5952, 1.5599, 1.5468, 1.5416, 1.5785, 1.5975, 1.4335, 1.5312,
         1.1497, 1.2606, 1.2341, 1.2819, 1.1442, 1.1506, 1.0726, 1.3419, 1.2247],
        [1.4414, 1.4413, 1.4397, 1.4369, 1.4372, 1.4414, 1.4371, 1.4414, 1.4414,
         1.4393, 1.4386, 1.4393, 1.4393, 1.4393, 1.4205, 1.4393, 1.4381, 1.4359,
         2.2004, 2.2008, 2.2177, 2.1933, 2.1745, 2.1728, 2.2021, 2.1719, 2.1719,
         1.5005, 1.4989, 1.5063, 1.5063, 1.5005, 1.5063, 1.5063, 1.5063, 1.5063,
         1.7755, 1.7755, 1.7755, 1.7723, 1.7754, 1.7754, 1.7755, 1.7527, 1.7554,
         1.4477, 1.4523, 1.4523, 1.4523, 1.4440, 1.4523, 1.4483, 1.4523, 1.4523],
        [1.3081, 1.3064, 1.2904, 1.2817, 1.3053, 1.3037, 1.3048, 1.3054, 1.3054,
         1.3043, 1.2977, 1.2939, 1.2934, 1.3051, 1.2896, 1.3011, 1.3046, 1.2771,
         1.6411, 1.6146, 1.6380, 1.6375, 1.6369, 1.6369, 1.6391, 1.6406, 1.6406,
         3.4883, 3.2788, 3.2043, 3.2629, 3.4139, 3.2313, 3.4627, 3.2126, 3.1909,
         1.6480, 1.6405, 1.6388, 1.6419, 1.6449, 1.6209, 1.6462, 1.5856, 1.6121,
         1.3155, 1.3100, 1.3002, 1.3148, 1.3105, 1.3027, 1.3148, 1.3149, 1.3170],
        [1.4443, 1.4399, 1.3963, 1.3999, 1.4376, 1.4442, 1.4427, 1.4442, 1.4442,
         1.4411, 1.4384, 1.4334, 1.4284, 1.4422, 1.4012, 1.4362, 1.4421, 1.4371,
         1.7551, 1.7463, 1.7448, 1.7531, 1.7709, 1.7694, 1.7495, 1.7710, 1.7710,
         1.4672, 1.4722, 1.5091, 1.5039, 1.4726, 1.5077, 1.4960, 1.5091, 1.5060,
         2.2021, 2.1815, 2.1701, 2.1882, 2.2325, 2.2495, 2.2159, 2.3208, 2.3172,
         1.4397, 1.4306, 1.4448, 1.4551, 1.4422, 1.4519, 1.4222, 1.4491, 1.4552],
        [1.3891, 1.2878, 1.2846, 1.3039, 1.2973, 1.3073, 1.3061, 1.2386, 1.2386,
         1.2804, 1.2384, 1.2373, 1.2419, 1.3234, 1.1953, 1.1526, 1.3234, 1.2215,
         1.6229, 1.5993, 1.5818, 1.5755, 1.5982, 1.5945, 1.6155, 1.5997, 1.5997,
         1.3789, 1.3520, 1.3487, 1.3697, 1.3528, 1.3992, 1.4001, 1.3725, 1.3487,
         1.5972, 1.5981, 1.6023, 1.5920, 1.5690, 1.5732, 1.6340, 1.5233, 1.4931,
         3.9875, 3.5995, 3.6799, 3.6664, 3.6757, 3.3811, 3.9793, 3.6444, 3.4113]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 183 : 1780.0518603432404
Test loss for epoch 183 : 194.81198545587435
Test Precision for epoch 183 : 0.26153846153846155
Test Recall for epoch 183 : 0.26153846153846155
Test F1 for epoch 183 : 0.26153846153846155


theta for epoch 184 : tensor([[3.6261, 3.6492, 3.7916, 3.7378, 3.7260, 3.6077, 3.6487, 3.5482, 3.5482,
         1.2672, 1.2475, 1.2462, 1.2490, 1.2866, 1.2300, 1.2001, 1.2866, 1.2344,
         1.5942, 1.5785, 1.6026, 1.5851, 1.5910, 1.5927, 1.6000, 1.5927, 1.5927,
         1.3254, 1.3366, 1.3227, 1.3443, 1.3248, 1.3556, 1.3485, 1.3356, 1.3227,
         1.5939, 1.6099, 1.5990, 1.5954, 1.6022, 1.5923, 1.6105, 1.5641, 1.5689,
         1.2531, 1.2792, 1.2713, 1.2883, 1.2481, 1.2399, 1.2270, 1.3098, 1.2681],
        [1.3545, 1.2098, 1.1991, 1.2413, 1.2416, 1.2538, 1.2478, 1.1576, 1.1576,
         3.6458, 3.7162, 3.5860, 3.8994, 3.6466, 4.1448, 3.5338, 3.6084, 3.9785,
         1.5605, 1.5486, 1.5227, 1.5218, 1.5425, 1.5520, 1.5760, 1.5520, 1.5520,
         1.3279, 1.2951, 1.2901, 1.3457, 1.2890, 1.3818, 1.3627, 1.3326, 1.2869,
         1.5343, 1.5894, 1.5538, 1.5407, 1.5355, 1.5727, 1.5919, 1.4270, 1.5251,
         1.1470, 1.2586, 1.2319, 1.2800, 1.1415, 1.1478, 1.0696, 1.3404, 1.2224],
        [1.4441, 1.4440, 1.4424, 1.4396, 1.4399, 1.4441, 1.4398, 1.4441, 1.4441,
         1.4386, 1.4379, 1.4386, 1.4386, 1.4386, 1.4198, 1.4386, 1.4374, 1.4352,
         2.2006, 2.2010, 2.2179, 2.1935, 2.1747, 2.1730, 2.2023, 2.1720, 2.1720,
         1.4975, 1.4959, 1.5033, 1.5033, 1.4975, 1.5033, 1.5033, 1.5033, 1.5033,
         1.7745, 1.7746, 1.7746, 1.7714, 1.7745, 1.7745, 1.7746, 1.7517, 1.7545,
         1.4504, 1.4550, 1.4550, 1.4550, 1.4467, 1.4550, 1.4510, 1.4550, 1.4550],
        [1.3111, 1.3093, 1.2934, 1.2847, 1.3083, 1.3067, 1.3078, 1.3084, 1.3084,
         1.3037, 1.2970, 1.2932, 1.2927, 1.3044, 1.2889, 1.3003, 1.3040, 1.2764,
         1.6414, 1.6149, 1.6383, 1.6378, 1.6372, 1.6373, 1.6395, 1.6410, 1.6410,
         3.4851, 3.2755, 3.2010, 3.2596, 3.4106, 3.2279, 3.4595, 3.2092, 3.1875,
         1.6471, 1.6396, 1.6379, 1.6411, 1.6440, 1.6200, 1.6453, 1.5847, 1.6112,
         1.3183, 1.3128, 1.3030, 1.3176, 1.3134, 1.3056, 1.3177, 1.3178, 1.3199],
        [1.4470, 1.4426, 1.3989, 1.4026, 1.4403, 1.4469, 1.4453, 1.4469, 1.4469,
         1.4403, 1.4377, 1.4327, 1.4276, 1.4414, 1.4004, 1.4355, 1.4414, 1.4364,
         1.7553, 1.7466, 1.7450, 1.7533, 1.7711, 1.7696, 1.7497, 1.7712, 1.7712,
         1.4642, 1.4691, 1.5061, 1.5008, 1.4695, 1.5047, 1.4930, 1.5061, 1.5030,
         2.2012, 2.1806, 2.1692, 2.1873, 2.2316, 2.2486, 2.2150, 2.3200, 2.3163,
         1.4423, 1.4332, 1.4475, 1.4578, 1.4449, 1.4546, 1.4248, 1.4518, 1.4579],
        [1.3806, 1.2821, 1.2787, 1.2977, 1.2912, 1.3011, 1.3000, 1.2347, 1.2347,
         1.2769, 1.2345, 1.2333, 1.2381, 1.3203, 1.1911, 1.1476, 1.3203, 1.2175,
         1.6197, 1.5962, 1.5785, 1.5727, 1.5954, 1.5918, 1.6124, 1.5969, 1.5969,
         1.3700, 1.3432, 1.3408, 1.3607, 1.3443, 1.3896, 1.3908, 1.3637, 1.3408,
         1.5940, 1.5946, 1.5991, 1.5888, 1.5656, 1.5697, 1.6304, 1.5200, 1.4897,
         3.9960, 3.6068, 3.6874, 3.6738, 3.6832, 3.3882, 3.9879, 3.6518, 3.4184]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 184 : 1779.7378129442861
Test loss for epoch 184 : 195.31833314969955
Test Precision for epoch 184 : 0.26153846153846155
Test Recall for epoch 184 : 0.26153846153846155
Test F1 for epoch 184 : 0.26153846153846155


theta for epoch 185 : tensor([[3.6259, 3.6490, 3.7915, 3.7377, 3.7259, 3.6075, 3.6485, 3.5480, 3.5480,
         1.2580, 1.2378, 1.2366, 1.2394, 1.2778, 1.2202, 1.1893, 1.2778, 1.2246,
         1.5975, 1.5818, 1.6059, 1.5882, 1.5942, 1.5958, 1.6033, 1.5958, 1.5958,
         1.3360, 1.3472, 1.3330, 1.3549, 1.3353, 1.3664, 1.3592, 1.3461, 1.3330,
         1.5929, 1.6090, 1.5979, 1.5943, 1.6012, 1.5913, 1.6096, 1.5631, 1.5679,
         1.2573, 1.2836, 1.2757, 1.2928, 1.2523, 1.2442, 1.2315, 1.3144, 1.2725],
        [1.3762, 1.2298, 1.2193, 1.2615, 1.2619, 1.2741, 1.2680, 1.1765, 1.1765,
         3.6231, 3.6937, 3.5631, 3.8776, 3.6239, 4.1241, 3.5108, 3.5856, 3.9571,
         1.5752, 1.5632, 1.5377, 1.5363, 1.5570, 1.5664, 1.5906, 1.5664, 1.5664,
         1.3493, 1.3165, 1.3110, 1.3671, 1.3103, 1.4035, 1.3842, 1.3539, 1.3078,
         1.5444, 1.5994, 1.5637, 1.5507, 1.5457, 1.5827, 1.6020, 1.4379, 1.5352,
         1.1645, 1.2760, 1.2494, 1.2975, 1.1590, 1.1652, 1.0875, 1.3577, 1.2399],
        [1.4504, 1.4503, 1.4487, 1.4459, 1.4462, 1.4504, 1.4461, 1.4504, 1.4504,
         1.4292, 1.4285, 1.4292, 1.4292, 1.4292, 1.4103, 1.4292, 1.4280, 1.4258,
         2.2030, 2.2035, 2.2203, 2.1959, 2.1771, 2.1754, 2.2046, 2.1744, 2.1744,
         1.5070, 1.5054, 1.5128, 1.5128, 1.5070, 1.5128, 1.5128, 1.5128, 1.5128,
         1.7731, 1.7732, 1.7732, 1.7700, 1.7731, 1.7731, 1.7732, 1.7503, 1.7531,
         1.4534, 1.4581, 1.4581, 1.4581, 1.4497, 1.4581, 1.4540, 1.4580, 1.4581],
        [1.3179, 1.3160, 1.3001, 1.2914, 1.3150, 1.3134, 1.3145, 1.3150, 1.3150,
         1.2944, 1.2877, 1.2839, 1.2834, 1.2951, 1.2795, 1.2909, 1.2947, 1.2670,
         1.6442, 1.6177, 1.6411, 1.6406, 1.6400, 1.6401, 1.6423, 1.6438, 1.6438,
         3.4921, 3.2825, 3.2081, 3.2666, 3.4177, 3.2350, 3.4665, 3.2162, 3.1947,
         1.6458, 1.6383, 1.6366, 1.6398, 1.6427, 1.6187, 1.6441, 1.5834, 1.6099,
         1.3216, 1.3160, 1.3062, 1.3209, 1.3166, 1.3088, 1.3209, 1.3210, 1.3231],
        [1.4532, 1.4488, 1.4052, 1.4090, 1.4466, 1.4531, 1.4516, 1.4532, 1.4532,
         1.4310, 1.4283, 1.4233, 1.4182, 1.4321, 1.3910, 1.4261, 1.4320, 1.4270,
         1.7579, 1.7492, 1.7476, 1.7559, 1.7737, 1.7723, 1.7523, 1.7739, 1.7739,
         1.4737, 1.4786, 1.5156, 1.5103, 1.4791, 1.5141, 1.5025, 1.5156, 1.5125,
         2.1999, 2.1793, 2.1679, 2.1860, 2.2303, 2.2473, 2.2137, 2.3187, 2.3151,
         1.4453, 1.4362, 1.4505, 1.4609, 1.4478, 1.4576, 1.4278, 1.4548, 1.4609],
        [1.3744, 1.2796, 1.2758, 1.2945, 1.2880, 1.2979, 1.2967, 1.2342, 1.2342,
         1.2654, 1.2233, 1.2220, 1.2268, 1.3086, 1.1797, 1.1368, 1.3086, 1.2063,
         1.6190, 1.5956, 1.5776, 1.5726, 1.5952, 1.5916, 1.6117, 1.5967, 1.5967,
         1.3720, 1.3453, 1.3440, 1.3625, 1.3468, 1.3906, 1.3923, 1.3658, 1.3440,
         1.5907, 1.5908, 1.5958, 1.5855, 1.5621, 1.5659, 1.6265, 1.5166, 1.4862,
         4.0040, 3.6136, 3.6944, 3.6808, 3.6902, 3.3947, 3.9959, 3.6587, 3.4250]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 185 : 1780.296933167207
Test loss for epoch 185 : 194.2484562213656
Test Precision for epoch 185 : 0.26153846153846155
Test Recall for epoch 185 : 0.26153846153846155
Test F1 for epoch 185 : 0.26153846153846155


theta for epoch 186 : tensor([[3.6230, 3.6461, 3.7887, 3.7348, 3.7230, 3.6046, 3.6456, 3.5450, 3.5450,
         1.2554, 1.2346, 1.2333, 1.2363, 1.2757, 1.2166, 1.1845, 1.2757, 1.2212,
         1.6003, 1.5845, 1.6088, 1.5907, 1.5968, 1.5984, 1.6061, 1.5984, 1.5984,
         1.3444, 1.3555, 1.3409, 1.3634, 1.3435, 1.3752, 1.3678, 1.3544, 1.3409,
         1.5930, 1.6093, 1.5981, 1.5945, 1.6014, 1.5915, 1.6100, 1.5633, 1.5681,
         1.2553, 1.2818, 1.2738, 1.2910, 1.2502, 1.2420, 1.2296, 1.3129, 1.2706],
        [1.3868, 1.2385, 1.2284, 1.2705, 1.2709, 1.2830, 1.2770, 1.1841, 1.1841,
         3.6103, 3.6811, 3.5501, 3.8657, 3.6110, 4.1132, 3.4977, 3.5726, 3.9455,
         1.5847, 1.5726, 1.5473, 1.5456, 1.5661, 1.5755, 1.5999, 1.5755, 1.5755,
         1.3633, 1.3305, 1.3244, 1.3812, 1.3241, 1.4179, 1.3985, 1.3678, 1.3213,
         1.5511, 1.6062, 1.5703, 1.5574, 1.5525, 1.5895, 1.6089, 1.4451, 1.5420,
         1.1721, 1.2836, 1.2569, 1.3051, 1.1665, 1.1726, 1.0954, 1.3654, 1.2474],
        [1.4496, 1.4496, 1.4480, 1.4452, 1.4454, 1.4496, 1.4454, 1.4497, 1.4497,
         1.4266, 1.4259, 1.4266, 1.4265, 1.4266, 1.4077, 1.4266, 1.4254, 1.4231,
         2.2053, 2.2058, 2.2227, 2.1981, 2.1793, 2.1776, 2.2068, 2.1766, 2.1766,
         1.5148, 1.5132, 1.5206, 1.5206, 1.5148, 1.5206, 1.5206, 1.5206, 1.5206,
         1.7732, 1.7733, 1.7733, 1.7701, 1.7732, 1.7732, 1.7733, 1.7504, 1.7532,
         1.4505, 1.4552, 1.4552, 1.4552, 1.4469, 1.4552, 1.4512, 1.4552, 1.4552],
        [1.3175, 1.3156, 1.2996, 1.2910, 1.3145, 1.3129, 1.3140, 1.3145, 1.3145,
         1.2919, 1.2852, 1.2813, 1.2808, 1.2926, 1.2770, 1.2883, 1.2922, 1.2645,
         1.6469, 1.6204, 1.6438, 1.6433, 1.6427, 1.6427, 1.6449, 1.6464, 1.6464,
         3.4975, 3.2879, 3.2135, 3.2720, 3.4231, 3.2403, 3.4718, 3.2216, 3.2001,
         1.6460, 1.6385, 1.6368, 1.6400, 1.6429, 1.6189, 1.6443, 1.5836, 1.6101,
         1.3189, 1.3134, 1.3036, 1.3182, 1.3140, 1.3061, 1.3182, 1.3184, 1.3205],
        [1.4525, 1.4480, 1.4043, 1.4083, 1.4458, 1.4524, 1.4508, 1.4525, 1.4525,
         1.4283, 1.4257, 1.4207, 1.4156, 1.4295, 1.3883, 1.4235, 1.4294, 1.4244,
         1.7604, 1.7517, 1.7500, 1.7583, 1.7762, 1.7747, 1.7548, 1.7763, 1.7763,
         1.4815, 1.4863, 1.5233, 1.5180, 1.4868, 1.5219, 1.5103, 1.5234, 1.5203,
         2.2000, 2.1794, 2.1680, 2.1861, 2.2304, 2.2474, 2.2138, 2.3188, 2.3152,
         1.4424, 1.4334, 1.4477, 1.4580, 1.4449, 1.4548, 1.4248, 1.4520, 1.4581],
        [1.3597, 1.2683, 1.2641, 1.2826, 1.2760, 1.2859, 1.2848, 1.2249, 1.2249,
         1.2590, 1.2169, 1.2156, 1.2205, 1.3021, 1.1731, 1.1305, 1.3021, 1.1999,
         1.6165, 1.5932, 1.5750, 1.5706, 1.5933, 1.5896, 1.6092, 1.5947, 1.5947,
         1.3700, 1.3434, 1.3432, 1.3602, 1.3452, 1.3877, 1.3898, 1.3640, 1.3432,
         1.5875, 1.5871, 1.5926, 1.5823, 1.5587, 1.5623, 1.6227, 1.5132, 1.4826,
         4.0129, 3.6213, 3.7023, 3.6886, 3.6981, 3.4022, 4.0048, 3.6665, 3.4324]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 186 : 1781.227902812107
Test loss for epoch 186 : 193.9794976056208
Test Precision for epoch 186 : 0.26153846153846155
Test Recall for epoch 186 : 0.26153846153846155
Test F1 for epoch 186 : 0.26153846153846155


theta for epoch 187 : tensor([[3.6215, 3.6446, 3.7873, 3.7334, 3.7215, 3.6031, 3.6441, 3.5435, 3.5435,
         1.2625, 1.2409, 1.2396, 1.2429, 1.2834, 1.2227, 1.1892, 1.2834, 1.2273,
         1.6007, 1.5849, 1.6093, 1.5909, 1.5969, 1.5986, 1.6064, 1.5986, 1.5986,
         1.3374, 1.3484, 1.3334, 1.3565, 1.3363, 1.3685, 1.3610, 1.3474, 1.3334,
         1.5950, 1.6114, 1.6000, 1.5964, 1.6034, 1.5936, 1.6122, 1.5652, 1.5700,
         1.2482, 1.2751, 1.2670, 1.2844, 1.2430, 1.2346, 1.2225, 1.3066, 1.2637],
        [1.3907, 1.2405, 1.2307, 1.2729, 1.2732, 1.2854, 1.2793, 1.1852, 1.1852,
         3.6079, 3.6789, 3.5475, 3.8641, 3.6086, 4.1127, 3.4950, 3.5700, 3.9442,
         1.5877, 1.5755, 1.5503, 1.5483, 1.5688, 1.5782, 1.6028, 1.5782, 1.5782,
         1.3623, 1.3295, 1.3230, 1.3802, 1.3230, 1.4170, 1.3975, 1.3666, 1.3199,
         1.5551, 1.6104, 1.5744, 1.5614, 1.5566, 1.5937, 1.6132, 1.4493, 1.5461,
         1.1710, 1.2825, 1.2558, 1.3040, 1.1653, 1.1714, 1.0946, 1.3644, 1.2463],
        [1.4496, 1.4495, 1.4479, 1.4451, 1.4454, 1.4496, 1.4453, 1.4496, 1.4496,
         1.4338, 1.4331, 1.4338, 1.4337, 1.4338, 1.4149, 1.4338, 1.4326, 1.4303,
         2.2056, 2.2061, 2.2230, 2.1984, 2.1796, 2.1779, 2.2071, 2.1769, 2.1769,
         1.5077, 1.5061, 1.5135, 1.5135, 1.5077, 1.5135, 1.5135, 1.5135, 1.5135,
         1.7753, 1.7754, 1.7754, 1.7722, 1.7753, 1.7753, 1.7754, 1.7524, 1.7552,
         1.4431, 1.4479, 1.4479, 1.4479, 1.4395, 1.4479, 1.4438, 1.4478, 1.4479],
        [1.3179, 1.3159, 1.3000, 1.2914, 1.3149, 1.3133, 1.3144, 1.3148, 1.3148,
         1.2992, 1.2925, 1.2887, 1.2882, 1.3000, 1.2843, 1.2956, 1.2996, 1.2718,
         1.6475, 1.6209, 1.6443, 1.6438, 1.6432, 1.6433, 1.6455, 1.6470, 1.6470,
         3.4900, 3.2803, 3.2058, 3.2644, 3.4156, 3.2327, 3.4644, 3.2140, 3.1923,
         1.6483, 1.6408, 1.6390, 1.6422, 1.6451, 1.6211, 1.6465, 1.5858, 1.6123,
         1.3117, 1.3062, 1.2964, 1.3111, 1.3068, 1.2990, 1.3111, 1.3113, 1.3133],
        [1.4524, 1.4479, 1.4042, 1.4082, 1.4458, 1.4523, 1.4507, 1.4524, 1.4524,
         1.4355, 1.4329, 1.4279, 1.4228, 1.4367, 1.3955, 1.4307, 1.4366, 1.4315,
         1.7607, 1.7520, 1.7503, 1.7586, 1.7765, 1.7751, 1.7551, 1.7767, 1.7767,
         1.4744, 1.4792, 1.5163, 1.5109, 1.4797, 1.5148, 1.5032, 1.5163, 1.5132,
         2.2020, 2.1814, 2.1700, 2.1881, 2.2324, 2.2494, 2.2158, 2.3209, 2.3173,
         1.4349, 1.4260, 1.4403, 1.4507, 1.4375, 1.4474, 1.4173, 1.4446, 1.4507],
        [1.3437, 1.2550, 1.2505, 1.2688, 1.2622, 1.2721, 1.2710, 1.2132, 1.2132,
         1.2609, 1.2186, 1.2173, 1.2222, 1.3041, 1.1744, 1.1317, 1.3041, 1.2016,
         1.6106, 1.5874, 1.5689, 1.5651, 1.5878, 1.5842, 1.6034, 1.5893, 1.5893,
         1.3534, 1.3269, 1.3276, 1.3434, 1.3290, 1.3703, 1.3728, 1.3475, 1.3277,
         1.5851, 1.5842, 1.5901, 1.5798, 1.5560, 1.5594, 1.6198, 1.5105, 1.4797,
         4.0226, 3.6298, 3.7109, 3.6973, 3.7069, 3.4105, 4.0145, 3.6751, 3.4407]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 187 : 1780.5831029728809
Test loss for epoch 187 : 194.27272103321926
Test Precision for epoch 187 : 0.26153846153846155
Test Recall for epoch 187 : 0.26153846153846155
Test F1 for epoch 187 : 0.26153846153846155


theta for epoch 188 : tensor([[3.6217, 3.6448, 3.7876, 3.7337, 3.7217, 3.6033, 3.6443, 3.5437, 3.5437,
         1.2744, 1.2520, 1.2506, 1.2542, 1.2958, 1.2335, 1.1984, 1.2958, 1.2382,
         1.5963, 1.5804, 1.6049, 1.5862, 1.5923, 1.5939, 1.6020, 1.5939, 1.5939,
         1.3302, 1.3412, 1.3256, 1.3493, 1.3288, 1.3618, 1.3540, 1.3401, 1.3256,
         1.5948, 1.6114, 1.5998, 1.5962, 1.6033, 1.5936, 1.6123, 1.5651, 1.5699,
         1.2388, 1.2663, 1.2579, 1.2758, 1.2335, 1.2250, 1.2131, 1.2984, 1.2546],
        [1.3885, 1.2368, 1.2271, 1.2694, 1.2698, 1.2819, 1.2759, 1.1806, 1.1806,
         3.6134, 3.6847, 3.5530, 3.8705, 3.6142, 4.1201, 3.5003, 3.5755, 3.9510,
         1.5828, 1.5706, 1.5455, 1.5432, 1.5638, 1.5731, 1.5980, 1.5732, 1.5732,
         1.3559, 1.3231, 1.3163, 1.3738, 1.3165, 1.4108, 1.3912, 1.3602, 1.3132,
         1.5537, 1.6091, 1.5729, 1.5600, 1.5552, 1.5924, 1.6120, 1.4477, 1.5446,
         1.1635, 1.2753, 1.2485, 1.2968, 1.1578, 1.1638, 1.0874, 1.3574, 1.2390],
        [1.4504, 1.4503, 1.4487, 1.4459, 1.4461, 1.4504, 1.4461, 1.4504, 1.4504,
         1.4459, 1.4451, 1.4458, 1.4458, 1.4459, 1.4270, 1.4458, 1.4446, 1.4424,
         2.2017, 2.2022, 2.2191, 2.1947, 2.1758, 2.1741, 2.2034, 2.1731, 2.1731,
         1.5008, 1.4992, 1.5067, 1.5067, 1.5008, 1.5067, 1.5066, 1.5067, 1.5067,
         1.7755, 1.7756, 1.7756, 1.7724, 1.7755, 1.7755, 1.7756, 1.7526, 1.7554,
         1.4342, 1.4389, 1.4389, 1.4389, 1.4305, 1.4389, 1.4348, 1.4389, 1.4389],
        [1.3192, 1.3171, 1.3011, 1.2925, 1.3160, 1.3145, 1.3155, 1.3159, 1.3159,
         1.3115, 1.3047, 1.3009, 1.3004, 1.3123, 1.2965, 1.3078, 1.3118, 1.2840,
         1.6435, 1.6170, 1.6404, 1.6399, 1.6393, 1.6393, 1.6416, 1.6430, 1.6430,
         3.4826, 3.2727, 3.1981, 3.2568, 3.4081, 3.2251, 3.4570, 3.2063, 3.1847,
         1.6486, 1.6412, 1.6394, 1.6426, 1.6455, 1.6215, 1.6469, 1.5861, 1.6127,
         1.3029, 1.2975, 1.2876, 1.3023, 1.2980, 1.2902, 1.3023, 1.3025, 1.3046],
        [1.4532, 1.4486, 1.4049, 1.4090, 1.4465, 1.4531, 1.4515, 1.4532, 1.4532,
         1.4476, 1.4449, 1.4399, 1.4348, 1.4487, 1.4075, 1.4427, 1.4486, 1.4436,
         1.7566, 1.7479, 1.7462, 1.7545, 1.7725, 1.7710, 1.7510, 1.7726, 1.7726,
         1.4675, 1.4722, 1.5094, 1.5040, 1.4728, 1.5079, 1.4963, 1.5095, 1.5064,
         2.2023, 2.1816, 2.1702, 2.1883, 2.2327, 2.2497, 2.2160, 2.3212, 2.3176,
         1.4259, 1.4170, 1.4313, 1.4417, 1.4285, 1.4384, 1.4082, 1.4356, 1.4418],
        [1.3275, 1.2405, 1.2358, 1.2540, 1.2473, 1.2573, 1.2561, 1.1997, 1.1997,
         1.2667, 1.2240, 1.2226, 1.2277, 1.3101, 1.1793, 1.1361, 1.3101, 1.2068,
         1.5995, 1.5763, 1.5576, 1.5542, 1.5770, 1.5733, 1.5923, 1.5785, 1.5785,
         1.3357, 1.3092, 1.3106, 1.3255, 1.3116, 1.3520, 1.3548, 1.3298, 1.3106,
         1.5798, 1.5786, 1.5848, 1.5745, 1.5505, 1.5538, 1.6142, 1.5050, 1.4739,
         4.0339, 3.6400, 3.7212, 3.7075, 3.7172, 3.4203, 4.0259, 3.6852, 3.4506]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 188 : 1780.2685760994657
Test loss for epoch 188 : 194.8591741243048
Test Precision for epoch 188 : 0.26153846153846155
Test Recall for epoch 188 : 0.26153846153846155
Test F1 for epoch 188 : 0.26153846153846155


theta for epoch 189 : tensor([[3.6247, 3.6478, 3.7907, 3.7368, 3.7248, 3.6063, 3.6474, 3.5468, 3.5468,
         1.2788, 1.2557, 1.2542, 1.2580, 1.3008, 1.2368, 1.2003, 1.3008, 1.2416,
         1.5924, 1.5763, 1.6010, 1.5819, 1.5880, 1.5897, 1.5980, 1.5896, 1.5896,
         1.3345, 1.3453, 1.3293, 1.3536, 1.3329, 1.3664, 1.3585, 1.3442, 1.3293,
         1.5916, 1.6085, 1.5967, 1.5931, 1.6003, 1.5906, 1.6094, 1.5620, 1.5668,
         1.2323, 1.2604, 1.2518, 1.2701, 1.2269, 1.2181, 1.2066, 1.2933, 1.2483],
        [1.3820, 1.2289, 1.2193, 1.2617, 1.2621, 1.2742, 1.2682, 1.1720, 1.1720,
         3.6223, 3.6937, 3.5616, 3.8802, 3.6230, 4.1308, 3.5089, 3.5842, 3.9610,
         1.5746, 1.5624, 1.5372, 1.5349, 1.5554, 1.5648, 1.5898, 1.5648, 1.5648,
         1.3519, 1.3189, 1.3120, 1.3698, 1.3123, 1.4071, 1.3874, 1.3562, 1.3089,
         1.5464, 1.6020, 1.5657, 1.5527, 1.5479, 1.5852, 1.6049, 1.4402, 1.5373,
         1.1540, 1.2662, 1.2393, 1.2878, 1.1483, 1.1542, 1.0780, 1.3486, 1.2297],
        [1.4534, 1.4533, 1.4517, 1.4489, 1.4491, 1.4534, 1.4491, 1.4534, 1.4534,
         1.4506, 1.4498, 1.4505, 1.4505, 1.4505, 1.4317, 1.4505, 1.4493, 1.4471,
         2.1985, 2.1990, 2.2159, 2.1916, 2.1727, 2.1710, 2.2003, 2.1700, 2.1700,
         1.5057, 1.5041, 1.5116, 1.5116, 1.5057, 1.5116, 1.5115, 1.5116, 1.5116,
         1.7730, 1.7731, 1.7731, 1.7699, 1.7730, 1.7730, 1.7731, 1.7502, 1.7529,
         1.4286, 1.4334, 1.4334, 1.4334, 1.4250, 1.4334, 1.4293, 1.4334, 1.4334],
        [1.3226, 1.3204, 1.3045, 1.2959, 1.3194, 1.3178, 1.3189, 1.3192, 1.3192,
         1.3163, 1.3096, 1.3057, 1.3052, 1.3171, 1.3013, 1.3125, 1.3167, 1.2889,
         1.6403, 1.6137, 1.6372, 1.6366, 1.6360, 1.6361, 1.6383, 1.6398, 1.6398,
         3.4853, 3.2754, 3.2008, 3.2594, 3.4108, 3.2277, 3.4597, 3.2090, 3.1873,
         1.6463, 1.6388, 1.6371, 1.6402, 1.6432, 1.6192, 1.6446, 1.5838, 1.6103,
         1.2976, 1.2921, 1.2823, 1.2970, 1.2927, 1.2848, 1.2969, 1.2973, 1.2992],
        [1.4562, 1.4516, 1.4078, 1.4120, 1.4495, 1.4561, 1.4545, 1.4562, 1.4562,
         1.4522, 1.4496, 1.4446, 1.4394, 1.4534, 1.4121, 1.4474, 1.4533, 1.4482,
         1.7532, 1.7445, 1.7428, 1.7511, 1.7691, 1.7676, 1.7477, 1.7693, 1.7693,
         1.4724, 1.4770, 1.5143, 1.5089, 1.4777, 1.5128, 1.5013, 1.5144, 1.5113,
         2.1999, 2.1792, 2.1678, 2.1860, 2.2303, 2.2473, 2.2136, 2.3189, 2.3153,
         1.4203, 1.4114, 1.4257, 1.4362, 1.4229, 1.4329, 1.4026, 1.4301, 1.4363],
        [1.3132, 1.2268, 1.2220, 1.2401, 1.2334, 1.2434, 1.2422, 1.1863, 1.1863,
         1.2651, 1.2218, 1.2204, 1.2256, 1.3088, 1.1766, 1.1326, 1.3088, 1.2044,
         1.5882, 1.5650, 1.5462, 1.5430, 1.5659, 1.5622, 1.5810, 1.5673, 1.5673,
         1.3274, 1.3008, 1.3027, 1.3170, 1.3033, 1.3433, 1.3464, 1.3215, 1.3027,
         1.5711, 1.5696, 1.5762, 1.5657, 1.5417, 1.5449, 1.6054, 1.4959, 1.4647,
         4.0486, 3.6535, 3.7349, 3.7211, 3.7309, 3.4336, 4.0407, 3.6988, 3.4639]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 189 : 1780.1543622798777
Test loss for epoch 189 : 195.47064574946563
Test Precision for epoch 189 : 0.26153846153846155
Test Recall for epoch 189 : 0.26153846153846155
Test F1 for epoch 189 : 0.26153846153846155


theta for epoch 190 : tensor([[3.6319, 3.6552, 3.7981, 3.7442, 3.7321, 3.6137, 3.6547, 3.5543, 3.5543,
         1.2687, 1.2449, 1.2435, 1.2475, 1.2911, 1.2258, 1.1881, 1.2912, 1.2307,
         1.5940, 1.5779, 1.6027, 1.5833, 1.5894, 1.5911, 1.5996, 1.5911, 1.5911,
         1.3465, 1.3574, 1.3410, 1.3658, 1.3448, 1.3788, 1.3707, 1.3563, 1.3410,
         1.5896, 1.6066, 1.5947, 1.5911, 1.5983, 1.5887, 1.6077, 1.5600, 1.5648,
         1.2311, 1.2598, 1.2509, 1.2697, 1.2254, 1.2164, 1.2052, 1.2935, 1.2474],
        [1.3725, 1.2184, 1.2088, 1.2514, 1.2518, 1.2640, 1.2579, 1.1611, 1.1611,
         3.6314, 3.7031, 3.5707, 3.8902, 3.6321, 4.1419, 3.5178, 3.5932, 3.9714,
         1.5675, 1.5553, 1.5299, 1.5276, 1.5483, 1.5577, 1.5828, 1.5578, 1.5578,
         1.3488, 1.3156, 1.3087, 1.3668, 1.3089, 1.4043, 1.3845, 1.3531, 1.3056,
         1.5372, 1.5931, 1.5566, 1.5435, 1.5387, 1.5762, 1.5960, 1.4305, 1.5281,
         1.1444, 1.2574, 1.2303, 1.2792, 1.1386, 1.1445, 1.0684, 1.3405, 1.2206],
        [1.4601, 1.4600, 1.4584, 1.4556, 1.4558, 1.4601, 1.4558, 1.4601, 1.4601,
         1.4410, 1.4403, 1.4410, 1.4410, 1.4410, 1.4221, 1.4410, 1.4398, 1.4376,
         2.2007, 2.2013, 2.2182, 2.1938, 2.1749, 2.1732, 2.2024, 2.1722, 2.1722,
         1.5189, 1.5174, 1.5248, 1.5248, 1.5190, 1.5248, 1.5247, 1.5248, 1.5248,
         1.7719, 1.7720, 1.7720, 1.7688, 1.7719, 1.7719, 1.7720, 1.7490, 1.7518,
         1.4290, 1.4338, 1.4338, 1.4338, 1.4253, 1.4338, 1.4296, 1.4337, 1.4338],
        [1.3295, 1.3274, 1.3114, 1.3028, 1.3263, 1.3247, 1.3258, 1.3261, 1.3261,
         1.3069, 1.3001, 1.2963, 1.2958, 1.3077, 1.2918, 1.3030, 1.3073, 1.2794,
         1.6429, 1.6163, 1.6398, 1.6392, 1.6386, 1.6387, 1.6409, 1.6424, 1.6424,
         3.4953, 3.2855, 3.2110, 3.2695, 3.4208, 3.2378, 3.4697, 3.2191, 3.1975,
         1.6453, 1.6378, 1.6360, 1.6392, 1.6421, 1.6182, 1.6435, 1.5828, 1.6093,
         1.2980, 1.2926, 1.2827, 1.2975, 1.2931, 1.2852, 1.2974, 1.2978, 1.2997],
        [1.4629, 1.4583, 1.4145, 1.4187, 1.4562, 1.4628, 1.4612, 1.4629, 1.4629,
         1.4427, 1.4401, 1.4351, 1.4299, 1.4439, 1.4025, 1.4379, 1.4438, 1.4387,
         1.7557, 1.7470, 1.7452, 1.7535, 1.7716, 1.7701, 1.7501, 1.7717, 1.7717,
         1.4857, 1.4902, 1.5275, 1.5221, 1.4909, 1.5260, 1.5145, 1.5276, 1.5245,
         2.1988, 2.1781, 2.1667, 2.1849, 2.2293, 2.2462, 2.2125, 2.3179, 2.3142,
         1.4206, 1.4118, 1.4261, 1.4366, 1.4233, 1.4333, 1.4029, 1.4305, 1.4366],
        [1.3027, 1.2158, 1.2109, 1.2292, 1.2225, 1.2325, 1.2314, 1.1751, 1.1751,
         1.2498, 1.2058, 1.2044, 1.2098, 1.2939, 1.1601, 1.1152, 1.2939, 1.1883,
         1.5821, 1.5588, 1.5399, 1.5367, 1.5597, 1.5560, 1.5749, 1.5612, 1.5612,
         1.3261, 1.2993, 1.3014, 1.3156, 1.3019, 1.3420, 1.3452, 1.3202, 1.3015,
         1.5632, 1.5616, 1.5682, 1.5577, 1.5335, 1.5367, 1.5975, 1.4876, 1.4561,
         4.0673, 3.6709, 3.7525, 3.7387, 3.7487, 3.4509, 4.0594, 3.7163, 3.4811]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 190 : 1779.0262720583805
Test loss for epoch 190 : 196.02160154183127
Test Precision for epoch 190 : 0.26153846153846155
Test Recall for epoch 190 : 0.26153846153846155
Test F1 for epoch 190 : 0.26153846153846155


theta for epoch 191 : tensor([[3.6315, 3.6547, 3.7977, 3.7438, 3.7316, 3.6132, 3.6543, 3.5538, 3.5538,
         1.2567, 1.2324, 1.2309, 1.2352, 1.2795, 1.2134, 1.1754, 1.2795, 1.2183,
         1.6022, 1.5860, 1.6109, 1.5914, 1.5975, 1.5991, 1.6078, 1.5991, 1.5991,
         1.3521, 1.3629, 1.3463, 1.3714, 1.3502, 1.3845, 1.3764, 1.3618, 1.3463,
         1.5925, 1.6096, 1.5976, 1.5940, 1.6013, 1.5917, 1.6107, 1.5629, 1.5677,
         1.2344, 1.2631, 1.2543, 1.2730, 1.2287, 1.2196, 1.2087, 1.2969, 1.2507],
        [1.3685, 1.2144, 1.2047, 1.2474, 1.2478, 1.2600, 1.2539, 1.1572, 1.1572,
         3.6324, 3.7043, 3.5715, 3.8921, 3.6330, 4.1448, 3.5186, 3.5940, 3.9735,
         1.5693, 1.5570, 1.5315, 1.5294, 1.5501, 1.5596, 1.5847, 1.5597, 1.5597,
         1.3463, 1.3131, 1.3064, 1.3644, 1.3065, 1.4018, 1.3820, 1.3507, 1.3032,
         1.5358, 1.5918, 1.5553, 1.5422, 1.5373, 1.5748, 1.5946, 1.4288, 1.5267,
         1.1430, 1.2554, 1.2286, 1.2770, 1.1374, 1.1436, 1.0675, 1.3377, 1.2190],
        [1.4649, 1.4649, 1.4632, 1.4605, 1.4607, 1.4649, 1.4606, 1.4649, 1.4649,
         1.4285, 1.4278, 1.4285, 1.4284, 1.4285, 1.4095, 1.4285, 1.4273, 1.4250,
         2.2078, 2.2083, 2.2252, 2.2006, 2.1817, 2.1800, 2.2092, 2.1790, 2.1790,
         1.5236, 1.5221, 1.5295, 1.5295, 1.5237, 1.5295, 1.5295, 1.5295, 1.5295,
         1.7745, 1.7746, 1.7746, 1.7714, 1.7745, 1.7745, 1.7746, 1.7516, 1.7544,
         1.4318, 1.4366, 1.4366, 1.4366, 1.4282, 1.4366, 1.4324, 1.4365, 1.4366],
        [1.3345, 1.3323, 1.3164, 1.3078, 1.3313, 1.3297, 1.3308, 1.3311, 1.3311,
         1.2944, 1.2876, 1.2838, 1.2833, 1.2953, 1.2793, 1.2905, 1.2949, 1.2669,
         1.6506, 1.6241, 1.6475, 1.6470, 1.6464, 1.6464, 1.6486, 1.6501, 1.6501,
         3.4984, 3.2885, 3.2140, 3.2726, 3.4239, 3.2408, 3.4727, 3.2222, 3.2006,
         1.6479, 1.6405, 1.6387, 1.6419, 1.6448, 1.6209, 1.6462, 1.5854, 1.6120,
         1.3009, 1.2955, 1.2857, 1.3004, 1.2960, 1.2882, 1.3003, 1.3007, 1.3026],
        [1.4677, 1.4631, 1.4194, 1.4236, 1.4610, 1.4676, 1.4660, 1.4678, 1.4678,
         1.4302, 1.4275, 1.4225, 1.4173, 1.4313, 1.3899, 1.4254, 1.4313, 1.4262,
         1.7632, 1.7545, 1.7527, 1.7610, 1.7791, 1.7775, 1.7576, 1.7792, 1.7792,
         1.4904, 1.4949, 1.5323, 1.5268, 1.4957, 1.5307, 1.5192, 1.5323, 1.5292,
         2.2013, 2.1806, 2.1692, 2.1874, 2.2318, 2.2487, 2.2150, 2.3204, 2.3167,
         1.4234, 1.4146, 1.4289, 1.4394, 1.4261, 1.4361, 1.4057, 1.4333, 1.4394],
        [1.3188, 1.2318, 1.2270, 1.2453, 1.2385, 1.2485, 1.2474, 1.1910, 1.1910,
         1.2439, 1.1994, 1.1979, 1.2039, 1.2883, 1.1542, 1.1101, 1.2883, 1.1825,
         1.5964, 1.5731, 1.5542, 1.5511, 1.5740, 1.5703, 1.5891, 1.5755, 1.5755,
         1.3402, 1.3134, 1.3155, 1.3297, 1.3160, 1.3561, 1.3592, 1.3343, 1.3155,
         1.5716, 1.5700, 1.5766, 1.5662, 1.5421, 1.5452, 1.6058, 1.4963, 1.4650,
         4.0529, 3.6554, 3.7372, 3.7233, 3.7333, 3.4350, 4.0451, 3.7010, 3.4654]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 191 : 1779.388283018623
Test loss for epoch 191 : 195.39366733200546
Test Precision for epoch 191 : 0.26153846153846155
Test Recall for epoch 191 : 0.26153846153846155
Test F1 for epoch 191 : 0.26153846153846155


theta for epoch 192 : tensor([[3.6283, 3.6515, 3.7946, 3.7406, 3.7284, 3.6100, 3.6511, 3.5505, 3.5505,
         1.2517, 1.2270, 1.2254, 1.2300, 1.2748, 1.2079, 1.1697, 1.2748, 1.2130,
         1.6074, 1.5913, 1.6162, 1.5965, 1.6027, 1.6043, 1.6130, 1.6043, 1.6043,
         1.3405, 1.3514, 1.3347, 1.3598, 1.3386, 1.3730, 1.3649, 1.3502, 1.3347,
         1.5973, 1.6145, 1.6023, 1.5988, 1.6061, 1.5965, 1.6156, 1.5677, 1.5725,
         1.2421, 1.2709, 1.2621, 1.2809, 1.2365, 1.2274, 1.2166, 1.3047, 1.2585],
        [1.3547, 1.2009, 1.1912, 1.2339, 1.2343, 1.2465, 1.2404, 1.1440, 1.1440,
         3.6410, 3.7133, 3.5801, 3.9016, 3.6416, 4.1553, 3.5270, 3.6026, 3.9834,
         1.5658, 1.5535, 1.5278, 1.5259, 1.5467, 1.5563, 1.5813, 1.5563, 1.5563,
         1.3299, 1.2967, 1.2902, 1.3479, 1.2901, 1.3852, 1.3655, 1.3343, 1.2871,
         1.5333, 1.5894, 1.5528, 1.5397, 1.5347, 1.5724, 1.5922, 1.4257, 1.5241,
         1.1410, 1.2534, 1.2266, 1.2749, 1.1355, 1.1421, 1.0659, 1.3353, 1.2171],
        [1.4602, 1.4602, 1.4586, 1.4558, 1.4560, 1.4602, 1.4560, 1.4603, 1.4603,
         1.4232, 1.4225, 1.4232, 1.4232, 1.4232, 1.4043, 1.4232, 1.4220, 1.4198,
         2.2126, 2.2131, 2.2300, 2.2052, 2.1863, 2.1846, 2.2138, 2.1836, 2.1836,
         1.5122, 1.5106, 1.5181, 1.5181, 1.5122, 1.5181, 1.5180, 1.5181, 1.5181,
         1.7793, 1.7794, 1.7794, 1.7761, 1.7793, 1.7793, 1.7794, 1.7564, 1.7591,
         1.4397, 1.4445, 1.4445, 1.4445, 1.4360, 1.4444, 1.4403, 1.4444, 1.4445],
        [1.3297, 1.3275, 1.3116, 1.3030, 1.3265, 1.3249, 1.3260, 1.3263, 1.3263,
         1.2892, 1.2824, 1.2786, 1.2781, 1.2901, 1.2741, 1.2853, 1.2897, 1.2617,
         1.6558, 1.6293, 1.6527, 1.6522, 1.6516, 1.6516, 1.6539, 1.6553, 1.6553,
         3.4883, 3.2782, 3.2036, 3.2623, 3.4137, 3.2305, 3.4626, 3.2118, 3.1902,
         1.6528, 1.6453, 1.6436, 1.6467, 1.6497, 1.6257, 1.6511, 1.5903, 1.6168,
         1.3089, 1.3035, 1.2936, 1.3084, 1.3040, 1.2961, 1.3083, 1.3087, 1.3106],
        [1.4630, 1.4585, 1.4147, 1.4188, 1.4564, 1.4630, 1.4613, 1.4631, 1.4631,
         1.4250, 1.4223, 1.4173, 1.4121, 1.4261, 1.3847, 1.4201, 1.4261, 1.4209,
         1.7683, 1.7596, 1.7578, 1.7661, 1.7841, 1.7826, 1.7627, 1.7843, 1.7843,
         1.4789, 1.4834, 1.5208, 1.5154, 1.4842, 1.5193, 1.5077, 1.5209, 1.5178,
         2.2059, 2.1853, 2.1738, 2.1920, 2.2364, 2.2533, 2.2196, 2.3249, 2.3213,
         1.4313, 1.4225, 1.4368, 1.4472, 1.4339, 1.4440, 1.4136, 1.4411, 1.4473],
        [1.3252, 1.2375, 1.2329, 1.2511, 1.2444, 1.2544, 1.2533, 1.1962, 1.1962,
         1.2433, 1.1980, 1.1966, 1.2032, 1.2881, 1.1533, 1.1093, 1.2881, 1.1818,
         1.6064, 1.5831, 1.5643, 1.5611, 1.5839, 1.5802, 1.5992, 1.5854, 1.5854,
         1.3378, 1.3111, 1.3129, 1.3275, 1.3136, 1.3539, 1.3568, 1.3319, 1.3129,
         1.5804, 1.5790, 1.5854, 1.5750, 1.5509, 1.5542, 1.6147, 1.5053, 1.4741,
         4.0454, 3.6468, 3.7287, 3.7148, 3.7248, 3.4260, 4.0377, 3.6925, 3.4565]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 192 : 1779.05720220176
Test loss for epoch 192 : 195.57993349278863
Test Precision for epoch 192 : 0.26153846153846155
Test Recall for epoch 192 : 0.26153846153846155
Test F1 for epoch 192 : 0.26153846153846155


theta for epoch 193 : tensor([[3.6227, 3.6458, 3.7890, 3.7351, 3.7228, 3.6044, 3.6454, 3.5447, 3.5447,
         1.2544, 1.2296, 1.2281, 1.2328, 1.2774, 1.2106, 1.1729, 1.2774, 1.2159,
         1.6020, 1.5858, 1.6107, 1.5911, 1.5972, 1.5988, 1.6076, 1.5988, 1.5988,
         1.3362, 1.3470, 1.3304, 1.3555, 1.3343, 1.3686, 1.3605, 1.3459, 1.3305,
         1.5989, 1.6162, 1.6040, 1.6004, 1.6077, 1.5982, 1.6173, 1.5694, 1.5742,
         1.2491, 1.2778, 1.2690, 1.2878, 1.2434, 1.2343, 1.2238, 1.3116, 1.2654],
        [1.3520, 1.1993, 1.1895, 1.2321, 1.2325, 1.2447, 1.2386, 1.1429, 1.1429,
         3.6406, 3.7130, 3.5795, 3.9019, 3.6411, 4.1567, 3.5262, 3.6020, 3.9841,
         1.5615, 1.5493, 1.5235, 1.5218, 1.5426, 1.5522, 1.5770, 1.5522, 1.5522,
         1.3271, 1.2940, 1.2878, 1.3450, 1.2875, 1.3821, 1.3625, 1.3315, 1.2846,
         1.5349, 1.5908, 1.5544, 1.5413, 1.5363, 1.5739, 1.5936, 1.4273, 1.5257,
         1.1462, 1.2583, 1.2317, 1.2797, 1.1409, 1.1476, 1.0717, 1.3398, 1.2223],
        [1.4555, 1.4555, 1.4539, 1.4511, 1.4513, 1.4556, 1.4513, 1.4556, 1.4556,
         1.4253, 1.4246, 1.4253, 1.4252, 1.4253, 1.4063, 1.4253, 1.4241, 1.4218,
         2.2070, 2.2075, 2.2245, 2.1998, 2.1809, 2.1792, 2.2084, 2.1782, 2.1782,
         1.5071, 1.5055, 1.5130, 1.5130, 1.5071, 1.5130, 1.5129, 1.5130, 1.5130,
         1.7805, 1.7806, 1.7806, 1.7773, 1.7805, 1.7805, 1.7806, 1.7576, 1.7603,
         1.4461, 1.4509, 1.4509, 1.4509, 1.4425, 1.4509, 1.4467, 1.4509, 1.4509],
        [1.3248, 1.3226, 1.3067, 1.2981, 1.3216, 1.3200, 1.3211, 1.3214, 1.3214,
         1.2913, 1.2845, 1.2807, 1.2802, 1.2922, 1.2762, 1.2874, 1.2918, 1.2638,
         1.6499, 1.6233, 1.6468, 1.6462, 1.6456, 1.6457, 1.6479, 1.6493, 1.6493,
         3.4838, 3.2737, 3.1990, 3.2577, 3.4091, 3.2260, 3.4581, 3.2072, 3.1855,
         1.6540, 1.6466, 1.6448, 1.6480, 1.6509, 1.6269, 1.6523, 1.5916, 1.6181,
         1.3154, 1.3100, 1.3001, 1.3149, 1.3105, 1.3026, 1.3148, 1.3151, 1.3171],
        [1.4584, 1.4538, 1.4100, 1.4141, 1.4517, 1.4583, 1.4567, 1.4584, 1.4584,
         1.4270, 1.4243, 1.4193, 1.4141, 1.4282, 1.3867, 1.4222, 1.4281, 1.4230,
         1.7624, 1.7537, 1.7519, 1.7603, 1.7783, 1.7768, 1.7568, 1.7784, 1.7784,
         1.4738, 1.4783, 1.5157, 1.5103, 1.4791, 1.5142, 1.5026, 1.5158, 1.5127,
         2.2071, 2.1864, 2.1750, 2.1932, 2.2375, 2.2545, 2.2208, 2.3261, 2.3224,
         1.4378, 1.4289, 1.4432, 1.4537, 1.4404, 1.4504, 1.4201, 1.4476, 1.4537],
        [1.3326, 1.2442, 1.2396, 1.2579, 1.2512, 1.2612, 1.2600, 1.2024, 1.2024,
         1.2496, 1.2042, 1.2028, 1.2097, 1.2943, 1.1598, 1.1171, 1.2943, 1.1886,
         1.6060, 1.5828, 1.5641, 1.5607, 1.5834, 1.5798, 1.5988, 1.5849, 1.5849,
         1.3413, 1.3147, 1.3161, 1.3311, 1.3171, 1.3576, 1.3604, 1.3354, 1.3162,
         1.5858, 1.5845, 1.5908, 1.5804, 1.5564, 1.5597, 1.6201, 1.5109, 1.4798,
         4.0373, 3.6375, 3.7195, 3.7057, 3.7157, 3.4164, 4.0296, 3.6833, 3.4469]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 193 : 1779.153122804707
Test loss for epoch 193 : 195.53583339751233
Test Precision for epoch 193 : 0.26153846153846155
Test Recall for epoch 193 : 0.26153846153846155
Test F1 for epoch 193 : 0.26153846153846155


theta for epoch 194 : tensor([[3.6177, 3.6407, 3.7840, 3.7301, 3.7177, 3.5993, 3.6404, 3.5396, 3.5396,
         1.2621, 1.2377, 1.2362, 1.2409, 1.2848, 1.2188, 1.1824, 1.2848, 1.2242,
         1.5941, 1.5780, 1.6029, 1.5833, 1.5894, 1.5910, 1.5997, 1.5910, 1.5910,
         1.3431, 1.3540, 1.3376, 1.3624, 1.3414, 1.3753, 1.3673, 1.3529, 1.3377,
         1.5949, 1.6122, 1.6000, 1.5964, 1.6037, 1.5942, 1.6133, 1.5654, 1.5702,
         1.2490, 1.2776, 1.2688, 1.2875, 1.2434, 1.2343, 1.2240, 1.3113, 1.2653],
        [1.3659, 1.2145, 1.2046, 1.2471, 1.2474, 1.2596, 1.2535, 1.1586, 1.1586,
         3.6278, 3.7004, 3.5665, 3.8900, 3.6284, 4.1457, 3.5131, 3.5891, 3.9724,
         1.5644, 1.5523, 1.5267, 1.5251, 1.5458, 1.5552, 1.5798, 1.5553, 1.5553,
         1.3420, 1.3091, 1.3031, 1.3599, 1.3027, 1.3967, 1.3772, 1.3465, 1.2999,
         1.5398, 1.5953, 1.5592, 1.5462, 1.5411, 1.5785, 1.5980, 1.4329, 1.5306,
         1.1559, 1.2672, 1.2408, 1.2884, 1.1506, 1.1574, 1.0822, 1.3479, 1.2315],
        [1.4566, 1.4566, 1.4549, 1.4521, 1.4524, 1.4566, 1.4523, 1.4566, 1.4566,
         1.4320, 1.4312, 1.4319, 1.4319, 1.4320, 1.4130, 1.4320, 1.4307, 1.4285,
         2.1988, 2.1993, 2.2162, 2.1919, 2.1730, 2.1713, 2.2005, 2.1703, 2.1703,
         1.5123, 1.5107, 1.5182, 1.5181, 1.5123, 1.5181, 1.5181, 1.5181, 1.5182,
         1.7756, 1.7757, 1.7757, 1.7725, 1.7756, 1.7756, 1.7757, 1.7528, 1.7555,
         1.4449, 1.4497, 1.4497, 1.4497, 1.4413, 1.4497, 1.4455, 1.4496, 1.4497],
        [1.3256, 1.3235, 1.3075, 1.2989, 1.3224, 1.3208, 1.3220, 1.3223, 1.3223,
         1.2980, 1.2912, 1.2874, 1.2869, 1.2989, 1.2830, 1.2942, 1.2985, 1.2705,
         1.6410, 1.6144, 1.6379, 1.6373, 1.6367, 1.6368, 1.6390, 1.6405, 1.6405,
         3.4882, 3.2781, 3.2035, 3.2621, 3.4136, 3.2304, 3.4625, 3.2116, 3.1900,
         1.6491, 1.6417, 1.6399, 1.6431, 1.6460, 1.6221, 1.6474, 1.5867, 1.6132,
         1.3141, 1.3087, 1.2988, 1.3136, 1.3092, 1.3014, 1.3135, 1.3138, 1.3158],
        [1.4594, 1.4549, 1.4111, 1.4151, 1.4527, 1.4593, 1.4577, 1.4595, 1.4595,
         1.4337, 1.4310, 1.4260, 1.4208, 1.4348, 1.3934, 1.4289, 1.4348, 1.4296,
         1.7537, 1.7450, 1.7432, 1.7515, 1.7696, 1.7681, 1.7481, 1.7697, 1.7697,
         1.4790, 1.4836, 1.5209, 1.5155, 1.4843, 1.5194, 1.5078, 1.5209, 1.5178,
         2.2024, 2.1817, 2.1702, 2.1884, 2.2328, 2.2498, 2.2161, 2.3214, 2.3177,
         1.4366, 1.4277, 1.4420, 1.4525, 1.4392, 1.4492, 1.4189, 1.4464, 1.4525],
        [1.3449, 1.2559, 1.2515, 1.2698, 1.2631, 1.2731, 1.2719, 1.2138, 1.2138,
         1.2604, 1.2154, 1.2140, 1.2210, 1.3044, 1.1712, 1.1308, 1.3044, 1.2004,
         1.6030, 1.5799, 1.5613, 1.5577, 1.5803, 1.5767, 1.5958, 1.5818, 1.5818,
         1.3539, 1.3273, 1.3285, 1.3437, 1.3297, 1.3704, 1.3731, 1.3480, 1.3285,
         1.5854, 1.5842, 1.5904, 1.5800, 1.5561, 1.5595, 1.6197, 1.5107, 1.4798,
         4.0258, 3.6247, 3.7069, 3.6931, 3.7031, 3.4033, 4.0181, 3.6707, 3.4339]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 194 : 1779.4822572725577
Test loss for epoch 194 : 194.84031194897406
Test Precision for epoch 194 : 0.26153846153846155
Test Recall for epoch 194 : 0.26153846153846155
Test F1 for epoch 194 : 0.26153846153846155


theta for epoch 195 : tensor([[3.6144, 3.6373, 3.7808, 3.7268, 3.7144, 3.5959, 3.6370, 3.5362, 3.5362,
         1.2708, 1.2466, 1.2451, 1.2498, 1.2931, 1.2278, 1.1924, 1.2932, 1.2334,
         1.5917, 1.5755, 1.6004, 1.5809, 1.5870, 1.5886, 1.5973, 1.5886, 1.5886,
         1.3462, 1.3571, 1.3410, 1.3654, 1.3446, 1.3781, 1.3702, 1.3560, 1.3410,
         1.5894, 1.6067, 1.5945, 1.5909, 1.5982, 1.5887, 1.6078, 1.5599, 1.5647,
         1.2455, 1.2739, 1.2652, 1.2838, 1.2399, 1.2309, 1.2207, 1.3074, 1.2616],
        [1.3727, 1.2221, 1.2122, 1.2546, 1.2549, 1.2671, 1.2610, 1.1667, 1.1667,
         3.6225, 3.6953, 3.5611, 3.8854, 3.6231, 4.1422, 3.5074, 3.5837, 3.9682,
         1.5671, 1.5551, 1.5295, 1.5281, 1.5487, 1.5581, 1.5824, 1.5581, 1.5581,
         1.3496, 1.3167, 1.3109, 1.3674, 1.3104, 1.4040, 1.3846, 1.3541, 1.3077,
         1.5394, 1.5946, 1.5587, 1.5458, 1.5407, 1.5779, 1.5973, 1.4329, 1.5303,
         1.1582, 1.2690, 1.2427, 1.2901, 1.1530, 1.1598, 1.0852, 1.3493, 1.2335],
        [1.4558, 1.4557, 1.4541, 1.4513, 1.4516, 1.4558, 1.4515, 1.4558, 1.4558,
         1.4401, 1.4394, 1.4401, 1.4400, 1.4401, 1.4212, 1.4401, 1.4389, 1.4366,
         2.1959, 2.1964, 2.2134, 2.1892, 2.1703, 2.1686, 2.1978, 2.1676, 2.1676,
         1.5145, 1.5129, 1.5204, 1.5204, 1.5145, 1.5204, 1.5203, 1.5204, 1.5204,
         1.7697, 1.7698, 1.7698, 1.7666, 1.7697, 1.7697, 1.7698, 1.7468, 1.7496,
         1.4408, 1.4456, 1.4456, 1.4456, 1.4372, 1.4456, 1.4414, 1.4455, 1.4456],
        [1.3244, 1.3224, 1.3064, 1.2978, 1.3214, 1.3197, 1.3209, 1.3213, 1.3213,
         1.3061, 1.2993, 1.2955, 1.2950, 1.3070, 1.2911, 1.3024, 1.3065, 1.2787,
         1.6379, 1.6114, 1.6348, 1.6343, 1.6337, 1.6337, 1.6359, 1.6374, 1.6374,
         3.4902, 3.2801, 3.2055, 3.2641, 3.4156, 3.2324, 3.4646, 3.2137, 3.1921,
         1.6432, 1.6357, 1.6340, 1.6371, 1.6401, 1.6161, 1.6415, 1.5807, 1.6072,
         1.3100, 1.3045, 1.2947, 1.3094, 1.3050, 1.2972, 1.3094, 1.3096, 1.3116],
        [1.4586, 1.4541, 1.4103, 1.4143, 1.4519, 1.4585, 1.4570, 1.4586, 1.4586,
         1.4418, 1.4391, 1.4341, 1.4289, 1.4429, 1.4016, 1.4370, 1.4429, 1.4378,
         1.7507, 1.7420, 1.7403, 1.7486, 1.7666, 1.7651, 1.7451, 1.7667, 1.7667,
         1.4812, 1.4859, 1.5231, 1.5178, 1.4865, 1.5216, 1.5100, 1.5232, 1.5201,
         2.1966, 2.1760, 2.1645, 2.1827, 2.2271, 2.2441, 2.2104, 2.3156, 2.3120,
         1.4325, 1.4236, 1.4379, 1.4484, 1.4351, 1.4451, 1.4149, 1.4423, 1.4484],
        [1.3520, 1.2624, 1.2580, 1.2764, 1.2698, 1.2797, 1.2786, 1.2200, 1.2200,
         1.2705, 1.2258, 1.2243, 1.2315, 1.3141, 1.1818, 1.1431, 1.3141, 1.2113,
         1.6033, 1.5802, 1.5617, 1.5579, 1.5805, 1.5769, 1.5961, 1.5820, 1.5820,
         1.3608, 1.3342, 1.3351, 1.3507, 1.3365, 1.3774, 1.3801, 1.3549, 1.3352,
         1.5821, 1.5810, 1.5870, 1.5767, 1.5529, 1.5563, 1.6165, 1.5075, 1.4767,
         4.0179, 3.6157, 3.6981, 3.6842, 3.6943, 3.3940, 4.0103, 3.6618, 3.4246]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 195 : 1780.0373689510961
Test loss for epoch 195 : 194.54859216304578
Test Precision for epoch 195 : 0.26153846153846155
Test Recall for epoch 195 : 0.26153846153846155
Test F1 for epoch 195 : 0.26153846153846155


theta for epoch 196 : tensor([[3.6118, 3.6346, 3.7781, 3.7241, 3.7117, 3.5932, 3.6343, 3.5334, 3.5334,
         1.2744, 1.2503, 1.2488, 1.2536, 1.2965, 1.2315, 1.1968, 1.2965, 1.2373,
         1.5963, 1.5802, 1.6050, 1.5856, 1.5917, 1.5933, 1.6019, 1.5933, 1.5933,
         1.3385, 1.3495, 1.3337, 1.3577, 1.3370, 1.3703, 1.3625, 1.3484, 1.3337,
         1.5879, 1.6051, 1.5929, 1.5893, 1.5967, 1.5872, 1.6062, 1.5584, 1.5632,
         1.2453, 1.2737, 1.2650, 1.2835, 1.2397, 1.2308, 1.2208, 1.3070, 1.2614],
        [1.3722, 1.2222, 1.2122, 1.2545, 1.2549, 1.2670, 1.2610, 1.1670, 1.1670,
         3.6219, 3.6950, 3.5604, 3.8857, 3.6225, 4.1435, 3.5065, 3.5831, 3.9688,
         1.5713, 1.5593, 1.5337, 1.5323, 1.5529, 1.5623, 1.5866, 1.5623, 1.5623,
         1.3460, 1.3132, 1.3074, 1.3638, 1.3069, 1.4003, 1.3810, 1.3505, 1.3043,
         1.5387, 1.5938, 1.5580, 1.5451, 1.5400, 1.5771, 1.5965, 1.4323, 1.5296,
         1.1585, 1.2693, 1.2430, 1.2903, 1.1533, 1.1601, 1.0860, 1.3495, 1.2338],
        [1.4521, 1.4521, 1.4504, 1.4476, 1.4479, 1.4521, 1.4478, 1.4521, 1.4521,
         1.4435, 1.4428, 1.4435, 1.4434, 1.4435, 1.4246, 1.4435, 1.4423, 1.4400,
         2.2001, 2.2006, 2.2175, 2.1931, 2.1742, 2.1725, 2.2018, 2.1715, 2.1715,
         1.5069, 1.5053, 1.5128, 1.5128, 1.5069, 1.5128, 1.5127, 1.5128, 1.5128,
         1.7681, 1.7682, 1.7682, 1.7649, 1.7680, 1.7680, 1.7682, 1.7452, 1.7479,
         1.4406, 1.4453, 1.4453, 1.4453, 1.4369, 1.4453, 1.4412, 1.4453, 1.4453],
        [1.3204, 1.3184, 1.3025, 1.2938, 1.3174, 1.3158, 1.3169, 1.3173, 1.3173,
         1.3095, 1.3027, 1.2989, 1.2985, 1.3104, 1.2945, 1.3058, 1.3100, 1.2821,
         1.6423, 1.6158, 1.6392, 1.6387, 1.6381, 1.6381, 1.6404, 1.6418, 1.6418,
         3.4838, 3.2737, 3.1990, 3.2577, 3.4092, 3.2260, 3.4582, 3.2072, 3.1855,
         1.6415, 1.6340, 1.6323, 1.6354, 1.6384, 1.6144, 1.6398, 1.5790, 1.6056,
         1.3097, 1.3042, 1.2944, 1.3091, 1.3047, 1.2969, 1.3091, 1.3093, 1.3113],
        [1.4550, 1.4505, 1.4067, 1.4105, 1.4483, 1.4549, 1.4533, 1.4550, 1.4550,
         1.4452, 1.4425, 1.4375, 1.4323, 1.4463, 1.4050, 1.4404, 1.4463, 1.4412,
         1.7551, 1.7464, 1.7447, 1.7530, 1.7710, 1.7695, 1.7495, 1.7711, 1.7711,
         1.4736, 1.4783, 1.5155, 1.5102, 1.4789, 1.5140, 1.5024, 1.5156, 1.5125,
         2.1950, 2.1743, 2.1629, 2.1811, 2.2254, 2.2424, 2.2088, 2.3140, 2.3104,
         1.4323, 1.4234, 1.4377, 1.4481, 1.4349, 1.4448, 1.4147, 1.4420, 1.4482],
        [1.3531, 1.2629, 1.2586, 1.2770, 1.2704, 1.2803, 1.2792, 1.2202, 1.2202,
         1.2745, 1.2298, 1.2284, 1.2357, 1.3178, 1.1859, 1.1484, 1.3178, 1.2158,
         1.6085, 1.5853, 1.5668, 1.5630, 1.5856, 1.5820, 1.6013, 1.5871, 1.5871,
         1.3561, 1.3295, 1.3303, 1.3461, 1.3317, 1.3729, 1.3754, 1.3502, 1.3303,
         1.5811, 1.5801, 1.5861, 1.5758, 1.5521, 1.5555, 1.6156, 1.5066, 1.4759,
         4.0163, 3.6129, 3.6954, 3.6815, 3.6917, 3.3909, 4.0087, 3.6590, 3.4216]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 196 : 1780.085967075019
Test loss for epoch 196 : 194.60746635801112
Test Precision for epoch 196 : 0.26153846153846155
Test Recall for epoch 196 : 0.26153846153846155
Test F1 for epoch 196 : 0.26153846153846155


theta for epoch 197 : tensor([[3.6123, 3.6351, 3.7787, 3.7247, 3.7122, 3.5937, 3.6348, 3.5339, 3.5339,
         1.2685, 1.2445, 1.2430, 1.2477, 1.2905, 1.2257, 1.1914, 1.2905, 1.2316,
         1.6020, 1.5859, 1.6107, 1.5914, 1.5975, 1.5991, 1.6076, 1.5991, 1.5991,
         1.3337, 1.3447, 1.3291, 1.3528, 1.3323, 1.3653, 1.3575, 1.3436, 1.3292,
         1.5905, 1.6077, 1.5956, 1.5920, 1.5993, 1.5898, 1.6088, 1.5610, 1.5658,
         1.2482, 1.2764, 1.2678, 1.2862, 1.2426, 1.2337, 1.2238, 1.3096, 1.2642],
        [1.3677, 1.2177, 1.2077, 1.2501, 1.2504, 1.2626, 1.2565, 1.1625, 1.1625,
         3.6239, 3.6972, 3.5623, 3.8885, 3.6245, 4.1473, 3.5083, 3.5850, 3.9719,
         1.5727, 1.5607, 1.5351, 1.5336, 1.5543, 1.5637, 1.5881, 1.5638, 1.5638,
         1.3399, 1.3071, 1.3013, 1.3577, 1.3008, 1.3942, 1.3749, 1.3444, 1.2982,
         1.5383, 1.5935, 1.5576, 1.5446, 1.5396, 1.5768, 1.5962, 1.4316, 1.5292,
         1.1571, 1.2681, 1.2418, 1.2893, 1.1518, 1.1585, 1.0846, 1.3487, 1.2325],
        [1.4504, 1.4503, 1.4487, 1.4459, 1.4462, 1.4504, 1.4461, 1.4504, 1.4504,
         1.4378, 1.4371, 1.4378, 1.4377, 1.4378, 1.4189, 1.4378, 1.4366, 1.4343,
         2.2056, 2.2061, 2.2230, 2.1984, 2.1795, 2.1778, 2.2071, 2.1769, 2.1769,
         1.5028, 1.5012, 1.5086, 1.5086, 1.5028, 1.5086, 1.5086, 1.5086, 1.5086,
         1.7709, 1.7710, 1.7710, 1.7677, 1.7709, 1.7709, 1.7710, 1.7480, 1.7508,
         1.4438, 1.4485, 1.4485, 1.4485, 1.4401, 1.4485, 1.4444, 1.4485, 1.4485],
        [1.3183, 1.3164, 1.3004, 1.2917, 1.3153, 1.3137, 1.3148, 1.3153, 1.3153,
         1.3038, 1.2970, 1.2932, 1.2927, 1.3047, 1.2888, 1.3001, 1.3042, 1.2764,
         1.6482, 1.6217, 1.6451, 1.6446, 1.6440, 1.6440, 1.6463, 1.6477, 1.6477,
         3.4804, 3.2701, 3.1954, 3.2541, 3.4057, 3.2225, 3.4547, 3.2036, 3.1820,
         1.6443, 1.6368, 1.6351, 1.6382, 1.6412, 1.6172, 1.6426, 1.5819, 1.6084,
         1.3128, 1.3074, 1.2975, 1.3122, 1.3079, 1.3000, 1.3122, 1.3125, 1.3144],
        [1.4532, 1.4488, 1.4050, 1.4087, 1.4465, 1.4531, 1.4516, 1.4532, 1.4532,
         1.4395, 1.4368, 1.4318, 1.4267, 1.4406, 1.3993, 1.4347, 1.4406, 1.4355,
         1.7610, 1.7523, 1.7506, 1.7589, 1.7768, 1.7754, 1.7554, 1.7770, 1.7770,
         1.4694, 1.4742, 1.5114, 1.5060, 1.4747, 1.5099, 1.4983, 1.5114, 1.5083,
         2.1977, 2.1770, 2.1656, 2.1838, 2.2281, 2.2451, 2.2115, 2.3166, 2.3130,
         1.4355, 1.4266, 1.4409, 1.4513, 1.4381, 1.4480, 1.4179, 1.4452, 1.4513],
        [1.3521, 1.2614, 1.2571, 1.2756, 1.2690, 1.2790, 1.2778, 1.2184, 1.2184,
         1.2682, 1.2235, 1.2221, 1.2296, 1.3114, 1.1797, 1.1431, 1.3114, 1.2098,
         1.6132, 1.5899, 1.5714, 1.5675, 1.5902, 1.5866, 1.6060, 1.5917, 1.5917,
         1.3515, 1.3249, 1.3255, 1.3415, 1.3271, 1.3685, 1.3710, 1.3456, 1.3256,
         1.5830, 1.5820, 1.5880, 1.5777, 1.5539, 1.5573, 1.6175, 1.5083, 1.4776,
         4.0202, 3.6158, 3.6984, 3.6844, 3.6947, 3.3936, 4.0127, 3.6620, 3.4242]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 197 : 1779.8160472826694
Test loss for epoch 197 : 194.75036281473035
Test Precision for epoch 197 : 0.26153846153846155
Test Recall for epoch 197 : 0.26153846153846155
Test F1 for epoch 197 : 0.26153846153846155


theta for epoch 198 : tensor([[3.6174, 3.6403, 3.7839, 3.7299, 3.7173, 3.5989, 3.6400, 3.5392, 3.5392,
         1.2591, 1.2351, 1.2336, 1.2384, 1.2810, 1.2162, 1.1821, 1.2811, 1.2222,
         1.6010, 1.5849, 1.6097, 1.5905, 1.5965, 1.5982, 1.6066, 1.5982, 1.5982,
         1.3380, 1.3490, 1.3337, 1.3571, 1.3367, 1.3693, 1.3617, 1.3479, 1.3338,
         1.5945, 1.6117, 1.5996, 1.5960, 1.6033, 1.5938, 1.6128, 1.5650, 1.5698,
         1.2496, 1.2777, 1.2691, 1.2875, 1.2441, 1.2352, 1.2253, 1.3109, 1.2656],
        [1.3614, 1.2107, 1.2007, 1.2432, 1.2436, 1.2558, 1.2497, 1.1553, 1.1553,
         3.6300, 3.7035, 3.5682, 3.8954, 3.6305, 4.1553, 3.5141, 3.5909, 3.9792,
         1.5659, 1.5538, 1.5281, 1.5266, 1.5474, 1.5568, 1.5813, 1.5568, 1.5568,
         1.3356, 1.3027, 1.2968, 1.3535, 1.2963, 1.3903, 1.3708, 1.3401, 1.2936,
         1.5361, 1.5916, 1.5555, 1.5425, 1.5374, 1.5748, 1.5943, 1.4290, 1.5269,
         1.1510, 1.2627, 1.2362, 1.2840, 1.1457, 1.1524, 1.0785, 1.3438, 1.2268],
        [1.4532, 1.4532, 1.4515, 1.4487, 1.4490, 1.4532, 1.4489, 1.4532, 1.4532,
         1.4290, 1.4283, 1.4290, 1.4290, 1.4290, 1.4101, 1.4290, 1.4278, 1.4255,
         2.2053, 2.2058, 2.2227, 2.1981, 2.1792, 2.1775, 2.2068, 2.1765, 2.1765,
         1.5082, 1.5067, 1.5141, 1.5141, 1.5083, 1.5141, 1.5141, 1.5141, 1.5141,
         1.7754, 1.7755, 1.7754, 1.7722, 1.7753, 1.7753, 1.7754, 1.7525, 1.7553,
         1.4460, 1.4507, 1.4507, 1.4507, 1.4423, 1.4507, 1.4466, 1.4507, 1.4507],
        [1.3209, 1.3190, 1.3030, 1.2943, 1.3180, 1.3163, 1.3175, 1.3180, 1.3180,
         1.2950, 1.2882, 1.2844, 1.2839, 1.2958, 1.2800, 1.2913, 1.2954, 1.2675,
         1.6479, 1.6214, 1.6448, 1.6442, 1.6436, 1.6437, 1.6459, 1.6474, 1.6474,
         3.4851, 3.2749, 3.2002, 3.2589, 3.4104, 3.2272, 3.4595, 3.2084, 3.1868,
         1.6488, 1.6413, 1.6396, 1.6427, 1.6457, 1.6217, 1.6471, 1.5864, 1.6129,
         1.3150, 1.3095, 1.2996, 1.3144, 1.3100, 1.3022, 1.3144, 1.3146, 1.3166],
        [1.4561, 1.4516, 1.4079, 1.4115, 1.4494, 1.4560, 1.4544, 1.4560, 1.4560,
         1.4307, 1.4281, 1.4230, 1.4179, 1.4319, 1.3905, 1.4259, 1.4319, 1.4267,
         1.7607, 1.7520, 1.7503, 1.7586, 1.7765, 1.7751, 1.7551, 1.7767, 1.7767,
         1.4749, 1.4797, 1.5169, 1.5115, 1.4803, 1.5154, 1.5037, 1.5169, 1.5138,
         2.2020, 2.1814, 2.1699, 2.1881, 2.2324, 2.2494, 2.2158, 2.3209, 2.3173,
         1.4378, 1.4288, 1.4431, 1.4535, 1.4404, 1.4502, 1.4202, 1.4474, 1.4536],
        [1.3516, 1.2604, 1.2560, 1.2747, 1.2680, 1.2781, 1.2769, 1.2172, 1.2172,
         1.2576, 1.2127, 1.2113, 1.2189, 1.3007, 1.1688, 1.1327, 1.3007, 1.1991,
         1.6102, 1.5869, 1.5684, 1.5645, 1.5872, 1.5836, 1.6030, 1.5887, 1.5887,
         1.3528, 1.3260, 1.3267, 1.3428, 1.3282, 1.3699, 1.3723, 1.3468, 1.3267,
         1.5850, 1.5840, 1.5901, 1.5797, 1.5559, 1.5593, 1.6197, 1.5102, 1.4794,
         4.0275, 3.6219, 3.7047, 3.6907, 3.7011, 3.3995, 4.0201, 3.6682, 3.4302]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 198 : 1779.341388339392
Test loss for epoch 198 : 194.96103417702778
Test Precision for epoch 198 : 0.26153846153846155
Test Recall for epoch 198 : 0.26153846153846155
Test F1 for epoch 198 : 0.26153846153846155


theta for epoch 199 : tensor([[3.6251, 3.6481, 3.7917, 3.7377, 3.7251, 3.6067, 3.6478, 3.5472, 3.5472,
         1.2532, 1.2291, 1.2276, 1.2324, 1.2752, 1.2102, 1.1760, 1.2752, 1.2162,
         1.5964, 1.5803, 1.6050, 1.5860, 1.5920, 1.5937, 1.6020, 1.5937, 1.5937,
         1.3451, 1.3562, 1.3412, 1.3642, 1.3440, 1.3762, 1.3687, 1.3551, 1.3412,
         1.5965, 1.6136, 1.6016, 1.5980, 1.6053, 1.5957, 1.6147, 1.5669, 1.5718,
         1.2471, 1.2751, 1.2665, 1.2848, 1.2416, 1.2327, 1.2229, 1.3081, 1.2630],
        [1.3517, 1.2001, 1.1901, 1.2328, 1.2331, 1.2454, 1.2393, 1.1442, 1.1442,
         3.6418, 3.7156, 3.5799, 3.9081, 3.6424, 4.1690, 3.5257, 3.6027, 3.9922,
         1.5536, 1.5414, 1.5157, 1.5140, 1.5349, 1.5444, 1.5691, 1.5444, 1.5444,
         1.3299, 1.2967, 1.2906, 1.3479, 1.2902, 1.3850, 1.3654, 1.3344, 1.2874,
         1.5295, 1.5855, 1.5491, 1.5359, 1.5309, 1.5685, 1.5882, 1.4218, 1.5203,
         1.1391, 1.2515, 1.2248, 1.2730, 1.1336, 1.1402, 1.0664, 1.3334, 1.2153],
        [1.4569, 1.4569, 1.4553, 1.4524, 1.4528, 1.4569, 1.4526, 1.4569, 1.4569,
         1.4241, 1.4233, 1.4240, 1.4240, 1.4241, 1.4051, 1.4240, 1.4228, 1.4206,
         2.2020, 2.2025, 2.2194, 2.1950, 2.1761, 2.1744, 2.2036, 2.1734, 2.1734,
         1.5171, 1.5155, 1.5230, 1.5230, 1.5171, 1.5230, 1.5230, 1.5230, 1.5230,
         1.7781, 1.7782, 1.7782, 1.7750, 1.7781, 1.7781, 1.7782, 1.7553, 1.7580,
         1.4446, 1.4493, 1.4493, 1.4493, 1.4409, 1.4493, 1.4452, 1.4493, 1.4493],
        [1.3243, 1.3225, 1.3065, 1.2978, 1.3215, 1.3198, 1.3210, 1.3215, 1.3215,
         1.2900, 1.2832, 1.2793, 1.2789, 1.2908, 1.2749, 1.2862, 1.2904, 1.2625,
         1.6443, 1.6178, 1.6412, 1.6407, 1.6401, 1.6401, 1.6423, 1.6438, 1.6438,
         3.4929, 3.2828, 3.2082, 3.2668, 3.4182, 3.2351, 3.4672, 3.2163, 3.1948,
         1.6515, 1.6440, 1.6422, 1.6454, 1.6484, 1.6244, 1.6498, 1.5891, 1.6156,
         1.3135, 1.3080, 1.2981, 1.3128, 1.3085, 1.3007, 1.3129, 1.3131, 1.3151],
        [1.4598, 1.4554, 1.4117, 1.4153, 1.4531, 1.4597, 1.4582, 1.4598, 1.4598,
         1.4258, 1.4231, 1.4181, 1.4129, 1.4269, 1.3856, 1.4210, 1.4269, 1.4218,
         1.7573, 1.7486, 1.7469, 1.7552, 1.7731, 1.7717, 1.7517, 1.7733, 1.7733,
         1.4838, 1.4887, 1.5257, 1.5204, 1.4892, 1.5243, 1.5126, 1.5258, 1.5227,
         2.2046, 2.1840, 2.1725, 2.1907, 2.2350, 2.2520, 2.2184, 2.3234, 2.3199,
         1.4364, 1.4274, 1.4417, 1.4521, 1.4390, 1.4489, 1.4188, 1.4460, 1.4522],
        [1.3490, 1.2575, 1.2530, 1.2718, 1.2651, 1.2752, 1.2740, 1.2141, 1.2141,
         1.2493, 1.2041, 1.2027, 1.2104, 1.2925, 1.1600, 1.1239, 1.2925, 1.1905,
         1.6028, 1.5794, 1.5609, 1.5569, 1.5797, 1.5761, 1.5956, 1.5813, 1.5813,
         1.3548, 1.3279, 1.3286, 1.3447, 1.3301, 1.3720, 1.3744, 1.3488, 1.3286,
         1.5842, 1.5831, 1.5892, 1.5788, 1.5549, 1.5583, 1.6188, 1.5090, 1.4782,
         4.0366, 3.6300, 3.7129, 3.6988, 3.7093, 3.4073, 4.0292, 3.6763, 3.4380]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 199 : 1778.8626268204118
Test loss for epoch 199 : 195.42365107048778
Test Precision for epoch 199 : 0.26153846153846155
Test Recall for epoch 199 : 0.26153846153846155
Test F1 for epoch 199 : 0.26153846153846155


theta for epoch 200 : tensor([[3.6266, 3.6497, 3.7933, 3.7393, 3.7266, 3.6083, 3.6494, 3.5488, 3.5488,
         1.2535, 1.2296, 1.2282, 1.2329, 1.2752, 1.2108, 1.1773, 1.2752, 1.2169,
         1.5966, 1.5806, 1.6052, 1.5864, 1.5924, 1.5941, 1.6022, 1.5940, 1.5940,
         1.3455, 1.3566, 1.3420, 1.3645, 1.3446, 1.3763, 1.3689, 1.3556, 1.3420,
         1.5966, 1.6136, 1.6016, 1.5980, 1.6053, 1.5957, 1.6146, 1.5670, 1.5718,
         1.2443, 1.2721, 1.2636, 1.2817, 1.2389, 1.2301, 1.2203, 1.3048, 1.2601],
        [1.3590, 1.2071, 1.1972, 1.2399, 1.2402, 1.2525, 1.2464, 1.1511, 1.1511,
         3.6357, 3.7097, 3.5737, 3.9029, 3.6363, 4.1647, 3.5193, 3.5965, 3.9872,
         1.5579, 1.5456, 1.5200, 1.5182, 1.5390, 1.5485, 1.5733, 1.5485, 1.5485,
         1.3354, 1.3023, 1.2960, 1.3535, 1.2957, 1.3907, 1.3710, 1.3399, 1.2928,
         1.5331, 1.5890, 1.5526, 1.5395, 1.5345, 1.5721, 1.5918, 1.4256, 1.5240,
         1.1409, 1.2535, 1.2266, 1.2750, 1.1353, 1.1417, 1.0683, 1.3357, 1.2171],
        [1.4578, 1.4577, 1.4561, 1.4533, 1.4536, 1.4578, 1.4534, 1.4578, 1.4578,
         1.4246, 1.4239, 1.4246, 1.4246, 1.4246, 1.4057, 1.4246, 1.4234, 1.4211,
         2.2024, 2.2028, 2.2198, 2.1953, 2.1764, 2.1747, 2.2040, 2.1737, 2.1737,
         1.5180, 1.5164, 1.5238, 1.5238, 1.5180, 1.5238, 1.5238, 1.5238, 1.5238,
         1.7782, 1.7783, 1.7783, 1.7751, 1.7782, 1.7782, 1.7783, 1.7554, 1.7581,
         1.4419, 1.4466, 1.4466, 1.4466, 1.4382, 1.4466, 1.4425, 1.4465, 1.4466],
        [1.3249, 1.3231, 1.3072, 1.2984, 1.3221, 1.3204, 1.3216, 1.3222, 1.3222,
         1.2905, 1.2837, 1.2798, 1.2794, 1.2913, 1.2754, 1.2868, 1.2909, 1.2630,
         1.6446, 1.6181, 1.6415, 1.6410, 1.6404, 1.6404, 1.6427, 1.6441, 1.6441,
         3.4939, 3.2838, 3.2092, 3.2678, 3.4192, 3.2361, 3.4682, 3.2174, 3.1958,
         1.6515, 1.6441, 1.6423, 1.6455, 1.6484, 1.6245, 1.6498, 1.5892, 1.6157,
         1.3106, 1.3051, 1.2953, 1.3100, 1.3056, 1.2978, 1.3100, 1.3102, 1.3122],
        [1.4606, 1.4563, 1.4125, 1.4161, 1.4539, 1.4605, 1.4590, 1.4606, 1.4606,
         1.4263, 1.4237, 1.4186, 1.4135, 1.4275, 1.3862, 1.4215, 1.4275, 1.4223,
         1.7577, 1.7490, 1.7473, 1.7556, 1.7735, 1.7721, 1.7521, 1.7737, 1.7737,
         1.4847, 1.4896, 1.5266, 1.5213, 1.4900, 1.5251, 1.5135, 1.5266, 1.5235,
         2.2047, 2.1841, 2.1726, 2.1908, 2.2351, 2.2521, 2.2185, 2.3235, 2.3199,
         1.4337, 1.4247, 1.4390, 1.4494, 1.4363, 1.4461, 1.4161, 1.4433, 1.4494],
        [1.3453, 1.2540, 1.2494, 1.2683, 1.2615, 1.2717, 1.2705, 1.2107, 1.2107,
         1.2468, 1.2019, 1.2006, 1.2082, 1.2897, 1.1578, 1.1227, 1.2897, 1.1885,
         1.6000, 1.5766, 1.5579, 1.5540, 1.5769, 1.5733, 1.5927, 1.5784, 1.5784,
         1.3511, 1.3242, 1.3250, 1.3410, 1.3264, 1.3683, 1.3708, 1.3452, 1.3250,
         1.5816, 1.5804, 1.5866, 1.5762, 1.5522, 1.5556, 1.6162, 1.5062, 1.4753,
         4.0433, 3.6355, 3.7185, 3.7045, 3.7150, 3.4127, 4.0359, 3.6819, 3.4434]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 200 : 1779.0682129047814
Test loss for epoch 200 : 195.23389464336103
Test Precision for epoch 200 : 0.26153846153846155
Test Recall for epoch 200 : 0.26153846153846155
Test F1 for epoch 200 : 0.26153846153846155


theta for epoch 201 : tensor([[3.6214, 3.6443, 3.7880, 3.7340, 3.7213, 3.6030, 3.6441, 3.5434, 3.5434,
         1.2603, 1.2370, 1.2356, 1.2401, 1.2813, 1.2182, 1.1860, 1.2813, 1.2244,
         1.6009, 1.5849, 1.6095, 1.5909, 1.5969, 1.5985, 1.6065, 1.5985, 1.5985,
         1.3382, 1.3494, 1.3352, 1.3572, 1.3375, 1.3688, 1.3615, 1.3484, 1.3352,
         1.5949, 1.6119, 1.6000, 1.5964, 1.6036, 1.5940, 1.6129, 1.5653, 1.5702,
         1.2425, 1.2699, 1.2616, 1.2795, 1.2371, 1.2284, 1.2186, 1.3024, 1.2582],
        [1.3747, 1.2233, 1.2134, 1.2559, 1.2563, 1.2685, 1.2624, 1.1673, 1.1673,
         3.6193, 3.6935, 3.5571, 3.8872, 3.6199, 4.1501, 3.5025, 3.5800, 3.9719,
         1.5730, 1.5608, 1.5354, 1.5335, 1.5542, 1.5636, 1.5883, 1.5636, 1.5636,
         1.3458, 1.3128, 1.3063, 1.3637, 1.3062, 1.4008, 1.3812, 1.3502, 1.3032,
         1.5424, 1.5981, 1.5618, 1.5488, 1.5439, 1.5813, 1.6009, 1.4358, 1.5334,
         1.1518, 1.2642, 1.2373, 1.2858, 1.1461, 1.1522, 1.0795, 1.3466, 1.2277],
        [1.4532, 1.4532, 1.4515, 1.4487, 1.4491, 1.4532, 1.4489, 1.4532, 1.4532,
         1.4310, 1.4303, 1.4310, 1.4310, 1.4310, 1.4121, 1.4310, 1.4298, 1.4275,
         2.2058, 2.2063, 2.2232, 2.1986, 2.1797, 2.1780, 2.2073, 2.1771, 2.1771,
         1.5102, 1.5086, 1.5160, 1.5160, 1.5102, 1.5160, 1.5160, 1.5160, 1.5160,
         1.7760, 1.7761, 1.7761, 1.7729, 1.7760, 1.7760, 1.7761, 1.7532, 1.7560,
         1.4392, 1.4439, 1.4439, 1.4439, 1.4355, 1.4439, 1.4398, 1.4439, 1.4439],
        [1.3200, 1.3183, 1.3023, 1.2935, 1.3172, 1.3156, 1.3167, 1.3174, 1.3174,
         1.2968, 1.2901, 1.2862, 1.2858, 1.2976, 1.2818, 1.2932, 1.2972, 1.2694,
         1.6482, 1.6218, 1.6452, 1.6446, 1.6440, 1.6441, 1.6463, 1.6477, 1.6477,
         3.4876, 3.2774, 3.2028, 3.2614, 3.4128, 3.2298, 3.4619, 3.2109, 3.1894,
         1.6493, 1.6418, 1.6401, 1.6432, 1.6462, 1.6222, 1.6476, 1.5869, 1.6134,
         1.3078, 1.3023, 1.2925, 1.3072, 1.3029, 1.2950, 1.3072, 1.3074, 1.3094],
        [1.4561, 1.4517, 1.4080, 1.4115, 1.4494, 1.4560, 1.4545, 1.4561, 1.4561,
         1.4327, 1.4301, 1.4250, 1.4199, 1.4339, 1.3926, 1.4279, 1.4338, 1.4287,
         1.7613, 1.7526, 1.7510, 1.7593, 1.7772, 1.7757, 1.7558, 1.7773, 1.7773,
         1.4768, 1.4818, 1.5188, 1.5135, 1.4822, 1.5173, 1.5057, 1.5188, 1.5157,
         2.2025, 2.1819, 2.1705, 2.1886, 2.2330, 2.2500, 2.2163, 2.3213, 2.3178,
         1.4311, 1.4220, 1.4363, 1.4467, 1.4336, 1.4434, 1.4135, 1.4406, 1.4467],
        [1.3387, 1.2477, 1.2430, 1.2619, 1.2551, 1.2654, 1.2642, 1.2048, 1.2048,
         1.2506, 1.2065, 1.2052, 1.2125, 1.2926, 1.1623, 1.1291, 1.2926, 1.1933,
         1.6011, 1.5776, 1.5589, 1.5551, 1.5781, 1.5744, 1.5938, 1.5796, 1.5796,
         1.3412, 1.3143, 1.3151, 1.3311, 1.3165, 1.3583, 1.3608, 1.3353, 1.3152,
         1.5774, 1.5762, 1.5825, 1.5721, 1.5480, 1.5514, 1.6120, 1.5019, 1.4709,
         4.0482, 3.6393, 3.7225, 3.7084, 3.7191, 3.4164, 4.0409, 3.6858, 3.4470]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 201 : 1779.4928669851981
Test loss for epoch 201 : 194.96733991332027
Test Precision for epoch 201 : 0.26153846153846155
Test Recall for epoch 201 : 0.26153846153846155
Test F1 for epoch 201 : 0.26153846153846155


theta for epoch 202 : tensor([[3.6181, 3.6409, 3.7847, 3.7307, 3.7179, 3.5996, 3.6408, 3.5400, 3.5400,
         1.2701, 1.2473, 1.2459, 1.2503, 1.2906, 1.2285, 1.1974, 1.2906, 1.2348,
         1.6009, 1.5850, 1.6095, 1.5910, 1.5970, 1.5987, 1.6066, 1.5987, 1.5987,
         1.3330, 1.3442, 1.3303, 1.3519, 1.3324, 1.3632, 1.3561, 1.3432, 1.3303,
         1.5914, 1.6083, 1.5964, 1.5928, 1.6000, 1.5904, 1.6092, 1.5618, 1.5666,
         1.2388, 1.2661, 1.2578, 1.2757, 1.2335, 1.2249, 1.2151, 1.2984, 1.2544],
        [1.3829, 1.2319, 1.2220, 1.2644, 1.2648, 1.2770, 1.2709, 1.1761, 1.1761,
         3.6116, 3.6860, 3.5493, 3.8803, 3.6123, 4.1442, 3.4944, 3.5723, 3.9653,
         1.5801, 1.5679, 1.5427, 1.5406, 1.5612, 1.5706, 1.5953, 1.5706, 1.5706,
         1.3514, 1.3186, 1.3120, 1.3694, 1.3120, 1.4064, 1.3868, 1.3558, 1.3088,
         1.5457, 1.6012, 1.5650, 1.5521, 1.5472, 1.5845, 1.6040, 1.4396, 1.5368,
         1.1560, 1.2684, 1.2414, 1.2901, 1.1501, 1.1560, 1.0839, 1.3512, 1.2318],
        [1.4482, 1.4481, 1.4465, 1.4437, 1.4440, 1.4482, 1.4438, 1.4482, 1.4482,
         1.4407, 1.4400, 1.4407, 1.4406, 1.4407, 1.4218, 1.4407, 1.4395, 1.4372,
         2.2057, 2.2061, 2.2231, 2.1985, 2.1796, 2.1779, 2.2071, 2.1769, 2.1769,
         1.5049, 1.5033, 1.5108, 1.5108, 1.5050, 1.5108, 1.5108, 1.5108, 1.5108,
         1.7723, 1.7724, 1.7724, 1.7692, 1.7723, 1.7723, 1.7724, 1.7495, 1.7522,
         1.4354, 1.4401, 1.4401, 1.4401, 1.4317, 1.4401, 1.4360, 1.4400, 1.4401],
        [1.3146, 1.3130, 1.2970, 1.2882, 1.3119, 1.3102, 1.3114, 1.3121, 1.3121,
         1.3065, 1.2997, 1.2959, 1.2954, 1.3072, 1.2915, 1.3029, 1.3068, 1.2791,
         1.6480, 1.6216, 1.6449, 1.6444, 1.6438, 1.6438, 1.6461, 1.6475, 1.6475,
         3.4835, 3.2734, 3.1987, 3.2573, 3.4088, 3.2257, 3.4579, 3.2069, 3.1853,
         1.6455, 1.6380, 1.6363, 1.6394, 1.6424, 1.6184, 1.6438, 1.5831, 1.6096,
         1.3039, 1.2984, 1.2885, 1.3032, 1.2989, 1.2911, 1.3033, 1.3034, 1.3055],
        [1.4511, 1.4467, 1.4029, 1.4064, 1.4443, 1.4509, 1.4494, 1.4510, 1.4510,
         1.4424, 1.4397, 1.4347, 1.4296, 1.4435, 1.4024, 1.4376, 1.4435, 1.4384,
         1.7612, 1.7525, 1.7509, 1.7592, 1.7770, 1.7756, 1.7557, 1.7772, 1.7772,
         1.4715, 1.4766, 1.5135, 1.5083, 1.4769, 1.5121, 1.5004, 1.5136, 1.5105,
         2.1989, 2.1783, 2.1669, 2.1850, 2.2293, 2.2464, 2.2127, 2.3177, 2.3142,
         1.4273, 1.4182, 1.4325, 1.4429, 1.4298, 1.4396, 1.4097, 1.4368, 1.4429],
        [1.3300, 1.2388, 1.2341, 1.2531, 1.2462, 1.2565, 1.2553, 1.1958, 1.1958,
         1.2566, 1.2129, 1.2116, 1.2188, 1.2980, 1.1684, 1.1364, 1.2980, 1.1998,
         1.5973, 1.5738, 1.5551, 1.5512, 1.5743, 1.5706, 1.5901, 1.5758, 1.5758,
         1.3319, 1.3049, 1.3058, 1.3218, 1.3072, 1.3491, 1.3516, 1.3260, 1.3058,
         1.5706, 1.5694, 1.5757, 1.5653, 1.5412, 1.5446, 1.6053, 1.4950, 1.4639,
         4.0555, 3.6455, 3.7289, 3.7147, 3.7255, 3.4224, 4.0483, 3.6920, 3.4531]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 202 : 1779.7989037647853
Test loss for epoch 202 : 195.15220776095026
Test Precision for epoch 202 : 0.26153846153846155
Test Recall for epoch 202 : 0.26153846153846155
Test F1 for epoch 202 : 0.26153846153846155


theta for epoch 203 : tensor([[3.6206, 3.6435, 3.7872, 3.7333, 3.7204, 3.6022, 3.6433, 3.5426, 3.5426,
         1.2756, 1.2533, 1.2519, 1.2561, 1.2957, 1.2345, 1.2043, 1.2957, 1.2409,
         1.5954, 1.5796, 1.6040, 1.5858, 1.5917, 1.5934, 1.6011, 1.5934, 1.5934,
         1.3355, 1.3468, 1.3332, 1.3544, 1.3351, 1.3655, 1.3585, 1.3458, 1.3332,
         1.5889, 1.6056, 1.5939, 1.5903, 1.5974, 1.5878, 1.6065, 1.5592, 1.5640,
         1.2339, 1.2611, 1.2528, 1.2706, 1.2285, 1.2199, 1.2101, 1.2933, 1.2494],
        [1.3876, 1.2370, 1.2271, 1.2695, 1.2699, 1.2821, 1.2760, 1.1814, 1.1814,
         3.6097, 3.6842, 3.5472, 3.8791, 3.6103, 4.1440, 3.4921, 3.5702, 3.9644,
         1.5786, 1.5664, 1.5413, 1.5392, 1.5598, 1.5691, 1.5938, 1.5692, 1.5692,
         1.3563, 1.3235, 1.3169, 1.3743, 1.3169, 1.4113, 1.3917, 1.3607, 1.3138,
         1.5458, 1.6012, 1.5651, 1.5522, 1.5473, 1.5845, 1.6040, 1.4399, 1.5369,
         1.1542, 1.2669, 1.2398, 1.2887, 1.1482, 1.1538, 1.0822, 1.3501, 1.2301],
        [1.4496, 1.4495, 1.4479, 1.4451, 1.4454, 1.4496, 1.4452, 1.4496, 1.4496,
         1.4464, 1.4457, 1.4464, 1.4464, 1.4464, 1.4276, 1.4464, 1.4452, 1.4430,
         2.2009, 2.2014, 2.2183, 2.1939, 2.1750, 2.1733, 2.2026, 2.1723, 2.1723,
         1.5080, 1.5064, 1.5139, 1.5139, 1.5080, 1.5139, 1.5138, 1.5139, 1.5139,
         1.7699, 1.7700, 1.7700, 1.7668, 1.7699, 1.7699, 1.7700, 1.7471, 1.7499,
         1.4310, 1.4357, 1.4357, 1.4357, 1.4273, 1.4357, 1.4316, 1.4357, 1.4357],
        [1.3158, 1.3142, 1.2983, 1.2894, 1.3132, 1.3115, 1.3126, 1.3134, 1.3134,
         1.3121, 1.3054, 1.3016, 1.3011, 1.3129, 1.2972, 1.3087, 1.3125, 1.2848,
         1.6428, 1.6164, 1.6397, 1.6392, 1.6386, 1.6386, 1.6409, 1.6423, 1.6423,
         3.4867, 3.2766, 3.2019, 3.2605, 3.4119, 3.2289, 3.4611, 3.2101, 3.1885,
         1.6430, 1.6355, 1.6338, 1.6370, 1.6399, 1.6160, 1.6413, 1.5807, 1.6072,
         1.2993, 1.2938, 1.2840, 1.2987, 1.2944, 1.2866, 1.2988, 1.2989, 1.3009],
        [1.4525, 1.4481, 1.4044, 1.4078, 1.4457, 1.4523, 1.4508, 1.4524, 1.4524,
         1.4481, 1.4455, 1.4405, 1.4354, 1.4493, 1.4082, 1.4433, 1.4492, 1.4442,
         1.7562, 1.7475, 1.7459, 1.7542, 1.7720, 1.7706, 1.7506, 1.7722, 1.7722,
         1.4746, 1.4798, 1.5166, 1.5114, 1.4800, 1.5152, 1.5035, 1.5167, 1.5135,
         2.1965, 2.1760, 2.1645, 2.1826, 2.2270, 2.2441, 2.2104, 2.3153, 2.3118,
         1.4229, 1.4138, 1.4281, 1.4385, 1.4255, 1.4352, 1.4054, 1.4324, 1.4385],
        [1.3256, 1.2332, 1.2285, 1.2476, 1.2408, 1.2512, 1.2499, 1.1896, 1.1896,
         1.2582, 1.2148, 1.2135, 1.2205, 1.2994, 1.1700, 1.1384, 1.2994, 1.2015,
         1.5880, 1.5644, 1.5457, 1.5416, 1.5648, 1.5611, 1.5807, 1.5663, 1.5663,
         1.3287, 1.3015, 1.3022, 1.3186, 1.3038, 1.3463, 1.3486, 1.3228, 1.3022,
         1.5642, 1.5631, 1.5694, 1.5589, 1.5348, 1.5382, 1.5992, 1.4883, 1.4572,
         4.0648, 3.6537, 3.7372, 3.7230, 3.7339, 3.4304, 4.0577, 3.7002, 3.4610]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 203 : 1779.8969793606689
Test loss for epoch 203 : 195.44003077278416
Test Precision for epoch 203 : 0.26153846153846155
Test Recall for epoch 203 : 0.26153846153846155
Test F1 for epoch 203 : 0.26153846153846155


theta for epoch 204 : tensor([[3.6272, 3.6501, 3.7939, 3.7399, 3.7270, 3.6089, 3.6500, 3.5494, 3.5494,
         1.2722, 1.2502, 1.2489, 1.2529, 1.2918, 1.2314, 1.2021, 1.2918, 1.2379,
         1.5922, 1.5764, 1.6007, 1.5827, 1.5887, 1.5903, 1.5979, 1.5903, 1.5903,
         1.3411, 1.3524, 1.3391, 1.3599, 1.3408, 1.3708, 1.3639, 1.3514, 1.3391,
         1.5897, 1.6064, 1.5947, 1.5911, 1.5982, 1.5885, 1.6072, 1.5601, 1.5649,
         1.2304, 1.2576, 1.2493, 1.2672, 1.2250, 1.2164, 1.2066, 1.2899, 1.2459],
        [1.3876, 1.2377, 1.2276, 1.2701, 1.2704, 1.2826, 1.2766, 1.1825, 1.1825,
         3.6112, 3.6859, 3.5485, 3.8814, 3.6118, 4.1473, 3.4934, 3.5717, 3.9670,
         1.5747, 1.5626, 1.5374, 1.5355, 1.5561, 1.5654, 1.5899, 1.5655, 1.5655,
         1.3580, 1.3252, 1.3188, 1.3760, 1.3186, 1.4129, 1.3934, 1.3625, 1.3156,
         1.5452, 1.6006, 1.5645, 1.5515, 1.5467, 1.5838, 1.6033, 1.4392, 1.5363,
         1.1490, 1.2621, 1.2348, 1.2840, 1.1428, 1.1482, 1.0768, 1.3459, 1.2250],
        [1.4542, 1.4542, 1.4525, 1.4497, 1.4501, 1.4542, 1.4499, 1.4542, 1.4542,
         1.4434, 1.4427, 1.4434, 1.4433, 1.4434, 1.4245, 1.4434, 1.4422, 1.4399,
         2.1986, 2.1990, 2.2159, 2.1916, 2.1728, 2.1711, 2.2003, 2.1701, 2.1701,
         1.5147, 1.5131, 1.5205, 1.5205, 1.5147, 1.5205, 1.5205, 1.5205, 1.5205,
         1.7712, 1.7713, 1.7713, 1.7681, 1.7712, 1.7712, 1.7713, 1.7484, 1.7512,
         1.4289, 1.4335, 1.4335, 1.4335, 1.4252, 1.4335, 1.4295, 1.4335, 1.4335],
        [1.3203, 1.3188, 1.3028, 1.2940, 1.3177, 1.3160, 1.3172, 1.3179, 1.3179,
         1.3090, 1.3023, 1.2985, 1.2980, 1.3097, 1.2941, 1.3056, 1.3093, 1.2817,
         1.6402, 1.6138, 1.6371, 1.6366, 1.6360, 1.6360, 1.6383, 1.6397, 1.6397,
         3.4929, 3.2829, 3.2084, 3.2669, 3.4182, 3.2353, 3.4674, 3.2165, 3.1950,
         1.6442, 1.6368, 1.6350, 1.6382, 1.6411, 1.6172, 1.6425, 1.5819, 1.6084,
         1.2970, 1.2915, 1.2817, 1.2963, 1.2920, 1.2842, 1.2964, 1.2966, 1.2986],
        [1.4571, 1.4528, 1.4091, 1.4125, 1.4504, 1.4570, 1.4555, 1.4570, 1.4570,
         1.4451, 1.4424, 1.4374, 1.4324, 1.4462, 1.4052, 1.4403, 1.4462, 1.4412,
         1.7538, 1.7450, 1.7435, 1.7518, 1.7696, 1.7681, 1.7482, 1.7697, 1.7697,
         1.4813, 1.4865, 1.5233, 1.5180, 1.4867, 1.5219, 1.5101, 1.5233, 1.5202,
         2.1977, 2.1772, 2.1658, 2.1839, 2.2281, 2.2453, 2.2116, 2.3164, 2.3129,
         1.4208, 1.4117, 1.4260, 1.4363, 1.4233, 1.4331, 1.4033, 1.4303, 1.4364],
        [1.3233, 1.2287, 1.2242, 1.2436, 1.2367, 1.2472, 1.2459, 1.1841, 1.1841,
         1.2513, 1.2077, 1.2065, 1.2133, 1.2924, 1.1626, 1.1309, 1.2924, 1.1943,
         1.5805, 1.5566, 1.5381, 1.5335, 1.5569, 1.5531, 1.5731, 1.5584, 1.5584,
         1.3279, 1.3005, 1.3007, 1.3178, 1.3025, 1.3460, 1.3482, 1.3219, 1.3007,
         1.5607, 1.5598, 1.5658, 1.5553, 1.5312, 1.5348, 1.5960, 1.4845, 1.4533,
         4.0768, 3.6646, 3.7482, 3.7339, 3.7450, 3.4411, 4.0698, 3.7111, 3.4717]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 204 : 1779.6529879789173
Test loss for epoch 204 : 195.7888864943891
Test Precision for epoch 204 : 0.26153846153846155
Test Recall for epoch 204 : 0.26153846153846155
Test F1 for epoch 204 : 0.26153846153846155


theta for epoch 205 : tensor([[3.6334, 3.6564, 3.8002, 3.7462, 3.7332, 3.6152, 3.6563, 3.5558, 3.5558,
         1.2646, 1.2431, 1.2417, 1.2456, 1.2838, 1.2242, 1.1957, 1.2838, 1.2308,
         1.5949, 1.5792, 1.6035, 1.5857, 1.5916, 1.5932, 1.6007, 1.5932, 1.5932,
         1.3402, 1.3516, 1.3385, 1.3591, 1.3401, 1.3698, 1.3630, 1.3506, 1.3386,
         1.5935, 1.6101, 1.5986, 1.5950, 1.6020, 1.5923, 1.6109, 1.5639, 1.5687,
         1.2291, 1.2565, 1.2481, 1.2661, 1.2236, 1.2149, 1.2051, 1.2890, 1.2447],
        [1.3790, 1.2304, 1.2201, 1.2626, 1.2629, 1.2751, 1.2691, 1.1759, 1.1759,
         3.6173, 3.6922, 3.5545, 3.8883, 3.6179, 4.1552, 3.4992, 3.5777, 3.9742,
         1.5718, 1.5597, 1.5343, 1.5327, 1.5534, 1.5627, 1.5871, 1.5628, 1.5628,
         1.3514, 1.3185, 1.3125, 1.3694, 1.3120, 1.4061, 1.3867, 1.3559, 1.3093,
         1.5439, 1.5993, 1.5633, 1.5502, 1.5453, 1.5825, 1.6019, 1.4374, 1.5349,
         1.1412, 1.2549, 1.2274, 1.2770, 1.1349, 1.1401, 1.0687, 1.3395, 1.2175],
        [1.4542, 1.4541, 1.4525, 1.4496, 1.4500, 1.4542, 1.4498, 1.4541, 1.4541,
         1.4365, 1.4358, 1.4365, 1.4364, 1.4365, 1.4176, 1.4365, 1.4353, 1.4331,
         2.2022, 2.2026, 2.2195, 2.1951, 2.1762, 2.1745, 2.2038, 2.1736, 2.1736,
         1.5157, 1.5141, 1.5215, 1.5215, 1.5157, 1.5215, 1.5215, 1.5215, 1.5215,
         1.7758, 1.7759, 1.7759, 1.7727, 1.7758, 1.7758, 1.7759, 1.7531, 1.7558,
         1.4297, 1.4343, 1.4343, 1.4343, 1.4260, 1.4343, 1.4303, 1.4343, 1.4343],
        [1.3201, 1.3185, 1.3026, 1.2937, 1.3175, 1.3158, 1.3169, 1.3177, 1.3177,
         1.3020, 1.2953, 1.2915, 1.2910, 1.3027, 1.2871, 1.2986, 1.3023, 1.2747,
         1.6439, 1.6175, 1.6409, 1.6404, 1.6397, 1.6398, 1.6420, 1.6435, 1.6435,
         3.4946, 3.2847, 3.2101, 3.2686, 3.4199, 3.2370, 3.4691, 3.2182, 3.1967,
         1.6487, 1.6413, 1.6395, 1.6427, 1.6456, 1.6217, 1.6470, 1.5864, 1.6129,
         1.2976, 1.2921, 1.2823, 1.2970, 1.2926, 1.2848, 1.2970, 1.2972, 1.2992],
        [1.4570, 1.4527, 1.4092, 1.4125, 1.4503, 1.4569, 1.4554, 1.4570, 1.4570,
         1.4382, 1.4356, 1.4305, 1.4255, 1.4393, 1.3983, 1.4334, 1.4393, 1.4343,
         1.7576, 1.7489, 1.7474, 1.7557, 1.7734, 1.7720, 1.7520, 1.7735, 1.7735,
         1.4823, 1.4876, 1.5243, 1.5191, 1.4878, 1.5229, 1.5111, 1.5243, 1.5212,
         2.2021, 2.1816, 2.1702, 2.1883, 2.2325, 2.2497, 2.2160, 2.3207, 2.3172,
         1.4217, 1.4125, 1.4268, 1.4371, 1.4242, 1.4339, 1.4042, 1.4311, 1.4372],
        [1.3175, 1.2198, 1.2155, 1.2352, 1.2283, 1.2389, 1.2376, 1.1735, 1.1735,
         1.2405, 1.1967, 1.1955, 1.2022, 1.2818, 1.1511, 1.1188, 1.2818, 1.1830,
         1.5785, 1.5544, 1.5359, 1.5308, 1.5543, 1.5505, 1.5710, 1.5558, 1.5558,
         1.3218, 1.2941, 1.2935, 1.3118, 1.2959, 1.3407, 1.3426, 1.3156, 1.2936,
         1.5597, 1.5592, 1.5650, 1.5544, 1.5302, 1.5340, 1.5957, 1.4832, 1.4519,
         4.0914, 3.6780, 3.7618, 3.7474, 3.7587, 3.4544, 4.0845, 3.7246, 3.4850]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 205 : 1779.0644560825679
Test loss for epoch 205 : 196.32851834855128
Test Precision for epoch 205 : 0.26153846153846155
Test Recall for epoch 205 : 0.26153846153846155
Test F1 for epoch 205 : 0.26153846153846155


theta for epoch 206 : tensor([[3.6329, 3.6559, 3.7997, 3.7457, 3.7327, 3.6147, 3.6558, 3.5553, 3.5553,
         1.2594, 1.2384, 1.2371, 1.2407, 1.2782, 1.2195, 1.1917, 1.2782, 1.2261,
         1.6019, 1.5862, 1.6104, 1.5929, 1.5987, 1.6004, 1.6077, 1.6004, 1.6004,
         1.3373, 1.3487, 1.3359, 1.3561, 1.3372, 1.3666, 1.3599, 1.3477, 1.3359,
         1.5978, 1.6143, 1.6028, 1.5992, 1.6063, 1.5965, 1.6150, 1.5681, 1.5729,
         1.2292, 1.2563, 1.2480, 1.2657, 1.2239, 1.2153, 1.2054, 1.2883, 1.2446],
        [1.3677, 1.2210, 1.2104, 1.2529, 1.2532, 1.2655, 1.2594, 1.1677, 1.1677,
         3.6249, 3.7000, 3.5620, 3.8967, 3.6255, 4.1646, 3.5066, 3.5852, 3.9829,
         1.5706, 1.5586, 1.5329, 1.5317, 1.5525, 1.5620, 1.5861, 1.5620, 1.5620,
         1.3416, 1.3087, 1.3033, 1.3595, 1.3025, 1.3960, 1.3767, 1.3462, 1.3001,
         1.5417, 1.5970, 1.5612, 1.5481, 1.5431, 1.5803, 1.5996, 1.4347, 1.5327,
         1.1336, 1.2470, 1.2196, 1.2689, 1.1275, 1.1330, 1.0615, 1.3309, 1.2098],
        [1.4517, 1.4516, 1.4500, 1.4472, 1.4476, 1.4517, 1.4473, 1.4517, 1.4517,
         1.4311, 1.4304, 1.4311, 1.4311, 1.4311, 1.4123, 1.4311, 1.4299, 1.4277,
         2.2087, 2.2091, 2.2260, 2.2013, 2.1825, 2.1808, 2.2100, 2.1798, 2.1798,
         1.5128, 1.5112, 1.5187, 1.5187, 1.5129, 1.5187, 1.5187, 1.5187, 1.5187,
         1.7799, 1.7800, 1.7800, 1.7768, 1.7799, 1.7799, 1.7800, 1.7572, 1.7599,
         1.4301, 1.4348, 1.4347, 1.4348, 1.4264, 1.4347, 1.4308, 1.4347, 1.4347],
        [1.3174, 1.3159, 1.2999, 1.2911, 1.3148, 1.3131, 1.3143, 1.3151, 1.3151,
         1.2965, 1.2899, 1.2860, 1.2855, 1.2972, 1.2817, 1.2932, 1.2968, 1.2693,
         1.6508, 1.6244, 1.6477, 1.6472, 1.6466, 1.6466, 1.6489, 1.6503, 1.6503,
         3.4932, 3.2832, 3.2086, 3.2671, 3.4184, 3.2355, 3.4676, 3.2167, 3.1952,
         1.6528, 1.6453, 1.6436, 1.6468, 1.6497, 1.6258, 1.6511, 1.5905, 1.6170,
         1.2979, 1.2924, 1.2825, 1.2972, 1.2929, 1.2851, 1.2973, 1.2974, 1.2994],
        [1.4545, 1.4503, 1.4068, 1.4100, 1.4479, 1.4544, 1.4530, 1.4545, 1.4545,
         1.4328, 1.4302, 1.4252, 1.4201, 1.4340, 1.3930, 1.4280, 1.4340, 1.4289,
         1.7645, 1.7558, 1.7543, 1.7626, 1.7803, 1.7788, 1.7589, 1.7804, 1.7804,
         1.4795, 1.4848, 1.5214, 1.5163, 1.4850, 1.5201, 1.5083, 1.5215, 1.5184,
         2.2061, 2.1856, 2.1742, 2.1923, 2.2365, 2.2536, 2.2200, 2.3246, 2.3211,
         1.4222, 1.4129, 1.4272, 1.4375, 1.4247, 1.4343, 1.4048, 1.4315, 1.4376],
        [1.3426, 1.2431, 1.2391, 1.2589, 1.2521, 1.2625, 1.2613, 1.1956, 1.1956,
         1.2469, 1.2029, 1.2017, 1.2083, 1.2883, 1.1573, 1.1237, 1.2883, 1.1888,
         1.5987, 1.5747, 1.5564, 1.5508, 1.5742, 1.5704, 1.5913, 1.5757, 1.5757,
         1.3404, 1.3127, 1.3112, 1.3306, 1.3142, 1.3599, 1.3614, 1.3341, 1.3112,
         1.5747, 1.5746, 1.5799, 1.5694, 1.5455, 1.5495, 1.6110, 1.4986, 1.4678,
         4.0642, 3.6496, 3.7336, 3.7192, 3.7304, 3.4256, 4.0573, 3.6963, 3.4564]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 206 : 1779.2304792960747
Test loss for epoch 206 : 195.2196384180394
Test Precision for epoch 206 : 0.26153846153846155
Test Recall for epoch 206 : 0.26153846153846155
Test F1 for epoch 206 : 0.26153846153846155


theta for epoch 207 : tensor([[3.6328, 3.6558, 3.7996, 3.7457, 3.7325, 3.6146, 3.6557, 3.5552, 3.5552,
         1.2575, 1.2367, 1.2354, 1.2389, 1.2759, 1.2179, 1.1905, 1.2760, 1.2244,
         1.6021, 1.5864, 1.6106, 1.5932, 1.5991, 1.6007, 1.6079, 1.6007, 1.6007,
         1.3330, 1.3444, 1.3318, 1.3517, 1.3330, 1.3622, 1.3555, 1.3434, 1.3318,
         1.5967, 1.6130, 1.6017, 1.5981, 1.6051, 1.5952, 1.6137, 1.5669, 1.5718,
         1.2368, 1.2636, 1.2554, 1.2730, 1.2315, 1.2230, 1.2130, 1.2953, 1.2521],
        [1.3507, 1.2058, 1.1950, 1.2374, 1.2376, 1.2500, 1.2439, 1.1536, 1.1536,
         3.6385, 3.7138, 3.5755, 3.9111, 3.6392, 4.1800, 3.5201, 3.5987, 3.9977,
         1.5613, 1.5493, 1.5234, 1.5226, 1.5435, 1.5530, 1.5769, 1.5530, 1.5530,
         1.3273, 1.2945, 1.2895, 1.3453, 1.2884, 1.3814, 1.3622, 1.3321, 1.2864,
         1.5321, 1.5874, 1.5517, 1.5385, 1.5334, 1.5706, 1.5898, 1.4245, 1.5230,
         1.1280, 1.2414, 1.2141, 1.2633, 1.1220, 1.1277, 1.0558, 1.3252, 1.2043],
        [1.4470, 1.4469, 1.4453, 1.4425, 1.4429, 1.4470, 1.4426, 1.4470, 1.4470,
         1.4292, 1.4285, 1.4291, 1.4291, 1.4292, 1.4103, 1.4292, 1.4280, 1.4257,
         2.2092, 2.2096, 2.2265, 2.2018, 2.1830, 2.1813, 2.2105, 2.1803, 2.1803,
         1.5091, 1.5075, 1.5150, 1.5150, 1.5091, 1.5150, 1.5149, 1.5150, 1.5150,
         1.7790, 1.7791, 1.7791, 1.7759, 1.7790, 1.7790, 1.7791, 1.7563, 1.7590,
         1.4384, 1.4430, 1.4430, 1.4430, 1.4347, 1.4430, 1.4390, 1.4429, 1.4430],
        [1.3125, 1.3110, 1.2950, 1.2862, 1.3099, 1.3082, 1.3094, 1.3102, 1.3102,
         1.2945, 1.2878, 1.2840, 1.2835, 1.2952, 1.2796, 1.2912, 1.2947, 1.2672,
         1.6512, 1.6248, 1.6481, 1.6476, 1.6470, 1.6470, 1.6492, 1.6507, 1.6507,
         3.4911, 3.2811, 3.2065, 3.2650, 3.4163, 3.2334, 3.4655, 3.2146, 3.1931,
         1.6517, 1.6443, 1.6425, 1.6457, 1.6487, 1.6247, 1.6500, 1.5895, 1.6159,
         1.3060, 1.3005, 1.2906, 1.3053, 1.3010, 1.2932, 1.3054, 1.3055, 1.3075],
        [1.4499, 1.4456, 1.4022, 1.4054, 1.4432, 1.4497, 1.4483, 1.4498, 1.4498,
         1.4309, 1.4282, 1.4232, 1.4182, 1.4320, 1.3911, 1.4261, 1.4320, 1.4270,
         1.7651, 1.7563, 1.7549, 1.7632, 1.7808, 1.7794, 1.7595, 1.7809, 1.7809,
         1.4758, 1.4811, 1.5177, 1.5126, 1.4812, 1.5163, 1.5046, 1.5177, 1.5146,
         2.2051, 2.1846, 2.1733, 2.1913, 2.2355, 2.2527, 2.2191, 2.3235, 2.3201,
         1.4305, 1.4212, 1.4355, 1.4458, 1.4330, 1.4425, 1.4132, 1.4397, 1.4458],
        [1.3612, 1.2598, 1.2561, 1.2759, 1.2692, 1.2796, 1.2783, 1.2110, 1.2110,
         1.2543, 1.2099, 1.2087, 1.2153, 1.2959, 1.1640, 1.1287, 1.2959, 1.1954,
         1.6103, 1.5862, 1.5682, 1.5620, 1.5853, 1.5816, 1.6028, 1.5868, 1.5868,
         1.3542, 1.3267, 1.3242, 1.3447, 1.3278, 1.3744, 1.3755, 1.3478, 1.3242,
         1.5823, 1.5828, 1.5876, 1.5771, 1.5535, 1.5577, 1.6191, 1.5068, 1.4763,
         4.0461, 3.6305, 3.7145, 3.7002, 3.7115, 3.4062, 4.0393, 3.6773, 3.4370]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 207 : 1778.8571955673144
Test loss for epoch 207 : 195.33991054295223
Test Precision for epoch 207 : 0.26153846153846155
Test Recall for epoch 207 : 0.26153846153846155
Test F1 for epoch 207 : 0.26153846153846155


theta for epoch 208 : tensor([[3.6292, 3.6521, 3.7960, 3.7421, 3.7288, 3.6109, 3.6520, 3.5515, 3.5515,
         1.2570, 1.2368, 1.2356, 1.2389, 1.2749, 1.2181, 1.1918, 1.2749, 1.2247,
         1.5958, 1.5802, 1.6043, 1.5871, 1.5929, 1.5946, 1.6017, 1.5946, 1.5946,
         1.3337, 1.3451, 1.3327, 1.3524, 1.3338, 1.3627, 1.3561, 1.3441, 1.3327,
         1.5926, 1.6088, 1.5976, 1.5940, 1.6009, 1.5911, 1.6095, 1.5628, 1.5677,
         1.2510, 1.2774, 1.2694, 1.2868, 1.2457, 1.2373, 1.2272, 1.3089, 1.2661],
        [1.3530, 1.2099, 1.1989, 1.2411, 1.2414, 1.2538, 1.2476, 1.1586, 1.1586,
         3.6337, 3.7092, 3.5706, 3.9070, 3.6344, 4.1769, 3.5150, 3.5939, 3.9939,
         1.5589, 1.5471, 1.5211, 1.5207, 1.5415, 1.5510, 1.5745, 1.5510, 1.5510,
         1.3306, 1.2978, 1.2933, 1.3484, 1.2918, 1.3842, 1.3652, 1.3354, 1.2902,
         1.5310, 1.5859, 1.5506, 1.5374, 1.5322, 1.5693, 1.5882, 1.4237, 1.5219,
         1.1403, 1.2534, 1.2262, 1.2753, 1.1344, 1.1402, 1.0682, 1.3368, 1.2165],
        [1.4454, 1.4453, 1.4437, 1.4409, 1.4413, 1.4454, 1.4411, 1.4454, 1.4454,
         1.4280, 1.4272, 1.4279, 1.4279, 1.4280, 1.4091, 1.4279, 1.4267, 1.4245,
         2.2028, 2.2032, 2.2201, 2.1956, 2.1769, 2.1752, 2.2044, 2.1742, 2.1742,
         1.5087, 1.5071, 1.5146, 1.5146, 1.5087, 1.5146, 1.5145, 1.5146, 1.5146,
         1.7743, 1.7744, 1.7744, 1.7712, 1.7743, 1.7743, 1.7744, 1.7516, 1.7543,
         1.4518, 1.4564, 1.4564, 1.4564, 1.4482, 1.4564, 1.4525, 1.4564, 1.4564],
        [1.3108, 1.3093, 1.2934, 1.2845, 1.3082, 1.3066, 1.3077, 1.3085, 1.3085,
         1.2932, 1.2865, 1.2827, 1.2822, 1.2938, 1.2784, 1.2899, 1.2934, 1.2660,
         1.6442, 1.6178, 1.6411, 1.6407, 1.6400, 1.6401, 1.6423, 1.6438, 1.6438,
         3.4917, 3.2817, 3.2071, 3.2656, 3.4169, 3.2340, 3.4661, 3.2152, 3.1937,
         1.6469, 1.6395, 1.6377, 1.6409, 1.6438, 1.6199, 1.6452, 1.5847, 1.6111,
         1.3194, 1.3139, 1.3040, 1.3186, 1.3144, 1.3066, 1.3188, 1.3188, 1.3209],
        [1.4483, 1.4441, 1.4006, 1.4038, 1.4416, 1.4481, 1.4467, 1.4482, 1.4482,
         1.4297, 1.4270, 1.4220, 1.4170, 1.4308, 1.3900, 1.4249, 1.4308, 1.4258,
         1.7583, 1.7496, 1.7482, 1.7564, 1.7740, 1.7727, 1.7527, 1.7742, 1.7742,
         1.4754, 1.4808, 1.5173, 1.5122, 1.4809, 1.5159, 1.5042, 1.5173, 1.5142,
         2.2005, 2.1801, 2.1687, 2.1867, 2.2309, 2.2481, 2.2146, 2.3189, 2.3154,
         1.4440, 1.4347, 1.4490, 1.4592, 1.4465, 1.4560, 1.4268, 1.4532, 1.4592],
        [1.3798, 1.2773, 1.2739, 1.2937, 1.2870, 1.2973, 1.2961, 1.2279, 1.2279,
         1.2618, 1.2176, 1.2163, 1.2227, 1.3031, 1.1716, 1.1359, 1.3031, 1.2028,
         1.6142, 1.5902, 1.5725, 1.5659, 1.5890, 1.5853, 1.6068, 1.5905, 1.5905,
         1.3696, 1.3422, 1.3391, 1.3603, 1.3431, 1.3902, 1.3911, 1.3632, 1.3391,
         1.5860, 1.5868, 1.5912, 1.5808, 1.5574, 1.5618, 1.6230, 1.5109, 1.4807,
         4.0317, 3.6150, 3.6991, 3.6847, 3.6961, 3.3904, 4.0249, 3.6619, 3.4213]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 208 : 1779.1146345089583
Test loss for epoch 208 : 195.0821493497861
Test Precision for epoch 208 : 0.26153846153846155
Test Recall for epoch 208 : 0.26153846153846155
Test F1 for epoch 208 : 0.26153846153846155


theta for epoch 209 : tensor([[3.6200, 3.6426, 3.7866, 3.7327, 3.7194, 3.6015, 3.6426, 3.5419, 3.5419,
         1.2596, 1.2403, 1.2391, 1.2420, 1.2767, 1.2216, 1.1969, 1.2767, 1.2283,
         1.5921, 1.5766, 1.6006, 1.5836, 1.5894, 1.5910, 1.5980, 1.5910, 1.5910,
         1.3357, 1.3471, 1.3347, 1.3543, 1.3358, 1.3646, 1.3580, 1.3461, 1.3348,
         1.5905, 1.6066, 1.5955, 1.5919, 1.5988, 1.5890, 1.6073, 1.5608, 1.5656,
         1.2613, 1.2875, 1.2796, 1.2967, 1.2561, 1.2478, 1.2377, 1.3186, 1.2763],
        [1.3740, 1.2328, 1.2217, 1.2637, 1.2640, 1.2763, 1.2702, 1.1824, 1.1824,
         3.6098, 3.6855, 3.5465, 3.8839, 3.6105, 4.1547, 3.4907, 3.5699, 3.9711,
         1.5712, 1.5596, 1.5337, 1.5335, 1.5542, 1.5635, 1.5867, 1.5635, 1.5635,
         1.3497, 1.3172, 1.3130, 1.3674, 1.3113, 1.4027, 1.3839, 1.3545, 1.3099,
         1.5435, 1.5977, 1.5628, 1.5498, 1.5446, 1.5812, 1.5999, 1.4371, 1.5344,
         1.1639, 1.2761, 1.2492, 1.2978, 1.1581, 1.1640, 1.0923, 1.3587, 1.2396],
        [1.4445, 1.4444, 1.4428, 1.4400, 1.4404, 1.4445, 1.4402, 1.4445, 1.4445,
         1.4289, 1.4282, 1.4289, 1.4288, 1.4289, 1.4101, 1.4289, 1.4277, 1.4255,
         2.1977, 2.1981, 2.2150, 2.1907, 2.1720, 2.1703, 2.1995, 2.1693, 2.1693,
         1.5077, 1.5061, 1.5136, 1.5136, 1.5077, 1.5136, 1.5135, 1.5136, 1.5136,
         1.7708, 1.7709, 1.7709, 1.7677, 1.7708, 1.7708, 1.7709, 1.7481, 1.7508,
         1.4601, 1.4646, 1.4646, 1.4646, 1.4564, 1.4646, 1.4607, 1.4646, 1.4646],
        [1.3100, 1.3085, 1.2926, 1.2838, 1.3074, 1.3058, 1.3069, 1.3077, 1.3077,
         1.2941, 1.2875, 1.2836, 1.2831, 1.2947, 1.2793, 1.2909, 1.2943, 1.2669,
         1.6387, 1.6123, 1.6356, 1.6351, 1.6345, 1.6345, 1.6367, 1.6382, 1.6382,
         3.4915, 3.2815, 3.2069, 3.2654, 3.4167, 3.2338, 3.4659, 3.2150, 3.1935,
         1.6433, 1.6358, 1.6341, 1.6373, 1.6402, 1.6163, 1.6416, 1.5811, 1.6075,
         1.3276, 1.3220, 1.3122, 1.3268, 1.3226, 1.3148, 1.3270, 1.3270, 1.3291],
        [1.4474, 1.4432, 1.3998, 1.4030, 1.4407, 1.4473, 1.4458, 1.4473, 1.4473,
         1.4306, 1.4280, 1.4229, 1.4180, 1.4318, 1.3910, 1.4258, 1.4317, 1.4267,
         1.7529, 1.7442, 1.7428, 1.7511, 1.7687, 1.7673, 1.7474, 1.7688, 1.7688,
         1.4744, 1.4799, 1.5163, 1.5112, 1.4799, 1.5150, 1.5032, 1.5164, 1.5132,
         2.1970, 2.1766, 2.1653, 2.1832, 2.2274, 2.2447, 2.2111, 2.3154, 2.3119,
         1.4523, 1.4429, 1.4572, 1.4674, 1.4547, 1.4642, 1.4350, 1.4614, 1.4674],
        [1.3957, 1.2933, 1.2899, 1.3097, 1.3030, 1.3133, 1.3120, 1.2438, 1.2438,
         1.2704, 1.2270, 1.2258, 1.2318, 1.3110, 1.1810, 1.1460, 1.3110, 1.2121,
         1.6185, 1.5946, 1.5771, 1.5702, 1.5932, 1.5896, 1.6111, 1.5948, 1.5948,
         1.3827, 1.3554, 1.3520, 1.3736, 1.3563, 1.4035, 1.4043, 1.3763, 1.3521,
         1.5901, 1.5912, 1.5953, 1.5850, 1.5618, 1.5662, 1.6273, 1.5155, 1.4855,
         4.0167, 3.5990, 3.6832, 3.6688, 3.6802, 3.3741, 4.0099, 3.6460, 3.4050]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 209 : 1780.7277309053861
Test loss for epoch 209 : 194.0970041918916
Test Precision for epoch 209 : 0.26153846153846155
Test Recall for epoch 209 : 0.26153846153846155
Test F1 for epoch 209 : 0.26153846153846155


theta for epoch 210 : tensor([[3.6110, 3.6335, 3.7776, 3.7237, 3.7104, 3.5924, 3.6336, 3.5326, 3.5326,
         1.2675, 1.2488, 1.2476, 1.2503, 1.2842, 1.2301, 1.2062, 1.2842, 1.2368,
         1.5937, 1.5782, 1.6021, 1.5852, 1.5909, 1.5926, 1.5995, 1.5926, 1.5926,
         1.3319, 1.3433, 1.3309, 1.3506, 1.3320, 1.3609, 1.3543, 1.3423, 1.3309,
         1.5917, 1.6077, 1.5967, 1.5931, 1.5999, 1.5901, 1.6084, 1.5620, 1.5668,
         1.2595, 1.2855, 1.2776, 1.2947, 1.2543, 1.2461, 1.2358, 1.3164, 1.2744],
        [1.3861, 1.2459, 1.2349, 1.2767, 1.2770, 1.2892, 1.2831, 1.1960, 1.1960,
         3.5959, 3.6717, 3.5325, 3.8707, 3.5966, 4.1425, 3.4765, 3.5560, 3.9582,
         1.5821, 1.5706, 1.5449, 1.5448, 1.5653, 1.5746, 1.5975, 1.5746, 1.5746,
         1.3590, 1.3267, 1.3227, 1.3765, 1.3210, 1.4116, 1.3930, 1.3638, 1.3196,
         1.5537, 1.6075, 1.5730, 1.5600, 1.5548, 1.5912, 1.6097, 1.4480, 1.5447,
         1.1733, 1.2846, 1.2579, 1.3061, 1.1675, 1.1735, 1.1021, 1.3665, 1.2484],
        [1.4411, 1.4410, 1.4394, 1.4366, 1.4370, 1.4411, 1.4368, 1.4411, 1.4411,
         1.4357, 1.4350, 1.4356, 1.4356, 1.4357, 1.4169, 1.4356, 1.4345, 1.4322,
         2.1979, 2.1983, 2.2151, 2.1909, 2.1721, 2.1704, 2.1997, 2.1695, 2.1695,
         1.5017, 1.5001, 1.5076, 1.5076, 1.5018, 1.5076, 1.5076, 1.5076, 1.5076,
         1.7708, 1.7709, 1.7709, 1.7677, 1.7708, 1.7708, 1.7709, 1.7481, 1.7508,
         1.4566, 1.4611, 1.4611, 1.4611, 1.4529, 1.4611, 1.4572, 1.4610, 1.4611],
        [1.3068, 1.3052, 1.2893, 1.2805, 1.3042, 1.3025, 1.3036, 1.3044, 1.3044,
         1.3008, 1.2943, 1.2904, 1.2899, 1.3015, 1.2861, 1.2978, 1.3010, 1.2737,
         1.6389, 1.6125, 1.6358, 1.6353, 1.6347, 1.6347, 1.6369, 1.6384, 1.6384,
         3.4865, 3.2764, 3.2019, 3.2603, 3.4117, 3.2288, 3.4610, 3.2100, 3.1884,
         1.6433, 1.6358, 1.6341, 1.6373, 1.6402, 1.6163, 1.6416, 1.5811, 1.6075,
         1.3241, 1.3185, 1.3087, 1.3233, 1.3191, 1.3113, 1.3235, 1.3235, 1.3255],
        [1.4440, 1.4398, 1.3964, 1.3996, 1.4373, 1.4438, 1.4424, 1.4439, 1.4439,
         1.4374, 1.4347, 1.4297, 1.4248, 1.4385, 1.3978, 1.4326, 1.4385, 1.4335,
         1.7531, 1.7444, 1.7430, 1.7513, 1.7688, 1.7675, 1.7475, 1.7690, 1.7690,
         1.4684, 1.4739, 1.5103, 1.5052, 1.4739, 1.5090, 1.4972, 1.5104, 1.5072,
         2.1970, 2.1766, 2.1653, 2.1832, 2.2274, 2.2447, 2.2111, 2.3153, 2.3118,
         1.4488, 1.4394, 1.4537, 1.4639, 1.4512, 1.4607, 1.4316, 1.4579, 1.4639],
        [1.4031, 1.3012, 1.2979, 1.3175, 1.3109, 1.3211, 1.3198, 1.2519, 1.2519,
         1.2821, 1.2392, 1.2380, 1.2437, 1.3221, 1.1930, 1.1583, 1.3221, 1.2241,
         1.6251, 1.6012, 1.5837, 1.5769, 1.5998, 1.5961, 1.6177, 1.6013, 1.6013,
         1.3868, 1.3597, 1.3562, 1.3777, 1.3605, 1.4075, 1.4082, 1.3804, 1.3562,
         1.5954, 1.5966, 1.6006, 1.5903, 1.5672, 1.5716, 1.6325, 1.5210, 1.4912,
         4.0029, 3.5841, 3.6685, 3.6541, 3.6655, 3.3590, 3.9962, 3.6313, 3.3900]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 210 : 1781.152602272328
Test loss for epoch 210 : 193.57700176913406
Test Precision for epoch 210 : 0.26153846153846155
Test Recall for epoch 210 : 0.26153846153846155
Test F1 for epoch 210 : 0.26153846153846155


theta for epoch 211 : tensor([[3.6023, 3.6246, 3.7688, 3.7149, 3.7015, 3.5836, 3.6247, 3.5236, 3.5236,
         1.2771, 1.2585, 1.2574, 1.2600, 1.2936, 1.2398, 1.2160, 1.2936, 1.2465,
         1.5969, 1.5813, 1.6053, 1.5883, 1.5941, 1.5957, 1.6027, 1.5957, 1.5957,
         1.3271, 1.3385, 1.3257, 1.3458, 1.3271, 1.3563, 1.3496, 1.3375, 1.3257,
         1.5935, 1.6096, 1.5985, 1.5949, 1.6018, 1.5920, 1.6103, 1.5639, 1.5687,
         1.2531, 1.2792, 1.2713, 1.2884, 1.2480, 1.2398, 1.2294, 1.3101, 1.2681],
        [1.3901, 1.2502, 1.2393, 1.2809, 1.2812, 1.2934, 1.2873, 1.2004, 1.2004,
         3.5901, 3.6660, 3.5265, 3.8655, 3.5908, 4.1383, 3.4704, 3.5501, 3.9533,
         1.5893, 1.5778, 1.5521, 1.5521, 1.5726, 1.5819, 1.6046, 1.5819, 1.5819,
         1.3615, 1.3294, 1.3255, 1.3790, 1.3237, 1.4138, 1.3953, 1.3663, 1.3223,
         1.5599, 1.6135, 1.5791, 1.5662, 1.5610, 1.5972, 1.6157, 1.4545, 1.5509,
         1.1743, 1.2850, 1.2585, 1.3063, 1.1686, 1.1746, 1.1035, 1.3662, 1.2491],
        [1.4361, 1.4360, 1.4344, 1.4316, 1.4320, 1.4361, 1.4318, 1.4361, 1.4361,
         1.4444, 1.4437, 1.4443, 1.4443, 1.4444, 1.4256, 1.4443, 1.4431, 1.4409,
         2.1999, 2.2002, 2.2171, 2.1928, 2.1740, 2.1723, 2.2016, 2.1714, 2.1714,
         1.4952, 1.4936, 1.5010, 1.5010, 1.4952, 1.5010, 1.5010, 1.5010, 1.5010,
         1.7719, 1.7720, 1.7720, 1.7688, 1.7719, 1.7719, 1.7720, 1.7492, 1.7519,
         1.4490, 1.4535, 1.4535, 1.4535, 1.4453, 1.4535, 1.4496, 1.4535, 1.4535],
        [1.3022, 1.3006, 1.2847, 1.2759, 1.2995, 1.2979, 1.2990, 1.2997, 1.2997,
         1.3096, 1.3030, 1.2992, 1.2987, 1.3102, 1.2949, 1.3066, 1.3098, 1.2825,
         1.6411, 1.6147, 1.6380, 1.6376, 1.6369, 1.6370, 1.6392, 1.6407, 1.6407,
         3.4803, 3.2701, 3.1955, 3.2540, 3.4054, 3.2225, 3.4548, 3.2036, 3.1821,
         1.6445, 1.6370, 1.6353, 1.6385, 1.6414, 1.6174, 1.6428, 1.5822, 1.6087,
         1.3166, 1.3110, 1.3012, 1.3158, 1.3116, 1.3038, 1.3160, 1.3160, 1.3181],
        [1.4390, 1.4348, 1.3914, 1.3946, 1.4323, 1.4389, 1.4374, 1.4389, 1.4389,
         1.4460, 1.4434, 1.4384, 1.4335, 1.4472, 1.4065, 1.4413, 1.4472, 1.4422,
         1.7552, 1.7465, 1.7452, 1.7534, 1.7709, 1.7696, 1.7497, 1.7711, 1.7711,
         1.4618, 1.4673, 1.5038, 1.4987, 1.4673, 1.5024, 1.4906, 1.5038, 1.5007,
         2.1981, 2.1777, 2.1663, 2.1843, 2.2284, 2.2457, 2.2122, 2.3163, 2.3129,
         1.4412, 1.4318, 1.4461, 1.4563, 1.4436, 1.4531, 1.4240, 1.4503, 1.4564],
        [1.4029, 1.3020, 1.2986, 1.3181, 1.3115, 1.3216, 1.3204, 1.2532, 1.2532,
         1.2932, 1.2507, 1.2496, 1.2550, 1.3328, 1.2044, 1.1697, 1.3329, 1.2355,
         1.6306, 1.6068, 1.5893, 1.5825, 1.6054, 1.6017, 1.6232, 1.6069, 1.6069,
         1.3858, 1.3588, 1.3555, 1.3767, 1.3597, 1.4063, 1.4071, 1.3795, 1.3555,
         1.5994, 1.6006, 1.6046, 1.5943, 1.5713, 1.5757, 1.6365, 1.5252, 1.4955,
         3.9928, 3.5730, 3.6575, 3.6431, 3.6545, 3.3477, 3.9861, 3.6203, 3.3787]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 211 : 1781.6812129246657
Test loss for epoch 211 : 193.37329972883143
Test Precision for epoch 211 : 0.26153846153846155
Test Recall for epoch 211 : 0.26153846153846155
Test F1 for epoch 211 : 0.26153846153846155


theta for epoch 212 : tensor([[3.5984, 3.6206, 3.7649, 3.7110, 3.6976, 3.5796, 3.6208, 3.5196, 3.5196,
         1.2802, 1.2615, 1.2604, 1.2630, 1.2968, 1.2427, 1.2183, 1.2968, 1.2493,
         1.5964, 1.5808, 1.6048, 1.5875, 1.5933, 1.5950, 1.6022, 1.5950, 1.5950,
         1.3286, 1.3399, 1.3265, 1.3473, 1.3283, 1.3582, 1.3513, 1.3388, 1.3266,
         1.5931, 1.6094, 1.5981, 1.5945, 1.6015, 1.5917, 1.6100, 1.5636, 1.5684,
         1.2520, 1.2782, 1.2703, 1.2875, 1.2468, 1.2385, 1.2280, 1.3094, 1.2670],
        [1.3909, 1.2505, 1.2395, 1.2812, 1.2815, 1.2936, 1.2876, 1.2003, 1.2003,
         3.5889, 3.6650, 3.5252, 3.8651, 3.5897, 4.1388, 3.4689, 3.5489, 3.9532,
         1.5891, 1.5776, 1.5519, 1.5519, 1.5724, 1.5816, 1.6044, 1.5816, 1.5816,
         1.3622, 1.3300, 1.3261, 1.3797, 1.3243, 1.4145, 1.3960, 1.3670, 1.3230,
         1.5599, 1.6135, 1.5791, 1.5662, 1.5610, 1.5972, 1.6156, 1.4545, 1.5509,
         1.1743, 1.2847, 1.2583, 1.3059, 1.1686, 1.1747, 1.1035, 1.3657, 1.2489],
        [1.4378, 1.4377, 1.4361, 1.4333, 1.4336, 1.4377, 1.4334, 1.4377, 1.4377,
         1.4469, 1.4462, 1.4469, 1.4469, 1.4469, 1.4281, 1.4469, 1.4457, 1.4435,
         2.1987, 2.1991, 2.2160, 2.1916, 2.1729, 2.1712, 2.2005, 2.1703, 2.1703,
         1.4954, 1.4938, 1.5012, 1.5012, 1.4954, 1.5012, 1.5012, 1.5012, 1.5012,
         1.7711, 1.7712, 1.7712, 1.7680, 1.7711, 1.7711, 1.7712, 1.7484, 1.7511,
         1.4469, 1.4514, 1.4514, 1.4514, 1.4432, 1.4515, 1.4475, 1.4514, 1.4515],
        [1.3046, 1.3028, 1.2870, 1.2782, 1.3018, 1.3002, 1.3013, 1.3019, 1.3019,
         1.3123, 1.3058, 1.3019, 1.3014, 1.3130, 1.2976, 1.3093, 1.3126, 1.2852,
         1.6401, 1.6137, 1.6370, 1.6366, 1.6359, 1.6360, 1.6382, 1.6397, 1.6397,
         3.4789, 3.2688, 3.1941, 3.2526, 3.4040, 3.2211, 3.4534, 3.2023, 3.1807,
         1.6438, 1.6364, 1.6346, 1.6378, 1.6407, 1.6168, 1.6421, 1.5816, 1.6080,
         1.3147, 1.3092, 1.2994, 1.3140, 1.3097, 1.3019, 1.3142, 1.3142, 1.3162],
        [1.4406, 1.4364, 1.3929, 1.3963, 1.4339, 1.4405, 1.4390, 1.4406, 1.4406,
         1.4486, 1.4460, 1.4410, 1.4360, 1.4498, 1.4090, 1.4438, 1.4497, 1.4448,
         1.7540, 1.7453, 1.7439, 1.7522, 1.7697, 1.7684, 1.7485, 1.7699, 1.7699,
         1.4620, 1.4674, 1.5040, 1.4988, 1.4675, 1.5026, 1.4908, 1.5040, 1.5009,
         2.1973, 2.1768, 2.1655, 2.1835, 2.2276, 2.2449, 2.2114, 2.3155, 2.3121,
         1.4391, 1.4297, 1.4440, 1.4542, 1.4415, 1.4510, 1.4218, 1.4482, 1.4543],
        [1.4019, 1.3023, 1.2989, 1.3182, 1.3116, 1.3217, 1.3205, 1.2542, 1.2542,
         1.2965, 1.2543, 1.2532, 1.2584, 1.3358, 1.2079, 1.1731, 1.3358, 1.2389,
         1.6303, 1.6066, 1.5891, 1.5825, 1.6053, 1.6017, 1.6230, 1.6068, 1.6068,
         1.3863, 1.3594, 1.3564, 1.3771, 1.3604, 1.4063, 1.4073, 1.3800, 1.3565,
         1.5996, 1.6006, 1.6047, 1.5945, 1.5714, 1.5758, 1.6364, 1.5255, 1.4957,
         3.9899, 3.5692, 3.6538, 3.6394, 3.6509, 3.3437, 3.9833, 3.6165, 3.3748]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 212 : 1781.9015567925976
Test loss for epoch 212 : 193.35635099579406
Test Precision for epoch 212 : 0.26153846153846155
Test Recall for epoch 212 : 0.26153846153846155
Test F1 for epoch 212 : 0.26153846153846155


theta for epoch 213 : tensor([[3.5988, 3.6210, 3.7653, 3.7114, 3.6979, 3.5800, 3.6212, 3.5200, 3.5200,
         1.2746, 1.2555, 1.2544, 1.2570, 1.2916, 1.2366, 1.2110, 1.2916, 1.2431,
         1.5938, 1.5782, 1.6023, 1.5847, 1.5905, 1.5922, 1.5996, 1.5921, 1.5921,
         1.3356, 1.3468, 1.3327, 1.3544, 1.3350, 1.3657, 1.3586, 1.3457, 1.3328,
         1.5914, 1.6078, 1.5964, 1.5928, 1.5998, 1.5901, 1.6085, 1.5619, 1.5667,
         1.2577, 1.2843, 1.2762, 1.2937, 1.2524, 1.2440, 1.2334, 1.3159, 1.2729],
        [1.3888, 1.2469, 1.2361, 1.2779, 1.2782, 1.2903, 1.2843, 1.1960, 1.1960,
         3.5910, 3.6673, 3.5272, 3.8680, 3.5918, 4.1427, 3.4708, 3.5509, 3.9564,
         1.5832, 1.5717, 1.5460, 1.5459, 1.5664, 1.5757, 1.5986, 1.5757, 1.5757,
         1.3612, 1.3289, 1.3248, 1.3787, 1.3232, 1.4138, 1.3952, 1.3660, 1.3217,
         1.5550, 1.6087, 1.5742, 1.5613, 1.5561, 1.5924, 1.6109, 1.4494, 1.5459,
         1.1750, 1.2857, 1.2592, 1.3069, 1.1694, 1.1755, 1.1040, 1.3667, 1.2498],
        [1.4450, 1.4450, 1.4433, 1.4405, 1.4409, 1.4450, 1.4407, 1.4450, 1.4450,
         1.4411, 1.4404, 1.4411, 1.4411, 1.4411, 1.4223, 1.4411, 1.4399, 1.4377,
         2.1960, 2.1964, 2.2133, 2.1890, 2.1703, 2.1686, 2.1979, 2.1676, 2.1676,
         1.5016, 1.5000, 1.5074, 1.5074, 1.5016, 1.5074, 1.5074, 1.5074, 1.5074,
         1.7693, 1.7694, 1.7694, 1.7662, 1.7693, 1.7693, 1.7694, 1.7466, 1.7493,
         1.4520, 1.4566, 1.4566, 1.4566, 1.4483, 1.4566, 1.4527, 1.4566, 1.4566],
        [1.3129, 1.3110, 1.2951, 1.2864, 1.3099, 1.3083, 1.3094, 1.3099, 1.3099,
         1.3068, 1.3002, 1.2963, 1.2958, 1.3074, 1.2920, 1.3036, 1.3070, 1.2796,
         1.6376, 1.6112, 1.6345, 1.6340, 1.6334, 1.6334, 1.6356, 1.6371, 1.6371,
         3.4819, 3.2718, 3.1971, 3.2556, 3.4070, 3.2241, 3.4563, 3.2053, 3.1837,
         1.6422, 1.6348, 1.6331, 1.6362, 1.6392, 1.6152, 1.6405, 1.5800, 1.6064,
         1.3203, 1.3147, 1.3049, 1.3195, 1.3153, 1.3075, 1.3197, 1.3198, 1.3218],
        [1.4479, 1.4435, 1.4001, 1.4037, 1.4412, 1.4478, 1.4463, 1.4479, 1.4479,
         1.4428, 1.4402, 1.4352, 1.4302, 1.4440, 1.4032, 1.4380, 1.4439, 1.4389,
         1.7512, 1.7425, 1.7411, 1.7493, 1.7670, 1.7656, 1.7456, 1.7671, 1.7671,
         1.4683, 1.4735, 1.5102, 1.5050, 1.4737, 1.5088, 1.4971, 1.5102, 1.5071,
         2.1955, 2.1751, 2.1637, 2.1817, 2.2259, 2.2431, 2.2096, 2.3139, 2.3104,
         1.4442, 1.4348, 1.4491, 1.4594, 1.4466, 1.4562, 1.4268, 1.4534, 1.4595],
        [1.4000, 1.3020, 1.2984, 1.3176, 1.3110, 1.3210, 1.3198, 1.2547, 1.2547,
         1.2899, 1.2481, 1.2470, 1.2519, 1.3290, 1.2015, 1.1667, 1.3290, 1.2324,
         1.6261, 1.6025, 1.5848, 1.5786, 1.6014, 1.5977, 1.6188, 1.6029, 1.6029,
         1.3880, 1.3611, 1.3588, 1.3786, 1.3623, 1.4075, 1.4087, 1.3817, 1.3588,
         1.5969, 1.5977, 1.6020, 1.5918, 1.5686, 1.5729, 1.6335, 1.5228, 1.4929,
         3.9945, 3.5730, 3.6577, 3.6432, 3.6548, 3.3474, 3.9880, 3.6204, 3.3784]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 213 : 1781.3858911046173
Test loss for epoch 213 : 193.4399759976529
Test Precision for epoch 213 : 0.26153846153846155
Test Recall for epoch 213 : 0.26153846153846155
Test F1 for epoch 213 : 0.26153846153846155


theta for epoch 214 : tensor([[3.5984, 3.6207, 3.7649, 3.7110, 3.6976, 3.5796, 3.6208, 3.5197, 3.5197,
         1.2672, 1.2474, 1.2462, 1.2491, 1.2847, 1.2283, 1.2011, 1.2847, 1.2347,
         1.5940, 1.5783, 1.6026, 1.5845, 1.5904, 1.5920, 1.5997, 1.5920, 1.5920,
         1.3399, 1.3510, 1.3361, 1.3588, 1.3389, 1.3707, 1.3632, 1.3498, 1.3361,
         1.5910, 1.6076, 1.5960, 1.5925, 1.5995, 1.5899, 1.6085, 1.5616, 1.5664,
         1.2643, 1.2914, 1.2831, 1.3009, 1.2589, 1.2503, 1.2397, 1.3235, 1.2797],
        [1.3795, 1.2357, 1.2250, 1.2670, 1.2673, 1.2795, 1.2734, 1.1839, 1.1839,
         3.5980, 3.6745, 3.5341, 3.8757, 3.5988, 4.1514, 3.4776, 3.5578, 3.9644,
         1.5758, 1.5642, 1.5384, 1.5382, 1.5588, 1.5681, 1.5912, 1.5682, 1.5682,
         1.3542, 1.3218, 1.3175, 1.3718, 1.3159, 1.4072, 1.3884, 1.3590, 1.3143,
         1.5478, 1.6018, 1.5671, 1.5542, 1.5489, 1.5854, 1.6041, 1.4418, 1.5388,
         1.1725, 1.2837, 1.2572, 1.3051, 1.1669, 1.1732, 1.1011, 1.3651, 1.2478],
        [1.4487, 1.4486, 1.4470, 1.4442, 1.4445, 1.4487, 1.4444, 1.4487, 1.4487,
         1.4338, 1.4331, 1.4338, 1.4338, 1.4338, 1.4150, 1.4338, 1.4326, 1.4304,
         2.1961, 2.1965, 2.2134, 2.1892, 2.1704, 2.1687, 2.1980, 2.1677, 2.1677,
         1.5057, 1.5041, 1.5115, 1.5115, 1.5057, 1.5115, 1.5115, 1.5115, 1.5115,
         1.7692, 1.7693, 1.7693, 1.7661, 1.7692, 1.7692, 1.7693, 1.7465, 1.7492,
         1.4584, 1.4630, 1.4630, 1.4630, 1.4547, 1.4630, 1.4590, 1.4629, 1.4630],
        [1.3176, 1.3155, 1.2997, 1.2910, 1.3145, 1.3129, 1.3140, 1.3143, 1.3143,
         1.2997, 1.2931, 1.2892, 1.2887, 1.3004, 1.2849, 1.2964, 1.3000, 1.2724,
         1.6381, 1.6117, 1.6351, 1.6345, 1.6339, 1.6340, 1.6362, 1.6377, 1.6377,
         3.4824, 3.2723, 3.1977, 3.2562, 3.4076, 3.2247, 3.4569, 3.2059, 3.1843,
         1.6424, 1.6350, 1.6332, 1.6364, 1.6393, 1.6154, 1.6407, 1.5801, 1.6066,
         1.3271, 1.3216, 1.3118, 1.3264, 1.3221, 1.3143, 1.3265, 1.3266, 1.3286],
        [1.4515, 1.4471, 1.4036, 1.4073, 1.4448, 1.4514, 1.4499, 1.4515, 1.4515,
         1.4355, 1.4329, 1.4278, 1.4228, 1.4367, 1.3957, 1.4307, 1.4366, 1.4316,
         1.7514, 1.7426, 1.7412, 1.7494, 1.7672, 1.7658, 1.7458, 1.7673, 1.7673,
         1.4724, 1.4774, 1.5143, 1.5090, 1.4778, 1.5128, 1.5012, 1.5143, 1.5112,
         2.1954, 2.1749, 2.1636, 2.1816, 2.2258, 2.2430, 2.2095, 2.3139, 2.3104,
         1.4505, 1.4411, 1.4555, 1.4658, 1.4529, 1.4625, 1.4330, 1.4597, 1.4658],
        [1.3907, 1.2946, 1.2909, 1.3099, 1.3033, 1.3133, 1.3121, 1.2485, 1.2485,
         1.2802, 1.2386, 1.2375, 1.2423, 1.3192, 1.1919, 1.1568, 1.3192, 1.2227,
         1.6225, 1.5990, 1.5812, 1.5754, 1.5981, 1.5945, 1.6152, 1.5996, 1.5996,
         1.3844, 1.3576, 1.3560, 1.3749, 1.3590, 1.4033, 1.4048, 1.3782, 1.3560,
         1.5941, 1.5947, 1.5992, 1.5890, 1.5657, 1.5699, 1.6304, 1.5199, 1.4899,
         4.0037, 3.5813, 3.6661, 3.6516, 3.6632, 3.3556, 3.9971, 3.6287, 3.3867]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 214 : 1781.0425119440322
Test loss for epoch 214 : 193.76764321061847
Test Precision for epoch 214 : 0.26153846153846155
Test Recall for epoch 214 : 0.26153846153846155
Test F1 for epoch 214 : 0.26153846153846155


theta for epoch 215 : tensor([[3.5992, 3.6214, 3.7656, 3.7117, 3.6983, 3.5804, 3.6215, 3.5204, 3.5204,
         1.2631, 1.2426, 1.2413, 1.2443, 1.2814, 1.2232, 1.1940, 1.2814, 1.2294,
         1.5980, 1.5821, 1.6066, 1.5881, 1.5940, 1.5956, 1.6037, 1.5956, 1.5956,
         1.3396, 1.3505, 1.3349, 1.3586, 1.3382, 1.3710, 1.3633, 1.3494, 1.3349,
         1.5931, 1.6099, 1.5981, 1.5946, 1.6017, 1.5921, 1.6109, 1.5637, 1.5685,
         1.2622, 1.2898, 1.2813, 1.2994, 1.2567, 1.2479, 1.2372, 1.3224, 1.2778],
        [1.3654, 1.2191, 1.2087, 1.2509, 1.2512, 1.2634, 1.2573, 1.1662, 1.1662,
         3.6110, 3.6877, 3.5469, 3.8894, 3.6117, 4.1660, 3.4904, 3.5707, 3.9784,
         1.5683, 1.5565, 1.5306, 1.5302, 1.5509, 1.5603, 1.5837, 1.5603, 1.5603,
         1.3410, 1.3083, 1.3037, 1.3587, 1.3024, 1.3944, 1.3755, 1.3457, 1.3005,
         1.5399, 1.5944, 1.5593, 1.5463, 1.5410, 1.5778, 1.5967, 1.4332, 1.5308,
         1.1606, 1.2724, 1.2457, 1.2939, 1.1550, 1.1613, 1.0888, 1.3542, 1.2363],
        [1.4510, 1.4509, 1.4493, 1.4465, 1.4468, 1.4510, 1.4467, 1.4510, 1.4510,
         1.4302, 1.4295, 1.4302, 1.4302, 1.4302, 1.4114, 1.4302, 1.4290, 1.4268,
         2.2001, 2.2005, 2.2174, 2.1930, 2.1742, 2.1725, 2.2018, 2.1715, 2.1715,
         1.5059, 1.5043, 1.5118, 1.5118, 1.5059, 1.5118, 1.5117, 1.5118, 1.5118,
         1.7718, 1.7719, 1.7719, 1.7687, 1.7718, 1.7718, 1.7719, 1.7491, 1.7518,
         1.4564, 1.4610, 1.4610, 1.4610, 1.4527, 1.4610, 1.4570, 1.4610, 1.4610],
        [1.3210, 1.3187, 1.3028, 1.2942, 1.3177, 1.3161, 1.3172, 1.3174, 1.3174,
         1.2964, 1.2897, 1.2859, 1.2854, 1.2971, 1.2815, 1.2929, 1.2967, 1.2691,
         1.6429, 1.6165, 1.6398, 1.6393, 1.6387, 1.6387, 1.6410, 1.6424, 1.6424,
         3.4794, 3.2693, 3.1947, 3.2533, 3.4046, 3.2218, 3.4539, 3.2029, 3.1813,
         1.6454, 1.6379, 1.6362, 1.6393, 1.6423, 1.6183, 1.6437, 1.5831, 1.6095,
         1.3256, 1.3201, 1.3103, 1.3250, 1.3206, 1.3127, 1.3249, 1.3252, 1.3271],
        [1.4538, 1.4493, 1.4057, 1.4097, 1.4471, 1.4537, 1.4521, 1.4538, 1.4538,
         1.4319, 1.4293, 1.4242, 1.4192, 1.4331, 1.3920, 1.4271, 1.4331, 1.4280,
         1.7557, 1.7469, 1.7455, 1.7537, 1.7715, 1.7700, 1.7501, 1.7716, 1.7716,
         1.4726, 1.4775, 1.5145, 1.5092, 1.4780, 1.5131, 1.5014, 1.5146, 1.5115,
         2.1980, 2.1775, 2.1661, 2.1842, 2.2284, 2.2456, 2.2120, 2.3166, 2.3130,
         1.4484, 1.4392, 1.4535, 1.4638, 1.4509, 1.4606, 1.4309, 1.4578, 1.4639],
        [1.3768, 1.2829, 1.2790, 1.2978, 1.2912, 1.3011, 1.2999, 1.2380, 1.2380,
         1.2724, 1.2308, 1.2297, 1.2344, 1.3114, 1.1840, 1.1483, 1.3114, 1.2147,
         1.6209, 1.5975, 1.5794, 1.5742, 1.5969, 1.5933, 1.6137, 1.5984, 1.5984,
         1.3747, 1.3480, 1.3472, 1.3650, 1.3497, 1.3928, 1.3948, 1.3686, 1.3472,
         1.5925, 1.5927, 1.5976, 1.5873, 1.5639, 1.5680, 1.6284, 1.5182, 1.4880,
         4.0130, 3.5898, 3.6747, 3.6603, 3.6719, 3.3641, 4.0065, 3.6373, 3.3952]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 215 : 1780.2588611511424
Test loss for epoch 215 : 194.42467247015162
Test Precision for epoch 215 : 0.26153846153846155
Test Recall for epoch 215 : 0.26153846153846155
Test F1 for epoch 215 : 0.26153846153846155


theta for epoch 216 : tensor([[3.6041, 3.6264, 3.7705, 3.7167, 3.7032, 3.5854, 3.6265, 3.5255, 3.5255,
         1.2618, 1.2403, 1.2390, 1.2423, 1.2809, 1.2208, 1.1892, 1.2809, 1.2268,
         1.6014, 1.5855, 1.6101, 1.5912, 1.5971, 1.5988, 1.6071, 1.5987, 1.5987,
         1.3401, 1.3510, 1.3347, 1.3593, 1.3384, 1.3721, 1.3642, 1.3498, 1.3347,
         1.5954, 1.6124, 1.6004, 1.5968, 1.6041, 1.5945, 1.6134, 1.5661, 1.5708,
         1.2518, 1.2798, 1.2712, 1.2896, 1.2463, 1.2374, 1.2265, 1.3130, 1.2677],
        [1.3497, 1.2005, 1.1903, 1.2327, 1.2331, 1.2453, 1.2392, 1.1460, 1.1460,
         3.6289, 3.7057, 3.5647, 3.9080, 3.6296, 4.1856, 3.5081, 3.5884, 3.9973,
         1.5580, 1.5461, 1.5201, 1.5194, 1.5403, 1.5497, 1.5736, 1.5497, 1.5497,
         1.3257, 1.2928, 1.2876, 1.3436, 1.2867, 1.3799, 1.3606, 1.3303, 1.2845,
         1.5298, 1.5850, 1.5494, 1.5363, 1.5310, 1.5682, 1.5874, 1.4223, 1.5207,
         1.1404, 1.2529, 1.2260, 1.2744, 1.1348, 1.1412, 1.0682, 1.3352, 1.2165],
        [1.4559, 1.4558, 1.4542, 1.4514, 1.4517, 1.4559, 1.4516, 1.4559, 1.4559,
         1.4299, 1.4292, 1.4299, 1.4299, 1.4299, 1.4110, 1.4299, 1.4287, 1.4265,
         2.2041, 2.2045, 2.2214, 2.1968, 2.1780, 2.1763, 2.2055, 2.1753, 2.1753,
         1.5079, 1.5063, 1.5137, 1.5137, 1.5079, 1.5137, 1.5137, 1.5137, 1.5137,
         1.7750, 1.7751, 1.7751, 1.7719, 1.7750, 1.7750, 1.7751, 1.7523, 1.7550,
         1.4468, 1.4514, 1.4514, 1.4514, 1.4431, 1.4514, 1.4474, 1.4514, 1.4514],
        [1.3268, 1.3244, 1.3085, 1.2999, 1.3233, 1.3218, 1.3229, 1.3230, 1.3230,
         1.2964, 1.2896, 1.2858, 1.2853, 1.2971, 1.2814, 1.2927, 1.2967, 1.2689,
         1.6476, 1.6211, 1.6445, 1.6440, 1.6433, 1.6434, 1.6456, 1.6471, 1.6471,
         3.4781, 3.2680, 3.1934, 3.2520, 3.4033, 3.2205, 3.4526, 3.2016, 3.1800,
         1.6488, 1.6414, 1.6396, 1.6428, 1.6458, 1.6218, 1.6472, 1.5865, 1.6130,
         1.3163, 1.3108, 1.3010, 1.3157, 1.3113, 1.3034, 1.3156, 1.3160, 1.3179],
        [1.4587, 1.4542, 1.4105, 1.4146, 1.4520, 1.4586, 1.4570, 1.4587, 1.4587,
         1.4316, 1.4290, 1.4239, 1.4189, 1.4328, 1.3916, 1.4268, 1.4328, 1.4277,
         1.7599, 1.7512, 1.7497, 1.7579, 1.7757, 1.7743, 1.7543, 1.7759, 1.7759,
         1.4746, 1.4793, 1.5165, 1.5112, 1.4799, 1.5150, 1.5034, 1.5165, 1.5134,
         2.2011, 2.1805, 2.1691, 2.1872, 2.2315, 2.2486, 2.2150, 2.3197, 2.3162,
         1.4386, 1.4295, 1.4438, 1.4542, 1.4411, 1.4509, 1.4210, 1.4481, 1.4543],
        [1.3622, 1.2706, 1.2665, 1.2851, 1.2784, 1.2883, 1.2872, 1.2270, 1.2270,
         1.2662, 1.2245, 1.2234, 1.2280, 1.3054, 1.1775, 1.1409, 1.3054, 1.2081,
         1.6177, 1.5943, 1.5759, 1.5713, 1.5941, 1.5904, 1.6104, 1.5956, 1.5956,
         1.3640, 1.3373, 1.3375, 1.3541, 1.3394, 1.3814, 1.3837, 1.3580, 1.3375,
         1.5901, 1.5899, 1.5952, 1.5849, 1.5613, 1.5651, 1.6256, 1.5155, 1.4851,
         4.0226, 3.5986, 3.6836, 3.6691, 3.6807, 3.3728, 4.0162, 3.6461, 3.4039]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 216 : 1779.3196291371173
Test loss for epoch 216 : 195.44716768852658
Test Precision for epoch 216 : 0.26153846153846155
Test Recall for epoch 216 : 0.26153846153846155
Test F1 for epoch 216 : 0.26153846153846155


theta for epoch 217 : tensor([[3.6046, 3.6269, 3.7709, 3.7171, 3.7037, 3.5859, 3.6270, 3.5260, 3.5260,
         1.2605, 1.2385, 1.2372, 1.2406, 1.2801, 1.2189, 1.1860, 1.2801, 1.2248,
         1.6020, 1.5860, 1.6106, 1.5915, 1.5974, 1.5991, 1.6076, 1.5990, 1.5990,
         1.3467, 1.3575, 1.3407, 1.3658, 1.3447, 1.3790, 1.3709, 1.3562, 1.3407,
         1.5966, 1.6137, 1.6016, 1.5980, 1.6053, 1.5958, 1.6148, 1.5673, 1.5721,
         1.2456, 1.2738, 1.2651, 1.2836, 1.2400, 1.2311, 1.2201, 1.3072, 1.2616],
        [1.3642, 1.2129, 1.2030, 1.2455, 1.2459, 1.2581, 1.2520, 1.1573, 1.1573,
         3.6150, 3.6921, 3.5507, 3.8949, 3.6158, 4.1734, 3.4940, 3.5746, 3.9845,
         1.5666, 1.5546, 1.5288, 1.5277, 1.5485, 1.5580, 1.5820, 1.5580, 1.5580,
         1.3392, 1.3062, 1.3006, 1.3571, 1.3000, 1.3937, 1.3743, 1.3437, 1.2974,
         1.5384, 1.5936, 1.5578, 1.5448, 1.5397, 1.5768, 1.5961, 1.4313, 1.5293,
         1.1459, 1.2582, 1.2313, 1.2797, 1.1402, 1.1465, 1.0737, 1.3404, 1.2218],
        [1.4615, 1.4615, 1.4599, 1.4571, 1.4574, 1.4616, 1.4573, 1.4616, 1.4616,
         1.4288, 1.4281, 1.4288, 1.4288, 1.4288, 1.4099, 1.4288, 1.4276, 1.4254,
         2.2044, 2.2049, 2.2218, 2.1971, 2.1783, 2.1766, 2.2058, 2.1757, 2.1757,
         1.5143, 1.5127, 1.5201, 1.5201, 1.5143, 1.5201, 1.5201, 1.5201, 1.5201,
         1.7763, 1.7764, 1.7764, 1.7731, 1.7762, 1.7762, 1.7764, 1.7535, 1.7562,
         1.4399, 1.4446, 1.4446, 1.4446, 1.4362, 1.4446, 1.4405, 1.4445, 1.4446],
        [1.3332, 1.3307, 1.3148, 1.3063, 1.3297, 1.3282, 1.3292, 1.3293, 1.3293,
         1.2955, 1.2887, 1.2849, 1.2844, 1.2963, 1.2805, 1.2917, 1.2959, 1.2680,
         1.6484, 1.6219, 1.6453, 1.6447, 1.6441, 1.6441, 1.6464, 1.6478, 1.6478,
         3.4808, 3.2708, 3.1962, 3.2547, 3.4060, 3.2232, 3.4552, 3.2044, 3.1828,
         1.6503, 1.6429, 1.6411, 1.6443, 1.6472, 1.6233, 1.6487, 1.5880, 1.6145,
         1.3097, 1.3043, 1.2944, 1.3092, 1.3048, 1.2969, 1.3090, 1.3095, 1.3114],
        [1.4643, 1.4598, 1.4160, 1.4203, 1.4576, 1.4643, 1.4627, 1.4644, 1.4644,
         1.4305, 1.4279, 1.4228, 1.4177, 1.4317, 1.3904, 1.4257, 1.4317, 1.4265,
         1.7603, 1.7516, 1.7501, 1.7583, 1.7762, 1.7747, 1.7548, 1.7763, 1.7763,
         1.4810, 1.4856, 1.5229, 1.5175, 1.4863, 1.5214, 1.5098, 1.5229, 1.5198,
         2.2023, 2.1817, 2.1703, 2.1884, 2.2327, 2.2498, 2.2162, 2.3211, 2.3175,
         1.4316, 1.4226, 1.4369, 1.4474, 1.4342, 1.4441, 1.4140, 1.4413, 1.4474],
        [1.3498, 1.2612, 1.2568, 1.2751, 1.2684, 1.2783, 1.2772, 1.2194, 1.2194,
         1.2600, 1.2187, 1.2176, 1.2220, 1.2989, 1.1716, 1.1354, 1.2989, 1.2022,
         1.6118, 1.5885, 1.5698, 1.5659, 1.5887, 1.5851, 1.6046, 1.5902, 1.5902,
         1.3585, 1.3319, 1.3331, 1.3483, 1.3343, 1.3750, 1.3777, 1.3526, 1.3332,
         1.5868, 1.5860, 1.5918, 1.5815, 1.5577, 1.5613, 1.6217, 1.5119, 1.4812,
         4.0313, 3.6065, 3.6916, 3.6770, 3.6887, 3.3806, 4.0249, 3.6541, 3.4117]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 217 : 1779.782259937851
Test loss for epoch 217 : 194.77246997082173
Test Precision for epoch 217 : 0.26153846153846155
Test Recall for epoch 217 : 0.26153846153846155
Test F1 for epoch 217 : 0.26153846153846155


theta for epoch 218 : tensor([[3.6043, 3.6265, 3.7705, 3.7168, 3.7033, 3.5856, 3.6266, 3.5257, 3.5257,
         1.2628, 1.2403, 1.2389, 1.2424, 1.2829, 1.2205, 1.1862, 1.2829, 1.2263,
         1.5986, 1.5825, 1.6072, 1.5879, 1.5939, 1.5955, 1.6041, 1.5955, 1.5955,
         1.3477, 1.3584, 1.3413, 1.3669, 1.3456, 1.3803, 1.3720, 1.3572, 1.3414,
         1.5946, 1.6118, 1.5996, 1.5961, 1.6034, 1.5939, 1.6130, 1.5653, 1.5701,
         1.2453, 1.2736, 1.2649, 1.2835, 1.2397, 1.2307, 1.2197, 1.3071, 1.2613],
        [1.3695, 1.2162, 1.2066, 1.2492, 1.2495, 1.2617, 1.2556, 1.1594, 1.1594,
         3.6091, 3.6863, 3.5447, 3.8897, 3.6099, 4.1691, 3.4878, 3.5686, 3.9796,
         1.5682, 1.5561, 1.5305, 1.5290, 1.5497, 1.5591, 1.5835, 1.5591, 1.5591,
         1.3449, 1.3118, 1.3055, 1.3628, 1.3054, 1.3999, 1.3803, 1.3493, 1.3024,
         1.5403, 1.5957, 1.5597, 1.5467, 1.5417, 1.5790, 1.5984, 1.4335, 1.5313,
         1.1508, 1.2635, 1.2365, 1.2851, 1.1451, 1.1512, 1.0784, 1.3461, 1.2269],
        [1.4602, 1.4602, 1.4585, 1.4557, 1.4560, 1.4602, 1.4560, 1.4602, 1.4603,
         1.4318, 1.4311, 1.4318, 1.4318, 1.4318, 1.4129, 1.4318, 1.4306, 1.4284,
         2.2016, 2.2021, 2.2190, 2.1945, 2.1756, 2.1739, 2.2032, 2.1730, 2.1730,
         1.5161, 1.5146, 1.5220, 1.5220, 1.5162, 1.5220, 1.5220, 1.5220, 1.5220,
         1.7748, 1.7749, 1.7749, 1.7716, 1.7748, 1.7748, 1.7749, 1.7520, 1.7547,
         1.4394, 1.4441, 1.4441, 1.4441, 1.4357, 1.4441, 1.4400, 1.4441, 1.4441],
        [1.3322, 1.3296, 1.3137, 1.3052, 1.3286, 1.3271, 1.3282, 1.3281, 1.3281,
         1.2987, 1.2919, 1.2880, 1.2876, 1.2995, 1.2836, 1.2948, 1.2991, 1.2711,
         1.6457, 1.6192, 1.6426, 1.6420, 1.6414, 1.6415, 1.6438, 1.6452, 1.6452,
         3.4801, 3.2701, 3.1956, 3.2541, 3.4053, 3.2226, 3.4546, 3.2037, 3.1822,
         1.6490, 1.6416, 1.6398, 1.6429, 1.6459, 1.6220, 1.6473, 1.5867, 1.6132,
         1.3096, 1.3042, 1.2943, 1.3091, 1.3046, 1.2967, 1.3089, 1.3094, 1.3112],
        [1.4630, 1.4583, 1.4144, 1.4188, 1.4562, 1.4629, 1.4613, 1.4631, 1.4631,
         1.4335, 1.4309, 1.4258, 1.4207, 1.4347, 1.3933, 1.4287, 1.4347, 1.4295,
         1.7575, 1.7487, 1.7471, 1.7554, 1.7733, 1.7719, 1.7519, 1.7735, 1.7735,
         1.4828, 1.4874, 1.5248, 1.5193, 1.4881, 1.5232, 1.5117, 1.5248, 1.5217,
         2.2008, 2.1802, 2.1688, 2.1870, 2.2313, 2.2483, 2.2147, 2.3197, 2.3162,
         1.4311, 1.4221, 1.4364, 1.4469, 1.4337, 1.4436, 1.4134, 1.4408, 1.4470],
        [1.3307, 1.2449, 1.2402, 1.2583, 1.2515, 1.2614, 1.2604, 1.2047, 1.2047,
         1.2565, 1.2153, 1.2142, 1.2185, 1.2952, 1.1681, 1.1316, 1.2953, 1.1986,
         1.6014, 1.5782, 1.5594, 1.5561, 1.5789, 1.5753, 1.5943, 1.5804, 1.5804,
         1.3476, 1.3210, 1.3232, 1.3371, 1.3237, 1.3632, 1.3663, 1.3418, 1.3233,
         1.5796, 1.5784, 1.5847, 1.5743, 1.5503, 1.5537, 1.6140, 1.5045, 1.4736,
         4.0455, 3.6200, 3.7051, 3.6906, 3.7023, 3.3941, 4.0392, 3.6676, 3.4252]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 218 : 1779.6483516437795
Test loss for epoch 218 : 194.8686324311127
Test Precision for epoch 218 : 0.26153846153846155
Test Recall for epoch 218 : 0.26153846153846155
Test F1 for epoch 218 : 0.26153846153846155


theta for epoch 219 : tensor([[3.6064, 3.6286, 3.7726, 3.7189, 3.7054, 3.5877, 3.6288, 3.5279, 3.5279,
         1.2674, 1.2443, 1.2429, 1.2466, 1.2880, 1.2244, 1.1887, 1.2880, 1.2301,
         1.5953, 1.5792, 1.6039, 1.5844, 1.5905, 1.5921, 1.6008, 1.5921, 1.5921,
         1.3421, 1.3529, 1.3356, 1.3614, 1.3400, 1.3749, 1.3666, 1.3516, 1.3357,
         1.5911, 1.6083, 1.5960, 1.5925, 1.5998, 1.5904, 1.6095, 1.5618, 1.5666,
         1.2453, 1.2738, 1.2650, 1.2836, 1.2397, 1.2308, 1.2196, 1.3074, 1.2615],
        [1.3692, 1.2140, 1.2045, 1.2472, 1.2476, 1.2597, 1.2536, 1.1561, 1.1561,
         3.6102, 3.6876, 3.5457, 3.8915, 3.6110, 4.1719, 3.4888, 3.5696, 3.9817,
         1.5659, 1.5537, 1.5283, 1.5263, 1.5470, 1.5565, 1.5812, 1.5565, 1.5565,
         1.3422, 1.3091, 1.3022, 1.3603, 1.3025, 1.3977, 1.3779, 1.3465, 1.2991,
         1.5373, 1.5929, 1.5567, 1.5437, 1.5387, 1.5761, 1.5957, 1.4305, 1.5283,
         1.1515, 1.2648, 1.2376, 1.2866, 1.1457, 1.1516, 1.0787, 1.3481, 1.2279],
        [1.4583, 1.4583, 1.4566, 1.4538, 1.4541, 1.4583, 1.4541, 1.4584, 1.4584,
         1.4374, 1.4367, 1.4374, 1.4374, 1.4374, 1.4185, 1.4374, 1.4362, 1.4340,
         2.1994, 2.1999, 2.2168, 2.1923, 2.1735, 2.1718, 2.2010, 2.1708, 2.1708,
         1.5123, 1.5107, 1.5182, 1.5182, 1.5123, 1.5182, 1.5181, 1.5182, 1.5182,
         1.7720, 1.7721, 1.7721, 1.7689, 1.7720, 1.7720, 1.7721, 1.7492, 1.7519,
         1.4400, 1.4447, 1.4447, 1.4447, 1.4363, 1.4447, 1.4406, 1.4447, 1.4447],
        [1.3305, 1.3278, 1.3119, 1.3034, 1.3268, 1.3253, 1.3264, 1.3263, 1.3263,
         1.3044, 1.2976, 1.2937, 1.2933, 1.3053, 1.2893, 1.3004, 1.3048, 1.2768,
         1.6436, 1.6171, 1.6405, 1.6399, 1.6393, 1.6393, 1.6416, 1.6430, 1.6430,
         3.4751, 3.2651, 3.1905, 3.2491, 3.4003, 3.2176, 3.4495, 3.1987, 3.1771,
         1.6464, 1.6390, 1.6372, 1.6403, 1.6433, 1.6194, 1.6447, 1.5841, 1.6106,
         1.3104, 1.3050, 1.2951, 1.3099, 1.3054, 1.2975, 1.3096, 1.3103, 1.3120],
        [1.4611, 1.4564, 1.4124, 1.4168, 1.4543, 1.4611, 1.4594, 1.4612, 1.4612,
         1.4391, 1.4365, 1.4314, 1.4263, 1.4403, 1.3989, 1.4343, 1.4402, 1.4351,
         1.7551, 1.7464, 1.7448, 1.7530, 1.7710, 1.7696, 1.7496, 1.7712, 1.7712,
         1.4789, 1.4834, 1.5209, 1.5155, 1.4842, 1.5194, 1.5078, 1.5210, 1.5179,
         2.1982, 2.1776, 2.1661, 2.1843, 2.2286, 2.2457, 2.2120, 2.3172, 2.3136,
         1.4316, 1.4226, 1.4370, 1.4475, 1.4342, 1.4442, 1.4138, 1.4414, 1.4476],
        [1.3113, 1.2276, 1.2225, 1.2405, 1.2337, 1.2437, 1.2426, 1.1886, 1.1886,
         1.2546, 1.2133, 1.2122, 1.2164, 1.2936, 1.1658, 1.1287, 1.2936, 1.1964,
         1.5908, 1.5676, 1.5486, 1.5458, 1.5687, 1.5650, 1.5837, 1.5702, 1.5702,
         1.3310, 1.3044, 1.3074, 1.3203, 1.3073, 1.3459, 1.3494, 1.3252, 1.3075,
         1.5704, 1.5688, 1.5755, 1.5651, 1.5409, 1.5441, 1.6045, 1.4950, 1.4638,
         4.0624, 3.6361, 3.7213, 3.7067, 3.7185, 3.4101, 4.0561, 3.6837, 3.4412]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 219 : 1779.4637285593717
Test loss for epoch 219 : 195.54001570884094
Test Precision for epoch 219 : 0.26153846153846155
Test Recall for epoch 219 : 0.26153846153846155
Test F1 for epoch 219 : 0.26153846153846155


theta for epoch 220 : tensor([[3.6147, 3.6370, 3.7809, 3.7272, 3.7137, 3.5961, 3.6372, 3.5365, 3.5365,
         1.2687, 1.2452, 1.2438, 1.2476, 1.2898, 1.2252, 1.1883, 1.2898, 1.2308,
         1.5949, 1.5788, 1.6036, 1.5841, 1.5901, 1.5917, 1.6005, 1.5917, 1.5917,
         1.3406, 1.3514, 1.3342, 1.3599, 1.3386, 1.3734, 1.3651, 1.3502, 1.3342,
         1.5888, 1.6060, 1.5937, 1.5902, 1.5975, 1.5881, 1.6072, 1.5595, 1.5642,
         1.2379, 1.2664, 1.2576, 1.2763, 1.2323, 1.2234, 1.2122, 1.3001, 1.2541],
        [1.3667, 1.2097, 1.2003, 1.2432, 1.2436, 1.2558, 1.2497, 1.1508, 1.1508,
         3.6162, 3.6938, 3.5516, 3.8982, 3.6170, 4.1795, 3.4946, 3.5756, 3.9887,
         1.5623, 1.5500, 1.5246, 1.5223, 1.5431, 1.5525, 1.5776, 1.5526, 1.5526,
         1.3378, 1.3046, 1.2972, 1.3560, 1.2978, 1.3938, 1.3738, 1.3420, 1.2941,
         1.5319, 1.5879, 1.5514, 1.5383, 1.5335, 1.5710, 1.5909, 1.4250, 1.5230,
         1.1427, 1.2566, 1.2292, 1.2786, 1.1367, 1.1425, 1.0695, 1.3406, 1.2194],
        [1.4620, 1.4620, 1.4604, 1.4576, 1.4578, 1.4621, 1.4578, 1.4621, 1.4621,
         1.4401, 1.4394, 1.4401, 1.4401, 1.4401, 1.4212, 1.4401, 1.4389, 1.4367,
         2.2004, 2.2009, 2.2177, 2.1933, 2.1744, 2.1727, 2.2019, 2.1717, 2.1717,
         1.5132, 1.5117, 1.5191, 1.5191, 1.5132, 1.5191, 1.5190, 1.5191, 1.5191,
         1.7709, 1.7710, 1.7710, 1.7677, 1.7709, 1.7709, 1.7710, 1.7480, 1.7508,
         1.4338, 1.4386, 1.4386, 1.4386, 1.4302, 1.4386, 1.4344, 1.4386, 1.4386],
        [1.3341, 1.3315, 1.3155, 1.3070, 1.3305, 1.3289, 1.3300, 1.3300, 1.3300,
         1.3072, 1.3003, 1.2965, 1.2960, 1.3080, 1.2921, 1.3031, 1.3076, 1.2796,
         1.6447, 1.6182, 1.6416, 1.6410, 1.6404, 1.6404, 1.6427, 1.6441, 1.6441,
         3.4747, 3.2648, 3.1903, 3.2488, 3.3999, 3.2174, 3.4492, 3.1985, 3.1769,
         1.6453, 1.6379, 1.6361, 1.6392, 1.6422, 1.6183, 1.6436, 1.5829, 1.6095,
         1.3043, 1.2989, 1.2890, 1.3038, 1.2993, 1.2914, 1.3035, 1.3042, 1.3060],
        [1.4648, 1.4601, 1.4160, 1.4205, 1.4580, 1.4648, 1.4631, 1.4649, 1.4649,
         1.4418, 1.4392, 1.4341, 1.4290, 1.4430, 1.4015, 1.4370, 1.4430, 1.4378,
         1.7562, 1.7475, 1.7458, 1.7541, 1.7721, 1.7706, 1.7506, 1.7722, 1.7722,
         1.4798, 1.4843, 1.5218, 1.5164, 1.4851, 1.5203, 1.5087, 1.5219, 1.5188,
         2.1970, 2.1764, 2.1649, 2.1832, 2.2275, 2.2446, 2.2109, 2.3161, 2.3126,
         1.4254, 1.4165, 1.4308, 1.4414, 1.4280, 1.4381, 1.4076, 1.4352, 1.4414],
        [1.2975, 1.2147, 1.2095, 1.2275, 1.2206, 1.2306, 1.2295, 1.1764, 1.1764,
         1.2497, 1.2080, 1.2068, 1.2111, 1.2892, 1.1602, 1.1218, 1.2892, 1.1907,
         1.5829, 1.5597, 1.5405, 1.5379, 1.5610, 1.5573, 1.5758, 1.5625, 1.5625,
         1.3183, 1.2916, 1.2952, 1.3075, 1.2948, 1.3329, 1.3366, 1.3126, 1.2952,
         1.5622, 1.5603, 1.5672, 1.5568, 1.5324, 1.5356, 1.5960, 1.4864, 1.4550,
         4.0779, 3.6507, 3.7361, 3.7215, 3.7333, 3.4248, 4.0716, 3.6984, 3.4558]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 220 : 1779.1108037368065
Test loss for epoch 220 : 196.21774664035715
Test Precision for epoch 220 : 0.26153846153846155
Test Recall for epoch 220 : 0.26153846153846155
Test F1 for epoch 220 : 0.26153846153846155


theta for epoch 221 : tensor([[3.6259, 3.6484, 3.7921, 3.7385, 3.7250, 3.6075, 3.6485, 3.5481, 3.5481,
         1.2634, 1.2395, 1.2381, 1.2420, 1.2848, 1.2198, 1.1816, 1.2848, 1.2249,
         1.5976, 1.5815, 1.6062, 1.5868, 1.5928, 1.5945, 1.6032, 1.5944, 1.5944,
         1.3457, 1.3566, 1.3396, 1.3650, 1.3438, 1.3783, 1.3701, 1.3553, 1.3396,
         1.5896, 1.6068, 1.5946, 1.5910, 1.5984, 1.5889, 1.6080, 1.5603, 1.5650,
         1.2274, 1.2559, 1.2471, 1.2658, 1.2218, 1.2129, 1.2016, 1.2895, 1.2436],
        [1.3616, 1.2031, 1.1939, 1.2370, 1.2373, 1.2495, 1.2435, 1.1437, 1.1437,
         3.6237, 3.7015, 3.5590, 3.9065, 3.6245, 4.1887, 3.5020, 3.5830, 3.9972,
         1.5589, 1.5465, 1.5211, 1.5185, 1.5394, 1.5489, 1.5742, 1.5489, 1.5489,
         1.3349, 1.3014, 1.2938, 1.3531, 1.2945, 1.3913, 1.3711, 1.3391, 1.2906,
         1.5273, 1.5837, 1.5469, 1.5338, 1.5289, 1.5667, 1.5867, 1.4200, 1.5184,
         1.1290, 1.2436, 1.2159, 1.2658, 1.1229, 1.1285, 1.0553, 1.3284, 1.2060],
        [1.4665, 1.4664, 1.4648, 1.4620, 1.4622, 1.4665, 1.4622, 1.4665, 1.4665,
         1.4364, 1.4357, 1.4364, 1.4363, 1.4364, 1.4174, 1.4364, 1.4352, 1.4329,
         2.2044, 2.2049, 2.2218, 2.1972, 2.1783, 2.1766, 2.2058, 2.1756, 2.1756,
         1.5212, 1.5196, 1.5270, 1.5270, 1.5212, 1.5270, 1.5270, 1.5270, 1.5270,
         1.7731, 1.7732, 1.7732, 1.7699, 1.7730, 1.7730, 1.7732, 1.7502, 1.7529,
         1.4252, 1.4300, 1.4299, 1.4300, 1.4215, 1.4299, 1.4257, 1.4299, 1.4300],
        [1.3381, 1.3356, 1.3196, 1.3111, 1.3346, 1.3330, 1.3341, 1.3341, 1.3341,
         1.3034, 1.2965, 1.2927, 1.2922, 1.3043, 1.2883, 1.2992, 1.3038, 1.2757,
         1.6490, 1.6226, 1.6460, 1.6454, 1.6447, 1.6448, 1.6471, 1.6485, 1.6485,
         3.4812, 3.2715, 3.1970, 3.2555, 3.4065, 3.2240, 3.4557, 3.2052, 3.1837,
         1.6474, 1.6400, 1.6383, 1.6414, 1.6444, 1.6204, 1.6458, 1.5851, 1.6116,
         1.2955, 1.2901, 1.2802, 1.2951, 1.2905, 1.2826, 1.2948, 1.2954, 1.2972],
        [1.4692, 1.4646, 1.4205, 1.4249, 1.4625, 1.4692, 1.4675, 1.4693, 1.4693,
         1.4381, 1.4354, 1.4303, 1.4252, 1.4392, 1.3978, 1.4333, 1.4392, 1.4341,
         1.7605, 1.7518, 1.7501, 1.7584, 1.7764, 1.7749, 1.7549, 1.7766, 1.7766,
         1.4878, 1.4923, 1.5298, 1.5243, 1.4931, 1.5282, 1.5167, 1.5298, 1.5267,
         2.1991, 2.1785, 2.1670, 2.1853, 2.2296, 2.2466, 2.2130, 2.3182, 2.3147,
         1.4167, 1.4078, 1.4222, 1.4327, 1.4194, 1.4294, 1.3989, 1.4266, 1.4328],
        [1.2869, 1.2039, 1.1986, 1.2167, 1.2098, 1.2199, 1.2188, 1.1656, 1.1656,
         1.2390, 1.1966, 1.1953, 1.1998, 1.2792, 1.1494, 1.1085, 1.2792, 1.1790,
         1.5783, 1.5550, 1.5356, 1.5332, 1.5564, 1.5526, 1.5711, 1.5579, 1.5579,
         1.3126, 1.2858, 1.2895, 1.3018, 1.2890, 1.3273, 1.3310, 1.3069, 1.2896,
         1.5570, 1.5550, 1.5621, 1.5516, 1.5271, 1.5302, 1.5910, 1.4809, 1.4492,
         4.0926, 3.6646, 3.7500, 3.7354, 3.7473, 3.4385, 4.0864, 3.7122, 3.4695]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 221 : 1778.4901961121948
Test loss for epoch 221 : 196.68738466116702
Test Precision for epoch 221 : 0.26153846153846155
Test Recall for epoch 221 : 0.26153846153846155
Test F1 for epoch 221 : 0.26153846153846155


theta for epoch 222 : tensor([[3.6285, 3.6510, 3.7946, 3.7410, 3.7275, 3.6102, 3.6511, 3.5508, 3.5508,
         1.2563, 1.2325, 1.2310, 1.2349, 1.2776, 1.2131, 1.1747, 1.2776, 1.2179,
         1.6016, 1.5856, 1.6103, 1.5910, 1.5971, 1.5987, 1.6072, 1.5987, 1.5987,
         1.3509, 1.3618, 1.3452, 1.3701, 1.3491, 1.3831, 1.3751, 1.3606, 1.3453,
         1.5939, 1.6110, 1.5989, 1.5954, 1.6026, 1.5931, 1.6121, 1.5646, 1.5693,
         1.2237, 1.2517, 1.2431, 1.2614, 1.2183, 1.2096, 1.1983, 1.2846, 1.2397],
        [1.3600, 1.2016, 1.1923, 1.2354, 1.2358, 1.2480, 1.2419, 1.1421, 1.1421,
         3.6233, 3.7012, 3.5584, 3.9067, 3.6240, 4.1898, 3.5013, 3.5825, 3.9978,
         1.5609, 1.5484, 1.5230, 1.5204, 1.5413, 1.5508, 1.5762, 1.5508, 1.5508,
         1.3371, 1.3035, 1.2958, 1.3554, 1.2965, 1.3937, 1.3735, 1.3413, 1.2926,
         1.5298, 1.5864, 1.5494, 1.5363, 1.5314, 1.5693, 1.5894, 1.4223, 1.5209,
         1.1256, 1.2395, 1.2121, 1.2615, 1.1196, 1.1254, 1.0521, 1.3237, 1.2023],
        [1.4651, 1.4650, 1.4634, 1.4606, 1.4608, 1.4651, 1.4608, 1.4651, 1.4651,
         1.4299, 1.4292, 1.4299, 1.4299, 1.4299, 1.4110, 1.4299, 1.4287, 1.4265,
         2.2087, 2.2092, 2.2261, 2.2013, 2.1824, 2.1807, 2.2099, 2.1798, 2.1798,
         1.5274, 1.5258, 1.5332, 1.5332, 1.5274, 1.5332, 1.5332, 1.5332, 1.5332,
         1.7777, 1.7778, 1.7778, 1.7745, 1.7776, 1.7776, 1.7778, 1.7548, 1.7575,
         1.4216, 1.4264, 1.4264, 1.4264, 1.4179, 1.4263, 1.4221, 1.4263, 1.4264],
        [1.3360, 1.3335, 1.3176, 1.3090, 1.3325, 1.3310, 1.3321, 1.3322, 1.3322,
         1.2968, 1.2900, 1.2861, 1.2857, 1.2977, 1.2817, 1.2927, 1.2973, 1.2692,
         1.6535, 1.6271, 1.6505, 1.6498, 1.6492, 1.6493, 1.6516, 1.6529, 1.6529,
         3.4869, 3.2773, 3.2029, 3.2613, 3.4122, 3.2299, 3.4614, 3.2110, 3.1896,
         1.6520, 1.6446, 1.6428, 1.6459, 1.6489, 1.6250, 1.6503, 1.5897, 1.6162,
         1.2918, 1.2864, 1.2765, 1.2913, 1.2868, 1.2789, 1.2911, 1.2916, 1.2934],
        [1.4679, 1.4632, 1.4191, 1.4234, 1.4611, 1.4678, 1.4661, 1.4679, 1.4679,
         1.4316, 1.4290, 1.4239, 1.4188, 1.4328, 1.3913, 1.4268, 1.4328, 1.4276,
         1.7651, 1.7563, 1.7547, 1.7629, 1.7810, 1.7795, 1.7595, 1.7811, 1.7811,
         1.4940, 1.4986, 1.5360, 1.5305, 1.4993, 1.5344, 1.5229, 1.5360, 1.5329,
         2.2036, 2.1830, 2.1715, 2.1897, 2.2340, 2.2511, 2.2174, 2.3226, 2.3190,
         1.4132, 1.4042, 1.4186, 1.4291, 1.4158, 1.4258, 1.3954, 1.4230, 1.4292],
        [1.3012, 1.2183, 1.2130, 1.2311, 1.2242, 1.2343, 1.2331, 1.1800, 1.1800,
         1.2387, 1.1965, 1.1952, 1.1996, 1.2786, 1.1502, 1.1086, 1.2786, 1.1788,
         1.5901, 1.5669, 1.5476, 1.5451, 1.5682, 1.5645, 1.5830, 1.5697, 1.5697,
         1.3292, 1.3024, 1.3060, 1.3184, 1.3055, 1.3439, 1.3476, 1.3235, 1.3060,
         1.5679, 1.5659, 1.5730, 1.5625, 1.5380, 1.5412, 1.6017, 1.4920, 1.4605,
         4.0757, 3.6468, 3.7323, 3.7177, 3.7297, 3.4206, 4.0695, 3.6946, 3.4517]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 222 : 1779.153472475083
Test loss for epoch 222 : 195.8534124284813
Test Precision for epoch 222 : 0.26153846153846155
Test Recall for epoch 222 : 0.26153846153846155
Test F1 for epoch 222 : 0.26153846153846155


theta for epoch 223 : tensor([[3.6265, 3.6489, 3.7925, 3.7389, 3.7253, 3.6081, 3.6491, 3.5487, 3.5487,
         1.2536, 1.2303, 1.2289, 1.2326, 1.2746, 1.2112, 1.1735, 1.2746, 1.2158,
         1.6011, 1.5851, 1.6097, 1.5907, 1.5967, 1.5984, 1.6067, 1.5983, 1.5983,
         1.3417, 1.3527, 1.3367, 1.3609, 1.3402, 1.3736, 1.3657, 1.3515, 1.3367,
         1.5971, 1.6140, 1.6020, 1.5985, 1.6057, 1.5961, 1.6151, 1.5677, 1.5724,
         1.2330, 1.2603, 1.2520, 1.2699, 1.2277, 1.2192, 1.2079, 1.2926, 1.2486],
        [1.3616, 1.2041, 1.1947, 1.2378, 1.2381, 1.2503, 1.2443, 1.1450, 1.1450,
         3.6177, 3.6959, 3.5528, 3.9018, 3.6186, 4.1859, 3.4955, 3.5769, 3.9932,
         1.5637, 1.5513, 1.5259, 1.5233, 1.5442, 1.5537, 1.5791, 1.5537, 1.5537,
         1.3360, 1.3025, 1.2949, 1.3543, 1.2956, 1.3925, 1.3723, 1.3402, 1.2917,
         1.5353, 1.5918, 1.5549, 1.5418, 1.5370, 1.5748, 1.5949, 1.4279, 1.5264,
         1.1354, 1.2491, 1.2217, 1.2710, 1.1295, 1.1355, 1.0620, 1.3328, 1.2120],
        [1.4582, 1.4582, 1.4565, 1.4537, 1.4540, 1.4582, 1.4539, 1.4582, 1.4582,
         1.4276, 1.4269, 1.4276, 1.4276, 1.4276, 1.4087, 1.4276, 1.4264, 1.4241,
         2.2084, 2.2089, 2.2258, 2.2010, 2.1822, 2.1805, 2.2096, 2.1795, 2.1795,
         1.5187, 1.5172, 1.5246, 1.5246, 1.5188, 1.5246, 1.5246, 1.5246, 1.5246,
         1.7807, 1.7808, 1.7808, 1.7776, 1.7807, 1.7807, 1.7808, 1.7579, 1.7606,
         1.4305, 1.4353, 1.4353, 1.4353, 1.4269, 1.4353, 1.4311, 1.4352, 1.4353],
        [1.3281, 1.3259, 1.3099, 1.3012, 1.3248, 1.3232, 1.3244, 1.3246, 1.3246,
         1.2944, 1.2875, 1.2837, 1.2832, 1.2953, 1.2793, 1.2902, 1.2948, 1.2668,
         1.6530, 1.6266, 1.6499, 1.6493, 1.6487, 1.6487, 1.6510, 1.6524, 1.6524,
         3.4804, 3.2709, 3.1965, 3.2549, 3.4058, 3.2235, 3.4550, 3.2046, 3.1831,
         1.6549, 1.6475, 1.6458, 1.6489, 1.6519, 1.6279, 1.6533, 1.5927, 1.6192,
         1.3005, 1.2951, 1.2852, 1.3000, 1.2956, 1.2877, 1.2999, 1.3004, 1.3022],
        [1.4610, 1.4564, 1.4124, 1.4165, 1.4542, 1.4610, 1.4593, 1.4611, 1.4611,
         1.4293, 1.4267, 1.4216, 1.4165, 1.4305, 1.3891, 1.4245, 1.4305, 1.4253,
         1.7647, 1.7560, 1.7544, 1.7626, 1.7806, 1.7791, 1.7592, 1.7808, 1.7808,
         1.4853, 1.4900, 1.5274, 1.5219, 1.4907, 1.5258, 1.5142, 1.5274, 1.5243,
         2.2065, 2.1859, 2.1744, 2.1926, 2.2369, 2.2540, 2.2203, 2.3254, 2.3219,
         1.4222, 1.4132, 1.4275, 1.4381, 1.4248, 1.4348, 1.4044, 1.4319, 1.4381],
        [1.3128, 1.2295, 1.2242, 1.2424, 1.2355, 1.2456, 1.2445, 1.1909, 1.1909,
         1.2422, 1.2007, 1.1996, 1.2037, 1.2815, 1.1554, 1.1143, 1.2815, 1.1833,
         1.5975, 1.5743, 1.5551, 1.5525, 1.5755, 1.5718, 1.5904, 1.5770, 1.5770,
         1.3338, 1.3072, 1.3103, 1.3231, 1.3101, 1.3488, 1.3522, 1.3281, 1.3104,
         1.5772, 1.5754, 1.5822, 1.5718, 1.5475, 1.5506, 1.6110, 1.5016, 1.4703,
         4.0642, 3.6346, 3.7201, 3.7055, 3.7175, 3.4081, 4.0581, 3.6824, 3.4393]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 223 : 1779.2447858535704
Test loss for epoch 223 : 195.46556529922094
Test Precision for epoch 223 : 0.26153846153846155
Test Recall for epoch 223 : 0.26153846153846155
Test F1 for epoch 223 : 0.26153846153846155


theta for epoch 224 : tensor([[3.6226, 3.6449, 3.7886, 3.7350, 3.7214, 3.6042, 3.6452, 3.5448, 3.5448,
         1.2567, 1.2337, 1.2323, 1.2359, 1.2773, 1.2153, 1.1790, 1.2774, 1.2198,
         1.5943, 1.5783, 1.6028, 1.5841, 1.5901, 1.5918, 1.5999, 1.5917, 1.5917,
         1.3324, 1.3435, 1.3281, 1.3515, 1.3312, 1.3638, 1.3561, 1.3423, 1.3281,
         1.5933, 1.6101, 1.5983, 1.5947, 1.6019, 1.5922, 1.6111, 1.5639, 1.5687,
         1.2484, 1.2753, 1.2671, 1.2847, 1.2432, 1.2349, 1.2236, 1.3070, 1.2639],
        [1.3681, 1.2120, 1.2025, 1.2454, 1.2458, 1.2580, 1.2519, 1.1536, 1.1536,
         3.6088, 3.6871, 3.5438, 3.8936, 3.6097, 4.1785, 3.4862, 3.5679, 3.9852,
         1.5652, 1.5528, 1.5275, 1.5250, 1.5458, 1.5552, 1.5804, 1.5552, 1.5552,
         1.3388, 1.3054, 1.2979, 1.3569, 1.2986, 1.3949, 1.3748, 1.3430, 1.2948,
         1.5382, 1.5944, 1.5577, 1.5446, 1.5398, 1.5775, 1.5974, 1.4312, 1.5293,
         1.1529, 1.2663, 1.2391, 1.2882, 1.1471, 1.1532, 1.0795, 1.3498, 1.2294],
        [1.4518, 1.4517, 1.4500, 1.4472, 1.4475, 1.4517, 1.4474, 1.4517, 1.4517,
         1.4306, 1.4299, 1.4306, 1.4305, 1.4306, 1.4117, 1.4306, 1.4294, 1.4271,
         2.2019, 2.2024, 2.2192, 2.1947, 2.1759, 2.1742, 2.2034, 2.1732, 2.1732,
         1.5092, 1.5077, 1.5151, 1.5151, 1.5092, 1.5151, 1.5151, 1.5151, 1.5151,
         1.7766, 1.7767, 1.7767, 1.7735, 1.7766, 1.7766, 1.7767, 1.7538, 1.7565,
         1.4453, 1.4501, 1.4501, 1.4501, 1.4417, 1.4501, 1.4459, 1.4500, 1.4501],
        [1.3206, 1.3185, 1.3025, 1.2938, 1.3174, 1.3158, 1.3170, 1.3173, 1.3173,
         1.2972, 1.2903, 1.2865, 1.2861, 1.2981, 1.2822, 1.2932, 1.2976, 1.2696,
         1.6457, 1.6193, 1.6426, 1.6420, 1.6414, 1.6415, 1.6437, 1.6451, 1.6451,
         3.4736, 3.2641, 3.1897, 3.2481, 3.3989, 3.2168, 3.4483, 3.1979, 3.1763,
         1.6506, 1.6432, 1.6415, 1.6446, 1.6476, 1.6237, 1.6490, 1.5884, 1.6149,
         1.3152, 1.3097, 1.2999, 1.3146, 1.3102, 1.3023, 1.3145, 1.3149, 1.3168],
        [1.4546, 1.4500, 1.4060, 1.4099, 1.4478, 1.4545, 1.4529, 1.4546, 1.4546,
         1.4323, 1.4297, 1.4246, 1.4195, 1.4335, 1.3921, 1.4275, 1.4334, 1.4283,
         1.7578, 1.7491, 1.7475, 1.7557, 1.7737, 1.7722, 1.7522, 1.7738, 1.7738,
         1.4757, 1.4806, 1.5178, 1.5124, 1.4811, 1.5163, 1.5047, 1.5179, 1.5148,
         2.2025, 2.1819, 2.1705, 2.1887, 2.2329, 2.2501, 2.2164, 2.3214, 2.3179,
         1.4371, 1.4280, 1.4424, 1.4528, 1.4396, 1.4496, 1.4194, 1.4467, 1.4529],
        [1.3247, 1.2405, 1.2354, 1.2536, 1.2467, 1.2568, 1.2557, 1.2015, 1.2015,
         1.2503, 1.2093, 1.2081, 1.2121, 1.2892, 1.1655, 1.1261, 1.2893, 1.1929,
         1.5982, 1.5751, 1.5561, 1.5533, 1.5762, 1.5725, 1.5911, 1.5777, 1.5777,
         1.3373, 1.3108, 1.3134, 1.3268, 1.3136, 1.3526, 1.3559, 1.3316, 1.3135,
         1.5792, 1.5775, 1.5842, 1.5738, 1.5496, 1.5528, 1.6131, 1.5039, 1.4728,
         4.0563, 3.6259, 3.7115, 3.6969, 3.7089, 3.3993, 4.0503, 3.6738, 3.4305]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 224 : 1779.6595997307497
Test loss for epoch 224 : 195.21457010053757
Test Precision for epoch 224 : 0.26153846153846155
Test Recall for epoch 224 : 0.26153846153846155
Test F1 for epoch 224 : 0.26153846153846155


theta for epoch 225 : tensor([[3.6234, 3.6457, 3.7893, 3.7358, 3.7221, 3.6050, 3.6459, 3.5456, 3.5456,
         1.2630, 1.2403, 1.2389, 1.2424, 1.2834, 1.2225, 1.1873, 1.2834, 1.2269,
         1.5883, 1.5725, 1.5969, 1.5785, 1.5844, 1.5860, 1.5940, 1.5860, 1.5860,
         1.3323, 1.3435, 1.3286, 1.3514, 1.3314, 1.3633, 1.3558, 1.3423, 1.3286,
         1.5862, 1.6028, 1.5912, 1.5876, 1.5947, 1.5850, 1.6038, 1.5568, 1.5615,
         1.2519, 1.2784, 1.2704, 1.2877, 1.2468, 1.2386, 1.2273, 1.3096, 1.2672],
        [1.3708, 1.2157, 1.2061, 1.2490, 1.2493, 1.2615, 1.2555, 1.1579, 1.1579,
         3.6078, 3.6862, 3.5426, 3.8932, 3.6086, 4.1790, 3.4848, 3.5668, 3.9851,
         1.5629, 1.5506, 1.5253, 1.5229, 1.5436, 1.5530, 1.5781, 1.5531, 1.5531,
         1.3417, 1.3084, 1.3011, 1.3599, 1.3016, 1.3977, 1.3777, 1.3459, 1.2979,
         1.5341, 1.5902, 1.5535, 1.5405, 1.5357, 1.5733, 1.5931, 1.4274, 1.5252,
         1.1572, 1.2704, 1.2433, 1.2922, 1.1514, 1.1576, 1.0839, 1.3536, 1.2336],
        [1.4498, 1.4497, 1.4481, 1.4453, 1.4456, 1.4498, 1.4454, 1.4498, 1.4498,
         1.4370, 1.4363, 1.4370, 1.4370, 1.4370, 1.4181, 1.4370, 1.4358, 1.4336,
         2.1965, 2.1970, 2.2138, 2.1895, 2.1707, 2.1690, 2.1982, 2.1680, 2.1680,
         1.5092, 1.5076, 1.5151, 1.5151, 1.5092, 1.5151, 1.5151, 1.5151, 1.5151,
         1.7695, 1.7696, 1.7696, 1.7664, 1.7695, 1.7695, 1.7696, 1.7467, 1.7494,
         1.4488, 1.4535, 1.4535, 1.4535, 1.4451, 1.4535, 1.4494, 1.4535, 1.4535],
        [1.3176, 1.3156, 1.2997, 1.2909, 1.3146, 1.3130, 1.3141, 1.3146, 1.3146,
         1.3034, 1.2966, 1.2928, 1.2923, 1.3043, 1.2885, 1.2995, 1.3039, 1.2759,
         1.6396, 1.6132, 1.6365, 1.6360, 1.6353, 1.6354, 1.6376, 1.6391, 1.6391,
         3.4753, 3.2659, 3.1915, 3.2499, 3.4006, 3.2186, 3.4499, 3.1997, 3.1781,
         1.6433, 1.6359, 1.6341, 1.6373, 1.6402, 1.6163, 1.6416, 1.5811, 1.6075,
         1.3183, 1.3129, 1.3030, 1.3177, 1.3134, 1.3055, 1.3177, 1.3180, 1.3199],
        [1.4527, 1.4482, 1.4042, 1.4079, 1.4459, 1.4526, 1.4510, 1.4526, 1.4526,
         1.4387, 1.4361, 1.4310, 1.4260, 1.4399, 1.3987, 1.4339, 1.4399, 1.4348,
         1.7521, 1.7433, 1.7418, 1.7501, 1.7680, 1.7665, 1.7465, 1.7681, 1.7681,
         1.4757, 1.4807, 1.5178, 1.5125, 1.4811, 1.5164, 1.5047, 1.5179, 1.5148,
         2.1955, 2.1750, 2.1636, 2.1817, 2.2260, 2.2432, 2.2095, 2.3144, 2.3109,
         1.4406, 1.4315, 1.4458, 1.4563, 1.4431, 1.4530, 1.4230, 1.4502, 1.4563],
        [1.3366, 1.2511, 1.2461, 1.2644, 1.2576, 1.2677, 1.2665, 1.2113, 1.2113,
         1.2599, 1.2190, 1.2178, 1.2217, 1.2988, 1.1765, 1.1380, 1.2988, 1.2034,
         1.5979, 1.5747, 1.5560, 1.5528, 1.5757, 1.5720, 1.5908, 1.5772, 1.5772,
         1.3458, 1.3193, 1.3214, 1.3355, 1.3219, 1.3617, 1.3647, 1.3401, 1.3215,
         1.5763, 1.5748, 1.5813, 1.5710, 1.5469, 1.5502, 1.6103, 1.5013, 1.4703,
         4.0487, 3.6174, 3.7031, 3.6885, 3.7005, 3.3907, 4.0427, 3.6654, 3.4219]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 225 : 1779.8698171330284
Test loss for epoch 225 : 195.02596764325654
Test Precision for epoch 225 : 0.26153846153846155
Test Recall for epoch 225 : 0.26153846153846155
Test F1 for epoch 225 : 0.26153846153846155


theta for epoch 226 : tensor([[3.6269, 3.6492, 3.7928, 3.7393, 3.7255, 3.6085, 3.6495, 3.5492, 3.5492,
         1.2667, 1.2442, 1.2428, 1.2462, 1.2870, 1.2269, 1.1925, 1.2870, 1.2312,
         1.5891, 1.5733, 1.5977, 1.5795, 1.5854, 1.5870, 1.5949, 1.5870, 1.5870,
         1.3380, 1.3492, 1.3348, 1.3570, 1.3372, 1.3686, 1.3613, 1.3481, 1.3348,
         1.5833, 1.5998, 1.5882, 1.5847, 1.5917, 1.5820, 1.6007, 1.5538, 1.5585,
         1.2427, 1.2689, 1.2611, 1.2782, 1.2377, 1.2296, 1.2184, 1.2999, 1.2579],
        [1.3689, 1.2146, 1.2049, 1.2477, 1.2481, 1.2603, 1.2543, 1.1572, 1.1572,
         3.6121, 3.6907, 3.5468, 3.8982, 3.6129, 4.1848, 3.4888, 3.5710, 3.9903,
         1.5617, 1.5493, 1.5240, 1.5216, 1.5425, 1.5519, 1.5769, 1.5519, 1.5519,
         1.3432, 1.3099, 1.3027, 1.3614, 1.3031, 1.3992, 1.3792, 1.3475, 1.2995,
         1.5298, 1.5859, 1.5493, 1.5362, 1.5314, 1.5690, 1.5888, 1.4230, 1.5209,
         1.1485, 1.2613, 1.2343, 1.2830, 1.1427, 1.1489, 1.0753, 1.3442, 1.2247],
        [1.4501, 1.4500, 1.4484, 1.4456, 1.4459, 1.4501, 1.4457, 1.4501, 1.4501,
         1.4412, 1.4405, 1.4411, 1.4411, 1.4412, 1.4223, 1.4412, 1.4400, 1.4377,
         2.1976, 2.1980, 2.2149, 2.1905, 2.1717, 2.1700, 2.1992, 2.1691, 2.1691,
         1.5152, 1.5136, 1.5211, 1.5211, 1.5152, 1.5211, 1.5210, 1.5211, 1.5211,
         1.7668, 1.7669, 1.7669, 1.7637, 1.7668, 1.7668, 1.7669, 1.7440, 1.7467,
         1.4402, 1.4449, 1.4449, 1.4449, 1.4365, 1.4449, 1.4408, 1.4448, 1.4449],
        [1.3169, 1.3151, 1.2991, 1.2903, 1.3140, 1.3124, 1.3136, 1.3141, 1.3141,
         1.3073, 1.3005, 1.2967, 1.2963, 1.3082, 1.2925, 1.3035, 1.3078, 1.2799,
         1.6404, 1.6140, 1.6374, 1.6368, 1.6362, 1.6362, 1.6385, 1.6399, 1.6399,
         3.4822, 3.2729, 3.1987, 3.2570, 3.4075, 3.2257, 3.4568, 3.2068, 3.1853,
         1.6403, 1.6329, 1.6312, 1.6343, 1.6373, 1.6134, 1.6387, 1.5781, 1.6046,
         1.3093, 1.3038, 1.2940, 1.3087, 1.3043, 1.2965, 1.3087, 1.3089, 1.3109],
        [1.4530, 1.4486, 1.4047, 1.4082, 1.4462, 1.4528, 1.4513, 1.4529, 1.4529,
         1.4429, 1.4402, 1.4352, 1.4301, 1.4440, 1.4029, 1.4381, 1.4440, 1.4390,
         1.7532, 1.7445, 1.7430, 1.7512, 1.7691, 1.7676, 1.7476, 1.7692, 1.7692,
         1.4817, 1.4868, 1.5238, 1.5185, 1.4871, 1.5223, 1.5106, 1.5239, 1.5207,
         2.1929, 2.1724, 2.1609, 2.1791, 2.2233, 2.2405, 2.2068, 2.3116, 2.3082,
         1.4320, 1.4229, 1.4372, 1.4476, 1.4346, 1.4444, 1.4144, 1.4415, 1.4477],
        [1.3465, 1.2592, 1.2543, 1.2729, 1.2660, 1.2762, 1.2750, 1.2185, 1.2185,
         1.2656, 1.2246, 1.2234, 1.2273, 1.3046, 1.1831, 1.1452, 1.3046, 1.2097,
         1.6018, 1.5786, 1.5599, 1.5565, 1.5794, 1.5757, 1.5946, 1.5808, 1.5808,
         1.3564, 1.3298, 1.3314, 1.3462, 1.3322, 1.3727, 1.3755, 1.3506, 1.3314,
         1.5757, 1.5745, 1.5808, 1.5705, 1.5465, 1.5499, 1.6100, 1.5009, 1.4700,
         4.0407, 3.6085, 3.6943, 3.6797, 3.6917, 3.3816, 4.0347, 3.6566, 3.4129]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 226 : 1779.8352422134353
Test loss for epoch 226 : 194.87961653331737
Test Precision for epoch 226 : 0.26153846153846155
Test Recall for epoch 226 : 0.26153846153846155
Test F1 for epoch 226 : 0.26153846153846155


theta for epoch 227 : tensor([[3.6306, 3.6529, 3.7965, 3.7430, 3.7292, 3.6123, 3.6532, 3.5530, 3.5530,
         1.2628, 1.2402, 1.2388, 1.2423, 1.2831, 1.2234, 1.1894, 1.2831, 1.2276,
         1.5953, 1.5795, 1.6038, 1.5858, 1.5917, 1.5933, 1.6010, 1.5933, 1.5933,
         1.3366, 1.3479, 1.3339, 1.3556, 1.3361, 1.3670, 1.3598, 1.3468, 1.3339,
         1.5868, 1.6032, 1.5917, 1.5882, 1.5952, 1.5854, 1.6041, 1.5573, 1.5620,
         1.2378, 1.2638, 1.2560, 1.2730, 1.2328, 1.2248, 1.2136, 1.2945, 1.2529],
        [1.3610, 1.2072, 1.1974, 1.2403, 1.2406, 1.2529, 1.2468, 1.1501, 1.1501,
         3.6192, 3.6980, 3.5539, 3.9061, 3.6200, 4.1936, 3.4957, 3.5781, 3.9984,
         1.5609, 1.5485, 1.5231, 1.5207, 1.5417, 1.5511, 1.5762, 1.5512, 1.5512,
         1.3364, 1.3030, 1.2960, 1.3547, 1.2963, 1.3925, 1.3725, 1.3408, 1.2928,
         1.5277, 1.5840, 1.5473, 1.5341, 1.5293, 1.5670, 1.5868, 1.4204, 1.5187,
         1.1389, 1.2518, 1.2248, 1.2736, 1.1332, 1.1395, 1.0656, 1.3348, 1.2152],
        [1.4485, 1.4484, 1.4468, 1.4440, 1.4444, 1.4485, 1.4441, 1.4485, 1.4485,
         1.4378, 1.4371, 1.4378, 1.4378, 1.4378, 1.4189, 1.4378, 1.4366, 1.4344,
         2.2038, 2.2043, 2.2211, 2.1965, 2.1778, 2.1760, 2.2052, 2.1751, 2.1751,
         1.5145, 1.5130, 1.5204, 1.5204, 1.5146, 1.5204, 1.5204, 1.5204, 1.5204,
         1.7707, 1.7707, 1.7707, 1.7675, 1.7706, 1.7706, 1.7707, 1.7479, 1.7506,
         1.4360, 1.4407, 1.4407, 1.4407, 1.4323, 1.4407, 1.4366, 1.4407, 1.4407],
        [1.3143, 1.3127, 1.2967, 1.2879, 1.3116, 1.3100, 1.3111, 1.3118, 1.3118,
         1.3037, 1.2970, 1.2931, 1.2927, 1.3046, 1.2889, 1.3000, 1.3042, 1.2763,
         1.6467, 1.6204, 1.6437, 1.6432, 1.6425, 1.6425, 1.6448, 1.6462, 1.6462,
         3.4835, 3.2744, 3.2002, 3.2584, 3.4089, 3.2271, 3.4582, 3.2083, 3.1868,
         1.6440, 1.6365, 1.6348, 1.6380, 1.6409, 1.6170, 1.6423, 1.5818, 1.6083,
         1.3048, 1.2993, 1.2894, 1.3041, 1.2998, 1.2920, 1.3042, 1.3043, 1.3063],
        [1.4514, 1.4470, 1.4033, 1.4067, 1.4446, 1.4513, 1.4498, 1.4513, 1.4513,
         1.4395, 1.4369, 1.4318, 1.4268, 1.4407, 1.3996, 1.4347, 1.4406, 1.4356,
         1.7598, 1.7510, 1.7496, 1.7578, 1.7756, 1.7742, 1.7542, 1.7757, 1.7757,
         1.4811, 1.4863, 1.5232, 1.5179, 1.4865, 1.5217, 1.5100, 1.5232, 1.5201,
         2.1965, 2.1761, 2.1647, 2.1828, 2.2269, 2.2442, 2.2105, 2.3152, 2.3118,
         1.4279, 1.4187, 1.4330, 1.4435, 1.4304, 1.4402, 1.4104, 1.4374, 1.4435],
        [1.3507, 1.2619, 1.2571, 1.2758, 1.2690, 1.2792, 1.2780, 1.2203, 1.2203,
         1.2626, 1.2214, 1.2202, 1.2242, 1.3019, 1.1807, 1.1432, 1.3019, 1.2071,
         1.6087, 1.5854, 1.5668, 1.5631, 1.5861, 1.5824, 1.6015, 1.5875, 1.5875,
         1.3582, 1.3316, 1.3327, 1.3481, 1.3339, 1.3750, 1.3776, 1.3524, 1.3328,
         1.5798, 1.5787, 1.5849, 1.5745, 1.5506, 1.5540, 1.6142, 1.5048, 1.4740,
         4.0389, 3.6059, 3.6918, 3.6771, 3.6892, 3.3789, 4.0330, 3.6540, 3.4102]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 227 : 1779.5238221219147
Test loss for epoch 227 : 195.0473820489987
Test Precision for epoch 227 : 0.26153846153846155
Test Recall for epoch 227 : 0.26153846153846155
Test F1 for epoch 227 : 0.26153846153846155


theta for epoch 228 : tensor([[3.6357, 3.6581, 3.8016, 3.7482, 3.7343, 3.6175, 3.6584, 3.5583, 3.5583,
         1.2533, 1.2306, 1.2292, 1.2327, 1.2738, 1.2140, 1.1802, 1.2738, 1.2182,
         1.5989, 1.5831, 1.6074, 1.5895, 1.5954, 1.5970, 1.6046, 1.5970, 1.5970,
         1.3301, 1.3415, 1.3277, 1.3491, 1.3296, 1.3603, 1.3532, 1.3404, 1.3277,
         1.5932, 1.6096, 1.5981, 1.5946, 1.6016, 1.5918, 1.6104, 1.5636, 1.5684,
         1.2418, 1.2677, 1.2599, 1.2769, 1.2368, 1.2288, 1.2177, 1.2983, 1.2568],
        [1.3492, 1.1953, 1.1853, 1.2284, 1.2287, 1.2410, 1.2349, 1.1381, 1.1381,
         3.6293, 3.7083, 3.5639, 3.9169, 3.6301, 4.2053, 3.5056, 3.5881, 4.0095,
         1.5553, 1.5428, 1.5172, 1.5149, 1.5360, 1.5455, 1.5707, 1.5455, 1.5455,
         1.3232, 1.2897, 1.2826, 1.3415, 1.2830, 1.3794, 1.3594, 1.3276, 1.2795,
         1.5252, 1.5819, 1.5449, 1.5317, 1.5268, 1.5648, 1.5847, 1.4172, 1.5161,
         1.1326, 1.2461, 1.2189, 1.2679, 1.1268, 1.1331, 1.0589, 1.3295, 1.2092],
        [1.4469, 1.4468, 1.4451, 1.4423, 1.4427, 1.4468, 1.4425, 1.4468, 1.4468,
         1.4292, 1.4285, 1.4292, 1.4291, 1.4292, 1.4103, 1.4292, 1.4280, 1.4257,
         2.2080, 2.2084, 2.2252, 2.2005, 2.1818, 2.1800, 2.2092, 2.1791, 2.1791,
         1.5091, 1.5075, 1.5150, 1.5150, 1.5091, 1.5150, 1.5149, 1.5150, 1.5150,
         1.7776, 1.7777, 1.7777, 1.7745, 1.7776, 1.7776, 1.7777, 1.7549, 1.7576,
         1.4410, 1.4457, 1.4457, 1.4457, 1.4373, 1.4457, 1.4416, 1.4456, 1.4457],
        [1.3118, 1.3103, 1.2944, 1.2855, 1.3092, 1.3075, 1.3087, 1.3095, 1.3095,
         1.2949, 1.2881, 1.2843, 1.2838, 1.2957, 1.2801, 1.2912, 1.2953, 1.2675,
         1.6508, 1.6245, 1.6478, 1.6473, 1.6466, 1.6467, 1.6489, 1.6503, 1.6503,
         3.4808, 3.2718, 3.1976, 3.2558, 3.4062, 3.2246, 3.4556, 3.2057, 3.1842,
         1.6508, 1.6433, 1.6416, 1.6448, 1.6477, 1.6238, 1.6491, 1.5886, 1.6151,
         1.3095, 1.3039, 1.2941, 1.3087, 1.3045, 1.2967, 1.3088, 1.3089, 1.3110],
        [1.4497, 1.4455, 1.4019, 1.4050, 1.4430, 1.4496, 1.4481, 1.4497, 1.4497,
         1.4309, 1.4283, 1.4232, 1.4182, 1.4321, 1.3911, 1.4261, 1.4320, 1.4270,
         1.7642, 1.7554, 1.7540, 1.7622, 1.7799, 1.7785, 1.7586, 1.7801, 1.7801,
         1.4756, 1.4810, 1.5177, 1.5125, 1.4811, 1.5163, 1.5045, 1.5178, 1.5146,
         2.2032, 2.1829, 2.1715, 2.1895, 2.2336, 2.2509, 2.2173, 2.3218, 2.3184,
         1.4330, 1.4238, 1.4381, 1.4485, 1.4355, 1.4452, 1.4155, 1.4424, 1.4485],
        [1.3506, 1.2606, 1.2559, 1.2747, 1.2679, 1.2782, 1.2769, 1.2185, 1.2185,
         1.2530, 1.2115, 1.2103, 1.2143, 1.2926, 1.1715, 1.1341, 1.2926, 1.1976,
         1.6115, 1.5882, 1.5695, 1.5657, 1.5888, 1.5850, 1.6043, 1.5903, 1.5903,
         1.3530, 1.3263, 1.3272, 1.3430, 1.3285, 1.3701, 1.3725, 1.3472, 1.3272,
         1.5852, 1.5842, 1.5904, 1.5800, 1.5560, 1.5594, 1.6198, 1.5101, 1.4793,
         4.0451, 3.6113, 3.6973, 3.6826, 3.6948, 3.3842, 4.0393, 3.6595, 3.4155]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 228 : 1778.886308063601
Test loss for epoch 228 : 195.5337140004449
Test Precision for epoch 228 : 0.26153846153846155
Test Recall for epoch 228 : 0.26153846153846155
Test F1 for epoch 228 : 0.26153846153846155


theta for epoch 229 : tensor([[3.6353, 3.6577, 3.8013, 3.7479, 3.7339, 3.6171, 3.6580, 3.5579, 3.5579,
         1.2459, 1.2234, 1.2220, 1.2255, 1.2662, 1.2071, 1.1741, 1.2662, 1.2113,
         1.5963, 1.5805, 1.6048, 1.5870, 1.5929, 1.5945, 1.6020, 1.5945, 1.5945,
         1.3323, 1.3437, 1.3302, 1.3512, 1.3319, 1.3623, 1.3553, 1.3426, 1.3302,
         1.5967, 1.6130, 1.6016, 1.5980, 1.6050, 1.5952, 1.6138, 1.5671, 1.5718,
         1.2508, 1.2766, 1.2689, 1.2857, 1.2458, 1.2378, 1.2268, 1.3071, 1.2658],
        [1.3595, 1.2060, 1.1960, 1.2390, 1.2393, 1.2517, 1.2456, 1.1490, 1.1490,
         3.6175, 3.6967, 3.5520, 3.9058, 3.6183, 4.1952, 3.4935, 3.5763, 3.9987,
         1.5597, 1.5473, 1.5218, 1.5194, 1.5404, 1.5499, 1.5750, 1.5499, 1.5499,
         1.3323, 1.2988, 1.2918, 1.3506, 1.2921, 1.3885, 1.3684, 1.3366, 1.2886,
         1.5339, 1.5905, 1.5536, 1.5404, 1.5355, 1.5735, 1.5934, 1.4263, 1.5249,
         1.1454, 1.2589, 1.2317, 1.2808, 1.1396, 1.1458, 1.0716, 1.3424, 1.2221],
        [1.4481, 1.4480, 1.4463, 1.4435, 1.4439, 1.4480, 1.4437, 1.4480, 1.4480,
         1.4215, 1.4208, 1.4215, 1.4215, 1.4215, 1.4027, 1.4215, 1.4203, 1.4181,
         2.2051, 2.2055, 2.2223, 2.1977, 2.1790, 2.1773, 2.2064, 2.1763, 2.1763,
         1.5101, 1.5085, 1.5160, 1.5160, 1.5101, 1.5160, 1.5159, 1.5160, 1.5160,
         1.7806, 1.7807, 1.7807, 1.7775, 1.7806, 1.7806, 1.7807, 1.7579, 1.7606,
         1.4494, 1.4540, 1.4540, 1.4540, 1.4457, 1.4540, 1.4500, 1.4540, 1.4540],
        [1.3123, 1.3110, 1.2950, 1.2861, 1.3099, 1.3082, 1.3093, 1.3102, 1.3102,
         1.2870, 1.2802, 1.2764, 1.2759, 1.2878, 1.2722, 1.2834, 1.2874, 1.2596,
         1.6474, 1.6211, 1.6444, 1.6438, 1.6432, 1.6432, 1.6455, 1.6469, 1.6469,
         3.4835, 3.2747, 3.2005, 3.2587, 3.4090, 3.2275, 3.4584, 3.2086, 3.1872,
         1.6535, 1.6461, 1.6444, 1.6475, 1.6505, 1.6266, 1.6519, 1.5914, 1.6179,
         1.3175, 1.3120, 1.3022, 1.3168, 1.3126, 1.3048, 1.3170, 1.3170, 1.3191],
        [1.4509, 1.4467, 1.4033, 1.4063, 1.4442, 1.4508, 1.4493, 1.4509, 1.4509,
         1.4233, 1.4206, 1.4156, 1.4106, 1.4244, 1.3835, 1.4184, 1.4244, 1.4194,
         1.7611, 1.7523, 1.7510, 1.7592, 1.7768, 1.7754, 1.7555, 1.7770, 1.7770,
         1.4766, 1.4821, 1.5187, 1.5135, 1.4821, 1.5173, 1.5055, 1.5187, 1.5156,
         2.2061, 2.1857, 2.1744, 2.1924, 2.2364, 2.2538, 2.2201, 2.3245, 2.3211,
         1.4414, 1.4321, 1.4464, 1.4568, 1.4439, 1.4536, 1.4240, 1.4507, 1.4568],
        [1.3522, 1.2618, 1.2571, 1.2760, 1.2692, 1.2795, 1.2782, 1.2195, 1.2195,
         1.2447, 1.2035, 1.2023, 1.2062, 1.2841, 1.1641, 1.1280, 1.2841, 1.1901,
         1.6077, 1.5843, 1.5657, 1.5619, 1.5850, 1.5813, 1.6005, 1.5865, 1.5865,
         1.3535, 1.3268, 1.3276, 1.3435, 1.3289, 1.3707, 1.3731, 1.3477, 1.3276,
         1.5873, 1.5862, 1.5924, 1.5820, 1.5580, 1.5614, 1.6218, 1.5120, 1.4812,
         4.0519, 3.6173, 3.7034, 3.6886, 3.7009, 3.3901, 4.0461, 3.6655, 3.4214]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 229 : 1779.619369286166
Test loss for epoch 229 : 195.05317603617647
Test Precision for epoch 229 : 0.26153846153846155
Test Recall for epoch 229 : 0.26153846153846155
Test F1 for epoch 229 : 0.26153846153846155


theta for epoch 230 : tensor([[3.6369, 3.6593, 3.8029, 3.7495, 3.7355, 3.6187, 3.6596, 3.5595, 3.5595,
         1.2476, 1.2252, 1.2238, 1.2272, 1.2679, 1.2091, 1.1764, 1.2679, 1.2133,
         1.5923, 1.5765, 1.6008, 1.5831, 1.5889, 1.5905, 1.5980, 1.5905, 1.5905,
         1.3379, 1.3493, 1.3360, 1.3569, 1.3376, 1.3678, 1.3608, 1.3483, 1.3360,
         1.5933, 1.6096, 1.5982, 1.5947, 1.6016, 1.5918, 1.6103, 1.5637, 1.5684,
         1.2514, 1.2771, 1.2694, 1.2863, 1.2464, 1.2384, 1.2274, 1.3076, 1.2663],
        [1.3641, 1.2106, 1.2006, 1.2436, 1.2439, 1.2563, 1.2502, 1.1536, 1.1536,
         3.6152, 3.6945, 3.5496, 3.9041, 3.6160, 4.1944, 3.4909, 3.5739, 3.9972,
         1.5588, 1.5463, 1.5209, 1.5185, 1.5394, 1.5489, 1.5741, 1.5489, 1.5489,
         1.3383, 1.3048, 1.2977, 1.3567, 1.2981, 1.3946, 1.3746, 1.3427, 1.2946,
         1.5329, 1.5895, 1.5525, 1.5394, 1.5345, 1.5725, 1.5923, 1.4254, 1.5238,
         1.1478, 1.2615, 1.2343, 1.2834, 1.1420, 1.1481, 1.0739, 1.3452, 1.2246],
        [1.4498, 1.4497, 1.4481, 1.4453, 1.4457, 1.4498, 1.4454, 1.4498, 1.4498,
         1.4232, 1.4225, 1.4232, 1.4232, 1.4232, 1.4044, 1.4232, 1.4220, 1.4198,
         2.2012, 2.2016, 2.2184, 2.1940, 2.1752, 2.1735, 2.2027, 2.1726, 2.1726,
         1.5149, 1.5133, 1.5207, 1.5207, 1.5149, 1.5207, 1.5207, 1.5207, 1.5207,
         1.7771, 1.7772, 1.7772, 1.7740, 1.7771, 1.7771, 1.7772, 1.7544, 1.7571,
         1.4497, 1.4543, 1.4543, 1.4543, 1.4460, 1.4543, 1.4503, 1.4543, 1.4543],
        [1.3135, 1.3122, 1.2963, 1.2874, 1.3112, 1.3094, 1.3106, 1.3116, 1.3116,
         1.2884, 1.2817, 1.2779, 1.2774, 1.2892, 1.2737, 1.2849, 1.2888, 1.2611,
         1.6428, 1.6166, 1.6398, 1.6393, 1.6387, 1.6387, 1.6409, 1.6424, 1.6424,
         3.4896, 3.2809, 3.2069, 3.2650, 3.4152, 3.2338, 3.4645, 3.2149, 3.1936,
         1.6498, 1.6423, 1.6407, 1.6438, 1.6468, 1.6228, 1.6481, 1.5877, 1.6141,
         1.3176, 1.3120, 1.3022, 1.3168, 1.3126, 1.3048, 1.3170, 1.3169, 1.3191],
        [1.4527, 1.4485, 1.4052, 1.4082, 1.4460, 1.4525, 1.4511, 1.4526, 1.4526,
         1.4249, 1.4223, 1.4173, 1.4123, 1.4261, 1.3853, 1.4201, 1.4261, 1.4211,
         1.7569, 1.7482, 1.7468, 1.7550, 1.7727, 1.7713, 1.7514, 1.7728, 1.7728,
         1.4815, 1.4870, 1.5235, 1.5183, 1.4870, 1.5221, 1.5103, 1.5235, 1.5204,
         2.2026, 2.1823, 2.1710, 2.1889, 2.2330, 2.2504, 2.2167, 2.3210, 2.3177,
         1.4418, 1.4325, 1.4468, 1.4571, 1.4443, 1.4539, 1.4245, 1.4510, 1.4572],
        [1.3507, 1.2600, 1.2552, 1.2743, 1.2674, 1.2778, 1.2765, 1.2176, 1.2176,
         1.2437, 1.2025, 1.2013, 1.2053, 1.2831, 1.1635, 1.1281, 1.2831, 1.1895,
         1.6012, 1.5778, 1.5592, 1.5554, 1.5785, 1.5748, 1.5940, 1.5800, 1.5800,
         1.3547, 1.3279, 1.3288, 1.3447, 1.3301, 1.3720, 1.3744, 1.3489, 1.3288,
         1.5817, 1.5805, 1.5868, 1.5764, 1.5523, 1.5557, 1.6162, 1.5063, 1.4754,
         4.0590, 3.6237, 3.7098, 3.6950, 3.7073, 3.3964, 4.0533, 3.6719, 3.4277]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 230 : 1779.6539333226365
Test loss for epoch 230 : 194.9809044773412
Test Precision for epoch 230 : 0.26153846153846155
Test Recall for epoch 230 : 0.26153846153846155
Test F1 for epoch 230 : 0.26153846153846155


theta for epoch 231 : tensor([[3.6384, 3.6608, 3.8044, 3.7510, 3.7369, 3.6202, 3.6611, 3.5611, 3.5611,
         1.2574, 1.2349, 1.2335, 1.2370, 1.2778, 1.2189, 1.1863, 1.2778, 1.2231,
         1.5929, 1.5771, 1.6014, 1.5837, 1.5895, 1.5912, 1.5986, 1.5912, 1.5912,
         1.3373, 1.3488, 1.3355, 1.3563, 1.3371, 1.3672, 1.3603, 1.3478, 1.3355,
         1.5890, 1.6053, 1.5940, 1.5904, 1.5973, 1.5875, 1.6060, 1.5594, 1.5641,
         1.2420, 1.2678, 1.2601, 1.2770, 1.2370, 1.2290, 1.2181, 1.2984, 1.2570],
        [1.3619, 1.2082, 1.1982, 1.2412, 1.2415, 1.2539, 1.2478, 1.1511, 1.1511,
         3.6215, 3.7009, 3.5558, 3.9110, 3.6222, 4.2022, 3.4969, 3.5801, 4.0044,
         1.5574, 1.5449, 1.5195, 1.5169, 1.5379, 1.5474, 1.5727, 1.5474, 1.5474,
         1.3361, 1.3025, 1.2954, 1.3545, 1.2958, 1.3925, 1.3724, 1.3405, 1.2922,
         1.5274, 1.5841, 1.5471, 1.5339, 1.5290, 1.5671, 1.5870, 1.4199, 1.5183,
         1.1392, 1.2530, 1.2257, 1.2749, 1.1333, 1.1394, 1.0653, 1.3368, 1.2159],
        [1.4490, 1.4489, 1.4473, 1.4445, 1.4449, 1.4490, 1.4446, 1.4490, 1.4490,
         1.4332, 1.4325, 1.4332, 1.4332, 1.4332, 1.4144, 1.4332, 1.4320, 1.4298,
         2.2018, 2.2022, 2.2190, 2.1946, 2.1759, 2.1741, 2.2033, 2.1732, 2.1732,
         1.5139, 1.5123, 1.5197, 1.5197, 1.5139, 1.5197, 1.5197, 1.5197, 1.5197,
         1.7729, 1.7730, 1.7730, 1.7698, 1.7729, 1.7729, 1.7730, 1.7502, 1.7529,
         1.4405, 1.4451, 1.4451, 1.4451, 1.4368, 1.4451, 1.4412, 1.4451, 1.4451],
        [1.3123, 1.3111, 1.2952, 1.2863, 1.3100, 1.3083, 1.3095, 1.3105, 1.3105,
         1.2982, 1.2915, 1.2877, 1.2872, 1.2990, 1.2835, 1.2948, 1.2986, 1.2710,
         1.6432, 1.6169, 1.6402, 1.6397, 1.6390, 1.6390, 1.6413, 1.6427, 1.6427,
         3.4909, 3.2823, 3.2082, 3.2663, 3.4164, 3.2351, 3.4657, 3.2163, 3.1949,
         1.6454, 1.6379, 1.6363, 1.6394, 1.6423, 1.6184, 1.6437, 1.5832, 1.6097,
         1.3080, 1.3024, 1.2926, 1.3072, 1.3030, 1.2953, 1.3075, 1.3073, 1.3095],
        [1.4519, 1.4478, 1.4046, 1.4075, 1.4453, 1.4517, 1.4503, 1.4518, 1.4518,
         1.4349, 1.4323, 1.4273, 1.4224, 1.4361, 1.3954, 1.4302, 1.4361, 1.4312,
         1.7575, 1.7488, 1.7475, 1.7556, 1.7733, 1.7719, 1.7520, 1.7734, 1.7734,
         1.4805, 1.4861, 1.5225, 1.5173, 1.4860, 1.5211, 1.5093, 1.5225, 1.5194,
         2.1986, 2.1783, 2.1669, 2.1849, 2.2289, 2.2464, 2.2127, 2.3168, 2.3136,
         1.4327, 1.4233, 1.4376, 1.4479, 1.4351, 1.4447, 1.4153, 1.4419, 1.4480],
        [1.3445, 1.2534, 1.2485, 1.2677, 1.2608, 1.2712, 1.2699, 1.2108, 1.2108,
         1.2494, 1.2079, 1.2067, 1.2108, 1.2890, 1.1689, 1.1336, 1.2890, 1.1951,
         1.5977, 1.5743, 1.5556, 1.5518, 1.5751, 1.5713, 1.5905, 1.5766, 1.5766,
         1.3489, 1.3220, 1.3229, 1.3389, 1.3242, 1.3662, 1.3686, 1.3431, 1.3230,
         1.5742, 1.5730, 1.5794, 1.5689, 1.5448, 1.5482, 1.6087, 1.4986, 1.4676,
         4.0654, 3.6292, 3.7155, 3.7006, 3.7130, 3.4019, 4.0597, 3.6774, 3.4331]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 231 : 1778.8590015921998
Test loss for epoch 231 : 195.20677822787195
Test Precision for epoch 231 : 0.26153846153846155
Test Recall for epoch 231 : 0.26153846153846155
Test F1 for epoch 231 : 0.26153846153846155


theta for epoch 232 : tensor([[3.6338, 3.6561, 3.7998, 3.7465, 3.7323, 3.6155, 3.6565, 3.5563, 3.5563,
         1.2668, 1.2445, 1.2431, 1.2466, 1.2869, 1.2286, 1.1967, 1.2869, 1.2329,
         1.5977, 1.5819, 1.6062, 1.5885, 1.5943, 1.5960, 1.6034, 1.5959, 1.5959,
         1.3330, 1.3445, 1.3312, 1.3520, 1.3328, 1.3630, 1.3560, 1.3435, 1.3313,
         1.5887, 1.6049, 1.5936, 1.5900, 1.5970, 1.5871, 1.6057, 1.5590, 1.5637,
         1.2341, 1.2600, 1.2523, 1.2692, 1.2291, 1.2210, 1.2102, 1.2907, 1.2491],
        [1.3686, 1.2153, 1.2053, 1.2482, 1.2485, 1.2609, 1.2548, 1.1583, 1.1583,
         3.6163, 3.6960, 3.5505, 3.9066, 3.6172, 4.1986, 3.4915, 3.5749, 4.0002,
         1.5662, 1.5536, 1.5283, 1.5257, 1.5467, 1.5562, 1.5814, 1.5562, 1.5562,
         1.3398, 1.3064, 1.2993, 1.3582, 1.2997, 1.3961, 1.3761, 1.3442, 1.2961,
         1.5318, 1.5885, 1.5515, 1.5383, 1.5335, 1.5715, 1.5913, 1.4247, 1.5228,
         1.1391, 1.2526, 1.2253, 1.2745, 1.1331, 1.1391, 1.0653, 1.3363, 1.2156],
        [1.4465, 1.4464, 1.4448, 1.4420, 1.4424, 1.4465, 1.4421, 1.4464, 1.4464,
         1.4419, 1.4412, 1.4419, 1.4419, 1.4419, 1.4232, 1.4419, 1.4408, 1.4385,
         2.2053, 2.2057, 2.2226, 2.1980, 2.1793, 2.1776, 2.2067, 2.1766, 2.1766,
         1.5078, 1.5061, 1.5136, 1.5136, 1.5078, 1.5136, 1.5136, 1.5136, 1.5136,
         1.7718, 1.7719, 1.7719, 1.7688, 1.7718, 1.7718, 1.7719, 1.7492, 1.7519,
         1.4318, 1.4364, 1.4364, 1.4364, 1.4281, 1.4364, 1.4325, 1.4364, 1.4364],
        [1.3095, 1.3083, 1.2925, 1.2836, 1.3072, 1.3055, 1.3067, 1.3077, 1.3077,
         1.3068, 1.3001, 1.2962, 1.2958, 1.3075, 1.2921, 1.3034, 1.3071, 1.2796,
         1.6467, 1.6205, 1.6437, 1.6432, 1.6425, 1.6426, 1.6448, 1.6463, 1.6463,
         3.4875, 3.2789, 3.2049, 3.2630, 3.4130, 3.2318, 3.4624, 3.2129, 3.1916,
         1.6441, 1.6366, 1.6350, 1.6381, 1.6411, 1.6171, 1.6425, 1.5820, 1.6084,
         1.2990, 1.2934, 1.2836, 1.2982, 1.2940, 1.2863, 1.2985, 1.2983, 1.3005],
        [1.4494, 1.4453, 1.4022, 1.4050, 1.4428, 1.4492, 1.4478, 1.4493, 1.4493,
         1.4436, 1.4410, 1.4360, 1.4311, 1.4448, 1.4042, 1.4389, 1.4447, 1.4399,
         1.7612, 1.7525, 1.7512, 1.7594, 1.7769, 1.7755, 1.7557, 1.7771, 1.7771,
         1.4744, 1.4801, 1.5163, 1.5112, 1.4799, 1.5150, 1.5031, 1.5164, 1.5133,
         2.1975, 2.1773, 2.1659, 2.1838, 2.2278, 2.2453, 2.2117, 2.3157, 2.3125,
         1.4240, 1.4146, 1.4289, 1.4392, 1.4265, 1.4360, 1.4067, 1.4331, 1.4392],
        [1.3377, 1.2464, 1.2415, 1.2607, 1.2538, 1.2643, 1.2630, 1.2038, 1.2038,
         1.2545, 1.2134, 1.2122, 1.2161, 1.2938, 1.1744, 1.1403, 1.2938, 1.2009,
         1.5980, 1.5745, 1.5557, 1.5520, 1.5753, 1.5715, 1.5908, 1.5768, 1.5768,
         1.3398, 1.3128, 1.3138, 1.3297, 1.3150, 1.3571, 1.3595, 1.3340, 1.3138,
         1.5704, 1.5691, 1.5756, 1.5651, 1.5409, 1.5443, 1.6049, 1.4946, 1.4636,
         4.0704, 3.6334, 3.7198, 3.7049, 3.7174, 3.4060, 4.0648, 3.6817, 3.4373]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 232 : 1779.290909655917
Test loss for epoch 232 : 195.17834235514664
Test Precision for epoch 232 : 0.26153846153846155
Test Recall for epoch 232 : 0.26153846153846155
Test F1 for epoch 232 : 0.26153846153846155


theta for epoch 233 : tensor([[3.6335, 3.6558, 3.7996, 3.7462, 3.7320, 3.6152, 3.6562, 3.5560, 3.5560,
         1.2665, 1.2444, 1.2430, 1.2464, 1.2864, 1.2284, 1.1971, 1.2864, 1.2329,
         1.5992, 1.5834, 1.6077, 1.5900, 1.5958, 1.5975, 1.6049, 1.5974, 1.5974,
         1.3325, 1.3440, 1.3307, 1.3515, 1.3322, 1.3625, 1.3555, 1.3430, 1.3307,
         1.5913, 1.6076, 1.5962, 1.5926, 1.5996, 1.5897, 1.6083, 1.5616, 1.5663,
         1.2328, 1.2589, 1.2511, 1.2681, 1.2278, 1.2196, 1.2088, 1.2898, 1.2479],
        [1.3712, 1.2180, 1.2080, 1.2510, 1.2513, 1.2636, 1.2576, 1.1611, 1.1611,
         3.6148, 3.6945, 3.5488, 3.9056, 3.6156, 4.1986, 3.4896, 3.5733, 3.9995,
         1.5682, 1.5557, 1.5303, 1.5278, 1.5488, 1.5582, 1.5834, 1.5583, 1.5583,
         1.3407, 1.3072, 1.3002, 1.3591, 1.3006, 1.3970, 1.3769, 1.3451, 1.2971,
         1.5349, 1.5915, 1.5546, 1.5414, 1.5366, 1.5745, 1.5944, 1.4278, 1.5258,
         1.1389, 1.2525, 1.2252, 1.2745, 1.1328, 1.1387, 1.0650, 1.3365, 1.2154],
        [1.4479, 1.4479, 1.4463, 1.4435, 1.4439, 1.4479, 1.4436, 1.4479, 1.4479,
         1.4413, 1.4406, 1.4412, 1.4412, 1.4413, 1.4225, 1.4412, 1.4401, 1.4378,
         2.2062, 2.2066, 2.2234, 2.1988, 2.1802, 2.1784, 2.2076, 2.1775, 2.1775,
         1.5060, 1.5043, 1.5118, 1.5118, 1.5060, 1.5118, 1.5118, 1.5118, 1.5118,
         1.7740, 1.7741, 1.7741, 1.7709, 1.7740, 1.7740, 1.7741, 1.7514, 1.7541,
         1.4302, 1.4348, 1.4348, 1.4348, 1.4265, 1.4348, 1.4309, 1.4348, 1.4348],
        [1.3109, 1.3098, 1.2939, 1.2850, 1.3087, 1.3069, 1.3081, 1.3092, 1.3092,
         1.3059, 1.2992, 1.2954, 1.2949, 1.3066, 1.2913, 1.3026, 1.3062, 1.2788,
         1.6474, 1.6211, 1.6444, 1.6439, 1.6432, 1.6432, 1.6455, 1.6469, 1.6469,
         3.4879, 3.2794, 3.2053, 3.2634, 3.4134, 3.2322, 3.4628, 3.2134, 3.1920,
         1.6461, 1.6387, 1.6370, 1.6402, 1.6431, 1.6191, 1.6445, 1.5840, 1.6105,
         1.2972, 1.2915, 1.2817, 1.2963, 1.2922, 1.2845, 1.2966, 1.2964, 1.2986],
        [1.4508, 1.4468, 1.4038, 1.4066, 1.4443, 1.4507, 1.4493, 1.4507, 1.4507,
         1.4430, 1.4403, 1.4354, 1.4305, 1.4441, 1.4036, 1.4382, 1.4441, 1.4392,
         1.7621, 1.7534, 1.7522, 1.7603, 1.7778, 1.7764, 1.7566, 1.7779, 1.7779,
         1.4726, 1.4784, 1.5145, 1.5094, 1.4781, 1.5132, 1.5013, 1.5146, 1.5115,
         2.1996, 2.1794, 2.1681, 2.1860, 2.2299, 2.2475, 2.2138, 2.3176, 2.3145,
         1.4225, 1.4130, 1.4273, 1.4376, 1.4249, 1.4344, 1.4052, 1.4315, 1.4376],
        [1.3319, 1.2400, 1.2352, 1.2545, 1.2475, 1.2580, 1.2567, 1.1971, 1.1971,
         1.2499, 1.2090, 1.2078, 1.2117, 1.2892, 1.1698, 1.1366, 1.2892, 1.1966,
         1.5943, 1.5708, 1.5519, 1.5482, 1.5717, 1.5678, 1.5871, 1.5731, 1.5731,
         1.3325, 1.3055, 1.3064, 1.3224, 1.3077, 1.3499, 1.3523, 1.3267, 1.3065,
         1.5686, 1.5672, 1.5738, 1.5633, 1.5390, 1.5424, 1.6031, 1.4925, 1.4614,
         4.0812, 3.6434, 3.7298, 3.7149, 3.7274, 3.4159, 4.0756, 3.6916, 3.4471]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 233 : 1779.165137950797
Test loss for epoch 233 : 195.35652351428038
Test Precision for epoch 233 : 0.26153846153846155
Test Recall for epoch 233 : 0.26153846153846155
Test F1 for epoch 233 : 0.26153846153846155


theta for epoch 234 : tensor([[3.6368, 3.6592, 3.8030, 3.7496, 3.7353, 3.6186, 3.6595, 3.5594, 3.5594,
         1.2591, 1.2372, 1.2359, 1.2392, 1.2790, 1.2212, 1.1903, 1.2790, 1.2257,
         1.5967, 1.5809, 1.6053, 1.5876, 1.5933, 1.5950, 1.6024, 1.5950, 1.5950,
         1.3381, 1.3495, 1.3362, 1.3571, 1.3377, 1.3681, 1.3611, 1.3485, 1.3362,
         1.5946, 1.6109, 1.5996, 1.5959, 1.6029, 1.5931, 1.6116, 1.5649, 1.5697,
         1.2364, 1.2627, 1.2548, 1.2720, 1.2313, 1.2230, 1.2123, 1.2939, 1.2516],
        [1.3695, 1.2164, 1.2063, 1.2494, 1.2497, 1.2621, 1.2560, 1.1596, 1.1596,
         3.6170, 3.6970, 3.5510, 3.9086, 3.6178, 4.2024, 3.4916, 3.5755, 4.0027,
         1.5635, 1.5509, 1.5255, 1.5231, 1.5441, 1.5535, 1.5787, 1.5536, 1.5536,
         1.3405, 1.3069, 1.3000, 1.3589, 1.3004, 1.3968, 1.3768, 1.3450, 1.2969,
         1.5349, 1.5917, 1.5547, 1.5414, 1.5366, 1.5747, 1.5945, 1.4275, 1.5258,
         1.1378, 1.2519, 1.2245, 1.2741, 1.1316, 1.1374, 1.0636, 1.3365, 1.2146],
        [1.4521, 1.4521, 1.4505, 1.4477, 1.4481, 1.4521, 1.4478, 1.4521, 1.4521,
         1.4338, 1.4331, 1.4338, 1.4338, 1.4338, 1.4151, 1.4338, 1.4326, 1.4304,
         2.2039, 2.2042, 2.2210, 2.1966, 2.1779, 2.1762, 2.2053, 2.1752, 2.1752,
         1.5108, 1.5092, 1.5166, 1.5166, 1.5109, 1.5166, 1.5166, 1.5166, 1.5166,
         1.7772, 1.7773, 1.7773, 1.7741, 1.7772, 1.7772, 1.7773, 1.7546, 1.7573,
         1.4341, 1.4386, 1.4386, 1.4386, 1.4304, 1.4386, 1.4348, 1.4386, 1.4386],
        [1.3152, 1.3141, 1.2982, 1.2894, 1.3129, 1.3112, 1.3124, 1.3135, 1.3135,
         1.2983, 1.2916, 1.2878, 1.2873, 1.2990, 1.2837, 1.2950, 1.2986, 1.2711,
         1.6445, 1.6183, 1.6415, 1.6410, 1.6404, 1.6404, 1.6426, 1.6441, 1.6441,
         3.4940, 3.2856, 3.2116, 3.2696, 3.4195, 3.2384, 3.4689, 3.2196, 3.1983,
         1.6492, 1.6417, 1.6401, 1.6432, 1.6461, 1.6222, 1.6475, 1.5871, 1.6135,
         1.3008, 1.2952, 1.2854, 1.2999, 1.2958, 1.2881, 1.3003, 1.3000, 1.3023],
        [1.4550, 1.4510, 1.4082, 1.4109, 1.4485, 1.4549, 1.4535, 1.4549, 1.4549,
         1.4355, 1.4329, 1.4280, 1.4231, 1.4367, 1.3963, 1.4308, 1.4366, 1.4318,
         1.7596, 1.7508, 1.7496, 1.7577, 1.7752, 1.7738, 1.7541, 1.7754, 1.7754,
         1.4775, 1.4833, 1.5194, 1.5143, 1.4830, 1.5180, 1.5062, 1.5194, 1.5163,
         2.2027, 2.1826, 2.1712, 2.1891, 2.2330, 2.2506, 2.2169, 2.3206, 2.3174,
         1.4264, 1.4169, 1.4311, 1.4414, 1.4288, 1.4383, 1.4092, 1.4354, 1.4415],
        [1.3270, 1.2339, 1.2291, 1.2486, 1.2416, 1.2522, 1.2509, 1.1905, 1.1905,
         1.2384, 1.1973, 1.1961, 1.2000, 1.2777, 1.1579, 1.1249, 1.2777, 1.1849,
         1.5865, 1.5628, 1.5440, 1.5401, 1.5637, 1.5598, 1.5792, 1.5652, 1.5652,
         1.3296, 1.3024, 1.3032, 1.3195, 1.3046, 1.3473, 1.3496, 1.3238, 1.3033,
         1.5669, 1.5655, 1.5721, 1.5615, 1.5372, 1.5406, 1.6016, 1.4905, 1.4592,
         4.0964, 3.6578, 3.7443, 3.7294, 3.7420, 3.4303, 4.0909, 3.7060, 3.4615]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 234 : 1778.6923238095064
Test loss for epoch 234 : 195.71384489002864
Test Precision for epoch 234 : 0.26153846153846155
Test Recall for epoch 234 : 0.26153846153846155
Test F1 for epoch 234 : 0.26153846153846155


theta for epoch 235 : tensor([[3.6309, 3.6532, 3.7971, 3.7438, 3.7294, 3.6126, 3.6536, 3.5534, 3.5534,
         1.2549, 1.2335, 1.2322, 1.2354, 1.2743, 1.2174, 1.1877, 1.2743, 1.2221,
         1.5980, 1.5822, 1.6066, 1.5889, 1.5946, 1.5963, 1.6036, 1.5963, 1.5963,
         1.3457, 1.3572, 1.3438, 1.3647, 1.3454, 1.3757, 1.3687, 1.3562, 1.3438,
         1.5980, 1.6143, 1.6030, 1.5993, 1.6063, 1.5965, 1.6150, 1.5683, 1.5731,
         1.2404, 1.2663, 1.2585, 1.2755, 1.2353, 1.2271, 1.2165, 1.2977, 1.2554],
        [1.3727, 1.2205, 1.2103, 1.2533, 1.2536, 1.2660, 1.2599, 1.1642, 1.1642,
         3.6130, 3.6931, 3.5469, 3.9053, 3.6139, 4.2000, 3.4874, 3.5714, 3.9997,
         1.5652, 1.5527, 1.5273, 1.5250, 1.5460, 1.5554, 1.5804, 1.5554, 1.5554,
         1.3457, 1.3121, 1.3055, 1.3641, 1.3057, 1.4018, 1.3819, 1.3502, 1.3024,
         1.5386, 1.5952, 1.5583, 1.5451, 1.5402, 1.5782, 1.5980, 1.4312, 1.5294,
         1.1416, 1.2549, 1.2277, 1.2768, 1.1357, 1.1417, 1.0678, 1.3394, 1.2180],
        [1.4544, 1.4544, 1.4528, 1.4500, 1.4504, 1.4544, 1.4501, 1.4544, 1.4544,
         1.4282, 1.4275, 1.4282, 1.4282, 1.4282, 1.4095, 1.4282, 1.4271, 1.4248,
         2.2035, 2.2038, 2.2207, 2.1962, 2.1775, 2.1758, 2.2050, 2.1749, 2.1749,
         1.5155, 1.5139, 1.5213, 1.5213, 1.5155, 1.5213, 1.5213, 1.5213, 1.5213,
         1.7792, 1.7793, 1.7793, 1.7761, 1.7792, 1.7792, 1.7793, 1.7566, 1.7593,
         1.4360, 1.4406, 1.4406, 1.4406, 1.4324, 1.4406, 1.4367, 1.4406, 1.4406],
        [1.3177, 1.3166, 1.3008, 1.2919, 1.3155, 1.3138, 1.3149, 1.3160, 1.3160,
         1.2925, 1.2859, 1.2821, 1.2816, 1.2932, 1.2780, 1.2894, 1.2928, 1.2655,
         1.6439, 1.6177, 1.6409, 1.6404, 1.6398, 1.6398, 1.6420, 1.6435, 1.6435,
         3.4996, 3.2913, 3.2174, 3.2753, 3.4252, 3.2442, 3.4746, 3.2254, 3.2041,
         1.6510, 1.6435, 1.6419, 1.6451, 1.6480, 1.6240, 1.6494, 1.5889, 1.6154,
         1.3027, 1.2970, 1.2872, 1.3017, 1.2977, 1.2900, 1.3022, 1.3018, 1.3041],
        [1.4572, 1.4533, 1.4106, 1.4133, 1.4508, 1.4571, 1.4557, 1.4572, 1.4572,
         1.4300, 1.4273, 1.4224, 1.4176, 1.4311, 1.3908, 1.4252, 1.4311, 1.4263,
         1.7591, 1.7504, 1.7492, 1.7573, 1.7747, 1.7734, 1.7536, 1.7749, 1.7749,
         1.4822, 1.4881, 1.5241, 1.5190, 1.4878, 1.5227, 1.5109, 1.5241, 1.5210,
         2.2046, 2.1845, 2.1732, 2.1910, 2.2348, 2.2525, 2.2188, 2.3223, 2.3192,
         1.4284, 1.4189, 1.4331, 1.4434, 1.4308, 1.4402, 1.4113, 1.4374, 1.4434],
        [1.3446, 1.2513, 1.2466, 1.2660, 1.2591, 1.2696, 1.2683, 1.2076, 1.2076,
         1.2402, 1.1999, 1.1987, 1.2025, 1.2790, 1.1604, 1.1289, 1.2790, 1.1876,
         1.5952, 1.5716, 1.5529, 1.5488, 1.5724, 1.5685, 1.5879, 1.5738, 1.5738,
         1.3470, 1.3198, 1.3204, 1.3369, 1.3219, 1.3647, 1.3670, 1.3411, 1.3205,
         1.5763, 1.5751, 1.5815, 1.5710, 1.5467, 1.5502, 1.6110, 1.5002, 1.4692,
         4.0806, 3.6412, 3.7278, 3.7128, 3.7254, 3.4135, 4.0751, 3.6894, 3.4447]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 235 : 1779.3936220083153
Test loss for epoch 235 : 194.98833116084143
Test Precision for epoch 235 : 0.26153846153846155
Test Recall for epoch 235 : 0.26153846153846155
Test F1 for epoch 235 : 0.26153846153846155


theta for epoch 236 : tensor([[3.6243, 3.6465, 3.7905, 3.7372, 3.7227, 3.6059, 3.6469, 3.5465, 3.5465,
         1.2574, 1.2364, 1.2351, 1.2382, 1.2765, 1.2202, 1.1913, 1.2765, 1.2251,
         1.6015, 1.5857, 1.6101, 1.5925, 1.5982, 1.5998, 1.6071, 1.5998, 1.5998,
         1.3395, 1.3509, 1.3375, 1.3584, 1.3391, 1.3694, 1.3624, 1.3499, 1.3375,
         1.5982, 1.6144, 1.6031, 1.5995, 1.6065, 1.5966, 1.6151, 1.5685, 1.5733,
         1.2460, 1.2718, 1.2641, 1.2809, 1.2410, 1.2329, 1.2223, 1.3033, 1.2609],
        [1.3670, 1.2159, 1.2055, 1.2485, 1.2488, 1.2612, 1.2551, 1.1602, 1.1602,
         3.6174, 3.6976, 3.5512, 3.9103, 3.6183, 4.2059, 3.4914, 3.5758, 4.0050,
         1.5647, 1.5522, 1.5267, 1.5246, 1.5456, 1.5551, 1.5800, 1.5551, 1.5551,
         1.3383, 1.3048, 1.2985, 1.3566, 1.2984, 1.3941, 1.3743, 1.3428, 1.2953,
         1.5359, 1.5925, 1.5557, 1.5425, 1.5375, 1.5755, 1.5952, 1.4284, 1.5267,
         1.1423, 1.2551, 1.2282, 1.2769, 1.1365, 1.1429, 1.0687, 1.3398, 1.2186],
        [1.4506, 1.4506, 1.4490, 1.4462, 1.4466, 1.4506, 1.4463, 1.4506, 1.4506,
         1.4297, 1.4291, 1.4297, 1.4297, 1.4297, 1.4111, 1.4297, 1.4286, 1.4263,
         2.2057, 2.2060, 2.2228, 2.1983, 2.1797, 2.1779, 2.2071, 2.1770, 2.1770,
         1.5073, 1.5057, 1.5131, 1.5131, 1.5073, 1.5131, 1.5131, 1.5131, 1.5131,
         1.7784, 1.7785, 1.7785, 1.7753, 1.7784, 1.7784, 1.7785, 1.7558, 1.7586,
         1.4405, 1.4451, 1.4451, 1.4451, 1.4368, 1.4451, 1.4412, 1.4450, 1.4451],
        [1.3142, 1.3130, 1.2972, 1.2884, 1.3119, 1.3102, 1.3114, 1.3124, 1.3124,
         1.2939, 1.2873, 1.2835, 1.2830, 1.2946, 1.2794, 1.2909, 1.2942, 1.2669,
         1.6461, 1.6199, 1.6431, 1.6426, 1.6419, 1.6420, 1.6442, 1.6457, 1.6457,
         3.4942, 3.2858, 3.2119, 3.2698, 3.4197, 3.2387, 3.4692, 3.2198, 3.1985,
         1.6502, 1.6427, 1.6410, 1.6442, 1.6471, 1.6231, 1.6485, 1.5880, 1.6145,
         1.3071, 1.3014, 1.2916, 1.3061, 1.3021, 1.2944, 1.3066, 1.3062, 1.3085],
        [1.4535, 1.4495, 1.4068, 1.4095, 1.4470, 1.4534, 1.4520, 1.4534, 1.4534,
         1.4315, 1.4289, 1.4239, 1.4191, 1.4326, 1.3924, 1.4267, 1.4326, 1.4278,
         1.7614, 1.7526, 1.7515, 1.7596, 1.7769, 1.7756, 1.7559, 1.7771, 1.7771,
         1.4741, 1.4800, 1.5159, 1.5108, 1.4796, 1.5145, 1.5027, 1.5159, 1.5128,
         2.2038, 2.1838, 2.1725, 2.1902, 2.2341, 2.2517, 2.2181, 2.3215, 2.3184,
         1.4330, 1.4234, 1.4376, 1.4479, 1.4353, 1.4447, 1.4159, 1.4418, 1.4479],
        [1.3539, 1.2599, 1.2553, 1.2748, 1.2679, 1.2783, 1.2770, 1.2158, 1.2158,
         1.2469, 1.2069, 1.2058, 1.2095, 1.2854, 1.1671, 1.1362, 1.2854, 1.1946,
         1.6040, 1.5805, 1.5619, 1.5576, 1.5811, 1.5772, 1.5968, 1.5826, 1.5826,
         1.3502, 1.3231, 1.3234, 1.3403, 1.3251, 1.3682, 1.3703, 1.3443, 1.3234,
         1.5809, 1.5800, 1.5862, 1.5757, 1.5516, 1.5551, 1.6158, 1.5052, 1.4743,
         4.0707, 3.6305, 3.7172, 3.7022, 3.7149, 3.4027, 4.0653, 3.6788, 3.4340]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 236 : 1779.0960648900857
Test loss for epoch 236 : 194.91782390555977
Test Precision for epoch 236 : 0.26153846153846155
Test Recall for epoch 236 : 0.26153846153846155
Test F1 for epoch 236 : 0.26153846153846155


theta for epoch 237 : tensor([[3.6206, 3.6427, 3.7868, 3.7335, 3.7189, 3.6022, 3.6432, 3.5427, 3.5427,
         1.2630, 1.2422, 1.2409, 1.2440, 1.2818, 1.2259, 1.1974, 1.2818, 1.2309,
         1.6021, 1.5864, 1.6107, 1.5931, 1.5988, 1.6005, 1.6077, 1.6004, 1.6004,
         1.3330, 1.3444, 1.3309, 1.3519, 1.3326, 1.3629, 1.3560, 1.3434, 1.3310,
         1.5949, 1.6111, 1.5999, 1.5962, 1.6032, 1.5933, 1.6118, 1.5653, 1.5700,
         1.2505, 1.2761, 1.2684, 1.2852, 1.2455, 1.2375, 1.2269, 1.3078, 1.2653],
        [1.3568, 1.2064, 1.1960, 1.2389, 1.2392, 1.2516, 1.2455, 1.1511, 1.1511,
         3.6281, 3.7085, 3.5618, 3.9216, 3.6290, 4.2182, 3.5019, 3.5864, 4.0166,
         1.5588, 1.5463, 1.5206, 1.5187, 1.5398, 1.5493, 1.5741, 1.5493, 1.5493,
         1.3269, 1.2934, 1.2874, 1.3452, 1.2871, 1.3826, 1.3628, 1.3315, 1.2842,
         1.5273, 1.5839, 1.5471, 1.5338, 1.5288, 1.5669, 1.5865, 1.4194, 1.5180,
         1.1384, 1.2512, 1.2243, 1.2728, 1.1328, 1.1394, 1.0650, 1.3363, 1.2148],
        [1.4472, 1.4472, 1.4456, 1.4428, 1.4432, 1.4472, 1.4429, 1.4472, 1.4472,
         1.4348, 1.4341, 1.4347, 1.4347, 1.4348, 1.4161, 1.4347, 1.4336, 1.4314,
         2.2057, 2.2060, 2.2228, 2.1983, 2.1797, 2.1780, 2.2071, 2.1771, 2.1771,
         1.4999, 1.4983, 1.5057, 1.5057, 1.5000, 1.5057, 1.5057, 1.5057, 1.5057,
         1.7747, 1.7747, 1.7747, 1.7716, 1.7746, 1.7746, 1.7747, 1.7521, 1.7548,
         1.4444, 1.4489, 1.4489, 1.4489, 1.4407, 1.4489, 1.4451, 1.4489, 1.4489],
        [1.3112, 1.3100, 1.2942, 1.2854, 1.3089, 1.3072, 1.3083, 1.3093, 1.3093,
         1.2989, 1.2923, 1.2885, 1.2880, 1.2995, 1.2844, 1.2959, 1.2991, 1.2719,
         1.6460, 1.6197, 1.6429, 1.6425, 1.6418, 1.6419, 1.6441, 1.6456, 1.6456,
         3.4892, 3.2808, 3.2068, 3.2648, 3.4147, 3.2337, 3.4643, 3.2148, 3.1935,
         1.6463, 1.6388, 1.6372, 1.6403, 1.6433, 1.6193, 1.6446, 1.5842, 1.6106,
         1.3109, 1.3052, 1.2954, 1.3099, 1.3059, 1.2982, 1.3104, 1.3100, 1.3123],
        [1.4501, 1.4461, 1.4034, 1.4062, 1.4436, 1.4500, 1.4486, 1.4501, 1.4501,
         1.4365, 1.4339, 1.4289, 1.4242, 1.4376, 1.3975, 1.4317, 1.4376, 1.4328,
         1.7613, 1.7526, 1.7515, 1.7595, 1.7769, 1.7756, 1.7558, 1.7770, 1.7770,
         1.4667, 1.4726, 1.5085, 1.5034, 1.4722, 1.5072, 1.4953, 1.5085, 1.5054,
         2.2002, 2.1802, 2.1689, 2.1866, 2.2304, 2.2482, 2.2146, 2.3178, 2.3147,
         1.4369, 1.4273, 1.4415, 1.4517, 1.4393, 1.4486, 1.4198, 1.4457, 1.4518],
        [1.3593, 1.2646, 1.2602, 1.2796, 1.2728, 1.2831, 1.2819, 1.2200, 1.2200,
         1.2550, 1.2149, 1.2138, 1.2175, 1.2935, 1.1747, 1.1437, 1.2935, 1.2024,
         1.6084, 1.5849, 1.5663, 1.5619, 1.5854, 1.5815, 1.6012, 1.5868, 1.5868,
         1.3506, 1.3236, 1.3235, 1.3408, 1.3255, 1.3688, 1.3708, 1.3447, 1.3235,
         1.5808, 1.5800, 1.5861, 1.5756, 1.5516, 1.5552, 1.6158, 1.5052, 1.4745,
         4.0655, 3.6245, 3.7112, 3.6963, 3.7089, 3.3965, 4.0601, 3.6728, 3.4279]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 237 : 1778.927426343693
Test loss for epoch 237 : 195.37226409305836
Test Precision for epoch 237 : 0.26153846153846155
Test Recall for epoch 237 : 0.26153846153846155
Test F1 for epoch 237 : 0.26153846153846155


theta for epoch 238 : tensor([[3.6170, 3.6390, 3.7832, 3.7298, 3.7152, 3.5985, 3.6395, 3.5389, 3.5389,
         1.2642, 1.2440, 1.2428, 1.2457, 1.2825, 1.2276, 1.2003, 1.2826, 1.2327,
         1.6007, 1.5850, 1.6092, 1.5918, 1.5974, 1.5991, 1.6063, 1.5991, 1.5991,
         1.3388, 1.3502, 1.3368, 1.3577, 1.3384, 1.3687, 1.3617, 1.3492, 1.3368,
         1.5935, 1.6097, 1.5985, 1.5948, 1.6018, 1.5919, 1.6103, 1.5639, 1.5686,
         1.2526, 1.2779, 1.2704, 1.2870, 1.2477, 1.2397, 1.2292, 1.3097, 1.2673],
        [1.3690, 1.2196, 1.2091, 1.2519, 1.2522, 1.2646, 1.2585, 1.1647, 1.1647,
         3.6171, 3.6977, 3.5507, 3.9113, 3.6181, 4.2087, 3.4907, 3.5754, 4.0065,
         1.5650, 1.5527, 1.5270, 1.5252, 1.5463, 1.5557, 1.5803, 1.5557, 1.5557,
         1.3387, 1.3053, 1.2994, 1.3569, 1.2991, 1.3941, 1.3744, 1.3433, 1.2963,
         1.5329, 1.5893, 1.5527, 1.5395, 1.5345, 1.5724, 1.5918, 1.4256, 1.5237,
         1.1474, 1.2595, 1.2329, 1.2810, 1.1419, 1.1485, 1.0743, 1.3446, 1.2234],
        [1.4509, 1.4509, 1.4493, 1.4465, 1.4469, 1.4509, 1.4466, 1.4509, 1.4509,
         1.4348, 1.4342, 1.4348, 1.4348, 1.4348, 1.4162, 1.4348, 1.4337, 1.4314,
         2.2032, 2.2035, 2.2203, 2.1959, 2.1773, 2.1756, 2.2047, 2.1747, 2.1747,
         1.5037, 1.5021, 1.5095, 1.5095, 1.5038, 1.5095, 1.5095, 1.5095, 1.5095,
         1.7721, 1.7722, 1.7722, 1.7691, 1.7721, 1.7721, 1.7722, 1.7496, 1.7523,
         1.4451, 1.4496, 1.4496, 1.4496, 1.4414, 1.4496, 1.4458, 1.4496, 1.4496],
        [1.3156, 1.3142, 1.2984, 1.2896, 1.3131, 1.3115, 1.3126, 1.3135, 1.3135,
         1.2989, 1.2923, 1.2885, 1.2880, 1.2995, 1.2844, 1.2960, 1.2991, 1.2719,
         1.6432, 1.6169, 1.6402, 1.6397, 1.6390, 1.6391, 1.6413, 1.6428, 1.6428,
         3.4935, 3.2851, 3.2111, 3.2691, 3.4190, 3.2380, 3.4685, 3.2191, 3.1978,
         1.6437, 1.6362, 1.6346, 1.6378, 1.6407, 1.6167, 1.6420, 1.5816, 1.6080,
         1.3116, 1.3058, 1.2961, 1.3105, 1.3065, 1.2989, 1.3111, 1.3106, 1.3129],
        [1.4537, 1.4498, 1.4070, 1.4099, 1.4473, 1.4536, 1.4522, 1.4537, 1.4537,
         1.4366, 1.4340, 1.4290, 1.4243, 1.4377, 1.3976, 1.4318, 1.4377, 1.4329,
         1.7586, 1.7498, 1.7488, 1.7568, 1.7742, 1.7728, 1.7531, 1.7743, 1.7743,
         1.4705, 1.4765, 1.5123, 1.5072, 1.4760, 1.5109, 1.4991, 1.5123, 1.5092,
         2.1978, 2.1778, 2.1665, 2.1842, 2.2280, 2.2458, 2.2122, 2.3153, 2.3122,
         1.4376, 1.4280, 1.4422, 1.4524, 1.4400, 1.4493, 1.4206, 1.4464, 1.4524],
        [1.3696, 1.2747, 1.2703, 1.2898, 1.2829, 1.2933, 1.2920, 1.2300, 1.2300,
         1.2587, 1.2192, 1.2181, 1.2217, 1.2966, 1.1785, 1.1486, 1.2966, 1.2066,
         1.6105, 1.5869, 1.5685, 1.5639, 1.5873, 1.5835, 1.6033, 1.5888, 1.5888,
         1.3603, 1.3333, 1.3331, 1.3505, 1.3351, 1.3786, 1.3805, 1.3544, 1.3331,
         1.5821, 1.5814, 1.5873, 1.5769, 1.5529, 1.5566, 1.6171, 1.5067, 1.4760,
         4.0584, 3.6167, 3.7035, 3.6885, 3.7012, 3.3886, 4.0531, 3.6650, 3.4200]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 238 : 1779.3086418149242
Test loss for epoch 238 : 194.74414602950446
Test Precision for epoch 238 : 0.26153846153846155
Test Recall for epoch 238 : 0.26153846153846155
Test F1 for epoch 238 : 0.26153846153846155


theta for epoch 239 : tensor([[3.6146, 3.6366, 3.7808, 3.7275, 3.7128, 3.5961, 3.6371, 3.5365, 3.5365,
         1.2637, 1.2439, 1.2427, 1.2455, 1.2817, 1.2273, 1.2007, 1.2817, 1.2326,
         1.5990, 1.5833, 1.6075, 1.5902, 1.5958, 1.5975, 1.6046, 1.5975, 1.5975,
         1.3450, 1.3563, 1.3430, 1.3639, 1.3446, 1.3748, 1.3679, 1.3554, 1.3430,
         1.5949, 1.6110, 1.5999, 1.5962, 1.6032, 1.5933, 1.6116, 1.5653, 1.5700,
         1.2526, 1.2777, 1.2702, 1.2867, 1.2477, 1.2398, 1.2293, 1.3096, 1.2672],
        [1.3740, 1.2249, 1.2144, 1.2572, 1.2574, 1.2699, 1.2638, 1.1703, 1.1703,
         3.6123, 3.6930, 3.5457, 3.9071, 3.6132, 4.2055, 3.4856, 3.5706, 4.0026,
         1.5669, 1.5546, 1.5290, 1.5273, 1.5483, 1.5577, 1.5822, 1.5577, 1.5577,
         1.3459, 1.3125, 1.3067, 1.3641, 1.3063, 1.4012, 1.3816, 1.3505, 1.3035,
         1.5370, 1.5932, 1.5568, 1.5435, 1.5385, 1.5763, 1.5958, 1.4298, 1.5278,
         1.1505, 1.2622, 1.2357, 1.2836, 1.1449, 1.1516, 1.0776, 1.3476, 1.2263],
        [1.4515, 1.4515, 1.4499, 1.4471, 1.4475, 1.4515, 1.4472, 1.4515, 1.4515,
         1.4337, 1.4331, 1.4337, 1.4337, 1.4337, 1.4151, 1.4337, 1.4326, 1.4303,
         2.2011, 2.2013, 2.2182, 2.1939, 2.1753, 2.1735, 2.2027, 2.1726, 2.1726,
         1.5091, 1.5074, 1.5148, 1.5148, 1.5091, 1.5148, 1.5148, 1.5148, 1.5148,
         1.7729, 1.7730, 1.7730, 1.7698, 1.7729, 1.7729, 1.7730, 1.7504, 1.7531,
         1.4443, 1.4488, 1.4488, 1.4488, 1.4407, 1.4488, 1.4450, 1.4488, 1.4488],
        [1.3168, 1.3154, 1.2996, 1.2908, 1.3143, 1.3127, 1.3138, 1.3146, 1.3146,
         1.2978, 1.2912, 1.2874, 1.2869, 1.2984, 1.2833, 1.2949, 1.2980, 1.2708,
         1.6408, 1.6146, 1.6378, 1.6374, 1.6367, 1.6368, 1.6389, 1.6405, 1.6405,
         3.4988, 3.2904, 3.2165, 3.2744, 3.4243, 3.2432, 3.4738, 3.2244, 3.2031,
         1.6445, 1.6370, 1.6354, 1.6385, 1.6414, 1.6174, 1.6428, 1.5823, 1.6088,
         1.3108, 1.3051, 1.2953, 1.3098, 1.3058, 1.2981, 1.3103, 1.3099, 1.3122],
        [1.4543, 1.4503, 1.4076, 1.4105, 1.4479, 1.4542, 1.4528, 1.4543, 1.4543,
         1.4355, 1.4329, 1.4279, 1.4232, 1.4366, 1.3966, 1.4307, 1.4365, 1.4319,
         1.7563, 1.7475, 1.7465, 1.7545, 1.7719, 1.7705, 1.7508, 1.7720, 1.7720,
         1.4759, 1.4818, 1.5176, 1.5125, 1.4814, 1.5163, 1.5045, 1.5176, 1.5145,
         2.1986, 2.1786, 2.1673, 2.1850, 2.2287, 2.2465, 2.2129, 2.3159, 2.3129,
         1.4369, 1.4272, 1.4414, 1.4516, 1.4392, 1.4485, 1.4198, 1.4456, 1.4517],
        [1.3729, 1.2781, 1.2738, 1.2932, 1.2863, 1.2967, 1.2954, 1.2334, 1.2334,
         1.2593, 1.2200, 1.2190, 1.2225, 1.2970, 1.1788, 1.1494, 1.2970, 1.2073,
         1.6105, 1.5870, 1.5686, 1.5639, 1.5873, 1.5834, 1.6033, 1.5887, 1.5887,
         1.3677, 1.3407, 1.3403, 1.3579, 1.3425, 1.3860, 1.3879, 1.3617, 1.3404,
         1.5845, 1.5839, 1.5897, 1.5793, 1.5554, 1.5591, 1.6196, 1.5092, 1.4786,
         4.0556, 3.6131, 3.7000, 3.6850, 3.6978, 3.3849, 4.0504, 3.6614, 3.4163]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 239 : 1779.650783365514
Test loss for epoch 239 : 194.41844375556667
Test Precision for epoch 239 : 0.26153846153846155
Test Recall for epoch 239 : 0.26153846153846155
Test F1 for epoch 239 : 0.26153846153846155


theta for epoch 240 : tensor([[3.6128, 3.6347, 3.7790, 3.7257, 3.7109, 3.5942, 3.6353, 3.5346, 3.5346,
         1.2644, 1.2447, 1.2435, 1.2463, 1.2821, 1.2279, 1.2016, 1.2822, 1.2333,
         1.6001, 1.5845, 1.6087, 1.5914, 1.5970, 1.5987, 1.6058, 1.5987, 1.5987,
         1.3399, 1.3512, 1.3378, 1.3587, 1.3395, 1.3696, 1.3627, 1.3502, 1.3378,
         1.5984, 1.6144, 1.6033, 1.5997, 1.6066, 1.5967, 1.6150, 1.5688, 1.5735,
         1.2532, 1.2782, 1.2707, 1.2871, 1.2483, 1.2405, 1.2300, 1.3101, 1.2677],
        [1.3716, 1.2226, 1.2121, 1.2549, 1.2551, 1.2676, 1.2615, 1.1681, 1.1681,
         3.6139, 3.6947, 3.5473, 3.9094, 3.6149, 4.2086, 3.4869, 3.5722, 4.0051,
         1.5671, 1.5547, 1.5291, 1.5273, 1.5484, 1.5578, 1.5823, 1.5578, 1.5578,
         1.3420, 1.3087, 1.3029, 1.3603, 1.3025, 1.3974, 1.3778, 1.3467, 1.2997,
         1.5390, 1.5954, 1.5589, 1.5456, 1.5406, 1.5785, 1.5979, 1.4318, 1.5298,
         1.1498, 1.2616, 1.2350, 1.2830, 1.1442, 1.1509, 1.0769, 1.3474, 1.2256],
        [1.4485, 1.4485, 1.4469, 1.4441, 1.4445, 1.4485, 1.4443, 1.4485, 1.4485,
         1.4342, 1.4336, 1.4342, 1.4342, 1.4342, 1.4156, 1.4342, 1.4331, 1.4308,
         2.2021, 2.2024, 2.2192, 2.1948, 2.1763, 2.1745, 2.2037, 2.1736, 2.1736,
         1.5042, 1.5025, 1.5099, 1.5099, 1.5042, 1.5099, 1.5099, 1.5099, 1.5099,
         1.7761, 1.7762, 1.7762, 1.7731, 1.7761, 1.7761, 1.7762, 1.7536, 1.7564,
         1.4448, 1.4493, 1.4493, 1.4493, 1.4411, 1.4493, 1.4455, 1.4492, 1.4493],
        [1.3145, 1.3130, 1.2972, 1.2884, 1.3119, 1.3103, 1.3114, 1.3121, 1.3121,
         1.2983, 1.2918, 1.2879, 1.2874, 1.2989, 1.2838, 1.2954, 1.2985, 1.2714,
         1.6420, 1.6157, 1.6390, 1.6385, 1.6378, 1.6379, 1.6401, 1.6416, 1.6416,
         3.4949, 3.2864, 3.2124, 3.2703, 3.4203, 3.2392, 3.4699, 3.2203, 3.1990,
         1.6478, 1.6403, 1.6387, 1.6418, 1.6447, 1.6207, 1.6461, 1.5856, 1.6120,
         1.3114, 1.3056, 1.2959, 1.3104, 1.3064, 1.2987, 1.3109, 1.3105, 1.3128],
        [1.4514, 1.4473, 1.4044, 1.4075, 1.4448, 1.4513, 1.4498, 1.4514, 1.4514,
         1.4360, 1.4334, 1.4285, 1.4237, 1.4371, 1.3971, 1.4312, 1.4371, 1.4324,
         1.7573, 1.7486, 1.7475, 1.7555, 1.7729, 1.7715, 1.7518, 1.7730, 1.7730,
         1.4710, 1.4769, 1.5127, 1.5076, 1.4765, 1.5113, 1.4996, 1.5127, 1.5096,
         2.2017, 2.1818, 2.1705, 2.1882, 2.2319, 2.2497, 2.2161, 2.3190, 2.3160,
         1.4373, 1.4276, 1.4419, 1.4521, 1.4397, 1.4489, 1.4203, 1.4461, 1.4521],
        [1.3693, 1.2748, 1.2705, 1.2898, 1.2830, 1.2933, 1.2920, 1.2302, 1.2302,
         1.2596, 1.2203, 1.2192, 1.2228, 1.2973, 1.1785, 1.1490, 1.2973, 1.2073,
         1.6114, 1.5878, 1.5694, 1.5648, 1.5881, 1.5843, 1.6041, 1.5896, 1.5896,
         1.3631, 1.3361, 1.3357, 1.3533, 1.3379, 1.3813, 1.3832, 1.3571, 1.3358,
         1.5875, 1.5869, 1.5928, 1.5823, 1.5584, 1.5621, 1.6226, 1.5121, 1.4815,
         4.0576, 3.6144, 3.7013, 3.6863, 3.6991, 3.3860, 4.0524, 3.6627, 3.4174]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 240 : 1779.45669335852
Test loss for epoch 240 : 194.54206140862456
Test Precision for epoch 240 : 0.26153846153846155
Test Recall for epoch 240 : 0.26153846153846155
Test F1 for epoch 240 : 0.26153846153846155


theta for epoch 241 : tensor([[3.6150, 3.6369, 3.7812, 3.7279, 3.7131, 3.5964, 3.6375, 3.5368, 3.5368,
         1.2645, 1.2449, 1.2437, 1.2465, 1.2823, 1.2279, 1.2015, 1.2823, 1.2334,
         1.6018, 1.5862, 1.6104, 1.5931, 1.5988, 1.6004, 1.6075, 1.6004, 1.6004,
         1.3340, 1.3453, 1.3320, 1.3528, 1.3337, 1.3638, 1.3568, 1.3443, 1.3320,
         1.5996, 1.6155, 1.6045, 1.6009, 1.6077, 1.5978, 1.6161, 1.5699, 1.5746,
         1.2527, 1.2776, 1.2702, 1.2865, 1.2478, 1.2401, 1.2296, 1.3094, 1.2672],
        [1.3658, 1.2164, 1.2059, 1.2487, 1.2490, 1.2614, 1.2553, 1.1617, 1.1617,
         3.6209, 3.7018, 3.5541, 3.9170, 3.6218, 4.2171, 3.4937, 3.5791, 4.0130,
         1.5641, 1.5517, 1.5260, 1.5242, 1.5453, 1.5547, 1.5794, 1.5547, 1.5547,
         1.3339, 1.3005, 1.2946, 1.3522, 1.2943, 1.3894, 1.3697, 1.3385, 1.2914,
         1.5359, 1.5925, 1.5558, 1.5425, 1.5375, 1.5755, 1.5950, 1.4283, 1.5266,
         1.1446, 1.2567, 1.2301, 1.2783, 1.1390, 1.1457, 1.0715, 1.3432, 1.2206],
        [1.4482, 1.4482, 1.4466, 1.4438, 1.4442, 1.4483, 1.4440, 1.4483, 1.4483,
         1.4347, 1.4341, 1.4347, 1.4347, 1.4347, 1.4161, 1.4347, 1.4336, 1.4314,
         2.2041, 2.2044, 2.2212, 2.1968, 2.1782, 2.1765, 2.2056, 2.1756, 2.1756,
         1.4995, 1.4979, 1.5053, 1.5053, 1.4996, 1.5053, 1.5053, 1.5053, 1.5053,
         1.7775, 1.7776, 1.7776, 1.7745, 1.7775, 1.7775, 1.7776, 1.7550, 1.7578,
         1.4446, 1.4491, 1.4491, 1.4491, 1.4410, 1.4492, 1.4454, 1.4491, 1.4492],
        [1.3150, 1.3134, 1.2975, 1.2888, 1.3123, 1.3107, 1.3118, 1.3124, 1.3124,
         1.2989, 1.2923, 1.2885, 1.2880, 1.2995, 1.2844, 1.2959, 1.2991, 1.2719,
         1.6442, 1.6180, 1.6412, 1.6407, 1.6401, 1.6401, 1.6423, 1.6438, 1.6438,
         3.4909, 3.2823, 3.2082, 3.2662, 3.4163, 3.2351, 3.4659, 3.2162, 3.1949,
         1.6493, 1.6418, 1.6402, 1.6433, 1.6462, 1.6222, 1.6476, 1.5871, 1.6135,
         1.3114, 1.3057, 1.2959, 1.3104, 1.3064, 1.2987, 1.3109, 1.3106, 1.3128],
        [1.4511, 1.4470, 1.4040, 1.4072, 1.4445, 1.4510, 1.4495, 1.4511, 1.4511,
         1.4365, 1.4339, 1.4290, 1.4242, 1.4376, 1.3976, 1.4317, 1.4376, 1.4329,
         1.7594, 1.7506, 1.7496, 1.7576, 1.7749, 1.7736, 1.7539, 1.7751, 1.7751,
         1.4664, 1.4722, 1.5081, 1.5030, 1.4718, 1.5067, 1.4950, 1.5081, 1.5050,
         2.2031, 2.1832, 2.1719, 2.1896, 2.2333, 2.2511, 2.2175, 2.3203, 2.3173,
         1.4372, 1.4275, 1.4418, 1.4519, 1.4396, 1.4488, 1.4202, 1.4460, 1.4520],
        [1.3640, 1.2699, 1.2655, 1.2848, 1.2780, 1.2883, 1.2870, 1.2255, 1.2255,
         1.2582, 1.2187, 1.2176, 1.2213, 1.2962, 1.1762, 1.1461, 1.2962, 1.2054,
         1.6112, 1.5877, 1.5692, 1.5646, 1.5880, 1.5841, 1.6040, 1.5895, 1.5895,
         1.3557, 1.3287, 1.3284, 1.3459, 1.3305, 1.3739, 1.3758, 1.3497, 1.3285,
         1.5871, 1.5864, 1.5923, 1.5819, 1.5579, 1.5616, 1.6222, 1.5116, 1.4809,
         4.0632, 3.6192, 3.7063, 3.6912, 3.7041, 3.3908, 4.0581, 3.6675, 3.4222]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 241 : 1779.225905599507
Test loss for epoch 241 : 194.96462108543437
Test Precision for epoch 241 : 0.26153846153846155
Test Recall for epoch 241 : 0.26153846153846155
Test F1 for epoch 241 : 0.26153846153846155


theta for epoch 242 : tensor([[3.6224, 3.6444, 3.7886, 3.7354, 3.7205, 3.6039, 3.6450, 3.5445, 3.5445,
         1.2619, 1.2422, 1.2410, 1.2438, 1.2797, 1.2249, 1.1981, 1.2797, 1.2305,
         1.6017, 1.5861, 1.6102, 1.5930, 1.5987, 1.6004, 1.6074, 1.6003, 1.6003,
         1.3373, 1.3485, 1.3352, 1.3560, 1.3369, 1.3669, 1.3600, 1.3475, 1.3352,
         1.5972, 1.6131, 1.6021, 1.5985, 1.6054, 1.5954, 1.6137, 1.5676, 1.5723,
         1.2501, 1.2749, 1.2675, 1.2837, 1.2453, 1.2375, 1.2270, 1.3066, 1.2645],
        [1.3584, 1.2079, 1.1973, 1.2404, 1.2406, 1.2531, 1.2470, 1.1527, 1.1527,
         3.6318, 3.7129, 3.5649, 3.9285, 3.6327, 4.2295, 3.5044, 3.5899, 4.0248,
         1.5569, 1.5444, 1.5186, 1.5166, 1.5378, 1.5473, 1.5722, 1.5473, 1.5473,
         1.3276, 1.2940, 1.2879, 1.3460, 1.2877, 1.3835, 1.3637, 1.3322, 1.2847,
         1.5270, 1.5839, 1.5470, 1.5336, 1.5286, 1.5669, 1.5866, 1.4190, 1.5177,
         1.1348, 1.2476, 1.2208, 1.2693, 1.1292, 1.1358, 1.0615, 1.3349, 1.2112],
        [1.4524, 1.4524, 1.4508, 1.4480, 1.4484, 1.4525, 1.4482, 1.4525, 1.4525,
         1.4329, 1.4323, 1.4329, 1.4329, 1.4329, 1.4143, 1.4329, 1.4318, 1.4295,
         2.2049, 2.2052, 2.2220, 2.1975, 2.1790, 2.1773, 2.2064, 2.1764, 2.1764,
         1.5048, 1.5031, 1.5105, 1.5105, 1.5048, 1.5105, 1.5105, 1.5105, 1.5105,
         1.7759, 1.7760, 1.7760, 1.7728, 1.7759, 1.7759, 1.7760, 1.7534, 1.7561,
         1.4430, 1.4475, 1.4475, 1.4475, 1.4393, 1.4475, 1.4437, 1.4475, 1.4475],
        [1.3200, 1.3182, 1.3023, 1.2936, 1.3171, 1.3155, 1.3166, 1.3172, 1.3172,
         1.2971, 1.2905, 1.2867, 1.2862, 1.2977, 1.2826, 1.2941, 1.2973, 1.2701,
         1.6452, 1.6189, 1.6422, 1.6417, 1.6411, 1.6411, 1.6433, 1.6448, 1.6448,
         3.4952, 3.2866, 3.2126, 3.2705, 3.4206, 3.2394, 3.4703, 3.2205, 3.1992,
         1.6477, 1.6402, 1.6386, 1.6417, 1.6446, 1.6206, 1.6460, 1.5855, 1.6119,
         1.3099, 1.3042, 1.2944, 1.3089, 1.3049, 1.2972, 1.3094, 1.3091, 1.3113],
        [1.4553, 1.4511, 1.4080, 1.4113, 1.4487, 1.4552, 1.4537, 1.4553, 1.4553,
         1.4347, 1.4321, 1.4272, 1.4224, 1.4358, 1.3958, 1.4299, 1.4357, 1.4311,
         1.7602, 1.7515, 1.7504, 1.7584, 1.7758, 1.7744, 1.7547, 1.7759, 1.7759,
         1.4717, 1.4774, 1.5133, 1.5082, 1.4771, 1.5119, 1.5002, 1.5133, 1.5102,
         2.2016, 2.1817, 2.1704, 2.1880, 2.2317, 2.2496, 2.2160, 2.3188, 2.3158,
         1.4355, 1.4259, 1.4401, 1.4503, 1.4379, 1.4472, 1.4185, 1.4443, 1.4503],
        [1.3589, 1.2652, 1.2608, 1.2801, 1.2732, 1.2835, 1.2823, 1.2212, 1.2212,
         1.2533, 1.2132, 1.2121, 1.2160, 1.2916, 1.1700, 1.1387, 1.2916, 1.1994,
         1.6082, 1.5846, 1.5661, 1.5615, 1.5849, 1.5811, 1.6009, 1.5864, 1.5864,
         1.3539, 1.3269, 1.3267, 1.3440, 1.3287, 1.3720, 1.3740, 1.3479, 1.3268,
         1.5823, 1.5816, 1.5876, 1.5771, 1.5531, 1.5568, 1.6174, 1.5066, 1.4759,
         4.0718, 3.6271, 3.7142, 3.6991, 3.7120, 3.3986, 4.0667, 3.6754, 3.4300]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 242 : 1778.6037621786113
Test loss for epoch 242 : 195.4607269890961
Test Precision for epoch 242 : 0.26153846153846155
Test Recall for epoch 242 : 0.26153846153846155
Test F1 for epoch 242 : 0.26153846153846155


theta for epoch 243 : tensor([[3.6246, 3.6466, 3.7908, 3.7376, 3.7227, 3.6062, 3.6472, 3.5468, 3.5468,
         1.2577, 1.2383, 1.2371, 1.2398, 1.2753, 1.2207, 1.1943, 1.2753, 1.2264,
         1.6022, 1.5867, 1.6107, 1.5937, 1.5993, 1.6010, 1.6079, 1.6010, 1.6010,
         1.3465, 1.3578, 1.3446, 1.3653, 1.3463, 1.3761, 1.3692, 1.3568, 1.3446,
         1.5963, 1.6121, 1.6012, 1.5976, 1.6044, 1.5944, 1.6127, 1.5666, 1.5713,
         1.2485, 1.2731, 1.2658, 1.2819, 1.2437, 1.2361, 1.2255, 1.3047, 1.2628],
        [1.3704, 1.2194, 1.2090, 1.2520, 1.2523, 1.2647, 1.2586, 1.1640, 1.1640,
         3.6203, 3.7016, 3.5533, 3.9177, 3.6213, 4.2196, 3.4927, 3.5784, 4.0142,
         1.5650, 1.5525, 1.5269, 1.5247, 1.5459, 1.5553, 1.5803, 1.5553, 1.5553,
         1.3420, 1.3083, 1.3020, 1.3604, 1.3020, 1.3980, 1.3781, 1.3465, 1.2988,
         1.5331, 1.5900, 1.5530, 1.5397, 1.5348, 1.5730, 1.5927, 1.4256, 1.5239,
         1.1414, 1.2542, 1.2273, 1.2760, 1.1357, 1.1421, 1.0681, 1.3419, 1.2177],
        [1.4553, 1.4553, 1.4536, 1.4508, 1.4512, 1.4553, 1.4511, 1.4553, 1.4553,
         1.4288, 1.4281, 1.4288, 1.4288, 1.4288, 1.4102, 1.4288, 1.4277, 1.4254,
         2.2056, 2.2059, 2.2227, 2.1982, 2.1797, 2.1779, 2.2071, 2.1770, 2.1770,
         1.5148, 1.5131, 1.5205, 1.5205, 1.5148, 1.5205, 1.5205, 1.5205, 1.5205,
         1.7749, 1.7750, 1.7750, 1.7719, 1.7749, 1.7749, 1.7750, 1.7524, 1.7552,
         1.4414, 1.4459, 1.4459, 1.4459, 1.4377, 1.4459, 1.4421, 1.4458, 1.4459],
        [1.3235, 1.3217, 1.3058, 1.2971, 1.3206, 1.3190, 1.3201, 1.3206, 1.3206,
         1.2931, 1.2865, 1.2827, 1.2822, 1.2937, 1.2785, 1.2900, 1.2933, 1.2661,
         1.6461, 1.6198, 1.6431, 1.6426, 1.6420, 1.6420, 1.6442, 1.6457, 1.6457,
         3.5035, 3.2949, 3.2209, 3.2788, 3.4289, 3.2476, 3.4785, 3.2288, 3.2075,
         1.6469, 1.6393, 1.6377, 1.6409, 1.6438, 1.6197, 1.6451, 1.5846, 1.6110,
         1.3084, 1.3027, 1.2930, 1.3075, 1.3034, 1.2957, 1.3079, 1.3077, 1.3099],
        [1.4581, 1.4539, 1.4107, 1.4141, 1.4515, 1.4580, 1.4565, 1.4581, 1.4581,
         1.4306, 1.4280, 1.4230, 1.4183, 1.4317, 1.3917, 1.4258, 1.4316, 1.4270,
         1.7609, 1.7522, 1.7511, 1.7591, 1.7765, 1.7752, 1.7554, 1.7766, 1.7766,
         1.4817, 1.4874, 1.5233, 1.5182, 1.4871, 1.5219, 1.5103, 1.5233, 1.5202,
         2.2007, 2.1808, 2.1695, 2.1871, 2.2308, 2.2487, 2.2151, 2.3179, 2.3149,
         1.4339, 1.4242, 1.4385, 1.4487, 1.4362, 1.4455, 1.4168, 1.4427, 1.4487],
        [1.3540, 1.2613, 1.2568, 1.2760, 1.2691, 1.2794, 1.2782, 1.2179, 1.2179,
         1.2470, 1.2071, 1.2060, 1.2099, 1.2853, 1.1633, 1.1322, 1.2853, 1.1931,
         1.6059, 1.5823, 1.5637, 1.5593, 1.5828, 1.5789, 1.5987, 1.5843, 1.5843,
         1.3574, 1.3303, 1.3305, 1.3474, 1.3323, 1.3752, 1.3774, 1.3514, 1.3305,
         1.5791, 1.5783, 1.5844, 1.5739, 1.5498, 1.5534, 1.6142, 1.5033, 1.4725,
         4.0783, 3.6328, 3.7200, 3.7049, 3.7178, 3.4042, 4.0732, 3.6811, 3.4356]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 243 : 1779.1516919842288
Test loss for epoch 243 : 194.92194604722974
Test Precision for epoch 243 : 0.26153846153846155
Test Recall for epoch 243 : 0.26153846153846155
Test F1 for epoch 243 : 0.26153846153846155


theta for epoch 244 : tensor([[3.6239, 3.6459, 3.7901, 3.7369, 3.7220, 3.6055, 3.6466, 3.5461, 3.5461,
         1.2590, 1.2397, 1.2385, 1.2412, 1.2765, 1.2224, 1.1955, 1.2765, 1.2283,
         1.6029, 1.5874, 1.6114, 1.5945, 1.6001, 1.6018, 1.6087, 1.6018, 1.6018,
         1.3424, 1.3537, 1.3406, 1.3611, 1.3422, 1.3719, 1.3650, 1.3527, 1.3406,
         1.5979, 1.6137, 1.6028, 1.5992, 1.6060, 1.5960, 1.6142, 1.5683, 1.5729,
         1.2478, 1.2723, 1.2651, 1.2811, 1.2431, 1.2355, 1.2250, 1.3037, 1.2621],
        [1.3788, 1.2276, 1.2173, 1.2603, 1.2605, 1.2730, 1.2669, 1.1720, 1.1720,
         3.6112, 3.6926, 3.5442, 3.9092, 3.6122, 4.2120, 3.4834, 3.5692, 4.0060,
         1.5729, 1.5604, 1.5349, 1.5325, 1.5536, 1.5630, 1.5881, 1.5631, 1.5631,
         1.3481, 1.3146, 1.3080, 1.3665, 1.3082, 1.4042, 1.3843, 1.3526, 1.3048,
         1.5410, 1.5978, 1.5609, 1.5476, 1.5428, 1.5808, 1.6006, 1.4339, 1.5319,
         1.1482, 1.2611, 1.2341, 1.2830, 1.1423, 1.1485, 1.0748, 1.3491, 1.2245],
        [1.4524, 1.4524, 1.4508, 1.4480, 1.4483, 1.4525, 1.4482, 1.4525, 1.4525,
         1.4303, 1.4296, 1.4303, 1.4302, 1.4303, 1.4117, 1.4303, 1.4291, 1.4269,
         2.2066, 2.2068, 2.2236, 2.1991, 2.1806, 2.1788, 2.2080, 2.1779, 2.1779,
         1.5117, 1.5100, 1.5175, 1.5174, 1.5117, 1.5174, 1.5174, 1.5175, 1.5175,
         1.7766, 1.7767, 1.7767, 1.7735, 1.7766, 1.7766, 1.7767, 1.7541, 1.7568,
         1.4408, 1.4453, 1.4453, 1.4453, 1.4372, 1.4453, 1.4415, 1.4453, 1.4453],
        [1.3212, 1.3193, 1.3033, 1.2946, 1.3182, 1.3166, 1.3177, 1.3182, 1.3182,
         1.2946, 1.2881, 1.2843, 1.2838, 1.2953, 1.2801, 1.2916, 1.2949, 1.2677,
         1.6473, 1.6209, 1.6442, 1.6437, 1.6431, 1.6432, 1.6453, 1.6468, 1.6468,
         3.5004, 3.2917, 3.2176, 3.2756, 3.4258, 3.2444, 3.4754, 3.2255, 3.2043,
         1.6486, 1.6411, 1.6395, 1.6426, 1.6455, 1.6215, 1.6469, 1.5863, 1.6128,
         1.3081, 1.3024, 1.2926, 1.3072, 1.3031, 1.2954, 1.3076, 1.3074, 1.3095],
        [1.4553, 1.4510, 1.4076, 1.4112, 1.4486, 1.4552, 1.4537, 1.4553, 1.4553,
         1.4320, 1.4294, 1.4245, 1.4198, 1.4331, 1.3932, 1.4273, 1.4331, 1.4284,
         1.7618, 1.7531, 1.7521, 1.7601, 1.7774, 1.7761, 1.7563, 1.7776, 1.7776,
         1.4786, 1.4842, 1.5202, 1.5151, 1.4840, 1.5188, 1.5072, 1.5203, 1.5171,
         2.2023, 2.1825, 2.1712, 2.1888, 2.2324, 2.2504, 2.2168, 2.3195, 2.3165,
         1.4333, 1.4236, 1.4379, 1.4481, 1.4357, 1.4450, 1.4162, 1.4421, 1.4482],
        [1.3438, 1.2520, 1.2474, 1.2666, 1.2596, 1.2700, 1.2687, 1.2092, 1.2092,
         1.2454, 1.2054, 1.2042, 1.2082, 1.2838, 1.1618, 1.1292, 1.2839, 1.1920,
         1.6032, 1.5796, 1.5609, 1.5566, 1.5801, 1.5762, 1.5960, 1.5816, 1.5816,
         1.3489, 1.3218, 1.3222, 1.3388, 1.3238, 1.3666, 1.3688, 1.3429, 1.3222,
         1.5777, 1.5768, 1.5830, 1.5725, 1.5484, 1.5520, 1.6128, 1.5018, 1.4708,
         4.0866, 3.6404, 3.7277, 3.7125, 3.7256, 3.4118, 4.0817, 3.6887, 3.4432]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 244 : 1779.3536591703094
Test loss for epoch 244 : 194.91479981249404
Test Precision for epoch 244 : 0.26153846153846155
Test Recall for epoch 244 : 0.26153846153846155
Test F1 for epoch 244 : 0.26153846153846155


theta for epoch 245 : tensor([[3.6253, 3.6473, 3.7915, 3.7383, 3.7234, 3.6070, 3.6480, 3.5476, 3.5476,
         1.2656, 1.2463, 1.2451, 1.2478, 1.2830, 1.2292, 1.2017, 1.2830, 1.2353,
         1.6011, 1.5856, 1.6095, 1.5928, 1.5984, 1.6001, 1.6069, 1.6001, 1.6001,
         1.3325, 1.3438, 1.3308, 1.3512, 1.3324, 1.3619, 1.3550, 1.3428, 1.3308,
         1.5991, 1.6147, 1.6040, 1.6004, 1.6071, 1.5971, 1.6152, 1.5694, 1.5741,
         1.2441, 1.2686, 1.2614, 1.2774, 1.2394, 1.2319, 1.2213, 1.2999, 1.2585],
        [1.3806, 1.2293, 1.2190, 1.2619, 1.2621, 1.2746, 1.2685, 1.1736, 1.1736,
         3.6106, 3.6922, 3.5435, 3.9093, 3.6116, 4.2129, 3.4827, 3.5686, 4.0062,
         1.5743, 1.5618, 1.5364, 1.5339, 1.5550, 1.5644, 1.5895, 1.5644, 1.5644,
         1.3457, 1.3122, 1.3055, 1.3640, 1.3058, 1.4017, 1.3818, 1.3501, 1.3023,
         1.5443, 1.6012, 1.5642, 1.5509, 1.5461, 1.5842, 1.6040, 1.4373, 1.5352,
         1.1479, 1.2612, 1.2340, 1.2831, 1.1419, 1.1478, 1.0743, 1.3496, 1.2243],
        [1.4493, 1.4493, 1.4476, 1.4449, 1.4452, 1.4493, 1.4451, 1.4494, 1.4494,
         1.4373, 1.4367, 1.4373, 1.4373, 1.4373, 1.4187, 1.4373, 1.4362, 1.4340,
         2.2056, 2.2058, 2.2226, 2.1981, 2.1796, 2.1779, 2.2071, 2.1770, 2.1770,
         1.5035, 1.5019, 1.5093, 1.5093, 1.5035, 1.5093, 1.5092, 1.5093, 1.5093,
         1.7781, 1.7782, 1.7782, 1.7751, 1.7781, 1.7781, 1.7782, 1.7556, 1.7583,
         1.4379, 1.4424, 1.4424, 1.4424, 1.4343, 1.4424, 1.4386, 1.4424, 1.4424],
        [1.3185, 1.3165, 1.3005, 1.2918, 1.3154, 1.3139, 1.3149, 1.3154, 1.3154,
         1.3018, 1.2953, 1.2914, 1.2909, 1.3025, 1.2873, 1.2987, 1.3021, 1.2748,
         1.6464, 1.6200, 1.6433, 1.6428, 1.6422, 1.6422, 1.6444, 1.6459, 1.6459,
         3.4930, 3.2841, 3.2099, 3.2680, 3.4183, 3.2367, 3.4680, 3.2178, 3.1965,
         1.6503, 1.6428, 1.6412, 1.6443, 1.6472, 1.6232, 1.6486, 1.5880, 1.6144,
         1.3054, 1.2997, 1.2899, 1.3045, 1.3004, 1.2926, 1.3048, 1.3047, 1.3068],
        [1.4522, 1.4478, 1.4043, 1.4080, 1.4455, 1.4521, 1.4505, 1.4522, 1.4522,
         1.4391, 1.4365, 1.4316, 1.4269, 1.4402, 1.4002, 1.4343, 1.4401, 1.4355,
         1.7607, 1.7520, 1.7509, 1.7590, 1.7763, 1.7750, 1.7552, 1.7765, 1.7765,
         1.4704, 1.4760, 1.5120, 1.5069, 1.4758, 1.5106, 1.4990, 1.5121, 1.5090,
         2.2039, 2.1840, 2.1727, 2.1903, 2.2340, 2.2519, 2.2183, 2.3210, 2.3181,
         1.4304, 1.4207, 1.4350, 1.4452, 1.4328, 1.4421, 1.4132, 1.4393, 1.4453],
        [1.3321, 1.2406, 1.2360, 1.2551, 1.2481, 1.2585, 1.2573, 1.1979, 1.1979,
         1.2482, 1.2076, 1.2064, 1.2106, 1.2870, 1.1641, 1.1294, 1.2871, 1.1947,
         1.5974, 1.5737, 1.5550, 1.5506, 1.5743, 1.5703, 1.5901, 1.5757, 1.5757,
         1.3346, 1.3074, 1.3079, 1.3245, 1.3095, 1.3522, 1.3545, 1.3286, 1.3080,
         1.5752, 1.5742, 1.5805, 1.5699, 1.5457, 1.5493, 1.6103, 1.4990, 1.4679,
         4.0966, 3.6496, 3.7370, 3.7218, 3.7349, 3.4209, 4.0917, 3.6979, 3.4523]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 245 : 1779.2277579040885
Test loss for epoch 245 : 195.36772077147725
Test Precision for epoch 245 : 0.26153846153846155
Test Recall for epoch 245 : 0.26153846153846155
Test F1 for epoch 245 : 0.26153846153846155


theta for epoch 246 : tensor([[3.6315, 3.6536, 3.7977, 3.7446, 3.7296, 3.6132, 3.6543, 3.5539, 3.5539,
         1.2708, 1.2515, 1.2503, 1.2530, 1.2882, 1.2345, 1.2064, 1.2883, 1.2407,
         1.5974, 1.5820, 1.6058, 1.5891, 1.5948, 1.5965, 1.6032, 1.5964, 1.5964,
         1.3322, 1.3435, 1.3305, 1.3508, 1.3321, 1.3615, 1.3547, 1.3424, 1.3306,
         1.5969, 1.6125, 1.6018, 1.5982, 1.6049, 1.5948, 1.6129, 1.5672, 1.5719,
         1.2364, 1.2610, 1.2537, 1.2697, 1.2317, 1.2241, 1.2135, 1.2922, 1.2507],
        [1.3785, 1.2271, 1.2168, 1.2598, 1.2600, 1.2725, 1.2664, 1.1714, 1.1714,
         3.6159, 3.6976, 3.5487, 3.9152, 3.6169, 4.2197, 3.4878, 3.5739, 4.0124,
         1.5702, 1.5577, 1.5323, 1.5298, 1.5508, 1.5603, 1.5854, 1.5603, 1.5603,
         1.3439, 1.3103, 1.3036, 1.3622, 1.3039, 1.4000, 1.3800, 1.3483, 1.3004,
         1.5411, 1.5980, 1.5609, 1.5476, 1.5428, 1.5810, 1.6007, 1.4339, 1.5319,
         1.1402, 1.2540, 1.2266, 1.2760, 1.1341, 1.1398, 1.0665, 1.3429, 1.2168],
        [1.4508, 1.4507, 1.4490, 1.4463, 1.4466, 1.4508, 1.4465, 1.4508, 1.4508,
         1.4433, 1.4426, 1.4432, 1.4432, 1.4433, 1.4247, 1.4432, 1.4421, 1.4399,
         2.2032, 2.2035, 2.2202, 2.1959, 2.1774, 2.1756, 2.2048, 2.1747, 2.1747,
         1.5054, 1.5038, 1.5112, 1.5112, 1.5054, 1.5112, 1.5111, 1.5112, 1.5112,
         1.7767, 1.7768, 1.7768, 1.7736, 1.7767, 1.7767, 1.7768, 1.7542, 1.7569,
         1.4317, 1.4362, 1.4362, 1.4362, 1.4280, 1.4362, 1.4324, 1.4362, 1.4362],
        [1.3202, 1.3182, 1.3022, 1.2935, 1.3171, 1.3155, 1.3166, 1.3170, 1.3170,
         1.3079, 1.3013, 1.2974, 1.2970, 1.3085, 1.2933, 1.3047, 1.3081, 1.2809,
         1.6440, 1.6176, 1.6410, 1.6404, 1.6398, 1.6399, 1.6421, 1.6436, 1.6436,
         3.4943, 3.2853, 3.2111, 3.2692, 3.4196, 3.2380, 3.4693, 3.2190, 3.1977,
         1.6490, 1.6415, 1.6398, 1.6430, 1.6459, 1.6218, 1.6473, 1.5866, 1.6131,
         1.2993, 1.2936, 1.2838, 1.2984, 1.2943, 1.2865, 1.2987, 1.2987, 1.3007],
        [1.4536, 1.4492, 1.4056, 1.4093, 1.4469, 1.4535, 1.4520, 1.4536, 1.4536,
         1.4450, 1.4424, 1.4375, 1.4328, 1.4461, 1.4062, 1.4402, 1.4461, 1.4414,
         1.7582, 1.7495, 1.7484, 1.7564, 1.7738, 1.7725, 1.7527, 1.7740, 1.7740,
         1.4723, 1.4778, 1.5139, 1.5088, 1.4776, 1.5125, 1.5009, 1.5140, 1.5109,
         2.2025, 2.1827, 2.1714, 2.1890, 2.2326, 2.2506, 2.2170, 2.3197, 2.3167,
         1.4241, 1.4145, 1.4288, 1.4390, 1.4265, 1.4358, 1.4069, 1.4330, 1.4390],
        [1.3233, 1.2312, 1.2266, 1.2458, 1.2388, 1.2492, 1.2480, 1.1881, 1.1881,
         1.2493, 1.2079, 1.2067, 1.2111, 1.2889, 1.1644, 1.1271, 1.2889, 1.1954,
         1.5894, 1.5655, 1.5469, 1.5423, 1.5660, 1.5621, 1.5821, 1.5675, 1.5675,
         1.3277, 1.3005, 1.3008, 1.3176, 1.3025, 1.3456, 1.3478, 1.3217, 1.3008,
         1.5688, 1.5680, 1.5741, 1.5635, 1.5393, 1.5430, 1.6042, 1.4924, 1.4612,
         4.1072, 3.6594, 3.7469, 3.7316, 3.7449, 3.4307, 4.1023, 3.7076, 3.4620]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 246 : 1779.0163240662907
Test loss for epoch 246 : 195.81189199118202
Test Precision for epoch 246 : 0.26153846153846155
Test Recall for epoch 246 : 0.26153846153846155
Test F1 for epoch 246 : 0.26153846153846155


theta for epoch 247 : tensor([[3.6295, 3.6515, 3.7956, 3.7425, 3.7274, 3.6111, 3.6522, 3.5518, 3.5518,
         1.2690, 1.2499, 1.2487, 1.2513, 1.2864, 1.2331, 1.2052, 1.2864, 1.2395,
         1.5987, 1.5833, 1.6071, 1.5906, 1.5962, 1.5979, 1.6045, 1.5978, 1.5978,
         1.3438, 1.3551, 1.3423, 1.3624, 1.3438, 1.3729, 1.3662, 1.3540, 1.3423,
         1.5960, 1.6114, 1.6008, 1.5972, 1.6039, 1.5938, 1.6119, 1.5663, 1.5709,
         1.2335, 1.2576, 1.2505, 1.2662, 1.2289, 1.2215, 1.2109, 1.2886, 1.2476],
        [1.3864, 1.2358, 1.2254, 1.2683, 1.2685, 1.2810, 1.2749, 1.1805, 1.1805,
         3.6083, 3.6902, 3.5411, 3.9082, 3.6093, 4.2136, 3.4801, 3.5662, 4.0056,
         1.5757, 1.5632, 1.5379, 1.5355, 1.5565, 1.5658, 1.5908, 1.5659, 1.5659,
         1.3554, 1.3219, 1.3153, 1.3738, 1.3155, 1.4115, 1.3915, 1.3599, 1.3122,
         1.5445, 1.6011, 1.5643, 1.5510, 1.5462, 1.5842, 1.6038, 1.4377, 1.5354,
         1.1430, 1.2558, 1.2288, 1.2776, 1.1371, 1.1430, 1.0699, 1.3444, 1.2191],
        [1.4546, 1.4545, 1.4529, 1.4501, 1.4505, 1.4546, 1.4503, 1.4546, 1.4546,
         1.4406, 1.4400, 1.4406, 1.4406, 1.4406, 1.4220, 1.4406, 1.4395, 1.4373,
         2.2038, 2.2040, 2.2208, 2.1964, 2.1779, 2.1761, 2.2053, 2.1753, 2.1753,
         1.5162, 1.5146, 1.5220, 1.5220, 1.5163, 1.5220, 1.5219, 1.5220, 1.5220,
         1.7750, 1.7751, 1.7751, 1.7719, 1.7749, 1.7749, 1.7750, 1.7524, 1.7552,
         1.4277, 1.4322, 1.4322, 1.4322, 1.4240, 1.4322, 1.4284, 1.4322, 1.4322],
        [1.3243, 1.3222, 1.3062, 1.2975, 1.3212, 1.3196, 1.3207, 1.3211, 1.3211,
         1.3054, 1.2988, 1.2949, 1.2945, 1.3060, 1.2908, 1.3022, 1.3056, 1.2784,
         1.6447, 1.6183, 1.6417, 1.6411, 1.6405, 1.6406, 1.6428, 1.6443, 1.6443,
         3.5031, 3.2942, 3.2200, 3.2780, 3.4284, 3.2467, 3.4781, 3.2278, 3.2066,
         1.6474, 1.6399, 1.6382, 1.6414, 1.6443, 1.6202, 1.6456, 1.5850, 1.6115,
         1.2954, 1.2898, 1.2800, 1.2946, 1.2904, 1.2826, 1.2949, 1.2949, 1.2969],
        [1.4574, 1.4531, 1.4094, 1.4131, 1.4507, 1.4573, 1.4558, 1.4574, 1.4574,
         1.4424, 1.4398, 1.4349, 1.4302, 1.4435, 1.4035, 1.4376, 1.4434, 1.4388,
         1.7587, 1.7500, 1.7490, 1.7570, 1.7744, 1.7730, 1.7532, 1.7745, 1.7745,
         1.4831, 1.4886, 1.5247, 1.5196, 1.4885, 1.5233, 1.5118, 1.5248, 1.5217,
         2.2009, 2.1810, 2.1697, 2.1874, 2.2310, 2.2490, 2.2154, 2.3180, 2.3151,
         1.4201, 1.4105, 1.4248, 1.4350, 1.4225, 1.4318, 1.4029, 1.4290, 1.4350],
        [1.3443, 1.2523, 1.2478, 1.2669, 1.2599, 1.2703, 1.2691, 1.2092, 1.2092,
         1.2561, 1.2148, 1.2136, 1.2180, 1.2962, 1.1716, 1.1335, 1.2963, 1.2026,
         1.6010, 1.5772, 1.5587, 1.5540, 1.5776, 1.5736, 1.5937, 1.5790, 1.5790,
         1.3515, 1.3243, 1.3245, 1.3415, 1.3263, 1.3694, 1.3716, 1.3455, 1.3245,
         1.5765, 1.5759, 1.5818, 1.5713, 1.5473, 1.5510, 1.6119, 1.5006, 1.4697,
         4.0841, 3.6356, 3.7231, 3.7079, 3.7211, 3.4067, 4.0793, 3.6839, 3.4381]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 247 : 1779.8573350414613
Test loss for epoch 247 : 194.74208605526044
Test Precision for epoch 247 : 0.26153846153846155
Test Recall for epoch 247 : 0.26153846153846155
Test F1 for epoch 247 : 0.26153846153846155


theta for epoch 248 : tensor([[3.6244, 3.6463, 3.7904, 3.7373, 3.7222, 3.6060, 3.6470, 3.5465, 3.5465,
         1.2654, 1.2464, 1.2453, 1.2478, 1.2829, 1.2298, 1.2018, 1.2829, 1.2362,
         1.6018, 1.5864, 1.6101, 1.5937, 1.5993, 1.6010, 1.6076, 1.6010, 1.6010,
         1.3406, 1.3519, 1.3391, 1.3592, 1.3406, 1.3697, 1.3630, 1.3508, 1.3392,
         1.5967, 1.6120, 1.6015, 1.5979, 1.6046, 1.5945, 1.6125, 1.5670, 1.5716,
         1.2423, 1.2662, 1.2591, 1.2747, 1.2377, 1.2304, 1.2198, 1.2971, 1.2563],
        [1.3833, 1.2337, 1.2232, 1.2660, 1.2662, 1.2787, 1.2726, 1.1790, 1.1790,
         3.6069, 3.6889, 3.5395, 3.9073, 3.6078, 4.2136, 3.4784, 3.5646, 4.0050,
         1.5780, 1.5655, 1.5401, 1.5379, 1.5589, 1.5683, 1.5931, 1.5683, 1.5683,
         1.3534, 1.3199, 1.3136, 1.3717, 1.3136, 1.4091, 1.3893, 1.3579, 1.3104,
         1.5452, 1.6017, 1.5650, 1.5517, 1.5469, 1.5848, 1.6044, 1.4383, 1.5361,
         1.1490, 1.2615, 1.2346, 1.2832, 1.1432, 1.1493, 1.0760, 1.3503, 1.2250],
        [1.4493, 1.4492, 1.4476, 1.4448, 1.4452, 1.4493, 1.4450, 1.4493, 1.4493,
         1.4365, 1.4359, 1.4365, 1.4365, 1.4365, 1.4179, 1.4365, 1.4354, 1.4332,
         2.2063, 2.2066, 2.2233, 2.1989, 2.1804, 2.1786, 2.2078, 2.1777, 2.1777,
         1.5130, 1.5113, 1.5187, 1.5187, 1.5130, 1.5187, 1.5187, 1.5187, 1.5187,
         1.7753, 1.7754, 1.7753, 1.7722, 1.7752, 1.7752, 1.7753, 1.7527, 1.7555,
         1.4360, 1.4406, 1.4406, 1.4406, 1.4324, 1.4406, 1.4367, 1.4405, 1.4406],
        [1.3191, 1.3170, 1.3009, 1.2922, 1.3159, 1.3143, 1.3154, 1.3158, 1.3158,
         1.3014, 1.2948, 1.2910, 1.2905, 1.3021, 1.2868, 1.2982, 1.3017, 1.2744,
         1.6476, 1.6212, 1.6446, 1.6440, 1.6435, 1.6435, 1.6457, 1.6472, 1.6472,
         3.4998, 3.2907, 3.2164, 3.2745, 3.4250, 3.2432, 3.4747, 3.2243, 3.2030,
         1.6478, 1.6403, 1.6387, 1.6418, 1.6447, 1.6206, 1.6461, 1.5854, 1.6119,
         1.3040, 1.2984, 1.2886, 1.3032, 1.2990, 1.2912, 1.3035, 1.3035, 1.3055],
        [1.4521, 1.4478, 1.4040, 1.4077, 1.4454, 1.4521, 1.4505, 1.4521, 1.4521,
         1.4383, 1.4357, 1.4308, 1.4261, 1.4394, 1.3994, 1.4335, 1.4394, 1.4347,
         1.7614, 1.7527, 1.7516, 1.7596, 1.7770, 1.7757, 1.7559, 1.7772, 1.7772,
         1.4798, 1.4853, 1.5215, 1.5163, 1.4852, 1.5200, 1.5085, 1.5215, 1.5184,
         2.2013, 2.1814, 2.1701, 2.1877, 2.2313, 2.2493, 2.2157, 2.3184, 2.3154,
         1.4284, 1.4188, 1.4331, 1.4434, 1.4308, 1.4402, 1.4113, 1.4374, 1.4434],
        [1.3544, 1.2621, 1.2577, 1.2768, 1.2698, 1.2801, 1.2789, 1.2187, 1.2187,
         1.2594, 1.2179, 1.2167, 1.2211, 1.3003, 1.1748, 1.1356, 1.3003, 1.2060,
         1.6118, 1.5881, 1.5697, 1.5648, 1.5882, 1.5843, 1.6045, 1.5897, 1.5897,
         1.3600, 1.3329, 1.3327, 1.3501, 1.3348, 1.3781, 1.3801, 1.3539, 1.3328,
         1.5837, 1.5833, 1.5890, 1.5785, 1.5547, 1.5585, 1.6193, 1.5082, 1.4775,
         4.0715, 3.6223, 3.7099, 3.6947, 3.7079, 3.3932, 4.0668, 3.6706, 3.4247]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 248 : 1779.7758420139075
Test loss for epoch 248 : 194.4162344160248
Test Precision for epoch 248 : 0.26153846153846155
Test Recall for epoch 248 : 0.26153846153846155
Test F1 for epoch 248 : 0.26153846153846155


theta for epoch 249 : tensor([[3.6209, 3.6427, 3.7869, 3.7338, 3.7187, 3.6025, 3.6435, 3.5430, 3.5430,
         1.2630, 1.2440, 1.2429, 1.2454, 1.2808, 1.2274, 1.1991, 1.2808, 1.2339,
         1.6008, 1.5854, 1.6091, 1.5927, 1.5983, 1.6000, 1.6066, 1.6000, 1.6000,
         1.3280, 1.3393, 1.3264, 1.3465, 1.3280, 1.3570, 1.3503, 1.3382, 1.3264,
         1.5973, 1.6126, 1.6021, 1.5985, 1.6052, 1.5951, 1.6131, 1.5676, 1.5723,
         1.2572, 1.2810, 1.2740, 1.2896, 1.2526, 1.2454, 1.2347, 1.3121, 1.2712],
        [1.3744, 1.2256, 1.2150, 1.2578, 1.2580, 1.2704, 1.2643, 1.1713, 1.1713,
         3.6117, 3.6939, 3.5443, 3.9128, 3.6125, 4.2199, 3.4831, 3.5693, 4.0107,
         1.5733, 1.5609, 1.5353, 1.5333, 1.5544, 1.5638, 1.5885, 1.5638, 1.5638,
         1.3413, 1.3079, 1.3018, 1.3595, 1.3017, 1.3967, 1.3770, 1.3458, 1.2986,
         1.5421, 1.5986, 1.5619, 1.5487, 1.5438, 1.5817, 1.6012, 1.4350, 1.5330,
         1.1550, 1.2677, 1.2408, 1.2894, 1.1492, 1.1555, 1.0818, 1.3569, 1.2312],
        [1.4438, 1.4437, 1.4421, 1.4393, 1.4397, 1.4438, 1.4395, 1.4438, 1.4438,
         1.4340, 1.4333, 1.4339, 1.4339, 1.4340, 1.4154, 1.4340, 1.4328, 1.4306,
         2.2055, 2.2057, 2.2225, 2.1980, 2.1796, 2.1778, 2.2070, 2.1769, 2.1769,
         1.5008, 1.4991, 1.5065, 1.5065, 1.5008, 1.5065, 1.5065, 1.5065, 1.5065,
         1.7758, 1.7759, 1.7759, 1.7728, 1.7758, 1.7758, 1.7759, 1.7533, 1.7560,
         1.4511, 1.4556, 1.4556, 1.4556, 1.4474, 1.4556, 1.4518, 1.4556, 1.4556],
        [1.3135, 1.3114, 1.2954, 1.2866, 1.3103, 1.3088, 1.3099, 1.3102, 1.3102,
         1.2990, 1.2924, 1.2885, 1.2881, 1.2997, 1.2844, 1.2957, 1.2993, 1.2720,
         1.6469, 1.6205, 1.6439, 1.6433, 1.6427, 1.6428, 1.6450, 1.6464, 1.6464,
         3.4887, 3.2793, 3.2049, 3.2630, 3.4138, 3.2318, 3.4636, 3.2128, 3.1915,
         1.6485, 1.6411, 1.6394, 1.6425, 1.6454, 1.6214, 1.6468, 1.5861, 1.6126,
         1.3194, 1.3138, 1.3040, 1.3186, 1.3144, 1.3066, 1.3188, 1.3189, 1.3209],
        [1.4467, 1.4422, 1.3984, 1.4021, 1.4399, 1.4466, 1.4450, 1.4466, 1.4466,
         1.4357, 1.4331, 1.4282, 1.4235, 1.4368, 1.3968, 1.4309, 1.4368, 1.4321,
         1.7605, 1.7517, 1.7507, 1.7587, 1.7761, 1.7748, 1.7549, 1.7763, 1.7763,
         1.4676, 1.4730, 1.5093, 1.5041, 1.4729, 1.5079, 1.4963, 1.5093, 1.5062,
         2.2019, 2.1820, 2.1707, 2.1883, 2.2319, 2.2499, 2.2163, 2.3190, 2.3160,
         1.4435, 1.4339, 1.4482, 1.4584, 1.4459, 1.4552, 1.4263, 1.4524, 1.4584],
        [1.3598, 1.2669, 1.2627, 1.2817, 1.2748, 1.2851, 1.2839, 1.2231, 1.2231,
         1.2620, 1.2200, 1.2188, 1.2233, 1.3037, 1.1769, 1.1363, 1.3037, 1.2082,
         1.6166, 1.5929, 1.5746, 1.5695, 1.5929, 1.5890, 1.6093, 1.5943, 1.5943,
         1.3574, 1.3305, 1.3299, 1.3476, 1.3322, 1.3756, 1.3776, 1.3513, 1.3299,
         1.5889, 1.5887, 1.5942, 1.5838, 1.5600, 1.5639, 1.6246, 1.5137, 1.4831,
         4.0668, 3.6170, 3.7046, 3.6893, 3.7026, 3.3877, 4.0621, 3.6652, 3.4193]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 249 : 1779.7441672763828
Test loss for epoch 249 : 194.70629497057587
Test Precision for epoch 249 : 0.26153846153846155
Test Recall for epoch 249 : 0.26153846153846155
Test F1 for epoch 249 : 0.26153846153846155


theta for epoch 250 : tensor([[3.6245, 3.6464, 3.7905, 3.7374, 3.7223, 3.6061, 3.6472, 3.5467, 3.5467,
         1.2615, 1.2424, 1.2412, 1.2438, 1.2797, 1.2257, 1.1967, 1.2797, 1.2322,
         1.5960, 1.5807, 1.6044, 1.5879, 1.5936, 1.5952, 1.6019, 1.5952, 1.5952,
         1.3274, 1.3387, 1.3258, 1.3460, 1.3274, 1.3566, 1.3498, 1.3376, 1.3258,
         1.5962, 1.6115, 1.6010, 1.5974, 1.6041, 1.5940, 1.6119, 1.5665, 1.5712,
         1.2609, 1.2847, 1.2777, 1.2933, 1.2563, 1.2490, 1.2384, 1.3159, 1.2749],
        [1.3654, 1.2166, 1.2060, 1.2488, 1.2490, 1.2615, 1.2554, 1.1625, 1.1625,
         3.6220, 3.7043, 3.5545, 3.9237, 3.6228, 4.2316, 3.4933, 3.5795, 4.0218,
         1.5624, 1.5500, 1.5244, 1.5225, 1.5436, 1.5530, 1.5777, 1.5530, 1.5530,
         1.3322, 1.2988, 1.2928, 1.3504, 1.2926, 1.3877, 1.3680, 1.3368, 1.2896,
         1.5344, 1.5910, 1.5543, 1.5410, 1.5360, 1.5740, 1.5936, 1.4269, 1.5252,
         1.1497, 1.2625, 1.2356, 1.2842, 1.1440, 1.1504, 1.0764, 1.3521, 1.2261],
        [1.4474, 1.4473, 1.4456, 1.4428, 1.4432, 1.4474, 1.4431, 1.4474, 1.4474,
         1.4327, 1.4320, 1.4326, 1.4326, 1.4327, 1.4140, 1.4326, 1.4315, 1.4293,
         2.2015, 2.2018, 2.2185, 2.1943, 2.1758, 2.1740, 2.2032, 2.1731, 2.1731,
         1.5011, 1.4994, 1.5069, 1.5069, 1.5011, 1.5069, 1.5068, 1.5069, 1.5069,
         1.7750, 1.7751, 1.7751, 1.7720, 1.7750, 1.7750, 1.7751, 1.7525, 1.7552,
         1.4554, 1.4599, 1.4599, 1.4599, 1.4517, 1.4599, 1.4561, 1.4599, 1.4599],
        [1.3171, 1.3149, 1.2989, 1.2902, 1.3139, 1.3123, 1.3134, 1.3138, 1.3138,
         1.2978, 1.2912, 1.2874, 1.2869, 1.2986, 1.2832, 1.2945, 1.2981, 1.2708,
         1.6429, 1.6164, 1.6398, 1.6392, 1.6387, 1.6387, 1.6409, 1.6424, 1.6424,
         3.4882, 3.2787, 3.2043, 3.2625, 3.4133, 3.2312, 3.4631, 3.2122, 3.1909,
         1.6479, 1.6404, 1.6387, 1.6418, 1.6448, 1.6207, 1.6462, 1.5854, 1.6119,
         1.3239, 1.3183, 1.3085, 1.3231, 1.3189, 1.3110, 1.3233, 1.3234, 1.3254],
        [1.4502, 1.4458, 1.4020, 1.4057, 1.4434, 1.4501, 1.4486, 1.4502, 1.4502,
         1.4344, 1.4318, 1.4269, 1.4222, 1.4355, 1.3954, 1.4296, 1.4355, 1.4308,
         1.7563, 1.7475, 1.7465, 1.7545, 1.7720, 1.7706, 1.7508, 1.7721, 1.7721,
         1.4679, 1.4732, 1.5096, 1.5044, 1.4732, 1.5082, 1.4966, 1.5097, 1.5066,
         2.2011, 2.1812, 2.1699, 2.1876, 2.2312, 2.2492, 2.2156, 2.3183, 2.3153,
         1.4478, 1.4381, 1.4525, 1.4627, 1.4501, 1.4595, 1.4306, 1.4567, 1.4627],
        [1.3674, 1.2740, 1.2698, 1.2888, 1.2820, 1.2922, 1.2910, 1.2297, 1.2297,
         1.2636, 1.2210, 1.2198, 1.2245, 1.3062, 1.1778, 1.1355, 1.3063, 1.2092,
         1.6158, 1.5921, 1.5740, 1.5686, 1.5919, 1.5881, 1.6085, 1.5934, 1.5934,
         1.3616, 1.3346, 1.3338, 1.3518, 1.3363, 1.3799, 1.3818, 1.3554, 1.3339,
         1.5907, 1.5906, 1.5959, 1.5855, 1.5619, 1.5658, 1.6265, 1.5156, 1.4851,
         4.0629, 3.6123, 3.7000, 3.6847, 3.6980, 3.3830, 4.0582, 3.6605, 3.4145]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 250 : 1779.4607381022784
Test loss for epoch 250 : 195.1393236684475
Test Precision for epoch 250 : 0.26153846153846155
Test Recall for epoch 250 : 0.26153846153846155
Test F1 for epoch 250 : 0.26153846153846155


theta for epoch 251 : tensor([[3.6234, 3.6452, 3.7893, 3.7363, 3.7211, 3.6050, 3.6461, 3.5456, 3.5456,
         1.2606, 1.2417, 1.2399, 1.2431, 1.2792, 1.2251, 1.1963, 1.2792, 1.2317,
         1.5961, 1.5807, 1.6044, 1.5880, 1.5936, 1.5953, 1.6019, 1.5952, 1.5952,
         1.3412, 1.3524, 1.3394, 1.3597, 1.3411, 1.3704, 1.3636, 1.3513, 1.3394,
         1.5963, 1.6117, 1.6012, 1.5976, 1.6042, 1.5941, 1.6121, 1.5667, 1.5714,
         1.2532, 1.2771, 1.2701, 1.2856, 1.2487, 1.2414, 1.2307, 1.3083, 1.2673],
        [1.3758, 1.2273, 1.2167, 1.2595, 1.2597, 1.2722, 1.2661, 1.1733, 1.1733,
         3.6123, 3.6948, 3.5448, 3.9146, 3.6131, 4.2234, 3.4835, 3.5697, 4.0130,
         1.5685, 1.5561, 1.5306, 1.5287, 1.5498, 1.5592, 1.5837, 1.5592, 1.5592,
         1.3465, 1.3131, 1.3072, 1.3648, 1.3069, 1.4020, 1.3823, 1.3511, 1.3040,
         1.5402, 1.5966, 1.5601, 1.5468, 1.5418, 1.5797, 1.5992, 1.4330, 1.5311,
         1.1508, 1.2630, 1.2362, 1.2845, 1.1451, 1.1516, 1.0779, 1.3521, 1.2267],
        [1.4531, 1.4530, 1.4513, 1.4485, 1.4489, 1.4531, 1.4488, 1.4531, 1.4531,
         1.4311, 1.4305, 1.4311, 1.4311, 1.4312, 1.4125, 1.4311, 1.4300, 1.4278,
         2.2010, 2.2012, 2.2180, 2.1937, 2.1753, 2.1735, 2.2027, 2.1726, 2.1726,
         1.5138, 1.5121, 1.5195, 1.5195, 1.5138, 1.5195, 1.5195, 1.5195, 1.5195,
         1.7746, 1.7747, 1.7747, 1.7716, 1.7746, 1.7746, 1.7747, 1.7521, 1.7548,
         1.4471, 1.4516, 1.4516, 1.4516, 1.4434, 1.4516, 1.4478, 1.4516, 1.4516],
        [1.3228, 1.3207, 1.3046, 1.2959, 1.3196, 1.3180, 1.3191, 1.3195, 1.3195,
         1.2965, 1.2898, 1.2860, 1.2855, 1.2972, 1.2818, 1.2931, 1.2968, 1.2694,
         1.6425, 1.6160, 1.6394, 1.6388, 1.6383, 1.6383, 1.6405, 1.6420, 1.6420,
         3.4983, 3.2888, 3.2144, 3.2725, 3.4233, 3.2412, 3.4731, 3.2222, 3.2010,
         1.6476, 1.6401, 1.6385, 1.6416, 1.6445, 1.6205, 1.6459, 1.5852, 1.6117,
         1.3157, 1.3102, 1.3003, 1.3150, 1.3107, 1.3029, 1.3151, 1.3153, 1.3172],
        [1.4559, 1.4515, 1.4078, 1.4114, 1.4491, 1.4558, 1.4543, 1.4559, 1.4559,
         1.4329, 1.4303, 1.4253, 1.4207, 1.4340, 1.3939, 1.4281, 1.4340, 1.4292,
         1.7557, 1.7470, 1.7459, 1.7539, 1.7714, 1.7701, 1.7502, 1.7716, 1.7716,
         1.4806, 1.4859, 1.5223, 1.5171, 1.4859, 1.5209, 1.5093, 1.5223, 1.5192,
         2.2008, 2.1809, 2.1696, 2.1873, 2.2308, 2.2489, 2.2153, 2.3180, 2.3150,
         1.4394, 1.4298, 1.4442, 1.4544, 1.4418, 1.4512, 1.4222, 1.4484, 1.4545],
        [1.3756, 1.2821, 1.2780, 1.2970, 1.2901, 1.3003, 1.2992, 1.2378, 1.2378,
         1.2648, 1.2224, 1.2203, 1.2259, 1.3083, 1.1791, 1.1366, 1.3084, 1.2106,
         1.6181, 1.5945, 1.5764, 1.5710, 1.5942, 1.5904, 1.6108, 1.5957, 1.5957,
         1.3755, 1.3486, 1.3477, 1.3657, 1.3502, 1.3938, 1.3957, 1.3693, 1.3478,
         1.5928, 1.5928, 1.5980, 1.5877, 1.5640, 1.5680, 1.6287, 1.5179, 1.4874,
         4.0540, 3.6027, 3.6905, 3.6752, 3.6885, 3.3733, 4.0494, 3.6509, 3.4048]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 251 : 1779.8194050736863
Test loss for epoch 251 : 194.47159887074827
Test Precision for epoch 251 : 0.26153846153846155
Test Recall for epoch 251 : 0.26153846153846155
Test F1 for epoch 251 : 0.26153846153846155


theta for epoch 252 : tensor([[3.6184, 3.6402, 3.7843, 3.7313, 3.7161, 3.6000, 3.6411, 3.5404, 3.5404,
         1.2632, 1.2443, 1.2420, 1.2457, 1.2824, 1.2276, 1.1984, 1.2824, 1.2342,
         1.5998, 1.5844, 1.6081, 1.5916, 1.5972, 1.5989, 1.6056, 1.5989, 1.5989,
         1.3425, 1.3537, 1.3405, 1.3610, 1.3423, 1.3718, 1.3650, 1.3526, 1.3405,
         1.5971, 1.6125, 1.6020, 1.5984, 1.6050, 1.5949, 1.6130, 1.5675, 1.5722,
         1.2489, 1.2729, 1.2658, 1.2814, 1.2443, 1.2370, 1.2263, 1.3041, 1.2629],
        [1.3750, 1.2265, 1.2160, 1.2587, 1.2589, 1.2713, 1.2653, 1.1725, 1.1725,
         3.6102, 3.6928, 3.5427, 3.9131, 3.6109, 4.2228, 3.4812, 3.5675, 4.0117,
         1.5729, 1.5605, 1.5349, 1.5331, 1.5541, 1.5635, 1.5881, 1.5636, 1.5636,
         1.3489, 1.3155, 1.3095, 1.3671, 1.3093, 1.4043, 1.3847, 1.3535, 1.3064,
         1.5425, 1.5988, 1.5623, 1.5491, 1.5441, 1.5819, 1.6014, 1.4354, 1.5334,
         1.1497, 1.2617, 1.2350, 1.2832, 1.1441, 1.1505, 1.0770, 1.3507, 1.2255],
        [1.4479, 1.4478, 1.4461, 1.4433, 1.4437, 1.4479, 1.4436, 1.4479, 1.4479,
         1.4336, 1.4329, 1.4335, 1.4335, 1.4336, 1.4149, 1.4336, 1.4324, 1.4302,
         2.2042, 2.2045, 2.2212, 2.1969, 2.1784, 2.1766, 2.2058, 2.1757, 2.1757,
         1.5148, 1.5131, 1.5206, 1.5205, 1.5148, 1.5205, 1.5205, 1.5205, 1.5206,
         1.7753, 1.7753, 1.7753, 1.7722, 1.7752, 1.7752, 1.7753, 1.7527, 1.7554,
         1.4425, 1.4471, 1.4471, 1.4471, 1.4389, 1.4471, 1.4432, 1.4470, 1.4471],
        [1.3173, 1.3152, 1.2992, 1.2904, 1.3142, 1.3126, 1.3137, 1.3141, 1.3141,
         1.2990, 1.2924, 1.2885, 1.2881, 1.2998, 1.2844, 1.2956, 1.2994, 1.2719,
         1.6461, 1.6197, 1.6431, 1.6425, 1.6419, 1.6420, 1.6442, 1.6456, 1.6456,
         3.4981, 3.2885, 3.2141, 3.2722, 3.4232, 3.2409, 3.4730, 3.2220, 3.2007,
         1.6484, 1.6409, 1.6392, 1.6423, 1.6453, 1.6212, 1.6467, 1.5859, 1.6124,
         1.3113, 1.3058, 1.2959, 1.3106, 1.3063, 1.2985, 1.3107, 1.3109, 1.3129],
        [1.4507, 1.4463, 1.4025, 1.4062, 1.4439, 1.4506, 1.4491, 1.4507, 1.4507,
         1.4353, 1.4327, 1.4278, 1.4231, 1.4364, 1.3963, 1.4305, 1.4364, 1.4317,
         1.7591, 1.7504, 1.7493, 1.7573, 1.7748, 1.7735, 1.7536, 1.7750, 1.7750,
         1.4816, 1.4869, 1.5233, 1.5181, 1.4869, 1.5219, 1.5103, 1.5233, 1.5203,
         2.2015, 2.1815, 2.1702, 2.1879, 2.2315, 2.2495, 2.2159, 2.3187, 2.3157,
         1.4348, 1.4253, 1.4396, 1.4499, 1.4372, 1.4466, 1.4176, 1.4439, 1.4499],
        [1.3709, 1.2779, 1.2737, 1.2927, 1.2858, 1.2960, 1.2948, 1.2338, 1.2338,
         1.2675, 1.2252, 1.2222, 1.2287, 1.3120, 1.1817, 1.1386, 1.3120, 1.2133,
         1.6216, 1.5980, 1.5799, 1.5745, 1.5978, 1.5940, 1.6143, 1.5993, 1.5993,
         1.3762, 1.3493, 1.3486, 1.3664, 1.3510, 1.3944, 1.3964, 1.3701, 1.3486,
         1.5938, 1.5938, 1.5991, 1.5887, 1.5651, 1.5690, 1.6297, 1.5190, 1.4885,
         4.0514, 3.5995, 3.6873, 3.6720, 3.6853, 3.3699, 4.0469, 3.6477, 3.4015]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 252 : 1779.9722824133228
Test loss for epoch 252 : 194.33001381937126
Test Precision for epoch 252 : 0.26153846153846155
Test Recall for epoch 252 : 0.26153846153846155
Test F1 for epoch 252 : 0.26153846153846155


theta for epoch 253 : tensor([[3.6175, 3.6392, 3.7833, 3.7304, 3.7151, 3.5990, 3.6401, 3.5395, 3.5395,
         1.2669, 1.2477, 1.2448, 1.2492, 1.2867, 1.2308, 1.2009, 1.2867, 1.2374,
         1.6013, 1.5859, 1.6097, 1.5930, 1.5987, 1.6003, 1.6072, 1.6003, 1.6003,
         1.3290, 1.3402, 1.3268, 1.3476, 1.3287, 1.3585, 1.3516, 1.3391, 1.3268,
         1.5969, 1.6124, 1.6018, 1.5982, 1.6049, 1.5948, 1.6129, 1.5673, 1.5720,
         1.2518, 1.2760, 1.2688, 1.2846, 1.2472, 1.2398, 1.2291, 1.3074, 1.2660],
        [1.3706, 1.2215, 1.2110, 1.2538, 1.2540, 1.2664, 1.2603, 1.1671, 1.1671,
         3.6143, 3.6970, 3.5468, 3.9178, 3.6149, 4.2283, 3.4851, 3.5715, 4.0166,
         1.5718, 1.5594, 1.5338, 1.5319, 1.5530, 1.5624, 1.5871, 1.5624, 1.5624,
         1.3386, 1.3052, 1.2991, 1.3567, 1.2990, 1.3939, 1.3742, 1.3430, 1.2959,
         1.5403, 1.5968, 1.5601, 1.5469, 1.5419, 1.5798, 1.5994, 1.4331, 1.5312,
         1.1497, 1.2620, 1.2352, 1.2836, 1.1440, 1.1504, 1.0768, 1.3512, 1.2257],
        [1.4458, 1.4457, 1.4441, 1.4413, 1.4417, 1.4458, 1.4415, 1.4458, 1.4458,
         1.4375, 1.4368, 1.4374, 1.4374, 1.4375, 1.4188, 1.4375, 1.4363, 1.4341,
         2.2059, 2.2061, 2.2229, 2.1985, 2.1800, 2.1782, 2.2074, 2.1773, 2.1773,
         1.5017, 1.5001, 1.5075, 1.5075, 1.5017, 1.5075, 1.5075, 1.5075, 1.5075,
         1.7753, 1.7754, 1.7754, 1.7723, 1.7753, 1.7753, 1.7754, 1.7528, 1.7555,
         1.4457, 1.4503, 1.4503, 1.4503, 1.4420, 1.4503, 1.4464, 1.4502, 1.4503],
        [1.3151, 1.3130, 1.2970, 1.2882, 1.3119, 1.3104, 1.3115, 1.3118, 1.3118,
         1.3031, 1.2965, 1.2926, 1.2922, 1.3039, 1.2884, 1.2996, 1.3035, 1.2760,
         1.6481, 1.6216, 1.6451, 1.6445, 1.6439, 1.6439, 1.6462, 1.6476, 1.6476,
         3.4858, 3.2759, 3.2013, 3.2596, 3.4107, 3.2283, 3.4606, 3.2092, 3.1879,
         1.6486, 1.6412, 1.6395, 1.6426, 1.6455, 1.6215, 1.6469, 1.5861, 1.6127,
         1.3147, 1.3092, 1.2994, 1.3141, 1.3097, 1.3019, 1.3141, 1.3144, 1.3163],
        [1.4487, 1.4442, 1.4004, 1.4041, 1.4418, 1.4486, 1.4470, 1.4486, 1.4486,
         1.4392, 1.4366, 1.4316, 1.4269, 1.4403, 1.4001, 1.4344, 1.4403, 1.4355,
         1.7609, 1.7521, 1.7510, 1.7591, 1.7766, 1.7753, 1.7553, 1.7768, 1.7768,
         1.4685, 1.4737, 1.5103, 1.5050, 1.4738, 1.5088, 1.4973, 1.5103, 1.5072,
         2.2016, 2.1816, 2.1703, 2.1880, 2.2316, 2.2496, 2.2160, 2.3188, 2.3159,
         1.4380, 1.4284, 1.4428, 1.4531, 1.4404, 1.4498, 1.4206, 1.4470, 1.4531],
        [1.3642, 1.2719, 1.2677, 1.2866, 1.2797, 1.2899, 1.2888, 1.2283, 1.2283,
         1.2697, 1.2272, 1.2235, 1.2308, 1.3152, 1.1834, 1.1396, 1.3152, 1.2151,
         1.6213, 1.5977, 1.5794, 1.5743, 1.5976, 1.5937, 1.6140, 1.5990, 1.5990,
         1.3621, 1.3353, 1.3348, 1.3522, 1.3370, 1.3800, 1.3821, 1.3560, 1.3348,
         1.5925, 1.5924, 1.5977, 1.5873, 1.5637, 1.5676, 1.6282, 1.5176, 1.4870,
         4.0563, 3.6037, 3.6915, 3.6763, 3.6896, 3.3741, 4.0517, 3.6518, 3.4057]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 253 : 1779.689706946653
Test loss for epoch 253 : 194.78659675617322
Test Precision for epoch 253 : 0.26153846153846155
Test Recall for epoch 253 : 0.26153846153846155
Test F1 for epoch 253 : 0.26153846153846155


theta for epoch 254 : tensor([[3.6229, 3.6447, 3.7887, 3.7358, 3.7206, 3.6045, 3.6456, 3.5451, 3.5451,
         1.2651, 1.2455, 1.2422, 1.2471, 1.2857, 1.2285, 1.1974, 1.2857, 1.2349,
         1.5968, 1.5814, 1.6052, 1.5883, 1.5941, 1.5957, 1.6027, 1.5957, 1.5957,
         1.3269, 1.3381, 1.3244, 1.3455, 1.3265, 1.3566, 1.3496, 1.3369, 1.3244,
         1.5946, 1.6101, 1.5994, 1.5959, 1.6026, 1.5925, 1.6106, 1.5650, 1.5697,
         1.2556, 1.2800, 1.2728, 1.2887, 1.2509, 1.2434, 1.2327, 1.3115, 1.2699],
        [1.3653, 1.2148, 1.2044, 1.2473, 1.2475, 1.2600, 1.2539, 1.1597, 1.1597,
         3.6219, 3.7048, 3.5544, 3.9260, 3.6224, 4.2373, 3.4926, 3.5789, 4.0251,
         1.5630, 1.5506, 1.5250, 1.5229, 1.5440, 1.5534, 1.5783, 1.5534, 1.5534,
         1.3309, 1.2975, 1.2911, 1.3491, 1.2912, 1.3866, 1.3668, 1.3354, 1.2879,
         1.5331, 1.5899, 1.5530, 1.5398, 1.5348, 1.5729, 1.5926, 1.4256, 1.5240,
         1.1467, 1.2597, 1.2327, 1.2814, 1.1409, 1.1473, 1.0734, 1.3493, 1.2231],
        [1.4507, 1.4506, 1.4490, 1.4462, 1.4466, 1.4507, 1.4464, 1.4507, 1.4507,
         1.4364, 1.4358, 1.4364, 1.4364, 1.4364, 1.4177, 1.4364, 1.4353, 1.4330,
         2.2024, 2.2027, 2.2194, 2.1951, 2.1766, 2.1748, 2.2041, 2.1739, 2.1739,
         1.5006, 1.4990, 1.5064, 1.5064, 1.5006, 1.5064, 1.5063, 1.5064, 1.5064,
         1.7737, 1.7738, 1.7738, 1.7706, 1.7737, 1.7737, 1.7738, 1.7511, 1.7538,
         1.4501, 1.4547, 1.4547, 1.4547, 1.4465, 1.4547, 1.4508, 1.4547, 1.4547],
        [1.3198, 1.3178, 1.3017, 1.2930, 1.3167, 1.3151, 1.3162, 1.3166, 1.3166,
         1.3022, 1.2955, 1.2916, 1.2912, 1.3031, 1.2875, 1.2986, 1.3026, 1.2750,
         1.6446, 1.6181, 1.6415, 1.6409, 1.6403, 1.6404, 1.6426, 1.6441, 1.6441,
         3.4837, 3.2737, 3.1991, 3.2574, 3.4086, 3.2261, 3.4585, 3.2070, 3.1857,
         1.6471, 1.6397, 1.6379, 1.6411, 1.6440, 1.6199, 1.6454, 1.5846, 1.6111,
         1.3194, 1.3138, 1.3040, 1.3187, 1.3144, 1.3065, 1.3187, 1.3190, 1.3209],
        [1.4535, 1.4491, 1.4054, 1.4090, 1.4467, 1.4535, 1.4519, 1.4535, 1.4535,
         1.4381, 1.4355, 1.4306, 1.4259, 1.4393, 1.3990, 1.4334, 1.4392, 1.4345,
         1.7572, 1.7485, 1.7473, 1.7554, 1.7730, 1.7716, 1.7517, 1.7731, 1.7731,
         1.4673, 1.4725, 1.5091, 1.5039, 1.4726, 1.5077, 1.4961, 1.5092, 1.5061,
         2.2000, 2.1800, 2.1687, 2.1865, 2.2301, 2.2481, 2.2145, 2.3174, 2.3144,
         1.4423, 1.4328, 1.4472, 1.4575, 1.4448, 1.4543, 1.4250, 1.4515, 1.4575],
        [1.3590, 1.2677, 1.2633, 1.2822, 1.2753, 1.2855, 1.2843, 1.2246, 1.2246,
         1.2655, 1.2228, 1.2184, 1.2264, 1.3119, 1.1787, 1.1341, 1.3119, 1.2104,
         1.6139, 1.5903, 1.5720, 1.5671, 1.5903, 1.5865, 1.6066, 1.5918, 1.5918,
         1.3550, 1.3282, 1.3281, 1.3450, 1.3300, 1.3726, 1.3748, 1.3489, 1.3281,
         1.5879, 1.5875, 1.5931, 1.5827, 1.5589, 1.5627, 1.6234, 1.5128, 1.4821,
         4.0655, 3.6123, 3.7002, 3.6849, 3.6983, 3.3827, 4.0610, 3.6605, 3.4143]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 254 : 1779.3687297156723
Test loss for epoch 254 : 195.3191282092446
Test Precision for epoch 254 : 0.26153846153846155
Test Recall for epoch 254 : 0.26153846153846155
Test F1 for epoch 254 : 0.26153846153846155


theta for epoch 255 : tensor([[3.6226, 3.6443, 3.7883, 3.7354, 3.7202, 3.6042, 3.6453, 3.5447, 3.5447,
         1.2592, 1.2396, 1.2360, 1.2413, 1.2802, 1.2224, 1.1912, 1.2802, 1.2289,
         1.5956, 1.5801, 1.6040, 1.5870, 1.5927, 1.5943, 1.6014, 1.5943, 1.5943,
         1.3415, 1.3527, 1.3388, 1.3602, 1.3410, 1.3714, 1.3643, 1.3515, 1.3388,
         1.5946, 1.6102, 1.5994, 1.5959, 1.6026, 1.5926, 1.6107, 1.5651, 1.5697,
         1.2542, 1.2788, 1.2714, 1.2875, 1.2495, 1.2419, 1.2312, 1.3103, 1.2685],
        [1.3788, 1.2274, 1.2171, 1.2600, 1.2603, 1.2727, 1.2666, 1.1718, 1.1718,
         3.6078, 3.6907, 3.5402, 3.9124, 3.6083, 4.2246, 3.4783, 3.5647, 4.0117,
         1.5703, 1.5579, 1.5324, 1.5301, 1.5511, 1.5606, 1.5855, 1.5606, 1.5606,
         1.3483, 1.3148, 1.3082, 1.3666, 1.3084, 1.4042, 1.3843, 1.3527, 1.3050,
         1.5408, 1.5974, 1.5606, 1.5474, 1.5425, 1.5805, 1.6002, 1.4337, 1.5317,
         1.1547, 1.2677, 1.2407, 1.2894, 1.1489, 1.1552, 1.0815, 1.3570, 1.2310],
        [1.4556, 1.4556, 1.4539, 1.4511, 1.4515, 1.4556, 1.4513, 1.4556, 1.4556,
         1.4304, 1.4297, 1.4303, 1.4303, 1.4304, 1.4117, 1.4304, 1.4292, 1.4270,
         2.2009, 2.2011, 2.2179, 2.1936, 2.1751, 2.1733, 2.2026, 2.1724, 2.1724,
         1.5143, 1.5127, 1.5201, 1.5201, 1.5143, 1.5201, 1.5201, 1.5201, 1.5201,
         1.7735, 1.7735, 1.7735, 1.7704, 1.7734, 1.7734, 1.7735, 1.7508, 1.7535,
         1.4481, 1.4527, 1.4527, 1.4527, 1.4444, 1.4527, 1.4488, 1.4527, 1.4527],
        [1.3245, 1.3225, 1.3065, 1.2978, 1.3215, 1.3199, 1.3210, 1.3214, 1.3214,
         1.2963, 1.2896, 1.2856, 1.2853, 1.2971, 1.2815, 1.2926, 1.2967, 1.2690,
         1.6431, 1.6166, 1.6400, 1.6394, 1.6388, 1.6389, 1.6411, 1.6425, 1.6425,
         3.4945, 3.2846, 3.2100, 3.2683, 3.4194, 3.2369, 3.4693, 3.2179, 3.1966,
         1.6470, 1.6395, 1.6378, 1.6409, 1.6439, 1.6198, 1.6453, 1.5845, 1.6110,
         1.3175, 1.3119, 1.3021, 1.3168, 1.3125, 1.3046, 1.3168, 1.3172, 1.3190],
        [1.4585, 1.4541, 1.4104, 1.4140, 1.4517, 1.4584, 1.4568, 1.4585, 1.4585,
         1.4321, 1.4295, 1.4245, 1.4198, 1.4332, 1.3928, 1.4273, 1.4332, 1.4284,
         1.7556, 1.7469, 1.7457, 1.7538, 1.7714, 1.7700, 1.7501, 1.7715, 1.7715,
         1.4810, 1.4862, 1.5229, 1.5176, 1.4863, 1.5214, 1.5098, 1.5229, 1.5198,
         2.1998, 2.1798, 2.1685, 2.1863, 2.2299, 2.2478, 2.2142, 2.3173, 2.3142,
         1.4403, 1.4308, 1.4452, 1.4555, 1.4427, 1.4522, 1.4229, 1.4494, 1.4555],
        [1.3547, 1.2647, 1.2602, 1.2790, 1.2721, 1.2823, 1.2811, 1.2224, 1.2224,
         1.2573, 1.2149, 1.2101, 1.2185, 1.3038, 1.1707, 1.1268, 1.3038, 1.2024,
         1.6090, 1.5855, 1.5671, 1.5625, 1.5857, 1.5819, 1.6018, 1.5872, 1.5872,
         1.3610, 1.3342, 1.3347, 1.3509, 1.3363, 1.3783, 1.3807, 1.3550, 1.3347,
         1.5852, 1.5846, 1.5904, 1.5800, 1.5561, 1.5598, 1.6205, 1.5100, 1.4792,
         4.0707, 3.6169, 3.7049, 3.6896, 3.7030, 3.3872, 4.0663, 3.6650, 3.4188]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 255 : 1779.6957724678607
Test loss for epoch 255 : 194.64459596046038
Test Precision for epoch 255 : 0.26153846153846155
Test Recall for epoch 255 : 0.26153846153846155
Test F1 for epoch 255 : 0.26153846153846155


theta for epoch 256 : tensor([[3.6200, 3.6417, 3.7857, 3.7328, 3.7175, 3.6015, 3.6426, 3.5420, 3.5420,
         1.2588, 1.2391, 1.2351, 1.2407, 1.2802, 1.2217, 1.1901, 1.2802, 1.2281,
         1.5985, 1.5830, 1.6069, 1.5898, 1.5955, 1.5971, 1.6043, 1.5971, 1.5971,
         1.3479, 1.3591, 1.3450, 1.3666, 1.3473, 1.3780, 1.3708, 1.3579, 1.3450,
         1.5964, 1.6120, 1.6012, 1.5977, 1.6044, 1.5944, 1.6126, 1.5669, 1.5715,
         1.2475, 1.2724, 1.2650, 1.2812, 1.2427, 1.2351, 1.2244, 1.3040, 1.2620],
        [1.3819, 1.2297, 1.2196, 1.2625, 1.2627, 1.2751, 1.2690, 1.1736, 1.1736,
         3.6022, 3.6853, 3.5347, 3.9075, 3.6027, 4.2206, 3.4726, 3.5591, 4.0070,
         1.5759, 1.5635, 1.5381, 1.5356, 1.5566, 1.5660, 1.5911, 1.5661, 1.5661,
         1.3558, 1.3222, 1.3154, 1.3741, 1.3158, 1.4119, 1.3919, 1.3602, 1.3122,
         1.5455, 1.6022, 1.5653, 1.5521, 1.5472, 1.5852, 1.6050, 1.4386, 1.5365,
         1.1541, 1.2671, 1.2401, 1.2889, 1.1482, 1.1543, 1.0809, 1.3563, 1.2304],
        [1.4527, 1.4527, 1.4510, 1.4482, 1.4486, 1.4527, 1.4484, 1.4527, 1.4527,
         1.4301, 1.4294, 1.4301, 1.4300, 1.4301, 1.4114, 1.4301, 1.4289, 1.4267,
         2.2036, 2.2039, 2.2206, 2.1962, 2.1777, 2.1759, 2.2052, 2.1750, 2.1750,
         1.5205, 1.5189, 1.5263, 1.5263, 1.5205, 1.5263, 1.5262, 1.5263, 1.5263,
         1.7753, 1.7754, 1.7754, 1.7722, 1.7753, 1.7753, 1.7754, 1.7527, 1.7554,
         1.4414, 1.4460, 1.4460, 1.4460, 1.4378, 1.4460, 1.4421, 1.4460, 1.4460],
        [1.3213, 1.3193, 1.3033, 1.2945, 1.3182, 1.3166, 1.3177, 1.3182, 1.3182,
         1.2961, 1.2894, 1.2854, 1.2851, 1.2970, 1.2813, 1.2924, 1.2966, 1.2688,
         1.6461, 1.6196, 1.6430, 1.6424, 1.6419, 1.6419, 1.6441, 1.6456, 1.6456,
         3.4989, 3.2890, 3.2144, 3.2726, 3.4238, 3.2412, 3.4736, 3.2223, 3.2010,
         1.6489, 1.6415, 1.6398, 1.6429, 1.6458, 1.6218, 1.6472, 1.5864, 1.6130,
         1.3109, 1.3053, 1.2955, 1.3102, 1.3059, 1.2980, 1.3102, 1.3106, 1.3124],
        [1.4556, 1.4512, 1.4075, 1.4111, 1.4488, 1.4555, 1.4539, 1.4556, 1.4556,
         1.4318, 1.4292, 1.4242, 1.4195, 1.4330, 1.3925, 1.4270, 1.4329, 1.4281,
         1.7585, 1.7498, 1.7486, 1.7566, 1.7743, 1.7729, 1.7529, 1.7744, 1.7744,
         1.4872, 1.4923, 1.5290, 1.5238, 1.4925, 1.5276, 1.5160, 1.5291, 1.5260,
         2.2016, 2.1816, 2.1703, 2.1881, 2.2317, 2.2497, 2.2160, 2.3191, 2.3161,
         1.4335, 1.4241, 1.4385, 1.4488, 1.4360, 1.4456, 1.4161, 1.4428, 1.4489],
        [1.3423, 1.2534, 1.2488, 1.2675, 1.2605, 1.2707, 1.2696, 1.2118, 1.2118,
         1.2531, 1.2109, 1.2056, 1.2145, 1.3000, 1.1663, 1.1226, 1.3000, 1.1981,
         1.6067, 1.5832, 1.5646, 1.5603, 1.5836, 1.5798, 1.5995, 1.5851, 1.5851,
         1.3588, 1.3320, 1.3329, 1.3486, 1.3342, 1.3757, 1.3783, 1.3528, 1.3329,
         1.5831, 1.5823, 1.5883, 1.5778, 1.5539, 1.5575, 1.6182, 1.5077, 1.4767,
         4.0774, 3.6229, 3.7110, 3.6956, 3.7091, 3.3932, 4.0730, 3.6710, 3.4248]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 256 : 1780.0124092748829
Test loss for epoch 256 : 194.5254702036945
Test Precision for epoch 256 : 0.26153846153846155
Test Recall for epoch 256 : 0.26153846153846155
Test F1 for epoch 256 : 0.26153846153846155


theta for epoch 257 : tensor([[3.6216, 3.6433, 3.7872, 3.7344, 3.7191, 3.6031, 3.6442, 3.5437, 3.5437,
         1.2649, 1.2449, 1.2407, 1.2466, 1.2867, 1.2272, 1.1950, 1.2867, 1.2336,
         1.6020, 1.5865, 1.6105, 1.5931, 1.5989, 1.6005, 1.6078, 1.6005, 1.6005,
         1.3337, 1.3448, 1.3306, 1.3525, 1.3330, 1.3640, 1.3567, 1.3437, 1.3306,
         1.5979, 1.6136, 1.6027, 1.5992, 1.6060, 1.5960, 1.6143, 1.5684, 1.5731,
         1.2420, 1.2672, 1.2596, 1.2761, 1.2371, 1.2293, 1.2186, 1.2989, 1.2566],
        [1.3807, 1.2277, 1.2177, 1.2606, 1.2609, 1.2732, 1.2672, 1.1712, 1.1712,
         3.6051, 3.6883, 3.5375, 3.9109, 3.6055, 4.2248, 3.4753, 3.5619, 4.0107,
         1.5776, 1.5651, 1.5397, 1.5371, 1.5581, 1.5676, 1.5928, 1.5676, 1.5676,
         1.3466, 1.3132, 1.3061, 1.3649, 1.3066, 1.4027, 1.3827, 1.3509, 1.3030,
         1.5459, 1.6028, 1.5657, 1.5526, 1.5477, 1.5858, 1.6057, 1.4390, 1.5370,
         1.1496, 1.2629, 1.2357, 1.2848, 1.1436, 1.1496, 1.0762, 1.3521, 1.2260],
        [1.4535, 1.4534, 1.4517, 1.4489, 1.4493, 1.4535, 1.4491, 1.4535, 1.4535,
         1.4366, 1.4359, 1.4365, 1.4365, 1.4366, 1.4178, 1.4365, 1.4354, 1.4332,
         2.2072, 2.2075, 2.2242, 2.1997, 2.1812, 2.1794, 2.2086, 2.1785, 2.1785,
         1.5067, 1.5051, 1.5125, 1.5125, 1.5067, 1.5125, 1.5125, 1.5125, 1.5125,
         1.7772, 1.7773, 1.7773, 1.7742, 1.7772, 1.7772, 1.7773, 1.7546, 1.7573,
         1.4364, 1.4411, 1.4411, 1.4411, 1.4328, 1.4411, 1.4371, 1.4410, 1.4411],
        [1.3217, 1.3198, 1.3038, 1.2950, 1.3187, 1.3171, 1.3182, 1.3187, 1.3187,
         1.3027, 1.2959, 1.2920, 1.2917, 1.3036, 1.2879, 1.2990, 1.3032, 1.2754,
         1.6501, 1.6236, 1.6470, 1.6464, 1.6458, 1.6459, 1.6481, 1.6495, 1.6495,
         3.4860, 3.2759, 3.2012, 3.2596, 3.4109, 3.2282, 3.4608, 3.2091, 3.1878,
         1.6510, 1.6435, 1.6418, 1.6449, 1.6479, 1.6238, 1.6493, 1.5885, 1.6150,
         1.3059, 1.3004, 1.2906, 1.3053, 1.3009, 1.2930, 1.3053, 1.3057, 1.3075],
        [1.4563, 1.4519, 1.4083, 1.4118, 1.4495, 1.4562, 1.4546, 1.4563, 1.4563,
         1.4383, 1.4357, 1.4307, 1.4259, 1.4394, 1.3989, 1.4335, 1.4394, 1.4346,
         1.7623, 1.7536, 1.7524, 1.7604, 1.7781, 1.7767, 1.7568, 1.7783, 1.7783,
         1.4733, 1.4785, 1.5153, 1.5100, 1.4787, 1.5138, 1.5022, 1.5153, 1.5122,
         2.2036, 2.1835, 2.1721, 2.1900, 2.2336, 2.2515, 2.2179, 2.3211, 2.3181,
         1.4285, 1.4191, 1.4335, 1.4439, 1.4310, 1.4406, 1.4110, 1.4378, 1.4439],
        [1.3312, 1.2428, 1.2380, 1.2567, 1.2498, 1.2600, 1.2588, 1.2014, 1.2014,
         1.2542, 1.2118, 1.2062, 1.2154, 1.3015, 1.1667, 1.1227, 1.3015, 1.1986,
         1.6039, 1.5804, 1.5617, 1.5576, 1.5810, 1.5771, 1.5967, 1.5825, 1.5825,
         1.3385, 1.3117, 1.3129, 1.3283, 1.3140, 1.3552, 1.3579, 1.3326, 1.3130,
         1.5799, 1.5789, 1.5850, 1.5746, 1.5505, 1.5540, 1.6148, 1.5042, 1.4730,
         4.0874, 3.6323, 3.7204, 3.7050, 3.7185, 3.4026, 4.0830, 3.6804, 3.4341]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 257 : 1779.4512881186583
Test loss for epoch 257 : 195.08378079630518
Test Precision for epoch 257 : 0.26153846153846155
Test Recall for epoch 257 : 0.26153846153846155
Test F1 for epoch 257 : 0.26153846153846155


theta for epoch 258 : tensor([[3.6261, 3.6479, 3.7918, 3.7390, 3.7237, 3.6078, 3.6489, 3.5484, 3.5484,
         1.2699, 1.2496, 1.2453, 1.2514, 1.2921, 1.2317, 1.1989, 1.2921, 1.2380,
         1.5989, 1.5833, 1.6074, 1.5899, 1.5957, 1.5973, 1.6047, 1.5973, 1.5973,
         1.3288, 1.3400, 1.3256, 1.3477, 1.3281, 1.3593, 1.3520, 1.3388, 1.3256,
         1.5954, 1.6112, 1.6003, 1.5967, 1.6035, 1.5936, 1.6119, 1.5659, 1.5706,
         1.2380, 1.2636, 1.2559, 1.2726, 1.2330, 1.2251, 1.2144, 1.2955, 1.2528],
        [1.3748, 1.2211, 1.2111, 1.2541, 1.2544, 1.2668, 1.2607, 1.1642, 1.1642,
         3.6135, 3.6968, 3.5458, 3.9199, 3.6139, 4.2346, 3.4835, 3.5702, 4.0199,
         1.5707, 1.5581, 1.5327, 1.5300, 1.5511, 1.5605, 1.5859, 1.5605, 1.5605,
         1.3385, 1.3050, 1.2979, 1.3568, 1.2984, 1.3947, 1.3747, 1.3428, 1.2947,
         1.5395, 1.5966, 1.5594, 1.5462, 1.5414, 1.5795, 1.5995, 1.4323, 1.5306,
         1.1418, 1.2557, 1.2283, 1.2778, 1.1357, 1.1415, 1.0681, 1.3451, 1.2185],
        [1.4555, 1.4555, 1.4538, 1.4510, 1.4514, 1.4555, 1.4512, 1.4555, 1.4555,
         1.4422, 1.4416, 1.4422, 1.4422, 1.4422, 1.4235, 1.4422, 1.4411, 1.4388,
         2.2050, 2.2053, 2.2221, 2.1976, 2.1791, 2.1773, 2.2065, 2.1764, 2.1764,
         1.5028, 1.5012, 1.5086, 1.5086, 1.5028, 1.5086, 1.5086, 1.5086, 1.5086,
         1.7755, 1.7756, 1.7756, 1.7724, 1.7755, 1.7755, 1.7756, 1.7529, 1.7556,
         1.4336, 1.4383, 1.4383, 1.4383, 1.4300, 1.4383, 1.4342, 1.4382, 1.4383],
        [1.3235, 1.3216, 1.3056, 1.2968, 1.3205, 1.3189, 1.3200, 1.3205, 1.3205,
         1.3084, 1.3017, 1.2977, 1.2974, 1.3093, 1.2936, 1.3047, 1.3089, 1.2811,
         1.6478, 1.6213, 1.6447, 1.6441, 1.6436, 1.6436, 1.6458, 1.6473, 1.6473,
         3.4820, 3.2718, 3.1971, 3.2555, 3.4068, 3.2241, 3.4568, 3.2050, 3.1836,
         1.6493, 1.6419, 1.6401, 1.6432, 1.6462, 1.6222, 1.6476, 1.5868, 1.6133,
         1.3031, 1.2976, 1.2877, 1.3025, 1.2981, 1.2902, 1.3025, 1.3029, 1.3047],
        [1.4584, 1.4540, 1.4104, 1.4140, 1.4516, 1.4583, 1.4567, 1.4584, 1.4584,
         1.4439, 1.4413, 1.4363, 1.4316, 1.4451, 1.4045, 1.4392, 1.4450, 1.4402,
         1.7601, 1.7513, 1.7501, 1.7582, 1.7759, 1.7745, 1.7545, 1.7760, 1.7760,
         1.4694, 1.4745, 1.5114, 1.5061, 1.4748, 1.5099, 1.4983, 1.5114, 1.5083,
         2.2019, 2.1818, 2.1705, 2.1883, 2.2320, 2.2499, 2.2163, 2.3195, 2.3165,
         1.4257, 1.4163, 1.4307, 1.4411, 1.4281, 1.4378, 1.4081, 1.4350, 1.4411],
        [1.3206, 1.2318, 1.2270, 1.2458, 1.2388, 1.2491, 1.2479, 1.1904, 1.1904,
         1.2539, 1.2110, 1.2052, 1.2147, 1.3017, 1.1654, 1.1206, 1.3017, 1.1973,
         1.5946, 1.5709, 1.5522, 1.5481, 1.5716, 1.5678, 1.5873, 1.5731, 1.5731,
         1.3255, 1.2986, 1.2999, 1.3151, 1.3009, 1.3421, 1.3449, 1.3195, 1.2999,
         1.5722, 1.5711, 1.5774, 1.5669, 1.5427, 1.5462, 1.6072, 1.4962, 1.4649,
         4.1005, 3.6447, 3.7329, 3.7175, 3.7311, 3.4150, 4.0961, 3.6928, 3.4465]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 258 : 1779.2721614308002
Test loss for epoch 258 : 195.79539604615113
Test Precision for epoch 258 : 0.26153846153846155
Test Recall for epoch 258 : 0.26153846153846155
Test F1 for epoch 258 : 0.26153846153846155


theta for epoch 259 : tensor([[3.6280, 3.6497, 3.7936, 3.7408, 3.7255, 3.6096, 3.6507, 3.5503, 3.5503,
         1.2662, 1.2458, 1.2415, 1.2477, 1.2886, 1.2278, 1.1952, 1.2886, 1.2340,
         1.5959, 1.5803, 1.6044, 1.5868, 1.5926, 1.5942, 1.6017, 1.5942, 1.5942,
         1.3413, 1.3525, 1.3380, 1.3602, 1.3406, 1.3719, 1.3645, 1.3514, 1.3380,
         1.5932, 1.6090, 1.5980, 1.5945, 1.6013, 1.5914, 1.6097, 1.5637, 1.5683,
         1.2365, 1.2625, 1.2546, 1.2716, 1.2314, 1.2233, 1.2126, 1.2946, 1.2515],
        [1.3776, 1.2239, 1.2139, 1.2570, 1.2572, 1.2696, 1.2635, 1.1670, 1.1670,
         3.6097, 3.6932, 3.5420, 3.9167, 3.6101, 4.2323, 3.4796, 3.5663, 4.0170,
         1.5700, 1.5574, 1.5320, 1.5294, 1.5504, 1.5599, 1.5852, 1.5599, 1.5599,
         1.3472, 1.3136, 1.3065, 1.3655, 1.3071, 1.4035, 1.3834, 1.3515, 1.3034,
         1.5392, 1.5962, 1.5591, 1.5459, 1.5410, 1.5791, 1.5991, 1.4321, 1.5303,
         1.1421, 1.2564, 1.2289, 1.2786, 1.1359, 1.1416, 1.0683, 1.3457, 1.2190],
        [1.4583, 1.4583, 1.4566, 1.4538, 1.4542, 1.4583, 1.4540, 1.4583, 1.4583,
         1.4386, 1.4379, 1.4385, 1.4385, 1.4386, 1.4198, 1.4385, 1.4374, 1.4352,
         2.2023, 2.2026, 2.2194, 2.1951, 2.1765, 2.1747, 2.2040, 2.1738, 2.1738,
         1.5151, 1.5135, 1.5210, 1.5210, 1.5152, 1.5210, 1.5209, 1.5210, 1.5210,
         1.7735, 1.7736, 1.7736, 1.7704, 1.7735, 1.7735, 1.7736, 1.7508, 1.7535,
         1.4327, 1.4373, 1.4373, 1.4373, 1.4290, 1.4373, 1.4333, 1.4373, 1.4373],
        [1.3259, 1.3240, 1.3081, 1.2993, 1.3230, 1.3213, 1.3225, 1.3230, 1.3230,
         1.3047, 1.2980, 1.2941, 1.2937, 1.3057, 1.2899, 1.3010, 1.3053, 1.2774,
         1.6449, 1.6185, 1.6419, 1.6413, 1.6407, 1.6407, 1.6430, 1.6444, 1.6444,
         3.4924, 3.2822, 3.2076, 3.2659, 3.4172, 3.2345, 3.4671, 3.2155, 3.1941,
         1.6472, 1.6398, 1.6381, 1.6412, 1.6441, 1.6201, 1.6456, 1.5848, 1.6113,
         1.3021, 1.2966, 1.2868, 1.3015, 1.2971, 1.2892, 1.3015, 1.3019, 1.3037],
        [1.4611, 1.4568, 1.4133, 1.4168, 1.4544, 1.4610, 1.4595, 1.4611, 1.4611,
         1.4403, 1.4377, 1.4327, 1.4279, 1.4414, 1.4008, 1.4355, 1.4414, 1.4365,
         1.7573, 1.7486, 1.7473, 1.7554, 1.7731, 1.7717, 1.7517, 1.7733, 1.7733,
         1.4818, 1.4869, 1.5237, 1.5184, 1.4871, 1.5222, 1.5106, 1.5238, 1.5207,
         2.1999, 2.1798, 2.1685, 2.1864, 2.2301, 2.2479, 2.2143, 2.3176, 2.3146,
         1.4247, 1.4154, 1.4297, 1.4401, 1.4272, 1.4368, 1.4072, 1.4341, 1.4402],
        [1.3148, 1.2252, 1.2204, 1.2393, 1.2323, 1.2427, 1.2415, 1.1834, 1.1834,
         1.2464, 1.2037, 1.1978, 1.2074, 1.2947, 1.1578, 1.1140, 1.2948, 1.1897,
         1.5867, 1.5630, 1.5442, 1.5401, 1.5636, 1.5598, 1.5794, 1.5651, 1.5651,
         1.3288, 1.3018, 1.3031, 1.3184, 1.3041, 1.3456, 1.3484, 1.3229, 1.3031,
         1.5657, 1.5647, 1.5709, 1.5604, 1.5362, 1.5397, 1.6009, 1.4895, 1.4581,
         4.1106, 3.6542, 3.7424, 3.7270, 3.7407, 3.4244, 4.1063, 3.7023, 3.4560]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 259 : 1778.8799754014199
Test loss for epoch 259 : 195.87306231299146
Test Precision for epoch 259 : 0.26153846153846155
Test Recall for epoch 259 : 0.26153846153846155
Test F1 for epoch 259 : 0.26153846153846155


theta for epoch 260 : tensor([[3.6239, 3.6456, 3.7895, 3.7367, 3.7214, 3.6055, 3.6466, 3.5461, 3.5461,
         1.2609, 1.2406, 1.2362, 1.2424, 1.2834, 1.2228, 1.1902, 1.2835, 1.2286,
         1.5979, 1.5823, 1.6064, 1.5888, 1.5946, 1.5962, 1.6037, 1.5962, 1.5962,
         1.3528, 1.3640, 1.3495, 1.3717, 1.3520, 1.3833, 1.3760, 1.3629, 1.3495,
         1.5943, 1.6101, 1.5991, 1.5956, 1.6024, 1.5925, 1.6108, 1.5648, 1.5695,
         1.2367, 1.2623, 1.2547, 1.2716, 1.2317, 1.2237, 1.2130, 1.2946, 1.2516],
        [1.3783, 1.2253, 1.2153, 1.2583, 1.2585, 1.2709, 1.2648, 1.1688, 1.1688,
         3.6059, 3.6896, 3.5382, 3.9135, 3.6062, 4.2299, 3.4757, 3.5624, 4.0140,
         1.5718, 1.5594, 1.5339, 1.5315, 1.5525, 1.5619, 1.5871, 1.5620, 1.5620,
         1.3541, 1.3205, 1.3136, 1.3724, 1.3140, 1.4103, 1.3903, 1.3585, 1.3104,
         1.5408, 1.5975, 1.5606, 1.5474, 1.5425, 1.5806, 1.6004, 1.4337, 1.5318,
         1.1433, 1.2564, 1.2296, 1.2787, 1.1373, 1.1432, 1.0699, 1.3457, 1.2198],
        [1.4584, 1.4584, 1.4567, 1.4539, 1.4543, 1.4584, 1.4541, 1.4584, 1.4584,
         1.4326, 1.4319, 1.4325, 1.4325, 1.4326, 1.4138, 1.4326, 1.4314, 1.4292,
         2.2035, 2.2038, 2.2205, 2.1961, 2.1776, 2.1758, 2.2050, 2.1749, 2.1749,
         1.5252, 1.5236, 1.5310, 1.5310, 1.5252, 1.5310, 1.5309, 1.5310, 1.5310,
         1.7740, 1.7741, 1.7741, 1.7709, 1.7740, 1.7740, 1.7741, 1.7513, 1.7540,
         1.4320, 1.4366, 1.4366, 1.4366, 1.4283, 1.4366, 1.4326, 1.4366, 1.4366],
        [1.3256, 1.3238, 1.3079, 1.2991, 1.3227, 1.3211, 1.3222, 1.3228, 1.3228,
         1.2988, 1.2920, 1.2881, 1.2877, 1.2997, 1.2839, 1.2950, 1.2993, 1.2714,
         1.6461, 1.6196, 1.6430, 1.6424, 1.6418, 1.6419, 1.6441, 1.6456, 1.6456,
         3.5010, 3.2909, 3.2163, 3.2745, 3.4258, 3.2431, 3.4757, 3.2241, 3.2028,
         1.6477, 1.6403, 1.6386, 1.6417, 1.6446, 1.6206, 1.6460, 1.5853, 1.6118,
         1.3013, 1.2958, 1.2859, 1.3007, 1.2963, 1.2884, 1.3007, 1.3011, 1.3029],
        [1.4612, 1.4569, 1.4135, 1.4169, 1.4545, 1.4611, 1.4596, 1.4612, 1.4612,
         1.4343, 1.4317, 1.4267, 1.4219, 1.4354, 1.3948, 1.4295, 1.4354, 1.4305,
         1.7585, 1.7498, 1.7485, 1.7566, 1.7743, 1.7729, 1.7530, 1.7745, 1.7745,
         1.4918, 1.4970, 1.5337, 1.5285, 1.4972, 1.5323, 1.5206, 1.5338, 1.5307,
         2.2004, 2.1803, 2.1689, 2.1868, 2.2305, 2.2484, 2.2147, 2.3181, 2.3151,
         1.4240, 1.4146, 1.4290, 1.4394, 1.4265, 1.4361, 1.4065, 1.4333, 1.4395],
        [1.3320, 1.2422, 1.2375, 1.2563, 1.2494, 1.2597, 1.2585, 1.2001, 1.2001,
         1.2488, 1.2064, 1.2005, 1.2100, 1.2974, 1.1612, 1.1170, 1.2975, 1.1920,
         1.5973, 1.5736, 1.5550, 1.5508, 1.5742, 1.5704, 1.5900, 1.5757, 1.5757,
         1.3501, 1.3231, 1.3242, 1.3397, 1.3253, 1.3669, 1.3696, 1.3441, 1.3242,
         1.5743, 1.5733, 1.5794, 1.5690, 1.5449, 1.5485, 1.6094, 1.4985, 1.4673,
         4.0912, 3.6342, 3.7224, 3.7070, 3.7206, 3.4043, 4.0869, 3.6822, 3.4358]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 260 : 1779.8200016689148
Test loss for epoch 260 : 194.96162215789
Test Precision for epoch 260 : 0.26153846153846155
Test Recall for epoch 260 : 0.26153846153846155
Test F1 for epoch 260 : 0.26153846153846155


theta for epoch 261 : tensor([[3.6215, 3.6431, 3.7871, 3.7343, 3.7189, 3.6031, 3.6442, 3.5436, 3.5436,
         1.2602, 1.2399, 1.2356, 1.2417, 1.2829, 1.2222, 1.1896, 1.2830, 1.2277,
         1.6024, 1.5867, 1.6108, 1.5932, 1.5990, 1.6006, 1.6081, 1.6006, 1.6006,
         1.3364, 1.3476, 1.3332, 1.3553, 1.3356, 1.3669, 1.3596, 1.3464, 1.3332,
         1.5976, 1.6135, 1.6024, 1.5989, 1.6057, 1.5958, 1.6141, 1.5681, 1.5728,
         1.2444, 1.2697, 1.2623, 1.2791, 1.2394, 1.2314, 1.2207, 1.3022, 1.2592],
        [1.3724, 1.2201, 1.2100, 1.2530, 1.2532, 1.2656, 1.2595, 1.1640, 1.1640,
         3.6097, 3.6934, 3.5419, 3.9178, 3.6099, 4.2350, 3.4793, 3.5660, 4.0185,
         1.5715, 1.5590, 1.5335, 1.5312, 1.5523, 1.5618, 1.5868, 1.5618, 1.5618,
         1.3406, 1.3071, 1.3005, 1.3588, 1.3007, 1.3965, 1.3766, 1.3450, 1.2973,
         1.5404, 1.5971, 1.5603, 1.5470, 1.5421, 1.5802, 1.6000, 1.4330, 1.5314,
         1.1451, 1.2576, 1.2312, 1.2800, 1.1392, 1.1454, 1.0718, 1.3471, 1.2216],
        [1.4563, 1.4562, 1.4546, 1.4518, 1.4522, 1.4563, 1.4520, 1.4563, 1.4563,
         1.4316, 1.4309, 1.4316, 1.4316, 1.4316, 1.4128, 1.4316, 1.4304, 1.4282,
         2.2073, 2.2076, 2.2244, 2.1998, 2.1813, 2.1795, 2.2087, 2.1786, 2.1786,
         1.5082, 1.5066, 1.5140, 1.5140, 1.5082, 1.5140, 1.5140, 1.5140, 1.5140,
         1.7771, 1.7772, 1.7772, 1.7740, 1.7771, 1.7771, 1.7772, 1.7544, 1.7571,
         1.4394, 1.4440, 1.4440, 1.4440, 1.4357, 1.4440, 1.4400, 1.4440, 1.4440],
        [1.3231, 1.3213, 1.3055, 1.2966, 1.3203, 1.3186, 1.3198, 1.3204, 1.3204,
         1.2978, 1.2910, 1.2871, 1.2868, 1.2987, 1.2829, 1.2940, 1.2983, 1.2704,
         1.6501, 1.6237, 1.6471, 1.6465, 1.6459, 1.6459, 1.6482, 1.6496, 1.6496,
         3.4862, 3.2759, 3.2012, 3.2596, 3.4110, 3.2281, 3.4610, 3.2091, 3.1877,
         1.6508, 1.6434, 1.6416, 1.6447, 1.6477, 1.6237, 1.6491, 1.5884, 1.6149,
         1.3087, 1.3031, 1.2933, 1.3080, 1.3036, 1.2958, 1.3080, 1.3083, 1.3102],
        [1.4591, 1.4549, 1.4115, 1.4148, 1.4524, 1.4590, 1.4575, 1.4591, 1.4591,
         1.4333, 1.4307, 1.4257, 1.4209, 1.4345, 1.3938, 1.4285, 1.4344, 1.4296,
         1.7626, 1.7539, 1.7526, 1.7607, 1.7784, 1.7770, 1.7570, 1.7785, 1.7785,
         1.4748, 1.4801, 1.5168, 1.5115, 1.4802, 1.5153, 1.5037, 1.5168, 1.5137,
         2.2034, 2.1833, 2.1719, 2.1898, 2.2335, 2.2514, 2.2177, 2.3211, 2.3180,
         1.4314, 1.4220, 1.4364, 1.4468, 1.4339, 1.4435, 1.4139, 1.4407, 1.4468],
        [1.3443, 1.2536, 1.2490, 1.2679, 1.2610, 1.2713, 1.2701, 1.2110, 1.2110,
         1.2540, 1.2113, 1.2055, 1.2150, 1.3029, 1.1666, 1.1216, 1.3030, 1.1965,
         1.6080, 1.5844, 1.5659, 1.5615, 1.5848, 1.5810, 1.6008, 1.5863, 1.5863,
         1.3458, 1.3189, 1.3197, 1.3356, 1.3211, 1.3629, 1.3654, 1.3398, 1.3197,
         1.5830, 1.5823, 1.5882, 1.5778, 1.5538, 1.5574, 1.6183, 1.5075, 1.4765,
         4.0801, 3.6225, 3.7108, 3.6954, 3.7090, 3.3925, 4.0759, 3.6705, 3.4241]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 261 : 1779.2749799329172
Test loss for epoch 261 : 195.01887387262775
Test Precision for epoch 261 : 0.26153846153846155
Test Recall for epoch 261 : 0.26153846153846155
Test F1 for epoch 261 : 0.26153846153846155


theta for epoch 262 : tensor([[3.6193, 3.6408, 3.7847, 3.7320, 3.7166, 3.6008, 3.6419, 3.5413, 3.5413,
         1.2617, 1.2412, 1.2370, 1.2431, 1.2845, 1.2236, 1.1907, 1.2846, 1.2288,
         1.6002, 1.5846, 1.6087, 1.5911, 1.5968, 1.5985, 1.6059, 1.5984, 1.5984,
         1.3271, 1.3384, 1.3240, 1.3461, 1.3264, 1.3576, 1.3503, 1.3372, 1.3241,
         1.5972, 1.6131, 1.6020, 1.5985, 1.6053, 1.5954, 1.6138, 1.5677, 1.5724,
         1.2529, 1.2780, 1.2708, 1.2875, 1.2479, 1.2399, 1.2292, 1.3107, 1.2677],
        [1.3597, 1.2082, 1.1979, 1.2409, 1.2411, 1.2535, 1.2474, 1.1524, 1.1524,
         3.6194, 3.7033, 3.5516, 3.9280, 3.6195, 4.2461, 3.4889, 3.5756, 4.0290,
         1.5630, 1.5505, 1.5248, 1.5227, 1.5439, 1.5534, 1.5783, 1.5534, 1.5534,
         1.3276, 1.2941, 1.2877, 1.3458, 1.2878, 1.3833, 1.3635, 1.3320, 1.2845,
         1.5338, 1.5906, 1.5537, 1.5404, 1.5354, 1.5736, 1.5933, 1.4260, 1.5247,
         1.1437, 1.2559, 1.2299, 1.2786, 1.1379, 1.1442, 1.0702, 1.3459, 1.2203],
        [1.4500, 1.4499, 1.4483, 1.4455, 1.4458, 1.4500, 1.4456, 1.4499, 1.4499,
         1.4331, 1.4324, 1.4331, 1.4331, 1.4331, 1.4143, 1.4331, 1.4319, 1.4297,
         2.2055, 2.2058, 2.2226, 2.1981, 2.1795, 2.1777, 2.2070, 2.1768, 2.1768,
         1.4991, 1.4975, 1.5049, 1.5049, 1.4991, 1.5049, 1.5049, 1.5049, 1.5049,
         1.7769, 1.7770, 1.7770, 1.7738, 1.7769, 1.7769, 1.7770, 1.7543, 1.7570,
         1.4481, 1.4528, 1.4528, 1.4528, 1.4445, 1.4528, 1.4488, 1.4527, 1.4528],
        [1.3162, 1.3146, 1.2987, 1.2899, 1.3135, 1.3119, 1.3130, 1.3137, 1.3137,
         1.2993, 1.2925, 1.2886, 1.2882, 1.3002, 1.2844, 1.2955, 1.2998, 1.2719,
         1.6481, 1.6217, 1.6450, 1.6445, 1.6438, 1.6439, 1.6461, 1.6476, 1.6476,
         3.4786, 3.2681, 3.1934, 3.2518, 3.4032, 3.2204, 3.4533, 3.2013, 3.1799,
         1.6506, 1.6431, 1.6414, 1.6445, 1.6475, 1.6235, 1.6489, 1.5882, 1.6147,
         1.3173, 1.3118, 1.3019, 1.3167, 1.3123, 1.3045, 1.3167, 1.3170, 1.3189],
        [1.4528, 1.4486, 1.4052, 1.4084, 1.4461, 1.4527, 1.4512, 1.4528, 1.4528,
         1.4348, 1.4322, 1.4272, 1.4224, 1.4360, 1.3954, 1.4300, 1.4360, 1.4311,
         1.7607, 1.7520, 1.7507, 1.7588, 1.7765, 1.7751, 1.7552, 1.7767, 1.7767,
         1.4657, 1.4710, 1.5077, 1.5024, 1.4711, 1.5062, 1.4945, 1.5077, 1.5046,
         2.2032, 2.1831, 2.1717, 2.1896, 2.2333, 2.2512, 2.2176, 2.3209, 2.3178,
         1.4402, 1.4308, 1.4452, 1.4555, 1.4427, 1.4523, 1.4228, 1.4495, 1.4556],
        [1.3496, 1.2579, 1.2534, 1.2724, 1.2655, 1.2758, 1.2746, 1.2147, 1.2147,
         1.2593, 1.2163, 1.2106, 1.2200, 1.3087, 1.1719, 1.1257, 1.3088, 1.2009,
         1.6108, 1.5872, 1.5688, 1.5642, 1.5874, 1.5836, 1.6035, 1.5889, 1.5889,
         1.3448, 1.3180, 1.3184, 1.3348, 1.3200, 1.3622, 1.3646, 1.3388, 1.3184,
         1.5865, 1.5860, 1.5917, 1.5813, 1.5574, 1.5611, 1.6219, 1.5112, 1.4803,
         4.0747, 3.6165, 3.7048, 3.6894, 3.7030, 3.3863, 4.0705, 3.6645, 3.4180]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 262 : 1779.3475333795075
Test loss for epoch 262 : 195.50075729676536
Test Precision for epoch 262 : 0.26153846153846155
Test Recall for epoch 262 : 0.26153846153846155
Test F1 for epoch 262 : 0.26153846153846155


theta for epoch 263 : tensor([[3.6172, 3.6387, 3.7826, 3.7299, 3.7144, 3.5987, 3.6398, 3.5391, 3.5391,
         1.2611, 1.2409, 1.2369, 1.2427, 1.2837, 1.2234, 1.1911, 1.2838, 1.2284,
         1.5960, 1.5804, 1.6045, 1.5870, 1.5927, 1.5943, 1.6018, 1.5943, 1.5943,
         1.3373, 1.3485, 1.3343, 1.3562, 1.3366, 1.3676, 1.3604, 1.3474, 1.3344,
         1.5944, 1.6103, 1.5993, 1.5957, 1.6026, 1.5926, 1.6110, 1.5650, 1.5697,
         1.2545, 1.2794, 1.2724, 1.2890, 1.2495, 1.2416, 1.2309, 1.3122, 1.2693],
        [1.3692, 1.2184, 1.2081, 1.2509, 1.2512, 1.2635, 1.2575, 1.1630, 1.1630,
         3.6093, 3.6933, 3.5414, 3.9185, 3.6094, 4.2373, 3.4787, 3.5654, 4.0197,
         1.5662, 1.5538, 1.5282, 1.5262, 1.5472, 1.5567, 1.5815, 1.5567, 1.5567,
         1.3402, 1.3068, 1.3005, 1.3584, 1.3005, 1.3957, 1.3760, 1.3447, 1.2974,
         1.5375, 1.5940, 1.5573, 1.5441, 1.5391, 1.5771, 1.5967, 1.4301, 1.5284,
         1.1514, 1.2629, 1.2374, 1.2857, 1.1457, 1.1521, 1.0783, 1.3527, 1.2278],
        [1.4520, 1.4519, 1.4503, 1.4475, 1.4479, 1.4519, 1.4476, 1.4519, 1.4519,
         1.4319, 1.4313, 1.4319, 1.4319, 1.4319, 1.4132, 1.4319, 1.4308, 1.4285,
         2.2010, 2.2013, 2.2181, 2.1937, 2.1752, 2.1734, 2.2026, 2.1725, 2.1725,
         1.5080, 1.5064, 1.5138, 1.5138, 1.5080, 1.5138, 1.5138, 1.5138, 1.5138,
         1.7737, 1.7738, 1.7738, 1.7706, 1.7737, 1.7737, 1.7738, 1.7510, 1.7537,
         1.4491, 1.4537, 1.4537, 1.4537, 1.4454, 1.4537, 1.4497, 1.4536, 1.4537],
        [1.3179, 1.3164, 1.3005, 1.2917, 1.3153, 1.3136, 1.3148, 1.3155, 1.3155,
         1.2980, 1.2913, 1.2873, 1.2870, 1.2989, 1.2832, 1.2943, 1.2985, 1.2707,
         1.6431, 1.6167, 1.6401, 1.6395, 1.6389, 1.6389, 1.6412, 1.6426, 1.6426,
         3.4866, 3.2762, 3.2015, 3.2599, 3.4113, 3.2285, 3.4613, 3.2094, 3.1881,
         1.6472, 1.6398, 1.6381, 1.6412, 1.6441, 1.6201, 1.6455, 1.5848, 1.6113,
         1.3181, 1.3125, 1.3027, 1.3174, 1.3131, 1.3052, 1.3175, 1.3177, 1.3196],
        [1.4548, 1.4506, 1.4073, 1.4104, 1.4481, 1.4547, 1.4532, 1.4548, 1.4548,
         1.4336, 1.4310, 1.4260, 1.4212, 1.4348, 1.3942, 1.4289, 1.4348, 1.4299,
         1.7560, 1.7472, 1.7460, 1.7541, 1.7718, 1.7704, 1.7504, 1.7719, 1.7719,
         1.4746, 1.4800, 1.5166, 1.5114, 1.4801, 1.5152, 1.5035, 1.5166, 1.5135,
         2.2000, 2.1799, 2.1685, 2.1864, 2.2302, 2.2480, 2.2144, 2.3178, 2.3147,
         1.4412, 1.4317, 1.4461, 1.4565, 1.4436, 1.4532, 1.4238, 1.4504, 1.4565],
        [1.3607, 1.2684, 1.2640, 1.2830, 1.2762, 1.2864, 1.2852, 1.2249, 1.2249,
         1.2621, 1.2194, 1.2140, 1.2231, 1.3113, 1.1755, 1.1296, 1.3113, 1.2037,
         1.6110, 1.5875, 1.5692, 1.5644, 1.5876, 1.5838, 1.6038, 1.5891, 1.5891,
         1.3588, 1.3320, 1.3321, 1.3488, 1.3339, 1.3763, 1.3786, 1.3528, 1.3322,
         1.5873, 1.5868, 1.5924, 1.5821, 1.5583, 1.5620, 1.6227, 1.5122, 1.4814,
         4.0659, 3.6072, 3.6955, 3.6801, 3.6937, 3.3769, 4.0618, 3.6551, 3.4086]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 263 : 1779.4168835739176
Test loss for epoch 263 : 194.8290252365472
Test Precision for epoch 263 : 0.26153846153846155
Test Recall for epoch 263 : 0.26153846153846155
Test F1 for epoch 263 : 0.26153846153846155


theta for epoch 264 : tensor([[3.6177, 3.6392, 3.7831, 3.7304, 3.7149, 3.5992, 3.6403, 3.5397, 3.5397,
         1.2612, 1.2411, 1.2372, 1.2428, 1.2837, 1.2236, 1.1915, 1.2837, 1.2283,
         1.5942, 1.5786, 1.6027, 1.5852, 1.5909, 1.5926, 1.6000, 1.5925, 1.5925,
         1.3486, 1.3599, 1.3458, 1.3675, 1.3480, 1.3788, 1.3717, 1.3587, 1.3458,
         1.5917, 1.6076, 1.5966, 1.5930, 1.5998, 1.5899, 1.6083, 1.5622, 1.5669,
         1.2500, 1.2746, 1.2678, 1.2843, 1.2450, 1.2371, 1.2264, 1.3075, 1.2647],
        [1.3727, 1.2222, 1.2119, 1.2548, 1.2550, 1.2674, 1.2613, 1.1669, 1.1669,
         3.6059, 3.6900, 3.5380, 3.9157, 3.6060, 4.2353, 3.4751, 3.5619, 4.0171,
         1.5668, 1.5545, 1.5288, 1.5269, 1.5479, 1.5574, 1.5821, 1.5574, 1.5574,
         1.3490, 1.3155, 1.3093, 1.3672, 1.3092, 1.4045, 1.3848, 1.3535, 1.3061,
         1.5372, 1.5935, 1.5569, 1.5438, 1.5388, 1.5766, 1.5962, 1.4300, 1.5281,
         1.1504, 1.2614, 1.2361, 1.2843, 1.1448, 1.1512, 1.0775, 1.3511, 1.2266],
        [1.4535, 1.4534, 1.4518, 1.4490, 1.4494, 1.4535, 1.4491, 1.4535, 1.4535,
         1.4319, 1.4312, 1.4319, 1.4319, 1.4319, 1.4131, 1.4319, 1.4307, 1.4285,
         2.1992, 2.1995, 2.2163, 2.1920, 2.1734, 2.1716, 2.2009, 2.1707, 2.1707,
         1.5189, 1.5173, 1.5248, 1.5247, 1.5189, 1.5247, 1.5247, 1.5248, 1.5248,
         1.7709, 1.7710, 1.7710, 1.7678, 1.7709, 1.7709, 1.7710, 1.7483, 1.7510,
         1.4444, 1.4490, 1.4490, 1.4490, 1.4407, 1.4490, 1.4450, 1.4490, 1.4490],
        [1.3192, 1.3177, 1.3019, 1.2930, 1.3166, 1.3150, 1.3161, 1.3169, 1.3169,
         1.2979, 1.2912, 1.2872, 1.2869, 1.2988, 1.2831, 1.2942, 1.2984, 1.2706,
         1.6411, 1.6147, 1.6380, 1.6374, 1.6368, 1.6369, 1.6391, 1.6406, 1.6406,
         3.4964, 3.2862, 3.2115, 3.2698, 3.4212, 3.2384, 3.4711, 3.2194, 3.1981,
         1.6443, 1.6369, 1.6352, 1.6383, 1.6413, 1.6172, 1.6427, 1.5820, 1.6085,
         1.3132, 1.3076, 1.2978, 1.3125, 1.3082, 1.3004, 1.3126, 1.3128, 1.3147],
        [1.4563, 1.4522, 1.4089, 1.4120, 1.4496, 1.4562, 1.4547, 1.4563, 1.4563,
         1.4336, 1.4310, 1.4260, 1.4212, 1.4348, 1.3942, 1.4288, 1.4347, 1.4299,
         1.7541, 1.7454, 1.7442, 1.7523, 1.7699, 1.7685, 1.7486, 1.7701, 1.7701,
         1.4855, 1.4910, 1.5275, 1.5223, 1.4910, 1.5261, 1.5144, 1.5275, 1.5244,
         2.1973, 2.1772, 2.1658, 2.1837, 2.2275, 2.2453, 2.2117, 2.3151, 2.3120,
         1.4365, 1.4271, 1.4414, 1.4518, 1.4390, 1.4485, 1.4191, 1.4457, 1.4518],
        [1.3668, 1.2742, 1.2699, 1.2889, 1.2820, 1.2923, 1.2911, 1.2306, 1.2306,
         1.2639, 1.2212, 1.2160, 1.2249, 1.3129, 1.1775, 1.1317, 1.3129, 1.2052,
         1.6114, 1.5878, 1.5695, 1.5647, 1.5879, 1.5841, 1.6041, 1.5894, 1.5894,
         1.3710, 1.3441, 1.3442, 1.3610, 1.3460, 1.3886, 1.3909, 1.3650, 1.3443,
         1.5863, 1.5859, 1.5915, 1.5811, 1.5574, 1.5612, 1.6218, 1.5114, 1.4806,
         4.0601, 3.6007, 3.6891, 3.6737, 3.6873, 3.3703, 4.0560, 3.6486, 3.4020]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 264 : 1779.9943476053757
Test loss for epoch 264 : 194.49054373008985
Test Precision for epoch 264 : 0.26153846153846155
Test Recall for epoch 264 : 0.26153846153846155
Test F1 for epoch 264 : 0.26153846153846155


theta for epoch 265 : tensor([[3.6185, 3.6400, 3.7839, 3.7313, 3.7157, 3.6001, 3.6412, 3.5405, 3.5405,
         1.2637, 1.2434, 1.2397, 1.2452, 1.2861, 1.2259, 1.1937, 1.2861, 1.2304,
         1.5978, 1.5822, 1.6063, 1.5888, 1.5945, 1.5962, 1.6036, 1.5961, 1.5961,
         1.3376, 1.3489, 1.3350, 1.3565, 1.3371, 1.3678, 1.3607, 1.3478, 1.3350,
         1.5929, 1.6088, 1.5977, 1.5942, 1.6010, 1.5911, 1.6095, 1.5634, 1.5681,
         1.2493, 1.2738, 1.2671, 1.2835, 1.2443, 1.2364, 1.2257, 1.3067, 1.2640],
        [1.3694, 1.2187, 1.2084, 1.2513, 1.2516, 1.2639, 1.2578, 1.1634, 1.1634,
         3.6091, 3.6934, 3.5412, 3.9194, 3.6092, 4.2399, 3.4783, 3.5651, 4.0212,
         1.5674, 1.5550, 1.5294, 1.5274, 1.5485, 1.5580, 1.5827, 1.5580, 1.5580,
         1.3407, 1.3073, 1.3011, 1.3589, 1.3010, 1.3963, 1.3765, 1.3452, 1.2979,
         1.5363, 1.5927, 1.5561, 1.5429, 1.5379, 1.5758, 1.5955, 1.4289, 1.5272,
         1.1480, 1.2588, 1.2337, 1.2819, 1.1423, 1.1487, 1.0749, 1.3487, 1.2242],
        [1.4515, 1.4514, 1.4498, 1.4470, 1.4474, 1.4515, 1.4471, 1.4515, 1.4515,
         1.4347, 1.4340, 1.4347, 1.4346, 1.4347, 1.4159, 1.4347, 1.4335, 1.4313,
         2.2028, 2.2031, 2.2199, 2.1955, 2.1769, 2.1751, 2.2044, 2.1742, 2.1742,
         1.5083, 1.5067, 1.5142, 1.5142, 1.5084, 1.5142, 1.5142, 1.5142, 1.5142,
         1.7724, 1.7725, 1.7725, 1.7693, 1.7724, 1.7724, 1.7725, 1.7498, 1.7525,
         1.4440, 1.4486, 1.4486, 1.4486, 1.4403, 1.4486, 1.4447, 1.4486, 1.4486],
        [1.3171, 1.3156, 1.2997, 1.2909, 1.3145, 1.3128, 1.3140, 1.3147, 1.3147,
         1.3006, 1.2939, 1.2900, 1.2896, 1.3015, 1.2858, 1.2970, 1.3011, 1.2733,
         1.6448, 1.6185, 1.6418, 1.6412, 1.6406, 1.6407, 1.6429, 1.6443, 1.6443,
         3.4873, 3.2770, 3.2023, 3.2606, 3.4120, 3.2292, 3.4620, 3.2102, 3.1888,
         1.6457, 1.6383, 1.6366, 1.6397, 1.6427, 1.6187, 1.6441, 1.5834, 1.6099,
         1.3127, 1.3071, 1.2973, 1.3120, 1.3077, 1.2998, 1.3121, 1.3122, 1.3142],
        [1.4543, 1.4502, 1.4069, 1.4100, 1.4476, 1.4542, 1.4527, 1.4543, 1.4543,
         1.4364, 1.4338, 1.4288, 1.4240, 1.4376, 1.3970, 1.4316, 1.4375, 1.4327,
         1.7580, 1.7493, 1.7480, 1.7561, 1.7738, 1.7724, 1.7525, 1.7739, 1.7739,
         1.4749, 1.4804, 1.5169, 1.5117, 1.4804, 1.5155, 1.5038, 1.5170, 1.5139,
         2.1987, 2.1786, 2.1672, 2.1851, 2.2289, 2.2467, 2.2131, 2.3165, 2.3134,
         1.4362, 1.4267, 1.4410, 1.4514, 1.4386, 1.4481, 1.4188, 1.4453, 1.4514],
        [1.3659, 1.2733, 1.2689, 1.2880, 1.2811, 1.2914, 1.2902, 1.2296, 1.2296,
         1.2663, 1.2234, 1.2185, 1.2271, 1.3151, 1.1798, 1.1338, 1.3152, 1.2070,
         1.6146, 1.5910, 1.5727, 1.5679, 1.5911, 1.5874, 1.6073, 1.5926, 1.5926,
         1.3622, 1.3354, 1.3354, 1.3522, 1.3373, 1.3798, 1.3820, 1.3562, 1.3355,
         1.5875, 1.5871, 1.5926, 1.5823, 1.5585, 1.5623, 1.6229, 1.5124, 1.4817,
         4.0604, 3.6005, 3.6889, 3.6735, 3.6871, 3.3700, 4.0564, 3.6484, 3.4018]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 265 : 1779.4548725735829
Test loss for epoch 265 : 194.76552867642405
Test Precision for epoch 265 : 0.26153846153846155
Test Recall for epoch 265 : 0.26153846153846155
Test F1 for epoch 265 : 0.26153846153846155


theta for epoch 266 : tensor([[3.6201, 3.6416, 3.7854, 3.7328, 3.7173, 3.6016, 3.6428, 3.5421, 3.5421,
         1.2634, 1.2428, 1.2393, 1.2446, 1.2859, 1.2252, 1.1925, 1.2859, 1.2296,
         1.6000, 1.5844, 1.6085, 1.5910, 1.5967, 1.5984, 1.6057, 1.5983, 1.5983,
         1.3279, 1.3392, 1.3253, 1.3468, 1.3273, 1.3580, 1.3509, 1.3381, 1.3253,
         1.5949, 1.6108, 1.5998, 1.5962, 1.6031, 1.5931, 1.6115, 1.5654, 1.5701,
         1.2510, 1.2755, 1.2688, 1.2853, 1.2461, 1.2382, 1.2275, 1.3084, 1.2658],
        [1.3603, 1.2090, 1.1987, 1.2417, 1.2419, 1.2543, 1.2482, 1.1534, 1.1534,
         3.6168, 3.7012, 3.5488, 3.9277, 3.6168, 4.2490, 3.4858, 3.5727, 4.0296,
         1.5636, 1.5512, 1.5254, 1.5234, 1.5445, 1.5540, 1.5790, 1.5540, 1.5540,
         1.3296, 1.2961, 1.2897, 1.3478, 1.2898, 1.3852, 1.3654, 1.3340, 1.2866,
         1.5328, 1.5895, 1.5527, 1.5394, 1.5345, 1.5726, 1.5923, 1.4251, 1.5237,
         1.1436, 1.2548, 1.2297, 1.2780, 1.1378, 1.1442, 1.0702, 1.3451, 1.2201],
        [1.4467, 1.4466, 1.4450, 1.4422, 1.4426, 1.4467, 1.4423, 1.4467, 1.4467,
         1.4352, 1.4345, 1.4351, 1.4351, 1.4352, 1.4164, 1.4351, 1.4340, 1.4318,
         2.2055, 2.2058, 2.2226, 2.1981, 2.1796, 2.1778, 2.2070, 2.1769, 2.1769,
         1.4996, 1.4980, 1.5055, 1.5055, 1.4997, 1.5055, 1.5055, 1.5055, 1.5055,
         1.7751, 1.7752, 1.7752, 1.7720, 1.7751, 1.7751, 1.7752, 1.7525, 1.7552,
         1.4465, 1.4511, 1.4511, 1.4511, 1.4428, 1.4511, 1.4471, 1.4510, 1.4511],
        [1.3122, 1.3107, 1.2948, 1.2860, 1.3096, 1.3079, 1.3091, 1.3098, 1.3098,
         1.3010, 1.2943, 1.2904, 1.2900, 1.3019, 1.2862, 1.2973, 1.3015, 1.2736,
         1.6477, 1.6213, 1.6446, 1.6441, 1.6435, 1.6435, 1.6457, 1.6472, 1.6472,
         3.4799, 3.2695, 3.1947, 3.2531, 3.4046, 3.2217, 3.4546, 3.2026, 3.1813,
         1.6484, 1.6409, 1.6393, 1.6424, 1.6453, 1.6213, 1.6467, 1.5861, 1.6126,
         1.3151, 1.3094, 1.2996, 1.3143, 1.3100, 1.3022, 1.3144, 1.3146, 1.3165],
        [1.4496, 1.4454, 1.4021, 1.4052, 1.4429, 1.4494, 1.4480, 1.4495, 1.4495,
         1.4369, 1.4343, 1.4292, 1.4245, 1.4380, 1.3974, 1.4321, 1.4380, 1.4331,
         1.7609, 1.7522, 1.7510, 1.7591, 1.7767, 1.7753, 1.7554, 1.7768, 1.7768,
         1.4662, 1.4718, 1.5082, 1.5030, 1.4717, 1.5068, 1.4951, 1.5083, 1.5052,
         2.2013, 2.1812, 2.1698, 2.1877, 2.2315, 2.2493, 2.2157, 2.3191, 2.3160,
         1.4386, 1.4292, 1.4435, 1.4539, 1.4411, 1.4506, 1.4213, 1.4478, 1.4539],
        [1.3587, 1.2665, 1.2620, 1.2811, 1.2742, 1.2845, 1.2833, 1.2231, 1.2231,
         1.2646, 1.2215, 1.2168, 1.2252, 1.3134, 1.1778, 1.1314, 1.3134, 1.2046,
         1.6147, 1.5912, 1.5728, 1.5682, 1.5914, 1.5876, 1.6075, 1.5929, 1.5929,
         1.3520, 1.3252, 1.3254, 1.3420, 1.3271, 1.3696, 1.3718, 1.3460, 1.3254,
         1.5880, 1.5875, 1.5932, 1.5828, 1.5590, 1.5627, 1.6233, 1.5128, 1.4820,
         4.0661, 3.6057, 3.6941, 3.6787, 3.6924, 3.3751, 4.0622, 3.6535, 3.4069]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 266 : 1779.3937915355696
Test loss for epoch 266 : 195.3078197421853
Test Precision for epoch 266 : 0.26153846153846155
Test Recall for epoch 266 : 0.26153846153846155
Test F1 for epoch 266 : 0.26153846153846155


theta for epoch 267 : tensor([[3.6201, 3.6416, 3.7854, 3.7328, 3.7173, 3.6017, 3.6428, 3.5422, 3.5422,
         1.2587, 1.2382, 1.2350, 1.2400, 1.2809, 1.2206, 1.1884, 1.2809, 1.2249,
         1.5986, 1.5829, 1.6071, 1.5896, 1.5953, 1.5969, 1.6043, 1.5969, 1.5969,
         1.3350, 1.3463, 1.3325, 1.3539, 1.3345, 1.3651, 1.3580, 1.3452, 1.3325,
         1.5961, 1.6120, 1.6009, 1.5974, 1.6042, 1.5943, 1.6127, 1.5666, 1.5713,
         1.2522, 1.2766, 1.2699, 1.2864, 1.2472, 1.2393, 1.2286, 1.3093, 1.2669],
        [1.3752, 1.2236, 1.2134, 1.2563, 1.2566, 1.2689, 1.2628, 1.1677, 1.1677,
         3.6013, 3.6858, 3.5332, 3.9127, 3.6012, 4.2348, 3.4701, 3.5571, 4.0149,
         1.5721, 1.5597, 1.5341, 1.5320, 1.5530, 1.5624, 1.5874, 1.5625, 1.5625,
         1.3442, 1.3108, 1.3043, 1.3624, 1.3044, 1.3999, 1.3801, 1.3486, 1.3011,
         1.5426, 1.5992, 1.5624, 1.5492, 1.5443, 1.5823, 1.6020, 1.4354, 1.5336,
         1.1546, 1.2657, 1.2407, 1.2890, 1.1488, 1.1551, 1.0814, 1.3557, 1.2310],
        [1.4501, 1.4500, 1.4484, 1.4456, 1.4460, 1.4501, 1.4457, 1.4501, 1.4501,
         1.4303, 1.4296, 1.4303, 1.4302, 1.4303, 1.4115, 1.4303, 1.4291, 1.4269,
         2.2038, 2.2041, 2.2209, 2.1965, 2.1779, 2.1761, 2.2053, 2.1752, 2.1752,
         1.5061, 1.5045, 1.5120, 1.5120, 1.5061, 1.5120, 1.5119, 1.5120, 1.5120,
         1.7760, 1.7761, 1.7761, 1.7729, 1.7760, 1.7760, 1.7761, 1.7534, 1.7561,
         1.4470, 1.4516, 1.4516, 1.4516, 1.4433, 1.4516, 1.4476, 1.4515, 1.4516],
        [1.3157, 1.3142, 1.2983, 1.2895, 1.3131, 1.3114, 1.3126, 1.3133, 1.3133,
         1.2960, 1.2893, 1.2854, 1.2850, 1.2969, 1.2813, 1.2924, 1.2965, 1.2687,
         1.6457, 1.6194, 1.6427, 1.6422, 1.6415, 1.6416, 1.6438, 1.6453, 1.6453,
         3.4856, 3.2753, 3.2006, 3.2589, 3.4103, 3.2275, 3.4603, 3.2084, 3.1871,
         1.6492, 1.6417, 1.6401, 1.6432, 1.6461, 1.6221, 1.6475, 1.5869, 1.6134,
         1.3154, 1.3098, 1.3000, 1.3146, 1.3104, 1.3026, 1.3148, 1.3149, 1.3169],
        [1.4529, 1.4488, 1.4055, 1.4086, 1.4463, 1.4528, 1.4513, 1.4529, 1.4529,
         1.4320, 1.4294, 1.4244, 1.4196, 1.4331, 1.3926, 1.4272, 1.4331, 1.4283,
         1.7592, 1.7504, 1.7492, 1.7573, 1.7749, 1.7736, 1.7536, 1.7751, 1.7751,
         1.4727, 1.4783, 1.5147, 1.5095, 1.4782, 1.5133, 1.5015, 1.5148, 1.5116,
         2.2021, 2.1820, 2.1706, 2.1885, 2.2323, 2.2501, 2.2165, 2.3199, 2.3168,
         1.4392, 1.4297, 1.4440, 1.4544, 1.4416, 1.4511, 1.4218, 1.4483, 1.4544],
        [1.3578, 1.2664, 1.2618, 1.2809, 1.2740, 1.2843, 1.2831, 1.2236, 1.2236,
         1.2584, 1.2157, 1.2114, 1.2193, 1.3064, 1.1722, 1.1269, 1.3064, 1.1987,
         1.6112, 1.5876, 1.5692, 1.5647, 1.5880, 1.5842, 1.6039, 1.5895, 1.5895,
         1.3550, 1.3282, 1.3287, 1.3450, 1.3302, 1.3723, 1.3747, 1.3491, 1.3287,
         1.5874, 1.5867, 1.5925, 1.5821, 1.5582, 1.5619, 1.6225, 1.5121, 1.4812,
         4.0698, 3.6089, 3.6973, 3.6819, 3.6956, 3.3783, 4.0659, 3.6567, 3.4100]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 267 : 1779.692200045926
Test loss for epoch 267 : 194.61261630297392
Test Precision for epoch 267 : 0.26153846153846155
Test Recall for epoch 267 : 0.26153846153846155
Test F1 for epoch 267 : 0.26153846153846155


theta for epoch 268 : tensor([[3.6217, 3.6431, 3.7869, 3.7344, 3.7188, 3.6032, 3.6443, 3.5438, 3.5438,
         1.2584, 1.2378, 1.2348, 1.2396, 1.2803, 1.2201, 1.1879, 1.2803, 1.2243,
         1.5949, 1.5793, 1.6034, 1.5859, 1.5917, 1.5933, 1.6007, 1.5933, 1.5933,
         1.3457, 1.3570, 1.3433, 1.3646, 1.3452, 1.3758, 1.3687, 1.3560, 1.3433,
         1.5940, 1.6099, 1.5989, 1.5953, 1.6022, 1.5922, 1.6106, 1.5645, 1.5692,
         1.2483, 1.2728, 1.2661, 1.2826, 1.2433, 1.2354, 1.2247, 1.3054, 1.2630],
        [1.3830, 1.2309, 1.2208, 1.2637, 1.2640, 1.2763, 1.2702, 1.1747, 1.1747,
         3.5942, 3.6788, 3.5260, 3.9061, 3.5941, 4.2291, 3.4629, 3.5499, 4.0085,
         1.5741, 1.5617, 1.5363, 1.5340, 1.5549, 1.5643, 1.5893, 1.5644, 1.5644,
         1.3557, 1.3222, 1.3155, 1.3739, 1.3157, 1.4116, 1.3917, 1.3601, 1.3123,
         1.5452, 1.6018, 1.5650, 1.5518, 1.5470, 1.5849, 1.6046, 1.4383, 1.5363,
         1.1571, 1.2681, 1.2431, 1.2915, 1.1512, 1.1574, 1.0838, 1.3580, 1.2334],
        [1.4525, 1.4525, 1.4508, 1.4480, 1.4484, 1.4525, 1.4482, 1.4525, 1.4525,
         1.4301, 1.4294, 1.4301, 1.4300, 1.4301, 1.4113, 1.4301, 1.4289, 1.4267,
         2.2004, 2.2007, 2.2175, 2.1932, 2.1746, 2.1728, 2.2021, 2.1719, 2.1719,
         1.5168, 1.5152, 1.5226, 1.5226, 1.5168, 1.5226, 1.5226, 1.5226, 1.5226,
         1.7740, 1.7741, 1.7741, 1.7709, 1.7740, 1.7740, 1.7741, 1.7514, 1.7541,
         1.4430, 1.4476, 1.4476, 1.4476, 1.4393, 1.4476, 1.4436, 1.4475, 1.4476],
        [1.3183, 1.3168, 1.3009, 1.2921, 1.3157, 1.3140, 1.3152, 1.3159, 1.3159,
         1.2958, 1.2890, 1.2851, 1.2848, 1.2966, 1.2810, 1.2921, 1.2962, 1.2684,
         1.6420, 1.6157, 1.6390, 1.6385, 1.6378, 1.6379, 1.6401, 1.6416, 1.6416,
         3.4949, 3.2847, 3.2101, 3.2684, 3.4197, 3.2370, 3.4697, 3.2180, 3.1967,
         1.6471, 1.6397, 1.6380, 1.6411, 1.6441, 1.6201, 1.6455, 1.5848, 1.6113,
         1.3113, 1.3057, 1.2959, 1.3105, 1.3063, 1.2985, 1.3107, 1.3108, 1.3128],
        [1.4554, 1.4512, 1.4079, 1.4110, 1.4487, 1.4553, 1.4538, 1.4554, 1.4554,
         1.4318, 1.4292, 1.4242, 1.4194, 1.4329, 1.3924, 1.4270, 1.4329, 1.4281,
         1.7556, 1.7469, 1.7457, 1.7538, 1.7714, 1.7700, 1.7501, 1.7716, 1.7716,
         1.4834, 1.4890, 1.5254, 1.5202, 1.4889, 1.5239, 1.5122, 1.5254, 1.5223,
         2.2001, 2.1800, 2.1687, 2.1866, 2.2303, 2.2482, 2.2145, 2.3179, 2.3149,
         1.4352, 1.4257, 1.4400, 1.4504, 1.4376, 1.4471, 1.4178, 1.4443, 1.4504],
        [1.3531, 1.2624, 1.2577, 1.2767, 1.2698, 1.2801, 1.2789, 1.2200, 1.2200,
         1.2550, 1.2125, 1.2086, 1.2161, 1.3025, 1.1689, 1.1243, 1.3025, 1.1952,
         1.6042, 1.5806, 1.5621, 1.5579, 1.5812, 1.5774, 1.5970, 1.5827, 1.5827,
         1.3591, 1.3322, 1.3330, 1.3490, 1.3343, 1.3763, 1.3787, 1.3532, 1.3331,
         1.5825, 1.5816, 1.5876, 1.5772, 1.5532, 1.5568, 1.6174, 1.5070, 1.4760,
         4.0754, 3.6139, 3.7023, 3.6869, 3.7006, 3.3833, 4.0715, 3.6616, 3.4150]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 268 : 1780.1365625538194
Test loss for epoch 268 : 194.39033964581424
Test Precision for epoch 268 : 0.26153846153846155
Test Recall for epoch 268 : 0.26153846153846155
Test F1 for epoch 268 : 0.26153846153846155


theta for epoch 269 : tensor([[3.6224, 3.6438, 3.7876, 3.7351, 3.7194, 3.6039, 3.6450, 3.5445, 3.5445,
         1.2646, 1.2438, 1.2411, 1.2456, 1.2863, 1.2260, 1.1936, 1.2864, 1.2301,
         1.5954, 1.5797, 1.6039, 1.5864, 1.5921, 1.5937, 1.6011, 1.5937, 1.5937,
         1.3398, 1.3512, 1.3374, 1.3587, 1.3394, 1.3699, 1.3628, 1.3501, 1.3374,
         1.5925, 1.6085, 1.5974, 1.5938, 1.6007, 1.5908, 1.6092, 1.5630, 1.5677,
         1.2440, 1.2687, 1.2619, 1.2785, 1.2390, 1.2310, 1.2203, 1.3013, 1.2588],
        [1.3825, 1.2299, 1.2198, 1.2627, 1.2630, 1.2754, 1.2693, 1.1734, 1.1734,
         3.5956, 3.6803, 3.5273, 3.9080, 3.5955, 4.2318, 3.4641, 3.5513, 4.0107,
         1.5745, 1.5621, 1.5367, 1.5342, 1.5552, 1.5646, 1.5897, 1.5647, 1.5647,
         1.3527, 1.3192, 1.3123, 1.3709, 1.3127, 1.4086, 1.3887, 1.3570, 1.3092,
         1.5441, 1.6007, 1.5638, 1.5507, 1.5458, 1.5838, 1.6036, 1.4372, 1.5351,
         1.1543, 1.2656, 1.2405, 1.2891, 1.1484, 1.1544, 1.0810, 1.3555, 1.2308],
        [1.4507, 1.4507, 1.4491, 1.4463, 1.4466, 1.4507, 1.4464, 1.4507, 1.4507,
         1.4366, 1.4359, 1.4366, 1.4365, 1.4366, 1.4178, 1.4366, 1.4354, 1.4332,
         2.2011, 2.2015, 2.2183, 2.1939, 2.1753, 2.1735, 2.2028, 2.1726, 2.1726,
         1.5113, 1.5097, 1.5172, 1.5172, 1.5114, 1.5172, 1.5171, 1.5172, 1.5172,
         1.7729, 1.7730, 1.7730, 1.7698, 1.7729, 1.7729, 1.7730, 1.7503, 1.7530,
         1.4391, 1.4437, 1.4437, 1.4437, 1.4354, 1.4437, 1.4398, 1.4437, 1.4437],
        [1.3167, 1.3152, 1.2993, 1.2905, 1.3141, 1.3124, 1.3136, 1.3143, 1.3143,
         1.3022, 1.2955, 1.2916, 1.2912, 1.3031, 1.2875, 1.2986, 1.3027, 1.2749,
         1.6428, 1.6165, 1.6398, 1.6392, 1.6386, 1.6386, 1.6409, 1.6423, 1.6423,
         3.4901, 3.2798, 3.2052, 3.2635, 3.4148, 3.2321, 3.4648, 3.2130, 3.1917,
         1.6460, 1.6385, 1.6369, 1.6400, 1.6429, 1.6189, 1.6443, 1.5837, 1.6102,
         1.3073, 1.3017, 1.2919, 1.3065, 1.3023, 1.2945, 1.3068, 1.3068, 1.3088],
        [1.4536, 1.4494, 1.4061, 1.4093, 1.4469, 1.4535, 1.4520, 1.4536, 1.4536,
         1.4383, 1.4357, 1.4307, 1.4259, 1.4394, 1.3989, 1.4335, 1.4394, 1.4346,
         1.7565, 1.7477, 1.7465, 1.7546, 1.7722, 1.7709, 1.7510, 1.7724, 1.7724,
         1.4780, 1.4836, 1.5199, 1.5147, 1.4835, 1.5185, 1.5068, 1.5200, 1.5168,
         2.1990, 2.1789, 2.1676, 2.1855, 2.2292, 2.2471, 2.2134, 2.3169, 2.3138,
         1.4313, 1.4218, 1.4361, 1.4465, 1.4337, 1.4433, 1.4139, 1.4404, 1.4466],
        [1.3429, 1.2525, 1.2477, 1.2668, 1.2598, 1.2702, 1.2690, 1.2103, 1.2103,
         1.2568, 1.2142, 1.2106, 1.2177, 1.3039, 1.1703, 1.1258, 1.3039, 1.1966,
         1.5997, 1.5761, 1.5575, 1.5534, 1.5768, 1.5730, 1.5925, 1.5783, 1.5783,
         1.3479, 1.3210, 1.3220, 1.3378, 1.3232, 1.3650, 1.3675, 1.3421, 1.3221,
         1.5771, 1.5760, 1.5822, 1.5718, 1.5477, 1.5512, 1.6120, 1.5014, 1.4703,
         4.0840, 3.6220, 3.7105, 3.6950, 3.7088, 3.3913, 4.0802, 3.6697, 3.4230]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 269 : 1779.6044983319243
Test loss for epoch 269 : 194.7050323808255
Test Precision for epoch 269 : 0.26153846153846155
Test Recall for epoch 269 : 0.26153846153846155
Test F1 for epoch 269 : 0.26153846153846155


theta for epoch 270 : tensor([[3.6242, 3.6457, 3.7894, 3.7370, 3.7213, 3.6058, 3.6469, 3.5464, 3.5464,
         1.2703, 1.2492, 1.2468, 1.2512, 1.2920, 1.2313, 1.1985, 1.2920, 1.2354,
         1.5977, 1.5820, 1.6062, 1.5886, 1.5943, 1.5960, 1.6034, 1.5959, 1.5959,
         1.3302, 1.3416, 1.3277, 1.3492, 1.3297, 1.3604, 1.3533, 1.3405, 1.3277,
         1.5919, 1.6080, 1.5968, 1.5932, 1.6001, 1.5902, 1.6087, 1.5624, 1.5671,
         1.2394, 1.2644, 1.2575, 1.2743, 1.2344, 1.2263, 1.2156, 1.2972, 1.2544],
        [1.3757, 1.2228, 1.2127, 1.2557, 1.2560, 1.2683, 1.2623, 1.1662, 1.1662,
         3.6028, 3.6876, 3.5345, 3.9158, 3.6027, 4.2403, 3.4712, 3.5584, 4.0187,
         1.5721, 1.5596, 1.5341, 1.5317, 1.5527, 1.5621, 1.5873, 1.5621, 1.5621,
         1.3430, 1.3095, 1.3026, 1.3612, 1.3030, 1.3990, 1.3790, 1.3473, 1.2995,
         1.5398, 1.5966, 1.5596, 1.5464, 1.5416, 1.5796, 1.5995, 1.4327, 1.5308,
         1.1470, 1.2587, 1.2334, 1.2822, 1.1409, 1.1469, 1.0734, 1.3486, 1.2236],
        [1.4481, 1.4481, 1.4464, 1.4436, 1.4440, 1.4481, 1.4438, 1.4481, 1.4481,
         1.4429, 1.4422, 1.4428, 1.4428, 1.4429, 1.4241, 1.4429, 1.4417, 1.4395,
         2.2039, 2.2042, 2.2210, 2.1965, 2.1779, 2.1762, 2.2054, 2.1752, 2.1752,
         1.5026, 1.5010, 1.5084, 1.5084, 1.5026, 1.5084, 1.5084, 1.5084, 1.5084,
         1.7730, 1.7731, 1.7731, 1.7699, 1.7730, 1.7730, 1.7731, 1.7503, 1.7531,
         1.4356, 1.4402, 1.4402, 1.4402, 1.4319, 1.4402, 1.4363, 1.4402, 1.4402],
        [1.3144, 1.3127, 1.2969, 1.2881, 1.3116, 1.3100, 1.3111, 1.3118, 1.3118,
         1.3085, 1.3017, 1.2979, 1.2975, 1.3093, 1.2937, 1.3048, 1.3089, 1.2811,
         1.6457, 1.6194, 1.6426, 1.6421, 1.6415, 1.6415, 1.6437, 1.6452, 1.6452,
         3.4823, 3.2720, 3.1974, 3.2557, 3.4070, 3.2243, 3.4571, 3.2052, 3.1839,
         1.6460, 1.6385, 1.6369, 1.6400, 1.6429, 1.6189, 1.6443, 1.5837, 1.6102,
         1.3037, 1.2981, 1.2883, 1.3029, 1.2987, 1.2909, 1.3031, 1.3032, 1.3052],
        [1.4510, 1.4468, 1.4034, 1.4066, 1.4443, 1.4509, 1.4494, 1.4510, 1.4510,
         1.4446, 1.4420, 1.4369, 1.4322, 1.4457, 1.4052, 1.4398, 1.4457, 1.4409,
         1.7594, 1.7506, 1.7494, 1.7575, 1.7751, 1.7737, 1.7539, 1.7753, 1.7753,
         1.4692, 1.4749, 1.5112, 1.5060, 1.4747, 1.5098, 1.4980, 1.5112, 1.5081,
         2.1990, 2.1789, 2.1676, 2.1855, 2.2292, 2.2471, 2.2134, 2.3169, 2.3138,
         1.4278, 1.4183, 1.4326, 1.4430, 1.4302, 1.4398, 1.4104, 1.4369, 1.4430],
        [1.3305, 1.2399, 1.2350, 1.2542, 1.2472, 1.2576, 1.2564, 1.1976, 1.1976,
         1.2575, 1.2144, 1.2112, 1.2181, 1.3043, 1.1702, 1.1255, 1.3043, 1.1965,
         1.5959, 1.5722, 1.5535, 1.5495, 1.5730, 1.5691, 1.5887, 1.5745, 1.5745,
         1.3326, 1.3057, 1.3067, 1.3224, 1.3079, 1.3497, 1.3523, 1.3268, 1.3067,
         1.5716, 1.5705, 1.5768, 1.5663, 1.5421, 1.5456, 1.6065, 1.4956, 1.4644,
         4.0954, 3.6327, 3.7213, 3.7058, 3.7196, 3.4021, 4.0915, 3.6804, 3.4338]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 270 : 1779.4922241763518
Test loss for epoch 270 : 195.3348522037071
Test Precision for epoch 270 : 0.26153846153846155
Test Recall for epoch 270 : 0.26153846153846155
Test F1 for epoch 270 : 0.26153846153846155


theta for epoch 271 : tensor([[3.6321, 3.6537, 3.7974, 3.7449, 3.7293, 3.6139, 3.6549, 3.5546, 3.5546,
         1.2659, 1.2445, 1.2423, 1.2465, 1.2875, 1.2264, 1.1933, 1.2875, 1.2305,
         1.5981, 1.5824, 1.6067, 1.5890, 1.5947, 1.5964, 1.6038, 1.5963, 1.5963,
         1.3327, 1.3441, 1.3302, 1.3517, 1.3322, 1.3630, 1.3558, 1.3430, 1.3302,
         1.5923, 1.6084, 1.5971, 1.5936, 1.6005, 1.5906, 1.6091, 1.5628, 1.5675,
         1.2353, 1.2606, 1.2535, 1.2705, 1.2301, 1.2219, 1.2113, 1.2936, 1.2503],
        [1.3673, 1.2140, 1.2039, 1.2470, 1.2473, 1.2597, 1.2536, 1.1572, 1.1572,
         3.6124, 3.6973, 3.5440, 3.9259, 3.6123, 4.2513, 3.4807, 3.5680, 4.0291,
         1.5647, 1.5522, 1.5266, 1.5242, 1.5453, 1.5548, 1.5800, 1.5548, 1.5548,
         1.3364, 1.3028, 1.2959, 1.3547, 1.2963, 1.3926, 1.3726, 1.3408, 1.2928,
         1.5329, 1.5900, 1.5528, 1.5396, 1.5347, 1.5729, 1.5928, 1.4254, 1.5239,
         1.1358, 1.2483, 1.2226, 1.2719, 1.1297, 1.1355, 1.0619, 1.3384, 1.2128],
        [1.4526, 1.4525, 1.4509, 1.4481, 1.4485, 1.4526, 1.4483, 1.4526, 1.4526,
         1.4392, 1.4385, 1.4392, 1.4392, 1.4392, 1.4205, 1.4392, 1.4380, 1.4358,
         2.2052, 2.2055, 2.2223, 2.1978, 2.1792, 2.1774, 2.2066, 2.1765, 2.1765,
         1.5065, 1.5049, 1.5123, 1.5123, 1.5065, 1.5123, 1.5123, 1.5123, 1.5123,
         1.7742, 1.7743, 1.7743, 1.7711, 1.7742, 1.7742, 1.7743, 1.7516, 1.7543,
         1.4330, 1.4376, 1.4376, 1.4376, 1.4293, 1.4376, 1.4337, 1.4376, 1.4376],
        [1.3191, 1.3174, 1.3015, 1.2928, 1.3163, 1.3147, 1.3158, 1.3165, 1.3165,
         1.3047, 1.2980, 1.2941, 1.2937, 1.3056, 1.2900, 1.3011, 1.3052, 1.2774,
         1.6470, 1.6207, 1.6440, 1.6435, 1.6428, 1.6429, 1.6451, 1.6466, 1.6466,
         3.4859, 3.2757, 3.2010, 3.2593, 3.4106, 3.2280, 3.4607, 3.2089, 3.1876,
         1.6471, 1.6397, 1.6380, 1.6411, 1.6441, 1.6201, 1.6455, 1.5849, 1.6114,
         1.3010, 1.2954, 1.2855, 1.3002, 1.2960, 1.2882, 1.3004, 1.3004, 1.3025],
        [1.4554, 1.4512, 1.4079, 1.4111, 1.4487, 1.4553, 1.4538, 1.4554, 1.4554,
         1.4409, 1.4383, 1.4333, 1.4285, 1.4421, 1.4016, 1.4361, 1.4420, 1.4372,
         1.7608, 1.7521, 1.7509, 1.7590, 1.7766, 1.7752, 1.7553, 1.7767, 1.7767,
         1.4732, 1.4788, 1.5151, 1.5099, 1.4787, 1.5137, 1.5019, 1.5151, 1.5120,
         2.2002, 2.1801, 2.1687, 2.1866, 2.2304, 2.2482, 2.2146, 2.3180, 2.3150,
         1.4252, 1.4157, 1.4300, 1.4404, 1.4276, 1.4372, 1.4079, 1.4343, 1.4404],
        [1.3225, 1.2309, 1.2261, 1.2454, 1.2383, 1.2488, 1.2475, 1.1882, 1.1882,
         1.2482, 1.2046, 1.2017, 1.2083, 1.2949, 1.1600, 1.1147, 1.2949, 1.1863,
         1.5899, 1.5661, 1.5473, 1.5432, 1.5668, 1.5630, 1.5826, 1.5683, 1.5683,
         1.3268, 1.2997, 1.3006, 1.3166, 1.3019, 1.3441, 1.3466, 1.3209, 1.3007,
         1.5664, 1.5653, 1.5716, 1.5610, 1.5368, 1.5403, 1.6015, 1.4900, 1.4587,
         4.1092, 3.6460, 3.7345, 3.7190, 3.7329, 3.4153, 4.1054, 3.6936, 3.4470]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 271 : 1778.7536165664453
Test loss for epoch 271 : 195.85812334456764
Test Precision for epoch 271 : 0.26153846153846155
Test Recall for epoch 271 : 0.26153846153846155
Test F1 for epoch 271 : 0.26153846153846155


theta for epoch 272 : tensor([[3.6370, 3.6587, 3.8023, 3.7499, 3.7342, 3.6188, 3.6599, 3.5596, 3.5596,
         1.2554, 1.2342, 1.2322, 1.2361, 1.2766, 1.2160, 1.1834, 1.2766, 1.2201,
         1.5984, 1.5827, 1.6070, 1.5893, 1.5950, 1.5967, 1.6041, 1.5966, 1.5966,
         1.3454, 1.3567, 1.3428, 1.3643, 1.3449, 1.3756, 1.3685, 1.3556, 1.3429,
         1.5945, 1.6106, 1.5994, 1.5958, 1.6028, 1.5929, 1.6114, 1.5650, 1.5697,
         1.2333, 1.2590, 1.2517, 1.2690, 1.2281, 1.2197, 1.2102, 1.2920, 1.2485],
        [1.3660, 1.2128, 1.2027, 1.2458, 1.2461, 1.2585, 1.2524, 1.1562, 1.1562,
         3.6128, 3.6979, 3.5444, 3.9269, 3.6127, 4.2531, 3.4810, 3.5684, 4.0303,
         1.5622, 1.5496, 1.5240, 1.5216, 1.5428, 1.5523, 1.5775, 1.5523, 1.5523,
         1.3408, 1.3070, 1.3003, 1.3592, 1.3006, 1.3971, 1.3770, 1.3452, 1.2972,
         1.5323, 1.5893, 1.5522, 1.5390, 1.5341, 1.5723, 1.5922, 1.4245, 1.5233,
         1.1311, 1.2441, 1.2182, 1.2678, 1.1249, 1.1306, 1.0590, 1.3342, 1.2083],
        [1.4580, 1.4579, 1.4563, 1.4535, 1.4539, 1.4580, 1.4537, 1.4580, 1.4580,
         1.4290, 1.4283, 1.4289, 1.4289, 1.4290, 1.4102, 1.4290, 1.4278, 1.4256,
         2.2057, 2.2060, 2.2228, 2.1983, 2.1797, 2.1779, 2.2071, 2.1770, 2.1770,
         1.5195, 1.5179, 1.5253, 1.5253, 1.5195, 1.5253, 1.5253, 1.5253, 1.5253,
         1.7767, 1.7768, 1.7768, 1.7737, 1.7767, 1.7767, 1.7768, 1.7541, 1.7568,
         1.4319, 1.4365, 1.4365, 1.4365, 1.4282, 1.4365, 1.4326, 1.4364, 1.4365],
        [1.3247, 1.3230, 1.3071, 1.2984, 1.3219, 1.3203, 1.3214, 1.3221, 1.3221,
         1.2944, 1.2877, 1.2838, 1.2834, 1.2952, 1.2796, 1.2908, 1.2948, 1.2670,
         1.6475, 1.6212, 1.6445, 1.6439, 1.6433, 1.6433, 1.6455, 1.6470, 1.6470,
         3.4977, 3.2876, 3.2131, 3.2712, 3.4225, 3.2399, 3.4724, 3.2209, 3.1996,
         1.6496, 1.6421, 1.6405, 1.6436, 1.6465, 1.6225, 1.6479, 1.5874, 1.6138,
         1.2997, 1.2941, 1.2843, 1.2989, 1.2947, 1.2869, 1.2992, 1.2991, 1.3012],
        [1.4608, 1.4566, 1.4133, 1.4166, 1.4542, 1.4607, 1.4592, 1.4608, 1.4608,
         1.4307, 1.4281, 1.4231, 1.4183, 1.4318, 1.3913, 1.4259, 1.4318, 1.4270,
         1.7614, 1.7527, 1.7515, 1.7596, 1.7771, 1.7757, 1.7559, 1.7773, 1.7773,
         1.4862, 1.4919, 1.5281, 1.5229, 1.4917, 1.5267, 1.5149, 1.5281, 1.5250,
         2.2026, 2.1825, 2.1711, 2.1890, 2.2327, 2.2506, 2.2169, 2.3203, 2.3173,
         1.4241, 1.4146, 1.4289, 1.4393, 1.4265, 1.4360, 1.4068, 1.4332, 1.4393],
        [1.3225, 1.2298, 1.2250, 1.2444, 1.2374, 1.2479, 1.2467, 1.1865, 1.1865,
         1.2360, 1.1926, 1.1901, 1.1963, 1.2818, 1.1478, 1.1037, 1.2818, 1.1743,
         1.5872, 1.5633, 1.5446, 1.5403, 1.5640, 1.5601, 1.5799, 1.5655, 1.5655,
         1.3340, 1.3067, 1.3075, 1.3237, 1.3088, 1.3515, 1.3539, 1.3280, 1.3075,
         1.5658, 1.5648, 1.5710, 1.5605, 1.5361, 1.5398, 1.6011, 1.4892, 1.4578,
         4.1157, 3.6519, 3.7405, 3.7250, 3.7390, 3.4212, 4.1119, 3.6995, 3.4529]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 272 : 1778.6174298635797
Test loss for epoch 272 : 195.79746667727184
Test Precision for epoch 272 : 0.26153846153846155
Test Recall for epoch 272 : 0.26153846153846155
Test F1 for epoch 272 : 0.26153846153846155


theta for epoch 273 : tensor([[3.6305, 3.6520, 3.7957, 3.7433, 3.7275, 3.6122, 3.6533, 3.5529, 3.5529,
         1.2518, 1.2310, 1.2293, 1.2329, 1.2722, 1.2128, 1.1815, 1.2722, 1.2171,
         1.6013, 1.5856, 1.6099, 1.5923, 1.5979, 1.5996, 1.6070, 1.5996, 1.5996,
         1.3482, 1.3595, 1.3457, 1.3671, 1.3477, 1.3783, 1.3712, 1.3584, 1.3458,
         1.5984, 1.6144, 1.6032, 1.5997, 1.6066, 1.5967, 1.6152, 1.5689, 1.5736,
         1.2368, 1.2623, 1.2551, 1.2721, 1.2317, 1.2235, 1.2148, 1.2947, 1.2519],
        [1.3684, 1.2163, 1.2060, 1.2491, 1.2494, 1.2618, 1.2557, 1.1602, 1.1602,
         3.6071, 3.6923, 3.5386, 3.9217, 3.6070, 4.2487, 3.4751, 3.5626, 4.0253,
         1.5663, 1.5538, 1.5282, 1.5260, 1.5472, 1.5567, 1.5816, 1.5567, 1.5567,
         1.3446, 1.3109, 1.3045, 1.3630, 1.3046, 1.4007, 1.3807, 1.3491, 1.3013,
         1.5376, 1.5944, 1.5575, 1.5442, 1.5393, 1.5774, 1.5972, 1.4298, 1.5285,
         1.1362, 1.2484, 1.2227, 1.2718, 1.1301, 1.1361, 1.0664, 1.3369, 1.2129],
        [1.4561, 1.4561, 1.4545, 1.4517, 1.4521, 1.4561, 1.4518, 1.4561, 1.4561,
         1.4244, 1.4237, 1.4244, 1.4243, 1.4244, 1.4056, 1.4244, 1.4232, 1.4210,
         2.2073, 2.2076, 2.2243, 2.1998, 2.1812, 2.1794, 2.2086, 2.1785, 2.1785,
         1.5207, 1.5191, 1.5265, 1.5265, 1.5207, 1.5265, 1.5264, 1.5265, 1.5265,
         1.7796, 1.7797, 1.7797, 1.7765, 1.7796, 1.7796, 1.7797, 1.7570, 1.7597,
         1.4340, 1.4386, 1.4386, 1.4386, 1.4304, 1.4386, 1.4347, 1.4386, 1.4386],
        [1.3230, 1.3213, 1.3054, 1.2966, 1.3202, 1.3186, 1.3197, 1.3203, 1.3203,
         1.2897, 1.2830, 1.2792, 1.2787, 1.2905, 1.2750, 1.2862, 1.2901, 1.2624,
         1.6490, 1.6228, 1.6460, 1.6455, 1.6449, 1.6449, 1.6471, 1.6486, 1.6486,
         3.4992, 3.2891, 3.2146, 3.2728, 3.4240, 3.2414, 3.4739, 3.2224, 3.2012,
         1.6523, 1.6449, 1.6432, 1.6463, 1.6493, 1.6253, 1.6507, 1.5901, 1.6166,
         1.3018, 1.2961, 1.2863, 1.3009, 1.2967, 1.2889, 1.3013, 1.3011, 1.3032],
        [1.4590, 1.4548, 1.4115, 1.4147, 1.4523, 1.4589, 1.4574, 1.4590, 1.4590,
         1.4261, 1.4235, 1.4185, 1.4137, 1.4273, 1.3868, 1.4213, 1.4272, 1.4224,
         1.7631, 1.7543, 1.7532, 1.7613, 1.7788, 1.7774, 1.7576, 1.7789, 1.7789,
         1.4874, 1.4931, 1.5292, 1.5241, 1.4929, 1.5278, 1.5161, 1.5293, 1.5262,
         2.2053, 2.1852, 2.1739, 2.1917, 2.2354, 2.2533, 2.2197, 2.3230, 2.3199,
         1.4263, 1.4168, 1.4311, 1.4414, 1.4287, 1.4382, 1.4091, 1.4354, 1.4414],
        [1.3377, 1.2447, 1.2400, 1.2594, 1.2524, 1.2629, 1.2616, 1.2011, 1.2011,
         1.2392, 1.1970, 1.1948, 1.2003, 1.2834, 1.1522, 1.1106, 1.2835, 1.1788,
         1.5981, 1.5742, 1.5556, 1.5512, 1.5748, 1.5709, 1.5908, 1.5763, 1.5763,
         1.3474, 1.3202, 1.3207, 1.3372, 1.3222, 1.3651, 1.3674, 1.3414, 1.3208,
         1.5762, 1.5754, 1.5815, 1.5709, 1.5468, 1.5504, 1.6116, 1.5000, 1.4689,
         4.0988, 3.6345, 3.7231, 3.7076, 3.7215, 3.4037, 4.0950, 3.6821, 3.4354]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 273 : 1779.4496988412468
Test loss for epoch 273 : 195.11707793918293
Test Precision for epoch 273 : 0.26153846153846155
Test Recall for epoch 273 : 0.26153846153846155
Test F1 for epoch 273 : 0.26153846153846155


theta for epoch 274 : tensor([[3.6239, 3.6453, 3.7891, 3.7367, 3.7209, 3.6055, 3.6466, 3.5461, 3.5461,
         1.2572, 1.2368, 1.2353, 1.2385, 1.2769, 1.2190, 1.1882, 1.2769, 1.2229,
         1.6019, 1.5862, 1.6105, 1.5929, 1.5986, 1.6002, 1.6076, 1.6002, 1.6002,
         1.3339, 1.3453, 1.3316, 1.3528, 1.3335, 1.3640, 1.3569, 1.3442, 1.3316,
         1.5986, 1.6146, 1.6035, 1.5999, 1.6068, 1.5969, 1.6153, 1.5691, 1.5738,
         1.2459, 1.2713, 1.2640, 1.2809, 1.2408, 1.2326, 1.2247, 1.3031, 1.2608],
        [1.3654, 1.2144, 1.2041, 1.2470, 1.2473, 1.2597, 1.2536, 1.1590, 1.1590,
         3.6081, 3.6934, 3.5396, 3.9232, 3.6081, 4.2510, 3.4759, 3.5636, 4.0271,
         1.5662, 1.5538, 1.5281, 1.5261, 1.5473, 1.5568, 1.5816, 1.5568, 1.5568,
         1.3359, 1.3023, 1.2962, 1.3541, 1.2961, 1.3915, 1.3717, 1.3404, 1.2930,
         1.5375, 1.5941, 1.5574, 1.5441, 1.5391, 1.5772, 1.5968, 1.4297, 1.5284,
         1.1419, 1.2539, 1.2283, 1.2770, 1.1360, 1.1423, 1.0739, 1.3412, 1.2186],
        [1.4506, 1.4506, 1.4489, 1.4462, 1.4466, 1.4506, 1.4463, 1.4506, 1.4506,
         1.4291, 1.4284, 1.4290, 1.4290, 1.4291, 1.4103, 1.4290, 1.4279, 1.4257,
         2.2070, 2.2073, 2.2241, 2.1995, 2.1810, 2.1792, 2.2084, 2.1783, 2.1783,
         1.5054, 1.5037, 1.5112, 1.5112, 1.5054, 1.5112, 1.5111, 1.5112, 1.5112,
         1.7791, 1.7792, 1.7792, 1.7760, 1.7791, 1.7791, 1.7792, 1.7566, 1.7593,
         1.4422, 1.4468, 1.4468, 1.4468, 1.4385, 1.4468, 1.4429, 1.4467, 1.4468],
        [1.3175, 1.3158, 1.2999, 1.2911, 1.3147, 1.3131, 1.3142, 1.3148, 1.3148,
         1.2943, 1.2876, 1.2838, 1.2833, 1.2951, 1.2796, 1.2908, 1.2947, 1.2670,
         1.6487, 1.6224, 1.6457, 1.6452, 1.6445, 1.6446, 1.6468, 1.6482, 1.6482,
         3.4863, 3.2762, 3.2016, 3.2598, 3.4110, 3.2285, 3.4611, 3.2094, 3.1881,
         1.6518, 1.6443, 1.6427, 1.6458, 1.6487, 1.6248, 1.6501, 1.5896, 1.6161,
         1.3099, 1.3042, 1.2944, 1.3090, 1.3048, 1.2971, 1.3094, 1.3092, 1.3113],
        [1.4535, 1.4493, 1.4060, 1.4092, 1.4468, 1.4534, 1.4519, 1.4535, 1.4535,
         1.4308, 1.4282, 1.4232, 1.4184, 1.4319, 1.3915, 1.4260, 1.4319, 1.4271,
         1.7628, 1.7541, 1.7530, 1.7610, 1.7785, 1.7772, 1.7573, 1.7786, 1.7786,
         1.4721, 1.4778, 1.5139, 1.5088, 1.4776, 1.5126, 1.5008, 1.5140, 1.5109,
         2.2048, 2.1847, 2.1734, 2.1912, 2.2349, 2.2528, 2.2192, 2.3224, 2.3194,
         1.4346, 1.4249, 1.4393, 1.4496, 1.4369, 1.4463, 1.4173, 1.4435, 1.4496],
        [1.3471, 1.2535, 1.2490, 1.2684, 1.2614, 1.2718, 1.2706, 1.2095, 1.2095,
         1.2494, 1.2077, 1.2059, 1.2109, 1.2923, 1.1637, 1.1229, 1.2923, 1.1897,
         1.6051, 1.5813, 1.5628, 1.5581, 1.5817, 1.5778, 1.5978, 1.5832, 1.5832,
         1.3444, 1.3174, 1.3175, 1.3344, 1.3193, 1.3623, 1.3645, 1.3385, 1.3175,
         1.5817, 1.5811, 1.5869, 1.5764, 1.5524, 1.5561, 1.6172, 1.5058, 1.4748,
         4.0887, 3.6238, 3.7125, 3.6969, 3.7109, 3.3929, 4.0848, 3.6715, 3.4246]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 274 : 1779.1478725552654
Test loss for epoch 274 : 195.14777732247424
Test Precision for epoch 274 : 0.26153846153846155
Test Recall for epoch 274 : 0.26153846153846155
Test F1 for epoch 274 : 0.26153846153846155


theta for epoch 275 : tensor([[3.6217, 3.6430, 3.7868, 3.7344, 3.7186, 3.6032, 3.6443, 3.5438, 3.5438,
         1.2653, 1.2450, 1.2438, 1.2467, 1.2845, 1.2276, 1.1971, 1.2845, 1.2313,
         1.5968, 1.5811, 1.6053, 1.5879, 1.5935, 1.5952, 1.6025, 1.5951, 1.5951,
         1.3283, 1.3397, 1.3261, 1.3472, 1.3279, 1.3582, 1.3512, 1.3386, 1.3261,
         1.5931, 1.6091, 1.5980, 1.5944, 1.6013, 1.5914, 1.6098, 1.5636, 1.5683,
         1.2513, 1.2765, 1.2692, 1.2860, 1.2462, 1.2381, 1.2308, 1.3078, 1.2661],
        [1.3586, 1.2085, 1.1980, 1.2410, 1.2412, 1.2536, 1.2475, 1.1534, 1.1534,
         3.6157, 3.7011, 3.5471, 3.9313, 3.6157, 4.2598, 3.4834, 3.5712, 4.0354,
         1.5584, 1.5460, 1.5201, 1.5184, 1.5396, 1.5490, 1.5737, 1.5491, 1.5491,
         1.3281, 1.2946, 1.2887, 1.3463, 1.2885, 1.3836, 1.3639, 1.3327, 1.2855,
         1.5292, 1.5858, 1.5491, 1.5358, 1.5308, 1.5688, 1.5884, 1.4213, 1.5200,
         1.1411, 1.2530, 1.2274, 1.2759, 1.1353, 1.1417, 1.0745, 1.3394, 1.2177],
        [1.4477, 1.4477, 1.4461, 1.4433, 1.4437, 1.4477, 1.4434, 1.4477, 1.4477,
         1.4369, 1.4362, 1.4368, 1.4368, 1.4369, 1.4182, 1.4369, 1.4357, 1.4335,
         2.2020, 2.2023, 2.2191, 2.1947, 2.1762, 2.1744, 2.2036, 2.1735, 2.1735,
         1.4994, 1.4978, 1.5052, 1.5052, 1.4994, 1.5052, 1.5052, 1.5052, 1.5052,
         1.7735, 1.7736, 1.7736, 1.7704, 1.7735, 1.7735, 1.7736, 1.7509, 1.7536,
         1.4473, 1.4518, 1.4518, 1.4518, 1.4436, 1.4518, 1.4480, 1.4518, 1.4518],
        [1.3146, 1.3129, 1.2970, 1.2882, 1.3118, 1.3102, 1.3113, 1.3119, 1.3119,
         1.3020, 1.2954, 1.2915, 1.2911, 1.3027, 1.2874, 1.2986, 1.3023, 1.2748,
         1.6432, 1.6170, 1.6402, 1.6397, 1.6390, 1.6391, 1.6413, 1.6428, 1.6428,
         3.4818, 3.2717, 3.1971, 3.2553, 3.4065, 3.2240, 3.4567, 3.2049, 3.1836,
         1.6460, 1.6385, 1.6369, 1.6400, 1.6430, 1.6190, 1.6444, 1.5838, 1.6103,
         1.3149, 1.3092, 1.2994, 1.3140, 1.3098, 1.3021, 1.3144, 1.3142, 1.3163],
        [1.4506, 1.4464, 1.4032, 1.4063, 1.4439, 1.4505, 1.4490, 1.4506, 1.4506,
         1.4386, 1.4360, 1.4310, 1.4263, 1.4397, 1.3994, 1.4338, 1.4397, 1.4349,
         1.7575, 1.7488, 1.7477, 1.7558, 1.7732, 1.7719, 1.7520, 1.7734, 1.7734,
         1.4661, 1.4719, 1.5080, 1.5029, 1.4716, 1.5066, 1.4948, 1.5080, 1.5049,
         2.1993, 2.1792, 2.1679, 2.1857, 2.2294, 2.2473, 2.2137, 2.3169, 2.3139,
         1.4397, 1.4301, 1.4444, 1.4546, 1.4421, 1.4514, 1.4225, 1.4486, 1.4547],
        [1.3543, 1.2600, 1.2556, 1.2750, 1.2680, 1.2784, 1.2772, 1.2155, 1.2155,
         1.2604, 1.2189, 1.2175, 1.2221, 1.3024, 1.1755, 1.1347, 1.3024, 1.2009,
         1.6050, 1.5812, 1.5629, 1.5580, 1.5815, 1.5776, 1.5977, 1.5829, 1.5829,
         1.3460, 1.3190, 1.3188, 1.3361, 1.3208, 1.3642, 1.3662, 1.3400, 1.3188,
         1.5801, 1.5797, 1.5853, 1.5749, 1.5510, 1.5548, 1.6157, 1.5044, 1.4736,
         4.0824, 3.6170, 3.7057, 3.6902, 3.7041, 3.3860, 4.0786, 3.6648, 3.4178]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 275 : 1779.233996099742
Test loss for epoch 275 : 195.5106783018324
Test Precision for epoch 275 : 0.26153846153846155
Test Recall for epoch 275 : 0.26153846153846155
Test F1 for epoch 275 : 0.26153846153846155


theta for epoch 276 : tensor([[3.6187, 3.6400, 3.7838, 3.7314, 3.7155, 3.6002, 3.6413, 3.5407, 3.5407,
         1.2658, 1.2461, 1.2451, 1.2477, 1.2842, 1.2290, 1.1996, 1.2842, 1.2325,
         1.5952, 1.5796, 1.6037, 1.5864, 1.5920, 1.5936, 1.6009, 1.5936, 1.5936,
         1.3389, 1.3503, 1.3368, 1.3577, 1.3386, 1.3687, 1.3618, 1.3492, 1.3368,
         1.5905, 1.6065, 1.5954, 1.5918, 1.5986, 1.5887, 1.6071, 1.5610, 1.5657,
         1.2503, 1.2754, 1.2681, 1.2847, 1.2453, 1.2373, 1.2305, 1.3062, 1.2650],
        [1.3724, 1.2231, 1.2125, 1.2554, 1.2556, 1.2681, 1.2620, 1.1684, 1.1684,
         3.6026, 3.6880, 3.5339, 3.9186, 3.6026, 4.2479, 3.4700, 3.5581, 4.0230,
         1.5660, 1.5537, 1.5279, 1.5263, 1.5474, 1.5568, 1.5812, 1.5568, 1.5568,
         1.3435, 1.3101, 1.3043, 1.3617, 1.3040, 1.3988, 1.3792, 1.3481, 1.3012,
         1.5353, 1.5915, 1.5551, 1.5419, 1.5369, 1.5747, 1.5941, 1.4281, 1.5262,
         1.1496, 1.2609, 1.2353, 1.2835, 1.1439, 1.1504, 1.0845, 1.3460, 1.2258],
        [1.4516, 1.4515, 1.4499, 1.4471, 1.4475, 1.4516, 1.4473, 1.4516, 1.4516,
         1.4365, 1.4358, 1.4364, 1.4364, 1.4365, 1.4178, 1.4365, 1.4353, 1.4331,
         2.1995, 2.1998, 2.2166, 2.1923, 2.1738, 2.1720, 2.2012, 2.1711, 2.1711,
         1.5085, 1.5069, 1.5143, 1.5143, 1.5085, 1.5143, 1.5143, 1.5143, 1.5143,
         1.7699, 1.7700, 1.7700, 1.7668, 1.7699, 1.7699, 1.7700, 1.7474, 1.7501,
         1.4451, 1.4496, 1.4496, 1.4496, 1.4414, 1.4496, 1.4458, 1.4496, 1.4496],
        [1.3185, 1.3168, 1.3009, 1.2922, 1.3157, 1.3141, 1.3152, 1.3159, 1.3159,
         1.3015, 1.2949, 1.2911, 1.2906, 1.3022, 1.2869, 1.2982, 1.3018, 1.2743,
         1.6404, 1.6141, 1.6374, 1.6369, 1.6362, 1.6362, 1.6385, 1.6399, 1.6399,
         3.4905, 3.2804, 3.2059, 3.2641, 3.4152, 3.2328, 3.4653, 3.2137, 3.1925,
         1.6423, 1.6349, 1.6332, 1.6363, 1.6393, 1.6153, 1.6407, 1.5802, 1.6066,
         1.3125, 1.3069, 1.2971, 1.3116, 1.3075, 1.2997, 1.3121, 1.3118, 1.3140],
        [1.4544, 1.4503, 1.4070, 1.4102, 1.4477, 1.4543, 1.4528, 1.4544, 1.4544,
         1.4382, 1.4356, 1.4306, 1.4259, 1.4393, 1.3991, 1.4334, 1.4393, 1.4345,
         1.7548, 1.7461, 1.7451, 1.7531, 1.7705, 1.7692, 1.7493, 1.7706, 1.7706,
         1.4753, 1.4811, 1.5171, 1.5120, 1.4808, 1.5157, 1.5040, 1.5171, 1.5140,
         2.1958, 2.1757, 2.1644, 2.1822, 2.2259, 2.2439, 2.2102, 2.3133, 2.3103,
         1.4375, 1.4278, 1.4421, 1.4524, 1.4399, 1.4492, 1.4204, 1.4464, 1.4524],
        [1.3659, 1.2713, 1.2670, 1.2864, 1.2795, 1.2899, 1.2886, 1.2268, 1.2268,
         1.2638, 1.2233, 1.2221, 1.2262, 1.3044, 1.1805, 1.1413, 1.3044, 1.2055,
         1.6074, 1.5837, 1.5654, 1.5604, 1.5838, 1.5799, 1.6001, 1.5853, 1.5853,
         1.3601, 1.3331, 1.3327, 1.3503, 1.3349, 1.3784, 1.3804, 1.3541, 1.3328,
         1.5807, 1.5804, 1.5859, 1.5755, 1.5517, 1.5555, 1.6163, 1.5052, 1.4746,
         4.0731, 3.6071, 3.6959, 3.6803, 3.6943, 3.3761, 4.0692, 3.6549, 3.4078]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 276 : 1779.541612372984
Test loss for epoch 276 : 194.69519966086682
Test Precision for epoch 276 : 0.26153846153846155
Test Recall for epoch 276 : 0.26153846153846155
Test F1 for epoch 276 : 0.26153846153846155


theta for epoch 277 : tensor([[3.6151, 3.6364, 3.7802, 3.7278, 3.7119, 3.5966, 3.6377, 3.5370, 3.5370,
         1.2633, 1.2439, 1.2431, 1.2454, 1.2810, 1.2271, 1.1983, 1.2810, 1.2305,
         1.5978, 1.5822, 1.6063, 1.5890, 1.5946, 1.5963, 1.6034, 1.5963, 1.5963,
         1.3464, 1.3577, 1.3443, 1.3651, 1.3460, 1.3761, 1.3691, 1.3566, 1.3443,
         1.5925, 1.6084, 1.5973, 1.5937, 1.6006, 1.5907, 1.6090, 1.5630, 1.5677,
         1.2482, 1.2732, 1.2659, 1.2825, 1.2433, 1.2353, 1.2288, 1.3035, 1.2629],
        [1.3771, 1.2283, 1.2177, 1.2605, 1.2608, 1.2732, 1.2671, 1.1739, 1.1739,
         3.5955, 3.6811, 3.5267, 3.9120, 3.5955, 4.2421, 3.4628, 3.5510, 4.0166,
         1.5719, 1.5596, 1.5339, 1.5324, 1.5534, 1.5628, 1.5872, 1.5629, 1.5629,
         1.3522, 1.3188, 1.3131, 1.3704, 1.3127, 1.4074, 1.3878, 1.3568, 1.3099,
         1.5408, 1.5968, 1.5606, 1.5474, 1.5423, 1.5801, 1.5994, 1.4337, 1.5317,
         1.1524, 1.2635, 1.2378, 1.2858, 1.1468, 1.1533, 1.0884, 1.3475, 1.2284],
        [1.4495, 1.4494, 1.4478, 1.4450, 1.4454, 1.4494, 1.4451, 1.4494, 1.4494,
         1.4335, 1.4328, 1.4335, 1.4335, 1.4335, 1.4148, 1.4335, 1.4323, 1.4301,
         2.2014, 2.2016, 2.2184, 2.1941, 2.1755, 2.1738, 2.2030, 2.1729, 2.1729,
         1.5153, 1.5136, 1.5211, 1.5211, 1.5153, 1.5211, 1.5210, 1.5211, 1.5211,
         1.7714, 1.7715, 1.7715, 1.7683, 1.7714, 1.7714, 1.7715, 1.7489, 1.7515,
         1.4423, 1.4469, 1.4469, 1.4469, 1.4387, 1.4469, 1.4430, 1.4468, 1.4469],
        [1.3164, 1.3147, 1.2988, 1.2901, 1.3136, 1.3120, 1.3131, 1.3138, 1.3138,
         1.2984, 1.2918, 1.2880, 1.2876, 1.2991, 1.2839, 1.2952, 1.2987, 1.2713,
         1.6423, 1.6160, 1.6393, 1.6388, 1.6381, 1.6382, 1.6404, 1.6418, 1.6418,
         3.4969, 3.2870, 3.2125, 3.2706, 3.4217, 3.2393, 3.4717, 3.2203, 3.1991,
         1.6437, 1.6363, 1.6346, 1.6377, 1.6407, 1.6167, 1.6421, 1.5816, 1.6080,
         1.3097, 1.3040, 1.2942, 1.3088, 1.3047, 1.2969, 1.3093, 1.3089, 1.3111],
        [1.4523, 1.4482, 1.4049, 1.4081, 1.4456, 1.4522, 1.4507, 1.4523, 1.4523,
         1.4352, 1.4326, 1.4276, 1.4229, 1.4364, 1.3962, 1.4305, 1.4363, 1.4316,
         1.7568, 1.7480, 1.7470, 1.7551, 1.7724, 1.7711, 1.7513, 1.7726, 1.7726,
         1.4821, 1.4879, 1.5238, 1.5187, 1.4875, 1.5224, 1.5107, 1.5239, 1.5207,
         2.1971, 2.1771, 2.1658, 2.1836, 2.2273, 2.2452, 2.2116, 2.3146, 2.3116,
         1.4348, 1.4251, 1.4394, 1.4497, 1.4372, 1.4465, 1.4177, 1.4436, 1.4497],
        [1.3684, 1.2739, 1.2696, 1.2890, 1.2820, 1.2924, 1.2912, 1.2293, 1.2293,
         1.2627, 1.2228, 1.2220, 1.2256, 1.3022, 1.1804, 1.1424, 1.3022, 1.2052,
         1.6115, 1.5878, 1.5695, 1.5644, 1.5878, 1.5840, 1.6042, 1.5893, 1.5893,
         1.3689, 1.3418, 1.3414, 1.3590, 1.3436, 1.3872, 1.3891, 1.3629, 1.3414,
         1.5839, 1.5836, 1.5891, 1.5787, 1.5549, 1.5588, 1.6195, 1.5085, 1.4779,
         4.0685, 3.6020, 3.6907, 3.6752, 3.6892, 3.3709, 4.0646, 3.6498, 3.4026]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 277 : 1780.089523779808
Test loss for epoch 277 : 194.23150634051086
Test Precision for epoch 277 : 0.26153846153846155
Test Recall for epoch 277 : 0.26153846153846155
Test F1 for epoch 277 : 0.26153846153846155


theta for epoch 278 : tensor([[3.6137, 3.6349, 3.7787, 3.7264, 3.7104, 3.5952, 3.6363, 3.5356, 3.5356,
         1.2632, 1.2440, 1.2433, 1.2454, 1.2806, 1.2273, 1.1987, 1.2806, 1.2306,
         1.6017, 1.5861, 1.6102, 1.5930, 1.5986, 1.6002, 1.6074, 1.6002, 1.6002,
         1.3350, 1.3463, 1.3330, 1.3538, 1.3347, 1.3646, 1.3577, 1.3453, 1.3330,
         1.5974, 1.6133, 1.6022, 1.5986, 1.6055, 1.5956, 1.6139, 1.5679, 1.5726,
         1.2503, 1.2753, 1.2679, 1.2844, 1.2453, 1.2374, 1.2311, 1.3053, 1.2649],
        [1.3759, 1.2272, 1.2166, 1.2594, 1.2597, 1.2721, 1.2660, 1.1729, 1.1729,
         3.5955, 3.6812, 3.5266, 3.9126, 3.5955, 4.2434, 3.4626, 3.5510, 4.0174,
         1.5744, 1.5622, 1.5364, 1.5349, 1.5560, 1.5654, 1.5897, 1.5654, 1.5654,
         1.3454, 1.3121, 1.3064, 1.3636, 1.3060, 1.4005, 1.3810, 1.3500, 1.3033,
         1.5444, 1.6006, 1.5643, 1.5511, 1.5460, 1.5838, 1.6031, 1.4372, 1.5353,
         1.1534, 1.2646, 1.2389, 1.2869, 1.1478, 1.1543, 1.0900, 1.3482, 1.2294],
        [1.4473, 1.4472, 1.4456, 1.4428, 1.4432, 1.4473, 1.4430, 1.4473, 1.4473,
         1.4334, 1.4327, 1.4334, 1.4334, 1.4334, 1.4148, 1.4334, 1.4322, 1.4300,
         2.2049, 2.2052, 2.2220, 2.1975, 2.1790, 2.1772, 2.2064, 2.1763, 2.1763,
         1.5039, 1.5023, 1.5097, 1.5097, 1.5039, 1.5097, 1.5097, 1.5097, 1.5097,
         1.7761, 1.7762, 1.7762, 1.7730, 1.7761, 1.7761, 1.7762, 1.7536, 1.7563,
         1.4443, 1.4488, 1.4488, 1.4488, 1.4406, 1.4488, 1.4450, 1.4487, 1.4488],
        [1.3144, 1.3127, 1.2968, 1.2880, 1.3116, 1.3100, 1.3111, 1.3117, 1.3117,
         1.2983, 1.2917, 1.2879, 1.2874, 1.2990, 1.2838, 1.2951, 1.2986, 1.2712,
         1.6461, 1.6199, 1.6431, 1.6426, 1.6419, 1.6420, 1.6442, 1.6457, 1.6457,
         3.4871, 3.2770, 3.2025, 3.2607, 3.4118, 3.2294, 3.4619, 3.2104, 3.1891,
         1.6485, 1.6410, 1.6394, 1.6425, 1.6454, 1.6215, 1.6468, 1.5863, 1.6128,
         1.3117, 1.3060, 1.2962, 1.3107, 1.3066, 1.2989, 1.3112, 1.3109, 1.3131],
        [1.4502, 1.4460, 1.4028, 1.4059, 1.4435, 1.4501, 1.4486, 1.4501, 1.4501,
         1.4351, 1.4325, 1.4275, 1.4229, 1.4363, 1.3961, 1.4304, 1.4362, 1.4315,
         1.7605, 1.7518, 1.7508, 1.7588, 1.7762, 1.7749, 1.7551, 1.7763, 1.7763,
         1.4707, 1.4765, 1.5125, 1.5074, 1.4762, 1.5111, 1.4994, 1.5125, 1.5094,
         2.2017, 2.1817, 2.1705, 2.1882, 2.2318, 2.2498, 2.2162, 2.3191, 2.3161,
         1.4368, 1.4270, 1.4413, 1.4516, 1.4391, 1.4484, 1.4196, 1.4456, 1.4516],
        [1.3666, 1.2722, 1.2678, 1.2872, 1.2803, 1.2907, 1.2894, 1.2277, 1.2277,
         1.2624, 1.2228, 1.2222, 1.2255, 1.3010, 1.1807, 1.1431, 1.3011, 1.2053,
         1.6148, 1.5911, 1.5728, 1.5678, 1.5912, 1.5873, 1.6076, 1.5927, 1.5927,
         1.3594, 1.3324, 1.3319, 1.3496, 1.3341, 1.3777, 1.3796, 1.3534, 1.3319,
         1.5882, 1.5880, 1.5935, 1.5830, 1.5592, 1.5631, 1.6239, 1.5128, 1.4822,
         4.0701, 3.6030, 3.6918, 3.6763, 3.6903, 3.3719, 4.0662, 3.6509, 3.4037]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 278 : 1779.835198346538
Test loss for epoch 278 : 194.38819808274445
Test Precision for epoch 278 : 0.26153846153846155
Test Recall for epoch 278 : 0.26153846153846155
Test F1 for epoch 278 : 0.26153846153846155


theta for epoch 279 : tensor([[3.6158, 3.6371, 3.7808, 3.7285, 3.7125, 3.5973, 3.6384, 3.5378, 3.5378,
         1.2644, 1.2451, 1.2445, 1.2466, 1.2817, 1.2286, 1.1997, 1.2817, 1.2318,
         1.5997, 1.5842, 1.6082, 1.5911, 1.5966, 1.5983, 1.6054, 1.5983, 1.5983,
         1.3285, 1.3398, 1.3265, 1.3473, 1.3282, 1.3582, 1.3512, 1.3388, 1.3265,
         1.5982, 1.6141, 1.6031, 1.5995, 1.6063, 1.5964, 1.6147, 1.5687, 1.5734,
         1.2522, 1.2773, 1.2698, 1.2864, 1.2473, 1.2394, 1.2331, 1.3071, 1.2668],
        [1.3707, 1.2217, 1.2111, 1.2539, 1.2542, 1.2666, 1.2605, 1.1672, 1.1672,
         3.6016, 3.6874, 3.5327, 3.9192, 3.6017, 4.2508, 3.4686, 3.5571, 4.0242,
         1.5689, 1.5566, 1.5308, 1.5292, 1.5504, 1.5598, 1.5842, 1.5598, 1.5598,
         1.3373, 1.3040, 1.2983, 1.3555, 1.2979, 1.3925, 1.3729, 1.3419, 1.2951,
         1.5411, 1.5974, 1.5610, 1.5477, 1.5427, 1.5806, 1.6000, 1.4336, 1.5320,
         1.1502, 1.2619, 1.2358, 1.2841, 1.1445, 1.1510, 1.0869, 1.3451, 1.2263],
        [1.4478, 1.4477, 1.4461, 1.4433, 1.4437, 1.4478, 1.4435, 1.4478, 1.4478,
         1.4350, 1.4343, 1.4350, 1.4349, 1.4350, 1.4163, 1.4350, 1.4338, 1.4316,
         2.2035, 2.2037, 2.2205, 2.1961, 2.1776, 2.1758, 2.2050, 2.1749, 2.1749,
         1.4981, 1.4964, 1.5039, 1.5039, 1.4981, 1.5039, 1.5038, 1.5039, 1.5039,
         1.7772, 1.7773, 1.7773, 1.7742, 1.7772, 1.7772, 1.7773, 1.7547, 1.7574,
         1.4466, 1.4511, 1.4511, 1.4511, 1.4429, 1.4511, 1.4473, 1.4510, 1.4511],
        [1.3151, 1.3133, 1.2974, 1.2887, 1.3122, 1.3106, 1.3118, 1.3123, 1.3123,
         1.2999, 1.2933, 1.2895, 1.2890, 1.3005, 1.2853, 1.2967, 1.3001, 1.2728,
         1.6446, 1.6183, 1.6416, 1.6410, 1.6404, 1.6404, 1.6427, 1.6441, 1.6441,
         3.4819, 3.2718, 3.1972, 3.2555, 3.4066, 3.2242, 3.4567, 3.2051, 3.1838,
         1.6496, 1.6422, 1.6405, 1.6436, 1.6466, 1.6226, 1.6480, 1.5875, 1.6139,
         1.3140, 1.3083, 1.2985, 1.3131, 1.3090, 1.3012, 1.3136, 1.3132, 1.3154],
        [1.4506, 1.4465, 1.4032, 1.4064, 1.4440, 1.4505, 1.4491, 1.4506, 1.4506,
         1.4367, 1.4341, 1.4291, 1.4244, 1.4378, 1.3977, 1.4319, 1.4378, 1.4331,
         1.7590, 1.7503, 1.7493, 1.7573, 1.7746, 1.7733, 1.7535, 1.7748, 1.7748,
         1.4649, 1.4706, 1.5066, 1.5015, 1.4703, 1.5053, 1.4935, 1.5067, 1.5036,
         2.2028, 2.1828, 2.1715, 2.1893, 2.2329, 2.2509, 2.2173, 2.3201, 2.3172,
         1.4391, 1.4293, 1.4436, 1.4539, 1.4414, 1.4507, 1.4219, 1.4479, 1.4539],
        [1.3627, 1.2685, 1.2641, 1.2835, 1.2766, 1.2870, 1.2857, 1.2241, 1.2241,
         1.2619, 1.2223, 1.2219, 1.2250, 1.3001, 1.1802, 1.1427, 1.3001, 1.2048,
         1.6113, 1.5876, 1.5692, 1.5642, 1.5877, 1.5838, 1.6040, 1.5891, 1.5891,
         1.3517, 1.3247, 1.3242, 1.3419, 1.3264, 1.3700, 1.3719, 1.3457, 1.3243,
         1.5874, 1.5871, 1.5927, 1.5822, 1.5584, 1.5623, 1.6231, 1.5118, 1.4812,
         4.0758, 3.6082, 3.6971, 3.6814, 3.6956, 3.3771, 4.0719, 3.6560, 3.4088]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 279 : 1779.699392143527
Test loss for epoch 279 : 194.8213040060619
Test Precision for epoch 279 : 0.26153846153846155
Test Recall for epoch 279 : 0.26153846153846155
Test F1 for epoch 279 : 0.26153846153846155


theta for epoch 280 : tensor([[3.6218, 3.6431, 3.7868, 3.7345, 3.7185, 3.6034, 3.6445, 3.5439, 3.5439,
         1.2636, 1.2441, 1.2436, 1.2456, 1.2808, 1.2275, 1.1981, 1.2808, 1.2307,
         1.5957, 1.5801, 1.6042, 1.5870, 1.5926, 1.5943, 1.6014, 1.5942, 1.5942,
         1.3356, 1.3470, 1.3335, 1.3544, 1.3353, 1.3653, 1.3584, 1.3459, 1.3336,
         1.5943, 1.6102, 1.5992, 1.5956, 1.6024, 1.5925, 1.6108, 1.5648, 1.5695,
         1.2496, 1.2748, 1.2673, 1.2838, 1.2447, 1.2368, 1.2305, 1.3045, 1.2642],
        [1.3624, 1.2126, 1.2020, 1.2450, 1.2452, 1.2577, 1.2516, 1.1578, 1.1578,
         3.6122, 3.6981, 3.5432, 3.9303, 3.6123, 4.2627, 3.4790, 3.5676, 4.0355,
         1.5585, 1.5461, 1.5203, 1.5186, 1.5398, 1.5492, 1.5738, 1.5493, 1.5493,
         1.3335, 1.3000, 1.2942, 1.3518, 1.2938, 1.3890, 1.3693, 1.3381, 1.2910,
         1.5308, 1.5873, 1.5507, 1.5374, 1.5324, 1.5704, 1.5899, 1.4230, 1.5216,
         1.1403, 1.2526, 1.2262, 1.2748, 1.1345, 1.1410, 1.0770, 1.3358, 1.2167],
        [1.4512, 1.4511, 1.4495, 1.4467, 1.4471, 1.4512, 1.4469, 1.4512, 1.4512,
         1.4349, 1.4342, 1.4349, 1.4348, 1.4349, 1.4162, 1.4349, 1.4337, 1.4315,
         2.2005, 2.2007, 2.2175, 2.1932, 2.1747, 2.1729, 2.2021, 2.1720, 2.1720,
         1.5065, 1.5048, 1.5123, 1.5123, 1.5065, 1.5123, 1.5122, 1.5123, 1.5123,
         1.7741, 1.7741, 1.7741, 1.7710, 1.7740, 1.7740, 1.7741, 1.7516, 1.7542,
         1.4448, 1.4493, 1.4493, 1.4493, 1.4412, 1.4493, 1.4455, 1.4493, 1.4493],
        [1.3187, 1.3169, 1.3010, 1.2922, 1.3158, 1.3142, 1.3153, 1.3159, 1.3159,
         1.2998, 1.2932, 1.2894, 1.2889, 1.3004, 1.2852, 1.2965, 1.3000, 1.2726,
         1.6414, 1.6152, 1.6384, 1.6379, 1.6372, 1.6373, 1.6395, 1.6410, 1.6410,
         3.4892, 3.2792, 3.2047, 3.2629, 3.4139, 3.2316, 3.4641, 3.2126, 3.1913,
         1.6464, 1.6389, 1.6373, 1.6404, 1.6434, 1.6194, 1.6447, 1.5843, 1.6107,
         1.3123, 1.3066, 1.2968, 1.3114, 1.3073, 1.2995, 1.3119, 1.3115, 1.3137],
        [1.4540, 1.4499, 1.4066, 1.4098, 1.4474, 1.4539, 1.4525, 1.4540, 1.4540,
         1.4366, 1.4340, 1.4290, 1.4243, 1.4377, 1.3976, 1.4318, 1.4377, 1.4330,
         1.7558, 1.7471, 1.7461, 1.7541, 1.7715, 1.7702, 1.7504, 1.7716, 1.7716,
         1.4733, 1.4790, 1.5150, 1.5099, 1.4787, 1.5136, 1.5019, 1.5151, 1.5119,
         2.1996, 2.1797, 2.1684, 2.1861, 2.2298, 2.2478, 2.2142, 2.3170, 2.3141,
         1.4373, 1.4276, 1.4419, 1.4521, 1.4397, 1.4489, 1.4202, 1.4461, 1.4522],
        [1.3577, 1.2636, 1.2593, 1.2786, 1.2717, 1.2821, 1.2808, 1.2194, 1.2194,
         1.2584, 1.2185, 1.2182, 1.2212, 1.2962, 1.1763, 1.1385, 1.2963, 1.2009,
         1.6044, 1.5807, 1.5623, 1.5573, 1.5808, 1.5769, 1.5971, 1.5823, 1.5823,
         1.3534, 1.3263, 1.3260, 1.3435, 1.3281, 1.3717, 1.3737, 1.3474, 1.3261,
         1.5810, 1.5807, 1.5862, 1.5758, 1.5519, 1.5557, 1.6167, 1.5053, 1.4745,
         4.0835, 3.6154, 3.7043, 3.6887, 3.7028, 3.3842, 4.0796, 3.6633, 3.4160]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 280 : 1778.9787297676453
Test loss for epoch 280 : 195.2324212753673
Test Precision for epoch 280 : 0.26153846153846155
Test Recall for epoch 280 : 0.26153846153846155
Test F1 for epoch 280 : 0.26153846153846155


theta for epoch 281 : tensor([[3.6218, 3.6431, 3.7867, 3.7345, 3.7185, 3.6034, 3.6444, 3.5439, 3.5439,
         1.2597, 1.2403, 1.2399, 1.2418, 1.2766, 1.2238, 1.1947, 1.2766, 1.2270,
         1.5974, 1.5818, 1.6059, 1.5888, 1.5943, 1.5960, 1.6031, 1.5960, 1.5960,
         1.3478, 1.3591, 1.3457, 1.3666, 1.3475, 1.3775, 1.3706, 1.3580, 1.3457,
         1.5929, 1.6088, 1.5977, 1.5941, 1.6010, 1.5911, 1.6094, 1.5634, 1.5681,
         1.2460, 1.2713, 1.2637, 1.2803, 1.2411, 1.2332, 1.2268, 1.3008, 1.2606],
        [1.3703, 1.2202, 1.2097, 1.2527, 1.2529, 1.2654, 1.2593, 1.1652, 1.1652,
         3.6036, 3.6895, 3.5345, 3.9221, 3.6037, 4.2553, 3.4702, 3.5590, 4.0276,
         1.5649, 1.5525, 1.5268, 1.5250, 1.5462, 1.5556, 1.5802, 1.5556, 1.5556,
         1.3460, 1.3124, 1.3065, 1.3643, 1.3062, 1.4016, 1.3819, 1.3506, 1.3033,
         1.5343, 1.5908, 1.5543, 1.5410, 1.5360, 1.5739, 1.5934, 1.4269, 1.5252,
         1.1432, 1.2556, 1.2291, 1.2777, 1.1374, 1.1438, 1.0799, 1.3385, 1.2195],
        [1.4532, 1.4532, 1.4515, 1.4487, 1.4492, 1.4532, 1.4489, 1.4532, 1.4532,
         1.4309, 1.4302, 1.4309, 1.4308, 1.4309, 1.4122, 1.4309, 1.4297, 1.4275,
         2.2019, 2.2021, 2.2189, 2.1946, 2.1761, 2.1743, 2.2035, 2.1734, 2.1734,
         1.5186, 1.5169, 1.5243, 1.5243, 1.5186, 1.5243, 1.5243, 1.5243, 1.5243,
         1.7725, 1.7726, 1.7726, 1.7694, 1.7724, 1.7724, 1.7725, 1.7500, 1.7527,
         1.4410, 1.4455, 1.4455, 1.4455, 1.4373, 1.4455, 1.4417, 1.4455, 1.4455],
        [1.3209, 1.3191, 1.3032, 1.2944, 1.3180, 1.3164, 1.3175, 1.3181, 1.3181,
         1.2958, 1.2892, 1.2854, 1.2849, 1.2964, 1.2812, 1.2926, 1.2960, 1.2687,
         1.6430, 1.6168, 1.6400, 1.6395, 1.6388, 1.6389, 1.6411, 1.6426, 1.6426,
         3.4996, 3.2898, 3.2154, 3.2734, 3.4244, 3.2422, 3.4745, 3.2232, 3.2020,
         1.6448, 1.6374, 1.6357, 1.6388, 1.6418, 1.6178, 1.6432, 1.5827, 1.6091,
         1.3085, 1.3029, 1.2930, 1.3076, 1.3035, 1.2957, 1.3081, 1.3077, 1.3099],
        [1.4561, 1.4519, 1.4086, 1.4118, 1.4494, 1.4560, 1.4545, 1.4561, 1.4561,
         1.4326, 1.4300, 1.4250, 1.4204, 1.4338, 1.3937, 1.4279, 1.4337, 1.4290,
         1.7574, 1.7486, 1.7476, 1.7556, 1.7730, 1.7717, 1.7519, 1.7731, 1.7731,
         1.4854, 1.4911, 1.5271, 1.5220, 1.4908, 1.5257, 1.5140, 1.5271, 1.5240,
         2.1981, 2.1781, 2.1669, 2.1846, 2.2282, 2.2462, 2.2126, 2.3155, 2.3125,
         1.4335, 1.4237, 1.4380, 1.4483, 1.4358, 1.4451, 1.4163, 1.4423, 1.4483],
        [1.3526, 1.2593, 1.2548, 1.2742, 1.2672, 1.2776, 1.2763, 1.2155, 1.2155,
         1.2519, 1.2124, 1.2123, 1.2151, 1.2891, 1.1703, 1.1335, 1.2891, 1.1951,
         1.6027, 1.5789, 1.5605, 1.5556, 1.5792, 1.5753, 1.5954, 1.5807, 1.5807,
         1.3593, 1.3321, 1.3321, 1.3493, 1.3340, 1.3774, 1.3795, 1.3533, 1.3321,
         1.5769, 1.5765, 1.5822, 1.5717, 1.5477, 1.5516, 1.6125, 1.5011, 1.4703,
         4.0886, 3.6200, 3.7089, 3.6933, 3.7075, 3.3888, 4.0847, 3.6678, 3.4206]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 281 : 1779.4856752019332
Test loss for epoch 281 : 194.79281524968042
Test Precision for epoch 281 : 0.26153846153846155
Test Recall for epoch 281 : 0.26153846153846155
Test F1 for epoch 281 : 0.26153846153846155


theta for epoch 282 : tensor([[3.6233, 3.6446, 3.7882, 3.7360, 3.7200, 3.6049, 3.6460, 3.5455, 3.5455,
         1.2596, 1.2402, 1.2398, 1.2417, 1.2763, 1.2236, 1.1946, 1.2763, 1.2269,
         1.6023, 1.5868, 1.6108, 1.5937, 1.5993, 1.6009, 1.6080, 1.6009, 1.6009,
         1.3399, 1.3512, 1.3377, 1.3586, 1.3396, 1.3696, 1.3626, 1.3501, 1.3378,
         1.5953, 1.6111, 1.6001, 1.5966, 1.6034, 1.5935, 1.6118, 1.5658, 1.5705,
         1.2443, 1.2697, 1.2620, 1.2786, 1.2394, 1.2315, 1.2248, 1.2991, 1.2590],
        [1.3716, 1.2210, 1.2105, 1.2535, 1.2538, 1.2662, 1.2601, 1.1658, 1.1658,
         3.6025, 3.6886, 3.5333, 3.9215, 3.6026, 4.2555, 3.4690, 3.5579, 4.0273,
         1.5693, 1.5569, 1.5312, 1.5293, 1.5504, 1.5599, 1.5846, 1.5599, 1.5599,
         1.3424, 1.3088, 1.3027, 1.3607, 1.3026, 1.3981, 1.3783, 1.3469, 1.2996,
         1.5369, 1.5935, 1.5569, 1.5436, 1.5386, 1.5766, 1.5962, 1.4294, 1.5278,
         1.1426, 1.2556, 1.2288, 1.2776, 1.1368, 1.1430, 1.0789, 1.3385, 1.2191],
        [1.4533, 1.4533, 1.4517, 1.4489, 1.4493, 1.4534, 1.4491, 1.4534, 1.4534,
         1.4311, 1.4304, 1.4311, 1.4310, 1.4311, 1.4124, 1.4311, 1.4299, 1.4277,
         2.2068, 2.2070, 2.2238, 2.1992, 2.1808, 2.1790, 2.2082, 2.1781, 2.1781,
         1.5112, 1.5096, 1.5170, 1.5170, 1.5113, 1.5170, 1.5170, 1.5170, 1.5170,
         1.7751, 1.7751, 1.7751, 1.7720, 1.7750, 1.7750, 1.7751, 1.7526, 1.7553,
         1.4396, 1.4441, 1.4441, 1.4441, 1.4359, 1.4441, 1.4403, 1.4440, 1.4441],
        [1.3212, 1.3193, 1.3034, 1.2946, 1.3182, 1.3166, 1.3178, 1.3183, 1.3183,
         1.2960, 1.2894, 1.2856, 1.2851, 1.2966, 1.2815, 1.2928, 1.2962, 1.2689,
         1.6483, 1.6220, 1.6453, 1.6447, 1.6441, 1.6442, 1.6464, 1.6478, 1.6478,
         3.4930, 3.2831, 3.2086, 3.2667, 3.4177, 3.2355, 3.4678, 3.2165, 3.1952,
         1.6475, 1.6400, 1.6384, 1.6415, 1.6444, 1.6204, 1.6458, 1.5853, 1.6117,
         1.3072, 1.3015, 1.2917, 1.3063, 1.3021, 1.2944, 1.3067, 1.3064, 1.3086],
        [1.4562, 1.4520, 1.4087, 1.4119, 1.4495, 1.4561, 1.4546, 1.4562, 1.4562,
         1.4328, 1.4302, 1.4252, 1.4206, 1.4339, 1.3939, 1.4280, 1.4339, 1.4292,
         1.7625, 1.7537, 1.7528, 1.7608, 1.7781, 1.7768, 1.7570, 1.7782, 1.7782,
         1.4780, 1.4837, 1.5198, 1.5146, 1.4835, 1.5184, 1.5067, 1.5198, 1.5167,
         2.2006, 2.1807, 2.1694, 2.1871, 2.2307, 2.2487, 2.2151, 2.3179, 2.3150,
         1.4320, 1.4223, 1.4366, 1.4469, 1.4344, 1.4437, 1.4149, 1.4409, 1.4469],
        [1.3438, 1.2510, 1.2465, 1.2658, 1.2588, 1.2692, 1.2680, 1.2075, 1.2075,
         1.2481, 1.2086, 1.2086, 1.2112, 1.2849, 1.1663, 1.1298, 1.2849, 1.1914,
         1.6027, 1.5789, 1.5603, 1.5556, 1.5793, 1.5753, 1.5954, 1.5807, 1.5807,
         1.3470, 1.3198, 1.3199, 1.3369, 1.3217, 1.3649, 1.3671, 1.3410, 1.3200,
         1.5754, 1.5749, 1.5807, 1.5702, 1.5461, 1.5499, 1.6110, 1.4993, 1.4684,
         4.0978, 3.6287, 3.7177, 3.7020, 3.7163, 3.3975, 4.0940, 3.6766, 3.4293]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 282 : 1779.1178821682324
Test loss for epoch 282 : 195.0422672024214
Test Precision for epoch 282 : 0.26153846153846155
Test Recall for epoch 282 : 0.26153846153846155
Test F1 for epoch 282 : 0.26153846153846155


theta for epoch 283 : tensor([[3.6260, 3.6473, 3.7909, 3.7387, 3.7227, 3.6076, 3.6487, 3.5482, 3.5482,
         1.2626, 1.2431, 1.2427, 1.2446, 1.2793, 1.2264, 1.1972, 1.2793, 1.2299,
         1.6023, 1.5867, 1.6108, 1.5937, 1.5993, 1.6009, 1.6080, 1.6009, 1.6009,
         1.3306, 1.3419, 1.3285, 1.3494, 1.3303, 1.3603, 1.3534, 1.3408, 1.3285,
         1.5979, 1.6137, 1.6028, 1.5992, 1.6060, 1.5961, 1.6143, 1.5684, 1.5731,
         1.2420, 1.2675, 1.2597, 1.2764, 1.2370, 1.2291, 1.2221, 1.2969, 1.2566],
        [1.3665, 1.2154, 1.2050, 1.2480, 1.2483, 1.2607, 1.2546, 1.1600, 1.1600,
         3.6083, 3.6944, 3.5390, 3.9278, 3.6084, 4.2625, 3.4746, 3.5636, 4.0337,
         1.5662, 1.5537, 1.5280, 1.5260, 1.5472, 1.5567, 1.5815, 1.5567, 1.5567,
         1.3338, 1.3003, 1.2941, 1.3521, 1.2940, 1.3896, 1.3698, 1.3384, 1.2909,
         1.5360, 1.5928, 1.5560, 1.5427, 1.5377, 1.5758, 1.5955, 1.4282, 1.5269,
         1.1373, 1.2509, 1.2238, 1.2730, 1.1313, 1.1374, 1.0730, 1.3341, 1.2140],
        [1.4514, 1.4513, 1.4497, 1.4469, 1.4473, 1.4514, 1.4471, 1.4514, 1.4514,
         1.4347, 1.4341, 1.4347, 1.4347, 1.4347, 1.4161, 1.4347, 1.4336, 1.4313,
         2.2074, 2.2077, 2.2244, 2.1998, 2.1814, 2.1796, 2.2088, 2.1787, 2.1787,
         1.5032, 1.5015, 1.5089, 1.5089, 1.5032, 1.5089, 1.5089, 1.5089, 1.5089,
         1.7782, 1.7783, 1.7783, 1.7751, 1.7782, 1.7782, 1.7783, 1.7557, 1.7584,
         1.4381, 1.4426, 1.4426, 1.4426, 1.4344, 1.4426, 1.4388, 1.4426, 1.4426],
        [1.3192, 1.3173, 1.3014, 1.2927, 1.3163, 1.3147, 1.3158, 1.3163, 1.3163,
         1.2996, 1.2930, 1.2892, 1.2887, 1.3003, 1.2851, 1.2964, 1.2999, 1.2725,
         1.6491, 1.6228, 1.6460, 1.6455, 1.6449, 1.6449, 1.6471, 1.6486, 1.6486,
         3.4858, 3.2759, 3.2014, 3.2595, 3.4106, 3.2283, 3.4607, 3.2092, 3.1880,
         1.6507, 1.6432, 1.6416, 1.6447, 1.6476, 1.6236, 1.6490, 1.5885, 1.6149,
         1.3058, 1.3001, 1.2903, 1.3049, 1.3007, 1.2929, 1.3053, 1.3050, 1.3072],
        [1.4542, 1.4500, 1.4067, 1.4100, 1.4475, 1.4541, 1.4526, 1.4542, 1.4542,
         1.4364, 1.4338, 1.4289, 1.4242, 1.4376, 1.3975, 1.4317, 1.4375, 1.4329,
         1.7632, 1.7544, 1.7534, 1.7614, 1.7788, 1.7775, 1.7577, 1.7789, 1.7789,
         1.4700, 1.4757, 1.5117, 1.5066, 1.4754, 1.5103, 1.4986, 1.5117, 1.5086,
         2.2036, 2.1837, 2.1725, 2.1902, 2.2337, 2.2518, 2.2182, 2.3209, 2.3180,
         1.4306, 1.4208, 1.4351, 1.4454, 1.4329, 1.4422, 1.4134, 1.4394, 1.4454],
        [1.3320, 1.2393, 1.2347, 1.2540, 1.2470, 1.2574, 1.2562, 1.1959, 1.1959,
         1.2465, 1.2067, 1.2068, 1.2094, 1.2833, 1.1640, 1.1272, 1.2833, 1.1895,
         1.5975, 1.5736, 1.5549, 1.5502, 1.5740, 1.5700, 1.5901, 1.5755, 1.5755,
         1.3326, 1.3053, 1.3056, 1.3225, 1.3073, 1.3505, 1.3527, 1.3266, 1.3056,
         1.5733, 1.5727, 1.5786, 1.5681, 1.5439, 1.5477, 1.6090, 1.4970, 1.4659,
         4.1097, 3.6400, 3.7290, 3.7133, 3.7277, 3.4089, 4.1059, 3.6879, 3.4406]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 283 : 1778.903473824212
Test loss for epoch 283 : 195.64539751889492
Test Precision for epoch 283 : 0.26153846153846155
Test Recall for epoch 283 : 0.26153846153846155
Test F1 for epoch 283 : 0.26153846153846155


theta for epoch 284 : tensor([[3.6287, 3.6501, 3.7937, 3.7415, 3.7254, 3.6104, 3.6515, 3.5511, 3.5511,
         1.2640, 1.2448, 1.2445, 1.2462, 1.2804, 1.2281, 1.1995, 1.2804, 1.2317,
         1.5980, 1.5825, 1.6065, 1.5894, 1.5950, 1.5967, 1.6037, 1.5967, 1.5967,
         1.3352, 1.3465, 1.3331, 1.3539, 1.3349, 1.3649, 1.3579, 1.3454, 1.3331,
         1.5977, 1.6134, 1.6025, 1.5989, 1.6057, 1.5958, 1.6140, 1.5682, 1.5728,
         1.2378, 1.2635, 1.2556, 1.2723, 1.2328, 1.2248, 1.2175, 1.2929, 1.2525],
        [1.3703, 1.2191, 1.2087, 1.2518, 1.2520, 1.2645, 1.2584, 1.1637, 1.1637,
         3.6059, 3.6922, 3.5366, 3.9259, 3.6061, 4.2615, 3.4721, 3.5613, 4.0321,
         1.5654, 1.5529, 1.5272, 1.5252, 1.5464, 1.5558, 1.5806, 1.5559, 1.5559,
         1.3388, 1.3052, 1.2990, 1.3571, 1.2989, 1.3946, 1.3748, 1.3433, 1.2958,
         1.5377, 1.5945, 1.5577, 1.5444, 1.5394, 1.5776, 1.5972, 1.4301, 1.5286,
         1.1362, 1.2502, 1.2228, 1.2723, 1.1300, 1.1359, 1.0712, 1.3335, 1.2130],
        [1.4537, 1.4536, 1.4520, 1.4492, 1.4496, 1.4537, 1.4494, 1.4537, 1.4537,
         1.4364, 1.4357, 1.4364, 1.4363, 1.4364, 1.4178, 1.4364, 1.4352, 1.4330,
         2.2037, 2.2040, 2.2207, 2.1963, 2.1779, 2.1761, 2.2053, 2.1752, 2.1752,
         1.5083, 1.5066, 1.5140, 1.5140, 1.5083, 1.5140, 1.5140, 1.5140, 1.5140,
         1.7781, 1.7782, 1.7782, 1.7750, 1.7781, 1.7781, 1.7782, 1.7556, 1.7583,
         1.4343, 1.4389, 1.4389, 1.4389, 1.4307, 1.4388, 1.4350, 1.4388, 1.4389],
        [1.3215, 1.3197, 1.3037, 1.2949, 1.3186, 1.3170, 1.3181, 1.3186, 1.3186,
         1.3013, 1.2947, 1.2909, 1.2904, 1.3019, 1.2868, 1.2981, 1.3015, 1.2742,
         1.6451, 1.6189, 1.6421, 1.6416, 1.6410, 1.6410, 1.6432, 1.6447, 1.6447,
         3.4904, 3.2806, 3.2061, 3.2642, 3.4152, 3.2330, 3.4653, 3.2139, 3.1927,
         1.6506, 1.6431, 1.6415, 1.6446, 1.6475, 1.6235, 1.6489, 1.5884, 1.6148,
         1.3020, 1.2964, 1.2866, 1.3012, 1.2970, 1.2892, 1.3016, 1.3013, 1.3035],
        [1.4565, 1.4523, 1.4090, 1.4123, 1.4498, 1.4564, 1.4549, 1.4565, 1.4565,
         1.4381, 1.4355, 1.4306, 1.4259, 1.4392, 1.3992, 1.4334, 1.4392, 1.4345,
         1.7592, 1.7505, 1.7495, 1.7575, 1.7749, 1.7736, 1.7538, 1.7750, 1.7750,
         1.4751, 1.4807, 1.5168, 1.5116, 1.4805, 1.5154, 1.5037, 1.5168, 1.5137,
         2.2035, 2.1836, 2.1724, 2.1900, 2.2336, 2.2517, 2.2181, 2.3208, 2.3179,
         1.4268, 1.4171, 1.4314, 1.4417, 1.4291, 1.4384, 1.4096, 1.4356, 1.4417],
        [1.3260, 1.2331, 1.2285, 1.2479, 1.2408, 1.2513, 1.2501, 1.1897, 1.1897,
         1.2442, 1.2047, 1.2048, 1.2073, 1.2804, 1.1617, 1.1260, 1.2805, 1.1876,
         1.5893, 1.5654, 1.5468, 1.5419, 1.5658, 1.5618, 1.5820, 1.5673, 1.5673,
         1.3310, 1.3037, 1.3039, 1.3209, 1.3057, 1.3490, 1.3512, 1.3250, 1.3039,
         1.5692, 1.5686, 1.5746, 1.5640, 1.5397, 1.5436, 1.6050, 1.4927, 1.4615,
         4.1182, 3.6480, 3.7371, 3.7214, 3.7358, 3.4169, 4.1145, 3.6959, 3.4486]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 284 : 1778.7293182773517
Test loss for epoch 284 : 195.7666947127389
Test Precision for epoch 284 : 0.26153846153846155
Test Recall for epoch 284 : 0.26153846153846155
Test F1 for epoch 284 : 0.26153846153846155


theta for epoch 285 : tensor([[3.6287, 3.6500, 3.7936, 3.7414, 3.7253, 3.6104, 3.6514, 3.5510, 3.5510,
         1.2634, 1.2447, 1.2444, 1.2460, 1.2791, 1.2280, 1.2008, 1.2792, 1.2319,
         1.5965, 1.5810, 1.6049, 1.5880, 1.5936, 1.5952, 1.6022, 1.5952, 1.5952,
         1.3461, 1.3574, 1.3441, 1.3648, 1.3459, 1.3757, 1.3688, 1.3563, 1.3442,
         1.5954, 1.6111, 1.6002, 1.5966, 1.6034, 1.5934, 1.6116, 1.5659, 1.5705,
         1.2342, 1.2600, 1.2520, 1.2688, 1.2292, 1.2211, 1.2145, 1.2894, 1.2489],
        [1.3780, 1.2274, 1.2169, 1.2599, 1.2602, 1.2726, 1.2665, 1.1722, 1.1722,
         3.5982, 3.6845, 3.5287, 3.9187, 3.5984, 4.2550, 3.4641, 3.5536, 4.0251,
         1.5696, 1.5572, 1.5316, 1.5297, 1.5508, 1.5602, 1.5848, 1.5602, 1.5602,
         1.3506, 1.3170, 1.3109, 1.3689, 1.3108, 1.4064, 1.3866, 1.3551, 1.3077,
         1.5408, 1.5974, 1.5608, 1.5475, 1.5425, 1.5805, 1.6000, 1.4335, 1.5318,
         1.1386, 1.2529, 1.2252, 1.2750, 1.1323, 1.1380, 1.0751, 1.3363, 1.2153],
        [1.4556, 1.4556, 1.4540, 1.4512, 1.4516, 1.4557, 1.4514, 1.4557, 1.4557,
         1.4356, 1.4349, 1.4355, 1.4355, 1.4356, 1.4169, 1.4355, 1.4344, 1.4322,
         2.2021, 2.2023, 2.2191, 2.1947, 2.1763, 2.1745, 2.2037, 2.1736, 2.1736,
         1.5189, 1.5173, 1.5247, 1.5247, 1.5190, 1.5247, 1.5247, 1.5247, 1.5247,
         1.7755, 1.7756, 1.7756, 1.7725, 1.7755, 1.7755, 1.7756, 1.7531, 1.7557,
         1.4307, 1.4352, 1.4352, 1.4352, 1.4270, 1.4352, 1.4314, 1.4352, 1.4352],
        [1.3234, 1.3215, 1.3056, 1.2968, 1.3205, 1.3189, 1.3200, 1.3205, 1.3205,
         1.3005, 1.2939, 1.2901, 1.2896, 1.3011, 1.2859, 1.2973, 1.3007, 1.2734,
         1.6434, 1.6171, 1.6404, 1.6398, 1.6392, 1.6392, 1.6414, 1.6429, 1.6429,
         3.5002, 3.2904, 3.2160, 3.2740, 3.4250, 3.2428, 3.4750, 3.2238, 3.2026,
         1.6480, 1.6405, 1.6389, 1.6420, 1.6449, 1.6209, 1.6463, 1.5858, 1.6122,
         1.2984, 1.2928, 1.2829, 1.2976, 1.2933, 1.2856, 1.2979, 1.2977, 1.2998],
        [1.4585, 1.4543, 1.4110, 1.4142, 1.4518, 1.4584, 1.4569, 1.4585, 1.4585,
         1.4373, 1.4347, 1.4297, 1.4251, 1.4384, 1.3984, 1.4325, 1.4384, 1.4337,
         1.7575, 1.7487, 1.7478, 1.7558, 1.7731, 1.7718, 1.7520, 1.7733, 1.7733,
         1.4858, 1.4914, 1.5275, 1.5223, 1.4912, 1.5260, 1.5144, 1.5275, 1.5244,
         2.2010, 2.1811, 2.1699, 2.1876, 2.2311, 2.2492, 2.2156, 2.3182, 2.3153,
         1.4232, 1.4135, 1.4278, 1.4380, 1.4255, 1.4348, 1.4060, 1.4320, 1.4381],
        [1.3273, 1.2340, 1.2294, 1.2489, 1.2418, 1.2523, 1.2511, 1.1903, 1.1903,
         1.2429, 1.2044, 1.2046, 1.2067, 1.2781, 1.1611, 1.1278, 1.2781, 1.1876,
         1.5873, 1.5633, 1.5448, 1.5398, 1.5637, 1.5597, 1.5800, 1.5652, 1.5652,
         1.3395, 1.3121, 1.3122, 1.3293, 1.3140, 1.3576, 1.3598, 1.3334, 1.3122,
         1.5663, 1.5658, 1.5716, 1.5610, 1.5368, 1.5407, 1.6022, 1.4897, 1.4585,
         4.1189, 3.6481, 3.7372, 3.7214, 3.7359, 3.4170, 4.1150, 3.6959, 3.4486]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 285 : 1779.2151341925755
Test loss for epoch 285 : 195.47443197543703
Test Precision for epoch 285 : 0.26153846153846155
Test Recall for epoch 285 : 0.26153846153846155
Test F1 for epoch 285 : 0.26153846153846155


theta for epoch 286 : tensor([[3.6295, 3.6509, 3.7944, 3.7423, 3.7261, 3.6112, 3.6523, 3.5519, 3.5519,
         1.2641, 1.2459, 1.2456, 1.2471, 1.2794, 1.2291, 1.2030, 1.2794, 1.2332,
         1.5993, 1.5838, 1.6078, 1.5910, 1.5965, 1.5982, 1.6051, 1.5982, 1.5982,
         1.3412, 1.3526, 1.3394, 1.3599, 1.3410, 1.3707, 1.3638, 1.3515, 1.3394,
         1.5943, 1.6100, 1.5992, 1.5956, 1.6023, 1.5923, 1.6105, 1.5648, 1.5695,
         1.2350, 1.2610, 1.2529, 1.2698, 1.2299, 1.2218, 1.2157, 1.2906, 1.2497],
        [1.3775, 1.2277, 1.2172, 1.2601, 1.2604, 1.2728, 1.2667, 1.1730, 1.1730,
         3.5977, 3.6841, 3.5281, 3.9186, 3.5980, 4.2557, 3.4633, 3.5531, 4.0252,
         1.5724, 1.5601, 1.5344, 1.5326, 1.5537, 1.5632, 1.5877, 1.5632, 1.5632,
         1.3485, 1.3149, 1.3090, 1.3668, 1.3088, 1.4040, 1.3843, 1.3531, 1.3059,
         1.5408, 1.5972, 1.5607, 1.5474, 1.5424, 1.5803, 1.5998, 1.4335, 1.5316,
         1.1390, 1.2538, 1.2259, 1.2759, 1.1325, 1.1380, 1.0765, 1.3376, 1.2159],
        [1.4539, 1.4538, 1.4522, 1.4494, 1.4498, 1.4539, 1.4496, 1.4539, 1.4539,
         1.4364, 1.4357, 1.4364, 1.4363, 1.4364, 1.4178, 1.4364, 1.4352, 1.4330,
         2.2050, 2.2052, 2.2220, 2.1975, 2.1791, 2.1773, 2.2065, 2.1764, 2.1764,
         1.5145, 1.5129, 1.5203, 1.5203, 1.5145, 1.5203, 1.5203, 1.5203, 1.5203,
         1.7746, 1.7747, 1.7747, 1.7716, 1.7746, 1.7746, 1.7747, 1.7522, 1.7548,
         1.4323, 1.4368, 1.4368, 1.4368, 1.4287, 1.4368, 1.4330, 1.4368, 1.4368],
        [1.3213, 1.3195, 1.3036, 1.2948, 1.3185, 1.3169, 1.3180, 1.3186, 1.3186,
         1.3013, 1.2947, 1.2909, 1.2904, 1.3019, 1.2868, 1.2981, 1.3015, 1.2742,
         1.6465, 1.6202, 1.6435, 1.6429, 1.6423, 1.6423, 1.6445, 1.6460, 1.6460,
         3.4967, 3.2869, 3.2126, 3.2706, 3.4215, 3.2394, 3.4716, 3.2204, 3.1991,
         1.6471, 1.6396, 1.6380, 1.6411, 1.6440, 1.6200, 1.6454, 1.5849, 1.6113,
         1.3000, 1.2944, 1.2846, 1.2992, 1.2949, 1.2871, 1.2996, 1.2994, 1.3014],
        [1.4567, 1.4525, 1.4092, 1.4124, 1.4500, 1.4566, 1.4551, 1.4567, 1.4567,
         1.4381, 1.4355, 1.4306, 1.4259, 1.4392, 1.3993, 1.4333, 1.4392, 1.4345,
         1.7605, 1.7518, 1.7509, 1.7588, 1.7762, 1.7749, 1.7550, 1.7763, 1.7763,
         1.4813, 1.4870, 1.5230, 1.5179, 1.4868, 1.5216, 1.5100, 1.5231, 1.5200,
         2.2001, 2.1803, 2.1690, 2.1867, 2.2302, 2.2483, 2.2147, 2.3173, 2.3144,
         1.4248, 1.4151, 1.4294, 1.4396, 1.4272, 1.4364, 1.4077, 1.4336, 1.4397],
        [1.3250, 1.2304, 1.2259, 1.2455, 1.2384, 1.2489, 1.2477, 1.1860, 1.1860,
         1.2424, 1.2043, 1.2045, 1.2064, 1.2770, 1.1607, 1.1287, 1.2770, 1.1878,
         1.5885, 1.5644, 1.5459, 1.5406, 1.5646, 1.5606, 1.5811, 1.5660, 1.5660,
         1.3340, 1.3065, 1.3063, 1.3239, 1.3084, 1.3525, 1.3546, 1.3279, 1.3063,
         1.5637, 1.5634, 1.5690, 1.5584, 1.5343, 1.5382, 1.5999, 1.4870, 1.4559,
         4.1242, 3.6529, 3.7421, 3.7262, 3.7408, 3.4218, 4.1204, 3.7007, 3.4534]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 286 : 1778.9843643101453
Test loss for epoch 286 : 195.7006428363227
Test Precision for epoch 286 : 0.26153846153846155
Test Recall for epoch 286 : 0.26153846153846155
Test F1 for epoch 286 : 0.26153846153846155


theta for epoch 287 : tensor([[3.6267, 3.6480, 3.7915, 3.7394, 3.7232, 3.6083, 3.6494, 3.5490, 3.5490,
         1.2657, 1.2479, 1.2476, 1.2489, 1.2806, 1.2310, 1.2058, 1.2806, 1.2354,
         1.6028, 1.5873, 1.6112, 1.5945, 1.6001, 1.6017, 1.6085, 1.6017, 1.6017,
         1.3328, 1.3442, 1.3311, 1.3515, 1.3327, 1.3622, 1.3554, 1.3431, 1.3311,
         1.5960, 1.6115, 1.6008, 1.5972, 1.6040, 1.5939, 1.6121, 1.5665, 1.5712,
         1.2383, 1.2636, 1.2554, 1.2725, 1.2333, 1.2253, 1.2195, 1.2936, 1.2522],
        [1.3737, 1.2252, 1.2145, 1.2574, 1.2576, 1.2701, 1.2640, 1.1713, 1.1713,
         3.6001, 3.6865, 3.5304, 3.9214, 3.6004, 4.2593, 3.4655, 3.5555, 4.0283,
         1.5732, 1.5609, 1.5350, 1.5336, 1.5548, 1.5642, 1.5885, 1.5642, 1.5642,
         1.3417, 1.3082, 1.3027, 1.3599, 1.3022, 1.3969, 1.3773, 1.3463, 1.2995,
         1.5406, 1.5969, 1.5606, 1.5473, 1.5422, 1.5801, 1.5994, 1.4332, 1.5315,
         1.1392, 1.2531, 1.2248, 1.2753, 1.1330, 1.1387, 1.0780, 1.3374, 1.2147],
        [1.4513, 1.4513, 1.4496, 1.4468, 1.4472, 1.4513, 1.4470, 1.4513, 1.4513,
         1.4375, 1.4369, 1.4375, 1.4375, 1.4375, 1.4189, 1.4375, 1.4364, 1.4342,
         2.2079, 2.2081, 2.2248, 2.2003, 2.1819, 2.1801, 2.2093, 2.1792, 2.1792,
         1.5057, 1.5041, 1.5115, 1.5115, 1.5058, 1.5115, 1.5115, 1.5115, 1.5115,
         1.7759, 1.7760, 1.7760, 1.7728, 1.7758, 1.7758, 1.7760, 1.7534, 1.7561,
         1.4351, 1.4396, 1.4396, 1.4396, 1.4314, 1.4396, 1.4358, 1.4395, 1.4396],
        [1.3186, 1.3168, 1.3009, 1.2921, 1.3157, 1.3141, 1.3152, 1.3158, 1.3158,
         1.3024, 1.2958, 1.2920, 1.2915, 1.3030, 1.2879, 1.2993, 1.3026, 1.2754,
         1.6495, 1.6233, 1.6465, 1.6460, 1.6454, 1.6454, 1.6476, 1.6491, 1.6491,
         3.4895, 3.2796, 3.2052, 3.2632, 3.4142, 3.2320, 3.4644, 3.2130, 3.1917,
         1.6483, 1.6408, 1.6392, 1.6423, 1.6453, 1.6212, 1.6466, 1.5861, 1.6125,
         1.3028, 1.2971, 1.2873, 1.3019, 1.2977, 1.2899, 1.3023, 1.3021, 1.3042],
        [1.4541, 1.4500, 1.4067, 1.4098, 1.4474, 1.4541, 1.4526, 1.4541, 1.4541,
         1.4392, 1.4367, 1.4317, 1.4271, 1.4404, 1.4005, 1.4345, 1.4403, 1.4357,
         1.7635, 1.7548, 1.7539, 1.7619, 1.7792, 1.7779, 1.7581, 1.7793, 1.7793,
         1.4725, 1.4782, 1.5143, 1.5091, 1.4779, 1.5129, 1.5012, 1.5143, 1.5112,
         2.2013, 2.1815, 2.1703, 2.1879, 2.2314, 2.2495, 2.2160, 2.3184, 2.3155,
         1.4276, 1.4178, 1.4321, 1.4424, 1.4299, 1.4392, 1.4105, 1.4364, 1.4424],
        [1.3422, 1.2467, 1.2424, 1.2619, 1.2549, 1.2654, 1.2642, 1.2017, 1.2017,
         1.2523, 1.2143, 1.2146, 1.2165, 1.2866, 1.1705, 1.1391, 1.2866, 1.1980,
         1.6019, 1.5778, 1.5595, 1.5539, 1.5777, 1.5737, 1.5945, 1.5792, 1.5792,
         1.3402, 1.3129, 1.3121, 1.3303, 1.3145, 1.3590, 1.3609, 1.3341, 1.3121,
         1.5736, 1.5737, 1.5789, 1.5684, 1.5445, 1.5486, 1.6101, 1.4974, 1.4665,
         4.1058, 3.6340, 3.7232, 3.7073, 3.7219, 3.4027, 4.1019, 3.6818, 3.4345]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 287 : 1779.2014075519328
Test loss for epoch 287 : 195.19527264631358
Test Precision for epoch 287 : 0.26153846153846155
Test Recall for epoch 287 : 0.26153846153846155
Test F1 for epoch 287 : 0.26153846153846155


theta for epoch 288 : tensor([[3.6261, 3.6473, 3.7909, 3.7388, 3.7226, 3.6077, 3.6488, 3.5484, 3.5484,
         1.2641, 1.2465, 1.2463, 1.2476, 1.2788, 1.2296, 1.2050, 1.2788, 1.2342,
         1.5990, 1.5836, 1.6075, 1.5909, 1.5964, 1.5981, 1.6048, 1.5981, 1.5981,
         1.3322, 1.3436, 1.3306, 1.3509, 1.3322, 1.3615, 1.3547, 1.3425, 1.3307,
         1.5968, 1.6123, 1.6016, 1.5980, 1.6047, 1.5947, 1.6127, 1.5673, 1.5719,
         1.2445, 1.2694, 1.2611, 1.2784, 1.2396, 1.2318, 1.2261, 1.2998, 1.2578],
        [1.3645, 1.2172, 1.2063, 1.2491, 1.2494, 1.2618, 1.2557, 1.1639, 1.1639,
         3.6073, 3.6938, 3.5375, 3.9290, 3.6076, 4.2677, 3.4725, 3.5627, 4.0361,
         1.5650, 1.5527, 1.5268, 1.5256, 1.5468, 1.5562, 1.5804, 1.5563, 1.5563,
         1.3353, 1.3019, 1.2967, 1.3535, 1.2960, 1.3904, 1.3709, 1.3400, 1.2935,
         1.5362, 1.5924, 1.5562, 1.5428, 1.5377, 1.5756, 1.5948, 1.4284, 1.5269,
         1.1372, 1.2506, 1.2220, 1.2730, 1.1311, 1.1370, 1.0767, 1.3356, 1.2117],
        [1.4483, 1.4483, 1.4466, 1.4438, 1.4443, 1.4483, 1.4440, 1.4483, 1.4483,
         1.4359, 1.4352, 1.4358, 1.4358, 1.4359, 1.4173, 1.4359, 1.4347, 1.4325,
         2.2046, 2.2048, 2.2215, 2.1971, 2.1787, 2.1769, 2.2061, 2.1760, 2.1760,
         1.5053, 1.5037, 1.5111, 1.5111, 1.5054, 1.5111, 1.5111, 1.5111, 1.5111,
         1.7766, 1.7767, 1.7767, 1.7736, 1.7766, 1.7766, 1.7767, 1.7542, 1.7569,
         1.4415, 1.4460, 1.4460, 1.4460, 1.4378, 1.4460, 1.4422, 1.4459, 1.4460],
        [1.3153, 1.3136, 1.2976, 1.2888, 1.3125, 1.3109, 1.3120, 1.3126, 1.3126,
         1.3007, 1.2942, 1.2904, 1.2899, 1.3013, 1.2862, 1.2977, 1.3009, 1.2737,
         1.6459, 1.6196, 1.6429, 1.6424, 1.6417, 1.6418, 1.6440, 1.6455, 1.6455,
         3.4897, 3.2799, 3.2054, 3.2635, 3.4145, 3.2323, 3.4647, 3.2133, 3.1920,
         1.6491, 1.6416, 1.6400, 1.6431, 1.6460, 1.6220, 1.6474, 1.5868, 1.6133,
         1.3092, 1.3035, 1.2937, 1.3083, 1.3041, 1.2963, 1.3088, 1.3085, 1.3106],
        [1.4512, 1.4470, 1.4037, 1.4068, 1.4445, 1.4511, 1.4496, 1.4511, 1.4511,
         1.4376, 1.4350, 1.4300, 1.4255, 1.4387, 1.3988, 1.4328, 1.4387, 1.4340,
         1.7600, 1.7513, 1.7504, 1.7583, 1.7756, 1.7743, 1.7545, 1.7758, 1.7758,
         1.4721, 1.4779, 1.5139, 1.5088, 1.4776, 1.5125, 1.5008, 1.5139, 1.5108,
         2.2021, 2.1823, 2.1710, 2.1887, 2.2321, 2.2503, 2.2168, 2.3191, 2.3162,
         1.4340, 1.4242, 1.4386, 1.4488, 1.4364, 1.4456, 1.4169, 1.4428, 1.4488],
        [1.3549, 1.2582, 1.2541, 1.2737, 1.2667, 1.2772, 1.2759, 1.2124, 1.2124,
         1.2575, 1.2193, 1.2195, 1.2215, 1.2918, 1.1751, 1.1435, 1.2918, 1.2030,
         1.6066, 1.5825, 1.5644, 1.5584, 1.5821, 1.5782, 1.5992, 1.5836, 1.5836,
         1.3502, 1.3228, 1.3215, 1.3404, 1.3243, 1.3693, 1.3709, 1.3440, 1.3215,
         1.5807, 1.5811, 1.5861, 1.5756, 1.5518, 1.5560, 1.6175, 1.5049, 1.4742,
         4.0942, 3.6218, 3.7111, 3.6952, 3.7098, 3.3904, 4.0902, 3.6696, 3.4223]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 288 : 1779.0172821196124
Test loss for epoch 288 : 195.13428315578818
Test Precision for epoch 288 : 0.26153846153846155
Test Recall for epoch 288 : 0.26153846153846155
Test F1 for epoch 288 : 0.26153846153846155


theta for epoch 289 : tensor([[3.6224, 3.6435, 3.7871, 3.7350, 3.7187, 3.6039, 3.6450, 3.5445, 3.5445,
         1.2595, 1.2425, 1.2416, 1.2433, 1.2741, 1.2254, 1.2022, 1.2741, 1.2303,
         1.5955, 1.5801, 1.6039, 1.5874, 1.5930, 1.5946, 1.6013, 1.5946, 1.5946,
         1.3399, 1.3513, 1.3384, 1.3585, 1.3399, 1.3691, 1.3624, 1.3502, 1.3385,
         1.5967, 1.6121, 1.6015, 1.5979, 1.6046, 1.5945, 1.6126, 1.5672, 1.5719,
         1.2524, 1.2768, 1.2684, 1.2859, 1.2475, 1.2397, 1.2341, 1.3075, 1.2651],
        [1.3701, 1.2240, 1.2130, 1.2558, 1.2560, 1.2685, 1.2624, 1.1714, 1.1714,
         3.5990, 3.6856, 3.5292, 3.9212, 3.5993, 4.2606, 3.4640, 3.5544, 4.0285,
         1.5669, 1.5547, 1.5288, 1.5278, 1.5490, 1.5584, 1.5822, 1.5584, 1.5584,
         1.3442, 1.3108, 1.3059, 1.3623, 1.3050, 1.3989, 1.3795, 1.3489, 1.3027,
         1.5404, 1.5963, 1.5604, 1.5470, 1.5419, 1.5796, 1.5986, 1.4328, 1.5312,
         1.1470, 1.2596, 1.2307, 1.2820, 1.1410, 1.1470, 1.0870, 1.3450, 1.2204],
        [1.4486, 1.4485, 1.4468, 1.4440, 1.4445, 1.4485, 1.4442, 1.4485, 1.4485,
         1.4304, 1.4298, 1.4304, 1.4304, 1.4304, 1.4118, 1.4304, 1.4293, 1.4271,
         2.2005, 2.2007, 2.2174, 2.1932, 2.1748, 2.1730, 2.2022, 2.1721, 2.1721,
         1.5119, 1.5103, 1.5177, 1.5177, 1.5120, 1.5177, 1.5177, 1.5177, 1.5177,
         1.7758, 1.7759, 1.7759, 1.7727, 1.7758, 1.7758, 1.7759, 1.7533, 1.7560,
         1.4484, 1.4528, 1.4528, 1.4528, 1.4447, 1.4528, 1.4491, 1.4528, 1.4528],
        [1.3153, 1.3137, 1.2977, 1.2889, 1.3126, 1.3109, 1.3121, 1.3127, 1.3127,
         1.2953, 1.2887, 1.2849, 1.2844, 1.2958, 1.2808, 1.2923, 1.2954, 1.2683,
         1.6416, 1.6153, 1.6386, 1.6380, 1.6374, 1.6374, 1.6396, 1.6411, 1.6411,
         3.4960, 3.2862, 3.2118, 3.2698, 3.4208, 3.2387, 3.4709, 3.2196, 3.1984,
         1.6482, 1.6407, 1.6391, 1.6422, 1.6451, 1.6211, 1.6465, 1.5860, 1.6124,
         1.3161, 1.3104, 1.3006, 1.3152, 1.3110, 1.3032, 1.3157, 1.3154, 1.3175],
        [1.4514, 1.4473, 1.4040, 1.4071, 1.4447, 1.4513, 1.4498, 1.4514, 1.4514,
         1.4322, 1.4296, 1.4246, 1.4200, 1.4333, 1.3934, 1.4274, 1.4333, 1.4286,
         1.7557, 1.7470, 1.7461, 1.7541, 1.7713, 1.7701, 1.7502, 1.7715, 1.7715,
         1.4788, 1.4845, 1.5205, 1.5154, 1.4842, 1.5191, 1.5074, 1.5205, 1.5174,
         2.2013, 2.1815, 2.1702, 2.1878, 2.2313, 2.2495, 2.2160, 2.3182, 2.3153,
         1.4410, 1.4311, 1.4454, 1.4556, 1.4433, 1.4524, 1.4239, 1.4497, 1.4557],
        [1.3689, 1.2714, 1.2674, 1.2871, 1.2801, 1.2905, 1.2893, 1.2251, 1.2251,
         1.2588, 1.2212, 1.2204, 1.2233, 1.2935, 1.1767, 1.1463, 1.2935, 1.2051,
         1.6104, 1.5863, 1.5684, 1.5621, 1.5857, 1.5818, 1.6030, 1.5872, 1.5872,
         1.3655, 1.3382, 1.3364, 1.3558, 1.3395, 1.3849, 1.3864, 1.3592, 1.3365,
         1.5862, 1.5869, 1.5916, 1.5811, 1.5575, 1.5619, 1.6232, 1.5108, 1.4803,
         4.0831, 3.6102, 3.6996, 3.6836, 3.6982, 3.3787, 4.0791, 3.6580, 3.4107]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 289 : 1779.5464576397362
Test loss for epoch 289 : 194.57299351643087
Test Precision for epoch 289 : 0.26153846153846155
Test Recall for epoch 289 : 0.26153846153846155
Test F1 for epoch 289 : 0.26153846153846155


theta for epoch 290 : tensor([[3.6212, 3.6423, 3.7858, 3.7338, 3.7175, 3.6027, 3.6438, 3.5433, 3.5433,
         1.2587, 1.2420, 1.2406, 1.2428, 1.2735, 1.2248, 1.2022, 1.2735, 1.2300,
         1.5961, 1.5808, 1.6045, 1.5881, 1.5936, 1.5953, 1.6019, 1.5953, 1.5953,
         1.3397, 1.3511, 1.3382, 1.3583, 1.3396, 1.3688, 1.3621, 1.3499, 1.3382,
         1.5957, 1.6110, 1.6005, 1.5969, 1.6035, 1.5935, 1.6115, 1.5662, 1.5708,
         1.2558, 1.2799, 1.2714, 1.2890, 1.2509, 1.2432, 1.2375, 1.3110, 1.2681],
        [1.3701, 1.2247, 1.2136, 1.2564, 1.2566, 1.2691, 1.2630, 1.1725, 1.1725,
         3.5983, 3.6849, 3.5285, 3.9209, 3.5986, 4.2611, 3.4631, 3.5536, 4.0285,
         1.5674, 1.5553, 1.5293, 1.5285, 1.5497, 1.5591, 1.5828, 1.5591, 1.5591,
         1.3439, 1.3105, 1.3059, 1.3620, 1.3048, 1.3985, 1.3792, 1.3487, 1.3027,
         1.5397, 1.5954, 1.5597, 1.5463, 1.5411, 1.5787, 1.5977, 1.4321, 1.5304,
         1.1492, 1.2613, 1.2322, 1.2838, 1.1432, 1.1494, 1.0893, 1.3473, 1.2218],
        [1.4490, 1.4489, 1.4473, 1.4445, 1.4450, 1.4490, 1.4447, 1.4490, 1.4490,
         1.4293, 1.4287, 1.4293, 1.4293, 1.4293, 1.4107, 1.4293, 1.4282, 1.4260,
         2.2009, 2.2010, 2.2177, 2.1935, 2.1751, 2.1733, 2.2025, 2.1724, 2.1724,
         1.5112, 1.5096, 1.5170, 1.5170, 1.5113, 1.5170, 1.5170, 1.5170, 1.5170,
         1.7744, 1.7745, 1.7745, 1.7714, 1.7744, 1.7744, 1.7745, 1.7520, 1.7547,
         1.4514, 1.4559, 1.4559, 1.4559, 1.4477, 1.4559, 1.4521, 1.4558, 1.4559],
        [1.3157, 1.3140, 1.2981, 1.2893, 1.3130, 1.3113, 1.3125, 1.3131, 1.3131,
         1.2942, 1.2877, 1.2838, 1.2834, 1.2948, 1.2797, 1.2912, 1.2944, 1.2672,
         1.6419, 1.6156, 1.6389, 1.6384, 1.6377, 1.6378, 1.6400, 1.6415, 1.6415,
         3.4957, 3.2859, 3.2115, 3.2695, 3.4204, 3.2383, 3.4706, 3.2193, 3.1981,
         1.6469, 1.6394, 1.6378, 1.6409, 1.6438, 1.6198, 1.6452, 1.5846, 1.6111,
         1.3192, 1.3135, 1.3037, 1.3183, 1.3141, 1.3063, 1.3188, 1.3185, 1.3205],
        [1.4518, 1.4477, 1.4045, 1.4075, 1.4451, 1.4517, 1.4503, 1.4518, 1.4518,
         1.4311, 1.4285, 1.4235, 1.4190, 1.4322, 1.3924, 1.4263, 1.4322, 1.4275,
         1.7560, 1.7473, 1.7464, 1.7544, 1.7716, 1.7704, 1.7505, 1.7718, 1.7718,
         1.4780, 1.4838, 1.5198, 1.5147, 1.4835, 1.5184, 1.5067, 1.5198, 1.5167,
         2.2000, 2.1802, 2.1689, 2.1865, 2.2300, 2.2482, 2.2147, 2.3169, 2.3140,
         1.4440, 1.4341, 1.4485, 1.4587, 1.4463, 1.4555, 1.4269, 1.4527, 1.4587],
        [1.3777, 1.2797, 1.2758, 1.2954, 1.2885, 1.2989, 1.2976, 1.2330, 1.2330,
         1.2618, 1.2243, 1.2226, 1.2264, 1.2970, 1.1795, 1.1495, 1.2970, 1.2084,
         1.6154, 1.5914, 1.5736, 1.5671, 1.5906, 1.5867, 1.6080, 1.5921, 1.5921,
         1.3709, 1.3437, 1.3417, 1.3613, 1.3449, 1.3905, 1.3919, 1.3647, 1.3417,
         1.5889, 1.5897, 1.5942, 1.5838, 1.5603, 1.5647, 1.6260, 1.5136, 1.4833,
         4.0760, 3.6026, 3.6920, 3.6760, 3.6906, 3.3710, 4.0720, 3.6503, 3.4031]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 290 : 1779.7154572100487
Test loss for epoch 290 : 194.48021517979782
Test Precision for epoch 290 : 0.26153846153846155
Test Recall for epoch 290 : 0.26153846153846155
Test F1 for epoch 290 : 0.26153846153846155


theta for epoch 291 : tensor([[3.6208, 3.6419, 3.7854, 3.7334, 3.7171, 3.6023, 3.6434, 3.5429, 3.5429,
         1.2623, 1.2456, 1.2437, 1.2464, 1.2775, 1.2283, 1.2057, 1.2775, 1.2337,
         1.5998, 1.5845, 1.6082, 1.5918, 1.5973, 1.5990, 1.6056, 1.5989, 1.5989,
         1.3325, 1.3439, 1.3310, 1.3512, 1.3325, 1.3617, 1.3550, 1.3428, 1.3310,
         1.5952, 1.6106, 1.6000, 1.5964, 1.6031, 1.5930, 1.6110, 1.5657, 1.5704,
         1.2543, 1.2782, 1.2696, 1.2874, 1.2495, 1.2418, 1.2358, 1.3096, 1.2662],
        [1.3638, 1.2186, 1.2075, 1.2502, 1.2504, 1.2629, 1.2568, 1.1665, 1.1665,
         3.6045, 3.6912, 3.5347, 3.9276, 3.6048, 4.2685, 3.4692, 3.5598, 4.0354,
         1.5662, 1.5541, 1.5279, 1.5273, 1.5485, 1.5579, 1.5816, 1.5579, 1.5579,
         1.3357, 1.3023, 1.2977, 1.3538, 1.2966, 1.3902, 1.3709, 1.3405, 1.2946,
         1.5357, 1.5916, 1.5557, 1.5424, 1.5371, 1.5748, 1.5938, 1.4280, 1.5265,
         1.1441, 1.2559, 1.2266, 1.2786, 1.1382, 1.1444, 1.0841, 1.3426, 1.2161],
        [1.4470, 1.4469, 1.4452, 1.4424, 1.4429, 1.4469, 1.4426, 1.4469, 1.4469,
         1.4330, 1.4324, 1.4330, 1.4330, 1.4330, 1.4144, 1.4330, 1.4319, 1.4297,
         2.2044, 2.2046, 2.2213, 2.1969, 2.1786, 2.1767, 2.2059, 2.1759, 2.1759,
         1.5043, 1.5026, 1.5101, 1.5101, 1.5043, 1.5101, 1.5100, 1.5101, 1.5101,
         1.7741, 1.7742, 1.7742, 1.7710, 1.7741, 1.7741, 1.7742, 1.7516, 1.7543,
         1.4500, 1.4544, 1.4544, 1.4544, 1.4463, 1.4544, 1.4507, 1.4544, 1.4544],
        [1.3136, 1.3119, 1.2960, 1.2872, 1.3109, 1.3092, 1.3104, 1.3110, 1.3110,
         1.2979, 1.2914, 1.2875, 1.2871, 1.2985, 1.2835, 1.2949, 1.2981, 1.2709,
         1.6458, 1.6195, 1.6428, 1.6422, 1.6416, 1.6417, 1.6439, 1.6453, 1.6453,
         3.4896, 3.2797, 3.2053, 3.2633, 3.4143, 3.2321, 3.4645, 3.2131, 3.1918,
         1.6466, 1.6391, 1.6375, 1.6406, 1.6435, 1.6195, 1.6449, 1.5843, 1.6108,
         1.3178, 1.3122, 1.3023, 1.3170, 1.3128, 1.3050, 1.3174, 1.3172, 1.3192],
        [1.4498, 1.4457, 1.4024, 1.4055, 1.4431, 1.4497, 1.4482, 1.4498, 1.4498,
         1.4347, 1.4322, 1.4272, 1.4227, 1.4359, 1.3961, 1.4300, 1.4359, 1.4312,
         1.7598, 1.7510, 1.7501, 1.7581, 1.7754, 1.7741, 1.7543, 1.7755, 1.7755,
         1.4710, 1.4768, 1.5128, 1.5077, 1.4765, 1.5114, 1.4997, 1.5129, 1.5097,
         2.1997, 2.1799, 2.1686, 2.1862, 2.2297, 2.2479, 2.2144, 2.3166, 2.3137,
         1.4426, 1.4327, 1.4471, 1.4572, 1.4449, 1.4540, 1.4255, 1.4513, 1.4573],
        [1.3793, 1.2812, 1.2774, 1.2970, 1.2901, 1.3004, 1.2992, 1.2344, 1.2344,
         1.2669, 1.2293, 1.2267, 1.2315, 1.3029, 1.1841, 1.1538, 1.3029, 1.2134,
         1.6209, 1.5968, 1.5790, 1.5724, 1.5960, 1.5921, 1.6135, 1.5975, 1.5975,
         1.3676, 1.3403, 1.3382, 1.3580, 1.3415, 1.3872, 1.3885, 1.3613, 1.3383,
         1.5902, 1.5912, 1.5956, 1.5851, 1.5617, 1.5662, 1.6274, 1.5151, 1.4848,
         4.0723, 3.5984, 3.6879, 3.6718, 3.6864, 3.3667, 4.0683, 3.6461, 3.3989]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 291 : 1779.4221891155998
Test loss for epoch 291 : 194.81934985445656
Test Precision for epoch 291 : 0.26153846153846155
Test Recall for epoch 291 : 0.26153846153846155
Test F1 for epoch 291 : 0.26153846153846155


theta for epoch 292 : tensor([[3.6235, 3.6446, 3.7882, 3.7362, 3.7198, 3.6051, 3.6462, 3.5457, 3.5457,
         1.2638, 1.2468, 1.2445, 1.2477, 1.2796, 1.2292, 1.2061, 1.2796, 1.2348,
         1.5999, 1.5845, 1.6083, 1.5918, 1.5974, 1.5990, 1.6057, 1.5990, 1.5990,
         1.3308, 1.3422, 1.3292, 1.3495, 1.3307, 1.3601, 1.3533, 1.3411, 1.3292,
         1.5950, 1.6103, 1.5998, 1.5962, 1.6029, 1.5928, 1.6108, 1.5655, 1.5701,
         1.2512, 1.2751, 1.2664, 1.2844, 1.2464, 1.2388, 1.2325, 1.3068, 1.2630],
        [1.3539, 1.2081, 1.1971, 1.2399, 1.2401, 1.2526, 1.2465, 1.1558, 1.1558,
         3.6151, 3.7018, 3.5452, 3.9386, 3.6153, 4.2803, 3.4795, 3.5703, 4.0466,
         1.5592, 1.5470, 1.5208, 1.5201, 1.5414, 1.5508, 1.5747, 1.5509, 1.5509,
         1.3273, 1.2938, 1.2891, 1.3454, 1.2881, 1.3820, 1.3626, 1.3321, 1.2860,
         1.5288, 1.5849, 1.5489, 1.5355, 1.5302, 1.5681, 1.5871, 1.4206, 1.5195,
         1.1347, 1.2466, 1.2170, 1.2694, 1.1288, 1.1351, 1.0742, 1.3340, 1.2064],
        [1.4459, 1.4458, 1.4442, 1.4414, 1.4418, 1.4459, 1.4416, 1.4458, 1.4458,
         1.4351, 1.4345, 1.4351, 1.4351, 1.4351, 1.4166, 1.4351, 1.4340, 1.4318,
         2.2051, 2.2053, 2.2220, 2.1976, 2.1793, 2.1774, 2.2066, 2.1766, 2.1766,
         1.5034, 1.5018, 1.5092, 1.5092, 1.5034, 1.5092, 1.5092, 1.5092, 1.5092,
         1.7744, 1.7745, 1.7745, 1.7713, 1.7744, 1.7744, 1.7745, 1.7520, 1.7546,
         1.4475, 1.4520, 1.4520, 1.4520, 1.4438, 1.4520, 1.4482, 1.4519, 1.4520],
        [1.3125, 1.3108, 1.2949, 1.2861, 1.3097, 1.3081, 1.3092, 1.3099, 1.3099,
         1.3001, 1.2936, 1.2897, 1.2893, 1.3007, 1.2856, 1.2971, 1.3003, 1.2731,
         1.6466, 1.6203, 1.6436, 1.6430, 1.6424, 1.6425, 1.6447, 1.6462, 1.6462,
         3.4889, 3.2790, 3.2045, 3.2626, 3.4136, 3.2314, 3.4638, 3.2123, 3.1911,
         1.6469, 1.6395, 1.6378, 1.6409, 1.6439, 1.6198, 1.6452, 1.5847, 1.6111,
         1.3154, 1.3097, 1.2999, 1.3145, 1.3103, 1.3025, 1.3150, 1.3148, 1.3167],
        [1.4487, 1.4446, 1.4013, 1.4044, 1.4420, 1.4486, 1.4472, 1.4487, 1.4487,
         1.4369, 1.4343, 1.4293, 1.4248, 1.4380, 1.3982, 1.4321, 1.4380, 1.4333,
         1.7605, 1.7518, 1.7509, 1.7589, 1.7761, 1.7749, 1.7550, 1.7763, 1.7763,
         1.4702, 1.4759, 1.5119, 1.5068, 1.4756, 1.5106, 1.4989, 1.5120, 1.5089,
         2.2000, 2.1802, 2.1690, 2.1866, 2.2300, 2.2482, 2.2147, 2.3169, 2.3140,
         1.4401, 1.4302, 1.4446, 1.4548, 1.4424, 1.4515, 1.4230, 1.4488, 1.4548],
        [1.3764, 1.2788, 1.2749, 1.2945, 1.2876, 1.2980, 1.2967, 1.2323, 1.2323,
         1.2683, 1.2304, 1.2270, 1.2326, 1.3053, 1.1846, 1.1538, 1.3053, 1.2144,
         1.6209, 1.5969, 1.5791, 1.5726, 1.5961, 1.5922, 1.6135, 1.5976, 1.5976,
         1.3658, 1.3386, 1.3366, 1.3562, 1.3398, 1.3853, 1.3867, 1.3595, 1.3367,
         1.5901, 1.5910, 1.5954, 1.5850, 1.5616, 1.5660, 1.6272, 1.5150, 1.4846,
         4.0730, 3.5987, 3.6882, 3.6720, 3.6867, 3.3669, 4.0690, 3.6463, 3.3992]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 292 : 1779.1869139874793
Test loss for epoch 292 : 195.4082274618458
Test Precision for epoch 292 : 0.26153846153846155
Test Recall for epoch 292 : 0.26153846153846155
Test F1 for epoch 292 : 0.26153846153846155


theta for epoch 293 : tensor([[3.6218, 3.6429, 3.7864, 3.7344, 3.7181, 3.6034, 3.6445, 3.5439, 3.5439,
         1.2590, 1.2421, 1.2394, 1.2430, 1.2751, 1.2244, 1.2015, 1.2751, 1.2302,
         1.5985, 1.5831, 1.6069, 1.5904, 1.5959, 1.5975, 1.6042, 1.5975, 1.5975,
         1.3391, 1.3505, 1.3374, 1.3577, 1.3390, 1.3684, 1.3616, 1.3494, 1.3374,
         1.5967, 1.6121, 1.6015, 1.5979, 1.6046, 1.5945, 1.6125, 1.5672, 1.5719,
         1.2528, 1.2765, 1.2679, 1.2859, 1.2481, 1.2405, 1.2337, 1.3084, 1.2645],
        [1.3734, 1.2272, 1.2162, 1.2590, 1.2592, 1.2716, 1.2655, 1.1745, 1.1745,
         3.5950, 3.6818, 3.5251, 3.9190, 3.5952, 4.2614, 3.4593, 3.5501, 4.0271,
         1.5716, 1.5594, 1.5334, 1.5326, 1.5537, 1.5631, 1.5869, 1.5632, 1.5632,
         1.3459, 1.3125, 1.3077, 1.3640, 1.3068, 1.4006, 1.3812, 1.3507, 1.3045,
         1.5428, 1.5986, 1.5627, 1.5494, 1.5442, 1.5819, 1.6009, 1.4353, 1.5335,
         1.1504, 1.2618, 1.2322, 1.2847, 1.1445, 1.1508, 1.0894, 1.3494, 1.2216],
        [1.4498, 1.4498, 1.4481, 1.4453, 1.4458, 1.4498, 1.4455, 1.4498, 1.4498,
         1.4299, 1.4292, 1.4299, 1.4298, 1.4299, 1.4113, 1.4299, 1.4287, 1.4265,
         2.2031, 2.2033, 2.2200, 2.1957, 2.1773, 2.1755, 2.2047, 2.1746, 2.1746,
         1.5107, 1.5091, 1.5165, 1.5165, 1.5107, 1.5165, 1.5164, 1.5165, 1.5165,
         1.7755, 1.7756, 1.7756, 1.7725, 1.7755, 1.7755, 1.7756, 1.7531, 1.7558,
         1.4479, 1.4524, 1.4524, 1.4524, 1.4442, 1.4524, 1.4486, 1.4523, 1.4524],
        [1.3166, 1.3149, 1.2990, 1.2902, 1.3138, 1.3122, 1.3133, 1.3140, 1.3140,
         1.2949, 1.2884, 1.2845, 1.2841, 1.2955, 1.2804, 1.2919, 1.2951, 1.2679,
         1.6446, 1.6182, 1.6415, 1.6410, 1.6404, 1.6404, 1.6426, 1.6441, 1.6441,
         3.4951, 3.2852, 3.2108, 3.2688, 3.4198, 3.2376, 3.4700, 3.2186, 3.1974,
         1.6481, 1.6407, 1.6390, 1.6421, 1.6451, 1.6210, 1.6464, 1.5859, 1.6123,
         1.3159, 1.3103, 1.3004, 1.3151, 1.3109, 1.3031, 1.3155, 1.3153, 1.3173],
        [1.4527, 1.4485, 1.4053, 1.4084, 1.4460, 1.4526, 1.4511, 1.4526, 1.4526,
         1.4316, 1.4291, 1.4241, 1.4195, 1.4328, 1.3929, 1.4269, 1.4327, 1.4281,
         1.7584, 1.7497, 1.7488, 1.7567, 1.7740, 1.7727, 1.7529, 1.7742, 1.7742,
         1.4775, 1.4832, 1.5192, 1.5141, 1.4829, 1.5178, 1.5062, 1.5193, 1.5162,
         2.2011, 2.1813, 2.1701, 2.1877, 2.2311, 2.2493, 2.2158, 2.3180, 2.3151,
         1.4404, 1.4306, 1.4450, 1.4552, 1.4427, 1.4520, 1.4233, 1.4492, 1.4552],
        [1.3762, 1.2801, 1.2760, 1.2955, 1.2885, 1.2989, 1.2977, 1.2344, 1.2344,
         1.2631, 1.2254, 1.2214, 1.2276, 1.3003, 1.1794, 1.1494, 1.3003, 1.2097,
         1.6185, 1.5946, 1.5767, 1.5705, 1.5940, 1.5901, 1.6112, 1.5954, 1.5954,
         1.3708, 1.3436, 1.3421, 1.3611, 1.3450, 1.3899, 1.3915, 1.3646, 1.3421,
         1.5911, 1.5918, 1.5964, 1.5860, 1.5625, 1.5668, 1.6280, 1.5160, 1.4855,
         4.0742, 3.5994, 3.6890, 3.6728, 3.6875, 3.3676, 4.0701, 3.6470, 3.4000]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 293 : 1779.829499785504
Test loss for epoch 293 : 194.34534398041228
Test Precision for epoch 293 : 0.26153846153846155
Test Recall for epoch 293 : 0.26153846153846155
Test F1 for epoch 293 : 0.26153846153846155


theta for epoch 294 : tensor([[3.6193, 3.6404, 3.7839, 3.7319, 3.7156, 3.6009, 3.6420, 3.5414, 3.5414,
         1.2592, 1.2422, 1.2392, 1.2431, 1.2757, 1.2242, 1.2009, 1.2757, 1.2302,
         1.5966, 1.5812, 1.6050, 1.5884, 1.5939, 1.5955, 1.6023, 1.5955, 1.5955,
         1.3406, 1.3519, 1.3387, 1.3593, 1.3404, 1.3700, 1.3632, 1.3508, 1.3388,
         1.5971, 1.6125, 1.6019, 1.5983, 1.6050, 1.5949, 1.6129, 1.5676, 1.5722,
         1.2548, 1.2784, 1.2698, 1.2878, 1.2500, 1.2424, 1.2352, 1.3105, 1.2664],
        [1.3835, 1.2365, 1.2257, 1.2684, 1.2686, 1.2810, 1.2750, 1.1833, 1.1833,
         3.5838, 3.6707, 3.5139, 3.9082, 3.5840, 4.2514, 3.4479, 3.5389, 4.0166,
         1.5784, 1.5662, 1.5404, 1.5393, 1.5604, 1.5697, 1.5936, 1.5698, 1.5698,
         1.3552, 1.3218, 1.3168, 1.3733, 1.3160, 1.4100, 1.3906, 1.3599, 1.3136,
         1.5506, 1.6064, 1.5705, 1.5572, 1.5521, 1.5897, 1.6087, 1.4435, 1.5414,
         1.1608, 1.2721, 1.2424, 1.2950, 1.1548, 1.1610, 1.0989, 1.3600, 1.2317],
        [1.4486, 1.4485, 1.4468, 1.4441, 1.4445, 1.4486, 1.4443, 1.4485, 1.4485,
         1.4301, 1.4294, 1.4300, 1.4300, 1.4301, 1.4115, 1.4300, 1.4289, 1.4267,
         2.2012, 2.2013, 2.2181, 2.1938, 2.1754, 2.1736, 2.2028, 2.1727, 2.1727,
         1.5118, 1.5101, 1.5176, 1.5176, 1.5118, 1.5176, 1.5175, 1.5176, 1.5176,
         1.7757, 1.7758, 1.7758, 1.7727, 1.7757, 1.7757, 1.7758, 1.7533, 1.7559,
         1.4491, 1.4536, 1.4536, 1.4536, 1.4455, 1.4536, 1.4498, 1.4536, 1.4536],
        [1.3155, 1.3138, 1.2979, 1.2891, 1.3127, 1.3111, 1.3122, 1.3128, 1.3128,
         1.2951, 1.2886, 1.2847, 1.2843, 1.2958, 1.2806, 1.2921, 1.2954, 1.2681,
         1.6426, 1.6162, 1.6395, 1.6390, 1.6384, 1.6384, 1.6406, 1.6421, 1.6421,
         3.4956, 3.2857, 3.2113, 3.2693, 3.4203, 3.2382, 3.4705, 3.2191, 3.1979,
         1.6484, 1.6410, 1.6393, 1.6424, 1.6453, 1.6213, 1.6467, 1.5861, 1.6126,
         1.3173, 1.3117, 1.3018, 1.3165, 1.3123, 1.3045, 1.3169, 1.3168, 1.3187],
        [1.4514, 1.4472, 1.4040, 1.4071, 1.4447, 1.4513, 1.4498, 1.4514, 1.4514,
         1.4318, 1.4292, 1.4242, 1.4197, 1.4329, 1.3930, 1.4270, 1.4329, 1.4283,
         1.7563, 1.7476, 1.7466, 1.7546, 1.7720, 1.7707, 1.7508, 1.7721, 1.7721,
         1.4785, 1.4843, 1.5203, 1.5152, 1.4840, 1.5189, 1.5073, 1.5204, 1.5172,
         2.2013, 2.1815, 2.1703, 2.1879, 2.2313, 2.2495, 2.2160, 2.3182, 2.3154,
         1.4416, 1.4318, 1.4462, 1.4564, 1.4440, 1.4532, 1.4245, 1.4504, 1.4565],
        [1.3680, 1.2736, 1.2694, 1.2887, 1.2817, 1.2921, 1.2908, 1.2289, 1.2289,
         1.2610, 1.2233, 1.2188, 1.2256, 1.2987, 1.1770, 1.1470, 1.2987, 1.2076,
         1.6139, 1.5900, 1.5720, 1.5661, 1.5896, 1.5857, 1.6065, 1.5911, 1.5911,
         1.3677, 1.3406, 1.3395, 1.3579, 1.3421, 1.3864, 1.3882, 1.3615, 1.3396,
         1.5893, 1.5898, 1.5946, 1.5842, 1.5606, 1.5648, 1.6259, 1.5141, 1.4836,
         4.0798, 3.6046, 3.6943, 3.6781, 3.6927, 3.3728, 4.0758, 3.6523, 3.4053]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 294 : 1780.3698154531583
Test loss for epoch 294 : 194.09072431907086
Test Precision for epoch 294 : 0.26153846153846155
Test Recall for epoch 294 : 0.26153846153846155
Test F1 for epoch 294 : 0.26153846153846155


theta for epoch 295 : tensor([[3.6181, 3.6391, 3.7826, 3.7307, 3.7143, 3.5996, 3.6407, 3.5401, 3.5401,
         1.2666, 1.2491, 1.2458, 1.2502, 1.2837, 1.2309, 1.2066, 1.2837, 1.2370,
         1.5969, 1.5814, 1.6053, 1.5885, 1.5941, 1.5957, 1.6026, 1.5957, 1.5957,
         1.3335, 1.3448, 1.3314, 1.3522, 1.3332, 1.3632, 1.3562, 1.3437, 1.3314,
         1.5956, 1.6111, 1.6004, 1.5968, 1.6035, 1.5935, 1.6116, 1.5661, 1.5708,
         1.2519, 1.2757, 1.2671, 1.2852, 1.2470, 1.2394, 1.2317, 1.3081, 1.2636],
        [1.3864, 1.2386, 1.2279, 1.2706, 1.2708, 1.2832, 1.2772, 1.1849, 1.1849,
         3.5816, 3.6686, 3.5117, 3.9065, 3.5819, 4.2504, 3.4456, 3.5367, 4.0151,
         1.5815, 1.5694, 1.5436, 1.5424, 1.5634, 1.5728, 1.5968, 1.5728, 1.5728,
         1.3543, 1.3209, 1.3156, 1.3724, 1.3151, 1.4091, 1.3896, 1.3589, 1.3125,
         1.5522, 1.6080, 1.5720, 1.5588, 1.5537, 1.5913, 1.6104, 1.4453, 1.5430,
         1.1626, 1.2739, 1.2442, 1.2969, 1.1566, 1.1628, 1.0998, 1.3621, 1.2335],
        [1.4468, 1.4468, 1.4451, 1.4423, 1.4427, 1.4468, 1.4425, 1.4468, 1.4468,
         1.4375, 1.4369, 1.4375, 1.4375, 1.4375, 1.4189, 1.4375, 1.4364, 1.4342,
         2.2015, 2.2017, 2.2184, 2.1941, 2.1758, 2.1739, 2.2032, 2.1731, 2.1731,
         1.5047, 1.5031, 1.5105, 1.5105, 1.5047, 1.5105, 1.5105, 1.5105, 1.5105,
         1.7744, 1.7745, 1.7745, 1.7714, 1.7744, 1.7744, 1.7745, 1.7519, 1.7546,
         1.4461, 1.4507, 1.4507, 1.4507, 1.4425, 1.4507, 1.4468, 1.4506, 1.4507],
        [1.3140, 1.3122, 1.2963, 1.2875, 1.3112, 1.3095, 1.3107, 1.3113, 1.3113,
         1.3028, 1.2962, 1.2923, 1.2919, 1.3034, 1.2882, 1.2996, 1.3030, 1.2757,
         1.6431, 1.6168, 1.6401, 1.6395, 1.6389, 1.6390, 1.6412, 1.6427, 1.6427,
         3.4886, 3.2786, 3.2042, 3.2622, 3.4133, 3.2311, 3.4635, 3.2120, 3.1907,
         1.6473, 1.6398, 1.6381, 1.6412, 1.6442, 1.6201, 1.6456, 1.5849, 1.6114,
         1.3145, 1.3089, 1.2990, 1.3137, 1.3095, 1.3016, 1.3140, 1.3140, 1.3159],
        [1.4497, 1.4454, 1.4021, 1.4054, 1.4430, 1.4496, 1.4481, 1.4496, 1.4496,
         1.4393, 1.4367, 1.4317, 1.4271, 1.4404, 1.4005, 1.4345, 1.4404, 1.4357,
         1.7567, 1.7479, 1.7470, 1.7550, 1.7724, 1.7710, 1.7512, 1.7725, 1.7725,
         1.4715, 1.4771, 1.5133, 1.5081, 1.4769, 1.5119, 1.5002, 1.5133, 1.5102,
         2.2001, 2.1803, 2.1691, 2.1867, 2.2301, 2.2483, 2.2148, 2.3171, 2.3142,
         1.4386, 1.4288, 1.4432, 1.4534, 1.4409, 1.4502, 1.4214, 1.4474, 1.4535],
        [1.3563, 1.2632, 1.2589, 1.2781, 1.2711, 1.2815, 1.2803, 1.2194, 1.2194,
         1.2642, 1.2262, 1.2213, 1.2286, 1.3027, 1.1794, 1.1489, 1.3027, 1.2105,
         1.6096, 1.5858, 1.5676, 1.5620, 1.5856, 1.5817, 1.6023, 1.5871, 1.5871,
         1.3554, 1.3284, 1.3278, 1.3455, 1.3300, 1.3737, 1.3757, 1.3493, 1.3278,
         1.5845, 1.5847, 1.5898, 1.5794, 1.5557, 1.5598, 1.6209, 1.5092, 1.4785,
         4.0874, 3.6118, 3.7014, 3.6852, 3.6999, 3.3799, 4.0833, 3.6594, 3.4124]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 295 : 1780.1346600968411
Test loss for epoch 295 : 194.33704357912058
Test Precision for epoch 295 : 0.26153846153846155
Test Recall for epoch 295 : 0.26153846153846155
Test F1 for epoch 295 : 0.26153846153846155


theta for epoch 296 : tensor([[3.6203, 3.6414, 3.7849, 3.7329, 3.7165, 3.6019, 3.6430, 3.5424, 3.5424,
         1.2740, 1.2559, 1.2525, 1.2572, 1.2918, 1.2375, 1.2120, 1.2918, 1.2436,
         1.5972, 1.5817, 1.6057, 1.5886, 1.5942, 1.5958, 1.6029, 1.5958, 1.5958,
         1.3311, 1.3424, 1.3286, 1.3499, 1.3307, 1.3611, 1.3540, 1.3413, 1.3287,
         1.5927, 1.6083, 1.5975, 1.5939, 1.6007, 1.5907, 1.6089, 1.5633, 1.5679,
         1.2431, 1.2673, 1.2586, 1.2769, 1.2382, 1.2304, 1.2222, 1.3002, 1.2551],
        [1.3846, 1.2358, 1.2252, 1.2680, 1.2682, 1.2806, 1.2746, 1.1816, 1.1816,
         3.5859, 3.6730, 3.5159, 3.9112, 3.5861, 4.2558, 3.4497, 3.5410, 4.0200,
         1.5801, 1.5678, 1.5421, 1.5407, 1.5618, 1.5712, 1.5953, 1.5712, 1.5712,
         1.3511, 1.3177, 1.3123, 1.3692, 1.3118, 1.4060, 1.3865, 1.3557, 1.3091,
         1.5484, 1.6043, 1.5682, 1.5550, 1.5499, 1.5876, 1.6067, 1.4414, 1.5392,
         1.1556, 1.2670, 1.2373, 1.2900, 1.1496, 1.1557, 1.0918, 1.3555, 1.2265],
        [1.4485, 1.4484, 1.4468, 1.4440, 1.4444, 1.4485, 1.4442, 1.4485, 1.4485,
         1.4453, 1.4446, 1.4453, 1.4453, 1.4453, 1.4267, 1.4453, 1.4441, 1.4419,
         2.2022, 2.2024, 2.2191, 2.1948, 2.1764, 2.1746, 2.2038, 2.1737, 2.1737,
         1.5028, 1.5011, 1.5086, 1.5086, 1.5028, 1.5086, 1.5085, 1.5086, 1.5086,
         1.7721, 1.7722, 1.7722, 1.7690, 1.7721, 1.7721, 1.7722, 1.7496, 1.7523,
         1.4380, 1.4425, 1.4425, 1.4425, 1.4343, 1.4425, 1.4386, 1.4425, 1.4425],
        [1.3161, 1.3142, 1.2983, 1.2895, 1.3131, 1.3115, 1.3127, 1.3132, 1.3132,
         1.3107, 1.3041, 1.3002, 1.2998, 1.3114, 1.2961, 1.3074, 1.3110, 1.2836,
         1.6441, 1.6177, 1.6410, 1.6405, 1.6399, 1.6399, 1.6421, 1.6436, 1.6436,
         3.4860, 3.2759, 3.2014, 3.2595, 3.4106, 3.2284, 3.4609, 3.2093, 3.1880,
         1.6450, 1.6376, 1.6359, 1.6390, 1.6420, 1.6179, 1.6434, 1.5827, 1.6092,
         1.3065, 1.3008, 1.2910, 1.3057, 1.3014, 1.2936, 1.3060, 1.3060, 1.3079],
        [1.4513, 1.4471, 1.4038, 1.4071, 1.4446, 1.4512, 1.4497, 1.4513, 1.4513,
         1.4470, 1.4444, 1.4395, 1.4349, 1.4481, 1.4082, 1.4422, 1.4481, 1.4435,
         1.7574, 1.7487, 1.7477, 1.7557, 1.7731, 1.7718, 1.7519, 1.7733, 1.7733,
         1.4695, 1.4751, 1.5113, 1.5061, 1.4749, 1.5099, 1.4982, 1.5114, 1.5082,
         2.1979, 2.1781, 2.1668, 2.1844, 2.2279, 2.2461, 2.2125, 2.3149, 2.3120,
         1.4304, 1.4206, 1.4350, 1.4453, 1.4327, 1.4421, 1.4131, 1.4393, 1.4453],
        [1.3449, 1.2526, 1.2481, 1.2673, 1.2603, 1.2706, 1.2694, 1.2091, 1.2091,
         1.2666, 1.2280, 1.2227, 1.2305, 1.3059, 1.1806, 1.1491, 1.3060, 1.2121,
         1.6041, 1.5802, 1.5620, 1.5566, 1.5802, 1.5763, 1.5968, 1.5817, 1.5817,
         1.3455, 1.3185, 1.3182, 1.3355, 1.3202, 1.3635, 1.3657, 1.3394, 1.3183,
         1.5773, 1.5773, 1.5826, 1.5722, 1.5484, 1.5524, 1.6135, 1.5018, 1.4709,
         4.0959, 3.6198, 3.7095, 3.6932, 3.7080, 3.3880, 4.0918, 3.6674, 3.4205]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 296 : 1780.0292183227089
Test loss for epoch 296 : 194.72929514658642
Test Precision for epoch 296 : 0.26153846153846155
Test Recall for epoch 296 : 0.26153846153846155
Test F1 for epoch 296 : 0.26153846153846155


theta for epoch 297 : tensor([[3.6260, 3.6471, 3.7906, 3.7386, 3.7223, 3.6077, 3.6488, 3.5483, 3.5483,
         1.2712, 1.2525, 1.2489, 1.2539, 1.2897, 1.2339, 1.2070, 1.2898, 1.2400,
         1.5971, 1.5815, 1.6056, 1.5883, 1.5939, 1.5955, 1.6028, 1.5955, 1.5955,
         1.3376, 1.3488, 1.3347, 1.3564, 1.3370, 1.3678, 1.3606, 1.3477, 1.3347,
         1.5917, 1.6075, 1.5965, 1.5930, 1.5998, 1.5898, 1.6081, 1.5623, 1.5670,
         1.2368, 1.2615, 1.2527, 1.2712, 1.2318, 1.2238, 1.2150, 1.2948, 1.2492],
        [1.3785, 1.2288, 1.2183, 1.2612, 1.2614, 1.2738, 1.2677, 1.1742, 1.1742,
         3.5930, 3.6802, 3.5230, 3.9187, 3.5932, 4.2642, 3.4567, 3.5480, 4.0278,
         1.5742, 1.5619, 1.5361, 1.5347, 1.5558, 1.5652, 1.5895, 1.5652, 1.5652,
         1.3486, 1.3151, 1.3096, 1.3668, 1.3092, 1.4038, 1.3842, 1.3532, 1.3064,
         1.5422, 1.5983, 1.5621, 1.5489, 1.5438, 1.5816, 1.6008, 1.4350, 1.5330,
         1.1458, 1.2575, 1.2277, 1.2806, 1.1397, 1.1458, 1.0808, 1.3464, 1.2170],
        [1.4532, 1.4531, 1.4515, 1.4487, 1.4491, 1.4532, 1.4489, 1.4532, 1.4532,
         1.4431, 1.4425, 1.4431, 1.4431, 1.4431, 1.4245, 1.4431, 1.4420, 1.4398,
         2.2029, 2.2030, 2.2198, 2.1954, 2.1770, 2.1752, 2.2044, 2.1743, 2.1743,
         1.5101, 1.5085, 1.5159, 1.5159, 1.5101, 1.5159, 1.5159, 1.5159, 1.5159,
         1.7719, 1.7720, 1.7720, 1.7688, 1.7719, 1.7719, 1.7720, 1.7494, 1.7521,
         1.4328, 1.4374, 1.4374, 1.4374, 1.4291, 1.4373, 1.4335, 1.4373, 1.4374],
        [1.3211, 1.3192, 1.3033, 1.2945, 1.3181, 1.3165, 1.3176, 1.3181, 1.3181,
         1.3086, 1.3020, 1.2981, 1.2977, 1.3094, 1.2940, 1.3053, 1.3090, 1.2815,
         1.6449, 1.6186, 1.6419, 1.6413, 1.6407, 1.6408, 1.6430, 1.6444, 1.6444,
         3.4916, 3.2816, 3.2071, 3.2652, 3.4162, 3.2340, 3.4665, 3.2149, 3.1937,
         1.6450, 1.6375, 1.6359, 1.6390, 1.6419, 1.6179, 1.6433, 1.5826, 1.6091,
         1.3015, 1.2958, 1.2859, 1.3007, 1.2964, 1.2886, 1.3009, 1.3010, 1.3029],
        [1.4560, 1.4517, 1.4084, 1.4118, 1.4493, 1.4559, 1.4544, 1.4560, 1.4560,
         1.4448, 1.4422, 1.4373, 1.4327, 1.4459, 1.4059, 1.4401, 1.4459, 1.4413,
         1.7581, 1.7494, 1.7484, 1.7564, 1.7738, 1.7725, 1.7526, 1.7740, 1.7740,
         1.4768, 1.4824, 1.5186, 1.5134, 1.4822, 1.5172, 1.5056, 1.5187, 1.5156,
         2.1977, 2.1779, 2.1666, 2.1843, 2.2277, 2.2459, 2.2124, 2.3148, 2.3119,
         1.4251, 1.4155, 1.4298, 1.4402, 1.4275, 1.4369, 1.4079, 1.4341, 1.4402],
        [1.3342, 1.2419, 1.2375, 1.2567, 1.2496, 1.2600, 1.2588, 1.1985, 1.1985,
         1.2588, 1.2193, 1.2138, 1.2221, 1.2992, 1.1715, 1.1385, 1.2992, 1.2032,
         1.5973, 1.5733, 1.5550, 1.5498, 1.5735, 1.5695, 1.5899, 1.5749, 1.5749,
         1.3420, 1.3148, 1.3148, 1.3319, 1.3167, 1.3598, 1.3621, 1.3359, 1.3148,
         1.5710, 1.5709, 1.5763, 1.5658, 1.5419, 1.5459, 1.6072, 1.4951, 1.4641,
         4.1080, 3.6315, 3.7213, 3.7049, 3.7197, 3.3997, 4.1040, 3.6790, 3.4322]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 297 : 1779.4723009024187
Test loss for epoch 297 : 195.10928124554943
Test Precision for epoch 297 : 0.26153846153846155
Test Recall for epoch 297 : 0.26153846153846155
Test F1 for epoch 297 : 0.26153846153846155


theta for epoch 298 : tensor([[3.6328, 3.6541, 3.7974, 3.7455, 3.7292, 3.6146, 3.6557, 3.5553, 3.5553,
         1.2608, 1.2414, 1.2377, 1.2430, 1.2800, 1.2225, 1.1942, 1.2800, 1.2287,
         1.5980, 1.5823, 1.6065, 1.5889, 1.5946, 1.5962, 1.6036, 1.5962, 1.5962,
         1.3439, 1.3551, 1.3407, 1.3628, 1.3432, 1.3744, 1.3671, 1.3540, 1.3407,
         1.5940, 1.6099, 1.5988, 1.5953, 1.6021, 1.5922, 1.6106, 1.5646, 1.5693,
         1.2361, 1.2614, 1.2525, 1.2713, 1.2310, 1.2227, 1.2135, 1.2953, 1.2489],
        [1.3668, 1.2164, 1.2059, 1.2489, 1.2491, 1.2616, 1.2555, 1.1615, 1.1615,
         3.6031, 3.6904, 3.5331, 3.9293, 3.6034, 4.2755, 3.4668, 3.5581, 4.0386,
         1.5654, 1.5531, 1.5271, 1.5257, 1.5469, 1.5564, 1.5808, 1.5564, 1.5564,
         1.3424, 1.3087, 1.3031, 1.3606, 1.3027, 1.3979, 1.3782, 1.3470, 1.3000,
         1.5354, 1.5918, 1.5554, 1.5421, 1.5369, 1.5750, 1.5943, 1.4275, 1.5261,
         1.1357, 1.2481, 1.2182, 1.2713, 1.1296, 1.1355, 1.0692, 1.3376, 1.2074],
        [1.4561, 1.4561, 1.4545, 1.4517, 1.4520, 1.4561, 1.4519, 1.4562, 1.4562,
         1.4335, 1.4328, 1.4334, 1.4334, 1.4335, 1.4148, 1.4335, 1.4323, 1.4301,
         2.2047, 2.2049, 2.2216, 2.1972, 2.1788, 2.1770, 2.2062, 2.1761, 2.1761,
         1.5178, 1.5162, 1.5236, 1.5236, 1.5178, 1.5236, 1.5236, 1.5236, 1.5236,
         1.7752, 1.7753, 1.7753, 1.7722, 1.7752, 1.7752, 1.7753, 1.7527, 1.7554,
         1.4339, 1.4384, 1.4384, 1.4384, 1.4302, 1.4384, 1.4345, 1.4384, 1.4384],
        [1.3243, 1.3223, 1.3065, 1.2977, 1.3213, 1.3197, 1.3208, 1.3213, 1.3213,
         1.2991, 1.2924, 1.2885, 1.2881, 1.2998, 1.2844, 1.2956, 1.2994, 1.2719,
         1.6470, 1.6207, 1.6440, 1.6434, 1.6428, 1.6429, 1.6451, 1.6465, 1.6465,
         3.4978, 3.2878, 3.2134, 3.2714, 3.4225, 3.2402, 3.4726, 3.2212, 3.2000,
         1.6484, 1.6410, 1.6393, 1.6424, 1.6453, 1.6213, 1.6468, 1.5861, 1.6126,
         1.3026, 1.2970, 1.2871, 1.3019, 1.2976, 1.2897, 1.3020, 1.3022, 1.3041],
        [1.4590, 1.4547, 1.4114, 1.4148, 1.4523, 1.4589, 1.4574, 1.4590, 1.4590,
         1.4352, 1.4326, 1.4276, 1.4230, 1.4363, 1.3962, 1.4304, 1.4363, 1.4316,
         1.7601, 1.7514, 1.7503, 1.7583, 1.7758, 1.7745, 1.7546, 1.7759, 1.7759,
         1.4846, 1.4901, 1.5264, 1.5212, 1.4899, 1.5249, 1.5133, 1.5264, 1.5233,
         2.2010, 2.1811, 2.1699, 2.1875, 2.2310, 2.2492, 2.2156, 2.3181, 2.3152,
         1.4262, 1.4165, 1.4309, 1.4412, 1.4286, 1.4380, 1.4089, 1.4352, 1.4413],
        [1.3218, 1.2289, 1.2245, 1.2437, 1.2367, 1.2471, 1.2459, 1.1852, 1.1852,
         1.2434, 1.2029, 1.1972, 1.2059, 1.2849, 1.1546, 1.1198, 1.2849, 1.1865,
         1.5907, 1.5666, 1.5482, 1.5430, 1.5668, 1.5628, 1.5833, 1.5683, 1.5683,
         1.3378, 1.3105, 1.3106, 1.3276, 1.3124, 1.3557, 1.3580, 1.3317, 1.3106,
         1.5671, 1.5669, 1.5724, 1.5618, 1.5378, 1.5418, 1.6034, 1.4908, 1.4596,
         4.1245, 3.6476, 3.7374, 3.7210, 3.7358, 3.4157, 4.1205, 3.6951, 3.4483]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 298 : 1778.6867735766393
Test loss for epoch 298 : 195.67477266253397
Test Precision for epoch 298 : 0.26153846153846155
Test Recall for epoch 298 : 0.26153846153846155
Test F1 for epoch 298 : 0.26153846153846155


theta for epoch 299 : tensor([[3.6337, 3.6550, 3.7983, 3.7464, 3.7301, 3.6155, 3.6566, 3.5562, 3.5562,
         1.2534, 1.2338, 1.2301, 1.2354, 1.2729, 1.2147, 1.1860, 1.2729, 1.2210,
         1.6015, 1.5858, 1.6100, 1.5923, 1.5980, 1.5996, 1.6071, 1.5996, 1.5996,
         1.3425, 1.3537, 1.3391, 1.3614, 1.3417, 1.3731, 1.3658, 1.3525, 1.3391,
         1.5988, 1.6148, 1.6036, 1.6000, 1.6069, 1.5970, 1.6155, 1.5694, 1.5740,
         1.2389, 1.2640, 1.2550, 1.2739, 1.2337, 1.2244, 1.2157, 1.2982, 1.2513],
        [1.3616, 1.2111, 1.2005, 1.2436, 1.2438, 1.2563, 1.2502, 1.1562, 1.1562,
         3.6066, 3.6940, 3.5365, 3.9332, 3.6068, 4.2802, 3.4701, 3.5616, 4.0427,
         1.5633, 1.5510, 1.5248, 1.5235, 1.5448, 1.5543, 1.5787, 1.5544, 1.5544,
         1.3367, 1.3030, 1.2975, 1.3549, 1.2970, 1.3921, 1.3724, 1.3413, 1.2944,
         1.5351, 1.5916, 1.5552, 1.5418, 1.5366, 1.5747, 1.5941, 1.4268, 1.5258,
         1.1337, 1.2452, 1.2153, 1.2685, 1.1278, 1.1318, 1.0665, 1.3351, 1.2044],
        [1.4584, 1.4584, 1.4568, 1.4540, 1.4543, 1.4584, 1.4542, 1.4585, 1.4585,
         1.4260, 1.4254, 1.4260, 1.4260, 1.4260, 1.4074, 1.4260, 1.4249, 1.4227,
         2.2079, 2.2081, 2.2249, 2.2003, 2.1819, 2.1801, 2.2093, 2.1792, 2.1792,
         1.5163, 1.5147, 1.5221, 1.5221, 1.5163, 1.5221, 1.5220, 1.5221, 1.5221,
         1.7800, 1.7801, 1.7801, 1.7770, 1.7800, 1.7800, 1.7801, 1.7575, 1.7602,
         1.4365, 1.4410, 1.4410, 1.4410, 1.4328, 1.4410, 1.4371, 1.4410, 1.4410],
        [1.3267, 1.3248, 1.3089, 1.3002, 1.3237, 1.3221, 1.3232, 1.3237, 1.3237,
         1.2917, 1.2850, 1.2811, 1.2808, 1.2925, 1.2770, 1.2882, 1.2921, 1.2645,
         1.6506, 1.6242, 1.6476, 1.6470, 1.6464, 1.6464, 1.6487, 1.6501, 1.6501,
         3.4959, 3.2860, 3.2115, 3.2695, 3.4206, 3.2383, 3.4708, 3.2193, 3.1981,
         1.6533, 1.6459, 1.6442, 1.6473, 1.6503, 1.6262, 1.6517, 1.5910, 1.6175,
         1.3053, 1.2997, 1.2898, 1.3046, 1.3003, 1.2924, 1.3047, 1.3050, 1.3067],
        [1.4612, 1.4570, 1.4137, 1.4171, 1.4546, 1.4612, 1.4597, 1.4613, 1.4613,
         1.4277, 1.4252, 1.4202, 1.4155, 1.4289, 1.3887, 1.4230, 1.4289, 1.4242,
         1.7635, 1.7548, 1.7537, 1.7617, 1.7792, 1.7779, 1.7580, 1.7794, 1.7794,
         1.4830, 1.4885, 1.5248, 1.5196, 1.4884, 1.5234, 1.5118, 1.5249, 1.5218,
         2.2057, 2.1858, 2.1745, 2.1922, 2.2357, 2.2538, 2.2203, 2.3227, 2.3198,
         1.4288, 1.4191, 1.4335, 1.4438, 1.4312, 1.4406, 1.4114, 1.4378, 1.4439],
        [1.3246, 1.2313, 1.2269, 1.2462, 1.2391, 1.2495, 1.2483, 1.1873, 1.1873,
         1.2374, 1.1967, 1.1910, 1.1998, 1.2792, 1.1483, 1.1133, 1.2792, 1.1804,
         1.5946, 1.5705, 1.5521, 1.5469, 1.5707, 1.5667, 1.5872, 1.5722, 1.5722,
         1.3374, 1.3101, 1.3101, 1.3272, 1.3119, 1.3553, 1.3576, 1.3312, 1.3102,
         1.5723, 1.5721, 1.5776, 1.5671, 1.5430, 1.5470, 1.6087, 1.4961, 1.4648,
         4.1238, 3.6464, 3.7363, 3.7199, 3.7347, 3.4147, 4.1198, 3.6939, 3.4472]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 299 : 1778.6546057699336
Test loss for epoch 299 : 195.728749649108
Test Precision for epoch 299 : 0.26153846153846155
Test Recall for epoch 299 : 0.26153846153846155
Test F1 for epoch 299 : 0.26153846153846155


theta for epoch 300 : tensor([[3.6262, 3.6473, 3.7907, 3.7388, 3.7224, 3.6078, 3.6489, 3.5484, 3.5484,
         1.2547, 1.2352, 1.2315, 1.2368, 1.2741, 1.2161, 1.1877, 1.2741, 1.2225,
         1.6036, 1.5880, 1.6122, 1.5944, 1.6001, 1.6017, 1.6093, 1.6017, 1.6017,
         1.3397, 1.3509, 1.3362, 1.3586, 1.3388, 1.3703, 1.3630, 1.3497, 1.3362,
         1.6007, 1.6167, 1.6055, 1.6019, 1.6088, 1.5990, 1.6174, 1.5713, 1.5760,
         1.2433, 1.2675, 1.2585, 1.2775, 1.2383, 1.2282, 1.2200, 1.3020, 1.2548],
        [1.3635, 1.2136, 1.2030, 1.2460, 1.2463, 1.2587, 1.2526, 1.1591, 1.1591,
         3.6031, 3.6905, 3.5329, 3.9301, 3.6034, 4.2778, 3.4664, 3.5581, 4.0398,
         1.5663, 1.5540, 1.5279, 1.5267, 1.5480, 1.5575, 1.5817, 1.5575, 1.5575,
         1.3364, 1.3028, 1.2975, 1.3546, 1.2969, 1.3916, 1.3720, 1.3411, 1.2944,
         1.5382, 1.5946, 1.5583, 1.5449, 1.5397, 1.5777, 1.5970, 1.4300, 1.5289,
         1.1399, 1.2490, 1.2191, 1.2723, 1.1346, 1.1373, 1.0726, 1.3389, 1.2083],
        [1.4575, 1.4574, 1.4558, 1.4530, 1.4534, 1.4575, 1.4532, 1.4575, 1.4575,
         1.4262, 1.4255, 1.4261, 1.4261, 1.4262, 1.4075, 1.4261, 1.4250, 1.4228,
         2.2087, 2.2089, 2.2256, 2.2010, 2.1827, 2.1808, 2.2100, 2.1800, 2.1800,
         1.5116, 1.5099, 1.5174, 1.5174, 1.5116, 1.5174, 1.5173, 1.5174, 1.5174,
         1.7809, 1.7810, 1.7810, 1.7778, 1.7809, 1.7809, 1.7810, 1.7584, 1.7610,
         1.4387, 1.4433, 1.4433, 1.4433, 1.4350, 1.4433, 1.4394, 1.4432, 1.4433],
        [1.3258, 1.3239, 1.3080, 1.2992, 1.3228, 1.3212, 1.3223, 1.3228, 1.3228,
         1.2919, 1.2853, 1.2813, 1.2810, 1.2927, 1.2772, 1.2884, 1.2923, 1.2647,
         1.6515, 1.6251, 1.6484, 1.6478, 1.6472, 1.6473, 1.6495, 1.6510, 1.6510,
         3.4914, 3.2814, 3.2069, 3.2650, 3.4161, 3.2338, 3.4663, 3.2147, 3.1935,
         1.6543, 1.6468, 1.6451, 1.6482, 1.6512, 1.6271, 1.6526, 1.5919, 1.6184,
         1.3077, 1.3020, 1.2921, 1.3069, 1.3026, 1.2947, 1.3070, 1.3072, 1.3090],
        [1.4603, 1.4561, 1.4127, 1.4161, 1.4536, 1.4602, 1.4587, 1.4603, 1.4603,
         1.4279, 1.4253, 1.4203, 1.4157, 1.4290, 1.3889, 1.4231, 1.4290, 1.4243,
         1.7643, 1.7556, 1.7545, 1.7625, 1.7800, 1.7787, 1.7588, 1.7802, 1.7802,
         1.4783, 1.4838, 1.5201, 1.5149, 1.4837, 1.5187, 1.5070, 1.5202, 1.5171,
         2.2065, 2.1866, 2.1754, 2.1930, 2.2365, 2.2546, 2.2211, 2.3236, 2.3207,
         1.4310, 1.4214, 1.4357, 1.4461, 1.4334, 1.4428, 1.4137, 1.4400, 1.4461],
        [1.3425, 1.2494, 1.2450, 1.2642, 1.2572, 1.2676, 1.2664, 1.2054, 1.2054,
         1.2470, 1.2069, 1.2013, 1.2098, 1.2882, 1.1586, 1.1245, 1.2882, 1.1907,
         1.6067, 1.5828, 1.5644, 1.5592, 1.5828, 1.5789, 1.5993, 1.5843, 1.5843,
         1.3475, 1.3204, 1.3203, 1.3374, 1.3222, 1.3654, 1.3676, 1.3414, 1.3203,
         1.5829, 1.5828, 1.5882, 1.5777, 1.5538, 1.5578, 1.6191, 1.5072, 1.4762,
         4.1024, 3.6247, 3.7146, 3.6981, 3.7128, 3.3929, 4.0984, 3.6722, 3.4255]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 300 : 1779.1408624077944
Test loss for epoch 300 : 195.1723193032624
Test Precision for epoch 300 : 0.26153846153846155
Test Recall for epoch 300 : 0.26153846153846155
Test F1 for epoch 300 : 0.26153846153846155


theta for epoch 301 : tensor([[3.6116, 3.6325, 3.7760, 3.7241, 3.7077, 3.5931, 3.6342, 3.5334, 3.5334,
         1.2632, 1.2442, 1.2407, 1.2457, 1.2826, 1.2252, 1.1978, 1.2826, 1.2316,
         1.6004, 1.5847, 1.6090, 1.5912, 1.5968, 1.5984, 1.6060, 1.5984, 1.5984,
         1.3401, 1.3513, 1.3366, 1.3590, 1.3392, 1.3708, 1.3634, 1.3501, 1.3367,
         1.5968, 1.6128, 1.6016, 1.5980, 1.6049, 1.5951, 1.6135, 1.5675, 1.5721,
         1.2516, 1.2750, 1.2660, 1.2851, 1.2468, 1.2361, 1.2283, 1.3097, 1.2623],
        [1.3760, 1.2274, 1.2168, 1.2596, 1.2598, 1.2722, 1.2661, 1.1734, 1.1734,
         3.5879, 3.6753, 3.5176, 3.9153, 3.5881, 4.2637, 3.4509, 3.5428, 4.0251,
         1.5752, 1.5630, 1.5370, 1.5360, 1.5572, 1.5666, 1.5905, 1.5666, 1.5666,
         1.3481, 1.3146, 1.3096, 1.3661, 1.3089, 1.4028, 1.3834, 1.3527, 1.3064,
         1.5459, 1.6017, 1.5658, 1.5525, 1.5473, 1.5850, 1.6041, 1.4385, 1.5366,
         1.1587, 1.2654, 1.2357, 1.2886, 1.1538, 1.1554, 1.0913, 1.3551, 1.2249],
        [1.4519, 1.4518, 1.4502, 1.4474, 1.4478, 1.4519, 1.4476, 1.4519, 1.4519,
         1.4329, 1.4322, 1.4329, 1.4329, 1.4329, 1.4142, 1.4329, 1.4317, 1.4295,
         2.2036, 2.2038, 2.2206, 2.1962, 2.1778, 2.1760, 2.2052, 2.1751, 2.1751,
         1.5090, 1.5074, 1.5148, 1.5148, 1.5090, 1.5148, 1.5148, 1.5148, 1.5148,
         1.7753, 1.7753, 1.7753, 1.7722, 1.7752, 1.7752, 1.7753, 1.7527, 1.7554,
         1.4440, 1.4486, 1.4486, 1.4486, 1.4403, 1.4486, 1.4447, 1.4485, 1.4486],
        [1.3202, 1.3182, 1.3024, 1.2936, 1.3172, 1.3156, 1.3167, 1.3172, 1.3172,
         1.2987, 1.2921, 1.2882, 1.2878, 1.2995, 1.2840, 1.2953, 1.2991, 1.2716,
         1.6461, 1.6197, 1.6431, 1.6425, 1.6419, 1.6419, 1.6441, 1.6456, 1.6456,
         3.4889, 3.2788, 3.2043, 3.2624, 3.4135, 3.2312, 3.4637, 3.2121, 3.1908,
         1.6487, 1.6412, 1.6395, 1.6426, 1.6456, 1.6215, 1.6470, 1.5863, 1.6128,
         1.3131, 1.3074, 1.2975, 1.3123, 1.3080, 1.3001, 1.3124, 1.3126, 1.3144],
        [1.4547, 1.4505, 1.4072, 1.4105, 1.4480, 1.4546, 1.4531, 1.4547, 1.4547,
         1.4346, 1.4320, 1.4270, 1.4224, 1.4358, 1.3956, 1.4298, 1.4357, 1.4310,
         1.7590, 1.7502, 1.7492, 1.7572, 1.7747, 1.7733, 1.7535, 1.7748, 1.7748,
         1.4757, 1.4812, 1.5175, 1.5124, 1.4811, 1.5161, 1.5045, 1.5176, 1.5145,
         2.2011, 2.1812, 2.1699, 2.1876, 2.2311, 2.2492, 2.2157, 2.3181, 2.3152,
         1.4363, 1.4267, 1.4410, 1.4513, 1.4387, 1.4481, 1.4190, 1.4453, 1.4514],
        [1.3572, 1.2644, 1.2601, 1.2792, 1.2723, 1.2825, 1.2813, 1.2205, 1.2205,
         1.2625, 1.2235, 1.2182, 1.2262, 1.3035, 1.1754, 1.1434, 1.3035, 1.2077,
         1.6131, 1.5893, 1.5711, 1.5659, 1.5893, 1.5854, 1.6058, 1.5908, 1.5908,
         1.3594, 1.3325, 1.3323, 1.3494, 1.3342, 1.3772, 1.3794, 1.3533, 1.3323,
         1.5874, 1.5873, 1.5926, 1.5822, 1.5585, 1.5624, 1.6234, 1.5121, 1.4814,
         4.0825, 3.6044, 3.6944, 3.6778, 3.6924, 3.3725, 4.0785, 3.6518, 3.4052]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 301 : 1779.8255674541285
Test loss for epoch 301 : 194.39122752440662
Test Precision for epoch 301 : 0.26153846153846155
Test Recall for epoch 301 : 0.26153846153846155
Test F1 for epoch 301 : 0.26153846153846155


theta for epoch 302 : tensor([[3.6018, 3.6225, 3.7661, 3.7142, 3.6978, 3.5831, 3.6242, 3.5233, 3.5233,
         1.2735, 1.2547, 1.2513, 1.2562, 1.2929, 1.2357, 1.2089, 1.2929, 1.2422,
         1.5945, 1.5788, 1.6030, 1.5852, 1.5908, 1.5924, 1.6001, 1.5924, 1.5924,
         1.3390, 1.3501, 1.3355, 1.3578, 1.3381, 1.3696, 1.3622, 1.3489, 1.3355,
         1.5907, 1.6068, 1.5955, 1.5920, 1.5989, 1.5891, 1.6075, 1.5615, 1.5661,
         1.2583, 1.2812, 1.2722, 1.2913, 1.2537, 1.2424, 1.2349, 1.3160, 1.2685],
        [1.3828, 1.2350, 1.2244, 1.2670, 1.2673, 1.2796, 1.2736, 1.1813, 1.1813,
         3.5807, 3.6682, 3.5103, 3.9084, 3.5809, 4.2575, 3.4435, 3.5356, 4.0185,
         1.5770, 1.5649, 1.5390, 1.5381, 1.5591, 1.5685, 1.5923, 1.5685, 1.5685,
         1.3535, 1.3202, 1.3153, 1.3715, 1.3145, 1.4079, 1.3886, 1.3582, 1.3121,
         1.5469, 1.6023, 1.5667, 1.5535, 1.5483, 1.5857, 1.6047, 1.4400, 1.5377,
         1.1707, 1.2757, 1.2460, 1.2989, 1.1662, 1.1668, 1.1030, 1.3653, 1.2353],
        [1.4486, 1.4486, 1.4469, 1.4441, 1.4445, 1.4486, 1.4443, 1.4486, 1.4486,
         1.4419, 1.4412, 1.4419, 1.4418, 1.4419, 1.4232, 1.4419, 1.4407, 1.4385,
         2.1967, 2.1969, 2.2137, 2.1895, 2.1711, 2.1693, 2.1985, 2.1684, 2.1684,
         1.5058, 1.5041, 1.5116, 1.5116, 1.5058, 1.5116, 1.5115, 1.5116, 1.5116,
         1.7681, 1.7682, 1.7682, 1.7650, 1.7681, 1.7681, 1.7682, 1.7456, 1.7482,
         1.4486, 1.4532, 1.4532, 1.4532, 1.4450, 1.4532, 1.4493, 1.4532, 1.4532],
        [1.3169, 1.3150, 1.2991, 1.2903, 1.3139, 1.3123, 1.3134, 1.3139, 1.3139,
         1.3078, 1.3012, 1.2973, 1.2969, 1.3086, 1.2931, 1.3044, 1.3082, 1.2806,
         1.6387, 1.6124, 1.6357, 1.6351, 1.6345, 1.6345, 1.6368, 1.6382, 1.6382,
         3.4856, 3.2755, 3.2010, 3.2591, 3.4102, 3.2279, 3.4605, 3.2088, 3.1875,
         1.6415, 1.6341, 1.6324, 1.6355, 1.6384, 1.6144, 1.6399, 1.5791, 1.6056,
         1.3178, 1.3121, 1.3022, 1.3170, 1.3127, 1.3048, 1.3172, 1.3173, 1.3191],
        [1.4515, 1.4472, 1.4039, 1.4072, 1.4447, 1.4514, 1.4499, 1.4515, 1.4515,
         1.4436, 1.4410, 1.4360, 1.4314, 1.4447, 1.4046, 1.4388, 1.4447, 1.4400,
         1.7517, 1.7429, 1.7419, 1.7499, 1.7674, 1.7661, 1.7462, 1.7675, 1.7675,
         1.4725, 1.4780, 1.5143, 1.5091, 1.4779, 1.5129, 1.5012, 1.5144, 1.5113,
         2.1941, 2.1742, 2.1629, 2.1806, 2.2241, 2.2423, 2.2088, 2.3113, 2.3084,
         1.4410, 1.4313, 1.4457, 1.4560, 1.4433, 1.4527, 1.4236, 1.4499, 1.4560],
        [1.3684, 1.2757, 1.2715, 1.2905, 1.2836, 1.2938, 1.2926, 1.2319, 1.2319,
         1.2774, 1.2391, 1.2341, 1.2417, 1.3184, 1.1911, 1.1604, 1.3184, 1.2235,
         1.6145, 1.5908, 1.5728, 1.5675, 1.5908, 1.5869, 1.6072, 1.5922, 1.5922,
         1.3667, 1.3399, 1.3396, 1.3568, 1.3417, 1.3845, 1.3866, 1.3606, 1.3397,
         1.5876, 1.5876, 1.5928, 1.5824, 1.5589, 1.5628, 1.6235, 1.5128, 1.4822,
         4.0684, 3.5899, 3.6800, 3.6634, 3.6779, 3.3580, 4.0644, 3.6373, 3.3908]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 302 : 1780.4912553249992
Test loss for epoch 302 : 194.07294600250128
Test Precision for epoch 302 : 0.26153846153846155
Test Recall for epoch 302 : 0.26153846153846155
Test F1 for epoch 302 : 0.26153846153846155


theta for epoch 303 : tensor([[3.5983, 3.6189, 3.7624, 3.7106, 3.6941, 3.5795, 3.6206, 3.5196, 3.5196,
         1.2763, 1.2576, 1.2544, 1.2590, 1.2960, 1.2386, 1.2119, 1.2960, 1.2451,
         1.5937, 1.5780, 1.6023, 1.5844, 1.5900, 1.5916, 1.5993, 1.5916, 1.5916,
         1.3377, 1.3489, 1.3342, 1.3566, 1.3368, 1.3684, 1.3610, 1.3477, 1.3343,
         1.5894, 1.6054, 1.5942, 1.5906, 1.5975, 1.5877, 1.6062, 1.5601, 1.5648,
         1.2602, 1.2828, 1.2738, 1.2929, 1.2557, 1.2440, 1.2366, 1.3176, 1.2701],
        [1.3860, 1.2383, 1.2277, 1.2703, 1.2706, 1.2829, 1.2769, 1.1847, 1.1847,
         3.5782, 3.6657, 3.5078, 3.9063, 3.5784, 4.2562, 3.4409, 3.5331, 4.0166,
         1.5777, 1.5657, 1.5398, 1.5389, 1.5599, 1.5693, 1.5929, 1.5693, 1.5693,
         1.3540, 1.3208, 1.3159, 1.3720, 1.3151, 1.4083, 1.3891, 1.3587, 1.3128,
         1.5471, 1.6024, 1.5668, 1.5537, 1.5484, 1.5858, 1.6047, 1.4403, 1.5379,
         1.1744, 1.2780, 1.2485, 1.3012, 1.1702, 1.1700, 1.1062, 1.3677, 1.2378],
        [1.4510, 1.4510, 1.4493, 1.4465, 1.4469, 1.4510, 1.4467, 1.4510, 1.4510,
         1.4440, 1.4434, 1.4440, 1.4440, 1.4440, 1.4254, 1.4440, 1.4429, 1.4407,
         2.1952, 2.1954, 2.2122, 2.1881, 2.1697, 2.1678, 2.1971, 2.1670, 2.1670,
         1.5034, 1.5018, 1.5092, 1.5092, 1.5034, 1.5092, 1.5092, 1.5092, 1.5092,
         1.7661, 1.7662, 1.7662, 1.7630, 1.7661, 1.7661, 1.7662, 1.7435, 1.7462,
         1.4493, 1.4538, 1.4538, 1.4538, 1.4456, 1.4538, 1.4499, 1.4538, 1.4538],
        [1.3194, 1.3175, 1.3016, 1.2928, 1.3164, 1.3148, 1.3159, 1.3164, 1.3164,
         1.3101, 1.3034, 1.2995, 1.2991, 1.3108, 1.2953, 1.3067, 1.3104, 1.2829,
         1.6372, 1.6108, 1.6342, 1.6336, 1.6330, 1.6330, 1.6353, 1.6367, 1.6367,
         3.4828, 3.2727, 3.1981, 3.2562, 3.4074, 3.2250, 3.4577, 3.2059, 3.1847,
         1.6396, 1.6321, 1.6304, 1.6335, 1.6365, 1.6125, 1.6379, 1.5772, 1.6037,
         1.3185, 1.3128, 1.3029, 1.3177, 1.3135, 1.3055, 1.3179, 1.3181, 1.3198],
        [1.4539, 1.4496, 1.4062, 1.4095, 1.4471, 1.4538, 1.4523, 1.4539, 1.4539,
         1.4457, 1.4431, 1.4381, 1.4335, 1.4469, 1.4067, 1.4410, 1.4468, 1.4421,
         1.7501, 1.7414, 1.7403, 1.7483, 1.7658, 1.7645, 1.7446, 1.7660, 1.7660,
         1.4701, 1.4756, 1.5120, 1.5068, 1.4755, 1.5106, 1.4989, 1.5120, 1.5089,
         2.1922, 2.1723, 2.1610, 2.1787, 2.2222, 2.2403, 2.2068, 2.3093, 2.3064,
         1.4416, 1.4319, 1.4463, 1.4566, 1.4440, 1.4534, 1.4243, 1.4506, 1.4567],
        [1.3782, 1.2857, 1.2815, 1.3004, 1.2936, 1.3037, 1.3026, 1.2418, 1.2418,
         1.2835, 1.2456, 1.2408, 1.2481, 1.3246, 1.1977, 1.1677, 1.3246, 1.2301,
         1.6179, 1.5944, 1.5763, 1.5711, 1.5943, 1.5905, 1.6107, 1.5958, 1.5958,
         1.3708, 1.3441, 1.3438, 1.3609, 1.3458, 1.3885, 1.3906, 1.3647, 1.3438,
         1.5900, 1.5900, 1.5952, 1.5848, 1.5614, 1.5653, 1.6258, 1.5155, 1.4850,
         4.0585, 3.5797, 3.6698, 3.6531, 3.6676, 3.3477, 4.0545, 3.6270, 3.3806]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 303 : 1780.8578719873258
Test loss for epoch 303 : 193.96193328968025
Test Precision for epoch 303 : 0.26153846153846155
Test Recall for epoch 303 : 0.26153846153846155
Test F1 for epoch 303 : 0.26153846153846155


theta for epoch 304 : tensor([[3.5965, 3.6171, 3.7607, 3.7088, 3.6924, 3.5777, 3.6189, 3.5178, 3.5178,
         1.2699, 1.2510, 1.2480, 1.2525, 1.2899, 1.2319, 1.2049, 1.2899, 1.2385,
         1.5988, 1.5831, 1.6074, 1.5894, 1.5951, 1.5967, 1.6044, 1.5967, 1.5967,
         1.3393, 1.3505, 1.3357, 1.3582, 1.3384, 1.3700, 1.3626, 1.3493, 1.3358,
         1.5937, 1.6098, 1.5985, 1.5950, 1.6019, 1.5921, 1.6106, 1.5645, 1.5691,
         1.2601, 1.2825, 1.2735, 1.2926, 1.2556, 1.2436, 1.2363, 1.3174, 1.2698],
        [1.3828, 1.2349, 1.2242, 1.2669, 1.2672, 1.2795, 1.2735, 1.1810, 1.1810,
         3.5792, 3.6668, 3.5087, 3.9077, 3.5794, 4.2583, 3.4417, 3.5340, 4.0183,
         1.5782, 1.5662, 1.5402, 1.5394, 1.5604, 1.5698, 1.5935, 1.5698, 1.5698,
         1.3518, 1.3185, 1.3136, 1.3697, 1.3128, 1.4062, 1.3869, 1.3565, 1.3105,
         1.5477, 1.6032, 1.5675, 1.5543, 1.5491, 1.5866, 1.6055, 1.4407, 1.5385,
         1.1722, 1.2750, 1.2455, 1.2983, 1.1682, 1.1673, 1.1034, 1.3648, 1.2348],
        [1.4519, 1.4518, 1.4502, 1.4474, 1.4478, 1.4519, 1.4476, 1.4519, 1.4519,
         1.4375, 1.4368, 1.4374, 1.4374, 1.4375, 1.4188, 1.4374, 1.4363, 1.4341,
         2.1997, 2.1999, 2.2166, 2.1924, 2.1739, 2.1721, 2.2014, 2.1712, 2.1712,
         1.5047, 1.5031, 1.5105, 1.5105, 1.5047, 1.5105, 1.5105, 1.5105, 1.5105,
         1.7702, 1.7703, 1.7703, 1.7672, 1.7702, 1.7702, 1.7703, 1.7477, 1.7504,
         1.4487, 1.4532, 1.4532, 1.4532, 1.4450, 1.4532, 1.4493, 1.4532, 1.4532],
        [1.3205, 1.3185, 1.3026, 1.2939, 1.3175, 1.3159, 1.3170, 1.3174, 1.3174,
         1.3036, 1.2970, 1.2930, 1.2927, 1.3044, 1.2889, 1.3002, 1.3040, 1.2764,
         1.6422, 1.6158, 1.6391, 1.6385, 1.6379, 1.6380, 1.6402, 1.6416, 1.6416,
         3.4828, 3.2727, 3.1981, 3.2563, 3.4074, 3.2251, 3.4577, 3.2060, 3.1847,
         1.6439, 1.6364, 1.6347, 1.6378, 1.6408, 1.6168, 1.6422, 1.5815, 1.6080,
         1.3180, 1.3123, 1.3024, 1.3172, 1.3130, 1.3050, 1.3174, 1.3175, 1.3193],
        [1.4547, 1.4505, 1.4071, 1.4104, 1.4480, 1.4546, 1.4531, 1.4547, 1.4547,
         1.4391, 1.4366, 1.4316, 1.4269, 1.4403, 1.4001, 1.4344, 1.4403, 1.4355,
         1.7548, 1.7461, 1.7450, 1.7531, 1.7706, 1.7692, 1.7494, 1.7707, 1.7707,
         1.4714, 1.4769, 1.5133, 1.5081, 1.4768, 1.5118, 1.5002, 1.5133, 1.5102,
         2.1962, 2.1763, 2.1650, 2.1827, 2.2262, 2.2443, 2.2108, 2.3134, 2.3105,
         1.4409, 1.4313, 1.4457, 1.4560, 1.4433, 1.4528, 1.4236, 1.4500, 1.4560],
        [1.3817, 1.2894, 1.2852, 1.3041, 1.2973, 1.3074, 1.3062, 1.2457, 1.2457,
         1.2791, 1.2414, 1.2369, 1.2438, 1.3204, 1.1936, 1.1639, 1.3205, 1.2260,
         1.6242, 1.6007, 1.5826, 1.5775, 1.6006, 1.5968, 1.6169, 1.6021, 1.6021,
         1.3741, 1.3474, 1.3472, 1.3642, 1.3492, 1.3917, 1.3939, 1.3680, 1.3472,
         1.5957, 1.5957, 1.6009, 1.5906, 1.5671, 1.5710, 1.6314, 1.5213, 1.4908,
         4.0534, 3.5743, 3.6644, 3.6477, 3.6621, 3.3423, 4.0494, 3.6216, 3.3752]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 304 : 1780.584326946764
Test loss for epoch 304 : 193.9062570179624
Test Precision for epoch 304 : 0.26153846153846155
Test Recall for epoch 304 : 0.26153846153846155
Test F1 for epoch 304 : 0.26153846153846155


theta for epoch 305 : tensor([[3.5959, 3.6165, 3.7600, 3.7082, 3.6917, 3.5771, 3.6182, 3.5172, 3.5172,
         1.2621, 1.2428, 1.2399, 1.2444, 1.2826, 1.2236, 1.1957, 1.2826, 1.2301,
         1.6026, 1.5869, 1.6112, 1.5931, 1.5988, 1.6004, 1.6082, 1.6004, 1.6004,
         1.3412, 1.3523, 1.3375, 1.3601, 1.3402, 1.3719, 1.3645, 1.3511, 1.3375,
         1.5986, 1.6149, 1.6034, 1.5999, 1.6069, 1.5971, 1.6157, 1.5695, 1.5741,
         1.2607, 1.2830, 1.2741, 1.2932, 1.2561, 1.2440, 1.2366, 1.3179, 1.2704],
        [1.3735, 1.2248, 1.2143, 1.2570, 1.2573, 1.2696, 1.2635, 1.1706, 1.1706,
         3.5852, 3.6729, 3.5147, 3.9142, 3.5854, 4.2655, 3.4477, 3.5400, 4.0249,
         1.5741, 1.5620, 1.5359, 1.5350, 1.5561, 1.5655, 1.5894, 1.5655, 1.5655,
         1.3459, 1.3125, 1.3075, 1.3639, 1.3068, 1.4006, 1.3812, 1.3506, 1.3043,
         1.5453, 1.6010, 1.5651, 1.5519, 1.5467, 1.5843, 1.6034, 1.4378, 1.5360,
         1.1664, 1.2690, 1.2395, 1.2923, 1.1626, 1.1612, 1.0969, 1.3592, 1.2287],
        [1.4500, 1.4499, 1.4482, 1.4454, 1.4458, 1.4500, 1.4456, 1.4499, 1.4499,
         1.4300, 1.4293, 1.4300, 1.4300, 1.4300, 1.4113, 1.4300, 1.4288, 1.4266,
         2.2035, 2.2037, 2.2204, 2.1960, 2.1776, 2.1758, 2.2050, 2.1749, 2.1749,
         1.5071, 1.5055, 1.5129, 1.5129, 1.5071, 1.5129, 1.5129, 1.5129, 1.5129,
         1.7755, 1.7756, 1.7756, 1.7724, 1.7755, 1.7755, 1.7756, 1.7529, 1.7556,
         1.4493, 1.4539, 1.4539, 1.4539, 1.4457, 1.4539, 1.4500, 1.4539, 1.4539],
        [1.3188, 1.3168, 1.3009, 1.2921, 1.3157, 1.3141, 1.3152, 1.3157, 1.3157,
         1.2963, 1.2896, 1.2857, 1.2853, 1.2971, 1.2815, 1.2928, 1.2967, 1.2690,
         1.6464, 1.6201, 1.6434, 1.6428, 1.6422, 1.6422, 1.6445, 1.6459, 1.6459,
         3.4835, 3.2734, 3.1988, 3.2570, 3.4081, 3.2258, 3.4584, 3.2067, 3.1854,
         1.6493, 1.6418, 1.6401, 1.6432, 1.6462, 1.6222, 1.6476, 1.5869, 1.6134,
         1.3189, 1.3132, 1.3032, 1.3181, 1.3138, 1.3058, 1.3182, 1.3184, 1.3202],
        [1.4528, 1.4485, 1.4050, 1.4084, 1.4460, 1.4527, 1.4512, 1.4528, 1.4528,
         1.4317, 1.4291, 1.4241, 1.4194, 1.4329, 1.3926, 1.4269, 1.4328, 1.4281,
         1.7589, 1.7502, 1.7491, 1.7571, 1.7747, 1.7733, 1.7534, 1.7748, 1.7748,
         1.4738, 1.4793, 1.5157, 1.5105, 1.4792, 1.5143, 1.5026, 1.5157, 1.5126,
         2.2013, 2.1813, 2.1700, 2.1878, 2.2313, 2.2494, 2.2158, 2.3185, 2.3156,
         1.4416, 1.4320, 1.4464, 1.4567, 1.4440, 1.4534, 1.4242, 1.4506, 1.4567],
        [1.3781, 1.2864, 1.2821, 1.3010, 1.2941, 1.3043, 1.3031, 1.2431, 1.2431,
         1.2716, 1.2338, 1.2297, 1.2363, 1.3133, 1.1861, 1.1563, 1.3133, 1.2184,
         1.6270, 1.6035, 1.5853, 1.5805, 1.6036, 1.5998, 1.6198, 1.6051, 1.6051,
         1.3747, 1.3481, 1.3481, 1.3648, 1.3499, 1.3922, 1.3944, 1.3687, 1.3482,
         1.6003, 1.6001, 1.6054, 1.5951, 1.5715, 1.5754, 1.6357, 1.5257, 1.4952,
         4.0537, 3.5743, 3.6644, 3.6477, 3.6620, 3.3423, 4.0497, 3.6215, 3.3753]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 305 : 1780.4129392045102
Test loss for epoch 305 : 194.13802897680984
Test Precision for epoch 305 : 0.26153846153846155
Test Recall for epoch 305 : 0.26153846153846155
Test F1 for epoch 305 : 0.26153846153846155


theta for epoch 306 : tensor([[3.6018, 3.6224, 3.7658, 3.7140, 3.6976, 3.5830, 3.6242, 3.5233, 3.5233,
         1.2584, 1.2385, 1.2358, 1.2402, 1.2795, 1.2192, 1.1900, 1.2795, 1.2256,
         1.5998, 1.5840, 1.6084, 1.5902, 1.5958, 1.5975, 1.6054, 1.5974, 1.5974,
         1.3411, 1.3522, 1.3373, 1.3600, 1.3401, 1.3719, 1.3644, 1.3510, 1.3373,
         1.5979, 1.6142, 1.6027, 1.5992, 1.6062, 1.5965, 1.6151, 1.5687, 1.5734,
         1.2616, 1.2841, 1.2752, 1.2942, 1.2571, 1.2448, 1.2373, 1.3189, 1.2715],
        [1.3631, 1.2128, 1.2024, 1.2453, 1.2456, 1.2579, 1.2519, 1.1578, 1.1578,
         3.5971, 3.6849, 3.5265, 3.9265, 3.5972, 4.2785, 3.4594, 3.5518, 4.0374,
         1.5623, 1.5500, 1.5240, 1.5228, 1.5440, 1.5534, 1.5777, 1.5535, 1.5535,
         1.3359, 1.3024, 1.2970, 1.3540, 1.2965, 1.3910, 1.3714, 1.3405, 1.2938,
         1.5353, 1.5915, 1.5553, 1.5420, 1.5368, 1.5747, 1.5940, 1.4274, 1.5261,
         1.1577, 1.2605, 1.2309, 1.2840, 1.1539, 1.1522, 1.0872, 1.3512, 1.2202],
        [1.4538, 1.4538, 1.4521, 1.4493, 1.4497, 1.4538, 1.4495, 1.4538, 1.4538,
         1.4273, 1.4266, 1.4273, 1.4273, 1.4273, 1.4086, 1.4273, 1.4261, 1.4239,
         2.2017, 2.2019, 2.2187, 2.1943, 2.1759, 2.1741, 2.2033, 2.1732, 2.1732,
         1.5085, 1.5069, 1.5143, 1.5143, 1.5085, 1.5143, 1.5143, 1.5143, 1.5143,
         1.7757, 1.7758, 1.7758, 1.7726, 1.7756, 1.7756, 1.7758, 1.7531, 1.7558,
         1.4511, 1.4557, 1.4557, 1.4557, 1.4474, 1.4557, 1.4518, 1.4557, 1.4557],
        [1.3230, 1.3209, 1.3050, 1.2962, 1.3199, 1.3183, 1.3194, 1.3198, 1.3198,
         1.2937, 1.2870, 1.2831, 1.2827, 1.2946, 1.2789, 1.2901, 1.2942, 1.2664,
         1.6448, 1.6184, 1.6417, 1.6411, 1.6405, 1.6406, 1.6428, 1.6443, 1.6443,
         3.4832, 3.2730, 3.1985, 3.2566, 3.4078, 3.2254, 3.4580, 3.2063, 3.1850,
         1.6496, 1.6422, 1.6405, 1.6435, 1.6465, 1.6225, 1.6480, 1.5872, 1.6137,
         1.3208, 1.3151, 1.3052, 1.3200, 1.3158, 1.3077, 1.3201, 1.3204, 1.3221],
        [1.4567, 1.4524, 1.4088, 1.4122, 1.4499, 1.4566, 1.4550, 1.4567, 1.4567,
         1.4290, 1.4264, 1.4214, 1.4167, 1.4302, 1.3898, 1.4242, 1.4301, 1.4254,
         1.7571, 1.7484, 1.7473, 1.7553, 1.7729, 1.7715, 1.7516, 1.7731, 1.7731,
         1.4752, 1.4806, 1.5171, 1.5118, 1.4806, 1.5156, 1.5040, 1.5171, 1.5140,
         2.2014, 2.1814, 2.1701, 2.1879, 2.2315, 2.2495, 2.2160, 2.3188, 2.3158,
         1.4433, 1.4337, 1.4481, 1.4585, 1.4457, 1.4552, 1.4259, 1.4524, 1.4585],
        [1.3740, 1.2833, 1.2789, 1.2977, 1.2908, 1.3010, 1.2998, 1.2405, 1.2405,
         1.2663, 1.2283, 1.2244, 1.2308, 1.3085, 1.1805, 1.1500, 1.3085, 1.2128,
         1.6220, 1.5986, 1.5803, 1.5758, 1.5989, 1.5951, 1.6148, 1.6004, 1.6004,
         1.3713, 1.3446, 1.3450, 1.3612, 1.3466, 1.3884, 1.3908, 1.3653, 1.3451,
         1.5980, 1.5975, 1.6031, 1.5928, 1.5691, 1.5728, 1.6331, 1.5233, 1.4927,
         4.0589, 3.5793, 3.6695, 3.6527, 3.6670, 3.3473, 4.0550, 3.6265, 3.3804]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 306 : 1779.7663601522338
Test loss for epoch 306 : 194.82860235609607
Test Precision for epoch 306 : 0.26153846153846155
Test Recall for epoch 306 : 0.26153846153846155
Test F1 for epoch 306 : 0.26153846153846155


theta for epoch 307 : tensor([[3.6114, 3.6321, 3.7754, 3.7236, 3.7072, 3.5928, 3.6338, 3.5332, 3.5332,
         1.2580, 1.2373, 1.2347, 1.2392, 1.2798, 1.2179, 1.1869, 1.2798, 1.2242,
         1.5959, 1.5801, 1.6045, 1.5862, 1.5919, 1.5935, 1.6015, 1.5935, 1.5935,
         1.3402, 1.3514, 1.3365, 1.3592, 1.3393, 1.3711, 1.3636, 1.3502, 1.3365,
         1.5932, 1.6095, 1.5980, 1.5945, 1.6015, 1.5918, 1.6104, 1.5640, 1.5686,
         1.2599, 1.2825, 1.2736, 1.2925, 1.2554, 1.2432, 1.2354, 1.3171, 1.2700],
        [1.3499, 1.1974, 1.1871, 1.2303, 1.2305, 1.2430, 1.2369, 1.1414, 1.1414,
         3.6137, 3.7016, 3.5431, 3.9435, 3.6138, 4.2963, 3.4759, 3.5684, 4.0547,
         1.5475, 1.5351, 1.5091, 1.5074, 1.5287, 1.5383, 1.5629, 1.5383, 1.5383,
         1.3233, 1.2896, 1.2837, 1.3416, 1.2835, 1.3791, 1.3593, 1.3279, 1.2805,
         1.5199, 1.5767, 1.5400, 1.5266, 1.5215, 1.5597, 1.5794, 1.4115, 1.5107,
         1.1447, 1.2483, 1.2186, 1.2719, 1.1409, 1.1390, 1.0732, 1.3397, 1.2077],
        [1.4575, 1.4574, 1.4558, 1.4530, 1.4534, 1.4575, 1.4532, 1.4575, 1.4575,
         1.4286, 1.4279, 1.4286, 1.4285, 1.4286, 1.4098, 1.4286, 1.4274, 1.4252,
         2.1997, 2.1999, 2.2167, 2.1924, 2.1739, 2.1721, 2.2013, 2.1712, 2.1712,
         1.5101, 1.5085, 1.5160, 1.5160, 1.5102, 1.5160, 1.5159, 1.5160, 1.5160,
         1.7724, 1.7725, 1.7725, 1.7694, 1.7724, 1.7724, 1.7725, 1.7498, 1.7525,
         1.4509, 1.4555, 1.4555, 1.4555, 1.4472, 1.4555, 1.4515, 1.4554, 1.4555],
        [1.3268, 1.3247, 1.3088, 1.3000, 1.3237, 1.3221, 1.3232, 1.3236, 1.3236,
         1.2951, 1.2883, 1.2844, 1.2841, 1.2960, 1.2802, 1.2913, 1.2956, 1.2677,
         1.6428, 1.6164, 1.6398, 1.6391, 1.6385, 1.6386, 1.6408, 1.6422, 1.6422,
         3.4833, 3.2732, 3.1986, 3.2567, 3.4079, 3.2255, 3.4581, 3.2064, 3.1852,
         1.6464, 1.6390, 1.6373, 1.6404, 1.6434, 1.6194, 1.6448, 1.5841, 1.6106,
         1.3207, 1.3150, 1.3051, 1.3199, 1.3156, 1.3076, 1.3200, 1.3203, 1.3220],
        [1.4603, 1.4560, 1.4124, 1.4158, 1.4535, 1.4602, 1.4587, 1.4603, 1.4603,
         1.4303, 1.4277, 1.4226, 1.4179, 1.4314, 1.3910, 1.4255, 1.4314, 1.4266,
         1.7551, 1.7464, 1.7452, 1.7532, 1.7709, 1.7695, 1.7496, 1.7710, 1.7710,
         1.4768, 1.4822, 1.5187, 1.5135, 1.4822, 1.5173, 1.5056, 1.5188, 1.5157,
         2.1983, 2.1783, 2.1669, 2.1847, 2.2283, 2.2464, 2.2128, 2.3157, 2.3128,
         1.4430, 1.4335, 1.4479, 1.4582, 1.4454, 1.4550, 1.4256, 1.4522, 1.4583],
        [1.3656, 1.2763, 1.2718, 1.2905, 1.2836, 1.2938, 1.2926, 1.2345, 1.2345,
         1.2627, 1.2241, 1.2206, 1.2268, 1.3054, 1.1762, 1.1447, 1.3054, 1.2084,
         1.6145, 1.5911, 1.5727, 1.5686, 1.5917, 1.5879, 1.6073, 1.5931, 1.5931,
         1.3651, 1.3385, 1.3394, 1.3549, 1.3406, 1.3818, 1.3844, 1.3592, 1.3394,
         1.5905, 1.5897, 1.5957, 1.5853, 1.5615, 1.5651, 1.6254, 1.5157, 1.4849,
         4.0678, 3.5879, 3.6781, 3.6613, 3.6756, 3.3560, 4.0639, 3.6351, 3.3891]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 307 : 1779.0060386440618
Test loss for epoch 307 : 195.9073965712008
Test Precision for epoch 307 : 0.26153846153846155
Test Recall for epoch 307 : 0.26153846153846155
Test F1 for epoch 307 : 0.26153846153846155


theta for epoch 308 : tensor([[3.6113, 3.6321, 3.7752, 3.7235, 3.7071, 3.5927, 3.6338, 3.5331, 3.5331,
         1.2570, 1.2360, 1.2336, 1.2380, 1.2790, 1.2165, 1.1849, 1.2790, 1.2227,
         1.5984, 1.5826, 1.6069, 1.5888, 1.5944, 1.5961, 1.6040, 1.5960, 1.5960,
         1.3431, 1.3543, 1.3395, 1.3621, 1.3422, 1.3739, 1.3664, 1.3531, 1.3395,
         1.5923, 1.6086, 1.5971, 1.5936, 1.6006, 1.5909, 1.6095, 1.5631, 1.5678,
         1.2565, 1.2791, 1.2705, 1.2891, 1.2520, 1.2401, 1.2320, 1.3133, 1.2669],
        [1.3696, 1.2160, 1.2059, 1.2491, 1.2493, 1.2617, 1.2556, 1.1593, 1.1593,
         3.5928, 3.6808, 3.5221, 3.9230, 3.5929, 4.2765, 3.4549, 3.5474, 4.0344,
         1.5650, 1.5525, 1.5268, 1.5247, 1.5458, 1.5553, 1.5802, 1.5553, 1.5553,
         1.3415, 1.3078, 1.3014, 1.3598, 1.3015, 1.3975, 1.3775, 1.3459, 1.2982,
         1.5336, 1.5904, 1.5536, 1.5403, 1.5353, 1.5735, 1.5931, 1.4260, 1.5245,
         1.1595, 1.2632, 1.2337, 1.2868, 1.1556, 1.1536, 1.0875, 1.3542, 1.2229],
        [1.4555, 1.4555, 1.4538, 1.4510, 1.4514, 1.4555, 1.4512, 1.4555, 1.4555,
         1.4282, 1.4275, 1.4282, 1.4281, 1.4282, 1.4094, 1.4282, 1.4270, 1.4248,
         2.2023, 2.2026, 2.2194, 2.1950, 2.1765, 2.1747, 2.2039, 2.1738, 2.1738,
         1.5138, 1.5122, 1.5197, 1.5197, 1.5139, 1.5197, 1.5196, 1.5197, 1.5197,
         1.7719, 1.7720, 1.7720, 1.7688, 1.7719, 1.7719, 1.7720, 1.7493, 1.7520,
         1.4474, 1.4520, 1.4520, 1.4520, 1.4437, 1.4520, 1.4480, 1.4520, 1.4520],
        [1.3249, 1.3228, 1.3068, 1.2981, 1.3217, 1.3201, 1.3213, 1.3216, 1.3216,
         1.2948, 1.2880, 1.2841, 1.2837, 1.2957, 1.2798, 1.2909, 1.2953, 1.2673,
         1.6458, 1.6194, 1.6428, 1.6421, 1.6415, 1.6416, 1.6438, 1.6452, 1.6452,
         3.4853, 3.2752, 3.2007, 3.2588, 3.4099, 3.2276, 3.4601, 3.2085, 3.1873,
         1.6460, 1.6386, 1.6369, 1.6399, 1.6429, 1.6189, 1.6444, 1.5836, 1.6101,
         1.3173, 1.3116, 1.3017, 1.3166, 1.3123, 1.3043, 1.3166, 1.3169, 1.3187],
        [1.4583, 1.4540, 1.4103, 1.4138, 1.4515, 1.4583, 1.4567, 1.4584, 1.4584,
         1.4299, 1.4273, 1.4223, 1.4175, 1.4310, 1.3905, 1.4251, 1.4310, 1.4262,
         1.7579, 1.7492, 1.7480, 1.7561, 1.7738, 1.7724, 1.7525, 1.7739, 1.7739,
         1.4805, 1.4858, 1.5224, 1.5171, 1.4859, 1.5210, 1.5093, 1.5225, 1.5193,
         2.1977, 2.1777, 2.1664, 2.1842, 2.2278, 2.2458, 2.2122, 2.3153, 2.3124,
         1.4395, 1.4300, 1.4444, 1.4548, 1.4419, 1.4515, 1.4220, 1.4487, 1.4549],
        [1.3539, 1.2670, 1.2621, 1.2807, 1.2737, 1.2839, 1.2828, 1.2265, 1.2265,
         1.2582, 1.2197, 1.2165, 1.2224, 1.3008, 1.1719, 1.1406, 1.3008, 1.2040,
         1.6122, 1.5889, 1.5702, 1.5667, 1.5899, 1.5860, 1.6051, 1.5913, 1.5913,
         1.3614, 1.3348, 1.3365, 1.3511, 1.3372, 1.3775, 1.3804, 1.3556, 1.3365,
         1.5865, 1.5852, 1.5916, 1.5812, 1.5572, 1.5606, 1.6207, 1.5115, 1.4805,
         4.0740, 3.5939, 3.6841, 3.6673, 3.6815, 3.3621, 4.0701, 3.6410, 3.3952]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 308 : 1779.6616175189326
Test loss for epoch 308 : 194.6966178335754
Test Precision for epoch 308 : 0.26153846153846155
Test Recall for epoch 308 : 0.26153846153846155
Test F1 for epoch 308 : 0.26153846153846155


theta for epoch 309 : tensor([[3.6125, 3.6332, 3.7763, 3.7246, 3.7082, 3.5939, 3.6349, 3.5343, 3.5343,
         1.2605, 1.2391, 1.2369, 1.2412, 1.2828, 1.2196, 1.1869, 1.2828, 1.2256,
         1.6000, 1.5842, 1.6086, 1.5904, 1.5961, 1.5978, 1.6056, 1.5977, 1.5977,
         1.3396, 1.3508, 1.3361, 1.3585, 1.3388, 1.3702, 1.3629, 1.3496, 1.3362,
         1.5934, 1.6097, 1.5982, 1.5947, 1.6017, 1.5919, 1.6105, 1.5641, 1.5688,
         1.2494, 1.2722, 1.2637, 1.2820, 1.2450, 1.2333, 1.2250, 1.3058, 1.2602],
        [1.3813, 1.2264, 1.2165, 1.2596, 1.2599, 1.2722, 1.2661, 1.1687, 1.1687,
         3.5807, 3.6687, 3.5099, 3.9112, 3.5808, 4.2655, 3.4427, 3.5353, 4.0228,
         1.5766, 1.5640, 1.5385, 1.5360, 1.5571, 1.5665, 1.5917, 1.5665, 1.5665,
         1.3507, 1.3170, 1.3101, 1.3690, 1.3106, 1.4070, 1.3869, 1.3550, 1.3070,
         1.5439, 1.6007, 1.5637, 1.5505, 1.5456, 1.5838, 1.6036, 1.4368, 1.5349,
         1.1662, 1.2703, 1.2409, 1.2938, 1.1622, 1.1602, 1.0936, 1.3611, 1.2302],
        [1.4505, 1.4504, 1.4487, 1.4459, 1.4463, 1.4505, 1.4461, 1.4504, 1.4504,
         1.4328, 1.4321, 1.4327, 1.4327, 1.4328, 1.4140, 1.4327, 1.4316, 1.4293,
         2.2047, 2.2050, 2.2218, 2.1973, 2.1787, 2.1770, 2.2061, 2.1760, 2.1760,
         1.5118, 1.5102, 1.5176, 1.5176, 1.5118, 1.5176, 1.5176, 1.5176, 1.5176,
         1.7737, 1.7738, 1.7738, 1.7706, 1.7737, 1.7737, 1.7738, 1.7510, 1.7538,
         1.4409, 1.4456, 1.4456, 1.4456, 1.4372, 1.4456, 1.4415, 1.4455, 1.4456],
        [1.3197, 1.3176, 1.3016, 1.2928, 1.3165, 1.3149, 1.3161, 1.3164, 1.3164,
         1.2994, 1.2926, 1.2887, 1.2883, 1.3003, 1.2844, 1.2954, 1.2999, 1.2719,
         1.6484, 1.6221, 1.6454, 1.6448, 1.6442, 1.6442, 1.6465, 1.6479, 1.6479,
         3.4825, 3.2724, 3.1979, 3.2561, 3.4071, 3.2249, 3.4573, 3.2057, 3.1845,
         1.6478, 1.6404, 1.6387, 1.6418, 1.6447, 1.6207, 1.6462, 1.5855, 1.6120,
         1.3108, 1.3052, 1.2952, 1.3101, 1.3058, 1.2978, 1.3101, 1.3105, 1.3122],
        [1.4533, 1.4489, 1.4051, 1.4087, 1.4465, 1.4532, 1.4516, 1.4533, 1.4533,
         1.4344, 1.4318, 1.4268, 1.4221, 1.4356, 1.3950, 1.4297, 1.4356, 1.4308,
         1.7605, 1.7518, 1.7506, 1.7586, 1.7763, 1.7749, 1.7550, 1.7765, 1.7765,
         1.4784, 1.4838, 1.5204, 1.5151, 1.4838, 1.5189, 1.5073, 1.5204, 1.5173,
         2.1994, 2.1794, 2.1680, 2.1859, 2.2295, 2.2475, 2.2139, 2.3171, 2.3141,
         1.4330, 1.4235, 1.4379, 1.4483, 1.4354, 1.4451, 1.4155, 1.4422, 1.4484],
        [1.3373, 1.2527, 1.2476, 1.2660, 1.2590, 1.2692, 1.2681, 1.2136, 1.2136,
         1.2567, 1.2180, 1.2152, 1.2208, 1.2994, 1.1703, 1.1385, 1.2995, 1.2023,
         1.6079, 1.5847, 1.5657, 1.5628, 1.5860, 1.5822, 1.6008, 1.5874, 1.5874,
         1.3509, 1.3244, 1.3267, 1.3404, 1.3270, 1.3665, 1.3696, 1.3451, 1.3268,
         1.5830, 1.5813, 1.5881, 1.5777, 1.5535, 1.5567, 1.6168, 1.5077, 1.4765,
         4.0826, 3.6022, 3.6925, 3.6756, 3.6898, 3.3705, 4.0787, 3.6494, 3.4036]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 309 : 1779.978515158327
Test loss for epoch 309 : 194.45801362663843
Test Precision for epoch 309 : 0.26153846153846155
Test Recall for epoch 309 : 0.26153846153846155
Test F1 for epoch 309 : 0.26153846153846155


theta for epoch 310 : tensor([[3.6185, 3.6393, 3.7823, 3.7307, 3.7143, 3.6000, 3.6411, 3.5406, 3.5406,
         1.2672, 1.2452, 1.2432, 1.2475, 1.2898, 1.2257, 1.1918, 1.2898, 1.2316,
         1.5953, 1.5796, 1.6039, 1.5858, 1.5915, 1.5931, 1.6009, 1.5931, 1.5931,
         1.3339, 1.3452, 1.3306, 1.3529, 1.3332, 1.3646, 1.3572, 1.3440, 1.3307,
         1.5929, 1.6091, 1.5977, 1.5941, 1.6011, 1.5914, 1.6100, 1.5636, 1.5682,
         1.2416, 1.2646, 1.2563, 1.2744, 1.2371, 1.2258, 1.2171, 1.2978, 1.2529],
        [1.3885, 1.2322, 1.2225, 1.2657, 1.2659, 1.2783, 1.2722, 1.1738, 1.1738,
         3.5765, 3.6646, 3.5057, 3.9075, 3.5766, 4.2624, 3.4384, 3.5310, 4.0192,
         1.5786, 1.5659, 1.5407, 1.5377, 1.5587, 1.5682, 1.5936, 1.5682, 1.5682,
         1.3534, 1.3197, 1.3123, 1.3717, 1.3131, 1.4099, 1.3897, 1.3576, 1.3091,
         1.5480, 1.6051, 1.5678, 1.5547, 1.5499, 1.5881, 1.6081, 1.4412, 1.5391,
         1.1668, 1.2716, 1.2423, 1.2950, 1.1625, 1.1607, 1.0935, 1.3622, 1.2315],
        [1.4510, 1.4510, 1.4493, 1.4465, 1.4468, 1.4510, 1.4467, 1.4510, 1.4510,
         1.4407, 1.4400, 1.4406, 1.4406, 1.4407, 1.4219, 1.4407, 1.4395, 1.4373,
         2.2015, 2.2019, 2.2186, 2.1942, 2.1757, 2.1739, 2.2031, 2.1730, 2.1730,
         1.5081, 1.5065, 1.5139, 1.5139, 1.5081, 1.5139, 1.5138, 1.5139, 1.5139,
         1.7742, 1.7743, 1.7743, 1.7711, 1.7742, 1.7742, 1.7743, 1.7515, 1.7543,
         1.4343, 1.4390, 1.4390, 1.4390, 1.4307, 1.4390, 1.4350, 1.4390, 1.4390],
        [1.3201, 1.3180, 1.3021, 1.2933, 1.3170, 1.3154, 1.3165, 1.3169, 1.3169,
         1.3073, 1.3005, 1.2966, 1.2963, 1.3083, 1.2924, 1.3033, 1.3079, 1.2798,
         1.6451, 1.6187, 1.6421, 1.6414, 1.6408, 1.6409, 1.6431, 1.6445, 1.6445,
         3.4783, 3.2683, 3.1937, 3.2519, 3.4029, 3.2207, 3.4531, 3.2016, 3.1803,
         1.6483, 1.6409, 1.6392, 1.6423, 1.6453, 1.6213, 1.6467, 1.5860, 1.6125,
         1.3042, 1.2986, 1.2887, 1.3035, 1.2992, 1.2912, 1.3035, 1.3039, 1.3056],
        [1.4539, 1.4494, 1.4056, 1.4092, 1.4470, 1.4538, 1.4522, 1.4539, 1.4539,
         1.4423, 1.4398, 1.4347, 1.4300, 1.4435, 1.4029, 1.4376, 1.4435, 1.4387,
         1.7572, 1.7485, 1.7473, 1.7553, 1.7731, 1.7716, 1.7517, 1.7732, 1.7732,
         1.4746, 1.4800, 1.5166, 1.5113, 1.4800, 1.5152, 1.5035, 1.5167, 1.5136,
         2.1999, 2.1799, 2.1685, 2.1864, 2.2300, 2.2480, 2.2143, 2.3176, 2.3147,
         1.4263, 1.4169, 1.4313, 1.4418, 1.4288, 1.4385, 1.4088, 1.4357, 1.4418],
        [1.3235, 1.2403, 1.2350, 1.2533, 1.2463, 1.2566, 1.2554, 1.2021, 1.2021,
         1.2574, 1.2182, 1.2156, 1.2211, 1.3004, 1.1703, 1.1376, 1.3004, 1.2023,
         1.5969, 1.5738, 1.5547, 1.5521, 1.5754, 1.5715, 1.5899, 1.5768, 1.5768,
         1.3375, 1.3110, 1.3139, 1.3269, 1.3138, 1.3527, 1.3560, 1.3318, 1.3139,
         1.5771, 1.5750, 1.5822, 1.5718, 1.5474, 1.5504, 1.6106, 1.5015, 1.4701,
         4.0939, 3.6132, 3.7035, 3.6866, 3.7008, 3.3816, 4.0900, 3.6603, 3.4147]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 310 : 1779.9551548605623
Test loss for epoch 310 : 194.81152334951784
Test Precision for epoch 310 : 0.26153846153846155
Test Recall for epoch 310 : 0.26153846153846155
Test F1 for epoch 310 : 0.26153846153846155


theta for epoch 311 : tensor([[3.6268, 3.6477, 3.7906, 3.7390, 3.7227, 3.6085, 3.6494, 3.5492, 3.5492,
         1.2702, 1.2476, 1.2458, 1.2500, 1.2930, 1.2280, 1.1930, 1.2930, 1.2338,
         1.5901, 1.5743, 1.5987, 1.5806, 1.5863, 1.5879, 1.5957, 1.5879, 1.5879,
         1.3339, 1.3452, 1.3307, 1.3529, 1.3332, 1.3645, 1.3572, 1.3440, 1.3307,
         1.5897, 1.6060, 1.5945, 1.5910, 1.5980, 1.5882, 1.6069, 1.5604, 1.5650,
         1.2358, 1.2593, 1.2510, 1.2690, 1.2312, 1.2202, 1.2111, 1.2923, 1.2477],
        [1.3895, 1.2322, 1.2226, 1.2659, 1.2661, 1.2785, 1.2724, 1.1733, 1.1733,
         3.5778, 3.6660, 3.5070, 3.9092, 3.5779, 4.2648, 3.4397, 3.5324, 4.0211,
         1.5754, 1.5627, 1.5376, 1.5343, 1.5553, 1.5647, 1.5904, 1.5648, 1.5648,
         1.3540, 1.3203, 1.3125, 1.3724, 1.3136, 1.4109, 1.3906, 1.3582, 1.3094,
         1.5457, 1.6029, 1.5654, 1.5523, 1.5476, 1.5859, 1.6060, 1.4389, 1.5368,
         1.1633, 1.2690, 1.2398, 1.2925, 1.1588, 1.1572, 1.0893, 1.3597, 1.2291],
        [1.4529, 1.4528, 1.4512, 1.4484, 1.4487, 1.4529, 1.4486, 1.4529, 1.4529,
         1.4449, 1.4442, 1.4449, 1.4449, 1.4449, 1.4262, 1.4449, 1.4437, 1.4415,
         2.1981, 2.1984, 2.2152, 2.1909, 2.1723, 2.1706, 2.1997, 2.1696, 2.1696,
         1.5102, 1.5086, 1.5160, 1.5160, 1.5102, 1.5160, 1.5160, 1.5160, 1.5160,
         1.7724, 1.7724, 1.7724, 1.7693, 1.7723, 1.7723, 1.7724, 1.7497, 1.7524,
         1.4304, 1.4351, 1.4351, 1.4351, 1.4268, 1.4351, 1.4310, 1.4351, 1.4351],
        [1.3218, 1.3197, 1.3037, 1.2950, 1.3187, 1.3171, 1.3182, 1.3186, 1.3186,
         1.3115, 1.3047, 1.3009, 1.3005, 1.3125, 1.2966, 1.3075, 1.3121, 1.2841,
         1.6414, 1.6151, 1.6384, 1.6378, 1.6371, 1.6372, 1.6395, 1.6409, 1.6409,
         3.4796, 3.2696, 3.1951, 3.2532, 3.4042, 3.2221, 3.4544, 3.2029, 3.1817,
         1.6464, 1.6390, 1.6373, 1.6404, 1.6434, 1.6194, 1.6448, 1.5841, 1.6106,
         1.3002, 1.2946, 1.2847, 1.2995, 1.2952, 1.2872, 1.2995, 1.2999, 1.3017],
        [1.4557, 1.4513, 1.4075, 1.4111, 1.4489, 1.4556, 1.4540, 1.4557, 1.4557,
         1.4466, 1.4440, 1.4390, 1.4342, 1.4478, 1.4071, 1.4418, 1.4477, 1.4429,
         1.7537, 1.7450, 1.7437, 1.7518, 1.7695, 1.7681, 1.7482, 1.7697, 1.7697,
         1.4767, 1.4821, 1.5187, 1.5134, 1.4821, 1.5173, 1.5056, 1.5188, 1.5157,
         2.1980, 2.1780, 2.1666, 2.1845, 2.2282, 2.2461, 2.2124, 2.3159, 2.3129,
         1.4224, 1.4130, 1.4274, 1.4379, 1.4249, 1.4346, 1.4049, 1.4318, 1.4379],
        [1.3103, 1.2273, 1.2219, 1.2403, 1.2332, 1.2435, 1.2424, 1.1894, 1.1894,
         1.2541, 1.2142, 1.2119, 1.2172, 1.2976, 1.1661, 1.1319, 1.2976, 1.1980,
         1.5848, 1.5616, 1.5424, 1.5400, 1.5634, 1.5596, 1.5778, 1.5649, 1.5649,
         1.3282, 1.3016, 1.3048, 1.3175, 1.3044, 1.3432, 1.3466, 1.3225, 1.3048,
         1.5680, 1.5657, 1.5731, 1.5626, 1.5381, 1.5410, 1.6013, 1.4920, 1.4604,
         4.1083, 3.6273, 3.7176, 3.7007, 3.7149, 3.3957, 4.1044, 3.6744, 3.4288]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 311 : 1779.8371494320518
Test loss for epoch 311 : 195.37722852833315
Test Precision for epoch 311 : 0.26153846153846155
Test Recall for epoch 311 : 0.26153846153846155
Test F1 for epoch 311 : 0.26153846153846155


theta for epoch 312 : tensor([[3.6355, 3.6566, 3.7993, 3.7477, 3.7314, 3.6173, 3.6582, 3.5581, 3.5581,
         1.2650, 1.2420, 1.2403, 1.2445, 1.2881, 1.2223, 1.1862, 1.2881, 1.2280,
         1.5908, 1.5750, 1.5993, 1.5812, 1.5870, 1.5886, 1.5964, 1.5886, 1.5886,
         1.3382, 1.3495, 1.3350, 1.3572, 1.3375, 1.3688, 1.3615, 1.3483, 1.3351,
         1.5875, 1.6038, 1.5923, 1.5888, 1.5958, 1.5860, 1.6047, 1.5581, 1.5628,
         1.2319, 1.2561, 1.2478, 1.2658, 1.2271, 1.2164, 1.2070, 1.2891, 1.2445],
        [1.3833, 1.2256, 1.2160, 1.2594, 1.2596, 1.2720, 1.2659, 1.1665, 1.1665,
         3.5829, 3.6712, 3.5121, 3.9147, 3.5830, 4.2710, 3.4447, 3.5374, 4.0268,
         1.5719, 1.5591, 1.5340, 1.5307, 1.5517, 1.5611, 1.5869, 1.5612, 1.5612,
         1.3525, 1.3186, 1.3107, 1.3709, 1.3119, 1.4096, 1.3892, 1.3566, 1.3076,
         1.5401, 1.5975, 1.5599, 1.5468, 1.5421, 1.5805, 1.6007, 1.4332, 1.5312,
         1.1562, 1.2632, 1.2339, 1.2866, 1.1515, 1.1503, 1.0815, 1.3538, 1.2233],
        [1.4524, 1.4523, 1.4507, 1.4479, 1.4482, 1.4524, 1.4481, 1.4524, 1.4524,
         1.4412, 1.4405, 1.4412, 1.4411, 1.4412, 1.4224, 1.4412, 1.4400, 1.4378,
         2.2003, 2.2007, 2.2174, 2.1931, 2.1745, 2.1727, 2.2019, 2.1718, 2.1718,
         1.5168, 1.5152, 1.5227, 1.5227, 1.5169, 1.5227, 1.5226, 1.5227, 1.5227,
         1.7717, 1.7718, 1.7718, 1.7686, 1.7717, 1.7717, 1.7718, 1.7490, 1.7517,
         1.4293, 1.4339, 1.4339, 1.4339, 1.4256, 1.4339, 1.4299, 1.4339, 1.4339],
        [1.3209, 1.3189, 1.3029, 1.2941, 1.3178, 1.3162, 1.3174, 1.3178, 1.3178,
         1.3077, 1.3009, 1.2970, 1.2967, 1.3087, 1.2928, 1.3036, 1.3083, 1.2802,
         1.6438, 1.6174, 1.6407, 1.6401, 1.6395, 1.6395, 1.6418, 1.6432, 1.6432,
         3.4853, 3.2755, 3.2010, 3.2591, 3.4100, 3.2279, 3.4602, 3.2088, 3.1876,
         1.6457, 1.6383, 1.6366, 1.6397, 1.6426, 1.6186, 1.6441, 1.5834, 1.6099,
         1.2989, 1.2933, 1.2834, 1.2982, 1.2939, 1.2859, 1.2982, 1.2985, 1.3004],
        [1.4552, 1.4508, 1.4070, 1.4106, 1.4484, 1.4551, 1.4536, 1.4552, 1.4552,
         1.4428, 1.4403, 1.4352, 1.4304, 1.4440, 1.4034, 1.4381, 1.4440, 1.4392,
         1.7561, 1.7474, 1.7461, 1.7542, 1.7719, 1.7705, 1.7506, 1.7721, 1.7721,
         1.4834, 1.4888, 1.5254, 1.5201, 1.4888, 1.5239, 1.5123, 1.5255, 1.5223,
         2.1974, 2.1773, 2.1659, 2.1838, 2.2275, 2.2454, 2.2118, 2.3152, 2.3123,
         1.4213, 1.4119, 1.4262, 1.4367, 1.4237, 1.4334, 1.4037, 1.4306, 1.4368],
        [1.2961, 1.2120, 1.2065, 1.2251, 1.2180, 1.2284, 1.2272, 1.1735, 1.1735,
         1.2432, 1.2023, 1.2003, 1.2056, 1.2873, 1.1540, 1.1180, 1.2873, 1.1858,
         1.5777, 1.5543, 1.5350, 1.5326, 1.5561, 1.5523, 1.5705, 1.5576, 1.5576,
         1.3223, 1.2955, 1.2987, 1.3116, 1.2984, 1.3375, 1.3410, 1.3167, 1.2988,
         1.5593, 1.5569, 1.5644, 1.5539, 1.5292, 1.5321, 1.5927, 1.4828, 1.4510,
         4.1253, 3.6440, 3.7343, 3.7174, 3.7315, 3.4125, 4.1215, 3.6911, 3.4456]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 312 : 1779.3045806912326
Test loss for epoch 312 : 195.9904371157278
Test Precision for epoch 312 : 0.26153846153846155
Test Recall for epoch 312 : 0.26153846153846155
Test F1 for epoch 312 : 0.26153846153846155


theta for epoch 313 : tensor([[3.6372, 3.6582, 3.8009, 3.7494, 3.7331, 3.6189, 3.6599, 3.5598, 3.5598,
         1.2582, 1.2347, 1.2332, 1.2373, 1.2814, 1.2151, 1.1781, 1.2814, 1.2206,
         1.5977, 1.5819, 1.6062, 1.5881, 1.5939, 1.5955, 1.6033, 1.5955, 1.5955,
         1.3406, 1.3519, 1.3375, 1.3596, 1.3399, 1.3712, 1.3639, 1.3507, 1.3375,
         1.5900, 1.6064, 1.5948, 1.5913, 1.5983, 1.5885, 1.6072, 1.5607, 1.5653,
         1.2300, 1.2543, 1.2463, 1.2638, 1.2252, 1.2151, 1.2053, 1.2871, 1.2430],
        [1.3761, 1.2189, 1.2092, 1.2526, 1.2528, 1.2652, 1.2591, 1.1600, 1.1600,
         3.5884, 3.6767, 3.5175, 3.9206, 3.5885, 4.2776, 3.4502, 3.5428, 4.0329,
         1.5707, 1.5579, 1.5326, 1.5294, 1.5506, 1.5600, 1.5858, 1.5601, 1.5601,
         1.3476, 1.3137, 1.3060, 1.3661, 1.3070, 1.4047, 1.3843, 1.3518, 1.3028,
         1.5366, 1.5941, 1.5565, 1.5433, 1.5385, 1.5770, 1.5972, 1.4293, 1.5276,
         1.1489, 1.2560, 1.2273, 1.2791, 1.1444, 1.1440, 1.0742, 1.3461, 1.2168],
        [1.4538, 1.4538, 1.4521, 1.4493, 1.4497, 1.4538, 1.4495, 1.4538, 1.4538,
         1.4343, 1.4336, 1.4343, 1.4342, 1.4343, 1.4155, 1.4343, 1.4331, 1.4309,
         2.2068, 2.2072, 2.2239, 2.1993, 2.1807, 2.1790, 2.2081, 2.1780, 2.1780,
         1.5193, 1.5177, 1.5251, 1.5251, 1.5194, 1.5251, 1.5251, 1.5251, 1.5251,
         1.7744, 1.7745, 1.7745, 1.7713, 1.7743, 1.7743, 1.7745, 1.7517, 1.7544,
         1.4277, 1.4324, 1.4323, 1.4324, 1.4240, 1.4323, 1.4283, 1.4323, 1.4323],
        [1.3219, 1.3200, 1.3040, 1.2952, 1.3189, 1.3173, 1.3184, 1.3189, 1.3189,
         1.3008, 1.2939, 1.2901, 1.2897, 1.3018, 1.2858, 1.2966, 1.3013, 1.2732,
         1.6506, 1.6243, 1.6476, 1.6469, 1.6463, 1.6464, 1.6486, 1.6500, 1.6500,
         3.4876, 3.2779, 3.2035, 3.2615, 3.4124, 3.2304, 3.4625, 3.2113, 3.1901,
         1.6483, 1.6409, 1.6392, 1.6422, 1.6452, 1.6212, 1.6467, 1.5860, 1.6125,
         1.2971, 1.2915, 1.2816, 1.2964, 1.2921, 1.2841, 1.2964, 1.2967, 1.2986],
        [1.4567, 1.4523, 1.4086, 1.4121, 1.4499, 1.4566, 1.4550, 1.4567, 1.4567,
         1.4360, 1.4334, 1.4283, 1.4235, 1.4371, 1.3965, 1.4312, 1.4371, 1.4323,
         1.7630, 1.7543, 1.7530, 1.7611, 1.7788, 1.7774, 1.7575, 1.7789, 1.7789,
         1.4859, 1.4913, 1.5279, 1.5226, 1.4913, 1.5264, 1.5148, 1.5279, 1.5248,
         2.1999, 2.1798, 2.1684, 2.1863, 2.2300, 2.2480, 2.2143, 2.3177, 2.3148,
         1.4197, 1.4103, 1.4247, 1.4351, 1.4222, 1.4319, 1.4022, 1.4290, 1.4352],
        [1.3171, 1.2320, 1.2268, 1.2453, 1.2383, 1.2486, 1.2475, 1.1929, 1.1929,
         1.2462, 1.2044, 1.2026, 1.2079, 1.2905, 1.1563, 1.1182, 1.2905, 1.1876,
         1.5950, 1.5717, 1.5525, 1.5500, 1.5734, 1.5695, 1.5879, 1.5749, 1.5749,
         1.3387, 1.3120, 1.3149, 1.3281, 1.3148, 1.3541, 1.3574, 1.3330, 1.3149,
         1.5712, 1.5690, 1.5763, 1.5658, 1.5413, 1.5443, 1.6046, 1.4952, 1.4637,
         4.1031, 3.6215, 3.7118, 3.6949, 3.7090, 3.3899, 4.0992, 3.6685, 3.4230]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 313 : 1779.4583760505377
Test loss for epoch 313 : 195.1259636198134
Test Precision for epoch 313 : 0.26153846153846155
Test Recall for epoch 313 : 0.26153846153846155
Test F1 for epoch 313 : 0.26153846153846155


theta for epoch 314 : tensor([[3.6377, 3.6587, 3.8014, 3.7499, 3.7335, 3.6194, 3.6604, 3.5603, 3.5603,
         1.2542, 1.2303, 1.2289, 1.2330, 1.2776, 1.2106, 1.1728, 1.2776, 1.2160,
         1.5986, 1.5828, 1.6072, 1.5891, 1.5948, 1.5964, 1.6042, 1.5964, 1.5964,
         1.3330, 1.3443, 1.3299, 1.3520, 1.3323, 1.3636, 1.3562, 1.3431, 1.3299,
         1.5929, 1.6093, 1.5977, 1.5942, 1.6012, 1.5914, 1.6101, 1.5635, 1.5682,
         1.2376, 1.2622, 1.2543, 1.2716, 1.2328, 1.2231, 1.2129, 1.2950, 1.2512],
        [1.3616, 1.2052, 1.1954, 1.2387, 1.2390, 1.2514, 1.2453, 1.1468, 1.1468,
         3.5998, 3.6882, 3.5289, 3.9324, 3.5998, 4.2901, 3.4616, 3.5542, 4.0449,
         1.5618, 1.5490, 1.5235, 1.5205, 1.5417, 1.5512, 1.5770, 1.5513, 1.5513,
         1.3334, 1.2995, 1.2920, 1.3519, 1.2928, 1.3904, 1.3700, 1.3376, 1.2888,
         1.5299, 1.5876, 1.5499, 1.5366, 1.5318, 1.5704, 1.5907, 1.4220, 1.5209,
         1.1437, 1.2514, 1.2230, 1.2743, 1.1392, 1.1397, 1.0686, 1.3413, 1.2128],
        [1.4502, 1.4501, 1.4484, 1.4456, 1.4460, 1.4501, 1.4458, 1.4501, 1.4501,
         1.4304, 1.4297, 1.4304, 1.4303, 1.4304, 1.4116, 1.4304, 1.4292, 1.4270,
         2.2080, 2.2083, 2.2251, 2.2004, 2.1819, 2.1801, 2.2092, 2.1792, 2.1792,
         1.5120, 1.5104, 1.5179, 1.5179, 1.5121, 1.5179, 1.5178, 1.5179, 1.5179,
         1.7776, 1.7777, 1.7777, 1.7745, 1.7776, 1.7776, 1.7777, 1.7549, 1.7576,
         1.4362, 1.4408, 1.4408, 1.4408, 1.4325, 1.4408, 1.4368, 1.4408, 1.4408],
        [1.3176, 1.3158, 1.2998, 1.2910, 1.3147, 1.3131, 1.3142, 1.3148, 1.3147,
         1.2967, 1.2899, 1.2860, 1.2856, 1.2977, 1.2817, 1.2926, 1.2973, 1.2692,
         1.6517, 1.6254, 1.6487, 1.6480, 1.6474, 1.6474, 1.6497, 1.6511, 1.6511,
         3.4816, 3.2719, 3.1975, 3.2556, 3.4064, 3.2244, 3.4566, 3.2053, 3.1841,
         1.6513, 1.6439, 1.6423, 1.6453, 1.6483, 1.6243, 1.6498, 1.5891, 1.6156,
         1.3054, 1.2998, 1.2899, 1.3047, 1.3004, 1.2925, 1.3047, 1.3050, 1.3069],
        [1.4530, 1.4487, 1.4051, 1.4085, 1.4462, 1.4529, 1.4514, 1.4530, 1.4530,
         1.4321, 1.4295, 1.4244, 1.4196, 1.4332, 1.3926, 1.4273, 1.4332, 1.4284,
         1.7643, 1.7556, 1.7544, 1.7624, 1.7801, 1.7787, 1.7588, 1.7802, 1.7802,
         1.4786, 1.4841, 1.5206, 1.5153, 1.4841, 1.5192, 1.5075, 1.5207, 1.5175,
         2.2029, 2.1829, 2.1715, 2.1894, 2.2331, 2.2510, 2.2174, 2.3207, 2.3178,
         1.4283, 1.4188, 1.4332, 1.4436, 1.4307, 1.4403, 1.4108, 1.4375, 1.4436],
        [1.3309, 1.2442, 1.2392, 1.2579, 1.2509, 1.2612, 1.2600, 1.2041, 1.2041,
         1.2497, 1.2068, 1.2053, 1.2106, 1.2945, 1.1589, 1.1183, 1.2945, 1.1898,
         1.6046, 1.5814, 1.5623, 1.5595, 1.5828, 1.5790, 1.5975, 1.5843, 1.5843,
         1.3439, 1.3172, 1.3196, 1.3334, 1.3199, 1.3596, 1.3627, 1.3382, 1.3196,
         1.5812, 1.5792, 1.5863, 1.5759, 1.5515, 1.5546, 1.6147, 1.5055, 1.4742,
         4.0901, 3.6082, 3.6985, 3.6817, 3.6957, 3.3766, 4.0863, 3.6553, 3.4098]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 314 : 1779.0088958546492
Test loss for epoch 314 : 195.25999902127478
Test Precision for epoch 314 : 0.26153846153846155
Test Recall for epoch 314 : 0.26153846153846155
Test F1 for epoch 314 : 0.26153846153846155


theta for epoch 315 : tensor([[3.6317, 3.6527, 3.7954, 3.7439, 3.7275, 3.6134, 3.6544, 3.5542, 3.5542,
         1.2535, 1.2297, 1.2284, 1.2324, 1.2766, 1.2101, 1.1724, 1.2766, 1.2154,
         1.5926, 1.5768, 1.6012, 1.5831, 1.5888, 1.5904, 1.5982, 1.5904, 1.5904,
         1.3310, 1.3424, 1.3279, 1.3501, 1.3303, 1.3616, 1.3543, 1.3412, 1.3280,
         1.5926, 1.6090, 1.5975, 1.5939, 1.6010, 1.5912, 1.6099, 1.5633, 1.5680,
         1.2512, 1.2763, 1.2685, 1.2855, 1.2464, 1.2371, 1.2267, 1.3090, 1.2654],
        [1.3598, 1.2046, 1.1947, 1.2379, 1.2382, 1.2506, 1.2445, 1.1467, 1.1467,
         3.5984, 3.6870, 3.5275, 3.9314, 3.5985, 4.2899, 3.4602, 3.5528, 4.0442,
         1.5574, 1.5447, 1.5192, 1.5164, 1.5376, 1.5471, 1.5726, 1.5471, 1.5471,
         1.3320, 1.2982, 1.2910, 1.3505, 1.2917, 1.3887, 1.3685, 1.3363, 1.2878,
         1.5298, 1.5872, 1.5498, 1.5365, 1.5316, 1.5702, 1.5903, 1.4219, 1.5208,
         1.1523, 1.2606, 1.2326, 1.2832, 1.1477, 1.1492, 1.0769, 1.3500, 1.2225],
        [1.4467, 1.4466, 1.4450, 1.4422, 1.4426, 1.4467, 1.4423, 1.4467, 1.4467,
         1.4288, 1.4281, 1.4287, 1.4287, 1.4288, 1.4100, 1.4287, 1.4276, 1.4254,
         2.2015, 2.2018, 2.2186, 2.1942, 2.1756, 2.1739, 2.2030, 2.1729, 2.1729,
         1.5086, 1.5070, 1.5144, 1.5144, 1.5086, 1.5144, 1.5144, 1.5144, 1.5144,
         1.7766, 1.7767, 1.7767, 1.7735, 1.7766, 1.7766, 1.7767, 1.7540, 1.7567,
         1.4493, 1.4539, 1.4539, 1.4539, 1.4456, 1.4539, 1.4499, 1.4539, 1.4539],
        [1.3136, 1.3118, 1.2959, 1.2871, 1.3107, 1.3091, 1.3103, 1.3108, 1.3108,
         1.2950, 1.2881, 1.2843, 1.2839, 1.2959, 1.2800, 1.2909, 1.2955, 1.2675,
         1.6445, 1.6183, 1.6415, 1.6409, 1.6403, 1.6403, 1.6426, 1.6440, 1.6440,
         3.4793, 3.2696, 3.1952, 3.2533, 3.4040, 3.2222, 3.4542, 3.2030, 3.1818,
         1.6502, 1.6428, 1.6412, 1.6442, 1.6472, 1.6232, 1.6487, 1.5881, 1.6145,
         1.3183, 1.3127, 1.3029, 1.3176, 1.3133, 1.3054, 1.3177, 1.3179, 1.3198],
        [1.4495, 1.4452, 1.4018, 1.4050, 1.4428, 1.4494, 1.4479, 1.4495, 1.4495,
         1.4304, 1.4279, 1.4228, 1.4180, 1.4316, 1.3910, 1.4257, 1.4316, 1.4268,
         1.7575, 1.7488, 1.7476, 1.7556, 1.7733, 1.7719, 1.7520, 1.7734, 1.7734,
         1.4752, 1.4807, 1.5172, 1.5119, 1.4806, 1.5157, 1.5040, 1.5172, 1.5141,
         2.2020, 2.1820, 2.1706, 2.1884, 2.2321, 2.2500, 2.2164, 2.3197, 2.3168,
         1.4414, 1.4320, 1.4463, 1.4567, 1.4439, 1.4534, 1.4241, 1.4506, 1.4567],
        [1.3439, 1.2559, 1.2510, 1.2698, 1.2628, 1.2731, 1.2719, 1.2150, 1.2150,
         1.2549, 1.2118, 1.2105, 1.2156, 1.2995, 1.1640, 1.1226, 1.2995, 1.1946,
         1.6065, 1.5833, 1.5644, 1.5614, 1.5846, 1.5808, 1.5995, 1.5861, 1.5861,
         1.3517, 1.3251, 1.3271, 1.3414, 1.3276, 1.3677, 1.3707, 1.3460, 1.3271,
         1.5870, 1.5851, 1.5921, 1.5817, 1.5574, 1.5606, 1.6206, 1.5116, 1.4805,
         4.0799, 3.5977, 3.6880, 3.6712, 3.6851, 3.3661, 4.0761, 3.6448, 3.3993]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 315 : 1779.2424195802723
Test loss for epoch 315 : 195.17971061825125
Test Precision for epoch 315 : 0.26153846153846155
Test Recall for epoch 315 : 0.26153846153846155
Test F1 for epoch 315 : 0.26153846153846155


theta for epoch 316 : tensor([[3.6284, 3.6493, 3.7921, 3.7406, 3.7242, 3.6100, 3.6510, 3.5508, 3.5508,
         1.2560, 1.2321, 1.2309, 1.2348, 1.2789, 1.2133, 1.1746, 1.2789, 1.2187,
         1.5890, 1.5732, 1.5976, 1.5795, 1.5852, 1.5868, 1.5946, 1.5868, 1.5868,
         1.3355, 1.3469, 1.3324, 1.3546, 1.3348, 1.3662, 1.3589, 1.3457, 1.3324,
         1.5890, 1.6055, 1.5938, 1.5903, 1.5974, 1.5876, 1.6063, 1.5597, 1.5644,
         1.2548, 1.2802, 1.2725, 1.2894, 1.2498, 1.2410, 1.2303, 1.3129, 1.2695],
        [1.3623, 1.2078, 1.1978, 1.2411, 1.2413, 1.2537, 1.2476, 1.1503, 1.1503,
         3.5963, 3.6849, 3.5253, 3.9296, 3.5963, 4.2887, 3.4580, 3.5506, 4.0425,
         1.5561, 1.5434, 1.5179, 1.5153, 1.5364, 1.5459, 1.5712, 1.5459, 1.5459,
         1.3356, 1.3018, 1.2948, 1.3540, 1.2953, 1.3922, 1.3720, 1.3400, 1.2916,
         1.5282, 1.5854, 1.5481, 1.5349, 1.5300, 1.5684, 1.5884, 1.4205, 1.5191,
         1.1555, 1.2643, 1.2367, 1.2867, 1.1509, 1.1533, 1.0802, 1.3530, 1.2267],
        [1.4486, 1.4486, 1.4469, 1.4441, 1.4445, 1.4486, 1.4443, 1.4486, 1.4486,
         1.4303, 1.4296, 1.4303, 1.4303, 1.4303, 1.4115, 1.4303, 1.4291, 1.4269,
         2.1972, 2.1975, 2.2143, 2.1900, 2.1714, 2.1697, 2.1988, 2.1687, 2.1687,
         1.5114, 1.5098, 1.5172, 1.5172, 1.5114, 1.5172, 1.5172, 1.5172, 1.5172,
         1.7723, 1.7724, 1.7724, 1.7692, 1.7723, 1.7723, 1.7724, 1.7497, 1.7524,
         1.4522, 1.4568, 1.4568, 1.4568, 1.4485, 1.4568, 1.4528, 1.4567, 1.4568],
        [1.3150, 1.3133, 1.2975, 1.2887, 1.3123, 1.3106, 1.3118, 1.3124, 1.3124,
         1.2964, 1.2895, 1.2857, 1.2853, 1.2973, 1.2815, 1.2923, 1.2969, 1.2689,
         1.6396, 1.6134, 1.6366, 1.6360, 1.6354, 1.6354, 1.6377, 1.6391, 1.6391,
         3.4826, 3.2731, 3.1987, 3.2568, 3.4074, 3.2257, 3.4576, 3.2065, 3.1853,
         1.6457, 1.6383, 1.6366, 1.6397, 1.6427, 1.6187, 1.6441, 1.5835, 1.6100,
         1.3209, 1.3153, 1.3055, 1.3202, 1.3159, 1.3081, 1.3203, 1.3204, 1.3224],
        [1.4515, 1.4473, 1.4039, 1.4071, 1.4447, 1.4514, 1.4499, 1.4515, 1.4515,
         1.4320, 1.4294, 1.4244, 1.4196, 1.4332, 1.3926, 1.4272, 1.4331, 1.4283,
         1.7529, 1.7442, 1.7430, 1.7511, 1.7687, 1.7673, 1.7474, 1.7688, 1.7688,
         1.4780, 1.4836, 1.5199, 1.5147, 1.4835, 1.5185, 1.5068, 1.5200, 1.5169,
         2.1977, 2.1777, 2.1663, 2.1842, 2.2279, 2.2458, 2.2122, 2.3154, 2.3125,
         1.4444, 1.4348, 1.4492, 1.4595, 1.4468, 1.4563, 1.4270, 1.4535, 1.4596],
        [1.3567, 1.2677, 1.2630, 1.2818, 1.2749, 1.2851, 1.2839, 1.2262, 1.2262,
         1.2612, 1.2176, 1.2166, 1.2216, 1.3056, 1.1710, 1.1275, 1.3056, 1.2014,
         1.6083, 1.5852, 1.5664, 1.5632, 1.5864, 1.5825, 1.6013, 1.5878, 1.5878,
         1.3619, 1.3354, 1.3371, 1.3517, 1.3378, 1.3782, 1.3810, 1.3562, 1.3371,
         1.5878, 1.5861, 1.5929, 1.5825, 1.5584, 1.5616, 1.6214, 1.5126, 1.4817,
         4.0701, 3.5877, 3.6780, 3.6611, 3.6750, 3.3560, 4.0663, 3.6347, 3.3893]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 316 : 1779.4794204826999
Test loss for epoch 316 : 195.006220623856
Test Precision for epoch 316 : 0.26153846153846155
Test Recall for epoch 316 : 0.26153846153846155
Test F1 for epoch 316 : 0.26153846153846155


theta for epoch 317 : tensor([[3.6273, 3.6482, 3.7911, 3.7395, 3.7231, 3.6090, 3.6499, 3.5497, 3.5497,
         1.2598, 1.2356, 1.2346, 1.2384, 1.2827, 1.2175, 1.1776, 1.2827, 1.2229,
         1.5923, 1.5765, 1.6010, 1.5828, 1.5884, 1.5901, 1.5979, 1.5901, 1.5901,
         1.3378, 1.3491, 1.3346, 1.3569, 1.3370, 1.3685, 1.3612, 1.3480, 1.3347,
         1.5873, 1.6038, 1.5921, 1.5885, 1.5956, 1.5859, 1.6047, 1.5579, 1.5626,
         1.2487, 1.2745, 1.2669, 1.2836, 1.2437, 1.2353, 1.2243, 1.3072, 1.2639],
        [1.3595, 1.2052, 1.1951, 1.2384, 1.2386, 1.2510, 1.2449, 1.1478, 1.1478,
         3.6002, 3.6889, 3.5292, 3.9339, 3.6002, 4.2937, 3.4620, 3.5545, 4.0470,
         1.5556, 1.5429, 1.5174, 1.5148, 1.5360, 1.5455, 1.5708, 1.5455, 1.5455,
         1.3340, 1.3002, 1.2933, 1.3525, 1.2937, 1.3906, 1.3705, 1.3384, 1.2901,
         1.5243, 1.5816, 1.5443, 1.5310, 1.5261, 1.5645, 1.5845, 1.4166, 1.5153,
         1.1485, 1.2578, 1.2305, 1.2799, 1.1439, 1.1470, 1.0732, 1.3459, 1.2207],
        [1.4495, 1.4495, 1.4479, 1.4451, 1.4455, 1.4495, 1.4452, 1.4495, 1.4495,
         1.4337, 1.4330, 1.4337, 1.4337, 1.4337, 1.4150, 1.4337, 1.4325, 1.4303,
         2.1997, 2.2000, 2.2168, 2.1925, 2.1739, 2.1721, 2.2013, 2.1712, 2.1712,
         1.5126, 1.5110, 1.5185, 1.5184, 1.5127, 1.5184, 1.5184, 1.5184, 1.5185,
         1.7703, 1.7704, 1.7704, 1.7672, 1.7703, 1.7703, 1.7704, 1.7477, 1.7504,
         1.4459, 1.4504, 1.4504, 1.4504, 1.4422, 1.4504, 1.4465, 1.4504, 1.4504],
        [1.3155, 1.3138, 1.2980, 1.2892, 1.3128, 1.3111, 1.3123, 1.3129, 1.3129,
         1.2996, 1.2927, 1.2889, 1.2885, 1.3005, 1.2847, 1.2956, 1.3001, 1.2722,
         1.6421, 1.6159, 1.6391, 1.6385, 1.6379, 1.6379, 1.6402, 1.6416, 1.6416,
         3.4848, 3.2754, 3.2010, 3.2591, 3.4096, 3.2280, 3.4598, 3.2089, 3.1877,
         1.6435, 1.6360, 1.6344, 1.6375, 1.6404, 1.6165, 1.6419, 1.5813, 1.6078,
         1.3143, 1.3087, 1.2989, 1.3135, 1.3093, 1.3015, 1.3137, 1.3138, 1.3158],
        [1.4524, 1.4482, 1.4051, 1.4081, 1.4457, 1.4523, 1.4508, 1.4524, 1.4524,
         1.4354, 1.4328, 1.4278, 1.4230, 1.4366, 1.3961, 1.4307, 1.4365, 1.4318,
         1.7556, 1.7469, 1.7458, 1.7538, 1.7714, 1.7700, 1.7502, 1.7715, 1.7715,
         1.4793, 1.4849, 1.5212, 1.5160, 1.4847, 1.5198, 1.5080, 1.5212, 1.5181,
         2.1957, 2.1757, 2.1643, 2.1822, 2.2258, 2.2438, 2.2102, 2.3134, 2.3105,
         1.4381, 1.4286, 1.4429, 1.4532, 1.4405, 1.4500, 1.4208, 1.4472, 1.4533],
        [1.3635, 1.2739, 1.2693, 1.2881, 1.2812, 1.2915, 1.2903, 1.2321, 1.2321,
         1.2667, 1.2226, 1.2217, 1.2267, 1.3111, 1.1769, 1.1314, 1.3111, 1.2072,
         1.6138, 1.5907, 1.5719, 1.5687, 1.5918, 1.5880, 1.6067, 1.5933, 1.5933,
         1.3672, 1.3407, 1.3422, 1.3570, 1.3430, 1.3835, 1.3863, 1.3615, 1.3423,
         1.5883, 1.5866, 1.5934, 1.5831, 1.5590, 1.5622, 1.6219, 1.5133, 1.4825,
         4.0624, 3.5798, 3.6701, 3.6532, 3.6671, 3.3480, 4.0587, 3.6268, 3.3813]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 317 : 1779.3939837787595
Test loss for epoch 317 : 195.142840435394
Test Precision for epoch 317 : 0.26153846153846155
Test Recall for epoch 317 : 0.26153846153846155
Test F1 for epoch 317 : 0.26153846153846155


theta for epoch 318 : tensor([[3.6223, 3.6431, 3.7861, 3.7345, 3.7181, 3.6038, 3.6448, 3.5445, 3.5445,
         1.2604, 1.2358, 1.2348, 1.2393, 1.2835, 1.2192, 1.1768, 1.2835, 1.2246,
         1.5991, 1.5833, 1.6078, 1.5895, 1.5952, 1.5968, 1.6047, 1.5968, 1.5968,
         1.3351, 1.3464, 1.3318, 1.3541, 1.3342, 1.3659, 1.3585, 1.3452, 1.3318,
         1.5902, 1.6067, 1.5950, 1.5914, 1.5986, 1.5888, 1.6076, 1.5608, 1.5655,
         1.2472, 1.2733, 1.2658, 1.2824, 1.2421, 1.2340, 1.2229, 1.3059, 1.2628],
        [1.3628, 1.2086, 1.1985, 1.2417, 1.2420, 1.2544, 1.2483, 1.1512, 1.1512,
         3.5952, 3.6841, 3.5242, 3.9293, 3.5952, 4.2897, 3.4571, 3.5495, 4.0425,
         1.5635, 1.5508, 1.5252, 1.5227, 1.5439, 1.5534, 1.5787, 1.5534, 1.5534,
         1.3358, 1.3020, 1.2951, 1.3543, 1.2956, 1.3923, 1.3722, 1.3402, 1.2920,
         1.5297, 1.5869, 1.5496, 1.5364, 1.5315, 1.5699, 1.5899, 1.4221, 1.5206,
         1.1508, 1.2606, 1.2336, 1.2825, 1.1460, 1.1499, 1.0755, 1.3481, 1.2239],
        [1.4467, 1.4466, 1.4450, 1.4422, 1.4427, 1.4467, 1.4424, 1.4467, 1.4467,
         1.4338, 1.4331, 1.4338, 1.4338, 1.4338, 1.4151, 1.4338, 1.4327, 1.4304,
         2.2052, 2.2055, 2.2222, 2.1977, 2.1791, 2.1774, 2.2065, 2.1765, 2.1765,
         1.5084, 1.5067, 1.5142, 1.5142, 1.5084, 1.5142, 1.5141, 1.5142, 1.5142,
         1.7725, 1.7726, 1.7726, 1.7695, 1.7725, 1.7725, 1.7726, 1.7500, 1.7527,
         1.4435, 1.4481, 1.4481, 1.4481, 1.4398, 1.4481, 1.4442, 1.4480, 1.4481],
        [1.3122, 1.3106, 1.2948, 1.2860, 1.3095, 1.3079, 1.3091, 1.3098, 1.3098,
         1.2995, 1.2927, 1.2889, 1.2885, 1.3004, 1.2847, 1.2955, 1.3000, 1.2722,
         1.6477, 1.6215, 1.6447, 1.6441, 1.6435, 1.6435, 1.6458, 1.6472, 1.6472,
         3.4820, 3.2726, 3.1983, 3.2563, 3.4068, 3.2253, 3.4570, 3.2061, 3.1849,
         1.6456, 1.6381, 1.6365, 1.6396, 1.6425, 1.6186, 1.6440, 1.5834, 1.6099,
         1.3117, 1.3061, 1.2963, 1.3109, 1.3067, 1.2989, 1.3111, 1.3111, 1.3132],
        [1.4496, 1.4454, 1.4024, 1.4053, 1.4429, 1.4495, 1.4480, 1.4495, 1.4495,
         1.4355, 1.4329, 1.4279, 1.4232, 1.4367, 1.3963, 1.4308, 1.4366, 1.4319,
         1.7614, 1.7527, 1.7516, 1.7596, 1.7771, 1.7757, 1.7559, 1.7772, 1.7772,
         1.4750, 1.4807, 1.5169, 1.5117, 1.4805, 1.5155, 1.5038, 1.5170, 1.5138,
         2.1978, 2.1779, 2.1665, 2.1843, 2.2280, 2.2460, 2.2123, 2.3154, 2.3125,
         1.4358, 1.4262, 1.4405, 1.4509, 1.4382, 1.4476, 1.4186, 1.4448, 1.4509],
        [1.3637, 1.2745, 1.2698, 1.2886, 1.2817, 1.2920, 1.2907, 1.2329, 1.2329,
         1.2675, 1.2229, 1.2222, 1.2279, 1.3119, 1.1791, 1.1306, 1.3119, 1.2094,
         1.6202, 1.5971, 1.5782, 1.5752, 1.5983, 1.5945, 1.6131, 1.5998, 1.5998,
         1.3655, 1.3390, 1.3407, 1.3553, 1.3414, 1.3817, 1.3845, 1.3598, 1.3407,
         1.5915, 1.5897, 1.5966, 1.5863, 1.5621, 1.5653, 1.6249, 1.5164, 1.4857,
         4.0595, 3.5765, 3.6669, 3.6500, 3.6639, 3.3449, 4.0558, 3.6236, 3.3782]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 318 : 1779.6416719453648
Test loss for epoch 318 : 194.87259653533246
Test Precision for epoch 318 : 0.26153846153846155
Test Recall for epoch 318 : 0.26153846153846155
Test F1 for epoch 318 : 0.26153846153846155


theta for epoch 319 : tensor([[3.6222, 3.6430, 3.7861, 3.7345, 3.7180, 3.6037, 3.6447, 3.5444, 3.5444,
         1.2585, 1.2332, 1.2322, 1.2375, 1.2818, 1.2178, 1.1728, 1.2818, 1.2233,
         1.5976, 1.5817, 1.6062, 1.5879, 1.5936, 1.5952, 1.6031, 1.5952, 1.5952,
         1.3323, 1.3436, 1.3289, 1.3515, 1.3314, 1.3633, 1.3558, 1.3425, 1.3290,
         1.5931, 1.6097, 1.5980, 1.5944, 1.6015, 1.5918, 1.6106, 1.5638, 1.5685,
         1.2513, 1.2778, 1.2703, 1.2868, 1.2461, 1.2384, 1.2270, 1.3104, 1.2673],
        [1.3625, 1.2077, 1.1977, 1.2409, 1.2412, 1.2536, 1.2475, 1.1499, 1.1499,
         3.5953, 3.6843, 3.5243, 3.9297, 3.5952, 4.2909, 3.4573, 3.5495, 4.0431,
         1.5618, 1.5491, 1.5235, 1.5209, 1.5421, 1.5515, 1.5770, 1.5516, 1.5516,
         1.3337, 1.2999, 1.2929, 1.3522, 1.2934, 1.3904, 1.3702, 1.3381, 1.2897,
         1.5313, 1.5887, 1.5513, 1.5380, 1.5331, 1.5716, 1.5917, 1.4236, 1.5222,
         1.1527, 1.2635, 1.2367, 1.2853, 1.1478, 1.1524, 1.0773, 1.3508, 1.2271],
        [1.4469, 1.4469, 1.4453, 1.4425, 1.4429, 1.4469, 1.4426, 1.4469, 1.4469,
         1.4319, 1.4313, 1.4319, 1.4319, 1.4320, 1.4132, 1.4319, 1.4308, 1.4285,
         2.2034, 2.2037, 2.2205, 2.1961, 2.1775, 2.1757, 2.2049, 2.1748, 2.1748,
         1.5050, 1.5034, 1.5108, 1.5108, 1.5050, 1.5108, 1.5108, 1.5108, 1.5108,
         1.7754, 1.7755, 1.7755, 1.7723, 1.7753, 1.7753, 1.7755, 1.7528, 1.7555,
         1.4473, 1.4519, 1.4519, 1.4519, 1.4436, 1.4519, 1.4480, 1.4518, 1.4519],
        [1.3121, 1.3106, 1.2948, 1.2860, 1.3095, 1.3078, 1.3090, 1.3097, 1.3097,
         1.2974, 1.2906, 1.2868, 1.2864, 1.2983, 1.2827, 1.2934, 1.2979, 1.2702,
         1.6456, 1.6195, 1.6427, 1.6421, 1.6415, 1.6415, 1.6437, 1.6452, 1.6452,
         3.4800, 3.2707, 3.1964, 3.2544, 3.4048, 3.2234, 3.4551, 3.2042, 3.1830,
         1.6482, 1.6408, 1.6392, 1.6423, 1.6452, 1.6212, 1.6466, 1.5861, 1.6126,
         1.3153, 1.3097, 1.2999, 1.3145, 1.3103, 1.3025, 1.3148, 1.3147, 1.3168],
        [1.4498, 1.4457, 1.4028, 1.4056, 1.4432, 1.4497, 1.4482, 1.4498, 1.4498,
         1.4336, 1.4311, 1.4260, 1.4213, 1.4348, 1.3945, 1.4289, 1.4348, 1.4300,
         1.7596, 1.7509, 1.7498, 1.7578, 1.7753, 1.7739, 1.7541, 1.7754, 1.7754,
         1.4716, 1.4774, 1.5135, 1.5084, 1.4771, 1.5121, 1.5004, 1.5136, 1.5105,
         2.2005, 2.1806, 2.1693, 2.1870, 2.2307, 2.2487, 2.2150, 2.3181, 2.3152,
         1.4396, 1.4300, 1.4443, 1.4547, 1.4420, 1.4515, 1.4224, 1.4486, 1.4547],
        [1.3610, 1.2726, 1.2678, 1.2866, 1.2797, 1.2899, 1.2887, 1.2315, 1.2315,
         1.2643, 1.2192, 1.2186, 1.2249, 1.3086, 1.1770, 1.1259, 1.3087, 1.2072,
         1.6172, 1.5941, 1.5752, 1.5724, 1.5956, 1.5917, 1.6102, 1.5970, 1.5970,
         1.3610, 1.3346, 1.3366, 1.3508, 1.3371, 1.3770, 1.3799, 1.3554, 1.3366,
         1.5931, 1.5911, 1.5982, 1.5878, 1.5636, 1.5667, 1.6263, 1.5179, 1.4871,
         4.0637, 3.5805, 3.6708, 3.6540, 3.6678, 3.3489, 4.0600, 3.6275, 3.3822]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 319 : 1779.5132102058867
Test loss for epoch 319 : 194.91223737955517
Test Precision for epoch 319 : 0.26153846153846155
Test Recall for epoch 319 : 0.26153846153846155
Test F1 for epoch 319 : 0.26153846153846155


theta for epoch 320 : tensor([[3.6268, 3.6477, 3.7907, 3.7391, 3.7226, 3.6084, 3.6494, 3.5491, 3.5491,
         1.2562, 1.2302, 1.2292, 1.2352, 1.2800, 1.2159, 1.1682, 1.2800, 1.2213,
         1.5918, 1.5759, 1.6005, 1.5821, 1.5877, 1.5894, 1.5973, 1.5893, 1.5893,
         1.3351, 1.3464, 1.3316, 1.3543, 1.3341, 1.3662, 1.3587, 1.3453, 1.3316,
         1.5924, 1.6091, 1.5973, 1.5937, 1.6008, 1.5912, 1.6100, 1.5630, 1.5677,
         1.2543, 1.2811, 1.2737, 1.2901, 1.2490, 1.2416, 1.2300, 1.3136, 1.2707],
        [1.3593, 1.2031, 1.1932, 1.2366, 1.2368, 1.2493, 1.2432, 1.1447, 1.1447,
         3.6005, 3.6897, 3.5296, 3.9354, 3.6005, 4.2972, 3.4627, 3.5547, 4.0489,
         1.5537, 1.5408, 1.5154, 1.5125, 1.5337, 1.5432, 1.5688, 1.5432, 1.5432,
         1.3311, 1.2972, 1.2899, 1.3497, 1.2906, 1.3882, 1.3678, 1.3355, 1.2867,
         1.5266, 1.5844, 1.5467, 1.5333, 1.5285, 1.5672, 1.5874, 1.4187, 1.5175,
         1.1503, 1.2623, 1.2355, 1.2841, 1.1451, 1.1504, 1.0745, 1.3497, 1.2260],
        [1.4503, 1.4503, 1.4487, 1.4459, 1.4463, 1.4503, 1.4460, 1.4503, 1.4503,
         1.4304, 1.4297, 1.4303, 1.4303, 1.4304, 1.4117, 1.4303, 1.4292, 1.4269,
         2.1983, 2.1986, 2.2154, 2.1912, 2.1726, 2.1708, 2.2000, 2.1699, 2.1699,
         1.5079, 1.5063, 1.5137, 1.5137, 1.5079, 1.5137, 1.5137, 1.5137, 1.5137,
         1.7751, 1.7751, 1.7751, 1.7720, 1.7750, 1.7750, 1.7751, 1.7525, 1.7552,
         1.4505, 1.4550, 1.4550, 1.4550, 1.4468, 1.4550, 1.4512, 1.4550, 1.4550],
        [1.3153, 1.3138, 1.2981, 1.2893, 1.3128, 1.3111, 1.3123, 1.3130, 1.3130,
         1.2957, 1.2888, 1.2850, 1.2847, 1.2966, 1.2809, 1.2916, 1.2962, 1.2684,
         1.6400, 1.6138, 1.6370, 1.6365, 1.6358, 1.6358, 1.6381, 1.6395, 1.6395,
         3.4836, 3.2744, 3.2002, 3.2582, 3.4085, 3.2271, 3.4587, 3.2080, 3.1868,
         1.6477, 1.6403, 1.6387, 1.6418, 1.6447, 1.6207, 1.6461, 1.5856, 1.6121,
         1.3183, 1.3127, 1.3029, 1.3174, 1.3133, 1.3056, 1.3177, 1.3176, 1.3198],
        [1.4532, 1.4491, 1.4063, 1.4092, 1.4466, 1.4531, 1.4516, 1.4532, 1.4532,
         1.4320, 1.4295, 1.4245, 1.4197, 1.4332, 1.3929, 1.4273, 1.4332, 1.4285,
         1.7542, 1.7455, 1.7445, 1.7525, 1.7699, 1.7686, 1.7488, 1.7701, 1.7701,
         1.4746, 1.4804, 1.5164, 1.5113, 1.4801, 1.5150, 1.5033, 1.5165, 1.5134,
         2.2002, 2.1803, 2.1689, 2.1867, 2.2303, 2.2483, 2.2147, 2.3177, 2.3148,
         1.4428, 1.4332, 1.4475, 1.4578, 1.4452, 1.4546, 1.4257, 1.4518, 1.4579],
        [1.3562, 1.2690, 1.2641, 1.2828, 1.2759, 1.2861, 1.2849, 1.2286, 1.2286,
         1.2593, 1.2137, 1.2131, 1.2201, 1.3037, 1.1728, 1.1193, 1.3038, 1.2030,
         1.6087, 1.5857, 1.5666, 1.5641, 1.5873, 1.5835, 1.6017, 1.5888, 1.5888,
         1.3588, 1.3323, 1.3348, 1.3484, 1.3350, 1.3744, 1.3775, 1.3532, 1.3348,
         1.5898, 1.5875, 1.5949, 1.5845, 1.5602, 1.5631, 1.6227, 1.5144, 1.4835,
         4.0719, 3.5886, 3.6789, 3.6621, 3.6758, 3.3570, 4.0683, 3.6356, 3.3903]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 320 : 1779.2244530245969
Test loss for epoch 320 : 195.17572454743828
Test Precision for epoch 320 : 0.26153846153846155
Test Recall for epoch 320 : 0.26153846153846155
Test F1 for epoch 320 : 0.26153846153846155


theta for epoch 321 : tensor([[3.6223, 3.6432, 3.7863, 3.7347, 3.7182, 3.6039, 3.6449, 3.5445, 3.5445,
         1.2566, 1.2304, 1.2295, 1.2359, 1.2804, 1.2170, 1.1681, 1.2804, 1.2225,
         1.5939, 1.5780, 1.6026, 1.5842, 1.5898, 1.5914, 1.5994, 1.5914, 1.5914,
         1.3425, 1.3538, 1.3389, 1.3617, 1.3415, 1.3737, 1.3662, 1.3527, 1.3389,
         1.5921, 1.6088, 1.5969, 1.5933, 1.6005, 1.5908, 1.6097, 1.5627, 1.5674,
         1.2519, 1.2790, 1.2715, 1.2879, 1.2466, 1.2394, 1.2277, 1.3113, 1.2686],
        [1.3760, 1.2192, 1.2094, 1.2528, 1.2530, 1.2654, 1.2594, 1.1603, 1.1603,
         3.5841, 3.6733, 3.5131, 3.9193, 3.5840, 4.2817, 3.4463, 3.5382, 4.0329,
         1.5670, 1.5541, 1.5289, 1.5257, 1.5468, 1.5563, 1.5820, 1.5563, 1.5563,
         1.3475, 1.3136, 1.3060, 1.3661, 1.3069, 1.4047, 1.3843, 1.3518, 1.3029,
         1.5374, 1.5950, 1.5573, 1.5441, 1.5393, 1.5779, 1.5981, 1.4301, 1.5283,
         1.1610, 1.2736, 1.2469, 1.2952, 1.1557, 1.1615, 1.0854, 1.3603, 1.2375],
        [1.4519, 1.4519, 1.4503, 1.4475, 1.4479, 1.4519, 1.4476, 1.4519, 1.4519,
         1.4301, 1.4294, 1.4301, 1.4301, 1.4301, 1.4114, 1.4301, 1.4290, 1.4267,
         2.1991, 2.1995, 2.2162, 2.1919, 2.1734, 2.1716, 2.2008, 2.1707, 2.1707,
         1.5135, 1.5118, 1.5193, 1.5193, 1.5135, 1.5193, 1.5192, 1.5193, 1.5193,
         1.7738, 1.7739, 1.7739, 1.7708, 1.7738, 1.7738, 1.7739, 1.7513, 1.7540,
         1.4465, 1.4511, 1.4511, 1.4511, 1.4428, 1.4511, 1.4472, 1.4510, 1.4511],
        [1.3169, 1.3154, 1.2997, 1.2909, 1.3143, 1.3127, 1.3138, 1.3146, 1.3146,
         1.2953, 1.2884, 1.2846, 1.2843, 1.2962, 1.2806, 1.2913, 1.2958, 1.2681,
         1.6407, 1.6146, 1.6377, 1.6372, 1.6365, 1.6366, 1.6388, 1.6402, 1.6402,
         3.4893, 3.2803, 3.2061, 3.2640, 3.4143, 3.2330, 3.4645, 3.2139, 3.1927,
         1.6463, 1.6389, 1.6373, 1.6404, 1.6433, 1.6193, 1.6447, 1.5843, 1.6107,
         1.3142, 1.3085, 1.2987, 1.3133, 1.3091, 1.3014, 1.3136, 1.3135, 1.3157],
        [1.4547, 1.4507, 1.4079, 1.4108, 1.4482, 1.4547, 1.4532, 1.4548, 1.4548,
         1.4318, 1.4292, 1.4242, 1.4195, 1.4330, 1.3928, 1.4271, 1.4330, 1.4283,
         1.7551, 1.7464, 1.7453, 1.7533, 1.7708, 1.7694, 1.7497, 1.7709, 1.7709,
         1.4802, 1.4860, 1.5220, 1.5168, 1.4857, 1.5206, 1.5089, 1.5221, 1.5189,
         2.1989, 2.1791, 2.1677, 2.1854, 2.2291, 2.2471, 2.2134, 2.3164, 2.3136,
         1.4389, 1.4292, 1.4435, 1.4539, 1.4413, 1.4507, 1.4217, 1.4478, 1.4539],
        [1.3504, 1.2649, 1.2598, 1.2784, 1.2714, 1.2817, 1.2805, 1.2256, 1.2256,
         1.2561, 1.2107, 1.2102, 1.2175, 1.2999, 1.1710, 1.1170, 1.3000, 1.2013,
         1.6063, 1.5834, 1.5642, 1.5621, 1.5853, 1.5815, 1.5993, 1.5868, 1.5868,
         1.3592, 1.3328, 1.3358, 1.3488, 1.3356, 1.3745, 1.3777, 1.3537, 1.3359,
         1.5862, 1.5836, 1.5913, 1.5809, 1.5564, 1.5593, 1.6187, 1.5107, 1.4797,
         4.0764, 3.5929, 3.6832, 3.6664, 3.6801, 3.3614, 4.0728, 3.6399, 3.3947]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 321 : 1779.9404786203154
Test loss for epoch 321 : 194.4048434297238
Test Precision for epoch 321 : 0.26153846153846155
Test Recall for epoch 321 : 0.26153846153846155
Test F1 for epoch 321 : 0.26153846153846155


theta for epoch 322 : tensor([[3.6184, 3.6393, 3.7825, 3.7308, 3.7143, 3.5999, 3.6409, 3.5404, 3.5404,
         1.2630, 1.2365, 1.2356, 1.2424, 1.2868, 1.2238, 1.1737, 1.2868, 1.2293,
         1.5999, 1.5840, 1.6086, 1.5901, 1.5957, 1.5974, 1.6054, 1.5973, 1.5973,
         1.3393, 1.3505, 1.3355, 1.3585, 1.3382, 1.3705, 1.3629, 1.3494, 1.3355,
         1.5919, 1.6087, 1.5968, 1.5932, 1.6004, 1.5908, 1.6097, 1.5626, 1.5673,
         1.2452, 1.2726, 1.2651, 1.2816, 1.2398, 1.2328, 1.2211, 1.3049, 1.2621],
        [1.3842, 1.2267, 1.2171, 1.2604, 1.2607, 1.2730, 1.2670, 1.1674, 1.1674,
         3.5766, 3.6660, 3.5057, 3.9122, 3.5765, 4.2753, 3.4389, 3.5307, 4.0259,
         1.5776, 1.5647, 1.5395, 1.5362, 1.5573, 1.5667, 1.5926, 1.5668, 1.5668,
         1.3525, 1.3186, 1.3108, 1.3711, 1.3119, 1.4097, 1.3893, 1.3568, 1.3077,
         1.5434, 1.6010, 1.5632, 1.5500, 1.5453, 1.5839, 1.6041, 1.4364, 1.5343,
         1.1634, 1.2765, 1.2500, 1.2981, 1.1579, 1.1642, 1.0880, 1.3628, 1.2406],
        [1.4502, 1.4502, 1.4486, 1.4458, 1.4462, 1.4502, 1.4459, 1.4502, 1.4502,
         1.4362, 1.4355, 1.4362, 1.4362, 1.4362, 1.4176, 1.4362, 1.4351, 1.4328,
         2.2040, 2.2043, 2.2211, 2.1966, 2.1780, 2.1763, 2.2054, 2.1754, 2.1754,
         1.5091, 1.5074, 1.5148, 1.5148, 1.5091, 1.5148, 1.5148, 1.5148, 1.5148,
         1.7732, 1.7733, 1.7733, 1.7702, 1.7732, 1.7732, 1.7733, 1.7507, 1.7534,
         1.4389, 1.4435, 1.4435, 1.4435, 1.4353, 1.4435, 1.4397, 1.4435, 1.4435],
        [1.3153, 1.3138, 1.2980, 1.2893, 1.3127, 1.3111, 1.3122, 1.3130, 1.3130,
         1.3012, 1.2944, 1.2906, 1.2903, 1.3021, 1.2866, 1.2973, 1.3017, 1.2741,
         1.6458, 1.6197, 1.6428, 1.6423, 1.6416, 1.6417, 1.6439, 1.6453, 1.6453,
         3.4860, 3.2770, 3.2028, 3.2607, 3.4109, 3.2297, 3.4611, 3.2106, 3.1894,
         1.6457, 1.6382, 1.6366, 1.6397, 1.6426, 1.6186, 1.6441, 1.5836, 1.6100,
         1.3065, 1.3009, 1.2911, 1.3056, 1.3015, 1.2938, 1.3060, 1.3058, 1.3080],
        [1.4530, 1.4490, 1.4062, 1.4091, 1.4465, 1.4529, 1.4515, 1.4530, 1.4530,
         1.4379, 1.4353, 1.4303, 1.4256, 1.4390, 1.3989, 1.4332, 1.4390, 1.4344,
         1.7602, 1.7515, 1.7505, 1.7585, 1.7759, 1.7745, 1.7548, 1.7760, 1.7760,
         1.4758, 1.4816, 1.5176, 1.5124, 1.4812, 1.5162, 1.5044, 1.5176, 1.5145,
         2.1983, 2.1785, 2.1671, 2.1848, 2.2285, 2.2465, 2.2128, 2.3157, 2.3129,
         1.4313, 1.4217, 1.4360, 1.4463, 1.4337, 1.4431, 1.4142, 1.4402, 1.4464],
        [1.3395, 1.2554, 1.2501, 1.2686, 1.2616, 1.2719, 1.2707, 1.2169, 1.2169,
         1.2573, 1.2119, 1.2115, 1.2191, 1.3007, 1.1731, 1.1183, 1.3008, 1.2034,
         1.6059, 1.5830, 1.5636, 1.5619, 1.5853, 1.5814, 1.5990, 1.5867, 1.5867,
         1.3492, 1.3228, 1.3263, 1.3386, 1.3258, 1.3640, 1.3675, 1.3438, 1.3263,
         1.5816, 1.5787, 1.5868, 1.5763, 1.5517, 1.5544, 1.6138, 1.5059, 1.4747,
         4.0832, 3.5994, 3.6897, 3.6729, 3.6866, 3.3680, 4.0796, 3.6464, 3.4012]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 322 : 1779.9805516145318
Test loss for epoch 322 : 194.31809383032848
Test Precision for epoch 322 : 0.26153846153846155
Test Recall for epoch 322 : 0.26153846153846155
Test F1 for epoch 322 : 0.26153846153846155


theta for epoch 323 : tensor([[3.6175, 3.6383, 3.7816, 3.7300, 3.7134, 3.5990, 3.6400, 3.5395, 3.5395,
         1.2710, 1.2443, 1.2434, 1.2505, 1.2949, 1.2321, 1.1809, 1.2949, 1.2375,
         1.6000, 1.5840, 1.6087, 1.5901, 1.5957, 1.5974, 1.6055, 1.5973, 1.5973,
         1.3337, 1.3449, 1.3297, 1.3529, 1.3325, 1.3650, 1.3574, 1.3438, 1.3297,
         1.5916, 1.6085, 1.5965, 1.5929, 1.6001, 1.5905, 1.6094, 1.5623, 1.5669,
         1.2399, 1.2677, 1.2601, 1.2767, 1.2345, 1.2275, 1.2157, 1.3001, 1.2571],
        [1.3865, 1.2283, 1.2187, 1.2621, 1.2624, 1.2747, 1.2687, 1.1687, 1.1687,
         3.5765, 3.6659, 3.5055, 3.9123, 3.5763, 4.2761, 3.4388, 3.5305, 4.0262,
         1.5792, 1.5663, 1.5412, 1.5377, 1.5588, 1.5682, 1.5942, 1.5683, 1.5683,
         1.3511, 1.3172, 1.3093, 1.3696, 1.3105, 1.4083, 1.3879, 1.3553, 1.3061,
         1.5445, 1.6022, 1.5643, 1.5511, 1.5465, 1.5851, 1.6054, 1.4376, 1.5354,
         1.1613, 1.2752, 1.2487, 1.2967, 1.1556, 1.1623, 1.0859, 1.3612, 1.2393],
        [1.4502, 1.4501, 1.4485, 1.4457, 1.4461, 1.4502, 1.4459, 1.4502, 1.4502,
         1.4442, 1.4435, 1.4442, 1.4441, 1.4442, 1.4256, 1.4442, 1.4431, 1.4408,
         2.2038, 2.2041, 2.2209, 2.1964, 2.1779, 2.1761, 2.2052, 2.1752, 2.1752,
         1.5029, 1.5013, 1.5087, 1.5087, 1.5030, 1.5087, 1.5087, 1.5087, 1.5087,
         1.7728, 1.7729, 1.7729, 1.7697, 1.7727, 1.7727, 1.7729, 1.7502, 1.7530,
         1.4335, 1.4380, 1.4380, 1.4380, 1.4298, 1.4380, 1.4342, 1.4380, 1.4380],
        [1.3155, 1.3140, 1.2982, 1.2895, 1.3129, 1.3113, 1.3124, 1.3131, 1.3131,
         1.3092, 1.3023, 1.2985, 1.2982, 1.3100, 1.2946, 1.3052, 1.3096, 1.2821,
         1.6455, 1.6194, 1.6426, 1.6420, 1.6413, 1.6414, 1.6436, 1.6451, 1.6451,
         3.4809, 3.2720, 3.1977, 3.2557, 3.4059, 3.2247, 3.4561, 3.2056, 3.1844,
         1.6451, 1.6377, 1.6361, 1.6392, 1.6421, 1.6181, 1.6435, 1.5831, 1.6095,
         1.3010, 1.2953, 1.2855, 1.3001, 1.2959, 1.2882, 1.3004, 1.3002, 1.3025],
        [1.4530, 1.4489, 1.4062, 1.4091, 1.4465, 1.4529, 1.4514, 1.4530, 1.4530,
         1.4459, 1.4433, 1.4383, 1.4336, 1.4470, 1.4070, 1.4412, 1.4470, 1.4424,
         1.7600, 1.7513, 1.7503, 1.7582, 1.7757, 1.7743, 1.7546, 1.7758, 1.7758,
         1.4696, 1.4755, 1.5115, 1.5063, 1.4751, 1.5100, 1.4983, 1.5115, 1.5084,
         2.1978, 2.1781, 2.1667, 2.1844, 2.2280, 2.2461, 2.2124, 2.3152, 2.3125,
         1.4259, 1.4162, 1.4305, 1.4408, 1.4283, 1.4376, 1.4087, 1.4348, 1.4409],
        [1.3279, 1.2445, 1.2391, 1.2576, 1.2506, 1.2609, 1.2597, 1.2065, 1.2065,
         1.2591, 1.2136, 1.2132, 1.2211, 1.3024, 1.1753, 1.1197, 1.3025, 1.2057,
         1.5993, 1.5764, 1.5569, 1.5554, 1.5788, 1.5749, 1.5924, 1.5803, 1.5803,
         1.3360, 1.3096, 1.3134, 1.3254, 1.3127, 1.3507, 1.3542, 1.3306, 1.3135,
         1.5758, 1.5727, 1.5809, 1.5705, 1.5457, 1.5483, 1.6078, 1.4998, 1.4684,
         4.0935, 3.6095, 3.6998, 3.6830, 3.6967, 3.3781, 4.0899, 3.6565, 3.4114]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 323 : 1780.0064699717132
Test loss for epoch 323 : 194.6835084620769
Test Precision for epoch 323 : 0.26153846153846155
Test Recall for epoch 323 : 0.26153846153846155
Test F1 for epoch 323 : 0.26153846153846155


theta for epoch 324 : tensor([[3.6211, 3.6421, 3.7854, 3.7337, 3.7171, 3.6027, 3.6437, 3.5433, 3.5433,
         1.2716, 1.2447, 1.2437, 1.2512, 1.2955, 1.2327, 1.1808, 1.2956, 1.2382,
         1.5949, 1.5789, 1.6036, 1.5849, 1.5905, 1.5922, 1.6003, 1.5921, 1.5921,
         1.3367, 1.3479, 1.3326, 1.3559, 1.3355, 1.3682, 1.3605, 1.3468, 1.3326,
         1.5914, 1.6083, 1.5963, 1.5927, 1.5999, 1.5903, 1.6093, 1.5620, 1.5667,
         1.2380, 1.2662, 1.2584, 1.2753, 1.2324, 1.2254, 1.2137, 1.2988, 1.2554],
        [1.3844, 1.2257, 1.2162, 1.2596, 1.2599, 1.2723, 1.2662, 1.1659, 1.1659,
         3.5805, 3.6700, 3.5095, 3.9167, 3.5804, 4.2812, 3.4428, 3.5345, 4.0308,
         1.5729, 1.5599, 1.5348, 1.5313, 1.5524, 1.5618, 1.5878, 1.5619, 1.5619,
         1.3497, 1.3157, 1.3078, 1.3683, 1.3090, 1.4071, 1.3866, 1.3539, 1.3047,
         1.5415, 1.5994, 1.5614, 1.5482, 1.5435, 1.5822, 1.6026, 1.4345, 1.5324,
         1.1565, 1.2713, 1.2448, 1.2929, 1.1506, 1.1577, 1.0809, 1.3573, 1.2353],
        [1.4543, 1.4542, 1.4527, 1.4499, 1.4502, 1.4543, 1.4500, 1.4543, 1.4543,
         1.4450, 1.4443, 1.4450, 1.4449, 1.4450, 1.4264, 1.4450, 1.4439, 1.4416,
         2.1992, 2.1995, 2.2163, 2.1920, 2.1734, 2.1717, 2.2008, 2.1708, 2.1708,
         1.5061, 1.5045, 1.5119, 1.5119, 1.5061, 1.5119, 1.5118, 1.5119, 1.5119,
         1.7728, 1.7729, 1.7729, 1.7697, 1.7728, 1.7728, 1.7729, 1.7503, 1.7530,
         1.4321, 1.4367, 1.4367, 1.4367, 1.4285, 1.4367, 1.4329, 1.4367, 1.4367],
        [1.3200, 1.3185, 1.3027, 1.2939, 1.3174, 1.3157, 1.3169, 1.3176, 1.3176,
         1.3099, 1.3031, 1.2993, 1.2990, 1.3108, 1.2953, 1.3060, 1.3104, 1.2828,
         1.6406, 1.6144, 1.6376, 1.6370, 1.6364, 1.6364, 1.6387, 1.6401, 1.6401,
         3.4841, 3.2752, 3.2010, 3.2590, 3.4091, 3.2280, 3.4593, 3.2088, 3.1877,
         1.6451, 1.6376, 1.6361, 1.6391, 1.6421, 1.6181, 1.6435, 1.5830, 1.6094,
         1.2996, 1.2940, 1.2841, 1.2987, 1.2945, 1.2869, 1.2990, 1.2989, 1.3011],
        [1.4571, 1.4530, 1.4103, 1.4132, 1.4506, 1.4570, 1.4555, 1.4571, 1.4571,
         1.4467, 1.4441, 1.4391, 1.4345, 1.4478, 1.4078, 1.4420, 1.4478, 1.4432,
         1.7552, 1.7465, 1.7454, 1.7534, 1.7708, 1.7695, 1.7497, 1.7710, 1.7710,
         1.4728, 1.4787, 1.5146, 1.5094, 1.4783, 1.5132, 1.5015, 1.5147, 1.5115,
         2.1978, 2.1781, 2.1667, 2.1844, 2.2280, 2.2461, 2.2124, 2.3152, 2.3124,
         1.4246, 1.4149, 1.4291, 1.4395, 1.4269, 1.4363, 1.4074, 1.4334, 1.4396],
        [1.3184, 1.2347, 1.2292, 1.2478, 1.2408, 1.2511, 1.2499, 1.1966, 1.1966,
         1.2536, 1.2077, 1.2073, 1.2155, 1.2969, 1.1697, 1.1133, 1.2969, 1.2002,
         1.5874, 1.5645, 1.5449, 1.5434, 1.5670, 1.5630, 1.5805, 1.5684, 1.5684,
         1.3293, 1.3028, 1.3067, 1.3186, 1.3059, 1.3439, 1.3475, 1.3239, 1.3067,
         1.5693, 1.5660, 1.5744, 1.5639, 1.5390, 1.5416, 1.6013, 1.4929, 1.4614,
         4.1077, 3.6234, 3.7138, 3.6970, 3.7106, 3.3921, 4.1041, 3.6704, 3.4254]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 324 : 1779.648188742774
Test loss for epoch 324 : 195.16864411168123
Test Precision for epoch 324 : 0.26153846153846155
Test Recall for epoch 324 : 0.26153846153846155
Test F1 for epoch 324 : 0.26153846153846155


theta for epoch 325 : tensor([[3.6269, 3.6480, 3.7913, 3.7396, 3.7230, 3.6086, 3.6496, 3.5492, 3.5492,
         1.2639, 1.2369, 1.2359, 1.2435, 1.2879, 1.2250, 1.1728, 1.2879, 1.2304,
         1.5942, 1.5782, 1.6030, 1.5841, 1.5898, 1.5914, 1.5996, 1.5914, 1.5914,
         1.3447, 1.3559, 1.3405, 1.3640, 1.3434, 1.3763, 1.3686, 1.3548, 1.3405,
         1.5924, 1.6094, 1.5973, 1.5937, 1.6010, 1.5913, 1.6104, 1.5631, 1.5677,
         1.2368, 1.2655, 1.2576, 1.2748, 1.2311, 1.2240, 1.2124, 1.2984, 1.2544],
        [1.3764, 1.2176, 1.2080, 1.2515, 1.2518, 1.2642, 1.2582, 1.1578, 1.1578,
         3.5879, 3.6775, 3.5169, 3.9245, 3.5878, 4.2897, 3.4503, 3.5419, 4.0388,
         1.5656, 1.5526, 1.5274, 1.5240, 1.5452, 1.5546, 1.5806, 1.5547, 1.5547,
         1.3470, 1.3129, 1.3050, 1.3657, 1.3062, 1.4046, 1.3841, 1.3513, 1.3019,
         1.5359, 1.5939, 1.5559, 1.5426, 1.5379, 1.5767, 1.5971, 1.4284, 1.5267,
         1.1477, 1.2637, 1.2370, 1.2853, 1.1416, 1.1490, 1.0720, 1.3498, 1.2275],
        [1.4575, 1.4574, 1.4559, 1.4531, 1.4534, 1.4575, 1.4532, 1.4575, 1.4575,
         1.4378, 1.4371, 1.4377, 1.4377, 1.4378, 1.4191, 1.4377, 1.4366, 1.4344,
         2.1992, 2.1995, 2.2163, 2.1920, 2.1734, 2.1717, 2.2008, 2.1708, 2.1708,
         1.5150, 1.5134, 1.5208, 1.5208, 1.5150, 1.5208, 1.5207, 1.5208, 1.5208,
         1.7744, 1.7745, 1.7745, 1.7714, 1.7744, 1.7744, 1.7745, 1.7519, 1.7546,
         1.4324, 1.4370, 1.4370, 1.4370, 1.4288, 1.4370, 1.4332, 1.4370, 1.4370],
        [1.3236, 1.3220, 1.3062, 1.2974, 1.3209, 1.3193, 1.3204, 1.3211, 1.3211,
         1.3026, 1.2958, 1.2920, 1.2917, 1.3034, 1.2880, 1.2987, 1.3030, 1.2755,
         1.6405, 1.6144, 1.6376, 1.6370, 1.6364, 1.6364, 1.6386, 1.6401, 1.6401,
         3.4924, 3.2837, 3.2096, 3.2675, 3.4175, 3.2365, 3.4677, 3.2174, 3.1962,
         1.6467, 1.6392, 1.6376, 1.6407, 1.6436, 1.6197, 1.6451, 1.5846, 1.6110,
         1.2998, 1.2942, 1.2844, 1.2990, 1.2948, 1.2871, 1.2993, 1.2991, 1.3013],
        [1.4603, 1.4562, 1.4134, 1.4164, 1.4538, 1.4602, 1.4587, 1.4603, 1.4603,
         1.4395, 1.4369, 1.4319, 1.4272, 1.4406, 1.4006, 1.4348, 1.4406, 1.4360,
         1.7552, 1.7465, 1.7454, 1.7534, 1.7708, 1.7695, 1.7497, 1.7709, 1.7709,
         1.4818, 1.4876, 1.5235, 1.5183, 1.4872, 1.5221, 1.5104, 1.5236, 1.5205,
         2.1994, 2.1797, 2.1683, 2.1859, 2.2295, 2.2476, 2.2140, 2.3167, 2.3139,
         1.4249, 1.4152, 1.4294, 1.4398, 1.4272, 1.4366, 1.4077, 1.4337, 1.4398],
        [1.3084, 1.2233, 1.2179, 1.2367, 1.2296, 1.2400, 1.2388, 1.1845, 1.1845,
         1.2402, 1.1939, 1.1934, 1.2019, 1.2838, 1.1559, 1.0986, 1.2838, 1.1864,
         1.5792, 1.5561, 1.5365, 1.5348, 1.5585, 1.5546, 1.5723, 1.5600, 1.5600,
         1.3267, 1.2999, 1.3037, 1.3159, 1.3030, 1.3416, 1.3451, 1.3212, 1.3037,
         1.5634, 1.5602, 1.5686, 1.5580, 1.5330, 1.5357, 1.5957, 1.4866, 1.4550,
         4.1242, 3.6397, 3.7300, 3.7132, 3.7269, 3.4084, 4.1207, 3.6866, 3.4416]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 325 : 1779.058626659663
Test loss for epoch 325 : 195.69171878559143
Test Precision for epoch 325 : 0.26153846153846155
Test Recall for epoch 325 : 0.26153846153846155
Test F1 for epoch 325 : 0.26153846153846155


theta for epoch 326 : tensor([[3.6333, 3.6545, 3.7977, 3.7461, 3.7294, 3.6150, 3.6560, 3.5558, 3.5558,
         1.2567, 1.2296, 1.2286, 1.2363, 1.2805, 1.2177, 1.1656, 1.2805, 1.2232,
         1.6004, 1.5844, 1.6092, 1.5904, 1.5960, 1.5977, 1.6058, 1.5976, 1.5976,
         1.3454, 1.3566, 1.3412, 1.3646, 1.3441, 1.3769, 1.3692, 1.3554, 1.3412,
         1.5950, 1.6120, 1.5999, 1.5963, 1.6036, 1.5940, 1.6130, 1.5657, 1.5703,
         1.2330, 1.2621, 1.2539, 1.2715, 1.2272, 1.2199, 1.2097, 1.2954, 1.2507],
        [1.3637, 1.2055, 1.1957, 1.2393, 1.2396, 1.2520, 1.2459, 1.1459, 1.1459,
         3.5996, 3.6894, 3.5286, 3.9366, 3.5994, 4.3025, 3.4621, 3.5535, 4.0510,
         1.5602, 1.5472, 1.5217, 1.5185, 1.5398, 1.5493, 1.5752, 1.5494, 1.5494,
         1.3372, 1.3030, 1.2954, 1.3560, 1.2964, 1.3948, 1.3743, 1.3416, 1.2923,
         1.5288, 1.5870, 1.5489, 1.5355, 1.5307, 1.5697, 1.5901, 1.4207, 1.5195,
         1.1338, 1.2508, 1.2239, 1.2726, 1.1275, 1.1352, 1.0601, 1.3372, 1.2144],
        [1.4592, 1.4592, 1.4576, 1.4548, 1.4552, 1.4592, 1.4549, 1.4592, 1.4592,
         1.4311, 1.4304, 1.4310, 1.4310, 1.4311, 1.4124, 1.4310, 1.4299, 1.4277,
         2.2058, 2.2061, 2.2228, 2.1983, 2.1798, 2.1781, 2.2072, 2.1772, 2.1772,
         1.5169, 1.5153, 1.5227, 1.5227, 1.5170, 1.5227, 1.5227, 1.5227, 1.5227,
         1.7777, 1.7778, 1.7778, 1.7747, 1.7777, 1.7777, 1.7778, 1.7552, 1.7580,
         1.4305, 1.4351, 1.4351, 1.4351, 1.4269, 1.4351, 1.4313, 1.4351, 1.4351],
        [1.3256, 1.3240, 1.3082, 1.2994, 1.3229, 1.3212, 1.3224, 1.3230, 1.3230,
         1.2958, 1.2890, 1.2852, 1.2849, 1.2966, 1.2813, 1.2919, 1.2963, 1.2688,
         1.6475, 1.6214, 1.6446, 1.6440, 1.6434, 1.6434, 1.6456, 1.6471, 1.6471,
         3.4949, 3.2862, 3.2121, 3.2700, 3.4199, 3.2390, 3.4701, 3.2199, 3.1988,
         1.6499, 1.6425, 1.6409, 1.6440, 1.6469, 1.6229, 1.6483, 1.5879, 1.6143,
         1.2978, 1.2922, 1.2824, 1.2970, 1.2928, 1.2851, 1.2973, 1.2971, 1.2993],
        [1.4620, 1.4580, 1.4151, 1.4181, 1.4555, 1.4619, 1.4605, 1.4621, 1.4621,
         1.4328, 1.4302, 1.4252, 1.4206, 1.4339, 1.3939, 1.4281, 1.4339, 1.4293,
         1.7621, 1.7534, 1.7524, 1.7604, 1.7777, 1.7764, 1.7567, 1.7779, 1.7779,
         1.4837, 1.4896, 1.5255, 1.5203, 1.4892, 1.5240, 1.5123, 1.5255, 1.5224,
         2.2026, 2.1829, 2.1715, 2.1892, 2.2327, 2.2508, 2.2172, 2.3198, 2.3170,
         1.4230, 1.4133, 1.4276, 1.4379, 1.4254, 1.4347, 1.4059, 1.4318, 1.4379],
        [1.3041, 1.2168, 1.2116, 1.2306, 1.2235, 1.2339, 1.2327, 1.1768, 1.1768,
         1.2302, 1.1832, 1.1827, 1.1914, 1.2741, 1.1451, 1.0867, 1.2741, 1.1756,
         1.5806, 1.5573, 1.5377, 1.5356, 1.5595, 1.5555, 1.5736, 1.5609, 1.5609,
         1.3227, 1.2957, 1.2990, 1.3120, 1.2986, 1.3381, 1.3414, 1.3171, 1.2990,
         1.5618, 1.5589, 1.5670, 1.5564, 1.5314, 1.5342, 1.5945, 1.4847, 1.4530,
         4.1340, 3.6493, 3.7396, 3.7228, 3.7365, 3.4181, 4.1305, 3.6962, 3.4512]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 326 : 1778.4054930041095
Test loss for epoch 326 : 196.10368962490614
Test Precision for epoch 326 : 0.26153846153846155
Test Recall for epoch 326 : 0.26153846153846155
Test F1 for epoch 326 : 0.26153846153846155


theta for epoch 327 : tensor([[3.6320, 3.6531, 3.7964, 3.7448, 3.7281, 3.6137, 3.6547, 3.5544, 3.5544,
         1.2551, 1.2285, 1.2275, 1.2350, 1.2784, 1.2165, 1.1658, 1.2784, 1.2220,
         1.6075, 1.5915, 1.6163, 1.5976, 1.6032, 1.6048, 1.6129, 1.6048, 1.6048,
         1.3417, 1.3530, 1.3377, 1.3610, 1.3406, 1.3731, 1.3655, 1.3518, 1.3378,
         1.5983, 1.6151, 1.6031, 1.5995, 1.6068, 1.5971, 1.6161, 1.5689, 1.5736,
         1.2315, 1.2602, 1.2522, 1.2696, 1.2258, 1.2185, 1.2095, 1.2930, 1.2490],
        [1.3582, 1.2013, 1.1913, 1.2349, 1.2352, 1.2476, 1.2415, 1.1425, 1.1425,
         3.6044, 3.6943, 3.5334, 3.9418, 3.6043, 4.3084, 3.4669, 3.5584, 4.0564,
         1.5607, 1.5477, 1.5220, 1.5192, 1.5406, 1.5501, 1.5759, 1.5502, 1.5502,
         1.3306, 1.2964, 1.2892, 1.3493, 1.2900, 1.3879, 1.3675, 1.3350, 1.2861,
         1.5273, 1.5854, 1.5475, 1.5341, 1.5292, 1.5682, 1.5885, 1.4189, 1.5180,
         1.1279, 1.2444, 1.2179, 1.2658, 1.1217, 1.1300, 1.0567, 1.3294, 1.2085],
        [1.4597, 1.4597, 1.4581, 1.4553, 1.4557, 1.4597, 1.4555, 1.4598, 1.4598,
         1.4288, 1.4282, 1.4288, 1.4288, 1.4288, 1.4102, 1.4288, 1.4277, 1.4254,
         2.2119, 2.2122, 2.2289, 2.2042, 2.1857, 2.1840, 2.2130, 2.1831, 2.1831,
         1.5128, 1.5111, 1.5185, 1.5185, 1.5128, 1.5185, 1.5185, 1.5185, 1.5185,
         1.7804, 1.7805, 1.7805, 1.7773, 1.7803, 1.7803, 1.7805, 1.7579, 1.7607,
         1.4287, 1.4332, 1.4332, 1.4332, 1.4251, 1.4332, 1.4294, 1.4332, 1.4332],
        [1.3264, 1.3247, 1.3089, 1.3002, 1.3236, 1.3220, 1.3231, 1.3238, 1.3238,
         1.2935, 1.2867, 1.2829, 1.2826, 1.2943, 1.2790, 1.2897, 1.2939, 1.2665,
         1.6540, 1.6279, 1.6510, 1.6505, 1.6498, 1.6499, 1.6521, 1.6536, 1.6536,
         3.4920, 3.2834, 3.2092, 3.2671, 3.4171, 3.2361, 3.4673, 3.2170, 3.1959,
         1.6526, 1.6451, 1.6435, 1.6466, 1.6495, 1.6255, 1.6510, 1.5905, 1.6169,
         1.2959, 1.2903, 1.2805, 1.2951, 1.2909, 1.2832, 1.2955, 1.2952, 1.2974],
        [1.4625, 1.4585, 1.4156, 1.4186, 1.4560, 1.4625, 1.4610, 1.4626, 1.4626,
         1.4305, 1.4280, 1.4230, 1.4184, 1.4317, 1.3918, 1.4258, 1.4317, 1.4270,
         1.7685, 1.7599, 1.7589, 1.7668, 1.7841, 1.7828, 1.7631, 1.7843, 1.7843,
         1.4796, 1.4855, 1.5213, 1.5161, 1.4851, 1.5199, 1.5082, 1.5213, 1.5182,
         2.2051, 2.1855, 2.1742, 2.1918, 2.2353, 2.2534, 2.2198, 2.3222, 2.3195,
         1.4212, 1.4115, 1.4257, 1.4360, 1.4236, 1.4329, 1.4041, 1.4300, 1.4361],
        [1.3255, 1.2367, 1.2317, 1.2507, 1.2437, 1.2541, 1.2529, 1.1957, 1.1957,
         1.2375, 1.1910, 1.1904, 1.1990, 1.2808, 1.1528, 1.0955, 1.2808, 1.1831,
         1.5977, 1.5744, 1.5550, 1.5525, 1.5762, 1.5722, 1.5906, 1.5777, 1.5777,
         1.3339, 1.3071, 1.3096, 1.3234, 1.3097, 1.3499, 1.3529, 1.3283, 1.3096,
         1.5736, 1.5711, 1.5788, 1.5683, 1.5435, 1.5464, 1.6067, 1.4970, 1.4656,
         4.1135, 3.6284, 3.7187, 3.7019, 3.7156, 3.3972, 4.1099, 3.6754, 3.4303]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 327 : 1778.7332780179534
Test loss for epoch 327 : 195.5883945548669
Test Precision for epoch 327 : 0.26153846153846155
Test Recall for epoch 327 : 0.26153846153846155
Test F1 for epoch 327 : 0.26153846153846155


theta for epoch 328 : tensor([[3.6241, 3.6452, 3.7886, 3.7369, 3.7202, 3.6057, 3.6468, 3.5463, 3.5463,
         1.2585, 1.2329, 1.2319, 1.2390, 1.2808, 1.2208, 1.1725, 1.2809, 1.2264,
         1.6028, 1.5869, 1.6115, 1.5931, 1.5986, 1.6003, 1.6083, 1.6003, 1.6003,
         1.3400, 1.3513, 1.3363, 1.3592, 1.3390, 1.3711, 1.3636, 1.3502, 1.3364,
         1.5979, 1.6146, 1.6028, 1.5991, 1.6063, 1.5967, 1.6155, 1.5685, 1.5732,
         1.2409, 1.2692, 1.2612, 1.2785, 1.2352, 1.2280, 1.2200, 1.3014, 1.2580],
        [1.3608, 1.2059, 1.1958, 1.2392, 1.2395, 1.2519, 1.2458, 1.1482, 1.1482,
         3.5992, 3.6891, 3.5281, 3.9369, 3.5990, 4.3041, 3.4616, 3.5531, 4.0516,
         1.5616, 1.5487, 1.5230, 1.5205, 1.5419, 1.5514, 1.5767, 1.5514, 1.5514,
         1.3338, 1.2997, 1.2930, 1.3524, 1.2935, 1.3906, 1.3704, 1.3383, 1.2899,
         1.5311, 1.5888, 1.5513, 1.5378, 1.5329, 1.5717, 1.5917, 1.4229, 1.5218,
         1.1376, 1.2537, 1.2275, 1.2750, 1.1315, 1.1403, 1.0686, 1.3375, 1.2182],
        [1.4539, 1.4538, 1.4522, 1.4494, 1.4498, 1.4539, 1.4496, 1.4539, 1.4539,
         1.4311, 1.4305, 1.4311, 1.4311, 1.4311, 1.4125, 1.4311, 1.4300, 1.4277,
         2.2066, 2.2068, 2.2236, 2.1990, 2.1806, 2.1789, 2.2079, 2.1780, 2.1780,
         1.5098, 1.5081, 1.5155, 1.5155, 1.5098, 1.5155, 1.5155, 1.5155, 1.5155,
         1.7789, 1.7790, 1.7790, 1.7759, 1.7789, 1.7789, 1.7790, 1.7565, 1.7592,
         1.4370, 1.4415, 1.4415, 1.4415, 1.4333, 1.4415, 1.4377, 1.4414, 1.4415],
        [1.3206, 1.3189, 1.3031, 1.2943, 1.3179, 1.3162, 1.3174, 1.3180, 1.3180,
         1.2957, 1.2890, 1.2852, 1.2849, 1.2965, 1.2813, 1.2921, 1.2961, 1.2688,
         1.6482, 1.6221, 1.6452, 1.6447, 1.6441, 1.6441, 1.6463, 1.6478, 1.6478,
         3.4903, 3.2817, 3.2076, 3.2654, 3.4154, 3.2345, 3.4656, 3.2153, 3.1942,
         1.6511, 1.6436, 1.6420, 1.6451, 1.6480, 1.6240, 1.6494, 1.5890, 1.6154,
         1.3042, 1.2985, 1.2887, 1.3033, 1.2991, 1.2914, 1.3038, 1.3034, 1.3056],
        [1.4567, 1.4526, 1.4097, 1.4126, 1.4501, 1.4566, 1.4551, 1.4567, 1.4567,
         1.4328, 1.4303, 1.4253, 1.4207, 1.4340, 1.3941, 1.4281, 1.4339, 1.4294,
         1.7628, 1.7542, 1.7532, 1.7612, 1.7784, 1.7771, 1.7574, 1.7786, 1.7786,
         1.4766, 1.4826, 1.5183, 1.5132, 1.4821, 1.5169, 1.5052, 1.5183, 1.5152,
         2.2037, 2.1841, 2.1728, 2.1904, 2.2338, 2.2520, 2.2184, 2.3207, 2.3180,
         1.4296, 1.4197, 1.4340, 1.4443, 1.4319, 1.4411, 1.4125, 1.4383, 1.4443],
        [1.3426, 1.2523, 1.2475, 1.2667, 1.2596, 1.2700, 1.2688, 1.2104, 1.2104,
         1.2488, 1.2034, 1.2029, 1.2110, 1.2909, 1.1651, 1.1104, 1.2909, 1.1954,
         1.6038, 1.5805, 1.5614, 1.5584, 1.5820, 1.5780, 1.5967, 1.5834, 1.5834,
         1.3461, 1.3193, 1.3211, 1.3358, 1.3217, 1.3625, 1.3653, 1.3404, 1.3211,
         1.5814, 1.5793, 1.5867, 1.5761, 1.5516, 1.5547, 1.6148, 1.5053, 1.4742,
         4.0971, 3.6118, 3.7021, 3.6853, 3.6990, 3.3805, 4.0935, 3.6589, 3.4137]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 328 : 1778.9113796500267
Test loss for epoch 328 : 195.13297382087092
Test Precision for epoch 328 : 0.26153846153846155
Test Recall for epoch 328 : 0.26153846153846155
Test F1 for epoch 328 : 0.26153846153846155


theta for epoch 329 : tensor([[3.6125, 3.6333, 3.7769, 3.7252, 3.7084, 3.5939, 3.6350, 3.5343, 3.5343,
         1.2643, 1.2400, 1.2390, 1.2457, 1.2854, 1.2277, 1.1829, 1.2854, 1.2335,
         1.5946, 1.5788, 1.6033, 1.5852, 1.5907, 1.5924, 1.6001, 1.5923, 1.5923,
         1.3403, 1.3515, 1.3369, 1.3593, 1.3394, 1.3710, 1.3637, 1.3504, 1.3369,
         1.5940, 1.6106, 1.5989, 1.5953, 1.6024, 1.5927, 1.6115, 1.5647, 1.5693,
         1.2552, 1.2830, 1.2752, 1.2922, 1.2496, 1.2424, 1.2353, 1.3147, 1.2720],
        [1.3771, 1.2244, 1.2141, 1.2573, 1.2575, 1.2700, 1.2639, 1.1678, 1.1678,
         3.5805, 3.6705, 3.5094, 3.9185, 3.5804, 4.2864, 3.4428, 3.5345, 4.0334,
         1.5702, 1.5576, 1.5320, 1.5298, 1.5510, 1.5604, 1.5853, 1.5604, 1.5604,
         1.3485, 1.3147, 1.3084, 1.3670, 1.3086, 1.4047, 1.3848, 1.3531, 1.3053,
         1.5418, 1.5989, 1.5618, 1.5485, 1.5436, 1.5819, 1.6016, 1.4345, 1.5325,
         1.1611, 1.2767, 1.2506, 1.2977, 1.1551, 1.1641, 1.0940, 1.3593, 1.2415],
        [1.4487, 1.4486, 1.4470, 1.4442, 1.4446, 1.4487, 1.4444, 1.4487, 1.4487,
         1.4351, 1.4345, 1.4351, 1.4351, 1.4351, 1.4166, 1.4351, 1.4340, 1.4318,
         2.1973, 2.1975, 2.2143, 2.1901, 2.1716, 2.1699, 2.1990, 2.1690, 2.1690,
         1.5077, 1.5061, 1.5135, 1.5135, 1.5078, 1.5135, 1.5134, 1.5135, 1.5135,
         1.7734, 1.7734, 1.7734, 1.7703, 1.7733, 1.7733, 1.7734, 1.7510, 1.7537,
         1.4493, 1.4537, 1.4537, 1.4537, 1.4456, 1.4537, 1.4500, 1.4537, 1.4537],
        [1.3156, 1.3139, 1.2981, 1.2893, 1.3128, 1.3112, 1.3123, 1.3130, 1.3130,
         1.2998, 1.2931, 1.2892, 1.2889, 1.3005, 1.2853, 1.2963, 1.3001, 1.2728,
         1.6382, 1.6121, 1.6353, 1.6347, 1.6341, 1.6341, 1.6363, 1.6378, 1.6378,
         3.4893, 3.2807, 3.2065, 3.2644, 3.4143, 3.2334, 3.4646, 3.2143, 3.1932,
         1.6454, 1.6380, 1.6364, 1.6395, 1.6424, 1.6184, 1.6438, 1.5834, 1.6098,
         1.3165, 1.3109, 1.3011, 1.3156, 1.3115, 1.3038, 1.3161, 1.3157, 1.3180],
        [1.4515, 1.4475, 1.4044, 1.4073, 1.4449, 1.4514, 1.4500, 1.4515, 1.4515,
         1.4368, 1.4343, 1.4293, 1.4247, 1.4380, 1.3983, 1.4321, 1.4380, 1.4334,
         1.7530, 1.7443, 1.7434, 1.7513, 1.7686, 1.7673, 1.7476, 1.7687, 1.7687,
         1.4746, 1.4805, 1.5162, 1.5111, 1.4800, 1.5149, 1.5031, 1.5163, 1.5132,
         2.1983, 2.1788, 2.1675, 2.1850, 2.2285, 2.2467, 2.2131, 2.3152, 2.3126,
         1.4419, 1.4320, 1.4463, 1.4565, 1.4442, 1.4534, 1.4249, 1.4505, 1.4566],
        [1.3591, 1.2677, 1.2632, 1.2823, 1.2753, 1.2857, 1.2844, 1.2252, 1.2252,
         1.2614, 1.2176, 1.2172, 1.2247, 1.3018, 1.1792, 1.1284, 1.3018, 1.2096,
         1.6057, 1.5825, 1.5637, 1.5602, 1.5837, 1.5797, 1.5987, 1.5851, 1.5851,
         1.3584, 1.3317, 1.3328, 1.3482, 1.3339, 1.3752, 1.3778, 1.3526, 1.3329,
         1.5851, 1.5834, 1.5903, 1.5799, 1.5556, 1.5589, 1.6188, 1.5095, 1.4787,
         4.0831, 3.5975, 3.6878, 3.6710, 3.6847, 3.3662, 4.0794, 3.6446, 3.3994]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 329 : 1779.9926522548021
Test loss for epoch 329 : 194.3312059186474
Test Precision for epoch 329 : 0.26153846153846155
Test Recall for epoch 329 : 0.26153846153846155
Test F1 for epoch 329 : 0.26153846153846155


theta for epoch 330 : tensor([[3.6069, 3.6277, 3.7713, 3.7196, 3.7028, 3.5883, 3.6294, 3.5286, 3.5286,
         1.2711, 1.2480, 1.2470, 1.2532, 1.2912, 1.2354, 1.1936, 1.2912, 1.2412,
         1.5930, 1.5772, 1.6016, 1.5837, 1.5892, 1.5909, 1.5985, 1.5908, 1.5908,
         1.3377, 1.3489, 1.3346, 1.3566, 1.3369, 1.3682, 1.3609, 1.3478, 1.3347,
         1.5909, 1.6074, 1.5958, 1.5921, 1.5992, 1.5895, 1.6082, 1.5616, 1.5662,
         1.2581, 1.2856, 1.2778, 1.2947, 1.2526, 1.2454, 1.2391, 1.3167, 1.2746],
        [1.3883, 1.2374, 1.2269, 1.2700, 1.2702, 1.2826, 1.2766, 1.1816, 1.1816,
         3.5700, 3.6600, 3.4988, 3.9082, 3.5699, 4.2768, 3.4322, 3.5240, 4.0233,
         1.5777, 1.5653, 1.5397, 1.5378, 1.5589, 1.5683, 1.5928, 1.5683, 1.5683,
         1.3560, 1.3224, 1.3164, 1.3743, 1.3164, 1.4117, 1.3919, 1.3606, 1.3133,
         1.5478, 1.6043, 1.5677, 1.5544, 1.5495, 1.5875, 1.6070, 1.4410, 1.5385,
         1.1714, 1.2864, 1.2605, 1.3073, 1.1654, 1.1746, 1.1060, 1.3680, 1.2515],
        [1.4487, 1.4487, 1.4471, 1.4443, 1.4447, 1.4487, 1.4444, 1.4487, 1.4487,
         1.4408, 1.4401, 1.4408, 1.4407, 1.4408, 1.4223, 1.4408, 1.4397, 1.4374,
         2.1947, 2.1949, 2.2116, 2.1876, 2.1691, 2.1674, 2.1965, 2.1665, 2.1665,
         1.5038, 1.5021, 1.5096, 1.5096, 1.5038, 1.5096, 1.5095, 1.5096, 1.5096,
         1.7691, 1.7692, 1.7692, 1.7661, 1.7691, 1.7691, 1.7692, 1.7467, 1.7494,
         1.4510, 1.4555, 1.4555, 1.4555, 1.4473, 1.4555, 1.4517, 1.4554, 1.4555],
        [1.3160, 1.3143, 1.2984, 1.2896, 1.3132, 1.3116, 1.3127, 1.3133, 1.3133,
         1.3054, 1.2988, 1.2950, 1.2946, 1.3061, 1.2910, 1.3021, 1.3057, 1.2786,
         1.6354, 1.6093, 1.6325, 1.6319, 1.6313, 1.6313, 1.6335, 1.6350, 1.6350,
         3.4863, 3.2776, 3.2035, 3.2614, 3.4113, 3.2304, 3.4616, 3.2113, 3.1901,
         1.6412, 1.6337, 1.6321, 1.6352, 1.6381, 1.6141, 1.6395, 1.5791, 1.6055,
         1.3183, 1.3127, 1.3029, 1.3174, 1.3133, 1.3056, 1.3180, 1.3175, 1.3198],
        [1.4516, 1.4475, 1.4044, 1.4073, 1.4449, 1.4515, 1.4500, 1.4516, 1.4516,
         1.4425, 1.4399, 1.4350, 1.4304, 1.4436, 1.4040, 1.4378, 1.4436, 1.4391,
         1.7502, 1.7415, 1.7406, 1.7486, 1.7658, 1.7645, 1.7448, 1.7659, 1.7659,
         1.4706, 1.4766, 1.5123, 1.5072, 1.4761, 1.5109, 1.4992, 1.5124, 1.5092,
         2.1942, 2.1747, 2.1634, 2.1809, 2.2243, 2.2426, 2.2090, 2.3110, 2.3084,
         1.4437, 1.4338, 1.4480, 1.4583, 1.4460, 1.4551, 1.4267, 1.4523, 1.4583],
        [1.3736, 1.2812, 1.2767, 1.2959, 1.2889, 1.2993, 1.2980, 1.2379, 1.2379,
         1.2728, 1.2304, 1.2299, 1.2370, 1.3120, 1.1915, 1.1441, 1.3120, 1.2221,
         1.6108, 1.5875, 1.5690, 1.5650, 1.5884, 1.5845, 1.6037, 1.5898, 1.5898,
         1.3650, 1.3384, 1.3389, 1.3550, 1.3403, 1.3823, 1.3846, 1.3592, 1.3390,
         1.5873, 1.5859, 1.5925, 1.5821, 1.5580, 1.5614, 1.6212, 1.5120, 1.4814,
         4.0710, 3.5851, 3.6754, 3.6587, 3.6724, 3.3539, 4.0673, 3.6323, 3.3871]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 330 : 1780.6758636784057
Test loss for epoch 330 : 193.90381069039688
Test Precision for epoch 330 : 0.26153846153846155
Test Recall for epoch 330 : 0.26153846153846155
Test F1 for epoch 330 : 0.26153846153846155


theta for epoch 331 : tensor([[3.6027, 3.6234, 3.7670, 3.7153, 3.6985, 3.5840, 3.6251, 3.5242, 3.5242,
         1.2753, 1.2531, 1.2521, 1.2579, 1.2946, 1.2400, 1.2008, 1.2946, 1.2459,
         1.5987, 1.5830, 1.6073, 1.5895, 1.5950, 1.5967, 1.6042, 1.5967, 1.5967,
         1.3360, 1.3472, 1.3331, 1.3549, 1.3353, 1.3663, 1.3591, 1.3461, 1.3331,
         1.5920, 1.6084, 1.5968, 1.5932, 1.6003, 1.5905, 1.6092, 1.5627, 1.5673,
         1.2521, 1.2793, 1.2715, 1.2884, 1.2467, 1.2394, 1.2335, 1.3101, 1.2683],
        [1.3919, 1.2422, 1.2317, 1.2746, 1.2748, 1.2872, 1.2812, 1.1871, 1.1871,
         3.5659, 3.6559, 3.4946, 3.9044, 3.5659, 4.2736, 3.4280, 3.5199, 4.0197,
         1.5851, 1.5727, 1.5470, 1.5454, 1.5665, 1.5758, 1.6001, 1.5759, 1.5759,
         1.3586, 1.3250, 1.3194, 1.3768, 1.3191, 1.4139, 1.3942, 1.3632, 1.3162,
         1.5520, 1.6083, 1.5719, 1.5587, 1.5536, 1.5916, 1.6109, 1.4454, 1.5428,
         1.1706, 1.2850, 1.2593, 1.3058, 1.1647, 1.1740, 1.1066, 1.3657, 1.2503],
        [1.4472, 1.4471, 1.4455, 1.4427, 1.4431, 1.4472, 1.4429, 1.4471, 1.4471,
         1.4442, 1.4436, 1.4442, 1.4442, 1.4442, 1.4257, 1.4442, 1.4431, 1.4409,
         2.1994, 2.1996, 2.2163, 2.1921, 2.1737, 2.1719, 2.2010, 2.1711, 2.1711,
         1.5015, 1.4999, 1.5073, 1.5073, 1.5016, 1.5073, 1.5072, 1.5073, 1.5073,
         1.7695, 1.7696, 1.7696, 1.7665, 1.7695, 1.7695, 1.7696, 1.7471, 1.7498,
         1.4445, 1.4489, 1.4489, 1.4489, 1.4408, 1.4489, 1.4452, 1.4489, 1.4489],
        [1.3148, 1.3131, 1.2972, 1.2883, 1.3120, 1.3104, 1.3115, 1.3121, 1.3121,
         1.3089, 1.3023, 1.2985, 1.2982, 1.3096, 1.2946, 1.3057, 1.3092, 1.2821,
         1.6406, 1.6144, 1.6376, 1.6371, 1.6365, 1.6365, 1.6387, 1.6402, 1.6402,
         3.4841, 3.2755, 3.2013, 3.2592, 3.4091, 3.2282, 3.4594, 3.2091, 3.1879,
         1.6417, 1.6342, 1.6326, 1.6357, 1.6386, 1.6146, 1.6400, 1.5796, 1.6060,
         1.3119, 1.3063, 1.2965, 1.3110, 1.3068, 1.2991, 1.3115, 1.3111, 1.3133],
        [1.4500, 1.4459, 1.4027, 1.4057, 1.4433, 1.4499, 1.4484, 1.4500, 1.4500,
         1.4459, 1.4434, 1.4384, 1.4339, 1.4470, 1.4074, 1.4412, 1.4470, 1.4425,
         1.7551, 1.7464, 1.7456, 1.7535, 1.7707, 1.7694, 1.7497, 1.7708, 1.7708,
         1.4684, 1.4743, 1.5100, 1.5049, 1.4738, 1.5087, 1.4970, 1.5101, 1.5070,
         2.1946, 2.1751, 2.1638, 2.1813, 2.2247, 2.2430, 2.2094, 2.3114, 2.3087,
         1.4372, 1.4272, 1.4415, 1.4517, 1.4394, 1.4486, 1.4202, 1.4457, 1.4518],
        [1.3813, 1.2878, 1.2835, 1.3027, 1.2958, 1.3061, 1.3049, 1.2439, 1.2439,
         1.2798, 1.2384, 1.2378, 1.2444, 1.3180, 1.1989, 1.1544, 1.3180, 1.2296,
         1.6197, 1.5964, 1.5780, 1.5737, 1.5970, 1.5931, 1.6126, 1.5985, 1.5985,
         1.3690, 1.3423, 1.3424, 1.3591, 1.3441, 1.3866, 1.3887, 1.3631, 1.3425,
         1.5912, 1.5901, 1.5964, 1.5860, 1.5621, 1.5656, 1.6254, 1.5161, 1.4857,
         4.0613, 3.5751, 3.6654, 3.6487, 3.6624, 3.3439, 4.0575, 3.6223, 3.3770]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 331 : 1780.9267936609583
Test loss for epoch 331 : 193.63273268025074
Test Precision for epoch 331 : 0.26153846153846155
Test Recall for epoch 331 : 0.26153846153846155
Test F1 for epoch 331 : 0.26153846153846155


theta for epoch 332 : tensor([[3.5996, 3.6202, 3.7638, 3.7122, 3.6953, 3.5808, 3.6219, 3.5210, 3.5210,
         1.2732, 1.2515, 1.2505, 1.2559, 1.2920, 1.2379, 1.2007, 1.2920, 1.2439,
         1.6027, 1.5870, 1.6113, 1.5936, 1.5991, 1.6008, 1.6083, 1.6007, 1.6007,
         1.3368, 1.3481, 1.3340, 1.3557, 1.3362, 1.3670, 1.3599, 1.3470, 1.3340,
         1.5954, 1.6117, 1.6002, 1.5966, 1.6037, 1.5939, 1.6125, 1.5661, 1.5707,
         1.2502, 1.2773, 1.2694, 1.2864, 1.2448, 1.2374, 1.2319, 1.3080, 1.2662],
        [1.3885, 1.2396, 1.2290, 1.2719, 1.2721, 1.2845, 1.2785, 1.1850, 1.1850,
         3.5665, 3.6566, 3.4952, 3.9054, 3.5665, 4.2753, 3.4285, 3.5205, 4.0208,
         1.5865, 1.5741, 1.5483, 1.5469, 1.5681, 1.5774, 1.6016, 1.5775, 1.5775,
         1.3575, 1.3240, 1.3186, 1.3757, 1.3182, 1.4126, 1.3931, 1.3621, 1.3154,
         1.5535, 1.6097, 1.5734, 1.5602, 1.5551, 1.5930, 1.6122, 1.4467, 1.5442,
         1.1675, 1.2818, 1.2561, 1.3025, 1.1616, 1.1710, 1.1044, 1.3620, 1.2471],
        [1.4443, 1.4442, 1.4426, 1.4398, 1.4402, 1.4443, 1.4400, 1.4443, 1.4443,
         1.4417, 1.4411, 1.4417, 1.4417, 1.4417, 1.4232, 1.4417, 1.4406, 1.4383,
         2.2030, 2.2032, 2.2200, 2.1956, 2.1772, 2.1754, 2.2046, 2.1746, 2.1746,
         1.5025, 1.5008, 1.5082, 1.5082, 1.5025, 1.5082, 1.5082, 1.5082, 1.5082,
         1.7726, 1.7727, 1.7727, 1.7696, 1.7726, 1.7726, 1.7727, 1.7502, 1.7529,
         1.4426, 1.4471, 1.4471, 1.4471, 1.4390, 1.4471, 1.4434, 1.4470, 1.4471],
        [1.3125, 1.3106, 1.2947, 1.2859, 1.3096, 1.3080, 1.3091, 1.3096, 1.3096,
         1.3066, 1.3000, 1.2962, 1.2958, 1.3073, 1.2922, 1.3033, 1.3069, 1.2797,
         1.6448, 1.6186, 1.6418, 1.6412, 1.6406, 1.6406, 1.6429, 1.6443, 1.6443,
         3.4841, 3.2755, 3.2013, 3.2592, 3.4092, 3.2282, 3.4595, 3.2091, 3.1879,
         1.6450, 1.6375, 1.6359, 1.6390, 1.6419, 1.6179, 1.6433, 1.5829, 1.6093,
         1.3103, 1.3047, 1.2949, 1.3094, 1.3052, 1.2975, 1.3099, 1.3096, 1.3117],
        [1.4471, 1.4430, 1.3997, 1.4027, 1.4404, 1.4470, 1.4456, 1.4471, 1.4471,
         1.4434, 1.4409, 1.4359, 1.4313, 1.4445, 1.4049, 1.4387, 1.4445, 1.4400,
         1.7589, 1.7502, 1.7494, 1.7573, 1.7745, 1.7732, 1.7535, 1.7747, 1.7747,
         1.4693, 1.4753, 1.5110, 1.5059, 1.4748, 1.5096, 1.4979, 1.5110, 1.5079,
         2.1977, 2.1781, 2.1669, 2.1843, 2.2277, 2.2461, 2.2125, 2.3144, 2.3117,
         1.4353, 1.4254, 1.4397, 1.4499, 1.4376, 1.4467, 1.4183, 1.4439, 1.4499],
        [1.3825, 1.2881, 1.2840, 1.3032, 1.2963, 1.3066, 1.3054, 1.2437, 1.2437,
         1.2790, 1.2383, 1.2378, 1.2440, 1.3164, 1.1983, 1.1562, 1.3164, 1.2289,
         1.6247, 1.6013, 1.5830, 1.5784, 1.6018, 1.5979, 1.6176, 1.6032, 1.6032,
         1.3717, 1.3451, 1.3448, 1.3619, 1.3467, 1.3897, 1.3917, 1.3658, 1.3448,
         1.5952, 1.5944, 1.6005, 1.5901, 1.5662, 1.5698, 1.6297, 1.5202, 1.4898,
         4.0582, 3.5718, 3.6621, 3.6454, 3.6591, 3.3406, 4.0544, 3.6190, 3.3737]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 332 : 1781.0077654099155
Test loss for epoch 332 : 193.56666372003255
Test Precision for epoch 332 : 0.26153846153846155
Test Recall for epoch 332 : 0.26153846153846155
Test F1 for epoch 332 : 0.26153846153846155


theta for epoch 333 : tensor([[3.6020, 3.6226, 3.7662, 3.7146, 3.6977, 3.5832, 3.6243, 3.5235, 3.5235,
         1.2676, 1.2463, 1.2452, 1.2503, 1.2861, 1.2321, 1.1962, 1.2861, 1.2380,
         1.5984, 1.5827, 1.6071, 1.5893, 1.5948, 1.5964, 1.6040, 1.5964, 1.5964,
         1.3385, 1.3497, 1.3356, 1.3573, 1.3378, 1.3687, 1.3616, 1.3486, 1.3356,
         1.5968, 1.6131, 1.6016, 1.5980, 1.6051, 1.5953, 1.6139, 1.5676, 1.5722,
         1.2554, 1.2825, 1.2745, 1.2917, 1.2500, 1.2423, 1.2371, 1.3133, 1.2712],
        [1.3824, 1.2337, 1.2230, 1.2659, 1.2662, 1.2786, 1.2725, 1.1792, 1.1792,
         3.5720, 3.6622, 3.5007, 3.9112, 3.5720, 4.2818, 3.4339, 3.5260, 4.0268,
         1.5779, 1.5656, 1.5397, 1.5385, 1.5596, 1.5690, 1.5931, 1.5690, 1.5690,
         1.3525, 1.3189, 1.3137, 1.3707, 1.3132, 1.4076, 1.3881, 1.3572, 1.3105,
         1.5494, 1.6056, 1.5693, 1.5561, 1.5509, 1.5889, 1.6081, 1.4422, 1.5400,
         1.1647, 1.2793, 1.2534, 1.3001, 1.1588, 1.1682, 1.1020, 1.3594, 1.2444],
        [1.4479, 1.4479, 1.4462, 1.4434, 1.4438, 1.4479, 1.4436, 1.4479, 1.4479,
         1.4362, 1.4356, 1.4362, 1.4361, 1.4362, 1.4176, 1.4362, 1.4351, 1.4328,
         2.1994, 2.1996, 2.2163, 2.1921, 2.1737, 2.1719, 2.2010, 2.1710, 2.1710,
         1.5049, 1.5033, 1.5107, 1.5107, 1.5049, 1.5107, 1.5106, 1.5107, 1.5107,
         1.7742, 1.7743, 1.7743, 1.7712, 1.7742, 1.7742, 1.7743, 1.7518, 1.7545,
         1.4484, 1.4528, 1.4528, 1.4528, 1.4447, 1.4528, 1.4491, 1.4528, 1.4528],
        [1.3169, 1.3149, 1.2990, 1.2902, 1.3139, 1.3123, 1.3134, 1.3138, 1.3138,
         1.3013, 1.2947, 1.2909, 1.2905, 1.3020, 1.2869, 1.2980, 1.3016, 1.2744,
         1.6412, 1.6150, 1.6382, 1.6376, 1.6370, 1.6371, 1.6393, 1.6408, 1.6408,
         3.4848, 3.2761, 3.2020, 3.2599, 3.4098, 3.2289, 3.4601, 3.2097, 3.1886,
         1.6468, 1.6394, 1.6378, 1.6409, 1.6438, 1.6198, 1.6452, 1.5847, 1.6111,
         1.3164, 1.3108, 1.3010, 1.3156, 1.3113, 1.3036, 1.3160, 1.3158, 1.3179],
        [1.4508, 1.4466, 1.4032, 1.4063, 1.4440, 1.4507, 1.4492, 1.4507, 1.4507,
         1.4379, 1.4354, 1.4304, 1.4258, 1.4390, 1.3993, 1.4332, 1.4390, 1.4345,
         1.7551, 1.7464, 1.7455, 1.7535, 1.7707, 1.7694, 1.7496, 1.7708, 1.7708,
         1.4717, 1.4776, 1.5134, 1.5083, 1.4772, 1.5120, 1.5004, 1.5135, 1.5103,
         2.1993, 2.1797, 2.1684, 2.1859, 2.2293, 2.2476, 2.2141, 2.3160, 2.3133,
         1.4410, 1.4311, 1.4454, 1.4556, 1.4433, 1.4524, 1.4240, 1.4496, 1.4557],
        [1.3829, 1.2879, 1.2838, 1.3031, 1.2962, 1.3065, 1.3053, 1.2431, 1.2431,
         1.2732, 1.2331, 1.2325, 1.2383, 1.3102, 1.1924, 1.1524, 1.3102, 1.2231,
         1.6202, 1.5968, 1.5785, 1.5737, 1.5971, 1.5932, 1.6130, 1.5985, 1.5985,
         1.3721, 1.3454, 1.3449, 1.3623, 1.3470, 1.3902, 1.3922, 1.3661, 1.3449,
         1.5956, 1.5949, 1.6009, 1.5905, 1.5667, 1.5703, 1.6304, 1.5206, 1.4902,
         4.0624, 3.5757, 3.6661, 3.6493, 3.6630, 3.3446, 4.0586, 3.6230, 3.3777]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 333 : 1780.524553916513
Test loss for epoch 333 : 193.82985500009914
Test Precision for epoch 333 : 0.26153846153846155
Test Recall for epoch 333 : 0.26153846153846155
Test F1 for epoch 333 : 0.26153846153846155


theta for epoch 334 : tensor([[3.6066, 3.6273, 3.7708, 3.7192, 3.7024, 3.5879, 3.6290, 3.5282, 3.5282,
         1.2633, 1.2420, 1.2409, 1.2458, 1.2818, 1.2271, 1.1921, 1.2818, 1.2329,
         1.5945, 1.5789, 1.6032, 1.5854, 1.5909, 1.5925, 1.6001, 1.5925, 1.5925,
         1.3389, 1.3502, 1.3358, 1.3578, 1.3382, 1.3692, 1.3620, 1.3490, 1.3359,
         1.5951, 1.6114, 1.5999, 1.5963, 1.6033, 1.5936, 1.6122, 1.5658, 1.5705,
         1.2602, 1.2872, 1.2791, 1.2965, 1.2547, 1.2468, 1.2416, 1.3183, 1.2758],
        [1.3717, 1.2226, 1.2119, 1.2549, 1.2551, 1.2676, 1.2615, 1.1680, 1.1680,
         3.5829, 3.6732, 3.5115, 3.9225, 3.5829, 4.2937, 3.4448, 3.5369, 4.0382,
         1.5660, 1.5537, 1.5277, 1.5265, 1.5477, 1.5571, 1.5813, 1.5571, 1.5571,
         1.3431, 1.3094, 1.3042, 1.3614, 1.3037, 1.3983, 1.3788, 1.3478, 1.3010,
         1.5393, 1.5957, 1.5593, 1.5460, 1.5408, 1.5789, 1.5982, 1.4316, 1.5299,
         1.1579, 1.2730, 1.2469, 1.2939, 1.1520, 1.1613, 1.0952, 1.3534, 1.2378],
        [1.4517, 1.4517, 1.4500, 1.4472, 1.4476, 1.4517, 1.4474, 1.4517, 1.4517,
         1.4324, 1.4317, 1.4323, 1.4323, 1.4324, 1.4138, 1.4323, 1.4312, 1.4290,
         2.1966, 2.1968, 2.2135, 2.1893, 2.1710, 2.1692, 2.1983, 2.1683, 2.1683,
         1.5068, 1.5051, 1.5125, 1.5125, 1.5068, 1.5125, 1.5125, 1.5125, 1.5125,
         1.7731, 1.7732, 1.7732, 1.7701, 1.7731, 1.7731, 1.7732, 1.7507, 1.7534,
         1.4541, 1.4586, 1.4586, 1.4586, 1.4504, 1.4586, 1.4548, 1.4585, 1.4586],
        [1.3215, 1.3194, 1.3034, 1.2947, 1.3183, 1.3168, 1.3179, 1.3182, 1.3182,
         1.2978, 1.2911, 1.2873, 1.2869, 1.2984, 1.2832, 1.2944, 1.2980, 1.2707,
         1.6386, 1.6124, 1.6356, 1.6350, 1.6344, 1.6345, 1.6367, 1.6381, 1.6381,
         3.4846, 3.2759, 3.2017, 3.2596, 3.4096, 3.2287, 3.4599, 3.2095, 3.1884,
         1.6460, 1.6386, 1.6370, 1.6401, 1.6430, 1.6190, 1.6444, 1.5839, 1.6103,
         1.3225, 1.3170, 1.3071, 1.3218, 1.3175, 1.3097, 1.3221, 1.3220, 1.3240],
        [1.4546, 1.4503, 1.4068, 1.4100, 1.4477, 1.4545, 1.4530, 1.4546, 1.4546,
         1.4341, 1.4315, 1.4265, 1.4220, 1.4352, 1.3954, 1.4294, 1.4352, 1.4306,
         1.7521, 1.7434, 1.7425, 1.7505, 1.7678, 1.7665, 1.7467, 1.7679, 1.7679,
         1.4736, 1.4793, 1.5153, 1.5102, 1.4790, 1.5139, 1.5022, 1.5153, 1.5122,
         2.1983, 2.1787, 2.1674, 2.1849, 2.2283, 2.2466, 2.2131, 2.3151, 2.3124,
         1.4467, 1.4368, 1.4511, 1.4613, 1.4490, 1.4582, 1.4296, 1.4553, 1.4614],
        [1.3787, 1.2835, 1.2794, 1.2987, 1.2918, 1.3021, 1.3009, 1.2385, 1.2385,
         1.2670, 1.2272, 1.2265, 1.2321, 1.3037, 1.1857, 1.1472, 1.3038, 1.2164,
         1.6141, 1.5906, 1.5724, 1.5675, 1.5908, 1.5869, 1.6069, 1.5923, 1.5923,
         1.3688, 1.3420, 1.3415, 1.3590, 1.3436, 1.3870, 1.3890, 1.3628, 1.3415,
         1.5916, 1.5909, 1.5968, 1.5864, 1.5626, 1.5663, 1.6265, 1.5165, 1.4860,
         4.0707, 3.5838, 3.6741, 3.6574, 3.6711, 3.3527, 4.0668, 3.6311, 3.3858]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 334 : 1780.0707210743503
Test loss for epoch 334 : 194.42612649260982
Test Precision for epoch 334 : 0.26153846153846155
Test Recall for epoch 334 : 0.26153846153846155
Test F1 for epoch 334 : 0.26153846153846155


theta for epoch 335 : tensor([[3.6119, 3.6327, 3.7762, 3.7245, 3.7077, 3.5933, 3.6344, 3.5337, 3.5337,
         1.2612, 1.2398, 1.2386, 1.2433, 1.2799, 1.2242, 1.1895, 1.2799, 1.2299,
         1.5972, 1.5815, 1.6059, 1.5880, 1.5935, 1.5951, 1.6028, 1.5951, 1.5951,
         1.3396, 1.3508, 1.3364, 1.3584, 1.3388, 1.3700, 1.3627, 1.3496, 1.3364,
         1.5937, 1.6101, 1.5986, 1.5950, 1.6020, 1.5923, 1.6110, 1.5645, 1.5691,
         1.2550, 1.2821, 1.2739, 1.2915, 1.2496, 1.2414, 1.2361, 1.3133, 1.2705],
        [1.3558, 1.2059, 1.1952, 1.2383, 1.2386, 1.2510, 1.2449, 1.1509, 1.1509,
         3.5988, 3.6891, 3.5274, 3.9387, 3.5988, 4.3106, 3.4606, 3.5528, 4.0547,
         1.5557, 1.5433, 1.5171, 1.5158, 1.5372, 1.5467, 1.5710, 1.5467, 1.5467,
         1.3309, 1.2971, 1.2917, 1.3492, 1.2913, 1.3864, 1.3667, 1.3356, 1.2885,
         1.5266, 1.5834, 1.5468, 1.5334, 1.5282, 1.5665, 1.5860, 1.4184, 1.5172,
         1.1417, 1.2573, 1.2310, 1.2784, 1.1358, 1.1450, 1.0790, 1.3381, 1.2218],
        [1.4521, 1.4520, 1.4503, 1.4475, 1.4480, 1.4521, 1.4478, 1.4521, 1.4521,
         1.4313, 1.4307, 1.4313, 1.4313, 1.4313, 1.4127, 1.4313, 1.4302, 1.4280,
         2.2004, 2.2006, 2.2173, 2.1930, 2.1746, 2.1728, 2.2020, 2.1719, 2.1719,
         1.5096, 1.5079, 1.5153, 1.5153, 1.5096, 1.5153, 1.5153, 1.5153, 1.5153,
         1.7729, 1.7730, 1.7730, 1.7699, 1.7729, 1.7729, 1.7730, 1.7505, 1.7532,
         1.4504, 1.4549, 1.4549, 1.4549, 1.4467, 1.4549, 1.4511, 1.4548, 1.4549],
        [1.3225, 1.3202, 1.3043, 1.2955, 1.3192, 1.3176, 1.3187, 1.3190, 1.3190,
         1.2970, 1.2903, 1.2865, 1.2861, 1.2977, 1.2824, 1.2935, 1.2973, 1.2699,
         1.6431, 1.6168, 1.6401, 1.6394, 1.6388, 1.6389, 1.6411, 1.6426, 1.6426,
         3.4852, 3.2765, 3.2023, 3.2602, 3.4102, 3.2293, 3.4605, 3.2101, 3.1890,
         1.6461, 1.6387, 1.6370, 1.6401, 1.6430, 1.6190, 1.6445, 1.5839, 1.6103,
         1.3192, 1.3136, 1.3038, 1.3185, 1.3141, 1.3063, 1.3188, 1.3187, 1.3207],
        [1.4549, 1.4506, 1.4069, 1.4103, 1.4481, 1.4548, 1.4533, 1.4549, 1.4549,
         1.4330, 1.4305, 1.4255, 1.4209, 1.4342, 1.3943, 1.4283, 1.4342, 1.4295,
         1.7561, 1.7474, 1.7465, 1.7545, 1.7718, 1.7705, 1.7507, 1.7719, 1.7719,
         1.4764, 1.4820, 1.5181, 1.5129, 1.4818, 1.5167, 1.5050, 1.5181, 1.5150,
         2.1981, 2.1785, 2.1672, 2.1847, 2.2282, 2.2464, 2.2129, 2.3150, 2.3123,
         1.4429, 1.4331, 1.4474, 1.4577, 1.4452, 1.4544, 1.4258, 1.4516, 1.4577],
        [1.3681, 1.2732, 1.2691, 1.2884, 1.2814, 1.2917, 1.2905, 1.2283, 1.2283,
         1.2615, 1.2218, 1.2210, 1.2263, 1.2983, 1.1793, 1.1418, 1.2983, 1.2100,
         1.6120, 1.5885, 1.5702, 1.5653, 1.5887, 1.5848, 1.6048, 1.5902, 1.5902,
         1.3635, 1.3367, 1.3362, 1.3537, 1.3383, 1.3817, 1.3837, 1.3575, 1.3362,
         1.5866, 1.5859, 1.5918, 1.5814, 1.5575, 1.5612, 1.6216, 1.5114, 1.4807,
         4.0794, 3.5923, 3.6826, 3.6659, 3.6796, 3.3613, 4.0755, 3.6397, 3.3944]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 335 : 1779.1784500976614
Test loss for epoch 335 : 195.2558189876952
Test Precision for epoch 335 : 0.26153846153846155
Test Recall for epoch 335 : 0.26153846153846155
Test F1 for epoch 335 : 0.26153846153846155


theta for epoch 336 : tensor([[3.6116, 3.6324, 3.7758, 3.7242, 3.7074, 3.5930, 3.6340, 3.5334, 3.5334,
         1.2591, 1.2380, 1.2368, 1.2412, 1.2776, 1.2217, 1.1884, 1.2776, 1.2275,
         1.6043, 1.5886, 1.6129, 1.5950, 1.6005, 1.6022, 1.6099, 1.6021, 1.6021,
         1.3422, 1.3534, 1.3390, 1.3611, 1.3415, 1.3726, 1.3654, 1.3522, 1.3390,
         1.5959, 1.6122, 1.6007, 1.5971, 1.6042, 1.5944, 1.6131, 1.5667, 1.5713,
         1.2470, 1.2740, 1.2657, 1.2834, 1.2416, 1.2333, 1.2277, 1.3051, 1.2623],
        [1.3666, 1.2163, 1.2057, 1.2488, 1.2490, 1.2615, 1.2554, 1.1611, 1.1611,
         3.5873, 3.6777, 3.5158, 3.9275, 3.5874, 4.3001, 3.4490, 3.5413, 4.0436,
         1.5685, 1.5560, 1.5299, 1.5286, 1.5499, 1.5593, 1.5838, 1.5594, 1.5594,
         1.3406, 1.3068, 1.3013, 1.3589, 1.3009, 1.3961, 1.3764, 1.3452, 1.2981,
         1.5358, 1.5925, 1.5559, 1.5426, 1.5374, 1.5757, 1.5951, 1.4279, 1.5265,
         1.1449, 1.2601, 1.2338, 1.2813, 1.1389, 1.1479, 1.0821, 1.3409, 1.2245],
        [1.4539, 1.4539, 1.4522, 1.4494, 1.4498, 1.4539, 1.4496, 1.4539, 1.4539,
         1.4293, 1.4286, 1.4292, 1.4292, 1.4293, 1.4106, 1.4292, 1.4281, 1.4259,
         2.2070, 2.2072, 2.2239, 2.1994, 2.1810, 2.1792, 2.2083, 2.1783, 2.1783,
         1.5127, 1.5110, 1.5184, 1.5184, 1.5127, 1.5184, 1.5184, 1.5184, 1.5184,
         1.7750, 1.7751, 1.7751, 1.7720, 1.7750, 1.7750, 1.7751, 1.7526, 1.7553,
         1.4422, 1.4468, 1.4468, 1.4468, 1.4386, 1.4468, 1.4429, 1.4467, 1.4468],
        [1.3248, 1.3225, 1.3065, 1.2977, 1.3214, 1.3199, 1.3210, 1.3212, 1.3212,
         1.2952, 1.2885, 1.2846, 1.2843, 1.2959, 1.2805, 1.2917, 1.2955, 1.2680,
         1.6505, 1.6242, 1.6475, 1.6469, 1.6463, 1.6463, 1.6486, 1.6500, 1.6500,
         3.4861, 3.2774, 3.2032, 3.2611, 3.4112, 3.2302, 3.4614, 3.2110, 3.1899,
         1.6485, 1.6411, 1.6394, 1.6425, 1.6454, 1.6214, 1.6469, 1.5863, 1.6127,
         1.3114, 1.3059, 1.2960, 1.3107, 1.3063, 1.2985, 1.3109, 1.3110, 1.3129],
        [1.4568, 1.4524, 1.4086, 1.4121, 1.4499, 1.4567, 1.4551, 1.4568, 1.4568,
         1.4309, 1.4284, 1.4234, 1.4188, 1.4321, 1.3921, 1.4262, 1.4321, 1.4275,
         1.7631, 1.7544, 1.7534, 1.7614, 1.7788, 1.7775, 1.7576, 1.7789, 1.7789,
         1.4794, 1.4850, 1.5212, 1.5160, 1.4848, 1.5198, 1.5082, 1.5212, 1.5181,
         2.2002, 2.1805, 2.1692, 2.1868, 2.2303, 2.2485, 2.2149, 2.3171, 2.3144,
         1.4347, 1.4249, 1.4393, 1.4495, 1.4370, 1.4463, 1.4175, 1.4435, 1.4496],
        [1.3593, 1.2655, 1.2613, 1.2805, 1.2734, 1.2838, 1.2826, 1.2213, 1.2213,
         1.2559, 1.2168, 1.2159, 1.2209, 1.2922, 1.1736, 1.1384, 1.2922, 1.2044,
         1.6136, 1.5900, 1.5716, 1.5669, 1.5904, 1.5865, 1.6064, 1.5918, 1.5918,
         1.3595, 1.3326, 1.3324, 1.3495, 1.3343, 1.3774, 1.3795, 1.3534, 1.3325,
         1.5847, 1.5839, 1.5899, 1.5795, 1.5555, 1.5591, 1.6196, 1.5093, 1.4785,
         4.0846, 3.5974, 3.6877, 3.6710, 3.6847, 3.3664, 4.0808, 3.6448, 3.3995]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 336 : 1779.596244445917
Test loss for epoch 336 : 194.68897699327852
Test Precision for epoch 336 : 0.26153846153846155
Test Recall for epoch 336 : 0.26153846153846155
Test F1 for epoch 336 : 0.26153846153846155


theta for epoch 337 : tensor([[3.6139, 3.6347, 3.7780, 3.7264, 3.7097, 3.5954, 3.6364, 3.5358, 3.5358,
         1.2613, 1.2404, 1.2391, 1.2432, 1.2797, 1.2234, 1.1909, 1.2798, 1.2291,
         1.6021, 1.5864, 1.6107, 1.5928, 1.5983, 1.6000, 1.6077, 1.5999, 1.5999,
         1.3400, 1.3512, 1.3367, 1.3588, 1.3392, 1.3704, 1.3631, 1.3499, 1.3367,
         1.5970, 1.6133, 1.6018, 1.5982, 1.6053, 1.5955, 1.6142, 1.5678, 1.5724,
         1.2429, 1.2697, 1.2614, 1.2792, 1.2376, 1.2291, 1.2232, 1.3009, 1.2581],
        [1.3713, 1.2201, 1.2096, 1.2528, 1.2530, 1.2654, 1.2594, 1.1645, 1.1645,
         3.5835, 3.6740, 3.5120, 3.9241, 3.5836, 4.2973, 3.4452, 3.5375, 4.0404,
         1.5704, 1.5580, 1.5320, 1.5304, 1.5517, 1.5611, 1.5857, 1.5612, 1.5612,
         1.3430, 1.3092, 1.3035, 1.3613, 1.3033, 1.3987, 1.3789, 1.3476, 1.3003,
         1.5398, 1.5966, 1.5599, 1.5465, 1.5414, 1.5797, 1.5992, 1.4319, 1.5305,
         1.1457, 1.2610, 1.2345, 1.2823, 1.1396, 1.1482, 1.0825, 1.3421, 1.2251],
        [1.4546, 1.4546, 1.4529, 1.4501, 1.4505, 1.4546, 1.4503, 1.4546, 1.4546,
         1.4320, 1.4313, 1.4320, 1.4320, 1.4320, 1.4134, 1.4320, 1.4309, 1.4286,
         2.2056, 2.2058, 2.2225, 2.1980, 2.1796, 2.1779, 2.2070, 2.1770, 2.1770,
         1.5116, 1.5100, 1.5174, 1.5174, 1.5116, 1.5174, 1.5174, 1.5174, 1.5174,
         1.7766, 1.7767, 1.7767, 1.7735, 1.7766, 1.7766, 1.7767, 1.7541, 1.7568,
         1.4386, 1.4431, 1.4431, 1.4431, 1.4349, 1.4431, 1.4392, 1.4431, 1.4431],
        [1.3257, 1.3234, 1.3074, 1.2986, 1.3223, 1.3208, 1.3219, 1.3221, 1.3221,
         1.2981, 1.2914, 1.2876, 1.2872, 1.2989, 1.2834, 1.2946, 1.2985, 1.2709,
         1.6494, 1.6230, 1.6463, 1.6457, 1.6451, 1.6451, 1.6474, 1.6488, 1.6488,
         3.4836, 3.2749, 3.2007, 3.2586, 3.4086, 3.2276, 3.4589, 3.2085, 3.1873,
         1.6503, 1.6429, 1.6412, 1.6443, 1.6472, 1.6232, 1.6487, 1.5881, 1.6145,
         1.3080, 1.3025, 1.2926, 1.3074, 1.3029, 1.2951, 1.3075, 1.3077, 1.3095],
        [1.4574, 1.4530, 1.4092, 1.4128, 1.4506, 1.4574, 1.4558, 1.4575, 1.4575,
         1.4337, 1.4311, 1.4261, 1.4215, 1.4349, 1.3948, 1.4290, 1.4348, 1.4302,
         1.7616, 1.7530, 1.7520, 1.7599, 1.7774, 1.7760, 1.7562, 1.7775, 1.7775,
         1.4784, 1.4839, 1.5201, 1.5150, 1.4837, 1.5187, 1.5071, 1.5202, 1.5171,
         2.2018, 2.1821, 2.1708, 2.1884, 2.2318, 2.2501, 2.2165, 2.3188, 2.3161,
         1.4309, 1.4212, 1.4356, 1.4459, 1.4333, 1.4426, 1.4137, 1.4399, 1.4459],
        [1.3470, 1.2543, 1.2500, 1.2691, 1.2621, 1.2724, 1.2712, 1.2109, 1.2109,
         1.2531, 1.2143, 1.2133, 1.2180, 1.2892, 1.1702, 1.1365, 1.2893, 1.2011,
         1.6058, 1.5822, 1.5637, 1.5592, 1.5828, 1.5788, 1.5986, 1.5842, 1.5842,
         1.3499, 1.3230, 1.3231, 1.3398, 1.3248, 1.3675, 1.3698, 1.3438, 1.3232,
         1.5808, 1.5798, 1.5861, 1.5756, 1.5515, 1.5550, 1.6156, 1.5052, 1.4741,
         4.0949, 3.6075, 3.6978, 3.6811, 3.6948, 3.3766, 4.0911, 3.6549, 3.4096]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 337 : 1779.5113108439205
Test loss for epoch 337 : 194.78438015006662
Test Precision for epoch 337 : 0.26153846153846155
Test Recall for epoch 337 : 0.26153846153846155
Test F1 for epoch 337 : 0.26153846153846155


theta for epoch 338 : tensor([[3.6178, 3.6386, 3.7819, 3.7303, 3.7135, 3.5993, 3.6403, 3.5398, 3.5398,
         1.2659, 1.2450, 1.2437, 1.2476, 1.2844, 1.2273, 1.1954, 1.2844, 1.2330,
         1.5943, 1.5786, 1.6029, 1.5850, 1.5906, 1.5922, 1.5999, 1.5922, 1.5922,
         1.3372, 1.3484, 1.3340, 1.3560, 1.3365, 1.3676, 1.3603, 1.3472, 1.3340,
         1.5947, 1.6110, 1.5995, 1.5960, 1.6030, 1.5932, 1.6119, 1.5656, 1.5701,
         1.2424, 1.2691, 1.2607, 1.2785, 1.2370, 1.2285, 1.2221, 1.3003, 1.2574],
        [1.3695, 1.2175, 1.2071, 1.2503, 1.2505, 1.2630, 1.2569, 1.1615, 1.1615,
         3.5865, 3.6771, 3.5150, 3.9275, 3.5867, 4.3013, 3.4482, 3.5406, 4.0439,
         1.5643, 1.5517, 1.5259, 1.5241, 1.5453, 1.5548, 1.5795, 1.5548, 1.5548,
         1.3407, 1.3069, 1.3009, 1.3590, 1.3009, 1.3966, 1.3767, 1.3452, 1.2977,
         1.5370, 1.5939, 1.5571, 1.5437, 1.5387, 1.5770, 1.5967, 1.4291, 1.5277,
         1.1440, 1.2598, 1.2329, 1.2813, 1.1378, 1.1461, 1.0800, 1.3415, 1.2234],
        [1.4534, 1.4533, 1.4517, 1.4489, 1.4493, 1.4534, 1.4491, 1.4534, 1.4534,
         1.4375, 1.4369, 1.4375, 1.4375, 1.4375, 1.4189, 1.4375, 1.4364, 1.4342,
         2.1995, 2.1997, 2.2164, 2.1921, 2.1737, 2.1719, 2.2011, 2.1710, 2.1710,
         1.5106, 1.5090, 1.5164, 1.5164, 1.5107, 1.5164, 1.5164, 1.5164, 1.5164,
         1.7752, 1.7753, 1.7753, 1.7722, 1.7752, 1.7752, 1.7753, 1.7527, 1.7554,
         1.4390, 1.4435, 1.4435, 1.4435, 1.4353, 1.4435, 1.4396, 1.4435, 1.4435],
        [1.3245, 1.3221, 1.3061, 1.2973, 1.3210, 1.3195, 1.3206, 1.3208, 1.3208,
         1.3038, 1.2971, 1.2933, 1.2929, 1.3046, 1.2891, 1.3002, 1.3042, 1.2766,
         1.6430, 1.6167, 1.6400, 1.6393, 1.6388, 1.6388, 1.6411, 1.6425, 1.6425,
         3.4815, 3.2728, 3.1986, 3.2565, 3.4066, 3.2255, 3.4568, 3.2063, 3.1852,
         1.6491, 1.6417, 1.6400, 1.6431, 1.6460, 1.6220, 1.6475, 1.5868, 1.6133,
         1.3087, 1.3032, 1.2933, 1.3081, 1.3036, 1.2957, 1.3081, 1.3084, 1.3102],
        [1.4562, 1.4518, 1.4079, 1.4116, 1.4493, 1.4562, 1.4546, 1.4562, 1.4562,
         1.4392, 1.4367, 1.4316, 1.4270, 1.4404, 1.4003, 1.4345, 1.4404, 1.4357,
         1.7552, 1.7465, 1.7454, 1.7534, 1.7709, 1.7696, 1.7497, 1.7711, 1.7711,
         1.4774, 1.4828, 1.5192, 1.5140, 1.4827, 1.5177, 1.5061, 1.5192, 1.5161,
         2.2005, 2.1808, 2.1694, 2.1871, 2.2305, 2.2488, 2.2152, 2.3176, 2.3148,
         1.4313, 1.4216, 1.4360, 1.4463, 1.4337, 1.4431, 1.4140, 1.4403, 1.4464],
        [1.3317, 1.2400, 1.2355, 1.2546, 1.2475, 1.2579, 1.2567, 1.1971, 1.1971,
         1.2518, 1.2128, 1.2118, 1.2163, 1.2881, 1.1679, 1.1348, 1.2881, 1.1988,
         1.5923, 1.5686, 1.5501, 1.5457, 1.5693, 1.5653, 1.5850, 1.5707, 1.5707,
         1.3388, 1.3119, 1.3123, 1.3286, 1.3138, 1.3562, 1.3586, 1.3328, 1.3123,
         1.5730, 1.5718, 1.5782, 1.5677, 1.5435, 1.5470, 1.6078, 1.4971, 1.4658,
         4.1094, 3.6218, 3.7120, 3.6954, 3.7091, 3.3910, 4.1056, 3.6691, 3.4239]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 338 : 1779.1858333563
Test loss for epoch 338 : 195.32134599591876
Test Precision for epoch 338 : 0.26153846153846155
Test Recall for epoch 338 : 0.26153846153846155
Test F1 for epoch 338 : 0.26153846153846155


theta for epoch 339 : tensor([[3.6260, 3.6470, 3.7901, 3.7386, 3.7218, 3.6076, 3.6486, 3.5483, 3.5483,
         1.2658, 1.2447, 1.2434, 1.2471, 1.2843, 1.2265, 1.1949, 1.2844, 1.2320,
         1.5919, 1.5762, 1.6005, 1.5827, 1.5883, 1.5899, 1.5976, 1.5899, 1.5899,
         1.3380, 1.3493, 1.3349, 1.3569, 1.3374, 1.3684, 1.3611, 1.3480, 1.3349,
         1.5915, 1.6077, 1.5962, 1.5927, 1.5997, 1.5899, 1.6085, 1.5623, 1.5668,
         1.2385, 1.2651, 1.2567, 1.2746, 1.2332, 1.2245, 1.2176, 1.2964, 1.2534],
        [1.3639, 1.2110, 1.2007, 1.2440, 1.2442, 1.2566, 1.2506, 1.1546, 1.1546,
         3.5940, 3.6846, 3.5224, 3.9352, 3.5941, 4.3097, 3.4555, 3.5480, 4.0518,
         1.5579, 1.5453, 1.5194, 1.5175, 1.5388, 1.5482, 1.5731, 1.5483, 1.5483,
         1.3364, 1.3024, 1.2962, 1.3547, 1.2963, 1.3925, 1.3726, 1.3409, 1.2931,
         1.5297, 1.5869, 1.5499, 1.5365, 1.5314, 1.5699, 1.5897, 1.4217, 1.5205,
         1.1359, 1.2522, 1.2250, 1.2739, 1.1296, 1.1375, 1.0710, 1.3347, 1.2153],
        [1.4551, 1.4551, 1.4534, 1.4506, 1.4510, 1.4551, 1.4508, 1.4551, 1.4551,
         1.4386, 1.4379, 1.4386, 1.4386, 1.4386, 1.4199, 1.4386, 1.4375, 1.4352,
         2.1988, 2.1990, 2.2157, 2.1915, 2.1731, 2.1713, 2.2004, 2.1704, 2.1704,
         1.5138, 1.5122, 1.5196, 1.5196, 1.5138, 1.5196, 1.5196, 1.5196, 1.5196,
         1.7732, 1.7733, 1.7733, 1.7701, 1.7732, 1.7732, 1.7733, 1.7506, 1.7534,
         1.4367, 1.4413, 1.4413, 1.4413, 1.4331, 1.4413, 1.4374, 1.4413, 1.4413],
        [1.3259, 1.3235, 1.3075, 1.2988, 1.3225, 1.3209, 1.3220, 1.3222, 1.3222,
         1.3050, 1.2983, 1.2944, 1.2940, 1.3058, 1.2902, 1.3013, 1.3054, 1.2777,
         1.6424, 1.6160, 1.6394, 1.6387, 1.6381, 1.6382, 1.6404, 1.6418, 1.6418,
         3.4837, 3.2749, 3.2007, 3.2587, 3.4087, 3.2277, 3.4589, 3.2085, 3.1874,
         1.6471, 1.6397, 1.6380, 1.6411, 1.6441, 1.6201, 1.6455, 1.5849, 1.6113,
         1.3065, 1.3010, 1.2911, 1.3059, 1.3015, 1.2935, 1.3059, 1.3063, 1.3080],
        [1.4579, 1.4535, 1.4096, 1.4133, 1.4510, 1.4578, 1.4563, 1.4579, 1.4579,
         1.4403, 1.4377, 1.4327, 1.4281, 1.4414, 1.4013, 1.4356, 1.4414, 1.4368,
         1.7544, 1.7457, 1.7447, 1.7527, 1.7702, 1.7689, 1.7490, 1.7704, 1.7704,
         1.4805, 1.4859, 1.5223, 1.5171, 1.4859, 1.5209, 1.5093, 1.5224, 1.5193,
         2.1985, 2.1788, 2.1675, 2.1851, 2.2286, 2.2468, 2.2132, 2.3157, 2.3130,
         1.4290, 1.4194, 1.4337, 1.4441, 1.4314, 1.4408, 1.4117, 1.4380, 1.4441],
        [1.3180, 1.2266, 1.2220, 1.2411, 1.2340, 1.2444, 1.2432, 1.1839, 1.1839,
         1.2456, 1.2062, 1.2051, 1.2096, 1.2825, 1.1603, 1.1272, 1.2825, 1.1913,
         1.5830, 1.5592, 1.5406, 1.5362, 1.5599, 1.5560, 1.5757, 1.5614, 1.5614,
         1.3303, 1.3032, 1.3038, 1.3200, 1.3052, 1.3476, 1.3501, 1.3242, 1.3038,
         1.5636, 1.5624, 1.5688, 1.5583, 1.5340, 1.5375, 1.5985, 1.4874, 1.4559,
         4.1250, 3.6372, 3.7274, 3.7108, 3.7245, 3.4064, 4.1212, 3.6845, 3.4394]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 339 : 1778.805412480923
Test loss for epoch 339 : 195.95192619465726
Test Precision for epoch 339 : 0.26153846153846155
Test Recall for epoch 339 : 0.26153846153846155
Test F1 for epoch 339 : 0.26153846153846155


theta for epoch 340 : tensor([[3.6336, 3.6546, 3.7977, 3.7462, 3.7294, 3.6153, 3.6563, 3.5561, 3.5561,
         1.2590, 1.2384, 1.2370, 1.2404, 1.2773, 1.2196, 1.1894, 1.2774, 1.2251,
         1.5982, 1.5826, 1.6067, 1.5891, 1.5947, 1.5963, 1.6039, 1.5963, 1.5963,
         1.3420, 1.3533, 1.3391, 1.3609, 1.3415, 1.3723, 1.3651, 1.3521, 1.3391,
         1.5922, 1.6083, 1.5969, 1.5934, 1.6003, 1.5905, 1.6091, 1.5629, 1.5675,
         1.2314, 1.2579, 1.2495, 1.2674, 1.2261, 1.2173, 1.2099, 1.2892, 1.2461],
        [1.3653, 1.2122, 1.2018, 1.2452, 1.2454, 1.2579, 1.2518, 1.1557, 1.1557,
         3.5931, 3.6838, 3.5215, 3.9347, 3.5933, 4.3099, 3.4546, 3.5472, 4.0515,
         1.5622, 1.5496, 1.5236, 1.5217, 1.5430, 1.5525, 1.5775, 1.5525, 1.5525,
         1.3386, 1.3046, 1.2984, 1.3571, 1.2985, 1.3949, 1.3749, 1.3432, 1.2952,
         1.5301, 1.5874, 1.5503, 1.5369, 1.5319, 1.5704, 1.5902, 1.4220, 1.5209,
         1.1305, 1.2470, 1.2195, 1.2689, 1.1241, 1.1315, 1.0646, 1.3302, 1.2097],
        [1.4591, 1.4590, 1.4573, 1.4545, 1.4549, 1.4591, 1.4548, 1.4591, 1.4591,
         1.4327, 1.4321, 1.4327, 1.4327, 1.4327, 1.4141, 1.4327, 1.4316, 1.4294,
         2.2057, 2.2059, 2.2226, 2.1981, 2.1797, 2.1779, 2.2070, 2.1770, 2.1770,
         1.5194, 1.5178, 1.5252, 1.5252, 1.5194, 1.5252, 1.5252, 1.5252, 1.5252,
         1.7746, 1.7747, 1.7747, 1.7716, 1.7746, 1.7746, 1.7747, 1.7521, 1.7548,
         1.4308, 1.4354, 1.4354, 1.4354, 1.4272, 1.4354, 1.4315, 1.4354, 1.4354],
        [1.3293, 1.3271, 1.3111, 1.3023, 1.3260, 1.3245, 1.3256, 1.3258, 1.3258,
         1.2991, 1.2924, 1.2886, 1.2882, 1.2999, 1.2844, 1.2955, 1.2995, 1.2718,
         1.6498, 1.6234, 1.6468, 1.6461, 1.6455, 1.6455, 1.6478, 1.6492, 1.6492,
         3.4885, 3.2798, 3.2057, 3.2636, 3.4136, 3.2326, 3.4638, 3.2134, 3.1923,
         1.6486, 1.6412, 1.6395, 1.6426, 1.6456, 1.6216, 1.6470, 1.5863, 1.6128,
         1.3006, 1.2951, 1.2852, 1.3000, 1.2955, 1.2876, 1.3000, 1.3003, 1.3021],
        [1.4619, 1.4575, 1.4137, 1.4173, 1.4550, 1.4618, 1.4602, 1.4619, 1.4619,
         1.4344, 1.4319, 1.4268, 1.4222, 1.4356, 1.3954, 1.4297, 1.4356, 1.4309,
         1.7617, 1.7530, 1.7520, 1.7600, 1.7775, 1.7761, 1.7562, 1.7776, 1.7776,
         1.4861, 1.4916, 1.5280, 1.5227, 1.4915, 1.5265, 1.5149, 1.5280, 1.5249,
         2.2000, 2.1802, 2.1689, 2.1866, 2.2300, 2.2483, 2.2147, 2.3171, 2.3144,
         1.4231, 1.4135, 1.4278, 1.4382, 1.4255, 1.4349, 1.4057, 1.4321, 1.4383],
        [1.3099, 1.2183, 1.2137, 1.2329, 1.2257, 1.2362, 1.2350, 1.1756, 1.1756,
         1.2345, 1.1954, 1.1943, 1.1984, 1.2713, 1.1488, 1.1172, 1.2713, 1.1799,
         1.5827, 1.5588, 1.5401, 1.5356, 1.5595, 1.5555, 1.5753, 1.5609, 1.5609,
         1.3263, 1.2991, 1.2997, 1.3160, 1.3011, 1.3438, 1.3463, 1.3203, 1.2998,
         1.5589, 1.5577, 1.5642, 1.5536, 1.5292, 1.5327, 1.5940, 1.4824, 1.4508,
         4.1364, 3.6483, 3.7386, 3.7219, 3.7357, 3.4176, 4.1326, 3.6957, 3.4505]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 340 : 1778.5209471819016
Test loss for epoch 340 : 196.1595698301814
Test Precision for epoch 340 : 0.26153846153846155
Test Recall for epoch 340 : 0.26153846153846155
Test F1 for epoch 340 : 0.26153846153846155


theta for epoch 341 : tensor([[3.6299, 3.6509, 3.7939, 3.7424, 3.7256, 3.6116, 3.6526, 3.5524, 3.5524,
         1.2556, 1.2356, 1.2343, 1.2373, 1.2733, 1.2165, 1.1883, 1.2733, 1.2221,
         1.6054, 1.5898, 1.6139, 1.5965, 1.6021, 1.6037, 1.6111, 1.6036, 1.6036,
         1.3428, 1.3541, 1.3402, 1.3616, 1.3424, 1.3728, 1.3657, 1.3529, 1.3402,
         1.5969, 1.6129, 1.6017, 1.5981, 1.6050, 1.5952, 1.6137, 1.5677, 1.5723,
         1.2290, 1.2547, 1.2465, 1.2640, 1.2239, 1.2153, 1.2072, 1.2852, 1.2433],
        [1.3699, 1.2174, 1.2070, 1.2503, 1.2505, 1.2630, 1.2569, 1.1613, 1.1613,
         3.5865, 3.6772, 3.5148, 3.9284, 3.5867, 4.3042, 3.4478, 3.5406, 4.0454,
         1.5711, 1.5585, 1.5325, 1.5306, 1.5520, 1.5615, 1.5863, 1.5615, 1.5615,
         1.3432, 1.3092, 1.3031, 1.3616, 1.3032, 1.3993, 1.3794, 1.3477, 1.2999,
         1.5376, 1.5947, 1.5577, 1.5444, 1.5393, 1.5778, 1.5975, 1.4295, 1.5283,
         1.1331, 1.2484, 1.2212, 1.2701, 1.1269, 1.1343, 1.0670, 1.3307, 1.2115],
        [1.4570, 1.4569, 1.4552, 1.4524, 1.4528, 1.4570, 1.4527, 1.4570, 1.4570,
         1.4289, 1.4283, 1.4289, 1.4289, 1.4289, 1.4103, 1.4289, 1.4278, 1.4255,
         2.2120, 2.2122, 2.2289, 2.2041, 2.1858, 2.1840, 2.2131, 2.1831, 2.1831,
         1.5196, 1.5180, 1.5254, 1.5254, 1.5196, 1.5254, 1.5253, 1.5254, 1.5254,
         1.7788, 1.7788, 1.7788, 1.7757, 1.7787, 1.7787, 1.7788, 1.7562, 1.7589,
         1.4272, 1.4318, 1.4318, 1.4318, 1.4235, 1.4318, 1.4278, 1.4317, 1.4318],
        [1.3264, 1.3243, 1.3084, 1.2996, 1.3233, 1.3217, 1.3228, 1.3232, 1.3232,
         1.2953, 1.2886, 1.2847, 1.2843, 1.2961, 1.2805, 1.2917, 1.2957, 1.2680,
         1.6564, 1.6300, 1.6534, 1.6527, 1.6521, 1.6521, 1.6544, 1.6558, 1.6558,
         3.4889, 3.2803, 3.2061, 3.2640, 3.4140, 3.2330, 3.4642, 3.2138, 3.1927,
         1.6527, 1.6453, 1.6437, 1.6467, 1.6497, 1.6257, 1.6511, 1.5905, 1.6170,
         1.2969, 1.2914, 1.2815, 1.2963, 1.2918, 1.2839, 1.2963, 1.2966, 1.2984],
        [1.4598, 1.4554, 1.4117, 1.4152, 1.4530, 1.4597, 1.4582, 1.4598, 1.4598,
         1.4306, 1.4281, 1.4230, 1.4184, 1.4318, 1.3916, 1.4259, 1.4318, 1.4271,
         1.7683, 1.7596, 1.7586, 1.7665, 1.7840, 1.7827, 1.7628, 1.7842, 1.7842,
         1.4862, 1.4917, 1.5281, 1.5229, 1.4916, 1.5267, 1.5151, 1.5282, 1.5251,
         2.2040, 2.1843, 2.1729, 2.1906, 2.2340, 2.2523, 2.2187, 2.3211, 2.3184,
         1.4195, 1.4098, 1.4242, 1.4346, 1.4218, 1.4313, 1.4021, 1.4285, 1.4346],
        [1.3249, 1.2338, 1.2291, 1.2482, 1.2411, 1.2516, 1.2504, 1.1912, 1.1912,
         1.2389, 1.2009, 1.1997, 1.2034, 1.2747, 1.1540, 1.1250, 1.2747, 1.1850,
         1.5983, 1.5745, 1.5559, 1.5513, 1.5751, 1.5711, 1.5910, 1.5765, 1.5765,
         1.3389, 1.3118, 1.3123, 1.3287, 1.3138, 1.3564, 1.3588, 1.3328, 1.3123,
         1.5712, 1.5702, 1.5765, 1.5659, 1.5417, 1.5452, 1.6064, 1.4951, 1.4637,
         4.1175, 3.6292, 3.7194, 3.7028, 3.7165, 3.3985, 4.1137, 3.6766, 3.4313]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 341 : 1779.5068764109396
Test loss for epoch 341 : 195.3081392848598
Test Precision for epoch 341 : 0.26153846153846155
Test Recall for epoch 341 : 0.26153846153846155
Test F1 for epoch 341 : 0.26153846153846155


theta for epoch 342 : tensor([[3.6270, 3.6479, 3.7910, 3.7395, 3.7227, 3.6087, 3.6496, 3.5494, 3.5494,
         1.2588, 1.2395, 1.2381, 1.2407, 1.2761, 1.2200, 1.1934, 1.2761, 1.2256,
         1.5985, 1.5830, 1.6070, 1.5897, 1.5953, 1.5969, 1.6042, 1.5969, 1.5969,
         1.3354, 1.3468, 1.3331, 1.3542, 1.3351, 1.3653, 1.3582, 1.3456, 1.3331,
         1.5980, 1.6139, 1.6028, 1.5992, 1.6061, 1.5962, 1.6146, 1.5688, 1.5733,
         1.2379, 1.2631, 1.2552, 1.2723, 1.2330, 1.2245, 1.2159, 1.2931, 1.2520],
        [1.3668, 1.2152, 1.2047, 1.2479, 1.2481, 1.2606, 1.2545, 1.1595, 1.1595,
         3.5881, 3.6789, 3.5163, 3.9304, 3.5884, 4.3068, 3.4493, 3.5423, 4.0475,
         1.5658, 1.5533, 1.5273, 1.5256, 1.5469, 1.5564, 1.5811, 1.5564, 1.5564,
         1.3386, 1.3047, 1.2988, 1.3569, 1.2987, 1.3945, 1.3747, 1.3432, 1.2956,
         1.5379, 1.5950, 1.5581, 1.5447, 1.5396, 1.5781, 1.5977, 1.4298, 1.5287,
         1.1379, 1.2528, 1.2257, 1.2745, 1.1319, 1.1394, 1.0711, 1.3347, 1.2161],
        [1.4510, 1.4509, 1.4492, 1.4464, 1.4469, 1.4510, 1.4467, 1.4510, 1.4510,
         1.4321, 1.4315, 1.4321, 1.4321, 1.4321, 1.4135, 1.4321, 1.4310, 1.4287,
         2.2055, 2.2058, 2.2225, 2.1980, 2.1796, 2.1778, 2.2069, 2.1769, 2.1769,
         1.5121, 1.5105, 1.5179, 1.5179, 1.5122, 1.5179, 1.5179, 1.5179, 1.5179,
         1.7797, 1.7798, 1.7798, 1.7766, 1.7797, 1.7797, 1.7798, 1.7572, 1.7599,
         1.4357, 1.4403, 1.4403, 1.4403, 1.4321, 1.4403, 1.4364, 1.4403, 1.4403],
        [1.3195, 1.3175, 1.3015, 1.2927, 1.3164, 1.3148, 1.3160, 1.3164, 1.3164,
         1.2984, 1.2917, 1.2879, 1.2875, 1.2992, 1.2837, 1.2949, 1.2988, 1.2711,
         1.6493, 1.6230, 1.6463, 1.6457, 1.6451, 1.6451, 1.6474, 1.6488, 1.6488,
         3.4831, 3.2743, 3.2001, 3.2581, 3.4081, 3.2271, 3.4584, 3.2079, 3.1868,
         1.6536, 1.6462, 1.6445, 1.6476, 1.6505, 1.6265, 1.6520, 1.5914, 1.6178,
         1.3053, 1.2998, 1.2899, 1.3047, 1.3003, 1.2924, 1.3047, 1.3050, 1.3068],
        [1.4538, 1.4495, 1.4059, 1.4093, 1.4470, 1.4537, 1.4522, 1.4538, 1.4538,
         1.4338, 1.4313, 1.4262, 1.4216, 1.4350, 1.3948, 1.4291, 1.4349, 1.4303,
         1.7615, 1.7528, 1.7518, 1.7598, 1.7773, 1.7759, 1.7560, 1.7774, 1.7774,
         1.4788, 1.4843, 1.5207, 1.5155, 1.4842, 1.5192, 1.5076, 1.5207, 1.5176,
         2.2049, 2.1852, 2.1739, 2.1915, 2.2349, 2.2532, 2.2196, 2.3220, 2.3192,
         1.4280, 1.4184, 1.4328, 1.4431, 1.4304, 1.4398, 1.4107, 1.4370, 1.4431],
        [1.3341, 1.2427, 1.2382, 1.2573, 1.2502, 1.2606, 1.2594, 1.2000, 1.2000,
         1.2477, 1.2102, 1.2090, 1.2124, 1.2831, 1.1629, 1.1354, 1.2831, 1.1939,
         1.5995, 1.5757, 1.5574, 1.5525, 1.5762, 1.5722, 1.5922, 1.5776, 1.5776,
         1.3423, 1.3154, 1.3155, 1.3322, 1.3172, 1.3600, 1.3623, 1.3363, 1.3155,
         1.5782, 1.5775, 1.5835, 1.5730, 1.5489, 1.5525, 1.6136, 1.5024, 1.4712,
         4.1081, 3.6195, 3.7097, 3.6931, 3.7068, 3.3887, 4.1043, 3.6670, 3.4216]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 342 : 1779.1183786551528
Test loss for epoch 342 : 195.19489632513148
Test Precision for epoch 342 : 0.26153846153846155
Test Recall for epoch 342 : 0.26153846153846155
Test F1 for epoch 342 : 0.26153846153846155


theta for epoch 343 : tensor([[3.6285, 3.6493, 3.7924, 3.7409, 3.7241, 3.6101, 3.6511, 3.5509, 3.5509,
         1.2630, 1.2440, 1.2426, 1.2450, 1.2800, 1.2242, 1.1987, 1.2800, 1.2298,
         1.5884, 1.5729, 1.5968, 1.5797, 1.5853, 1.5869, 1.5941, 1.5869, 1.5869,
         1.3307, 1.3421, 1.3286, 1.3495, 1.3305, 1.3604, 1.3535, 1.3409, 1.3287,
         1.5917, 1.6074, 1.5964, 1.5929, 1.5997, 1.5897, 1.6080, 1.5623, 1.5669,
         1.2498, 1.2745, 1.2667, 1.2836, 1.2449, 1.2365, 1.2273, 1.3041, 1.2636],
        [1.3598, 1.2088, 1.1982, 1.2414, 1.2417, 1.2541, 1.2480, 1.1536, 1.1536,
         3.5957, 3.6865, 3.5239, 3.9383, 3.5960, 4.3153, 3.4568, 3.5499, 4.0555,
         1.5545, 1.5420, 1.5160, 1.5143, 1.5357, 1.5451, 1.5698, 1.5452, 1.5452,
         1.3314, 1.2975, 1.2917, 1.3497, 1.2916, 1.3872, 1.3674, 1.3360, 1.2886,
         1.5288, 1.5858, 1.5489, 1.5356, 1.5304, 1.5688, 1.5884, 1.4205, 1.5195,
         1.1403, 1.2551, 1.2279, 1.2768, 1.1344, 1.1418, 1.0725, 1.3371, 1.2183],
        [1.4482, 1.4481, 1.4464, 1.4436, 1.4441, 1.4482, 1.4438, 1.4482, 1.4482,
         1.4366, 1.4359, 1.4365, 1.4365, 1.4366, 1.4179, 1.4365, 1.4354, 1.4332,
         2.1965, 2.1968, 2.2135, 2.1893, 2.1709, 2.1691, 2.1983, 2.1682, 2.1682,
         1.5079, 1.5063, 1.5137, 1.5137, 1.5079, 1.5137, 1.5136, 1.5137, 1.5137,
         1.7736, 1.7737, 1.7737, 1.7705, 1.7736, 1.7736, 1.7737, 1.7511, 1.7538,
         1.4478, 1.4523, 1.4523, 1.4523, 1.4441, 1.4523, 1.4484, 1.4523, 1.4523],
        [1.3157, 1.3138, 1.2979, 1.2891, 1.3127, 1.3111, 1.3123, 1.3128, 1.3128,
         1.3028, 1.2961, 1.2922, 1.2918, 1.3035, 1.2880, 1.2992, 1.3031, 1.2755,
         1.6395, 1.6132, 1.6365, 1.6358, 1.6352, 1.6353, 1.6375, 1.6389, 1.6389,
         3.4804, 3.2716, 3.1974, 3.2554, 3.4054, 3.2244, 3.4557, 3.2052, 3.1840,
         1.6473, 1.6399, 1.6383, 1.6413, 1.6443, 1.6203, 1.6457, 1.5851, 1.6116,
         1.3172, 1.3116, 1.3018, 1.3165, 1.3121, 1.3042, 1.3166, 1.3168, 1.3187],
        [1.4510, 1.4467, 1.4033, 1.4065, 1.4442, 1.4509, 1.4494, 1.4510, 1.4510,
         1.4382, 1.4357, 1.4307, 1.4261, 1.4394, 1.3993, 1.4335, 1.4394, 1.4347,
         1.7520, 1.7433, 1.7423, 1.7503, 1.7678, 1.7664, 1.7465, 1.7679, 1.7679,
         1.4745, 1.4801, 1.5164, 1.5112, 1.4799, 1.5150, 1.5033, 1.5165, 1.5134,
         2.1990, 2.1793, 2.1680, 2.1856, 2.2290, 2.2474, 2.2138, 2.3161, 2.3134,
         1.4401, 1.4304, 1.4448, 1.4551, 1.4425, 1.4518, 1.4228, 1.4491, 1.4551],
        [1.3417, 1.2498, 1.2453, 1.2644, 1.2574, 1.2678, 1.2666, 1.2067, 1.2067,
         1.2555, 1.2182, 1.2170, 1.2202, 1.2909, 1.1704, 1.1434, 1.2909, 1.2014,
         1.5959, 1.5721, 1.5539, 1.5487, 1.5723, 1.5684, 1.5885, 1.5737, 1.5737,
         1.3454, 1.3184, 1.3182, 1.3353, 1.3201, 1.3633, 1.3655, 1.3393, 1.3183,
         1.5765, 1.5760, 1.5817, 1.5713, 1.5474, 1.5511, 1.6121, 1.5010, 1.4699,
         4.1047, 3.6159, 3.7062, 3.6896, 3.7033, 3.3852, 4.1010, 3.6635, 3.4181]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 343 : 1779.180067180677
Test loss for epoch 343 : 195.52845019709787
Test Precision for epoch 343 : 0.26153846153846155
Test Recall for epoch 343 : 0.26153846153846155
Test F1 for epoch 343 : 0.26153846153846155


theta for epoch 344 : tensor([[3.6283, 3.6492, 3.7922, 3.7408, 3.7239, 3.6100, 3.6509, 3.5507, 3.5507,
         1.2610, 1.2427, 1.2414, 1.2434, 1.2774, 1.2228, 1.1992, 1.2774, 1.2285,
         1.5900, 1.5745, 1.5984, 1.5816, 1.5871, 1.5887, 1.5958, 1.5887, 1.5887,
         1.3368, 1.3482, 1.3349, 1.3555, 1.3367, 1.3663, 1.3594, 1.3471, 1.3350,
         1.5887, 1.6043, 1.5934, 1.5899, 1.5966, 1.5866, 1.6049, 1.5594, 1.5639,
         1.2507, 1.2750, 1.2674, 1.2840, 1.2460, 1.2377, 1.2279, 1.3042, 1.2644],
        [1.3690, 1.2186, 1.2080, 1.2511, 1.2514, 1.2639, 1.2578, 1.1638, 1.1638,
         3.5876, 3.6784, 3.5156, 3.9304, 3.5879, 4.3081, 3.4484, 3.5418, 4.0478,
         1.5612, 1.5487, 1.5227, 1.5213, 1.5425, 1.5520, 1.5765, 1.5520, 1.5520,
         1.3405, 1.3066, 1.3010, 1.3588, 1.3007, 1.3961, 1.3764, 1.3451, 1.2979,
         1.5319, 1.5886, 1.5520, 1.5386, 1.5335, 1.5717, 1.5912, 1.4240, 1.5226,
         1.1464, 1.2605, 1.2334, 1.2821, 1.1405, 1.1478, 1.0779, 1.3421, 1.2238],
        [1.4520, 1.4519, 1.4503, 1.4475, 1.4479, 1.4520, 1.4477, 1.4520, 1.4520,
         1.4341, 1.4334, 1.4340, 1.4340, 1.4341, 1.4154, 1.4341, 1.4329, 1.4307,
         2.1975, 2.1977, 2.2144, 2.1902, 2.1718, 2.1700, 2.1992, 2.1691, 2.1691,
         1.5129, 1.5113, 1.5187, 1.5187, 1.5129, 1.5187, 1.5187, 1.5187, 1.5187,
         1.7700, 1.7701, 1.7701, 1.7669, 1.7700, 1.7700, 1.7701, 1.7475, 1.7502,
         1.4478, 1.4523, 1.4523, 1.4523, 1.4441, 1.4523, 1.4485, 1.4523, 1.4523],
        [1.3186, 1.3169, 1.3011, 1.2922, 1.3159, 1.3142, 1.3154, 1.3160, 1.3160,
         1.3001, 1.2935, 1.2896, 1.2892, 1.3009, 1.2854, 1.2967, 1.3005, 1.2729,
         1.6402, 1.6139, 1.6372, 1.6366, 1.6360, 1.6360, 1.6383, 1.6397, 1.6397,
         3.4860, 3.2774, 3.2032, 3.2611, 3.4111, 3.2301, 3.4613, 3.2109, 3.1898,
         1.6436, 1.6362, 1.6345, 1.6376, 1.6405, 1.6165, 1.6420, 1.5813, 1.6078,
         1.3170, 1.3114, 1.3015, 1.3163, 1.3119, 1.3040, 1.3164, 1.3165, 1.3184],
        [1.4548, 1.4506, 1.4074, 1.4104, 1.4481, 1.4547, 1.4532, 1.4548, 1.4548,
         1.4357, 1.4332, 1.4282, 1.4236, 1.4369, 1.3969, 1.4310, 1.4369, 1.4323,
         1.7530, 1.7442, 1.7433, 1.7513, 1.7687, 1.7674, 1.7475, 1.7688, 1.7688,
         1.4795, 1.4852, 1.5214, 1.5163, 1.4849, 1.5200, 1.5083, 1.5215, 1.5184,
         2.1955, 2.1758, 2.1645, 2.1822, 2.2256, 2.2439, 2.2103, 2.3126, 2.3099,
         1.4402, 1.4304, 1.4448, 1.4551, 1.4425, 1.4519, 1.4230, 1.4491, 1.4552],
        [1.3538, 1.2615, 1.2571, 1.2762, 1.2692, 1.2796, 1.2784, 1.2182, 1.2182,
         1.2572, 1.2206, 1.2194, 1.2222, 1.2920, 1.1726, 1.1475, 1.2920, 1.2036,
         1.6016, 1.5778, 1.5598, 1.5544, 1.5779, 1.5740, 1.5943, 1.5794, 1.5794,
         1.3561, 1.3292, 1.3288, 1.3462, 1.3308, 1.3742, 1.3763, 1.3501, 1.3289,
         1.5773, 1.5770, 1.5825, 1.5721, 1.5483, 1.5521, 1.6130, 1.5020, 1.4710,
         4.0970, 3.6079, 3.6981, 3.6815, 3.6952, 3.3771, 4.0933, 3.6555, 3.4100]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 344 : 1779.4250096074352
Test loss for epoch 344 : 194.98807304281155
Test Precision for epoch 344 : 0.26153846153846155
Test Recall for epoch 344 : 0.26153846153846155
Test F1 for epoch 344 : 0.26153846153846155


theta for epoch 345 : tensor([[3.6265, 3.6473, 3.7903, 3.7389, 3.7220, 3.6081, 3.6491, 3.5488, 3.5488,
         1.2585, 1.2407, 1.2394, 1.2411, 1.2746, 1.2205, 1.1980, 1.2746, 1.2263,
         1.5994, 1.5839, 1.6078, 1.5910, 1.5965, 1.5981, 1.6051, 1.5981, 1.5981,
         1.3397, 1.3511, 1.3380, 1.3584, 1.3396, 1.3691, 1.3623, 1.3500, 1.3380,
         1.5914, 1.6069, 1.5962, 1.5926, 1.5993, 1.5893, 1.6075, 1.5621, 1.5667,
         1.2445, 1.2685, 1.2610, 1.2774, 1.2398, 1.2316, 1.2213, 1.2975, 1.2580],
        [1.3690, 1.2192, 1.2084, 1.2516, 1.2518, 1.2643, 1.2582, 1.1646, 1.1646,
         3.5857, 3.6766, 3.5137, 3.9289, 3.5861, 4.3072, 3.4464, 3.5400, 4.0465,
         1.5685, 1.5561, 1.5300, 1.5286, 1.5499, 1.5594, 1.5838, 1.5594, 1.5594,
         1.3430, 1.3092, 1.3037, 1.3614, 1.3034, 1.3987, 1.3789, 1.3477, 1.3006,
         1.5349, 1.5916, 1.5550, 1.5417, 1.5365, 1.5747, 1.5941, 1.4270, 1.5256,
         1.1430, 1.2565, 1.2295, 1.2781, 1.1372, 1.1444, 1.0738, 1.3379, 1.2199],
        [1.4486, 1.4485, 1.4469, 1.4441, 1.4446, 1.4486, 1.4443, 1.4486, 1.4486,
         1.4314, 1.4308, 1.4314, 1.4314, 1.4314, 1.4128, 1.4314, 1.4303, 1.4281,
         2.2060, 2.2062, 2.2229, 2.1984, 2.1801, 2.1782, 2.2074, 2.1774, 2.1774,
         1.5152, 1.5136, 1.5210, 1.5210, 1.5153, 1.5210, 1.5210, 1.5210, 1.5210,
         1.7725, 1.7726, 1.7726, 1.7694, 1.7725, 1.7725, 1.7726, 1.7500, 1.7527,
         1.4412, 1.4458, 1.4458, 1.4458, 1.4376, 1.4458, 1.4419, 1.4457, 1.4458],
        [1.3143, 1.3128, 1.2969, 1.2880, 1.3117, 1.3100, 1.3112, 1.3119, 1.3119,
         1.2973, 1.2907, 1.2869, 1.2864, 1.2980, 1.2826, 1.2940, 1.2976, 1.2701,
         1.6490, 1.6227, 1.6460, 1.6454, 1.6447, 1.6448, 1.6471, 1.6485, 1.6485,
         3.4895, 3.2809, 3.2067, 3.2646, 3.4145, 3.2336, 3.4648, 3.2144, 3.1933,
         1.6459, 1.6385, 1.6368, 1.6399, 1.6429, 1.6189, 1.6443, 1.5837, 1.6102,
         1.3101, 1.3045, 1.2946, 1.3093, 1.3050, 1.2972, 1.3095, 1.3096, 1.3115],
        [1.4515, 1.4473, 1.4042, 1.4071, 1.4447, 1.4514, 1.4499, 1.4514, 1.4514,
         1.4331, 1.4306, 1.4255, 1.4210, 1.4343, 1.3943, 1.4284, 1.4343, 1.4296,
         1.7619, 1.7532, 1.7523, 1.7602, 1.7776, 1.7763, 1.7564, 1.7777, 1.7777,
         1.4818, 1.4877, 1.5238, 1.5186, 1.4873, 1.5224, 1.5107, 1.5238, 1.5207,
         2.1979, 2.1782, 2.1670, 2.1846, 2.2279, 2.2463, 2.2127, 2.3149, 2.3122,
         1.4337, 1.4239, 1.4383, 1.4486, 1.4360, 1.4453, 1.4164, 1.4425, 1.4486],
        [1.3565, 1.2639, 1.2595, 1.2787, 1.2716, 1.2821, 1.2808, 1.2205, 1.2205,
         1.2566, 1.2203, 1.2191, 1.2217, 1.2911, 1.1720, 1.1480, 1.2911, 1.2031,
         1.6119, 1.5881, 1.5700, 1.5646, 1.5881, 1.5842, 1.6046, 1.5896, 1.5896,
         1.3615, 1.3345, 1.3340, 1.3515, 1.3361, 1.3796, 1.3817, 1.3554, 1.3340,
         1.5814, 1.5813, 1.5867, 1.5762, 1.5525, 1.5564, 1.6173, 1.5062, 1.4753,
         4.0917, 3.6023, 3.6925, 3.6759, 3.6897, 3.3714, 4.0880, 3.6500, 3.4043]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 345 : 1779.5141574894312
Test loss for epoch 345 : 194.67594222455
Test Precision for epoch 345 : 0.26153846153846155
Test Recall for epoch 345 : 0.26153846153846155
Test F1 for epoch 345 : 0.26153846153846155


theta for epoch 346 : tensor([[3.6271, 3.6480, 3.7910, 3.7396, 3.7226, 3.6087, 3.6497, 3.5495, 3.5495,
         1.2585, 1.2408, 1.2396, 1.2412, 1.2745, 1.2205, 1.1985, 1.2745, 1.2263,
         1.6021, 1.5867, 1.6106, 1.5938, 1.5993, 1.6010, 1.6079, 1.6009, 1.6009,
         1.3325, 1.3439, 1.3308, 1.3512, 1.3324, 1.3619, 1.3551, 1.3428, 1.3308,
         1.5963, 1.6118, 1.6011, 1.5975, 1.6042, 1.5942, 1.6124, 1.5670, 1.5716,
         1.2432, 1.2671, 1.2597, 1.2760, 1.2386, 1.2304, 1.2196, 1.2961, 1.2567],
        [1.3639, 1.2142, 1.2035, 1.2466, 1.2468, 1.2593, 1.2532, 1.1597, 1.1597,
         3.5904, 3.6813, 3.5183, 3.9338, 3.5908, 4.3129, 3.4509, 3.5446, 4.0516,
         1.5673, 1.5548, 1.5286, 1.5273, 1.5487, 1.5582, 1.5826, 1.5582, 1.5582,
         1.3358, 1.3020, 1.2966, 1.3541, 1.2962, 1.3914, 1.3717, 1.3405, 1.2934,
         1.5356, 1.5924, 1.5558, 1.5424, 1.5372, 1.5756, 1.5950, 1.4273, 1.5263,
         1.1385, 1.2518, 1.2248, 1.2735, 1.1327, 1.1397, 1.0684, 1.3334, 1.2152],
        [1.4459, 1.4459, 1.4443, 1.4415, 1.4419, 1.4459, 1.4416, 1.4459, 1.4459,
         1.4317, 1.4310, 1.4316, 1.4316, 1.4317, 1.4131, 1.4317, 1.4305, 1.4283,
         2.2088, 2.2090, 2.2257, 2.2011, 2.1828, 2.1809, 2.2101, 2.1801, 2.1801,
         1.5080, 1.5063, 1.5138, 1.5138, 1.5080, 1.5138, 1.5137, 1.5138, 1.5138,
         1.7775, 1.7776, 1.7776, 1.7744, 1.7775, 1.7775, 1.7776, 1.7550, 1.7577,
         1.4401, 1.4446, 1.4446, 1.4446, 1.4364, 1.4446, 1.4408, 1.4446, 1.4446],
        [1.3109, 1.3094, 1.2936, 1.2847, 1.3084, 1.3067, 1.3079, 1.3086, 1.3086,
         1.2974, 1.2908, 1.2870, 1.2865, 1.2981, 1.2827, 1.2941, 1.2977, 1.2702,
         1.6517, 1.6254, 1.6487, 1.6481, 1.6474, 1.6475, 1.6498, 1.6512, 1.6512,
         3.4843, 3.2757, 3.2015, 3.2594, 3.4093, 3.2284, 3.4597, 3.2092, 3.1881,
         1.6508, 1.6433, 1.6417, 1.6448, 1.6477, 1.6237, 1.6492, 1.5886, 1.6150,
         1.3087, 1.3031, 1.2932, 1.3079, 1.3036, 1.2958, 1.3081, 1.3081, 1.3101],
        [1.4488, 1.4447, 1.4017, 1.4045, 1.4421, 1.4487, 1.4472, 1.4488, 1.4488,
         1.4334, 1.4308, 1.4258, 1.4213, 1.4345, 1.3946, 1.4286, 1.4345, 1.4299,
         1.7648, 1.7561, 1.7552, 1.7632, 1.7805, 1.7792, 1.7593, 1.7806, 1.7806,
         1.4746, 1.4804, 1.5165, 1.5114, 1.4800, 1.5151, 1.5034, 1.5166, 1.5134,
         2.2028, 2.1831, 2.1719, 2.1895, 2.2328, 2.2512, 2.2176, 2.3197, 2.3170,
         1.4326, 1.4228, 1.4371, 1.4474, 1.4349, 1.4442, 1.4154, 1.4414, 1.4475],
        [1.3553, 1.2625, 1.2581, 1.2774, 1.2703, 1.2808, 1.2795, 1.2190, 1.2190,
         1.2565, 1.2203, 1.2191, 1.2216, 1.2912, 1.1717, 1.1480, 1.2912, 1.2028,
         1.6144, 1.5906, 1.5725, 1.5670, 1.5906, 1.5866, 1.6071, 1.5920, 1.5920,
         1.3557, 1.3288, 1.3282, 1.3458, 1.3303, 1.3739, 1.3760, 1.3496, 1.3283,
         1.5859, 1.5858, 1.5912, 1.5807, 1.5570, 1.5609, 1.6219, 1.5106, 1.4797,
         4.0928, 3.6031, 3.6934, 3.6768, 3.6905, 3.3723, 4.0891, 3.6509, 3.4051]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 346 : 1779.3805101215282
Test loss for epoch 346 : 194.91398759937348
Test Precision for epoch 346 : 0.26153846153846155
Test Recall for epoch 346 : 0.26153846153846155
Test F1 for epoch 346 : 0.26153846153846155


theta for epoch 347 : tensor([[3.6334, 3.6543, 3.7973, 3.7460, 3.7290, 3.6151, 3.6561, 3.5559, 3.5559,
         1.2587, 1.2409, 1.2397, 1.2412, 1.2748, 1.2204, 1.1982, 1.2749, 1.2262,
         1.5931, 1.5776, 1.6015, 1.5848, 1.5903, 1.5919, 1.5988, 1.5919, 1.5919,
         1.3300, 1.3415, 1.3283, 1.3488, 1.3299, 1.3595, 1.3526, 1.3403, 1.3284,
         1.5962, 1.6117, 1.6009, 1.5974, 1.6041, 1.5940, 1.6122, 1.5668, 1.5714,
         1.2475, 1.2715, 1.2640, 1.2803, 1.2429, 1.2347, 1.2235, 1.3004, 1.2611],
        [1.3569, 1.2067, 1.1960, 1.2392, 1.2394, 1.2520, 1.2459, 1.1521, 1.1521,
         3.6002, 3.6911, 3.5281, 3.9440, 3.6007, 4.3237, 3.4606, 3.5545, 4.0619,
         1.5544, 1.5419, 1.5157, 1.5143, 1.5358, 1.5453, 1.5697, 1.5453, 1.5453,
         1.3275, 1.2936, 1.2882, 1.3459, 1.2878, 1.3833, 1.3635, 1.3322, 1.2850,
         1.5290, 1.5860, 1.5493, 1.5358, 1.5306, 1.5691, 1.5886, 1.4203, 1.5196,
         1.1338, 1.2475, 1.2203, 1.2693, 1.1281, 1.1349, 1.0626, 1.3297, 1.2106],
        [1.4494, 1.4494, 1.4478, 1.4450, 1.4454, 1.4494, 1.4451, 1.4494, 1.4494,
         1.4325, 1.4319, 1.4325, 1.4325, 1.4325, 1.4139, 1.4325, 1.4314, 1.4292,
         2.2009, 2.2011, 2.2178, 2.1935, 2.1752, 2.1733, 2.2025, 2.1725, 2.1725,
         1.5060, 1.5043, 1.5118, 1.5118, 1.5060, 1.5118, 1.5117, 1.5118, 1.5118,
         1.7779, 1.7779, 1.7779, 1.7748, 1.7778, 1.7778, 1.7779, 1.7554, 1.7581,
         1.4450, 1.4495, 1.4495, 1.4495, 1.4414, 1.4495, 1.4457, 1.4495, 1.4495],
        [1.3139, 1.3125, 1.2967, 1.2878, 1.3114, 1.3097, 1.3109, 1.3117, 1.3117,
         1.2981, 1.2915, 1.2876, 1.2872, 1.2988, 1.2834, 1.2948, 1.2984, 1.2709,
         1.6429, 1.6167, 1.6400, 1.6394, 1.6387, 1.6388, 1.6410, 1.6425, 1.6425,
         3.4839, 3.2753, 3.2011, 3.2590, 3.4089, 3.2280, 3.4593, 3.2088, 3.1877,
         1.6510, 1.6435, 1.6419, 1.6450, 1.6479, 1.6239, 1.6493, 1.5888, 1.6152,
         1.3134, 1.3077, 1.2979, 1.3125, 1.3083, 1.3005, 1.3127, 1.3127, 1.3148],
        [1.4523, 1.4483, 1.4054, 1.4081, 1.4456, 1.4522, 1.4507, 1.4523, 1.4523,
         1.4342, 1.4317, 1.4267, 1.4221, 1.4354, 1.3955, 1.4295, 1.4353, 1.4307,
         1.7565, 1.7478, 1.7469, 1.7548, 1.7722, 1.7709, 1.7510, 1.7723, 1.7723,
         1.4726, 1.4785, 1.5145, 1.5094, 1.4781, 1.5131, 1.5014, 1.5146, 1.5114,
         2.2032, 2.1835, 2.1723, 2.1898, 2.2331, 2.2516, 2.2180, 2.3200, 2.3173,
         1.4375, 1.4277, 1.4420, 1.4523, 1.4398, 1.4491, 1.4204, 1.4463, 1.4524],
        [1.3542, 1.2615, 1.2570, 1.2763, 1.2692, 1.2797, 1.2784, 1.2180, 1.2180,
         1.2552, 1.2187, 1.2174, 1.2199, 1.2902, 1.1697, 1.1456, 1.2902, 1.2008,
         1.6047, 1.5808, 1.5628, 1.5572, 1.5809, 1.5769, 1.5974, 1.5823, 1.5823,
         1.3514, 1.3245, 1.3240, 1.3415, 1.3261, 1.3696, 1.3717, 1.3454, 1.3240,
         1.5842, 1.5841, 1.5895, 1.5790, 1.5552, 1.5591, 1.6202, 1.5088, 1.4778,
         4.1001, 3.6102, 3.7005, 3.6839, 3.6976, 3.3793, 4.0965, 3.6580, 3.4122]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 347 : 1778.813237596685
Test loss for epoch 347 : 195.466620325501
Test Precision for epoch 347 : 0.26153846153846155
Test Recall for epoch 347 : 0.26153846153846155
Test F1 for epoch 347 : 0.26153846153846155


theta for epoch 348 : tensor([[3.6315, 3.6524, 3.7954, 3.7440, 3.7270, 3.6132, 3.6541, 3.5540, 3.5540,
         1.2568, 1.2393, 1.2380, 1.2394, 1.2727, 1.2187, 1.1971, 1.2727, 1.2245,
         1.5906, 1.5751, 1.5990, 1.5823, 1.5878, 1.5894, 1.5963, 1.5894, 1.5894,
         1.3385, 1.3500, 1.3368, 1.3573, 1.3384, 1.3680, 1.3612, 1.3489, 1.3368,
         1.5935, 1.6089, 1.5982, 1.5946, 1.6014, 1.5913, 1.6094, 1.5640, 1.5686,
         1.2514, 1.2753, 1.2679, 1.2842, 1.2467, 1.2386, 1.2271, 1.3043, 1.2650],
        [1.3670, 1.2166, 1.2059, 1.2491, 1.2494, 1.2619, 1.2558, 1.1618, 1.1618,
         3.5903, 3.6813, 3.5181, 3.9344, 3.5908, 4.3148, 3.4506, 3.5446, 4.0525,
         1.5597, 1.5472, 1.5211, 1.5197, 1.5410, 1.5505, 1.5750, 1.5506, 1.5506,
         1.3394, 1.3054, 1.2999, 1.3577, 1.2996, 1.3952, 1.3754, 1.3440, 1.2968,
         1.5335, 1.5904, 1.5537, 1.5403, 1.5351, 1.5735, 1.5929, 1.4252, 1.5242,
         1.1435, 1.2571, 1.2298, 1.2790, 1.1377, 1.1443, 1.0714, 1.3395, 1.2201],
        [1.4508, 1.4508, 1.4492, 1.4464, 1.4468, 1.4508, 1.4465, 1.4508, 1.4508,
         1.4301, 1.4295, 1.4301, 1.4301, 1.4301, 1.4115, 1.4301, 1.4290, 1.4268,
         2.1979, 2.1981, 2.2148, 2.1906, 2.1723, 2.1704, 2.1996, 2.1696, 2.1696,
         1.5131, 1.5115, 1.5189, 1.5189, 1.5131, 1.5189, 1.5189, 1.5189, 1.5189,
         1.7746, 1.7747, 1.7747, 1.7716, 1.7746, 1.7746, 1.7747, 1.7521, 1.7548,
         1.4479, 1.4524, 1.4524, 1.4524, 1.4442, 1.4524, 1.4486, 1.4524, 1.4524],
        [1.3149, 1.3136, 1.2978, 1.2889, 1.3125, 1.3108, 1.3120, 1.3128, 1.3128,
         1.2955, 1.2889, 1.2851, 1.2846, 1.2962, 1.2809, 1.2923, 1.2958, 1.2683,
         1.6395, 1.6132, 1.6365, 1.6359, 1.6353, 1.6353, 1.6376, 1.6390, 1.6390,
         3.4916, 3.2830, 3.2089, 3.2667, 3.4166, 3.2358, 3.4670, 3.2166, 3.1955,
         1.6475, 1.6401, 1.6384, 1.6415, 1.6445, 1.6204, 1.6459, 1.5853, 1.6118,
         1.3160, 1.3104, 1.3005, 1.3152, 1.3110, 1.3031, 1.3154, 1.3153, 1.3174],
        [1.4537, 1.4497, 1.4070, 1.4096, 1.4471, 1.4536, 1.4522, 1.4537, 1.4537,
         1.4318, 1.4293, 1.4243, 1.4197, 1.4330, 1.3931, 1.4271, 1.4329, 1.4284,
         1.7533, 1.7446, 1.7438, 1.7517, 1.7690, 1.7677, 1.7479, 1.7692, 1.7692,
         1.4797, 1.4858, 1.5216, 1.5165, 1.4852, 1.5203, 1.5085, 1.5217, 1.5186,
         2.2000, 2.1804, 2.1691, 2.1867, 2.2300, 2.2484, 2.2148, 2.3168, 2.3141,
         1.4404, 1.4306, 1.4449, 1.4552, 1.4428, 1.4520, 1.4233, 1.4492, 1.4552],
        [1.3521, 1.2599, 1.2553, 1.2746, 1.2675, 1.2780, 1.2768, 1.2168, 1.2168,
         1.2514, 1.2153, 1.2140, 1.2163, 1.2862, 1.1661, 1.1429, 1.2862, 1.1973,
         1.6003, 1.5764, 1.5584, 1.5529, 1.5765, 1.5726, 1.5929, 1.5780, 1.5780,
         1.3554, 1.3284, 1.3281, 1.3453, 1.3300, 1.3734, 1.3755, 1.3493, 1.3282,
         1.5798, 1.5796, 1.5851, 1.5746, 1.5508, 1.5546, 1.6158, 1.5043, 1.4733,
         4.1054, 3.6152, 3.7055, 3.6889, 3.7027, 3.3844, 4.1018, 3.6631, 3.4173]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 348 : 1779.2308115065882
Test loss for epoch 348 : 195.02130900640313
Test Precision for epoch 348 : 0.26153846153846155
Test Recall for epoch 348 : 0.26153846153846155
Test F1 for epoch 348 : 0.26153846153846155


theta for epoch 349 : tensor([[3.6302, 3.6511, 3.7942, 3.7428, 3.7257, 3.6119, 3.6529, 3.5527, 3.5527,
         1.2582, 1.2407, 1.2394, 1.2408, 1.2741, 1.2201, 1.1984, 1.2741, 1.2259,
         1.5967, 1.5812, 1.6051, 1.5884, 1.5938, 1.5955, 1.6024, 1.5954, 1.5954,
         1.3411, 1.3525, 1.3393, 1.3599, 1.3409, 1.3707, 1.3638, 1.3514, 1.3393,
         1.5920, 1.6075, 1.5968, 1.5932, 1.5999, 1.5898, 1.6080, 1.5626, 1.5672,
         1.2464, 1.2704, 1.2630, 1.2792, 1.2417, 1.2335, 1.2217, 1.2996, 1.2600],
        [1.3694, 1.2188, 1.2081, 1.2513, 1.2515, 1.2641, 1.2580, 1.1638, 1.1638,
         3.5880, 3.6790, 3.5157, 3.9324, 3.5885, 4.3134, 3.4481, 3.5423, 4.0507,
         1.5660, 1.5535, 1.5274, 1.5260, 1.5473, 1.5568, 1.5813, 1.5568, 1.5568,
         1.3431, 1.3091, 1.3036, 1.3615, 1.3033, 1.3990, 1.3792, 1.3478, 1.3004,
         1.5345, 1.5913, 1.5547, 1.5412, 1.5361, 1.5744, 1.5939, 1.4263, 1.5251,
         1.1425, 1.2560, 1.2287, 1.2779, 1.1367, 1.1431, 1.0697, 1.3388, 1.2189],
        [1.4489, 1.4489, 1.4473, 1.4445, 1.4449, 1.4489, 1.4446, 1.4489, 1.4489,
         1.4314, 1.4308, 1.4314, 1.4314, 1.4314, 1.4128, 1.4314, 1.4303, 1.4281,
         2.2033, 2.2035, 2.2202, 2.1958, 2.1775, 2.1757, 2.2048, 2.1748, 2.1748,
         1.5150, 1.5133, 1.5207, 1.5207, 1.5150, 1.5207, 1.5207, 1.5207, 1.5207,
         1.7730, 1.7731, 1.7731, 1.7700, 1.7730, 1.7730, 1.7731, 1.7506, 1.7533,
         1.4425, 1.4470, 1.4470, 1.4470, 1.4389, 1.4470, 1.4432, 1.4470, 1.4470],
        [1.3126, 1.3114, 1.2956, 1.2867, 1.3103, 1.3086, 1.3098, 1.3107, 1.3107,
         1.2966, 1.2901, 1.2862, 1.2858, 1.2973, 1.2820, 1.2934, 1.2969, 1.2695,
         1.6449, 1.6187, 1.6420, 1.6414, 1.6407, 1.6408, 1.6430, 1.6445, 1.6445,
         3.4946, 3.2861, 3.2120, 3.2698, 3.4197, 3.2388, 3.4700, 3.2197, 3.1986,
         1.6457, 1.6383, 1.6367, 1.6398, 1.6427, 1.6187, 1.6441, 1.5835, 1.6100,
         1.3104, 1.3047, 1.2949, 1.3095, 1.3053, 1.2975, 1.3098, 1.3096, 1.3118],
        [1.4518, 1.4478, 1.4052, 1.4077, 1.4452, 1.4517, 1.4502, 1.4517, 1.4517,
         1.4331, 1.4306, 1.4256, 1.4211, 1.4343, 1.3945, 1.4284, 1.4342, 1.4297,
         1.7590, 1.7502, 1.7494, 1.7574, 1.7746, 1.7733, 1.7535, 1.7748, 1.7748,
         1.4816, 1.4877, 1.5235, 1.5184, 1.4871, 1.5221, 1.5103, 1.5235, 1.5204,
         2.1984, 2.1788, 2.1676, 2.1851, 2.2284, 2.2469, 2.2133, 2.3152, 2.3125,
         1.4351, 1.4252, 1.4396, 1.4498, 1.4374, 1.4466, 1.4180, 1.4438, 1.4499],
        [1.3445, 1.2528, 1.2482, 1.2675, 1.2604, 1.2709, 1.2696, 1.2100, 1.2100,
         1.2495, 1.2133, 1.2120, 1.2143, 1.2845, 1.1640, 1.1407, 1.2845, 1.1952,
         1.6018, 1.5779, 1.5597, 1.5544, 1.5782, 1.5742, 1.5944, 1.5796, 1.5796,
         1.3525, 1.3255, 1.3255, 1.3425, 1.3273, 1.3704, 1.3727, 1.3465, 1.3256,
         1.5753, 1.5750, 1.5806, 1.5701, 1.5462, 1.5500, 1.6112, 1.4996, 1.4685,
         4.1113, 3.6209, 3.7112, 3.6946, 3.7084, 3.3901, 4.1078, 3.6688, 3.4229]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 349 : 1779.152263170415
Test loss for epoch 349 : 194.945591400132
Test Precision for epoch 349 : 0.26153846153846155
Test Recall for epoch 349 : 0.26153846153846155
Test F1 for epoch 349 : 0.26153846153846155


theta for epoch 350 : tensor([[3.6332, 3.6541, 3.7972, 3.7458, 3.7287, 3.6149, 3.6559, 3.5557, 3.5557,
         1.2621, 1.2444, 1.2432, 1.2446, 1.2782, 1.2239, 1.2017, 1.2782, 1.2296,
         1.6029, 1.5874, 1.6114, 1.5946, 1.6001, 1.6017, 1.6086, 1.6017, 1.6017,
         1.3332, 1.3447, 1.3314, 1.3521, 1.3330, 1.3629, 1.3560, 1.3436, 1.3314,
         1.5936, 1.6091, 1.5983, 1.5948, 1.6015, 1.5914, 1.6096, 1.5641, 1.5687,
         1.2387, 1.2629, 1.2554, 1.2718, 1.2339, 1.2258, 1.2138, 1.2923, 1.2525],
        [1.3675, 1.2164, 1.2057, 1.2491, 1.2493, 1.2618, 1.2557, 1.1613, 1.1613,
         3.5924, 3.6834, 3.5201, 3.9371, 3.5930, 4.3188, 3.4524, 3.5468, 4.0556,
         1.5682, 1.5556, 1.5295, 1.5280, 1.5494, 1.5589, 1.5835, 1.5589, 1.5589,
         1.3367, 1.3028, 1.2971, 1.3551, 1.2969, 1.3927, 1.3728, 1.3414, 1.2940,
         1.5336, 1.5906, 1.5538, 1.5404, 1.5352, 1.5737, 1.5932, 1.4253, 1.5242,
         1.1352, 1.2488, 1.2213, 1.2708, 1.1294, 1.1355, 1.0615, 1.3319, 1.2115],
        [1.4504, 1.4503, 1.4487, 1.4459, 1.4464, 1.4504, 1.4460, 1.4504, 1.4504,
         1.4356, 1.4349, 1.4356, 1.4355, 1.4356, 1.4170, 1.4356, 1.4345, 1.4322,
         2.2093, 2.2095, 2.2261, 2.2016, 2.1833, 2.1815, 2.2106, 2.1806, 2.1806,
         1.5070, 1.5053, 1.5128, 1.5128, 1.5070, 1.5128, 1.5127, 1.5128, 1.5128,
         1.7748, 1.7749, 1.7748, 1.7717, 1.7747, 1.7747, 1.7748, 1.7523, 1.7550,
         1.4352, 1.4396, 1.4396, 1.4396, 1.4315, 1.4396, 1.4359, 1.4396, 1.4396],
        [1.3140, 1.3128, 1.2970, 1.2881, 1.3117, 1.3100, 1.3111, 1.3121, 1.3121,
         1.3007, 1.2941, 1.2902, 1.2898, 1.3013, 1.2861, 1.2975, 1.3009, 1.2735,
         1.6511, 1.6249, 1.6481, 1.6475, 1.6469, 1.6469, 1.6492, 1.6506, 1.6506,
         3.4889, 3.2803, 3.2061, 3.2640, 3.4139, 3.2330, 3.4643, 3.2139, 3.1928,
         1.6473, 1.6399, 1.6383, 1.6414, 1.6443, 1.6203, 1.6457, 1.5852, 1.6116,
         1.3027, 1.2970, 1.2872, 1.3018, 1.2977, 1.2899, 1.3021, 1.3019, 1.3041],
        [1.4532, 1.4493, 1.4067, 1.4093, 1.4467, 1.4531, 1.4517, 1.4532, 1.4532,
         1.4373, 1.4347, 1.4298, 1.4253, 1.4384, 1.3987, 1.4326, 1.4384, 1.4339,
         1.7653, 1.7565, 1.7557, 1.7637, 1.7809, 1.7796, 1.7598, 1.7810, 1.7810,
         1.4736, 1.4797, 1.5155, 1.5104, 1.4791, 1.5141, 1.5023, 1.5156, 1.5124,
         2.2001, 2.1806, 2.1693, 2.1868, 2.2301, 2.2486, 2.2150, 2.3168, 2.3142,
         1.4277, 1.4178, 1.4322, 1.4424, 1.4300, 1.4392, 1.4107, 1.4364, 1.4425],
        [1.3370, 1.2454, 1.2407, 1.2600, 1.2529, 1.2634, 1.2622, 1.2027, 1.2027,
         1.2490, 1.2123, 1.2110, 1.2134, 1.2844, 1.1627, 1.1386, 1.2844, 1.1940,
         1.6023, 1.5783, 1.5601, 1.5548, 1.5787, 1.5747, 1.5950, 1.5802, 1.5802,
         1.3397, 1.3127, 1.3128, 1.3296, 1.3145, 1.3575, 1.3598, 1.3337, 1.3129,
         1.5725, 1.5721, 1.5778, 1.5672, 1.5433, 1.5471, 1.6084, 1.4966, 1.4653,
         4.1196, 3.6289, 3.7192, 3.7026, 3.7164, 3.3981, 4.1161, 3.6768, 3.4309]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 350 : 1778.9118742770843
Test loss for epoch 350 : 195.3222205425339
Test Precision for epoch 350 : 0.26153846153846155
Test Recall for epoch 350 : 0.26153846153846155
Test F1 for epoch 350 : 0.26153846153846155


theta for epoch 351 : tensor([[3.6326, 3.6535, 3.7967, 3.7453, 3.7282, 3.6143, 3.6553, 3.5551, 3.5551,
         1.2636, 1.2461, 1.2448, 1.2462, 1.2795, 1.2256, 1.2037, 1.2795, 1.2314,
         1.6001, 1.5845, 1.6085, 1.5917, 1.5972, 1.5988, 1.6057, 1.5988, 1.5988,
         1.3339, 1.3454, 1.3320, 1.3528, 1.3337, 1.3637, 1.3568, 1.3443, 1.3320,
         1.5970, 1.6125, 1.6017, 1.5981, 1.6049, 1.5948, 1.6130, 1.5675, 1.5721,
         1.2368, 1.2613, 1.2538, 1.2702, 1.2320, 1.2238, 1.2116, 1.2910, 1.2508],
        [1.3737, 1.2225, 1.2118, 1.2551, 1.2554, 1.2679, 1.2618, 1.1673, 1.1673,
         3.5877, 3.6788, 3.5153, 3.9327, 3.5883, 4.3150, 3.4475, 3.5421, 4.0513,
         1.5700, 1.5575, 1.5314, 1.5299, 1.5512, 1.5607, 1.5853, 1.5607, 1.5607,
         1.3410, 1.3071, 1.3015, 1.3594, 1.3013, 1.3969, 1.3771, 1.3457, 1.2983,
         1.5398, 1.5968, 1.5600, 1.5466, 1.5414, 1.5799, 1.5993, 1.4316, 1.5304,
         1.1378, 1.2514, 1.2238, 1.2735, 1.1318, 1.1377, 1.0634, 1.3350, 1.2140],
        [1.4528, 1.4527, 1.4511, 1.4483, 1.4488, 1.4528, 1.4485, 1.4528, 1.4528,
         1.4366, 1.4360, 1.4366, 1.4366, 1.4366, 1.4181, 1.4366, 1.4355, 1.4333,
         2.2061, 2.2062, 2.2229, 2.1985, 2.1802, 2.1783, 2.2075, 2.1775, 2.1775,
         1.5066, 1.5049, 1.5123, 1.5123, 1.5066, 1.5123, 1.5123, 1.5123, 1.5123,
         1.7777, 1.7777, 1.7777, 1.7746, 1.7776, 1.7776, 1.7777, 1.7553, 1.7580,
         1.4328, 1.4373, 1.4373, 1.4373, 1.4292, 1.4373, 1.4336, 1.4373, 1.4373],
        [1.3165, 1.3153, 1.2995, 1.2907, 1.3142, 1.3125, 1.3136, 1.3146, 1.3146,
         1.3016, 1.2950, 1.2912, 1.2907, 1.3022, 1.2870, 1.2984, 1.3018, 1.2745,
         1.6474, 1.6212, 1.6444, 1.6439, 1.6432, 1.6433, 1.6455, 1.6469, 1.6469,
         3.4898, 3.2812, 3.2071, 3.2649, 3.4148, 3.2340, 3.4652, 3.2148, 3.1937,
         1.6501, 1.6426, 1.6410, 1.6441, 1.6470, 1.6230, 1.6485, 1.5879, 1.6144,
         1.3002, 1.2945, 1.2846, 1.2992, 1.2951, 1.2873, 1.2996, 1.2994, 1.3016],
        [1.4556, 1.4517, 1.4092, 1.4117, 1.4491, 1.4555, 1.4541, 1.4556, 1.4556,
         1.4383, 1.4358, 1.4308, 1.4263, 1.4395, 1.3998, 1.4336, 1.4394, 1.4349,
         1.7619, 1.7531, 1.7523, 1.7602, 1.7775, 1.7762, 1.7564, 1.7776, 1.7776,
         1.4732, 1.4794, 1.5151, 1.5100, 1.4788, 1.5137, 1.5019, 1.5151, 1.5120,
         2.2029, 2.1834, 2.1722, 2.1896, 2.2329, 2.2514, 2.2178, 2.3195, 2.3169,
         1.4254, 1.4155, 1.4299, 1.4401, 1.4278, 1.4369, 1.4084, 1.4341, 1.4402],
        [1.3321, 1.2404, 1.2356, 1.2550, 1.2479, 1.2585, 1.2572, 1.1976, 1.1976,
         1.2465, 1.2100, 1.2087, 1.2110, 1.2818, 1.1604, 1.1368, 1.2819, 1.1918,
         1.5953, 1.5713, 1.5529, 1.5477, 1.5717, 1.5676, 1.5879, 1.5731, 1.5731,
         1.3345, 1.3074, 1.3077, 1.3244, 1.3093, 1.3523, 1.3546, 1.3286, 1.3078,
         1.5716, 1.5712, 1.5769, 1.5664, 1.5423, 1.5461, 1.6076, 1.4955, 1.4641,
         4.1277, 3.6367, 3.7270, 3.7104, 3.7243, 3.4059, 4.1243, 3.6846, 3.4387]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 351 : 1778.9606965477276
Test loss for epoch 351 : 195.41149723058447
Test Precision for epoch 351 : 0.26153846153846155
Test Recall for epoch 351 : 0.26153846153846155
Test F1 for epoch 351 : 0.26153846153846155


theta for epoch 352 : tensor([[3.6329, 3.6538, 3.7971, 3.7457, 3.7285, 3.6146, 3.6557, 3.5554, 3.5554,
         1.2625, 1.2451, 1.2439, 1.2452, 1.2784, 1.2247, 1.2029, 1.2784, 1.2305,
         1.5941, 1.5786, 1.6026, 1.5857, 1.5912, 1.5928, 1.5998, 1.5928, 1.5928,
         1.3409, 1.3524, 1.3389, 1.3599, 1.3406, 1.3708, 1.3638, 1.3513, 1.3390,
         1.5969, 1.6125, 1.6017, 1.5981, 1.6049, 1.5948, 1.6130, 1.5674, 1.5721,
         1.2385, 1.2633, 1.2558, 1.2724, 1.2337, 1.2254, 1.2132, 1.2935, 1.2527],
        [1.3721, 1.2211, 1.2104, 1.2537, 1.2539, 1.2665, 1.2604, 1.1660, 1.1660,
         3.5888, 3.6799, 3.5163, 3.9341, 3.5895, 4.3171, 3.4485, 3.5432, 4.0529,
         1.5652, 1.5527, 1.5266, 1.5251, 1.5465, 1.5560, 1.5805, 1.5560, 1.5560,
         1.3440, 1.3100, 1.3044, 1.3624, 1.3042, 1.3999, 1.3801, 1.3487, 1.3013,
         1.5391, 1.5961, 1.5593, 1.5459, 1.5407, 1.5792, 1.5986, 1.4308, 1.5297,
         1.1376, 1.2517, 1.2239, 1.2739, 1.1316, 1.1372, 1.0624, 1.3359, 1.2140],
        [1.4517, 1.4516, 1.4500, 1.4472, 1.4477, 1.4517, 1.4474, 1.4517, 1.4517,
         1.4355, 1.4349, 1.4355, 1.4355, 1.4355, 1.4170, 1.4355, 1.4344, 1.4322,
         2.2004, 2.2006, 2.2173, 2.1931, 2.1748, 2.1729, 2.2021, 2.1721, 2.1721,
         1.5132, 1.5116, 1.5190, 1.5190, 1.5132, 1.5190, 1.5190, 1.5190, 1.5190,
         1.7776, 1.7777, 1.7777, 1.7746, 1.7776, 1.7776, 1.7777, 1.7552, 1.7579,
         1.4349, 1.4394, 1.4394, 1.4394, 1.4313, 1.4394, 1.4357, 1.4394, 1.4394],
        [1.3155, 1.3143, 1.2985, 1.2897, 1.3131, 1.3115, 1.3126, 1.3136, 1.3136,
         1.3003, 1.2937, 1.2899, 1.2894, 1.3009, 1.2857, 1.2972, 1.3005, 1.2732,
         1.6411, 1.6150, 1.6382, 1.6376, 1.6370, 1.6370, 1.6392, 1.6407, 1.6407,
         3.4972, 3.2886, 3.2145, 3.2723, 3.4222, 3.2414, 3.4726, 3.2222, 3.2012,
         1.6499, 1.6424, 1.6408, 1.6439, 1.6469, 1.6228, 1.6483, 1.5877, 1.6142,
         1.3021, 1.2963, 1.2865, 1.3011, 1.2970, 1.2892, 1.3014, 1.3012, 1.3034],
        [1.4545, 1.4506, 1.4081, 1.4106, 1.4480, 1.4544, 1.4530, 1.4545, 1.4545,
         1.4372, 1.4347, 1.4297, 1.4252, 1.4384, 1.3988, 1.4325, 1.4383, 1.4338,
         1.7559, 1.7472, 1.7464, 1.7543, 1.7715, 1.7703, 1.7505, 1.7717, 1.7717,
         1.4799, 1.4861, 1.5217, 1.5167, 1.4855, 1.5204, 1.5086, 1.5218, 1.5187,
         2.2029, 2.1834, 2.1722, 2.1896, 2.2328, 2.2514, 2.2178, 2.3194, 2.3168,
         1.4276, 1.4176, 1.4320, 1.4422, 1.4299, 1.4390, 1.4106, 1.4362, 1.4422],
        [1.3237, 1.2312, 1.2264, 1.2460, 1.2388, 1.2494, 1.2481, 1.1880, 1.1880,
         1.2412, 1.2045, 1.2032, 1.2055, 1.2768, 1.1548, 1.1307, 1.2768, 1.1863,
         1.5848, 1.5607, 1.5424, 1.5371, 1.5611, 1.5571, 1.5774, 1.5626, 1.5626,
         1.3338, 1.3065, 1.3068, 1.3236, 1.3084, 1.3517, 1.3540, 1.3278, 1.3068,
         1.5669, 1.5665, 1.5722, 1.5616, 1.5376, 1.5414, 1.6031, 1.4905, 1.4591,
         4.1399, 3.6485, 3.7389, 3.7223, 3.7362, 3.4178, 4.1365, 3.6965, 3.4505]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 352 : 1778.7901857489544
Test loss for epoch 352 : 195.72057926779863
Test Precision for epoch 352 : 0.26153846153846155
Test Recall for epoch 352 : 0.26153846153846155
Test F1 for epoch 352 : 0.26153846153846155


theta for epoch 353 : tensor([[3.6272, 3.6480, 3.7913, 3.7399, 3.7227, 3.6088, 3.6498, 3.5495, 3.5495,
         1.2624, 1.2454, 1.2442, 1.2455, 1.2780, 1.2253, 1.2041, 1.2780, 1.2311,
         1.5972, 1.5817, 1.6058, 1.5889, 1.5943, 1.5960, 1.6029, 1.5959, 1.5959,
         1.3449, 1.3563, 1.3429, 1.3638, 1.3446, 1.3748, 1.3678, 1.3553, 1.3429,
         1.5967, 1.6122, 1.6014, 1.5978, 1.6046, 1.5945, 1.6127, 1.5672, 1.5718,
         1.2404, 1.2649, 1.2575, 1.2739, 1.2356, 1.2275, 1.2153, 1.2947, 1.2545],
        [1.3773, 1.2272, 1.2164, 1.2596, 1.2598, 1.2724, 1.2663, 1.1724, 1.1724,
         3.5839, 3.6750, 3.5113, 3.9295, 3.5846, 4.3131, 3.4433, 3.5384, 4.0484,
         1.5701, 1.5577, 1.5315, 1.5303, 1.5516, 1.5611, 1.5854, 1.5611, 1.5611,
         1.3489, 1.3149, 1.3096, 1.3672, 1.3092, 1.4046, 1.3849, 1.3536, 1.3064,
         1.5417, 1.5985, 1.5619, 1.5485, 1.5433, 1.5816, 1.6009, 1.4336, 1.5323,
         1.1423, 1.2553, 1.2279, 1.2772, 1.1365, 1.1424, 1.0671, 1.3385, 1.2181],
        [1.4543, 1.4543, 1.4527, 1.4499, 1.4503, 1.4543, 1.4500, 1.4543, 1.4543,
         1.4341, 1.4335, 1.4341, 1.4341, 1.4341, 1.4156, 1.4341, 1.4330, 1.4308,
         2.2018, 2.2020, 2.2187, 2.1944, 2.1761, 2.1743, 2.2034, 2.1734, 2.1734,
         1.5148, 1.5131, 1.5206, 1.5206, 1.5148, 1.5206, 1.5205, 1.5206, 1.5206,
         1.7760, 1.7761, 1.7761, 1.7730, 1.7760, 1.7760, 1.7761, 1.7537, 1.7564,
         1.4348, 1.4393, 1.4393, 1.4393, 1.4311, 1.4393, 1.4355, 1.4392, 1.4393],
        [1.3186, 1.3173, 1.3015, 1.2927, 1.3162, 1.3145, 1.3156, 1.3165, 1.3165,
         1.2988, 1.2922, 1.2884, 1.2879, 1.2994, 1.2843, 1.2958, 1.2990, 1.2717,
         1.6424, 1.6163, 1.6395, 1.6389, 1.6383, 1.6383, 1.6406, 1.6420, 1.6420,
         3.4997, 3.2912, 3.2171, 3.2749, 3.4248, 3.2439, 3.4752, 3.2248, 3.2037,
         1.6482, 1.6407, 1.6391, 1.6422, 1.6451, 1.6211, 1.6465, 1.5860, 1.6125,
         1.3018, 1.2960, 1.2862, 1.3008, 1.2967, 1.2890, 1.3012, 1.3009, 1.3031],
        [1.4571, 1.4533, 1.4108, 1.4133, 1.4507, 1.4570, 1.4556, 1.4571, 1.4571,
         1.4358, 1.4333, 1.4283, 1.4239, 1.4370, 1.3975, 1.4311, 1.4369, 1.4324,
         1.7574, 1.7486, 1.7479, 1.7558, 1.7730, 1.7717, 1.7519, 1.7731, 1.7731,
         1.4815, 1.4878, 1.5233, 1.5182, 1.4871, 1.5219, 1.5102, 1.5234, 1.5202,
         2.2013, 2.1818, 2.1706, 2.1881, 2.2313, 2.2499, 2.2163, 2.3178, 2.3152,
         1.4275, 1.4175, 1.4318, 1.4421, 1.4298, 1.4389, 1.4105, 1.4361, 1.4421],
        [1.3438, 1.2511, 1.2464, 1.2659, 1.2588, 1.2694, 1.2681, 1.2077, 1.2077,
         1.2491, 1.2130, 1.2117, 1.2139, 1.2842, 1.1636, 1.1404, 1.2842, 1.1951,
         1.5972, 1.5732, 1.5550, 1.5496, 1.5735, 1.5695, 1.5898, 1.5749, 1.5749,
         1.3492, 1.3221, 1.3222, 1.3392, 1.3239, 1.3672, 1.3694, 1.3433, 1.3222,
         1.5751, 1.5749, 1.5804, 1.5698, 1.5460, 1.5498, 1.6112, 1.4991, 1.4680,
         4.1204, 3.6288, 3.7192, 3.7025, 3.7165, 3.3980, 4.1171, 3.6768, 3.4307]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 353 : 1779.3396578113416
Test loss for epoch 353 : 194.8982397240439
Test Precision for epoch 353 : 0.26153846153846155
Test Recall for epoch 353 : 0.26153846153846155
Test F1 for epoch 353 : 0.26153846153846155


theta for epoch 354 : tensor([[3.6213, 3.6420, 3.7854, 3.7340, 3.7167, 3.6028, 3.6439, 3.5434, 3.5434,
         1.2644, 1.2476, 1.2465, 1.2477, 1.2797, 1.2277, 1.2068, 1.2798, 1.2336,
         1.6037, 1.5882, 1.6122, 1.5953, 1.6007, 1.6024, 1.6093, 1.6024, 1.6024,
         1.3356, 1.3470, 1.3335, 1.3544, 1.3352, 1.3654, 1.3584, 1.3459, 1.3335,
         1.5961, 1.6116, 1.6009, 1.5973, 1.6040, 1.5940, 1.6121, 1.5666, 1.5713,
         1.2469, 1.2713, 1.2640, 1.2802, 1.2422, 1.2342, 1.2219, 1.3008, 1.2610],
        [1.3739, 1.2246, 1.2137, 1.2569, 1.2572, 1.2697, 1.2636, 1.1704, 1.1704,
         3.5859, 3.6771, 3.5133, 3.9318, 3.5867, 4.3161, 3.4452, 3.5405, 4.0509,
         1.5728, 1.5604, 1.5341, 1.5330, 1.5544, 1.5639, 1.5881, 1.5639, 1.5639,
         1.3419, 1.3081, 1.3030, 1.3602, 1.3024, 1.3973, 1.3777, 1.3467, 1.2999,
         1.5398, 1.5964, 1.5601, 1.5466, 1.5413, 1.5796, 1.5988, 1.4317, 1.5304,
         1.1449, 1.2574, 1.2302, 1.2792, 1.1393, 1.1454, 1.0696, 1.3400, 1.2205],
        [1.4509, 1.4509, 1.4493, 1.4465, 1.4470, 1.4510, 1.4467, 1.4510, 1.4510,
         1.4352, 1.4346, 1.4352, 1.4352, 1.4352, 1.4168, 1.4352, 1.4341, 1.4319,
         2.2069, 2.2071, 2.2237, 2.1993, 2.1810, 2.1792, 2.2083, 2.1784, 2.1784,
         1.5040, 1.5023, 1.5097, 1.5097, 1.5040, 1.5097, 1.5097, 1.5097, 1.5097,
         1.7746, 1.7747, 1.7747, 1.7716, 1.7746, 1.7746, 1.7747, 1.7523, 1.7550,
         1.4402, 1.4447, 1.4447, 1.4447, 1.4366, 1.4447, 1.4410, 1.4446, 1.4447],
        [1.3156, 1.3143, 1.2985, 1.2897, 1.3132, 1.3115, 1.3126, 1.3135, 1.3135,
         1.2998, 1.2933, 1.2895, 1.2890, 1.3004, 1.2853, 1.2969, 1.3000, 1.2728,
         1.6477, 1.6216, 1.6448, 1.6442, 1.6436, 1.6436, 1.6458, 1.6473, 1.6473,
         3.4911, 3.2825, 3.2083, 3.2661, 3.4161, 3.2352, 3.4666, 3.2160, 3.1949,
         1.6467, 1.6392, 1.6376, 1.6407, 1.6437, 1.6196, 1.6451, 1.5845, 1.6110,
         1.3072, 1.3014, 1.2916, 1.3061, 1.3021, 1.2943, 1.3066, 1.3062, 1.3085],
        [1.4538, 1.4499, 1.4074, 1.4099, 1.4473, 1.4537, 1.4523, 1.4538, 1.4538,
         1.4369, 1.4344, 1.4295, 1.4250, 1.4381, 1.3986, 1.4322, 1.4381, 1.4336,
         1.7627, 1.7540, 1.7532, 1.7611, 1.7782, 1.7770, 1.7573, 1.7784, 1.7784,
         1.4707, 1.4770, 1.5125, 1.5074, 1.4762, 1.5111, 1.4993, 1.5125, 1.5094,
         2.2000, 2.1805, 2.1693, 2.1867, 2.2299, 2.2485, 2.2150, 2.3164, 2.3138,
         1.4330, 1.4229, 1.4373, 1.4475, 1.4352, 1.4443, 1.4160, 1.4415, 1.4475],
        [1.3557, 1.2623, 1.2578, 1.2773, 1.2702, 1.2807, 1.2794, 1.2185, 1.2185,
         1.2571, 1.2210, 1.2198, 1.2220, 1.2920, 1.1719, 1.1485, 1.2920, 1.2033,
         1.6101, 1.5862, 1.5681, 1.5625, 1.5863, 1.5823, 1.6028, 1.5878, 1.5878,
         1.3510, 1.3240, 1.3237, 1.3410, 1.3256, 1.3691, 1.3712, 1.3450, 1.3238,
         1.5808, 1.5808, 1.5862, 1.5756, 1.5519, 1.5558, 1.6171, 1.5053, 1.4743,
         4.1083, 3.6164, 3.7068, 3.6902, 3.7041, 3.3855, 4.1050, 3.6645, 3.4183]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 354 : 1779.332013446216
Test loss for epoch 354 : 194.77866256782102
Test Precision for epoch 354 : 0.26153846153846155
Test Recall for epoch 354 : 0.26153846153846155
Test F1 for epoch 354 : 0.26153846153846155


theta for epoch 355 : tensor([[3.6180, 3.6387, 3.7821, 3.7307, 3.7134, 3.5995, 3.6406, 3.5400, 3.5400,
         1.2649, 1.2481, 1.2470, 1.2483, 1.2802, 1.2284, 1.2073, 1.2802, 1.2343,
         1.6022, 1.5867, 1.6108, 1.5939, 1.5993, 1.6010, 1.6079, 1.6009, 1.6009,
         1.3324, 1.3438, 1.3303, 1.3513, 1.3320, 1.3623, 1.3553, 1.3427, 1.3303,
         1.5956, 1.6111, 1.6003, 1.5967, 1.6035, 1.5934, 1.6116, 1.5661, 1.5707,
         1.2544, 1.2787, 1.2714, 1.2875, 1.2496, 1.2418, 1.2296, 1.3081, 1.2685],
        [1.3650, 1.2164, 1.2054, 1.2486, 1.2488, 1.2614, 1.2553, 1.1625, 1.1625,
         3.5933, 3.6845, 3.5206, 3.9395, 3.5941, 4.3244, 3.4524, 3.5478, 4.0588,
         1.5662, 1.5538, 1.5274, 1.5266, 1.5480, 1.5575, 1.5816, 1.5575, 1.5575,
         1.3343, 1.3004, 1.2956, 1.3526, 1.2949, 1.3896, 1.3700, 1.3391, 1.2924,
         1.5342, 1.5908, 1.5545, 1.5410, 1.5356, 1.5739, 1.5931, 1.4257, 1.5246,
         1.1439, 1.2562, 1.2291, 1.2779, 1.1384, 1.1447, 1.0682, 1.3386, 1.2195],
        [1.4470, 1.4470, 1.4454, 1.4426, 1.4430, 1.4470, 1.4427, 1.4470, 1.4470,
         1.4354, 1.4347, 1.4353, 1.4353, 1.4354, 1.4169, 1.4354, 1.4343, 1.4320,
         2.2052, 2.2054, 2.2220, 2.1977, 2.1794, 2.1776, 2.2067, 2.1768, 2.1768,
         1.5003, 1.4986, 1.5060, 1.5060, 1.5003, 1.5060, 1.5060, 1.5060, 1.5060,
         1.7738, 1.7739, 1.7739, 1.7708, 1.7738, 1.7738, 1.7739, 1.7515, 1.7542,
         1.4474, 1.4518, 1.4518, 1.4518, 1.4437, 1.4518, 1.4481, 1.4517, 1.4518],
        [1.3122, 1.3107, 1.2950, 1.2861, 1.3096, 1.3080, 1.3091, 1.3099, 1.3099,
         1.2999, 1.2934, 1.2895, 1.2891, 1.3005, 1.2854, 1.2969, 1.3001, 1.2729,
         1.6458, 1.6197, 1.6429, 1.6423, 1.6417, 1.6417, 1.6439, 1.6454, 1.6454,
         3.4887, 3.2800, 3.2058, 3.2636, 3.4137, 3.2326, 3.4641, 3.2135, 3.1924,
         1.6458, 1.6383, 1.6367, 1.6398, 1.6427, 1.6187, 1.6442, 1.5836, 1.6101,
         1.3142, 1.3085, 1.2987, 1.3132, 1.3092, 1.3014, 1.3137, 1.3133, 1.3156],
        [1.4499, 1.4460, 1.4033, 1.4059, 1.4433, 1.4498, 1.4483, 1.4498, 1.4498,
         1.4371, 1.4346, 1.4296, 1.4252, 1.4382, 1.3988, 1.4324, 1.4382, 1.4337,
         1.7609, 1.7522, 1.7515, 1.7593, 1.7764, 1.7752, 1.7555, 1.7766, 1.7766,
         1.4670, 1.4733, 1.5088, 1.5037, 1.4726, 1.5074, 1.4956, 1.5088, 1.5057,
         2.1992, 2.1797, 2.1685, 2.1859, 2.2291, 2.2478, 2.2142, 2.3155, 2.3130,
         1.4401, 1.4301, 1.4444, 1.4546, 1.4424, 1.4514, 1.4232, 1.4486, 1.4546],
        [1.3626, 1.2683, 1.2640, 1.2835, 1.2764, 1.2869, 1.2856, 1.2240, 1.2240,
         1.2617, 1.2253, 1.2242, 1.2265, 1.2969, 1.1765, 1.1521, 1.2969, 1.2078,
         1.6139, 1.5900, 1.5720, 1.5663, 1.5900, 1.5860, 1.6066, 1.5915, 1.5915,
         1.3549, 1.3279, 1.3274, 1.3450, 1.3295, 1.3732, 1.3751, 1.3489, 1.3274,
         1.5846, 1.5848, 1.5899, 1.5794, 1.5558, 1.5598, 1.6209, 1.5093, 1.4785,
         4.1021, 3.6099, 3.7003, 3.6836, 3.6976, 3.3789, 4.0988, 3.6580, 3.4117]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 355 : 1779.2738043625423
Test loss for epoch 355 : 195.00923656959577
Test Precision for epoch 355 : 0.26153846153846155
Test Recall for epoch 355 : 0.26153846153846155
Test F1 for epoch 355 : 0.26153846153846155


theta for epoch 356 : tensor([[3.6230, 3.6437, 3.7872, 3.7358, 3.7184, 3.6045, 3.6456, 3.5451, 3.5451,
         1.2605, 1.2435, 1.2424, 1.2438, 1.2760, 1.2240, 1.2023, 1.2760, 1.2299,
         1.5964, 1.5809, 1.6050, 1.5881, 1.5935, 1.5952, 1.6021, 1.5951, 1.5951,
         1.3395, 1.3509, 1.3374, 1.3583, 1.3391, 1.3693, 1.3623, 1.3498, 1.3374,
         1.5959, 1.6114, 1.6007, 1.5970, 1.6038, 1.5937, 1.6119, 1.5664, 1.5710,
         1.2557, 1.2800, 1.2728, 1.2888, 1.2509, 1.2432, 1.2311, 1.3093, 1.2699],
        [1.3558, 1.2071, 1.1960, 1.2393, 1.2395, 1.2521, 1.2460, 1.1532, 1.1532,
         3.6041, 3.6954, 3.5314, 3.9507, 3.6050, 4.3362, 3.4632, 3.5587, 4.0701,
         1.5536, 1.5412, 1.5147, 1.5139, 1.5354, 1.5449, 1.5690, 1.5450, 1.5450,
         1.3291, 1.2950, 1.2903, 1.3474, 1.2895, 1.3845, 1.3649, 1.3339, 1.2871,
         1.5260, 1.5828, 1.5464, 1.5329, 1.5274, 1.5659, 1.5851, 1.4171, 1.5164,
         1.1355, 1.2478, 1.2208, 1.2696, 1.1301, 1.1365, 1.0595, 1.3303, 1.2112],
        [1.4515, 1.4515, 1.4499, 1.4471, 1.4476, 1.4516, 1.4473, 1.4516, 1.4516,
         1.4313, 1.4306, 1.4312, 1.4312, 1.4313, 1.4128, 1.4312, 1.4301, 1.4279,
         2.2001, 2.2003, 2.2169, 2.1927, 2.1745, 2.1727, 2.2018, 2.1718, 2.1718,
         1.5078, 1.5062, 1.5136, 1.5136, 1.5079, 1.5136, 1.5135, 1.5136, 1.5136,
         1.7744, 1.7745, 1.7745, 1.7714, 1.7744, 1.7744, 1.7745, 1.7521, 1.7548,
         1.4490, 1.4535, 1.4535, 1.4535, 1.4454, 1.4535, 1.4498, 1.4534, 1.4535],
        [1.3173, 1.3158, 1.3000, 1.2912, 1.3147, 1.3131, 1.3142, 1.3150, 1.3150,
         1.2957, 1.2892, 1.2853, 1.2849, 1.2963, 1.2812, 1.2927, 1.2959, 1.2687,
         1.6403, 1.6142, 1.6374, 1.6368, 1.6362, 1.6362, 1.6384, 1.6399, 1.6399,
         3.4962, 3.2875, 3.2133, 3.2711, 3.4212, 3.2401, 3.4717, 3.2210, 3.1999,
         1.6463, 1.6388, 1.6373, 1.6404, 1.6433, 1.6192, 1.6447, 1.5842, 1.6106,
         1.3159, 1.3101, 1.3003, 1.3148, 1.3108, 1.3031, 1.3153, 1.3149, 1.3172],
        [1.4544, 1.4505, 1.4078, 1.4104, 1.4478, 1.4543, 1.4529, 1.4544, 1.4544,
         1.4330, 1.4304, 1.4255, 1.4211, 1.4341, 1.3947, 1.4283, 1.4341, 1.4296,
         1.7555, 1.7468, 1.7461, 1.7540, 1.7710, 1.7698, 1.7501, 1.7712, 1.7712,
         1.4747, 1.4809, 1.5163, 1.5113, 1.4802, 1.5150, 1.5032, 1.5164, 1.5133,
         2.1998, 2.1803, 2.1691, 2.1865, 2.2296, 2.2483, 2.2148, 2.3160, 2.3135,
         1.4418, 1.4318, 1.4461, 1.4563, 1.4441, 1.4531, 1.4250, 1.4503, 1.4563],
        [1.3702, 1.2753, 1.2710, 1.2906, 1.2835, 1.2940, 1.2927, 1.2306, 1.2306,
         1.2600, 1.2231, 1.2219, 1.2244, 1.2957, 1.1744, 1.1485, 1.2958, 1.2056,
         1.6117, 1.5878, 1.5699, 1.5641, 1.5878, 1.5838, 1.6044, 1.5892, 1.5892,
         1.3643, 1.3373, 1.3366, 1.3544, 1.3388, 1.3827, 1.3846, 1.3583, 1.3366,
         1.5873, 1.5875, 1.5926, 1.5821, 1.5586, 1.5626, 1.6237, 1.5121, 1.4813,
         4.0990, 3.6065, 3.6969, 3.6803, 3.6942, 3.3755, 4.0958, 3.6548, 3.4083]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 356 : 1778.7845507249824
Test loss for epoch 356 : 195.39492023972718
Test Precision for epoch 356 : 0.26153846153846155
Test Recall for epoch 356 : 0.26153846153846155
Test F1 for epoch 356 : 0.26153846153846155


theta for epoch 357 : tensor([[3.6207, 3.6414, 3.7848, 3.7334, 3.7161, 3.6022, 3.6433, 3.5427, 3.5427,
         1.2553, 1.2385, 1.2374, 1.2388, 1.2706, 1.2191, 1.1976, 1.2706, 1.2251,
         1.5984, 1.5829, 1.6069, 1.5901, 1.5955, 1.5972, 1.6040, 1.5971, 1.5971,
         1.3470, 1.3584, 1.3449, 1.3658, 1.3466, 1.3767, 1.3698, 1.3573, 1.3450,
         1.5993, 1.6147, 1.6040, 1.6004, 1.6071, 1.5971, 1.6152, 1.5698, 1.5744,
         1.2552, 1.2795, 1.2723, 1.2882, 1.2505, 1.2429, 1.2309, 1.3085, 1.2694],
        [1.3710, 1.2225, 1.2115, 1.2547, 1.2549, 1.2675, 1.2614, 1.1687, 1.1687,
         3.5883, 3.6796, 3.5155, 3.9351, 3.5892, 4.3213, 3.4471, 3.5429, 4.0547,
         1.5658, 1.5534, 1.5270, 1.5262, 1.5476, 1.5571, 1.5811, 1.5571, 1.5571,
         1.3443, 1.3104, 1.3056, 1.3627, 1.3048, 1.3997, 1.3801, 1.3491, 1.3024,
         1.5390, 1.5956, 1.5593, 1.5458, 1.5404, 1.5788, 1.5979, 1.4305, 1.5294,
         1.1469, 1.2588, 1.2319, 1.2804, 1.1416, 1.1480, 1.0711, 1.3408, 1.2224],
        [1.4542, 1.4542, 1.4525, 1.4498, 1.4502, 1.4542, 1.4499, 1.4542, 1.4542,
         1.4254, 1.4247, 1.4253, 1.4253, 1.4254, 1.4069, 1.4253, 1.4242, 1.4220,
         2.2012, 2.2013, 2.2180, 2.1938, 2.1755, 2.1737, 2.2029, 2.1729, 2.1729,
         1.5144, 1.5127, 1.5201, 1.5201, 1.5144, 1.5201, 1.5201, 1.5201, 1.5201,
         1.7770, 1.7771, 1.7771, 1.7740, 1.7770, 1.7770, 1.7771, 1.7547, 1.7574,
         1.4475, 1.4519, 1.4519, 1.4519, 1.4439, 1.4519, 1.4483, 1.4519, 1.4519],
        [1.3207, 1.3191, 1.3033, 1.2945, 1.3180, 1.3164, 1.3175, 1.3182, 1.3182,
         1.2898, 1.2833, 1.2794, 1.2790, 1.2903, 1.2753, 1.2868, 1.2899, 1.2628,
         1.6415, 1.6153, 1.6385, 1.6380, 1.6373, 1.6374, 1.6396, 1.6411, 1.6411,
         3.5024, 3.2937, 3.2196, 3.2773, 3.4274, 3.2463, 3.4778, 3.2272, 3.2062,
         1.6490, 1.6415, 1.6399, 1.6430, 1.6459, 1.6218, 1.6473, 1.5868, 1.6132,
         1.3144, 1.3086, 1.2988, 1.3134, 1.3093, 1.3016, 1.3138, 1.3134, 1.3157],
        [1.4570, 1.4531, 1.4103, 1.4130, 1.4505, 1.4569, 1.4555, 1.4570, 1.4570,
         1.4271, 1.4246, 1.4196, 1.4152, 1.4282, 1.3889, 1.4224, 1.4282, 1.4237,
         1.7566, 1.7479, 1.7472, 1.7551, 1.7721, 1.7709, 1.7512, 1.7723, 1.7723,
         1.4812, 1.4875, 1.5229, 1.5178, 1.4867, 1.5215, 1.5098, 1.5229, 1.5198,
         2.2023, 2.1829, 2.1717, 2.1890, 2.2322, 2.2509, 2.2173, 2.3185, 2.3160,
         1.4403, 1.4302, 1.4446, 1.4547, 1.4426, 1.4516, 1.4235, 1.4488, 1.4548],
        [1.3757, 1.2812, 1.2769, 1.2964, 1.2893, 1.2998, 1.2985, 1.2367, 1.2367,
         1.2569, 1.2201, 1.2189, 1.2215, 1.2925, 1.1717, 1.1457, 1.2926, 1.2028,
         1.6154, 1.5915, 1.5736, 1.5678, 1.5915, 1.5875, 1.6081, 1.5929, 1.5929,
         1.3728, 1.3458, 1.3452, 1.3629, 1.3473, 1.3911, 1.3931, 1.3668, 1.3452,
         1.5921, 1.5923, 1.5974, 1.5870, 1.5634, 1.5674, 1.6284, 1.5170, 1.4862,
         4.0942, 3.6015, 3.6919, 3.6753, 3.6892, 3.3704, 4.0910, 3.6498, 3.4032]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 357 : 1779.8405589061924
Test loss for epoch 357 : 194.46756722445298
Test Precision for epoch 357 : 0.26153846153846155
Test Recall for epoch 357 : 0.26153846153846155
Test F1 for epoch 357 : 0.26153846153846155


theta for epoch 358 : tensor([[3.6163, 3.6370, 3.7805, 3.7291, 3.7117, 3.5978, 3.6389, 3.5383, 3.5383,
         1.2589, 1.2419, 1.2408, 1.2424, 1.2743, 1.2228, 1.2007, 1.2743, 1.2288,
         1.6044, 1.5889, 1.6129, 1.5961, 1.6015, 1.6032, 1.6100, 1.6031, 1.6031,
         1.3371, 1.3485, 1.3351, 1.3559, 1.3368, 1.3669, 1.3599, 1.3475, 1.3352,
         1.6009, 1.6163, 1.6056, 1.6020, 1.6087, 1.5987, 1.6168, 1.5714, 1.5760,
         1.2557, 1.2799, 1.2728, 1.2886, 1.2510, 1.2435, 1.2316, 1.3089, 1.2699],
        [1.3760, 1.2275, 1.2165, 1.2596, 1.2599, 1.2724, 1.2663, 1.1736, 1.1736,
         3.5817, 3.6730, 3.5089, 3.9288, 3.5826, 4.3156, 3.4404, 3.5363, 4.0486,
         1.5757, 1.5633, 1.5370, 1.5361, 1.5575, 1.5670, 1.5910, 1.5670, 1.5670,
         1.3452, 1.3113, 1.3064, 1.3635, 1.3058, 1.4005, 1.3809, 1.3500, 1.3033,
         1.5458, 1.6024, 1.5661, 1.5526, 1.5473, 1.5856, 1.6047, 1.4376, 1.5363,
         1.1538, 1.2655, 1.2387, 1.2871, 1.1484, 1.1548, 1.0779, 1.3475, 1.2292],
        [1.4478, 1.4477, 1.4461, 1.4433, 1.4438, 1.4478, 1.4435, 1.4478, 1.4478,
         1.4288, 1.4282, 1.4288, 1.4288, 1.4288, 1.4104, 1.4288, 1.4277, 1.4255,
         2.2067, 2.2068, 2.2234, 2.1990, 2.1808, 2.1790, 2.2081, 2.1781, 2.1781,
         1.5045, 1.5029, 1.5103, 1.5103, 1.5046, 1.5103, 1.5102, 1.5103, 1.5103,
         1.7784, 1.7785, 1.7785, 1.7754, 1.7784, 1.7784, 1.7785, 1.7561, 1.7588,
         1.4476, 1.4520, 1.4520, 1.4520, 1.4439, 1.4520, 1.4484, 1.4520, 1.4520],
        [1.3149, 1.3132, 1.2973, 1.2885, 1.3121, 1.3105, 1.3116, 1.3122, 1.3122,
         1.2933, 1.2868, 1.2829, 1.2825, 1.2938, 1.2788, 1.2903, 1.2935, 1.2663,
         1.6474, 1.6212, 1.6444, 1.6438, 1.6432, 1.6433, 1.6455, 1.6469, 1.6469,
         3.4937, 3.2848, 3.2106, 3.2684, 3.4186, 3.2374, 3.4691, 3.2182, 3.1972,
         1.6504, 1.6429, 1.6414, 1.6445, 1.6474, 1.6233, 1.6488, 1.5882, 1.6146,
         1.3146, 1.3088, 1.2991, 1.3136, 1.3095, 1.3018, 1.3141, 1.3136, 1.3160],
        [1.4506, 1.4466, 1.4037, 1.4065, 1.4440, 1.4505, 1.4491, 1.4506, 1.4506,
         1.4305, 1.4280, 1.4231, 1.4187, 1.4317, 1.3923, 1.4258, 1.4316, 1.4272,
         1.7623, 1.7536, 1.7529, 1.7608, 1.7778, 1.7766, 1.7569, 1.7780, 1.7780,
         1.4714, 1.4776, 1.5130, 1.5080, 1.4769, 1.5117, 1.4999, 1.5131, 1.5099,
         2.2037, 2.1842, 2.1730, 2.1904, 2.2335, 2.2522, 2.2187, 2.3199, 2.3173,
         1.4404, 1.4303, 1.4447, 1.4548, 1.4427, 1.4517, 1.4235, 1.4489, 1.4549],
        [1.3702, 1.2764, 1.2721, 1.2915, 1.2845, 1.2949, 1.2936, 1.2323, 1.2323,
         1.2600, 1.2229, 1.2218, 1.2245, 1.2959, 1.1748, 1.1477, 1.2959, 1.2058,
         1.6204, 1.5966, 1.5786, 1.5730, 1.5967, 1.5927, 1.6131, 1.5981, 1.5981,
         1.3643, 1.3374, 1.3369, 1.3544, 1.3390, 1.3824, 1.3844, 1.3583, 1.3370,
         1.5935, 1.5936, 1.5989, 1.5884, 1.5648, 1.5687, 1.6297, 1.5184, 1.4876,
         4.0948, 3.6018, 3.6922, 3.6756, 3.6895, 3.3707, 4.0916, 3.6501, 3.4034]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 358 : 1779.892064332372
Test loss for epoch 358 : 194.31762821963576
Test Precision for epoch 358 : 0.26153846153846155
Test Recall for epoch 358 : 0.26153846153846155
Test F1 for epoch 358 : 0.26153846153846155


theta for epoch 359 : tensor([[3.6168, 3.6375, 3.7810, 3.7296, 3.7122, 3.5983, 3.6394, 3.5388, 3.5388,
         1.2683, 1.2509, 1.2499, 1.2516, 1.2840, 1.2320, 1.2089, 1.2840, 1.2379,
         1.6021, 1.5867, 1.6107, 1.5938, 1.5992, 1.6009, 1.6078, 1.6009, 1.6009,
         1.3304, 1.3417, 1.3283, 1.3491, 1.3300, 1.3601, 1.3531, 1.3406, 1.3283,
         1.5964, 1.6118, 1.6011, 1.5975, 1.6042, 1.5942, 1.6123, 1.5669, 1.5715,
         1.2536, 1.2779, 1.2708, 1.2866, 1.2489, 1.2415, 1.2298, 1.3069, 1.2679],
        [1.3767, 1.2276, 1.2168, 1.2599, 1.2601, 1.2726, 1.2666, 1.1734, 1.1734,
         3.5831, 3.6745, 3.5102, 3.9305, 3.5841, 4.3180, 3.4417, 3.5378, 4.0505,
         1.5755, 1.5631, 1.5368, 1.5357, 1.5571, 1.5666, 1.5908, 1.5666, 1.5666,
         1.3429, 1.3090, 1.3040, 1.3611, 1.3035, 1.3982, 1.3786, 1.3476, 1.3008,
         1.5435, 1.6000, 1.5637, 1.5503, 1.5449, 1.5832, 1.6024, 1.4354, 1.5340,
         1.1540, 1.2659, 1.2391, 1.2875, 1.1486, 1.1550, 1.0780, 1.3482, 1.2295],
        [1.4456, 1.4455, 1.4439, 1.4411, 1.4415, 1.4456, 1.4413, 1.4456, 1.4456,
         1.4386, 1.4379, 1.4385, 1.4385, 1.4386, 1.4201, 1.4386, 1.4375, 1.4352,
         2.2049, 2.2050, 2.2217, 2.1973, 2.1791, 2.1773, 2.2064, 2.1765, 2.1765,
         1.4985, 1.4968, 1.5042, 1.5042, 1.4985, 1.5042, 1.5042, 1.5042, 1.5042,
         1.7743, 1.7743, 1.7743, 1.7712, 1.7742, 1.7742, 1.7743, 1.7519, 1.7546,
         1.4458, 1.4503, 1.4503, 1.4503, 1.4422, 1.4503, 1.4466, 1.4502, 1.4503],
        [1.3134, 1.3116, 1.2957, 1.2869, 1.3105, 1.3089, 1.3100, 1.3105, 1.3105,
         1.3031, 1.2966, 1.2928, 1.2923, 1.3037, 1.2887, 1.3001, 1.3033, 1.2762,
         1.6457, 1.6195, 1.6427, 1.6421, 1.6415, 1.6416, 1.6438, 1.6452, 1.6452,
         3.4880, 3.2790, 3.2047, 3.2626, 3.4128, 3.2315, 3.4634, 3.2123, 3.1913,
         1.6463, 1.6388, 1.6373, 1.6404, 1.6433, 1.6192, 1.6447, 1.5841, 1.6105,
         1.3130, 1.3072, 1.2975, 1.3120, 1.3079, 1.3002, 1.3125, 1.3121, 1.3144],
        [1.4484, 1.4443, 1.4012, 1.4042, 1.4418, 1.4483, 1.4468, 1.4484, 1.4484,
         1.4403, 1.4378, 1.4328, 1.4284, 1.4414, 1.4021, 1.4356, 1.4414, 1.4369,
         1.7604, 1.7517, 1.7510, 1.7589, 1.7760, 1.7747, 1.7550, 1.7761, 1.7761,
         1.4653, 1.4715, 1.5070, 1.5019, 1.4708, 1.5056, 1.4939, 1.5070, 1.5039,
         2.1996, 2.1802, 2.1690, 2.1864, 2.2295, 2.2482, 2.2147, 2.3159, 2.3134,
         1.4386, 1.4286, 1.4429, 1.4531, 1.4409, 1.4499, 1.4217, 1.4471, 1.4531],
        [1.3635, 1.2704, 1.2660, 1.2853, 1.2783, 1.2887, 1.2874, 1.2267, 1.2267,
         1.2669, 1.2292, 1.2280, 1.2310, 1.3034, 1.1811, 1.1524, 1.3034, 1.2121,
         1.6165, 1.5927, 1.5746, 1.5692, 1.5929, 1.5889, 1.6092, 1.5943, 1.5943,
         1.3558, 1.3290, 1.3287, 1.3459, 1.3306, 1.3738, 1.3759, 1.3498, 1.3288,
         1.5878, 1.5878, 1.5931, 1.5827, 1.5590, 1.5629, 1.6238, 1.5126, 1.4818,
         4.0988, 3.6055, 3.6960, 3.6794, 3.6933, 3.3744, 4.0957, 3.6539, 3.4072]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 359 : 1779.7754382626567
Test loss for epoch 359 : 194.57169414493447
Test Precision for epoch 359 : 0.26153846153846155
Test Recall for epoch 359 : 0.26153846153846155
Test F1 for epoch 359 : 0.26153846153846155


theta for epoch 360 : tensor([[3.6237, 3.6444, 3.7879, 3.7365, 3.7191, 3.6053, 3.6464, 3.5459, 3.5459,
         1.2719, 1.2541, 1.2530, 1.2549, 1.2881, 1.2352, 1.2107, 1.2881, 1.2411,
         1.5947, 1.5792, 1.6032, 1.5863, 1.5917, 1.5934, 1.6003, 1.5934, 1.5934,
         1.3357, 1.3471, 1.3336, 1.3545, 1.3354, 1.3655, 1.3585, 1.3460, 1.3336,
         1.5915, 1.6070, 1.5963, 1.5927, 1.5994, 1.5894, 1.6075, 1.5620, 1.5667,
         1.2486, 1.2730, 1.2659, 1.2817, 1.2439, 1.2365, 1.2250, 1.3021, 1.2630],
        [1.3750, 1.2249, 1.2141, 1.2573, 1.2575, 1.2701, 1.2640, 1.1702, 1.1702,
         3.5889, 3.6803, 3.5159, 3.9366, 3.5899, 4.3247, 3.4474, 3.5436, 4.0567,
         1.5676, 1.5551, 1.5289, 1.5276, 1.5490, 1.5585, 1.5828, 1.5585, 1.5585,
         1.3427, 1.3088, 1.3035, 1.3611, 1.3031, 1.3984, 1.3787, 1.3474, 1.3003,
         1.5368, 1.5936, 1.5570, 1.5436, 1.5383, 1.5767, 1.5960, 1.4287, 1.5273,
         1.1478, 1.2601, 1.2332, 1.2818, 1.1424, 1.1487, 1.0717, 1.3428, 1.2236],
        [1.4506, 1.4506, 1.4489, 1.4461, 1.4466, 1.4506, 1.4464, 1.4506, 1.4506,
         1.4430, 1.4423, 1.4429, 1.4429, 1.4430, 1.4245, 1.4430, 1.4418, 1.4396,
         2.1988, 2.1989, 2.2156, 2.1914, 2.1732, 2.1713, 2.2005, 2.1705, 2.1705,
         1.5053, 1.5036, 1.5110, 1.5110, 1.5053, 1.5110, 1.5110, 1.5110, 1.5110,
         1.7702, 1.7703, 1.7703, 1.7672, 1.7702, 1.7702, 1.7703, 1.7479, 1.7506,
         1.4417, 1.4462, 1.4462, 1.4462, 1.4380, 1.4462, 1.4425, 1.4461, 1.4462],
        [1.3192, 1.3172, 1.3013, 1.2925, 1.3161, 1.3146, 1.3157, 1.3162, 1.3162,
         1.3076, 1.3011, 1.2972, 1.2968, 1.3082, 1.2931, 1.3045, 1.3078, 1.2806,
         1.6393, 1.6130, 1.6363, 1.6357, 1.6351, 1.6352, 1.6374, 1.6388, 1.6388,
         3.4936, 3.2845, 3.2102, 3.2681, 3.4184, 3.2371, 3.4689, 3.2179, 3.1968,
         1.6424, 1.6349, 1.6333, 1.6364, 1.6393, 1.6152, 1.6407, 1.5801, 1.6066,
         1.3091, 1.3033, 1.2935, 1.3081, 1.3040, 1.2962, 1.3085, 1.3082, 1.3104],
        [1.4535, 1.4493, 1.4061, 1.4092, 1.4468, 1.4534, 1.4519, 1.4535, 1.4535,
         1.4447, 1.4421, 1.4372, 1.4328, 1.4458, 1.4065, 1.4400, 1.4458, 1.4413,
         1.7540, 1.7453, 1.7445, 1.7524, 1.7695, 1.7683, 1.7485, 1.7697, 1.7697,
         1.4721, 1.4782, 1.5138, 1.5087, 1.4776, 1.5124, 1.5007, 1.5138, 1.5107,
         2.1958, 2.1763, 2.1651, 2.1825, 2.2257, 2.2444, 2.2108, 2.3121, 2.3095,
         1.4344, 1.4244, 1.4387, 1.4490, 1.4367, 1.4458, 1.4175, 1.4430, 1.4490],
        [1.3582, 1.2656, 1.2612, 1.2805, 1.2734, 1.2838, 1.2826, 1.2223, 1.2223,
         1.2673, 1.2286, 1.2274, 1.2308, 1.3045, 1.1806, 1.1499, 1.3045, 1.2116,
         1.6063, 1.5826, 1.5645, 1.5592, 1.5829, 1.5789, 1.5990, 1.5843, 1.5843,
         1.3552, 1.3284, 1.3283, 1.3452, 1.3301, 1.3730, 1.3752, 1.3493, 1.3284,
         1.5804, 1.5802, 1.5857, 1.5752, 1.5515, 1.5553, 1.6163, 1.5051, 1.4742,
         4.1056, 3.6121, 3.7025, 3.6859, 3.6999, 3.3810, 4.1025, 3.6605, 3.4137]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 360 : 1779.573466954368
Test loss for epoch 360 : 194.85869974922895
Test Precision for epoch 360 : 0.26153846153846155
Test Recall for epoch 360 : 0.26153846153846155
Test F1 for epoch 360 : 0.26153846153846155


theta for epoch 361 : tensor([[3.6310, 3.6518, 3.7952, 3.7439, 3.7264, 3.6126, 3.6537, 3.5533, 3.5533,
         1.2634, 1.2449, 1.2437, 1.2460, 1.2802, 1.2261, 1.2000, 1.2802, 1.2319,
         1.5942, 1.5787, 1.6027, 1.5858, 1.5912, 1.5929, 1.5999, 1.5929, 1.5929,
         1.3443, 1.3557, 1.3421, 1.3631, 1.3440, 1.3741, 1.3671, 1.3546, 1.3421,
         1.5927, 1.6082, 1.5975, 1.5939, 1.6006, 1.5906, 1.6088, 1.5632, 1.5678,
         1.2456, 1.2702, 1.2630, 1.2789, 1.2408, 1.2334, 1.2221, 1.2994, 1.2601],
        [1.3670, 1.2158, 1.2051, 1.2485, 1.2487, 1.2613, 1.2552, 1.1606, 1.1606,
         3.5967, 3.6882, 3.5237, 3.9448, 3.5977, 4.3335, 3.4551, 3.5514, 4.0651,
         1.5606, 1.5481, 1.5219, 1.5204, 1.5418, 1.5513, 1.5759, 1.5514, 1.5514,
         1.3405, 1.3064, 1.3008, 1.3590, 1.3006, 1.3967, 1.3768, 1.3452, 1.2977,
         1.5311, 1.5882, 1.5514, 1.5379, 1.5326, 1.5712, 1.5907, 1.4225, 1.5215,
         1.1389, 1.2518, 1.2247, 1.2736, 1.1333, 1.1396, 1.0625, 1.3351, 1.2150],
        [1.4526, 1.4525, 1.4509, 1.4481, 1.4485, 1.4526, 1.4483, 1.4526, 1.4526,
         1.4356, 1.4349, 1.4355, 1.4355, 1.4356, 1.4171, 1.4355, 1.4344, 1.4322,
         2.1996, 2.1997, 2.2164, 2.1922, 2.1740, 2.1721, 2.2013, 2.1713, 2.1713,
         1.5159, 1.5143, 1.5217, 1.5216, 1.5160, 1.5216, 1.5216, 1.5216, 1.5217,
         1.7725, 1.7726, 1.7726, 1.7695, 1.7725, 1.7725, 1.7726, 1.7501, 1.7528,
         1.4401, 1.4446, 1.4446, 1.4446, 1.4364, 1.4445, 1.4408, 1.4445, 1.4446],
        [1.3216, 1.3196, 1.3037, 1.2949, 1.3185, 1.3170, 1.3181, 1.3185, 1.3185,
         1.3003, 1.2937, 1.2898, 1.2894, 1.3009, 1.2857, 1.2971, 1.3005, 1.2732,
         1.6403, 1.6141, 1.6373, 1.6368, 1.6362, 1.6362, 1.6384, 1.6399, 1.6399,
         3.5026, 3.2935, 3.2193, 3.2771, 3.4274, 3.2460, 3.4779, 3.2269, 3.2058,
         1.6448, 1.6373, 1.6357, 1.6388, 1.6417, 1.6176, 1.6431, 1.5825, 1.6089,
         1.3076, 1.3019, 1.2921, 1.3067, 1.3025, 1.2948, 1.3070, 1.3068, 1.3090],
        [1.4554, 1.4512, 1.4079, 1.4111, 1.4487, 1.4553, 1.4538, 1.4554, 1.4554,
         1.4373, 1.4347, 1.4298, 1.4254, 1.4384, 1.3990, 1.4326, 1.4384, 1.4339,
         1.7548, 1.7461, 1.7454, 1.7533, 1.7704, 1.7691, 1.7494, 1.7706, 1.7706,
         1.4828, 1.4889, 1.5244, 1.5193, 1.4882, 1.5230, 1.5114, 1.5244, 1.5213,
         2.1980, 2.1785, 2.1673, 2.1847, 2.2279, 2.2466, 2.2130, 2.3143, 2.3118,
         1.4328, 1.4228, 1.4371, 1.4473, 1.4351, 1.4442, 1.4158, 1.4414, 1.4474],
        [1.3479, 1.2559, 1.2514, 1.2706, 1.2635, 1.2740, 1.2727, 1.2128, 1.2128,
         1.2553, 1.2157, 1.2145, 1.2182, 1.2934, 1.1677, 1.1349, 1.2934, 1.1986,
         1.6009, 1.5771, 1.5589, 1.5538, 1.5776, 1.5735, 1.5936, 1.5790, 1.5790,
         1.3556, 1.3287, 1.3289, 1.3455, 1.3305, 1.3732, 1.3756, 1.3496, 1.3290,
         1.5772, 1.5768, 1.5825, 1.5720, 1.5482, 1.5519, 1.6130, 1.5016, 1.4705,
         4.1165, 3.6228, 3.7133, 3.6967, 3.7106, 3.3917, 4.1135, 3.6712, 3.4244]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 361 : 1778.9602750156944
Test loss for epoch 361 : 195.12616366539874
Test Precision for epoch 361 : 0.26153846153846155
Test Recall for epoch 361 : 0.26153846153846155
Test F1 for epoch 361 : 0.26153846153846155


theta for epoch 362 : tensor([[3.6315, 3.6523, 3.7957, 3.7444, 3.7270, 3.6132, 3.6543, 3.5539, 3.5539,
         1.2540, 1.2352, 1.2341, 1.2365, 1.2710, 1.2166, 1.1899, 1.2710, 1.2224,
         1.6028, 1.5873, 1.6113, 1.5943, 1.5998, 1.6014, 1.6084, 1.6014, 1.6014,
         1.3407, 1.3520, 1.3385, 1.3595, 1.3404, 1.3705, 1.3635, 1.3509, 1.3385,
         1.5998, 1.6153, 1.6046, 1.6010, 1.6077, 1.5977, 1.6159, 1.5703, 1.5749,
         1.2462, 1.2710, 1.2637, 1.2798, 1.2414, 1.2339, 1.2228, 1.3005, 1.2608],
        [1.3706, 1.2188, 1.2081, 1.2515, 1.2517, 1.2643, 1.2582, 1.1632, 1.1632,
         3.5907, 3.6823, 3.5177, 3.9391, 3.5918, 4.3285, 3.4490, 3.5454, 4.0596,
         1.5694, 1.5567, 1.5305, 1.5289, 1.5504, 1.5599, 1.5846, 1.5599, 1.5599,
         1.3417, 1.3075, 1.3018, 1.3601, 1.3017, 1.3979, 1.3779, 1.3463, 1.2986,
         1.5392, 1.5965, 1.5595, 1.5460, 1.5408, 1.5795, 1.5990, 1.4306, 1.5296,
         1.1425, 1.2559, 1.2286, 1.2779, 1.1368, 1.1429, 1.0660, 1.3398, 1.2189],
        [1.4520, 1.4519, 1.4503, 1.4475, 1.4479, 1.4520, 1.4477, 1.4520, 1.4520,
         1.4265, 1.4258, 1.4264, 1.4264, 1.4265, 1.4080, 1.4264, 1.4253, 1.4231,
         2.2079, 2.2080, 2.2246, 2.2002, 2.1819, 2.1801, 2.2092, 2.1793, 2.1793,
         1.5130, 1.5113, 1.5187, 1.5187, 1.5130, 1.5187, 1.5187, 1.5187, 1.5187,
         1.7797, 1.7798, 1.7798, 1.7767, 1.7797, 1.7797, 1.7798, 1.7574, 1.7601,
         1.4410, 1.4455, 1.4455, 1.4455, 1.4374, 1.4455, 1.4418, 1.4455, 1.4455],
        [1.3215, 1.3194, 1.3034, 1.2946, 1.3183, 1.3168, 1.3178, 1.3182, 1.3182,
         1.2913, 1.2847, 1.2808, 1.2804, 1.2919, 1.2767, 1.2880, 1.2915, 1.2642,
         1.6494, 1.6231, 1.6464, 1.6458, 1.6452, 1.6452, 1.6474, 1.6489, 1.6489,
         3.4993, 3.2901, 3.2158, 3.2736, 3.4241, 3.2426, 3.4746, 3.2234, 3.2024,
         1.6522, 1.6447, 1.6431, 1.6462, 1.6491, 1.6250, 1.6505, 1.5899, 1.6163,
         1.3088, 1.3031, 1.2933, 1.3079, 1.3037, 1.2959, 1.3082, 1.3080, 1.3102],
        [1.4548, 1.4506, 1.4071, 1.4105, 1.4481, 1.4547, 1.4532, 1.4548, 1.4548,
         1.4282, 1.4256, 1.4207, 1.4163, 1.4293, 1.3899, 1.4235, 1.4293, 1.4248,
         1.7635, 1.7548, 1.7540, 1.7619, 1.7791, 1.7778, 1.7581, 1.7792, 1.7792,
         1.4799, 1.4858, 1.5214, 1.5163, 1.4853, 1.5200, 1.5084, 1.5215, 1.5184,
         2.2050, 2.1856, 2.1743, 2.1918, 2.2349, 2.2536, 2.2200, 2.3213, 2.3188,
         1.4337, 1.4237, 1.4381, 1.4483, 1.4360, 1.4451, 1.4167, 1.4423, 1.4483],
        [1.3379, 1.2465, 1.2419, 1.2611, 1.2540, 1.2645, 1.2632, 1.2038, 1.2038,
         1.2428, 1.2030, 1.2018, 1.2056, 1.2811, 1.1552, 1.1219, 1.2811, 1.1861,
         1.6036, 1.5797, 1.5614, 1.5565, 1.5804, 1.5763, 1.5963, 1.5818, 1.5818,
         1.3463, 1.3193, 1.3198, 1.3361, 1.3212, 1.3637, 1.3661, 1.3403, 1.3198,
         1.5797, 1.5791, 1.5850, 1.5744, 1.5504, 1.5541, 1.6153, 1.5038, 1.4725,
         4.1263, 3.6322, 3.7227, 3.7061, 3.7201, 3.4011, 4.1233, 3.6807, 3.4338]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 362 : 1779.0733013309316
Test loss for epoch 362 : 195.15368651782467
Test Precision for epoch 362 : 0.26153846153846155
Test Recall for epoch 362 : 0.26153846153846155
Test F1 for epoch 362 : 0.26153846153846155


theta for epoch 363 : tensor([[3.6300, 3.6508, 3.7942, 3.7429, 3.7254, 3.6116, 3.6527, 3.5523, 3.5523,
         1.2545, 1.2354, 1.2342, 1.2371, 1.2717, 1.2174, 1.1908, 1.2717, 1.2232,
         1.6070, 1.5915, 1.6155, 1.5985, 1.6040, 1.6056, 1.6127, 1.6056, 1.6056,
         1.3350, 1.3463, 1.3327, 1.3538, 1.3346, 1.3648, 1.3578, 1.3452, 1.3327,
         1.6028, 1.6184, 1.6076, 1.6040, 1.6108, 1.6007, 1.6189, 1.5734, 1.5779,
         1.2443, 1.2694, 1.2620, 1.2782, 1.2394, 1.2319, 1.2211, 1.2990, 1.2591],
        [1.3804, 1.2284, 1.2178, 1.2612, 1.2614, 1.2740, 1.2679, 1.1727, 1.1727,
         3.5810, 3.6727, 3.5080, 3.9297, 3.5821, 4.3197, 3.4391, 3.5358, 4.0503,
         1.5794, 1.5668, 1.5407, 1.5390, 1.5604, 1.5699, 1.5946, 1.5699, 1.5699,
         1.3461, 1.3120, 1.3062, 1.3645, 1.3062, 1.4021, 1.3822, 1.3506, 1.3030,
         1.5484, 1.6056, 1.5687, 1.5552, 1.5500, 1.5887, 1.6082, 1.4401, 1.5389,
         1.1490, 1.2626, 1.2353, 1.2846, 1.1431, 1.1491, 1.0726, 1.3468, 1.2255],
        [1.4533, 1.4533, 1.4516, 1.4488, 1.4492, 1.4533, 1.4491, 1.4533, 1.4533,
         1.4266, 1.4260, 1.4266, 1.4266, 1.4266, 1.4081, 1.4266, 1.4255, 1.4233,
         2.2115, 2.2116, 2.2283, 2.2037, 2.1855, 2.1836, 2.2128, 2.1828, 2.1828,
         1.5071, 1.5054, 1.5128, 1.5128, 1.5071, 1.5128, 1.5128, 1.5128, 1.5128,
         1.7824, 1.7825, 1.7825, 1.7794, 1.7824, 1.7824, 1.7825, 1.7600, 1.7627,
         1.4390, 1.4435, 1.4435, 1.4435, 1.4353, 1.4435, 1.4397, 1.4434, 1.4435],
        [1.3232, 1.3210, 1.3050, 1.2963, 1.3199, 1.3184, 1.3195, 1.3199, 1.3199,
         1.2915, 1.2849, 1.2811, 1.2807, 1.2922, 1.2770, 1.2883, 1.2918, 1.2645,
         1.6535, 1.6272, 1.6505, 1.6499, 1.6493, 1.6493, 1.6515, 1.6530, 1.6530,
         3.4934, 3.2840, 3.2096, 3.2676, 3.4181, 3.2365, 3.4687, 3.2173, 3.1962,
         1.6550, 1.6475, 1.6459, 1.6490, 1.6519, 1.6279, 1.6534, 1.5927, 1.6192,
         1.3069, 1.3013, 1.2914, 1.3061, 1.3019, 1.2941, 1.3064, 1.3062, 1.3084],
        [1.4562, 1.4519, 1.4084, 1.4118, 1.4494, 1.4561, 1.4545, 1.4562, 1.4562,
         1.4283, 1.4258, 1.4208, 1.4164, 1.4295, 1.3900, 1.4236, 1.4294, 1.4250,
         1.7673, 1.7586, 1.7578, 1.7657, 1.7829, 1.7816, 1.7619, 1.7830, 1.7830,
         1.4740, 1.4799, 1.5155, 1.5104, 1.4793, 1.5142, 1.5025, 1.5156, 1.5125,
         2.2076, 2.1882, 2.1770, 2.1944, 2.2375, 2.2562, 2.2226, 2.3239, 2.3214,
         1.4316, 1.4217, 1.4360, 1.4463, 1.4339, 1.4431, 1.4146, 1.4403, 1.4463],
        [1.3314, 1.2402, 1.2356, 1.2548, 1.2476, 1.2581, 1.2569, 1.1977, 1.1977,
         1.2396, 1.1993, 1.1980, 1.2028, 1.2785, 1.1527, 1.1200, 1.2785, 1.1836,
         1.6029, 1.5790, 1.5606, 1.5558, 1.5797, 1.5757, 1.5956, 1.5811, 1.5811,
         1.3359, 1.3089, 1.3095, 1.3257, 1.3108, 1.3532, 1.3557, 1.3299, 1.3096,
         1.5787, 1.5780, 1.5840, 1.5734, 1.5493, 1.5529, 1.6143, 1.5026, 1.4712,
         4.1332, 3.6389, 3.7294, 3.7128, 3.7269, 3.4079, 4.1303, 3.6874, 3.4405]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 363 : 1779.7768033185491
Test loss for epoch 363 : 195.32752872490806
Test Precision for epoch 363 : 0.26153846153846155
Test Recall for epoch 363 : 0.26153846153846155
Test F1 for epoch 363 : 0.26153846153846155


theta for epoch 364 : tensor([[3.6318, 3.6526, 3.7960, 3.7447, 3.7272, 3.6135, 3.6546, 3.5542, 3.5542,
         1.2650, 1.2455, 1.2444, 1.2477, 1.2825, 1.2281, 1.2015, 1.2826, 1.2340,
         1.5987, 1.5832, 1.6072, 1.5902, 1.5957, 1.5973, 1.6044, 1.5973, 1.5973,
         1.3377, 1.3490, 1.3354, 1.3564, 1.3373, 1.3674, 1.3604, 1.3478, 1.3354,
         1.5967, 1.6122, 1.6014, 1.5978, 1.6046, 1.5946, 1.6128, 1.5672, 1.5718,
         1.2382, 1.2636, 1.2561, 1.2725, 1.2332, 1.2256, 1.2150, 1.2937, 1.2531],
        [1.3835, 1.2316, 1.2210, 1.2644, 1.2646, 1.2771, 1.2711, 1.1760, 1.1760,
         3.5810, 3.6727, 3.5080, 3.9300, 3.5821, 4.3206, 3.4390, 3.5358, 4.0507,
         1.5761, 1.5635, 1.5375, 1.5358, 1.5571, 1.5666, 1.5913, 1.5666, 1.5666,
         1.3497, 1.3157, 1.3099, 1.3681, 1.3099, 1.4058, 1.3859, 1.3543, 1.3067,
         1.5459, 1.6030, 1.5662, 1.5528, 1.5475, 1.5861, 1.6056, 1.4379, 1.5365,
         1.1472, 1.2612, 1.2337, 1.2832, 1.1413, 1.1471, 1.0709, 1.3458, 1.2238],
        [1.4550, 1.4550, 1.4533, 1.4505, 1.4509, 1.4550, 1.4508, 1.4551, 1.4551,
         1.4372, 1.4366, 1.4372, 1.4372, 1.4372, 1.4187, 1.4372, 1.4361, 1.4339,
         2.2040, 2.2041, 2.2208, 2.1964, 2.1782, 2.1764, 2.2055, 2.1755, 2.1755,
         1.5103, 1.5086, 1.5160, 1.5160, 1.5103, 1.5160, 1.5160, 1.5160, 1.5160,
         1.7765, 1.7766, 1.7766, 1.7735, 1.7765, 1.7765, 1.7766, 1.7541, 1.7568,
         1.4337, 1.4382, 1.4382, 1.4382, 1.4300, 1.4382, 1.4344, 1.4381, 1.4382],
        [1.3250, 1.3228, 1.3068, 1.2980, 1.3217, 1.3202, 1.3213, 1.3217, 1.3217,
         1.3023, 1.2956, 1.2918, 1.2914, 1.3029, 1.2877, 1.2990, 1.3025, 1.2752,
         1.6456, 1.6193, 1.6426, 1.6420, 1.6414, 1.6414, 1.6437, 1.6451, 1.6451,
         3.4959, 3.2865, 3.2121, 3.2700, 3.4206, 3.2389, 3.4712, 3.2197, 3.1986,
         1.6492, 1.6417, 1.6401, 1.6432, 1.6461, 1.6220, 1.6475, 1.5868, 1.6133,
         1.3018, 1.2961, 1.2863, 1.3009, 1.2967, 1.2889, 1.3012, 1.3011, 1.3032],
        [1.4579, 1.4536, 1.4101, 1.4135, 1.4511, 1.4578, 1.4562, 1.4579, 1.4579,
         1.4389, 1.4364, 1.4314, 1.4270, 1.4400, 1.4006, 1.4342, 1.4400, 1.4355,
         1.7594, 1.7507, 1.7499, 1.7578, 1.7750, 1.7737, 1.7540, 1.7751, 1.7751,
         1.4772, 1.4831, 1.5188, 1.5136, 1.4825, 1.5174, 1.5058, 1.5188, 1.5157,
         2.2019, 2.1824, 2.1712, 2.1886, 2.2318, 2.2505, 2.2169, 2.3183, 2.3157,
         1.4263, 1.4163, 1.4307, 1.4410, 1.4286, 1.4378, 1.4092, 1.4350, 1.4410],
        [1.3245, 1.2325, 1.2279, 1.2472, 1.2400, 1.2505, 1.2493, 1.1896, 1.1896,
         1.2453, 1.2039, 1.2026, 1.2083, 1.2850, 1.1581, 1.1251, 1.2850, 1.1892,
         1.5907, 1.5668, 1.5484, 1.5434, 1.5674, 1.5633, 1.5834, 1.5688, 1.5688,
         1.3319, 1.3048, 1.3053, 1.3216, 1.3067, 1.3494, 1.3518, 1.3259, 1.3053,
         1.5685, 1.5679, 1.5739, 1.5633, 1.5392, 1.5428, 1.6043, 1.4923, 1.4608,
         4.1414, 3.6468, 3.7374, 3.7207, 3.7348, 3.4157, 4.1385, 3.6953, 3.4484]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 364 : 1779.0856024127106
Test loss for epoch 364 : 195.6421832280372
Test Precision for epoch 364 : 0.26153846153846155
Test Recall for epoch 364 : 0.26153846153846155
Test F1 for epoch 364 : 0.26153846153846155


theta for epoch 365 : tensor([[3.6314, 3.6523, 3.7957, 3.7444, 3.7269, 3.6131, 3.6543, 3.5538, 3.5538,
         1.2753, 1.2554, 1.2543, 1.2580, 1.2931, 1.2385, 1.2117, 1.2931, 1.2444,
         1.5923, 1.5768, 1.6009, 1.5838, 1.5893, 1.5910, 1.5980, 1.5909, 1.5909,
         1.3422, 1.3535, 1.3399, 1.3609, 1.3419, 1.3720, 1.3650, 1.3524, 1.3400,
         1.5905, 1.6061, 1.5953, 1.5917, 1.5984, 1.5884, 1.6066, 1.5610, 1.5656,
         1.2313, 1.2571, 1.2494, 1.2662, 1.2262, 1.2184, 1.2095, 1.2877, 1.2464],
        [1.3784, 1.2274, 1.2167, 1.2600, 1.2602, 1.2728, 1.2667, 1.1722, 1.1722,
         3.5864, 3.6781, 3.5133, 3.9356, 3.5875, 4.3268, 3.4442, 3.5411, 4.0565,
         1.5701, 1.5576, 1.5315, 1.5299, 1.5513, 1.5607, 1.5853, 1.5608, 1.5608,
         1.3502, 1.3161, 1.3105, 1.3685, 1.3103, 1.4061, 1.3863, 1.3548, 1.3073,
         1.5397, 1.5966, 1.5599, 1.5465, 1.5413, 1.5797, 1.5992, 1.4317, 1.5302,
         1.1404, 1.2547, 1.2271, 1.2769, 1.1343, 1.1400, 1.0665, 1.3398, 1.2172],
        [1.4509, 1.4508, 1.4492, 1.4464, 1.4468, 1.4509, 1.4466, 1.4509, 1.4509,
         1.4476, 1.4469, 1.4475, 1.4475, 1.4476, 1.4291, 1.4476, 1.4464, 1.4442,
         2.1985, 2.1986, 2.2153, 2.1911, 2.1729, 2.1711, 2.2002, 2.1702, 2.1702,
         1.5156, 1.5139, 1.5213, 1.5213, 1.5156, 1.5213, 1.5213, 1.5213, 1.5213,
         1.7707, 1.7708, 1.7708, 1.7677, 1.7707, 1.7707, 1.7708, 1.7483, 1.7511,
         1.4281, 1.4326, 1.4326, 1.4326, 1.4244, 1.4326, 1.4288, 1.4326, 1.4326],
        [1.3206, 1.3185, 1.3024, 1.2937, 1.3174, 1.3158, 1.3169, 1.3173, 1.3173,
         1.3127, 1.3061, 1.3022, 1.3019, 1.3134, 1.2982, 1.3095, 1.3130, 1.2857,
         1.6399, 1.6135, 1.6368, 1.6362, 1.6356, 1.6357, 1.6379, 1.6394, 1.6394,
         3.5005, 3.2910, 3.2166, 3.2745, 3.4252, 3.2434, 3.4757, 3.2242, 3.2032,
         1.6435, 1.6360, 1.6344, 1.6375, 1.6404, 1.6163, 1.6418, 1.5811, 1.6076,
         1.2962, 1.2906, 1.2808, 1.2955, 1.2912, 1.2833, 1.2957, 1.2957, 1.2977],
        [1.4537, 1.4494, 1.4059, 1.4092, 1.4469, 1.4536, 1.4521, 1.4537, 1.4537,
         1.4492, 1.4467, 1.4418, 1.4373, 1.4504, 1.4109, 1.4445, 1.4504, 1.4459,
         1.7536, 1.7449, 1.7441, 1.7520, 1.7692, 1.7679, 1.7482, 1.7694, 1.7694,
         1.4825, 1.4883, 1.5241, 1.5189, 1.4878, 1.5227, 1.5111, 1.5241, 1.5210,
         2.1963, 2.1769, 2.1656, 2.1831, 2.2262, 2.2449, 2.2113, 2.3128, 2.3102,
         1.4207, 1.4108, 1.4251, 1.4354, 1.4230, 1.4322, 1.4036, 1.4294, 1.4354],
        [1.3198, 1.2263, 1.2219, 1.2413, 1.2341, 1.2446, 1.2434, 1.1825, 1.1825,
         1.2536, 1.2110, 1.2096, 1.2162, 1.2943, 1.1658, 1.1316, 1.2944, 1.1970,
         1.5835, 1.5595, 1.5412, 1.5360, 1.5600, 1.5559, 1.5762, 1.5614, 1.5614,
         1.3338, 1.3066, 1.3067, 1.3236, 1.3083, 1.3517, 1.3540, 1.3277, 1.3067,
         1.5612, 1.5607, 1.5665, 1.5559, 1.5319, 1.5356, 1.5972, 1.4850, 1.4535,
         4.1438, 3.6488, 3.7394, 3.7227, 3.7369, 3.4178, 4.1408, 3.6973, 3.4503]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 365 : 1779.4925205338895
Test loss for epoch 365 : 195.77765219432712
Test Precision for epoch 365 : 0.26153846153846155
Test Recall for epoch 365 : 0.26153846153846155
Test F1 for epoch 365 : 0.26153846153846155


theta for epoch 366 : tensor([[3.6302, 3.6510, 3.7944, 3.7432, 3.7257, 3.6119, 3.6530, 3.5526, 3.5526,
         1.2704, 1.2503, 1.2491, 1.2532, 1.2885, 1.2342, 1.2069, 1.2886, 1.2397,
         1.5974, 1.5819, 1.6059, 1.5890, 1.5944, 1.5961, 1.6031, 1.5961, 1.5961,
         1.3410, 1.3523, 1.3388, 1.3597, 1.3407, 1.3707, 1.3637, 1.3512, 1.3388,
         1.5930, 1.6085, 1.5977, 1.5941, 1.6009, 1.5909, 1.6091, 1.5635, 1.5681,
         1.2336, 1.2592, 1.2516, 1.2682, 1.2285, 1.2208, 1.2133, 1.2895, 1.2486],
        [1.3762, 1.2262, 1.2154, 1.2587, 1.2589, 1.2714, 1.2653, 1.1715, 1.1715,
         3.5880, 3.6798, 3.5149, 3.9375, 3.5891, 4.3293, 3.4457, 3.5427, 4.0586,
         1.5707, 1.5583, 1.5320, 1.5308, 1.5522, 1.5616, 1.5860, 1.5617, 1.5617,
         1.3464, 1.3124, 1.3071, 1.3647, 1.3067, 1.4021, 1.3824, 1.3511, 1.3039,
         1.5391, 1.5959, 1.5594, 1.5460, 1.5406, 1.5791, 1.5984, 1.4310, 1.5296,
         1.1392, 1.2529, 1.2256, 1.2748, 1.1333, 1.1394, 1.0679, 1.3371, 1.2158],
        [1.4547, 1.4546, 1.4530, 1.4502, 1.4506, 1.4547, 1.4504, 1.4547, 1.4547,
         1.4420, 1.4413, 1.4419, 1.4419, 1.4420, 1.4235, 1.4420, 1.4408, 1.4386,
         2.2027, 2.2028, 2.2195, 2.1952, 2.1769, 2.1751, 2.2043, 2.1743, 2.1743,
         1.5137, 1.5121, 1.5195, 1.5195, 1.5138, 1.5195, 1.5194, 1.5195, 1.5195,
         1.7726, 1.7727, 1.7727, 1.7696, 1.7726, 1.7726, 1.7727, 1.7502, 1.7529,
         1.4298, 1.4343, 1.4343, 1.4343, 1.4262, 1.4343, 1.4306, 1.4343, 1.4343],
        [1.3242, 1.3221, 1.3061, 1.2973, 1.3211, 1.3195, 1.3206, 1.3210, 1.3210,
         1.3072, 1.3005, 1.2967, 1.2963, 1.3079, 1.2927, 1.3040, 1.3075, 1.2802,
         1.6444, 1.6181, 1.6414, 1.6408, 1.6402, 1.6403, 1.6425, 1.6439, 1.6439,
         3.4987, 3.2891, 3.2147, 3.2726, 3.4234, 3.2415, 3.4739, 3.2223, 3.2012,
         1.6454, 1.6379, 1.6363, 1.6394, 1.6423, 1.6182, 1.6438, 1.5831, 1.6095,
         1.2981, 1.2925, 1.2826, 1.2973, 1.2930, 1.2852, 1.2976, 1.2975, 1.2996],
        [1.4575, 1.4533, 1.4098, 1.4131, 1.4507, 1.4574, 1.4559, 1.4575, 1.4575,
         1.4437, 1.4411, 1.4362, 1.4317, 1.4448, 1.4053, 1.4390, 1.4448, 1.4403,
         1.7580, 1.7493, 1.7485, 1.7564, 1.7736, 1.7723, 1.7525, 1.7737, 1.7737,
         1.4806, 1.4865, 1.5222, 1.5171, 1.4860, 1.5208, 1.5092, 1.5223, 1.5192,
         2.1981, 2.1787, 2.1674, 2.1849, 2.2280, 2.2467, 2.2132, 2.3145, 2.3120,
         1.4224, 1.4125, 1.4269, 1.4371, 1.4248, 1.4339, 1.4054, 1.4311, 1.4372],
        [1.3455, 1.2511, 1.2468, 1.2662, 1.2591, 1.2696, 1.2684, 1.2066, 1.2066,
         1.2603, 1.2166, 1.2152, 1.2227, 1.3019, 1.1734, 1.1367, 1.3019, 1.2033,
         1.6009, 1.5770, 1.5589, 1.5534, 1.5772, 1.5731, 1.5936, 1.5786, 1.5786,
         1.3495, 1.3225, 1.3220, 1.3395, 1.3241, 1.3677, 1.3698, 1.3434, 1.3221,
         1.5748, 1.5746, 1.5801, 1.5695, 1.5458, 1.5496, 1.6109, 1.4991, 1.4679,
         4.1192, 3.6239, 3.7145, 3.6979, 3.7120, 3.3928, 4.1162, 3.6725, 3.4254]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 366 : 1779.463781950526
Test loss for epoch 366 : 194.99076877544866
Test Precision for epoch 366 : 0.26153846153846155
Test Recall for epoch 366 : 0.26153846153846155
Test F1 for epoch 366 : 0.26153846153846155


theta for epoch 367 : tensor([[3.6271, 3.6479, 3.7913, 3.7400, 3.7225, 3.6088, 3.6499, 3.5494, 3.5494,
         1.2576, 1.2371, 1.2359, 1.2404, 1.2761, 1.2216, 1.1938, 1.2761, 1.2268,
         1.6048, 1.5893, 1.6133, 1.5964, 1.6018, 1.6035, 1.6105, 1.6035, 1.6035,
         1.3338, 1.3451, 1.3316, 1.3525, 1.3335, 1.3634, 1.3564, 1.3439, 1.3316,
         1.5993, 1.6148, 1.6041, 1.6005, 1.6072, 1.5972, 1.6154, 1.5699, 1.5745,
         1.2475, 1.2730, 1.2654, 1.2819, 1.2424, 1.2347, 1.2284, 1.3031, 1.2623],
        [1.3652, 1.2164, 1.2054, 1.2486, 1.2488, 1.2614, 1.2553, 1.1623, 1.1623,
         3.5931, 3.6850, 3.5200, 3.9429, 3.5942, 4.3354, 3.4507, 3.5477, 4.0642,
         1.5690, 1.5566, 1.5301, 1.5291, 1.5506, 1.5602, 1.5844, 1.5602, 1.5602,
         1.3354, 1.3014, 1.2964, 1.3536, 1.2958, 1.3908, 1.3711, 1.3401, 1.2932,
         1.5377, 1.5945, 1.5581, 1.5446, 1.5392, 1.5777, 1.5969, 1.4290, 1.5281,
         1.1410, 1.2547, 1.2275, 1.2766, 1.1352, 1.1415, 1.0715, 1.3386, 1.2178],
        [1.4502, 1.4501, 1.4485, 1.4457, 1.4461, 1.4502, 1.4459, 1.4502, 1.4502,
         1.4288, 1.4282, 1.4288, 1.4288, 1.4288, 1.4103, 1.4288, 1.4277, 1.4255,
         2.2095, 2.2096, 2.2263, 2.2017, 2.1835, 2.1817, 2.2108, 2.1808, 2.1808,
         1.5065, 1.5048, 1.5122, 1.5122, 1.5065, 1.5122, 1.5122, 1.5122, 1.5122,
         1.7787, 1.7788, 1.7788, 1.7757, 1.7787, 1.7787, 1.7788, 1.7564, 1.7591,
         1.4438, 1.4482, 1.4482, 1.4482, 1.4401, 1.4482, 1.4445, 1.4482, 1.4482],
        [1.3193, 1.3173, 1.3013, 1.2924, 1.3162, 1.3146, 1.3157, 1.3162, 1.3162,
         1.2941, 1.2875, 1.2836, 1.2833, 1.2949, 1.2796, 1.2909, 1.2945, 1.2671,
         1.6518, 1.6254, 1.6487, 1.6481, 1.6475, 1.6476, 1.6498, 1.6513, 1.6513,
         3.4922, 3.2825, 3.2079, 3.2659, 3.4168, 3.2348, 3.4674, 3.2156, 3.1945,
         1.6517, 1.6442, 1.6426, 1.6457, 1.6486, 1.6245, 1.6500, 1.5893, 1.6158,
         1.3122, 1.3066, 1.2967, 1.3114, 1.3071, 1.2993, 1.3117, 1.3116, 1.3136],
        [1.4530, 1.4488, 1.4054, 1.4086, 1.4462, 1.4529, 1.4514, 1.4530, 1.4530,
         1.4305, 1.4280, 1.4230, 1.4186, 1.4317, 1.3922, 1.4258, 1.4317, 1.4272,
         1.7651, 1.7564, 1.7556, 1.7635, 1.7807, 1.7795, 1.7597, 1.7809, 1.7809,
         1.4733, 1.4792, 1.5150, 1.5099, 1.4787, 1.5136, 1.5020, 1.5150, 1.5119,
         2.2041, 2.1847, 2.1734, 2.1909, 2.2340, 2.2527, 2.2191, 2.3204, 2.3179,
         1.4364, 1.4264, 1.4408, 1.4510, 1.4387, 1.4478, 1.4194, 1.4450, 1.4511],
        [1.3607, 1.2651, 1.2611, 1.2805, 1.2734, 1.2839, 1.2826, 1.2200, 1.2200,
         1.2573, 1.2125, 1.2111, 1.2193, 1.2999, 1.1709, 1.1316, 1.2999, 1.1996,
         1.6175, 1.5936, 1.5756, 1.5698, 1.5935, 1.5895, 1.6101, 1.5949, 1.5949,
         1.3568, 1.3298, 1.3288, 1.3469, 1.3312, 1.3753, 1.3772, 1.3506, 1.3289,
         1.5894, 1.5894, 1.5947, 1.5842, 1.5605, 1.5645, 1.6257, 1.5141, 1.4831,
         4.1050, 3.6096, 3.7001, 3.6835, 3.6977, 3.3784, 4.1020, 3.6582, 3.4110]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 367 : 1779.202645582448
Test loss for epoch 367 : 194.9592141219033
Test Precision for epoch 367 : 0.26153846153846155
Test Recall for epoch 367 : 0.26153846153846155
Test F1 for epoch 367 : 0.26153846153846155


theta for epoch 368 : tensor([[3.6244, 3.6451, 3.7886, 3.7373, 3.7197, 3.6060, 3.6471, 3.5465, 3.5465,
         1.2502, 1.2292, 1.2280, 1.2327, 1.2691, 1.2149, 1.1853, 1.2691, 1.2198,
         1.6012, 1.5858, 1.6097, 1.5928, 1.5983, 1.5999, 1.6069, 1.5999, 1.5999,
         1.3339, 1.3452, 1.3318, 1.3526, 1.3336, 1.3634, 1.3565, 1.3440, 1.3318,
         1.6006, 1.6161, 1.6053, 1.6017, 1.6085, 1.5985, 1.6167, 1.5712, 1.5758,
         1.2618, 1.2872, 1.2797, 1.2962, 1.2567, 1.2490, 1.2437, 1.3172, 1.2766],
        [1.3572, 1.2091, 1.1981, 1.2413, 1.2415, 1.2540, 1.2479, 1.1555, 1.1555,
         3.5971, 3.6891, 3.5241, 3.9473, 3.5982, 4.3403, 3.4548, 3.5517, 4.0686,
         1.5619, 1.5495, 1.5229, 1.5221, 1.5436, 1.5532, 1.5773, 1.5532, 1.5532,
         1.3303, 1.2963, 1.2915, 1.3486, 1.2909, 1.3856, 1.3660, 1.3351, 1.2884,
         1.5342, 1.5910, 1.5546, 1.5411, 1.5356, 1.5741, 1.5934, 1.4252, 1.5246,
         1.1450, 1.2590, 1.2318, 1.2808, 1.1393, 1.1459, 1.0771, 1.3427, 1.2221],
        [1.4466, 1.4465, 1.4449, 1.4421, 1.4425, 1.4466, 1.4423, 1.4466, 1.4466,
         1.4211, 1.4205, 1.4211, 1.4211, 1.4211, 1.4026, 1.4211, 1.4200, 1.4178,
         2.2060, 2.2062, 2.2228, 2.1984, 2.1802, 2.1784, 2.2075, 2.1775, 2.1775,
         1.5065, 1.5048, 1.5122, 1.5122, 1.5065, 1.5122, 1.5122, 1.5122, 1.5122,
         1.7798, 1.7799, 1.7799, 1.7768, 1.7798, 1.7798, 1.7799, 1.7575, 1.7602,
         1.4581, 1.4625, 1.4625, 1.4625, 1.4544, 1.4625, 1.4588, 1.4625, 1.4625],
        [1.3152, 1.3132, 1.2972, 1.2884, 1.3121, 1.3106, 1.3117, 1.3121, 1.3121,
         1.2865, 1.2798, 1.2759, 1.2756, 1.2872, 1.2719, 1.2832, 1.2868, 1.2594,
         1.6482, 1.6218, 1.6451, 1.6445, 1.6440, 1.6440, 1.6462, 1.6477, 1.6477,
         3.4923, 3.2824, 3.2078, 3.2658, 3.4168, 3.2347, 3.4674, 3.2155, 3.1944,
         1.6528, 1.6454, 1.6438, 1.6468, 1.6498, 1.6257, 1.6512, 1.5905, 1.6170,
         1.3266, 1.3210, 1.3111, 1.3258, 1.3215, 1.3137, 1.3262, 1.3260, 1.3281],
        [1.4494, 1.4452, 1.4019, 1.4050, 1.4426, 1.4493, 1.4478, 1.4494, 1.4494,
         1.4229, 1.4203, 1.4153, 1.4109, 1.4240, 1.3845, 1.4181, 1.4240, 1.4195,
         1.7615, 1.7528, 1.7520, 1.7599, 1.7771, 1.7758, 1.7561, 1.7773, 1.7773,
         1.4733, 1.4792, 1.5150, 1.5099, 1.4787, 1.5136, 1.5020, 1.5150, 1.5119,
         2.2052, 2.1858, 2.1745, 2.1920, 2.2351, 2.2538, 2.2203, 2.3215, 2.3190,
         1.4507, 1.4407, 1.4551, 1.4653, 1.4530, 1.4621, 1.4337, 1.4593, 1.4654],
        [1.3719, 1.2758, 1.2718, 1.2912, 1.2842, 1.2946, 1.2934, 1.2302, 1.2302,
         1.2571, 1.2111, 1.2096, 1.2185, 1.3008, 1.1719, 1.1285, 1.3008, 1.1997,
         1.6221, 1.5983, 1.5804, 1.5745, 1.5980, 1.5941, 1.6148, 1.5995, 1.5995,
         1.3668, 1.3399, 1.3386, 1.3571, 1.3412, 1.3855, 1.3873, 1.3606, 1.3387,
         1.5973, 1.5975, 1.6025, 1.5921, 1.5686, 1.5726, 1.6336, 1.5223, 1.4915,
         4.0955, 3.5998, 3.6904, 3.6737, 3.6879, 3.3685, 4.0924, 3.6485, 3.4011]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 368 : 1779.600543775926
Test loss for epoch 368 : 195.12028570618293
Test Precision for epoch 368 : 0.26153846153846155
Test Recall for epoch 368 : 0.26153846153846155
Test F1 for epoch 368 : 0.26153846153846155


theta for epoch 369 : tensor([[3.6200, 3.6406, 3.7841, 3.7329, 3.7153, 3.6015, 3.6427, 3.5420, 3.5420,
         1.2541, 1.2330, 1.2318, 1.2367, 1.2730, 1.2199, 1.1895, 1.2730, 1.2246,
         1.5966, 1.5812, 1.6051, 1.5882, 1.5937, 1.5953, 1.6023, 1.5953, 1.5953,
         1.3424, 1.3537, 1.3403, 1.3611, 1.3422, 1.3719, 1.3650, 1.3526, 1.3404,
         1.5973, 1.6128, 1.6020, 1.5984, 1.6052, 1.5952, 1.6133, 1.5679, 1.5725,
         1.2610, 1.2863, 1.2788, 1.2952, 1.2560, 1.2483, 1.2438, 1.3161, 1.2757],
        [1.3751, 1.2275, 1.2165, 1.2596, 1.2598, 1.2723, 1.2662, 1.1741, 1.1741,
         3.5811, 3.6732, 3.5081, 3.9316, 3.5822, 4.3252, 3.4388, 3.5357, 4.0530,
         1.5705, 1.5582, 1.5318, 1.5311, 1.5525, 1.5619, 1.5858, 1.5620, 1.5620,
         1.3471, 1.3132, 1.3086, 1.3653, 1.3078, 1.4022, 1.3827, 1.3519, 1.3054,
         1.5432, 1.5996, 1.5635, 1.5500, 1.5446, 1.5828, 1.6019, 1.4350, 1.5337,
         1.1574, 1.2706, 1.2437, 1.2922, 1.1517, 1.1585, 1.0913, 1.3535, 1.2341],
        [1.4526, 1.4526, 1.4509, 1.4481, 1.4486, 1.4526, 1.4483, 1.4526, 1.4526,
         1.4237, 1.4231, 1.4237, 1.4237, 1.4237, 1.4052, 1.4237, 1.4226, 1.4204,
         2.2004, 2.2005, 2.2172, 2.1930, 2.1747, 2.1729, 2.2021, 2.1721, 2.1721,
         1.5132, 1.5115, 1.5189, 1.5189, 1.5132, 1.5189, 1.5189, 1.5189, 1.5189,
         1.7753, 1.7754, 1.7754, 1.7723, 1.7753, 1.7753, 1.7754, 1.7530, 1.7557,
         1.4557, 1.4601, 1.4601, 1.4601, 1.4520, 1.4601, 1.4564, 1.4601, 1.4601],
        [1.3210, 1.3191, 1.3031, 1.2943, 1.3180, 1.3164, 1.3175, 1.3181, 1.3181,
         1.2891, 1.2824, 1.2786, 1.2783, 1.2899, 1.2747, 1.2858, 1.2895, 1.2621,
         1.6422, 1.6159, 1.6392, 1.6386, 1.6380, 1.6381, 1.6403, 1.6418, 1.6418,
         3.4979, 3.2880, 3.2135, 3.2715, 3.4225, 3.2403, 3.4731, 3.2211, 3.2000,
         1.6484, 1.6409, 1.6393, 1.6424, 1.6453, 1.6212, 1.6468, 1.5860, 1.6125,
         1.3243, 1.3187, 1.3088, 1.3235, 1.3192, 1.3114, 1.3239, 1.3237, 1.3257],
        [1.4555, 1.4513, 1.4081, 1.4111, 1.4487, 1.4554, 1.4539, 1.4555, 1.4555,
         1.4254, 1.4229, 1.4179, 1.4135, 1.4266, 1.3870, 1.4207, 1.4266, 1.4220,
         1.7555, 1.7469, 1.7461, 1.7540, 1.7712, 1.7699, 1.7501, 1.7713, 1.7713,
         1.4800, 1.4858, 1.5217, 1.5166, 1.4854, 1.5203, 1.5087, 1.5217, 1.5186,
         2.2009, 2.1814, 2.1701, 2.1876, 2.2307, 2.2494, 2.2159, 2.3172, 2.3146,
         1.4483, 1.4383, 1.4527, 1.4629, 1.4506, 1.4597, 1.4313, 1.4569, 1.4630],
        [1.3875, 1.2916, 1.2877, 1.3070, 1.3000, 1.3104, 1.3092, 1.2461, 1.2461,
         1.2659, 1.2194, 1.2179, 1.2272, 1.3098, 1.1823, 1.1366, 1.3099, 1.2094,
         1.6241, 1.6003, 1.5826, 1.5766, 1.6001, 1.5961, 1.6168, 1.6015, 1.6015,
         1.3813, 1.3545, 1.3531, 1.3716, 1.3558, 1.4000, 1.4018, 1.3752, 1.3532,
         1.5996, 1.5999, 1.6048, 1.5945, 1.5711, 1.5751, 1.6359, 1.5250, 1.4944,
         4.0809, 3.5849, 3.6755, 3.6589, 3.6730, 3.3536, 4.0778, 3.6337, 3.3862]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 369 : 1780.4042779559402
Test loss for epoch 369 : 194.2583574428341
Test Precision for epoch 369 : 0.26153846153846155
Test Recall for epoch 369 : 0.26153846153846155
Test F1 for epoch 369 : 0.26153846153846155


theta for epoch 370 : tensor([[3.6125, 3.6331, 3.7766, 3.7253, 3.7078, 3.5940, 3.6352, 3.5343, 3.5343,
         1.2679, 1.2466, 1.2453, 1.2503, 1.2871, 1.2342, 1.2025, 1.2871, 1.2388,
         1.5965, 1.5811, 1.6050, 1.5881, 1.5935, 1.5952, 1.6022, 1.5952, 1.5952,
         1.3390, 1.3503, 1.3368, 1.3576, 1.3387, 1.3685, 1.3616, 1.3491, 1.3369,
         1.5936, 1.6092, 1.5984, 1.5948, 1.6016, 1.5916, 1.6097, 1.5643, 1.5689,
         1.2546, 1.2798, 1.2723, 1.2887, 1.2496, 1.2420, 1.2379, 1.3096, 1.2693],
        [1.3816, 1.2343, 1.2233, 1.2663, 1.2665, 1.2790, 1.2729, 1.1809, 1.1809,
         3.5751, 3.6672, 3.5020, 3.9257, 3.5761, 4.3199, 3.4327, 3.5297, 4.0473,
         1.5770, 1.5647, 1.5384, 1.5377, 1.5590, 1.5684, 1.5923, 1.5684, 1.5684,
         1.3521, 1.3183, 1.3136, 1.3702, 1.3129, 1.4070, 1.3875, 1.3568, 1.3105,
         1.5469, 1.6030, 1.5670, 1.5537, 1.5482, 1.5863, 1.6053, 1.4391, 1.5374,
         1.1608, 1.2734, 1.2467, 1.2949, 1.1552, 1.1620, 1.0962, 1.3558, 1.2372],
        [1.4479, 1.4478, 1.4462, 1.4434, 1.4438, 1.4479, 1.4436, 1.4479, 1.4479,
         1.4368, 1.4362, 1.4368, 1.4368, 1.4368, 1.4183, 1.4368, 1.4357, 1.4335,
         2.1996, 2.1997, 2.2164, 2.1922, 2.1740, 2.1721, 2.2013, 2.1713, 2.1713,
         1.5087, 1.5070, 1.5144, 1.5144, 1.5087, 1.5144, 1.5144, 1.5144, 1.5144,
         1.7711, 1.7712, 1.7712, 1.7681, 1.7711, 1.7711, 1.7712, 1.7487, 1.7514,
         1.4483, 1.4527, 1.4527, 1.4527, 1.4446, 1.4527, 1.4490, 1.4527, 1.4527],
        [1.3159, 1.3140, 1.2981, 1.2892, 1.3129, 1.3113, 1.3125, 1.3130, 1.3130,
         1.3024, 1.2957, 1.2918, 1.2915, 1.3031, 1.2879, 1.2990, 1.3027, 1.2754,
         1.6415, 1.6152, 1.6385, 1.6379, 1.6373, 1.6373, 1.6396, 1.6410, 1.6410,
         3.4933, 3.2833, 3.2087, 3.2667, 3.4178, 3.2355, 3.4684, 3.2163, 3.1952,
         1.6443, 1.6368, 1.6352, 1.6383, 1.6412, 1.6171, 1.6426, 1.5819, 1.6084,
         1.3170, 1.3114, 1.3015, 1.3162, 1.3119, 1.3041, 1.3166, 1.3164, 1.3185],
        [1.4507, 1.4466, 1.4033, 1.4063, 1.4440, 1.4506, 1.4492, 1.4507, 1.4507,
         1.4385, 1.4360, 1.4310, 1.4266, 1.4397, 1.4001, 1.4338, 1.4396, 1.4351,
         1.7547, 1.7460, 1.7452, 1.7531, 1.7704, 1.7691, 1.7493, 1.7705, 1.7705,
         1.4755, 1.4813, 1.5172, 1.5120, 1.4809, 1.5158, 1.5041, 1.5172, 1.5141,
         2.1968, 2.1773, 2.1660, 2.1835, 2.2267, 2.2453, 2.2118, 2.3132, 2.3106,
         1.4408, 1.4309, 1.4453, 1.4555, 1.4431, 1.4523, 1.4238, 1.4495, 1.4556],
        [1.3895, 1.2944, 1.2905, 1.3097, 1.3028, 1.3131, 1.3119, 1.2494, 1.2494,
         1.2813, 1.2343, 1.2328, 1.2424, 1.3258, 1.1988, 1.1505, 1.3258, 1.2255,
         1.6272, 1.6035, 1.5858, 1.5799, 1.6033, 1.5993, 1.6199, 1.6047, 1.6047,
         1.3822, 1.3555, 1.3542, 1.3725, 1.3568, 1.4007, 1.4025, 1.3761, 1.3543,
         1.5993, 1.5996, 1.6046, 1.5942, 1.5709, 1.5749, 1.6354, 1.5250, 1.4945,
         4.0705, 3.5742, 3.6649, 3.6482, 3.6624, 3.3429, 4.0673, 3.6231, 3.3755]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 370 : 1780.3834973985595
Test loss for epoch 370 : 194.00698893930758
Test Precision for epoch 370 : 0.26153846153846155
Test Recall for epoch 370 : 0.26153846153846155
Test F1 for epoch 370 : 0.26153846153846155


theta for epoch 371 : tensor([[3.6058, 3.6262, 3.7699, 3.7186, 3.7010, 3.5872, 3.6284, 3.5274, 3.5274,
         1.2788, 1.2569, 1.2556, 1.2609, 1.2986, 1.2451, 1.2116, 1.2986, 1.2496,
         1.5979, 1.5824, 1.6064, 1.5893, 1.5948, 1.5965, 1.6036, 1.5964, 1.5964,
         1.3286, 1.3398, 1.3262, 1.3472, 1.3282, 1.3582, 1.3513, 1.3387, 1.3263,
         1.5920, 1.6076, 1.5967, 1.5932, 1.5999, 1.5900, 1.6082, 1.5627, 1.5673,
         1.2532, 1.2785, 1.2709, 1.2874, 1.2482, 1.2405, 1.2367, 1.3083, 1.2679],
        [1.3806, 1.2329, 1.2220, 1.2649, 1.2651, 1.2776, 1.2715, 1.1793, 1.1793,
         3.5749, 3.6671, 3.5018, 3.9258, 3.5759, 4.3205, 3.4324, 3.5294, 4.0475,
         1.5796, 1.5674, 1.5411, 1.5402, 1.5615, 1.5709, 1.5949, 1.5710, 1.5710,
         1.3483, 1.3146, 1.3098, 1.3664, 1.3092, 1.4031, 1.3837, 1.3530, 1.3067,
         1.5473, 1.6035, 1.5674, 1.5541, 1.5487, 1.5868, 1.6058, 1.4397, 1.5378,
         1.1624, 1.2750, 1.2483, 1.2964, 1.1568, 1.1637, 1.0988, 1.3572, 1.2388],
        [1.4398, 1.4397, 1.4381, 1.4353, 1.4357, 1.4398, 1.4355, 1.4398, 1.4398,
         1.4476, 1.4470, 1.4476, 1.4476, 1.4476, 1.4291, 1.4476, 1.4465, 1.4443,
         2.2007, 2.2008, 2.2175, 2.1933, 2.1750, 2.1732, 2.2024, 2.1724, 2.1724,
         1.4979, 1.4963, 1.5037, 1.5037, 1.4980, 1.5037, 1.5037, 1.5037, 1.5037,
         1.7694, 1.7695, 1.7695, 1.7664, 1.7694, 1.7694, 1.7695, 1.7470, 1.7497,
         1.4463, 1.4508, 1.4508, 1.4508, 1.4427, 1.4508, 1.4470, 1.4508, 1.4508],
        [1.3076, 1.3057, 1.2898, 1.2809, 1.3046, 1.3030, 1.3041, 1.3047, 1.3047,
         1.3134, 1.3066, 1.3028, 1.3025, 1.3141, 1.2989, 1.3100, 1.3137, 1.2863,
         1.6429, 1.6165, 1.6399, 1.6392, 1.6387, 1.6387, 1.6409, 1.6424, 1.6424,
         3.4826, 3.2724, 3.1977, 3.2558, 3.4071, 3.2247, 3.4578, 3.2054, 3.1843,
         1.6427, 1.6353, 1.6336, 1.6367, 1.6396, 1.6155, 1.6411, 1.5803, 1.6068,
         1.3153, 1.3097, 1.2998, 1.3145, 1.3102, 1.3024, 1.3149, 1.3147, 1.3168],
        [1.4427, 1.4385, 1.3952, 1.3982, 1.4359, 1.4426, 1.4411, 1.4426, 1.4426,
         1.4493, 1.4468, 1.4418, 1.4374, 1.4505, 1.4109, 1.4446, 1.4504, 1.4459,
         1.7558, 1.7472, 1.7463, 1.7542, 1.7715, 1.7702, 1.7504, 1.7717, 1.7717,
         1.4647, 1.4705, 1.5064, 1.5013, 1.4701, 1.5050, 1.4934, 1.5065, 1.5034,
         2.1951, 2.1756, 2.1644, 2.1819, 2.2250, 2.2437, 2.2101, 2.3117, 2.3091,
         1.4389, 1.4290, 1.4434, 1.4536, 1.4412, 1.4504, 1.4218, 1.4476, 1.4537],
        [1.3833, 1.2896, 1.2855, 1.3046, 1.2977, 1.3079, 1.3067, 1.2452, 1.2452,
         1.2920, 1.2445, 1.2428, 1.2528, 1.3369, 1.2101, 1.1595, 1.3369, 1.2364,
         1.6289, 1.6053, 1.5875, 1.5819, 1.6052, 1.6013, 1.6216, 1.6066, 1.6066,
         1.3738, 1.3472, 1.3462, 1.3641, 1.3486, 1.3920, 1.3939, 1.3677, 1.3463,
         1.5987, 1.5988, 1.6039, 1.5936, 1.5702, 1.5741, 1.6345, 1.5245, 1.4939,
         4.0673, 3.5709, 3.6615, 3.6449, 3.6590, 3.3396, 4.0641, 3.6198, 3.3722]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 371 : 1781.1335099809326
Test loss for epoch 371 : 194.2048298401662
Test Precision for epoch 371 : 0.26153846153846155
Test Recall for epoch 371 : 0.26153846153846155
Test F1 for epoch 371 : 0.26153846153846155


theta for epoch 372 : tensor([[3.6111, 3.6316, 3.7752, 3.7239, 3.7063, 3.5925, 3.6337, 3.5328, 3.5328,
         1.2699, 1.2473, 1.2459, 1.2514, 1.2903, 1.2357, 1.2001, 1.2903, 1.2400,
         1.5972, 1.5816, 1.6057, 1.5884, 1.5939, 1.5956, 1.6028, 1.5955, 1.5955,
         1.3302, 1.3415, 1.3277, 1.3490, 1.3298, 1.3601, 1.3531, 1.3403, 1.3277,
         1.5930, 1.6088, 1.5978, 1.5942, 1.6010, 1.5911, 1.6094, 1.5637, 1.5683,
         1.2578, 1.2832, 1.2756, 1.2922, 1.2527, 1.2450, 1.2412, 1.3132, 1.2725],
        [1.3810, 1.2318, 1.2211, 1.2641, 1.2643, 1.2768, 1.2707, 1.1775, 1.1775,
         3.5754, 3.6677, 3.5024, 3.9267, 3.5764, 4.3220, 3.4330, 3.5299, 4.0485,
         1.5767, 1.5643, 1.5381, 1.5370, 1.5583, 1.5678, 1.5919, 1.5678, 1.5678,
         1.3467, 1.3130, 1.3078, 1.3649, 1.3074, 1.4019, 1.3823, 1.3514, 1.3047,
         1.5456, 1.6020, 1.5658, 1.5524, 1.5471, 1.5853, 1.6045, 1.4379, 1.5361,
         1.1634, 1.2764, 1.2496, 1.2980, 1.1578, 1.1647, 1.1001, 1.3589, 1.2401],
        [1.4480, 1.4479, 1.4463, 1.4435, 1.4439, 1.4480, 1.4437, 1.4480, 1.4480,
         1.4392, 1.4386, 1.4392, 1.4391, 1.4392, 1.4207, 1.4392, 1.4381, 1.4359,
         2.2004, 2.2005, 2.2172, 2.1930, 2.1747, 2.1729, 2.2021, 2.1720, 2.1720,
         1.5001, 1.4985, 1.5059, 1.5059, 1.5001, 1.5059, 1.5059, 1.5059, 1.5059,
         1.7709, 1.7710, 1.7710, 1.7679, 1.7709, 1.7709, 1.7710, 1.7485, 1.7512,
         1.4510, 1.4555, 1.4555, 1.4555, 1.4473, 1.4555, 1.4517, 1.4554, 1.4555],
        [1.3158, 1.3140, 1.2980, 1.2892, 1.3129, 1.3113, 1.3124, 1.3130, 1.3130,
         1.3051, 1.2983, 1.2945, 1.2941, 1.3059, 1.2905, 1.3015, 1.3055, 1.2780,
         1.6428, 1.6164, 1.6397, 1.6391, 1.6385, 1.6386, 1.6408, 1.6423, 1.6423,
         3.4832, 3.2729, 3.1982, 3.2563, 3.4076, 3.2251, 3.4583, 3.2059, 3.1847,
         1.6444, 1.6369, 1.6353, 1.6384, 1.6413, 1.6172, 1.6427, 1.5820, 1.6085,
         1.3202, 1.3146, 1.3047, 1.3194, 1.3151, 1.3072, 1.3198, 1.3197, 1.3216],
        [1.4508, 1.4466, 1.4034, 1.4065, 1.4441, 1.4507, 1.4492, 1.4508, 1.4508,
         1.4409, 1.4384, 1.4334, 1.4289, 1.4420, 1.4023, 1.4362, 1.4420, 1.4375,
         1.7555, 1.7469, 1.7460, 1.7539, 1.7713, 1.7699, 1.7501, 1.7714, 1.7714,
         1.4669, 1.4726, 1.5086, 1.5035, 1.4722, 1.5072, 1.4956, 1.5087, 1.5056,
         2.1966, 2.1771, 2.1658, 2.1833, 2.2265, 2.2451, 2.2116, 2.3132, 2.3106,
         1.4435, 1.4336, 1.4480, 1.4583, 1.4458, 1.4550, 1.4263, 1.4522, 1.4583],
        [1.3824, 1.2903, 1.2861, 1.3051, 1.2981, 1.3084, 1.3072, 1.2469, 1.2469,
         1.2824, 1.2346, 1.2329, 1.2430, 1.3277, 1.2012, 1.1489, 1.3277, 1.2271,
         1.6264, 1.6029, 1.5850, 1.5798, 1.6030, 1.5991, 1.6192, 1.6045, 1.6045,
         1.3721, 1.3457, 1.3451, 1.3623, 1.3472, 1.3899, 1.3920, 1.3661, 1.3452,
         1.5986, 1.5984, 1.6038, 1.5935, 1.5700, 1.5737, 1.6340, 1.5243, 1.4937,
         4.0713, 3.5748, 3.6654, 3.6488, 3.6629, 3.3435, 4.0681, 3.6237, 3.3760]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 372 : 1780.3565525449649
Test loss for epoch 372 : 194.25171632067253
Test Precision for epoch 372 : 0.26153846153846155
Test Recall for epoch 372 : 0.26153846153846155
Test F1 for epoch 372 : 0.26153846153846155


theta for epoch 373 : tensor([[3.6170, 3.6376, 3.7811, 3.7298, 3.7123, 3.5985, 3.6396, 3.5389, 3.5389,
         1.2564, 1.2329, 1.2315, 1.2372, 1.2776, 1.2214, 1.1835, 1.2776, 1.2256,
         1.5958, 1.5802, 1.6043, 1.5868, 1.5924, 1.5940, 1.6014, 1.5940, 1.5940,
         1.3412, 1.3524, 1.3382, 1.3600, 1.3406, 1.3713, 1.3642, 1.3512, 1.3383,
         1.5951, 1.6109, 1.5998, 1.5962, 1.6031, 1.5932, 1.6117, 1.5658, 1.5704,
         1.2602, 1.2859, 1.2781, 1.2949, 1.2551, 1.2472, 1.2433, 1.3161, 1.2751],
        [1.3752, 1.2242, 1.2136, 1.2568, 1.2570, 1.2695, 1.2634, 1.1689, 1.1689,
         3.5801, 3.6726, 3.5071, 3.9318, 3.5811, 4.3276, 3.4377, 3.5346, 4.0537,
         1.5694, 1.5569, 1.5308, 1.5294, 1.5507, 1.5602, 1.5847, 1.5602, 1.5602,
         1.3462, 1.3121, 1.3067, 1.3644, 1.3065, 1.4019, 1.3821, 1.3507, 1.3035,
         1.5409, 1.5977, 1.5611, 1.5477, 1.5424, 1.5808, 1.6003, 1.4327, 1.5314,
         1.1590, 1.2727, 1.2458, 1.2944, 1.1534, 1.1603, 1.0958, 1.3557, 1.2362],
        [1.4532, 1.4532, 1.4515, 1.4487, 1.4491, 1.4532, 1.4489, 1.4532, 1.4532,
         1.4267, 1.4260, 1.4267, 1.4266, 1.4267, 1.4081, 1.4267, 1.4256, 1.4233,
         2.1999, 2.2001, 2.2168, 2.1926, 2.1742, 2.1724, 2.2016, 2.1716, 2.1716,
         1.5122, 1.5105, 1.5179, 1.5179, 1.5122, 1.5179, 1.5179, 1.5179, 1.5179,
         1.7738, 1.7739, 1.7739, 1.7708, 1.7738, 1.7738, 1.7739, 1.7514, 1.7541,
         1.4539, 1.4585, 1.4585, 1.4585, 1.4503, 1.4585, 1.4546, 1.4584, 1.4585],
        [1.3212, 1.3193, 1.3034, 1.2946, 1.3182, 1.3166, 1.3177, 1.3182, 1.3182,
         1.2927, 1.2859, 1.2820, 1.2817, 1.2936, 1.2781, 1.2890, 1.2932, 1.2656,
         1.6425, 1.6162, 1.6395, 1.6389, 1.6383, 1.6383, 1.6406, 1.6420, 1.6420,
         3.4924, 3.2821, 3.2074, 3.2655, 3.4168, 3.2343, 3.4674, 3.2151, 3.1940,
         1.6475, 1.6400, 1.6384, 1.6415, 1.6444, 1.6203, 1.6459, 1.5851, 1.6116,
         1.3234, 1.3178, 1.3079, 1.3227, 1.3183, 1.3104, 1.3230, 1.3229, 1.3249],
        [1.4560, 1.4518, 1.4086, 1.4118, 1.4493, 1.4560, 1.4544, 1.4561, 1.4561,
         1.4284, 1.4259, 1.4208, 1.4163, 1.4296, 1.3897, 1.4237, 1.4295, 1.4249,
         1.7551, 1.7464, 1.7455, 1.7534, 1.7708, 1.7695, 1.7497, 1.7710, 1.7710,
         1.4789, 1.4845, 1.5207, 1.5155, 1.4843, 1.5192, 1.5076, 1.5207, 1.5176,
         2.1995, 2.1799, 2.1686, 2.1862, 2.2294, 2.2480, 2.2144, 2.3162, 2.3136,
         1.4463, 1.4366, 1.4509, 1.4613, 1.4487, 1.4580, 1.4291, 1.4552, 1.4613],
        [1.3750, 1.2848, 1.2804, 1.2992, 1.2922, 1.3025, 1.3013, 1.2425, 1.2425,
         1.2670, 1.2188, 1.2172, 1.2273, 1.3125, 1.1861, 1.1324, 1.3126, 1.2118,
         1.6213, 1.5979, 1.5798, 1.5750, 1.5983, 1.5944, 1.6141, 1.5997, 1.5997,
         1.3753, 1.3488, 1.3490, 1.3652, 1.3505, 1.3925, 1.3948, 1.3693, 1.3490,
         1.5977, 1.5970, 1.6028, 1.5925, 1.5688, 1.5724, 1.6326, 1.5232, 1.4923,
         4.0791, 3.5824, 3.6730, 3.6565, 3.6705, 3.3512, 4.0758, 3.6314, 3.3837]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 373 : 1780.1416237619073
Test loss for epoch 373 : 194.36640260426597
Test Precision for epoch 373 : 0.26153846153846155
Test Recall for epoch 373 : 0.26153846153846155
Test F1 for epoch 373 : 0.26153846153846155


theta for epoch 374 : tensor([[3.6206, 3.6413, 3.7847, 3.7335, 3.7160, 3.6022, 3.6434, 3.5427, 3.5427,
         1.2519, 1.2273, 1.2259, 1.2318, 1.2740, 1.2157, 1.1753, 1.2740, 1.2198,
         1.5981, 1.5824, 1.6066, 1.5888, 1.5944, 1.5960, 1.6037, 1.5960, 1.5960,
         1.3436, 1.3549, 1.3404, 1.3625, 1.3429, 1.3741, 1.3668, 1.3537, 1.3404,
         1.5969, 1.6129, 1.6016, 1.5981, 1.6050, 1.5952, 1.6137, 1.5676, 1.5722,
         1.2557, 1.2816, 1.2738, 1.2907, 1.2506, 1.2426, 1.2383, 1.3122, 1.2707],
        [1.3617, 1.2087, 1.1983, 1.2417, 1.2419, 1.2543, 1.2483, 1.1523, 1.1523,
         3.5920, 3.6845, 3.5190, 3.9440, 3.5930, 4.3404, 3.4496, 3.5465, 4.0660,
         1.5612, 1.5486, 1.5224, 1.5206, 1.5421, 1.5516, 1.5765, 1.5516, 1.5516,
         1.3376, 1.3033, 1.2974, 1.3560, 1.2975, 1.3939, 1.3739, 1.3421, 1.2942,
         1.5326, 1.5900, 1.5529, 1.5395, 1.5342, 1.5730, 1.5927, 1.4239, 1.5231,
         1.1467, 1.2611, 1.2340, 1.2829, 1.1410, 1.1479, 1.0834, 1.3446, 1.2243],
        [1.4505, 1.4505, 1.4488, 1.4460, 1.4464, 1.4505, 1.4462, 1.4505, 1.4505,
         1.4236, 1.4229, 1.4235, 1.4235, 1.4236, 1.4049, 1.4235, 1.4224, 1.4202,
         2.2033, 2.2035, 2.2202, 2.1958, 2.1775, 2.1756, 2.2048, 2.1748, 2.1748,
         1.5163, 1.5147, 1.5221, 1.5221, 1.5164, 1.5221, 1.5221, 1.5221, 1.5221,
         1.7770, 1.7771, 1.7770, 1.7739, 1.7769, 1.7769, 1.7770, 1.7545, 1.7572,
         1.4504, 1.4550, 1.4550, 1.4550, 1.4468, 1.4550, 1.4511, 1.4550, 1.4550],
        [1.3185, 1.3166, 1.3007, 1.2919, 1.3155, 1.3139, 1.3150, 1.3155, 1.3155,
         1.2897, 1.2829, 1.2790, 1.2787, 1.2906, 1.2751, 1.2859, 1.2902, 1.2625,
         1.6463, 1.6199, 1.6433, 1.6427, 1.6421, 1.6421, 1.6444, 1.6458, 1.6458,
         3.4944, 3.2842, 3.2095, 3.2676, 3.4189, 3.2363, 3.4695, 3.2171, 3.1960,
         1.6508, 1.6433, 1.6417, 1.6447, 1.6477, 1.6236, 1.6492, 1.5884, 1.6149,
         1.3201, 1.3145, 1.3046, 1.3194, 1.3150, 1.3071, 1.3196, 1.3196, 1.3216],
        [1.4534, 1.4491, 1.4058, 1.4091, 1.4466, 1.4533, 1.4517, 1.4534, 1.4534,
         1.4253, 1.4227, 1.4177, 1.4132, 1.4264, 1.3865, 1.4205, 1.4264, 1.4218,
         1.7587, 1.7500, 1.7490, 1.7569, 1.7744, 1.7731, 1.7532, 1.7746, 1.7746,
         1.4830, 1.4886, 1.5249, 1.5196, 1.4884, 1.5234, 1.5118, 1.5249, 1.5218,
         2.2025, 2.1829, 2.1716, 2.1892, 2.2325, 2.2510, 2.2174, 2.3193, 2.3167,
         1.4428, 1.4330, 1.4474, 1.4578, 1.4451, 1.4545, 1.4255, 1.4517, 1.4578],
        [1.3586, 1.2706, 1.2660, 1.2846, 1.2776, 1.2878, 1.2866, 1.2296, 1.2296,
         1.2583, 1.2097, 1.2080, 1.2183, 1.3042, 1.1772, 1.1220, 1.3043, 1.2028,
         1.6176, 1.5942, 1.5759, 1.5717, 1.5950, 1.5911, 1.6104, 1.5964, 1.5964,
         1.3692, 1.3427, 1.3437, 1.3590, 1.3447, 1.3858, 1.3885, 1.3633, 1.3437,
         1.5950, 1.5939, 1.6002, 1.5898, 1.5659, 1.5693, 1.6295, 1.5203, 1.4892,
         4.0884, 3.5917, 3.6823, 3.6657, 3.6798, 3.3604, 4.0852, 3.6406, 3.3930]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 374 : 1779.4865044311064
Test loss for epoch 374 : 194.91119901325646
Test Precision for epoch 374 : 0.26153846153846155
Test Recall for epoch 374 : 0.26153846153846155
Test F1 for epoch 374 : 0.26153846153846155


theta for epoch 375 : tensor([[3.6294, 3.6502, 3.7936, 3.7423, 3.7248, 3.6111, 3.6522, 3.5517, 3.5517,
         1.2556, 1.2300, 1.2285, 1.2347, 1.2787, 1.2190, 1.1750, 1.2787, 1.2220,
         1.6005, 1.5847, 1.6090, 1.5910, 1.5966, 1.5982, 1.6060, 1.5982, 1.5982,
         1.3342, 1.3454, 1.3306, 1.3532, 1.3333, 1.3650, 1.3576, 1.3442, 1.3307,
         1.5957, 1.6119, 1.6004, 1.5969, 1.6039, 1.5941, 1.6127, 1.5664, 1.5710,
         1.2473, 1.2734, 1.2655, 1.2826, 1.2422, 1.2341, 1.2293, 1.3043, 1.2624],
        [1.3518, 1.1963, 1.1861, 1.2297, 1.2299, 1.2424, 1.2363, 1.1387, 1.1387,
         3.6058, 3.6984, 3.5328, 3.9581, 3.6067, 4.3551, 3.4635, 3.5602, 4.0803,
         1.5536, 1.5407, 1.5146, 1.5124, 1.5339, 1.5435, 1.5689, 1.5435, 1.5435,
         1.3231, 1.2887, 1.2823, 1.3416, 1.2827, 1.3799, 1.3597, 1.3275, 1.2791,
         1.5224, 1.5804, 1.5428, 1.5293, 1.5242, 1.5633, 1.5833, 1.4134, 1.5130,
         1.1324, 1.2475, 1.2201, 1.2694, 1.1266, 1.1335, 1.0687, 1.3316, 1.2104],
        [1.4542, 1.4541, 1.4525, 1.4497, 1.4501, 1.4542, 1.4499, 1.4542, 1.4542,
         1.4290, 1.4283, 1.4289, 1.4289, 1.4290, 1.4103, 1.4289, 1.4278, 1.4256,
         2.2069, 2.2072, 2.2239, 2.1994, 2.1810, 2.1792, 2.2083, 2.1783, 2.1783,
         1.5089, 1.5072, 1.5146, 1.5146, 1.5089, 1.5146, 1.5146, 1.5146, 1.5146,
         1.7773, 1.7773, 1.7773, 1.7742, 1.7772, 1.7772, 1.7773, 1.7547, 1.7574,
         1.4432, 1.4478, 1.4478, 1.4478, 1.4396, 1.4478, 1.4439, 1.4478, 1.4478],
        [1.3222, 1.3203, 1.3044, 1.2956, 1.3192, 1.3176, 1.3187, 1.3192, 1.3192,
         1.2952, 1.2883, 1.2845, 1.2842, 1.2962, 1.2806, 1.2912, 1.2958, 1.2679,
         1.6504, 1.6240, 1.6474, 1.6467, 1.6462, 1.6462, 1.6485, 1.6499, 1.6499,
         3.4863, 3.2760, 3.2012, 3.2594, 3.4107, 3.2281, 3.4614, 3.2089, 3.1878,
         1.6512, 1.6438, 1.6421, 1.6452, 1.6481, 1.6241, 1.6496, 1.5888, 1.6153,
         1.3130, 1.3074, 1.2975, 1.3123, 1.3079, 1.3000, 1.3125, 1.3126, 1.3145],
        [1.4570, 1.4527, 1.4095, 1.4128, 1.4503, 1.4569, 1.4554, 1.4570, 1.4570,
         1.4306, 1.4281, 1.4231, 1.4185, 1.4318, 1.3918, 1.4259, 1.4318, 1.4272,
         1.7626, 1.7539, 1.7529, 1.7608, 1.7783, 1.7770, 1.7571, 1.7785, 1.7785,
         1.4755, 1.4811, 1.5174, 1.5121, 1.4809, 1.5159, 1.5043, 1.5174, 1.5143,
         2.2028, 2.1832, 2.1718, 2.1895, 2.2328, 2.2512, 2.2176, 2.3198, 2.3171,
         1.4355, 1.4258, 1.4402, 1.4506, 1.4379, 1.4473, 1.4181, 1.4445, 1.4506],
        [1.3441, 1.2585, 1.2536, 1.2721, 1.2650, 1.2752, 1.2741, 1.2188, 1.2188,
         1.2560, 1.2070, 1.2052, 1.2155, 1.3025, 1.1755, 1.1174, 1.3025, 1.1999,
         1.6127, 1.5894, 1.5707, 1.5672, 1.5906, 1.5866, 1.6055, 1.5920, 1.5920,
         1.3518, 1.3254, 1.3271, 1.3414, 1.3277, 1.3677, 1.3707, 1.3460, 1.3272,
         1.5885, 1.5869, 1.5937, 1.5833, 1.5591, 1.5623, 1.6225, 1.5135, 1.4821,
         4.0993, 3.6024, 3.6930, 3.6765, 3.6905, 3.3712, 4.0960, 3.6514, 3.4038]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 375 : 1778.5235382347498
Test loss for epoch 375 : 195.8452998825107
Test Precision for epoch 375 : 0.26153846153846155
Test Recall for epoch 375 : 0.26153846153846155
Test F1 for epoch 375 : 0.26153846153846155


theta for epoch 376 : tensor([[3.6305, 3.6513, 3.7947, 3.7435, 3.7260, 3.6122, 3.6534, 3.5529, 3.5529,
         1.2593, 1.2333, 1.2317, 1.2379, 1.2828, 1.2226, 1.1768, 1.2828, 1.2249,
         1.5992, 1.5834, 1.6078, 1.5896, 1.5953, 1.5969, 1.6048, 1.5969, 1.5969,
         1.3350, 1.3462, 1.3313, 1.3540, 1.3340, 1.3659, 1.3584, 1.3450, 1.3313,
         1.5933, 1.6096, 1.5981, 1.5946, 1.6016, 1.5918, 1.6105, 1.5641, 1.5686,
         1.2428, 1.2689, 1.2610, 1.2782, 1.2376, 1.2295, 1.2242, 1.2999, 1.2578],
        [1.3677, 1.2105, 1.2005, 1.2441, 1.2444, 1.2568, 1.2508, 1.1519, 1.1519,
         3.5920, 3.6847, 3.5190, 3.9446, 3.5929, 4.3421, 3.4497, 3.5464, 4.0669,
         1.5639, 1.5510, 1.5251, 1.5225, 1.5439, 1.5534, 1.5791, 1.5535, 1.5535,
         1.3353, 1.3010, 1.2940, 1.3539, 1.2948, 1.3924, 1.3721, 1.3397, 1.2909,
         1.5313, 1.5893, 1.5515, 1.5381, 1.5331, 1.5721, 1.5923, 1.4228, 1.5219,
         1.1423, 1.2575, 1.2301, 1.2795, 1.1365, 1.1432, 1.0783, 1.3418, 1.2203],
        [1.4568, 1.4568, 1.4552, 1.4524, 1.4527, 1.4568, 1.4525, 1.4568, 1.4568,
         1.4331, 1.4324, 1.4331, 1.4331, 1.4331, 1.4145, 1.4331, 1.4320, 1.4297,
         2.2059, 2.2062, 2.2229, 2.1984, 2.1800, 2.1782, 2.2073, 2.1773, 2.1773,
         1.5097, 1.5081, 1.5155, 1.5155, 1.5097, 1.5155, 1.5155, 1.5155, 1.5155,
         1.7752, 1.7753, 1.7753, 1.7721, 1.7752, 1.7752, 1.7753, 1.7526, 1.7554,
         1.4382, 1.4428, 1.4428, 1.4428, 1.4345, 1.4428, 1.4388, 1.4427, 1.4428],
        [1.3249, 1.3229, 1.3070, 1.2983, 1.3218, 1.3202, 1.3214, 1.3218, 1.3218,
         1.2995, 1.2925, 1.2887, 1.2884, 1.3004, 1.2848, 1.2954, 1.3000, 1.2721,
         1.6494, 1.6230, 1.6464, 1.6457, 1.6452, 1.6452, 1.6475, 1.6489, 1.6489,
         3.4860, 3.2756, 3.2009, 3.2590, 3.4104, 3.2278, 3.4610, 3.2085, 3.1874,
         1.6492, 1.6418, 1.6401, 1.6431, 1.6461, 1.6221, 1.6476, 1.5868, 1.6133,
         1.3080, 1.3025, 1.2925, 1.3074, 1.3030, 1.2951, 1.3075, 1.3076, 1.3096],
        [1.4596, 1.4553, 1.4121, 1.4154, 1.4529, 1.4596, 1.4580, 1.4597, 1.4597,
         1.4348, 1.4323, 1.4272, 1.4226, 1.4360, 1.3959, 1.4301, 1.4359, 1.4313,
         1.7615, 1.7528, 1.7518, 1.7597, 1.7773, 1.7759, 1.7561, 1.7774, 1.7774,
         1.4764, 1.4819, 1.5182, 1.5129, 1.4817, 1.5168, 1.5052, 1.5183, 1.5152,
         2.2008, 2.1811, 2.1698, 2.1874, 2.2308, 2.2492, 2.2156, 2.3179, 2.3153,
         1.4303, 1.4208, 1.4351, 1.4456, 1.4328, 1.4423, 1.4129, 1.4395, 1.4456],
        [1.3312, 1.2483, 1.2431, 1.2614, 1.2543, 1.2645, 1.2634, 1.2102, 1.2102,
         1.2537, 1.2051, 1.2033, 1.2133, 1.2999, 1.1743, 1.1156, 1.2999, 1.1979,
         1.6047, 1.5815, 1.5626, 1.5598, 1.5832, 1.5792, 1.5976, 1.5846, 1.5846,
         1.3429, 1.3166, 1.3192, 1.3324, 1.3192, 1.3581, 1.3615, 1.3372, 1.3193,
         1.5811, 1.5789, 1.5862, 1.5758, 1.5514, 1.5543, 1.6144, 1.5058, 1.4742,
         4.1086, 3.6117, 3.7022, 3.6857, 3.6997, 3.3805, 4.1053, 3.6607, 3.4130]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 376 : 1778.864142952169
Test loss for epoch 376 : 195.30882049242874
Test Precision for epoch 376 : 0.26153846153846155
Test Recall for epoch 376 : 0.26153846153846155
Test F1 for epoch 376 : 0.26153846153846155


theta for epoch 377 : tensor([[3.6218, 3.6425, 3.7859, 3.7346, 3.7172, 3.6033, 3.6445, 3.5439, 3.5439,
         1.2631, 1.2372, 1.2356, 1.2417, 1.2865, 1.2269, 1.1805, 1.2865, 1.2286,
         1.5958, 1.5800, 1.6044, 1.5861, 1.5918, 1.5934, 1.6013, 1.5933, 1.5933,
         1.3435, 1.3547, 1.3397, 1.3626, 1.3426, 1.3746, 1.3670, 1.3535, 1.3398,
         1.5921, 1.6085, 1.5969, 1.5934, 1.6004, 1.5906, 1.6094, 1.5629, 1.5674,
         1.2421, 1.2683, 1.2603, 1.2776, 1.2369, 1.2288, 1.2228, 1.2993, 1.2572],
        [1.3906, 1.2327, 1.2229, 1.2664, 1.2667, 1.2791, 1.2730, 1.1735, 1.1735,
         3.5668, 3.6595, 3.4938, 3.9196, 3.5677, 4.3177, 3.4245, 3.5212, 4.0421,
         1.5808, 1.5679, 1.5424, 1.5394, 1.5606, 1.5701, 1.5958, 1.5701, 1.5701,
         1.3600, 1.3257, 1.3184, 1.3785, 1.3194, 1.4172, 1.3968, 1.3642, 1.3152,
         1.5488, 1.6066, 1.5689, 1.5556, 1.5507, 1.5896, 1.6098, 1.4414, 1.5396,
         1.1631, 1.2782, 1.2507, 1.3002, 1.1572, 1.1636, 1.0986, 1.3625, 1.2409],
        [1.4515, 1.4515, 1.4498, 1.4470, 1.4474, 1.4515, 1.4472, 1.4515, 1.4515,
         1.4365, 1.4358, 1.4364, 1.4364, 1.4365, 1.4178, 1.4365, 1.4353, 1.4331,
         2.2018, 2.2020, 2.2188, 2.1944, 2.1760, 2.1742, 2.2033, 2.1733, 2.1733,
         1.5169, 1.5153, 1.5227, 1.5227, 1.5169, 1.5227, 1.5226, 1.5227, 1.5227,
         1.7733, 1.7734, 1.7734, 1.7703, 1.7733, 1.7733, 1.7734, 1.7507, 1.7534,
         1.4359, 1.4405, 1.4405, 1.4405, 1.4322, 1.4405, 1.4365, 1.4405, 1.4405],
        [1.3193, 1.3174, 1.3015, 1.2927, 1.3163, 1.3147, 1.3158, 1.3163, 1.3163,
         1.3029, 1.2959, 1.2921, 1.2918, 1.3038, 1.2882, 1.2987, 1.3034, 1.2755,
         1.6451, 1.6187, 1.6421, 1.6414, 1.6408, 1.6408, 1.6431, 1.6445, 1.6445,
         3.4916, 3.2813, 3.2066, 3.2647, 3.4160, 3.2334, 3.4667, 3.2142, 3.1931,
         1.6473, 1.6399, 1.6382, 1.6413, 1.6442, 1.6202, 1.6457, 1.5849, 1.6114,
         1.3057, 1.3002, 1.2903, 1.3051, 1.3007, 1.2928, 1.3052, 1.3054, 1.3073],
        [1.4543, 1.4500, 1.4067, 1.4101, 1.4476, 1.4543, 1.4527, 1.4544, 1.4544,
         1.4381, 1.4356, 1.4306, 1.4260, 1.4393, 1.3992, 1.4334, 1.4393, 1.4347,
         1.7572, 1.7485, 1.7474, 1.7554, 1.7730, 1.7716, 1.7518, 1.7732, 1.7732,
         1.4835, 1.4891, 1.5254, 1.5201, 1.4889, 1.5239, 1.5124, 1.5255, 1.5224,
         2.1990, 2.1793, 2.1679, 2.1856, 2.2290, 2.2474, 2.2137, 2.3162, 2.3135,
         1.4280, 1.4185, 1.4328, 1.4433, 1.4304, 1.4400, 1.4106, 1.4372, 1.4433],
        [1.3158, 1.2353, 1.2298, 1.2479, 1.2408, 1.2510, 1.2499, 1.1987, 1.1987,
         1.2518, 1.2043, 1.2025, 1.2121, 1.2969, 1.1741, 1.1165, 1.2970, 1.1970,
         1.5951, 1.5721, 1.5530, 1.5507, 1.5741, 1.5702, 1.5881, 1.5755, 1.5755,
         1.3411, 1.3148, 1.3182, 1.3303, 1.3176, 1.3556, 1.3593, 1.3355, 1.3183,
         1.5748, 1.5721, 1.5799, 1.5694, 1.5449, 1.5476, 1.6076, 1.4993, 1.4676,
         4.1169, 3.6198, 3.7104, 3.6939, 3.7079, 3.3888, 4.1136, 3.6688, 3.4213]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 377 : 1779.9029152075275
Test loss for epoch 377 : 194.86258010288475
Test Precision for epoch 377 : 0.26153846153846155
Test Recall for epoch 377 : 0.26153846153846155
Test F1 for epoch 377 : 0.26153846153846155


theta for epoch 378 : tensor([[3.6203, 3.6409, 3.7843, 3.7331, 3.7156, 3.6018, 3.6430, 3.5423, 3.5423,
         1.2700, 1.2442, 1.2426, 1.2485, 1.2932, 1.2340, 1.1872, 1.2932, 1.2352,
         1.5936, 1.5778, 1.6022, 1.5838, 1.5895, 1.5911, 1.5991, 1.5911, 1.5911,
         1.3397, 1.3509, 1.3358, 1.3588, 1.3387, 1.3708, 1.3632, 1.3497, 1.3359,
         1.5914, 1.6078, 1.5961, 1.5926, 1.5997, 1.5899, 1.6087, 1.5622, 1.5667,
         1.2386, 1.2650, 1.2569, 1.2743, 1.2334, 1.2251, 1.2184, 1.2963, 1.2537],
        [1.4078, 1.2494, 1.2398, 1.2832, 1.2835, 1.2958, 1.2898, 1.1899, 1.1899,
         3.5511, 3.6439, 3.4780, 3.9041, 3.5520, 4.3027, 3.4087, 3.5055, 4.0267,
         1.5922, 1.5793, 1.5541, 1.5509, 1.5719, 1.5813, 1.6071, 1.5814, 1.5814,
         1.3714, 1.3373, 1.3297, 1.3898, 1.3309, 1.4285, 1.4081, 1.3756, 1.3265,
         1.5607, 1.6183, 1.5807, 1.5675, 1.5627, 1.6013, 1.6215, 1.4540, 1.5516,
         1.1751, 1.2901, 1.2626, 1.3121, 1.1690, 1.1753, 1.1100, 1.3746, 1.2528],
        [1.4532, 1.4532, 1.4515, 1.4487, 1.4491, 1.4532, 1.4489, 1.4532, 1.4532,
         1.4432, 1.4425, 1.4431, 1.4431, 1.4432, 1.4245, 1.4431, 1.4420, 1.4398,
         2.1994, 2.1997, 2.2164, 2.1921, 2.1737, 2.1719, 2.2010, 2.1710, 2.1710,
         1.5124, 1.5108, 1.5182, 1.5182, 1.5124, 1.5182, 1.5182, 1.5182, 1.5182,
         1.7723, 1.7724, 1.7724, 1.7693, 1.7723, 1.7723, 1.7724, 1.7497, 1.7525,
         1.4319, 1.4366, 1.4366, 1.4366, 1.4283, 1.4366, 1.4326, 1.4365, 1.4366],
        [1.3209, 1.3190, 1.3031, 1.2944, 1.3179, 1.3163, 1.3174, 1.3179, 1.3179,
         1.3096, 1.3027, 1.2988, 1.2985, 1.3105, 1.2949, 1.3055, 1.3101, 1.2822,
         1.6425, 1.6162, 1.6395, 1.6388, 1.6382, 1.6383, 1.6406, 1.6420, 1.6420,
         3.4870, 3.2766, 3.2019, 3.2600, 3.4114, 3.2288, 3.4620, 3.2095, 3.1884,
         1.6463, 1.6389, 1.6373, 1.6403, 1.6433, 1.6192, 1.6448, 1.5839, 1.6105,
         1.3017, 1.2962, 1.2863, 1.3011, 1.2967, 1.2888, 1.3012, 1.3014, 1.3033],
        [1.4560, 1.4517, 1.4084, 1.4118, 1.4493, 1.4559, 1.4544, 1.4560, 1.4560,
         1.4448, 1.4423, 1.4373, 1.4327, 1.4460, 1.4058, 1.4401, 1.4460, 1.4413,
         1.7547, 1.7460, 1.7449, 1.7529, 1.7705, 1.7691, 1.7493, 1.7707, 1.7707,
         1.4790, 1.4846, 1.5209, 1.5156, 1.4844, 1.5195, 1.5079, 1.5210, 1.5179,
         2.1980, 2.1783, 2.1669, 2.1846, 2.2281, 2.2464, 2.2127, 2.3153, 2.3126,
         1.4241, 1.4145, 1.4289, 1.4394, 1.4265, 1.4361, 1.4066, 1.4332, 1.4394],
        [1.3051, 1.2254, 1.2198, 1.2379, 1.2307, 1.2410, 1.2398, 1.1893, 1.1893,
         1.2522, 1.2056, 1.2038, 1.2129, 1.2967, 1.1753, 1.1185, 1.2968, 1.1979,
         1.5861, 1.5631, 1.5438, 1.5418, 1.5653, 1.5613, 1.5791, 1.5667, 1.5667,
         1.3287, 1.3024, 1.3063, 1.3178, 1.3053, 1.3429, 1.3467, 1.3231, 1.3063,
         1.5682, 1.5651, 1.5732, 1.5627, 1.5381, 1.5406, 1.6006, 1.4924, 1.4604,
         4.1270, 3.6298, 3.7203, 3.7038, 3.7178, 3.3988, 4.1237, 3.6788, 3.4312]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 378 : 1780.4175234873226
Test loss for epoch 378 : 195.44037650648878
Test Precision for epoch 378 : 0.26153846153846155
Test Recall for epoch 378 : 0.26153846153846155
Test F1 for epoch 378 : 0.26153846153846155


theta for epoch 379 : tensor([[3.6233, 3.6440, 3.7874, 3.7362, 3.7187, 3.6049, 3.6461, 3.5454, 3.5454,
         1.2770, 1.2515, 1.2500, 1.2556, 1.3001, 1.2411, 1.1944, 1.3001, 1.2421,
         1.5945, 1.5786, 1.6031, 1.5846, 1.5903, 1.5919, 1.6000, 1.5919, 1.5919,
         1.3329, 1.3441, 1.3289, 1.3520, 1.3318, 1.3640, 1.3564, 1.3429, 1.3290,
         1.5907, 1.6071, 1.5954, 1.5919, 1.5990, 1.5892, 1.6081, 1.5614, 1.5660,
         1.2301, 1.2570, 1.2487, 1.2665, 1.2247, 1.2163, 1.2088, 1.2890, 1.2454],
        [1.4167, 1.2588, 1.2492, 1.2926, 1.2928, 1.3052, 1.2991, 1.1995, 1.1995,
         3.5435, 3.6363, 3.4704, 3.8968, 3.5444, 4.2959, 3.4011, 3.4979, 4.0195,
         1.5998, 1.5870, 1.5618, 1.5586, 1.5797, 1.5890, 1.6146, 1.5891, 1.5891,
         1.3750, 1.3410, 1.3335, 1.3933, 1.3347, 1.4318, 1.4115, 1.3792, 1.3304,
         1.5672, 1.6245, 1.5871, 1.5739, 1.5691, 1.6076, 1.6277, 1.4608, 1.5581,
         1.1776, 1.2925, 1.2649, 1.3145, 1.1715, 1.1776, 1.1119, 1.3770, 1.2551],
        [1.4558, 1.4557, 1.4541, 1.4513, 1.4517, 1.4558, 1.4515, 1.4558, 1.4558,
         1.4504, 1.4497, 1.4504, 1.4504, 1.4504, 1.4318, 1.4504, 1.4493, 1.4470,
         2.2005, 2.2008, 2.2175, 2.1932, 2.1748, 2.1730, 2.2021, 2.1721, 2.1721,
         1.5058, 1.5042, 1.5116, 1.5116, 1.5059, 1.5116, 1.5116, 1.5116, 1.5116,
         1.7721, 1.7722, 1.7722, 1.7690, 1.7720, 1.7720, 1.7722, 1.7494, 1.7522,
         1.4247, 1.4293, 1.4293, 1.4293, 1.4210, 1.4293, 1.4253, 1.4293, 1.4293],
        [1.3234, 1.3215, 1.3056, 1.2969, 1.3204, 1.3188, 1.3199, 1.3204, 1.3204,
         1.3168, 1.3099, 1.3061, 1.3058, 1.3178, 1.3022, 1.3127, 1.3174, 1.2895,
         1.6437, 1.6174, 1.6407, 1.6400, 1.6394, 1.6395, 1.6418, 1.6432, 1.6432,
         3.4807, 3.2703, 3.1955, 3.2537, 3.4051, 3.2224, 3.4557, 3.2032, 3.1820,
         1.6460, 1.6386, 1.6369, 1.6400, 1.6429, 1.6189, 1.6444, 1.5836, 1.6102,
         1.2944, 1.2888, 1.2789, 1.2937, 1.2893, 1.2814, 1.2938, 1.2940, 1.2959],
        [1.4586, 1.4543, 1.4110, 1.4144, 1.4519, 1.4585, 1.4570, 1.4586, 1.4586,
         1.4521, 1.4495, 1.4445, 1.4399, 1.4532, 1.4131, 1.4474, 1.4532, 1.4486,
         1.7560, 1.7473, 1.7462, 1.7541, 1.7718, 1.7704, 1.7505, 1.7719, 1.7719,
         1.4724, 1.4780, 1.5144, 1.5091, 1.4778, 1.5129, 1.5013, 1.5144, 1.5113,
         2.1977, 2.1780, 2.1666, 2.1843, 2.2278, 2.2461, 2.2124, 2.3150, 2.3124,
         1.4168, 1.4073, 1.4217, 1.4321, 1.4193, 1.4289, 1.3993, 1.4260, 1.4322],
        [1.2964, 1.2153, 1.2098, 1.2280, 1.2209, 1.2312, 1.2300, 1.1785, 1.1785,
         1.2532, 1.2070, 1.2053, 1.2139, 1.2974, 1.1763, 1.1198, 1.2974, 1.1987,
         1.5798, 1.5566, 1.5374, 1.5353, 1.5588, 1.5548, 1.5727, 1.5602, 1.5602,
         1.3144, 1.2880, 1.2917, 1.3035, 1.2909, 1.3288, 1.3326, 1.3088, 1.2917,
         1.5612, 1.5582, 1.5663, 1.5557, 1.5310, 1.5336, 1.5939, 1.4850, 1.4530,
         4.1374, 3.6399, 3.7305, 3.7140, 3.7280, 3.4090, 4.1341, 3.6889, 3.4414]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 379 : 1780.7630906226225
Test loss for epoch 379 : 196.30579865855336
Test Precision for epoch 379 : 0.26153846153846155
Test Recall for epoch 379 : 0.26153846153846155
Test F1 for epoch 379 : 0.26153846153846155


theta for epoch 380 : tensor([[3.6274, 3.6482, 3.7916, 3.7403, 3.7229, 3.6091, 3.6502, 3.5496, 3.5496,
         1.2781, 1.2529, 1.2514, 1.2567, 1.3009, 1.2422, 1.1959, 1.3010, 1.2430,
         1.5957, 1.5798, 1.6043, 1.5858, 1.5915, 1.5931, 1.6012, 1.5931, 1.5931,
         1.3349, 1.3462, 1.3309, 1.3541, 1.3339, 1.3662, 1.3586, 1.3450, 1.3310,
         1.5897, 1.6063, 1.5945, 1.5909, 1.5981, 1.5884, 1.6072, 1.5605, 1.5651,
         1.2216, 1.2494, 1.2408, 1.2592, 1.2160, 1.2072, 1.1991, 1.2825, 1.2373],
        [1.4144, 1.2585, 1.2487, 1.2919, 1.2922, 1.3045, 1.2985, 1.2001, 1.2001,
         3.5417, 3.6346, 3.4687, 3.8953, 3.5427, 4.2949, 3.3993, 3.4962, 4.0181,
         1.6024, 1.5897, 1.5644, 1.5617, 1.5827, 1.5920, 1.6173, 1.5921, 1.5921,
         1.3779, 1.3440, 1.3370, 1.3962, 1.3378, 1.4343, 1.4142, 1.3821, 1.3339,
         1.5688, 1.6257, 1.5886, 1.5755, 1.5706, 1.6089, 1.6288, 1.4624, 1.5596,
         1.1746, 1.2893, 1.2618, 1.3113, 1.1684, 1.1744, 1.1081, 1.3738, 1.2519],
        [1.4513, 1.4512, 1.4496, 1.4468, 1.4472, 1.4513, 1.4470, 1.4513, 1.4513,
         1.4521, 1.4514, 1.4520, 1.4520, 1.4521, 1.4334, 1.4521, 1.4509, 1.4487,
         2.2028, 2.2031, 2.2199, 2.1955, 2.1770, 2.1752, 2.2043, 2.1743, 2.1743,
         1.5094, 1.5078, 1.5152, 1.5152, 1.5095, 1.5152, 1.5152, 1.5152, 1.5152,
         1.7723, 1.7724, 1.7724, 1.7693, 1.7723, 1.7723, 1.7724, 1.7497, 1.7525,
         1.4195, 1.4242, 1.4242, 1.4242, 1.4159, 1.4242, 1.4202, 1.4241, 1.4242],
        [1.3185, 1.3166, 1.3008, 1.2920, 1.3155, 1.3139, 1.3151, 1.3156, 1.3156,
         1.3184, 1.3116, 1.3077, 1.3074, 1.3194, 1.3038, 1.3144, 1.3190, 1.2911,
         1.6460, 1.6197, 1.6430, 1.6424, 1.6418, 1.6418, 1.6441, 1.6455, 1.6455,
         3.4839, 3.2735, 3.1988, 3.2570, 3.4083, 3.2257, 3.4589, 3.2065, 3.1853,
         1.6462, 1.6388, 1.6371, 1.6402, 1.6431, 1.6191, 1.6446, 1.5838, 1.6103,
         1.2889, 1.2834, 1.2735, 1.2883, 1.2839, 1.2760, 1.2883, 1.2886, 1.2905],
        [1.4541, 1.4498, 1.4065, 1.4098, 1.4474, 1.4540, 1.4525, 1.4541, 1.4541,
         1.4537, 1.4512, 1.4462, 1.4415, 1.4549, 1.4147, 1.4490, 1.4549, 1.4502,
         1.7585, 1.7498, 1.7487, 1.7566, 1.7743, 1.7729, 1.7530, 1.7744, 1.7744,
         1.4760, 1.4816, 1.5180, 1.5127, 1.4814, 1.5165, 1.5049, 1.5180, 1.5149,
         2.1979, 2.1782, 2.1668, 2.1845, 2.2280, 2.2463, 2.2126, 2.3153, 2.3126,
         1.4117, 1.4021, 1.4165, 1.4270, 1.4141, 1.4237, 1.3942, 1.4209, 1.4270],
        [1.2855, 1.2006, 1.1954, 1.2140, 1.2068, 1.2172, 1.2160, 1.1616, 1.1616,
         1.2498, 1.2035, 1.2019, 1.2101, 1.2939, 1.1720, 1.1156, 1.2939, 1.1944,
         1.5745, 1.5510, 1.5319, 1.5292, 1.5529, 1.5489, 1.5673, 1.5543, 1.5543,
         1.3089, 1.2822, 1.2851, 1.2981, 1.2849, 1.3241, 1.3276, 1.3032, 1.2852,
         1.5542, 1.5516, 1.5593, 1.5487, 1.5240, 1.5268, 1.5875, 1.4777, 1.4456,
         4.1491, 3.6514, 3.7420, 3.7255, 3.7396, 3.4206, 4.1459, 3.7004, 3.4529]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 380 : 1780.7278613061087
Test loss for epoch 380 : 197.03964325571096
Test Precision for epoch 380 : 0.26153846153846155
Test Recall for epoch 380 : 0.26153846153846155
Test F1 for epoch 380 : 0.26153846153846155


theta for epoch 381 : tensor([[3.6231, 3.6438, 3.7872, 3.7359, 3.7185, 3.6047, 3.6458, 3.5452, 3.5452,
         1.2744, 1.2496, 1.2481, 1.2531, 1.2968, 1.2385, 1.1931, 1.2968, 1.2392,
         1.5970, 1.5811, 1.6056, 1.5871, 1.5927, 1.5943, 1.6025, 1.5943, 1.5943,
         1.3441, 1.3553, 1.3401, 1.3632, 1.3430, 1.3754, 1.3678, 1.3541, 1.3401,
         1.5912, 1.6078, 1.5960, 1.5924, 1.5996, 1.5899, 1.6088, 1.5620, 1.5666,
         1.2213, 1.2492, 1.2405, 1.2590, 1.2157, 1.2068, 1.1979, 1.2824, 1.2371],
        [1.4107, 1.2578, 1.2477, 1.2908, 1.2910, 1.3033, 1.2973, 1.2011, 1.2011,
         3.5406, 3.6336, 3.4676, 3.8944, 3.5416, 4.2945, 3.3982, 3.4951, 4.0174,
         1.6015, 1.5891, 1.5634, 1.5615, 1.5825, 1.5919, 1.6165, 1.5919, 1.5919,
         1.3807, 1.3469, 1.3407, 1.3988, 1.3410, 1.4364, 1.4166, 1.3851, 1.3376,
         1.5691, 1.6254, 1.5889, 1.5757, 1.5707, 1.6087, 1.6283, 1.4626, 1.5598,
         1.1735, 1.2871, 1.2599, 1.3087, 1.1676, 1.1740, 1.1068, 1.3701, 1.2503],
        [1.4520, 1.4519, 1.4503, 1.4475, 1.4479, 1.4520, 1.4477, 1.4520, 1.4520,
         1.4469, 1.4463, 1.4469, 1.4469, 1.4469, 1.4283, 1.4469, 1.4458, 1.4436,
         2.2031, 2.2034, 2.2202, 2.1958, 2.1773, 2.1755, 2.2046, 2.1746, 2.1746,
         1.5172, 1.5156, 1.5230, 1.5230, 1.5172, 1.5230, 1.5230, 1.5230, 1.5230,
         1.7731, 1.7732, 1.7732, 1.7701, 1.7731, 1.7731, 1.7732, 1.7505, 1.7533,
         1.4192, 1.4238, 1.4238, 1.4238, 1.4156, 1.4238, 1.4199, 1.4238, 1.4238],
        [1.3190, 1.3172, 1.3013, 1.2926, 1.3161, 1.3145, 1.3156, 1.3162, 1.3162,
         1.3133, 1.3064, 1.3026, 1.3022, 1.3142, 1.2986, 1.3092, 1.3138, 1.2859,
         1.6463, 1.6200, 1.6433, 1.6426, 1.6420, 1.6421, 1.6443, 1.6457, 1.6457,
         3.4908, 3.2805, 3.2058, 3.2640, 3.4152, 3.2327, 3.4658, 3.2135, 3.1924,
         1.6469, 1.6395, 1.6378, 1.6409, 1.6438, 1.6198, 1.6453, 1.5846, 1.6111,
         1.2884, 1.2829, 1.2729, 1.2877, 1.2833, 1.2754, 1.2878, 1.2880, 1.2899],
        [1.4548, 1.4506, 1.4074, 1.4105, 1.4481, 1.4547, 1.4532, 1.4548, 1.4548,
         1.4486, 1.4460, 1.4410, 1.4364, 1.4498, 1.4095, 1.4439, 1.4497, 1.4451,
         1.7588, 1.7502, 1.7491, 1.7571, 1.7747, 1.7733, 1.7534, 1.7748, 1.7748,
         1.4838, 1.4894, 1.5258, 1.5205, 1.4893, 1.5243, 1.5126, 1.5258, 1.5227,
         2.1987, 2.1789, 2.1675, 2.1852, 2.2287, 2.2470, 2.2133, 2.3160, 2.3133,
         1.4114, 1.4018, 1.4162, 1.4266, 1.4138, 1.4234, 1.3940, 1.4205, 1.4267],
        [1.3425, 1.2549, 1.2502, 1.2688, 1.2618, 1.2720, 1.2709, 1.2141, 1.2141,
         1.2752, 1.2296, 1.2280, 1.2357, 1.3187, 1.1974, 1.1413, 1.3187, 1.2196,
         1.6090, 1.5858, 1.5671, 1.5638, 1.5871, 1.5832, 1.6019, 1.5885, 1.5885,
         1.3582, 1.3317, 1.3335, 1.3478, 1.3340, 1.3741, 1.3771, 1.3524, 1.3335,
         1.5850, 1.5831, 1.5901, 1.5797, 1.5555, 1.5586, 1.6186, 1.5099, 1.4786,
         4.0879, 3.5900, 3.6806, 3.6641, 3.6781, 3.3591, 4.0846, 3.6391, 3.3915]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 381 : 1782.4540085738477
Test loss for epoch 381 : 193.8735486308939
Test Precision for epoch 381 : 0.26153846153846155
Test Recall for epoch 381 : 0.26153846153846155
Test F1 for epoch 381 : 0.26153846153846155


theta for epoch 382 : tensor([[3.6157, 3.6363, 3.7797, 3.7285, 3.7110, 3.5971, 3.6383, 3.5375, 3.5375,
         1.2709, 1.2464, 1.2449, 1.2497, 1.2931, 1.2348, 1.1899, 1.2931, 1.2355,
         1.5943, 1.5784, 1.6030, 1.5843, 1.5899, 1.5915, 1.5998, 1.5915, 1.5915,
         1.3338, 1.3450, 1.3295, 1.3529, 1.3325, 1.3652, 1.3575, 1.3438, 1.3295,
         1.5917, 1.6084, 1.5965, 1.5929, 1.6001, 1.5905, 1.6095, 1.5625, 1.5672,
         1.2420, 1.2704, 1.2615, 1.2803, 1.2362, 1.2270, 1.2175, 1.3042, 1.2579],
        [1.3971, 1.2477, 1.2372, 1.2800, 1.2803, 1.2926, 1.2865, 1.1928, 1.1928,
         3.5457, 3.6387, 3.4727, 3.8997, 3.5467, 4.3004, 3.4034, 3.5002, 4.0229,
         1.5933, 1.5810, 1.5551, 1.5540, 1.5750, 1.5844, 1.6084, 1.5844, 1.5844,
         1.3680, 1.3344, 1.3292, 1.3859, 1.3288, 1.4227, 1.4033, 1.3725, 1.3261,
         1.5641, 1.6199, 1.5840, 1.5708, 1.5655, 1.6033, 1.6225, 1.4573, 1.5548,
         1.1806, 1.2938, 1.2669, 1.3153, 1.1749, 1.1817, 1.1131, 1.3760, 1.2573],
        [1.4451, 1.4450, 1.4434, 1.4406, 1.4410, 1.4451, 1.4407, 1.4450, 1.4450,
         1.4422, 1.4415, 1.4421, 1.4421, 1.4422, 1.4235, 1.4422, 1.4410, 1.4388,
         2.2001, 2.2004, 2.2171, 2.1928, 2.1743, 2.1725, 2.2017, 2.1716, 2.1716,
         1.5058, 1.5042, 1.5116, 1.5116, 1.5058, 1.5116, 1.5116, 1.5116, 1.5116,
         1.7733, 1.7734, 1.7734, 1.7702, 1.7733, 1.7733, 1.7734, 1.7507, 1.7534,
         1.4407, 1.4453, 1.4453, 1.4453, 1.4370, 1.4453, 1.4413, 1.4452, 1.4453],
        [1.3120, 1.3102, 1.2944, 1.2856, 1.3091, 1.3075, 1.3086, 1.3092, 1.3092,
         1.3086, 1.3017, 1.2979, 1.2975, 1.3095, 1.2939, 1.3045, 1.3091, 1.2812,
         1.6430, 1.6167, 1.6400, 1.6394, 1.6388, 1.6388, 1.6411, 1.6425, 1.6425,
         3.4799, 3.2695, 3.1948, 3.2530, 3.4043, 3.2218, 3.4549, 3.2025, 3.1814,
         1.6471, 1.6397, 1.6380, 1.6411, 1.6440, 1.6200, 1.6455, 1.5848, 1.6113,
         1.3098, 1.3043, 1.2944, 1.3092, 1.3047, 1.2969, 1.3091, 1.3095, 1.3113],
        [1.4479, 1.4437, 1.4004, 1.4035, 1.4411, 1.4478, 1.4463, 1.4479, 1.4479,
         1.4438, 1.4413, 1.4362, 1.4316, 1.4450, 1.4047, 1.4391, 1.4450, 1.4403,
         1.7557, 1.7470, 1.7459, 1.7539, 1.7715, 1.7701, 1.7503, 1.7716, 1.7716,
         1.4724, 1.4779, 1.5143, 1.5091, 1.4778, 1.5129, 1.5012, 1.5144, 1.5113,
         2.1988, 2.1790, 2.1676, 2.1854, 2.2289, 2.2471, 2.2135, 2.3162, 2.3134,
         1.4329, 1.4233, 1.4377, 1.4480, 1.4353, 1.4448, 1.4155, 1.4420, 1.4481],
        [1.3863, 1.2953, 1.2910, 1.3098, 1.3029, 1.3130, 1.3118, 1.2522, 1.2522,
         1.2965, 1.2513, 1.2497, 1.2570, 1.3394, 1.2181, 1.1622, 1.3395, 1.2402,
         1.6350, 1.6119, 1.5937, 1.5896, 1.6125, 1.6087, 1.6279, 1.6139, 1.6139,
         1.3854, 1.3592, 1.3597, 1.3754, 1.3610, 1.4021, 1.4046, 1.3795, 1.3597,
         1.6102, 1.6090, 1.6152, 1.6050, 1.5813, 1.5847, 1.6441, 1.5363, 1.5057,
         4.0434, 3.5455, 3.6360, 3.6196, 3.6335, 3.3145, 4.0402, 3.5947, 3.3469]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 382 : 1782.129615552606
Test loss for epoch 382 : 193.46366757089112
Test Precision for epoch 382 : 0.26153846153846155
Test Recall for epoch 382 : 0.26153846153846155
Test F1 for epoch 382 : 0.26153846153846155


theta for epoch 383 : tensor([[3.6056, 3.6261, 3.7696, 3.7183, 3.7009, 3.5869, 3.6281, 3.5272, 3.5272,
         1.2665, 1.2419, 1.2404, 1.2450, 1.2889, 1.2295, 1.1845, 1.2889, 1.2303,
         1.5876, 1.5716, 1.5964, 1.5772, 1.5829, 1.5845, 1.5931, 1.5845, 1.5845,
         1.3219, 1.3330, 1.3170, 1.3411, 1.3204, 1.3537, 1.3459, 1.3318, 1.3171,
         1.5864, 1.6035, 1.5913, 1.5877, 1.5950, 1.5855, 1.6046, 1.5574, 1.5620,
         1.2755, 1.3046, 1.2955, 1.3148, 1.2695, 1.2599, 1.2498, 1.3393, 1.2917],
        [1.3759, 1.2292, 1.2185, 1.2611, 1.2613, 1.2735, 1.2675, 1.1757, 1.1757,
         3.5561, 3.6492, 3.4831, 3.9104, 3.5571, 4.3115, 3.4138, 3.5105, 4.0337,
         1.5780, 1.5660, 1.5397, 1.5394, 1.5604, 1.5698, 1.5933, 1.5698, 1.5698,
         1.3499, 1.3166, 1.3122, 1.3678, 1.3112, 1.4039, 1.3848, 1.3546, 1.3091,
         1.5508, 1.6061, 1.5706, 1.5575, 1.5520, 1.5896, 1.6085, 1.4436, 1.5413,
         1.1913, 1.3049, 1.2781, 1.3263, 1.1859, 1.1931, 1.1227, 1.3868, 1.2686],
        [1.4330, 1.4329, 1.4313, 1.4285, 1.4289, 1.4330, 1.4287, 1.4330, 1.4330,
         1.4367, 1.4361, 1.4367, 1.4367, 1.4367, 1.4180, 1.4367, 1.4356, 1.4333,
         2.1934, 2.1937, 2.2105, 2.1864, 2.1678, 2.1661, 2.1953, 2.1652, 2.1652,
         1.4930, 1.4914, 1.4988, 1.4988, 1.4930, 1.4988, 1.4988, 1.4988, 1.4988,
         1.7682, 1.7683, 1.7683, 1.7651, 1.7682, 1.7682, 1.7683, 1.7456, 1.7483,
         1.4749, 1.4794, 1.4795, 1.4794, 1.4712, 1.4795, 1.4755, 1.4794, 1.4794],
        [1.3001, 1.2982, 1.2824, 1.2736, 1.2972, 1.2955, 1.2967, 1.2971, 1.2971,
         1.3033, 1.2964, 1.2926, 1.2922, 1.3042, 1.2886, 1.2992, 1.3038, 1.2759,
         1.6361, 1.6098, 1.6331, 1.6324, 1.6318, 1.6318, 1.6341, 1.6355, 1.6355,
         3.4670, 3.2566, 3.1818, 3.2400, 3.3913, 3.2088, 3.4420, 3.1895, 3.1683,
         1.6420, 1.6346, 1.6329, 1.6360, 1.6390, 1.6150, 1.6404, 1.5798, 1.6062,
         1.3442, 1.3387, 1.3288, 1.3436, 1.3391, 1.3312, 1.3435, 1.3439, 1.3457],
        [1.4359, 1.4317, 1.3883, 1.3914, 1.4290, 1.4357, 1.4343, 1.4358, 1.4358,
         1.4384, 1.4358, 1.4307, 1.4261, 1.4396, 1.3992, 1.4337, 1.4396, 1.4348,
         1.7487, 1.7401, 1.7389, 1.7470, 1.7646, 1.7632, 1.7433, 1.7647, 1.7647,
         1.4596, 1.4651, 1.5015, 1.4963, 1.4650, 1.5001, 1.4884, 1.5016, 1.4985,
         2.1938, 2.1739, 2.1625, 2.1803, 2.2239, 2.2421, 2.2085, 2.3113, 2.3085,
         1.4672, 1.4575, 1.4719, 1.4822, 1.4695, 1.4790, 1.4498, 1.4762, 1.4823],
        [1.4167, 1.3230, 1.3193, 1.3380, 1.3313, 1.3412, 1.3401, 1.2782, 1.2782,
         1.3122, 1.2675, 1.2660, 1.2728, 1.3547, 1.2332, 1.1780, 1.3547, 1.2554,
         1.6520, 1.6291, 1.6113, 1.6067, 1.6292, 1.6255, 1.6449, 1.6306, 1.6306,
         1.4043, 1.3783, 1.3778, 1.3946, 1.3798, 1.4216, 1.4237, 1.3983, 1.3779,
         1.6257, 1.6251, 1.6307, 1.6206, 1.5974, 1.6010, 1.6599, 1.5529, 1.5229,
         4.0124, 3.5144, 3.6049, 3.5885, 3.6024, 3.2834, 4.0091, 3.5637, 3.3158]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 383 : 1782.3918997051665
Test loss for epoch 383 : 194.31229894889844
Test Precision for epoch 383 : 0.26153846153846155
Test Recall for epoch 383 : 0.26153846153846155
Test F1 for epoch 383 : 0.26153846153846155


theta for epoch 384 : tensor([[3.6079, 3.6285, 3.7720, 3.7207, 3.7033, 3.5893, 3.6305, 3.5295, 3.5295,
         1.2601, 1.2348, 1.2333, 1.2380, 1.2830, 1.2215, 1.1755, 1.2830, 1.2224,
         1.5850, 1.5688, 1.5939, 1.5741, 1.5798, 1.5814, 1.5904, 1.5814, 1.5814,
         1.3249, 1.3360, 1.3193, 1.3442, 1.3231, 1.3573, 1.3492, 1.3347, 1.3193,
         1.5812, 1.5986, 1.5860, 1.5825, 1.5900, 1.5806, 1.5999, 1.5522, 1.5569,
         1.2855, 1.3153, 1.3059, 1.3258, 1.2792, 1.2694, 1.2586, 1.3510, 1.3020],
        [1.3583, 1.2124, 1.2016, 1.2442, 1.2445, 1.2567, 1.2506, 1.1595, 1.1595,
         3.5703, 3.6635, 3.4973, 3.9248, 3.5713, 4.3266, 3.4281, 3.5247, 4.0483,
         1.5624, 1.5504, 1.5239, 1.5240, 1.5452, 1.5546, 1.5778, 1.5546, 1.5546,
         1.3368, 1.3035, 1.2996, 1.3546, 1.2983, 1.3905, 1.3715, 1.3416, 1.2965,
         1.5343, 1.5894, 1.5542, 1.5410, 1.5354, 1.5730, 1.5917, 1.4266, 1.5247,
         1.1846, 1.2981, 1.2714, 1.3194, 1.1793, 1.1870, 1.1151, 1.3794, 1.2620],
        [1.4384, 1.4383, 1.4367, 1.4339, 1.4343, 1.4384, 1.4341, 1.4384, 1.4384,
         1.4301, 1.4294, 1.4300, 1.4300, 1.4301, 1.4113, 1.4300, 1.4289, 1.4267,
         2.1910, 2.1914, 2.2082, 2.1841, 2.1655, 2.1638, 2.1930, 2.1629, 2.1629,
         1.4958, 1.4943, 1.5017, 1.5017, 1.4959, 1.5017, 1.5017, 1.5017, 1.5017,
         1.7637, 1.7638, 1.7638, 1.7606, 1.7637, 1.7637, 1.7638, 1.7411, 1.7438,
         1.4858, 1.4903, 1.4903, 1.4903, 1.4821, 1.4903, 1.4864, 1.4903, 1.4903],
        [1.3061, 1.3041, 1.2883, 1.2795, 1.3031, 1.3014, 1.3026, 1.3029, 1.3029,
         1.2967, 1.2898, 1.2860, 1.2856, 1.2977, 1.2820, 1.2926, 1.2972, 1.2693,
         1.6338, 1.6075, 1.6308, 1.6301, 1.6295, 1.6295, 1.6318, 1.6332, 1.6332,
         3.4676, 3.2572, 3.1825, 3.2407, 3.3920, 3.2096, 3.4426, 3.1903, 3.1690,
         1.6375, 1.6302, 1.6284, 1.6315, 1.6345, 1.6105, 1.6360, 1.5753, 1.6018,
         1.3552, 1.3497, 1.3398, 1.3546, 1.3501, 1.3423, 1.3545, 1.3549, 1.3567],
        [1.4413, 1.4370, 1.3936, 1.3968, 1.4344, 1.4412, 1.4397, 1.4412, 1.4412,
         1.4317, 1.4292, 1.4240, 1.4193, 1.4329, 1.3924, 1.4270, 1.4329, 1.4281,
         1.7464, 1.7377, 1.7365, 1.7446, 1.7622, 1.7609, 1.7410, 1.7624, 1.7624,
         1.4625, 1.4679, 1.5044, 1.4992, 1.4679, 1.5030, 1.4913, 1.5045, 1.5014,
         2.1894, 2.1694, 2.1580, 2.1759, 2.2195, 2.2376, 2.2040, 2.3070, 2.3042,
         1.4780, 1.4684, 1.4828, 1.4931, 1.4803, 1.4898, 1.4607, 1.4870, 1.4932],
        [1.4470, 1.3520, 1.3485, 1.3673, 1.3606, 1.3705, 1.3693, 1.3062, 1.3062,
         1.3218, 1.2777, 1.2762, 1.2826, 1.3638, 1.2423, 1.1881, 1.3638, 1.2647,
         1.6672, 1.6444, 1.6269, 1.6221, 1.6443, 1.6406, 1.6601, 1.6457, 1.6457,
         1.4279, 1.4021, 1.4012, 1.4184, 1.4035, 1.4454, 1.4474, 1.4220, 1.4013,
         1.6370, 1.6367, 1.6419, 1.6320, 1.6090, 1.6127, 1.6711, 1.5650, 1.5355,
         3.9828, 3.4848, 3.5753, 3.5589, 3.5728, 3.2538, 3.9795, 3.5342, 3.2863]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 384 : 1782.4374483226952
Test loss for epoch 384 : 196.13493927617958
Test Precision for epoch 384 : 0.26153846153846155
Test Recall for epoch 384 : 0.26153846153846155
Test F1 for epoch 384 : 0.26153846153846155


theta for epoch 385 : tensor([[3.6171, 3.6378, 3.7813, 3.7300, 3.7127, 3.5986, 3.6398, 3.5390, 3.5390,
         1.2530, 1.2266, 1.2249, 1.2299, 1.2770, 1.2121, 1.1639, 1.2770, 1.2131,
         1.5889, 1.5726, 1.5979, 1.5775, 1.5833, 1.5849, 1.5943, 1.5849, 1.5849,
         1.3362, 1.3472, 1.3297, 1.3557, 1.3340, 1.3692, 1.3609, 1.3459, 1.3298,
         1.5816, 1.5995, 1.5865, 1.5829, 1.5906, 1.5813, 1.6009, 1.5527, 1.5574,
         1.2729, 1.3035, 1.2938, 1.3141, 1.2665, 1.2564, 1.2451, 1.3399, 1.2898],
        [1.3400, 1.1933, 1.1826, 1.2252, 1.2255, 1.2378, 1.2317, 1.1401, 1.1401,
         3.5872, 3.6804, 3.5141, 3.9420, 3.5882, 4.3442, 3.4450, 3.5416, 4.0656,
         1.5499, 1.5379, 1.5111, 1.5114, 1.5327, 1.5422, 1.5655, 1.5423, 1.5423,
         1.3272, 1.2936, 1.2899, 1.3451, 1.2884, 1.3811, 1.3620, 1.3320, 1.2867,
         1.5206, 1.5759, 1.5406, 1.5273, 1.5216, 1.5594, 1.5782, 1.4120, 1.5109,
         1.1631, 1.2762, 1.2497, 1.2973, 1.1580, 1.1661, 1.0929, 1.3569, 1.2404],
        [1.4455, 1.4455, 1.4438, 1.4410, 1.4414, 1.4455, 1.4412, 1.4455, 1.4455,
         1.4242, 1.4235, 1.4242, 1.4242, 1.4242, 1.4054, 1.4242, 1.4230, 1.4208,
         2.1959, 2.1963, 2.2131, 2.1888, 2.1702, 2.1685, 2.1977, 2.1675, 2.1675,
         1.5086, 1.5071, 1.5145, 1.5145, 1.5086, 1.5145, 1.5145, 1.5145, 1.5145,
         1.7658, 1.7659, 1.7659, 1.7627, 1.7658, 1.7658, 1.7659, 1.7431, 1.7458,
         1.4746, 1.4792, 1.4792, 1.4792, 1.4709, 1.4792, 1.4753, 1.4792, 1.4792],
        [1.3138, 1.3116, 1.2959, 1.2871, 1.3106, 1.3090, 1.3102, 1.3104, 1.3104,
         1.2910, 1.2841, 1.2802, 1.2799, 1.2919, 1.2762, 1.2868, 1.2915, 1.2634,
         1.6392, 1.6129, 1.6362, 1.6356, 1.6349, 1.6350, 1.6373, 1.6386, 1.6386,
         3.4770, 3.2669, 3.1922, 3.2504, 3.4015, 3.2192, 3.4521, 3.1999, 3.1788,
         1.6397, 1.6324, 1.6307, 1.6337, 1.6367, 1.6128, 1.6382, 1.5775, 1.6040,
         1.3441, 1.3387, 1.3288, 1.3435, 1.3391, 1.3312, 1.3434, 1.3439, 1.3457],
        [1.4484, 1.4441, 1.4007, 1.4040, 1.4415, 1.4483, 1.4468, 1.4483, 1.4483,
         1.4258, 1.4233, 1.4181, 1.4134, 1.4271, 1.3864, 1.4211, 1.4271, 1.4222,
         1.7516, 1.7430, 1.7417, 1.7498, 1.7675, 1.7661, 1.7462, 1.7676, 1.7676,
         1.4753, 1.4806, 1.5172, 1.5120, 1.4807, 1.5158, 1.5041, 1.5173, 1.5142,
         2.1914, 2.1714, 2.1600, 2.1778, 2.2215, 2.2396, 2.2060, 2.3092, 2.3063,
         1.4668, 1.4572, 1.4716, 1.4820, 1.4691, 1.4787, 1.4494, 1.4759, 1.4820],
        [1.4668, 1.3723, 1.3689, 1.3875, 1.3809, 1.3907, 1.3895, 1.3267, 1.3267,
         1.3270, 1.2836, 1.2822, 1.2881, 1.3681, 1.2471, 1.1947, 1.3681, 1.2698,
         1.6828, 1.6604, 1.6428, 1.6383, 1.6602, 1.6566, 1.6759, 1.6616, 1.6616,
         1.4515, 1.4258, 1.4251, 1.4420, 1.4272, 1.4687, 1.4707, 1.4455, 1.4251,
         1.6494, 1.6489, 1.6541, 1.6443, 1.6215, 1.6251, 1.6830, 1.5780, 1.5486,
         3.9553, 3.4574, 3.5479, 3.5316, 3.5453, 3.2264, 3.9520, 3.5069, 3.2589]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 385 : 1782.4935856792492
Test loss for epoch 385 : 198.70906280691554
Test Precision for epoch 385 : 0.26153846153846155
Test Recall for epoch 385 : 0.26153846153846155
Test F1 for epoch 385 : 0.26153846153846155


theta for epoch 386 : tensor([[3.6252, 3.6461, 3.7896, 3.7382, 3.7210, 3.6067, 3.6479, 3.5473, 3.5473,
         1.2457, 1.2174, 1.2157, 1.2211, 1.2713, 1.2017, 1.1498, 1.2714, 1.2028,
         1.5926, 1.5761, 1.6017, 1.5807, 1.5865, 1.5882, 1.5979, 1.5881, 1.5881,
         1.3312, 1.3422, 1.3241, 1.3509, 1.3287, 1.3649, 1.3563, 1.3409, 1.3241,
         1.5857, 1.6039, 1.5906, 1.5870, 1.5948, 1.5856, 1.6055, 1.5566, 1.5614,
         1.2707, 1.3018, 1.2920, 1.3126, 1.2642, 1.2540, 1.2420, 1.3389, 1.2879],
        [1.3142, 1.1658, 1.1553, 1.1980, 1.1983, 1.2105, 1.2044, 1.1116, 1.1116,
         3.6052, 3.6985, 3.5322, 3.9603, 3.6061, 4.3631, 3.4631, 3.5596, 4.0841,
         1.5382, 1.5260, 1.4989, 1.4991, 1.5206, 1.5302, 1.5538, 1.5302, 1.5302,
         1.3099, 1.2761, 1.2721, 1.3279, 1.2708, 1.3643, 1.3450, 1.3147, 1.2690,
         1.5100, 1.5660, 1.5302, 1.5168, 1.5110, 1.5492, 1.5684, 1.4004, 1.5001,
         1.1498, 1.2634, 1.2368, 1.2846, 1.1449, 1.1532, 1.0786, 1.3442, 1.2276],
        [1.4332, 1.4331, 1.4315, 1.4287, 1.4290, 1.4332, 1.4289, 1.4332, 1.4332,
         1.4203, 1.4196, 1.4203, 1.4203, 1.4203, 1.4014, 1.4203, 1.4191, 1.4169,
         2.2024, 2.2028, 2.2196, 2.1951, 2.1764, 2.1747, 2.2038, 2.1737, 2.1737,
         1.5076, 1.5061, 1.5135, 1.5135, 1.5077, 1.5135, 1.5135, 1.5135, 1.5135,
         1.7731, 1.7732, 1.7732, 1.7700, 1.7731, 1.7731, 1.7732, 1.7504, 1.7531,
         1.4748, 1.4794, 1.4794, 1.4794, 1.4711, 1.4795, 1.4754, 1.4794, 1.4794],
        [1.3015, 1.2992, 1.2834, 1.2747, 1.2982, 1.2966, 1.2977, 1.2980, 1.2980,
         1.2871, 1.2801, 1.2763, 1.2759, 1.2881, 1.2721, 1.2827, 1.2877, 1.2594,
         1.6462, 1.6199, 1.6432, 1.6426, 1.6419, 1.6420, 1.6443, 1.6456, 1.6456,
         3.4745, 3.2644, 3.1898, 3.2480, 3.3990, 3.2168, 3.4495, 3.1975, 3.1763,
         1.6471, 1.6397, 1.6380, 1.6410, 1.6440, 1.6201, 1.6455, 1.5849, 1.6113,
         1.3444, 1.3389, 1.3290, 1.3438, 1.3394, 1.3315, 1.3436, 1.3442, 1.3460],
        [1.4361, 1.4317, 1.3881, 1.3916, 1.4292, 1.4359, 1.4344, 1.4360, 1.4360,
         1.4219, 1.4194, 1.4142, 1.4094, 1.4232, 1.3823, 1.4172, 1.4232, 1.4183,
         1.7585, 1.7499, 1.7485, 1.7566, 1.7744, 1.7730, 1.7531, 1.7745, 1.7745,
         1.4743, 1.4795, 1.5163, 1.5109, 1.4797, 1.5148, 1.5031, 1.5163, 1.5132,
         2.1984, 2.1784, 2.1669, 2.1848, 2.2286, 2.2465, 2.2129, 2.3164, 2.3134,
         1.4669, 1.4574, 1.4718, 1.4822, 1.4693, 1.4789, 1.4494, 1.4761, 1.4823],
        [1.4625, 1.3709, 1.3675, 1.3856, 1.3791, 1.3887, 1.3876, 1.3266, 1.3266,
         1.3285, 1.2863, 1.2848, 1.2903, 1.3686, 1.2487, 1.1988, 1.3686, 1.2718,
         1.6938, 1.6716, 1.6538, 1.6501, 1.6717, 1.6682, 1.6869, 1.6731, 1.6731,
         1.4560, 1.4307, 1.4306, 1.4465, 1.4323, 1.4725, 1.4748, 1.4502, 1.4306,
         1.6613, 1.6603, 1.6660, 1.6562, 1.6333, 1.6366, 1.6941, 1.5902, 1.5609,
         3.9411, 3.4434, 3.5338, 3.5176, 3.5311, 3.2125, 3.9377, 3.4929, 3.2450]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 386 : 1782.5871393968355
Test loss for epoch 386 : 201.47037341493382
Test Precision for epoch 386 : 0.26153846153846155
Test Recall for epoch 386 : 0.26153846153846155
Test F1 for epoch 386 : 0.26153846153846155


theta for epoch 387 : tensor([[3.6220, 3.6429, 3.7865, 3.7351, 3.7180, 3.6035, 3.6447, 3.5440, 3.5440,
         1.2404, 1.2111, 1.2093, 1.2149, 1.2670, 1.1942, 1.1406, 1.2670, 1.1956,
         1.5900, 1.5733, 1.5991, 1.5776, 1.5836, 1.5852, 1.5952, 1.5852, 1.5852,
         1.3230, 1.3339, 1.3154, 1.3428, 1.3204, 1.3571, 1.3483, 1.3326, 1.3155,
         1.5880, 1.6066, 1.5930, 1.5894, 1.5973, 1.5882, 1.6082, 1.5590, 1.5638,
         1.2861, 1.3176, 1.3077, 1.3284, 1.2797, 1.2694, 1.2569, 1.3549, 1.3036],
        [1.3834, 1.2344, 1.2242, 1.2666, 1.2670, 1.2790, 1.2730, 1.1796, 1.1796,
         3.5313, 3.6247, 3.4583, 3.8866, 3.5322, 4.2898, 3.3894, 3.4856, 4.0105,
         1.5965, 1.5845, 1.5580, 1.5579, 1.5789, 1.5883, 1.6117, 1.5883, 1.5883,
         1.3668, 1.3334, 1.3291, 1.3845, 1.3281, 1.4206, 1.4015, 1.3714, 1.3260,
         1.5698, 1.6249, 1.5896, 1.5765, 1.5708, 1.6084, 1.6274, 1.4624, 1.5601,
         1.2215, 1.3342, 1.3079, 1.3551, 1.2166, 1.2249, 1.1501, 1.4140, 1.2987],
        [1.4327, 1.4326, 1.4309, 1.4282, 1.4284, 1.4326, 1.4283, 1.4326, 1.4326,
         1.4156, 1.4149, 1.4156, 1.4156, 1.4156, 1.3967, 1.4156, 1.4144, 1.4122,
         2.1995, 2.2000, 2.2168, 2.1924, 2.1737, 2.1720, 2.2011, 2.1710, 2.1710,
         1.4989, 1.4974, 1.5048, 1.5048, 1.4990, 1.5048, 1.5048, 1.5048, 1.5048,
         1.7757, 1.7757, 1.7757, 1.7725, 1.7756, 1.7756, 1.7757, 1.7529, 1.7556,
         1.4882, 1.4929, 1.4929, 1.4929, 1.4846, 1.4929, 1.4888, 1.4929, 1.4929],
        [1.3011, 1.2988, 1.2830, 1.2744, 1.2978, 1.2962, 1.2974, 1.2975, 1.2975,
         1.2824, 1.2754, 1.2715, 1.2712, 1.2834, 1.2673, 1.2779, 1.2830, 1.2547,
         1.6434, 1.6171, 1.6404, 1.6397, 1.6391, 1.6392, 1.6415, 1.6428, 1.6428,
         3.4649, 3.2549, 3.1802, 3.2385, 3.3895, 3.2073, 3.4400, 3.1880, 3.1667,
         1.6497, 1.6423, 1.6406, 1.6436, 1.6466, 1.6227, 1.6481, 1.5874, 1.6139,
         1.3580, 1.3526, 1.3427, 1.3575, 1.3530, 1.3452, 1.3573, 1.3578, 1.3596],
        [1.4355, 1.4310, 1.3873, 1.3911, 1.4286, 1.4354, 1.4338, 1.4355, 1.4355,
         1.4172, 1.4147, 1.4095, 1.4047, 1.4185, 1.3775, 1.4125, 1.4185, 1.4136,
         1.7557, 1.7471, 1.7456, 1.7537, 1.7716, 1.7702, 1.7503, 1.7718, 1.7718,
         1.4655, 1.4706, 1.5076, 1.5021, 1.4709, 1.5061, 1.4944, 1.5076, 1.5045,
         2.2008, 2.1808, 2.1693, 2.1873, 2.2311, 2.2489, 2.2152, 2.3190, 2.3161,
         1.4801, 1.4708, 1.4852, 1.4957, 1.4826, 1.4924, 1.4626, 1.4895, 1.4958],
        [1.4555, 1.3685, 1.3648, 1.3824, 1.3759, 1.3853, 1.3842, 1.3266, 1.3266,
         1.3248, 1.2844, 1.2830, 1.2878, 1.3636, 1.2459, 1.1997, 1.3636, 1.2695,
         1.6913, 1.6694, 1.6515, 1.6488, 1.6702, 1.6667, 1.6845, 1.6715, 1.6715,
         1.4478, 1.4229, 1.4239, 1.4380, 1.4248, 1.4630, 1.4658, 1.4421, 1.4239,
         1.6648, 1.6630, 1.6694, 1.6597, 1.6366, 1.6395, 1.6965, 1.5941, 1.5645,
         3.9388, 3.4415, 3.5318, 3.5157, 3.5290, 3.2108, 3.9354, 3.4911, 3.2433]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 387 : 1785.883376249348
Test loss for epoch 387 : 195.43123805811717
Test Precision for epoch 387 : 0.26153846153846155
Test Recall for epoch 387 : 0.26153846153846155
Test F1 for epoch 387 : 0.26153846153846155


theta for epoch 388 : tensor([[3.6161, 3.6371, 3.7808, 3.7292, 3.7122, 3.5976, 3.6387, 3.5379, 3.5379,
         1.2540, 1.2230, 1.2211, 1.2272, 1.2820, 1.2049, 1.1481, 1.2821, 1.2065,
         1.5785, 1.5616, 1.5876, 1.5653, 1.5714, 1.5730, 1.5836, 1.5730, 1.5730,
         1.3208, 1.3315, 1.3121, 1.3407, 1.3177, 1.3556, 1.3465, 1.3302, 1.3122,
         1.5768, 1.5958, 1.5817, 1.5782, 1.5862, 1.5773, 1.5977, 1.5477, 1.5525,
         1.2934, 1.3255, 1.3154, 1.3366, 1.2869, 1.2765, 1.2635, 1.3635, 1.3113],
        [1.4404, 1.2897, 1.2799, 1.3222, 1.3225, 1.3345, 1.3285, 1.2337, 1.2337,
         3.4739, 3.5674, 3.4010, 3.8294, 3.4748, 4.2331, 3.3322, 3.4283, 3.9534,
         1.6384, 1.6264, 1.6006, 1.6001, 1.6207, 1.6299, 1.6532, 1.6299, 1.6299,
         1.4153, 1.3823, 1.3776, 1.4328, 1.3769, 1.4688, 1.4498, 1.4198, 1.3745,
         1.6097, 1.6638, 1.6290, 1.6162, 1.6107, 1.6477, 1.6665, 1.5045, 1.6002,
         1.2781, 1.3898, 1.3638, 1.4105, 1.2734, 1.2816, 1.2066, 1.4686, 1.3547],
        [1.4334, 1.4333, 1.4317, 1.4290, 1.4291, 1.4334, 1.4291, 1.4334, 1.4334,
         1.4295, 1.4287, 1.4294, 1.4294, 1.4295, 1.4105, 1.4294, 1.4283, 1.4260,
         2.1880, 2.1886, 2.2054, 2.1814, 2.1625, 2.1608, 2.1899, 2.1598, 2.1598,
         1.4954, 1.4938, 1.5013, 1.5013, 1.4954, 1.5013, 1.5012, 1.5013, 1.5013,
         1.7647, 1.7648, 1.7648, 1.7616, 1.7647, 1.7647, 1.7648, 1.7418, 1.7446,
         1.4924, 1.4972, 1.4972, 1.4972, 1.4888, 1.4972, 1.4930, 1.4972, 1.4972],
        [1.3024, 1.3000, 1.2841, 1.2756, 1.2989, 1.2974, 1.2985, 1.2986, 1.2986,
         1.2964, 1.2893, 1.2855, 1.2851, 1.2974, 1.2812, 1.2917, 1.2970, 1.2686,
         1.6315, 1.6051, 1.6285, 1.6278, 1.6272, 1.6272, 1.6295, 1.6309, 1.6309,
         3.4590, 3.2490, 3.1743, 3.2327, 3.3836, 3.2015, 3.4341, 3.1822, 3.1609,
         1.6387, 1.6314, 1.6297, 1.6327, 1.6357, 1.6118, 1.6372, 1.5765, 1.6030,
         1.3626, 1.3572, 1.3472, 1.3621, 1.3576, 1.3498, 1.3618, 1.3624, 1.3643],
        [1.4363, 1.4316, 1.3878, 1.3919, 1.4294, 1.4362, 1.4345, 1.4362, 1.4362,
         1.4311, 1.4285, 1.4233, 1.4184, 1.4323, 1.3911, 1.4264, 1.4323, 1.4273,
         1.7437, 1.7351, 1.7335, 1.7417, 1.7597, 1.7582, 1.7384, 1.7599, 1.7599,
         1.4620, 1.4668, 1.5040, 1.4985, 1.4673, 1.5025, 1.4908, 1.5041, 1.5010,
         2.1901, 2.1701, 2.1584, 2.1765, 2.2205, 2.2382, 2.2044, 2.3087, 2.3058,
         1.4841, 1.4750, 1.4893, 1.5000, 1.4867, 1.4967, 1.4664, 1.4937, 1.5000],
        [1.4407, 1.3594, 1.3552, 1.3722, 1.3659, 1.3750, 1.3740, 1.3205, 1.3205,
         1.3343, 1.2956, 1.2942, 1.2985, 1.3716, 1.2562, 1.2138, 1.3716, 1.2804,
         1.6765, 1.6551, 1.6370, 1.6355, 1.6566, 1.6531, 1.6699, 1.6579, 1.6579,
         1.4377, 1.4133, 1.4157, 1.4277, 1.4156, 1.4514, 1.4548, 1.4322, 1.4158,
         1.6525, 1.6497, 1.6570, 1.6473, 1.6241, 1.6264, 1.6827, 1.5822, 1.5524,
         3.9399, 3.4432, 3.5334, 3.5173, 3.5304, 3.2126, 3.9364, 3.4928, 3.2452]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 388 : 1789.5912914459307
Test loss for epoch 388 : 194.97088965927506
Test Precision for epoch 388 : 0.26153846153846155
Test Recall for epoch 388 : 0.26153846153846155
Test F1 for epoch 388 : 0.26153846153846155


theta for epoch 389 : tensor([[3.5963, 3.6170, 3.7610, 3.7093, 3.6925, 3.5774, 3.6186, 3.5175, 3.5175,
         1.2871, 1.2540, 1.2519, 1.2586, 1.3170, 1.2344, 1.1735, 1.3170, 1.2363,
         1.5749, 1.5576, 1.5842, 1.5602, 1.5665, 1.5681, 1.5798, 1.5681, 1.5681,
         1.3271, 1.3375, 1.3162, 1.3473, 1.3230, 1.3635, 1.3537, 1.3362, 1.3163,
         1.5675, 1.5875, 1.5725, 1.5689, 1.5774, 1.5688, 1.5898, 1.5386, 1.5434,
         1.2712, 1.3049, 1.2942, 1.3164, 1.2644, 1.2536, 1.2402, 1.3445, 1.2899],
        [1.4807, 1.3281, 1.3187, 1.3608, 1.3612, 1.3730, 1.3672, 1.2708, 1.2708,
         3.4330, 3.5265, 3.3600, 3.7885, 3.4339, 4.1926, 3.2913, 3.3873, 3.9126,
         1.6732, 1.6614, 1.6359, 1.6354, 1.6556, 1.6647, 1.6878, 1.6647, 1.6647,
         1.4557, 1.4228, 1.4180, 1.4730, 1.4175, 1.5088, 1.4899, 1.4601, 1.4150,
         1.6401, 1.6934, 1.6590, 1.6465, 1.6411, 1.6775, 1.6961, 1.5367, 1.6307,
         1.3064, 1.4160, 1.3907, 1.4362, 1.3020, 1.3104, 1.2357, 1.4928, 1.3818],
        [1.4264, 1.4263, 1.4247, 1.4220, 1.4220, 1.4264, 1.4221, 1.4264, 1.4264,
         1.4609, 1.4601, 1.4609, 1.4608, 1.4609, 1.4419, 1.4609, 1.4597, 1.4574,
         2.1825, 2.1832, 2.2001, 2.1762, 2.1571, 2.1555, 2.1846, 2.1544, 2.1544,
         1.4983, 1.4968, 1.5042, 1.5042, 1.4983, 1.5042, 1.5042, 1.5042, 1.5042,
         1.7551, 1.7552, 1.7552, 1.7519, 1.7550, 1.7550, 1.7552, 1.7320, 1.7349,
         1.4658, 1.4708, 1.4708, 1.4708, 1.4623, 1.4708, 1.4665, 1.4707, 1.4708],
        [1.2963, 1.2934, 1.2775, 1.2691, 1.2924, 1.2909, 1.2920, 1.2918, 1.2918,
         1.3281, 1.3211, 1.3172, 1.3169, 1.3292, 1.3129, 1.3233, 1.3288, 1.3003,
         1.6263, 1.5999, 1.6233, 1.6226, 1.6220, 1.6220, 1.6243, 1.6257, 1.6257,
         3.4572, 3.2474, 3.1727, 3.2311, 3.3819, 3.1999, 3.4323, 3.1806, 3.1593,
         1.6293, 1.6220, 1.6203, 1.6233, 1.6263, 1.6024, 1.6279, 1.5671, 1.5936,
         1.3365, 1.3312, 1.3212, 1.3361, 1.3316, 1.3237, 1.3357, 1.3365, 1.3383],
        [1.4293, 1.4244, 1.3804, 1.3849, 1.4224, 1.4292, 1.4274, 1.4293, 1.4293,
         1.4624, 1.4599, 1.4547, 1.4497, 1.4637, 1.4223, 1.4578, 1.4637, 1.4587,
         1.7381, 1.7296, 1.7277, 1.7359, 1.7542, 1.7526, 1.7328, 1.7544, 1.7544,
         1.4648, 1.4694, 1.5069, 1.5013, 1.4702, 1.5053, 1.4938, 1.5070, 1.5039,
         2.1807, 2.1606, 2.1489, 2.1671, 2.2113, 2.2288, 2.1949, 2.2999, 2.2969,
         1.4573, 1.4484, 1.4628, 1.4735, 1.4600, 1.4702, 1.4394, 1.4673, 1.4736],
        [1.4140, 1.3382, 1.3337, 1.3500, 1.3437, 1.3526, 1.3516, 1.3023, 1.3023,
         1.3567, 1.3197, 1.3183, 1.3222, 1.3925, 1.2792, 1.2407, 1.3925, 1.3042,
         1.6632, 1.6423, 1.6238, 1.6238, 1.6446, 1.6412, 1.6568, 1.6459, 1.6459,
         1.4276, 1.4036, 1.4078, 1.4173, 1.4064, 1.4396, 1.4438, 1.4223, 1.4078,
         1.6381, 1.6341, 1.6424, 1.6328, 1.6093, 1.6111, 1.6668, 1.5680, 1.5379,
         3.9365, 3.4403, 3.5304, 3.5144, 3.5272, 3.2099, 3.9330, 3.4900, 3.2425]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 389 : 1789.383294611507
Test loss for epoch 389 : 194.79093255665424
Test Precision for epoch 389 : 0.26153846153846155
Test Recall for epoch 389 : 0.26153846153846155
Test F1 for epoch 389 : 0.26153846153846155


theta for epoch 390 : tensor([[3.5683, 3.5888, 3.7330, 3.6812, 3.6645, 3.5491, 3.5903, 3.4886, 3.4886,
         1.3258, 1.2903, 1.2880, 1.2955, 1.3578, 1.2693, 1.2034, 1.3579, 1.2714,
         1.5752, 1.5574, 1.5849, 1.5585, 1.5649, 1.5665, 1.5799, 1.5665, 1.5665,
         1.3196, 1.3297, 1.3055, 1.3403, 1.3142, 1.3585, 1.3476, 1.3283, 1.3055,
         1.5626, 1.5842, 1.5677, 1.5642, 1.5732, 1.5652, 1.5871, 1.5341, 1.5389,
         1.2504, 1.2865, 1.2750, 1.2988, 1.2430, 1.2313, 1.2176, 1.3290, 1.2703],
        [1.5085, 1.3545, 1.3455, 1.3874, 1.3878, 1.3994, 1.3936, 1.2960, 1.2960,
         3.4038, 3.4973, 3.3309, 3.7595, 3.4047, 4.1639, 3.2623, 3.3581, 3.8836,
         1.6996, 1.6880, 1.6626, 1.6624, 1.6823, 1.6913, 1.7141, 1.6913, 1.6913,
         1.4777, 1.4452, 1.4407, 1.4947, 1.4401, 1.5299, 1.5114, 1.4820, 1.4376,
         1.6639, 1.7162, 1.6824, 1.6701, 1.6647, 1.7006, 1.7189, 1.5617, 1.6545,
         1.3255, 1.4326, 1.4080, 1.4522, 1.3215, 1.3303, 1.2556, 1.5069, 1.3996],
        [1.4211, 1.4210, 1.4194, 1.4167, 1.4166, 1.4211, 1.4168, 1.4211, 1.4211,
         1.4958, 1.4950, 1.4958, 1.4957, 1.4958, 1.4767, 1.4958, 1.4946, 1.4922,
         2.1794, 2.1802, 2.1972, 2.1733, 2.1541, 2.1526, 2.1816, 2.1515, 2.1515,
         1.4857, 1.4842, 1.4916, 1.4916, 1.4858, 1.4917, 1.4916, 1.4916, 1.4916,
         1.7494, 1.7495, 1.7495, 1.7463, 1.7494, 1.7494, 1.7495, 1.7262, 1.7291,
         1.4400, 1.4450, 1.4450, 1.4450, 1.4364, 1.4450, 1.4406, 1.4450, 1.4450],
        [1.2925, 1.2887, 1.2728, 1.2646, 1.2878, 1.2864, 1.2874, 1.2865, 1.2865,
         1.3636, 1.3565, 1.3527, 1.3524, 1.3648, 1.3483, 1.3587, 1.3644, 1.3357,
         1.6241, 1.5977, 1.6210, 1.6203, 1.6197, 1.6197, 1.6221, 1.6234, 1.6234,
         3.4394, 3.2296, 3.1549, 3.2135, 3.3641, 3.1822, 3.4145, 3.1629, 3.1415,
         1.6242, 1.6168, 1.6151, 1.6181, 1.6212, 1.5972, 1.6228, 1.5619, 1.5884,
         1.3114, 1.3061, 1.2961, 1.3111, 1.3065, 1.2986, 1.3105, 1.3115, 1.3132],
        [1.4240, 1.4189, 1.3746, 1.3795, 1.4170, 1.4239, 1.4220, 1.4240, 1.4240,
         1.4972, 1.4947, 1.4895, 1.4844, 1.4985, 1.4568, 1.4926, 1.4985, 1.4934,
         1.7352, 1.7267, 1.7246, 1.7328, 1.7514, 1.7497, 1.7298, 1.7515, 1.7515,
         1.4522, 1.4564, 1.4944, 1.4886, 1.4575, 1.4927, 1.4812, 1.4944, 1.4913,
         2.1752, 2.1549, 2.1431, 2.1615, 2.2059, 2.2232, 2.1892, 2.2949, 2.2918,
         1.4312, 1.4225, 1.4369, 1.4478, 1.4339, 1.4444, 1.4130, 1.4414, 1.4479],
        [1.3819, 1.3101, 1.3054, 1.3212, 1.3150, 1.3237, 1.3228, 1.2764, 1.2764,
         1.3795, 1.3442, 1.3428, 1.3461, 1.4138, 1.3026, 1.2683, 1.4139, 1.3285,
         1.6484, 1.6279, 1.6089, 1.6105, 1.6310, 1.6277, 1.6421, 1.6323, 1.6323,
         1.4006, 1.3769, 1.3829, 1.3900, 1.3803, 1.4109, 1.4159, 1.3955, 1.3829,
         1.6238, 1.6186, 1.6281, 1.6184, 1.5946, 1.5958, 1.6510, 1.5537, 1.5232,
         3.9391, 3.4435, 3.5334, 3.5176, 3.5301, 3.2133, 3.9355, 3.4932, 3.2459]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 390 : 1792.4926405773042
Test loss for epoch 390 : 194.44463734553852
Test Precision for epoch 390 : 0.26153846153846155
Test Recall for epoch 390 : 0.26153846153846155
Test F1 for epoch 390 : 0.26153846153846155


theta for epoch 391 : tensor([[3.5507, 3.5711, 3.7155, 3.6635, 3.6471, 3.5313, 3.5725, 3.4706, 3.4706,
         1.3287, 1.2906, 1.2882, 1.2964, 1.3630, 1.2682, 1.1974, 1.3630, 1.2705,
         1.5794, 1.5609, 1.5895, 1.5601, 1.5666, 1.5683, 1.5838, 1.5682, 1.5682,
         1.3238, 1.3334, 1.3054, 1.3450, 1.3166, 1.3656, 1.3535, 1.3318, 1.3055,
         1.5653, 1.5888, 1.5704, 1.5669, 1.5766, 1.5693, 1.5923, 1.5373, 1.5421,
         1.2481, 1.2879, 1.2751, 1.3011, 1.2400, 1.2271, 1.2132, 1.3342, 1.2697],
        [1.5346, 1.3792, 1.3704, 1.4123, 1.4128, 1.4243, 1.4185, 1.3199, 1.3199,
         3.3756, 3.4691, 3.3027, 3.7313, 3.3765, 4.1362, 3.2342, 3.3299, 3.8556,
         1.7190, 1.7077, 1.6821, 1.6826, 1.7023, 1.7113, 1.7335, 1.7113, 1.7113,
         1.4958, 1.4636, 1.4597, 1.5125, 1.4587, 1.5470, 1.5288, 1.5001, 1.4567,
         1.6846, 1.7358, 1.7028, 1.6907, 1.6851, 1.7205, 1.7384, 1.5829, 1.6750,
         1.3466, 1.4517, 1.4278, 1.4706, 1.3431, 1.3525, 1.2775, 1.5234, 1.4197],
        [1.4423, 1.4422, 1.4407, 1.4379, 1.4377, 1.4423, 1.4380, 1.4423, 1.4423,
         1.4933, 1.4926, 1.4933, 1.4933, 1.4933, 1.4742, 1.4933, 1.4921, 1.4898,
         2.1795, 2.1804, 2.1974, 2.1735, 2.1541, 2.1526, 2.1816, 2.1514, 2.1514,
         1.4842, 1.4827, 1.4901, 1.4901, 1.4842, 1.4901, 1.4901, 1.4901, 1.4901,
         1.7512, 1.7512, 1.7512, 1.7480, 1.7511, 1.7511, 1.7512, 1.7278, 1.7307,
         1.4334, 1.4386, 1.4386, 1.4386, 1.4299, 1.4386, 1.4340, 1.4386, 1.4386],
        [1.3161, 1.3111, 1.2954, 1.2873, 1.3104, 1.3090, 1.3101, 1.3083, 1.3083,
         1.3621, 1.3549, 1.3511, 1.3507, 1.3633, 1.3465, 1.3569, 1.3629, 1.3340,
         1.6255, 1.5990, 1.6225, 1.6217, 1.6211, 1.6211, 1.6235, 1.6248, 1.6248,
         3.4292, 3.2196, 3.1449, 3.2036, 3.3541, 3.1723, 3.4044, 3.1529, 3.1315,
         1.6267, 1.6194, 1.6176, 1.6206, 1.6237, 1.5998, 1.6253, 1.5644, 1.5909,
         1.3059, 1.3008, 1.2907, 1.3059, 1.3011, 1.2931, 1.3050, 1.3064, 1.3079],
        [1.4451, 1.4399, 1.3955, 1.4008, 1.4382, 1.4451, 1.4431, 1.4452, 1.4452,
         1.4948, 1.4922, 1.4870, 1.4817, 1.4961, 1.4539, 1.4902, 1.4961, 1.4908,
         1.7355, 1.7270, 1.7246, 1.7330, 1.7518, 1.7501, 1.7302, 1.7520, 1.7520,
         1.4506, 1.4544, 1.4929, 1.4869, 1.4558, 1.4911, 1.4797, 1.4929, 1.4898,
         2.1769, 2.1564, 2.1445, 2.1630, 2.2078, 2.2247, 2.1907, 2.2972, 2.2940,
         1.4243, 1.4159, 1.4303, 1.4414, 1.4271, 1.4380, 1.4059, 1.4349, 1.4414],
        [1.3612, 1.2909, 1.2862, 1.3016, 1.2955, 1.3040, 1.3032, 1.2578, 1.2578,
         1.3661, 1.3327, 1.3314, 1.3341, 1.3988, 1.2904, 1.2610, 1.3988, 1.3171,
         1.6328, 1.6126, 1.5930, 1.5961, 1.6165, 1.6133, 1.6266, 1.6179, 1.6179,
         1.3779, 1.3544, 1.3620, 1.3669, 1.3583, 1.3867, 1.3924, 1.3730, 1.3620,
         1.6129, 1.6065, 1.6171, 1.6074, 1.5831, 1.5838, 1.6387, 1.5424, 1.5114,
         3.9536, 3.4585, 3.5483, 3.5326, 3.5449, 3.2286, 3.9499, 3.5083, 3.2612]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 391 : 1791.7019952096164
Test loss for epoch 391 : 194.703114438634
Test Precision for epoch 391 : 0.26153846153846155
Test Recall for epoch 391 : 0.26153846153846155
Test F1 for epoch 391 : 0.26153846153846155


theta for epoch 392 : tensor([[3.5293, 3.5495, 3.6940, 3.6419, 3.6258, 3.5095, 3.5508, 3.4485, 3.4485,
         1.3171, 1.2764, 1.2739, 1.2828, 1.3536, 1.2527, 1.1771, 1.3536, 1.2553,
         1.5821, 1.5628, 1.5926, 1.5599, 1.5667, 1.5683, 1.5861, 1.5683, 1.5683,
         1.3400, 1.3491, 1.3169, 1.3618, 1.3308, 1.3850, 1.3715, 1.3473, 1.3170,
         1.5693, 1.5949, 1.5745, 1.5710, 1.5815, 1.5750, 1.5993, 1.5418, 1.5468,
         1.2579, 1.3021, 1.2876, 1.3165, 1.2486, 1.2341, 1.2203, 1.3532, 1.2816],
        [1.5483, 1.3932, 1.3846, 1.4263, 1.4269, 1.4383, 1.4325, 1.3339, 1.3339,
         3.3519, 3.4455, 3.2790, 3.7077, 3.3528, 4.1129, 3.2107, 3.3062, 3.8321,
         1.7296, 1.7187, 1.6929, 1.6944, 1.7138, 1.7228, 1.7441, 1.7228, 1.7228,
         1.5116, 1.4797, 1.4768, 1.5280, 1.4752, 1.5617, 1.5439, 1.5161, 1.4738,
         1.6991, 1.7491, 1.7171, 1.7051, 1.6993, 1.7341, 1.7516, 1.5978, 1.6894,
         1.3677, 1.4708, 1.4477, 1.4890, 1.3649, 1.3751, 1.2993, 1.5398, 1.4399],
        [1.4581, 1.4581, 1.4566, 1.4538, 1.4535, 1.4582, 1.4539, 1.4582, 1.4582,
         1.4754, 1.4745, 1.4753, 1.4753, 1.4754, 1.4560, 1.4754, 1.4741, 1.4717,
         2.1783, 2.1793, 2.1964, 2.1724, 2.1528, 2.1514, 2.1804, 2.1502, 2.1502,
         1.4950, 1.4936, 1.5010, 1.5010, 1.4950, 1.5010, 1.5010, 1.5010, 1.5010,
         1.7546, 1.7547, 1.7547, 1.7514, 1.7546, 1.7546, 1.7547, 1.7312, 1.7341,
         1.4409, 1.4462, 1.4462, 1.4462, 1.4374, 1.4462, 1.4414, 1.4462, 1.4462],
        [1.3348, 1.3284, 1.3128, 1.3048, 1.3280, 1.3265, 1.3276, 1.3247, 1.3247,
         1.3452, 1.3380, 1.3341, 1.3338, 1.3465, 1.3294, 1.3397, 1.3461, 1.3169,
         1.6260, 1.5995, 1.6230, 1.6221, 1.6215, 1.6215, 1.6240, 1.6252, 1.6252,
         3.4281, 3.2187, 3.1441, 3.2028, 3.3531, 3.1715, 3.4032, 3.1522, 3.1307,
         1.6312, 1.6240, 1.6221, 1.6251, 1.6282, 1.6044, 1.6299, 1.5690, 1.5954,
         1.3148, 1.3099, 1.2997, 1.3150, 1.3100, 1.3019, 1.3138, 1.3157, 1.3169],
        [1.4609, 1.4556, 1.4110, 1.4167, 1.4539, 1.4609, 1.4589, 1.4610, 1.4610,
         1.4768, 1.4742, 1.4689, 1.4634, 1.4782, 1.4353, 1.4722, 1.4781, 1.4727,
         1.7347, 1.7262, 1.7235, 1.7320, 1.7511, 1.7493, 1.7293, 1.7512, 1.7512,
         1.4615, 1.4646, 1.5037, 1.4977, 1.4666, 1.5020, 1.4905, 1.5038, 1.5007,
         2.1803, 2.1595, 2.1475, 2.1663, 2.2113, 2.2279, 2.1938, 2.3012, 2.2978,
         1.4315, 1.4234, 1.4378, 1.4490, 1.4344, 1.4455, 1.4128, 1.4425, 1.4490],
        [1.3341, 1.2621, 1.2576, 1.2730, 1.2669, 1.2753, 1.2745, 1.2277, 1.2277,
         1.3369, 1.3054, 1.3042, 1.3061, 1.3681, 1.2624, 1.2380, 1.3681, 1.2898,
         1.6132, 1.5931, 1.5731, 1.5774, 1.5977, 1.5945, 1.6071, 1.5991, 1.5991,
         1.3615, 1.3379, 1.3469, 1.3502, 1.3424, 1.3692, 1.3754, 1.3567, 1.3469,
         1.6006, 1.5932, 1.6047, 1.5949, 1.5701, 1.5705, 1.6255, 1.5295, 1.4980,
         3.9774, 3.4830, 3.5726, 3.5571, 3.5691, 3.2533, 3.9736, 3.5328, 3.2860]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 392 : 1791.7244628690469
Test loss for epoch 392 : 195.56962016426388
Test Precision for epoch 392 : 0.26153846153846155
Test Recall for epoch 392 : 0.26153846153846155
Test F1 for epoch 392 : 0.26153846153846155


theta for epoch 393 : tensor([[3.5064, 3.5265, 3.6711, 3.6188, 3.6031, 3.4863, 3.5276, 3.4250, 3.4250,
         1.3176, 1.2746, 1.2719, 1.2815, 1.3560, 1.2497, 1.1698, 1.3561, 1.2525,
         1.5850, 1.5650, 1.5960, 1.5600, 1.5669, 1.5685, 1.5887, 1.5685, 1.5685,
         1.3538, 1.3624, 1.3262, 1.3761, 1.3426, 1.4018, 1.3871, 1.3603, 1.3262,
         1.5694, 1.5971, 1.5747, 1.5712, 1.5825, 1.5768, 1.6023, 1.5424, 1.5476,
         1.2555, 1.3048, 1.2885, 1.3206, 1.2449, 1.2286, 1.2147, 1.3616, 1.2815],
        [1.5478, 1.3951, 1.3865, 1.4278, 1.4285, 1.4397, 1.4339, 1.3370, 1.3370,
         3.3383, 3.4320, 3.2655, 3.6942, 3.3393, 4.0996, 3.1973, 3.2927, 3.8187,
         1.7339, 1.7234, 1.6971, 1.7000, 1.7193, 1.7282, 1.7485, 1.7283, 1.7283,
         1.5196, 1.4880, 1.4866, 1.5356, 1.4839, 1.5681, 1.5509, 1.5242, 1.4835,
         1.7051, 1.7536, 1.7228, 1.7109, 1.7048, 1.7389, 1.7558, 1.6039, 1.6953,
         1.3767, 1.4770, 1.4549, 1.4944, 1.3746, 1.3857, 1.3095, 1.5427, 1.4477],
        [1.4605, 1.4605, 1.4589, 1.4561, 1.4559, 1.4605, 1.4563, 1.4606, 1.4606,
         1.4696, 1.4687, 1.4695, 1.4695, 1.4696, 1.4501, 1.4696, 1.4682, 1.4659,
         2.1786, 2.1797, 2.1968, 2.1727, 2.1529, 2.1516, 2.1806, 2.1503, 2.1503,
         1.5054, 1.5040, 1.5114, 1.5114, 1.5054, 1.5114, 1.5114, 1.5114, 1.5114,
         1.7554, 1.7555, 1.7555, 1.7522, 1.7554, 1.7554, 1.7555, 1.7318, 1.7347,
         1.4402, 1.4456, 1.4456, 1.4456, 1.4367, 1.4456, 1.4407, 1.4456, 1.4456],
        [1.3402, 1.3323, 1.3169, 1.3091, 1.3321, 1.3307, 1.3318, 1.3279, 1.3279,
         1.3408, 1.3334, 1.3296, 1.3293, 1.3422, 1.3248, 1.3350, 1.3417, 1.3123,
         1.6283, 1.6018, 1.6253, 1.6243, 1.6237, 1.6237, 1.6263, 1.6274, 1.6274,
         3.4248, 3.2157, 3.1411, 3.1998, 3.3500, 3.1686, 3.3999, 3.1493, 3.1278,
         1.6332, 1.6261, 1.6241, 1.6271, 1.6302, 1.6065, 1.6320, 1.5710, 1.5975,
         1.3155, 1.3108, 1.3006, 1.3160, 1.3107, 1.3025, 1.3144, 1.3169, 1.3178],
        [1.4633, 1.4578, 1.4128, 1.4189, 1.4561, 1.4632, 1.4612, 1.4634, 1.4634,
         1.4709, 1.4684, 1.4629, 1.4572, 1.4724, 1.4288, 1.4663, 1.4723, 1.4667,
         1.7354, 1.7270, 1.7239, 1.7325, 1.7519, 1.7501, 1.7300, 1.7521, 1.7521,
         1.4718, 1.4744, 1.5142, 1.5080, 1.4770, 1.5123, 1.5010, 1.5142, 1.5111,
         2.1810, 2.1599, 2.1478, 2.1668, 2.2122, 2.2283, 2.1944, 2.3027, 2.2990,
         1.4304, 1.4227, 1.4371, 1.4484, 1.4334, 1.4448, 1.4115, 1.4418, 1.4484],
        [1.2992, 1.2219, 1.2181, 1.2337, 1.2278, 1.2360, 1.2353, 1.1843, 1.1843,
         1.3188, 1.2884, 1.2874, 1.2887, 1.3490, 1.2445, 1.2242, 1.3491, 1.2728,
         1.5935, 1.5733, 1.5529, 1.5579, 1.5782, 1.5750, 1.5873, 1.5796, 1.5796,
         1.3435, 1.3196, 1.3291, 1.3318, 1.3243, 1.3508, 1.3573, 1.3385, 1.3291,
         1.5840, 1.5760, 1.5880, 1.5782, 1.5530, 1.5533, 1.6085, 1.5121, 1.4802,
         4.0010, 3.5071, 3.5966, 3.5812, 3.5930, 3.2777, 3.9971, 3.5569, 3.3104]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 393 : 1793.0675641094654
Test loss for epoch 393 : 197.58358486467696
Test Precision for epoch 393 : 0.26153846153846155
Test Recall for epoch 393 : 0.26153846153846155
Test F1 for epoch 393 : 0.26153846153846155


theta for epoch 394 : tensor([[3.5074, 3.5276, 3.6721, 3.6197, 3.6043, 3.4873, 3.5284, 3.4259, 3.4259,
         1.3319, 1.2872, 1.2844, 1.2945, 1.3719, 1.2611, 1.1781, 1.3720, 1.2642,
         1.5882, 1.5675, 1.5996, 1.5608, 1.5679, 1.5695, 1.5917, 1.5695, 1.5695,
         1.3527, 1.3610, 1.3214, 1.3755, 1.3399, 1.4034, 1.3875, 1.3587, 1.3214,
         1.5658, 1.5955, 1.5713, 1.5678, 1.5798, 1.5748, 1.6014, 1.5393, 1.5446,
         1.2258, 1.2804, 1.2621, 1.2978, 1.2137, 1.1953, 1.1816, 1.3435, 1.2542],
        [1.5445, 1.3956, 1.3867, 1.4277, 1.4285, 1.4395, 1.4337, 1.3395, 1.3395,
         3.3353, 3.4289, 3.2624, 3.6910, 3.3363, 4.0966, 3.1944, 3.2897, 3.8156,
         1.7332, 1.7233, 1.6964, 1.7010, 1.7202, 1.7291, 1.7481, 1.7291, 1.7291,
         1.5151, 1.4841, 1.4843, 1.5307, 1.4804, 1.5617, 1.5452, 1.5200, 1.4813,
         1.7037, 1.7505, 1.7212, 1.7095, 1.7029, 1.7362, 1.7525, 1.6026, 1.6938,
         1.3659, 1.4625, 1.4417, 1.4789, 1.3647, 1.3768, 1.3005, 1.5241, 1.4350],
        [1.4780, 1.4780, 1.4765, 1.4737, 1.4734, 1.4781, 1.4738, 1.4782, 1.4782,
         1.4793, 1.4784, 1.4793, 1.4792, 1.4793, 1.4596, 1.4793, 1.4779, 1.4756,
         2.1819, 2.1830, 2.2003, 2.1759, 2.1560, 2.1547, 2.1837, 2.1534, 2.1534,
         1.5049, 1.5035, 1.5110, 1.5110, 1.5049, 1.5110, 1.5109, 1.5110, 1.5110,
         1.7547, 1.7548, 1.7548, 1.7514, 1.7547, 1.7547, 1.7548, 1.7310, 1.7339,
         1.4177, 1.4231, 1.4231, 1.4231, 1.4141, 1.4231, 1.4180, 1.4231, 1.4231],
        [1.3607, 1.3518, 1.3366, 1.3287, 1.3518, 1.3504, 1.3514, 1.3467, 1.3467,
         1.3520, 1.3445, 1.3407, 1.3403, 1.3534, 1.3358, 1.3459, 1.3530, 1.3233,
         1.6339, 1.6072, 1.6308, 1.6298, 1.6292, 1.6292, 1.6319, 1.6329, 1.6329,
         3.4113, 3.2024, 3.1278, 3.1866, 3.3366, 3.1554, 3.3863, 3.1361, 3.1145,
         1.6337, 1.6266, 1.6245, 1.6275, 1.6307, 1.6071, 1.6325, 1.5715, 1.5980,
         1.2940, 1.2896, 1.2793, 1.2949, 1.2891, 1.2809, 1.2927, 1.2960, 1.2964],
        [1.4808, 1.4752, 1.4299, 1.4364, 1.4735, 1.4808, 1.4788, 1.4810, 1.4810,
         1.4806, 1.4780, 1.4724, 1.4665, 1.4821, 1.4378, 1.4760, 1.4821, 1.4761,
         1.7393, 1.7309, 1.7275, 1.7363, 1.7559, 1.7540, 1.7339, 1.7561, 1.7561,
         1.4713, 1.4732, 1.5137, 1.5075, 1.4764, 1.5119, 1.5005, 1.5138, 1.5107,
         2.1803, 2.1588, 2.1467, 2.1659, 2.2116, 2.2273, 2.1934, 2.3027, 2.2987,
         1.4075, 1.4000, 1.4145, 1.4259, 1.4106, 1.4222, 1.3884, 1.4193, 1.4260],
        [1.2796, 1.1934, 1.1904, 1.2067, 1.2008, 1.2091, 1.2083, 1.1504, 1.1504,
         1.3171, 1.2871, 1.2862, 1.2870, 1.3470, 1.2419, 1.2241, 1.3470, 1.2712,
         1.5774, 1.5569, 1.5363, 1.5412, 1.5615, 1.5585, 1.5712, 1.5630, 1.5630,
         1.3187, 1.2943, 1.3034, 1.3070, 1.2990, 1.3266, 1.3329, 1.3135, 1.3034,
         1.5660, 1.5581, 1.5699, 1.5601, 1.5347, 1.5352, 1.5910, 1.4932, 1.4612,
         4.0159, 3.5224, 3.6117, 3.5964, 3.6082, 3.2933, 4.0120, 3.5722, 3.3260]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 394 : 1791.5918330989655
Test loss for epoch 394 : 199.5892498134623
Test Precision for epoch 394 : 0.26153846153846155
Test Recall for epoch 394 : 0.26153846153846155
Test F1 for epoch 394 : 0.26153846153846155


theta for epoch 395 : tensor([[3.5166, 3.5370, 3.6814, 3.6288, 3.6138, 3.4966, 3.5377, 3.4354, 3.4354,
         1.3508, 1.3048, 1.3019, 1.3123, 1.3919, 1.2778, 1.1927, 1.3920, 1.2812,
         1.5837, 1.5624, 1.5954, 1.5544, 1.5616, 1.5632, 1.5870, 1.5632, 1.5632,
         1.3456, 1.3536, 1.3114, 1.3688, 1.3316, 1.3983, 1.3817, 1.3512, 1.3115,
         1.5579, 1.5892, 1.5635, 1.5600, 1.5726, 1.5682, 1.5957, 1.5317, 1.5372,
         1.1953, 1.2558, 1.2353, 1.2748, 1.1816, 1.1610, 1.1475, 1.3256, 1.2263],
        [1.5271, 1.3841, 1.3748, 1.4152, 1.4160, 1.4269, 1.4210, 1.3310, 1.3310,
         3.3403, 3.4338, 3.2674, 3.6958, 3.3413, 4.1015, 3.1995, 3.2947, 3.8205,
         1.7236, 1.7143, 1.6868, 1.6934, 1.7123, 1.7212, 1.7388, 1.7213, 1.7213,
         1.5034, 1.4731, 1.4753, 1.5185, 1.4700, 1.5478, 1.5322, 1.5086, 1.4723,
         1.6953, 1.7403, 1.7126, 1.7009, 1.6940, 1.7263, 1.7418, 1.5942, 1.6852,
         1.3515, 1.4443, 1.4247, 1.4595, 1.3512, 1.3643, 1.2880, 1.5015, 1.4187],
        [1.4779, 1.4779, 1.4763, 1.4736, 1.4733, 1.4780, 1.4737, 1.4780, 1.4780,
         1.4958, 1.4949, 1.4958, 1.4957, 1.4958, 1.4760, 1.4958, 1.4944, 1.4921,
         2.1811, 2.1823, 2.1996, 2.1752, 2.1551, 2.1538, 2.1829, 2.1525, 2.1525,
         1.5029, 1.5016, 1.5091, 1.5091, 1.5029, 1.5091, 1.5091, 1.5091, 1.5091,
         1.7522, 1.7523, 1.7523, 1.7488, 1.7522, 1.7522, 1.7523, 1.7284, 1.7312,
         1.4004, 1.4059, 1.4059, 1.4059, 1.3968, 1.4059, 1.4007, 1.4059, 1.4059],
        [1.3625, 1.3529, 1.3377, 1.3299, 1.3530, 1.3516, 1.3526, 1.3474, 1.3474,
         1.3699, 1.3623, 1.3585, 1.3581, 1.3714, 1.3534, 1.3636, 1.3709, 1.3410,
         1.6349, 1.6082, 1.6318, 1.6307, 1.6301, 1.6301, 1.6328, 1.6338, 1.6338,
         3.3975, 3.1888, 3.1143, 3.1732, 3.3230, 3.1421, 3.3725, 3.1228, 3.1011,
         1.6321, 1.6252, 1.6229, 1.6259, 1.6292, 1.6057, 1.6310, 1.5701, 1.5966,
         1.2774, 1.2734, 1.2630, 1.2788, 1.2725, 1.2642, 1.2760, 1.2802, 1.2800],
        [1.4807, 1.4750, 1.4292, 1.4359, 1.4732, 1.4807, 1.4786, 1.4808, 1.4808,
         1.4970, 1.4945, 1.4887, 1.4827, 1.4986, 1.4536, 1.4924, 1.4986, 1.4924,
         1.7389, 1.7306, 1.7269, 1.7358, 1.7557, 1.7538, 1.7335, 1.7559, 1.7559,
         1.4693, 1.4706, 1.5118, 1.5056, 1.4744, 1.5100, 1.4986, 1.5119, 1.5088,
         2.1778, 2.1559, 2.1437, 2.1632, 2.2092, 2.2245, 2.1908, 2.3009, 2.2966,
         1.3900, 1.3827, 1.3972, 1.4087, 1.3930, 1.4049, 1.3707, 1.4021, 1.4087],
        [1.2574, 1.1595, 1.1577, 1.1749, 1.1691, 1.1774, 1.1766, 1.1097, 1.1097,
         1.3250, 1.2945, 1.2937, 1.2943, 1.3552, 1.2479, 1.2310, 1.3552, 1.2781,
         1.5601, 1.5391, 1.5185, 1.5225, 1.5428, 1.5399, 1.5537, 1.5444, 1.5444,
         1.2966, 1.2715, 1.2791, 1.2851, 1.2759, 1.3061, 1.3118, 1.2911, 1.2791,
         1.5476, 1.5406, 1.5516, 1.5417, 1.5163, 1.5173, 1.5740, 1.4740, 1.4421,
         4.0291, 3.5359, 3.6251, 3.6099, 3.6216, 3.3070, 4.0252, 3.5857, 3.3397]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 395 : 1791.6935594860363
Test loss for epoch 395 : 201.25534399263748
Test Precision for epoch 395 : 0.26153846153846155
Test Recall for epoch 395 : 0.26153846153846155
Test F1 for epoch 395 : 0.26153846153846155


theta for epoch 396 : tensor([[3.5415, 3.5624, 3.7064, 3.6537, 3.6391, 3.5217, 3.5628, 3.4610, 3.4610,
         1.3486, 1.3019, 1.2989, 1.3094, 1.3903, 1.2740, 1.1881, 1.3904, 1.2779,
         1.5748, 1.5531, 1.5869, 1.5442, 1.5516, 1.5532, 1.5781, 1.5532, 1.5532,
         1.3447, 1.3526, 1.3086, 1.3682, 1.3299, 1.3987, 1.3816, 1.3500, 1.3087,
         1.5505, 1.5830, 1.5562, 1.5527, 1.5658, 1.5618, 1.5900, 1.5244, 1.5302,
         1.1767, 1.2435, 1.2206, 1.2642, 1.1614, 1.1384, 1.1253, 1.3202, 1.2104],
        [1.5005, 1.3649, 1.3550, 1.3947, 1.3956, 1.4062, 1.4004, 1.3157, 1.3157,
         3.3470, 3.4404, 3.2741, 3.7022, 3.3480, 4.1081, 3.2063, 3.3014, 3.8270,
         1.7079, 1.6994, 1.6711, 1.6799, 1.6987, 1.7076, 1.7235, 1.7077, 1.7077,
         1.4914, 1.4617, 1.4662, 1.5061, 1.4592, 1.5336, 1.5189, 1.4970, 1.4632,
         1.6839, 1.7268, 1.7009, 1.6893, 1.6818, 1.7132, 1.7279, 1.5824, 1.6736,
         1.3411, 1.4304, 1.4120, 1.4446, 1.3417, 1.3560, 1.2793, 1.4835, 1.4066],
        [1.4705, 1.4705, 1.4689, 1.4661, 1.4659, 1.4706, 1.4662, 1.4706, 1.4706,
         1.4938, 1.4928, 1.4938, 1.4937, 1.4938, 1.4738, 1.4938, 1.4923, 1.4900,
         2.1797, 2.1810, 2.1984, 2.1738, 2.1537, 2.1524, 2.1815, 2.1510, 2.1510,
         1.5118, 1.5107, 1.5181, 1.5181, 1.5118, 1.5181, 1.5181, 1.5181, 1.5181,
         1.7527, 1.7529, 1.7529, 1.7493, 1.7527, 1.7527, 1.7528, 1.7288, 1.7316,
         1.4011, 1.4065, 1.4065, 1.4066, 1.3973, 1.4065, 1.4013, 1.4065, 1.4065],
        [1.3558, 1.3459, 1.3307, 1.3229, 1.3461, 1.3446, 1.3457, 1.3402, 1.3402,
         1.3689, 1.3613, 1.3575, 1.3571, 1.3704, 1.3523, 1.3625, 1.3699, 1.3398,
         1.6349, 1.6081, 1.6317, 1.6306, 1.6300, 1.6300, 1.6328, 1.6337, 1.6337,
         3.3955, 3.1872, 3.1129, 3.1717, 3.3211, 3.1406, 3.3704, 3.1214, 3.0996,
         1.6333, 1.6265, 1.6241, 1.6271, 1.6304, 1.6070, 1.6322, 1.5714, 1.5978,
         1.2783, 1.2746, 1.2641, 1.2801, 1.2733, 1.2649, 1.2767, 1.2817, 1.2810],
        [1.4733, 1.4676, 1.4213, 1.4281, 1.4656, 1.4733, 1.4713, 1.4734, 1.4734,
         1.4949, 1.4924, 1.4864, 1.4803, 1.4966, 1.4509, 1.4904, 1.4966, 1.4901,
         1.7380, 1.7297, 1.7257, 1.7348, 1.7548, 1.7530, 1.7325, 1.7550, 1.7550,
         1.4782, 1.4790, 1.5209, 1.5147, 1.4833, 1.5190, 1.5076, 1.5209, 1.5178,
         2.1782, 2.1559, 2.1437, 2.1634, 2.2097, 2.2246, 2.1910, 2.3020, 2.2973,
         1.3905, 1.3832, 1.3978, 1.4093, 1.3934, 1.4055, 1.3710, 1.4027, 1.4094],
        [1.2405, 1.1288, 1.1283, 1.1467, 1.1410, 1.1493, 1.1485, 1.0710, 1.0710,
         1.3198, 1.2883, 1.2877, 1.2880, 1.3507, 1.2404, 1.2237, 1.3507, 1.2715,
         1.5456, 1.5239, 1.5036, 1.5058, 1.5262, 1.5234, 1.5389, 1.5280, 1.5280,
         1.2883, 1.2622, 1.2673, 1.2770, 1.2659, 1.3001, 1.3050, 1.2822, 1.2674,
         1.5341, 1.5285, 1.5381, 1.5282, 1.5030, 1.5048, 1.5627, 1.4597, 1.4281,
         4.0436, 3.5507, 3.6398, 3.6246, 3.6364, 3.3221, 4.0397, 3.6005, 3.3548]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 396 : 1790.9366005437698
Test loss for epoch 396 : 202.56784375612676
Test Precision for epoch 396 : 0.26153846153846155
Test Recall for epoch 396 : 0.26153846153846155
Test F1 for epoch 396 : 0.26153846153846155


theta for epoch 397 : tensor([[3.5887, 3.6103, 3.7540, 3.7012, 3.6870, 3.5695, 3.6104, 3.5095, 3.5095,
         1.3220, 1.2751, 1.2721, 1.2826, 1.3640, 1.2466, 1.1610, 1.3641, 1.2509,
         1.5678, 1.5458, 1.5802, 1.5364, 1.5439, 1.5456, 1.5712, 1.5456, 1.5456,
         1.3441, 1.3522, 1.3072, 1.3680, 1.3290, 1.3991, 1.3816, 1.3495, 1.3073,
         1.5453, 1.5788, 1.5511, 1.5477, 1.5611, 1.5574, 1.5861, 1.5192, 1.5252,
         1.1674, 1.2404, 1.2152, 1.2629, 1.1502, 1.1249, 1.1121, 1.3244, 1.2038],
        [1.4710, 1.3437, 1.3332, 1.3722, 1.3732, 1.3836, 1.3778, 1.2991, 1.2991,
         3.3539, 3.4473, 3.2811, 3.7090, 3.3550, 4.1150, 3.2135, 3.3084, 3.8339,
         1.6905, 1.6827, 1.6536, 1.6647, 1.6835, 1.6924, 1.7064, 1.6924, 1.6924,
         1.4768, 1.4477, 1.4547, 1.4910, 1.4458, 1.5166, 1.5028, 1.4828, 1.4516,
         1.6710, 1.7119, 1.6878, 1.6763, 1.6683, 1.6987, 1.7125, 1.5690, 1.6605,
         1.3334, 1.4195, 1.4023, 1.4327, 1.3350, 1.3505, 1.2732, 1.4687, 1.3975],
        [1.4710, 1.4709, 1.4693, 1.4665, 1.4664, 1.4710, 1.4666, 1.4710, 1.4710,
         1.4699, 1.4688, 1.4698, 1.4698, 1.4699, 1.4496, 1.4698, 1.4683, 1.4660,
         2.1831, 2.1845, 2.2019, 2.1771, 2.1568, 2.1556, 2.1848, 2.1542, 2.1542,
         1.5253, 1.5242, 1.5317, 1.5317, 1.5253, 1.5317, 1.5317, 1.5317, 1.5317,
         1.7578, 1.7579, 1.7579, 1.7543, 1.7578, 1.7578, 1.7579, 1.7339, 1.7365,
         1.4159, 1.4213, 1.4213, 1.4213, 1.4121, 1.4213, 1.4161, 1.4213, 1.4213],
        [1.3559, 1.3461, 1.3310, 1.3230, 1.3463, 1.3448, 1.3459, 1.3405, 1.3405,
         1.3457, 1.3380, 1.3342, 1.3337, 1.3472, 1.3289, 1.3391, 1.3467, 1.3164,
         1.6394, 1.6126, 1.6362, 1.6352, 1.6345, 1.6345, 1.6373, 1.6382, 1.6382,
         3.3998, 3.1921, 3.1180, 3.1767, 3.3257, 3.1457, 3.3748, 3.1266, 3.1048,
         1.6387, 1.6319, 1.6294, 1.6325, 1.6359, 1.6125, 1.6377, 1.5770, 1.6034,
         1.2930, 1.2895, 1.2789, 1.2950, 1.2879, 1.2793, 1.2912, 1.2970, 1.2958],
        [1.4737, 1.4681, 1.4215, 1.4282, 1.4658, 1.4737, 1.4718, 1.4739, 1.4739,
         1.4709, 1.4684, 1.4622, 1.4559, 1.4727, 1.4263, 1.4663, 1.4726, 1.4659,
         1.7420, 1.7337, 1.7296, 1.7388, 1.7590, 1.7571, 1.7366, 1.7591, 1.7591,
         1.4917, 1.4921, 1.5345, 1.5283, 1.4969, 1.5326, 1.5212, 1.5345, 1.5314,
         2.1830, 2.1603, 2.1481, 2.1680, 2.2145, 2.2291, 2.1957, 2.3074, 2.3023,
         1.4052, 1.3980, 1.4127, 1.4241, 1.4080, 1.4202, 1.3856, 1.4175, 1.4242],
        [1.2382, 1.1112, 1.1120, 1.1318, 1.1262, 1.1347, 1.1339, 1.0447, 1.0447,
         1.2981, 1.2653, 1.2650, 1.2651, 1.3301, 1.2162, 1.1991, 1.3301, 1.2480,
         1.5390, 1.5163, 1.4965, 1.4964, 1.5169, 1.5142, 1.5320, 1.5188, 1.5188,
         1.2889, 1.2617, 1.2636, 1.2780, 1.2645, 1.3039, 1.3075, 1.2822, 1.2636,
         1.5270, 1.5234, 1.5312, 1.5212, 1.4963, 1.4992, 1.5585, 1.4518, 1.4206,
         4.0584, 3.5656, 3.6546, 3.6395, 3.6513, 3.3373, 4.0545, 3.6154, 3.3700]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 397 : 1788.7479855872195
Test loss for epoch 397 : 203.53323373164392
Test Precision for epoch 397 : 0.26153846153846155
Test Recall for epoch 397 : 0.26153846153846155
Test F1 for epoch 397 : 0.26153846153846155


theta for epoch 398 : tensor([[3.6415, 3.6640, 3.8072, 3.7543, 3.7405, 3.6230, 3.6637, 3.5637, 3.5637,
         1.3009, 1.2541, 1.2512, 1.2615, 1.3428, 1.2250, 1.1406, 1.3428, 1.2298,
         1.5638, 1.5415, 1.5764, 1.5320, 1.5396, 1.5413, 1.5673, 1.5413, 1.5413,
         1.3313, 1.3395, 1.2943, 1.3554, 1.3161, 1.3867, 1.3692, 1.3368, 1.2944,
         1.5408, 1.5751, 1.5468, 1.5433, 1.5570, 1.5534, 1.5825, 1.5146, 1.5208,
         1.1526, 1.2318, 1.2043, 1.2562, 1.1337, 1.1059, 1.0935, 1.3231, 1.1917],
        [1.4329, 1.3152, 1.3039, 1.3421, 1.3432, 1.3533, 1.3475, 1.2757, 1.2757,
         3.3672, 3.4605, 3.2944, 3.7220, 3.3683, 4.1281, 3.2269, 3.3218, 3.8470,
         1.6718, 1.6648, 1.6347, 1.6483, 1.6671, 1.6760, 1.6882, 1.6761, 1.6761,
         1.4531, 1.4248, 1.4344, 1.4668, 1.4235, 1.4903, 1.4775, 1.4596, 1.4313,
         1.6556, 1.6945, 1.6723, 1.6608, 1.6522, 1.6817, 1.6945, 1.5529, 1.6449,
         1.3199, 1.4025, 1.3865, 1.4146, 1.3224, 1.3392, 1.2614, 1.4475, 1.3824],
        [1.4610, 1.4610, 1.4593, 1.4566, 1.4565, 1.4610, 1.4566, 1.4611, 1.4611,
         1.4527, 1.4516, 1.4526, 1.4526, 1.4527, 1.4323, 1.4526, 1.4510, 1.4488,
         2.1910, 2.1923, 2.2098, 2.1846, 2.1643, 2.1631, 2.1923, 2.1617, 2.1617,
         1.5286, 1.5276, 1.5351, 1.5351, 1.5286, 1.5351, 1.5350, 1.5351, 1.5351,
         1.7648, 1.7649, 1.7649, 1.7612, 1.7648, 1.7648, 1.7649, 1.7409, 1.7435,
         1.4284, 1.4338, 1.4338, 1.4338, 1.4245, 1.4338, 1.4286, 1.4338, 1.4338],
        [1.3443, 1.3350, 1.3199, 1.3119, 1.3353, 1.3337, 1.3348, 1.3297, 1.3297,
         1.3288, 1.3212, 1.3173, 1.3168, 1.3304, 1.3120, 1.3223, 1.3299, 1.2995,
         1.6482, 1.6214, 1.6450, 1.6440, 1.6433, 1.6433, 1.6461, 1.6470, 1.6470,
         3.3974, 3.1902, 3.1163, 3.1749, 3.3236, 3.1440, 3.3724, 3.1251, 3.1031,
         1.6458, 1.6390, 1.6365, 1.6396, 1.6430, 1.6197, 1.6447, 1.5842, 1.6106,
         1.3049, 1.3016, 1.2910, 1.3072, 1.2998, 1.2911, 1.3030, 1.3093, 1.3077],
        [1.4638, 1.4584, 1.4115, 1.4179, 1.4557, 1.4638, 1.4619, 1.4639, 1.4639,
         1.4537, 1.4511, 1.4447, 1.4384, 1.4555, 1.4086, 1.4491, 1.4555, 1.4484,
         1.7507, 1.7424, 1.7383, 1.7475, 1.7677, 1.7659, 1.7452, 1.7679, 1.7679,
         1.4949, 1.4950, 1.5378, 1.5318, 1.5003, 1.5360, 1.5245, 1.5379, 1.5348,
         2.1897, 2.1666, 2.1545, 2.1745, 2.2212, 2.2354, 2.2024, 2.3145, 2.3090,
         1.4177, 1.4105, 1.4252, 1.4365, 1.4204, 1.4326, 1.3981, 1.4300, 1.4366],
        [1.2363, 1.0933, 1.0956, 1.1168, 1.1113, 1.1200, 1.1191, 1.0178, 1.0178,
         1.2854, 1.2508, 1.2506, 1.2506, 1.3188, 1.2002, 1.1818, 1.3188, 1.2328,
         1.5390, 1.5153, 1.4961, 1.4931, 1.5139, 1.5113, 1.5316, 1.5160, 1.5160,
         1.2857, 1.2573, 1.2555, 1.2753, 1.2591, 1.3043, 1.3065, 1.2783, 1.2555,
         1.5236, 1.5223, 1.5279, 1.5178, 1.4934, 1.4975, 1.5584, 1.4474, 1.4169,
         4.0698, 3.5770, 3.6659, 3.6509, 3.6628, 3.3490, 4.0658, 3.6268, 3.3816]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 398 : 1787.9516157216008
Test loss for epoch 398 : 204.2693557750976
Test Precision for epoch 398 : 0.26153846153846155
Test Recall for epoch 398 : 0.26153846153846155
Test F1 for epoch 398 : 0.26153846153846155


theta for epoch 399 : tensor([[3.6943, 3.7177, 3.8607, 3.8076, 3.7941, 3.6764, 3.7171, 3.6179, 3.6179,
         1.2943, 1.2478, 1.2450, 1.2551, 1.3359, 1.2184, 1.1355, 1.3360, 1.2236,
         1.5594, 1.5369, 1.5721, 1.5275, 1.5351, 1.5369, 1.5630, 1.5368, 1.5368,
         1.3181, 1.3265, 1.2814, 1.3424, 1.3029, 1.3736, 1.3561, 1.3238, 1.2815,
         1.5352, 1.5701, 1.5413, 1.5378, 1.5517, 1.5482, 1.5776, 1.5087, 1.5152,
         1.1219, 1.2071, 1.1773, 1.2331, 1.1013, 1.0712, 1.0592, 1.3054, 1.1636],
        [1.3896, 1.2823, 1.2700, 1.3074, 1.3086, 1.3185, 1.3126, 1.2484, 1.2484,
         3.3880, 3.4811, 3.3152, 3.7424, 3.3891, 4.1485, 3.2478, 3.3426, 3.8675,
         1.6494, 1.6432, 1.6122, 1.6284, 1.6472, 1.6561, 1.6664, 1.6562, 1.6562,
         1.4257, 1.3981, 1.4105, 1.4388, 1.3975, 1.4602, 1.4484, 1.4326, 1.4073,
         1.6361, 1.6729, 1.6526, 1.6412, 1.6319, 1.6605, 1.6723, 1.5326, 1.6252,
         1.2937, 1.3722, 1.3576, 1.3832, 1.2973, 1.3153, 1.2374, 1.4126, 1.3543],
        [1.4476, 1.4475, 1.4459, 1.4431, 1.4432, 1.4476, 1.4431, 1.4476, 1.4476,
         1.4498, 1.4487, 1.4498, 1.4497, 1.4498, 1.4293, 1.4498, 1.4481, 1.4459,
         2.1985, 2.1998, 2.2173, 2.1917, 2.1714, 2.1701, 2.1994, 2.1688, 2.1688,
         1.5309, 1.5299, 1.5374, 1.5374, 1.5309, 1.5374, 1.5374, 1.5374, 1.5374,
         1.7704, 1.7705, 1.7705, 1.7667, 1.7704, 1.7704, 1.7705, 1.7465, 1.7490,
         1.4253, 1.4305, 1.4305, 1.4305, 1.4213, 1.4305, 1.4254, 1.4305, 1.4305],
        [1.3282, 1.3198, 1.3047, 1.2964, 1.3199, 1.3183, 1.3195, 1.3150, 1.3150,
         1.3261, 1.3184, 1.3146, 1.3140, 1.3276, 1.3092, 1.3196, 1.3270, 1.2966,
         1.6560, 1.6292, 1.6527, 1.6518, 1.6511, 1.6511, 1.6539, 1.6548, 1.6548,
         3.3966, 3.1900, 3.1163, 3.1749, 3.3230, 3.1441, 3.3716, 3.1252, 3.1032,
         1.6511, 1.6444, 1.6417, 1.6449, 1.6483, 1.6251, 1.6500, 1.5897, 1.6160,
         1.3007, 1.2976, 1.2870, 1.3032, 1.2955, 1.2869, 1.2988, 1.3054, 1.3036],
        [1.4505, 1.4452, 1.3983, 1.4043, 1.4422, 1.4503, 1.4486, 1.4504, 1.4504,
         1.4507, 1.4482, 1.4416, 1.4353, 1.4527, 1.4053, 1.4461, 1.4526, 1.4453,
         1.7588, 1.7506, 1.7464, 1.7557, 1.7759, 1.7741, 1.7534, 1.7760, 1.7760,
         1.4972, 1.4971, 1.5402, 1.5343, 1.5026, 1.5385, 1.5268, 1.5402, 1.5372,
         2.1950, 2.1716, 2.1595, 2.1797, 2.2265, 2.2405, 2.2077, 2.3200, 2.3142,
         1.4147, 1.4072, 1.4221, 1.4333, 1.4171, 1.4293, 1.3951, 1.4268, 1.4334],
        [1.2355, 1.0763, 1.0799, 1.1027, 1.0973, 1.1062, 1.1053, 0.9919, 0.9919,
         1.2868, 1.2500, 1.2500, 1.2500, 1.3219, 1.1979, 1.1773, 1.3220, 1.2313,
         1.5399, 1.5150, 1.4964, 1.4905, 1.5116, 1.5091, 1.5321, 1.5138, 1.5138,
         1.2839, 1.2543, 1.2487, 1.2742, 1.2551, 1.3064, 1.3070, 1.2760, 1.2487,
         1.5197, 1.5209, 1.5242, 1.5140, 1.4899, 1.4955, 1.5581, 1.4425, 1.4127,
         4.0759, 3.5831, 3.6719, 3.6569, 3.6690, 3.3553, 4.0720, 3.6328, 3.3879]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 399 : 1786.0129272728996
Test loss for epoch 399 : 204.69690875888944
Test Precision for epoch 399 : 0.26153846153846155
Test Recall for epoch 399 : 0.26153846153846155
Test F1 for epoch 399 : 0.26153846153846155


Max Test F1 is for epoch 0 : 0.26153846153846155
