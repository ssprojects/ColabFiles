theta for epoch 0 : tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 0 : 189.17531120056842
Test loss for epoch 0 : 188.78813183955108
Test Precision for epoch 0 : 0.26153846153846155
Test Recall for epoch 0 : 0.26153846153846155
Test F1 for epoch 0 : 0.26153846153846155


theta for epoch 1 : tensor([[1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000],
        [1.1000, 1.1000, 0.9000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 0.9000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         0.9000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 1.1000, 1.1000],
        [1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 0.9000, 0.9000,
         1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 1 : 187.28049765588867
Test loss for epoch 1 : 186.93048373650106
Test Precision for epoch 1 : 0.26153846153846155
Test Recall for epoch 1 : 0.26153846153846155
Test F1 for epoch 1 : 0.26153846153846155


theta for epoch 2 : tensor([[1.1914, 1.1936, 1.1957, 1.1947, 1.1948, 1.1921, 1.1929, 1.1914, 1.1914,
         1.1468, 1.1446, 1.1468, 1.1389, 1.1467, 1.1102, 1.1463, 1.1470, 1.1259,
         1.1353, 1.1156, 1.1429, 1.1371, 1.1504, 1.1512, 1.1496, 1.1513, 1.1513,
         1.1684, 1.1829, 1.1825, 1.1824, 1.1804, 1.1825, 1.1808, 1.1794, 1.1825,
         1.1961, 1.1960, 1.1960, 1.1961, 1.1961, 1.1950, 1.1960, 1.1976, 1.1946,
         1.1780, 1.1800, 1.1803, 1.1811, 1.1790, 1.1797, 1.1613, 1.1811, 1.1811],
        [1.1905, 1.1633, 1.0274, 1.1831, 1.1864, 1.1921, 1.1892, 1.1922, 1.1922,
         1.1946, 1.1967, 1.1910, 1.1983, 1.1938, 1.1992, 1.1943, 1.1893, 1.1989,
         1.1667, 1.1671, 0.8030, 1.1595, 1.1870, 1.1911, 1.1890, 1.1912, 1.1912,
         1.1995, 1.1973, 1.1994, 1.1993, 1.1976, 1.1994, 1.1994, 1.1994, 1.1993,
         1.1999, 1.2001, 1.2000, 1.1999, 1.1996, 1.2000, 1.2000, 0.8098, 1.1986,
         1.0336, 1.1992, 1.1992, 1.1992, 1.1904, 1.1992, 0.8072, 1.1992, 1.1992],
        [1.1697, 1.1656, 1.1569, 1.1569, 1.1466, 1.1696, 1.1536, 1.1697, 1.1697,
         1.1628, 1.1563, 1.1631, 1.1570, 1.1631, 1.0264, 1.1629, 1.1557, 1.1260,
         1.1981, 1.1987, 1.1990, 1.1986, 1.1964, 1.1963, 1.1978, 1.1956, 1.1956,
         1.1869, 1.1867, 1.1916, 1.1915, 1.1858, 1.1916, 1.1914, 1.1915, 1.1916,
         1.1989, 1.1989, 1.1989, 1.1989, 1.1990, 1.1989, 1.1989, 0.9720, 1.1975,
         1.1820, 1.1907, 1.1906, 1.1907, 1.1718, 1.1906, 1.1700, 1.1906, 1.1907],
        [1.1658, 1.1652, 1.1223, 1.1032, 1.1622, 1.1630, 1.1632, 1.1658, 1.1658,
         1.1594, 1.1449, 1.1435, 1.1370, 1.1596, 1.1092, 1.1581, 1.1591, 1.0556,
         1.1634, 1.1061, 1.1611, 1.1605, 1.1603, 1.1583, 1.1623, 1.1639, 1.1639,
         1.1978, 1.1947, 1.1924, 1.1943, 1.1974, 1.1922, 1.1973, 1.1925, 1.1921,
         1.1983, 1.1979, 1.1979, 1.1982, 1.1984, 1.1973, 1.1982, 0.9470, 1.1985,
         1.1888, 1.1830, 1.1680, 1.1862, 1.1868, 1.1748, 1.1895, 1.1863, 1.1887],
        [1.1947, 1.1921, 0.8912, 0.9379, 1.1903, 1.1944, 1.1936, 1.1947, 1.1947,
         1.1948, 1.1927, 1.1904, 0.9742, 1.1953, 0.8564, 1.1935, 1.1953, 1.1890,
         1.1900, 1.1754, 0.9692, 1.1865, 1.1944, 1.1945, 1.1877, 1.1949, 1.1949,
         0.9425, 0.9414, 1.1925, 1.1892, 0.9614, 1.1923, 1.1829, 1.1924, 1.1921,
         1.0633, 1.0458, 1.0420, 1.0555, 1.0875, 1.0939, 1.0558, 1.1663, 1.1583,
         0.9651, 1.1794, 1.1846, 1.1920, 1.1777, 1.1917, 0.9116, 1.1904, 1.1930],
        [1.1801, 1.1779, 1.1581, 1.1737, 1.1663, 1.1760, 1.1756, 1.1801, 1.1801,
         1.1621, 1.1514, 1.1527, 1.1405, 1.1746, 1.0289, 1.1623, 1.1745, 1.1270,
         1.1770, 1.1606, 1.0753, 1.1611, 1.1773, 1.1779, 1.1736, 1.1786, 1.1786,
         1.1948, 1.1876, 1.1959, 1.1884, 1.1902, 1.1866, 1.1950, 1.1936, 1.1959,
         1.1999, 1.1998, 1.1998, 1.2000, 1.2000, 1.1988, 1.1998, 0.9017, 0.8083,
         1.2000, 1.1990, 1.1994, 1.1993, 1.1995, 1.1967, 1.2000, 1.1991, 1.1965]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 2 : 186.36379937957926
Test loss for epoch 2 : 186.01961285769664
Test Precision for epoch 2 : 0.26153846153846155
Test Recall for epoch 2 : 0.26153846153846155
Test F1 for epoch 2 : 0.26153846153846155


theta for epoch 3 : tensor([[1.2728, 1.2787, 1.2845, 1.2820, 1.2825, 1.2748, 1.2771, 1.2728, 1.2728,
         1.2202, 1.2171, 1.2201, 1.2094, 1.2201, 1.1708, 1.2194, 1.2205, 1.1914,
         1.1990, 1.1685, 1.2117, 1.2018, 1.2223, 1.2235, 1.2212, 1.2236, 1.2236,
         1.1253, 1.1571, 1.1587, 1.1584, 1.1486, 1.1587, 1.1533, 1.1505, 1.1586,
         1.2905, 1.2908, 1.2908, 1.2908, 1.2908, 1.2875, 1.2906, 1.2829, 1.2823,
         1.2155, 1.2226, 1.2245, 1.2270, 1.2188, 1.2219, 1.1663, 1.2271, 1.2271],
        [1.2851, 1.2421, 1.0167, 1.2736, 1.2785, 1.2877, 1.2831, 1.2877, 1.2877,
         1.2861, 1.2923, 1.2764, 1.2963, 1.2837, 1.2983, 1.2851, 1.2706, 1.2976,
         1.2486, 1.2489, 0.8490, 1.2381, 1.2790, 1.2855, 1.2821, 1.2858, 1.2858,
         1.1822, 1.1457, 1.2045, 1.1955, 1.1496, 1.2045, 1.1983, 1.2012, 1.1980,
         1.2962, 1.2975, 1.2972, 1.2963, 1.2948, 1.2970, 1.2971, 0.7806, 1.2912,
         0.9599, 1.2798, 1.2788, 1.2804, 1.1677, 1.2797, 0.7112, 1.2805, 1.2805],
        [1.2471, 1.2403, 1.2270, 1.2253, 1.2062, 1.2470, 1.2182, 1.2471, 1.2471,
         1.2426, 1.2333, 1.2429, 1.2341, 1.2431, 1.0427, 1.2427, 1.2325, 1.1921,
         1.2951, 1.2964, 1.2972, 1.2962, 1.2914, 1.2911, 1.2945, 1.2898, 1.2898,
         1.1513, 1.1499, 1.1732, 1.1722, 1.1479, 1.1732, 1.1719, 1.1725, 1.1731,
         1.2960, 1.2962, 1.2961, 1.2954, 1.2961, 1.2960, 1.2961, 1.0489, 1.2777,
         1.1956, 1.2427, 1.2425, 1.2426, 1.1631, 1.2423, 1.1556, 1.2420, 1.2426],
        [1.2471, 1.2462, 1.1827, 1.1527, 1.2417, 1.2430, 1.2433, 1.2472, 1.2472,
         1.2367, 1.2173, 1.2155, 1.2069, 1.2369, 1.1717, 1.2348, 1.2362, 1.0984,
         1.2438, 1.1630, 1.2403, 1.2396, 1.2393, 1.2364, 1.2423, 1.2446, 1.2446,
         1.2266, 1.1932, 1.1803, 1.1904, 1.2210, 1.1787, 1.2204, 1.1805, 1.1782,
         1.2915, 1.2897, 1.2894, 1.2903, 1.2910, 1.2847, 1.2907, 1.0154, 1.2831,
         1.2701, 1.2515, 1.2093, 1.2617, 1.2631, 1.2272, 1.2735, 1.2618, 1.2687],
        [1.2444, 1.2218, 0.8307, 0.8999, 1.2097, 1.2409, 1.2335, 1.2444, 1.2444,
         1.2733, 1.2635, 1.2522, 1.0122, 1.2759, 0.7851, 1.2665, 1.2759, 1.2449,
         1.2189, 1.1575, 0.9727, 1.2000, 1.2507, 1.2509, 1.2063, 1.2547, 1.2547,
         0.8947, 0.8928, 1.1932, 1.1754, 0.9237, 1.1919, 1.1549, 1.1924, 1.1907,
         1.1055, 1.0756, 1.0686, 1.0933, 1.1411, 1.1498, 1.0935, 1.2457, 1.2350,
         0.9451, 1.1646, 1.1823, 1.2193, 1.1568, 1.2148, 0.8574, 1.2083, 1.2256],
        [1.2689, 1.2655, 1.2362, 1.2590, 1.2483, 1.2627, 1.2620, 1.2690, 1.2690,
         1.2390, 1.2248, 1.2267, 1.2107, 1.2562, 1.0707, 1.2393, 1.2560, 1.1942,
         1.2629, 1.2392, 1.1277, 1.2400, 1.2634, 1.2643, 1.2579, 1.2654, 1.2654,
         1.1843, 1.1432, 1.2029, 1.1539, 1.1578, 1.1512, 1.1917, 1.1798, 1.2028,
         1.2936, 1.2886, 1.2939, 1.2931, 1.2823, 1.2743, 1.2939, 0.9645, 0.8283,
         1.2636, 1.2237, 1.2363, 1.2350, 1.2339, 1.1842, 1.2637, 1.2265, 1.1828]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 3 : 186.50606543719414
Test loss for epoch 3 : 186.23779923947393
Test Precision for epoch 3 : 0.26153846153846155
Test Recall for epoch 3 : 0.26153846153846155
Test F1 for epoch 3 : 0.26153846153846155


theta for epoch 4 : tensor([[1.2574, 1.2709, 1.2867, 1.2798, 1.2815, 1.2618, 1.2669, 1.2573, 1.2573,
         1.3024, 1.2988, 1.3024, 1.2899, 1.3023, 1.2458, 1.3015, 1.3028, 1.2687,
         1.2233, 1.1820, 1.2485, 1.2281, 1.2570, 1.2587, 1.2559, 1.2587, 1.2587,
         1.1574, 1.1976, 1.1997, 1.1994, 1.1867, 1.1997, 1.1927, 1.1890, 1.1997,
         1.3636, 1.3650, 1.3650, 1.3646, 1.3646, 1.3536, 1.3637, 1.3382, 1.3386,
         1.2804, 1.2894, 1.2918, 1.2950, 1.2847, 1.2885, 1.2234, 1.2950, 1.2951],
        [1.3524, 1.2600, 0.9913, 1.3233, 1.3345, 1.3603, 1.3473, 1.3604, 1.3604,
         1.2563, 1.2778, 1.2372, 1.3100, 1.2503, 1.3491, 1.2542, 1.2275, 1.3314,
         1.2853, 1.2878, 0.8955, 1.2698, 1.3413, 1.3578, 1.3498, 1.3584, 1.3584,
         1.2285, 1.1735, 1.2589, 1.2467, 1.1807, 1.2589, 1.2505, 1.2545, 1.2501,
         1.3802, 1.3858, 1.3847, 1.3809, 1.3736, 1.3833, 1.3842, 0.7518, 1.3649,
         1.0061, 1.3588, 1.3572, 1.3599, 1.2189, 1.3587, 0.7469, 1.3600, 1.3601],
        [1.2963, 1.2857, 1.2727, 1.2631, 1.2307, 1.2962, 1.2474, 1.2963, 1.2963,
         1.3299, 1.3190, 1.3304, 1.3200, 1.3305, 1.0938, 1.3301, 1.3181, 1.2712,
         1.2810, 1.2891, 1.2989, 1.2887, 1.2660, 1.2655, 1.2779, 1.2615, 1.2615,
         1.1878, 1.1859, 1.2175, 1.2161, 1.1833, 1.2174, 1.2157, 1.2165, 1.2174,
         1.3799, 1.3808, 1.3808, 1.3770, 1.3802, 1.3799, 1.3807, 1.1216, 1.3190,
         1.2545, 1.3121, 1.3119, 1.3120, 1.2168, 1.3116, 1.2091, 1.3113, 1.3121],
        [1.2217, 1.2206, 1.1425, 1.1081, 1.2142, 1.2157, 1.2164, 1.2217, 1.2217,
         1.2643, 1.2360, 1.2339, 1.2222, 1.2646, 1.1803, 1.2616, 1.2637, 1.0827,
         1.2244, 1.1256, 1.2204, 1.2186, 1.2178, 1.2137, 1.2220, 1.2252, 1.2252,
         1.2893, 1.2464, 1.2300, 1.2429, 1.2821, 1.2279, 1.2813, 1.2303, 1.2274,
         1.3000, 1.2921, 1.2904, 1.2942, 1.2975, 1.2744, 1.2956, 0.9925, 1.2695,
         1.3236, 1.2804, 1.1980, 1.3043, 1.3092, 1.2304, 1.3304, 1.3045, 1.3220],
        [1.2495, 1.2039, 0.7545, 0.8365, 1.1820, 1.2414, 1.2262, 1.2495, 1.2495,
         1.3405, 1.3183, 1.2919, 1.0300, 1.3462, 0.7046, 1.3245, 1.3461, 1.2758,
         1.1941, 1.1019, 0.9339, 1.1631, 1.2555, 1.2565, 1.1735, 1.2654, 1.2654,
         0.8678, 0.8656, 1.2216, 1.1896, 0.9092, 1.2192, 1.1534, 1.2202, 1.2173,
         1.1515, 1.1079, 1.0974, 1.1346, 1.1988, 1.2103, 1.1345, 1.3289, 1.3157,
         0.9401, 1.1661, 1.1973, 1.2633, 1.1509, 1.2547, 0.8131, 1.2436, 1.2742],
        [1.2678, 1.2608, 1.2172, 1.2496, 1.2322, 1.2557, 1.2547, 1.2678, 1.2678,
         1.2948, 1.2768, 1.2781, 1.2602, 1.3199, 1.0916, 1.2952, 1.3197, 1.2406,
         1.2671, 1.2302, 1.1000, 1.2304, 1.2678, 1.2692, 1.2578, 1.2712, 1.2712,
         1.2217, 1.1562, 1.2506, 1.1733, 1.1796, 1.1698, 1.2334, 1.2145, 1.2505,
         1.3308, 1.3027, 1.3326, 1.3271, 1.2803, 1.2601, 1.3325, 0.9626, 0.7916,
         1.3411, 1.2836, 1.3016, 1.2998, 1.2980, 1.2262, 1.3412, 1.2876, 1.2241]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 4 : 186.08571282502805
Test loss for epoch 4 : 185.81068719249947
Test Precision for epoch 4 : 0.26153846153846155
Test Recall for epoch 4 : 0.26153846153846155
Test F1 for epoch 4 : 0.26153846153846155


theta for epoch 5 : tensor([[1.2875, 1.3059, 1.3280, 1.3185, 1.3208, 1.2934, 1.3004, 1.2874, 1.2874,
         1.3412, 1.3371, 1.3416, 1.3269, 1.3409, 1.2784, 1.3402, 1.3416, 1.3010,
         1.2706, 1.2225, 1.3044, 1.2767, 1.3107, 1.3126, 1.3098, 1.3125, 1.3125,
         1.2012, 1.2491, 1.2511, 1.2508, 1.2360, 1.2512, 1.2429, 1.2381, 1.2510,
         1.3337, 1.3362, 1.3363, 1.3354, 1.3355, 1.3190, 1.3340, 1.2974, 1.2989,
         1.3265, 1.3361, 1.3390, 1.3423, 1.3311, 1.3348, 1.2621, 1.3425, 1.3425],
        [1.4313, 1.3117, 1.0292, 1.3921, 1.4066, 1.4423, 1.4243, 1.4425, 1.4425,
         1.2449, 1.2835, 1.2151, 1.3435, 1.2350, 1.4138, 1.2416, 1.2011, 1.3825,
         1.3451, 1.3492, 0.9618, 1.3269, 1.4168, 1.4396, 1.4288, 1.4405, 1.4405,
         1.2863, 1.2145, 1.3234, 1.3084, 1.2246, 1.3234, 1.3132, 1.3180, 1.3125,
         1.3591, 1.3732, 1.3703, 1.3608, 1.3466, 1.3666, 1.3692, 0.6928, 1.3332,
         1.0389, 1.4258, 1.4235, 1.4271, 1.2520, 1.4255, 0.7702, 1.4273, 1.4274],
        [1.3620, 1.3494, 1.3380, 1.3228, 1.2815, 1.3619, 1.3004, 1.3619, 1.3619,
         1.3728, 1.3587, 1.3738, 1.3612, 1.3734, 1.0985, 1.3731, 1.3565, 1.3008,
         1.3094, 1.3225, 1.3385, 1.3221, 1.2858, 1.2852, 1.3046, 1.2791, 1.2791,
         1.2338, 1.2316, 1.2703, 1.2688, 1.2283, 1.2703, 1.2683, 1.2691, 1.2702,
         1.3538, 1.3560, 1.3558, 1.3481, 1.3544, 1.3539, 1.3556, 1.0842, 1.2719,
         1.2932, 1.3620, 1.3618, 1.3614, 1.2490, 1.3612, 1.2440, 1.3606, 1.3616],
        [1.2203, 1.2192, 1.1275, 1.0883, 1.2111, 1.2127, 1.2138, 1.2203, 1.2203,
         1.2716, 1.2338, 1.2320, 1.2172, 1.2718, 1.1707, 1.2681, 1.2706, 1.0492,
         1.2277, 1.1115, 1.2242, 1.2207, 1.2189, 1.2135, 1.2246, 1.2283, 1.2283,
         1.3596, 1.3084, 1.2888, 1.3041, 1.3510, 1.2863, 1.3501, 1.2892, 1.2856,
         1.2599, 1.2486, 1.2462, 1.2515, 1.2564, 1.2242, 1.2534, 0.9372, 1.2178,
         1.3594, 1.2843, 1.1653, 1.3222, 1.3343, 1.2087, 1.3721, 1.3227, 1.3531],
        [1.2934, 1.2335, 0.7332, 0.8306, 1.2043, 1.2826, 1.2625, 1.2934, 1.2934,
         1.4153, 1.3834, 1.3451, 1.0709, 1.4235, 0.6596, 1.3921, 1.4233, 1.3219,
         1.2193, 1.1014, 0.9520, 1.1796, 1.2994, 1.3010, 1.1935, 1.3128, 1.3128,
         0.8802, 0.8781, 1.2751, 1.2334, 0.9323, 1.2720, 1.1856, 1.2734, 1.2696,
         1.1378, 1.0830, 1.0700, 1.1168, 1.1967, 1.2117, 1.1165, 1.3705, 1.3516,
         0.9602, 1.1887, 1.2318, 1.3213, 1.1658, 1.3093, 0.7962, 1.2946, 1.3358],
        [1.3061, 1.2973, 1.2464, 1.2838, 1.2612, 1.2902, 1.2891, 1.3060, 1.3060,
         1.3490, 1.3280, 1.3283, 1.3108, 1.3819, 1.1222, 1.3496, 1.3818, 1.2883,
         1.3078, 1.2629, 1.1225, 1.2625, 1.3084, 1.3101, 1.2955, 1.3127, 1.3127,
         1.2842, 1.2064, 1.3184, 1.2265, 1.2342, 1.2225, 1.2980, 1.2756, 1.3183,
         1.3063, 1.2634, 1.3094, 1.3003, 1.2328, 1.2070, 1.3092, 0.9182, 0.7294,
         1.3956, 1.3123, 1.3378, 1.3352, 1.3315, 1.2328, 1.3957, 1.3179, 1.2300]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 5 : 185.7162522274542
Test loss for epoch 5 : 185.40227147422385
Test Precision for epoch 5 : 0.26153846153846155
Test Recall for epoch 5 : 0.26153846153846155
Test F1 for epoch 5 : 0.26153846153846155


theta for epoch 6 : tensor([[1.3356, 1.3580, 1.3849, 1.3735, 1.3763, 1.3429, 1.3513, 1.3355, 1.3355,
         1.3287, 1.3243, 1.3295, 1.3126, 1.3282, 1.2610, 1.3276, 1.3291, 1.2833,
         1.3120, 1.2582, 1.3531, 1.3195, 1.3580, 1.3601, 1.3576, 1.3600, 1.3600,
         1.2471, 1.3027, 1.3036, 1.3037, 1.2876, 1.3039, 1.2945, 1.2883, 1.3036,
         1.3166, 1.3203, 1.3203, 1.3190, 1.3192, 1.2972, 1.3171, 1.2706, 1.2725,
         1.3170, 1.3271, 1.3306, 1.3336, 1.3222, 1.3256, 1.2476, 1.3340, 1.3339],
        [1.4809, 1.3213, 1.0238, 1.4235, 1.4450, 1.4983, 1.4701, 1.4985, 1.4985,
         1.2658, 1.3187, 1.2263, 1.3990, 1.2525, 1.4900, 1.2614, 1.2083, 1.4498,
         1.3697, 1.3771, 0.9818, 1.3486, 1.4663, 1.5006, 1.4844, 1.5017, 1.5017,
         1.3400, 1.2493, 1.3838, 1.3660, 1.2628, 1.3840, 1.3720, 1.3777, 1.3707,
         1.3457, 1.3689, 1.3643, 1.3485, 1.3267, 1.3580, 1.3624, 0.6359, 1.3089,
         1.0163, 1.4314, 1.4281, 1.4327, 1.2270, 1.4309, 0.7434, 1.4332, 1.4332],
        [1.4049, 1.3898, 1.3786, 1.3573, 1.3057, 1.4048, 1.3270, 1.4047, 1.4047,
         1.3614, 1.3443, 1.3628, 1.3481, 1.3620, 1.0609, 1.3617, 1.3409, 1.2785,
         1.3585, 1.3754, 1.3960, 1.3749, 1.3280, 1.3275, 1.3523, 1.3195, 1.3195,
         1.2792, 1.2768, 1.3219, 1.3205, 1.2726, 1.3222, 1.3198, 1.3207, 1.3218,
         1.3381, 1.3416, 1.3413, 1.3296, 1.3391, 1.3384, 1.3409, 1.0568, 1.2349,
         1.2785, 1.3566, 1.3565, 1.3554, 1.2296, 1.3557, 1.2273, 1.3546, 1.3556],
        [1.2518, 1.2509, 1.1508, 1.1081, 1.2416, 1.2432, 1.2446, 1.2518, 1.2518,
         1.2853, 1.2394, 1.2387, 1.2211, 1.2854, 1.1741, 1.2814, 1.2842, 1.0313,
         1.2631, 1.1357, 1.2604, 1.2555, 1.2527, 1.2462, 1.2596, 1.2635, 1.2635,
         1.3952, 1.3323, 1.3086, 1.3270, 1.3846, 1.3056, 1.3834, 1.3092, 1.3047,
         1.2560, 1.2415, 1.2381, 1.2451, 1.2517, 1.2105, 1.2474, 0.9254, 1.2048,
         1.3644, 1.2625, 1.1230, 1.3091, 1.3292, 1.1708, 1.3849, 1.3103, 1.3511],
        [1.3382, 1.2630, 0.7099, 0.8238, 1.2258, 1.3245, 1.2991, 1.3382, 1.3382,
         1.4328, 1.3842, 1.3343, 1.0574, 1.4462, 0.5950, 1.3979, 1.4458, 1.3033,
         1.2448, 1.1000, 0.9699, 1.1958, 1.3448, 1.3471, 1.2143, 1.3618, 1.3618,
         0.8924, 0.8900, 1.3302, 1.2788, 0.9556, 1.3266, 1.2188, 1.3284, 1.3235,
         1.1388, 1.0718, 1.0562, 1.1136, 1.2096, 1.2282, 1.1128, 1.4254, 1.4013,
         0.9408, 1.1690, 1.2226, 1.3364, 1.1390, 1.3208, 0.7504, 1.3015, 1.3556],
        [1.3589, 1.3488, 1.2930, 1.3338, 1.3068, 1.3400, 1.3389, 1.3588, 1.3588,
         1.3743, 1.3502, 1.3497, 1.3332, 1.4168, 1.1327, 1.3751, 1.4169, 1.3094,
         1.3631, 1.3122, 1.1646, 1.3111, 1.3635, 1.3654, 1.3485, 1.3685, 1.3685,
         1.3571, 1.2702, 1.3949, 1.2919, 1.3013, 1.2877, 1.3723, 1.3469, 1.3948,
         1.3123, 1.2548, 1.3165, 1.3043, 1.2160, 1.1842, 1.3161, 0.9149, 0.7085,
         1.4069, 1.2968, 1.3293, 1.3258, 1.3201, 1.2001, 1.4068, 1.3038, 1.1966]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 6 : 185.70954189260317
Test loss for epoch 6 : 185.41218146597384
Test Precision for epoch 6 : 0.26153846153846155
Test Recall for epoch 6 : 0.26153846153846155
Test F1 for epoch 6 : 0.26153846153846155


theta for epoch 7 : tensor([[1.3661, 1.3929, 1.4254, 1.4119, 1.4151, 1.3748, 1.3848, 1.3660, 1.3660,
         1.3287, 1.3242, 1.3301, 1.3113, 1.3280, 1.2579, 1.3276, 1.3292, 1.2794,
         1.2929, 1.2355, 1.3380, 1.3016, 1.3438, 1.3461, 1.3436, 1.3458, 1.3458,
         1.2875, 1.3509, 1.3490, 1.3498, 1.3338, 1.3499, 1.3395, 1.3314, 1.3491,
         1.3198, 1.3245, 1.3244, 1.3228, 1.3230, 1.2961, 1.3204, 1.2660, 1.2677,
         1.3277, 1.3380, 1.3422, 1.3443, 1.3333, 1.3365, 1.2546, 1.3449, 1.3448],
        [1.4625, 1.2799, 0.9765, 1.3926, 1.4186, 1.4856, 1.4487, 1.4858, 1.4858,
         1.3138, 1.3761, 1.2678, 1.4690, 1.2982, 1.5733, 1.3086, 1.2469, 1.5273,
         1.3333, 1.3422, 0.9439, 1.3109, 1.4443, 1.4883, 1.4669, 1.4897, 1.4897,
         1.3763, 1.2633, 1.4274, 1.4061, 1.2809, 1.4280, 1.4139, 1.4204, 1.4116,
         1.3430, 1.3755, 1.3693, 1.3469, 1.3170, 1.3603, 1.3666, 0.5847, 1.2948,
         0.9958, 1.4419, 1.4377, 1.4432, 1.2049, 1.4413, 0.7168, 1.4439, 1.4438],
        [1.3856, 1.3683, 1.3561, 1.3314, 1.2739, 1.3856, 1.2966, 1.3855, 1.3855,
         1.3586, 1.3388, 1.3607, 1.3440, 1.3593, 1.0348, 1.3590, 1.3339, 1.2656,
         1.3957, 1.4170, 1.4428, 1.4165, 1.3576, 1.3572, 1.3882, 1.3473, 1.3473,
         1.3169, 1.3145, 1.3650, 1.3641, 1.3092, 1.3658, 1.3632, 1.3639, 1.3650,
         1.3408, 1.3455, 1.3451, 1.3294, 1.3422, 1.3415, 1.3445, 1.0495, 1.2169,
         1.2803, 1.3671, 1.3672, 1.3650, 1.2270, 1.3661, 1.2280, 1.3642, 1.3653],
        [1.2862, 1.2858, 1.1808, 1.1348, 1.2755, 1.2767, 1.2787, 1.2861, 1.2861,
         1.3314, 1.2811, 1.2813, 1.2623, 1.3314, 1.2158, 1.3274, 1.3301, 1.0608,
         1.2975, 1.1620, 1.2963, 1.2896, 1.2852, 1.2779, 1.2935, 1.2972, 1.2972,
         1.3959, 1.3214, 1.2939, 1.3150, 1.3833, 1.2905, 1.3817, 1.2947, 1.2895,
         1.2795, 1.2624, 1.2580, 1.2665, 1.2746, 1.2259, 1.2690, 0.9448, 1.2213,
         1.4141, 1.3060, 1.1644, 1.3537, 1.3764, 1.2118, 1.4367, 1.3551, 1.3983],
        [1.3518, 1.2603, 0.6648, 0.7920, 1.2150, 1.3349, 1.3036, 1.3518, 1.3518,
         1.4491, 1.3829, 1.3214, 1.0400, 1.4680, 0.5273, 1.4019, 1.4674, 1.2823,
         1.2329, 1.0667, 0.9531, 1.1760, 1.3527, 1.3561, 1.1990, 1.3739, 1.3739,
         0.8880, 0.8850, 1.3726, 1.3097, 0.9625, 1.3685, 1.2361, 1.3707, 1.3644,
         1.1580, 1.0786, 1.0605, 1.1288, 1.2400, 1.2617, 1.1273, 1.4918, 1.4636,
         0.9257, 1.1566, 1.2217, 1.3595, 1.1180, 1.3403, 0.7070, 1.3163, 1.3832],
        [1.3738, 1.3625, 1.3031, 1.3468, 1.3147, 1.3517, 1.3506, 1.3737, 1.3737,
         1.3967, 1.3700, 1.3681, 1.3538, 1.4495, 1.1428, 1.3978, 1.4498, 1.3290,
         1.3763, 1.3201, 1.1667, 1.3177, 1.3765, 1.3786, 1.3590, 1.3820, 1.3820,
         1.4141, 1.3178, 1.4547, 1.3384, 1.3510, 1.3333, 1.4299, 1.4000, 1.4547,
         1.3308, 1.2582, 1.3360, 1.3209, 1.2112, 1.1728, 1.3353, 0.9249, 0.6989,
         1.4410, 1.3081, 1.3471, 1.3427, 1.3346, 1.1947, 1.4407, 1.3164, 1.1905]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 7 : 185.31588554544672
Test loss for epoch 7 : 185.0660610798106
Test Precision for epoch 7 : 0.26153846153846155
Test Recall for epoch 7 : 0.26153846153846155
Test F1 for epoch 7 : 0.26153846153846155


theta for epoch 8 : tensor([[1.3831, 1.4147, 1.4530, 1.4373, 1.4410, 1.3933, 1.4050, 1.3829, 1.3829,
         1.3347, 1.3305, 1.3371, 1.3169, 1.3339, 1.2640, 1.3338, 1.3353, 1.2832,
         1.2706, 1.2115, 1.3193, 1.2803, 1.3245, 1.3269, 1.3250, 1.3264, 1.3264,
         1.2967, 1.3680, 1.3622, 1.3638, 1.3490, 1.3636, 1.3526, 1.3421, 1.3624,
         1.3393, 1.3450, 1.3448, 1.3429, 1.3432, 1.3119, 1.3400, 1.2802, 1.2808,
         1.3569, 1.3671, 1.3718, 1.3729, 1.3629, 1.3657, 1.2814, 1.3737, 1.3734],
        [1.4401, 1.2368, 0.9323, 1.3594, 1.3890, 1.4688, 1.4236, 1.4690, 1.4690,
         1.3557, 1.4282, 1.3029, 1.5348, 1.3377, 1.6538, 1.3498, 1.2789, 1.6013,
         1.2911, 1.3017, 0.9022, 1.2677, 1.4151, 1.4684, 1.4423, 1.4700, 1.4700,
         1.3820, 1.2480, 1.4402, 1.4152, 1.2695, 1.4412, 1.4250, 1.4323, 1.4214,
         1.3566, 1.3981, 1.3904, 1.3617, 1.3241, 1.3788, 1.3869, 0.5544, 1.2982,
         0.9930, 1.4673, 1.4621, 1.4682, 1.1996, 1.4666, 0.7083, 1.4691, 1.4690],
        [1.3651, 1.3467, 1.3360, 1.3075, 1.2441, 1.3652, 1.2673, 1.3649, 1.3649,
         1.3607, 1.3384, 1.3637, 1.3457, 1.3612, 1.0194, 1.3613, 1.3319, 1.2592,
         1.4210, 1.4473, 1.4787, 1.4467, 1.3748, 1.3747, 1.4122, 1.3626, 1.3626,
         1.3244, 1.3222, 1.3772, 1.3769, 1.3156, 1.3785, 1.3758, 1.3762, 1.3773,
         1.3596, 1.3653, 1.3648, 1.3456, 1.3614, 1.3607, 1.3640, 1.0615, 1.2172,
         1.3003, 1.3941, 1.3945, 1.3910, 1.2434, 1.3931, 1.2478, 1.3903, 1.3914],
        [1.3178, 1.3184, 1.2099, 1.1604, 1.3072, 1.3076, 1.3103, 1.3177, 1.3177,
         1.3778, 1.3234, 1.3248, 1.3045, 1.3776, 1.2598, 1.3737, 1.3764, 1.0922,
         1.3261, 1.1835, 1.3273, 1.3181, 1.3115, 1.3033, 1.3216, 1.3246, 1.3246,
         1.3870, 1.3006, 1.2693, 1.2932, 1.3723, 1.2655, 1.3703, 1.2703, 1.2643,
         1.3129, 1.2932, 1.2880, 1.2979, 1.3076, 1.2516, 1.3007, 0.9744, 1.2483,
         1.4753, 1.3621, 1.2187, 1.4106, 1.4357, 1.2657, 1.4996, 1.4123, 1.4573],
        [1.3593, 1.2511, 0.6156, 0.7553, 1.1973, 1.3388, 1.3017, 1.3592, 1.3592,
         1.4600, 1.3760, 1.3031, 1.0177, 1.4845, 0.4591, 1.4004, 1.4837, 1.2565,
         1.2118, 1.0252, 0.9279, 1.1470, 1.3512, 1.3559, 1.1747, 1.3770, 1.3770,
         0.8600, 0.8565, 1.3874, 1.3120, 0.9443, 1.3827, 1.2251, 1.3854, 1.3776,
         1.1857, 1.0936, 1.0731, 1.1525, 1.2785, 1.3035, 1.1502, 1.5643, 1.5324,
         0.9216, 1.1572, 1.2335, 1.3934, 1.1090, 1.3711, 0.6740, 1.3427, 1.4213],
        [1.3734, 1.3613, 1.2992, 1.3452, 1.3077, 1.3480, 1.3469, 1.3733, 1.3733,
         1.3969, 1.3679, 1.3639, 1.3528, 1.4613, 1.1321, 1.3983, 1.4618, 1.3268,
         1.3725, 1.3111, 1.1524, 1.3073, 1.3722, 1.3744, 1.3521, 1.3782, 1.3782,
         1.4236, 1.3194, 1.4666, 1.3371, 1.3532, 1.3309, 1.4397, 1.4047, 1.4666,
         1.3556, 1.2673, 1.3616, 1.3440, 1.2119, 1.1666, 1.3608, 0.9410, 0.6932,
         1.4937, 1.3435, 1.3877, 1.3825, 1.3722, 1.2161, 1.4932, 1.3529, 1.2113]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 8 : 185.1131487547612
Test loss for epoch 8 : 184.9123523251907
Test Precision for epoch 8 : 0.26153846153846155
Test Recall for epoch 8 : 0.26153846153846155
Test F1 for epoch 8 : 0.26153846153846155


theta for epoch 9 : tensor([[1.4008, 1.4372, 1.4815, 1.4636, 1.4677, 1.4125, 1.4260, 1.4006, 1.4006,
         1.3249, 1.3213, 1.3288, 1.3081, 1.3237, 1.2580, 1.3244, 1.3256, 1.2723,
         1.2627, 1.2041, 1.3144, 1.2736, 1.3173, 1.3195, 1.3189, 1.3187, 1.3187,
         1.2922, 1.3710, 1.3612, 1.3638, 1.3502, 1.3632, 1.3516, 1.3388, 1.3615,
         1.3684, 1.3749, 1.3745, 1.3724, 1.3729, 1.3377, 1.3691, 1.3059, 1.3048,
         1.3820, 1.3915, 1.3965, 1.3965, 1.3882, 1.3900, 1.3052, 1.3975, 1.3971],
        [1.4387, 1.2205, 0.9240, 1.3510, 1.3825, 1.4721, 1.4201, 1.4721, 1.4721,
         1.3574, 1.4402, 1.2986, 1.5630, 1.3372, 1.7043, 1.3509, 1.2720, 1.6413,
         1.2706, 1.2839, 0.8875, 1.2472, 1.4048, 1.4664, 1.4366, 1.4681, 1.4681,
         1.3834, 1.2299, 1.4483, 1.4196, 1.2550, 1.4497, 1.4316, 1.4394, 1.4266,
         1.3862, 1.4355, 1.4264, 1.3923, 1.3480, 1.4128, 1.4223, 0.5521, 1.3198,
         1.0005, 1.4965, 1.4903, 1.4966, 1.2019, 1.4955, 0.7136, 1.4979, 1.4977],
        [1.3587, 1.3411, 1.3347, 1.3020, 1.2330, 1.3589, 1.2552, 1.3583, 1.3583,
         1.3483, 1.3242, 1.3528, 1.3342, 1.3487, 0.9965, 1.3493, 1.3157, 1.2403,
         1.4455, 1.4769, 1.5142, 1.4763, 1.3910, 1.3912, 1.4355, 1.3769, 1.3769,
         1.3191, 1.3173, 1.3764, 1.3768, 1.3094, 1.3782, 1.3755, 1.3755, 1.3766,
         1.3883, 1.3951, 1.3944, 1.3719, 1.3907, 1.3900, 1.3933, 1.0859, 1.2297,
         1.3173, 1.4170, 1.4176, 1.4127, 1.2572, 1.4159, 1.2658, 1.4122, 1.4133],
        [1.3392, 1.3410, 1.2286, 1.1756, 1.3288, 1.3282, 1.3318, 1.3390, 1.3390,
         1.3905, 1.3320, 1.3351, 1.3134, 1.3901, 1.2719, 1.3866, 1.3891, 1.0918,
         1.3449, 1.1947, 1.3486, 1.3369, 1.3277, 1.3183, 1.3397, 1.3420, 1.3420,
         1.3934, 1.2951, 1.2598, 1.2865, 1.3766, 1.2555, 1.3743, 1.2610, 1.2541,
         1.3459, 1.3236, 1.3175, 1.3289, 1.3403, 1.2769, 1.3319, 1.0023, 1.2749,
         1.5117, 1.3935, 1.2491, 1.4423, 1.4704, 1.2951, 1.5375, 1.4442, 1.4912],
        [1.3769, 1.2532, 0.5809, 0.7325, 1.1906, 1.3529, 1.3104, 1.3767, 1.3767,
         1.4550, 1.3546, 1.2720, 0.9861, 1.4850, 0.3934, 1.3839, 1.4841, 1.2190,
         1.2014, 0.9946, 0.9148, 1.1289, 1.3593, 1.3654, 1.1617, 1.3895, 1.3895,
         0.8289, 0.8252, 1.3965, 1.3084, 0.9223, 1.3911, 1.2082, 1.3945, 1.3851,
         1.2088, 1.1036, 1.0805, 1.1716, 1.3130, 1.3416, 1.1683, 1.6357, 1.5998,
         0.9216, 1.1606, 1.2470, 1.4276, 1.1025, 1.4021, 0.6478, 1.3700, 1.4594],
        [1.3718, 1.3593, 1.2957, 1.3431, 1.3000, 1.3430, 1.3422, 1.3716, 1.3716,
         1.3673, 1.3365, 1.3310, 1.3226, 1.4416, 1.0954, 1.3691, 1.4424, 1.2953,
         1.3677, 1.3017, 1.1384, 1.2964, 1.3667, 1.3689, 1.3441, 1.3730, 1.3730,
         1.4145, 1.3035, 1.4597, 1.3178, 1.3371, 1.3104, 1.4309, 1.3908, 1.4598,
         1.3859, 1.2817, 1.3927, 1.3729, 1.2180, 1.1655, 1.3917, 0.9643, 0.6930,
         1.5533, 1.3874, 1.4364, 1.4306, 1.4179, 1.2467, 1.5526, 1.3977, 1.2412]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 9 : 185.27511338416326
Test loss for epoch 9 : 185.1033035582808
Test Precision for epoch 9 : 0.26153846153846155
Test Recall for epoch 9 : 0.26153846153846155
Test F1 for epoch 9 : 0.26153846153846155


theta for epoch 10 : tensor([[1.4241, 1.4651, 1.5153, 1.4954, 1.4996, 1.4372, 1.4526, 1.4238, 1.4238,
         1.3236, 1.3210, 1.3295, 1.3090, 1.3220, 1.2635, 1.3236, 1.3242, 1.2712,
         1.2725, 1.2159, 1.3262, 1.2843, 1.3257, 1.3275, 1.3289, 1.3264, 1.3264,
         1.2922, 1.3779, 1.3643, 1.3677, 1.3556, 1.3669, 1.3548, 1.3396, 1.3647,
         1.4020, 1.4094, 1.4088, 1.4066, 1.4074, 1.3684, 1.4027, 1.3382, 1.3349,
         1.3654, 1.3739, 1.3790, 1.3780, 1.3718, 1.3721, 1.2884, 1.3794, 1.3788],
        [1.4516, 1.2221, 0.9365, 1.3592, 1.3918, 1.4892, 1.4314, 1.4891, 1.4891,
         1.3510, 1.4443, 1.2864, 1.5839, 1.3286, 1.7496, 1.3440, 1.2571, 1.6750,
         1.2680, 1.2843, 0.8918, 1.2452, 1.4105, 1.4794, 1.4469, 1.4811, 1.4811,
         1.3932, 1.2217, 1.4641, 1.4322, 1.2501, 1.4659, 1.4461, 1.4543, 1.4399,
         1.4232, 1.4797, 1.4691, 1.4303, 1.3799, 1.4541, 1.4645, 0.5632, 1.3504,
         0.9778, 1.4863, 1.4791, 1.4854, 1.1725, 1.4847, 0.6930, 1.4870, 1.4868],
        [1.3669, 1.3512, 1.3509, 1.3142, 1.2403, 1.3673, 1.2606, 1.3663, 1.3663,
         1.3453, 1.3198, 1.3517, 1.3334, 1.3452, 0.9893, 1.3468, 1.3090, 1.2323,
         1.4734, 1.5100, 1.5530, 1.5095, 1.4109, 1.4115, 1.4624, 1.3949, 1.3949,
         1.3191, 1.3178, 1.3803, 1.3814, 1.3086, 1.3825, 1.3800, 1.3796, 1.3806,
         1.4221, 1.4299, 1.4289, 1.4034, 1.4252, 1.4245, 1.4276, 1.1177, 1.2494,
         1.2966, 1.4000, 1.4006, 1.3945, 1.2344, 1.3986, 1.2466, 1.3942, 1.3953],
        [1.3461, 1.3493, 1.2322, 1.1754, 1.3360, 1.3344, 1.3388, 1.3458, 1.3458,
         1.3900, 1.3269, 1.3321, 1.3087, 1.3893, 1.2703, 1.3862, 1.3885, 1.0766,
         1.3519, 1.1931, 1.3580, 1.3439, 1.3317, 1.3210, 1.3460, 1.3473, 1.3473,
         1.4227, 1.3143, 1.2754, 1.3046, 1.4043, 1.2707, 1.4016, 1.2768, 1.2692,
         1.3731, 1.3480, 1.3410, 1.3539, 1.3672, 1.2961, 1.3573, 1.0225, 1.2957,
         1.4916, 1.3711, 1.2275, 1.4195, 1.4497, 1.2723, 1.5182, 1.4217, 1.4697],
        [1.4102, 1.2741, 0.5731, 0.7345, 1.2036, 1.3831, 1.3364, 1.4099, 1.4099,
         1.4729, 1.3606, 1.2720, 0.9894, 1.5067, 0.3773, 1.3937, 1.5058, 1.2145,
         1.2120, 0.9877, 0.9249, 1.1330, 1.3849, 1.3923, 1.1706, 1.4188, 1.4188,
         0.8174, 0.8140, 1.4190, 1.3199, 0.9190, 1.4132, 1.2074, 1.4172, 1.4064,
         1.2150, 1.0967, 1.0713, 1.1739, 1.3309, 1.3638, 1.1695, 1.6975, 1.6565,
         0.8981, 1.1363, 1.2295, 1.4266, 1.0707, 1.3984, 0.6068, 1.3634, 1.4625],
        [1.3778, 1.3656, 1.3022, 1.3501, 1.3011, 1.3460, 1.3454, 1.3776, 1.3776,
         1.3480, 1.3169, 1.3095, 1.3064, 1.4314, 1.0801, 1.3504, 1.4326, 1.2770,
         1.3724, 1.3028, 1.1362, 1.2958, 1.3704, 1.3723, 1.3454, 1.3767, 1.3767,
         1.4093, 1.2928, 1.4566, 1.3029, 1.3251, 1.2942, 1.4261, 1.3808, 1.4568,
         1.4218, 1.3021, 1.4292, 1.4075, 1.2306, 1.1709, 1.4279, 0.9968, 0.7024,
         1.5945, 1.4112, 1.4656, 1.4589, 1.4432, 1.2562, 1.5935, 1.4227, 1.2502]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 10 : 184.8585527090954
Test loss for epoch 10 : 184.70065217496696
Test Precision for epoch 10 : 0.26153846153846155
Test Recall for epoch 10 : 0.26153846153846155
Test F1 for epoch 10 : 0.26153846153846155


theta for epoch 11 : tensor([[1.4413, 1.4872, 1.5432, 1.5215, 1.5256, 1.4559, 1.4731, 1.4410, 1.4410,
         1.3353, 1.3338, 1.3435, 1.3236, 1.3331, 1.2838, 1.3360, 1.3358, 1.2840,
         1.2876, 1.2344, 1.3429, 1.3005, 1.3378, 1.3391, 1.3430, 1.3376, 1.3376,
         1.2937, 1.3856, 1.3684, 1.3726, 1.3621, 1.3714, 1.3590, 1.3413, 1.3689,
         1.4337, 1.4419, 1.4409, 1.4387, 1.4400, 1.3975, 1.4342, 1.3703, 1.3644,
         1.3426, 1.3498, 1.3548, 1.3526, 1.3490, 1.3475, 1.2662, 1.3543, 1.3536],
        [1.4568, 1.2184, 0.9470, 1.3615, 1.3946, 1.4985, 1.4355, 1.4981, 1.4981,
         1.3490, 1.4528, 1.2787, 1.6094, 1.3245, 1.7990, 1.3415, 1.2467, 1.7130,
         1.2670, 1.2867, 0.8986, 1.2453, 1.4168, 1.4925, 1.4579, 1.4942, 1.4942,
         1.4023, 1.2135, 1.4790, 1.4440, 1.2449, 1.4813, 1.4599, 1.4684, 1.4523,
         1.4570, 1.5210, 1.5086, 1.4651, 1.4091, 1.4926, 1.5034, 0.5742, 1.3790,
         0.9490, 1.4678, 1.4596, 1.4657, 1.1365, 1.4654, 0.6675, 1.4677, 1.4673],
        [1.3690, 1.3564, 1.3639, 1.3231, 1.2447, 1.3697, 1.2621, 1.3682, 1.3682,
         1.3557, 1.3295, 1.3644, 1.3468, 1.3551, 1.0006, 1.3578, 1.3162, 1.2394,
         1.4971, 1.5390, 1.5878, 1.5387, 1.4263, 1.4275, 1.4852, 1.4086, 1.4086,
         1.3212, 1.3205, 1.3858, 1.3876, 1.3101, 1.3885, 1.3861, 1.3852, 1.3862,
         1.4543, 1.4631, 1.4617, 1.4334, 1.4583, 1.4577, 1.4601, 1.1502, 1.2694,
         1.2707, 1.3769, 1.3773, 1.3699, 1.2067, 1.3749, 1.2231, 1.3699, 1.3708],
        [1.3312, 1.3356, 1.2142, 1.1543, 1.3214, 1.3187, 1.3241, 1.3308, 1.3308,
         1.3812, 1.3130, 1.3208, 1.2952, 1.3801, 1.2596, 1.3776, 1.3795, 1.0518,
         1.3425, 1.1754, 1.3510, 1.3346, 1.3195, 1.3074, 1.3360, 1.3363, 1.3363,
         1.4671, 1.3498, 1.3077, 1.3392, 1.4472, 1.3026, 1.4443, 1.3093, 1.3010,
         1.3896, 1.3616, 1.3536, 1.3681, 1.3837, 1.3047, 1.3719, 1.0309, 1.3060,
         1.4569, 1.3343, 1.1911, 1.3824, 1.4146, 1.2348, 1.4843, 1.3847, 1.4337],
        [1.4475, 1.3007, 0.5781, 0.7476, 1.2229, 1.4174, 1.3673, 1.4470, 1.4470,
         1.5101, 1.3893, 1.2970, 1.0178, 1.5465, 0.3928, 1.4252, 1.5457, 1.2363,
         1.2333, 0.9938, 0.9472, 1.1486, 1.4188, 1.4275, 1.1909, 1.4561, 1.4561,
         0.8191, 0.8164, 1.4497, 1.3405, 0.9279, 1.4435, 1.2167, 1.4481, 1.4360,
         1.2044, 1.0739, 1.0464, 1.1597, 1.3320, 1.3692, 1.1542, 1.7481, 1.7009,
         0.8804, 1.1155, 1.2137, 1.4248, 1.0428, 1.3942, 0.5773, 1.3570, 1.4646],
        [1.3791, 1.3678, 1.3065, 1.3536, 1.2989, 1.3444, 1.3443, 1.3787, 1.3787,
         1.3435, 1.3135, 1.3039, 1.3080, 1.4347, 1.0879, 1.3467, 1.4363, 1.2761,
         1.3790, 1.3069, 1.1383, 1.2980, 1.3755, 1.3772, 1.3485, 1.3817, 1.3817,
         1.4047, 1.2840, 1.4538, 1.2891, 1.3140, 1.2791, 1.4219, 1.3713, 1.4541,
         1.4550, 1.3197, 1.4630, 1.4397, 1.2408, 1.1740, 1.4614, 1.0302, 0.7130,
         1.6301, 1.4292, 1.4892, 1.4816, 1.4622, 1.2595, 1.6289, 1.4418, 1.2528]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 11 : 184.54341947014683
Test loss for epoch 11 : 184.3848527329368
Test Precision for epoch 11 : 0.26153846153846155
Test Recall for epoch 11 : 0.26153846153846155
Test F1 for epoch 11 : 0.26153846153846155


theta for epoch 12 : tensor([[1.4513, 1.5019, 1.5639, 1.5404, 1.5444, 1.4672, 1.4864, 1.4509, 1.4509,
         1.3577, 1.3575, 1.3683, 1.3494, 1.3548, 1.3156, 1.3592, 1.3580, 1.3082,
         1.3027, 1.2539, 1.3590, 1.3167, 1.3484, 1.3490, 1.3560, 1.3471, 1.3471,
         1.2921, 1.3895, 1.3686, 1.3737, 1.3651, 1.3721, 1.3597, 1.3395, 1.3693,
         1.4530, 1.4624, 1.4608, 1.4586, 1.4606, 1.4148, 1.4535, 1.3918, 1.3830,
         1.3324, 1.3376, 1.3424, 1.3387, 1.3386, 1.3346, 1.2577, 1.3408, 1.3399],
        [1.4545, 1.2093, 0.9542, 1.3575, 1.3909, 1.5000, 1.4322, 1.4992, 1.4992,
         1.3522, 1.4665, 1.2763, 1.6398, 1.3256, 1.8527, 1.3443, 1.2416, 1.7557,
         1.2625, 1.2861, 0.9026, 1.2424, 1.4186, 1.5008, 1.4646, 1.5024, 1.5024,
         1.4052, 1.2000, 1.4876, 1.4496, 1.2341, 1.4903, 1.4675, 1.4761, 1.4584,
         1.4761, 1.5478, 1.5335, 1.4854, 1.4238, 1.5168, 1.5277, 0.5744, 1.3937,
         0.9314, 1.4594, 1.4499, 1.4555, 1.1114, 1.4558, 0.6536, 1.4580, 1.4574],
        [1.3685, 1.3598, 1.3764, 1.3319, 1.2495, 1.3694, 1.2635, 1.3673, 1.3673,
         1.3780, 1.3514, 1.3890, 1.3725, 1.3767, 1.0273, 1.3808, 1.3357, 1.2599,
         1.5111, 1.5587, 1.6135, 1.5586, 1.4321, 1.4340, 1.4986, 1.4127, 1.4127,
         1.3218, 1.3218, 1.3890, 1.3917, 1.3102, 1.3922, 1.3900, 1.3886, 1.3896,
         1.4748, 1.4849, 1.4828, 1.4519, 1.4801, 1.4796, 1.4809, 1.1739, 1.2800,
         1.2589, 1.3666, 1.3668, 1.3577, 1.1936, 1.3638, 1.2149, 1.3582, 1.3588],
        [1.3042, 1.3099, 1.1848, 1.1221, 1.2949, 1.2912, 1.2974, 1.3037, 1.3037,
         1.3698, 1.2964, 1.3071, 1.2791, 1.3684, 1.2464, 1.3664, 1.3680, 1.0238,
         1.3221, 1.1473, 1.3331, 1.3143, 1.2962, 1.2827, 1.3150, 1.3142, 1.3142,
         1.5186, 1.3930, 1.3477, 1.3814, 1.4974, 1.3423, 1.4941, 1.3495, 1.3406,
         1.3915, 1.3606, 1.3514, 1.3676, 1.3855, 1.2988, 1.3718, 1.0254, 1.3021,
         1.4250, 1.2997, 1.1566, 1.3475, 1.3821, 1.1993, 1.4533, 1.3500, 1.4001],
        [1.4824, 1.3255, 0.5850, 0.7616, 1.2402, 1.4492, 1.3960, 1.4817, 1.4817,
         1.5557, 1.4278, 1.3327, 1.0561, 1.5943, 0.4199, 1.4662, 1.5937, 1.2691,
         1.2544, 1.0005, 0.9699, 1.1642, 1.4516, 1.4618, 1.2116, 1.4924, 1.4924,
         0.8209, 0.8191, 1.4785, 1.3595, 0.9365, 1.4720, 1.2244, 1.4772, 1.4639,
         1.1851, 1.0426, 1.0130, 1.1368, 1.3242, 1.3662, 1.1301, 1.7939, 1.7398,
         0.8789, 1.1111, 1.2131, 1.4359, 1.0316, 1.4031, 0.5665, 1.3643, 1.4791],
        [1.3761, 1.3662, 1.3088, 1.3542, 1.2936, 1.3388, 1.3393, 1.3755, 1.3755,
         1.3506, 1.3227, 1.3109, 1.3228, 1.4483, 1.1122, 1.3546, 1.4506, 1.2886,
         1.3839, 1.3103, 1.1411, 1.2994, 1.3785, 1.3798, 1.3498, 1.3843, 1.3843,
         1.3964, 1.2728, 1.4468, 1.2723, 1.2998, 1.2607, 1.4139, 1.3581, 1.4473,
         1.4736, 1.3227, 1.4821, 1.4574, 1.2371, 1.1638, 1.4801, 1.0523, 0.7134,
         1.6685, 1.4504, 1.5159, 1.5074, 1.4840, 1.2660, 1.6669, 1.4642, 1.2587]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 12 : 184.4112116482683
Test loss for epoch 12 : 184.23948150867017
Test Precision for epoch 12 : 0.26153846153846155
Test Recall for epoch 12 : 0.26153846153846155
Test F1 for epoch 12 : 0.26153846153846155


theta for epoch 13 : tensor([[1.4628, 1.5180, 1.5857, 1.5606, 1.5644, 1.4800, 1.5011, 1.4623, 1.4623,
         1.3797, 1.3809, 1.3927, 1.3747, 1.3760, 1.3476, 1.3819, 1.3797, 1.3326,
         1.3181, 1.2745, 1.3748, 1.3331, 1.3584, 1.3583, 1.3683, 1.3559, 1.3559,
         1.2819, 1.3845, 1.3595, 1.3657, 1.3593, 1.3638, 1.3512, 1.3285, 1.3604,
         1.4592, 1.4697, 1.4675, 1.4654, 1.4681, 1.4193, 1.4595, 1.4008, 1.3891,
         1.3350, 1.3379, 1.3423, 1.3369, 1.3411, 1.3341, 1.2625, 1.3395, 1.3383],
        [1.4555, 1.2053, 0.9671, 1.3578, 1.3910, 1.5045, 1.4324, 1.5033, 1.5033,
         1.3535, 1.4783, 1.2721, 1.6686, 1.3248, 1.9055, 1.3452, 1.2348, 1.7973,
         1.2589, 1.2865, 0.9077, 1.2406, 1.4205, 1.5085, 1.4710, 1.5099, 1.5099,
         1.3999, 1.1793, 1.4874, 1.4466, 1.2160, 1.4908, 1.4666, 1.4751, 1.4558,
         1.4819, 1.5614, 1.5451, 1.4923, 1.4255, 1.5278, 1.5386, 0.5654, 1.3955,
         0.9281, 1.4636, 1.4531, 1.4577, 1.1007, 1.4590, 0.6539, 1.4608, 1.4599],
        [1.3753, 1.3712, 1.3971, 1.3491, 1.2639, 1.3765, 1.2741, 1.3738, 1.3738,
         1.4014, 1.3749, 1.4148, 1.3995, 1.3994, 1.0582, 1.4049, 1.3565, 1.2827,
         1.5212, 1.5745, 1.6354, 1.5746, 1.4340, 1.4367, 1.5081, 1.4130, 1.4130,
         1.3154, 1.3164, 1.3845, 1.3882, 1.3035, 1.3883, 1.3863, 1.3844, 1.3852,
         1.4830, 1.4943, 1.4916, 1.4580, 1.4896, 1.4893, 1.4893, 1.1868, 1.2797,
         1.2612, 1.3694, 1.3693, 1.3584, 1.1949, 1.3657, 1.2213, 1.3593, 1.3597],
        [1.2798, 1.2871, 1.1587, 1.0933, 1.2713, 1.2663, 1.2734, 1.2792, 1.2792,
         1.3579, 1.2796, 1.2935, 1.2630, 1.3560, 1.2338, 1.3549, 1.3560, 0.9969,
         1.3020, 1.1205, 1.3156, 1.2946, 1.2732, 1.2582, 1.2942, 1.2921, 1.2921,
         1.5679, 1.4338, 1.3853, 1.4212, 1.5453, 1.3796, 1.5417, 1.3873, 1.3777,
         1.3840, 1.3504, 1.3400, 1.3577, 1.3782, 1.2840, 1.3623, 1.0123, 1.2895,
         1.4036, 1.2754, 1.1322, 1.3225, 1.3603, 1.1736, 1.4329, 1.3253, 1.3765],
        [1.5137, 1.3461, 0.5865, 0.7704, 1.2528, 1.4772, 1.4207, 1.5127, 1.5127,
         1.5934, 1.4581, 1.3604, 1.0851, 1.6342, 0.4388, 1.4992, 1.6337, 1.2941,
         1.2689, 1.0003, 0.9850, 1.1731, 1.4783, 1.4903, 1.2260, 1.5229, 1.5229,
         0.8107, 0.8100, 1.4959, 1.3667, 0.9330, 1.4892, 1.2199, 1.4952, 1.4804,
         1.1688, 1.0139, 0.9823, 1.1170, 1.3199, 1.3669, 1.1089, 1.8442, 1.7833,
         0.8835, 1.1150, 1.2209, 1.4549, 1.0283, 1.4201, 0.5612, 1.3798, 1.5013],
        [1.3777, 1.3698, 1.3176, 1.3604, 1.2943, 1.3382, 1.3395, 1.3769, 1.3769,
         1.3600, 1.3352, 1.3210, 1.3413, 1.4632, 1.1434, 1.3650, 1.4661, 1.3053,
         1.3906, 1.3166, 1.1483, 1.3035, 1.3831, 1.3838, 1.3529, 1.3883, 1.3883,
         1.3827, 1.2576, 1.4336, 1.2504, 1.2807, 1.2372, 1.4001, 1.3391, 1.4342,
         1.4794, 1.3135, 1.4884, 1.4626, 1.2220, 1.1429, 1.4860, 1.0646, 0.7059,
         1.7078, 1.4731, 1.5442, 1.5346, 1.5070, 1.2741, 1.7059, 1.4881, 1.2661]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 13 : 184.47368627052342
Test loss for epoch 13 : 184.28811666669233
Test Precision for epoch 13 : 0.26153846153846155
Test Recall for epoch 13 : 0.26153846153846155
Test F1 for epoch 13 : 0.26153846153846155


theta for epoch 14 : tensor([[1.4802, 1.5398, 1.6126, 1.5861, 1.5899, 1.4986, 1.5217, 1.4796, 1.4796,
         1.3832, 1.3859, 1.3987, 1.3815, 1.3787, 1.3614, 1.3862, 1.3830, 1.3391,
         1.3330, 1.2947, 1.3891, 1.3488, 1.3676, 1.3665, 1.3795, 1.3637, 1.3637,
         1.2652, 1.3730, 1.3433, 1.3509, 1.3470, 1.3484, 1.3358, 1.3105, 1.3444,
         1.4588, 1.4704, 1.4675, 1.4654, 1.4689, 1.4174, 1.4589, 1.4033, 1.3889,
         1.3475, 1.3480, 1.3521, 1.3447, 1.3535, 1.3434, 1.2777, 1.3478, 1.3464],
        [1.4609, 1.2073, 0.9856, 1.3630, 1.3961, 1.5129, 1.4371, 1.5113, 1.5113,
         1.3459, 1.4813, 1.2592, 1.6889, 1.3151, 1.9516, 1.3372, 1.2193, 1.8315,
         1.2579, 1.2897, 0.9151, 1.2418, 1.4243, 1.5177, 1.4789, 1.5188, 1.5188,
         1.3897, 1.1548, 1.4816, 1.4384, 1.1938, 1.4858, 1.4603, 1.4687, 1.4477,
         1.4822, 1.5696, 1.5513, 1.4939, 1.4221, 1.5335, 1.5441, 0.5541, 1.3921,
         0.9370, 1.4790, 1.4675, 1.4710, 1.1026, 1.4733, 0.6663, 1.4746, 1.4734],
        [1.3847, 1.3853, 1.4200, 1.3690, 1.2818, 1.3863, 1.2883, 1.3829, 1.3829,
         1.4073, 1.3810, 1.4230, 1.4088, 1.4044, 1.0742, 1.4114, 1.3600, 1.2890,
         1.5354, 1.5944, 1.6611, 1.5948, 1.4404, 1.4439, 1.5219, 1.4179, 1.4179,
         1.3023, 1.3047, 1.3727, 1.3778, 1.2904, 1.3775, 1.3756, 1.3731, 1.3737,
         1.4843, 1.4969, 1.4935, 1.4574, 1.4922, 1.4921, 1.4907, 1.1932, 1.2733,
         1.2732, 1.3816, 1.3813, 1.3683, 1.2062, 1.3772, 1.2378, 1.3698, 1.3699],
        [1.2674, 1.2764, 1.1460, 1.0784, 1.2600, 1.2536, 1.2617, 1.2666, 1.2666,
         1.3412, 1.2591, 1.2763, 1.2432, 1.3387, 1.2188, 1.3387, 1.3391, 0.9697,
         1.2923, 1.1062, 1.3088, 1.2855, 1.2607, 1.2442, 1.2839, 1.2803, 1.2803,
         1.6066, 1.4636, 1.4117, 1.4499, 1.5827, 1.4057, 1.5787, 1.4139, 1.4036,
         1.3771, 1.3412, 1.3296, 1.3488, 1.3717, 1.2707, 1.3536, 1.0020, 1.2786,
         1.3967, 1.2654, 1.1225, 1.3115, 1.3532, 1.1626, 1.4272, 1.3147, 1.3667],
        [1.5371, 1.3576, 0.5758, 0.7673, 1.2554, 1.4968, 1.4366, 1.5359, 1.5359,
         1.6021, 1.4592, 1.3593, 1.0846, 1.6453, 0.4316, 1.5033, 1.6449, 1.2905,
         1.2727, 0.9884, 0.9876, 1.1708, 1.4956, 1.5096, 1.2300, 1.5445, 1.5445,
         0.7865, 0.7869, 1.5013, 1.3613, 0.9156, 1.4944, 1.2023, 1.5012, 1.4848,
         1.1667, 0.9989, 0.9652, 1.1113, 1.3296, 1.3815, 1.1017, 1.9045, 1.8376,
         0.8855, 1.1200, 1.2306, 1.4766, 1.0248, 1.4397, 0.5511, 1.3979, 1.5264],
        [1.3867, 1.3811, 1.3350, 1.3745, 1.3036, 1.3454, 1.3474, 1.3857, 1.3857,
         1.3561, 1.3349, 1.3185, 1.3467, 1.4632, 1.1656, 1.3619, 1.4669, 1.3100,
         1.4023, 1.3291, 1.1627, 1.3136, 1.3927, 1.3928, 1.3611, 1.3971, 1.3971,
         1.3676, 1.2424, 1.4178, 1.2272, 1.2608, 1.2123, 1.3841, 1.3179, 1.4186,
         1.4823, 1.3025, 1.4917, 1.4651, 1.2057, 1.1216, 1.4888, 1.0769, 0.7016,
         1.7445, 1.4933, 1.5701, 1.5595, 1.5271, 1.2798, 1.7422, 1.5096, 1.2712]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 14 : 184.4602956761147
Test loss for epoch 14 : 184.27302777145866
Test Precision for epoch 14 : 0.26153846153846155
Test Recall for epoch 14 : 0.26153846153846155
Test F1 for epoch 14 : 0.26153846153846155


theta for epoch 15 : tensor([[1.4989, 1.5627, 1.6403, 1.6127, 1.6163, 1.5184, 1.5433, 1.4982, 1.4982,
         1.3745, 1.3786, 1.3924, 1.3758, 1.3693, 1.3624, 1.3783, 1.3741, 1.3336,
         1.3398, 1.3068, 1.3944, 1.3562, 1.3687, 1.3668, 1.3823, 1.3636, 1.3636,
         1.2495, 1.3625, 1.3271, 1.3365, 1.3357, 1.3335, 1.3207, 1.2929, 1.3284,
         1.4548, 1.4675, 1.4640, 1.4619, 1.4661, 1.4121, 1.4547, 1.4022, 1.3853,
         1.3675, 1.3655, 1.3694, 1.3599, 1.3733, 1.3604, 1.3004, 1.3635, 1.3618],
        [1.4576, 1.2019, 0.9963, 1.3598, 1.3926, 1.5125, 1.4331, 1.5104, 1.5104,
         1.3390, 1.4850, 1.2471, 1.7101, 1.3062, 1.9988, 1.3300, 1.2047, 1.8669,
         1.2508, 1.2867, 0.9154, 1.2370, 1.4216, 1.5198, 1.4799, 1.5207, 1.5207,
         1.3789, 1.1300, 1.4745, 1.4292, 1.1713, 1.4799, 1.4530, 1.4612, 1.4382,
         1.4781, 1.5733, 1.5530, 1.4910, 1.4144, 1.5346, 1.5452, 0.5389, 1.3841,
         0.9523, 1.5010, 1.4887, 1.4907, 1.1116, 1.4945, 0.6843, 1.4949, 1.4934],
        [1.3804, 1.3852, 1.4275, 1.3742, 1.2856, 1.3823, 1.2889, 1.3782, 1.3782,
         1.3995, 1.3736, 1.4176, 1.4043, 1.3958, 1.0775, 1.4042, 1.3502, 1.2822,
         1.5552, 1.6199, 1.6921, 1.6206, 1.4528, 1.4573, 1.5417, 1.4289, 1.4289,
         1.2884, 1.2925, 1.3594, 1.3662, 1.2768, 1.3654, 1.3635, 1.3604, 1.3606,
         1.4807, 1.4946, 1.4905, 1.4520, 1.4899, 1.4901, 1.4873, 1.1945, 1.2625,
         1.2913, 1.3998, 1.3994, 1.3844, 1.2238, 1.3948, 1.2606, 1.3864, 1.3862],
        [1.2648, 1.2755, 1.1449, 1.0758, 1.2588, 1.2510, 1.2600, 1.2638, 1.2638,
         1.3287, 1.2441, 1.2648, 1.2291, 1.3254, 1.2103, 1.3268, 1.3264, 0.9524,
         1.2937, 1.1057, 1.3131, 1.2878, 1.2597, 1.2419, 1.2847, 1.2796, 1.2796,
         1.6313, 1.4791, 1.4237, 1.4643, 1.6061, 1.4175, 1.6016, 1.4262, 1.4151,
         1.3759, 1.3381, 1.3252, 1.3457, 1.3710, 1.2643, 1.3507, 1.0000, 1.2746,
         1.4038, 1.2699, 1.1279, 1.3146, 1.3605, 1.1664, 1.4358, 1.3181, 1.3708],
        [1.5456, 1.3531, 0.5490, 0.7478, 1.2418, 1.5013, 1.4369, 1.5442, 1.5442,
         1.5901, 1.4397, 1.3378, 1.0631, 1.6356, 0.4045, 1.4867, 1.6353, 1.2668,
         1.2620, 0.9622, 0.9744, 1.1539, 1.4994, 1.5157, 1.2199, 1.5530, 1.5530,
         0.7526, 0.7540, 1.4996, 1.3483, 0.8888, 1.4927, 1.1765, 1.5003, 1.4820,
         1.1797, 0.9993, 0.9634, 1.1210, 1.3540, 1.4106, 1.1098, 1.9738, 1.9020,
         0.8811, 1.1225, 1.2388, 1.4981, 1.0172, 1.4589, 0.5322, 1.4153, 1.5514],
        [1.3967, 1.3935, 1.3543, 1.3900, 1.3149, 1.3540, 1.3568, 1.3953, 1.3953,
         1.3467, 1.3296, 1.3113, 1.3468, 1.4564, 1.1854, 1.3533, 1.4609, 1.3104,
         1.4158, 1.3445, 1.1812, 1.3267, 1.4044, 1.4038, 1.3713, 1.4078, 1.4078,
         1.3576, 1.2340, 1.4057, 1.2093, 1.2468, 1.1927, 1.3726, 1.3013, 1.4068,
         1.4862, 1.2938, 1.4962, 1.4690, 1.1927, 1.1044, 1.4927, 1.0934, 0.7051,
         1.7757, 1.5081, 1.5908, 1.5791, 1.5413, 1.2804, 1.7728, 1.5258, 1.2710]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 15 : 184.26259940071012
Test loss for epoch 15 : 184.09217173855993
Test Precision for epoch 15 : 0.26153846153846155
Test Recall for epoch 15 : 0.26153846153846155
Test F1 for epoch 15 : 0.26153846153846155


theta for epoch 16 : tensor([[1.5134, 1.5812, 1.6633, 1.6348, 1.6384, 1.5340, 1.5607, 1.5126, 1.5126,
         1.3670, 1.3724, 1.3871, 1.3709, 1.3609, 1.3639, 1.3714, 1.3664, 1.3295,
         1.3318, 1.3039, 1.3842, 1.3487, 1.3554, 1.3528, 1.3703, 1.3491, 1.3491,
         1.2425, 1.3602, 1.3181, 1.3298, 1.3327, 1.3261, 1.3134, 1.2829, 1.3197,
         1.4470, 1.4608, 1.4567, 1.4545, 1.4594, 1.4033, 1.4468, 1.3975, 1.3783,
         1.3914, 1.3870, 1.3908, 1.3790, 1.3972, 1.3815, 1.3274, 1.3831, 1.3811],
        [1.4382, 1.1810, 0.9906, 1.3404, 1.3730, 1.4956, 1.4129, 1.4931, 1.4931,
         1.3440, 1.5003, 1.2471, 1.7417, 1.3092, 2.0540, 1.3347, 1.2023, 1.9116,
         1.2297, 1.2695, 0.9008, 1.2181, 1.4046, 1.5072, 1.4662, 1.5079, 1.5079,
         1.3714, 1.1087, 1.4701, 1.4230, 1.1522, 1.4770, 1.4487, 1.4566, 1.4316,
         1.4673, 1.5703, 1.5479, 1.4814, 1.4001, 1.5291, 1.5394, 0.5167, 1.3694,
         0.9678, 1.5241, 1.5111, 1.5116, 1.1215, 1.5169, 0.7015, 1.5164, 1.5146],
        [1.3573, 1.3657, 1.4143, 1.3593, 1.2697, 1.3594, 1.2705, 1.3549, 1.3549,
         1.3906, 1.3651, 1.4109, 1.3983, 1.3861, 1.0800, 1.3959, 1.3394, 1.2746,
         1.5765, 1.6469, 1.7243, 1.6479, 1.4671, 1.4727, 1.5631, 1.4419, 1.4419,
         1.2806, 1.2867, 1.3511, 1.3601, 1.2694, 1.3586, 1.3567, 1.3530, 1.3526,
         1.4718, 1.4871, 1.4823, 1.4414, 1.4823, 1.4828, 1.4786, 1.1906, 1.2474,
         1.3120, 1.4206, 1.4202, 1.4029, 1.2442, 1.4151, 1.2862, 1.4054, 1.4049],
        [1.2655, 1.2781, 1.1491, 1.0792, 1.2613, 1.2520, 1.2619, 1.2643, 1.2643,
         1.3296, 1.2435, 1.2678, 1.2296, 1.3255, 1.2164, 1.3283, 1.3270, 0.9521,
         1.2992, 1.1119, 1.3214, 1.2943, 1.2631, 1.2442, 1.2896, 1.2829, 1.2829,
         1.6460, 1.4844, 1.4256, 1.4686, 1.6194, 1.4191, 1.6145, 1.4284, 1.4165,
         1.3780, 1.3390, 1.3248, 1.3464, 1.3740, 1.2625, 1.3514, 1.0038, 1.2753,
         1.4201, 1.2839, 1.1433, 1.3267, 1.3771, 1.1801, 1.4536, 1.3306, 1.3837],
        [1.5392, 1.3335, 0.5093, 0.7147, 1.2134, 1.4906, 1.4221, 1.5376, 1.5376,
         1.5714, 1.4134, 1.3097, 1.0335, 1.6193, 0.3684, 1.4636, 1.6191, 1.2363,
         1.2376, 0.9233, 0.9471, 1.1235, 1.4891, 1.5080, 1.1965, 1.5477, 1.5477,
         0.7155, 0.7179, 1.4970, 1.3341, 0.8589, 1.4901, 1.1489, 1.4987, 1.4782,
         1.2023, 1.0092, 0.9713, 1.1404, 1.3874, 1.4487, 1.1275, 2.0491, 1.9729,
         0.8697, 1.1213, 1.2440, 1.5173, 1.0047, 1.4757, 0.5056, 1.4302, 1.5742],
        [1.4015, 1.4009, 1.3695, 1.4008, 1.3222, 1.3580, 1.3614, 1.3999, 1.3999,
         1.3463, 1.3339, 1.3134, 1.3560, 1.4568, 1.2150, 1.3535, 1.4621, 1.3205,
         1.4253, 1.3571, 1.1982, 1.3368, 1.4121, 1.4108, 1.3778, 1.4146, 1.4146,
         1.3578, 1.2374, 1.4026, 1.2019, 1.2438, 1.1834, 1.3707, 1.2941, 1.4040,
         1.4893, 1.2857, 1.4999, 1.4724, 1.1810, 1.0896, 1.4958, 1.1118, 0.7137,
         1.8006, 1.5168, 1.6056, 1.5927, 1.5490, 1.2753, 1.7970, 1.5361, 1.2651]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 16 : 183.9854670443821
Test loss for epoch 16 : 183.84716492467356
Test Precision for epoch 16 : 0.26153846153846155
Test Recall for epoch 16 : 0.26153846153846155
Test F1 for epoch 16 : 0.26153846153846155


theta for epoch 17 : tensor([[1.5283, 1.5999, 1.6861, 1.6570, 1.6604, 1.5499, 1.5784, 1.5274, 1.5274,
         1.3623, 1.3690, 1.3845, 1.3687, 1.3554, 1.3679, 1.3672, 1.3614, 1.3283,
         1.3149, 1.2918, 1.3644, 1.3322, 1.3333, 1.3300, 1.3493, 1.3259, 1.3259,
         1.2470, 1.3687, 1.3193, 1.3334, 1.3407, 1.3290, 1.3166, 1.2832, 1.3212,
         1.4332, 1.4483, 1.4435, 1.4413, 1.4469, 1.3891, 1.4330, 1.3874, 1.3659,
         1.4109, 1.4039, 1.4076, 1.3934, 1.4167, 1.3980, 1.3503, 1.3980, 1.3957],
        [1.4131, 1.1552, 0.9791, 1.3157, 1.3481, 1.4729, 1.3871, 1.4700, 1.4700,
         1.3580, 1.5241, 1.2565, 1.7809, 1.3214, 2.1151, 1.3485, 1.2094, 1.9632,
         1.2004, 1.2439, 0.8772, 1.1911, 1.3790, 1.4855, 1.4435, 1.4859, 1.4859,
         1.3714, 1.0955, 1.4721, 1.4237, 1.1411, 1.4805, 1.4514, 1.4585, 1.4314,
         1.4488, 1.5593, 1.5350, 1.4640, 1.3784, 1.5159, 1.5258, 0.4876, 1.3473,
         0.9763, 1.5405, 1.5269, 1.5257, 1.1248, 1.5326, 0.7116, 1.5309, 1.5288],
        [1.3296, 1.3415, 1.3958, 1.3397, 1.2496, 1.3321, 1.2480, 1.3270, 1.3270,
         1.3835, 1.3586, 1.4059, 1.3940, 1.3782, 1.0852, 1.3893, 1.3306, 1.2692,
         1.5982, 1.6741, 1.7565, 1.6756, 1.4820, 1.4888, 1.5852, 1.4557, 1.4557,
         1.2829, 1.2911, 1.3516, 1.3630, 1.2723, 1.3607, 1.3591, 1.3544, 1.3534,
         1.4565, 1.4731, 1.4676, 1.4245, 1.4683, 1.4692, 1.4634, 1.1808, 1.2270,
         1.3279, 1.4362, 1.4358, 1.4162, 1.2601, 1.4303, 1.3073, 1.4193, 1.4184],
        [1.2696, 1.2841, 1.1579, 1.0878, 1.2675, 1.2565, 1.2673, 1.2681, 1.2681,
         1.3382, 1.2513, 1.2793, 1.2386, 1.3332, 1.2311, 1.3378, 1.3354, 0.9614,
         1.3051, 1.1204, 1.3301, 1.3014, 1.2671, 1.2470, 1.2950, 1.2865, 1.2865,
         1.6579, 1.4870, 1.4246, 1.4700, 1.6301, 1.4179, 1.6245, 1.4277, 1.4151,
         1.3779, 1.3379, 1.3223, 1.3449, 1.3750, 1.2594, 1.3499, 1.0075, 1.2750,
         1.4359, 1.2978, 1.1590, 1.3381, 1.3935, 1.1939, 1.4711, 1.3425, 1.3957],
        [1.5289, 1.3105, 0.4678, 0.6793, 1.1816, 1.4760, 1.4036, 1.5271, 1.5271,
         1.5531, 1.3876, 1.2827, 1.0039, 1.6034, 0.3321, 1.4413, 1.6032, 1.2071,
         1.2078, 0.8800, 0.9141, 1.0880, 1.4727, 1.4943, 1.1682, 1.5362, 1.5362,
         0.6830, 0.6865, 1.4991, 1.3250, 0.8337, 1.4924, 1.1262, 1.5020, 1.4793,
         1.2249, 1.0191, 0.9792, 1.1599, 1.4210, 1.4870, 1.1452, 2.1252, 2.0446,
         0.8503, 1.1136, 1.2422, 1.5290, 0.9852, 1.4852, 0.4727, 1.4378, 1.5896],
        [1.4056, 1.4078, 1.3849, 1.4115, 1.3299, 1.3617, 1.3657, 1.4038, 1.4038,
         1.3524, 1.3451, 1.3225, 1.3720, 1.4628, 1.2516, 1.3601, 1.4689, 1.3376,
         1.4309, 1.3666, 1.2130, 1.3440, 1.4160, 1.4140, 1.3806, 1.4173, 1.4173,
         1.3688, 1.2524, 1.4092, 1.2054, 1.2519, 1.1848, 1.3792, 1.2972, 1.4110,
         1.4869, 1.2729, 1.4981, 1.4704, 1.1652, 1.0714, 1.4933, 1.1267, 0.7205,
         1.8202, 1.5205, 1.6155, 1.6013, 1.5512, 1.2652, 1.8157, 1.5414, 1.2543]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 17 : 183.88563019189112
Test loss for epoch 17 : 183.78405283936468
Test Precision for epoch 17 : 0.26153846153846155
Test Recall for epoch 17 : 0.26153846153846155
Test F1 for epoch 17 : 0.26153846153846155


theta for epoch 18 : tensor([[1.5492, 1.6242, 1.7142, 1.6848, 1.6878, 1.5716, 1.6020, 1.5482, 1.5482,
         1.3557, 1.3639, 1.3802, 1.3649, 1.3481, 1.3703, 1.3614, 1.3546, 1.3257,
         1.3010, 1.2826, 1.3469, 1.3185, 1.3137, 1.3097, 1.3309, 1.3053, 1.3053,
         1.2620, 1.3869, 1.3299, 1.3465, 1.3585, 1.3412, 1.3296, 1.2932, 1.3321,
         1.4151, 1.4315, 1.4259, 1.4237, 1.4301, 1.3708, 1.4148, 1.3738, 1.3500,
         1.4154, 1.4059, 1.4095, 1.3929, 1.4212, 1.3996, 1.3584, 1.3980, 1.3953],
        [1.3946, 1.1373, 0.9743, 1.2983, 1.3304, 1.4562, 1.3679, 1.4529, 1.4529,
         1.3720, 1.5477, 1.2661, 1.8197, 1.3336, 2.1758, 1.3624, 1.2168, 2.0145,
         1.1752, 1.2224, 0.8570, 1.1683, 1.3567, 1.4663, 1.4237, 1.4663, 1.4663,
         1.3815, 1.0943, 1.4830, 1.4336, 1.1415, 1.4929, 1.4633, 1.4693, 1.4403,
         1.4264, 1.5444, 1.5180, 1.4428, 1.3533, 1.4989, 1.5081, 0.4573, 1.3221,
         0.9715, 1.5421, 1.5278, 1.5249, 1.1149, 1.5335, 0.7092, 1.5307, 1.5283],
        [1.3097, 1.3252, 1.3849, 1.3284, 1.2379, 1.3125, 1.2342, 1.3068, 1.3068,
         1.3748, 1.3509, 1.3993, 1.3883, 1.3687, 1.0907, 1.3811, 1.3207, 1.2629,
         1.6233, 1.7046, 1.7916, 1.7065, 1.5008, 1.5088, 1.6109, 1.4735, 1.4735,
         1.2955, 1.3057, 1.3612, 1.3751, 1.2855, 1.3718, 1.3707, 1.3649, 1.3633,
         1.4369, 1.4548, 1.4486, 1.4034, 1.4500, 1.4514, 1.4438, 1.1678, 1.2038,
         1.3293, 1.4371, 1.4367, 1.4148, 1.2620, 1.4307, 1.3141, 1.4184, 1.4172],
        [1.2772, 1.2939, 1.1709, 1.1009, 1.2775, 1.2647, 1.2764, 1.2755, 1.2755,
         1.3451, 1.2577, 1.2897, 1.2466, 1.3391, 1.2449, 1.3455, 1.3421, 0.9703,
         1.3123, 1.1312, 1.3401, 1.3100, 1.2724, 1.2511, 1.3017, 1.2912, 1.2912,
         1.6733, 1.4932, 1.4272, 1.4750, 1.6442, 1.4203, 1.6381, 1.4306, 1.4172,
         1.3736, 1.3330, 1.3159, 1.3394, 1.3720, 1.2529, 1.3444, 1.0084, 1.2713,
         1.4403, 1.3007, 1.1644, 1.3382, 1.3988, 1.1971, 1.4770, 1.3430, 1.3961],
        [1.5263, 1.2965, 0.4384, 0.6555, 1.1592, 1.4692, 1.3934, 1.5242, 1.5242,
         1.5384, 1.3665, 1.2618, 0.9802, 1.5905, 0.3038, 1.4237, 1.5905, 1.1843,
         1.1852, 0.8457, 0.8879, 1.0600, 1.4618, 1.4861, 1.1479, 1.5301, 1.5301,
         0.6641, 0.6687, 1.5106, 1.3267, 0.8215, 1.5043, 1.1156, 1.5149, 1.4900,
         1.2380, 1.0199, 0.9781, 1.1700, 1.4451, 1.5162, 1.1534, 2.1959, 2.1104,
         0.8227, 1.0968, 1.2297, 1.5277, 0.9574, 1.4822, 0.4363, 1.4333, 1.5919],
        [1.4115, 1.4166, 1.4025, 1.4241, 1.3399, 1.3674, 1.3717, 1.4094, 1.4094,
         1.3537, 1.3519, 1.3269, 1.3837, 1.4638, 1.2845, 1.3620, 1.4707, 1.3497,
         1.4356, 1.3759, 1.2280, 1.3509, 1.4189, 1.4161, 1.3824, 1.4190, 1.4190,
         1.3868, 1.2752, 1.4225, 1.2160, 1.2670, 1.1932, 1.3948, 1.3071, 1.4247,
         1.4780, 1.2536, 1.4897, 1.4621, 1.1433, 1.0472, 1.4842, 1.1358, 0.7211,
         1.8377, 1.5227, 1.6239, 1.6083, 1.5511, 1.2535, 1.8324, 1.5452, 1.2418]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 18 : 183.85965128758284
Test loss for epoch 18 : 183.7870110760897
Test Precision for epoch 18 : 0.26153846153846155
Test Recall for epoch 18 : 0.26153846153846155
Test F1 for epoch 18 : 0.26153846153846155


theta for epoch 19 : tensor([[1.5743, 1.6524, 1.7458, 1.7163, 1.7187, 1.5974, 1.6295, 1.5732, 1.5732,
         1.3436, 1.3532, 1.3704, 1.3560, 1.3352, 1.3678, 1.3500, 1.3423, 1.3176,
         1.2943, 1.2805, 1.3359, 1.3118, 1.3009, 1.2961, 1.3192, 1.2912, 1.2912,
         1.2829, 1.4101, 1.3455, 1.3647, 1.3815, 1.3583, 1.3479, 1.3084, 1.3482,
         1.3973, 1.4149, 1.4086, 1.4063, 1.4136, 1.3530, 1.3968, 1.3618, 1.3351,
         1.4078, 1.3960, 1.3992, 1.3803, 1.4136, 1.3892, 1.3546, 1.3860, 1.3830],
        [1.3843, 1.1298, 0.9790, 1.2906, 1.3221, 1.4474, 1.3574, 1.4436, 1.4436,
         1.3782, 1.5632, 1.2684, 1.8507, 1.3383, 2.2302, 1.3687, 1.2169, 2.0588,
         1.1598, 1.2106, 0.8459, 1.1554, 1.3427, 1.4543, 1.4118, 1.4540, 1.4540,
         1.3991, 1.1030, 1.5000, 1.4502, 1.1512, 1.5114, 1.4820, 1.4863, 1.4558,
         1.4058, 1.5308, 1.5024, 1.4234, 1.3308, 1.4837, 1.4917, 0.4327, 1.2997,
         0.9585, 1.5330, 1.5181, 1.5134, 1.0964, 1.5237, 0.6995, 1.5197, 1.5171],
        [1.2971, 1.3163, 1.3813, 1.3250, 1.2343, 1.3001, 1.2287, 1.2940, 1.2940,
         1.3610, 1.3384, 1.3878, 1.3779, 1.3540, 1.0935, 1.3680, 1.3059, 1.2522,
         1.6512, 1.7378, 1.8290, 1.7401, 1.5230, 1.5324, 1.6397, 1.4948, 1.4948,
         1.3139, 1.3260, 1.3755, 1.3919, 1.3046, 1.3876, 1.3874, 1.3801, 1.3780,
         1.4175, 1.4369, 1.4299, 1.3829, 1.4321, 1.4339, 1.4244, 1.1565, 1.1827,
         1.3192, 1.4262, 1.4257, 1.4016, 1.2528, 1.4192, 1.3096, 1.4058, 1.4042],
        [1.2841, 1.3030, 1.1836, 1.1137, 1.2870, 1.2722, 1.2848, 1.2821, 1.2821,
         1.3428, 1.2552, 1.2917, 1.2462, 1.3360, 1.2505, 1.3443, 1.3397, 0.9715,
         1.3191, 1.1419, 1.3495, 1.3181, 1.2770, 1.2544, 1.3080, 1.2951, 1.2951,
         1.6947, 1.5057, 1.4359, 1.4862, 1.6644, 1.4288, 1.6576, 1.4397, 1.4255,
         1.3671, 1.3260, 1.3073, 1.3317, 1.3670, 1.2445, 1.3366, 1.0075, 1.2660,
         1.4331, 1.2925, 1.1590, 1.3269, 1.3927, 1.1893, 1.4713, 1.3322, 1.3851],
        [1.5339, 1.2952, 0.4274, 0.6487, 1.1505, 1.4730, 1.3949, 1.5316, 1.5316,
         1.5274, 1.3508, 1.2484, 0.9647, 1.5809, 0.2883, 1.4115, 1.5811, 1.1697,
         1.1763, 0.8280, 0.8751, 1.0465, 1.4615, 1.4886, 1.1417, 1.5339, 1.5339,
         0.6613, 0.6672, 1.5312, 1.3392, 0.8240, 1.5253, 1.1180, 1.5369, 1.5100,
         1.2373, 1.0076, 0.9641, 1.1666, 1.4551, 1.5314, 1.1481, 2.2574, 2.1660,
         0.7970, 1.0802, 1.2149, 1.5203, 0.9310, 1.4737, 0.4081, 1.4241, 1.5878],
        [1.4130, 1.4212, 1.4160, 1.4327, 1.3460, 1.3689, 1.3733, 1.4107, 1.4107,
         1.3391, 1.3427, 1.3150, 1.3796, 1.4495, 1.3013, 1.3480, 1.4570, 1.3449,
         1.4365, 1.3818, 1.2396, 1.3544, 1.4180, 1.4144, 1.3805, 1.4168, 1.4168,
         1.4040, 1.2975, 1.4348, 1.2256, 1.2809, 1.2001, 1.4096, 1.3158, 1.4374,
         1.4646, 1.2293, 1.4769, 1.4494, 1.1163, 1.0179, 1.4707, 1.1401, 0.7146,
         1.8624, 1.5332, 1.6406, 1.6235, 1.5587, 1.2503, 1.8562, 1.5574, 1.2377]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 19 : 183.79006001908124
Test loss for epoch 19 : 183.7286849043978
Test Precision for epoch 19 : 0.26153846153846155
Test Recall for epoch 19 : 0.26153846153846155
Test F1 for epoch 19 : 0.26153846153846155


theta for epoch 20 : tensor([[1.5947, 1.6757, 1.7724, 1.7431, 1.7447, 1.6183, 1.6523, 1.5935, 1.5935,
         1.3329, 1.3441, 1.3622, 1.3489, 1.3238, 1.3672, 1.3401, 1.3314, 1.3113,
         1.2947, 1.2855, 1.3316, 1.3121, 1.2945, 1.2889, 1.3143, 1.2836, 1.2836,
         1.2970, 1.4256, 1.3535, 1.3751, 1.3969, 1.3676, 1.3588, 1.3160, 1.3566,
         1.3857, 1.4046, 1.3975, 1.3953, 1.4035, 1.3418, 1.3851, 1.3575, 1.3274,
         1.3986, 1.3845, 1.3874, 1.3663, 1.4045, 1.3772, 1.3494, 1.3725, 1.3693],
        [1.3759, 1.1262, 0.9873, 1.2862, 1.3166, 1.4398, 1.3489, 1.4355, 1.4355,
         1.3786, 1.5725, 1.2652, 1.8756, 1.3372, 2.2794, 1.3692, 1.2117, 2.0976,
         1.1516, 1.2060, 0.8418, 1.1499, 1.3346, 1.4470, 1.4054, 1.4463, 1.4463,
         1.4106, 1.1077, 1.5100, 1.4601, 1.1564, 1.5226, 1.4940, 1.4962, 1.4644,
         1.3921, 1.5236, 1.4931, 1.4108, 1.3157, 1.4752, 1.4817, 0.4188, 1.2854,
         0.9466, 1.5227, 1.5072, 1.5008, 1.0789, 1.5126, 0.6915, 1.5076, 1.5047],
        [1.2859, 1.3092, 1.3794, 1.3238, 1.2331, 1.2893, 1.2256, 1.2826, 1.2826,
         1.3486, 1.3277, 1.3779, 1.3692, 1.3408, 1.1000, 1.3563, 1.2930, 1.2437,
         1.6762, 1.7680, 1.8632, 1.7708, 1.5427, 1.5535, 1.6659, 1.5137, 1.5137,
         1.3257, 1.3394, 1.3822, 1.4011, 1.3170, 1.3955, 1.3966, 1.3877, 1.3851,
         1.4044, 1.4251, 1.4173, 1.3688, 1.4206, 1.4228, 1.4112, 1.1533, 1.1700,
         1.3079, 1.4137, 1.4130, 1.3869, 1.2429, 1.4062, 1.3040, 1.3917, 1.3898],
        [1.2850, 1.3063, 1.1907, 1.1214, 1.2908, 1.2738, 1.2874, 1.2828, 1.2828,
         1.3355, 1.2477, 1.2888, 1.2411, 1.3278, 1.2513, 1.3380, 1.3322, 0.9679,
         1.3227, 1.1500, 1.3559, 1.3232, 1.2786, 1.2545, 1.3112, 1.2957, 1.2957,
         1.7192, 1.5216, 1.4479, 1.5006, 1.6878, 1.4407, 1.6804, 1.4521, 1.4372,
         1.3621, 1.3204, 1.3001, 1.3254, 1.3634, 1.2378, 1.3303, 1.0078, 1.2625,
         1.4214, 1.2800, 1.1493, 1.3113, 1.3822, 1.1772, 1.4608, 1.3171, 1.3697],
        [1.5456, 1.3002, 0.4279, 0.6521, 1.1490, 1.4811, 1.4016, 1.5431, 1.5431,
         1.5228, 1.3429, 1.2444, 0.9588, 1.5771, 0.2847, 1.4072, 1.5775, 1.1647,
         1.1768, 0.8221, 0.8718, 1.0431, 1.4682, 1.4979, 1.1456, 1.5443, 1.5443,
         0.6636, 0.6708, 1.5500, 1.3515, 0.8302, 1.5447, 1.1220, 1.5572, 1.5286,
         1.2274, 0.9869, 0.9418, 1.1542, 1.4556, 1.5372, 1.1338, 2.3128, 2.2150,
         0.7824, 1.0735, 1.2077, 1.5164, 0.9157, 1.4695, 0.3960, 1.4200, 1.5869],
        [1.4035, 1.4147, 1.4184, 1.4302, 1.3412, 1.3594, 1.3636, 1.4009, 1.4009,
         1.3134, 1.3224, 1.2917, 1.3643, 1.4246, 1.3063, 1.3230, 1.4329, 1.3280,
         1.4305, 1.3809, 1.2443, 1.3512, 1.4101, 1.4056, 1.3714, 1.4076, 1.4076,
         1.4065, 1.3056, 1.4327, 1.2206, 1.2798, 1.1922, 1.4100, 1.3097, 1.4357,
         1.4511, 1.2042, 1.4640, 1.4367, 1.0883, 0.9872, 1.4570, 1.1437, 0.7048,
         1.8998, 1.5585, 1.6715, 1.6530, 1.5807, 1.2625, 1.8927, 1.5843, 1.2492]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 20 : 183.75303920389422
Test loss for epoch 20 : 183.68785310850438
Test Precision for epoch 20 : 0.26153846153846155
Test Recall for epoch 20 : 0.26153846153846155
Test F1 for epoch 20 : 0.26153846153846155


theta for epoch 21 : tensor([[1.6060, 1.6897, 1.7894, 1.7605, 1.7612, 1.6301, 1.6660, 1.6047, 1.6047,
         1.3323, 1.3451, 1.3641, 1.3521, 1.3226, 1.3766, 1.3404, 1.3308, 1.3152,
         1.3011, 1.2965, 1.3332, 1.3183, 1.2940, 1.2874, 1.3151, 1.2816, 1.2816,
         1.2922, 1.4215, 1.3427, 1.3665, 1.3928, 1.3579, 1.3508, 1.3050, 1.3461,
         1.3844, 1.4045, 1.3965, 1.3944, 1.4036, 1.3413, 1.3835, 1.3642, 1.3308,
         1.3938, 1.3774, 1.3799, 1.3567, 1.3997, 1.3696, 1.3489, 1.3633, 1.3600],
        [1.3666, 1.1235, 0.9959, 1.2820, 1.3110, 1.4310, 1.3398, 1.4261, 1.4261,
         1.3786, 1.5811, 1.2619, 1.8994, 1.3359, 2.3278, 1.3694, 1.2067, 2.1356,
         1.1471, 1.2051, 0.8412, 1.1482, 1.3292, 1.4415, 1.4014, 1.4403, 1.4403,
         1.4029, 1.0954, 1.5007, 1.4509, 1.1441, 1.5143, 1.4868, 1.4867, 1.4541,
         1.3881, 1.5254, 1.4929, 1.4078, 1.3110, 1.4761, 1.4807, 0.4167, 1.2815,
         0.9397, 1.5156, 1.4996, 1.4913, 1.0665, 1.5047, 0.6887, 1.4987, 1.4956],
        [1.2778, 1.3051, 1.3804, 1.3261, 1.2356, 1.2815, 1.2264, 1.2742, 1.2742,
         1.3466, 1.3277, 1.3783, 1.3710, 1.3381, 1.1181, 1.3550, 1.2911, 1.2465,
         1.6923, 1.7892, 1.8883, 1.7924, 1.5537, 1.5660, 1.6833, 1.5241, 1.5241,
         1.3199, 1.3351, 1.3710, 1.3922, 1.3119, 1.3854, 1.3878, 1.3772, 1.3743,
         1.4021, 1.4240, 1.4154, 1.3658, 1.4198, 1.4224, 1.4086, 1.1622, 1.1703,
         1.3021, 1.4060, 1.4050, 1.3769, 1.2388, 1.3979, 1.3039, 1.3823, 1.3802],
        [1.2798, 1.3036, 1.1922, 1.1237, 1.2886, 1.2694, 1.2839, 1.2773, 1.2773,
         1.3300, 1.2420, 1.2880, 1.2380, 1.3215, 1.2537, 1.3337, 1.3267, 0.9657,
         1.3227, 1.1548, 1.3584, 1.3246, 1.2763, 1.2507, 1.3106, 1.2924, 1.2924,
         1.7431, 1.5367, 1.4592, 1.5143, 1.7106, 1.4517, 1.7024, 1.4637, 1.4480,
         1.3614, 1.3192, 1.2973, 1.3235, 1.3643, 1.2358, 1.3284, 1.0119, 1.2636,
         1.4097, 1.2677, 1.1394, 1.2957, 1.3718, 1.1651, 1.4502, 1.3020, 1.3545],
        [1.5560, 1.3049, 0.4313, 0.6574, 1.1474, 1.4878, 1.4074, 1.5532, 1.5532,
         1.5255, 1.3429, 1.2489, 0.9602, 1.5803, 0.2880, 1.4108, 1.5811, 1.1683,
         1.1796, 0.8197, 0.8702, 1.0423, 1.4758, 1.5081, 1.1519, 1.5553, 1.5553,
         0.6568, 0.6654, 1.5542, 1.3499, 0.8262, 1.5494, 1.1136, 1.5629, 1.5328,
         1.2171, 0.9661, 0.9195, 1.1415, 1.4555, 1.5426, 1.1192, 2.3690, 2.2646,
         0.7752, 1.0747, 1.2071, 1.5168, 0.9087, 1.4701, 0.3934, 1.4213, 1.5902],
        [1.3854, 1.3997, 1.4122, 1.4192, 1.3281, 1.3415, 1.3455, 1.3826, 1.3826,
         1.2885, 1.3031, 1.2690, 1.3502, 1.4008, 1.3118, 1.2988, 1.4098, 1.3115,
         1.4192, 1.3749, 1.2441, 1.3430, 1.3968, 1.3914, 1.3569, 1.3929, 1.3929,
         1.3883, 1.2929, 1.4101, 1.1956, 1.2583, 1.1647, 1.3898, 1.2836, 1.4134,
         1.4430, 1.1842, 1.4563, 1.4295, 1.0656, 0.9618, 1.4486, 1.1527, 0.6991,
         1.9461, 1.5944, 1.7126, 1.6928, 1.6131, 1.2863, 1.9382, 1.6217, 1.2722]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 21 : 183.5979385055109
Test loss for epoch 21 : 183.52530509795724
Test Precision for epoch 21 : 0.26153846153846155
Test Recall for epoch 21 : 0.26153846153846155
Test F1 for epoch 21 : 0.26153846153846155


theta for epoch 22 : tensor([[1.6105, 1.6967, 1.7992, 1.7709, 1.7706, 1.6350, 1.6728, 1.6091, 1.6091,
         1.3392, 1.3534, 1.3732, 1.3625, 1.3289, 1.3927, 1.3481, 1.3376, 1.3264,
         1.3056, 1.3052, 1.3331, 1.3226, 1.2917, 1.2841, 1.3140, 1.2780, 1.2780,
         1.2773, 1.4066, 1.3219, 1.3476, 1.3781, 1.3380, 1.3326, 1.2841, 1.3256,
         1.3925, 1.4139, 1.4050, 1.4030, 1.4132, 1.3506, 1.3915, 1.3806, 1.3443,
         1.3905, 1.3717, 1.3735, 1.3483, 1.3964, 1.3632, 1.3501, 1.3555, 1.3520],
        [1.3557, 1.1204, 1.0032, 1.2768, 1.3044, 1.4202, 1.3293, 1.4147, 1.4147,
         1.3785, 1.5891, 1.2588, 1.9225, 1.3346, 2.3756, 1.3696, 1.2019, 2.1730,
         1.1418, 1.2029, 0.8398, 1.1456, 1.3220, 1.4334, 1.3951, 1.4317, 1.4317,
         1.3848, 1.0742, 1.4809, 1.4312, 1.1226, 1.4954, 1.4689, 1.4666, 1.4333,
         1.3933, 1.5359, 1.5013, 1.4140, 1.3161, 1.4860, 1.4885, 0.4256, 1.2877,
         0.9347, 1.5090, 1.4923, 1.4823, 1.0561, 1.4973, 0.6881, 1.4902, 1.4869],
        [1.2723, 1.3034, 1.3828, 1.3304, 1.2408, 1.2762, 1.2302, 1.2684, 1.2684,
         1.3533, 1.3367, 1.3872, 1.3812, 1.3441, 1.1451, 1.3625, 1.2984, 1.2583,
         1.6976, 1.7996, 1.9025, 1.8034, 1.5545, 1.5683, 1.6902, 1.5243, 1.5243,
         1.3056, 1.3220, 1.3511, 1.3742, 1.2984, 1.3664, 1.3701, 1.3579, 1.3547,
         1.4102, 1.4334, 1.4239, 1.3736, 1.4295, 1.4325, 1.4164, 1.1822, 1.1831,
         1.2991, 1.4004, 1.3991, 1.3692, 1.2380, 1.3917, 1.3068, 1.3751, 1.3728],
        [1.2684, 1.2946, 1.1876, 1.1201, 1.2802, 1.2588, 1.2742, 1.2657, 1.2657,
         1.3253, 1.2368, 1.2879, 1.2354, 1.3159, 1.2562, 1.3301, 1.3219, 0.9636,
         1.3157, 1.1531, 1.3539, 1.3190, 1.2672, 1.2400, 1.3031, 1.2822, 1.2822,
         1.7680, 1.5531, 1.4716, 1.5291, 1.7345, 1.4640, 1.7256, 1.4765, 1.4601,
         1.3650, 1.3225, 1.2990, 1.3259, 1.3695, 1.2386, 1.3310, 1.0196, 1.2692,
         1.3962, 1.2536, 1.1278, 1.2784, 1.3598, 1.1511, 1.4378, 1.2852, 1.3375],
        [1.5612, 1.3048, 0.4311, 0.6587, 1.1410, 1.4892, 1.4082, 1.5581, 1.5581,
         1.5302, 1.3446, 1.2555, 0.9621, 1.5856, 0.2905, 1.4166, 1.5866, 1.1737,
         1.1776, 0.8128, 0.8632, 1.0365, 1.4780, 1.5131, 1.1538, 1.5610, 1.5610,
         0.6412, 0.6514, 1.5476, 1.3379, 0.8129, 1.5434, 1.0952, 1.5579, 1.5262,
         1.2126, 0.9511, 0.9031, 1.1347, 1.4610, 1.5537, 1.1103, 2.4302, 2.3194,
         0.7649, 1.0738, 1.2041, 1.5145, 0.8994, 1.4679, 0.3882, 1.4201, 1.5908],
        [1.3648, 1.3821, 1.4035, 1.4056, 1.3131, 1.3214, 1.3249, 1.3617, 1.3617,
         1.2714, 1.2918, 1.2541, 1.3438, 1.3842, 1.3241, 1.2824, 1.3938, 1.3022,
         1.4049, 1.3665, 1.2422, 1.3325, 1.3805, 1.3742, 1.3396, 1.3752, 1.3752,
         1.3614, 1.2722, 1.3790, 1.1631, 1.2287, 1.1296, 1.3612, 1.2496, 1.3826,
         1.4444, 1.1751, 1.4581, 1.4319, 1.0545, 0.9486, 1.4495, 1.1721, 0.7056,
         1.9908, 1.6293, 1.7527, 1.7315, 1.6438, 1.3092, 1.9820, 1.6582, 1.2945]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 22 : 183.45758460678385
Test loss for epoch 22 : 183.38291222402808
Test Precision for epoch 22 : 0.26153846153846155
Test Recall for epoch 22 : 0.26153846153846155
Test F1 for epoch 22 : 0.26153846153846155


theta for epoch 23 : tensor([[1.6159, 1.7042, 1.8091, 1.7817, 1.7804, 1.6406, 1.6803, 1.6143, 1.6143,
         1.3429, 1.3583, 1.3789, 1.3693, 1.3320, 1.4049, 1.3526, 1.3413, 1.3340,
         1.3055, 1.3084, 1.3282, 1.3220, 1.2853, 1.2767, 1.3086, 1.2704, 1.2704,
         1.2635, 1.3923, 1.3022, 1.3297, 1.3641, 1.3192, 1.3155, 1.2644, 1.3062,
         1.4053, 1.4279, 1.4182, 1.4162, 1.4274, 1.3649, 1.4041, 1.4016, 1.3627,
         1.3834, 1.3619, 1.3631, 1.3359, 1.3892, 1.3528, 1.3476, 1.3436, 1.3399],
        [1.3460, 1.1195, 1.0109, 1.2729, 1.2991, 1.4102, 1.3201, 1.4041, 1.4041,
         1.3741, 1.5925, 1.2519, 1.9408, 1.3292, 2.4194, 1.3657, 1.1935, 2.2062,
         1.1368, 1.2006, 0.8387, 1.1433, 1.3144, 1.4240, 1.3878, 1.4219, 1.4219,
         1.3688, 1.0568, 1.4628, 1.4136, 1.1047, 1.4783, 1.4530, 1.4484, 1.4145,
         1.4045, 1.5519, 1.5152, 1.4259, 1.3279, 1.5017, 1.5018, 0.4419, 1.3006,
         0.9276, 1.4989, 1.4817, 1.4697, 1.0439, 1.4863, 0.6856, 1.4782, 1.4747],
        [1.2677, 1.3020, 1.3845, 1.3343, 1.2463, 1.2718, 1.2350, 1.2636, 1.2636,
         1.3583, 1.3440, 1.3941, 1.3893, 1.3484, 1.1705, 1.3681, 1.3042, 1.2684,
         1.6997, 1.8066, 1.9131, 1.8110, 1.5525, 1.5679, 1.6941, 1.5219, 1.5219,
         1.2935, 1.3111, 1.3331, 1.3582, 1.2872, 1.3493, 1.3542, 1.3405, 1.3369,
         1.4237, 1.4482, 1.4378, 1.3870, 1.4446, 1.4480, 1.4295, 1.2078, 1.2027,
         1.2933, 1.3915, 1.3898, 1.3580, 1.2346, 1.3820, 1.3072, 1.3645, 1.3619],
        [1.2528, 1.2811, 1.1784, 1.1123, 1.2674, 1.2440, 1.2601, 1.2498, 1.2498,
         1.3146, 1.2258, 1.2818, 1.2269, 1.3044, 1.2523, 1.3204, 1.3112, 0.9559,
         1.3026, 1.1457, 1.3430, 1.3073, 1.2522, 1.2234, 1.2895, 1.2660, 1.2660,
         1.7970, 1.5738, 1.4883, 1.5483, 1.7625, 1.4806, 1.7529, 1.4936, 1.4765,
         1.3704, 1.3277, 1.3025, 1.3301, 1.3766, 1.2435, 1.3353, 1.0285, 1.2769,
         1.3783, 1.2350, 1.1115, 1.2565, 1.3434, 1.1326, 1.4211, 1.2638, 1.3160],
        [1.5621, 1.3003, 0.4267, 0.6556, 1.1301, 1.4861, 1.4046, 1.5587, 1.5587,
         1.5291, 1.3404, 1.2567, 0.9577, 1.5850, 0.2862, 1.4170, 1.5863, 1.1732,
         1.1704, 0.8008, 0.8502, 1.0256, 1.4748, 1.5128, 1.1509, 1.5615, 1.5615,
         0.6236, 0.6356, 1.5393, 1.3243, 0.7977, 1.5357, 1.0752, 1.5513, 1.5180,
         1.2140, 0.9423, 0.8929, 1.1341, 1.4725, 1.5708, 1.1076, 2.4961, 2.3793,
         0.7449, 1.0639, 1.1921, 1.5037, 0.8812, 1.4571, 0.3736, 1.4105, 1.5831],
        [1.3500, 1.3703, 1.4005, 1.3977, 1.3048, 1.3078, 1.3106, 1.3467, 1.3467,
         1.2609, 1.2869, 1.2460, 1.3431, 1.3726, 1.3415, 1.2723, 1.3829, 1.2986,
         1.3942, 1.3623, 1.2456, 1.3267, 1.3680, 1.3607, 1.3265, 1.3612, 1.3612,
         1.3411, 1.2591, 1.3541, 1.1385, 1.2066, 1.1028, 1.3391, 1.2227, 1.3580,
         1.4552, 1.1781, 1.4692, 1.4441, 1.0569, 0.9499, 1.4599, 1.2026, 0.7268,
         2.0211, 1.6500, 1.7787, 1.7560, 1.6598, 1.3185, 2.0112, 1.6806, 1.3032]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 23 : 183.3884058832684
Test loss for epoch 23 : 183.32090994852956
Test Precision for epoch 23 : 0.26153846153846155
Test Recall for epoch 23 : 0.26153846153846155
Test F1 for epoch 23 : 0.26153846153846155


theta for epoch 24 : tensor([[1.6282, 1.7182, 1.8250, 1.7987, 1.7963, 1.6529, 1.6945, 1.6265, 1.6265,
         1.3367, 1.3530, 1.3743, 1.3657, 1.3252, 1.4060, 1.3470, 1.3349, 1.3308,
         1.3053, 1.3105, 1.3230, 1.3213, 1.2795, 1.2702, 1.3035, 1.2636, 1.2636,
         1.2556, 1.3835, 1.2883, 1.3177, 1.3557, 1.3063, 1.3042, 1.2508, 1.2927,
         1.4123, 1.4363, 1.4255, 1.4236, 1.4360, 1.3736, 1.4109, 1.4167, 1.3757,
         1.3746, 1.3502, 1.3507, 1.3215, 1.3802, 1.3403, 1.3435, 1.3297, 1.3258],
        [1.3399, 1.1225, 1.0205, 1.2721, 1.2975, 1.4034, 1.3145, 1.3968, 1.3968,
         1.3653, 1.5910, 1.2408, 1.9540, 1.3194, 2.4590, 1.3574, 1.1811, 2.2350,
         1.1364, 1.2023, 0.8412, 1.1454, 1.3110, 1.4182, 1.3841, 1.4157, 1.4157,
         1.3602, 1.0484, 1.4517, 1.4033, 1.0955, 1.4681, 1.4441, 1.4371, 1.4030,
         1.4114, 1.5634, 1.5244, 1.4336, 1.3361, 1.5132, 1.5103, 0.4562, 1.3100,
         0.9208, 1.4882, 1.4704, 1.4563, 1.0321, 1.4745, 0.6836, 1.4654, 1.4617],
        [1.2623, 1.2993, 1.3836, 1.3361, 1.2499, 1.2666, 1.2385, 1.2581, 1.2581,
         1.3533, 1.3412, 1.3909, 1.3870, 1.3427, 1.1858, 1.3636, 1.3002, 1.2682,
         1.7088, 1.8203, 1.9300, 1.8253, 1.5582, 1.5753, 1.7052, 1.5274, 1.5274,
         1.2869, 1.3054, 1.3202, 1.3473, 1.2815, 1.3374, 1.3435, 1.3284, 1.3244,
         1.4310, 1.4569, 1.4455, 1.3943, 1.4537, 1.4575, 1.4365, 1.2273, 1.2172,
         1.2854, 1.3803, 1.3782, 1.3444, 1.2292, 1.3700, 1.3055, 1.3516, 1.3488],
        [1.2371, 1.2674, 1.1688, 1.1042, 1.2544, 1.2292, 1.2459, 1.2339, 1.2339,
         1.2959, 1.2068, 1.2678, 1.2105, 1.2849, 1.2400, 1.3027, 1.2924, 0.9412,
         1.2897, 1.1387, 1.3321, 1.2957, 1.2377, 1.2073, 1.2762, 1.2503, 1.2503,
         1.8293, 1.5981, 1.5087, 1.5711, 1.7939, 1.5009, 1.7836, 1.5144, 1.4966,
         1.3710, 1.3285, 1.3015, 1.3296, 1.3792, 1.2444, 1.3350, 1.0331, 1.2804,
         1.3596, 1.2153, 1.0940, 1.2334, 1.3261, 1.1128, 1.4035, 1.2412, 1.2932],
        [1.5627, 1.2957, 0.4226, 0.6525, 1.1192, 1.4826, 1.4007, 1.5591, 1.5591,
         1.5203, 1.3287, 1.2511, 0.9463, 1.5765, 0.2759, 1.4103, 1.5782, 1.1657,
         1.1641, 0.7898, 0.8369, 1.0153, 1.4719, 1.5129, 1.1490, 1.5623, 1.5623,
         0.6102, 0.6242, 1.5349, 1.3151, 0.7865, 1.5321, 1.0597, 1.5487, 1.5137,
         1.2149, 0.9333, 0.8824, 1.1329, 1.4833, 1.5875, 1.1043, 2.5627, 2.4398,
         0.7220, 1.0514, 1.1775, 1.4898, 0.8607, 1.4434, 0.3566, 1.3981, 1.5723],
        [1.3451, 1.3683, 1.4067, 1.3992, 1.3072, 1.3048, 1.3067, 1.3416, 1.3416,
         1.2527, 1.2840, 1.2405, 1.3438, 1.3619, 1.3594, 1.2646, 1.3727, 1.2963,
         1.3932, 1.3682, 1.2598, 1.3314, 1.3653, 1.3571, 1.3236, 1.3570, 1.3570,
         1.3332, 1.2594, 1.3412, 1.1279, 1.1978, 1.0900, 1.3294, 1.2088, 1.3455,
         1.4653, 1.1832, 1.4798, 1.4558, 1.0625, 0.9556, 1.4695, 1.2346, 0.7533,
         2.0369, 1.6567, 1.7907, 1.7664, 1.6614, 1.3143, 2.0260, 1.6891, 1.2984]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 24 : 183.3797577299464
Test loss for epoch 24 : 183.3225427072351
Test Precision for epoch 24 : 0.26153846153846155
Test Recall for epoch 24 : 0.26153846153846155
Test F1 for epoch 24 : 0.26153846153846155


theta for epoch 25 : tensor([[1.6467, 1.7381, 1.8464, 1.8215, 1.8180, 1.6715, 1.7148, 1.6449, 1.6449,
         1.3279, 1.3450, 1.3669, 1.3593, 1.3159, 1.4035, 1.3387, 1.3260, 1.3246,
         1.3075, 1.3143, 1.3200, 1.3229, 1.2771, 1.2671, 1.3014, 1.2605, 1.2605,
         1.2547, 1.3812, 1.2812, 1.3124, 1.3539, 1.3001, 1.2997, 1.2439, 1.2859,
         1.4021, 1.4275, 1.4157, 1.4137, 1.4274, 1.3652, 1.4005, 1.4142, 1.3712,
         1.3701, 1.3428, 1.3426, 1.3113, 1.3755, 1.3321, 1.3439, 1.3200, 1.3159],
        [1.3347, 1.1261, 1.0286, 1.2716, 1.2966, 1.3973, 1.3096, 1.3903, 1.3903,
         1.3612, 1.5938, 1.2347, 1.9711, 1.3146, 2.5017, 1.3540, 1.1739, 2.2674,
         1.1385, 1.2060, 0.8450, 1.1499, 1.3105, 1.4148, 1.3827, 1.4120, 1.4120,
         1.3577, 1.0469, 1.4462, 1.3990, 1.0930, 1.4637, 1.4412, 1.4315, 1.3972,
         1.4007, 1.5571, 1.5159, 1.4236, 1.3271, 1.5069, 1.5011, 0.4541, 1.3022,
         0.9183, 1.4818, 1.4634, 1.4471, 1.0252, 1.4670, 0.6852, 1.4568, 1.4528],
        [1.2552, 1.2941, 1.3793, 1.3348, 1.2504, 1.2597, 1.2396, 1.2509, 1.2509,
         1.3444, 1.3345, 1.3834, 1.3804, 1.3332, 1.1962, 1.3552, 1.2924, 1.2634,
         1.7275, 1.8432, 1.9556, 1.8488, 1.5741, 1.5928, 1.7261, 1.5431, 1.5431,
         1.2859, 1.3051, 1.3125, 1.3416, 1.2814, 1.3306, 1.3379, 1.3213, 1.3170,
         1.4203, 1.4477, 1.4352, 1.3837, 1.4447, 1.4488, 1.4254, 1.2283, 1.2140,
         1.2808, 1.3723, 1.3697, 1.3341, 1.2271, 1.3612, 1.3071, 1.3419, 1.3387],
        [1.2256, 1.2576, 1.1631, 1.1005, 1.2455, 1.2186, 1.2358, 1.2221, 1.2221,
         1.2791, 1.1902, 1.2558, 1.1964, 1.2674, 1.2293, 1.2868, 1.2755, 0.9294,
         1.2823, 1.1376, 1.3263, 1.2896, 1.2292, 1.1973, 1.2686, 1.2405, 1.2405,
         1.8611, 1.6222, 1.5289, 1.5936, 1.8250, 1.5211, 1.8139, 1.5350, 1.5165,
         1.3593, 1.3175, 1.2886, 1.3170, 1.3696, 1.2339, 1.3226, 1.0273, 1.2721,
         1.3468, 1.2016, 1.0824, 1.2160, 1.3148, 1.0989, 1.3919, 1.2244, 1.2761],
        [1.5656, 1.2941, 0.4226, 0.6533, 1.1119, 1.4817, 1.3996, 1.5618, 1.5618,
         1.5129, 1.3186, 1.2478, 0.9368, 1.5693, 0.2672, 1.4055, 1.5712, 1.1604,
         1.1624, 0.7842, 0.8272, 1.0098, 1.4728, 1.5170, 1.1522, 1.5668, 1.5668,
         0.6042, 0.6202, 1.5363, 1.3126, 0.7825, 1.5345, 1.0517, 1.5522, 1.5155,
         1.2068, 0.9158, 0.8637, 1.1230, 1.4851, 1.5952, 1.0922, 2.6242, 2.4945,
         0.7083, 1.0483, 1.1716, 1.4828, 0.8500, 1.4369, 0.3491, 1.3933, 1.5682],
        [1.3463, 1.3721, 1.4183, 1.4063, 1.3160, 1.3083, 1.3091, 1.3426, 1.3426,
         1.2504, 1.2867, 1.2408, 1.3493, 1.3561, 1.3807, 1.2625, 1.3674, 1.2987,
         1.3991, 1.3812, 1.2814, 1.3436, 1.3698, 1.3608, 1.3282, 1.3602, 1.3602,
         1.3350, 1.2699, 1.3376, 1.1277, 1.1990, 1.0875, 1.3293, 1.2048, 1.3422,
         1.4589, 1.1735, 1.4738, 1.4510, 1.0540, 0.9482, 1.4627, 1.2504, 0.7665,
         2.0483, 1.6596, 1.7990, 1.7730, 1.6587, 1.3068, 2.0362, 1.6939, 1.2905]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 25 : 183.30068248497648
Test loss for epoch 25 : 183.24795792344773
Test Precision for epoch 25 : 0.26153846153846155
Test Recall for epoch 25 : 0.26153846153846155
Test F1 for epoch 25 : 0.26153846153846155


theta for epoch 26 : tensor([[1.6651, 1.7575, 1.8669, 1.8436, 1.8389, 1.6898, 1.7348, 1.6632, 1.6632,
         1.3217, 1.3393, 1.3617, 1.3549, 1.3093, 1.4022, 1.3329, 1.3197, 1.3204,
         1.3046, 1.3121, 1.3120, 1.3193, 1.2705, 1.2600, 1.2947, 1.2534, 1.2534,
         1.2587, 1.3833, 1.2786, 1.3116, 1.3566, 1.2983, 1.2998, 1.2417, 1.2835,
         1.3821, 1.4090, 1.3961, 1.3941, 1.4089, 1.3470, 1.3804, 1.4016, 1.3568,
         1.3730, 1.3428, 1.3420, 1.3087, 1.3781, 1.3314, 1.3514, 1.3179, 1.3136],
        [1.3235, 1.1230, 1.0285, 1.2644, 1.2893, 1.3851, 1.2984, 1.3777, 1.3777,
         1.3665, 1.6055, 1.2383, 1.9962, 1.3193, 2.5508, 1.3600, 1.1764, 2.3072,
         1.1344, 1.2031, 0.8418, 1.1479, 1.3041, 1.4054, 1.3750, 1.4022, 1.4022,
         1.3570, 1.0472, 1.4423, 1.3963, 1.0923, 1.4608, 1.4399, 1.4274, 1.3930,
         1.3786, 1.5391, 1.4957, 1.4022, 1.3068, 1.4891, 1.4803, 0.4403, 1.2829,
         0.9209, 1.4810, 1.4620, 1.4437, 1.0240, 1.4652, 0.6908, 1.4538, 1.4497],
        [1.2423, 1.2824, 1.3676, 1.3262, 1.2439, 1.2470, 1.2341, 1.2380, 1.2380,
         1.3365, 1.3288, 1.3766, 1.3743, 1.3248, 1.2063, 1.3476, 1.2858, 1.2593,
         1.7487, 1.8683, 1.9830, 1.8745, 1.5929, 1.6134, 1.7497, 1.5620, 1.5620,
         1.2885, 1.3082, 1.3080, 1.3390, 1.2850, 1.3270, 1.3357, 1.3175, 1.3128,
         1.3992, 1.4279, 1.4145, 1.3627, 1.4252, 1.4297, 1.4040, 1.2185, 1.2006,
         1.2827, 1.3707, 1.3676, 1.3302, 1.2315, 1.3588, 1.3150, 1.3386, 1.3352],
        [1.2185, 1.2520, 1.1621, 1.1018, 1.2409, 1.2126, 1.2300, 1.2149, 1.2149,
         1.2715, 1.1832, 1.2531, 1.1918, 1.2592, 1.2272, 1.2800, 1.2679, 0.9278,
         1.2788, 1.1412, 1.3240, 1.2872, 1.2251, 1.1919, 1.2650, 1.2349, 1.2349,
         1.8876, 1.6411, 1.5439, 1.6109, 1.8507, 1.5361, 1.8388, 1.5503, 1.5312,
         1.3422, 1.3016, 1.2708, 1.2993, 1.3546, 1.2189, 1.3051, 1.0177, 1.2591,
         1.3439, 1.1981, 1.0807, 1.2089, 1.3136, 1.0951, 1.3900, 1.2177, 1.2691],
        [1.5664, 1.2909, 0.4226, 0.6537, 1.1033, 1.4787, 1.3967, 1.5624, 1.5624,
         1.5087, 1.3119, 1.2483, 0.9301, 1.5652, 0.2600, 1.4043, 1.5673, 1.1587,
         1.1597, 0.7782, 0.8157, 1.0033, 1.4718, 1.5191, 1.1544, 1.5692, 1.5692,
         0.6018, 0.6198, 1.5403, 1.3131, 0.7819, 1.5395, 1.0472, 1.5582, 1.5199,
         1.1941, 0.8941, 0.8406, 1.1085, 1.4820, 1.5983, 1.0756, 2.6833, 2.5466,
         0.7047, 1.0560, 1.1761, 1.4848, 0.8502, 1.4399, 0.3511, 1.3982, 1.5728],
        [1.3446, 1.3727, 1.4264, 1.4102, 1.3222, 1.3093, 1.3086, 1.3408, 1.3408,
         1.2518, 1.2930, 1.2446, 1.3579, 1.3539, 1.4032, 1.2641, 1.3655, 1.3039,
         1.4017, 1.3910, 1.3001, 1.3528, 1.3713, 1.3616, 1.3299, 1.3604, 1.3604,
         1.3405, 1.2844, 1.3374, 1.1314, 1.2041, 1.0888, 1.3330, 1.2044, 1.3423,
         1.4411, 1.1531, 1.4565, 1.4347, 1.0350, 0.9308, 1.4445, 1.2539, 0.7684,
         2.0632, 1.6670, 1.8116, 1.7839, 1.6600, 1.3044, 2.0499, 1.7032, 1.2875]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 26 : 183.21864671885666
Test loss for epoch 26 : 183.16804479971879
Test Precision for epoch 26 : 0.26153846153846155
Test Recall for epoch 26 : 0.26153846153846155
Test F1 for epoch 26 : 0.26153846153846155


theta for epoch 27 : tensor([[1.6794, 1.7726, 1.8827, 1.8613, 1.8554, 1.7039, 1.7506, 1.6774, 1.6774,
         1.3160, 1.3339, 1.3566, 1.3505, 1.3035, 1.4000, 1.3274, 1.3141, 1.3161,
         1.2899, 1.2973, 1.2925, 1.3037, 1.2531, 1.2423, 1.2770, 1.2357, 1.2357,
         1.2634, 1.3858, 1.2764, 1.3112, 1.3597, 1.2970, 1.3004, 1.2401, 1.2816,
         1.3646, 1.3928, 1.3790, 1.3769, 1.3926, 1.3314, 1.3628, 1.3910, 1.3447,
         1.3823, 1.3495, 1.3479, 1.3129, 1.3871, 1.3374, 1.3652, 1.3226, 1.3181],
        [1.3061, 1.1133, 1.0205, 1.2504, 1.2756, 1.3667, 1.2810, 1.3590, 1.3590,
         1.3765, 1.6214, 1.2469, 2.0250, 1.3288, 2.6028, 1.3709, 1.1842, 2.3506,
         1.1200, 1.1895, 0.8283, 1.1355, 1.2875, 1.3857, 1.3568, 1.3822, 1.3822,
         1.3544, 1.0459, 1.4364, 1.3917, 1.0901, 1.4558, 1.4368, 1.4212, 1.3869,
         1.3575, 1.5219, 1.4763, 1.3816, 1.2876, 1.4720, 1.4603, 0.4268, 1.2647,
         0.9281, 1.4851, 1.4657, 1.4454, 1.0281, 1.4685, 0.7003, 1.4560, 1.4517],
        [1.2253, 1.2659, 1.3501, 1.3121, 1.2319, 1.2301, 1.2237, 1.2211, 1.2211,
         1.3289, 1.3233, 1.3697, 1.3680, 1.3169, 1.2158, 1.3403, 1.2799, 1.2552,
         1.7645, 1.8878, 2.0047, 1.8947, 1.6067, 1.6290, 1.7679, 1.5759, 1.5759,
         1.2918, 1.3118, 1.3036, 1.3367, 1.2892, 1.3235, 1.3336, 1.3137, 1.3087,
         1.3804, 1.4105, 1.3961, 1.3443, 1.4079, 1.4127, 1.3849, 1.2110, 1.1904,
         1.2909, 1.3754, 1.3719, 1.3330, 1.2425, 1.3629, 1.3288, 1.3419, 1.3382],
        [1.2160, 1.2505, 1.1656, 1.1081, 1.2405, 1.2112, 1.2286, 1.2123, 1.2123,
         1.2718, 1.1846, 1.2581, 1.1955, 1.2591, 1.2322, 1.2810, 1.2683, 0.9353,
         1.2756, 1.1463, 1.3215, 1.2851, 1.2219, 1.1876, 1.2618, 1.2301, 1.2301,
         1.9058, 1.6517, 1.5507, 1.6200, 1.8682, 1.5429, 1.8555, 1.5575, 1.5378,
         1.3307, 1.2916, 1.2591, 1.2874, 1.3451, 1.2103, 1.2934, 1.0145, 1.2521,
         1.3506, 1.2046, 1.0890, 1.2117, 1.3219, 1.1015, 1.3974, 1.2211, 1.2721],
        [1.5611, 1.2816, 0.4168, 0.6481, 1.0886, 1.4695, 1.3875, 1.5570, 1.5570,
         1.5016, 1.3019, 1.2458, 0.9196, 1.5583, 0.2476, 1.4004, 1.5606, 1.1538,
         1.1482, 0.7640, 0.7952, 0.9881, 1.4617, 1.5124, 1.1481, 1.5627, 1.5627,
         0.5960, 0.6160, 1.5413, 1.3105, 0.7778, 1.5415, 1.0397, 1.5613, 1.5214,
         1.1858, 0.8771, 0.8224, 1.0987, 1.4834, 1.6058, 1.0636, 2.7465, 2.6030,
         0.7040, 1.0683, 1.1855, 1.4914, 0.8544, 1.4476, 0.3543, 1.4080, 1.5821],
        [1.3367, 1.3668, 1.4272, 1.4073, 1.3220, 1.3043, 1.3018, 1.3328, 1.3328,
         1.2507, 1.2963, 1.2452, 1.3629, 1.3493, 1.4205, 1.2629, 1.3611, 1.3053,
         1.3940, 1.3902, 1.3086, 1.3518, 1.3628, 1.3524, 1.3215, 1.3508, 1.3508,
         1.3446, 1.2977, 1.3356, 1.1336, 1.2077, 1.0886, 1.3351, 1.2024, 1.3408,
         1.4238, 1.1339, 1.4398, 1.4190, 1.0172, 0.9147, 1.4269, 1.2573, 0.7702,
         2.0841, 1.6815, 1.8310, 1.8017, 1.6679, 1.3095, 2.0695, 1.7196, 1.2921]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 27 : 183.14345852221788
Test loss for epoch 27 : 183.09984673979
Test Precision for epoch 27 : 0.26153846153846155
Test Recall for epoch 27 : 0.26153846153846155
Test F1 for epoch 27 : 0.26153846153846155


theta for epoch 28 : tensor([[1.6915, 1.7850, 1.8957, 1.8762, 1.8691, 1.7156, 1.7640, 1.6894, 1.6894,
         1.3056, 1.3236, 1.3464, 1.3409, 1.2930, 1.3919, 1.3171, 1.3037, 1.3066,
         1.2737, 1.2803, 1.2720, 1.2865, 1.2351, 1.2242, 1.2583, 1.2178, 1.2178,
         1.2659, 1.3859, 1.2721, 1.3086, 1.3604, 1.2934, 1.2988, 1.2363, 1.2776,
         1.3544, 1.3839, 1.3693, 1.3669, 1.3835, 1.3231, 1.3526, 1.3873, 1.3397,
         1.3921, 1.3568, 1.3547, 1.3182, 1.3966, 1.3443, 1.3793, 1.3282, 1.3237],
        [1.2910, 1.1055, 1.0127, 1.2379, 1.2637, 1.3503, 1.2658, 1.3423, 1.3423,
         1.3822, 1.6325, 1.2514, 2.0488, 1.3343, 2.6506, 1.3775, 1.1882, 2.3896,
         1.1057, 1.1755, 0.8148, 1.1229, 1.2710, 1.3655, 1.3380, 1.3619, 1.3619,
         1.3496, 1.0431, 1.4279, 1.3848, 1.0863, 1.4483, 1.4312, 1.4126, 1.3784,
         1.3440, 1.5117, 1.4642, 1.3686, 1.2763, 1.4620, 1.4475, 0.4212, 1.2543,
         0.9369, 1.4898, 1.4702, 1.4480, 1.0340, 1.4726, 0.7109, 1.4590, 1.4546],
        [1.2115, 1.2518, 1.3342, 1.2995, 1.2218, 1.2164, 1.2156, 1.2074, 1.2074,
         1.3170, 1.3134, 1.3581, 1.3568, 1.3047, 1.2200, 1.3284, 1.2698, 1.2465,
         1.7770, 1.9038, 2.0228, 1.9114, 1.6178, 1.6419, 1.7831, 1.5872, 1.5872,
         1.2930, 1.3132, 1.2970, 1.3320, 1.2915, 1.3177, 1.3292, 1.3078, 1.3024,
         1.3689, 1.4003, 1.3851, 1.3333, 1.3976, 1.4027, 1.3731, 1.2103, 1.1880,
         1.2999, 1.3808, 1.3769, 1.3367, 1.2543, 1.3678, 1.3432, 1.3461, 1.3423],
        [1.2192, 1.2544, 1.1745, 1.1199, 1.2456, 1.2155, 1.2328, 1.2154, 1.2154,
         1.2728, 1.1871, 1.2637, 1.2001, 1.2598, 1.2375, 1.2825, 1.2694, 0.9450,
         1.2761, 1.1555, 1.3224, 1.2864, 1.2228, 1.1878, 1.2624, 1.2295, 1.2295,
         1.9174, 1.6559, 1.5511, 1.6226, 1.8791, 1.5433, 1.8656, 1.5583, 1.5380,
         1.3274, 1.2903, 1.2563, 1.2840, 1.3438, 1.2109, 1.2903, 1.0197, 1.2537,
         1.3606, 1.2149, 1.1013, 1.2186, 1.3337, 1.1121, 1.4080, 1.2284, 1.2790],
        [1.5517, 1.2677, 0.4056, 0.6372, 1.0692, 1.4560, 1.3741, 1.5475, 1.5475,
         1.4857, 1.2829, 1.2343, 0.8997, 1.5429, 0.2255, 1.3878, 1.5453, 1.1397,
         1.1313, 0.7439, 0.7683, 0.9672, 1.4464, 1.5005, 1.1364, 1.5511, 1.5511,
         0.5839, 0.6059, 1.5368, 1.3023, 0.7675, 1.5381, 1.0263, 1.5590, 1.5173,
         1.1858, 0.8686, 0.8127, 1.0972, 1.4928, 1.6213, 1.0599, 2.8155, 2.6658,
         0.6971, 1.0762, 1.1907, 1.4945, 0.8534, 1.4518, 0.3498, 1.4144, 1.5881],
        [1.3272, 1.3589, 1.4253, 1.4019, 1.3198, 1.2977, 1.2933, 1.3232, 1.3232,
         1.2413, 1.2909, 1.2371, 1.3587, 1.3366, 1.4271, 1.2533, 1.3486, 1.2973,
         1.3826, 1.3856, 1.3133, 1.3470, 1.3509, 1.3399, 1.3095, 1.3379, 1.3379,
         1.3453, 1.3080, 1.3305, 1.1328, 1.2080, 1.0853, 1.3340, 1.1973, 1.3360,
         1.4129, 1.1218, 1.4295, 1.4098, 1.0066, 0.9060, 1.4157, 1.2663, 0.7777,
         2.1072, 1.6990, 1.8535, 1.8225, 1.6785, 1.3181, 2.0913, 1.7392, 1.3003]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 28 : 183.08352951478508
Test loss for epoch 28 : 183.05302837625817
Test Precision for epoch 28 : 0.26153846153846155
Test Recall for epoch 28 : 0.26153846153846155
Test F1 for epoch 28 : 0.26153846153846155


theta for epoch 29 : tensor([[1.7035, 1.7971, 1.9079, 1.8907, 1.8823, 1.7272, 1.7773, 1.7014, 1.7014,
         1.2934, 1.3113, 1.3341, 1.3292, 1.2808, 1.3813, 1.3048, 1.2916, 1.2949,
         1.2671, 1.2724, 1.2615, 1.2790, 1.2276, 1.2168, 1.2498, 1.2105, 1.2105,
         1.2680, 1.3852, 1.2676, 1.3056, 1.3603, 1.2895, 1.2969, 1.2325, 1.2733,
         1.3511, 1.3819, 1.3665, 1.3638, 1.3812, 1.3217, 1.3493, 1.3902, 1.3415,
         1.3925, 1.3549, 1.3521, 1.3144, 1.3967, 1.3421, 1.3839, 1.3247, 1.3203],
        [1.2836, 1.1053, 1.0105, 1.2329, 1.2594, 1.3414, 1.2583, 1.3332, 1.3332,
         1.3821, 1.6374, 1.2506, 2.0660, 1.3341, 2.6929, 1.3786, 1.1869, 2.4228,
         1.1006, 1.1702, 0.8100, 1.1192, 1.2636, 1.3541, 1.3279, 1.3502, 1.3502,
         1.3453, 1.0421, 1.4199, 1.3783, 1.0842, 1.4411, 1.4260, 1.4043, 1.3704,
         1.3386, 1.5089, 1.4596, 1.3636, 1.2735, 1.4596, 1.4423, 0.4245, 1.2524,
         0.9380, 1.4856, 1.4657, 1.4420, 1.0324, 1.4679, 0.7143, 1.4534, 1.4490],
        [1.2059, 1.2454, 1.3251, 1.2938, 1.2187, 1.2108, 1.2149, 1.2019, 1.2019,
         1.3031, 1.3015, 1.3443, 1.3433, 1.2908, 1.2215, 1.3145, 1.2580, 1.2355,
         1.7906, 1.9205, 2.0412, 1.9289, 1.6303, 1.6563, 1.7994, 1.6000, 1.6000,
         1.2938, 1.3138, 1.2899, 1.3266, 1.2932, 1.3113, 1.3242, 1.3013, 1.2956,
         1.3641, 1.3967, 1.3808, 1.3293, 1.3939, 1.3993, 1.3681, 1.2162, 1.1930,
         1.2996, 1.3768, 1.3725, 1.3313, 1.2570, 1.3635, 1.3479, 1.3411, 1.3373],
        [1.2261, 1.2619, 1.1865, 1.1348, 1.2542, 1.2235, 1.2405, 1.2222, 1.2222,
         1.2722, 1.1882, 1.2676, 1.2034, 1.2591, 1.2409, 1.2823, 1.2690, 0.9535,
         1.2818, 1.1696, 1.3282, 1.2929, 1.2292, 1.1933, 1.2681, 1.2342, 1.2342,
         1.9279, 1.6592, 1.5506, 1.6243, 1.8890, 1.5428, 1.8747, 1.5582, 1.5373,
         1.3298, 1.2948, 1.2594, 1.2863, 1.3480, 1.2173, 1.2930, 1.0300, 1.2609,
         1.3638, 1.2186, 1.1074, 1.2190, 1.3387, 1.1165, 1.4115, 1.2291, 1.2792],
        [1.5428, 1.2542, 0.3938, 0.6257, 1.0501, 1.4429, 1.3610, 1.5384, 1.5384,
         1.4658, 1.2596, 1.2187, 0.8754, 1.5234, 0.1985, 1.3712, 1.5260, 1.1214,
         1.1161, 0.7250, 0.7419, 0.9476, 1.4329, 1.4905, 1.1263, 1.5413, 1.5413,
         0.5692, 0.5935, 1.5297, 1.2915, 0.7546, 1.5320, 1.0108, 1.5542, 1.5108,
         1.1907, 0.8654, 0.8084, 1.1007, 1.5068, 1.6415, 1.0612, 2.8883, 2.7324,
         0.6769, 1.0703, 1.1823, 1.4846, 0.8387, 1.4427, 0.3319, 1.4076, 1.5811],
        [1.3207, 1.3539, 1.4255, 1.3990, 1.3206, 1.2944, 1.2877, 1.3168, 1.3168,
         1.2293, 1.2823, 1.2259, 1.3509, 1.3213, 1.4286, 1.2410, 1.3334, 1.2856,
         1.3755, 1.3848, 1.3218, 1.3465, 1.3434, 1.3320, 1.3020, 1.3295, 1.3295,
         1.3452, 1.3175, 1.3248, 1.1317, 1.2077, 1.0818, 1.3323, 1.1917, 1.3306,
         1.4091, 1.1176, 1.4263, 1.4077, 1.0041, 0.9056, 1.4116, 1.2817, 0.7918,
         2.1257, 1.7122, 1.8718, 1.8389, 1.6844, 1.3226, 2.1083, 1.7545, 1.3043]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 29 : 183.0352516892547
Test loss for epoch 29 : 183.02214481995352
Test Precision for epoch 29 : 0.26153846153846155
Test Recall for epoch 29 : 0.26153846153846155
Test F1 for epoch 29 : 0.26153846153846155


theta for epoch 30 : tensor([[1.7151, 1.8085, 1.9192, 1.9043, 1.8946, 1.7383, 1.7900, 1.7129, 1.7129,
         1.2861, 1.3038, 1.3264, 1.3222, 1.2736, 1.3748, 1.2974, 1.2845, 1.2875,
         1.2699, 1.2735, 1.2608, 1.2807, 1.2300, 1.2192, 1.2510, 1.2131, 1.2131,
         1.2719, 1.3858, 1.2652, 1.3044, 1.3617, 1.2876, 1.2969, 1.2308, 1.2712,
         1.3512, 1.3832, 1.3671, 1.3641, 1.3821, 1.3236, 1.3494, 1.3962, 1.3466,
         1.3824, 1.3426, 1.3393, 1.3007, 1.3863, 1.3296, 1.3778, 1.3111, 1.3068],
        [1.2809, 1.1095, 1.0115, 1.2322, 1.2597, 1.3371, 1.2556, 1.3288, 1.3288,
         1.3819, 1.6415, 1.2500, 2.0822, 1.3340, 2.7340, 1.3796, 1.1861, 2.4552,
         1.1030, 1.1720, 0.8124, 1.1228, 1.2636, 1.3498, 1.3249, 1.3458, 1.3458,
         1.3429, 1.0441, 1.4137, 1.3739, 1.0849, 1.4355, 1.4226, 1.3978, 1.3646,
         1.3368, 1.5092, 1.4582, 1.3620, 1.2745, 1.4604, 1.4403, 0.4321, 1.2545,
         0.9295, 1.4708, 1.4508, 1.4258, 1.0212, 1.4528, 0.7084, 1.4374, 1.4331],
        [1.2064, 1.2447, 1.3213, 1.2934, 1.2209, 1.2113, 1.2196, 1.2026, 1.2026,
         1.2941, 1.2944, 1.3350, 1.3344, 1.2817, 1.2267, 1.3053, 1.2512, 1.2289,
         1.8046, 1.9375, 2.0596, 1.9465, 1.6438, 1.6716, 1.8163, 1.6140, 1.6140,
         1.2966, 1.3161, 1.2850, 1.3231, 1.2969, 1.3069, 1.3211, 1.2968, 1.2908,
         1.3628, 1.3965, 1.3799, 1.3288, 1.3935, 1.3990, 1.3664, 1.2253, 1.2018,
         1.2893, 1.3627, 1.3580, 1.3161, 1.2496, 1.3492, 1.3422, 1.3261, 1.3223],
        [1.2310, 1.2672, 1.1961, 1.1474, 1.2607, 1.2295, 1.2461, 1.2271, 1.2271,
         1.2714, 1.1888, 1.2710, 1.2063, 1.2582, 1.2434, 1.2819, 1.2684, 0.9609,
         1.2879, 1.1837, 1.3344, 1.2997, 1.2361, 1.1993, 1.2744, 1.2395, 1.2395,
         1.9424, 1.6668, 1.5545, 1.6304, 1.9030, 1.5468, 1.8880, 1.5625, 1.5411,
         1.3325, 1.2997, 1.2629, 1.2891, 1.3526, 1.2243, 1.2961, 1.0402, 1.2684,
         1.3566, 1.2123, 1.1036, 1.2094, 1.3334, 1.1111, 1.4046, 1.2197, 1.2693],
        [1.5377, 1.2457, 0.3883, 0.6202, 1.0370, 1.4342, 1.3525, 1.5333, 1.5333,
         1.4527, 1.2437, 1.2106, 0.8584, 1.5108, 0.1783, 1.3620, 1.5135, 1.1104,
         1.1084, 0.7145, 0.7226, 0.9358, 1.4256, 1.4865, 1.1234, 1.5373, 1.5373,
         0.5603, 0.5867, 1.5254, 1.2845, 0.7468, 1.5287, 1.0003, 1.5520, 1.5071,
         1.1918, 0.8591, 0.8011, 1.1007, 1.5167, 1.6576, 1.0591, 2.9589, 2.7967,
         0.6508, 1.0561, 1.1650, 1.4650, 0.8175, 1.4242, 0.3094, 1.3914, 1.5644],
        [1.3153, 1.3496, 1.4260, 1.3967, 1.3222, 1.2924, 1.2832, 1.3114, 1.3114,
         1.2212, 1.2774, 1.2182, 1.3466, 1.3102, 1.4319, 1.2325, 1.3223, 1.2769,
         1.3719, 1.3872, 1.3334, 1.3493, 1.3395, 1.3276, 1.2981, 1.3247, 1.3247,
         1.3455, 1.3274, 1.3199, 1.1315, 1.2078, 1.0793, 1.3313, 1.1872, 1.3259,
         1.4078, 1.1165, 1.4256, 1.4081, 1.0048, 0.9084, 1.4100, 1.2990, 0.8076,
         2.1402, 1.7218, 1.8864, 1.8517, 1.6862, 1.3235, 2.1213, 1.7663, 1.3049]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 30 : 183.01047800262046
Test loss for epoch 30 : 183.01193429465548
Test Precision for epoch 30 : 0.26153846153846155
Test Recall for epoch 30 : 0.26153846153846155
Test F1 for epoch 30 : 0.26153846153846155


theta for epoch 31 : tensor([[1.7254, 1.8183, 1.9288, 1.9163, 1.9053, 1.7481, 1.8013, 1.7231, 1.7231,
         1.2854, 1.3028, 1.3252, 1.3217, 1.2732, 1.3744, 1.2966, 1.2840, 1.2863,
         1.2731, 1.2748, 1.2614, 1.2831, 1.2333, 1.2226, 1.2532, 1.2168, 1.2168,
         1.2767, 1.3868, 1.2642, 1.3043, 1.3636, 1.2867, 1.2980, 1.2304, 1.2703,
         1.3497, 1.3829, 1.3661, 1.3628, 1.3814, 1.3239, 1.3480, 1.4006, 1.3500,
         1.3713, 1.3295, 1.3256, 1.2862, 1.3749, 1.3162, 1.3706, 1.2968, 1.2926],
        [1.2772, 1.1122, 1.0104, 1.2303, 1.2590, 1.3318, 1.2518, 1.3232, 1.3232,
         1.3850, 1.6484, 1.2531, 2.1005, 1.3374, 2.7769, 1.3841, 1.1892, 2.4897,
         1.1061, 1.1742, 0.8158, 1.1270, 1.2643, 1.3458, 1.3224, 1.3418, 1.3418,
         1.3412, 1.0474, 1.4084, 1.3704, 1.0869, 1.4306, 1.4200, 1.3920, 1.3598,
         1.3331, 1.5074, 1.4546, 1.3584, 1.2738, 1.4591, 1.4362, 0.4380, 1.2550,
         0.9206, 1.4549, 1.4348, 1.4086, 1.0097, 1.4366, 0.7020, 1.4203, 1.4162],
        [1.2079, 1.2447, 1.3182, 1.2933, 1.2235, 1.2129, 1.2246, 1.2044, 1.2044,
         1.2925, 1.2948, 1.3330, 1.3329, 1.2802, 1.2383, 1.3036, 1.2521, 1.2295,
         1.8154, 1.9509, 2.0743, 1.9606, 1.6544, 1.6841, 1.8300, 1.6250, 1.6250,
         1.3015, 1.3201, 1.2823, 1.3215, 1.3026, 1.3044, 1.3201, 1.2944, 1.2884,
         1.3604, 1.3952, 1.3779, 1.3275, 1.3920, 1.3977, 1.3637, 1.2336, 1.2102,
         1.2790, 1.3484, 1.3434, 1.3009, 1.2422, 1.3347, 1.3361, 1.3111, 1.3074],
        [1.2285, 1.2650, 1.1981, 1.1523, 1.2598, 1.2281, 1.2443, 1.2246, 1.2246,
         1.2699, 1.1884, 1.2734, 1.2084, 1.2566, 1.2445, 1.2806, 1.2671, 0.9661,
         1.2876, 1.1913, 1.3342, 1.3000, 1.2366, 1.1989, 1.2742, 1.2384, 1.2384,
         1.9632, 1.6810, 1.5650, 1.6429, 1.9233, 1.5574, 1.9075, 1.5733, 1.5514,
         1.3308, 1.3002, 1.2618, 1.2872, 1.3526, 1.2267, 1.2947, 1.0455, 1.2712,
         1.3455, 1.2021, 1.0957, 1.1960, 1.3242, 1.1017, 1.3936, 1.2066, 1.2557],
        [1.5378, 1.2445, 0.3937, 0.6246, 1.0331, 1.4313, 1.3507, 1.5334, 1.5334,
         1.4530, 1.2425, 1.2171, 0.8569, 1.5113, 0.1735, 1.3668, 1.5142, 1.1143,
         1.1096, 0.7152, 0.7136, 0.9341, 1.4248, 1.4887, 1.1290, 1.5392, 1.5392,
         0.5628, 0.5912, 1.5270, 1.2850, 0.7491, 1.5311, 0.9996, 1.5554, 1.5095,
         1.1813, 0.8425, 0.7836, 1.0893, 1.5143, 1.6612, 1.0457, 3.0212, 2.8518,
         0.6385, 1.0517, 1.1564, 1.4513, 0.8088, 1.4118, 0.3021, 1.3818, 1.5527],
        [1.3050, 1.3403, 1.4208, 1.3892, 1.3187, 1.2854, 1.2737, 1.3011, 1.3011,
         1.2163, 1.2756, 1.2135, 1.3455, 1.3028, 1.4369, 1.2272, 1.3148, 1.2707,
         1.3649, 1.3859, 1.3411, 1.3487, 1.3322, 1.3199, 1.2909, 1.3167, 1.3167,
         1.3442, 1.3356, 1.3139, 1.1300, 1.2062, 1.0755, 1.3290, 1.1814, 1.3201,
         1.4025, 1.1111, 1.4208, 1.4044, 1.0011, 0.9065, 1.4044, 1.3112, 0.8170,
         2.1591, 1.7364, 1.9060, 1.8694, 1.6928, 1.3298, 2.1387, 1.7832, 1.3108]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 31 : 182.94940687382262
Test loss for epoch 31 : 182.95334525863473
Test Precision for epoch 31 : 0.26153846153846155
Test Recall for epoch 31 : 0.26153846153846155
Test F1 for epoch 31 : 0.26153846153846155


theta for epoch 32 : tensor([[1.7353, 1.8276, 1.9377, 1.9277, 1.9154, 1.7575, 1.8123, 1.7330, 1.7330,
         1.2882, 1.3051, 1.3272, 1.3246, 1.2762, 1.3771, 1.2991, 1.2869, 1.2881,
         1.2719, 1.2714, 1.2582, 1.2811, 1.2325, 1.2219, 1.2515, 1.2164, 1.2164,
         1.2793, 1.3854, 1.2616, 1.3023, 1.3631, 1.2841, 1.2972, 1.2284, 1.2679,
         1.3463, 1.3806, 1.3631, 1.3595, 1.3787, 1.3221, 1.3446, 1.4029, 1.3512,
         1.3649, 1.3211, 1.3166, 1.2766, 1.3680, 1.3076, 1.3677, 1.2874, 1.2833],
        [1.2737, 1.1150, 1.0088, 1.2285, 1.2586, 1.3267, 1.2484, 1.3180, 1.3180,
         1.3878, 1.6544, 1.2563, 2.1175, 1.3407, 2.8185, 1.3885, 1.1925, 2.5233,
         1.1080, 1.1752, 0.8189, 1.1300, 1.2638, 1.3405, 1.3185, 1.3364, 1.3364,
         1.3385, 1.0506, 1.4024, 1.3661, 1.0888, 1.4248, 1.4165, 1.3854, 1.3544,
         1.3279, 1.5037, 1.4492, 1.3532, 1.2719, 1.4561, 1.4302, 0.4433, 1.2545,
         0.9183, 1.4446, 1.4244, 1.3972, 1.0051, 1.4260, 0.7021, 1.4090, 1.4051],
        [1.2105, 1.2458, 1.3158, 1.2938, 1.2266, 1.2157, 1.2299, 1.2073, 1.2073,
         1.2960, 1.3002, 1.3359, 1.3362, 1.2839, 1.2538, 1.3069, 1.2581, 1.2347,
         1.8213, 1.9591, 2.0837, 1.9696, 1.6604, 1.6919, 1.8387, 1.6316, 1.6316,
         1.3059, 1.3232, 1.2795, 1.3195, 1.3076, 1.3017, 1.3186, 1.2917, 1.2857,
         1.3569, 1.3928, 1.3749, 1.3252, 1.3894, 1.3950, 1.3599, 1.2407, 1.2178,
         1.2747, 1.3399, 1.3344, 1.2916, 1.2407, 1.3259, 1.3355, 1.3020, 1.2984],
        [1.2199, 1.2566, 1.1936, 1.1508, 1.2527, 1.2205, 1.2363, 1.2160, 1.2160,
         1.2664, 1.1858, 1.2736, 1.2084, 1.2532, 1.2433, 1.2774, 1.2639, 0.9684,
         1.2797, 1.1911, 1.3263, 1.2927, 1.2295, 1.1908, 1.2663, 1.2297, 1.2297,
         1.9883, 1.6999, 1.5803, 1.6602, 1.9480, 1.5727, 1.9314, 1.5889, 1.5666,
         1.3250, 1.2966, 1.2567, 1.2813, 1.3484, 1.2249, 1.2893, 1.0462, 1.2698,
         1.3357, 1.1930, 1.0887, 1.1839, 1.3162, 1.0933, 1.3839, 1.1948, 1.2436],
        [1.5413, 1.2484, 0.4066, 0.6359, 1.0357, 1.4325, 1.3534, 1.5369, 1.5369,
         1.4619, 1.2507, 1.2328, 0.8654, 1.5201, 0.1789, 1.3805, 1.5232, 1.1275,
         1.1154, 0.7222, 0.7104, 0.9377, 1.4267, 1.4932, 1.1386, 1.5431, 1.5431,
         0.5719, 0.6023, 1.5310, 1.2892, 0.7572, 1.5359, 1.0043, 1.5611, 1.5145,
         1.1623, 0.8183, 0.7587, 1.0696, 1.5028, 1.6557, 1.0242, 3.0775, 2.9001,
         0.6422, 1.0606, 1.1605, 1.4483, 0.8155, 1.4105, 0.3109, 1.3837, 1.5512],
        [1.2906, 1.3268, 1.4108, 1.3771, 1.3108, 1.2744, 1.2600, 1.2867, 1.2867,
         1.2123, 1.2746, 1.2093, 1.3451, 1.2968, 1.4414, 1.2229, 1.3086, 1.2649,
         1.3527, 1.3791, 1.3433, 1.3426, 1.3198, 1.3071, 1.2785, 1.3035, 1.3035,
         1.3397, 1.3403, 1.3050, 1.1258, 1.2014, 1.0689, 1.3237, 1.1728, 1.3114,
         1.3932, 1.1017, 1.4121, 1.3967, 0.9934, 0.9003, 1.3948, 1.3184, 0.8206,
         2.1838, 1.7577, 1.9321, 1.8937, 1.7060, 1.3432, 2.1619, 1.8068, 1.3239]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 32 : 182.86670004064197
Test loss for epoch 32 : 182.86203180923263
Test Precision for epoch 32 : 0.26153846153846155
Test Recall for epoch 32 : 0.26153846153846155
Test F1 for epoch 32 : 0.26153846153846155


theta for epoch 33 : tensor([[1.7457, 1.8370, 1.9464, 1.9391, 1.9254, 1.7672, 1.8236, 1.7434, 1.7434,
         1.2887, 1.3051, 1.3268, 1.3250, 1.2771, 1.3770, 1.2993, 1.2876, 1.2872,
         1.2702, 1.2671, 1.2552, 1.2787, 1.2318, 1.2214, 1.2497, 1.2162, 1.2162,
         1.2763, 1.3783, 1.2543, 1.2952, 1.3569, 1.2765, 1.2913, 1.2216, 1.2606,
         1.3442, 1.3794, 1.3614, 1.3574, 1.3771, 1.3214, 1.3425, 1.4058, 1.3533,
         1.3634, 1.3177, 1.3126, 1.2723, 1.3660, 1.3040, 1.3697, 1.2831, 1.2793],
        [1.2745, 1.1216, 1.0102, 1.2304, 1.2620, 1.3257, 1.2493, 1.3170, 1.3170,
         1.3844, 1.6536, 1.2536, 2.1274, 1.3380, 2.8539, 1.3868, 1.1901, 2.5504,
         1.1134, 1.1792, 0.8261, 1.1363, 1.2668, 1.3383, 1.3177, 1.3342, 1.3342,
         1.3330, 1.0516, 1.3938, 1.3593, 1.0885, 1.4162, 1.4102, 1.3762, 1.3466,
         1.3255, 1.5024, 1.4462, 1.3508, 1.2731, 1.4553, 1.4268, 0.4523, 1.2571,
         0.9240, 1.4409, 1.4208, 1.3927, 1.0085, 1.4222, 0.7101, 1.4046, 1.4008],
        [1.2149, 1.2481, 1.3145, 1.2950, 1.2306, 1.2201, 1.2361, 1.2120, 1.2120,
         1.2979, 1.3037, 1.3368, 1.3376, 1.2859, 1.2666, 1.3084, 1.2625, 1.2377,
         1.8262, 1.9660, 2.0916, 1.9773, 1.6658, 1.6991, 1.8465, 1.6375, 1.6375,
         1.3053, 1.3210, 1.2724, 1.3128, 1.3077, 1.2944, 1.3125, 1.2846, 1.2786,
         1.3550, 1.3918, 1.3733, 1.3245, 1.3881, 1.3936, 1.3577, 1.2488, 1.2269,
         1.2756, 1.3365, 1.3307, 1.2877, 1.2443, 1.3224, 1.3397, 1.2983, 1.2948],
        [1.2099, 1.2467, 1.1871, 1.1472, 1.2439, 1.2115, 1.2268, 1.2060, 1.2060,
         1.2595, 1.1797, 1.2700, 1.2049, 1.2464, 1.2381, 1.2707, 1.2572, 0.9670,
         1.2698, 1.1886, 1.3162, 1.2832, 1.2206, 1.1810, 1.2566, 1.2194, 1.2194,
         2.0137, 1.7192, 1.5960, 1.6779, 1.9731, 1.5885, 1.9557, 1.6050, 1.5822,
         1.3193, 1.2932, 1.2519, 1.2755, 1.3443, 1.2234, 1.2842, 1.0466, 1.2683,
         1.3293, 1.1873, 1.0847, 1.1753, 1.3114, 1.0880, 1.3773, 1.1864, 1.2350],
        [1.5440, 1.2516, 0.4185, 0.6462, 1.0380, 1.4331, 1.3554, 1.5397, 1.5397,
         1.4682, 1.2562, 1.2458, 0.8711, 1.5265, 0.1815, 1.3918, 1.5298, 1.1377,
         1.1206, 0.7284, 0.7063, 0.9406, 1.4277, 1.4967, 1.1473, 1.5460, 1.5460,
         0.5774, 0.6100, 1.5307, 1.2892, 0.7615, 1.5364, 1.0053, 1.5625, 1.5152,
         1.1446, 0.7958, 0.7355, 1.0513, 1.4924, 1.6512, 1.0041, 3.1356, 2.9502,
         0.6507, 1.0742, 1.1696, 1.4503, 0.8271, 1.4142, 0.3231, 1.3906, 1.5545],
        [1.2783, 1.3150, 1.4017, 1.3664, 1.3045, 1.2655, 1.2483, 1.2745, 1.2745,
         1.2082, 1.2727, 1.2047, 1.3437, 1.2907, 1.4433, 1.2183, 1.3024, 1.2580,
         1.3417, 1.3729, 1.3460, 1.3374, 1.3087, 1.2957, 1.2677, 1.2919, 1.2919,
         1.3322, 1.3420, 1.2937, 1.1193, 1.1939, 1.0604, 1.3157, 1.1622, 1.3002,
         1.3861, 1.0955, 1.4055, 1.3910, 0.9889, 0.8975, 1.3874, 1.3269, 0.8259,
         2.2082, 1.7793, 1.9584, 1.9182, 1.7192, 1.3573, 2.1847, 1.8307, 1.3378]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 33 : 182.8458241543597
Test loss for epoch 33 : 182.83106322881537
Test Precision for epoch 33 : 0.26153846153846155
Test Recall for epoch 33 : 0.26153846153846155
Test F1 for epoch 33 : 0.26153846153846155


theta for epoch 34 : tensor([[1.7559, 1.8459, 1.9544, 1.9498, 1.9348, 1.7766, 1.8345, 1.7535, 1.7535,
         1.2859, 1.3015, 1.3227, 1.3216, 1.2747, 1.3727, 1.2960, 1.2850, 1.2824,
         1.2716, 1.2656, 1.2555, 1.2794, 1.2348, 1.2248, 1.2515, 1.2199, 1.2199,
         1.2688, 1.3667, 1.2432, 1.2842, 1.3463, 1.2651, 1.2813, 1.2110, 1.2495,
         1.3448, 1.3811, 1.3625, 1.3581, 1.3782, 1.3235, 1.3432, 1.4108, 1.3578,
         1.3645, 1.3168, 1.3111, 1.2707, 1.3666, 1.3031, 1.3739, 1.2815, 1.2779],
        [1.2780, 1.1301, 1.0128, 1.2343, 1.2677, 1.3276, 1.2529, 1.3188, 1.3188,
         1.3768, 1.6483, 1.2472, 2.1324, 1.3313, 2.8850, 1.3811, 1.1840, 2.5733,
         1.1226, 1.1866, 0.8370, 1.1460, 1.2738, 1.3404, 1.3208, 1.3364, 1.3364,
         1.3242, 1.0497, 1.3823, 1.3495, 1.0854, 1.4047, 1.4007, 1.3640, 1.3361,
         1.3270, 1.5044, 1.4467, 1.3520, 1.2782, 1.4580, 1.4268, 0.4651, 1.2636,
         0.9333, 1.4404, 1.4204, 1.3916, 1.0157, 1.4216, 0.7214, 1.4034, 1.4000],
        [1.2187, 1.2496, 1.3121, 1.2947, 1.2330, 1.2238, 1.2408, 1.2160, 1.2160,
         1.2954, 1.3027, 1.3333, 1.3343, 1.2838, 1.2736, 1.3055, 1.2625, 1.2359,
         1.8340, 1.9755, 2.1019, 1.9876, 1.6744, 1.7095, 1.8572, 1.6469, 1.6469,
         1.2994, 1.3133, 1.2606, 1.3013, 1.3024, 1.2824, 1.3014, 1.2728, 1.2669,
         1.3553, 1.3930, 1.3740, 1.3260, 1.3889, 1.3942, 1.3577, 1.2582, 1.2381,
         1.2785, 1.3350, 1.3288, 1.2859, 1.2497, 1.3209, 1.3455, 1.2965, 1.2932],
        [1.2020, 1.2386, 1.1820, 1.1450, 1.2369, 1.2046, 1.2192, 1.1982, 1.1982,
         1.2513, 1.1723, 1.2647, 1.1999, 1.2384, 1.2309, 1.2624, 1.2492, 0.9643,
         1.2632, 1.1888, 1.3092, 1.2768, 1.2152, 1.1748, 1.2501, 1.2126, 1.2126,
         2.0361, 1.7358, 1.6090, 1.6928, 1.9952, 1.6016, 1.9771, 1.6183, 1.5952,
         1.3167, 1.2930, 1.2504, 1.2729, 1.3431, 1.2252, 1.2823, 1.0496, 1.2697,
         1.3259, 1.1845, 1.0835, 1.1701, 1.3096, 1.0859, 1.3738, 1.1812, 1.2296],
        [1.5423, 1.2495, 0.4233, 0.6496, 1.0346, 1.4291, 1.3527, 1.5381, 1.5381,
         1.4666, 1.2531, 1.2501, 0.8675, 1.5252, 0.1741, 1.3950, 1.5287, 1.1389,
         1.1217, 0.7293, 0.6969, 0.9390, 1.4255, 1.4973, 1.1518, 1.5460, 1.5460,
         0.5743, 0.6092, 1.5238, 1.2823, 0.7574, 1.5302, 0.9988, 1.5573, 1.5092,
         1.1345, 0.7812, 0.7202, 1.0408, 1.4895, 1.6544, 0.9917, 3.1997, 3.0068,
         0.6535, 1.0838, 1.1753, 1.4506, 0.8338, 1.4159, 0.3273, 1.3955, 1.5564],
        [1.2729, 1.3097, 1.3980, 1.3616, 1.3045, 1.2635, 1.2436, 1.2692, 1.2692,
         1.2082, 1.2741, 1.2040, 1.3447, 1.2885, 1.4455, 1.2176, 1.2998, 1.2543,
         1.3381, 1.3733, 1.3547, 1.3391, 1.3053, 1.2921, 1.2646, 1.2882, 1.2882,
         1.3253, 1.3438, 1.2834, 1.1145, 1.1875, 1.0539, 1.3085, 1.1531, 1.2900,
         1.3858, 1.0980, 1.4057, 1.3922, 0.9934, 0.9041, 1.3868, 1.3409, 0.8391,
         2.2242, 1.7928, 1.9766, 1.9345, 1.7241, 1.3640, 2.1991, 1.8465, 1.3443]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 34 : 182.80887647703383
Test loss for epoch 34 : 182.7931422847069
Test Precision for epoch 34 : 0.26153846153846155
Test Recall for epoch 34 : 0.26153846153846155
Test F1 for epoch 34 : 0.26153846153846155


theta for epoch 35 : tensor([[1.7648, 1.8533, 1.9606, 1.9589, 1.9426, 1.7847, 1.8441, 1.7623, 1.7623,
         1.2836, 1.2983, 1.3189, 1.3182, 1.2729, 1.3679, 1.2932, 1.2829, 1.2777,
         1.2731, 1.2638, 1.2563, 1.2801, 1.2385, 1.2289, 1.2538, 1.2245, 1.2245,
         1.2622, 1.3560, 1.2336, 1.2744, 1.3365, 1.2552, 1.2724, 1.2019, 1.2399,
         1.3464, 1.3835, 1.3645, 1.3596, 1.3799, 1.3262, 1.3449, 1.4157, 1.3627,
         1.3661, 1.3165, 1.3104, 1.2700, 1.3676, 1.3029, 1.3786, 1.2807, 1.2775],
        [1.2797, 1.1357, 1.0117, 1.2352, 1.2708, 1.3276, 1.2544, 1.3190, 1.3190,
         1.3733, 1.6464, 1.2449, 2.1403, 1.3287, 2.9186, 1.3795, 1.1823, 2.5992,
         1.1294, 1.1914, 0.8454, 1.1533, 1.2793, 1.3411, 1.3222, 1.3373, 1.3373,
         1.3146, 1.0464, 1.3706, 1.3394, 1.0813, 1.3929, 1.3907, 1.3516, 1.3252,
         1.3283, 1.5060, 1.4469, 1.3530, 1.2831, 1.4602, 1.4266, 0.4764, 1.2700,
         0.9412, 1.4392, 1.4194, 1.3900, 1.0218, 1.4205, 0.7310, 1.4018, 1.3987],
        [1.2205, 1.2490, 1.3073, 1.2917, 1.2326, 1.2257, 1.2428, 1.2182, 1.2182,
         1.2923, 1.3008, 1.3287, 1.3298, 1.2810, 1.2782, 1.3018, 1.2618, 1.2327,
         1.8435, 1.9863, 2.1133, 1.9993, 1.6851, 1.7221, 1.8696, 1.6583, 1.6583,
         1.2933, 1.3052, 1.2492, 1.2900, 1.2968, 1.2708, 1.2905, 1.2614, 1.2555,
         1.3557, 1.3943, 1.3749, 1.3279, 1.3897, 1.3948, 1.3579, 1.2669, 1.2492,
         1.2810, 1.3333, 1.3268, 1.2841, 1.2546, 1.3193, 1.3508, 1.2947, 1.2917],
        [1.1976, 1.2337, 1.1796, 1.1453, 1.2330, 1.2010, 1.2149, 1.1940, 1.1940,
         1.2472, 1.1689, 1.2628, 1.1986, 1.2345, 1.2268, 1.2581, 1.2453, 0.9652,
         1.2599, 1.1918, 1.3052, 1.2736, 1.2136, 1.1726, 1.2470, 1.2098, 1.2098,
         2.0548, 1.7487, 1.6185, 1.7041, 2.0136, 1.6113, 1.9948, 1.6282, 1.6046,
         1.3164, 1.2955, 1.2517, 1.2728, 1.3440, 1.2296, 1.2830, 1.0548, 1.2734,
         1.3249, 1.1842, 1.0848, 1.1675, 1.3102, 1.0864, 1.3726, 1.1787, 1.2269],
        [1.5359, 1.2417, 0.4205, 0.6458, 1.0250, 1.4201, 1.3447, 1.5318, 1.5318,
         1.4603, 1.2445, 1.2487, 0.8573, 1.5196, 0.1587, 1.3932, 1.5233, 1.1340,
         1.1174, 0.7235, 0.6811, 0.9314, 1.4186, 1.4934, 1.1509, 1.5419, 1.5419,
         0.5655, 0.6028, 1.5139, 1.2717, 0.7480, 1.5210, 0.9880, 1.5491, 1.5002,
         1.1313, 0.7736, 0.7119, 1.0371, 1.4934, 1.6643, 0.9862, 3.2690, 3.0690,
         0.6482, 1.0868, 1.1754, 1.4469, 0.8330, 1.4132, 0.3216, 1.3960, 1.5546],
        [1.2742, 1.3107, 1.3994, 1.3624, 1.3103, 1.2682, 1.2458, 1.2707, 1.2707,
         1.2174, 1.2837, 1.2121, 1.3531, 1.2952, 1.4527, 1.2260, 1.3061, 1.2590,
         1.3403, 1.3788, 1.3678, 1.3462, 1.3081, 1.2948, 1.2678, 1.2908, 1.2908,
         1.3231, 1.3500, 1.2783, 1.1154, 1.1864, 1.0536, 1.3062, 1.1499, 1.2849,
         1.3902, 1.1072, 1.4107, 1.3980, 1.0048, 0.9179, 1.3911, 1.3584, 0.8579,
         2.2301, 1.7965, 1.9848, 1.9409, 1.7191, 1.3613, 2.2032, 1.8526, 1.3415]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 35 : 182.7528440463593
Test loss for epoch 35 : 182.74801399486702
Test Precision for epoch 35 : 0.26153846153846155
Test Recall for epoch 35 : 0.26153846153846155
Test F1 for epoch 35 : 0.26153846153846155


theta for epoch 36 : tensor([[1.7736, 1.8605, 1.9665, 1.9676, 1.9501, 1.7928, 1.8536, 1.7712, 1.7712,
         1.2833, 1.2969, 1.3168, 1.3165, 1.2731, 1.3643, 1.2922, 1.2827, 1.2745,
         1.2705, 1.2580, 1.2535, 1.2768, 1.2386, 1.2295, 1.2524, 1.2255, 1.2255,
         1.2611, 1.3507, 1.2299, 1.2704, 1.3323, 1.2511, 1.2692, 1.1987, 1.2361,
         1.3442, 1.3821, 1.3628, 1.3573, 1.3777, 1.3249, 1.3429, 1.4161, 1.3631,
         1.3687, 1.3174, 1.3109, 1.2708, 1.3696, 1.3040, 1.3840, 1.2813, 1.2784],
        [1.2787, 1.1374, 1.0064, 1.2328, 1.2708, 1.3254, 1.2531, 1.3168, 1.3168,
         1.3770, 1.6515, 1.2502, 2.1545, 1.3336, 2.9573, 1.3854, 1.1882, 2.6312,
         1.1299, 1.1898, 0.8476, 1.1542, 1.2792, 1.3367, 1.3181, 1.3331, 1.3331,
         1.3078, 1.0452, 1.3621, 1.3325, 1.0797, 1.3843, 1.3838, 1.3424, 1.3176,
         1.3242, 1.5021, 1.4418, 1.3486, 1.2826, 1.4568, 1.4210, 0.4808, 1.2710,
         0.9477, 1.4375, 1.4179, 1.3882, 1.0268, 1.4190, 0.7385, 1.3997, 1.3970],
        [1.2229, 1.2487, 1.3031, 1.2889, 1.2323, 1.2280, 1.2446, 1.2209, 1.2209,
         1.2908, 1.3003, 1.3256, 1.3266, 1.2799, 1.2828, 1.2997, 1.2627, 1.2307,
         1.8521, 1.9959, 2.1233, 2.0097, 1.6951, 1.7339, 1.8810, 1.6691, 1.6691,
         1.2925, 1.3023, 1.2435, 1.2842, 1.2966, 1.2648, 1.2851, 1.2557, 1.2498,
         1.3524, 1.3917, 1.3720, 1.3259, 1.3864, 1.3913, 1.3544, 1.2710, 1.2560,
         1.2846, 1.3327, 1.3259, 1.2836, 1.2602, 1.3189, 1.3565, 1.2941, 1.2914],
        [1.1978, 1.2330, 1.1811, 1.1493, 1.2333, 1.2019, 1.2150, 1.1942, 1.1942,
         1.2489, 1.1713, 1.2662, 1.2029, 1.2365, 1.2277, 1.2594, 1.2472, 0.9715,
         1.2583, 1.1962, 1.3027, 1.2720, 1.2140, 1.1725, 1.2457, 1.2091, 1.2091,
         2.0704, 1.7588, 1.6253, 1.7127, 2.0290, 1.6183, 2.0095, 1.6353, 1.6115,
         1.3149, 1.2969, 1.2520, 1.2716, 1.3435, 1.2329, 1.2826, 1.0588, 1.2756,
         1.3272, 1.1873, 1.0895, 1.1686, 1.3138, 1.0905, 1.3744, 1.1797, 1.2278],
        [1.5285, 1.2326, 0.4156, 0.6401, 1.0144, 1.4103, 1.3357, 1.5245, 1.5245,
         1.4543, 1.2360, 1.2471, 0.8466, 1.5144, 0.1417, 1.3916, 1.5184, 1.1288,
         1.1100, 0.7145, 0.6622, 0.9206, 1.4088, 1.4866, 1.1465, 1.5346, 1.5346,
         0.5580, 0.5976, 1.5065, 1.2636, 0.7401, 1.5144, 0.9796, 1.5434, 1.4938,
         1.1283, 0.7668, 0.7043, 1.0338, 1.4974, 1.6743, 0.9812, 3.3391, 3.1321,
         0.6417, 1.0889, 1.1749, 1.4434, 0.8310, 1.4106, 0.3132, 1.3964, 1.5529],
        [1.2786, 1.3144, 1.4027, 1.3656, 1.3184, 1.2757, 1.2508, 1.2753, 1.2753,
         1.2318, 1.2979, 1.2252, 1.3658, 1.3072, 1.4623, 1.2395, 1.3177, 1.2684,
         1.3422, 1.3832, 1.3796, 1.3524, 1.3107, 1.2976, 1.2710, 1.2936, 1.2936,
         1.3267, 1.3613, 1.2794, 1.1223, 1.1912, 1.0595, 1.3098, 1.1529, 1.2860,
         1.3916, 1.1141, 1.4127, 1.4006, 1.0140, 0.9296, 1.3924, 1.3712, 0.8730,
         2.2329, 1.7974, 1.9903, 1.9445, 1.7113, 1.3564, 2.2043, 1.8560, 1.3365]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 36 : 182.71780224390443
Test loss for epoch 36 : 182.72779111332346
Test Precision for epoch 36 : 0.26153846153846155
Test Recall for epoch 36 : 0.26153846153846155
Test F1 for epoch 36 : 0.26153846153846155


theta for epoch 37 : tensor([[1.7840, 1.8689, 1.9734, 1.9775, 1.9588, 1.8024, 1.8645, 1.7816, 1.7816,
         1.2814, 1.2939, 1.3129, 1.3130, 1.2717, 1.3589, 1.2894, 1.2809, 1.2695,
         1.2657, 1.2501, 1.2490, 1.2715, 1.2366, 1.2281, 1.2492, 1.2245, 1.2245,
         1.2667, 1.3521, 1.2331, 1.2733, 1.3347, 1.2539, 1.2729, 1.2024, 1.2393,
         1.3362, 1.3749, 1.3554, 1.3492, 1.3695, 1.3177, 1.3351, 1.4102, 1.3573,
         1.3730, 1.3202, 1.3133, 1.2736, 1.3732, 1.3071, 1.3908, 1.2840, 1.2815],
        [1.2774, 1.1379, 0.9999, 1.2296, 1.2702, 1.3231, 1.2515, 1.3147, 1.3147,
         1.3837, 1.6592, 1.2586, 2.1707, 1.3415, 2.9977, 1.3943, 1.1974, 2.6653,
         1.1273, 1.1853, 0.8471, 1.1520, 1.2766, 1.3302, 1.3116, 1.3268, 1.3268,
         1.3066, 1.0491, 1.3593, 1.3311, 1.0832, 1.3813, 1.3825, 1.3388, 1.3157,
         1.3139, 1.4918, 1.4302, 1.3378, 1.2754, 1.4468, 1.4091, 0.4781, 1.2655,
         0.9550, 1.4370, 1.4178, 1.3879, 1.0327, 1.4190, 0.7465, 1.3992, 1.3969],
        [1.2265, 1.2498, 1.3005, 1.2874, 1.2331, 1.2316, 1.2470, 1.2248, 1.2248,
         1.2879, 1.2983, 1.3209, 1.3220, 1.2775, 1.2849, 1.2961, 1.2621, 1.2269,
         1.8606, 2.0052, 2.1328, 2.0199, 1.7054, 1.7459, 1.8923, 1.6802, 1.6802,
         1.2986, 1.3059, 1.2448, 1.2853, 1.3030, 1.2657, 1.2865, 1.2568, 1.2510,
         1.3434, 1.3834, 1.3635, 1.3184, 1.3773, 1.3819, 1.3453, 1.2688, 1.2567,
         1.2899, 1.3340, 1.3270, 1.2853, 1.2674, 1.3206, 1.3635, 1.2957, 1.2933],
        [1.2018, 1.2361, 1.1861, 1.1566, 1.2374, 1.2067, 1.2189, 1.1985, 1.1985,
         1.2526, 1.1760, 1.2713, 1.2093, 1.2407, 1.2305, 1.2626, 1.2511, 0.9797,
         1.2589, 1.2024, 1.3023, 1.2723, 1.2166, 1.1748, 1.2466, 1.2107, 1.2107,
         2.0844, 1.7675, 1.6309, 1.7199, 2.0429, 1.6240, 2.0227, 1.6411, 1.6170,
         1.3101, 1.2951, 1.2493, 1.2671, 1.3395, 1.2330, 1.2791, 1.0597, 1.2742,
         1.3329, 1.1941, 1.0977, 1.1736, 1.3209, 1.0983, 1.3796, 1.1846, 1.2325],
        [1.5240, 1.2272, 0.4145, 0.6381, 1.0082, 1.4039, 1.3303, 1.5202, 1.5202,
         1.4500, 1.2296, 1.2473, 0.8386, 1.5109, 0.1281, 1.3918, 1.5152, 1.1256,
         1.1051, 0.7084, 0.6467, 0.9128, 1.4006, 1.4812, 1.1439, 1.5288, 1.5288,
         0.5574, 0.5993, 1.5054, 1.2623, 0.7389, 1.5139, 0.9786, 1.5439, 1.4936,
         1.1197, 0.7550, 0.6920, 1.0251, 1.4953, 1.6781, 0.9708, 3.4058, 3.1912,
         0.6417, 1.0964, 1.1799, 1.4448, 0.8352, 1.4131, 0.3109, 1.4018, 1.5559],
        [1.2813, 1.3163, 1.4037, 1.3668, 1.3244, 1.2814, 1.2541, 1.2782, 1.2782,
         1.2409, 1.3066, 1.2327, 1.3729, 1.3146, 1.4656, 1.2477, 1.3245, 1.2723,
         1.3406, 1.3837, 1.3869, 1.3547, 1.3100, 1.2970, 1.2707, 1.2930, 1.2930,
         1.3340, 1.3758, 1.2845, 1.1327, 1.1994, 1.0688, 1.3173, 1.1597, 1.2911,
         1.3851, 1.1128, 1.4068, 1.3953, 1.0144, 0.9323, 1.3859, 1.3744, 0.8775,
         2.2406, 1.8039, 2.0013, 1.9537, 1.7089, 1.3574, 2.2103, 1.8649, 1.3374]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 37 : 182.66848400758636
Test loss for epoch 37 : 182.68705558857812
Test Precision for epoch 37 : 0.26153846153846155
Test Recall for epoch 37 : 0.26153846153846155
Test F1 for epoch 37 : 0.26153846153846155


theta for epoch 38 : tensor([[1.7948, 1.8776, 1.9806, 1.9876, 1.9677, 1.8123, 1.8758, 1.7923, 1.7923,
         1.2752, 1.2867, 1.3049, 1.3054, 1.2661, 1.3495, 1.2825, 1.2750, 1.2603,
         1.2627, 1.2443, 1.2468, 1.2682, 1.2364, 1.2285, 1.2479, 1.2253, 1.2253,
         1.2770, 1.3581, 1.2413, 1.2809, 1.3417, 1.2614, 1.2814, 1.2109, 1.2473,
         1.3270, 1.3663, 1.3467, 1.3399, 1.3598, 1.3088, 1.3261, 1.4026, 1.3496,
         1.3769, 1.3229, 1.3157, 1.2767, 1.3765, 1.3102, 1.3970, 1.2867, 1.2847],
        [1.2772, 1.1388, 0.9941, 1.2272, 1.2704, 1.3219, 1.2509, 1.3137, 1.3137,
         1.3874, 1.6634, 1.2643, 2.1832, 1.3466, 3.0347, 1.4004, 1.2039, 2.6962,
         1.1269, 1.1831, 0.8493, 1.1521, 1.2767, 1.3264, 1.3078, 1.3233, 1.3233,
         1.3107, 1.0581, 1.3618, 1.3350, 1.0921, 1.3834, 1.3864, 1.3404, 1.3191,
         1.3027, 1.4804, 1.4178, 1.3261, 1.2674, 1.4356, 1.3963, 0.4745, 1.2592,
         0.9631, 1.4372, 1.4183, 1.3885, 1.0395, 1.4197, 0.7553, 1.3995, 1.3977],
        [1.2287, 1.2498, 1.2974, 1.2849, 1.2327, 1.2338, 1.2478, 1.2274, 1.2274,
         1.2809, 1.2920, 1.3121, 1.3132, 1.2710, 1.2824, 1.2883, 1.2573, 1.2186,
         1.8708, 2.0158, 2.1436, 2.0314, 1.7175, 1.7597, 1.9051, 1.6932, 1.6932,
         1.3091, 1.3138, 1.2508, 1.2909, 1.3137, 1.2711, 1.2926, 1.2625, 1.2569,
         1.3330, 1.3736, 1.3536, 1.3095, 1.3666, 1.3708, 1.3348, 1.2646, 1.2555,
         1.2948, 1.3351, 1.3280, 1.2871, 1.2739, 1.3221, 1.3696, 1.2972, 1.2952],
        [1.2075, 1.2408, 1.1925, 1.1651, 1.2429, 1.2129, 1.2244, 1.2043, 1.2043,
         1.2545, 1.1790, 1.2742, 1.2141, 1.2431, 1.2317, 1.2640, 1.2532, 0.9864,
         1.2623, 1.2109, 1.3048, 1.2755, 1.2221, 1.1801, 1.2503, 1.2153, 1.2153,
         2.0977, 1.7758, 1.6360, 1.7266, 2.0561, 1.6293, 2.0352, 1.6465, 1.6222,
         1.3049, 1.2930, 1.2465, 1.2624, 1.3349, 1.2326, 1.2753, 1.0603, 1.2721,
         1.3397, 1.2022, 1.1073, 1.1802, 1.3290, 1.1077, 1.3857, 1.1910, 1.2388],
        [1.5224, 1.2254, 0.4177, 0.6403, 1.0065, 1.4010, 1.3285, 1.5188, 1.5188,
         1.4457, 1.2240, 1.2478, 0.8324, 1.5074, 0.1178, 1.3921, 1.5121, 1.1231,
         1.1051, 0.7079, 0.6372, 0.9103, 1.3966, 1.4797, 1.1456, 1.5267, 1.5267,
         0.5634, 0.6074, 1.5095, 1.2668, 0.7439, 1.5185, 0.9842, 1.5494, 1.4987,
         1.1062, 0.7392, 0.6757, 1.0116, 1.4879, 1.6765, 0.9558, 3.4693, 3.2467,
         0.6474, 1.1078, 1.1887, 1.4498, 0.8444, 1.4190, 0.3143, 1.4106, 1.5618],
        [1.2795, 1.3136, 1.3998, 1.3633, 1.3253, 1.2824, 1.2526, 1.2766, 1.2766,
         1.2393, 1.3045, 1.2293, 1.3693, 1.3121, 1.4583, 1.2452, 1.3215, 1.2655,
         1.3361, 1.3808, 1.3903, 1.3536, 1.3064, 1.2936, 1.2674, 1.2896, 1.2896,
         1.3421, 1.3906, 1.2907, 1.1435, 1.2079, 1.0784, 1.3258, 1.1672, 1.2972,
         1.3745, 1.1066, 1.3969, 1.3858, 1.0096, 0.9292, 1.3754, 1.3719, 0.8748,
         2.2550, 1.8176, 2.0192, 1.9698, 1.7136, 1.3657, 2.2229, 1.8810, 1.3457]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 38 : 182.6191439808432
Test loss for epoch 38 : 182.63814312433408
Test Precision for epoch 38 : 0.26153846153846155
Test Recall for epoch 38 : 0.26153846153846155
Test F1 for epoch 38 : 0.26153846153846155


theta for epoch 39 : tensor([[1.8045, 1.8852, 1.9865, 1.9964, 1.9753, 1.8212, 1.8860, 1.8021, 1.8021,
         1.2701, 1.2806, 1.2978, 1.2989, 1.2615, 1.3413, 1.2765, 1.2699, 1.2520,
         1.2630, 1.2420, 1.2482, 1.2682, 1.2393, 1.2319, 1.2498, 1.2291, 1.2291,
         1.2868, 1.3639, 1.2495, 1.2884, 1.3483, 1.2689, 1.2897, 1.2193, 1.2554,
         1.3220, 1.3618, 1.3423, 1.3348, 1.3542, 1.3039, 1.3215, 1.3987, 1.3457,
         1.3764, 1.3215, 1.3141, 1.2760, 1.3755, 1.3094, 1.3986, 1.2856, 1.2841],
        [1.2783, 1.1408, 0.9900, 1.2262, 1.2718, 1.3223, 1.2518, 1.3143, 1.3143,
         1.3884, 1.6645, 1.2677, 2.1920, 1.3492, 3.0686, 1.4040, 1.2081, 2.7241,
         1.1299, 1.1845, 0.8554, 1.1555, 1.2803, 1.3266, 1.3078, 1.3237, 1.3237,
         1.3157, 1.0679, 1.3653, 1.3399, 1.1019, 1.3864, 1.3911, 1.3430, 1.3237,
         1.2967, 1.4736, 1.4103, 1.3195, 1.2642, 1.4289, 1.3884, 0.4756, 1.2579,
         0.9683, 1.4340, 1.4156, 1.3861, 1.0433, 1.4172, 0.7613, 1.3967, 1.3954],
        [1.2304, 1.2495, 1.2948, 1.2823, 1.2319, 1.2355, 1.2476, 1.2293, 1.2293,
         1.2749, 1.2868, 1.3043, 1.3057, 1.2656, 1.2801, 1.2817, 1.2534, 1.2113,
         1.8808, 2.0260, 2.1537, 2.0424, 1.7296, 1.7736, 1.9176, 1.7062, 1.7062,
         1.3192, 1.3214, 1.2570, 1.2965, 1.3241, 1.2766, 1.2987, 1.2684, 1.2629,
         1.3271, 1.3681, 1.3481, 1.3050, 1.3600, 1.3638, 1.3288, 1.2641, 1.2581,
         1.2957, 1.3323, 1.3250, 1.2852, 1.2761, 1.3199, 1.3712, 1.2950, 1.2934],
        [1.2133, 1.2456, 1.1987, 1.1732, 1.2485, 1.2193, 1.2299, 1.2103, 1.2103,
         1.2575, 1.1831, 1.2779, 1.2200, 1.2466, 1.2340, 1.2663, 1.2564, 0.9937,
         1.2679, 1.2210, 1.3094, 1.2808, 1.2297, 1.1876, 1.2562, 1.2221, 1.2221,
         2.1100, 1.7833, 1.6405, 1.7326, 2.0684, 1.6339, 2.0468, 1.6512, 1.6267,
         1.3033, 1.2945, 1.2473, 1.2614, 1.3336, 1.2357, 1.2753, 1.0639, 1.2733,
         1.3436, 1.2077, 1.1143, 1.1844, 1.3341, 1.1146, 1.3888, 1.1949, 1.2426],
        [1.5213, 1.2245, 0.4219, 0.6434, 1.0064, 1.3990, 1.3277, 1.5179, 1.5179,
         1.4429, 1.2201, 1.2495, 0.8280, 1.5054, 0.1097, 1.3937, 1.5105, 1.1220,
         1.1077, 0.7100, 0.6309, 0.9107, 1.3951, 1.4804, 1.1493, 1.5268, 1.5268,
         0.5704, 0.6165, 1.5140, 1.2719, 0.7497, 1.5234, 0.9909, 1.5550, 1.5041,
         1.0927, 0.7239, 0.6600, 0.9982, 1.4800, 1.6743, 0.9411, 3.5331, 3.3023,
         0.6504, 1.1153, 1.1938, 1.4512, 0.8505, 1.4214, 0.3150, 1.4157, 1.5641],
        [1.2746, 1.3078, 1.3925, 1.3565, 1.3226, 1.2801, 1.2480, 1.2720, 1.2720,
         1.2347, 1.2993, 1.2227, 1.3628, 1.3071, 1.4478, 1.2397, 1.3159, 1.2557,
         1.3309, 1.3767, 1.3919, 1.3512, 1.3020, 1.2895, 1.2631, 1.2855, 1.2855,
         1.3480, 1.4027, 1.2951, 1.1520, 1.2141, 1.0858, 1.3322, 1.1728, 1.3016,
         1.3669, 1.1030, 1.3899, 1.3791, 1.0068, 0.9279, 1.3678, 1.3710, 0.8724,
         2.2713, 1.8334, 2.0393, 1.9881, 1.7204, 1.3764, 2.2374, 1.8994, 1.3564]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 39 : 182.59874642455267
Test loss for epoch 39 : 182.61651698941026
Test Precision for epoch 39 : 0.26153846153846155
Test Recall for epoch 39 : 0.26153846153846155
Test F1 for epoch 39 : 0.26153846153846155


theta for epoch 40 : tensor([[1.8137, 1.8920, 1.9916, 2.0044, 1.9822, 1.8295, 1.8956, 1.8113, 1.8113,
         1.2708, 1.2804, 1.2967, 1.2984, 1.2628, 1.3391, 1.2765, 1.2707, 1.2497,
         1.2646, 1.2415, 1.2513, 1.2696, 1.2434, 1.2364, 1.2530, 1.2339, 1.2339,
         1.2910, 1.3641, 1.2527, 1.2906, 1.3494, 1.2712, 1.2927, 1.2226, 1.2584,
         1.3236, 1.3638, 1.3444, 1.3362, 1.3550, 1.3053, 1.3234, 1.4008, 1.3478,
         1.3707, 1.3149, 1.3074, 1.2703, 1.3692, 1.3034, 1.3946, 1.2796, 1.2786],
        [1.2817, 1.1447, 0.9883, 1.2275, 1.2753, 1.3252, 1.2550, 1.3172, 1.3172,
         1.3895, 1.6653, 1.2715, 2.2000, 1.3520, 3.1015, 1.4079, 1.2127, 2.7515,
         1.1344, 1.1876, 0.8636, 1.1605, 1.2858, 1.3289, 1.3097, 1.3262, 1.3262,
         1.3163, 1.0732, 1.3649, 1.3407, 1.1073, 1.3854, 1.3917, 1.3417, 1.3243,
         1.2978, 1.4737, 1.4097, 1.3199, 1.2680, 1.4290, 1.3876, 0.4829, 1.2637,
         0.9689, 1.4260, 1.4081, 1.3792, 1.0423, 1.4100, 0.7629, 1.3893, 1.3886],
        [1.2353, 1.2529, 1.2963, 1.2835, 1.2348, 1.2404, 1.2506, 1.2344, 1.2344,
         1.2758, 1.2882, 1.3033, 1.3050, 1.2670, 1.2833, 1.2817, 1.2561, 1.2106,
         1.8877, 2.0326, 2.1603, 2.0500, 1.7386, 1.7843, 1.9267, 1.7161, 1.7161,
         1.3248, 1.3242, 1.2593, 1.2980, 1.3296, 1.2781, 1.3007, 1.2703, 1.2651,
         1.3284, 1.3696, 1.3499, 1.3078, 1.3605, 1.3638, 1.3301, 1.2700, 1.2672,
         1.2921, 1.3252, 1.3178, 1.2791, 1.2737, 1.3134, 1.3678, 1.2886, 1.2876],
        [1.2189, 1.2502, 1.2044, 1.1805, 1.2539, 1.2254, 1.2352, 1.2162, 1.2162,
         1.2645, 1.1909, 1.2853, 1.2296, 1.2541, 1.2400, 1.2726, 1.2635, 1.0036,
         1.2731, 1.2303, 1.3137, 1.2857, 1.2369, 1.1947, 1.2616, 1.2285, 1.2285,
         2.1214, 1.7901, 1.6442, 1.7378, 2.0797, 1.6379, 2.0575, 1.6552, 1.6306,
         1.3067, 1.3008, 1.2532, 1.2653, 1.3371, 1.2434, 1.2802, 1.0714, 1.2790,
         1.3430, 1.2087, 1.1170, 1.1844, 1.3346, 1.1173, 1.3874, 1.1947, 1.2422],
        [1.5202, 1.2234, 0.4252, 0.6458, 1.0062, 1.3971, 1.3269, 1.5170, 1.5170,
         1.4436, 1.2195, 1.2540, 0.8261, 1.5071, 0.1032, 1.3986, 1.5126, 1.1237,
         1.1101, 0.7115, 0.6247, 0.9108, 1.3934, 1.4809, 1.1523, 1.5267, 1.5267,
         0.5733, 0.6215, 1.5142, 1.2727, 0.7513, 1.5238, 0.9934, 1.5563, 1.5051,
         1.0823, 0.7122, 0.6480, 0.9880, 1.4748, 1.6747, 0.9296, 3.5994, 3.3606,
         0.6465, 1.1150, 1.1915, 1.4462, 0.8491, 1.4170, 0.3087, 1.4138, 1.5599],
        [1.2705, 1.3026, 1.3854, 1.3502, 1.3202, 1.2783, 1.2440, 1.2681, 1.2681,
         1.2356, 1.2996, 1.2216, 1.3621, 1.3081, 1.4423, 1.2397, 1.3163, 1.2519,
         1.3262, 1.3725, 1.3929, 1.3489, 1.2981, 1.2858, 1.2594, 1.2820, 1.2820,
         1.3492, 1.4095, 1.2953, 1.1560, 1.2157, 1.0889, 1.3341, 1.1741, 1.3017,
         1.3663, 1.1063, 1.3899, 1.3792, 1.0108, 0.9328, 1.3673, 1.3756, 0.8750,
         2.2850, 1.8468, 2.0571, 2.0041, 1.7248, 1.3849, 2.2493, 1.9153, 1.3649]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 40 : 182.55294846779168
Test loss for epoch 40 : 182.5734959251773
Test Precision for epoch 40 : 0.26153846153846155
Test Recall for epoch 40 : 0.26153846153846155
Test F1 for epoch 40 : 0.26153846153846155


theta for epoch 41 : tensor([[1.8217, 1.8977, 1.9955, 2.0112, 1.9879, 1.8368, 1.9040, 1.8194, 1.8194,
         1.2760, 1.2848, 1.3000, 1.3024, 1.2685, 1.3417, 1.2808, 1.2760, 1.2520,
         1.2653, 1.2405, 1.2538, 1.2704, 1.2462, 1.2396, 1.2553, 1.2374, 1.2374,
         1.2890, 1.3585, 1.2504, 1.2873, 1.3446, 1.2681, 1.2900, 1.2203, 1.2559,
         1.3305, 1.3709, 1.3518, 1.3429, 1.3609, 1.3117, 1.3305, 1.4077, 1.3547,
         1.3635, 1.3071, 1.2994, 1.2635, 1.3614, 1.2962, 1.3890, 1.2723, 1.2719],
        [1.2863, 1.1495, 0.9884, 1.2302, 1.2800, 1.3295, 1.2596, 1.3217, 1.3217,
         1.3900, 1.6651, 1.2749, 2.2064, 1.3543, 3.1329, 1.4112, 1.2171, 2.7776,
         1.1390, 1.1910, 0.8727, 1.1656, 1.2914, 1.3316, 1.3121, 1.3293, 1.3293,
         1.3123, 1.0735, 1.3605, 1.3372, 1.1079, 1.3802, 1.3878, 1.3363, 1.3209,
         1.3047, 1.4793, 1.4149, 1.3260, 1.2775, 1.4346, 1.3925, 0.4954, 1.2752,
         0.9687, 1.4172, 1.3998, 1.3716, 1.0406, 1.4020, 0.7641, 1.3811, 1.3811],
        [1.2417, 1.2582, 1.3004, 1.2869, 1.2397, 1.2469, 1.2550, 1.2410, 1.2410,
         1.2819, 1.2947, 1.3076, 1.3096, 1.2736, 1.2908, 1.2870, 1.2638, 1.2150,
         1.8909, 2.0354, 2.1630, 2.0538, 1.7442, 1.7915, 1.9321, 1.7226, 1.7226,
         1.3251, 1.3217, 1.2572, 1.2949, 1.3298, 1.2752, 1.2980, 1.2676, 1.2628,
         1.3355, 1.3769, 1.3574, 1.3165, 1.3667, 1.3693, 1.3372, 1.2809, 1.2816,
         1.2878, 1.3174, 1.3100, 1.2726, 1.2702, 1.3064, 1.3634, 1.2816, 1.2811],
        [1.2222, 1.2524, 1.2075, 1.1850, 1.2568, 1.2291, 1.2381, 1.2196, 1.2196,
         1.2726, 1.1995, 1.2934, 1.2401, 1.2627, 1.2469, 1.2799, 1.2716, 1.0135,
         1.2751, 1.2359, 1.3150, 1.2874, 1.2409, 1.1984, 1.2638, 1.2318, 1.2318,
         2.1333, 1.7976, 1.6488, 1.7438, 2.0917, 1.6427, 2.0689, 1.6601, 1.6353,
         1.3132, 1.3101, 1.2621, 1.2722, 1.3435, 1.2540, 1.2882, 1.0811, 1.2875,
         1.3400, 1.2074, 1.1173, 1.1822, 1.3327, 1.1177, 1.3835, 1.1921, 1.2396],
        [1.5190, 1.2222, 0.4279, 0.6476, 1.0062, 1.3954, 1.3262, 1.5160, 1.5160,
         1.4472, 1.2218, 1.2607, 0.8265, 1.5118, 0.0987, 1.4061, 1.5179, 1.1277,
         1.1117, 0.7121, 0.6185, 0.9103, 1.3909, 1.4805, 1.1540, 1.5258, 1.5258,
         0.5725, 0.6230, 1.5103, 1.2694, 0.7490, 1.5201, 0.9920, 1.5532, 1.5021,
         1.0738, 0.7030, 0.6385, 0.9799, 1.4712, 1.6766, 0.9202, 3.6672, 3.4205,
         0.6402, 1.1119, 1.1865, 1.4392, 0.8452, 1.4105, 0.2999, 1.4096, 1.5537],
        [1.2675, 1.2986, 1.3790, 1.3449, 1.3182, 1.2773, 1.2411, 1.2653, 1.2653,
         1.2417, 1.3050, 1.2257, 1.3666, 1.3145, 1.4416, 1.2450, 1.3222, 1.2536,
         1.3216, 1.3681, 1.3930, 1.3461, 1.2943, 1.2824, 1.2559, 1.2786, 1.2786,
         1.3462, 1.4114, 1.2918, 1.1559, 1.2131, 1.0882, 1.3319, 1.1718, 1.2980,
         1.3718, 1.1157, 1.3959, 1.3854, 1.0207, 0.9435, 1.3729, 1.3850, 0.8823,
         2.2964, 1.8581, 2.0726, 2.0179, 1.7271, 1.3915, 2.2589, 1.9292, 1.3716]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 41 : 182.5029960334925
Test loss for epoch 41 : 182.52867332405094
Test Precision for epoch 41 : 0.26153846153846155
Test Recall for epoch 41 : 0.26153846153846155
Test F1 for epoch 41 : 0.26153846153846155


theta for epoch 42 : tensor([[1.8285, 1.9020, 1.9981, 2.0165, 1.9921, 1.8427, 1.9112, 1.8262, 1.8262,
         1.2798, 1.2879, 1.3021, 1.3053, 1.2727, 1.3433, 1.2838, 1.2797, 1.2530,
         1.2659, 1.2399, 1.2565, 1.2711, 1.2487, 1.2424, 1.2573, 1.2403, 1.2403,
         1.2853, 1.3514, 1.2471, 1.2827, 1.3383, 1.2638, 1.2860, 1.2170, 1.2524,
         1.3385, 1.3791, 1.3603, 1.3506, 1.3678, 1.3190, 1.3388, 1.4152, 1.3623,
         1.3591, 1.3021, 1.2943, 1.2596, 1.3564, 1.2919, 1.3860, 1.2679, 1.2681],
        [1.2912, 1.1545, 0.9895, 1.2332, 1.2849, 1.3342, 1.2644, 1.3265, 1.3265,
         1.3871, 1.6611, 1.2752, 2.2087, 1.3532, 3.1606, 1.4112, 1.2182, 2.8001,
         1.1445, 1.1956, 0.8834, 1.1717, 1.2981, 1.3357, 1.3159, 1.3336, 1.3336,
         1.3081, 1.0733, 1.3562, 1.3338, 1.1082, 1.3750, 1.3838, 1.3310, 1.3176,
         1.3133, 1.4863, 1.4216, 1.3338, 1.2885, 1.4416, 1.3990, 0.5091, 1.2885,
         0.9725, 1.4122, 1.3953, 1.3678, 1.0427, 1.3978, 0.7692, 1.3768, 1.3774],
        [1.2453, 1.2611, 1.3029, 1.2884, 1.2424, 1.2505, 1.2566, 1.2448, 1.2448,
         1.2864, 1.2995, 1.3104, 1.3129, 1.2785, 1.2964, 1.2908, 1.2698, 1.2177,
         1.8941, 2.0380, 2.1653, 2.0573, 1.7499, 1.7987, 1.9373, 1.7291, 1.7291,
         1.3235, 1.3172, 1.2539, 1.2905, 1.3281, 1.2710, 1.2940, 1.2638, 1.2593,
         1.3436, 1.3850, 1.3659, 1.3260, 1.3736, 1.3757, 1.3453, 1.2921, 1.2963,
         1.2861, 1.3123, 1.3049, 1.2689, 1.2690, 1.3020, 1.3611, 1.2774, 1.2775],
        [1.2211, 1.2504, 1.2061, 1.1849, 1.2554, 1.2283, 1.2367, 1.2187, 1.2187,
         1.2757, 1.2031, 1.2965, 1.2456, 1.2663, 1.2491, 1.2823, 1.2748, 1.0181,
         1.2734, 1.2375, 1.3126, 1.2853, 1.2410, 1.1983, 1.2623, 1.2313, 1.2313,
         2.1481, 1.8082, 1.6565, 1.7528, 2.1066, 1.6506, 2.0831, 1.6680, 1.6431,
         1.3188, 1.3185, 1.2700, 1.2783, 1.3489, 1.2634, 1.2953, 1.0893, 1.2947,
         1.3374, 1.2063, 1.1176, 1.1804, 1.3310, 1.1181, 1.3800, 1.1899, 1.2375],
        [1.5186, 1.2224, 0.4323, 0.6510, 1.0081, 1.3949, 1.3269, 1.5158, 1.5158,
         1.4510, 1.2247, 1.2676, 0.8282, 1.5167, 0.0966, 1.4136, 1.5233, 1.1320,
         1.1153, 0.7150, 0.6155, 0.9122, 1.3902, 1.4815, 1.1572, 1.5263, 1.5263,
         0.5732, 0.6258, 1.5069, 1.2671, 0.7478, 1.5168, 0.9920, 1.5506, 1.4995,
         1.0631, 0.6923, 0.6276, 0.9697, 1.4650, 1.6757, 0.9089, 3.7338, 3.4788,
         0.6395, 1.1130, 1.1860, 1.4369, 0.8464, 1.4084, 0.2966, 1.4097, 1.5518],
        [1.2645, 1.2945, 1.3725, 1.3394, 1.3158, 1.2759, 1.2381, 1.2625, 1.2625,
         1.2463, 1.3088, 1.2285, 1.3697, 1.3196, 1.4396, 1.2488, 1.3268, 1.2543,
         1.3178, 1.3640, 1.3926, 1.3436, 1.2913, 1.2796, 1.2531, 1.2760, 1.2760,
         1.3424, 1.4119, 1.2880, 1.1553, 1.2098, 1.0873, 1.3291, 1.1692, 1.2940,
         1.3786, 1.1266, 1.4033, 1.3929, 1.0318, 0.9551, 1.3799, 1.3945, 0.8896,
         2.3077, 1.8696, 2.0883, 2.0317, 1.7296, 1.3987, 2.2684, 1.9433, 1.3788]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 42 : 182.47403795527816
Test loss for epoch 42 : 182.50153065704174
Test Precision for epoch 42 : 0.26153846153846155
Test Recall for epoch 42 : 0.26153846153846155
Test F1 for epoch 42 : 0.26153846153846155


theta for epoch 43 : tensor([[1.8357, 1.9067, 2.0010, 2.0222, 1.9968, 1.8491, 1.9188, 1.8334, 1.8334,
         1.2797, 1.2872, 1.3005, 1.3045, 1.2729, 1.3417, 1.2829, 1.2795, 1.2502,
         1.2675, 1.2407, 1.2603, 1.2731, 1.2518, 1.2457, 1.2603, 1.2438, 1.2438,
         1.2835, 1.3464, 1.2462, 1.2804, 1.3340, 1.2618, 1.2841, 1.2158, 1.2511,
         1.3426, 1.3832, 1.3648, 1.3544, 1.3706, 1.3221, 1.3432, 1.4184, 1.3656,
         1.3589, 1.3013, 1.2935, 1.2601, 1.3555, 1.2917, 1.3870, 1.2679, 1.2686],
        [1.2962, 1.1594, 0.9914, 1.2367, 1.2899, 1.3393, 1.2696, 1.3317, 1.3317,
         1.3824, 1.6550, 1.2737, 2.2083, 1.3503, 3.1860, 1.4095, 1.2177, 2.8205,
         1.1507, 1.2011, 0.8950, 1.1785, 1.3057, 1.3410, 1.3209, 1.3393, 1.3393,
         1.3063, 1.0752, 1.3547, 1.3330, 1.1107, 1.3726, 1.3823, 1.3285, 1.3171,
         1.3181, 1.4895, 1.4245, 1.3378, 1.2956, 1.4446, 1.4017, 0.5188, 1.2979,
         0.9806, 1.4118, 1.3954, 1.3687, 1.0492, 1.3982, 0.7787, 1.3772, 1.3784],
        [1.2468, 1.2623, 1.3042, 1.2884, 1.2435, 1.2521, 1.2561, 1.2463, 1.2463,
         1.2865, 1.2998, 1.3089, 1.3119, 1.2790, 1.2974, 1.2901, 1.2710, 1.2159,
         1.8999, 2.0428, 2.1698, 2.0630, 1.7582, 1.8085, 1.9449, 1.7383, 1.7383,
         1.3230, 1.3139, 1.2524, 1.2876, 1.3274, 1.2684, 1.2914, 1.2617, 1.2575,
         1.3473, 1.3887, 1.3701, 1.3312, 1.3762, 1.3775, 1.3491, 1.2984, 1.3060,
         1.2880, 1.3110, 1.3035, 1.2689, 1.2712, 1.3013, 1.3622, 1.2769, 1.2776],
        [1.2174, 1.2458, 1.2020, 1.1819, 1.2514, 1.2249, 1.2326, 1.2152, 1.2152,
         1.2729, 1.2006, 1.2935, 1.2451, 1.2639, 1.2456, 1.2787, 1.2719, 1.0166,
         1.2697, 1.2366, 1.3083, 1.2812, 1.2389, 1.1960, 1.2587, 1.2287, 1.2287,
         2.1660, 1.8221, 1.6675, 1.7651, 2.1245, 1.6619, 2.1004, 1.6792, 1.6543,
         1.3198, 1.3222, 1.2733, 1.2796, 1.3496, 1.2680, 1.2979, 1.0926, 1.2972,
         1.3367, 1.2070, 1.1193, 1.1805, 1.3311, 1.1202, 1.3785, 1.1896, 1.2373],
        [1.5209, 1.2258, 0.4401, 0.6578, 1.0137, 1.3977, 1.3308, 1.5183, 1.5183,
         1.4544, 1.2277, 1.2741, 0.8309, 1.5210, 0.0975, 1.4206, 1.5282, 1.1363,
         1.1227, 0.7220, 0.6176, 0.9184, 1.3929, 1.4856, 1.1635, 1.5298, 1.5298,
         0.5784, 0.6330, 1.5072, 1.2689, 0.7510, 1.5170, 0.9965, 1.5514, 1.5006,
         1.0474, 0.6773, 0.6124, 0.9547, 1.4533, 1.6691, 0.8929, 3.7971, 3.5332,
         0.6469, 1.1211, 1.1927, 1.4415, 0.8554, 1.4134, 0.3016, 1.4167, 1.5566],
        [1.2632, 1.2923, 1.3677, 1.3358, 1.3146, 1.2760, 1.2369, 1.2614, 1.2614,
         1.2477, 1.3093, 1.2284, 1.3697, 1.3217, 1.4346, 1.2495, 1.3283, 1.2522,
         1.3164, 1.3618, 1.3934, 1.3429, 1.2905, 1.2791, 1.2526, 1.2757, 1.2757,
         1.3411, 1.4141, 1.2872, 1.1573, 1.2091, 1.0891, 1.3290, 1.1697, 1.2930,
         1.3818, 1.1336, 1.4070, 1.3965, 1.0389, 0.9625, 1.3832, 1.3991, 0.8920,
         2.3189, 1.8812, 2.1039, 2.0457, 1.7324, 1.4063, 2.2777, 1.9575, 1.3865]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 43 : 182.43293756406672
Test loss for epoch 43 : 182.4571975791045
Test Precision for epoch 43 : 0.26153846153846155
Test Recall for epoch 43 : 0.26153846153846155
Test F1 for epoch 43 : 0.26153846153846155


theta for epoch 44 : tensor([[1.8439, 1.9123, 2.0048, 2.0287, 2.0023, 1.8566, 1.9273, 1.8417, 1.8417,
         1.2793, 1.2863, 1.2987, 1.3034, 1.2728, 1.3399, 1.2818, 1.2789, 1.2474,
         1.2685, 1.2413, 1.2634, 1.2745, 1.2540, 1.2480, 1.2625, 1.2462, 1.2462,
         1.2835, 1.3434, 1.2473, 1.2801, 1.3317, 1.2620, 1.2842, 1.2167, 1.2520,
         1.3418, 1.3824, 1.3644, 1.3533, 1.3686, 1.3202, 1.3427, 1.4162, 1.3635,
         1.3617, 1.3036, 1.2957, 1.2636, 1.3576, 1.2946, 1.3909, 1.2708, 1.2721],
        [1.3004, 1.1630, 0.9924, 1.2391, 1.2940, 1.3437, 1.2737, 1.3362, 1.3362,
         1.3813, 1.6523, 1.2761, 2.2109, 1.3512, 3.2138, 1.4115, 1.2209, 2.8439,
         1.1540, 1.2041, 0.9040, 1.1826, 1.3110, 1.3445, 1.3239, 1.3431, 1.3431,
         1.3053, 1.0769, 1.3543, 1.3332, 1.1133, 1.3713, 1.3818, 1.3271, 1.3177,
         1.3173, 1.4871, 1.4219, 1.3360, 1.2967, 1.4419, 1.3989, 0.5218, 1.3016,
         0.9902, 1.4137, 1.3979, 1.3720, 1.0571, 1.4009, 0.7893, 1.3798, 1.3816],
        [1.2486, 1.2642, 1.3068, 1.2896, 1.2455, 1.2539, 1.2562, 1.2481, 1.2481,
         1.2861, 1.2995, 1.3070, 1.3105, 1.2788, 1.2973, 1.2889, 1.2715, 1.2134,
         1.9066, 2.0482, 2.1748, 2.0694, 1.7674, 1.8192, 1.9531, 1.7484, 1.7484,
         1.3240, 1.3121, 1.2528, 1.2867, 1.3281, 1.2679, 1.2908, 1.2615, 1.2576,
         1.3461, 1.3875, 1.3693, 1.3315, 1.3738, 1.3744, 1.3480, 1.2991, 1.3101,
         1.2927, 1.3126, 1.3051, 1.2719, 1.2757, 1.3036, 1.3658, 1.2794, 1.2805],
        [1.2145, 1.2421, 1.1985, 1.1792, 1.2481, 1.2223, 1.2294, 1.2124, 1.2124,
         1.2697, 1.1976, 1.2900, 1.2440, 1.2610, 1.2417, 1.2747, 1.2685, 1.0144,
         1.2656, 1.2349, 1.3036, 1.2768, 1.2364, 1.1933, 1.2548, 1.2258, 1.2258,
         2.1841, 1.8366, 1.6792, 1.7780, 2.1429, 1.6738, 2.1182, 1.6911, 1.6662,
         1.3168, 1.3219, 1.2726, 1.2770, 1.3461, 1.2683, 1.2965, 1.0918, 1.2953,
         1.3385, 1.2100, 1.1231, 1.1830, 1.3335, 1.1244, 1.3794, 1.1917, 1.2397],
        [1.5248, 1.2307, 0.4487, 0.6655, 1.0210, 1.4022, 1.3364, 1.5224, 1.5224,
         1.4582, 1.2312, 1.2807, 0.8343, 1.5256, 0.0995, 1.4277, 1.5334, 1.1408,
         1.1305, 0.7293, 0.6209, 0.9251, 1.3962, 1.4901, 1.1698, 1.5338, 1.5338,
         0.5851, 0.6416, 1.5094, 1.2726, 0.7558, 1.5192, 1.0029, 1.5540, 1.5035,
         1.0293, 0.6602, 0.5953, 0.9372, 1.4387, 1.6595, 0.8746, 3.8590, 3.5862,
         0.6575, 1.1320, 1.2025, 1.4498, 0.8673, 1.4219, 0.3095, 1.4270, 1.5649],
        [1.2660, 1.2942, 1.3669, 1.3364, 1.3171, 1.2799, 1.2399, 1.2644, 1.2644,
         1.2516, 1.3122, 1.2310, 1.3720, 1.3263, 1.4320, 1.2527, 1.3324, 1.2532,
         1.3175, 1.3618, 1.3955, 1.3443, 1.2923, 1.2812, 1.2548, 1.2780, 1.2780,
         1.3432, 1.4188, 1.2901, 1.1627, 1.2119, 1.0946, 1.3322, 1.1738, 1.2957,
         1.3812, 1.1371, 1.4068, 1.3962, 1.0422, 0.9661, 1.3828, 1.3986, 0.8900,
         2.3273, 1.8903, 2.1170, 2.0571, 1.7328, 1.4117, 2.2844, 1.9691, 1.3921]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 44 : 182.39640542553752
Test loss for epoch 44 : 182.41769741598014
Test Precision for epoch 44 : 0.26153846153846155
Test Recall for epoch 44 : 0.26153846153846155
Test F1 for epoch 44 : 0.26153846153846155


theta for epoch 45 : tensor([[1.8519, 1.9177, 2.0083, 2.0349, 2.0075, 1.8637, 1.9356, 1.8497, 1.8497,
         1.2807, 1.2872, 1.2987, 1.3041, 1.2743, 1.3401, 1.2824, 1.2801, 1.2465,
         1.2681, 1.2408, 1.2649, 1.2744, 1.2544, 1.2485, 1.2631, 1.2468, 1.2468,
         1.2836, 1.3407, 1.2488, 1.2802, 1.3296, 1.2625, 1.2846, 1.2180, 1.2532,
         1.3399, 1.3805, 1.3630, 1.3511, 1.3653, 1.3170, 1.3412, 1.4124, 1.3600,
         1.3651, 1.3067, 1.2988, 1.2680, 1.3604, 1.2983, 1.3953, 1.2747, 1.2765],
        [1.3024, 1.1640, 0.9913, 1.2393, 1.2956, 1.3462, 1.2757, 1.3388, 1.3388,
         1.3853, 1.6545, 1.2837, 2.2178, 1.3572, 3.2451, 1.4187, 1.2292, 2.8715,
         1.1533, 1.2034, 0.9087, 1.1827, 1.3127, 1.3449, 1.3236, 1.3437, 1.3437,
         1.3029, 1.0761, 1.3530, 1.3321, 1.1137, 1.3691, 1.3801, 1.3248, 1.3172,
         1.3144, 1.4826, 1.4172, 1.3321, 1.2954, 1.4370, 1.3941, 0.5212, 1.3031,
         0.9982, 1.4151, 1.3999, 1.3749, 1.0635, 1.4032, 0.7980, 1.3821, 1.3845],
        [1.2509, 1.2669, 1.3105, 1.2918, 1.2485, 1.2563, 1.2570, 1.2504, 1.2504,
         1.2875, 1.3008, 1.3069, 1.3109, 1.2804, 1.2982, 1.2895, 1.2735, 1.2127,
         1.9122, 2.0524, 2.1784, 2.0745, 1.7756, 1.8287, 1.9601, 1.7574, 1.7574,
         1.3250, 1.3104, 1.2537, 1.2862, 1.3288, 1.2679, 1.2905, 1.2618, 1.2582,
         1.3440, 1.3853, 1.3676, 1.3307, 1.3703, 1.3702, 1.3460, 1.2981, 1.3125,
         1.2981, 1.3151, 1.3075, 1.2757, 1.2807, 1.3067, 1.3698, 1.2827, 1.2844],
        [1.2147, 1.2416, 1.1979, 1.1791, 1.2479, 1.2226, 1.2293, 1.2128, 1.2128,
         1.2705, 1.1986, 1.2902, 1.2467, 1.2621, 1.2417, 1.2747, 1.2692, 1.0156,
         1.2635, 1.2346, 1.3009, 1.2742, 1.2357, 1.1924, 1.2527, 1.2248, 1.2248,
         2.1991, 1.8480, 1.6880, 1.7879, 2.1581, 1.6829, 2.1328, 1.7001, 1.6752,
         1.3143, 1.3220, 1.2725, 1.2749, 1.3429, 1.2689, 1.2956, 1.0912, 1.2936,
         1.3422, 1.2150, 1.1288, 1.1878, 1.3378, 1.1306, 1.3823, 1.1960, 1.2442],
        [1.5269, 1.2330, 0.4533, 0.6696, 1.0253, 1.4049, 1.3399, 1.5246, 1.5246,
         1.4605, 1.2328, 1.2851, 0.8351, 1.5290, 0.0984, 1.4331, 1.5376, 1.1431,
         1.1346, 0.7321, 0.6203, 0.9279, 1.3965, 1.4917, 1.1722, 1.5349, 1.5349,
         0.5881, 0.6466, 1.5100, 1.2741, 0.7572, 1.5196, 1.0065, 1.5549, 1.5046,
         1.0142, 0.6464, 0.5814, 0.9228, 1.4270, 1.6527, 0.8594, 3.9236, 3.6418,
         0.6635, 1.1395, 1.2094, 1.4564, 0.8751, 1.4284, 0.3122, 1.4352, 1.5717],
        [1.2726, 1.2999, 1.3697, 1.3406, 1.3229, 1.2871, 1.2466, 1.2711, 1.2711,
         1.2605, 1.3200, 1.2388, 1.3792, 1.3358, 1.4340, 1.2610, 1.3415, 1.2598,
         1.3207, 1.3635, 1.3985, 1.3473, 1.2962, 1.2854, 1.2591, 1.2825, 1.2825,
         1.3471, 1.4247, 1.2951, 1.1700, 1.2166, 1.1022, 1.3373, 1.1801, 1.3005,
         1.3811, 1.1412, 1.4072, 1.3963, 1.0461, 0.9702, 1.3830, 1.3973, 0.8882,
         2.3314, 1.8951, 2.1256, 2.0641, 1.7291, 1.4131, 2.2867, 1.9764, 1.3937]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 45 : 182.36398030490443
Test loss for epoch 45 : 182.38842537420874
Test Precision for epoch 45 : 0.26153846153846155
Test Recall for epoch 45 : 0.26153846153846155
Test F1 for epoch 45 : 0.26153846153846155


theta for epoch 46 : tensor([[1.8586, 1.9217, 2.0106, 2.0397, 2.0114, 1.8697, 1.9426, 1.8564, 1.8564,
         1.2817, 1.2878, 1.2985, 1.3045, 1.2754, 1.3400, 1.2827, 1.2807, 1.2455,
         1.2683, 1.2413, 1.2669, 1.2751, 1.2553, 1.2494, 1.2642, 1.2477, 1.2477,
         1.2833, 1.3380, 1.2501, 1.2802, 1.3276, 1.2629, 1.2846, 1.2190, 1.2542,
         1.3400, 1.3804, 1.3635, 1.3508, 1.3638, 1.3155, 1.3416, 1.4101, 1.3580,
         1.3679, 1.3093, 1.3014, 1.2719, 1.3626, 1.3016, 1.3989, 1.2781, 1.2804],
        [1.3032, 1.1636, 0.9895, 1.2382, 1.2959, 1.3476, 1.2764, 1.3403, 1.3403,
         1.3897, 1.6570, 1.2917, 2.2245, 1.3636, 3.2760, 1.4264, 1.2380, 2.8992,
         1.1518, 1.2021, 0.9127, 1.1821, 1.3139, 1.3452, 1.3231, 1.3443, 1.3443,
         1.2998, 1.0740, 1.3513, 1.3306, 1.1130, 1.3665, 1.3779, 1.3221, 1.3162,
         1.3131, 1.4797, 1.4143, 1.3299, 1.2956, 1.4336, 1.3911, 0.5213, 1.3060,
         1.0046, 1.4158, 1.4011, 1.3770, 1.0685, 1.4047, 0.8052, 1.3836, 1.3867],
        [1.2519, 1.2686, 1.3136, 1.2933, 1.2506, 1.2573, 1.2568, 1.2514, 1.2514,
         1.2882, 1.3015, 1.3064, 1.3107, 1.2813, 1.2980, 1.2896, 1.2747, 1.2115,
         1.9175, 2.0560, 2.1814, 2.0791, 1.7835, 1.8380, 1.9666, 1.7662, 1.7662,
         1.3255, 1.3082, 1.2544, 1.2856, 1.3289, 1.2677, 1.2900, 1.2620, 1.2586,
         1.3438, 1.3849, 1.3678, 1.3317, 1.3685, 1.3677, 1.3459, 1.2983, 1.3161,
         1.3027, 1.3170, 1.3095, 1.2792, 1.2846, 1.3094, 1.3728, 1.2856, 1.2878],
        [1.2184, 1.2445, 1.2006, 1.1820, 1.2510, 1.2263, 1.2326, 1.2167, 1.2167,
         1.2745, 1.2028, 1.2933, 1.2523, 1.2663, 1.2450, 1.2778, 1.2728, 1.0199,
         1.2654, 1.2378, 1.3024, 1.2758, 1.2391, 1.1958, 1.2548, 1.2279, 1.2279,
         2.2096, 1.8551, 1.6926, 1.7935, 2.1687, 1.6877, 2.1429, 1.7048, 1.6800,
         1.3153, 1.3255, 1.2759, 1.2764, 1.3430, 1.2727, 1.2983, 1.0937, 1.2950,
         1.3475, 1.2216, 1.1362, 1.1943, 1.3435, 1.1386, 1.3868, 1.2020, 1.2505],
        [1.5256, 1.2311, 0.4523, 0.6684, 1.0246, 1.4040, 1.3396, 1.5236, 1.5236,
         1.4585, 1.2296, 1.2845, 0.8303, 1.5283, 0.0915, 1.4338, 1.5376, 1.1402,
         1.1348, 0.7299, 0.6154, 0.9263, 1.3939, 1.4905, 1.1707, 1.5335, 1.5335,
         0.5860, 0.6466, 1.5077, 1.2722, 0.7538, 1.5172, 1.0057, 1.5530, 1.5029,
         1.0043, 0.6381, 0.5730, 0.9138, 1.4205, 1.6510, 0.8496, 3.9922, 3.7019,
         0.6622, 1.1411, 1.2109, 1.4591, 0.8761, 1.4309, 0.3069, 1.4390, 1.5749],
        [1.2800, 1.3065, 1.3734, 1.3458, 1.3290, 1.2949, 1.2541, 1.2786, 1.2786,
         1.2693, 1.3276, 1.2466, 1.3861, 1.3452, 1.4361, 1.2692, 1.3504, 1.2668,
         1.3254, 1.3663, 1.4020, 1.3513, 1.3015, 1.2910, 1.2648, 1.2883, 1.2883,
         1.3512, 1.4301, 1.3005, 1.1773, 1.2215, 1.1099, 1.3426, 1.1868, 1.3056,
         1.3837, 1.1480, 1.4103, 1.3989, 1.0524, 0.9764, 1.3858, 1.3976, 0.8881,
         2.3333, 1.8978, 2.1322, 2.0690, 1.7234, 1.4127, 2.2868, 1.9817, 1.3935]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 46 : 182.32280809283927
Test loss for epoch 46 : 182.35556766323248
Test Precision for epoch 46 : 0.26153846153846155
Test Recall for epoch 46 : 0.26153846153846155
Test F1 for epoch 46 : 0.26153846153846155


theta for epoch 47 : tensor([[1.8648, 1.9254, 2.0124, 2.0439, 2.0148, 1.8752, 1.9491, 1.8627, 1.8627,
         1.2799, 1.2858, 1.2957, 1.3022, 1.2736, 1.3378, 1.2802, 1.2786, 1.2421,
         1.2695, 1.2431, 1.2696, 1.2768, 1.2566, 1.2508, 1.2659, 1.2491, 1.2491,
         1.2840, 1.3366, 1.2524, 1.2811, 1.3266, 1.2644, 1.2857, 1.2209, 1.2562,
         1.3416, 1.3818, 1.3656, 1.3522, 1.3639, 1.3155, 1.3436, 1.4090, 1.3573,
         1.3696, 1.3110, 1.3032, 1.2751, 1.3637, 1.3040, 1.4012, 1.2807, 1.2836],
        [1.3044, 1.1639, 0.9892, 1.2380, 1.2966, 1.3496, 1.2776, 1.3423, 1.3423,
         1.3901, 1.6552, 1.2959, 2.2264, 1.3660, 3.3029, 1.4301, 1.2428, 2.9227,
         1.1521, 1.2028, 0.9184, 1.1833, 1.3169, 1.3475, 1.3247, 1.3469, 1.3469,
         1.2990, 1.0737, 1.3517, 1.3311, 1.1141, 1.3661, 1.3777, 1.3216, 1.3172,
         1.3144, 1.4791, 1.4139, 1.3302, 1.2980, 1.4325, 1.3907, 0.5237, 1.3112,
         1.0109, 1.4166, 1.4025, 1.3794, 1.0733, 1.4065, 0.8123, 1.3854, 1.3890],
        [1.2511, 1.2687, 1.3153, 1.2935, 1.2512, 1.2565, 1.2550, 1.2504, 1.2504,
         1.2864, 1.2995, 1.3034, 1.3082, 1.2796, 1.2954, 1.2870, 1.2731, 1.2079,
         1.9231, 2.0597, 2.1846, 2.0839, 1.7918, 1.8476, 1.9733, 1.7753, 1.7753,
         1.3267, 1.3071, 1.2561, 1.2860, 1.3298, 1.2686, 1.2906, 1.2632, 1.2601,
         1.3452, 1.3859, 1.3695, 1.3343, 1.3682, 1.3666, 1.3475, 1.2995, 1.3205,
         1.3062, 1.3181, 1.3107, 1.2818, 1.2872, 1.3113, 1.3745, 1.2876, 1.2904],
        [1.2242, 1.2497, 1.2054, 1.1868, 1.2562, 1.2321, 1.2381, 1.2226, 1.2226,
         1.2786, 1.2073, 1.2964, 1.2580, 1.2705, 1.2488, 1.2810, 1.2766, 1.0245,
         1.2708, 1.2439, 1.3074, 1.2807, 1.2456, 1.2024, 1.2602, 1.2344, 1.2344,
         2.2172, 1.8594, 1.6944, 1.7963, 2.1765, 1.6898, 2.1501, 1.7068, 1.6820,
         1.3190, 1.3316, 1.2821, 1.2806, 1.3457, 1.2789, 1.3037, 1.0987, 1.2988,
         1.3535, 1.2290, 1.1444, 1.2020, 1.3499, 1.1475, 1.3920, 1.2092, 1.2578],
        [1.5229, 1.2273, 0.4486, 0.6648, 1.0218, 1.4016, 1.3376, 1.5210, 1.5210,
         1.4527, 1.2224, 1.2796, 0.8216, 1.5238, 0.0816, 1.4304, 1.5339, 1.1333,
         1.1339, 0.7261, 0.6095, 0.9235, 1.3907, 1.4887, 1.1677, 1.5315, 1.5315,
         0.5823, 0.6451, 1.5052, 1.2697, 0.7491, 1.5144, 1.0039, 1.5508, 1.5008,
         0.9969, 0.6325, 0.5673, 0.9071, 1.4160, 1.6512, 0.8423, 4.0627, 3.7638,
         0.6573, 1.1396, 1.2096, 1.4598, 0.8736, 1.4311, 0.2981, 1.4404, 1.5762],
        [1.2850, 1.3108, 1.3749, 1.3486, 1.3325, 1.3001, 1.2590, 1.2838, 1.2838,
         1.2720, 1.3294, 1.2485, 1.3873, 1.3488, 1.4333, 1.2714, 1.3537, 1.2682,
         1.3291, 1.3681, 1.4038, 1.3540, 1.3058, 1.2956, 1.2694, 1.2931, 1.2931,
         1.3548, 1.4345, 1.3055, 1.1836, 1.2258, 1.1167, 1.3473, 1.1927, 1.3103,
         1.3870, 1.1548, 1.4141, 1.4023, 1.0585, 0.9822, 1.3895, 1.3977, 0.8873,
         2.3374, 1.9028, 2.1410, 2.0762, 1.7202, 1.4147, 2.2890, 1.9892, 1.3957]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 47 : 182.2889102510389
Test loss for epoch 47 : 182.32910537514812
Test Precision for epoch 47 : 0.26153846153846155
Test Recall for epoch 47 : 0.26153846153846155
Test F1 for epoch 47 : 0.26153846153846155


theta for epoch 48 : tensor([[1.8721, 1.9300, 2.0153, 2.0492, 2.0192, 1.8817, 1.9567, 1.8700, 1.8700,
         1.2779, 1.2838, 1.2929, 1.3002, 1.2716, 1.3361, 1.2776, 1.2762, 1.2389,
         1.2690, 1.2436, 1.2706, 1.2769, 1.2559, 1.2499, 1.2657, 1.2482, 1.2482,
         1.2864, 1.3371, 1.2564, 1.2838, 1.3276, 1.2675, 1.2885, 1.2244, 1.2599,
         1.3428, 1.3826, 1.3671, 1.3530, 1.3633, 1.3147, 1.3451, 1.4074, 1.3557,
         1.3696, 1.3111, 1.3034, 1.2767, 1.3632, 1.3048, 1.4016, 1.2818, 1.2852],
        [1.3060, 1.1648, 0.9904, 1.2386, 1.2978, 1.3518, 1.2792, 1.3446, 1.3446,
         1.3888, 1.6516, 1.2985, 2.2261, 1.3667, 3.3275, 1.4321, 1.2460, 2.9442,
         1.1525, 1.2040, 0.9246, 1.1847, 1.3198, 1.3500, 1.3266, 1.3496, 1.3496,
         1.3012, 1.0762, 1.3550, 1.3345, 1.1181, 1.3686, 1.3805, 1.3240, 1.3212,
         1.3158, 1.4786, 1.4137, 1.3306, 1.3002, 1.4315, 1.3905, 0.5262, 1.3164,
         1.0164, 1.4169, 1.4033, 1.3812, 1.0772, 1.4076, 0.8189, 1.3866, 1.3908],
        [1.2491, 1.2679, 1.3166, 1.2933, 1.2513, 1.2545, 1.2524, 1.2483, 1.2483,
         1.2849, 1.2979, 1.3010, 1.3065, 1.2781, 1.2932, 1.2850, 1.2717, 1.2049,
         1.9284, 2.0629, 2.1872, 2.0880, 1.7996, 1.8567, 1.9793, 1.7839, 1.7839,
         1.3301, 1.3081, 1.2601, 1.2886, 1.3327, 1.2717, 1.2934, 1.2666, 1.2637,
         1.3464, 1.3867, 1.3711, 1.3367, 1.3677, 1.3653, 1.3489, 1.3002, 1.3241,
         1.3084, 1.3181, 1.3108, 1.2833, 1.2882, 1.3120, 1.3744, 1.2886, 1.2919],
        [1.2299, 1.2549, 1.2103, 1.1915, 1.2614, 1.2377, 1.2435, 1.2284, 1.2284,
         1.2831, 1.2122, 1.3000, 1.2642, 1.2751, 1.2536, 1.2848, 1.2807, 1.0293,
         1.2760, 1.2496, 1.3124, 1.2856, 1.2518, 1.2086, 1.2655, 1.2405, 1.2405,
         2.2246, 1.8638, 1.6965, 1.7992, 2.1843, 1.6921, 2.1573, 1.7090, 1.6843,
         1.3226, 1.3375, 1.2881, 1.2848, 1.3481, 1.2848, 1.3089, 1.1034, 1.3023,
         1.3586, 1.2357, 1.1518, 1.2089, 1.3552, 1.1556, 1.3963, 1.2156, 1.2644],
        [1.5223, 1.2260, 0.4479, 0.6640, 1.0218, 1.4016, 1.3381, 1.5204, 1.5204,
         1.4493, 1.2181, 1.2770, 0.8165, 1.5215, 0.0763, 1.4292, 1.5324, 1.1291,
         1.1352, 0.7249, 0.6072, 0.9233, 1.3895, 1.4886, 1.1666, 1.5312, 1.5312,
         0.5825, 0.6472, 1.5059, 1.2706, 0.7481, 1.5147, 1.0057, 1.5517, 1.5019,
         0.9863, 0.6242, 0.5590, 0.8975, 1.4077, 1.6475, 0.8320, 4.1308, 3.8231,
         0.6547, 1.1392, 1.2094, 1.4613, 0.8729, 1.4322, 0.2925, 1.4424, 1.5781],
        [1.2861, 1.3113, 1.3729, 1.3479, 1.3320, 1.3011, 1.2600, 1.2850, 1.2850,
         1.2701, 1.3270, 1.2460, 1.3847, 1.3482, 1.4274, 1.2690, 1.3527, 1.2656,
         1.3292, 1.3662, 1.4017, 1.3529, 1.3063, 1.2965, 1.2701, 1.2942, 1.2942,
         1.3577, 1.4378, 1.3100, 1.1887, 1.2290, 1.1222, 1.3513, 1.1977, 1.3145,
         1.3882, 1.1584, 1.4156, 1.4033, 1.0610, 0.9840, 1.3910, 1.3949, 0.8822,
         2.3459, 1.9125, 2.1544, 2.0880, 1.7217, 1.4215, 2.2957, 2.0015, 1.4027]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 48 : 182.26112673758843
Test loss for epoch 48 : 182.3036898001758
Test Precision for epoch 48 : 0.26153846153846155
Test Recall for epoch 48 : 0.26153846153846155
Test F1 for epoch 48 : 0.26153846153846155


theta for epoch 49 : tensor([[1.8804, 1.9358, 2.0195, 2.0556, 2.0248, 1.8894, 1.9653, 1.8783, 1.8783,
         1.2792, 1.2852, 1.2936, 1.3017, 1.2726, 1.3383, 1.2783, 1.2769, 1.2393,
         1.2669, 1.2427, 1.2697, 1.2754, 1.2531, 1.2469, 1.2637, 1.2450, 1.2450,
         1.2896, 1.3389, 1.2613, 1.2875, 1.3297, 1.2716, 1.2922, 1.2288, 1.2645,
         1.3428, 1.3822, 1.3676, 1.3528, 1.3616, 1.3127, 1.3455, 1.4047, 1.3528,
         1.3669, 1.3088, 1.3012, 1.2758, 1.3601, 1.3031, 1.3993, 1.2803, 1.2842],
        [1.3070, 1.1654, 0.9920, 1.2392, 1.2987, 1.3536, 1.2803, 1.3464, 1.3464,
         1.3895, 1.6498, 1.3031, 2.2271, 1.3694, 3.3530, 1.4361, 1.2511, 2.9671,
         1.1517, 1.2044, 0.9296, 1.1850, 1.3215, 1.3515, 1.3275, 1.3512, 1.3512,
         1.3048, 1.0797, 1.3597, 1.3393, 1.1231, 1.3725, 1.3846, 1.3279, 1.3265,
         1.3161, 1.4771, 1.4125, 1.3300, 1.3012, 1.4293, 1.3893, 0.5271, 1.3204,
         1.0192, 1.4149, 1.4018, 1.3808, 1.0782, 1.4064, 0.8228, 1.3855, 1.3903],
        [1.2467, 1.2670, 1.3179, 1.2933, 1.2516, 1.2521, 1.2497, 1.2457, 1.2457,
         1.2870, 1.2998, 1.3023, 1.3085, 1.2801, 1.2946, 1.2865, 1.2735, 1.2056,
         1.9333, 2.0656, 2.1892, 2.0917, 1.8070, 1.8652, 1.9847, 1.7920, 1.7920,
         1.3346, 1.3106, 1.2654, 1.2928, 1.3368, 1.2762, 1.2977, 1.2714, 1.2688,
         1.3468, 1.3866, 1.3718, 1.3382, 1.3663, 1.3631, 1.3495, 1.2998, 1.3263,
         1.3081, 1.3159, 1.3087, 1.2826, 1.2867, 1.3105, 1.3719, 1.2873, 1.2911],
        [1.2339, 1.2586, 1.2137, 1.1945, 1.2651, 1.2416, 1.2472, 1.2325, 1.2325,
         1.2889, 1.2184, 1.3050, 1.2716, 1.2810, 1.2600, 1.2898, 1.2861, 1.0348,
         1.2790, 1.2530, 1.3154, 1.2884, 1.2556, 1.2124, 1.2685, 1.2442, 1.2442,
         2.2337, 1.8701, 1.7004, 1.8040, 2.1937, 1.6964, 2.1662, 1.7131, 1.6885,
         1.3248, 1.3418, 1.2925, 1.2874, 1.3489, 1.2888, 1.3127, 1.1065, 1.3040,
         1.3610, 1.2396, 1.1564, 1.2132, 1.3578, 1.1610, 1.3979, 1.2193, 1.2683],
        [1.5255, 1.2293, 0.4525, 0.6685, 1.0270, 1.4059, 1.3430, 1.5237, 1.5237,
         1.4526, 1.2214, 1.2812, 0.8193, 1.5257, 0.0798, 1.4343, 1.5375, 1.1323,
         1.1404, 0.7287, 0.6108, 0.9278, 1.3918, 1.4915, 1.1690, 1.5339, 1.5339,
         0.5882, 0.6546, 1.5104, 1.2759, 0.7524, 1.5188, 1.0124, 1.5561, 1.5067,
         0.9702, 0.6112, 0.5461, 0.8824, 1.3934, 1.6373, 0.8166, 4.1949, 3.8776,
         0.6560, 1.1405, 1.2106, 1.4638, 0.8752, 1.4343, 0.2923, 1.4452, 1.5806],
        [1.2845, 1.3093, 1.3686, 1.3448, 1.3287, 1.2991, 1.2581, 1.2834, 1.2834,
         1.2683, 1.3250, 1.2437, 1.3829, 1.3479, 1.4231, 1.2668, 1.3521, 1.2637,
         1.3264, 1.3614, 1.3964, 1.3488, 1.3038, 1.2941, 1.2677, 1.2921, 1.2921,
         1.3598, 1.4400, 1.3137, 1.1924, 1.2312, 1.1264, 1.3545, 1.2017, 1.3179,
         1.3868, 1.1585, 1.4146, 1.4018, 1.0597, 0.9818, 1.3899, 1.3891, 0.8730,
         2.3572, 1.9251, 2.1707, 2.1027, 1.7264, 1.4313, 2.3053, 2.0166, 1.4127]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 49 : 182.22087308296824
Test loss for epoch 49 : 182.2614862003777
Test Precision for epoch 49 : 0.26153846153846155
Test Recall for epoch 49 : 0.26153846153846155
Test F1 for epoch 49 : 0.26153846153846155


theta for epoch 50 : tensor([[1.8882, 1.9412, 2.0232, 2.0615, 2.0299, 1.8965, 1.9734, 1.8862, 1.8862,
         1.2829, 1.2894, 1.2970, 1.3060, 1.2761, 1.3436, 1.2816, 1.2801, 1.2427,
         1.2665, 1.2439, 1.2704, 1.2756, 1.2518, 1.2452, 1.2631, 1.2432, 1.2432,
         1.2915, 1.3395, 1.2648, 1.2900, 1.3307, 1.2744, 1.2947, 1.2318, 1.2678,
         1.3440, 1.3828, 1.3690, 1.3537, 1.3610, 1.3117, 1.3470, 1.4029, 1.3509,
         1.3620, 1.3043, 1.2968, 1.2726, 1.3548, 1.2991, 1.3946, 1.2766, 1.2809],
        [1.3080, 1.1664, 0.9946, 1.2403, 1.2999, 1.3556, 1.2815, 1.3483, 1.3483,
         1.3910, 1.6487, 1.3085, 2.2281, 1.3728, 3.3784, 1.4409, 1.2569, 2.9902,
         1.1517, 1.2058, 0.9353, 1.1862, 1.3237, 1.3538, 1.3295, 1.3536, 1.3536,
         1.3074, 1.0818, 1.3635, 1.3430, 1.1267, 1.3755, 1.3877, 1.3310, 1.3309,
         1.3175, 1.4766, 1.4124, 1.3303, 1.3029, 1.4282, 1.3892, 0.5285, 1.3252,
         1.0193, 1.4108, 1.3981, 1.3780, 1.0766, 1.4030, 0.8242, 1.3821, 1.3874],
        [1.2443, 1.2663, 1.3197, 1.2939, 1.2523, 1.2497, 1.2475, 1.2430, 1.2430,
         1.2912, 1.3040, 1.3060, 1.3131, 1.2841, 1.2983, 1.2902, 1.2774, 1.2086,
         1.9386, 2.0685, 2.1913, 2.0955, 1.8147, 1.8741, 1.9904, 1.8005, 1.8005,
         1.3375, 1.3115, 1.2694, 1.2956, 1.3392, 1.2794, 1.3006, 1.2748, 1.2725,
         1.3481, 1.3874, 1.3734, 1.3406, 1.3659, 1.3620, 1.3511, 1.3001, 1.3289,
         1.3055, 1.3116, 1.3044, 1.2796, 1.2826, 1.3067, 1.3668, 1.2838, 1.2880],
        [1.2359, 1.2604, 1.2152, 1.1956, 1.2668, 1.2435, 1.2491, 1.2345, 1.2345,
         1.2945, 1.2241, 1.3097, 1.2787, 1.2864, 1.2663, 1.2947, 1.2911, 1.0395,
         1.2807, 1.2549, 1.3171, 1.2899, 1.2578, 1.2145, 1.2702, 1.2463, 1.2463,
         2.2444, 1.8782, 1.7062, 1.8105, 2.2047, 1.7024, 2.1767, 1.7190, 1.6946,
         1.3267, 1.3457, 1.2966, 1.2898, 1.3495, 1.2924, 1.3161, 1.1089, 1.3054,
         1.3604, 1.2405, 1.1580, 1.2143, 1.3573, 1.1632, 1.3965, 1.2199, 1.2691],
        [1.5305, 1.2349, 0.4594, 0.6753, 1.0344, 1.4123, 1.3499, 1.5288, 1.5288,
         1.4594, 1.2283, 1.2885, 0.8260, 1.5332, 0.0878, 1.4424, 1.5457, 1.1389,
         1.1479, 0.7352, 0.6177, 0.9350, 1.3966, 1.4965, 1.1736, 1.5387, 1.5387,
         0.5951, 0.6631, 1.5154, 1.2819, 0.7577, 1.5233, 1.0198, 1.5609, 1.5119,
         0.9523, 0.5968, 0.5318, 0.8656, 1.3767, 1.6244, 0.7996, 4.2576, 3.9305,
         0.6571, 1.1405, 1.2106, 1.4649, 0.8769, 1.4351, 0.2932, 1.4463, 1.5816],
        [1.2828, 1.3074, 1.3649, 1.3421, 1.3253, 1.2970, 1.2562, 1.2817, 1.2817,
         1.2682, 1.3251, 1.2433, 1.3835, 1.3493, 1.4216, 1.2664, 1.3532, 1.2641,
         1.3244, 1.3575, 1.3914, 1.3452, 1.3019, 1.2924, 1.2660, 1.2905, 1.2905,
         1.3605, 1.4402, 1.3161, 1.1945, 1.2320, 1.1291, 1.3563, 1.2042, 1.3201,
         1.3863, 1.1590, 1.4144, 1.4011, 1.0587, 0.9795, 1.3897, 1.3837, 0.8641,
         2.3675, 1.9368, 2.1860, 2.1163, 1.7303, 1.4402, 2.3139, 2.0308, 1.4218]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 50 : 182.1900462055363
Test loss for epoch 50 : 182.22821913008926
Test Precision for epoch 50 : 0.26153846153846155
Test Recall for epoch 50 : 0.26153846153846155
Test F1 for epoch 50 : 0.26153846153846155


theta for epoch 51 : tensor([[1.8944, 1.9450, 2.0255, 2.0658, 2.0335, 1.9021, 1.9799, 1.8924, 1.8924,
         1.2857, 1.2925, 1.2996, 1.3095, 1.2785, 1.3482, 1.2840, 1.2822, 1.2453,
         1.2690, 1.2481, 1.2737, 1.2788, 1.2530, 1.2461, 1.2652, 1.2439, 1.2439,
         1.2901, 1.3372, 1.2652, 1.2893, 1.3285, 1.2742, 1.2940, 1.2317, 1.2679,
         1.3480, 1.3863, 1.3733, 1.3574, 1.3634, 1.3136, 1.3513, 1.4040, 1.3518,
         1.3573, 1.3001, 1.2927, 1.2696, 1.3498, 1.2954, 1.3902, 1.2731, 1.2779],
        [1.3106, 1.1691, 0.9994, 1.2433, 1.3027, 1.3590, 1.2843, 1.3516, 1.3516,
         1.3896, 1.6446, 1.3111, 2.2259, 1.3734, 3.4008, 1.4427, 1.2598, 3.0103,
         1.1537, 1.2094, 0.9427, 1.1894, 1.3278, 1.3581, 1.3336, 1.3580, 1.3580,
         1.3075, 1.0811, 1.3649, 1.3442, 1.1275, 1.3762, 1.3883, 1.3317, 1.3327,
         1.3219, 1.4792, 1.4154, 1.3338, 1.3076, 1.4302, 1.3923, 0.5327, 1.3330,
         1.0196, 1.4072, 1.3949, 1.3756, 1.0752, 1.3999, 0.8259, 1.3792, 1.3850],
        [1.2430, 1.2667, 1.3226, 1.2958, 1.2544, 1.2484, 1.2466, 1.2415, 1.2415,
         1.2939, 1.3067, 1.3085, 1.3164, 1.2865, 1.3007, 1.2925, 1.2795, 1.2105,
         1.9439, 2.0712, 2.1934, 2.0993, 1.8224, 1.8828, 1.9958, 1.8088, 1.8088,
         1.3365, 1.3089, 1.2699, 1.2949, 1.3378, 1.2792, 1.3000, 1.2748, 1.2727,
         1.3521, 1.3908, 1.3777, 1.3455, 1.3681, 1.3635, 1.3553, 1.3026, 1.3337,
         1.3028, 1.3073, 1.3002, 1.2765, 1.2782, 1.3029, 1.3616, 1.2802, 1.2849],
        [1.2367, 1.2612, 1.2156, 1.1954, 1.2674, 1.2441, 1.2497, 1.2353, 1.2353,
         1.2967, 1.2264, 1.3112, 1.2824, 1.2885, 1.2695, 1.2963, 1.2928, 1.0410,
         1.2817, 1.2558, 1.3182, 1.2907, 1.2592, 1.2158, 1.2711, 1.2476, 1.2476,
         2.2556, 1.8869, 1.7126, 1.8177, 2.2162, 1.7091, 2.1877, 1.7255, 1.7013,
         1.3300, 1.3508, 1.3019, 1.2935, 1.3514, 1.2971, 1.3209, 1.1123, 1.3081,
         1.3586, 1.2402, 1.1582, 1.2142, 1.3557, 1.1641, 1.3941, 1.2193, 1.2688],
        [1.5350, 1.2393, 0.4645, 0.6804, 1.0403, 1.4179, 1.3559, 1.5333, 1.5333,
         1.4631, 1.2321, 1.2926, 0.8296, 1.5376, 0.0932, 1.4474, 1.5509, 1.1423,
         1.1545, 0.7403, 0.6238, 0.9411, 1.4010, 1.5012, 1.1772, 1.5433, 1.5433,
         0.5981, 0.6678, 1.5172, 1.2844, 0.7593, 1.5245, 1.0233, 1.5625, 1.5139,
         0.9370, 0.5852, 0.5204, 0.8515, 1.3624, 1.6138, 0.7853, 4.3223, 3.9855,
         0.6554, 1.1379, 1.2082, 1.4642, 0.8758, 1.4340, 0.2914, 1.4455, 1.5810],
        [1.2835, 1.3080, 1.3640, 1.3421, 1.3244, 1.2971, 1.2568, 1.2824, 1.2824,
         1.2678, 1.3251, 1.2431, 1.3839, 1.3502, 1.4209, 1.2658, 1.3539, 1.2647,
         1.3253, 1.3565, 1.3889, 1.3444, 1.3028, 1.2934, 1.2670, 1.2917, 1.2917,
         1.3593, 1.4381, 1.3168, 1.1947, 1.2311, 1.1301, 1.3561, 1.2050, 1.3204,
         1.3897, 1.1631, 1.4180, 1.4042, 1.0613, 0.9809, 1.3934, 1.3819, 0.8592,
         2.3748, 1.9453, 2.1981, 2.1268, 1.7314, 1.4462, 2.3194, 2.0418, 1.4280]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 51 : 182.15965341429202
Test loss for epoch 51 : 182.197557631972
Test Precision for epoch 51 : 0.26153846153846155
Test Recall for epoch 51 : 0.26153846153846155
Test F1 for epoch 51 : 0.26153846153846155


theta for epoch 52 : tensor([[1.8989, 1.9472, 2.0263, 2.0685, 2.0355, 1.9061, 1.9848, 1.8969, 1.8969,
         1.2862, 1.2936, 1.3002, 1.3108, 1.2786, 1.3509, 1.2842, 1.2821, 1.2460,
         1.2714, 1.2523, 1.2765, 1.2817, 1.2539, 1.2466, 1.2670, 1.2442, 1.2442,
         1.2861, 1.3325, 1.2631, 1.2862, 1.3241, 1.2715, 1.2907, 1.2290, 1.2656,
         1.3539, 1.3917, 1.3795, 1.3630, 1.3677, 1.3174, 1.3575, 1.4069, 1.3546,
         1.3554, 1.2986, 1.2913, 1.2692, 1.3476, 1.2943, 1.3884, 1.2723, 1.2774],
        [1.3133, 1.1722, 1.0048, 1.2467, 1.3057, 1.3625, 1.2871, 1.3550, 1.3550,
         1.3861, 1.6384, 1.3115, 2.2211, 1.3718, 3.4208, 1.4424, 1.2604, 3.0282,
         1.1551, 1.2126, 0.9493, 1.1920, 1.3311, 1.3618, 1.3371, 1.3617, 1.3617,
         1.3052, 1.0777, 1.3640, 1.3431, 1.1256, 1.3747, 1.3865, 1.3302, 1.3323,
         1.3282, 1.4838, 1.4205, 1.3392, 1.3140, 1.4341, 1.3974, 0.5384, 1.3426,
         1.0222, 1.4063, 1.3944, 1.3758, 1.0761, 1.3996, 0.8299, 1.3790, 1.3851],
        [1.2426, 1.2681, 1.3264, 1.2987, 1.2574, 1.2481, 1.2470, 1.2409, 1.2409,
         1.2946, 1.3073, 1.3090, 1.3177, 1.2869, 1.3013, 1.2928, 1.2795, 1.2106,
         1.9475, 2.0721, 2.1935, 2.1011, 1.8283, 1.8896, 1.9993, 1.8152, 1.8152,
         1.3329, 1.3039, 1.2680, 1.2920, 1.3337, 1.2767, 1.2971, 1.2725, 1.2705,
         1.3581, 1.3962, 1.3838, 1.3523, 1.3724, 1.3670, 1.3614, 1.3068, 1.3399,
         1.3027, 1.3057, 1.2987, 1.2760, 1.2764, 1.3018, 1.3591, 1.2792, 1.2843],
        [1.2364, 1.2610, 1.2150, 1.1942, 1.2671, 1.2436, 1.2493, 1.2351, 1.2351,
         1.2956, 1.2253, 1.3093, 1.2825, 1.2870, 1.2695, 1.2945, 1.2909, 1.0392,
         1.2810, 1.2551, 1.3178, 1.2900, 1.2588, 1.2153, 1.2704, 1.2472, 1.2472,
         2.2666, 1.8956, 1.7192, 1.8249, 2.2276, 1.7160, 2.1986, 1.7322, 1.7081,
         1.3343, 1.3568, 1.3080, 1.2981, 1.3543, 1.3025, 1.3265, 1.1162, 1.3116,
         1.3581, 1.2410, 1.1593, 1.2152, 1.3552, 1.1659, 1.3930, 1.2199, 1.2697],
        [1.5377, 1.2414, 0.4664, 0.6825, 1.0433, 1.4216, 1.3598, 1.5360, 1.5360,
         1.4624, 1.2311, 1.2920, 0.8284, 1.5376, 0.0942, 1.4476, 1.5516, 1.1408,
         1.1581, 0.7418, 0.6266, 0.9440, 1.4031, 1.5035, 1.1779, 1.5457, 1.5457,
         0.5969, 0.6683, 1.5158, 1.2833, 0.7568, 1.5224, 1.0226, 1.5608, 1.5125,
         0.9250, 0.5770, 0.5124, 0.8407, 1.3511, 1.6061, 0.7744, 4.3894, 4.0430,
         0.6521, 1.1348, 1.2056, 1.4639, 0.8737, 1.4331, 0.2879, 1.4449, 1.5811],
        [1.2865, 1.3110, 1.3657, 1.3446, 1.3256, 1.2992, 1.2595, 1.2853, 1.2853,
         1.2666, 1.3243, 1.2423, 1.3834, 1.3499, 1.4199, 1.2644, 1.3535, 1.2648,
         1.3277, 1.3571, 1.3876, 1.3451, 1.3052, 1.2958, 1.2696, 1.2943, 1.2943,
         1.3571, 1.4346, 1.3165, 1.1938, 1.2294, 1.1302, 1.3549, 1.2050, 1.3199,
         1.3960, 1.1702, 1.4246, 1.4102, 1.0670, 0.9853, 1.4000, 1.3828, 0.8578,
         2.3795, 1.9513, 2.2076, 2.1348, 1.7303, 1.4499, 2.3225, 2.0503, 1.4319]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 52 : 182.12541497864134
Test loss for epoch 52 : 182.16543861215416
Test Precision for epoch 52 : 0.26153846153846155
Test Recall for epoch 52 : 0.26153846153846155
Test F1 for epoch 52 : 0.26153846153846155


theta for epoch 53 : tensor([[1.9025, 1.9486, 2.0263, 2.0703, 2.0367, 1.9092, 1.9887, 1.9006, 1.9006,
         1.2867, 1.2947, 1.3009, 1.3122, 1.2786, 1.3537, 1.2844, 1.2819, 1.2469,
         1.2713, 1.2540, 1.2767, 1.2822, 1.2523, 1.2446, 1.2663, 1.2420, 1.2420,
         1.2820, 1.3280, 1.2607, 1.2830, 1.3197, 1.2686, 1.2872, 1.2262, 1.2630,
         1.3582, 1.3954, 1.3839, 1.3670, 1.3703, 1.3195, 1.3620, 1.4081, 1.3557,
         1.3569, 1.3005, 1.2933, 1.2720, 1.3488, 1.2964, 1.3900, 1.2747, 1.2801],
        [1.3133, 1.1729, 1.0079, 1.2475, 1.3060, 1.3633, 1.2873, 1.3557, 1.3557,
         1.3849, 1.6344, 1.3142, 2.2181, 1.3724, 3.4421, 1.4444, 1.2632, 3.0479,
         1.1534, 1.2126, 0.9523, 1.1913, 1.3312, 1.3623, 1.3375, 1.3622, 1.3622,
         1.3020, 1.0729, 1.3624, 1.3410, 1.1224, 1.3724, 1.3839, 1.3280, 1.3309,
         1.3322, 1.4862, 1.4233, 1.3422, 1.3179, 1.4360, 1.4003, 0.5413, 1.3498,
         1.0267, 1.4083, 1.3967, 1.3787, 1.0791, 1.4018, 0.8357, 1.3814, 1.3878],
        [1.2413, 1.2684, 1.3288, 1.3006, 1.2595, 1.2467, 1.2466, 1.2393, 1.2393,
         1.2955, 1.3080, 1.3099, 1.3193, 1.2873, 1.3021, 1.2933, 1.2795, 1.2110,
         1.9495, 2.0714, 2.1921, 2.1013, 1.8325, 1.8948, 2.0011, 1.8200, 1.8200,
         1.3292, 1.2990, 1.2660, 1.2891, 1.3296, 1.2743, 1.2941, 1.2702, 1.2684,
         1.3625, 1.4000, 1.3884, 1.3575, 1.3752, 1.3691, 1.3660, 1.3093, 1.3443,
         1.3061, 1.3077, 1.3007, 1.2789, 1.2778, 1.3040, 1.3599, 1.2817, 1.2871],
        [1.2352, 1.2599, 1.2136, 1.1920, 1.2657, 1.2422, 1.2480, 1.2339, 1.2339,
         1.2939, 1.2236, 1.3072, 1.2821, 1.2851, 1.2691, 1.2923, 1.2887, 1.0370,
         1.2787, 1.2527, 1.3159, 1.2877, 1.2566, 1.2130, 1.2681, 1.2451, 1.2451,
         2.2775, 1.9044, 1.7257, 1.8321, 2.2389, 1.7229, 2.2094, 1.7389, 1.7150,
         1.3371, 1.3612, 1.3124, 1.3012, 1.3557, 1.3063, 1.3306, 1.1186, 1.3135,
         1.3600, 1.2440, 1.1625, 1.2185, 1.3570, 1.1697, 1.3944, 1.2227, 1.2728],
        [1.5394, 1.2422, 0.4669, 0.6832, 1.0448, 1.4241, 1.3624, 1.5376, 1.5376,
         1.4610, 1.2294, 1.2905, 0.8265, 1.5369, 0.0947, 1.4470, 1.5517, 1.1385,
         1.1598, 0.7414, 0.6278, 0.9450, 1.4036, 1.5042, 1.1768, 1.5465, 1.5465,
         0.5947, 0.6679, 1.5140, 1.2817, 0.7535, 1.5200, 1.0210, 1.5588, 1.5107,
         0.9131, 0.5691, 0.5046, 0.8300, 1.3396, 1.5979, 0.7636, 4.4567, 4.1006,
         0.6509, 1.1342, 1.2055, 1.4663, 0.8739, 1.4350, 0.2865, 1.4469, 1.5839],
        [1.2899, 1.3147, 1.3684, 1.3479, 1.3274, 1.3017, 1.2628, 1.2887, 1.2887,
         1.2667, 1.3249, 1.2431, 1.3844, 1.3507, 1.4209, 1.2644, 1.3541, 1.2667,
         1.3301, 1.3578, 1.3862, 1.3457, 1.3075, 1.2981, 1.2721, 1.2967, 1.2967,
         1.3557, 1.4314, 1.3169, 1.1935, 1.2285, 1.1309, 1.3542, 1.2055, 1.3200,
         1.4012, 1.1759, 1.4299, 1.4150, 1.0713, 0.9884, 1.4055, 1.3825, 0.8557,
         2.3833, 1.9564, 2.2161, 2.1417, 1.7285, 1.4529, 2.3246, 2.0578, 1.4351]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 53 : 182.0972290292549
Test loss for epoch 53 : 182.14022872093875
Test Precision for epoch 53 : 0.26153846153846155
Test Recall for epoch 53 : 0.26153846153846155
Test F1 for epoch 53 : 0.26153846153846155


theta for epoch 54 : tensor([[1.9076, 1.9515, 2.0280, 2.0736, 2.0394, 1.9138, 1.9941, 1.9057, 1.9057,
         1.2874, 1.2960, 1.3019, 1.3138, 1.2787, 1.3568, 1.2849, 1.2819, 1.2482,
         1.2706, 1.2549, 1.2759, 1.2819, 1.2501, 1.2418, 1.2649, 1.2391, 1.2391,
         1.2793, 1.3252, 1.2596, 1.2812, 1.3169, 1.2672, 1.2852, 1.2245, 1.2617,
         1.3577, 1.3944, 1.3836, 1.3662, 1.3684, 1.3170, 1.3618, 1.4046, 1.3521,
         1.3600, 1.3040, 1.2968, 1.2762, 1.3516, 1.3001, 1.3931, 1.2785, 1.2842],
        [1.3109, 1.1712, 1.0087, 1.2460, 1.3040, 1.3617, 1.2849, 1.3540, 1.3540,
         1.3871, 1.6340, 1.3203, 2.2180, 1.3764, 3.4659, 1.4497, 1.2692, 3.0703,
         1.1500, 1.2111, 0.9533, 1.1892, 1.3297, 1.3614, 1.3366, 1.3613, 1.3613,
         1.2997, 1.0686, 1.3615, 1.3398, 1.1198, 1.3711, 1.3823, 1.3266, 1.3303,
         1.3310, 1.4836, 1.4211, 1.3401, 1.3166, 1.4329, 1.3983, 0.5386, 1.3518,
         1.0318, 1.4115, 1.4002, 1.3826, 1.0827, 1.4053, 0.8416, 1.3850, 1.3917],
        [1.2380, 1.2667, 1.3289, 1.3004, 1.2595, 1.2434, 1.2445, 1.2358, 1.2358,
         1.2964, 1.3089, 1.3109, 1.3210, 1.2877, 1.3031, 1.2939, 1.2796, 1.2116,
         1.9534, 2.0724, 2.1923, 2.1032, 1.8384, 1.9016, 2.0045, 1.8265, 1.8265,
         1.3268, 1.2956, 1.2654, 1.2877, 1.3268, 1.2733, 1.2926, 1.2692, 1.2675,
         1.3621, 1.3991, 1.3882, 1.3578, 1.3733, 1.3666, 1.3659, 1.3069, 1.3436,
         1.3108, 1.3112, 1.3043, 1.2831, 1.2805, 1.3078, 1.3622, 1.2856, 1.2912],
        [1.2341, 1.2590, 1.2125, 1.1903, 1.2646, 1.2409, 1.2469, 1.2328, 1.2328,
         1.2936, 1.2233, 1.3063, 1.2827, 1.2844, 1.2700, 1.2914, 1.2876, 1.0359,
         1.2773, 1.2511, 1.3148, 1.2863, 1.2552, 1.2115, 1.2667, 1.2436, 1.2436,
         2.2879, 1.9128, 1.7320, 1.8389, 2.2497, 1.7295, 2.2197, 1.7453, 1.7216,
         1.3366, 1.3621, 1.3135, 1.3010, 1.3539, 1.3066, 1.3314, 1.1180, 1.3122,
         1.3637, 1.2487, 1.1672, 1.2234, 1.3606, 1.1751, 1.3978, 1.2272, 1.2777],
        [1.5418, 1.2439, 0.4686, 0.6851, 1.0471, 1.4275, 1.3659, 1.5400, 1.5400,
         1.4615, 1.2298, 1.2908, 0.8268, 1.5379, 0.0977, 1.4480, 1.5534, 1.1382,
         1.1626, 0.7425, 0.6308, 0.9474, 1.4055, 1.5061, 1.1770, 1.5486, 1.5486,
         0.5947, 0.6695, 1.5143, 1.2823, 0.7524, 1.5197, 1.0215, 1.5589, 1.5110,
         0.8982, 0.5586, 0.4942, 0.8164, 1.3247, 1.5862, 0.7501, 4.5220, 4.1557,
         0.6532, 1.1367, 1.2086, 1.4715, 0.8774, 1.4398, 0.2891, 1.4516, 1.5895],
        [1.2935, 1.3186, 1.3717, 1.3517, 1.3294, 1.3043, 1.2663, 1.2922, 1.2922,
         1.2683, 1.3272, 1.2456, 1.3871, 1.3528, 1.4239, 1.2660, 1.3561, 1.2702,
         1.3334, 1.3597, 1.3856, 1.3473, 1.3105, 1.3012, 1.2754, 1.2999, 1.2999,
         1.3561, 1.4298, 1.3191, 1.1947, 1.2296, 1.1333, 1.3554, 1.2078, 1.3220,
         1.4019, 1.1768, 1.4307, 1.4152, 1.0707, 0.9866, 1.4064, 1.3775, 0.8493,
         2.3867, 1.9613, 2.2243, 2.1484, 1.7269, 1.4557, 2.3264, 2.0651, 1.4382]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 54 : 182.0634781992468
Test loss for epoch 54 : 182.10842199737905
Test Precision for epoch 54 : 0.26153846153846155
Test Recall for epoch 54 : 0.26153846153846155
Test F1 for epoch 54 : 0.26153846153846155


theta for epoch 55 : tensor([[1.9153, 1.9571, 2.0323, 2.0796, 2.0448, 1.9210, 2.0021, 1.9134, 1.9134,
         1.2864, 1.2956, 1.3012, 1.3137, 1.2771, 1.3583, 1.2837, 1.2802, 1.2479,
         1.2702, 1.2561, 1.2752, 1.2820, 1.2482, 1.2395, 1.2638, 1.2366, 1.2366,
         1.2785, 1.3244, 1.2600, 1.2811, 1.3161, 1.2673, 1.2849, 1.2244, 1.2619,
         1.3543, 1.3905, 1.3804, 1.3627, 1.3637, 1.3116, 1.3586, 1.3984, 1.3457,
         1.3618, 1.3063, 1.2992, 1.2791, 1.3532, 1.3024, 1.3950, 1.2811, 1.2870],
        [1.3085, 1.1698, 1.0096, 1.2447, 1.3022, 1.3601, 1.2826, 1.3523, 1.3523,
         1.3896, 1.6337, 1.3265, 2.2178, 1.3806, 3.4892, 1.4552, 1.2753, 3.0927,
         1.1477, 1.2106, 0.9546, 1.1880, 1.3290, 1.3613, 1.3366, 1.3612, 1.3612,
         1.2997, 1.0664, 1.3628, 1.3407, 1.1192, 1.3720, 1.3828, 1.3274, 1.3317,
         1.3273, 1.4787, 1.4165, 1.3356, 1.3127, 1.4275, 1.3938, 0.5335, 1.3512,
         1.0355, 1.4141, 1.4029, 1.3857, 1.0850, 1.4080, 0.8463, 1.3877, 1.3946],
        [1.2339, 1.2638, 1.3276, 1.2990, 1.2584, 1.2393, 1.2415, 1.2315, 1.2315,
         1.2956, 1.3080, 1.3104, 1.3211, 1.2864, 1.3027, 1.2929, 1.2778, 1.2106,
         1.9601, 2.0762, 2.1952, 2.1079, 1.8471, 1.9111, 2.0106, 1.8357, 1.8357,
         1.3261, 1.2941, 1.2661, 1.2878, 1.3257, 1.2737, 1.2928, 1.2697, 1.2681,
         1.3590, 1.3953, 1.3851, 1.3553, 1.3688, 1.3615, 1.3630, 1.3017, 1.3398,
         1.3142, 1.3136, 1.3066, 1.2860, 1.2819, 1.3102, 1.3631, 1.2881, 1.2940],
        [1.2346, 1.2598, 1.2132, 1.1901, 1.2652, 1.2411, 1.2473, 1.2332, 1.2332,
         1.2937, 1.2235, 1.3060, 1.2838, 1.2841, 1.2716, 1.2912, 1.2870, 1.0356,
         1.2784, 1.2518, 1.3163, 1.2874, 1.2561, 1.2123, 1.2678, 1.2445, 1.2445,
         2.2972, 1.9203, 1.7375, 1.8449, 2.2594, 1.7353, 2.2289, 1.7508, 1.7273,
         1.3348, 1.3617, 1.3131, 1.2995, 1.3507, 1.3055, 1.3307, 1.1162, 1.3095,
         1.3675, 1.2535, 1.1719, 1.2283, 1.3642, 1.1804, 1.4012, 1.2318, 1.2825],
        [1.5452, 1.2464, 0.4709, 0.6877, 1.0501, 1.4318, 1.3701, 1.5433, 1.5433,
         1.4618, 1.2301, 1.2909, 0.8273, 1.5387, 0.1012, 1.4486, 1.5548, 1.1379,
         1.1666, 0.7449, 0.6351, 0.9510, 1.4089, 1.5093, 1.1785, 1.5520, 1.5520,
         0.5965, 0.6727, 1.5167, 1.2849, 0.7530, 1.5213, 1.0236, 1.5610, 1.5132,
         0.8821, 0.5469, 0.4827, 0.8015, 1.3082, 1.5725, 0.7353, 4.5864, 4.2097,
         0.6553, 1.1387, 1.2111, 1.4760, 0.8806, 1.4439, 0.2921, 1.4557, 1.5944],
        [1.2974, 1.3229, 1.3757, 1.3561, 1.3320, 1.3071, 1.2701, 1.2960, 1.2960,
         1.2689, 1.3288, 1.2473, 1.3889, 1.3537, 1.4267, 1.2666, 1.3570, 1.2730,
         1.3379, 1.3629, 1.3862, 1.3501, 1.3148, 1.3053, 1.2799, 1.3041, 1.3041,
         1.3585, 1.4299, 1.3231, 1.1975, 1.2326, 1.1372, 1.3583, 1.2117, 1.3257,
         1.4000, 1.1746, 1.4288, 1.4128, 1.0672, 0.9819, 1.4048, 1.3700, 0.8407,
         2.3896, 1.9655, 2.2318, 2.1543, 1.7248, 1.4581, 2.3277, 2.0717, 1.4407]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 55 : 182.03318729075212
Test loss for epoch 55 : 182.0793458610244
Test Precision for epoch 55 : 0.26153846153846155
Test Recall for epoch 55 : 0.26153846153846155
Test F1 for epoch 55 : 0.26153846153846155


theta for epoch 56 : tensor([[1.9235, 1.9633, 2.0374, 2.0862, 2.0508, 1.9288, 2.0106, 1.9216, 1.9216,
         1.2841, 1.2941, 1.2995, 1.3125, 1.2742, 1.3587, 1.2814, 1.2772, 1.2465,
         1.2690, 1.2562, 1.2734, 1.2811, 1.2455, 1.2365, 1.2619, 1.2334, 1.2334,
         1.2790, 1.3251, 1.2615, 1.2822, 1.3169, 1.2687, 1.2858, 1.2254, 1.2632,
         1.3523, 1.3879, 1.3784, 1.3605, 1.3604, 1.3077, 1.3568, 1.3936, 1.3407,
         1.3610, 1.3060, 1.2990, 1.2793, 1.3523, 1.3022, 1.3942, 1.2811, 1.2871],
        [1.3069, 1.1694, 1.0114, 1.2442, 1.3011, 1.3590, 1.2810, 1.3511, 1.3511,
         1.3901, 1.6316, 1.3306, 2.2153, 1.3827, 3.5104, 1.4586, 1.2792, 3.1129,
         1.1459, 1.2107, 0.9561, 1.1872, 1.3285, 1.3615, 1.3369, 1.3614, 1.3614,
         1.3019, 1.0664, 1.3658, 1.3434, 1.1207, 1.3748, 1.3853, 1.3301, 1.3349,
         1.3254, 1.4758, 1.4139, 1.3330, 1.3105, 1.4241, 1.3914, 0.5304, 1.3522,
         1.0370, 1.4147, 1.4037, 1.3866, 1.0852, 1.4086, 0.8489, 1.3884, 1.3955],
        [1.2298, 1.2608, 1.3257, 1.2974, 1.2571, 1.2351, 1.2386, 1.2272, 1.2272,
         1.2937, 1.3062, 1.3089, 1.3203, 1.2840, 1.3015, 1.2910, 1.2750, 1.2089,
         1.9669, 2.0800, 2.1982, 2.1126, 1.8559, 1.9206, 2.0167, 1.8449, 1.8449,
         1.3267, 1.2942, 1.2681, 1.2893, 1.3260, 1.2755, 1.2942, 1.2715, 1.2698,
         1.3572, 1.3930, 1.3834, 1.3540, 1.3657, 1.3578, 1.3614, 1.2979, 1.3370,
         1.3149, 1.3135, 1.3066, 1.2863, 1.2806, 1.3101, 1.3615, 1.2882, 1.2942],
        [1.2365, 1.2621, 1.2153, 1.1915, 1.2671, 1.2428, 1.2492, 1.2351, 1.2351,
         1.2944, 1.2243, 1.3064, 1.2854, 1.2843, 1.2739, 1.2915, 1.2870, 1.0361,
         1.2807, 1.2537, 1.3190, 1.2899, 1.2581, 1.2143, 1.2701, 1.2466, 1.2466,
         2.3050, 1.9264, 1.7416, 1.8495, 2.2676, 1.7397, 2.2366, 1.7550, 1.7318,
         1.3350, 1.3630, 1.3146, 1.3000, 1.3495, 1.3061, 1.3319, 1.1164, 1.3087,
         1.3701, 1.2572, 1.1755, 1.2320, 1.3665, 1.1846, 1.4035, 1.2351, 1.2861],
        [1.5477, 1.2477, 0.4717, 0.6889, 1.0515, 1.4350, 1.3731, 1.5457, 1.5457,
         1.4601, 1.2283, 1.2889, 0.8256, 1.5374, 0.1027, 1.4471, 1.5541, 1.1355,
         1.1691, 0.7455, 0.6377, 0.9530, 1.4112, 1.5114, 1.1786, 1.5544, 1.5544,
         0.5975, 0.6753, 1.5193, 1.2874, 0.7532, 1.5231, 1.0252, 1.5633, 1.5156,
         0.8680, 0.5373, 0.4734, 0.7887, 1.2933, 1.5603, 0.7226, 4.6521, 4.2651,
         0.6532, 1.1367, 1.2096, 1.4766, 0.8797, 1.4442, 0.2911, 1.4559, 1.5957],
        [1.3005, 1.3264, 1.3791, 1.3598, 1.3338, 1.3091, 1.2731, 1.2990, 1.2990,
         1.2675, 1.3284, 1.2471, 1.3889, 1.3526, 1.4281, 1.2653, 1.3558, 1.2739,
         1.3415, 1.3653, 1.3861, 1.3521, 1.3181, 1.3085, 1.2834, 1.3074, 1.3074,
         1.3616, 1.4306, 1.3275, 1.2006, 1.2362, 1.1415, 1.3618, 1.2159, 1.3300,
         1.3993, 1.1732, 1.4281, 1.4116, 1.0644, 0.9780, 1.4043, 1.3640, 0.8335,
         2.3921, 1.9693, 2.2389, 2.1598, 1.7226, 1.4601, 2.3286, 2.0779, 1.4429]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 56 : 182.006269636109
Test loss for epoch 56 : 182.05444894569644
Test Precision for epoch 56 : 0.26153846153846155
Test Recall for epoch 56 : 0.26153846153846155
Test F1 for epoch 56 : 0.26153846153846155


theta for epoch 57 : tensor([[1.9292, 1.9672, 2.0402, 2.0903, 2.0545, 1.9341, 2.0167, 1.9273, 1.9273,
         1.2834, 1.2941, 1.2993, 1.3129, 1.2729, 1.3606, 1.2806, 1.2758, 1.2469,
         1.2664, 1.2547, 1.2701, 1.2787, 1.2415, 1.2322, 1.2585, 1.2289, 1.2289,
         1.2797, 1.3263, 1.2629, 1.2834, 1.3179, 1.2700, 1.2868, 1.2264, 1.2645,
         1.3535, 1.3885, 1.3797, 1.3615, 1.3604, 1.3071, 1.3582, 1.3923, 1.3390,
         1.3588, 1.3043, 1.2974, 1.2780, 1.3499, 1.3004, 1.3918, 1.2795, 1.2856],
        [1.3046, 1.1686, 1.0128, 1.2433, 1.2995, 1.3571, 1.2787, 1.3492, 1.3492,
         1.3897, 1.6286, 1.3337, 2.2116, 1.3839, 3.5302, 1.4609, 1.2821, 3.1320,
         1.1431, 1.2096, 0.9564, 1.1853, 1.3266, 1.3603, 1.3358, 1.3600, 1.3600,
         1.3042, 1.0666, 1.3688, 1.3461, 1.1223, 1.3776, 1.3878, 1.3329, 1.3379,
         1.3268, 1.4761, 1.4145, 1.3336, 1.3114, 1.4241, 1.3922, 0.5304, 1.3563,
         1.0367, 1.4138, 1.4030, 1.3860, 1.0836, 1.4077, 0.8497, 1.3876, 1.3947],
        [1.2255, 1.2574, 1.3230, 1.2951, 1.2553, 1.2308, 1.2356, 1.2228, 1.2228,
         1.2933, 1.3058, 1.3089, 1.3209, 1.2830, 1.3019, 1.2904, 1.2736, 1.2087,
         1.9714, 2.0815, 2.1988, 2.1150, 1.8621, 1.9276, 2.0203, 1.8515, 1.8515,
         1.3274, 1.2946, 1.2699, 1.2909, 1.3264, 1.2773, 1.2958, 1.2733, 1.2716,
         1.3587, 1.3938, 1.3849, 1.3560, 1.3659, 1.3575, 1.3630, 1.2973, 1.3372,
         1.3141, 1.3120, 1.3051, 1.2852, 1.2778, 1.3086, 1.3584, 1.2868, 1.2929],
        [1.2384, 1.2644, 1.2176, 1.1930, 1.2691, 1.2444, 1.2511, 1.2369, 1.2369,
         1.2966, 1.2267, 1.3084, 1.2884, 1.2860, 1.2778, 1.2934, 1.2885, 1.0382,
         1.2825, 1.2552, 1.3213, 1.2918, 1.2596, 1.2158, 1.2719, 1.2481, 1.2481,
         2.3113, 1.9312, 1.7445, 1.8527, 2.2744, 1.7429, 2.2429, 1.7580, 1.7350,
         1.3380, 1.3672, 1.3189, 1.3034, 1.3513, 1.3096, 1.3359, 1.1193, 1.3108,
         1.3716, 1.2597, 1.1781, 1.2346, 1.3678, 1.1876, 1.4047, 1.2374, 1.2885],
        [1.5484, 1.2469, 0.4703, 0.6879, 1.0505, 1.4361, 1.3740, 1.5463, 1.5463,
         1.4579, 1.2258, 1.2862, 0.8229, 1.5357, 0.1028, 1.4449, 1.5529, 1.1323,
         1.1690, 0.7436, 0.6377, 0.9524, 1.4112, 1.5113, 1.1764, 1.5546, 1.5546,
         0.5969, 0.6763, 1.5208, 1.2887, 0.7519, 1.5239, 1.0252, 1.5646, 1.5169,
         0.8564, 0.5304, 0.4666, 0.7784, 1.2808, 1.5502, 0.7126, 4.7195, 4.3221,
         0.6477, 1.1316, 1.2049, 1.4742, 0.8755, 1.4415, 0.2869, 1.4529, 1.5941],
        [1.3007, 1.3271, 1.3800, 1.3607, 1.3329, 1.3082, 1.2730, 1.2990, 1.2990,
         1.2649, 1.3271, 1.2457, 1.3878, 1.3502, 1.4288, 1.2627, 1.3534, 1.2735,
         1.3419, 1.3649, 1.3832, 1.3511, 1.3181, 1.3084, 1.2836, 1.3073, 1.3073,
         1.3631, 1.4297, 1.3303, 1.2017, 1.2382, 1.1438, 1.3637, 1.2182, 1.3326,
         1.4009, 1.1736, 1.4297, 1.4128, 1.0634, 0.9757, 1.4061, 1.3605, 0.8284,
         2.3960, 1.9746, 2.2475, 2.1667, 1.7221, 1.4635, 2.3310, 2.0856, 1.4466]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 57 : 181.97492589430857
Test loss for epoch 57 : 182.02589301500126
Test Precision for epoch 57 : 0.26153846153846155
Test Recall for epoch 57 : 0.26153846153846155
Test F1 for epoch 57 : 0.26153846153846155


theta for epoch 58 : tensor([[1.9331, 1.9693, 2.0414, 2.0928, 2.0565, 1.9376, 2.0209, 1.9312, 1.9312,
         1.2845, 1.2959, 1.3010, 1.3150, 1.2734, 1.3642, 1.2817, 1.2763, 1.2491,
         1.2642, 1.2535, 1.2672, 1.2768, 1.2381, 1.2284, 1.2557, 1.2250, 1.2250,
         1.2791, 1.3261, 1.2626, 1.2831, 1.3177, 1.2698, 1.2864, 1.2258, 1.2642,
         1.3566, 1.3910, 1.3828, 1.3644, 1.3624, 1.3084, 1.3614, 1.3931, 1.3394,
         1.3562, 1.3023, 1.2954, 1.2762, 1.3473, 1.2983, 1.3891, 1.2776, 1.2837],
        [1.3020, 1.1679, 1.0140, 1.2422, 1.2977, 1.3549, 1.2761, 1.3468, 1.3468,
         1.3895, 1.6258, 1.3369, 2.2076, 1.3852, 3.5495, 1.4633, 1.2850, 3.1508,
         1.1402, 1.2084, 0.9563, 1.1833, 1.3242, 1.3585, 1.3345, 1.3581, 1.3581,
         1.3049, 1.0652, 1.3699, 1.3470, 1.1223, 1.3786, 1.3886, 1.3338, 1.3392,
         1.3298, 1.4780, 1.4169, 1.3359, 1.3138, 1.4258, 1.3947, 0.5320, 1.3618,
         1.0356, 1.4124, 1.4017, 1.3847, 1.0813, 1.4062, 0.8496, 1.3862, 1.3933],
        [1.2217, 1.2542, 1.3204, 1.2930, 1.2536, 1.2270, 1.2329, 1.2189, 1.2189,
         1.2942, 1.3068, 1.3103, 1.3230, 1.2834, 1.3038, 1.2913, 1.2736, 1.2102,
         1.9749, 2.0820, 2.1985, 2.1163, 1.8673, 1.9334, 2.0228, 1.8570, 1.8570,
         1.3265, 1.2936, 1.2700, 1.2908, 1.3252, 1.2773, 1.2956, 1.2733, 1.2716,
         1.3618, 1.3964, 1.3881, 1.3596, 1.3680, 1.3591, 1.3664, 1.2984, 1.3390,
         1.3127, 1.3101, 1.3032, 1.2834, 1.2745, 1.3066, 1.3548, 1.2849, 1.2911],
        [1.2398, 1.2662, 1.2197, 1.1943, 1.2707, 1.2455, 1.2524, 1.2381, 1.2381,
         1.2996, 1.2299, 1.3113, 1.2922, 1.2886, 1.2825, 1.2962, 1.2908, 1.0411,
         1.2839, 1.2564, 1.3232, 1.2934, 1.2605, 1.2167, 1.2733, 1.2490, 1.2490,
         2.3169, 1.9355, 1.7469, 1.8555, 2.2805, 1.7456, 2.2485, 1.7604, 1.7377,
         1.3424, 1.3725, 1.3243, 1.3080, 1.3544, 1.3142, 1.3411, 1.1235, 1.3142,
         1.3723, 1.2616, 1.1799, 1.2364, 1.3683, 1.1898, 1.4052, 1.2390, 1.2902],
        [1.5494, 1.2465, 0.4697, 0.6876, 1.0498, 1.4375, 1.3752, 1.5472, 1.5472,
         1.4573, 1.2250, 1.2850, 0.8220, 1.5355, 0.1047, 1.4441, 1.5532, 1.1308,
         1.1691, 0.7422, 0.6383, 0.9522, 1.4115, 1.5114, 1.1747, 1.5551, 1.5551,
         0.5960, 0.6769, 1.5215, 1.2892, 0.7501, 1.5237, 1.0243, 1.5650, 1.5173,
         0.8448, 0.5235, 0.4599, 0.7681, 1.2676, 1.5392, 0.7026, 4.7865, 4.3786,
         0.6430, 1.1267, 1.2005, 1.4715, 0.8719, 1.4386, 0.2840, 1.4499, 1.5922],
        [1.2982, 1.3251, 1.3785, 1.3591, 1.3295, 1.3047, 1.2701, 1.2963, 1.2963,
         1.2609, 1.3247, 1.2429, 1.3856, 1.3466, 1.4287, 1.2588, 1.3497, 1.2717,
         1.3399, 1.3623, 1.3782, 1.3479, 1.3157, 1.3059, 1.2812, 1.3048, 1.3048,
         1.3616, 1.4258, 1.3298, 1.1994, 1.2371, 1.1427, 1.3624, 1.2172, 1.3320,
         1.4030, 1.1738, 1.4318, 1.4145, 1.0623, 0.9732, 1.4084, 1.3580, 0.8237,
         2.4025, 1.9825, 2.2586, 2.1762, 1.7246, 1.4697, 2.3360, 2.0959, 1.4529]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 58 : 181.9458853867464
Test loss for epoch 58 : 181.99839842082366
Test Precision for epoch 58 : 0.26153846153846155
Test Recall for epoch 58 : 0.26153846153846155
Test F1 for epoch 58 : 0.26153846153846155


theta for epoch 59 : tensor([[1.9380, 1.9726, 2.0439, 2.0964, 2.0597, 1.9422, 2.0262, 1.9361, 1.9361,
         1.2851, 1.2974, 1.3023, 1.3169, 1.2735, 1.3674, 1.2824, 1.2763, 1.2511,
         1.2641, 1.2543, 1.2663, 1.2769, 1.2369, 1.2269, 1.2550, 1.2234, 1.2234,
         1.2769, 1.3246, 1.2607, 1.2812, 1.3160, 1.2679, 1.2843, 1.2235, 1.2622,
         1.3588, 1.3927, 1.3849, 1.3665, 1.3637, 1.3091, 1.3637, 1.3933, 1.3390,
         1.3533, 1.3001, 1.2932, 1.2740, 1.3445, 1.2959, 1.3861, 1.2753, 1.2814],
        [1.3009, 1.1688, 1.0164, 1.2428, 1.2976, 1.3541, 1.2751, 1.3458, 1.3458,
         1.3891, 1.6231, 1.3399, 2.2034, 1.3864, 3.5684, 1.4656, 1.2875, 3.1692,
         1.1390, 1.2088, 0.9572, 1.1829, 1.3233, 1.3582, 1.3345, 1.3576, 1.3576,
         1.3044, 1.0627, 1.3697, 1.3465, 1.1210, 1.3784, 1.3882, 1.3335, 1.3390,
         1.3318, 1.4793, 1.4184, 1.3373, 1.3154, 1.4269, 1.3965, 0.5328, 1.3663,
         1.0341, 1.4110, 1.4002, 1.3831, 1.0787, 1.4044, 0.8492, 1.3845, 1.3916],
        [1.2201, 1.2530, 1.3195, 1.2927, 1.2538, 1.2253, 1.2324, 1.2172, 1.2172,
         1.2947, 1.3073, 1.3113, 1.3246, 1.2833, 1.3056, 1.2918, 1.2731, 1.2112,
         1.9799, 2.0840, 2.1996, 2.1190, 1.8737, 1.9405, 2.0266, 1.8638, 1.8638,
         1.3238, 1.2910, 1.2682, 1.2890, 1.3224, 1.2756, 1.2938, 1.2715, 1.2697,
         1.3641, 1.3981, 1.3903, 1.3622, 1.3693, 1.3600, 1.3687, 1.2988, 1.3397,
         1.3109, 1.3079, 1.3009, 1.2812, 1.2708, 1.3042, 1.3508, 1.2826, 1.2887],
        [1.2408, 1.2678, 1.2216, 1.1955, 1.2721, 1.2463, 1.2535, 1.2391, 1.2391,
         1.3010, 1.2315, 1.3128, 1.2944, 1.2895, 1.2856, 1.2975, 1.2916, 1.0426,
         1.2851, 1.2576, 1.3249, 1.2950, 1.2612, 1.2174, 1.2746, 1.2496, 1.2496,
         2.3233, 1.9407, 1.7502, 1.8591, 2.2874, 1.7493, 2.2549, 1.7638, 1.7413,
         1.3455, 1.3764, 1.3283, 1.3114, 1.3564, 1.3175, 1.3450, 1.1265, 1.3164,
         1.3720, 1.2624, 1.1806, 1.2371, 1.3678, 1.1909, 1.4048, 1.2394, 1.2908],
        [1.5533, 1.2493, 0.4728, 0.6909, 1.0526, 1.4419, 1.3793, 1.5509, 1.5509,
         1.4587, 1.2266, 1.2861, 0.8241, 1.5372, 0.1101, 1.4452, 1.5551, 1.1318,
         1.1724, 0.7447, 0.6426, 0.9555, 1.4150, 1.5143, 1.1763, 1.5583, 1.5583,
         0.5969, 0.6792, 1.5228, 1.2906, 0.7500, 1.5240, 1.0246, 1.5660, 1.5183,
         0.8303, 0.5140, 0.4507, 0.7550, 1.2512, 1.5247, 0.6899, 4.8513, 4.4324,
         0.6419, 1.1245, 1.1984, 1.4702, 0.8715, 1.4373, 0.2855, 1.4485, 1.5916],
        [1.2955, 1.3231, 1.3773, 1.3577, 1.3263, 1.3011, 1.2672, 1.2935, 1.2935,
         1.2555, 1.3209, 1.2387, 1.3821, 1.3413, 1.4275, 1.2534, 1.3445, 1.2682,
         1.3381, 1.3601, 1.3739, 1.3450, 1.3134, 1.3034, 1.2789, 1.3022, 1.3022,
         1.3581, 1.4199, 1.3272, 1.1950, 1.2342, 1.1395, 1.3591, 1.2139, 1.3292,
         1.4036, 1.1721, 1.4322, 1.4146, 1.0593, 0.9688, 1.4092, 1.3543, 0.8176,
         2.4105, 1.9919, 2.2712, 2.1871, 1.7287, 1.4773, 2.3425, 2.1077, 1.4607]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 59 : 181.91701692844256
Test loss for epoch 59 : 181.96848645749822
Test Precision for epoch 59 : 0.26153846153846155
Test Recall for epoch 59 : 0.26153846153846155
Test F1 for epoch 59 : 0.26153846153846155


theta for epoch 60 : tensor([[1.9441, 1.9772, 2.0477, 2.1013, 2.0642, 1.9481, 2.0326, 1.9423, 1.9423,
         1.2849, 1.2979, 1.3028, 1.3178, 1.2728, 1.3696, 1.2823, 1.2756, 1.2521,
         1.2652, 1.2560, 1.2665, 1.2780, 1.2370, 1.2268, 1.2556, 1.2231, 1.2231,
         1.2749, 1.3233, 1.2588, 1.2795, 1.3146, 1.2662, 1.2824, 1.2214, 1.2602,
         1.3595, 1.3929, 1.3855, 1.3671, 1.3637, 1.3084, 1.3645, 1.3922, 1.3374,
         1.3505, 1.2978, 1.2909, 1.2715, 1.3417, 1.2932, 1.3830, 1.2728, 1.2789],
        [1.3008, 1.1707, 1.0194, 1.2442, 1.2984, 1.3540, 1.2749, 1.3457, 1.3457,
         1.3889, 1.6205, 1.3429, 2.1990, 1.3875, 3.5868, 1.4677, 1.2900, 3.1874,
         1.1388, 1.2100, 0.9587, 1.1834, 1.3232, 1.3585, 1.3354, 1.3578, 1.3578,
         1.3042, 1.0606, 1.3697, 1.3462, 1.1202, 1.3784, 1.3881, 1.3334, 1.3390,
         1.3323, 1.4792, 1.4185, 1.3372, 1.3155, 1.4268, 1.3968, 0.5323, 1.3693,
         1.0324, 1.4095, 1.3987, 1.3813, 1.0759, 1.4025, 0.8484, 1.3827, 1.3897],
        [1.2200, 1.2531, 1.3195, 1.2935, 1.2553, 1.2253, 1.2334, 1.2171, 1.2171,
         1.2943, 1.3071, 1.3115, 1.3254, 1.2824, 1.3067, 1.2914, 1.2719, 1.2115,
         1.9858, 2.0869, 2.2016, 2.1227, 1.8811, 1.9484, 2.0312, 1.8714, 1.8714,
         1.3214, 1.2888, 1.2666, 1.2874, 1.3197, 1.2740, 1.2922, 1.2699, 1.2680,
         1.3648, 1.3984, 1.3909, 1.3632, 1.3692, 1.3596, 1.3696, 1.2979, 1.3389,
         1.3090, 1.3056, 1.2986, 1.2787, 1.2671, 1.3016, 1.3469, 1.2800, 1.2861],
        [1.2406, 1.2681, 1.2223, 1.1956, 1.2722, 1.2459, 1.2534, 1.2388, 1.2388,
         1.3000, 1.2306, 1.3119, 1.2941, 1.2880, 1.2862, 1.2964, 1.2900, 1.0418,
         1.2852, 1.2577, 1.3256, 1.2954, 1.2607, 1.2169, 1.2748, 1.2491, 1.2491,
         2.3316, 1.9479, 1.7555, 1.8647, 2.2961, 1.7549, 2.2632, 1.7692, 1.7470,
         1.3466, 1.3783, 1.3301, 1.3128, 1.3565, 1.3187, 1.3468, 1.1276, 1.3166,
         1.3707, 1.2620, 1.1800, 1.2364, 1.3662, 1.1906, 1.4033, 1.2386, 1.2900],
        [1.5588, 1.2540, 0.4780, 0.6962, 1.0574, 1.4479, 1.3851, 1.5563, 1.5563,
         1.4608, 1.2292, 1.2881, 0.8276, 1.5394, 0.1169, 1.4470, 1.5576, 1.1338,
         1.1774, 0.7493, 0.6489, 0.9608, 1.4201, 1.5188, 1.1800, 1.5632, 1.5632,
         0.5998, 0.6833, 1.5253, 1.2935, 0.7516, 1.5256, 1.0264, 1.5683, 1.5205,
         0.8141, 0.5028, 0.4399, 0.7402, 1.2327, 1.5076, 0.6755, 4.9145, 4.4842,
         0.6431, 1.1237, 1.1976, 1.4695, 0.8731, 1.4369, 0.2896, 1.4479, 1.5917],
        [1.2944, 1.3226, 1.3778, 1.3580, 1.3248, 1.2991, 1.2659, 1.2923, 1.2923,
         1.2505, 1.3176, 1.2352, 1.3790, 1.3363, 1.4268, 1.2486, 1.3395, 1.2651,
         1.3378, 1.3597, 1.3714, 1.3438, 1.3127, 1.3024, 1.2783, 1.3012, 1.3012,
         1.3555, 1.4149, 1.3254, 1.1913, 1.2322, 1.1371, 1.3565, 1.2113, 1.3273,
         1.4030, 1.1691, 1.4315, 1.4135, 1.0552, 0.9635, 1.4087, 1.3501, 0.8114,
         2.4169, 1.9997, 2.2821, 2.1963, 1.7316, 1.4834, 2.3474, 2.1178, 1.4669]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 60 : 181.88945518930308
Test loss for epoch 60 : 181.93909556679466
Test Precision for epoch 60 : 0.26153846153846155
Test Recall for epoch 60 : 0.26153846153846155
Test F1 for epoch 60 : 0.26153846153846155


theta for epoch 61 : tensor([[1.9490, 1.9807, 2.0506, 2.1051, 2.0676, 1.9528, 2.0379, 1.9472, 1.9472,
         1.2849, 1.2985, 1.3034, 1.3187, 1.2723, 1.3716, 1.2824, 1.2751, 1.2532,
         1.2651, 1.2563, 1.2656, 1.2781, 1.2363, 1.2260, 1.2552, 1.2222, 1.2222,
         1.2740, 1.3231, 1.2578, 1.2787, 1.3143, 1.2654, 1.2815, 1.2201, 1.2592,
         1.3599, 1.3929, 1.3858, 1.3674, 1.3636, 1.3076, 1.3649, 1.3911, 1.3358,
         1.3486, 1.2964, 1.2894, 1.2698, 1.3400, 1.2914, 1.3810, 1.2711, 1.2770],
        [1.2990, 1.1710, 1.0204, 1.2438, 1.2976, 1.3523, 1.2731, 1.3438, 1.3438,
         1.3893, 1.6188, 1.3463, 2.1950, 1.3893, 3.6054, 1.4704, 1.2929, 3.2060,
         1.1375, 1.2100, 0.9588, 1.1826, 1.3218, 1.3574, 1.3349, 1.3566, 1.3566,
         1.3046, 1.0592, 1.3702, 1.3465, 1.1199, 1.3791, 1.3885, 1.3340, 1.3395,
         1.3323, 1.4788, 1.4182, 1.3367, 1.3151, 1.4264, 1.3966, 0.5313, 1.3717,
         1.0309, 1.4086, 1.3978, 1.3799, 1.0735, 1.4011, 0.8478, 1.3814, 1.3881],
        [1.2192, 1.2522, 1.3182, 1.2931, 1.2555, 1.2244, 1.2334, 1.2162, 1.2162,
         1.2942, 1.3071, 1.3120, 1.3264, 1.2818, 1.3081, 1.2914, 1.2711, 1.2122,
         1.9905, 2.0886, 2.2025, 2.1251, 1.8871, 1.9549, 2.0346, 1.8776, 1.8776,
         1.3200, 1.2879, 1.2659, 1.2869, 1.3183, 1.2736, 1.2917, 1.2693, 1.2673,
         1.3654, 1.3985, 1.3913, 1.3640, 1.3692, 1.3593, 1.3702, 1.2969, 1.3379,
         1.3080, 1.3044, 1.2972, 1.2771, 1.2644, 1.2999, 1.3442, 1.2784, 1.2844],
        [1.2381, 1.2662, 1.2208, 1.1936, 1.2701, 1.2433, 1.2510, 1.2362, 1.2362,
         1.2977, 1.2284, 1.3099, 1.2923, 1.2852, 1.2853, 1.2940, 1.2871, 1.0398,
         1.2832, 1.2559, 1.3241, 1.2937, 1.2581, 1.2142, 1.2729, 1.2464, 1.2464,
         2.3411, 1.9565, 1.7623, 1.8717, 2.3061, 1.7621, 2.2727, 1.7761, 1.7541,
         1.3469, 1.3792, 1.3309, 1.3132, 1.3559, 1.3191, 1.3476, 1.1278, 1.3161,
         1.3692, 1.2614, 1.1790, 1.2353, 1.3645, 1.1899, 1.4017, 1.2374, 1.2889],
        [1.5625, 1.2567, 0.4811, 0.6994, 1.0599, 1.4519, 1.3888, 1.5598, 1.5598,
         1.4619, 1.2306, 1.2891, 0.8297, 1.5408, 0.1221, 1.4477, 1.5591, 1.1347,
         1.1806, 0.7520, 0.6530, 0.9641, 1.4237, 1.5217, 1.1820, 1.5665, 1.5665,
         0.6020, 0.6868, 1.5280, 1.2963, 0.7528, 1.5272, 1.0278, 1.5707, 1.5228,
         0.7992, 0.4930, 0.4303, 0.7266, 1.2152, 1.4915, 0.6624, 4.9786, 4.5369,
         0.6434, 1.1223, 1.1963, 1.4683, 0.8740, 1.4360, 0.2926, 1.4469, 1.5915],
        [1.2943, 1.3232, 1.3794, 1.3593, 1.3246, 1.2983, 1.2656, 1.2920, 1.2920,
         1.2487, 1.3174, 1.2348, 1.3787, 1.3341, 1.4287, 1.2469, 1.3373, 1.2649,
         1.3388, 1.3607, 1.3705, 1.3441, 1.3131, 1.3026, 1.2788, 1.3014, 1.3014,
         1.3550, 1.4120, 1.3255, 1.1897, 1.2325, 1.1370, 1.3560, 1.2109, 1.3273,
         1.4032, 1.1671, 1.4315, 1.4134, 1.0524, 0.9597, 1.4090, 1.3472, 0.8076,
         2.4200, 2.0040, 2.2895, 2.2019, 1.7314, 1.4862, 2.3491, 2.1245, 1.4698]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 61 : 181.8624402297902
Test loss for epoch 61 : 181.9123795705545
Test Precision for epoch 61 : 0.26153846153846155
Test Recall for epoch 61 : 0.26153846153846155
Test F1 for epoch 61 : 0.26153846153846155


theta for epoch 62 : tensor([[1.9530, 1.9834, 2.0527, 2.1080, 2.0703, 1.9566, 2.0423, 1.9512, 1.9512,
         1.2847, 1.2988, 1.3037, 1.3193, 1.2716, 1.3730, 1.2823, 1.2744, 1.2539,
         1.2636, 1.2549, 1.2632, 1.2765, 1.2344, 1.2239, 1.2534, 1.2201, 1.2201,
         1.2725, 1.3225, 1.2561, 1.2774, 1.3135, 1.2640, 1.2801, 1.2184, 1.2576,
         1.3605, 1.3931, 1.3862, 1.3680, 1.3638, 1.3073, 1.3656, 1.3903, 1.3346,
         1.3486, 1.2968, 1.2897, 1.2697, 1.3401, 1.2912, 1.3809, 1.2711, 1.2768],
        [1.2958, 1.1701, 1.0197, 1.2419, 1.2954, 1.3491, 1.2698, 1.3405, 1.3405,
         1.3898, 1.6173, 1.3497, 2.1909, 1.3911, 3.6236, 1.4729, 1.2956, 3.2243,
         1.1352, 1.2087, 0.9575, 1.1808, 1.3192, 1.3551, 1.3331, 1.3541, 1.3541,
         1.3044, 1.0572, 1.3700, 1.3461, 1.1191, 1.3790, 1.3883, 1.3338, 1.3393,
         1.3325, 1.4788, 1.4181, 1.3364, 1.3149, 1.4265, 1.3968, 0.5306, 1.3743,
         1.0309, 1.4095, 1.3985, 1.3801, 1.0727, 1.4013, 0.8484, 1.3816, 1.3882],
        [1.2174, 1.2500, 1.3153, 1.2910, 1.2542, 1.2226, 1.2322, 1.2145, 1.2145,
         1.2941, 1.3072, 1.3124, 1.3272, 1.2813, 1.3095, 1.2914, 1.2704, 1.2129,
         1.9942, 2.0893, 2.2023, 2.1265, 1.8919, 1.9602, 2.0368, 1.8826, 1.8826,
         1.3183, 1.2867, 1.2647, 1.2860, 1.3165, 1.2726, 1.2907, 1.2683, 1.2662,
         1.3663, 1.3990, 1.3920, 1.3650, 1.3697, 1.3595, 1.3711, 1.2963, 1.3373,
         1.3090, 1.3050, 1.2978, 1.2772, 1.2637, 1.3000, 1.3434, 1.2785, 1.2843],
        [1.2349, 1.2634, 1.2186, 1.1910, 1.2672, 1.2398, 1.2478, 1.2328, 1.2328,
         1.2954, 1.2261, 1.3079, 1.2904, 1.2825, 1.2842, 1.2917, 1.2843, 1.0380,
         1.2804, 1.2534, 1.3217, 1.2912, 1.2548, 1.2109, 1.2702, 1.2431, 1.2431,
         2.3499, 1.9645, 1.7686, 1.8782, 2.3155, 1.7687, 2.2816, 1.7824, 1.7607,
         1.3474, 1.3803, 1.3319, 1.3140, 1.3557, 1.3198, 1.3486, 1.1284, 1.3160,
         1.3691, 1.2620, 1.1791, 1.2354, 1.3641, 1.1903, 1.4016, 1.2374, 1.2890],
        [1.5635, 1.2562, 0.4810, 0.6995, 1.0590, 1.4530, 1.3894, 1.5607, 1.5607,
         1.4611, 1.2297, 1.2879, 0.8290, 1.5402, 0.1237, 1.4464, 1.5586, 1.1331,
         1.1807, 0.7514, 0.6536, 0.9641, 1.4246, 1.5222, 1.1815, 1.5674, 1.5674,
         0.6017, 0.6878, 1.5290, 1.2973, 0.7514, 1.5272, 1.0269, 1.5716, 1.5234,
         0.7870, 0.4856, 0.4232, 0.7158, 1.2003, 1.4777, 0.6520, 5.0445, 4.5914,
         0.6425, 1.1207, 1.1948, 1.4671, 0.8741, 1.4350, 0.2937, 1.4460, 1.5914],
        [1.2947, 1.3243, 1.3816, 1.3611, 1.3252, 1.2981, 1.2660, 1.2924, 1.2924,
         1.2492, 1.3193, 1.2367, 1.3802, 1.3339, 1.4323, 1.2474, 1.3371, 1.2667,
         1.3403, 1.3625, 1.3706, 1.3452, 1.3141, 1.3035, 1.2801, 1.3021, 1.3021,
         1.3551, 1.4098, 1.3262, 1.1888, 1.2338, 1.1378, 1.3561, 1.2111, 1.3279,
         1.4046, 1.1665, 1.4327, 1.4144, 1.0514, 0.9579, 1.4104, 1.3462, 0.8065,
         2.4208, 2.0060, 2.2945, 2.2052, 1.7292, 1.4868, 2.3485, 2.1288, 1.4705]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 62 : 181.8340346001419
Test loss for epoch 62 : 181.88655030858234
Test Precision for epoch 62 : 0.26153846153846155
Test Recall for epoch 62 : 0.26153846153846155
Test F1 for epoch 62 : 0.26153846153846155


theta for epoch 63 : tensor([[1.9583, 1.9875, 2.0563, 2.1123, 2.0743, 1.9617, 2.0479, 1.9564, 1.9564,
         1.2832, 1.2977, 1.3027, 1.3184, 1.2697, 1.3727, 1.2809, 1.2725, 1.2533,
         1.2619, 1.2530, 1.2607, 1.2747, 1.2326, 1.2221, 1.2517, 1.2183, 1.2183,
         1.2693, 1.3201, 1.2525, 1.2742, 1.3109, 1.2608, 1.2768, 1.2146, 1.2540,
         1.3603, 1.3926, 1.3858, 1.3677, 1.3634, 1.3063, 1.3653, 1.3888, 1.3328,
         1.3502, 1.2986, 1.2915, 1.2710, 1.3418, 1.2926, 1.3823, 1.2725, 1.2780],
        [1.2934, 1.1698, 1.0192, 1.2406, 1.2938, 1.3465, 1.2673, 1.3379, 1.3379,
         1.3897, 1.6153, 1.3523, 2.1861, 1.3922, 3.6409, 1.4748, 1.2976, 3.2419,
         1.1335, 1.2078, 0.9566, 1.1794, 1.3171, 1.3532, 1.3317, 1.3520, 1.3520,
         1.3028, 1.0540, 1.3683, 1.3442, 1.1171, 1.3776, 1.3867, 1.3322, 1.3376,
         1.3320, 1.4783, 1.4175, 1.3355, 1.3142, 1.4262, 1.3964, 0.5297, 1.3761,
         1.0326, 1.4122, 1.4011, 1.3820, 1.0738, 1.4034, 0.8507, 1.3837, 1.3900],
        [1.2160, 1.2480, 1.3122, 1.2888, 1.2529, 1.2212, 1.2312, 1.2131, 1.2131,
         1.2928, 1.3059, 1.3115, 1.3267, 1.2796, 1.3096, 1.2902, 1.2685, 1.2124,
         1.9989, 2.0911, 2.2033, 2.1290, 1.8977, 1.9665, 2.0400, 1.8885, 1.8885,
         1.3149, 1.2839, 1.2616, 1.2832, 1.3131, 1.2699, 1.2879, 1.2653, 1.2631,
         1.3663, 1.3987, 1.3918, 1.3652, 1.3695, 1.3591, 1.3712, 1.2950, 1.3358,
         1.3113, 1.3071, 1.2998, 1.2788, 1.2646, 1.3016, 1.3443, 1.2802, 1.2857],
        [1.2332, 1.2621, 1.2180, 1.1901, 1.2659, 1.2380, 1.2461, 1.2310, 1.2310,
         1.2937, 1.2245, 1.3065, 1.2890, 1.2803, 1.2834, 1.2900, 1.2821, 1.0370,
         1.2793, 1.2527, 1.3210, 1.2904, 1.2531, 1.2093, 1.2692, 1.2413, 1.2413,
         2.3567, 1.9706, 1.7730, 1.8828, 2.3228, 1.7734, 2.2884, 1.7868, 1.7654,
         1.3481, 1.3816, 1.3329, 1.3149, 1.3557, 1.3206, 1.3497, 1.1294, 1.3162,
         1.3710, 1.2645, 1.1812, 1.2374, 1.3657, 1.1925, 1.4035, 1.2393, 1.2910],
        [1.5641, 1.2549, 0.4800, 0.6986, 1.0573, 1.4534, 1.3894, 1.5611, 1.5611,
         1.4587, 1.2270, 1.2853, 0.8267, 1.5383, 0.1234, 1.4437, 1.5567, 1.1299,
         1.1801, 0.7500, 0.6528, 0.9633, 1.4249, 1.5221, 1.1804, 1.5679, 1.5679,
         0.5994, 0.6870, 1.5283, 1.2964, 0.7481, 1.5254, 1.0238, 1.5708, 1.5223,
         0.7759, 0.4792, 0.4171, 0.7060, 1.1861, 1.4645, 0.6427, 5.1110, 4.6465,
         0.6424, 1.1203, 1.1946, 1.4669, 0.8753, 1.4353, 0.2952, 1.4464, 1.5926],
        [1.2956, 1.3257, 1.3842, 1.3632, 1.3262, 1.2984, 1.2668, 1.2931, 1.2931,
         1.2492, 1.3207, 1.2381, 1.3811, 1.3332, 1.4351, 1.2475, 1.3364, 1.2677,
         1.3422, 1.3649, 1.3713, 1.3468, 1.3156, 1.3047, 1.2816, 1.3033, 1.3033,
         1.3542, 1.4066, 1.3255, 1.1868, 1.2341, 1.1374, 1.3550, 1.2100, 1.3272,
         1.4054, 1.1653, 1.4332, 1.4148, 1.0498, 0.9557, 1.4112, 1.3451, 0.8057,
         2.4220, 2.0083, 2.2998, 2.2087, 1.7277, 1.4878, 2.3484, 2.1335, 1.4716]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 63 : 181.80660751163074
Test loss for epoch 63 : 181.8616625522484
Test Precision for epoch 63 : 0.26153846153846155
Test Recall for epoch 63 : 0.26153846153846155
Test F1 for epoch 63 : 0.26153846153846155


theta for epoch 64 : tensor([[1.9647, 1.9928, 2.0611, 2.1179, 2.0797, 1.9679, 2.0547, 1.9629, 1.9629,
         1.2814, 1.2963, 1.3012, 1.3171, 1.2676, 1.3718, 1.2792, 1.2704, 1.2521,
         1.2606, 1.2513, 1.2586, 1.2733, 1.2313, 1.2209, 1.2504, 1.2171, 1.2171,
         1.2662, 1.3178, 1.2488, 1.2710, 1.3085, 1.2574, 1.2736, 1.2109, 1.2504,
         1.3586, 1.3905, 1.3838, 1.3660, 1.3616, 1.3039, 1.3635, 1.3861, 1.3296,
         1.3519, 1.3006, 1.2934, 1.2724, 1.3436, 1.2940, 1.3838, 1.2740, 1.2792],
        [1.2915, 1.1700, 1.0185, 1.2395, 1.2927, 1.3444, 1.2653, 1.3357, 1.3357,
         1.3902, 1.6142, 1.3554, 2.1818, 1.3940, 3.6584, 1.4771, 1.3001, 3.2598,
         1.1324, 1.2073, 0.9559, 1.1785, 1.3155, 1.3517, 1.3306, 1.3503, 1.3503,
         1.3013, 1.0510, 1.3664, 1.3422, 1.1152, 1.3760, 1.3851, 1.3305, 1.3357,
         1.3301, 1.4764, 1.4155, 1.3332, 1.3120, 1.4247, 1.3946, 0.5274, 1.3763,
         1.0344, 1.4151, 1.4039, 1.3841, 1.0750, 1.4057, 0.8529, 1.3860, 1.3919],
        [1.2147, 1.2461, 1.3091, 1.2865, 1.2515, 1.2200, 1.2301, 1.2120, 1.2120,
         1.2909, 1.3041, 1.3101, 1.3255, 1.2773, 1.3093, 1.2884, 1.2662, 1.2112,
         2.0053, 2.0946, 2.2060, 2.1332, 1.9051, 1.9743, 2.0449, 1.8960, 1.8960,
         1.3113, 1.2810, 1.2582, 1.2802, 1.3096, 1.2668, 1.2849, 1.2621, 1.2597,
         1.3647, 1.3968, 1.3900, 1.3637, 1.3678, 1.3572, 1.3696, 1.2923, 1.3327,
         1.3136, 1.3092, 1.3017, 1.2802, 1.2655, 1.3031, 1.3453, 1.2817, 1.2870],
        [1.2330, 1.2624, 1.2190, 1.1908, 1.2660, 1.2378, 1.2460, 1.2308, 1.2308,
         1.2931, 1.2242, 1.3063, 1.2888, 1.2794, 1.2836, 1.2895, 1.2811, 1.0375,
         1.2798, 1.2536, 1.3218, 1.2912, 1.2532, 1.2095, 1.2699, 1.2413, 1.2413,
         2.3620, 1.9755, 1.7761, 1.8861, 2.3287, 1.7769, 2.2939, 1.7901, 1.7689,
         1.3483, 1.3821, 1.3332, 1.3153, 1.3554, 1.3209, 1.3501, 1.1300, 1.3158,
         1.3737, 1.2678, 1.1840, 1.2401, 1.3681, 1.1954, 1.4062, 1.2420, 1.2938],
        [1.5655, 1.2548, 0.4803, 0.6990, 1.0568, 1.4547, 1.3903, 1.5625, 1.5625,
         1.4572, 1.2254, 1.2836, 0.8254, 1.5371, 0.1241, 1.4418, 1.5556, 1.1279,
         1.1806, 0.7499, 0.6532, 0.9638, 1.4264, 1.5231, 1.1808, 1.5694, 1.5694,
         0.5980, 0.6870, 1.5281, 1.2961, 0.7457, 1.5241, 1.0215, 1.5706, 1.5217,
         0.7637, 0.4718, 0.4098, 0.6951, 1.1706, 1.4496, 0.6323, 5.1765, 4.7002,
         0.6443, 1.1215, 1.1959, 1.4677, 0.8783, 1.4367, 0.2986, 1.4481, 1.5947],
        [1.2957, 1.3262, 1.3860, 1.3646, 1.3267, 1.2981, 1.2667, 1.2931, 1.2931,
         1.2481, 1.3211, 1.2383, 1.3809, 1.3313, 1.4366, 1.2466, 1.3346, 1.2674,
         1.3434, 1.3666, 1.3718, 1.3479, 1.3163, 1.3053, 1.2825, 1.3037, 1.3037,
         1.3527, 1.4031, 1.3240, 1.1839, 1.2339, 1.1363, 1.3532, 1.2080, 1.3257,
         1.4041, 1.1617, 1.4315, 1.4131, 1.0460, 0.9513, 1.4098, 1.3425, 0.8031,
         2.4248, 2.0123, 2.3068, 2.2138, 1.7282, 1.4905, 2.3499, 2.1399, 1.4744]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 64 : 181.78101114015723
Test loss for epoch 64 : 181.83712745175413
Test Precision for epoch 64 : 0.26153846153846155
Test Recall for epoch 64 : 0.26153846153846155
Test F1 for epoch 64 : 0.26153846153846155


theta for epoch 65 : tensor([[1.9705, 1.9976, 2.0655, 2.1229, 2.0845, 1.9736, 2.0609, 1.9686, 1.9686,
         1.2807, 1.2959, 1.3008, 1.3168, 1.2667, 1.3717, 1.2787, 1.2695, 1.2520,
         1.2590, 1.2492, 1.2564, 1.2715, 1.2300, 1.2197, 1.2490, 1.2159, 1.2159,
         1.2660, 1.3183, 1.2477, 1.2705, 1.3089, 1.2567, 1.2731, 1.2098, 1.2494,
         1.3566, 1.3883, 1.3815, 1.3640, 1.3597, 1.3014, 1.3614, 1.3834, 1.3264,
         1.3519, 1.3009, 1.2936, 1.2720, 1.3438, 1.2937, 1.3837, 1.2737, 1.2787],
        [1.2890, 1.1695, 1.0169, 1.2376, 1.2910, 1.3416, 1.2627, 1.3329, 1.3329,
         1.3922, 1.6146, 1.3597, 2.1789, 1.3971, 3.6767, 1.4806, 1.3038, 3.2788,
         1.1306, 1.2059, 0.9543, 1.1768, 1.3130, 1.3492, 1.3286, 1.3477, 1.3477,
         1.3018, 1.0502, 1.3664, 1.3422, 1.1155, 1.3763, 1.3855, 1.3306, 1.3356,
         1.3275, 1.4740, 1.4128, 1.3303, 1.3092, 1.4226, 1.3922, 0.5246, 1.3758,
         1.0339, 1.4159, 1.4045, 1.3840, 1.0740, 1.4057, 0.8528, 1.3860, 1.3917],
        [1.2134, 1.2439, 1.3057, 1.2839, 1.2497, 1.2187, 1.2288, 1.2108, 1.2108,
         1.2898, 1.3032, 1.3093, 1.3250, 1.2760, 1.3097, 1.2875, 1.2649, 1.2109,
         2.0118, 2.0983, 2.2088, 2.1374, 1.9124, 1.9819, 2.0497, 1.9034, 1.9034,
         1.3104, 1.2808, 1.2570, 1.2796, 1.3087, 1.2660, 1.2843, 1.2612, 1.2586,
         1.3627, 1.3945, 1.3877, 1.3617, 1.3658, 1.3551, 1.3676, 1.2893, 1.3292,
         1.3138, 1.3095, 1.3018, 1.2797, 1.2646, 1.3028, 1.3444, 1.2813, 1.2864],
        [1.2329, 1.2626, 1.2201, 1.1918, 1.2663, 1.2376, 1.2460, 1.2306, 1.2306,
         1.2936, 1.2249, 1.3072, 1.2895, 1.2796, 1.2848, 1.2901, 1.2813, 1.0391,
         1.2801, 1.2545, 1.3224, 1.2918, 1.2530, 1.2095, 1.2704, 1.2411, 1.2411,
         2.3676, 1.9806, 1.7796, 1.8897, 2.3347, 1.7808, 2.2995, 1.7936, 1.7728,
         1.3482, 1.3824, 1.3333, 1.3154, 1.3549, 1.3209, 1.3503, 1.1306, 1.3153,
         1.3749, 1.2697, 1.1854, 1.2414, 1.3691, 1.1969, 1.4075, 1.2432, 1.2949],
        [1.5675, 1.2555, 0.4819, 0.7006, 1.0573, 1.4566, 1.3918, 1.5644, 1.5644,
         1.4576, 1.2259, 1.2840, 0.8264, 1.5379, 0.1265, 1.4418, 1.5562, 1.1280,
         1.1818, 0.7511, 0.6545, 0.9651, 1.4283, 1.5244, 1.1820, 1.5712, 1.5712,
         0.5994, 0.6895, 1.5303, 1.2984, 0.7458, 1.5250, 1.0218, 1.5727, 1.5235,
         0.7504, 0.4632, 0.4016, 0.6831, 1.1538, 1.4330, 0.6210, 5.2408, 4.7525,
         0.6463, 1.1224, 1.1968, 1.4673, 0.8811, 1.4371, 0.3023, 1.4489, 1.5957],
        [1.2940, 1.3251, 1.3861, 1.3642, 1.3257, 1.2962, 1.2650, 1.2914, 1.2914,
         1.2468, 1.3213, 1.2383, 1.3803, 1.3294, 1.4375, 1.2453, 1.3326, 1.2664,
         1.3427, 1.3667, 1.3710, 1.3473, 1.3153, 1.3040, 1.2815, 1.3024, 1.3024,
         1.3523, 1.4008, 1.3235, 1.1819, 1.2348, 1.1360, 1.3526, 1.2068, 1.3252,
         1.4016, 1.1567, 1.4287, 1.4103, 1.0409, 0.9457, 1.4072, 1.3392, 0.7997,
         2.4286, 2.0172, 2.3148, 2.2198, 1.7298, 1.4943, 2.3524, 2.1473, 1.4782]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 65 : 181.75532754616472
Test loss for epoch 65 : 181.81175377705455
Test Precision for epoch 65 : 0.26153846153846155
Test Recall for epoch 65 : 0.26153846153846155
Test F1 for epoch 65 : 0.26153846153846155


theta for epoch 66 : tensor([[1.9752, 2.0015, 2.0691, 2.1270, 2.0884, 1.9782, 2.0660, 1.9734, 1.9734,
         1.2805, 1.2959, 1.3009, 1.3170, 1.2664, 1.3718, 1.2787, 1.2692, 1.2523,
         1.2573, 1.2469, 1.2542, 1.2697, 1.2287, 1.2186, 1.2476, 1.2148, 1.2148,
         1.2683, 1.3212, 1.2490, 1.2723, 1.3117, 1.2584, 1.2750, 1.2111, 1.2508,
         1.3559, 1.3874, 1.3806, 1.3634, 1.3593, 1.3005, 1.3607, 1.3822, 1.3248,
         1.3496, 1.2989, 1.2915, 1.2693, 1.3418, 1.2911, 1.3812, 1.2712, 1.2758],
        [1.2869, 1.1695, 1.0154, 1.2362, 1.2898, 1.3393, 1.2606, 1.3305, 1.3305,
         1.3938, 1.6150, 1.3636, 2.1755, 1.3998, 3.6943, 1.4837, 1.3070, 3.2973,
         1.1286, 1.2042, 0.9526, 1.1749, 1.3102, 1.3464, 1.3262, 1.3447, 1.3447,
         1.3044, 1.0518, 1.3683, 1.3441, 1.1181, 1.3786, 1.3879, 1.3327, 1.3376,
         1.3261, 1.4729, 1.4115, 1.3286, 1.3078, 1.4220, 1.3910, 0.5232, 1.3763,
         1.0308, 1.4141, 1.4025, 1.3813, 1.0706, 1.4032, 0.8500, 1.3835, 1.3888],
        [1.2131, 1.2428, 1.3034, 1.2822, 1.2488, 1.2184, 1.2284, 1.2106, 1.2106,
         1.2891, 1.3026, 1.3089, 1.3248, 1.2751, 1.3104, 1.2869, 1.2641, 1.2109,
         2.0172, 2.1010, 2.2107, 2.1407, 1.9185, 1.9885, 2.0535, 1.9096, 1.9096,
         1.3119, 1.2831, 1.2581, 1.2812, 1.3103, 1.2675, 1.2860, 1.2625, 1.2598,
         1.3620, 1.3936, 1.3867, 1.3611, 1.3653, 1.3544, 1.3668, 1.2879, 1.3270,
         1.3118, 1.3074, 1.2996, 1.2769, 1.2615, 1.3001, 1.3413, 1.2786, 1.2834],
        [1.2325, 1.2625, 1.2210, 1.1926, 1.2663, 1.2372, 1.2456, 1.2301, 1.2301,
         1.2938, 1.2254, 1.3079, 1.2901, 1.2796, 1.2855, 1.2905, 1.2813, 1.0406,
         1.2796, 1.2548, 1.3222, 1.2917, 1.2521, 1.2088, 1.2701, 1.2401, 1.2401,
         2.3737, 1.9865, 1.7839, 1.8941, 2.3414, 1.7853, 2.3057, 1.7979, 1.7774,
         1.3489, 1.3834, 1.3340, 1.3164, 1.3554, 1.3218, 1.3511, 1.1320, 1.3156,
         1.3739, 1.2694, 1.1846, 1.2403, 1.3678, 1.1962, 1.4065, 1.2422, 1.2938],
        [1.5696, 1.2562, 0.4839, 0.7024, 1.0581, 1.4585, 1.3933, 1.5663, 1.5663,
         1.4582, 1.2266, 1.2847, 0.8277, 1.5390, 0.1291, 1.4421, 1.5571, 1.1284,
         1.1827, 0.7521, 0.6554, 0.9662, 1.4298, 1.5254, 1.1832, 1.5727, 1.5727,
         0.6023, 0.6936, 1.5341, 1.3023, 0.7474, 1.5275, 1.0237, 1.5766, 1.5269,
         0.7378, 0.4551, 0.3938, 0.6718, 1.1372, 1.4165, 0.6102, 5.3052, 4.8046,
         0.6463, 1.1210, 1.1952, 1.4643, 0.8819, 1.4349, 0.3041, 1.4471, 1.5940],
        [1.2914, 1.3229, 1.3852, 1.3627, 1.3238, 1.2934, 1.2623, 1.2887, 1.2887,
         1.2447, 1.3206, 1.2373, 1.3788, 1.3267, 1.4373, 1.2433, 1.3299, 1.2644,
         1.3405, 1.3653, 1.3690, 1.3454, 1.3128, 1.3013, 1.2790, 1.2996, 1.2996,
         1.3529, 1.3998, 1.3238, 1.1809, 1.2368, 1.1368, 1.3529, 1.2065, 1.3256,
         1.3999, 1.1523, 1.4266, 1.4083, 1.0365, 0.9409, 1.4054, 1.3374, 0.7973,
         2.4325, 2.0222, 2.3227, 2.2257, 1.7317, 1.4980, 2.3551, 2.1547, 1.4820]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 66 : 181.72861428410846
Test loss for epoch 66 : 181.78542912983363
Test Precision for epoch 66 : 0.26153846153846155
Test Recall for epoch 66 : 0.26153846153846155
Test F1 for epoch 66 : 0.26153846153846155


theta for epoch 67 : tensor([[1.9797, 2.0052, 2.0726, 2.1309, 2.0922, 1.9826, 2.0708, 1.9778, 1.9778,
         1.2798, 1.2953, 1.3002, 1.3164, 1.2655, 1.3711, 1.2780, 1.2683, 1.2518,
         1.2568, 1.2457, 1.2533, 1.2689, 1.2287, 1.2187, 1.2474, 1.2150, 1.2150,
         1.2697, 1.3233, 1.2494, 1.2734, 1.3136, 1.2592, 1.2762, 1.2116, 1.2513,
         1.3570, 1.3883, 1.3813, 1.3645, 1.3607, 1.3014, 1.3617, 1.3829, 1.3250,
         1.3466, 1.2961, 1.2886, 1.2658, 1.3390, 1.2877, 1.3780, 1.2678, 1.2721],
        [1.2864, 1.1709, 1.0149, 1.2361, 1.2900, 1.3384, 1.2600, 1.3296, 1.3296,
         1.3937, 1.6138, 1.3657, 2.1705, 1.4009, 3.7103, 1.4850, 1.3084, 3.3140,
         1.1281, 1.2037, 0.9522, 1.1744, 1.3089, 1.3448, 1.3250, 1.3430, 1.3430,
         1.3065, 1.0532, 1.3695, 1.3454, 1.1205, 1.3802, 1.3898, 1.3342, 1.3389,
         1.3267, 1.4738, 1.4121, 1.3289, 1.3083, 1.4235, 1.3919, 0.5239, 1.3786,
         1.0274, 1.4118, 1.4000, 1.3780, 1.0667, 1.4002, 0.8469, 1.3805, 1.3854],
        [1.2142, 1.2431, 1.3025, 1.2818, 1.2492, 1.2196, 1.2292, 1.2119, 1.2119,
         1.2879, 1.3015, 1.3079, 1.3240, 1.2737, 1.3107, 1.2858, 1.2629, 1.2104,
         2.0223, 2.1036, 2.2124, 2.1438, 1.9243, 1.9946, 2.0569, 1.9154, 1.9154,
         1.3127, 1.2847, 1.2584, 1.2821, 1.3112, 1.2681, 1.2870, 1.2631, 1.2602,
         1.3630, 1.3945, 1.3874, 1.3621, 1.3666, 1.3557, 1.3678, 1.2883, 1.3266,
         1.3089, 1.3045, 1.2966, 1.2733, 1.2577, 1.2966, 1.3375, 1.2751, 1.2797],
        [1.2323, 1.2626, 1.2220, 1.1937, 1.2665, 1.2370, 1.2455, 1.2299, 1.2299,
         1.2933, 1.2251, 1.3078, 1.2898, 1.2788, 1.2853, 1.2902, 1.2806, 1.0415,
         1.2794, 1.2555, 1.3222, 1.2917, 1.2515, 1.2085, 1.2701, 1.2394, 1.2394,
         2.3795, 1.9922, 1.7880, 1.8982, 2.3477, 1.7898, 2.3116, 1.8020, 1.7818,
         1.3509, 1.3856, 1.3359, 1.3186, 1.3572, 1.3240, 1.3532, 1.1347, 1.3173,
         1.3719, 1.2681, 1.1830, 1.2382, 1.3657, 1.1947, 1.4046, 1.2402, 1.2917],
        [1.5716, 1.2570, 0.4858, 0.7041, 1.0589, 1.4602, 1.3948, 1.5682, 1.5682,
         1.4580, 1.2264, 1.2846, 0.8281, 1.5392, 0.1306, 1.4415, 1.5571, 1.1280,
         1.1836, 0.7532, 0.6561, 0.9673, 1.4314, 1.5265, 1.1845, 1.5742, 1.5742,
         0.6045, 0.6969, 1.5371, 1.3054, 0.7482, 1.5290, 1.0248, 1.5795, 1.5294,
         0.7264, 0.4482, 0.3872, 0.6616, 1.1216, 1.4007, 0.6006, 5.3700, 4.8571,
         0.6454, 1.1185, 1.1927, 1.4600, 0.8816, 1.4316, 0.3046, 1.4444, 1.5913],
        [1.2885, 1.3203, 1.3838, 1.3608, 1.3217, 1.2905, 1.2593, 1.2857, 1.2857,
         1.2413, 1.3186, 1.2349, 1.3758, 1.3227, 1.4353, 1.2399, 1.3259, 1.2608,
         1.3381, 1.3638, 1.3672, 1.3434, 1.3100, 1.2984, 1.2762, 1.2965, 1.2965,
         1.3523, 1.3977, 1.3229, 1.1786, 1.2376, 1.1363, 1.3520, 1.2048, 1.3247,
         1.3996, 1.1494, 1.4259, 1.4078, 1.0337, 0.9377, 1.4050, 1.3375, 0.7968,
         2.4368, 2.0274, 2.3309, 2.2319, 1.7342, 1.5020, 2.3581, 2.1625, 1.4861]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 67 : 181.70321582012826
Test loss for epoch 67 : 181.76020982338036
Test Precision for epoch 67 : 0.26153846153846155
Test Recall for epoch 67 : 0.26153846153846155
Test F1 for epoch 67 : 0.26153846153846155


theta for epoch 68 : tensor([[1.9842, 2.0090, 2.0763, 2.1350, 2.0962, 1.9871, 2.0757, 1.9823, 1.9823,
         1.2794, 1.2949, 1.2998, 1.3162, 1.2651, 1.3704, 1.2777, 1.2679, 1.2516,
         1.2573, 1.2455, 1.2537, 1.2693, 1.2298, 1.2200, 1.2483, 1.2164, 1.2164,
         1.2682, 1.3223, 1.2469, 1.2714, 1.3126, 1.2571, 1.2744, 1.2092, 1.2489,
         1.3586, 1.3898, 1.3826, 1.3661, 1.3627, 1.3031, 1.3631, 1.3844, 1.3259,
         1.3447, 1.2945, 1.2868, 1.2634, 1.3373, 1.2855, 1.3760, 1.2656, 1.2696],
        [1.2862, 1.1726, 1.0145, 1.2362, 1.2905, 1.3378, 1.2597, 1.3289, 1.3289,
         1.3937, 1.6129, 1.3676, 2.1655, 1.4019, 3.7258, 1.4861, 1.3097, 3.3305,
         1.1287, 1.2042, 0.9529, 1.1748, 1.3085, 1.3442, 1.3248, 1.3422, 1.3422,
         1.3058, 1.0520, 1.3681, 1.3440, 1.1204, 1.3791, 1.3890, 1.3329, 1.3375,
         1.3279, 1.4754, 1.4133, 1.3299, 1.3095, 1.4257, 1.3933, 0.5255, 1.3814,
         1.0252, 1.4106, 1.3987, 1.3760, 1.0643, 1.3984, 0.8450, 1.3786, 1.3832],
        [1.2154, 1.2435, 1.3018, 1.2816, 1.2497, 1.2209, 1.2302, 1.2133, 1.2133,
         1.2871, 1.3008, 1.3072, 1.3235, 1.2729, 1.3112, 1.2852, 1.2622, 1.2103,
         2.0278, 2.1065, 2.2146, 2.1472, 1.9303, 2.0009, 2.0607, 1.9214, 1.9214,
         1.3106, 1.2834, 1.2558, 1.2801, 1.3092, 1.2659, 1.2850, 1.2607, 1.2577,
         1.3646, 1.3959, 1.3886, 1.3636, 1.3686, 1.3576, 1.3693, 1.2894, 1.3269,
         1.3072, 1.3028, 1.2948, 1.2708, 1.2553, 1.2944, 1.3351, 1.2728, 1.2771],
        [1.2319, 1.2625, 1.2229, 1.1947, 1.2665, 1.2366, 1.2451, 1.2294, 1.2294,
         1.2930, 1.2252, 1.3079, 1.2897, 1.2784, 1.2852, 1.2900, 1.2802, 1.0428,
         1.2796, 1.2566, 1.3226, 1.2922, 1.2513, 1.2086, 1.2705, 1.2392, 1.2392,
         2.3845, 1.9972, 1.7914, 1.9017, 2.3533, 1.7935, 2.3168, 1.8055, 1.7855,
         1.3533, 1.3882, 1.3382, 1.3213, 1.3596, 1.3266, 1.3556, 1.1379, 1.3193,
         1.3707, 1.2676, 1.1820, 1.2369, 1.3643, 1.1937, 1.4035, 1.2388, 1.2903],
        [1.5735, 1.2577, 0.4880, 0.7060, 1.0599, 1.4619, 1.3962, 1.5701, 1.5701,
         1.4582, 1.2267, 1.2851, 0.8290, 1.5401, 0.1323, 1.4415, 1.5577, 1.1281,
         1.1852, 0.7550, 0.6572, 0.9690, 1.4334, 1.5280, 1.1866, 1.5762, 1.5762,
         0.6052, 0.6988, 1.5380, 1.3066, 0.7473, 1.5285, 1.0241, 1.5806, 1.5300,
         0.7153, 0.4414, 0.3808, 0.6518, 1.1062, 1.3848, 0.5914, 5.4348, 4.9093,
         0.6462, 1.1179, 1.1919, 1.4572, 0.8831, 1.4299, 0.3066, 1.4434, 1.5900],
        [1.2852, 1.3174, 1.3819, 1.3585, 1.3194, 1.2874, 1.2560, 1.2825, 1.2825,
         1.2384, 1.3171, 1.2330, 1.3732, 1.3192, 1.4334, 1.2370, 1.3224, 1.2574,
         1.3359, 1.3626, 1.3659, 1.3418, 1.3076, 1.2958, 1.2738, 1.2938, 1.2938,
         1.3491, 1.3933, 1.3192, 1.1738, 1.2360, 1.1336, 1.3485, 1.2006, 1.3212,
         1.3997, 1.1469, 1.4257, 1.4078, 1.0316, 0.9352, 1.4050, 1.3386, 0.7973,
         2.4417, 2.0334, 2.3399, 2.2387, 1.7377, 1.5068, 2.3618, 2.1710, 1.4909]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 68 : 181.67831749863706
Test loss for epoch 68 : 181.73505434463098
Test Precision for epoch 68 : 0.26153846153846155
Test Recall for epoch 68 : 0.26153846153846155
Test F1 for epoch 68 : 0.26153846153846155


theta for epoch 69 : tensor([[1.9890, 2.0133, 2.0804, 2.1394, 2.1006, 1.9919, 2.0810, 1.9871, 1.9871,
         1.2797, 1.2953, 1.3001, 1.3166, 1.2655, 1.3703, 1.2782, 1.2683, 1.2519,
         1.2570, 1.2445, 1.2533, 1.2689, 1.2302, 1.2207, 1.2485, 1.2171, 1.2171,
         1.2656, 1.3201, 1.2432, 1.2683, 1.3103, 1.2538, 1.2714, 1.2056, 1.2453,
         1.3593, 1.3904, 1.3829, 1.3668, 1.3640, 1.3039, 1.3636, 1.3850, 1.3261,
         1.3445, 1.2944, 1.2866, 1.2626, 1.3374, 1.2848, 1.3756, 1.2649, 1.2686],
        [1.2851, 1.1733, 1.0129, 1.2352, 1.2901, 1.3363, 1.2587, 1.3275, 1.3275,
         1.3950, 1.6135, 1.3708, 2.1619, 1.4043, 3.7423, 1.4885, 1.3122, 3.3481,
         1.1286, 1.2039, 0.9529, 1.1745, 1.3075, 1.3429, 1.3238, 1.3408, 1.3408,
         1.3038, 1.0495, 1.3653, 1.3413, 1.1190, 1.3767, 1.3869, 1.3303, 1.3348,
         1.3279, 1.4760, 1.4135, 1.3297, 1.3097, 1.4269, 1.3936, 0.5260, 1.3831,
         1.0245, 1.4110, 1.3988, 1.3754, 1.0634, 1.3980, 0.8444, 1.3782, 1.3825],
        [1.2161, 1.2435, 1.3007, 1.2808, 1.2496, 1.2217, 1.2304, 1.2141, 1.2141,
         1.2874, 1.3012, 1.3075, 1.3239, 1.2731, 1.3127, 1.2855, 1.2627, 1.2111,
         2.0330, 2.1093, 2.2166, 2.1504, 1.9359, 2.0068, 2.0642, 1.9270, 1.9270,
         1.3077, 1.2812, 1.2522, 1.2771, 1.3065, 1.2627, 1.2822, 1.2574, 1.2543,
         1.3653, 1.3966, 1.3890, 1.3643, 1.3699, 1.3589, 1.3699, 1.2898, 1.3265,
         1.3072, 1.3028, 1.2947, 1.2701, 1.2548, 1.2938, 1.3345, 1.2722, 1.2761],
        [1.2304, 1.2612, 1.2227, 1.1947, 1.2654, 1.2352, 1.2438, 1.2280, 1.2280,
         1.2929, 1.2254, 1.3083, 1.2899, 1.2782, 1.2850, 1.2902, 1.2801, 1.0443,
         1.2788, 1.2568, 1.3219, 1.2916, 1.2503, 1.2078, 1.2699, 1.2381, 1.2381,
         2.3898, 2.0025, 1.7953, 1.9056, 2.3591, 1.7977, 2.3222, 1.8094, 1.7897,
         1.3547, 1.3897, 1.3393, 1.3229, 1.3610, 1.3282, 1.3569, 1.1401, 1.3205,
         1.3705, 1.2679, 1.1817, 1.2363, 1.3639, 1.1935, 1.4033, 1.2383, 1.2897],
        [1.5754, 1.2586, 0.4906, 0.7083, 1.0612, 1.4635, 1.3976, 1.5720, 1.5720,
         1.4599, 1.2284, 1.2870, 0.8313, 1.5423, 0.1351, 1.4430, 1.5596, 1.1297,
         1.1869, 0.7573, 0.6587, 0.9710, 1.4356, 1.5297, 1.1891, 1.5783, 1.5783,
         0.6060, 0.7007, 1.5387, 1.3076, 0.7464, 1.5276, 1.0233, 1.5814, 1.5303,
         0.7038, 0.4340, 0.3737, 0.6415, 1.0901, 1.3679, 0.5817, 5.4988, 4.9605,
         0.6496, 1.1198, 1.1938, 1.4566, 0.8872, 1.4305, 0.3108, 1.4448, 1.5909],
        [1.2821, 1.3145, 1.3801, 1.3562, 1.3173, 1.2845, 1.2529, 1.2794, 1.2794,
         1.2376, 1.3176, 1.2332, 1.3726, 1.3179, 1.4332, 1.2362, 1.3211, 1.2560,
         1.3339, 1.3616, 1.3651, 1.3404, 1.3053, 1.2935, 1.2715, 1.2914, 1.2914,
         1.3456, 1.3888, 1.3152, 1.1687, 1.2343, 1.1306, 1.3447, 1.1960, 1.3172,
         1.3992, 1.1440, 1.4247, 1.4071, 1.0291, 0.9326, 1.4042, 1.3396, 0.7978,
         2.4465, 2.0391, 2.3485, 2.2452, 1.7412, 1.5115, 2.3653, 2.1792, 1.4956]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 69 : 181.65432724200514
Test loss for epoch 69 : 181.71065731605364
Test Precision for epoch 69 : 0.26153846153846155
Test Recall for epoch 69 : 0.26153846153846155
Test F1 for epoch 69 : 0.26153846153846155


theta for epoch 70 : tensor([[1.9944, 2.0182, 2.0852, 2.1446, 2.1057, 1.9974, 2.0868, 1.9925, 1.9925,
         1.2794, 1.2948, 1.2995, 1.3161, 1.2652, 1.3691, 1.2779, 1.2680, 1.2514,
         1.2557, 1.2424, 1.2521, 1.2674, 1.2296, 1.2203, 1.2477, 1.2168, 1.2168,
         1.2644, 1.3193, 1.2411, 1.2667, 1.3095, 1.2520, 1.2700, 1.2036, 1.2433,
         1.3585, 1.3896, 1.3817, 1.3661, 1.3639, 1.3035, 1.3627, 1.3843, 1.3249,
         1.3451, 1.2950, 1.2871, 1.2624, 1.3381, 1.2849, 1.3760, 1.2649, 1.2683],
        [1.2840, 1.1737, 1.0109, 1.2340, 1.2896, 1.3349, 1.2575, 1.3260, 1.3260,
         1.3964, 1.6145, 1.3740, 2.1585, 1.4068, 3.7586, 1.4908, 1.3148, 3.3657,
         1.1281, 1.2031, 0.9526, 1.1738, 1.3062, 1.3412, 1.3223, 1.3390, 1.3390,
         1.3032, 1.0486, 1.3639, 1.3400, 1.1192, 1.3757, 1.3862, 1.3292, 1.3335,
         1.3266, 1.4754, 1.4123, 1.3282, 1.3086, 1.4270, 1.3926, 0.5253, 1.3833,
         1.0246, 1.4120, 1.3996, 1.3755, 1.0633, 1.3984, 0.8446, 1.3785, 1.3824],
        [1.2164, 1.2431, 1.2994, 1.2796, 1.2491, 1.2221, 1.2302, 1.2146, 1.2146,
         1.2871, 1.3009, 1.3071, 1.3237, 1.2728, 1.3134, 1.2854, 1.2627, 1.2113,
         2.0383, 2.1122, 2.2188, 2.1538, 1.9415, 2.0127, 2.0677, 1.9325, 1.9325,
         1.3065, 1.2806, 1.2503, 1.2757, 1.3054, 1.2611, 1.2809, 1.2557, 1.2525,
         1.3647, 1.3960, 1.3880, 1.3637, 1.3700, 1.3590, 1.3692, 1.2890, 1.3248,
         1.3080, 1.3036, 1.2954, 1.2701, 1.2552, 1.2940, 1.3350, 1.2724, 1.2760],
        [1.2280, 1.2589, 1.2216, 1.1938, 1.2633, 1.2329, 1.2414, 1.2255, 1.2255,
         1.2916, 1.2243, 1.3074, 1.2888, 1.2768, 1.2835, 1.2890, 1.2787, 1.0446,
         1.2767, 1.2559, 1.3199, 1.2897, 1.2480, 1.2058, 1.2680, 1.2357, 1.2357,
         2.3963, 2.0092, 1.8005, 1.9108, 2.3661, 1.8032, 2.3289, 1.8147, 1.7953,
         1.3545, 1.3896, 1.3389, 1.3230, 1.3611, 1.3284, 1.3566, 1.1409, 1.3201,
         1.3703, 1.2682, 1.1815, 1.2358, 1.3636, 1.1934, 1.4032, 1.2378, 1.2891],
        [1.5771, 1.2594, 0.4932, 0.7106, 1.0627, 1.4650, 1.3990, 1.5737, 1.5737,
         1.4612, 1.2297, 1.2887, 0.8334, 1.5443, 0.1374, 1.4442, 1.5612, 1.1310,
         1.1885, 0.7594, 0.6598, 0.9729, 1.4374, 1.5310, 1.1915, 1.5800, 1.5800,
         0.6080, 0.7037, 1.5406, 1.3100, 0.7465, 1.5279, 1.0240, 1.5834, 1.5318,
         0.6921, 0.4263, 0.3664, 0.6310, 1.0737, 1.3505, 0.5717, 5.5625, 5.0111,
         0.6538, 1.1226, 1.1965, 1.4568, 0.8921, 1.4319, 0.3155, 1.4472, 1.5926],
        [1.2804, 1.3130, 1.3793, 1.3551, 1.3165, 1.2831, 1.2513, 1.2777, 1.2777,
         1.2383, 1.3194, 1.2348, 1.3732, 1.3179, 1.4337, 1.2369, 1.3212, 1.2558,
         1.3328, 1.3615, 1.3653, 1.3401, 1.3041, 1.2922, 1.2703, 1.2899, 1.2899,
         1.3444, 1.3867, 1.3133, 1.1662, 1.2350, 1.1303, 1.3431, 1.1937, 1.3154,
         1.3979, 1.1408, 1.4230, 1.4057, 1.0265, 0.9300, 1.4028, 1.3403, 0.7986,
         2.4493, 2.0428, 2.3552, 2.2496, 1.7430, 1.5143, 2.3671, 2.1856, 1.4984]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 70 : 181.6296457023041
Test loss for epoch 70 : 181.68592931965998
Test Precision for epoch 70 : 0.26153846153846155
Test Recall for epoch 70 : 0.26153846153846155
Test F1 for epoch 70 : 0.26153846153846155


theta for epoch 71 : tensor([[1.9998, 2.0233, 2.0903, 2.1499, 2.1110, 2.0029, 2.0927, 1.9980, 1.9980,
         1.2777, 1.2930, 1.2976, 1.3142, 1.2637, 1.3665, 1.2764, 1.2665, 1.2494,
         1.2549, 1.2409, 1.2514, 1.2665, 1.2295, 1.2205, 1.2473, 1.2170, 1.2170,
         1.2649, 1.3200, 1.2407, 1.2668, 1.3103, 1.2519, 1.2703, 1.2034, 1.2430,
         1.3572, 1.3883, 1.3800, 1.3648, 1.3633, 1.3026, 1.3611, 1.3830, 1.3233,
         1.3458, 1.2956, 1.2876, 1.2624, 1.3390, 1.2850, 1.3766, 1.2649, 1.2680],
        [1.2834, 1.1745, 1.0091, 1.2331, 1.2894, 1.3339, 1.2570, 1.3251, 1.3251,
         1.3971, 1.6150, 1.3762, 2.1544, 1.4086, 3.7741, 1.4923, 1.3164, 3.3825,
         1.1282, 1.2027, 0.9529, 1.1736, 1.3055, 1.3401, 1.3213, 1.3378, 1.3378,
         1.3041, 1.0495, 1.3641, 1.3403, 1.1212, 1.3762, 1.3871, 1.3296, 1.3339,
         1.3248, 1.4742, 1.4106, 1.3262, 1.3071, 1.4265, 1.3911, 0.5242, 1.3828,
         1.0248, 1.4131, 1.4005, 1.3757, 1.0634, 1.3988, 0.8448, 1.3789, 1.3824],
        [1.2165, 1.2426, 1.2981, 1.2784, 1.2483, 1.2222, 1.2298, 1.2148, 1.2148,
         1.2853, 1.2992, 1.3052, 1.3219, 1.2711, 1.3127, 1.2837, 1.2614, 1.2099,
         2.0443, 2.1161, 2.2219, 2.1581, 1.9478, 2.0193, 2.0721, 1.9388, 1.9388,
         1.3067, 1.2815, 1.2499, 1.2758, 1.3058, 1.2610, 1.2811, 1.2555, 1.2521,
         1.3634, 1.3947, 1.3863, 1.3623, 1.3695, 1.3584, 1.3677, 1.2876, 1.3225,
         1.3087, 1.3043, 1.2959, 1.2701, 1.2556, 1.2941, 1.3354, 1.2724, 1.2757],
        [1.2255, 1.2564, 1.2202, 1.1928, 1.2611, 1.2305, 1.2389, 1.2230, 1.2230,
         1.2889, 1.2220, 1.3051, 1.2864, 1.2742, 1.2804, 1.2865, 1.2761, 1.0439,
         1.2745, 1.2549, 1.3178, 1.2877, 1.2457, 1.2039, 1.2661, 1.2334, 1.2334,
         2.4033, 2.0166, 1.8064, 1.9167, 2.3737, 1.8094, 2.3360, 1.8206, 1.8014,
         1.3537, 1.3889, 1.3377, 1.3224, 1.3606, 1.3279, 1.3556, 1.1411, 1.3192,
         1.3700, 1.2684, 1.1811, 1.2350, 1.3631, 1.1930, 1.4031, 1.2371, 1.2883],
        [1.5783, 1.2596, 0.4952, 0.7121, 1.0635, 1.4659, 1.3998, 1.5749, 1.5749,
         1.4609, 1.2293, 1.2888, 0.8337, 1.5447, 0.1380, 1.4439, 1.5613, 1.1306,
         1.1896, 0.7609, 0.6601, 0.9742, 1.4388, 1.5319, 1.1935, 1.5814, 1.5814,
         0.6103, 0.7069, 1.5433, 1.3130, 0.7470, 1.5289, 1.0252, 1.5863, 1.5341,
         0.6813, 0.4192, 0.3596, 0.6213, 1.0581, 1.3336, 0.5626, 5.6265, 5.0619,
         0.6569, 1.1246, 1.1985, 1.4564, 0.8960, 1.4328, 0.3188, 1.4491, 1.5938],
        [1.2802, 1.3128, 1.3798, 1.3553, 1.3173, 1.2832, 1.2512, 1.2775, 1.2775,
         1.2394, 1.3215, 1.2367, 1.3738, 1.3183, 1.4340, 1.2379, 1.3215, 1.2559,
         1.3331, 1.3627, 1.3670, 1.3411, 1.3042, 1.2923, 1.2704, 1.2899, 1.2899,
         1.3453, 1.3869, 1.3137, 1.1659, 1.2380, 1.1323, 1.3438, 1.1937, 1.3158,
         1.3966, 1.1379, 1.4213, 1.4043, 1.0244, 0.9282, 1.4013, 1.3415, 0.8002,
         2.4503, 2.0445, 2.3598, 2.2519, 1.7431, 1.5152, 2.3669, 2.1899, 1.4993]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 71 : 181.60492996183427
Test loss for epoch 71 : 181.66196104470737
Test Precision for epoch 71 : 0.26153846153846155
Test Recall for epoch 71 : 0.26153846153846155
Test F1 for epoch 71 : 0.26153846153846155


theta for epoch 72 : tensor([[2.0047, 2.0279, 2.0949, 2.1547, 2.1158, 2.0078, 2.0980, 2.0029, 2.0029,
         1.2766, 1.2916, 1.2962, 1.3129, 1.2627, 1.3642, 1.2753, 1.2656, 1.2478,
         1.2546, 1.2399, 1.2513, 1.2660, 1.2299, 1.2212, 1.2475, 1.2178, 1.2178,
         1.2652, 1.3205, 1.2402, 1.2668, 1.3108, 1.2517, 1.2705, 1.2031, 1.2426,
         1.3561, 1.3873, 1.3785, 1.3638, 1.3631, 1.3020, 1.3598, 1.3820, 1.3221,
         1.3467, 1.2964, 1.2882, 1.2625, 1.3400, 1.2853, 1.3774, 1.2651, 1.2680],
        [1.2828, 1.1753, 1.0072, 1.2321, 1.2893, 1.3331, 1.2565, 1.3243, 1.3243,
         1.3984, 1.6162, 1.3791, 2.1511, 1.4109, 3.7898, 1.4942, 1.3186, 3.3997,
         1.1281, 1.2021, 0.9532, 1.1732, 1.3048, 1.3390, 1.3203, 1.3367, 1.3367,
         1.3044, 1.0498, 1.3637, 1.3400, 1.1226, 1.3761, 1.3873, 1.3293, 1.3336,
         1.3230, 1.4732, 1.4089, 1.3243, 1.3057, 1.4262, 1.3896, 0.5233, 1.3823,
         1.0249, 1.4139, 1.4012, 1.3758, 1.0634, 1.3991, 0.8449, 1.3791, 1.3823],
        [1.2166, 1.2423, 1.2972, 1.2774, 1.2478, 1.2224, 1.2294, 1.2150, 1.2150,
         1.2838, 1.2977, 1.3035, 1.3202, 1.2697, 1.3120, 1.2823, 1.2603, 1.2086,
         2.0506, 2.1202, 2.2253, 2.1626, 1.9542, 2.0259, 2.0766, 1.9451, 1.9451,
         1.3066, 1.2819, 1.2490, 1.2754, 1.3059, 1.2604, 1.2808, 1.2548, 1.2514,
         1.3622, 1.3936, 1.3847, 1.3610, 1.3691, 1.3580, 1.3663, 1.2863, 1.3204,
         1.3093, 1.3048, 1.2963, 1.2700, 1.2560, 1.2942, 1.3359, 1.2725, 1.2755],
        [1.2239, 1.2549, 1.2198, 1.1928, 1.2598, 1.2290, 1.2375, 1.2215, 1.2215,
         1.2873, 1.2207, 1.3039, 1.2850, 1.2726, 1.2784, 1.2851, 1.2747, 1.0443,
         1.2733, 1.2549, 1.3165, 1.2866, 1.2444, 1.2030, 1.2650, 1.2320, 1.2320,
         2.4092, 2.0228, 1.8112, 1.9216, 2.3801, 1.8146, 2.3421, 1.8255, 1.8066,
         1.3533, 1.3886, 1.3371, 1.3223, 1.3606, 1.3280, 1.3550, 1.1419, 1.3187,
         1.3701, 1.2689, 1.1810, 1.2346, 1.3630, 1.1930, 1.4033, 1.2367, 1.2878],
        [1.5790, 1.2593, 0.4964, 0.7129, 1.0638, 1.4662, 1.4000, 1.5756, 1.5756,
         1.4604, 1.2285, 1.2886, 0.8335, 1.5449, 0.1377, 1.4434, 1.5612, 1.1299,
         1.1902, 0.7618, 0.6596, 0.9749, 1.4397, 1.5325, 1.1951, 1.5823, 1.5823,
         0.6116, 0.7092, 1.5452, 1.3153, 0.7463, 1.5290, 1.0256, 1.5885, 1.5357,
         0.6715, 0.4130, 0.3538, 0.6127, 1.0434, 1.3176, 0.5545, 5.6910, 5.1131,
         0.6590, 1.1261, 1.2001, 1.4556, 0.8991, 1.4333, 0.3208, 1.4508, 1.5948],
        [1.2800, 1.3127, 1.3802, 1.3554, 1.3181, 1.2835, 1.2512, 1.2774, 1.2774,
         1.2409, 1.3238, 1.2390, 1.3748, 1.3191, 1.4343, 1.2393, 1.3223, 1.2563,
         1.3333, 1.3637, 1.3687, 1.3421, 1.3043, 1.2924, 1.2705, 1.2899, 1.2899,
         1.3458, 1.3869, 1.3135, 1.1654, 1.2408, 1.1342, 1.3440, 1.1934, 1.3158,
         1.3955, 1.1353, 1.4197, 1.4031, 1.0228, 0.9267, 1.3999, 1.3432, 0.8022,
         2.4512, 2.0462, 2.3645, 2.2542, 1.7435, 1.5161, 2.3667, 2.1943, 1.5002]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 72 : 181.5822675234078
Test loss for epoch 72 : 181.6406617114529
Test Precision for epoch 72 : 0.26153846153846155
Test Recall for epoch 72 : 0.26153846153846155
Test F1 for epoch 72 : 0.26153846153846155


theta for epoch 73 : tensor([[2.0093, 2.0323, 2.0994, 2.1593, 2.1205, 2.0125, 2.1031, 2.0075, 2.0075,
         1.2767, 1.2914, 1.2958, 1.3126, 1.2630, 1.3630, 1.2754, 1.2658, 1.2473,
         1.2540, 1.2388, 1.2510, 1.2654, 1.2300, 1.2215, 1.2473, 1.2182, 1.2182,
         1.2645, 1.3198, 1.2386, 1.2656, 1.3101, 1.2503, 1.2695, 1.2017, 1.2411,
         1.3556, 1.3869, 1.3776, 1.3634, 1.3635, 1.3021, 1.3592, 1.3817, 1.3215,
         1.3477, 1.2973, 1.2891, 1.2629, 1.3412, 1.2858, 1.3784, 1.2656, 1.2682],
        [1.2824, 1.1759, 1.0052, 1.2312, 1.2891, 1.3324, 1.2561, 1.3236, 1.3236,
         1.4008, 1.6188, 1.3829, 2.1489, 1.4144, 3.8064, 1.4972, 1.3219, 3.4179,
         1.1273, 1.2008, 0.9530, 1.1722, 1.3036, 1.3373, 1.3186, 1.3350, 1.3350,
         1.3032, 1.0485, 1.3617, 1.3382, 1.1225, 1.3744, 1.3861, 1.3275, 1.3319,
         1.3216, 1.4726, 1.4077, 1.3227, 1.3046, 1.4263, 1.3885, 0.5225, 1.3819,
         1.0249, 1.4146, 1.4017, 1.3759, 1.0633, 1.3993, 0.8448, 1.3792, 1.3822],
        [1.2174, 1.2427, 1.2972, 1.2773, 1.2480, 1.2233, 1.2297, 1.2159, 1.2159,
         1.2834, 1.2973, 1.3028, 1.3196, 1.2695, 1.3123, 1.2819, 1.2605, 1.2084,
         2.0562, 2.1239, 2.2284, 2.1666, 1.9600, 2.0319, 2.0806, 1.9508, 1.9508,
         1.3055, 1.2813, 1.2471, 1.2739, 1.3049, 1.2587, 1.2794, 1.2531, 1.2496,
         1.3616, 1.3930, 1.3837, 1.3603, 1.3693, 1.3583, 1.3655, 1.2857, 1.3188,
         1.3101, 1.3056, 1.2970, 1.2702, 1.2568, 1.2945, 1.3367, 1.2727, 1.2755],
        [1.2238, 1.2547, 1.2207, 1.1941, 1.2599, 1.2290, 1.2374, 1.2214, 1.2214,
         1.2878, 1.2216, 1.3045, 1.2857, 1.2731, 1.2782, 1.2857, 1.2752, 1.0466,
         1.2728, 1.2556, 1.3160, 1.2863, 1.2440, 1.2031, 1.2648, 1.2316, 1.2316,
         2.4134, 2.0276, 1.8146, 1.9249, 2.3849, 1.8183, 2.3465, 1.8289, 1.8103,
         1.3539, 1.3892, 1.3373, 1.3232, 1.3616, 1.3290, 1.3553, 1.1436, 1.3191,
         1.3708, 1.2700, 1.1816, 1.2349, 1.3635, 1.1937, 1.4040, 1.2370, 1.2880],
        [1.5799, 1.2593, 0.4980, 0.7141, 1.0646, 1.4669, 1.4006, 1.5765, 1.5765,
         1.4608, 1.2286, 1.2894, 0.8341, 1.5462, 0.1380, 1.4440, 1.5622, 1.1301,
         1.1907, 0.7627, 0.6591, 0.9756, 1.4403, 1.5328, 1.1966, 1.5830, 1.5830,
         0.6122, 0.7109, 1.5462, 1.3166, 0.7449, 1.5281, 1.0252, 1.5897, 1.5364,
         0.6622, 0.4070, 0.3481, 0.6044, 1.0291, 1.3016, 0.5468, 5.7554, 5.1639,
         0.6615, 1.1281, 1.2023, 1.4554, 0.9027, 1.4344, 0.3229, 1.4532, 1.5963],
        [1.2788, 1.3114, 1.3793, 1.3544, 1.3177, 1.2827, 1.2501, 1.2762, 1.2762,
         1.2418, 1.3257, 1.2407, 1.3752, 1.3196, 1.4339, 1.2402, 1.3228, 1.2560,
         1.3318, 1.3630, 1.3689, 1.3414, 1.3028, 1.2909, 1.2690, 1.2883, 1.2883,
         1.3443, 1.3852, 1.3114, 1.1628, 1.2416, 1.1341, 1.3424, 1.1909, 1.3138,
         1.3942, 1.1324, 1.4180, 1.4018, 1.0208, 0.9250, 1.3983, 1.3449, 0.8037,
         2.4543, 2.0500, 2.3713, 2.2585, 1.7462, 1.5193, 2.3688, 2.2010, 1.5033]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 73 : 181.55890173965162
Test loss for epoch 73 : 181.61815972350968
Test Precision for epoch 73 : 0.26153846153846155
Test Recall for epoch 73 : 0.26153846153846155
Test F1 for epoch 73 : 0.26153846153846155


theta for epoch 74 : tensor([[2.0140, 2.0368, 2.1040, 2.1640, 2.1253, 2.0173, 2.1083, 2.0122, 2.0122,
         1.2766, 1.2909, 1.2953, 1.3121, 1.2630, 1.3616, 1.2752, 1.2659, 1.2466,
         1.2537, 1.2381, 1.2511, 1.2651, 1.2303, 1.2219, 1.2474, 1.2187, 1.2187,
         1.2641, 1.3193, 1.2374, 1.2647, 1.3098, 1.2493, 1.2689, 1.2006, 1.2400,
         1.3557, 1.3870, 1.3773, 1.3635, 1.3645, 1.3028, 1.3590, 1.3819, 1.3214,
         1.3480, 1.2976, 1.2892, 1.2627, 1.3417, 1.2857, 1.3786, 1.2654, 1.2678],
        [1.2825, 1.1770, 1.0039, 1.2307, 1.2895, 1.3323, 1.2562, 1.3235, 1.3235,
         1.4027, 1.6211, 1.3861, 2.1465, 1.4174, 3.8223, 1.4996, 1.3246, 3.4355,
         1.1271, 1.2001, 0.9534, 1.1717, 1.3029, 1.3362, 1.3174, 1.3339, 1.3339,
         1.3023, 1.0478, 1.3602, 1.3368, 1.1230, 1.3731, 1.3853, 1.3261, 1.3306,
         1.3208, 1.4725, 1.4070, 1.3218, 1.3042, 1.4269, 1.3881, 0.5225, 1.3820,
         1.0245, 1.4147, 1.4017, 1.3755, 1.0628, 1.3990, 0.8443, 1.3788, 1.3816],
        [1.2182, 1.2435, 1.2978, 1.2776, 1.2486, 1.2242, 1.2301, 1.2168, 1.2168,
         1.2829, 1.2968, 1.3019, 1.3189, 1.2691, 1.3124, 1.2815, 1.2606, 1.2080,
         2.0619, 2.1277, 2.2316, 2.1707, 1.9657, 2.0379, 2.0847, 1.9564, 1.9564,
         1.3048, 1.2809, 1.2455, 1.2727, 1.3044, 1.2574, 1.2785, 1.2517, 1.2481,
         1.3615, 1.3930, 1.3832, 1.3601, 1.3701, 1.3591, 1.3652, 1.2856, 1.3179,
         1.3102, 1.3057, 1.2970, 1.2698, 1.2569, 1.2943, 1.3368, 1.2724, 1.2750],
        [1.2241, 1.2550, 1.2220, 1.1959, 1.2604, 1.2295, 1.2378, 1.2218, 1.2218,
         1.2884, 1.2227, 1.3054, 1.2867, 1.2739, 1.2783, 1.2865, 1.2760, 1.0493,
         1.2729, 1.2569, 1.3160, 1.2865, 1.2442, 1.2037, 1.2651, 1.2318, 1.2318,
         2.4173, 2.0320, 1.8177, 1.9279, 2.3893, 1.8217, 2.3505, 1.8320, 1.8137,
         1.3550, 1.3903, 1.3380, 1.3246, 1.3633, 1.3306, 1.3561, 1.1459, 1.3199,
         1.3711, 1.2708, 1.1819, 1.2348, 1.3637, 1.1942, 1.4044, 1.2370, 1.2879],
        [1.5814, 1.2601, 0.5006, 0.7163, 1.0664, 1.4681, 1.4020, 1.5781, 1.5781,
         1.4617, 1.2294, 1.2908, 0.8356, 1.5480, 0.1392, 1.4451, 1.5637, 1.1311,
         1.1922, 0.7646, 0.6596, 0.9773, 1.4416, 1.5337, 1.1990, 1.5844, 1.5844,
         0.6138, 0.7133, 1.5477, 1.3186, 0.7444, 1.5277, 1.0258, 1.5915, 1.5376,
         0.6527, 0.4005, 0.3421, 0.5958, 1.0144, 1.2850, 0.5388, 5.8191, 5.2138,
         0.6645, 1.1304, 1.2047, 1.4552, 0.9065, 1.4357, 0.3256, 1.4557, 1.5978],
        [1.2762, 1.3088, 1.3770, 1.3519, 1.3161, 1.2807, 1.2477, 1.2738, 1.2738,
         1.2408, 1.3257, 1.2403, 1.3738, 1.3184, 1.4317, 1.2391, 1.3215, 1.2538,
         1.3290, 1.3610, 1.3679, 1.3394, 1.3000, 1.2882, 1.2661, 1.2855, 1.2855,
         1.3422, 1.3829, 1.3085, 1.1596, 1.2418, 1.1333, 1.3400, 1.1877, 1.3110,
         1.3926, 1.1292, 1.4160, 1.4002, 1.0185, 0.9228, 1.3965, 1.3466, 0.8046,
         2.4593, 2.0558, 2.3799, 2.2646, 1.7509, 1.5243, 2.3727, 2.2095, 1.5083]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 74 : 181.53608468085815
Test loss for epoch 74 : 181.59484035755239
Test Precision for epoch 74 : 0.26153846153846155
Test Recall for epoch 74 : 0.26153846153846155
Test F1 for epoch 74 : 0.26153846153846155


theta for epoch 75 : tensor([[2.0188, 2.0415, 2.1089, 2.1690, 2.1303, 2.0222, 2.1135, 2.0170, 2.0170,
         1.2759, 1.2899, 1.2941, 1.3112, 1.2625, 1.3597, 1.2745, 1.2653, 1.2453,
         1.2540, 1.2382, 1.2518, 1.2654, 1.2310, 1.2228, 1.2480, 1.2196, 1.2196,
         1.2652, 1.3202, 1.2378, 1.2654, 1.3109, 1.2499, 1.2699, 1.2012, 1.2405,
         1.3562, 1.3876, 1.3773, 1.3640, 1.3658, 1.3039, 1.3592, 1.3826, 1.3218,
         1.3468, 1.2963, 1.2879, 1.2611, 1.3406, 1.2842, 1.3774, 1.2637, 1.2660],
        [1.2829, 1.1784, 1.0030, 1.2307, 1.2903, 1.3326, 1.2568, 1.3239, 1.3239,
         1.4036, 1.6226, 1.3882, 2.1431, 1.4193, 3.8371, 1.5008, 1.3262, 3.4521,
         1.1278, 1.2003, 0.9551, 1.1722, 1.3033, 1.3362, 1.3173, 1.3338, 1.3338,
         1.3033, 1.0490, 1.3604, 1.3372, 1.1254, 1.3736, 1.3862, 1.3265, 1.3311,
         1.3207, 1.4731, 1.4070, 1.3215, 1.3045, 1.4281, 1.3882, 0.5232, 1.3826,
         1.0230, 1.4136, 1.4004, 1.3740, 1.0613, 1.3975, 0.8429, 1.3772, 1.3798],
        [1.2185, 1.2437, 1.2981, 1.2775, 1.2487, 1.2245, 1.2300, 1.2171, 1.2171,
         1.2820, 1.2959, 1.3006, 1.3177, 1.2683, 1.3120, 1.2805, 1.2602, 1.2072,
         2.0679, 2.1320, 2.2352, 2.1753, 1.9717, 2.0441, 2.0891, 1.9623, 1.9623,
         1.3058, 1.2821, 1.2456, 1.2732, 1.3055, 1.2577, 1.2791, 1.2519, 1.2483,
         1.3618, 1.3935, 1.3831, 1.3603, 1.3714, 1.3603, 1.3653, 1.2860, 1.3174,
         1.3088, 1.3043, 1.2955, 1.2681, 1.2557, 1.2926, 1.3356, 1.2706, 1.2730],
        [1.2238, 1.2546, 1.2227, 1.1970, 1.2603, 1.2294, 1.2376, 1.2215, 1.2215,
         1.2882, 1.2229, 1.3053, 1.2868, 1.2737, 1.2775, 1.2863, 1.2759, 1.0511,
         1.2729, 1.2581, 1.3158, 1.2865, 1.2443, 1.2042, 1.2652, 1.2318, 1.2318,
         2.4219, 2.0373, 1.8217, 1.9319, 2.3944, 1.8260, 2.3553, 1.8360, 1.8180,
         1.3561, 1.3914, 1.3388, 1.3260, 1.3650, 1.3322, 1.3570, 1.1483, 1.3208,
         1.3699, 1.2701, 1.1809, 1.2333, 1.3624, 1.1933, 1.4032, 1.2354, 1.2862],
        [1.5832, 1.2615, 0.5040, 0.7190, 1.0689, 1.4698, 1.4038, 1.5799, 1.5799,
         1.4627, 1.2302, 1.2923, 0.8374, 1.5499, 0.1411, 1.4463, 1.5652, 1.1323,
         1.1946, 0.7676, 0.6613, 0.9800, 1.4437, 1.5355, 1.2022, 1.5864, 1.5864,
         0.6170, 0.7174, 1.5508, 1.3222, 0.7454, 1.5287, 1.0282, 1.5948, 1.5404,
         0.6430, 0.3937, 0.3358, 0.5871, 0.9995, 1.2679, 0.5306, 5.8822, 5.2629,
         0.6668, 1.1317, 1.2062, 1.4541, 0.9094, 1.4359, 0.3276, 1.4573, 1.5983],
        [1.2732, 1.3057, 1.3740, 1.3488, 1.3138, 1.2782, 1.2449, 1.2708, 1.2708,
         1.2387, 1.3247, 1.2389, 1.3714, 1.3161, 1.4284, 1.2369, 1.3193, 1.2506,
         1.3263, 1.3590, 1.3669, 1.3375, 1.2973, 1.2855, 1.2632, 1.2828, 1.2828,
         1.3411, 1.3819, 1.3067, 1.1574, 1.2430, 1.1337, 1.3388, 1.1856, 1.3093,
         1.3913, 1.1264, 1.4143, 1.3989, 1.0165, 0.9209, 1.3949, 1.3488, 0.8056,
         2.4642, 2.0614, 2.3885, 2.2706, 1.7558, 1.5292, 2.3765, 2.2181, 1.5132]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 75 : 181.51305759238514
Test loss for epoch 75 : 181.57067531509045
Test Precision for epoch 75 : 0.26153846153846155
Test Recall for epoch 75 : 0.26153846153846155
Test F1 for epoch 75 : 0.26153846153846155


theta for epoch 76 : tensor([[2.0238, 2.0465, 2.1140, 2.1742, 2.1356, 2.0273, 2.1190, 2.0220, 2.0220,
         1.2757, 1.2895, 1.2935, 1.3108, 1.2626, 1.3584, 1.2744, 1.2654, 1.2445,
         1.2539, 1.2379, 1.2522, 1.2653, 1.2312, 1.2232, 1.2482, 1.2200, 1.2200,
         1.2668, 1.3216, 1.2388, 1.2666, 1.3124, 1.2510, 1.2714, 1.2023, 1.2416,
         1.3568, 1.3883, 1.3776, 1.3647, 1.3674, 1.3052, 1.3597, 1.3834, 1.3223,
         1.3449, 1.2943, 1.2857, 1.2588, 1.3388, 1.2820, 1.3754, 1.2614, 1.2634],
        [1.2833, 1.1796, 1.0022, 1.2305, 1.2909, 1.3328, 1.2573, 1.3241, 1.3241,
         1.4049, 1.6245, 1.3906, 2.1403, 1.4216, 3.8520, 1.5023, 1.3281, 3.4689,
         1.1284, 1.2004, 0.9567, 1.1726, 1.3036, 1.3362, 1.3171, 1.3338, 1.3338,
         1.3047, 1.0508, 1.3612, 1.3382, 1.1284, 1.3745, 1.3876, 1.3273, 1.3322,
         1.3208, 1.4739, 1.4072, 1.3215, 1.3051, 1.4296, 1.3885, 0.5240, 1.3833,
         1.0209, 1.4116, 1.3982, 1.3717, 1.0590, 1.3953, 0.8408, 1.3748, 1.3773],
        [1.2185, 1.2439, 1.2984, 1.2775, 1.2487, 1.2246, 1.2298, 1.2172, 1.2172,
         1.2818, 1.2957, 1.3000, 1.3173, 1.2683, 1.3124, 1.2803, 1.2606, 1.2070,
         2.0736, 2.1360, 2.2387, 2.1796, 1.9773, 2.0499, 2.0932, 1.9677, 1.9677,
         1.3075, 1.2840, 1.2465, 1.2743, 1.3073, 1.2587, 1.2804, 1.2529, 1.2493,
         1.3624, 1.3942, 1.3833, 1.3609, 1.3729, 1.3618, 1.3658, 1.2867, 1.3173,
         1.3068, 1.3023, 1.2934, 1.2658, 1.2540, 1.2903, 1.3338, 1.2683, 1.2705],
        [1.2228, 1.2535, 1.2227, 1.1974, 1.2594, 1.2285, 1.2366, 1.2206, 1.2206,
         1.2879, 1.2231, 1.3051, 1.2869, 1.2735, 1.2767, 1.2861, 1.2758, 1.0528,
         1.2722, 1.2585, 1.3149, 1.2857, 1.2437, 1.2040, 1.2645, 1.2312, 1.2312,
         2.4273, 2.0435, 1.8266, 1.9367, 2.4003, 1.8311, 2.3609, 1.8409, 1.8232,
         1.3571, 1.3923, 1.3394, 1.3273, 1.3665, 1.3337, 1.3576, 1.1504, 1.3215,
         1.3678, 1.2685, 1.1789, 1.2309, 1.3602, 1.1915, 1.4012, 1.2330, 1.2837],
        [1.5849, 1.2629, 0.5074, 0.7219, 1.0715, 1.4714, 1.4057, 1.5817, 1.5817,
         1.4644, 1.2317, 1.2945, 0.8398, 1.5523, 0.1435, 1.4482, 1.5674, 1.1341,
         1.1970, 0.7706, 0.6630, 0.9828, 1.4457, 1.5371, 1.2055, 1.5884, 1.5884,
         0.6208, 0.7219, 1.5543, 1.3264, 0.7469, 1.5302, 1.0312, 1.5987, 1.5437,
         0.6336, 0.3870, 0.3295, 0.5786, 0.9848, 1.2509, 0.5226, 5.9452, 5.3115,
         0.6681, 1.1321, 1.2068, 1.4523, 0.9113, 1.4355, 0.3289, 1.4582, 1.5981],
        [1.2707, 1.3031, 1.3713, 1.3461, 1.3120, 1.2762, 1.2425, 1.2684, 1.2684,
         1.2380, 1.3250, 1.2389, 1.3704, 1.3154, 1.4263, 1.2361, 1.3184, 1.2489,
         1.3240, 1.3572, 1.3663, 1.3359, 1.2951, 1.2833, 1.2608, 1.2805, 1.2805,
         1.3407, 1.3818, 1.3057, 1.1562, 1.2451, 1.1352, 1.3384, 1.1844, 1.3084,
         1.3905, 1.1243, 1.4132, 1.3981, 1.0153, 0.9199, 1.3939, 1.3516, 0.8072,
         2.4680, 2.0658, 2.3959, 2.2753, 1.7596, 1.5330, 2.3793, 2.2255, 1.5170]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 76 : 181.4910639563402
Test loss for epoch 76 : 181.54813291862712
Test Precision for epoch 76 : 0.26153846153846155
Test Recall for epoch 76 : 0.26153846153846155
Test F1 for epoch 76 : 0.26153846153846155


theta for epoch 77 : tensor([[2.0290, 2.0517, 2.1193, 2.1796, 2.1411, 2.0326, 2.1246, 2.0271, 2.0271,
         1.2762, 1.2896, 1.2935, 1.3110, 1.2632, 1.3578, 1.2748, 1.2660, 1.2443,
         1.2536, 1.2375, 1.2522, 1.2650, 1.2311, 1.2231, 1.2480, 1.2199, 1.2199,
         1.2668, 1.3213, 1.2384, 1.2664, 1.3123, 1.2506, 1.2714, 1.2021, 1.2413,
         1.3573, 1.3890, 1.3778, 1.3653, 1.3689, 1.3064, 1.3600, 1.3841, 1.3228,
         1.3441, 1.2933, 1.2846, 1.2576, 1.3380, 1.2808, 1.3746, 1.2600, 1.2620],
        [1.2836, 1.1807, 1.0013, 1.2303, 1.2913, 1.3331, 1.2577, 1.3244, 1.3244,
         1.4068, 1.6273, 1.3936, 2.1384, 1.4245, 3.8674, 1.5044, 1.3307, 3.4863,
         1.1286, 1.2003, 0.9582, 1.1727, 1.3038, 1.3360, 1.3167, 1.3336, 1.3336,
         1.3045, 1.0509, 1.3605, 1.3376, 1.1298, 1.3740, 1.3875, 1.3267, 1.3318,
         1.3208, 1.4745, 1.4072, 1.3212, 1.3055, 1.4308, 1.3886, 0.5246, 1.3836,
         1.0199, 1.4105, 1.3971, 1.3704, 1.0578, 1.3940, 0.8398, 1.3734, 1.3758],
        [1.2186, 1.2443, 1.2990, 1.2778, 1.2490, 1.2247, 1.2298, 1.2172, 1.2172,
         1.2824, 1.2962, 1.3001, 1.3176, 1.2690, 1.3132, 1.2809, 1.2617, 1.2076,
         2.0790, 2.1399, 2.2421, 2.1838, 1.9825, 2.0553, 2.0971, 1.9728, 1.9728,
         1.3078, 1.2843, 1.2461, 1.2741, 1.3077, 1.2583, 1.2804, 1.2526, 1.2489,
         1.3630, 1.3949, 1.3835, 1.3613, 1.3744, 1.3633, 1.3661, 1.2874, 1.3171,
         1.3059, 1.3013, 1.2924, 1.2647, 1.2534, 1.2892, 1.3333, 1.2670, 1.2692],
        [1.2218, 1.2523, 1.2225, 1.1977, 1.2584, 1.2276, 1.2356, 1.2196, 1.2196,
         1.2879, 1.2236, 1.3053, 1.2874, 1.2736, 1.2761, 1.2862, 1.2760, 1.0547,
         1.2711, 1.2586, 1.3137, 1.2846, 1.2428, 1.2036, 1.2635, 1.2302, 1.2302,
         2.4324, 2.0494, 1.8313, 1.9413, 2.4060, 1.8362, 2.3662, 1.8456, 1.8282,
         1.3579, 1.3930, 1.3397, 1.3283, 1.3679, 1.3350, 1.3581, 1.1522, 1.3219,
         1.3663, 1.2675, 1.1775, 1.2292, 1.3587, 1.1903, 1.3998, 1.2312, 1.2818],
        [1.5865, 1.2642, 0.5106, 0.7245, 1.0740, 1.4730, 1.4075, 1.5834, 1.5834,
         1.4664, 1.2334, 1.2969, 0.8423, 1.5552, 0.1459, 1.4505, 1.5699, 1.1360,
         1.1993, 0.7734, 0.6645, 0.9853, 1.4474, 1.5385, 1.2085, 1.5900, 1.5900,
         0.6235, 0.7253, 1.5567, 1.3294, 0.7472, 1.5305, 1.0331, 1.6014, 1.5458,
         0.6247, 0.3806, 0.3235, 0.5706, 0.9706, 1.2342, 0.5150, 6.0081, 5.3600,
         0.6700, 1.1333, 1.2083, 1.4516, 0.9139, 1.4361, 0.3305, 1.4601, 1.5990],
        [1.2691, 1.3013, 1.3694, 1.3442, 1.3109, 1.2751, 1.2411, 1.2669, 1.2669,
         1.2388, 1.3268, 1.2405, 1.3709, 1.3161, 1.4257, 1.2368, 1.3191, 1.2488,
         1.3222, 1.3559, 1.3660, 1.3348, 1.2934, 1.2817, 1.2590, 1.2788, 1.2788,
         1.3397, 1.3810, 1.3041, 1.1544, 1.2465, 1.1361, 1.3373, 1.1826, 1.3069,
         1.3899, 1.1227, 1.4122, 1.3975, 1.0146, 0.9195, 1.3930, 1.3548, 0.8092,
         2.4714, 2.0697, 2.4028, 2.2794, 1.7632, 1.5364, 2.3817, 2.2324, 1.5204]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 77 : 181.46975699025114
Test loss for epoch 77 : 181.52677104658613
Test Precision for epoch 77 : 0.26153846153846155
Test Recall for epoch 77 : 0.26153846153846155
Test F1 for epoch 77 : 0.26153846153846155


theta for epoch 78 : tensor([[2.0339, 2.0567, 2.1246, 2.1849, 2.1465, 2.0377, 2.1300, 2.0321, 2.0321,
         1.2761, 1.2892, 1.2928, 1.3106, 1.2632, 1.3566, 1.2746, 1.2660, 1.2435,
         1.2538, 1.2378, 1.2528, 1.2653, 1.2314, 1.2235, 1.2483, 1.2204, 1.2204,
         1.2654, 1.3195, 1.2367, 1.2647, 1.3106, 1.2489, 1.2700, 1.2004, 1.2396,
         1.3575, 1.3893, 1.3776, 1.3655, 1.3699, 1.3073, 1.3600, 1.3843, 1.3229,
         1.3452, 1.2942, 1.2855, 1.2584, 1.3391, 1.2816, 1.3757, 1.2607, 1.2626],
        [1.2840, 1.1818, 1.0008, 1.2302, 1.2919, 1.3336, 1.2583, 1.3249, 1.3249,
         1.4084, 1.6300, 1.3962, 2.1363, 1.4271, 3.8824, 1.5060, 1.3328, 3.5034,
         1.1292, 1.2005, 0.9600, 1.1731, 1.3044, 1.3363, 1.3167, 1.3339, 1.3339,
         1.3028, 1.0495, 1.3585, 1.3357, 1.1296, 1.3720, 1.3860, 1.3246, 1.3302,
         1.3204, 1.4748, 1.4069, 1.3207, 1.3056, 1.4316, 1.3883, 0.5248, 1.3836,
         1.0209, 1.4113, 1.3978, 1.3712, 1.0587, 1.3947, 0.8408, 1.3739, 1.3763],
        [1.2184, 1.2444, 1.2995, 1.2779, 1.2490, 1.2245, 1.2295, 1.2170, 1.2170,
         1.2822, 1.2960, 1.2995, 1.3172, 1.2689, 1.3133, 1.2806, 1.2620, 1.2073,
         2.0848, 2.1444, 2.2461, 2.1885, 1.9882, 2.0612, 2.1016, 1.9784, 1.9784,
         1.3064, 1.2830, 1.2442, 1.2722, 1.3065, 1.2565, 1.2787, 1.2507, 1.2471,
         1.3630, 1.3952, 1.3833, 1.3613, 1.3754, 1.3643, 1.3660, 1.2875, 1.3166,
         1.3069, 1.3021, 1.2931, 1.2654, 1.2547, 1.2899, 1.3346, 1.2676, 1.2697],
        [1.2208, 1.2512, 1.2223, 1.1979, 1.2575, 1.2268, 1.2347, 1.2187, 1.2187,
         1.2874, 1.2235, 1.3048, 1.2874, 1.2732, 1.2751, 1.2857, 1.2756, 1.0561,
         1.2702, 1.2589, 1.3127, 1.2838, 1.2422, 1.2035, 1.2628, 1.2296, 1.2296,
         2.4372, 2.0550, 1.8357, 1.9456, 2.4112, 1.8408, 2.3711, 1.8501, 1.8329,
         1.3582, 1.3932, 1.3398, 1.3290, 1.3690, 1.3359, 1.3581, 1.1537, 1.3220,
         1.3664, 1.2679, 1.1775, 1.2289, 1.3586, 1.1906, 1.4000, 1.2308, 1.2814],
        [1.5879, 1.2654, 0.5134, 0.7268, 1.0763, 1.4744, 1.4091, 1.5849, 1.5849,
         1.4675, 1.2341, 1.2984, 0.8439, 1.5571, 0.1476, 1.4520, 1.5716, 1.1371,
         1.2015, 0.7759, 0.6659, 0.9878, 1.4492, 1.5399, 1.2113, 1.5918, 1.5918,
         0.6249, 0.7274, 1.5578, 1.3311, 0.7463, 1.5295, 1.0338, 1.6028, 1.5467,
         0.6163, 0.3743, 0.3178, 0.5630, 0.9570, 1.2179, 0.5078, 6.0711, 5.4083,
         0.6731, 1.1362, 1.2115, 1.4527, 0.9178, 1.4385, 0.3330, 1.4640, 1.6018],
        [1.2681, 1.3002, 1.3680, 1.3429, 1.3104, 1.2746, 1.2403, 1.2660, 1.2660,
         1.2394, 1.3283, 1.2417, 1.3712, 1.3165, 1.4248, 1.2372, 1.3196, 1.2485,
         1.3212, 1.3552, 1.3665, 1.3344, 1.2925, 1.2809, 1.2579, 1.2780, 1.2780,
         1.3377, 1.3795, 1.3016, 1.1519, 1.2472, 1.1364, 1.3354, 1.1800, 1.3045,
         1.3891, 1.1211, 1.4111, 1.3968, 1.0140, 0.9191, 1.3920, 1.3578, 0.8110,
         2.4750, 2.0739, 2.4099, 2.2837, 1.7672, 1.5402, 2.3843, 2.2397, 1.5241]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 78 : 181.44772547682456
Test loss for epoch 78 : 181.50445456470212
Test Precision for epoch 78 : 0.26153846153846155
Test Recall for epoch 78 : 0.26153846153846155
Test F1 for epoch 78 : 0.26153846153846155


theta for epoch 79 : tensor([[2.0385, 2.0614, 2.1295, 2.1898, 2.1516, 2.0424, 2.1351, 2.0367, 2.0367,
         1.2754, 1.2882, 1.2916, 1.3097, 1.2626, 1.3550, 1.2738, 1.2654, 1.2421,
         1.2540, 1.2380, 1.2532, 1.2655, 1.2316, 1.2237, 1.2485, 1.2205, 1.2205,
         1.2644, 1.3180, 1.2355, 1.2636, 1.3094, 1.2478, 1.2691, 1.1994, 1.2385,
         1.3573, 1.3893, 1.3771, 1.3653, 1.3706, 1.3078, 1.3596, 1.3841, 1.3225,
         1.3473, 1.2960, 1.2873, 1.2602, 1.3412, 1.2833, 1.3778, 1.2623, 1.2642],
        [1.2844, 1.1827, 1.0003, 1.2301, 1.2924, 1.3340, 1.2588, 1.3253, 1.3253,
         1.4098, 1.6326, 1.3986, 2.1343, 1.4296, 3.8972, 1.5075, 1.3348, 3.5203,
         1.1294, 1.2004, 0.9617, 1.1732, 1.3047, 1.3364, 1.3166, 1.3341, 1.3341,
         1.3014, 1.0484, 1.3568, 1.3341, 1.1298, 1.3704, 1.3847, 1.3230, 1.3288,
         1.3196, 1.4745, 1.4060, 1.3196, 1.3052, 1.4318, 1.3876, 0.5244, 1.3829,
         1.0227, 1.4129, 1.3993, 1.3728, 1.0604, 1.3962, 0.8427, 1.3753, 1.3777],
        [1.2179, 1.2443, 1.2999, 1.2780, 1.2489, 1.2241, 1.2291, 1.2165, 1.2165,
         1.2813, 1.2950, 1.2981, 1.3160, 1.2681, 1.3127, 1.2797, 1.2616, 1.2063,
         2.0907, 2.1489, 2.2502, 2.1933, 1.9938, 2.0670, 2.1060, 1.9838, 1.9838,
         1.3055, 1.2819, 1.2427, 1.2708, 1.3056, 1.2550, 1.2775, 1.2493, 1.2457,
         1.3626, 1.3949, 1.3826, 1.3609, 1.3759, 1.3648, 1.3654, 1.2870, 1.3156,
         1.3086, 1.3038, 1.2947, 1.2671, 1.2568, 1.2914, 1.3368, 1.2691, 1.2711],
        [1.2197, 1.2499, 1.2220, 1.1980, 1.2564, 1.2259, 1.2337, 1.2177, 1.2177,
         1.2860, 1.2227, 1.3034, 1.2866, 1.2719, 1.2733, 1.2844, 1.2744, 1.0568,
         1.2691, 1.2588, 1.3114, 1.2826, 1.2413, 1.2031, 1.2617, 1.2288, 1.2288,
         2.4421, 2.0609, 1.8404, 1.9503, 2.4166, 1.8458, 2.3762, 1.8548, 1.8378,
         1.3581, 1.3930, 1.3393, 1.3291, 1.3695, 1.3363, 1.3576, 1.1546, 1.3214,
         1.3670, 1.2689, 1.1781, 1.2293, 1.3591, 1.1915, 1.4006, 1.2309, 1.2815],
        [1.5891, 1.2663, 0.5158, 0.7288, 1.0783, 1.4756, 1.4106, 1.5862, 1.5862,
         1.4678, 1.2339, 1.2991, 0.8447, 1.5582, 0.1488, 1.4526, 1.5726, 1.1373,
         1.2034, 0.7780, 0.6670, 0.9898, 1.4505, 1.5411, 1.2138, 1.5932, 1.5932,
         0.6263, 0.7295, 1.5591, 1.3329, 0.7453, 1.5286, 1.0346, 1.6043, 1.5477,
         0.6083, 0.3682, 0.3122, 0.5557, 0.9438, 1.2018, 0.5009, 6.1340, 5.4563,
         0.6764, 1.1395, 1.2152, 1.4547, 0.9220, 1.4417, 0.3357, 1.4686, 1.6054],
        [1.2678, 1.2998, 1.3671, 1.3422, 1.3104, 1.2747, 1.2402, 1.2658, 1.2658,
         1.2396, 1.3294, 1.2426, 1.3711, 1.3166, 1.4236, 1.2373, 1.3197, 1.2480,
         1.3206, 1.3548, 1.3671, 1.3343, 1.2920, 1.2805, 1.2573, 1.2776, 1.2776,
         1.3364, 1.3787, 1.2998, 1.1503, 1.2485, 1.1375, 1.3341, 1.1782, 1.3028,
         1.3880, 1.1196, 1.4097, 1.3958, 1.0133, 0.9186, 1.3907, 1.3605, 0.8125,
         2.4783, 2.0778, 2.4168, 2.2876, 1.7711, 1.5437, 2.3867, 2.2467, 1.5275]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 79 : 181.42659503568964
Test loss for epoch 79 : 181.48309122087377
Test Precision for epoch 79 : 0.26153846153846155
Test Recall for epoch 79 : 0.26153846153846155
Test F1 for epoch 79 : 0.26153846153846155


theta for epoch 80 : tensor([[2.0431, 2.0662, 2.1345, 2.1949, 2.1568, 2.0471, 2.1402, 2.0413, 2.0413,
         1.2750, 1.2876, 1.2909, 1.3092, 1.2623, 1.3539, 1.2734, 1.2651, 1.2412,
         1.2535, 1.2377, 1.2530, 1.2651, 1.2310, 1.2231, 1.2479, 1.2199, 1.2199,
         1.2648, 1.3180, 1.2359, 1.2639, 1.3096, 1.2481, 1.2697, 1.1998, 1.2389,
         1.3569, 1.3890, 1.3763, 1.3649, 1.3710, 1.3080, 1.3589, 1.3835, 1.3219,
         1.3486, 1.2970, 1.2882, 1.2613, 1.3424, 1.2843, 1.3791, 1.2631, 1.2650],
        [1.2844, 1.1832, 0.9997, 1.2297, 1.2925, 1.3341, 1.2589, 1.3255, 1.3255,
         1.4121, 1.6361, 1.4018, 2.1334, 1.4329, 3.9126, 1.5098, 1.3376, 3.5380,
         1.1288, 1.1995, 0.9626, 1.1725, 1.3044, 1.3359, 1.3157, 1.3335, 1.3335,
         1.3011, 1.0482, 1.3563, 1.3337, 1.1309, 1.3699, 1.3846, 1.3224, 1.3287,
         1.3184, 1.4739, 1.4048, 1.3182, 1.3044, 1.4316, 1.3865, 0.5234, 1.3817,
         1.0236, 1.4134, 1.3998, 1.3735, 1.0610, 1.3967, 0.8436, 1.3757, 1.3780],
        [1.2175, 1.2443, 1.3003, 1.2781, 1.2490, 1.2236, 1.2287, 1.2160, 1.2160,
         1.2808, 1.2945, 1.2972, 1.3153, 1.2677, 1.3124, 1.2791, 1.2615, 1.2057,
         2.0962, 2.1533, 2.2541, 2.1979, 1.9990, 2.0724, 2.1102, 1.9889, 1.9889,
         1.3060, 1.2822, 1.2428, 1.2709, 1.3062, 1.2551, 1.2777, 1.2493, 1.2458,
         1.3620, 1.3945, 1.3816, 1.3602, 1.3761, 1.3650, 1.3647, 1.2864, 1.3144,
         1.3096, 1.3046, 1.2955, 1.2680, 1.2582, 1.2922, 1.3382, 1.2697, 1.2717],
        [1.2187, 1.2487, 1.2216, 1.1981, 1.2553, 1.2250, 1.2327, 1.2167, 1.2167,
         1.2849, 1.2221, 1.3023, 1.2861, 1.2709, 1.2718, 1.2833, 1.2734, 1.0576,
         1.2675, 1.2582, 1.3097, 1.2810, 1.2400, 1.2023, 1.2602, 1.2275, 1.2275,
         2.4474, 2.0673, 1.8457, 1.9554, 2.4224, 1.8513, 2.3817, 1.8600, 1.8433,
         1.3576, 1.3924, 1.3385, 1.3290, 1.3697, 1.3363, 1.3568, 1.1552, 1.3205,
         1.3669, 1.2692, 1.1779, 1.2289, 1.3589, 1.1917, 1.4006, 1.2304, 1.2810],
        [1.5904, 1.2674, 0.5183, 0.7308, 1.0804, 1.4769, 1.4122, 1.5875, 1.5875,
         1.4684, 1.2340, 1.3001, 0.8457, 1.5596, 0.1502, 1.4537, 1.5738, 1.1377,
         1.2051, 0.7798, 0.6679, 0.9917, 1.4516, 1.5419, 1.2159, 1.5943, 1.5943,
         0.6285, 0.7323, 1.5613, 1.3357, 0.7452, 1.5286, 1.0364, 1.6068, 1.5497,
         0.6004, 0.3621, 0.3066, 0.5485, 0.9308, 1.1859, 0.4941, 6.1967, 5.5038,
         0.6785, 1.1416, 1.2178, 1.4558, 0.9249, 1.4440, 0.3373, 1.4722, 1.6081],
        [1.2681, 1.2999, 1.3668, 1.3420, 1.3109, 1.2754, 1.2407, 1.2661, 1.2661,
         1.2405, 1.3312, 1.2444, 1.3718, 1.3176, 1.4233, 1.2381, 1.3206, 1.2485,
         1.3200, 1.3543, 1.3675, 1.3341, 1.2915, 1.2802, 1.2567, 1.2773, 1.2773,
         1.3365, 1.3794, 1.2995, 1.1501, 1.2512, 1.1401, 1.3343, 1.1780, 1.3026,
         1.3869, 1.1181, 1.4083, 1.3947, 1.0127, 0.9183, 1.3894, 1.3630, 0.8139,
         2.4808, 2.0807, 2.4227, 2.2906, 1.7742, 1.5463, 2.3882, 2.2529, 1.5301]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 80 : 181.40578673109226
Test loss for epoch 80 : 181.4627535367707
Test Precision for epoch 80 : 0.26153846153846155
Test Recall for epoch 80 : 0.26153846153846155
Test F1 for epoch 80 : 0.26153846153846155


theta for epoch 81 : tensor([[2.0480, 2.0713, 2.1399, 2.2003, 2.1623, 2.0522, 2.1456, 2.0462, 2.0462,
         1.2750, 1.2873, 1.2904, 1.3090, 1.2623, 1.3532, 1.2732, 1.2651, 1.2406,
         1.2533, 1.2378, 1.2530, 1.2651, 1.2307, 1.2227, 1.2477, 1.2195, 1.2195,
         1.2657, 1.3184, 1.2369, 1.2647, 1.3103, 1.2490, 1.2707, 1.2008, 1.2398,
         1.3566, 1.3889, 1.3758, 1.3647, 1.3715, 1.3083, 1.3585, 1.3830, 1.3214,
         1.3485, 1.2968, 1.2879, 1.2612, 1.3423, 1.2841, 1.3792, 1.2628, 1.2647],
        [1.2845, 1.1837, 0.9993, 1.2293, 1.2927, 1.3343, 1.2590, 1.3257, 1.3257,
         1.4147, 1.6401, 1.4052, 2.1330, 1.4365, 3.9282, 1.5123, 1.3406, 3.5560,
         1.1284, 1.1991, 0.9638, 1.1721, 1.3044, 1.3357, 1.3153, 1.3334, 1.3334,
         1.3012, 1.0486, 1.3563, 1.3338, 1.1324, 1.3699, 1.3849, 1.3223, 1.3291,
         1.3174, 1.4734, 1.4038, 1.3169, 1.3038, 1.4315, 1.3855, 0.5225, 1.3806,
         1.0232, 1.4127, 1.3990, 1.3729, 1.0604, 1.3960, 0.8434, 1.3748, 1.3772],
        [1.2169, 1.2441, 1.3006, 1.2782, 1.2488, 1.2230, 1.2283, 1.2153, 1.2153,
         1.2806, 1.2942, 1.2967, 1.3150, 1.2675, 1.3123, 1.2789, 1.2617, 1.2054,
         2.1021, 2.1582, 2.2586, 2.2030, 2.0046, 2.0783, 2.1149, 1.9944, 1.9944,
         1.3071, 1.2830, 1.2435, 1.2714, 1.3073, 1.2557, 1.2784, 1.2499, 1.2464,
         1.3616, 1.3942, 1.3809, 1.3597, 1.3765, 1.3653, 1.3640, 1.2858, 1.3134,
         1.3093, 1.3042, 1.2950, 1.2677, 1.2583, 1.2917, 1.3385, 1.2692, 1.2712],
        [1.2181, 1.2479, 1.2216, 1.1985, 1.2547, 1.2245, 1.2322, 1.2162, 1.2162,
         1.2845, 1.2222, 1.3018, 1.2863, 1.2705, 1.2710, 1.2829, 1.2731, 1.0590,
         1.2667, 1.2583, 1.3086, 1.2800, 1.2395, 1.2021, 1.2594, 1.2269, 1.2269,
         2.4524, 2.0735, 1.8507, 1.9604, 2.4280, 1.8566, 2.3870, 1.8651, 1.8486,
         1.3573, 1.3920, 1.3380, 1.3290, 1.3701, 1.3367, 1.3562, 1.1560, 1.3198,
         1.3660, 1.2687, 1.1771, 1.2279, 1.3579, 1.1913, 1.3998, 1.2291, 1.2797],
        [1.5920, 1.2689, 0.5211, 0.7332, 1.0829, 1.4786, 1.4142, 1.5892, 1.5892,
         1.4695, 1.2346, 1.3015, 0.8473, 1.5615, 0.1523, 1.4552, 1.5756, 1.1386,
         1.2073, 0.7821, 0.6695, 0.9940, 1.4532, 1.5432, 1.2185, 1.5958, 1.5958,
         0.6311, 0.7355, 1.5640, 1.3390, 0.7456, 1.5291, 1.0387, 1.6098, 1.5521,
         0.5926, 0.3558, 0.3009, 0.5414, 0.9179, 1.1700, 0.4873, 6.2591, 5.5508,
         0.6795, 1.1426, 1.2191, 1.4559, 0.9266, 1.4451, 0.3382, 1.4747, 1.6097],
        [1.2682, 1.2998, 1.3662, 1.3417, 1.3111, 1.2758, 1.2410, 1.2663, 1.2663,
         1.2414, 1.3330, 1.2460, 1.3726, 1.3184, 1.4232, 1.2389, 1.3214, 1.2490,
         1.3195, 1.3538, 1.3679, 1.3340, 1.2912, 1.2800, 1.2562, 1.2770, 1.2770,
         1.3369, 1.3803, 1.2996, 1.1502, 1.2542, 1.1430, 1.3348, 1.1780, 1.3026,
         1.3858, 1.1168, 1.4070, 1.3937, 1.0121, 0.9179, 1.3881, 1.3656, 0.8149,
         2.4834, 2.0837, 2.4287, 2.2935, 1.7774, 1.5489, 2.3899, 2.2591, 1.5327]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 81 : 181.38559919771475
Test loss for epoch 81 : 181.44308126574555
Test Precision for epoch 81 : 0.26153846153846155
Test Recall for epoch 81 : 0.26153846153846155
Test F1 for epoch 81 : 0.26153846153846155


theta for epoch 82 : tensor([[2.0532, 2.0767, 2.1455, 2.2060, 2.1681, 2.0575, 2.1513, 2.0514, 2.0514,
         1.2747, 1.2868, 1.2898, 1.3087, 1.2620, 1.3526, 1.2728, 1.2647, 1.2399,
         1.2536, 1.2383, 1.2533, 1.2654, 1.2307, 1.2227, 1.2478, 1.2194, 1.2194,
         1.2659, 1.3180, 1.2371, 1.2647, 1.3102, 1.2491, 1.2710, 1.2010, 1.2400,
         1.3570, 1.3893, 1.3758, 1.3650, 1.3725, 1.3092, 1.3587, 1.3831, 1.3214,
         1.3482, 1.2962, 1.2873, 1.2608, 1.3418, 1.2836, 1.3789, 1.2621, 1.2641],
        [1.2848, 1.1845, 0.9994, 1.2294, 1.2931, 1.3348, 1.2595, 1.3262, 1.3262,
         1.4165, 1.6435, 1.4078, 2.1321, 1.4393, 3.9431, 1.5141, 1.3430, 3.5733,
         1.1287, 1.1994, 0.9657, 1.1725, 1.3051, 1.3364, 1.3156, 1.3341, 1.3341,
         1.3010, 1.0485, 1.3559, 1.3335, 1.1335, 1.3695, 1.3848, 1.3218, 1.3291,
         1.3172, 1.4736, 1.4035, 1.3164, 1.3040, 1.4321, 1.3853, 0.5223, 1.3802,
         1.0230, 1.4119, 1.3981, 1.3724, 1.0598, 1.3952, 0.8433, 1.3739, 1.3765],
        [1.2160, 1.2437, 1.3006, 1.2781, 1.2485, 1.2221, 1.2276, 1.2143, 1.2143,
         1.2802, 1.2938, 1.2959, 1.3145, 1.2672, 1.3121, 1.2784, 1.2616, 1.2049,
         2.1084, 2.1635, 2.2636, 2.2085, 2.0105, 2.0844, 2.1200, 2.0002, 2.0002,
         1.3074, 1.2830, 1.2435, 1.2713, 1.3077, 1.2556, 1.2785, 1.2499, 1.2464,
         1.3618, 1.3945, 1.3808, 1.3598, 1.3773, 1.3661, 1.3640, 1.2858, 1.3129,
         1.3087, 1.3034, 1.2943, 1.2673, 1.2582, 1.2911, 1.3384, 1.2684, 1.2705],
        [1.2182, 1.2478, 1.2222, 1.1994, 1.2546, 1.2246, 1.2322, 1.2163, 1.2163,
         1.2845, 1.2228, 1.3017, 1.2870, 1.2705, 1.2708, 1.2828, 1.2731, 1.0608,
         1.2668, 1.2592, 1.3086, 1.2800, 1.2398, 1.2030, 1.2595, 1.2273, 1.2273,
         2.4567, 2.0789, 1.8551, 1.9646, 2.4327, 1.8612, 2.3915, 1.8694, 1.8532,
         1.3578, 1.3924, 1.3383, 1.3298, 1.3712, 1.3377, 1.3564, 1.1575, 1.3196,
         1.3652, 1.2684, 1.1765, 1.2270, 1.3570, 1.1911, 1.3991, 1.2280, 1.2786],
        [1.5938, 1.2707, 0.5241, 0.7358, 1.0856, 1.4805, 1.4165, 1.5911, 1.5911,
         1.4708, 1.2353, 1.3030, 0.8490, 1.5633, 0.1548, 1.4568, 1.5774, 1.1396,
         1.2101, 0.7850, 0.6718, 0.9970, 1.4554, 1.5450, 1.2215, 1.5979, 1.5979,
         0.6336, 0.7385, 1.5663, 1.3419, 0.7459, 1.5293, 1.0409, 1.6124, 1.5542,
         0.5850, 0.3495, 0.2951, 0.5343, 0.9053, 1.1541, 0.4806, 6.3210, 5.5971,
         0.6807, 1.1437, 1.2206, 1.4562, 0.9284, 1.4464, 0.3393, 1.4773, 1.6115],
        [1.2673, 1.2987, 1.3645, 1.3403, 1.3101, 1.2751, 1.2402, 1.2654, 1.2654,
         1.2405, 1.3332, 1.2459, 1.3718, 1.3176, 1.4217, 1.2379, 1.3207, 1.2479,
         1.3184, 1.3526, 1.3675, 1.3331, 1.2902, 1.2792, 1.2550, 1.2762, 1.2762,
         1.3360, 1.3801, 1.2983, 1.1491, 1.2558, 1.1445, 1.3341, 1.1768, 1.3014,
         1.3848, 1.1154, 1.4059, 1.3928, 1.0113, 0.9172, 1.3870, 1.3681, 0.8153,
         2.4876, 2.0884, 2.4363, 2.2980, 1.7825, 1.5533, 2.3932, 2.2671, 1.5370]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 82 : 181.36530056928157
Test loss for epoch 82 : 181.422272467877
Test Precision for epoch 82 : 0.26153846153846155
Test Recall for epoch 82 : 0.26153846153846155
Test F1 for epoch 82 : 0.26153846153846155


theta for epoch 83 : tensor([[2.0582, 2.0820, 2.1510, 2.2115, 2.1738, 2.0627, 2.1567, 2.0564, 2.0564,
         1.2746, 1.2865, 1.2893, 1.3086, 1.2618, 1.3523, 1.2726, 1.2645, 1.2394,
         1.2531, 1.2382, 1.2529, 1.2651, 1.2299, 1.2218, 1.2472, 1.2186, 1.2186,
         1.2654, 1.3170, 1.2368, 1.2642, 1.3095, 1.2487, 1.2708, 1.2007, 1.2397,
         1.3579, 1.3904, 1.3765, 1.3659, 1.3741, 1.3106, 1.3595, 1.3837, 1.3220,
         1.3480, 1.2958, 1.2869, 1.2607, 1.3414, 1.2833, 1.3787, 1.2617, 1.2637],
        [1.2851, 1.1852, 0.9998, 1.2295, 1.2935, 1.3352, 1.2598, 1.3266, 1.3266,
         1.4180, 1.6465, 1.4101, 2.1311, 1.4417, 3.9576, 1.5154, 1.3449, 3.5902,
         1.1288, 1.1995, 0.9675, 1.1727, 1.3056, 1.3368, 1.3158, 1.3346, 1.3346,
         1.3004, 1.0481, 1.3552, 1.3329, 1.1342, 1.3687, 1.3843, 1.3210, 1.3288,
         1.3178, 1.4744, 1.4040, 1.3167, 1.3048, 1.4332, 1.3858, 0.5228, 1.3804,
         1.0232, 1.4114, 1.3976, 1.3723, 1.0597, 1.3948, 0.8438, 1.3733, 1.3761],
        [1.2150, 1.2432, 1.3005, 1.2779, 1.2481, 1.2211, 1.2269, 1.2133, 1.2133,
         1.2803, 1.2938, 1.2956, 1.3145, 1.2671, 1.3123, 1.2784, 1.2618, 1.2048,
         2.1138, 2.1681, 2.2679, 2.2133, 2.0156, 2.0897, 2.1243, 2.0051, 2.0051,
         1.3074, 1.2826, 1.2432, 1.2708, 1.3077, 1.2551, 1.2782, 1.2494, 1.2461,
         1.3626, 1.3955, 1.3815, 1.3607, 1.3789, 1.3676, 1.3648, 1.2864, 1.3132,
         1.3085, 1.3030, 1.2939, 1.2672, 1.2583, 1.2908, 1.3386, 1.2680, 1.2702],
        [1.2182, 1.2477, 1.2229, 1.2003, 1.2545, 1.2247, 1.2323, 1.2164, 1.2164,
         1.2848, 1.2237, 1.3018, 1.2880, 1.2707, 1.2711, 1.2831, 1.2734, 1.0628,
         1.2667, 1.2599, 1.3084, 1.2799, 1.2401, 1.2036, 1.2594, 1.2275, 1.2275,
         2.4606, 2.0840, 1.8591, 1.9686, 2.4371, 1.8654, 2.3956, 1.8734, 1.8575,
         1.3588, 1.3933, 1.3392, 1.3312, 1.3729, 1.3393, 1.3571, 1.1595, 1.3200,
         1.3647, 1.2683, 1.1762, 1.2265, 1.3564, 1.1912, 1.3986, 1.2272, 1.2778],
        [1.5956, 1.2726, 0.5272, 0.7385, 1.0883, 1.4825, 1.4187, 1.5929, 1.5929,
         1.4721, 1.2361, 1.3046, 0.8509, 1.5653, 0.1577, 1.4585, 1.5792, 1.1406,
         1.2128, 0.7877, 0.6741, 0.9998, 1.4573, 1.5466, 1.2242, 1.5997, 1.5997,
         0.6358, 0.7412, 1.5682, 1.3443, 0.7459, 1.5290, 1.0426, 1.6145, 1.5559,
         0.5777, 0.3433, 0.2896, 0.5276, 0.8931, 1.1386, 0.4741, 6.3829, 5.6431,
         0.6822, 1.1451, 1.2224, 1.4570, 0.9304, 1.4481, 0.3408, 1.4802, 1.6137],
        [1.2653, 1.2966, 1.3619, 1.3379, 1.3081, 1.2734, 1.2383, 1.2635, 1.2635,
         1.2385, 1.3324, 1.2447, 1.3701, 1.3159, 1.4195, 1.2359, 1.3189, 1.2459,
         1.3162, 1.3503, 1.3659, 1.3310, 1.2881, 1.2772, 1.2526, 1.2742, 1.2742,
         1.3341, 1.3789, 1.2962, 1.1469, 1.2564, 1.1451, 1.3323, 1.1746, 1.2993,
         1.3841, 1.1142, 1.4050, 1.3921, 1.0105, 0.9165, 1.3861, 1.3706, 0.8153,
         2.4933, 2.0946, 2.4454, 2.3040, 1.7890, 1.5591, 2.3980, 2.2767, 1.5427]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 83 : 181.34519415389988
Test loss for epoch 83 : 181.40096732438803
Test Precision for epoch 83 : 0.26153846153846155
Test Recall for epoch 83 : 0.26153846153846155
Test F1 for epoch 83 : 0.26153846153846155


theta for epoch 84 : tensor([[2.0628, 2.0869, 2.1562, 2.2168, 2.1792, 2.0675, 2.1619, 2.0611, 2.0611,
         1.2749, 1.2867, 1.2894, 1.3091, 1.2620, 1.3526, 1.2728, 1.2647, 1.2395,
         1.2525, 1.2379, 1.2523, 1.2646, 1.2290, 1.2208, 1.2463, 1.2175, 1.2175,
         1.2653, 1.3163, 1.2369, 1.2641, 1.3091, 1.2486, 1.2708, 1.2007, 1.2397,
         1.3590, 1.3916, 1.3774, 1.3670, 1.3758, 1.3121, 1.3605, 1.3844, 1.3227,
         1.3475, 1.2952, 1.2862, 1.2605, 1.3408, 1.2828, 1.3784, 1.2610, 1.2632],
        [1.2850, 1.1856, 1.0001, 1.2294, 1.2936, 1.3353, 1.2598, 1.3267, 1.3267,
         1.4198, 1.6499, 1.4125, 2.1306, 1.4444, 3.9722, 1.5170, 1.3471, 3.6073,
         1.1285, 1.1994, 0.9689, 1.1725, 1.3057, 1.3370, 1.3157, 1.3348, 1.3348,
         1.2999, 1.0478, 1.3548, 1.3325, 1.1349, 1.3682, 1.3840, 1.3204, 1.3288,
         1.3185, 1.4753, 1.4045, 1.3171, 1.3058, 1.4343, 1.3863, 0.5233, 1.3806,
         1.0231, 1.4105, 1.3967, 1.3719, 1.0592, 1.3941, 0.8440, 1.3724, 1.3754],
        [1.2140, 1.2425, 1.3002, 1.2775, 1.2476, 1.2200, 1.2261, 1.2123, 1.2123,
         1.2807, 1.2942, 1.2958, 1.3150, 1.2675, 1.3129, 1.2788, 1.2624, 1.2052,
         2.1190, 2.1726, 2.2721, 2.2179, 2.0203, 2.0946, 2.1284, 2.0097, 2.0097,
         1.3077, 1.2824, 1.2432, 1.2707, 1.3079, 1.2550, 1.2782, 1.2493, 1.2461,
         1.3637, 1.3966, 1.3823, 1.3617, 1.3805, 1.3691, 1.3657, 1.2871, 1.3137,
         1.3080, 1.3024, 1.2932, 1.2669, 1.2582, 1.2902, 1.3385, 1.2674, 1.2697],
        [1.2179, 1.2471, 1.2230, 1.2007, 1.2540, 1.2244, 1.2319, 1.2161, 1.2161,
         1.2850, 1.2246, 1.3019, 1.2890, 1.2709, 1.2714, 1.2833, 1.2736, 1.0647,
         1.2662, 1.2601, 1.3077, 1.2792, 1.2397, 1.2037, 1.2589, 1.2272, 1.2272,
         2.4648, 2.0896, 1.8636, 1.9730, 2.4418, 1.8702, 2.4001, 1.8779, 1.8622,
         1.3596, 1.3940, 1.3400, 1.3324, 1.3743, 1.3407, 1.3577, 1.1612, 1.3202,
         1.3637, 1.2679, 1.1755, 1.2255, 1.3554, 1.1909, 1.3977, 1.2260, 1.2766],
        [1.5973, 1.2744, 0.5301, 0.7410, 1.0908, 1.4844, 1.4209, 1.5946, 1.5946,
         1.4738, 1.2370, 1.3064, 0.8529, 1.5674, 0.1609, 1.4605, 1.5813, 1.1418,
         1.2152, 0.7901, 0.6763, 1.0024, 1.4590, 1.5480, 1.2267, 1.6014, 1.6014,
         0.6380, 0.7440, 1.5702, 1.3469, 0.7462, 1.5289, 1.0445, 1.6167, 1.5577,
         0.5706, 0.3372, 0.2841, 0.5210, 0.8813, 1.1234, 0.4678, 6.4445, 5.6886,
         0.6831, 1.1459, 1.2236, 1.4575, 0.9318, 1.4493, 0.3420, 1.4827, 1.6155],
        [1.2637, 1.2949, 1.3596, 1.3358, 1.3062, 1.2718, 1.2367, 1.2619, 1.2619,
         1.2372, 1.3322, 1.2442, 1.3692, 1.3148, 1.4182, 1.2345, 1.3178, 1.2448,
         1.3141, 1.3481, 1.3643, 1.3291, 1.2862, 1.2754, 1.2505, 1.2724, 1.2724,
         1.3326, 1.3781, 1.2945, 1.1452, 1.2573, 1.1460, 1.3310, 1.1729, 1.2976,
         1.3836, 1.1134, 1.4044, 1.3917, 1.0101, 0.9161, 1.3855, 1.3733, 0.8154,
         2.4985, 2.1002, 2.4541, 2.3093, 1.7952, 1.5644, 2.4024, 2.2857, 1.5480]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 84 : 181.3260428113866
Test loss for epoch 84 : 181.38102709465448
Test Precision for epoch 84 : 0.26153846153846155
Test Recall for epoch 84 : 0.26153846153846155
Test F1 for epoch 84 : 0.26153846153846155


theta for epoch 85 : tensor([[2.0677, 2.0921, 2.1617, 2.2223, 2.1848, 2.0725, 2.1673, 2.0660, 2.0660,
         1.2750, 1.2868, 1.2893, 1.3093, 1.2620, 1.3528, 1.2729, 1.2647, 1.2394,
         1.2526, 1.2383, 1.2523, 1.2648, 1.2288, 1.2205, 1.2462, 1.2171, 1.2171,
         1.2654, 1.3160, 1.2373, 1.2643, 1.3090, 1.2489, 1.2712, 1.2011, 1.2402,
         1.3596, 1.3923, 1.3779, 1.3675, 1.3769, 1.3131, 1.3610, 1.3844, 1.3228,
         1.3468, 1.2943, 1.2853, 1.2600, 1.3400, 1.2820, 1.3778, 1.2601, 1.2625],
        [1.2852, 1.1861, 1.0006, 1.2296, 1.2939, 1.3357, 1.2600, 1.3271, 1.3271,
         1.4216, 1.6534, 1.4151, 2.1304, 1.4472, 3.9870, 1.5187, 1.3494, 3.6246,
         1.1285, 1.1997, 0.9705, 1.1727, 1.3063, 1.3376, 1.3160, 1.3354, 1.3354,
         1.2998, 1.0477, 1.3547, 1.3324, 1.1358, 1.3680, 1.3841, 1.3201, 1.3291,
         1.3187, 1.4757, 1.4045, 1.3169, 1.3061, 1.4349, 1.3863, 0.5231, 1.3802,
         1.0227, 1.4093, 1.3955, 1.3712, 1.0583, 1.3931, 0.8439, 1.3712, 1.3744],
        [1.2132, 1.2420, 1.2999, 1.2773, 1.2472, 1.2191, 1.2256, 1.2113, 1.2113,
         1.2808, 1.2943, 1.2956, 1.3152, 1.2675, 1.3131, 1.2787, 1.2625, 1.2052,
         2.1248, 2.1778, 2.2771, 2.2233, 2.0257, 2.1003, 2.1333, 2.0150, 2.0150,
         1.3081, 1.2823, 1.2435, 1.2707, 1.3083, 1.2552, 1.2784, 1.2495, 1.2463,
         1.3641, 1.3972, 1.3826, 1.3621, 1.3814, 1.3700, 1.3660, 1.2871, 1.3136,
         1.3072, 1.3014, 1.2922, 1.2663, 1.2578, 1.2893, 1.3381, 1.2664, 1.2688],
        [1.2173, 1.2464, 1.2230, 1.2008, 1.2533, 1.2239, 1.2313, 1.2155, 1.2155,
         1.2845, 1.2246, 1.3013, 1.2893, 1.2704, 1.2710, 1.2827, 1.2731, 1.0658,
         1.2655, 1.2601, 1.3070, 1.2784, 1.2393, 1.2037, 1.2582, 1.2268, 1.2268,
         2.4698, 2.0959, 1.8689, 1.9782, 2.4473, 1.8757, 2.4052, 1.8832, 1.8677,
         1.3597, 1.3940, 1.3401, 1.3328, 1.3750, 1.3414, 1.3576, 1.1622, 1.3197,
         1.3623, 1.2669, 1.1743, 1.2241, 1.3538, 1.1902, 1.3963, 1.2243, 1.2749],
        [1.5993, 1.2765, 0.5330, 0.7435, 1.0935, 1.4865, 1.4234, 1.5966, 1.5966,
         1.4752, 1.2378, 1.3080, 0.8547, 1.5692, 0.1640, 1.4622, 1.5832, 1.1427,
         1.2180, 0.7928, 0.6789, 1.0053, 1.4611, 1.5498, 1.2294, 1.6034, 1.6034,
         0.6404, 0.7469, 1.5725, 1.3497, 0.7467, 1.5292, 1.0467, 1.6192, 1.5598,
         0.5636, 0.3309, 0.2784, 0.5144, 0.8696, 1.1083, 0.4614, 6.5058, 5.7336,
         0.6835, 1.1461, 1.2242, 1.4575, 0.9326, 1.4500, 0.3428, 1.4845, 1.6169],
        [1.2634, 1.2945, 1.3587, 1.3351, 1.3057, 1.2716, 1.2365, 1.2617, 1.2617,
         1.2368, 1.3328, 1.2446, 1.3691, 1.3145, 1.4178, 1.2340, 1.3175, 1.2446,
         1.3136, 1.3472, 1.3639, 1.3285, 1.2858, 1.2750, 1.2498, 1.2721, 1.2721,
         1.3321, 1.3782, 1.2939, 1.1446, 1.2591, 1.1481, 1.3308, 1.1723, 1.2970,
         1.3831, 1.1128, 1.4038, 1.3913, 1.0098, 0.9158, 1.3849, 1.3757, 0.8155,
         2.5023, 2.1043, 2.4612, 2.3131, 1.7999, 1.5682, 2.4053, 2.2933, 1.5517]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 85 : 181.30682392993674
Test loss for epoch 85 : 181.36166858159697
Test Precision for epoch 85 : 0.26153846153846155
Test Recall for epoch 85 : 0.26153846153846155
Test F1 for epoch 85 : 0.26153846153846155


theta for epoch 86 : tensor([[2.0729, 2.0975, 2.1674, 2.2281, 2.1907, 2.0778, 2.1729, 2.0711, 2.0711,
         1.2747, 1.2865, 1.2889, 1.3092, 1.2615, 1.3528, 1.2725, 1.2642, 1.2390,
         1.2527, 1.2386, 1.2521, 1.2649, 1.2285, 1.2201, 1.2461, 1.2167, 1.2167,
         1.2653, 1.3153, 1.2376, 1.2642, 1.3086, 1.2490, 1.2713, 1.2012, 1.2404,
         1.3596, 1.3924, 1.3777, 1.3675, 1.3774, 1.3135, 1.3609, 1.3838, 1.3223,
         1.3469, 1.2942, 1.2851, 1.2602, 1.3398, 1.2820, 1.3779, 1.2599, 1.2625],
        [1.2854, 1.1867, 1.0013, 1.2298, 1.2943, 1.3361, 1.2601, 1.3275, 1.3275,
         1.4236, 1.6571, 1.4177, 2.1306, 1.4501, 4.0018, 1.5205, 1.3518, 3.6421,
         1.1284, 1.1999, 0.9718, 1.1728, 1.3067, 1.3380, 1.3163, 1.3359, 1.3359,
         1.2994, 1.0473, 1.3544, 1.3322, 1.1364, 1.3676, 1.3838, 1.3197, 1.3292,
         1.3182, 1.4754, 1.4039, 1.3161, 1.3059, 1.4347, 1.3857, 0.5221, 1.3792,
         1.0231, 1.4088, 1.3950, 1.3712, 1.0582, 1.3927, 0.8446, 1.3707, 1.3741],
        [1.2126, 1.2416, 1.2997, 1.2772, 1.2470, 1.2185, 1.2252, 1.2107, 1.2107,
         1.2804, 1.2939, 1.2951, 1.3149, 1.2670, 1.3129, 1.2783, 1.2622, 1.2047,
         2.1309, 2.1834, 2.2824, 2.2290, 2.0314, 2.1061, 2.1385, 2.0205, 2.0205,
         1.3082, 1.2819, 1.2435, 1.2705, 1.3084, 1.2551, 1.2783, 1.2494, 1.2463,
         1.3639, 1.3971, 1.3822, 1.3619, 1.3817, 1.3703, 1.3657, 1.2865, 1.3130,
         1.3070, 1.3011, 1.2918, 1.2664, 1.2580, 1.2891, 1.3384, 1.2660, 1.2687],
        [1.2166, 1.2456, 1.2228, 1.2007, 1.2524, 1.2232, 1.2306, 1.2148, 1.2148,
         1.2834, 1.2241, 1.3001, 1.2890, 1.2692, 1.2701, 1.2816, 1.2719, 1.0663,
         1.2646, 1.2597, 1.3060, 1.2774, 1.2386, 1.2034, 1.2572, 1.2261, 1.2261,
         2.4750, 2.1025, 1.8745, 1.9837, 2.4529, 1.8815, 2.4107, 1.8888, 1.8735,
         1.3592, 1.3933, 1.3396, 1.3327, 1.3751, 1.3414, 1.3568, 1.1625, 1.3184,
         1.3613, 1.2664, 1.1736, 1.2231, 1.3528, 1.1900, 1.3954, 1.2229, 1.2737],
        [1.6014, 1.2787, 0.5358, 0.7461, 1.0962, 1.4889, 1.4260, 1.5988, 1.5988,
         1.4763, 1.2381, 1.3092, 0.8562, 1.5706, 0.1669, 1.4636, 1.5847, 1.1431,
         1.2207, 0.7953, 0.6815, 1.0081, 1.4633, 1.5517, 1.2320, 1.6055, 1.6055,
         0.6427, 0.7496, 1.5747, 1.3524, 0.7472, 1.5294, 1.0487, 1.6215, 1.5617,
         0.5565, 0.3244, 0.2726, 0.5077, 0.8581, 1.0933, 0.4549, 6.5668, 5.7779,
         0.6845, 1.1470, 1.2254, 1.4583, 0.9339, 1.4513, 0.3442, 1.4870, 1.6189],
        [1.2641, 1.2951, 1.3587, 1.3354, 1.3060, 1.2723, 1.2372, 1.2623, 1.2623,
         1.2366, 1.3335, 1.2452, 1.3693, 1.3143, 1.4178, 1.2338, 1.3173, 1.2448,
         1.3137, 1.3471, 1.3641, 1.3286, 1.2861, 1.2754, 1.2499, 1.2725, 1.2725,
         1.3319, 1.3786, 1.2936, 1.1444, 1.2612, 1.1504, 1.3308, 1.1721, 1.2967,
         1.3823, 1.1120, 1.4029, 1.3905, 1.0094, 0.9154, 1.3840, 1.3776, 0.8152,
         2.5057, 2.1080, 2.4678, 2.3164, 1.8042, 1.5716, 2.4078, 2.3004, 1.5551]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 86 : 181.287986139039
Test loss for epoch 86 : 181.3428306227895
Test Precision for epoch 86 : 0.26153846153846155
Test Recall for epoch 86 : 0.26153846153846155
Test F1 for epoch 86 : 0.26153846153846155


theta for epoch 87 : tensor([[2.0777, 2.1026, 2.1727, 2.2335, 2.1963, 2.0827, 2.1782, 2.0759, 2.0759,
         1.2745, 1.2862, 1.2886, 1.3092, 1.2610, 1.3529, 1.2722, 1.2638, 1.2387,
         1.2520, 1.2381, 1.2512, 1.2642, 1.2275, 1.2190, 1.2452, 1.2155, 1.2155,
         1.2645, 1.3141, 1.2372, 1.2636, 1.3076, 1.2485, 1.2708, 1.2008, 1.2400,
         1.3596, 1.3925, 1.3776, 1.3674, 1.3778, 1.3138, 1.3608, 1.3831, 1.3218,
         1.3481, 1.2952, 1.2861, 1.2616, 1.3407, 1.2831, 1.3792, 1.2609, 1.2636],
        [1.2850, 1.1865, 1.0014, 1.2294, 1.2941, 1.3358, 1.2596, 1.3272, 1.3272,
         1.4259, 1.6610, 1.4206, 2.1313, 1.4532, 4.0169, 1.5226, 1.3544, 3.6598,
         1.1276, 1.1993, 0.9724, 1.1721, 1.3063, 1.3378, 1.3159, 1.3356, 1.3356,
         1.2983, 1.0462, 1.3535, 1.3312, 1.1360, 1.3666, 1.3829, 1.3186, 1.3287,
         1.3177, 1.4749, 1.4031, 1.3152, 1.3055, 1.4344, 1.3849, 0.5210, 1.3781,
         1.0245, 1.4094, 1.3956, 1.3723, 1.0591, 1.3935, 0.8463, 1.3713, 1.3749],
        [1.2117, 1.2408, 1.2989, 1.2766, 1.2463, 1.2175, 1.2245, 1.2097, 1.2097,
         1.2802, 1.2936, 1.2947, 1.3148, 1.2666, 1.3128, 1.2780, 1.2619, 1.2045,
         2.1365, 2.1884, 2.2873, 2.2342, 2.0365, 2.1114, 2.1432, 2.0255, 2.0255,
         1.3077, 1.2809, 1.2431, 1.2697, 1.3078, 1.2545, 1.2777, 1.2488, 1.2458,
         1.3637, 1.3970, 1.3819, 1.3617, 1.3820, 1.3704, 1.3654, 1.2858, 1.3123,
         1.3081, 1.3020, 1.2927, 1.2677, 1.2593, 1.2901, 1.3399, 1.2669, 1.2697],
        [1.2157, 1.2446, 1.2224, 1.2005, 1.2514, 1.2223, 1.2297, 1.2140, 1.2140,
         1.2825, 1.2237, 1.2989, 1.2889, 1.2681, 1.2693, 1.2805, 1.2708, 1.0669,
         1.2634, 1.2591, 1.3047, 1.2761, 1.2376, 1.2027, 1.2559, 1.2251, 1.2251,
         2.4799, 2.1089, 1.8799, 1.9890, 2.4583, 1.8871, 2.4158, 1.8942, 1.8791,
         1.3586, 1.3927, 1.3391, 1.3324, 1.3750, 1.3414, 1.3560, 1.1627, 1.3171,
         1.3613, 1.2668, 1.1737, 1.2231, 1.3527, 1.1907, 1.3954, 1.2226, 1.2734],
        [1.6031, 1.2805, 0.5382, 0.7483, 1.0983, 1.4909, 1.4282, 1.6005, 1.6005,
         1.4773, 1.2383, 1.3102, 0.8574, 1.5718, 0.1696, 1.4648, 1.5860, 1.1433,
         1.2228, 0.7972, 0.6835, 1.0103, 1.4649, 1.5530, 1.2340, 1.6071, 1.6071,
         0.6442, 0.7516, 1.5762, 1.3544, 0.7471, 1.5290, 1.0500, 1.6232, 1.5630,
         0.5498, 0.3181, 0.2669, 0.5013, 0.8472, 1.0789, 0.4486, 6.6277, 5.8220,
         0.6864, 1.1488, 1.2275, 1.4602, 0.9362, 1.4536, 0.3464, 1.4904, 1.6220],
        [1.2644, 1.2953, 1.3585, 1.3354, 1.3059, 1.2726, 1.2375, 1.2627, 1.2627,
         1.2363, 1.3342, 1.2457, 1.3694, 1.3140, 1.4179, 1.2335, 1.3171, 1.2450,
         1.3135, 1.3465, 1.3637, 1.3282, 1.2859, 1.2753, 1.2495, 1.2724, 1.2724,
         1.3312, 1.3785, 1.2928, 1.1437, 1.2627, 1.1521, 1.3303, 1.1715, 1.2960,
         1.3814, 1.1112, 1.4020, 1.3897, 1.0087, 0.9148, 1.3831, 1.3792, 0.8146,
         2.5097, 2.1123, 2.4751, 2.3203, 1.8093, 1.5756, 2.4110, 2.3083, 1.5590]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 87 : 181.26926186408713
Test loss for epoch 87 : 181.32400951405424
Test Precision for epoch 87 : 0.26153846153846155
Test Recall for epoch 87 : 0.26153846153846155
Test F1 for epoch 87 : 0.26153846153846155


theta for epoch 88 : tensor([[2.0824, 2.1077, 2.1780, 2.2389, 2.2017, 2.0875, 2.1834, 2.0806, 2.0806,
         1.2742, 1.2860, 1.2883, 1.3091, 1.2605, 1.3530, 1.2718, 1.2633, 1.2384,
         1.2512, 1.2375, 1.2501, 1.2635, 1.2264, 1.2178, 1.2442, 1.2143, 1.2143,
         1.2635, 1.3127, 1.2366, 1.2626, 1.3064, 1.2477, 1.2700, 1.2000, 1.2392,
         1.3598, 1.3928, 1.3778, 1.3676, 1.3783, 1.3143, 1.3610, 1.3826, 1.3215,
         1.3492, 1.2962, 1.2871, 1.2631, 1.3417, 1.2843, 1.3805, 1.2619, 1.2648],
        [1.2842, 1.1861, 1.0014, 1.2288, 1.2935, 1.3351, 1.2588, 1.3265, 1.3265,
         1.4280, 1.6648, 1.4233, 2.1320, 1.4561, 4.0318, 1.5246, 1.3569, 3.6774,
         1.1267, 1.1988, 0.9728, 1.1715, 1.3059, 1.3375, 1.3155, 1.3354, 1.3354,
         1.2970, 1.0448, 1.3524, 1.3301, 1.1354, 1.3654, 1.3818, 1.3173, 1.3280,
         1.3176, 1.4747, 1.4027, 1.3146, 1.3055, 1.4342, 1.3845, 0.5200, 1.3772,
         1.0260, 1.4101, 1.3963, 1.3735, 1.0602, 1.3943, 0.8481, 1.3719, 1.3758],
        [1.2105, 1.2395, 1.2976, 1.2755, 1.2452, 1.2161, 1.2234, 1.2084, 1.2084,
         1.2800, 1.2933, 1.2944, 1.3147, 1.2662, 1.3127, 1.2777, 1.2615, 1.2043,
         2.1419, 2.1936, 2.2923, 2.2395, 2.0415, 2.1167, 2.1479, 2.0304, 2.0304,
         1.3069, 1.2797, 1.2424, 1.2687, 1.3070, 1.2536, 1.2768, 1.2480, 1.2451,
         1.3638, 1.3972, 1.3819, 1.3618, 1.3824, 1.3708, 1.3654, 1.2853, 1.3120,
         1.3092, 1.3029, 1.2936, 1.2690, 1.2607, 1.2911, 1.3414, 1.2678, 1.2708],
        [1.2150, 1.2437, 1.2221, 1.2003, 1.2504, 1.2216, 1.2289, 1.2132, 1.2132,
         1.2818, 1.2236, 1.2981, 1.2889, 1.2672, 1.2689, 1.2797, 1.2699, 1.0676,
         1.2624, 1.2586, 1.3037, 1.2751, 1.2369, 1.2024, 1.2550, 1.2244, 1.2244,
         2.4844, 2.1149, 1.8850, 1.9940, 2.4633, 1.8923, 2.4205, 1.8992, 1.8844,
         1.3583, 1.3923, 1.3389, 1.3325, 1.3752, 1.3417, 1.3556, 1.1632, 1.3161,
         1.3615, 1.2675, 1.1741, 1.2234, 1.3527, 1.1916, 1.3957, 1.2225, 1.2734],
        [1.6046, 1.2820, 0.5400, 0.7499, 1.0999, 1.4925, 1.4300, 1.6020, 1.6020,
         1.4780, 1.2382, 1.3109, 0.8583, 1.5728, 0.1720, 1.4657, 1.5870, 1.1431,
         1.2247, 0.7988, 0.6853, 1.0122, 1.4664, 1.5541, 1.2357, 1.6085, 1.6085,
         0.6453, 0.7532, 1.5773, 1.3559, 0.7467, 1.5284, 1.0508, 1.6245, 1.5639,
         0.5435, 0.3122, 0.2616, 0.4954, 0.8368, 1.0650, 0.4428, 6.6886, 5.8658,
         0.6881, 1.1504, 1.2295, 1.4620, 0.9382, 1.4557, 0.3484, 1.4936, 1.6249],
        [1.2645, 1.2953, 1.3580, 1.3351, 1.3055, 1.2725, 1.2375, 1.2627, 1.2627,
         1.2358, 1.3346, 1.2459, 1.3693, 1.3135, 1.4180, 1.2330, 1.3166, 1.2450,
         1.3132, 1.3459, 1.3631, 1.3277, 1.2857, 1.2752, 1.2491, 1.2723, 1.2723,
         1.3302, 1.3780, 1.2919, 1.1428, 1.2638, 1.1535, 1.3296, 1.1707, 1.2950,
         1.3808, 1.1107, 1.4014, 1.3892, 1.0083, 0.9143, 1.3824, 1.3808, 0.8140,
         2.5140, 2.1169, 2.4826, 2.3244, 1.8146, 1.5799, 2.4145, 2.3164, 1.5633]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 88 : 181.25124904749202
Test loss for epoch 88 : 181.3059454609053
Test Precision for epoch 88 : 0.26153846153846155
Test Recall for epoch 88 : 0.26153846153846155
Test F1 for epoch 88 : 0.26153846153846155


theta for epoch 89 : tensor([[2.0878, 2.1133, 2.1838, 2.2449, 2.2079, 2.0930, 2.1892, 2.0860, 2.0860,
         1.2737, 1.2856, 1.2878, 1.3090, 1.2598, 1.3531, 1.2713, 1.2626, 1.2380,
         1.2507, 1.2371, 1.2493, 1.2630, 1.2257, 1.2170, 1.2436, 1.2135, 1.2135,
         1.2628, 1.3116, 1.2363, 1.2621, 1.3056, 1.2473, 1.2695, 1.1996, 1.2389,
         1.3602, 1.3933, 1.3781, 1.3680, 1.3790, 1.3149, 1.3614, 1.3822, 1.3213,
         1.3491, 1.2960, 1.2868, 1.2632, 1.3412, 1.2841, 1.3805, 1.2616, 1.2647],
        [1.2839, 1.1861, 1.0018, 1.2287, 1.2935, 1.3349, 1.2584, 1.3263, 1.3263,
         1.4298, 1.6684, 1.4257, 2.1328, 1.4588, 4.0464, 1.5262, 1.3591, 3.6948,
         1.1264, 1.1989, 0.9736, 1.1714, 1.3060, 1.3378, 1.3156, 1.3356, 1.3356,
         1.2965, 1.0442, 1.3520, 1.3297, 1.1354, 1.3648, 1.3813, 1.3167, 1.3279,
         1.3177, 1.4748, 1.4026, 1.3143, 1.3057, 1.4344, 1.3844, 0.5194, 1.3767,
         1.0264, 1.4097, 1.3959, 1.3735, 1.0600, 1.3939, 0.8488, 1.3714, 1.3755],
        [1.2096, 1.2386, 1.2965, 1.2746, 1.2444, 1.2152, 1.2226, 1.2075, 1.2075,
         1.2796, 1.2930, 1.2940, 1.3146, 1.2657, 1.3125, 1.2773, 1.2610, 1.2040,
         2.1478, 2.1992, 2.2978, 2.2453, 2.0469, 2.1224, 2.1531, 2.0357, 2.0357,
         1.3065, 1.2789, 1.2421, 1.2682, 1.3066, 1.2532, 1.2764, 1.2475, 1.2447,
         1.3641, 1.3976, 1.3822, 1.3621, 1.3830, 1.3714, 1.3657, 1.2850, 1.3118,
         1.3091, 1.3025, 1.2932, 1.2691, 1.2607, 1.2909, 1.3415, 1.2675, 1.2706],
        [1.2146, 1.2433, 1.2222, 1.2005, 1.2499, 1.2212, 1.2285, 1.2129, 1.2129,
         1.2812, 1.2237, 1.2974, 1.2891, 1.2665, 1.2687, 1.2791, 1.2692, 1.0685,
         1.2621, 1.2587, 1.3033, 1.2746, 1.2366, 1.2025, 1.2545, 1.2241, 1.2241,
         2.4889, 2.1210, 1.8901, 1.9990, 2.4682, 1.8976, 2.4253, 1.9043, 1.8896,
         1.3582, 1.3922, 1.3391, 1.3328, 1.3756, 1.3422, 1.3554, 1.1640, 1.3153,
         1.3609, 1.2673, 1.1738, 1.2228, 1.3520, 1.1918, 1.3950, 1.2216, 1.2725],
        [1.6063, 1.2837, 0.5421, 0.7518, 1.1017, 1.4944, 1.4320, 1.6037, 1.6037,
         1.4788, 1.2381, 1.3117, 0.8592, 1.5737, 0.1745, 1.4667, 1.5880, 1.1429,
         1.2269, 0.8007, 0.6875, 1.0144, 1.4682, 1.5556, 1.2377, 1.6102, 1.6102,
         0.6467, 0.7551, 1.5788, 1.3578, 0.7468, 1.5282, 1.0520, 1.6261, 1.5652,
         0.5373, 0.3062, 0.2563, 0.4895, 0.8268, 1.0515, 0.4370, 6.7493, 5.9091,
         0.6887, 1.1507, 1.2300, 1.4626, 0.9389, 1.4565, 0.3495, 1.4954, 1.6265],
        [1.2646, 1.2954, 1.3577, 1.3351, 1.3053, 1.2725, 1.2376, 1.2628, 1.2628,
         1.2350, 1.3348, 1.2459, 1.3690, 1.3128, 1.4179, 1.2322, 1.3158, 1.2448,
         1.3132, 1.3455, 1.3627, 1.3275, 1.2858, 1.2753, 1.2490, 1.2724, 1.2724,
         1.3296, 1.3779, 1.2914, 1.1422, 1.2652, 1.1551, 1.3292, 1.1702, 1.2944,
         1.3805, 1.1104, 1.4011, 1.3889, 1.0080, 0.9140, 1.3821, 1.3824, 0.8133,
         2.5181, 2.1212, 2.4899, 2.3282, 1.8197, 1.5838, 2.4177, 2.3243, 1.5672]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 89 : 181.2333798415444
Test loss for epoch 89 : 181.28815315939642
Test Precision for epoch 89 : 0.26153846153846155
Test Recall for epoch 89 : 0.26153846153846155
Test F1 for epoch 89 : 0.26153846153846155


theta for epoch 90 : tensor([[2.0932, 2.1190, 2.1898, 2.2510, 2.2140, 2.0985, 2.1951, 2.0914, 2.0914,
         1.2736, 1.2855, 1.2877, 1.3091, 1.2595, 1.3536, 1.2711, 1.2622, 1.2380,
         1.2500, 1.2365, 1.2484, 1.2624, 1.2250, 1.2162, 1.2429, 1.2127, 1.2127,
         1.2629, 1.3113, 1.2367, 1.2622, 1.3055, 1.2475, 1.2698, 1.1998, 1.2393,
         1.3607, 1.3938, 1.3786, 1.3684, 1.3797, 1.3155, 1.3619, 1.3818, 1.3211,
         1.3480, 1.2948, 1.2856, 1.2624, 1.3399, 1.2830, 1.3794, 1.2604, 1.2636],
        [1.2834, 1.1860, 1.0021, 1.2285, 1.2933, 1.3346, 1.2578, 1.3260, 1.3260,
         1.4319, 1.6720, 1.4283, 2.1339, 1.4616, 4.0613, 1.5281, 1.3615, 3.7124,
         1.1260, 1.1989, 0.9742, 1.1712, 1.3059, 1.3378, 1.3156, 1.3357, 1.3357,
         1.2966, 1.0442, 1.3522, 1.3300, 1.1360, 1.3649, 1.3815, 1.3167, 1.3285,
         1.3180, 1.4748, 1.4025, 1.3141, 1.3059, 1.4345, 1.3843, 0.5188, 1.3762,
         1.0258, 1.4084, 1.3945, 1.3726, 1.0590, 1.3927, 0.8487, 1.3701, 1.3744],
        [1.2088, 1.2377, 1.2953, 1.2737, 1.2436, 1.2143, 1.2219, 1.2067, 1.2067,
         1.2796, 1.2929, 1.2940, 1.3148, 1.2654, 1.3126, 1.2772, 1.2608, 1.2040,
         2.1537, 2.2048, 2.3034, 2.2511, 2.0523, 2.1280, 2.1583, 2.0410, 2.0410,
         1.3069, 1.2788, 1.2425, 1.2683, 1.3069, 1.2535, 1.2767, 1.2478, 1.2451,
         1.3645, 1.3980, 1.3825, 1.3625, 1.3836, 1.3719, 1.3660, 1.2848, 1.3118,
         1.3080, 1.3013, 1.2920, 1.2683, 1.2598, 1.2897, 1.3407, 1.2663, 1.2696],
        [1.2143, 1.2429, 1.2224, 1.2007, 1.2494, 1.2208, 1.2281, 1.2125, 1.2125,
         1.2809, 1.2240, 1.2969, 1.2896, 1.2661, 1.2689, 1.2787, 1.2687, 1.0697,
         1.2616, 1.2587, 1.3028, 1.2742, 1.2363, 1.2025, 1.2541, 1.2238, 1.2238,
         2.4936, 2.1273, 1.8954, 2.0043, 2.4733, 1.9032, 2.4302, 1.9096, 1.8952,
         1.3582, 1.3921, 1.3393, 1.3331, 1.3759, 1.3427, 1.3553, 1.1647, 1.3145,
         1.3596, 1.2665, 1.1728, 1.2216, 1.3505, 1.1914, 1.3937, 1.2200, 1.2710],
        [1.6083, 1.2858, 0.5445, 0.7541, 1.1039, 1.4967, 1.4344, 1.6057, 1.6057,
         1.4801, 1.2386, 1.3130, 0.8607, 1.5751, 0.1778, 1.4682, 1.5896, 1.1432,
         1.2294, 0.8029, 0.6901, 1.0169, 1.4704, 1.5573, 1.2399, 1.6122, 1.6122,
         0.6489, 0.7577, 1.5809, 1.3604, 0.7478, 1.5288, 1.0538, 1.6284, 1.5671,
         0.5309, 0.2999, 0.2506, 0.4833, 0.8167, 1.0380, 0.4309, 6.8093, 5.9515,
         0.6890, 1.1505, 1.2300, 1.4626, 0.9392, 1.4565, 0.3506, 1.4963, 1.6274],
        [1.2643, 1.2951, 1.3571, 1.3346, 1.3045, 1.2720, 1.2371, 1.2624, 1.2624,
         1.2340, 1.3347, 1.2456, 1.3686, 1.3118, 1.4178, 1.2313, 1.3149, 1.2444,
         1.3127, 1.3447, 1.3618, 1.3268, 1.2854, 1.2750, 1.2484, 1.2721, 1.2721,
         1.3294, 1.3781, 1.2911, 1.1419, 1.2667, 1.1568, 1.3292, 1.1700, 1.2942,
         1.3800, 1.1098, 1.4006, 1.3884, 1.0073, 0.9132, 1.3816, 1.3837, 0.8121,
         2.5227, 2.1258, 2.4976, 2.3323, 1.8252, 1.5881, 2.4214, 2.3326, 1.5714]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 90 : 181.21566375942746
Test loss for epoch 90 : 181.270304045817
Test Precision for epoch 90 : 0.26153846153846155
Test Recall for epoch 90 : 0.26153846153846155
Test F1 for epoch 90 : 0.26153846153846155


theta for epoch 91 : tensor([[2.0981, 2.1243, 2.1952, 2.2567, 2.2198, 2.1035, 2.2005, 2.0963, 2.0963,
         1.2736, 1.2857, 1.2879, 1.3095, 1.2593, 1.3543, 1.2712, 1.2620, 1.2383,
         1.2492, 1.2357, 1.2474, 1.2616, 1.2241, 1.2153, 1.2420, 1.2117, 1.2117,
         1.2630, 1.3111, 1.2371, 1.2624, 1.3055, 1.2478, 1.2700, 1.2001, 1.2396,
         1.3613, 1.3945, 1.3791, 1.3689, 1.3804, 1.3162, 1.3625, 1.3816, 1.3211,
         1.3471, 1.2939, 1.2846, 1.2619, 1.3388, 1.2821, 1.3786, 1.2595, 1.2629],
        [1.2827, 1.1856, 1.0022, 1.2281, 1.2929, 1.3339, 1.2570, 1.3253, 1.3253,
         1.4339, 1.6757, 1.4309, 2.1352, 1.4643, 4.0761, 1.5301, 1.3639, 3.7301,
         1.1253, 1.1986, 0.9745, 1.1707, 1.3055, 1.3376, 1.3153, 1.3354, 1.3354,
         1.2968, 1.0442, 1.3524, 1.3302, 1.1364, 1.3650, 1.3817, 1.3167, 1.3291,
         1.3183, 1.4749, 1.4025, 1.3140, 1.3062, 1.4346, 1.3842, 0.5182, 1.3757,
         1.0255, 1.4073, 1.3934, 1.3719, 1.0581, 1.3916, 0.8488, 1.3689, 1.3734],
        [1.2079, 1.2366, 1.2940, 1.2727, 1.2426, 1.2134, 1.2210, 1.2058, 1.2058,
         1.2797, 1.2930, 1.2941, 1.3151, 1.2653, 1.3129, 1.2773, 1.2606, 1.2042,
         2.1593, 2.2103, 2.3088, 2.2566, 2.0574, 2.1333, 2.1633, 2.0460, 2.0460,
         1.3072, 1.2787, 1.2429, 1.2685, 1.3071, 1.2538, 1.2769, 1.2481, 1.2454,
         1.3649, 1.3985, 1.3830, 1.3630, 1.3842, 1.3725, 1.3665, 1.2846, 1.3119,
         1.3072, 1.3003, 1.2910, 1.2677, 1.2591, 1.2888, 1.3400, 1.2653, 1.2687],
        [1.2138, 1.2424, 1.2225, 1.2007, 1.2488, 1.2202, 1.2275, 1.2120, 1.2120,
         1.2807, 1.2244, 1.2966, 1.2902, 1.2657, 1.2691, 1.2784, 1.2684, 1.0709,
         1.2610, 1.2585, 1.3023, 1.2735, 1.2358, 1.2023, 1.2535, 1.2233, 1.2233,
         2.4983, 2.1335, 1.9008, 2.0097, 2.4784, 1.9087, 2.4350, 1.9149, 1.9007,
         1.3581, 1.3920, 1.3396, 1.3335, 1.3763, 1.3433, 1.3552, 1.1655, 1.3137,
         1.3584, 1.2659, 1.1721, 1.2206, 1.3493, 1.1912, 1.3926, 1.2186, 1.2697],
        [1.6104, 1.2880, 0.5470, 0.7564, 1.1061, 1.4989, 1.4368, 1.6077, 1.6077,
         1.4818, 1.2395, 1.3146, 0.8626, 1.5768, 0.1813, 1.4700, 1.5913, 1.1438,
         1.2318, 0.8052, 0.6928, 1.0194, 1.4725, 1.5589, 1.2420, 1.6142, 1.6142,
         0.6512, 0.7605, 1.5831, 1.3630, 0.7491, 1.5296, 1.0558, 1.6306, 1.5691,
         0.5243, 0.2934, 0.2448, 0.4770, 0.8066, 1.0245, 0.4246, 6.8689, 5.9931,
         0.6902, 1.1509, 1.2305, 1.4630, 0.9402, 1.4569, 0.3525, 1.4977, 1.6286],
        [1.2632, 1.2940, 1.3558, 1.3334, 1.3030, 1.2707, 1.2359, 1.2613, 1.2613,
         1.2324, 1.3340, 1.2447, 1.3676, 1.3102, 1.4172, 1.2297, 1.3133, 1.2434,
         1.3116, 1.3433, 1.3601, 1.3254, 1.2843, 1.2738, 1.2470, 1.2710, 1.2710,
         1.3287, 1.3778, 1.2905, 1.1411, 1.2676, 1.1579, 1.3288, 1.1694, 1.2936,
         1.3793, 1.1089, 1.4000, 1.3877, 1.0062, 0.9120, 1.3809, 1.3845, 0.8103,
         2.5282, 2.1316, 2.5063, 2.3375, 1.8316, 1.5934, 2.4262, 2.3420, 1.5766]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 91 : 181.19835517312325
Test loss for epoch 91 : 181.2523442772377
Test Precision for epoch 91 : 0.26153846153846155
Test Recall for epoch 91 : 0.26153846153846155
Test F1 for epoch 91 : 0.26153846153846155


theta for epoch 92 : tensor([[2.1031, 2.1296, 2.2007, 2.2623, 2.2256, 2.1086, 2.2060, 2.1013, 2.1013,
         1.2734, 1.2856, 1.2878, 1.3095, 1.2589, 1.3547, 1.2709, 1.2616, 1.2383,
         1.2487, 1.2351, 1.2465, 1.2610, 1.2235, 1.2146, 1.2415, 1.2111, 1.2111,
         1.2623, 1.3102, 1.2368, 1.2617, 1.3048, 1.2474, 1.2695, 1.1995, 1.2392,
         1.3620, 1.3952, 1.3799, 1.3695, 1.3812, 1.3169, 1.3632, 1.3814, 1.3212,
         1.3467, 1.2934, 1.2842, 1.2618, 1.3381, 1.2818, 1.3783, 1.2590, 1.2626],
        [1.2823, 1.1856, 1.0026, 1.2280, 1.2930, 1.3335, 1.2565, 1.3249, 1.3249,
         1.4356, 1.6789, 1.4330, 2.1364, 1.4667, 4.0906, 1.5316, 1.3658, 3.7474,
         1.1249, 1.1985, 0.9748, 1.1704, 1.3052, 1.3374, 1.3152, 1.3352, 1.3352,
         1.2963, 1.0435, 1.3520, 1.3298, 1.1362, 1.3645, 1.3812, 1.3161, 1.3290,
         1.3187, 1.4752, 1.4026, 1.3140, 1.3066, 1.4349, 1.3843, 0.5177, 1.3755,
         1.0257, 1.4068, 1.3929, 1.3718, 1.0579, 1.3911, 0.8494, 1.3683, 1.3730],
        [1.2075, 1.2360, 1.2931, 1.2720, 1.2421, 1.2129, 1.2206, 1.2053, 1.2053,
         1.2794, 1.2928, 1.2939, 1.3152, 1.2649, 1.3128, 1.2770, 1.2602, 1.2042,
         2.1649, 2.2158, 2.3143, 2.2623, 2.0626, 2.1387, 2.1684, 2.0511, 2.0511,
         1.3066, 1.2778, 1.2425, 1.2678, 1.3066, 1.2533, 1.2764, 1.2475, 1.2449,
         1.3655, 1.3991, 1.3836, 1.3636, 1.3849, 1.3732, 1.3670, 1.2845, 1.3121,
         1.3068, 1.2998, 1.2904, 1.2676, 1.2588, 1.2883, 1.3398, 1.2647, 1.2684],
        [1.2135, 1.2421, 1.2227, 1.2009, 1.2484, 1.2199, 1.2272, 1.2117, 1.2117,
         1.2803, 1.2247, 1.2961, 1.2906, 1.2651, 1.2692, 1.2780, 1.2678, 1.0718,
         1.2606, 1.2584, 1.3018, 1.2731, 1.2354, 1.2023, 1.2530, 1.2229, 1.2229,
         2.5027, 2.1396, 1.9059, 2.0148, 2.4832, 1.9140, 2.4397, 1.9200, 1.9060,
         1.3582, 1.3920, 1.3401, 1.3339, 1.3766, 1.3439, 1.3552, 1.1663, 1.3130,
         1.3577, 1.2657, 1.1717, 1.2200, 1.3484, 1.1914, 1.3918, 1.2177, 1.2689],
        [1.6124, 1.2901, 0.5492, 0.7585, 1.1081, 1.5012, 1.4390, 1.6097, 1.6097,
         1.4830, 1.2399, 1.3158, 0.8640, 1.5779, 0.1843, 1.4712, 1.5926, 1.1439,
         1.2340, 0.8072, 0.6953, 1.0217, 1.4744, 1.5605, 1.2440, 1.6160, 1.6160,
         0.6527, 0.7625, 1.5845, 1.3648, 0.7498, 1.5297, 1.0569, 1.6321, 1.5703,
         0.5181, 0.2871, 0.2392, 0.4710, 0.7972, 1.0117, 0.4186, 6.9284, 6.0344,
         0.6916, 1.1516, 1.2313, 1.4638, 0.9415, 1.4574, 0.3545, 1.4992, 1.6300],
        [1.2623, 1.2931, 1.3548, 1.3325, 1.3018, 1.2696, 1.2349, 1.2604, 1.2604,
         1.2305, 1.3329, 1.2434, 1.3662, 1.3084, 1.4164, 1.2279, 1.3115, 1.2421,
         1.3106, 1.3420, 1.3586, 1.3242, 1.2833, 1.2729, 1.2459, 1.2701, 1.2701,
         1.3275, 1.3768, 1.2894, 1.1397, 1.2679, 1.1583, 1.3278, 1.1682, 1.2924,
         1.3787, 1.1082, 1.3995, 1.3872, 1.0052, 0.9109, 1.3804, 1.3852, 0.8086,
         2.5340, 2.1375, 2.5153, 2.3428, 1.8383, 1.5989, 2.4312, 2.3515, 1.5820]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 92 : 181.18142918629343
Test loss for epoch 92 : 181.2347159993045
Test Precision for epoch 92 : 0.26153846153846155
Test Recall for epoch 92 : 0.26153846153846155
Test F1 for epoch 92 : 0.26153846153846155


theta for epoch 93 : tensor([[2.1082, 2.1350, 2.2063, 2.2682, 2.2315, 2.1138, 2.2116, 2.1064, 2.1064,
         1.2732, 1.2855, 1.2877, 1.3096, 1.2584, 1.3550, 1.2707, 1.2611, 1.2384,
         1.2483, 1.2346, 1.2459, 1.2606, 1.2231, 1.2143, 1.2411, 1.2107, 1.2107,
         1.2612, 1.3089, 1.2360, 1.2608, 1.3037, 1.2465, 1.2687, 1.1986, 1.2383,
         1.3626, 1.3958, 1.3805, 1.3701, 1.3819, 1.3176, 1.3639, 1.3811, 1.3211,
         1.3464, 1.2932, 1.2839, 1.2618, 1.3376, 1.2815, 1.3781, 1.2587, 1.2624],
        [1.2819, 1.1856, 1.0029, 1.2279, 1.2930, 1.3332, 1.2560, 1.3245, 1.3245,
         1.4374, 1.6822, 1.4353, 2.1379, 1.4692, 4.1053, 1.5333, 1.3680, 3.7649,
         1.1245, 1.1985, 0.9750, 1.1702, 1.3049, 1.3373, 1.3151, 1.3351, 1.3351,
         1.2955, 1.0426, 1.3513, 1.3290, 1.1355, 1.3637, 1.3804, 1.3152, 1.3286,
         1.3191, 1.4753, 1.4027, 1.3140, 1.3069, 1.4350, 1.3843, 0.5172, 1.3751,
         1.0260, 1.4064, 1.3925, 1.3717, 1.0577, 1.3907, 0.8500, 1.3678, 1.3727],
        [1.2072, 1.2355, 1.2922, 1.2713, 1.2417, 1.2127, 1.2203, 1.2051, 1.2051,
         1.2792, 1.2925, 1.2937, 1.3152, 1.2644, 1.3127, 1.2767, 1.2596, 1.2041,
         2.1706, 2.2216, 2.3201, 2.2682, 2.0679, 2.1443, 2.1737, 2.0563, 2.0563,
         1.3057, 1.2765, 1.2417, 1.2668, 1.3056, 1.2524, 1.2755, 1.2466, 1.2441,
         1.3659, 1.3996, 1.3840, 1.3641, 1.3854, 1.3737, 1.3675, 1.2842, 1.3122,
         1.3066, 1.2994, 1.2900, 1.2675, 1.2586, 1.2880, 1.3396, 1.2643, 1.2681],
        [1.2131, 1.2417, 1.2230, 1.2011, 1.2479, 1.2194, 1.2267, 1.2113, 1.2113,
         1.2798, 1.2248, 1.2955, 1.2907, 1.2644, 1.2691, 1.2774, 1.2670, 1.0727,
         1.2601, 1.2583, 1.3014, 1.2726, 1.2350, 1.2022, 1.2525, 1.2225, 1.2225,
         2.5072, 2.1458, 1.9112, 2.0201, 2.4881, 1.9195, 2.4444, 1.9253, 1.9115,
         1.3580, 1.3919, 1.3404, 1.3342, 1.3768, 1.3444, 1.3551, 1.1670, 1.3122,
         1.3571, 1.2656, 1.1715, 1.2195, 1.3477, 1.1917, 1.3911, 1.2168, 1.2680],
        [1.6142, 1.2919, 0.5509, 0.7602, 1.1096, 1.5031, 1.4410, 1.6115, 1.6115,
         1.4839, 1.2399, 1.3166, 0.8648, 1.5787, 0.1867, 1.4721, 1.5935, 1.1435,
         1.2358, 0.8088, 0.6972, 1.0235, 1.4762, 1.5618, 1.2457, 1.6177, 1.6177,
         0.6536, 0.7640, 1.5855, 1.3662, 0.7500, 1.5296, 1.0574, 1.6332, 1.5711,
         0.5124, 0.2813, 0.2340, 0.4654, 0.7884, 0.9996, 0.4130, 6.9880, 6.0756,
         0.6927, 1.1520, 1.2318, 1.4643, 0.9424, 1.4577, 0.3561, 1.5003, 1.6312],
        [1.2623, 1.2931, 1.3546, 1.3325, 1.3014, 1.2693, 1.2347, 1.2603, 1.2603,
         1.2296, 1.3327, 1.2430, 1.3657, 1.3074, 1.4164, 1.2270, 1.3105, 1.2417,
         1.3104, 1.3416, 1.3578, 1.3237, 1.2832, 1.2727, 1.2455, 1.2699, 1.2699,
         1.3265, 1.3761, 1.2885, 1.1386, 1.2683, 1.1589, 1.3270, 1.1674, 1.2915,
         1.3785, 1.1079, 1.3994, 1.3870, 1.0046, 0.9102, 1.3802, 1.3860, 0.8073,
         2.5390, 2.1424, 2.5232, 2.3471, 1.8440, 1.6033, 2.4353, 2.3602, 1.5864]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 93 : 181.1647541035009
Test loss for epoch 93 : 181.21805657016148
Test Precision for epoch 93 : 0.26153846153846155
Test Recall for epoch 93 : 0.26153846153846155
Test F1 for epoch 93 : 0.26153846153846155


theta for epoch 94 : tensor([[2.1133, 2.1404, 2.2119, 2.2740, 2.2373, 2.1190, 2.2171, 2.1115, 2.1115,
         1.2730, 1.2855, 1.2877, 1.3097, 1.2581, 1.3554, 1.2706, 1.2608, 1.2385,
         1.2475, 1.2337, 1.2449, 1.2598, 1.2224, 1.2136, 1.2404, 1.2100, 1.2100,
         1.2606, 1.3081, 1.2356, 1.2602, 1.3031, 1.2461, 1.2682, 1.1981, 1.2379,
         1.3628, 1.3961, 1.3808, 1.3702, 1.3822, 1.3179, 1.3641, 1.3804, 1.3208,
         1.3463, 1.2930, 1.2837, 1.2620, 1.3372, 1.2813, 1.3779, 1.2585, 1.2623],
        [1.2810, 1.1850, 1.0026, 1.2273, 1.2924, 1.3322, 1.2550, 1.3236, 1.3236,
         1.4397, 1.6859, 1.4380, 2.1400, 1.4720, 4.1204, 1.5355, 1.3705, 3.7829,
         1.1237, 1.1980, 0.9747, 1.1695, 1.3042, 1.3367, 1.3146, 1.3345, 1.3345,
         1.2951, 1.0419, 1.3509, 1.3286, 1.1351, 1.3632, 1.3800, 1.3146, 1.3284,
         1.3191, 1.4750, 1.4022, 1.3135, 1.3068, 1.4347, 1.3838, 0.5162, 1.3744,
         1.0263, 1.4061, 1.3921, 1.3716, 1.0575, 1.3903, 0.8506, 1.3673, 1.3723],
        [1.2066, 1.2346, 1.2909, 1.2703, 1.2408, 1.2120, 1.2196, 1.2045, 1.2045,
         1.2790, 1.2924, 1.2937, 1.3153, 1.2641, 1.3127, 1.2766, 1.2593, 1.2041,
         2.1763, 2.2274, 2.3259, 2.2741, 2.0731, 2.1498, 2.1790, 2.0615, 2.0615,
         1.3052, 1.2757, 1.2413, 1.2662, 1.3050, 1.2519, 1.2750, 1.2461, 1.2436,
         1.3660, 1.3997, 1.3842, 1.3642, 1.3856, 1.3739, 1.3676, 1.2836, 1.3121,
         1.3065, 1.2992, 1.2898, 1.2675, 1.2585, 1.2877, 1.3396, 1.2640, 1.2679],
        [1.2122, 1.2407, 1.2227, 1.2008, 1.2469, 1.2184, 1.2257, 1.2104, 1.2104,
         1.2791, 1.2247, 1.2947, 1.2907, 1.2636, 1.2688, 1.2766, 1.2661, 1.0734,
         1.2591, 1.2577, 1.3004, 1.2716, 1.2340, 1.2015, 1.2515, 1.2215, 1.2215,
         2.5121, 2.1526, 1.9171, 2.0259, 2.4934, 1.9255, 2.4495, 1.9311, 1.9174,
         1.3575, 1.3913, 1.3403, 1.3340, 1.3765, 1.3444, 1.3546, 1.1673, 1.3109,
         1.3564, 1.2655, 1.1712, 1.2189, 1.3469, 1.1920, 1.3904, 1.2159, 1.2672],
        [1.6158, 1.2934, 0.5524, 0.7616, 1.1108, 1.5048, 1.4426, 1.6130, 1.6130,
         1.4849, 1.2401, 1.3175, 0.8657, 1.5796, 0.1890, 1.4731, 1.5945, 1.1431,
         1.2374, 0.8102, 0.6990, 1.0251, 1.4778, 1.5630, 1.2471, 1.6192, 1.6192,
         0.6547, 0.7657, 1.5867, 1.3678, 0.7505, 1.5298, 1.0581, 1.6345, 1.5721,
         0.5066, 0.2754, 0.2287, 0.4598, 0.7798, 0.9879, 0.4073, 7.0473, 6.1162,
         0.6939, 1.1524, 1.2323, 1.4649, 0.9434, 1.4578, 0.3578, 1.5014, 1.6323],
        [1.2625, 1.2934, 1.3549, 1.3329, 1.3014, 1.2694, 1.2348, 1.2605, 1.2605,
         1.2297, 1.3334, 1.2435, 1.3662, 1.3074, 1.4172, 1.2271, 1.3105, 1.2423,
         1.3107, 1.3417, 1.3574, 1.3238, 1.2835, 1.2730, 1.2457, 1.2702, 1.2702,
         1.3264, 1.3761, 1.2885, 1.1384, 1.2694, 1.1601, 1.3270, 1.1674, 1.2914,
         1.3782, 1.1076, 1.3993, 1.3867, 1.0041, 0.9096, 1.3801, 1.3866, 0.8062,
         2.5431, 2.1466, 2.5304, 2.3507, 1.8489, 1.6069, 2.4387, 2.3680, 1.5899]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 94 : 181.14824753493616
Test loss for epoch 94 : 181.2020571360275
Test Precision for epoch 94 : 0.26153846153846155
Test Recall for epoch 94 : 0.26153846153846155
Test F1 for epoch 94 : 0.26153846153846155


theta for epoch 95 : tensor([[2.1188, 2.1461, 2.2177, 2.2801, 2.2435, 2.1245, 2.2230, 2.1170, 2.1170,
         1.2724, 1.2850, 1.2872, 1.3093, 1.2573, 1.3553, 1.2700, 1.2600, 1.2381,
         1.2464, 1.2325, 1.2436, 1.2587, 1.2215, 1.2127, 1.2395, 1.2091, 1.2091,
         1.2602, 1.3076, 1.2354, 1.2598, 1.3027, 1.2458, 1.2679, 1.1977, 1.2376,
         1.3626, 1.3960, 1.3807, 1.3700, 1.3820, 1.3178, 1.3641, 1.3794, 1.3201,
         1.3464, 1.2931, 1.2837, 1.2623, 1.3371, 1.2814, 1.3781, 1.2585, 1.2624],
        [1.2800, 1.1843, 1.0021, 1.2265, 1.2919, 1.3312, 1.2539, 1.3226, 1.3226,
         1.4418, 1.6893, 1.4405, 2.1422, 1.4747, 4.1354, 1.5376, 1.3729, 3.8007,
         1.1228, 1.1974, 0.9743, 1.1688, 1.3034, 1.3360, 1.3139, 1.3337, 1.3337,
         1.2950, 1.0416, 1.3507, 1.3285, 1.1350, 1.3631, 1.3799, 1.3144, 1.3286,
         1.3187, 1.4743, 1.4015, 1.3127, 1.3064, 1.4341, 1.3831, 0.5149, 1.3735,
         1.0268, 1.4062, 1.3922, 1.3719, 1.0576, 1.3903, 0.8515, 1.3672, 1.3723],
        [1.2058, 1.2336, 1.2895, 1.2691, 1.2399, 1.2113, 1.2187, 1.2038, 1.2038,
         1.2785, 1.2919, 1.2933, 1.3150, 1.2634, 1.3123, 1.2760, 1.2585, 1.2038,
         2.1821, 2.2332, 2.3318, 2.2801, 2.0785, 2.1553, 2.1844, 2.0667, 2.0667,
         1.3049, 1.2752, 1.2411, 1.2659, 1.3046, 1.2517, 1.2748, 1.2459, 1.2434,
         1.3658, 1.3996, 1.3840, 1.3641, 1.3854, 1.3738, 1.3675, 1.2828, 1.3117,
         1.3067, 1.2993, 1.2898, 1.2679, 1.2586, 1.2877, 1.3398, 1.2640, 1.2680],
        [1.2111, 1.2396, 1.2222, 1.2003, 1.2457, 1.2172, 1.2246, 1.2092, 1.2092,
         1.2779, 1.2242, 1.2935, 1.2902, 1.2623, 1.2680, 1.2754, 1.2648, 1.0737,
         1.2580, 1.2569, 1.2993, 1.2705, 1.2329, 1.2007, 1.2504, 1.2203, 1.2203,
         2.5173, 2.1595, 1.9231, 2.0320, 2.4990, 1.9317, 2.4549, 1.9371, 1.9236,
         1.3565, 1.3905, 1.3399, 1.3335, 1.3759, 1.3442, 1.3537, 1.1673, 1.3094,
         1.3559, 1.2656, 1.1711, 1.2185, 1.3463, 1.1925, 1.3899, 1.2151, 1.2665],
        [1.6174, 1.2950, 0.5540, 0.7631, 1.1123, 1.5066, 1.4444, 1.6146, 1.6146,
         1.4858, 1.2402, 1.3184, 0.8667, 1.5804, 0.1913, 1.4740, 1.5954, 1.1427,
         1.2391, 0.8117, 0.7009, 1.0269, 1.4794, 1.5642, 1.2487, 1.6207, 1.6207,
         0.6563, 0.7678, 1.5883, 1.3697, 0.7515, 1.5305, 1.0591, 1.6362, 1.5735,
         0.5006, 0.2691, 0.2231, 0.4538, 0.7711, 0.9761, 0.4013, 7.1060, 6.1559,
         0.6960, 1.1536, 1.2335, 1.4660, 0.9452, 1.4585, 0.3603, 1.5030, 1.6338],
        [1.2627, 1.2936, 1.3551, 1.3331, 1.3013, 1.2693, 1.2349, 1.2606, 1.2606,
         1.2294, 1.3336, 1.2437, 1.3662, 1.3069, 1.4176, 1.2269, 1.3100, 1.2424,
         1.3109, 1.3417, 1.3570, 1.3237, 1.2837, 1.2732, 1.2457, 1.2704, 1.2704,
         1.3265, 1.3762, 1.2887, 1.1383, 1.2706, 1.1615, 1.3273, 1.1676, 1.2916,
         1.3776, 1.1070, 1.3988, 1.3861, 1.0032, 0.9087, 1.3796, 1.3866, 0.8047,
         2.5476, 2.1510, 2.5378, 2.3544, 1.8540, 1.6107, 2.4423, 2.3761, 1.5937]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 95 : 181.13210610636503
Test loss for epoch 95 : 181.1860578963352
Test Precision for epoch 95 : 0.26153846153846155
Test Recall for epoch 95 : 0.26153846153846155
Test F1 for epoch 95 : 0.26153846153846155


theta for epoch 96 : tensor([[2.1243, 2.1519, 2.2237, 2.2864, 2.2499, 2.1301, 2.2291, 2.1225, 2.1225,
         1.2716, 1.2844, 1.2866, 1.3087, 1.2564, 1.3549, 1.2692, 1.2591, 1.2376,
         1.2457, 1.2316, 1.2427, 1.2579, 1.2209, 1.2121, 1.2388, 1.2086, 1.2086,
         1.2594, 1.3067, 1.2347, 1.2590, 1.3019, 1.2451, 1.2672, 1.1969, 1.2369,
         1.3626, 1.3961, 1.3807, 1.3699, 1.3820, 1.3178, 1.3641, 1.3786, 1.3196,
         1.3464, 1.2932, 1.2838, 1.2625, 1.3369, 1.2814, 1.3781, 1.2585, 1.2624],
        [1.2792, 1.1838, 1.0017, 1.2260, 1.2915, 1.3303, 1.2530, 1.3217, 1.3217,
         1.4437, 1.6924, 1.4428, 2.1443, 1.4771, 4.1503, 1.5395, 1.3751, 3.8184,
         1.1223, 1.1971, 0.9740, 1.1684, 1.3028, 1.3355, 1.3135, 1.3332, 1.3332,
         1.2946, 1.0410, 1.3503, 1.3281, 1.1345, 1.3626, 1.3795, 1.3139, 1.3285,
         1.3186, 1.4739, 1.4010, 1.3120, 1.3061, 1.4337, 1.3825, 0.5139, 1.3728,
         1.0275, 1.4064, 1.3923, 1.3722, 1.0578, 1.3903, 0.8525, 1.3672, 1.3724],
        [1.2053, 1.2327, 1.2884, 1.2681, 1.2391, 1.2108, 1.2180, 1.2033, 1.2033,
         1.2778, 1.2912, 1.2927, 1.3145, 1.2626, 1.3118, 1.2753, 1.2576, 1.2034,
         2.1880, 2.2393, 2.3379, 2.2863, 2.0839, 2.1611, 2.1901, 2.0721, 2.0721,
         1.3042, 1.2743, 1.2405, 1.2652, 1.3039, 1.2511, 1.2742, 1.2453, 1.2428,
         1.3657, 1.3996, 1.3840, 1.3641, 1.3853, 1.3738, 1.3674, 1.2820, 1.3114,
         1.3069, 1.2994, 1.2898, 1.2681, 1.2588, 1.2877, 1.3399, 1.2640, 1.2680],
        [1.2102, 1.2388, 1.2221, 1.2001, 1.2448, 1.2163, 1.2237, 1.2084, 1.2084,
         1.2769, 1.2238, 1.2925, 1.2898, 1.2611, 1.2674, 1.2744, 1.2636, 1.0741,
         1.2572, 1.2565, 1.2986, 1.2697, 1.2321, 1.2002, 1.2496, 1.2195, 1.2195,
         2.5221, 2.1662, 1.9289, 2.0378, 2.5042, 1.9376, 2.4600, 1.9429, 1.9296,
         1.3558, 1.3899, 1.3397, 1.3333, 1.3755, 1.3441, 1.3531, 1.1676, 1.3081,
         1.3556, 1.2658, 1.1711, 1.2183, 1.3459, 1.1932, 1.3896, 1.2146, 1.2660],
        [1.6192, 1.2967, 0.5557, 0.7648, 1.1138, 1.5084, 1.4462, 1.6163, 1.6163,
         1.4867, 1.2404, 1.3193, 0.8677, 1.5811, 0.1936, 1.4749, 1.5963, 1.1422,
         1.2410, 0.8134, 0.7030, 1.0287, 1.4813, 1.5656, 1.2505, 1.6225, 1.6225,
         0.6576, 0.7697, 1.5896, 1.3714, 0.7525, 1.5311, 1.0599, 1.6375, 1.5746,
         0.4946, 0.2630, 0.2175, 0.4479, 0.7627, 0.9647, 0.3954, 7.1644, 6.1950,
         0.6984, 1.1550, 1.2350, 1.4673, 0.9472, 1.4592, 0.3630, 1.5046, 1.6354],
        [1.2625, 1.2935, 1.3550, 1.3331, 1.3010, 1.2689, 1.2345, 1.2604, 1.2604,
         1.2286, 1.3333, 1.2432, 1.3656, 1.3060, 1.4175, 1.2262, 1.3091, 1.2420,
         1.3109, 1.3416, 1.3564, 1.3235, 1.2837, 1.2731, 1.2455, 1.2703, 1.2703,
         1.3261, 1.3759, 1.2884, 1.1377, 1.2712, 1.1621, 1.3271, 1.1673, 1.2912,
         1.3770, 1.1062, 1.3984, 1.3855, 1.0021, 0.9076, 1.3791, 1.3864, 0.8030,
         2.5528, 2.1561, 2.5459, 2.3588, 1.8597, 1.6151, 2.4467, 2.3848, 1.5980]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 96 : 181.1163421052276
Test loss for epoch 96 : 181.17011523843186
Test Precision for epoch 96 : 0.26153846153846155
Test Recall for epoch 96 : 0.26153846153846155
Test F1 for epoch 96 : 0.26153846153846155


theta for epoch 97 : tensor([[2.1296, 2.1574, 2.2293, 2.2923, 2.2558, 2.1354, 2.2348, 2.1278, 2.1278,
         1.2714, 1.2843, 1.2866, 1.3087, 1.2562, 1.3551, 1.2691, 1.2588, 1.2377,
         1.2451, 1.2308, 1.2420, 1.2573, 1.2205, 1.2118, 1.2384, 1.2083, 1.2083,
         1.2584, 1.3057, 1.2338, 1.2581, 1.3010, 1.2442, 1.2663, 1.1959, 1.2360,
         1.3631, 1.3966, 1.3813, 1.3704, 1.3825, 1.3183, 1.3647, 1.3782, 1.3195,
         1.3460, 1.2928, 1.2834, 1.2623, 1.3363, 1.2809, 1.3776, 1.2580, 1.2620],
        [1.2784, 1.1834, 1.0013, 1.2254, 1.2912, 1.3294, 1.2521, 1.3208, 1.3208,
         1.4458, 1.6957, 1.4453, 2.1467, 1.4797, 4.1654, 1.5416, 1.3774, 3.8364,
         1.1217, 1.1968, 0.9737, 1.1679, 1.3021, 1.3349, 1.3130, 1.3325, 1.3325,
         1.2941, 1.0402, 1.3496, 1.3275, 1.1338, 1.3620, 1.3789, 1.3131, 1.3280,
         1.3188, 1.4738, 1.4008, 1.3119, 1.3063, 1.4337, 1.3823, 0.5132, 1.3725,
         1.0274, 1.4060, 1.3919, 1.3719, 1.0574, 1.3898, 0.8527, 1.3666, 1.3719],
        [1.2049, 1.2322, 1.2875, 1.2673, 1.2385, 1.2104, 1.2176, 1.2030, 1.2030,
         1.2776, 1.2910, 1.2926, 1.3145, 1.2623, 1.3118, 1.2752, 1.2572, 1.2035,
         2.1937, 2.2452, 2.3439, 2.2923, 2.0892, 2.1666, 2.1955, 2.0773, 2.0773,
         1.3033, 1.2733, 1.2397, 1.2643, 1.3029, 1.2503, 1.2734, 1.2444, 1.2419,
         1.3660, 1.4000, 1.3845, 1.3645, 1.3857, 1.3742, 1.3679, 1.2818, 1.3116,
         1.3065, 1.2989, 1.2894, 1.2679, 1.2583, 1.2872, 1.3394, 1.2634, 1.2676],
        [1.2097, 1.2383, 1.2223, 1.2002, 1.2443, 1.2157, 1.2231, 1.2078, 1.2078,
         1.2766, 1.2242, 1.2921, 1.2901, 1.2607, 1.2675, 1.2740, 1.2632, 1.0753,
         1.2567, 1.2564, 1.2982, 1.2693, 1.2316, 1.2000, 1.2492, 1.2190, 1.2190,
         2.5266, 2.1726, 1.9344, 2.0433, 2.5090, 1.9432, 2.4647, 1.9483, 1.9352,
         1.3556, 1.3897, 1.3401, 1.3335, 1.3755, 1.3446, 1.3530, 1.1683, 1.3074,
         1.3551, 1.2659, 1.1710, 1.2178, 1.3452, 1.1937, 1.3889, 1.2139, 1.2653],
        [1.6207, 1.2982, 0.5572, 0.7662, 1.1150, 1.5100, 1.4477, 1.6178, 1.6178,
         1.4878, 1.2407, 1.3203, 0.8687, 1.5821, 0.1958, 1.4759, 1.5973, 1.1419,
         1.2425, 0.8149, 0.7048, 1.0303, 1.4829, 1.5667, 1.2520, 1.6240, 1.6240,
         0.6585, 0.7712, 1.5905, 1.3726, 0.7531, 1.5314, 1.0602, 1.6385, 1.5753,
         0.4890, 0.2572, 0.2123, 0.4425, 0.7549, 0.9541, 0.3898, 7.2228, 6.2339,
         0.7001, 1.1557, 1.2357, 1.4679, 0.9486, 1.4591, 0.3650, 1.5055, 1.6362],
        [1.2619, 1.2930, 1.3547, 1.3327, 1.3003, 1.2682, 1.2339, 1.2598, 1.2598,
         1.2281, 1.3331, 1.2429, 1.3653, 1.3053, 1.4175, 1.2257, 1.3084, 1.2417,
         1.3106, 1.3413, 1.3556, 1.3231, 1.2833, 1.2728, 1.2451, 1.2699, 1.2699,
         1.3254, 1.3750, 1.2877, 1.1367, 1.2712, 1.1621, 1.3265, 1.1665, 1.2905,
         1.3768, 1.1057, 1.3983, 1.3853, 1.0012, 0.9067, 1.3790, 1.3865, 0.8015,
         2.5582, 2.1613, 2.5542, 2.3634, 1.8655, 1.6196, 2.4513, 2.3937, 1.6025]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 97 : 181.10071533421493
Test loss for epoch 97 : 181.15458534961053
Test Precision for epoch 97 : 0.26153846153846155
Test Recall for epoch 97 : 0.26153846153846155
Test F1 for epoch 97 : 0.26153846153846155


theta for epoch 98 : tensor([[2.1347, 2.1628, 2.2348, 2.2981, 2.2617, 2.1406, 2.2404, 2.1329, 2.1329,
         1.2713, 1.2844, 1.2866, 1.3088, 1.2560, 1.3553, 1.2691, 1.2587, 1.2379,
         1.2445, 1.2301, 1.2414, 1.2567, 1.2201, 1.2115, 1.2380, 1.2080, 1.2080,
         1.2580, 1.3052, 1.2333, 1.2576, 1.3006, 1.2438, 1.2659, 1.1953, 1.2355,
         1.3637, 1.3973, 1.3821, 1.3710, 1.3831, 1.3190, 1.3655, 1.3781, 1.3198,
         1.3450, 1.2919, 1.2825, 1.2615, 1.3351, 1.2799, 1.3766, 1.2570, 1.2611],
        [1.2778, 1.1831, 1.0010, 1.2250, 1.2911, 1.3288, 1.2515, 1.3201, 1.3201,
         1.4478, 1.6988, 1.4476, 2.1492, 1.4822, 4.1804, 1.5437, 1.3797, 3.8543,
         1.1212, 1.1964, 0.9733, 1.1674, 1.3014, 1.3343, 1.3125, 1.3318, 1.3318,
         1.2940, 1.0399, 1.3493, 1.3272, 1.1335, 1.3617, 1.3787, 1.3127, 1.3280,
         1.3193, 1.4740, 1.4009, 1.3119, 1.3066, 1.4339, 1.3824, 0.5129, 1.3725,
         1.0269, 1.4051, 1.3910, 1.3710, 1.0565, 1.3888, 0.8525, 1.3655, 1.3708],
        [1.2049, 1.2319, 1.2870, 1.2669, 1.2383, 1.2104, 1.2174, 1.2030, 1.2030,
         1.2775, 1.2909, 1.2926, 1.3146, 1.2621, 1.3118, 1.2751, 1.2570, 1.2037,
         2.1992, 2.2509, 2.3498, 2.2982, 2.0943, 2.1720, 2.2009, 2.0823, 2.0823,
         1.3028, 1.2728, 1.2392, 1.2638, 1.3024, 1.2498, 1.2730, 1.2439, 1.2414,
         1.3666, 1.4007, 1.3852, 1.3652, 1.3862, 1.3749, 1.3686, 1.2818, 1.3121,
         1.3057, 1.2980, 1.2885, 1.2671, 1.2574, 1.2862, 1.3384, 1.2624, 1.2666],
        [1.2092, 1.2379, 1.2227, 1.2005, 1.2439, 1.2152, 1.2226, 1.2073, 1.2073,
         1.2764, 1.2247, 1.2919, 1.2904, 1.2604, 1.2676, 1.2738, 1.2629, 1.0766,
         1.2562, 1.2563, 1.2977, 1.2688, 1.2310, 1.1998, 1.2487, 1.2184, 1.2184,
         2.5311, 2.1790, 1.9400, 2.0489, 2.5139, 1.9489, 2.4694, 1.9538, 1.9409,
         1.3556, 1.3898, 1.3408, 1.3340, 1.3756, 1.3452, 1.3532, 1.1693, 1.3068,
         1.3541, 1.2655, 1.1706, 1.2170, 1.3441, 1.1938, 1.3879, 1.2128, 1.2642],
        [1.6222, 1.2996, 0.5586, 0.7675, 1.1162, 1.5116, 1.4492, 1.6193, 1.6193,
         1.4889, 1.2411, 1.3214, 0.8697, 1.5831, 0.1978, 1.4770, 1.5984, 1.1417,
         1.2439, 0.8162, 0.7063, 1.0318, 1.4844, 1.5677, 1.2534, 1.6253, 1.6253,
         0.6595, 0.7729, 1.5916, 1.3741, 0.7539, 1.5320, 1.0607, 1.6396, 1.5762,
         0.4836, 0.2516, 0.2073, 0.4372, 0.7474, 0.9440, 0.3844, 7.2810, 6.2723,
         0.7013, 1.1559, 1.2359, 1.4678, 0.9494, 1.4584, 0.3665, 1.5057, 1.6363],
        [1.2612, 1.2924, 1.3542, 1.3322, 1.2996, 1.2673, 1.2331, 1.2591, 1.2591,
         1.2274, 1.3328, 1.2424, 1.3648, 1.3046, 1.4173, 1.2251, 1.3077, 1.2413,
         1.3100, 1.3406, 1.3546, 1.3223, 1.2827, 1.2721, 1.2443, 1.2692, 1.2692,
         1.3248, 1.3744, 1.2872, 1.1357, 1.2713, 1.1621, 1.3260, 1.1659, 1.2899,
         1.3767, 1.1054, 1.3984, 1.3853, 1.0005, 0.9059, 1.3790, 1.3866, 0.8002,
         2.5637, 2.1666, 2.5625, 2.3681, 1.8714, 1.6241, 2.4560, 2.4027, 1.6069]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 98 : 181.08537913995968
Test loss for epoch 98 : 181.1394152226892
Test Precision for epoch 98 : 0.26153846153846155
Test Recall for epoch 98 : 0.26153846153846155
Test F1 for epoch 98 : 0.26153846153846155


theta for epoch 99 : tensor([[2.1401, 2.1683, 2.2404, 2.3041, 2.2678, 2.1459, 2.2462, 2.1382, 2.1382,
         1.2709, 1.2841, 1.2863, 1.3085, 1.2555, 1.3551, 1.2687, 1.2582, 1.2377,
         1.2440, 1.2294, 1.2409, 1.2562, 1.2198, 1.2113, 1.2376, 1.2077, 1.2077,
         1.2579, 1.3051, 1.2332, 1.2574, 1.3006, 1.2437, 1.2659, 1.1950, 1.2353,
         1.3642, 1.3978, 1.3826, 1.3714, 1.3835, 1.3195, 1.3660, 1.3778, 1.3198,
         1.3440, 1.2910, 1.2816, 1.2607, 1.3339, 1.2789, 1.3755, 1.2560, 1.2601],
        [1.2773, 1.1829, 1.0007, 1.2248, 1.2911, 1.3282, 1.2511, 1.3196, 1.3196,
         1.4494, 1.7015, 1.4496, 2.1515, 1.4843, 4.1952, 1.5454, 1.3816, 3.8719,
         1.1209, 1.1962, 0.9731, 1.1671, 1.3009, 1.3337, 1.3121, 1.3312, 1.3312,
         1.2944, 1.0401, 1.3495, 1.3275, 1.1338, 1.3619, 1.3790, 1.3128, 1.3284,
         1.3196, 1.4740, 1.4008, 1.3118, 1.3068, 1.4340, 1.3823, 0.5125, 1.3724,
         1.0263, 1.4044, 1.3902, 1.3702, 1.0557, 1.3878, 0.8522, 1.3645, 1.3698],
        [1.2047, 1.2315, 1.2864, 1.2664, 1.2380, 1.2103, 1.2171, 1.2028, 1.2028,
         1.2769, 1.2905, 1.2922, 1.3143, 1.2615, 1.3115, 1.2746, 1.2563, 1.2035,
         2.2050, 2.2570, 2.3560, 2.3044, 2.0997, 2.1776, 2.2065, 2.0877, 2.0877,
         1.3026, 1.2726, 1.2391, 1.2636, 1.3022, 1.2497, 1.2730, 1.2437, 1.2413,
         1.3670, 1.4011, 1.3856, 1.3656, 1.3865, 1.3753, 1.3690, 1.2816, 1.3123,
         1.3047, 1.2971, 1.2875, 1.2662, 1.2563, 1.2852, 1.3373, 1.2614, 1.2656],
        [1.2086, 1.2374, 1.2229, 1.2007, 1.2434, 1.2145, 1.2220, 1.2067, 1.2067,
         1.2758, 1.2248, 1.2913, 1.2904, 1.2597, 1.2672, 1.2732, 1.2622, 1.0775,
         1.2557, 1.2562, 1.2972, 1.2683, 1.2304, 1.1995, 1.2482, 1.2178, 1.2178,
         2.5359, 2.1858, 1.9458, 2.0548, 2.5191, 1.9549, 2.4744, 1.9596, 1.9468,
         1.3553, 1.3897, 1.3411, 1.3342, 1.3755, 1.3457, 1.3530, 1.1702, 1.3061,
         1.3531, 1.2652, 1.1701, 1.2161, 1.3430, 1.1940, 1.3868, 1.2117, 1.2631],
        [1.6239, 1.3012, 0.5603, 0.7691, 1.1178, 1.5133, 1.4509, 1.6209, 1.6209,
         1.4900, 1.2415, 1.3225, 0.8709, 1.5840, 0.1999, 1.4779, 1.5993, 1.1414,
         1.2455, 0.8179, 0.7082, 1.0335, 1.4860, 1.5689, 1.2551, 1.6269, 1.6269,
         0.6611, 0.7751, 1.5932, 1.3760, 0.7553, 1.5332, 1.0616, 1.6412, 1.5775,
         0.4779, 0.2458, 0.2021, 0.4316, 0.7399, 0.9339, 0.3787, 7.3387, 6.3098,
         0.7030, 1.1565, 1.2364, 1.4681, 0.9507, 1.4579, 0.3685, 1.5061, 1.6366],
        [1.2604, 1.2916, 1.3536, 1.3316, 1.2988, 1.2663, 1.2321, 1.2582, 1.2582,
         1.2263, 1.3320, 1.2415, 1.3638, 1.3034, 1.4166, 1.2240, 1.3065, 1.2403,
         1.3094, 1.3400, 1.3535, 1.3215, 1.2820, 1.2713, 1.2434, 1.2685, 1.2685,
         1.3245, 1.3739, 1.2869, 1.1350, 1.2715, 1.1622, 1.3259, 1.1656, 1.2896,
         1.3763, 1.1046, 1.3982, 1.3849, 0.9994, 0.9048, 1.3788, 1.3863, 0.7987,
         2.5696, 2.1722, 2.5712, 2.3730, 1.8774, 1.6288, 2.4610, 2.4120, 1.6115]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 99 : 181.07033647277913
Test loss for epoch 99 : 181.12414783209564
Test Precision for epoch 99 : 0.26153846153846155
Test Recall for epoch 99 : 0.26153846153846155
Test F1 for epoch 99 : 0.26153846153846155


theta for epoch 100 : tensor([[2.1455, 2.1740, 2.2462, 2.3103, 2.2740, 2.1515, 2.2521, 2.1437, 2.1437,
         1.2704, 1.2837, 1.2859, 1.3082, 1.2551, 1.3548, 1.2683, 1.2578, 1.2375,
         1.2435, 1.2287, 1.2403, 1.2556, 1.2194, 1.2110, 1.2372, 1.2074, 1.2074,
         1.2576, 1.3048, 1.2328, 1.2570, 1.3004, 1.2433, 1.2656, 1.1946, 1.2349,
         1.3643, 1.3980, 1.3828, 1.3715, 1.3836, 1.3196, 1.3662, 1.3772, 1.3195,
         1.3433, 1.2905, 1.2810, 1.2602, 1.3331, 1.2783, 1.3748, 1.2553, 1.2594],
        [1.2767, 1.1826, 1.0002, 1.2243, 1.2909, 1.3275, 1.2505, 1.3188, 1.3188,
         1.4514, 1.7044, 1.4519, 2.1543, 1.4867, 4.2104, 1.5475, 1.3838, 3.8899,
         1.1205, 1.1959, 0.9728, 1.1667, 1.3002, 1.3331, 1.3115, 1.3305, 1.3305,
         1.2945, 1.0401, 1.3494, 1.3274, 1.1337, 1.3618, 1.3790, 1.3126, 1.3285,
         1.3196, 1.4736, 1.4003, 1.3113, 1.3067, 1.4337, 1.3818, 0.5118, 1.3719,
         1.0261, 1.4040, 1.3898, 1.3697, 1.0552, 1.3872, 0.8522, 1.3639, 1.3692],
        [1.2042, 1.2310, 1.2858, 1.2657, 1.2375, 1.2099, 1.2165, 1.2025, 1.2025,
         1.2764, 1.2900, 1.2919, 1.3139, 1.2611, 1.3112, 1.2742, 1.2558, 1.2034,
         2.2108, 2.2632, 2.3623, 2.3107, 2.1052, 2.1834, 2.2123, 2.0931, 2.0931,
         1.3023, 1.2723, 1.2387, 1.2632, 1.3018, 1.2494, 1.2727, 1.2434, 1.2409,
         1.3670, 1.4012, 1.3858, 1.3657, 1.3866, 1.3754, 1.3691, 1.2811, 1.3123,
         1.3042, 1.2965, 1.2869, 1.2656, 1.2557, 1.2845, 1.3366, 1.2607, 1.2649],
        [1.2079, 1.2367, 1.2231, 1.2008, 1.2427, 1.2138, 1.2212, 1.2059, 1.2059,
         1.2752, 1.2250, 1.2908, 1.2903, 1.2591, 1.2669, 1.2727, 1.2615, 1.0786,
         1.2550, 1.2560, 1.2967, 1.2678, 1.2297, 1.1991, 1.2476, 1.2171, 1.2171,
         2.5407, 2.1926, 1.9517, 2.0608, 2.5242, 1.9610, 2.4794, 1.9655, 1.9528,
         1.3548, 1.3894, 1.3413, 1.3341, 1.3752, 1.3459, 1.3527, 1.1708, 1.3052,
         1.3524, 1.2651, 1.1699, 1.2156, 1.3422, 1.1944, 1.3860, 1.2109, 1.2623],
        [1.6256, 1.3029, 0.5620, 0.7707, 1.1193, 1.5151, 1.4525, 1.6226, 1.6226,
         1.4912, 1.2422, 1.3239, 0.8722, 1.5851, 0.2021, 1.4791, 1.6005, 1.1414,
         1.2472, 0.8197, 0.7102, 1.0353, 1.4878, 1.5702, 1.2569, 1.6286, 1.6286,
         0.6627, 0.7773, 1.5946, 1.3779, 0.7568, 1.5345, 1.0625, 1.6427, 1.5788,
         0.4721, 0.2398, 0.1967, 0.4258, 0.7323, 0.9239, 0.3728, 7.3959, 6.3466,
         0.7054, 1.1577, 1.2376, 1.4689, 0.9527, 1.4578, 0.3710, 1.5071, 1.6374],
        [1.2595, 1.2908, 1.3531, 1.3310, 1.2980, 1.2654, 1.2312, 1.2573, 1.2573,
         1.2256, 1.3316, 1.2409, 1.3632, 1.3026, 1.4161, 1.2233, 1.3057, 1.2396,
         1.3088, 1.3395, 1.3527, 1.3209, 1.2814, 1.2707, 1.2427, 1.2678, 1.2678,
         1.3242, 1.3734, 1.2866, 1.1343, 1.2716, 1.1622, 1.3257, 1.1652, 1.2893,
         1.3758, 1.1037, 1.3978, 1.3843, 0.9981, 0.9035, 1.3784, 1.3856, 0.7970,
         2.5755, 2.1778, 2.5798, 2.3779, 1.8833, 1.6334, 2.4661, 2.4212, 1.6161]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 100 : 181.05560280728116
Test loss for epoch 100 : 181.10919427083638
Test Precision for epoch 100 : 0.26153846153846155
Test Recall for epoch 100 : 0.26153846153846155
Test F1 for epoch 100 : 0.26153846153846155


theta for epoch 101 : tensor([[2.1511, 2.1797, 2.2520, 2.3165, 2.2802, 2.1570, 2.2582, 2.1493, 2.1493,
         1.2701, 1.2835, 1.2857, 1.3079, 1.2549, 1.3545, 1.2680, 1.2575, 1.2374,
         1.2428, 1.2279, 1.2397, 1.2549, 1.2189, 1.2106, 1.2366, 1.2070, 1.2070,
         1.2568, 1.3041, 1.2318, 1.2561, 1.2997, 1.2424, 1.2648, 1.1936, 1.2340,
         1.3643, 1.3982, 1.3830, 1.3715, 1.3836, 1.3198, 1.3664, 1.3767, 1.3192,
         1.3430, 1.2903, 1.2808, 1.2600, 1.3327, 1.2780, 1.3744, 1.2550, 1.2591],
        [1.2759, 1.1821, 0.9995, 1.2237, 1.2907, 1.3267, 1.2498, 1.3180, 1.3180,
         1.4537, 1.7074, 1.4545, 2.1574, 1.4893, 4.2258, 1.5499, 1.3863, 3.9082,
         1.1199, 1.1953, 0.9723, 1.1662, 1.2994, 1.3323, 1.3108, 1.3297, 1.3297,
         1.2941, 1.0395, 1.3488, 1.3268, 1.1331, 1.3612, 1.3786, 1.3119, 1.3281,
         1.3195, 1.4733, 1.3998, 1.3108, 1.3065, 1.4335, 1.3813, 0.5111, 1.3715,
         1.0261, 1.4039, 1.3897, 1.3695, 1.0549, 1.3870, 0.8525, 1.3636, 1.3688],
        [1.2039, 1.2306, 1.2853, 1.2652, 1.2371, 1.2096, 1.2161, 1.2022, 1.2022,
         1.2762, 1.2898, 1.2917, 1.3138, 1.2608, 1.3111, 1.2740, 1.2555, 1.2035,
         2.2165, 2.2692, 2.3685, 2.3168, 2.1105, 2.1890, 2.2179, 2.0984, 2.0984,
         1.3015, 1.2715, 1.2379, 1.2624, 1.3010, 1.2486, 1.2720, 1.2425, 1.2401,
         1.3670, 1.4013, 1.3859, 1.3658, 1.3866, 1.3756, 1.3693, 1.2807, 1.3123,
         1.3040, 1.2963, 1.2867, 1.2655, 1.2554, 1.2842, 1.3362, 1.2604, 1.2646],
        [1.2071, 1.2360, 1.2233, 1.2010, 1.2420, 1.2130, 1.2205, 1.2052, 1.2052,
         1.2748, 1.2253, 1.2904, 1.2904, 1.2587, 1.2667, 1.2723, 1.2611, 1.0798,
         1.2543, 1.2558, 1.2960, 1.2671, 1.2289, 1.1987, 1.2469, 1.2163, 1.2163,
         2.5454, 2.1993, 1.9576, 2.0667, 2.5292, 1.9669, 2.4843, 1.9713, 1.9588,
         1.3543, 1.3890, 1.3415, 1.3341, 1.3749, 1.3461, 1.3524, 1.1716, 1.3043,
         1.3520, 1.2654, 1.1700, 1.2153, 1.3417, 1.1952, 1.3856, 1.2104, 1.2618],
        [1.6270, 1.3042, 0.5634, 0.7720, 1.1206, 1.5165, 1.4539, 1.6239, 1.6239,
         1.4924, 1.2427, 1.3251, 0.8733, 1.5862, 0.2039, 1.4802, 1.6016, 1.1412,
         1.2485, 0.8210, 0.7116, 1.0367, 1.4892, 1.5712, 1.2584, 1.6299, 1.6299,
         0.6636, 0.7789, 1.5956, 1.3792, 0.7576, 1.5352, 1.0628, 1.6437, 1.5795,
         0.4667, 0.2342, 0.1916, 0.4205, 0.7254, 0.9147, 0.3673, 7.4532, 6.3831,
         0.7077, 1.1589, 1.2389, 1.4698, 0.9546, 1.4579, 0.3733, 1.5082, 1.6382],
        [1.2591, 1.2905, 1.3529, 1.3308, 1.2978, 1.2649, 1.2307, 1.2569, 1.2569,
         1.2256, 1.3318, 1.2410, 1.3633, 1.3026, 1.4162, 1.2234, 1.3057, 1.2398,
         1.3086, 1.3394, 1.3522, 1.3207, 1.2811, 1.2704, 1.2423, 1.2675, 1.2675,
         1.3239, 1.3728, 1.2863, 1.1335, 1.2716, 1.1620, 1.3254, 1.1647, 1.2889,
         1.3754, 1.1030, 1.3976, 1.3840, 0.9971, 0.9027, 1.3782, 1.3852, 0.7957,
         2.5809, 2.1828, 2.5880, 2.3824, 1.8887, 1.6375, 2.4707, 2.4299, 1.6201]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 101 : 181.0410424834065
Test loss for epoch 101 : 181.0949161575437
Test Precision for epoch 101 : 0.26153846153846155
Test Recall for epoch 101 : 0.26153846153846155
Test F1 for epoch 101 : 0.26153846153846155


theta for epoch 102 : tensor([[2.1565, 2.1853, 2.2577, 2.3226, 2.2864, 2.1625, 2.2641, 2.1547, 2.1547,
         1.2695, 1.2830, 1.2852, 1.3074, 1.2543, 1.3539, 1.2675, 1.2569, 1.2369,
         1.2423, 1.2273, 1.2392, 1.2544, 1.2186, 1.2103, 1.2363, 1.2068, 1.2068,
         1.2560, 1.3033, 1.2309, 1.2552, 1.2990, 1.2415, 1.2640, 1.1926, 1.2330,
         1.3645, 1.3985, 1.3833, 1.3717, 1.3838, 1.3200, 1.3667, 1.3763, 1.3191,
         1.3428, 1.2903, 1.2807, 1.2599, 1.3324, 1.2778, 1.3742, 1.2549, 1.2589],
        [1.2753, 1.1817, 0.9988, 1.2231, 1.2905, 1.3260, 1.2492, 1.3173, 1.3173,
         1.4556, 1.7101, 1.4567, 2.1603, 1.4916, 4.2410, 1.5520, 1.3884, 3.9263,
         1.1195, 1.1950, 0.9720, 1.1658, 1.2988, 1.3316, 1.3102, 1.3290, 1.3290,
         1.2938, 1.0389, 1.3481, 1.3263, 1.1326, 1.3606, 1.3782, 1.3113, 1.3277,
         1.3195, 1.4730, 1.3995, 1.3104, 1.3065, 1.4334, 1.3809, 0.5106, 1.3713,
         1.0262, 1.4040, 1.3898, 1.3695, 1.0549, 1.3869, 0.8528, 1.3635, 1.3687],
        [1.2035, 1.2302, 1.2848, 1.2647, 1.2367, 1.2093, 1.2157, 1.2018, 1.2018,
         1.2756, 1.2893, 1.2912, 1.3133, 1.2602, 1.3106, 1.2734, 1.2549, 1.2032,
         2.2222, 2.2753, 2.3748, 2.3230, 2.1158, 2.1946, 2.2236, 2.1037, 2.1037,
         1.3006, 1.2707, 1.2370, 1.2616, 1.3001, 1.2478, 1.2713, 1.2417, 1.2392,
         1.3672, 1.4016, 1.3862, 1.3660, 1.3867, 1.3758, 1.3695, 1.2804, 1.3125,
         1.3040, 1.2963, 1.2866, 1.2654, 1.2552, 1.2840, 1.3360, 1.2602, 1.2644],
        [1.2063, 1.2352, 1.2234, 1.2010, 1.2413, 1.2121, 1.2196, 1.2043, 1.2043,
         1.2740, 1.2253, 1.2897, 1.2900, 1.2579, 1.2660, 1.2716, 1.2603, 1.0808,
         1.2536, 1.2556, 1.2953, 1.2665, 1.2281, 1.1983, 1.2463, 1.2155, 1.2155,
         2.5501, 2.2061, 1.9635, 2.0727, 2.5343, 1.9730, 2.4892, 1.9772, 1.9648,
         1.3538, 1.3888, 1.3417, 1.3341, 1.3746, 1.3464, 1.3521, 1.1724, 1.3036,
         1.3517, 1.2657, 1.1702, 1.2150, 1.3413, 1.1960, 1.3852, 1.2100, 1.2614],
        [1.6280, 1.3051, 0.5644, 0.7728, 1.1214, 1.5175, 1.4549, 1.6250, 1.6250,
         1.4929, 1.2426, 1.3257, 0.8738, 1.5867, 0.2051, 1.4807, 1.6021, 1.1404,
         1.2495, 0.8221, 0.7127, 1.0378, 1.4904, 1.5719, 1.2596, 1.6310, 1.6310,
         0.6642, 0.7802, 1.5963, 1.3803, 0.7581, 1.5359, 1.0627, 1.6445, 1.5800,
         0.4616, 0.2291, 0.1870, 0.4155, 0.7190, 0.9062, 0.3622, 7.5104, 6.4194,
         0.7097, 1.1600, 1.2401, 1.4706, 0.9563, 1.4578, 0.3752, 1.5092, 1.6390],
        [1.2590, 1.2904, 1.3530, 1.3309, 1.2978, 1.2648, 1.2306, 1.2568, 1.2568,
         1.2258, 1.3321, 1.2412, 1.3634, 1.3027, 1.4163, 1.2236, 1.3057, 1.2399,
         1.3088, 1.3397, 1.3522, 1.3208, 1.2812, 1.2705, 1.2422, 1.2675, 1.2675,
         1.3237, 1.3724, 1.2861, 1.1329, 1.2716, 1.1620, 1.3253, 1.1644, 1.2887,
         1.3754, 1.1027, 1.3977, 1.3840, 0.9966, 0.9022, 1.3783, 1.3849, 0.7950,
         2.5861, 2.1875, 2.5957, 2.3864, 1.8936, 1.6411, 2.4750, 2.4382, 1.6236]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 102 : 181.02673781943304
Test loss for epoch 102 : 181.08113364235555
Test Precision for epoch 102 : 0.26153846153846155
Test Recall for epoch 102 : 0.26153846153846155
Test F1 for epoch 102 : 0.26153846153846155


theta for epoch 103 : tensor([[2.1619, 2.1908, 2.2633, 2.3286, 2.2924, 2.1679, 2.2699, 2.1601, 2.1601,
         1.2688, 1.2824, 1.2845, 1.3067, 1.2537, 1.3531, 1.2668, 1.2563, 1.2364,
         1.2419, 1.2268, 1.2389, 1.2540, 1.2183, 1.2101, 1.2360, 1.2065, 1.2065,
         1.2555, 1.3029, 1.2303, 1.2547, 1.2986, 1.2410, 1.2636, 1.1919, 1.2324,
         1.3646, 1.3987, 1.3835, 1.3717, 1.3839, 1.3202, 1.3669, 1.3758, 1.3190,
         1.3426, 1.2902, 1.2807, 1.2598, 1.3321, 1.2776, 1.3739, 1.2547, 1.2587],
        [1.2747, 1.1813, 0.9982, 1.2226, 1.2903, 1.3254, 1.2487, 1.3167, 1.3167,
         1.4575, 1.7126, 1.4588, 2.1633, 1.4938, 4.2563, 1.5541, 1.3905, 3.9444,
         1.1191, 1.1946, 0.9717, 1.1654, 1.2982, 1.3310, 1.3096, 1.3283, 1.3283,
         1.2937, 1.0387, 1.3478, 1.3260, 1.1323, 1.3603, 1.3781, 1.3109, 1.3275,
         1.3194, 1.4727, 1.3990, 1.3099, 1.3063, 1.4332, 1.3804, 0.5100, 1.3709,
         1.0263, 1.4041, 1.3898, 1.3694, 1.0548, 1.3868, 0.8531, 1.3633, 1.3685],
        [1.2031, 1.2298, 1.2844, 1.2643, 1.2364, 1.2089, 1.2153, 1.2015, 1.2015,
         1.2749, 1.2886, 1.2906, 1.3127, 1.2596, 1.3101, 1.2728, 1.2542, 1.2029,
         2.2279, 2.2813, 2.3810, 2.3292, 2.1211, 2.2002, 2.2293, 2.1089, 2.1089,
         1.3001, 1.2703, 1.2364, 1.2610, 1.2996, 1.2472, 1.2709, 1.2411, 1.2386,
         1.3672, 1.4018, 1.3863, 1.3661, 1.3868, 1.3760, 1.3696, 1.2801, 1.3125,
         1.3040, 1.2963, 1.2865, 1.2653, 1.2551, 1.2838, 1.3357, 1.2601, 1.2642],
        [1.2053, 1.2342, 1.2234, 1.2011, 1.2404, 1.2111, 1.2186, 1.2033, 1.2033,
         1.2731, 1.2252, 1.2888, 1.2895, 1.2570, 1.2651, 1.2706, 1.2593, 1.0816,
         1.2528, 1.2553, 1.2945, 1.2657, 1.2272, 1.1978, 1.2455, 1.2145, 1.2145,
         2.5551, 2.2131, 1.9697, 2.0790, 2.5396, 1.9793, 2.4944, 1.9833, 1.9711,
         1.3532, 1.3884, 1.3419, 1.3340, 1.3741, 1.3465, 1.3517, 1.1732, 1.3027,
         1.3513, 1.2660, 1.1703, 1.2147, 1.3409, 1.1968, 1.3847, 1.2096, 1.2610],
        [1.6292, 1.3062, 0.5655, 0.7738, 1.1225, 1.5187, 1.4560, 1.6261, 1.6261,
         1.4936, 1.2426, 1.3265, 0.8745, 1.5873, 0.2064, 1.4813, 1.6027, 1.1398,
         1.2507, 0.8233, 0.7140, 1.0391, 1.4916, 1.5727, 1.2610, 1.6322, 1.6322,
         0.6651, 0.7818, 1.5973, 1.3817, 0.7590, 1.5369, 1.0631, 1.6455, 1.5808,
         0.4564, 0.2239, 0.1822, 0.4104, 0.7125, 0.8978, 0.3570, 7.5672, 6.4549,
         0.7118, 1.1613, 1.2415, 1.4716, 0.9582, 1.4579, 0.3773, 1.5103, 1.6398],
        [1.2587, 1.2901, 1.3530, 1.3308, 1.2977, 1.2645, 1.2303, 1.2565, 1.2565,
         1.2257, 1.3321, 1.2412, 1.3632, 1.3025, 1.4162, 1.2236, 1.3055, 1.2398,
         1.3088, 1.3398, 1.3521, 1.3209, 1.2811, 1.2704, 1.2420, 1.2674, 1.2674,
         1.3237, 1.3720, 1.2860, 1.1324, 1.2718, 1.1619, 1.3253, 1.1643, 1.2886,
         1.3753, 1.1022, 1.3977, 1.3839, 0.9958, 0.9015, 1.3783, 1.3844, 0.7941,
         2.5914, 2.1923, 2.6036, 2.3907, 1.8985, 1.6448, 2.4795, 2.4467, 1.6272]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 103 : 181.01275475869608
Test loss for epoch 103 : 181.06749392349104
Test Precision for epoch 103 : 0.26153846153846155
Test Recall for epoch 103 : 0.26153846153846155
Test F1 for epoch 103 : 0.26153846153846155


theta for epoch 104 : tensor([[2.1674, 2.1965, 2.2690, 2.3348, 2.2986, 2.1734, 2.2759, 2.1656, 2.1656,
         1.2685, 1.2821, 1.2842, 1.3063, 1.2534, 1.3526, 1.2665, 1.2560, 1.2361,
         1.2414, 1.2263, 1.2385, 1.2535, 1.2179, 1.2098, 1.2356, 1.2062, 1.2062,
         1.2552, 1.3026, 1.2297, 1.2542, 1.2984, 1.2405, 1.2633, 1.1913, 1.2319,
         1.3645, 1.3988, 1.3835, 1.3716, 1.3838, 1.3203, 1.3669, 1.3753, 1.3187,
         1.3421, 1.2899, 1.2803, 1.2594, 1.3316, 1.2772, 1.3734, 1.2543, 1.2582],
        [1.2742, 1.1810, 0.9976, 1.2221, 1.2902, 1.3248, 1.2483, 1.3161, 1.3161,
         1.4598, 1.7155, 1.4613, 2.1667, 1.4963, 4.2720, 1.5565, 1.3929, 3.9629,
         1.1186, 1.1940, 0.9713, 1.1649, 1.2974, 1.3302, 1.3088, 1.3274, 1.3274,
         1.2937, 1.0385, 1.3474, 1.3257, 1.1322, 1.3600, 1.3780, 1.3105, 1.3274,
         1.3191, 1.4722, 1.3983, 1.3093, 1.3060, 1.4329, 1.3797, 0.5092, 1.3704,
         1.0260, 1.4039, 1.3896, 1.3690, 1.0544, 1.3864, 0.8530, 1.3629, 1.3680],
        [1.2028, 1.2296, 1.2843, 1.2640, 1.2362, 1.2087, 1.2151, 1.2012, 1.2012,
         1.2745, 1.2883, 1.2902, 1.3124, 1.2593, 1.3099, 1.2724, 1.2539, 1.2028,
         2.2335, 2.2874, 2.3873, 2.3354, 2.1265, 2.2058, 2.2350, 2.1142, 2.1142,
         1.2997, 1.2700, 1.2359, 1.2606, 1.2992, 1.2468, 1.2707, 1.2407, 1.2381,
         1.3671, 1.4018, 1.3863, 1.3661, 1.3867, 1.3761, 1.3697, 1.2797, 1.3125,
         1.3036, 1.2960, 1.2862, 1.2649, 1.2546, 1.2834, 1.3351, 1.2597, 1.2637],
        [1.2045, 1.2335, 1.2237, 1.2013, 1.2397, 1.2103, 1.2179, 1.2025, 1.2025,
         1.2725, 1.2254, 1.2882, 1.2894, 1.2564, 1.2646, 1.2701, 1.2587, 1.0828,
         1.2520, 1.2551, 1.2938, 1.2649, 1.2263, 1.1973, 1.2447, 1.2137, 1.2137,
         2.5600, 2.2202, 1.9759, 2.0853, 2.5448, 1.9855, 2.4995, 1.9894, 1.9774,
         1.3526, 1.3881, 1.3420, 1.3339, 1.3736, 1.3466, 1.3513, 1.1740, 1.3019,
         1.3508, 1.2661, 1.1703, 1.2143, 1.3402, 1.1974, 1.3841, 1.2090, 1.2603],
        [1.6306, 1.3077, 0.5672, 0.7753, 1.1241, 1.5201, 1.4574, 1.6275, 1.6275,
         1.4948, 1.2433, 1.3279, 0.8759, 1.5884, 0.2083, 1.4824, 1.6039, 1.1399,
         1.2521, 0.8249, 0.7157, 1.0407, 1.4931, 1.5737, 1.2627, 1.6336, 1.6336,
         0.6665, 0.7839, 1.5986, 1.3835, 0.7603, 1.5383, 1.0638, 1.6469, 1.5819,
         0.4508, 0.2183, 0.1771, 0.4050, 0.7059, 0.8893, 0.3514, 7.6234, 6.4895,
         0.7143, 1.1628, 1.2431, 1.4727, 0.9604, 1.4580, 0.3797, 1.5116, 1.6407],
        [1.2581, 1.2896, 1.3527, 1.3305, 1.2974, 1.2640, 1.2298, 1.2559, 1.2559,
         1.2256, 1.3321, 1.2410, 1.3631, 1.3024, 1.4159, 1.2235, 1.3054, 1.2396,
         1.3083, 1.3395, 1.3516, 1.3205, 1.2806, 1.2699, 1.2414, 1.2669, 1.2669,
         1.3235, 1.3716, 1.2858, 1.1318, 1.2717, 1.1617, 1.3253, 1.1640, 1.2884,
         1.3748, 1.1013, 1.3973, 1.3834, 0.9947, 0.9005, 1.3780, 1.3836, 0.7929,
         2.5973, 2.1976, 2.6121, 2.3954, 1.9039, 1.6489, 2.4845, 2.4556, 1.6312]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 104 : 180.99896361310616
Test loss for epoch 104 : 181.0538342961381
Test Precision for epoch 104 : 0.26153846153846155
Test Recall for epoch 104 : 0.26153846153846155
Test F1 for epoch 104 : 0.26153846153846155


theta for epoch 105 : tensor([[2.1729, 2.2021, 2.2747, 2.3410, 2.3048, 2.1789, 2.2819, 2.1711, 2.1711,
         1.2682, 1.2818, 1.2839, 1.3060, 1.2532, 1.3522, 1.2663, 1.2558, 1.2359,
         1.2412, 1.2260, 1.2383, 1.2533, 1.2178, 1.2097, 1.2354, 1.2061, 1.2061,
         1.2548, 1.3022, 1.2291, 1.2537, 1.2981, 1.2399, 1.2629, 1.1907, 1.2313,
         1.3647, 1.3991, 1.3838, 1.3718, 1.3840, 1.3205, 1.3672, 1.3750, 1.3186,
         1.3413, 1.2893, 1.2797, 1.2587, 1.3308, 1.2764, 1.3725, 1.2536, 1.2574],
        [1.2740, 1.1809, 0.9972, 1.2219, 1.2903, 1.3245, 1.2481, 1.3158, 1.3158,
         1.4618, 1.7180, 1.4636, 2.1700, 1.4986, 4.2876, 1.5588, 1.3951, 3.9813,
         1.1184, 1.1938, 0.9713, 1.1646, 1.2970, 1.3297, 1.3084, 1.3269, 1.3269,
         1.2936, 1.0383, 1.3471, 1.3254, 1.1320, 1.3597, 1.3780, 1.3101, 1.3272,
         1.3191, 1.4720, 1.3979, 1.3089, 1.3059, 1.4328, 1.3793, 0.5088, 1.3702,
         1.0254, 1.4034, 1.3891, 1.3683, 1.0537, 1.3857, 0.8526, 1.3623, 1.3672],
        [1.2026, 1.2294, 1.2842, 1.2639, 1.2360, 1.2085, 1.2148, 1.2010, 1.2010,
         1.2741, 1.2880, 1.2899, 1.3120, 1.2590, 1.3097, 1.2721, 1.2536, 1.2028,
         2.2393, 2.2936, 2.3937, 2.3417, 2.1319, 2.2116, 2.2408, 2.1197, 2.1197,
         1.2992, 1.2697, 1.2353, 1.2601, 1.2986, 1.2462, 1.2703, 1.2401, 1.2375,
         1.3673, 1.4021, 1.3865, 1.3663, 1.3869, 1.3764, 1.3699, 1.2795, 1.3126,
         1.3030, 1.2953, 1.2856, 1.2642, 1.2539, 1.2827, 1.3342, 1.2589, 1.2629],
        [1.2039, 1.2329, 1.2242, 1.2018, 1.2393, 1.2097, 1.2173, 1.2019, 1.2019,
         1.2721, 1.2259, 1.2879, 1.2894, 1.2561, 1.2643, 1.2697, 1.2584, 1.0843,
         1.2515, 1.2551, 1.2933, 1.2645, 1.2258, 1.1971, 1.2443, 1.2131, 1.2131,
         2.5647, 2.2271, 1.9819, 2.0914, 2.5498, 1.9916, 2.5044, 1.9954, 1.9834,
         1.3523, 1.3880, 1.3424, 1.3341, 1.3735, 1.3471, 1.3512, 1.1752, 1.3013,
         1.3501, 1.2661, 1.1701, 1.2137, 1.3395, 1.1980, 1.3833, 1.2083, 1.2596],
        [1.6320, 1.3092, 0.5688, 0.7767, 1.1257, 1.5216, 1.4589, 1.6290, 1.6290,
         1.4960, 1.2440, 1.3293, 0.8772, 1.5896, 0.2102, 1.4836, 1.6050, 1.1399,
         1.2536, 0.8266, 0.7174, 1.0424, 1.4946, 1.5748, 1.2645, 1.6350, 1.6350,
         0.6677, 0.7858, 1.5998, 1.3851, 0.7614, 1.5396, 1.0643, 1.6481, 1.5829,
         0.4455, 0.2131, 0.1723, 0.3997, 0.6995, 0.8813, 0.3460, 7.6794, 6.5236,
         0.7164, 1.1640, 1.2443, 1.4734, 0.9621, 1.4579, 0.3817, 1.5125, 1.6412],
        [1.2574, 1.2889, 1.3522, 1.3299, 1.2969, 1.2633, 1.2291, 1.2552, 1.2552,
         1.2253, 1.3320, 1.2407, 1.3628, 1.3021, 1.4154, 1.2232, 1.3051, 1.2392,
         1.3078, 1.3391, 1.3511, 1.3200, 1.2800, 1.2694, 1.2407, 1.2662, 1.2662,
         1.3232, 1.3709, 1.2854, 1.1309, 1.2714, 1.1611, 1.3250, 1.1633, 1.2880,
         1.3745, 1.1005, 1.3971, 1.3831, 0.9937, 0.8995, 1.3778, 1.3829, 0.7918,
         2.6034, 2.2030, 2.6207, 2.4004, 1.9093, 1.6531, 2.4898, 2.4647, 1.6354]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 105 : 180.98540953004965
Test loss for epoch 105 : 181.04035115413905
Test Precision for epoch 105 : 0.26153846153846155
Test Recall for epoch 105 : 0.26153846153846155
Test F1 for epoch 105 : 0.26153846153846155


theta for epoch 106 : tensor([[2.1783, 2.2076, 2.2802, 2.3470, 2.3108, 2.1843, 2.2878, 2.1765, 2.1765,
         1.2678, 1.2815, 1.2835, 1.3056, 1.2529, 1.3516, 1.2659, 1.2555, 1.2356,
         1.2410, 1.2258, 1.2382, 1.2531, 1.2176, 1.2095, 1.2352, 1.2059, 1.2059,
         1.2545, 1.3019, 1.2285, 1.2532, 1.2978, 1.2394, 1.2626, 1.1901, 1.2307,
         1.3651, 1.3997, 1.3843, 1.3722, 1.3845, 1.3211, 1.3677, 1.3751, 1.3189,
         1.3405, 1.2886, 1.2790, 1.2580, 1.3299, 1.2756, 1.3716, 1.2528, 1.2566],
        [1.2738, 1.1809, 0.9969, 1.2217, 1.2904, 1.3243, 1.2481, 1.3156, 1.3156,
         1.4635, 1.7201, 1.4655, 2.1730, 1.5005, 4.3030, 1.5608, 1.3970, 3.9994,
         1.1184, 1.1936, 0.9714, 1.1645, 1.2968, 1.3294, 1.3080, 1.3265, 1.3265,
         1.2937, 1.0382, 1.3468, 1.3252, 1.1320, 1.3595, 1.3780, 1.3099, 1.3271,
         1.3194, 1.4722, 1.3978, 1.3089, 1.3062, 1.4331, 1.3792, 0.5088, 1.3703,
         1.0248, 1.4029, 1.3886, 1.3676, 1.0530, 1.3851, 0.8522, 1.3616, 1.3665],
        [1.2022, 1.2292, 1.2841, 1.2637, 1.2358, 1.2081, 1.2145, 1.2006, 1.2006,
         1.2737, 1.2876, 1.2894, 1.3116, 1.2586, 1.3095, 1.2717, 1.2532, 1.2027,
         2.2449, 2.2996, 2.4000, 2.3479, 2.1372, 2.2172, 2.2466, 2.1250, 2.1250,
         1.2987, 1.2694, 1.2347, 1.2596, 1.2982, 1.2457, 1.2700, 1.2395, 1.2370,
         1.3677, 1.4027, 1.3870, 1.3668, 1.3873, 1.3770, 1.3704, 1.2797, 1.3130,
         1.3022, 1.2946, 1.2848, 1.2635, 1.2530, 1.2819, 1.3333, 1.2582, 1.2621],
        [1.2034, 1.2324, 1.2247, 1.2024, 1.2389, 1.2092, 1.2168, 1.2014, 1.2014,
         1.2718, 1.2264, 1.2876, 1.2895, 1.2558, 1.2640, 1.2695, 1.2581, 1.0858,
         1.2511, 1.2553, 1.2929, 1.2642, 1.2253, 1.1971, 1.2440, 1.2127, 1.2127,
         2.5692, 2.2338, 1.9878, 2.0975, 2.5546, 1.9976, 2.5091, 2.0012, 1.9894,
         1.3522, 1.3882, 1.3430, 1.3346, 1.3736, 1.3478, 1.3514, 1.1767, 1.3012,
         1.3494, 1.2661, 1.1700, 1.2131, 1.3387, 1.1986, 1.3826, 1.2077, 1.2590],
        [1.6331, 1.3103, 0.5701, 0.7778, 1.1269, 1.5227, 1.4600, 1.6301, 1.6301,
         1.4968, 1.2443, 1.3303, 0.8782, 1.5905, 0.2117, 1.4844, 1.6058, 1.1396,
         1.2549, 0.8280, 0.7187, 1.0438, 1.4958, 1.5756, 1.2660, 1.6362, 1.6362,
         0.6686, 0.7875, 1.6008, 1.3865, 0.7623, 1.5407, 1.0646, 1.6491, 1.5837,
         0.4406, 0.2083, 0.1679, 0.3949, 0.6937, 0.8740, 0.3411, 7.7355, 6.5575,
         0.7179, 1.1647, 1.2452, 1.4740, 0.9634, 1.4574, 0.3832, 1.5132, 1.6415],
        [1.2565, 1.2881, 1.3515, 1.3292, 1.2963, 1.2625, 1.2282, 1.2544, 1.2544,
         1.2249, 1.3316, 1.2402, 1.3623, 1.3016, 1.4148, 1.2227, 1.3046, 1.2387,
         1.3072, 1.3387, 1.3506, 1.3195, 1.2794, 1.2687, 1.2398, 1.2655, 1.2655,
         1.3228, 1.3702, 1.2849, 1.1299, 1.2709, 1.1604, 1.3246, 1.1627, 1.2875,
         1.3745, 1.0999, 1.3972, 1.3831, 0.9930, 0.8989, 1.3780, 1.3825, 0.7911,
         2.6096, 2.2085, 2.6294, 2.4054, 1.9147, 1.6572, 2.4951, 2.4738, 1.6394]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 106 : 180.97207630128642
Test loss for epoch 106 : 181.02717033262488
Test Precision for epoch 106 : 0.26153846153846155
Test Recall for epoch 106 : 0.26153846153846155
Test F1 for epoch 106 : 0.26153846153846155


theta for epoch 107 : tensor([[2.1837, 2.2130, 2.2857, 2.3530, 2.3168, 2.1897, 2.2937, 2.1819, 2.1819,
         1.2674, 1.2812, 1.2831, 1.3053, 1.2527, 1.3511, 1.2656, 1.2553, 1.2352,
         1.2404, 1.2253, 1.2377, 1.2525, 1.2170, 1.2090, 1.2346, 1.2054, 1.2054,
         1.2543, 1.3017, 1.2280, 1.2528, 1.2976, 1.2390, 1.2624, 1.1896, 1.2303,
         1.3654, 1.4001, 1.3846, 1.3725, 1.3848, 1.3215, 1.3682, 1.3751, 1.3191,
         1.3398, 1.2881, 1.2784, 1.2573, 1.3292, 1.2750, 1.3708, 1.2522, 1.2559],
        [1.2735, 1.1808, 0.9965, 1.2214, 1.2904, 1.3240, 1.2479, 1.3153, 1.3153,
         1.4654, 1.7223, 1.4676, 2.1762, 1.5026, 4.3186, 1.5629, 1.3990, 4.0178,
         1.1180, 1.1932, 0.9714, 1.1642, 1.2963, 1.3288, 1.3074, 1.3259, 1.3259,
         1.2938, 1.0381, 1.3465, 1.3250, 1.1320, 1.3593, 1.3781, 1.3096, 1.3270,
         1.3195, 1.4722, 1.3976, 1.3087, 1.3063, 1.4333, 1.3790, 0.5087, 1.3703,
         1.0244, 1.4026, 1.3882, 1.3671, 1.0525, 1.3846, 0.8520, 1.3611, 1.3659],
        [1.2018, 1.2289, 1.2838, 1.2634, 1.2354, 1.2077, 1.2141, 1.2001, 1.2001,
         1.2734, 1.2873, 1.2891, 1.3113, 1.2584, 1.3093, 1.2714, 1.2530, 1.2027,
         2.2503, 2.3055, 2.4061, 2.3538, 2.1424, 2.2226, 2.2521, 2.1301, 2.1301,
         1.2984, 1.2693, 1.2343, 1.2593, 1.2979, 1.2453, 1.2698, 1.2391, 1.2366,
         1.3680, 1.4032, 1.3874, 1.3672, 1.3877, 1.3775, 1.3709, 1.2798, 1.3134,
         1.3017, 1.2942, 1.2843, 1.2629, 1.2524, 1.2813, 1.3325, 1.2576, 1.2614],
        [1.2028, 1.2319, 1.2252, 1.2029, 1.2384, 1.2087, 1.2163, 1.2008, 1.2008,
         1.2714, 1.2270, 1.2874, 1.2896, 1.2555, 1.2637, 1.2692, 1.2578, 1.0874,
         1.2506, 1.2553, 1.2923, 1.2636, 1.2247, 1.1968, 1.2434, 1.2120, 1.2120,
         2.5738, 2.2407, 1.9937, 2.1036, 2.5595, 2.0037, 2.5139, 2.0071, 1.9954,
         1.3521, 1.3884, 1.3436, 1.3350, 1.3736, 1.3484, 1.3515, 1.1782, 1.3009,
         1.3488, 1.2662, 1.1700, 1.2127, 1.3381, 1.1994, 1.3819, 1.2072, 1.2584],
        [1.6341, 1.3114, 0.5713, 0.7789, 1.1281, 1.5237, 1.4610, 1.6311, 1.6311,
         1.4977, 1.2446, 1.3314, 0.8792, 1.5914, 0.2132, 1.4853, 1.6067, 1.1394,
         1.2560, 0.8292, 0.7199, 1.0450, 1.4969, 1.5762, 1.2674, 1.6372, 1.6372,
         0.6696, 0.7892, 1.6019, 1.3880, 0.7631, 1.5420, 1.0650, 1.6503, 1.5846,
         0.4357, 0.2035, 0.1636, 0.3902, 0.6881, 0.8670, 0.3362, 7.7912, 6.5907,
         0.7195, 1.1657, 1.2463, 1.4747, 0.9649, 1.4572, 0.3847, 1.5142, 1.6420],
        [1.2557, 1.2873, 1.3508, 1.3284, 1.2957, 1.2618, 1.2275, 1.2536, 1.2536,
         1.2246, 1.3314, 1.2399, 1.3620, 1.3013, 1.4143, 1.2224, 1.3043, 1.2383,
         1.3065, 1.3381, 1.3501, 1.3189, 1.2786, 1.2680, 1.2389, 1.2648, 1.2648,
         1.3226, 1.3696, 1.2846, 1.1291, 1.2706, 1.1598, 1.3245, 1.1622, 1.2872,
         1.3745, 1.0994, 1.3972, 1.3831, 0.9923, 0.8983, 1.3780, 1.3820, 0.7904,
         2.6158, 2.2139, 2.6380, 2.4104, 1.9199, 1.6612, 2.5005, 2.4828, 1.6434]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 107 : 180.95903673562816
Test loss for epoch 107 : 181.01437181494
Test Precision for epoch 107 : 0.26153846153846155
Test Recall for epoch 107 : 0.26153846153846155
Test F1 for epoch 107 : 0.26153846153846155


theta for epoch 108 : tensor([[2.1892, 2.2187, 2.2914, 2.3592, 2.3230, 2.1953, 2.2997, 2.1874, 2.1874,
         1.2670, 1.2807, 1.2826, 1.3048, 1.2524, 1.3504, 1.2652, 1.2549, 1.2348,
         1.2401, 1.2249, 1.2374, 1.2522, 1.2167, 1.2087, 1.2343, 1.2050, 1.2050,
         1.2540, 1.3014, 1.2275, 1.2524, 1.2974, 1.2385, 1.2621, 1.1891, 1.2297,
         1.3653, 1.4002, 1.3846, 1.3725, 1.3848, 1.3215, 1.3681, 1.3747, 1.3188,
         1.3393, 1.2877, 1.2781, 1.2569, 1.3287, 1.2746, 1.3702, 1.2518, 1.2554],
        [1.2731, 1.1805, 0.9960, 1.2210, 1.2903, 1.3237, 1.2476, 1.3149, 1.3149,
         1.4676, 1.7248, 1.4699, 2.1798, 1.5050, 4.3345, 1.5653, 1.4013, 4.0364,
         1.1178, 1.1929, 0.9714, 1.1639, 1.2959, 1.3284, 1.3070, 1.3255, 1.3255,
         1.2938, 1.0379, 1.3462, 1.3247, 1.1319, 1.3590, 1.3781, 1.3092, 1.3269,
         1.3192, 1.4718, 1.3969, 1.3080, 1.3060, 1.4331, 1.3784, 0.5081, 1.3699,
         1.0240, 1.4024, 1.3880, 1.3667, 1.0521, 1.3843, 0.8518, 1.3608, 1.3655],
        [1.2012, 1.2284, 1.2835, 1.2630, 1.2350, 1.2071, 1.2137, 1.1996, 1.1996,
         1.2729, 1.2870, 1.2886, 1.3109, 1.2580, 1.3091, 1.2710, 1.2527, 1.2025,
         2.2560, 2.3116, 2.4125, 2.3601, 2.1478, 2.2284, 2.2579, 2.1355, 2.1355,
         1.2981, 1.2690, 1.2338, 1.2589, 1.2975, 1.2449, 1.2695, 1.2387, 1.2361,
         1.3679, 1.4032, 1.3874, 1.3672, 1.3877, 1.3776, 1.3709, 1.2796, 1.3133,
         1.3013, 1.2939, 1.2840, 1.2625, 1.2521, 1.2809, 1.3320, 1.2572, 1.2610],
        [1.2021, 1.2312, 1.2257, 1.2034, 1.2379, 1.2080, 1.2157, 1.2002, 1.2002,
         1.2710, 1.2274, 1.2870, 1.2896, 1.2551, 1.2632, 1.2688, 1.2574, 1.0889,
         1.2500, 1.2554, 1.2918, 1.2631, 1.2241, 1.1967, 1.2429, 1.2115, 1.2115,
         2.5786, 2.2477, 1.9999, 2.1099, 2.5645, 2.0099, 2.5189, 2.0132, 2.0016,
         1.3517, 1.3882, 1.3439, 1.3351, 1.3733, 1.3487, 1.3513, 1.1794, 1.3003,
         1.3484, 1.2665, 1.1700, 1.2123, 1.3377, 1.2003, 1.3815, 1.2068, 1.2580],
        [1.6353, 1.3127, 0.5728, 0.7801, 1.1296, 1.5250, 1.4623, 1.6323, 1.6323,
         1.4988, 1.2451, 1.3327, 0.8804, 1.5924, 0.2150, 1.4863, 1.6077, 1.1394,
         1.2574, 0.8308, 0.7215, 1.0466, 1.4982, 1.5771, 1.2691, 1.6385, 1.6385,
         0.6708, 0.7912, 1.6031, 1.3897, 0.7642, 1.5434, 1.0656, 1.6515, 1.5857,
         0.4305, 0.1986, 0.1591, 0.3851, 0.6822, 0.8599, 0.3310, 7.8465, 6.6232,
         0.7216, 1.1670, 1.2479, 1.4759, 0.9668, 1.4574, 0.3868, 1.5155, 1.6429],
        [1.2551, 1.2867, 1.3503, 1.3279, 1.2953, 1.2613, 1.2270, 1.2531, 1.2531,
         1.2245, 1.3315, 1.2399, 1.3618, 1.3013, 1.4140, 1.2223, 1.3042, 1.2381,
         1.3061, 1.3379, 1.3499, 1.3187, 1.2782, 1.2676, 1.2384, 1.2643, 1.2643,
         1.3224, 1.3692, 1.2844, 1.1284, 1.2704, 1.1594, 1.3244, 1.1618, 1.2870,
         1.3741, 1.0985, 1.3970, 1.3828, 0.9914, 0.8974, 1.3778, 1.3813, 0.7894,
         2.6220, 2.2191, 2.6464, 2.4152, 1.9249, 1.6650, 2.5057, 2.4916, 1.6471]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 108 : 180.94615594611747
Test loss for epoch 108 : 181.00172893128735
Test Precision for epoch 108 : 0.26153846153846155
Test Recall for epoch 108 : 0.26153846153846155
Test F1 for epoch 108 : 0.26153846153846155


theta for epoch 109 : tensor([[2.1949, 2.2244, 2.2971, 2.3655, 2.3293, 2.2009, 2.3059, 2.1931, 2.1931,
         1.2664, 1.2802, 1.2819, 1.3042, 1.2519, 1.3496, 1.2646, 1.2544, 1.2342,
         1.2399, 1.2248, 1.2372, 1.2520, 1.2164, 1.2084, 1.2340, 1.2048, 1.2048,
         1.2536, 1.3010, 1.2269, 1.2519, 1.2970, 1.2379, 1.2618, 1.1885, 1.2292,
         1.3651, 1.4001, 1.3844, 1.3722, 1.3847, 1.3214, 1.3680, 1.3742, 1.3185,
         1.3390, 1.2876, 1.2779, 1.2566, 1.3284, 1.2744, 1.3699, 1.2516, 1.2551],
        [1.2729, 1.1804, 0.9957, 1.2208, 1.2903, 1.3234, 1.2474, 1.3147, 1.3147,
         1.4697, 1.7271, 1.4722, 2.1834, 1.5072, 4.3505, 1.5677, 1.4035, 4.0552,
         1.1176, 1.1926, 0.9715, 1.1637, 1.2957, 1.3281, 1.3066, 1.3251, 1.3251,
         1.2936, 1.0375, 1.3457, 1.3243, 1.1318, 1.3586, 1.3780, 1.3088, 1.3266,
         1.3188, 1.4714, 1.3961, 1.3073, 1.3057, 1.4328, 1.3777, 0.5074, 1.3693,
         1.0238, 1.4023, 1.3880, 1.3664, 1.0519, 1.3842, 0.8518, 1.3606, 1.3652],
        [1.2008, 1.2281, 1.2833, 1.2628, 1.2347, 1.2067, 1.2133, 1.1991, 1.1991,
         1.2723, 1.2864, 1.2880, 1.3103, 1.2575, 1.3087, 1.2704, 1.2522, 1.2022,
         2.2617, 2.3178, 2.4189, 2.3665, 2.1533, 2.2342, 2.2638, 2.1410, 2.1410,
         1.2976, 1.2687, 1.2332, 1.2584, 1.2971, 1.2443, 1.2692, 1.2382, 1.2355,
         1.3677, 1.4032, 1.3873, 1.3670, 1.3876, 1.3776, 1.3707, 1.2792, 1.3131,
         1.3012, 1.2937, 1.2838, 1.2622, 1.2518, 1.2807, 1.3316, 1.2570, 1.2607],
        [1.2014, 1.2305, 1.2261, 1.2039, 1.2373, 1.2074, 1.2150, 1.1995, 1.1995,
         1.2703, 1.2277, 1.2863, 1.2893, 1.2545, 1.2625, 1.2681, 1.2568, 1.0903,
         1.2495, 1.2554, 1.2912, 1.2626, 1.2236, 1.1965, 1.2424, 1.2109, 1.2109,
         2.5834, 2.2548, 2.0061, 2.1163, 2.5696, 2.0162, 2.5239, 2.0194, 2.0079,
         1.3511, 1.3879, 1.3440, 1.3351, 1.3728, 1.3488, 1.3510, 1.1806, 1.2997,
         1.3481, 1.2668, 1.1702, 1.2121, 1.3373, 1.2012, 1.3811, 1.2065, 1.2577],
        [1.6365, 1.3140, 0.5743, 0.7814, 1.1310, 1.5262, 1.4636, 1.6335, 1.6335,
         1.4997, 1.2455, 1.3338, 0.8815, 1.5933, 0.2167, 1.4872, 1.6086, 1.1392,
         1.2588, 0.8324, 0.7230, 1.0482, 1.4996, 1.5781, 1.2709, 1.6397, 1.6397,
         0.6719, 0.7930, 1.6042, 1.3913, 0.7651, 1.5447, 1.0662, 1.6527, 1.5866,
         0.4254, 0.1938, 0.1546, 0.3802, 0.6765, 0.8531, 0.3259, 7.9015, 6.6550,
         0.7236, 1.1684, 1.2495, 1.4772, 0.9686, 1.4578, 0.3888, 1.5171, 1.6440],
        [1.2549, 1.2865, 1.3502, 1.3278, 1.2953, 1.2612, 1.2268, 1.2529, 1.2529,
         1.2245, 1.3316, 1.2398, 1.3618, 1.3012, 1.4138, 1.2223, 1.3042, 1.2381,
         1.3060, 1.3379, 1.3500, 1.3187, 1.2781, 1.2675, 1.2381, 1.2642, 1.2642,
         1.3224, 1.3688, 1.2842, 1.1278, 1.2703, 1.1590, 1.3244, 1.1615, 1.2869,
         1.3738, 1.0977, 1.3966, 1.3824, 0.9905, 0.8967, 1.3775, 1.3805, 0.7887,
         2.6279, 2.2241, 2.6546, 2.4198, 1.9295, 1.6684, 2.5107, 2.5001, 1.6505]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 109 : 180.9335204217244
Test loss for epoch 109 : 180.98943512243102
Test Precision for epoch 109 : 0.26153846153846155
Test Recall for epoch 109 : 0.26153846153846155
Test F1 for epoch 109 : 0.26153846153846155


theta for epoch 110 : tensor([[2.2002, 2.2298, 2.3025, 2.3714, 2.3352, 2.2062, 2.3117, 2.1984, 2.1984,
         1.2660, 1.2797, 1.2814, 1.3037, 1.2515, 1.3490, 1.2642, 1.2541, 1.2337,
         1.2395, 1.2244, 1.2368, 1.2517, 1.2160, 1.2080, 1.2336, 1.2043, 1.2043,
         1.2532, 1.3005, 1.2263, 1.2514, 1.2967, 1.2374, 1.2615, 1.1880, 1.2286,
         1.3651, 1.4003, 1.3845, 1.3723, 1.3848, 1.3216, 1.3681, 1.3740, 1.3185,
         1.3388, 1.2875, 1.2778, 1.2565, 1.3283, 1.2742, 1.3696, 1.2514, 1.2550],
        [1.2727, 1.1802, 0.9954, 1.2205, 1.2903, 1.3232, 1.2472, 1.3144, 1.3144,
         1.4717, 1.7292, 1.4743, 2.1869, 1.5093, 4.3666, 1.5700, 1.4055, 4.0739,
         1.1172, 1.1922, 0.9715, 1.1633, 1.2953, 1.3277, 1.3060, 1.3247, 1.3247,
         1.2934, 1.0371, 1.3452, 1.3239, 1.1316, 1.3581, 1.3779, 1.3083, 1.3264,
         1.3186, 1.4711, 1.3956, 1.3068, 1.3055, 1.4327, 1.3772, 0.5070, 1.3690,
         1.0237, 1.4024, 1.3880, 1.3663, 1.0517, 1.3842, 0.8519, 1.3605, 1.3650],
        [1.2003, 1.2278, 1.2830, 1.2625, 1.2344, 1.2063, 1.2130, 1.1987, 1.1987,
         1.2719, 1.2860, 1.2875, 1.3099, 1.2571, 1.3084, 1.2700, 1.2519, 1.2021,
         2.2671, 2.3237, 2.4251, 2.3725, 2.1584, 2.2397, 2.2694, 2.1461, 2.1461,
         1.2972, 1.2684, 1.2326, 1.2579, 1.2967, 1.2438, 1.2689, 1.2376, 1.2350,
         1.3678, 1.4034, 1.3873, 1.3671, 1.3877, 1.3778, 1.3709, 1.2792, 1.3131,
         1.3011, 1.2937, 1.2838, 1.2621, 1.2517, 1.2806, 1.3314, 1.2569, 1.2606],
        [1.2007, 1.2298, 1.2265, 1.2044, 1.2366, 1.2067, 1.2143, 1.1988, 1.1988,
         1.2696, 1.2280, 1.2857, 1.2891, 1.2539, 1.2618, 1.2675, 1.2562, 1.0916,
         1.2487, 1.2553, 1.2904, 1.2618, 1.2228, 1.1962, 1.2417, 1.2102, 1.2102,
         2.5882, 2.2620, 2.0124, 2.1228, 2.5747, 2.0225, 2.5289, 2.0256, 2.0143,
         1.3508, 1.3879, 1.3444, 1.3352, 1.3726, 1.3492, 1.3509, 1.1820, 1.2993,
         1.3477, 1.2671, 1.1703, 1.2118, 1.3369, 1.2022, 1.3807, 1.2062, 1.2574],
        [1.6375, 1.3150, 0.5755, 0.7823, 1.1322, 1.5272, 1.4646, 1.6345, 1.6345,
         1.5004, 1.2455, 1.3347, 0.8822, 1.5940, 0.2181, 1.4879, 1.6093, 1.1388,
         1.2599, 0.8335, 0.7242, 1.0494, 1.5005, 1.5787, 1.2722, 1.6407, 1.6407,
         0.6727, 0.7945, 1.6052, 1.3927, 0.7656, 1.5458, 1.0664, 1.6537, 1.5874,
         0.4207, 0.1894, 0.1506, 0.3757, 0.6712, 0.8469, 0.3213, 7.9565, 6.6866,
         0.7253, 1.1695, 1.2509, 1.4784, 0.9701, 1.4580, 0.3904, 1.5185, 1.6449],
        [1.2547, 1.2863, 1.3500, 1.3276, 1.2953, 1.2611, 1.2267, 1.2527, 1.2527,
         1.2246, 1.3318, 1.2400, 1.3619, 1.3013, 1.4137, 1.2224, 1.3043, 1.2381,
         1.3057, 1.3378, 1.3500, 1.3186, 1.2778, 1.2673, 1.2376, 1.2639, 1.2639,
         1.3223, 1.3684, 1.2840, 1.1272, 1.2701, 1.1586, 1.3244, 1.1612, 1.2867,
         1.3738, 1.0972, 1.3966, 1.3824, 0.9900, 0.8962, 1.3776, 1.3800, 0.7882,
         2.6338, 2.2289, 2.6628, 2.4244, 1.9339, 1.6717, 2.5157, 2.5086, 1.6537]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 110 : 180.9210937490886
Test loss for epoch 110 : 180.97754480667373
Test Precision for epoch 110 : 0.26153846153846155
Test Recall for epoch 110 : 0.26153846153846155
Test F1 for epoch 110 : 0.26153846153846155


theta for epoch 111 : tensor([[2.2054, 2.2350, 2.3078, 2.3773, 2.3410, 2.2115, 2.3174, 2.2036, 2.2036,
         1.2657, 1.2794, 1.2810, 1.3034, 1.2512, 1.3486, 1.2638, 1.2538, 1.2334,
         1.2392, 1.2241, 1.2364, 1.2513, 1.2156, 1.2076, 1.2332, 1.2039, 1.2039,
         1.2528, 1.3001, 1.2257, 1.2508, 1.2963, 1.2368, 1.2611, 1.1874, 1.2281,
         1.3653, 1.4007, 1.3847, 1.3725, 1.3851, 1.3219, 1.3684, 1.3740, 1.3185,
         1.3385, 1.2873, 1.2775, 1.2562, 1.3280, 1.2740, 1.3693, 1.2512, 1.2547],
        [1.2725, 1.1801, 0.9952, 1.2203, 1.2903, 1.3230, 1.2471, 1.3143, 1.3143,
         1.4736, 1.7312, 1.4764, 2.1903, 1.5113, 4.3826, 1.5722, 1.4075, 4.0926,
         1.1170, 1.1919, 0.9716, 1.1630, 1.2950, 1.3274, 1.3056, 1.3244, 1.3244,
         1.2932, 1.0367, 1.3447, 1.3234, 1.1314, 1.3577, 1.3777, 1.3078, 1.3261,
         1.3186, 1.4711, 1.3952, 1.3065, 1.3055, 1.4328, 1.3768, 0.5067, 1.3687,
         1.0235, 1.4023, 1.3879, 1.3661, 1.0514, 1.3841, 0.8519, 1.3603, 1.3648],
        [1.1998, 1.2274, 1.2826, 1.2622, 1.2339, 1.2058, 1.2125, 1.1982, 1.1982,
         1.2715, 1.2857, 1.2871, 1.3095, 1.2568, 1.3083, 1.2696, 1.2517, 1.2020,
         2.2725, 2.3295, 2.4312, 2.3784, 2.1636, 2.2451, 2.2750, 2.1512, 2.1512,
         1.2967, 1.2681, 1.2320, 1.2573, 1.2962, 1.2432, 1.2685, 1.2370, 1.2344,
         1.3680, 1.4038, 1.3875, 1.3673, 1.3880, 1.3782, 1.3711, 1.2793, 1.3132,
         1.3008, 1.2935, 1.2836, 1.2618, 1.2515, 1.2804, 1.3310, 1.2567, 1.2603],
        [1.2000, 1.2291, 1.2269, 1.2049, 1.2360, 1.2060, 1.2137, 1.1981, 1.1981,
         1.2691, 1.2284, 1.2852, 1.2890, 1.2534, 1.2613, 1.2670, 1.2558, 1.0931,
         1.2481, 1.2552, 1.2897, 1.2612, 1.2222, 1.1959, 1.2411, 1.2095, 1.2095,
         2.5929, 2.2691, 2.0186, 2.1292, 2.5797, 2.0288, 2.5338, 2.0317, 2.0205,
         1.3506, 1.3880, 1.3448, 1.3356, 1.3725, 1.3496, 1.3509, 1.1836, 1.2990,
         1.3473, 1.2674, 1.1704, 1.2115, 1.3365, 1.2032, 1.3802, 1.2059, 1.2570],
        [1.6384, 1.3161, 0.5767, 0.7833, 1.1334, 1.5281, 1.4657, 1.6354, 1.6354,
         1.5011, 1.2457, 1.3357, 0.8831, 1.5947, 0.2196, 1.4887, 1.6100, 1.1385,
         1.2610, 0.8347, 0.7254, 1.0506, 1.5016, 1.5793, 1.2737, 1.6416, 1.6416,
         0.6734, 0.7960, 1.6061, 1.3940, 0.7661, 1.5469, 1.0667, 1.6547, 1.5881,
         0.4161, 0.1851, 0.1467, 0.3712, 0.6660, 0.8409, 0.3167, 8.0112, 6.7176,
         0.7268, 1.1705, 1.2521, 1.4795, 0.9715, 1.4581, 0.3919, 1.5199, 1.6458],
        [1.2543, 1.2859, 1.3495, 1.3272, 1.2950, 1.2609, 1.2264, 1.2523, 1.2523,
         1.2245, 1.3318, 1.2399, 1.3619, 1.3013, 1.4135, 1.2223, 1.3042, 1.2381,
         1.3054, 1.3375, 1.3499, 1.3183, 1.2775, 1.2670, 1.2370, 1.2636, 1.2636,
         1.3221, 1.3679, 1.2837, 1.1265, 1.2698, 1.1580, 1.3242, 1.1607, 1.2863,
         1.3738, 1.0967, 1.3966, 1.3824, 0.9895, 0.8957, 1.3777, 1.3796, 0.7877,
         2.6399, 2.2340, 2.6711, 2.4292, 1.9385, 1.6751, 2.5209, 2.5171, 1.6571]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 111 : 180.90891015200884
Test loss for epoch 111 : 180.96581656161862
Test Precision for epoch 111 : 0.26153846153846155
Test Recall for epoch 111 : 0.26153846153846155
Test F1 for epoch 111 : 0.26153846153846155


theta for epoch 112 : tensor([[2.2110, 2.2406, 2.3134, 2.3834, 2.3472, 2.2170, 2.3235, 2.2092, 2.2092,
         1.2653, 1.2791, 1.2805, 1.3030, 1.2509, 1.3481, 1.2635, 1.2535, 1.2330,
         1.2390, 1.2239, 1.2361, 1.2511, 1.2152, 1.2073, 1.2329, 1.2035, 1.2035,
         1.2524, 1.2996, 1.2251, 1.2503, 1.2959, 1.2362, 1.2608, 1.1868, 1.2275,
         1.3653, 1.4009, 1.3847, 1.3725, 1.3853, 1.3220, 1.3685, 1.3738, 1.3185,
         1.3379, 1.2868, 1.2770, 1.2556, 1.3274, 1.2735, 1.3686, 1.2507, 1.2541],
        [1.2724, 1.1802, 0.9952, 1.2202, 1.2904, 1.3231, 1.2471, 1.3143, 1.3143,
         1.4754, 1.7331, 1.4784, 2.1937, 1.5133, 4.3987, 1.5743, 1.4094, 4.1113,
         1.1169, 1.1918, 0.9720, 1.1630, 1.2950, 1.3273, 1.3054, 1.3243, 1.3243,
         1.2931, 1.0364, 1.3443, 1.3231, 1.1314, 1.3573, 1.3777, 1.3074, 1.3259,
         1.3184, 1.4709, 1.3948, 1.3060, 1.3054, 1.4328, 1.3764, 0.5064, 1.3684,
         1.0231, 1.4020, 1.3876, 1.3656, 1.0510, 1.3838, 0.8517, 1.3599, 1.3644],
        [1.1994, 1.2270, 1.2823, 1.2618, 1.2336, 1.2053, 1.2122, 1.1977, 1.1977,
         1.2711, 1.2854, 1.2867, 1.3091, 1.2565, 1.3082, 1.2693, 1.2514, 1.2018,
         2.2781, 2.3356, 2.4375, 2.3847, 2.1690, 2.2508, 2.2808, 2.1566, 2.1566,
         1.2963, 1.2677, 1.2315, 1.2568, 1.2958, 1.2426, 1.2681, 1.2365, 1.2339,
         1.3680, 1.4040, 1.3876, 1.3674, 1.3882, 1.3784, 1.3713, 1.2793, 1.3132,
         1.3004, 1.2930, 1.2831, 1.2613, 1.2511, 1.2799, 1.3304, 1.2562, 1.2598],
        [1.1995, 1.2286, 1.2275, 1.2056, 1.2356, 1.2056, 1.2133, 1.1977, 1.1977,
         1.2687, 1.2290, 1.2849, 1.2891, 1.2531, 1.2609, 1.2667, 1.2554, 1.0948,
         1.2476, 1.2554, 1.2893, 1.2608, 1.2217, 1.1959, 1.2407, 1.2091, 1.2091,
         2.5975, 2.2761, 2.0247, 2.1356, 2.5846, 2.0350, 2.5386, 2.0378, 2.0267,
         1.3504, 1.3880, 1.3453, 1.3359, 1.3725, 1.3501, 1.3509, 1.1852, 1.2988,
         1.3468, 1.2675, 1.1704, 1.2111, 1.3359, 1.2040, 1.3797, 1.2055, 1.2566],
        [1.6396, 1.3175, 0.5782, 0.7846, 1.1349, 1.5294, 1.4670, 1.6367, 1.6367,
         1.5021, 1.2461, 1.3369, 0.8843, 1.5957, 0.2215, 1.4897, 1.6110, 1.1385,
         1.2625, 0.8364, 0.7270, 1.0523, 1.5029, 1.5802, 1.2754, 1.6429, 1.6429,
         0.6745, 0.7978, 1.6072, 1.3956, 0.7669, 1.5482, 1.0673, 1.6559, 1.5891,
         0.4113, 0.1807, 0.1426, 0.3666, 0.6607, 0.8348, 0.3120, 8.0654, 6.7478,
         0.7284, 1.1715, 1.2534, 1.4806, 0.9729, 1.4583, 0.3936, 1.5212, 1.6467],
        [1.2538, 1.2854, 1.3490, 1.3266, 1.2946, 1.2605, 1.2259, 1.2519, 1.2519,
         1.2242, 1.3317, 1.2396, 1.3616, 1.3010, 1.4131, 1.2219, 1.3039, 1.2377,
         1.3049, 1.3371, 1.3496, 1.3180, 1.2770, 1.2665, 1.2363, 1.2631, 1.2631,
         1.3217, 1.3673, 1.2832, 1.1256, 1.2693, 1.1573, 1.3239, 1.1601, 1.2859,
         1.3736, 1.0959, 1.3964, 1.3822, 0.9887, 0.8950, 1.3775, 1.3790, 0.7870,
         2.6464, 2.2393, 2.6797, 2.4343, 1.9432, 1.6788, 2.5264, 2.5260, 1.6606]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 112 : 180.896888766899
Test loss for epoch 112 : 180.9539899376765
Test Precision for epoch 112 : 0.26153846153846155
Test Recall for epoch 112 : 0.26153846153846155
Test F1 for epoch 112 : 0.26153846153846155


theta for epoch 113 : tensor([[2.2165, 2.2462, 2.3190, 2.3895, 2.3533, 2.2225, 2.3296, 2.2147, 2.2147,
         1.2650, 1.2788, 1.2802, 1.3028, 1.2507, 1.3477, 1.2632, 1.2532, 1.2327,
         1.2386, 1.2235, 1.2356, 1.2507, 1.2148, 1.2068, 1.2324, 1.2030, 1.2030,
         1.2522, 1.2993, 1.2248, 1.2500, 1.2958, 1.2359, 1.2607, 1.1865, 1.2272,
         1.3654, 1.4011, 1.3848, 1.3726, 1.3854, 1.3221, 1.3686, 1.3737, 1.3184,
         1.3372, 1.2862, 1.2764, 1.2549, 1.3268, 1.2729, 1.3679, 1.2500, 1.2534],
        [1.2723, 1.1801, 0.9951, 1.2201, 1.2905, 1.3230, 1.2470, 1.3142, 1.3142,
         1.4774, 1.7350, 1.4804, 2.1972, 1.5153, 4.4150, 1.5766, 1.4113, 4.1302,
         1.1167, 1.1916, 0.9722, 1.1628, 1.2949, 1.3272, 1.3052, 1.3241, 1.3241,
         1.2931, 1.0362, 1.3441, 1.3229, 1.1316, 1.3571, 1.3778, 1.3071, 1.3259,
         1.3183, 1.4708, 1.3943, 1.3056, 1.3053, 1.4328, 1.3760, 0.5060, 1.3681,
         1.0226, 1.4015, 1.3871, 1.3650, 1.0504, 1.3833, 0.8514, 1.3594, 1.3638],
        [1.1989, 1.2265, 1.2818, 1.2614, 1.2330, 1.2047, 1.2117, 1.1971, 1.1971,
         1.2709, 1.2852, 1.2863, 1.3089, 1.2563, 1.3081, 1.2690, 1.2512, 1.2018,
         2.2836, 2.3416, 2.4438, 2.3908, 2.1743, 2.2565, 2.2865, 2.1619, 2.1619,
         1.2961, 1.2677, 1.2311, 1.2565, 1.2956, 1.2423, 1.2680, 1.2362, 1.2336,
         1.3681, 1.4043, 1.3877, 1.3675, 1.3884, 1.3787, 1.3714, 1.2793, 1.3132,
         1.2997, 1.2924, 1.2825, 1.2607, 1.2505, 1.2794, 1.3297, 1.2556, 1.2591],
        [1.1991, 1.2281, 1.2282, 1.2064, 1.2351, 1.2052, 1.2128, 1.1972, 1.1972,
         1.2684, 1.2298, 1.2846, 1.2892, 1.2528, 1.2607, 1.2664, 1.2552, 1.0965,
         1.2472, 1.2556, 1.2888, 1.2603, 1.2213, 1.1959, 1.2402, 1.2087, 1.2087,
         2.6021, 2.2832, 2.0309, 2.1420, 2.5894, 2.0413, 2.5434, 2.0439, 2.0329,
         1.3503, 1.3882, 1.3458, 1.3363, 1.3725, 1.3506, 1.3510, 1.1869, 1.2985,
         1.3462, 1.2675, 1.1702, 1.2106, 1.3353, 1.2048, 1.3790, 1.2050, 1.2561],
        [1.6408, 1.3189, 0.5798, 0.7859, 1.1365, 1.5307, 1.4684, 1.6379, 1.6379,
         1.5032, 1.2467, 1.3383, 0.8856, 1.5968, 0.2237, 1.4909, 1.6121, 1.1386,
         1.2641, 0.8380, 0.7287, 1.0539, 1.5042, 1.5811, 1.2772, 1.6441, 1.6441,
         0.6758, 0.7997, 1.6085, 1.3974, 0.7679, 1.5497, 1.0680, 1.6573, 1.5902,
         0.4065, 0.1763, 0.1385, 0.3619, 0.6553, 0.8289, 0.3072, 8.1193, 6.7773,
         0.7299, 1.1724, 1.2545, 1.4816, 0.9742, 1.4584, 0.3953, 1.5225, 1.6476],
        [1.2532, 1.2847, 1.3482, 1.3259, 1.2941, 1.2599, 1.2253, 1.2512, 1.2512,
         1.2238, 1.3315, 1.2393, 1.3613, 1.3006, 1.4127, 1.2214, 1.3035, 1.2374,
         1.3042, 1.3365, 1.3493, 1.3174, 1.2763, 1.2659, 1.2355, 1.2625, 1.2625,
         1.3214, 1.3668, 1.2828, 1.1248, 1.2690, 1.1568, 1.3237, 1.1595, 1.2855,
         1.3734, 1.0951, 1.3961, 1.3820, 0.9879, 0.8941, 1.3773, 1.3784, 0.7861,
         2.6531, 2.2447, 2.6885, 2.4395, 1.9479, 1.6824, 2.5321, 2.5349, 1.6642]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 113 : 180.88509060830265
Test loss for epoch 113 : 180.94237350527206
Test Precision for epoch 113 : 0.26153846153846155
Test Recall for epoch 113 : 0.26153846153846155
Test F1 for epoch 113 : 0.26153846153846155


theta for epoch 114 : tensor([[2.2218, 2.2515, 2.3243, 2.3954, 2.3592, 2.2278, 2.3354, 2.2200, 2.2200,
         1.2647, 1.2785, 1.2798, 1.3025, 1.2504, 1.3474, 1.2628, 1.2529, 1.2324,
         1.2381, 1.2230, 1.2351, 1.2503, 1.2143, 1.2063, 1.2319, 1.2025, 1.2025,
         1.2521, 1.2991, 1.2245, 1.2498, 1.2956, 1.2356, 1.2606, 1.1863, 1.2270,
         1.3655, 1.4014, 1.3849, 1.3727, 1.3857, 1.3224, 1.3688, 1.3737, 1.3184,
         1.3366, 1.2857, 1.2758, 1.2544, 1.3262, 1.2724, 1.3672, 1.2495, 1.2529],
        [1.2721, 1.1800, 0.9950, 1.2199, 1.2904, 1.3228, 1.2468, 1.3140, 1.3140,
         1.4792, 1.7368, 1.4823, 2.2006, 1.5172, 4.4314, 1.5787, 1.4132, 4.1491,
         1.1165, 1.1914, 0.9724, 1.1626, 1.2948, 1.3271, 1.3049, 1.3239, 1.3239,
         1.2932, 1.0361, 1.3439, 1.3228, 1.1317, 1.3569, 1.3779, 1.3069, 1.3259,
         1.3183, 1.4708, 1.3939, 1.3053, 1.3053, 1.4329, 1.3757, 0.5058, 1.3678,
         1.0221, 1.4011, 1.3867, 1.3645, 1.0499, 1.3829, 0.8512, 1.3589, 1.3633],
        [1.1983, 1.2259, 1.2812, 1.2609, 1.2325, 1.2042, 1.2111, 1.1966, 1.1966,
         1.2706, 1.2850, 1.2860, 1.3086, 1.2560, 1.3080, 1.2687, 1.2510, 1.2018,
         2.2890, 2.3473, 2.4499, 2.3967, 2.1794, 2.2619, 2.2921, 2.1670, 2.1670,
         1.2960, 1.2676, 1.2309, 1.2563, 1.2955, 1.2421, 1.2680, 1.2360, 1.2334,
         1.3683, 1.4046, 1.3879, 1.3677, 1.3887, 1.3790, 1.3717, 1.2795, 1.3133,
         1.2992, 1.2919, 1.2819, 1.2601, 1.2501, 1.2789, 1.3292, 1.2551, 1.2586],
        [1.1986, 1.2276, 1.2288, 1.2071, 1.2347, 1.2047, 1.2123, 1.1967, 1.1967,
         1.2681, 1.2305, 1.2843, 1.2894, 1.2526, 1.2604, 1.2661, 1.2549, 1.0982,
         1.2467, 1.2557, 1.2883, 1.2598, 1.2209, 1.1959, 1.2398, 1.2083, 1.2083,
         2.6067, 2.2902, 2.0371, 2.1484, 2.5943, 2.0475, 2.5482, 2.0500, 2.0391,
         1.3503, 1.3884, 1.3464, 1.3368, 1.3725, 1.3511, 1.3511, 1.1887, 1.2985,
         1.3456, 1.2676, 1.1702, 1.2102, 1.3347, 1.2057, 1.3784, 1.2045, 1.2556],
        [1.6418, 1.3201, 0.5811, 0.7869, 1.1378, 1.5317, 1.4695, 1.6389, 1.6389,
         1.5041, 1.2469, 1.3393, 0.8866, 1.5977, 0.2255, 1.4918, 1.6129, 1.1384,
         1.2654, 0.8393, 0.7301, 1.0553, 1.5053, 1.5818, 1.2787, 1.6452, 1.6452,
         0.6768, 0.8014, 1.6098, 1.3990, 0.7686, 1.5510, 1.0686, 1.6586, 1.5913,
         0.4020, 0.1722, 0.1348, 0.3576, 0.6504, 0.8234, 0.3028, 8.1732, 6.8065,
         0.7311, 1.1730, 1.2554, 1.4825, 0.9752, 1.4583, 0.3966, 1.5237, 1.6483],
        [1.2526, 1.2841, 1.3475, 1.3253, 1.2935, 1.2594, 1.2248, 1.2507, 1.2507,
         1.2233, 1.3312, 1.2389, 1.3610, 1.3002, 1.4123, 1.2210, 1.3031, 1.2370,
         1.3036, 1.3359, 1.3489, 1.3169, 1.2758, 1.2654, 1.2347, 1.2619, 1.2619,
         1.3212, 1.3664, 1.2825, 1.1241, 1.2688, 1.1564, 1.3236, 1.1591, 1.2852,
         1.3733, 1.0944, 1.3960, 1.3819, 0.9873, 0.8935, 1.3773, 1.3780, 0.7855,
         2.6596, 2.2499, 2.6971, 2.4446, 1.9524, 1.6858, 2.5376, 2.5436, 1.6676]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 114 : 180.87349998329913
Test loss for epoch 114 : 180.93113827410488
Test Precision for epoch 114 : 0.26153846153846155
Test Recall for epoch 114 : 0.26153846153846155
Test F1 for epoch 114 : 0.26153846153846155


theta for epoch 115 : tensor([[2.2271, 2.2568, 2.3297, 2.4014, 2.3651, 2.2332, 2.3413, 2.2254, 2.2254,
         1.2643, 1.2781, 1.2793, 1.3021, 1.2499, 1.3469, 1.2624, 1.2525, 1.2319,
         1.2378, 1.2227, 1.2346, 1.2499, 1.2139, 1.2059, 1.2315, 1.2021, 1.2021,
         1.2517, 1.2986, 1.2241, 1.2493, 1.2953, 1.2351, 1.2604, 1.1858, 1.2265,
         1.3656, 1.4016, 1.3850, 1.3728, 1.3859, 1.3225, 1.3689, 1.3737, 1.3184,
         1.3362, 1.2853, 1.2755, 1.2540, 1.3258, 1.2721, 1.3668, 1.2491, 1.2525],
        [1.2720, 1.1799, 0.9950, 1.2199, 1.2905, 1.3228, 1.2467, 1.3139, 1.3139,
         1.4809, 1.7385, 1.4842, 2.2039, 1.5190, 4.4478, 1.5808, 1.4149, 4.1681,
         1.1163, 1.1912, 0.9727, 1.1624, 1.2947, 1.3270, 1.3047, 1.3239, 1.3239,
         1.2930, 1.0357, 1.3435, 1.3224, 1.1317, 1.3564, 1.3778, 1.3065, 1.3257,
         1.3182, 1.4707, 1.3935, 1.3049, 1.3052, 1.4329, 1.3754, 0.5054, 1.3675,
         1.0219, 1.4009, 1.3864, 1.3642, 1.0496, 1.3827, 0.8512, 1.3586, 1.3630],
        [1.1979, 1.2255, 1.2807, 1.2604, 1.2320, 1.2037, 1.2107, 1.1961, 1.1961,
         1.2702, 1.2846, 1.2855, 1.3082, 1.2556, 1.3079, 1.2682, 1.2506, 1.2016,
         2.2943, 2.3532, 2.4560, 2.4027, 2.1846, 2.2674, 2.2977, 2.1722, 2.1722,
         1.2956, 1.2673, 1.2304, 1.2558, 1.2951, 1.2416, 1.2677, 1.2355, 1.2329,
         1.3684, 1.4049, 1.3880, 1.3678, 1.3890, 1.3793, 1.3718, 1.2796, 1.3132,
         1.2989, 1.2916, 1.2816, 1.2598, 1.2498, 1.2786, 1.3288, 1.2547, 1.2583],
        [1.1982, 1.2272, 1.2295, 1.2079, 1.2343, 1.2044, 1.2120, 1.1964, 1.1964,
         1.2677, 1.2311, 1.2839, 1.2894, 1.2522, 1.2600, 1.2657, 1.2545, 1.0999,
         1.2464, 1.2558, 1.2878, 1.2594, 1.2206, 1.1960, 1.2394, 1.2080, 1.2080,
         2.6112, 2.2972, 2.0432, 2.1548, 2.5990, 2.0536, 2.5529, 2.0560, 2.0453,
         1.3503, 1.3886, 1.3469, 1.3372, 1.3726, 1.3517, 1.3513, 1.1906, 1.2984,
         1.3453, 1.2679, 1.1702, 1.2099, 1.3343, 1.2067, 1.3780, 1.2042, 1.2553],
        [1.6428, 1.3212, 0.5823, 0.7879, 1.1390, 1.5327, 1.4706, 1.6398, 1.6398,
         1.5047, 1.2469, 1.3401, 0.8873, 1.5983, 0.2271, 1.4925, 1.6135, 1.1379,
         1.2666, 0.8405, 0.7314, 1.0566, 1.5064, 1.5825, 1.2801, 1.6462, 1.6462,
         0.6775, 0.8029, 1.6107, 1.4004, 0.7690, 1.5521, 1.0690, 1.6596, 1.5921,
         0.3977, 0.1683, 0.1312, 0.3535, 0.6456, 0.8182, 0.2986, 8.2269, 6.8352,
         0.7323, 1.1737, 1.2564, 1.4835, 0.9762, 1.4584, 0.3979, 1.5250, 1.6492],
        [1.2523, 1.2838, 1.3471, 1.3249, 1.2933, 1.2592, 1.2245, 1.2504, 1.2504,
         1.2229, 1.3311, 1.2386, 1.3607, 1.2998, 1.4120, 1.2206, 1.3027, 1.2367,
         1.3033, 1.3356, 1.3488, 1.3166, 1.2754, 1.2651, 1.2341, 1.2616, 1.2616,
         1.3209, 1.3659, 1.2821, 1.1233, 1.2685, 1.1559, 1.3234, 1.1585, 1.2848,
         1.3732, 1.0938, 1.3959, 1.3818, 0.9868, 0.8929, 1.3773, 1.3776, 0.7849,
         2.6660, 2.2549, 2.7056, 2.4496, 1.9566, 1.6891, 2.5431, 2.5522, 1.6708]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 115 : 180.86209736628768
Test loss for epoch 115 : 180.92019144393464
Test Precision for epoch 115 : 0.26153846153846155
Test Recall for epoch 115 : 0.26153846153846155
Test F1 for epoch 115 : 0.26153846153846155


theta for epoch 116 : tensor([[2.2325, 2.2622, 2.3350, 2.4073, 2.3710, 2.2385, 2.3472, 2.2307, 2.2307,
         1.2639, 1.2778, 1.2789, 1.3018, 1.2496, 1.3466, 1.2620, 1.2521, 1.2315,
         1.2374, 1.2223, 1.2341, 1.2495, 1.2135, 1.2054, 1.2311, 1.2016, 1.2016,
         1.2513, 1.2980, 1.2235, 1.2488, 1.2948, 1.2345, 1.2600, 1.1853, 1.2260,
         1.3655, 1.4017, 1.3848, 1.3727, 1.3859, 1.3225, 1.3688, 1.3734, 1.3182,
         1.3360, 1.2852, 1.2753, 1.2538, 1.3257, 1.2720, 1.3666, 1.2489, 1.2523],
        [1.2718, 1.1797, 0.9949, 1.2197, 1.2904, 1.3226, 1.2464, 1.3138, 1.3138,
         1.4829, 1.7404, 1.4862, 2.2075, 1.5210, 4.4644, 1.5830, 1.4168, 4.1873,
         1.1160, 1.1910, 0.9728, 1.1622, 1.2946, 1.3269, 1.3044, 1.3237, 1.3237,
         1.2926, 1.0351, 1.3429, 1.3219, 1.1314, 1.3559, 1.3776, 1.3059, 1.3254,
         1.3179, 1.4704, 1.3929, 1.3043, 1.3049, 1.4327, 1.3749, 0.5047, 1.3669,
         1.0218, 1.4008, 1.3864, 1.3641, 1.0494, 1.3827, 0.8513, 1.3584, 1.3629],
        [1.1974, 1.2250, 1.2801, 1.2599, 1.2315, 1.2032, 1.2103, 1.1957, 1.1957,
         1.2698, 1.2844, 1.2851, 1.3079, 1.2552, 1.3077, 1.2679, 1.2503, 1.2014,
         2.2998, 2.3591, 2.4622, 2.4087, 2.1898, 2.2730, 2.3033, 2.1775, 2.1775,
         1.2951, 1.2669, 1.2299, 1.2553, 1.2947, 1.2410, 1.2672, 1.2350, 1.2324,
         1.3684, 1.4050, 1.3879, 1.3677, 1.3890, 1.3794, 1.3718, 1.2794, 1.3130,
         1.2988, 1.2915, 1.2814, 1.2596, 1.2498, 1.2785, 1.3287, 1.2546, 1.2581],
        [1.1978, 1.2267, 1.2301, 1.2086, 1.2339, 1.2040, 1.2116, 1.1960, 1.1960,
         1.2673, 1.2317, 1.2836, 1.2895, 1.2518, 1.2597, 1.2653, 1.2542, 1.1015,
         1.2459, 1.2559, 1.2873, 1.2590, 1.2202, 1.1960, 1.2390, 1.2076, 1.2076,
         2.6157, 2.3043, 2.0493, 2.1612, 2.6037, 2.0598, 2.5576, 2.0621, 2.0515,
         1.3501, 1.3887, 1.3473, 1.3376, 1.3725, 1.3520, 1.3512, 1.1923, 1.2981,
         1.3450, 1.2682, 1.1704, 1.2097, 1.3340, 1.2078, 1.3778, 1.2041, 1.2552],
        [1.6438, 1.3225, 0.5835, 0.7889, 1.1402, 1.5338, 1.4718, 1.6409, 1.6409,
         1.5055, 1.2470, 1.3411, 0.8882, 1.5991, 0.2289, 1.4933, 1.6143, 1.1376,
         1.2679, 0.8418, 0.7329, 1.0580, 1.5075, 1.5833, 1.2816, 1.6472, 1.6472,
         0.6783, 0.8044, 1.6117, 1.4018, 0.7695, 1.5531, 1.0693, 1.6607, 1.5929,
         0.3933, 0.1644, 0.1276, 0.3493, 0.6407, 0.8129, 0.2944, 8.2802, 6.8632,
         0.7337, 1.1746, 1.2575, 1.4847, 0.9775, 1.4587, 0.3995, 1.5265, 1.6504],
        [1.2522, 1.2836, 1.3468, 1.3246, 1.2931, 1.2591, 1.2244, 1.2503, 1.2503,
         1.2227, 1.3311, 1.2385, 1.3606, 1.2996, 1.4120, 1.2203, 1.3025, 1.2367,
         1.3030, 1.3353, 1.3487, 1.3165, 1.2752, 1.2649, 1.2336, 1.2614, 1.2614,
         1.3206, 1.3654, 1.2817, 1.1225, 1.2682, 1.1554, 1.3232, 1.1580, 1.2845,
         1.3730, 1.0931, 1.3956, 1.3816, 0.9861, 0.8922, 1.3771, 1.3770, 0.7842,
         2.6725, 2.2599, 2.7140, 2.4546, 1.9607, 1.6922, 2.5485, 2.5606, 1.6738]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 116 : 180.85087558156044
Test loss for epoch 116 : 180.90944655898443
Test Precision for epoch 116 : 0.26153846153846155
Test Recall for epoch 116 : 0.26153846153846155
Test F1 for epoch 116 : 0.26153846153846155


theta for epoch 117 : tensor([[2.2379, 2.2675, 2.3404, 2.4133, 2.3769, 2.2439, 2.3530, 2.2361, 2.2361,
         1.2636, 1.2775, 1.2785, 1.3015, 1.2492, 1.3463, 1.2617, 1.2517, 1.2312,
         1.2369, 1.2217, 1.2335, 1.2490, 1.2129, 1.2049, 1.2305, 1.2011, 1.2011,
         1.2510, 1.2975, 1.2232, 1.2484, 1.2944, 1.2341, 1.2598, 1.1849, 1.2257,
         1.3654, 1.4017, 1.3846, 1.3726, 1.3859, 1.3224, 1.3687, 1.3732, 1.3179,
         1.3358, 1.2850, 1.2751, 1.2536, 1.3256, 1.2719, 1.3665, 1.2487, 1.2522],
        [1.2715, 1.1795, 0.9948, 1.2194, 1.2903, 1.3223, 1.2461, 1.3135, 1.3135,
         1.4847, 1.7421, 1.4882, 2.2109, 1.5229, 4.4812, 1.5852, 1.4187, 4.2065,
         1.1157, 1.1907, 0.9729, 1.1618, 1.2944, 1.3267, 1.3041, 1.3235, 1.3235,
         1.2924, 1.0346, 1.3426, 1.3215, 1.1314, 1.3555, 1.3775, 1.3056, 1.3253,
         1.3175, 1.4701, 1.3923, 1.3037, 1.3046, 1.4325, 1.3743, 0.5040, 1.3662,
         1.0218, 1.4007, 1.3863, 1.3640, 1.0493, 1.3827, 0.8515, 1.3583, 1.3628],
        [1.1969, 1.2244, 1.2794, 1.2593, 1.2309, 1.2026, 1.2097, 1.1951, 1.1951,
         1.2695, 1.2841, 1.2847, 1.3075, 1.2549, 1.3076, 1.2675, 1.2499, 1.2013,
         2.3051, 2.3649, 2.4683, 2.4146, 2.1950, 2.2786, 2.3089, 2.1827, 2.1827,
         1.2948, 1.2666, 1.2295, 1.2549, 1.2944, 1.2406, 1.2670, 1.2346, 1.2320,
         1.3683, 1.4050, 1.3877, 1.3675, 1.3891, 1.3794, 1.3717, 1.2793, 1.3127,
         1.2987, 1.2913, 1.2812, 1.2594, 1.2498, 1.2784, 1.3285, 1.2544, 1.2580],
        [1.1972, 1.2261, 1.2306, 1.2092, 1.2332, 1.2034, 1.2110, 1.1954, 1.1954,
         1.2668, 1.2323, 1.2830, 1.2895, 1.2513, 1.2592, 1.2648, 1.2536, 1.1030,
         1.2453, 1.2558, 1.2866, 1.2583, 1.2196, 1.1958, 1.2383, 1.2071, 1.2071,
         2.6204, 2.3116, 2.0557, 2.1678, 2.6086, 2.0662, 2.5624, 2.0684, 2.0579,
         1.3498, 1.3886, 1.3476, 1.3378, 1.3724, 1.3522, 1.3511, 1.1939, 1.2978,
         1.3447, 1.2685, 1.1704, 1.2094, 1.3337, 1.2089, 1.3774, 1.2038, 1.2549],
        [1.6449, 1.3237, 0.5848, 0.7900, 1.1415, 1.5350, 1.4731, 1.6420, 1.6420,
         1.5064, 1.2472, 1.3421, 0.8892, 1.5999, 0.2308, 1.4942, 1.6151, 1.1374,
         1.2693, 0.8431, 0.7343, 1.0594, 1.5086, 1.5840, 1.2831, 1.6483, 1.6483,
         0.6793, 0.8060, 1.6129, 1.4034, 0.7702, 1.5543, 1.0699, 1.6619, 1.5939,
         0.3889, 0.1605, 0.1240, 0.3450, 0.6357, 0.8077, 0.2901, 8.3332, 6.8906,
         0.7353, 1.1755, 1.2587, 1.4860, 0.9788, 1.4590, 0.4012, 1.5280, 1.6516],
        [1.2520, 1.2834, 1.3465, 1.3244, 1.2929, 1.2590, 1.2242, 1.2501, 1.2501,
         1.2225, 1.3311, 1.2384, 1.3606, 1.2994, 1.4119, 1.2201, 1.3023, 1.2366,
         1.3027, 1.3350, 1.3486, 1.3162, 1.2749, 1.2647, 1.2331, 1.2611, 1.2611,
         1.3205, 1.3651, 1.2814, 1.1220, 1.2681, 1.1552, 1.3231, 1.1577, 1.2842,
         1.3728, 1.0923, 1.3953, 1.3814, 0.9854, 0.8914, 1.3769, 1.3765, 0.7834,
         2.6789, 2.2648, 2.7223, 2.4595, 1.9647, 1.6952, 2.5539, 2.5689, 1.6768]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 117 : 180.83985035150013
Test loss for epoch 117 : 180.89888215445768
Test Precision for epoch 117 : 0.26153846153846155
Test Recall for epoch 117 : 0.26153846153846155
Test F1 for epoch 117 : 0.26153846153846155


theta for epoch 118 : tensor([[2.2432, 2.2729, 2.3457, 2.4192, 2.3828, 2.2492, 2.3589, 2.2414, 2.2414,
         1.2632, 1.2772, 1.2781, 1.3012, 1.2488, 1.3460, 1.2612, 1.2513, 1.2308,
         1.2364, 1.2212, 1.2328, 1.2485, 1.2124, 1.2044, 1.2300, 1.2005, 1.2005,
         1.2506, 1.2971, 1.2228, 1.2480, 1.2941, 1.2338, 1.2595, 1.1846, 1.2253,
         1.3654, 1.4018, 1.3845, 1.3726, 1.3861, 1.3224, 1.3687, 1.3730, 1.3178,
         1.3355, 1.2847, 1.2747, 1.2533, 1.3252, 1.2716, 1.3661, 1.2484, 1.2518],
        [1.2713, 1.1794, 0.9949, 1.2194, 1.2903, 1.3222, 1.2459, 1.3134, 1.3134,
         1.4863, 1.7435, 1.4898, 2.2141, 1.5245, 4.4978, 1.5870, 1.4202, 4.2256,
         1.1155, 1.1906, 0.9731, 1.1617, 1.2943, 1.3267, 1.3039, 1.3235, 1.3235,
         1.2924, 1.0343, 1.3424, 1.3213, 1.1315, 1.3553, 1.3776, 1.3053, 1.3252,
         1.3174, 1.4700, 1.3918, 1.3032, 1.3045, 1.4324, 1.3739, 0.5036, 1.3657,
         1.0217, 1.4005, 1.3861, 1.3637, 1.0491, 1.3826, 0.8517, 1.3580, 1.3626],
        [1.1964, 1.2238, 1.2787, 1.2587, 1.2304, 1.2021, 1.2092, 1.1946, 1.1946,
         1.2691, 1.2838, 1.2842, 1.3072, 1.2544, 1.3074, 1.2671, 1.2495, 1.2011,
         2.3105, 2.3707, 2.4743, 2.4205, 2.2002, 2.2841, 2.3145, 2.1879, 2.1879,
         1.2945, 1.2663, 1.2291, 1.2545, 1.2941, 1.2402, 1.2667, 1.2342, 1.2316,
         1.3683, 1.4052, 1.3877, 1.3675, 1.3892, 1.3795, 1.3718, 1.2793, 1.3125,
         1.2984, 1.2910, 1.2809, 1.2591, 1.2497, 1.2781, 1.3283, 1.2540, 1.2576],
        [1.1967, 1.2255, 1.2311, 1.2098, 1.2326, 1.2029, 1.2105, 1.1949, 1.1949,
         1.2663, 1.2328, 1.2825, 1.2894, 1.2507, 1.2587, 1.2643, 1.2531, 1.1044,
         1.2447, 1.2558, 1.2860, 1.2577, 1.2191, 1.1957, 1.2377, 1.2066, 1.2066,
         2.6250, 2.3188, 2.0620, 2.1745, 2.6135, 2.0726, 2.5672, 2.0747, 2.0642,
         1.3498, 1.3888, 1.3480, 1.3382, 1.3724, 1.3526, 1.3512, 1.1957, 1.2976,
         1.3442, 1.2686, 1.1703, 1.2091, 1.3332, 1.2098, 1.3770, 1.2034, 1.2545],
        [1.6459, 1.3250, 0.5860, 0.7910, 1.1427, 1.5361, 1.4742, 1.6430, 1.6430,
         1.5071, 1.2472, 1.3430, 0.8899, 1.6005, 0.2325, 1.4950, 1.6158, 1.1370,
         1.2706, 0.8444, 0.7357, 1.0608, 1.5097, 1.5848, 1.2846, 1.6493, 1.6493,
         0.6801, 0.8076, 1.6140, 1.4049, 0.7707, 1.5554, 1.0704, 1.6631, 1.5949,
         0.3846, 0.1567, 0.1206, 0.3410, 0.6310, 0.8028, 0.2860, 8.3861, 6.9175,
         0.7366, 1.1761, 1.2596, 1.4869, 0.9797, 1.4591, 0.4027, 1.5293, 1.6525],
        [1.2518, 1.2832, 1.3462, 1.3241, 1.2926, 1.2588, 1.2241, 1.2499, 1.2499,
         1.2222, 1.3310, 1.2382, 1.3604, 1.2990, 1.4118, 1.2197, 1.3019, 1.2365,
         1.3025, 1.3347, 1.3484, 1.3160, 1.2747, 1.2645, 1.2327, 1.2609, 1.2609,
         1.3203, 1.3648, 1.2812, 1.1214, 1.2680, 1.1550, 1.3230, 1.1573, 1.2840,
         1.3727, 1.0917, 1.3951, 1.3813, 0.9849, 0.8908, 1.3768, 1.3761, 0.7827,
         2.6853, 2.2696, 2.7307, 2.4644, 1.9685, 1.6980, 2.5593, 2.5772, 1.6796]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 118 : 180.82901176958677
Test loss for epoch 118 : 180.88850188489695
Test Precision for epoch 118 : 0.26153846153846155
Test Recall for epoch 118 : 0.26153846153846155
Test F1 for epoch 118 : 0.26153846153846155


theta for epoch 119 : tensor([[2.2484, 2.2781, 2.3510, 2.4250, 2.3886, 2.2544, 2.3647, 2.2467, 2.2467,
         1.2630, 1.2770, 1.2778, 1.3010, 1.2485, 1.3459, 1.2610, 1.2510, 1.2306,
         1.2360, 1.2207, 1.2323, 1.2481, 1.2120, 1.2039, 1.2296, 1.2001, 1.2001,
         1.2501, 1.2964, 1.2223, 1.2474, 1.2936, 1.2332, 1.2592, 1.1841, 1.2248,
         1.3655, 1.4021, 1.3846, 1.3728, 1.3864, 1.3226, 1.3689, 1.3730, 1.3177,
         1.3350, 1.2843, 1.2743, 1.2528, 1.3248, 1.2712, 1.3657, 1.2479, 1.2514],
        [1.2712, 1.1793, 0.9949, 1.2193, 1.2903, 1.3220, 1.2457, 1.3132, 1.3132,
         1.4879, 1.7450, 1.4915, 2.2173, 1.5262, 4.5145, 1.5889, 1.4218, 4.2448,
         1.1153, 1.1905, 0.9733, 1.1615, 1.2943, 1.3267, 1.3038, 1.3235, 1.3235,
         1.2921, 1.0339, 1.3419, 1.3209, 1.1314, 1.3548, 1.3774, 1.3048, 1.3251,
         1.3173, 1.4700, 1.3915, 1.3030, 1.3044, 1.4325, 1.3737, 0.5032, 1.3653,
         1.0215, 1.4002, 1.3857, 1.3634, 1.0487, 1.3823, 0.8517, 1.3576, 1.3623],
        [1.1959, 1.2233, 1.2780, 1.2581, 1.2298, 1.2017, 1.2087, 1.1941, 1.1941,
         1.2689, 1.2836, 1.2840, 1.3070, 1.2542, 1.3074, 1.2669, 1.2493, 1.2012,
         2.3157, 2.3764, 2.4804, 2.4264, 2.2054, 2.2896, 2.3200, 2.1931, 2.1931,
         1.2941, 1.2658, 1.2286, 1.2539, 1.2936, 1.2396, 1.2663, 1.2337, 1.2312,
         1.3685, 1.4055, 1.3878, 1.3677, 1.3895, 1.3798, 1.3719, 1.2794, 1.3124,
         1.2980, 1.2906, 1.2804, 1.2587, 1.2494, 1.2777, 1.3279, 1.2536, 1.2572],
        [1.1962, 1.2250, 1.2317, 1.2105, 1.2322, 1.2025, 1.2100, 1.1944, 1.1944,
         1.2660, 1.2335, 1.2822, 1.2896, 1.2505, 1.2585, 1.2640, 1.2528, 1.1061,
         1.2443, 1.2559, 1.2855, 1.2572, 1.2188, 1.1958, 1.2373, 1.2062, 1.2062,
         2.6295, 2.3259, 2.0682, 2.1809, 2.6181, 2.0788, 2.5719, 2.0808, 2.0704,
         1.3499, 1.3890, 1.3486, 1.3388, 1.3726, 1.3531, 1.3514, 1.1977, 1.2976,
         1.3437, 1.2687, 1.1702, 1.2087, 1.3327, 1.2108, 1.3765, 1.2030, 1.2541],
        [1.6469, 1.3262, 0.5872, 0.7919, 1.1439, 1.5371, 1.4754, 1.6440, 1.6440,
         1.5079, 1.2473, 1.3439, 0.8908, 1.6013, 0.2343, 1.4959, 1.6166, 1.1367,
         1.2719, 0.8456, 0.7372, 1.0621, 1.5109, 1.5855, 1.2860, 1.6504, 1.6504,
         0.6809, 0.8090, 1.6150, 1.4063, 0.7712, 1.5564, 1.0708, 1.6642, 1.5957,
         0.3806, 0.1531, 0.1173, 0.3371, 0.6264, 0.7980, 0.2821, 8.4387, 6.9438,
         0.7377, 1.1766, 1.2603, 1.4878, 0.9806, 1.4590, 0.4040, 1.5304, 1.6534],
        [1.2515, 1.2828, 1.3457, 1.3237, 1.2922, 1.2585, 1.2237, 1.2496, 1.2496,
         1.2218, 1.3309, 1.2380, 1.3602, 1.2987, 1.4117, 1.2193, 1.3016, 1.2363,
         1.3021, 1.3342, 1.3481, 1.3156, 1.2744, 1.2642, 1.2321, 1.2606, 1.2606,
         1.3199, 1.3643, 1.2806, 1.1205, 1.2677, 1.1545, 1.3227, 1.1567, 1.2835,
         1.3727, 1.0911, 1.3950, 1.3812, 0.9844, 0.8901, 1.3767, 1.3759, 0.7820,
         2.6920, 2.2746, 2.7392, 2.4695, 1.9724, 1.7010, 2.5649, 2.5856, 1.6825]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 119 : 180.81833839695065
Test loss for epoch 119 : 180.8782881514332
Test Precision for epoch 119 : 0.26153846153846155
Test Recall for epoch 119 : 0.26153846153846155
Test F1 for epoch 119 : 0.26153846153846155


theta for epoch 120 : tensor([[2.2537, 2.2834, 2.3562, 2.4309, 2.3944, 2.2597, 2.3705, 2.2519, 2.2519,
         1.2628, 1.2769, 1.2776, 1.3009, 1.2482, 1.3458, 1.2608, 1.2507, 1.2304,
         1.2355, 1.2202, 1.2317, 1.2476, 1.2115, 1.2035, 1.2291, 1.1996, 1.1996,
         1.2497, 1.2958, 1.2219, 1.2469, 1.2931, 1.2327, 1.2588, 1.1836, 1.2244,
         1.3656, 1.4023, 1.3847, 1.3729, 1.3866, 1.3227, 1.3690, 1.3730, 1.3177,
         1.3346, 1.2838, 1.2738, 1.2524, 1.3244, 1.2708, 1.3652, 1.2474, 1.2510],
        [1.2709, 1.1791, 0.9949, 1.2191, 1.2903, 1.3218, 1.2454, 1.3130, 1.3130,
         1.4895, 1.7465, 1.4932, 2.2204, 1.5278, 4.5315, 1.5909, 1.4233, 4.2641,
         1.1150, 1.1904, 0.9734, 1.1613, 1.2942, 1.3266, 1.3036, 1.3234, 1.3234,
         1.2919, 1.0334, 1.3415, 1.3205, 1.1312, 1.3544, 1.3773, 1.3044, 1.3249,
         1.3173, 1.4700, 1.3912, 1.3026, 1.3044, 1.4325, 1.3735, 0.5027, 1.3649,
         1.0213, 1.3999, 1.3853, 1.3630, 1.0484, 1.3821, 0.8517, 1.3572, 1.3620],
        [1.1955, 1.2228, 1.2774, 1.2576, 1.2294, 1.2013, 1.2083, 1.1938, 1.1938,
         1.2687, 1.2835, 1.2838, 1.3069, 1.2540, 1.3075, 1.2667, 1.2491, 1.2012,
         2.3210, 2.3820, 2.4863, 2.4321, 2.2104, 2.2950, 2.3255, 2.1981, 2.1981,
         1.2937, 1.2654, 1.2282, 1.2534, 1.2932, 1.2391, 1.2660, 1.2332, 1.2307,
         1.3687, 1.4057, 1.3879, 1.3678, 1.3898, 1.3800, 1.3721, 1.2795, 1.3123,
         1.2976, 1.2902, 1.2800, 1.2583, 1.2492, 1.2773, 1.3276, 1.2531, 1.2568],
        [1.1959, 1.2247, 1.2323, 1.2112, 1.2318, 1.2021, 1.2097, 1.1941, 1.1941,
         1.2658, 1.2344, 1.2820, 1.2899, 1.2503, 1.2585, 1.2638, 1.2526, 1.1078,
         1.2439, 1.2560, 1.2851, 1.2568, 1.2185, 1.1958, 1.2369, 1.2060, 1.2060,
         2.6338, 2.3329, 2.0742, 2.1873, 2.6226, 2.0849, 2.5764, 2.0868, 2.0765,
         1.3500, 1.3894, 1.3492, 1.3394, 1.3728, 1.3537, 1.3517, 1.1997, 1.2976,
         1.3433, 1.2688, 1.1702, 1.2083, 1.3323, 1.2117, 1.3760, 1.2026, 1.2538],
        [1.6479, 1.3275, 0.5884, 0.7929, 1.1451, 1.5383, 1.4766, 1.6450, 1.6450,
         1.5088, 1.2475, 1.3449, 0.8917, 1.6021, 0.2362, 1.4968, 1.6174, 1.1364,
         1.2732, 0.8469, 0.7386, 1.0635, 1.5120, 1.5863, 1.2875, 1.6514, 1.6514,
         0.6817, 0.8105, 1.6161, 1.4077, 0.7717, 1.5574, 1.0712, 1.6653, 1.5965,
         0.3765, 0.1495, 0.1140, 0.3332, 0.6217, 0.7932, 0.2782, 8.4910, 6.9696,
         0.7390, 1.1772, 1.2611, 1.4887, 0.9816, 1.4590, 0.4055, 1.5315, 1.6543],
        [1.2510, 1.2823, 1.3451, 1.3231, 1.2917, 1.2580, 1.2232, 1.2491, 1.2491,
         1.2212, 1.3306, 1.2376, 1.3598, 1.2981, 1.4115, 1.2188, 1.3010, 1.2359,
         1.3015, 1.3337, 1.3477, 1.3151, 1.2738, 1.2637, 1.2313, 1.2601, 1.2601,
         1.3193, 1.3637, 1.2800, 1.1196, 1.2673, 1.1540, 1.3223, 1.1560, 1.2829,
         1.3725, 1.0904, 1.3947, 1.3810, 0.9837, 0.8893, 1.3766, 1.3755, 0.7810,
         2.6989, 2.2798, 2.7479, 2.4749, 1.9765, 1.7042, 2.5707, 2.5942, 1.6856]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 120 : 180.80784462261113
Test loss for epoch 120 : 180.86815463340176
Test Precision for epoch 120 : 0.26153846153846155
Test Recall for epoch 120 : 0.26153846153846155
Test F1 for epoch 120 : 0.26153846153846155


theta for epoch 121 : tensor([[2.2590, 2.2886, 2.3614, 2.4367, 2.4002, 2.2649, 2.3763, 2.2572, 2.2572,
         1.2624, 1.2766, 1.2772, 1.3006, 1.2478, 1.3456, 1.2604, 1.2503, 1.2301,
         1.2351, 1.2197, 1.2312, 1.2471, 1.2111, 1.2031, 1.2286, 1.1992, 1.1992,
         1.2494, 1.2954, 1.2216, 1.2466, 1.2929, 1.2324, 1.2587, 1.1833, 1.2241,
         1.3657, 1.4024, 1.3846, 1.3729, 1.3868, 1.3227, 1.3690, 1.3728, 1.3176,
         1.3341, 1.2834, 1.2733, 1.2519, 1.3240, 1.2704, 1.3648, 1.2469, 1.2505],
        [1.2707, 1.1790, 0.9949, 1.2190, 1.2902, 1.3216, 1.2451, 1.3128, 1.3128,
         1.4910, 1.7478, 1.4948, 2.2235, 1.5294, 4.5484, 1.5926, 1.4248, 4.2834,
         1.1148, 1.1902, 0.9734, 1.1611, 1.2941, 1.3266, 1.3034, 1.3233, 1.3233,
         1.2918, 1.0331, 1.3414, 1.3203, 1.1313, 1.3542, 1.3773, 1.3042, 1.3250,
         1.3172, 1.4699, 1.3908, 1.3022, 1.3042, 1.4324, 1.3731, 0.5021, 1.3643,
         1.0211, 1.3996, 1.3850, 1.3627, 1.0480, 1.3818, 0.8518, 1.3567, 1.3616],
        [1.1951, 1.2223, 1.2768, 1.2570, 1.2289, 1.2008, 1.2078, 1.1933, 1.1933,
         1.2683, 1.2832, 1.2834, 1.3066, 1.2536, 1.3073, 1.2663, 1.2486, 1.2011,
         2.3262, 2.3878, 2.4923, 2.4380, 2.2156, 2.3005, 2.3310, 2.2033, 2.2033,
         1.2934, 1.2652, 1.2279, 1.2531, 1.2930, 1.2388, 1.2658, 1.2329, 1.2304,
         1.3687, 1.4059, 1.3878, 1.3678, 1.3900, 1.3801, 1.3722, 1.2796, 1.3121,
         1.2972, 1.2897, 1.2795, 1.2578, 1.2490, 1.2769, 1.3272, 1.2526, 1.2564],
        [1.1956, 1.2243, 1.2330, 1.2120, 1.2314, 1.2018, 1.2094, 1.1938, 1.1938,
         1.2655, 1.2351, 1.2816, 1.2901, 1.2499, 1.2582, 1.2634, 1.2522, 1.1094,
         1.2436, 1.2561, 1.2847, 1.2564, 1.2182, 1.1959, 1.2366, 1.2057, 1.2057,
         2.6382, 2.3400, 2.0804, 2.1938, 2.6272, 2.0911, 2.5809, 2.0928, 2.0827,
         1.3501, 1.3896, 1.3498, 1.3399, 1.3730, 1.3541, 1.3519, 1.2017, 1.2976,
         1.3428, 1.2689, 1.1701, 1.2079, 1.3318, 1.2127, 1.3756, 1.2021, 1.2534],
        [1.6490, 1.3287, 0.5896, 0.7939, 1.1464, 1.5394, 1.4779, 1.6461, 1.6461,
         1.5096, 1.2475, 1.3458, 0.8925, 1.6028, 0.2380, 1.4976, 1.6182, 1.1360,
         1.2745, 0.8482, 0.7401, 1.0649, 1.5132, 1.5871, 1.2889, 1.6525, 1.6525,
         0.6827, 0.8121, 1.6173, 1.4093, 0.7724, 1.5585, 1.0718, 1.6666, 1.5976,
         0.3724, 0.1459, 0.1107, 0.3293, 0.6170, 0.7885, 0.2743, 8.5431, 6.9947,
         0.7403, 1.1777, 1.2618, 1.4895, 0.9825, 1.4589, 0.4070, 1.5326, 1.6551],
        [1.2506, 1.2819, 1.3445, 1.3227, 1.2912, 1.2576, 1.2228, 1.2487, 1.2487,
         1.2205, 1.3302, 1.2370, 1.3593, 1.2974, 1.4111, 1.2181, 1.3003, 1.2354,
         1.3011, 1.3331, 1.3472, 1.3146, 1.2734, 1.2633, 1.2306, 1.2597, 1.2597,
         1.3190, 1.3633, 1.2796, 1.1189, 1.2671, 1.1538, 1.3221, 1.1555, 1.2825,
         1.3723, 1.0896, 1.3944, 1.3808, 0.9830, 0.8884, 1.3763, 1.3751, 0.7800,
         2.7058, 2.2849, 2.7566, 2.4802, 1.9804, 1.7072, 2.5765, 2.6027, 1.6886]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 121 : 180.79752333710482
Test loss for epoch 121 : 180.85816722020874
Test Precision for epoch 121 : 0.26153846153846155
Test Recall for epoch 121 : 0.26153846153846155
Test F1 for epoch 121 : 0.26153846153846155


theta for epoch 122 : tensor([[2.2642, 2.2938, 2.3666, 2.4425, 2.4060, 2.2701, 2.3821, 2.2624, 2.2624,
         1.2621, 1.2764, 1.2769, 1.3003, 1.2474, 1.3454, 1.2600, 1.2499, 1.2298,
         1.2346, 1.2191, 1.2306, 1.2466, 1.2107, 1.2026, 1.2282, 1.1988, 1.1988,
         1.2492, 1.2950, 1.2214, 1.2463, 1.2926, 1.2322, 1.2585, 1.1831, 1.2239,
         1.3657, 1.4025, 1.3845, 1.3729, 1.3869, 1.3226, 1.3690, 1.3727, 1.3174,
         1.3337, 1.2830, 1.2728, 1.2515, 1.3236, 1.2700, 1.3644, 1.2464, 1.2501],
        [1.2704, 1.1787, 0.9948, 1.2189, 1.2902, 1.3213, 1.2448, 1.3125, 1.3125,
         1.4925, 1.7491, 1.4964, 2.2265, 1.5309, 4.5655, 1.5944, 1.4262, 4.3028,
         1.1145, 1.1901, 0.9734, 1.1609, 1.2939, 1.3264, 1.3032, 1.3232, 1.3232,
         1.2918, 1.0328, 1.3412, 1.3202, 1.1314, 1.3540, 1.3774, 1.3039, 1.3250,
         1.3170, 1.4697, 1.3904, 1.3017, 1.3040, 1.4323, 1.3728, 0.5014, 1.3637,
         1.0210, 1.3992, 1.3846, 1.3624, 1.0477, 1.3815, 0.8518, 1.3563, 1.3613],
        [1.1947, 1.2218, 1.2761, 1.2564, 1.2284, 1.2004, 1.2073, 1.1929, 1.1929,
         1.2680, 1.2829, 1.2830, 1.3063, 1.2532, 1.3072, 1.2659, 1.2482, 1.2010,
         2.3315, 2.3934, 2.4982, 2.4438, 2.2207, 2.3059, 2.3365, 2.2085, 2.2085,
         1.2932, 1.2649, 1.2277, 1.2528, 1.2928, 1.2386, 1.2656, 1.2327, 1.2302,
         1.3687, 1.4060, 1.3878, 1.3677, 1.3901, 1.3802, 1.3722, 1.2795, 1.3118,
         1.2969, 1.2893, 1.2790, 1.2574, 1.2488, 1.2765, 1.3269, 1.2522, 1.2560],
        [1.1952, 1.2239, 1.2336, 1.2127, 1.2310, 1.2014, 1.2090, 1.1934, 1.1934,
         1.2652, 1.2358, 1.2813, 1.2902, 1.2496, 1.2580, 1.2631, 1.2519, 1.1110,
         1.2432, 1.2561, 1.2842, 1.2560, 1.2178, 1.1959, 1.2361, 1.2053, 1.2053,
         2.6426, 2.3471, 2.0865, 2.2003, 2.6318, 2.0973, 2.5855, 2.0990, 2.0889,
         1.3502, 1.3898, 1.3503, 1.3404, 1.3731, 1.3545, 1.3520, 1.2036, 1.2975,
         1.3424, 1.2690, 1.1700, 1.2075, 1.3314, 1.2136, 1.3751, 1.2017, 1.2530],
        [1.6500, 1.3299, 0.5906, 0.7948, 1.1474, 1.5405, 1.4790, 1.6471, 1.6471,
         1.5103, 1.2475, 1.3466, 0.8932, 1.6034, 0.2396, 1.4983, 1.6188, 1.1356,
         1.2758, 0.8493, 0.7414, 1.0661, 1.5143, 1.5877, 1.2903, 1.6535, 1.6535,
         0.6835, 0.8136, 1.6185, 1.4109, 0.7730, 1.5595, 1.0723, 1.6678, 1.5986,
         0.3685, 0.1425, 0.1076, 0.3256, 0.6125, 0.7839, 0.2706, 8.5950, 7.0193,
         0.7415, 1.1782, 1.2624, 1.4902, 0.9833, 1.4587, 0.4083, 1.5335, 1.6559],
        [1.2504, 1.2817, 1.3442, 1.3224, 1.2908, 1.2573, 1.2225, 1.2484, 1.2484,
         1.2201, 1.3300, 1.2367, 1.3591, 1.2970, 1.4110, 1.2177, 1.2999, 1.2352,
         1.3008, 1.3328, 1.3469, 1.3143, 1.2731, 1.2631, 1.2301, 1.2594, 1.2594,
         1.3188, 1.3631, 1.2794, 1.1183, 1.2671, 1.1537, 1.3220, 1.1551, 1.2822,
         1.3721, 1.0889, 1.3941, 1.3806, 0.9823, 0.8876, 1.3761, 1.3747, 0.7791,
         2.7125, 2.2897, 2.7650, 2.4852, 1.9840, 1.7099, 2.5820, 2.6109, 1.6913]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 122 : 180.78736725012777
Test loss for epoch 122 : 180.84854206366603
Test Precision for epoch 122 : 0.26153846153846155
Test Recall for epoch 122 : 0.26153846153846155
Test F1 for epoch 122 : 0.26153846153846155


theta for epoch 123 : tensor([[2.2694, 2.2990, 2.3718, 2.4483, 2.4118, 2.2753, 2.3879, 2.2676, 2.2676,
         1.2618, 1.2762, 1.2767, 1.3002, 1.2471, 1.3453, 1.2597, 1.2496, 1.2296,
         1.2340, 1.2185, 1.2300, 1.2461, 1.2102, 1.2022, 1.2277, 1.1983, 1.1983,
         1.2487, 1.2943, 1.2210, 1.2458, 1.2921, 1.2317, 1.2581, 1.1826, 1.2235,
         1.3656, 1.4025, 1.3844, 1.3728, 1.3870, 1.3226, 1.3690, 1.3724, 1.3172,
         1.3335, 1.2827, 1.2725, 1.2513, 1.3234, 1.2698, 1.3642, 1.2461, 1.2499],
        [1.2700, 1.1785, 0.9946, 1.2187, 1.2901, 1.3210, 1.2444, 1.3122, 1.3122,
         1.4941, 1.7505, 1.4980, 2.2295, 1.5325, 4.5827, 1.5962, 1.4277, 4.3223,
         1.1142, 1.1898, 0.9733, 1.1606, 1.2936, 1.3262, 1.3028, 1.3229, 1.3229,
         1.2916, 1.0323, 1.3409, 1.3198, 1.1313, 1.3536, 1.3772, 1.3035, 1.3249,
         1.3168, 1.4696, 1.3899, 1.3013, 1.3038, 1.4321, 1.3724, 0.5007, 1.3631,
         1.0210, 1.3991, 1.3844, 1.3622, 1.0476, 1.3814, 0.8520, 1.3560, 1.3611],
        [1.1943, 1.2213, 1.2756, 1.2559, 1.2279, 1.1999, 1.2068, 1.1925, 1.1925,
         1.2678, 1.2828, 1.2828, 1.3061, 1.2529, 1.3071, 1.2657, 1.2479, 1.2010,
         2.3367, 2.3991, 2.5041, 2.4495, 2.2258, 2.3113, 2.3419, 2.2135, 2.2135,
         1.2927, 1.2645, 1.2272, 1.2523, 1.2923, 1.2380, 1.2652, 1.2322, 1.2297,
         1.3687, 1.4061, 1.3877, 1.3677, 1.3903, 1.3802, 1.3722, 1.2795, 1.3115,
         1.2967, 1.2891, 1.2787, 1.2572, 1.2488, 1.2763, 1.3268, 1.2519, 1.2557],
        [1.1948, 1.2235, 1.2342, 1.2134, 1.2306, 1.2011, 1.2086, 1.1931, 1.1931,
         1.2649, 1.2366, 1.2810, 1.2904, 1.2493, 1.2578, 1.2628, 1.2516, 1.1125,
         1.2428, 1.2561, 1.2837, 1.2555, 1.2175, 1.1959, 1.2357, 1.2050, 1.2050,
         2.6468, 2.3541, 2.0927, 2.2068, 2.6363, 2.1034, 2.5899, 2.1050, 2.0950,
         1.3503, 1.3900, 1.3508, 1.3409, 1.3732, 1.3549, 1.3522, 1.2055, 1.2975,
         1.3421, 1.2693, 1.1700, 1.2072, 1.3311, 1.2147, 1.3748, 1.2014, 1.2528],
        [1.6510, 1.3310, 0.5916, 0.7956, 1.1484, 1.5415, 1.4801, 1.6481, 1.6481,
         1.5110, 1.2474, 1.3474, 0.8938, 1.6040, 0.2412, 1.4991, 1.6195, 1.1351,
         1.2769, 0.8504, 0.7426, 1.0672, 1.5153, 1.5883, 1.2915, 1.6545, 1.6545,
         0.6841, 0.8149, 1.6194, 1.4122, 0.7735, 1.5604, 1.0725, 1.6688, 1.5994,
         0.3647, 0.1392, 0.1046, 0.3221, 0.6081, 0.7795, 0.2670, 8.6467, 7.0435,
         0.7427, 1.1787, 1.2632, 1.4910, 0.9843, 1.4585, 0.4096, 1.5345, 1.6568],
        [1.2502, 1.2815, 1.3440, 1.3222, 1.2906, 1.2572, 1.2223, 1.2483, 1.2483,
         1.2199, 1.3300, 1.2366, 1.3590, 1.2968, 1.4110, 1.2174, 1.2996, 1.2352,
         1.3006, 1.3325, 1.3467, 1.3141, 1.2729, 1.2629, 1.2297, 1.2592, 1.2592,
         1.3185, 1.3628, 1.2790, 1.1177, 1.2670, 1.1535, 1.3217, 1.1547, 1.2818,
         1.3719, 1.0883, 1.3938, 1.3804, 0.9817, 0.8869, 1.3759, 1.3743, 0.7782,
         2.7191, 2.2944, 2.7733, 2.4902, 1.9874, 1.7125, 2.5875, 2.6190, 1.6938]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 123 : 180.77736786505332
Test loss for epoch 123 : 180.83915568397785
Test Precision for epoch 123 : 0.26153846153846155
Test Recall for epoch 123 : 0.26153846153846155
Test F1 for epoch 123 : 0.26153846153846155


theta for epoch 124 : tensor([[2.2746, 2.3041, 2.3769, 2.4540, 2.4175, 2.2805, 2.3936, 2.2728, 2.2728,
         1.2615, 1.2759, 1.2763, 1.2999, 1.2467, 1.3451, 1.2594, 1.2491, 1.2293,
         1.2336, 1.2180, 1.2295, 1.2456, 1.2097, 1.2018, 1.2272, 1.1979, 1.1979,
         1.2481, 1.2936, 1.2205, 1.2452, 1.2915, 1.2311, 1.2577, 1.1820, 1.2229,
         1.3656, 1.4026, 1.3843, 1.3728, 1.3871, 1.3225, 1.3689, 1.3722, 1.3170,
         1.3334, 1.2826, 1.2724, 1.2512, 1.3233, 1.2697, 1.3641, 1.2459, 1.2497],
        [1.2697, 1.1782, 0.9945, 1.2185, 1.2900, 1.3207, 1.2440, 1.3118, 1.3118,
         1.4954, 1.7516, 1.4994, 2.2323, 1.5338, 4.5999, 1.5978, 1.4289, 4.3417,
         1.1139, 1.1897, 0.9733, 1.1604, 1.2935, 1.3261, 1.3026, 1.3228, 1.3228,
         1.2913, 1.0318, 1.3405, 1.3194, 1.1311, 1.3532, 1.3770, 1.3031, 1.3247,
         1.3166, 1.4694, 1.3895, 1.3008, 1.3035, 1.4319, 1.3720, 0.5000, 1.3625,
         1.0212, 1.3991, 1.3844, 1.3622, 1.0476, 1.3815, 0.8524, 1.3559, 1.3611],
        [1.1938, 1.2207, 1.2749, 1.2553, 1.2274, 1.1995, 1.2063, 1.1920, 1.1920,
         1.2674, 1.2825, 1.2824, 1.3059, 1.2525, 1.3069, 1.2653, 1.2475, 1.2009,
         2.3419, 2.4047, 2.5100, 2.4552, 2.2309, 2.3168, 2.3474, 2.2187, 2.2187,
         1.2922, 1.2639, 1.2267, 1.2516, 1.2918, 1.2375, 1.2647, 1.2316, 1.2292,
         1.3687, 1.4061, 1.3876, 1.3676, 1.3904, 1.3803, 1.3722, 1.2794, 1.3112,
         1.2966, 1.2889, 1.2786, 1.2571, 1.2489, 1.2762, 1.3268, 1.2516, 1.2556],
        [1.1944, 1.2230, 1.2348, 1.2140, 1.2301, 1.2006, 1.2081, 1.1926, 1.1926,
         1.2646, 1.2373, 1.2806, 1.2905, 1.2489, 1.2575, 1.2624, 1.2512, 1.1140,
         1.2423, 1.2561, 1.2832, 1.2551, 1.2171, 1.1959, 1.2353, 1.2046, 1.2046,
         2.6511, 2.3612, 2.0988, 2.2132, 2.6407, 2.1095, 2.5944, 2.1110, 2.1011,
         1.3503, 1.3901, 1.3513, 1.3414, 1.3734, 1.3552, 1.3523, 1.2075, 1.2974,
         1.3418, 1.2696, 1.1701, 1.2070, 1.3308, 1.2158, 1.3746, 1.2012, 1.2526],
        [1.6519, 1.3321, 0.5925, 0.7963, 1.1494, 1.5425, 1.4811, 1.6490, 1.6490,
         1.5116, 1.2473, 1.3481, 0.8944, 1.6046, 0.2426, 1.4998, 1.6201, 1.1345,
         1.2780, 0.8515, 0.7439, 1.0684, 1.5163, 1.5890, 1.2928, 1.6554, 1.6554,
         0.6848, 0.8162, 1.6203, 1.4134, 0.7739, 1.5611, 1.0728, 1.6698, 1.6001,
         0.3610, 0.1359, 0.1016, 0.3185, 0.6036, 0.7750, 0.2635, 8.6981, 7.0671,
         0.7442, 1.1795, 1.2641, 1.4919, 0.9854, 1.4586, 0.4112, 1.5357, 1.6578],
        [1.2500, 1.2813, 1.3437, 1.3220, 1.2903, 1.2569, 1.2221, 1.2481, 1.2481,
         1.2195, 1.3298, 1.2363, 1.3588, 1.2964, 1.4109, 1.2171, 1.2992, 1.2350,
         1.3004, 1.3322, 1.3464, 1.3138, 1.2727, 1.2627, 1.2292, 1.2591, 1.2591,
         1.3181, 1.3623, 1.2785, 1.1169, 1.2668, 1.1533, 1.3214, 1.1542, 1.2814,
         1.3717, 1.0876, 1.3935, 1.3802, 0.9810, 0.8861, 1.3757, 1.3740, 0.7773,
         2.7258, 2.2991, 2.7818, 2.4954, 1.9909, 1.7151, 2.5931, 2.6271, 1.6964]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 124 : 180.76753094147665
Test loss for epoch 124 : 180.829796572408
Test Precision for epoch 124 : 0.26153846153846155
Test Recall for epoch 124 : 0.26153846153846155
Test F1 for epoch 124 : 0.26153846153846155


theta for epoch 125 : tensor([[2.2797, 2.3092, 2.3821, 2.4598, 2.4232, 2.2857, 2.3993, 2.2779, 2.2779,
         1.2612, 1.2757, 1.2760, 1.2996, 1.2463, 1.3449, 1.2590, 1.2488, 1.2291,
         1.2331, 1.2174, 1.2289, 1.2451, 1.2093, 1.2014, 1.2268, 1.1975, 1.1975,
         1.2476, 1.2930, 1.2201, 1.2447, 1.2911, 1.2307, 1.2573, 1.1816, 1.2225,
         1.3656, 1.4027, 1.3842, 1.3728, 1.3872, 1.3224, 1.3689, 1.3720, 1.3168,
         1.3332, 1.2823, 1.2721, 1.2509, 1.3230, 1.2695, 1.3638, 1.2456, 1.2495],
        [1.2694, 1.1780, 0.9944, 1.2183, 1.2900, 1.3203, 1.2437, 1.3115, 1.3115,
         1.4967, 1.7527, 1.5007, 2.2351, 1.5351, 4.6171, 1.5994, 1.4302, 4.3612,
         1.1136, 1.1896, 0.9732, 1.1601, 1.2933, 1.3259, 1.3024, 1.3226, 1.3226,
         1.2912, 1.0314, 1.3402, 1.3191, 1.1310, 1.3529, 1.3769, 1.3028, 1.3247,
         1.3164, 1.4693, 1.3891, 1.3004, 1.3034, 1.4318, 1.3717, 0.4994, 1.3619,
         1.0212, 1.3989, 1.3842, 1.3620, 1.0475, 1.3814, 0.8527, 1.3556, 1.3609],
        [1.1934, 1.2203, 1.2744, 1.2548, 1.2270, 1.1991, 1.2059, 1.1916, 1.1916,
         1.2671, 1.2822, 1.2821, 1.3056, 1.2522, 1.3068, 1.2650, 1.2471, 1.2009,
         2.3470, 2.4103, 2.5158, 2.4608, 2.2360, 2.3221, 2.3527, 2.2237, 2.2237,
         1.2917, 1.2635, 1.2263, 1.2512, 1.2914, 1.2370, 1.2644, 1.2312, 1.2288,
         1.3688, 1.4062, 1.3875, 1.3676, 1.3905, 1.3803, 1.3722, 1.2793, 1.3110,
         1.2964, 1.2887, 1.2783, 1.2568, 1.2489, 1.2760, 1.3267, 1.2513, 1.2553],
        [1.1939, 1.2225, 1.2353, 1.2145, 1.2296, 1.2001, 1.2076, 1.1922, 1.1922,
         1.2642, 1.2379, 1.2802, 1.2906, 1.2485, 1.2572, 1.2620, 1.2508, 1.1154,
         1.2418, 1.2560, 1.2827, 1.2546, 1.2166, 1.1958, 1.2347, 1.2042, 1.2042,
         2.6554, 2.3683, 2.1049, 2.2198, 2.6452, 2.1158, 2.5988, 2.1171, 2.1073,
         1.3504, 1.3903, 1.3517, 1.3419, 1.3735, 1.3556, 1.3525, 1.2094, 1.2974,
         1.3415, 1.2697, 1.1701, 1.2067, 1.3305, 1.2168, 1.3742, 1.2008, 1.2522],
        [1.6529, 1.3332, 0.5935, 0.7972, 1.1505, 1.5436, 1.4822, 1.6500, 1.6500,
         1.5123, 1.2473, 1.3489, 0.8951, 1.6052, 0.2442, 1.5005, 1.6208, 1.1340,
         1.2792, 0.8526, 0.7452, 1.0696, 1.5174, 1.5897, 1.2941, 1.6564, 1.6564,
         0.6855, 0.8176, 1.6214, 1.4148, 0.7745, 1.5620, 1.0732, 1.6709, 1.6010,
         0.3573, 0.1326, 0.0987, 0.3150, 0.5992, 0.7706, 0.2600, 8.7493, 7.0900,
         0.7456, 1.1801, 1.2649, 1.4927, 0.9864, 1.4584, 0.4126, 1.5367, 1.6586],
        [1.2497, 1.2810, 1.3434, 1.3217, 1.2900, 1.2566, 1.2218, 1.2478, 1.2478,
         1.2192, 1.3296, 1.2360, 1.3585, 1.2960, 1.4108, 1.2167, 1.2988, 1.2348,
         1.3001, 1.3319, 1.3461, 1.3135, 1.2725, 1.2625, 1.2287, 1.2588, 1.2588,
         1.3177, 1.3620, 1.2781, 1.1163, 1.2667, 1.1531, 1.3212, 1.1537, 1.2810,
         1.3715, 1.0869, 1.3932, 1.3799, 0.9804, 0.8852, 1.3755, 1.3736, 0.7763,
         2.7326, 2.3038, 2.7902, 2.5005, 1.9943, 1.7177, 2.5987, 2.6352, 1.6990]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 125 : 180.75784941009874
Test loss for epoch 125 : 180.82058779669347
Test Precision for epoch 125 : 0.26153846153846155
Test Recall for epoch 125 : 0.26153846153846155
Test F1 for epoch 125 : 0.26153846153846155


theta for epoch 126 : tensor([[2.2848, 2.3143, 2.3872, 2.4655, 2.4288, 2.2908, 2.4050, 2.2830, 2.2830,
         1.2609, 1.2756, 1.2758, 1.2995, 1.2461, 1.3449, 1.2588, 1.2485, 1.2289,
         1.2327, 1.2170, 1.2285, 1.2447, 1.2089, 1.2010, 1.2264, 1.1971, 1.1971,
         1.2473, 1.2925, 1.2197, 1.2443, 1.2907, 1.2303, 1.2570, 1.1812, 1.2222,
         1.3657, 1.4028, 1.3842, 1.3729, 1.3874, 1.3224, 1.3690, 1.3718, 1.3167,
         1.3327, 1.2819, 1.2716, 1.2505, 1.3226, 1.2690, 1.3634, 1.2450, 1.2490],
        [1.2691, 1.1778, 0.9942, 1.2181, 1.2900, 1.3200, 1.2434, 1.3112, 1.3112,
         1.4980, 1.7538, 1.5021, 2.2378, 1.5365, 4.6345, 1.6009, 1.4314, 4.3808,
         1.1134, 1.1894, 0.9732, 1.1599, 1.2931, 1.3258, 1.3021, 1.3224, 1.3224,
         1.2911, 1.0311, 1.3400, 1.3189, 1.1310, 1.3527, 1.3769, 1.3025, 1.3247,
         1.3163, 1.4692, 1.3888, 1.3000, 1.3032, 1.4317, 1.3714, 0.4987, 1.3613,
         1.0210, 1.3986, 1.3838, 1.3616, 1.0471, 1.3811, 0.8527, 1.3550, 1.3605],
        [1.1930, 1.2199, 1.2740, 1.2544, 1.2266, 1.1987, 1.2055, 1.1913, 1.1913,
         1.2669, 1.2821, 1.2819, 1.3055, 1.2519, 1.3067, 1.2648, 1.2468, 1.2009,
         2.3521, 2.4158, 2.5216, 2.4664, 2.2410, 2.3275, 2.3581, 2.2287, 2.2287,
         1.2914, 1.2631, 1.2260, 1.2508, 1.2910, 1.2367, 1.2641, 1.2309, 1.2284,
         1.3689, 1.4064, 1.3875, 1.3676, 1.3907, 1.3804, 1.3723, 1.2794, 1.3108,
         1.2961, 1.2882, 1.2778, 1.2564, 1.2487, 1.2755, 1.3264, 1.2508, 1.2549],
        [1.1935, 1.2220, 1.2358, 1.2151, 1.2291, 1.1997, 1.2072, 1.1917, 1.1917,
         1.2639, 1.2387, 1.2799, 1.2908, 1.2482, 1.2570, 1.2617, 1.2504, 1.1169,
         1.2414, 1.2559, 1.2822, 1.2541, 1.2162, 1.1957, 1.2343, 1.2038, 1.2038,
         2.6597, 2.3755, 2.1111, 2.2263, 2.6496, 2.1219, 2.6033, 2.1232, 2.1135,
         1.3506, 1.3905, 1.3523, 1.3425, 1.3738, 1.3560, 1.3527, 1.2113, 1.2974,
         1.3410, 1.2697, 1.1699, 1.2062, 1.3300, 1.2176, 1.3737, 1.2002, 1.2518],
        [1.6539, 1.3344, 0.5945, 0.7980, 1.1515, 1.5446, 1.4833, 1.6509, 1.6509,
         1.5131, 1.2474, 1.3498, 0.8958, 1.6059, 0.2457, 1.5013, 1.6216, 1.1337,
         1.2804, 0.8537, 0.7465, 1.0708, 1.5184, 1.5904, 1.2953, 1.6574, 1.6574,
         0.6863, 0.8190, 1.6224, 1.4162, 0.7752, 1.5629, 1.0736, 1.6720, 1.6019,
         0.3536, 0.1293, 0.0958, 0.3115, 0.5948, 0.7662, 0.2565, 8.8002, 7.1124,
         0.7469, 1.1806, 1.2655, 1.4933, 0.9873, 1.4580, 0.4139, 1.5374, 1.6592],
        [1.2494, 1.2807, 1.3431, 1.3214, 1.2896, 1.2563, 1.2214, 1.2475, 1.2475,
         1.2188, 1.3295, 1.2358, 1.3584, 1.2956, 1.4107, 1.2164, 1.2985, 1.2346,
         1.2998, 1.3316, 1.3457, 1.3132, 1.2722, 1.2622, 1.2282, 1.2585, 1.2585,
         1.3174, 1.3617, 1.2777, 1.1156, 1.2667, 1.1530, 1.3210, 1.1533, 1.2806,
         1.3714, 1.0862, 1.3930, 1.3797, 0.9797, 0.8844, 1.3753, 1.3733, 0.7754,
         2.7394, 2.3085, 2.7986, 2.5056, 1.9976, 1.7202, 2.6042, 2.6432, 1.7014]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 126 : 180.74831517137002
Test loss for epoch 126 : 180.81160115101073
Test Precision for epoch 126 : 0.26153846153846155
Test Recall for epoch 126 : 0.26153846153846155
Test F1 for epoch 126 : 0.26153846153846155


theta for epoch 127 : tensor([[2.2899, 2.3194, 2.3922, 2.4711, 2.4345, 2.2958, 2.4107, 2.2881, 2.2881,
         1.2607, 1.2754, 1.2756, 1.2993, 1.2458, 1.3447, 1.2585, 1.2482, 1.2288,
         1.2323, 1.2166, 1.2281, 1.2444, 1.2087, 1.2008, 1.2261, 1.1969, 1.1969,
         1.2468, 1.2919, 1.2193, 1.2438, 1.2902, 1.2299, 1.2567, 1.1807, 1.2218,
         1.3658, 1.4029, 1.3842, 1.3730, 1.3876, 1.3225, 1.3691, 1.3717, 1.3166,
         1.3323, 1.2814, 1.2711, 1.2500, 1.3222, 1.2686, 1.3630, 1.2445, 1.2485],
        [1.2688, 1.1776, 0.9941, 1.2180, 1.2900, 1.3197, 1.2431, 1.3109, 1.3109,
         1.4991, 1.7548, 1.5033, 2.2403, 1.5377, 4.6519, 1.6023, 1.4325, 4.4004,
         1.1132, 1.1893, 0.9731, 1.1597, 1.2929, 1.3256, 1.3019, 1.3222, 1.3222,
         1.2910, 1.0307, 1.3398, 1.3187, 1.1309, 1.3524, 1.3768, 1.3022, 1.3247,
         1.3163, 1.4691, 1.3885, 1.2997, 1.3031, 1.4316, 1.3712, 0.4982, 1.3609,
         1.0209, 1.3983, 1.3835, 1.3613, 1.0468, 1.3808, 0.8527, 1.3546, 1.3601],
        [1.1927, 1.2196, 1.2736, 1.2540, 1.2263, 1.1984, 1.2052, 1.1910, 1.1910,
         1.2666, 1.2819, 1.2817, 1.3053, 1.2516, 1.3066, 1.2645, 1.2465, 1.2010,
         2.3573, 2.4213, 2.5274, 2.4720, 2.2460, 2.3328, 2.3634, 2.2338, 2.2338,
         1.2909, 1.2627, 1.2256, 1.2503, 1.2906, 1.2362, 1.2637, 1.2304, 1.2280,
         1.3690, 1.4066, 1.3876, 1.3676, 1.3910, 1.3806, 1.3724, 1.2794, 1.3106,
         1.2957, 1.2878, 1.2773, 1.2559, 1.2486, 1.2751, 1.3261, 1.2502, 1.2544],
        [1.1932, 1.2217, 1.2364, 1.2158, 1.2287, 1.1993, 1.2068, 1.1914, 1.1914,
         1.2636, 1.2395, 1.2797, 1.2910, 1.2479, 1.2569, 1.2614, 1.2502, 1.1184,
         1.2411, 1.2560, 1.2818, 1.2538, 1.2160, 1.1958, 1.2340, 1.2035, 1.2035,
         2.6638, 2.3824, 2.1171, 2.2327, 2.6539, 2.1280, 2.6075, 2.1292, 2.1195,
         1.3508, 1.3908, 1.3529, 1.3432, 1.3741, 1.3565, 1.3530, 1.2134, 1.2975,
         1.3405, 1.2698, 1.1697, 1.2058, 1.3295, 1.2185, 1.3732, 1.1998, 1.2513],
        [1.6549, 1.3355, 0.5954, 0.7988, 1.1525, 1.5457, 1.4844, 1.6519, 1.6519,
         1.5138, 1.2474, 1.3505, 0.8965, 1.6065, 0.2471, 1.5020, 1.6222, 1.1332,
         1.2815, 0.8549, 0.7478, 1.0720, 1.5195, 1.5910, 1.2966, 1.6584, 1.6584,
         0.6871, 0.8204, 1.6234, 1.4175, 0.7758, 1.5638, 1.0739, 1.6731, 1.6027,
         0.3501, 0.1262, 0.0930, 0.3082, 0.5905, 0.7619, 0.2532, 8.8510, 7.1343,
         0.7481, 1.1810, 1.2661, 1.4938, 0.9882, 1.4576, 0.4152, 1.5382, 1.6598],
        [1.2491, 1.2804, 1.3427, 1.3211, 1.2892, 1.2558, 1.2210, 1.2471, 1.2471,
         1.2184, 1.3292, 1.2354, 1.3580, 1.2952, 1.4105, 1.2159, 1.2980, 1.2343,
         1.2995, 1.3312, 1.3453, 1.3129, 1.2719, 1.2619, 1.2277, 1.2582, 1.2582,
         1.3170, 1.3612, 1.2773, 1.1149, 1.2665, 1.1528, 1.3207, 1.1528, 1.2801,
         1.3712, 1.0855, 1.3927, 1.3795, 0.9790, 0.8836, 1.3751, 1.3730, 0.7744,
         2.7463, 2.3133, 2.8071, 2.5108, 2.0010, 1.7228, 2.6099, 2.6513, 1.7040]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 127 : 180.73892774853147
Test loss for epoch 127 : 180.8026880878424
Test Precision for epoch 127 : 0.26153846153846155
Test Recall for epoch 127 : 0.26153846153846155
Test F1 for epoch 127 : 0.26153846153846155


theta for epoch 128 : tensor([[2.2950, 2.3244, 2.3972, 2.4767, 2.4401, 2.3009, 2.4163, 2.2932, 2.2932,
         1.2604, 1.2752, 1.2753, 1.2991, 1.2454, 1.3445, 1.2582, 1.2478, 1.2285,
         1.2319, 1.2161, 1.2277, 1.2439, 1.2082, 1.2004, 1.2257, 1.1965, 1.1965,
         1.2464, 1.2913, 1.2189, 1.2434, 1.2898, 1.2294, 1.2563, 1.1803, 1.2213,
         1.3659, 1.4031, 1.3842, 1.3730, 1.3878, 1.3225, 1.3692, 1.3715, 1.3166,
         1.3320, 1.2811, 1.2707, 1.2497, 1.3219, 1.2683, 1.3627, 1.2441, 1.2482],
        [1.2685, 1.1774, 0.9940, 1.2179, 1.2900, 1.3194, 1.2428, 1.3106, 1.3106,
         1.5002, 1.7557, 1.5045, 2.2427, 1.5388, 4.6694, 1.6036, 1.4335, 4.4200,
         1.1129, 1.1892, 0.9730, 1.1595, 1.2926, 1.3254, 1.3016, 1.3219, 1.3219,
         1.2909, 1.0304, 1.3395, 1.3184, 1.1308, 1.3521, 1.3768, 1.3019, 1.3247,
         1.3162, 1.4690, 1.3882, 1.2994, 1.3030, 1.4316, 1.3710, 0.4976, 1.3603,
         1.0208, 1.3981, 1.3832, 1.3611, 1.0467, 1.3806, 0.8529, 1.3542, 1.3599],
        [1.1923, 1.2192, 1.2732, 1.2536, 1.2260, 1.1980, 1.2048, 1.1906, 1.1906,
         1.2663, 1.2817, 1.2814, 1.3051, 1.2513, 1.3064, 1.2642, 1.2461, 1.2010,
         2.3623, 2.4267, 2.5330, 2.4775, 2.2510, 2.3381, 2.3687, 2.2388, 2.2388,
         1.2905, 1.2623, 1.2251, 1.2498, 1.2901, 1.2358, 1.2633, 1.2300, 1.2276,
         1.3691, 1.4067, 1.3876, 1.3676, 1.3912, 1.3807, 1.3725, 1.2795, 1.3105,
         1.2954, 1.2875, 1.2769, 1.2556, 1.2485, 1.2748, 1.3259, 1.2498, 1.2541],
        [1.1929, 1.2213, 1.2371, 1.2165, 1.2284, 1.1990, 1.2065, 1.1911, 1.1911,
         1.2635, 1.2403, 1.2794, 1.2912, 1.2477, 1.2567, 1.2612, 1.2500, 1.1199,
         1.2407, 1.2560, 1.2815, 1.2534, 1.2156, 1.1958, 1.2336, 1.2032, 1.2032,
         2.6678, 2.3893, 2.1230, 2.2390, 2.6581, 2.1339, 2.6117, 2.1350, 2.1255,
         1.3511, 1.3912, 1.3536, 1.3438, 1.3744, 1.3570, 1.3533, 1.2154, 1.2977,
         1.3402, 1.2700, 1.1697, 1.2055, 1.3292, 1.2196, 1.3729, 1.1994, 1.2511],
        [1.6558, 1.3365, 0.5963, 0.7995, 1.1535, 1.5467, 1.4854, 1.6528, 1.6528,
         1.5144, 1.2473, 1.3513, 0.8971, 1.6071, 0.2484, 1.5026, 1.6229, 1.1327,
         1.2826, 0.8559, 0.7489, 1.0730, 1.5205, 1.5916, 1.2978, 1.6593, 1.6593,
         0.6877, 0.8217, 1.6244, 1.4188, 0.7763, 1.5646, 1.0742, 1.6741, 1.6035,
         0.3467, 0.1231, 0.0902, 0.3049, 0.5863, 0.7576, 0.2500, 8.9015, 7.1557,
         0.7495, 1.1817, 1.2668, 1.4944, 0.9892, 1.4574, 0.4166, 1.5390, 1.6604],
        [1.2486, 1.2800, 1.3423, 1.3207, 1.2887, 1.2553, 1.2205, 1.2466, 1.2466,
         1.2179, 1.3289, 1.2349, 1.3576, 1.2946, 1.4102, 1.2154, 1.2974, 1.2339,
         1.2991, 1.3307, 1.3448, 1.3124, 1.2715, 1.2615, 1.2270, 1.2578, 1.2578,
         1.3166, 1.3608, 1.2768, 1.1141, 1.2663, 1.1526, 1.3203, 1.1523, 1.2796,
         1.3709, 1.0848, 1.3924, 1.3793, 0.9783, 0.8827, 1.3748, 1.3727, 0.7733,
         2.7534, 2.3181, 2.8157, 2.5162, 2.0044, 1.7254, 2.6157, 2.6595, 1.7066]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 128 : 180.7296873422655
Test loss for epoch 128 : 180.7938892403667
Test Precision for epoch 128 : 0.26153846153846155
Test Recall for epoch 128 : 0.26153846153846155
Test F1 for epoch 128 : 0.26153846153846155


theta for epoch 129 : tensor([[2.3000, 2.3294, 2.4022, 2.4823, 2.4456, 2.3059, 2.4219, 2.2982, 2.2982,
         1.2601, 1.2750, 1.2751, 1.2989, 1.2452, 1.3443, 1.2579, 1.2475, 1.2284,
         1.2314, 1.2156, 1.2272, 1.2435, 1.2078, 1.2000, 1.2253, 1.1961, 1.1961,
         1.2460, 1.2908, 1.2186, 1.2429, 1.2894, 1.2291, 1.2560, 1.1799, 1.2210,
         1.3659, 1.4031, 1.3842, 1.3730, 1.3879, 1.3225, 1.3692, 1.3713, 1.3164,
         1.3317, 1.2808, 1.2704, 1.2494, 1.3216, 1.2680, 1.3624, 1.2437, 1.2479],
        [1.2682, 1.1771, 0.9937, 1.2176, 1.2899, 1.3190, 1.2425, 1.3102, 1.3102,
         1.5014, 1.7567, 1.5057, 2.2452, 1.5400, 4.6870, 1.6050, 1.4346, 4.4397,
         1.1126, 1.1889, 0.9728, 1.1592, 1.2923, 1.3251, 1.3013, 1.3216, 1.3216,
         1.2909, 1.0301, 1.3393, 1.3183, 1.1307, 1.3519, 1.3768, 1.3017, 1.3247,
         1.3161, 1.4689, 1.3878, 1.2989, 1.3027, 1.4314, 1.3706, 0.4969, 1.3597,
         1.0208, 1.3979, 1.3830, 1.3608, 1.0465, 1.3804, 0.8530, 1.3539, 1.3596],
        [1.1918, 1.2187, 1.2728, 1.2532, 1.2255, 1.1976, 1.2044, 1.1902, 1.1902,
         1.2661, 1.2815, 1.2812, 1.3049, 1.2510, 1.3063, 1.2639, 1.2457, 1.2010,
         2.3673, 2.4322, 2.5387, 2.4830, 2.2560, 2.3434, 2.3739, 2.2437, 2.2437,
         1.2901, 1.2620, 1.2248, 1.2494, 1.2897, 1.2354, 1.2630, 1.2296, 1.2272,
         1.3692, 1.4068, 1.3876, 1.3676, 1.3913, 1.3807, 1.3725, 1.2794, 1.3102,
         1.2952, 1.2871, 1.2766, 1.2553, 1.2485, 1.2745, 1.3257, 1.2494, 1.2537],
        [1.1925, 1.2209, 1.2376, 1.2171, 1.2280, 1.1986, 1.2061, 1.1907, 1.1907,
         1.2633, 1.2411, 1.2792, 1.2914, 1.2475, 1.2566, 1.2610, 1.2497, 1.1214,
         1.2404, 1.2560, 1.2811, 1.2531, 1.2153, 1.1958, 1.2333, 1.2028, 1.2028,
         2.6718, 2.3963, 2.1290, 2.2454, 2.6622, 2.1399, 2.6159, 2.1409, 2.1314,
         1.3513, 1.3914, 1.3541, 1.3444, 1.3747, 1.3574, 1.3535, 1.2174, 1.2977,
         1.3399, 1.2702, 1.1697, 1.2053, 1.3289, 1.2206, 1.3725, 1.1991, 1.2508],
        [1.6567, 1.3375, 0.5971, 0.8002, 1.1544, 1.5476, 1.4863, 1.6537, 1.6537,
         1.5150, 1.2472, 1.3520, 0.8977, 1.6076, 0.2496, 1.5033, 1.6235, 1.1322,
         1.2835, 0.8569, 0.7500, 1.0741, 1.5214, 1.5922, 1.2990, 1.6602, 1.6602,
         0.6884, 0.8230, 1.6253, 1.4201, 0.7769, 1.5654, 1.0745, 1.6751, 1.6043,
         0.3434, 0.1200, 0.0875, 0.3017, 0.5821, 0.7534, 0.2468, 8.9518, 7.1765,
         0.7507, 1.1823, 1.2676, 1.4950, 0.9901, 1.4571, 0.4178, 1.5398, 1.6610],
        [1.2483, 1.2796, 1.3420, 1.3204, 1.2884, 1.2550, 1.2201, 1.2463, 1.2463,
         1.2176, 1.3287, 1.2347, 1.3574, 1.2943, 1.4100, 1.2151, 1.2971, 1.2337,
         1.2988, 1.3304, 1.3444, 1.3121, 1.2712, 1.2612, 1.2265, 1.2574, 1.2574,
         1.3163, 1.3605, 1.2764, 1.1135, 1.2662, 1.1525, 1.3201, 1.1519, 1.2793,
         1.3707, 1.0841, 1.3920, 1.3790, 0.9776, 0.8819, 1.3745, 1.3723, 0.7723,
         2.7603, 2.3227, 2.8241, 2.5213, 2.0075, 1.7278, 2.6213, 2.6674, 1.7089]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 129 : 180.72058483776848
Test loss for epoch 129 : 180.78534112651923
Test Precision for epoch 129 : 0.26153846153846155
Test Recall for epoch 129 : 0.26153846153846155
Test F1 for epoch 129 : 0.26153846153846155


theta for epoch 130 : tensor([[2.3050, 2.3344, 2.4073, 2.4880, 2.4513, 2.3110, 2.4275, 2.3033, 2.3033,
         1.2597, 1.2748, 1.2748, 1.2986, 1.2448, 1.3441, 1.2576, 1.2472, 1.2281,
         1.2311, 1.2153, 1.2268, 1.2431, 1.2075, 1.1997, 1.2250, 1.1958, 1.1958,
         1.2456, 1.2903, 1.2182, 1.2425, 1.2890, 1.2287, 1.2557, 1.1795, 1.2206,
         1.3659, 1.4031, 1.3840, 1.3730, 1.3880, 1.3224, 1.3691, 1.3710, 1.3162,
         1.3314, 1.2805, 1.2700, 1.2491, 1.3212, 1.2677, 1.3621, 1.2433, 1.2475],
        [1.2679, 1.1769, 0.9936, 1.2175, 1.2899, 1.3187, 1.2422, 1.3099, 1.3099,
         1.5024, 1.7576, 1.5068, 2.2475, 1.5411, 4.7047, 1.6062, 1.4356, 4.4595,
         1.1123, 1.1888, 0.9727, 1.1589, 1.2921, 1.3249, 1.3010, 1.3213, 1.3213,
         1.2909, 1.0298, 1.3391, 1.3181, 1.1307, 1.3518, 1.3768, 1.3015, 1.3247,
         1.3159, 1.4686, 1.3874, 1.2984, 1.3025, 1.4312, 1.3703, 0.4961, 1.3591,
         1.0207, 1.3977, 1.3828, 1.3606, 1.0463, 1.3803, 0.8532, 1.3535, 1.3593],
        [1.1915, 1.2184, 1.2724, 1.2528, 1.2252, 1.1972, 1.2040, 1.1898, 1.1898,
         1.2657, 1.2812, 1.2809, 1.3046, 1.2507, 1.3061, 1.2636, 1.2453, 1.2010,
         2.3724, 2.4377, 2.5444, 2.4885, 2.2610, 2.3488, 2.3792, 2.2488, 2.2488,
         1.2897, 1.2616, 1.2244, 1.2489, 1.2893, 1.2350, 1.2627, 1.2292, 1.2269,
         1.3691, 1.4068, 1.3874, 1.3675, 1.3914, 1.3807, 1.3725, 1.2793, 1.3100,
         1.2950, 1.2868, 1.2762, 1.2550, 1.2484, 1.2742, 1.3255, 1.2490, 1.2534],
        [1.1922, 1.2205, 1.2382, 1.2176, 1.2276, 1.1983, 1.2058, 1.1904, 1.1904,
         1.2630, 1.2418, 1.2789, 1.2916, 1.2472, 1.2564, 1.2607, 1.2494, 1.1228,
         1.2400, 1.2560, 1.2807, 1.2527, 1.2150, 1.1958, 1.2329, 1.2025, 1.2025,
         2.6758, 2.4033, 2.1350, 2.2518, 2.6664, 2.1459, 2.6201, 2.1469, 2.1375,
         1.3515, 1.3916, 1.3546, 1.3449, 1.3749, 1.3578, 1.3537, 1.2192, 1.2978,
         1.3395, 1.2703, 1.1697, 1.2049, 1.3286, 1.2216, 1.3722, 1.1987, 1.2504],
        [1.6576, 1.3384, 0.5979, 0.8009, 1.1553, 1.5485, 1.4873, 1.6546, 1.6546,
         1.5156, 1.2471, 1.3526, 0.8982, 1.6081, 0.2508, 1.5038, 1.6241, 1.1317,
         1.2845, 0.8579, 0.7511, 1.0751, 1.5224, 1.5928, 1.3002, 1.6611, 1.6611,
         0.6891, 0.8243, 1.6263, 1.4214, 0.7776, 1.5662, 1.0748, 1.6762, 1.6051,
         0.3401, 0.1170, 0.0848, 0.2986, 0.5780, 0.7492, 0.2437, 9.0020, 7.1968,
         0.7520, 1.1828, 1.2683, 1.4956, 0.9910, 1.4567, 0.4190, 1.5406, 1.6616],
        [1.2481, 1.2795, 1.3419, 1.3203, 1.2882, 1.2547, 1.2199, 1.2461, 1.2461,
         1.2174, 1.3287, 1.2346, 1.3573, 1.2941, 1.4099, 1.2150, 1.2969, 1.2337,
         1.2987, 1.3303, 1.3442, 1.3120, 1.2710, 1.2611, 1.2261, 1.2573, 1.2573,
         1.3161, 1.3603, 1.2762, 1.1130, 1.2663, 1.1525, 1.3200, 1.1516, 1.2791,
         1.3704, 1.0834, 1.3917, 1.3787, 0.9769, 0.8811, 1.3742, 1.3719, 0.7713,
         2.7670, 2.3270, 2.8324, 2.5263, 2.0104, 1.7300, 2.6268, 2.6751, 1.7111]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 130 : 180.71161707931623
Test loss for epoch 130 : 180.77699517981273
Test Precision for epoch 130 : 0.26153846153846155
Test Recall for epoch 130 : 0.26153846153846155
Test F1 for epoch 130 : 0.26153846153846155


theta for epoch 131 : tensor([[2.3100, 2.3394, 2.4122, 2.4935, 2.4568, 2.3159, 2.4331, 2.3082, 2.3082,
         1.2594, 1.2746, 1.2745, 1.2983, 1.2445, 1.3438, 1.2573, 1.2469, 1.2279,
         1.2307, 1.2149, 1.2265, 1.2428, 1.2072, 1.1994, 1.2246, 1.1954, 1.1954,
         1.2451, 1.2897, 1.2178, 1.2420, 1.2886, 1.2283, 1.2553, 1.1790, 1.2202,
         1.3659, 1.4032, 1.3840, 1.3730, 1.3881, 1.3224, 1.3691, 1.3707, 1.3161,
         1.3312, 1.2803, 1.2698, 1.2489, 1.3210, 1.2675, 1.3619, 1.2430, 1.2473],
        [1.2676, 1.1767, 0.9934, 1.2173, 1.2899, 1.3184, 1.2420, 1.3096, 1.3096,
         1.5034, 1.7584, 1.5079, 2.2497, 1.5422, 4.7224, 1.6074, 1.4365, 4.4793,
         1.1121, 1.1886, 0.9726, 1.1587, 1.2918, 1.3246, 1.3006, 1.3210, 1.3210,
         1.2908, 1.0295, 1.3389, 1.3178, 1.1306, 1.3515, 1.3767, 1.3012, 1.3247,
         1.3157, 1.4684, 1.3870, 1.2980, 1.3022, 1.4310, 1.3699, 0.4954, 1.3585,
         1.0208, 1.3976, 1.3827, 1.3605, 1.0462, 1.3802, 0.8534, 1.3532, 1.3591],
        [1.1911, 1.2180, 1.2721, 1.2525, 1.2249, 1.1969, 1.2037, 1.1894, 1.1894,
         1.2654, 1.2810, 1.2806, 1.3044, 1.2504, 1.3060, 1.2633, 1.2450, 1.2011,
         2.3774, 2.4431, 2.5499, 2.4939, 2.2659, 2.3540, 2.3844, 2.2537, 2.2537,
         1.2892, 1.2612, 1.2240, 1.2485, 1.2888, 1.2346, 1.2624, 1.2288, 1.2264,
         1.3691, 1.4068, 1.3874, 1.3674, 1.3915, 1.3807, 1.3725, 1.2793, 1.3098,
         1.2948, 1.2866, 1.2760, 1.2548, 1.2485, 1.2740, 1.3254, 1.2487, 1.2531],
        [1.1917, 1.2201, 1.2387, 1.2182, 1.2272, 1.1978, 1.2053, 1.1899, 1.1899,
         1.2627, 1.2425, 1.2786, 1.2916, 1.2469, 1.2561, 1.2604, 1.2491, 1.1242,
         1.2396, 1.2559, 1.2802, 1.2523, 1.2145, 1.1957, 1.2325, 1.2021, 1.2021,
         2.6798, 2.4103, 2.1410, 2.2582, 2.6706, 2.1519, 2.6242, 2.1528, 2.1435,
         1.3516, 1.3917, 1.3551, 1.3455, 1.3751, 1.3581, 1.3539, 1.2211, 1.2978,
         1.3392, 1.2705, 1.1697, 1.2047, 1.3283, 1.2226, 1.3719, 1.1984, 1.2501],
        [1.6584, 1.3394, 0.5987, 0.8015, 1.1561, 1.5494, 1.4882, 1.6554, 1.6554,
         1.5162, 1.2470, 1.3533, 0.8988, 1.6086, 0.2519, 1.5044, 1.6246, 1.1312,
         1.2855, 0.8589, 0.7522, 1.0761, 1.5233, 1.5933, 1.3013, 1.6620, 1.6620,
         0.6897, 0.8255, 1.6272, 1.4227, 0.7781, 1.5670, 1.0751, 1.6771, 1.6058,
         0.3369, 0.1140, 0.0822, 0.2955, 0.5739, 0.7450, 0.2407, 9.0519, 7.2165,
         0.7533, 1.1835, 1.2692, 1.4962, 0.9921, 1.4564, 0.4203, 1.5414, 1.6622],
        [1.2478, 1.2792, 1.3417, 1.3201, 1.2880, 1.2545, 1.2197, 1.2458, 1.2458,
         1.2172, 1.3286, 1.2344, 1.3572, 1.2939, 1.4098, 1.2148, 1.2967, 1.2336,
         1.2986, 1.3301, 1.3439, 1.3118, 1.2708, 1.2609, 1.2257, 1.2571, 1.2571,
         1.3158, 1.3600, 1.2759, 1.1123, 1.2662, 1.1524, 1.3198, 1.1513, 1.2787,
         1.3701, 1.0827, 1.3913, 1.3784, 0.9761, 0.8803, 1.3740, 1.3715, 0.7704,
         2.7738, 2.3314, 2.8407, 2.5313, 2.0133, 1.7322, 2.6323, 2.6828, 1.7133]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 131 : 180.70278363567638
Test loss for epoch 131 : 180.76874216402564
Test Precision for epoch 131 : 0.26153846153846155
Test Recall for epoch 131 : 0.26153846153846155
Test F1 for epoch 131 : 0.26153846153846155


theta for epoch 132 : tensor([[2.3149, 2.3442, 2.4171, 2.4990, 2.4622, 2.3208, 2.4385, 2.3131, 2.3131,
         1.2592, 1.2744, 1.2743, 1.2981, 1.2443, 1.3436, 1.2570, 1.2466, 1.2277,
         1.2304, 1.2146, 1.2262, 1.2425, 1.2068, 1.1991, 1.2243, 1.1951, 1.1951,
         1.2446, 1.2891, 1.2173, 1.2415, 1.2881, 1.2277, 1.2549, 1.1784, 1.2197,
         1.3660, 1.4033, 1.3840, 1.3730, 1.3883, 1.3224, 1.3692, 1.3705, 1.3161,
         1.3310, 1.2801, 1.2696, 1.2487, 1.3208, 1.2674, 1.3617, 1.2427, 1.2471],
        [1.2673, 1.1765, 0.9932, 1.2172, 1.2900, 1.3181, 1.2417, 1.3093, 1.3093,
         1.5044, 1.7592, 1.5088, 2.2517, 1.5432, 4.7402, 1.6086, 1.4374, 4.4990,
         1.1118, 1.1885, 0.9725, 1.1585, 1.2915, 1.3244, 1.3003, 1.3208, 1.3208,
         1.2906, 1.0291, 1.3386, 1.3175, 1.1304, 1.3512, 1.3766, 1.3008, 1.3246,
         1.3156, 1.4683, 1.3867, 1.2976, 1.3021, 1.4308, 1.3696, 0.4948, 1.3580,
         1.0208, 1.3976, 1.3826, 1.3604, 1.0461, 1.3801, 0.8536, 1.3530, 1.3590],
        [1.1907, 1.2177, 1.2717, 1.2522, 1.2246, 1.1965, 1.2033, 1.1891, 1.1891,
         1.2652, 1.2808, 1.2804, 1.3042, 1.2501, 1.3058, 1.2630, 1.2447, 1.2012,
         2.3823, 2.4484, 2.5554, 2.4992, 2.2708, 2.3591, 2.3895, 2.2585, 2.2585,
         1.2887, 1.2608, 1.2235, 1.2479, 1.2883, 1.2341, 1.2619, 1.2282, 1.2259,
         1.3692, 1.4069, 1.3874, 1.3674, 1.3917, 1.3808, 1.3725, 1.2793, 1.3096,
         1.2947, 1.2864, 1.2757, 1.2546, 1.2486, 1.2738, 1.3254, 1.2485, 1.2529],
        [1.1913, 1.2196, 1.2392, 1.2187, 1.2267, 1.1974, 1.2049, 1.1895, 1.1895,
         1.2624, 1.2432, 1.2783, 1.2918, 1.2466, 1.2559, 1.2601, 1.2488, 1.1255,
         1.2392, 1.2558, 1.2798, 1.2519, 1.2141, 1.1956, 1.2321, 1.2017, 1.2017,
         2.6837, 2.4172, 2.1469, 2.2646, 2.6746, 2.1579, 2.6283, 2.1586, 2.1494,
         1.3519, 1.3920, 1.3557, 1.3460, 1.3755, 1.3585, 1.3541, 1.2230, 1.2979,
         1.3389, 1.2707, 1.1697, 1.2044, 1.3280, 1.2236, 1.3716, 1.1981, 1.2499],
        [1.6593, 1.3403, 0.5995, 0.8022, 1.1570, 1.5503, 1.4891, 1.6563, 1.6563,
         1.5168, 1.2469, 1.3540, 0.8994, 1.6092, 0.2531, 1.5050, 1.6252, 1.1307,
         1.2864, 0.8599, 0.7532, 1.0771, 1.5242, 1.5939, 1.3025, 1.6628, 1.6628,
         0.6903, 0.8267, 1.6280, 1.4238, 0.7787, 1.5677, 1.0753, 1.6780, 1.6065,
         0.3337, 0.1111, 0.0796, 0.2925, 0.5699, 0.7409, 0.2377, 9.1016, 7.2358,
         0.7547, 1.1843, 1.2701, 1.4969, 0.9931, 1.4562, 0.4216, 1.5423, 1.6628],
        [1.2475, 1.2789, 1.3414, 1.3198, 1.2877, 1.2541, 1.2193, 1.2454, 1.2454,
         1.2169, 1.3284, 1.2341, 1.3570, 1.2936, 1.4097, 1.2145, 1.2964, 1.2334,
         1.2983, 1.3299, 1.3436, 1.3115, 1.2706, 1.2606, 1.2252, 1.2568, 1.2568,
         1.3154, 1.3596, 1.2754, 1.1116, 1.2660, 1.1522, 1.3195, 1.1508, 1.2783,
         1.3699, 1.0820, 1.3910, 1.3782, 0.9754, 0.8795, 1.3737, 1.3712, 0.7694,
         2.7808, 2.3359, 2.8491, 2.5365, 2.0163, 1.7346, 2.6379, 2.6907, 1.7155]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 132 : 180.6940801073493
Test loss for epoch 132 : 180.76057192723675
Test Precision for epoch 132 : 0.26153846153846155
Test Recall for epoch 132 : 0.26153846153846155
Test F1 for epoch 132 : 0.26153846153846155


theta for epoch 133 : tensor([[2.3198, 2.3491, 2.4220, 2.5045, 2.4677, 2.3257, 2.4440, 2.3180, 2.3180,
         1.2589, 1.2742, 1.2740, 1.2979, 1.2440, 1.3434, 1.2568, 1.2463, 1.2275,
         1.2302, 1.2143, 1.2259, 1.2422, 1.2066, 1.1989, 1.2240, 1.1949, 1.1949,
         1.2441, 1.2886, 1.2168, 1.2410, 1.2876, 1.2273, 1.2545, 1.1780, 1.2192,
         1.3661, 1.4034, 1.3840, 1.3731, 1.3885, 1.3225, 1.3693, 1.3704, 1.3161,
         1.3306, 1.2798, 1.2692, 1.2484, 1.3204, 1.2670, 1.3613, 1.2423, 1.2467],
        [1.2671, 1.1764, 0.9931, 1.2171, 1.2901, 1.3179, 1.2416, 1.3091, 1.3091,
         1.5052, 1.7599, 1.5097, 2.2537, 1.5441, 4.7580, 1.6096, 1.4382, 4.5188,
         1.1117, 1.1884, 0.9725, 1.1583, 1.2913, 1.3242, 1.3001, 1.3205, 1.3205,
         1.2906, 1.0287, 1.3384, 1.3173, 1.1303, 1.3510, 1.3766, 1.3005, 1.3246,
         1.3155, 1.4682, 1.3864, 1.2973, 1.3019, 1.4308, 1.3694, 0.4943, 1.3576,
         1.0206, 1.3974, 1.3823, 1.3601, 1.0458, 1.3799, 0.8536, 1.3526, 1.3587],
        [1.1904, 1.2174, 1.2715, 1.2519, 1.2243, 1.1962, 1.2031, 1.1888, 1.1888,
         1.2649, 1.2806, 1.2801, 1.3040, 1.2499, 1.3057, 1.2627, 1.2443, 1.2013,
         2.3872, 2.4537, 2.5609, 2.5045, 2.2756, 2.3643, 2.3947, 2.2634, 2.2634,
         1.2882, 1.2604, 1.2231, 1.2474, 1.2878, 1.2337, 1.2616, 1.2278, 1.2255,
         1.3693, 1.4071, 1.3874, 1.3674, 1.3919, 1.3810, 1.3726, 1.2794, 1.3096,
         1.2944, 1.2861, 1.2753, 1.2543, 1.2485, 1.2734, 1.3251, 1.2480, 1.2525],
        [1.1909, 1.2193, 1.2397, 1.2192, 1.2264, 1.1970, 1.2045, 1.1891, 1.1891,
         1.2621, 1.2440, 1.2781, 1.2919, 1.2464, 1.2557, 1.2598, 1.2486, 1.1269,
         1.2389, 1.2558, 1.2794, 1.2515, 1.2138, 1.1955, 1.2318, 1.2013, 1.2013,
         2.6876, 2.4241, 2.1528, 2.2709, 2.6786, 2.1638, 2.6323, 2.1645, 2.1553,
         1.3521, 1.3923, 1.3563, 1.3467, 1.3758, 1.3590, 1.3544, 1.2250, 1.2981,
         1.3385, 1.2708, 1.1696, 1.2041, 1.3276, 1.2245, 1.3711, 1.1977, 1.2495],
        [1.6601, 1.3412, 0.6003, 0.8029, 1.1579, 1.5512, 1.4900, 1.6571, 1.6571,
         1.5173, 1.2469, 1.3546, 0.8999, 1.6097, 0.2542, 1.5056, 1.6258, 1.1303,
         1.2874, 0.8609, 0.7543, 1.0781, 1.5252, 1.5944, 1.3036, 1.6637, 1.6637,
         0.6910, 0.8280, 1.6289, 1.4250, 0.7793, 1.5684, 1.0755, 1.6789, 1.6072,
         0.3307, 0.1082, 0.0771, 0.2896, 0.5659, 0.7368, 0.2348, 9.1511, 7.2545,
         0.7558, 1.1849, 1.2708, 1.4974, 0.9940, 1.4559, 0.4227, 1.5430, 1.6633],
        [1.2471, 1.2786, 1.3411, 1.3196, 1.2874, 1.2537, 1.2189, 1.2451, 1.2451,
         1.2167, 1.3283, 1.2339, 1.3568, 1.2934, 1.4095, 1.2142, 1.2961, 1.2332,
         1.2981, 1.3297, 1.3433, 1.3113, 1.2703, 1.2604, 1.2247, 1.2565, 1.2565,
         1.3150, 1.3592, 1.2750, 1.1109, 1.2659, 1.1520, 1.3193, 1.1504, 1.2779,
         1.3696, 1.0813, 1.3908, 1.3780, 0.9748, 0.8788, 1.3735, 1.3709, 0.7685,
         2.7877, 2.3403, 2.8575, 2.5416, 2.0192, 1.7368, 2.6434, 2.6984, 1.7177]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 133 : 180.6855011525469
Test loss for epoch 133 : 180.7525538977002
Test Precision for epoch 133 : 0.26153846153846155
Test Recall for epoch 133 : 0.26153846153846155
Test F1 for epoch 133 : 0.26153846153846155


theta for epoch 134 : tensor([[2.3247, 2.3540, 2.4269, 2.5099, 2.4731, 2.3306, 2.4495, 2.3229, 2.3229,
         1.2586, 1.2740, 1.2738, 1.2977, 1.2438, 1.3432, 1.2565, 1.2461, 1.2274,
         1.2299, 1.2140, 1.2256, 1.2419, 1.2063, 1.1986, 1.2237, 1.1946, 1.1946,
         1.2438, 1.2882, 1.2165, 1.2406, 1.2873, 1.2270, 1.2543, 1.1776, 1.2189,
         1.3662, 1.4035, 1.3840, 1.3732, 1.3887, 1.3225, 1.3693, 1.3702, 1.3161,
         1.3301, 1.2794, 1.2687, 1.2480, 1.3200, 1.2666, 1.3609, 1.2418, 1.2462],
        [1.2669, 1.1762, 0.9929, 1.2170, 1.2901, 1.3177, 1.2414, 1.3088, 1.3088,
         1.5060, 1.7606, 1.5107, 2.2556, 1.5450, 4.7759, 1.6106, 1.4390, 4.5387,
         1.1115, 1.1882, 0.9724, 1.1581, 1.2911, 1.3240, 1.2997, 1.3203, 1.3203,
         1.2906, 1.0285, 1.3382, 1.3172, 1.1303, 1.3509, 1.3766, 1.3004, 1.3247,
         1.3154, 1.4680, 1.3861, 1.2969, 1.3018, 1.4307, 1.3691, 0.4937, 1.3571,
         1.0204, 1.3971, 1.3820, 1.3597, 1.0455, 1.3796, 0.8536, 1.3522, 1.3583],
        [1.1900, 1.2170, 1.2711, 1.2516, 1.2239, 1.1959, 1.2027, 1.1884, 1.1884,
         1.2646, 1.2804, 1.2799, 1.3038, 1.2496, 1.3056, 1.2625, 1.2440, 1.2014,
         2.3921, 2.4590, 2.5664, 2.5098, 2.2805, 2.3695, 2.3998, 2.2683, 2.2683,
         1.2878, 1.2602, 1.2227, 1.2471, 1.2874, 1.2333, 1.2613, 1.2275, 1.2251,
         1.3694, 1.4072, 1.3875, 1.3674, 1.3921, 1.3811, 1.3727, 1.2795, 1.3095,
         1.2940, 1.2856, 1.2749, 1.2539, 1.2484, 1.2730, 1.3248, 1.2475, 1.2521],
        [1.1905, 1.2189, 1.2402, 1.2198, 1.2260, 1.1966, 1.2041, 1.1887, 1.1887,
         1.2619, 1.2448, 1.2779, 1.2921, 1.2462, 1.2555, 1.2597, 1.2484, 1.1283,
         1.2385, 1.2558, 1.2791, 1.2512, 1.2134, 1.1955, 1.2314, 1.2010, 1.2010,
         2.6914, 2.4310, 2.1587, 2.2772, 2.6826, 2.1697, 2.6363, 2.1702, 2.1612,
         1.3524, 1.3925, 1.3569, 1.3473, 1.3762, 1.3595, 1.3547, 1.2269, 1.2983,
         1.3381, 1.2708, 1.1695, 1.2037, 1.3272, 1.2254, 1.3707, 1.1972, 1.2491],
        [1.6610, 1.3422, 0.6011, 0.8036, 1.1588, 1.5521, 1.4909, 1.6580, 1.6580,
         1.5179, 1.2468, 1.3553, 0.9006, 1.6102, 0.2554, 1.5062, 1.6264, 1.1299,
         1.2883, 0.8619, 0.7554, 1.0791, 1.5261, 1.5950, 1.3048, 1.6645, 1.6645,
         0.6917, 0.8292, 1.6298, 1.4263, 0.7799, 1.5693, 1.0759, 1.6799, 1.6079,
         0.3276, 0.1053, 0.0746, 0.2867, 0.5620, 0.7327, 0.2319, 9.2004, 7.2726,
         0.7569, 1.1854, 1.2716, 1.4978, 0.9948, 1.4554, 0.4238, 1.5437, 1.6637],
        [1.2468, 1.2782, 1.3408, 1.3193, 1.2871, 1.2533, 1.2186, 1.2447, 1.2447,
         1.2164, 1.3282, 1.2337, 1.3566, 1.2931, 1.4093, 1.2140, 1.2959, 1.2330,
         1.2978, 1.3294, 1.3429, 1.3110, 1.2700, 1.2601, 1.2241, 1.2562, 1.2562,
         1.3148, 1.3589, 1.2747, 1.1103, 1.2658, 1.1519, 1.3191, 1.1501, 1.2776,
         1.3694, 1.0806, 1.3905, 1.3777, 0.9741, 0.8780, 1.3732, 1.3705, 0.7676,
         2.7946, 2.3447, 2.8658, 2.5467, 2.0221, 1.7390, 2.6489, 2.7061, 1.7199]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 134 : 180.67704578422683
Test loss for epoch 134 : 180.74468996734572
Test Precision for epoch 134 : 0.26153846153846155
Test Recall for epoch 134 : 0.26153846153846155
Test F1 for epoch 134 : 0.26153846153846155


theta for epoch 135 : tensor([[2.3295, 2.3588, 2.4317, 2.5154, 2.4785, 2.3354, 2.4549, 2.3277, 2.3277,
         1.2584, 1.2738, 1.2736, 1.2975, 1.2435, 1.3429, 1.2563, 1.2459, 1.2271,
         1.2295, 1.2136, 1.2252, 1.2416, 1.2059, 1.1982, 1.2234, 1.1942, 1.1942,
         1.2435, 1.2878, 1.2161, 1.2402, 1.2870, 1.2266, 1.2540, 1.1772, 1.2185,
         1.3662, 1.4036, 1.3840, 1.3732, 1.3888, 1.3226, 1.3694, 1.3700, 1.3160,
         1.3298, 1.2791, 1.2684, 1.2477, 1.3197, 1.2663, 1.3605, 1.2414, 1.2459],
        [1.2667, 1.1761, 0.9928, 1.2169, 1.2902, 1.3175, 1.2413, 1.3086, 1.3086,
         1.5068, 1.7612, 1.5115, 2.2574, 1.5458, 4.7939, 1.6115, 1.4397, 4.5586,
         1.1112, 1.1881, 0.9723, 1.1579, 1.2908, 1.3237, 1.2994, 1.3200, 1.3200,
         1.2907, 1.0283, 1.3381, 1.3170, 1.1302, 1.3507, 1.3767, 1.3002, 1.3247,
         1.3153, 1.4679, 1.3858, 1.2965, 1.3016, 1.4305, 1.3688, 0.4932, 1.3566,
         1.0203, 1.3969, 1.3818, 1.3595, 1.0452, 1.3795, 0.8536, 1.3519, 1.3580],
        [1.1896, 1.2167, 1.2707, 1.2512, 1.2236, 1.1955, 1.2024, 1.1880, 1.1880,
         1.2644, 1.2802, 1.2796, 1.3036, 1.2494, 1.3055, 1.2622, 1.2437, 1.2015,
         2.3969, 2.4642, 2.5718, 2.5150, 2.2853, 2.3746, 2.4048, 2.2731, 2.2731,
         1.2874, 1.2599, 1.2224, 1.2467, 1.2870, 1.2330, 1.2610, 1.2271, 1.2248,
         1.3695, 1.4073, 1.3875, 1.3674, 1.3923, 1.3812, 1.3728, 1.2796, 1.3094,
         1.2938, 1.2853, 1.2746, 1.2536, 1.2483, 1.2727, 1.3245, 1.2472, 1.2517],
        [1.1902, 1.2185, 1.2408, 1.2204, 1.2257, 1.1962, 1.2038, 1.1884, 1.1884,
         1.2617, 1.2455, 1.2777, 1.2922, 1.2460, 1.2554, 1.2595, 1.2482, 1.1297,
         1.2382, 1.2557, 1.2787, 1.2509, 1.2131, 1.1955, 1.2311, 1.2007, 1.2007,
         2.6951, 2.4378, 2.1645, 2.2834, 2.6864, 2.1755, 2.6401, 2.1760, 2.1670,
         1.3526, 1.3928, 1.3574, 1.3479, 1.3765, 1.3599, 1.3550, 1.2288, 1.2985,
         1.3377, 1.2709, 1.1695, 1.2035, 1.3269, 1.2264, 1.3704, 1.1969, 1.2488],
        [1.6618, 1.3430, 0.6019, 0.8042, 1.1597, 1.5529, 1.4918, 1.6588, 1.6588,
         1.5185, 1.2468, 1.3560, 0.9012, 1.6107, 0.2564, 1.5067, 1.6270, 1.1295,
         1.2892, 0.8628, 0.7564, 1.0800, 1.5269, 1.5955, 1.3059, 1.6653, 1.6653,
         0.6924, 0.8305, 1.6307, 1.4276, 0.7806, 1.5701, 1.0762, 1.6808, 1.6087,
         0.3247, 0.1025, 0.0721, 0.2838, 0.5582, 0.7287, 0.2291, 9.2496, 7.2903,
         0.7581, 1.1860, 1.2724, 1.4984, 0.9957, 1.4552, 0.4249, 1.5444, 1.6642],
        [1.2464, 1.2779, 1.3405, 1.3189, 1.2867, 1.2530, 1.2182, 1.2443, 1.2443,
         1.2162, 1.3280, 1.2334, 1.3564, 1.2929, 1.4091, 1.2137, 1.2956, 1.2328,
         1.2975, 1.3291, 1.3426, 1.3107, 1.2697, 1.2598, 1.2235, 1.2559, 1.2559,
         1.3145, 1.3586, 1.2744, 1.1097, 1.2657, 1.1517, 1.3189, 1.1497, 1.2773,
         1.3691, 1.0799, 1.3902, 1.3774, 0.9733, 0.8773, 1.3729, 1.3701, 0.7666,
         2.8016, 2.3491, 2.8742, 2.5519, 2.0249, 1.7412, 2.6545, 2.7138, 1.7220]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 135 : 180.6687116437627
Test loss for epoch 135 : 180.73690867035768
Test Precision for epoch 135 : 0.26153846153846155
Test Recall for epoch 135 : 0.26153846153846155
Test F1 for epoch 135 : 0.26153846153846155


theta for epoch 136 : tensor([[2.3343, 2.3636, 2.4365, 2.5208, 2.4839, 2.3402, 2.4603, 2.3325, 2.3325,
         1.2581, 1.2736, 1.2733, 1.2972, 1.2432, 1.3426, 1.2560, 1.2456, 1.2269,
         1.2292, 1.2133, 1.2249, 1.2413, 1.2056, 1.1979, 1.2231, 1.1939, 1.1939,
         1.2431, 1.2873, 1.2157, 1.2398, 1.2866, 1.2262, 1.2537, 1.1767, 1.2181,
         1.3662, 1.4037, 1.3840, 1.3732, 1.3890, 1.3226, 1.3694, 1.3697, 1.3160,
         1.3296, 1.2789, 1.2682, 1.2475, 1.3194, 1.2661, 1.3603, 1.2412, 1.2456],
        [1.2665, 1.1759, 0.9927, 1.2168, 1.2902, 1.3173, 1.2411, 1.3084, 1.3084,
         1.5075, 1.7618, 1.5123, 2.2590, 1.5466, 4.8119, 1.6124, 1.4404, 4.5785,
         1.1110, 1.1879, 0.9723, 1.1577, 1.2907, 1.3235, 1.2991, 1.3198, 1.3198,
         1.2906, 1.0280, 1.3378, 1.3168, 1.1301, 1.3505, 1.3767, 1.3000, 1.3247,
         1.3151, 1.4677, 1.3854, 1.2961, 1.3014, 1.4304, 1.3684, 0.4926, 1.3561,
         1.0202, 1.3969, 1.3817, 1.3593, 1.0451, 1.3794, 0.8538, 1.3516, 1.3578],
        [1.1893, 1.2163, 1.2704, 1.2509, 1.2232, 1.1951, 1.2020, 1.1876, 1.1876,
         1.2640, 1.2800, 1.2794, 1.3034, 1.2491, 1.3054, 1.2619, 1.2434, 1.2016,
         2.4017, 2.4695, 2.5772, 2.5201, 2.2902, 2.3797, 2.4098, 2.2779, 2.2779,
         1.2870, 1.2596, 1.2220, 1.2462, 1.2865, 1.2325, 1.2607, 1.2267, 1.2244,
         1.3695, 1.4074, 1.3874, 1.3674, 1.3924, 1.3813, 1.3728, 1.2796, 1.3093,
         1.2936, 1.2851, 1.2743, 1.2533, 1.2484, 1.2725, 1.3244, 1.2469, 1.2515],
        [1.1899, 1.2182, 1.2413, 1.2210, 1.2254, 1.1959, 1.2035, 1.1881, 1.1881,
         1.2615, 1.2463, 1.2775, 1.2924, 1.2458, 1.2552, 1.2593, 1.2480, 1.1310,
         1.2379, 1.2557, 1.2784, 1.2506, 1.2128, 1.1955, 1.2308, 1.2004, 1.2004,
         2.6988, 2.4445, 2.1702, 2.2896, 2.6902, 2.1812, 2.6439, 2.1816, 2.1727,
         1.3529, 1.3930, 1.3580, 1.3485, 1.3769, 1.3604, 1.3552, 1.2306, 1.2986,
         1.3375, 1.2712, 1.1696, 1.2033, 1.3267, 1.2275, 1.3701, 1.1967, 1.2486],
        [1.6625, 1.3439, 0.6026, 0.8048, 1.1605, 1.5537, 1.4926, 1.6595, 1.6595,
         1.5189, 1.2466, 1.3565, 0.9016, 1.6111, 0.2574, 1.5072, 1.6275, 1.1290,
         1.2901, 0.8637, 0.7573, 1.0809, 1.5278, 1.5960, 1.3070, 1.6661, 1.6661,
         0.6930, 0.8316, 1.6315, 1.4287, 0.7811, 1.5708, 1.0764, 1.6817, 1.6093,
         0.3218, 0.0998, 0.0697, 0.2811, 0.5544, 0.7248, 0.2264, 9.2985, 7.3074,
         0.7592, 1.1867, 1.2732, 1.4990, 0.9966, 1.4549, 0.4259, 1.5453, 1.6647],
        [1.2461, 1.2776, 1.3403, 1.3187, 1.2865, 1.2527, 1.2179, 1.2440, 1.2440,
         1.2159, 1.3278, 1.2331, 1.3562, 1.2926, 1.4089, 1.2135, 1.2954, 1.2326,
         1.2973, 1.3289, 1.3423, 1.3105, 1.2694, 1.2595, 1.2230, 1.2556, 1.2556,
         1.3142, 1.3583, 1.2741, 1.1090, 1.2656, 1.1515, 1.3187, 1.1494, 1.2770,
         1.3688, 1.0792, 1.3898, 1.3771, 0.9726, 0.8765, 1.3726, 1.3697, 0.7657,
         2.8085, 2.3534, 2.8826, 2.5569, 2.0277, 1.7433, 2.6600, 2.7214, 1.7241]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 136 : 180.66049298857172
Test loss for epoch 136 : 180.72927845478085
Test Precision for epoch 136 : 0.26153846153846155
Test Recall for epoch 136 : 0.26153846153846155
Test F1 for epoch 136 : 0.26153846153846155


theta for epoch 137 : tensor([[2.3390, 2.3683, 2.4413, 2.5261, 2.4892, 2.3450, 2.4656, 2.3373, 2.3373,
         1.2578, 1.2734, 1.2730, 1.2970, 1.2430, 1.3424, 1.2557, 1.2454, 1.2267,
         1.2290, 1.2130, 1.2246, 1.2410, 1.2053, 1.1977, 1.2228, 1.1936, 1.1936,
         1.2427, 1.2868, 1.2153, 1.2393, 1.2862, 1.2258, 1.2534, 1.1763, 1.2177,
         1.3663, 1.4038, 1.3840, 1.3732, 1.3891, 1.3227, 1.3694, 1.3695, 1.3159,
         1.3293, 1.2787, 1.2679, 1.2473, 1.3191, 1.2659, 1.3600, 1.2409, 1.2454],
        [1.2663, 1.1758, 0.9926, 1.2167, 1.2903, 1.3171, 1.2410, 1.3082, 1.3082,
         1.5083, 1.7624, 1.5131, 2.2607, 1.5474, 4.8300, 1.6133, 1.4411, 4.5985,
         1.1108, 1.1878, 0.9723, 1.1575, 1.2905, 1.3233, 1.2988, 1.3195, 1.3195,
         1.2906, 1.0277, 1.3376, 1.3166, 1.1300, 1.3503, 1.3767, 1.2997, 1.3247,
         1.3149, 1.4674, 1.3850, 1.2956, 1.3012, 1.4302, 1.3680, 0.4920, 1.3556,
         1.0201, 1.3967, 1.3815, 1.3592, 1.0449, 1.3793, 0.8538, 1.3514, 1.3576],
        [1.1890, 1.2160, 1.2700, 1.2505, 1.2229, 1.1948, 1.2017, 1.1873, 1.1873,
         1.2638, 1.2798, 1.2791, 1.3032, 1.2489, 1.3053, 1.2617, 1.2431, 1.2017,
         2.4065, 2.4746, 2.5824, 2.5252, 2.2949, 2.3847, 2.4148, 2.2827, 2.2827,
         1.2865, 1.2594, 1.2216, 1.2458, 1.2861, 1.2321, 1.2604, 1.2263, 1.2240,
         1.3695, 1.4074, 1.3874, 1.3673, 1.3926, 1.3814, 1.3728, 1.2796, 1.3091,
         1.2934, 1.2849, 1.2740, 1.2531, 1.2484, 1.2723, 1.3242, 1.2466, 1.2512],
        [1.1895, 1.2178, 1.2418, 1.2215, 1.2250, 1.1956, 1.2031, 1.1877, 1.1877,
         1.2613, 1.2470, 1.2773, 1.2925, 1.2456, 1.2550, 1.2591, 1.2478, 1.1323,
         1.2376, 1.2557, 1.2781, 1.2503, 1.2125, 1.1954, 1.2305, 1.2001, 1.2001,
         2.7024, 2.4513, 2.1760, 2.2958, 2.6940, 2.1869, 2.6477, 2.1873, 2.1785,
         1.3531, 1.3933, 1.3585, 1.3490, 1.3772, 1.3608, 1.3555, 1.2324, 1.2988,
         1.3372, 1.2713, 1.1696, 1.2031, 1.3264, 1.2284, 1.3698, 1.1964, 1.2483],
        [1.6633, 1.3447, 0.6033, 0.8053, 1.1612, 1.5545, 1.4933, 1.6602, 1.6602,
         1.5194, 1.2465, 1.3571, 0.9021, 1.6116, 0.2584, 1.5076, 1.6280, 1.1285,
         1.2909, 0.8646, 0.7582, 1.0817, 1.5286, 1.5964, 1.3081, 1.6669, 1.6669,
         0.6935, 0.8327, 1.6322, 1.4298, 0.7816, 1.5716, 1.0766, 1.6825, 1.6099,
         0.3191, 0.0971, 0.0673, 0.2784, 0.5508, 0.7209, 0.2237, 9.3473, 7.3241,
         0.7603, 1.1872, 1.2740, 1.4996, 0.9974, 1.4547, 0.4269, 1.5461, 1.6652],
        [1.2458, 1.2773, 1.3401, 1.3185, 1.2863, 1.2524, 1.2176, 1.2438, 1.2438,
         1.2158, 1.3278, 1.2331, 1.3562, 1.2925, 1.4088, 1.2134, 1.2953, 1.2326,
         1.2972, 1.3288, 1.3422, 1.3104, 1.2693, 1.2594, 1.2226, 1.2554, 1.2554,
         1.3140, 1.3580, 1.2739, 1.1084, 1.2655, 1.1514, 1.3186, 1.1491, 1.2767,
         1.3685, 1.0786, 1.3895, 1.3768, 0.9719, 0.8758, 1.3724, 1.3693, 0.7649,
         2.8153, 2.3575, 2.8907, 2.5619, 2.0302, 1.7453, 2.6653, 2.7288, 1.7260]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 137 : 180.6523880123822
Test loss for epoch 137 : 180.72186581050772
Test Precision for epoch 137 : 0.26153846153846155
Test Recall for epoch 137 : 0.26153846153846155
Test F1 for epoch 137 : 0.26153846153846155


theta for epoch 138 : tensor([[2.3438, 2.3731, 2.4460, 2.5314, 2.4945, 2.3497, 2.4709, 2.3420, 2.3420,
         1.2575, 1.2732, 1.2728, 1.2968, 1.2428, 1.3421, 1.2555, 1.2451, 1.2265,
         1.2287, 1.2127, 1.2243, 1.2407, 1.2050, 1.1974, 1.2225, 1.1933, 1.1933,
         1.2423, 1.2864, 1.2149, 1.2389, 1.2859, 1.2254, 1.2531, 1.1759, 1.2173,
         1.3663, 1.4038, 1.3840, 1.3733, 1.3893, 1.3227, 1.3695, 1.3693, 1.3159,
         1.3290, 1.2784, 1.2677, 1.2470, 1.3189, 1.2657, 1.3597, 1.2406, 1.2451],
        [1.2662, 1.1757, 0.9926, 1.2166, 1.2904, 1.3170, 1.2408, 1.3081, 1.3081,
         1.5090, 1.7629, 1.5138, 2.2622, 1.5481, 4.8481, 1.6141, 1.4418, 4.6184,
         1.1106, 1.1877, 0.9723, 1.1573, 1.2903, 1.3232, 1.2985, 1.3193, 1.3193,
         1.2906, 1.0274, 1.3375, 1.3165, 1.1300, 1.3501, 1.3767, 1.2995, 1.3248,
         1.3147, 1.4672, 1.3846, 1.2952, 1.3010, 1.4301, 1.3676, 0.4915, 1.3551,
         1.0200, 1.3966, 1.3814, 1.3590, 1.0447, 1.3792, 0.8539, 1.3511, 1.3574],
        [1.1886, 1.2156, 1.2697, 1.2502, 1.2225, 1.1944, 1.2014, 1.1869, 1.1869,
         1.2635, 1.2796, 1.2789, 1.3029, 1.2486, 1.3052, 1.2614, 1.2428, 1.2018,
         2.4112, 2.4798, 2.5877, 2.5303, 2.2996, 2.3897, 2.4197, 2.2874, 2.2874,
         1.2861, 1.2591, 1.2212, 1.2454, 1.2856, 1.2318, 1.2601, 1.2259, 1.2236,
         1.3695, 1.4075, 1.3874, 1.3672, 1.3927, 1.3815, 1.3728, 1.2797, 1.3091,
         1.2933, 1.2846, 1.2738, 1.2529, 1.2484, 1.2721, 1.3241, 1.2463, 1.2510],
        [1.1891, 1.2174, 1.2423, 1.2220, 1.2246, 1.1952, 1.2027, 1.1873, 1.1873,
         1.2610, 1.2476, 1.2770, 1.2926, 1.2454, 1.2548, 1.2588, 1.2475, 1.1335,
         1.2372, 1.2556, 1.2777, 1.2499, 1.2121, 1.1953, 1.2302, 1.1997, 1.1997,
         2.7061, 2.4581, 2.1817, 2.3020, 2.6978, 2.1927, 2.6516, 2.1930, 2.1842,
         1.3533, 1.3935, 1.3590, 1.3495, 1.3775, 1.3612, 1.3557, 1.2341, 1.2989,
         1.3369, 1.2714, 1.1696, 1.2028, 1.3261, 1.2294, 1.3694, 1.1961, 1.2480],
        [1.6640, 1.3455, 0.6041, 0.8060, 1.1620, 1.5553, 1.4941, 1.6610, 1.6610,
         1.5199, 1.2464, 1.3577, 0.9026, 1.6120, 0.2594, 1.5081, 1.6284, 1.1281,
         1.2917, 0.8655, 0.7592, 1.0826, 1.5294, 1.5969, 1.3092, 1.6676, 1.6676,
         0.6942, 0.8338, 1.6330, 1.4310, 0.7822, 1.5724, 1.0770, 1.6834, 1.6105,
         0.3163, 0.0944, 0.0649, 0.2757, 0.5471, 0.7169, 0.2210, 9.3959, 7.3402,
         0.7613, 1.1878, 1.2749, 1.5002, 0.9983, 1.4545, 0.4280, 1.5469, 1.6657],
        [1.2456, 1.2771, 1.3399, 1.3183, 1.2861, 1.2522, 1.2174, 1.2436, 1.2436,
         1.2157, 1.3278, 1.2329, 1.3561, 1.2924, 1.4088, 1.2133, 1.2951, 1.2325,
         1.2970, 1.3287, 1.3420, 1.3103, 1.2691, 1.2592, 1.2222, 1.2552, 1.2552,
         1.3139, 1.3578, 1.2737, 1.1079, 1.2654, 1.1513, 1.3185, 1.1488, 1.2765,
         1.3682, 1.0779, 1.3892, 1.3765, 0.9713, 0.8752, 1.3721, 1.3689, 0.7641,
         2.8221, 2.3615, 2.8989, 2.5668, 2.0328, 1.7472, 2.6707, 2.7362, 1.7279]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 138 : 180.64439472607725
Test loss for epoch 138 : 180.71453534631465
Test Precision for epoch 138 : 0.26153846153846155
Test Recall for epoch 138 : 0.26153846153846155
Test F1 for epoch 138 : 0.26153846153846155


theta for epoch 139 : tensor([[2.3484, 2.3777, 2.4507, 2.5367, 2.4998, 2.3544, 2.4762, 2.3467, 2.3467,
         1.2573, 1.2730, 1.2725, 1.2965, 1.2425, 1.3418, 1.2552, 1.2448, 1.2262,
         1.2284, 1.2124, 1.2239, 1.2405, 1.2047, 1.1971, 1.2222, 1.1930, 1.1930,
         1.2420, 1.2860, 1.2145, 1.2385, 1.2855, 1.2250, 1.2528, 1.1755, 1.2169,
         1.3663, 1.4039, 1.3840, 1.3733, 1.3894, 1.3228, 1.3695, 1.3691, 1.3159,
         1.3287, 1.2782, 1.2674, 1.2468, 1.3186, 1.2655, 1.3595, 1.2403, 1.2449],
        [1.2661, 1.1756, 0.9925, 1.2166, 1.2905, 1.3169, 1.2407, 1.3080, 1.3080,
         1.5095, 1.7633, 1.5145, 2.2636, 1.5488, 4.8663, 1.6148, 1.4423, 4.6384,
         1.1105, 1.1876, 0.9724, 1.1572, 1.2902, 1.3231, 1.2983, 1.3192, 1.3192,
         1.2906, 1.0272, 1.3373, 1.3163, 1.1299, 1.3499, 1.3767, 1.2993, 1.3248,
         1.3146, 1.4670, 1.3842, 1.2948, 1.3008, 1.4299, 1.3673, 0.4910, 1.3546,
         1.0199, 1.3965, 1.3813, 1.3588, 1.0445, 1.3792, 0.8540, 1.3509, 1.3572],
        [1.1883, 1.2153, 1.2692, 1.2498, 1.2221, 1.1941, 1.2010, 1.1866, 1.1866,
         1.2632, 1.2794, 1.2786, 1.3027, 1.2483, 1.3051, 1.2611, 1.2425, 1.2019,
         2.4159, 2.4849, 2.5929, 2.5353, 2.3044, 2.3947, 2.4246, 2.2921, 2.2921,
         1.2857, 1.2589, 1.2208, 1.2450, 1.2852, 1.2314, 1.2598, 1.2255, 1.2232,
         1.3696, 1.4076, 1.3874, 1.3672, 1.3929, 1.3816, 1.3729, 1.2798, 1.3090,
         1.2931, 1.2844, 1.2735, 1.2526, 1.2485, 1.2718, 1.3239, 1.2460, 1.2507],
        [1.1887, 1.2170, 1.2427, 1.2224, 1.2242, 1.1948, 1.2023, 1.1869, 1.1869,
         1.2608, 1.2483, 1.2767, 1.2926, 1.2451, 1.2546, 1.2585, 1.2472, 1.1347,
         1.2368, 1.2555, 1.2773, 1.2496, 1.2118, 1.1953, 1.2298, 1.1994, 1.1994,
         2.7097, 2.4648, 2.1875, 2.3082, 2.7015, 2.1984, 2.6553, 2.1986, 2.1900,
         1.3535, 1.3937, 1.3595, 1.3500, 1.3778, 1.3616, 1.3559, 1.2359, 1.2991,
         1.3365, 1.2715, 1.1696, 1.2026, 1.3258, 1.2303, 1.3691, 1.1958, 1.2477],
        [1.6648, 1.3464, 0.6049, 0.8066, 1.1629, 1.5561, 1.4949, 1.6618, 1.6618,
         1.5204, 1.2463, 1.3583, 0.9032, 1.6124, 0.2605, 1.5086, 1.6289, 1.1277,
         1.2926, 0.8665, 0.7602, 1.0835, 1.5302, 1.5974, 1.3104, 1.6684, 1.6684,
         0.6948, 0.8350, 1.6338, 1.4322, 0.7828, 1.5731, 1.0773, 1.6842, 1.6111,
         0.3136, 0.0917, 0.0626, 0.2730, 0.5435, 0.7131, 0.2184, 9.4443, 7.3558,
         0.7624, 1.1885, 1.2757, 1.5008, 0.9991, 1.4544, 0.4291, 1.5478, 1.6662],
        [1.2453, 1.2768, 1.3396, 1.3181, 1.2859, 1.2520, 1.2171, 1.2433, 1.2433,
         1.2155, 1.3277, 1.2327, 1.3560, 1.2922, 1.4086, 1.2130, 1.2949, 1.2323,
         1.2968, 1.3285, 1.3418, 1.3101, 1.2688, 1.2590, 1.2217, 1.2550, 1.2550,
         1.3136, 1.3574, 1.2734, 1.1072, 1.2652, 1.1511, 1.3183, 1.1485, 1.2762,
         1.3679, 1.0772, 1.3889, 1.3763, 0.9706, 0.8745, 1.3719, 1.3686, 0.7632,
         2.8290, 2.3657, 2.9072, 2.5718, 2.0354, 1.7492, 2.6760, 2.7437, 1.7299]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 139 : 180.63650879794935
Test loss for epoch 139 : 180.70725289758104
Test Precision for epoch 139 : 0.26153846153846155
Test Recall for epoch 139 : 0.26153846153846155
Test F1 for epoch 139 : 0.26153846153846155


theta for epoch 140 : tensor([[2.3531, 2.3824, 2.4553, 2.5419, 2.5050, 2.3590, 2.4814, 2.3513, 2.3513,
         1.2571, 1.2729, 1.2723, 1.2964, 1.2424, 1.3417, 1.2550, 1.2447, 1.2261,
         1.2281, 1.2121, 1.2236, 1.2402, 1.2044, 1.1968, 1.2218, 1.1927, 1.1927,
         1.2415, 1.2855, 1.2140, 1.2380, 1.2851, 1.2245, 1.2524, 1.1750, 1.2164,
         1.3664, 1.4041, 1.3841, 1.3734, 1.3897, 1.3230, 1.3696, 1.3690, 1.3160,
         1.3284, 1.2779, 1.2671, 1.2465, 1.3183, 1.2652, 1.3591, 1.2400, 1.2446],
        [1.2660, 1.1756, 0.9925, 1.2165, 1.2906, 1.3168, 1.2407, 1.3078, 1.3078,
         1.5101, 1.7637, 1.5151, 2.2649, 1.5494, 4.8845, 1.6155, 1.4429, 4.6584,
         1.1103, 1.1875, 0.9725, 1.1570, 1.2900, 1.3229, 1.2980, 1.3190, 1.3190,
         1.2906, 1.0268, 1.3370, 1.3160, 1.1299, 1.3497, 1.3767, 1.2991, 1.3247,
         1.3145, 1.4669, 1.3839, 1.2944, 1.3007, 1.4299, 1.3670, 0.4906, 1.3542,
         1.0197, 1.3964, 1.3811, 1.3586, 1.0443, 1.3791, 0.8541, 1.3506, 1.3570],
        [1.1879, 1.2149, 1.2688, 1.2495, 1.2218, 1.1937, 1.2007, 1.1862, 1.1862,
         1.2630, 1.2792, 1.2784, 1.3026, 1.2482, 1.3052, 1.2610, 1.2422, 1.2021,
         2.4205, 2.4900, 2.5981, 2.5403, 2.3090, 2.3996, 2.4295, 2.2968, 2.2968,
         1.2852, 1.2586, 1.2203, 1.2445, 1.2847, 1.2309, 1.2594, 1.2250, 1.2228,
         1.3697, 1.4078, 1.3875, 1.3673, 1.3931, 1.3818, 1.3730, 1.2800, 1.3090,
         1.2929, 1.2841, 1.2732, 1.2523, 1.2485, 1.2716, 1.3237, 1.2457, 1.2504],
        [1.1884, 1.2166, 1.2432, 1.2229, 1.2239, 1.1944, 1.2019, 1.1866, 1.1866,
         1.2606, 1.2490, 1.2766, 1.2928, 1.2450, 1.2544, 1.2584, 1.2471, 1.1360,
         1.2365, 1.2555, 1.2769, 1.2493, 1.2114, 1.1952, 1.2295, 1.1990, 1.1990,
         2.7132, 2.4715, 2.1931, 2.3143, 2.7051, 2.2041, 2.6589, 2.2042, 2.1956,
         1.3537, 1.3940, 1.3601, 1.3506, 1.3782, 1.3621, 1.3562, 1.2377, 1.2993,
         1.3362, 1.2716, 1.1696, 1.2023, 1.3255, 1.2313, 1.3688, 1.1955, 1.2475],
        [1.6655, 1.3472, 0.6056, 0.8072, 1.1637, 1.5568, 1.4957, 1.6625, 1.6625,
         1.5209, 1.2462, 1.3589, 0.9038, 1.6128, 0.2616, 1.5091, 1.6294, 1.1274,
         1.2934, 0.8674, 0.7611, 1.0844, 1.5310, 1.5979, 1.3115, 1.6692, 1.6692,
         0.6954, 0.8360, 1.6346, 1.4333, 0.7833, 1.5738, 1.0775, 1.6850, 1.6117,
         0.3109, 0.0891, 0.0603, 0.2705, 0.5400, 0.7093, 0.2158, 9.4925, 7.3710,
         0.7634, 1.1890, 1.2765, 1.5013, 0.9998, 1.4542, 0.4301, 1.5486, 1.6667],
        [1.2450, 1.2765, 1.3394, 1.3178, 1.2857, 1.2517, 1.2168, 1.2430, 1.2430,
         1.2153, 1.3276, 1.2326, 1.3559, 1.2920, 1.4085, 1.2129, 1.2947, 1.2322,
         1.2965, 1.3283, 1.3416, 1.3099, 1.2686, 1.2588, 1.2211, 1.2547, 1.2547,
         1.3133, 1.3571, 1.2730, 1.1065, 1.2650, 1.1508, 1.3181, 1.1481, 1.2759,
         1.3677, 1.0766, 1.3887, 1.3761, 0.9700, 0.8738, 1.3716, 1.3682, 0.7624,
         2.8360, 2.3697, 2.9154, 2.5768, 2.0379, 1.7512, 2.6814, 2.7511, 1.7319]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 140 : 180.6287272134769
Test loss for epoch 140 : 180.70012241187374
Test Precision for epoch 140 : 0.26153846153846155
Test Recall for epoch 140 : 0.26153846153846155
Test F1 for epoch 140 : 0.26153846153846155


theta for epoch 141 : tensor([[2.3577, 2.3870, 2.4599, 2.5471, 2.5102, 2.3636, 2.4866, 2.3559, 2.3559,
         1.2569, 1.2728, 1.2721, 1.2962, 1.2422, 1.3414, 1.2548, 1.2445, 1.2259,
         1.2278, 1.2117, 1.2232, 1.2399, 1.2041, 1.1965, 1.2216, 1.1924, 1.1924,
         1.2412, 1.2851, 1.2137, 1.2377, 1.2848, 1.2242, 1.2522, 1.1746, 1.2161,
         1.3665, 1.4043, 1.3842, 1.3735, 1.3899, 1.3231, 1.3698, 1.3688, 1.3160,
         1.3280, 1.2776, 1.2667, 1.2462, 1.3179, 1.2650, 1.3588, 1.2396, 1.2443],
        [1.2659, 1.1755, 0.9925, 1.2165, 1.2907, 1.3167, 1.2406, 1.3078, 1.3078,
         1.5106, 1.7641, 1.5157, 2.2661, 1.5500, 4.9027, 1.6161, 1.4434, 4.6784,
         1.1102, 1.1874, 0.9725, 1.1569, 1.2900, 1.3229, 1.2978, 1.3189, 1.3189,
         1.2906, 1.0266, 1.3369, 1.3159, 1.1299, 1.3496, 1.3768, 1.2989, 1.3248,
         1.3144, 1.4667, 1.3836, 1.2940, 1.3006, 1.4298, 1.3667, 0.4902, 1.3538,
         1.0195, 1.3962, 1.3808, 1.3583, 1.0440, 1.3789, 0.8541, 1.3503, 1.3568],
        [1.1876, 1.2146, 1.2684, 1.2491, 1.2214, 1.1934, 1.2003, 1.1859, 1.1859,
         1.2628, 1.2791, 1.2782, 1.3024, 1.2479, 1.3051, 1.2607, 1.2420, 1.2023,
         2.4251, 2.4950, 2.6032, 2.5452, 2.3137, 2.4045, 2.4343, 2.3014, 2.3014,
         1.2848, 1.2584, 1.2200, 1.2441, 1.2843, 1.2306, 1.2592, 1.2247, 1.2224,
         1.3698, 1.4079, 1.3876, 1.3673, 1.3933, 1.3820, 1.3731, 1.2802, 1.3090,
         1.2926, 1.2838, 1.2728, 1.2520, 1.2484, 1.2713, 1.3234, 1.2453, 1.2501],
        [1.1881, 1.2163, 1.2437, 1.2235, 1.2236, 1.1941, 1.2016, 1.1863, 1.1863,
         1.2604, 1.2497, 1.2764, 1.2929, 1.2448, 1.2543, 1.2582, 1.2469, 1.1373,
         1.2362, 1.2555, 1.2766, 1.2490, 1.2112, 1.1952, 1.2292, 1.1988, 1.1988,
         2.7166, 2.4781, 2.1986, 2.3203, 2.7087, 2.2096, 2.6625, 2.2097, 2.2012,
         1.3540, 1.3943, 1.3607, 1.3512, 1.3786, 1.3626, 1.3565, 1.2394, 1.2996,
         1.3359, 1.2717, 1.1695, 1.2021, 1.3252, 1.2322, 1.3684, 1.1952, 1.2472],
        [1.6662, 1.3480, 0.6063, 0.8078, 1.1644, 1.5575, 1.4965, 1.6632, 1.6632,
         1.5213, 1.2461, 1.3595, 0.9042, 1.6132, 0.2626, 1.5096, 1.6299, 1.1270,
         1.2942, 0.8682, 0.7620, 1.0852, 1.5317, 1.5983, 1.3126, 1.6699, 1.6699,
         0.6960, 0.8371, 1.6353, 1.4344, 0.7838, 1.5746, 1.0778, 1.6858, 1.6123,
         0.3084, 0.0865, 0.0581, 0.2680, 0.5366, 0.7055, 0.2133, 9.5406, 7.3856,
         0.7643, 1.1894, 1.2772, 1.5018, 1.0005, 1.4539, 0.4309, 1.5493, 1.6671],
        [1.2447, 1.2762, 1.3391, 1.3175, 1.2854, 1.2514, 1.2165, 1.2427, 1.2427,
         1.2151, 1.3275, 1.2324, 1.3558, 1.2918, 1.4084, 1.2126, 1.2945, 1.2320,
         1.2963, 1.3280, 1.3414, 1.3097, 1.2683, 1.2585, 1.2206, 1.2545, 1.2545,
         1.3131, 1.3568, 1.2728, 1.1059, 1.2648, 1.1506, 1.3180, 1.1478, 1.2757,
         1.3675, 1.0760, 1.3885, 1.3758, 0.9694, 0.8732, 1.3714, 1.3679, 0.7617,
         2.8428, 2.3738, 2.9236, 2.5817, 2.0404, 1.7532, 2.6867, 2.7585, 1.7338]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 141 : 180.62104943220623
Test loss for epoch 141 : 180.69311699383397
Test Precision for epoch 141 : 0.26153846153846155
Test Recall for epoch 141 : 0.26153846153846155
Test F1 for epoch 141 : 0.26153846153846155


theta for epoch 142 : tensor([[2.3622, 2.3915, 2.4645, 2.5523, 2.5153, 2.3682, 2.4918, 2.3605, 2.3605,
         1.2566, 1.2726, 1.2718, 1.2960, 1.2419, 1.3412, 1.2546, 1.2442, 1.2257,
         1.2275, 1.2114, 1.2229, 1.2396, 1.2038, 1.1962, 1.2212, 1.1921, 1.1921,
         1.2410, 1.2848, 1.2134, 1.2374, 1.2845, 1.2239, 1.2520, 1.1743, 1.2158,
         1.3665, 1.4044, 1.3842, 1.3735, 1.3900, 1.3232, 1.3698, 1.3686, 1.3160,
         1.3277, 1.2773, 1.2664, 1.2459, 1.3176, 1.2647, 1.3584, 1.2393, 1.2440],
        [1.2658, 1.1755, 0.9926, 1.2165, 1.2908, 1.3166, 1.2405, 1.3077, 1.3077,
         1.5111, 1.7644, 1.5162, 2.2672, 1.5505, 4.9210, 1.6167, 1.4438, 4.6984,
         1.1101, 1.1873, 0.9726, 1.1567, 1.2899, 1.3228, 1.2975, 1.3188, 1.3188,
         1.2907, 1.0264, 1.3368, 1.3158, 1.1299, 1.3495, 1.3769, 1.2988, 1.3249,
         1.3142, 1.4665, 1.3832, 1.2936, 1.3004, 1.4297, 1.3663, 0.4897, 1.3534,
         1.0194, 1.3961, 1.3807, 1.3581, 1.0438, 1.3788, 0.8542, 1.3501, 1.3565],
        [1.1872, 1.2142, 1.2680, 1.2487, 1.2210, 1.1930, 1.2000, 1.1856, 1.1856,
         1.2625, 1.2789, 1.2779, 1.3021, 1.2477, 1.3051, 1.2605, 1.2417, 1.2024,
         2.4297, 2.5001, 2.6083, 2.5500, 2.3183, 2.4093, 2.4391, 2.3061, 2.3061,
         1.2844, 1.2583, 1.2197, 1.2438, 1.2839, 1.2303, 1.2590, 1.2244, 1.2221,
         1.3698, 1.4080, 1.3876, 1.3672, 1.3935, 1.3821, 1.3731, 1.2804, 1.3090,
         1.2924, 1.2835, 1.2725, 1.2517, 1.2484, 1.2710, 1.3232, 1.2450, 1.2498],
        [1.1878, 1.2160, 1.2442, 1.2240, 1.2233, 1.1938, 1.2013, 1.1860, 1.1860,
         1.2602, 1.2504, 1.2762, 1.2930, 1.2446, 1.2541, 1.2580, 1.2467, 1.1384,
         1.2359, 1.2554, 1.2763, 1.2487, 1.2109, 1.1952, 1.2289, 1.1985, 1.1985,
         2.7200, 2.4847, 2.2042, 2.3263, 2.7122, 2.2152, 2.6661, 2.2152, 2.2067,
         1.3542, 1.3945, 1.3612, 1.3517, 1.3789, 1.3630, 1.3567, 1.2411, 1.2997,
         1.3356, 1.2718, 1.1695, 1.2019, 1.3250, 1.2331, 1.3681, 1.1950, 1.2470],
        [1.6669, 1.3488, 0.6071, 0.8084, 1.1652, 1.5583, 1.4972, 1.6639, 1.6639,
         1.5217, 1.2460, 1.3600, 0.9047, 1.6136, 0.2636, 1.5100, 1.6303, 1.1266,
         1.2950, 0.8691, 0.7629, 1.0861, 1.5325, 1.5988, 1.3136, 1.6706, 1.6706,
         0.6967, 0.8382, 1.6361, 1.4355, 0.7844, 1.5754, 1.0781, 1.6866, 1.6129,
         0.3059, 0.0840, 0.0559, 0.2655, 0.5333, 0.7018, 0.2109, 9.5884, 7.3997,
         0.7653, 1.1899, 1.2779, 1.5024, 1.0012, 1.4538, 0.4319, 1.5501, 1.6675],
        [1.2444, 1.2760, 1.3388, 1.3173, 1.2852, 1.2512, 1.2163, 1.2425, 1.2425,
         1.2149, 1.3274, 1.2322, 1.3557, 1.2915, 1.4083, 1.2124, 1.2943, 1.2319,
         1.2961, 1.3278, 1.3412, 1.3095, 1.2681, 1.2583, 1.2200, 1.2542, 1.2542,
         1.3129, 1.3565, 1.2726, 1.1054, 1.2647, 1.1504, 1.3179, 1.1476, 1.2755,
         1.3672, 1.0753, 1.3882, 1.3756, 0.9687, 0.8726, 1.3712, 1.3675, 0.7608,
         2.8497, 2.3777, 2.9318, 2.5866, 2.0429, 1.7551, 2.6920, 2.7658, 1.7356]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 142 : 180.61347044827176
Test loss for epoch 142 : 180.68620048476186
Test Precision for epoch 142 : 0.26153846153846155
Test Recall for epoch 142 : 0.26153846153846155
Test F1 for epoch 142 : 0.26153846153846155


theta for epoch 143 : tensor([[2.3668, 2.3961, 2.4691, 2.5574, 2.5204, 2.3727, 2.4969, 2.3650, 2.3650,
         1.2564, 1.2724, 1.2716, 1.2958, 1.2417, 1.3410, 1.2544, 1.2440, 1.2255,
         1.2272, 1.2110, 1.2225, 1.2393, 1.2035, 1.1959, 1.2209, 1.1918, 1.1918,
         1.2407, 1.2844, 1.2130, 1.2370, 1.2842, 1.2235, 1.2517, 1.1739, 1.2155,
         1.3665, 1.4044, 1.3841, 1.3735, 1.3901, 1.3233, 1.3698, 1.3684, 1.3160,
         1.3274, 1.2771, 1.2662, 1.2457, 1.3173, 1.2645, 1.3581, 1.2391, 1.2438],
        [1.2656, 1.1754, 0.9926, 1.2165, 1.2909, 1.3165, 1.2404, 1.3076, 1.3076,
         1.5116, 1.7647, 1.5168, 2.2682, 1.5511, 4.9393, 1.6173, 1.4443, 4.7185,
         1.1099, 1.1872, 0.9727, 1.1565, 1.2898, 1.3227, 1.2973, 1.3187, 1.3187,
         1.2907, 1.0261, 1.3366, 1.3156, 1.1299, 1.3493, 1.3769, 1.2986, 1.3250,
         1.3140, 1.4663, 1.3828, 1.2931, 1.3001, 1.4295, 1.3659, 0.4892, 1.3529,
         1.0192, 1.3960, 1.3805, 1.3579, 1.0436, 1.3788, 0.8543, 1.3498, 1.3564],
        [1.1869, 1.2138, 1.2675, 1.2483, 1.2206, 1.1927, 1.1996, 1.1852, 1.1852,
         1.2623, 1.2787, 1.2777, 1.3020, 1.2475, 1.3051, 1.2602, 1.2414, 1.2026,
         2.4342, 2.5051, 2.6133, 2.5549, 2.3229, 2.4142, 2.4438, 2.3106, 2.3106,
         1.2841, 1.2581, 1.2193, 1.2435, 1.2835, 1.2299, 1.2587, 1.2240, 1.2218,
         1.3698, 1.4081, 1.3875, 1.3671, 1.3936, 1.3822, 1.3731, 1.2805, 1.3089,
         1.2922, 1.2833, 1.2723, 1.2515, 1.2485, 1.2708, 1.3230, 1.2448, 1.2496],
        [1.1875, 1.2156, 1.2446, 1.2245, 1.2229, 1.1935, 1.2010, 1.1857, 1.1857,
         1.2601, 1.2511, 1.2761, 1.2931, 1.2444, 1.2540, 1.2579, 1.2465, 1.1396,
         1.2357, 1.2554, 1.2760, 1.2484, 1.2106, 1.1951, 1.2287, 1.1982, 1.1982,
         2.7234, 2.4912, 2.2097, 2.3323, 2.7157, 2.2207, 2.6696, 2.2206, 2.2122,
         1.3543, 1.3947, 1.3616, 1.3521, 1.3792, 1.3634, 1.3569, 1.2427, 1.2999,
         1.3353, 1.2720, 1.1695, 1.2017, 1.3247, 1.2340, 1.3678, 1.1948, 1.2468],
        [1.6676, 1.3496, 0.6078, 0.8090, 1.1660, 1.5590, 1.4980, 1.6646, 1.6646,
         1.5222, 1.2459, 1.3606, 0.9052, 1.6140, 0.2646, 1.5104, 1.6308, 1.1262,
         1.2958, 0.8699, 0.7637, 1.0869, 1.5332, 1.5992, 1.3147, 1.6713, 1.6713,
         0.6973, 0.8392, 1.6368, 1.4367, 0.7849, 1.5762, 1.0784, 1.6874, 1.6135,
         0.3034, 0.0815, 0.0537, 0.2630, 0.5300, 0.6982, 0.2084, 9.6361, 7.4134,
         0.7663, 1.1905, 1.2786, 1.5030, 1.0019, 1.4537, 0.4328, 1.5510, 1.6680],
        [1.2442, 1.2757, 1.3386, 1.3170, 1.2850, 1.2510, 1.2161, 1.2422, 1.2422,
         1.2147, 1.3274, 1.2321, 1.3556, 1.2914, 1.4082, 1.2122, 1.2941, 1.2318,
         1.2959, 1.3277, 1.3410, 1.3093, 1.2679, 1.2582, 1.2195, 1.2540, 1.2540,
         1.3127, 1.3562, 1.2724, 1.1048, 1.2646, 1.1502, 1.3178, 1.1473, 1.2753,
         1.3668, 1.0746, 1.3879, 1.3753, 0.9680, 0.8719, 1.3709, 1.3670, 0.7600,
         2.8565, 2.3816, 2.9400, 2.5915, 2.0452, 1.7569, 2.6973, 2.7730, 1.7374]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 143 : 180.60598828595394
Test loss for epoch 143 : 180.67942045207295
Test Precision for epoch 143 : 0.26153846153846155
Test Recall for epoch 143 : 0.26153846153846155
Test F1 for epoch 143 : 0.26153846153846155


theta for epoch 144 : tensor([[2.3713, 2.4006, 2.4736, 2.5625, 2.5255, 2.3772, 2.5020, 2.3695, 2.3695,
         1.2562, 1.2722, 1.2714, 1.2956, 1.2415, 1.3408, 1.2541, 1.2438, 1.2253,
         1.2269, 1.2107, 1.2221, 1.2390, 1.2032, 1.1957, 1.2206, 1.1915, 1.1915,
         1.2403, 1.2840, 1.2126, 1.2366, 1.2838, 1.2231, 1.2514, 1.1735, 1.2151,
         1.3666, 1.4046, 1.3842, 1.3736, 1.3903, 1.3234, 1.3699, 1.3683, 1.3160,
         1.3271, 1.2769, 1.2660, 1.2455, 1.3171, 1.2644, 1.3579, 1.2389, 1.2436],
        [1.2656, 1.1753, 0.9926, 1.2165, 1.2910, 1.3164, 1.2403, 1.3075, 1.3075,
         1.5120, 1.7649, 1.5173, 2.2692, 1.5515, 4.9577, 1.6177, 1.4447, 4.7385,
         1.1097, 1.1872, 0.9728, 1.1564, 1.2897, 1.3227, 1.2971, 1.3186, 1.3186,
         1.2907, 1.0258, 1.3364, 1.3154, 1.1299, 1.3491, 1.3770, 1.2984, 1.3250,
         1.3138, 1.4661, 1.3824, 1.2927, 1.3000, 1.4294, 1.3655, 0.4888, 1.3524,
         1.0192, 1.3960, 1.3804, 1.3577, 1.0434, 1.3788, 0.8544, 1.3497, 1.3563],
        [1.1866, 1.2134, 1.2671, 1.2479, 1.2203, 1.1923, 1.1993, 1.1849, 1.1849,
         1.2621, 1.2785, 1.2774, 1.3018, 1.2472, 1.3051, 1.2600, 1.2411, 1.2027,
         2.4387, 2.5100, 2.6183, 2.5596, 2.3275, 2.4190, 2.4485, 2.3152, 2.3152,
         1.2836, 1.2579, 1.2189, 1.2430, 1.2831, 1.2295, 1.2584, 1.2236, 1.2214,
         1.3698, 1.4082, 1.3875, 1.3671, 1.3937, 1.3823, 1.3732, 1.2807, 1.3088,
         1.2921, 1.2831, 1.2720, 1.2513, 1.2486, 1.2706, 1.3229, 1.2445, 1.2494],
        [1.1871, 1.2153, 1.2450, 1.2249, 1.2226, 1.1932, 1.2007, 1.1854, 1.1854,
         1.2599, 1.2517, 1.2759, 1.2932, 1.2443, 1.2538, 1.2577, 1.2464, 1.1408,
         1.2354, 1.2553, 1.2756, 1.2481, 1.2103, 1.1951, 1.2284, 1.1980, 1.1980,
         2.7267, 2.4978, 2.2152, 2.3383, 2.7191, 2.2262, 2.6731, 2.2260, 2.2177,
         1.3545, 1.3949, 1.3621, 1.3526, 1.3795, 1.3638, 1.3571, 1.2443, 1.3000,
         1.3351, 1.2721, 1.1696, 1.2016, 1.3245, 1.2349, 1.3676, 1.1946, 1.2466],
        [1.6682, 1.3503, 0.6085, 0.8096, 1.1667, 1.5597, 1.4987, 1.6652, 1.6652,
         1.5226, 1.2457, 1.3611, 0.9056, 1.6143, 0.2656, 1.5108, 1.6311, 1.1257,
         1.2966, 0.8708, 0.7646, 1.0877, 1.5340, 1.5996, 1.3158, 1.6720, 1.6720,
         0.6978, 0.8402, 1.6375, 1.4377, 0.7853, 1.5769, 1.0787, 1.6881, 1.6140,
         0.3010, 0.0790, 0.0515, 0.2606, 0.5268, 0.6946, 0.2060, 9.6837, 7.4266,
         0.7672, 1.1909, 1.2793, 1.5036, 1.0025, 1.4536, 0.4337, 1.5518, 1.6686],
        [1.2440, 1.2756, 1.3384, 1.3169, 1.2848, 1.2508, 1.2159, 1.2421, 1.2421,
         1.2146, 1.3273, 1.2319, 1.3556, 1.2912, 1.4082, 1.2121, 1.2940, 1.2317,
         1.2958, 1.3275, 1.3409, 1.3092, 1.2677, 1.2580, 1.2191, 1.2539, 1.2539,
         1.3125, 1.3559, 1.2722, 1.1042, 1.2644, 1.1499, 1.3177, 1.1470, 1.2751,
         1.3666, 1.0740, 1.3876, 1.3751, 0.9674, 0.8713, 1.3707, 1.3666, 0.7593,
         2.8633, 2.3854, 2.9480, 2.5962, 2.0475, 1.7587, 2.7024, 2.7802, 1.7392]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 144 : 180.59860037563655
Test loss for epoch 144 : 180.67276988065584
Test Precision for epoch 144 : 0.26153846153846155
Test Recall for epoch 144 : 0.26153846153846155
Test F1 for epoch 144 : 0.26153846153846155


theta for epoch 145 : tensor([[2.3757, 2.4051, 2.4781, 2.5675, 2.5305, 2.3817, 2.5070, 2.3740, 2.3740,
         1.2560, 1.2721, 1.2711, 1.2954, 1.2413, 1.3406, 1.2539, 1.2436, 1.2251,
         1.2266, 1.2103, 1.2217, 1.2386, 1.2029, 1.1954, 1.2203, 1.1912, 1.1912,
         1.2400, 1.2836, 1.2123, 1.2362, 1.2835, 1.2228, 1.2512, 1.1732, 1.2147,
         1.3666, 1.4047, 1.3842, 1.3736, 1.3905, 1.3236, 1.3699, 1.3681, 1.3161,
         1.3269, 1.2767, 1.2657, 1.2453, 1.3169, 1.2642, 1.3576, 1.2386, 1.2433],
        [1.2655, 1.1753, 0.9926, 1.2165, 1.2911, 1.3164, 1.2402, 1.3074, 1.3074,
         1.5123, 1.7651, 1.5177, 2.2700, 1.5519, 4.9760, 1.6182, 1.4451, 4.7585,
         1.1096, 1.1871, 0.9729, 1.1563, 1.2897, 1.3226, 1.2969, 1.3185, 1.3185,
         1.2907, 1.0256, 1.3362, 1.3153, 1.1299, 1.3490, 1.3770, 1.2982, 1.3250,
         1.3137, 1.4659, 1.3821, 1.2923, 1.2998, 1.4293, 1.3651, 0.4884, 1.3520,
         1.0191, 1.3959, 1.3803, 1.3576, 1.0433, 1.3788, 0.8546, 1.3495, 1.3561],
        [1.1862, 1.2131, 1.2667, 1.2475, 1.2199, 1.1920, 1.1989, 1.1845, 1.1845,
         1.2619, 1.2783, 1.2772, 1.3016, 1.2470, 1.3051, 1.2598, 1.2408, 1.2029,
         2.4432, 2.5149, 2.6232, 2.5643, 2.3320, 2.4237, 2.4532, 2.3197, 2.3197,
         1.2832, 1.2577, 1.2186, 1.2427, 1.2826, 1.2291, 1.2581, 1.2233, 1.2210,
         1.3699, 1.4083, 1.3876, 1.3671, 1.3939, 1.3825, 1.3732, 1.2809, 1.3088,
         1.2920, 1.2829, 1.2718, 1.2511, 1.2487, 1.2704, 1.3227, 1.2443, 1.2491],
        [1.1868, 1.2149, 1.2454, 1.2254, 1.2223, 1.1928, 1.2003, 1.1850, 1.1850,
         1.2596, 1.2523, 1.2757, 1.2932, 1.2440, 1.2536, 1.2575, 1.2461, 1.1418,
         1.2350, 1.2552, 1.2753, 1.2478, 1.2100, 1.1950, 1.2280, 1.1977, 1.1977,
         2.7300, 2.5043, 2.2207, 2.3442, 2.7225, 2.2317, 2.6765, 2.2314, 2.2232,
         1.3547, 1.3952, 1.3626, 1.3531, 1.3799, 1.3642, 1.3573, 1.2458, 1.3002,
         1.3348, 1.2722, 1.1696, 1.2014, 1.3243, 1.2358, 1.3673, 1.1943, 1.2464],
        [1.6689, 1.3511, 0.6092, 0.8101, 1.1673, 1.5603, 1.4994, 1.6659, 1.6659,
         1.5230, 1.2456, 1.3616, 0.9060, 1.6146, 0.2665, 1.5112, 1.6315, 1.1253,
         1.2973, 0.8715, 0.7654, 1.0884, 1.5347, 1.6000, 1.3168, 1.6726, 1.6726,
         0.6984, 0.8411, 1.6382, 1.4387, 0.7858, 1.5776, 1.0790, 1.6888, 1.6145,
         0.2986, 0.0767, 0.0494, 0.2583, 0.5237, 0.6911, 0.2037, 9.7311, 7.4393,
         0.7681, 1.1914, 1.2800, 1.5041, 1.0031, 1.4535, 0.4346, 1.5526, 1.6690],
        [1.2438, 1.2754, 1.3382, 1.3167, 1.2846, 1.2506, 1.2157, 1.2419, 1.2419,
         1.2144, 1.3273, 1.2318, 1.3555, 1.2911, 1.4081, 1.2119, 1.2938, 1.2316,
         1.2956, 1.3273, 1.3408, 1.3091, 1.2675, 1.2579, 1.2186, 1.2537, 1.2537,
         1.3124, 1.3557, 1.2720, 1.1036, 1.2642, 1.1497, 1.3176, 1.1468, 1.2749,
         1.3664, 1.0735, 1.3874, 1.3749, 0.9668, 0.8708, 1.3705, 1.3663, 0.7586,
         2.8701, 2.3891, 2.9561, 2.6010, 2.0498, 1.7605, 2.7075, 2.7873, 1.7409]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 145 : 180.59130469832886
Test loss for epoch 145 : 180.66621654167912
Test Precision for epoch 145 : 0.26153846153846155
Test Recall for epoch 145 : 0.26153846153846155
Test F1 for epoch 145 : 0.26153846153846155


theta for epoch 146 : tensor([[2.3801, 2.4095, 2.4826, 2.5725, 2.5356, 2.3861, 2.5120, 2.3784, 2.3784,
         1.2558, 1.2720, 1.2710, 1.2953, 1.2411, 1.3405, 1.2538, 1.2434, 1.2249,
         1.2263, 1.2099, 1.2214, 1.2383, 1.2026, 1.1951, 1.2199, 1.1909, 1.1909,
         1.2396, 1.2832, 1.2119, 1.2359, 1.2832, 1.2224, 1.2509, 1.1728, 1.2144,
         1.3667, 1.4048, 1.3842, 1.3737, 1.3907, 1.3237, 1.3700, 1.3680, 1.3161,
         1.3266, 1.2764, 1.2654, 1.2450, 1.3166, 1.2640, 1.3573, 1.2383, 1.2431],
        [1.2654, 1.1752, 0.9927, 1.2165, 1.2912, 1.3163, 1.2401, 1.3073, 1.3073,
         1.5127, 1.7652, 1.5181, 2.2707, 1.5523, 4.9944, 1.6186, 1.4454, 4.7785,
         1.1095, 1.1871, 0.9730, 1.1561, 1.2896, 1.3226, 1.2967, 1.3185, 1.3185,
         1.2907, 1.0253, 1.3361, 1.3151, 1.1299, 1.3488, 1.3771, 1.2980, 1.3251,
         1.3135, 1.4657, 1.3817, 1.2919, 1.2997, 1.4292, 1.3648, 0.4880, 1.3516,
         1.0190, 1.3958, 1.3801, 1.3574, 1.0431, 1.3787, 0.8547, 1.3493, 1.3560],
        [1.1859, 1.2127, 1.2662, 1.2471, 1.2195, 1.1916, 1.1985, 1.1842, 1.1842,
         1.2617, 1.2782, 1.2770, 1.3014, 1.2468, 1.3051, 1.2596, 1.2406, 1.2031,
         2.4476, 2.5198, 2.6281, 2.5690, 2.3365, 2.4284, 2.4578, 2.3243, 2.3243,
         1.2828, 1.2576, 1.2182, 1.2423, 1.2822, 1.2288, 1.2579, 1.2229, 1.2207,
         1.3699, 1.4085, 1.3876, 1.3671, 1.3941, 1.3827, 1.3733, 1.2812, 1.3088,
         1.2918, 1.2826, 1.2715, 1.2508, 1.2487, 1.2702, 1.3225, 1.2440, 1.2489],
        [1.1864, 1.2146, 1.2458, 1.2258, 1.2219, 1.1925, 1.2000, 1.1847, 1.1847,
         1.2594, 1.2529, 1.2755, 1.2933, 1.2438, 1.2535, 1.2573, 1.2459, 1.1429,
         1.2347, 1.2551, 1.2749, 1.2474, 1.2097, 1.1950, 1.2277, 1.1973, 1.1973,
         2.7333, 2.5108, 2.2261, 2.3502, 2.7259, 2.2371, 2.6800, 2.2368, 2.2286,
         1.3549, 1.3954, 1.3630, 1.3535, 1.3802, 1.3646, 1.3575, 1.2473, 1.3004,
         1.3345, 1.2722, 1.1695, 1.2012, 1.3240, 1.2366, 1.3669, 1.1941, 1.2461],
        [1.6695, 1.3519, 0.6099, 0.8107, 1.1681, 1.5610, 1.5001, 1.6665, 1.6665,
         1.5234, 1.2455, 1.3621, 0.9065, 1.6150, 0.2676, 1.5117, 1.6320, 1.1250,
         1.2981, 0.8724, 0.7663, 1.0893, 1.5354, 1.6004, 1.3178, 1.6733, 1.6733,
         0.6990, 0.8421, 1.6389, 1.4398, 0.7864, 1.5783, 1.0793, 1.6895, 1.6150,
         0.2962, 0.0743, 0.0473, 0.2559, 0.5206, 0.6876, 0.2014, 9.7784, 7.4515,
         0.7690, 1.1919, 1.2807, 1.5047, 1.0038, 1.4534, 0.4356, 1.5534, 1.6695],
        [1.2436, 1.2751, 1.3379, 1.3164, 1.2844, 1.2504, 1.2155, 1.2417, 1.2417,
         1.2142, 1.3272, 1.2317, 1.3554, 1.2909, 1.4081, 1.2117, 1.2936, 1.2315,
         1.2954, 1.3271, 1.3407, 1.3089, 1.2673, 1.2577, 1.2181, 1.2535, 1.2535,
         1.3122, 1.3554, 1.2718, 1.1030, 1.2640, 1.1495, 1.3175, 1.1465, 1.2746,
         1.3661, 1.0729, 1.3872, 1.3747, 0.9662, 0.8702, 1.3703, 1.3659, 0.7578,
         2.8769, 2.3929, 2.9642, 2.6057, 2.0521, 1.7623, 2.7126, 2.7944, 1.7426]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 146 : 180.58409809745453
Test loss for epoch 146 : 180.6597326382451
Test Precision for epoch 146 : 0.26153846153846155
Test Recall for epoch 146 : 0.26153846153846155
Test F1 for epoch 146 : 0.26153846153846155


theta for epoch 147 : tensor([[2.3846, 2.4139, 2.4870, 2.5775, 2.5406, 2.3905, 2.5170, 2.3828, 2.3828,
         1.2556, 1.2718, 1.2708, 1.2952, 1.2409, 1.3403, 1.2536, 1.2431, 1.2247,
         1.2260, 1.2096, 1.2210, 1.2380, 1.2023, 1.1948, 1.2196, 1.1906, 1.1906,
         1.2393, 1.2828, 1.2116, 1.2355, 1.2829, 1.2221, 1.2507, 1.1725, 1.2140,
         1.3667, 1.4050, 1.3843, 1.3737, 1.3908, 1.3238, 1.3701, 1.3679, 1.3161,
         1.3262, 1.2762, 1.2651, 1.2447, 1.3163, 1.2637, 1.3570, 1.2380, 1.2428],
        [1.2653, 1.1752, 0.9928, 1.2165, 1.2914, 1.3162, 1.2400, 1.3073, 1.3073,
         1.5130, 1.7653, 1.5184, 2.2714, 1.5526, 5.0128, 1.6190, 1.4457, 4.7986,
         1.1094, 1.1871, 0.9731, 1.1560, 1.2896, 1.3226, 1.2965, 1.3184, 1.3184,
         1.2907, 1.0251, 1.3359, 1.3150, 1.1299, 1.3487, 1.3771, 1.2979, 1.3252,
         1.3134, 1.4656, 1.3813, 1.2915, 1.2995, 1.4292, 1.3644, 0.4877, 1.3511,
         1.0189, 1.3957, 1.3799, 1.3572, 1.0428, 1.3786, 0.8549, 1.3490, 1.3558],
        [1.1856, 1.2124, 1.2658, 1.2467, 1.2192, 1.1913, 1.1982, 1.1839, 1.1839,
         1.2615, 1.2781, 1.2768, 1.3013, 1.2466, 1.3051, 1.2594, 1.2403, 1.2033,
         2.4520, 2.5247, 2.6329, 2.5736, 2.3410, 2.4331, 2.4624, 2.3288, 2.3288,
         1.2824, 1.2574, 1.2179, 1.2419, 1.2818, 1.2284, 1.2576, 1.2226, 1.2203,
         1.3699, 1.4086, 1.3876, 1.3670, 1.3943, 1.3829, 1.3734, 1.2814, 1.3088,
         1.2916, 1.2823, 1.2711, 1.2505, 1.2487, 1.2699, 1.3223, 1.2437, 1.2486],
        [1.1862, 1.2143, 1.2462, 1.2262, 1.2216, 1.1922, 1.1997, 1.1844, 1.1844,
         1.2593, 1.2535, 1.2753, 1.2934, 1.2437, 1.2533, 1.2571, 1.2457, 1.1440,
         1.2344, 1.2551, 1.2746, 1.2471, 1.2094, 1.1949, 1.2274, 1.1971, 1.1971,
         2.7366, 2.5172, 2.2315, 2.3560, 2.7292, 2.2425, 2.6833, 2.2421, 2.2340,
         1.3551, 1.3956, 1.3635, 1.3540, 1.3805, 1.3651, 1.3577, 1.2489, 1.3005,
         1.3342, 1.2723, 1.1695, 1.2009, 1.3237, 1.2374, 1.3666, 1.1938, 1.2459],
        [1.6702, 1.3527, 0.6107, 0.8114, 1.1688, 1.5618, 1.5009, 1.6672, 1.6672,
         1.5239, 1.2455, 1.3626, 0.9070, 1.6153, 0.2686, 1.5121, 1.6324, 1.1246,
         1.2989, 0.8733, 0.7671, 1.0901, 1.5361, 1.6009, 1.3189, 1.6740, 1.6740,
         0.6996, 0.8431, 1.6396, 1.4409, 0.7869, 1.5791, 1.0796, 1.6902, 1.6155,
         0.2939, 0.0719, 0.0453, 0.2536, 0.5175, 0.6841, 0.1991, 9.8254, 7.4632,
         0.7699, 1.1923, 1.2813, 1.5052, 1.0044, 1.4533, 0.4365, 1.5542, 1.6700],
        [1.2434, 1.2749, 1.3376, 1.3162, 1.2842, 1.2502, 1.2153, 1.2414, 1.2414,
         1.2140, 1.3271, 1.2315, 1.3553, 1.2906, 1.4080, 1.2115, 1.2933, 1.2313,
         1.2952, 1.3269, 1.3405, 1.3087, 1.2671, 1.2575, 1.2176, 1.2533, 1.2533,
         1.3119, 1.3551, 1.2715, 1.1023, 1.2638, 1.1492, 1.3173, 1.1462, 1.2744,
         1.3659, 1.0723, 1.3870, 1.3745, 0.9656, 0.8696, 1.3701, 1.3656, 0.7570,
         2.8837, 2.3966, 2.9722, 2.6105, 2.0544, 1.7641, 2.7177, 2.8015, 1.7444]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 147 : 180.57697869859263
Test loss for epoch 147 : 180.65332959304294
Test Precision for epoch 147 : 0.26153846153846155
Test Recall for epoch 147 : 0.26153846153846155
Test F1 for epoch 147 : 0.26153846153846155


theta for epoch 148 : tensor([[2.3889, 2.4182, 2.4914, 2.5824, 2.5455, 2.3949, 2.5219, 2.3871, 2.3871,
         1.2554, 1.2717, 1.2706, 1.2950, 1.2407, 1.3402, 1.2534, 1.2430, 1.2246,
         1.2257, 1.2092, 1.2207, 1.2377, 1.2020, 1.1945, 1.2193, 1.1903, 1.1903,
         1.2390, 1.2825, 1.2113, 1.2352, 1.2826, 1.2217, 1.2504, 1.1721, 1.2137,
         1.3668, 1.4052, 1.3844, 1.3738, 1.3910, 1.3240, 1.3702, 1.3678, 1.3162,
         1.3259, 1.2759, 1.2648, 1.2445, 1.3160, 1.2635, 1.3567, 1.2377, 1.2426],
        [1.2652, 1.1752, 0.9928, 1.2165, 1.2915, 1.3161, 1.2399, 1.3072, 1.3072,
         1.5132, 1.7654, 1.5187, 2.2719, 1.5529, 5.0313, 1.6193, 1.4460, 4.8186,
         1.1092, 1.1871, 0.9733, 1.1559, 1.2896, 1.3226, 1.2963, 1.3184, 1.3184,
         1.2908, 1.0249, 1.3358, 1.3148, 1.1299, 1.3485, 1.3772, 1.2977, 1.3252,
         1.3133, 1.4654, 1.3810, 1.2911, 1.2994, 1.4291, 1.3641, 0.4873, 1.3507,
         1.0188, 1.3955, 1.3798, 1.3570, 1.0427, 1.3786, 0.8550, 1.3488, 1.3556],
        [1.1852, 1.2120, 1.2654, 1.2463, 1.2188, 1.1910, 1.1979, 1.1836, 1.1836,
         1.2613, 1.2779, 1.2766, 1.3011, 1.2464, 1.3052, 1.2592, 1.2400, 1.2035,
         2.4563, 2.5296, 2.6377, 2.5782, 2.3455, 2.4378, 2.4670, 2.3332, 2.3332,
         1.2820, 1.2573, 1.2175, 1.2416, 1.2814, 1.2281, 1.2573, 1.2222, 1.2200,
         1.3700, 1.4088, 1.3877, 1.3670, 1.3944, 1.3830, 1.3735, 1.2817, 1.3087,
         1.2914, 1.2820, 1.2708, 1.2502, 1.2488, 1.2697, 1.3221, 1.2434, 1.2483],
        [1.1859, 1.2140, 1.2466, 1.2266, 1.2213, 1.1919, 1.1994, 1.1841, 1.1841,
         1.2591, 1.2541, 1.2751, 1.2935, 1.2435, 1.2532, 1.2570, 1.2456, 1.1450,
         1.2342, 1.2550, 1.2743, 1.2469, 1.2092, 1.1949, 1.2272, 1.1969, 1.1969,
         2.7397, 2.5236, 2.2368, 2.3618, 2.7324, 2.2478, 2.6866, 2.2474, 2.2393,
         1.3552, 1.3959, 1.3640, 1.3544, 1.3808, 1.3655, 1.3579, 1.2503, 1.3007,
         1.3339, 1.2724, 1.1694, 1.2008, 1.3234, 1.2381, 1.3663, 1.1936, 1.2457],
        [1.6708, 1.3534, 0.6113, 0.8119, 1.1695, 1.5624, 1.5016, 1.6678, 1.6678,
         1.5242, 1.2453, 1.3631, 0.9073, 1.6156, 0.2695, 1.5125, 1.6328, 1.1242,
         1.2996, 0.8740, 0.7679, 1.0908, 1.5368, 1.6013, 1.3199, 1.6746, 1.6746,
         0.7002, 0.8440, 1.6402, 1.4419, 0.7873, 1.5798, 1.0799, 1.6909, 1.6160,
         0.2917, 0.0696, 0.0433, 0.2514, 0.5146, 0.6808, 0.1968, 9.8724, 7.4745,
         0.7708, 1.1927, 1.2819, 1.5057, 1.0049, 1.4532, 0.4373, 1.5549, 1.6704],
        [1.2432, 1.2747, 1.3374, 1.3159, 1.2840, 1.2500, 1.2150, 1.2412, 1.2412,
         1.2138, 1.3271, 1.2313, 1.3552, 1.2904, 1.4079, 1.2113, 1.2931, 1.2312,
         1.2950, 1.3267, 1.3403, 1.3085, 1.2669, 1.2573, 1.2170, 1.2531, 1.2531,
         1.3117, 1.3548, 1.2713, 1.1017, 1.2636, 1.1489, 1.3172, 1.1459, 1.2742,
         1.3657, 1.0717, 1.3868, 1.3743, 0.9651, 0.8690, 1.3700, 1.3652, 0.7563,
         2.8905, 2.4003, 2.9803, 2.6152, 2.0566, 1.7658, 2.7227, 2.8085, 1.7461]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 148 : 180.56994344616785
Test loss for epoch 148 : 180.64705268473526
Test Precision for epoch 148 : 0.26153846153846155
Test Recall for epoch 148 : 0.26153846153846155
Test F1 for epoch 148 : 0.26153846153846155


theta for epoch 149 : tensor([[2.3932, 2.4226, 2.4957, 2.5874, 2.5504, 2.3992, 2.5268, 2.3914, 2.3914,
         1.2553, 1.2716, 1.2704, 1.2949, 1.2405, 1.3400, 1.2532, 1.2428, 1.2244,
         1.2253, 1.2089, 1.2203, 1.2373, 1.2017, 1.1942, 1.2190, 1.1900, 1.1900,
         1.2387, 1.2821, 1.2110, 1.2348, 1.2823, 1.2214, 1.2502, 1.1718, 1.2134,
         1.3668, 1.4053, 1.3844, 1.3739, 1.3912, 1.3241, 1.3702, 1.3677, 1.3162,
         1.3256, 1.2757, 1.2645, 1.2442, 1.3157, 1.2633, 1.3564, 1.2375, 1.2424],
        [1.2651, 1.1751, 0.9929, 1.2165, 1.2916, 1.3161, 1.2398, 1.3071, 1.3071,
         1.5135, 1.7654, 1.5190, 2.2724, 1.5532, 5.0497, 1.6196, 1.4463, 4.8386,
         1.1091, 1.1870, 0.9733, 1.1558, 1.2895, 1.3226, 1.2961, 1.3184, 1.3184,
         1.2908, 1.0246, 1.3357, 1.3147, 1.1300, 1.3484, 1.3773, 1.2976, 1.3253,
         1.3131, 1.4652, 1.3806, 1.2907, 1.2993, 1.4290, 1.3637, 0.4869, 1.3503,
         1.0188, 1.3955, 1.3796, 1.3568, 1.0425, 1.3785, 0.8552, 1.3486, 1.3555],
        [1.1849, 1.2117, 1.2650, 1.2460, 1.2185, 1.1907, 1.1975, 1.1832, 1.1832,
         1.2611, 1.2778, 1.2764, 1.3010, 1.2462, 1.3052, 1.2590, 1.2398, 1.2037,
         2.4606, 2.5344, 2.6424, 2.5827, 2.3499, 2.4424, 2.4715, 2.3376, 2.3376,
         1.2816, 1.2571, 1.2172, 1.2412, 1.2811, 1.2278, 1.2571, 1.2219, 1.2197,
         1.3700, 1.4089, 1.3877, 1.3670, 1.3946, 1.3832, 1.3735, 1.2820, 1.3087,
         1.2912, 1.2818, 1.2705, 1.2500, 1.2489, 1.2695, 1.3220, 1.2431, 1.2481],
        [1.1856, 1.2137, 1.2469, 1.2270, 1.2210, 1.1917, 1.1992, 1.1839, 1.1839,
         1.2590, 1.2547, 1.2750, 1.2936, 1.2434, 1.2531, 1.2568, 1.2454, 1.1461,
         1.2339, 1.2550, 1.2740, 1.2466, 1.2089, 1.1949, 1.2269, 1.1966, 1.1966,
         2.7428, 2.5299, 2.2420, 2.3676, 2.7356, 2.2530, 2.6898, 2.2526, 2.2446,
         1.3554, 1.3961, 1.3644, 1.3548, 1.3811, 1.3659, 1.3581, 1.2518, 1.3009,
         1.3336, 1.2724, 1.1694, 1.2006, 1.3232, 1.2389, 1.3660, 1.1934, 1.2455],
        [1.6714, 1.3542, 0.6120, 0.8124, 1.1701, 1.5630, 1.5022, 1.6684, 1.6684,
         1.5246, 1.2452, 1.3635, 0.9077, 1.6159, 0.2703, 1.5129, 1.6332, 1.1237,
         1.3003, 0.8748, 0.7686, 1.0915, 1.5375, 1.6016, 1.3209, 1.6753, 1.6753,
         0.7008, 0.8449, 1.6409, 1.4429, 0.7878, 1.5805, 1.0802, 1.6916, 1.6165,
         0.2895, 0.0674, 0.0413, 0.2492, 0.5118, 0.6776, 0.1947, 9.9192, 7.4853,
         0.7716, 1.1931, 1.2825, 1.5062, 1.0055, 1.4530, 0.4381, 1.5556, 1.6709],
        [1.2430, 1.2745, 1.3371, 1.3157, 1.2837, 1.2498, 1.2148, 1.2410, 1.2410,
         1.2136, 1.3270, 1.2311, 1.3551, 1.2902, 1.4079, 1.2111, 1.2929, 1.2311,
         1.2948, 1.3265, 1.3402, 1.3083, 1.2667, 1.2572, 1.2165, 1.2529, 1.2529,
         1.3116, 1.3545, 1.2711, 1.1012, 1.2635, 1.1487, 1.3171, 1.1457, 1.2740,
         1.3655, 1.0711, 1.3866, 1.3741, 0.9645, 0.8684, 1.3698, 1.3649, 0.7556,
         2.8972, 2.4038, 2.9883, 2.6198, 2.0588, 1.7675, 2.7277, 2.8155, 1.7477]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 149 : 180.56299169163768
Test loss for epoch 149 : 180.6408777010573
Test Precision for epoch 149 : 0.26153846153846155
Test Recall for epoch 149 : 0.26153846153846155
Test F1 for epoch 149 : 0.26153846153846155


theta for epoch 150 : tensor([[2.3975, 2.4269, 2.5001, 2.5923, 2.5553, 2.4035, 2.5317, 2.3957, 2.3957,
         1.2551, 1.2714, 1.2702, 1.2948, 1.2403, 1.3399, 1.2530, 1.2425, 1.2242,
         1.2250, 1.2085, 1.2199, 1.2370, 1.2014, 1.1939, 1.2187, 1.1897, 1.1897,
         1.2384, 1.2817, 1.2107, 1.2345, 1.2820, 1.2211, 1.2500, 1.1715, 1.2131,
         1.3668, 1.4054, 1.3844, 1.3739, 1.3913, 1.3242, 1.3703, 1.3675, 1.3162,
         1.3254, 1.2755, 1.2643, 1.2440, 1.3155, 1.2631, 1.3561, 1.2372, 1.2421],
        [1.2650, 1.1751, 0.9929, 1.2166, 1.2917, 1.3160, 1.2397, 1.3070, 1.3070,
         1.5137, 1.7653, 1.5193, 2.2728, 1.5534, 5.0682, 1.6199, 1.4465, 4.8586,
         1.1090, 1.1870, 0.9734, 1.1557, 1.2895, 1.3226, 1.2959, 1.3183, 1.3183,
         1.2908, 1.0244, 1.3356, 1.3146, 1.1301, 1.3483, 1.3774, 1.2975, 1.3254,
         1.3129, 1.4650, 1.3802, 1.2903, 1.2991, 1.4289, 1.3633, 0.4865, 1.3498,
         1.0188, 1.3954, 1.3795, 1.3566, 1.0424, 1.3785, 0.8554, 1.3484, 1.3554],
        [1.1846, 1.2113, 1.2646, 1.2456, 1.2181, 1.1903, 1.1972, 1.1829, 1.1829,
         1.2609, 1.2776, 1.2761, 1.3008, 1.2459, 1.3052, 1.2588, 1.2395, 1.2039,
         2.4649, 2.5392, 2.6472, 2.5872, 2.3543, 2.4470, 2.4760, 2.3421, 2.3421,
         1.2812, 1.2570, 1.2169, 1.2409, 1.2807, 1.2274, 1.2568, 1.2216, 1.2194,
         1.3700, 1.4090, 1.3877, 1.3669, 1.3947, 1.3833, 1.3735, 1.2822, 1.3086,
         1.2911, 1.2816, 1.2703, 1.2497, 1.2490, 1.2693, 1.3218, 1.2428, 1.2479],
        [1.1853, 1.2134, 1.2473, 1.2274, 1.2207, 1.1914, 1.1989, 1.1836, 1.1836,
         1.2588, 1.2552, 1.2748, 1.2937, 1.2432, 1.2530, 1.2567, 1.2453, 1.1470,
         1.2337, 1.2549, 1.2737, 1.2463, 1.2087, 1.1949, 1.2266, 1.1964, 1.1964,
         2.7459, 2.5362, 2.2473, 2.3733, 2.7388, 2.2583, 2.6931, 2.2577, 2.2498,
         1.3555, 1.3963, 1.3648, 1.3552, 1.3814, 1.3663, 1.3583, 1.2531, 1.3010,
         1.3334, 1.2725, 1.1694, 1.2005, 1.3230, 1.2397, 1.3658, 1.1932, 1.2454],
        [1.6720, 1.3549, 0.6127, 0.8130, 1.1708, 1.5637, 1.5029, 1.6690, 1.6690,
         1.5250, 1.2451, 1.3640, 0.9081, 1.6162, 0.2712, 1.5133, 1.6335, 1.1233,
         1.3011, 0.8755, 0.7694, 1.0922, 1.5382, 1.6020, 1.3219, 1.6759, 1.6759,
         0.7014, 0.8458, 1.6415, 1.4440, 0.7883, 1.5812, 1.0806, 1.6923, 1.6170,
         0.2873, 0.0652, 0.0393, 0.2470, 0.5089, 0.6743, 0.1925, 9.9658, 7.4956,
         0.7725, 1.1935, 1.2831, 1.5067, 1.0061, 1.4530, 0.4389, 1.5564, 1.6714],
        [1.2428, 1.2743, 1.3369, 1.3155, 1.2836, 1.2497, 1.2147, 1.2408, 1.2408,
         1.2134, 1.3269, 1.2310, 1.3551, 1.2900, 1.4078, 1.2109, 1.2927, 1.2310,
         1.2946, 1.3263, 1.3401, 1.3082, 1.2666, 1.2570, 1.2161, 1.2527, 1.2527,
         1.3114, 1.3543, 1.2709, 1.1006, 1.2633, 1.1485, 1.3170, 1.1454, 1.2739,
         1.3652, 1.0705, 1.3863, 1.3739, 0.9639, 0.8678, 1.3696, 1.3645, 0.7548,
         2.9039, 2.4074, 2.9962, 2.6244, 2.0609, 1.7692, 2.7326, 2.8224, 1.7494]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 150 : 180.5561181022201
Test loss for epoch 150 : 180.63478134301715
Test Precision for epoch 150 : 0.26153846153846155
Test Recall for epoch 150 : 0.26153846153846155
Test F1 for epoch 150 : 0.26153846153846155


theta for epoch 151 : tensor([[ 2.4018,  2.4312,  2.5044,  2.5971,  2.5601,  2.4078,  2.5365,  2.4000,
          2.4000,  1.2549,  1.2713,  1.2700,  1.2946,  1.2401,  1.3397,  1.2528,
          1.2423,  1.2241,  1.2247,  1.2082,  1.2195,  1.2367,  1.2011,  1.1936,
          1.2184,  1.1894,  1.1894,  1.2381,  1.2814,  1.2104,  1.2342,  1.2817,
          1.2208,  1.2497,  1.1712,  1.2128,  1.3668,  1.4055,  1.3844,  1.3739,
          1.3914,  1.3243,  1.3703,  1.3674,  1.3162,  1.3251,  1.2753,  1.2640,
          1.2438,  1.3153,  1.2629,  1.3559,  1.2370,  1.2419],
        [ 1.2649,  1.1750,  0.9929,  1.2166,  1.2919,  1.3159,  1.2396,  1.3069,
          1.3069,  1.5139,  1.7653,  1.5195,  2.2731,  1.5536,  5.0867,  1.6201,
          1.4467,  4.8786,  1.1088,  1.1870,  0.9735,  1.1555,  1.2895,  1.3226,
          1.2957,  1.3183,  1.3183,  1.2908,  1.0242,  1.3355,  1.3145,  1.1301,
          1.3482,  1.3774,  1.2973,  1.3255,  1.3128,  1.4648,  1.3799,  1.2899,
          1.2989,  1.4288,  1.3629,  0.4862,  1.3493,  1.0188,  1.3954,  1.3794,
          1.3565,  1.0422,  1.3785,  0.8556,  1.3482,  1.3553],
        [ 1.1842,  1.2109,  1.2642,  1.2452,  1.2178,  1.1900,  1.1969,  1.1826,
          1.1826,  1.2607,  1.2775,  1.2759,  1.3006,  1.2457,  1.3052,  1.2586,
          1.2392,  1.2041,  2.4691,  2.5439,  2.6518,  2.5916,  2.3587,  2.4516,
          2.4805,  2.3464,  2.3464,  1.2808,  1.2569,  1.2166,  1.2405,  1.2803,
          1.2271,  1.2565,  1.2213,  1.2191,  1.3700,  1.4091,  1.3877,  1.3668,
          1.3948,  1.3834,  1.3735,  1.2825,  1.3085,  1.2910,  1.2813,  1.2700,
          1.2495,  1.2492,  1.2691,  1.3217,  1.2426,  1.2477],
        [ 1.1850,  1.2130,  1.2476,  1.2278,  1.2204,  1.1911,  1.1986,  1.1833,
          1.1833,  1.2586,  1.2557,  1.2747,  1.2938,  1.2430,  1.2529,  1.2565,
          1.2451,  1.1480,  1.2333,  1.2548,  1.2733,  1.2460,  1.2084,  1.1948,
          1.2263,  1.1961,  1.1961,  2.7490,  2.5425,  2.2525,  2.3790,  2.7420,
          2.2635,  2.6963,  2.2629,  2.2550,  1.3556,  1.3965,  1.3652,  1.3556,
          1.3816,  1.3666,  1.3585,  1.2545,  1.3011,  1.3331,  1.2726,  1.1694,
          1.2003,  1.3228,  1.2404,  1.3655,  1.1930,  1.2452],
        [ 1.6726,  1.3556,  0.6133,  0.8136,  1.1714,  1.5643,  1.5036,  1.6696,
          1.6696,  1.5253,  1.2450,  1.3645,  0.9085,  1.6165,  0.2721,  1.5137,
          1.6339,  1.1229,  1.3018,  0.8763,  0.7702,  1.0929,  1.5388,  1.6024,
          1.3228,  1.6765,  1.6765,  0.7019,  0.8467,  1.6422,  1.4450,  0.7888,
          1.5818,  1.0809,  1.6930,  1.6175,  0.2851,  0.0630,  0.0374,  0.2448,
          0.5062,  0.6712,  0.1903, 10.0123,  7.5055,  0.7734,  1.1939,  1.2837,
          1.5072,  1.0067,  1.4529,  0.4397,  1.5571,  1.6719],
        [ 1.2426,  1.2741,  1.3367,  1.3154,  1.2834,  1.2495,  1.2145,  1.2407,
          1.2407,  1.2132,  1.3269,  1.2309,  1.3550,  1.2899,  1.4078,  1.2107,
          1.2925,  1.2309,  1.2945,  1.3261,  1.3399,  1.3081,  1.2664,  1.2569,
          1.2156,  1.2526,  1.2526,  1.3113,  1.3540,  1.2708,  1.1000,  1.2632,
          1.1483,  1.3169,  1.1452,  1.2737,  1.3650,  1.0699,  1.3861,  1.3737,
          0.9633,  0.8672,  1.3694,  1.3641,  0.7541,  2.9105,  2.4108,  3.0041,
          2.6289,  2.0629,  1.7708,  2.7375,  2.8292,  1.7509]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 151 : 180.54932318129806
Test loss for epoch 151 : 180.62879352048748
Test Precision for epoch 151 : 0.26153846153846155
Test Recall for epoch 151 : 0.26153846153846155
Test F1 for epoch 151 : 0.26153846153846155


theta for epoch 152 : tensor([[ 2.4060,  2.4354,  2.5086,  2.6019,  2.5649,  2.4120,  2.5413,  2.4042,
          2.4042,  1.2547,  1.2712,  1.2698,  1.2945,  1.2399,  1.3396,  1.2526,
          1.2421,  1.2239,  1.2244,  1.2078,  1.2192,  1.2364,  1.2008,  1.1934,
          1.2181,  1.1891,  1.1891,  1.2378,  1.2810,  1.2100,  1.2338,  1.2814,
          1.2204,  1.2495,  1.1708,  1.2125,  1.3669,  1.4057,  1.3845,  1.3740,
          1.3916,  1.3244,  1.3704,  1.3674,  1.3162,  1.3249,  1.2750,  1.2638,
          1.2435,  1.3151,  1.2627,  1.3556,  1.2367,  1.2417],
        [ 1.2649,  1.1750,  0.9930,  1.2166,  1.2920,  1.3158,  1.2395,  1.3068,
          1.3068,  1.5140,  1.7651,  1.5197,  2.2733,  1.5538,  5.1051,  1.6203,
          1.4468,  4.8986,  1.1087,  1.1870,  0.9736,  1.1554,  1.2894,  1.3226,
          1.2956,  1.3182,  1.3182,  1.2909,  1.0240,  1.3353,  1.3143,  1.1301,
          1.3480,  1.3775,  1.2972,  1.3256,  1.3126,  1.4647,  1.3795,  1.2896,
          1.2988,  1.4287,  1.3626,  0.4858,  1.3489,  1.0188,  1.3953,  1.3792,
          1.3563,  1.0421,  1.3785,  0.8559,  1.3480,  1.3552],
        [ 1.1839,  1.2106,  1.2638,  1.2449,  1.2175,  1.1897,  1.1965,  1.1822,
          1.1822,  1.2605,  1.2773,  1.2758,  1.3005,  1.2455,  1.3053,  1.2584,
          1.2389,  1.2044,  2.4733,  2.5487,  2.6564,  2.5959,  2.3631,  2.4561,
          2.4849,  2.3508,  2.3508,  1.2804,  1.2567,  1.2162,  1.2401,  1.2799,
          1.2267,  1.2562,  1.2209,  1.2187,  1.3700,  1.4092,  1.3877,  1.3668,
          1.3950,  1.3836,  1.3736,  1.2829,  1.3085,  1.2909,  1.2811,  1.2697,
          1.2493,  1.2493,  1.2689,  1.3215,  1.2423,  1.2474],
        [ 1.1847,  1.2127,  1.2478,  1.2281,  1.2201,  1.1908,  1.1983,  1.1830,
          1.1830,  1.2585,  1.2562,  1.2745,  1.2938,  1.2428,  1.2527,  1.2563,
          1.2449,  1.1489,  1.2331,  1.2547,  1.2730,  1.2457,  1.2081,  1.1947,
          1.2260,  1.1959,  1.1959,  2.7521,  2.5487,  2.2577,  2.3847,  2.7451,
          2.2687,  2.6995,  2.2680,  2.2602,  1.3558,  1.3968,  1.3656,  1.3560,
          1.3819,  1.3670,  1.3587,  1.2558,  1.3013,  1.3329,  1.2726,  1.1694,
          1.2001,  1.3225,  1.2411,  1.3652,  1.1928,  1.2450],
        [ 1.6732,  1.3563,  0.6140,  0.8141,  1.1720,  1.5650,  1.5043,  1.6702,
          1.6702,  1.5257,  1.2448,  1.3649,  0.9088,  1.6168,  0.2729,  1.5140,
          1.6343,  1.1225,  1.3025,  0.8770,  0.7709,  1.0936,  1.5394,  1.6028,
          1.3238,  1.6771,  1.6771,  0.7025,  0.8475,  1.6428,  1.4459,  0.7893,
          1.5825,  1.0812,  1.6936,  1.6179,  0.2831,  0.0609,  0.0355,  0.2427,
          0.5035,  0.6681,  0.1883, 10.0587,  7.5149,  0.7742,  1.1943,  1.2843,
          1.5077,  1.0072,  1.4528,  0.4405,  1.5578,  1.6723],
        [ 1.2425,  1.2740,  1.3365,  1.3152,  1.2832,  1.2493,  1.2143,  1.2405,
          1.2405,  1.2131,  1.3268,  1.2307,  1.3550,  1.2897,  1.4078,  1.2106,
          1.2924,  1.2308,  1.2943,  1.3259,  1.3398,  1.3079,  1.2662,  1.2568,
          1.2151,  1.2524,  1.2524,  1.3111,  1.3537,  1.2706,  1.0995,  1.2630,
          1.1480,  1.3168,  1.1449,  1.2735,  1.3649,  1.0694,  1.3860,  1.3736,
          0.9628,  0.8667,  1.3693,  1.3638,  0.7534,  2.9172,  2.4142,  3.0120,
          2.6334,  2.0650,  1.7724,  2.7423,  2.8360,  1.7525]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 152 : 180.54260425082754
Test loss for epoch 152 : 180.6228870493647
Test Precision for epoch 152 : 0.26153846153846155
Test Recall for epoch 152 : 0.26153846153846155
Test F1 for epoch 152 : 0.26153846153846155


theta for epoch 153 : tensor([[ 2.4102,  2.4396,  2.5129,  2.6067,  2.5697,  2.4162,  2.5461,  2.4084,
          2.4084,  1.2546,  1.2711,  1.2697,  1.2944,  1.2397,  1.3395,  1.2525,
          1.2420,  1.2238,  1.2242,  1.2075,  1.2189,  1.2361,  1.2005,  1.1931,
          1.2178,  1.1889,  1.1889,  1.2374,  1.2806,  1.2097,  1.2334,  1.2811,
          1.2201,  1.2492,  1.1705,  1.2122,  1.3669,  1.4058,  1.3845,  1.3741,
          1.3918,  1.3246,  1.3705,  1.3673,  1.3162,  1.3246,  1.2748,  1.2635,
          1.2433,  1.3148,  1.2625,  1.3553,  1.2364,  1.2415],
        [ 1.2648,  1.1750,  0.9931,  1.2166,  1.2922,  1.3157,  1.2395,  1.3067,
          1.3067,  1.5141,  1.7649,  1.5198,  2.2735,  1.5539,  5.1236,  1.6204,
          1.4469,  4.9185,  1.1086,  1.1870,  0.9737,  1.1553,  1.2894,  1.3226,
          1.2954,  1.3182,  1.3182,  1.2909,  1.0237,  1.3352,  1.3142,  1.1302,
          1.3479,  1.3775,  1.2971,  1.3257,  1.3125,  1.4646,  1.3792,  1.2892,
          1.2987,  1.4286,  1.3623,  0.4855,  1.3485,  1.0188,  1.3952,  1.3791,
          1.3561,  1.0420,  1.3785,  0.8561,  1.3478,  1.3551],
        [ 1.1836,  1.2103,  1.2635,  1.2445,  1.2172,  1.1894,  1.1962,  1.1819,
          1.1819,  1.2603,  1.2772,  1.2756,  1.3004,  1.2453,  1.3053,  1.2582,
          1.2386,  1.2046,  2.4775,  2.5534,  2.6610,  2.6003,  2.3674,  2.4605,
          2.4893,  2.3551,  2.3551,  1.2800,  1.2565,  1.2159,  1.2398,  1.2795,
          1.2263,  1.2559,  1.2206,  1.2184,  1.3701,  1.4094,  1.3878,  1.3668,
          1.3951,  1.3838,  1.3737,  1.2833,  1.3084,  1.2907,  1.2808,  1.2694,
          1.2490,  1.2494,  1.2686,  1.3214,  1.2420,  1.2472],
        [ 1.1845,  1.2124,  1.2481,  1.2284,  1.2197,  1.1905,  1.1980,  1.1827,
          1.1827,  1.2583,  1.2567,  1.2743,  1.2939,  1.2427,  1.2526,  1.2561,
          1.2447,  1.1498,  1.2328,  1.2546,  1.2727,  1.2454,  1.2079,  1.1946,
          1.2257,  1.1956,  1.1956,  2.7551,  2.5549,  2.2628,  2.3903,  2.7482,
          2.2738,  2.7026,  2.2731,  2.2653,  1.3559,  1.3970,  1.3660,  1.3563,
          1.3822,  1.3674,  1.3588,  1.2571,  1.3014,  1.3326,  1.2727,  1.1693,
          1.1999,  1.3223,  1.2418,  1.3650,  1.1926,  1.2448],
        [ 1.6738,  1.3570,  0.6146,  0.8147,  1.1727,  1.5656,  1.5050,  1.6708,
          1.6708,  1.5261,  1.2447,  1.3653,  0.9091,  1.6171,  0.2737,  1.5144,
          1.6347,  1.1221,  1.3032,  0.8778,  0.7716,  1.0943,  1.5401,  1.6032,
          1.3248,  1.6777,  1.6777,  0.7030,  0.8483,  1.6434,  1.4469,  0.7898,
          1.5831,  1.0815,  1.6942,  1.6184,  0.2810,  0.0588,  0.0337,  0.2406,
          0.5009,  0.6651,  0.1862, 10.1049,  7.5239,  0.7751,  1.1948,  1.2849,
          1.5081,  1.0078,  1.4527,  0.4413,  1.5584,  1.6727],
        [ 1.2423,  1.2738,  1.3363,  1.3150,  1.2830,  1.2491,  1.2141,  1.2403,
          1.2403,  1.2129,  1.3268,  1.2306,  1.3549,  1.2895,  1.4077,  1.2104,
          1.2921,  1.2307,  1.2942,  1.3257,  1.3396,  1.3078,  1.2661,  1.2566,
          1.2146,  1.2522,  1.2522,  1.3109,  1.3535,  1.2703,  1.0989,  1.2628,
          1.1478,  1.3167,  1.1447,  1.2733,  1.3647,  1.0689,  1.3858,  1.3735,
          0.9622,  0.8661,  1.3692,  1.3635,  0.7527,  2.9238,  2.4176,  3.0199,
          2.6379,  2.0671,  1.7740,  2.7471,  2.8428,  1.7541]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 153 : 180.5359581369813
Test loss for epoch 153 : 180.61704023904812
Test Precision for epoch 153 : 0.26153846153846155
Test Recall for epoch 153 : 0.26153846153846155
Test F1 for epoch 153 : 0.26153846153846155


theta for epoch 154 : tensor([[ 2.4143,  2.4438,  2.5171,  2.6114,  2.5744,  2.4204,  2.5508,  2.4126,
          2.4126,  1.2544,  1.2710,  1.2695,  1.2943,  1.2396,  1.3394,  1.2523,
          1.2418,  1.2236,  1.2239,  1.2072,  1.2186,  1.2359,  1.2003,  1.1929,
          1.2176,  1.1886,  1.1886,  1.2371,  1.2802,  1.2094,  1.2331,  1.2808,
          1.2198,  1.2489,  1.1702,  1.2119,  1.3670,  1.4060,  1.3846,  1.3741,
          1.3919,  1.3247,  1.3705,  1.3672,  1.3163,  1.3243,  1.2745,  1.2632,
          1.2430,  1.3145,  1.2623,  1.3550,  1.2361,  1.2412],
        [ 1.2647,  1.1749,  0.9931,  1.2166,  1.2923,  1.3156,  1.2394,  1.3066,
          1.3066,  1.5142,  1.7647,  1.5200,  2.2736,  1.5540,  5.1420,  1.6205,
          1.4470,  4.9384,  1.1085,  1.1870,  0.9738,  1.1552,  1.2894,  1.3226,
          1.2952,  1.3182,  1.3182,  1.2909,  1.0235,  1.3351,  1.3141,  1.1302,
          1.3478,  1.3776,  1.2970,  1.3258,  1.3124,  1.4644,  1.3789,  1.2889,
          1.2986,  1.4285,  1.3620,  0.4852,  1.3480,  1.0188,  1.3952,  1.3789,
          1.3560,  1.0419,  1.3784,  0.8563,  1.3475,  1.3549],
        [ 1.1833,  1.2100,  1.2632,  1.2442,  1.2169,  1.1890,  1.1959,  1.1816,
          1.1816,  1.2601,  1.2771,  1.2754,  1.3003,  1.2452,  1.3053,  1.2580,
          1.2384,  1.2049,  2.4816,  2.5580,  2.6656,  2.6045,  2.3717,  2.4650,
          2.4936,  2.3594,  2.3594,  1.2796,  1.2564,  1.2156,  1.2394,  1.2791,
          1.2260,  1.2557,  1.2202,  1.2181,  1.3701,  1.4095,  1.3878,  1.3667,
          1.3953,  1.3839,  1.3737,  1.2836,  1.3083,  1.2906,  1.2806,  1.2691,
          1.2487,  1.2495,  1.2684,  1.3212,  1.2417,  1.2469],
        [ 1.1842,  1.2121,  1.2484,  1.2287,  1.2194,  1.1902,  1.1977,  1.1824,
          1.1824,  1.2582,  1.2572,  1.2742,  1.2940,  1.2425,  1.2525,  1.2560,
          1.2446,  1.1507,  1.2325,  1.2545,  1.2723,  1.2451,  1.2076,  1.1946,
          1.2255,  1.1954,  1.1954,  2.7580,  2.5611,  2.2679,  2.3959,  2.7513,
          2.2789,  2.7057,  2.2781,  2.2704,  1.3560,  1.3972,  1.3664,  1.3567,
          1.3824,  1.3677,  1.3590,  1.2583,  1.3015,  1.3323,  1.2727,  1.1692,
          1.1997,  1.3221,  1.2424,  1.3647,  1.1924,  1.2446],
        [ 1.6744,  1.3578,  0.6153,  0.8152,  1.1733,  1.5663,  1.5056,  1.6714,
          1.6714,  1.5265,  1.2447,  1.3658,  0.9095,  1.6174,  0.2745,  1.5148,
          1.6351,  1.1218,  1.3039,  0.8785,  0.7723,  1.0950,  1.5408,  1.6035,
          1.3257,  1.6783,  1.6783,  0.7036,  0.8492,  1.6440,  1.4479,  0.7904,
          1.5838,  1.0818,  1.6949,  1.6188,  0.2789,  0.0567,  0.0318,  0.2385,
          0.4982,  0.6621,  0.1841, 10.1510,  7.5324,  0.7759,  1.1952,  1.2854,
          1.5086,  1.0083,  1.4527,  0.4420,  1.5591,  1.6732],
        [ 1.2421,  1.2735,  1.3360,  1.3147,  1.2828,  1.2489,  1.2139,  1.2401,
          1.2401,  1.2127,  1.3267,  1.2304,  1.3548,  1.2893,  1.4076,  1.2102,
          1.2919,  1.2306,  1.2940,  1.3255,  1.3394,  1.3076,  1.2659,  1.2564,
          1.2141,  1.2520,  1.2520,  1.3107,  1.3532,  1.2701,  1.0983,  1.2626,
          1.1476,  1.3165,  1.1444,  1.2731,  1.3645,  1.0683,  1.3856,  1.3733,
          0.9617,  0.8655,  1.3690,  1.3632,  0.7519,  2.9305,  2.4210,  3.0278,
          2.6424,  2.0691,  1.7756,  2.7519,  2.8496,  1.7557]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 154 : 180.52938321354358
Test loss for epoch 154 : 180.61126908436577
Test Precision for epoch 154 : 0.26153846153846155
Test Recall for epoch 154 : 0.26153846153846155
Test F1 for epoch 154 : 0.26153846153846155


theta for epoch 155 : tensor([[ 2.4185,  2.4480,  2.5213,  2.6161,  2.5791,  2.4245,  2.5555,  2.4167,
          2.4167,  1.2542,  1.2709,  1.2694,  1.2942,  1.2394,  1.3393,  1.2521,
          1.2416,  1.2235,  1.2236,  1.2069,  1.2183,  1.2356,  1.2000,  1.1926,
          1.2173,  1.1883,  1.1883,  1.2368,  1.2799,  1.2092,  1.2328,  1.2805,
          1.2195,  1.2487,  1.1699,  1.2117,  1.3670,  1.4061,  1.3846,  1.3742,
          1.3921,  1.3248,  1.3706,  1.3671,  1.3163,  1.3240,  1.2743,  1.2629,
          1.2427,  1.3143,  1.2620,  1.3547,  1.2358,  1.2410],
        [ 1.2646,  1.1749,  0.9931,  1.2167,  1.2925,  1.3155,  1.2393,  1.3065,
          1.3065,  1.5142,  1.7645,  1.5200,  2.2735,  1.5540,  5.1605,  1.6206,
          1.4471,  4.9583,  1.1083,  1.1871,  0.9739,  1.1551,  1.2893,  1.3225,
          1.2950,  1.3181,  1.3181,  1.2910,  1.0234,  1.3351,  1.3140,  1.1303,
          1.3477,  1.3777,  1.2969,  1.3260,  1.3123,  1.4643,  1.3786,  1.2885,
          1.2985,  1.4285,  1.3616,  0.4849,  1.3476,  1.0189,  1.3951,  1.3788,
          1.3558,  1.0417,  1.3784,  0.8566,  1.3473,  1.3548],
        [ 1.1830,  1.2096,  1.2628,  1.2439,  1.2166,  1.1887,  1.1956,  1.1813,
          1.1813,  1.2599,  1.2770,  1.2752,  1.3001,  1.2450,  1.3053,  1.2578,
          1.2381,  1.2051,  2.4857,  2.5627,  2.6701,  2.6088,  2.3760,  2.4694,
          2.4980,  2.3637,  2.3637,  1.2792,  1.2563,  1.2153,  1.2391,  1.2787,
          1.2257,  1.2554,  1.2200,  1.2178,  1.3701,  1.4096,  1.3878,  1.3667,
          1.3954,  1.3840,  1.3738,  1.2840,  1.3082,  1.2904,  1.2803,  1.2688,
          1.2484,  1.2497,  1.2681,  1.3211,  1.2414,  1.2467],
        [ 1.1839,  1.2118,  1.2487,  1.2290,  1.2192,  1.1900,  1.1974,  1.1822,
          1.1822,  1.2580,  1.2577,  1.2740,  1.2941,  1.2424,  1.2524,  1.2559,
          1.2444,  1.1515,  1.2323,  1.2544,  1.2721,  1.2449,  1.2074,  1.1945,
          1.2252,  1.1951,  1.1951,  2.7610,  2.5671,  2.2729,  2.4015,  2.7543,
          2.2839,  2.7088,  2.2831,  2.2755,  1.3562,  1.3974,  1.3668,  1.3571,
          1.3827,  1.3681,  1.3592,  1.2595,  1.3016,  1.3320,  1.2727,  1.1692,
          1.1996,  1.3218,  1.2430,  1.3644,  1.1922,  1.2444],
        [ 1.6750,  1.3584,  0.6159,  0.8157,  1.1739,  1.5669,  1.5063,  1.6720,
          1.6720,  1.5268,  1.2446,  1.3662,  0.9098,  1.6177,  0.2753,  1.5151,
          1.6355,  1.1213,  1.3046,  0.8792,  0.7730,  1.0956,  1.5414,  1.6039,
          1.3266,  1.6789,  1.6789,  0.7042,  0.8500,  1.6446,  1.4488,  0.7909,
          1.5844,  1.0821,  1.6956,  1.6193,  0.2770,  0.0546,  0.0301,  0.2365,
          0.4957,  0.6592,  0.1821, 10.1970,  7.5405,  0.7767,  1.1956,  1.2860,
          1.5090,  1.0088,  1.4526,  0.4427,  1.5597,  1.6735],
        [ 1.2419,  1.2734,  1.3358,  1.3145,  1.2825,  1.2487,  1.2137,  1.2399,
          1.2399,  1.2125,  1.3266,  1.2302,  1.3547,  1.2891,  1.4076,  1.2100,
          1.2917,  1.2304,  1.2938,  1.3253,  1.3392,  1.3074,  1.2657,  1.2563,
          1.2137,  1.2519,  1.2519,  1.3105,  1.3530,  1.2700,  1.0977,  1.2625,
          1.1474,  1.3164,  1.1442,  1.2729,  1.3644,  1.0677,  1.3854,  1.3732,
          0.9611,  0.8649,  1.3689,  1.3629,  0.7512,  2.9371,  2.4243,  3.0356,
          2.6468,  2.0711,  1.7772,  2.7566,  2.8563,  1.7572]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 155 : 180.5228789840425
Test loss for epoch 155 : 180.60559007128575
Test Precision for epoch 155 : 0.26153846153846155
Test Recall for epoch 155 : 0.26153846153846155
Test F1 for epoch 155 : 0.26153846153846155


theta for epoch 156 : tensor([[ 2.4226,  2.4521,  2.5254,  2.6208,  2.5838,  2.4286,  2.5602,  2.4208,
          2.4208,  1.2541,  1.2708,  1.2692,  1.2941,  1.2392,  1.3391,  1.2520,
          1.2414,  1.2234,  1.2233,  1.2066,  1.2180,  1.2353,  1.1997,  1.1924,
          1.2170,  1.1881,  1.1881,  1.2365,  1.2795,  1.2089,  1.2325,  1.2802,
          1.2192,  1.2485,  1.1696,  1.2114,  1.3670,  1.4062,  1.3846,  1.3742,
          1.3922,  1.3249,  1.3707,  1.3671,  1.3163,  1.3238,  1.2741,  1.2627,
          1.2425,  1.3141,  1.2618,  1.3545,  1.2356,  1.2408],
        [ 1.2645,  1.1748,  0.9932,  1.2167,  1.2926,  1.3154,  1.2392,  1.3064,
          1.3064,  1.5142,  1.7642,  1.5201,  2.2734,  1.5541,  5.1789,  1.6207,
          1.4472,  4.9782,  1.1082,  1.1871,  0.9740,  1.1550,  1.2893,  1.3225,
          1.2948,  1.3180,  1.3180,  1.2910,  1.0232,  1.3350,  1.3140,  1.1304,
          1.3476,  1.3777,  1.2968,  1.3261,  1.3122,  1.4641,  1.3782,  1.2882,
          1.2983,  1.4284,  1.3613,  0.4845,  1.3472,  1.0189,  1.3951,  1.3787,
          1.3557,  1.0416,  1.3784,  0.8568,  1.3471,  1.3547],
        [ 1.1827,  1.2093,  1.2625,  1.2436,  1.2163,  1.1884,  1.1953,  1.1810,
          1.1810,  1.2597,  1.2768,  1.2750,  1.3000,  1.2448,  1.3054,  1.2576,
          1.2378,  1.2054,  2.4898,  2.5673,  2.6745,  2.6129,  2.3803,  2.4738,
          2.5023,  2.3680,  2.3680,  1.2788,  1.2562,  1.2150,  1.2387,  1.2783,
          1.2254,  1.2551,  1.2196,  1.2175,  1.3701,  1.4097,  1.3878,  1.3666,
          1.3955,  1.3842,  1.3738,  1.2843,  1.3081,  1.2903,  1.2801,  1.2685,
          1.2482,  1.2499,  1.2679,  1.3210,  1.2411,  1.2464],
        [ 1.1837,  1.2115,  1.2489,  1.2293,  1.2189,  1.1897,  1.1972,  1.1819,
          1.1819,  1.2579,  1.2582,  1.2739,  1.2942,  1.2423,  1.2523,  1.2557,
          1.2443,  1.1523,  1.2320,  1.2543,  1.2718,  1.2446,  1.2072,  1.1945,
          1.2249,  1.1949,  1.1949,  2.7639,  2.5732,  2.2779,  2.4069,  2.7572,
          2.2889,  2.7118,  2.2880,  2.2804,  1.3563,  1.3976,  1.3672,  1.3574,
          1.3829,  1.3684,  1.3594,  1.2607,  1.3018,  1.3318,  1.2728,  1.1692,
          1.1994,  1.3216,  1.2436,  1.3642,  1.1920,  1.2443],
        [ 1.6756,  1.3591,  0.6165,  0.8162,  1.1745,  1.5674,  1.5069,  1.6725,
          1.6725,  1.5271,  1.2444,  1.3665,  0.9101,  1.6180,  0.2759,  1.5155,
          1.6358,  1.1209,  1.3052,  0.8799,  0.7736,  1.0962,  1.5420,  1.6042,
          1.3275,  1.6795,  1.6795,  0.7048,  0.8508,  1.6452,  1.4497,  0.7914,
          1.5850,  1.0824,  1.6962,  1.6197,  0.2750,  0.0527,  0.0283,  0.2346,
          0.4933,  0.6564,  0.1802, 10.2428,  7.5481,  0.7774,  1.1960,  1.2866,
          1.5094,  1.0093,  1.4525,  0.4434,  1.5603,  1.6739],
        [ 1.2417,  1.2732,  1.3356,  1.3143,  1.2824,  1.2485,  1.2135,  1.2397,
          1.2397,  1.2123,  1.3265,  1.2301,  1.3546,  1.2889,  1.4075,  1.2098,
          1.2916,  1.2304,  1.2936,  1.3251,  1.3391,  1.3073,  1.2655,  1.2561,
          1.2132,  1.2517,  1.2517,  1.3103,  1.3528,  1.2698,  1.0972,  1.2623,
          1.1472,  1.3163,  1.1439,  1.2727,  1.3642,  1.0672,  1.3853,  1.3731,
          0.9606,  0.8643,  1.3688,  1.3626,  0.7505,  2.9436,  2.4276,  3.0434,
          2.6511,  2.0731,  1.7787,  2.7612,  2.8630,  1.7587]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 156 : 180.5164413878744
Test loss for epoch 156 : 180.60001092367247
Test Precision for epoch 156 : 0.26153846153846155
Test Recall for epoch 156 : 0.26153846153846155
Test F1 for epoch 156 : 0.26153846153846155


theta for epoch 157 : tensor([[ 2.4266,  2.4562,  2.5295,  2.6255,  2.5884,  2.4327,  2.5648,  2.4249,
          2.4249,  1.2539,  1.2707,  1.2691,  1.2940,  1.2390,  1.3390,  1.2518,
          1.2412,  1.2232,  1.2231,  1.2063,  1.2177,  1.2351,  1.1994,  1.1921,
          1.2167,  1.1878,  1.1878,  1.2362,  1.2791,  1.2086,  1.2322,  1.2799,
          1.2189,  1.2482,  1.1693,  1.2111,  1.3670,  1.4063,  1.3846,  1.3743,
          1.3923,  1.3250,  1.3707,  1.3670,  1.3163,  1.3235,  1.2739,  1.2624,
          1.2423,  1.3139,  1.2617,  1.3543,  1.2353,  1.2406],
        [ 1.2644,  1.1748,  0.9932,  1.2167,  1.2927,  1.3153,  1.2391,  1.3063,
          1.3063,  1.5143,  1.7638,  1.5202,  2.2733,  1.5541,  5.1974,  1.6207,
          1.4472,  4.9981,  1.1081,  1.1870,  0.9740,  1.1549,  1.2892,  1.3225,
          1.2946,  1.3180,  1.3180,  1.2910,  1.0230,  1.3349,  1.3138,  1.1304,
          1.3475,  1.3778,  1.2967,  1.3262,  1.3121,  1.4639,  1.3779,  1.2878,
          1.2982,  1.4283,  1.3610,  0.4842,  1.3467,  1.0190,  1.3950,  1.3786,
          1.3555,  1.0416,  1.3784,  0.8571,  1.3469,  1.3546],
        [ 1.1824,  1.2090,  1.2621,  1.2432,  1.2160,  1.1881,  1.1950,  1.1807,
          1.1807,  1.2596,  1.2767,  1.2749,  1.2999,  1.2446,  1.3054,  1.2575,
          1.2375,  1.2057,  2.4938,  2.5719,  2.6789,  2.6171,  2.3846,  2.4781,
          2.5066,  2.3722,  2.3722,  1.2784,  1.2561,  1.2146,  1.2384,  1.2779,
          1.2250,  1.2548,  1.2193,  1.2172,  1.3701,  1.4098,  1.3878,  1.3665,
          1.3956,  1.3843,  1.3739,  1.2847,  1.3080,  1.2902,  1.2799,  1.2683,
          1.2479,  1.2501,  1.2677,  1.3209,  1.2408,  1.2462],
        [ 1.1834,  1.2113,  1.2491,  1.2296,  1.2186,  1.1894,  1.1969,  1.1817,
          1.1817,  1.2578,  1.2587,  1.2738,  1.2943,  1.2422,  1.2522,  1.2556,
          1.2441,  1.1531,  1.2318,  1.2542,  1.2715,  1.2444,  1.2069,  1.1944,
          1.2247,  1.1947,  1.1947,  2.7667,  2.5792,  2.2828,  2.4124,  2.7602,
          2.2938,  2.7148,  2.2929,  2.2854,  1.3564,  1.3978,  1.3675,  1.3577,
          1.3831,  1.3687,  1.3595,  1.2618,  1.3019,  1.3316,  1.2728,  1.1691,
          1.1993,  1.3214,  1.2442,  1.3639,  1.1918,  1.2441],
        [ 1.6761,  1.3597,  0.6170,  0.8167,  1.1750,  1.5680,  1.5075,  1.6731,
          1.6731,  1.5274,  1.2444,  1.3669,  0.9104,  1.6182,  0.2766,  1.5158,
          1.6362,  1.1205,  1.3058,  0.8806,  0.7743,  1.0968,  1.5426,  1.6045,
          1.3284,  1.6800,  1.6800,  0.7053,  0.8515,  1.6458,  1.4507,  0.7919,
          1.5856,  1.0827,  1.6968,  1.6201,  0.2731,  0.0507,  0.0266,  0.2326,
          0.4909,  0.6536,  0.1783, 10.2885,  7.5553,  0.7782,  1.1965,  1.2872,
          1.5098,  1.0099,  1.4524,  0.4441,  1.5610,  1.6744],
        [ 1.2415,  1.2730,  1.3354,  1.3142,  1.2822,  1.2483,  1.2133,  1.2396,
          1.2396,  1.2121,  1.3265,  1.2300,  1.3546,  1.2888,  1.4075,  1.2097,
          1.2914,  1.2303,  1.2935,  1.3249,  1.3389,  1.3071,  1.2654,  1.2560,
          1.2127,  1.2515,  1.2515,  1.3101,  1.3525,  1.2696,  1.0966,  1.2622,
          1.1470,  1.3162,  1.1437,  1.2725,  1.3640,  1.0666,  1.3851,  1.3729,
          0.9600,  0.8637,  1.3686,  1.3623,  0.7498,  2.9502,  2.4308,  3.0511,
          2.6554,  2.0750,  1.7802,  2.7658,  2.8696,  1.7602]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 157 : 180.5100699060476
Test loss for epoch 157 : 180.5944974637256
Test Precision for epoch 157 : 0.26153846153846155
Test Recall for epoch 157 : 0.26153846153846155
Test F1 for epoch 157 : 0.26153846153846155


theta for epoch 158 : tensor([[ 2.4307,  2.4602,  2.5336,  2.6301,  2.5931,  2.4367,  2.5694,  2.4289,
          2.4289,  1.2537,  1.2706,  1.2689,  1.2939,  1.2388,  1.3389,  1.2516,
          1.2410,  1.2231,  1.2228,  1.2061,  1.2174,  1.2348,  1.1992,  1.1919,
          1.2165,  1.1876,  1.1876,  1.2359,  1.2788,  1.2083,  1.2318,  1.2796,
          1.2186,  1.2480,  1.1690,  1.2108,  1.3671,  1.4064,  1.3847,  1.3743,
          1.3924,  1.3250,  1.3707,  1.3669,  1.3163,  1.3233,  1.2737,  1.2622,
          1.2421,  1.3137,  1.2615,  1.3540,  1.2351,  1.2404],
        [ 1.2643,  1.1747,  0.9933,  1.2167,  1.2929,  1.3152,  1.2391,  1.3062,
          1.3062,  1.5142,  1.7635,  1.5202,  2.2731,  1.5541,  5.2158,  1.6207,
          1.4472,  5.0179,  1.1080,  1.1871,  0.9741,  1.1548,  1.2892,  1.3225,
          1.2944,  1.3179,  1.3179,  1.2911,  1.0229,  1.3348,  1.3138,  1.1305,
          1.3474,  1.3779,  1.2966,  1.3263,  1.3119,  1.4638,  1.3776,  1.2875,
          1.2981,  1.4282,  1.3607,  0.4839,  1.3463,  1.0191,  1.3950,  1.3785,
          1.3554,  1.0415,  1.3784,  0.8574,  1.3468,  1.3545],
        [ 1.1821,  1.2087,  1.2618,  1.2429,  1.2157,  1.1878,  1.1947,  1.1804,
          1.1804,  1.2594,  1.2766,  1.2747,  1.2997,  1.2444,  1.3054,  1.2573,
          1.2372,  1.2060,  2.4978,  2.5765,  2.6833,  2.6211,  2.3888,  2.4825,
          2.5108,  2.3765,  2.3765,  1.2780,  1.2560,  1.2143,  1.2380,  1.2775,
          1.2247,  1.2546,  1.2190,  1.2169,  1.3701,  1.4099,  1.3879,  1.3665,
          1.3957,  1.3844,  1.3739,  1.2851,  1.3079,  1.2901,  1.2796,  1.2680,
          1.2477,  1.2503,  1.2675,  1.3208,  1.2405,  1.2460],
        [ 1.1831,  1.2110,  1.2493,  1.2298,  1.2183,  1.1892,  1.1966,  1.1814,
          1.1814,  1.2576,  1.2591,  1.2736,  1.2944,  1.2420,  1.2521,  1.2554,
          1.2440,  1.1539,  1.2315,  1.2541,  1.2712,  1.2441,  1.2066,  1.1943,
          1.2244,  1.1944,  1.1944,  2.7696,  2.5852,  2.2878,  2.4178,  2.7632,
          2.2987,  2.7178,  2.2977,  2.2903,  1.3565,  1.3980,  1.3678,  1.3580,
          1.3833,  1.3690,  1.3597,  1.2629,  1.3019,  1.3313,  1.2728,  1.1691,
          1.1991,  1.3212,  1.2447,  1.3637,  1.1916,  1.2439],
        [ 1.6767,  1.3604,  0.6176,  0.8173,  1.1756,  1.5686,  1.5081,  1.6737,
          1.6737,  1.5277,  1.2443,  1.3673,  0.9107,  1.6185,  0.2773,  1.5161,
          1.6366,  1.1201,  1.3065,  0.8813,  0.7749,  1.0974,  1.5432,  1.6049,
          1.3293,  1.6806,  1.6806,  0.7059,  0.8523,  1.6464,  1.4516,  0.7924,
          1.5862,  1.0831,  1.6974,  1.6206,  0.2712,  0.0488,  0.0249,  0.2307,
          0.4885,  0.6509,  0.1763, 10.3341,  7.5621,  0.7790,  1.1969,  1.2878,
          1.5103,  1.0104,  1.4524,  0.4447,  1.5616,  1.6748],
        [ 1.2414,  1.2728,  1.3352,  1.3140,  1.2820,  1.2482,  1.2131,  1.2394,
          1.2394,  1.2120,  1.3264,  1.2298,  1.3545,  1.2886,  1.4074,  1.2095,
          1.2912,  1.2302,  1.2934,  1.3248,  1.3388,  1.3070,  1.2652,  1.2559,
          1.2123,  1.2514,  1.2514,  1.3100,  1.3523,  1.2694,  1.0961,  1.2621,
          1.1468,  1.3161,  1.1435,  1.2723,  1.3639,  1.0661,  1.3849,  1.3728,
          0.9595,  0.8632,  1.3685,  1.3620,  0.7492,  2.9567,  2.4339,  3.0589,
          2.6597,  2.0769,  1.7817,  2.7704,  2.8762,  1.7616]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 158 : 180.5037616068218
Test loss for epoch 158 : 180.58904490070915
Test Precision for epoch 158 : 0.26153846153846155
Test Recall for epoch 158 : 0.26153846153846155
Test F1 for epoch 158 : 0.26153846153846155


theta for epoch 159 : tensor([[ 2.4347,  2.4643,  2.5376,  2.6346,  2.5976,  2.4407,  2.5739,  2.4329,
          2.4329,  1.2536,  1.2705,  1.2688,  1.2938,  1.2387,  1.3388,  1.2515,
          1.2409,  1.2230,  1.2226,  1.2058,  1.2172,  1.2346,  1.1989,  1.1917,
          1.2162,  1.1873,  1.1873,  1.2356,  1.2784,  1.2080,  1.2315,  1.2793,
          1.2183,  1.2477,  1.1687,  1.2105,  1.3671,  1.4066,  1.3847,  1.3744,
          1.3926,  1.3252,  1.3708,  1.3669,  1.3163,  1.3230,  1.2735,  1.2619,
          1.2418,  1.3134,  1.2612,  1.3537,  1.2348,  1.2401],
        [ 1.2642,  1.1747,  0.9933,  1.2167,  1.2931,  1.3151,  1.2390,  1.3061,
          1.3061,  1.5142,  1.7631,  1.5201,  2.2728,  1.5540,  5.2342,  1.6207,
          1.4472,  5.0376,  1.1078,  1.1871,  0.9742,  1.1547,  1.2891,  1.3224,
          1.2942,  1.3178,  1.3178,  1.2911,  1.0227,  1.3347,  1.3137,  1.1305,
          1.3474,  1.3779,  1.2965,  1.3264,  1.3119,  1.4636,  1.3773,  1.2871,
          1.2980,  1.4281,  1.3604,  0.4836,  1.3458,  1.0191,  1.3949,  1.3783,
          1.3553,  1.0414,  1.3783,  0.8577,  1.3465,  1.3544],
        [ 1.1818,  1.2084,  1.2615,  1.2426,  1.2154,  1.1875,  1.1944,  1.1801,
          1.1801,  1.2592,  1.2765,  1.2745,  1.2996,  1.2442,  1.3054,  1.2571,
          1.2369,  1.2063,  2.5017,  2.5811,  2.6876,  2.6252,  2.3930,  2.4867,
          2.5150,  2.3806,  2.3806,  1.2776,  1.2559,  1.2140,  1.2377,  1.2771,
          1.2244,  1.2543,  1.2187,  1.2165,  1.3702,  1.4100,  1.3879,  1.3664,
          1.3958,  1.3845,  1.3740,  1.2855,  1.3078,  1.2900,  1.2794,  1.2677,
          1.2474,  1.2505,  1.2672,  1.3207,  1.2402,  1.2457],
        [ 1.1829,  1.2107,  1.2495,  1.2300,  1.2180,  1.1889,  1.1963,  1.1811,
          1.1811,  1.2575,  1.2595,  1.2735,  1.2944,  1.2418,  1.2520,  1.2553,
          1.2438,  1.1546,  1.2312,  1.2539,  1.2709,  1.2438,  1.2064,  1.1942,
          1.2241,  1.1942,  1.1942,  2.7725,  2.5912,  2.2926,  2.4232,  2.7661,
          2.3036,  2.7207,  2.3026,  2.2952,  1.3566,  1.3982,  1.3682,  1.3583,
          1.3835,  1.3693,  1.3598,  1.2640,  1.3021,  1.3311,  1.2728,  1.1690,
          1.1989,  1.3210,  1.2452,  1.3634,  1.1914,  1.2437],
        [ 1.6773,  1.3610,  0.6182,  0.8178,  1.1762,  1.5692,  1.5087,  1.6742,
          1.6742,  1.5281,  1.2442,  1.3677,  0.9110,  1.6188,  0.2779,  1.5164,
          1.6370,  1.1197,  1.3071,  0.8820,  0.7756,  1.0980,  1.5438,  1.6052,
          1.3302,  1.6812,  1.6812,  0.7065,  0.8531,  1.6469,  1.4525,  0.7929,
          1.5868,  1.0834,  1.6980,  1.6210,  0.2693,  0.0469,  0.0232,  0.2288,
          0.4861,  0.6482,  0.1745, 10.3796,  7.5684,  0.7797,  1.1973,  1.2884,
          1.5106,  1.0108,  1.4523,  0.4454,  1.5622,  1.6751],
        [ 1.2412,  1.2726,  1.3350,  1.3138,  1.2818,  1.2480,  1.2129,  1.2392,
          1.2392,  1.2118,  1.3264,  1.2297,  1.3545,  1.2885,  1.4073,  1.2094,
          1.2911,  1.2301,  1.2932,  1.3246,  1.3386,  1.3068,  1.2651,  1.2557,
          1.2119,  1.2512,  1.2512,  1.3098,  1.3521,  1.2692,  1.0956,  1.2619,
          1.1467,  1.3159,  1.1432,  1.2721,  1.3638,  1.0656,  1.3848,  1.3727,
          0.9590,  0.8626,  1.3684,  1.3617,  0.7485,  2.9632,  2.4370,  3.0666,
          2.6639,  2.0788,  1.7832,  2.7749,  2.8827,  1.7631]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 159 : 180.4975150646006
Test loss for epoch 159 : 180.5836785551928
Test Precision for epoch 159 : 0.26153846153846155
Test Recall for epoch 159 : 0.26153846153846155
Test F1 for epoch 159 : 0.26153846153846155


theta for epoch 160 : tensor([[ 2.4386,  2.4682,  2.5416,  2.6392,  2.6022,  2.4447,  2.5785,  2.4369,
          2.4369,  1.2534,  1.2704,  1.2686,  1.2937,  1.2386,  1.3387,  1.2513,
          1.2407,  1.2229,  1.2223,  1.2055,  1.2169,  1.2344,  1.1987,  1.1915,
          1.2160,  1.1871,  1.1871,  1.2353,  1.2780,  1.2077,  1.2312,  1.2790,
          1.2179,  1.2474,  1.1684,  1.2102,  1.3672,  1.4067,  1.3848,  1.3745,
          1.3927,  1.3253,  1.3709,  1.3668,  1.3163,  1.3227,  1.2732,  1.2616,
          1.2416,  1.3132,  1.2610,  1.3535,  1.2345,  1.2399],
        [ 1.2642,  1.1747,  0.9934,  1.2168,  1.2932,  1.3151,  1.2390,  1.3060,
          1.3060,  1.5141,  1.7626,  1.5201,  2.2724,  1.5539,  5.2526,  1.6206,
          1.4471,  5.0573,  1.1077,  1.1871,  0.9743,  1.1546,  1.2891,  1.3224,
          1.2940,  1.3178,  1.3178,  1.2911,  1.0225,  1.3346,  1.3136,  1.1305,
          1.3473,  1.3780,  1.2964,  1.3265,  1.3118,  1.4635,  1.3770,  1.2869,
          1.2979,  1.4280,  1.3601,  0.4833,  1.3454,  1.0192,  1.3949,  1.3782,
          1.3551,  1.0413,  1.3783,  0.8580,  1.3463,  1.3543],
        [ 1.1815,  1.2081,  1.2612,  1.2423,  1.2151,  1.1872,  1.1941,  1.1798,
          1.1798,  1.2590,  1.2763,  1.2743,  1.2995,  1.2440,  1.3055,  1.2569,
          1.2367,  1.2066,  2.5056,  2.5856,  2.6919,  2.6291,  2.3972,  2.4910,
          2.5192,  2.3848,  2.3848,  1.2772,  1.2557,  1.2137,  1.2373,  1.2767,
          1.2240,  1.2540,  1.2183,  1.2162,  1.3702,  1.4101,  1.3879,  1.3664,
          1.3960,  1.3846,  1.3740,  1.2860,  1.3077,  1.2899,  1.2791,  1.2674,
          1.2472,  1.2507,  1.2670,  1.3206,  1.2399,  1.2455],
        [ 1.1826,  1.2104,  1.2497,  1.2303,  1.2177,  1.1886,  1.1961,  1.1809,
          1.1809,  1.2573,  1.2599,  1.2733,  1.2945,  1.2417,  1.2519,  1.2552,
          1.2437,  1.1554,  1.2310,  1.2538,  1.2706,  1.2436,  1.2062,  1.1942,
          1.2239,  1.1940,  1.1940,  2.7753,  2.5971,  2.2975,  2.4286,  2.7689,
          2.3084,  2.7236,  2.3073,  2.3000,  1.3567,  1.3984,  1.3685,  1.3587,
          1.3837,  1.3696,  1.3600,  1.2650,  1.3022,  1.3308,  1.2728,  1.1689,
          1.1988,  1.3208,  1.2457,  1.3631,  1.1912,  1.2435],
        [ 1.6778,  1.3616,  0.6188,  0.8183,  1.1767,  1.5698,  1.5093,  1.6748,
          1.6748,  1.5284,  1.2441,  1.3681,  0.9113,  1.6190,  0.2786,  1.5167,
          1.6373,  1.1193,  1.3077,  0.8826,  0.7762,  1.0986,  1.5444,  1.6055,
          1.3311,  1.6817,  1.6817,  0.7070,  0.8538,  1.6475,  1.4533,  0.7935,
          1.5873,  1.0837,  1.6986,  1.6214,  0.2675,  0.0451,  0.0216,  0.2269,
          0.4839,  0.6457,  0.1726, 10.4249,  7.5743,  0.7804,  1.1978,  1.2890,
          1.5110,  1.0113,  1.4523,  0.4460,  1.5628,  1.6755],
        [ 1.2410,  1.2724,  1.3348,  1.3136,  1.2816,  1.2477,  1.2127,  1.2390,
          1.2390,  1.2117,  1.3263,  1.2296,  1.3544,  1.2883,  1.4073,  1.2092,
          1.2909,  1.2300,  1.2931,  1.3244,  1.3384,  1.3067,  1.2649,  1.2556,
          1.2114,  1.2511,  1.2511,  1.3096,  1.3518,  1.2690,  1.0950,  1.2617,
          1.1465,  1.3158,  1.1430,  1.2719,  1.3636,  1.0651,  1.3847,  1.3727,
          0.9585,  0.8621,  1.3683,  1.3615,  0.7479,  2.9696,  2.4401,  3.0743,
          2.6681,  2.0807,  1.7846,  2.7794,  2.8893,  1.7645]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 160 : 180.4913283805165
Test loss for epoch 160 : 180.57836133504043
Test Precision for epoch 160 : 0.26153846153846155
Test Recall for epoch 160 : 0.26153846153846155
Test F1 for epoch 160 : 0.26153846153846155


theta for epoch 161 : tensor([[ 2.4426,  2.4722,  2.5456,  2.6437,  2.6067,  2.4487,  2.5830,  2.4408,
          2.4408,  1.2533,  1.2703,  1.2685,  1.2936,  1.2384,  1.3385,  1.2512,
          1.2405,  1.2227,  1.2221,  1.2052,  1.2166,  1.2341,  1.1984,  1.1912,
          1.2157,  1.1868,  1.1868,  1.2350,  1.2777,  1.2074,  1.2309,  1.2787,
          1.2177,  1.2472,  1.1681,  1.2099,  1.3672,  1.4068,  1.3848,  1.3745,
          1.3928,  1.3253,  1.3710,  1.3668,  1.3163,  1.3225,  1.2730,  1.2614,
          1.2413,  1.3130,  1.2608,  1.3532,  1.2342,  1.2397],
        [ 1.2641,  1.1747,  0.9935,  1.2168,  1.2934,  1.3150,  1.2389,  1.3060,
          1.3060,  1.5140,  1.7621,  1.5200,  2.2720,  1.5538,  5.2709,  1.6205,
          1.4470,  5.0770,  1.1076,  1.1871,  0.9744,  1.1545,  1.2890,  1.3224,
          1.2938,  1.3177,  1.3177,  1.2912,  1.0224,  1.3345,  1.3136,  1.1306,
          1.3472,  1.3780,  1.2963,  1.3267,  1.3117,  1.4634,  1.3767,  1.2866,
          1.2978,  1.4279,  1.3598,  0.4830,  1.3450,  1.0193,  1.3949,  1.3781,
          1.3550,  1.0412,  1.3783,  0.8583,  1.3461,  1.3542],
        [ 1.1812,  1.2078,  1.2608,  1.2420,  1.2148,  1.1869,  1.1939,  1.1795,
          1.1795,  1.2589,  1.2762,  1.2742,  1.2994,  1.2439,  1.3055,  1.2567,
          1.2364,  1.2070,  2.5095,  2.5901,  2.6961,  2.6331,  2.4014,  2.4952,
          2.5233,  2.3890,  2.3890,  1.2768,  1.2557,  1.2134,  1.2370,  1.2763,
          1.2237,  1.2537,  1.2180,  1.2159,  1.3702,  1.4102,  1.3879,  1.3663,
          1.3961,  1.3848,  1.3741,  1.2864,  1.3076,  1.2898,  1.2789,  1.2672,
          1.2469,  1.2509,  1.2667,  1.3205,  1.2396,  1.2452],
        [ 1.1824,  1.2101,  1.2499,  1.2305,  1.2175,  1.1884,  1.1958,  1.1806,
          1.1806,  1.2572,  1.2603,  1.2732,  1.2946,  1.2416,  1.2518,  1.2550,
          1.2435,  1.1561,  1.2308,  1.2537,  1.2703,  1.2433,  1.2059,  1.1941,
          1.2236,  1.1937,  1.1937,  2.7781,  2.6029,  2.3022,  2.4338,  2.7718,
          2.3132,  2.7265,  2.3120,  2.3048,  1.3568,  1.3986,  1.3688,  1.3590,
          1.3839,  1.3699,  1.3601,  1.2660,  1.3023,  1.3306,  1.2728,  1.1689,
          1.1986,  1.3206,  1.2462,  1.3629,  1.1910,  1.2434],
        [ 1.6784,  1.3622,  0.6194,  0.8188,  1.1773,  1.5704,  1.5099,  1.6753,
          1.6753,  1.5287,  1.2440,  1.3684,  0.9116,  1.6193,  0.2792,  1.5170,
          1.6377,  1.1189,  1.3083,  0.8833,  0.7768,  1.0992,  1.5450,  1.6058,
          1.3320,  1.6823,  1.6823,  0.7076,  0.8545,  1.6481,  1.4542,  0.7940,
          1.5879,  1.0840,  1.6992,  1.6218,  0.2657,  0.0432,  0.0200,  0.2250,
          0.4816,  0.6431,  0.1708, 10.4701,  7.5798,  0.7810,  1.1982,  1.2895,
          1.5114,  1.0118,  1.4522,  0.4466,  1.5634,  1.6758],
        [ 1.2408,  1.2722,  1.3346,  1.3134,  1.2814,  1.2475,  1.2125,  1.2388,
          1.2388,  1.2115,  1.3262,  1.2294,  1.3543,  1.2882,  1.4072,  1.2090,
          1.2907,  1.2299,  1.2929,  1.3242,  1.3382,  1.3065,  1.2647,  1.2554,
          1.2109,  1.2509,  1.2509,  1.3094,  1.3516,  1.2688,  1.0945,  1.2616,
          1.1463,  1.3156,  1.1427,  1.2717,  1.3635,  1.0646,  1.3845,  1.3725,
          0.9579,  0.8615,  1.3682,  1.3612,  0.7472,  2.9761,  2.4432,  3.0819,
          2.6722,  2.0825,  1.7861,  2.7838,  2.8958,  1.7660]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 161 : 180.4852005762739
Test loss for epoch 161 : 180.57310287962238
Test Precision for epoch 161 : 0.26153846153846155
Test Recall for epoch 161 : 0.26153846153846155
Test F1 for epoch 161 : 0.26153846153846155


theta for epoch 162 : tensor([[ 2.4465,  2.4761,  2.5496,  2.6482,  2.6112,  2.4526,  2.5874,  2.4447,
          2.4447,  1.2531,  1.2702,  1.2683,  1.2935,  1.2382,  1.3384,  1.2510,
          1.2404,  1.2226,  1.2219,  1.2050,  1.2164,  1.2339,  1.1982,  1.1910,
          1.2155,  1.1866,  1.1866,  1.2347,  1.2773,  1.2072,  1.2306,  1.2784,
          1.2174,  1.2470,  1.1678,  1.2097,  1.3672,  1.4069,  1.3848,  1.3746,
          1.3929,  1.3254,  1.3710,  1.3667,  1.3163,  1.3222,  1.2728,  1.2611,
          1.2411,  1.3128,  1.2606,  1.3530,  1.2340,  1.2394],
        [ 1.2640,  1.1746,  0.9936,  1.2168,  1.2936,  1.3149,  1.2389,  1.3059,
          1.3059,  1.5139,  1.7616,  1.5199,  2.2715,  1.5537,  5.2893,  1.6204,
          1.4469,  5.0967,  1.1075,  1.1871,  0.9745,  1.1544,  1.2890,  1.3223,
          1.2936,  1.3176,  1.3176,  1.2913,  1.0223,  1.3345,  1.3135,  1.1307,
          1.3471,  1.3781,  1.2962,  1.3268,  1.3116,  1.4632,  1.3764,  1.2862,
          1.2977,  1.4278,  1.3595,  0.4827,  1.3446,  1.0194,  1.3948,  1.3780,
          1.3548,  1.0411,  1.3783,  0.8586,  1.3459,  1.3541],
        [ 1.1809,  1.2075,  1.2605,  1.2417,  1.2145,  1.1866,  1.1936,  1.1792,
          1.1792,  1.2587,  1.2761,  1.2740,  1.2993,  1.2437,  1.3055,  1.2566,
          1.2361,  1.2073,  2.5133,  2.5946,  2.7003,  2.6369,  2.4055,  2.4994,
          2.5274,  2.3931,  2.3931,  1.2764,  1.2556,  1.2131,  1.2367,  1.2759,
          1.2235,  1.2535,  1.2178,  1.2157,  1.3702,  1.4103,  1.3879,  1.3662,
          1.3962,  1.3848,  1.3741,  1.2869,  1.3074,  1.2897,  1.2787,  1.2669,
          1.2467,  1.2511,  1.2665,  1.3204,  1.2393,  1.2450],
        [ 1.1821,  1.2098,  1.2500,  1.2307,  1.2172,  1.1881,  1.1956,  1.1804,
          1.1804,  1.2571,  1.2607,  1.2731,  1.2947,  1.2415,  1.2518,  1.2549,
          1.2434,  1.1568,  1.2305,  1.2536,  1.2701,  1.2431,  1.2057,  1.1940,
          1.2234,  1.1935,  1.1935,  2.7808,  2.6087,  2.3070,  2.4391,  2.7746,
          2.3179,  2.7294,  2.3167,  2.3095,  1.3569,  1.3988,  1.3691,  1.3592,
          1.3841,  1.3702,  1.3603,  1.2670,  1.3024,  1.3303,  1.2728,  1.1688,
          1.1985,  1.3203,  1.2466,  1.3626,  1.1908,  1.2432],
        [ 1.6789,  1.3628,  0.6199,  0.8193,  1.1778,  1.5709,  1.5105,  1.6758,
          1.6758,  1.5290,  1.2439,  1.3688,  0.9119,  1.6195,  0.2798,  1.5173,
          1.6381,  1.1185,  1.3089,  0.8839,  0.7773,  1.0997,  1.5456,  1.6061,
          1.3328,  1.6828,  1.6828,  0.7082,  0.8552,  1.6486,  1.4551,  0.7945,
          1.5885,  1.0844,  1.6998,  1.6222,  0.2639,  0.0415,  0.0184,  0.2232,
          0.4794,  0.6406,  0.1691, 10.5152,  7.5848,  0.7817,  1.1986,  1.2901,
          1.5118,  1.0122,  1.4522,  0.4471,  1.5640,  1.6762],
        [ 1.2406,  1.2720,  1.3344,  1.3132,  1.2812,  1.2473,  1.2123,  1.2386,
          1.2386,  1.2114,  1.3262,  1.2293,  1.3543,  1.2880,  1.4071,  1.2089,
          1.2906,  1.2298,  1.2928,  1.3241,  1.3380,  1.3064,  1.2646,  1.2553,
          1.2105,  1.2507,  1.2507,  1.3092,  1.3514,  1.2686,  1.0940,  1.2615,
          1.1462,  1.3155,  1.1425,  1.2716,  1.3633,  1.0640,  1.3844,  1.3724,
          0.9574,  0.8610,  1.3681,  1.3610,  0.7466,  2.9825,  2.4462,  3.0896,
          2.6763,  2.0844,  1.7875,  2.7882,  2.9022,  1.7673]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 162 : 180.47912889563815
Test loss for epoch 162 : 180.56793978584636
Test Precision for epoch 162 : 0.26153846153846155
Test Recall for epoch 162 : 0.26153846153846155
Test F1 for epoch 162 : 0.26153846153846155


theta for epoch 163 : tensor([[ 2.4504,  2.4801,  2.5535,  2.6526,  2.6156,  2.4565,  2.5919,  2.4486,
          2.4486,  1.2529,  1.2701,  1.2682,  1.2934,  1.2381,  1.3383,  1.2509,
          1.2402,  1.2225,  1.2216,  1.2047,  1.2161,  1.2337,  1.1980,  1.1908,
          1.2152,  1.1864,  1.1864,  1.2344,  1.2770,  1.2069,  1.2303,  1.2781,
          1.2171,  1.2467,  1.1675,  1.2094,  1.3672,  1.4070,  1.3848,  1.3746,
          1.3930,  1.3255,  1.3711,  1.3666,  1.3163,  1.3220,  1.2726,  1.2609,
          1.2409,  1.3126,  1.2604,  1.3527,  1.2337,  1.2392],
        [ 1.2640,  1.1746,  0.9937,  1.2169,  1.2938,  1.3149,  1.2388,  1.3058,
          1.3058,  1.5138,  1.7611,  1.5198,  2.2710,  1.5536,  5.3076,  1.6203,
          1.4468,  5.1163,  1.1074,  1.1871,  0.9747,  1.1543,  1.2889,  1.3223,
          1.2934,  1.3176,  1.3176,  1.2913,  1.0222,  1.3344,  1.3135,  1.1307,
          1.3471,  1.3782,  1.2962,  1.3270,  1.3116,  1.4631,  1.3761,  1.2859,
          1.2976,  1.4277,  1.3592,  0.4824,  1.3441,  1.0194,  1.3948,  1.3779,
          1.3547,  1.0410,  1.3783,  0.8589,  1.3458,  1.3540],
        [ 1.1806,  1.2072,  1.2602,  1.2414,  1.2142,  1.1864,  1.1933,  1.1790,
          1.1790,  1.2585,  1.2760,  1.2738,  1.2991,  1.2435,  1.3055,  1.2564,
          1.2358,  1.2076,  2.5171,  2.5990,  2.7044,  2.6408,  2.4096,  2.5035,
          2.5315,  2.3972,  2.3972,  1.2760,  1.2555,  1.2128,  1.2364,  1.2755,
          1.2231,  1.2532,  1.2175,  1.2154,  1.3702,  1.4104,  1.3879,  1.3661,
          1.3962,  1.3849,  1.3741,  1.2873,  1.3073,  1.2896,  1.2784,  1.2666,
          1.2464,  1.2513,  1.2663,  1.3204,  1.2391,  1.2447],
        [ 1.1819,  1.2096,  1.2502,  1.2309,  1.2170,  1.1879,  1.1953,  1.1802,
          1.1802,  1.2570,  1.2611,  1.2730,  1.2948,  1.2414,  1.2517,  1.2548,
          1.2433,  1.1574,  1.2303,  1.2535,  1.2698,  1.2429,  1.2055,  1.1940,
          1.2232,  1.1933,  1.1933,  2.7836,  2.6145,  2.3117,  2.4443,  2.7774,
          2.3226,  2.7323,  2.3214,  2.3142,  1.3570,  1.3989,  1.3694,  1.3595,
          1.3843,  1.3705,  1.3604,  1.2679,  1.3025,  1.3301,  1.2728,  1.1687,
          1.1983,  1.3201,  1.2471,  1.3624,  1.1906,  1.2430],
        [ 1.6794,  1.3634,  0.6205,  0.8197,  1.1783,  1.5715,  1.5111,  1.6763,
          1.6763,  1.5292,  1.2438,  1.3691,  0.9121,  1.6197,  0.2803,  1.5176,
          1.6384,  1.1181,  1.3094,  0.8845,  0.7779,  1.1002,  1.5462,  1.6064,
          1.3337,  1.6833,  1.6833,  0.7087,  0.8559,  1.6492,  1.4559,  0.7951,
          1.5890,  1.0847,  1.7003,  1.6226,  0.2622,  0.0397,  0.0169,  0.2215,
          0.4773,  0.6382,  0.1673, 10.5603,  7.5895,  0.7823,  1.1990,  1.2907,
          1.5122,  1.0126,  1.4522,  0.4476,  1.5646,  1.6765],
        [ 1.2404,  1.2719,  1.3343,  1.3131,  1.2811,  1.2472,  1.2121,  1.2384,
          1.2384,  1.2112,  1.3261,  1.2292,  1.3542,  1.2879,  1.4071,  1.2088,
          1.2904,  1.2297,  1.2926,  1.3239,  1.3379,  1.3063,  1.2644,  1.2552,
          1.2101,  1.2506,  1.2506,  1.3090,  1.3512,  1.2684,  1.0935,  1.2614,
          1.1460,  1.3154,  1.1423,  1.2714,  1.3632,  1.0635,  1.3842,  1.3723,
          0.9569,  0.8604,  1.3680,  1.3607,  0.7459,  2.9888,  2.4491,  3.0971,
          2.6804,  2.0861,  1.7889,  2.7925,  2.9086,  1.7687]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 163 : 180.4731121520649
Test loss for epoch 163 : 180.56284153647323
Test Precision for epoch 163 : 0.26153846153846155
Test Recall for epoch 163 : 0.26153846153846155
Test F1 for epoch 163 : 0.26153846153846155


theta for epoch 164 : tensor([[ 2.4542,  2.4839,  2.5574,  2.6570,  2.6200,  2.4603,  2.5962,  2.4524,
          2.4524,  1.2528,  1.2700,  1.2680,  1.2933,  1.2379,  1.3382,  1.2507,
          1.2400,  1.2224,  1.2214,  1.2045,  1.2159,  1.2334,  1.1977,  1.1906,
          1.2150,  1.1862,  1.1862,  1.2341,  1.2767,  1.2066,  1.2300,  1.2778,
          1.2168,  1.2465,  1.1672,  1.2091,  1.3673,  1.4071,  1.3849,  1.3747,
          1.3932,  1.3255,  1.3711,  1.3666,  1.3164,  1.3218,  1.2724,  1.2607,
          1.2407,  1.3124,  1.2603,  1.3525,  1.2335,  1.2390],
        [ 1.2639,  1.1746,  0.9938,  1.2169,  1.2939,  1.3148,  1.2388,  1.3057,
          1.3057,  1.5136,  1.7605,  1.5197,  2.2704,  1.5534,  5.3259,  1.6202,
          1.4467,  5.1358,  1.1073,  1.1871,  0.9748,  1.1542,  1.2889,  1.3223,
          1.2932,  1.3175,  1.3175,  1.2914,  1.0220,  1.3343,  1.3134,  1.1307,
          1.3470,  1.3782,  1.2961,  1.3271,  1.3115,  1.4629,  1.3758,  1.2856,
          1.2975,  1.4276,  1.3589,  0.4822,  1.3437,  1.0196,  1.3948,  1.3778,
          1.3546,  1.0409,  1.3783,  0.8592,  1.3456,  1.3539],
        [ 1.1803,  1.2069,  1.2598,  1.2411,  1.2139,  1.1861,  1.1930,  1.1787,
          1.1787,  1.2583,  1.2758,  1.2737,  1.2990,  1.2433,  1.3056,  1.2562,
          1.2355,  1.2080,  2.5209,  2.6034,  2.7085,  2.6446,  2.4137,  2.5076,
          2.5356,  2.4013,  2.4013,  1.2755,  1.2554,  1.2125,  1.2360,  1.2750,
          1.2228,  1.2529,  1.2171,  1.2150,  1.3703,  1.4105,  1.3880,  1.3660,
          1.3963,  1.3850,  1.3742,  1.2878,  1.3072,  1.2896,  1.2782,  1.2664,
          1.2462,  1.2516,  1.2661,  1.3203,  1.2388,  1.2445],
        [ 1.1817,  1.2093,  1.2503,  1.2310,  1.2167,  1.1876,  1.1951,  1.1799,
          1.1799,  1.2569,  1.2615,  1.2729,  1.2949,  1.2412,  1.2516,  1.2547,
          1.2431,  1.1581,  1.2301,  1.2534,  1.2696,  1.2427,  1.2053,  1.1939,
          1.2229,  1.1931,  1.1931,  2.7863,  2.6202,  2.3163,  2.4495,  2.7802,
          2.3273,  2.7351,  2.3260,  2.3189,  1.3571,  1.3991,  1.3697,  1.3598,
          1.3845,  1.3707,  1.3606,  1.2689,  1.3026,  1.3299,  1.2728,  1.1687,
          1.1982,  1.3200,  1.2475,  1.3622,  1.1905,  1.2429],
        [ 1.6799,  1.3639,  0.6210,  0.8202,  1.1788,  1.5720,  1.5116,  1.6769,
          1.6769,  1.5295,  1.2437,  1.3694,  0.9124,  1.6200,  0.2809,  1.5178,
          1.6387,  1.1177,  1.3099,  0.8852,  0.7784,  1.1007,  1.5467,  1.6067,
          1.3345,  1.6839,  1.6839,  0.7092,  0.8565,  1.6497,  1.4567,  0.7956,
          1.5895,  1.0850,  1.7009,  1.6229,  0.2605,  0.0380,  0.0154,  0.2197,
          0.4752,  0.6359,  0.1656, 10.6052,  7.5937,  0.7829,  1.1994,  1.2913,
          1.5126,  1.0130,  1.4522,  0.4482,  1.5652,  1.6769],
        [ 1.2402,  1.2717,  1.3341,  1.3129,  1.2809,  1.2470,  1.2119,  1.2382,
          1.2382,  1.2111,  1.3261,  1.2291,  1.3542,  1.2878,  1.4070,  1.2086,
          1.2903,  1.2297,  1.2925,  1.3238,  1.3377,  1.3062,  1.2643,  1.2551,
          1.2096,  1.2504,  1.2504,  1.3089,  1.3510,  1.2682,  1.0930,  1.2612,
          1.1459,  1.3153,  1.1421,  1.2712,  1.3631,  1.0630,  1.3841,  1.3722,
          0.9564,  0.8599,  1.3679,  1.3605,  0.7453,  2.9952,  2.4520,  3.1047,
          2.6844,  2.0879,  1.7904,  2.7968,  2.9150,  1.7701]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 164 : 180.46714880539596
Test loss for epoch 164 : 180.5577902788723
Test Precision for epoch 164 : 0.26153846153846155
Test Recall for epoch 164 : 0.26153846153846155
Test F1 for epoch 164 : 0.26153846153846155


theta for epoch 165 : tensor([[ 2.4581,  2.4878,  2.5613,  2.6614,  2.6244,  2.4642,  2.6006,  2.4563,
          2.4563,  1.2526,  1.2700,  1.2679,  1.2932,  1.2378,  1.3380,  1.2506,
          1.2399,  1.2223,  1.2212,  1.2042,  1.2156,  1.2332,  1.1975,  1.1904,
          1.2148,  1.1859,  1.1859,  1.2338,  1.2763,  1.2063,  1.2297,  1.2775,
          1.2165,  1.2462,  1.1669,  1.2088,  1.3673,  1.4072,  1.3849,  1.3748,
          1.3933,  1.3256,  1.3712,  1.3665,  1.3164,  1.3215,  1.2722,  1.2604,
          1.2405,  1.3122,  1.2601,  1.3523,  1.2332,  1.2388],
        [ 1.2639,  1.1746,  0.9939,  1.2170,  1.2941,  1.3148,  1.2388,  1.3057,
          1.3057,  1.5134,  1.7599,  1.5196,  2.2697,  1.5532,  5.3441,  1.6200,
          1.4466,  5.1553,  1.1072,  1.1872,  0.9749,  1.1541,  1.2889,  1.3223,
          1.2929,  1.3174,  1.3174,  1.2914,  1.0219,  1.3343,  1.3133,  1.1308,
          1.3469,  1.3783,  1.2960,  1.3272,  1.3114,  1.4628,  1.3755,  1.2854,
          1.2975,  1.4275,  1.3586,  0.4820,  1.3433,  1.0197,  1.3947,  1.3777,
          1.3545,  1.0408,  1.3783,  0.8596,  1.3454,  1.3538],
        [ 1.1801,  1.2066,  1.2595,  1.2408,  1.2136,  1.1858,  1.1927,  1.1784,
          1.1784,  1.2581,  1.2757,  1.2735,  1.2989,  1.2432,  1.3056,  1.2560,
          1.2352,  1.2084,  2.5246,  2.6078,  2.7126,  2.6483,  2.4178,  2.5117,
          2.5396,  2.4054,  2.4054,  1.2751,  1.2554,  1.2122,  1.2357,  1.2746,
          1.2225,  1.2526,  1.2168,  1.2148,  1.3703,  1.4106,  1.3880,  1.3659,
          1.3964,  1.3851,  1.3742,  1.2882,  1.3070,  1.2895,  1.2780,  1.2661,
          1.2460,  1.2519,  1.2659,  1.3203,  1.2385,  1.2443],
        [ 1.1814,  1.2091,  1.2504,  1.2312,  1.2164,  1.1874,  1.1948,  1.1797,
          1.1797,  1.2567,  1.2618,  1.2727,  1.2949,  1.2411,  1.2515,  1.2545,
          1.2430,  1.1587,  1.2298,  1.2532,  1.2693,  1.2424,  1.2050,  1.1938,
          1.2227,  1.1928,  1.1928,  2.7890,  2.6259,  2.3209,  2.4546,  2.7830,
          2.3319,  2.7379,  2.3305,  2.3235,  1.3572,  1.3993,  1.3700,  1.3601,
          1.3847,  1.3710,  1.3607,  1.2697,  1.3027,  1.3296,  1.2728,  1.1686,
          1.1980,  1.3197,  1.2479,  1.3619,  1.1903,  1.2427],
        [ 1.6804,  1.3645,  0.6215,  0.8207,  1.1793,  1.5726,  1.5122,  1.6774,
          1.6774,  1.5298,  1.2437,  1.3698,  0.9127,  1.6202,  0.2815,  1.5181,
          1.6391,  1.1173,  1.3105,  0.8858,  0.7789,  1.1012,  1.5473,  1.6070,
          1.3353,  1.6844,  1.6844,  0.7098,  0.8572,  1.6502,  1.4576,  0.7961,
          1.5900,  1.0854,  1.7014,  1.6233,  0.2588,  0.0363,  0.0139,  0.2180,
          0.4731,  0.6335,  0.1640, 10.6500,  7.5975,  0.7835,  1.1999,  1.2919,
          1.5129,  1.0134,  1.4522,  0.4487,  1.5658,  1.6772],
        [ 1.2401,  1.2715,  1.3339,  1.3127,  1.2807,  1.2468,  1.2118,  1.2381,
          1.2381,  1.2110,  1.3261,  1.2290,  1.3541,  1.2876,  1.4070,  1.2085,
          1.2902,  1.2296,  1.2924,  1.3236,  1.3376,  1.3060,  1.2641,  1.2549,
          1.2092,  1.2503,  1.2503,  1.3087,  1.3508,  1.2680,  1.0925,  1.2611,
          1.1457,  1.3152,  1.1419,  1.2710,  1.3630,  1.0625,  1.3839,  1.3722,
          0.9559,  0.8594,  1.3678,  1.3602,  0.7447,  3.0015,  2.4549,  3.1122,
          2.6884,  2.0897,  1.7917,  2.8010,  2.9213,  1.7714]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 165 : 180.46123694682657
Test loss for epoch 165 : 180.55279781275618
Test Precision for epoch 165 : 0.26153846153846155
Test Recall for epoch 165 : 0.26153846153846155
Test F1 for epoch 165 : 0.26153846153846155


theta for epoch 166 : tensor([[ 2.4618,  2.4916,  2.5651,  2.6658,  2.6288,  2.4680,  2.6049,  2.4601,
          2.4601,  1.2525,  1.2699,  1.2678,  1.2931,  1.2377,  1.3379,  1.2504,
          1.2397,  1.2222,  1.2210,  1.2040,  1.2154,  1.2330,  1.1973,  1.1902,
          1.2146,  1.1857,  1.1857,  1.2335,  1.2760,  1.2061,  1.2294,  1.2773,
          1.2163,  1.2460,  1.1667,  1.2086,  1.3673,  1.4073,  1.3849,  1.3748,
          1.3934,  1.3257,  1.3712,  1.3665,  1.3164,  1.3213,  1.2720,  1.2602,
          1.2403,  1.3119,  1.2599,  1.3520,  1.2330,  1.2386],
        [ 1.2638,  1.1746,  0.9940,  1.2170,  1.2943,  1.3147,  1.2387,  1.3057,
          1.3057,  1.5132,  1.7593,  1.5194,  2.2690,  1.5530,  5.3623,  1.6198,
          1.4464,  5.1747,  1.1071,  1.1872,  0.9751,  1.1540,  1.2889,  1.3223,
          1.2928,  1.3174,  1.3174,  1.2915,  1.0218,  1.3342,  1.3133,  1.1308,
          1.3469,  1.3784,  1.2959,  1.3274,  1.3114,  1.4626,  1.3753,  1.2851,
          1.2974,  1.4274,  1.3584,  0.4817,  1.3429,  1.0197,  1.3947,  1.3776,
          1.3544,  1.0407,  1.3783,  0.8599,  1.3452,  1.3537],
        [ 1.1797,  1.2063,  1.2591,  1.2404,  1.2132,  1.1855,  1.1924,  1.1781,
          1.1781,  1.2580,  1.2756,  1.2734,  1.2988,  1.2430,  1.3057,  1.2559,
          1.2349,  1.2087,  2.5283,  2.6122,  2.7166,  2.6520,  2.4219,  2.5157,
          2.5436,  2.4094,  2.4094,  1.2747,  1.2553,  1.2119,  1.2354,  1.2742,
          1.2222,  1.2524,  1.2165,  1.2145,  1.3703,  1.4107,  1.3880,  1.3658,
          1.3965,  1.3852,  1.3742,  1.2887,  1.3069,  1.2894,  1.2777,  1.2658,
          1.2457,  1.2521,  1.2656,  1.3202,  1.2382,  1.2440],
        [ 1.1811,  1.2088,  1.2505,  1.2313,  1.2161,  1.1871,  1.1945,  1.1794,
          1.1794,  1.2566,  1.2622,  1.2726,  1.2950,  1.2410,  1.2515,  1.2544,
          1.2429,  1.1593,  1.2296,  1.2531,  1.2690,  1.2422,  1.2048,  1.1937,
          1.2224,  1.1926,  1.1926,  2.7917,  2.6315,  2.3255,  2.4597,  2.7857,
          2.3365,  2.7407,  2.3351,  2.3281,  1.3573,  1.3995,  1.3703,  1.3604,
          1.3848,  1.3712,  1.3609,  1.2706,  1.3028,  1.3294,  1.2727,  1.1685,
          1.1979,  1.3195,  1.2483,  1.3617,  1.1901,  1.2425],
        [ 1.6809,  1.3651,  0.6221,  0.8212,  1.1798,  1.5731,  1.5127,  1.6779,
          1.6779,  1.5300,  1.2436,  1.3701,  0.9129,  1.6204,  0.2820,  1.5184,
          1.6394,  1.1169,  1.3110,  0.8864,  0.7795,  1.1017,  1.5478,  1.6073,
          1.3362,  1.6849,  1.6849,  0.7104,  0.8578,  1.6507,  1.4584,  0.7966,
          1.5905,  1.0857,  1.7020,  1.6237,  0.2572,  0.0346,  0.0124,  0.2163,
          0.4710,  0.6313,  0.1623, 10.6946,  7.6009,  0.7841,  1.2002,  1.2924,
          1.5133,  1.0137,  1.4522,  0.4492,  1.5663,  1.6776],
        [ 1.2399,  1.2713,  1.3337,  1.3126,  1.2805,  1.2466,  1.2116,  1.2379,
          1.2379,  1.2109,  1.3260,  1.2289,  1.3541,  1.2875,  1.4069,  1.2084,
          1.2900,  1.2295,  1.2922,  1.3235,  1.3374,  1.3059,  1.2640,  1.2548,
          1.2088,  1.2501,  1.2501,  1.3085,  1.3506,  1.2678,  1.0920,  1.2610,
          1.1456,  1.3150,  1.1417,  1.2708,  1.3628,  1.0621,  1.3838,  1.3721,
          0.9554,  0.8589,  1.3677,  1.3600,  0.7442,  3.0078,  2.4577,  3.1197,
          2.6923,  2.0914,  1.7931,  2.8052,  2.9276,  1.7728]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 166 : 180.45537537197626
Test loss for epoch 166 : 180.54786674592998
Test Precision for epoch 166 : 0.26153846153846155
Test Recall for epoch 166 : 0.26153846153846155
Test F1 for epoch 166 : 0.26153846153846155


theta for epoch 167 : tensor([[ 2.4656,  2.4954,  2.5689,  2.6701,  2.6331,  2.4718,  2.6093,  2.4639,
          2.4639,  1.2524,  1.2698,  1.2676,  1.2930,  1.2375,  1.3378,  1.2503,
          1.2396,  1.2220,  1.2207,  1.2036,  1.2150,  1.2327,  1.1970,  1.1899,
          1.2143,  1.1854,  1.1854,  1.2332,  1.2757,  1.2058,  1.2291,  1.2770,
          1.2160,  1.2458,  1.1664,  1.2083,  1.3674,  1.4074,  1.3850,  1.3749,
          1.3935,  1.3258,  1.3713,  1.3664,  1.3165,  1.3210,  1.2718,  1.2599,
          1.2401,  1.3117,  1.2597,  1.3518,  1.2327,  1.2384],
        [ 1.2638,  1.1747,  0.9942,  1.2171,  1.2945,  1.3147,  1.2387,  1.3056,
          1.3056,  1.5130,  1.7586,  1.5192,  2.2682,  1.5528,  5.3804,  1.6196,
          1.4462,  5.1941,  1.1070,  1.1872,  0.9752,  1.1539,  1.2888,  1.3222,
          1.2925,  1.3173,  1.3173,  1.2915,  1.0217,  1.3342,  1.3133,  1.1308,
          1.3468,  1.3784,  1.2959,  1.3275,  1.3114,  1.4625,  1.3750,  1.2848,
          1.2974,  1.4273,  1.3581,  0.4815,  1.3425,  1.0198,  1.3947,  1.3775,
          1.3542,  1.0406,  1.3782,  0.8602,  1.3450,  1.3536],
        [ 1.1795,  1.2061,  1.2588,  1.2402,  1.2130,  1.1853,  1.1922,  1.1779,
          1.1779,  1.2578,  1.2755,  1.2732,  1.2987,  1.2428,  1.3057,  1.2557,
          1.2346,  1.2091,  2.5319,  2.6165,  2.7205,  2.6556,  2.4259,  2.5197,
          2.5476,  2.4134,  2.4134,  1.2743,  1.2553,  1.2117,  1.2351,  1.2738,
          1.2219,  1.2521,  1.2163,  1.2142,  1.3703,  1.4108,  1.3880,  1.3657,
          1.3966,  1.3853,  1.3743,  1.2892,  1.3068,  1.2893,  1.2775,  1.2656,
          1.2455,  1.2524,  1.2654,  1.3202,  1.2380,  1.2438],
        [ 1.1809,  1.2085,  1.2507,  1.2314,  1.2159,  1.1869,  1.1943,  1.1792,
          1.1792,  1.2565,  1.2625,  1.2725,  1.2951,  1.2409,  1.2514,  1.2543,
          1.2427,  1.1599,  1.2294,  1.2529,  1.2688,  1.2420,  1.2046,  1.1936,
          1.2222,  1.1924,  1.1924,  2.7944,  2.6371,  2.3301,  2.4647,  2.7885,
          2.3410,  2.7435,  2.3395,  2.3326,  1.3574,  1.3997,  1.3706,  1.3606,
          1.3850,  1.3715,  1.3610,  1.2714,  1.3029,  1.3291,  1.2727,  1.1685,
          1.1977,  1.3193,  1.2486,  1.3614,  1.1899,  1.2423],
        [ 1.6814,  1.3657,  0.6226,  0.8217,  1.1803,  1.5736,  1.5132,  1.6784,
          1.6784,  1.5303,  1.2435,  1.3704,  0.9132,  1.6206,  0.2826,  1.5186,
          1.6398,  1.1165,  1.3115,  0.8870,  0.7799,  1.1022,  1.5483,  1.6075,
          1.3370,  1.6854,  1.6854,  0.7109,  0.8585,  1.6513,  1.4592,  0.7971,
          1.5910,  1.0860,  1.7025,  1.6240,  0.2556,  0.0330,  0.0110,  0.2146,
          0.4690,  0.6290,  0.1607, 10.7392,  7.6039,  0.7847,  1.2006,  1.2930,
          1.5137,  1.0140,  1.4523,  0.4497,  1.5669,  1.6779],
        [ 1.2397,  1.2712,  1.3335,  1.3124,  1.2804,  1.2465,  1.2114,  1.2377,
          1.2377,  1.2107,  1.3260,  1.2288,  1.3541,  1.2874,  1.4069,  1.2083,
          1.2899,  1.2294,  1.2921,  1.3233,  1.3373,  1.3058,  1.2638,  1.2547,
          1.2083,  1.2499,  1.2499,  1.3083,  1.3504,  1.2676,  1.0915,  1.2609,
          1.1455,  1.3149,  1.1415,  1.2706,  1.3627,  1.0616,  1.3837,  1.3720,
          0.9549,  0.8584,  1.3676,  1.3598,  0.7436,  3.0141,  2.4605,  3.1272,
          2.6962,  2.0932,  1.7945,  2.8093,  2.9338,  1.7741]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 167 : 180.44956213675994
Test loss for epoch 167 : 180.54298371878585
Test Precision for epoch 167 : 0.26153846153846155
Test Recall for epoch 167 : 0.26153846153846155
Test F1 for epoch 167 : 0.26153846153846155


theta for epoch 168 : tensor([[2.4693e+00, 2.4991e+00, 2.5726e+00, 2.6743e+00, 2.6373e+00, 2.4754e+00,
         2.6135e+00, 2.4675e+00, 2.4675e+00, 1.2522e+00, 1.2697e+00, 1.2675e+00,
         1.2929e+00, 1.2374e+00, 1.3377e+00, 1.2502e+00, 1.2395e+00, 1.2219e+00,
         1.2206e+00, 1.2034e+00, 1.2148e+00, 1.2326e+00, 1.1969e+00, 1.1898e+00,
         1.2141e+00, 1.1853e+00, 1.1853e+00, 1.2330e+00, 1.2754e+00, 1.2056e+00,
         1.2288e+00, 1.2767e+00, 1.2158e+00, 1.2456e+00, 1.1661e+00, 1.2081e+00,
         1.3674e+00, 1.4075e+00, 1.3850e+00, 1.3750e+00, 1.3936e+00, 1.3258e+00,
         1.3714e+00, 1.3664e+00, 1.3165e+00, 1.3208e+00, 1.2716e+00, 1.2597e+00,
         1.2399e+00, 1.3115e+00, 1.2595e+00, 1.3516e+00, 1.2325e+00, 1.2382e+00],
        [1.2638e+00, 1.1746e+00, 9.9427e-01, 1.2171e+00, 1.2946e+00, 1.3146e+00,
         1.2387e+00, 1.3056e+00, 1.3056e+00, 1.5128e+00, 1.7580e+00, 1.5190e+00,
         2.2674e+00, 1.5525e+00, 5.3985e+00, 1.6194e+00, 1.4461e+00, 5.2134e+00,
         1.1070e+00, 1.1873e+00, 9.7544e-01, 1.1539e+00, 1.2888e+00, 1.3223e+00,
         1.2924e+00, 1.3173e+00, 1.3173e+00, 1.2916e+00, 1.0216e+00, 1.3341e+00,
         1.3132e+00, 1.1309e+00, 1.3468e+00, 1.3785e+00, 1.2958e+00, 1.3276e+00,
         1.3113e+00, 1.4624e+00, 1.3747e+00, 1.2846e+00, 1.2973e+00, 1.4272e+00,
         1.3578e+00, 4.8134e-01, 1.3421e+00, 1.0199e+00, 1.3946e+00, 1.3774e+00,
         1.3541e+00, 1.0406e+00, 1.3783e+00, 8.6053e-01, 1.3449e+00, 1.3535e+00],
        [1.1792e+00, 1.2057e+00, 1.2584e+00, 1.2397e+00, 1.2126e+00, 1.1849e+00,
         1.1918e+00, 1.1775e+00, 1.1775e+00, 1.2576e+00, 1.2754e+00, 1.2730e+00,
         1.2985e+00, 1.2426e+00, 1.3058e+00, 1.2555e+00, 1.2343e+00, 1.2095e+00,
         2.5356e+00, 2.6209e+00, 2.7245e+00, 2.6592e+00, 2.4299e+00, 2.5237e+00,
         2.5516e+00, 2.4175e+00, 2.4175e+00, 1.2739e+00, 1.2552e+00, 1.2114e+00,
         1.2347e+00, 1.2734e+00, 1.2216e+00, 1.2519e+00, 1.2160e+00, 1.2139e+00,
         1.3703e+00, 1.4108e+00, 1.3880e+00, 1.3656e+00, 1.3967e+00, 1.3854e+00,
         1.3743e+00, 1.2897e+00, 1.3066e+00, 1.2893e+00, 1.2773e+00, 1.2653e+00,
         1.2453e+00, 1.2526e+00, 1.2652e+00, 1.3201e+00, 1.2377e+00, 1.2436e+00],
        [1.1807e+00, 1.2083e+00, 1.2508e+00, 1.2315e+00, 1.2157e+00, 1.1866e+00,
         1.1941e+00, 1.1790e+00, 1.1790e+00, 1.2564e+00, 1.2629e+00, 1.2724e+00,
         1.2951e+00, 1.2408e+00, 1.2514e+00, 1.2542e+00, 1.2426e+00, 1.1605e+00,
         1.2292e+00, 1.2529e+00, 1.2686e+00, 1.2418e+00, 1.2044e+00, 1.1936e+00,
         1.2220e+00, 1.1922e+00, 1.1922e+00, 2.7970e+00, 2.6427e+00, 2.3345e+00,
         2.4697e+00, 2.7911e+00, 2.3455e+00, 2.7462e+00, 2.3440e+00, 2.3371e+00,
         1.3575e+00, 1.3998e+00, 1.3709e+00, 1.3609e+00, 1.3852e+00, 1.3717e+00,
         1.3612e+00, 1.2723e+00, 1.3031e+00, 1.3289e+00, 1.2727e+00, 1.1684e+00,
         1.1976e+00, 1.3191e+00, 1.2490e+00, 1.3612e+00, 1.1898e+00, 1.2421e+00],
        [1.6819e+00, 1.3662e+00, 6.2310e-01, 8.2211e-01, 1.1807e+00, 1.5741e+00,
         1.5137e+00, 1.6788e+00, 1.6788e+00, 1.5306e+00, 1.2435e+00, 1.3707e+00,
         9.1339e-01, 1.6208e+00, 2.8309e-01, 1.5189e+00, 1.6401e+00, 1.1161e+00,
         1.3120e+00, 8.8754e-01, 7.8043e-01, 1.1027e+00, 1.5489e+00, 1.6078e+00,
         1.3378e+00, 1.6859e+00, 1.6859e+00, 7.1147e-01, 8.5907e-01, 1.6518e+00,
         1.4600e+00, 7.9765e-01, 1.5915e+00, 1.0864e+00, 1.7030e+00, 1.6244e+00,
         2.5401e-01, 3.1389e-02, 9.5828e-03, 2.1297e-01, 4.6706e-01, 6.2685e-01,
         1.5911e-01, 1.0784e+01, 7.6065e+00, 7.8524e-01, 1.2010e+00, 1.2935e+00,
         1.5140e+00, 1.0144e+00, 1.4523e+00, 4.5014e-01, 1.5675e+00, 1.6782e+00],
        [1.2395e+00, 1.2709e+00, 1.3333e+00, 1.3122e+00, 1.2802e+00, 1.2462e+00,
         1.2112e+00, 1.2375e+00, 1.2375e+00, 1.2106e+00, 1.3259e+00, 1.2286e+00,
         1.3540e+00, 1.2872e+00, 1.4068e+00, 1.2081e+00, 1.2897e+00, 1.2294e+00,
         1.2920e+00, 1.3231e+00, 1.3371e+00, 1.3057e+00, 1.2637e+00, 1.2546e+00,
         1.2079e+00, 1.2498e+00, 1.2498e+00, 1.3081e+00, 1.3502e+00, 1.2675e+00,
         1.0910e+00, 1.2607e+00, 1.1453e+00, 1.3148e+00, 1.1413e+00, 1.2705e+00,
         1.3626e+00, 1.0611e+00, 1.3835e+00, 1.3719e+00, 9.5439e-01, 8.5785e-01,
         1.3675e+00, 1.3596e+00, 7.4302e-01, 3.0203e+00, 2.4633e+00, 3.1347e+00,
         2.7001e+00, 2.0949e+00, 1.7958e+00, 2.8135e+00, 2.9401e+00, 1.7754e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 168 : 180.44379616356525
Test loss for epoch 168 : 180.5381516807649
Test Precision for epoch 168 : 0.26153846153846155
Test Recall for epoch 168 : 0.26153846153846155
Test F1 for epoch 168 : 0.26153846153846155


theta for epoch 169 : tensor([[2.4731e+00, 2.5029e+00, 2.5764e+00, 2.6787e+00, 2.6417e+00, 2.4792e+00,
         2.6178e+00, 2.4713e+00, 2.4713e+00, 1.2521e+00, 1.2696e+00, 1.2674e+00,
         1.2928e+00, 1.2372e+00, 1.3376e+00, 1.2500e+00, 1.2393e+00, 1.2218e+00,
         1.2202e+00, 1.2031e+00, 1.2145e+00, 1.2323e+00, 1.1965e+00, 1.1895e+00,
         1.2138e+00, 1.1850e+00, 1.1850e+00, 1.2327e+00, 1.2751e+00, 1.2053e+00,
         1.2285e+00, 1.2764e+00, 1.2155e+00, 1.2453e+00, 1.1658e+00, 1.2078e+00,
         1.3674e+00, 1.4076e+00, 1.3850e+00, 1.3750e+00, 1.3937e+00, 1.3259e+00,
         1.3714e+00, 1.3663e+00, 1.3165e+00, 1.3206e+00, 1.2714e+00, 1.2595e+00,
         1.2397e+00, 1.3113e+00, 1.2593e+00, 1.3513e+00, 1.2322e+00, 1.2380e+00],
        [1.2638e+00, 1.1747e+00, 9.9448e-01, 1.2173e+00, 1.2949e+00, 1.3147e+00,
         1.2387e+00, 1.3056e+00, 1.3056e+00, 1.5126e+00, 1.7573e+00, 1.5188e+00,
         2.2666e+00, 1.5523e+00, 5.4166e+00, 1.6192e+00, 1.4459e+00, 5.2327e+00,
         1.1068e+00, 1.1873e+00, 9.7557e-01, 1.1538e+00, 1.2888e+00, 1.3222e+00,
         1.2921e+00, 1.3173e+00, 1.3173e+00, 1.2916e+00, 1.0215e+00, 1.3341e+00,
         1.3132e+00, 1.1309e+00, 1.3467e+00, 1.3786e+00, 1.2957e+00, 1.3278e+00,
         1.3113e+00, 1.4622e+00, 1.3744e+00, 1.2843e+00, 1.2973e+00, 1.4271e+00,
         1.3576e+00, 4.8115e-01, 1.3417e+00, 1.0200e+00, 1.3946e+00, 1.3773e+00,
         1.3540e+00, 1.0405e+00, 1.3782e+00, 8.6087e-01, 1.3447e+00, 1.3535e+00],
        [1.1790e+00, 1.2055e+00, 1.2582e+00, 1.2396e+00, 1.2125e+00, 1.1847e+00,
         1.1917e+00, 1.1774e+00, 1.1774e+00, 1.2575e+00, 1.2753e+00, 1.2729e+00,
         1.2984e+00, 1.2425e+00, 1.3058e+00, 1.2554e+00, 1.2340e+00, 1.2099e+00,
         2.5391e+00, 2.6251e+00, 2.7283e+00, 2.6626e+00, 2.4338e+00, 2.5276e+00,
         2.5554e+00, 2.4214e+00, 2.4214e+00, 1.2735e+00, 1.2552e+00, 1.2111e+00,
         1.2344e+00, 1.2730e+00, 1.2214e+00, 1.2516e+00, 1.2157e+00, 1.2136e+00,
         1.3703e+00, 1.4109e+00, 1.3880e+00, 1.3655e+00, 1.3968e+00, 1.3855e+00,
         1.3743e+00, 1.2902e+00, 1.3065e+00, 1.2892e+00, 1.2770e+00, 1.2651e+00,
         1.2451e+00, 1.2529e+00, 1.2650e+00, 1.3201e+00, 1.2374e+00, 1.2433e+00],
        [1.1805e+00, 1.2081e+00, 1.2509e+00, 1.2317e+00, 1.2155e+00, 1.1865e+00,
         1.1939e+00, 1.1788e+00, 1.1788e+00, 1.2563e+00, 1.2632e+00, 1.2723e+00,
         1.2952e+00, 1.2407e+00, 1.2513e+00, 1.2541e+00, 1.2425e+00, 1.1610e+00,
         1.2290e+00, 1.2527e+00, 1.2683e+00, 1.2416e+00, 1.2041e+00, 1.1935e+00,
         1.2218e+00, 1.1920e+00, 1.1920e+00, 2.7996e+00, 2.6482e+00, 2.3390e+00,
         2.4747e+00, 2.7938e+00, 2.3499e+00, 2.7490e+00, 2.3483e+00, 2.3415e+00,
         1.3576e+00, 1.4000e+00, 1.3711e+00, 1.3611e+00, 1.3854e+00, 1.3720e+00,
         1.3613e+00, 1.2730e+00, 1.3032e+00, 1.3287e+00, 1.2727e+00, 1.1683e+00,
         1.1975e+00, 1.3189e+00, 1.2493e+00, 1.3610e+00, 1.1896e+00, 1.2420e+00],
        [1.6824e+00, 1.3668e+00, 6.2364e-01, 8.2260e-01, 1.1812e+00, 1.5747e+00,
         1.5143e+00, 1.6794e+00, 1.6794e+00, 1.5308e+00, 1.2434e+00, 1.3710e+00,
         9.1360e-01, 1.6210e+00, 2.8358e-01, 1.5191e+00, 1.6404e+00, 1.1156e+00,
         1.3125e+00, 8.8807e-01, 7.8085e-01, 1.1031e+00, 1.5493e+00, 1.6080e+00,
         1.3386e+00, 1.6864e+00, 1.6864e+00, 7.1201e-01, 8.5966e-01, 1.6523e+00,
         1.4607e+00, 7.9816e-01, 1.5920e+00, 1.0867e+00, 1.7036e+00, 1.6247e+00,
         2.5247e-01, 2.9811e-02, 8.1960e-03, 2.1136e-01, 4.6512e-01, 6.2470e-01,
         1.5756e-01, 1.0828e+01, 7.6087e+00, 7.8576e-01, 1.2014e+00, 1.2940e+00,
         1.5144e+00, 1.0147e+00, 1.4524e+00, 4.5058e-01, 1.5681e+00, 1.6785e+00],
        [1.2394e+00, 1.2709e+00, 1.3332e+00, 1.3121e+00, 1.2801e+00, 1.2462e+00,
         1.2111e+00, 1.2374e+00, 1.2374e+00, 1.2105e+00, 1.3259e+00, 1.2285e+00,
         1.3540e+00, 1.2871e+00, 1.4068e+00, 1.2080e+00, 1.2896e+00, 1.2293e+00,
         1.2918e+00, 1.3230e+00, 1.3370e+00, 1.3055e+00, 1.2635e+00, 1.2544e+00,
         1.2075e+00, 1.2496e+00, 1.2496e+00, 1.3080e+00, 1.3500e+00, 1.2673e+00,
         1.0905e+00, 1.2606e+00, 1.1452e+00, 1.3147e+00, 1.1411e+00, 1.2703e+00,
         1.3624e+00, 1.0606e+00, 1.3834e+00, 1.3718e+00, 9.5391e-01, 8.5737e-01,
         1.3673e+00, 1.3594e+00, 7.4247e-01, 3.0265e+00, 2.4660e+00, 3.1421e+00,
         2.7039e+00, 2.0966e+00, 1.7971e+00, 2.8175e+00, 2.9463e+00, 1.7767e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 169 : 180.43807665118652
Test loss for epoch 169 : 180.53339382928857
Test Precision for epoch 169 : 0.26153846153846155
Test Recall for epoch 169 : 0.26153846153846155
Test F1 for epoch 169 : 0.26153846153846155


theta for epoch 170 : tensor([[2.4766e+00, 2.5064e+00, 2.5800e+00, 2.6828e+00, 2.6458e+00, 2.4828e+00,
         2.6219e+00, 2.4748e+00, 2.4748e+00, 1.2520e+00, 1.2696e+00, 1.2673e+00,
         1.2927e+00, 1.2371e+00, 1.3375e+00, 1.2499e+00, 1.2392e+00, 1.2217e+00,
         1.2202e+00, 1.2030e+00, 1.2144e+00, 1.2322e+00, 1.1965e+00, 1.1894e+00,
         1.2137e+00, 1.1849e+00, 1.1849e+00, 1.2325e+00, 1.2748e+00, 1.2051e+00,
         1.2283e+00, 1.2762e+00, 1.2153e+00, 1.2452e+00, 1.1656e+00, 1.2076e+00,
         1.3675e+00, 1.4077e+00, 1.3850e+00, 1.3751e+00, 1.3938e+00, 1.3260e+00,
         1.3715e+00, 1.3663e+00, 1.3166e+00, 1.3204e+00, 1.2712e+00, 1.2593e+00,
         1.2395e+00, 1.3111e+00, 1.2591e+00, 1.3511e+00, 1.2321e+00, 1.2378e+00],
        [1.2636e+00, 1.1746e+00, 9.9452e-01, 1.2172e+00, 1.2949e+00, 1.3145e+00,
         1.2386e+00, 1.3054e+00, 1.3054e+00, 1.5124e+00, 1.7566e+00, 1.5186e+00,
         2.2657e+00, 1.5520e+00, 5.4346e+00, 1.6190e+00, 1.4457e+00, 5.2519e+00,
         1.1068e+00, 1.1874e+00, 9.7581e-01, 1.1538e+00, 1.2888e+00, 1.3223e+00,
         1.2920e+00, 1.3173e+00, 1.3173e+00, 1.2917e+00, 1.0215e+00, 1.3340e+00,
         1.3132e+00, 1.1310e+00, 1.3467e+00, 1.3786e+00, 1.2957e+00, 1.3279e+00,
         1.3112e+00, 1.4621e+00, 1.3742e+00, 1.2840e+00, 1.2972e+00, 1.4270e+00,
         1.3573e+00, 4.8097e-01, 1.3413e+00, 1.0202e+00, 1.3946e+00, 1.3772e+00,
         1.3539e+00, 1.0404e+00, 1.3782e+00, 8.6122e-01, 1.3445e+00, 1.3534e+00],
        [1.1785e+00, 1.2050e+00, 1.2576e+00, 1.2390e+00, 1.2119e+00, 1.1842e+00,
         1.1911e+00, 1.1769e+00, 1.1769e+00, 1.2573e+00, 1.2751e+00, 1.2727e+00,
         1.2983e+00, 1.2423e+00, 1.3059e+00, 1.2552e+00, 1.2337e+00, 1.2103e+00,
         2.5428e+00, 2.6294e+00, 2.7323e+00, 2.6662e+00, 2.4379e+00, 2.5316e+00,
         2.5594e+00, 2.4255e+00, 2.4255e+00, 1.2731e+00, 1.2552e+00, 1.2108e+00,
         1.2341e+00, 1.2725e+00, 1.2211e+00, 1.2514e+00, 1.2154e+00, 1.2133e+00,
         1.3703e+00, 1.4109e+00, 1.3880e+00, 1.3654e+00, 1.3968e+00, 1.3855e+00,
         1.3744e+00, 1.2907e+00, 1.3063e+00, 1.2892e+00, 1.2768e+00, 1.2648e+00,
         1.2448e+00, 1.2532e+00, 1.2648e+00, 1.3201e+00, 1.2372e+00, 1.2431e+00],
        [1.1802e+00, 1.2078e+00, 1.2509e+00, 1.2317e+00, 1.2152e+00, 1.1861e+00,
         1.1936e+00, 1.1785e+00, 1.1785e+00, 1.2562e+00, 1.2635e+00, 1.2722e+00,
         1.2953e+00, 1.2406e+00, 1.2513e+00, 1.2540e+00, 1.2424e+00, 1.1616e+00,
         1.2288e+00, 1.2526e+00, 1.2681e+00, 1.2414e+00, 1.2040e+00, 1.1934e+00,
         1.2216e+00, 1.1919e+00, 1.1919e+00, 2.8023e+00, 2.6536e+00, 2.3434e+00,
         2.4796e+00, 2.7965e+00, 2.3543e+00, 2.7517e+00, 2.3527e+00, 2.3460e+00,
         1.3577e+00, 1.4001e+00, 1.3714e+00, 1.3614e+00, 1.3855e+00, 1.3722e+00,
         1.3614e+00, 1.2738e+00, 1.3033e+00, 1.3285e+00, 1.2726e+00, 1.1683e+00,
         1.1973e+00, 1.3188e+00, 1.2496e+00, 1.3608e+00, 1.1894e+00, 1.2418e+00],
        [1.6828e+00, 1.3672e+00, 6.2409e-01, 8.2300e-01, 1.1816e+00, 1.5751e+00,
         1.5147e+00, 1.6798e+00, 1.6798e+00, 1.5310e+00, 1.2433e+00, 1.3713e+00,
         9.1382e-01, 1.6212e+00, 2.8409e-01, 1.5193e+00, 1.6408e+00, 1.1152e+00,
         1.3130e+00, 8.8867e-01, 7.8135e-01, 1.1035e+00, 1.5499e+00, 1.6083e+00,
         1.3394e+00, 1.6869e+00, 1.6869e+00, 7.1256e-01, 8.6024e-01, 1.6528e+00,
         1.4615e+00, 7.9867e-01, 1.5925e+00, 1.0871e+00, 1.7041e+00, 1.6251e+00,
         2.5095e-01, 2.8255e-02, 6.8284e-03, 2.0978e-01, 4.6322e-01, 6.2260e-01,
         1.5603e-01, 1.0872e+01, 7.6104e+00, 7.8629e-01, 1.2017e+00, 1.2946e+00,
         1.5148e+00, 1.0150e+00, 1.4524e+00, 4.5101e-01, 1.5687e+00, 1.6789e+00],
        [1.2391e+00, 1.2706e+00, 1.3329e+00, 1.3118e+00, 1.2798e+00, 1.2459e+00,
         1.2108e+00, 1.2372e+00, 1.2372e+00, 1.2104e+00, 1.3259e+00, 1.2285e+00,
         1.3540e+00, 1.2870e+00, 1.4068e+00, 1.2079e+00, 1.2895e+00, 1.2292e+00,
         1.2918e+00, 1.3229e+00, 1.3369e+00, 1.3055e+00, 1.2634e+00, 1.2544e+00,
         1.2071e+00, 1.2496e+00, 1.2496e+00, 1.3078e+00, 1.3498e+00, 1.2671e+00,
         1.0901e+00, 1.2605e+00, 1.1451e+00, 1.3146e+00, 1.1409e+00, 1.2702e+00,
         1.3623e+00, 1.0601e+00, 1.3832e+00, 1.3717e+00, 9.5343e-01, 8.5689e-01,
         1.3672e+00, 1.3592e+00, 7.4192e-01, 3.0327e+00, 2.4687e+00, 3.1495e+00,
         2.7076e+00, 2.0983e+00, 1.7984e+00, 2.8215e+00, 2.9524e+00, 1.7780e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 170 : 180.4324013853374
Test loss for epoch 170 : 180.52867797479502
Test Precision for epoch 170 : 0.26153846153846155
Test Recall for epoch 170 : 0.26153846153846155
Test F1 for epoch 170 : 0.26153846153846155


theta for epoch 171 : tensor([[2.4805e+00, 2.5103e+00, 2.5839e+00, 2.6872e+00, 2.6502e+00, 2.4867e+00,
         2.6263e+00, 2.4787e+00, 2.4787e+00, 1.2518e+00, 1.2694e+00, 1.2671e+00,
         1.2926e+00, 1.2369e+00, 1.3373e+00, 1.2497e+00, 1.2389e+00, 1.2215e+00,
         1.2197e+00, 1.2024e+00, 1.2138e+00, 1.2317e+00, 1.1960e+00, 1.1890e+00,
         1.2132e+00, 1.1844e+00, 1.1844e+00, 1.2321e+00, 1.2744e+00, 1.2048e+00,
         1.2279e+00, 1.2759e+00, 1.2149e+00, 1.2449e+00, 1.1653e+00, 1.2073e+00,
         1.3675e+00, 1.4078e+00, 1.3851e+00, 1.3751e+00, 1.3939e+00, 1.3260e+00,
         1.3715e+00, 1.3662e+00, 1.3166e+00, 1.3201e+00, 1.2710e+00, 1.2590e+00,
         1.2393e+00, 1.3109e+00, 1.2589e+00, 1.3509e+00, 1.2318e+00, 1.2376e+00],
        [1.2638e+00, 1.1748e+00, 9.9487e-01, 1.2175e+00, 1.2953e+00, 1.3147e+00,
         1.2388e+00, 1.3056e+00, 1.3056e+00, 1.5121e+00, 1.7558e+00, 1.5183e+00,
         2.2647e+00, 1.5517e+00, 5.4526e+00, 1.6187e+00, 1.4454e+00, 5.2709e+00,
         1.1066e+00, 1.1873e+00, 9.7592e-01, 1.1536e+00, 1.2887e+00, 1.3222e+00,
         1.2917e+00, 1.3172e+00, 1.3172e+00, 1.2917e+00, 1.0214e+00, 1.3339e+00,
         1.3131e+00, 1.1310e+00, 1.3466e+00, 1.3787e+00, 1.2956e+00, 1.3280e+00,
         1.3112e+00, 1.4619e+00, 1.3739e+00, 1.2838e+00, 1.2972e+00, 1.4269e+00,
         1.3570e+00, 4.8084e-01, 1.3409e+00, 1.0203e+00, 1.3945e+00, 1.3771e+00,
         1.3538e+00, 1.0404e+00, 1.3783e+00, 8.6160e-01, 1.3444e+00, 1.3533e+00],
        [1.1786e+00, 1.2051e+00, 1.2576e+00, 1.2391e+00, 1.2120e+00, 1.1843e+00,
         1.1912e+00, 1.1769e+00, 1.1769e+00, 1.2571e+00, 1.2750e+00, 1.2726e+00,
         1.2982e+00, 1.2422e+00, 1.3059e+00, 1.2551e+00, 1.2334e+00, 1.2107e+00,
         2.5461e+00, 2.6335e+00, 2.7359e+00, 2.6695e+00, 2.4417e+00, 2.5353e+00,
         2.5632e+00, 2.4293e+00, 2.4293e+00, 1.2727e+00, 1.2551e+00, 1.2106e+00,
         1.2338e+00, 1.2721e+00, 1.2208e+00, 1.2511e+00, 1.2151e+00, 1.2131e+00,
         1.3704e+00, 1.4110e+00, 1.3880e+00, 1.3653e+00, 1.3969e+00, 1.3856e+00,
         1.3744e+00, 1.2913e+00, 1.3062e+00, 1.2892e+00, 1.2766e+00, 1.2646e+00,
         1.2446e+00, 1.2536e+00, 1.2646e+00, 1.3201e+00, 1.2370e+00, 1.2429e+00],
        [1.1801e+00, 1.2076e+00, 1.2511e+00, 1.2320e+00, 1.2150e+00, 1.1860e+00,
         1.1935e+00, 1.1784e+00, 1.1784e+00, 1.2560e+00, 1.2638e+00, 1.2721e+00,
         1.2953e+00, 1.2404e+00, 1.2512e+00, 1.2539e+00, 1.2423e+00, 1.1621e+00,
         1.2285e+00, 1.2524e+00, 1.2678e+00, 1.2411e+00, 1.2037e+00, 1.1932e+00,
         1.2213e+00, 1.1916e+00, 1.1916e+00, 2.8049e+00, 2.6591e+00, 2.3477e+00,
         2.4845e+00, 2.7992e+00, 2.3587e+00, 2.7544e+00, 2.3570e+00, 2.3503e+00,
         1.3578e+00, 1.4003e+00, 1.3716e+00, 1.3616e+00, 1.3857e+00, 1.3724e+00,
         1.3616e+00, 1.2745e+00, 1.3034e+00, 1.3283e+00, 1.2726e+00, 1.1682e+00,
         1.1972e+00, 1.3186e+00, 1.2499e+00, 1.3605e+00, 1.1893e+00, 1.2417e+00],
        [1.6834e+00, 1.3679e+00, 6.2467e-01, 8.2356e-01, 1.1822e+00, 1.5757e+00,
         1.5153e+00, 1.6804e+00, 1.6804e+00, 1.5313e+00, 1.2432e+00, 1.3716e+00,
         9.1401e-01, 1.6214e+00, 2.8457e-01, 1.5195e+00, 1.6411e+00, 1.1147e+00,
         1.3134e+00, 8.8914e-01, 7.8172e-01, 1.1039e+00, 1.5503e+00, 1.6085e+00,
         1.3401e+00, 1.6873e+00, 1.6873e+00, 7.1309e-01, 8.6079e-01, 1.6532e+00,
         1.4623e+00, 7.9917e-01, 1.5930e+00, 1.0874e+00, 1.7046e+00, 1.6254e+00,
         2.4946e-01, 2.6724e-02, 5.4827e-03, 2.0822e-01, 4.6134e-01, 6.2052e-01,
         1.5452e-01, 1.0917e+01, 7.6118e+00, 7.8681e-01, 1.2021e+00, 1.2951e+00,
         1.5151e+00, 1.0152e+00, 1.4525e+00, 4.5144e-01, 1.5692e+00, 1.6792e+00],
        [1.2391e+00, 1.2706e+00, 1.3329e+00, 1.3118e+00, 1.2798e+00, 1.2459e+00,
         1.2108e+00, 1.2372e+00, 1.2372e+00, 1.2102e+00, 1.3258e+00, 1.2283e+00,
         1.3539e+00, 1.2869e+00, 1.4067e+00, 1.2078e+00, 1.2893e+00, 1.2292e+00,
         1.2915e+00, 1.3226e+00, 1.3367e+00, 1.3053e+00, 1.2632e+00, 1.2542e+00,
         1.2066e+00, 1.2493e+00, 1.2493e+00, 1.3077e+00, 1.3496e+00, 1.2670e+00,
         1.0896e+00, 1.2604e+00, 1.1449e+00, 1.3144e+00, 1.1407e+00, 1.2700e+00,
         1.3622e+00, 1.0597e+00, 1.3831e+00, 1.3717e+00, 9.5297e-01, 8.5643e-01,
         1.3671e+00, 1.3590e+00, 7.4140e-01, 3.0389e+00, 2.4714e+00, 3.1569e+00,
         2.7114e+00, 2.0999e+00, 1.7997e+00, 2.8255e+00, 2.9585e+00, 1.7792e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 171 : 180.4267725567662
Test loss for epoch 171 : 180.52399874508814
Test Precision for epoch 171 : 0.26153846153846155
Test Recall for epoch 171 : 0.26153846153846155
Test F1 for epoch 171 : 0.26153846153846155


theta for epoch 172 : tensor([[2.4837e+00, 2.5136e+00, 2.5872e+00, 2.6909e+00, 2.6540e+00, 2.4899e+00,
         2.6300e+00, 2.4820e+00, 2.4820e+00, 1.2518e+00, 1.2695e+00, 1.2671e+00,
         1.2926e+00, 1.2369e+00, 1.3374e+00, 1.2497e+00, 1.2390e+00, 1.2216e+00,
         1.2199e+00, 1.2026e+00, 1.2140e+00, 1.2319e+00, 1.1962e+00, 1.1892e+00,
         1.2134e+00, 1.1846e+00, 1.1846e+00, 1.2320e+00, 1.2742e+00, 1.2046e+00,
         1.2277e+00, 1.2757e+00, 1.2148e+00, 1.2447e+00, 1.1651e+00, 1.2071e+00,
         1.3676e+00, 1.4079e+00, 1.3851e+00, 1.3753e+00, 1.3941e+00, 1.3261e+00,
         1.3716e+00, 1.3662e+00, 1.3167e+00, 1.3199e+00, 1.2708e+00, 1.2589e+00,
         1.2392e+00, 1.3107e+00, 1.2588e+00, 1.3507e+00, 1.2316e+00, 1.2375e+00],
        [1.2635e+00, 1.1745e+00, 9.9477e-01, 1.2173e+00, 1.2952e+00, 1.3144e+00,
         1.2384e+00, 1.3053e+00, 1.3053e+00, 1.5119e+00, 1.7551e+00, 1.5181e+00,
         2.2638e+00, 1.5514e+00, 5.4705e+00, 1.6184e+00, 1.4452e+00, 5.2900e+00,
         1.1067e+00, 1.1876e+00, 9.7627e-01, 1.1537e+00, 1.2889e+00, 1.3224e+00,
         1.2917e+00, 1.3173e+00, 1.3173e+00, 1.2918e+00, 1.0213e+00, 1.3339e+00,
         1.3131e+00, 1.1310e+00, 1.3466e+00, 1.3788e+00, 1.2955e+00, 1.3282e+00,
         1.3112e+00, 1.4618e+00, 1.3737e+00, 1.2836e+00, 1.2972e+00, 1.4268e+00,
         1.3568e+00, 4.8070e-01, 1.3406e+00, 1.0204e+00, 1.3945e+00, 1.3769e+00,
         1.3537e+00, 1.0403e+00, 1.3783e+00, 8.6197e-01, 1.3442e+00, 1.3532e+00],
        [1.1778e+00, 1.2042e+00, 1.2568e+00, 1.2382e+00, 1.2112e+00, 1.1835e+00,
         1.1904e+00, 1.1761e+00, 1.1761e+00, 1.2569e+00, 1.2749e+00, 1.2724e+00,
         1.2981e+00, 1.2420e+00, 1.3060e+00, 1.2549e+00, 1.2331e+00, 1.2111e+00,
         2.5498e+00, 2.6380e+00, 2.7399e+00, 2.6731e+00, 2.4459e+00, 2.5393e+00,
         2.5672e+00, 2.4334e+00, 2.4334e+00, 1.2722e+00, 1.2551e+00, 1.2102e+00,
         1.2335e+00, 1.2717e+00, 1.2205e+00, 1.2508e+00, 1.2148e+00, 1.2128e+00,
         1.3703e+00, 1.4111e+00, 1.3880e+00, 1.3651e+00, 1.3970e+00, 1.3857e+00,
         1.3744e+00, 1.2918e+00, 1.3060e+00, 1.2891e+00, 1.2764e+00, 1.2643e+00,
         1.2444e+00, 1.2538e+00, 1.2643e+00, 1.3200e+00, 1.2367e+00, 1.2427e+00],
        [1.1797e+00, 1.2072e+00, 1.2510e+00, 1.2319e+00, 1.2146e+00, 1.1856e+00,
         1.1930e+00, 1.1779e+00, 1.1779e+00, 1.2560e+00, 1.2641e+00, 1.2720e+00,
         1.2954e+00, 1.2404e+00, 1.2512e+00, 1.2538e+00, 1.2422e+00, 1.1626e+00,
         1.2285e+00, 1.2524e+00, 1.2677e+00, 1.2411e+00, 1.2036e+00, 1.1933e+00,
         1.2212e+00, 1.1915e+00, 1.1915e+00, 2.8075e+00, 2.6644e+00, 2.3521e+00,
         2.4893e+00, 2.8018e+00, 2.3630e+00, 2.7571e+00, 2.3613e+00, 2.3546e+00,
         1.3579e+00, 1.4005e+00, 1.3719e+00, 1.3619e+00, 1.3859e+00, 1.3727e+00,
         1.3617e+00, 1.2753e+00, 1.3035e+00, 1.3280e+00, 1.2725e+00, 1.1681e+00,
         1.1971e+00, 1.3184e+00, 1.2502e+00, 1.3603e+00, 1.1891e+00, 1.2415e+00],
        [1.6837e+00, 1.3682e+00, 6.2503e-01, 8.2387e-01, 1.1825e+00, 1.5760e+00,
         1.5156e+00, 1.6806e+00, 1.6806e+00, 1.5315e+00, 1.2432e+00, 1.3719e+00,
         9.1425e-01, 1.6216e+00, 2.8507e-01, 1.5198e+00, 1.6414e+00, 1.1143e+00,
         1.3140e+00, 8.8979e-01, 7.8226e-01, 1.1044e+00, 1.5509e+00, 1.6088e+00,
         1.3410e+00, 1.6879e+00, 1.6879e+00, 7.1364e-01, 8.6134e-01, 1.6537e+00,
         1.4630e+00, 7.9967e-01, 1.5935e+00, 1.0877e+00, 1.7051e+00, 1.6258e+00,
         2.4800e-01, 2.5223e-02, 4.1641e-03, 2.0669e-01, 4.5950e-01, 6.1849e-01,
         1.5305e-01, 1.0961e+01, 7.6128e+00, 7.8731e-01, 1.2025e+00, 1.2956e+00,
         1.5155e+00, 1.0155e+00, 1.4526e+00, 4.5185e-01, 1.5698e+00, 1.6795e+00],
        [1.2387e+00, 1.2702e+00, 1.3325e+00, 1.3114e+00, 1.2794e+00, 1.2455e+00,
         1.2104e+00, 1.2368e+00, 1.2368e+00, 1.2102e+00, 1.3259e+00, 1.2283e+00,
         1.3540e+00, 1.2868e+00, 1.4068e+00, 1.2077e+00, 1.2893e+00, 1.2291e+00,
         1.2916e+00, 1.3227e+00, 1.3367e+00, 1.3054e+00, 1.2632e+00, 1.2542e+00,
         1.2064e+00, 1.2493e+00, 1.2493e+00, 1.3075e+00, 1.3495e+00, 1.2668e+00,
         1.0891e+00, 1.2603e+00, 1.1448e+00, 1.3143e+00, 1.1405e+00, 1.2698e+00,
         1.3621e+00, 1.0593e+00, 1.3830e+00, 1.3716e+00, 9.5252e-01, 8.5598e-01,
         1.3671e+00, 1.3588e+00, 7.4088e-01, 3.0450e+00, 2.4740e+00, 3.1642e+00,
         2.7151e+00, 2.1016e+00, 1.8010e+00, 2.8294e+00, 2.9646e+00, 1.7805e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 172 : 180.42119450538166
Test loss for epoch 172 : 180.5193837691133
Test Precision for epoch 172 : 0.26153846153846155
Test Recall for epoch 172 : 0.26153846153846155
Test F1 for epoch 172 : 0.26153846153846155


theta for epoch 173 : tensor([[2.4879e+00, 2.5178e+00, 2.5914e+00, 2.6957e+00, 2.6587e+00, 2.4941e+00,
         2.6347e+00, 2.4862e+00, 2.4862e+00, 1.2514e+00, 1.2692e+00, 1.2667e+00,
         1.2924e+00, 1.2366e+00, 1.3371e+00, 1.2494e+00, 1.2386e+00, 1.2213e+00,
         1.2190e+00, 1.2017e+00, 1.2131e+00, 1.2310e+00, 1.1953e+00, 1.1883e+00,
         1.2125e+00, 1.1837e+00, 1.1837e+00, 1.2316e+00, 1.2738e+00, 1.2042e+00,
         1.2273e+00, 1.2753e+00, 1.2144e+00, 1.2444e+00, 1.1647e+00, 1.2067e+00,
         1.3675e+00, 1.4079e+00, 1.3851e+00, 1.3753e+00, 1.3941e+00, 1.3261e+00,
         1.3716e+00, 1.3661e+00, 1.3167e+00, 1.3196e+00, 1.2705e+00, 1.2585e+00,
         1.2388e+00, 1.3104e+00, 1.2585e+00, 1.3504e+00, 1.2313e+00, 1.2371e+00],
        [1.2640e+00, 1.1751e+00, 9.9539e-01, 1.2179e+00, 1.2959e+00, 1.3149e+00,
         1.2389e+00, 1.3058e+00, 1.3058e+00, 1.5115e+00, 1.7543e+00, 1.5178e+00,
         2.2627e+00, 1.5511e+00, 5.4883e+00, 1.6181e+00, 1.4449e+00, 5.3089e+00,
         1.1064e+00, 1.1874e+00, 9.7624e-01, 1.1534e+00, 1.2886e+00, 1.3222e+00,
         1.2913e+00, 1.3170e+00, 1.3170e+00, 1.2918e+00, 1.0213e+00, 1.3338e+00,
         1.3131e+00, 1.1311e+00, 1.3465e+00, 1.3788e+00, 1.2955e+00, 1.3283e+00,
         1.3112e+00, 1.4617e+00, 1.3734e+00, 1.2833e+00, 1.2972e+00, 1.4267e+00,
         1.3565e+00, 4.8061e-01, 1.3402e+00, 1.0205e+00, 1.3945e+00, 1.3768e+00,
         1.3535e+00, 1.0402e+00, 1.3782e+00, 8.6234e-01, 1.3440e+00, 1.3531e+00],
        [1.1784e+00, 1.2048e+00, 1.2573e+00, 1.2388e+00, 1.2118e+00, 1.1841e+00,
         1.1910e+00, 1.1767e+00, 1.1767e+00, 1.2568e+00, 1.2749e+00, 1.2723e+00,
         1.2980e+00, 1.2419e+00, 1.3061e+00, 1.2548e+00, 1.2328e+00, 1.2116e+00,
         2.5529e+00, 2.6418e+00, 2.7433e+00, 2.6760e+00, 2.4494e+00, 2.5427e+00,
         2.5707e+00, 2.4369e+00, 2.4369e+00, 1.2719e+00, 1.2551e+00, 1.2100e+00,
         1.2333e+00, 1.2713e+00, 1.2203e+00, 1.2507e+00, 1.2146e+00, 1.2126e+00,
         1.3704e+00, 1.4112e+00, 1.3881e+00, 1.3651e+00, 1.3971e+00, 1.3858e+00,
         1.3745e+00, 1.2924e+00, 1.3059e+00, 1.2892e+00, 1.2762e+00, 1.2641e+00,
         1.2442e+00, 1.2542e+00, 1.2642e+00, 1.3201e+00, 1.2364e+00, 1.2425e+00],
        [1.1798e+00, 1.2073e+00, 1.2514e+00, 1.2323e+00, 1.2147e+00, 1.1857e+00,
         1.1932e+00, 1.1781e+00, 1.1781e+00, 1.2558e+00, 1.2643e+00, 1.2719e+00,
         1.2954e+00, 1.2402e+00, 1.2511e+00, 1.2537e+00, 1.2420e+00, 1.1631e+00,
         1.2280e+00, 1.2521e+00, 1.2673e+00, 1.2406e+00, 1.2032e+00, 1.1930e+00,
         1.2208e+00, 1.1911e+00, 1.1911e+00, 2.8101e+00, 2.6698e+00, 2.3563e+00,
         2.4941e+00, 2.8045e+00, 2.3673e+00, 2.7598e+00, 2.3655e+00, 2.3589e+00,
         1.3580e+00, 1.4006e+00, 1.3721e+00, 1.3621e+00, 1.3860e+00, 1.3729e+00,
         1.3619e+00, 1.2760e+00, 1.3037e+00, 1.3278e+00, 1.2725e+00, 1.1680e+00,
         1.1969e+00, 1.3182e+00, 1.2505e+00, 1.3601e+00, 1.1889e+00, 1.2413e+00],
        [1.6844e+00, 1.3690e+00, 6.2573e-01, 8.2457e-01, 1.1832e+00, 1.5768e+00,
         1.5164e+00, 1.6814e+00, 1.6814e+00, 1.5317e+00, 1.2430e+00, 1.3721e+00,
         9.1440e-01, 1.6217e+00, 2.8550e-01, 1.5200e+00, 1.6417e+00, 1.1138e+00,
         1.3143e+00, 8.9014e-01, 7.8250e-01, 1.1046e+00, 1.5512e+00, 1.6088e+00,
         1.3416e+00, 1.6881e+00, 1.6881e+00, 7.1417e-01, 8.6186e-01, 1.6542e+00,
         1.4637e+00, 8.0017e-01, 1.5939e+00, 1.0881e+00, 1.7056e+00, 1.6261e+00,
         2.4656e-01, 2.3739e-02, 2.8590e-03, 2.0518e-01, 4.5769e-01, 6.1649e-01,
         1.5159e-01, 1.1005e+01, 7.6135e+00, 7.8778e-01, 1.2028e+00, 1.2961e+00,
         1.5158e+00, 1.0157e+00, 1.4526e+00, 4.5221e-01, 1.5703e+00, 1.6798e+00],
        [1.2390e+00, 1.2704e+00, 1.3327e+00, 1.3117e+00, 1.2797e+00, 1.2458e+00,
         1.2106e+00, 1.2370e+00, 1.2370e+00, 1.2100e+00, 1.3258e+00, 1.2281e+00,
         1.3539e+00, 1.2866e+00, 1.4067e+00, 1.2075e+00, 1.2891e+00, 1.2290e+00,
         1.2912e+00, 1.3223e+00, 1.3364e+00, 1.3050e+00, 1.2628e+00, 1.2539e+00,
         1.2057e+00, 1.2490e+00, 1.2490e+00, 1.3073e+00, 1.3493e+00, 1.2666e+00,
         1.0887e+00, 1.2601e+00, 1.1447e+00, 1.3142e+00, 1.1403e+00, 1.2697e+00,
         1.3619e+00, 1.0588e+00, 1.3829e+00, 1.3715e+00, 9.5208e-01, 8.5553e-01,
         1.3670e+00, 1.3586e+00, 7.4037e-01, 3.0510e+00, 2.4766e+00, 3.1715e+00,
         2.7187e+00, 2.1032e+00, 1.8022e+00, 2.8332e+00, 2.9707e+00, 1.7817e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 173 : 180.41567995923913
Test loss for epoch 173 : 180.51483616208262
Test Precision for epoch 173 : 0.26153846153846155
Test Recall for epoch 173 : 0.26153846153846155
Test F1 for epoch 173 : 0.26153846153846155


theta for epoch 174 : tensor([[2.4905e+00, 2.5204e+00, 2.5940e+00, 2.6988e+00, 2.6618e+00, 2.4966e+00,
         2.6378e+00, 2.4887e+00, 2.4887e+00, 1.2517e+00, 1.2695e+00, 1.2670e+00,
         1.2926e+00, 1.2368e+00, 1.3373e+00, 1.2496e+00, 1.2388e+00, 1.2215e+00,
         1.2199e+00, 1.2025e+00, 1.2139e+00, 1.2319e+00, 1.1962e+00, 1.1892e+00,
         1.2134e+00, 1.1846e+00, 1.1846e+00, 1.2316e+00, 1.2738e+00, 1.2042e+00,
         1.2273e+00, 1.2753e+00, 1.2144e+00, 1.2444e+00, 1.1647e+00, 1.2068e+00,
         1.3677e+00, 1.4082e+00, 1.3853e+00, 1.3755e+00, 1.3943e+00, 1.3263e+00,
         1.3717e+00, 1.3662e+00, 1.3169e+00, 1.3195e+00, 1.2705e+00, 1.2585e+00,
         1.2388e+00, 1.3104e+00, 1.2585e+00, 1.3503e+00, 1.2312e+00, 1.2371e+00],
        [1.2631e+00, 1.1743e+00, 9.9486e-01, 1.2171e+00, 1.2953e+00, 1.3140e+00,
         1.2381e+00, 1.3049e+00, 1.3049e+00, 1.5114e+00, 1.7536e+00, 1.5176e+00,
         2.2617e+00, 1.5509e+00, 5.5061e+00, 1.6179e+00, 1.4448e+00, 5.3279e+00,
         1.1068e+00, 1.1879e+00, 9.7683e-01, 1.1538e+00, 1.2891e+00, 1.3227e+00,
         1.2915e+00, 1.3175e+00, 1.3175e+00, 1.2919e+00, 1.0212e+00, 1.3338e+00,
         1.3131e+00, 1.1312e+00, 1.3465e+00, 1.3789e+00, 1.2955e+00, 1.3285e+00,
         1.3112e+00, 1.4615e+00, 1.3732e+00, 1.2831e+00, 1.2972e+00, 1.4266e+00,
         1.3562e+00, 4.8048e-01, 1.3398e+00, 1.0207e+00, 1.3944e+00, 1.3767e+00,
         1.3534e+00, 1.0402e+00, 1.3782e+00, 8.6272e-01, 1.3438e+00, 1.3530e+00],
        [1.1767e+00, 1.2031e+00, 1.2556e+00, 1.2371e+00, 1.2101e+00, 1.1824e+00,
         1.1893e+00, 1.1750e+00, 1.1750e+00, 1.2566e+00, 1.2747e+00, 1.2720e+00,
         1.2978e+00, 1.2416e+00, 1.3060e+00, 1.2545e+00, 1.2324e+00, 1.2120e+00,
         2.5569e+00, 2.6465e+00, 2.7475e+00, 2.6799e+00, 2.4539e+00, 2.5471e+00,
         2.5751e+00, 2.4415e+00, 2.4415e+00, 1.2713e+00, 1.2550e+00, 1.2097e+00,
         1.2329e+00, 1.2708e+00, 1.2199e+00, 1.2503e+00, 1.2142e+00, 1.2122e+00,
         1.3703e+00, 1.4112e+00, 1.3880e+00, 1.3649e+00, 1.3971e+00, 1.3858e+00,
         1.3744e+00, 1.2929e+00, 1.3057e+00, 1.2891e+00, 1.2759e+00, 1.2637e+00,
         1.2439e+00, 1.2544e+00, 1.2639e+00, 1.3200e+00, 1.2361e+00, 1.2422e+00],
        [1.1790e+00, 1.2065e+00, 1.2509e+00, 1.2318e+00, 1.2139e+00, 1.1850e+00,
         1.1924e+00, 1.1773e+00, 1.1773e+00, 1.2558e+00, 1.2647e+00, 1.2719e+00,
         1.2955e+00, 1.2402e+00, 1.2512e+00, 1.2537e+00, 1.2420e+00, 1.1637e+00,
         1.2282e+00, 1.2523e+00, 1.2674e+00, 1.2409e+00, 1.2034e+00, 1.1933e+00,
         1.2210e+00, 1.1913e+00, 1.1913e+00, 2.8127e+00, 2.6751e+00, 2.3606e+00,
         2.4988e+00, 2.8071e+00, 2.3715e+00, 2.7625e+00, 2.3697e+00, 2.3632e+00,
         1.3581e+00, 1.4008e+00, 1.3724e+00, 1.3624e+00, 1.3862e+00, 1.3731e+00,
         1.3620e+00, 1.2766e+00, 1.3038e+00, 1.3276e+00, 1.2725e+00, 1.1680e+00,
         1.1968e+00, 1.3180e+00, 1.2508e+00, 1.3599e+00, 1.1888e+00, 1.2412e+00],
        [1.6844e+00, 1.3690e+00, 6.2585e-01, 8.2462e-01, 1.1831e+00, 1.5767e+00,
         1.5164e+00, 1.6813e+00, 1.6813e+00, 1.5320e+00, 1.2431e+00, 1.3725e+00,
         9.1465e-01, 1.6219e+00, 2.8599e-01, 1.5203e+00, 1.6421e+00, 1.1134e+00,
         1.3151e+00, 8.9096e-01, 7.8319e-01, 1.1053e+00, 1.5520e+00, 1.6094e+00,
         1.3427e+00, 1.6889e+00, 1.6889e+00, 7.1473e-01, 8.6240e-01, 1.6547e+00,
         1.4645e+00, 8.0069e-01, 1.5944e+00, 1.0884e+00, 1.7061e+00, 1.6264e+00,
         2.4516e-01, 2.2282e-02, 1.5781e-03, 2.0370e-01, 4.5591e-01, 6.1452e-01,
         1.5017e-01, 1.1049e+01, 7.6137e+00, 7.8828e-01, 1.2032e+00, 1.2966e+00,
         1.5162e+00, 1.0160e+00, 1.4527e+00, 4.5261e-01, 1.5709e+00, 1.6801e+00],
        [1.2382e+00, 1.2696e+00, 1.3319e+00, 1.3108e+00, 1.2789e+00, 1.2450e+00,
         1.2098e+00, 1.2362e+00, 1.2362e+00, 1.2100e+00, 1.3258e+00, 1.2281e+00,
         1.3540e+00, 1.2866e+00, 1.4067e+00, 1.2075e+00, 1.2890e+00, 1.2291e+00,
         1.2915e+00, 1.3225e+00, 1.3367e+00, 1.3053e+00, 1.2631e+00, 1.2542e+00,
         1.2057e+00, 1.2492e+00, 1.2492e+00, 1.3072e+00, 1.3491e+00, 1.2665e+00,
         1.0882e+00, 1.2600e+00, 1.1446e+00, 1.3141e+00, 1.1402e+00, 1.2695e+00,
         1.3618e+00, 1.0584e+00, 1.3827e+00, 1.3714e+00, 9.5162e-01, 8.5508e-01,
         1.3669e+00, 1.3584e+00, 7.3985e-01, 3.0571e+00, 2.4792e+00, 3.1788e+00,
         2.7224e+00, 2.1048e+00, 1.8035e+00, 2.8371e+00, 2.9767e+00, 1.7830e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 174 : 180.41026896803055
Test loss for epoch 174 : 180.51038185303963
Test Precision for epoch 174 : 0.26153846153846155
Test Recall for epoch 174 : 0.26153846153846155
Test F1 for epoch 174 : 0.26153846153846155


theta for epoch 175 : tensor([[2.4957e+00, 2.5255e+00, 2.5991e+00, 2.7045e+00, 2.6675e+00, 2.5018e+00,
         2.6435e+00, 2.4939e+00, 2.4939e+00, 1.2510e+00, 1.2688e+00, 1.2663e+00,
         1.2920e+00, 1.2361e+00, 1.3366e+00, 1.2489e+00, 1.2381e+00, 1.2208e+00,
         1.2178e+00, 1.2004e+00, 1.2119e+00, 1.2299e+00, 1.1941e+00, 1.1872e+00,
         1.2113e+00, 1.1826e+00, 1.1826e+00, 1.2309e+00, 1.2731e+00, 1.2036e+00,
         1.2267e+00, 1.2747e+00, 1.2137e+00, 1.2438e+00, 1.1640e+00, 1.2061e+00,
         1.3675e+00, 1.4080e+00, 1.3851e+00, 1.3753e+00, 1.3942e+00, 1.3262e+00,
         1.3716e+00, 1.3659e+00, 1.3167e+00, 1.3190e+00, 1.2700e+00, 1.2580e+00,
         1.2384e+00, 1.3099e+00, 1.2581e+00, 1.3498e+00, 1.2307e+00, 1.2367e+00],
        [1.2645e+00, 1.1756e+00, 9.9620e-01, 1.2185e+00, 1.2968e+00, 1.3154e+00,
         1.2394e+00, 1.3062e+00, 1.3062e+00, 1.5109e+00, 1.7526e+00, 1.5172e+00,
         2.2605e+00, 1.5503e+00, 5.5237e+00, 1.6174e+00, 1.4443e+00, 5.3465e+00,
         1.1060e+00, 1.1872e+00, 9.7640e-01, 1.1530e+00, 1.2883e+00, 1.3219e+00,
         1.2906e+00, 1.3167e+00, 1.3167e+00, 1.2920e+00, 1.0212e+00, 1.3338e+00,
         1.3130e+00, 1.1312e+00, 1.3465e+00, 1.3790e+00, 1.2954e+00, 1.3286e+00,
         1.3112e+00, 1.4614e+00, 1.3729e+00, 1.2829e+00, 1.2972e+00, 1.4265e+00,
         1.3560e+00, 4.8043e-01, 1.3395e+00, 1.0208e+00, 1.3944e+00, 1.3766e+00,
         1.3533e+00, 1.0402e+00, 1.3782e+00, 8.6315e-01, 1.3437e+00, 1.3530e+00],
        [1.1787e+00, 1.2051e+00, 1.2576e+00, 1.2391e+00, 1.2121e+00, 1.1844e+00,
         1.1914e+00, 1.1771e+00, 1.1771e+00, 1.2566e+00, 1.2747e+00, 1.2720e+00,
         1.2979e+00, 1.2416e+00, 1.3062e+00, 1.2545e+00, 1.2322e+00, 1.2126e+00,
         2.5593e+00, 2.6497e+00, 2.7502e+00, 2.6821e+00, 2.4567e+00, 2.5498e+00,
         2.5778e+00, 2.4443e+00, 2.4443e+00, 1.2711e+00, 1.2552e+00, 1.2096e+00,
         1.2328e+00, 1.2706e+00, 1.2198e+00, 1.2503e+00, 1.2141e+00, 1.2121e+00,
         1.3704e+00, 1.4114e+00, 1.3881e+00, 1.3648e+00, 1.3973e+00, 1.3859e+00,
         1.3746e+00, 1.2936e+00, 1.3057e+00, 1.2892e+00, 1.2758e+00, 1.2636e+00,
         1.2438e+00, 1.2549e+00, 1.2638e+00, 1.3202e+00, 1.2360e+00, 1.2421e+00],
        [1.1797e+00, 1.2072e+00, 1.2518e+00, 1.2328e+00, 1.2146e+00, 1.1857e+00,
         1.1931e+00, 1.1780e+00, 1.1780e+00, 1.2556e+00, 1.2649e+00, 1.2717e+00,
         1.2955e+00, 1.2400e+00, 1.2510e+00, 1.2535e+00, 1.2418e+00, 1.1641e+00,
         1.2274e+00, 1.2516e+00, 1.2666e+00, 1.2400e+00, 1.2026e+00, 1.1926e+00,
         1.2201e+00, 1.1905e+00, 1.1905e+00, 2.8152e+00, 2.6803e+00, 2.3647e+00,
         2.5035e+00, 2.8097e+00, 2.3757e+00, 2.7651e+00, 2.3739e+00, 2.3673e+00,
         1.3582e+00, 1.4010e+00, 1.3726e+00, 1.3626e+00, 1.3864e+00, 1.3733e+00,
         1.3621e+00, 1.2773e+00, 1.3039e+00, 1.3274e+00, 1.2724e+00, 1.1679e+00,
         1.1967e+00, 1.3178e+00, 1.2510e+00, 1.3597e+00, 1.1886e+00, 1.2410e+00],
        [1.6857e+00, 1.3703e+00, 6.2688e-01, 8.2570e-01, 1.1844e+00, 1.5780e+00,
         1.5177e+00, 1.6826e+00, 1.6826e+00, 1.5321e+00, 1.2428e+00, 1.3726e+00,
         9.1471e-01, 1.6220e+00, 2.8633e-01, 1.5203e+00, 1.6423e+00, 1.1128e+00,
         1.3150e+00, 8.9095e-01, 7.8308e-01, 1.1051e+00, 1.5519e+00, 1.6090e+00,
         1.3429e+00, 1.6888e+00, 1.6888e+00, 7.1522e-01, 8.6286e-01, 1.6551e+00,
         1.4652e+00, 8.0114e-01, 1.5948e+00, 1.0887e+00, 1.7065e+00, 1.6267e+00,
         2.4378e-01, 2.0846e-02, 3.1424e-04, 2.0224e-01, 4.5415e-01, 6.1257e-01,
         1.4877e-01, 1.1093e+01, 7.6135e+00, 7.8870e-01, 1.2035e+00, 1.2970e+00,
         1.5165e+00, 1.0162e+00, 1.4528e+00, 4.5292e-01, 1.5714e+00, 1.6804e+00],
        [1.2391e+00, 1.2705e+00, 1.3328e+00, 1.3117e+00, 1.2798e+00, 1.2459e+00,
         1.2108e+00, 1.2371e+00, 1.2371e+00, 1.2097e+00, 1.3257e+00, 1.2279e+00,
         1.3538e+00, 1.2863e+00, 1.4066e+00, 1.2072e+00, 1.2887e+00, 1.2289e+00,
         1.2907e+00, 1.3217e+00, 1.3359e+00, 1.3045e+00, 1.2623e+00, 1.2534e+00,
         1.2046e+00, 1.2484e+00, 1.2484e+00, 1.3070e+00, 1.3489e+00, 1.2663e+00,
         1.0878e+00, 1.2599e+00, 1.1444e+00, 1.3140e+00, 1.1400e+00, 1.2694e+00,
         1.3617e+00, 1.0579e+00, 1.3826e+00, 1.3713e+00, 9.5118e-01, 8.5465e-01,
         1.3668e+00, 1.3582e+00, 7.3935e-01, 3.0631e+00, 2.4817e+00, 3.1860e+00,
         2.7259e+00, 2.1063e+00, 1.8047e+00, 2.8409e+00, 2.9827e+00, 1.7842e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 175 : 180.40507572308042
Test loss for epoch 175 : 180.50617099469073
Test Precision for epoch 175 : 0.26153846153846155
Test Recall for epoch 175 : 0.26153846153846155
Test F1 for epoch 175 : 0.26153846153846155


theta for epoch 176 : tensor([[ 2.4964e+00,  2.5263e+00,  2.6000e+00,  2.7058e+00,  2.6688e+00,
          2.5026e+00,  2.6448e+00,  2.4946e+00,  2.4946e+00,  1.2518e+00,
          1.2697e+00,  1.2671e+00,  1.2929e+00,  1.2370e+00,  1.3375e+00,
          1.2498e+00,  1.2389e+00,  1.2217e+00,  1.2207e+00,  1.2033e+00,
          1.2146e+00,  1.2327e+00,  1.1969e+00,  1.1901e+00,  1.2141e+00,
          1.1854e+00,  1.1854e+00,  1.2314e+00,  1.2735e+00,  1.2040e+00,
          1.2271e+00,  1.2751e+00,  1.2142e+00,  1.2443e+00,  1.1645e+00,
          1.2066e+00,  1.3679e+00,  1.4085e+00,  1.3855e+00,  1.3757e+00,
          1.3947e+00,  1.3266e+00,  1.3720e+00,  1.3662e+00,  1.3171e+00,
          1.3193e+00,  1.2703e+00,  1.2583e+00,  1.2387e+00,  1.3102e+00,
          1.2584e+00,  1.3501e+00,  1.2310e+00,  1.2370e+00],
        [ 1.2621e+00,  1.1734e+00,  9.9443e-01,  1.2164e+00,  1.2947e+00,
          1.3130e+00,  1.2371e+00,  1.3039e+00,  1.3039e+00,  1.5109e+00,
          1.7521e+00,  1.5172e+00,  2.2596e+00,  1.5503e+00,  5.5416e+00,
          1.6174e+00,  1.4444e+00,  5.3655e+00,  1.1072e+00,  1.1885e+00,
          9.7768e-01,  1.1542e+00,  1.2896e+00,  1.3232e+00,  1.2917e+00,
          1.3180e+00,  1.3180e+00,  1.2920e+00,  1.0212e+00,  1.3337e+00,
          1.3130e+00,  1.1313e+00,  1.3464e+00,  1.3790e+00,  1.2954e+00,
          1.3288e+00,  1.3112e+00,  1.4612e+00,  1.3726e+00,  1.2827e+00,
          1.2972e+00,  1.4264e+00,  1.3557e+00,  4.8030e-01,  1.3391e+00,
          1.0210e+00,  1.3944e+00,  1.3765e+00,  1.3532e+00,  1.0401e+00,
          1.3783e+00,  8.6355e-01,  1.3435e+00,  1.3529e+00],
        [ 1.1746e+00,  1.2010e+00,  1.2534e+00,  1.2349e+00,  1.2079e+00,
          1.1803e+00,  1.1872e+00,  1.1729e+00,  1.1729e+00,  1.2562e+00,
          1.2744e+00,  1.2716e+00,  1.2975e+00,  1.2412e+00,  1.3061e+00,
          1.2541e+00,  1.2317e+00,  1.2128e+00,  2.5644e+00,  2.6555e+00,
          2.7554e+00,  2.6869e+00,  2.4624e+00,  2.5552e+00,  2.5833e+00,
          2.4499e+00,  2.4499e+00,  1.2704e+00,  1.2549e+00,  1.2090e+00,
          1.2322e+00,  1.2698e+00,  1.2192e+00,  1.2497e+00,  1.2136e+00,
          1.2115e+00,  1.3702e+00,  1.4112e+00,  1.3879e+00,  1.3645e+00,
          1.3972e+00,  1.3858e+00,  1.3744e+00,  1.2939e+00,  1.3053e+00,
          1.2890e+00,  1.2753e+00,  1.2631e+00,  1.2434e+00,  1.2550e+00,
          1.2634e+00,  1.3199e+00,  1.2355e+00,  1.2416e+00],
        [ 1.1780e+00,  1.2055e+00,  1.2505e+00,  1.2314e+00,  1.2129e+00,
          1.1839e+00,  1.1913e+00,  1.1763e+00,  1.1763e+00,  1.2557e+00,
          1.2653e+00,  1.2718e+00,  1.2957e+00,  1.2401e+00,  1.2512e+00,
          1.2536e+00,  1.2419e+00,  1.1647e+00,  1.2283e+00,  1.2525e+00,
          1.2674e+00,  1.2409e+00,  1.2035e+00,  1.1936e+00,  1.2210e+00,
          1.1914e+00,  1.1914e+00,  2.8178e+00,  2.6855e+00,  2.3690e+00,
          2.5082e+00,  2.8123e+00,  2.3799e+00,  2.7678e+00,  2.3780e+00,
          2.3715e+00,  1.3583e+00,  1.4011e+00,  1.3728e+00,  1.3629e+00,
          1.3865e+00,  1.3735e+00,  1.3623e+00,  1.2779e+00,  1.3040e+00,
          1.3272e+00,  1.2724e+00,  1.1678e+00,  1.1966e+00,  1.3177e+00,
          1.2513e+00,  1.3595e+00,  1.1885e+00,  1.2409e+00],
        [ 1.6846e+00,  1.3694e+00,  6.2635e-01,  8.2504e-01,  1.1834e+00,
          1.5770e+00,  1.5167e+00,  1.6815e+00,  1.6815e+00,  1.5326e+00,
          1.2430e+00,  1.3731e+00,  9.1506e-01,  1.6224e+00,  2.8686e-01,
          1.5207e+00,  1.6428e+00,  1.1125e+00,  1.3163e+00,  8.9227e-01,
          7.8423e-01,  1.1064e+00,  1.5533e+00,  1.6102e+00,  1.3445e+00,
          1.6902e+00,  1.6902e+00,  7.1580e-01,  8.6339e-01,  1.6556e+00,
          1.4659e+00,  8.0169e-01,  1.5954e+00,  1.0891e+00,  1.7070e+00,
          1.6271e+00,  2.4245e-01,  1.9451e-02, -9.1070e-04,  2.0082e-01,
          4.5245e-01,  6.1068e-01,  1.4741e-01,  1.1137e+01,  7.6130e+00,
          7.8920e-01,  1.2039e+00,  1.2975e+00,  1.5169e+00,  1.0165e+00,
          1.4529e+00,  4.5330e-01,  1.5720e+00,  1.6808e+00],
        [ 1.2371e+00,  1.2686e+00,  1.3309e+00,  1.3098e+00,  1.2779e+00,
          1.2440e+00,  1.2088e+00,  1.2352e+00,  1.2352e+00,  1.2098e+00,
          1.3259e+00,  1.2281e+00,  1.3541e+00,  1.2865e+00,  1.4068e+00,
          1.2074e+00,  1.2889e+00,  1.2291e+00,  1.2918e+00,  1.3227e+00,
          1.3369e+00,  1.3056e+00,  1.2633e+00,  1.2544e+00,  1.2054e+00,
          1.2494e+00,  1.2494e+00,  1.3069e+00,  1.3488e+00,  1.2662e+00,
          1.0874e+00,  1.2598e+00,  1.1443e+00,  1.3140e+00,  1.1399e+00,
          1.2693e+00,  1.3616e+00,  1.0575e+00,  1.3825e+00,  1.3713e+00,
          9.5076e-01,  8.5423e-01,  1.3667e+00,  1.3580e+00,  7.3887e-01,
          3.0692e+00,  2.4843e+00,  3.1933e+00,  2.7295e+00,  2.1080e+00,
          1.8060e+00,  2.8447e+00,  2.9887e+00,  1.7854e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 176 : 180.40045838659245
Test loss for epoch 176 : 180.50251571469215
Test Precision for epoch 176 : 0.26153846153846155
Test Recall for epoch 176 : 0.26153846153846155
Test F1 for epoch 176 : 0.26153846153846155


theta for epoch 177 : tensor([[ 2.5045e+00,  2.5344e+00,  2.6079e+00,  2.7143e+00,  2.6773e+00,
          2.5106e+00,  2.6533e+00,  2.5027e+00,  2.5027e+00,  1.2501e+00,
          1.2681e+00,  1.2654e+00,  1.2912e+00,  1.2352e+00,  1.3359e+00,
          1.2481e+00,  1.2372e+00,  1.2200e+00,  1.2152e+00,  1.1978e+00,
          1.2093e+00,  1.2273e+00,  1.1915e+00,  1.1847e+00,  1.2087e+00,
          1.1800e+00,  1.1800e+00,  1.2300e+00,  1.2721e+00,  1.2027e+00,
          1.2257e+00,  1.2738e+00,  1.2128e+00,  1.2430e+00,  1.1631e+00,
          1.2052e+00,  1.3673e+00,  1.4080e+00,  1.3849e+00,  1.3752e+00,
          1.3942e+00,  1.3260e+00,  1.3715e+00,  1.3656e+00,  1.3165e+00,
          1.3183e+00,  1.2694e+00,  1.2572e+00,  1.2377e+00,  1.3092e+00,
          1.2574e+00,  1.3491e+00,  1.2300e+00,  1.2360e+00],
        [ 1.2659e+00,  1.1771e+00,  9.9785e-01,  1.2201e+00,  1.2986e+00,
          1.3168e+00,  1.2409e+00,  1.3077e+00,  1.3077e+00,  1.5100e+00,
          1.7508e+00,  1.5163e+00,  2.2580e+00,  1.5494e+00,  5.5587e+00,
          1.6165e+00,  1.4436e+00,  5.3837e+00,  1.1050e+00,  1.1865e+00,
          9.7610e-01,  1.1521e+00,  1.2874e+00,  1.3211e+00,  1.2893e+00,
          1.3158e+00,  1.3158e+00,  1.2921e+00,  1.0212e+00,  1.3337e+00,
          1.3130e+00,  1.1314e+00,  1.3464e+00,  1.3791e+00,  1.2953e+00,
          1.3289e+00,  1.3112e+00,  1.4611e+00,  1.3724e+00,  1.2825e+00,
          1.2973e+00,  1.4264e+00,  1.3555e+00,  4.8037e-01,  1.3387e+00,
          1.0212e+00,  1.3944e+00,  1.3764e+00,  1.3531e+00,  1.0401e+00,
          1.3783e+00,  8.6405e-01,  1.3434e+00,  1.3528e+00],
        [ 1.1807e+00,  1.2071e+00,  1.2594e+00,  1.2410e+00,  1.2141e+00,
          1.1864e+00,  1.1934e+00,  1.1791e+00,  1.1791e+00,  1.2564e+00,
          1.2747e+00,  1.2719e+00,  1.2978e+00,  1.2415e+00,  1.3065e+00,
          1.2544e+00,  1.2318e+00,  1.2137e+00,  2.5648e+00,  2.6567e+00,
          2.7561e+00,  2.6872e+00,  2.4632e+00,  2.5559e+00,  2.5841e+00,
          2.4507e+00,  2.4507e+00,  1.2705e+00,  1.2555e+00,  1.2093e+00,
          1.2324e+00,  1.2700e+00,  1.2195e+00,  1.2500e+00,  1.2139e+00,
          1.2118e+00,  1.3706e+00,  1.4116e+00,  1.3883e+00,  1.3647e+00,
          1.3976e+00,  1.3862e+00,  1.3748e+00,  1.2949e+00,  1.3055e+00,
          1.2894e+00,  1.2755e+00,  1.2633e+00,  1.2436e+00,  1.2558e+00,
          1.2636e+00,  1.3204e+00,  1.2357e+00,  1.2419e+00],
        [ 1.1803e+00,  1.2078e+00,  1.2528e+00,  1.2338e+00,  1.2152e+00,
          1.1862e+00,  1.1937e+00,  1.1786e+00,  1.1786e+00,  1.2553e+00,
          1.2653e+00,  1.2714e+00,  1.2954e+00,  1.2397e+00,  1.2509e+00,
          1.2532e+00,  1.2414e+00,  1.1649e+00,  1.2263e+00,  1.2506e+00,
          1.2654e+00,  1.2389e+00,  1.2014e+00,  1.1917e+00,  1.2190e+00,
          1.1893e+00,  1.1893e+00,  2.8203e+00,  2.6906e+00,  2.3730e+00,
          2.5127e+00,  2.8148e+00,  2.3839e+00,  2.7703e+00,  2.3820e+00,
          2.3756e+00,  1.3584e+00,  1.4013e+00,  1.3731e+00,  1.3631e+00,
          1.3867e+00,  1.3737e+00,  1.3624e+00,  1.2785e+00,  1.3042e+00,
          1.3270e+00,  1.2723e+00,  1.1677e+00,  1.1965e+00,  1.3175e+00,
          1.2515e+00,  1.3593e+00,  1.1884e+00,  1.2407e+00],
        [ 1.6875e+00,  1.3722e+00,  6.2839e-01,  8.2726e-01,  1.1861e+00,
          1.5799e+00,  1.5196e+00,  1.6844e+00,  1.6844e+00,  1.5324e+00,
          1.2426e+00,  1.3730e+00,  9.1492e-01,  1.6221e+00,  2.8705e-01,
          1.5206e+00,  1.6428e+00,  1.1116e+00,  1.3152e+00,  8.9135e-01,
          7.8325e-01,  1.1052e+00,  1.5521e+00,  1.6087e+00,  1.3437e+00,
          1.6889e+00,  1.6889e+00,  7.1625e-01,  8.6379e-01,  1.6560e+00,
          1.4665e+00,  8.0210e-01,  1.5957e+00,  1.0894e+00,  1.7074e+00,
          1.6273e+00,  2.4110e-01,  1.8040e-02, -2.1554e-03,  1.9939e-01,
          4.5074e-01,  6.0878e-01,  1.4603e-01,  1.1180e+01,  7.6121e+00,
          7.8955e-01,  1.2041e+00,  1.2979e+00,  1.5171e+00,  1.0166e+00,
          1.4529e+00,  4.5355e-01,  1.5724e+00,  1.6810e+00],
        [ 1.2400e+00,  1.2714e+00,  1.3336e+00,  1.3126e+00,  1.2807e+00,
          1.2468e+00,  1.2116e+00,  1.2380e+00,  1.2380e+00,  1.2093e+00,
          1.3255e+00,  1.2276e+00,  1.3536e+00,  1.2860e+00,  1.4064e+00,
          1.2069e+00,  1.2883e+00,  1.2286e+00,  1.2897e+00,  1.3206e+00,
          1.3349e+00,  1.3036e+00,  1.2612e+00,  1.2524e+00,  1.2031e+00,
          1.2474e+00,  1.2474e+00,  1.3067e+00,  1.3486e+00,  1.2660e+00,
          1.0869e+00,  1.2597e+00,  1.1441e+00,  1.3138e+00,  1.1397e+00,
          1.2691e+00,  1.3614e+00,  1.0571e+00,  1.3824e+00,  1.3712e+00,
          9.5035e-01,  8.5383e-01,  1.3666e+00,  1.3578e+00,  7.3840e-01,
          3.0750e+00,  2.4866e+00,  3.2004e+00,  2.7329e+00,  2.1094e+00,
          1.8071e+00,  2.8482e+00,  2.9945e+00,  1.7865e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 177 : 180.39731274333286
Test loss for epoch 177 : 180.50037434370563
Test Precision for epoch 177 : 0.26153846153846155
Test Recall for epoch 177 : 0.26153846153846155
Test F1 for epoch 177 : 0.26153846153846155


theta for epoch 178 : tensor([[ 2.5001e+00,  2.5301e+00,  2.6038e+00,  2.7106e+00,  2.6736e+00,
          2.5063e+00,  2.6495e+00,  2.4983e+00,  2.4983e+00,  1.2528e+00,
          1.2708e+00,  1.2681e+00,  1.2939e+00,  1.2379e+00,  1.3384e+00,
          1.2507e+00,  1.2399e+00,  1.2228e+00,  1.2237e+00,  1.2063e+00,
          1.2176e+00,  1.2357e+00,  1.2000e+00,  1.1931e+00,  1.2171e+00,
          1.1885e+00,  1.1885e+00,  1.2317e+00,  1.2737e+00,  1.2044e+00,
          1.2274e+00,  1.2754e+00,  1.2145e+00,  1.2447e+00,  1.1648e+00,
          1.2069e+00,  1.3684e+00,  1.4091e+00,  1.3860e+00,  1.3763e+00,
          1.3953e+00,  1.3272e+00,  1.3725e+00,  1.3666e+00,  1.3176e+00,
          1.3195e+00,  1.2706e+00,  1.2584e+00,  1.2389e+00,  1.3104e+00,
          1.2587e+00,  1.3503e+00,  1.2312e+00,  1.2372e+00],
        [ 1.2593e+00,  1.1708e+00,  9.9239e-01,  1.2138e+00,  1.2923e+00,
          1.3102e+00,  1.2343e+00,  1.3010e+00,  1.3010e+00,  1.5106e+00,
          1.7508e+00,  1.5169e+00,  2.2576e+00,  1.5500e+00,  5.5770e+00,
          1.6171e+00,  1.4442e+00,  5.4030e+00,  1.1084e+00,  1.1900e+00,
          9.7930e-01,  1.1555e+00,  1.2911e+00,  1.3247e+00,  1.2928e+00,
          1.3194e+00,  1.3194e+00,  1.2922e+00,  1.0212e+00,  1.3337e+00,
          1.3131e+00,  1.1315e+00,  1.3464e+00,  1.3792e+00,  1.2954e+00,
          1.3291e+00,  1.3112e+00,  1.4610e+00,  1.3722e+00,  1.2823e+00,
          1.2973e+00,  1.4262e+00,  1.3552e+00,  4.8019e-01,  1.3384e+00,
          1.0214e+00,  1.3944e+00,  1.3764e+00,  1.3530e+00,  1.0401e+00,
          1.3783e+00,  8.6445e-01,  1.3433e+00,  1.3528e+00],
        [ 1.1694e+00,  1.1958e+00,  1.2483e+00,  1.2297e+00,  1.2027e+00,
          1.1751e+00,  1.1819e+00,  1.1677e+00,  1.1677e+00,  1.2556e+00,
          1.2739e+00,  1.2711e+00,  1.2971e+00,  1.2407e+00,  1.3060e+00,
          1.2536e+00,  1.2308e+00,  1.2135e+00,  2.5729e+00,  2.6655e+00,
          2.7644e+00,  2.6950e+00,  2.4720e+00,  2.5645e+00,  2.5927e+00,
          2.4595e+00,  2.4595e+00,  1.2692e+00,  1.2546e+00,  1.2081e+00,
          1.2313e+00,  1.2686e+00,  1.2183e+00,  1.2489e+00,  1.2127e+00,
          1.2107e+00,  1.3700e+00,  1.4111e+00,  1.3877e+00,  1.3640e+00,
          1.3971e+00,  1.3857e+00,  1.3742e+00,  1.2949e+00,  1.3047e+00,
          1.2887e+00,  1.2746e+00,  1.2624e+00,  1.2427e+00,  1.2555e+00,
          1.2627e+00,  1.3197e+00,  1.2347e+00,  1.2410e+00],
        [ 1.1756e+00,  1.2031e+00,  1.2487e+00,  1.2298e+00,  1.2105e+00,
          1.1816e+00,  1.1890e+00,  1.1739e+00,  1.1739e+00,  1.2558e+00,
          1.2661e+00,  1.2719e+00,  1.2961e+00,  1.2402e+00,  1.2514e+00,
          1.2537e+00,  1.2419e+00,  1.1659e+00,  1.2291e+00,  1.2533e+00,
          1.2682e+00,  1.2418e+00,  1.2043e+00,  1.1946e+00,  1.2218e+00,
          1.1922e+00,  1.1922e+00,  2.8230e+00,  2.6959e+00,  2.3772e+00,
          2.5175e+00,  2.8176e+00,  2.3881e+00,  2.7731e+00,  2.3862e+00,
          2.3798e+00,  1.3586e+00,  1.4015e+00,  1.3733e+00,  1.3634e+00,
          1.3869e+00,  1.3740e+00,  1.3626e+00,  1.2792e+00,  1.3043e+00,
          1.3269e+00,  1.2724e+00,  1.1678e+00,  1.1965e+00,  1.3174e+00,
          1.2518e+00,  1.3592e+00,  1.1883e+00,  1.2407e+00],
        [ 1.6836e+00,  1.3686e+00,  6.2603e-01,  8.2456e-01,  1.1825e+00,
          1.5760e+00,  1.5158e+00,  1.6805e+00,  1.6805e+00,  1.5333e+00,
          1.2432e+00,  1.3739e+00,  9.1565e-01,  1.6230e+00,  2.8782e-01,
          1.5215e+00,  1.6438e+00,  1.1118e+00,  1.3182e+00,  8.9417e-01,
          7.8583e-01,  1.1081e+00,  1.5554e+00,  1.6117e+00,  1.3470e+00,
          1.6922e+00,  1.6922e+00,  7.1696e-01,  8.6442e-01,  1.6566e+00,
          1.4674e+00,  8.0278e-01,  1.5964e+00,  1.0899e+00,  1.7081e+00,
          1.6279e+00,  2.3984e-01,  1.6706e-02, -3.3259e-03,  1.9804e-01,
          4.4911e-01,  6.0696e-01,  1.4473e-01,  1.1224e+01,  7.6108e+00,
          7.9019e-01,  1.2047e+00,  1.2986e+00,  1.5177e+00,  1.0170e+00,
          1.4533e+00,  4.5405e-01,  1.5732e+00,  1.6816e+00],
        [ 1.2346e+00,  1.2661e+00,  1.3284e+00,  1.3073e+00,  1.2754e+00,
          1.2415e+00,  1.2063e+00,  1.2327e+00,  1.2327e+00,  1.2100e+00,
          1.3263e+00,  1.2283e+00,  1.3544e+00,  1.2867e+00,  1.4072e+00,
          1.2076e+00,  1.2890e+00,  1.2294e+00,  1.2928e+00,  1.3237e+00,
          1.3379e+00,  1.3067e+00,  1.2643e+00,  1.2555e+00,  1.2059e+00,
          1.2505e+00,  1.2505e+00,  1.3068e+00,  1.3486e+00,  1.2661e+00,
          1.0866e+00,  1.2597e+00,  1.1442e+00,  1.3139e+00,  1.1397e+00,
          1.2691e+00,  1.3614e+00,  1.0568e+00,  1.3823e+00,  1.3712e+00,
          9.4998e-01,  8.5346e-01,  1.3666e+00,  1.3577e+00,  7.3796e-01,
          3.0812e+00,  2.4893e+00,  3.2077e+00,  2.7366e+00,  2.1111e+00,
          1.8085e+00,  2.8521e+00,  3.0006e+00,  1.7879e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 178 : 180.39882186736415
Test loss for epoch 178 : 180.50280469850426
Test Precision for epoch 178 : 0.26153846153846155
Test Recall for epoch 178 : 0.26153846153846155
Test F1 for epoch 178 : 0.26153846153846155


theta for epoch 179 : tensor([[ 2.5163e+00,  2.5462e+00,  2.6197e+00,  2.7270e+00,  2.6901e+00,
          2.5225e+00,  2.6661e+00,  2.5145e+00,  2.5145e+00,  1.2481e+00,
          1.2662e+00,  1.2634e+00,  1.2894e+00,  1.2332e+00,  1.3340e+00,
          1.2461e+00,  1.2352e+00,  1.2180e+00,  1.2087e+00,  1.1911e+00,
          1.2028e+00,  1.2209e+00,  1.1850e+00,  1.1782e+00,  1.2023e+00,
          1.1735e+00,  1.1735e+00,  1.2283e+00,  1.2705e+00,  1.2011e+00,
          1.2241e+00,  1.2721e+00,  1.2112e+00,  1.2414e+00,  1.1614e+00,
          1.2036e+00,  1.3668e+00,  1.4076e+00,  1.3844e+00,  1.3747e+00,
          1.3938e+00,  1.3255e+00,  1.3710e+00,  1.3649e+00,  1.3160e+00,
          1.3170e+00,  1.2682e+00,  1.2560e+00,  1.2365e+00,  1.3080e+00,
          1.2562e+00,  1.3479e+00,  1.2287e+00,  1.2348e+00],
        [ 1.2695e+00,  1.1806e+00,  1.0014e+00,  1.2238e+00,  1.3026e+00,
          1.3204e+00,  1.2445e+00,  1.3113e+00,  1.3113e+00,  1.5088e+00,
          1.7485e+00,  1.5151e+00,  2.2549e+00,  1.5481e+00,  5.5931e+00,
          1.6152e+00,  1.4424e+00,  5.4200e+00,  1.1024e+00,  1.1841e+00,
          9.7434e-01,  1.1495e+00,  1.2848e+00,  1.3184e+00,  1.2863e+00,
          1.3130e+00,  1.3130e+00,  1.2924e+00,  1.0214e+00,  1.3338e+00,
          1.3132e+00,  1.1317e+00,  1.3465e+00,  1.3794e+00,  1.2954e+00,
          1.3293e+00,  1.3115e+00,  1.4610e+00,  1.3722e+00,  1.2823e+00,
          1.2976e+00,  1.4264e+00,  1.3552e+00,  4.8062e-01,  1.3382e+00,
          1.0218e+00,  1.3945e+00,  1.3764e+00,  1.3530e+00,  1.0404e+00,
          1.3784e+00,  8.6520e-01,  1.3432e+00,  1.3529e+00],
        [ 1.1864e+00,  1.2127e+00,  1.2648e+00,  1.2465e+00,  1.2197e+00,
          1.1921e+00,  1.1991e+00,  1.1848e+00,  1.1848e+00,  1.2568e+00,
          1.2751e+00,  1.2722e+00,  1.2983e+00,  1.2418e+00,  1.3072e+00,
          1.2547e+00,  1.2318e+00,  1.2153e+00,  2.5678e+00,  2.6613e+00,
          2.7597e+00,  2.6898e+00,  2.4673e+00,  2.5595e+00,  2.5880e+00,
          2.4548e+00,  2.4548e+00,  1.2705e+00,  1.2564e+00,  1.2096e+00,
          1.2327e+00,  1.2700e+00,  1.2198e+00,  1.2504e+00,  1.2142e+00,
          1.2122e+00,  1.3711e+00,  1.4123e+00,  1.3888e+00,  1.3650e+00,
          1.3983e+00,  1.3869e+00,  1.3754e+00,  1.2967e+00,  1.3057e+00,
          1.2901e+00,  1.2758e+00,  1.2635e+00,  1.2438e+00,  1.2572e+00,
          1.2638e+00,  1.3211e+00,  1.2359e+00,  1.2421e+00],
        [ 1.1824e+00,  1.2097e+00,  1.2551e+00,  1.2361e+00,  1.2171e+00,
          1.1883e+00,  1.1957e+00,  1.1807e+00,  1.1807e+00,  1.2549e+00,
          1.2656e+00,  1.2710e+00,  1.2954e+00,  1.2394e+00,  1.2506e+00,
          1.2528e+00,  1.2410e+00,  1.1656e+00,  1.2236e+00,  1.2482e+00,
          1.2627e+00,  1.2362e+00,  1.1987e+00,  1.1892e+00,  1.2163e+00,
          1.1866e+00,  1.1866e+00,  2.8253e+00,  2.7007e+00,  2.3810e+00,
          2.5218e+00,  2.8199e+00,  2.3919e+00,  2.7755e+00,  2.3900e+00,
          2.3836e+00,  1.3587e+00,  1.4017e+00,  1.3736e+00,  1.3637e+00,
          1.3872e+00,  1.3743e+00,  1.3628e+00,  1.2798e+00,  1.3046e+00,
          1.3267e+00,  1.2723e+00,  1.1677e+00,  1.1963e+00,  1.3172e+00,
          1.2520e+00,  1.3589e+00,  1.1882e+00,  1.2405e+00],
        [ 1.6907e+00,  1.3754e+00,  6.3081e-01,  8.2986e-01,  1.1891e+00,
          1.5831e+00,  1.5228e+00,  1.6876e+00,  1.6876e+00,  1.5325e+00,
          1.2421e+00,  1.3732e+00,  9.1499e-01,  1.6221e+00,  2.8763e-01,
          1.5207e+00,  1.6431e+00,  1.1103e+00,  1.3140e+00,  8.9055e-01,
          7.8225e-01,  1.1040e+00,  1.5509e+00,  1.6069e+00,  1.3432e+00,
          1.6877e+00,  1.6877e+00,  7.1731e-01,  8.6470e-01,  1.6569e+00,
          1.4679e+00,  8.0310e-01,  1.5966e+00,  1.0900e+00,  1.7083e+00,
          1.6279e+00,  2.3856e-01,  1.5352e-02, -4.5203e-03,  1.9667e-01,
          4.4747e-01,  6.0512e-01,  1.4342e-01,  1.1268e+01,  7.6092e+00,
          7.9041e-01,  1.2048e+00,  1.2989e+00,  1.5178e+00,  1.0171e+00,
          1.4531e+00,  4.5418e-01,  1.5735e+00,  1.6816e+00],
        [ 1.2425e+00,  1.2740e+00,  1.3360e+00,  1.3151e+00,  1.2832e+00,
          1.2493e+00,  1.2142e+00,  1.2406e+00,  1.2406e+00,  1.2089e+00,
          1.3252e+00,  1.2271e+00,  1.3533e+00,  1.2855e+00,  1.4061e+00,
          1.2064e+00,  1.2878e+00,  1.2283e+00,  1.2871e+00,  1.3180e+00,
          1.3325e+00,  1.3010e+00,  1.2586e+00,  1.2498e+00,  1.1999e+00,
          1.2447e+00,  1.2447e+00,  1.3065e+00,  1.3483e+00,  1.2658e+00,
          1.0861e+00,  1.2595e+00,  1.1439e+00,  1.3137e+00,  1.1394e+00,
          1.2689e+00,  1.3614e+00,  1.0565e+00,  1.3823e+00,  1.3712e+00,
          9.4971e-01,  8.5320e-01,  1.3666e+00,  1.3576e+00,  7.3765e-01,
          3.0867e+00,  2.4913e+00,  3.2145e+00,  2.7396e+00,  2.1123e+00,
          1.8093e+00,  2.8554e+00,  3.0061e+00,  1.7887e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 179 : 180.40964716422093
Test loss for epoch 179 : 180.51471876871827
Test Precision for epoch 179 : 0.26153846153846155
Test Recall for epoch 179 : 0.26153846153846155
Test F1 for epoch 179 : 0.26153846153846155


theta for epoch 180 : tensor([[ 2.4988e+00,  2.5289e+00,  2.6027e+00,  2.7104e+00,  2.6735e+00,
          2.5050e+00,  2.6492e+00,  2.4970e+00,  2.4970e+00,  1.2557e+00,
          1.2738e+00,  1.2710e+00,  1.2969e+00,  1.2409e+00,  1.3413e+00,
          1.2537e+00,  1.2428e+00,  1.2258e+00,  1.2306e+00,  1.2132e+00,
          1.2243e+00,  1.2426e+00,  1.2069e+00,  1.2002e+00,  1.2240e+00,
          1.1955e+00,  1.1955e+00,  1.2336e+00,  1.2755e+00,  1.2062e+00,
          1.2292e+00,  1.2772e+00,  1.2163e+00,  1.2466e+00,  1.1667e+00,
          1.2087e+00,  1.3697e+00,  1.4105e+00,  1.3873e+00,  1.3777e+00,
          1.3967e+00,  1.3286e+00,  1.3739e+00,  1.3677e+00,  1.3190e+00,
          1.3207e+00,  1.2719e+00,  1.2597e+00,  1.2403e+00,  1.3117e+00,
          1.2600e+00,  1.3515e+00,  1.2325e+00,  1.2386e+00],
        [ 1.2514e+00,  1.1633e+00,  9.8603e-01,  1.2064e+00,  1.2851e+00,
          1.3024e+00,  1.2265e+00,  1.2932e+00,  1.2932e+00,  1.5110e+00,
          1.7501e+00,  1.5173e+00,  2.2561e+00,  1.5503e+00,  5.6125e+00,
          1.6173e+00,  1.4446e+00,  5.4406e+00,  1.1114e+00,  1.1933e+00,
          9.8242e-01,  1.1585e+00,  1.2943e+00,  1.3280e+00,  1.2956e+00,
          1.3226e+00,  1.3226e+00,  1.2928e+00,  1.0217e+00,  1.3342e+00,
          1.3136e+00,  1.1321e+00,  1.3469e+00,  1.3799e+00,  1.2958e+00,
          1.3299e+00,  1.3116e+00,  1.4610e+00,  1.3721e+00,  1.2822e+00,
          1.2977e+00,  1.4264e+00,  1.3551e+00,  4.8037e-01,  1.3380e+00,
          1.0222e+00,  1.3948e+00,  1.3766e+00,  1.3532e+00,  1.0405e+00,
          1.3788e+00,  8.6573e-01,  1.3434e+00,  1.3531e+00],
        [ 1.1576e+00,  1.1839e+00,  1.2364e+00,  1.2178e+00,  1.1908e+00,
          1.1632e+00,  1.1700e+00,  1.1559e+00,  1.1559e+00,  1.2549e+00,
          1.2733e+00,  1.2704e+00,  1.2965e+00,  1.2399e+00,  1.3057e+00,
          1.2529e+00,  1.2298e+00,  1.2140e+00,  2.5842e+00,  2.6782e+00,
          2.7759e+00,  2.7057e+00,  2.4844e+00,  2.5764e+00,  2.6048e+00,
          2.4719e+00,  2.4719e+00,  1.2677e+00,  1.2539e+00,  1.2069e+00,
          1.2300e+00,  1.2671e+00,  1.2171e+00,  1.2478e+00,  1.2115e+00,
          1.2095e+00,  1.3696e+00,  1.4108e+00,  1.3873e+00,  1.3632e+00,
          1.3968e+00,  1.3854e+00,  1.3738e+00,  1.2956e+00,  1.3039e+00,
          1.2883e+00,  1.2737e+00,  1.2614e+00,  1.2417e+00,  1.2557e+00,
          1.2618e+00,  1.3193e+00,  1.2338e+00,  1.2401e+00],
        [ 1.1697e+00,  1.1971e+00,  1.2436e+00,  1.2248e+00,  1.2046e+00,
          1.1756e+00,  1.1831e+00,  1.1680e+00,  1.1680e+00,  1.2567e+00,
          1.2676e+00,  1.2728e+00,  1.2972e+00,  1.2411e+00,  1.2523e+00,
          1.2546e+00,  1.2428e+00,  1.1676e+00,  1.2315e+00,  1.2556e+00,
          1.2705e+00,  1.2441e+00,  1.2067e+00,  1.1972e+00,  1.2242e+00,
          1.1946e+00,  1.1946e+00,  2.8283e+00,  2.7062e+00,  2.3855e+00,
          2.5267e+00,  2.8229e+00,  2.3964e+00,  2.7786e+00,  2.3944e+00,
          2.3881e+00,  1.3591e+00,  1.4021e+00,  1.3741e+00,  1.3641e+00,
          1.3876e+00,  1.3747e+00,  1.3632e+00,  1.2806e+00,  1.3049e+00,
          1.3269e+00,  1.2727e+00,  1.1680e+00,  1.1967e+00,  1.3175e+00,
          1.2526e+00,  1.3592e+00,  1.1885e+00,  1.2408e+00],
        [ 1.6791e+00,  1.3644e+00,  6.2335e-01,  8.2147e-01,  1.1783e+00,
          1.5716e+00,  1.5115e+00,  1.6760e+00,  1.6760e+00,  1.5348e+00,
          1.2441e+00,  1.3755e+00,  9.1684e-01,  1.6244e+00,  2.8915e-01,
          1.5229e+00,  1.6456e+00,  1.1117e+00,  1.3214e+00,  8.9724e-01,
          7.8851e-01,  1.1110e+00,  1.5588e+00,  1.6146e+00,  1.3508e+00,
          1.6956e+00,  1.6956e+00,  7.1845e-01,  8.6573e-01,  1.6581e+00,
          1.4693e+00,  8.0423e-01,  1.5978e+00,  1.0911e+00,  1.7095e+00,
          1.6290e+00,  2.3745e-01,  1.4172e-02, -5.5417e-03,  1.9547e-01,
          4.4600e-01,  6.0345e-01,  1.4227e-01,  1.1311e+01,  7.6072e+00,
          7.9157e-01,  1.2061e+00,  1.3002e+00,  1.5190e+00,  1.0180e+00,
          1.4541e+00,  4.5514e-01,  1.5749e+00,  1.6828e+00],
        [ 1.2280e+00,  1.2595e+00,  1.3218e+00,  1.3007e+00,  1.2688e+00,
          1.2349e+00,  1.1998e+00,  1.2261e+00,  1.2261e+00,  1.2112e+00,
          1.3277e+00,  1.2295e+00,  1.3558e+00,  1.2879e+00,  1.4085e+00,
          1.2088e+00,  1.2902e+00,  1.2307e+00,  1.2955e+00,  1.3262e+00,
          1.3404e+00,  1.3094e+00,  1.2670e+00,  1.2583e+00,  1.2080e+00,
          1.2531e+00,  1.2531e+00,  1.3070e+00,  1.3488e+00,  1.2664e+00,
          1.0863e+00,  1.2600e+00,  1.1445e+00,  1.3142e+00,  1.1399e+00,
          1.2694e+00,  1.3616e+00,  1.0565e+00,  1.3826e+00,  1.3715e+00,
          9.4961e-01,  8.5312e-01,  1.3669e+00,  1.3578e+00,  7.3746e-01,
          3.0932e+00,  2.4944e+00,  3.2223e+00,  2.7437e+00,  2.1145e+00,
          1.8112e+00,  2.8596e+00,  3.0126e+00,  1.7905e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 180 : 180.4471484626185
Test loss for epoch 180 : 180.55306662909663
Test Precision for epoch 180 : 0.26153846153846155
Test Recall for epoch 180 : 0.26153846153846155
Test F1 for epoch 180 : 0.26153846153846155


theta for epoch 181 : tensor([[ 2.5296e+00,  2.5595e+00,  2.6330e+00,  2.7413e+00,  2.7044e+00,
          2.5358e+00,  2.6804e+00,  2.5279e+00,  2.5279e+00,  1.2448e+00,
          1.2630e+00,  1.2602e+00,  1.2862e+00,  1.2299e+00,  1.3309e+00,
          1.2428e+00,  1.2318e+00,  1.2147e+00,  1.1984e+00,  1.1806e+00,
          1.1923e+00,  1.2105e+00,  1.1747e+00,  1.1679e+00,  1.1919e+00,
          1.1632e+00,  1.1632e+00,  1.2260e+00,  1.2683e+00,  1.1989e+00,
          1.2219e+00,  1.2700e+00,  1.2090e+00,  1.2393e+00,  1.1591e+00,
          1.2014e+00,  1.3659e+00,  1.4069e+00,  1.3836e+00,  1.3740e+00,
          1.3931e+00,  1.3247e+00,  1.3702e+00,  1.3639e+00,  1.3152e+00,
          1.3154e+00,  1.2666e+00,  1.2543e+00,  1.2349e+00,  1.3065e+00,
          1.2547e+00,  1.3463e+00,  1.2271e+00,  1.2332e+00],
        [ 1.2723e+00,  1.1835e+00,  1.0045e+00,  1.2267e+00,  1.3057e+00,
          1.3231e+00,  1.2473e+00,  1.3140e+00,  1.3140e+00,  1.5069e+00,
          1.7455e+00,  1.5132e+00,  2.2511e+00,  1.5461e+00,  5.6265e+00,
          1.6132e+00,  1.4406e+00,  5.4553e+00,  1.0970e+00,  1.1790e+00,
          9.7021e-01,  1.1442e+00,  1.2792e+00,  1.3128e+00,  1.2805e+00,
          1.3073e+00,  1.3073e+00,  1.2939e+00,  1.0230e+00,  1.3352e+00,
          1.3146e+00,  1.1334e+00,  1.3478e+00,  1.3809e+00,  1.2968e+00,
          1.3310e+00,  1.3127e+00,  1.4620e+00,  1.3729e+00,  1.2832e+00,
          1.2989e+00,  1.4274e+00,  1.3559e+00,  4.8203e-01,  1.3387e+00,
          1.0237e+00,  1.3958e+00,  1.3775e+00,  1.3541e+00,  1.0418e+00,
          1.3797e+00,  8.6760e-01,  1.3442e+00,  1.3541e+00],
        [ 1.1900e+00,  1.2162e+00,  1.2681e+00,  1.2498e+00,  1.2232e+00,
          1.1957e+00,  1.2026e+00,  1.1884e+00,  1.1884e+00,  1.2583e+00,
          1.2767e+00,  1.2738e+00,  1.2999e+00,  1.2433e+00,  1.3091e+00,
          1.2563e+00,  1.2330e+00,  1.2182e+00,  2.5676e+00,  2.6626e+00,
          2.7601e+00,  2.6891e+00,  2.4680e+00,  2.5598e+00,  2.5886e+00,
          2.4555e+00,  2.4555e+00,  1.2723e+00,  1.2590e+00,  1.2116e+00,
          1.2347e+00,  1.2717e+00,  1.2218e+00,  1.2524e+00,  1.2162e+00,
          1.2142e+00,  1.3728e+00,  1.4141e+00,  1.3905e+00,  1.3663e+00,
          1.4001e+00,  1.3887e+00,  1.3771e+00,  1.2996e+00,  1.3071e+00,
          1.2922e+00,  1.2773e+00,  1.2650e+00,  1.2454e+00,  1.2600e+00,
          1.2654e+00,  1.3232e+00,  1.2374e+00,  1.2437e+00],
        [ 1.1839e+00,  1.2112e+00,  1.2568e+00,  1.2378e+00,  1.2185e+00,
          1.1897e+00,  1.1971e+00,  1.1822e+00,  1.1822e+00,  1.2552e+00,
          1.2664e+00,  1.2712e+00,  1.2958e+00,  1.2396e+00,  1.2510e+00,
          1.2530e+00,  1.2412e+00,  1.1669e+00,  1.2184e+00,  1.2434e+00,
          1.2575e+00,  1.2311e+00,  1.1935e+00,  1.1843e+00,  1.2111e+00,
          1.1815e+00,  1.1815e+00,  2.8303e+00,  2.7107e+00,  2.3889e+00,
          2.5307e+00,  2.8250e+00,  2.3998e+00,  2.7807e+00,  2.3978e+00,
          2.3915e+00,  1.3598e+00,  1.4029e+00,  1.3749e+00,  1.3650e+00,
          1.3883e+00,  1.3755e+00,  1.3639e+00,  1.2818e+00,  1.3057e+00,
          1.3271e+00,  1.2730e+00,  1.1684e+00,  1.1970e+00,  1.3177e+00,
          1.2532e+00,  1.3594e+00,  1.1887e+00,  1.2410e+00],
        [ 1.6933e+00,  1.3781e+00,  6.3293e-01,  8.3215e-01,  1.1916e+00,
          1.5858e+00,  1.5255e+00,  1.6902e+00,  1.6902e+00,  1.5330e+00,
          1.2420e+00,  1.3738e+00,  9.1529e-01,  1.6225e+00,  2.8831e-01,
          1.5211e+00,  1.6439e+00,  1.1093e+00,  1.3106e+00,  8.8768e-01,
          7.7925e-01,  1.1005e+00,  1.5472e+00,  1.6027e+00,  1.3404e+00,
          1.6839e+00,  1.6839e+00,  7.1893e-01,  8.6613e-01,  1.6585e+00,
          1.4699e+00,  8.0469e-01,  1.5983e+00,  1.0914e+00,  1.7100e+00,
          1.6293e+00,  2.3641e-01,  1.3048e-02, -6.5111e-03,  1.9433e-01,
          4.4460e-01,  6.0183e-01,  1.4119e-01,  1.1355e+01,  7.6049e+00,
          7.9207e-01,  1.2065e+00,  1.3008e+00,  1.5195e+00,  1.0183e+00,
          1.4543e+00,  4.5550e-01,  1.5755e+00,  1.6832e+00],
        [ 1.2444e+00,  1.2758e+00,  1.3377e+00,  1.3168e+00,  1.2850e+00,
          1.2512e+00,  1.2160e+00,  1.2425e+00,  1.2425e+00,  1.2091e+00,
          1.3256e+00,  1.2275e+00,  1.3538e+00,  1.2858e+00,  1.4066e+00,
          1.2067e+00,  1.2881e+00,  1.2287e+00,  1.2819e+00,  1.3128e+00,
          1.3275e+00,  1.2959e+00,  1.2533e+00,  1.2446e+00,  1.1942e+00,
          1.2394e+00,  1.2394e+00,  1.3073e+00,  1.3490e+00,  1.2666e+00,
          1.0863e+00,  1.2603e+00,  1.1447e+00,  1.3145e+00,  1.1402e+00,
          1.2697e+00,  1.3623e+00,  1.0570e+00,  1.3832e+00,  1.3723e+00,
          9.5015e-01,  8.5366e-01,  1.3676e+00,  1.3584e+00,  7.3799e-01,
          3.0984e+00,  2.4960e+00,  3.2286e+00,  2.7463e+00,  2.1152e+00,
          1.8116e+00,  2.8625e+00,  3.0176e+00,  1.7909e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 181 : 180.46443487401086
Test loss for epoch 181 : 180.57166925333988
Test Precision for epoch 181 : 0.26153846153846155
Test Recall for epoch 181 : 0.26153846153846155
Test F1 for epoch 181 : 0.26153846153846155


theta for epoch 182 : tensor([[ 2.5056e+00,  2.5357e+00,  2.6095e+00,  2.7181e+00,  2.6812e+00,
          2.5118e+00,  2.6569e+00,  2.5038e+00,  2.5038e+00,  1.2563e+00,
          1.2745e+00,  1.2716e+00,  1.2976e+00,  1.2414e+00,  1.3420e+00,
          1.2542e+00,  1.2433e+00,  1.2264e+00,  1.2280e+00,  1.2104e+00,
          1.2216e+00,  1.2400e+00,  1.2044e+00,  1.1977e+00,  1.2214e+00,
          1.1930e+00,  1.1930e+00,  1.2334e+00,  1.2753e+00,  1.2060e+00,
          1.2289e+00,  1.2771e+00,  1.2161e+00,  1.2464e+00,  1.1665e+00,
          1.2085e+00,  1.3700e+00,  1.4110e+00,  1.3876e+00,  1.3780e+00,
          1.3972e+00,  1.3290e+00,  1.3742e+00,  1.3677e+00,  1.3193e+00,
          1.3207e+00,  1.2720e+00,  1.2597e+00,  1.2403e+00,  1.3118e+00,
          1.2601e+00,  1.3516e+00,  1.2324e+00,  1.2386e+00],
        [ 1.2493e+00,  1.1613e+00,  9.8437e-01,  1.2044e+00,  1.2832e+00,
          1.3002e+00,  1.2244e+00,  1.2910e+00,  1.2910e+00,  1.5103e+00,
          1.7483e+00,  1.5166e+00,  2.2534e+00,  1.5495e+00,  5.6466e+00,
          1.6165e+00,  1.4440e+00,  5.4767e+00,  1.1111e+00,  1.1932e+00,
          9.8283e-01,  1.1582e+00,  1.2940e+00,  1.3278e+00,  1.2950e+00,
          1.3223e+00,  1.3223e+00,  1.2938e+00,  1.0226e+00,  1.3350e+00,
          1.3145e+00,  1.1331e+00,  1.3477e+00,  1.3808e+00,  1.2966e+00,
          1.3311e+00,  1.3127e+00,  1.4618e+00,  1.3726e+00,  1.2830e+00,
          1.2989e+00,  1.4272e+00,  1.3557e+00,  4.8150e-01,  1.3383e+00,
          1.0236e+00,  1.3957e+00,  1.3773e+00,  1.3540e+00,  1.0416e+00,
          1.3797e+00,  8.6771e-01,  1.3441e+00,  1.3540e+00],
        [ 1.1562e+00,  1.1824e+00,  1.2344e+00,  1.2160e+00,  1.1892e+00,
          1.1618e+00,  1.1686e+00,  1.1545e+00,  1.1545e+00,  1.2539e+00,
          1.2724e+00,  1.2694e+00,  1.2957e+00,  1.2389e+00,  1.3052e+00,
          1.2519e+00,  1.2284e+00,  1.2143e+00,  2.5924e+00,  2.6878e+00,
          2.7844e+00,  2.7133e+00,  2.4936e+00,  2.5851e+00,  2.6138e+00,
          2.4811e+00,  2.4811e+00,  1.2661e+00,  1.2532e+00,  1.2056e+00,
          1.2287e+00,  1.2655e+00,  1.2158e+00,  1.2465e+00,  1.2102e+00,
          1.2082e+00,  1.3694e+00,  1.4108e+00,  1.3871e+00,  1.3627e+00,
          1.3968e+00,  1.3854e+00,  1.3737e+00,  1.2967e+00,  1.3034e+00,
          1.2880e+00,  1.2729e+00,  1.2605e+00,  1.2409e+00,  1.2561e+00,
          1.2610e+00,  1.3190e+00,  1.2329e+00,  1.2392e+00],
        [ 1.1672e+00,  1.1946e+00,  1.2416e+00,  1.2228e+00,  1.2021e+00,
          1.1732e+00,  1.1806e+00,  1.1655e+00,  1.1655e+00,  1.2581e+00,
          1.2696e+00,  1.2742e+00,  1.2988e+00,  1.2426e+00,  1.2538e+00,
          1.2560e+00,  1.2442e+00,  1.1699e+00,  1.2313e+00,  1.2555e+00,
          1.2702e+00,  1.2439e+00,  1.2064e+00,  1.1972e+00,  1.2239e+00,
          1.1945e+00,  1.1945e+00,  2.8329e+00,  2.7157e+00,  2.3930e+00,
          2.5352e+00,  2.8277e+00,  2.4039e+00,  2.7834e+00,  2.4018e+00,
          2.3956e+00,  1.3602e+00,  1.4034e+00,  1.3755e+00,  1.3655e+00,
          1.3888e+00,  1.3761e+00,  1.3644e+00,  1.2826e+00,  1.3062e+00,
          1.3274e+00,  1.2734e+00,  1.1688e+00,  1.1974e+00,  1.3180e+00,
          1.2539e+00,  1.3596e+00,  1.1891e+00,  1.2414e+00],
        [ 1.6776e+00,  1.3632e+00,  6.2275e-01,  8.2072e-01,  1.1771e+00,
          1.5702e+00,  1.5102e+00,  1.6746e+00,  1.6746e+00,  1.5368e+00,
          1.2455e+00,  1.3774e+00,  9.1850e-01,  1.6262e+00,  2.9093e-01,
          1.5248e+00,  1.6477e+00,  1.1121e+00,  1.3225e+00,  8.9856e-01,
          7.8954e-01,  1.1119e+00,  1.5599e+00,  1.6151e+00,  1.3525e+00,
          1.6966e+00,  1.6966e+00,  7.2028e-01,  8.6729e-01,  1.6597e+00,
          1.4714e+00,  8.0600e-01,  1.5995e+00,  1.0926e+00,  1.7111e+00,
          1.6303e+00,  2.3497e-01,  1.1550e-02, -7.8533e-03,  1.9279e-01,
          4.4278e-01,  5.9978e-01,  1.3971e-01,  1.1398e+01,  7.6018e+00,
          7.9356e-01,  1.2080e+00,  1.3024e+00,  1.5209e+00,  1.0196e+00,
          1.4555e+00,  4.5686e-01,  1.5771e+00,  1.6846e+00],
        [ 1.2256e+00,  1.2570e+00,  1.3192e+00,  1.2982e+00,  1.2663e+00,
          1.2324e+00,  1.1973e+00,  1.2237e+00,  1.2237e+00,  1.2131e+00,
          1.3297e+00,  1.2313e+00,  1.3578e+00,  1.2898e+00,  1.4103e+00,
          1.2106e+00,  1.2920e+00,  1.2327e+00,  1.2954e+00,  1.3260e+00,
          1.3402e+00,  1.3093e+00,  1.2669e+00,  1.2582e+00,  1.2074e+00,
          1.2530e+00,  1.2530e+00,  1.3077e+00,  1.3494e+00,  1.2671e+00,
          1.0865e+00,  1.2607e+00,  1.1451e+00,  1.3150e+00,  1.1406e+00,
          1.2701e+00,  1.3627e+00,  1.0571e+00,  1.3836e+00,  1.3727e+00,
          9.5022e-01,  8.5378e-01,  1.3680e+00,  1.3587e+00,  7.3801e-01,
          3.1044e+00,  2.4986e+00,  3.2359e+00,  2.7498e+00,  2.1170e+00,
          1.8130e+00,  2.8662e+00,  3.0236e+00,  1.7923e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 182 : 180.44867670312954
Test loss for epoch 182 : 180.55677941461047
Test Precision for epoch 182 : 0.26153846153846155
Test Recall for epoch 182 : 0.26153846153846155
Test F1 for epoch 182 : 0.26153846153846155


theta for epoch 183 : tensor([[ 2.5269e+00,  2.5568e+00,  2.6305e+00,  2.7395e+00,  2.7026e+00,
          2.5331e+00,  2.6785e+00,  2.5251e+00,  2.5251e+00,  1.2468e+00,
          1.2651e+00,  1.2622e+00,  1.2883e+00,  1.2319e+00,  1.3329e+00,
          1.2448e+00,  1.2338e+00,  1.2168e+00,  1.2109e+00,  1.1930e+00,
          1.2044e+00,  1.2229e+00,  1.1873e+00,  1.1806e+00,  1.2043e+00,
          1.1759e+00,  1.1759e+00,  1.2274e+00,  1.2695e+00,  1.2001e+00,
          1.2231e+00,  1.2713e+00,  1.2102e+00,  1.2406e+00,  1.1604e+00,
          1.2027e+00,  1.3666e+00,  1.4077e+00,  1.3843e+00,  1.3748e+00,
          1.3939e+00,  1.3256e+00,  1.3709e+00,  1.3643e+00,  1.3158e+00,
          1.3162e+00,  1.2674e+00,  1.2551e+00,  1.2357e+00,  1.3073e+00,
          1.2556e+00,  1.3471e+00,  1.2279e+00,  1.2341e+00],
        [ 1.2658e+00,  1.1773e+00,  9.9929e-01,  1.2205e+00,  1.2996e+00,
          1.3166e+00,  1.2408e+00,  1.3074e+00,  1.3074e+00,  1.5063e+00,
          1.7438e+00,  1.5126e+00,  2.2485e+00,  1.5455e+00,  5.6605e+00,
          1.6125e+00,  1.4401e+00,  5.4913e+00,  1.1026e+00,  1.1848e+00,
          9.7568e-01,  1.1498e+00,  1.2851e+00,  1.3188e+00,  1.2860e+00,
          1.3132e+00,  1.3132e+00,  1.2941e+00,  1.0232e+00,  1.3353e+00,
          1.3148e+00,  1.1335e+00,  1.3479e+00,  1.3811e+00,  1.2969e+00,
          1.3315e+00,  1.3133e+00,  1.4621e+00,  1.3729e+00,  1.2834e+00,
          1.2995e+00,  1.4276e+00,  1.3559e+00,  4.8250e-01,  1.3385e+00,
          1.0242e+00,  1.3959e+00,  1.3774e+00,  1.3541e+00,  1.0420e+00,
          1.3800e+00,  8.6868e-01,  1.3441e+00,  1.3542e+00],
        [ 1.1790e+00,  1.2050e+00,  1.2567e+00,  1.2385e+00,  1.2119e+00,
          1.1846e+00,  1.1914e+00,  1.1773e+00,  1.1773e+00,  1.2545e+00,
          1.2730e+00,  1.2700e+00,  1.2963e+00,  1.2395e+00,  1.3061e+00,
          1.2525e+00,  1.2288e+00,  1.2157e+00,  2.5825e+00,  2.6789e+00,
          2.7751e+00,  2.7034e+00,  2.4842e+00,  2.5754e+00,  2.6044e+00,
          2.4716e+00,  2.4716e+00,  1.2687e+00,  1.2564e+00,  1.2084e+00,
          1.2314e+00,  1.2682e+00,  1.2186e+00,  1.2493e+00,  1.2130e+00,
          1.2110e+00,  1.3712e+00,  1.4126e+00,  1.3890e+00,  1.3644e+00,
          1.3986e+00,  1.3872e+00,  1.3755e+00,  1.2992e+00,  1.3050e+00,
          1.2903e+00,  1.2749e+00,  1.2625e+00,  1.2429e+00,  1.2588e+00,
          1.2630e+00,  1.3213e+00,  1.2348e+00,  1.2412e+00],
        [ 1.1788e+00,  1.2062e+00,  1.2525e+00,  1.2337e+00,  1.2136e+00,
          1.1847e+00,  1.1922e+00,  1.1771e+00,  1.1771e+00,  1.2554e+00,
          1.2672e+00,  1.2715e+00,  1.2963e+00,  1.2399e+00,  1.2513e+00,
          1.2533e+00,  1.2415e+00,  1.1681e+00,  1.2234e+00,  1.2481e+00,
          1.2623e+00,  1.2360e+00,  1.1985e+00,  1.1894e+00,  1.2160e+00,
          1.1865e+00,  1.1865e+00,  2.8349e+00,  2.7201e+00,  2.3963e+00,
          2.5391e+00,  2.8297e+00,  2.4072e+00,  2.7854e+00,  2.4051e+00,
          2.3990e+00,  1.3605e+00,  1.4037e+00,  1.3759e+00,  1.3659e+00,
          1.3891e+00,  1.3764e+00,  1.3647e+00,  1.2832e+00,  1.3064e+00,
          1.3271e+00,  1.2733e+00,  1.1686e+00,  1.1972e+00,  1.3177e+00,
          1.2540e+00,  1.3593e+00,  1.1889e+00,  1.2412e+00],
        [ 1.6892e+00,  1.3745e+00,  6.3074e-01,  8.2959e-01,  1.1880e+00,
          1.5818e+00,  1.5217e+00,  1.6862e+00,  1.6862e+00,  1.5341e+00,
          1.2427e+00,  1.3750e+00,  9.1626e-01,  1.6236e+00,  2.8953e-01,
          1.5222e+00,  1.6452e+00,  1.1089e+00,  1.3159e+00,  8.9274e-01,
          7.8384e-01,  1.1056e+00,  1.5529e+00,  1.6078e+00,  1.3463e+00,
          1.6896e+00,  1.6896e+00,  7.2044e-01,  8.6735e-01,  1.6598e+00,
          1.4717e+00,  8.0613e-01,  1.5996e+00,  1.0926e+00,  1.7113e+00,
          1.6303e+00,  2.3381e-01,  1.0299e-02, -8.9505e-03,  1.9153e-01,
          4.4127e-01,  5.9805e-01,  1.3850e-01,  1.1441e+01,  7.5987e+00,
          7.9340e-01,  1.2079e+00,  1.3024e+00,  1.5208e+00,  1.0193e+00,
          1.4552e+00,  4.5658e-01,  1.5772e+00,  1.6845e+00],
        [ 1.2388e+00,  1.2702e+00,  1.3322e+00,  1.3113e+00,  1.2795e+00,
          1.2456e+00,  1.2105e+00,  1.2369e+00,  1.2369e+00,  1.2095e+00,
          1.3261e+00,  1.2278e+00,  1.3542e+00,  1.2862e+00,  1.4068e+00,
          1.2070e+00,  1.2884e+00,  1.2291e+00,  1.2872e+00,  1.3179e+00,
          1.3324e+00,  1.3011e+00,  1.2586e+00,  1.2500e+00,  1.1989e+00,
          1.2447e+00,  1.2447e+00,  1.3073e+00,  1.3490e+00,  1.2668e+00,
          1.0859e+00,  1.2604e+00,  1.1449e+00,  1.3147e+00,  1.1403e+00,
          1.2698e+00,  1.3628e+00,  1.0570e+00,  1.3837e+00,  1.3729e+00,
          9.5011e-01,  8.5369e-01,  1.3681e+00,  1.3587e+00,  7.3791e-01,
          3.1095e+00,  2.5001e+00,  3.2421e+00,  2.7524e+00,  2.1177e+00,
          1.8135e+00,  2.8690e+00,  3.0286e+00,  1.7927e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 183 : 180.3722624780258
Test loss for epoch 183 : 180.48126876528207
Test Precision for epoch 183 : 0.26153846153846155
Test Recall for epoch 183 : 0.26153846153846155
Test F1 for epoch 183 : 0.26153846153846155


theta for epoch 184 : tensor([[ 2.5308e+00,  2.5608e+00,  2.6344e+00,  2.7439e+00,  2.7069e+00,
          2.5370e+00,  2.6828e+00,  2.5290e+00,  2.5290e+00,  1.2469e+00,
          1.2653e+00,  1.2623e+00,  1.2884e+00,  1.2321e+00,  1.3330e+00,
          1.2449e+00,  1.2339e+00,  1.2170e+00,  1.2152e+00,  1.1973e+00,
          1.2087e+00,  1.2272e+00,  1.1916e+00,  1.1850e+00,  1.2086e+00,
          1.1802e+00,  1.1802e+00,  1.2257e+00,  1.2677e+00,  1.1984e+00,
          1.2213e+00,  1.2695e+00,  1.2084e+00,  1.2389e+00,  1.1586e+00,
          1.2009e+00,  1.3651e+00,  1.4063e+00,  1.3828e+00,  1.3732e+00,
          1.3924e+00,  1.3240e+00,  1.3694e+00,  1.3625e+00,  1.3142e+00,
          1.3146e+00,  1.2658e+00,  1.2535e+00,  1.2341e+00,  1.3057e+00,
          1.2540e+00,  1.3455e+00,  1.2262e+00,  1.2325e+00],
        [ 1.2695e+00,  1.1809e+00,  1.0026e+00,  1.2243e+00,  1.3035e+00,
          1.3204e+00,  1.2446e+00,  1.3112e+00,  1.3112e+00,  1.5078e+00,
          1.7448e+00,  1.5141e+00,  2.2489e+00,  1.5469e+00,  5.6790e+00,
          1.6139e+00,  1.4416e+00,  5.5108e+00,  1.1040e+00,  1.1864e+00,
          9.7712e-01,  1.1512e+00,  1.2867e+00,  1.3205e+00,  1.2875e+00,
          1.3149e+00,  1.3149e+00,  1.2917e+00,  1.0205e+00,  1.3330e+00,
          1.3124e+00,  1.1310e+00,  1.3456e+00,  1.3788e+00,  1.2945e+00,
          1.3293e+00,  1.3117e+00,  1.4603e+00,  1.3710e+00,  1.2815e+00,
          1.2978e+00,  1.4258e+00,  1.3540e+00,  4.8060e-01,  1.3364e+00,
          1.0221e+00,  1.3938e+00,  1.3752e+00,  1.3519e+00,  1.0397e+00,
          1.3779e+00,  8.6679e-01,  1.3419e+00,  1.3521e+00],
        [ 1.1854e+00,  1.2115e+00,  1.2630e+00,  1.2449e+00,  1.2184e+00,
          1.1910e+00,  1.1979e+00,  1.1838e+00,  1.1838e+00,  1.2544e+00,
          1.2730e+00,  1.2700e+00,  1.2963e+00,  1.2394e+00,  1.3062e+00,
          1.2524e+00,  1.2286e+00,  1.2163e+00,  2.5856e+00,  2.6826e+00,
          2.7782e+00,  2.7061e+00,  2.4877e+00,  2.5786e+00,  2.6078e+00,
          2.4752e+00,  2.4752e+00,  1.2669e+00,  1.2549e+00,  1.2067e+00,
          1.2297e+00,  1.2663e+00,  1.2169e+00,  1.2476e+00,  1.2113e+00,
          1.2093e+00,  1.3698e+00,  1.4114e+00,  1.3876e+00,  1.3629e+00,
          1.3973e+00,  1.3859e+00,  1.3742e+00,  1.2985e+00,  1.3035e+00,
          1.2891e+00,  1.2733e+00,  1.2609e+00,  1.2414e+00,  1.2579e+00,
          1.2615e+00,  1.3201e+00,  1.2333e+00,  1.2397e+00],
        [ 1.1821e+00,  1.2094e+00,  1.2558e+00,  1.2369e+00,  1.2168e+00,
          1.1880e+00,  1.1954e+00,  1.1804e+00,  1.1804e+00,  1.2553e+00,
          1.2673e+00,  1.2713e+00,  1.2962e+00,  1.2398e+00,  1.2511e+00,
          1.2532e+00,  1.2413e+00,  1.1684e+00,  1.2254e+00,  1.2501e+00,
          1.2644e+00,  1.2381e+00,  1.2005e+00,  1.1915e+00,  1.2180e+00,
          1.1885e+00,  1.1885e+00,  2.8370e+00,  2.7245e+00,  2.3997e+00,
          2.5430e+00,  2.8318e+00,  2.4106e+00,  2.7876e+00,  2.4085e+00,
          2.4023e+00,  1.3595e+00,  1.4027e+00,  1.3750e+00,  1.3650e+00,
          1.3882e+00,  1.3755e+00,  1.3638e+00,  1.2827e+00,  1.3055e+00,
          1.3257e+00,  1.2721e+00,  1.1675e+00,  1.1960e+00,  1.3164e+00,
          1.2530e+00,  1.3579e+00,  1.1876e+00,  1.2399e+00],
        [ 1.6928e+00,  1.3780e+00,  6.3344e-01,  8.3252e-01,  1.1914e+00,
          1.5854e+00,  1.5252e+00,  1.6897e+00,  1.6897e+00,  1.5349e+00,
          1.2431e+00,  1.3757e+00,  9.1692e-01,  1.6242e+00,  2.9026e-01,
          1.5229e+00,  1.6461e+00,  1.1089e+00,  1.3182e+00,  8.9494e-01,
          7.8582e-01,  1.1077e+00,  1.5553e+00,  1.6100e+00,  1.3488e+00,
          1.6919e+00,  1.6919e+00,  7.2023e-01,  8.6696e-01,  1.6592e+00,
          1.4713e+00,  8.0583e-01,  1.5990e+00,  1.0920e+00,  1.7107e+00,
          1.6296e+00,  2.3187e-01,  8.2724e-03, -1.0824e-02,  1.8948e-01,
          4.3898e-01,  5.9553e-01,  1.3651e-01,  1.1484e+01,  7.5945e+00,
          7.9250e-01,  1.2070e+00,  1.3016e+00,  1.5198e+00,  1.0181e+00,
          1.4540e+00,  4.5572e-01,  1.5764e+00,  1.6835e+00],
        [ 1.2424e+00,  1.2738e+00,  1.3358e+00,  1.3149e+00,  1.2831e+00,
          1.2492e+00,  1.2141e+00,  1.2405e+00,  1.2405e+00,  1.2091e+00,
          1.3257e+00,  1.2273e+00,  1.3538e+00,  1.2858e+00,  1.4063e+00,
          1.2066e+00,  1.2881e+00,  1.2287e+00,  1.2892e+00,  1.3199e+00,
          1.3344e+00,  1.3032e+00,  1.2606e+00,  1.2520e+00,  1.2007e+00,
          1.2467e+00,  1.2467e+00,  1.3057e+00,  1.3473e+00,  1.2652e+00,
          1.0840e+00,  1.2587e+00,  1.1433e+00,  1.3131e+00,  1.1387e+00,
          1.2682e+00,  1.3612e+00,  1.0551e+00,  1.3822e+00,  1.3714e+00,
          9.4817e-01,  8.5178e-01,  1.3666e+00,  1.3570e+00,  7.3596e-01,
          3.1148e+00,  2.5019e+00,  3.2486e+00,  2.7552e+00,  2.1187e+00,
          1.8141e+00,  2.8719e+00,  3.0338e+00,  1.7933e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 184 : 180.37384118010317
Test loss for epoch 184 : 180.4842886536098
Test Precision for epoch 184 : 0.26153846153846155
Test Recall for epoch 184 : 0.26153846153846155
Test F1 for epoch 184 : 0.26153846153846155


theta for epoch 185 : tensor([[ 2.5119e+00,  2.5420e+00,  2.6159e+00,  2.7256e+00,  2.6887e+00,
          2.5181e+00,  2.6643e+00,  2.5101e+00,  2.5101e+00,  1.2571e+00,
          1.2754e+00,  1.2724e+00,  1.2985e+00,  1.2422e+00,  1.3428e+00,
          1.2550e+00,  1.2441e+00,  1.2273e+00,  1.2352e+00,  1.2175e+00,
          1.2286e+00,  1.2471e+00,  1.2116e+00,  1.2050e+00,  1.2285e+00,
          1.2003e+00,  1.2003e+00,  1.2336e+00,  1.2753e+00,  1.2061e+00,
          1.2290e+00,  1.2772e+00,  1.2162e+00,  1.2466e+00,  1.1666e+00,
          1.2087e+00,  1.3684e+00,  1.4096e+00,  1.3862e+00,  1.3766e+00,
          1.3957e+00,  1.3276e+00,  1.3728e+00,  1.3657e+00,  1.3175e+00,
          1.3197e+00,  1.2711e+00,  1.2587e+00,  1.2393e+00,  1.3109e+00,
          1.2592e+00,  1.3506e+00,  1.2314e+00,  1.2377e+00],
        [ 1.2514e+00,  1.1633e+00,  9.8659e-01,  1.2067e+00,  1.2859e+00,
          1.3023e+00,  1.2265e+00,  1.2931e+00,  1.2931e+00,  1.5113e+00,
          1.7477e+00,  1.5176e+00,  2.2512e+00,  1.5504e+00,  5.6989e+00,
          1.6174e+00,  1.4452e+00,  5.5319e+00,  1.1121e+00,  1.1947e+00,
          9.8450e-01,  1.1594e+00,  1.2953e+00,  1.3292e+00,  1.2959e+00,
          1.3236e+00,  1.3236e+00,  1.2927e+00,  1.0214e+00,  1.3341e+00,
          1.3135e+00,  1.1319e+00,  1.3467e+00,  1.3800e+00,  1.2956e+00,
          1.3306e+00,  1.3115e+00,  1.4599e+00,  1.3705e+00,  1.2810e+00,
          1.2976e+00,  1.4254e+00,  1.3535e+00,  4.7986e-01,  1.3357e+00,
          1.0224e+00,  1.3942e+00,  1.3756e+00,  1.3522e+00,  1.0398e+00,
          1.3783e+00,  8.6723e-01,  1.3422e+00,  1.3525e+00],
        [ 1.1642e+00,  1.1903e+00,  1.2420e+00,  1.2238e+00,  1.1972e+00,
          1.1699e+00,  1.1767e+00,  1.1626e+00,  1.1626e+00,  1.2541e+00,
          1.2728e+00,  1.2697e+00,  1.2960e+00,  1.2391e+00,  1.3061e+00,
          1.2521e+00,  1.2281e+00,  1.2165e+00,  2.5984e+00,  2.6960e+00,
          2.7910e+00,  2.7185e+00,  2.5012e+00,  2.5918e+00,  2.6211e+00,
          2.4887e+00,  2.4887e+00,  1.2658e+00,  1.2543e+00,  1.2059e+00,
          1.2289e+00,  1.2653e+00,  1.2160e+00,  1.2468e+00,  1.2104e+00,
          1.2084e+00,  1.3683e+00,  1.4099e+00,  1.3862e+00,  1.3612e+00,
          1.3958e+00,  1.3844e+00,  1.3728e+00,  1.2976e+00,  1.3016e+00,
          1.2881e+00,  1.2721e+00,  1.2596e+00,  1.2401e+00,  1.2572e+00,
          1.2603e+00,  1.3191e+00,  1.2320e+00,  1.2385e+00],
        [ 1.1679e+00,  1.1953e+00,  1.2428e+00,  1.2241e+00,  1.2028e+00,
          1.1738e+00,  1.1813e+00,  1.1662e+00,  1.1662e+00,  1.2570e+00,
          1.2692e+00,  1.2730e+00,  1.2979e+00,  1.2415e+00,  1.2526e+00,
          1.2549e+00,  1.2431e+00,  1.1702e+00,  1.2325e+00,  1.2567e+00,
          1.2713e+00,  1.2451e+00,  1.2075e+00,  1.1986e+00,  1.2250e+00,
          1.1956e+00,  1.1956e+00,  2.8409e+00,  2.7308e+00,  2.4050e+00,
          2.5488e+00,  2.8358e+00,  2.4159e+00,  2.7916e+00,  2.4138e+00,
          2.4077e+00,  1.3593e+00,  1.4026e+00,  1.3750e+00,  1.3650e+00,
          1.3880e+00,  1.3754e+00,  1.3637e+00,  1.2829e+00,  1.3053e+00,
          1.3257e+00,  1.2723e+00,  1.1677e+00,  1.1962e+00,  1.3165e+00,
          1.2535e+00,  1.3579e+00,  1.1878e+00,  1.2401e+00],
        [ 1.6797e+00,  1.3653e+00,  6.2423e-01,  8.2237e-01,  1.1790e+00,
          1.5724e+00,  1.5123e+00,  1.6767e+00,  1.6767e+00,  1.5376e+00,
          1.2454e+00,  1.3782e+00,  9.1878e-01,  1.6270e+00,  2.9147e-01,
          1.5255e+00,  1.6491e+00,  1.1104e+00,  1.3249e+00,  9.0085e-01,
          7.9128e-01,  1.1139e+00,  1.5626e+00,  1.6170e+00,  1.3558e+00,
          1.6993e+00,  1.6993e+00,  7.2158e-01,  8.6819e-01,  1.6610e+00,
          1.4733e+00,  8.0720e-01,  1.6008e+00,  1.0935e+00,  1.7125e+00,
          1.6313e+00,  2.3125e-01,  7.5192e-03, -1.1423e-02,  1.8875e-01,
          4.3801e-01,  5.9435e-01,  1.3582e-01,  1.1528e+01,  7.5911e+00,
          7.9341e-01,  1.2084e+00,  1.3031e+00,  1.5213e+00,  1.0190e+00,
          1.4553e+00,  4.5620e-01,  1.5781e+00,  1.6850e+00],
        [ 1.2266e+00,  1.2580e+00,  1.3203e+00,  1.2992e+00,  1.2673e+00,
          1.2334e+00,  1.1983e+00,  1.2246e+00,  1.2246e+00,  1.2113e+00,
          1.3281e+00,  1.2295e+00,  1.3561e+00,  1.2882e+00,  1.4085e+00,
          1.2089e+00,  1.2904e+00,  1.2309e+00,  1.2965e+00,  1.3271e+00,
          1.3414e+00,  1.3105e+00,  1.2680e+00,  1.2594e+00,  1.2077e+00,
          1.2541e+00,  1.2541e+00,  1.3064e+00,  1.3481e+00,  1.2661e+00,
          1.0845e+00,  1.2595e+00,  1.1440e+00,  1.3139e+00,  1.1394e+00,
          1.2691e+00,  1.3609e+00,  1.0543e+00,  1.3819e+00,  1.3711e+00,
          9.4724e-01,  8.5084e-01,  1.3663e+00,  1.3564e+00,  7.3490e-01,
          3.1225e+00,  2.5063e+00,  3.2577e+00,  2.7605e+00,  2.1222e+00,
          1.8173e+00,  2.8773e+00,  3.0417e+00,  1.7966e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 185 : 180.4351657345916
Test loss for epoch 185 : 180.54601025544108
Test Precision for epoch 185 : 0.26153846153846155
Test Recall for epoch 185 : 0.26153846153846155
Test F1 for epoch 185 : 0.26153846153846155


theta for epoch 186 : tensor([[ 2.5382e+00,  2.5682e+00,  2.6418e+00,  2.7520e+00,  2.7151e+00,
          2.5444e+00,  2.6910e+00,  2.5364e+00,  2.5364e+00,  1.2449e+00,
          1.2633e+00,  1.2603e+00,  1.2865e+00,  1.2300e+00,  1.3311e+00,
          1.2428e+00,  1.2318e+00,  1.2149e+00,  1.2047e+00,  1.1868e+00,
          1.1982e+00,  1.2167e+00,  1.1812e+00,  1.1746e+00,  1.1982e+00,
          1.1699e+00,  1.1699e+00,  1.2270e+00,  1.2690e+00,  1.1997e+00,
          1.2226e+00,  1.2709e+00,  1.2098e+00,  1.2403e+00,  1.1599e+00,
          1.2022e+00,  1.3655e+00,  1.4068e+00,  1.3833e+00,  1.3737e+00,
          1.3929e+00,  1.3245e+00,  1.3699e+00,  1.3627e+00,  1.3145e+00,
          1.3153e+00,  1.2666e+00,  1.2542e+00,  1.2348e+00,  1.3065e+00,
          1.2548e+00,  1.3463e+00,  1.2269e+00,  1.2332e+00],
        [ 1.2708e+00,  1.1824e+00,  1.0047e+00,  1.2258e+00,  1.3051e+00,
          1.3215e+00,  1.2459e+00,  1.3124e+00,  1.3124e+00,  1.5033e+00,
          1.7391e+00,  1.5095e+00,  2.2423e+00,  1.5423e+00,  5.7089e+00,
          1.6092e+00,  1.4372e+00,  5.5422e+00,  1.0959e+00,  1.1785e+00,
          9.7066e-01,  1.1432e+00,  1.2782e+00,  1.3119e+00,  1.2787e+00,
          1.3062e+00,  1.3062e+00,  1.2966e+00,  1.0259e+00,  1.3377e+00,
          1.3172e+00,  1.1362e+00,  1.3503e+00,  1.3836e+00,  1.2993e+00,
          1.3344e+00,  1.3151e+00,  1.4631e+00,  1.3738e+00,  1.2845e+00,
          1.3013e+00,  1.4287e+00,  1.3568e+00,  4.8449e-01,  1.3388e+00,
          1.0268e+00,  1.3976e+00,  1.3789e+00,  1.3556e+00,  1.0440e+00,
          1.3818e+00,  8.7207e-01,  1.3455e+00,  1.3559e+00],
        [ 1.1882e+00,  1.2141e+00,  1.2654e+00,  1.2474e+00,  1.2210e+00,
          1.1938e+00,  1.2006e+00,  1.1866e+00,  1.1866e+00,  1.2562e+00,
          1.2750e+00,  1.2718e+00,  1.2983e+00,  1.2412e+00,  1.3084e+00,
          1.2542e+00,  1.2300e+00,  1.2196e+00,  2.5818e+00,  2.6803e+00,
          2.7750e+00,  2.7018e+00,  2.4849e+00,  2.5752e+00,  2.6049e+00,
          2.4723e+00,  2.4723e+00,  1.2717e+00,  1.2607e+00,  1.2118e+00,
          1.2348e+00,  1.2712e+00,  1.2220e+00,  1.2527e+00,  1.2164e+00,
          1.2144e+00,  1.3729e+00,  1.4145e+00,  1.3907e+00,  1.3656e+00,
          1.4004e+00,  1.3890e+00,  1.3773e+00,  1.3029e+00,  1.3061e+00,
          1.2933e+00,  1.2770e+00,  1.2645e+00,  1.2450e+00,  1.2628e+00,
          1.2651e+00,  1.3243e+00,  1.2368e+00,  1.2434e+00],
        [ 1.1807e+00,  1.2080e+00,  1.2548e+00,  1.2359e+00,  1.2154e+00,
          1.1866e+00,  1.1940e+00,  1.1790e+00,  1.1790e+00,  1.2545e+00,
          1.2671e+00,  1.2706e+00,  1.2957e+00,  1.2390e+00,  1.2504e+00,
          1.2524e+00,  1.2406e+00,  1.1686e+00,  1.2161e+00,  1.2413e+00,
          1.2550e+00,  1.2288e+00,  1.1912e+00,  1.1824e+00,  1.2087e+00,
          1.1792e+00,  1.1792e+00,  2.8432e+00,  2.7354e+00,  2.4086e+00,
          2.5529e+00,  2.8381e+00,  2.4195e+00,  2.7940e+00,  2.4173e+00,
          2.4113e+00,  1.3613e+00,  1.4046e+00,  1.3770e+00,  1.3671e+00,
          1.3901e+00,  1.3775e+00,  1.3657e+00,  1.2851e+00,  1.3073e+00,
          1.3271e+00,  1.2737e+00,  1.1691e+00,  1.1976e+00,  1.3179e+00,
          1.2551e+00,  1.3593e+00,  1.1892e+00,  1.2415e+00],
        [ 1.6922e+00,  1.3774e+00,  6.3256e-01,  8.3172e-01,  1.1906e+00,
          1.5848e+00,  1.5246e+00,  1.6892e+00,  1.6892e+00,  1.5340e+00,
          1.2414e+00,  1.3747e+00,  9.1535e-01,  1.6234e+00,  2.8897e-01,
          1.5220e+00,  1.6457e+00,  1.1060e+00,  1.3109e+00,  8.8814e-01,
          7.7889e-01,  1.1002e+00,  1.5478e+00,  1.6019e+00,  1.3422e+00,
          1.6844e+00,  1.6844e+00,  7.2226e-01,  8.6881e-01,  1.6622e+00,
          1.4745e+00,  8.0792e-01,  1.6019e+00,  1.0942e+00,  1.7137e+00,
          1.6323e+00,  2.3148e-01,  7.6328e-03, -1.1166e-02,  1.8887e-01,
          4.3791e-01,  5.9403e-01,  1.3598e-01,  1.1572e+01,  7.5880e+00,
          7.9441e-01,  1.2097e+00,  1.3046e+00,  1.5229e+00,  1.0200e+00,
          1.4566e+00,  4.5678e-01,  1.5799e+00,  1.6867e+00],
        [ 1.2412e+00,  1.2725e+00,  1.3344e+00,  1.3136e+00,  1.2818e+00,
          1.2480e+00,  1.2128e+00,  1.2392e+00,  1.2392e+00,  1.2080e+00,
          1.3248e+00,  1.2263e+00,  1.3529e+00,  1.2848e+00,  1.4054e+00,
          1.2055e+00,  1.2870e+00,  1.2277e+00,  1.2798e+00,  1.3104e+00,
          1.3253e+00,  1.2938e+00,  1.2511e+00,  1.2426e+00,  1.1908e+00,
          1.2373e+00,  1.2373e+00,  1.3079e+00,  1.3495e+00,  1.2676e+00,
          1.0857e+00,  1.2609e+00,  1.1456e+00,  1.3154e+00,  1.1410e+00,
          1.2707e+00,  1.3633e+00,  1.0567e+00,  1.3843e+00,  1.3736e+00,
          9.4959e-01,  8.5318e-01,  1.3689e+00,  1.3589e+00,  7.3722e-01,
          3.1280e+00,  2.5084e+00,  3.2644e+00,  2.7635e+00,  2.1235e+00,
          1.8183e+00,  2.8805e+00,  3.0471e+00,  1.7976e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 186 : 180.41387910675851
Test loss for epoch 186 : 180.52555527488252
Test Precision for epoch 186 : 0.26153846153846155
Test Recall for epoch 186 : 0.26153846153846155
Test F1 for epoch 186 : 0.26153846153846155


theta for epoch 187 : tensor([[ 2.5353e+00,  2.5653e+00,  2.6391e+00,  2.7496e+00,  2.7127e+00,
          2.5415e+00,  2.6885e+00,  2.5335e+00,  2.5335e+00,  1.2497e+00,
          1.2682e+00,  1.2651e+00,  1.2914e+00,  1.2348e+00,  1.3358e+00,
          1.2476e+00,  1.2366e+00,  1.2198e+00,  1.2175e+00,  1.1995e+00,
          1.2107e+00,  1.2294e+00,  1.1941e+00,  1.1876e+00,  1.2110e+00,
          1.1828e+00,  1.1828e+00,  1.2247e+00,  1.2667e+00,  1.1972e+00,
          1.2202e+00,  1.2686e+00,  1.2073e+00,  1.2380e+00,  1.1575e+00,
          1.1998e+00,  1.3655e+00,  1.4070e+00,  1.3834e+00,  1.3738e+00,
          1.3931e+00,  1.3247e+00,  1.3700e+00,  1.3626e+00,  1.3146e+00,
          1.3145e+00,  1.2657e+00,  1.2532e+00,  1.2339e+00,  1.3056e+00,
          1.2539e+00,  1.3455e+00,  1.2259e+00,  1.2323e+00],
        [ 1.2631e+00,  1.1749e+00,  9.9793e-01,  1.2183e+00,  1.2977e+00,
          1.3139e+00,  1.2383e+00,  1.3047e+00,  1.3047e+00,  1.5057e+00,
          1.7409e+00,  1.5119e+00,  2.2434e+00,  1.5446e+00,  5.7274e+00,
          1.6115e+00,  1.4397e+00,  5.5618e+00,  1.1060e+00,  1.1886e+00,
          9.7987e-01,  1.1532e+00,  1.2886e+00,  1.3224e+00,  1.2888e+00,
          1.3167e+00,  1.3167e+00,  1.2932e+00,  1.0224e+00,  1.3342e+00,
          1.3139e+00,  1.1327e+00,  1.3469e+00,  1.3803e+00,  1.2958e+00,
          1.3311e+00,  1.3148e+00,  1.4627e+00,  1.3732e+00,  1.2840e+00,
          1.3011e+00,  1.4284e+00,  1.3562e+00,  4.8404e-01,  1.3382e+00,
          1.0253e+00,  1.3959e+00,  1.3771e+00,  1.3537e+00,  1.0422e+00,
          1.3800e+00,  8.7088e-01,  1.3436e+00,  1.3541e+00],
        [ 1.1728e+00,  1.1987e+00,  1.2499e+00,  1.2319e+00,  1.2056e+00,
          1.1784e+00,  1.1852e+00,  1.1712e+00,  1.1712e+00,  1.2519e+00,
          1.2707e+00,  1.2675e+00,  1.2941e+00,  1.2368e+00,  1.3046e+00,
          1.2499e+00,  1.2254e+00,  1.2157e+00,  2.6028e+00,  2.7018e+00,
          2.7957e+00,  2.7223e+00,  2.5066e+00,  2.5966e+00,  2.6264e+00,
          2.4941e+00,  2.4941e+00,  1.2617e+00,  1.2511e+00,  1.2020e+00,
          1.2250e+00,  1.2611e+00,  1.2121e+00,  1.2430e+00,  1.2065e+00,
          1.2046e+00,  1.3688e+00,  1.4106e+00,  1.3867e+00,  1.3614e+00,
          1.3965e+00,  1.3851e+00,  1.3734e+00,  1.2995e+00,  1.3018e+00,
          1.2871e+00,  1.2705e+00,  1.2580e+00,  1.2385e+00,  1.2569e+00,
          1.2587e+00,  1.3183e+00,  1.2303e+00,  1.2369e+00],
        [ 1.1762e+00,  1.2035e+00,  1.2507e+00,  1.2319e+00,  1.2109e+00,
          1.1821e+00,  1.1895e+00,  1.1745e+00,  1.1745e+00,  1.2595e+00,
          1.2723e+00,  1.2756e+00,  1.3007e+00,  1.2441e+00,  1.2554e+00,
          1.2575e+00,  1.2456e+00,  1.1735e+00,  1.2267e+00,  1.2512e+00,
          1.2654e+00,  1.2393e+00,  1.2019e+00,  1.1931e+00,  1.2193e+00,
          1.1899e+00,  1.1899e+00,  2.8429e+00,  2.7373e+00,  2.4095e+00,
          2.5542e+00,  2.8379e+00,  2.4204e+00,  2.7937e+00,  2.4182e+00,
          2.4121e+00,  1.3622e+00,  1.4056e+00,  1.3780e+00,  1.3680e+00,
          1.3910e+00,  1.3785e+00,  1.3666e+00,  1.2863e+00,  1.3083e+00,
          1.3269e+00,  1.2737e+00,  1.1691e+00,  1.1976e+00,  1.3177e+00,
          1.2553e+00,  1.3591e+00,  1.1891e+00,  1.2413e+00],
        [ 1.6882e+00,  1.3741e+00,  6.3139e-01,  8.3006e-01,  1.1877e+00,
          1.5810e+00,  1.5210e+00,  1.6851e+00,  1.6851e+00,  1.5395e+00,
          1.2470e+00,  1.3802e+00,  9.2088e-01,  1.6287e+00,  2.9414e-01,
          1.5273e+00,  1.6511e+00,  1.1111e+00,  1.3212e+00,  8.9833e-01,
          7.8868e-01,  1.1105e+00,  1.5584e+00,  1.6122e+00,  1.3528e+00,
          1.6949e+00,  1.6949e+00,  7.2305e-01,  8.6917e-01,  1.6614e+00,
          1.4742e+00,  8.0854e-01,  1.6013e+00,  1.0942e+00,  1.7129e+00,
          1.6315e+00,  2.2814e-01,  4.3331e-03, -1.4333e-02,  1.8543e-01,
          4.3417e-01,  5.8995e-01,  1.3263e-01,  1.1613e+01,  7.5810e+00,
          7.9589e-01,  1.2104e+00,  1.3053e+00,  1.5230e+00,  1.0208e+00,
          1.4567e+00,  4.5882e-01,  1.5801e+00,  1.6866e+00],
        [ 1.2359e+00,  1.2673e+00,  1.3292e+00,  1.3084e+00,  1.2766e+00,
          1.2427e+00,  1.2076e+00,  1.2340e+00,  1.2340e+00,  1.2143e+00,
          1.3311e+00,  1.2326e+00,  1.3593e+00,  1.2910e+00,  1.4116e+00,
          1.2119e+00,  1.2932e+00,  1.2342e+00,  1.2905e+00,  1.3210e+00,
          1.3355e+00,  1.3045e+00,  1.2620e+00,  1.2535e+00,  1.2014e+00,
          1.2482e+00,  1.2482e+00,  1.3065e+00,  1.3480e+00,  1.2660e+00,
          1.0842e+00,  1.2596e+00,  1.1442e+00,  1.3140e+00,  1.1395e+00,
          1.2691e+00,  1.3640e+00,  1.0574e+00,  1.3850e+00,  1.3743e+00,
          9.5033e-01,  8.5405e-01,  1.3695e+00,  1.3595e+00,  7.3809e-01,
          3.1303e+00,  2.5071e+00,  3.2678e+00,  2.7632e+00,  2.1215e+00,
          1.8160e+00,  2.8805e+00,  3.0492e+00,  1.7952e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 187 : 180.34762755565154
Test loss for epoch 187 : 180.46146321027436
Test Precision for epoch 187 : 0.26153846153846155
Test Recall for epoch 187 : 0.26153846153846155
Test F1 for epoch 187 : 0.26153846153846155


theta for epoch 188 : tensor([[ 2.5313e+00,  2.5614e+00,  2.6352e+00,  2.7461e+00,  2.7092e+00,
          2.5375e+00,  2.6848e+00,  2.5295e+00,  2.5295e+00,  1.2512e+00,
          1.2697e+00,  1.2666e+00,  1.2929e+00,  1.2363e+00,  1.3373e+00,
          1.2492e+00,  1.2382e+00,  1.2215e+00,  1.2264e+00,  1.2084e+00,
          1.2195e+00,  1.2383e+00,  1.2030e+00,  1.1964e+00,  1.2198e+00,
          1.1917e+00,  1.1917e+00,  1.2278e+00,  1.2696e+00,  1.2002e+00,
          1.2232e+00,  1.2716e+00,  1.2103e+00,  1.2410e+00,  1.1606e+00,
          1.2028e+00,  1.3656e+00,  1.4072e+00,  1.3835e+00,  1.3740e+00,
          1.3932e+00,  1.3249e+00,  1.3701e+00,  1.3625e+00,  1.3147e+00,
          1.3155e+00,  1.2668e+00,  1.2543e+00,  1.2350e+00,  1.3067e+00,
          1.2550e+00,  1.3465e+00,  1.2270e+00,  1.2334e+00],
        [ 1.2582e+00,  1.1701e+00,  9.9353e-01,  1.2136e+00,  1.2931e+00,
          1.3090e+00,  1.2334e+00,  1.2999e+00,  1.2999e+00,  1.5074e+00,
          1.7421e+00,  1.5136e+00,  2.2440e+00,  1.5463e+00,  5.7456e+00,
          1.6132e+00,  1.4415e+00,  5.5810e+00,  1.1100e+00,  1.1928e+00,
          9.8359e-01,  1.1572e+00,  1.2929e+00,  1.3267e+00,  1.2930e+00,
          1.3210e+00,  1.3210e+00,  1.2932e+00,  1.0222e+00,  1.3343e+00,
          1.3139e+00,  1.1326e+00,  1.3470e+00,  1.3804e+00,  1.2958e+00,
          1.3313e+00,  1.3136e+00,  1.4613e+00,  1.3717e+00,  1.2826e+00,
          1.2999e+00,  1.4270e+00,  1.3547e+00,  4.8237e-01,  1.3366e+00,
          1.0242e+00,  1.3948e+00,  1.3759e+00,  1.3526e+00,  1.0409e+00,
          1.3790e+00,  8.6995e-01,  1.3424e+00,  1.3530e+00],
        [ 1.1675e+00,  1.1934e+00,  1.2447e+00,  1.2267e+00,  1.2003e+00,
          1.1731e+00,  1.1799e+00,  1.1659e+00,  1.1659e+00,  1.2489e+00,
          1.2678e+00,  1.2646e+00,  1.2913e+00,  1.2339e+00,  1.3020e+00,
          1.2469e+00,  1.2223e+00,  1.2134e+00,  2.6106e+00,  2.7101e+00,
          2.8034e+00,  2.7296e+00,  2.5149e+00,  2.6046e+00,  2.6345e+00,
          2.5024e+00,  2.5024e+00,  1.2609e+00,  1.2508e+00,  1.2014e+00,
          1.2244e+00,  1.2604e+00,  1.2116e+00,  1.2425e+00,  1.2060e+00,
          1.2040e+00,  1.3671e+00,  1.4089e+00,  1.3850e+00,  1.3594e+00,
          1.3948e+00,  1.3834e+00,  1.3716e+00,  1.2983e+00,  1.2997e+00,
          1.2859e+00,  1.2690e+00,  1.2564e+00,  1.2370e+00,  1.2560e+00,
          1.2571e+00,  1.3170e+00,  1.2287e+00,  1.2353e+00],
        [ 1.1726e+00,  1.1999e+00,  1.2475e+00,  1.2288e+00,  1.2074e+00,
          1.1785e+00,  1.1859e+00,  1.1709e+00,  1.1709e+00,  1.2581e+00,
          1.2711e+00,  1.2741e+00,  1.2993e+00,  1.2426e+00,  1.2539e+00,
          1.2560e+00,  1.2441e+00,  1.1726e+00,  1.2308e+00,  1.2551e+00,
          1.2695e+00,  1.2434e+00,  1.2060e+00,  1.1972e+00,  1.2233e+00,
          1.1940e+00,  1.1940e+00,  2.8461e+00,  2.7426e+00,  2.4139e+00,
          2.5591e+00,  2.8410e+00,  2.4248e+00,  2.7969e+00,  2.4225e+00,
          2.4165e+00,  1.3615e+00,  1.4049e+00,  1.3774e+00,  1.3674e+00,
          1.3903e+00,  1.3779e+00,  1.3659e+00,  1.2860e+00,  1.3076e+00,
          1.3262e+00,  1.2732e+00,  1.1686e+00,  1.1970e+00,  1.3171e+00,
          1.2550e+00,  1.3584e+00,  1.1886e+00,  1.2408e+00],
        [ 1.6857e+00,  1.3719e+00,  6.3018e-01,  8.2860e-01,  1.1855e+00,
          1.5786e+00,  1.5187e+00,  1.6826e+00,  1.6826e+00,  1.5397e+00,
          1.2471e+00,  1.3806e+00,  9.2135e-01,  1.6289e+00,  2.9492e-01,
          1.5275e+00,  1.6515e+00,  1.1107e+00,  1.3260e+00,  9.0293e-01,
          7.9299e-01,  1.1151e+00,  1.5634e+00,  1.6170e+00,  1.3578e+00,
          1.6998e+00,  1.6998e+00,  7.2492e-01,  8.7075e-01,  1.6631e+00,
          1.4760e+00,  8.1039e-01,  1.6029e+00,  1.0959e+00,  1.7146e+00,
          1.6330e+00,  2.2609e-01,  2.1998e-03, -1.6326e-02,  1.8325e-01,
          4.3176e-01,  5.8727e-01,  1.3051e-01,  1.1656e+01,  7.5750e+00,
          7.9667e-01,  1.2112e+00,  1.3061e+00,  1.5236e+00,  1.0213e+00,
          1.4572e+00,  4.5961e-01,  1.5808e+00,  1.6871e+00],
        [ 1.2322e+00,  1.2636e+00,  1.3256e+00,  1.3047e+00,  1.2729e+00,
          1.2390e+00,  1.2039e+00,  1.2302e+00,  1.2302e+00,  1.2126e+00,
          1.3295e+00,  1.2309e+00,  1.3576e+00,  1.2894e+00,  1.4098e+00,
          1.2102e+00,  1.2916e+00,  1.2325e+00,  1.2951e+00,  1.3254e+00,
          1.3398e+00,  1.3090e+00,  1.2665e+00,  1.2581e+00,  1.2057e+00,
          1.2527e+00,  1.2527e+00,  1.3070e+00,  1.3485e+00,  1.2666e+00,
          1.0844e+00,  1.2601e+00,  1.1447e+00,  1.3145e+00,  1.1400e+00,
          1.2697e+00,  1.3629e+00,  1.0560e+00,  1.3839e+00,  1.3733e+00,
          9.4887e-01,  8.5261e-01,  1.3685e+00,  1.3583e+00,  7.3660e-01,
          3.1361e+00,  2.5095e+00,  3.2749e+00,  2.7665e+00,  2.1231e+00,
          1.8173e+00,  2.8840e+00,  3.0549e+00,  1.7965e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 188 : 180.37192872397674
Test loss for epoch 188 : 180.48643273467246
Test Precision for epoch 188 : 0.26153846153846155
Test Recall for epoch 188 : 0.26153846153846155
Test F1 for epoch 188 : 0.26153846153846155


theta for epoch 189 : tensor([[ 2.5453e+00,  2.5753e+00,  2.6491e+00,  2.7603e+00,  2.7235e+00,
          2.5515e+00,  2.6992e+00,  2.5435e+00,  2.5435e+00,  1.2448e+00,
          1.2633e+00,  1.2602e+00,  1.2865e+00,  1.2299e+00,  1.3310e+00,
          1.2427e+00,  1.2317e+00,  1.2149e+00,  1.2052e+00,  1.1872e+00,
          1.1986e+00,  1.2172e+00,  1.1816e+00,  1.1751e+00,  1.1986e+00,
          1.1703e+00,  1.1703e+00,  1.2282e+00,  1.2700e+00,  1.2007e+00,
          1.2236e+00,  1.2720e+00,  1.2108e+00,  1.2414e+00,  1.1610e+00,
          1.2033e+00,  1.3643e+00,  1.4060e+00,  1.3823e+00,  1.3728e+00,
          1.3920e+00,  1.3236e+00,  1.3689e+00,  1.3610e+00,  1.3132e+00,
          1.3149e+00,  1.2662e+00,  1.2536e+00,  1.2343e+00,  1.3061e+00,
          1.2543e+00,  1.3459e+00,  1.2263e+00,  1.2328e+00],
        [ 1.2712e+00,  1.1828e+00,  1.0054e+00,  1.2264e+00,  1.3062e+00,
          1.3221e+00,  1.2464e+00,  1.3129e+00,  1.3129e+00,  1.5058e+00,
          1.7399e+00,  1.5119e+00,  2.2413e+00,  1.5446e+00,  5.7608e+00,
          1.6115e+00,  1.4399e+00,  5.5969e+00,  1.0920e+00,  1.1752e+00,
          9.6786e-01,  1.1396e+00,  1.2746e+00,  1.3084e+00,  1.2746e+00,
          1.3026e+00,  1.3026e+00,  1.2964e+00,  1.0255e+00,  1.3376e+00,
          1.3172e+00,  1.1358e+00,  1.3502e+00,  1.3836e+00,  1.2991e+00,
          1.3347e+00,  1.3147e+00,  1.4620e+00,  1.3725e+00,  1.2834e+00,
          1.3008e+00,  1.4277e+00,  1.3554e+00,  4.8325e-01,  1.3371e+00,
          1.0261e+00,  1.3966e+00,  1.3776e+00,  1.3543e+00,  1.0427e+00,
          1.3808e+00,  8.7203e-01,  1.3442e+00,  1.3548e+00],
        [ 1.1911e+00,  1.2170e+00,  1.2683e+00,  1.2503e+00,  1.2239e+00,
          1.1967e+00,  1.2035e+00,  1.1894e+00,  1.1894e+00,  1.2550e+00,
          1.2739e+00,  1.2706e+00,  1.2973e+00,  1.2400e+00,  1.3078e+00,
          1.2530e+00,  1.2283e+00,  1.2204e+00,  2.5883e+00,  2.6888e+00,
          2.7819e+00,  2.7073e+00,  2.4930e+00,  2.5823e+00,  2.6127e+00,
          2.4804e+00,  2.4804e+00,  1.2721e+00,  1.2625e+00,  1.2128e+00,
          1.2357e+00,  1.2716e+00,  1.2229e+00,  1.2537e+00,  1.2173e+00,
          1.2154e+00,  1.3723e+00,  1.4141e+00,  1.3902e+00,  1.3645e+00,
          1.4000e+00,  1.3886e+00,  1.3769e+00,  1.3042e+00,  1.3047e+00,
          1.2938e+00,  1.2765e+00,  1.2639e+00,  1.2446e+00,  1.2643e+00,
          1.2647e+00,  1.3248e+00,  1.2363e+00,  1.2430e+00],
        [ 1.1814e+00,  1.2087e+00,  1.2560e+00,  1.2371e+00,  1.2161e+00,
          1.1873e+00,  1.1947e+00,  1.1797e+00,  1.1797e+00,  1.2535e+00,
          1.2669e+00,  1.2696e+00,  1.2949e+00,  1.2381e+00,  1.2495e+00,
          1.2514e+00,  1.2396e+00,  1.1690e+00,  1.2144e+00,  1.2397e+00,
          1.2532e+00,  1.2270e+00,  1.1895e+00,  1.1809e+00,  1.2069e+00,
          1.1774e+00,  1.1774e+00,  2.8509e+00,  2.7497e+00,  2.4200e+00,
          2.5657e+00,  2.8459e+00,  2.4309e+00,  2.8019e+00,  2.4286e+00,
          2.4226e+00,  1.3615e+00,  1.4050e+00,  1.3776e+00,  1.3676e+00,
          1.3904e+00,  1.3779e+00,  1.3660e+00,  1.2863e+00,  1.3076e+00,
          1.3265e+00,  1.2736e+00,  1.1690e+00,  1.1975e+00,  1.3174e+00,
          1.2556e+00,  1.3587e+00,  1.1890e+00,  1.2412e+00],
        [ 1.6944e+00,  1.3798e+00,  6.3466e-01,  8.3396e-01,  1.1928e+00,
          1.5871e+00,  1.5270e+00,  1.6913e+00,  1.6913e+00,  1.5352e+00,
          1.2417e+00,  1.3760e+00,  9.1623e-01,  1.6244e+00,  2.9024e-01,
          1.5230e+00,  1.6474e+00,  1.1047e+00,  1.3113e+00,  8.8894e-01,
          7.7919e-01,  1.1004e+00,  1.5483e+00,  1.6016e+00,  1.3435e+00,
          1.6849e+00,  1.6849e+00,  7.2511e-01,  8.7101e-01,  1.6649e+00,
          1.4777e+00,  8.1070e-01,  1.6047e+00,  1.0966e+00,  1.7164e+00,
          1.6347e+00,  2.2756e-01,  3.4283e-03, -1.4956e-02,  1.8459e-01,
          4.3297e-01,  5.8831e-01,  1.3186e-01,  1.1701e+01,  7.5723e+00,
          7.9562e-01,  1.2113e+00,  1.3066e+00,  1.5245e+00,  1.0207e+00,
          1.4577e+00,  4.5763e-01,  1.5820e+00,  1.6882e+00],
        [ 1.2424e+00,  1.2737e+00,  1.3357e+00,  1.3149e+00,  1.2830e+00,
          1.2491e+00,  1.2140e+00,  1.2404e+00,  1.2404e+00,  1.2069e+00,
          1.3238e+00,  1.2252e+00,  1.3518e+00,  1.2838e+00,  1.4042e+00,
          1.2045e+00,  1.2860e+00,  1.2267e+00,  1.2784e+00,  1.3089e+00,
          1.3239e+00,  1.2924e+00,  1.2497e+00,  1.2412e+00,  1.1887e+00,
          1.2358e+00,  1.2358e+00,  1.3086e+00,  1.3501e+00,  1.2684e+00,
          1.0857e+00,  1.2616e+00,  1.1463e+00,  1.3163e+00,  1.1417e+00,
          1.2715e+00,  1.3631e+00,  1.0556e+00,  1.3841e+00,  1.3736e+00,
          9.4834e-01,  8.5203e-01,  1.3688e+00,  1.3582e+00,  7.3590e-01,
          3.1447e+00,  2.5147e+00,  3.2847e+00,  2.7726e+00,  2.1275e+00,
          1.8215e+00,  2.8901e+00,  3.0636e+00,  1.8007e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 189 : 180.41206249853542
Test loss for epoch 189 : 180.5281859326771
Test Precision for epoch 189 : 0.26153846153846155
Test Recall for epoch 189 : 0.26153846153846155
Test F1 for epoch 189 : 0.26153846153846155


theta for epoch 190 : tensor([[ 2.5334e+00,  2.5636e+00,  2.6374e+00,  2.7490e+00,  2.7121e+00,
          2.5397e+00,  2.6877e+00,  2.5317e+00,  2.5317e+00,  1.2529e+00,
          1.2715e+00,  1.2683e+00,  1.2946e+00,  1.2380e+00,  1.3389e+00,
          1.2509e+00,  1.2398e+00,  1.2232e+00,  1.2250e+00,  1.2070e+00,
          1.2182e+00,  1.2369e+00,  1.2014e+00,  1.1949e+00,  1.2183e+00,
          1.1901e+00,  1.1901e+00,  1.2287e+00,  1.2704e+00,  1.2011e+00,
          1.2240e+00,  1.2724e+00,  1.2112e+00,  1.2418e+00,  1.1615e+00,
          1.2037e+00,  1.3666e+00,  1.4083e+00,  1.3846e+00,  1.3750e+00,
          1.3943e+00,  1.3260e+00,  1.3712e+00,  1.3631e+00,  1.3155e+00,
          1.3171e+00,  1.2685e+00,  1.2559e+00,  1.2367e+00,  1.3084e+00,
          1.2567e+00,  1.3481e+00,  1.2286e+00,  1.2351e+00],
        [ 1.2588e+00,  1.1708e+00,  9.9454e-01,  1.2144e+00,  1.2942e+00,
          1.3096e+00,  1.2340e+00,  1.3005e+00,  1.3005e+00,  1.5071e+00,
          1.7407e+00,  1.5133e+00,  2.2414e+00,  1.5460e+00,  5.7781e+00,
          1.6128e+00,  1.4413e+00,  5.6152e+00,  1.1065e+00,  1.1896e+00,
          9.8115e-01,  1.1539e+00,  1.2893e+00,  1.3232e+00,  1.2892e+00,
          1.3173e+00,  1.3173e+00,  1.2927e+00,  1.0218e+00,  1.3340e+00,
          1.3136e+00,  1.1320e+00,  1.3466e+00,  1.3800e+00,  1.2955e+00,
          1.3313e+00,  1.3149e+00,  1.4620e+00,  1.3724e+00,  1.2834e+00,
          1.3011e+00,  1.4278e+00,  1.3553e+00,  4.8342e-01,  1.3369e+00,
          1.0256e+00,  1.3958e+00,  1.3768e+00,  1.3535e+00,  1.0420e+00,
          1.3801e+00,  8.7184e-01,  1.3433e+00,  1.3541e+00],
        [ 1.1729e+00,  1.1989e+00,  1.2503e+00,  1.2322e+00,  1.2058e+00,
          1.1786e+00,  1.1854e+00,  1.1713e+00,  1.1713e+00,  1.2520e+00,
          1.2709e+00,  1.2676e+00,  1.2944e+00,  1.2369e+00,  1.3052e+00,
          1.2500e+00,  1.2249e+00,  1.2179e+00,  2.6069e+00,  2.7079e+00,
          2.8002e+00,  2.7253e+00,  2.5122e+00,  2.6012e+00,  2.6317e+00,
          2.4996e+00,  2.4996e+00,  1.2632e+00,  1.2540e+00,  1.2041e+00,
          1.2270e+00,  1.2626e+00,  1.2142e+00,  1.2451e+00,  1.2086e+00,
          1.2067e+00,  1.3691e+00,  1.4111e+00,  1.3872e+00,  1.3612e+00,
          1.3969e+00,  1.3855e+00,  1.3738e+00,  1.3016e+00,  1.3012e+00,
          1.2894e+00,  1.2719e+00,  1.2593e+00,  1.2399e+00,  1.2602e+00,
          1.2601e+00,  1.3205e+00,  1.2316e+00,  1.2384e+00],
        [ 1.1721e+00,  1.1994e+00,  1.2474e+00,  1.2287e+00,  1.2069e+00,
          1.1780e+00,  1.1854e+00,  1.1704e+00,  1.1704e+00,  1.2572e+00,
          1.2707e+00,  1.2732e+00,  1.2986e+00,  1.2418e+00,  1.2530e+00,
          1.2551e+00,  1.2433e+00,  1.1726e+00,  1.2275e+00,  1.2521e+00,
          1.2662e+00,  1.2402e+00,  1.2026e+00,  1.1941e+00,  1.2200e+00,
          1.1906e+00,  1.1906e+00,  2.8514e+00,  2.7522e+00,  2.4216e+00,
          2.5677e+00,  2.8464e+00,  2.4324e+00,  2.8024e+00,  2.4301e+00,
          2.4242e+00,  1.3622e+00,  1.4057e+00,  1.3783e+00,  1.3683e+00,
          1.3910e+00,  1.3787e+00,  1.3667e+00,  1.2872e+00,  1.3083e+00,
          1.3264e+00,  1.2736e+00,  1.1690e+00,  1.1975e+00,  1.3173e+00,
          1.2558e+00,  1.3585e+00,  1.1889e+00,  1.2411e+00],
        [ 1.6846e+00,  1.3703e+00,  6.2767e-01,  8.2631e-01,  1.1834e+00,
          1.5774e+00,  1.5173e+00,  1.6815e+00,  1.6815e+00,  1.5379e+00,
          1.2439e+00,  1.3784e+00,  9.1806e-01,  1.6272e+00,  2.9149e-01,
          1.5256e+00,  1.6503e+00,  1.1061e+00,  1.3219e+00,  8.9850e-01,
          7.8817e-01,  1.1105e+00,  1.5597e+00,  1.6128e+00,  1.3544e+00,
          1.6963e+00,  1.6963e+00,  7.2293e-01,  8.6868e-01,  1.6624e+00,
          1.4754e+00,  8.0838e-01,  1.6022e+00,  1.0940e+00,  1.7140e+00,
          1.6321e+00,  2.2680e-01,  2.5439e-03, -1.5712e-02,  1.8370e-01,
          4.3190e-01,  5.8699e-01,  1.3102e-01,  1.1744e+01,  7.5668e+00,
          7.9451e-01,  1.2105e+00,  1.3059e+00,  1.5238e+00,  1.0194e+00,
          1.4568e+00,  4.5638e-01,  1.5815e+00,  1.6876e+00],
        [ 1.2314e+00,  1.2628e+00,  1.3250e+00,  1.3041e+00,  1.2722e+00,
          1.2382e+00,  1.2031e+00,  1.2295e+00,  1.2295e+00,  1.2108e+00,
          1.3279e+00,  1.2291e+00,  1.3559e+00,  1.2878e+00,  1.4081e+00,
          1.2084e+00,  1.2899e+00,  1.2307e+00,  1.2914e+00,  1.3217e+00,
          1.3364e+00,  1.3054e+00,  1.2628e+00,  1.2544e+00,  1.2015e+00,
          1.2489e+00,  1.2489e+00,  1.3056e+00,  1.3472e+00,  1.2655e+00,
          1.0826e+00,  1.2587e+00,  1.1435e+00,  1.3134e+00,  1.1388e+00,
          1.2686e+00,  1.3633e+00,  1.0556e+00,  1.3844e+00,  1.3739e+00,
          9.4833e-01,  8.5207e-01,  1.3691e+00,  1.3583e+00,  7.3589e-01,
          3.1494e+00,  2.5160e+00,  3.2906e+00,  2.7748e+00,  2.1280e+00,
          1.8217e+00,  2.8925e+00,  3.0682e+00,  1.8009e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 190 : 180.3439001262333
Test loss for epoch 190 : 180.46035082538768
Test Precision for epoch 190 : 0.26153846153846155
Test Recall for epoch 190 : 0.26153846153846155
Test F1 for epoch 190 : 0.26153846153846155


theta for epoch 191 : tensor([[ 2.5442e+00,  2.5744e+00,  2.6482e+00,  2.7601e+00,  2.7233e+00,
          2.5505e+00,  2.6989e+00,  2.5425e+00,  2.5425e+00,  1.2480e+00,
          1.2667e+00,  1.2635e+00,  1.2900e+00,  1.2332e+00,  1.3344e+00,
          1.2460e+00,  1.2349e+00,  1.2184e+00,  1.2274e+00,  1.2093e+00,
          1.2205e+00,  1.2394e+00,  1.2038e+00,  1.1974e+00,  1.2207e+00,
          1.1925e+00,  1.1925e+00,  1.2226e+00,  1.2645e+00,  1.1951e+00,
          1.2180e+00,  1.2664e+00,  1.2051e+00,  1.2359e+00,  1.1554e+00,
          1.1976e+00,  1.3630e+00,  1.4048e+00,  1.3810e+00,  1.3715e+00,
          1.3908e+00,  1.3224e+00,  1.3676e+00,  1.3595e+00,  1.3119e+00,
          1.3123e+00,  1.2636e+00,  1.2510e+00,  1.2317e+00,  1.3035e+00,
          1.2518e+00,  1.3433e+00,  1.2236e+00,  1.2301e+00],
        [ 1.2648e+00,  1.1768e+00,  1.0006e+00,  1.2205e+00,  1.3003e+00,
          1.3156e+00,  1.2400e+00,  1.3064e+00,  1.3064e+00,  1.5030e+00,
          1.7359e+00,  1.5091e+00,  2.2361e+00,  1.5417e+00,  5.7907e+00,
          1.6085e+00,  1.4372e+00,  5.6282e+00,  1.1143e+00,  1.1975e+00,
          9.8879e-01,  1.1617e+00,  1.2970e+00,  1.3309e+00,  1.2968e+00,
          1.3250e+00,  1.3250e+00,  1.2914e+00,  1.0208e+00,  1.3324e+00,
          1.3121e+00,  1.1308e+00,  1.3450e+00,  1.3785e+00,  1.2939e+00,
          1.3298e+00,  1.3141e+00,  1.4610e+00,  1.3712e+00,  1.2824e+00,
          1.3004e+00,  1.4267e+00,  1.3542e+00,  4.8343e-01,  1.3357e+00,
          1.0247e+00,  1.3942e+00,  1.3751e+00,  1.3518e+00,  1.0409e+00,
          1.3785e+00,  8.7149e-01,  1.3415e+00,  1.3524e+00],
        [ 1.1740e+00,  1.2000e+00,  1.2514e+00,  1.2333e+00,  1.2069e+00,
          1.1796e+00,  1.1865e+00,  1.1724e+00,  1.1724e+00,  1.2474e+00,
          1.2664e+00,  1.2631e+00,  1.2900e+00,  1.2323e+00,  1.3012e+00,
          1.2454e+00,  1.2200e+00,  1.2140e+00,  2.6172e+00,  2.7188e+00,
          2.8104e+00,  2.7352e+00,  2.5231e+00,  2.6117e+00,  2.6425e+00,
          2.5105e+00,  2.5105e+00,  1.2575e+00,  1.2488e+00,  1.1986e+00,
          1.2215e+00,  1.2569e+00,  1.2087e+00,  1.2396e+00,  1.2031e+00,
          1.2012e+00,  1.3658e+00,  1.4078e+00,  1.3838e+00,  1.3576e+00,
          1.3936e+00,  1.3822e+00,  1.3704e+00,  1.2990e+00,  1.2975e+00,
          1.2851e+00,  1.2673e+00,  1.2546e+00,  1.2353e+00,  1.2563e+00,
          1.2555e+00,  1.3163e+00,  1.2269e+00,  1.2337e+00],
        [ 1.1762e+00,  1.2035e+00,  1.2514e+00,  1.2327e+00,  1.2110e+00,
          1.1821e+00,  1.1895e+00,  1.1745e+00,  1.1745e+00,  1.2567e+00,
          1.2705e+00,  1.2728e+00,  1.2983e+00,  1.2413e+00,  1.2528e+00,
          1.2547e+00,  1.2427e+00,  1.1727e+00,  1.2334e+00,  1.2576e+00,
          1.2720e+00,  1.2460e+00,  1.2085e+00,  1.2000e+00,  1.2259e+00,
          1.1966e+00,  1.1966e+00,  2.8522e+00,  2.7551e+00,  2.4234e+00,
          2.5701e+00,  2.8472e+00,  2.4343e+00,  2.8032e+00,  2.4320e+00,
          2.4261e+00,  1.3613e+00,  1.4049e+00,  1.3776e+00,  1.3676e+00,
          1.3903e+00,  1.3780e+00,  1.3659e+00,  1.2868e+00,  1.3075e+00,
          1.3248e+00,  1.2721e+00,  1.1676e+00,  1.1960e+00,  1.3157e+00,
          1.2546e+00,  1.3569e+00,  1.1874e+00,  1.2395e+00],
        [ 1.6902e+00,  1.3762e+00,  6.3317e-01,  8.3202e-01,  1.1895e+00,
          1.5831e+00,  1.5231e+00,  1.6871e+00,  1.6871e+00,  1.5386e+00,
          1.2449e+00,  1.3794e+00,  9.1966e-01,  1.6276e+00,  2.9393e-01,
          1.5263e+00,  1.6510e+00,  1.1067e+00,  1.3286e+00,  9.0537e-01,
          7.9481e-01,  1.1172e+00,  1.5664e+00,  1.6192e+00,  1.3613e+00,
          1.7029e+00,  1.7029e+00,  7.2405e-01,  8.6934e-01,  1.6620e+00,
          1.4754e+00,  8.0937e-01,  1.6018e+00,  1.0943e+00,  1.7135e+00,
          1.6316e+00,  2.2293e-01, -1.3158e-03, -1.9444e-02,  1.7972e-01,
          4.2767e-01,  5.8240e-01,  1.2712e-01,  1.1784e+01,  7.5579e+00,
          7.9494e-01,  1.2100e+00,  1.3053e+00,  1.5228e+00,  1.0191e+00,
          1.4557e+00,  4.5746e-01,  1.5805e+00,  1.6864e+00],
        [ 1.2362e+00,  1.2676e+00,  1.3296e+00,  1.3087e+00,  1.2769e+00,
          1.2430e+00,  1.2078e+00,  1.2342e+00,  1.2342e+00,  1.2102e+00,
          1.3274e+00,  1.2286e+00,  1.3554e+00,  1.2871e+00,  1.4077e+00,
          1.2078e+00,  1.2892e+00,  1.2303e+00,  1.2976e+00,  1.3279e+00,
          1.3423e+00,  1.3116e+00,  1.2690e+00,  1.2606e+00,  1.2075e+00,
          1.2552e+00,  1.2552e+00,  1.3039e+00,  1.3455e+00,  1.2637e+00,
          1.0807e+00,  1.2571e+00,  1.1418e+00,  1.3117e+00,  1.1371e+00,
          1.2668e+00,  1.3619e+00,  1.0541e+00,  1.3830e+00,  1.3725e+00,
          9.4680e-01,  8.5059e-01,  1.3677e+00,  1.3570e+00,  7.3444e-01,
          3.1521e+00,  2.5152e+00,  3.2945e+00,  2.7750e+00,  2.1265e+00,
          1.8199e+00,  2.8929e+00,  3.0707e+00,  1.7990e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 191 : 180.3562245480574
Test loss for epoch 191 : 180.47186534910952
Test Precision for epoch 191 : 0.26153846153846155
Test Recall for epoch 191 : 0.26153846153846155
Test F1 for epoch 191 : 0.26153846153846155


theta for epoch 192 : tensor([[ 2.5572e+00,  2.5873e+00,  2.6610e+00,  2.7734e+00,  2.7365e+00,
          2.5634e+00,  2.7122e+00,  2.5554e+00,  2.5554e+00,  1.2477e+00,
          1.2665e+00,  1.2632e+00,  1.2897e+00,  1.2328e+00,  1.3342e+00,
          1.2457e+00,  1.2346e+00,  1.2180e+00,  1.2003e+00,  1.1822e+00,
          1.1937e+00,  1.2123e+00,  1.1767e+00,  1.1702e+00,  1.1937e+00,
          1.1653e+00,  1.1653e+00,  1.2252e+00,  1.2671e+00,  1.1978e+00,
          1.2206e+00,  1.2691e+00,  1.2078e+00,  1.2386e+00,  1.1580e+00,
          1.2003e+00,  1.3620e+00,  1.4040e+00,  1.3801e+00,  1.3705e+00,
          1.3898e+00,  1.3214e+00,  1.3667e+00,  1.3584e+00,  1.3109e+00,
          1.3119e+00,  1.2632e+00,  1.2506e+00,  1.2313e+00,  1.3032e+00,
          1.2514e+00,  1.3430e+00,  1.2232e+00,  1.2298e+00],
        [ 1.2717e+00,  1.1834e+00,  1.0068e+00,  1.2273e+00,  1.3073e+00,
          1.3225e+00,  1.2469e+00,  1.3134e+00,  1.3134e+00,  1.5064e+00,
          1.7387e+00,  1.5125e+00,  2.2381e+00,  1.5451e+00,  5.8095e+00,
          1.6119e+00,  1.4407e+00,  5.6481e+00,  1.0908e+00,  1.1742e+00,
          9.6764e-01,  1.1384e+00,  1.2732e+00,  1.3070e+00,  1.2728e+00,
          1.3011e+00,  1.3011e+00,  1.2966e+00,  1.0262e+00,  1.3377e+00,
          1.3174e+00,  1.1361e+00,  1.3503e+00,  1.3838e+00,  1.2992e+00,
          1.3353e+00,  1.3150e+00,  1.4616e+00,  1.3718e+00,  1.2831e+00,
          1.3012e+00,  1.4274e+00,  1.3547e+00,  4.8379e-01,  1.3361e+00,
          1.0267e+00,  1.3961e+00,  1.3769e+00,  1.3536e+00,  1.0427e+00,
          1.3805e+00,  8.7364e-01,  1.3433e+00,  1.3543e+00],
        [ 1.1883e+00,  1.2143e+00,  1.2657e+00,  1.2477e+00,  1.2212e+00,
          1.1939e+00,  1.2008e+00,  1.1867e+00,  1.1867e+00,  1.2581e+00,
          1.2772e+00,  1.2737e+00,  1.3006e+00,  1.2430e+00,  1.3112e+00,
          1.2561e+00,  1.2306e+00,  1.2255e+00,  2.5982e+00,  2.7005e+00,
          2.7919e+00,  2.7160e+00,  2.5043e+00,  2.5926e+00,  2.6239e+00,
          2.4918e+00,  2.4918e+00,  1.2693e+00,  1.2611e+00,  1.2106e+00,
          1.2334e+00,  1.2688e+00,  1.2206e+00,  1.2515e+00,  1.2151e+00,
          1.2132e+00,  1.3702e+00,  1.4123e+00,  1.3883e+00,  1.3619e+00,
          1.3981e+00,  1.3867e+00,  1.3749e+00,  1.3042e+00,  1.3017e+00,
          1.2922e+00,  1.2740e+00,  1.2613e+00,  1.2420e+00,  1.2637e+00,
          1.2622e+00,  1.3233e+00,  1.2336e+00,  1.2405e+00],
        [ 1.1808e+00,  1.2080e+00,  1.2558e+00,  1.2371e+00,  1.2155e+00,
          1.1867e+00,  1.1941e+00,  1.1791e+00,  1.1791e+00,  1.2582e+00,
          1.2722e+00,  1.2743e+00,  1.2999e+00,  1.2428e+00,  1.2542e+00,
          1.2562e+00,  1.2442e+00,  1.1743e+00,  1.2123e+00,  1.2376e+00,
          1.2510e+00,  1.2249e+00,  1.1874e+00,  1.1791e+00,  1.2047e+00,
          1.1754e+00,  1.1754e+00,  2.8579e+00,  2.7629e+00,  2.4303e+00,
          2.5774e+00,  2.8529e+00,  2.4412e+00,  2.8090e+00,  2.4388e+00,
          2.4330e+00,  1.3616e+00,  1.4052e+00,  1.3780e+00,  1.3680e+00,
          1.3906e+00,  1.3784e+00,  1.3662e+00,  1.2873e+00,  1.3078e+00,
          1.3255e+00,  1.2730e+00,  1.1684e+00,  1.1968e+00,  1.3165e+00,
          1.2556e+00,  1.3576e+00,  1.1882e+00,  1.2404e+00],
        [ 1.6970e+00,  1.3829e+00,  6.3819e-01,  8.3755e-01,  1.1961e+00,
          1.5900e+00,  1.5299e+00,  1.6939e+00,  1.6939e+00,  1.5422e+00,
          1.2481e+00,  1.3828e+00,  9.2257e-01,  1.6312e+00,  2.9623e-01,
          1.5298e+00,  1.6549e+00,  1.1092e+00,  1.3126e+00,  8.9100e-01,
          7.8080e-01,  1.1016e+00,  1.5495e+00,  1.6019e+00,  1.3457e+00,
          1.6858e+00,  1.6858e+00,  7.2875e-01,  8.7373e-01,  1.6673e+00,
          1.4808e+00,  8.1420e-01,  1.6071e+00,  1.0994e+00,  1.7188e+00,
          1.6367e+00,  2.2207e-01, -2.2773e-03, -2.0277e-02,  1.7872e-01,
          4.2647e-01,  5.8091e-01,  1.2617e-01,  1.1827e+01,  7.5514e+00,
          7.9805e-01,  1.2134e+00,  1.3088e+00,  1.5261e+00,  1.0222e+00,
          1.4589e+00,  4.6019e-01,  1.5840e+00,  1.6897e+00],
        [ 1.2424e+00,  1.2737e+00,  1.3357e+00,  1.3149e+00,  1.2830e+00,
          1.2492e+00,  1.2140e+00,  1.2404e+00,  1.2404e+00,  1.2133e+00,
          1.3307e+00,  1.2317e+00,  1.3588e+00,  1.2903e+00,  1.4110e+00,
          1.2110e+00,  1.2924e+00,  1.2336e+00,  1.2768e+00,  1.3071e+00,
          1.3222e+00,  1.2909e+00,  1.2481e+00,  1.2398e+00,  1.1865e+00,
          1.2343e+00,  1.2343e+00,  1.3083e+00,  1.3499e+00,  1.2683e+00,
          1.0848e+00,  1.2614e+00,  1.1461e+00,  1.3162e+00,  1.1415e+00,
          1.2713e+00,  1.3627e+00,  1.0544e+00,  1.3838e+00,  1.3733e+00,
          9.4699e-01,  8.5074e-01,  1.3685e+00,  1.3576e+00,  7.3451e-01,
          3.1599e+00,  2.5197e+00,  3.3036e+00,  2.7803e+00,  2.1303e+00,
          1.8234e+00,  2.8983e+00,  3.0786e+00,  1.8025e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 192 : 180.40776345571058
Test loss for epoch 192 : 180.52762812675476
Test Precision for epoch 192 : 0.26153846153846155
Test Recall for epoch 192 : 0.26153846153846155
Test F1 for epoch 192 : 0.26153846153846155


theta for epoch 193 : tensor([[ 2.5389e+00,  2.5690e+00,  2.6430e+00,  2.7556e+00,  2.7187e+00,
          2.5451e+00,  2.6942e+00,  2.5371e+00,  2.5371e+00,  1.2526e+00,
          1.2714e+00,  1.2681e+00,  1.2946e+00,  1.2378e+00,  1.3389e+00,
          1.2506e+00,  1.2395e+00,  1.2232e+00,  1.2177e+00,  1.1997e+00,
          1.2110e+00,  1.2297e+00,  1.1941e+00,  1.1877e+00,  1.2110e+00,
          1.1828e+00,  1.1828e+00,  1.2328e+00,  1.2743e+00,  1.2051e+00,
          1.2279e+00,  1.2764e+00,  1.2152e+00,  1.2459e+00,  1.1656e+00,
          1.2077e+00,  1.3687e+00,  1.4107e+00,  1.3868e+00,  1.3773e+00,
          1.3966e+00,  1.3284e+00,  1.3734e+00,  1.3650e+00,  1.3177e+00,
          1.3191e+00,  1.2704e+00,  1.2578e+00,  1.2386e+00,  1.3104e+00,
          1.2586e+00,  1.3501e+00,  1.2304e+00,  1.2370e+00],
        [ 1.2547e+00,  1.1671e+00,  9.9218e-01,  1.2109e+00,  1.2908e+00,
          1.3055e+00,  1.2300e+00,  1.2964e+00,  1.2964e+00,  1.5023e+00,
          1.7341e+00,  1.5084e+00,  2.2329e+00,  1.5410e+00,  5.8219e+00,
          1.6077e+00,  1.4367e+00,  5.6609e+00,  1.1031e+00,  1.1864e+00,
          9.7916e-01,  1.1505e+00,  1.2855e+00,  1.3194e+00,  1.2849e+00,
          1.3134e+00,  1.3134e+00,  1.2986e+00,  1.0285e+00,  1.3395e+00,
          1.3193e+00,  1.1382e+00,  1.3521e+00,  1.3857e+00,  1.3010e+00,
          1.3372e+00,  1.3190e+00,  1.4652e+00,  1.3754e+00,  1.2869e+00,
          1.3052e+00,  1.4311e+00,  1.3583e+00,  4.8795e-01,  1.3395e+00,
          1.0306e+00,  1.3995e+00,  1.3802e+00,  1.3569e+00,  1.0465e+00,
          1.3838e+00,  8.7788e-01,  1.3466e+00,  1.3577e+00],
        [ 1.1638e+00,  1.1899e+00,  1.2415e+00,  1.2233e+00,  1.1968e+00,
          1.1695e+00,  1.1763e+00,  1.1622e+00,  1.1622e+00,  1.2485e+00,
          1.2676e+00,  1.2642e+00,  1.2911e+00,  1.2334e+00,  1.3023e+00,
          1.2465e+00,  1.2207e+00,  1.2165e+00,  2.6166e+00,  2.7194e+00,
          2.8101e+00,  2.7338e+00,  2.5234e+00,  2.6113e+00,  2.6428e+00,
          2.5108e+00,  2.5108e+00,  1.2640e+00,  1.2562e+00,  1.2055e+00,
          1.2283e+00,  1.2634e+00,  1.2156e+00,  1.2465e+00,  1.2100e+00,
          1.2081e+00,  1.3693e+00,  1.4115e+00,  1.3875e+00,  1.3607e+00,
          1.3972e+00,  1.3858e+00,  1.3741e+00,  1.3037e+00,  1.3004e+00,
          1.2901e+00,  1.2716e+00,  1.2589e+00,  1.2396e+00,  1.2619e+00,
          1.2599e+00,  1.3213e+00,  1.2312e+00,  1.2381e+00],
        [ 1.1666e+00,  1.1939e+00,  1.2427e+00,  1.2241e+00,  1.2014e+00,
          1.1725e+00,  1.1800e+00,  1.1649e+00,  1.1649e+00,  1.2563e+00,
          1.2705e+00,  1.2724e+00,  1.2982e+00,  1.2408e+00,  1.2525e+00,
          1.2542e+00,  1.2423e+00,  1.1731e+00,  1.2219e+00,  1.2467e+00,
          1.2605e+00,  1.2346e+00,  1.1971e+00,  1.1888e+00,  1.2144e+00,
          1.1852e+00,  1.1852e+00,  2.8599e+00,  2.7669e+00,  2.4334e+00,
          2.5809e+00,  2.8550e+00,  2.4443e+00,  2.8111e+00,  2.4418e+00,
          2.4360e+00,  1.3645e+00,  1.4082e+00,  1.3810e+00,  1.3710e+00,
          1.3936e+00,  1.3814e+00,  1.3692e+00,  1.2903e+00,  1.3108e+00,
          1.3277e+00,  1.2752e+00,  1.1706e+00,  1.1991e+00,  1.3186e+00,
          1.2579e+00,  1.3598e+00,  1.1905e+00,  1.2426e+00],
        [ 1.6819e+00,  1.3678e+00,  6.2620e-01,  8.2469e-01,  1.1809e+00,
          1.5747e+00,  1.5148e+00,  1.6788e+00,  1.6788e+00,  1.5381e+00,
          1.2433e+00,  1.3788e+00,  9.1805e-01,  1.6273e+00,  2.9216e-01,
          1.5258e+00,  1.6512e+00,  1.1037e+00,  1.3194e+00,  8.9671e-01,
          7.8589e-01,  1.1078e+00,  1.5571e+00,  1.6094e+00,  1.3529e+00,
          1.6936e+00,  1.6936e+00,  7.2763e-01,  8.7261e-01,  1.6672e+00,
          1.4807e+00,  8.1311e-01,  1.6070e+00,  1.0985e+00,  1.7189e+00,
          1.6365e+00,  2.2407e-01, -4.7244e-04, -1.8358e-02,  1.8059e-01,
          4.2822e-01,  5.8244e-01,  1.2805e-01,  1.1872e+01,  7.5473e+00,
          7.9797e-01,  1.2144e+00,  1.3101e+00,  1.5277e+00,  1.0224e+00,
          1.4602e+00,  4.5928e-01,  1.5859e+00,  1.6915e+00],
        [ 1.2263e+00,  1.2578e+00,  1.3199e+00,  1.2990e+00,  1.2671e+00,
          1.2332e+00,  1.1980e+00,  1.2244e+00,  1.2244e+00,  1.2103e+00,
          1.3277e+00,  1.2287e+00,  1.3558e+00,  1.2872e+00,  1.4081e+00,
          1.2079e+00,  1.2893e+00,  1.2305e+00,  1.2865e+00,  1.3167e+00,
          1.3315e+00,  1.3005e+00,  1.2579e+00,  1.2496e+00,  1.1959e+00,
          1.2441e+00,  1.2441e+00,  1.3091e+00,  1.3506e+00,  1.2691e+00,
          1.0853e+00,  1.2622e+00,  1.1469e+00,  1.3170e+00,  1.1423e+00,
          1.2722e+00,  1.3662e+00,  1.0577e+00,  1.3873e+00,  1.3769e+00,
          9.5023e-01,  8.5401e-01,  1.3721e+00,  1.3610e+00,  7.3766e-01,
          3.1661e+00,  2.5226e+00,  3.3111e+00,  2.7841e+00,  2.1325e+00,
          1.8254e+00,  2.9022e+00,  3.0848e+00,  1.8045e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 193 : 180.35950703755697
Test loss for epoch 193 : 180.47810568796342
Test Precision for epoch 193 : 0.26153846153846155
Test Recall for epoch 193 : 0.26153846153846155
Test F1 for epoch 193 : 0.26153846153846155


theta for epoch 194 : tensor([[ 2.5524e+00,  2.5825e+00,  2.6564e+00,  2.7694e+00,  2.7325e+00,
          2.5586e+00,  2.7081e+00,  2.5506e+00,  2.5506e+00,  1.2458e+00,
          1.2647e+00,  1.2613e+00,  1.2879e+00,  1.2309e+00,  1.3323e+00,
          1.2438e+00,  1.2326e+00,  1.2163e+00,  1.2265e+00,  1.2084e+00,
          1.2197e+00,  1.2386e+00,  1.2029e+00,  1.1965e+00,  1.2198e+00,
          1.1915e+00,  1.1915e+00,  1.2195e+00,  1.2613e+00,  1.1920e+00,
          1.2148e+00,  1.2634e+00,  1.2020e+00,  1.2329e+00,  1.1523e+00,
          1.1946e+00,  1.3641e+00,  1.4063e+00,  1.3823e+00,  1.3728e+00,
          1.3921e+00,  1.3239e+00,  1.3689e+00,  1.3604e+00,  1.3132e+00,
          1.3117e+00,  1.2630e+00,  1.2504e+00,  1.2311e+00,  1.3030e+00,
          1.2512e+00,  1.3428e+00,  1.2229e+00,  1.2296e+00],
        [ 1.2630e+00,  1.1751e+00,  9.9987e-01,  1.2191e+00,  1.2992e+00,
          1.3138e+00,  1.2383e+00,  1.3047e+00,  1.3047e+00,  1.5019e+00,
          1.7331e+00,  1.5079e+00,  2.2312e+00,  1.5405e+00,  5.8372e+00,
          1.6071e+00,  1.4363e+00,  5.6770e+00,  1.1161e+00,  1.1995e+00,
          9.9135e-01,  1.1635e+00,  1.2988e+00,  1.3327e+00,  1.2981e+00,
          1.3267e+00,  1.3267e+00,  1.2890e+00,  1.0188e+00,  1.3300e+00,
          1.3098e+00,  1.1284e+00,  1.3426e+00,  1.3762e+00,  1.2915e+00,
          1.3278e+00,  1.3166e+00,  1.4627e+00,  1.3727e+00,  1.2843e+00,
          1.3029e+00,  1.4286e+00,  1.3556e+00,  4.8564e-01,  1.3368e+00,
          1.0258e+00,  1.3944e+00,  1.3750e+00,  1.3517e+00,  1.0413e+00,
          1.3787e+00,  8.7351e-01,  1.3413e+00,  1.3525e+00],
        [ 1.1693e+00,  1.1953e+00,  1.2470e+00,  1.2288e+00,  1.2023e+00,
          1.1749e+00,  1.1818e+00,  1.1677e+00,  1.1677e+00,  1.2436e+00,
          1.2628e+00,  1.2593e+00,  1.2863e+00,  1.2285e+00,  1.2978e+00,
          1.2416e+00,  1.2155e+00,  1.2123e+00,  2.6288e+00,  2.7321e+00,
          2.8222e+00,  2.7455e+00,  2.5361e+00,  2.6236e+00,  2.6554e+00,
          2.5236e+00,  2.5236e+00,  1.2522e+00,  1.2449e+00,  1.1939e+00,
          1.2168e+00,  1.2517e+00,  1.2040e+00,  1.2351e+00,  1.1985e+00,
          1.1965e+00,  1.3652e+00,  1.4076e+00,  1.3834e+00,  1.3564e+00,
          1.3933e+00,  1.3819e+00,  1.3701e+00,  1.3003e+00,  1.2961e+00,
          1.2841e+00,  1.2652e+00,  1.2525e+00,  1.2332e+00,  1.2562e+00,
          1.2535e+00,  1.3153e+00,  1.2247e+00,  1.2316e+00],
        [ 1.1762e+00,  1.2034e+00,  1.2518e+00,  1.2331e+00,  1.2109e+00,
          1.1821e+00,  1.1895e+00,  1.1745e+00,  1.1745e+00,  1.2568e+00,
          1.2713e+00,  1.2729e+00,  1.2988e+00,  1.2414e+00,  1.2532e+00,
          1.2548e+00,  1.2428e+00,  1.1741e+00,  1.2359e+00,  1.2600e+00,
          1.2744e+00,  1.2485e+00,  1.2110e+00,  1.2027e+00,  1.2283e+00,
          1.1991e+00,  1.1991e+00,  2.8568e+00,  2.7657e+00,  2.4312e+00,
          2.5792e+00,  2.8519e+00,  2.4420e+00,  2.8080e+00,  2.4396e+00,
          2.4338e+00,  1.3640e+00,  1.4078e+00,  1.3806e+00,  1.3706e+00,
          1.3931e+00,  1.3810e+00,  1.3687e+00,  1.2902e+00,  1.3104e+00,
          1.3255e+00,  1.2731e+00,  1.1688e+00,  1.1970e+00,  1.3165e+00,
          1.2561e+00,  1.3576e+00,  1.1884e+00,  1.2404e+00],
        [ 1.6905e+00,  1.3766e+00,  6.3334e-01,  8.3236e-01,  1.1896e+00,
          1.5835e+00,  1.5235e+00,  1.6874e+00,  1.6874e+00,  1.5377e+00,
          1.2430e+00,  1.3786e+00,  9.1836e-01,  1.6267e+00,  2.9321e-01,
          1.5254e+00,  1.6508e+00,  1.1029e+00,  1.3303e+00,  9.0718e-01,
          7.9592e-01,  1.1184e+00,  1.5685e+00,  1.6204e+00,  1.3641e+00,
          1.7049e+00,  1.7049e+00,  7.2361e-01,  8.6819e-01,  1.6612e+00,
          1.4750e+00,  8.0878e-01,  1.6011e+00,  1.0931e+00,  1.7128e+00,
          1.6304e+00,  2.2065e-01, -3.9289e-03, -2.1714e-02,  1.7703e-01,
          4.2450e-01,  5.7838e-01,  1.2456e-01,  1.1913e+01,  7.5378e+00,
          7.9474e-01,  1.2104e+00,  1.3061e+00,  1.5234e+00,  1.0185e+00,
          1.4558e+00,  4.5679e-01,  1.5816e+00,  1.6871e+00],
        [ 1.2359e+00,  1.2673e+00,  1.3293e+00,  1.3084e+00,  1.2766e+00,
          1.2427e+00,  1.2076e+00,  1.2340e+00,  1.2340e+00,  1.2097e+00,
          1.3269e+00,  1.2281e+00,  1.3550e+00,  1.2865e+00,  1.4073e+00,
          1.2073e+00,  1.2885e+00,  1.2300e+00,  1.2999e+00,  1.3300e+00,
          1.3444e+00,  1.3139e+00,  1.2712e+00,  1.2630e+00,  1.2092e+00,
          1.2574e+00,  1.2574e+00,  1.3026e+00,  1.3441e+00,  1.2624e+00,
          1.0787e+00,  1.2558e+00,  1.1405e+00,  1.3104e+00,  1.1357e+00,
          1.2654e+00,  1.3645e+00,  1.0561e+00,  1.3856e+00,  1.3753e+00,
          9.4867e-01,  8.5259e-01,  1.3704e+00,  1.3592e+00,  7.3631e-01,
          3.1662e+00,  2.5191e+00,  3.3122e+00,  2.7816e+00,  2.1283e+00,
          1.8209e+00,  2.9000e+00,  3.0846e+00,  1.8000e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 194 : 180.37123587486357
Test loss for epoch 194 : 180.490887629091
Test Precision for epoch 194 : 0.26153846153846155
Test Recall for epoch 194 : 0.26153846153846155
Test F1 for epoch 194 : 0.26153846153846155


theta for epoch 195 : tensor([[ 2.5696e+00,  2.5997e+00,  2.6735e+00,  2.7868e+00,  2.7500e+00,
          2.5758e+00,  2.7256e+00,  2.5678e+00,  2.5678e+00,  1.2463e+00,
          1.2652e+00,  1.2618e+00,  1.2885e+00,  1.2314e+00,  1.3329e+00,
          1.2444e+00,  1.2332e+00,  1.2167e+00,  1.1986e+00,  1.1805e+00,
          1.1921e+00,  1.2108e+00,  1.1748e+00,  1.1684e+00,  1.1919e+00,
          1.1634e+00,  1.1634e+00,  1.2201e+00,  1.2621e+00,  1.1928e+00,
          1.2156e+00,  1.2642e+00,  1.2029e+00,  1.2337e+00,  1.1529e+00,
          1.1954e+00,  1.3599e+00,  1.4021e+00,  1.3781e+00,  1.3686e+00,
          1.3879e+00,  1.3195e+00,  1.3647e+00,  1.3559e+00,  1.3088e+00,
          1.3095e+00,  1.2608e+00,  1.2481e+00,  1.2290e+00,  1.3008e+00,
          1.2491e+00,  1.3406e+00,  1.2207e+00,  1.2274e+00],
        [ 1.2741e+00,  1.1857e+00,  1.0095e+00,  1.2298e+00,  1.3105e+00,
          1.3251e+00,  1.2492e+00,  1.3159e+00,  1.3159e+00,  1.5116e+00,
          1.7422e+00,  1.5177e+00,  2.2395e+00,  1.5502e+00,  5.8610e+00,
          1.6169e+00,  1.4462e+00,  5.7021e+00,  1.0897e+00,  1.1735e+00,
          9.6718e-01,  1.1374e+00,  1.2724e+00,  1.3063e+00,  1.2716e+00,
          1.3002e+00,  1.3002e+00,  1.2912e+00,  1.0206e+00,  1.3324e+00,
          1.3122e+00,  1.1302e+00,  1.3450e+00,  1.3786e+00,  1.2938e+00,
          1.3304e+00,  1.3133e+00,  1.4592e+00,  1.3691e+00,  1.2807e+00,
          1.2996e+00,  1.4251e+00,  1.3520e+00,  4.8116e-01,  1.3331e+00,
          1.0244e+00,  1.3935e+00,  1.3740e+00,  1.3507e+00,  1.0398e+00,
          1.3779e+00,  8.7212e-01,  1.3403e+00,  1.3516e+00],
        [ 1.1931e+00,  1.2193e+00,  1.2710e+00,  1.2529e+00,  1.2263e+00,
          1.1988e+00,  1.2057e+00,  1.1915e+00,  1.1915e+00,  1.2607e+00,
          1.2799e+00,  1.2764e+00,  1.3033e+00,  1.2457e+00,  1.3137e+00,
          1.2587e+00,  1.2326e+00,  1.2302e+00,  2.6033e+00,  2.7074e+00,
          2.7972e+00,  2.7198e+00,  2.5109e+00,  2.5980e+00,  2.6303e+00,
          2.4983e+00,  2.4983e+00,  1.2666e+00,  1.2597e+00,  1.2085e+00,
          1.2312e+00,  1.2660e+00,  1.2185e+00,  1.2495e+00,  1.2130e+00,
          1.2110e+00,  1.3688e+00,  1.4112e+00,  1.3870e+00,  1.3598e+00,
          1.3968e+00,  1.3855e+00,  1.3737e+00,  1.3047e+00,  1.2995e+00,
          1.2928e+00,  1.2735e+00,  1.2608e+00,  1.2415e+00,  1.2653e+00,
          1.2618e+00,  1.3240e+00,  1.2330e+00,  1.2400e+00],
        [ 1.1856e+00,  1.2128e+00,  1.2608e+00,  1.2420e+00,  1.2202e+00,
          1.1914e+00,  1.1988e+00,  1.1839e+00,  1.1839e+00,  1.2592e+00,
          1.2738e+00,  1.2753e+00,  1.3012e+00,  1.2438e+00,  1.2553e+00,
          1.2572e+00,  1.2452e+00,  1.1764e+00,  1.2134e+00,  1.2387e+00,
          1.2521e+00,  1.2261e+00,  1.1885e+00,  1.1804e+00,  1.2058e+00,
          1.1765e+00,  1.1765e+00,  2.8632e+00,  2.7741e+00,  2.4387e+00,
          2.5872e+00,  2.8583e+00,  2.4495e+00,  2.8145e+00,  2.4471e+00,
          2.4413e+00,  1.3615e+00,  1.4053e+00,  1.3781e+00,  1.3681e+00,
          1.3906e+00,  1.3785e+00,  1.3662e+00,  1.2880e+00,  1.3078e+00,
          1.3247e+00,  1.2725e+00,  1.1681e+00,  1.1963e+00,  1.3158e+00,
          1.2557e+00,  1.3568e+00,  1.1877e+00,  1.2397e+00],
        [ 1.7034e+00,  1.3893e+00,  6.4324e-01,  8.4312e-01,  1.2021e+00,
          1.5964e+00,  1.5363e+00,  1.7003e+00,  1.7003e+00,  1.5446e+00,
          1.2497e+00,  1.3852e+00,  9.2447e-01,  1.6335e+00,  2.9817e-01,
          1.5320e+00,  1.6579e+00,  1.1088e+00,  1.3133e+00,  8.9218e-01,
          7.8134e-01,  1.1021e+00,  1.5505e+00,  1.6021e+00,  1.3475e+00,
          1.6867e+00,  1.6867e+00,  7.2889e-01,  8.7296e-01,  1.6665e+00,
          1.4805e+00,  8.1414e-01,  1.6063e+00,  1.0986e+00,  1.7180e+00,
          1.6356e+00,  2.1776e-01, -6.8965e-03, -2.4557e-02,  1.7398e-01,
          4.2127e-01,  5.7481e-01,  1.2159e-01,  1.1954e+01,  7.5284e+00,
          7.9811e-01,  1.2138e+00,  1.3094e+00,  1.5264e+00,  1.0216e+00,
          1.4587e+00,  4.6002e-01,  1.5847e+00,  1.6899e+00],
        [ 1.2473e+00,  1.2787e+00,  1.3406e+00,  1.3198e+00,  1.2880e+00,
          1.2541e+00,  1.2189e+00,  1.2454e+00,  1.2454e+00,  1.2141e+00,
          1.3316e+00,  1.2324e+00,  1.3597e+00,  1.2911e+00,  1.4117e+00,
          1.2117e+00,  1.2931e+00,  1.2345e+00,  1.2775e+00,  1.3078e+00,
          1.3229e+00,  1.2917e+00,  1.2487e+00,  1.2405e+00,  1.1865e+00,
          1.2349e+00,  1.2349e+00,  1.3053e+00,  1.3469e+00,  1.2653e+00,
          1.0811e+00,  1.2585e+00,  1.1433e+00,  1.3133e+00,  1.1384e+00,
          1.2684e+00,  1.3615e+00,  1.0524e+00,  1.3826e+00,  1.3723e+00,
          9.4477e-01,  8.4862e-01,  1.3675e+00,  1.3560e+00,  7.3227e-01,
          3.1749e+00,  2.5246e+00,  3.3222e+00,  2.7878e+00,  2.1330e+00,
          1.8253e+00,  2.9063e+00,  3.0934e+00,  1.8045e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 195 : 180.45231855704841
Test loss for epoch 195 : 180.57740638320757
Test Precision for epoch 195 : 0.26153846153846155
Test Recall for epoch 195 : 0.26153846153846155
Test F1 for epoch 195 : 0.26153846153846155


theta for epoch 196 : tensor([[ 2.5420e+00,  2.5723e+00,  2.6463e+00,  2.7599e+00,  2.7230e+00,
          2.5483e+00,  2.6984e+00,  2.5403e+00,  2.5403e+00,  1.2518e+00,
          1.2708e+00,  1.2673e+00,  1.2940e+00,  1.2369e+00,  1.3384e+00,
          1.2498e+00,  1.2386e+00,  1.2227e+00,  1.2180e+00,  1.2001e+00,
          1.2115e+00,  1.2301e+00,  1.1942e+00,  1.1878e+00,  1.2112e+00,
          1.1828e+00,  1.1828e+00,  1.2395e+00,  1.2810e+00,  1.2120e+00,
          1.2347e+00,  1.2831e+00,  1.2220e+00,  1.2527e+00,  1.1725e+00,
          1.2146e+00,  1.3690e+00,  1.4112e+00,  1.3873e+00,  1.3778e+00,
          1.3970e+00,  1.3289e+00,  1.3739e+00,  1.3650e+00,  1.3180e+00,
          1.3213e+00,  1.2728e+00,  1.2600e+00,  1.2410e+00,  1.3127e+00,
          1.2610e+00,  1.3523e+00,  1.2327e+00,  1.2395e+00],
        [ 1.2487e+00,  1.1613e+00,  9.8764e-01,  1.2054e+00,  1.2855e+00,
          1.2996e+00,  1.2240e+00,  1.2904e+00,  1.2904e+00,  1.5006e+00,
          1.7305e+00,  1.5064e+00,  2.2273e+00,  1.5390e+00,  5.8666e+00,
          1.6056e+00,  1.4351e+00,  5.7077e+00,  1.1043e+00,  1.1879e+00,
          9.8131e-01,  1.1518e+00,  1.2867e+00,  1.3206e+00,  1.2857e+00,
          1.3145e+00,  1.3145e+00,  1.3040e+00,  1.0346e+00,  1.3449e+00,
          1.3249e+00,  1.1438e+00,  1.3574e+00,  1.3911e+00,  1.3064e+00,
          1.3431e+00,  1.3193e+00,  1.4647e+00,  1.3747e+00,  1.2866e+00,
          1.3056e+00,  1.4306e+00,  1.3575e+00,  4.8849e-01,  1.3383e+00,
          1.0333e+00,  1.4011e+00,  1.3816e+00,  1.3583e+00,  1.0486e+00,
          1.3856e+00,  8.8146e-01,  1.3479e+00,  1.3593e+00],
        [ 1.1616e+00,  1.1878e+00,  1.2397e+00,  1.2214e+00,  1.1948e+00,
          1.1673e+00,  1.1742e+00,  1.1600e+00,  1.1600e+00,  1.2499e+00,
          1.2692e+00,  1.2656e+00,  1.2927e+00,  1.2349e+00,  1.3038e+00,
          1.2480e+00,  1.2215e+00,  1.2201e+00,  2.6193e+00,  2.7239e+00,
          2.8131e+00,  2.7353e+00,  2.5275e+00,  2.6142e+00,  2.6468e+00,
          2.5150e+00,  2.5150e+00,  1.2705e+00,  1.2642e+00,  1.2127e+00,
          1.2354e+00,  1.2700e+00,  1.2227e+00,  1.2537e+00,  1.2172e+00,
          1.2153e+00,  1.3684e+00,  1.4109e+00,  1.3867e+00,  1.3592e+00,
          1.3965e+00,  1.3852e+00,  1.3733e+00,  1.3048e+00,  1.2986e+00,
          1.2936e+00,  1.2741e+00,  1.2612e+00,  1.2420e+00,  1.2664e+00,
          1.2623e+00,  1.3248e+00,  1.2335e+00,  1.2405e+00],
        [ 1.1600e+00,  1.1873e+00,  1.2367e+00,  1.2182e+00,  1.1948e+00,
          1.1659e+00,  1.1733e+00,  1.1583e+00,  1.1583e+00,  1.2514e+00,
          1.2665e+00,  1.2676e+00,  1.2938e+00,  1.2360e+00,  1.2479e+00,
          1.2494e+00,  1.2374e+00,  1.1700e+00,  1.2200e+00,  1.2450e+00,
          1.2586e+00,  1.2327e+00,  1.1951e+00,  1.1871e+00,  1.2124e+00,
          1.1832e+00,  1.1832e+00,  2.8709e+00,  2.7839e+00,  2.4476e+00,
          2.5965e+00,  2.8661e+00,  2.4584e+00,  2.8223e+00,  2.4559e+00,
          2.4502e+00,  1.3632e+00,  1.4070e+00,  1.3800e+00,  1.3700e+00,
          1.3924e+00,  1.3803e+00,  1.3680e+00,  1.2898e+00,  1.3095e+00,
          1.3268e+00,  1.2747e+00,  1.1701e+00,  1.1986e+00,  1.3179e+00,
          1.2580e+00,  1.3589e+00,  1.1899e+00,  1.2420e+00],
        [ 1.6794e+00,  1.3654e+00,  6.2379e-01,  8.2236e-01,  1.1782e+00,
          1.5723e+00,  1.5123e+00,  1.6763e+00,  1.6763e+00,  1.5366e+00,
          1.2407e+00,  1.3772e+00,  9.1592e-01,  1.6256e+00,  2.9054e-01,
          1.5241e+00,  1.6504e+00,  1.0991e+00,  1.3187e+00,  8.9625e-01,
          7.8476e-01,  1.1067e+00,  1.5568e+00,  1.6083e+00,  1.3533e+00,
          1.6934e+00,  1.6934e+00,  7.3215e-01,  8.7632e-01,  1.6726e+00,
          1.4863e+00,  8.1772e-01,  1.6123e+00,  1.1032e+00,  1.7243e+00,
          1.6416e+00,  2.2130e-01, -3.6378e-03, -2.1174e-02,  1.7739e-01,
          4.2461e-01,  5.7796e-01,  1.2498e-01,  1.2001e+01,  7.5247e+00,
          7.9919e-01,  1.2166e+00,  1.3127e+00,  1.5301e+00,  1.0233e+00,
          1.4622e+00,  4.5961e-01,  1.5889e+00,  1.6940e+00],
        [ 1.2206e+00,  1.2520e+00,  1.3141e+00,  1.2932e+00,  1.2613e+00,
          1.2274e+00,  1.1922e+00,  1.2187e+00,  1.2187e+00,  1.2054e+00,
          1.3232e+00,  1.2239e+00,  1.3512e+00,  1.2826e+00,  1.4036e+00,
          1.2031e+00,  1.2846e+00,  1.2258e+00,  1.2855e+00,  1.3157e+00,
          1.3306e+00,  1.2997e+00,  1.2568e+00,  1.2487e+00,  1.1943e+00,
          1.2430e+00,  1.2430e+00,  1.3121e+00,  1.3536e+00,  1.2724e+00,
          1.0876e+00,  1.2652e+00,  1.1500e+00,  1.3202e+00,  1.1453e+00,
          1.2755e+00,  1.3646e+00,  1.0550e+00,  1.3858e+00,  1.3755e+00,
          9.4722e-01,  8.5099e-01,  1.3707e+00,  1.3590e+00,  7.3446e-01,
          3.1849e+00,  2.5315e+00,  3.3336e+00,  2.7955e+00,  2.1392e+00,
          1.8314e+00,  2.9139e+00,  3.1036e+00,  1.8105e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 196 : 180.41679404956508
Test loss for epoch 196 : 180.53560655074403
Test Precision for epoch 196 : 0.26153846153846155
Test Recall for epoch 196 : 0.26153846153846155
Test F1 for epoch 196 : 0.26153846153846155


theta for epoch 197 : tensor([[ 2.5565e+00,  2.5866e+00,  2.6606e+00,  2.7745e+00,  2.7377e+00,
          2.5627e+00,  2.7132e+00,  2.5547e+00,  2.5547e+00,  1.2478e+00,
          1.2669e+00,  1.2634e+00,  1.2902e+00,  1.2328e+00,  1.3348e+00,
          1.2458e+00,  1.2345e+00,  1.2186e+00,  1.2298e+00,  1.2117e+00,
          1.2231e+00,  1.2420e+00,  1.2060e+00,  1.1997e+00,  1.2231e+00,
          1.1946e+00,  1.1946e+00,  1.2171e+00,  1.2589e+00,  1.1898e+00,
          1.2126e+00,  1.2610e+00,  1.1998e+00,  1.2306e+00,  1.1502e+00,
          1.1924e+00,  1.3662e+00,  1.4085e+00,  1.3845e+00,  1.3750e+00,
          1.3943e+00,  1.3260e+00,  1.3711e+00,  1.3622e+00,  1.3152e+00,
          1.3119e+00,  1.2633e+00,  1.2506e+00,  1.2315e+00,  1.3033e+00,
          1.2516e+00,  1.3430e+00,  1.2232e+00,  1.2300e+00],
        [ 1.2563e+00,  1.1689e+00,  9.9530e-01,  1.2130e+00,  1.2932e+00,
          1.3071e+00,  1.2317e+00,  1.2979e+00,  1.2979e+00,  1.4988e+00,
          1.7280e+00,  1.5046e+00,  2.2240e+00,  1.5371e+00,  5.8798e+00,
          1.6036e+00,  1.4334e+00,  5.7213e+00,  1.1237e+00,  1.2073e+00,
          9.9973e-01,  1.1711e+00,  1.3062e+00,  1.3401e+00,  1.3051e+00,
          1.3340e+00,  1.3340e+00,  1.2874e+00,  1.0183e+00,  1.3283e+00,
          1.3083e+00,  1.1271e+00,  1.3409e+00,  1.3745e+00,  1.2898e+00,
          1.3265e+00,  1.3204e+00,  1.4654e+00,  1.3753e+00,  1.2875e+00,
          1.3069e+00,  1.4315e+00,  1.3582e+00,  4.9025e-01,  1.3390e+00,
          1.0288e+00,  1.3958e+00,  1.3761e+00,  1.3529e+00,  1.0437e+00,
          1.3802e+00,  8.7766e-01,  1.3424e+00,  1.3539e+00],
        [ 1.1616e+00,  1.1877e+00,  1.2395e+00,  1.2213e+00,  1.1946e+00,
          1.1672e+00,  1.1741e+00,  1.1599e+00,  1.1599e+00,  1.2462e+00,
          1.2656e+00,  1.2620e+00,  1.2891e+00,  1.2312e+00,  1.3004e+00,
          1.2443e+00,  1.2175e+00,  1.2170e+00,  2.6391e+00,  2.7442e+00,
          2.8327e+00,  2.7545e+00,  2.5480e+00,  2.6342e+00,  2.6671e+00,
          2.5354e+00,  2.5354e+00,  1.2472e+00,  1.2412e+00,  1.1896e+00,
          1.2124e+00,  1.2466e+00,  1.1997e+00,  1.2308e+00,  1.1941e+00,
          1.1922e+00,  1.3645e+00,  1.4073e+00,  1.3830e+00,  1.3551e+00,
          1.3928e+00,  1.3815e+00,  1.3695e+00,  1.3016e+00,  1.2945e+00,
          1.2838e+00,  1.2639e+00,  1.2510e+00,  1.2317e+00,  1.2568e+00,
          1.2521e+00,  1.3151e+00,  1.2232e+00,  1.2302e+00],
        [ 1.1701e+00,  1.1972e+00,  1.2462e+00,  1.2276e+00,  1.2047e+00,
          1.1760e+00,  1.1834e+00,  1.1684e+00,  1.1684e+00,  1.2590e+00,
          1.2740e+00,  1.2750e+00,  1.3012e+00,  1.2436e+00,  1.2555e+00,
          1.2570e+00,  1.2449e+00,  1.1772e+00,  1.2400e+00,  1.2641e+00,
          1.2786e+00,  1.2527e+00,  1.2151e+00,  1.2071e+00,  1.2324e+00,
          1.2033e+00,  1.2033e+00,  2.8628e+00,  2.7774e+00,  2.4401e+00,
          2.5895e+00,  2.8580e+00,  2.4509e+00,  2.8142e+00,  2.4484e+00,
          2.4428e+00,  1.3658e+00,  1.4097e+00,  1.3827e+00,  1.3727e+00,
          1.3951e+00,  1.3831e+00,  1.3707e+00,  1.2926e+00,  1.3123e+00,
          1.3250e+00,  1.2730e+00,  1.1687e+00,  1.1969e+00,  1.3162e+00,
          1.2565e+00,  1.3571e+00,  1.1882e+00,  1.2402e+00],
        [ 1.6865e+00,  1.3725e+00,  6.2951e-01,  8.2858e-01,  1.1852e+00,
          1.5795e+00,  1.5195e+00,  1.6834e+00,  1.6834e+00,  1.5396e+00,
          1.2436e+00,  1.3802e+00,  9.1868e-01,  1.6286e+00,  2.9301e-01,
          1.5271e+00,  1.6535e+00,  1.1012e+00,  1.3331e+00,  9.0986e-01,
          7.9774e-01,  1.1207e+00,  1.5720e+00,  1.6231e+00,  1.3681e+00,
          1.7085e+00,  1.7085e+00,  7.2167e-01,  8.6552e-01,  1.6593e+00,
          1.4734e+00,  8.0670e-01,  1.5991e+00,  1.0906e+00,  1.7110e+00,
          1.6282e+00,  2.1940e-01, -5.5712e-03, -2.3030e-02,  1.7536e-01,
          4.2245e-01,  5.7544e-01,  1.2300e-01,  1.2042e+01,  7.5154e+00,
          7.9346e-01,  1.2102e+00,  1.3062e+00,  1.5236e+00,  1.0169e+00,
          1.4555e+00,  4.5472e-01,  1.5824e+00,  1.6875e+00],
        [ 1.2300e+00,  1.2613e+00,  1.3231e+00,  1.3023e+00,  1.2705e+00,
          1.2367e+00,  1.2016e+00,  1.2280e+00,  1.2280e+00,  1.2130e+00,
          1.3306e+00,  1.2314e+00,  1.3588e+00,  1.2898e+00,  1.4109e+00,
          1.2107e+00,  1.2918e+00,  1.2337e+00,  1.3046e+00,  1.3347e+00,
          1.3491e+00,  1.3187e+00,  1.2759e+00,  1.2677e+00,  1.2132e+00,
          1.2621e+00,  1.2621e+00,  1.2994e+00,  1.3410e+00,  1.2592e+00,
          1.0750e+00,  1.2528e+00,  1.1375e+00,  1.3073e+00,  1.1326e+00,
          1.2623e+00,  1.3666e+00,  1.0575e+00,  1.3877e+00,  1.3776e+00,
          9.4990e-01,  8.5390e-01,  1.3727e+00,  1.3610e+00,  7.3751e-01,
          3.1814e+00,  2.5243e+00,  3.3309e+00,  2.7893e+00,  2.1315e+00,
          1.8233e+00,  2.9081e+00,  3.0996e+00,  1.8024e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 197 : 180.42801879713303
Test loss for epoch 197 : 180.54931105250657
Test Precision for epoch 197 : 0.26153846153846155
Test Recall for epoch 197 : 0.26153846153846155
Test F1 for epoch 197 : 0.26153846153846155


theta for epoch 198 : tensor([[ 2.5867e+00,  2.6168e+00,  2.6905e+00,  2.8049e+00,  2.7680e+00,
          2.5929e+00,  2.7437e+00,  2.5849e+00,  2.5849e+00,  1.2444e+00,
          1.2636e+00,  1.2601e+00,  1.2871e+00,  1.2295e+00,  1.3317e+00,
          1.2425e+00,  1.2311e+00,  1.2150e+00,  1.1897e+00,  1.1715e+00,
          1.1831e+00,  1.2019e+00,  1.1659e+00,  1.1595e+00,  1.1830e+00,
          1.1544e+00,  1.1544e+00,  1.2103e+00,  1.2525e+00,  1.1833e+00,
          1.2061e+00,  1.2545e+00,  1.1934e+00,  1.2241e+00,  1.1434e+00,
          1.1859e+00,  1.3594e+00,  1.4019e+00,  1.3779e+00,  1.3684e+00,
          1.3876e+00,  1.3191e+00,  1.3645e+00,  1.3553e+00,  1.3083e+00,
          1.3061e+00,  1.2575e+00,  1.2447e+00,  1.2256e+00,  1.2975e+00,
          1.2457e+00,  1.3372e+00,  1.2173e+00,  1.2241e+00],
        [ 1.2791e+00,  1.1909e+00,  1.0159e+00,  1.2353e+00,  1.3161e+00,
          1.3300e+00,  1.2543e+00,  1.3208e+00,  1.3208e+00,  1.5103e+00,
          1.7390e+00,  1.5162e+00,  2.2339e+00,  1.5487e+00,  5.9043e+00,
          1.6152e+00,  1.4451e+00,  5.7472e+00,  1.0894e+00,  1.1731e+00,
          9.6765e-01,  1.1370e+00,  1.2716e+00,  1.3056e+00,  1.2705e+00,
          1.2994e+00,  1.2994e+00,  1.2868e+00,  1.0173e+00,  1.3278e+00,
          1.3078e+00,  1.1261e+00,  1.3404e+00,  1.3741e+00,  1.2892e+00,
          1.3262e+00,  1.3174e+00,  1.4623e+00,  1.3720e+00,  1.2842e+00,
          1.3039e+00,  1.4284e+00,  1.3548e+00,  4.8601e-01,  1.3357e+00,
          1.0273e+00,  1.3948e+00,  1.3750e+00,  1.3517e+00,  1.0421e+00,
          1.3792e+00,  8.7622e-01,  1.3412e+00,  1.3528e+00],
        [ 1.1941e+00,  1.2202e+00,  1.2720e+00,  1.2539e+00,  1.2273e+00,
          1.1997e+00,  1.2067e+00,  1.1925e+00,  1.1925e+00,  1.2657e+00,
          1.2850e+00,  1.2813e+00,  1.3083e+00,  1.2507e+00,  1.3183e+00,
          1.2637e+00,  1.2369e+00,  1.2371e+00,  2.6113e+00,  2.7172e+00,
          2.8053e+00,  2.7265e+00,  2.5204e+00,  2.6063e+00,  2.6398e+00,
          2.5079e+00,  2.5079e+00,  1.2586e+00,  1.2531e+00,  1.2011e+00,
          1.2239e+00,  1.2580e+00,  1.2112e+00,  1.2423e+00,  1.2056e+00,
          1.2037e+00,  1.3684e+00,  1.4112e+00,  1.3868e+00,  1.3588e+00,
          1.3967e+00,  1.3855e+00,  1.3734e+00,  1.3062e+00,  1.2983e+00,
          1.2927e+00,  1.2723e+00,  1.2594e+00,  1.2402e+00,  1.2661e+00,
          1.2605e+00,  1.3239e+00,  1.2316e+00,  1.2387e+00],
        [ 1.1905e+00,  1.2176e+00,  1.2656e+00,  1.2469e+00,  1.2249e+00,
          1.1963e+00,  1.2037e+00,  1.1888e+00,  1.1888e+00,  1.2649e+00,
          1.2800e+00,  1.2809e+00,  1.3071e+00,  1.2495e+00,  1.2611e+00,
          1.2630e+00,  1.2508e+00,  1.1825e+00,  1.2105e+00,  1.2358e+00,
          1.2490e+00,  1.2232e+00,  1.1856e+00,  1.1777e+00,  1.2029e+00,
          1.1736e+00,  1.1736e+00,  2.8672e+00,  2.7836e+00,  2.4454e+00,
          2.5953e+00,  2.8624e+00,  2.4563e+00,  2.8186e+00,  2.4538e+00,
          2.4481e+00,  1.3641e+00,  1.4081e+00,  1.3811e+00,  1.3711e+00,
          1.3934e+00,  1.3815e+00,  1.3690e+00,  1.2912e+00,  1.3107e+00,
          1.3250e+00,  1.2730e+00,  1.1687e+00,  1.1969e+00,  1.3161e+00,
          1.2567e+00,  1.3571e+00,  1.1881e+00,  1.2401e+00],
        [ 1.7109e+00,  1.3970e+00,  6.4978e-01,  8.5018e-01,  1.2096e+00,
          1.6040e+00,  1.5439e+00,  1.7078e+00,  1.7078e+00,  1.5515e+00,
          1.2560e+00,  1.3919e+00,  9.3039e-01,  1.6402e+00,  3.0336e-01,
          1.5387e+00,  1.6653e+00,  1.1127e+00,  1.3105e+00,  8.9036e-01,
          7.7893e-01,  1.0992e+00,  1.5477e+00,  1.5984e+00,  1.3457e+00,
          1.6837e+00,  1.6837e+00,  7.2829e-01,  8.7123e-01,  1.6640e+00,
          1.4786e+00,  8.1326e-01,  1.6040e+00,  1.0967e+00,  1.7156e+00,
          1.6329e+00,  2.1388e-01, -1.0993e-02, -2.8338e-02,  1.6969e-01,
          4.1651e-01,  5.6901e-01,  1.1745e-01,  1.2081e+01,  7.5018e+00,
          8.0082e-01,  1.2166e+00,  1.3123e+00,  1.5287e+00,  1.0235e+00,
          1.4607e+00,  4.6261e-01,  1.5875e+00,  1.6920e+00],
        [ 1.2529e+00,  1.2842e+00,  1.3458e+00,  1.3250e+00,  1.2934e+00,
          1.2596e+00,  1.2244e+00,  1.2510e+00,  1.2510e+00,  1.2215e+00,
          1.3394e+00,  1.2400e+00,  1.3677e+00,  1.2985e+00,  1.4193e+00,
          1.2192e+00,  1.3005e+00,  1.2424e+00,  1.2745e+00,  1.3047e+00,
          1.3198e+00,  1.2887e+00,  1.2457e+00,  1.2376e+00,  1.1830e+00,
          1.2319e+00,  1.2319e+00,  1.3005e+00,  1.3421e+00,  1.2604e+00,
          1.0758e+00,  1.2539e+00,  1.1386e+00,  1.3085e+00,  1.1336e+00,
          1.2635e+00,  1.3644e+00,  1.0548e+00,  1.3855e+00,  1.3754e+00,
          9.4701e-01,  8.5099e-01,  1.3706e+00,  1.3586e+00,  7.3459e-01,
          3.1885e+00,  2.5282e+00,  3.3393e+00,  2.7940e+00,  2.1347e+00,
          1.8263e+00,  2.9129e+00,  3.1067e+00,  1.8054e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 198 : 180.56962774183478
Test loss for epoch 198 : 180.699130844189
Test Precision for epoch 198 : 0.26153846153846155
Test Recall for epoch 198 : 0.26153846153846155
Test F1 for epoch 198 : 0.26153846153846155


theta for epoch 199 : tensor([[ 2.5528e+00,  2.5831e+00,  2.6570e+00,  2.7716e+00,  2.7347e+00,
          2.5591e+00,  2.7102e+00,  2.5511e+00,  2.5511e+00,  1.2499e+00,
          1.2691e+00,  1.2655e+00,  1.2926e+00,  1.2349e+00,  1.3372e+00,
          1.2479e+00,  1.2365e+00,  1.2211e+00,  1.2058e+00,  1.1878e+00,
          1.1994e+00,  1.2180e+00,  1.1820e+00,  1.1757e+00,  1.1990e+00,
          1.1706e+00,  1.1706e+00,  1.2428e+00,  1.2843e+00,  1.2156e+00,
          1.2381e+00,  1.2864e+00,  1.2255e+00,  1.2562e+00,  1.1760e+00,
          1.2182e+00,  1.3722e+00,  1.4146e+00,  1.3906e+00,  1.3812e+00,
          1.4002e+00,  1.3322e+00,  1.3773e+00,  1.3680e+00,  1.3210e+00,
          1.3244e+00,  1.2759e+00,  1.2631e+00,  1.2441e+00,  1.3159e+00,
          1.2642e+00,  1.3553e+00,  1.2358e+00,  1.2427e+00],
        [ 1.2466e+00,  1.1594e+00,  9.8677e-01,  1.2038e+00,  1.2842e+00,
          1.2975e+00,  1.2220e+00,  1.2883e+00,  1.2883e+00,  1.4998e+00,
          1.7278e+00,  1.5055e+00,  2.2223e+00,  1.5380e+00,  5.9097e+00,
          1.6044e+00,  1.4345e+00,  5.7525e+00,  1.0966e+00,  1.1802e+00,
          9.7492e-01,  1.1441e+00,  1.2787e+00,  1.3126e+00,  1.2773e+00,
          1.3064e+00,  1.3064e+00,  1.3091e+00,  1.0407e+00,  1.3499e+00,
          1.3301e+00,  1.1490e+00,  1.3624e+00,  1.3960e+00,  1.3114e+00,
          1.3485e+00,  1.3244e+00,  1.4687e+00,  1.3785e+00,  1.2910e+00,
          1.3109e+00,  1.4348e+00,  1.3614e+00,  4.9371e-01,  1.3419e+00,
          1.0392e+00,  1.4056e+00,  1.3858e+00,  1.3626e+00,  1.0539e+00,
          1.3901e+00,  8.8827e-01,  1.3521e+00,  1.3638e+00],
        [ 1.1599e+00,  1.1861e+00,  1.2380e+00,  1.2198e+00,  1.1931e+00,
          1.1656e+00,  1.1725e+00,  1.1583e+00,  1.1583e+00,  1.2507e+00,
          1.2701e+00,  1.2664e+00,  1.2934e+00,  1.2357e+00,  1.3043e+00,
          1.2487e+00,  1.2216e+00,  1.2228e+00,  2.6249e+00,  2.7312e+00,
          2.8188e+00,  2.7395e+00,  2.5345e+00,  2.6199e+00,  2.6537e+00,
          2.5219e+00,  2.5219e+00,  1.2725e+00,  1.2674e+00,  1.2151e+00,
          1.2379e+00,  1.2719e+00,  1.2252e+00,  1.2563e+00,  1.2196e+00,
          1.2177e+00,  1.3686e+00,  1.4116e+00,  1.3872e+00,  1.3588e+00,
          1.3970e+00,  1.3858e+00,  1.3738e+00,  1.3069e+00,  1.2980e+00,
          1.2966e+00,  1.2760e+00,  1.2630e+00,  1.2438e+00,  1.2703e+00,
          1.2642e+00,  1.3279e+00,  1.2352e+00,  1.2423e+00],
        [ 1.1586e+00,  1.1857e+00,  1.2353e+00,  1.2168e+00,  1.1932e+00,
          1.1645e+00,  1.1719e+00,  1.1569e+00,  1.1569e+00,  1.2505e+00,
          1.2661e+00,  1.2666e+00,  1.2931e+00,  1.2350e+00,  1.2471e+00,
          1.2484e+00,  1.2363e+00,  1.1701e+00,  1.2095e+00,  1.2348e+00,
          1.2480e+00,  1.2223e+00,  1.1847e+00,  1.1769e+00,  1.2019e+00,
          1.1728e+00,  1.1728e+00,  2.8808e+00,  2.7992e+00,  2.4602e+00,
          2.6105e+00,  2.8760e+00,  2.4711e+00,  2.8323e+00,  2.4685e+00,
          2.4629e+00,  1.3654e+00,  1.4096e+00,  1.3825e+00,  1.3725e+00,
          1.3948e+00,  1.3829e+00,  1.3704e+00,  1.2925e+00,  1.3120e+00,
          1.3284e+00,  1.2765e+00,  1.1718e+00,  1.2003e+00,  1.3195e+00,
          1.2601e+00,  1.3605e+00,  1.1915e+00,  1.2436e+00],
        [ 1.6831e+00,  1.3695e+00,  6.2746e-01,  8.2635e-01,  1.1823e+00,
          1.5762e+00,  1.5163e+00,  1.6800e+00,  1.6800e+00,  1.5413e+00,
          1.2452e+00,  1.3820e+00,  9.2062e-01,  1.6301e+00,  2.9519e-01,
          1.5287e+00,  1.6555e+00,  1.1013e+00,  1.3123e+00,  8.9153e-01,
          7.7957e-01,  1.1005e+00,  1.5501e+00,  1.6005e+00,  1.3480e+00,
          1.6863e+00,  1.6863e+00,  7.3988e-01,  8.8264e-01,  1.6793e+00,
          1.4936e+00,  8.2544e-01,  1.6191e+00,  1.1106e+00,  1.7308e+00,
          1.6480e+00,  2.1707e-01, -8.0188e-03, -2.5235e-02,  1.7275e-01,
          4.1945e-01,  5.7169e-01,  1.2051e-01,  1.2126e+01,  7.4964e+00,
          8.0742e-01,  1.2251e+00,  1.3213e+00,  1.5378e+00,  1.0308e+00,
          1.4696e+00,  4.6745e-01,  1.5970e+00,  1.7013e+00],
        [ 1.2209e+00,  1.2522e+00,  1.3140e+00,  1.2931e+00,  1.2614e+00,
          1.2277e+00,  1.1924e+00,  1.2190e+00,  1.2190e+00,  1.2067e+00,
          1.3246e+00,  1.2251e+00,  1.3527e+00,  1.2839e+00,  1.4049e+00,
          1.2044e+00,  1.2858e+00,  1.2274e+00,  1.2762e+00,  1.3063e+00,
          1.3214e+00,  1.2905e+00,  1.2476e+00,  1.2395e+00,  1.1845e+00,
          1.2338e+00,  1.2338e+00,  1.3157e+00,  1.3571e+00,  1.2760e+00,
          1.0905e+00,  1.2687e+00,  1.1536e+00,  1.3239e+00,  1.1489e+00,
          1.2791e+00,  1.3683e+00,  1.0580e+00,  1.3895e+00,  1.3794e+00,
          9.4994e-01,  8.5380e-01,  1.3746e+00,  1.3624e+00,  7.3717e-01,
          3.2018e+00,  2.5387e+00,  3.3542e+00,  2.8052e+00,  2.1445e+00,
          1.8360e+00,  2.9239e+00,  3.1204e+00,  1.8151e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 199 : 180.47428017148545
Test loss for epoch 199 : 180.59656748015536
Test Precision for epoch 199 : 0.26153846153846155
Test Recall for epoch 199 : 0.26153846153846155
Test F1 for epoch 199 : 0.26153846153846155


theta for epoch 200 : tensor([[ 2.5543e+00,  2.5845e+00,  2.6584e+00,  2.7733e+00,  2.7365e+00,
          2.5605e+00,  2.7119e+00,  2.5525e+00,  2.5525e+00,  1.2501e+00,
          1.2694e+00,  1.2657e+00,  1.2929e+00,  1.2351e+00,  1.3376e+00,
          1.2482e+00,  1.2367e+00,  1.2214e+00,  1.2313e+00,  1.2132e+00,
          1.2246e+00,  1.2434e+00,  1.2075e+00,  1.2012e+00,  1.2245e+00,
          1.1961e+00,  1.1961e+00,  1.2261e+00,  1.2676e+00,  1.1990e+00,
          1.2215e+00,  1.2697e+00,  1.2089e+00,  1.2395e+00,  1.1595e+00,
          1.2015e+00,  1.3731e+00,  1.4156e+00,  1.3916e+00,  1.3821e+00,
          1.4012e+00,  1.3332e+00,  1.3783e+00,  1.3687e+00,  1.3219e+00,
          1.3168e+00,  1.2683e+00,  1.2555e+00,  1.2366e+00,  1.3083e+00,
          1.2567e+00,  1.3478e+00,  1.2282e+00,  1.2351e+00],
        [ 1.2462e+00,  1.1591e+00,  9.8691e-01,  1.2036e+00,  1.2840e+00,
          1.2971e+00,  1.2216e+00,  1.2879e+00,  1.2879e+00,  1.4995e+00,
          1.7269e+00,  1.5052e+00,  2.2205e+00,  1.5377e+00,  5.9235e+00,
          1.6040e+00,  1.4344e+00,  5.7669e+00,  1.1235e+00,  1.2071e+00,
          1.0004e+00,  1.1709e+00,  1.3059e+00,  1.3400e+00,  1.3044e+00,
          1.3338e+00,  1.3338e+00,  1.2910e+00,  1.0226e+00,  1.3318e+00,
          1.3121e+00,  1.1307e+00,  1.3444e+00,  1.3780e+00,  1.2934e+00,
          1.3305e+00,  1.3261e+00,  1.4700e+00,  1.3797e+00,  1.2924e+00,
          1.3126e+00,  1.4362e+00,  1.3626e+00,  4.9543e-01,  1.3431e+00,
          1.0310e+00,  1.3970e+00,  1.3772e+00,  1.3540e+00,  1.0454e+00,
          1.3816e+00,  8.8081e-01,  1.3434e+00,  1.3552e+00],
        [ 1.1518e+00,  1.1780e+00,  1.2299e+00,  1.2117e+00,  1.1850e+00,
          1.1575e+00,  1.1643e+00,  1.1502e+00,  1.1502e+00,  1.2417e+00,
          1.2611e+00,  1.2574e+00,  1.2845e+00,  1.2266e+00,  1.2957e+00,
          1.2397e+00,  1.2123e+00,  1.2143e+00,  2.6529e+00,  2.7596e+00,
          2.8465e+00,  2.7669e+00,  2.5632e+00,  2.6482e+00,  2.6822e+00,
          2.5506e+00,  2.5506e+00,  1.2459e+00,  1.2412e+00,  1.1888e+00,
          1.2116e+00,  1.2453e+00,  1.1989e+00,  1.2301e+00,  1.1933e+00,
          1.1914e+00,  1.3630e+00,  1.4062e+00,  1.3816e+00,  1.3529e+00,
          1.3915e+00,  1.3804e+00,  1.3682e+00,  1.3017e+00,  1.2920e+00,
          1.2818e+00,  1.2608e+00,  1.2478e+00,  1.2286e+00,  1.2557e+00,
          1.2490e+00,  1.3132e+00,  1.2199e+00,  1.2270e+00],
        [ 1.1641e+00,  1.1911e+00,  1.2405e+00,  1.2219e+00,  1.1985e+00,
          1.1699e+00,  1.1773e+00,  1.1624e+00,  1.1624e+00,  1.2577e+00,
          1.2732e+00,  1.2738e+00,  1.3001e+00,  1.2423e+00,  1.2542e+00,
          1.2557e+00,  1.2436e+00,  1.1770e+00,  1.2382e+00,  1.2625e+00,
          1.2766e+00,  1.2509e+00,  1.2134e+00,  1.2055e+00,  1.2306e+00,
          1.2015e+00,  1.2015e+00,  2.8709e+00,  2.7908e+00,  2.4508e+00,
          2.6016e+00,  2.8661e+00,  2.4617e+00,  2.8224e+00,  2.4591e+00,
          2.4535e+00,  1.3691e+00,  1.4133e+00,  1.3863e+00,  1.3762e+00,
          1.3986e+00,  1.3868e+00,  1.3741e+00,  1.2961e+00,  1.3158e+00,
          1.3251e+00,  1.2733e+00,  1.1691e+00,  1.1972e+00,  1.3163e+00,
          1.2572e+00,  1.3573e+00,  1.1884e+00,  1.2403e+00],
        [ 1.6827e+00,  1.3687e+00,  6.2569e-01,  8.2486e-01,  1.1811e+00,
          1.5756e+00,  1.5157e+00,  1.6796e+00,  1.6796e+00,  1.5408e+00,
          1.2437e+00,  1.3812e+00,  9.1875e-01,  1.6297e+00,  2.9268e-01,
          1.5281e+00,  1.6554e+00,  1.0988e+00,  1.3323e+00,  9.0960e-01,
          7.9661e-01,  1.1196e+00,  1.5714e+00,  1.6217e+00,  1.3683e+00,
          1.7078e+00,  1.7078e+00,  7.2513e-01,  8.6786e-01,  1.6633e+00,
          1.4776e+00,  8.1019e-01,  1.6031e+00,  1.0941e+00,  1.7150e+00,
          1.6318e+00,  2.1843e-01, -6.8513e-03, -2.4016e-02,  1.7396e-01,
          4.2067e-01,  5.7265e-01,  1.2170e-01,  1.2171e+01,  7.4893e+00,
          7.9434e-01,  1.2125e+00,  1.3089e+00,  1.5261e+00,  1.0175e+00,
          1.4575e+00,  4.5475e-01,  1.5854e+00,  1.6900e+00],
        [ 1.2250e+00,  1.2562e+00,  1.3179e+00,  1.2970e+00,  1.2654e+00,
          1.2317e+00,  1.1966e+00,  1.2230e+00,  1.2230e+00,  1.2138e+00,
          1.3313e+00,  1.2322e+00,  1.3593e+00,  1.2906e+00,  1.4111e+00,
          1.2115e+00,  1.2925e+00,  1.2345e+00,  1.3043e+00,  1.3343e+00,
          1.3487e+00,  1.3185e+00,  1.2756e+00,  1.2676e+00,  1.2125e+00,
          1.2619e+00,  1.2619e+00,  1.3025e+00,  1.3440e+00,  1.2624e+00,
          1.0776e+00,  1.2559e+00,  1.1407e+00,  1.3105e+00,  1.1357e+00,
          1.2655e+00,  1.3719e+00,  1.0625e+00,  1.3931e+00,  1.3831e+00,
          9.5465e-01,  8.5889e-01,  1.3782e+00,  1.3658e+00,  7.4241e-01,
          3.1950e+00,  2.5282e+00,  3.3481e+00,  2.7956e+00,  2.1335e+00,
          1.8246e+00,  2.9148e+00,  3.1130e+00,  1.8037e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 200 : 180.49911457431006
Test loss for epoch 200 : 180.62576172252403
Test Precision for epoch 200 : 0.26153846153846155
Test Recall for epoch 200 : 0.26153846153846155
Test F1 for epoch 200 : 0.26153846153846155


theta for epoch 201 : tensor([[ 2.5892,  2.6194,  2.6932,  2.8084,  2.7716,  2.5955,  2.7471,  2.5875,
          2.5875,  1.2412,  1.2606,  1.2569,  1.2842,  1.2262,  1.3292,  1.2393,
          1.2278,  1.2121,  1.2009,  1.1827,  1.1943,  1.2131,  1.1771,  1.1708,
          1.1941,  1.1656,  1.1656,  1.2104,  1.2524,  1.1836,  1.2062,  1.2544,
          1.1936,  1.2242,  1.1437,  1.1862,  1.3598,  1.4024,  1.3784,  1.3689,
          1.3879,  1.3194,  1.3649,  1.3551,  1.3081,  1.3054,  1.2569,  1.2441,
          1.2252,  1.2970,  1.2453,  1.3365,  1.2168,  1.2237],
        [ 1.2721,  1.1844,  1.0108,  1.2291,  1.3100,  1.3231,  1.2475,  1.3139,
          1.3139,  1.5122,  1.7389,  1.5179,  2.2314,  1.5503,  5.9482,  1.6166,
          1.4472,  5.7928,  1.0994,  1.1833,  0.9779,  1.1471,  1.2819,  1.3160,
          1.2804,  1.3097,  1.3097,  1.2839,  1.0151,  1.3250,  1.3052,  1.1231,
          1.3376,  1.3712,  1.2864,  1.3237,  1.3188,  1.4625,  1.3721,  1.2848,
          1.3053,  1.4287,  1.3549,  0.4872,  1.3354,  1.0266,  1.3931,  1.3732,
          1.3500,  1.0408,  1.3777,  0.8763,  1.3394,  1.3513],
        [ 1.1871,  1.2133,  1.2650,  1.2469,  1.2203,  1.1928,  1.1997,  1.1855,
          1.1855,  1.2632,  1.2825,  1.2788,  1.3057,  1.2482,  1.3159,  1.2612,
          1.2337,  1.2365,  2.6271,  2.7344,  2.8210,  2.7408,  2.5376,  2.6222,
          2.6568,  2.5251,  2.5251,  1.2532,  1.2490,  1.1961,  1.2189,  1.2526,
          1.2062,  1.2375,  1.2006,  1.1987,  1.3636,  1.4069,  1.3823,  1.3533,
          1.3921,  1.3811,  1.3689,  1.3032,  1.2926,  1.2902,  1.2688,  1.2558,
          1.2365,  1.2645,  1.2570,  1.3215,  1.2278,  1.2350],
        [ 1.1897,  1.2166,  1.2650,  1.2463,  1.2239,  1.1955,  1.2028,  1.1880,
          1.1880,  1.2667,  1.2821,  1.2826,  1.3088,  1.2513,  1.2627,  1.2647,
          1.2526,  1.1851,  1.2201,  1.2451,  1.2587,  1.2329,  1.1952,  1.1875,
          1.2125,  1.1833,  1.1833,  2.8704,  2.7919,  2.4511,  2.6023,  2.8657,
          2.4619,  2.8220,  2.4594,  2.4538,  1.3651,  1.4094,  1.3824,  1.3723,
          1.3946,  1.3829,  1.3702,  1.2926,  1.3119,  1.3246,  1.2729,  1.1687,
          1.1968,  1.3158,  1.2569,  1.3567,  1.1879,  1.2398],
        [ 1.7098,  1.3957,  0.6482,  0.8488,  1.2079,  1.6029,  1.5428,  1.7067,
          1.7067,  1.5528,  1.2560,  1.3929,  0.9302,  1.6414,  0.3026,  1.5398,
          1.6674,  1.1102,  1.3158,  0.8954,  0.7829,  1.1039,  1.5538,  1.6037,
          1.3521,  1.6899,  1.6899,  0.7269,  0.8687,  1.6626,  1.4775,  0.8117,
          1.6025,  1.0948,  1.7142,  1.6311,  0.2117, -0.0136, -0.0306,  0.1670,
          0.4136,  0.5651,  0.1149, 12.2084,  7.4739,  0.7984,  1.2158,  1.3120,
          1.5284,  1.0208,  1.4599,  0.4595,  1.5877,  1.6918],
        [ 1.2507,  1.2817,  1.3431,  1.3224,  1.2908,  1.2573,  1.2221,  1.2487,
          1.2487,  1.2219,  1.3397,  1.2403,  1.3677,  1.2990,  1.4189,  1.2197,
          1.3009,  1.2428,  1.2836,  1.3138,  1.3287,  1.2980,  1.2549,  1.2469,
          1.1916,  1.2410,  1.2410,  1.2979,  1.3394,  1.2576,  1.0725,  1.2513,
          1.1359,  1.3058,  1.1308,  1.2607,  1.3649,  1.0549,  1.3861,  1.3761,
          0.9469,  0.8511,  1.3713,  1.3584,  0.7347,  3.2013,  2.5313,  3.3556,
          2.7995,  2.1360,  1.8268,  2.9188,  3.1193,  1.8059]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 201 : 180.43879822304024
Test loss for epoch 201 : 180.5717403482329
Test Precision for epoch 201 : 0.26153846153846155
Test Recall for epoch 201 : 0.26153846153846155
Test F1 for epoch 201 : 0.26153846153846155


theta for epoch 202 : tensor([[ 2.5794,  2.6095,  2.6834,  2.7989,  2.7620,  2.5856,  2.7375,  2.5776,
          2.5776,  1.2313,  1.2508,  1.2471,  1.2746,  1.2163,  1.3199,  1.2294,
          1.2178,  1.2026,  1.2049,  1.1869,  1.1985,  1.2172,  1.1810,  1.1748,
          1.1981,  1.1696,  1.1696,  1.2295,  1.2713,  1.2029,  1.2253,  1.2734,
          1.2127,  1.2433,  1.1631,  1.2054,  1.3622,  1.4047,  1.3808,  1.3713,
          1.3901,  1.3218,  1.3674,  1.3574,  1.3102,  1.3150,  1.2666,  1.2538,
          1.2350,  1.3067,  1.2551,  1.3460,  1.2267,  1.2337],
        [ 1.2612,  1.1740,  1.0019,  1.2188,  1.2994,  1.3121,  1.2367,  1.3028,
          1.3028,  1.4981,  1.7243,  1.5037,  2.2164,  1.5362,  5.9499,  1.6023,
          1.4331,  5.7941,  1.1025,  1.1864,  0.9816,  1.1501,  1.2845,  1.3185,
          1.2829,  1.3122,  1.3122,  1.3026,  1.0351,  1.3435,  1.3239,  1.1425,
          1.3561,  1.3896,  1.3051,  1.3425,  1.3211,  1.4641,  1.3739,  1.2870,
          1.3075,  1.4303,  1.3568,  0.4912,  1.3368,  1.0373,  1.4026,  1.3826,
          1.3596,  1.0514,  1.3873,  0.8874,  1.3490,  1.3610],
        [ 1.1796,  1.2057,  1.2575,  1.2393,  1.2127,  1.1853,  1.1922,  1.1780,
          1.1780,  1.2548,  1.2743,  1.2705,  1.2975,  1.2399,  1.3082,  1.2529,
          1.2253,  1.2291,  2.6233,  2.7311,  2.8173,  2.7366,  2.5343,  2.6185,
          2.6535,  2.5217,  2.5217,  1.2716,  1.2679,  1.2147,  1.2374,  1.2710,
          1.2247,  1.2560,  1.2191,  1.2173,  1.3643,  1.4076,  1.3830,  1.3538,
          1.3928,  1.3817,  1.3696,  1.3046,  1.2928,  1.2996,  1.2779,  1.2648,
          1.2457,  1.2742,  1.2661,  1.3309,  1.2370,  1.2442],
        [ 1.1750,  1.2019,  1.2508,  1.2322,  1.2092,  1.1808,  1.1881,  1.1733,
          1.1733,  1.2479,  1.2640,  1.2641,  1.2907,  1.2326,  1.2446,  1.2460,
          1.2338,  1.1689,  1.2152,  1.2405,  1.2539,  1.2281,  1.1902,  1.1825,
          1.2075,  1.1782,  1.1782,  2.8836,  2.8070,  2.4654,  2.6170,  2.8790,
          2.4763,  2.8353,  2.4737,  2.4681,  1.3617,  1.4061,  1.3791,  1.3691,
          1.3912,  1.3795,  1.3669,  1.2895,  1.3084,  1.3259,  1.2743,  1.1699,
          1.1981,  1.3171,  1.2585,  1.3580,  1.1893,  1.2412],
        [ 1.6996,  1.3855,  0.6395,  0.8397,  1.1976,  1.5926,  1.5326,  1.6965,
          1.6965,  1.5399,  1.2429,  1.3806,  0.9187,  1.6285,  0.2937,  1.5271,
          1.6548,  1.0966,  1.3138,  0.8934,  0.7806,  1.1017,  1.5521,  1.6017,
          1.3505,  1.6883,  1.6883,  0.7374,  0.8789,  1.6757,  1.4904,  0.8227,
          1.6155,  1.1071,  1.7272,  1.6441,  0.2119, -0.0136, -0.0305,  0.1671,
          0.4135,  0.5647,  0.1150, 12.2515,  7.4648,  0.8051,  1.2241,  1.3205,
          1.5369,  1.0280,  1.4683,  0.4646,  1.5965,  1.7003],
        [ 1.2360,  1.2671,  1.3284,  1.3077,  1.2761,  1.2427,  1.2074,  1.2341,
          1.2341,  1.1997,  1.3176,  1.2180,  1.3453,  1.2771,  1.3974,  1.1974,
          1.2790,  1.2202,  1.2801,  1.3103,  1.3254,  1.2945,  1.2513,  1.2433,
          1.1877,  1.2374,  1.2374,  1.3081,  1.3497,  1.2683,  1.0822,  1.2613,
          1.1460,  1.3164,  1.1411,  1.2714,  1.3620,  1.0506,  1.3832,  1.3733,
          0.9422,  0.8462,  1.3685,  1.3553,  0.7297,  3.2170,  2.5443,  3.3729,
          2.8132,  2.1482,  1.8391,  2.9322,  3.1355,  1.8182]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 202 : 180.36173330974287
Test loss for epoch 202 : 180.48354540154975
Test Precision for epoch 202 : 0.26153846153846155
Test Recall for epoch 202 : 0.26153846153846155
Test F1 for epoch 202 : 0.26153846153846155


theta for epoch 203 : tensor([[ 2.5610e+00,  2.5912e+00,  2.6651e+00,  2.7808e+00,  2.7440e+00,
          2.5672e+00,  2.7194e+00,  2.5592e+00,  2.5592e+00,  1.2468e+00,
          1.2664e+00,  1.2626e+00,  1.2900e+00,  1.2319e+00,  1.3350e+00,
          1.2450e+00,  1.2334e+00,  1.2186e+00,  1.2304e+00,  1.2124e+00,
          1.2239e+00,  1.2427e+00,  1.2065e+00,  1.2003e+00,  1.2235e+00,
          1.1951e+00,  1.1951e+00,  1.2347e+00,  1.2762e+00,  1.2079e+00,
          1.2303e+00,  1.2783e+00,  1.2178e+00,  1.2482e+00,  1.1685e+00,
          1.2105e+00,  1.3701e+00,  1.4127e+00,  1.3889e+00,  1.3793e+00,
          1.3980e+00,  1.3301e+00,  1.3755e+00,  1.3651e+00,  1.3183e+00,
          1.3149e+00,  1.2666e+00,  1.2538e+00,  1.2350e+00,  1.3066e+00,
          1.2551e+00,  1.3459e+00,  1.2267e+00,  1.2337e+00],
        [ 1.2446e+00,  1.1577e+00,  9.8662e-01,  1.2026e+00,  1.2833e+00,
          1.2956e+00,  1.2202e+00,  1.2863e+00,  1.2863e+00,  1.5031e+00,
          1.7286e+00,  1.5086e+00,  2.2197e+00,  1.5411e+00,  5.9673e+00,
          1.6072e+00,  1.4382e+00,  5.8122e+00,  1.1203e+00,  1.2044e+00,
          9.9877e-01,  1.1680e+00,  1.3028e+00,  1.3369e+00,  1.3011e+00,
          1.3306e+00,  1.3306e+00,  1.2979e+00,  1.0306e+00,  1.3392e+00,
          1.3195e+00,  1.1377e+00,  1.3517e+00,  1.3851e+00,  1.3007e+00,
          1.3382e+00,  1.3236e+00,  1.4661e+00,  1.3759e+00,  1.2892e+00,
          1.3100e+00,  1.4324e+00,  1.3588e+00,  4.9302e-01,  1.3386e+00,
          1.0288e+00,  1.3940e+00,  1.3740e+00,  1.3510e+00,  1.0427e+00,
          1.3788e+00,  8.7943e-01,  1.3404e+00,  1.3525e+00],
        [ 1.1613e+00,  1.1874e+00,  1.2392e+00,  1.2210e+00,  1.1943e+00,
          1.1669e+00,  1.1738e+00,  1.1596e+00,  1.1596e+00,  1.2506e+00,
          1.2701e+00,  1.2662e+00,  1.2933e+00,  1.2357e+00,  1.3041e+00,
          1.2487e+00,  1.2207e+00,  1.2254e+00,  2.6450e+00,  2.7532e+00,
          2.8387e+00,  2.7577e+00,  2.5565e+00,  2.6402e+00,  2.6757e+00,
          2.5439e+00,  2.5439e+00,  1.2609e+00,  1.2576e+00,  1.2043e+00,
          1.2270e+00,  1.2603e+00,  1.2143e+00,  1.2456e+00,  1.2087e+00,
          1.2069e+00,  1.3607e+00,  1.4043e+00,  1.3796e+00,  1.3500e+00,
          1.3893e+00,  1.3783e+00,  1.3661e+00,  1.3014e+00,  1.2887e+00,
          1.2870e+00,  1.2649e+00,  1.2518e+00,  1.2326e+00,  1.2618e+00,
          1.2531e+00,  1.3183e+00,  1.2239e+00,  1.2312e+00],
        [ 1.1637e+00,  1.1906e+00,  1.2401e+00,  1.2216e+00,  1.1979e+00,
          1.1694e+00,  1.1768e+00,  1.1620e+00,  1.1620e+00,  1.2528e+00,
          1.2688e+00,  1.2688e+00,  1.2953e+00,  1.2375e+00,  1.2491e+00,
          1.2508e+00,  1.2387e+00,  1.1734e+00,  1.2328e+00,  1.2576e+00,
          1.2715e+00,  1.2457e+00,  1.2078e+00,  1.2002e+00,  1.2252e+00,
          1.1959e+00,  1.1959e+00,  2.8841e+00,  2.8090e+00,  2.4666e+00,
          2.6186e+00,  2.8794e+00,  2.4774e+00,  2.8358e+00,  2.4748e+00,
          2.4692e+00,  1.3639e+00,  1.4084e+00,  1.3814e+00,  1.3713e+00,
          1.3934e+00,  1.3819e+00,  1.3691e+00,  1.2914e+00,  1.3106e+00,
          1.3198e+00,  1.2683e+00,  1.1642e+00,  1.1921e+00,  1.3111e+00,
          1.2528e+00,  1.3519e+00,  1.1832e+00,  1.2351e+00],
        [ 1.6858e+00,  1.3712e+00,  6.2629e-01,  8.2616e-01,  1.1830e+00,
          1.5786e+00,  1.5185e+00,  1.6827e+00,  1.6827e+00,  1.5413e+00,
          1.2428e+00,  1.3813e+00,  9.1738e-01,  1.6302e+00,  2.9049e-01,
          1.5283e+00,  1.6568e+00,  1.0950e+00,  1.3271e+00,  9.0483e-01,
          7.9102e-01,  1.1140e+00,  1.5666e+00,  1.6160e+00,  1.3642e+00,
          1.7031e+00,  1.7031e+00,  7.3109e-01,  8.7261e-01,  1.6710e+00,
          1.4853e+00,  8.1630e-01,  1.6107e+00,  1.1009e+00,  1.7226e+00,
          1.6392e+00,  2.1584e-01, -9.9412e-03, -2.6796e-02,  1.7089e-01,
          4.1741e-01,  5.6837e-01,  1.1870e-01,  1.2298e+01,  7.4591e+00,
          7.9075e-01,  1.2111e+00,  1.3079e+00,  1.5253e+00,  1.0139e+00,
          1.4562e+00,  4.5004e-01,  1.5851e+00,  1.6893e+00],
        [ 1.2255e+00,  1.2565e+00,  1.3181e+00,  1.2972e+00,  1.2656e+00,
          1.2321e+00,  1.1969e+00,  1.2235e+00,  1.2235e+00,  1.2096e+00,
          1.3272e+00,  1.2278e+00,  1.3548e+00,  1.2868e+00,  1.4063e+00,
          1.2073e+00,  1.2887e+00,  1.2301e+00,  1.3003e+00,  1.3304e+00,
          1.3451e+00,  1.3147e+00,  1.2716e+00,  1.2637e+00,  1.2078e+00,
          1.2577e+00,  1.2577e+00,  1.3069e+00,  1.3483e+00,  1.2670e+00,
          1.0812e+00,  1.2601e+00,  1.1450e+00,  1.3151e+00,  1.1401e+00,
          1.2701e+00,  1.3668e+00,  1.0562e+00,  1.3881e+00,  1.3781e+00,
          9.4786e-01,  8.5221e-01,  1.3734e+00,  1.3597e+00,  7.3566e-01,
          3.2127e+00,  2.5365e+00,  3.3694e+00,  2.8062e+00,  2.1399e+00,
          1.8304e+00,  2.9256e+00,  3.1307e+00,  1.8095e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 203 : 180.37273921236553
Test loss for epoch 203 : 180.50112563485072
Test Precision for epoch 203 : 0.26153846153846155
Test Recall for epoch 203 : 0.26153846153846155
Test F1 for epoch 203 : 0.26153846153846155


theta for epoch 204 : tensor([[ 2.5754,  2.6056,  2.6795,  2.7955,  2.7587,  2.5816,  2.7341,  2.5736,
          2.5736,  1.2494,  1.2690,  1.2652,  1.2927,  1.2344,  1.3377,  1.2475,
          1.2359,  1.2210,  1.2217,  1.2036,  1.2152,  1.2340,  1.1979,  1.1917,
          1.2149,  1.1865,  1.1865,  1.2199,  1.2615,  1.1932,  1.2156,  1.2636,
          1.2031,  1.2335,  1.1537,  1.1958,  1.3668,  1.4095,  1.3856,  1.3761,
          1.3948,  1.3268,  1.3722,  1.3616,  1.3148,  1.3098,  1.2615,  1.2486,
          1.2299,  1.3016,  1.2500,  1.3409,  1.2215,  1.2286],
        [ 1.2555,  1.1684,  0.9971,  1.2135,  1.2943,  1.3065,  1.2310,  1.2972,
          1.2972,  1.5121,  1.7369,  1.5176,  2.2268,  1.5500,  5.9878,  1.6161,
          1.4473,  5.8337,  1.1131,  1.1973,  0.9922,  1.1609,  1.2957,  1.3298,
          1.2939,  1.3234,  1.3234,  1.2851,  1.0177,  1.3265,  1.3068,  1.1245,
          1.3390,  1.3724,  1.2879,  1.3255,  1.3223,  1.4646,  1.3743,  1.2877,
          1.3089,  1.4309,  1.3571,  0.4912,  1.3370,  1.0263,  1.3913,  1.3713,
          1.3483,  1.0399,  1.3762,  0.8771,  1.3376,  1.3498],
        [ 1.1715,  1.1976,  1.2493,  1.2312,  1.2045,  1.1771,  1.1840,  1.1699,
          1.1699,  1.2581,  1.2776,  1.2737,  1.3009,  1.2432,  1.3112,  1.2561,
          1.2279,  1.2335,  2.6456,  2.7542,  2.8393,  2.7578,  2.5575,  2.6407,
          2.6767,  2.5450,  2.5450,  1.2493,  1.2464,  1.1928,  1.2155,  1.2487,
          1.2029,  1.2343,  1.1972,  1.1954,  1.3590,  1.4027,  1.3780,  1.3481,
          1.3877,  1.3767,  1.3645,  1.3005,  1.2869,  1.2858,  1.2633,  1.2502,
          1.2310,  1.2609,  1.2515,  1.3171,  1.2222,  1.2295],
        [ 1.1775,  1.2043,  1.2534,  1.2348,  1.2116,  1.1832,  1.1906,  1.1757,
          1.1757,  1.2651,  1.2810,  1.2810,  1.3073,  1.2499,  1.2610,  1.2632,
          1.2510,  1.1846,  1.2305,  1.2554,  1.2692,  1.2435,  1.2055,  1.1979,
          1.2229,  1.1936,  1.1936,  2.8785,  2.8048,  2.4615,  2.6140,  2.8739,
          2.4724,  2.8303,  2.4697,  2.4642,  1.3654,  1.4100,  1.3831,  1.3729,
          1.3950,  1.3836,  1.3707,  1.2931,  1.3124,  1.3210,  1.2695,  1.1656,
          1.1934,  1.3122,  1.2541,  1.3531,  1.1845,  1.2362],
        [ 1.6984,  1.3838,  0.6373,  0.8378,  1.1956,  1.5913,  1.5311,  1.6953,
          1.6953,  1.5522,  1.2538,  1.3920,  0.9275,  1.6410,  0.2991,  1.5390,
          1.6678,  1.1049,  1.3243,  0.9033,  0.7894,  1.1116,  1.5634,  1.6125,
          1.3618,  1.6997,  1.6997,  0.7264,  0.8672,  1.6633,  1.4782,  0.8112,
          1.6032,  1.0945,  1.7150,  1.6315,  0.2120, -0.0137, -0.0305,  0.1669,
          0.4133,  0.5638,  0.1148, 12.3373,  7.4450,  0.7932,  1.2130,  1.3096,
          1.5264,  1.0157,  1.4573,  0.4531,  1.5862,  1.6901],
        [ 1.2371,  1.2681,  1.3296,  1.3088,  1.2772,  1.2437,  1.2085,  1.2351,
          1.2351,  1.2205,  1.3382,  1.2387,  1.3660,  1.2978,  1.4169,  1.2183,
          1.2996,  1.2413,  1.2954,  1.3254,  1.3402,  1.3098,  1.2667,  1.2588,
          1.2028,  1.2528,  1.2528,  1.2967,  1.3383,  1.2565,  1.0707,  1.2501,
          1.1348,  1.3048,  1.1297,  1.2596,  1.3663,  1.0556,  1.3877,  1.3778,
          0.9472,  0.8516,  1.3730,  1.3590,  0.7351,  3.2162,  2.5369,  3.3740,
          2.8074,  2.1397,  1.8300,  2.9269,  3.1341,  1.8091]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 204 : 180.3096111111177
Test loss for epoch 204 : 180.44367038966706
Test Precision for epoch 204 : 0.26153846153846155
Test Recall for epoch 204 : 0.26153846153846155
Test F1 for epoch 204 : 0.26153846153846155


theta for epoch 205 : tensor([[ 2.5959,  2.6260,  2.6999,  2.8162,  2.7794,  2.6021,  2.7549,  2.5941,
          2.5941,  1.2219,  1.2417,  1.2378,  1.2656,  1.2068,  1.3112,  1.2200,
          1.2083,  1.1936,  1.2032,  1.1849,  1.1965,  1.2154,  1.1793,  1.1732,
          1.1963,  1.1679,  1.1679,  1.2173,  1.2593,  1.1909,  1.2133,  1.2613,
          1.2008,  1.2313,  1.1511,  1.1935,  1.3619,  1.4047,  1.3808,  1.3713,
          1.3899,  1.3216,  1.3674,  1.3568,  1.3098,  1.3099,  1.2615,  1.2486,
          1.2299,  1.3017,  1.2501,  1.3410,  1.2215,  1.2286],
        [ 1.2774,  1.1905,  1.0197,  1.2358,  1.3163,  1.3282,  1.2531,  1.3189,
          1.3189,  1.4927,  1.7169,  1.4980,  2.2066,  1.5305,  5.9838,  1.5965,
          1.4278,  5.8289,  1.1034,  1.1874,  0.9840,  1.1511,  1.2850,  1.3190,
          1.2832,  1.3126,  1.3126,  1.2940,  1.0282,  1.3349,  1.3155,  1.1342,
          1.3474,  1.3809,  1.2964,  1.3341,  1.3250,  1.4665,  1.3763,  1.2902,
          1.3117,  1.4329,  1.3592,  0.4966,  1.3389,  1.0383,  1.4015,  1.3814,
          1.3585,  1.0518,  1.3864,  0.8898,  1.3478,  1.3600],
        [ 1.1890,  1.2150,  1.2667,  1.2486,  1.2220,  1.1946,  1.2015,  1.1873,
          1.1873,  1.2448,  1.2645,  1.2605,  1.2880,  1.2299,  1.2993,  1.2429,
          1.2144,  1.2214,  2.6364,  2.7456,  2.8302,  2.7481,  2.5487,  2.6314,
          2.6680,  2.5361,  2.5361,  1.2567,  1.2542,  1.2002,  1.2230,  1.2560,
          1.2103,  1.2418,  1.2046,  1.2028,  1.3602,  1.4040,  1.3792,  1.3491,
          1.3889,  1.3780,  1.3657,  1.3028,  1.2878,  1.2950,  1.2721,  1.2590,
          1.2399,  1.2704,  1.2603,  1.3263,  1.2310,  1.2384],
        [ 1.1910,  1.2178,  1.2664,  1.2478,  1.2250,  1.1967,  1.2041,  1.1893,
          1.1893,  1.2475,  1.2640,  1.2636,  1.2903,  1.2322,  1.2445,  1.2455,
          1.2333,  1.1696,  1.2164,  1.2417,  1.2551,  1.2293,  1.1914,  1.1839,
          1.2087,  1.1794,  1.1794,  2.8836,  2.8115,  2.4674,  2.6202,  2.8789,
          2.4782,  2.8354,  2.4755,  2.4701,  1.3642,  1.4089,  1.3820,  1.3719,
          1.3939,  1.3825,  1.3696,  1.2923,  1.3112,  1.3250,  1.2735,  1.1694,
          1.1974,  1.3162,  1.2580,  1.3571,  1.1885,  1.2403],
        [ 1.7152,  1.4005,  0.6518,  0.8531,  1.2122,  1.6081,  1.5479,  1.7121,
          1.7121,  1.5383,  1.2409,  1.3793,  0.9176,  1.6267,  0.2936,  1.5253,
          1.6537,  1.0920,  1.3145,  0.8952,  0.7815,  1.1023,  1.5528,  1.6014,
          1.3522,  1.6888,  1.6888,  0.7335,  0.8734,  1.6692,  1.4844,  0.8183,
          1.6091,  1.1014,  1.7207,  1.6374,  0.2079, -0.0178, -0.0345,  0.1627,
          0.4088,  0.5588,  0.1106, 12.3766,  7.4302,  0.8052,  1.2247,  1.3212,
          1.5371,  1.0273,  1.4682,  0.4648,  1.5970,  1.7002],
        [ 1.2505,  1.2816,  1.3430,  1.3222,  1.2906,  1.2571,  1.2218,  1.2485,
          1.2485,  1.1961,  1.3139,  1.2144,  1.3416,  1.2734,  1.3935,  1.1938,
          1.2752,  1.2168,  1.2801,  1.3101,  1.3253,  1.2946,  1.2514,  1.2435,
          1.1872,  1.2375,  1.2375,  1.2983,  1.3400,  1.2581,  1.0718,  1.2517,
          1.1362,  1.3065,  1.1310,  1.2613,  1.3638,  1.0521,  1.3852,  1.3753,
          0.9435,  0.8477,  1.3705,  1.3566,  0.7311,  3.2289,  2.5469,  3.3882,
          2.8180,  2.1491,  1.8392,  2.9374,  3.1472,  1.8183]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 205 : 180.43294276286954
Test loss for epoch 205 : 180.55730873863155
Test Precision for epoch 205 : 0.26153846153846155
Test Recall for epoch 205 : 0.26153846153846155
Test F1 for epoch 205 : 0.26153846153846155


theta for epoch 206 : tensor([[ 2.5739,  2.6041,  2.6780,  2.7946,  2.7578,  2.5801,  2.7332,  2.5721,
          2.5721,  1.2432,  1.2628,  1.2589,  1.2865,  1.2282,  1.3315,  1.2413,
          1.2297,  1.2150,  1.2148,  1.1967,  1.2082,  1.2270,  1.1910,  1.1848,
          1.2079,  1.1796,  1.1796,  1.2367,  1.2783,  1.2102,  1.2326,  1.2805,
          1.2201,  1.2505,  1.1706,  1.2128,  1.3702,  1.4131,  1.3891,  1.3796,
          1.3983,  1.3304,  1.3757,  1.3646,  1.3183,  1.3163,  1.2679,  1.2550,
          1.2362,  1.3080,  1.2564,  1.3474,  1.2278,  1.2349],
        [ 1.2442,  1.1575,  0.9875,  1.2026,  1.2834,  1.2951,  1.2199,  1.2859,
          1.2859,  1.5084,  1.7319,  1.5137,  2.2204,  1.5461,  6.0096,  1.6121,
          1.4436,  5.8558,  1.1044,  1.1887,  0.9852,  1.1523,  1.2866,  1.3207,
          1.2847,  1.3143,  1.3143,  1.3031,  1.0369,  1.3441,  1.3248,  1.1428,
          1.3566,  1.3901,  1.3056,  1.3435,  1.3258,  1.4672,  1.3767,  1.2907,
          1.3126,  1.4336,  1.3596,  0.4953,  1.3393,  1.0350,  1.3987,  1.3784,
          1.3555,  1.0482,  1.3835,  0.8865,  1.3448,  1.3571],
        [ 1.1612,  1.1872,  1.2387,  1.2206,  1.1941,  1.1668,  1.1736,  1.1596,
          1.1596,  1.2517,  1.2714,  1.2674,  1.2949,  1.2367,  1.3057,  1.2498,
          1.2210,  1.2289,  2.6452,  2.7548,  2.8389,  2.7563,  2.5580,  2.6402,
          2.6772,  2.5454,  2.5454,  1.2662,  1.2642,  1.2099,  1.2327,  1.2656,
          1.2200,  1.2515,  1.2143,  1.2125,  1.3610,  1.4050,  1.3801,  1.3496,
          1.3898,  1.3790,  1.3666,  1.3041,  1.2884,  1.2936,  1.2703,  1.2572,
          1.2380,  1.2692,  1.2585,  1.3249,  1.2292,  1.2365],
        [ 1.1636,  1.1904,  1.2399,  1.2215,  1.1977,  1.1694,  1.1767,  1.1619,
          1.1619,  1.2550,  1.2714,  1.2710,  1.2977,  1.2397,  1.2513,  1.2531,
          1.2408,  1.1762,  1.2191,  1.2444,  1.2578,  1.2321,  1.1941,  1.1867,
          1.2114,  1.1821,  1.1821,  2.8925,  2.8220,  2.4771,  2.6304,  2.8879,
          2.4879,  2.8443,  2.4853,  2.4798,  1.3654,  1.4103,  1.3833,  1.3731,
          1.3952,  1.3839,  1.3708,  1.2932,  1.3125,  1.3234,  1.2719,  1.1677,
          1.1957,  1.3146,  1.2566,  1.3556,  1.1867,  1.2385],
        [ 1.6905,  1.3763,  0.6318,  0.8320,  1.1883,  1.5835,  1.5234,  1.6874,
          1.6874,  1.5483,  1.2500,  1.3886,  0.9250,  1.6367,  0.2982,  1.5350,
          1.6640,  1.0995,  1.3187,  0.8990,  0.7847,  1.1062,  1.5574,  1.6058,
          1.3568,  1.6935,  1.6935,  0.7419,  0.8813,  1.6796,  1.4948,  0.8271,
          1.6195,  1.1112,  1.7312,  1.6477,  0.2093, -0.0166, -0.0332,  0.1639,
          0.4101,  0.5597,  0.1119, 12.4203,  7.4205,  0.8034,  1.2237,  1.3204,
          1.5365,  1.0255,  1.4674,  0.4626,  1.5966,  1.6998],
        [ 1.2245,  1.2555,  1.3170,  1.2962,  1.2646,  1.2311,  1.1959,  1.2225,
          1.2225,  1.2128,  1.3305,  1.2310,  1.3582,  1.2900,  1.4094,  1.2106,
          1.2917,  1.2337,  1.2874,  1.3173,  1.3324,  1.3019,  1.2587,  1.2509,
          1.1944,  1.2449,  1.2449,  1.3121,  1.3534,  1.2720,  1.0857,  1.2653,
          1.1500,  1.3203,  1.1451,  1.2751,  1.3691,  1.0580,  1.3905,  1.3807,
          0.9494,  0.8540,  1.3759,  1.3614,  0.7373,  3.2289,  2.5437,  3.3890,
          2.8155,  2.1453,  1.8353,  2.9351,  3.1468,  1.8144]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 206 : 180.33065702664544
Test loss for epoch 206 : 180.46346576541202
Test Precision for epoch 206 : 0.26153846153846155
Test Recall for epoch 206 : 0.26153846153846155
Test F1 for epoch 206 : 0.26153846153846155


theta for epoch 207 : tensor([[ 2.5758,  2.6061,  2.6800,  2.7968,  2.7600,  2.5821,  2.7354,  2.5740,
          2.5740,  1.2500,  1.2696,  1.2657,  1.2932,  1.2350,  1.3379,  1.2481,
          1.2365,  1.2217,  1.2257,  1.2075,  1.2190,  1.2380,  1.2019,  1.1958,
          1.2188,  1.1905,  1.1905,  1.2249,  1.2666,  1.1984,  1.2208,  1.2687,
          1.2083,  1.2387,  1.1589,  1.2010,  1.3703,  1.4133,  1.3893,  1.3797,
          1.3984,  1.3306,  1.3758,  1.3644,  1.3185,  1.3113,  1.2628,  1.2498,
          1.2311,  1.3030,  1.2513,  1.3425,  1.2226,  1.2298],
        [ 1.2397,  1.1530,  0.9833,  1.1979,  1.2789,  1.2905,  1.2153,  1.2813,
          1.2813,  1.5133,  1.7362,  1.5186,  2.2237,  1.5510,  6.0256,  1.6169,
          1.4487,  5.8723,  1.1166,  1.2012,  0.9974,  1.1646,  1.2990,  1.3332,
          1.2971,  1.3266,  1.3266,  1.2910,  1.0252,  1.3320,  1.3127,  1.1306,
          1.3446,  1.3781,  1.2934,  1.3314,  1.3266,  1.4676,  1.3770,  1.2913,
          1.3136,  1.4341,  1.3599,  0.4962,  1.3396,  1.0310,  1.3941,  1.3738,
          1.3508,  1.0439,  1.3789,  0.8831,  1.3401,  1.3525],
        [ 1.1545,  1.1805,  1.2319,  1.2138,  1.1874,  1.1601,  1.1670,  1.1529,
          1.1529,  1.2548,  1.2746,  1.2706,  1.2981,  1.2398,  1.3088,  1.2529,
          1.2238,  1.2327,  2.6573,  2.7673,  2.8509,  2.7678,  2.5706,  2.6523,
          2.6898,  2.5580,  2.5580,  1.2520,  1.2504,  1.1959,  1.2188,  1.2513,
          1.2060,  1.2376,  1.2004,  1.1986,  1.3596,  1.4037,  1.3788,  1.3480,
          1.3886,  1.3777,  1.3653,  1.3034,  1.2868,  1.2880,  1.2642,  1.2511,
          1.2319,  1.2639,  1.2525,  1.3194,  1.2230,  1.2304],
        [ 1.1627,  1.1894,  1.2389,  1.2205,  1.1967,  1.1684,  1.1757,  1.1610,
          1.1610,  1.2658,  1.2821,  1.2817,  1.3083,  1.2506,  1.2620,  1.2640,
          1.2517,  1.1863,  1.2343,  1.2592,  1.2731,  1.2473,  1.2093,  1.2018,
          1.2266,  1.1973,  1.1973,  2.8865,  2.8173,  2.4716,  2.6253,  2.8819,
          2.4824,  2.8384,  2.4797,  2.4743,  1.3682,  1.4132,  1.3861,  1.3760,
          1.3981,  1.3868,  1.3737,  1.2959,  1.3155,  1.3226,  1.2712,  1.1672,
          1.1950,  1.3139,  1.2559,  1.3548,  1.1860,  1.2377],
        [ 1.6859,  1.3713,  0.6266,  0.8269,  1.1831,  1.5788,  1.5186,  1.6828,
          1.6828,  1.5526,  1.2531,  1.3922,  0.9269,  1.6411,  0.2982,  1.5391,
          1.6688,  1.1011,  1.3284,  0.9075,  0.7924,  1.1152,  1.5680,  1.6161,
          1.3669,  1.7042,  1.7042,  0.7313,  0.8705,  1.6688,  1.4838,  0.8162,
          1.6086,  1.0996,  1.7205,  1.6367,  0.2113, -0.0148, -0.0314,  0.1657,
          0.4120,  0.5613,  0.1136, 12.4649,  7.4115,  0.7947,  1.2160,  1.3129,
          1.5297,  1.0169,  1.4602,  0.4537,  1.5899,  1.6934],
        [ 1.2223,  1.2532,  1.3147,  1.2939,  1.2624,  1.2289,  1.1938,  1.2203,
          1.2203,  1.2257,  1.3433,  1.2439,  1.3712,  1.3027,  1.4219,  1.2236,
          1.3045,  1.2469,  1.3023,  1.3322,  1.3471,  1.3168,  1.2736,  1.2658,
          1.2092,  1.2597,  1.2597,  1.3041,  1.3455,  1.2639,  1.0780,  1.2576,
          1.1423,  1.3122,  1.1373,  1.2670,  1.3722,  1.0619,  1.3936,  1.3839,
          0.9534,  0.8583,  1.3791,  1.3642,  0.7417,  3.2255,  2.5370,  3.3866,
          2.8096,  2.1382,  1.8279,  2.9296,  3.1431,  1.8070]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 207 : 180.38209474920998
Test loss for epoch 207 : 180.5199868840262
Test Precision for epoch 207 : 0.26153846153846155
Test Recall for epoch 207 : 0.26153846153846155
Test F1 for epoch 207 : 0.26153846153846155


theta for epoch 208 : tensor([[ 2.6023,  2.6325,  2.7064,  2.8235,  2.7867,  2.6086,  2.7622,  2.6005,
          2.6005,  1.2218,  1.2415,  1.2375,  1.2653,  1.2068,  1.3103,  1.2199,
          1.2082,  1.1935,  1.2103,  1.1919,  1.2035,  1.2226,  1.1864,  1.1803,
          1.2033,  1.1749,  1.1749,  1.2124,  1.2544,  1.1861,  1.2086,  1.2565,
          1.1960,  1.2265,  1.1463,  1.1887,  1.3605,  1.4037,  1.3796,  1.3700,
          1.3887,  1.3205,  1.3661,  1.3546,  1.3085,  1.3063,  1.2577,  1.2447,
          1.2260,  1.2980,  1.2462,  1.3375,  1.2174,  1.2246],
        [ 1.2666,  1.1801,  1.0107,  1.2250,  1.3058,  1.3171,  1.2423,  1.3080,
          1.3080,  1.4916,  1.7139,  1.4966,  2.2010,  1.5291,  6.0182,  1.5949,
          1.4269,  5.8639,  1.1138,  1.1983,  0.9961,  1.1618,  1.2950,  1.3290,
          1.2933,  1.3224,  1.3224,  1.2936,  1.0296,  1.3339,  1.3150,  1.1340,
          1.3465,  1.3801,  1.2955,  1.3335,  1.3272,  1.4673,  1.3770,  1.2918,
          1.3143,  1.4338,  1.3598,  0.5007,  1.3392,  1.0423,  1.4031,  1.3827,
          1.3598,  1.0551,  1.3880,  0.8952,  1.3490,  1.3615],
        [ 1.1769,  1.2028,  1.2541,  1.2361,  1.2097,  1.1824,  1.1893,  1.1753,
          1.1753,  1.2434,  1.2635,  1.2593,  1.2872,  1.2284,  1.2989,  1.2415,
          1.2121,  1.2226,  2.6471,  2.7577,  2.8408,  2.7572,  2.5608,  2.6420,
          2.6802,  2.5483,  2.5483,  1.2542,  1.2531,  1.1983,  1.2212,  1.2536,
          1.2084,  1.2400,  1.2028,  1.2010,  1.3601,  1.4041,  1.3793,  1.3483,
          1.3890,  1.3782,  1.3659,  1.3052,  1.2871,  1.2970,  1.2728,  1.2597,
          1.2406,  1.2732,  1.2611,  1.3283,  1.2317,  1.2391],
        [ 1.1814,  1.2081,  1.2570,  1.2386,  1.2153,  1.1871,  1.1944,  1.1797,
          1.1797,  1.2505,  1.2674,  1.2666,  1.2936,  1.2352,  1.2479,  1.2486,
          1.2362,  1.1733,  1.2278,  1.2530,  1.2667,  1.2408,  1.2027,  1.1953,
          1.2200,  1.1906,  1.1906,  2.8868,  2.8190,  2.4725,  2.6266,  2.8822,
          2.4833,  2.8387,  2.4806,  2.4752,  1.3661,  1.4111,  1.3842,  1.3740,
          1.3960,  1.3847,  1.3717,  1.2944,  1.3134,  1.3264,  1.2750,  1.1709,
          1.1990,  1.3177,  1.2598,  1.3585,  1.1900,  1.2416],
        [ 1.7053,  1.3903,  0.6424,  0.8439,  1.2018,  1.5981,  1.5378,  1.7022,
          1.7022,  1.5364,  1.2375,  1.3772,  0.9140,  1.6247,  0.2898,  1.5232,
          1.6527,  1.0854,  1.3225,  0.9025,  0.7874,  1.1095,  1.5618,  1.6095,
          1.3613,  1.6979,  1.6979,  0.7314,  0.8700,  1.6677,  1.4829,  0.8162,
          1.6076,  1.0991,  1.7193,  1.6355,  0.2078, -0.0185, -0.0350,  0.1620,
          0.4083,  0.5571,  0.1100, 12.5050,  7.3967,  0.8021,  1.2237,  1.3206,
          1.5368,  1.0242,  1.4674,  0.4607,  1.5972,  1.7003],
        [ 1.2391,  1.2700,  1.3314,  1.3106,  1.2791,  1.2457,  1.2104,  1.2371,
          1.2371,  1.2019,  1.3196,  1.2202,  1.3475,  1.2790,  1.3990,  1.1997,
          1.2806,  1.2231,  1.2926,  1.3225,  1.3376,  1.3071,  1.2637,  1.2560,
          1.1991,  1.2499,  1.2499,  1.2987,  1.3402,  1.2585,  1.0720,  1.2522,
          1.1368,  1.3068,  1.1316,  1.2616,  1.3666,  1.0551,  1.3880,  1.3783,
          0.9464,  0.8510,  1.3735,  1.3587,  0.7343,  3.2383,  2.5471,  3.4008,
          2.8204,  2.1477,  1.8373,  2.9402,  3.1562,  1.8164]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 208 : 180.32351314688032
Test loss for epoch 208 : 180.44909950892657
Test Precision for epoch 208 : 0.26153846153846155
Test Recall for epoch 208 : 0.26153846153846155
Test F1 for epoch 208 : 0.26153846153846155


theta for epoch 209 : tensor([[ 2.6005,  2.6307,  2.7046,  2.8219,  2.7852,  2.6067,  2.7606,  2.5987,
          2.5987,  1.2341,  1.2538,  1.2498,  1.2774,  1.2192,  1.3220,  1.2323,
          1.2206,  1.2059,  1.2067,  1.1885,  1.2001,  1.2190,  1.1827,  1.1766,
          1.1997,  1.1713,  1.1713,  1.2214,  1.2633,  1.1951,  1.2175,  1.2655,
          1.2050,  1.2355,  1.1553,  1.1976,  1.3583,  1.4017,  1.3775,  1.3679,
          1.3866,  1.3186,  1.3640,  1.3520,  1.3065,  1.3049,  1.2563,  1.2433,
          1.2245,  1.2966,  1.2448,  1.3362,  1.2160,  1.2232],
        [ 1.2661,  1.1794,  1.0099,  1.2245,  1.3056,  1.3168,  1.2417,  1.3076,
          1.3076,  1.5058,  1.7275,  1.5108,  2.2136,  1.5433,  6.0419,  1.6091,
          1.4412,  5.8885,  1.1019,  1.1868,  0.9851,  1.1501,  1.2834,  1.3175,
          1.2816,  1.3108,  1.3108,  1.2961,  1.0318,  1.3366,  1.3176,  1.1359,
          1.3491,  1.3828,  1.2980,  1.3363,  1.3200,  1.4599,  1.3694,  1.2843,
          1.3072,  1.4263,  1.3522,  0.4924,  1.3314,  1.0348,  1.3959,  1.3755,
          1.3526,  1.0473,  1.3809,  0.8878,  1.3418,  1.3544],
        [ 1.1811,  1.2071,  1.2585,  1.2405,  1.2140,  1.1867,  1.1936,  1.1795,
          1.1795,  1.2533,  1.2735,  1.2692,  1.2972,  1.2383,  1.3084,  1.2515,
          1.2218,  1.2334,  2.6412,  2.7522,  2.8349,  2.7507,  2.5554,  2.6359,
          2.6748,  2.5428,  2.5428,  1.2632,  1.2626,  1.2076,  1.2304,  1.2626,
          1.2177,  1.2492,  1.2120,  1.2103,  1.3583,  1.4023,  1.3774,  1.3462,
          1.3871,  1.3763,  1.3640,  1.3042,  1.2850,  1.2965,  1.2720,  1.2589,
          1.2398,  1.2730,  1.2603,  1.3277,  1.2309,  1.2384],
        [ 1.1808,  1.2075,  1.2567,  1.2383,  1.2148,  1.1865,  1.1938,  1.1791,
          1.1791,  1.2535,  1.2705,  1.2696,  1.2967,  1.2383,  1.2506,  1.2516,
          1.2393,  1.1761,  1.2187,  1.2442,  1.2576,  1.2317,  1.1935,  1.1862,
          1.2108,  1.1814,  1.1814,  2.8948,  2.8286,  2.4813,  2.6357,  2.8903,
          2.4921,  2.8468,  2.4893,  2.4840,  1.3609,  1.4060,  1.3791,  1.3689,
          1.3907,  1.3796,  1.3665,  1.2895,  1.3081,  1.3209,  1.2697,  1.1658,
          1.1937,  1.3123,  1.2548,  1.3531,  1.1846,  1.2362],
        [ 1.7082,  1.3935,  0.6462,  0.8476,  1.2052,  1.6012,  1.5409,  1.7052,
          1.7052,  1.5461,  1.2474,  1.3867,  0.9234,  1.6342,  0.2979,  1.5326,
          1.6624,  1.0941,  1.3187,  0.8999,  0.7847,  1.1060,  1.5576,  1.6050,
          1.3578,  1.6935,  1.6935,  0.7399,  0.8775,  1.6755,  1.4910,  0.8247,
          1.6155,  1.1077,  1.7270,  1.6433,  0.2025, -0.0238, -0.0402,  0.1566,
          0.4029,  0.5512,  0.1046, 12.5438,  7.3798,  0.8023,  1.2233,  1.3199,
          1.5357,  1.0237,  1.4664,  0.4615,  1.5960,  1.6988],
        [ 1.2391,  1.2702,  1.3319,  1.3111,  1.2794,  1.2458,  1.2105,  1.2371,
          1.2371,  1.2082,  1.3262,  1.2265,  1.3541,  1.2855,  1.4053,  1.2060,
          1.2871,  1.2296,  1.2848,  1.3147,  1.3300,  1.2994,  1.2559,  1.2482,
          1.1910,  1.2421,  1.2421,  1.3033,  1.3448,  1.2633,  1.0764,  1.2566,
          1.1413,  1.3116,  1.1362,  1.2664,  1.3608,  1.0486,  1.3823,  1.3725,
          0.9396,  0.8442,  1.3678,  1.3524,  0.7274,  3.2445,  2.5503,  3.4081,
          2.8243,  2.1502,  1.8396,  2.9441,  3.1624,  1.8187]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 209 : 180.29420326621374
Test loss for epoch 209 : 180.42491551685688
Test Precision for epoch 209 : 0.26153846153846155
Test Recall for epoch 209 : 0.26153846153846155
Test F1 for epoch 209 : 0.26153846153846155


theta for epoch 210 : tensor([[ 2.5792,  2.6094,  2.6834,  2.8009,  2.7642,  2.5854,  2.7395,  2.5774,
          2.5774,  1.2590,  1.2786,  1.2746,  1.3019,  1.2442,  1.3459,  1.2572,
          1.2456,  1.2310,  1.2234,  1.2054,  1.2170,  1.2357,  1.1994,  1.1934,
          1.2164,  1.1880,  1.1880,  1.2333,  1.2748,  1.2067,  1.2291,  1.2769,
          1.2166,  1.2470,  1.1672,  1.2092,  1.3680,  1.4115,  1.3872,  1.3776,
          1.3964,  1.3289,  1.3738,  1.3613,  1.3165,  1.3092,  1.2606,  1.2476,
          1.2289,  1.3009,  1.2491,  1.3405,  1.2203,  1.2275],
        [ 1.2501,  1.1635,  0.9947,  1.2087,  1.2900,  1.3008,  1.2258,  1.2916,
          1.2916,  1.5183,  1.7393,  1.5232,  2.2243,  1.5557,  6.0637,  1.6214,
          1.4537,  5.9111,  1.1065,  1.1916,  0.9898,  1.1549,  1.2884,  1.3226,
          1.2866,  1.3159,  1.3159,  1.2941,  1.0297,  1.3348,  1.3158,  1.1335,
          1.3473,  1.3810,  1.2961,  1.3346,  1.3205,  1.4601,  1.3694,  1.2845,
          1.3078,  1.4265,  1.3522,  0.4917,  1.3313,  1.0268,  1.3880,  1.3675,
          1.3446,  1.0391,  1.3730,  0.8803,  1.3338,  1.3465],
        [ 1.1643,  1.1904,  1.2420,  1.2240,  1.1974,  1.1699,  1.1768,  1.1626,
          1.1626,  1.2561,  1.2764,  1.2721,  1.3001,  1.2412,  1.3111,  1.2543,
          1.2242,  1.2368,  2.6555,  2.7669,  2.8490,  2.7643,  2.5701,  2.6501,
          2.6896,  2.5575,  2.5575,  1.2586,  1.2585,  1.2034,  1.2261,  1.2580,
          1.2135,  1.2450,  1.2078,  1.2060,  1.3569,  1.4010,  1.3762,  1.3445,
          1.3858,  1.3751,  1.3628,  1.3033,  1.2832,  1.2874,  1.2626,  1.2494,
          1.2305,  1.2642,  1.2509,  1.3187,  1.2215,  1.2290],
        [ 1.1675,  1.1943,  1.2443,  1.2259,  1.2017,  1.1733,  1.1806,  1.1658,
          1.1658,  1.2617,  1.2787,  1.2777,  1.3048,  1.2465,  1.2584,  1.2599,
          1.2475,  1.1835,  1.2252,  1.2505,  1.2640,  1.2382,  1.2000,  1.1928,
          1.2173,  1.1880,  1.1880,  2.8984,  2.8335,  2.4855,  2.6403,  2.8939,
          2.4962,  2.8504,  2.4935,  2.4881,  1.3623,  1.4075,  1.3806,  1.3704,
          1.3922,  1.3812,  1.3680,  1.2908,  1.3096,  1.3158,  1.2648,  1.1611,
          1.1887,  1.3072,  1.2501,  1.3480,  1.1796,  1.2312],
        [ 1.6936,  1.3785,  0.6324,  0.8335,  1.1899,  1.5864,  1.5261,  1.6905,
          1.6905,  1.5527,  1.2525,  1.3924,  0.9267,  1.6410,  0.2981,  1.5389,
          1.6696,  1.0974,  1.3239,  0.9039,  0.7877,  1.1104,  1.5638,  1.6110,
          1.3635,  1.6999,  1.6999,  0.7374,  0.8748,  1.6750,  1.4902,  0.8223,
          1.6148,  1.1058,  1.7266,  1.6427,  0.2063, -0.0204, -0.0368,  0.1602,
          0.4066,  0.5546,  0.1081, 12.5896,  7.3713,  0.7910,  1.2135,  1.3104,
          1.5270,  1.0127,  1.4573,  0.4498,  1.5876,  1.6907],
        [ 1.2259,  1.2572,  1.3194,  1.2984,  1.2665,  1.2326,  1.1974,  1.2239,
          1.2239,  1.2217,  1.3398,  1.2400,  1.3677,  1.2990,  1.4183,  1.2196,
          1.3006,  1.2433,  1.2935,  1.3232,  1.3385,  1.3080,  1.2647,  1.2571,
          1.1995,  1.2509,  1.2509,  1.3055,  1.3469,  1.2656,  1.0787,  1.2588,
          1.1438,  1.3138,  1.1387,  1.2687,  1.3645,  1.0527,  1.3860,  1.3763,
          0.9436,  0.8485,  1.3716,  1.3556,  0.7316,  3.2438,  2.5465,  3.4084,
          2.8212,  2.1459,  1.8350,  2.9413,  3.1615,  1.8141]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 210 : 180.32909351878607
Test loss for epoch 210 : 180.46848657504393
Test Precision for epoch 210 : 0.26153846153846155
Test Recall for epoch 210 : 0.26153846153846155
Test F1 for epoch 210 : 0.26153846153846155


theta for epoch 211 : tensor([[ 2.5850,  2.6153,  2.6892,  2.8071,  2.7703,  2.5913,  2.7456,  2.5833,
          2.5833,  1.2390,  1.2586,  1.2546,  1.2819,  1.2243,  1.3259,  1.2372,
          1.2256,  1.2112,  1.2274,  1.2093,  1.2209,  1.2398,  1.2034,  1.1974,
          1.2204,  1.1920,  1.1920,  1.2271,  1.2686,  1.2005,  1.2229,  1.2708,
          1.2104,  1.2409,  1.1610,  1.2030,  1.3715,  1.4151,  1.3907,  1.3811,
          1.3999,  1.3324,  1.3773,  1.3646,  1.3200,  1.3126,  1.2640,  1.2509,
          1.2322,  1.3043,  1.2524,  1.3439,  1.2236,  1.2308],
        [ 1.2628,  1.1767,  1.0089,  1.2219,  1.3028,  1.3134,  1.2387,  1.3042,
          1.3042,  1.4926,  1.7130,  1.4973,  2.1977,  1.5298,  6.0512,  1.5954,
          1.4279,  5.8974,  1.1186,  1.2034,  1.0027,  1.1668,  1.2994,  1.3335,
          1.2977,  1.3267,  1.3267,  1.2948,  1.0325,  1.3347,  1.3161,  1.1352,
          1.3472,  1.3809,  1.2962,  1.3346,  1.3297,  1.4683,  1.3779,  1.2937,
          1.3173,  1.4348,  1.3607,  0.5048,  1.3395,  1.0399,  1.3984,  1.3778,
          1.3550,  1.0520,  1.3834,  0.8944,  1.3441,  1.3569],
        [ 1.1661,  1.1922,  1.2439,  1.2258,  1.1992,  1.1717,  1.1786,  1.1645,
          1.1645,  1.2291,  1.2496,  1.2452,  1.2736,  1.2141,  1.2860,  1.2274,
          1.1968,  1.2110,  2.6662,  2.7780,  2.8595,  2.7743,  2.5813,  2.6607,
          2.7008,  2.5687,  2.5687,  1.2491,  1.2495,  1.1942,  1.2169,  1.2485,
          1.2043,  1.2358,  1.1987,  1.1969,  1.3590,  1.4031,  1.3783,  1.3463,
          1.3879,  1.3772,  1.3649,  1.3064,  1.2850,  1.2892,  1.2640,  1.2509,
          1.2320,  1.2663,  1.2524,  1.3205,  1.2230,  1.2305],
        [ 1.1743,  1.2012,  1.2511,  1.2326,  1.2086,  1.1801,  1.1875,  1.1726,
          1.1726,  1.2427,  1.2603,  1.2589,  1.2864,  1.2274,  1.2408,  1.2408,
          1.2284,  1.1673,  1.2321,  1.2572,  1.2708,  1.2451,  1.2070,  1.1998,
          1.2242,  1.1950,  1.1950,  2.8961,  2.8325,  2.4836,  2.6388,  2.8916,
          2.4944,  2.8481,  2.4916,  2.4863,  1.3675,  1.4126,  1.3859,  1.3756,
          1.3973,  1.3863,  1.3732,  1.2958,  1.3147,  1.3213,  1.2703,  1.1665,
          1.1944,  1.3127,  1.2555,  1.3534,  1.1853,  1.2369],
        [ 1.6972,  1.3814,  0.6334,  0.8352,  1.1924,  1.5898,  1.5294,  1.6941,
          1.6941,  1.5282,  1.2277,  1.3688,  0.9043,  1.6164,  0.2802,  1.5147,
          1.6454,  1.0720,  1.3276,  0.9065,  0.7895,  1.1134,  1.5682,  1.6151,
          1.3676,  1.7045,  1.7045,  0.7307,  0.8679,  1.6690,  1.4839,  0.8155,
          1.6087,  1.0988,  1.7207,  1.6365,  0.2102, -0.0168, -0.0331,  0.1640,
          0.4105,  0.5581,  0.1118, 12.6353,  7.3624,  0.7923,  1.2165,  1.3138,
          1.5308,  1.0145,  1.4608,  0.4496,  1.5917,  1.6948],
        [ 1.2301,  1.2615,  1.3238,  1.3028,  1.2708,  1.2368,  1.2016,  1.2281,
          1.2281,  1.1954,  1.3135,  1.2138,  1.3413,  1.2726,  1.3928,  1.1933,
          1.2742,  1.2171,  1.2979,  1.3274,  1.3427,  1.3124,  1.2691,  1.2615,
          1.2035,  1.2553,  1.2553,  1.2994,  1.3410,  1.2596,  1.0724,  1.2529,
          1.1377,  1.3078,  1.1327,  1.2627,  1.3687,  1.0564,  1.3902,  1.3806,
          0.9472,  0.8520,  1.3759,  1.3600,  0.7349,  3.2529,  2.5528,  3.4187,
          2.8281,  2.1517,  1.8406,  2.9481,  3.1707,  1.8197]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 211 : 180.34447104431374
Test loss for epoch 211 : 180.47235030696544
Test Precision for epoch 211 : 0.26153846153846155
Test Recall for epoch 211 : 0.26153846153846155
Test F1 for epoch 211 : 0.26153846153846155


theta for epoch 212 : tensor([[ 2.6065,  2.6367,  2.7106,  2.8287,  2.7919,  2.6127,  2.7673,  2.6047,
          2.6047,  1.2369,  1.2564,  1.2524,  1.2797,  1.2221,  1.3234,  1.2351,
          1.2235,  1.2088,  1.2041,  1.1860,  1.1976,  1.2165,  1.1802,  1.1742,
          1.1971,  1.1687,  1.1687,  1.2171,  1.2589,  1.1905,  1.2130,  1.2610,
          1.2004,  1.2311,  1.1507,  1.1931,  1.3618,  1.4057,  1.3812,  1.3716,
          1.3904,  1.3227,  1.3677,  1.3546,  1.3105,  1.3075,  1.2588,  1.2457,
          1.2268,  1.2992,  1.2471,  1.3390,  1.2182,  1.2254],
        [ 1.2742,  1.1877,  1.0191,  1.2329,  1.3143,  1.3249,  1.2500,  1.3157,
          1.3157,  1.5067,  1.7265,  1.5113,  2.2102,  1.5438,  6.0738,  1.6095,
          1.4421,  5.9207,  1.0964,  1.1814,  0.9819,  1.1448,  1.2771,  1.3112,
          1.2754,  1.3044,  1.3044,  1.2887,  1.0262,  1.3285,  1.3100,  1.1285,
          1.3411,  1.3751,  1.2898,  1.3285,  1.3224,  1.4609,  1.3701,  1.2860,
          1.3103,  1.4273,  1.3528,  0.4966,  1.3318,  1.0389,  1.3975,  1.3768,
          1.3539,  1.0507,  1.3825,  0.8935,  1.3430,  1.3559],
        [ 1.1826,  1.2087,  1.2603,  1.2423,  1.2157,  1.1882,  1.1952,  1.1810,
          1.1810,  1.2417,  1.2621,  1.2577,  1.2861,  1.2266,  1.2979,  1.2399,
          1.2091,  1.2244,  2.6520,  2.7644,  2.8454,  2.7595,  2.5675,  2.6463,
          2.6872,  2.5549,  2.5549,  1.2526,  1.2535,  1.1979,  1.2207,  1.2520,
          1.2080,  1.2396,  1.2024,  1.2006,  1.3591,  1.4033,  1.3784,  1.3462,
          1.3881,  1.3775,  1.3651,  1.3074,  1.2852,  1.2970,  1.2713,  1.2582,
          1.2392,  1.2743,  1.2596,  1.3282,  1.2302,  1.2377],
        [ 1.1874,  1.2142,  1.2638,  1.2453,  1.2216,  1.1932,  1.2005,  1.1857,
          1.1857,  1.2496,  1.2673,  1.2658,  1.2934,  1.2344,  1.2476,  1.2478,
          1.2353,  1.1739,  1.2162,  1.2418,  1.2550,  1.2293,  1.1911,  1.1840,
          1.2083,  1.1790,  1.1790,  2.8967,  2.8344,  2.4847,  2.6404,  2.8922,
          2.4955,  2.8487,  2.4927,  2.4874,  1.3647,  1.4100,  1.3832,  1.3730,
          1.3947,  1.3838,  1.3706,  1.2935,  1.3122,  1.3243,  1.2732,  1.1694,
          1.1974,  1.3157,  1.2585,  1.3564,  1.1883,  1.2398],
        [ 1.7141,  1.3989,  0.6507,  0.8529,  1.2104,  1.6070,  1.5466,  1.7110,
          1.7110,  1.5416,  1.2424,  1.3825,  0.9192,  1.6291,  0.2948,  1.5278,
          1.6584,  1.0860,  1.3175,  0.8994,  0.7828,  1.1045,  1.5569,  1.6033,
          1.3579,  1.6927,  1.6927,  0.7383,  0.8740,  1.6724,  1.4882,  0.8228,
          1.6124,  1.1049,  1.7239,  1.6399,  0.2003, -0.0265, -0.0427,  0.1539,
          0.4002,  0.5471,  0.1018, 12.6698,  7.3392,  0.8057,  1.2281,  1.3247,
          1.5400,  1.0266,  1.4706,  0.4642,  1.6007,  1.7031],
        [ 1.2432,  1.2746,  1.3369,  1.3160,  1.2840,  1.2500,  1.2147,  1.2413,
          1.2413,  1.2025,  1.3208,  1.2209,  1.3487,  1.2798,  1.4000,  1.2004,
          1.2813,  1.2245,  1.2807,  1.3103,  1.3259,  1.2952,  1.2518,  1.2443,
          1.1862,  1.2380,  1.2380,  1.2980,  1.3395,  1.2580,  1.0706,  1.2514,
          1.1362,  1.3063,  1.1310,  1.2611,  1.3634,  1.0508,  1.3850,  1.3754,
          0.9414,  0.8462,  1.3707,  1.3544,  0.7291,  3.2595,  2.5566,  3.4265,
          2.8326,  2.1549,  1.8437,  2.9526,  3.1774,  1.8228]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 212 : 180.3123065423432
Test loss for epoch 212 : 180.44509778949595
Test Precision for epoch 212 : 0.26153846153846155
Test Recall for epoch 212 : 0.26153846153846155
Test F1 for epoch 212 : 0.26153846153846155


theta for epoch 213 : tensor([[ 2.6020,  2.6322,  2.7061,  2.8245,  2.7878,  2.6082,  2.7631,  2.6002,
          2.6002,  1.2555,  1.2750,  1.2709,  1.2981,  1.2408,  1.3414,  1.2537,
          1.2421,  1.2273,  1.2046,  1.1864,  1.1981,  1.2170,  1.1807,  1.1747,
          1.1976,  1.1692,  1.1692,  1.2234,  1.2651,  1.1968,  1.2193,  1.2673,
          1.2067,  1.2374,  1.1570,  1.1994,  1.3622,  1.4063,  1.3816,  1.3720,
          1.3910,  1.3234,  1.3682,  1.3547,  1.3113,  1.3033,  1.2545,  1.2413,
          1.2224,  1.2950,  1.2428,  1.3348,  1.2137,  1.2209],
        [ 1.2557,  1.1691,  1.0008,  1.2140,  1.2959,  1.3064,  1.2313,  1.2973,
          1.2973,  1.5251,  1.7443,  1.5298,  2.2267,  1.5623,  6.0996,  1.6278,
          1.4606,  5.9474,  1.0928,  1.1780,  0.9788,  1.1413,  1.2738,  1.3080,
          1.2720,  1.3011,  1.3011,  1.2913,  1.0287,  1.3312,  1.3127,  1.1306,
          1.3438,  1.3778,  1.2924,  1.3313,  1.3196,  1.4580,  1.3668,  1.2829,
          1.3079,  1.4244,  1.3495,  0.4926,  1.3286,  1.0307,  1.3893,  1.3685,
          1.3454,  1.0421,  1.3742,  0.8857,  1.3344,  1.3474],
        [ 1.1684,  1.1944,  1.2458,  1.2279,  1.2014,  1.1740,  1.1809,  1.1667,
          1.1667,  1.2590,  1.2795,  1.2750,  1.3034,  1.2440,  1.3142,  1.2573,
          1.2262,  1.2424,  2.6546,  2.7674,  2.8479,  2.7614,  2.5706,  2.6488,
          2.6904,  2.5580,  2.5580,  1.2586,  1.2600,  1.2042,  1.2269,  1.2580,
          1.2143,  1.2458,  1.2086,  1.2068,  1.3592,  1.4036,  1.3786,  1.3460,
          1.3884,  1.3779,  1.3652,  1.3082,  1.2854,  1.2932,  1.2670,  1.2538,
          1.2348,  1.2707,  1.2552,  1.3245,  1.2257,  1.2332],
        [ 1.1724,  1.1991,  1.2490,  1.2307,  1.2065,  1.1781,  1.1855,  1.1707,
          1.1707,  1.2654,  1.2829,  1.2814,  1.3089,  1.2501,  1.2628,  1.2636,
          1.2510,  1.1881,  1.2157,  1.2413,  1.2544,  1.2288,  1.1905,  1.1835,
          1.2077,  1.1785,  1.1785,  2.9022,  2.8411,  2.4908,  2.6468,  2.8977,
          2.5015,  2.8542,  2.4988,  2.4935,  1.3642,  1.4097,  1.3828,  1.3725,
          1.3943,  1.3835,  1.3701,  1.2929,  1.3118,  1.3200,  1.2690,  1.1653,
          1.1930,  1.3115,  1.2544,  1.3522,  1.1839,  1.2354],
        [ 1.7017,  1.3871,  0.6413,  0.8431,  1.1990,  1.5948,  1.5345,  1.6987,
          1.6987,  1.5598,  1.2600,  1.3999,  0.9347,  1.6471,  0.3063,  1.5455,
          1.6767,  1.1019,  1.3190,  0.9012,  0.7841,  1.1059,  1.5586,  1.6046,
          1.3599,  1.6943,  1.6943,  0.7447,  0.8796,  1.6791,  1.4950,  0.8293,
          1.6191,  1.1117,  1.7306,  1.6465,  0.1985, -0.0283, -0.0446,  0.1520,
          0.3983,  0.5448,  0.0999, 12.7110,  7.3240,  0.8010,  1.2231,  1.3196,
          1.5348,  1.0214,  1.4654,  0.4601,  1.5956,  1.6979],
        [ 1.2309,  1.2623,  1.3245,  1.3035,  1.2717,  1.2377,  1.2026,  1.2290,
          1.2290,  1.2279,  1.3462,  1.2463,  1.3743,  1.3049,  1.4250,  1.2258,
          1.3065,  1.2503,  1.2845,  1.3141,  1.3297,  1.2991,  1.2556,  1.2481,
          1.1900,  1.2418,  1.2418,  1.3082,  1.3495,  1.2683,  1.0813,  1.2617,
          1.1467,  1.3165,  1.1417,  1.2714,  1.3661,  1.0547,  1.3878,  1.3782,
          0.9454,  0.8507,  1.3735,  1.3569,  0.7338,  3.2535,  2.5473,  3.4212,
          2.8240,  2.1453,  1.8337,  2.9444,  3.1708,  1.8128]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 213 : 180.33992684586977
Test loss for epoch 213 : 180.48485403970824
Test Precision for epoch 213 : 0.26153846153846155
Test Recall for epoch 213 : 0.26153846153846155
Test F1 for epoch 213 : 0.26153846153846155


theta for epoch 214 : tensor([[ 2.5994,  2.6296,  2.7036,  2.8223,  2.7855,  2.6056,  2.7608,  2.5976,
          2.5976,  1.2306,  1.2501,  1.2460,  1.2733,  1.2159,  1.3168,  1.2288,
          1.2172,  1.2027,  1.2209,  1.2025,  1.2142,  1.2333,  1.1969,  1.1909,
          1.2138,  1.1854,  1.1854,  1.2273,  1.2691,  1.2008,  1.2232,  1.2713,
          1.2107,  1.2413,  1.1610,  1.2033,  1.3681,  1.4122,  1.3876,  1.3779,
          1.3969,  1.3294,  1.3742,  1.3606,  1.3174,  1.3077,  1.2589,  1.2457,
          1.2269,  1.2994,  1.2472,  1.3393,  1.2182,  1.2254],
        [ 1.2576,  1.1718,  1.0054,  1.2166,  1.2978,  1.3079,  1.2335,  1.2988,
          1.2988,  1.4905,  1.7091,  1.4949,  2.1913,  1.5275,  6.0772,  1.5929,
          1.4260,  5.9233,  1.1202,  1.2051,  1.0066,  1.1684,  1.2999,  1.3339,
          1.2982,  1.3270,  1.3270,  1.3046,  1.0449,  1.3433,  1.3254,  1.1454,
          1.3559,  1.3899,  1.3049,  1.3436,  1.3324,  1.4694,  1.3788,  1.2958,
          1.3210,  1.4359,  1.3615,  0.5112,  1.3400,  1.0465,  1.4013,  1.3804,
          1.3575,  1.0577,  1.3862,  0.9029,  1.3465,  1.3595],
        [ 1.1572,  1.1832,  1.2346,  1.2166,  1.1902,  1.1629,  1.1697,  1.1556,
          1.1556,  1.2259,  1.2465,  1.2420,  1.2706,  1.2109,  1.2827,  1.2242,
          1.1927,  1.2103,  2.6730,  2.7862,  2.8661,  2.7790,  2.5896,  2.6671,
          2.7093,  2.5770,  2.5770,  1.2559,  1.2579,  1.2019,  1.2246,  1.2554,
          1.2119,  1.2435,  1.2064,  1.2045,  1.3606,  1.4051,  1.3801,  1.3471,
          1.3898,  1.3793,  1.3667,  1.3104,  1.2863,  1.2923,  1.2656,  1.2524,
          1.2335,  1.2700,  1.2539,  1.3237,  1.2244,  1.2320],
        [ 1.1661,  1.1928,  1.2429,  1.2247,  1.2001,  1.1718,  1.1792,  1.1644,
          1.1644,  1.2381,  1.2563,  1.2545,  1.2824,  1.2229,  1.2370,  1.2363,
          1.2237,  1.1642,  1.2323,  1.2574,  1.2709,  1.2453,  1.2070,  1.2000,
          1.2242,  1.1951,  1.1951,  2.9046,  2.8449,  2.4938,  2.6502,  2.9002,
          2.5046,  2.8567,  2.5018,  2.4965,  1.3689,  1.4144,  1.3876,  1.3774,
          1.3989,  1.3882,  1.3749,  1.2976,  1.3165,  1.3235,  1.2724,  1.1686,
          1.1966,  1.3149,  1.2579,  1.3556,  1.1875,  1.2390],
        [ 1.6925,  1.3770,  0.6301,  0.8323,  1.1883,  1.5853,  1.5249,  1.6895,
          1.6895,  1.5276,  1.2269,  1.3684,  0.9037,  1.6150,  0.2795,  1.5136,
          1.6451,  1.0681,  1.3301,  0.9098,  0.7914,  1.1157,  1.5713,  1.6173,
          1.3716,  1.7076,  1.7076,  0.7402,  0.8753,  1.6784,  1.4937,  0.8251,
          1.6182,  1.1085,  1.7302,  1.6457,  0.2068, -0.0206, -0.0368,  0.1600,
          0.4067,  0.5529,  0.1078, 12.7601,  7.3186,  0.7951,  1.2202,  1.3174,
          1.5338,  1.0167,  1.4638,  0.4520,  1.5950,  1.6976],
        [ 1.2240,  1.2553,  1.3174,  1.2965,  1.2647,  1.2307,  1.1956,  1.2220,
          1.2220,  1.1978,  1.3159,  1.2163,  1.3439,  1.2746,  1.3953,  1.1958,
          1.2761,  1.2203,  1.3012,  1.3307,  1.3461,  1.3158,  1.2723,  1.2648,
          1.2064,  1.2585,  1.2585,  1.3119,  1.3532,  1.2722,  1.0850,  1.2654,
          1.1505,  1.3203,  1.1456,  1.2753,  1.3723,  1.0609,  1.3939,  1.3845,
          0.9517,  0.8570,  1.3797,  1.3632,  0.7399,  3.2587,  2.5497,  3.4275,
          2.8270,  2.1472,  1.8355,  2.9475,  3.1760,  1.8146]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 214 : 180.37164804141167
Test loss for epoch 214 : 180.50116920079645
Test Precision for epoch 214 : 0.26153846153846155
Test Recall for epoch 214 : 0.26153846153846155
Test F1 for epoch 214 : 0.26153846153846155


theta for epoch 215 : tensor([[ 2.6079,  2.6382,  2.7121,  2.8311,  2.7943,  2.6142,  2.7696,  2.6062,
          2.6062,  1.2328,  1.2524,  1.2483,  1.2755,  1.2182,  1.3189,  1.2311,
          1.2195,  1.2050,  1.2147,  1.1964,  1.2081,  1.2272,  1.1906,  1.1847,
          1.2076,  1.1792,  1.1792,  1.2167,  1.2586,  1.1902,  1.2126,  1.2607,
          1.2001,  1.2308,  1.1503,  1.1927,  1.3635,  1.4077,  1.3830,  1.3734,
          1.3923,  1.3248,  1.3696,  1.3557,  1.3129,  1.3100,  1.2612,  1.2480,
          1.2292,  1.3017,  1.2495,  1.3415,  1.2205,  1.2277],
        [ 1.2629,  1.1769,  1.0103,  1.2219,  1.3035,  1.3134,  1.2387,  1.3043,
          1.3043,  1.5013,  1.7193,  1.5055,  2.2007,  1.5381,  6.0956,  1.6036,
          1.4367,  5.9421,  1.1121,  1.1972,  0.9993,  1.1605,  1.2918,  1.3258,
          1.2901,  1.3189,  1.3189,  1.2912,  1.0315,  1.3299,  1.3120,  1.1315,
          1.3425,  1.3766,  1.2913,  1.3302,  1.3263,  1.4629,  1.3722,  1.2894,
          1.3150,  1.4293,  1.3548,  0.5047,  1.3329,  1.0471,  1.4020,  1.3810,
          1.3581,  1.0582,  1.3869,  0.9037,  1.3471,  1.3602],
        [ 1.1674,  1.1935,  1.2449,  1.2270,  1.2005,  1.1731,  1.1799,  1.1658,
          1.1658,  1.2342,  1.2548,  1.2502,  1.2788,  1.2192,  1.2904,  1.2325,
          1.2009,  1.2192,  2.6668,  2.7804,  2.8599,  2.7721,  2.5838,  2.6606,
          2.7037,  2.5712,  2.5712,  1.2501,  1.2526,  1.1963,  1.2190,  1.2495,
          1.2063,  1.2379,  1.2007,  1.1989,  1.3597,  1.4042,  1.3792,  1.3459,
          1.3889,  1.3786,  1.3659,  1.3101,  1.2853,  1.2998,  1.2727,  1.2595,
          1.2406,  1.2778,  1.2610,  1.3311,  1.2315,  1.2391],
        [ 1.1753,  1.2021,  1.2521,  1.2338,  1.2095,  1.1811,  1.1885,  1.1737,
          1.1737,  1.2440,  1.2622,  1.2603,  1.2882,  1.2288,  1.2428,  1.2422,
          1.2296,  1.1699,  1.2295,  1.2547,  1.2682,  1.2425,  1.2042,  1.1972,
          1.2213,  1.1921,  1.1921,  2.9010,  2.8423,  2.4904,  2.6472,  2.8965,
          2.5012,  2.8531,  2.4984,  2.4932,  1.3673,  1.4128,  1.3861,  1.3758,
          1.3973,  1.3866,  1.3734,  1.2962,  1.3149,  1.3286,  1.2776,  1.1738,
          1.2020,  1.3201,  1.2630,  1.3606,  1.1929,  1.2444],
        [ 1.7018,  1.3865,  0.6391,  0.8416,  1.1980,  1.5948,  1.5343,  1.6988,
          1.6988,  1.5353,  1.2350,  1.3761,  0.9116,  1.6224,  0.2865,  1.5211,
          1.6527,  1.0752,  1.3277,  0.9086,  0.7900,  1.1136,  1.5687,  1.6143,
          1.3696,  1.7048,  1.7048,  0.7375,  0.8716,  1.6729,  1.4884,  0.8220,
          1.6127,  1.1042,  1.7245,  1.6401,  0.2013, -0.0262, -0.0422,  0.1544,
          0.4010,  0.5466,  0.1022, 12.7982,  7.2991,  0.8045,  1.2297,  1.3267,
          1.5423,  1.0257,  1.4725,  0.4612,  1.6035,  1.7056],
        [ 1.2293,  1.2607,  1.3229,  1.3020,  1.2701,  1.2361,  1.2009,  1.2274,
          1.2274,  1.1979,  1.3163,  1.2164,  1.3444,  1.2750,  1.3957,  1.1959,
          1.2765,  1.2206,  1.2936,  1.3231,  1.3388,  1.3083,  1.2646,  1.2572,
          1.1984,  1.2508,  1.2508,  1.3005,  1.3421,  1.2608,  1.0730,  1.2540,
          1.1391,  1.3089,  1.1340,  1.2639,  1.3654,  1.0530,  1.3871,  1.3777,
          0.9433,  0.8485,  1.3730,  1.3560,  0.7313,  3.2719,  2.5603,  3.4420,
          2.8382,  2.1572,  1.8454,  2.9585,  3.1895,  1.8245]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 215 : 180.25786686699075
Test loss for epoch 215 : 180.38634446442387
Test Precision for epoch 215 : 0.26153846153846155
Test Recall for epoch 215 : 0.26153846153846155
Test F1 for epoch 215 : 0.26153846153846155


theta for epoch 216 : tensor([[ 2.6118,  2.6421,  2.7160,  2.8352,  2.7984,  2.6181,  2.7738,  2.6101,
          2.6101,  1.2571,  1.2766,  1.2725,  1.2996,  1.2426,  1.3426,  1.2554,
          1.2438,  1.2292,  1.2057,  1.1876,  1.1993,  1.2182,  1.1816,  1.1757,
          1.1986,  1.1701,  1.1701,  1.2158,  1.2577,  1.1892,  1.2117,  1.2598,
          1.1992,  1.2299,  1.1494,  1.1918,  1.3597,  1.4042,  1.3794,  1.3697,
          1.3887,  1.3214,  1.3660,  1.3516,  1.3095,  1.2997,  1.2510,  1.2378,
          1.2190,  1.2915,  1.2393,  1.3312,  1.2102,  1.2175],
        [ 1.2634,  1.1768,  1.0095,  1.2221,  1.3044,  1.3142,  1.2390,  1.3051,
          1.3051,  1.5321,  1.7495,  1.5363,  2.2297,  1.5689,  6.1319,  1.6344,
          1.4677,  5.9795,  1.0931,  1.1785,  0.9810,  1.1417,  1.2733,  1.3075,
          1.2715,  1.3005,  1.3005,  1.2795,  1.0189,  1.3189,  1.3008,  1.1187,
          1.3315,  1.3657,  1.2800,  1.3193,  1.3151,  1.4517,  1.3605,  1.2778,
          1.3040,  1.4180,  1.3431,  0.4905,  1.3211,  1.0262,  1.3821,  1.3610,
          1.3381,  1.0368,  1.3671,  0.8830,  1.3270,  1.3402],
        [ 1.1791,  1.2052,  1.2569,  1.2390,  1.2124,  1.1848,  1.1917,  1.1775,
          1.1775,  1.2631,  1.2835,  1.2790,  1.3073,  1.2482,  1.3175,  1.2614,
          1.2296,  1.2486,  2.6550,  2.7692,  2.8481,  2.7597,  2.5725,  2.6486,
          2.6926,  2.5599,  2.5599,  1.2533,  1.2562,  1.1997,  1.2224,  1.2527,
          1.2097,  1.2413,  1.2041,  1.2023,  1.3591,  1.4038,  1.3786,  1.3450,
          1.3883,  1.3782,  1.3653,  1.3099,  1.2848,  1.2938,  1.2663,  1.2531,
          1.2341,  1.2721,  1.2545,  1.3251,  1.2250,  1.2326],
        [ 1.1821,  1.2090,  1.2591,  1.2407,  1.2164,  1.1879,  1.1953,  1.1805,
          1.1805,  1.2656,  1.2834,  1.2816,  1.3094,  1.2504,  1.2634,  1.2638,
          1.2512,  1.1894,  1.2184,  1.2440,  1.2572,  1.2315,  1.1931,  1.1862,
          1.2102,  1.1810,  1.1810,  2.9036,  2.8461,  2.4935,  2.6507,  2.8991,
          2.5043,  2.8557,  2.5015,  2.4962,  1.3628,  1.4084,  1.3818,  1.3714,
          1.3928,  1.3823,  1.3690,  1.2918,  1.3106,  1.3184,  1.2678,  1.1644,
          1.1921,  1.3100,  1.2536,  1.3505,  1.1829,  1.2343],
        [ 1.7105,  1.3952,  0.6471,  0.8501,  1.2068,  1.6035,  1.5431,  1.7075,
          1.7075,  1.5610,  1.2602,  1.4009,  0.9343,  1.6479,  0.3045,  1.5462,
          1.6785,  1.0986,  1.3194,  0.9016,  0.7828,  1.1057,  1.5603,  1.6055,
          1.3620,  1.6962,  1.6962,  0.7396,  0.8726,  1.6734,  1.4892,  0.8239,
          1.6133,  1.1057,  1.7249,  1.6406,  0.1960, -0.0316, -0.0476,  0.1489,
          0.3955,  0.5405,  0.0967, 12.8367,  7.2796,  0.7952,  1.2195,  1.3161,
          1.5313,  1.0154,  1.4616,  0.4534,  1.5924,  1.6944],
        [ 1.2384,  1.2699,  1.3324,  1.3114,  1.2794,  1.2453,  1.2101,  1.2365,
          1.2365,  1.2243,  1.3429,  1.2428,  1.3711,  1.3016,  1.4218,  1.2223,
          1.3030,  1.2473,  1.2838,  1.3134,  1.3293,  1.2986,  1.2547,  1.2473,
          1.1884,  1.2409,  1.2409,  1.2998,  1.3413,  1.2602,  1.0724,  1.2533,
          1.1385,  1.3083,  1.1334,  1.2633,  1.3604,  1.0482,  1.3822,  1.3728,
          0.9383,  0.8438,  1.3682,  1.3503,  0.7266,  3.2688,  2.5541,  3.4398,
          2.8327,  2.1505,  1.8383,  2.9533,  3.1861,  1.8174]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 216 : 180.3901067370935
Test loss for epoch 216 : 180.53642440392855
Test Precision for epoch 216 : 0.26153846153846155
Test Recall for epoch 216 : 0.26153846153846155
Test F1 for epoch 216 : 0.26153846153846155


theta for epoch 217 : tensor([[ 2.6055,  2.6358,  2.7097,  2.8292,  2.7924,  2.6118,  2.7677,  2.6037,
          2.6037,  1.2376,  1.2573,  1.2530,  1.2803,  1.2231,  1.3235,  1.2360,
          1.2243,  1.2103,  1.2169,  1.1988,  1.2105,  1.2294,  1.1928,  1.1869,
          1.2098,  1.1813,  1.1813,  1.2303,  1.2720,  1.2038,  1.2261,  1.2741,
          1.2136,  1.2443,  1.1640,  1.2063,  1.3675,  1.4119,  1.3872,  1.3775,
          1.3964,  1.3293,  1.3738,  1.3594,  1.3174,  1.3049,  1.2562,  1.2431,
          1.2243,  1.2967,  1.2446,  1.3363,  1.2156,  1.2229],
        [ 1.2695,  1.1837,  1.0185,  1.2293,  1.3109,  1.3201,  1.2454,  1.3109,
          1.3109,  1.5037,  1.7206,  1.5077,  2.2005,  1.5404,  6.1130,  1.6058,
          1.4392,  5.9594,  1.1106,  1.1955,  0.9993,  1.1589,  1.2896,  1.3236,
          1.2878,  1.3166,  1.3166,  1.2990,  1.0411,  1.3375,  1.3198,  1.1395,
          1.3500,  1.3841,  1.2989,  1.3381,  1.3265,  1.4617,  1.3710,  1.2892,
          1.3157,  1.4280,  1.3537,  0.5073,  1.3309,  1.0377,  1.3899,  1.3689,
          1.3460,  1.0481,  1.3751,  0.8960,  1.3349,  1.3483],
        [ 1.1741,  1.2004,  1.2522,  1.2342,  1.2075,  1.1798,  1.1868,  1.1725,
          1.1725,  1.2361,  1.2566,  1.2520,  1.2804,  1.2213,  1.2913,  1.2345,
          1.2024,  1.2224,  2.6675,  2.7821,  2.8605,  2.7714,  2.5855,  2.6610,
          2.7057,  2.5729,  2.5729,  1.2584,  1.2620,  1.2053,  1.2279,  1.2578,
          1.2153,  1.2468,  1.2098,  1.2080,  1.3601,  1.4049,  1.3798,  1.3458,
          1.3894,  1.3794,  1.3665,  1.3116,  1.2854,  1.2907,  1.2627,  1.2495,
          1.2306,  1.2692,  1.2510,  1.3221,  1.2215,  1.2291],
        [ 1.1778,  1.2047,  1.2551,  1.2367,  1.2121,  1.1836,  1.1910,  1.1761,
          1.1761,  1.2373,  1.2558,  1.2536,  1.2817,  1.2221,  1.2361,  1.2356,
          1.2229,  1.1638,  1.2226,  1.2481,  1.2614,  1.2357,  1.1973,  1.1905,
          1.2144,  1.1853,  1.1853,  2.9137,  2.8576,  2.5043,  2.6618,  2.9092,
          2.5150,  2.8658,  2.5122,  2.5070,  1.3641,  1.4097,  1.3832,  1.3728,
          1.3941,  1.3836,  1.3704,  1.2931,  1.3118,  1.3162,  1.2657,  1.1622,
          1.1900,  1.3078,  1.2516,  1.3482,  1.1808,  1.2322],
        [ 1.7065,  1.3903,  0.6406,  0.8441,  1.2013,  1.5992,  1.5386,  1.7034,
          1.7034,  1.5340,  1.2327,  1.3745,  0.9083,  1.6209,  0.2814,  1.5194,
          1.6519,  1.0702,  1.3231,  0.9036,  0.7836,  1.1083,  1.5653,  1.6104,
          1.3664,  1.7017,  1.7017,  0.7419,  0.8748,  1.6799,  1.4951,  0.8266,
          1.6196,  1.1099,  1.7315,  1.6469,  0.2026, -0.0254, -0.0414,  0.1553,
          0.4023,  0.5469,  0.1030, 12.8845,  7.2715,  0.7880,  1.2148,  1.3119,
          1.5281,  1.0091,  1.4580,  0.4445,  1.5896,  1.6919],
        [ 1.2364,  1.2680,  1.3305,  1.3095,  1.2775,  1.2432,  1.2080,  1.2344,
          1.2344,  1.1962,  1.3147,  1.2147,  1.3428,  1.2734,  1.3940,  1.1942,
          1.2748,  1.2192,  1.2907,  1.3201,  1.3360,  1.3054,  1.2616,  1.2542,
          1.1949,  1.2477,  1.2477,  1.3088,  1.3503,  1.2697,  1.0813,  1.2623,
          1.1477,  1.3175,  1.1428,  1.2728,  1.3645,  1.0520,  1.3863,  1.3769,
          0.9420,  0.8474,  1.3723,  1.3545,  0.7301,  3.2750,  2.5575,  3.4471,
          2.8367,  2.1534,  1.8411,  2.9574,  3.1923,  1.8202]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 217 : 180.2527040983287
Test loss for epoch 217 : 180.38689145448566
Test Precision for epoch 217 : 0.26153846153846155
Test Recall for epoch 217 : 0.26153846153846155
Test F1 for epoch 217 : 0.26153846153846155


theta for epoch 218 : tensor([[ 2.6010,  2.6313,  2.7053,  2.8250,  2.7882,  2.6072,  2.7635,  2.5992,
          2.5992,  1.2372,  1.2569,  1.2526,  1.2801,  1.2227,  1.3233,  1.2356,
          1.2238,  1.2102,  1.2256,  1.2075,  1.2192,  1.2382,  1.2014,  1.1956,
          1.2185,  1.1900,  1.1900,  1.2263,  1.2680,  1.1998,  1.2221,  1.2701,
          1.2096,  1.2403,  1.1601,  1.2023,  1.3705,  1.4149,  1.3902,  1.3806,
          1.3994,  1.3325,  1.3769,  1.3625,  1.3206,  1.3140,  1.2654,  1.2523,
          1.2336,  1.3058,  1.2538,  1.3453,  1.2248,  1.2321],
        [ 1.2638,  1.1785,  1.0146,  1.2242,  1.3056,  1.3144,  1.2399,  1.3052,
          1.3052,  1.4991,  1.7153,  1.5029,  2.1945,  1.5357,  6.1157,  1.6010,
          1.4346,  5.9618,  1.1211,  1.2058,  1.0101,  1.1692,  1.2996,  1.3335,
          1.2977,  1.3264,  1.3264,  1.2945,  1.0381,  1.3325,  1.3151,  1.1354,
          1.3451,  1.3792,  1.2941,  1.3332,  1.3292,  1.4636,  1.3731,  1.2918,
          1.3187,  1.4299,  1.3557,  0.5125,  1.3325,  1.0478,  1.3982,  1.3771,
          1.3542,  1.0579,  1.3834,  0.9067,  1.3431,  1.3566],
        [ 1.1639,  1.1902,  1.2421,  1.2240,  1.1974,  1.1696,  1.1766,  1.1623,
          1.1623,  1.2296,  1.2501,  1.2455,  1.2739,  1.2149,  1.2848,  1.2280,
          1.1956,  1.2166,  2.6806,  2.7956,  2.8733,  2.7837,  2.5992,  2.6739,
          2.7194,  2.5865,  2.5865,  1.2463,  1.2504,  1.1935,  1.2161,  1.2457,
          1.2035,  1.2351,  1.1980,  1.1962,  1.3578,  1.4027,  1.3775,  1.3431,
          1.3871,  1.3772,  1.3643,  1.3098,  1.2828,  1.2934,  1.2649,  1.2516,
          1.2328,  1.2720,  1.2532,  1.3247,  1.2236,  1.2312],
        [ 1.1725,  1.1994,  1.2501,  1.2318,  1.2069,  1.1783,  1.1857,  1.1709,
          1.1709,  1.2358,  1.2545,  1.2521,  1.2804,  1.2207,  1.2349,  1.2341,
          1.2213,  1.1629,  1.2309,  1.2562,  1.2696,  1.2440,  1.2056,  1.1988,
          1.2227,  1.1936,  1.1936,  2.9119,  2.8569,  2.5028,  2.6607,  2.9075,
          2.5136,  2.8641,  2.5107,  2.5055,  1.3656,  1.4113,  1.3848,  1.3744,
          1.3955,  1.3852,  1.3720,  1.2946,  1.3133,  1.3229,  1.2724,  1.1688,
          1.1968,  1.3146,  1.2582,  1.3549,  1.1876,  1.2391],
        [ 1.7014,  1.3855,  0.6370,  0.8404,  1.1966,  1.5942,  1.5336,  1.6983,
          1.6983,  1.5326,  1.2313,  1.3732,  0.9071,  1.6192,  0.2806,  1.5179,
          1.6506,  1.0677,  1.3315,  0.9120,  0.7913,  1.1167,  1.5742,  1.6191,
          1.3753,  1.7106,  1.7106,  0.7383,  0.8704,  1.6749,  1.4902,  0.8227,
          1.6146,  1.1054,  1.7265,  1.6419,  0.2013, -0.0270, -0.0428,  0.1538,
          0.4007,  0.5448,  0.1015, 12.9256,  7.2548,  0.7967,  1.2245,  1.3216,
          1.5373,  1.0178,  1.4673,  0.4523,  1.5990,  1.7008],
        [ 1.2278,  1.2594,  1.3220,  1.3009,  1.2689,  1.2347,  1.1994,  1.2259,
          1.2259,  1.1903,  1.3091,  1.2088,  1.3373,  1.2676,  1.3887,  1.1883,
          1.2689,  1.2136,  1.2960,  1.3254,  1.3413,  1.3108,  1.2669,  1.2596,
          1.1999,  1.2530,  1.2530,  1.3006,  1.3424,  1.2615,  1.0727,  1.2542,
          1.1395,  1.3094,  1.1344,  1.2646,  1.3633,  1.0501,  1.3852,  1.3759,
          0.9398,  0.8451,  1.3713,  1.3533,  0.7276,  3.2869,  2.5670,  3.4604,
          2.8467,  2.1623,  1.8499,  2.9672,  3.2045,  1.8290]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 218 : 180.31299131402722
Test loss for epoch 218 : 180.43896987135798
Test Precision for epoch 218 : 0.26153846153846155
Test Recall for epoch 218 : 0.26153846153846155
Test F1 for epoch 218 : 0.26153846153846155


theta for epoch 219 : tensor([[ 2.6125,  2.6427,  2.7167,  2.8367,  2.7999,  2.6187,  2.7752,  2.6107,
          2.6107,  1.2530,  1.2728,  1.2684,  1.2959,  1.2385,  1.3391,  1.2514,
          1.2396,  1.2258,  1.2087,  1.1905,  1.2022,  1.2212,  1.1845,  1.1788,
          1.2016,  1.1731,  1.1731,  1.2167,  1.2586,  1.1903,  1.2127,  1.2607,
          1.2002,  1.2309,  1.1504,  1.1929,  1.3658,  1.4104,  1.3856,  1.3760,
          1.3949,  1.3279,  1.3723,  1.3576,  1.3164,  1.3081,  1.2595,  1.2464,
          1.2276,  1.2999,  1.2479,  1.3394,  1.2188,  1.2261],
        [ 1.2593,  1.1736,  1.0092,  1.2193,  1.3014,  1.3101,  1.2352,  1.3009,
          1.3009,  1.5243,  1.7399,  1.5281,  2.2181,  1.5608,  6.1457,  1.6261,
          1.4599,  5.9925,  1.1017,  1.1865,  0.9916,  1.1499,  1.2803,  1.3143,
          1.2784,  1.3073,  1.3073,  1.2822,  1.0254,  1.3205,  1.3031,  1.1223,
          1.3331,  1.3673,  1.2818,  1.3212,  1.3224,  1.4567,  1.3657,  1.2846,
          1.3123,  1.4229,  1.3482,  0.5035,  1.3251,  1.0386,  1.3895,  1.3682,
          1.3452,  1.0484,  1.3746,  0.8977,  1.3340,  1.3476],
        [ 1.1695,  1.1957,  1.2475,  1.2295,  1.2029,  1.1752,  1.1821,  1.1679,
          1.1679,  1.2549,  1.2752,  1.2707,  1.2988,  1.2402,  1.3087,  1.2533,
          1.2207,  1.2422,  2.6701,  2.7855,  2.8628,  2.7725,  2.5891,  2.6630,
          2.7096,  2.5764,  2.5764,  1.2453,  1.2498,  1.1927,  1.2153,  1.2447,
          1.2027,  1.2344,  1.1971,  1.1953,  1.3595,  1.4047,  1.3793,  1.3445,
          1.3890,  1.3793,  1.3660,  1.3118,  1.2848,  1.2954,  1.2664,  1.2531,
          1.2341,  1.2742,  1.2546,  1.3268,  1.2249,  1.2325],
        [ 1.1768,  1.2037,  1.2542,  1.2359,  1.2111,  1.1826,  1.1900,  1.1752,
          1.1752,  1.2591,  1.2775,  1.2752,  1.3033,  1.2440,  1.2576,  1.2575,
          1.2447,  1.1846,  1.2194,  1.2450,  1.2581,  1.2326,  1.1941,  1.1875,
          1.2112,  1.1821,  1.1821,  2.9094,  2.8554,  2.5006,  2.6589,  2.9050,
          2.5114,  2.8616,  2.5085,  2.5033,  1.3656,  1.4115,  1.3848,  1.3744,
          1.3956,  1.3854,  1.3720,  1.2944,  1.3136,  1.3233,  1.2727,  1.1692,
          1.1971,  1.3149,  1.2585,  1.3552,  1.1879,  1.2393],
        [ 1.7068,  1.3914,  0.6432,  0.8469,  1.2029,  1.5999,  1.5394,  1.7038,
          1.7038,  1.5569,  1.2552,  1.3968,  0.9292,  1.6432,  0.2990,  1.5417,
          1.6749,  1.0899,  1.3214,  0.9037,  0.7829,  1.1072,  1.5638,  1.6083,
          1.3659,  1.7000,  1.7000,  0.7394,  0.8700,  1.6731,  1.4889,  0.8234,
          1.6130,  1.1051,  1.7246,  1.6401,  0.1959, -0.0323, -0.0482,  0.1482,
          0.3952,  0.5385,  0.0959, 12.9637,  7.2337,  0.7987,  1.2257,  1.3225,
          1.5374,  1.0189,  1.4675,  0.4552,  1.5989,  1.7005],
        [ 1.2336,  1.2651,  1.3274,  1.3065,  1.2746,  1.2404,  1.2053,  1.2317,
          1.2317,  1.2165,  1.3353,  1.2350,  1.3637,  1.2937,  1.4147,  1.2146,
          1.2950,  1.2401,  1.2846,  1.3140,  1.3301,  1.2994,  1.2554,  1.2481,
          1.1885,  1.2415,  1.2415,  1.2991,  1.3407,  1.2597,  1.0713,  1.2527,
          1.1380,  1.3077,  1.1329,  1.2628,  1.3628,  1.0505,  1.3848,  1.3755,
          0.9402,  0.8459,  1.3709,  1.3522,  0.7286,  3.2842,  2.5612,  3.4584,
          2.8416,  2.1562,  1.8435,  2.9624,  3.2014,  1.8226]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 219 : 180.23592819990006
Test loss for epoch 219 : 180.37699451674135
Test Precision for epoch 219 : 0.26153846153846155
Test Recall for epoch 219 : 0.26153846153846155
Test F1 for epoch 219 : 0.26153846153846155


theta for epoch 220 : tensor([[ 2.6237,  2.6539,  2.7279,  2.8482,  2.8114,  2.6299,  2.7867,  2.6219,
          2.6219,  1.2441,  1.2640,  1.2596,  1.2873,  1.2296,  1.3306,  1.2425,
          1.2307,  1.2170,  1.2015,  1.1831,  1.1949,  1.2141,  1.1773,  1.1716,
          1.1944,  1.1659,  1.1659,  1.2174,  1.2595,  1.1912,  1.2135,  1.2616,
          1.2010,  1.2318,  1.1511,  1.1937,  1.3631,  1.4078,  1.3829,  1.3733,
          1.3922,  1.3251,  1.3696,  1.3548,  1.3139,  1.3014,  1.2528,  1.2396,
          1.2209,  1.2932,  1.2411,  1.3327,  1.2121,  1.2193],
        [ 1.2627,  1.1771,  1.0135,  1.2229,  1.3050,  1.3134,  1.2386,  1.3043,
          1.3043,  1.5206,  1.7356,  1.5242,  2.2131,  1.5570,  6.1486,  1.6222,
          1.4562,  5.9950,  1.1014,  1.1860,  0.9922,  1.1495,  1.2794,  1.3133,
          1.2774,  1.3062,  1.3062,  1.2902,  1.0348,  1.3281,  1.3110,  1.1307,
          1.3407,  1.3749,  1.2896,  1.3290,  1.3244,  1.4580,  1.3669,  1.2864,
          1.3148,  1.4242,  1.3494,  0.5077,  1.3262,  1.0387,  1.3876,  1.3662,
          1.3431,  1.0481,  1.3726,  0.8989,  1.3319,  1.3455],
        [ 1.1724,  1.1986,  1.2502,  1.2323,  1.2057,  1.1781,  1.1851,  1.1708,
          1.1708,  1.2540,  1.2742,  1.2697,  1.2978,  1.2393,  1.3075,  1.2524,
          1.2196,  1.2420,  2.6687,  2.7846,  2.8613,  2.7703,  2.5882,  2.6614,
          2.7088,  2.5755,  2.5755,  1.2523,  1.2573,  1.1999,  1.2226,  1.2517,
          1.2100,  1.2416,  1.2044,  1.2026,  1.3611,  1.4066,  1.3810,  1.3458,
          1.3908,  1.3813,  1.3677,  1.3138,  1.2865,  1.2941,  1.2644,  1.2511,
          1.2321,  1.2731,  1.2526,  1.3256,  1.2228,  1.2304],
        [ 1.1785,  1.2053,  1.2557,  1.2375,  1.2127,  1.1843,  1.1917,  1.1769,
          1.1769,  1.2558,  1.2743,  1.2719,  1.3001,  1.2407,  1.2544,  1.2541,
          1.2413,  1.1818,  1.2159,  1.2416,  1.2547,  1.2291,  1.1906,  1.1841,
          1.2077,  1.1786,  1.1786,  2.9139,  2.8610,  2.5055,  2.6642,  2.9095,
          2.5163,  2.8661,  2.5134,  2.5083,  1.3655,  1.4115,  1.3849,  1.3744,
          1.3956,  1.3855,  1.3720,  1.2943,  1.3138,  1.3208,  1.2702,  1.1667,
          1.1946,  1.3124,  1.2561,  1.3528,  1.1853,  1.2366],
        [ 1.7094,  1.3938,  0.6444,  0.8487,  1.2052,  1.6025,  1.5419,  1.7064,
          1.7064,  1.5538,  1.2516,  1.3937,  0.9256,  1.6400,  0.2953,  1.5385,
          1.6720,  1.0849,  1.3178,  0.9001,  0.7786,  1.1033,  1.5607,  1.6050,
          1.3630,  1.6972,  1.6972,  0.7431,  0.8730,  1.6780,  1.4937,  0.8272,
          1.6179,  1.1095,  1.7296,  1.6449,  0.1963, -0.0321, -0.0480,  0.1485,
          0.3957,  0.5385,  0.0961, 13.0067,  7.2185,  0.7927,  1.2204,  1.3173,
          1.5323,  1.0128,  1.4624,  0.4492,  1.5940,  1.6956],
        [ 1.2397,  1.2711,  1.3331,  1.3123,  1.2805,  1.2465,  1.2114,  1.2378,
          1.2378,  1.2167,  1.3353,  1.2353,  1.3638,  1.2937,  1.4149,  1.2148,
          1.2950,  1.2406,  1.2843,  1.3137,  1.3299,  1.2992,  1.2550,  1.2478,
          1.1882,  1.2411,  1.2411,  1.3084,  1.3499,  1.2691,  1.0808,  1.2621,
          1.1475,  1.3170,  1.1425,  1.2722,  1.3654,  1.0542,  1.3874,  1.3781,
          0.9440,  0.8502,  1.3736,  1.3546,  0.7330,  3.2794,  2.5534,  3.4544,
          2.8344,  2.1481,  1.8351,  2.9555,  3.1963,  1.8142]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 220 : 180.23605509778793
Test loss for epoch 220 : 180.38053407335053
Test Precision for epoch 220 : 0.26153846153846155
Test Recall for epoch 220 : 0.26153846153846155
Test F1 for epoch 220 : 0.26153846153846155


theta for epoch 221 : tensor([[ 2.6191,  2.6494,  2.7234,  2.8439,  2.8072,  2.6253,  2.7825,  2.6173,
          2.6173,  1.2311,  1.2511,  1.2466,  1.2745,  1.2166,  1.3181,  1.2295,
          1.2176,  1.2044,  1.2130,  1.1946,  1.2064,  1.2256,  1.1888,  1.1831,
          1.2059,  1.1774,  1.1774,  1.2242,  1.2662,  1.1979,  1.2203,  1.2683,
          1.2078,  1.2385,  1.1579,  1.2005,  1.3651,  1.4097,  1.3850,  1.3754,
          1.3941,  1.3272,  1.3717,  1.3570,  1.3160,  1.3085,  1.2600,  1.2469,
          1.2283,  1.3004,  1.2484,  1.3397,  1.2195,  1.2267],
        [ 1.2583,  1.1735,  1.0118,  1.2194,  1.3010,  1.3089,  1.2345,  1.2997,
          1.2997,  1.5039,  1.7183,  1.5073,  2.1951,  1.5402,  6.1391,  1.6053,
          1.4395,  5.9847,  1.1185,  1.2028,  1.0099,  1.1664,  1.2956,  1.3293,
          1.2936,  1.3222,  1.3222,  1.3015,  1.0482,  1.3387,  1.3219,  1.1428,
          1.3512,  1.3854,  1.3003,  1.3396,  1.3292,  1.4617,  1.3710,  1.2913,
          1.3201,  1.4280,  1.3535,  0.5169,  1.3297,  1.0512,  1.3973,  1.3759,
          1.3528,  1.0603,  1.3823,  0.9125,  1.3416,  1.3553],
        [ 1.1613,  1.1874,  1.2390,  1.2211,  1.1946,  1.1669,  1.1739,  1.1596,
          1.1596,  1.2372,  1.2575,  1.2530,  1.2811,  1.2226,  1.2911,  1.2357,
          1.2026,  1.2260,  2.6822,  2.7984,  2.8746,  2.7829,  2.6022,  2.6746,
          2.7230,  2.5896,  2.5896,  1.2527,  1.2583,  1.2006,  1.2233,  1.2521,
          1.2107,  1.2423,  1.2051,  1.2033,  1.3586,  1.4042,  1.3786,  1.3429,
          1.3883,  1.3789,  1.3653,  1.3120,  1.2836,  1.2953,  1.2652,  1.2518,
          1.2328,  1.2745,  1.2533,  1.3269,  1.2235,  1.2311],
        [ 1.1702,  1.1970,  1.2476,  1.2295,  1.2044,  1.1760,  1.1833,  1.1685,
          1.1685,  1.2414,  1.2602,  1.2576,  1.2861,  1.2263,  1.2407,  1.2398,
          1.2269,  1.1689,  1.2261,  1.2515,  1.2648,  1.2392,  1.2007,  1.1942,
          1.2178,  1.1887,  1.1887,  2.9181,  2.8663,  2.5102,  2.6691,  2.9137,
          2.5209,  2.8703,  2.5180,  2.5129,  1.3653,  1.4114,  1.3848,  1.3743,
          1.3954,  1.3854,  1.3719,  1.2943,  1.3136,  1.3246,  1.2740,  1.1704,
          1.1985,  1.3162,  1.2599,  1.3565,  1.1892,  1.2406],
        [ 1.7016,  1.3860,  0.6372,  0.8415,  1.1973,  1.5947,  1.5341,  1.6986,
          1.6986,  1.5394,  1.2369,  1.3797,  0.9118,  1.6254,  0.2836,  1.5241,
          1.6579,  1.0690,  1.3275,  0.9090,  0.7865,  1.1125,  1.5714,  1.6155,
          1.3732,  1.7080,  1.7080,  0.7455,  0.8748,  1.6818,  1.4974,  0.8298,
          1.6217,  1.1126,  1.7335,  1.6486,  0.1973, -0.0315, -0.0474,  0.1492,
          0.3966,  0.5389,  0.0967, 13.0502,  7.2033,  0.7958,  1.2252,  1.3223,
          1.5375,  1.0163,  1.4674,  0.4511,  1.5994,  1.7008],
        [ 1.2299,  1.2613,  1.3231,  1.3023,  1.2706,  1.2367,  1.2016,  1.2280,
          1.2280,  1.1989,  1.3176,  1.2176,  1.3461,  1.2759,  1.3977,  1.1970,
          1.2771,  1.2229,  1.2930,  1.3223,  1.3386,  1.3079,  1.2637,  1.2565,
          1.1965,  1.2497,  1.2497,  1.3114,  1.3529,  1.2722,  1.0833,  1.2650,
          1.1503,  1.3201,  1.1453,  1.2753,  1.3636,  1.0518,  1.3857,  1.3765,
          0.9413,  0.8474,  1.3719,  1.3529,  0.7301,  3.2901,  2.5615,  3.4662,
          2.8431,  2.1557,  1.8426,  2.9641,  3.2071,  1.8217]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 221 : 180.2342309854361
Test loss for epoch 221 : 180.36540986049965
Test Precision for epoch 221 : 0.26153846153846155
Test Recall for epoch 221 : 0.26153846153846155
Test F1 for epoch 221 : 0.26153846153846155


theta for epoch 222 : tensor([[ 2.6161,  2.6464,  2.7205,  2.8413,  2.8045,  2.6224,  2.7798,  2.6144,
          2.6144,  1.2394,  1.2595,  1.2549,  1.2830,  1.2249,  1.3266,  1.2378,
          1.2259,  1.2130,  1.2178,  1.1995,  1.2113,  1.2305,  1.1936,  1.1879,
          1.2106,  1.1821,  1.1821,  1.2198,  1.2618,  1.1935,  1.2158,  1.2639,
          1.2033,  1.2341,  1.1535,  1.1961,  1.3662,  1.4108,  1.3861,  1.3765,
          1.3951,  1.3283,  1.3729,  1.3580,  1.3173,  1.3123,  1.2640,  1.2508,
          1.2323,  1.3042,  1.2524,  1.3433,  1.2235,  1.2307],
        [ 1.2531,  1.1684,  1.0074,  1.2146,  1.2964,  1.3039,  1.2293,  1.2947,
          1.2947,  1.5132,  1.7269,  1.5165,  2.2029,  1.5494,  6.1537,  1.6145,
          1.4489,  5.9993,  1.1192,  1.2036,  1.0111,  1.1671,  1.2962,  1.3300,
          1.2943,  1.3229,  1.3229,  1.2913,  1.0387,  1.3284,  1.3117,  1.1324,
          1.3410,  1.3752,  1.2900,  1.3295,  1.3261,  1.4580,  1.3672,  1.2879,
          1.3173,  1.4242,  1.3497,  0.5139,  1.3256,  1.0498,  1.3952,  1.3737,
          1.3507,  1.0586,  1.3803,  0.9115,  1.3394,  1.3532],
        [ 1.1600,  1.1862,  1.2380,  1.2200,  1.1934,  1.1657,  1.1726,  1.1584,
          1.1584,  1.2438,  1.2641,  1.2595,  1.2876,  1.2293,  1.2973,  1.2423,
          1.2090,  1.2332,  2.6849,  2.8015,  2.8771,  2.7847,  2.6054,  2.6770,
          2.7263,  2.5927,  2.5927,  1.2450,  1.2510,  1.1932,  1.2159,  1.2444,
          1.2032,  1.2350,  1.1977,  1.1958,  1.3579,  1.4037,  1.3780,  1.3419,
          1.3876,  1.3784,  1.3648,  1.3116,  1.2827,  1.2964,  1.2658,  1.2524,
          1.2334,  1.2758,  1.2539,  1.3280,  1.2241,  1.2317],
        [ 1.1701,  1.1970,  1.2478,  1.2296,  1.2044,  1.1759,  1.1833,  1.1685,
          1.1685,  1.2491,  1.2679,  1.2653,  1.2937,  1.2341,  1.2483,  1.2475,
          1.2346,  1.1764,  1.2302,  1.2555,  1.2690,  1.2434,  1.2048,  1.1983,
          1.2219,  1.1928,  1.1928,  2.9153,  2.8646,  2.5077,  2.6670,  2.9110,
          2.5184,  2.8676,  2.5155,  2.5104,  1.3652,  1.4114,  1.3848,  1.3743,
          1.3952,  1.3854,  1.3719,  1.2941,  1.3135,  1.3265,  1.2759,  1.1724,
          1.2005,  1.3181,  1.2619,  1.3584,  1.1912,  1.2426],
        [ 1.7007,  1.3852,  0.6367,  0.8411,  1.1965,  1.5939,  1.5332,  1.6977,
          1.6977,  1.5464,  1.2433,  1.3863,  0.9175,  1.6322,  0.2880,  1.5307,
          1.6651,  1.0736,  1.3306,  0.9124,  0.7892,  1.1157,  1.5751,  1.6189,
          1.3770,  1.7117,  1.7117,  0.7411,  0.8693,  1.6759,  1.4915,  0.8250,
          1.6158,  1.1071,  1.7275,  1.6426,  0.1952, -0.0339, -0.0496,  0.1469,
          0.3944,  0.5361,  0.0944, 13.0913,  7.1847,  0.7975,  1.2279,  1.3249,
          1.5397,  1.0179,  1.4697,  0.4524,  1.6017,  1.7029],
        [ 1.2267,  1.2580,  1.3199,  1.2990,  1.2674,  1.2335,  1.1982,  1.2247,
          1.2247,  1.2023,  1.3214,  1.2210,  1.3499,  1.2796,  1.4015,  1.2005,
          1.2808,  1.2266,  1.2932,  1.3226,  1.3390,  1.3083,  1.2638,  1.2566,
          1.1963,  1.2498,  1.2498,  1.3019,  1.3436,  1.2625,  1.0732,  1.2555,
          1.1406,  1.3106,  1.1355,  1.2657,  1.3596,  1.0471,  1.3818,  1.3726,
          0.9361,  0.8422,  1.3681,  1.3485,  0.7247,  3.2998,  2.5687,  3.4772,
          2.8508,  2.1623,  1.8491,  2.9717,  3.2170,  1.8281]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 222 : 180.2099244837728
Test loss for epoch 222 : 180.34053958497006
Test Precision for epoch 222 : 0.26153846153846155
Test Recall for epoch 222 : 0.26153846153846155
Test F1 for epoch 222 : 0.26153846153846155


theta for epoch 223 : tensor([[ 2.6223,  2.6526,  2.7266,  2.8477,  2.8110,  2.6286,  2.7862,  2.6205,
          2.6205,  1.2522,  1.2725,  1.2678,  1.2960,  1.2378,  1.3396,  1.2507,
          1.2387,  1.2260,  1.2077,  1.1895,  1.2013,  1.2204,  1.1835,  1.1778,
          1.2005,  1.1720,  1.1720,  1.2174,  1.2593,  1.1910,  1.2133,  1.2614,
          1.2008,  1.2317,  1.1511,  1.1936,  1.3660,  1.4107,  1.3860,  1.3764,
          1.3949,  1.3283,  1.3728,  1.3575,  1.3173,  1.3039,  1.2557,  1.2426,
          1.2241,  1.2959,  1.2442,  1.3349,  1.2153,  1.2226],
        [ 1.2569,  1.1719,  1.0110,  1.2185,  1.3007,  1.3079,  1.2330,  1.2986,
          1.2986,  1.5302,  1.7431,  1.5333,  2.2181,  1.5662,  6.1750,  1.6313,
          1.4658,  6.0209,  1.1049,  1.1893,  0.9979,  1.1528,  1.2817,  1.3155,
          1.2798,  1.3083,  1.3083,  1.2840,  1.0317,  1.3214,  1.3047,  1.1246,
          1.3340,  1.3682,  1.2828,  1.3225,  1.3225,  1.4541,  1.3629,  1.2839,
          1.3142,  1.4203,  1.3453,  0.5091,  1.3213,  1.0366,  1.3815,  1.3599,
          1.3369,  1.0449,  1.3666,  0.8990,  1.3255,  1.3394],
        [ 1.1721,  1.1984,  1.2503,  1.2323,  1.2056,  1.1778,  1.1848,  1.1705,
          1.1705,  1.2621,  1.2823,  1.2777,  1.3057,  1.2476,  1.3146,  1.2605,
          1.2270,  1.2521,  2.6736,  2.7907,  2.8658,  2.7726,  2.5945,  2.6653,
          2.7157,  2.5819,  2.5819,  1.2476,  1.2541,  1.1962,  1.2188,  1.2470,
          1.2062,  1.2379,  1.2006,  1.1988,  1.3622,  1.4081,  1.3823,  1.3459,
          1.3919,  1.3829,  1.3691,  1.3160,  1.2870,  1.2926,  1.2615,  1.2481,
          1.2291,  1.2722,  1.2496,  1.3242,  1.2197,  1.2274],
        [ 1.1779,  1.2048,  1.2556,  1.2373,  1.2123,  1.1837,  1.1911,  1.1762,
          1.1762,  1.2622,  1.2809,  1.2782,  1.3066,  1.2472,  1.2610,  1.2607,
          1.2477,  1.1886,  1.2193,  1.2450,  1.2581,  1.2326,  1.1940,  1.1876,
          1.2110,  1.1820,  1.1820,  2.9171,  2.8673,  2.5097,  2.6694,  2.9127,
          2.5205,  2.8693,  2.5176,  2.5125,  1.3647,  1.4111,  1.3845,  1.3739,
          1.3948,  1.3851,  1.3715,  1.2933,  1.3132,  1.3187,  1.2684,  1.1652,
          1.1929,  1.3104,  1.2547,  1.3506,  1.1835,  1.2348],
        [ 1.7085,  1.3925,  0.6420,  0.8472,  1.2035,  1.6015,  1.5408,  1.7055,
          1.7055,  1.5594,  1.2551,  1.3986,  0.9277,  1.6452,  0.2953,  1.5434,
          1.6785,  1.0832,  1.3196,  0.9019,  0.7781,  1.1046,  1.5645,  1.6081,
          1.3668,  1.7013,  1.7013,  0.7391,  0.8664,  1.6739,  1.4895,  0.8229,
          1.6138,  1.1050,  1.7256,  1.6406,  0.1949, -0.0344, -0.0502,  0.1465,
          0.3942,  0.5353,  0.0938, 13.1341,  7.1676,  0.7859,  1.2168,  1.3138,
          1.5288,  1.0060,  1.4586,  0.4413,  1.5908,  1.6920],
        [ 1.2373,  1.2687,  1.3306,  1.3098,  1.2781,  1.2441,  1.2090,  1.2354,
          1.2354,  1.2180,  1.3372,  1.2367,  1.3658,  1.2953,  1.4171,  1.2162,
          1.2965,  1.2425,  1.2833,  1.3127,  1.3294,  1.2984,  1.2538,  1.2467,
          1.1863,  1.2398,  1.2398,  1.3009,  1.3426,  1.2615,  1.0722,  1.2546,
          1.1397,  1.3097,  1.1345,  1.2647,  1.3599,  1.0479,  1.3821,  1.3729,
          0.9367,  0.8431,  1.3685,  1.3481,  0.7256,  3.2968,  2.5627,  3.4750,
          2.8455,  2.1558,  1.8423,  2.9666,  3.2137,  1.8213]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 223 : 180.24101640918184
Test loss for epoch 223 : 180.38503961057563
Test Precision for epoch 223 : 0.26153846153846155
Test Recall for epoch 223 : 0.26153846153846155
Test F1 for epoch 223 : 0.26153846153846155


theta for epoch 224 : tensor([[ 2.6259,  2.6562,  2.7302,  2.8515,  2.8148,  2.6321,  2.7901,  2.6241,
          2.6241,  1.2354,  1.2557,  1.2511,  1.2794,  1.2209,  1.3233,  1.2339,
          1.2218,  1.2095,  1.2093,  1.1910,  1.2029,  1.2220,  1.1850,  1.1794,
          1.2021,  1.1736,  1.1736,  1.2237,  1.2656,  1.1974,  1.2196,  1.2677,
          1.2072,  1.2380,  1.1574,  1.2000,  1.3676,  1.4123,  1.3877,  1.3781,
          1.3965,  1.3299,  1.3745,  1.3592,  1.3191,  1.3055,  1.2574,  1.2443,
          1.2258,  1.2975,  1.2459,  1.3365,  1.2171,  1.2243],
        [ 1.2654,  1.1810,  1.0214,  1.2279,  1.3097,  1.3163,  1.2418,  1.3071,
          1.3071,  1.5160,  1.7283,  1.5189,  2.2026,  1.5519,  6.1670,  1.6168,
          1.4516,  6.0122,  1.1112,  1.1954,  1.0053,  1.1590,  1.2871,  1.3208,
          1.2852,  1.3136,  1.3136,  1.2949,  1.0445,  1.3318,  1.3154,  1.1361,
          1.3443,  1.3785,  1.2933,  1.3330,  1.3270,  1.4576,  1.3666,  1.2884,
          1.3193,  1.4239,  1.3490,  0.5171,  1.3249,  1.0435,  1.3856,  1.3640,
          1.3410,  1.0513,  1.3707,  0.9069,  1.3296,  1.3435],
        [ 1.1756,  1.2020,  1.2540,  1.2359,  1.2092,  1.1814,  1.1884,  1.1740,
          1.1740,  1.2460,  1.2662,  1.2616,  1.2896,  1.2315,  1.2989,  1.2445,
          1.2107,  1.2368,  2.6780,  2.7955,  2.8700,  2.7762,  2.5995,  2.6695,
          2.7209,  2.5868,  2.5868,  1.2524,  1.2594,  1.2013,  1.2239,  1.2517,
          1.2113,  1.2429,  1.2058,  1.2039,  1.3630,  1.4091,  1.3833,  1.3464,
          1.3927,  1.3839,  1.3701,  1.3174,  1.2876,  1.2924,  1.2608,  1.2474,
          1.2284,  1.2723,  1.2489,  1.3241,  1.2190,  1.2267],
        [ 1.1803,  1.2072,  1.2581,  1.2398,  1.2147,  1.1861,  1.1935,  1.1786,
          1.1786,  1.2436,  1.2627,  1.2598,  1.2884,  1.2287,  1.2429,  1.2421,
          1.2291,  1.1717,  1.2183,  1.2440,  1.2571,  1.2316,  1.1930,  1.1866,
          1.2100,  1.1810,  1.1810,  2.9246,  2.8760,  2.5178,  2.6778,  2.9203,
          2.5285,  2.8769,  2.5256,  2.5205,  1.3639,  1.4104,  1.3838,  1.3732,
          1.3940,  1.3845,  1.3709,  1.2926,  1.3125,  1.3173,  1.2670,  1.1638,
          1.1914,  1.3090,  1.2534,  1.3492,  1.1820,  1.2333],
        [ 1.7131,  1.3968,  0.6451,  0.8509,  1.2076,  1.6060,  1.5452,  1.7100,
          1.7100,  1.5436,  1.2392,  1.3834,  0.9131,  1.6291,  0.2834,  1.5276,
          1.6629,  1.0659,  1.3211,  0.9034,  0.7788,  1.1059,  1.5666,  1.6100,
          1.3689,  1.7036,  1.7036,  0.7443,  0.8705,  1.6799,  1.4954,  0.8281,
          1.6197,  1.1108,  1.7315,  1.6465,  0.1948, -0.0347, -0.0505,  0.1462,
          0.3941,  0.5346,  0.0935, 13.1769,  7.1501,  0.7858,  1.2177,  1.3148,
          1.5297,  1.0059,  1.4595,  0.4408,  1.5919,  1.6929],
        [ 1.2423,  1.2737,  1.3355,  1.3147,  1.2830,  1.2491,  1.2139,  1.2403,
          1.2403,  1.1992,  1.3183,  1.2179,  1.3470,  1.2764,  1.3987,  1.1974,
          1.2775,  1.2238,  1.2837,  1.3131,  1.3298,  1.2989,  1.2542,  1.2471,
          1.1865,  1.2402,  1.2402,  1.3060,  1.3477,  1.2667,  1.0770,  1.2595,
          1.1447,  1.3148,  1.1396,  1.2699,  1.3599,  1.0477,  1.3822,  1.3730,
          0.9363,  0.8427,  1.3686,  1.3481,  0.7250,  3.3029,  2.5662,  3.4821,
          2.8495,  2.1588,  1.8451,  2.9707,  3.2198,  1.8241]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 224 : 180.19859138875643
Test loss for epoch 224 : 180.33506849132453
Test Precision for epoch 224 : 0.26153846153846155
Test Recall for epoch 224 : 0.26153846153846155
Test F1 for epoch 224 : 0.26153846153846155


theta for epoch 225 : tensor([[ 2.6194,  2.6498,  2.7238,  2.8454,  2.8087,  2.6257,  2.7839,  2.6177,
          2.6177,  1.2342,  1.2547,  1.2499,  1.2785,  1.2197,  1.3224,  1.2327,
          1.2206,  1.2087,  1.2195,  1.2011,  1.2130,  1.2322,  1.1952,  1.1896,
          1.2122,  1.1837,  1.1837,  1.2249,  1.2668,  1.1986,  1.2208,  1.2689,
          1.2084,  1.2393,  1.1586,  1.2012,  1.3694,  1.4142,  1.3895,  1.3799,
          1.3982,  1.3319,  1.3763,  1.3611,  1.3212,  1.3146,  1.2666,  1.2535,
          1.2350,  1.3066,  1.2551,  1.3455,  1.2262,  1.2335],
        [ 1.2550,  1.1711,  1.0130,  1.2181,  1.2998,  1.3059,  1.2315,  1.2966,
          1.2966,  1.5142,  1.7257,  1.5169,  2.1992,  1.5499,  6.1702,  1.6148,
          1.4498,  6.0151,  1.1210,  1.2052,  1.0156,  1.1687,  1.2965,  1.3302,
          1.2947,  1.3229,  1.3229,  1.2946,  1.0456,  1.3311,  1.3150,  1.1360,
          1.3436,  1.3778,  1.2926,  1.3324,  1.3272,  1.4571,  1.3660,  1.2883,
          1.3201,  1.4235,  1.3484,  0.5193,  1.3243,  1.0518,  1.3923,  1.3706,
          1.3475,  1.0593,  1.3773,  0.9160,  1.3361,  1.3500],
        [ 1.1625,  1.1889,  1.2408,  1.2227,  1.1961,  1.1682,  1.1752,  1.1609,
          1.1609,  1.2384,  1.2587,  1.2541,  1.2822,  1.2240,  1.2916,  1.2370,
          1.2028,  1.2300,  2.6918,  2.8097,  2.8836,  2.7891,  2.6138,  2.6830,
          2.7354,  2.6012,  2.6012,  1.2454,  1.2529,  1.1947,  1.2173,  1.2448,
          1.2047,  1.2364,  1.1992,  1.1973,  1.3594,  1.4057,  1.3798,  1.3425,
          1.3892,  1.3806,  1.3666,  1.3143,  1.2838,  1.2944,  1.2623,  1.2488,
          1.2298,  1.2745,  1.2503,  1.3261,  1.2203,  1.2281],
        [ 1.1710,  1.1979,  1.2491,  1.2309,  1.2054,  1.1768,  1.1842,  1.1693,
          1.1693,  1.2406,  1.2599,  1.2569,  1.2856,  1.2257,  1.2402,  1.2391,
          1.2261,  1.1693,  1.2270,  1.2524,  1.2657,  1.2403,  1.2017,  1.1954,
          1.2187,  1.1897,  1.1897,  2.9258,  2.8781,  2.5192,  2.6795,  2.9215,
          2.5299,  2.8781,  2.5270,  2.5219,  1.3635,  1.4102,  1.3836,  1.3729,
          1.3937,  1.3843,  1.3706,  1.2922,  1.3123,  1.3227,  1.2723,  1.1689,
          1.1968,  1.3145,  1.2586,  1.3547,  1.1874,  1.2388],
        [ 1.7056,  1.3899,  0.6404,  0.8458,  1.2012,  1.5988,  1.5381,  1.7025,
          1.7025,  1.5419,  1.2375,  1.3819,  0.9118,  1.6271,  0.2833,  1.5257,
          1.6612,  1.0625,  1.3320,  0.9147,  0.7893,  1.1169,  1.5779,  1.6210,
          1.3803,  1.7147,  1.7147,  0.7463,  0.8713,  1.6803,  1.4961,  0.8300,
          1.6202,  1.1122,  1.7319,  1.6468,  0.1911, -0.0385, -0.0542,  0.1423,
          0.3904,  0.5301,  0.0896, 13.2169,  7.1287,  0.7956,  1.2281,  1.3250,
          1.5392,  1.0155,  1.4692,  0.4501,  1.6014,  1.7020],
        [ 1.2312,  1.2626,  1.3244,  1.3036,  1.2720,  1.2380,  1.2028,  1.2293,
          1.2293,  1.1935,  1.3129,  1.2123,  1.3417,  1.2708,  1.3936,  1.1918,
          1.2718,  1.2185,  1.2909,  1.3203,  1.3370,  1.3061,  1.2613,  1.2543,
          1.1934,  1.2473,  1.2473,  1.3031,  1.3449,  1.2637,  1.0736,  1.2566,
          1.1416,  1.3119,  1.1364,  1.2668,  1.3573,  1.0447,  1.3797,  1.3706,
          0.9329,  0.8394,  1.3662,  1.3454,  0.7216,  3.3128,  2.5736,  3.4932,
          2.8574,  2.1658,  1.8520,  2.9785,  3.2299,  1.8309]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 225 : 180.2157683075733
Test loss for epoch 225 : 180.34442318747858
Test Precision for epoch 225 : 0.26153846153846155
Test Recall for epoch 225 : 0.26153846153846155
Test F1 for epoch 225 : 0.26153846153846155


theta for epoch 226 : tensor([[ 2.6241,  2.6544,  2.7285,  2.8504,  2.8137,  2.6304,  2.7889,  2.6223,
          2.6223,  1.2455,  1.2661,  1.2613,  1.2900,  1.2311,  1.3339,  1.2441,
          1.2319,  1.2202,  1.2127,  1.1943,  1.2061,  1.2254,  1.1884,  1.1829,
          1.2054,  1.1769,  1.1769,  1.2185,  1.2605,  1.1922,  1.2145,  1.2625,
          1.2020,  1.2329,  1.1522,  1.1948,  1.3689,  1.4139,  1.3892,  1.3796,
          1.3979,  1.3317,  1.3760,  1.3604,  1.3211,  1.3114,  1.2634,  1.2502,
          1.2318,  1.3034,  1.2518,  1.3423,  1.2230,  1.2302],
        [ 1.2489,  1.1648,  1.0072,  1.2120,  1.2940,  1.2999,  1.2253,  1.2906,
          1.2906,  1.5294,  1.7401,  1.5319,  2.2125,  1.5650,  6.1889,  1.6298,
          1.4650,  6.0339,  1.1125,  1.1967,  1.0082,  1.1603,  1.2878,  1.3215,
          1.2861,  1.3142,  1.3142,  1.2862,  1.0378,  1.3227,  1.3067,  1.1272,
          1.3352,  1.3695,  1.2841,  1.3240,  1.3253,  1.4548,  1.3633,  1.2860,
          1.3188,  1.4213,  1.3456,  0.5167,  1.3218,  1.0466,  1.3863,  1.3645,
          1.3413,  1.0536,  1.3713,  0.9114,  1.3298,  1.3438],
        [ 1.1619,  1.1882,  1.2400,  1.2220,  1.1954,  1.1676,  1.1746,  1.1602,
          1.1602,  1.2526,  1.2729,  1.2682,  1.2963,  1.2382,  1.3052,  1.2512,
          1.2167,  1.2449,  2.6894,  2.8076,  2.8810,  2.7857,  2.6118,  2.6801,
          2.7336,  2.5992,  2.5992,  1.2419,  1.2499,  1.1915,  1.2141,  1.2413,
          1.2015,  1.2332,  1.1960,  1.1941,  1.3620,  1.4085,  1.3825,  1.3447,
          1.3919,  1.3835,  1.3693,  1.3171,  1.2864,  1.2939,  1.2612,  1.2478,
          1.2287,  1.2742,  1.2492,  1.3258,  1.2192,  1.2269],
        [ 1.1712,  1.1981,  1.2492,  1.2311,  1.2056,  1.1770,  1.1844,  1.1695,
          1.1695,  1.2564,  1.2756,  1.2726,  1.3013,  1.2415,  1.2558,  1.2550,
          1.2419,  1.1844,  1.2237,  1.2492,  1.2624,  1.2370,  1.1984,  1.1922,
          1.2154,  1.1865,  1.1865,  2.9230,  2.8762,  2.5166,  2.6773,  2.9187,
          2.5273,  2.8753,  2.5244,  2.5193,  1.3657,  1.4126,  1.3860,  1.3751,
          1.3960,  1.3868,  1.3729,  1.2940,  1.3148,  1.3229,  1.2724,  1.1691,
          1.1969,  1.3146,  1.2587,  1.3549,  1.1874,  1.2387],
        [ 1.7042,  1.3884,  0.6384,  0.8443,  1.1996,  1.5975,  1.5367,  1.7012,
          1.7012,  1.5543,  1.2486,  1.3936,  0.9214,  1.6394,  0.2901,  1.5377,
          1.6741,  1.0712,  1.3264,  0.9095,  0.7832,  1.1113,  1.5729,  1.6159,
          1.3755,  1.7100,  1.7100,  0.7422,  0.8661,  1.6759,  1.4917,  0.8256,
          1.6159,  1.1077,  1.7276,  1.6424,  0.1913, -0.0385, -0.0543,  0.1424,
          0.3907,  0.5298,  0.0895, 13.2603,  7.1109,  0.7904,  1.2240,  1.3210,
          1.5353,  1.0103,  1.4652,  0.4448,  1.5976,  1.6982],
        [ 1.2330,  1.2643,  1.3259,  1.3051,  1.2736,  1.2398,  1.2046,  1.2310,
          1.2310,  1.2113,  1.3307,  1.2302,  1.3597,  1.2885,  1.4114,  1.2096,
          1.2895,  1.2367,  1.2882,  1.3175,  1.3343,  1.3035,  1.2586,  1.2516,
          1.1907,  1.2446,  1.2446,  1.3020,  1.3436,  1.2622,  1.0726,  1.2556,
          1.1405,  1.3106,  1.1352,  1.2654,  1.3603,  1.0490,  1.3827,  1.3736,
          0.9372,  0.8442,  1.3693,  1.3479,  0.7264,  3.3084,  2.5663,  3.4895,
          2.8507,  2.1581,  1.8440,  2.9721,  3.2251,  1.8230]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 226 : 180.17127574947833
Test loss for epoch 226 : 180.31140076484985
Test Precision for epoch 226 : 0.26153846153846155
Test Recall for epoch 226 : 0.26153846153846155
Test F1 for epoch 226 : 0.26153846153846155


theta for epoch 227 : tensor([[ 2.6363,  2.6666,  2.7406,  2.8628,  2.8261,  2.6425,  2.8013,  2.6345,
          2.6345,  1.2418,  1.2625,  1.2576,  1.2865,  1.2273,  1.3306,  1.2404,
          1.2281,  1.2165,  1.2022,  1.1837,  1.1956,  1.2149,  1.1779,  1.1724,
          1.1949,  1.1665,  1.1665,  1.2156,  1.2577,  1.1894,  1.2117,  1.2597,
          1.1992,  1.2302,  1.1492,  1.1920,  1.3652,  1.4103,  1.3855,  1.3758,
          1.3942,  1.3278,  1.3723,  1.3565,  1.3175,  1.3059,  1.2578,  1.2447,
          1.2262,  1.2979,  1.2462,  1.3368,  1.2174,  1.2246],
        [ 1.2553,  1.1715,  1.0146,  1.2188,  1.3008,  1.3063,  1.2318,  1.2970,
          1.2970,  1.5296,  1.7395,  1.5319,  2.2108,  1.5650,  6.1931,  1.6298,
          1.4652,  6.0378,  1.1073,  1.1914,  1.0044,  1.1549,  1.2817,  1.3153,
          1.2801,  1.3080,  1.3080,  1.2895,  1.0426,  1.3256,  1.3099,  1.1308,
          1.3382,  1.3725,  1.2871,  1.3271,  1.3257,  1.4546,  1.3629,  1.2863,
          1.3200,  1.4211,  1.3453,  0.5193,  1.3216,  1.0475,  1.3851,  1.3632,
          1.3399,  1.0540,  1.3700,  0.9133,  1.3284,  1.3424],
        [ 1.1692,  1.1954,  1.2471,  1.2291,  1.2026,  1.1749,  1.1819,  1.1676,
          1.1676,  1.2565,  1.2768,  1.2721,  1.3003,  1.2421,  1.3091,  1.2551,
          1.2203,  1.2496,  2.6836,  2.8022,  2.8750,  2.7790,  2.6065,  2.6739,
          2.7286,  2.5938,  2.5938,  1.2468,  1.2552,  1.1966,  1.2192,  1.2461,
          1.2067,  1.2383,  1.2012,  1.1993,  1.3644,  1.4111,  1.3850,  1.3469,
          1.3944,  1.3861,  1.3718,  1.3200,  1.2887,  1.2953,  1.2620,  1.2485,
          1.2295,  1.2757,  1.2500,  1.3272,  1.2199,  1.2277],
        [ 1.1765,  1.2034,  1.2543,  1.2362,  1.2108,  1.1823,  1.1897,  1.1749,
          1.1749,  1.2583,  1.2775,  1.2744,  1.3032,  1.2434,  1.2578,  1.2568,
          1.2437,  1.1865,  1.2172,  1.2427,  1.2558,  1.2304,  1.1919,  1.1857,
          1.2088,  1.1799,  1.1799,  2.9251,  2.8792,  2.5190,  2.6800,  2.9208,
          2.5297,  2.8774,  2.5268,  2.5217,  1.3655,  1.4125,  1.3858,  1.3749,
          1.3958,  1.3868,  1.3728,  1.2937,  1.3148,  1.3217,  1.2712,  1.1679,
          1.1956,  1.3134,  1.2575,  1.3537,  1.1861,  1.2374],
        [ 1.7093,  1.3930,  0.6411,  0.8478,  1.2040,  1.6025,  1.5416,  1.7063,
          1.7063,  1.5541,  1.2474,  1.3931,  0.9195,  1.6391,  0.2877,  1.5372,
          1.6742,  1.0677,  1.3186,  0.9018,  0.7748,  1.1033,  1.5658,  1.6086,
          1.3685,  1.7031,  1.7031,  0.7425,  0.8655,  1.6772,  1.4928,  0.8260,
          1.6172,  1.1084,  1.7289,  1.6436,  0.1918, -0.0383, -0.0542,  0.1426,
          0.3914,  0.5298,  0.0897, 13.3042,  7.0932,  0.7852,  1.2200,  1.3171,
          1.5317,  1.0051,  1.4615,  0.4391,  1.5942,  1.6948],
        [ 1.2409,  1.2722,  1.3335,  1.3128,  1.2814,  1.2477,  1.2126,  1.2390,
          1.2390,  1.2146,  1.3340,  1.2335,  1.3631,  1.2916,  1.4150,  1.2129,
          1.2926,  1.2403,  1.2828,  1.3120,  1.3291,  1.2981,  1.2531,  1.2462,
          1.1852,  1.2391,  1.2391,  1.3057,  1.3473,  1.2659,  1.0763,  1.2594,
          1.1442,  1.3143,  1.1390,  1.2690,  1.3608,  1.0503,  1.3833,  1.3742,
          0.9385,  0.8458,  1.3700,  1.3482,  0.7280,  3.3070,  2.5621,  3.4889,
          2.8471,  2.1536,  1.8392,  2.9687,  3.2235,  1.8182]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 227 : 180.1852323061703
Test loss for epoch 227 : 180.32904677675438
Test Precision for epoch 227 : 0.26153846153846155
Test Recall for epoch 227 : 0.26153846153846155
Test F1 for epoch 227 : 0.26153846153846155


theta for epoch 228 : tensor([[ 2.6367,  2.6670,  2.7411,  2.8635,  2.8268,  2.6429,  2.8020,  2.6349,
          2.6349,  1.2313,  1.2522,  1.2472,  1.2764,  1.2168,  1.3207,  1.2300,
          1.2176,  1.2065,  1.2069,  1.1884,  1.2003,  1.2197,  1.1826,  1.1772,
          1.1996,  1.1712,  1.1712,  1.2207,  1.2628,  1.1945,  1.2168,  1.2649,
          1.2043,  1.2353,  1.1543,  1.1971,  1.3635,  1.4086,  1.3839,  1.3742,
          1.3924,  1.3262,  1.3708,  1.3550,  1.3159,  1.3107,  1.2627,  1.2495,
          1.2312,  1.3027,  1.2512,  1.3415,  1.2223,  1.2296],
        [ 1.2567,  1.1735,  1.0183,  1.2211,  1.3026,  1.3076,  1.2335,  1.2983,
          1.2983,  1.5186,  1.7277,  1.5207,  2.1981,  1.5538,  6.1868,  1.6185,
          1.4542,  6.0308,  1.1161,  1.2001,  1.0145,  1.1637,  1.2896,  1.3231,
          1.2881,  1.3157,  1.3157,  1.2988,  1.0540,  1.3342,  1.3189,  1.1407,
          1.3468,  1.3811,  1.2958,  1.3358,  1.3266,  1.4544,  1.3630,  1.2871,
          1.3216,  1.4211,  1.3453,  0.5243,  1.3215,  1.0578,  1.3926,  1.3707,
          1.3474,  1.0638,  1.3774,  0.9246,  1.3358,  1.3499],
        [ 1.1657,  1.1919,  1.2436,  1.2256,  1.1991,  1.1714,  1.1784,  1.1641,
          1.1641,  1.2445,  1.2650,  1.2602,  1.2887,  1.2301,  1.2977,  1.2431,
          1.2080,  1.2387,  2.6910,  2.8101,  2.8823,  2.7855,  2.6145,  2.6810,
          2.7368,  2.6018,  2.6018,  1.2492,  1.2581,  1.1994,  1.2220,  1.2486,
          1.2095,  1.2410,  1.2039,  1.2020,  1.3612,  1.4080,  1.3819,  1.3434,
          1.3911,  1.3829,  1.3688,  1.3176,  1.2851,  1.2976,  1.2639,  1.2504,
          1.2314,  1.2783,  1.2519,  1.3295,  1.2218,  1.2296],
        [ 1.1735,  1.2003,  1.2514,  1.2333,  1.2078,  1.1793,  1.1867,  1.1718,
          1.1718,  1.2468,  1.2665,  1.2631,  1.2922,  1.2319,  1.2470,  1.2454,
          1.2322,  1.1763,  1.2206,  1.2460,  1.2592,  1.2339,  1.1953,  1.1892,
          1.2122,  1.1834,  1.1834,  2.9304,  2.8855,  2.5246,  2.6860,  2.9261,
          2.5354,  2.8827,  2.5324,  2.5274,  1.3627,  1.4098,  1.3832,  1.3722,
          1.3930,  1.3841,  1.3701,  1.2911,  1.3120,  1.3239,  1.2734,  1.1701,
          1.1978,  1.3156,  1.2598,  1.3560,  1.1883,  1.2396],
        [ 1.7086,  1.3926,  0.6411,  0.8480,  1.2037,  1.6019,  1.5411,  1.7056,
          1.7056,  1.5443,  1.2376,  1.3838,  0.9107,  1.6290,  0.2813,  1.5273,
          1.6646,  1.0562,  1.3247,  0.9083,  0.7805,  1.1096,  1.5724,  1.6149,
          1.3751,  1.7096,  1.7096,  0.7486,  0.8703,  1.6829,  1.4987,  0.8320,
          1.6229,  1.1146,  1.7345,  1.6492,  0.1884, -0.0420, -0.0578,  0.1390,
          0.3879,  0.5256,  0.0860, 13.3449,  7.0711,  0.7919,  1.2277,  1.3246,
          1.5387,  1.0118,  1.4686,  0.4453,  1.6013,  1.7015],
        [ 1.2367,  1.2679,  1.3292,  1.3085,  1.2771,  1.2434,  1.2082,  1.2347,
          1.2347,  1.2000,  1.3197,  1.2190,  1.3489,  1.2771,  1.4012,  1.1984,
          1.2780,  1.2261,  1.2848,  1.3139,  1.3310,  1.3001,  1.2550,  1.2481,
          1.1868,  1.2410,  1.2410,  1.3072,  1.3489,  1.2673,  1.0771,  1.2607,
          1.1454,  1.3159,  1.1401,  1.2705,  1.3553,  1.0439,  1.3779,  1.3688,
          0.9316,  0.8388,  1.3646,  1.3426,  0.7208,  3.3191,  2.5718,  3.5022,
          2.8572,  2.1628,  1.8483,  2.9788,  3.2358,  1.8272]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 228 : 180.1680626479437
Test loss for epoch 228 : 180.29971737182922
Test Precision for epoch 228 : 0.26153846153846155
Test Recall for epoch 228 : 0.26153846153846155
Test F1 for epoch 228 : 0.26153846153846155


theta for epoch 229 : tensor([[ 2.6300,  2.6603,  2.7344,  2.8571,  2.8204,  2.6362,  2.7956,  2.6282,
          2.6282,  1.2384,  1.2595,  1.2544,  1.2837,  1.2240,  1.3279,  1.2371,
          1.2246,  1.2140,  1.2167,  1.1981,  1.2100,  1.2294,  1.1923,  1.1869,
          1.2093,  1.1809,  1.1809,  1.2214,  1.2633,  1.1951,  1.2173,  1.2654,
          1.2049,  1.2359,  1.1550,  1.1977,  1.3669,  1.4121,  1.3874,  1.3777,
          1.3958,  1.3298,  1.3743,  1.3582,  1.3195,  1.3124,  1.2645,  1.2514,
          1.2330,  1.3045,  1.2530,  1.3431,  1.2242,  1.2315],
        [ 1.2501,  1.1672,  1.0133,  1.2152,  1.2966,  1.3011,  1.2270,  1.2918,
          1.2918,  1.5243,  1.7326,  1.5262,  2.2019,  1.5593,  6.1957,  1.6240,
          1.4600,  6.0396,  1.1214,  1.2055,  1.0206,  1.1689,  1.2945,  1.3280,
          1.2932,  1.3205,  1.3205,  1.2937,  1.0501,  1.3290,  1.3139,  1.1355,
          1.3415,  1.3759,  1.2905,  1.3306,  1.3259,  1.4531,  1.3614,  1.2861,
          1.3216,  1.4198,  1.3437,  0.5247,  1.3201,  1.0554,  1.3886,  1.3667,
          1.3434,  1.0609,  1.3735,  0.9231,  1.3318,  1.3458],
        [ 1.1599,  1.1862,  1.2379,  1.2199,  1.1933,  1.1656,  1.1726,  1.1582,
          1.1582,  1.2451,  1.2657,  1.2609,  1.2894,  1.2307,  1.2984,  1.2438,
          1.2082,  1.2401,  2.6993,  2.8188,  2.8903,  2.7928,  2.6233,  2.6889,
          2.7458,  2.6106,  2.6106,  1.2429,  1.2523,  1.1935,  1.2160,  1.2422,
          1.2035,  1.2350,  1.1980,  1.1961,  1.3606,  1.4075,  1.3815,  1.3424,
          1.3904,  1.3824,  1.3683,  1.3174,  1.2842,  1.2936,  1.2595,  1.2460,
          1.2270,  1.2745,  1.2475,  1.3255,  1.2174,  1.2252],
        [ 1.1694,  1.1964,  1.2476,  1.2296,  1.2038,  1.1753,  1.1826,  1.1678,
          1.1678,  1.2501,  1.2699,  1.2664,  1.2957,  1.2353,  1.2504,  1.2488,
          1.2355,  1.1798,  1.2276,  1.2528,  1.2662,  1.2409,  1.2023,  1.1962,
          1.2191,  1.1904,  1.1904,  2.9305,  2.8865,  2.5250,  2.6866,  2.9263,
          2.5357,  2.8828,  2.5327,  2.5277,  1.3632,  1.4105,  1.3838,  1.3728,
          1.3934,  1.3847,  1.3707,  1.2914,  1.3126,  1.3220,  1.2715,  1.1683,
          1.1959,  1.3137,  1.2580,  1.3540,  1.1863,  1.2377],
        [ 1.7045,  1.3885,  0.6375,  0.8445,  1.1996,  1.5978,  1.5370,  1.7015,
          1.7015,  1.5470,  1.2395,  1.3862,  0.9122,  1.6315,  0.2821,  1.5297,
          1.6676,  1.0558,  1.3315,  0.9151,  0.7862,  1.1162,  1.5799,  1.6223,
          1.3825,  1.7173,  1.7173,  0.7465,  0.8670,  1.6801,  1.4959,  0.8297,
          1.6202,  1.1121,  1.7317,  1.6464,  0.1873, -0.0433, -0.0591,  0.1378,
          0.3869,  0.5238,  0.0846, 13.3876,  7.0508,  0.7890,  1.2259,  1.3227,
          1.5367,  1.0088,  1.4666,  0.4422,  1.5994,  1.6994],
        [ 1.2311,  1.2623,  1.3237,  1.3031,  1.2716,  1.2378,  1.2026,  1.2291,
          1.2291,  1.2015,  1.3216,  1.2207,  1.3508,  1.2788,  1.4031,  1.2000,
          1.2797,  1.2280,  1.2903,  1.3194,  1.3365,  1.3057,  1.2605,  1.2536,
          1.1921,  1.2465,  1.2465,  1.3021,  1.3439,  1.2620,  1.0715,  1.2556,
          1.1401,  1.3107,  1.1347,  1.2652,  1.3541,  1.0425,  1.3768,  1.3678,
          0.9298,  0.8371,  1.3636,  1.3410,  0.7189,  3.3243,  2.5744,  3.5084,
          2.8604,  2.1649,  1.8501,  2.9820,  3.2410,  1.8290]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 229 : 180.1640118581368
Test loss for epoch 229 : 180.2952343659404
Test Precision for epoch 229 : 0.26153846153846155
Test Recall for epoch 229 : 0.26153846153846155
Test F1 for epoch 229 : 0.26153846153846155


theta for epoch 230 : tensor([[ 2.6324,  2.6628,  2.7369,  2.8599,  2.8231,  2.6387,  2.7983,  2.6306,
          2.6306,  1.2489,  1.2700,  1.2649,  1.2943,  1.2345,  1.3385,  1.2477,
          1.2351,  1.2248,  1.2109,  1.1924,  1.2043,  1.2236,  1.1865,  1.1811,
          1.2035,  1.1751,  1.1751,  1.2188,  1.2607,  1.1924,  1.2147,  1.2627,
          1.2022,  1.2332,  1.1524,  1.1951,  1.3698,  1.4152,  1.3905,  1.3807,
          1.3987,  1.3329,  1.3773,  1.3608,  1.3226,  1.3080,  1.2601,  1.2470,
          1.2287,  1.3001,  1.2486,  1.3387,  1.2198,  1.2271],
        [ 1.2505,  1.1676,  1.0142,  1.2158,  1.2975,  1.3016,  1.2274,  1.2923,
          1.2923,  1.5376,  1.7449,  1.5392,  2.2129,  1.5724,  6.2113,  1.6370,
          1.4732,  6.0552,  1.1112,  1.1954,  1.0119,  1.1588,  1.2840,  1.3174,
          1.2827,  1.3099,  1.3099,  1.2864,  1.0436,  1.3217,  1.3067,  1.1278,
          1.3343,  1.3686,  1.2831,  1.3234,  1.3258,  1.4525,  1.3605,  1.2856,
          1.3222,  1.4193,  1.3428,  0.5241,  1.3194,  1.0476,  1.3795,  1.3575,
          1.3341,  1.0523,  1.3643,  0.9160,  1.3225,  1.3366],
        [ 1.1662,  1.1925,  1.2443,  1.2263,  1.1997,  1.1719,  1.1789,  1.1646,
          1.1646,  1.2568,  1.2775,  1.2726,  1.3012,  1.2425,  1.3099,  1.2555,
          1.2196,  1.2527,  2.6927,  2.8126,  2.8836,  2.7852,  2.6172,  2.6819,
          2.7400,  2.6045,  2.6045,  1.2425,  1.2524,  1.1935,  1.2160,  1.2418,
          1.2035,  1.2350,  1.1980,  1.1961,  1.3664,  1.4133,  1.3873,  1.3478,
          1.3961,  1.3883,  1.3741,  1.3233,  1.2897,  1.2917,  1.2571,  1.2436,
          1.2246,  1.2729,  1.2451,  1.3236,  1.2150,  1.2229],
        [ 1.1734,  1.2004,  1.2517,  1.2336,  1.2079,  1.1793,  1.1866,  1.1718,
          1.1718,  1.2600,  1.2798,  1.2762,  1.3055,  1.2452,  1.2601,  1.2587,
          1.2454,  1.1893,  1.2209,  1.2463,  1.2595,  1.2342,  1.1957,  1.1896,
          1.2125,  1.1838,  1.1838,  2.9308,  2.8876,  2.5254,  2.6874,  2.9265,
          2.5361,  2.8831,  2.5332,  2.5282,  1.3655,  1.4131,  1.3864,  1.3752,
          1.3958,  1.3873,  1.3732,  1.2932,  1.3151,  1.3175,  1.2671,  1.1641,
          1.1914,  1.3092,  1.2538,  1.3496,  1.1818,  1.2331],
        [ 1.7074,  1.3908,  0.6382,  0.8460,  1.2017,  1.6006,  1.5396,  1.7043,
          1.7043,  1.5550,  1.2462,  1.3936,  0.9173,  1.6393,  0.2848,  1.5372,
          1.6761,  1.0597,  1.3232,  0.9070,  0.7771,  1.1078,  1.5723,  1.6146,
          1.3751,  1.7100,  1.7100,  0.7424,  0.8618,  1.6764,  1.4921,  0.8254,
          1.6165,  1.1080,  1.7282,  1.6427,  0.1891, -0.0418, -0.0576,  0.1394,
          0.3889,  0.5251,  0.0861, 13.4327,  7.0330,  0.7793,  1.2177,  1.3147,
          1.5290,  0.9992,  1.4587,  0.4323,  1.5918,  1.6919],
        [ 1.2364,  1.2677,  1.3292,  1.3085,  1.2770,  1.2432,  1.2079,  1.2344,
          1.2344,  1.2128,  1.3330,  1.2320,  1.3623,  1.2901,  1.4144,  1.2113,
          1.2909,  1.2396,  1.2842,  1.3132,  1.3305,  1.2996,  1.2543,  1.2475,
          1.1859,  1.2403,  1.2403,  1.2996,  1.3413,  1.2594,  1.0689,  1.2531,
          1.1376,  1.3081,  1.1322,  1.2626,  1.3574,  1.0464,  1.3802,  1.3712,
          0.9335,  0.8412,  1.3671,  1.3437,  0.7228,  3.3227,  2.5700,  3.5076,
          2.8566,  2.1601,  1.8451,  2.9784,  3.2392,  1.8239]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 230 : 180.1614900052382
Test loss for epoch 230 : 180.303177052276
Test Precision for epoch 230 : 0.26153846153846155
Test Recall for epoch 230 : 0.26153846153846155
Test F1 for epoch 230 : 0.26153846153846155


theta for epoch 231 : tensor([[ 2.6400,  2.6704,  2.7445,  2.8677,  2.8310,  2.6463,  2.8062,  2.6382,
          2.6382,  1.2380,  1.2593,  1.2540,  1.2836,  1.2236,  1.3279,  1.2368,
          1.2242,  1.2142,  1.2067,  1.1882,  1.2001,  1.2195,  1.1823,  1.1769,
          1.1993,  1.1709,  1.1709,  1.2193,  1.2613,  1.1931,  1.2153,  1.2634,
          1.2029,  1.2339,  1.1530,  1.1957,  1.3681,  1.4136,  1.3889,  1.3791,
          1.3970,  1.3313,  1.3757,  1.3590,  1.3211,  1.3088,  1.2609,  1.2478,
          1.2294,  1.3009,  1.2494,  1.3395,  1.2205,  1.2279],
        [ 1.2584,  1.1758,  1.0235,  1.2243,  1.3058,  1.3094,  1.2354,  1.3001,
          1.3001,  1.5322,  1.7386,  1.5336,  2.2055,  1.5668,  6.2092,  1.6313,
          1.4678,  6.0526,  1.1105,  1.1946,  1.0128,  1.1580,  1.2822,  1.3155,
          1.2812,  1.3079,  1.3079,  1.2911,  1.0501,  1.3259,  1.3112,  1.1328,
          1.3385,  1.3728,  1.2873,  1.3276,  1.3268,  1.4527,  1.3607,  1.2865,
          1.3241,  1.4197,  1.3429,  0.5282,  1.3197,  1.0538,  1.3832,  1.3612,
          1.3378,  1.0580,  1.3680,  0.9232,  1.3261,  1.3403],
        [ 1.1725,  1.1988,  1.2506,  1.2326,  1.2060,  1.1782,  1.1853,  1.1709,
          1.1709,  1.2490,  1.2698,  1.2648,  1.2937,  1.2347,  1.3025,  1.2477,
          1.2115,  1.2460,  2.6916,  2.8119,  2.8823,  2.7831,  2.6166,  2.6803,
          2.7397,  2.6039,  2.6039,  1.2462,  1.2565,  1.1976,  1.2200,  1.2456,
          1.2076,  1.2389,  1.2021,  1.2002,  1.3675,  1.4146,  1.3885,  1.3487,
          1.3972,  1.3896,  1.3754,  1.3251,  1.2906,  1.2956,  1.2606,  1.2471,
          1.2281,  1.2770,  1.2486,  1.3275,  1.2185,  1.2264],
        [ 1.1779,  1.2048,  1.2561,  1.2380,  1.2124,  1.1837,  1.1911,  1.1762,
          1.1762,  1.2501,  1.2702,  1.2665,  1.2959,  1.2353,  1.2506,  1.2488,
          1.2355,  1.1806,  1.2171,  1.2424,  1.2556,  1.2304,  1.1918,  1.1858,
          1.2086,  1.1799,  1.1799,  2.9353,  2.8930,  2.5302,  2.6925,  2.9310,
          2.5409,  2.8876,  2.5379,  2.5329,  1.3644,  1.4121,  1.3854,  1.3742,
          1.3948,  1.3864,  1.3722,  1.2921,  1.3142,  1.3185,  1.2680,  1.1649,
          1.1923,  1.3102,  1.2547,  1.3506,  1.1826,  1.2340],
        [ 1.7139,  1.3971,  0.6435,  0.8519,  1.2080,  1.6071,  1.5460,  1.7108,
          1.7108,  1.5469,  1.2380,  1.3858,  0.9098,  1.6309,  0.2789,  1.5289,
          1.6681,  1.0495,  1.3214,  0.9059,  0.7752,  1.1062,  1.5709,  1.6129,
          1.3740,  1.7087,  1.7087,  0.7465,  0.8645,  1.6801,  1.4959,  0.8294,
          1.6203,  1.1123,  1.7318,  1.6464,  0.1867, -0.0444, -0.0601,  0.1368,
          0.3865,  0.5220,  0.0835, 13.4746,  7.0106,  0.7831,  1.2225,  1.3193,
          1.5332,  1.0029,  1.4631,  0.4356,  1.5961,  1.6959],
        [ 1.2417,  1.2730,  1.3345,  1.3138,  1.2823,  1.2485,  1.2132,  1.2398,
          1.2398,  1.2021,  1.3224,  1.2213,  1.3519,  1.2794,  1.4042,  1.2006,
          1.2802,  1.2293,  1.2805,  1.3094,  1.3269,  1.2959,  1.2506,  1.2438,
          1.1819,  1.2365,  1.2365,  1.3009,  1.3427,  1.2607,  1.0699,  1.2544,
          1.1388,  1.3095,  1.1334,  1.2639,  1.3556,  1.0444,  1.3784,  1.3695,
          0.9311,  0.8389,  1.3654,  1.3417,  0.7204,  3.3297,  2.5744,  3.5156,
          2.8615,  2.1641,  1.8488,  2.9833,  3.2462,  1.8277]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 231 : 180.14472513965796
Test loss for epoch 231 : 180.28156214929163
Test Precision for epoch 231 : 0.26153846153846155
Test Recall for epoch 231 : 0.26153846153846155
Test F1 for epoch 231 : 0.26153846153846155


theta for epoch 232 : tensor([[ 2.6386,  2.6690,  2.7431,  2.8667,  2.8300,  2.6449,  2.8051,  2.6368,
          2.6368,  1.2345,  1.2559,  1.2505,  1.2803,  1.2201,  1.3245,  1.2333,
          1.2206,  1.2110,  1.2124,  1.1938,  1.2058,  1.2252,  1.1880,  1.1827,
          1.2050,  1.1766,  1.1766,  1.2217,  1.2637,  1.1955,  1.2177,  1.2657,
          1.2053,  1.2363,  1.1554,  1.1981,  1.3668,  1.4124,  1.3877,  1.3778,
          1.3957,  1.3301,  1.3745,  1.3575,  1.3200,  1.3133,  1.2654,  1.2522,
          1.2339,  1.3054,  1.2538,  1.3440,  1.2249,  1.2323],
        [ 1.2530,  1.1710,  1.0202,  1.2196,  1.3008,  1.3040,  1.2302,  1.2946,
          1.2946,  1.5299,  1.7353,  1.5310,  2.2009,  1.5642,  6.2096,  1.6287,
          1.4655,  6.0525,  1.1176,  1.2017,  1.0211,  1.1649,  1.2885,  1.3217,
          1.2876,  1.3141,  1.3141,  1.2946,  1.0554,  1.3288,  1.3144,  1.1365,
          1.3414,  1.3758,  1.2902,  1.3306,  1.3261,  1.4512,  1.3590,  1.2856,
          1.3243,  1.4183,  1.3413,  0.5306,  1.3183,  1.0611,  1.3881,  1.3660,
          1.3425,  1.0647,  1.3728,  0.9315,  1.3308,  1.3449],
        [ 1.1643,  1.1906,  1.2422,  1.2243,  1.1977,  1.1700,  1.1770,  1.1627,
          1.1627,  1.2418,  1.2627,  1.2576,  1.2867,  1.2274,  1.2957,  1.2405,
          1.2038,  1.2398,  2.7013,  2.8220,  2.8918,  2.7918,  2.6268,  2.6896,
          2.7502,  2.6142,  2.6142,  1.2447,  1.2555,  1.1964,  1.2189,  1.2440,
          1.2064,  1.2378,  1.2010,  1.1991,  1.3638,  1.4111,  1.3850,  1.3447,
          1.3935,  1.3860,  1.3718,  1.3221,  1.2866,  1.2973,  1.2618,  1.2482,
          1.2293,  1.2789,  1.2498,  1.3292,  1.2196,  1.2275],
        [ 1.1717,  1.1986,  1.2499,  1.2319,  1.2061,  1.1775,  1.1849,  1.1700,
          1.1700,  1.2458,  1.2661,  1.2622,  1.2919,  1.2310,  1.2466,  1.2445,
          1.2311,  1.1771,  1.2226,  1.2478,  1.2611,  1.2359,  1.1974,  1.1914,
          1.2141,  1.1855,  1.1855,  2.9382,  2.8968,  2.5333,  2.6959,  2.9339,
          2.5441,  2.8905,  2.5410,  2.5361,  1.3627,  1.4106,  1.3839,  1.3726,
          1.3931,  1.3849,  1.3706,  1.2904,  1.3126,  1.3216,  1.2710,  1.1678,
          1.1952,  1.3133,  1.2576,  1.3537,  1.1855,  1.2369],
        [ 1.7097,  1.3933,  0.6409,  0.8493,  1.2046,  1.6032,  1.5421,  1.7067,
          1.7067,  1.5438,  1.2347,  1.3829,  0.9069,  1.6274,  0.2769,  1.5255,
          1.6651,  1.0441,  1.3287,  0.9138,  0.7822,  1.1138,  1.5789,  1.6206,
          1.3820,  1.7165,  1.7165,  0.7509,  0.8674,  1.6836,  1.4996,  0.8336,
          1.6238,  1.1165,  1.7352,  1.6498,  0.1829, -0.0483, -0.0641,  0.1329,
          0.3828,  0.5174,  0.0794, 13.5156,  6.9864,  0.7893,  1.2296,  1.3263,
          1.5397,  1.0090,  1.4697,  0.4415,  1.6027,  1.7021],
        [ 1.2350,  1.2663,  1.3278,  1.3071,  1.2756,  1.2418,  1.2065,  1.2331,
          1.2331,  1.1971,  1.3176,  1.2164,  1.3471,  1.2743,  1.3996,  1.1956,
          1.2750,  1.2247,  1.2862,  1.3150,  1.3325,  1.3016,  1.2562,  1.2495,
          1.1874,  1.2422,  1.2422,  1.3022,  1.3441,  1.2619,  1.0709,  1.2557,
          1.1400,  1.3108,  1.1345,  1.2651,  1.3525,  1.0414,  1.3755,  1.3665,
          0.9278,  0.8358,  1.3625,  1.3385,  0.7171,  3.3359,  2.5782,  3.5228,
          2.8657,  2.1674,  1.8520,  2.9876,  3.2525,  1.8309]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 232 : 180.1417104933355
Test loss for epoch 232 : 180.2723684558248
Test Precision for epoch 232 : 0.26153846153846155
Test Recall for epoch 232 : 0.26153846153846155
Test F1 for epoch 232 : 0.26153846153846155


theta for epoch 233 : tensor([[ 2.6391,  2.6695,  2.7436,  2.8675,  2.8307,  2.6453,  2.8059,  2.6373,
          2.6373,  1.2427,  1.2641,  1.2587,  1.2886,  1.2283,  1.3327,  1.2415,
          1.2288,  1.2194,  1.2134,  1.1947,  1.2067,  1.2262,  1.1891,  1.1838,
          1.2060,  1.1776,  1.1776,  1.2189,  1.2608,  1.1926,  1.2149,  1.2628,
          1.2024,  1.2334,  1.1526,  1.1953,  1.3675,  1.4133,  1.3885,  1.3786,
          1.3964,  1.3311,  1.3754,  1.3578,  1.3209,  1.3104,  1.2624,  1.2492,
          1.2309,  1.3025,  1.2509,  1.3412,  1.2219,  1.2293],
        [ 1.2466,  1.1648,  1.0150,  1.2135,  1.2947,  1.2975,  1.2238,  1.2882,
          1.2882,  1.5391,  1.7434,  1.5400,  2.2076,  1.5732,  6.2202,  1.6376,
          1.4747,  6.0630,  1.1173,  1.2014,  1.0222,  1.1645,  1.2877,  1.3208,
          1.2869,  1.3131,  1.3131,  1.2900,  1.0522,  1.3239,  1.3098,  1.1319,
          1.3366,  1.3710,  1.2853,  1.3258,  1.3258,  1.4503,  1.3578,  1.2850,
          1.3250,  1.4175,  1.3401,  0.5316,  1.3175,  1.0582,  1.3831,  1.3610,
          1.3375,  1.0610,  1.3678,  0.9297,  1.3257,  1.3399],
        [ 1.1596,  1.1858,  1.2373,  1.2194,  1.1929,  1.1653,  1.1723,  1.1580,
          1.1580,  1.2481,  1.2692,  1.2641,  1.2933,  1.2338,  1.3021,  1.2469,
          1.2098,  1.2472,  2.7052,  2.8262,  2.8954,  2.7946,  2.6312,  2.6930,
          2.7549,  2.6185,  2.6185,  1.2409,  1.2522,  1.1930,  1.2155,  1.2402,
          1.2031,  1.2343,  1.1976,  1.1957,  1.3647,  1.4121,  1.3860,  1.3452,
          1.3943,  1.3870,  1.3728,  1.3233,  1.2872,  1.2944,  1.2584,  1.2448,
          1.2259,  1.2762,  1.2464,  1.3264,  1.2162,  1.2241],
        [ 1.1689,  1.1958,  1.2471,  1.2292,  1.2033,  1.1748,  1.1821,  1.1673,
          1.1673,  1.2553,  1.2757,  1.2717,  1.3015,  1.2405,  1.2562,  1.2541,
          1.2406,  1.1865,  1.2255,  1.2506,  1.2639,  1.2388,  1.2003,  1.1944,
          1.2170,  1.1884,  1.1884,  2.9367,  2.8960,  2.5320,  2.6949,  2.9325,
          2.5427,  2.8890,  2.5397,  2.5347,  1.3646,  1.4127,  1.3859,  1.3745,
          1.3950,  1.3871,  1.3726,  1.2919,  1.3147,  1.3205,  1.2699,  1.1667,
          1.1940,  1.3122,  1.2565,  1.3527,  1.1843,  1.2356],
        [ 1.7053,  1.3886,  0.6356,  0.8446,  1.1998,  1.5988,  1.5376,  1.7023,
          1.7023,  1.5500,  1.2396,  1.3885,  0.9104,  1.6334,  0.2781,  1.5313,
          1.6717,  1.0462,  1.3285,  0.9134,  0.7805,  1.1134,  1.5797,  1.6214,
          1.3827,  1.7177,  1.7177,  0.7471,  0.8625,  1.6804,  1.4963,  0.8297,
          1.6207,  1.1128,  1.7322,  1.6466,  0.1842, -0.0473, -0.0632,  0.1340,
          0.3844,  0.5182,  0.0803, 13.5610,  6.9671,  0.7817,  1.2238,  1.3206,
          1.5344,  1.0016,  1.4642,  0.4333,  1.5975,  1.6970],
        [ 1.2331,  1.2644,  1.3258,  1.3051,  1.2737,  1.2399,  1.2047,  1.2312,
          1.2312,  1.2085,  1.3290,  1.2278,  1.3588,  1.2856,  1.4111,  1.2071,
          1.2862,  1.2366,  1.2903,  1.3189,  1.3365,  1.3058,  1.2604,  1.2536,
          1.1915,  1.2463,  1.2463,  1.3024,  1.3441,  1.2618,  1.0712,  1.2560,
          1.1402,  1.3108,  1.1348,  1.2650,  1.3554,  1.0455,  1.3785,  1.3695,
          0.9318,  0.8403,  1.3656,  1.3409,  0.7216,  3.3316,  2.5710,  3.5191,
          2.8591,  2.1599,  1.8442,  2.9812,  3.2478,  1.8231]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 233 : 180.12924144376416
Test loss for epoch 233 : 180.26726961239052
Test Precision for epoch 233 : 0.26153846153846155
Test Recall for epoch 233 : 0.26153846153846155
Test F1 for epoch 233 : 0.26153846153846155


theta for epoch 234 : tensor([[ 2.6464,  2.6768,  2.7509,  2.8750,  2.8383,  2.6526,  2.8135,  2.6446,
          2.6446,  1.2444,  1.2659,  1.2604,  1.2904,  1.2300,  1.3345,  1.2432,
          1.2305,  1.2213,  1.2049,  1.1862,  1.1981,  1.2177,  1.1805,  1.1753,
          1.1974,  1.1691,  1.1691,  1.2159,  1.2580,  1.1898,  1.2120,  1.2600,
          1.1996,  1.2306,  1.1496,  1.1924,  1.3661,  1.4121,  1.3873,  1.3773,
          1.3950,  1.3297,  1.3741,  1.3561,  1.3196,  1.3084,  1.2603,  1.2471,
          1.2287,  1.3005,  1.2487,  1.3392,  1.2197,  1.2271],
        [ 1.2498,  1.1683,  1.0195,  1.2172,  1.2984,  1.3008,  1.2272,  1.2915,
          1.2915,  1.5434,  1.7466,  1.5439,  2.2092,  1.5772,  6.2258,  1.6414,
          1.4790,  6.0682,  1.1106,  1.1947,  1.0174,  1.1577,  1.2800,  1.3129,
          1.2793,  1.3051,  1.3051,  1.2895,  1.0533,  1.3229,  1.3091,  1.1315,
          1.3355,  1.3700,  1.2842,  1.3249,  1.3263,  1.4500,  1.3574,  1.2853,
          1.3264,  1.4174,  1.3397,  0.5345,  1.3173,  1.0602,  1.3828,  1.3607,
          1.3371,  1.0624,  1.3675,  0.9328,  1.3253,  1.3394],
        [ 1.1647,  1.1909,  1.2422,  1.2244,  1.1980,  1.1704,  1.1774,  1.1631,
          1.1631,  1.2536,  1.2748,  1.2695,  1.2990,  1.2392,  1.3077,  1.2524,
          1.2149,  1.2537,  2.6996,  2.8211,  2.8897,  2.7880,  2.6262,  2.6870,
          2.7502,  2.6135,  2.6135,  1.2431,  1.2550,  1.1956,  1.2180,  1.2425,
          1.2056,  1.2368,  1.2002,  1.1982,  1.3677,  1.4151,  1.3891,  1.3479,
          1.3972,  1.3901,  1.3759,  1.3268,  1.2899,  1.2978,  1.2613,  1.2478,
          1.2289,  1.2798,  1.2494,  1.3297,  1.2191,  1.2271],
        [ 1.1725,  1.1993,  1.2505,  1.2326,  1.2068,  1.1783,  1.1857,  1.1709,
          1.1709,  1.2597,  1.2802,  1.2761,  1.3060,  1.2449,  1.2607,  1.2585,
          1.2449,  1.1911,  1.2193,  1.2444,  1.2576,  1.2326,  1.1941,  1.1882,
          1.2107,  1.1822,  1.1822,  2.9374,  2.8975,  2.5328,  2.6960,  2.9332,
          2.5436,  2.8897,  2.5405,  2.5356,  1.3654,  1.4137,  1.3869,  1.3754,
          1.3958,  1.3881,  1.3736,  1.2925,  1.3157,  1.3211,  1.2704,  1.1673,
          1.1946,  1.3128,  1.2571,  1.3534,  1.1848,  1.2362],
        [ 1.7085,  1.3912,  0.6368,  0.8467,  1.2024,  1.6019,  1.5406,  1.7054,
          1.7054,  1.5525,  1.2412,  1.3907,  0.9111,  1.6357,  0.2774,  1.5334,
          1.6747,  1.0450,  1.3207,  0.9060,  0.7720,  1.1055,  1.5725,  1.6141,
          1.3758,  1.7108,  1.7108,  0.7461,  0.8603,  1.6800,  1.4957,  0.8286,
          1.6202,  1.1120,  1.7317,  1.6460,  0.1844, -0.0474, -0.0633,  0.1340,
          0.3848,  0.5178,  0.0802, 13.6056,  6.9462,  0.7793,  1.2233,  1.3202,
          1.5341,  0.9995,  1.4639,  0.4302,  1.5974,  1.6968],
        [ 1.2365,  1.2678,  1.3292,  1.3085,  1.2771,  1.2433,  1.2081,  1.2346,
          1.2346,  1.2125,  1.3333,  1.2319,  1.3632,  1.2896,  1.4155,  1.2111,
          1.2902,  1.2411,  1.2836,  1.3122,  1.3299,  1.2991,  1.2537,  1.2470,
          1.1847,  1.2396,  1.2396,  1.3021,  1.3438,  1.2614,  1.0707,  1.2557,
          1.1398,  1.3104,  1.1343,  1.2646,  1.3556,  1.0460,  1.3788,  1.3699,
          0.9321,  0.8408,  1.3660,  1.3407,  0.7220,  3.3346,  2.5714,  3.5230,
          2.8600,  2.1599,  1.8441,  2.9823,  3.2507,  1.8229]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 234 : 180.12696461393944
Test loss for epoch 234 : 180.2676760447697
Test Precision for epoch 234 : 0.26153846153846155
Test Recall for epoch 234 : 0.26153846153846155
Test F1 for epoch 234 : 0.26153846153846155


theta for epoch 235 : tensor([[ 2.6499,  2.6803,  2.7544,  2.8788,  2.8421,  2.6561,  2.8173,  2.6481,
          2.6481,  1.2361,  1.2578,  1.2522,  1.2824,  1.2218,  1.3265,  1.2350,
          1.2222,  1.2135,  1.2049,  1.1861,  1.1981,  1.2177,  1.1805,  1.1753,
          1.1974,  1.1691,  1.1691,  1.2183,  1.2604,  1.1923,  1.2145,  1.2624,
          1.2021,  1.2330,  1.1521,  1.1949,  1.3646,  1.4108,  1.3860,  1.3759,
          1.3935,  1.3283,  1.3728,  1.3545,  1.3182,  1.3108,  1.2627,  1.2495,
          1.2311,  1.3029,  1.2512,  1.3417,  1.2221,  1.2295],
        [ 1.2549,  1.1739,  1.0267,  1.2232,  1.3039,  1.3058,  1.2325,  1.2965,
          1.2965,  1.5373,  1.7394,  1.5375,  2.2006,  1.5708,  6.2214,  1.6350,
          1.4729,  6.0632,  1.1136,  1.1976,  1.0222,  1.1605,  1.2817,  1.3144,
          1.2813,  1.3066,  1.3066,  1.2950,  1.0611,  1.3277,  1.3143,  1.1375,
          1.3403,  1.3749,  1.2891,  1.3298,  1.3271,  1.4498,  1.3573,  1.2860,
          1.3281,  1.4172,  1.3395,  0.5395,  1.3171,  1.0681,  1.3876,  1.3655,
          1.3419,  1.0697,  1.3723,  0.9419,  1.3301,  1.3442],
        [ 1.1668,  1.1929,  1.2443,  1.2265,  1.2000,  1.1725,  1.1794,  1.1652,
          1.1652,  1.2451,  1.2665,  1.2611,  1.2909,  1.2307,  1.2998,  1.2439,
          1.2060,  1.2464,  2.7022,  2.8240,  2.8921,  2.7896,  2.6293,  2.6891,
          2.7536,  2.6166,  2.6166,  1.2454,  1.2578,  1.1983,  1.2207,  1.2448,
          1.2083,  1.2394,  1.2029,  1.2009,  1.3665,  1.4140,  1.3881,  1.3465,
          1.3959,  1.3889,  1.3749,  1.3265,  1.2884,  1.3009,  1.2641,  1.2505,
          1.2317,  1.2832,  1.2522,  1.3328,  1.2219,  1.2300],
        [ 1.1740,  1.2008,  1.2520,  1.2341,  1.2083,  1.1798,  1.1872,  1.1723,
          1.1723,  1.2506,  1.2715,  1.2671,  1.2973,  1.2358,  1.2521,  1.2494,
          1.2357,  1.1832,  1.2186,  1.2436,  1.2569,  1.2319,  1.1933,  1.1876,
          1.2099,  1.1815,  1.1815,  2.9417,  2.9027,  2.5374,  2.7009,  2.9375,
          2.5481,  2.8940,  2.5451,  2.5401,  1.3637,  1.4121,  1.3853,  1.3737,
          1.3940,  1.3864,  1.3720,  1.2908,  1.3140,  1.3225,  1.2718,  1.1686,
          1.1960,  1.3142,  1.2585,  1.3548,  1.1862,  1.2376],
        [ 1.7123,  1.3951,  0.6404,  0.8507,  1.2063,  1.6058,  1.5444,  1.7092,
          1.7092,  1.5457,  1.2344,  1.3842,  0.9048,  1.6283,  0.2726,  1.5263,
          1.6679,  1.0361,  1.3222,  0.9083,  0.7734,  1.1074,  1.5745,  1.6159,
          1.3781,  1.7128,  1.7128,  0.7512,  0.8638,  1.6843,  1.5002,  0.8335,
          1.6247,  1.1171,  1.7361,  1.6504,  0.1809, -0.0512, -0.0670,  0.1303,
          0.3812,  0.5133,  0.0764, 13.6472,  6.9209,  0.7849,  1.2300,  1.3267,
          1.5401,  1.0050,  1.4701,  0.4352,  1.6035,  1.7025],
        [ 1.2365,  1.2678,  1.3292,  1.3086,  1.2771,  1.2432,  1.2079,  1.2345,
          1.2345,  1.2008,  1.3220,  1.2203,  1.3519,  1.2781,  1.4045,  1.1995,
          1.2786,  1.2300,  1.2817,  1.3100,  1.3280,  1.2971,  1.2517,  1.2450,
          1.1824,  1.2376,  1.2376,  1.3018,  1.3437,  1.2612,  1.0699,  1.2554,
          1.1393,  1.3103,  1.1339,  1.2644,  1.3514,  1.0410,  1.3746,  1.3658,
          0.9265,  0.8352,  1.3620,  1.3363,  0.7161,  3.3455,  2.5799,  3.5350,
          2.8690,  2.1680,  1.8519,  2.9911,  3.2618,  1.8307]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 235 : 180.12182118985774
Test loss for epoch 235 : 180.25388078665765
Test Precision for epoch 235 : 0.26153846153846155
Test Recall for epoch 235 : 0.26153846153846155
Test F1 for epoch 235 : 0.26153846153846155


theta for epoch 236 : tensor([[ 2.6451,  2.6756,  2.7498,  2.8744,  2.8377,  2.6514,  2.8128,  2.6433,
          2.6433,  1.2401,  1.2619,  1.2562,  1.2865,  1.2258,  1.3304,  1.2391,
          1.2261,  1.2179,  1.2135,  1.1947,  1.2067,  1.2263,  1.1891,  1.1839,
          1.2059,  1.1777,  1.1777,  1.2211,  1.2631,  1.1950,  1.2172,  1.2651,
          1.2048,  1.2358,  1.1550,  1.1976,  1.3676,  1.4139,  1.3891,  1.3789,
          1.3965,  1.3316,  1.3759,  1.3570,  1.3214,  1.3094,  1.2614,  1.2481,
          1.2298,  1.3016,  1.2498,  1.3403,  1.2207,  1.2282],
        [ 1.2510,  1.1705,  1.0247,  1.2200,  1.3006,  1.3019,  1.2287,  1.2926,
          1.2926,  1.5413,  1.7422,  1.5412,  2.2017,  1.5745,  6.2260,  1.6385,
          1.4768,  6.0675,  1.1192,  1.2033,  1.0292,  1.1659,  1.2865,  1.3192,
          1.2863,  1.3113,  1.3113,  1.2936,  1.0615,  1.3259,  1.3128,  1.1362,
          1.3385,  1.3731,  1.2872,  1.3280,  1.3274,  1.4493,  1.3566,  1.2861,
          1.3294,  1.4169,  1.3388,  0.5424,  1.3166,  1.0655,  1.3823,  1.3601,
          1.3366,  1.0663,  1.3669,  0.9406,  1.3247,  1.3389],
        [ 1.1622,  1.1883,  1.2397,  1.2219,  1.1955,  1.1679,  1.1749,  1.1606,
          1.1606,  1.2427,  1.2644,  1.2588,  1.2888,  1.2283,  1.2978,  1.2416,
          1.2033,  1.2452,  2.7107,  2.8329,  2.9003,  2.7970,  2.6383,  2.6971,
          2.7630,  2.6256,  2.6256,  1.2420,  1.2550,  1.1954,  1.2177,  1.2414,
          1.2053,  1.2364,  1.1999,  1.1980,  1.3657,  1.4132,  1.3874,  1.3452,
          1.3950,  1.3882,  1.3742,  1.3261,  1.2871,  1.2952,  1.2579,  1.2444,
          1.2256,  1.2777,  1.2461,  1.3270,  1.2158,  1.2239],
        [ 1.1708,  1.1976,  1.2490,  1.2311,  1.2051,  1.1766,  1.1840,  1.1692,
          1.1692,  1.2504,  1.2715,  1.2670,  1.2974,  1.2357,  1.2521,  1.2493,
          1.2355,  1.1836,  1.2245,  1.2493,  1.2627,  1.2378,  1.1992,  1.1935,
          1.2158,  1.1874,  1.1874,  2.9440,  2.9057,  2.5398,  2.7036,  2.9398,
          2.5505,  2.8963,  2.5475,  2.5425,  1.3640,  1.4125,  1.3858,  1.3741,
          1.3943,  1.3869,  1.3725,  1.2909,  1.3144,  1.3184,  1.2677,  1.1647,
          1.1918,  1.3101,  1.2546,  1.3506,  1.1819,  1.2334],
        [ 1.7098,  1.3925,  0.6378,  0.8485,  1.2039,  1.6034,  1.5420,  1.7068,
          1.7068,  1.5462,  1.2344,  1.3846,  0.9042,  1.6285,  0.2713,  1.5264,
          1.6687,  1.0333,  1.3281,  0.9144,  0.7782,  1.1134,  1.5814,  1.6226,
          1.3849,  1.7198,  1.7198,  0.7515,  0.8627,  1.6846,  1.5004,  0.8337,
          1.6250,  1.1175,  1.7363,  1.6506,  0.1799, -0.0524, -0.0683,  0.1291,
          0.3803,  0.5115,  0.0751, 13.6910,  6.8978,  0.7795,  1.2258,  1.3224,
          1.5358,  0.9994,  1.4658,  0.4297,  1.5993,  1.6982],
        [ 1.2330,  1.2644,  1.3261,  1.3053,  1.2738,  1.2398,  1.2045,  1.2311,
          1.2311,  1.2010,  1.3224,  1.2206,  1.3524,  1.2783,  1.4050,  1.1998,
          1.2788,  1.2307,  1.2883,  1.3164,  1.3344,  1.3037,  1.2583,  1.2517,
          1.1887,  1.2442,  1.2442,  1.3010,  1.3428,  1.2603,  1.0689,  1.2545,
          1.1385,  1.3094,  1.1330,  1.2635,  1.3516,  1.0414,  1.3749,  1.3661,
          0.9265,  0.8355,  1.3624,  1.3360,  0.7162,  3.3469,  2.5787,  3.5372,
          2.8683,  2.1663,  1.8500,  2.9906,  3.2631,  1.8288]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 236 : 180.10924368676157
Test loss for epoch 236 : 180.24187446243772
Test Precision for epoch 236 : 0.26153846153846155
Test Recall for epoch 236 : 0.26153846153846155
Test F1 for epoch 236 : 0.26153846153846155


theta for epoch 237 : tensor([[ 2.6449,  2.6753,  2.7495,  2.8745,  2.8378,  2.6512,  2.8129,  2.6431,
          2.6431,  1.2485,  1.2704,  1.2646,  1.2949,  1.2343,  1.3387,  1.2475,
          1.2346,  1.2266,  1.2128,  1.1940,  1.2060,  1.2255,  1.1884,  1.1832,
          1.2052,  1.1769,  1.1769,  1.2192,  1.2612,  1.1931,  1.2154,  1.2631,
          1.2029,  1.2338,  1.1532,  1.1957,  1.3700,  1.4165,  1.3916,  1.3813,
          1.3988,  1.3342,  1.3784,  1.3588,  1.3239,  1.3078,  1.2596,  1.2463,
          1.2280,  1.2999,  1.2480,  1.3387,  1.2189,  1.2264],
        [ 1.2485,  1.1682,  1.0235,  1.2181,  1.2986,  1.2995,  1.2263,  1.2902,
          1.2902,  1.5521,  1.7517,  1.5517,  2.2095,  1.5850,  6.2365,  1.6490,
          1.4877,  6.0779,  1.1149,  1.1991,  1.0267,  1.1614,  1.2814,  1.3139,
          1.2812,  1.3060,  1.3060,  1.2873,  1.0567,  1.3193,  1.3064,  1.1298,
          1.3319,  1.3665,  1.2805,  1.3214,  1.3272,  1.4483,  1.3554,  1.2855,
          1.3301,  1.4160,  1.3376,  0.5436,  1.3155,  1.0621,  1.3765,  1.3543,
          1.3307,  1.0619,  1.3611,  0.9383,  1.3188,  1.3330],
        [ 1.1635,  1.1896,  1.2410,  1.2232,  1.1968,  1.1692,  1.1762,  1.1619,
          1.1619,  1.2496,  1.2714,  1.2657,  1.2959,  1.2353,  1.3046,  1.2486,
          1.2098,  1.2531,  2.7096,  2.8322,  2.8990,  2.7947,  2.6377,  2.6955,
          2.7627,  2.6250,  2.6250,  1.2397,  1.2531,  1.1934,  1.2156,  1.2390,
          1.2033,  1.2344,  1.1979,  1.1960,  1.3684,  1.4161,  1.3902,  1.3477,
          1.3976,  1.3910,  1.3770,  1.3292,  1.2895,  1.2943,  1.2566,  1.2431,
          1.2243,  1.2771,  1.2448,  1.3261,  1.2145,  1.2227],
        [ 1.1715,  1.1983,  1.2496,  1.2317,  1.2058,  1.1773,  1.1846,  1.1698,
          1.1698,  1.2573,  1.2784,  1.2738,  1.3043,  1.2426,  1.2589,  1.2562,
          1.2423,  1.1905,  1.2230,  1.2478,  1.2611,  1.2362,  1.1977,  1.1920,
          1.2142,  1.1859,  1.1859,  2.9440,  2.9064,  2.5399,  2.7040,  2.9398,
          2.5506,  2.8963,  2.5476,  2.5426,  1.3656,  1.4144,  1.3876,  1.3758,
          1.3959,  1.3888,  1.3742,  1.2920,  1.3162,  1.3162,  1.2656,  1.1627,
          1.1896,  1.3080,  1.2526,  1.3486,  1.1797,  1.2312],
        [ 1.7099,  1.3921,  0.6364,  0.8479,  1.2034,  1.6034,  1.5419,  1.7069,
          1.7069,  1.5523,  1.2394,  1.3902,  0.9079,  1.6343,  0.2727,  1.5320,
          1.6751,  1.0353,  1.3247,  0.9113,  0.7737,  1.1101,  1.5789,  1.6201,
          1.3826,  1.7176,  1.7176,  0.7483,  0.8581,  1.6816,  1.4972,  0.8301,
          1.6219,  1.1142,  1.7333,  1.6476,  0.1805, -0.0521, -0.0680,  0.1295,
          0.3812,  0.5114,  0.0753, 13.7364,  6.8758,  0.7734,  1.2216,  1.3183,
          1.5319,  0.9934,  1.4617,  0.4230,  1.5955,  1.6944],
        [ 1.2336,  1.2651,  1.3269,  1.3061,  1.2745,  1.2405,  1.2052,  1.2317,
          1.2317,  1.2087,  1.3302,  1.2283,  1.3603,  1.2860,  1.4127,  1.2075,
          1.2864,  1.2388,  1.2871,  1.3152,  1.3333,  1.3026,  1.2571,  1.2505,
          1.1875,  1.2430,  1.2430,  1.2983,  1.3402,  1.2575,  1.0662,  1.2519,
          1.1359,  1.3066,  1.1304,  1.2607,  1.3535,  1.0437,  1.3768,  1.3680,
          0.9285,  0.8378,  1.3644,  1.3372,  0.7184,  3.3473,  2.5763,  3.5383,
          2.8665,  2.1636,  1.8470,  2.9890,  3.2633,  1.8258]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 237 : 180.10750059571643
Test loss for epoch 237 : 180.24619376023287
Test Precision for epoch 237 : 0.26153846153846155
Test Recall for epoch 237 : 0.26153846153846155
Test F1 for epoch 237 : 0.26153846153846155


theta for epoch 238 : tensor([[ 2.6516,  2.6820,  2.7562,  2.8815,  2.8447,  2.6578,  2.8198,  2.6498,
          2.6498,  1.2431,  1.2651,  1.2592,  1.2897,  1.2289,  1.3334,  1.2422,
          1.2291,  1.2215,  1.2071,  1.1883,  1.2003,  1.2199,  1.1827,  1.1775,
          1.1995,  1.1712,  1.1712,  1.2178,  1.2598,  1.1918,  1.2140,  1.2617,
          1.2016,  1.2325,  1.1518,  1.1944,  1.3680,  1.4147,  1.3898,  1.3795,
          1.3968,  1.3324,  1.3765,  1.3565,  1.3220,  1.3097,  1.2615,  1.2482,
          1.2298,  1.3018,  1.2499,  1.3407,  1.2207,  1.2282],
        [ 1.2533,  1.1734,  1.0300,  1.2235,  1.3037,  1.3042,  1.2312,  1.2949,
          1.2949,  1.5517,  1.7500,  1.5508,  2.2060,  1.5842,  6.2360,  1.6481,
          1.4872,  6.0769,  1.1119,  1.1961,  1.0258,  1.1582,  1.2771,  1.3094,
          1.2771,  1.3013,  1.3013,  1.2889,  1.0604,  1.3201,  1.3076,  1.1317,
          1.3328,  1.3674,  1.2814,  1.3223,  1.3277,  1.4478,  1.3549,  1.2859,
          1.3316,  1.4156,  1.3371,  0.5479,  1.3151,  1.0694,  1.3808,  1.3586,
          1.3350,  1.0685,  1.3655,  0.9469,  1.3231,  1.3373],
        [ 1.1686,  1.1947,  1.2459,  1.2282,  1.2018,  1.1742,  1.1812,  1.1670,
          1.1670,  1.2474,  1.2694,  1.2636,  1.2940,  1.2331,  1.3028,  1.2464,
          1.2073,  1.2521,  2.7061,  2.8291,  2.8953,  2.7902,  2.6347,  2.6914,
          2.7601,  2.6220,  2.6220,  1.2423,  1.2563,  1.1964,  1.2186,  1.2417,
          1.2063,  1.2373,  1.2009,  1.1990,  1.3697,  1.4174,  1.3916,  1.3487,
          1.3988,  1.3923,  1.3785,  1.3310,  1.2905,  1.3009,  1.2629,  1.2494,
          1.2307,  1.2840,  1.2511,  1.3327,  1.2208,  1.2290],
        [ 1.1747,  1.2015,  1.2527,  1.2348,  1.2090,  1.1805,  1.1879,  1.1731,
          1.1731,  1.2531,  1.2745,  1.2697,  1.3005,  1.2385,  1.2551,  1.2522,
          1.2382,  1.1872,  1.2184,  1.2432,  1.2565,  1.2316,  1.1931,  1.1875,
          1.2095,  1.1813,  1.1813,  2.9464,  2.9096,  2.5425,  2.7069,  2.9423,
          2.5532,  2.8987,  2.5502,  2.5453,  1.3650,  1.4139,  1.3872,  1.3753,
          1.3953,  1.3884,  1.3738,  1.2913,  1.3157,  1.3194,  1.2687,  1.1656,
          1.1927,  1.3111,  1.2556,  1.3517,  1.1828,  1.2343],
        [ 1.7142,  1.3961,  0.6393,  0.8516,  1.2075,  1.6079,  1.5461,  1.7112,
          1.7112,  1.5491,  1.2358,  1.3871,  0.9040,  1.6307,  0.2688,  1.5284,
          1.6721,  1.0290,  1.3200,  0.9074,  0.7688,  1.1058,  1.5750,  1.6161,
          1.3790,  1.7139,  1.7139,  0.7499,  0.8582,  1.6831,  1.4987,  0.8315,
          1.6235,  1.1159,  1.7348,  1.6491,  0.1788, -0.0540, -0.0699,  0.1277,
          0.3796,  0.5089,  0.0733, 13.7802,  6.8511,  0.7772,  1.2274,  1.3240,
          1.5374,  0.9974,  1.4674,  0.4259,  1.6013,  1.6999],
        [ 1.2362,  1.2677,  1.3296,  1.3088,  1.2771,  1.2431,  1.2077,  1.2343,
          1.2343,  1.2035,  1.3252,  1.2231,  1.3555,  1.2809,  1.4080,  1.2024,
          1.2812,  1.2342,  1.2821,  1.3100,  1.3283,  1.2976,  1.2520,  1.2455,
          1.1822,  1.2379,  1.2379,  1.2978,  1.3398,  1.2570,  1.0654,  1.2514,
          1.1354,  1.3062,  1.1299,  1.2602,  1.3516,  1.0416,  1.3750,  1.3662,
          0.9259,  0.8354,  1.3627,  1.3348,  0.7159,  3.3547,  2.5814,  3.5467,
          2.8720,  2.1683,  1.8516,  2.9945,  3.2709,  1.8303]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 238 : 180.09483691177215
Test loss for epoch 238 : 180.23025683433534
Test Precision for epoch 238 : 0.26153846153846155
Test Recall for epoch 238 : 0.26153846153846155
Test F1 for epoch 238 : 0.26153846153846155


theta for epoch 239 : tensor([[ 2.6542,  2.6846,  2.7589,  2.8844,  2.8477,  2.6605,  2.8228,  2.6524,
          2.6524,  1.2384,  1.2604,  1.2545,  1.2851,  1.2243,  1.3288,  1.2375,
          1.2244,  1.2172,  1.2086,  1.1898,  1.2018,  1.2214,  1.1842,  1.1791,
          1.2010,  1.1728,  1.1728,  1.2192,  1.2613,  1.1934,  1.2156,  1.2633,
          1.2032,  1.2340,  1.1533,  1.1960,  1.3662,  1.4130,  1.3881,  1.3777,
          1.3950,  1.3307,  1.3749,  1.3542,  1.3204,  1.3104,  1.2621,  1.2487,
          1.2303,  1.3025,  1.2504,  1.3415,  1.2212,  1.2287],
        [ 1.2526,  1.1734,  1.0316,  1.2236,  1.3036,  1.3034,  1.2308,  1.2942,
          1.2942,  1.5496,  1.7466,  1.5484,  2.2007,  1.5818,  6.2334,  1.6455,
          1.4851,  6.0738,  1.1166,  1.2007,  1.0323,  1.1625,  1.2805,  1.3125,
          1.2806,  1.3044,  1.3044,  1.2932,  1.0670,  1.3237,  1.3116,  1.1365,
          1.3363,  1.3710,  1.2850,  1.3260,  1.3282,  1.4474,  1.3544,  1.2863,
          1.3332,  1.4152,  1.3366,  0.5530,  1.3147,  1.0757,  1.3836,  1.3613,
          1.3377,  1.0739,  1.3682,  0.9546,  1.3257,  1.3400],
        [ 1.1656,  1.1916,  1.2427,  1.2250,  1.1987,  1.1712,  1.1782,  1.1640,
          1.1640,  1.2419,  1.2641,  1.2582,  1.2889,  1.2276,  1.2977,  1.2410,
          1.2014,  1.2479,  2.7114,  2.8348,  2.9004,  2.7943,  2.6405,  2.6962,
          2.7662,  2.6278,  2.6278,  1.2433,  1.2578,  1.1978,  1.2199,  1.2427,
          1.2077,  1.2387,  1.2023,  1.2004,  1.3676,  1.4154,  1.3897,  1.3462,
          1.3966,  1.3903,  1.3765,  1.3296,  1.2880,  1.3022,  1.2638,  1.2502,
          1.2316,  1.2855,  1.2520,  1.3340,  1.2217,  1.2299],
        [ 1.1725,  1.1993,  1.2505,  1.2326,  1.2067,  1.1783,  1.1857,  1.1709,
          1.1709,  1.2487,  1.2704,  1.2654,  1.2965,  1.2341,  1.2511,  1.2478,
          1.2337,  1.1837,  1.2207,  1.2455,  1.2588,  1.2340,  1.1954,  1.1898,
          1.2119,  1.1836,  1.1836,  2.9495,  2.9134,  2.5457,  2.7104,  2.9453,
          2.5565,  2.9018,  2.5534,  2.5485,  1.3639,  1.4130,  1.3862,  1.3742,
          1.3941,  1.3874,  1.3728,  1.2900,  1.3147,  1.3207,  1.2699,  1.1668,
          1.1939,  1.3124,  1.2568,  1.3531,  1.1839,  1.2355],
        [ 1.7134,  1.3952,  0.6381,  0.8509,  1.2068,  1.6072,  1.5453,  1.7105,
          1.7105,  1.5458,  1.2319,  1.3837,  0.8999,  1.6268,  0.2647,  1.5246,
          1.6689,  1.0223,  1.3224,  0.9102,  0.7703,  1.1085,  1.5783,  1.6193,
          1.3825,  1.7173,  1.7173,  0.7529,  0.8597,  1.6864,  1.5019,  0.8344,
          1.6268,  1.1192,  1.7381,  1.6523,  0.1767, -0.0563, -0.0722,  0.1255,
          0.3778,  0.5061,  0.0710, 13.8241,  6.8259,  0.7782,  1.2302,  1.3268,
          1.5400,  0.9985,  1.4700,  0.4262,  1.6040,  1.7024],
        [ 1.2343,  1.2658,  1.3277,  1.3068,  1.2752,  1.2411,  1.2058,  1.2323,
          1.2323,  1.1996,  1.3214,  1.2193,  1.3518,  1.2769,  1.4044,  1.1985,
          1.2771,  1.2308,  1.2855,  1.3132,  1.3316,  1.3010,  1.2554,  1.2489,
          1.1854,  1.2413,  1.2413,  1.3008,  1.3427,  1.2600,  1.0683,  1.2544,
          1.1384,  1.3092,  1.1330,  1.2632,  1.3501,  1.0405,  1.3736,  1.3649,
          0.9244,  0.8342,  1.3614,  1.3329,  0.7146,  3.3579,  2.5820,  3.5507,
          2.8731,  2.1685,  1.8516,  2.9956,  3.2739,  1.8303]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 239 : 180.09019092123157
Test loss for epoch 239 : 180.22230249528732
Test Precision for epoch 239 : 0.26153846153846155
Test Recall for epoch 239 : 0.26153846153846155
Test F1 for epoch 239 : 0.26153846153846155


theta for epoch 240 : tensor([[ 2.6535,  2.6840,  2.7582,  2.8841,  2.8474,  2.6598,  2.8224,  2.6517,
          2.6517,  1.2438,  1.2659,  1.2600,  1.2906,  1.2298,  1.3342,  1.2430,
          1.2299,  1.2229,  1.2123,  1.1934,  1.2054,  1.2251,  1.1879,  1.1828,
          1.2046,  1.1765,  1.1765,  1.2187,  1.2608,  1.1929,  1.2151,  1.2627,
          1.2027,  1.2335,  1.1528,  1.1955,  1.3668,  1.4139,  1.3889,  1.3783,
          1.3956,  1.3316,  1.3756,  1.3542,  1.3212,  1.3077,  1.2592,  1.2458,
          1.2274,  1.2997,  1.2475,  1.3388,  1.2182,  1.2257],
        [ 1.2468,  1.1680,  1.0278,  1.2185,  1.2982,  1.2976,  1.2250,  1.2883,
          1.2883,  1.5569,  1.7524,  1.5552,  2.2043,  1.5887,  6.2390,  1.6523,
          1.4923,  6.0791,  1.1197,  1.2037,  1.0371,  1.1652,  1.2825,  1.3143,
          1.2827,  1.3062,  1.3062,  1.2911,  1.0669,  1.3209,  1.3092,  1.1346,
          1.3336,  1.3683,  1.2822,  1.3233,  1.3281,  1.4464,  1.3533,  1.2859,
          1.3343,  1.4144,  1.3354,  0.5561,  1.3137,  1.0742,  1.3789,  1.3566,
          1.3329,  1.0715,  1.3634,  0.9547,  1.3209,  1.3352],
        [ 1.1602,  1.1861,  1.2371,  1.2195,  1.1932,  1.1658,  1.1727,  1.1586,
          1.1586,  1.2443,  1.2666,  1.2606,  1.2915,  1.2300,  1.3002,  1.2434,
          1.2034,  1.2513,  2.7177,  2.8415,  2.9065,  2.7995,  2.6475,  2.7021,
          2.7735,  2.6347,  2.6347,  1.2402,  1.2553,  1.1950,  1.2172,  1.2396,
          1.2049,  1.2359,  1.1995,  1.1976,  1.3666,  1.4146,  1.3888,  1.3448,
          1.3955,  1.3895,  1.3756,  1.3289,  1.2867,  1.2984,  1.2594,  1.2459,
          1.2272,  1.2819,  1.2476,  1.3302,  1.2173,  1.2256],
        [ 1.1692,  1.1959,  1.2471,  1.2293,  1.2034,  1.1750,  1.1823,  1.1676,
          1.1676,  1.2540,  1.2758,  1.2707,  1.3019,  1.2394,  1.2565,  1.2532,
          1.2390,  1.1893,  1.2253,  1.2498,  1.2633,  1.2385,  1.2000,  1.1944,
          1.2163,  1.1882,  1.1882,  2.9496,  2.9142,  2.5459,  2.7108,  2.9454,
          2.5566,  2.9019,  2.5535,  2.5487,  1.3648,  1.4141,  1.3873,  1.3752,
          1.3950,  1.3886,  1.3738,  1.2905,  1.3158,  1.3189,  1.2680,  1.1650,
          1.1919,  1.3106,  1.2550,  1.3513,  1.1819,  1.2335],
        [ 1.7099,  1.3913,  0.6342,  0.8475,  1.2031,  1.6037,  1.5418,  1.7070,
          1.7070,  1.5504,  1.2355,  1.3880,  0.9023,  1.6311,  0.2652,  1.5287,
          1.6738,  1.0227,  1.3250,  0.9130,  0.7717,  1.1112,  1.5820,  1.6229,
          1.3862,  1.7212,  1.7212,  0.7521,  0.8573,  1.6858,  1.5011,  0.8332,
          1.6262,  1.1185,  1.7375,  1.6517,  0.1762, -0.0571, -0.0730,  0.1248,
          0.3775,  0.5048,  0.0701, 13.8694,  6.8015,  0.7721,  1.2260,  1.3225,
          1.5359,  0.9925,  1.4658,  0.4199,  1.6001,  1.6984],
        [ 1.2312,  1.2627,  1.3247,  1.3038,  1.2722,  1.2381,  1.2029,  1.2293,
          1.2293,  1.2063,  1.3283,  1.2261,  1.3588,  1.2836,  1.4113,  1.2053,
          1.2837,  1.2382,  1.2913,  1.3188,  1.3372,  1.3067,  1.2612,  1.2547,
          1.1911,  1.2471,  1.2471,  1.3019,  1.3437,  1.2610,  1.0696,  1.2556,
          1.1396,  1.3102,  1.1342,  1.2642,  1.3515,  1.0427,  1.3750,  1.3664,
          0.9265,  0.8367,  1.3630,  1.3337,  0.7171,  3.3553,  2.5767,  3.5488,
          2.8683,  2.1630,  1.8458,  2.9912,  3.2711,  1.8245]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 240 : 180.08426503414623
Test loss for epoch 240 : 180.22030377134598
Test Precision for epoch 240 : 0.26153846153846155
Test Recall for epoch 240 : 0.26153846153846155
Test F1 for epoch 240 : 0.26153846153846155


theta for epoch 241 : tensor([[ 2.6568,  2.6873,  2.7615,  2.8877,  2.8509,  2.6631,  2.8260,  2.6550,
          2.6550,  1.2470,  1.2692,  1.2631,  1.2939,  1.2330,  1.3373,  1.2462,
          1.2330,  1.2264,  1.2077,  1.1887,  1.2008,  1.2204,  1.1832,  1.1782,
          1.2000,  1.1718,  1.1718,  1.2167,  1.2589,  1.1909,  1.2131,  1.2607,
          1.2007,  1.2315,  1.1509,  1.1935,  1.3671,  1.4144,  1.3893,  1.3787,
          1.3958,  1.3320,  1.3760,  1.3539,  1.3216,  1.3078,  1.2592,  1.2458,
          1.2274,  1.2999,  1.2475,  1.3390,  1.2182,  1.2257],
        [ 1.2467,  1.1684,  1.0296,  1.2192,  1.2987,  1.2975,  1.2251,  1.2883,
          1.2883,  1.5635,  1.7574,  1.5614,  2.2072,  1.5949,  6.2435,  1.6583,
          1.4989,  6.0832,  1.1152,  1.1992,  1.0348,  1.1604,  1.2766,  1.3082,
          1.2769,  1.3000,  1.3000,  1.2887,  1.0666,  1.3178,  1.3064,  1.1325,
          1.3305,  1.3653,  1.2790,  1.3202,  1.3286,  1.4460,  1.3528,  1.2862,
          1.3359,  1.4140,  1.3349,  0.5600,  1.3132,  1.0769,  1.3783,  1.3561,
          1.3324,  1.0733,  1.3629,  0.9588,  1.3203,  1.3346],
        [ 1.1623,  1.1882,  1.2391,  1.2215,  1.1953,  1.1679,  1.1748,  1.1607,
          1.1607,  1.2484,  1.2709,  1.2648,  1.2959,  1.2342,  1.3045,  1.2476,
          1.2072,  1.2566,  2.7152,  2.8394,  2.9037,  2.7959,  2.6455,  2.6990,
          2.7719,  2.6327,  2.6327,  1.2400,  1.2557,  1.1952,  1.2173,  1.2395,
          1.2051,  1.2361,  1.1997,  1.1978,  1.3685,  1.4166,  1.3909,  1.3464,
          1.3973,  1.3915,  1.3777,  1.3312,  1.2883,  1.3013,  1.2620,  1.2485,
          1.2299,  1.2851,  1.2503,  1.3331,  1.2199,  1.2283],
        [ 1.1708,  1.1975,  1.2486,  1.2309,  1.2050,  1.1766,  1.1839,  1.1692,
          1.1692,  1.2578,  1.2798,  1.2745,  1.3059,  1.2433,  1.2605,  1.2570,
          1.2428,  1.1934,  1.2215,  1.2461,  1.2595,  1.2347,  1.1962,  1.1907,
          1.2125,  1.1844,  1.1844,  2.9499,  2.9151,  2.5463,  2.7115,  2.9458,
          2.5570,  2.9021,  2.5539,  2.5490,  1.3660,  1.4154,  1.3887,  1.3764,
          1.3961,  1.3899,  1.3752,  1.2912,  1.3171,  1.3202,  1.2693,  1.1663,
          1.1933,  1.3120,  1.2563,  1.3527,  1.1832,  1.2348],
        [ 1.7118,  1.3928,  0.6349,  0.8490,  1.2047,  1.6056,  1.5435,  1.7089,
          1.7089,  1.5545,  1.2388,  1.3918,  0.9045,  1.6347,  0.2659,  1.5322,
          1.6781,  1.0228,  1.3200,  0.9090,  0.7663,  1.1068,  1.5780,  1.6188,
          1.3826,  1.7174,  1.7174,  0.7518,  0.8553,  1.6853,  1.5005,  0.8326,
          1.6257,  1.1181,  1.7370,  1.6511,  0.1750, -0.0585, -0.0744,  0.1235,
          0.3765,  0.5028,  0.0686, 13.9142,  6.7758,  0.7722,  1.2280,  1.3245,
          1.5378,  0.9926,  1.4677,  0.4191,  1.6021,  1.7003],
        [ 1.2313,  1.2628,  1.3248,  1.3039,  1.2722,  1.2381,  1.2029,  1.2293,
          1.2293,  1.2089,  1.3311,  1.2287,  1.3618,  1.2863,  1.4143,  1.2080,
          1.2863,  1.2413,  1.2864,  1.3137,  1.3324,  1.3019,  1.2563,  1.2499,
          1.1859,  1.2422,  1.2422,  1.2998,  1.3417,  1.2588,  1.0672,  1.2535,
          1.1375,  1.3081,  1.1320,  1.2620,  1.3513,  1.0423,  1.3748,  1.3662,
          0.9256,  0.8361,  1.3629,  1.3327,  0.7163,  3.3607,  2.5796,  3.5550,
          2.8717,  2.1655,  1.8481,  2.9946,  3.2765,  1.8268]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 241 : 180.07565999107388
Test loss for epoch 241 : 180.21251341790236
Test Precision for epoch 241 : 0.26153846153846155
Test Recall for epoch 241 : 0.26153846153846155
Test F1 for epoch 241 : 0.26153846153846155


theta for epoch 242 : tensor([[ 2.6606,  2.6910,  2.7653,  2.8917,  2.8550,  2.6668,  2.8301,  2.6588,
          2.6588,  1.2409,  1.2632,  1.2570,  1.2880,  1.2269,  1.3313,  1.2402,
          1.2269,  1.2207,  1.2056,  1.1866,  1.1987,  1.2184,  1.1811,  1.1761,
          1.1979,  1.1697,  1.1697,  1.2177,  1.2600,  1.1921,  1.2143,  1.2618,
          1.2019,  1.2326,  1.1520,  1.1947,  1.3675,  1.4149,  1.3899,  1.3792,
          1.3962,  1.3326,  1.3766,  1.3538,  1.3221,  1.3091,  1.2604,  1.2470,
          1.2286,  1.3012,  1.2488,  1.3403,  1.2194,  1.2270],
        [ 1.2517,  1.1739,  1.0370,  1.2251,  1.3042,  1.3024,  1.2303,  1.2932,
          1.2932,  1.5613,  1.7537,  1.5587,  2.2012,  1.5923,  6.2393,  1.6555,
          1.4966,  6.0783,  1.1156,  1.1995,  1.0375,  1.1603,  1.2754,  1.3067,
          1.2758,  1.2984,  1.2984,  1.2918,  1.0722,  1.3200,  1.3090,  1.1362,
          1.3327,  1.3675,  1.2812,  1.3224,  1.3310,  1.4473,  1.3541,  1.2885,
          1.3394,  1.4154,  1.3362,  0.5672,  1.3144,  1.0834,  1.3809,  1.3587,
          1.3350,  1.0789,  1.3655,  0.9669,  1.3229,  1.3372],
        [ 1.1662,  1.1922,  1.2431,  1.2255,  1.1992,  1.1718,  1.1788,  1.1646,
          1.1646,  1.2432,  1.2659,  1.2596,  1.2910,  1.2291,  1.2997,  1.2425,
          1.2017,  1.2527,  2.7147,  2.8394,  2.9031,  2.7942,  2.6455,  2.6980,
          2.7723,  2.6328,  2.6328,  1.2421,  1.2583,  1.1976,  1.2197,  1.2415,
          1.2074,  1.2384,  1.2021,  1.2002,  1.3698,  1.4179,  1.3923,  1.3474,
          1.3984,  1.3927,  1.3791,  1.3329,  1.2891,  1.3046,  1.2649,  1.2514,
          1.2328,  1.2886,  1.2532,  1.3363,  1.2228,  1.2312],
        [ 1.1738,  1.2004,  1.2515,  1.2337,  1.2079,  1.1795,  1.1869,  1.1721,
          1.1721,  1.2512,  1.2735,  1.2680,  1.2997,  1.2368,  1.2543,  1.2505,
          1.2362,  1.1879,  1.2190,  1.2436,  1.2570,  1.2322,  1.1937,  1.1882,
          1.2099,  1.1818,  1.1818,  2.9530,  2.9189,  2.5495,  2.7149,  2.9488,
          2.5602,  2.9052,  2.5571,  2.5522,  1.3662,  1.4158,  1.3891,  1.3767,
          1.3963,  1.3903,  1.3755,  1.2912,  1.3173,  1.3213,  1.2703,  1.1673,
          1.1943,  1.3130,  1.2573,  1.3537,  1.1842,  1.2359],
        [ 1.7159,  1.3965,  0.6373,  0.8523,  1.2084,  1.6097,  1.5474,  1.7130,
          1.7130,  1.5496,  1.2333,  1.3869,  0.8987,  1.6293,  0.2603,  1.5268,
          1.6734,  1.0142,  1.3174,  0.9071,  0.7632,  1.1046,  1.5763,  1.6171,
          1.3813,  1.7159,  1.7159,  0.7538,  0.8557,  1.6875,  1.5026,  0.8343,
          1.6279,  1.1204,  1.7392,  1.6533,  0.1738, -0.0600, -0.0759,  0.1221,
          0.3754,  0.5006,  0.0671, 13.9593,  6.7496,  0.7734,  1.2315,  1.3279,
          1.5411,  0.9941,  1.4710,  0.4195,  1.6055,  1.7034],
        [ 1.2330,  1.2646,  1.3267,  1.3058,  1.2740,  1.2398,  1.2045,  1.2310,
          1.2310,  1.2005,  1.3230,  1.2204,  1.3538,  1.2781,  1.4064,  1.1997,
          1.2781,  1.2335,  1.2830,  1.3101,  1.3291,  1.2985,  1.2529,  1.2465,
          1.1822,  1.2388,  1.2388,  1.2994,  1.3414,  1.2584,  1.0664,  1.2531,
          1.1369,  1.3077,  1.1315,  1.2617,  1.3500,  1.0406,  1.3736,  1.3651,
          0.9233,  0.8339,  1.3619,  1.3309,  0.7139,  3.3689,  2.5854,  3.5641,
          2.8779,  2.1708,  1.8532,  3.0007,  3.2848,  1.8319]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 242 : 180.07205699010947
Test loss for epoch 242 : 180.2044894521596
Test Precision for epoch 242 : 0.26153846153846155
Test Recall for epoch 242 : 0.26153846153846155
Test F1 for epoch 242 : 0.26153846153846155


theta for epoch 243 : tensor([[ 2.6587,  2.6892,  2.7635,  2.8902,  2.8535,  2.6650,  2.8286,  2.6570,
          2.6570,  1.2423,  1.2647,  1.2584,  1.2895,  1.2284,  1.3328,  1.2417,
          1.2283,  1.2226,  1.2110,  1.1920,  1.2041,  1.2238,  1.1866,  1.1816,
          1.2033,  1.1751,  1.1751,  1.2203,  1.2624,  1.1946,  1.2168,  1.2643,
          1.2044,  1.2351,  1.1546,  1.1972,  1.3691,  1.4167,  1.3917,  1.3808,
          1.3977,  1.3345,  1.3783,  1.3547,  1.3238,  1.3071,  1.2584,  1.2450,
          1.2266,  1.2992,  1.2467,  1.3384,  1.2173,  1.2249],
        [ 1.2500,  1.1729,  1.0377,  1.2245,  1.3032,  1.3007,  1.2288,  1.2915,
          1.2915,  1.5651,  1.7559,  1.5621,  2.2010,  1.5957,  6.2400,  1.6588,
          1.5004,  6.0786,  1.1203,  1.2041,  1.0441,  1.1644,  1.2787,  1.3097,
          1.2791,  1.3014,  1.3014,  1.2920,  1.0748,  1.3195,  1.3089,  1.1368,
          1.3321,  1.3669,  1.2807,  1.3219,  1.3315,  1.4468,  1.3536,  1.2889,
          1.3411,  1.4150,  1.3356,  0.5720,  1.3139,  1.0827,  1.3763,  1.3540,
          1.3303,  1.0772,  1.3609,  0.9680,  1.3182,  1.3326],
        [ 1.1642,  1.1902,  1.2411,  1.2235,  1.1972,  1.1698,  1.1768,  1.1626,
          1.1626,  1.2410,  1.2638,  1.2574,  1.2890,  1.2269,  1.2976,  1.2403,
          1.1991,  1.2516,  2.7206,  2.8457,  2.9087,  2.7990,  2.6520,  2.7033,
          2.7792,  2.6393,  2.6393,  1.2407,  1.2575,  1.1966,  1.2187,  1.2402,
          1.2065,  1.2374,  1.2011,  1.1992,  1.3687,  1.4169,  1.3913,  1.3459,
          1.3972,  1.3918,  1.3781,  1.3321,  1.2876,  1.3003,  1.2602,  1.2467,
          1.2281,  1.2846,  1.2485,  1.3320,  1.2181,  1.2265],
        [ 1.1724,  1.1991,  1.2502,  1.2325,  1.2066,  1.1782,  1.1855,  1.1708,
          1.1708,  1.2498,  1.2722,  1.2666,  1.2985,  1.2354,  1.2531,  1.2492,
          1.2347,  1.1871,  1.2226,  1.2471,  1.2606,  1.2358,  1.1972,  1.1918,
          1.2135,  1.1854,  1.1854,  2.9557,  2.9223,  2.5523,  2.7180,  2.9516,
          2.5630,  2.9079,  2.5599,  2.5551,  1.3660,  1.4157,  1.3890,  1.3765,
          1.3960,  1.3902,  1.3755,  1.2905,  1.3172,  1.3177,  1.2668,  1.1639,
          1.1907,  1.3095,  1.2539,  1.3502,  1.1805,  1.2323],
        [ 1.7155,  1.3957,  0.6359,  0.8516,  1.2078,  1.6094,  1.5469,  1.7126,
          1.7126,  1.5498,  1.2325,  1.3869,  0.8971,  1.6290,  0.2577,  1.5265,
          1.6738,  1.0100,  1.3205,  0.9105,  0.7651,  1.1080,  1.5806,  1.6214,
          1.3857,  1.7204,  1.7204,  0.7547,  0.8549,  1.6887,  1.5036,  0.8349,
          1.6291,  1.1215,  1.7404,  1.6545,  0.1727, -0.0613, -0.0773,  0.1209,
          0.3746,  0.4987,  0.0657, 14.0049,  6.7232,  0.7676,  1.2275,  1.3238,
          1.5371,  0.9882,  1.4670,  0.4133,  1.6016,  1.6995],
        [ 1.2321,  1.2638,  1.3261,  1.3051,  1.2733,  1.2390,  1.2037,  1.2301,
          1.2301,  1.2001,  1.3227,  1.2200,  1.3536,  1.2777,  1.4062,  1.1994,
          1.2775,  1.2337,  1.2878,  1.3148,  1.3338,  1.3033,  1.2577,  1.2514,
          1.1868,  1.2436,  1.2436,  1.3004,  1.3424,  1.2595,  1.0673,  1.2541,
          1.1380,  1.3087,  1.1326,  1.2627,  1.3500,  1.0409,  1.3737,  1.3652,
          0.9231,  0.8341,  1.3621,  1.3302,  0.7140,  3.3694,  2.5833,  3.5653,
          2.8763,  2.1684,  1.8506,  2.9993,  3.2852,  1.8292]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 243 : 180.05997110214278
Test loss for epoch 243 : 180.19319348374535
Test Precision for epoch 243 : 0.26153846153846155
Test Recall for epoch 243 : 0.26153846153846155
Test F1 for epoch 243 : 0.26153846153846155


theta for epoch 244 : tensor([[ 2.6578,  2.6883,  2.7626,  2.8896,  2.8529,  2.6641,  2.8279,  2.6560,
          2.6560,  1.2484,  1.2708,  1.2645,  1.2957,  1.2346,  1.3388,  1.2478,
          1.2344,  1.2290,  1.2131,  1.1941,  1.2062,  1.2258,  1.1886,  1.1836,
          1.2053,  1.1771,  1.1771,  1.2192,  1.2614,  1.1936,  1.2157,  1.2632,
          1.2034,  1.2340,  1.1536,  1.1962,  1.3693,  1.4172,  1.3921,  1.3812,
          1.3980,  1.3350,  1.3787,  1.3543,  1.3243,  1.3069,  1.2581,  1.2447,
          1.2262,  1.2990,  1.2464,  1.3383,  1.2169,  1.2246],
        [ 1.2459,  1.1693,  1.0359,  1.2213,  1.2998,  1.2966,  1.2249,  1.2874,
          1.2874,  1.5749,  1.7639,  1.5714,  2.2064,  1.6050,  6.2457,  1.6680,
          1.5102,  6.0840,  1.1204,  1.2043,  1.0463,  1.1640,  1.2775,  1.3082,
          1.2779,  1.2998,  1.2998,  1.2875,  1.0725,  1.3143,  1.3041,  1.1327,
          1.3269,  1.3618,  1.2754,  1.3168,  1.3298,  1.4442,  1.3509,  1.2870,
          1.3406,  1.4125,  1.3329,  0.5741,  1.3112,  1.0825,  1.3724,  1.3502,
          1.3265,  1.0759,  1.3570,  0.9695,  1.3143,  1.3287],
        [ 1.1628,  1.1887,  1.2396,  1.2220,  1.1958,  1.1684,  1.1753,  1.1612,
          1.1612,  1.2451,  1.2680,  1.2616,  1.2934,  1.2311,  1.3018,  1.2446,
          1.2029,  1.2568,  2.7229,  2.8484,  2.9108,  2.8001,  2.6548,  2.7050,
          2.7824,  2.6421,  2.6421,  1.2379,  1.2553,  1.1941,  1.2162,  1.2373,
          1.2040,  1.2349,  1.1986,  1.1968,  1.3678,  1.4162,  1.3906,  1.3446,
          1.3962,  1.3911,  1.3774,  1.3314,  1.2865,  1.2997,  1.2592,  1.2456,
          1.2271,  1.2843,  1.2475,  1.3314,  1.2170,  1.2255],
        [ 1.1712,  1.1979,  1.2491,  1.2313,  1.2054,  1.1770,  1.1843,  1.1696,
          1.1696,  1.2544,  1.2769,  1.2712,  1.3032,  1.2401,  1.2578,  1.2539,
          1.2393,  1.1919,  1.2239,  1.2483,  1.2619,  1.2372,  1.1985,  1.1931,
          1.2148,  1.1867,  1.1867,  2.9563,  2.9235,  2.5529,  2.7189,  2.9522,
          2.5637,  2.9085,  2.5605,  2.5557,  1.3656,  1.4156,  1.3888,  1.3762,
          1.3956,  1.3901,  1.3753,  1.2897,  1.3170,  1.3169,  1.2660,  1.1632,
          1.1898,  1.3087,  1.2531,  1.3494,  1.1796,  1.2314],
        [ 1.7149,  1.3947,  0.6345,  0.8509,  1.2070,  1.6089,  1.5463,  1.7121,
          1.7121,  1.5557,  1.2374,  1.3924,  0.9005,  1.6344,  0.2592,  1.5317,
          1.6799,  1.0111,  1.3207,  0.9115,  0.7646,  1.1089,  1.5821,  1.6229,
          1.3875,  1.7221,  1.7221,  0.7538,  0.8522,  1.6875,  1.5022,  0.8335,
          1.6280,  1.1206,  1.7392,  1.6533,  0.1708, -0.0634, -0.0794,  0.1188,
          0.3729,  0.4959,  0.0634, 14.0502,  6.6955,  0.7648,  1.2268,  1.3230,
          1.5362,  0.9854,  1.4662,  0.4100,  1.6009,  1.6986],
        [ 1.2305,  1.2622,  1.3247,  1.3037,  1.2718,  1.2374,  1.2022,  1.2285,
          1.2285,  1.2052,  1.3279,  1.2251,  1.3590,  1.2829,  1.4115,  1.2045,
          1.2826,  1.2393,  1.2894,  1.3162,  1.3354,  1.3050,  1.2592,  1.2530,
          1.1882,  1.2451,  1.2451,  1.2985,  1.3405,  1.2575,  1.0654,  1.2522,
          1.1362,  1.3067,  1.1307,  1.2607,  1.3489,  1.0400,  1.3726,  1.3642,
          0.9218,  0.8332,  1.3612,  1.3281,  0.7130,  3.3714,  2.5826,  3.5679,
          2.8761,  2.1674,  1.8493,  2.9993,  3.2870,  1.8279]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 244 : 180.05802413220184
Test loss for epoch 244 : 180.19328475052293
Test Precision for epoch 244 : 0.26153846153846155
Test Recall for epoch 244 : 0.26153846153846155
Test F1 for epoch 244 : 0.26153846153846155


theta for epoch 245 : tensor([[ 2.6627,  2.6932,  2.7675,  2.8948,  2.8581,  2.6690,  2.8331,  2.6609,
          2.6609,  1.2454,  1.2680,  1.2616,  1.2929,  1.2317,  1.3360,  1.2450,
          1.2315,  1.2265,  1.2084,  1.1893,  1.2015,  1.2211,  1.1838,  1.1789,
          1.2005,  1.1724,  1.1724,  1.2176,  1.2599,  1.1921,  1.2142,  1.2616,
          1.2019,  1.2325,  1.1521,  1.1947,  1.3684,  1.4165,  1.3914,  1.3803,
          1.3970,  1.3343,  1.3780,  1.3526,  1.3235,  1.3089,  1.2600,  1.2465,
          1.2280,  1.3010,  1.2482,  1.3403,  1.2187,  1.2264],
        [ 1.2478,  1.1719,  1.0404,  1.2243,  1.3023,  1.2986,  1.2270,  1.2894,
          1.2894,  1.5770,  1.7642,  1.5730,  2.2040,  1.6066,  6.2436,  1.6694,
          1.5123,  6.0813,  1.1186,  1.2023,  1.0469,  1.1615,  1.2738,  1.3041,
          1.2743,  1.2957,  1.2957,  1.2882,  1.0758,  1.3140,  1.3043,  1.1340,
          1.3266,  1.3615,  1.2752,  1.3166,  1.3311,  1.4445,  1.3511,  1.2882,
          1.3431,  1.4128,  1.3331,  0.5806,  1.3114,  1.0900,  1.3757,  1.3534,
          1.3297,  1.0823,  1.3603,  0.9787,  1.3175,  1.3319],
        [ 1.1658,  1.1918,  1.2426,  1.2250,  1.1989,  1.1714,  1.1784,  1.1642,
          1.1642,  1.2451,  1.2681,  1.2616,  1.2936,  1.2311,  1.3019,  1.2446,
          1.2026,  1.2579,  2.7200,  2.8459,  2.9077,  2.7960,  2.6524,  2.7015,
          2.7804,  2.6397,  2.6397,  1.2394,  1.2574,  1.1960,  1.2180,  1.2389,
          1.2058,  1.2368,  1.2005,  1.1986,  1.3691,  1.4177,  1.3921,  1.3457,
          1.3975,  1.3926,  1.3789,  1.3330,  1.2875,  1.3054,  1.2645,  1.2510,
          1.2324,  1.2903,  1.2528,  1.3372,  1.2223,  1.2308],
        [ 1.1730,  1.1996,  1.2507,  1.2330,  1.2071,  1.1788,  1.1861,  1.1714,
          1.1714,  1.2528,  1.2754,  1.2696,  1.3019,  1.2385,  1.2564,  1.2523,
          1.2377,  1.1910,  1.2203,  1.2447,  1.2583,  1.2335,  1.1949,  1.1895,
          1.2110,  1.1830,  1.1830,  2.9579,  2.9257,  2.5546,  2.7208,  2.9538,
          2.5653,  2.9100,  2.5622,  2.5573,  1.3659,  1.4160,  1.3893,  1.3765,
          1.3958,  1.3905,  1.3756,  1.2895,  1.3174,  1.3201,  1.2690,  1.1661,
          1.1928,  1.3118,  1.2561,  1.3525,  1.1826,  1.2345],
        [ 1.7173,  1.3964,  0.6348,  0.8522,  1.2088,  1.6113,  1.5483,  1.7144,
          1.7144,  1.5548,  1.2353,  1.3912,  0.8975,  1.6330,  0.2552,  1.5301,
          1.6792,  1.0053,  1.3155,  0.9071,  0.7587,  1.1042,  1.5781,  1.6189,
          1.3839,  1.7184,  1.7184,  0.7537,  0.8503,  1.6879,  1.5023,  0.8330,
          1.6283,  1.1207,  1.7396,  1.6536,  0.1701, -0.0644, -0.0804,  0.1180,
          0.3724,  0.4944,  0.0624, 14.0968,  6.6685,  0.7659,  1.2308,  1.3271,
          1.5403,  0.9869,  1.4702,  0.4098,  1.6052,  1.7027],
        [ 1.2317,  1.2634,  1.3259,  1.3049,  1.2730,  1.2386,  1.2034,  1.2297,
          1.2297,  1.2028,  1.3257,  1.2228,  1.3570,  1.2806,  1.4095,  1.2023,
          1.2802,  1.2375,  1.2854,  1.3120,  1.3314,  1.3009,  1.2551,  1.2489,
          1.1838,  1.2410,  1.2410,  1.2981,  1.3401,  1.2571,  1.0647,  1.2518,
          1.1357,  1.3063,  1.1303,  1.2603,  1.3481,  1.0392,  1.3719,  1.3635,
          0.9205,  0.8321,  1.3606,  1.3265,  0.7118,  3.3773,  2.5862,  3.5747,
          2.8801,  2.1706,  1.8524,  3.0033,  3.2930,  1.8310]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 245 : 180.04573847683224
Test loss for epoch 245 : 180.17937483597635
Test Precision for epoch 245 : 0.26153846153846155
Test Recall for epoch 245 : 0.26153846153846155
Test F1 for epoch 245 : 0.26153846153846155


theta for epoch 246 : tensor([[ 2.6665,  2.6970,  2.7713,  2.8989,  2.8622,  2.6728,  2.8372,  2.6647,
          2.6647,  1.2409,  1.2635,  1.2571,  1.2886,  1.2273,  1.3316,  1.2405,
          1.2269,  1.2223,  1.2075,  1.1883,  1.2005,  1.2202,  1.1829,  1.1780,
          1.1996,  1.1715,  1.1715,  1.2181,  1.2604,  1.1927,  1.2148,  1.2622,
          1.2024,  1.2330,  1.1526,  1.1953,  1.3680,  1.4164,  1.3912,  1.3800,
          1.3966,  1.3341,  1.3778,  1.3515,  1.3233,  1.3083,  1.2592,  1.2457,
          1.2273,  1.3004,  1.2475,  1.3397,  1.2179,  1.2256],
        [ 1.2486,  1.1735,  1.0442,  1.2262,  1.3038,  1.2992,  1.2281,  1.2901,
          1.2901,  1.5769,  1.7622,  1.5723,  2.1992,  1.6060,  6.2387,  1.6686,
          1.5121,  6.0758,  1.1216,  1.2051,  1.0522,  1.1637,  1.2749,  1.3048,
          1.2754,  1.2964,  1.2964,  1.2918,  1.0822,  1.3165,  1.3074,  1.1384,
          1.3291,  1.3640,  1.2777,  1.3191,  1.3335,  1.4457,  1.3524,  1.2905,
          1.3468,  1.4141,  1.3344,  0.5888,  1.3126,  1.0958,  1.3767,  1.3545,
          1.3308,  1.0870,  1.3613,  0.9866,  1.3185,  1.3330],
        [ 1.1656,  1.1914,  1.2422,  1.2247,  1.1985,  1.1711,  1.1781,  1.1640,
          1.1640,  1.2417,  1.2648,  1.2582,  1.2904,  1.2277,  1.2987,  1.2413,
          1.1988,  1.2556,  2.7221,  2.8485,  2.9096,  2.7969,  2.6551,  2.7031,
          2.7836,  2.6424,  2.6424,  1.2408,  1.2593,  1.1977,  1.2197,  1.2402,
          1.2075,  1.2384,  1.2021,  1.2003,  1.3692,  1.4180,  1.3924,  1.3454,
          1.3975,  1.3929,  1.3791,  1.3333,  1.2874,  1.3064,  1.2651,  1.2515,
          1.2330,  1.2915,  1.2533,  1.3382,  1.2228,  1.2314],
        [ 1.1729,  1.1995,  1.2505,  1.2329,  1.2069,  1.1787,  1.1860,  1.1713,
          1.1713,  1.2493,  1.2722,  1.2661,  1.2987,  1.2351,  1.2533,  1.2489,
          1.2341,  1.1884,  1.2204,  1.2448,  1.2584,  1.2336,  1.1950,  1.1896,
          1.2111,  1.1831,  1.1831,  2.9604,  2.9288,  2.5571,  2.7235,  2.9562,
          2.5678,  2.9125,  2.5647,  2.5599,  1.3663,  1.4166,  1.3899,  1.3770,
          1.3961,  1.3912,  1.3762,  1.2894,  1.3180,  1.3206,  1.2695,  1.1666,
          1.1933,  1.3124,  1.2566,  1.3531,  1.1830,  1.2350],
        [ 1.7179,  1.3963,  0.6337,  0.8520,  1.2089,  1.6119,  1.5487,  1.7151,
          1.7151,  1.5521,  1.2314,  1.3883,  0.8927,  1.6298,  0.2498,  1.5269,
          1.6769,  0.9975,  1.3142,  0.9063,  0.7563,  1.1034,  1.5781,  1.6191,
          1.3842,  1.7188,  1.7188,  0.7549,  0.8498,  1.6899,  1.5041,  0.8338,
          1.6304,  1.1225,  1.7416,  1.6556,  0.1697, -0.0651, -0.0812,  0.1174,
          0.3722,  0.4931,  0.0616, 14.1439,  6.6413,  0.7635,  1.2311,  1.3273,
          1.5406,  0.9848,  1.4705,  0.4065,  1.6058,  1.7031],
        [ 1.2321,  1.2639,  1.3263,  1.3053,  1.2734,  1.2390,  1.2038,  1.2302,
          1.2302,  1.1998,  1.3229,  1.2199,  1.3543,  1.2776,  1.4069,  1.1994,
          1.2772,  1.2352,  1.2864,  1.3128,  1.3324,  1.3019,  1.2561,  1.2499,
          1.1846,  1.2419,  1.2419,  1.3007,  1.3428,  1.2598,  1.0673,  1.2545,
          1.1385,  1.3090,  1.1331,  1.2630,  1.3487,  1.0401,  1.3724,  1.3641,
          0.9210,  0.8330,  1.3614,  1.3262,  0.7126,  3.3793,  2.5856,  3.5773,
          2.8800,  2.1698,  1.8513,  3.0033,  3.2949,  1.8299]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 246 : 180.04221897406407
Test loss for epoch 246 : 180.17499634847786
Test Precision for epoch 246 : 0.26153846153846155
Test Recall for epoch 246 : 0.26153846153846155
Test F1 for epoch 246 : 0.26153846153846155


theta for epoch 247 : tensor([[ 2.6660,  2.6966,  2.7709,  2.8988,  2.8620,  2.6723,  2.8371,  2.6642,
          2.6642,  1.2443,  1.2670,  1.2604,  1.2921,  1.2307,  1.3351,  1.2440,
          1.2303,  1.2261,  1.2108,  1.1916,  1.2038,  1.2235,  1.1862,  1.1813,
          1.2028,  1.1748,  1.1748,  1.2183,  1.2607,  1.1929,  1.2150,  1.2624,
          1.2026,  1.2332,  1.1528,  1.1955,  1.3682,  1.4168,  1.3915,  1.3802,
          1.3968,  1.3346,  1.3781,  1.3509,  1.3237,  1.3065,  1.2573,  1.2438,
          1.2253,  1.2986,  1.2456,  1.3380,  1.2159,  1.2237],
        [ 1.2435,  1.1692,  1.0420,  1.2222,  1.2994,  1.2941,  1.2232,  1.2850,
          1.2850,  1.5847,  1.7680,  1.5795,  2.2019,  1.6132,  6.2404,  1.6757,
          1.5198,  6.0770,  1.1250,  1.2085,  1.0578,  1.1664,  1.2767,  1.3062,
          1.2771,  1.2978,  1.2978,  1.2905,  1.0834,  1.3142,  1.3056,  1.1377,
          1.3269,  1.3618,  1.2754,  1.3169,  1.3331,  1.4443,  1.3508,  1.2899,
          1.3477,  1.4128,  1.3328,  0.5934,  1.3112,  1.0962,  1.3726,  1.3504,
          1.3266,  1.0862,  1.3572,  0.9891,  1.3143,  1.3288],
        [ 1.1612,  1.1870,  1.2377,  1.2202,  1.1941,  1.1667,  1.1737,  1.1596,
          1.1596,  1.2426,  1.2659,  1.2592,  1.2916,  1.2288,  1.2998,  1.2423,
          1.1994,  1.2577,  2.7281,  2.8549,  2.9153,  2.8017,  2.6616,  2.7085,
          2.7905,  2.6489,  2.6489,  1.2382,  1.2574,  1.1954,  1.2174,  1.2377,
          1.2052,  1.2362,  1.1999,  1.1980,  1.3674,  1.4164,  1.3907,  1.3431,
          1.3957,  1.3913,  1.3774,  1.3316,  1.2853,  1.3031,  1.2613,  1.2477,
          1.2292,  1.2885,  1.2496,  1.3350,  1.2189,  1.2276],
        [ 1.1703,  1.1969,  1.2479,  1.2303,  1.2043,  1.1761,  1.1834,  1.1687,
          1.1687,  1.2523,  1.2753,  1.2691,  1.3019,  1.2381,  1.2565,  1.2520,
          1.2371,  1.1918,  1.2239,  1.2482,  1.2619,  1.2372,  1.1985,  1.1932,
          1.2146,  1.1866,  1.1866,  2.9613,  2.9303,  2.5580,  2.7247,  2.9572,
          2.5688,  2.9134,  2.5656,  2.5608,  1.3663,  1.4169,  1.3901,  1.3771,
          1.3962,  1.3915,  1.3764,  1.2889,  1.3183,  1.3192,  1.2680,  1.1652,
          1.1917,  1.3110,  1.2551,  1.3517,  1.1814,  1.2334],
        [ 1.7165,  1.3946,  0.6320,  0.8510,  1.2076,  1.6106,  1.5472,  1.7137,
          1.7137,  1.5569,  1.2351,  1.3928,  0.8952,  1.6340,  0.2509,  1.5309,
          1.6818,  0.9972,  1.3172,  0.9103,  0.7588,  1.1073,  1.5824,  1.6235,
          1.3890,  1.7233,  1.7233,  0.7566,  0.8494,  1.6911,  1.5051,  0.8349,
          1.6316,  1.1241,  1.7427,  1.6567,  0.1668, -0.0681, -0.0843,  0.1144,
          0.3696,  0.4892,  0.0585, 14.1893,  6.6110,  0.7607,  1.2301,  1.3262,
          1.5392,  0.9818,  1.4692,  0.4034,  1.6044,  1.7015],
        [ 1.2293,  1.2611,  1.3236,  1.3026,  1.2706,  1.2362,  1.2011,  1.2273,
          1.2273,  1.2033,  1.3265,  1.2234,  1.3581,  1.2811,  1.4107,  1.2030,
          1.2806,  1.2394,  1.2903,  1.3165,  1.3363,  1.3059,  1.2599,  1.2538,
          1.1882,  1.2458,  1.2458,  1.3013,  1.3433,  1.2602,  1.0677,  1.2551,
          1.1390,  1.3095,  1.1336,  1.2634,  1.3482,  1.0401,  1.3720,  1.3638,
          0.9205,  0.8329,  1.3611,  1.3247,  0.7124,  3.3799,  2.5836,  3.5785,
          2.8784,  2.1674,  1.8487,  3.0019,  3.2953,  1.8272]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 247 : 180.03256805309755
Test loss for epoch 247 : 180.1662477189663
Test Precision for epoch 247 : 0.26153846153846155
Test Recall for epoch 247 : 0.26153846153846155
Test F1 for epoch 247 : 0.26153846153846155


theta for epoch 248 : tensor([[ 2.6673,  2.6978,  2.7722,  2.9004,  2.8636,  2.6736,  2.8386,  2.6655,
          2.6655,  1.2466,  1.2694,  1.2628,  1.2946,  1.2332,  1.3376,  1.2464,
          1.2327,  1.2289,  1.2093,  1.1901,  1.2024,  1.2221,  1.1847,  1.1799,
          1.2014,  1.1733,  1.1733,  1.2174,  1.2598,  1.1920,  1.2141,  1.2615,
          1.2018,  1.2324,  1.1519,  1.1946,  1.3690,  1.4178,  1.3925,  1.3810,
          1.3975,  1.3356,  1.3790,  1.3508,  1.3246,  1.3070,  1.2577,  1.2442,
          1.2257,  1.2991,  1.2460,  1.3385,  1.2163,  1.2240],
        [ 1.2418,  1.1683,  1.0433,  1.2218,  1.2986,  1.2925,  1.2218,  1.2833,
          1.2833,  1.5923,  1.7735,  1.5865,  2.2042,  1.6202,  6.2412,  1.6825,
          1.5274,  6.0774,  1.1239,  1.2073,  1.0591,  1.1644,  1.2737,  1.3028,
          1.2740,  1.2943,  1.2943,  1.2885,  1.0839,  1.3111,  1.3030,  1.1363,
          1.3237,  1.3587,  1.2722,  1.3138,  1.3335,  1.4437,  1.3501,  1.2901,
          1.3494,  1.4123,  1.3320,  0.5990,  1.3104,  1.0993,  1.3710,  1.3488,
          1.3250,  1.0880,  1.3556,  0.9942,  1.3127,  1.3272],
        [ 1.1616,  1.1875,  1.2382,  1.2207,  1.1946,  1.1672,  1.1741,  1.1600,
          1.1600,  1.2450,  1.2684,  1.2615,  1.2942,  1.2312,  1.3022,  1.2447,
          1.2014,  1.2612,  2.7281,  2.8555,  2.9152,  2.8005,  2.6623,  2.7080,
          2.7916,  2.6495,  2.6495,  1.2371,  1.2568,  1.1946,  1.2166,  1.2365,
          1.2044,  1.2354,  1.1990,  1.1972,  1.3680,  1.4172,  1.3914,  1.3433,
          1.3962,  1.3921,  1.3782,  1.3321,  1.2856,  1.3042,  1.2620,  1.2484,
          1.2298,  1.2898,  1.2503,  1.3361,  1.2195,  1.2282],
        [ 1.1709,  1.1974,  1.2485,  1.2309,  1.2049,  1.1766,  1.1839,  1.1693,
          1.1693,  1.2546,  1.2777,  1.2715,  1.3044,  1.2406,  1.2590,  1.2544,
          1.2394,  1.1945,  1.2226,  1.2469,  1.2605,  1.2358,  1.1971,  1.1918,
          1.2131,  1.1852,  1.1852,  2.9619,  2.9314,  2.5587,  2.7256,  2.9578,
          2.5694,  2.9140,  2.5662,  2.5614,  1.3671,  1.4178,  1.3911,  1.3779,
          1.3969,  1.3925,  1.3774,  1.2890,  1.3192,  1.3199,  1.2686,  1.1659,
          1.1924,  1.3117,  1.2558,  1.3524,  1.1820,  1.2340],
        [ 1.7177,  1.3953,  0.6320,  0.8520,  1.2086,  1.6120,  1.5483,  1.7150,
          1.7150,  1.5607,  1.2376,  1.3962,  0.8964,  1.6371,  0.2507,  1.5340,
          1.6858,  0.9955,  1.3148,  0.9090,  0.7559,  1.1058,  1.5813,  1.6225,
          1.3884,  1.7225,  1.7225,  0.7569,  0.8478,  1.6911,  1.5049,  0.8346,
          1.6316,  1.1245,  1.7428,  1.6567,  0.1648, -0.0703, -0.0865,  0.1123,
          0.3677,  0.4862,  0.0561, 14.2358,  6.5809,  0.7601,  1.2319,  1.3278,
          1.5406,  0.9812,  1.4707,  0.4019,  1.6060,  1.7028],
        [ 1.2286,  1.2604,  1.3231,  1.3020,  1.2700,  1.2355,  1.2004,  1.2266,
          1.2266,  1.2045,  1.3280,  1.2247,  1.3597,  1.2825,  1.4123,  1.2043,
          1.2818,  1.2413,  1.2879,  1.3139,  1.3340,  1.3035,  1.2575,  1.2513,
          1.1855,  1.2433,  1.2433,  1.2995,  1.3416,  1.2584,  1.0656,  1.2533,
          1.1372,  1.3077,  1.1317,  1.2616,  1.3475,  1.0392,  1.3713,  1.3631,
          0.9190,  0.8318,  1.3606,  1.3229,  0.7110,  3.3849,  2.5860,  3.5842,
          2.8813,  2.1695,  1.8506,  3.0049,  3.3003,  1.8291]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 248 : 180.02597786102245
Test loss for epoch 248 : 180.15951284934766
Test Precision for epoch 248 : 0.26153846153846155
Test Recall for epoch 248 : 0.26153846153846155
Test F1 for epoch 248 : 0.26153846153846155


theta for epoch 249 : tensor([[ 2.6704,  2.7009,  2.7753,  2.9038,  2.8670,  2.6767,  2.8420,  2.6686,
          2.6686,  1.2422,  1.2652,  1.2584,  1.2905,  1.2289,  1.3334,  1.2421,
          1.2283,  1.2251,  1.2070,  1.1878,  1.2000,  1.2198,  1.1824,  1.1775,
          1.1990,  1.1709,  1.1709,  1.2180,  1.2605,  1.1927,  1.2148,  1.2622,
          1.2024,  1.2330,  1.1526,  1.1953,  1.3703,  1.4193,  1.3940,  1.3824,
          1.3987,  1.3371,  1.3805,  1.3513,  1.3261,  1.3078,  1.2585,  1.2450,
          1.2265,  1.2999,  1.2468,  1.3393,  1.2170,  1.2248],
        [ 1.2452,  1.1728,  1.0501,  1.2268,  1.3029,  1.2959,  1.2256,  1.2868,
          1.2868,  1.5932,  1.7723,  1.5868,  2.1996,  1.6206,  6.2351,  1.6826,
          1.5283,  6.0706,  1.1243,  1.2076,  1.0621,  1.1638,  1.2719,  1.3005,
          1.2722,  1.2919,  1.2919,  1.2906,  1.0889,  1.3120,  1.3046,  1.1394,
          1.3246,  1.3596,  1.2732,  1.3148,  1.3366,  1.4456,  1.3521,  1.2931,
          1.3537,  1.4142,  1.3340,  0.6084,  1.3123,  1.1054,  1.3720,  1.3498,
          1.3260,  1.0930,  1.3566,  1.0026,  1.3137,  1.3282],
        [ 1.1655,  1.1914,  1.2421,  1.2246,  1.1985,  1.1711,  1.1780,  1.1639,
          1.1639,  1.2422,  1.2658,  1.2588,  1.2917,  1.2285,  1.2996,  1.2421,
          1.1984,  1.2595,  2.7265,  2.8543,  2.9134,  2.7977,  2.6612,  2.7058,
          2.7910,  2.6484,  2.6484,  1.2388,  1.2591,  1.1966,  1.2186,  1.2383,
          1.2064,  1.2375,  1.2011,  1.1992,  1.3701,  1.4195,  1.3937,  1.3451,
          1.3982,  1.3944,  1.3805,  1.3342,  1.2874,  1.3067,  1.2641,  1.2505,
          1.2319,  1.2926,  1.2524,  1.3386,  1.2216,  1.2303],
        [ 1.1737,  1.2002,  1.2512,  1.2336,  1.2077,  1.1794,  1.1867,  1.1721,
          1.1721,  1.2501,  1.2735,  1.2670,  1.3003,  1.2362,  1.2550,  1.2500,
          1.2350,  1.1910,  1.2199,  1.2442,  1.2578,  1.2331,  1.1943,  1.1891,
          1.2103,  1.1825,  1.1825,  2.9642,  2.9343,  2.5610,  2.7281,  2.9601,
          2.5717,  2.9162,  2.5685,  2.5638,  1.3682,  1.4191,  1.3923,  1.3790,
          1.3978,  1.3937,  1.3786,  1.2894,  1.3203,  1.3205,  1.2693,  1.1665,
          1.1930,  1.3123,  1.2564,  1.3531,  1.1826,  1.2347],
        [ 1.7207,  1.3973,  0.6320,  0.8533,  1.2106,  1.6149,  1.5509,  1.7180,
          1.7180,  1.5570,  1.2324,  1.3923,  0.8900,  1.6329,  0.2435,  1.5296,
          1.6826,  0.9857,  1.3100,  0.9048,  0.7500,  1.1018,  1.5781,  1.6195,
          1.3857,  1.7198,  1.7198,  0.7565,  0.8456,  1.6918,  1.5052,  0.8337,
          1.6323,  1.1248,  1.7435,  1.6574,  0.1653, -0.0700, -0.0863,  0.1126,
          0.3685,  0.4859,  0.0563, 14.2847,  6.5529,  0.7571,  1.2323,  1.3283,
          1.5413,  0.9787,  1.4713,  0.3975,  1.6069,  1.7036],
        [ 1.2311,  1.2630,  1.3257,  1.3046,  1.2726,  1.2380,  1.2029,  1.2291,
          1.2291,  1.1993,  1.3229,  1.2194,  1.3548,  1.2773,  1.4074,  1.1992,
          1.2765,  1.2366,  1.2848,  1.3107,  1.3310,  1.3004,  1.2543,  1.2482,
          1.1820,  1.2401,  1.2401,  1.2996,  1.3418,  1.2585,  1.0654,  1.2534,
          1.1372,  1.3079,  1.1318,  1.2618,  1.3479,  1.0395,  1.3717,  1.3636,
          0.9188,  0.8318,  1.3612,  1.3222,  0.7109,  3.3901,  2.5887,  3.5901,
          2.8844,  2.1719,  1.8528,  3.0081,  3.3055,  1.8313]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 249 : 180.01884993186817
Test loss for epoch 249 : 180.1513976953454
Test Precision for epoch 249 : 0.26153846153846155
Test Recall for epoch 249 : 0.26153846153846155
Test F1 for epoch 249 : 0.26153846153846155


theta for epoch 250 : tensor([[ 2.6702,  2.7008,  2.7752,  2.9039,  2.8672,  2.6765,  2.8422,  2.6684,
          2.6684,  1.2425,  1.2656,  1.2587,  1.2910,  1.2293,  1.3339,  1.2425,
          1.2286,  1.2259,  1.2098,  1.1906,  1.2028,  1.2226,  1.1851,  1.1803,
          1.2017,  1.1737,  1.1737,  1.2194,  1.2618,  1.1940,  1.2161,  1.2635,
          1.2038,  1.2344,  1.1540,  1.1966,  1.3705,  1.4197,  1.3943,  1.3827,
          1.3989,  1.3376,  1.3808,  1.3506,  1.3265,  1.3074,  1.2580,  1.2445,
          1.2260,  1.2995,  1.2462,  1.3389,  1.2165,  1.2243],
        [ 1.2438,  1.1723,  1.0521,  1.2268,  1.3023,  1.2944,  1.2245,  1.2853,
          1.2853,  1.5987,  1.7754,  1.5916,  2.1992,  1.6254,  6.2323,  1.6872,
          1.5337,  6.0672,  1.1279,  1.2111,  1.0682,  1.1663,  1.2735,  1.3015,
          1.2736,  1.2929,  1.2929,  1.2909,  1.0919,  1.3112,  1.3043,  1.1406,
          1.3238,  1.3588,  1.2723,  1.3140,  1.3365,  1.4444,  1.3509,  1.2930,
          1.3549,  1.4132,  1.3327,  0.6147,  1.3111,  1.1080,  1.3693,  1.3471,
          1.3233,  1.0943,  1.3539,  1.0077,  1.3110,  1.3255],
        [ 1.1648,  1.1907,  1.2414,  1.2239,  1.1978,  1.1704,  1.1773,  1.1632,
          1.1632,  1.2411,  1.2648,  1.2577,  1.2909,  1.2276,  1.2986,  1.2411,
          1.1970,  1.2596,  2.7299,  2.8582,  2.9166,  2.7999,  2.6652,  2.7086,
          2.7954,  2.6524,  2.6524,  1.2381,  1.2590,  1.1962,  1.2182,  1.2376,
          1.2060,  1.2371,  1.2007,  1.1989,  1.3687,  1.4184,  1.3925,  1.3433,
          1.3968,  1.3933,  1.3792,  1.3327,  1.2858,  1.3051,  1.2621,  1.2485,
          1.2299,  1.2912,  1.2503,  1.3370,  1.2194,  1.2282],
        [ 1.1731,  1.1997,  1.2507,  1.2331,  1.2072,  1.1789,  1.1862,  1.1715,
          1.1715,  1.2490,  1.2726,  1.2660,  1.2995,  1.2352,  1.2541,  1.2490,
          1.2339,  1.1906,  1.2216,  1.2458,  1.2595,  1.2348,  1.1960,  1.1908,
          1.2120,  1.1841,  1.1841,  2.9665,  2.9372,  2.5633,  2.7306,  2.9624,
          2.5741,  2.9185,  2.5709,  2.5661,  1.3674,  1.4185,  1.3918,  1.3782,
          1.3970,  1.3932,  1.3780,  1.2879,  1.3197,  1.3190,  1.2677,  1.1650,
          1.1914,  1.3109,  1.2550,  1.3516,  1.1809,  1.2331],
        [ 1.7213,  1.3971,  0.6309,  0.8532,  1.2106,  1.6155,  1.5512,  1.7186,
          1.7186,  1.5579,  1.2317,  1.3928,  0.8881,  1.6332,  0.2404,  1.5297,
          1.6837,  0.9805,  1.3107,  0.9063,  0.7498,  1.1034,  1.5805,  1.6221,
          1.3885,  1.7226,  1.7226,  0.7574,  0.8445,  1.6930,  1.5060,  0.8339,
          1.6335,  1.1260,  1.7447,  1.6585,  0.1635, -0.0721, -0.0885,  0.1106,
          0.3669,  0.4831,  0.0541, 14.3322,  6.5221,  0.7533,  1.2312,  1.3270,
          1.5400,  0.9749,  1.4701,  0.3929,  1.6058,  1.7023],
        [ 1.2310,  1.2629,  1.3257,  1.3046,  1.2725,  1.2379,  1.2028,  1.2290,
          1.2290,  1.1987,  1.3225,  1.2189,  1.3546,  1.2768,  1.4072,  1.1987,
          1.2759,  1.2368,  1.2870,  1.3128,  1.3333,  1.3027,  1.2565,  1.2504,
          1.1840,  1.2423,  1.2423,  1.3002,  1.3424,  1.2591,  1.0658,  1.2540,
          1.1378,  1.3084,  1.1323,  1.2623,  1.3466,  1.0385,  1.3704,  1.3624,
          0.9172,  0.8306,  1.3601,  1.3197,  0.7096,  3.3921,  2.5882,  3.5928,
          2.8844,  2.1711,  1.8517,  3.0082,  3.3074,  1.8302]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 250 : 180.00862042983513
Test loss for epoch 250 : 180.14108605821582
Test Precision for epoch 250 : 0.26153846153846155
Test Recall for epoch 250 : 0.26153846153846155
Test F1 for epoch 250 : 0.26153846153846155


theta for epoch 251 : tensor([[ 2.6698,  2.7004,  2.7748,  2.9038,  2.8671,  2.6761,  2.8420,  2.6680,
          2.6680,  1.2464,  1.2696,  1.2626,  1.2951,  1.2332,  1.3379,  1.2464,
          1.2324,  1.2303,  1.2122,  1.1930,  1.2053,  1.2250,  1.1875,  1.1827,
          1.2041,  1.1761,  1.1761,  1.2187,  1.2612,  1.1934,  1.2155,  1.2628,
          1.2031,  1.2337,  1.1533,  1.1960,  1.3698,  1.4193,  1.3939,  1.3821,
          1.3982,  1.3373,  1.3804,  1.3490,  1.3261,  1.3074,  1.2579,  1.2444,
          1.2259,  1.2995,  1.2461,  1.3390,  1.2163,  1.2242],
        [ 1.2392,  1.1688,  1.0512,  1.2238,  1.2988,  1.2899,  1.2204,  1.2808,
          1.2808,  1.6084,  1.7827,  1.6007,  2.2027,  1.6344,  6.2326,  1.6960,
          1.5433,  6.0670,  1.1303,  1.2134,  1.0731,  1.1676,  1.2738,  1.3014,
          1.2737,  1.2928,  1.2928,  1.2883,  1.0919,  1.3073,  1.3012,  1.1388,
          1.3199,  1.3550,  1.2684,  1.3101,  1.3348,  1.4417,  1.3480,  1.2911,
          1.3546,  1.4105,  1.3298,  0.6193,  1.3083,  1.1101,  1.3661,  1.3439,
          1.3201,  1.0950,  1.3507,  1.0123,  1.3077,  1.3222],
        [ 1.1625,  1.1884,  1.2391,  1.2217,  1.1955,  1.1681,  1.1750,  1.1609,
          1.1609,  1.2437,  1.2675,  1.2603,  1.2936,  1.2302,  1.3012,  1.2437,
          1.1992,  1.2632,  2.7332,  2.8621,  2.9197,  2.8020,  2.6691,  2.7114,
          2.7998,  2.6563,  2.6563,  1.2356,  1.2571,  1.1940,  1.2160,  1.2350,
          1.2038,  1.2350,  1.1984,  1.1966,  1.3666,  1.4166,  1.3906,  1.3408,
          1.3947,  1.3915,  1.3773,  1.3304,  1.2835,  1.3042,  1.2607,  1.2470,
          1.2284,  1.2905,  1.2489,  1.3361,  1.2179,  1.2267],
        [ 1.1714,  1.1980,  1.2491,  1.2315,  1.2054,  1.1771,  1.1845,  1.1698,
          1.1698,  1.2521,  1.2758,  1.2691,  1.3028,  1.2384,  1.2574,  1.2522,
          1.2370,  1.1941,  1.2236,  1.2478,  1.2616,  1.2368,  1.1979,  1.1928,
          1.2139,  1.1861,  1.1861,  2.9676,  2.9387,  2.5643,  2.7319,  2.9635,
          2.5751,  2.9195,  2.5719,  2.5671,  1.3663,  1.4177,  1.3909,  1.3772,
          1.3959,  1.3925,  1.3771,  1.2862,  1.3189,  1.3186,  1.2672,  1.1646,
          1.1908,  1.3104,  1.2545,  1.3512,  1.1802,  1.2325],
        [ 1.7210,  1.3961,  0.6296,  0.8529,  1.2102,  1.6153,  1.5506,  1.7183,
          1.7183,  1.5632,  1.2355,  1.3976,  0.8904,  1.6378,  0.2410,  1.5341,
          1.6892,  0.9796,  1.3121,  0.9088,  0.7507,  1.1060,  1.5834,  1.6253,
          1.3920,  1.7259,  1.7259,  0.7582,  0.8431,  1.6932,  1.5061,  0.8339,
          1.6338,  1.1268,  1.7449,  1.6588,  0.1601, -0.0756, -0.0920,  0.1072,
          0.3637,  0.4787,  0.0504, 14.3790,  6.4892,  0.7517,  1.2320,  1.3276,
          1.5403,  0.9732,  1.4705,  0.3905,  1.6062,  1.7024],
        [ 1.2291,  1.2612,  1.3241,  1.3029,  1.2708,  1.2361,  1.2010,  1.2272,
          1.2272,  1.2021,  1.3261,  1.2224,  1.3584,  1.2803,  1.4110,  1.2023,
          1.2793,  1.2410,  1.2892,  1.3147,  1.3355,  1.3049,  1.2585,  1.2525,
          1.1858,  1.2443,  1.2443,  1.2992,  1.3414,  1.2580,  1.0646,  1.2530,
          1.1367,  1.3074,  1.1312,  1.2612,  1.3444,  1.0366,  1.3683,  1.3603,
          0.9147,  0.8287,  1.3582,  1.3162,  0.7074,  3.3944,  2.5879,  3.5956,
          2.8845,  2.1704,  1.8508,  3.0084,  3.3096,  1.8293]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 251 : 180.00425945647967
Test loss for epoch 251 : 180.13685970211205
Test Precision for epoch 251 : 0.26153846153846155
Test Recall for epoch 251 : 0.26153846153846155
Test F1 for epoch 251 : 0.26153846153846155


theta for epoch 252 : tensor([[ 2.6735,  2.7041,  2.7785,  2.9078,  2.8711,  2.6798,  2.8460,  2.6717,
          2.6717,  1.2439,  1.2672,  1.2601,  1.2929,  1.2308,  1.3357,  1.2441,
          1.2300,  1.2283,  1.2090,  1.1898,  1.2021,  1.2218,  1.1843,  1.1795,
          1.2009,  1.1729,  1.1729,  1.2176,  1.2601,  1.1923,  1.2144,  1.2617,
          1.2021,  1.2326,  1.1522,  1.1949,  1.3702,  1.4199,  1.3944,  1.3825,
          1.3986,  1.3379,  1.3809,  1.3483,  1.3267,  1.3081,  1.2585,  1.2449,
          1.2264,  1.3001,  1.2467,  1.3396,  1.2168,  1.2247],
        [ 1.2397,  1.1704,  1.0555,  1.2258,  1.3002,  1.2903,  1.2212,  1.2812,
          1.2812,  1.6125,  1.7842,  1.6040,  2.2003,  1.6378,  6.2267,  1.6991,
          1.5474,  6.0605,  1.1307,  1.2136,  1.0761,  1.1666,  1.2717,  1.2986,
          1.2714,  1.2900,  1.2900,  1.2893,  1.0958,  1.3070,  1.3015,  1.1410,
          1.3195,  1.3546,  1.2681,  1.3098,  1.3372,  1.4429,  1.3492,  1.2934,
          1.3583,  1.4119,  1.3310,  0.6288,  1.3095,  1.1169,  1.3671,  1.3449,
          1.3211,  1.1004,  1.3517,  1.0216,  1.3087,  1.3232],
        [ 1.1641,  1.1901,  1.2407,  1.2233,  1.1972,  1.1697,  1.1767,  1.1625,
          1.1625,  1.2436,  1.2676,  1.2602,  1.2938,  1.2302,  1.3012,  1.2438,
          1.1989,  1.2643,  2.7318,  2.8612,  2.9181,  2.7993,  2.6682,  2.7094,
          2.7994,  2.6554,  2.6554,  1.2364,  1.2585,  1.1951,  1.2172,  1.2359,
          1.2050,  1.2361,  1.1996,  1.1978,  1.3683,  1.4185,  1.3925,  1.3422,
          1.3964,  1.3935,  1.3792,  1.3318,  1.2850,  1.3070,  1.2631,  1.2494,
          1.2308,  1.2936,  1.2513,  1.3391,  1.2202,  1.2291],
        [ 1.1724,  1.1989,  1.2499,  1.2324,  1.2064,  1.1781,  1.1854,  1.1707,
          1.1707,  1.2510,  1.2748,  1.2680,  1.3020,  1.2374,  1.2567,  1.2512,
          1.2359,  1.1938,  1.2213,  1.2455,  1.2593,  1.2346,  1.1956,  1.1905,
          1.2115,  1.1837,  1.1837,  2.9690,  2.9407,  2.5657,  2.7334,  2.9649,
          2.5765,  2.9209,  2.5733,  2.5685,  1.3674,  1.4190,  1.3922,  1.3783,
          1.3970,  1.3938,  1.3783,  1.2864,  1.3201,  1.3202,  1.2687,  1.1660,
          1.1922,  1.3120,  1.2559,  1.3528,  1.1816,  1.2340],
        [ 1.7223,  1.3964,  0.6284,  0.8529,  1.2107,  1.6166,  1.5515,  1.7197,
          1.7197,  1.5626,  1.2331,  1.3967,  0.8865,  1.6367,  0.2358,  1.5327,
          1.6891,  0.9722,  1.3075,  0.9051,  0.7451,  1.1024,  1.5807,  1.6229,
          1.3898,  1.7237,  1.7237,  0.7577,  0.8407,  1.6936,  1.5059,  0.8326,
          1.6341,  1.1269,  1.7452,  1.6591,  0.1599, -0.0761, -0.0926,  0.1068,
          0.3637,  0.4776,  0.0498, 14.4286,  6.4588,  0.7495,  1.2333,  1.3289,
          1.5417,  0.9714,  1.4719,  0.3868,  1.6079,  1.7039],
        [ 1.2302,  1.2623,  1.3252,  1.3040,  1.2719,  1.2372,  1.2022,  1.2283,
          1.2283,  1.2009,  1.3250,  1.2212,  1.3576,  1.2791,  1.4102,  1.2012,
          1.2780,  1.2405,  1.2868,  1.3122,  1.3332,  1.3025,  1.2561,  1.2500,
          1.1831,  1.2418,  1.2418,  1.2995,  1.3418,  1.2582,  1.0646,  1.2534,
          1.1370,  1.3077,  1.1315,  1.2614,  1.3451,  1.0375,  1.3689,  1.3610,
          0.9151,  0.8294,  1.3591,  1.3155,  0.7080,  3.3979,  2.5888,  3.5997,
          2.8858,  2.1711,  1.8513,  3.0099,  3.3130,  1.8298]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 252 : 179.9916258665077
Test loss for epoch 252 : 180.1245070841609
Test Precision for epoch 252 : 0.26153846153846155
Test Recall for epoch 252 : 0.26153846153846155
Test F1 for epoch 252 : 0.26153846153846155


theta for epoch 253 : tensor([[ 2.6768,  2.7073,  2.7818,  2.9114,  2.8746,  2.6831,  2.8496,  2.6750,
          2.6750,  1.2404,  1.2639,  1.2567,  1.2898,  1.2274,  1.3325,  1.2407,
          1.2265,  1.2254,  1.2072,  1.1879,  1.2003,  1.2200,  1.1825,  1.1777,
          1.1990,  1.1710,  1.1710,  1.2175,  1.2601,  1.1923,  1.2144,  1.2617,
          1.2020,  1.2326,  1.1521,  1.1949,  1.3708,  1.4207,  1.3952,  1.3831,
          1.3991,  1.3387,  1.3816,  1.3479,  1.3275,  1.3080,  1.2584,  1.2448,
          1.2262,  1.3001,  1.2465,  1.3396,  1.2167,  1.2245],
        [ 1.2398,  1.1719,  1.0598,  1.2277,  1.3013,  1.2903,  1.2218,  1.2812,
          1.2812,  1.6158,  1.7848,  1.6066,  2.1968,  1.6404,  6.2191,  1.7014,
          1.5506,  6.0521,  1.1328,  1.2155,  1.0809,  1.1673,  1.2712,  1.2974,
          1.2706,  1.2888,  1.2888,  1.2916,  1.1010,  1.3078,  1.3032,  1.1446,
          1.3204,  1.3554,  1.2690,  1.3107,  1.3399,  1.4445,  1.3507,  1.2960,
          1.3623,  1.4135,  1.3325,  0.6392,  1.3111,  1.1234,  1.3675,  1.3454,
          1.3216,  1.1056,  1.3521,  1.0310,  1.3091,  1.3236],
        [ 1.1646,  1.1905,  1.2412,  1.2237,  1.1976,  1.1702,  1.1771,  1.1630,
          1.1630,  1.2417,  1.2658,  1.2583,  1.2922,  1.2284,  1.2995,  1.2420,
          1.1966,  1.2636,  2.7323,  2.8623,  2.9185,  2.7987,  2.6693,  2.7094,
          2.8010,  2.6565,  2.6565,  1.2372,  1.2599,  1.1963,  1.2183,  1.2367,
          1.2061,  1.2373,  1.2007,  1.1989,  1.3695,  1.4200,  1.3938,  1.3429,
          1.3975,  1.3950,  1.3805,  1.3326,  1.2859,  1.3082,  1.2639,  1.2502,
          1.2315,  1.2951,  1.2520,  1.3404,  1.2208,  1.2298],
        [ 1.1728,  1.1993,  1.2503,  1.2328,  1.2067,  1.1785,  1.1858,  1.1712,
          1.1712,  1.2487,  1.2728,  1.2657,  1.3000,  1.2352,  1.2548,  1.2490,
          1.2336,  1.1924,  1.2203,  1.2444,  1.2583,  1.2335,  1.1945,  1.1894,
          1.2104,  1.1826,  1.1826,  2.9708,  2.9430,  2.5675,  2.7354,  2.9667,
          2.5783,  2.9226,  2.5751,  2.5703,  1.3685,  1.4204,  1.3935,  1.3795,
          1.3981,  1.3952,  1.3796,  1.2867,  1.3214,  1.3210,  1.2694,  1.1667,
          1.1928,  1.3128,  1.2566,  1.3536,  1.1822,  1.2346],
        [ 1.7235,  1.3966,  0.6272,  0.8531,  1.2112,  1.6178,  1.5523,  1.7209,
          1.7209,  1.5614,  1.2301,  1.3950,  0.8821,  1.6347,  0.2303,  1.5305,
          1.6882,  0.9640,  1.3045,  0.9031,  0.7414,  1.1007,  1.5796,  1.6222,
          1.3894,  1.7232,  1.7232,  0.7585,  0.8396,  1.6950,  1.5070,  0.8326,
          1.6356,  1.1283,  1.7467,  1.6605,  0.1591, -0.0771, -0.0937,  0.1059,
          0.3631,  0.4758,  0.0487, 14.4782,  6.4271,  0.7472,  1.2343,  1.3298,
          1.5426,  0.9693,  1.4728,  0.3831,  1.6091,  1.7048],
        [ 1.2308,  1.2629,  1.3258,  1.3045,  1.2724,  1.2377,  1.2027,  1.2288,
          1.2288,  1.1984,  1.3228,  1.2188,  1.3555,  1.2767,  1.4082,  1.1989,
          1.2755,  1.2389,  1.2857,  1.3109,  1.3323,  1.3015,  1.2549,  1.2489,
          1.1817,  1.2406,  1.2406,  1.3007,  1.3430,  1.2593,  1.0655,  1.2545,
          1.1381,  1.3088,  1.1326,  1.2625,  1.3457,  1.0385,  1.3696,  1.3618,
          0.9155,  0.8302,  1.3600,  1.3148,  0.7086,  3.4010,  2.5894,  3.6033,
          2.8868,  2.1714,  1.8514,  3.0111,  3.3161,  1.8298]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 253 : 179.98700751658708
Test loss for epoch 253 : 180.1196904093369
Test Precision for epoch 253 : 0.26153846153846155
Test Recall for epoch 253 : 0.26153846153846155
Test F1 for epoch 253 : 0.26153846153846155


theta for epoch 254 : tensor([[ 2.6765,  2.7071,  2.7816,  2.9114,  2.8747,  2.6828,  2.8497,  2.6747,
          2.6747,  1.2427,  1.2664,  1.2590,  1.2924,  1.2298,  1.3351,  1.2431,
          1.2288,  1.2284,  1.2096,  1.1902,  1.2026,  1.2224,  1.1848,  1.1801,
          1.2013,  1.1733,  1.1733,  1.2178,  1.2605,  1.1926,  1.2147,  1.2620,
          1.2023,  1.2329,  1.1524,  1.1951,  1.3708,  1.4210,  1.3954,  1.3832,
          1.3991,  1.3390,  1.3818,  1.3469,  1.3278,  1.3073,  1.2576,  1.2440,
          1.2254,  1.2994,  1.2457,  1.3390,  1.2158,  1.2237],
        [ 1.2354,  1.1689,  1.0598,  1.2251,  1.2980,  1.2859,  1.2179,  1.2768,
          1.2768,  1.6251,  1.7913,  1.6151,  2.1989,  1.6489,  6.2162,  1.7096,
          1.5598,  6.0487,  1.1361,  1.2187,  1.0869,  1.1691,  1.2721,  1.2976,
          1.2711,  1.2889,  1.2889,  1.2906,  1.1028,  1.3054,  1.3016,  1.1449,
          1.3179,  1.3531,  1.2665,  1.3083,  1.3392,  1.4427,  1.3488,  1.2952,
          1.3630,  1.4119,  1.3305,  0.6460,  1.3094,  1.1260,  1.3639,  1.3419,
          1.3180,  1.1066,  1.3485,  1.0365,  1.3055,  1.3200],
        [ 1.1616,  1.1876,  1.2382,  1.2208,  1.1947,  1.1672,  1.1742,  1.1600,
          1.1600,  1.2424,  1.2667,  1.2591,  1.2932,  1.2292,  1.3003,  1.2428,
          1.1970,  1.2654,  2.7367,  2.8672,  2.9228,  2.8019,  2.6743,  2.7133,
          2.8065,  2.6615,  2.6615,  1.2351,  1.2585,  1.1945,  1.2166,  1.2346,
          1.2043,  1.2355,  1.1989,  1.1971,  1.3677,  1.4185,  1.3922,  1.3407,
          1.3958,  1.3935,  1.3789,  1.3304,  1.2839,  1.3059,  1.2611,  1.2474,
          1.2286,  1.2929,  1.2492,  1.3381,  1.2179,  1.2269],
        [ 1.1711,  1.1976,  1.2487,  1.2312,  1.2051,  1.1768,  1.1841,  1.1695,
          1.1695,  1.2508,  1.2750,  1.2678,  1.3024,  1.2373,  1.2571,  1.2512,
          1.2356,  1.1950,  1.2225,  1.2466,  1.2605,  1.2357,  1.1967,  1.1917,
          1.2126,  1.1848,  1.1848,  2.9719,  2.9446,  2.5686,  2.7367,  2.9679,
          2.5794,  2.9237,  2.5762,  2.5714,  1.3682,  1.4204,  1.3934,  1.3792,
          1.3978,  1.3952,  1.3795,  1.2855,  1.3214,  1.3201,  1.2684,  1.1658,
          1.1918,  1.3119,  1.2557,  1.3528,  1.1811,  1.2336],
        [ 1.7234,  1.3958,  0.6262,  0.8532,  1.2111,  1.6179,  1.5520,  1.7209,
          1.7209,  1.5658,  1.2329,  1.3991,  0.8837,  1.6384,  0.2304,  1.5340,
          1.6929,  0.9619,  1.3063,  0.9064,  0.7429,  1.1040,  1.5832,  1.6261,
          1.3937,  1.7271,  1.7271,  0.7608,  0.8397,  1.6967,  1.5084,  0.8339,
          1.6373,  1.1307,  1.7483,  1.6622,  0.1552, -0.0810, -0.0977,  0.1019,
          0.3594,  0.4708,  0.0445, 14.5258,  6.3917,  0.7458,  1.2352,  1.3305,
          1.5429,  0.9676,  1.4732,  0.3810,  1.6094,  1.7048],
        [ 1.2287,  1.2608,  1.3238,  1.3025,  1.2704,  1.2356,  1.2007,  1.2267,
          1.2267,  1.2002,  1.3248,  1.2207,  1.3579,  1.2786,  1.4105,  1.2008,
          1.2772,  1.2415,  1.2876,  1.3126,  1.3342,  1.3034,  1.2567,  1.2507,
          1.1832,  1.2424,  1.2424,  1.3004,  1.3428,  1.2589,  1.0649,  1.2543,
          1.1377,  1.3085,  1.1322,  1.2622,  1.3441,  1.0370,  1.3680,  1.3603,
          0.9134,  0.8285,  1.3586,  1.3117,  0.7067,  3.4036,  2.5894,  3.6064,
          2.8872,  2.1711,  1.8508,  3.0116,  3.3185,  1.8292]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 254 : 179.97551165573208
Test loss for epoch 254 : 180.10765836230436
Test Precision for epoch 254 : 0.26153846153846155
Test Recall for epoch 254 : 0.26153846153846155
Test F1 for epoch 254 : 0.26153846153846155


theta for epoch 255 : tensor([[ 2.6771,  2.7077,  2.7822,  2.9124,  2.8756,  2.6834,  2.8506,  2.6753,
          2.6753,  1.2439,  1.2678,  1.2602,  1.2940,  1.2311,  1.3366,  1.2444,
          1.2300,  1.2303,  1.2099,  1.1905,  1.2029,  1.2227,  1.1851,  1.1804,
          1.2016,  1.1736,  1.1736,  1.2178,  1.2605,  1.1926,  1.2147,  1.2620,
          1.2023,  1.2329,  1.1524,  1.1952,  1.3716,  1.4220,  1.3963,  1.3840,
          1.3999,  1.3401,  1.3827,  1.3465,  1.3288,  1.3071,  1.2573,  1.2437,
          1.2251,  1.2992,  1.2454,  1.3387,  1.2155,  1.2234],
        [ 1.2336,  1.1685,  1.0625,  1.2252,  1.2974,  1.2841,  1.2167,  1.2750,
          1.2750,  1.6335,  1.7967,  1.6226,  2.1997,  1.6564,  6.2113,  1.7168,
          1.5681,  6.0431,  1.1379,  1.2203,  1.0914,  1.1692,  1.2712,  1.2959,
          1.2697,  1.2872,  1.2872,  1.2899,  1.1048,  1.3031,  1.3002,  1.1455,
          1.3157,  1.3508,  1.2642,  1.3060,  1.3398,  1.4421,  1.3481,  1.2957,
          1.3648,  1.4114,  1.3298,  0.6546,  1.3088,  1.1296,  1.3612,  1.3392,
          1.3154,  1.1087,  1.3458,  1.0432,  1.3028,  1.3172],
        [ 1.1616,  1.1877,  1.2383,  1.2209,  1.1948,  1.1673,  1.1742,  1.1601,
          1.1601,  1.2433,  1.2677,  1.2599,  1.2944,  1.2302,  1.3012,  1.2438,
          1.1975,  1.2674,  2.7380,  2.8691,  2.9239,  2.8019,  2.6762,  2.7140,
          2.8089,  2.6634,  2.6634,  1.2341,  1.2581,  1.1938,  1.2159,  1.2336,
          1.2037,  1.2349,  1.1982,  1.1964,  1.3677,  1.4189,  1.3925,  1.3403,
          1.3958,  1.3939,  1.3791,  1.3300,  1.2838,  1.3052,  1.2600,  1.2462,
          1.2274,  1.2925,  1.2480,  1.3375,  1.2166,  1.2257],
        [ 1.1714,  1.1980,  1.2490,  1.2316,  1.2054,  1.1771,  1.1845,  1.1698,
          1.1698,  1.2518,  1.2762,  1.2688,  1.3037,  1.2385,  1.2585,  1.2523,
          1.2366,  1.1967,  1.2226,  1.2466,  1.2606,  1.2358,  1.1968,  1.1917,
          1.2125,  1.1848,  1.1848,  2.9729,  2.9460,  2.5696,  2.7378,  2.9689,
          2.5803,  2.9247,  2.5771,  2.5724,  1.3687,  1.4211,  1.3941,  1.3797,
          1.3982,  1.3960,  1.3801,  1.2850,  1.3220,  1.3196,  1.2679,  1.1654,
          1.1912,  1.3114,  1.2552,  1.3523,  1.1804,  1.2330],
        [ 1.7244,  1.3957,  0.6249,  0.8533,  1.2115,  1.6190,  1.5525,  1.7219,
          1.7219,  1.5680,  1.2332,  1.4009,  0.8824,  1.6399,  0.2274,  1.5352,
          1.6955,  0.9568,  1.3044,  0.9056,  0.7403,  1.1035,  1.5833,  1.6268,
          1.3946,  1.7279,  1.7279,  0.7609,  0.8378,  1.6971,  1.5083,  0.8330,
          1.6378,  1.1313,  1.7487,  1.6626,  0.1534, -0.0829, -0.0998,  0.1001,
          0.3577,  0.4680,  0.0424, 14.5756,  6.3578,  0.7422,  1.2349,  1.3300,
          1.5424,  0.9642,  1.4728,  0.3762,  1.6092,  1.7043],
        [ 1.2288,  1.2610,  1.3240,  1.3027,  1.2705,  1.2357,  1.2008,  1.2268,
          1.2268,  1.2009,  1.3258,  1.2214,  1.3590,  1.2794,  1.4116,  1.2016,
          1.2778,  1.2431,  1.2873,  1.3120,  1.3340,  1.3031,  1.2562,  1.2503,
          1.1824,  1.2419,  1.2419,  1.2998,  1.3422,  1.2582,  1.0639,  1.2538,
          1.1370,  1.3079,  1.1314,  1.2615,  1.3435,  1.0366,  1.3673,  1.3597,
          0.9124,  0.8279,  1.3582,  1.3095,  0.7059,  3.4064,  2.5896,  3.6097,
          2.8879,  2.1710,  1.8505,  3.0124,  3.3213,  1.8289]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 255 : 179.96792050955608
Test loss for epoch 255 : 180.10080195539595
Test Precision for epoch 255 : 0.26153846153846155
Test Recall for epoch 255 : 0.26153846153846155
Test F1 for epoch 255 : 0.26153846153846155


theta for epoch 256 : tensor([[ 2.6796,  2.7102,  2.7847,  2.9151,  2.8784,  2.6859,  2.8533,  2.6778,
          2.6778,  1.2407,  1.2648,  1.2571,  1.2912,  1.2281,  1.3338,  1.2414,
          1.2268,  1.2278,  1.2080,  1.1886,  1.2011,  1.2208,  1.1831,  1.1785,
          1.1996,  1.1717,  1.1717,  1.2181,  1.2609,  1.1929,  1.2150,  1.2624,
          1.2026,  1.2333,  1.1527,  1.1955,  1.3725,  1.4232,  1.3975,  1.3850,
          1.4008,  1.3413,  1.3839,  1.3463,  1.3299,  1.3081,  1.2582,  1.2446,
          1.2261,  1.3002,  1.2464,  1.3398,  1.2164,  1.2243],
        [ 1.2354,  1.1719,  1.0691,  1.2290,  1.3003,  1.2858,  1.2191,  1.2767,
          1.2767,  1.6378,  1.7979,  1.6261,  2.1962,  1.6599,  6.2017,  1.7200,
          1.5723,  6.0327,  1.1393,  1.2214,  1.0957,  1.1688,  1.2696,  1.2935,
          1.2677,  1.2848,  1.2848,  1.2915,  1.1094,  1.3031,  1.3011,  1.1488,
          1.3156,  1.3508,  1.2642,  1.3061,  1.3421,  1.4432,  1.3492,  1.2980,
          1.3683,  1.4126,  1.3309,  0.6657,  1.3100,  1.1366,  1.3615,  1.3396,
          1.3158,  1.1142,  1.3462,  1.0535,  1.3032,  1.3176],
        [ 1.1646,  1.1907,  1.2413,  1.2239,  1.1978,  1.1702,  1.1772,  1.1630,
          1.1630,  1.2417,  1.2663,  1.2584,  1.2932,  1.2288,  1.2998,  1.2423,
          1.1957,  1.2670,  2.7364,  2.8682,  2.9223,  2.7991,  2.6752,  2.7119,
          2.8084,  2.6624,  2.6624,  1.2354,  1.2599,  1.1953,  1.2174,  1.2349,
          1.2052,  1.2364,  1.1998,  1.1980,  1.3694,  1.4208,  1.3943,  1.3416,
          1.3975,  1.3959,  1.3809,  1.3310,  1.2852,  1.3074,  1.2617,  1.2480,
          1.2292,  1.2949,  1.2498,  1.3397,  1.2182,  1.2274],
        [ 1.1734,  1.2000,  1.2510,  1.2336,  1.2075,  1.1792,  1.1865,  1.1718,
          1.1718,  1.2488,  1.2734,  1.2659,  1.3011,  1.2356,  1.2559,  1.2495,
          1.2337,  1.1948,  1.2204,  1.2445,  1.2584,  1.2336,  1.1945,  1.1895,
          1.2103,  1.1826,  1.1826,  2.9748,  2.9483,  2.5714,  2.7398,  2.9707,
          2.5821,  2.9265,  2.5789,  2.5742,  1.3695,  1.4221,  1.3951,  1.3805,
          1.3989,  1.3970,  1.3810,  1.2847,  1.3230,  1.3204,  1.2686,  1.1660,
          1.1918,  1.3122,  1.2558,  1.3531,  1.1810,  1.2337],
        [ 1.7266,  1.3964,  0.6236,  0.8537,  1.2126,  1.6212,  1.5541,  1.7242,
          1.7242,  1.5656,  1.2286,  1.3980,  0.8762,  1.6368,  0.2197,  1.5318,
          1.6936,  0.9465,  1.2993,  0.9015,  0.7342,  1.0998,  1.5805,  1.6246,
          1.3926,  1.7259,  1.7259,  0.7601,  0.8351,  1.6976,  1.5082,  0.8312,
          1.6383,  1.1313,  1.7493,  1.6630,  0.1534, -0.0832, -0.1002,  0.0999,
          0.3579,  0.4670,  0.0420, 14.6275,  6.3252,  0.7385,  1.2352,  1.3304,
          1.5430,  0.9610,  1.4733,  0.3705,  1.6101,  1.7050],
        [ 1.2308,  1.2631,  1.3262,  1.3049,  1.2727,  1.2378,  1.2029,  1.2289,
          1.2289,  1.1975,  1.3226,  1.2180,  1.3560,  1.2760,  1.4086,  1.1983,
          1.2743,  1.2406,  1.2847,  1.3093,  1.3316,  1.3006,  1.2536,  1.2477,
          1.1795,  1.2392,  1.2392,  1.2999,  1.3423,  1.2582,  1.0636,  1.2538,
          1.1370,  1.3080,  1.1314,  1.2615,  1.3435,  1.0368,  1.3673,  1.3598,
          0.9119,  0.8278,  1.3584,  1.3078,  0.7055,  3.4105,  2.5912,  3.6144,
          2.8899,  2.1723,  1.8516,  3.0145,  3.3254,  1.8300]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 256 : 179.95870524100897
Test loss for epoch 256 : 180.0920691755427
Test Precision for epoch 256 : 0.26153846153846155
Test Recall for epoch 256 : 0.26153846153846155
Test F1 for epoch 256 : 0.26153846153846155


theta for epoch 257 : tensor([[ 2.6801,  2.7107,  2.7853,  2.9160,  2.8792,  2.6864,  2.8542,  2.6783,
          2.6783,  1.2409,  1.2652,  1.2573,  1.2918,  1.2283,  1.3343,  1.2417,
          1.2269,  1.2288,  1.2091,  1.1897,  1.2022,  1.2219,  1.1842,  1.1795,
          1.2007,  1.1727,  1.1727,  1.2184,  1.2611,  1.1932,  1.2153,  1.2626,
          1.2029,  1.2335,  1.1530,  1.1957,  1.3723,  1.4232,  1.3975,  1.3848,
          1.4006,  1.3414,  1.3838,  1.3449,  1.3300,  1.3089,  1.2589,  1.2453,
          1.2267,  1.3010,  1.2470,  1.3406,  1.2170,  1.2250],
        [ 1.2332,  1.1715,  1.0720,  1.2290,  1.2993,  1.2836,  1.2176,  1.2745,
          1.2745,  1.6459,  1.8028,  1.6333,  2.1961,  1.6671,  6.1945,  1.7268,
          1.5804,  6.0248,  1.1425,  1.2244,  1.1016,  1.1701,  1.2698,  1.2928,
          1.2673,  1.2841,  1.2841,  1.2915,  1.1120,  1.3013,  1.3004,  1.1504,
          1.3139,  1.3490,  1.2624,  1.3043,  1.3418,  1.4418,  1.3476,  1.2976,
          1.3693,  1.4113,  1.3293,  0.6744,  1.3086,  1.1418,  1.3600,  1.3381,
          1.3143,  1.1179,  1.3446,  1.0621,  1.3016,  1.3160],
        [ 1.1641,  1.1902,  1.2409,  1.2235,  1.1973,  1.1697,  1.1767,  1.1625,
          1.1625,  1.2416,  1.2664,  1.2583,  1.2934,  1.2287,  1.2998,  1.2423,
          1.1952,  1.2681,  2.7382,  2.8706,  2.9239,  2.7997,  2.6776,  2.7131,
          2.8113,  2.6648,  2.6648,  1.2346,  1.2597,  1.1949,  1.2170,  1.2341,
          1.2048,  1.2360,  1.1994,  1.1976,  1.3684,  1.4201,  1.3935,  1.3402,
          1.3965,  1.3952,  1.3801,  1.3294,  1.2840,  1.3076,  1.2615,  1.2477,
          1.2289,  1.2953,  1.2495,  1.3400,  1.2179,  1.2271],
        [ 1.1729,  1.1995,  1.2505,  1.2331,  1.2069,  1.1786,  1.1859,  1.1712,
          1.1712,  1.2485,  1.2734,  1.2656,  1.3012,  1.2354,  1.2560,  1.2493,
          1.2333,  1.1953,  1.2210,  1.2450,  1.2590,  1.2342,  1.1951,  1.1901,
          1.2107,  1.1831,  1.1831,  2.9765,  2.9506,  2.5731,  2.7417,  2.9725,
          2.5839,  2.9282,  2.5807,  2.5759,  1.3688,  1.4217,  1.3946,  1.3798,
          1.3982,  1.3966,  1.3805,  1.2830,  1.3225,  1.3204,  1.2685,  1.1660,
          1.1916,  1.3122,  1.2558,  1.3532,  1.1807,  1.2336],
        [ 1.7275,  1.3961,  0.6224,  0.8539,  1.2130,  1.6222,  1.5545,  1.7251,
          1.7251,  1.5673,  1.2284,  1.3993,  0.8745,  1.6377,  0.2164,  1.5324,
          1.6956,  0.9409,  1.2985,  0.9020,  0.7329,  1.1007,  1.5819,  1.6266,
          1.3949,  1.7280,  1.7280,  0.7612,  0.8342,  1.6989,  1.5089,  0.8311,
          1.6396,  1.1329,  1.7505,  1.6643,  0.1505, -0.0862, -0.1033,  0.0970,
          0.3551,  0.4631,  0.0388, 14.6775,  6.2890,  0.7369,  1.2368,  1.3317,
          1.5442,  0.9594,  1.4746,  0.3675,  1.6115,  1.7060],
        [ 1.2303,  1.2626,  1.3258,  1.3045,  1.2722,  1.2373,  1.2024,  1.2284,
          1.2284,  1.1971,  1.3224,  1.2177,  1.3562,  1.2757,  1.4087,  1.1981,
          1.2739,  1.2412,  1.2852,  1.3095,  1.3322,  1.3011,  1.2539,  1.2480,
          1.1795,  1.2395,  1.2395,  1.2995,  1.3420,  1.2577,  1.0628,  1.2534,
          1.1365,  1.3076,  1.1309,  1.2610,  1.3415,  1.0351,  1.3653,  1.3580,
          0.9095,  0.8258,  1.3567,  1.3041,  0.7032,  3.4140,  2.5921,  3.6183,
          2.8912,  2.1730,  1.8520,  3.0159,  3.3289,  1.8304]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 257 : 179.9480360503652
Test loss for epoch 257 : 180.08080301393352
Test Precision for epoch 257 : 0.26153846153846155
Test Recall for epoch 257 : 0.26153846153846155
Test F1 for epoch 257 : 0.26153846153846155


theta for epoch 258 : tensor([[ 2.6804,  2.7110,  2.7856,  2.9165,  2.8798,  2.6867,  2.8547,  2.6786,
          2.6786,  1.2429,  1.2675,  1.2594,  1.2942,  1.2305,  1.3366,  1.2439,
          1.2290,  1.2316,  1.2110,  1.1915,  1.2041,  1.2238,  1.1860,  1.1814,
          1.2025,  1.1745,  1.1745,  1.2180,  1.2607,  1.1927,  1.2149,  1.2622,
          1.2025,  1.2331,  1.1526,  1.1953,  1.3723,  1.4235,  1.3977,  1.3849,
          1.4006,  1.3418,  1.3840,  1.3437,  1.3303,  1.3080,  1.2580,  1.2443,
          1.2257,  1.3001,  1.2461,  1.3398,  1.2160,  1.2240],
        [ 1.2292,  1.1694,  1.0732,  1.2271,  1.2966,  1.2796,  1.2144,  1.2705,
          1.2705,  1.6563,  1.8097,  1.6428,  2.1978,  1.6765,  6.1882,  1.7359,
          1.5907,  6.0179,  1.1463,  1.2279,  1.1081,  1.1718,  1.2705,  1.2926,
          1.2675,  1.2838,  1.2838,  1.2904,  1.1136,  1.2985,  1.2986,  1.1511,
          1.3110,  1.3462,  1.2596,  1.3015,  1.3414,  1.4402,  1.3460,  1.2971,
          1.3701,  1.4099,  1.3276,  0.6833,  1.3071,  1.1453,  1.3564,  1.3346,
          1.3107,  1.1196,  1.3411,  1.0692,  1.2981,  1.3124],
        [ 1.1620,  1.1881,  1.2388,  1.2214,  1.1952,  1.1676,  1.1747,  1.1604,
          1.1604,  1.2428,  1.2679,  1.2596,  1.2950,  1.2301,  1.3012,  1.2437,
          1.1961,  1.2706,  2.7413,  2.8743,  2.9269,  2.8016,  2.6813,  2.7157,
          2.8155,  2.6685,  2.6685,  1.2327,  1.2584,  1.1934,  1.2155,  1.2323,
          1.2033,  1.2345,  1.1978,  1.1960,  1.3673,  1.4194,  1.3927,  1.3386,
          1.3955,  1.3945,  1.3792,  1.3276,  1.2827,  1.3058,  1.2593,  1.2455,
          1.2266,  1.2938,  1.2473,  1.3383,  1.2155,  1.2248],
        [ 1.1713,  1.1980,  1.2490,  1.2316,  1.2054,  1.1771,  1.1844,  1.1697,
          1.1697,  1.2504,  1.2755,  1.2675,  1.3035,  1.2375,  1.2583,  1.2514,
          1.2353,  1.1979,  1.2228,  1.2467,  1.2608,  1.2360,  1.1968,  1.1918,
          1.2124,  1.1848,  1.1848,  2.9778,  2.9522,  2.5743,  2.7430,  2.9737,
          2.5850,  2.9294,  2.5818,  2.5771,  1.3685,  1.4217,  1.3946,  1.3796,
          1.3980,  1.3967,  1.3805,  1.2817,  1.3225,  1.3194,  1.2674,  1.1650,
          1.1904,  1.3112,  1.2547,  1.3522,  1.1794,  1.2323],
        [ 1.7274,  1.3948,  0.6205,  0.8535,  1.2126,  1.6222,  1.5539,  1.7251,
          1.7251,  1.5711,  1.2302,  1.4026,  0.8747,  1.6406,  0.2147,  1.5350,
          1.6997,  0.9371,  1.2988,  0.9038,  0.7328,  1.1028,  1.5844,  1.6297,
          1.3983,  1.7312,  1.7312,  0.7620,  0.8332,  1.6997,  1.5094,  0.8307,
          1.6405,  1.1342,  1.7514,  1.6652,  0.1475, -0.0894, -0.1066,  0.0938,
          0.3521,  0.4589,  0.0355, 14.7280,  6.2518,  0.7338,  1.2366,  1.3313,
          1.5436,  0.9562,  1.4742,  0.3633,  1.6112,  1.7053],
        [ 1.2292,  1.2616,  1.3248,  1.3034,  1.2712,  1.2362,  1.2013,  1.2272,
          1.2272,  1.1996,  1.3253,  1.2203,  1.3593,  1.2783,  1.4118,  1.2008,
          1.2763,  1.2447,  1.2873,  1.3114,  1.3344,  1.3032,  1.2560,  1.2500,
          1.1813,  1.2415,  1.2415,  1.2994,  1.3419,  1.2575,  1.0624,  1.2534,
          1.1363,  1.3074,  1.1306,  1.2607,  1.3405,  1.0346,  1.3643,  1.3571,
          0.9084,  0.8251,  1.3560,  1.3013,  0.7024,  3.4151,  2.5905,  3.6198,
          2.8900,  2.1711,  1.8499,  3.0150,  3.3298,  1.8282]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 258 : 179.9400533507535
Test loss for epoch 258 : 180.0737856043903
Test Precision for epoch 258 : 0.26153846153846155
Test Recall for epoch 258 : 0.26153846153846155
Test F1 for epoch 258 : 0.26153846153846155


theta for epoch 259 : tensor([[ 2.6832,  2.7139,  2.7885,  2.9197,  2.8830,  2.6895,  2.8579,  2.6814,
          2.6814,  1.2406,  1.2655,  1.2571,  1.2924,  1.2283,  1.3347,  1.2417,
          1.2267,  1.2301,  1.2091,  1.1895,  1.2021,  1.2218,  1.1840,  1.1794,
          1.2005,  1.1725,  1.1725,  1.2173,  1.2602,  1.1922,  1.2143,  1.2616,
          1.2019,  1.2325,  1.1520,  1.1947,  1.3732,  1.4246,  1.3988,  1.3858,
          1.4015,  1.3429,  1.3850,  1.3432,  1.3314,  1.3080,  1.2578,  1.2442,
          1.2256,  1.3001,  1.2459,  1.3398,  1.2158,  1.2238],
        [ 1.2288,  1.1710,  1.0783,  1.2289,  1.2974,  1.2791,  1.2148,  1.2700,
          1.2700,  1.6629,  1.8127,  1.6484,  2.1953,  1.6820,  6.1772,  1.7410,
          1.5971,  6.0061,  1.1485,  1.2298,  1.1132,  1.1717,  1.2694,  1.2904,
          1.2656,  1.2816,  1.2816,  1.2917,  1.1177,  1.2980,  1.2993,  1.1546,
          1.3105,  1.3457,  1.2590,  1.3010,  1.3438,  1.4414,  1.3471,  1.2995,
          1.3737,  1.4113,  1.3287,  0.6956,  1.3085,  1.1521,  1.3560,  1.3342,
          1.3104,  1.1248,  1.3406,  1.0798,  1.2977,  1.3120],
        [ 1.1628,  1.1890,  1.2396,  1.2222,  1.1961,  1.1685,  1.1755,  1.1613,
          1.1613,  1.2421,  1.2673,  1.2589,  1.2947,  1.2295,  1.3007,  1.2431,
          1.1950,  1.2711,  2.7410,  2.8747,  2.9265,  2.8001,  2.6816,  2.7148,
          2.8163,  2.6687,  2.6687,  1.2331,  1.2594,  1.1941,  1.2163,  1.2327,
          1.2040,  1.2353,  1.1986,  1.1967,  1.3690,  1.4213,  1.3945,  1.3399,
          1.3971,  1.3965,  1.3810,  1.3284,  1.2841,  1.3069,  1.2601,  1.2462,
          1.2273,  1.2951,  1.2480,  1.3396,  1.2161,  1.2255],
        [ 1.1719,  1.1985,  1.2495,  1.2322,  1.2059,  1.1776,  1.1850,  1.1703,
          1.1703,  1.2492,  1.2746,  1.2664,  1.3028,  1.2364,  1.2576,  1.2503,
          1.2341,  1.1978,  1.2215,  1.2453,  1.2595,  1.2347,  1.1954,  1.1905,
          1.2110,  1.1835,  1.1835,  2.9791,  2.9540,  2.5755,  2.7444,  2.9751,
          2.5863,  2.9307,  2.5831,  2.5784,  1.3698,  1.4233,  1.3961,  1.3809,
          1.3993,  1.3984,  1.3819,  1.2818,  1.3240,  1.3200,  1.2679,  1.1655,
          1.1908,  1.3119,  1.2552,  1.3529,  1.1797,  1.2328],
        [ 1.7287,  1.3945,  0.6188,  0.8535,  1.2131,  1.6236,  1.5545,  1.7264,
          1.7264,  1.5707,  1.2276,  1.4017,  0.8706,  1.6394,  0.2088,  1.5334,
          1.6998,  0.9287,  1.2948,  0.9010,  0.7281,  1.1006,  1.5829,  1.6289,
          1.3978,  1.7305,  1.7305,  0.7621,  0.8314,  1.7007,  1.5096,  0.8294,
          1.6415,  1.1350,  1.7523,  1.6661,  0.1464, -0.0905, -0.1079,  0.0927,
          0.3512,  0.4568,  0.0341, 14.7805,  6.2159,  0.7308,  1.2372,  1.3319,
          1.5442,  0.9534,  1.4748,  0.3585,  1.6121,  1.7060],
        [ 1.2300,  1.2624,  1.3257,  1.3043,  1.2720,  1.2370,  1.2022,  1.2280,
          1.2280,  1.1983,  1.3243,  1.2192,  1.3586,  1.2771,  1.4111,  1.1998,
          1.2750,  1.2446,  1.2860,  1.3097,  1.3331,  1.3019,  1.2544,  1.2485,
          1.1795,  1.2399,  1.2399,  1.2999,  1.3424,  1.2578,  1.0625,  1.2538,
          1.1367,  1.3078,  1.1310,  1.2611,  1.3412,  1.0357,  1.3649,  1.3579,
          0.9089,  0.8260,  1.3569,  1.3002,  0.7029,  3.4178,  2.5905,  3.6228,
          2.8905,  2.1709,  1.8495,  3.0156,  3.3324,  1.8278]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 259 : 179.9277513408092
Test loss for epoch 259 : 180.06277380256824
Test Precision for epoch 259 : 0.26153846153846155
Test Recall for epoch 259 : 0.26153846153846155
Test F1 for epoch 259 : 0.26153846153846155


theta for epoch 260 : tensor([[ 2.6855,  2.7162,  2.7908,  2.9223,  2.8856,  2.6919,  2.8605,  2.6837,
          2.6837,  1.2386,  1.2637,  1.2551,  1.2908,  1.2264,  1.3331,  1.2398,
          1.2246,  1.2289,  1.2074,  1.1878,  1.2004,  1.2201,  1.1823,  1.1776,
          1.1987,  1.1707,  1.1707,  1.2171,  1.2600,  1.1919,  1.2142,  1.2614,
          1.2017,  1.2323,  1.1517,  1.1945,  1.3737,  1.4254,  1.3995,  1.3864,
          1.4020,  1.3437,  1.3857,  1.3424,  1.3321,  1.3089,  1.2587,  1.2450,
          1.2264,  1.3011,  1.2468,  1.3407,  1.2166,  1.2246],
        [ 1.2280,  1.1724,  1.0832,  1.2304,  1.2978,  1.2782,  1.2149,  1.2692,
          1.2692,  1.6701,  1.8162,  1.6546,  2.1932,  1.6882,  6.1656,  1.7467,
          1.6042,  5.9937,  1.1508,  1.2317,  1.1183,  1.1716,  1.2681,  1.2880,
          1.2636,  1.2792,  1.2792,  1.2931,  1.1216,  1.2973,  1.2998,  1.1582,
          1.3098,  1.3450,  1.2584,  1.3004,  1.3453,  1.4418,  1.3475,  1.3011,
          1.3764,  1.4118,  1.3290,  0.7075,  1.3090,  1.1595,  1.3561,  1.3344,
          1.3105,  1.1306,  1.3407,  1.0911,  1.2978,  1.3121],
        [ 1.1633,  1.1895,  1.2401,  1.2227,  1.1966,  1.1690,  1.1760,  1.1618,
          1.1618,  1.2411,  1.2666,  1.2579,  1.2941,  1.2286,  1.2999,  1.2423,
          1.1937,  1.2713,  2.7410,  2.8753,  2.9265,  2.7989,  2.6821,  2.7143,
          2.8175,  2.6693,  2.6693,  1.2334,  1.2603,  1.1947,  1.2169,  1.2330,
          1.2047,  1.2359,  1.1992,  1.1974,  1.3698,  1.4225,  1.3956,  1.3403,
          1.3980,  1.3977,  1.3821,  1.3284,  1.2848,  1.3086,  1.2614,  1.2475,
          1.2285,  1.2970,  1.2492,  1.3413,  1.2172,  1.2267],
        [ 1.1723,  1.1990,  1.2499,  1.2326,  1.2064,  1.1781,  1.1854,  1.1707,
          1.1707,  1.2480,  1.2737,  1.2652,  1.3021,  1.2353,  1.2569,  1.2493,
          1.2329,  1.1976,  1.2202,  1.2440,  1.2583,  1.2334,  1.1941,  1.1892,
          1.2096,  1.1822,  1.1822,  2.9804,  2.9557,  2.5768,  2.7457,  2.9764,
          2.5875,  2.9319,  2.5843,  2.5796,  1.3706,  1.4244,  1.3971,  1.3817,
          1.4001,  1.3995,  1.3829,  1.2814,  1.3250,  1.3213,  1.2691,  1.1667,
          1.1918,  1.3131,  1.2563,  1.3542,  1.1807,  1.2339],
        [ 1.7302,  1.3945,  0.6176,  0.8540,  1.2141,  1.6252,  1.5553,  1.7280,
          1.7280,  1.5708,  1.2256,  1.4014,  0.8672,  1.6385,  0.2039,  1.5322,
          1.7002,  0.9211,  1.2913,  0.8991,  0.7243,  1.0991,  1.5818,  1.6286,
          1.3978,  1.7303,  1.7303,  0.7631,  0.8306,  1.7022,  1.5105,  0.8290,
          1.6431,  1.1367,  1.7538,  1.6676,  0.1443, -0.0928, -0.1103,  0.0905,
          0.3490,  0.4535,  0.0316, 14.8328,  6.1782,  0.7300,  1.2398,  1.3343,
          1.5466,  0.9527,  1.4772,  0.3559,  1.6148,  1.7082],
        [ 1.2299,  1.2624,  1.3257,  1.3043,  1.2720,  1.2369,  1.2021,  1.2279,
          1.2279,  1.1963,  1.3226,  1.2172,  1.3572,  1.2751,  1.4096,  1.1979,
          1.2728,  1.2436,  1.2840,  1.3074,  1.3313,  1.2999,  1.2523,  1.2464,
          1.1770,  1.2377,  1.2377,  1.2997,  1.3423,  1.2574,  1.0618,  1.2536,
          1.1363,  1.3075,  1.1306,  1.2607,  1.3406,  1.0352,  1.3642,  1.3573,
          0.9077,  0.8251,  1.3566,  1.2976,  0.7018,  3.4224,  2.5925,  3.6278,
          2.8928,  2.1727,  1.8510,  3.0181,  3.3370,  1.8293]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 260 : 179.91927596293837
Test loss for epoch 260 : 180.05403318297732
Test Precision for epoch 260 : 0.26153846153846155
Test Recall for epoch 260 : 0.26153846153846155
Test F1 for epoch 260 : 0.26153846153846155


theta for epoch 261 : tensor([[ 2.6853,  2.7160,  2.7906,  2.9224,  2.8857,  2.6916,  2.8606,  2.6835,
          2.6835,  1.2405,  1.2658,  1.2571,  1.2932,  1.2284,  1.3353,  1.2418,
          1.2265,  1.2316,  1.2091,  1.1895,  1.2021,  1.2218,  1.1840,  1.1794,
          1.2004,  1.1724,  1.1724,  1.2176,  1.2605,  1.1924,  1.2146,  1.2619,
          1.2021,  1.2328,  1.1522,  1.1950,  1.3741,  1.4260,  1.4001,  1.3868,
          1.4024,  1.3444,  1.3862,  1.3414,  1.3328,  1.3083,  1.2579,  1.2443,
          1.2257,  1.3004,  1.2460,  1.3401,  1.2158,  1.2239],
        [ 1.2246,  1.1713,  1.0856,  1.2293,  1.2957,  1.2747,  1.2125,  1.2657,
          1.2657,  1.6811,  1.8233,  1.6646,  2.1944,  1.6981,  6.1564,  1.7562,
          1.6152,  5.9837,  1.1547,  1.2351,  1.1249,  1.1729,  1.2685,  1.2872,
          1.2631,  1.2784,  1.2784,  1.2927,  1.1235,  1.2949,  1.2987,  1.1601,
          1.3074,  1.3426,  1.2559,  1.2980,  1.3450,  1.4404,  1.3459,  1.3008,
          1.3772,  1.4105,  1.3274,  0.7176,  1.3077,  1.1632,  1.3524,  1.3308,
          1.3069,  1.1326,  1.3370,  1.0989,  1.2941,  1.3084],
        [ 1.1616,  1.1878,  1.2384,  1.2211,  1.1949,  1.1673,  1.1743,  1.1601,
          1.1601,  1.2417,  1.2674,  1.2586,  1.2952,  1.2293,  1.3007,  1.2430,
          1.1939,  1.2732,  2.7439,  2.8790,  2.9294,  2.8006,  2.6857,  2.7167,
          2.8216,  2.6728,  2.6728,  1.2320,  1.2595,  1.1936,  1.2158,  1.2315,
          1.2036,  1.2348,  1.1981,  1.1963,  1.3689,  1.4219,  1.3948,  1.3389,
          1.3971,  1.3971,  1.3813,  1.3265,  1.2835,  1.3066,  1.2590,  1.2450,
          1.2260,  1.2953,  1.2468,  1.3395,  1.2146,  1.2242],
        [ 1.1715,  1.1982,  1.2491,  1.2318,  1.2056,  1.1772,  1.1846,  1.1699,
          1.1699,  1.2496,  1.2756,  1.2669,  1.3041,  1.2371,  1.2589,  1.2510,
          1.2344,  1.2001,  1.2217,  1.2454,  1.2598,  1.2349,  1.1956,  1.1907,
          1.2110,  1.1836,  1.1836,  2.9814,  2.9571,  2.5777,  2.7467,  2.9774,
          2.5885,  2.9328,  2.5852,  2.5805,  1.3707,  1.4247,  1.3974,  1.3817,
          1.4002,  1.3999,  1.3831,  1.2802,  1.3252,  1.3203,  1.2680,  1.1657,
          1.1906,  1.3122,  1.2553,  1.3533,  1.1794,  1.2328],
        [ 1.7305,  1.3933,  0.6158,  0.8539,  1.2140,  1.6257,  1.5550,  1.7284,
          1.7284,  1.5740,  1.2267,  1.4041,  0.8668,  1.6408,  0.2014,  1.5341,
          1.7037,  0.9166,  1.2907,  0.9002,  0.7236,  1.1007,  1.5837,  1.6314,
          1.4009,  1.7332,  1.7332,  0.7642,  0.8300,  1.7035,  1.5112,  0.8285,
          1.6444,  1.1383,  1.7551,  1.6689,  0.1411, -0.0960, -0.1136,  0.0873,
          0.3458,  0.4492,  0.0282, 14.8849,  6.1388,  0.7269,  1.2396,  1.3339,
          1.5460,  0.9495,  1.4768,  0.3515,  1.6145,  1.7076],
        [ 1.2289,  1.2614,  1.3248,  1.3034,  1.2710,  1.2359,  1.2011,  1.2269,
          1.2269,  1.1978,  1.3245,  1.2188,  1.3594,  1.2767,  1.4117,  1.1996,
          1.2742,  1.2463,  1.2853,  1.3084,  1.3326,  1.3011,  1.2535,  1.2475,
          1.1778,  1.2388,  1.2388,  1.2995,  1.3422,  1.2571,  1.0612,  1.2535,
          1.1360,  1.3073,  1.1303,  1.2604,  1.3393,  1.0342,  1.3628,  1.3561,
          0.9060,  0.8239,  1.3555,  1.2942,  0.7002,  3.4243,  2.5917,  3.6300,
          2.8925,  2.1717,  1.8497,  3.0179,  3.3388,  1.8280]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 261 : 179.90695807335828
Test loss for epoch 261 : 180.0426252425113
Test Precision for epoch 261 : 0.26153846153846155
Test Recall for epoch 261 : 0.26153846153846155
Test F1 for epoch 261 : 0.26153846153846155


theta for epoch 262 : tensor([[ 2.6859,  2.7166,  2.7912,  2.9233,  2.8865,  2.6922,  2.8614,  2.6841,
          2.6841,  1.2408,  1.2664,  1.2574,  1.2939,  1.2289,  1.3360,  1.2423,
          1.2268,  1.2329,  1.2100,  1.1904,  1.2030,  1.2227,  1.1849,  1.1802,
          1.2012,  1.1733,  1.1733,  1.2180,  1.2609,  1.1928,  1.2151,  1.2623,
          1.2025,  1.2331,  1.1526,  1.1954,  1.3747,  1.4270,  1.4009,  1.3875,
          1.4031,  1.3454,  1.3871,  1.3406,  1.3337,  1.3079,  1.2574,  1.2438,
          1.2251,  1.3000,  1.2455,  1.3398,  1.2152,  1.2233],
        [ 1.2231,  1.1722,  1.0900,  1.2301,  1.2954,  1.2731,  1.2120,  1.2640,
          1.2640,  1.6909,  1.8289,  1.6733,  2.1939,  1.7067,  6.1448,  1.7643,
          1.6248,  5.9712,  1.1585,  1.2384,  1.1314,  1.1740,  1.2685,  1.2860,
          1.2622,  1.2772,  1.2772,  1.2929,  1.1261,  1.2931,  1.2983,  1.1628,
          1.3056,  1.3408,  1.2541,  1.2962,  1.3455,  1.4397,  1.3451,  1.3013,
          1.3787,  1.4100,  1.3266,  0.7290,  1.3072,  1.1678,  1.3495,  1.3280,
          1.3042,  1.1355,  1.3342,  1.1078,  1.2913,  1.3055],
        [ 1.1617,  1.1880,  1.2385,  1.2212,  1.1950,  1.1673,  1.1744,  1.1601,
          1.1601,  1.2415,  1.2675,  1.2584,  1.2954,  1.2293,  1.3007,  1.2430,
          1.1934,  1.2743,  2.7453,  2.8812,  2.9308,  2.8009,  2.6877,  2.7176,
          2.8242,  2.6749,  2.6749,  1.2313,  1.2594,  1.1933,  1.2156,  1.2309,
          1.2033,  1.2345,  1.1978,  1.1960,  1.3688,  1.4222,  1.3950,  1.3384,
          1.3972,  1.3975,  1.3815,  1.3254,  1.2832,  1.3056,  1.2576,  1.2436,
          1.2246,  1.2945,  1.2454,  1.3386,  1.2131,  1.2227],
        [ 1.1718,  1.1985,  1.2494,  1.2322,  1.2059,  1.1775,  1.1849,  1.1701,
          1.1701,  1.2497,  1.2759,  1.2669,  1.3046,  1.2373,  1.2593,  1.2512,
          1.2345,  1.2011,  1.2223,  1.2459,  1.2604,  1.2355,  1.1962,  1.1912,
          1.2115,  1.1841,  1.1841,  2.9826,  2.9587,  2.5788,  2.7480,  2.9787,
          2.5896,  2.9340,  2.5864,  2.5817,  1.3709,  1.4253,  1.3979,  1.3820,
          1.4005,  1.4005,  1.3836,  1.2792,  1.3257,  1.3196,  1.2671,  1.1649,
          1.1896,  1.3114,  1.2544,  1.3526,  1.1783,  1.2318],
        [ 1.7315,  1.3925,  0.6138,  0.8537,  1.2143,  1.6267,  1.5552,  1.7295,
          1.7295,  1.5750,  1.2255,  1.4047,  0.8641,  1.6409,  0.1965,  1.5338,
          1.7052,  0.9097,  1.2883,  0.8994,  0.7208,  1.1004,  1.5841,  1.6327,
          1.4025,  1.7346,  1.7346,  0.7641,  0.8284,  1.7044,  1.5113,  0.8268,
          1.6453,  1.1391,  1.7560,  1.6697,  0.1393, -0.0980, -0.1158,  0.0854,
          0.3438,  0.4462,  0.0260, 14.9386,  6.0999,  0.7226,  1.2387,  1.3328,
          1.5451,  0.9453,  1.4758,  0.3455,  1.6139,  1.7066],
        [ 1.2293,  1.2620,  1.3254,  1.3039,  1.2715,  1.2363,  1.2016,  1.2273,
          1.2273,  1.1979,  1.3249,  1.2190,  1.3601,  1.2769,  1.4124,  1.1999,
          1.2742,  1.2476,  1.2858,  1.3086,  1.3333,  1.3017,  1.2539,  1.2480,
          1.1779,  1.2392,  1.2392,  1.2996,  1.3423,  1.2570,  1.0609,  1.2536,
          1.1360,  1.3073,  1.1302,  1.2603,  1.3386,  1.0339,  1.3620,  1.3554,
          0.9051,  0.8233,  1.3550,  1.2913,  0.6993,  3.4262,  2.5909,  3.6321,
          2.8920,  2.1706,  1.8484,  3.0176,  3.3405,  1.8266]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 262 : 179.89675427710768
Test loss for epoch 262 : 180.0342826346614
Test Precision for epoch 262 : 0.26153846153846155
Test Recall for epoch 262 : 0.26153846153846155
Test F1 for epoch 262 : 0.26153846153846155


theta for epoch 263 : tensor([[ 2.6879,  2.7186,  2.7933,  2.9256,  2.8888,  2.6942,  2.8637,  2.6861,
          2.6861,  1.2385,  1.2645,  1.2552,  1.2922,  1.2267,  1.3341,  1.2402,
          1.2245,  1.2315,  1.2086,  1.1889,  1.2016,  1.2212,  1.1834,  1.1787,
          1.1997,  1.1718,  1.1718,  1.2179,  1.2608,  1.1927,  1.2150,  1.2623,
          1.2025,  1.2331,  1.1525,  1.1953,  1.3752,  1.4276,  1.4016,  1.3880,
          1.4035,  1.3461,  1.3877,  1.3395,  1.3343,  1.3093,  1.2587,  1.2450,
          1.2264,  1.3014,  1.2468,  1.3412,  1.2165,  1.2246],
        [ 1.2233,  1.1750,  1.0963,  1.2327,  1.2969,  1.2732,  1.2134,  1.2642,
          1.2642,  1.6988,  1.8327,  1.6801,  2.1914,  1.7134,  6.1303,  1.7705,
          1.6327,  5.9558,  1.1611,  1.2404,  1.1367,  1.1737,  1.2672,  1.2834,
          1.2598,  1.2745,  1.2745,  1.2941,  1.1295,  1.2921,  1.2987,  1.1667,
          1.3045,  1.3398,  1.2531,  1.2952,  1.3467,  1.4396,  1.3450,  1.3026,
          1.3808,  1.4102,  1.3265,  0.7416,  1.3073,  1.1755,  1.3497,  1.3283,
          1.3044,  1.1415,  1.3343,  1.1197,  1.2915,  1.3057],
        [ 1.1636,  1.1899,  1.2405,  1.2231,  1.1969,  1.1692,  1.1763,  1.1620,
          1.1620,  1.2403,  1.2667,  1.2573,  1.2948,  1.2283,  1.2998,  1.2420,
          1.1919,  1.2745,  2.7442,  2.8808,  2.9297,  2.7986,  2.6872,  2.7160,
          2.8243,  2.6743,  2.6743,  1.2319,  1.2606,  1.1943,  1.2166,  1.2316,
          1.2043,  1.2355,  1.1988,  1.1970,  1.3698,  1.4235,  1.3962,  1.3390,
          1.3982,  1.3988,  1.3826,  1.3253,  1.2839,  1.3079,  1.2596,  1.2456,
          1.2265,  1.2970,  1.2474,  1.3409,  1.2149,  1.2247],
        [ 1.1729,  1.1997,  1.2505,  1.2333,  1.2070,  1.1786,  1.1860,  1.1713,
          1.1713,  1.2476,  1.2742,  1.2649,  1.3030,  1.2353,  1.2578,  1.2493,
          1.2324,  1.2002,  1.2208,  1.2443,  1.2588,  1.2339,  1.1945,  1.1896,
          1.2098,  1.1825,  1.1825,  2.9842,  2.9606,  2.5803,  2.7495,  2.9803,
          2.5911,  2.9355,  2.5879,  2.5832,  1.3713,  1.4259,  1.3985,  1.3823,
          1.4009,  1.4011,  1.3841,  1.2782,  1.3262,  1.3207,  1.2681,  1.1659,
          1.1905,  1.3125,  1.2554,  1.3538,  1.1791,  1.2328],
        [ 1.7335,  1.3926,  0.6126,  0.8544,  1.2157,  1.6289,  1.5563,  1.7317,
          1.7317,  1.5741,  1.2224,  1.4034,  0.8596,  1.6390,  0.1902,  1.5315,
          1.7047,  0.9009,  1.2839,  0.8967,  0.7161,  1.0981,  1.5824,  1.6319,
          1.4020,  1.7339,  1.7339,  0.7642,  0.8270,  1.7054,  1.5115,  0.8253,
          1.6464,  1.1400,  1.7571,  1.6708,  0.1374, -0.0999, -0.1179,  0.0836,
          0.3419,  0.4432,  0.0239, 14.9930,  6.0603,  0.7212,  1.2407,  1.3347,
          1.5471,  0.9441,  1.4779,  0.3422,  1.6163,  1.7086],
        [ 1.2302,  1.2629,  1.3265,  1.3049,  1.2725,  1.2372,  1.2025,  1.2282,
          1.2282,  1.1951,  1.3226,  1.2164,  1.3581,  1.2743,  1.4103,  1.1974,
          1.2714,  1.2461,  1.2838,  1.3062,  1.3314,  1.2997,  1.2517,  1.2458,
          1.1753,  1.2370,  1.2370,  1.2991,  1.3418,  1.2564,  1.0598,  1.2531,
          1.1353,  1.3068,  1.1295,  1.2597,  1.3375,  1.0330,  1.3607,  1.3545,
          0.9034,  0.8220,  1.3542,  1.2880,  0.6976,  3.4308,  2.5928,  3.6369,
          2.8943,  2.1723,  1.8499,  3.0201,  3.3451,  1.8281]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 263 : 179.88513250671517
Test loss for epoch 263 : 180.0231999532285
Test Precision for epoch 263 : 0.26153846153846155
Test Recall for epoch 263 : 0.26153846153846155
Test F1 for epoch 263 : 0.26153846153846155


theta for epoch 264 : tensor([[ 2.6887,  2.7194,  2.7941,  2.9267,  2.8899,  2.6950,  2.8648,  2.6869,
          2.6869,  1.2388,  1.2651,  1.2556,  1.2930,  1.2272,  1.3348,  1.2407,
          1.2248,  1.2327,  1.2090,  1.1892,  1.2019,  1.2215,  1.1836,  1.1790,
          1.1999,  1.1720,  1.1720,  1.2176,  1.2606,  1.1925,  1.2148,  1.2620,
          1.2023,  1.2328,  1.1523,  1.1951,  1.3757,  1.4284,  1.4023,  1.3885,
          1.4041,  1.3469,  1.3883,  1.3384,  1.3351,  1.3096,  1.2589,  1.2452,
          1.2266,  1.3017,  1.2470,  1.3416,  1.2166,  1.2248],
        [ 1.2210,  1.1754,  1.1001,  1.2326,  1.2957,  1.2707,  1.2122,  1.2617,
          1.2617,  1.7096,  1.8390,  1.6897,  2.1913,  1.7229,  6.1171,  1.7794,
          1.6433,  5.9418,  1.1647,  1.2434,  1.1430,  1.1744,  1.2668,  1.2817,
          1.2584,  1.2728,  1.2728,  1.2940,  1.1314,  1.2899,  1.2979,  1.1695,
          1.3023,  1.3376,  1.2509,  1.2930,  1.3471,  1.4389,  1.3442,  1.3031,
          1.3821,  1.4096,  1.3256,  0.7534,  1.3068,  1.1810,  1.3478,  1.3264,
          1.3026,  1.1453,  1.3324,  1.1296,  1.2897,  1.3038],
        [ 1.1631,  1.1894,  1.2400,  1.2227,  1.1965,  1.1688,  1.1759,  1.1615,
          1.1615,  1.2406,  1.2672,  1.2576,  1.2955,  1.2286,  1.3003,  1.2424,
          1.1918,  1.2760,  2.7452,  2.8826,  2.9306,  2.7984,  2.6887,  2.7165,
          2.8264,  2.6759,  2.6759,  1.2313,  1.2605,  1.1940,  1.2163,  1.2309,
          1.2040,  1.2352,  1.1985,  1.1966,  1.3701,  1.4241,  1.3967,  1.3387,
          1.3985,  1.3993,  1.3830,  1.3243,  1.2839,  1.3081,  1.2595,  1.2455,
          1.2264,  1.2974,  1.2472,  1.3413,  1.2146,  1.2245],
        [ 1.1723,  1.1991,  1.2500,  1.2328,  1.2065,  1.1780,  1.1855,  1.1707,
          1.1707,  1.2478,  1.2747,  1.2652,  1.3037,  1.2357,  1.2584,  1.2497,
          1.2326,  1.2015,  1.2210,  1.2444,  1.2590,  1.2340,  1.1946,  1.1897,
          1.2098,  1.1826,  1.1826,  2.9856,  2.9623,  2.5816,  2.7509,  2.9816,
          2.5924,  2.9367,  2.5891,  2.5844,  1.3716,  1.4265,  1.3990,  1.3826,
          1.4012,  1.4017,  1.3846,  1.2771,  1.3267,  1.3207,  1.2680,  1.1659,
          1.1903,  1.3126,  1.2553,  1.3539,  1.1788,  1.2327],
        [ 1.7342,  1.3915,  0.6109,  0.8545,  1.2160,  1.6298,  1.5562,  1.7326,
          1.7326,  1.5758,  1.2221,  1.4047,  0.8579,  1.6397,  0.1865,  1.5318,
          1.7069,  0.8951,  1.2816,  0.8962,  0.7138,  1.0981,  1.5827,  1.6333,
          1.4038,  1.7354,  1.7354,  0.7648,  0.8261,  1.7065,  1.5119,  0.8240,
          1.6475,  1.1412,  1.7582,  1.6719,  0.1348, -0.1026, -0.1208,  0.0809,
          0.3390,  0.4394,  0.0210, 15.0473,  6.0190,  0.7193,  1.2418,  1.3356,
          1.5479,  0.9422,  1.4788,  0.3388,  1.6175,  1.7094],
        [ 1.2296,  1.2624,  1.3261,  1.3045,  1.2720,  1.2366,  1.2019,  1.2276,
          1.2276,  1.1954,  1.3232,  1.2167,  1.3590,  1.2746,  1.4111,  1.1978,
          1.2715,  1.2475,  1.2839,  1.3059,  1.3316,  1.2998,  1.2517,  1.2457,
          1.1749,  1.2369,  1.2369,  1.2987,  1.3415,  1.2559,  1.0590,  1.2528,
          1.1348,  1.3063,  1.1290,  1.2592,  1.3366,  1.0325,  1.3597,  1.3536,
          0.9021,  0.8211,  1.3536,  1.2848,  0.6964,  3.4336,  2.5928,  3.6398,
          2.8947,  2.1721,  1.8494,  3.0206,  3.3478,  1.8276]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 264 : 179.8729442065541
Test loss for epoch 264 : 180.0121590237571
Test Precision for epoch 264 : 0.26153846153846155
Test Recall for epoch 264 : 0.26153846153846155
Test F1 for epoch 264 : 0.26153846153846155


theta for epoch 265 : tensor([[ 2.6892,  2.7199,  2.7947,  2.9275,  2.8908,  2.6955,  2.8656,  2.6874,
          2.6874,  1.2399,  1.2664,  1.2567,  1.2945,  1.2283,  1.3362,  1.2419,
          1.2258,  1.2347,  1.2103,  1.1904,  1.2032,  1.2228,  1.1849,  1.1802,
          1.2012,  1.1733,  1.1733,  1.2174,  1.2605,  1.1924,  1.2147,  1.2619,
          1.2021,  1.2327,  1.1522,  1.1950,  1.3764,  1.4294,  1.4032,  1.3892,
          1.4049,  1.3479,  1.3892,  1.3375,  1.3360,  1.3085,  1.2577,  1.2439,
          1.2253,  1.3006,  1.2457,  1.3405,  1.2152,  1.2234],
        [ 1.2178,  1.1751,  1.1031,  1.2317,  1.2936,  1.2673,  1.2103,  1.2583,
          1.2583,  1.7212,  1.8460,  1.7001,  2.1917,  1.7332,  6.1035,  1.7891,
          1.6548,  5.9273,  1.1694,  1.2473,  1.1501,  1.1760,  1.2675,  1.2809,
          1.2580,  1.2721,  1.2721,  1.2940,  1.1332,  1.2876,  1.2972,  1.1725,
          1.3001,  1.3354,  1.2486,  1.2908,  1.3476,  1.4383,  1.3435,  1.3037,
          1.3834,  1.4093,  1.3249,  0.7655,  1.3064,  1.1851,  1.3443,  1.3231,
          1.2992,  1.1476,  1.3289,  1.1382,  1.2862,  1.3003],
        [ 1.1615,  1.1879,  1.2384,  1.2211,  1.1949,  1.1672,  1.1743,  1.1599,
          1.1599,  1.2409,  1.2679,  1.2580,  1.2963,  1.2291,  1.3008,  1.2429,
          1.1918,  1.2776,  2.7476,  2.8858,  2.9331,  2.7996,  2.6918,  2.7185,
          2.8301,  2.6789,  2.6789,  1.2300,  1.2598,  1.1931,  1.2154,  1.2297,
          1.2031,  1.2342,  1.1976,  1.1957,  1.3701,  1.4244,  1.3969,  1.3382,
          1.3986,  1.3997,  1.3832,  1.3231,  1.2836,  1.3064,  1.2574,  1.2434,
          1.2242,  1.2959,  1.2451,  1.3397,  1.2123,  1.2223],
        [ 1.1712,  1.1980,  1.2489,  1.2317,  1.2054,  1.1770,  1.1844,  1.1696,
          1.1696,  1.2489,  1.2761,  1.2663,  1.3053,  1.2369,  1.2600,  1.2510,
          1.2336,  1.2036,  1.2224,  1.2457,  1.2603,  1.2353,  1.1960,  1.1911,
          1.2111,  1.1839,  1.1839,  2.9867,  2.9637,  2.5826,  2.7519,  2.9827,
          2.5934,  2.9377,  2.5901,  2.5854,  1.3722,  1.4273,  1.3998,  1.3832,
          1.4019,  1.4027,  1.3853,  1.2762,  1.3275,  1.3197,  1.2668,  1.1648,
          1.1889,  1.3115,  1.2542,  1.3529,  1.1773,  1.2314],
        [ 1.7343,  1.3896,  0.6086,  0.8540,  1.2158,  1.6301,  1.5554,  1.7328,
          1.7328,  1.5783,  1.2225,  1.4067,  0.8570,  1.6411,  0.1834,  1.5327,
          1.7097,  0.8902,  1.2804,  0.8970,  0.7127,  1.0992,  1.5842,  1.6358,
          1.4067,  1.7380,  1.7380,  0.7653,  0.8254,  1.7077,  1.5122,  0.8228,
          1.6487,  1.1425,  1.7593,  1.6730,  0.1321, -0.1053, -0.1237,  0.0782,
          0.3362,  0.4356,  0.0181, 15.1022,  5.9769,  0.7158,  1.2409,  1.3345,
          1.5468,  0.9386,  1.4778,  0.3340,  1.6168,  1.7083],
        [ 1.2289,  1.2618,  1.3255,  1.3039,  1.2714,  1.2360,  1.2013,  1.2269,
          1.2269,  1.1970,  1.3253,  1.2184,  1.3613,  1.2763,  1.4134,  1.1997,
          1.2730,  1.2504,  1.2858,  1.3074,  1.3335,  1.3016,  1.2534,  1.2474,
          1.1762,  1.2385,  1.2385,  1.2990,  1.3418,  1.2560,  1.0590,  1.2532,
          1.1351,  1.3066,  1.1293,  1.2594,  1.3364,  1.0329,  1.3593,  1.3535,
          0.9019,  0.8212,  1.3536,  1.2822,  0.6962,  3.4342,  2.5906,  3.6405,
          2.8929,  2.1697,  1.8468,  3.0191,  3.3483,  1.8250]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 265 : 179.8617367618495
Test loss for epoch 265 : 180.0033075421798
Test Precision for epoch 265 : 0.26153846153846155
Test Recall for epoch 265 : 0.26153846153846155
Test F1 for epoch 265 : 0.26153846153846155


theta for epoch 266 : tensor([[ 2.6913,  2.7221,  2.7968,  2.9299,  2.8932,  2.6976,  2.8680,  2.6895,
          2.6895,  1.2380,  1.2649,  1.2549,  1.2932,  1.2267,  1.3347,  1.2403,
          1.2239,  1.2338,  1.2091,  1.1892,  1.2020,  1.2216,  1.1837,  1.1790,
          1.1999,  1.1720,  1.1720,  1.2172,  1.2603,  1.1922,  1.2146,  1.2617,
          1.2020,  1.2325,  1.1520,  1.1948,  1.3768,  1.4301,  1.4039,  1.3897,
          1.4054,  1.3487,  1.3898,  1.3363,  1.3367,  1.3089,  1.2580,  1.2443,
          1.2256,  1.3011,  1.2460,  1.3410,  1.2155,  1.2237],
        [ 1.2171,  1.1773,  1.1085,  1.2332,  1.2939,  1.2664,  1.2109,  1.2574,
          1.2574,  1.7305,  1.8507,  1.7082,  2.1896,  1.7412,  6.0865,  1.7964,
          1.6641,  5.9094,  1.1728,  1.2499,  1.1561,  1.1763,  1.2668,  1.2787,
          1.2561,  1.2698,  1.2698,  1.2954,  1.1363,  1.2867,  1.2978,  1.1770,
          1.2992,  1.3345,  1.2477,  1.2899,  1.3489,  1.4384,  1.3436,  1.3051,
          1.3855,  1.4096,  1.3249,  0.7787,  1.3068,  1.1919,  1.3437,  1.3226,
          1.2987,  1.1528,  1.3284,  1.1495,  1.2857,  1.2997],
        [ 1.1619,  1.1883,  1.2388,  1.2215,  1.1954,  1.1676,  1.1747,  1.1604,
          1.1604,  1.2398,  1.2670,  1.2569,  1.2957,  1.2281,  1.3000,  1.2420,
          1.1902,  1.2778,  2.7478,  2.8868,  2.9333,  2.7987,  2.6926,  2.7182,
          2.8315,  2.6796,  2.6796,  1.2301,  1.2605,  1.1936,  1.2159,  1.2299,
          1.2036,  1.2348,  1.1981,  1.1963,  1.3708,  1.4255,  1.3978,  1.3385,
          1.3994,  1.4008,  1.3842,  1.3225,  1.2840,  1.3075,  1.2582,  1.2441,
          1.2250,  1.2972,  1.2459,  1.3409,  1.2130,  1.2231],
        [ 1.1717,  1.1985,  1.2493,  1.2321,  1.2058,  1.1774,  1.1849,  1.1701,
          1.1701,  1.2477,  1.2753,  1.2652,  1.3046,  1.2359,  1.2594,  1.2500,
          1.2325,  1.2036,  1.2217,  1.2448,  1.2596,  1.2346,  1.1952,  1.1903,
          1.2102,  1.1831,  1.1831,  2.9878,  2.9653,  2.5837,  2.7530,  2.9839,
          2.5945,  2.9389,  2.5912,  2.5865,  1.3729,  1.4284,  1.4008,  1.3839,
          1.4027,  1.4038,  1.3862,  1.2755,  1.3284,  1.3205,  1.2675,  1.1655,
          1.1895,  1.3123,  1.2548,  1.3538,  1.1777,  1.2320],
        [ 1.7358,  1.3891,  0.6074,  0.8547,  1.2169,  1.6318,  1.5558,  1.7344,
          1.7344,  1.5783,  1.2205,  1.4064,  0.8539,  1.6401,  0.1785,  1.5313,
          1.7102,  0.8831,  1.2770,  0.8955,  0.7094,  1.0980,  1.5834,  1.6360,
          1.4073,  1.7383,  1.7383,  0.7661,  0.8250,  1.7092,  1.5129,  0.8217,
          1.6503,  1.1440,  1.7608,  1.6746,  0.1297, -0.1077, -0.1263,  0.0758,
          0.3335,  0.4320,  0.0155, 15.1578,  5.9342,  0.7148,  1.2427,  1.3360,
          1.5484,  0.9376,  1.4795,  0.3314,  1.6188,  1.7098],
        [ 1.2290,  1.2620,  1.3258,  1.3041,  1.2715,  1.2360,  1.2014,  1.2270,
          1.2270,  1.1953,  1.3240,  1.2168,  1.3604,  1.2748,  1.4124,  1.1983,
          1.2712,  1.2500,  1.2846,  1.3058,  1.3324,  1.3005,  1.2521,  1.2461,
          1.1745,  1.2372,  1.2372,  1.2991,  1.3419,  1.2559,  1.0585,  1.2533,
          1.1350,  1.3065,  1.1291,  1.2592,  1.3357,  1.0324,  1.3584,  1.3529,
          0.9007,  0.8204,  1.3532,  1.2791,  0.6950,  3.4378,  2.5915,  3.6442,
          2.8941,  2.1703,  1.8472,  3.0204,  3.3518,  1.8253]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 266 : 179.84822274425204
Test loss for epoch 266 : 179.9908971716764
Test Precision for epoch 266 : 0.26153846153846155
Test Recall for epoch 266 : 0.26153846153846155
Test F1 for epoch 266 : 0.26153846153846155


theta for epoch 267 : tensor([[ 2.6928e+00,  2.7236e+00,  2.7983e+00,  2.9317e+00,  2.8950e+00,
          2.6991e+00,  2.8698e+00,  2.6910e+00,  2.6910e+00,  1.2371e+00,
          1.2643e+00,  1.2540e+00,  1.2928e+00,  1.2259e+00,  1.3342e+00,
          1.2396e+00,  1.2230e+00,  1.2339e+00,  1.2080e+00,  1.1880e+00,
          1.2009e+00,  1.2204e+00,  1.1825e+00,  1.1778e+00,  1.1987e+00,
          1.1708e+00,  1.1708e+00,  1.2172e+00,  1.2604e+00,  1.1922e+00,
          1.2146e+00,  1.2618e+00,  1.2020e+00,  1.2325e+00,  1.1520e+00,
          1.1948e+00,  1.3774e+00,  1.4309e+00,  1.4047e+00,  1.3903e+00,
          1.4060e+00,  1.3495e+00,  1.3906e+00,  1.3352e+00,  1.3375e+00,
          1.3097e+00,  1.2586e+00,  1.2449e+00,  1.2262e+00,  1.3018e+00,
          1.2466e+00,  1.3419e+00,  1.2160e+00,  1.2244e+00],
        [ 1.2163e+00,  1.1795e+00,  1.1138e+00,  1.2345e+00,  1.2940e+00,
          1.2653e+00,  1.2114e+00,  1.2563e+00,  1.2563e+00,  1.7408e+00,
          1.8562e+00,  1.7173e+00,  2.1882e+00,  1.7500e+00,  6.0693e+00,
          1.8047e+00,  1.6743e+00,  5.8912e+00,  1.1758e+00,  1.2520e+00,
          1.1615e+00,  1.1761e+00,  1.2656e+00,  1.2760e+00,  1.2536e+00,
          1.2671e+00,  1.2671e+00,  1.2964e+00,  1.1389e+00,  1.2854e+00,
          1.2981e+00,  1.1813e+00,  1.2979e+00,  1.3332e+00,  1.2464e+00,
          1.2886e+00,  1.3498e+00,  1.4383e+00,  1.3434e+00,  1.3063e+00,
          1.3871e+00,  1.4096e+00,  1.3247e+00,  7.9157e-01,  1.3068e+00,
          1.1984e+00,  1.3430e+00,  1.3220e+00,  1.2981e+00,  1.1576e+00,
          1.3276e+00,  1.1603e+00,  1.2850e+00,  1.2990e+00],
        [ 1.1626e+00,  1.1890e+00,  1.2394e+00,  1.2222e+00,  1.1960e+00,
          1.1682e+00,  1.1754e+00,  1.1610e+00,  1.1610e+00,  1.2392e+00,
          1.2668e+00,  1.2564e+00,  1.2957e+00,  1.2278e+00,  1.2998e+00,
          1.2417e+00,  1.1894e+00,  1.2785e+00,  2.7476e+00,  2.8875e+00,
          2.9332e+00,  2.7973e+00,  2.6929e+00,  2.7175e+00,  2.8325e+00,
          2.6800e+00,  2.6800e+00,  1.2303e+00,  1.2612e+00,  1.1941e+00,
          1.2164e+00,  1.2300e+00,  1.2041e+00,  1.2353e+00,  1.1987e+00,
          1.1968e+00,  1.3716e+00,  1.4265e+00,  1.3988e+00,  1.3388e+00,
          1.4002e+00,  1.4018e+00,  1.3851e+00,  1.3219e+00,  1.2844e+00,
          1.3087e+00,  1.2591e+00,  1.2451e+00,  1.2259e+00,  1.2987e+00,
          1.2468e+00,  1.3422e+00,  1.2137e+00,  1.2240e+00],
        [ 1.1723e+00,  1.1991e+00,  1.2498e+00,  1.2327e+00,  1.2064e+00,
          1.1780e+00,  1.1855e+00,  1.1706e+00,  1.1706e+00,  1.2472e+00,
          1.2751e+00,  1.2647e+00,  1.3047e+00,  1.2356e+00,  1.2595e+00,
          1.2497e+00,  1.2320e+00,  1.2043e+00,  1.2208e+00,  1.2439e+00,
          1.2587e+00,  1.2337e+00,  1.1943e+00,  1.1893e+00,  1.2092e+00,
          1.1821e+00,  1.1821e+00,  2.9888e+00,  2.9665e+00,  2.5845e+00,
          2.7539e+00,  2.9849e+00,  2.5953e+00,  2.9397e+00,  2.5921e+00,
          2.5874e+00,  1.3736e+00,  1.4294e+00,  1.4018e+00,  1.3846e+00,
          1.4035e+00,  1.4048e+00,  1.3871e+00,  1.2747e+00,  1.3293e+00,
          1.3214e+00,  1.2683e+00,  1.1664e+00,  1.1901e+00,  1.3132e+00,
          1.2556e+00,  1.3548e+00,  1.1783e+00,  1.2327e+00],
        [ 1.7370e+00,  1.3882e+00,  6.0601e-01,  8.5508e-01,  1.2178e+00,
          1.6333e+00,  1.5561e+00,  1.7359e+00,  1.7359e+00,  1.5786e+00,
          1.2189e+00,  1.4063e+00,  8.5117e-01,  1.6394e+00,  1.7384e-01,
          1.5301e+00,  1.7110e+00,  8.7653e-01,  1.2730e+00,  8.9356e-01,
          7.0565e-01,  1.0963e+00,  1.5821e+00,  1.6358e+00,  1.4075e+00,
          1.7382e+00,  1.7382e+00,  7.6643e-01,  8.2427e-01,  1.7104e+00,
          1.5133e+00,  8.2022e-01,  1.6516e+00,  1.1451e+00,  1.7621e+00,
          1.6758e+00,  1.2754e-01, -1.0990e-01, -1.2868e-01,  7.3665e-02,
          3.3100e-01,  4.2859e-01,  1.3047e-02,  1.5214e+01,  5.8910e+00,
          7.1353e-01,  1.2442e+00,  1.3373e+00,  1.5498e+00,  9.3634e-01,
          1.4809e+00,  3.2857e-01,  1.6207e+00,  1.7112e+00],
        [ 1.2290e+00,  1.2621e+00,  1.3260e+00,  1.3042e+00,  1.2716e+00,
          1.2361e+00,  1.2015e+00,  1.2270e+00,  1.2270e+00,  1.1941e+00,
          1.3232e+00,  1.2157e+00,  1.3599e+00,  1.2737e+00,  1.4118e+00,
          1.1973e+00,  1.2699e+00,  1.2501e+00,  1.2832e+00,  1.3038e+00,
          1.3310e+00,  1.2990e+00,  1.2505e+00,  1.2444e+00,  1.1723e+00,
          1.2355e+00,  1.2355e+00,  1.2988e+00,  1.3417e+00,  1.2555e+00,
          1.0576e+00,  1.2531e+00,  1.1346e+00,  1.3062e+00,  1.1287e+00,
          1.2588e+00,  1.3347e+00,  1.0317e+00,  1.3572e+00,  1.3520e+00,
          8.9924e-01,  8.1917e-01,  1.3525e+00,  1.2756e+00,  6.9340e-01,
          3.4416e+00,  2.5925e+00,  3.6481e+00,  2.8954e+00,  2.1712e+00,
          1.8478e+00,  3.0219e+00,  3.3556e+00,  1.8259e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 267 : 179.83646033206713
Test loss for epoch 267 : 179.9805974490437
Test Precision for epoch 267 : 0.26153846153846155
Test Recall for epoch 267 : 0.26153846153846155
Test F1 for epoch 267 : 0.26153846153846155


theta for epoch 268 : tensor([[ 2.6925e+00,  2.7234e+00,  2.7981e+00,  2.9318e+00,  2.8950e+00,
          2.6989e+00,  2.8698e+00,  2.6908e+00,  2.6908e+00,  1.2388e+00,
          1.2663e+00,  1.2557e+00,  1.2949e+00,  1.2277e+00,  1.3362e+00,
          1.2414e+00,  1.2246e+00,  1.2364e+00,  1.2095e+00,  1.1894e+00,
          1.2023e+00,  1.2218e+00,  1.1839e+00,  1.1792e+00,  1.2000e+00,
          1.1722e+00,  1.1722e+00,  1.2178e+00,  1.2609e+00,  1.1928e+00,
          1.2152e+00,  1.2623e+00,  1.2025e+00,  1.2330e+00,  1.1526e+00,
          1.1954e+00,  1.3782e+00,  1.4320e+00,  1.4057e+00,  1.3912e+00,
          1.4069e+00,  1.3507e+00,  1.3915e+00,  1.3342e+00,  1.3385e+00,
          1.3091e+00,  1.2579e+00,  1.2442e+00,  1.2254e+00,  1.3012e+00,
          1.2459e+00,  1.3413e+00,  1.2152e+00,  1.2236e+00],
        [ 1.2137e+00,  1.1801e+00,  1.1173e+00,  1.2340e+00,  1.2923e+00,
          1.2625e+00,  1.2103e+00,  1.2536e+00,  1.2536e+00,  1.7534e+00,
          1.8639e+00,  1.7287e+00,  2.1888e+00,  1.7612e+00,  6.0530e+00,
          1.8152e+00,  1.6869e+00,  5.8741e+00,  1.1802e+00,  1.2554e+00,
          1.1681e+00,  1.1773e+00,  1.2658e+00,  1.2747e+00,  1.2526e+00,
          1.2658e+00,  1.2658e+00,  1.2964e+00,  1.1401e+00,  1.2831e+00,
          1.2974e+00,  1.1845e+00,  1.2955e+00,  1.3309e+00,  1.2440e+00,
          1.2863e+00,  1.3499e+00,  1.4373e+00,  1.3423e+00,  1.3066e+00,
          1.3878e+00,  1.4089e+00,  1.3235e+00,  8.0349e-01,  1.3061e+00,
          1.2019e+00,  1.3395e+00,  1.3186e+00,  1.2947e+00,  1.1594e+00,
          1.3241e+00,  1.1683e+00,  1.2815e+00,  1.2954e+00],
        [ 1.1617e+00,  1.1882e+00,  1.2385e+00,  1.2213e+00,  1.1951e+00,
          1.1673e+00,  1.1745e+00,  1.1601e+00,  1.1601e+00,  1.2397e+00,
          1.2676e+00,  1.2569e+00,  1.2967e+00,  1.2284e+00,  1.3004e+00,
          1.2423e+00,  1.1894e+00,  1.2802e+00,  2.7494e+00,  2.8902e+00,
          2.9351e+00,  2.7980e+00,  2.6954e+00,  2.7189e+00,  2.8356e+00,
          2.6824e+00,  2.6824e+00,  1.2293e+00,  1.2608e+00,  1.1935e+00,
          1.2159e+00,  1.2291e+00,  1.2035e+00,  1.2347e+00,  1.1981e+00,
          1.1962e+00,  1.3714e+00,  1.4266e+00,  1.3989e+00,  1.3381e+00,
          1.4002e+00,  1.4020e+00,  1.3851e+00,  1.3203e+00,  1.2839e+00,
          1.3072e+00,  1.2573e+00,  1.2433e+00,  1.2240e+00,  1.2973e+00,
          1.2450e+00,  1.3408e+00,  1.2117e+00,  1.2221e+00],
        [ 1.1719e+00,  1.1988e+00,  1.2494e+00,  1.2324e+00,  1.2060e+00,
          1.1776e+00,  1.1851e+00,  1.1703e+00,  1.1703e+00,  1.2484e+00,
          1.2766e+00,  1.2659e+00,  1.3063e+00,  1.2369e+00,  1.2611e+00,
          1.2511e+00,  1.2331e+00,  1.2065e+00,  1.2219e+00,  1.2449e+00,
          1.2598e+00,  1.2348e+00,  1.1954e+00,  1.1904e+00,  1.2101e+00,
          1.1832e+00,  1.1832e+00,  2.9896e+00,  2.9676e+00,  2.5853e+00,
          2.7546e+00,  2.9857e+00,  2.5961e+00,  2.9404e+00,  2.5928e+00,
          2.5881e+00,  1.3741e+00,  1.4301e+00,  1.4024e+00,  1.3850e+00,
          1.4040e+00,  1.4056e+00,  1.3877e+00,  1.2735e+00,  1.3299e+00,
          1.3204e+00,  1.2672e+00,  1.1655e+00,  1.1889e+00,  1.3123e+00,
          1.2545e+00,  1.3539e+00,  1.1769e+00,  1.2316e+00],
        [ 1.7373e+00,  1.3862e+00,  6.0379e-01,  8.5464e-01,  1.2177e+00,
          1.6338e+00,  1.5552e+00,  1.7364e+00,  1.7364e+00,  1.5806e+00,
          1.2190e+00,  1.4079e+00,  8.5000e-01,  1.6404e+00,  1.7042e-01,
          1.5306e+00,  1.7136e+00,  8.7175e-01,  1.2711e+00,  8.9357e-01,
          7.0380e-01,  1.0966e+00,  1.5828e+00,  1.6376e+00,  1.4096e+00,
          1.7400e+00,  1.7400e+00,  7.6640e-01,  8.2328e-01,  1.7113e+00,
          1.5133e+00,  8.1834e-01,  1.6524e+00,  1.1458e+00,  1.7630e+00,
          1.6766e+00,  1.2529e-01, -1.1216e-01, -1.3117e-01,  7.1441e-02,
          3.2840e-01,  4.2517e-01,  1.0569e-02,  1.5271e+01,  5.8469e+00,
          7.0978e-01,  1.2428e+00,  1.3357e+00,  1.5484e+00,  9.3252e-01,
          1.4795e+00,  3.2360e-01,  1.6198e+00,  1.7098e+00],
        [ 1.2286e+00,  1.2618e+00,  1.3258e+00,  1.3039e+00,  1.2713e+00,
          1.2357e+00,  1.2011e+00,  1.2266e+00,  1.2266e+00,  1.1954e+00,
          1.3250e+00,  1.2171e+00,  1.3619e+00,  1.2751e+00,  1.4137e+00,
          1.1989e+00,  1.2711e+00,  1.2527e+00,  1.2844e+00,  1.3045e+00,
          1.3323e+00,  1.3002e+00,  1.2515e+00,  1.2455e+00,  1.1729e+00,
          1.2365e+00,  1.2365e+00,  1.2990e+00,  1.3418e+00,  1.2554e+00,
          1.0573e+00,  1.2533e+00,  1.1346e+00,  1.3063e+00,  1.1288e+00,
          1.2588e+00,  1.3339e+00,  1.0314e+00,  1.3561e+00,  1.3513e+00,
          8.9824e-01,  8.1851e-01,  1.3520e+00,  1.2722e+00,  6.9240e-01,
          3.4429e+00,  2.5908e+00,  3.6492e+00,  2.8941e+00,  2.1693e+00,
          1.8457e+00,  3.0209e+00,  3.3566e+00,  1.8238e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 268 : 179.82273771365595
Test loss for epoch 268 : 179.96975709747576
Test Precision for epoch 268 : 0.26153846153846155
Test Recall for epoch 268 : 0.26153846153846155
Test F1 for epoch 268 : 0.26153846153846155


theta for epoch 269 : tensor([[ 2.6931e+00,  2.7240e+00,  2.7988e+00,  2.9327e+00,  2.8959e+00,
          2.6995e+00,  2.8707e+00,  2.6913e+00,  2.6913e+00,  1.2385e+00,
          1.2663e+00,  1.2555e+00,  1.2951e+00,  1.2276e+00,  1.3362e+00,
          1.2413e+00,  1.2244e+00,  1.2370e+00,  1.2103e+00,  1.1902e+00,
          1.2031e+00,  1.2226e+00,  1.1846e+00,  1.1800e+00,  1.2007e+00,
          1.1729e+00,  1.1729e+00,  1.2181e+00,  1.2612e+00,  1.1931e+00,
          1.2155e+00,  1.2626e+00,  1.2029e+00,  1.2333e+00,  1.1529e+00,
          1.1957e+00,  1.3786e+00,  1.4326e+00,  1.4064e+00,  1.3916e+00,
          1.4075e+00,  1.3514e+00,  1.3921e+00,  1.3328e+00,  1.3392e+00,
          1.3093e+00,  1.2580e+00,  1.2443e+00,  1.2255e+00,  1.3014e+00,
          1.2460e+00,  1.3416e+00,  1.2152e+00,  1.2236e+00],
        [ 1.2124e+00,  1.1820e+00,  1.1218e+00,  1.2346e+00,  1.2917e+00,
          1.2609e+00,  1.2104e+00,  1.2520e+00,  1.2520e+00,  1.7649e+00,
          1.8703e+00,  1.7388e+00,  2.1881e+00,  1.7712e+00,  6.0346e+00,
          1.8244e+00,  1.6983e+00,  5.8546e+00,  1.1845e+00,  1.2587e+00,
          1.1746e+00,  1.1784e+00,  1.2660e+00,  1.2734e+00,  1.2515e+00,
          1.2645e+00,  1.2645e+00,  1.2969e+00,  1.1417e+00,  1.2814e+00,
          1.2972e+00,  1.1883e+00,  1.2938e+00,  1.3292e+00,  1.2422e+00,
          1.2845e+00,  1.3501e+00,  1.4364e+00,  1.3414e+00,  1.3071e+00,
          1.3885e+00,  1.4082e+00,  1.3226e+00,  8.1555e-01,  1.3055e+00,
          1.2068e+00,  1.3375e+00,  1.3167e+00,  1.2928e+00,  1.1627e+00,
          1.3221e+00,  1.1774e+00,  1.2796e+00,  1.2935e+00],
        [ 1.1617e+00,  1.1882e+00,  1.2385e+00,  1.2214e+00,  1.1952e+00,
          1.1673e+00,  1.1745e+00,  1.1601e+00,  1.1601e+00,  1.2389e+00,
          1.2671e+00,  1.2562e+00,  1.2964e+00,  1.2277e+00,  1.2999e+00,
          1.2417e+00,  1.1883e+00,  1.2807e+00,  2.7505e+00,  2.8922e+00,
          2.9364e+00,  2.7980e+00,  2.6971e+00,  2.7196e+00,  2.8380e+00,
          2.6841e+00,  2.6841e+00,  1.2288e+00,  1.2609e+00,  1.1934e+00,
          1.2157e+00,  1.2286e+00,  1.2034e+00,  1.2345e+00,  1.1980e+00,
          1.1961e+00,  1.3713e+00,  1.4268e+00,  1.3990e+00,  1.3375e+00,
          1.4002e+00,  1.4022e+00,  1.3851e+00,  1.3187e+00,  1.2835e+00,
          1.3071e+00,  1.2570e+00,  1.2429e+00,  1.2236e+00,  1.2975e+00,
          1.2446e+00,  1.3408e+00,  1.2112e+00,  1.2217e+00],
        [ 1.1720e+00,  1.1989e+00,  1.2495e+00,  1.2325e+00,  1.2061e+00,
          1.1777e+00,  1.1852e+00,  1.1704e+00,  1.1704e+00,  1.2478e+00,
          1.2763e+00,  1.2654e+00,  1.3062e+00,  1.2365e+00,  1.2611e+00,
          1.2507e+00,  1.2325e+00,  1.2070e+00,  1.2225e+00,  1.2453e+00,
          1.2603e+00,  1.2353e+00,  1.1958e+00,  1.1909e+00,  1.2105e+00,
          1.1837e+00,  1.1837e+00,  2.9908e+00,  2.9691e+00,  2.5864e+00,
          2.7557e+00,  2.9870e+00,  2.5972e+00,  2.9415e+00,  2.5939e+00,
          2.5892e+00,  1.3742e+00,  1.4305e+00,  1.4028e+00,  1.3850e+00,
          1.4043e+00,  1.4060e+00,  1.3880e+00,  1.2721e+00,  1.3301e+00,
          1.3203e+00,  1.2670e+00,  1.1654e+00,  1.1885e+00,  1.3122e+00,
          1.2543e+00,  1.3538e+00,  1.1764e+00,  1.2313e+00],
        [ 1.7383e+00,  1.3851e+00,  6.0260e-01,  8.5516e-01,  1.2187e+00,
          1.6351e+00,  1.5552e+00,  1.7377e+00,  1.7377e+00,  1.5813e+00,
          1.2180e+00,  1.4083e+00,  8.4808e-01,  1.6400e+00,  1.6672e-01,
          1.5298e+00,  1.7148e+00,  8.6631e-01,  1.2691e+00,  8.9374e-01,
          7.0220e-01,  1.0968e+00,  1.5833e+00,  1.6392e+00,  1.4117e+00,
          1.7417e+00,  1.7417e+00,  7.6698e-01,  8.2295e-01,  1.7125e+00,
          1.5138e+00,  8.1709e-01,  1.6537e+00,  1.1470e+00,  1.7642e+00,
          1.6779e+00,  1.2256e-01, -1.1486e-01, -1.3409e-01,  6.8763e-02,
          3.2528e-01,  4.2125e-01,  7.6481e-03,  1.5329e+01,  5.8014e+00,
          7.0816e-01,  1.2434e+00,  1.3360e+00,  1.5487e+00,  9.3079e-01,
          1.4799e+00,  3.2087e-01,  1.6206e+00,  1.7101e+00],
        [ 1.2285e+00,  1.2618e+00,  1.3259e+00,  1.3040e+00,  1.2713e+00,
          1.2356e+00,  1.2011e+00,  1.2265e+00,  1.2265e+00,  1.1946e+00,
          1.3246e+00,  1.2164e+00,  1.3618e+00,  1.2744e+00,  1.4136e+00,
          1.1983e+00,  1.2702e+00,  1.2531e+00,  1.2849e+00,  1.3045e+00,
          1.3328e+00,  1.3006e+00,  1.2518e+00,  1.2458e+00,  1.1727e+00,
          1.2367e+00,  1.2367e+00,  1.2988e+00,  1.3417e+00,  1.2551e+00,
          1.0566e+00,  1.2532e+00,  1.1343e+00,  1.3060e+00,  1.1285e+00,
          1.2584e+00,  1.3325e+00,  1.0303e+00,  1.3544e+00,  1.3499e+00,
          8.9640e-01,  8.1696e-01,  1.3508e+00,  1.2681e+00,  6.9047e-01,
          3.4456e+00,  2.5907e+00,  3.6519e+00,  2.8944e+00,  2.1690e+00,
          1.8451e+00,  3.0213e+00,  3.3593e+00,  1.8232e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 269 : 179.80956013004777
Test loss for epoch 269 : 179.95819796323033
Test Precision for epoch 269 : 0.26153846153846155
Test Recall for epoch 269 : 0.26153846153846155
Test F1 for epoch 269 : 0.26153846153846155


theta for epoch 270 : tensor([[ 2.6948e+00,  2.7257e+00,  2.8005e+00,  2.9347e+00,  2.8979e+00,
          2.7012e+00,  2.8727e+00,  2.6931e+00,  2.6931e+00,  1.2368e+00,
          1.2650e+00,  1.2538e+00,  1.2939e+00,  1.2261e+00,  1.3349e+00,
          1.2399e+00,  1.2227e+00,  1.2363e+00,  1.2093e+00,  1.1890e+00,
          1.2020e+00,  1.2215e+00,  1.1835e+00,  1.1788e+00,  1.1996e+00,
          1.1718e+00,  1.1718e+00,  1.2178e+00,  1.2610e+00,  1.1929e+00,
          1.2154e+00,  1.2625e+00,  1.2027e+00,  1.2331e+00,  1.1527e+00,
          1.1955e+00,  1.3792e+00,  1.4335e+00,  1.4072e+00,  1.3922e+00,
          1.4082e+00,  1.3523e+00,  1.3929e+00,  1.3316e+00,  1.3400e+00,
          1.3102e+00,  1.2588e+00,  1.2450e+00,  1.2262e+00,  1.3023e+00,
          1.2467e+00,  1.3426e+00,  1.2159e+00,  1.2244e+00],
        [ 1.2122e+00,  1.1851e+00,  1.1272e+00,  1.2361e+00,  1.2921e+00,
          1.2603e+00,  1.2117e+00,  1.2514e+00,  1.2514e+00,  1.7754e+00,
          1.8758e+00,  1.7481e+00,  2.1863e+00,  1.7802e+00,  6.0141e+00,
          1.8327e+00,  1.7089e+00,  5.8332e+00,  1.1876e+00,  1.2607e+00,
          1.1800e+00,  1.1785e+00,  1.2650e+00,  1.2708e+00,  1.2493e+00,
          1.2619e+00,  1.2619e+00,  1.2978e+00,  1.1437e+00,  1.2801e+00,
          1.2974e+00,  1.1927e+00,  1.2925e+00,  1.3279e+00,  1.2410e+00,
          1.2833e+00,  1.3512e+00,  1.4364e+00,  1.3415e+00,  1.3085e+00,
          1.3901e+00,  1.4085e+00,  1.3225e+00,  8.2839e-01,  1.3058e+00,
          1.2130e+00,  1.3371e+00,  1.3165e+00,  1.2925e+00,  1.1673e+00,
          1.3217e+00,  1.1877e+00,  1.2793e+00,  1.2931e+00],
        [ 1.1629e+00,  1.1895e+00,  1.2397e+00,  1.2226e+00,  1.1964e+00,
          1.1686e+00,  1.1758e+00,  1.1613e+00,  1.1613e+00,  1.2380e+00,
          1.2665e+00,  1.2553e+00,  1.2960e+00,  1.2270e+00,  1.2992e+00,
          1.2410e+00,  1.1870e+00,  1.2810e+00,  2.7497e+00,  2.8924e+00,
          2.9357e+00,  2.7962e+00,  2.6969e+00,  2.7184e+00,  2.8385e+00,
          2.6839e+00,  2.6839e+00,  1.2292e+00,  1.2617e+00,  1.1941e+00,
          1.2165e+00,  1.2290e+00,  1.2042e+00,  1.2352e+00,  1.1987e+00,
          1.1968e+00,  1.3724e+00,  1.4282e+00,  1.4003e+00,  1.3381e+00,
          1.4014e+00,  1.4035e+00,  1.3864e+00,  1.3182e+00,  1.2842e+00,
          1.3089e+00,  1.2585e+00,  1.2444e+00,  1.2251e+00,  1.2994e+00,
          1.2462e+00,  1.3427e+00,  1.2125e+00,  1.2232e+00],
        [ 1.1726e+00,  1.1996e+00,  1.2501e+00,  1.2331e+00,  1.2068e+00,
          1.1784e+00,  1.1859e+00,  1.1710e+00,  1.1710e+00,  1.2463e+00,
          1.2752e+00,  1.2639e+00,  1.3052e+00,  1.2351e+00,  1.2601e+00,
          1.2494e+00,  1.2309e+00,  1.2067e+00,  1.2215e+00,  1.2441e+00,
          1.2593e+00,  1.2342e+00,  1.1947e+00,  1.1898e+00,  1.2093e+00,
          1.1825e+00,  1.1825e+00,  2.9921e+00,  2.9707e+00,  2.5876e+00,
          2.7569e+00,  2.9883e+00,  2.5984e+00,  2.9427e+00,  2.5952e+00,
          2.5905e+00,  1.3748e+00,  1.4314e+00,  1.4037e+00,  1.3856e+00,
          1.4050e+00,  1.4070e+00,  1.3888e+00,  1.2712e+00,  1.3309e+00,
          1.3211e+00,  1.2677e+00,  1.1662e+00,  1.1890e+00,  1.3130e+00,
          1.2550e+00,  1.3548e+00,  1.1768e+00,  1.2320e+00],
        [ 1.7398e+00,  1.3844e+00,  6.0172e-01,  8.5600e-01,  1.2200e+00,
          1.6369e+00,  1.5556e+00,  1.7395e+00,  1.7395e+00,  1.5808e+00,
          1.2159e+00,  1.4075e+00,  8.4522e-01,  1.6385e+00,  1.6223e-01,
          1.5279e+00,  1.7149e+00,  8.6003e-01,  1.2655e+00,  8.9223e-01,
          6.9894e-01,  1.0952e+00,  1.5820e+00,  1.6390e+00,  1.4119e+00,
          1.7415e+00,  1.7415e+00,  7.6728e-01,  8.2244e-01,  1.7136e+00,
          1.5141e+00,  8.1563e-01,  1.6548e+00,  1.1480e+00,  1.7653e+00,
          1.6790e+00,  1.2042e-01, -1.1699e-01, -1.3645e-01,  6.6679e-02,
          3.2269e-01,  4.1792e-01,  5.3151e-03,  1.5387e+01,  5.7556e+00,
          7.0754e-01,  1.2450e+00,  1.3374e+00,  1.5502e+00,  9.3016e-01,
          1.4815e+00,  3.1904e-01,  1.6226e+00,  1.7116e+00],
        [ 1.2289e+00,  1.2623e+00,  1.3265e+00,  1.3045e+00,  1.2718e+00,
          1.2360e+00,  1.2015e+00,  1.2269e+00,  1.2269e+00,  1.1927e+00,
          1.3231e+00,  1.2146e+00,  1.3606e+00,  1.2727e+00,  1.4123e+00,
          1.1967e+00,  1.2682e+00,  1.2524e+00,  1.2836e+00,  1.3026e+00,
          1.3316e+00,  1.2993e+00,  1.2504e+00,  1.2443e+00,  1.1707e+00,
          1.2352e+00,  1.2352e+00,  1.2985e+00,  1.3414e+00,  1.2546e+00,
          1.0557e+00,  1.2529e+00,  1.1339e+00,  1.3056e+00,  1.1280e+00,
          1.2580e+00,  1.3316e+00,  1.0297e+00,  1.3532e+00,  1.3491e+00,
          8.9500e-01,  8.1580e-01,  1.3501e+00,  1.2645e+00,  6.8893e-01,
          3.4494e+00,  2.5915e+00,  3.6555e+00,  2.8956e+00,  2.1697e+00,
          1.8456e+00,  3.0227e+00,  3.3630e+00,  1.8237e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 270 : 179.79600745343697
Test loss for epoch 270 : 179.94645129359935
Test Precision for epoch 270 : 0.26153846153846155
Test Recall for epoch 270 : 0.26153846153846155
Test F1 for epoch 270 : 0.26153846153846155


theta for epoch 271 : tensor([[ 2.6955e+00,  2.7264e+00,  2.8013e+00,  2.9356e+00,  2.8989e+00,
          2.7019e+00,  2.8736e+00,  2.6938e+00,  2.6938e+00,  1.2374e+00,
          1.2658e+00,  1.2544e+00,  1.2949e+00,  1.2268e+00,  1.3357e+00,
          1.2407e+00,  1.2232e+00,  1.2376e+00,  1.2094e+00,  1.1891e+00,
          1.2021e+00,  1.2216e+00,  1.1836e+00,  1.1789e+00,  1.1996e+00,
          1.1718e+00,  1.1718e+00,  1.2176e+00,  1.2608e+00,  1.1927e+00,
          1.2152e+00,  1.2623e+00,  1.2025e+00,  1.2329e+00,  1.1525e+00,
          1.1953e+00,  1.3803e+00,  1.4347e+00,  1.4084e+00,  1.3933e+00,
          1.4094e+00,  1.3537e+00,  1.3940e+00,  1.3308e+00,  1.3412e+00,
          1.3099e+00,  1.2584e+00,  1.2446e+00,  1.2258e+00,  1.3021e+00,
          1.2463e+00,  1.3424e+00,  1.2154e+00,  1.2239e+00],
        [ 1.2103e+00,  1.1864e+00,  1.1307e+00,  1.2357e+00,  1.2906e+00,
          1.2580e+00,  1.2113e+00,  1.2491e+00,  1.2491e+00,  1.7880e+00,
          1.8831e+00,  1.7592e+00,  2.1864e+00,  1.7911e+00,  5.9945e+00,
          1.8428e+00,  1.7214e+00,  5.8126e+00,  1.1912e+00,  1.2630e+00,
          1.1856e+00,  1.1790e+00,  1.2646e+00,  1.2689e+00,  1.2476e+00,
          1.2600e+00,  1.2600e+00,  1.2979e+00,  1.1446e+00,  1.2780e+00,
          1.2968e+00,  1.1961e+00,  1.2904e+00,  1.3259e+00,  1.2389e+00,
          1.2812e+00,  1.3521e+00,  1.4364e+00,  1.3414e+00,  1.3098e+00,
          1.3915e+00,  1.4087e+00,  1.3224e+00,  8.4078e-01,  1.3061e+00,
          1.2171e+00,  1.3349e+00,  1.3143e+00,  1.2904e+00,  1.1699e+00,
          1.3194e+00,  1.1958e+00,  1.2771e+00,  1.2908e+00],
        [ 1.1625e+00,  1.1891e+00,  1.2393e+00,  1.2222e+00,  1.1960e+00,
          1.1682e+00,  1.1754e+00,  1.1610e+00,  1.1610e+00,  1.2384e+00,
          1.2673e+00,  1.2557e+00,  1.2969e+00,  1.2275e+00,  1.2998e+00,
          1.2417e+00,  1.1871e+00,  1.2825e+00,  2.7502e+00,  2.8938e+00,
          2.9364e+00,  2.7956e+00,  2.6979e+00,  2.7185e+00,  2.8402e+00,
          2.6849e+00,  2.6849e+00,  1.2286e+00,  1.2617e+00,  1.1940e+00,
          1.2163e+00,  1.2285e+00,  1.2040e+00,  1.2351e+00,  1.1985e+00,
          1.1966e+00,  1.3733e+00,  1.4294e+00,  1.4014e+00,  1.3385e+00,
          1.4024e+00,  1.4047e+00,  1.3875e+00,  1.3176e+00,  1.2848e+00,
          1.3088e+00,  1.2582e+00,  1.2441e+00,  1.2247e+00,  1.2995e+00,
          1.2458e+00,  1.3427e+00,  1.2120e+00,  1.2228e+00],
        [ 1.1722e+00,  1.1992e+00,  1.2496e+00,  1.2327e+00,  1.2064e+00,
          1.1779e+00,  1.1855e+00,  1.1706e+00,  1.1706e+00,  1.2468e+00,
          1.2760e+00,  1.2645e+00,  1.3062e+00,  1.2358e+00,  1.2611e+00,
          1.2502e+00,  1.2314e+00,  1.2083e+00,  1.2217e+00,  1.2441e+00,
          1.2594e+00,  1.2343e+00,  1.1948e+00,  1.1899e+00,  1.2093e+00,
          1.1826e+00,  1.1826e+00,  2.9930e+00,  2.9718e+00,  2.5884e+00,
          2.7576e+00,  2.9892e+00,  2.5992e+00,  2.9435e+00,  2.5959e+00,
          2.5912e+00,  1.3758e+00,  1.4326e+00,  1.4048e+00,  1.3865e+00,
          1.4061e+00,  1.4082e+00,  1.3899e+00,  1.2705e+00,  1.3320e+00,
          1.3209e+00,  1.2674e+00,  1.1660e+00,  1.1885e+00,  1.3128e+00,
          1.2546e+00,  1.3546e+00,  1.1762e+00,  1.2316e+00],
        [ 1.7400e+00,  1.3824e+00,  5.9989e-01,  8.5578e-01,  1.2202e+00,
          1.6375e+00,  1.5547e+00,  1.7401e+00,  1.7401e+00,  1.5821e+00,
          1.2156e+00,  1.4085e+00,  8.4403e-01,  1.6387e+00,  1.5911e-01,
          1.5278e+00,  1.7169e+00,  8.5572e-01,  1.2630e+00,  8.9177e-01,
          6.9670e-01,  1.0945e+00,  1.5817e+00,  1.6397e+00,  1.4132e+00,
          1.7424e+00,  1.7424e+00,  7.6719e-01,  8.2158e-01,  1.7143e+00,
          1.5141e+00,  8.1383e-01,  1.6556e+00,  1.1485e+00,  1.7661e+00,
          1.6797e+00,  1.1850e-01, -1.1887e-01, -1.3858e-01,  6.4836e-02,
          3.2031e-01,  4.1484e-01,  3.2209e-03,  1.5446e+01,  5.7092e+00,
          7.0512e-01,  1.2445e+00,  1.3367e+00,  1.5497e+00,  9.2765e-01,
          1.4810e+00,  3.1571e-01,  1.6227e+00,  1.7112e+00],
        [ 1.2285e+00,  1.2621e+00,  1.3263e+00,  1.3043e+00,  1.2715e+00,
          1.2356e+00,  1.2012e+00,  1.2266e+00,  1.2266e+00,  1.1935e+00,
          1.3243e+00,  1.2155e+00,  1.3621e+00,  1.2736e+00,  1.4137e+00,
          1.1978e+00,  1.2688e+00,  1.2543e+00,  1.2840e+00,  1.3024e+00,
          1.3321e+00,  1.2996e+00,  1.2506e+00,  1.2445e+00,  1.1704e+00,
          1.2353e+00,  1.2353e+00,  1.2986e+00,  1.3415e+00,  1.2545e+00,
          1.0552e+00,  1.2531e+00,  1.1339e+00,  1.3056e+00,  1.1280e+00,
          1.2579e+00,  1.3314e+00,  1.0300e+00,  1.3527e+00,  1.3490e+00,
          8.9466e-01,  8.1574e-01,  1.3503e+00,  1.2617e+00,  6.8853e-01,
          3.4510e+00,  2.5901e+00,  3.6568e+00,  2.8945e+00,  2.1682e+00,
          1.8439e+00,  3.0218e+00,  3.3645e+00,  1.8219e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 271 : 179.78161506101438
Test loss for epoch 271 : 179.93529867156408
Test Precision for epoch 271 : 0.26153846153846155
Test Recall for epoch 271 : 0.26153846153846155
Test F1 for epoch 271 : 0.26153846153846155


theta for epoch 272 : tensor([[ 2.6959e+00,  2.7268e+00,  2.8017e+00,  2.9363e+00,  2.8996e+00,
          2.7023e+00,  2.8743e+00,  2.6942e+00,  2.6942e+00,  1.2380e+00,
          1.2667e+00,  1.2550e+00,  1.2959e+00,  1.2276e+00,  1.3366e+00,
          1.2415e+00,  1.2238e+00,  1.2390e+00,  1.2103e+00,  1.1899e+00,
          1.2029e+00,  1.2224e+00,  1.1844e+00,  1.1797e+00,  1.2004e+00,
          1.1726e+00,  1.1726e+00,  1.2176e+00,  1.2608e+00,  1.1928e+00,
          1.2153e+00,  1.2624e+00,  1.2025e+00,  1.2329e+00,  1.1526e+00,
          1.1954e+00,  1.3807e+00,  1.4354e+00,  1.4091e+00,  1.3937e+00,
          1.4100e+00,  1.3544e+00,  1.3946e+00,  1.3294e+00,  1.3419e+00,
          1.3097e+00,  1.2581e+00,  1.2443e+00,  1.2254e+00,  1.3018e+00,
          1.2460e+00,  1.3422e+00,  1.2149e+00,  1.2235e+00],
        [ 1.2081e+00,  1.1874e+00,  1.1337e+00,  1.2348e+00,  1.2886e+00,
          1.2553e+00,  1.2105e+00,  1.2464e+00,  1.2464e+00,  1.8007e+00,
          1.8906e+00,  1.7706e+00,  2.1865e+00,  1.8022e+00,  5.9739e+00,
          1.8531e+00,  1.7342e+00,  5.7910e+00,  1.1954e+00,  1.2660e+00,
          1.1917e+00,  1.1803e+00,  1.2649e+00,  1.2678e+00,  1.2468e+00,
          1.2589e+00,  1.2589e+00,  1.2981e+00,  1.1456e+00,  1.2761e+00,
          1.2964e+00,  1.1996e+00,  1.2885e+00,  1.3240e+00,  1.2370e+00,
          1.2793e+00,  1.3523e+00,  1.4357e+00,  1.3406e+00,  1.3104e+00,
          1.3921e+00,  1.4083e+00,  1.3216e+00,  8.5235e-01,  1.3058e+00,
          1.2210e+00,  1.3326e+00,  1.3123e+00,  1.2883e+00,  1.1723e+00,
          1.3172e+00,  1.2034e+00,  1.2749e+00,  1.2886e+00],
        [ 1.1613e+00,  1.1880e+00,  1.2380e+00,  1.2210e+00,  1.1948e+00,
          1.1670e+00,  1.1743e+00,  1.1598e+00,  1.1598e+00,  1.2383e+00,
          1.2675e+00,  1.2557e+00,  1.2973e+00,  1.2276e+00,  1.2998e+00,
          1.2418e+00,  1.1866e+00,  1.2835e+00,  2.7519e+00,  2.8966e+00,
          2.9383e+00,  2.7963e+00,  2.7002e+00,  2.7198e+00,  2.8432e+00,
          2.6872e+00,  2.6872e+00,  1.2277e+00,  1.2613e+00,  1.1934e+00,
          1.2158e+00,  1.2276e+00,  1.2035e+00,  1.2345e+00,  1.1980e+00,
          1.1961e+00,  1.3731e+00,  1.4295e+00,  1.4014e+00,  1.3378e+00,
          1.4024e+00,  1.4049e+00,  1.3874e+00,  1.3158e+00,  1.2842e+00,
          1.3082e+00,  1.2574e+00,  1.2432e+00,  1.2238e+00,  1.2990e+00,
          1.2449e+00,  1.3422e+00,  1.2109e+00,  1.2219e+00],
        [ 1.1715e+00,  1.1986e+00,  1.2489e+00,  1.2320e+00,  1.2057e+00,
          1.1773e+00,  1.1848e+00,  1.1699e+00,  1.1699e+00,  1.2474e+00,
          1.2769e+00,  1.2651e+00,  1.3072e+00,  1.2366e+00,  1.2622e+00,
          1.2510e+00,  1.2320e+00,  1.2100e+00,  1.2227e+00,  1.2450e+00,
          1.2604e+00,  1.2353e+00,  1.1958e+00,  1.1908e+00,  1.2101e+00,
          1.1835e+00,  1.1835e+00,  2.9938e+00,  2.9729e+00,  2.5891e+00,
          2.7582e+00,  2.9900e+00,  2.6000e+00,  2.9442e+00,  2.5967e+00,
          2.5920e+00,  1.3762e+00,  1.4333e+00,  1.4055e+00,  1.3868e+00,
          1.4067e+00,  1.4090e+00,  1.3905e+00,  1.2694e+00,  1.3326e+00,
          1.3207e+00,  1.2671e+00,  1.1659e+00,  1.1881e+00,  1.3126e+00,
          1.2543e+00,  1.3545e+00,  1.1756e+00,  1.2312e+00],
        [ 1.7401e+00,  1.3805e+00,  5.9859e-01,  8.5592e-01,  1.2206e+00,
          1.6380e+00,  1.5538e+00,  1.7406e+00,  1.7406e+00,  1.5838e+00,
          1.2160e+00,  1.4098e+00,  8.4370e-01,  1.6393e+00,  1.5715e-01,
          1.5280e+00,  1.7192e+00,  8.5250e-01,  1.2621e+00,  8.9297e-01,
          6.9624e-01,  1.0954e+00,  1.5827e+00,  1.6417e+00,  1.4157e+00,
          1.7444e+00,  1.7444e+00,  7.6800e-01,  8.2161e-01,  1.7155e+00,
          1.5147e+00,  8.1302e-01,  1.6568e+00,  1.1497e+00,  1.7673e+00,
          1.6809e+00,  1.1566e-01, -1.2161e-01, -1.4159e-01,  6.2098e-02,
          3.1696e-01,  4.1082e-01,  2.4830e-04,  1.5504e+01,  5.6610e+00,
          7.0387e-01,  1.2448e+00,  1.3366e+00,  1.5497e+00,  9.2617e-01,
          1.4811e+00,  3.1388e-01,  1.6232e+00,  1.7111e+00],
        [ 1.2276e+00,  1.2613e+00,  1.3256e+00,  1.3035e+00,  1.2707e+00,
          1.2347e+00,  1.2004e+00,  1.2256e+00,  1.2256e+00,  1.1940e+00,
          1.3252e+00,  1.2161e+00,  1.3633e+00,  1.2743e+00,  1.4148e+00,
          1.1986e+00,  1.2693e+00,  1.2560e+00,  1.2851e+00,  1.3028e+00,
          1.3331e+00,  1.3007e+00,  1.2515e+00,  1.2453e+00,  1.1707e+00,
          1.2362e+00,  1.2362e+00,  1.2987e+00,  1.3416e+00,  1.2544e+00,
          1.0547e+00,  1.2532e+00,  1.1338e+00,  1.3056e+00,  1.1279e+00,
          1.2578e+00,  1.3303e+00,  1.0294e+00,  1.3512e+00,  1.3479e+00,
          8.9325e-01,  8.1460e-01,  1.3494e+00,  1.2579e+00,  6.8704e-01,
          3.4530e+00,  2.5891e+00,  3.6585e+00,  2.8938e+00,  2.1670e+00,
          1.8425e+00,  3.0213e+00,  3.3663e+00,  1.8205e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 272 : 179.76771311759927
Test loss for epoch 272 : 179.92350206139957
Test Precision for epoch 272 : 0.26153846153846155
Test Recall for epoch 272 : 0.26153846153846155
Test F1 for epoch 272 : 0.26153846153846155


theta for epoch 273 : tensor([[ 2.6974e+00,  2.7283e+00,  2.8032e+00,  2.9381e+00,  2.9013e+00,
          2.7037e+00,  2.8761e+00,  2.6956e+00,  2.6956e+00,  1.2366e+00,
          1.2655e+00,  1.2537e+00,  1.2949e+00,  1.2264e+00,  1.3354e+00,
          1.2403e+00,  1.2224e+00,  1.2384e+00,  1.2097e+00,  1.1892e+00,
          1.2022e+00,  1.2218e+00,  1.1838e+00,  1.1790e+00,  1.1996e+00,
          1.1719e+00,  1.1719e+00,  1.2178e+00,  1.2610e+00,  1.1930e+00,
          1.2156e+00,  1.2626e+00,  1.2028e+00,  1.2332e+00,  1.1528e+00,
          1.1956e+00,  1.3810e+00,  1.4360e+00,  1.4096e+00,  1.3940e+00,
          1.4104e+00,  1.3551e+00,  1.3950e+00,  1.3279e+00,  1.3424e+00,
          1.3102e+00,  1.2585e+00,  1.2447e+00,  1.2258e+00,  1.3024e+00,
          1.2464e+00,  1.3428e+00,  1.2152e+00,  1.2239e+00],
        [ 1.2079e+00,  1.1904e+00,  1.1384e+00,  1.2359e+00,  1.2886e+00,
          1.2547e+00,  1.2117e+00,  1.2458e+00,  1.2458e+00,  1.8117e+00,
          1.8963e+00,  1.7802e+00,  2.1849e+00,  1.8114e+00,  5.9508e+00,
          1.8616e+00,  1.7453e+00,  5.7669e+00,  1.1986e+00,  1.2679e+00,
          1.1968e+00,  1.1808e+00,  1.2644e+00,  1.2659e+00,  1.2452e+00,
          1.2569e+00,  1.2569e+00,  1.2994e+00,  1.1476e+00,  1.2754e+00,
          1.2970e+00,  1.2041e+00,  1.2877e+00,  1.3234e+00,  1.2363e+00,
          1.2786e+00,  1.3531e+00,  1.4356e+00,  1.3406e+00,  1.3118e+00,
          1.3932e+00,  1.4084e+00,  1.3214e+00,  8.6434e-01,  1.3060e+00,
          1.2262e+00,  1.3321e+00,  1.3118e+00,  1.2879e+00,  1.1761e+00,
          1.3166e+00,  1.2121e+00,  1.2744e+00,  1.2880e+00],
        [ 1.1619e+00,  1.1886e+00,  1.2385e+00,  1.2215e+00,  1.1954e+00,
          1.1675e+00,  1.1748e+00,  1.1603e+00,  1.1603e+00,  1.2371e+00,
          1.2666e+00,  1.2545e+00,  1.2965e+00,  1.2266e+00,  1.2988e+00,
          1.2408e+00,  1.1850e+00,  1.2834e+00,  2.7520e+00,  2.8977e+00,
          2.9386e+00,  2.7953e+00,  2.7009e+00,  2.7195e+00,  2.8447e+00,
          2.6879e+00,  2.6879e+00,  1.2279e+00,  1.2620e+00,  1.1940e+00,
          1.2164e+00,  1.2279e+00,  1.2041e+00,  1.2351e+00,  1.1986e+00,
          1.1967e+00,  1.3735e+00,  1.4301e+00,  1.4020e+00,  1.3376e+00,
          1.4029e+00,  1.4055e+00,  1.3880e+00,  1.3146e+00,  1.2842e+00,
          1.3091e+00,  1.2582e+00,  1.2440e+00,  1.2246e+00,  1.3001e+00,
          1.2457e+00,  1.3432e+00,  1.2114e+00,  1.2226e+00],
        [ 1.1721e+00,  1.1992e+00,  1.2494e+00,  1.2326e+00,  1.2062e+00,
          1.1778e+00,  1.1855e+00,  1.1705e+00,  1.1705e+00,  1.2463e+00,
          1.2761e+00,  1.2640e+00,  1.3065e+00,  1.2357e+00,  1.2617e+00,
          1.2501e+00,  1.2309e+00,  1.2100e+00,  1.2223e+00,  1.2445e+00,
          1.2599e+00,  1.2348e+00,  1.1954e+00,  1.1904e+00,  1.2095e+00,
          1.1831e+00,  1.1831e+00,  2.9948e+00,  2.9740e+00,  2.5900e+00,
          2.7590e+00,  2.9910e+00,  2.6008e+00,  2.9450e+00,  2.5976e+00,
          2.5928e+00,  1.3767e+00,  1.4341e+00,  1.4062e+00,  1.3872e+00,
          1.4074e+00,  1.4098e+00,  1.3911e+00,  1.2683e+00,  1.3332e+00,
          1.3214e+00,  1.2677e+00,  1.1667e+00,  1.1885e+00,  1.3133e+00,
          1.2549e+00,  1.3553e+00,  1.1759e+00,  1.2318e+00],
        [ 1.7412e+00,  1.3794e+00,  5.9788e-01,  8.5669e-01,  1.2218e+00,
          1.6395e+00,  1.5538e+00,  1.7421e+00,  1.7421e+00,  1.5833e+00,
          1.2143e+00,  1.4092e+00,  8.4152e-01,  1.6378e+00,  1.5359e-01,
          1.5262e+00,  1.7195e+00,  8.4745e-01,  1.2595e+00,  8.9252e-01,
          6.9410e-01,  1.0944e+00,  1.5820e+00,  1.6419e+00,  1.4164e+00,
          1.7446e+00,  1.7446e+00,  7.6868e-01,  8.2153e-01,  1.7169e+00,
          1.5154e+00,  8.1220e-01,  1.6581e+00,  1.1508e+00,  1.7686e+00,
          1.6822e+00,  1.1343e-01, -1.2377e-01, -1.4402e-01,  5.9978e-02,
          3.1420e-01,  4.0744e-01, -2.1165e-03,  1.5564e+01,  5.6126e+00,
          7.0321e-01,  1.2459e+00,  1.3374e+00,  1.5506e+00,  9.2540e-01,
          1.4821e+00,  3.1249e-01,  1.6248e+00,  1.7120e+00],
        [ 1.2278e+00,  1.2616e+00,  1.3260e+00,  1.3038e+00,  1.2709e+00,
          1.2349e+00,  1.2006e+00,  1.2258e+00,  1.2258e+00,  1.1924e+00,
          1.3240e+00,  1.2146e+00,  1.3623e+00,  1.2728e+00,  1.4138e+00,
          1.1973e+00,  1.2675e+00,  1.2555e+00,  1.2844e+00,  1.3014e+00,
          1.3325e+00,  1.2999e+00,  1.2507e+00,  1.2444e+00,  1.1692e+00,
          1.2352e+00,  1.2352e+00,  1.2989e+00,  1.3418e+00,  1.2545e+00,
          1.0543e+00,  1.2535e+00,  1.1339e+00,  1.3058e+00,  1.1280e+00,
          1.2578e+00,  1.3290e+00,  1.0284e+00,  1.3495e+00,  1.3467e+00,
          8.9152e-01,  8.1308e-01,  1.3484e+00,  1.2540e+00,  6.8516e-01,
          3.4563e+00,  2.5894e+00,  3.6614e+00,  2.8944e+00,  2.1672e+00,
          1.8424e+00,  3.0222e+00,  3.3696e+00,  1.8204e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 273 : 179.7526964270154
Test loss for epoch 273 : 179.91063528308513
Test Precision for epoch 273 : 0.26153846153846155
Test Recall for epoch 273 : 0.26153846153846155
Test F1 for epoch 273 : 0.26153846153846155


theta for epoch 274 : tensor([[ 2.6982e+00,  2.7292e+00,  2.8041e+00,  2.9392e+00,  2.9024e+00,
          2.7046e+00,  2.8772e+00,  2.6965e+00,  2.6965e+00,  1.2365e+00,
          1.2657e+00,  1.2536e+00,  1.2952e+00,  1.2265e+00,  1.3356e+00,
          1.2404e+00,  1.2222e+00,  1.2390e+00,  1.2092e+00,  1.1886e+00,
          1.2017e+00,  1.2212e+00,  1.1832e+00,  1.1784e+00,  1.1990e+00,
          1.1713e+00,  1.1713e+00,  1.2180e+00,  1.2612e+00,  1.1933e+00,
          1.2159e+00,  1.2629e+00,  1.2030e+00,  1.2334e+00,  1.1530e+00,
          1.1958e+00,  1.3818e+00,  1.4370e+00,  1.4107e+00,  1.3948e+00,
          1.4115e+00,  1.3562e+00,  1.3960e+00,  1.3269e+00,  1.3434e+00,
          1.3104e+00,  1.2587e+00,  1.2448e+00,  1.2259e+00,  1.3026e+00,
          1.2465e+00,  1.3431e+00,  1.2152e+00,  1.2240e+00],
        [ 1.2075e+00,  1.1932e+00,  1.1425e+00,  1.2365e+00,  1.2881e+00,
          1.2537e+00,  1.2127e+00,  1.2448e+00,  1.2448e+00,  1.8238e+00,
          1.9032e+00,  1.7909e+00,  2.1845e+00,  1.8219e+00,  5.9279e+00,
          1.8712e+00,  1.7576e+00,  5.7429e+00,  1.2011e+00,  1.2691e+00,
          1.2011e+00,  1.1808e+00,  1.2633e+00,  1.2635e+00,  1.2431e+00,
          1.2546e+00,  1.2546e+00,  1.2998e+00,  1.1488e+00,  1.2740e+00,
          1.2969e+00,  1.2076e+00,  1.2863e+00,  1.3220e+00,  1.2349e+00,
          1.2772e+00,  1.3540e+00,  1.4356e+00,  1.3406e+00,  1.3132e+00,
          1.3943e+00,  1.4087e+00,  1.3214e+00,  8.7598e-01,  1.3064e+00,
          1.2303e+00,  1.3306e+00,  1.3105e+00,  1.2865e+00,  1.1789e+00,
          1.3152e+00,  1.2193e+00,  1.2730e+00,  1.2866e+00],
        [ 1.1626e+00,  1.1893e+00,  1.2391e+00,  1.2222e+00,  1.1960e+00,
          1.1682e+00,  1.1755e+00,  1.1610e+00,  1.1610e+00,  1.2370e+00,
          1.2668e+00,  1.2545e+00,  1.2969e+00,  1.2267e+00,  1.2989e+00,
          1.2409e+00,  1.1846e+00,  1.2843e+00,  2.7517e+00,  2.8984e+00,
          2.9385e+00,  2.7939e+00,  2.7011e+00,  2.7188e+00,  2.8456e+00,
          2.6881e+00,  2.6881e+00,  1.2279e+00,  1.2626e+00,  1.1945e+00,
          1.2169e+00,  1.2280e+00,  1.2045e+00,  1.2356e+00,  1.1990e+00,
          1.1971e+00,  1.3743e+00,  1.4312e+00,  1.4031e+00,  1.3379e+00,
          1.4039e+00,  1.4066e+00,  1.3889e+00,  1.3138e+00,  1.2846e+00,
          1.3096e+00,  1.2586e+00,  1.2443e+00,  1.2249e+00,  1.3008e+00,
          1.2461e+00,  1.3439e+00,  1.2116e+00,  1.2229e+00],
        [ 1.1728e+00,  1.1999e+00,  1.2499e+00,  1.2332e+00,  1.2069e+00,
          1.1785e+00,  1.1861e+00,  1.1712e+00,  1.1712e+00,  1.2463e+00,
          1.2764e+00,  1.2640e+00,  1.3069e+00,  1.2358e+00,  1.2622e+00,
          1.2503e+00,  1.2308e+00,  1.2110e+00,  1.2219e+00,  1.2438e+00,
          1.2594e+00,  1.2343e+00,  1.1949e+00,  1.1899e+00,  1.2089e+00,
          1.1825e+00,  1.1825e+00,  2.9954e+00,  2.9749e+00,  2.5906e+00,
          2.7594e+00,  2.9916e+00,  2.6014e+00,  2.9455e+00,  2.5981e+00,
          2.5934e+00,  1.3775e+00,  1.4351e+00,  1.4073e+00,  1.3880e+00,
          1.4084e+00,  1.4109e+00,  1.3921e+00,  1.2676e+00,  1.3342e+00,
          1.3217e+00,  1.2679e+00,  1.1671e+00,  1.1886e+00,  1.3136e+00,
          1.2551e+00,  1.3557e+00,  1.1757e+00,  1.2319e+00],
        [ 1.7417e+00,  1.3779e+00,  5.9661e-01,  8.5689e-01,  1.2226e+00,
          1.6406e+00,  1.5534e+00,  1.7431e+00,  1.7431e+00,  1.5834e+00,
          1.2132e+00,  1.4090e+00,  8.3972e-01,  1.6368e+00,  1.5014e-01,
          1.5250e+00,  1.7204e+00,  8.4297e-01,  1.2566e+00,  8.9145e-01,
          6.9129e-01,  1.0927e+00,  1.5808e+00,  1.6416e+00,  1.4166e+00,
          1.7444e+00,  1.7444e+00,  7.6847e-01,  8.2056e-01,  1.7175e+00,
          1.5155e+00,  8.1058e-01,  1.6588e+00,  1.1511e+00,  1.7693e+00,
          1.6828e+00,  1.1195e-01, -1.2520e-01, -1.4574e-01,  5.8617e-02,
          3.1219e-01,  4.0487e-01, -3.7379e-03,  1.5625e+01,  5.5641e+00,
          7.0099e-01,  1.2455e+00,  1.3368e+00,  1.5502e+00,  9.2312e-01,
          1.4818e+00,  3.0958e-01,  1.6251e+00,  1.7118e+00],
        [ 1.2281e+00,  1.2620e+00,  1.3265e+00,  1.3043e+00,  1.2713e+00,
          1.2352e+00,  1.2010e+00,  1.2261e+00,  1.2261e+00,  1.1921e+00,
          1.3240e+00,  1.2143e+00,  1.3626e+00,  1.2727e+00,  1.4140e+00,
          1.1973e+00,  1.2671e+00,  1.2562e+00,  1.2837e+00,  1.3000e+00,
          1.3318e+00,  1.2992e+00,  1.2499e+00,  1.2436e+00,  1.1677e+00,
          1.2343e+00,  1.2343e+00,  1.2990e+00,  1.3419e+00,  1.2544e+00,
          1.0537e+00,  1.2536e+00,  1.1339e+00,  1.3058e+00,  1.1280e+00,
          1.2578e+00,  1.3283e+00,  1.0281e+00,  1.3483e+00,  1.3460e+00,
          8.9047e-01,  8.1224e-01,  1.3479e+00,  1.2506e+00,  6.8398e-01,
          3.4587e+00,  2.5887e+00,  3.6634e+00,  2.8940e+00,  2.1664e+00,
          1.8414e+00,  3.0220e+00,  3.3719e+00,  1.8194e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 274 : 179.73800839077296
Test loss for epoch 274 : 179.8994788110177
Test Precision for epoch 274 : 0.26153846153846155
Test Recall for epoch 274 : 0.26153846153846155
Test F1 for epoch 274 : 0.26153846153846155


theta for epoch 275 : tensor([[ 2.6979e+00,  2.7289e+00,  2.8039e+00,  2.9392e+00,  2.9024e+00,
          2.7043e+00,  2.8771e+00,  2.6961e+00,  2.6961e+00,  1.2378e+00,
          1.2672e+00,  1.2549e+00,  1.2968e+00,  1.2279e+00,  1.3370e+00,
          1.2419e+00,  1.2235e+00,  1.2409e+00,  1.2103e+00,  1.1896e+00,
          1.2028e+00,  1.2223e+00,  1.1843e+00,  1.1795e+00,  1.2000e+00,
          1.1723e+00,  1.1723e+00,  1.2183e+00,  1.2615e+00,  1.1935e+00,
          1.2162e+00,  1.2632e+00,  1.2033e+00,  1.2337e+00,  1.1533e+00,
          1.1961e+00,  1.3825e+00,  1.4379e+00,  1.4116e+00,  1.3955e+00,
          1.4123e+00,  1.3572e+00,  1.3968e+00,  1.3257e+00,  1.3443e+00,
          1.3105e+00,  1.2587e+00,  1.2449e+00,  1.2259e+00,  1.3027e+00,
          1.2465e+00,  1.3433e+00,  1.2151e+00,  1.2240e+00],
        [ 1.2056e+00,  1.1944e+00,  1.1450e+00,  1.2354e+00,  1.2860e+00,
          1.2512e+00,  1.2121e+00,  1.2424e+00,  1.2424e+00,  1.8375e+00,
          1.9116e+00,  1.8032e+00,  2.1856e+00,  1.8337e+00,  5.9054e+00,
          1.8823e+00,  1.7715e+00,  5.7194e+00,  1.2042e+00,  1.2709e+00,
          1.2059e+00,  1.1816e+00,  1.2631e+00,  1.2621e+00,  1.2419e+00,
          1.2531e+00,  1.2531e+00,  1.2993e+00,  1.1489e+00,  1.2718e+00,
          1.2958e+00,  1.2100e+00,  1.2841e+00,  1.3198e+00,  1.2326e+00,
          1.2750e+00,  1.3540e+00,  1.4348e+00,  1.3397e+00,  1.3138e+00,
          1.3946e+00,  1.4082e+00,  1.3204e+00,  8.8644e-01,  1.3060e+00,
          1.2332e+00,  1.3282e+00,  1.3083e+00,  1.2842e+00,  1.1804e+00,
          1.3128e+00,  1.2251e+00,  1.2706e+00,  1.2841e+00],
        [ 1.1619e+00,  1.1888e+00,  1.2385e+00,  1.2216e+00,  1.1954e+00,
          1.1676e+00,  1.1750e+00,  1.1604e+00,  1.1604e+00,  1.2373e+00,
          1.2674e+00,  1.2548e+00,  1.2976e+00,  1.2272e+00,  1.2993e+00,
          1.2415e+00,  1.1846e+00,  1.2855e+00,  2.7527e+00,  2.9005e+00,
          2.9398e+00,  2.7940e+00,  2.7027e+00,  2.7195e+00,  2.8480e+00,
          2.6897e+00,  2.6897e+00,  1.2270e+00,  1.2622e+00,  1.1940e+00,
          1.2164e+00,  1.2271e+00,  1.2040e+00,  1.2351e+00,  1.1985e+00,
          1.1966e+00,  1.3743e+00,  1.4314e+00,  1.4032e+00,  1.3373e+00,
          1.4041e+00,  1.4068e+00,  1.3890e+00,  1.3122e+00,  1.2842e+00,
          1.3092e+00,  1.2580e+00,  1.2437e+00,  1.2242e+00,  1.3005e+00,
          1.2454e+00,  1.3435e+00,  1.2107e+00,  1.2223e+00],
        [ 1.1724e+00,  1.1996e+00,  1.2495e+00,  1.2329e+00,  1.2065e+00,
          1.1781e+00,  1.1858e+00,  1.1708e+00,  1.1708e+00,  1.2470e+00,
          1.2774e+00,  1.2648e+00,  1.3080e+00,  1.2367e+00,  1.2634e+00,
          1.2513e+00,  1.2315e+00,  1.2127e+00,  1.2227e+00,  1.2445e+00,
          1.2602e+00,  1.2351e+00,  1.1956e+00,  1.1906e+00,  1.2095e+00,
          1.1832e+00,  1.1832e+00,  2.9961e+00,  2.9757e+00,  2.5911e+00,
          2.7598e+00,  2.9923e+00,  2.6020e+00,  2.9460e+00,  2.5987e+00,
          2.5940e+00,  1.3779e+00,  1.4358e+00,  1.4079e+00,  1.3882e+00,
          1.4090e+00,  1.4116e+00,  1.3926e+00,  1.2665e+00,  1.3346e+00,
          1.3215e+00,  1.2676e+00,  1.1670e+00,  1.1881e+00,  1.3134e+00,
          1.2548e+00,  1.3555e+00,  1.1751e+00,  1.2315e+00],
        [ 1.7417e+00,  1.3759e+00,  5.9550e-01,  8.5705e-01,  1.2230e+00,
          1.6411e+00,  1.5525e+00,  1.7436e+00,  1.7436e+00,  1.5849e+00,
          1.2138e+00,  1.4102e+00,  8.3973e-01,  1.6372e+00,  1.4863e-01,
          1.5253e+00,  1.7227e+00,  8.4056e-01,  1.2559e+00,  8.9270e-01,
          6.9090e-01,  1.0932e+00,  1.5815e+00,  1.6430e+00,  1.4187e+00,
          1.7459e+00,  1.7459e+00,  7.6889e-01,  8.2013e-01,  1.7182e+00,
          1.5158e+00,  8.0971e-01,  1.6595e+00,  1.1517e+00,  1.7700e+00,
          1.6835e+00,  1.0952e-01, -1.2751e-01, -1.4835e-01,  5.6341e-02,
          3.0919e-01,  4.0133e-01, -6.2582e-03,  1.5686e+01,  5.5138e+00,
          6.9944e-01,  1.2454e+00,  1.3362e+00,  1.5498e+00,  9.2131e-01,
          1.4815e+00,  3.0774e-01,  1.6253e+00,  1.7113e+00],
        [ 1.2274e+00,  1.2615e+00,  1.3261e+00,  1.3038e+00,  1.2707e+00,
          1.2346e+00,  1.2004e+00,  1.2254e+00,  1.2254e+00,  1.1928e+00,
          1.3250e+00,  1.2151e+00,  1.3638e+00,  1.2735e+00,  1.4152e+00,
          1.1982e+00,  1.2676e+00,  1.2578e+00,  1.2844e+00,  1.3000e+00,
          1.3326e+00,  1.2999e+00,  1.2505e+00,  1.2442e+00,  1.1676e+00,
          1.2349e+00,  1.2349e+00,  1.2988e+00,  1.3416e+00,  1.2540e+00,
          1.0528e+00,  1.2534e+00,  1.1335e+00,  1.3055e+00,  1.1276e+00,
          1.2573e+00,  1.3270e+00,  1.0271e+00,  1.3465e+00,  1.3447e+00,
          8.8877e-01,  8.1076e-01,  1.3468e+00,  1.2466e+00,  6.8216e-01,
          3.4609e+00,  2.5877e+00,  3.6650e+00,  2.8933e+00,  2.1653e+00,
          1.8402e+00,  3.0216e+00,  3.3740e+00,  1.8181e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 275 : 179.72265103940538
Test loss for epoch 275 : 179.88675666481518
Test Precision for epoch 275 : 0.26153846153846155
Test Recall for epoch 275 : 0.26153846153846155
Test F1 for epoch 275 : 0.26153846153846155


theta for epoch 276 : tensor([[ 2.6985e+00,  2.7296e+00,  2.8045e+00,  2.9401e+00,  2.9033e+00,
          2.7049e+00,  2.8780e+00,  2.6968e+00,  2.6968e+00,  1.2370e+00,
          1.2666e+00,  1.2541e+00,  1.2963e+00,  1.2273e+00,  1.3364e+00,
          1.2413e+00,  1.2227e+00,  1.2408e+00,  1.2109e+00,  1.1901e+00,
          1.2032e+00,  1.2228e+00,  1.1848e+00,  1.1799e+00,  1.2005e+00,
          1.1728e+00,  1.1728e+00,  1.2185e+00,  1.2617e+00,  1.1938e+00,
          1.2165e+00,  1.2634e+00,  1.2036e+00,  1.2339e+00,  1.1536e+00,
          1.1964e+00,  1.3830e+00,  1.4386e+00,  1.4123e+00,  1.3960e+00,
          1.4131e+00,  1.3581e+00,  1.3974e+00,  1.3245e+00,  1.3451e+00,
          1.3108e+00,  1.2590e+00,  1.2451e+00,  1.2261e+00,  1.3031e+00,
          1.2467e+00,  1.3437e+00,  1.2152e+00,  1.2241e+00],
        [ 1.2051e+00,  1.1968e+00,  1.1485e+00,  1.2355e+00,  1.2850e+00,
          1.2499e+00,  1.2127e+00,  1.2411e+00,  1.2411e+00,  1.8495e+00,
          1.9184e+00,  1.8137e+00,  2.1850e+00,  1.8438e+00,  5.8806e+00,
          1.8917e+00,  1.7838e+00,  5.6935e+00,  1.2073e+00,  1.2726e+00,
          1.2106e+00,  1.1827e+00,  1.2631e+00,  1.2610e+00,  1.2411e+00,
          1.2520e+00,  1.2520e+00,  1.2996e+00,  1.1500e+00,  1.2705e+00,
          1.2956e+00,  1.2131e+00,  1.2828e+00,  1.3186e+00,  1.2313e+00,
          1.2737e+00,  1.3545e+00,  1.4345e+00,  1.3396e+00,  1.3151e+00,
          1.3953e+00,  1.4082e+00,  1.3202e+00,  8.9721e-01,  1.3062e+00,
          1.2369e+00,  1.3270e+00,  1.3072e+00,  1.2831e+00,  1.1830e+00,
          1.3115e+00,  1.2314e+00,  1.2694e+00,  1.2829e+00],
        [ 1.1621e+00,  1.1889e+00,  1.2385e+00,  1.2217e+00,  1.1955e+00,
          1.1677e+00,  1.1751e+00,  1.1605e+00,  1.1605e+00,  1.2363e+00,
          1.2666e+00,  1.2539e+00,  1.2970e+00,  1.2264e+00,  1.2983e+00,
          1.2407e+00,  1.1832e+00,  1.2854e+00,  2.7533e+00,  2.9022e+00,
          2.9407e+00,  2.7936e+00,  2.7039e+00,  2.7197e+00,  2.8499e+00,
          2.6908e+00,  2.6908e+00,  1.2268e+00,  1.2624e+00,  1.1941e+00,
          1.2165e+00,  1.2269e+00,  1.2041e+00,  1.2352e+00,  1.1987e+00,
          1.1967e+00,  1.3745e+00,  1.4319e+00,  1.4037e+00,  1.3370e+00,
          1.4045e+00,  1.4073e+00,  1.3894e+00,  1.3109e+00,  1.2841e+00,
          1.3095e+00,  1.2582e+00,  1.2439e+00,  1.2244e+00,  1.3010e+00,
          1.2456e+00,  1.3439e+00,  1.2106e+00,  1.2224e+00],
        [ 1.1725e+00,  1.1997e+00,  1.2494e+00,  1.2329e+00,  1.2066e+00,
          1.1782e+00,  1.1859e+00,  1.1709e+00,  1.1709e+00,  1.2460e+00,
          1.2766e+00,  1.2638e+00,  1.3073e+00,  1.2359e+00,  1.2629e+00,
          1.2505e+00,  1.2304e+00,  1.2127e+00,  1.2231e+00,  1.2446e+00,
          1.2605e+00,  1.2354e+00,  1.1960e+00,  1.1909e+00,  1.2097e+00,
          1.1835e+00,  1.1835e+00,  2.9971e+00,  2.9769e+00,  2.5921e+00,
          2.7606e+00,  2.9933e+00,  2.6030e+00,  2.9469e+00,  2.5997e+00,
          2.5950e+00,  1.3782e+00,  1.4364e+00,  1.4085e+00,  1.3884e+00,
          1.4096e+00,  1.4122e+00,  1.3930e+00,  1.2655e+00,  1.3351e+00,
          1.3216e+00,  1.2676e+00,  1.1672e+00,  1.1879e+00,  1.3135e+00,
          1.2548e+00,  1.3557e+00,  1.1747e+00,  1.2315e+00],
        [ 1.7422e+00,  1.3747e+00,  5.9498e-01,  8.5776e-01,  1.2241e+00,
          1.6422e+00,  1.5523e+00,  1.7447e+00,  1.7447e+00,  1.5847e+00,
          1.2129e+00,  1.4099e+00,  8.3848e-01,  1.6358e+00,  1.4624e-01,
          1.5240e+00,  1.7234e+00,  8.3689e-01,  1.2551e+00,  8.9390e-01,
          6.9050e-01,  1.0934e+00,  1.5820e+00,  1.6442e+00,  1.4204e+00,
          1.7471e+00,  1.7471e+00,  7.6974e-01,  8.2005e-01,  1.7193e+00,
          1.5166e+00,  8.0940e-01,  1.6606e+00,  1.1527e+00,  1.7710e+00,
          1.6846e+00,  1.0720e-01, -1.2971e-01, -1.5086e-01,  5.4186e-02,
          3.0627e-01,  3.9792e-01, -8.6593e-03,  1.5747e+01,  5.4628e+00,
          6.9862e-01,  1.2459e+00,  1.3364e+00,  1.5501e+00,  9.2024e-01,
          1.4819e+00,  3.0668e-01,  1.6262e+00,  1.7116e+00],
        [ 1.2273e+00,  1.2615e+00,  1.3261e+00,  1.3038e+00,  1.2707e+00,
          1.2344e+00,  1.2003e+00,  1.2253e+00,  1.2253e+00,  1.1916e+00,
          1.3242e+00,  1.2140e+00,  1.3632e+00,  1.2725e+00,  1.4145e+00,
          1.1974e+00,  1.2663e+00,  1.2576e+00,  1.2848e+00,  1.2997e+00,
          1.3330e+00,  1.3003e+00,  1.2507e+00,  1.2444e+00,  1.1671e+00,
          1.2350e+00,  1.2350e+00,  1.2988e+00,  1.3417e+00,  1.2538e+00,
          1.0521e+00,  1.2535e+00,  1.1335e+00,  1.3055e+00,  1.1275e+00,
          1.2572e+00,  1.3257e+00,  1.0262e+00,  1.3446e+00,  1.3435e+00,
          8.8709e-01,  8.0927e-01,  1.3457e+00,  1.2427e+00,  6.8034e-01,
          3.4636e+00,  2.5872e+00,  3.6671e+00,  2.8932e+00,  2.1648e+00,
          1.8394e+00,  3.0216e+00,  3.3765e+00,  1.8173e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 276 : 179.70704699299898
Test loss for epoch 276 : 179.87364176113832
Test Precision for epoch 276 : 0.26153846153846155
Test Recall for epoch 276 : 0.26153846153846155
Test F1 for epoch 276 : 0.26153846153846155


theta for epoch 277 : tensor([[ 2.6999e+00,  2.7309e+00,  2.8059e+00,  2.9417e+00,  2.9049e+00,
          2.7062e+00,  2.8796e+00,  2.6981e+00,  2.6981e+00,  1.2360e+00,
          1.2658e+00,  1.2531e+00,  1.2955e+00,  1.2265e+00,  1.3355e+00,
          1.2405e+00,  1.2216e+00,  1.2403e+00,  1.2101e+00,  1.1893e+00,
          1.2024e+00,  1.2220e+00,  1.1839e+00,  1.1791e+00,  1.1996e+00,
          1.1720e+00,  1.1720e+00,  1.2184e+00,  1.2616e+00,  1.1937e+00,
          1.2164e+00,  1.2633e+00,  1.2035e+00,  1.2338e+00,  1.1535e+00,
          1.1963e+00,  1.3837e+00,  1.4396e+00,  1.4132e+00,  1.3966e+00,
          1.4140e+00,  1.3591e+00,  1.3982e+00,  1.3235e+00,  1.3460e+00,
          1.3111e+00,  1.2591e+00,  1.2452e+00,  1.2262e+00,  1.3033e+00,
          1.2469e+00,  1.3440e+00,  1.2152e+00,  1.2242e+00],
        [ 1.2052e+00,  1.1998e+00,  1.1523e+00,  1.2360e+00,  1.2846e+00,
          1.2493e+00,  1.2139e+00,  1.2405e+00,  1.2405e+00,  1.8613e+00,
          1.9250e+00,  1.8241e+00,  2.1844e+00,  1.8537e+00,  5.8548e+00,
          1.9008e+00,  1.7959e+00,  5.6666e+00,  1.2091e+00,  1.2731e+00,
          1.2141e+00,  1.1828e+00,  1.2621e+00,  1.2589e+00,  1.2394e+00,
          1.2500e+00,  1.2500e+00,  1.2999e+00,  1.1513e+00,  1.2695e+00,
          1.2954e+00,  1.2161e+00,  1.2817e+00,  1.3176e+00,  1.2303e+00,
          1.2727e+00,  1.3556e+00,  1.4350e+00,  1.3400e+00,  1.3170e+00,
          1.3967e+00,  1.4090e+00,  1.3205e+00,  9.0822e-01,  1.3071e+00,
          1.2409e+00,  1.3262e+00,  1.3065e+00,  1.2824e+00,  1.1858e+00,
          1.3107e+00,  1.2376e+00,  1.2686e+00,  1.2821e+00],
        [ 1.1629e+00,  1.1899e+00,  1.2393e+00,  1.2226e+00,  1.1964e+00,
          1.1686e+00,  1.1760e+00,  1.1614e+00,  1.1614e+00,  1.2359e+00,
          1.2664e+00,  1.2535e+00,  1.2969e+00,  1.2261e+00,  1.2979e+00,
          1.2405e+00,  1.1824e+00,  1.2857e+00,  2.7526e+00,  2.9026e+00,
          2.9403e+00,  2.7919e+00,  2.7037e+00,  2.7187e+00,  2.8506e+00,
          2.6906e+00,  2.6906e+00,  1.2270e+00,  1.2631e+00,  1.1947e+00,
          1.2171e+00,  1.2271e+00,  1.2048e+00,  1.2359e+00,  1.1993e+00,
          1.1974e+00,  1.3756e+00,  1.4332e+00,  1.4049e+00,  1.3375e+00,
          1.4059e+00,  1.4087e+00,  1.3906e+00,  1.3104e+00,  1.2848e+00,
          1.3105e+00,  1.2591e+00,  1.2448e+00,  1.2252e+00,  1.3021e+00,
          1.2464e+00,  1.3450e+00,  1.2112e+00,  1.2232e+00],
        [ 1.1730e+00,  1.2002e+00,  1.2498e+00,  1.2333e+00,  1.2070e+00,
          1.1786e+00,  1.1864e+00,  1.1713e+00,  1.1713e+00,  1.2452e+00,
          1.2760e+00,  1.2629e+00,  1.3067e+00,  1.2352e+00,  1.2626e+00,
          1.2498e+00,  1.2296e+00,  1.2128e+00,  1.2224e+00,  1.2438e+00,
          1.2598e+00,  1.2347e+00,  1.1953e+00,  1.1902e+00,  1.2088e+00,
          1.1828e+00,  1.1828e+00,  2.9980e+00,  2.9779e+00,  2.5930e+00,
          2.7612e+00,  2.9942e+00,  2.6038e+00,  2.9476e+00,  2.6005e+00,
          2.5958e+00,  1.3790e+00,  1.4374e+00,  1.4095e+00,  1.3891e+00,
          1.4106e+00,  1.4133e+00,  1.3940e+00,  1.2649e+00,  1.3361e+00,
          1.3220e+00,  1.2680e+00,  1.1678e+00,  1.1881e+00,  1.3139e+00,
          1.2551e+00,  1.3562e+00,  1.1747e+00,  1.2317e+00],
        [ 1.7427e+00,  1.3734e+00,  5.9427e-01,  8.5833e-01,  1.2252e+00,
          1.6434e+00,  1.5521e+00,  1.7459e+00,  1.7459e+00,  1.5842e+00,
          1.2117e+00,  1.4092e+00,  8.3681e-01,  1.6341e+00,  1.4331e-01,
          1.5223e+00,  1.7239e+00,  8.3285e-01,  1.2532e+00,  8.9369e-01,
          6.8866e-01,  1.0921e+00,  1.5812e+00,  1.6440e+00,  1.4208e+00,
          1.7469e+00,  1.7469e+00,  7.7003e-01,  8.1934e-01,  1.7200e+00,
          1.5171e+00,  8.0865e-01,  1.6613e+00,  1.1531e+00,  1.7718e+00,
          1.6853e+00,  1.0566e-01, -1.3114e-01, -1.5261e-01,  5.2836e-02,
          3.0415e-01,  3.9534e-01, -1.0274e-02,  1.5809e+01,  5.4117e+00,
          6.9720e-01,  1.2460e+00,  1.3362e+00,  1.5501e+00,  9.1865e-01,
          1.4820e+00,  3.0492e-01,  1.6270e+00,  1.7116e+00],
        [ 1.2277e+00,  1.2621e+00,  1.3268e+00,  1.3044e+00,  1.2712e+00,
          1.2349e+00,  1.2009e+00,  1.2257e+00,  1.2257e+00,  1.1908e+00,
          1.3236e+00,  1.2132e+00,  1.3628e+00,  1.2718e+00,  1.4141e+00,
          1.1968e+00,  1.2653e+00,  1.2575e+00,  1.2843e+00,  1.2983e+00,
          1.3325e+00,  1.2997e+00,  1.2500e+00,  1.2436e+00,  1.1657e+00,
          1.2342e+00,  1.2342e+00,  1.2990e+00,  1.3419e+00,  1.2539e+00,
          1.0516e+00,  1.2538e+00,  1.1336e+00,  1.3056e+00,  1.1276e+00,
          1.2573e+00,  1.3251e+00,  1.0260e+00,  1.3434e+00,  1.3429e+00,
          8.8616e-01,  8.0852e-01,  1.3453e+00,  1.2396e+00,  6.7928e-01,
          3.4660e+00,  2.5864e+00,  3.6688e+00,  2.8926e+00,  2.1639e+00,
          1.8383e+00,  3.0213e+00,  3.3789e+00,  1.8162e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 277 : 179.69134457818927
Test loss for epoch 277 : 179.86158773760516
Test Precision for epoch 277 : 0.26153846153846155
Test Recall for epoch 277 : 0.26153846153846155
Test F1 for epoch 277 : 0.26153846153846155


theta for epoch 278 : tensor([[ 2.7002e+00,  2.7313e+00,  2.8063e+00,  2.9422e+00,  2.9054e+00,
          2.7065e+00,  2.8802e+00,  2.6984e+00,  2.6984e+00,  1.2369e+00,
          1.2669e+00,  1.2540e+00,  1.2967e+00,  1.2276e+00,  1.3365e+00,
          1.2416e+00,  1.2225e+00,  1.2417e+00,  1.2102e+00,  1.1893e+00,
          1.2025e+00,  1.2221e+00,  1.1840e+00,  1.1792e+00,  1.1996e+00,
          1.1720e+00,  1.1720e+00,  1.2182e+00,  1.2614e+00,  1.1935e+00,
          1.2162e+00,  1.2632e+00,  1.2033e+00,  1.2336e+00,  1.1533e+00,
          1.1961e+00,  1.3842e+00,  1.4403e+00,  1.4140e+00,  1.3971e+00,
          1.4148e+00,  1.3600e+00,  1.3989e+00,  1.3224e+00,  1.3468e+00,
          1.3113e+00,  1.2593e+00,  1.2454e+00,  1.2263e+00,  1.3036e+00,
          1.2470e+00,  1.3443e+00,  1.2152e+00,  1.2243e+00],
        [ 1.2039e+00,  1.2012e+00,  1.1544e+00,  1.2349e+00,  1.2824e+00,
          1.2471e+00,  1.2134e+00,  1.2383e+00,  1.2383e+00,  1.8748e+00,
          1.9334e+00,  1.8361e+00,  2.1856e+00,  1.8652e+00,  5.8298e+00,
          1.9117e+00,  1.8098e+00,  5.6406e+00,  1.2109e+00,  1.2735e+00,
          1.2173e+00,  1.1831e+00,  1.2613e+00,  1.2572e+00,  1.2380e+00,
          1.2482e+00,  1.2482e+00,  1.2993e+00,  1.1516e+00,  1.2676e+00,
          1.2943e+00,  1.2178e+00,  1.2798e+00,  1.3157e+00,  1.2284e+00,
          1.2708e+00,  1.3560e+00,  1.4346e+00,  1.3397e+00,  1.3182e+00,
          1.3972e+00,  1.4090e+00,  1.3201e+00,  9.1814e-01,  1.3072e+00,
          1.2439e+00,  1.3247e+00,  1.3051e+00,  1.2810e+00,  1.1878e+00,
          1.3092e+00,  1.2425e+00,  1.2671e+00,  1.2805e+00],
        [ 1.1625e+00,  1.1894e+00,  1.2387e+00,  1.2221e+00,  1.1959e+00,
          1.1681e+00,  1.1756e+00,  1.1609e+00,  1.1609e+00,  1.2366e+00,
          1.2673e+00,  1.2542e+00,  1.2979e+00,  1.2270e+00,  1.2985e+00,
          1.2414e+00,  1.1827e+00,  1.2871e+00,  2.7528e+00,  2.9040e+00,
          2.9409e+00,  2.7912e+00,  2.7045e+00,  2.7186e+00,  2.8522e+00,
          2.6913e+00,  2.6913e+00,  1.2263e+00,  1.2629e+00,  1.1945e+00,
          1.2169e+00,  1.2265e+00,  1.2045e+00,  1.2356e+00,  1.1990e+00,
          1.1971e+00,  1.3759e+00,  1.4338e+00,  1.4055e+00,  1.3372e+00,
          1.4064e+00,  1.4092e+00,  1.3910e+00,  1.3092e+00,  1.2848e+00,
          1.3108e+00,  1.2592e+00,  1.2449e+00,  1.2253e+00,  1.3025e+00,
          1.2466e+00,  1.3454e+00,  1.2111e+00,  1.2233e+00],
        [ 1.1726e+00,  1.1999e+00,  1.2493e+00,  1.2329e+00,  1.2066e+00,
          1.1783e+00,  1.1861e+00,  1.1710e+00,  1.1710e+00,  1.2461e+00,
          1.2770e+00,  1.2638e+00,  1.3079e+00,  1.2363e+00,  1.2639e+00,
          1.2510e+00,  1.2304e+00,  1.2146e+00,  1.2226e+00,  1.2438e+00,
          1.2599e+00,  1.2349e+00,  1.1954e+00,  1.1904e+00,  1.2088e+00,
          1.1829e+00,  1.1829e+00,  2.9984e+00,  2.9785e+00,  2.5934e+00,
          2.7613e+00,  2.9947e+00,  2.6042e+00,  2.9479e+00,  2.6009e+00,
          2.5962e+00,  1.3796e+00,  1.4382e+00,  1.4103e+00,  1.3895e+00,
          1.4115e+00,  1.4142e+00,  1.3946e+00,  1.2642e+00,  1.3368e+00,
          1.3223e+00,  1.2682e+00,  1.1683e+00,  1.1881e+00,  1.3143e+00,
          1.2553e+00,  1.3566e+00,  1.1745e+00,  1.2319e+00],
        [ 1.7423e+00,  1.3715e+00,  5.9326e-01,  8.5847e-01,  1.2257e+00,
          1.6438e+00,  1.5512e+00,  1.7463e+00,  1.7463e+00,  1.5854e+00,
          1.2124e+00,  1.4102e+00,  8.3706e-01,  1.6341e+00,  1.4219e-01,
          1.5226e+00,  1.7262e+00,  8.3093e-01,  1.2525e+00,  8.9478e-01,
          6.8820e-01,  1.0920e+00,  1.5814e+00,  1.6447e+00,  1.4221e+00,
          1.7476e+00,  1.7476e+00,  7.7054e-01,  8.1872e-01,  1.7205e+00,
          1.5176e+00,  8.0823e-01,  1.6618e+00,  1.1536e+00,  1.7723e+00,
          1.6858e+00,  1.0355e-01, -1.3310e-01, -1.5491e-01,  5.0934e-02,
          3.0143e-01,  3.9220e-01, -1.2435e-02,  1.5872e+01,  5.3592e+00,
          6.9611e-01,  1.2463e+00,  1.3360e+00,  1.5501e+00,  9.1726e-01,
          1.4821e+00,  3.0371e-01,  1.6277e+00,  1.7116e+00],
        [ 1.2271e+00,  1.2616e+00,  1.3263e+00,  1.3039e+00,  1.2706e+00,
          1.2342e+00,  1.2003e+00,  1.2250e+00,  1.2250e+00,  1.1916e+00,
          1.3248e+00,  1.2141e+00,  1.3641e+00,  1.2728e+00,  1.4153e+00,
          1.1979e+00,  1.2660e+00,  1.2591e+00,  1.2844e+00,  1.2976e+00,
          1.3326e+00,  1.2998e+00,  1.2500e+00,  1.2436e+00,  1.1649e+00,
          1.2342e+00,  1.2342e+00,  1.2989e+00,  1.3417e+00,  1.2535e+00,
          1.0507e+00,  1.2537e+00,  1.1333e+00,  1.3054e+00,  1.1273e+00,
          1.2569e+00,  1.3240e+00,  1.0252e+00,  1.3417e+00,  1.3417e+00,
          8.8472e-01,  8.0725e-01,  1.3444e+00,  1.2361e+00,  6.7771e-01,
          3.4682e+00,  2.5853e+00,  3.6703e+00,  2.8918e+00,  2.1628e+00,
          1.8370e+00,  3.0207e+00,  3.3810e+00,  1.8149e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 278 : 179.67498474061114
Test loss for epoch 278 : 179.84837156227826
Test Precision for epoch 278 : 0.26153846153846155
Test Recall for epoch 278 : 0.26153846153846155
Test F1 for epoch 278 : 0.26153846153846155


theta for epoch 279 : tensor([[ 2.7004e+00,  2.7315e+00,  2.8065e+00,  2.9427e+00,  2.9059e+00,
          2.7067e+00,  2.8806e+00,  2.6986e+00,  2.6986e+00,  1.2370e+00,
          1.2671e+00,  1.2541e+00,  1.2970e+00,  1.2279e+00,  1.3367e+00,
          1.2420e+00,  1.2226e+00,  1.2422e+00,  1.2109e+00,  1.1899e+00,
          1.2031e+00,  1.2227e+00,  1.1847e+00,  1.1798e+00,  1.2002e+00,
          1.1727e+00,  1.1727e+00,  1.2185e+00,  1.2617e+00,  1.1938e+00,
          1.2166e+00,  1.2635e+00,  1.2036e+00,  1.2340e+00,  1.1536e+00,
          1.1964e+00,  1.3846e+00,  1.4409e+00,  1.4145e+00,  1.3975e+00,
          1.4155e+00,  1.3607e+00,  1.3993e+00,  1.3211e+00,  1.3474e+00,
          1.3115e+00,  1.2594e+00,  1.2455e+00,  1.2263e+00,  1.3038e+00,
          1.2471e+00,  1.3446e+00,  1.2152e+00,  1.2243e+00],
        [ 1.2030e+00,  1.2029e+00,  1.1568e+00,  1.2341e+00,  1.2806e+00,
          1.2452e+00,  1.2133e+00,  1.2365e+00,  1.2365e+00,  1.8874e+00,
          1.9409e+00,  1.8472e+00,  2.1861e+00,  1.8757e+00,  5.8032e+00,
          1.9216e+00,  1.8229e+00,  5.6129e+00,  1.2131e+00,  1.2743e+00,
          1.2209e+00,  1.1841e+00,  1.2612e+00,  1.2563e+00,  1.2375e+00,
          1.2473e+00,  1.2473e+00,  1.2992e+00,  1.1527e+00,  1.2664e+00,
          1.2938e+00,  1.2199e+00,  1.2786e+00,  1.3145e+00,  1.2272e+00,
          1.2696e+00,  1.3563e+00,  1.4343e+00,  1.3395e+00,  1.3195e+00,
          1.3976e+00,  1.4090e+00,  1.3198e+00,  9.2785e-01,  1.3074e+00,
          1.2470e+00,  1.3233e+00,  1.3038e+00,  1.2797e+00,  1.1898e+00,
          1.3078e+00,  1.2471e+00,  1.2657e+00,  1.2791e+00],
        [ 1.1619e+00,  1.1889e+00,  1.2380e+00,  1.2214e+00,  1.1953e+00,
          1.1675e+00,  1.1750e+00,  1.1603e+00,  1.1603e+00,  1.2362e+00,
          1.2671e+00,  1.2538e+00,  1.2978e+00,  1.2267e+00,  1.2980e+00,
          1.2412e+00,  1.1820e+00,  1.2873e+00,  2.7538e+00,  2.9061e+00,
          2.9422e+00,  2.7913e+00,  2.7060e+00,  2.7193e+00,  2.8545e+00,
          2.6928e+00,  2.6928e+00,  1.2258e+00,  1.2628e+00,  1.1943e+00,
          1.2168e+00,  1.2260e+00,  1.2044e+00,  1.2355e+00,  1.1989e+00,
          1.1970e+00,  1.3758e+00,  1.4339e+00,  1.4055e+00,  1.3364e+00,
          1.4065e+00,  1.4093e+00,  1.3910e+00,  1.3077e+00,  1.2842e+00,
          1.3106e+00,  1.2590e+00,  1.2447e+00,  1.2250e+00,  1.3025e+00,
          1.2463e+00,  1.3453e+00,  1.2105e+00,  1.2229e+00],
        [ 1.1723e+00,  1.1997e+00,  1.2489e+00,  1.2327e+00,  1.2063e+00,
          1.1780e+00,  1.1858e+00,  1.1707e+00,  1.1707e+00,  1.2461e+00,
          1.2773e+00,  1.2639e+00,  1.3082e+00,  1.2366e+00,  1.2645e+00,
          1.2512e+00,  1.2304e+00,  1.2155e+00,  1.2234e+00,  1.2443e+00,
          1.2606e+00,  1.2356e+00,  1.1961e+00,  1.1910e+00,  1.2094e+00,
          1.1836e+00,  1.1836e+00,  2.9989e+00,  2.9791e+00,  2.5939e+00,
          2.7615e+00,  2.9952e+00,  2.6047e+00,  2.9482e+00,  2.6014e+00,
          2.5967e+00,  1.3800e+00,  1.4388e+00,  1.4108e+00,  1.3897e+00,
          1.4121e+00,  1.4148e+00,  1.3951e+00,  1.2634e+00,  1.3372e+00,
          1.3225e+00,  1.2683e+00,  1.1687e+00,  1.1880e+00,  1.3144e+00,
          1.2554e+00,  1.3568e+00,  1.1742e+00,  1.2319e+00],
        [ 1.7420e+00,  1.3697e+00,  5.9237e-01,  8.5872e-01,  1.2263e+00,
          1.6442e+00,  1.5505e+00,  1.7467e+00,  1.7467e+00,  1.5856e+00,
          1.2124e+00,  1.4104e+00,  8.3667e-01,  1.6332e+00,  1.4061e-01,
          1.5220e+00,  1.7276e+00,  8.2833e-01,  1.2526e+00,  8.9661e-01,
          6.8849e-01,  1.0924e+00,  1.5823e+00,  1.6460e+00,  1.4240e+00,
          1.7489e+00,  1.7489e+00,  7.7147e-01,  8.1838e-01,  1.7214e+00,
          1.5185e+00,  8.0832e-01,  1.6628e+00,  1.1544e+00,  1.7732e+00,
          1.6867e+00,  1.0138e-01, -1.3512e-01, -1.5727e-01,  4.8989e-02,
          2.9866e-01,  3.8902e-01, -1.4644e-02,  1.5935e+01,  5.3059e+00,
          6.9492e-01,  1.2464e+00,  1.3357e+00,  1.5499e+00,  9.1573e-01,
          1.4820e+00,  3.0247e-01,  1.6282e+00,  1.7113e+00],
        [ 1.2265e+00,  1.2612e+00,  1.3260e+00,  1.3035e+00,  1.2701e+00,
          1.2337e+00,  1.1998e+00,  1.2244e+00,  1.2244e+00,  1.1916e+00,
          1.3249e+00,  1.2141e+00,  1.3645e+00,  1.2729e+00,  1.4156e+00,
          1.1981e+00,  1.2658e+00,  1.2598e+00,  1.2850e+00,  1.2974e+00,
          1.3333e+00,  1.3005e+00,  1.2505e+00,  1.2441e+00,  1.1647e+00,
          1.2346e+00,  1.2346e+00,  1.2991e+00,  1.3420e+00,  1.2536e+00,
          1.0502e+00,  1.2540e+00,  1.1334e+00,  1.3056e+00,  1.1273e+00,
          1.2570e+00,  1.3226e+00,  1.0242e+00,  1.3396e+00,  1.3403e+00,
          8.8295e-01,  8.0565e-01,  1.3431e+00,  1.2323e+00,  6.7583e-01,
          3.4705e+00,  2.5842e+00,  3.6716e+00,  2.8910e+00,  2.1616e+00,
          1.8357e+00,  3.0201e+00,  3.3831e+00,  1.8135e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 279 : 179.6586620209249
Test loss for epoch 279 : 179.83515038649324
Test Precision for epoch 279 : 0.26153846153846155
Test Recall for epoch 279 : 0.26153846153846155
Test F1 for epoch 279 : 0.26153846153846155


theta for epoch 280 : tensor([[ 2.7013,  2.7325,  2.8075,  2.9439,  2.9071,  2.7076,  2.8818,  2.6995,
          2.6995,  1.2360,  1.2662,  1.2531,  1.2961,  1.2270,  1.3357,  1.2411,
          1.2215,  1.2416,  1.2106,  1.1894,  1.2027,  1.2223,  1.1843,  1.1794,
          1.1998,  1.1723,  1.1723,  1.2189,  1.2621,  1.1942,  1.2170,  1.2639,
          1.2040,  1.2344,  1.1540,  1.1968,  1.3850,  1.4415,  1.4152,  1.3979,
          1.4162,  1.3615,  1.3998,  1.3201,  1.3482,  1.3117,  1.2596,  1.2457,
          1.2264,  1.3040,  1.2472,  1.3449,  1.2152,  1.2244],
        [ 1.2036,  1.2060,  1.1604,  1.2346,  1.2801,  1.2448,  1.2145,  1.2361,
          1.2361,  1.8991,  1.9476,  1.8573,  2.1858,  1.8852,  5.7751,  1.9305,
          1.8351,  5.5837,  1.2144,  1.2742,  1.2234,  1.1845,  1.2603,  1.2547,
          1.2364,  1.2458,  1.2458,  1.2995,  1.1545,  1.2658,  1.2937,  1.2222,
          1.2780,  1.3140,  1.2266,  1.2690,  1.3570,  1.4346,  1.3398,  1.3213,
          1.3986,  1.4096,  1.3200,  0.9378,  1.3082,  1.2504,  1.3225,  1.3032,
          1.2790,  1.1923,  1.3070,  1.2518,  1.2649,  1.2783],
        [ 1.1626,  1.1896,  1.2386,  1.2221,  1.1960,  1.1681,  1.1757,  1.1610,
          1.1610,  1.2354,  1.2664,  1.2530,  1.2972,  1.2261,  1.2971,  1.2406,
          1.1808,  1.2871,  2.7536,  2.9071,  2.9423,  2.7902,  2.7062,  2.7187,
          2.8557,  2.6931,  2.6931,  1.2260,  1.2635,  1.1950,  1.2174,  1.2262,
          1.2050,  1.2362,  1.1995,  1.1976,  1.3763,  1.4346,  1.4062,  1.3363,
          1.4073,  1.4100,  1.3915,  1.3068,  1.2844,  1.3112,  1.2594,  1.2451,
          1.2254,  1.3031,  1.2467,  1.3459,  1.2107,  1.2233],
        [ 1.1730,  1.2004,  1.2494,  1.2333,  1.2070,  1.1787,  1.1865,  1.1714,
          1.1714,  1.2453,  1.2766,  1.2630,  1.3075,  1.2359,  1.2641,  1.2505,
          1.2295,  1.2155,  1.2231,  1.2438,  1.2603,  1.2353,  1.1959,  1.1908,
          1.2089,  1.1833,  1.1833,  2.9996,  2.9798,  2.5945,  2.7618,  2.9959,
          2.6054,  2.9487,  2.6021,  2.5974,  1.3805,  1.4395,  1.4116,  1.3900,
          1.4130,  1.4156,  1.3957,  1.2628,  1.3379,  1.3228,  1.2686,  1.1693,
          1.1882,  1.3148,  1.2556,  1.3572,  1.1741,  1.2321],
        [ 1.7422,  1.3686,  0.5918,  0.8594,  1.2274,  1.6454,  1.5504,  1.7479,
          1.7479,  1.5847,  1.2112,  1.4093,  0.8351,  1.6310,  0.1378,  1.5202,
          1.7279,  0.8244,  1.2516,  0.8972,  0.6876,  1.0916,  1.5821,  1.6460,
          1.4247,  1.7489,  1.7489,  0.7722,  0.8177,  1.7223,  1.5195,  0.8083,
          1.6637,  1.1551,  1.7741,  1.6876,  0.0998, -0.1366, -0.1591,  0.0476,
          0.2965,  0.3865, -0.0163, 15.9985,  5.2524,  0.6934,  1.2463,  1.3353,
          1.5497,  0.9139,  1.4819,  0.3008,  1.6288,  1.7111],
        [ 1.2269,  1.2617,  1.3266,  1.3040,  1.2706,  1.2341,  1.2003,  1.2248,
          1.2248,  1.1905,  1.3240,  1.2130,  1.3637,  1.2719,  1.4148,  1.1973,
          1.2645,  1.2593,  1.2846,  1.2962,  1.3330,  1.3001,  1.2500,  1.2436,
          1.1634,  1.2341,  1.2341,  1.2996,  1.3424,  1.2538,  1.0498,  1.2545,
          1.1337,  1.3060,  1.1276,  1.2572,  1.3214,  1.0234,  1.3377,  1.3391,
          0.8814,  0.8043,  1.3421,  1.2289,  0.6742,  3.4730,  2.5833,  3.6732,
          2.8904,  2.1607,  1.8347,  3.0197,  3.3855,  1.8124]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 280 : 179.6418362673552
Test loss for epoch 280 : 179.82220897653025
Test Precision for epoch 280 : 0.26153846153846155
Test Recall for epoch 280 : 0.26153846153846155
Test F1 for epoch 280 : 0.26153846153846155


theta for epoch 281 : tensor([[ 2.7016,  2.7328,  2.8078,  2.9444,  2.9076,  2.7079,  2.8824,  2.6998,
          2.6998,  1.2365,  1.2668,  1.2536,  1.2967,  1.2277,  1.3362,  1.2418,
          1.2219,  1.2424,  1.2104,  1.1892,  1.2024,  1.2221,  1.1841,  1.1792,
          1.1995,  1.1720,  1.1720,  1.2189,  1.2621,  1.1943,  1.2171,  1.2639,
          1.2041,  1.2344,  1.1540,  1.1968,  1.3856,  1.4423,  1.4159,  1.3984,
          1.4171,  1.3624,  1.4005,  1.3192,  1.3490,  1.3122,  1.2600,  1.2460,
          1.2267,  1.3045,  1.2476,  1.3454,  1.2154,  1.2247],
        [ 1.2033,  1.2080,  1.1629,  1.2340,  1.2786,  1.2434,  1.2146,  1.2347,
          1.2347,  1.9123,  1.9560,  1.8691,  2.1874,  1.8962,  5.7479,  1.9411,
          1.8491,  5.5554,  1.2148,  1.2732,  1.2250,  1.1843,  1.2588,  1.2527,
          1.2348,  1.2437,  1.2437,  1.2985,  1.1551,  1.2641,  1.2924,  1.2230,
          1.2763,  1.3123,  1.2249,  1.2673,  1.3573,  1.4344,  1.3396,  1.3227,
          1.3990,  1.4097,  1.3197,  0.9470,  1.3085,  1.2532,  1.3212,  1.3020,
          1.2778,  1.1943,  1.3056,  1.2556,  1.2636,  1.2769],
        [ 1.1630,  1.1901,  1.2388,  1.2225,  1.1964,  1.1685,  1.1762,  1.1613,
          1.1613,  1.2359,  1.2670,  1.2534,  1.2978,  1.2267,  1.2974,  1.2412,
          1.1809,  1.2880,  2.7531,  2.9078,  2.9423,  2.7888,  2.7063,  2.7180,
          2.8566,  2.6931,  2.6931,  1.2257,  1.2637,  1.1950,  1.2175,  1.2259,
          1.2051,  1.2363,  1.1996,  1.1977,  1.3768,  1.4353,  1.4068,  1.3361,
          1.4081,  1.4107,  1.3921,  1.3059,  1.2845,  1.3117,  1.2599,  1.2456,
          1.2258,  1.3038,  1.2472,  1.3466,  1.2108,  1.2237],
        [ 1.1733,  1.2008,  1.2496,  1.2336,  1.2073,  1.1790,  1.1869,  1.1717,
          1.1717,  1.2456,  1.2770,  1.2634,  1.3080,  1.2364,  1.2649,  1.2511,
          1.2298,  1.2166,  1.2228,  1.2434,  1.2599,  1.2350,  1.1956,  1.1905,
          1.2084,  1.1830,  1.1830,  2.9999,  2.9803,  2.5949,  2.7618,  2.9963,
          2.6057,  2.9488,  2.6025,  2.5977,  1.3810,  1.4403,  1.4123,  1.3903,
          1.4138,  1.4164,  1.3963,  1.2623,  1.3385,  1.3232,  1.2689,  1.1700,
          1.1883,  1.3152,  1.2559,  1.3577,  1.1740,  1.2323],
        [ 1.7421,  1.3674,  0.5912,  0.8599,  1.2285,  1.6463,  1.5502,  1.7487,
          1.7487,  1.5850,  1.2115,  1.4096,  0.8349,  1.6301,  0.1364,  1.5198,
          1.7296,  0.8220,  1.2510,  0.8982,  0.6871,  1.0911,  1.5821,  1.6462,
          1.4255,  1.7491,  1.7491,  0.7729,  0.8169,  1.7228,  1.5202,  0.8083,
          1.6642,  1.1555,  1.7746,  1.6881,  0.0979, -0.1383, -0.1612,  0.0460,
          0.2940,  0.3836, -0.0182, 16.0625,  5.1978,  0.6923,  1.2466,  1.3351,
          1.5496,  0.9125,  1.4820,  0.2996,  1.6296,  1.7111],
        [ 1.2268,  1.2618,  1.3267,  1.3041,  1.2706,  1.2340,  1.2003,  1.2247,
          1.2247,  1.1906,  1.3243,  1.2132,  1.3641,  1.2722,  1.4152,  1.1976,
          1.2644,  1.2599,  1.2841,  1.2947,  1.3325,  1.2995,  1.2494,  1.2429,
          1.1619,  1.2333,  1.2333,  1.2993,  1.3422,  1.2534,  1.0487,  1.2542,
          1.1333,  1.3057,  1.1272,  1.2568,  1.3200,  1.0224,  1.3356,  1.3377,
          0.8796,  0.8026,  1.3409,  1.2254,  0.6722,  3.4757,  2.5826,  3.6748,
          2.8899,  2.1600,  1.8338,  3.0195,  3.3881,  1.8115]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 281 : 179.62473595509448
Test loss for epoch 281 : 179.80867672097347
Test Precision for epoch 281 : 0.26153846153846155
Test Recall for epoch 281 : 0.26153846153846155
Test F1 for epoch 281 : 0.26153846153846155


theta for epoch 282 : tensor([[ 2.7013,  2.7326,  2.8076,  2.9444,  2.9076,  2.7076,  2.8823,  2.6995,
          2.6995,  1.2372,  1.2675,  1.2542,  1.2975,  1.2285,  1.3368,  1.2426,
          1.2225,  1.2433,  1.2112,  1.1899,  1.2032,  1.2229,  1.1849,  1.1800,
          1.2003,  1.1728,  1.1728,  1.2190,  1.2623,  1.1944,  1.2173,  1.2641,
          1.2042,  1.2346,  1.1542,  1.1970,  1.3863,  1.4432,  1.4168,  1.3990,
          1.4181,  1.3634,  1.4012,  1.3185,  1.3500,  1.3124,  1.2602,  1.2462,
          1.2269,  1.3047,  1.2477,  1.3457,  1.2154,  1.2248],
        [ 1.2025,  1.2094,  1.1649,  1.2328,  1.2764,  1.2414,  1.2140,  1.2327,
          1.2327,  1.9256,  1.9646,  1.8808,  2.1892,  1.9072,  5.7201,  1.9517,
          1.8631,  5.5265,  1.2158,  1.2729,  1.2270,  1.1850,  1.2582,  1.2516,
          1.2342,  1.2427,  1.2427,  1.2973,  1.1559,  1.2623,  1.2909,  1.2234,
          1.2745,  1.3106,  1.2231,  1.2655,  1.3576,  1.4342,  1.3395,  1.3242,
          1.3994,  1.4098,  1.3194,  0.9561,  1.3088,  1.2555,  1.3195,  1.3004,
          1.2762,  1.1958,  1.3039,  1.2587,  1.2619,  1.2752],
        [ 1.1626,  1.1897,  1.2383,  1.2221,  1.1959,  1.1681,  1.1758,  1.1609,
          1.1609,  1.2361,  1.2673,  1.2536,  1.2981,  1.2271,  1.2973,  1.2416,
          1.1807,  1.2886,  2.7536,  2.9095,  2.9432,  2.7885,  2.7072,  2.7182,
          2.8585,  2.6940,  2.6940,  1.2250,  1.2634,  1.1948,  1.2172,  1.2252,
          1.2048,  1.2360,  1.1993,  1.1974,  1.3770,  1.4357,  1.4072,  1.3357,
          1.4086,  1.4112,  1.3924,  1.3049,  1.2844,  1.3116,  1.2598,  1.2454,
          1.2255,  1.3038,  1.2470,  1.3466,  1.2103,  1.2234],
        [ 1.1730,  1.2004,  1.2491,  1.2332,  1.2069,  1.1786,  1.1865,  1.1713,
          1.1713,  1.2459,  1.2774,  1.2637,  1.3084,  1.2369,  1.2656,  1.2516,
          1.2300,  1.2176,  1.2234,  1.2437,  1.2605,  1.2356,  1.1961,  1.1910,
          1.2088,  1.1836,  1.1836,  3.0003,  2.9807,  2.5953,  2.7618,  2.9967,
          2.6062,  2.9490,  2.6029,  2.5982,  1.3815,  1.4409,  1.4130,  1.3905,
          1.4145,  1.4171,  1.3968,  1.2619,  1.3391,  1.3232,  1.2688,  1.1703,
          1.1880,  1.3152,  1.2558,  1.3577,  1.1735,  1.2321],
        [ 1.7414,  1.3657,  0.5902,  0.8601,  1.2290,  1.6466,  1.5496,  1.7491,
          1.7491,  1.5854,  1.2119,  1.4099,  0.8350,  1.6291,  0.1351,  1.5196,
          1.7314,  0.8197,  1.2516,  0.9004,  0.6879,  1.0915,  1.5832,  1.6475,
          1.4273,  1.7503,  1.7503,  0.7737,  0.8160,  1.7233,  1.5211,  0.8085,
          1.6648,  1.1561,  1.7752,  1.6887,  0.0959, -0.1401, -0.1634,  0.0443,
          0.2914,  0.3807, -0.0202, 16.1269,  5.1423,  0.6909,  1.2465,  1.3345,
          1.5492,  0.9107,  1.4817,  0.2982,  1.6299,  1.7106],
        [ 1.2263,  1.2614,  1.3264,  1.3037,  1.2702,  1.2335,  1.1998,  1.2242,
          1.2242,  1.1909,  1.3247,  1.2136,  1.3647,  1.2727,  1.4157,  1.1982,
          1.2645,  1.2607,  1.2847,  1.2944,  1.3331,  1.3002,  1.2499,  1.2434,
          1.1615,  1.2338,  1.2338,  1.2992,  1.3421,  1.2531,  1.0477,  1.2541,
          1.1330,  1.3055,  1.1269,  1.2565,  1.3188,  1.0215,  1.3336,  1.3363,
          0.8780,  0.8012,  1.3398,  1.2221,  0.6705,  3.4778,  2.5812,  3.6757,
          2.8887,  2.1586,  1.8322,  3.0185,  3.3901,  1.8099]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 282 : 179.60742313782208
Test loss for epoch 282 : 179.79511355196297
Test Precision for epoch 282 : 0.26153846153846155
Test Recall for epoch 282 : 0.26153846153846155
Test F1 for epoch 282 : 0.26153846153846155


theta for epoch 283 : tensor([[ 2.7019,  2.7331,  2.8082,  2.9452,  2.9084,  2.7082,  2.8831,  2.7001,
          2.7001,  1.2363,  1.2666,  1.2533,  1.2967,  1.2278,  1.3358,  1.2418,
          1.2215,  1.2426,  1.2114,  1.1901,  1.2034,  1.2232,  1.1852,  1.1803,
          1.2005,  1.1730,  1.1730,  1.2192,  1.2625,  1.1946,  1.2175,  1.2642,
          1.2044,  1.2348,  1.1544,  1.1972,  1.3867,  1.4438,  1.4175,  1.3994,
          1.4189,  1.3642,  1.4017,  1.3177,  1.3507,  1.3126,  1.2603,  1.2463,
          1.2269,  1.3050,  1.2478,  1.3459,  1.2154,  1.2248],
        [ 1.2028,  1.2117,  1.1679,  1.2327,  1.2752,  1.2404,  1.2145,  1.2317,
          1.2317,  1.9373,  1.9719,  1.8910,  2.1898,  1.9165,  5.6903,  1.9608,
          1.8758,  5.4957,  1.2167,  1.2724,  1.2288,  1.1858,  1.2576,  1.2507,
          1.2338,  1.2418,  1.2418,  1.2969,  1.1578,  1.2615,  1.2903,  1.2246,
          1.2737,  1.3098,  1.2223,  1.2647,  1.3582,  1.4344,  1.3398,  1.3262,
          1.4002,  1.4104,  1.3196,  0.9655,  1.3097,  1.2586,  1.3185,  1.2996,
          1.2754,  1.1981,  1.3030,  1.2622,  1.2609,  1.2743],
        [ 1.1628,  1.1900,  1.2384,  1.2223,  1.1962,  1.1684,  1.1760,  1.1612,
          1.1612,  1.2353,  1.2666,  1.2529,  1.2975,  1.2266,  1.2963,  1.2410,
          1.1796,  1.2882,  2.7536,  2.9108,  2.9436,  2.7876,  2.7077,  2.7179,
          2.8599,  2.6945,  2.6945,  1.2249,  1.2638,  1.1951,  1.2176,  1.2251,
          1.2052,  1.2364,  1.1996,  1.1978,  1.3775,  1.4364,  1.4079,  1.3355,
          1.4093,  1.4118,  1.3929,  1.3042,  1.2845,  1.3120,  1.2601,  1.2457,
          1.2258,  1.3043,  1.2472,  1.3470,  1.2102,  1.2236],
        [ 1.1731,  1.2006,  1.2490,  1.2332,  1.2069,  1.1787,  1.1866,  1.1714,
          1.1714,  1.2450,  1.2765,  1.2627,  1.3075,  1.2362,  1.2651,  1.2508,
          1.2290,  1.2175,  1.2236,  1.2436,  1.2606,  1.2358,  1.1963,  1.1912,
          1.2088,  1.1837,  1.1837,  3.0010,  2.9815,  2.5961,  2.7621,  2.9974,
          2.6069,  2.9495,  2.6037,  2.5989,  1.3819,  1.4415,  1.4136,  1.3907,
          1.4153,  1.4177,  1.3972,  1.2615,  1.3396,  1.3234,  1.2690,  1.1708,
          1.1879,  1.3154,  1.2559,  1.3579,  1.1732,  1.2322],
        [ 1.7411,  1.3644,  0.5894,  0.8606,  1.2300,  1.6475,  1.5494,  1.7499,
          1.7499,  1.5844,  1.2111,  1.4089,  0.8338,  1.6267,  0.1327,  1.5180,
          1.7319,  0.8161,  1.2519,  0.9022,  0.6882,  1.0916,  1.5840,  1.6483,
          1.4288,  1.7512,  1.7512,  0.7748,  0.8152,  1.7242,  1.5223,  0.8090,
          1.6657,  1.1569,  1.7760,  1.6895,  0.0941, -0.1417, -0.1653,  0.0429,
          0.2890,  0.3780, -0.0219, 16.1919,  5.0863,  0.6897,  1.2465,  1.3341,
          1.5490,  0.9090,  1.4817,  0.2969,  1.6306,  1.7103],
        [ 1.2264,  1.2616,  1.3266,  1.3040,  1.2703,  1.2336,  1.2000,  1.2242,
          1.2242,  1.1900,  1.3240,  1.2127,  1.3641,  1.2720,  1.4151,  1.1975,
          1.2634,  1.2603,  1.2849,  1.2938,  1.3334,  1.3005,  1.2501,  1.2436,
          1.1609,  1.2340,  1.2340,  1.2995,  1.3424,  1.2532,  1.0472,  1.2545,
          1.1332,  1.3059,  1.1271,  1.2567,  1.3176,  1.0208,  1.3316,  1.3351,
          0.8765,  0.7998,  1.3387,  1.2190,  0.6689,  3.4800,  2.5799,  3.6767,
          2.8876,  2.1573,  1.8308,  3.0177,  3.3922,  1.8084]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 283 : 179.5896898823294
Test loss for epoch 283 : 179.7815871608697
Test Precision for epoch 283 : 0.26153846153846155
Test Recall for epoch 283 : 0.26153846153846155
Test F1 for epoch 283 : 0.26153846153846155


theta for epoch 284 : tensor([[ 2.7026,  2.7339,  2.8090,  2.9462,  2.9094,  2.7090,  2.8841,  2.7008,
          2.7008,  1.2361,  1.2665,  1.2531,  1.2965,  1.2278,  1.3356,  1.2418,
          1.2212,  1.2426,  1.2108,  1.1894,  1.2028,  1.2226,  1.1846,  1.1797,
          1.1999,  1.1725,  1.1725,  1.2190,  1.2623,  1.1945,  1.2173,  1.2640,
          1.2043,  1.2347,  1.1542,  1.1970,  1.3870,  1.4442,  1.4179,  1.3995,
          1.4194,  1.3648,  1.4020,  1.3166,  1.3512,  1.3130,  1.2607,  1.2467,
          1.2272,  1.3054,  1.2481,  1.3464,  1.2155,  1.2251],
        [ 1.2031,  1.2138,  1.1708,  1.2324,  1.2738,  1.2393,  1.2147,  1.2306,
          1.2306,  1.9499,  1.9800,  1.9020,  2.1915,  1.9266,  5.6607,  1.9707,
          1.8894,  5.4650,  1.2165,  1.2707,  1.2293,  1.1858,  1.2560,  1.2489,
          1.2326,  1.2400,  1.2400,  1.2958,  1.1593,  1.2603,  1.2891,  1.2249,
          1.2724,  1.3085,  1.2210,  1.2634,  1.3585,  1.4344,  1.3398,  1.3279,
          1.4007,  1.4107,  1.3195,  0.9745,  1.3102,  1.2617,  1.3177,  1.2989,
          1.2747,  1.2006,  1.3022,  1.2656,  1.2601,  1.2734],
        [ 1.1633,  1.1905,  1.2387,  1.2227,  1.1966,  1.1688,  1.1765,  1.1616,
          1.1616,  1.2356,  1.2670,  1.2532,  1.2979,  1.2271,  1.2963,  1.2415,
          1.1795,  1.2888,  2.7529,  2.9114,  2.9434,  2.7861,  2.7075,  2.7169,
          2.8607,  2.6942,  2.6942,  1.2248,  1.2642,  1.1954,  1.2179,  1.2250,
          1.2055,  1.2368,  1.2000,  1.1981,  1.3779,  1.4370,  1.4085,  1.3353,
          1.4101,  1.4125,  1.3934,  1.3036,  1.2847,  1.3129,  1.2609,  1.2465,
          1.2265,  1.3053,  1.2480,  1.3480,  1.2107,  1.2243],
        [ 1.1733,  1.2008,  1.2490,  1.2334,  1.2071,  1.1789,  1.1869,  1.1716,
          1.1716,  1.2451,  1.2766,  1.2628,  1.3076,  1.2364,  1.2656,  1.2510,
          1.2289,  1.2182,  1.2231,  1.2430,  1.2601,  1.2353,  1.1959,  1.1908,
          1.2082,  1.1833,  1.1833,  3.0014,  2.9819,  2.5965,  2.7621,  2.9978,
          2.6074,  2.9496,  2.6042,  2.5994,  1.3823,  1.4421,  1.4141,  1.3908,
          1.4160,  1.4183,  1.3976,  1.2612,  1.3401,  1.3239,  1.2694,  1.1717,
          1.1883,  1.3160,  1.2563,  1.3586,  1.1732,  1.2326],
        [ 1.7409,  1.3634,  0.5888,  0.8613,  1.2312,  1.6484,  1.5494,  1.7508,
          1.7508,  1.5842,  1.2113,  1.4087,  0.8335,  1.6252,  0.1310,  1.5174,
          1.7333,  0.8133,  1.2516,  0.9035,  0.6882,  1.0910,  1.5842,  1.6486,
          1.4296,  1.7513,  1.7513,  0.7759,  0.8143,  1.7249,  1.5234,  0.8095,
          1.6665,  1.1576,  1.7767,  1.6903,  0.0922, -0.1435, -0.1675,  0.0412,
          0.2864,  0.3751, -0.0239, 16.2573,  5.0294,  0.6890,  1.2472,  1.3342,
          1.5493,  0.9078,  1.4821,  0.2961,  1.6317,  1.7105],
        [ 1.2264,  1.2618,  1.3268,  1.3041,  1.2704,  1.2336,  1.2001,  1.2242,
          1.2242,  1.1900,  1.3239,  1.2127,  1.3642,  1.2720,  1.4152,  1.1976,
          1.2631,  1.2606,  1.2843,  1.2923,  1.3329,  1.3000,  1.2494,  1.2429,
          1.1593,  1.2332,  1.2332,  1.2995,  1.3424,  1.2530,  1.0463,  1.2544,
          1.1331,  1.3058,  1.1269,  1.2565,  1.3161,  1.0196,  1.3293,  1.3335,
          0.8747,  0.7981,  1.3373,  1.2156,  0.6669,  3.4826,  2.5789,  3.6780,
          2.8868,  2.1564,  1.8298,  3.0171,  3.3947,  1.8074]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 284 : 179.5717467531982
Test loss for epoch 284 : 179.7676852246717
Test Precision for epoch 284 : 0.26153846153846155
Test Recall for epoch 284 : 0.26153846153846155
Test F1 for epoch 284 : 0.26153846153846155


theta for epoch 285 : tensor([[ 2.7025,  2.7339,  2.8090,  2.9464,  2.9096,  2.7089,  2.8843,  2.7007,
          2.7007,  1.2370,  1.2673,  1.2540,  1.2974,  1.2289,  1.3363,  1.2428,
          1.2220,  1.2436,  1.2110,  1.1895,  1.2029,  1.2228,  1.1848,  1.1799,
          1.2001,  1.1727,  1.1727,  1.2190,  1.2623,  1.1945,  1.2174,  1.2640,
          1.2043,  1.2347,  1.1542,  1.1971,  1.3874,  1.4448,  1.4185,  1.3998,
          1.4202,  1.3656,  1.4025,  1.3160,  1.3520,  1.3133,  1.2608,  1.2468,
          1.2273,  1.3057,  1.2483,  1.3467,  1.2154,  1.2251],
        [ 1.2025,  1.2151,  1.1730,  1.2313,  1.2715,  1.2373,  1.2140,  1.2286,
          1.2286,  1.9630,  1.9890,  1.9136,  2.1941,  1.9372,  5.6312,  1.9812,
          1.9038,  5.4344,  1.2164,  1.2692,  1.2298,  1.1861,  1.2547,  1.2475,
          1.2318,  1.2386,  1.2386,  1.2943,  1.1608,  1.2586,  1.2875,  1.2247,
          1.2707,  1.3069,  1.2194,  1.2618,  1.3587,  1.4342,  1.3397,  1.3295,
          1.4010,  1.4109,  1.3193,  0.9833,  1.3106,  1.2641,  1.3163,  1.2975,
          1.2733,  1.2025,  1.3007,  1.2682,  1.2586,  1.2719],
        [ 1.1629,  1.1902,  1.2381,  1.2223,  1.1962,  1.1684,  1.1762,  1.1613,
          1.1613,  1.2364,  1.2677,  1.2539,  1.2986,  1.2280,  1.2967,  1.2423,
          1.1798,  1.2898,  2.7529,  2.9127,  2.9439,  2.7854,  2.7080,  2.7167,
          2.8621,  2.6947,  2.6947,  1.2241,  1.2641,  1.1953,  1.2177,  1.2244,
          1.2054,  1.2366,  1.1998,  1.1979,  1.3782,  1.4375,  1.4089,  1.3349,
          1.4107,  1.4129,  1.3937,  1.3028,  1.2846,  1.3130,  1.2609,  1.2465,
          1.2264,  1.3054,  1.2480,  1.3482,  1.2103,  1.2243],
        [ 1.1731,  1.2006,  1.2486,  1.2332,  1.2069,  1.1787,  1.1867,  1.1714,
          1.1714,  1.2459,  1.2775,  1.2636,  1.3085,  1.2375,  1.2669,  1.2520,
          1.2297,  1.2198,  1.2233,  1.2430,  1.2603,  1.2356,  1.1961,  1.1910,
          1.2082,  1.1835,  1.1835,  3.0014,  2.9819,  2.5967,  2.7617,  2.9979,
          2.6075,  2.9494,  2.6043,  2.5995,  1.3827,  1.4428,  1.4148,  1.3910,
          1.4168,  1.4190,  1.3981,  1.2611,  1.3407,  1.3242,  1.2696,  1.1723,
          1.1883,  1.3163,  1.2565,  1.3589,  1.1729,  1.2327],
        [ 1.7399,  1.3618,  0.5875,  0.8613,  1.2318,  1.6487,  1.5488,  1.7511,
          1.7511,  1.5846,  1.2120,  1.4090,  0.8337,  1.6241,  0.1295,  1.5173,
          1.7353,  0.8108,  1.2519,  0.9052,  0.6887,  1.0909,  1.5850,  1.6493,
          1.4309,  1.7521,  1.7521,  0.7768,  0.8130,  1.7254,  1.5244,  0.8097,
          1.6670,  1.1580,  1.7772,  1.6908,  0.0903, -0.1452, -0.1696,  0.0397,
          0.2840,  0.3724, -0.0257, 16.3232,  4.9718,  0.6876,  1.2470,  1.3336,
          1.5488,  0.9059,  1.4818,  0.2947,  1.6322,  1.7100],
        [ 1.2259,  1.2614,  1.3266,  1.3038,  1.2700,  1.2331,  1.1997,  1.2237,
          1.2237,  1.1908,  1.3248,  1.2136,  1.3652,  1.2730,  1.4161,  1.1986,
          1.2637,  1.2618,  1.2845,  1.2915,  1.3331,  1.3002,  1.2495,  1.2430,
          1.1585,  1.2333,  1.2333,  1.2995,  1.3425,  1.2528,  1.0454,  1.2544,
          1.1329,  1.3058,  1.1267,  1.2563,  1.3148,  1.0188,  1.3271,  1.3321,
          0.8731,  0.7966,  1.3361,  1.2125,  0.6652,  3.4847,  2.5773,  3.6786,
          2.8854,  2.1548,  1.8281,  3.0159,  3.3966,  1.8056]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 285 : 179.55346431133773
Test loss for epoch 285 : 179.7539883264975
Test Precision for epoch 285 : 0.26153846153846155
Test Recall for epoch 285 : 0.26153846153846155
Test F1 for epoch 285 : 0.26153846153846155


theta for epoch 286 : tensor([[ 2.7025,  2.7340,  2.8091,  2.9466,  2.9098,  2.7089,  2.8845,  2.7007,
          2.7007,  1.2367,  1.2670,  1.2537,  1.2971,  1.2288,  1.3359,  1.2426,
          1.2216,  1.2435,  1.2115,  1.1900,  1.2033,  1.2233,  1.1853,  1.1804,
          1.2005,  1.1732,  1.1732,  1.2194,  1.2628,  1.1949,  1.2178,  1.2644,
          1.2047,  1.2351,  1.1546,  1.1975,  1.3879,  1.4454,  1.4192,  1.4002,
          1.4210,  1.3664,  1.4030,  1.3153,  1.3528,  1.3135,  1.2610,  1.2470,
          1.2274,  1.3060,  1.2484,  1.3470,  1.2154,  1.2252],
        [ 1.2027,  1.2169,  1.1759,  1.2308,  1.2698,  1.2359,  1.2139,  1.2273,
          1.2273,  1.9750,  1.9969,  1.9241,  2.1960,  1.9465,  5.6001,  1.9906,
          1.9171,  5.4022,  1.2167,  1.2681,  1.2305,  1.1871,  1.2539,  1.2467,
          1.2317,  1.2378,  1.2378,  1.2935,  1.1632,  1.2578,  1.2865,  1.2250,
          1.2698,  1.3060,  1.2185,  1.2609,  1.3590,  1.4343,  1.3399,  1.3315,
          1.4015,  1.4113,  1.3193,  0.9924,  1.3112,  1.2668,  1.3151,  1.2964,
          1.2722,  1.2047,  1.2995,  1.2709,  1.2573,  1.2707],
        [ 1.1628,  1.1900,  1.2378,  1.2221,  1.1960,  1.1682,  1.1760,  1.1611,
          1.1611,  1.2359,  1.2672,  1.2534,  1.2982,  1.2277,  1.2958,  1.2420,
          1.1789,  1.2895,  2.7532,  2.9144,  2.9447,  2.7849,  2.7088,  2.7168,
          2.8639,  2.6954,  2.6954,  1.2238,  1.2642,  1.1954,  1.2179,  1.2241,
          1.2055,  1.2368,  1.1999,  1.1981,  1.3784,  1.4378,  1.4093,  1.3343,
          1.4112,  1.4132,  1.3940,  1.3020,  1.2845,  1.3130,  1.2608,  1.2464,
          1.2263,  1.3055,  1.2479,  1.3483,  1.2098,  1.2241],
        [ 1.1731,  1.2006,  1.2483,  1.2331,  1.2068,  1.1786,  1.1867,  1.1713,
          1.1713,  1.2456,  1.2772,  1.2633,  1.3082,  1.2374,  1.2670,  1.2518,
          1.2292,  1.2202,  1.2238,  1.2431,  1.2606,  1.2360,  1.1966,  1.1915,
          1.2085,  1.1840,  1.1840,  3.0017,  2.9822,  2.5971,  2.7615,  2.9982,
          2.6080,  2.9495,  2.6047,  2.5999,  1.3832,  1.4433,  1.4154,  1.3910,
          1.4176,  1.4196,  1.3986,  1.2610,  1.3412,  1.3244,  1.2697,  1.1729,
          1.1882,  1.3165,  1.2566,  1.3591,  1.1725,  1.2327],
        [ 1.7391,  1.3604,  0.5863,  0.8615,  1.2325,  1.6493,  1.5485,  1.7516,
          1.7516,  1.5837,  1.2116,  1.4082,  0.8329,  1.6218,  0.1271,  1.5161,
          1.7362,  0.8072,  1.2526,  0.9073,  0.6896,  1.0911,  1.5863,  1.6504,
          1.4325,  1.7532,  1.7532,  0.7780,  0.8120,  1.7263,  1.5257,  0.8102,
          1.6679,  1.1588,  1.7781,  1.6917,  0.0885, -0.1468, -0.1716,  0.0383,
          0.2816,  0.3697, -0.0275, 16.3896,  4.9136,  0.6863,  1.2469,  1.3330,
          1.5485,  0.9040,  1.4816,  0.2933,  1.6327,  1.7096],
        [ 1.2257,  1.2613,  1.3265,  1.3037,  1.2699,  1.2329,  1.1995,  1.2235,
          1.2235,  1.1904,  1.3244,  1.2132,  1.3650,  1.2728,  1.4158,  1.1983,
          1.2630,  1.2617,  1.2848,  1.2909,  1.3335,  1.3006,  1.2498,  1.2433,
          1.1579,  1.2335,  1.2335,  1.2998,  1.3429,  1.2529,  1.0448,  1.2547,
          1.1331,  1.3060,  1.1268,  1.2564,  1.3134,  1.0178,  1.3248,  1.3305,
          0.8713,  0.7950,  1.3348,  1.2095,  0.6634,  3.4869,  2.5758,  3.6792,
          2.8840,  2.1534,  1.8266,  3.0149,  3.3987,  1.8041]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 286 : 179.53488864760058
Test loss for epoch 286 : 179.74016452147444
Test Precision for epoch 286 : 0.26153846153846155
Test Recall for epoch 286 : 0.26153846153846155
Test F1 for epoch 286 : 0.26153846153846155


theta for epoch 287 : tensor([[ 2.7030,  2.7345,  2.8096,  2.9473,  2.9105,  2.7093,  2.8852,  2.7012,
          2.7012,  1.2362,  1.2665,  1.2532,  1.2967,  1.2285,  1.3353,  1.2423,
          1.2210,  1.2432,  1.2112,  1.1896,  1.2030,  1.2230,  1.1851,  1.1802,
          1.2002,  1.1730,  1.1730,  1.2195,  1.2629,  1.1951,  1.2180,  1.2645,
          1.2049,  1.2353,  1.1548,  1.1976,  1.3882,  1.4459,  1.4196,  1.4004,
          1.4216,  1.3670,  1.4033,  1.3146,  1.3534,  1.3139,  1.2613,  1.2473,
          1.2276,  1.3064,  1.2487,  1.3475,  1.2155,  1.2254],
        [ 1.2034,  1.2191,  1.1794,  1.2308,  1.2685,  1.2349,  1.2141,  1.2263,
          1.2263,  1.9871,  2.0053,  1.9347,  2.1984,  1.9559,  5.5688,  2.0003,
          1.9308,  5.3698,  1.2160,  1.2660,  1.2302,  1.1874,  1.2522,  1.2451,
          1.2309,  1.2362,  1.2362,  1.2923,  1.1655,  1.2566,  1.2852,  1.2250,
          1.2687,  1.3048,  1.2173,  1.2598,  1.3592,  1.4342,  1.3399,  1.3333,
          1.4019,  1.4116,  1.3191,  1.0014,  1.3117,  1.2697,  1.3141,  1.2955,
          1.2712,  1.2072,  1.2984,  1.2737,  1.2563,  1.2697],
        [ 1.1633,  1.1906,  1.2381,  1.2226,  1.1965,  1.1688,  1.1766,  1.1616,
          1.1616,  1.2357,  1.2670,  1.2532,  1.2980,  1.2277,  1.2953,  1.2419,
          1.1784,  1.2895,  2.7526,  2.9152,  2.9447,  2.7836,  2.7086,  2.7160,
          2.8648,  2.6953,  2.6953,  1.2238,  1.2647,  1.1958,  1.2182,  1.2240,
          1.2059,  1.2372,  1.2003,  1.1985,  1.3788,  1.4384,  1.4098,  1.3340,
          1.4119,  1.4138,  1.3944,  1.3015,  1.2847,  1.3137,  1.2613,  1.2469,
          1.2267,  1.3062,  1.2484,  1.3489,  1.2099,  1.2245],
        [ 1.1735,  1.2011,  1.2485,  1.2335,  1.2072,  1.1790,  1.1871,  1.1717,
          1.1717,  1.2453,  1.2767,  1.2629,  1.3078,  1.2372,  1.2671,  1.2515,
          1.2287,  1.2206,  1.2235,  1.2426,  1.2603,  1.2358,  1.1963,  1.1913,
          1.2080,  1.1838,  1.1838,  3.0020,  2.9824,  2.5975,  2.7613,  2.9985,
          2.6084,  2.9495,  2.6052,  2.6004,  1.3835,  1.4438,  1.4159,  1.3910,
          1.4183,  1.4201,  1.3989,  1.2610,  1.3416,  1.3248,  1.2701,  1.1738,
          1.1884,  1.3170,  1.2569,  1.3596,  1.1724,  1.2329],
        [ 1.7389,  1.3597,  0.5856,  0.8623,  1.2340,  1.6505,  1.5489,  1.7528,
          1.7528,  1.5829,  1.2115,  1.4074,  0.8324,  1.6196,  0.1250,  1.5150,
          1.7372,  0.8038,  1.2527,  0.9090,  0.6901,  1.0907,  1.5870,  1.6510,
          1.4335,  1.7537,  1.7537,  0.7794,  0.8111,  1.7273,  1.5272,  0.8110,
          1.6690,  1.1598,  1.7791,  1.6927,  0.0864, -0.1487, -0.1739,  0.0366,
          0.2790,  0.3667, -0.0296, 16.4562,  4.8544,  0.6858,  1.2475,  1.3330,
          1.5487,  0.9029,  1.4820,  0.2927,  1.6339,  1.7098],
        [ 1.2258,  1.2616,  1.3268,  1.3040,  1.2701,  1.2330,  1.1997,  1.2235,
          1.2235,  1.1897,  1.3238,  1.2125,  1.3644,  1.2723,  1.4153,  1.1978,
          1.2621,  1.2614,  1.2842,  1.2894,  1.3331,  1.3001,  1.2492,  1.2427,
          1.1564,  1.2329,  1.2329,  1.2998,  1.3429,  1.2528,  1.0438,  1.2547,
          1.1329,  1.3060,  1.1267,  1.2562,  1.3118,  1.0165,  1.3223,  1.3287,
          0.8693,  0.7931,  1.3332,  1.2062,  0.6612,  3.4897,  2.5748,  3.6804,
          2.8832,  2.1526,  1.8256,  3.0143,  3.4015,  1.8031]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 287 : 179.5160589233486
Test loss for epoch 287 : 179.72585472145005
Test Precision for epoch 287 : 0.26153846153846155
Test Recall for epoch 287 : 0.26153846153846155
Test F1 for epoch 287 : 0.26153846153846155


theta for epoch 288 : tensor([[ 2.7029,  2.7344,  2.8096,  2.9475,  2.9106,  2.7093,  2.8854,  2.7011,
          2.7011,  1.2369,  1.2671,  1.2538,  1.2973,  1.2294,  1.3358,  1.2430,
          1.2215,  1.2440,  1.2112,  1.1896,  1.2030,  1.2231,  1.1851,  1.1803,
          1.2002,  1.1730,  1.1730,  1.2194,  1.2629,  1.1950,  1.2180,  1.2644,
          1.2048,  1.2353,  1.1547,  1.1976,  1.3888,  1.4466,  1.4204,  1.4008,
          1.4225,  1.3679,  1.4039,  1.3142,  1.3543,  1.3141,  1.2614,  1.2474,
          1.2277,  1.3066,  1.2487,  1.3477,  1.2154,  1.2255],
        [ 1.2034,  1.2204,  1.1824,  1.2302,  1.2666,  1.2331,  1.2136,  1.2246,
          1.2246,  2.0001,  2.0147,  1.9461,  2.2020,  1.9662,  5.5378,  2.0108,
          1.9456,  5.3377,  1.2152,  1.2637,  1.2294,  1.1876,  1.2504,  1.2434,
          1.2301,  1.2345,  1.2345,  1.2903,  1.1674,  1.2548,  1.2832,  1.2241,
          1.2668,  1.3030,  1.2155,  1.2579,  1.3592,  1.4340,  1.3399,  1.3351,
          1.4022,  1.4118,  1.3189,  1.0103,  1.3122,  1.2719,  1.3124,  1.2939,
          1.2696,  1.2091,  1.2967,  1.2757,  1.2545,  1.2680],
        [ 1.1636,  1.1909,  1.2381,  1.2228,  1.1967,  1.1690,  1.1768,  1.1618,
          1.1618,  1.2365,  1.2677,  1.2540,  1.2987,  1.2287,  1.2957,  1.2428,
          1.1788,  1.2904,  2.7520,  2.9159,  2.9446,  2.7823,  2.7084,  2.7152,
          2.8657,  2.6951,  2.6951,  1.2233,  1.2647,  1.1958,  1.2183,  1.2235,
          1.2060,  1.2372,  1.2004,  1.1985,  1.3795,  1.4392,  1.4106,  1.3340,
          1.4129,  1.4145,  1.3951,  1.3012,  1.2850,  1.3139,  1.2615,  1.2471,
          1.2268,  1.3065,  1.2485,  1.3493,  1.2096,  1.2246],
        [ 1.1736,  1.2012,  1.2484,  1.2335,  1.2072,  1.1790,  1.1871,  1.1718,
          1.1718,  1.2458,  1.2773,  1.2635,  1.3083,  1.2380,  1.2681,  1.2522,
          1.2292,  1.2218,  1.2233,  1.2422,  1.2602,  1.2357,  1.1963,  1.1912,
          1.2077,  1.1837,  1.1837,  3.0020,  2.9824,  2.5977,  2.7608,  2.9985,
          2.6086,  2.9492,  2.6054,  2.6006,  1.3840,  1.4445,  1.4166,  1.3912,
          1.4191,  1.4207,  1.3994,  1.2612,  1.3422,  1.3249,  1.2701,  1.1744,
          1.1883,  1.3171,  1.2569,  1.3598,  1.1719,  1.2328],
        [ 1.7381,  1.3586,  0.5844,  0.8626,  1.2349,  1.6512,  1.5487,  1.7534,
          1.7534,  1.5827,  1.2120,  1.4073,  0.8325,  1.6180,  0.1231,  1.5147,
          1.7391,  0.8009,  1.2528,  0.9107,  0.6907,  1.0902,  1.5877,  1.6517,
          1.4346,  1.7543,  1.7543,  0.7803,  0.8095,  1.7278,  1.5282,  0.8112,
          1.6696,  1.1602,  1.7796,  1.6932,  0.0845, -0.1503, -0.1759,  0.0351,
          0.2766,  0.3640, -0.0314, 16.5234,  4.7947,  0.6845,  1.2474,  1.3323,
          1.5483,  0.9010,  1.4817,  0.2915,  1.6344,  1.7093],
        [ 1.2257,  1.2616,  1.3269,  1.3041,  1.2700,  1.2329,  1.1997,  1.2234,
          1.2234,  1.1903,  1.3243,  1.2132,  1.3651,  1.2731,  1.4160,  1.1985,
          1.2623,  1.2624,  1.2841,  1.2883,  1.3330,  1.3000,  1.2490,  1.2425,
          1.1553,  1.2327,  1.2327,  1.2996,  1.3428,  1.2524,  1.0427,  1.2545,
          1.1327,  1.3058,  1.1263,  1.2559,  1.3105,  1.0157,  1.3201,  1.3273,
          0.8677,  0.7917,  1.3320,  1.2033,  0.6596,  3.4918,  2.5731,  3.6807,
          2.8817,  2.1510,  1.8239,  3.0130,  3.4035,  1.8014]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 288 : 179.4969012152217
Test loss for epoch 288 : 179.71199730808422
Test Precision for epoch 288 : 0.26153846153846155
Test Recall for epoch 288 : 0.26153846153846155
Test F1 for epoch 288 : 0.26153846153846155


theta for epoch 289 : tensor([[ 2.7027,  2.7342,  2.8094,  2.9474,  2.9106,  2.7090,  2.8853,  2.7009,
          2.7009,  1.2370,  1.2672,  1.2540,  1.2973,  1.2297,  1.3358,  1.2432,
          1.2215,  1.2442,  1.2118,  1.1901,  1.2035,  1.2237,  1.1857,  1.1809,
          1.2008,  1.1736,  1.1736,  1.2195,  1.2631,  1.1952,  1.2181,  1.2645,
          1.2050,  1.2354,  1.1549,  1.1977,  1.3893,  1.4473,  1.4211,  1.4012,
          1.4234,  1.3688,  1.4044,  1.3138,  1.3551,  1.3145,  1.2616,  1.2476,
          1.2278,  1.3070,  1.2489,  1.3481,  1.2155,  1.2256],
        [ 1.2033,  1.2217,  1.1854,  1.2294,  1.2644,  1.2313,  1.2130,  1.2227,
          1.2227,  2.0123,  2.0236,  1.9568,  2.2053,  1.9756,  5.5057,  2.0206,
          1.9597,  5.3046,  1.2150,  1.2621,  1.2291,  1.1887,  1.2494,  1.2425,
          1.2301,  1.2337,  1.2337,  1.2886,  1.1699,  1.2533,  1.2816,  1.2236,
          1.2654,  1.3015,  1.2140,  1.2565,  1.3593,  1.4340,  1.3399,  1.3370,
          1.4025,  1.4121,  1.3188,  1.0195,  1.3127,  1.2744,  1.3110,  1.2926,
          1.2683,  1.2114,  1.2954,  1.2780,  1.2530,  1.2666],
        [ 1.1633,  1.1907,  1.2376,  1.2225,  1.1964,  1.1687,  1.1766,  1.1615,
          1.1615,  1.2366,  1.2677,  1.2540,  1.2987,  1.2290,  1.2953,  1.2429,
          1.1784,  1.2906,  2.7521,  2.9173,  2.9452,  2.7817,  2.7089,  2.7150,
          2.8672,  2.6955,  2.6955,  1.2228,  1.2647,  1.1958,  1.2182,  1.2230,
          1.2060,  1.2372,  1.2004,  1.1985,  1.3799,  1.4397,  1.4112,  1.3336,
          1.4136,  1.4150,  1.3955,  1.3007,  1.2851,  1.3141,  1.2616,  1.2471,
          1.2268,  1.3068,  1.2485,  1.3495,  1.2092,  1.2245],
        [ 1.1732,  1.2009,  1.2478,  1.2331,  1.2069,  1.1787,  1.1868,  1.1714,
          1.1714,  1.2458,  1.2772,  1.2634,  1.3082,  1.2382,  1.2686,  1.2522,
          1.2290,  1.2226,  1.2238,  1.2424,  1.2606,  1.2362,  1.1967,  1.1917,
          1.2079,  1.1842,  1.1842,  3.0022,  2.9825,  2.5981,  2.7605,  2.9987,
          2.6090,  2.9491,  2.6058,  2.6010,  1.3844,  1.4450,  1.4171,  1.3912,
          1.4199,  1.4213,  1.3998,  1.2613,  1.3427,  1.3251,  1.2702,  1.1750,
          1.1882,  1.3173,  1.2569,  1.3600,  1.1715,  1.2328],
        [ 1.7370,  1.3572,  0.5829,  0.8626,  1.2355,  1.6516,  1.5483,  1.7538,
          1.7538,  1.5819,  1.2120,  1.4067,  0.8321,  1.6159,  0.1208,  1.5137,
          1.7403,  0.7975,  1.2535,  0.9129,  0.6918,  1.0903,  1.5892,  1.6530,
          1.4362,  1.7555,  1.7555,  0.7814,  0.8081,  1.7285,  1.5295,  0.8115,
          1.6704,  1.1609,  1.7804,  1.6940,  0.0826, -0.1521, -0.1780,  0.0336,
          0.2741,  0.3612, -0.0332, 16.5910,  4.7343,  0.6835,  1.2474,  1.3317,
          1.5480,  0.8993,  1.4816,  0.2904,  1.6351,  1.7090],
        [ 1.2254,  1.2613,  1.3267,  1.3038,  1.2697,  1.2325,  1.1993,  1.2230,
          1.2230,  1.1904,  1.3243,  1.2132,  1.3653,  1.2733,  1.4161,  1.1986,
          1.2620,  1.2627,  1.2845,  1.2878,  1.3335,  1.3006,  1.2494,  1.2429,
          1.1549,  1.2331,  1.2331,  1.2997,  1.3430,  1.2523,  1.0419,  1.2546,
          1.1326,  1.3058,  1.1262,  1.2558,  1.3092,  1.0148,  1.3179,  1.3258,
          0.8661,  0.7902,  1.3308,  1.2004,  0.6579,  3.4940,  2.5713,  3.6809,
          2.8800,  2.1494,  1.8222,  3.0116,  3.4055,  1.7996]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 289 : 179.47750096664532
Test loss for epoch 289 : 179.6979535475457
Test Precision for epoch 289 : 0.26153846153846155
Test Recall for epoch 289 : 0.26153846153846155
Test F1 for epoch 289 : 0.26153846153846155


theta for epoch 290 : tensor([[ 2.7030,  2.7346,  2.8097,  2.9480,  2.9111,  2.7093,  2.8859,  2.7012,
          2.7012,  1.2365,  1.2665,  1.2534,  1.2967,  1.2293,  1.3351,  1.2427,
          1.2208,  1.2438,  1.2118,  1.1900,  1.2035,  1.2237,  1.1857,  1.1809,
          1.2008,  1.1737,  1.1737,  1.2195,  1.2632,  1.1953,  1.2182,  1.2646,
          1.2051,  1.2355,  1.1550,  1.1978,  1.3894,  1.4475,  1.4214,  1.4012,
          1.4238,  1.3692,  1.4045,  1.3130,  1.3555,  1.3149,  1.2620,  1.2479,
          1.2281,  1.3075,  1.2492,  1.3486,  1.2156,  1.2258],
        [ 1.2038,  1.2234,  1.1892,  1.2294,  1.2629,  1.2300,  1.2130,  1.2215,
          1.2215,  2.0239,  2.0322,  1.9670,  2.2085,  1.9843,  5.4727,  2.0299,
          1.9734,  5.2705,  1.2146,  1.2602,  1.2284,  1.1897,  1.2480,  1.2414,
          1.2300,  1.2325,  1.2325,  1.2873,  1.1731,  1.2523,  1.2803,  1.2235,
          1.2643,  1.3004,  1.2130,  1.2554,  1.3593,  1.4338,  1.3398,  1.3388,
          1.4027,  1.4123,  1.3185,  1.0287,  1.3131,  1.2774,  1.3101,  1.2918,
          1.2674,  1.2142,  1.2944,  1.2808,  1.2521,  1.2656],
        [ 1.1636,  1.1909,  1.2376,  1.2227,  1.1966,  1.1689,  1.1768,  1.1617,
          1.1617,  1.2364,  1.2674,  1.2538,  1.2984,  1.2290,  1.2947,  1.2428,
          1.1778,  1.2906,  2.7517,  2.9184,  2.9454,  2.7806,  2.7089,  2.7144,
          2.8684,  2.6955,  2.6955,  1.2227,  1.2651,  1.1962,  1.2186,  1.2229,
          1.2063,  1.2376,  1.2007,  1.1988,  1.3802,  1.4402,  1.4116,  1.3332,
          1.4142,  1.4154,  1.3958,  1.3002,  1.2852,  1.3147,  1.2621,  1.2476,
          1.2273,  1.3075,  1.2490,  1.3502,  1.2093,  1.2250],
        [ 1.1733,  1.2009,  1.2476,  1.2331,  1.2069,  1.1787,  1.1869,  1.1714,
          1.1714,  1.2454,  1.2766,  1.2630,  1.3076,  1.2379,  1.2687,  1.2518,
          1.2284,  1.2230,  1.2238,  1.2420,  1.2605,  1.2362,  1.1968,  1.1918,
          1.2077,  1.1843,  1.1843,  3.0025,  2.9826,  2.5986,  2.7602,  2.9990,
          2.6095,  2.9490,  2.6064,  2.6015,  1.3846,  1.4454,  1.4175,  1.3909,
          1.4204,  1.4215,  1.4000,  1.2614,  1.3429,  1.3255,  1.2705,  1.1760,
          1.1883,  1.3178,  1.2572,  1.3605,  1.1713,  1.2331],
        [ 1.7364,  1.3564,  0.5818,  0.8632,  1.2367,  1.6526,  1.5484,  1.7548,
          1.7548,  1.5807,  1.2118,  1.4057,  0.8317,  1.6134,  0.1184,  1.5125,
          1.7413,  0.7938,  1.2539,  0.9150,  0.6929,  1.0901,  1.5904,  1.6540,
          1.4376,  1.7565,  1.7565,  0.7828,  0.8070,  1.7296,  1.5310,  0.8121,
          1.6715,  1.1619,  1.7815,  1.6951,  0.0804, -0.1540, -0.1804,  0.0318,
          0.2713,  0.3581, -0.0354, 16.6588,  4.6730,  0.6833,  1.2481,  1.3318,
          1.5484,  0.8983,  1.4821,  0.2903,  1.6365,  1.7092],
        [ 1.2253,  1.2613,  1.3268,  1.3038,  1.2697,  1.2324,  1.1993,  1.2228,
          1.2228,  1.1898,  1.3237,  1.2127,  1.3648,  1.2730,  1.4157,  1.1982,
          1.2612,  1.2626,  1.2844,  1.2868,  1.3335,  1.3006,  1.2492,  1.2428,
          1.1538,  1.2329,  1.2329,  1.2998,  1.3432,  1.2522,  1.0411,  1.2547,
          1.1326,  1.3059,  1.1262,  1.2557,  1.3075,  1.0135,  1.3153,  1.3239,
          0.8641,  0.7883,  1.3291,  1.1971,  0.6558,  3.4966,  2.5700,  3.6816,
          2.8788,  2.1483,  1.8210,  3.0107,  3.4080,  1.7984]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 290 : 179.45784680062903
Test loss for epoch 290 : 179.68347446556754
Test Precision for epoch 290 : 0.26153846153846155
Test Recall for epoch 290 : 0.26153846153846155
Test F1 for epoch 290 : 0.26153846153846155


theta for epoch 291 : tensor([[ 2.7032,  2.7349,  2.8100,  2.9484,  2.9115,  2.7095,  2.8863,  2.7014,
          2.7014,  1.2369,  1.2668,  1.2537,  1.2970,  1.2299,  1.3354,  1.2431,
          1.2210,  1.2443,  1.2114,  1.1896,  1.2031,  1.2234,  1.1854,  1.1806,
          1.2005,  1.1734,  1.1734,  1.2194,  1.2631,  1.1952,  1.2182,  1.2644,
          1.2050,  1.2355,  1.1549,  1.1978,  1.3898,  1.4480,  1.4219,  1.4014,
          1.4245,  1.3699,  1.4048,  1.3124,  1.3562,  1.3150,  1.2620,  1.2479,
          1.2280,  1.3076,  1.2492,  1.3488,  1.2153,  1.2257],
        [ 1.2041,  1.2248,  1.1929,  1.2292,  1.2612,  1.2285,  1.2128,  1.2199,
          1.2199,  2.0362,  2.0417,  1.9778,  2.2128,  1.9937,  5.4401,  2.0400,
          1.9881,  5.2368,  1.2136,  1.2577,  1.2269,  1.1903,  1.2460,  1.2396,
          1.2294,  1.2308,  1.2308,  1.2855,  1.1759,  1.2507,  1.2785,  1.2230,
          1.2627,  1.2988,  1.2114,  1.2539,  1.3592,  1.4336,  1.3397,  1.3407,
          1.4029,  1.4124,  1.3183,  1.0379,  1.3135,  1.2798,  1.3086,  1.2904,
          1.2660,  1.2166,  1.2929,  1.2829,  1.2505,  1.2641],
        [ 1.1639,  1.1912,  1.2376,  1.2229,  1.1969,  1.1692,  1.1771,  1.1620,
          1.1620,  1.2371,  1.2680,  1.2545,  1.2990,  1.2299,  1.2951,  1.2435,
          1.1781,  1.2914,  2.7509,  2.9190,  2.9452,  2.7792,  2.7085,  2.7135,
          2.8691,  2.6951,  2.6951,  1.2224,  1.2653,  1.1964,  1.2188,  1.2226,
          1.2065,  1.2378,  1.2009,  1.1991,  1.3809,  1.4409,  1.4124,  1.3330,
          1.4151,  1.4161,  1.3964,  1.3000,  1.2855,  1.3151,  1.2623,  1.2479,
          1.2275,  1.3079,  1.2492,  1.3507,  1.2091,  1.2251],
        [ 1.1735,  1.2011,  1.2474,  1.2333,  1.2070,  1.1789,  1.1870,  1.1716,
          1.1716,  1.2460,  1.2771,  1.2635,  1.3081,  1.2387,  1.2698,  1.2525,
          1.2288,  1.2243,  1.2235,  1.2415,  1.2602,  1.2360,  1.1966,  1.1916,
          1.2072,  1.1841,  1.1841,  3.0024,  2.9824,  2.5988,  2.7595,  2.9989,
          2.6097,  2.9486,  2.6066,  2.6016,  1.3851,  1.4460,  1.4181,  1.3909,
          1.4212,  1.4221,  1.4004,  1.2618,  1.3434,  1.3258,  1.2707,  1.1768,
          1.1883,  1.3181,  1.2573,  1.3608,  1.1709,  1.2331],
        [ 1.7356,  1.3555,  0.5805,  0.8634,  1.2378,  1.6535,  1.5483,  1.7556,
          1.7556,  1.5801,  1.2121,  1.4053,  0.8317,  1.6116,  0.1162,  1.5119,
          1.7429,  0.7907,  1.2537,  0.9164,  0.6933,  1.0892,  1.5911,  1.6546,
          1.4384,  1.7571,  1.7571,  0.7838,  0.8053,  1.7304,  1.5322,  0.8123,
          1.6724,  1.1625,  1.7822,  1.6959,  0.0785, -0.1558, -0.1825,  0.0303,
          0.2689,  0.3554, -0.0372, 16.7273,  4.6113,  0.6823,  1.2480,  1.3312,
          1.5481,  0.8966,  1.4820,  0.2894,  1.6372,  1.7089],
        [ 1.2254,  1.2615,  1.3270,  1.3040,  1.2698,  1.2324,  1.1994,  1.2229,
          1.2229,  1.1904,  1.3242,  1.2133,  1.3654,  1.2737,  1.4163,  1.1988,
          1.2613,  1.2635,  1.2841,  1.2855,  1.3333,  1.3004,  1.2489,  1.2424,
          1.1526,  1.2325,  1.2325,  1.2998,  1.3433,  1.2521,  1.0403,  1.2547,
          1.1325,  1.3060,  1.1261,  1.2556,  1.3062,  1.0127,  1.3131,  1.3224,
          0.8625,  0.7869,  1.3279,  1.1942,  0.6541,  3.4987,  2.5681,  3.6816,
          2.8770,  2.1466,  1.8192,  3.0091,  3.4100,  1.7966]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 291 : 179.43789841946798
Test loss for epoch 291 : 179.6695653990247
Test Precision for epoch 291 : 0.26153846153846155
Test Recall for epoch 291 : 0.26153846153846155
Test F1 for epoch 291 : 0.26153846153846155


theta for epoch 292 : tensor([[ 2.7029,  2.7346,  2.8097,  2.9482,  2.9114,  2.7092,  2.8861,  2.7010,
          2.7010,  1.2374,  1.2672,  1.2542,  1.2974,  1.2306,  1.3357,  1.2436,
          1.2212,  1.2450,  1.2117,  1.1899,  1.2034,  1.2238,  1.1857,  1.1810,
          1.2008,  1.1737,  1.1737,  1.2195,  1.2633,  1.1953,  1.2183,  1.2645,
          1.2052,  1.2356,  1.1550,  1.1979,  1.3903,  1.4486,  1.4226,  1.4017,
          1.4253,  1.3707,  1.4054,  1.3121,  1.3570,  1.3153,  1.2621,  1.2480,
          1.2281,  1.3080,  1.2493,  1.3492,  1.2153,  1.2259],
        [ 1.2040,  1.2257,  1.1964,  1.2286,  1.2590,  1.2265,  1.2121,  1.2180,
          1.2180,  2.0484,  2.0513,  1.9886,  2.2175,  2.0030,  5.4070,  2.0501,
          2.0028,  5.2027,  1.2130,  1.2555,  1.2256,  1.1914,  1.2444,  1.2383,
          1.2293,  1.2295,  1.2295,  1.2836,  1.1789,  1.2491,  1.2767,  1.2224,
          1.2611,  1.2972,  1.2098,  1.2523,  1.3591,  1.4333,  1.3396,  1.3425,
          1.4030,  1.4125,  1.3180,  1.0473,  1.3138,  1.2821,  1.3070,  1.2889,
          1.2645,  1.2189,  1.2913,  1.2849,  1.2488,  1.2625],
        [ 1.1637,  1.1910,  1.2371,  1.2226,  1.1966,  1.1690,  1.1769,  1.1618,
          1.1618,  1.2375,  1.2683,  1.2548,  1.2993,  1.2305,  1.2951,  1.2440,
          1.1781,  1.2919,  2.7507,  2.9203,  2.9456,  2.7784,  2.7087,  2.7131,
          2.8704,  2.6953,  2.6953,  1.2219,  1.2653,  1.1964,  1.2188,  1.2221,
          1.2065,  1.2378,  1.2009,  1.1991,  1.3814,  1.4415,  1.4130,  1.3328,
          1.4159,  1.4166,  1.3969,  1.2996,  1.2857,  1.3152,  1.2623,  1.2479,
          1.2274,  1.3081,  1.2492,  1.3509,  1.2086,  1.2251],
        [ 1.1733,  1.2009,  1.2470,  1.2330,  1.2068,  1.1787,  1.1868,  1.1714,
          1.1714,  1.2465,  1.2774,  1.2639,  1.3084,  1.2394,  1.2708,  1.2530,
          1.2290,  1.2256,  1.2238,  1.2414,  1.2604,  1.2363,  1.1968,  1.1919,
          1.2073,  1.1844,  1.1844,  3.0022,  2.9820,  2.5989,  2.7587,  2.9987,
          2.6098,  2.9480,  2.6067,  2.6018,  1.3856,  1.4466,  1.4187,  1.3910,
          1.4220,  1.4226,  1.4009,  1.2623,  1.3440,  1.3260,  1.2708,  1.1776,
          1.1883,  1.3183,  1.2574,  1.3612,  1.1705,  1.2332],
        [ 1.7346,  1.3543,  0.5789,  0.8634,  1.2385,  1.6540,  1.5479,  1.7561,
          1.7561,  1.5794,  1.2124,  1.4048,  0.8319,  1.6098,  0.1140,  1.5112,
          1.7444,  0.7876,  1.2540,  0.9183,  0.6943,  1.0887,  1.5924,  1.6557,
          1.4396,  1.7582,  1.7582,  0.7849,  0.8038,  1.7312,  1.5334,  0.8124,
          1.6732,  1.1631,  1.7830,  1.6967,  0.0764, -0.1575, -0.1846,  0.0287,
          0.2663,  0.3525, -0.0392, 16.7961,  4.5488,  0.6816,  1.2481,  1.3306,
          1.5480,  0.8951,  1.4819,  0.2887,  1.6380,  1.7087],
        [ 1.2250,  1.2611,  1.3268,  1.3038,  1.2694,  1.2320,  1.1990,  1.2224,
          1.2224,  1.1907,  1.3244,  1.2137,  1.3658,  1.2743,  1.4168,  1.1992,
          1.2613,  1.2643,  1.2842,  1.2847,  1.3335,  1.3006,  1.2489,  1.2425,
          1.1518,  1.2326,  1.2326,  1.2998,  1.3434,  1.2519,  1.0393,  1.2547,
          1.1324,  1.3059,  1.1259,  1.2554,  1.3048,  1.0118,  1.3109,  1.3208,
          0.8609,  0.7855,  1.3266,  1.1912,  0.6524,  3.5009,  2.5663,  3.6816,
          2.8753,  2.1450,  1.8176,  3.0077,  3.4121,  1.7949]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 292 : 179.41775531786624
Test loss for epoch 292 : 179.65538121800537
Test Precision for epoch 292 : 0.26153846153846155
Test Recall for epoch 292 : 0.26153846153846155
Test F1 for epoch 292 : 0.26153846153846155


theta for epoch 293 : tensor([[ 2.7027,  2.7345,  2.8096,  2.9483,  2.9114,  2.7090,  2.8862,  2.7009,
          2.7009,  1.2370,  1.2667,  1.2538,  1.2969,  1.2304,  1.3352,  1.2433,
          1.2206,  1.2448,  1.2120,  1.1901,  1.2036,  1.2241,  1.1861,  1.1814,
          1.2011,  1.1741,  1.1741,  1.2198,  1.2637,  1.1957,  1.2187,  1.2648,
          1.2055,  1.2359,  1.1554,  1.1982,  1.3907,  1.4492,  1.4232,  1.4020,
          1.4260,  1.3714,  1.4058,  1.3116,  1.3577,  1.3158,  1.2625,  1.2484,
          1.2284,  1.3084,  1.2496,  1.3497,  1.2154,  1.2261],
        [ 1.2044,  1.2270,  1.2005,  1.2286,  1.2573,  1.2249,  1.2120,  1.2165,
          1.2165,  2.0598,  2.0604,  1.9985,  2.2219,  2.0114,  5.3730,  2.0595,
          2.0169,  5.1676,  1.2126,  1.2537,  1.2244,  1.1929,  1.2430,  1.2372,
          1.2295,  1.2284,  1.2284,  1.2821,  1.1824,  1.2480,  1.2753,  1.2223,
          1.2599,  1.2960,  1.2086,  1.2511,  1.3590,  1.4331,  1.3395,  1.3444,
          1.4031,  1.4127,  1.3177,  1.0568,  1.3141,  1.2847,  1.3057,  1.2877,
          1.2633,  1.2216,  1.2901,  1.2871,  1.2474,  1.2613],
        [ 1.1637,  1.1910,  1.2368,  1.2226,  1.1966,  1.1690,  1.1769,  1.1618,
          1.1618,  1.2372,  1.2678,  1.2545,  1.2989,  1.2304,  1.2944,  1.2437,
          1.1774,  1.2918,  2.7505,  2.9215,  2.9460,  2.7776,  2.7089,  2.7127,
          2.8718,  2.6954,  2.6954,  1.2216,  1.2656,  1.1967,  1.2190,  1.2218,
          1.2068,  1.2380,  1.2012,  1.1993,  1.3818,  1.4420,  1.4136,  1.3324,
          1.4166,  1.4170,  1.3973,  1.2992,  1.2859,  1.3155,  1.2625,  1.2481,
          1.2276,  1.3085,  1.2494,  1.3513,  1.2083,  1.2252],
        [ 1.1734,  1.2009,  1.2467,  1.2330,  1.2067,  1.1786,  1.1868,  1.1714,
          1.1714,  1.2461,  1.2769,  1.2635,  1.3079,  1.2392,  1.2711,  1.2526,
          1.2284,  1.2262,  1.2240,  1.2413,  1.2606,  1.2366,  1.1971,  1.1922,
          1.2072,  1.1847,  1.1847,  3.0022,  2.9819,  2.5993,  2.7581,  2.9988,
          2.6102,  2.9477,  2.6071,  2.6021,  1.3860,  1.4470,  1.4192,  1.3908,
          1.4227,  1.4230,  1.4012,  1.2627,  1.3443,  1.3263,  1.2710,  1.1785,
          1.1884,  1.3187,  1.2576,  1.3616,  1.1702,  1.2333],
        [ 1.7339,  1.3536,  0.5778,  0.8638,  1.2396,  1.6549,  1.5478,  1.7569,
          1.7569,  1.5778,  1.2120,  1.4036,  0.8316,  1.6073,  0.1115,  1.5098,
          1.7453,  0.7840,  1.2544,  0.9204,  0.6956,  1.0884,  1.5938,  1.6570,
          1.4410,  1.7594,  1.7594,  0.7863,  0.8026,  1.7324,  1.5348,  0.8129,
          1.6745,  1.1641,  1.7842,  1.6979,  0.0742, -0.1595, -0.1869,  0.0269,
          0.2636,  0.3494, -0.0413, 16.8652,  4.4856,  0.6814,  1.2486,  1.3305,
          1.5482,  0.8941,  1.4823,  0.2888,  1.6392,  1.7089],
        [ 1.2247,  1.2610,  1.3268,  1.3037,  1.2692,  1.2317,  1.1988,  1.2221,
          1.2221,  1.1901,  1.3237,  1.2130,  1.3652,  1.2739,  1.4163,  1.1986,
          1.2603,  1.2641,  1.2842,  1.2838,  1.3336,  1.3007,  1.2489,  1.2425,
          1.1509,  1.2325,  1.2325,  1.2998,  1.3436,  1.2518,  1.0385,  1.2547,
          1.1323,  1.3059,  1.1259,  1.2554,  1.3033,  1.0106,  1.3085,  1.3191,
          0.8591,  0.7838,  1.3251,  1.1879,  0.6505,  3.5036,  2.5649,  3.6820,
          2.8739,  2.1438,  1.8164,  3.0066,  3.4147,  1.7936]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 293 : 179.3973767083648
Test loss for epoch 293 : 179.64081825675862
Test Precision for epoch 293 : 0.26153846153846155
Test Recall for epoch 293 : 0.26153846153846155
Test F1 for epoch 293 : 0.26153846153846155


theta for epoch 294 : tensor([[ 2.7028,  2.7346,  2.8098,  2.9486,  2.9117,  2.7091,  2.8864,  2.7009,
          2.7009,  1.2371,  1.2666,  1.2538,  1.2969,  1.2307,  1.3352,  1.2433,
          1.2205,  1.2450,  1.2119,  1.1899,  1.2034,  1.2240,  1.1859,  1.1813,
          1.2010,  1.1740,  1.1740,  1.2198,  1.2637,  1.1957,  1.2187,  1.2648,
          1.2056,  1.2360,  1.1554,  1.1983,  1.3912,  1.4497,  1.4237,  1.4022,
          1.4268,  1.3721,  1.4062,  1.3111,  1.3585,  1.3159,  1.2625,  1.2484,
          1.2283,  1.3086,  1.2496,  1.3499,  1.2152,  1.2260],
        [ 1.2048,  1.2283,  1.2048,  1.2288,  1.2558,  1.2235,  1.2120,  1.2151,
          1.2151,  2.0716,  2.0702,  2.0089,  2.2272,  2.0203,  5.3391,  2.0693,
          2.0317,  5.1327,  1.2117,  1.2513,  1.2226,  1.1939,  1.2411,  1.2355,
          1.2292,  1.2267,  1.2267,  1.2803,  1.1856,  1.2464,  1.2736,  1.2220,
          1.2583,  1.2944,  1.2070,  1.2495,  1.3588,  1.4328,  1.3393,  1.3462,
          1.4032,  1.4127,  1.3174,  1.0662,  1.3144,  1.2868,  1.3041,  1.2861,
          1.2617,  1.2240,  1.2884,  1.2890,  1.2457,  1.2596],
        [ 1.1643,  1.1915,  1.2370,  1.2231,  1.1970,  1.1695,  1.1774,  1.1623,
          1.1623,  1.2376,  1.2680,  1.2548,  1.2991,  1.2310,  1.2944,  1.2441,
          1.1774,  1.2923,  2.7497,  2.9221,  2.9457,  2.7762,  2.7084,  2.7117,
          2.8725,  2.6949,  2.6949,  1.2214,  1.2659,  1.1970,  1.2194,  1.2217,
          1.2071,  1.2383,  1.2015,  1.1997,  1.3826,  1.4429,  1.4145,  1.3324,
          1.4176,  1.4177,  1.3980,  1.2991,  1.2864,  1.3159,  1.2628,  1.2483,
          1.2277,  1.3089,  1.2496,  1.3517,  1.2081,  1.2254],
        [ 1.1736,  1.2012,  1.2466,  1.2332,  1.2069,  1.1789,  1.1871,  1.1716,
          1.1716,  1.2462,  1.2769,  1.2636,  1.3079,  1.2395,  1.2719,  1.2527,
          1.2283,  1.2273,  1.2238,  1.2408,  1.2604,  1.2364,  1.1969,  1.1921,
          1.2068,  1.1846,  1.1846,  3.0021,  2.9816,  2.5996,  2.7573,  2.9987,
          2.6105,  2.9472,  2.6074,  2.6024,  1.3864,  1.4476,  1.4198,  1.3907,
          1.4235,  1.4234,  1.4016,  1.2632,  1.3447,  1.3264,  1.2710,  1.1793,
          1.1883,  1.3189,  1.2576,  1.3618,  1.1696,  1.2332],
        [ 1.7334,  1.3531,  0.5767,  0.8642,  1.2407,  1.6560,  1.5479,  1.7580,
          1.7580,  1.5766,  1.2119,  1.4028,  0.8317,  1.6052,  0.1092,  1.5088,
          1.7465,  0.7809,  1.2542,  0.9219,  0.6963,  1.0874,  1.5946,  1.6578,
          1.4417,  1.7602,  1.7602,  0.7873,  0.8010,  1.7333,  1.5359,  0.8130,
          1.6754,  1.1647,  1.7851,  1.6988,  0.0722, -0.1613, -0.1891,  0.0253,
          0.2611,  0.3465, -0.0433, 16.9348,  4.4219,  0.6807,  1.2486,  1.3298,
          1.5480,  0.8926,  1.4822,  0.2883,  1.6400,  1.7086],
        [ 1.2250,  1.2613,  1.3272,  1.3040,  1.2695,  1.2319,  1.1990,  1.2223,
          1.2223,  1.1902,  1.3237,  1.2132,  1.3654,  1.2742,  1.4165,  1.1988,
          1.2600,  1.2647,  1.2840,  1.2827,  1.3335,  1.3006,  1.2486,  1.2422,
          1.1498,  1.2322,  1.2322,  1.2999,  1.3438,  1.2517,  1.0378,  1.2548,
          1.1322,  1.3060,  1.1258,  1.2553,  1.3020,  1.0098,  1.3064,  1.3176,
          0.8576,  0.7825,  1.3239,  1.1849,  0.6489,  3.5058,  2.5630,  3.6818,
          2.8720,  2.1421,  1.8147,  3.0050,  3.4167,  1.7918]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 294 : 179.37677169998815
Test loss for epoch 294 : 179.6267939776956
Test Precision for epoch 294 : 0.26153846153846155
Test Recall for epoch 294 : 0.26153846153846155
Test F1 for epoch 294 : 0.26153846153846155


theta for epoch 295 : tensor([[ 2.7025,  2.7343,  2.8095,  2.9484,  2.9115,  2.7088,  2.8863,  2.7006,
          2.7006,  1.2376,  1.2670,  1.2543,  1.2973,  1.2314,  1.3356,  1.2439,
          1.2208,  1.2458,  1.2120,  1.1900,  1.2036,  1.2242,  1.1861,  1.1815,
          1.2011,  1.1742,  1.1742,  1.2197,  1.2637,  1.1957,  1.2187,  1.2647,
          1.2056,  1.2360,  1.1554,  1.1983,  1.3916,  1.4502,  1.4243,  1.4025,
          1.4275,  1.3729,  1.4066,  1.3105,  1.3592,  1.3162,  1.2627,  1.2486,
          1.2285,  1.3090,  1.2498,  1.3503,  1.2152,  1.2262],
        [ 1.2047,  1.2290,  1.2087,  1.2284,  1.2538,  1.2215,  1.2115,  1.2131,
          1.2131,  2.0836,  2.0805,  2.0196,  2.2333,  2.0293,  5.3051,  2.0796,
          2.0470,  5.0978,  1.2111,  1.2491,  1.2209,  1.1953,  1.2393,  1.2339,
          1.2292,  1.2251,  1.2251,  1.2782,  1.1886,  1.2445,  1.2716,  1.2215,
          1.2565,  1.2925,  1.2052,  1.2476,  1.3584,  1.4324,  1.3390,  1.3478,
          1.4030,  1.4126,  1.3169,  1.0756,  1.3144,  1.2888,  1.3025,  1.2846,
          1.2601,  1.2263,  1.2868,  1.2907,  1.2439,  1.2580],
        [ 1.1644,  1.1916,  1.2368,  1.2230,  1.1970,  1.1695,  1.1774,  1.1623,
          1.1623,  1.2383,  1.2686,  1.2555,  1.2997,  1.2319,  1.2948,  1.2448,
          1.1777,  1.2932,  2.7490,  2.9229,  2.9457,  2.7750,  2.7081,  2.7109,
          2.8734,  2.6946,  2.6946,  1.2210,  1.2660,  1.1971,  1.2194,  1.2212,
          1.2072,  1.2384,  1.2016,  1.1997,  1.3833,  1.4436,  1.4153,  1.3323,
          1.4185,  1.4183,  1.3987,  1.2989,  1.2867,  1.3162,  1.2630,  1.2486,
          1.2280,  1.3093,  1.2498,  1.3521,  1.2078,  1.2256],
        [ 1.1735,  1.2011,  1.2462,  1.2330,  1.2068,  1.1787,  1.1869,  1.1715,
          1.1715,  1.2467,  1.2772,  1.2641,  1.3082,  1.2402,  1.2730,  1.2532,
          1.2286,  1.2287,  1.2239,  1.2405,  1.2604,  1.2365,  1.1970,  1.1922,
          1.2066,  1.1847,  1.1847,  3.0018,  2.9811,  2.5998,  2.7564,  2.9985,
          2.6107,  2.9465,  2.6076,  2.6026,  1.3869,  1.4481,  1.4204,  1.3906,
          1.4242,  1.4238,  1.4020,  1.2637,  1.3451,  1.3266,  1.2711,  1.1802,
          1.1883,  1.3191,  1.2577,  1.3621,  1.1692,  1.2333],
        [ 1.7326,  1.3523,  0.5753,  0.8643,  1.2416,  1.6568,  1.5475,  1.7587,
          1.7587,  1.5757,  1.2122,  1.4024,  0.8322,  1.6037,  0.1073,  1.5081,
          1.7480,  0.7783,  1.2543,  0.9236,  0.6972,  1.0866,  1.5958,  1.6588,
          1.4427,  1.7612,  1.7612,  0.7882,  0.7994,  1.7341,  1.5369,  0.8129,
          1.6763,  1.1651,  1.7859,  1.6996,  0.0701, -0.1631, -0.1912,  0.0236,
          0.2585,  0.3435, -0.0453, 17.0047,  4.3576,  0.6802,  1.2487,  1.3293,
          1.5479,  0.8914,  1.4823,  0.2882,  1.6410,  1.7085],
        [ 1.2248,  1.2611,  1.3271,  1.3039,  1.2693,  1.2316,  1.1988,  1.2220,
          1.2220,  1.1907,  1.3241,  1.2137,  1.3659,  1.2749,  1.4171,  1.1993,
          1.2601,  1.2656,  1.2841,  1.2819,  1.3336,  1.3007,  1.2486,  1.2422,
          1.1490,  1.2322,  1.2322,  1.2997,  1.3437,  1.2514,  1.0369,  1.2547,
          1.1320,  1.3058,  1.1255,  1.2550,  1.3007,  1.0090,  1.3043,  1.3160,
          0.8561,  0.7811,  1.3226,  1.1817,  0.6473,  3.5080,  2.5610,  3.6815,
          2.8701,  2.1405,  1.8130,  3.0034,  3.4189,  1.7901]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 295 : 179.35602221840062
Test loss for epoch 295 : 179.61250429113852
Test Precision for epoch 295 : 0.26153846153846155
Test Recall for epoch 295 : 0.26153846153846155
Test F1 for epoch 295 : 0.26153846153846155


theta for epoch 296 : tensor([[ 2.7022,  2.7341,  2.8093,  2.9483,  2.9114,  2.7085,  2.8862,  2.7003,
          2.7003,  1.2374,  1.2667,  1.2541,  1.2971,  1.2314,  1.3353,  1.2437,
          1.2204,  1.2458,  1.2125,  1.1904,  1.2039,  1.2246,  1.1865,  1.1819,
          1.2015,  1.1747,  1.1747,  1.2198,  1.2640,  1.1959,  1.2189,  1.2649,
          1.2057,  1.2361,  1.1556,  1.1985,  1.3920,  1.4507,  1.4249,  1.4027,
          1.4281,  1.3735,  1.4070,  1.3099,  1.3599,  1.3167,  1.2630,  1.2489,
          1.2288,  1.3095,  1.2501,  1.3509,  1.2154,  1.2265],
        [ 1.2047,  1.2298,  1.2128,  1.2284,  1.2519,  1.2198,  1.2113,  1.2114,
          1.2114,  2.0946,  2.0900,  2.0294,  2.2390,  2.0375,  5.2702,  2.0889,
          2.0614,  5.0618,  1.2110,  1.2475,  1.2196,  1.1973,  1.2380,  1.2329,
          1.2298,  1.2241,  1.2241,  1.2767,  1.1922,  1.2432,  1.2701,  1.2216,
          1.2551,  1.2911,  1.2039,  1.2463,  1.3581,  1.4320,  1.3388,  1.3495,
          1.4030,  1.4125,  1.3165,  1.0850,  1.3146,  1.2911,  1.3013,  1.2835,
          1.2589,  1.2290,  1.2856,  1.2928,  1.2427,  1.2568],
        [ 1.1643,  1.1914,  1.2363,  1.2228,  1.1968,  1.1693,  1.1773,  1.1622,
          1.1622,  1.2383,  1.2683,  1.2554,  1.2994,  1.2320,  1.2943,  1.2447,
          1.1772,  1.2933,  2.7487,  2.9241,  2.9460,  2.7742,  2.7081,  2.7105,
          2.8746,  2.6946,  2.6946,  1.2206,  1.2662,  1.1973,  1.2196,  1.2209,
          1.2074,  1.2385,  1.2018,  1.1999,  1.3838,  1.4442,  1.4159,  1.3320,
          1.4193,  1.4187,  1.3992,  1.2985,  1.2869,  1.3167,  1.2634,  1.2489,
          1.2283,  1.3098,  1.2501,  1.3526,  1.2077,  1.2259],
        [ 1.1733,  1.2008,  1.2456,  1.2327,  1.2065,  1.1785,  1.1867,  1.1712,
          1.1712,  1.2465,  1.2769,  1.2638,  1.3078,  1.2402,  1.2736,  1.2530,
          1.2281,  1.2296,  1.2242,  1.2404,  1.2607,  1.2369,  1.1974,  1.1926,
          1.2066,  1.1851,  1.1851,  3.0017,  2.9807,  2.6001,  2.7556,  2.9984,
          2.6111,  2.9459,  2.6080,  2.6030,  1.3872,  1.4485,  1.4208,  1.3904,
          1.4248,  1.4241,  1.4023,  1.2641,  1.3453,  1.3270,  1.2714,  1.1813,
          1.1884,  1.3195,  1.2579,  1.3625,  1.1688,  1.2335],
        [ 1.7318,  1.3516,  0.5741,  0.8643,  1.2423,  1.6574,  1.5471,  1.7593,
          1.7593,  1.5740,  1.2119,  1.4013,  0.8322,  1.6015,  0.1051,  1.5069,
          1.7488,  0.7752,  1.2546,  0.9256,  0.6984,  1.0861,  1.5972,  1.6602,
          1.4439,  1.7625,  1.7625,  0.7893,  0.7981,  1.7351,  1.5380,  0.8131,
          1.6773,  1.1658,  1.7869,  1.7007,  0.0679, -0.1650, -0.1934,  0.0218,
          0.2558,  0.3405, -0.0473, 17.0749,  4.2927,  0.6801,  1.2492,  1.3291,
          1.5482,  0.8905,  1.4826,  0.2884,  1.6423,  1.7088],
        [ 1.2245,  1.2609,  1.3269,  1.3037,  1.2690,  1.2312,  1.1985,  1.2216,
          1.2216,  1.1904,  1.3237,  1.2134,  1.3656,  1.2748,  1.4170,  1.1990,
          1.2593,  1.2659,  1.2844,  1.2813,  1.3339,  1.3011,  1.2488,  1.2424,
          1.1484,  1.2324,  1.2324,  1.2998,  1.3439,  1.2513,  1.0362,  1.2548,
          1.1319,  1.3058,  1.1255,  1.2549,  1.2993,  1.0080,  1.3021,  1.3143,
          0.8545,  0.7797,  1.3212,  1.1784,  0.6457,  3.5104,  2.5593,  3.6814,
          2.8684,  2.1391,  1.8116,  3.0019,  3.4212,  1.7887]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 296 : 179.3350696694996
Test loss for epoch 296 : 179.59804737153448
Test Precision for epoch 296 : 0.26153846153846155
Test Recall for epoch 296 : 0.26153846153846155
Test F1 for epoch 296 : 0.26153846153846155


theta for epoch 297 : tensor([[ 2.7022,  2.7342,  2.8094,  2.9485,  2.9116,  2.7085,  2.8864,  2.7003,
          2.7003,  1.2373,  1.2664,  1.2540,  1.2968,  1.2315,  1.3351,  1.2436,
          1.2200,  1.2460,  1.2124,  1.1902,  1.2038,  1.2246,  1.1865,  1.1818,
          1.2014,  1.1746,  1.1746,  1.2199,  1.2641,  1.1960,  1.2190,  1.2650,
          1.2058,  1.2362,  1.1557,  1.1986,  1.3923,  1.4511,  1.4254,  1.4028,
          1.4287,  1.3742,  1.4073,  1.3093,  1.3605,  1.3168,  1.2631,  1.2490,
          1.2288,  1.3097,  1.2501,  1.3511,  1.2152,  1.2265],
        [ 1.2049,  1.2307,  1.2172,  1.2287,  1.2505,  1.2183,  1.2114,  1.2100,
          1.2100,  2.1056,  2.0998,  2.0392,  2.2451,  2.0456,  5.2351,  2.0984,
          2.0761,  5.0257,  1.2105,  1.2455,  1.2179,  1.1990,  1.2363,  1.2314,
          1.2300,  1.2227,  1.2227,  1.2753,  1.1957,  1.2419,  1.2688,  1.2219,
          1.2538,  1.2898,  1.2026,  1.2450,  1.3578,  1.4317,  1.3386,  1.3512,
          1.4030,  1.4125,  1.3161,  1.0944,  1.3148,  1.2931,  1.2999,  1.2821,
          1.2576,  1.2315,  1.2842,  1.2945,  1.2411,  1.2554],
        [ 1.1646,  1.1917,  1.2362,  1.2231,  1.1971,  1.1696,  1.1776,  1.1625,
          1.1625,  1.2385,  1.2684,  1.2555,  1.2995,  1.2324,  1.2942,  1.2449,
          1.1769,  1.2936,  2.7480,  2.9249,  2.9459,  2.7730,  2.7077,  2.7096,
          2.8755,  2.6942,  2.6942,  1.2205,  1.2666,  1.1977,  1.2200,  1.2208,
          1.2078,  1.2389,  1.2022,  1.2003,  1.3845,  1.4450,  1.4168,  1.3319,
          1.4202,  1.4193,  1.3999,  1.2982,  1.2874,  1.3170,  1.2636,  1.2492,
          1.2285,  1.3102,  1.2504,  1.3530,  1.2074,  1.2261],
        [ 1.1735,  1.2009,  1.2454,  1.2328,  1.2065,  1.1786,  1.1868,  1.1713,
          1.1713,  1.2465,  1.2767,  1.2638,  1.3077,  1.2404,  1.2744,  1.2530,
          1.2279,  1.2307,  1.2242,  1.2400,  1.2606,  1.2369,  1.1973,  1.1926,
          1.2062,  1.1851,  1.1851,  3.0015,  2.9802,  2.6004,  2.7547,  2.9982,
          2.6114,  2.9452,  2.6084,  2.6033,  1.3877,  1.4490,  1.4214,  1.3902,
          1.4255,  1.4244,  1.4027,  1.2647,  1.3457,  1.3272,  1.2715,  1.1823,
          1.1884,  1.3198,  1.2580,  1.3628,  1.1683,  1.2335],
        [ 1.7314,  1.3512,  0.5731,  0.8646,  1.2434,  1.6584,  1.5469,  1.7603,
          1.7603,  1.5724,  1.2116,  1.4004,  0.8325,  1.5996,  0.1030,  1.5057,
          1.7497,  0.7725,  1.2545,  0.9271,  0.6992,  1.0850,  1.5980,  1.6611,
          1.4445,  1.7634,  1.7634,  0.7903,  0.7967,  1.7362,  1.5390,  0.8132,
          1.6784,  1.1664,  1.7880,  1.7017,  0.0659, -0.1668, -0.1955,  0.0201,
          0.2533,  0.3375, -0.0492, 17.1455,  4.2273,  0.6797,  1.2493,  1.3285,
          1.5481,  0.8894,  1.4827,  0.2884,  1.6432,  1.7087],
        [ 1.2246,  1.2610,  1.3272,  1.3039,  1.2691,  1.2313,  1.1986,  1.2217,
          1.2217,  1.1904,  1.3235,  1.2134,  1.3656,  1.2750,  1.4172,  1.1990,
          1.2589,  1.2664,  1.2843,  1.2805,  1.3339,  1.3011,  1.2486,  1.2423,
          1.1476,  1.2323,  1.2323,  1.3000,  1.3442,  1.2514,  1.0357,  1.2550,
          1.1320,  1.3060,  1.1256,  1.2549,  1.2981,  1.0073,  1.3002,  1.3129,
          0.8531,  0.7785,  1.3201,  1.1752,  0.6443,  3.5126,  2.5573,  3.6809,
          2.8664,  2.1374,  1.8099,  3.0001,  3.4233,  1.7869]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 297 : 179.3139950167892
Test loss for epoch 297 : 179.58398840414884
Test Precision for epoch 297 : 0.26153846153846155
Test Recall for epoch 297 : 0.26153846153846155
Test F1 for epoch 297 : 0.26153846153846155


theta for epoch 298 : tensor([[ 2.7020,  2.7340,  2.8092,  2.9485,  2.9115,  2.7083,  2.8864,  2.7001,
          2.7001,  1.2379,  1.2668,  1.2544,  1.2972,  1.2321,  1.3355,  1.2441,
          1.2202,  1.2467,  1.2123,  1.1901,  1.2037,  1.2245,  1.1864,  1.1818,
          1.2013,  1.1745,  1.1745,  1.2198,  1.2641,  1.1960,  1.2191,  1.2649,
          1.2058,  1.2362,  1.1557,  1.1985,  1.3928,  1.4516,  1.4260,  1.4031,
          1.4294,  1.3749,  1.4077,  1.3086,  1.3612,  1.3170,  1.2632,  1.2491,
          1.2288,  1.3099,  1.2502,  1.3514,  1.2151,  1.2265],
        [ 1.2048,  1.2311,  1.2212,  1.2287,  1.2487,  1.2166,  1.2112,  1.2082,
          1.2082,  2.1171,  2.1104,  2.0496,  2.2524,  2.0543,  5.2003,  2.1085,
          2.0915,  4.9900,  1.2098,  1.2434,  1.2159,  1.2006,  1.2344,  1.2296,
          1.2300,  1.2209,  1.2209,  1.2734,  1.1987,  1.2402,  1.2670,  1.2218,
          1.2521,  1.2880,  1.2009,  1.2433,  1.3574,  1.4312,  1.3382,  1.3526,
          1.4028,  1.4123,  1.3156,  1.1035,  1.3147,  1.2947,  1.2982,  1.2805,
          1.2560,  1.2336,  1.2825,  1.2958,  1.2394,  1.2537],
        [ 1.1648,  1.1919,  1.2360,  1.2232,  1.1972,  1.1698,  1.1777,  1.1626,
          1.1626,  1.2392,  1.2689,  1.2562,  1.3000,  1.2333,  1.2946,  1.2456,
          1.1772,  1.2945,  2.7472,  2.9257,  2.9458,  2.7718,  2.7072,  2.7087,
          2.8763,  2.6937,  2.6937,  1.2201,  1.2667,  1.1978,  1.2201,  1.2204,
          1.2079,  1.2390,  1.2023,  1.2004,  1.3853,  1.4457,  1.4176,  1.3319,
          1.4211,  1.4199,  1.4006,  1.2979,  1.2878,  1.3173,  1.2639,  1.2494,
          1.2287,  1.3106,  1.2506,  1.3534,  1.2071,  1.2263],
        [ 1.1736,  1.2010,  1.2451,  1.2328,  1.2066,  1.1786,  1.1869,  1.1714,
          1.1714,  1.2471,  1.2772,  1.2643,  1.3081,  1.2412,  1.2758,  1.2536,
          1.2282,  1.2324,  1.2242,  1.2395,  1.2605,  1.2368,  1.1973,  1.1925,
          1.2058,  1.1850,  1.1850,  3.0010,  2.9794,  2.6005,  2.7535,  2.9978,
          2.6115,  2.9443,  2.6085,  2.6034,  1.3882,  1.4496,  1.4220,  1.3901,
          1.4263,  1.4248,  1.4031,  1.2653,  1.3460,  1.3274,  1.2716,  1.1833,
          1.1885,  1.3201,  1.2581,  1.3631,  1.1679,  1.2336],
        [ 1.7310,  1.3509,  0.5723,  0.8648,  1.2443,  1.6593,  1.5467,  1.7611,
          1.7611,  1.5714,  1.2119,  1.4001,  0.8334,  1.5984,  0.1017,  1.5052,
          1.7511,  0.7707,  1.2544,  0.9286,  0.7000,  1.0840,  1.5989,  1.6619,
          1.4451,  1.7642,  1.7642,  0.7912,  0.7955,  1.7371,  1.5398,  0.8133,
          1.6793,  1.1669,  1.7889,  1.7026,  0.0637, -0.1687, -0.1977,  0.0182,
          0.2507,  0.3345, -0.0513, 17.2163,  4.1613,  0.6795,  1.2495,  1.3280,
          1.5481,  0.8885,  1.4828,  0.2887,  1.6442,  1.7087],
        [ 1.2245,  1.2610,  1.3272,  1.3039,  1.2690,  1.2312,  1.1985,  1.2215,
          1.2215,  1.1909,  1.3239,  1.2139,  1.3661,  1.2757,  1.4178,  1.1995,
          1.2589,  1.2674,  1.2842,  1.2795,  1.3338,  1.3010,  1.2483,  1.2420,
          1.1466,  1.2320,  1.2320,  1.2999,  1.3442,  1.2511,  1.0349,  1.2549,
          1.1318,  1.3059,  1.1253,  1.2547,  1.2969,  1.0064,  1.2983,  1.3114,
          0.8518,  0.7773,  1.3189,  1.1719,  0.6428,  3.5149,  2.5554,  3.6804,
          2.8644,  2.1359,  1.8083,  2.9985,  3.4255,  1.7853]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 298 : 179.292805891636
Test loss for epoch 298 : 179.56959818429848
Test Precision for epoch 298 : 0.26153846153846155
Test Recall for epoch 298 : 0.26153846153846155
Test F1 for epoch 298 : 0.26153846153846155


theta for epoch 299 : tensor([[ 2.7015e+00,  2.7335e+00,  2.8088e+00,  2.9481e+00,  2.9112e+00,
          2.7078e+00,  2.8860e+00,  2.6996e+00,  2.6996e+00,  1.2379e+00,
          1.2667e+00,  1.2544e+00,  1.2971e+00,  1.2323e+00,  1.3355e+00,
          1.2441e+00,  1.2200e+00,  1.2470e+00,  1.2127e+00,  1.1904e+00,
          1.2040e+00,  1.2249e+00,  1.1868e+00,  1.1822e+00,  1.2017e+00,
          1.1749e+00,  1.1749e+00,  1.2200e+00,  1.2644e+00,  1.1963e+00,
          1.2194e+00,  1.2652e+00,  1.2061e+00,  1.2365e+00,  1.1560e+00,
          1.1988e+00,  1.3934e+00,  1.4522e+00,  1.4267e+00,  1.4035e+00,
          1.4302e+00,  1.3757e+00,  1.4083e+00,  1.3081e+00,  1.3620e+00,
          1.3174e+00,  1.2635e+00,  1.2494e+00,  1.2291e+00,  1.3104e+00,
          1.2505e+00,  1.3519e+00,  1.2153e+00,  1.2268e+00],
        [ 1.2045e+00,  1.2314e+00,  1.2251e+00,  1.2287e+00,  1.2470e+00,
          1.2148e+00,  1.2111e+00,  1.2065e+00,  1.2065e+00,  2.1278e+00,
          2.1204e+00,  2.0593e+00,  2.2594e+00,  2.0624e+00,  5.1648e+00,
          2.1180e+00,  2.1064e+00,  4.9536e+00,  1.2097e+00,  1.2419e+00,
          1.2144e+00,  1.2027e+00,  1.2331e+00,  1.2284e+00,  1.2306e+00,
          1.2197e+00,  1.2197e+00,  1.2720e+00,  1.2018e+00,  1.2388e+00,
          1.2656e+00,  1.2222e+00,  1.2507e+00,  1.2866e+00,  1.1995e+00,
          1.2419e+00,  1.3571e+00,  1.4308e+00,  1.3380e+00,  1.3541e+00,
          1.4027e+00,  1.4123e+00,  1.3152e+00,  1.1125e+00,  1.3148e+00,
          1.2964e+00,  1.2969e+00,  1.2793e+00,  1.2546e+00,  1.2358e+00,
          1.2812e+00,  1.2972e+00,  1.2379e+00,  1.2524e+00],
        [ 1.1647e+00,  1.1918e+00,  1.2356e+00,  1.2230e+00,  1.1970e+00,
          1.1696e+00,  1.1776e+00,  1.1625e+00,  1.1625e+00,  1.2392e+00,
          1.2687e+00,  1.2561e+00,  1.2998e+00,  1.2335e+00,  1.2943e+00,
          1.2456e+00,  1.1768e+00,  1.2947e+00,  2.7469e+00,  2.9268e+00,
          2.9460e+00,  2.7709e+00,  2.7071e+00,  2.7081e+00,  2.8775e+00,
          2.6935e+00,  2.6935e+00,  1.2197e+00,  1.2668e+00,  1.1980e+00,
          1.2203e+00,  1.2201e+00,  1.2081e+00,  1.2392e+00,  1.2025e+00,
          1.2006e+00,  1.3860e+00,  1.4465e+00,  1.4184e+00,  1.3318e+00,
          1.4220e+00,  1.4204e+00,  1.4013e+00,  1.2976e+00,  1.2881e+00,
          1.3176e+00,  1.2641e+00,  1.2496e+00,  1.2288e+00,  1.3109e+00,
          1.2508e+00,  1.3537e+00,  1.2068e+00,  1.2264e+00],
        [ 1.1735e+00,  1.2009e+00,  1.2446e+00,  1.2327e+00,  1.2064e+00,
          1.1785e+00,  1.1867e+00,  1.1713e+00,  1.1713e+00,  1.2471e+00,
          1.2770e+00,  1.2643e+00,  1.3078e+00,  1.2413e+00,  1.2766e+00,
          1.2536e+00,  1.2279e+00,  1.2335e+00,  1.2245e+00,  1.2393e+00,
          1.2607e+00,  1.2371e+00,  1.1976e+00,  1.1928e+00,  1.2057e+00,
          1.1853e+00,  1.1853e+00,  3.0007e+00,  2.9787e+00,  2.6007e+00,
          2.7524e+00,  2.9974e+00,  2.6117e+00,  2.9434e+00,  2.6088e+00,
          2.6036e+00,  1.3887e+00,  1.4502e+00,  1.4226e+00,  1.3899e+00,
          1.4270e+00,  1.4251e+00,  1.4035e+00,  1.2660e+00,  1.3464e+00,
          1.3277e+00,  1.2718e+00,  1.1844e+00,  1.1886e+00,  1.3204e+00,
          1.2583e+00,  1.3634e+00,  1.1675e+00,  1.2337e+00],
        [ 1.7305e+00,  1.3505e+00,  5.7136e-01,  8.6485e-01,  1.2450e+00,
          1.6600e+00,  1.5462e+00,  1.7618e+00,  1.7618e+00,  1.5697e+00,
          1.2115e+00,  1.3993e+00,  8.3379e-01,  1.5968e+00,  1.0005e-01,
          1.5042e+00,  1.7518e+00,  7.6845e-01,  1.2547e+00,  9.3035e-01,
          7.0110e-01,  1.0833e+00,  1.6000e+00,  1.6631e+00,  1.4460e+00,
          1.7654e+00,  1.7654e+00,  7.9216e-01,  7.9430e-01,  1.7380e+00,
          1.5406e+00,  8.1336e-01,  1.6803e+00,  1.1673e+00,  1.7898e+00,
          1.7036e+00,  6.1754e-02, -1.7041e-01, -1.9966e-01,  1.6505e-02,
          2.4829e-01,  3.3160e-01, -5.3163e-02,  1.7288e+01,  4.0950e+00,
          6.7937e-01,  1.2497e+00,  1.3276e+00,  1.5482e+00,  8.8769e-01,
          1.4830e+00,  2.8898e-01,  1.6453e+00,  1.7087e+00],
        [ 1.2242e+00,  1.2607e+00,  1.3271e+00,  1.3037e+00,  1.2687e+00,
          1.2308e+00,  1.1982e+00,  1.2212e+00,  1.2212e+00,  1.1908e+00,
          1.3236e+00,  1.2137e+00,  1.3659e+00,  1.2757e+00,  1.4178e+00,
          1.1993e+00,  1.2582e+00,  1.2677e+00,  1.2844e+00,  1.2789e+00,
          1.3340e+00,  1.3013e+00,  1.2484e+00,  1.2421e+00,  1.1460e+00,
          1.2320e+00,  1.2320e+00,  1.2999e+00,  1.3444e+00,  1.2510e+00,
          1.0343e+00,  1.2550e+00,  1.1318e+00,  1.3059e+00,  1.1253e+00,
          1.2546e+00,  1.2957e+00,  1.0057e+00,  1.2965e+00,  1.3100e+00,
          8.5047e-01,  7.7619e-01,  1.3178e+00,  1.1686e+00,  6.4149e-01,
          3.5174e+00,  2.5536e+00,  3.6800e+00,  2.8626e+00,  2.1345e+00,
          1.8069e+00,  2.9969e+00,  3.4278e+00,  1.7839e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 299 : 179.2714881857263
Test loss for epoch 299 : 179.5552600912331
Test Precision for epoch 299 : 0.26153846153846155
Test Recall for epoch 299 : 0.26153846153846155
Test F1 for epoch 299 : 0.26153846153846155


theta for epoch 300 : tensor([[ 2.7013e+00,  2.7333e+00,  2.8085e+00,  2.9480e+00,  2.9110e+00,
          2.7075e+00,  2.8859e+00,  2.6993e+00,  2.6993e+00,  1.2377e+00,
          1.2663e+00,  1.2542e+00,  1.2967e+00,  1.2323e+00,  1.3352e+00,
          1.2439e+00,  1.2195e+00,  1.2470e+00,  1.2129e+00,  1.1906e+00,
          1.2042e+00,  1.2252e+00,  1.1870e+00,  1.1824e+00,  1.2019e+00,
          1.1751e+00,  1.1751e+00,  1.2202e+00,  1.2647e+00,  1.1965e+00,
          1.2196e+00,  1.2654e+00,  1.2064e+00,  1.2368e+00,  1.1562e+00,
          1.1991e+00,  1.3938e+00,  1.4528e+00,  1.4273e+00,  1.4038e+00,
          1.4308e+00,  1.3764e+00,  1.4087e+00,  1.3075e+00,  1.3628e+00,
          1.3177e+00,  1.2637e+00,  1.2496e+00,  1.2293e+00,  1.3107e+00,
          1.2507e+00,  1.3523e+00,  1.2153e+00,  1.2269e+00],
        [ 1.2044e+00,  1.2319e+00,  1.2291e+00,  1.2291e+00,  1.2456e+00,
          1.2135e+00,  1.2113e+00,  1.2051e+00,  1.2051e+00,  2.1382e+00,
          2.1304e+00,  2.0688e+00,  2.2667e+00,  2.0702e+00,  5.1291e+00,
          2.1273e+00,  2.1211e+00,  4.9169e+00,  1.2096e+00,  1.2405e+00,
          1.2129e+00,  1.2048e+00,  1.2317e+00,  1.2271e+00,  1.2311e+00,
          1.2184e+00,  1.2184e+00,  1.2708e+00,  1.2049e+00,  1.2376e+00,
          1.2644e+00,  1.2227e+00,  1.2494e+00,  1.2854e+00,  1.1983e+00,
          1.2406e+00,  1.3567e+00,  1.4304e+00,  1.3378e+00,  1.3555e+00,
          1.4026e+00,  1.4122e+00,  1.3148e+00,  1.1213e+00,  1.3149e+00,
          1.2978e+00,  1.2956e+00,  1.2780e+00,  1.2534e+00,  1.2379e+00,
          1.2799e+00,  1.2983e+00,  1.2365e+00,  1.2511e+00],
        [ 1.1650e+00,  1.1920e+00,  1.2354e+00,  1.2232e+00,  1.1972e+00,
          1.1699e+00,  1.1779e+00,  1.1627e+00,  1.1627e+00,  1.2392e+00,
          1.2685e+00,  1.2560e+00,  1.2995e+00,  1.2336e+00,  1.2940e+00,
          1.2455e+00,  1.1763e+00,  1.2948e+00,  2.7462e+00,  2.9277e+00,
          2.9460e+00,  2.7698e+00,  2.7067e+00,  2.7074e+00,  2.8784e+00,
          2.6931e+00,  2.6931e+00,  1.2195e+00,  1.2672e+00,  1.1983e+00,
          1.2207e+00,  1.2199e+00,  1.2084e+00,  1.2395e+00,  1.2029e+00,
          1.2010e+00,  1.3867e+00,  1.4473e+00,  1.4193e+00,  1.3317e+00,
          1.4230e+00,  1.4209e+00,  1.4020e+00,  1.2972e+00,  1.2885e+00,
          1.3180e+00,  1.2644e+00,  1.2500e+00,  1.2291e+00,  1.3113e+00,
          1.2510e+00,  1.3541e+00,  1.2065e+00,  1.2267e+00],
        [ 1.1736e+00,  1.2009e+00,  1.2442e+00,  1.2327e+00,  1.2064e+00,
          1.1785e+00,  1.1868e+00,  1.1713e+00,  1.1713e+00,  1.2469e+00,
          1.2766e+00,  1.2640e+00,  1.3074e+00,  1.2413e+00,  1.2772e+00,
          1.2533e+00,  1.2274e+00,  1.2345e+00,  1.2246e+00,  1.2390e+00,
          1.2608e+00,  1.2373e+00,  1.1977e+00,  1.1929e+00,  1.2054e+00,
          1.1855e+00,  1.1855e+00,  3.0004e+00,  2.9780e+00,  2.6011e+00,
          2.7513e+00,  2.9972e+00,  2.6121e+00,  2.9425e+00,  2.6092e+00,
          2.6039e+00,  1.3892e+00,  1.4507e+00,  1.4232e+00,  1.3897e+00,
          1.4277e+00,  1.4254e+00,  1.4039e+00,  1.2666e+00,  1.3467e+00,
          1.3278e+00,  1.2719e+00,  1.1855e+00,  1.1886e+00,  1.3206e+00,
          1.2584e+00,  1.3637e+00,  1.1670e+00,  1.2338e+00],
        [ 1.7303e+00,  1.3504e+00,  5.7075e-01,  8.6504e-01,  1.2459e+00,
          1.6609e+00,  1.5459e+00,  1.7627e+00,  1.7627e+00,  1.5679e+00,
          1.2110e+00,  1.3984e+00,  8.3411e-01,  1.5952e+00,  9.8466e-02,
          1.5030e+00,  1.7524e+00,  7.6632e-01,  1.2548e+00,  9.3189e-01,
          7.0199e-01,  1.0824e+00,  1.6009e+00,  1.6640e+00,  1.4466e+00,
          1.7664e+00,  1.7664e+00,  7.9306e-01,  7.9328e-01,  1.7390e+00,
          1.5413e+00,  8.1349e-01,  1.6813e+00,  1.1678e+00,  1.7908e+00,
          1.7045e+00,  5.9812e-02, -1.7209e-01, -2.0159e-01,  1.4766e-02,
          2.4592e-01,  3.2877e-01, -5.4997e-02,  1.7359e+01,  4.0282e+00,
          6.7916e-01,  1.2499e+00,  1.3270e+00,  1.5482e+00,  8.8688e-01,
          1.4831e+00,  2.8920e-01,  1.6463e+00,  1.7087e+00],
        [ 1.2243e+00,  1.2608e+00,  1.3273e+00,  1.3038e+00,  1.2688e+00,
          1.2308e+00,  1.1983e+00,  1.2211e+00,  1.2211e+00,  1.1905e+00,
          1.3232e+00,  1.2134e+00,  1.3655e+00,  1.2755e+00,  1.4177e+00,
          1.1991e+00,  1.2575e+00,  1.2679e+00,  1.2845e+00,  1.2783e+00,
          1.3342e+00,  1.3015e+00,  1.2485e+00,  1.2421e+00,  1.1454e+00,
          1.2320e+00,  1.2320e+00,  1.3000e+00,  1.3447e+00,  1.2510e+00,
          1.0339e+00,  1.2552e+00,  1.1318e+00,  1.3061e+00,  1.1253e+00,
          1.2546e+00,  1.2946e+00,  1.0050e+00,  1.2948e+00,  1.3086e+00,
          8.4927e-01,  7.7516e-01,  1.3167e+00,  1.1653e+00,  6.4025e-01,
          3.5197e+00,  2.5516e+00,  3.6794e+00,  2.8605e+00,  2.1329e+00,
          1.8054e+00,  2.9951e+00,  3.4300e+00,  1.7823e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 300 : 179.25014077661348
Test loss for epoch 300 : 179.54114452345422
Test Precision for epoch 300 : 0.26153846153846155
Test Recall for epoch 300 : 0.26153846153846155
Test F1 for epoch 300 : 0.26153846153846155


theta for epoch 301 : tensor([[ 2.7011e+00,  2.7332e+00,  2.8084e+00,  2.9479e+00,  2.9110e+00,
          2.7073e+00,  2.8858e+00,  2.6991e+00,  2.6991e+00,  1.2381e+00,
          1.2665e+00,  1.2545e+00,  1.2969e+00,  1.2327e+00,  1.3355e+00,
          1.2442e+00,  1.2196e+00,  1.2476e+00,  1.2129e+00,  1.1905e+00,
          1.2041e+00,  1.2251e+00,  1.1869e+00,  1.1823e+00,  1.2018e+00,
          1.1751e+00,  1.1751e+00,  1.2202e+00,  1.2647e+00,  1.1965e+00,
          1.2196e+00,  1.2654e+00,  1.2063e+00,  1.2367e+00,  1.1562e+00,
          1.1990e+00,  1.3942e+00,  1.4531e+00,  1.4277e+00,  1.4039e+00,
          1.4313e+00,  1.3770e+00,  1.4090e+00,  1.3067e+00,  1.3633e+00,
          1.3179e+00,  1.2639e+00,  1.2498e+00,  1.2294e+00,  1.3110e+00,
          1.2508e+00,  1.3526e+00,  1.2153e+00,  1.2270e+00],
        [ 1.2041e+00,  1.2321e+00,  1.2327e+00,  1.2293e+00,  1.2442e+00,
          1.2119e+00,  1.2114e+00,  1.2036e+00,  1.2036e+00,  2.1491e+00,
          2.1410e+00,  2.0789e+00,  2.2750e+00,  2.0786e+00,  5.0937e+00,
          2.1373e+00,  2.1365e+00,  4.8807e+00,  1.2092e+00,  1.2388e+00,
          1.2112e+00,  1.2065e+00,  1.2300e+00,  1.2254e+00,  1.2313e+00,
          1.2167e+00,  1.2167e+00,  1.2692e+00,  1.2074e+00,  1.2360e+00,
          1.2629e+00,  1.2230e+00,  1.2478e+00,  1.2837e+00,  1.1967e+00,
          1.2390e+00,  1.3561e+00,  1.4298e+00,  1.3372e+00,  1.3565e+00,
          1.4022e+00,  1.4118e+00,  1.3141e+00,  1.1295e+00,  1.3147e+00,
          1.2990e+00,  1.2942e+00,  1.2766e+00,  1.2519e+00,  1.2396e+00,
          1.2784e+00,  1.2992e+00,  1.2349e+00,  1.2496e+00],
        [ 1.1654e+00,  1.1923e+00,  1.2353e+00,  1.2235e+00,  1.1975e+00,
          1.1702e+00,  1.1782e+00,  1.1631e+00,  1.1631e+00,  1.2398e+00,
          1.2689e+00,  1.2566e+00,  1.2999e+00,  1.2343e+00,  1.2944e+00,
          1.2461e+00,  1.1765e+00,  1.2956e+00,  2.7453e+00,  2.9283e+00,
          2.9457e+00,  2.7685e+00,  2.7060e+00,  2.7063e+00,  2.8791e+00,
          2.6924e+00,  2.6924e+00,  1.2192e+00,  1.2674e+00,  1.1986e+00,
          1.2210e+00,  1.2196e+00,  1.2086e+00,  1.2397e+00,  1.2031e+00,
          1.2012e+00,  1.3875e+00,  1.4480e+00,  1.4201e+00,  1.3316e+00,
          1.4239e+00,  1.4214e+00,  1.4027e+00,  1.2969e+00,  1.2889e+00,
          1.3184e+00,  1.2648e+00,  1.2504e+00,  1.2295e+00,  1.3118e+00,
          1.2514e+00,  1.3546e+00,  1.2064e+00,  1.2271e+00],
        [ 1.1738e+00,  1.2010e+00,  1.2439e+00,  1.2327e+00,  1.2065e+00,
          1.1786e+00,  1.1869e+00,  1.1714e+00,  1.1714e+00,  1.2473e+00,
          1.2768e+00,  1.2643e+00,  1.3075e+00,  1.2418e+00,  1.2784e+00,
          1.2537e+00,  1.2274e+00,  1.2360e+00,  1.2245e+00,  1.2384e+00,
          1.2606e+00,  1.2372e+00,  1.1976e+00,  1.1929e+00,  1.2049e+00,
          1.1854e+00,  1.1854e+00,  2.9999e+00,  2.9771e+00,  2.6013e+00,
          2.7501e+00,  2.9967e+00,  2.6123e+00,  2.9415e+00,  2.6095e+00,
          2.6042e+00,  1.3895e+00,  1.4511e+00,  1.4236e+00,  1.3894e+00,
          1.4283e+00,  1.4255e+00,  1.4042e+00,  1.2671e+00,  1.3468e+00,
          1.3280e+00,  1.2721e+00,  1.1866e+00,  1.1887e+00,  1.3209e+00,
          1.2585e+00,  1.3640e+00,  1.1665e+00,  1.2339e+00],
        [ 1.7304e+00,  1.3505e+00,  5.7044e-01,  8.6536e-01,  1.2469e+00,
          1.6619e+00,  1.5457e+00,  1.7636e+00,  1.7636e+00,  1.5668e+00,
          1.2112e+00,  1.3982e+00,  8.3517e-01,  1.5944e+00,  9.7688e-02,
          1.5026e+00,  1.7535e+00,  7.6517e-01,  1.2549e+00,  9.3329e-01,
          7.0279e-01,  1.0815e+00,  1.6016e+00,  1.6648e+00,  1.4471e+00,
          1.7672e+00,  1.7672e+00,  7.9390e-01,  7.9235e-01,  1.7398e+00,
          1.5418e+00,  8.1360e-01,  1.6821e+00,  1.1681e+00,  1.7916e+00,
          1.7053e+00,  5.7743e-02, -1.7389e-01, -2.0362e-01,  1.2849e-02,
          2.4343e-01,  3.2580e-01, -5.6955e-02,  1.7431e+01,  3.9610e+00,
          6.7917e-01,  1.2501e+00,  1.3265e+00,  1.5483e+00,  8.8634e-01,
          1.4832e+00,  2.8968e-01,  1.6473e+00,  1.7088e+00],
        [ 1.2243e+00,  1.2609e+00,  1.3275e+00,  1.3040e+00,  1.2689e+00,
          1.2308e+00,  1.1983e+00,  1.2211e+00,  1.2211e+00,  1.1909e+00,
          1.3234e+00,  1.2138e+00,  1.3658e+00,  1.2760e+00,  1.4182e+00,
          1.1994e+00,  1.2574e+00,  1.2688e+00,  1.2845e+00,  1.2776e+00,
          1.3341e+00,  1.3014e+00,  1.2483e+00,  1.2419e+00,  1.1446e+00,
          1.2318e+00,  1.2318e+00,  1.3000e+00,  1.3447e+00,  1.2508e+00,
          1.0333e+00,  1.2552e+00,  1.1317e+00,  1.3060e+00,  1.1251e+00,
          1.2544e+00,  1.2934e+00,  1.0042e+00,  1.2930e+00,  1.3072e+00,
          8.4798e-01,  7.7405e-01,  1.3155e+00,  1.1619e+00,  6.3895e-01,
          3.5220e+00,  2.5497e+00,  3.6787e+00,  2.8585e+00,  2.1314e+00,
          1.8038e+00,  2.9934e+00,  3.4322e+00,  1.7808e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 301 : 179.2287123677662
Test loss for epoch 301 : 179.52675361389794
Test Precision for epoch 301 : 0.26153846153846155
Test Recall for epoch 301 : 0.26153846153846155
Test F1 for epoch 301 : 0.26153846153846155


theta for epoch 302 : tensor([[ 2.7007e+00,  2.7328e+00,  2.8080e+00,  2.9476e+00,  2.9106e+00,
          2.7068e+00,  2.8855e+00,  2.6986e+00,  2.6986e+00,  1.2383e+00,
          1.2665e+00,  1.2546e+00,  1.2969e+00,  1.2330e+00,  1.3356e+00,
          1.2443e+00,  1.2194e+00,  1.2480e+00,  1.2132e+00,  1.1907e+00,
          1.2043e+00,  1.2254e+00,  1.1871e+00,  1.1826e+00,  1.2020e+00,
          1.1754e+00,  1.1754e+00,  1.2202e+00,  1.2648e+00,  1.1966e+00,
          1.2198e+00,  1.2655e+00,  1.2064e+00,  1.2368e+00,  1.1563e+00,
          1.1991e+00,  1.3946e+00,  1.4537e+00,  1.4283e+00,  1.4043e+00,
          1.4320e+00,  1.3777e+00,  1.4095e+00,  1.3060e+00,  1.3641e+00,
          1.3182e+00,  1.2642e+00,  1.2501e+00,  1.2296e+00,  1.3114e+00,
          1.2511e+00,  1.3530e+00,  1.2154e+00,  1.2273e+00],
        [ 1.2035e+00,  1.2319e+00,  1.2361e+00,  1.2295e+00,  1.2426e+00,
          1.2104e+00,  1.2114e+00,  1.2020e+00,  1.2020e+00,  2.1594e+00,
          2.1513e+00,  2.0885e+00,  2.2833e+00,  2.0865e+00,  5.0579e+00,
          2.1468e+00,  2.1515e+00,  4.8440e+00,  1.2091e+00,  1.2376e+00,
          1.2098e+00,  1.2087e+00,  1.2287e+00,  1.2242e+00,  1.2320e+00,
          1.2155e+00,  1.2155e+00,  1.2679e+00,  1.2098e+00,  1.2346e+00,
          1.2616e+00,  1.2235e+00,  1.2464e+00,  1.2824e+00,  1.1954e+00,
          1.2377e+00,  1.3557e+00,  1.4294e+00,  1.3370e+00,  1.3577e+00,
          1.4020e+00,  1.4117e+00,  1.3137e+00,  1.1376e+00,  1.3148e+00,
          1.3001e+00,  1.2930e+00,  1.2755e+00,  1.2508e+00,  1.2414e+00,
          1.2772e+00,  1.2999e+00,  1.2336e+00,  1.2484e+00],
        [ 1.1654e+00,  1.1923e+00,  1.2349e+00,  1.2234e+00,  1.1975e+00,
          1.1702e+00,  1.1782e+00,  1.1631e+00,  1.1631e+00,  1.2401e+00,
          1.2690e+00,  1.2568e+00,  1.2999e+00,  1.2347e+00,  1.2944e+00,
          1.2463e+00,  1.1764e+00,  1.2960e+00,  2.7446e+00,  2.9292e+00,
          2.9456e+00,  2.7674e+00,  2.7056e+00,  2.7055e+00,  2.8800e+00,
          2.6920e+00,  2.6920e+00,  1.2188e+00,  1.2675e+00,  1.1988e+00,
          1.2212e+00,  1.2193e+00,  1.2088e+00,  1.2399e+00,  1.2033e+00,
          1.2014e+00,  1.3882e+00,  1.4488e+00,  1.4210e+00,  1.3316e+00,
          1.4248e+00,  1.4219e+00,  1.4035e+00,  1.2965e+00,  1.2893e+00,
          1.3188e+00,  1.2652e+00,  1.2508e+00,  1.2298e+00,  1.3123e+00,
          1.2518e+00,  1.3551e+00,  1.2062e+00,  1.2274e+00],
        [ 1.1737e+00,  1.2009e+00,  1.2433e+00,  1.2326e+00,  1.2063e+00,
          1.1785e+00,  1.1868e+00,  1.1713e+00,  1.1713e+00,  1.2474e+00,
          1.2767e+00,  1.2643e+00,  1.3074e+00,  1.2420e+00,  1.2794e+00,
          1.2537e+00,  1.2273e+00,  1.2372e+00,  1.2247e+00,  1.2381e+00,
          1.2608e+00,  1.2374e+00,  1.1978e+00,  1.1930e+00,  1.2047e+00,
          1.1856e+00,  1.1856e+00,  2.9995e+00,  2.9762e+00,  2.6016e+00,
          2.7488e+00,  2.9963e+00,  2.6126e+00,  2.9404e+00,  2.6098e+00,
          2.6045e+00,  1.3900e+00,  1.4516e+00,  1.4242e+00,  1.3892e+00,
          1.4289e+00,  1.4258e+00,  1.4046e+00,  1.2678e+00,  1.3471e+00,
          1.3283e+00,  1.2723e+00,  1.1878e+00,  1.1888e+00,  1.3211e+00,
          1.2587e+00,  1.3643e+00,  1.1660e+00,  1.2340e+00],
        [ 1.7302e+00,  1.3504e+00,  5.6994e-01,  8.6533e-01,  1.2475e+00,
          1.6625e+00,  1.5453e+00,  1.7642e+00,  1.7642e+00,  1.5653e+00,
          1.2110e+00,  1.3978e+00,  8.3586e-01,  1.5935e+00,  9.6720e-02,
          1.5018e+00,  1.7542e+00,  7.6383e-01,  1.2551e+00,  9.3477e-01,
          7.0365e-01,  1.0808e+00,  1.6025e+00,  1.6657e+00,  1.4477e+00,
          1.7681e+00,  1.7681e+00,  7.9460e-01,  7.9145e-01,  1.7405e+00,
          1.5423e+00,  8.1361e-01,  1.6828e+00,  1.1683e+00,  1.7924e+00,
          1.7061e+00,  5.5928e-02, -1.7545e-01, -2.0539e-01,  1.1130e-02,
          2.4122e-01,  3.2310e-01, -5.8663e-02,  1.7503e+01,  3.8936e+00,
          6.7905e-01,  1.2502e+00,  1.3259e+00,  1.5482e+00,  8.8574e-01,
          1.4833e+00,  2.8995e-01,  1.6483e+00,  1.7088e+00],
        [ 1.2242e+00,  1.2608e+00,  1.3274e+00,  1.3039e+00,  1.2687e+00,
          1.2306e+00,  1.1982e+00,  1.2209e+00,  1.2209e+00,  1.1911e+00,
          1.3234e+00,  1.2139e+00,  1.3658e+00,  1.2763e+00,  1.4185e+00,
          1.1995e+00,  1.2570e+00,  1.2693e+00,  1.2847e+00,  1.2771e+00,
          1.3344e+00,  1.3017e+00,  1.2484e+00,  1.2420e+00,  1.1442e+00,
          1.2319e+00,  1.2319e+00,  1.3000e+00,  1.3448e+00,  1.2507e+00,
          1.0329e+00,  1.2553e+00,  1.1316e+00,  1.3060e+00,  1.1251e+00,
          1.2543e+00,  1.2924e+00,  1.0036e+00,  1.2915e+00,  1.3060e+00,
          8.4696e-01,  7.7321e-01,  1.3146e+00,  1.1586e+00,  6.3794e-01,
          3.5242e+00,  2.5476e+00,  3.6778e+00,  2.8564e+00,  2.1298e+00,
          1.8023e+00,  2.9915e+00,  3.4344e+00,  1.7792e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 302 : 179.20726088890666
Test loss for epoch 302 : 179.51263172145337
Test Precision for epoch 302 : 0.26153846153846155
Test Recall for epoch 302 : 0.26153846153846155
Test F1 for epoch 302 : 0.26153846153846155


theta for epoch 303 : tensor([[ 2.7003e+00,  2.7324e+00,  2.8077e+00,  2.9474e+00,  2.9104e+00,
          2.7064e+00,  2.8853e+00,  2.6983e+00,  2.6983e+00,  1.2381e+00,
          1.2662e+00,  1.2543e+00,  1.2965e+00,  1.2329e+00,  1.3353e+00,
          1.2441e+00,  1.2190e+00,  1.2480e+00,  1.2134e+00,  1.1908e+00,
          1.2045e+00,  1.2257e+00,  1.1874e+00,  1.1828e+00,  1.2022e+00,
          1.1756e+00,  1.1756e+00,  1.2204e+00,  1.2651e+00,  1.1968e+00,
          1.2201e+00,  1.2657e+00,  1.2066e+00,  1.2371e+00,  1.1565e+00,
          1.1993e+00,  1.3951e+00,  1.4542e+00,  1.4289e+00,  1.4046e+00,
          1.4327e+00,  1.3784e+00,  1.4100e+00,  1.3053e+00,  1.3648e+00,
          1.3186e+00,  1.2645e+00,  1.2504e+00,  1.2299e+00,  1.3118e+00,
          1.2514e+00,  1.3535e+00,  1.2155e+00,  1.2275e+00],
        [ 1.2031e+00,  1.2318e+00,  1.2393e+00,  1.2298e+00,  1.2413e+00,
          1.2090e+00,  1.2115e+00,  1.2007e+00,  1.2007e+00,  2.1691e+00,
          2.1613e+00,  2.0976e+00,  2.2916e+00,  2.0940e+00,  5.0217e+00,
          2.1558e+00,  2.1661e+00,  4.8070e+00,  1.2092e+00,  1.2366e+00,
          1.2087e+00,  1.2108e+00,  1.2276e+00,  1.2231e+00,  1.2327e+00,
          1.2145e+00,  1.2145e+00,  1.2670e+00,  1.2122e+00,  1.2336e+00,
          1.2608e+00,  1.2244e+00,  1.2454e+00,  1.2814e+00,  1.1944e+00,
          1.2366e+00,  1.3555e+00,  1.4291e+00,  1.3368e+00,  1.3588e+00,
          1.4020e+00,  1.4117e+00,  1.3134e+00,  1.1453e+00,  1.3149e+00,
          1.3011e+00,  1.2920e+00,  1.2746e+00,  1.2498e+00,  1.2431e+00,
          1.2763e+00,  1.3007e+00,  1.2325e+00,  1.2474e+00],
        [ 1.1655e+00,  1.1923e+00,  1.2345e+00,  1.2234e+00,  1.1975e+00,
          1.1702e+00,  1.1782e+00,  1.1631e+00,  1.1631e+00,  1.2400e+00,
          1.2687e+00,  1.2566e+00,  1.2996e+00,  1.2347e+00,  1.2940e+00,
          1.2462e+00,  1.1758e+00,  1.2961e+00,  2.7441e+00,  2.9302e+00,
          2.9457e+00,  2.7665e+00,  2.7053e+00,  2.7048e+00,  2.8811e+00,
          2.6916e+00,  2.6916e+00,  1.2185e+00,  1.2678e+00,  1.1990e+00,
          1.2215e+00,  1.2191e+00,  1.2091e+00,  1.2402e+00,  1.2035e+00,
          1.2016e+00,  1.3890e+00,  1.4495e+00,  1.4218e+00,  1.3315e+00,
          1.4257e+00,  1.4224e+00,  1.4042e+00,  1.2961e+00,  1.2897e+00,
          1.3192e+00,  1.2655e+00,  1.2512e+00,  1.2302e+00,  1.3127e+00,
          1.2521e+00,  1.3555e+00,  1.2060e+00,  1.2277e+00],
        [ 1.1736e+00,  1.2008e+00,  1.2428e+00,  1.2324e+00,  1.2062e+00,
          1.1783e+00,  1.1867e+00,  1.1712e+00,  1.1712e+00,  1.2472e+00,
          1.2763e+00,  1.2640e+00,  1.3069e+00,  1.2418e+00,  1.2801e+00,
          1.2535e+00,  1.2267e+00,  1.2382e+00,  1.2249e+00,  1.2377e+00,
          1.2609e+00,  1.2376e+00,  1.1979e+00,  1.1932e+00,  1.2044e+00,
          1.1857e+00,  1.1857e+00,  2.9991e+00,  2.9753e+00,  2.6020e+00,
          2.7475e+00,  2.9959e+00,  2.6130e+00,  2.9394e+00,  2.6102e+00,
          2.6048e+00,  1.3905e+00,  1.4521e+00,  1.4247e+00,  1.3890e+00,
          1.4296e+00,  1.4259e+00,  1.4050e+00,  1.2684e+00,  1.3473e+00,
          1.3285e+00,  1.2725e+00,  1.1891e+00,  1.1889e+00,  1.3215e+00,
          1.2589e+00,  1.3646e+00,  1.1656e+00,  1.2342e+00],
        [ 1.7302e+00,  1.3505e+00,  5.6969e-01,  8.6540e-01,  1.2482e+00,
          1.6631e+00,  1.5449e+00,  1.7648e+00,  1.7648e+00,  1.5637e+00,
          1.2105e+00,  1.3973e+00,  8.3638e-01,  1.5925e+00,  9.5840e-02,
          1.5009e+00,  1.7546e+00,  7.6251e-01,  1.2555e+00,  9.3629e-01,
          7.0458e-01,  1.0803e+00,  1.6033e+00,  1.6667e+00,  1.4484e+00,
          1.7691e+00,  1.7691e+00,  7.9546e-01,  7.9087e-01,  1.7414e+00,
          1.5428e+00,  8.1384e-01,  1.6837e+00,  1.1687e+00,  1.7932e+00,
          1.7069e+00,  5.4120e-02, -1.7701e-01, -2.0714e-01,  9.3610e-03,
          2.3903e-01,  3.2042e-01, -6.0365e-02,  1.7575e+01,  3.8258e+00,
          6.7913e-01,  1.2505e+00,  1.3255e+00,  1.5483e+00,  8.8539e-01,
          1.4835e+00,  2.9041e-01,  1.6493e+00,  1.7089e+00],
        [ 1.2240e+00,  1.2607e+00,  1.3274e+00,  1.3038e+00,  1.2686e+00,
          1.2304e+00,  1.1981e+00,  1.2207e+00,  1.2207e+00,  1.1909e+00,
          1.3230e+00,  1.2136e+00,  1.3654e+00,  1.2761e+00,  1.4184e+00,
          1.1993e+00,  1.2563e+00,  1.2695e+00,  1.2849e+00,  1.2767e+00,
          1.3346e+00,  1.3020e+00,  1.2485e+00,  1.2421e+00,  1.1437e+00,
          1.2320e+00,  1.2320e+00,  1.3001e+00,  1.3451e+00,  1.2507e+00,
          1.0327e+00,  1.2555e+00,  1.1317e+00,  1.3062e+00,  1.1251e+00,
          1.2543e+00,  1.2914e+00,  1.0029e+00,  1.2901e+00,  1.3048e+00,
          8.4594e-01,  7.7236e-01,  1.3136e+00,  1.1554e+00,  6.3694e-01,
          3.5265e+00,  2.5458e+00,  3.6771e+00,  2.8544e+00,  2.1284e+00,
          1.8010e+00,  2.9897e+00,  3.4367e+00,  1.7778e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 303 : 179.185831975891
Test loss for epoch 303 : 179.49850145971425
Test Precision for epoch 303 : 0.26153846153846155
Test Recall for epoch 303 : 0.26153846153846155
Test F1 for epoch 303 : 0.26153846153846155


theta for epoch 304 : tensor([[ 2.7001e+00,  2.7323e+00,  2.8076e+00,  2.9473e+00,  2.9103e+00,
          2.7062e+00,  2.8852e+00,  2.6980e+00,  2.6980e+00,  1.2383e+00,
          1.2662e+00,  1.2545e+00,  1.2965e+00,  1.2332e+00,  1.3354e+00,
          1.2443e+00,  1.2189e+00,  1.2484e+00,  1.2133e+00,  1.1907e+00,
          1.2043e+00,  1.2256e+00,  1.1872e+00,  1.1827e+00,  1.2021e+00,
          1.1755e+00,  1.1755e+00,  1.2204e+00,  1.2651e+00,  1.1968e+00,
          1.2201e+00,  1.2658e+00,  1.2067e+00,  1.2371e+00,  1.1566e+00,
          1.1994e+00,  1.3955e+00,  1.4546e+00,  1.4294e+00,  1.4048e+00,
          1.4332e+00,  1.3790e+00,  1.4103e+00,  1.3045e+00,  1.3655e+00,
          1.3187e+00,  1.2646e+00,  1.2506e+00,  1.2300e+00,  1.3120e+00,
          1.2515e+00,  1.3537e+00,  1.2155e+00,  1.2276e+00],
        [ 1.2025e+00,  1.2316e+00,  1.2423e+00,  1.2301e+00,  1.2401e+00,
          1.2077e+00,  1.2116e+00,  1.1995e+00,  1.1995e+00,  2.1792e+00,
          2.1718e+00,  2.1073e+00,  2.3007e+00,  2.1021e+00,  4.9860e+00,
          2.1654e+00,  2.1813e+00,  4.7705e+00,  1.2088e+00,  1.2353e+00,
          1.2072e+00,  1.2125e+00,  1.2262e+00,  1.2216e+00,  1.2329e+00,
          1.2130e+00,  1.2130e+00,  1.2659e+00,  1.2140e+00,  1.2323e+00,
          1.2596e+00,  1.2251e+00,  1.2441e+00,  1.2801e+00,  1.1931e+00,
          1.2354e+00,  1.3550e+00,  1.4285e+00,  1.3364e+00,  1.3596e+00,
          1.4017e+00,  1.4114e+00,  1.3130e+00,  1.1524e+00,  1.3148e+00,
          1.3017e+00,  1.2908e+00,  1.2735e+00,  1.2486e+00,  1.2443e+00,
          1.2750e+00,  1.3009e+00,  1.2312e+00,  1.2462e+00],
        [ 1.1658e+00,  1.1926e+00,  1.2343e+00,  1.2236e+00,  1.1977e+00,
          1.1705e+00,  1.1785e+00,  1.1634e+00,  1.1634e+00,  1.2404e+00,
          1.2689e+00,  1.2569e+00,  1.2998e+00,  1.2351e+00,  1.2942e+00,
          1.2465e+00,  1.1758e+00,  1.2966e+00,  2.7432e+00,  2.9310e+00,
          2.9454e+00,  2.7653e+00,  2.7046e+00,  2.7038e+00,  2.8818e+00,
          2.6910e+00,  2.6910e+00,  1.2182e+00,  1.2680e+00,  1.1993e+00,
          1.2218e+00,  1.2188e+00,  1.2093e+00,  1.2404e+00,  1.2038e+00,
          1.2019e+00,  1.3897e+00,  1.4503e+00,  1.4226e+00,  1.3314e+00,
          1.4265e+00,  1.4228e+00,  1.4049e+00,  1.2957e+00,  1.2900e+00,
          1.3196e+00,  1.2659e+00,  1.2515e+00,  1.2305e+00,  1.3130e+00,
          1.2524e+00,  1.3558e+00,  1.2057e+00,  1.2280e+00],
        [ 1.1738e+00,  1.2009e+00,  1.2425e+00,  1.2325e+00,  1.2063e+00,
          1.1785e+00,  1.1868e+00,  1.1713e+00,  1.1713e+00,  1.2475e+00,
          1.2764e+00,  1.2642e+00,  1.3069e+00,  1.2422e+00,  1.2812e+00,
          1.2537e+00,  1.2267e+00,  1.2396e+00,  1.2249e+00,  1.2371e+00,
          1.2607e+00,  1.2376e+00,  1.1978e+00,  1.1931e+00,  1.2038e+00,
          1.1856e+00,  1.1856e+00,  2.9985e+00,  2.9742e+00,  2.6022e+00,
          2.7461e+00,  2.9954e+00,  2.6132e+00,  2.9382e+00,  2.6105e+00,
          2.6051e+00,  1.3909e+00,  1.4526e+00,  1.4252e+00,  1.3887e+00,
          1.4302e+00,  1.4261e+00,  1.4054e+00,  1.2691e+00,  1.3474e+00,
          1.3287e+00,  1.2726e+00,  1.1903e+00,  1.1890e+00,  1.3217e+00,
          1.2590e+00,  1.3649e+00,  1.1651e+00,  1.2343e+00],
        [ 1.7306e+00,  1.3509e+00,  5.6987e-01,  8.6573e-01,  1.2491e+00,
          1.6640e+00,  1.5449e+00,  1.7657e+00,  1.7657e+00,  1.5627e+00,
          1.2106e+00,  1.3974e+00,  8.3750e-01,  1.5923e+00,  9.5671e-02,
          1.5007e+00,  1.7554e+00,  7.6202e-01,  1.2558e+00,  9.3761e-01,
          7.0535e-01,  1.0797e+00,  1.6039e+00,  1.6673e+00,  1.4489e+00,
          1.7697e+00,  1.7697e+00,  7.9635e-01,  7.9049e-01,  1.7421e+00,
          1.5432e+00,  8.1413e-01,  1.6845e+00,  1.1690e+00,  1.7940e+00,
          1.7077e+00,  5.2221e-02, -1.7865e-01, -2.0896e-01,  7.4435e-03,
          2.3676e-01,  3.1765e-01, -6.2156e-02,  1.7648e+01,  3.7577e+00,
          6.7930e-01,  1.2507e+00,  1.3250e+00,  1.5483e+00,  8.8516e-01,
          1.4836e+00,  2.9097e-01,  1.6503e+00,  1.7089e+00],
        [ 1.2241e+00,  1.2607e+00,  1.3275e+00,  1.3039e+00,  1.2686e+00,
          1.2304e+00,  1.1981e+00,  1.2207e+00,  1.2207e+00,  1.1911e+00,
          1.3230e+00,  1.2137e+00,  1.3655e+00,  1.2763e+00,  1.4187e+00,
          1.1995e+00,  1.2561e+00,  1.2700e+00,  1.2848e+00,  1.2761e+00,
          1.3345e+00,  1.3019e+00,  1.2482e+00,  1.2418e+00,  1.1430e+00,
          1.2317e+00,  1.2317e+00,  1.3002e+00,  1.3452e+00,  1.2506e+00,
          1.0323e+00,  1.2556e+00,  1.1316e+00,  1.3062e+00,  1.1250e+00,
          1.2542e+00,  1.2904e+00,  1.0022e+00,  1.2886e+00,  1.3036e+00,
          8.4487e-01,  7.7145e-01,  1.3126e+00,  1.1522e+00,  6.3592e-01,
          3.5289e+00,  2.5439e+00,  3.6762e+00,  2.8523e+00,  2.1270e+00,
          1.7996e+00,  2.9880e+00,  3.4389e+00,  1.7764e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 304 : 179.1643891222845
Test loss for epoch 304 : 179.48421981606762
Test Precision for epoch 304 : 0.26153846153846155
Test Recall for epoch 304 : 0.26153846153846155
Test F1 for epoch 304 : 0.26153846153846155


theta for epoch 305 : tensor([[ 2.6997e+00,  2.7319e+00,  2.8072e+00,  2.9470e+00,  2.9099e+00,
          2.7058e+00,  2.8849e+00,  2.6976e+00,  2.6976e+00,  1.2386e+00,
          1.2663e+00,  1.2546e+00,  1.2964e+00,  1.2334e+00,  1.3355e+00,
          1.2444e+00,  1.2189e+00,  1.2487e+00,  1.2135e+00,  1.1907e+00,
          1.2044e+00,  1.2257e+00,  1.1873e+00,  1.1828e+00,  1.2022e+00,
          1.1756e+00,  1.1756e+00,  1.2206e+00,  1.2653e+00,  1.1970e+00,
          1.2203e+00,  1.2659e+00,  1.2068e+00,  1.2373e+00,  1.1567e+00,
          1.1995e+00,  1.3960e+00,  1.4552e+00,  1.4300e+00,  1.4052e+00,
          1.4338e+00,  1.3798e+00,  1.4108e+00,  1.3039e+00,  1.3662e+00,
          1.3190e+00,  1.2648e+00,  1.2508e+00,  1.2302e+00,  1.3122e+00,
          1.2517e+00,  1.3540e+00,  1.2155e+00,  1.2278e+00],
        [ 1.2018e+00,  1.2312e+00,  1.2449e+00,  1.2304e+00,  1.2389e+00,
          1.2065e+00,  1.2117e+00,  1.1982e+00,  1.1982e+00,  2.1889e+00,
          2.1821e+00,  2.1167e+00,  2.3101e+00,  2.1100e+00,  4.9502e+00,
          2.1749e+00,  2.1963e+00,  4.7339e+00,  1.2086e+00,  1.2343e+00,
          1.2059e+00,  1.2141e+00,  1.2249e+00,  1.2203e+00,  1.2333e+00,
          1.2117e+00,  1.2117e+00,  1.2648e+00,  1.2155e+00,  1.2311e+00,
          1.2586e+00,  1.2258e+00,  1.2429e+00,  1.2789e+00,  1.1920e+00,
          1.2342e+00,  1.3547e+00,  1.4282e+00,  1.3362e+00,  1.3604e+00,
          1.4015e+00,  1.4113e+00,  1.3126e+00,  1.1592e+00,  1.3149e+00,
          1.3021e+00,  1.2897e+00,  1.2724e+00,  1.2475e+00,  1.2452e+00,
          1.2739e+00,  1.3009e+00,  1.2299e+00,  1.2450e+00],
        [ 1.1660e+00,  1.1927e+00,  1.2340e+00,  1.2237e+00,  1.1978e+00,
          1.1706e+00,  1.1787e+00,  1.1635e+00,  1.1635e+00,  1.2407e+00,
          1.2690e+00,  1.2571e+00,  1.2998e+00,  1.2355e+00,  1.2942e+00,
          1.2467e+00,  1.1757e+00,  1.2969e+00,  2.7424e+00,  2.9318e+00,
          2.9453e+00,  2.7642e+00,  2.7040e+00,  2.7029e+00,  2.8827e+00,
          2.6904e+00,  2.6904e+00,  1.2179e+00,  1.2681e+00,  1.1995e+00,
          1.2220e+00,  1.2185e+00,  1.2095e+00,  1.2406e+00,  1.2040e+00,
          1.2021e+00,  1.3904e+00,  1.4510e+00,  1.4235e+00,  1.3314e+00,
          1.4274e+00,  1.4232e+00,  1.4056e+00,  1.2953e+00,  1.2904e+00,
          1.3199e+00,  1.2661e+00,  1.2518e+00,  1.2307e+00,  1.3133e+00,
          1.2527e+00,  1.3561e+00,  1.2054e+00,  1.2283e+00],
        [ 1.1738e+00,  1.2009e+00,  1.2420e+00,  1.2325e+00,  1.2063e+00,
          1.1785e+00,  1.1869e+00,  1.1713e+00,  1.1713e+00,  1.2477e+00,
          1.2765e+00,  1.2643e+00,  1.3067e+00,  1.2424e+00,  1.2822e+00,
          1.2538e+00,  1.2266e+00,  1.2409e+00,  1.2250e+00,  1.2366e+00,
          1.2607e+00,  1.2376e+00,  1.1979e+00,  1.1932e+00,  1.2034e+00,
          1.1857e+00,  1.1857e+00,  2.9980e+00,  2.9730e+00,  2.6025e+00,
          2.7445e+00,  2.9948e+00,  2.6135e+00,  2.9369e+00,  2.6108e+00,
          2.6053e+00,  1.3914e+00,  1.4531e+00,  1.4257e+00,  1.3885e+00,
          1.4308e+00,  1.4263e+00,  1.4058e+00,  1.2698e+00,  1.3477e+00,
          1.3289e+00,  1.2728e+00,  1.1914e+00,  1.1891e+00,  1.3219e+00,
          1.2591e+00,  1.3651e+00,  1.1646e+00,  1.2344e+00],
        [ 1.7308e+00,  1.3512e+00,  5.6992e-01,  8.6582e-01,  1.2497e+00,
          1.6647e+00,  1.5447e+00,  1.7664e+00,  1.7664e+00,  1.5616e+00,
          1.2105e+00,  1.3975e+00,  8.3836e-01,  1.5921e+00,  9.5387e-02,
          1.5003e+00,  1.7561e+00,  7.6142e-01,  1.2561e+00,  9.3887e-01,
          7.0604e-01,  1.0792e+00,  1.6044e+00,  1.6679e+00,  1.4494e+00,
          1.7704e+00,  1.7704e+00,  7.9705e-01,  7.9007e-01,  1.7428e+00,
          1.5434e+00,  8.1425e-01,  1.6851e+00,  1.1692e+00,  1.7947e+00,
          1.7083e+00,  5.0581e-02, -1.8005e-01, -2.1052e-01,  5.7278e-03,
          2.3478e-01,  3.1516e-01, -6.3695e-02,  1.7720e+01,  3.6896e+00,
          6.7921e-01,  1.2506e+00,  1.3242e+00,  1.5482e+00,  8.8473e-01,
          1.4835e+00,  2.9119e-01,  1.6510e+00,  1.7087e+00],
        [ 1.2241e+00,  1.2608e+00,  1.3276e+00,  1.3040e+00,  1.2686e+00,
          1.2304e+00,  1.1981e+00,  1.2206e+00,  1.2206e+00,  1.1914e+00,
          1.3231e+00,  1.2138e+00,  1.3655e+00,  1.2765e+00,  1.4189e+00,
          1.1996e+00,  1.2558e+00,  1.2705e+00,  1.2849e+00,  1.2756e+00,
          1.3346e+00,  1.3020e+00,  1.2482e+00,  1.2418e+00,  1.1426e+00,
          1.2316e+00,  1.2316e+00,  1.3002e+00,  1.3453e+00,  1.2506e+00,
          1.0321e+00,  1.2557e+00,  1.1316e+00,  1.3063e+00,  1.1250e+00,
          1.2542e+00,  1.2895e+00,  1.0016e+00,  1.2874e+00,  1.3026e+00,
          8.4401e-01,  7.7077e-01,  1.3118e+00,  1.1492e+00,  6.3514e-01,
          3.5311e+00,  2.5419e+00,  3.6752e+00,  2.8501e+00,  2.1255e+00,
          1.7982e+00,  2.9860e+00,  3.4410e+00,  1.7749e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 305 : 179.1430216819808
Test loss for epoch 305 : 179.4703113908903
Test Precision for epoch 305 : 0.26153846153846155
Test Recall for epoch 305 : 0.26153846153846155
Test F1 for epoch 305 : 0.26153846153846155


theta for epoch 306 : tensor([[ 2.6992e+00,  2.7314e+00,  2.8067e+00,  2.9466e+00,  2.9095e+00,
          2.7052e+00,  2.8845e+00,  2.6971e+00,  2.6971e+00,  1.2384e+00,
          1.2660e+00,  1.2543e+00,  1.2960e+00,  1.2332e+00,  1.3352e+00,
          1.2442e+00,  1.2184e+00,  1.2487e+00,  1.2138e+00,  1.1910e+00,
          1.2046e+00,  1.2261e+00,  1.1876e+00,  1.1831e+00,  1.2024e+00,
          1.1759e+00,  1.1759e+00,  1.2208e+00,  1.2656e+00,  1.1972e+00,
          1.2207e+00,  1.2662e+00,  1.2071e+00,  1.2376e+00,  1.1570e+00,
          1.1998e+00,  1.3965e+00,  1.4557e+00,  1.4306e+00,  1.4056e+00,
          1.4344e+00,  1.3805e+00,  1.4113e+00,  1.3032e+00,  1.3670e+00,
          1.3194e+00,  1.2653e+00,  1.2513e+00,  1.2306e+00,  1.3127e+00,
          1.2521e+00,  1.3545e+00,  1.2158e+00,  1.2282e+00],
        [ 1.2011e+00,  1.2307e+00,  1.2472e+00,  1.2307e+00,  1.2378e+00,
          1.2053e+00,  1.2117e+00,  1.1970e+00,  1.1970e+00,  2.1981e+00,
          2.1921e+00,  2.1257e+00,  2.3193e+00,  2.1175e+00,  4.9140e+00,
          2.1839e+00,  2.2108e+00,  4.6970e+00,  1.2087e+00,  1.2336e+00,
          1.2051e+00,  1.2160e+00,  1.2241e+00,  1.2194e+00,  1.2340e+00,
          1.2108e+00,  1.2108e+00,  1.2641e+00,  1.2168e+00,  1.2302e+00,
          1.2579e+00,  1.2267e+00,  1.2420e+00,  1.2780e+00,  1.1911e+00,
          1.2333e+00,  1.3544e+00,  1.4278e+00,  1.3359e+00,  1.3611e+00,
          1.4014e+00,  1.4113e+00,  1.3123e+00,  1.1655e+00,  1.3151e+00,
          1.3025e+00,  1.2890e+00,  1.2717e+00,  1.2468e+00,  1.2463e+00,
          1.2731e+00,  1.3010e+00,  1.2290e+00,  1.2443e+00],
        [ 1.1661e+00,  1.1928e+00,  1.2336e+00,  1.2237e+00,  1.1978e+00,
          1.1706e+00,  1.1787e+00,  1.1636e+00,  1.1636e+00,  1.2406e+00,
          1.2687e+00,  1.2568e+00,  1.2993e+00,  1.2353e+00,  1.2938e+00,
          1.2465e+00,  1.1752e+00,  1.2968e+00,  2.7419e+00,  2.9328e+00,
          2.9453e+00,  2.7633e+00,  2.7036e+00,  2.7022e+00,  2.8837e+00,
          2.6900e+00,  2.6900e+00,  1.2176e+00,  1.2683e+00,  1.1997e+00,
          1.2223e+00,  1.2182e+00,  1.2097e+00,  1.2409e+00,  1.2042e+00,
          1.2023e+00,  1.3911e+00,  1.4517e+00,  1.4242e+00,  1.3313e+00,
          1.4282e+00,  1.4235e+00,  1.4062e+00,  1.2949e+00,  1.2906e+00,
          1.3203e+00,  1.2666e+00,  1.2523e+00,  1.2311e+00,  1.3138e+00,
          1.2531e+00,  1.3565e+00,  1.2052e+00,  1.2287e+00],
        [ 1.1738e+00,  1.2008e+00,  1.2415e+00,  1.2324e+00,  1.2062e+00,
          1.1784e+00,  1.1868e+00,  1.1712e+00,  1.1712e+00,  1.2475e+00,
          1.2760e+00,  1.2639e+00,  1.3062e+00,  1.2421e+00,  1.2828e+00,
          1.2535e+00,  1.2261e+00,  1.2417e+00,  1.2252e+00,  1.2363e+00,
          1.2609e+00,  1.2378e+00,  1.1981e+00,  1.1933e+00,  1.2032e+00,
          1.1859e+00,  1.1859e+00,  2.9975e+00,  2.9719e+00,  2.6028e+00,
          2.7431e+00,  2.9944e+00,  2.6139e+00,  2.9356e+00,  2.6112e+00,
          2.6057e+00,  1.3918e+00,  1.4535e+00,  1.4261e+00,  1.3882e+00,
          1.4314e+00,  1.4263e+00,  1.4061e+00,  1.2704e+00,  1.3478e+00,
          1.3292e+00,  1.2731e+00,  1.1927e+00,  1.1893e+00,  1.3222e+00,
          1.2594e+00,  1.3655e+00,  1.1642e+00,  1.2346e+00],
        [ 1.7311e+00,  1.3515e+00,  5.7009e-01,  8.6588e-01,  1.2503e+00,
          1.6653e+00,  1.5445e+00,  1.7670e+00,  1.7670e+00,  1.5603e+00,
          1.2101e+00,  1.3974e+00,  8.3894e-01,  1.5917e+00,  9.5063e-02,
          1.4996e+00,  1.7563e+00,  7.6069e-01,  1.2567e+00,  9.4033e-01,
          7.0695e-01,  1.0792e+00,  1.6052e+00,  1.6687e+00,  1.4501e+00,
          1.7712e+00,  1.7712e+00,  7.9786e-01,  7.8991e-01,  1.7435e+00,
          1.5437e+00,  8.1451e-01,  1.6858e+00,  1.1694e+00,  1.7954e+00,
          1.7090e+00,  4.8939e-02, -1.8146e-01, -2.1207e-01,  3.9541e-03,
          2.3281e-01,  3.1269e-01, -6.5240e-02,  1.7793e+01,  3.6214e+00,
          6.7946e-01,  1.2509e+00,  1.3238e+00,  1.5482e+00,  8.8470e-01,
          1.4836e+00,  2.9170e-01,  1.6520e+00,  1.7088e+00],
        [ 1.2239e+00,  1.2606e+00,  1.3275e+00,  1.3039e+00,  1.2685e+00,
          1.2302e+00,  1.1980e+00,  1.2204e+00,  1.2204e+00,  1.1911e+00,
          1.3226e+00,  1.2134e+00,  1.3649e+00,  1.2762e+00,  1.4187e+00,
          1.1993e+00,  1.2551e+00,  1.2705e+00,  1.2851e+00,  1.2753e+00,
          1.3348e+00,  1.3022e+00,  1.2483e+00,  1.2419e+00,  1.1423e+00,
          1.2317e+00,  1.2317e+00,  1.3003e+00,  1.3455e+00,  1.2505e+00,
          1.0319e+00,  1.2558e+00,  1.1316e+00,  1.3064e+00,  1.1250e+00,
          1.2541e+00,  1.2885e+00,  1.0009e+00,  1.2861e+00,  1.3015e+00,
          8.4303e-01,  7.6994e-01,  1.3109e+00,  1.1461e+00,  6.3425e-01,
          3.5335e+00,  2.5401e+00,  3.6743e+00,  2.8482e+00,  2.1243e+00,
          1.7971e+00,  2.9844e+00,  3.4434e+00,  1.7738e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 306 : 179.12171221918686
Test loss for epoch 306 : 179.4562734389027
Test Precision for epoch 306 : 0.26153846153846155
Test Recall for epoch 306 : 0.26153846153846155
Test F1 for epoch 306 : 0.26153846153846155


theta for epoch 307 : tensor([[ 2.6989e+00,  2.7311e+00,  2.8065e+00,  2.9463e+00,  2.9093e+00,
          2.7049e+00,  2.8843e+00,  2.6967e+00,  2.6967e+00,  1.2385e+00,
          1.2660e+00,  1.2543e+00,  1.2959e+00,  1.2333e+00,  1.3352e+00,
          1.2443e+00,  1.2183e+00,  1.2488e+00,  1.2139e+00,  1.1910e+00,
          1.2046e+00,  1.2261e+00,  1.1877e+00,  1.1831e+00,  1.2024e+00,
          1.1759e+00,  1.1759e+00,  1.2208e+00,  1.2656e+00,  1.1973e+00,
          1.2208e+00,  1.2662e+00,  1.2071e+00,  1.2377e+00,  1.1570e+00,
          1.1998e+00,  1.3968e+00,  1.4560e+00,  1.4310e+00,  1.4059e+00,
          1.4349e+00,  1.3810e+00,  1.4116e+00,  1.3025e+00,  1.3676e+00,
          1.3197e+00,  1.2655e+00,  1.2515e+00,  1.2308e+00,  1.3130e+00,
          1.2523e+00,  1.3548e+00,  1.2158e+00,  1.2284e+00],
        [ 1.2003e+00,  1.2302e+00,  1.2492e+00,  1.2311e+00,  1.2368e+00,
          1.2043e+00,  1.2117e+00,  1.1960e+00,  1.1960e+00,  2.2075e+00,
          2.2023e+00,  2.1350e+00,  2.3292e+00,  2.1253e+00,  4.8783e+00,
          2.1931e+00,  2.2256e+00,  4.6605e+00,  1.2084e+00,  1.2327e+00,
          1.2040e+00,  1.2173e+00,  1.2230e+00,  1.2182e+00,  1.2342e+00,
          1.2096e+00,  1.2096e+00,  1.2632e+00,  1.2176e+00,  1.2292e+00,
          1.2570e+00,  1.2275e+00,  1.2409e+00,  1.2770e+00,  1.1901e+00,
          1.2322e+00,  1.3540e+00,  1.4274e+00,  1.3356e+00,  1.3616e+00,
          1.4011e+00,  1.4111e+00,  1.3119e+00,  1.1712e+00,  1.3151e+00,
          1.3026e+00,  1.2881e+00,  1.2709e+00,  1.2459e+00,  1.2468e+00,
          1.2722e+00,  1.3008e+00,  1.2280e+00,  1.2433e+00],
        [ 1.1664e+00,  1.1930e+00,  1.2333e+00,  1.2239e+00,  1.1980e+00,
          1.1709e+00,  1.1790e+00,  1.1638e+00,  1.1638e+00,  1.2409e+00,
          1.2688e+00,  1.2570e+00,  1.2993e+00,  1.2356e+00,  1.2938e+00,
          1.2467e+00,  1.1750e+00,  1.2971e+00,  2.7410e+00,  2.9335e+00,
          2.9450e+00,  2.7621e+00,  2.7029e+00,  2.7012e+00,  2.8844e+00,
          2.6892e+00,  2.6892e+00,  1.2172e+00,  1.2685e+00,  1.1999e+00,
          1.2226e+00,  1.2179e+00,  1.2100e+00,  1.2411e+00,  1.2044e+00,
          1.2025e+00,  1.3917e+00,  1.4523e+00,  1.4249e+00,  1.3312e+00,
          1.4289e+00,  1.4238e+00,  1.4069e+00,  1.2945e+00,  1.2909e+00,
          1.3207e+00,  1.2670e+00,  1.2527e+00,  1.2315e+00,  1.3142e+00,
          1.2535e+00,  1.3569e+00,  1.2050e+00,  1.2291e+00],
        [ 1.1738e+00,  1.2009e+00,  1.2410e+00,  1.2324e+00,  1.2062e+00,
          1.1784e+00,  1.1869e+00,  1.1713e+00,  1.1713e+00,  1.2475e+00,
          1.2759e+00,  1.2639e+00,  1.3059e+00,  1.2421e+00,  1.2836e+00,
          1.2535e+00,  1.2259e+00,  1.2428e+00,  1.2252e+00,  1.2357e+00,
          1.2608e+00,  1.2378e+00,  1.1980e+00,  1.1933e+00,  1.2026e+00,
          1.1858e+00,  1.1858e+00,  2.9970e+00,  2.9707e+00,  2.6032e+00,
          2.7416e+00,  2.9939e+00,  2.6143e+00,  2.9343e+00,  2.6117e+00,
          2.6061e+00,  1.3921e+00,  1.4539e+00,  1.4265e+00,  1.3878e+00,
          1.4318e+00,  1.4262e+00,  1.4063e+00,  1.2710e+00,  1.3478e+00,
          1.3293e+00,  1.2732e+00,  1.1939e+00,  1.1894e+00,  1.3224e+00,
          1.2595e+00,  1.3657e+00,  1.1637e+00,  1.2347e+00],
        [ 1.7317e+00,  1.3521e+00,  5.7053e-01,  8.6610e-01,  1.2510e+00,
          1.6660e+00,  1.5446e+00,  1.7677e+00,  1.7677e+00,  1.5595e+00,
          1.2101e+00,  1.3977e+00,  8.3988e-01,  1.5919e+00,  9.5202e-02,
          1.4994e+00,  1.7569e+00,  7.6049e-01,  1.2572e+00,  9.4162e-01,
          7.0772e-01,  1.0791e+00,  1.6057e+00,  1.6693e+00,  1.4508e+00,
          1.7718e+00,  1.7718e+00,  7.9868e-01,  7.8989e-01,  1.7441e+00,
          1.5440e+00,  8.1478e-01,  1.6864e+00,  1.1697e+00,  1.7960e+00,
          1.7096e+00,  4.7277e-02, -1.8290e-01, -2.1364e-01,  2.1085e-03,
          2.3085e-01,  3.1021e-01, -6.6807e-02,  1.7866e+01,  3.5529e+00,
          6.7970e-01,  1.2510e+00,  1.3233e+00,  1.5482e+00,  8.8468e-01,
          1.4837e+00,  2.9220e-01,  1.6529e+00,  1.7088e+00],
        [ 1.2239e+00,  1.2607e+00,  1.3276e+00,  1.3040e+00,  1.2686e+00,
          1.2302e+00,  1.1981e+00,  1.2204e+00,  1.2204e+00,  1.1913e+00,
          1.3226e+00,  1.2134e+00,  1.3648e+00,  1.2763e+00,  1.4188e+00,
          1.1993e+00,  1.2548e+00,  1.2708e+00,  1.2852e+00,  1.2749e+00,
          1.3348e+00,  1.3023e+00,  1.2483e+00,  1.2418e+00,  1.1419e+00,
          1.2316e+00,  1.2316e+00,  1.3004e+00,  1.3456e+00,  1.2505e+00,
          1.0317e+00,  1.2559e+00,  1.1315e+00,  1.3065e+00,  1.1249e+00,
          1.2541e+00,  1.2875e+00,  1.0002e+00,  1.2848e+00,  1.3004e+00,
          8.4208e-01,  7.6915e-01,  1.3099e+00,  1.1432e+00,  6.3344e-01,
          3.5357e+00,  2.5383e+00,  3.6733e+00,  2.8461e+00,  2.1229e+00,
          1.7958e+00,  2.9825e+00,  3.4456e+00,  1.7725e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 307 : 179.10048601021177
Test loss for epoch 307 : 179.44233148179157
Test Precision for epoch 307 : 0.26153846153846155
Test Recall for epoch 307 : 0.26153846153846155
Test F1 for epoch 307 : 0.26153846153846155


theta for epoch 308 : tensor([[ 2.6986e+00,  2.7309e+00,  2.8062e+00,  2.9461e+00,  2.9091e+00,
          2.7046e+00,  2.8841e+00,  2.6964e+00,  2.6964e+00,  1.2388e+00,
          1.2660e+00,  1.2544e+00,  1.2958e+00,  1.2335e+00,  1.3352e+00,
          1.2444e+00,  1.2183e+00,  1.2490e+00,  1.2139e+00,  1.1909e+00,
          1.2046e+00,  1.2261e+00,  1.1877e+00,  1.1831e+00,  1.2024e+00,
          1.1759e+00,  1.1759e+00,  1.2208e+00,  1.2656e+00,  1.1973e+00,
          1.2209e+00,  1.2662e+00,  1.2071e+00,  1.2377e+00,  1.1570e+00,
          1.1998e+00,  1.3972e+00,  1.4564e+00,  1.4314e+00,  1.4062e+00,
          1.4354e+00,  1.3816e+00,  1.4120e+00,  1.3018e+00,  1.3683e+00,
          1.3198e+00,  1.2657e+00,  1.2517e+00,  1.2309e+00,  1.3132e+00,
          1.2525e+00,  1.3550e+00,  1.2158e+00,  1.2284e+00],
        [ 1.1994e+00,  1.2295e+00,  1.2510e+00,  1.2315e+00,  1.2358e+00,
          1.2032e+00,  1.2117e+00,  1.1950e+00,  1.1950e+00,  2.2167e+00,
          2.2126e+00,  2.1443e+00,  2.3394e+00,  2.1332e+00,  4.8426e+00,
          2.2024e+00,  2.2403e+00,  4.6242e+00,  1.2081e+00,  1.2319e+00,
          1.2030e+00,  1.2184e+00,  1.2220e+00,  1.2170e+00,  1.2344e+00,
          1.2084e+00,  1.2084e+00,  1.2624e+00,  1.2180e+00,  1.2282e+00,
          1.2561e+00,  1.2282e+00,  1.2399e+00,  1.2760e+00,  1.1891e+00,
          1.2312e+00,  1.3537e+00,  1.4270e+00,  1.3354e+00,  1.3621e+00,
          1.4010e+00,  1.4110e+00,  1.3116e+00,  1.1764e+00,  1.3153e+00,
          1.3025e+00,  1.2872e+00,  1.2700e+00,  1.2450e+00,  1.2471e+00,
          1.2713e+00,  1.3003e+00,  1.2270e+00,  1.2424e+00],
        [ 1.1666e+00,  1.1932e+00,  1.2330e+00,  1.2241e+00,  1.1982e+00,
          1.1711e+00,  1.1792e+00,  1.1641e+00,  1.1641e+00,  1.2412e+00,
          1.2690e+00,  1.2572e+00,  1.2994e+00,  1.2359e+00,  1.2938e+00,
          1.2470e+00,  1.1750e+00,  1.2975e+00,  2.7401e+00,  2.9343e+00,
          2.9447e+00,  2.7609e+00,  2.7021e+00,  2.7002e+00,  2.8852e+00,
          2.6885e+00,  2.6885e+00,  1.2169e+00,  1.2686e+00,  1.2001e+00,
          1.2229e+00,  1.2176e+00,  1.2101e+00,  1.2413e+00,  1.2046e+00,
          1.2027e+00,  1.3924e+00,  1.4530e+00,  1.4256e+00,  1.3311e+00,
          1.4297e+00,  1.4241e+00,  1.4075e+00,  1.2942e+00,  1.2912e+00,
          1.3211e+00,  1.2674e+00,  1.2531e+00,  1.2318e+00,  1.3145e+00,
          1.2539e+00,  1.3572e+00,  1.2048e+00,  1.2294e+00],
        [ 1.1739e+00,  1.2009e+00,  1.2405e+00,  1.2324e+00,  1.2062e+00,
          1.1785e+00,  1.1869e+00,  1.1713e+00,  1.1713e+00,  1.2477e+00,
          1.2759e+00,  1.2639e+00,  1.3057e+00,  1.2423e+00,  1.2846e+00,
          1.2536e+00,  1.2258e+00,  1.2439e+00,  1.2251e+00,  1.2350e+00,
          1.2607e+00,  1.2378e+00,  1.1980e+00,  1.1932e+00,  1.2021e+00,
          1.1858e+00,  1.1858e+00,  2.9964e+00,  2.9695e+00,  2.6036e+00,
          2.7400e+00,  2.9933e+00,  2.6146e+00,  2.9329e+00,  2.6121e+00,
          2.6064e+00,  1.3925e+00,  1.4543e+00,  1.4268e+00,  1.3875e+00,
          1.4323e+00,  1.4262e+00,  1.4066e+00,  1.2717e+00,  1.3479e+00,
          1.3295e+00,  1.2733e+00,  1.1950e+00,  1.1894e+00,  1.3226e+00,
          1.2596e+00,  1.3659e+00,  1.1631e+00,  1.2347e+00],
        [ 1.7323e+00,  1.3527e+00,  5.7097e-01,  8.6624e-01,  1.2517e+00,
          1.6666e+00,  1.5447e+00,  1.7683e+00,  1.7683e+00,  1.5589e+00,
          1.2102e+00,  1.3983e+00,  8.4085e-01,  1.5923e+00,  9.5454e-02,
          1.4993e+00,  1.7576e+00,  7.6043e-01,  1.2576e+00,  9.4280e-01,
          7.0838e-01,  1.0791e+00,  1.6062e+00,  1.6698e+00,  1.4515e+00,
          1.7723e+00,  1.7723e+00,  7.9941e-01,  7.8989e-01,  1.7446e+00,
          1.5441e+00,  8.1495e-01,  1.6869e+00,  1.1698e+00,  1.7965e+00,
          1.7101e+00,  4.5760e-02, -1.8420e-01, -2.1506e-01,  3.5957e-04,
          2.2905e-01,  3.0790e-01, -6.8235e-02,  1.7939e+01,  3.4846e+00,
          6.7979e-01,  1.2510e+00,  1.3227e+00,  1.5480e+00,  8.8453e-01,
          1.4835e+00,  2.9252e-01,  1.6535e+00,  1.7085e+00],
        [ 1.2240e+00,  1.2608e+00,  1.3277e+00,  1.3042e+00,  1.2686e+00,
          1.2302e+00,  1.1982e+00,  1.2205e+00,  1.2205e+00,  1.1916e+00,
          1.3227e+00,  1.2136e+00,  1.3649e+00,  1.2765e+00,  1.4191e+00,
          1.1996e+00,  1.2547e+00,  1.2712e+00,  1.2852e+00,  1.2746e+00,
          1.3349e+00,  1.3024e+00,  1.2482e+00,  1.2417e+00,  1.1415e+00,
          1.2315e+00,  1.2315e+00,  1.3004e+00,  1.3457e+00,  1.2504e+00,
          1.0315e+00,  1.2560e+00,  1.1315e+00,  1.3066e+00,  1.1249e+00,
          1.2540e+00,  1.2867e+00,  9.9965e-01,  1.2837e+00,  1.2996e+00,
          8.4131e-01,  7.6855e-01,  1.3091e+00,  1.1405e+00,  6.3286e-01,
          3.5378e+00,  2.5363e+00,  3.6720e+00,  2.8439e+00,  2.1215e+00,
          1.7944e+00,  2.9805e+00,  3.4476e+00,  1.7711e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 308 : 179.07940183253015
Test loss for epoch 308 : 179.42871475652285
Test Precision for epoch 308 : 0.26153846153846155
Test Recall for epoch 308 : 0.26153846153846155
Test F1 for epoch 308 : 0.26153846153846155


theta for epoch 309 : tensor([[ 2.6981e+00,  2.7305e+00,  2.8059e+00,  2.9458e+00,  2.9087e+00,
          2.7041e+00,  2.8837e+00,  2.6960e+00,  2.6960e+00,  1.2387e+00,
          1.2657e+00,  1.2541e+00,  1.2954e+00,  1.2333e+00,  1.3349e+00,
          1.2442e+00,  1.2179e+00,  1.2489e+00,  1.2141e+00,  1.1910e+00,
          1.2047e+00,  1.2263e+00,  1.1879e+00,  1.1833e+00,  1.2026e+00,
          1.1761e+00,  1.1761e+00,  1.2209e+00,  1.2658e+00,  1.1974e+00,
          1.2211e+00,  1.2664e+00,  1.2073e+00,  1.2379e+00,  1.1571e+00,
          1.2000e+00,  1.3976e+00,  1.4569e+00,  1.4319e+00,  1.4066e+00,
          1.4359e+00,  1.3822e+00,  1.4124e+00,  1.3013e+00,  1.3690e+00,
          1.3202e+00,  1.2661e+00,  1.2521e+00,  1.2312e+00,  1.3136e+00,
          1.2528e+00,  1.3554e+00,  1.2160e+00,  1.2288e+00],
        [ 1.1985e+00,  1.2287e+00,  1.2523e+00,  1.2319e+00,  1.2348e+00,
          1.2023e+00,  1.2115e+00,  1.1940e+00,  1.1940e+00,  2.2253e+00,
          2.2223e+00,  2.1532e+00,  2.3495e+00,  2.1407e+00,  4.8068e+00,
          2.2111e+00,  2.2546e+00,  4.5877e+00,  1.2080e+00,  1.2314e+00,
          1.2024e+00,  1.2196e+00,  1.2213e+00,  1.2162e+00,  1.2348e+00,
          1.2076e+00,  1.2076e+00,  1.2619e+00,  1.2184e+00,  1.2274e+00,
          1.2556e+00,  1.2292e+00,  1.2392e+00,  1.2753e+00,  1.1885e+00,
          1.2304e+00,  1.3536e+00,  1.4268e+00,  1.3353e+00,  1.3626e+00,
          1.4009e+00,  1.4111e+00,  1.3115e+00,  1.1813e+00,  1.3157e+00,
          1.3025e+00,  1.2867e+00,  1.2696e+00,  1.2445e+00,  1.2475e+00,
          1.2708e+00,  1.2999e+00,  1.2264e+00,  1.2419e+00],
        [ 1.1666e+00,  1.1932e+00,  1.2325e+00,  1.2240e+00,  1.1982e+00,
          1.1711e+00,  1.1792e+00,  1.1640e+00,  1.1640e+00,  1.2411e+00,
          1.2687e+00,  1.2570e+00,  1.2990e+00,  1.2357e+00,  1.2934e+00,
          1.2468e+00,  1.1746e+00,  1.2973e+00,  2.7395e+00,  2.9353e+00,
          2.9447e+00,  2.7600e+00,  2.7017e+00,  2.6994e+00,  2.8862e+00,
          2.6880e+00,  2.6880e+00,  1.2165e+00,  1.2687e+00,  1.2002e+00,
          1.2231e+00,  1.2172e+00,  1.2103e+00,  1.2415e+00,  1.2047e+00,
          1.2028e+00,  1.3929e+00,  1.4536e+00,  1.4263e+00,  1.3309e+00,
          1.4304e+00,  1.4242e+00,  1.4081e+00,  1.2938e+00,  1.2914e+00,
          1.3215e+00,  1.2678e+00,  1.2535e+00,  1.2322e+00,  1.3149e+00,
          1.2543e+00,  1.3576e+00,  1.2046e+00,  1.2297e+00],
        [ 1.1738e+00,  1.2007e+00,  1.2399e+00,  1.2322e+00,  1.2060e+00,
          1.1783e+00,  1.1868e+00,  1.1712e+00,  1.1712e+00,  1.2475e+00,
          1.2756e+00,  1.2636e+00,  1.3052e+00,  1.2420e+00,  1.2851e+00,
          1.2533e+00,  1.2254e+00,  1.2446e+00,  1.2252e+00,  1.2345e+00,
          1.2608e+00,  1.2379e+00,  1.1981e+00,  1.1933e+00,  1.2017e+00,
          1.1859e+00,  1.1859e+00,  2.9959e+00,  2.9682e+00,  2.6040e+00,
          2.7385e+00,  2.9929e+00,  2.6151e+00,  2.9316e+00,  2.6126e+00,
          2.6069e+00,  1.3928e+00,  1.4547e+00,  1.4272e+00,  1.3872e+00,
          1.4328e+00,  1.4262e+00,  1.4069e+00,  1.2724e+00,  1.3479e+00,
          1.3297e+00,  1.2736e+00,  1.1963e+00,  1.1896e+00,  1.3229e+00,
          1.2598e+00,  1.3662e+00,  1.1627e+00,  1.2349e+00],
        [ 1.7328e+00,  1.3532e+00,  5.7143e-01,  8.6630e-01,  1.2522e+00,
          1.6671e+00,  1.5447e+00,  1.7688e+00,  1.7688e+00,  1.5581e+00,
          1.2100e+00,  1.3987e+00,  8.4157e-01,  1.5926e+00,  9.5649e-02,
          1.4990e+00,  1.7579e+00,  7.6020e-01,  1.2584e+00,  9.4423e-01,
          7.0930e-01,  1.0794e+00,  1.6068e+00,  1.6705e+00,  1.4524e+00,
          1.7730e+00,  1.7730e+00,  8.0031e-01,  7.9015e-01,  1.7451e+00,
          1.5443e+00,  8.1529e-01,  1.6875e+00,  1.1701e+00,  1.7971e+00,
          1.7107e+00,  4.4230e-02, -1.8552e-01, -2.1649e-01, -1.4450e-03,
          2.2726e-01,  3.0560e-01, -6.9679e-02,  1.8013e+01,  3.4163e+00,
          6.8028e-01,  1.2513e+00,  1.3224e+00,  1.5481e+00,  8.8481e-01,
          1.4837e+00,  2.9320e-01,  1.6545e+00,  1.7086e+00],
        [ 1.2238e+00,  1.2606e+00,  1.3275e+00,  1.3040e+00,  1.2685e+00,
          1.2300e+00,  1.1980e+00,  1.2202e+00,  1.2202e+00,  1.1914e+00,
          1.3224e+00,  1.2133e+00,  1.3644e+00,  1.2761e+00,  1.4189e+00,
          1.1993e+00,  1.2541e+00,  1.2711e+00,  1.2854e+00,  1.2744e+00,
          1.3350e+00,  1.3025e+00,  1.2483e+00,  1.2418e+00,  1.1413e+00,
          1.2315e+00,  1.2315e+00,  1.3004e+00,  1.3458e+00,  1.2503e+00,
          1.0314e+00,  1.2560e+00,  1.1315e+00,  1.3067e+00,  1.1248e+00,
          1.2539e+00,  1.2857e+00,  9.9896e-01,  1.2826e+00,  1.2987e+00,
          8.4043e-01,  7.6782e-01,  1.3082e+00,  1.1379e+00,  6.3218e-01,
          3.5402e+00,  2.5346e+00,  3.6711e+00,  2.8420e+00,  2.1204e+00,
          1.7935e+00,  2.9789e+00,  3.4499e+00,  1.7701e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 309 : 179.05843425283885
Test loss for epoch 309 : 179.41496339490413
Test Precision for epoch 309 : 0.26153846153846155
Test Recall for epoch 309 : 0.26153846153846155
Test F1 for epoch 309 : 0.26153846153846155


theta for epoch 310 : tensor([[ 2.6978e+00,  2.7302e+00,  2.8056e+00,  2.9455e+00,  2.9084e+00,
          2.7038e+00,  2.8834e+00,  2.6956e+00,  2.6956e+00,  1.2387e+00,
          1.2656e+00,  1.2540e+00,  1.2951e+00,  1.2332e+00,  1.3348e+00,
          1.2442e+00,  1.2177e+00,  1.2489e+00,  1.2141e+00,  1.1910e+00,
          1.2047e+00,  1.2263e+00,  1.1879e+00,  1.1833e+00,  1.2026e+00,
          1.1761e+00,  1.1761e+00,  1.2210e+00,  1.2659e+00,  1.1975e+00,
          1.2212e+00,  1.2665e+00,  1.2074e+00,  1.2381e+00,  1.1572e+00,
          1.2001e+00,  1.3980e+00,  1.4573e+00,  1.4323e+00,  1.4070e+00,
          1.4364e+00,  1.3828e+00,  1.4128e+00,  1.3007e+00,  1.3698e+00,
          1.3204e+00,  1.2663e+00,  1.2523e+00,  1.2314e+00,  1.3138e+00,
          1.2530e+00,  1.3557e+00,  1.2161e+00,  1.2289e+00],
        [ 1.1975e+00,  1.2279e+00,  1.2535e+00,  1.2323e+00,  1.2339e+00,
          1.2014e+00,  1.2113e+00,  1.1932e+00,  1.1932e+00,  2.2339e+00,
          2.2322e+00,  2.1622e+00,  2.3599e+00,  2.1484e+00,  4.7712e+00,
          2.2200e+00,  2.2689e+00,  4.5516e+00,  1.2077e+00,  1.2308e+00,
          1.2017e+00,  1.2203e+00,  1.2205e+00,  1.2153e+00,  1.2348e+00,
          1.2067e+00,  1.2067e+00,  1.2613e+00,  1.2184e+00,  1.2267e+00,
          1.2550e+00,  1.2301e+00,  1.2384e+00,  1.2746e+00,  1.1878e+00,
          1.2297e+00,  1.3534e+00,  1.4266e+00,  1.3352e+00,  1.3630e+00,
          1.4009e+00,  1.4112e+00,  1.3113e+00,  1.1856e+00,  1.3161e+00,
          1.3021e+00,  1.2860e+00,  1.2690e+00,  1.2439e+00,  1.2475e+00,
          1.2701e+00,  1.2993e+00,  1.2256e+00,  1.2412e+00],
        [ 1.1667e+00,  1.1932e+00,  1.2321e+00,  1.2241e+00,  1.1982e+00,
          1.1712e+00,  1.1794e+00,  1.1641e+00,  1.1641e+00,  1.2412e+00,
          1.2687e+00,  1.2569e+00,  1.2988e+00,  1.2357e+00,  1.2932e+00,
          1.2468e+00,  1.1743e+00,  1.2973e+00,  2.7388e+00,  2.9362e+00,
          2.9445e+00,  2.7590e+00,  2.7011e+00,  2.6986e+00,  2.8871e+00,
          2.6874e+00,  2.6874e+00,  1.2161e+00,  1.2688e+00,  1.2004e+00,
          1.2233e+00,  1.2168e+00,  1.2104e+00,  1.2417e+00,  1.2049e+00,
          1.2030e+00,  1.3935e+00,  1.4542e+00,  1.4269e+00,  1.3308e+00,
          1.4310e+00,  1.4244e+00,  1.4086e+00,  1.2935e+00,  1.2916e+00,
          1.3218e+00,  1.2681e+00,  1.2539e+00,  1.2325e+00,  1.3151e+00,
          1.2546e+00,  1.3579e+00,  1.2043e+00,  1.2300e+00],
        [ 1.1738e+00,  1.2007e+00,  1.2393e+00,  1.2322e+00,  1.2060e+00,
          1.1783e+00,  1.1868e+00,  1.1712e+00,  1.1712e+00,  1.2475e+00,
          1.2754e+00,  1.2634e+00,  1.3048e+00,  1.2419e+00,  1.2857e+00,
          1.2532e+00,  1.2251e+00,  1.2454e+00,  1.2252e+00,  1.2339e+00,
          1.2607e+00,  1.2379e+00,  1.1981e+00,  1.1933e+00,  1.2012e+00,
          1.1858e+00,  1.1858e+00,  2.9953e+00,  2.9669e+00,  2.6044e+00,
          2.7369e+00,  2.9923e+00,  2.6155e+00,  2.9301e+00,  2.6132e+00,
          2.6073e+00,  1.3932e+00,  1.4551e+00,  1.4275e+00,  1.3869e+00,
          1.4333e+00,  1.4261e+00,  1.4071e+00,  1.2731e+00,  1.3480e+00,
          1.3299e+00,  1.2738e+00,  1.1974e+00,  1.1897e+00,  1.3231e+00,
          1.2600e+00,  1.3664e+00,  1.1622e+00,  1.2350e+00],
        [ 1.7334e+00,  1.3538e+00,  5.7201e-01,  8.6642e-01,  1.2528e+00,
          1.6677e+00,  1.5449e+00,  1.7694e+00,  1.7694e+00,  1.5576e+00,
          1.2100e+00,  1.3993e+00,  8.4240e-01,  1.5931e+00,  9.5997e-02,
          1.4989e+00,  1.7584e+00,  7.6017e-01,  1.2590e+00,  9.4548e-01,
          7.1007e-01,  1.0798e+00,  1.6073e+00,  1.6711e+00,  1.4534e+00,
          1.7736e+00,  1.7736e+00,  8.0120e-01,  7.9048e-01,  1.7457e+00,
          1.5446e+00,  8.1560e-01,  1.6880e+00,  1.1704e+00,  1.7976e+00,
          1.7112e+00,  4.2769e-02, -1.8677e-01, -2.1785e-01, -3.2185e-03,
          2.2556e-01,  3.0340e-01, -7.1059e-02,  1.8086e+01,  3.3481e+00,
          6.8060e-01,  1.2513e+00,  1.3219e+00,  1.5480e+00,  8.8494e-01,
          1.4837e+00,  2.9371e-01,  1.6552e+00,  1.7085e+00],
        [ 1.2237e+00,  1.2606e+00,  1.3275e+00,  1.3041e+00,  1.2684e+00,
          1.2299e+00,  1.1980e+00,  1.2201e+00,  1.2201e+00,  1.1915e+00,
          1.3223e+00,  1.2132e+00,  1.3641e+00,  1.2760e+00,  1.4188e+00,
          1.1993e+00,  1.2538e+00,  1.2712e+00,  1.2854e+00,  1.2740e+00,
          1.3351e+00,  1.3026e+00,  1.2482e+00,  1.2417e+00,  1.1409e+00,
          1.2314e+00,  1.2314e+00,  1.3005e+00,  1.3459e+00,  1.2503e+00,
          1.0313e+00,  1.2561e+00,  1.1315e+00,  1.3068e+00,  1.1248e+00,
          1.2539e+00,  1.2849e+00,  9.9833e-01,  1.2816e+00,  1.2978e+00,
          8.3963e-01,  7.6718e-01,  1.3074e+00,  1.1355e+00,  6.3162e-01,
          3.5425e+00,  2.5329e+00,  3.6699e+00,  2.8400e+00,  2.1192e+00,
          1.7924e+00,  2.9771e+00,  3.4521e+00,  1.7690e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 310 : 179.0376444389233
Test loss for epoch 310 : 179.4015324291321
Test Precision for epoch 310 : 0.26153846153846155
Test Recall for epoch 310 : 0.26153846153846155
Test F1 for epoch 310 : 0.26153846153846155


theta for epoch 311 : tensor([[ 2.6975e+00,  2.7299e+00,  2.8053e+00,  2.9453e+00,  2.9082e+00,
          2.7035e+00,  2.8833e+00,  2.6953e+00,  2.6953e+00,  1.2389e+00,
          1.2657e+00,  1.2540e+00,  1.2950e+00,  1.2333e+00,  1.3348e+00,
          1.2443e+00,  1.2177e+00,  1.2490e+00,  1.2140e+00,  1.1908e+00,
          1.2046e+00,  1.2262e+00,  1.1878e+00,  1.1832e+00,  1.2024e+00,
          1.1760e+00,  1.1760e+00,  1.2211e+00,  1.2659e+00,  1.1976e+00,
          1.2213e+00,  1.2665e+00,  1.2074e+00,  1.2382e+00,  1.1573e+00,
          1.2001e+00,  1.3983e+00,  1.4577e+00,  1.4327e+00,  1.4074e+00,
          1.4369e+00,  1.3833e+00,  1.4131e+00,  1.3002e+00,  1.3705e+00,
          1.3205e+00,  1.2664e+00,  1.2525e+00,  1.2315e+00,  1.3139e+00,
          1.2531e+00,  1.3558e+00,  1.2161e+00,  1.2290e+00],
        [ 1.1966e+00,  1.2270e+00,  1.2545e+00,  1.2328e+00,  1.2331e+00,
          1.2006e+00,  1.2110e+00,  1.1924e+00,  1.1924e+00,  2.2426e+00,
          2.2421e+00,  2.1714e+00,  2.3708e+00,  2.1564e+00,  4.7360e+00,
          2.2290e+00,  2.2834e+00,  4.5159e+00,  1.2071e+00,  1.2300e+00,
          1.2008e+00,  1.2207e+00,  1.2195e+00,  1.2143e+00,  1.2346e+00,
          1.2057e+00,  1.2057e+00,  1.2606e+00,  1.2180e+00,  1.2259e+00,
          1.2543e+00,  1.2309e+00,  1.2376e+00,  1.2739e+00,  1.1870e+00,
          1.2289e+00,  1.3532e+00,  1.4264e+00,  1.3350e+00,  1.3632e+00,
          1.4008e+00,  1.4111e+00,  1.3111e+00,  1.1894e+00,  1.3164e+00,
          1.3015e+00,  1.2853e+00,  1.2683e+00,  1.2431e+00,  1.2472e+00,
          1.2693e+00,  1.2983e+00,  1.2248e+00,  1.2404e+00],
        [ 1.1669e+00,  1.1935e+00,  1.2318e+00,  1.2243e+00,  1.1985e+00,
          1.1714e+00,  1.1796e+00,  1.1644e+00,  1.1644e+00,  1.2415e+00,
          1.2688e+00,  1.2570e+00,  1.2988e+00,  1.2359e+00,  1.2932e+00,
          1.2470e+00,  1.1742e+00,  1.2975e+00,  2.7379e+00,  2.9370e+00,
          2.9442e+00,  2.7579e+00,  2.7003e+00,  2.6976e+00,  2.8879e+00,
          2.6866e+00,  2.6866e+00,  1.2157e+00,  1.2688e+00,  1.2006e+00,
          1.2235e+00,  1.2164e+00,  1.2106e+00,  1.2419e+00,  1.2050e+00,
          1.2031e+00,  1.3940e+00,  1.4547e+00,  1.4274e+00,  1.3306e+00,
          1.4317e+00,  1.4245e+00,  1.4091e+00,  1.2932e+00,  1.2918e+00,
          1.3221e+00,  1.2684e+00,  1.2541e+00,  1.2327e+00,  1.3153e+00,
          1.2548e+00,  1.3581e+00,  1.2039e+00,  1.2302e+00],
        [ 1.1739e+00,  1.2008e+00,  1.2389e+00,  1.2323e+00,  1.2061e+00,
          1.1784e+00,  1.1869e+00,  1.1712e+00,  1.1712e+00,  1.2477e+00,
          1.2755e+00,  1.2634e+00,  1.3046e+00,  1.2419e+00,  1.2865e+00,
          1.2533e+00,  1.2251e+00,  1.2464e+00,  1.2251e+00,  1.2332e+00,
          1.2605e+00,  1.2377e+00,  1.1980e+00,  1.1932e+00,  1.2005e+00,
          1.1857e+00,  1.1857e+00,  2.9947e+00,  2.9655e+00,  2.6049e+00,
          2.7352e+00,  2.9918e+00,  2.6159e+00,  2.9286e+00,  2.6136e+00,
          2.6077e+00,  1.3935e+00,  1.4554e+00,  1.4278e+00,  1.3865e+00,
          1.4337e+00,  1.4260e+00,  1.4073e+00,  1.2738e+00,  1.3480e+00,
          1.3300e+00,  1.2739e+00,  1.1985e+00,  1.1898e+00,  1.3232e+00,
          1.2601e+00,  1.3665e+00,  1.1616e+00,  1.2351e+00],
        [ 1.7342e+00,  1.3546e+00,  5.7270e-01,  8.6661e-01,  1.2536e+00,
          1.6683e+00,  1.5454e+00,  1.7700e+00,  1.7700e+00,  1.5574e+00,
          1.2102e+00,  1.4002e+00,  8.4340e-01,  1.5940e+00,  9.6535e-02,
          1.4989e+00,  1.7591e+00,  7.6036e-01,  1.2595e+00,  9.4663e-01,
          7.1073e-01,  1.0802e+00,  1.6077e+00,  1.6715e+00,  1.4542e+00,
          1.7739e+00,  1.7739e+00,  8.0206e-01,  7.9085e-01,  1.7461e+00,
          1.5447e+00,  8.1585e-01,  1.6885e+00,  1.1707e+00,  1.7981e+00,
          1.7116e+00,  4.1324e-02, -1.8803e-01, -2.1920e-01, -5.0071e-03,
          2.2390e-01,  3.0123e-01, -7.2428e-02,  1.8159e+01,  3.2801e+00,
          6.8085e-01,  1.2513e+00,  1.3213e+00,  1.5478e+00,  8.8500e-01,
          1.4836e+00,  2.9417e-01,  1.6559e+00,  1.7082e+00],
        [ 1.2238e+00,  1.2607e+00,  1.3276e+00,  1.3042e+00,  1.2686e+00,
          1.2300e+00,  1.1982e+00,  1.2202e+00,  1.2202e+00,  1.1918e+00,
          1.3224e+00,  1.2133e+00,  1.3641e+00,  1.2761e+00,  1.4190e+00,
          1.1995e+00,  1.2538e+00,  1.2714e+00,  1.2853e+00,  1.2737e+00,
          1.3350e+00,  1.3025e+00,  1.2481e+00,  1.2415e+00,  1.1406e+00,
          1.2312e+00,  1.2312e+00,  1.3006e+00,  1.3460e+00,  1.2502e+00,
          1.0312e+00,  1.2562e+00,  1.1314e+00,  1.3069e+00,  1.1247e+00,
          1.2538e+00,  1.2840e+00,  9.9766e-01,  1.2805e+00,  1.2970e+00,
          8.3883e-01,  7.6653e-01,  1.3065e+00,  1.1332e+00,  6.3110e-01,
          3.5446e+00,  2.5311e+00,  3.6686e+00,  2.8379e+00,  2.1180e+00,
          1.7913e+00,  2.9753e+00,  3.4542e+00,  1.7679e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 311 : 179.01704999392103
Test loss for epoch 311 : 179.38832606626048
Test Precision for epoch 311 : 0.26153846153846155
Test Recall for epoch 311 : 0.26153846153846155
Test F1 for epoch 311 : 0.26153846153846155


theta for epoch 312 : tensor([[ 2.6972e+00,  2.7296e+00,  2.8050e+00,  2.9450e+00,  2.9079e+00,
          2.7031e+00,  2.8829e+00,  2.6949e+00,  2.6949e+00,  1.2388e+00,
          1.2654e+00,  1.2538e+00,  1.2946e+00,  1.2331e+00,  1.3344e+00,
          1.2441e+00,  1.2175e+00,  1.2488e+00,  1.2141e+00,  1.1909e+00,
          1.2047e+00,  1.2264e+00,  1.1879e+00,  1.1834e+00,  1.2025e+00,
          1.1761e+00,  1.1761e+00,  1.2212e+00,  1.2660e+00,  1.1977e+00,
          1.2215e+00,  1.2666e+00,  1.2075e+00,  1.2383e+00,  1.1574e+00,
          1.2002e+00,  1.3986e+00,  1.4580e+00,  1.4330e+00,  1.4077e+00,
          1.4373e+00,  1.3838e+00,  1.4134e+00,  1.2998e+00,  1.3711e+00,
          1.3209e+00,  1.2668e+00,  1.2528e+00,  1.2318e+00,  1.3142e+00,
          1.2534e+00,  1.3562e+00,  1.2163e+00,  1.2293e+00],
        [ 1.1956e+00,  1.2261e+00,  1.2552e+00,  1.2333e+00,  1.2323e+00,
          1.1998e+00,  1.2107e+00,  1.1917e+00,  1.1917e+00,  2.2508e+00,
          2.2517e+00,  2.1802e+00,  2.3815e+00,  2.1641e+00,  4.7008e+00,
          2.2375e+00,  2.2973e+00,  4.4801e+00,  1.2068e+00,  1.2295e+00,
          1.2003e+00,  1.2211e+00,  1.2189e+00,  1.2136e+00,  1.2346e+00,
          1.2050e+00,  1.2050e+00,  1.2601e+00,  1.2175e+00,  1.2252e+00,
          1.2538e+00,  1.2318e+00,  1.2369e+00,  1.2732e+00,  1.1864e+00,
          1.2282e+00,  1.3530e+00,  1.4262e+00,  1.3349e+00,  1.3634e+00,
          1.4007e+00,  1.4112e+00,  1.3110e+00,  1.1928e+00,  1.3168e+00,
          1.3011e+00,  1.2849e+00,  1.2679e+00,  1.2427e+00,  1.2470e+00,
          1.2689e+00,  1.2976e+00,  1.2243e+00,  1.2400e+00],
        [ 1.1670e+00,  1.1935e+00,  1.2313e+00,  1.2243e+00,  1.1985e+00,
          1.1715e+00,  1.1797e+00,  1.1644e+00,  1.1644e+00,  1.2415e+00,
          1.2686e+00,  1.2568e+00,  1.2984e+00,  1.2357e+00,  1.2927e+00,
          1.2469e+00,  1.1738e+00,  1.2973e+00,  2.7373e+00,  2.9379e+00,
          2.9441e+00,  2.7571e+00,  2.6997e+00,  2.6968e+00,  2.8889e+00,
          2.6860e+00,  2.6860e+00,  1.2153e+00,  1.2689e+00,  1.2007e+00,
          1.2237e+00,  1.2160e+00,  1.2107e+00,  1.2421e+00,  1.2051e+00,
          1.2033e+00,  1.3944e+00,  1.4552e+00,  1.4278e+00,  1.3304e+00,
          1.4322e+00,  1.4245e+00,  1.4095e+00,  1.2929e+00,  1.2919e+00,
          1.3224e+00,  1.2688e+00,  1.2545e+00,  1.2331e+00,  1.3156e+00,
          1.2551e+00,  1.3584e+00,  1.2036e+00,  1.2305e+00],
        [ 1.1738e+00,  1.2007e+00,  1.2383e+00,  1.2322e+00,  1.2060e+00,
          1.1783e+00,  1.1869e+00,  1.1712e+00,  1.1712e+00,  1.2475e+00,
          1.2751e+00,  1.2631e+00,  1.3040e+00,  1.2416e+00,  1.2869e+00,
          1.2530e+00,  1.2247e+00,  1.2469e+00,  1.2251e+00,  1.2326e+00,
          1.2605e+00,  1.2378e+00,  1.1980e+00,  1.1932e+00,  1.2001e+00,
          1.1857e+00,  1.1857e+00,  2.9942e+00,  2.9641e+00,  2.6054e+00,
          2.7336e+00,  2.9913e+00,  2.6165e+00,  2.9272e+00,  2.6142e+00,
          2.6082e+00,  1.3937e+00,  1.4557e+00,  1.4279e+00,  1.3861e+00,
          1.4340e+00,  1.4258e+00,  1.4074e+00,  1.2745e+00,  1.3479e+00,
          1.3302e+00,  1.2741e+00,  1.1996e+00,  1.1899e+00,  1.3234e+00,
          1.2602e+00,  1.3668e+00,  1.1611e+00,  1.2352e+00],
        [ 1.7350e+00,  1.3553e+00,  5.7332e-01,  8.6671e-01,  1.2542e+00,
          1.6688e+00,  1.5457e+00,  1.7705e+00,  1.7705e+00,  1.5570e+00,
          1.2101e+00,  1.4008e+00,  8.4413e-01,  1.5946e+00,  9.6908e-02,
          1.4988e+00,  1.7596e+00,  7.6031e-01,  1.2603e+00,  9.4797e-01,
          7.1162e-01,  1.0809e+00,  1.6083e+00,  1.6721e+00,  1.4554e+00,
          1.7745e+00,  1.7745e+00,  8.0301e-01,  7.9135e-01,  1.7466e+00,
          1.5450e+00,  8.1617e-01,  1.6890e+00,  1.1710e+00,  1.7986e+00,
          1.7121e+00,  3.9880e-02, -1.8928e-01, -2.2054e-01, -6.8191e-03,
          2.2226e-01,  2.9910e-01, -7.3799e-02,  1.8233e+01,  3.2123e+00,
          6.8140e-01,  1.2516e+00,  1.3211e+00,  1.5478e+00,  8.8537e-01,
          1.4837e+00,  2.9489e-01,  1.6567e+00,  1.7082e+00],
        [ 1.2236e+00,  1.2606e+00,  1.3275e+00,  1.3042e+00,  1.2685e+00,
          1.2299e+00,  1.1981e+00,  1.2201e+00,  1.2201e+00,  1.1917e+00,
          1.3221e+00,  1.2129e+00,  1.3636e+00,  1.2757e+00,  1.4187e+00,
          1.1992e+00,  1.2533e+00,  1.2712e+00,  1.2853e+00,  1.2735e+00,
          1.3351e+00,  1.3026e+00,  1.2481e+00,  1.2415e+00,  1.1403e+00,
          1.2312e+00,  1.2312e+00,  1.3006e+00,  1.3460e+00,  1.2501e+00,
          1.0311e+00,  1.2562e+00,  1.1314e+00,  1.3070e+00,  1.1246e+00,
          1.2538e+00,  1.2830e+00,  9.9689e-01,  1.2794e+00,  1.2962e+00,
          8.3792e-01,  7.6577e-01,  1.3056e+00,  1.1310e+00,  6.3051e-01,
          3.5470e+00,  2.5296e+00,  3.6676e+00,  2.8361e+00,  2.1171e+00,
          1.7905e+00,  2.9737e+00,  3.4565e+00,  1.7670e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 312 : 178.99665467560052
Test loss for epoch 312 : 179.37515815216278
Test Precision for epoch 312 : 0.26153846153846155
Test Recall for epoch 312 : 0.26153846153846155
Test F1 for epoch 312 : 0.26153846153846155


theta for epoch 313 : tensor([[ 2.6968e+00,  2.7292e+00,  2.8047e+00,  2.9447e+00,  2.9075e+00,
          2.7027e+00,  2.8826e+00,  2.6945e+00,  2.6945e+00,  1.2387e+00,
          1.2652e+00,  1.2535e+00,  1.2943e+00,  1.2328e+00,  1.3342e+00,
          1.2439e+00,  1.2172e+00,  1.2486e+00,  1.2142e+00,  1.1910e+00,
          1.2048e+00,  1.2265e+00,  1.1881e+00,  1.1835e+00,  1.2026e+00,
          1.1762e+00,  1.1762e+00,  1.2212e+00,  1.2661e+00,  1.1978e+00,
          1.2217e+00,  1.2667e+00,  1.2076e+00,  1.2385e+00,  1.1574e+00,
          1.2003e+00,  1.3989e+00,  1.4584e+00,  1.4334e+00,  1.4082e+00,
          1.4377e+00,  1.3844e+00,  1.4137e+00,  1.2995e+00,  1.3719e+00,
          1.3211e+00,  1.2670e+00,  1.2531e+00,  1.2320e+00,  1.3145e+00,
          1.2536e+00,  1.3564e+00,  1.2164e+00,  1.2295e+00],
        [ 1.1946e+00,  1.2251e+00,  1.2557e+00,  1.2338e+00,  1.2315e+00,
          1.1991e+00,  1.2102e+00,  1.1909e+00,  1.1909e+00,  2.2588e+00,
          2.2611e+00,  2.1891e+00,  2.3925e+00,  2.1718e+00,  4.6658e+00,
          2.2460e+00,  2.3112e+00,  4.4447e+00,  1.2063e+00,  1.2291e+00,
          1.1998e+00,  1.2212e+00,  1.2184e+00,  1.2129e+00,  1.2345e+00,
          1.2043e+00,  1.2043e+00,  1.2596e+00,  1.2168e+00,  1.2246e+00,
          1.2533e+00,  1.2327e+00,  1.2363e+00,  1.2727e+00,  1.1859e+00,
          1.2276e+00,  1.3530e+00,  1.4261e+00,  1.3348e+00,  1.3636e+00,
          1.4007e+00,  1.4113e+00,  1.3110e+00,  1.1958e+00,  1.3174e+00,
          1.3004e+00,  1.2844e+00,  1.2675e+00,  1.2423e+00,  1.2466e+00,
          1.2684e+00,  1.2968e+00,  1.2237e+00,  1.2395e+00],
        [ 1.1671e+00,  1.1935e+00,  1.2309e+00,  1.2243e+00,  1.1985e+00,
          1.1715e+00,  1.1798e+00,  1.1645e+00,  1.1645e+00,  1.2414e+00,
          1.2685e+00,  1.2566e+00,  1.2981e+00,  1.2355e+00,  1.2924e+00,
          1.2468e+00,  1.1735e+00,  1.2971e+00,  2.7366e+00,  2.9389e+00,
          2.9440e+00,  2.7562e+00,  2.6991e+00,  2.6960e+00,  2.8899e+00,
          2.6854e+00,  2.6854e+00,  1.2148e+00,  1.2689e+00,  1.2008e+00,
          1.2239e+00,  1.2155e+00,  1.2108e+00,  1.2423e+00,  1.2052e+00,
          1.2034e+00,  1.3948e+00,  1.4556e+00,  1.4283e+00,  1.3302e+00,
          1.4327e+00,  1.4245e+00,  1.4099e+00,  1.2928e+00,  1.2920e+00,
          1.3227e+00,  1.2691e+00,  1.2548e+00,  1.2334e+00,  1.3158e+00,
          1.2554e+00,  1.3587e+00,  1.2033e+00,  1.2308e+00],
        [ 1.1737e+00,  1.2006e+00,  1.2377e+00,  1.2321e+00,  1.2059e+00,
          1.1782e+00,  1.1868e+00,  1.1711e+00,  1.1711e+00,  1.2473e+00,
          1.2748e+00,  1.2627e+00,  1.3035e+00,  1.2413e+00,  1.2872e+00,
          1.2528e+00,  1.2244e+00,  1.2474e+00,  1.2251e+00,  1.2320e+00,
          1.2605e+00,  1.2378e+00,  1.1980e+00,  1.1933e+00,  1.1996e+00,
          1.1858e+00,  1.1858e+00,  2.9938e+00,  2.9628e+00,  2.6059e+00,
          2.7320e+00,  2.9908e+00,  2.6170e+00,  2.9257e+00,  2.6149e+00,
          2.6088e+00,  1.3939e+00,  1.4559e+00,  1.4281e+00,  1.3858e+00,
          1.4343e+00,  1.4255e+00,  1.4075e+00,  1.2751e+00,  1.3479e+00,
          1.3303e+00,  1.2742e+00,  1.2006e+00,  1.1900e+00,  1.3235e+00,
          1.2603e+00,  1.3670e+00,  1.1606e+00,  1.2353e+00],
        [ 1.7356e+00,  1.3559e+00,  5.7388e-01,  8.6674e-01,  1.2547e+00,
          1.6693e+00,  1.5461e+00,  1.7710e+00,  1.7710e+00,  1.5566e+00,
          1.2101e+00,  1.4016e+00,  8.4483e-01,  1.5954e+00,  9.7245e-02,
          1.4986e+00,  1.7600e+00,  7.6024e-01,  1.2611e+00,  9.4925e-01,
          7.1244e-01,  1.0816e+00,  1.6089e+00,  1.6726e+00,  1.4566e+00,
          1.7751e+00,  1.7751e+00,  8.0390e-01,  7.9182e-01,  1.7470e+00,
          1.5452e+00,  8.1641e-01,  1.6895e+00,  1.1714e+00,  1.7990e+00,
          1.7126e+00,  3.8533e-02, -1.9045e-01, -2.2179e-01, -8.5524e-03,
          2.2074e-01,  2.9709e-01, -7.5079e-02,  1.8307e+01,  3.1450e+00,
          6.8178e-01,  1.2517e+00,  1.3207e+00,  1.5477e+00,  8.8560e-01,
          1.4837e+00,  2.9546e-01,  1.6574e+00,  1.7081e+00],
        [ 1.2235e+00,  1.2605e+00,  1.3274e+00,  1.3042e+00,  1.2684e+00,
          1.2298e+00,  1.1980e+00,  1.2199e+00,  1.2199e+00,  1.1916e+00,
          1.3219e+00,  1.2127e+00,  1.3633e+00,  1.2755e+00,  1.4186e+00,
          1.1991e+00,  1.2530e+00,  1.2711e+00,  1.2854e+00,  1.2733e+00,
          1.3352e+00,  1.3027e+00,  1.2482e+00,  1.2416e+00,  1.1402e+00,
          1.2312e+00,  1.2312e+00,  1.3006e+00,  1.3461e+00,  1.2501e+00,
          1.0311e+00,  1.2562e+00,  1.1314e+00,  1.3071e+00,  1.1246e+00,
          1.2537e+00,  1.2821e+00,  9.9624e-01,  1.2785e+00,  1.2955e+00,
          8.3716e-01,  7.6516e-01,  1.3047e+00,  1.1291e+00,  6.3011e-01,
          3.5492e+00,  2.5279e+00,  3.6663e+00,  2.8341e+00,  2.1160e+00,
          1.7896e+00,  2.9720e+00,  3.4587e+00,  1.7661e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 313 : 178.97651507794802
Test loss for epoch 313 : 179.36242919931055
Test Precision for epoch 313 : 0.26153846153846155
Test Recall for epoch 313 : 0.26153846153846155
Test F1 for epoch 313 : 0.26153846153846155


theta for epoch 314 : tensor([[ 2.6966e+00,  2.7291e+00,  2.8046e+00,  2.9446e+00,  2.9074e+00,
          2.7025e+00,  2.8825e+00,  2.6943e+00,  2.6943e+00,  1.2388e+00,
          1.2652e+00,  1.2535e+00,  1.2941e+00,  1.2328e+00,  1.3341e+00,
          1.2440e+00,  1.2172e+00,  1.2486e+00,  1.2141e+00,  1.1908e+00,
          1.2046e+00,  1.2263e+00,  1.1880e+00,  1.1834e+00,  1.2025e+00,
          1.1761e+00,  1.1761e+00,  1.2211e+00,  1.2660e+00,  1.1977e+00,
          1.2217e+00,  1.2666e+00,  1.2075e+00,  1.2384e+00,  1.1573e+00,
          1.2002e+00,  1.3991e+00,  1.4587e+00,  1.4336e+00,  1.4085e+00,
          1.4380e+00,  1.3848e+00,  1.4139e+00,  1.2992e+00,  1.3725e+00,
          1.3212e+00,  1.2671e+00,  1.2532e+00,  1.2321e+00,  1.3146e+00,
          1.2537e+00,  1.3566e+00,  1.2163e+00,  1.2295e+00],
        [ 1.1936e+00,  1.2241e+00,  1.2560e+00,  1.2343e+00,  1.2308e+00,
          1.1984e+00,  1.2096e+00,  1.1902e+00,  1.1902e+00,  2.2669e+00,
          2.2707e+00,  2.1982e+00,  2.4038e+00,  2.1799e+00,  4.6313e+00,
          2.2547e+00,  2.3252e+00,  4.4098e+00,  1.2056e+00,  1.2284e+00,
          1.1991e+00,  1.2209e+00,  1.2176e+00,  1.2120e+00,  1.2340e+00,
          1.2035e+00,  1.2035e+00,  1.2590e+00,  1.2157e+00,  1.2238e+00,
          1.2526e+00,  1.2334e+00,  1.2355e+00,  1.2719e+00,  1.1852e+00,
          1.2269e+00,  1.3529e+00,  1.4259e+00,  1.3347e+00,  1.3637e+00,
          1.4007e+00,  1.4114e+00,  1.3109e+00,  1.1984e+00,  1.3179e+00,
          1.2996e+00,  1.2838e+00,  1.2670e+00,  1.2417e+00,  1.2459e+00,
          1.2679e+00,  1.2957e+00,  1.2231e+00,  1.2389e+00],
        [ 1.1672e+00,  1.1937e+00,  1.2305e+00,  1.2244e+00,  1.1987e+00,
          1.1717e+00,  1.1799e+00,  1.1647e+00,  1.1647e+00,  1.2417e+00,
          1.2686e+00,  1.2567e+00,  1.2980e+00,  1.2356e+00,  1.2923e+00,
          1.2470e+00,  1.1735e+00,  1.2972e+00,  2.7358e+00,  2.9398e+00,
          2.9437e+00,  2.7552e+00,  2.6984e+00,  2.6951e+00,  2.8908e+00,
          2.6846e+00,  2.6846e+00,  1.2144e+00,  1.2689e+00,  1.2009e+00,
          1.2241e+00,  1.2151e+00,  1.2109e+00,  1.2424e+00,  1.2053e+00,
          1.2035e+00,  1.3952e+00,  1.4561e+00,  1.4287e+00,  1.3299e+00,
          1.4332e+00,  1.4245e+00,  1.4103e+00,  1.2926e+00,  1.2921e+00,
          1.3230e+00,  1.2693e+00,  1.2551e+00,  1.2336e+00,  1.3160e+00,
          1.2557e+00,  1.3589e+00,  1.2029e+00,  1.2310e+00],
        [ 1.1736e+00,  1.2006e+00,  1.2371e+00,  1.2320e+00,  1.2059e+00,
          1.1782e+00,  1.1868e+00,  1.1711e+00,  1.1711e+00,  1.2474e+00,
          1.2748e+00,  1.2627e+00,  1.3032e+00,  1.2412e+00,  1.2878e+00,
          1.2528e+00,  1.2243e+00,  1.2481e+00,  1.2250e+00,  1.2313e+00,
          1.2603e+00,  1.2376e+00,  1.1979e+00,  1.1931e+00,  1.1989e+00,
          1.1856e+00,  1.1856e+00,  2.9933e+00,  2.9614e+00,  2.6065e+00,
          2.7304e+00,  2.9904e+00,  2.6176e+00,  2.9242e+00,  2.6156e+00,
          2.6093e+00,  1.3941e+00,  1.4561e+00,  1.4282e+00,  1.3854e+00,
          1.4346e+00,  1.4253e+00,  1.4076e+00,  1.2758e+00,  1.3478e+00,
          1.3304e+00,  1.2743e+00,  1.2014e+00,  1.1900e+00,  1.3236e+00,
          1.2604e+00,  1.3671e+00,  1.1600e+00,  1.2353e+00],
        [ 1.7365e+00,  1.3567e+00,  5.7462e-01,  8.6695e-01,  1.2555e+00,
          1.6699e+00,  1.5468e+00,  1.7715e+00,  1.7715e+00,  1.5567e+00,
          1.2104e+00,  1.4027e+00,  8.4589e-01,  1.5965e+00,  9.7927e-02,
          1.4988e+00,  1.7609e+00,  7.6058e-01,  1.2618e+00,  9.5048e-01,
          7.1325e-01,  1.0823e+00,  1.6094e+00,  1.6731e+00,  1.4578e+00,
          1.7755e+00,  1.7755e+00,  8.0487e-01,  7.9239e-01,  1.7475e+00,
          1.5455e+00,  8.1670e-01,  1.6899e+00,  1.1718e+00,  1.7994e+00,
          1.7130e+00,  3.7077e-02, -1.9173e-01, -2.2315e-01, -1.0405e-02,
          2.1912e-01,  2.9499e-01, -7.6469e-02,  1.8380e+01,  3.0779e+00,
          6.8228e-01,  1.2519e+00,  1.3204e+00,  1.5477e+00,  8.8592e-01,
          1.4838e+00,  2.9619e-01,  1.6581e+00,  1.7079e+00],
        [ 1.2235e+00,  1.2605e+00,  1.3274e+00,  1.3043e+00,  1.2685e+00,
          1.2298e+00,  1.1981e+00,  1.2199e+00,  1.2199e+00,  1.1919e+00,
          1.3221e+00,  1.2127e+00,  1.3632e+00,  1.2755e+00,  1.4187e+00,
          1.1993e+00,  1.2530e+00,  1.2713e+00,  1.2853e+00,  1.2730e+00,
          1.3351e+00,  1.3026e+00,  1.2481e+00,  1.2414e+00,  1.1399e+00,
          1.2311e+00,  1.2311e+00,  1.3006e+00,  1.3461e+00,  1.2499e+00,
          1.0310e+00,  1.2562e+00,  1.1313e+00,  1.3071e+00,  1.1245e+00,
          1.2536e+00,  1.2812e+00,  9.9554e-01,  1.2775e+00,  1.2948e+00,
          8.3635e-01,  7.6451e-01,  1.3039e+00,  1.1273e+00,  6.2970e-01,
          3.5514e+00,  2.5263e+00,  3.6651e+00,  2.8322e+00,  2.1150e+00,
          1.7887e+00,  2.9703e+00,  3.4608e+00,  1.7652e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 314 : 178.9566283363882
Test loss for epoch 314 : 179.3498201132056
Test Precision for epoch 314 : 0.26153846153846155
Test Recall for epoch 314 : 0.26153846153846155
Test F1 for epoch 314 : 0.26153846153846155


theta for epoch 315 : tensor([[ 2.6964e+00,  2.7289e+00,  2.8044e+00,  2.9444e+00,  2.9072e+00,
          2.7023e+00,  2.8824e+00,  2.6941e+00,  2.6941e+00,  1.2387e+00,
          1.2650e+00,  1.2532e+00,  1.2937e+00,  1.2325e+00,  1.3337e+00,
          1.2438e+00,  1.2170e+00,  1.2484e+00,  1.2141e+00,  1.1907e+00,
          1.2045e+00,  1.2263e+00,  1.1880e+00,  1.1834e+00,  1.2024e+00,
          1.1761e+00,  1.1761e+00,  1.2211e+00,  1.2660e+00,  1.1977e+00,
          1.2217e+00,  1.2666e+00,  1.2075e+00,  1.2385e+00,  1.1573e+00,
          1.2002e+00,  1.3994e+00,  1.4590e+00,  1.4338e+00,  1.4089e+00,
          1.4383e+00,  1.3852e+00,  1.4141e+00,  1.2989e+00,  1.3732e+00,
          1.3214e+00,  1.2673e+00,  1.2533e+00,  1.2322e+00,  1.3147e+00,
          1.2539e+00,  1.3568e+00,  1.2163e+00,  1.2296e+00],
        [ 1.1926e+00,  1.2232e+00,  1.2563e+00,  1.2349e+00,  1.2301e+00,
          1.1978e+00,  1.2090e+00,  1.1896e+00,  1.1896e+00,  2.2746e+00,
          2.2798e+00,  2.2070e+00,  2.4150e+00,  2.1877e+00,  4.5968e+00,
          2.2630e+00,  2.3388e+00,  4.3750e+00,  1.2051e+00,  1.2279e+00,
          1.1987e+00,  1.2206e+00,  1.2170e+00,  1.2114e+00,  1.2335e+00,
          1.2028e+00,  1.2028e+00,  1.2585e+00,  1.2147e+00,  1.2233e+00,
          1.2521e+00,  1.2342e+00,  1.2350e+00,  1.2714e+00,  1.1847e+00,
          1.2263e+00,  1.3529e+00,  1.4259e+00,  1.3348e+00,  1.3638e+00,
          1.4007e+00,  1.4116e+00,  1.3109e+00,  1.2007e+00,  1.3186e+00,
          1.2989e+00,  1.2835e+00,  1.2666e+00,  1.2414e+00,  1.2452e+00,
          1.2675e+00,  1.2948e+00,  1.2226e+00,  1.2385e+00],
        [ 1.1672e+00,  1.1937e+00,  1.2300e+00,  1.2245e+00,  1.1987e+00,
          1.1717e+00,  1.1800e+00,  1.1647e+00,  1.1647e+00,  1.2416e+00,
          1.2685e+00,  1.2565e+00,  1.2977e+00,  1.2354e+00,  1.2919e+00,
          1.2469e+00,  1.1732e+00,  1.2970e+00,  2.7352e+00,  2.9408e+00,
          2.9436e+00,  2.7543e+00,  2.6978e+00,  2.6943e+00,  2.8918e+00,
          2.6841e+00,  2.6841e+00,  1.2139e+00,  1.2689e+00,  1.2009e+00,
          1.2242e+00,  1.2146e+00,  1.2110e+00,  1.2425e+00,  1.2053e+00,
          1.2035e+00,  1.3955e+00,  1.4564e+00,  1.4290e+00,  1.3297e+00,
          1.4336e+00,  1.4244e+00,  1.4106e+00,  1.2925e+00,  1.2922e+00,
          1.3233e+00,  1.2696e+00,  1.2554e+00,  1.2338e+00,  1.3162e+00,
          1.2559e+00,  1.3591e+00,  1.2026e+00,  1.2312e+00],
        [ 1.1735e+00,  1.2005e+00,  1.2365e+00,  1.2319e+00,  1.2058e+00,
          1.1781e+00,  1.1867e+00,  1.1710e+00,  1.1710e+00,  1.2472e+00,
          1.2745e+00,  1.2623e+00,  1.3027e+00,  1.2409e+00,  1.2881e+00,
          1.2526e+00,  1.2241e+00,  1.2485e+00,  1.2249e+00,  1.2306e+00,
          1.2602e+00,  1.2375e+00,  1.1978e+00,  1.1930e+00,  1.1983e+00,
          1.1855e+00,  1.1855e+00,  2.9929e+00,  2.9600e+00,  2.6071e+00,
          2.7288e+00,  2.9900e+00,  2.6183e+00,  2.9227e+00,  2.6163e+00,
          2.6100e+00,  1.3942e+00,  1.4564e+00,  1.4282e+00,  1.3850e+00,
          1.4349e+00,  1.4250e+00,  1.4076e+00,  1.2765e+00,  1.3478e+00,
          1.3305e+00,  1.2744e+00,  1.2023e+00,  1.1900e+00,  1.3237e+00,
          1.2605e+00,  1.3672e+00,  1.1594e+00,  1.2353e+00],
        [ 1.7372e+00,  1.3574e+00,  5.7530e-01,  8.6709e-01,  1.2562e+00,
          1.6704e+00,  1.5474e+00,  1.7721e+00,  1.7721e+00,  1.5567e+00,
          1.2105e+00,  1.4036e+00,  8.4673e-01,  1.5974e+00,  9.8439e-02,
          1.4987e+00,  1.7615e+00,  7.6070e-01,  1.2626e+00,  9.5180e-01,
          7.1416e-01,  1.0832e+00,  1.6100e+00,  1.6737e+00,  1.4592e+00,
          1.7761e+00,  1.7761e+00,  8.0591e-01,  7.9303e-01,  1.7480e+00,
          1.5459e+00,  8.1704e-01,  1.6905e+00,  1.1723e+00,  1.7999e+00,
          1.7135e+00,  3.5638e-02, -1.9300e-01, -2.2448e-01, -1.2246e-02,
          2.1753e-01,  2.9293e-01, -7.7843e-02,  1.8454e+01,  3.0113e+00,
          6.8290e-01,  1.2522e+00,  1.3202e+00,  1.5477e+00,  8.8637e-01,
          1.4839e+00,  2.9704e-01,  1.6589e+00,  1.7079e+00],
        [ 1.2233e+00,  1.2605e+00,  1.3274e+00,  1.3042e+00,  1.2684e+00,
          1.2297e+00,  1.1980e+00,  1.2198e+00,  1.2198e+00,  1.1918e+00,
          1.3219e+00,  1.2125e+00,  1.3629e+00,  1.2752e+00,  1.4185e+00,
          1.1992e+00,  1.2527e+00,  1.2712e+00,  1.2852e+00,  1.2728e+00,
          1.3351e+00,  1.3025e+00,  1.2480e+00,  1.2414e+00,  1.1396e+00,
          1.2310e+00,  1.2310e+00,  1.3005e+00,  1.3461e+00,  1.2498e+00,
          1.0309e+00,  1.2561e+00,  1.1312e+00,  1.3072e+00,  1.1243e+00,
          1.2535e+00,  1.2803e+00,  9.9483e-01,  1.2765e+00,  1.2941e+00,
          8.3554e-01,  7.6384e-01,  1.3030e+00,  1.1257e+00,  6.2932e-01,
          3.5536e+00,  2.5249e+00,  3.6639e+00,  2.8304e+00,  2.1142e+00,
          1.7881e+00,  2.9687e+00,  3.4631e+00,  1.7645e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 315 : 178.93702732629663
Test loss for epoch 315 : 179.3374740508865
Test Precision for epoch 315 : 0.26153846153846155
Test Recall for epoch 315 : 0.26153846153846155
Test F1 for epoch 315 : 0.26153846153846155


theta for epoch 316 : tensor([[ 2.6962e+00,  2.7287e+00,  2.8042e+00,  2.9442e+00,  2.9070e+00,
          2.7020e+00,  2.8821e+00,  2.6938e+00,  2.6938e+00,  1.2386e+00,
          1.2648e+00,  1.2529e+00,  1.2933e+00,  1.2323e+00,  1.3334e+00,
          1.2436e+00,  1.2168e+00,  1.2482e+00,  1.2141e+00,  1.1907e+00,
          1.2046e+00,  1.2263e+00,  1.1880e+00,  1.1834e+00,  1.2024e+00,
          1.1762e+00,  1.1762e+00,  1.2212e+00,  1.2660e+00,  1.1977e+00,
          1.2218e+00,  1.2666e+00,  1.2076e+00,  1.2386e+00,  1.1574e+00,
          1.2003e+00,  1.3996e+00,  1.4593e+00,  1.4341e+00,  1.4093e+00,
          1.4387e+00,  1.3857e+00,  1.4144e+00,  1.2988e+00,  1.3740e+00,
          1.3215e+00,  1.2675e+00,  1.2535e+00,  1.2323e+00,  1.3149e+00,
          1.2540e+00,  1.3570e+00,  1.2164e+00,  1.2297e+00],
        [ 1.1917e+00,  1.2222e+00,  1.2564e+00,  1.2354e+00,  1.2293e+00,
          1.1971e+00,  1.2083e+00,  1.1889e+00,  1.1889e+00,  2.2821e+00,
          2.2887e+00,  2.2157e+00,  2.4263e+00,  2.1955e+00,  4.5626e+00,
          2.2711e+00,  2.3522e+00,  4.3405e+00,  1.2045e+00,  1.2275e+00,
          1.1983e+00,  1.2201e+00,  1.2166e+00,  1.2109e+00,  1.2331e+00,
          1.2023e+00,  1.2023e+00,  1.2580e+00,  1.2137e+00,  1.2228e+00,
          1.2517e+00,  1.2351e+00,  1.2345e+00,  1.2709e+00,  1.1843e+00,
          1.2258e+00,  1.3529e+00,  1.4259e+00,  1.3349e+00,  1.3639e+00,
          1.4009e+00,  1.4119e+00,  1.3111e+00,  1.2028e+00,  1.3194e+00,
          1.2982e+00,  1.2831e+00,  1.2663e+00,  1.2410e+00,  1.2445e+00,
          1.2671e+00,  1.2940e+00,  1.2222e+00,  1.2381e+00],
        [ 1.1672e+00,  1.1936e+00,  1.2295e+00,  1.2244e+00,  1.1986e+00,
          1.1717e+00,  1.1799e+00,  1.1647e+00,  1.1647e+00,  1.2415e+00,
          1.2682e+00,  1.2562e+00,  1.2974e+00,  1.2352e+00,  1.2914e+00,
          1.2467e+00,  1.1728e+00,  1.2967e+00,  2.7346e+00,  2.9419e+00,
          2.9436e+00,  2.7536e+00,  2.6973e+00,  2.6936e+00,  2.8929e+00,
          2.6836e+00,  2.6836e+00,  1.2134e+00,  1.2688e+00,  1.2010e+00,
          1.2243e+00,  1.2141e+00,  1.2110e+00,  1.2426e+00,  1.2054e+00,
          1.2036e+00,  1.3958e+00,  1.4568e+00,  1.4293e+00,  1.3294e+00,
          1.4340e+00,  1.4243e+00,  1.4109e+00,  1.2925e+00,  1.2923e+00,
          1.3235e+00,  1.2698e+00,  1.2555e+00,  1.2339e+00,  1.3163e+00,
          1.2560e+00,  1.3592e+00,  1.2022e+00,  1.2313e+00],
        [ 1.1734e+00,  1.2003e+00,  1.2358e+00,  1.2318e+00,  1.2056e+00,
          1.1780e+00,  1.1866e+00,  1.1708e+00,  1.1708e+00,  1.2470e+00,
          1.2743e+00,  1.2620e+00,  1.3022e+00,  1.2405e+00,  1.2882e+00,
          1.2523e+00,  1.2237e+00,  1.2487e+00,  1.2248e+00,  1.2299e+00,
          1.2602e+00,  1.2374e+00,  1.1978e+00,  1.1930e+00,  1.1978e+00,
          1.1855e+00,  1.1855e+00,  2.9925e+00,  2.9586e+00,  2.6078e+00,
          2.7271e+00,  2.9896e+00,  2.6189e+00,  2.9212e+00,  2.6171e+00,
          2.6106e+00,  1.3944e+00,  1.4566e+00,  1.4283e+00,  1.3846e+00,
          1.4351e+00,  1.4247e+00,  1.4077e+00,  1.2772e+00,  1.3477e+00,
          1.3306e+00,  1.2745e+00,  1.2031e+00,  1.1901e+00,  1.3238e+00,
          1.2605e+00,  1.3674e+00,  1.1588e+00,  1.2354e+00],
        [ 1.7379e+00,  1.3580e+00,  5.7584e-01,  8.6713e-01,  1.2568e+00,
          1.6709e+00,  1.5480e+00,  1.7725e+00,  1.7725e+00,  1.5565e+00,
          1.2105e+00,  1.4044e+00,  8.4746e-01,  1.5983e+00,  9.8814e-02,
          1.4985e+00,  1.7620e+00,  7.6071e-01,  1.2634e+00,  9.5310e-01,
          7.1505e-01,  1.0840e+00,  1.6106e+00,  1.6743e+00,  1.4606e+00,
          1.7766e+00,  1.7766e+00,  8.0692e-01,  7.9364e-01,  1.7484e+00,
          1.5462e+00,  8.1733e-01,  1.6910e+00,  1.1728e+00,  1.8004e+00,
          1.7140e+00,  3.4275e-02, -1.9420e-01, -2.2575e-01, -1.4010e-02,
          2.1603e-01,  2.9097e-01, -7.9147e-02,  1.8527e+01,  2.9454e+00,
          6.8340e-01,  1.2524e+00,  1.3200e+00,  1.5477e+00,  8.8673e-01,
          1.4840e+00,  2.9776e-01,  1.6596e+00,  1.7079e+00],
        [ 1.2231e+00,  1.2603e+00,  1.3272e+00,  1.3042e+00,  1.2683e+00,
          1.2295e+00,  1.1979e+00,  1.2196e+00,  1.2196e+00,  1.1918e+00,
          1.3217e+00,  1.2122e+00,  1.3625e+00,  1.2748e+00,  1.4183e+00,
          1.1990e+00,  1.2524e+00,  1.2710e+00,  1.2852e+00,  1.2727e+00,
          1.3352e+00,  1.3025e+00,  1.2480e+00,  1.2414e+00,  1.1395e+00,
          1.2310e+00,  1.2310e+00,  1.3005e+00,  1.3462e+00,  1.2498e+00,
          1.0308e+00,  1.2561e+00,  1.1311e+00,  1.3072e+00,  1.1243e+00,
          1.2535e+00,  1.2795e+00,  9.9418e-01,  1.2756e+00,  1.2935e+00,
          8.3480e-01,  7.6325e-01,  1.3021e+00,  1.1243e+00,  6.2905e-01,
          3.5559e+00,  2.5236e+00,  3.6627e+00,  2.8287e+00,  2.1134e+00,
          1.7874e+00,  2.9672e+00,  3.4653e+00,  1.7638e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 316 : 178.91774623985324
Test loss for epoch 316 : 179.32556338879314
Test Precision for epoch 316 : 0.26153846153846155
Test Recall for epoch 316 : 0.26153846153846155
Test F1 for epoch 316 : 0.26153846153846155


theta for epoch 317 : tensor([[ 2.6960e+00,  2.7286e+00,  2.8041e+00,  2.9441e+00,  2.9069e+00,
          2.7019e+00,  2.8821e+00,  2.6937e+00,  2.6937e+00,  1.2386e+00,
          1.2648e+00,  1.2528e+00,  1.2932e+00,  1.2322e+00,  1.3333e+00,
          1.2437e+00,  1.2168e+00,  1.2482e+00,  1.2140e+00,  1.1905e+00,
          1.2044e+00,  1.2261e+00,  1.1879e+00,  1.1833e+00,  1.2023e+00,
          1.1761e+00,  1.1761e+00,  1.2211e+00,  1.2660e+00,  1.1977e+00,
          1.2218e+00,  1.2666e+00,  1.2076e+00,  1.2386e+00,  1.1573e+00,
          1.2002e+00,  1.3998e+00,  1.4595e+00,  1.4343e+00,  1.4096e+00,
          1.4390e+00,  1.3860e+00,  1.4145e+00,  1.2987e+00,  1.3747e+00,
          1.3216e+00,  1.2675e+00,  1.2536e+00,  1.2324e+00,  1.3150e+00,
          1.2540e+00,  1.3571e+00,  1.2163e+00,  1.2297e+00],
        [ 1.1907e+00,  1.2212e+00,  1.2565e+00,  1.2360e+00,  1.2286e+00,
          1.1964e+00,  1.2076e+00,  1.1883e+00,  1.1883e+00,  2.2897e+00,
          2.2979e+00,  2.2247e+00,  2.4380e+00,  2.2037e+00,  4.5290e+00,
          2.2794e+00,  2.3658e+00,  4.3067e+00,  1.2036e+00,  1.2268e+00,
          1.1977e+00,  1.2193e+00,  1.2158e+00,  1.2101e+00,  1.2323e+00,
          1.2016e+00,  1.2016e+00,  1.2574e+00,  1.2125e+00,  1.2221e+00,
          1.2510e+00,  1.2358e+00,  1.2338e+00,  1.2703e+00,  1.1837e+00,
          1.2252e+00,  1.3529e+00,  1.4258e+00,  1.3348e+00,  1.3639e+00,
          1.4008e+00,  1.4120e+00,  1.3110e+00,  1.2045e+00,  1.3201e+00,
          1.2972e+00,  1.2826e+00,  1.2658e+00,  1.2405e+00,  1.2436e+00,
          1.2665e+00,  1.2929e+00,  1.2216e+00,  1.2376e+00],
        [ 1.1672e+00,  1.1937e+00,  1.2290e+00,  1.2244e+00,  1.1987e+00,
          1.1718e+00,  1.1800e+00,  1.1647e+00,  1.1647e+00,  1.2416e+00,
          1.2683e+00,  1.2562e+00,  1.2973e+00,  1.2351e+00,  1.2912e+00,
          1.2468e+00,  1.1727e+00,  1.2966e+00,  2.7340e+00,  2.9429e+00,
          2.9435e+00,  2.7528e+00,  2.6967e+00,  2.6928e+00,  2.8940e+00,
          2.6829e+00,  2.6829e+00,  1.2129e+00,  1.2688e+00,  1.2010e+00,
          1.2244e+00,  1.2136e+00,  1.2111e+00,  1.2427e+00,  1.2054e+00,
          1.2036e+00,  1.3960e+00,  1.4570e+00,  1.4295e+00,  1.3291e+00,
          1.4343e+00,  1.4241e+00,  1.4110e+00,  1.2924e+00,  1.2923e+00,
          1.3236e+00,  1.2699e+00,  1.2557e+00,  1.2341e+00,  1.3164e+00,
          1.2562e+00,  1.3593e+00,  1.2017e+00,  1.2314e+00],
        [ 1.1733e+00,  1.2003e+00,  1.2353e+00,  1.2317e+00,  1.2056e+00,
          1.1779e+00,  1.1865e+00,  1.1708e+00,  1.1708e+00,  1.2471e+00,
          1.2742e+00,  1.2618e+00,  1.3019e+00,  1.2404e+00,  1.2886e+00,
          1.2523e+00,  1.2237e+00,  1.2492e+00,  1.2246e+00,  1.2292e+00,
          1.2600e+00,  1.2372e+00,  1.1977e+00,  1.1929e+00,  1.1971e+00,
          1.1854e+00,  1.1854e+00,  2.9921e+00,  2.9571e+00,  2.6084e+00,
          2.7255e+00,  2.9893e+00,  2.6196e+00,  2.9197e+00,  2.6178e+00,
          2.6113e+00,  1.3944e+00,  1.4567e+00,  1.4282e+00,  1.3841e+00,
          1.4353e+00,  1.4243e+00,  1.4076e+00,  1.2778e+00,  1.3477e+00,
          1.3307e+00,  1.2745e+00,  1.2039e+00,  1.1900e+00,  1.3238e+00,
          1.2606e+00,  1.3675e+00,  1.1582e+00,  1.2353e+00],
        [ 1.7387e+00,  1.3588e+00,  5.7653e-01,  8.6734e-01,  1.2576e+00,
          1.6715e+00,  1.5488e+00,  1.7731e+00,  1.7731e+00,  1.5567e+00,
          1.2108e+00,  1.4055e+00,  8.4852e-01,  1.5994e+00,  9.9494e-02,
          1.4987e+00,  1.7629e+00,  7.6109e-01,  1.2641e+00,  9.5435e-01,
          7.1593e-01,  1.0849e+00,  1.6112e+00,  1.6748e+00,  1.4619e+00,
          1.7771e+00,  1.7771e+00,  8.0798e-01,  7.9429e-01,  1.7489e+00,
          1.5467e+00,  8.1767e-01,  1.6915e+00,  1.1733e+00,  1.8008e+00,
          1.7145e+00,  3.2772e-02, -1.9554e-01, -2.2715e-01, -1.5905e-02,
          2.1440e-01,  2.8890e-01, -8.0588e-02,  1.8601e+01,  2.8801e+00,
          6.8401e-01,  1.2527e+00,  1.3199e+00,  1.5478e+00,  8.8719e-01,
          1.4842e+00,  2.9863e-01,  1.6604e+00,  1.7078e+00],
        [ 1.2230e+00,  1.2603e+00,  1.3271e+00,  1.3042e+00,  1.2683e+00,
          1.2295e+00,  1.1978e+00,  1.2196e+00,  1.2196e+00,  1.1919e+00,
          1.3218e+00,  1.2121e+00,  1.3624e+00,  1.2747e+00,  1.4183e+00,
          1.1991e+00,  1.2524e+00,  1.2711e+00,  1.2850e+00,  1.2724e+00,
          1.3350e+00,  1.3024e+00,  1.2479e+00,  1.2412e+00,  1.1391e+00,
          1.2308e+00,  1.2308e+00,  1.3005e+00,  1.3461e+00,  1.2496e+00,
          1.0307e+00,  1.2560e+00,  1.1310e+00,  1.3072e+00,  1.1241e+00,
          1.2533e+00,  1.2785e+00,  9.9341e-01,  1.2746e+00,  1.2928e+00,
          8.3395e-01,  7.6255e-01,  1.3012e+00,  1.1229e+00,  6.2871e-01,
          3.5581e+00,  2.5223e+00,  3.6615e+00,  2.8270e+00,  2.1127e+00,
          1.7868e+00,  2.9657e+00,  3.4675e+00,  1.7632e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 317 : 178.89878636672125
Test loss for epoch 317 : 179.3137966899369
Test Precision for epoch 317 : 0.26153846153846155
Test Recall for epoch 317 : 0.26153846153846155
Test F1 for epoch 317 : 0.26153846153846155


theta for epoch 318 : tensor([[ 2.6960e+00,  2.7285e+00,  2.8041e+00,  2.9441e+00,  2.9068e+00,
          2.7018e+00,  2.8820e+00,  2.6936e+00,  2.6936e+00,  1.2385e+00,
          1.2646e+00,  1.2525e+00,  1.2928e+00,  1.2319e+00,  1.3330e+00,
          1.2435e+00,  1.2165e+00,  1.2479e+00,  1.2139e+00,  1.1904e+00,
          1.2043e+00,  1.2260e+00,  1.1879e+00,  1.1833e+00,  1.2021e+00,
          1.1760e+00,  1.1760e+00,  1.2210e+00,  1.2659e+00,  1.1977e+00,
          1.2219e+00,  1.2665e+00,  1.2075e+00,  1.2386e+00,  1.1573e+00,
          1.2002e+00,  1.3999e+00,  1.4597e+00,  1.4344e+00,  1.4099e+00,
          1.4392e+00,  1.3864e+00,  1.4146e+00,  1.2986e+00,  1.3754e+00,
          1.3217e+00,  1.2676e+00,  1.2536e+00,  1.2324e+00,  1.3150e+00,
          1.2541e+00,  1.3572e+00,  1.2163e+00,  1.2297e+00],
        [ 1.1899e+00,  1.2203e+00,  1.2566e+00,  1.2367e+00,  1.2279e+00,
          1.1959e+00,  1.2068e+00,  1.1877e+00,  1.1877e+00,  2.2971e+00,
          2.3067e+00,  2.2336e+00,  2.4495e+00,  2.2118e+00,  4.4956e+00,
          2.2874e+00,  2.3790e+00,  4.2731e+00,  1.2029e+00,  1.2261e+00,
          1.1971e+00,  1.2184e+00,  1.2152e+00,  1.2095e+00,  1.2315e+00,
          1.2009e+00,  1.2009e+00,  1.2568e+00,  1.2113e+00,  1.2216e+00,
          1.2504e+00,  1.2366e+00,  1.2332e+00,  1.2697e+00,  1.1832e+00,
          1.2246e+00,  1.3529e+00,  1.4257e+00,  1.3348e+00,  1.3639e+00,
          1.4009e+00,  1.4122e+00,  1.3111e+00,  1.2060e+00,  1.3209e+00,
          1.2964e+00,  1.2821e+00,  1.2654e+00,  1.2401e+00,  1.2428e+00,
          1.2661e+00,  1.2920e+00,  1.2211e+00,  1.2371e+00],
        [ 1.1673e+00,  1.1938e+00,  1.2286e+00,  1.2245e+00,  1.1988e+00,
          1.1718e+00,  1.1801e+00,  1.1648e+00,  1.1648e+00,  1.2416e+00,
          1.2682e+00,  1.2559e+00,  1.2970e+00,  1.2349e+00,  1.2909e+00,
          1.2467e+00,  1.1724e+00,  1.2964e+00,  2.7334e+00,  2.9440e+00,
          2.9434e+00,  2.7521e+00,  2.6961e+00,  2.6921e+00,  2.8951e+00,
          2.6823e+00,  2.6823e+00,  1.2125e+00,  1.2687e+00,  1.2011e+00,
          1.2245e+00,  1.2131e+00,  1.2111e+00,  1.2428e+00,  1.2054e+00,
          1.2037e+00,  1.3962e+00,  1.4573e+00,  1.4297e+00,  1.3288e+00,
          1.4346e+00,  1.4239e+00,  1.4112e+00,  1.2924e+00,  1.2923e+00,
          1.3238e+00,  1.2701e+00,  1.2558e+00,  1.2342e+00,  1.3164e+00,
          1.2563e+00,  1.3594e+00,  1.2013e+00,  1.2314e+00],
        [ 1.1732e+00,  1.2002e+00,  1.2347e+00,  1.2317e+00,  1.2055e+00,
          1.1779e+00,  1.1865e+00,  1.1707e+00,  1.1707e+00,  1.2469e+00,
          1.2740e+00,  1.2615e+00,  1.3014e+00,  1.2401e+00,  1.2887e+00,
          1.2521e+00,  1.2234e+00,  1.2494e+00,  1.2245e+00,  1.2285e+00,
          1.2598e+00,  1.2371e+00,  1.1976e+00,  1.1928e+00,  1.1965e+00,
          1.1853e+00,  1.1853e+00,  2.9918e+00,  2.9557e+00,  2.6092e+00,
          2.7240e+00,  2.9890e+00,  2.6203e+00,  2.9182e+00,  2.6187e+00,
          2.6120e+00,  1.3945e+00,  1.4568e+00,  1.4281e+00,  1.3837e+00,
          1.4354e+00,  1.4239e+00,  1.4075e+00,  1.2784e+00,  1.3476e+00,
          1.3307e+00,  1.2746e+00,  1.2045e+00,  1.1900e+00,  1.3239e+00,
          1.2605e+00,  1.3676e+00,  1.1576e+00,  1.2353e+00],
        [ 1.7395e+00,  1.3596e+00,  5.7719e-01,  8.6756e-01,  1.2583e+00,
          1.6721e+00,  1.5496e+00,  1.7737e+00,  1.7737e+00,  1.5568e+00,
          1.2110e+00,  1.4064e+00,  8.4939e-01,  1.6003e+00,  1.0000e-01,
          1.4986e+00,  1.7636e+00,  7.6128e-01,  1.2648e+00,  9.5562e-01,
          7.1683e-01,  1.0857e+00,  1.6118e+00,  1.6754e+00,  1.4633e+00,
          1.7777e+00,  1.7777e+00,  8.0904e-01,  7.9495e-01,  1.7494e+00,
          1.5472e+00,  8.1802e-01,  1.6921e+00,  1.1739e+00,  1.8013e+00,
          1.7151e+00,  3.1292e-02, -1.9686e-01, -2.2853e-01, -1.7765e-02,
          2.1280e-01,  2.8687e-01, -8.2008e-02,  1.8674e+01,  2.8155e+00,
          6.8460e-01,  1.2530e+00,  1.3198e+00,  1.5479e+00,  8.8763e-01,
          1.4843e+00,  2.9948e-01,  1.6612e+00,  1.7078e+00],
        [ 1.2230e+00,  1.2602e+00,  1.3271e+00,  1.3042e+00,  1.2683e+00,
          1.2294e+00,  1.1978e+00,  1.2195e+00,  1.2195e+00,  1.1918e+00,
          1.3217e+00,  1.2119e+00,  1.3622e+00,  1.2745e+00,  1.4181e+00,
          1.1990e+00,  1.2522e+00,  1.2711e+00,  1.2849e+00,  1.2721e+00,
          1.3350e+00,  1.3023e+00,  1.2478e+00,  1.2411e+00,  1.1389e+00,
          1.2307e+00,  1.2307e+00,  1.3004e+00,  1.3461e+00,  1.2495e+00,
          1.0306e+00,  1.2560e+00,  1.1309e+00,  1.3072e+00,  1.1240e+00,
          1.2532e+00,  1.2776e+00,  9.9270e-01,  1.2737e+00,  1.2922e+00,
          8.3316e-01,  7.6190e-01,  1.3003e+00,  1.1216e+00,  6.2846e-01,
          3.5603e+00,  2.5210e+00,  3.6603e+00,  2.8254e+00,  2.1121e+00,
          1.7863e+00,  2.9643e+00,  3.4697e+00,  1.7626e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 318 : 178.88018616391471
Test loss for epoch 318 : 179.30248092465936
Test Precision for epoch 318 : 0.26153846153846155
Test Recall for epoch 318 : 0.26153846153846155
Test F1 for epoch 318 : 0.26153846153846155


theta for epoch 319 : tensor([[ 2.6959,  2.7284,  2.8040,  2.9440,  2.9067,  2.7017,  2.8819,  2.6935,
          2.6935,  1.2383,  1.2643,  1.2522,  1.2924,  1.2315,  1.3326,  1.2432,
          1.2163,  1.2477,  1.2139,  1.1904,  1.2043,  1.2260,  1.1880,  1.1834,
          1.2021,  1.1761,  1.1761,  1.2210,  1.2659,  1.1977,  1.2219,  1.2665,
          1.2075,  1.2386,  1.1573,  1.2002,  1.4001,  1.4600,  1.4346,  1.4103,
          1.4395,  1.3867,  1.4148,  1.2986,  1.3761,  1.3218,  1.2677,  1.2538,
          1.2325,  1.3152,  1.2542,  1.3574,  1.2163,  1.2298],
        [ 1.1890,  1.2194,  1.2566,  1.2372,  1.2272,  1.1952,  1.2059,  1.1871,
          1.1871,  2.3041,  2.3152,  2.2423,  2.4611,  2.2198,  4.4624,  2.2953,
          2.3920,  4.2398,  1.2022,  1.2257,  1.1967,  1.2175,  1.2148,  1.2090,
          1.2308,  1.2005,  1.2005,  1.2563,  1.2102,  1.2210,  1.2499,  1.2374,
          1.2327,  1.2691,  1.1827,  1.2240,  1.3530,  1.4258,  1.3350,  1.3640,
          1.4010,  1.4125,  1.3112,  1.2074,  1.3217,  1.2956,  1.2818,  1.2651,
          1.2398,  1.2420,  1.2657,  1.2912,  1.2207,  1.2367],
        [ 1.1672,  1.1937,  1.2281,  1.2244,  1.1987,  1.1718,  1.1800,  1.1647,
          1.1647,  1.2414,  1.2679,  1.2556,  1.2966,  1.2346,  1.2904,  1.2465,
          1.1720,  1.2960,  2.7330,  2.9452,  2.9435,  2.7515,  2.6957,  2.6916,
          2.8963,  2.6819,  2.6819,  1.2119,  1.2686,  1.2011,  1.2245,  1.2126,
          1.2111,  1.2428,  1.2054,  1.2037,  1.3964,  1.4575,  1.4299,  1.3284,
          1.4349,  1.4237,  1.4114,  1.2924,  1.2924,  1.3240,  1.2702,  1.2560,
          1.2343,  1.3165,  1.2564,  1.3595,  1.2008,  1.2315],
        [ 1.1730,  1.2000,  1.2341,  1.2315,  1.2053,  1.1777,  1.1863,  1.1705,
          1.1705,  1.2466,  1.2736,  1.2610,  1.3008,  1.2396,  1.2887,  1.2517,
          1.2231,  1.2495,  1.2244,  1.2278,  1.2598,  1.2370,  1.1976,  1.1928,
          1.1960,  1.1853,  1.1853,  2.9916,  2.9544,  2.6100,  2.7225,  2.9888,
          2.6212,  2.9168,  2.6197,  2.6129,  1.3945,  1.4569,  1.4280,  1.3833,
          1.4356,  1.4236,  1.4074,  1.2790,  1.3475,  1.3308,  1.2746,  1.2051,
          1.1900,  1.3239,  1.2606,  1.3676,  1.1570,  1.2352],
        [ 1.7402,  1.3602,  0.5778,  0.8677,  1.2590,  1.6727,  1.5503,  1.7742,
          1.7742,  1.5567,  1.2110,  1.4072,  0.8502,  1.6011,  0.1005,  1.4985,
          1.7642,  0.7614,  1.2657,  0.9570,  0.7178,  1.0867,  1.6126,  1.6762,
          1.4649,  1.7784,  1.7784,  0.8101,  0.7956,  1.7500,  1.5477,  0.8184,
          1.6927,  1.1745,  1.8019,  1.7156,  0.0298, -0.1982, -0.2299, -0.0196,
          0.2112,  0.2848, -0.0834, 18.7476,  2.7517,  0.6853,  1.2534,  1.3199,
          1.5481,  0.8882,  1.4846,  0.3004,  1.6620,  1.7079],
        [ 1.2227,  1.2601,  1.3270,  1.3041,  1.2681,  1.2293,  1.1976,  1.2193,
          1.2193,  1.1917,  1.3214,  1.2115,  1.3618,  1.2741,  1.4178,  1.1988,
          1.2519,  1.2709,  1.2849,  1.2720,  1.3350,  1.3023,  1.2478,  1.2412,
          1.1387,  1.2307,  1.2307,  1.3003,  1.3461,  1.2494,  1.0305,  1.2559,
          1.1308,  1.3072,  1.1239,  1.2531,  1.2767,  0.9920,  1.2728,  1.2917,
          0.8324,  0.7613,  1.2995,  1.1205,  0.6283,  3.5626,  2.5199,  3.6592,
          2.8239,  2.1115,  1.7859,  2.9630,  3.4720,  1.7622]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 319 : 178.86196098118154
Test loss for epoch 319 : 179.29149234207597
Test Precision for epoch 319 : 0.26153846153846155
Test Recall for epoch 319 : 0.26153846153846155
Test F1 for epoch 319 : 0.26153846153846155


theta for epoch 320 : tensor([[ 2.6959,  2.7285,  2.8040,  2.9440,  2.9067,  2.7016,  2.8820,  2.6934,
          2.6934,  1.2382,  1.2642,  1.2520,  1.2922,  1.2314,  1.3324,  1.2432,
          1.2162,  1.2476,  1.2137,  1.1902,  1.2042,  1.2259,  1.1879,  1.1833,
          1.2020,  1.1760,  1.1760,  1.2208,  1.2658,  1.1975,  1.2218,  1.2663,
          1.2074,  1.2385,  1.1571,  1.2001,  1.4002,  1.4601,  1.4347,  1.4106,
          1.4397,  1.3870,  1.4149,  1.2986,  1.3768,  1.3219,  1.2677,  1.2538,
          1.2325,  1.3152,  1.2542,  1.3574,  1.2162,  1.2298],
        [ 1.1881,  1.2184,  1.2566,  1.2378,  1.2264,  1.1945,  1.2049,  1.1864,
          1.1864,  2.3114,  2.3239,  2.2513,  2.4729,  2.2281,  4.4299,  2.3032,
          2.4050,  4.2072,  1.2013,  1.2250,  1.1962,  1.2164,  1.2141,  1.2084,
          1.2299,  1.1999,  1.1999,  1.2556,  1.2089,  1.2203,  1.2492,  1.2380,
          1.2320,  1.2684,  1.1821,  1.2234,  1.3530,  1.4258,  1.3350,  1.3640,
          1.4010,  1.4126,  1.3113,  1.2085,  1.3226,  1.2947,  1.2813,  1.2646,
          1.2393,  1.2411,  1.2652,  1.2904,  1.2202,  1.2362],
        [ 1.1671,  1.1936,  1.2276,  1.2244,  1.1987,  1.1717,  1.1800,  1.1647,
          1.1647,  1.2415,  1.2679,  1.2555,  1.2965,  1.2345,  1.2901,  1.2465,
          1.1719,  1.2959,  2.7325,  2.9464,  2.9434,  2.7509,  2.6952,  2.6909,
          2.8975,  2.6814,  2.6814,  1.2114,  1.2685,  1.2010,  1.2245,  1.2121,
          1.2111,  1.2428,  1.2054,  1.2036,  1.3965,  1.4578,  1.4300,  1.3281,
          1.4352,  1.4234,  1.4115,  1.2925,  1.2925,  1.3241,  1.2703,  1.2561,
          1.2344,  1.3165,  1.2565,  1.3595,  1.2004,  1.2316],
        [ 1.1728,  1.1998,  1.2335,  1.2313,  1.2051,  1.1775,  1.1861,  1.1704,
          1.1704,  1.2465,  1.2735,  1.2608,  1.3004,  1.2394,  1.2888,  1.2516,
          1.2229,  1.2497,  1.2242,  1.2271,  1.2596,  1.2368,  1.1974,  1.1927,
          1.1954,  1.1851,  1.1851,  2.9914,  2.9531,  2.6109,  2.7210,  2.9887,
          2.6220,  2.9154,  2.6207,  2.6137,  1.3945,  1.4570,  1.4279,  1.3828,
          1.4356,  1.4231,  1.4072,  1.2796,  1.3475,  1.3308,  1.2746,  1.2056,
          1.1899,  1.3239,  1.2605,  1.3677,  1.1564,  1.2351],
        [ 1.7409,  1.3610,  0.5784,  0.8679,  1.2598,  1.6733,  1.5511,  1.7748,
          1.7748,  1.5569,  1.2114,  1.4082,  0.8513,  1.6021,  0.1012,  1.4986,
          1.7652,  0.7619,  1.2665,  0.9583,  0.7189,  1.0876,  1.6134,  1.6768,
          1.4663,  1.7790,  1.7790,  0.8112,  0.7963,  1.7505,  1.5482,  0.8188,
          1.6933,  1.1751,  1.8024,  1.7162,  0.0282, -0.1996, -0.2314, -0.0216,
          0.2095,  0.2827, -0.0850, 18.8208,  2.6888,  0.6860,  1.2538,  1.3200,
          1.5483,  0.8888,  1.4849,  0.3014,  1.6629,  1.7080],
        [ 1.2226,  1.2599,  1.3268,  1.3040,  1.2680,  1.2291,  1.1975,  1.2192,
          1.2192,  1.1917,  1.3215,  1.2114,  1.3617,  1.2739,  1.4178,  1.1989,
          1.2518,  1.2710,  1.2848,  1.2718,  1.3349,  1.3021,  1.2477,  1.2411,
          1.1384,  1.2306,  1.2306,  1.3002,  1.3460,  1.2492,  1.0303,  1.2558,
          1.1306,  1.3071,  1.1237,  1.2529,  1.2759,  0.9914,  1.2719,  1.2911,
          0.8317,  0.7607,  1.2986,  1.1194,  0.6281,  3.5649,  2.5189,  3.6581,
          2.8224,  2.1111,  1.7856,  2.9617,  3.4743,  1.7619]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 320 : 178.84412417386957
Test loss for epoch 320 : 179.2807539858183
Test Precision for epoch 320 : 0.26153846153846155
Test Recall for epoch 320 : 0.26153846153846155
Test F1 for epoch 320 : 0.26153846153846155


theta for epoch 321 : tensor([[ 2.6960,  2.7286,  2.8042,  2.9442,  2.9069,  2.7018,  2.8821,  2.6936,
          2.6936,  1.2381,  1.2640,  1.2517,  1.2919,  1.2311,  1.3321,  1.2430,
          1.2160,  1.2474,  1.2136,  1.1900,  1.2040,  1.2257,  1.1877,  1.1831,
          1.2018,  1.1759,  1.1759,  1.2207,  1.2657,  1.1974,  1.2217,  1.2662,
          1.2073,  1.2384,  1.1570,  1.2000,  1.4003,  1.4603,  1.4348,  1.4109,
          1.4399,  1.3873,  1.4150,  1.2986,  1.3775,  1.3218,  1.2677,  1.2537,
          1.2324,  1.3152,  1.2541,  1.3574,  1.2160,  1.2297],
        [ 1.1873,  1.2176,  1.2568,  1.2384,  1.2257,  1.1939,  1.2041,  1.1858,
          1.1858,  2.3183,  2.3322,  2.2601,  2.4847,  2.2364,  4.3976,  2.3110,
          2.4178,  4.1749,  1.2005,  1.2243,  1.1956,  1.2152,  1.2135,  1.2078,
          1.2290,  1.1992,  1.1992,  1.2549,  1.2079,  1.2197,  1.2485,  1.2387,
          1.2314,  1.2678,  1.1816,  1.2227,  1.3530,  1.4258,  1.3351,  1.3641,
          1.4011,  1.4129,  1.3115,  1.2096,  1.3235,  1.2939,  1.2808,  1.2641,
          1.2389,  1.2403,  1.2647,  1.2896,  1.2196,  1.2357],
        [ 1.1671,  1.1936,  1.2271,  1.2244,  1.1987,  1.1717,  1.1800,  1.1647,
          1.1647,  1.2414,  1.2679,  1.2553,  1.2963,  1.2343,  1.2898,  1.2464,
          1.1716,  1.2958,  2.7321,  2.9476,  2.9435,  2.7504,  2.6947,  2.6903,
          2.8987,  2.6809,  2.6809,  1.2109,  1.2684,  1.2010,  1.2246,  1.2116,
          1.2111,  1.2428,  1.2053,  1.2036,  1.3967,  1.4580,  1.4302,  1.3278,
          1.4354,  1.4232,  1.4117,  1.2926,  1.2926,  1.3242,  1.2703,  1.2561,
          1.2344,  1.3164,  1.2565,  1.3595,  1.1999,  1.2316],
        [ 1.1727,  1.1997,  1.2329,  1.2312,  1.2050,  1.1774,  1.1860,  1.1703,
          1.1703,  1.2463,  1.2733,  1.2605,  1.2999,  1.2391,  1.2888,  1.2515,
          1.2227,  1.2499,  1.2240,  1.2264,  1.2594,  1.2366,  1.1973,  1.1925,
          1.1947,  1.1850,  1.1850,  2.9913,  2.9518,  2.6118,  2.7196,  2.9886,
          2.6230,  2.9140,  2.6218,  2.6146,  1.3945,  1.4571,  1.4277,  1.3824,
          1.4357,  1.4227,  1.4071,  1.2801,  1.3475,  1.3307,  1.2745,  1.2060,
          1.1898,  1.3238,  1.2604,  1.3677,  1.1557,  1.2350],
        [ 1.7417,  1.3617,  0.5791,  0.8683,  1.2607,  1.6740,  1.5520,  1.7754,
          1.7754,  1.5570,  1.2117,  1.4091,  0.8523,  1.6030,  0.1019,  1.4986,
          1.7660,  0.7624,  1.2672,  0.9596,  0.7198,  1.0884,  1.6141,  1.6775,
          1.4677,  1.7796,  1.7796,  0.8123,  0.7970,  1.7511,  1.5489,  0.8193,
          1.6939,  1.1758,  1.8030,  1.7168,  0.0266, -0.2011, -0.2329, -0.0235,
          0.2078,  0.2806, -0.0865, 18.8940,  2.6269,  0.6867,  1.2542,  1.3201,
          1.5485,  0.8893,  1.4852,  0.3023,  1.6637,  1.7082],
        [ 1.2225,  1.2599,  1.3268,  1.3041,  1.2680,  1.2291,  1.1974,  1.2191,
          1.2191,  1.1917,  1.3214,  1.2113,  1.3615,  1.2737,  1.4177,  1.1988,
          1.2517,  1.2710,  1.2846,  1.2716,  1.3348,  1.3020,  1.2476,  1.2410,
          1.1381,  1.2305,  1.2305,  1.3001,  1.3460,  1.2491,  1.0301,  1.2557,
          1.1305,  1.3071,  1.1235,  1.2528,  1.2751,  0.9908,  1.2711,  1.2906,
          0.8310,  0.7602,  1.2978,  1.1185,  0.6281,  3.5671,  2.5179,  3.6570,
          2.8210,  2.1106,  1.7853,  2.9605,  3.4765,  1.7615]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 321 : 178.82670385885064
Test loss for epoch 321 : 179.27053038340418
Test Precision for epoch 321 : 0.26153846153846155
Test Recall for epoch 321 : 0.26153846153846155
Test F1 for epoch 321 : 0.26153846153846155


theta for epoch 322 : tensor([[ 2.6961,  2.7288,  2.8043,  2.9443,  2.9070,  2.7018,  2.8822,  2.6936,
          2.6936,  1.2378,  1.2637,  1.2513,  1.2915,  1.2307,  1.3317,  1.2428,
          1.2157,  1.2471,  1.2135,  1.1899,  1.2039,  1.2256,  1.1877,  1.1831,
          1.2017,  1.1759,  1.1759,  1.2206,  1.2656,  1.1974,  1.2217,  1.2661,
          1.2072,  1.2384,  1.1569,  1.1999,  1.4004,  1.4605,  1.4349,  1.4112,
          1.4400,  1.3876,  1.4151,  1.2986,  1.3782,  1.3219,  1.2677,  1.2537,
          1.2324,  1.3152,  1.2541,  1.3575,  1.2159,  1.2296],
        [ 1.1865,  1.2168,  1.2569,  1.2390,  1.2250,  1.1932,  1.2031,  1.1851,
          1.1851,  2.3251,  2.3403,  2.2689,  2.4963,  2.2446,  4.3657,  2.3185,
          2.4304,  4.1431,  1.1997,  1.2237,  1.1951,  1.2142,  1.2130,  1.2073,
          1.2281,  1.1988,  1.1988,  1.2544,  1.2070,  1.2192,  1.2479,  1.2394,
          1.2308,  1.2672,  1.1812,  1.2222,  1.3531,  1.4258,  1.3352,  1.3641,
          1.4012,  1.4131,  1.3116,  1.2105,  1.3244,  1.2932,  1.2804,  1.2637,
          1.2385,  1.2396,  1.2643,  1.2889,  1.2192,  1.2353],
        [ 1.1670,  1.1935,  1.2266,  1.2243,  1.1985,  1.1716,  1.1798,  1.1646,
          1.1646,  1.2412,  1.2676,  1.2550,  1.2959,  1.2340,  1.2893,  1.2462,
          1.1712,  1.2954,  2.7319,  2.9491,  2.9437,  2.7500,  2.6945,  2.6900,
          2.9001,  2.6807,  2.6807,  1.2104,  1.2682,  1.2009,  1.2245,  1.2111,
          1.2110,  1.2427,  1.2053,  1.2035,  1.3967,  1.4581,  1.4302,  1.3274,
          1.4356,  1.4229,  1.4117,  1.2926,  1.2927,  1.3242,  1.2703,  1.2561,
          1.2344,  1.3164,  1.2565,  1.3595,  1.1994,  1.2315],
        [ 1.1725,  1.1995,  1.2323,  1.2310,  1.2048,  1.1772,  1.1858,  1.1701,
          1.1701,  1.2460,  1.2730,  1.2601,  1.2994,  1.2387,  1.2887,  1.2512,
          1.2223,  1.2498,  1.2239,  1.2257,  1.2593,  1.2365,  1.1972,  1.1924,
          1.1942,  1.1849,  1.1849,  2.9913,  2.9506,  2.6128,  2.7183,  2.9886,
          2.6240,  2.9127,  2.6229,  2.6156,  1.3944,  1.4571,  1.4275,  1.3820,
          1.4358,  1.4223,  1.4068,  1.2806,  1.3475,  1.3307,  1.2745,  1.2064,
          1.1897,  1.3238,  1.2603,  1.3677,  1.1552,  1.2349],
        [ 1.7423,  1.3624,  0.5797,  0.8686,  1.2615,  1.6747,  1.5528,  1.7760,
          1.7760,  1.5570,  1.2119,  1.4098,  0.8532,  1.6037,  0.1025,  1.4985,
          1.7667,  0.7628,  1.2681,  0.9609,  0.7209,  1.0893,  1.6150,  1.6783,
          1.4692,  1.7804,  1.7804,  0.8135,  0.7978,  1.7518,  1.5496,  0.8198,
          1.6946,  1.1766,  1.8036,  1.7175,  0.0249, -0.2026, -0.2344, -0.0255,
          0.2060,  0.2785, -0.0881, 18.9670,  2.5661,  0.6875,  1.2548,  1.3204,
          1.5489,  0.8900,  1.4856,  0.3034,  1.6646,  1.7085],
        [ 1.2222,  1.2597,  1.3266,  1.3039,  1.2678,  1.2289,  1.1972,  1.2189,
          1.2189,  1.1915,  1.3212,  1.2109,  1.3611,  1.2733,  1.4175,  1.1986,
          1.2513,  1.2709,  1.2845,  1.2714,  1.3348,  1.3019,  1.2475,  1.2409,
          1.1379,  1.2304,  1.2304,  1.3000,  1.3460,  1.2489,  1.0299,  1.2556,
          1.1304,  1.3070,  1.1234,  1.2526,  1.2742,  0.9901,  1.2702,  1.2900,
          0.8302,  0.7595,  1.2970,  1.1175,  0.6280,  3.5695,  2.5171,  3.6561,
          2.8198,  2.1104,  1.7852,  2.9595,  3.4789,  1.7614]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 322 : 178.80970475489113
Test loss for epoch 322 : 179.26056351125212
Test Precision for epoch 322 : 0.26153846153846155
Test Recall for epoch 322 : 0.26153846153846155
Test F1 for epoch 322 : 0.26153846153846155


theta for epoch 323 : tensor([[ 2.6963,  2.7289,  2.8045,  2.9444,  2.9071,  2.7020,  2.8824,  2.6938,
          2.6938,  1.2377,  1.2636,  1.2511,  1.2912,  1.2305,  1.3315,  1.2427,
          1.2156,  1.2471,  1.2134,  1.1898,  1.2038,  1.2255,  1.1877,  1.1831,
          1.2016,  1.1758,  1.1758,  1.2205,  1.2655,  1.1973,  1.2216,  1.2660,
          1.2071,  1.2383,  1.1568,  1.1998,  1.4005,  1.4606,  1.4350,  1.4115,
          1.4402,  1.3878,  1.4152,  1.2987,  1.3789,  1.3219,  1.2677,  1.2537,
          1.2324,  1.3152,  1.2540,  1.3575,  1.2158,  1.2296],
        [ 1.1857,  1.2160,  1.2570,  1.2395,  1.2241,  1.1925,  1.2021,  1.1844,
          1.1844,  2.3320,  2.3485,  2.2778,  2.5082,  2.2531,  4.3344,  2.3261,
          2.4430,  4.1119,  1.1989,  1.2230,  1.1945,  1.2130,  1.2123,  1.2067,
          1.2271,  1.1982,  1.1982,  1.2537,  1.2061,  1.2185,  1.2472,  1.2400,
          1.2301,  1.2665,  1.1806,  1.2215,  1.3531,  1.4258,  1.3353,  1.3641,
          1.4012,  1.4133,  1.3117,  1.2114,  1.3253,  1.2924,  1.2798,  1.2632,
          1.2380,  1.2388,  1.2637,  1.2882,  1.2186,  1.2348],
        [ 1.1668,  1.1934,  1.2261,  1.2241,  1.1984,  1.1715,  1.1797,  1.1645,
          1.1645,  1.2411,  1.2675,  1.2548,  1.2957,  1.2338,  1.2890,  1.2462,
          1.1709,  1.2952,  2.7317,  2.9505,  2.9439,  2.7497,  2.6942,  2.6896,
          2.9015,  2.6804,  2.6804,  1.2099,  1.2681,  1.2009,  1.2245,  1.2106,
          1.2109,  1.2427,  1.2052,  1.2035,  1.3968,  1.4582,  1.4303,  1.3271,
          1.4357,  1.4226,  1.4118,  1.2927,  1.2928,  1.3242,  1.2703,  1.2561,
          1.2343,  1.3163,  1.2564,  1.3594,  1.1989,  1.2315],
        [ 1.1723,  1.1993,  1.2317,  1.2309,  1.2046,  1.1770,  1.1856,  1.1699,
          1.1699,  1.2459,  1.2728,  1.2598,  1.2990,  1.2384,  1.2887,  1.2511,
          1.2222,  1.2499,  1.2237,  1.2251,  1.2591,  1.2363,  1.1971,  1.1923,
          1.1937,  1.1848,  1.1848,  2.9914,  2.9494,  2.6138,  2.7169,  2.9887,
          2.6250,  2.9114,  2.6241,  2.6166,  1.3943,  1.4571,  1.4273,  1.3816,
          1.4358,  1.4219,  1.4066,  1.2810,  1.3475,  1.3307,  1.2744,  1.2067,
          1.1896,  1.3238,  1.2602,  1.3677,  1.1546,  1.2348],
        [ 1.7430,  1.3631,  0.5804,  0.8689,  1.2624,  1.6753,  1.5537,  1.7767,
          1.7767,  1.5572,  1.2123,  1.4107,  0.8542,  1.6046,  0.1034,  1.4986,
          1.7676,  0.7634,  1.2689,  0.9622,  0.7219,  1.0902,  1.6158,  1.6791,
          1.4706,  1.7811,  1.7811,  0.8146,  0.7985,  1.7524,  1.5502,  0.8203,
          1.6953,  1.1773,  1.8042,  1.7181,  0.0232, -0.2041, -0.2360, -0.0274,
          0.2041,  0.2763, -0.0898, 19.0398,  2.5066,  0.6882,  1.2553,  1.3206,
          1.5493,  0.8907,  1.4860,  0.3044,  1.6655,  1.7087],
        [ 1.2220,  1.2595,  1.3264,  1.3038,  1.2677,  1.2287,  1.1970,  1.2187,
          1.2187,  1.1915,  1.3211,  1.2107,  1.3610,  1.2731,  1.4175,  1.1987,
          1.2512,  1.2710,  1.2844,  1.2711,  1.3347,  1.3018,  1.2474,  1.2408,
          1.1376,  1.2303,  1.2303,  1.2998,  1.3459,  1.2488,  1.0297,  1.2555,
          1.1302,  1.3069,  1.1232,  1.2525,  1.2734,  0.9895,  1.2694,  1.2895,
          0.8296,  0.7590,  1.2962,  1.1166,  0.6280,  3.5719,  2.5164,  3.6551,
          2.8186,  2.1103,  1.7851,  2.9585,  3.4813,  1.7613]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 323 : 178.7931463065817
Test loss for epoch 323 : 179.2509950490164
Test Precision for epoch 323 : 0.26153846153846155
Test Recall for epoch 323 : 0.26153846153846155
Test F1 for epoch 323 : 0.26153846153846155


theta for epoch 324 : tensor([[ 2.6966,  2.7293,  2.8049,  2.9448,  2.9074,  2.7023,  2.8827,  2.6941,
          2.6941,  1.2376,  1.2634,  1.2508,  1.2909,  1.2303,  1.3313,  1.2425,
          1.2153,  1.2469,  1.2132,  1.1896,  1.2036,  1.2253,  1.1875,  1.1829,
          1.2013,  1.1757,  1.1757,  1.2203,  1.2654,  1.1971,  1.2215,  1.2659,
          1.2070,  1.2382,  1.1567,  1.1997,  1.4006,  1.4607,  1.4350,  1.4117,
          1.4403,  1.3880,  1.4152,  1.2987,  1.3797,  1.3218,  1.2675,  1.2536,
          1.2322,  1.3151,  1.2539,  1.3575,  1.2156,  1.2294],
        [ 1.1851,  1.2153,  1.2572,  1.2400,  1.2234,  1.1918,  1.2012,  1.1837,
          1.1837,  2.3388,  2.3566,  2.2868,  2.5201,  2.2616,  4.3035,  2.3337,
          2.4554,  4.0812,  1.1980,  1.2223,  1.1938,  1.2118,  1.2116,  1.2060,
          1.2261,  1.1975,  1.1975,  1.2530,  1.2052,  1.2178,  1.2465,  1.2406,
          1.2294,  1.2658,  1.1800,  1.2208,  1.3531,  1.4258,  1.3354,  1.3642,
          1.4012,  1.4134,  1.3118,  1.2121,  1.3262,  1.2917,  1.2792,  1.2626,
          1.2374,  1.2381,  1.2631,  1.2876,  1.2180,  1.2342],
        [ 1.1668,  1.1933,  1.2257,  1.2241,  1.1984,  1.1715,  1.1797,  1.1645,
          1.1645,  1.2410,  1.2674,  1.2546,  1.2954,  1.2336,  1.2886,  1.2461,
          1.1706,  1.2951,  2.7315,  2.9519,  2.9441,  2.7494,  2.6939,  2.6892,
          2.9029,  2.6801,  2.6801,  1.2094,  1.2679,  1.2008,  1.2244,  1.2102,
          1.2109,  1.2426,  1.2051,  1.2034,  1.3969,  1.4584,  1.4304,  1.3267,
          1.4359,  1.4224,  1.4119,  1.2927,  1.2930,  1.3242,  1.2703,  1.2560,
          1.2343,  1.3162,  1.2564,  1.3594,  1.1984,  1.2314],
        [ 1.1721,  1.1991,  1.2313,  1.2307,  1.2045,  1.1769,  1.1854,  1.1697,
          1.1697,  1.2457,  1.2726,  1.2595,  1.2985,  1.2381,  1.2886,  1.2509,
          1.2219,  1.2499,  1.2235,  1.2243,  1.2589,  1.2361,  1.1969,  1.1921,
          1.1931,  1.1846,  1.1846,  2.9915,  2.9483,  2.6149,  2.7157,  2.9889,
          2.6261,  2.9102,  2.6253,  2.6177,  1.3943,  1.4571,  1.4271,  1.3812,
          1.4358,  1.4215,  1.4064,  1.2814,  1.3475,  1.3306,  1.2743,  1.2070,
          1.1894,  1.3237,  1.2601,  1.3676,  1.1539,  1.2346],
        [ 1.7437,  1.3639,  0.5812,  0.8694,  1.2633,  1.6761,  1.5546,  1.7774,
          1.7774,  1.5573,  1.2126,  1.4116,  0.8553,  1.6054,  0.1042,  1.4987,
          1.7685,  0.7641,  1.2697,  0.9635,  0.7229,  1.0909,  1.6166,  1.6799,
          1.4719,  1.7818,  1.7818,  0.8157,  0.7992,  1.7531,  1.5510,  0.8210,
          1.6961,  1.1780,  1.8049,  1.7188,  0.0214, -0.2057, -0.2376, -0.0294,
          0.2022,  0.2740, -0.0915, 19.1125,  2.4483,  0.6890,  1.2558,  1.3209,
          1.5497,  0.8913,  1.4865,  0.3054,  1.6664,  1.7090],
        [ 1.2219,  1.2595,  1.3264,  1.3038,  1.2676,  1.2286,  1.1969,  1.2186,
          1.2186,  1.1914,  1.3210,  1.2105,  1.3608,  1.2729,  1.4174,  1.1986,
          1.2510,  1.2711,  1.2842,  1.2709,  1.3346,  1.3016,  1.2472,  1.2407,
          1.1373,  1.2302,  1.2302,  1.2997,  1.3458,  1.2486,  1.0296,  1.2554,
          1.1301,  1.3068,  1.1230,  1.2523,  1.2727,  0.9889,  1.2687,  1.2890,
          0.8289,  0.7585,  1.2955,  1.1157,  0.6281,  3.5742,  2.5157,  3.6542,
          2.8176,  2.1101,  1.7851,  2.9575,  3.4836,  1.7613]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 324 : 178.77704009845743
Test loss for epoch 324 : 179.24186468848654
Test Precision for epoch 324 : 0.26153846153846155
Test Recall for epoch 324 : 0.26153846153846155
Test F1 for epoch 324 : 0.26153846153846155


theta for epoch 325 : tensor([[ 2.6969,  2.7296,  2.8053,  2.9451,  2.9077,  2.7026,  2.8831,  2.6944,
          2.6944,  1.2372,  1.2631,  1.2504,  1.2905,  1.2299,  1.3309,  1.2422,
          1.2149,  1.2467,  1.2131,  1.1894,  1.2035,  1.2252,  1.1874,  1.1829,
          1.2012,  1.1756,  1.1756,  1.2201,  1.2653,  1.1970,  1.2214,  1.2657,
          1.2069,  1.2380,  1.1566,  1.1996,  1.4006,  1.4608,  1.4350,  1.4119,
          1.4404,  1.3882,  1.4153,  1.2987,  1.3804,  1.3218,  1.2675,  1.2535,
          1.2322,  1.3151,  1.2538,  1.3575,  1.2155,  1.2294],
        [ 1.1844,  1.2146,  1.2574,  1.2405,  1.2226,  1.1911,  1.2003,  1.1830,
          1.1830,  2.3454,  2.3644,  2.2956,  2.5319,  2.2700,  4.2730,  2.3410,
          2.4676,  4.0510,  1.1973,  1.2216,  1.1933,  1.2107,  1.2110,  1.2055,
          1.2252,  1.1970,  1.1970,  1.2524,  1.2046,  1.2172,  1.2458,  1.2412,
          1.2288,  1.2651,  1.1795,  1.2202,  1.3531,  1.4258,  1.3355,  1.3642,
          1.4013,  1.4136,  1.3119,  1.2129,  1.3271,  1.2911,  1.2787,  1.2622,
          1.2370,  1.2375,  1.2626,  1.2871,  1.2175,  1.2337],
        [ 1.1667,  1.1932,  1.2252,  1.2240,  1.1982,  1.1714,  1.1795,  1.1643,
          1.1643,  1.2408,  1.2671,  1.2542,  1.2951,  1.2333,  1.2881,  1.2458,
          1.1701,  1.2947,  2.7315,  2.9535,  2.9445,  2.7493,  2.6938,  2.6890,
          2.9045,  2.6800,  2.6800,  1.2089,  1.2677,  1.2007,  1.2244,  1.2097,
          1.2108,  1.2426,  1.2050,  1.2033,  1.3969,  1.4585,  1.4304,  1.3264,
          1.4360,  1.4221,  1.4119,  1.2928,  1.2931,  1.3243,  1.2703,  1.2560,
          1.2342,  1.3161,  1.2563,  1.3593,  1.1979,  1.2314],
        [ 1.1719,  1.1989,  1.2307,  1.2305,  1.2043,  1.1767,  1.1852,  1.1695,
          1.1695,  1.2453,  1.2722,  1.2590,  1.2979,  1.2377,  1.2883,  1.2505,
          1.2215,  1.2498,  1.2234,  1.2237,  1.2587,  1.2360,  1.1967,  1.1920,
          1.1926,  1.1845,  1.1845,  2.9918,  2.9472,  2.6161,  2.7146,  2.9892,
          2.6273,  2.9092,  2.6267,  2.6189,  1.3942,  1.4571,  1.4268,  1.3807,
          1.4358,  1.4210,  1.4061,  1.2817,  1.3476,  1.3305,  1.2742,  1.2072,
          1.1892,  1.3236,  1.2600,  1.3676,  1.1534,  1.2345],
        [ 1.7444,  1.3647,  0.5820,  0.8699,  1.2642,  1.6769,  1.5554,  1.7781,
          1.7781,  1.5574,  1.2130,  1.4123,  0.8563,  1.6060,  0.1052,  1.4988,
          1.7693,  0.7648,  1.2707,  0.9648,  0.7241,  1.0919,  1.6175,  1.6808,
          1.4734,  1.7827,  1.7827,  0.8169,  0.8001,  1.7539,  1.5518,  0.8217,
          1.6969,  1.1789,  1.8056,  1.7196,  0.0196, -0.2074, -0.2393, -0.0315,
          0.2002,  0.2717, -0.0933, 19.1850,  2.3913,  0.6899,  1.2566,  1.3214,
          1.5502,  0.8922,  1.4871,  0.3065,  1.6674,  1.7095],
        [ 1.2217,  1.2593,  1.3262,  1.3037,  1.2674,  1.2284,  1.1967,  1.2184,
          1.2184,  1.1912,  1.3208,  1.2102,  1.3604,  1.2725,  1.4171,  1.1984,
          1.2506,  1.2710,  1.2842,  1.2707,  1.3345,  1.3016,  1.2472,  1.2406,
          1.1371,  1.2301,  1.2301,  1.2995,  1.3458,  1.2484,  1.0293,  1.2553,
          1.1299,  1.3067,  1.1229,  1.2521,  1.2720,  0.9884,  1.2679,  1.2885,
          0.8283,  0.7580,  1.2948,  1.1148,  0.6282,  3.5767,  2.5153,  3.6535,
          2.8167,  2.1102,  1.7853,  2.9568,  3.4862,  1.7614]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 325 : 178.76138930656526
Test loss for epoch 325 : 179.23298817413342
Test Precision for epoch 325 : 0.26153846153846155
Test Recall for epoch 325 : 0.26153846153846155
Test F1 for epoch 325 : 0.26153846153846155


theta for epoch 326 : tensor([[ 2.6973e+00,  2.7300e+00,  2.8057e+00,  2.9455e+00,  2.9081e+00,
          2.7030e+00,  2.8835e+00,  2.6948e+00,  2.6948e+00,  1.2371e+00,
          1.2629e+00,  1.2501e+00,  1.2902e+00,  1.2296e+00,  1.3307e+00,
          1.2421e+00,  1.2147e+00,  1.2466e+00,  1.2130e+00,  1.1893e+00,
          1.2034e+00,  1.2251e+00,  1.1874e+00,  1.1828e+00,  1.2011e+00,
          1.1756e+00,  1.1756e+00,  1.2200e+00,  1.2652e+00,  1.1968e+00,
          1.2213e+00,  1.2656e+00,  1.2067e+00,  1.2379e+00,  1.1564e+00,
          1.1994e+00,  1.4007e+00,  1.4609e+00,  1.4351e+00,  1.4122e+00,
          1.4406e+00,  1.3884e+00,  1.4153e+00,  1.2988e+00,  1.3811e+00,
          1.3217e+00,  1.2674e+00,  1.2534e+00,  1.2321e+00,  1.3150e+00,
          1.2537e+00,  1.3574e+00,  1.2153e+00,  1.2292e+00],
        [ 1.1837e+00,  1.2138e+00,  1.2576e+00,  1.2408e+00,  1.2218e+00,
          1.1903e+00,  1.1993e+00,  1.1822e+00,  1.1822e+00,  2.3520e+00,
          2.3722e+00,  2.3045e+00,  2.5437e+00,  2.2787e+00,  4.2430e+00,
          2.3484e+00,  2.4798e+00,  4.0214e+00,  1.1966e+00,  1.2210e+00,
          1.1926e+00,  1.2097e+00,  1.2104e+00,  1.2049e+00,  1.2243e+00,
          1.1964e+00,  1.1964e+00,  1.2517e+00,  1.2040e+00,  1.2165e+00,
          1.2450e+00,  1.2416e+00,  1.2280e+00,  1.2644e+00,  1.1789e+00,
          1.2195e+00,  1.3532e+00,  1.4257e+00,  1.3356e+00,  1.3643e+00,
          1.4013e+00,  1.4137e+00,  1.3121e+00,  1.2136e+00,  1.3280e+00,
          1.2904e+00,  1.2781e+00,  1.2616e+00,  1.2364e+00,  1.2369e+00,
          1.2620e+00,  1.2866e+00,  1.2169e+00,  1.2332e+00],
        [ 1.1665e+00,  1.1930e+00,  1.2247e+00,  1.2238e+00,  1.1981e+00,
          1.1712e+00,  1.1793e+00,  1.1642e+00,  1.1642e+00,  1.2407e+00,
          1.2670e+00,  1.2540e+00,  1.2948e+00,  1.2331e+00,  1.2878e+00,
          1.2457e+00,  1.1698e+00,  1.2945e+00,  2.7315e+00,  2.9551e+00,
          2.9450e+00,  2.7493e+00,  2.6937e+00,  2.6888e+00,  2.9062e+00,
          2.6799e+00,  2.6799e+00,  1.2084e+00,  1.2675e+00,  1.2006e+00,
          1.2243e+00,  1.2093e+00,  1.2107e+00,  1.2424e+00,  1.2049e+00,
          1.2032e+00,  1.3970e+00,  1.4586e+00,  1.4305e+00,  1.3261e+00,
          1.4361e+00,  1.4219e+00,  1.4119e+00,  1.2928e+00,  1.2934e+00,
          1.3242e+00,  1.2702e+00,  1.2559e+00,  1.2341e+00,  1.3159e+00,
          1.2562e+00,  1.3591e+00,  1.1974e+00,  1.2312e+00],
        [ 1.1716e+00,  1.1986e+00,  1.2301e+00,  1.2302e+00,  1.2040e+00,
          1.1764e+00,  1.1849e+00,  1.1692e+00,  1.1692e+00,  1.2451e+00,
          1.2720e+00,  1.2587e+00,  1.2974e+00,  1.2374e+00,  1.2882e+00,
          1.2503e+00,  1.2212e+00,  1.2497e+00,  1.2232e+00,  1.2231e+00,
          1.2586e+00,  1.2358e+00,  1.1966e+00,  1.1919e+00,  1.1921e+00,
          1.1844e+00,  1.1844e+00,  2.9922e+00,  2.9463e+00,  2.6173e+00,
          2.7136e+00,  2.9896e+00,  2.6285e+00,  2.9081e+00,  2.6282e+00,
          2.6202e+00,  1.3941e+00,  1.4570e+00,  1.4265e+00,  1.3803e+00,
          1.4358e+00,  1.4207e+00,  1.4058e+00,  1.2820e+00,  1.3477e+00,
          1.3304e+00,  1.2740e+00,  1.2073e+00,  1.1890e+00,  1.3235e+00,
          1.2598e+00,  1.3675e+00,  1.1528e+00,  1.2343e+00],
        [ 1.7450e+00,  1.3655e+00,  5.8283e-01,  8.7041e-01,  1.2651e+00,
          1.6776e+00,  1.5562e+00,  1.7788e+00,  1.7788e+00,  1.5576e+00,
          1.2135e+00,  1.4131e+00,  8.5734e-01,  1.6068e+00,  1.0623e-01,
          1.4990e+00,  1.7701e+00,  7.6568e-01,  1.2716e+00,  9.6616e-01,
          7.2521e-01,  1.0928e+00,  1.6184e+00,  1.6817e+00,  1.4747e+00,
          1.7835e+00,  1.7835e+00,  8.1801e-01,  8.0093e-01,  1.7546e+00,
          1.5525e+00,  8.2240e-01,  1.6976e+00,  1.1796e+00,  1.8064e+00,
          1.7204e+00,  1.7676e-02, -2.0909e-01, -2.4106e-01, -3.3587e-02,
          1.9821e-01,  2.6935e-01, -9.5041e-02,  1.9257e+01,  2.3358e+00,
          6.9078e-01,  1.2572e+00,  1.3218e+00,  1.5507e+00,  8.9297e-01,
          1.4876e+00,  3.0759e-01,  1.6683e+00,  1.7099e+00],
        [ 1.2215e+00,  1.2591e+00,  1.3261e+00,  1.3035e+00,  1.2672e+00,
          1.2282e+00,  1.1964e+00,  1.2182e+00,  1.2182e+00,  1.1911e+00,
          1.3207e+00,  1.2100e+00,  1.3603e+00,  1.2723e+00,  1.4171e+00,
          1.1984e+00,  1.2504e+00,  1.2712e+00,  1.2841e+00,  1.2705e+00,
          1.3345e+00,  1.3015e+00,  1.2471e+00,  1.2405e+00,  1.1369e+00,
          1.2300e+00,  1.2300e+00,  1.2994e+00,  1.3457e+00,  1.2482e+00,
          1.0291e+00,  1.2551e+00,  1.1297e+00,  1.3066e+00,  1.1227e+00,
          1.2520e+00,  1.2713e+00,  9.8791e-01,  1.2673e+00,  1.2880e+00,
          8.2777e-01,  7.5757e-01,  1.2941e+00,  1.1139e+00,  6.2842e-01,
          3.5791e+00,  2.5149e+00,  3.6527e+00,  2.8159e+00,  2.1103e+00,
          1.7855e+00,  2.9562e+00,  3.4886e+00,  1.7616e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 326 : 178.74620323561834
Test loss for epoch 326 : 179.2245689468349
Test Precision for epoch 326 : 0.26153846153846155
Test Recall for epoch 326 : 0.26153846153846155
Test F1 for epoch 326 : 0.26153846153846155


theta for epoch 327 : tensor([[ 2.6979e+00,  2.7306e+00,  2.8063e+00,  2.9461e+00,  2.9087e+00,
          2.7035e+00,  2.8840e+00,  2.6953e+00,  2.6953e+00,  1.2369e+00,
          1.2627e+00,  1.2498e+00,  1.2899e+00,  1.2294e+00,  1.3304e+00,
          1.2419e+00,  1.2144e+00,  1.2465e+00,  1.2128e+00,  1.1891e+00,
          1.2031e+00,  1.2249e+00,  1.1872e+00,  1.1826e+00,  1.2008e+00,
          1.1754e+00,  1.1754e+00,  1.2197e+00,  1.2650e+00,  1.1966e+00,
          1.2211e+00,  1.2654e+00,  1.2065e+00,  1.2377e+00,  1.1562e+00,
          1.1992e+00,  1.4007e+00,  1.4610e+00,  1.4351e+00,  1.4123e+00,
          1.4407e+00,  1.3886e+00,  1.4153e+00,  1.2988e+00,  1.3818e+00,
          1.3216e+00,  1.2672e+00,  1.2533e+00,  1.2319e+00,  1.3149e+00,
          1.2535e+00,  1.3573e+00,  1.2151e+00,  1.2290e+00],
        [ 1.1831e+00,  1.2132e+00,  1.2579e+00,  1.2412e+00,  1.2210e+00,
          1.1896e+00,  1.1985e+00,  1.1815e+00,  1.1815e+00,  2.3586e+00,
          2.3799e+00,  2.3134e+00,  2.5556e+00,  2.2873e+00,  4.2136e+00,
          2.3557e+00,  2.4919e+00,  3.9924e+00,  1.1958e+00,  1.2202e+00,
          1.1919e+00,  1.2087e+00,  1.2097e+00,  1.2042e+00,  1.2233e+00,
          1.1958e+00,  1.1958e+00,  1.2510e+00,  1.2034e+00,  1.2158e+00,
          1.2442e+00,  1.2421e+00,  1.2273e+00,  1.2636e+00,  1.1782e+00,
          1.2187e+00,  1.3531e+00,  1.4257e+00,  1.3357e+00,  1.3643e+00,
          1.4013e+00,  1.4138e+00,  1.3122e+00,  1.2143e+00,  1.3289e+00,
          1.2898e+00,  1.2775e+00,  1.2610e+00,  1.2358e+00,  1.2364e+00,
          1.2614e+00,  1.2862e+00,  1.2163e+00,  1.2326e+00],
        [ 1.1664e+00,  1.1929e+00,  1.2242e+00,  1.2237e+00,  1.1979e+00,
          1.1711e+00,  1.1792e+00,  1.1641e+00,  1.1641e+00,  1.2406e+00,
          1.2668e+00,  1.2538e+00,  1.2946e+00,  1.2329e+00,  1.2875e+00,
          1.2457e+00,  1.1695e+00,  1.2944e+00,  2.7316e+00,  2.9568e+00,
          2.9454e+00,  2.7493e+00,  2.6937e+00,  2.6887e+00,  2.9078e+00,
          2.6799e+00,  2.6799e+00,  1.2080e+00,  1.2673e+00,  1.2005e+00,
          1.2242e+00,  1.2088e+00,  1.2105e+00,  1.2423e+00,  1.2048e+00,
          1.2031e+00,  1.3970e+00,  1.4587e+00,  1.4306e+00,  1.3257e+00,
          1.4362e+00,  1.4216e+00,  1.4120e+00,  1.2928e+00,  1.2936e+00,
          1.3242e+00,  1.2701e+00,  1.2558e+00,  1.2341e+00,  1.3157e+00,
          1.2561e+00,  1.3590e+00,  1.1969e+00,  1.2311e+00],
        [ 1.1714e+00,  1.1984e+00,  1.2296e+00,  1.2300e+00,  1.2038e+00,
          1.1762e+00,  1.1846e+00,  1.1690e+00,  1.1690e+00,  1.2449e+00,
          1.2718e+00,  1.2584e+00,  1.2969e+00,  1.2371e+00,  1.2880e+00,
          1.2502e+00,  1.2209e+00,  1.2496e+00,  1.2230e+00,  1.2224e+00,
          1.2583e+00,  1.2356e+00,  1.1964e+00,  1.1917e+00,  1.1915e+00,
          1.1842e+00,  1.1842e+00,  2.9926e+00,  2.9454e+00,  2.6186e+00,
          2.7126e+00,  2.9900e+00,  2.6299e+00,  2.9071e+00,  2.6297e+00,
          2.6215e+00,  1.3940e+00,  1.4570e+00,  1.4262e+00,  1.3799e+00,
          1.4357e+00,  1.4203e+00,  1.4055e+00,  1.2822e+00,  1.3479e+00,
          1.3303e+00,  1.2738e+00,  1.2073e+00,  1.1888e+00,  1.3234e+00,
          1.2596e+00,  1.3674e+00,  1.1522e+00,  1.2341e+00],
        [ 1.7457e+00,  1.3663e+00,  5.8378e-01,  8.7107e-01,  1.2661e+00,
          1.6785e+00,  1.5571e+00,  1.7796e+00,  1.7796e+00,  1.5579e+00,
          1.2141e+00,  1.4139e+00,  8.5847e-01,  1.6075e+00,  1.0743e-01,
          1.4994e+00,  1.7710e+00,  7.6668e-01,  1.2725e+00,  9.6742e-01,
          7.2630e-01,  1.0936e+00,  1.6193e+00,  1.6825e+00,  1.4759e+00,
          1.7843e+00,  1.7843e+00,  8.1918e-01,  8.0182e-01,  1.7554e+00,
          1.5533e+00,  8.2321e-01,  1.6984e+00,  1.1805e+00,  1.8071e+00,
          1.7212e+00,  1.5701e-02, -2.1086e-01, -2.4285e-01, -3.5715e-02,
          1.9609e-01,  2.6693e-01, -9.6921e-02,  1.9329e+01,  2.2819e+00,
          6.9171e-01,  1.2579e+00,  1.3224e+00,  1.5513e+00,  8.9381e-01,
          1.4882e+00,  3.0873e-01,  1.6693e+00,  1.7104e+00],
        [ 1.2213e+00,  1.2590e+00,  1.3260e+00,  1.3034e+00,  1.2671e+00,
          1.2280e+00,  1.1963e+00,  1.2180e+00,  1.2180e+00,  1.1910e+00,
          1.3206e+00,  1.2098e+00,  1.3601e+00,  1.2722e+00,  1.4170e+00,
          1.1984e+00,  1.2502e+00,  1.2713e+00,  1.2839e+00,  1.2702e+00,
          1.3343e+00,  1.3014e+00,  1.2469e+00,  1.2403e+00,  1.1365e+00,
          1.2298e+00,  1.2298e+00,  1.2992e+00,  1.3456e+00,  1.2480e+00,
          1.0289e+00,  1.2550e+00,  1.1295e+00,  1.3064e+00,  1.1225e+00,
          1.2518e+00,  1.2707e+00,  9.8743e-01,  1.2666e+00,  1.2876e+00,
          8.2722e-01,  7.5713e-01,  1.2935e+00,  1.1130e+00,  6.2863e-01,
          3.5817e+00,  2.5147e+00,  3.6521e+00,  2.8152e+00,  2.1106e+00,
          1.7858e+00,  2.9556e+00,  3.4912e+00,  1.7619e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 327 : 178.7314854014062
Test loss for epoch 327 : 179.21647969998162
Test Precision for epoch 327 : 0.26153846153846155
Test Recall for epoch 327 : 0.26153846153846155
Test F1 for epoch 327 : 0.26153846153846155


theta for epoch 328 : tensor([[ 2.6985e+00,  2.7313e+00,  2.8070e+00,  2.9467e+00,  2.9093e+00,
          2.7042e+00,  2.8847e+00,  2.6960e+00,  2.6960e+00,  1.2366e+00,
          1.2623e+00,  1.2494e+00,  1.2895e+00,  1.2290e+00,  1.3301e+00,
          1.2416e+00,  1.2140e+00,  1.2462e+00,  1.2126e+00,  1.1889e+00,
          1.2030e+00,  1.2247e+00,  1.1870e+00,  1.1825e+00,  1.2006e+00,
          1.1753e+00,  1.1753e+00,  1.2196e+00,  1.2649e+00,  1.1965e+00,
          1.2209e+00,  1.2652e+00,  1.2064e+00,  1.2376e+00,  1.1560e+00,
          1.1990e+00,  1.4007e+00,  1.4610e+00,  1.4351e+00,  1.4125e+00,
          1.4407e+00,  1.3887e+00,  1.4153e+00,  1.2987e+00,  1.3825e+00,
          1.3215e+00,  1.2671e+00,  1.2531e+00,  1.2318e+00,  1.3148e+00,
          1.2534e+00,  1.3572e+00,  1.2149e+00,  1.2289e+00],
        [ 1.1825e+00,  1.2126e+00,  1.2583e+00,  1.2415e+00,  1.2202e+00,
          1.1889e+00,  1.1977e+00,  1.1808e+00,  1.1808e+00,  2.3651e+00,
          2.3874e+00,  2.3222e+00,  2.5673e+00,  2.2959e+00,  4.1846e+00,
          2.3628e+00,  2.5037e+00,  3.9639e+00,  1.1951e+00,  1.2196e+00,
          1.1913e+00,  1.2078e+00,  1.2090e+00,  1.2036e+00,  1.2225e+00,
          1.1952e+00,  1.1952e+00,  1.2504e+00,  1.2031e+00,  1.2151e+00,
          1.2436e+00,  1.2425e+00,  1.2267e+00,  1.2629e+00,  1.1777e+00,
          1.2181e+00,  1.3531e+00,  1.4256e+00,  1.3358e+00,  1.3644e+00,
          1.4012e+00,  1.4139e+00,  1.3123e+00,  1.2149e+00,  1.3298e+00,
          1.2893e+00,  1.2770e+00,  1.2605e+00,  1.2353e+00,  1.2360e+00,
          1.2609e+00,  1.2858e+00,  1.2157e+00,  1.2320e+00],
        [ 1.1662e+00,  1.1927e+00,  1.2238e+00,  1.2235e+00,  1.1978e+00,
          1.1709e+00,  1.1790e+00,  1.1639e+00,  1.1639e+00,  1.2403e+00,
          1.2665e+00,  1.2534e+00,  1.2942e+00,  1.2326e+00,  1.2870e+00,
          1.2454e+00,  1.1690e+00,  1.2940e+00,  2.7319e+00,  2.9586e+00,
          2.9461e+00,  2.7495e+00,  2.6938e+00,  2.6888e+00,  2.9097e+00,
          2.6800e+00,  2.6800e+00,  1.2075e+00,  1.2671e+00,  1.2004e+00,
          1.2241e+00,  1.2084e+00,  1.2104e+00,  1.2422e+00,  1.2046e+00,
          1.2030e+00,  1.3970e+00,  1.4587e+00,  1.4306e+00,  1.3254e+00,
          1.4363e+00,  1.4213e+00,  1.4120e+00,  1.2928e+00,  1.2939e+00,
          1.3241e+00,  1.2700e+00,  1.2557e+00,  1.2339e+00,  1.3156e+00,
          1.2560e+00,  1.3588e+00,  1.1965e+00,  1.2310e+00],
        [ 1.1711e+00,  1.1982e+00,  1.2292e+00,  1.2298e+00,  1.2035e+00,
          1.1760e+00,  1.1844e+00,  1.1688e+00,  1.1688e+00,  1.2446e+00,
          1.2714e+00,  1.2580e+00,  1.2963e+00,  1.2367e+00,  1.2877e+00,
          1.2498e+00,  1.2205e+00,  1.2494e+00,  1.2228e+00,  1.2218e+00,
          1.2581e+00,  1.2354e+00,  1.1962e+00,  1.1915e+00,  1.1911e+00,
          1.1840e+00,  1.1840e+00,  2.9932e+00,  2.9446e+00,  2.6201e+00,
          2.7118e+00,  2.9907e+00,  2.6313e+00,  2.9063e+00,  2.6313e+00,
          2.6229e+00,  1.3938e+00,  1.4569e+00,  1.4259e+00,  1.3795e+00,
          1.4357e+00,  1.4199e+00,  1.4051e+00,  1.2823e+00,  1.3480e+00,
          1.3301e+00,  1.2737e+00,  1.2074e+00,  1.1887e+00,  1.3233e+00,
          1.2594e+00,  1.3673e+00,  1.1517e+00,  1.2339e+00],
        [ 1.7465e+00,  1.3672e+00,  5.8480e-01,  8.7180e-01,  1.2671e+00,
          1.6793e+00,  1.5580e+00,  1.7805e+00,  1.7805e+00,  1.5581e+00,
          1.2146e+00,  1.4147e+00,  8.5950e-01,  1.6082e+00,  1.0864e-01,
          1.4996e+00,  1.7718e+00,  7.6762e-01,  1.2734e+00,  9.6874e-01,
          7.2747e-01,  1.0945e+00,  1.6202e+00,  1.6834e+00,  1.4772e+00,
          1.7852e+00,  1.7852e+00,  8.2041e-01,  8.0280e-01,  1.7562e+00,
          1.5542e+00,  8.2412e-01,  1.6993e+00,  1.1814e+00,  1.8079e+00,
          1.7220e+00,  1.3657e-02, -2.1270e-01, -2.4470e-01, -3.7886e-02,
          1.9388e-01,  2.6444e-01, -9.8865e-02,  1.9401e+01,  2.2296e+00,
          6.9272e-01,  1.2587e+00,  1.3230e+00,  1.5519e+00,  8.9473e-01,
          1.4889e+00,  3.0995e-01,  1.6703e+00,  1.7110e+00],
        [ 1.2211e+00,  1.2588e+00,  1.3258e+00,  1.3033e+00,  1.2669e+00,
          1.2279e+00,  1.1961e+00,  1.2179e+00,  1.2179e+00,  1.1908e+00,
          1.3204e+00,  1.2095e+00,  1.3597e+00,  1.2718e+00,  1.4168e+00,
          1.1982e+00,  1.2498e+00,  1.2712e+00,  1.2838e+00,  1.2700e+00,
          1.3342e+00,  1.3013e+00,  1.2468e+00,  1.2402e+00,  1.1363e+00,
          1.2297e+00,  1.2297e+00,  1.2991e+00,  1.3455e+00,  1.2479e+00,
          1.0287e+00,  1.2549e+00,  1.1294e+00,  1.3063e+00,  1.1223e+00,
          1.2516e+00,  1.2701e+00,  9.8693e-01,  1.2660e+00,  1.2871e+00,
          8.2666e-01,  7.5667e-01,  1.2929e+00,  1.1120e+00,  6.2885e-01,
          3.5843e+00,  2.5146e+00,  3.6517e+00,  2.8147e+00,  2.1110e+00,
          1.7863e+00,  2.9553e+00,  3.4939e+00,  1.7623e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 328 : 178.71723258568153
Test loss for epoch 328 : 179.20872525831143
Test Precision for epoch 328 : 0.26153846153846155
Test Recall for epoch 328 : 0.26153846153846155
Test F1 for epoch 328 : 0.26153846153846155


theta for epoch 329 : tensor([[ 2.6992e+00,  2.7319e+00,  2.8077e+00,  2.9474e+00,  2.9099e+00,
          2.7048e+00,  2.8853e+00,  2.6966e+00,  2.6966e+00,  1.2364e+00,
          1.2621e+00,  1.2491e+00,  1.2891e+00,  1.2287e+00,  1.3298e+00,
          1.2414e+00,  1.2137e+00,  1.2461e+00,  1.2125e+00,  1.1887e+00,
          1.2028e+00,  1.2246e+00,  1.1869e+00,  1.1824e+00,  1.2005e+00,
          1.1752e+00,  1.1752e+00,  1.2194e+00,  1.2647e+00,  1.1963e+00,
          1.2208e+00,  1.2651e+00,  1.2062e+00,  1.2374e+00,  1.1559e+00,
          1.1989e+00,  1.4007e+00,  1.4611e+00,  1.4352e+00,  1.4126e+00,
          1.4408e+00,  1.3888e+00,  1.4154e+00,  1.2987e+00,  1.3833e+00,
          1.3213e+00,  1.2670e+00,  1.2530e+00,  1.2316e+00,  1.3147e+00,
          1.2532e+00,  1.3571e+00,  1.2147e+00,  1.2287e+00],
        [ 1.1818e+00,  1.2119e+00,  1.2585e+00,  1.2416e+00,  1.2194e+00,
          1.1881e+00,  1.1968e+00,  1.1800e+00,  1.1800e+00,  2.3716e+00,
          2.3949e+00,  2.3312e+00,  2.5791e+00,  2.3047e+00,  4.1563e+00,
          2.3701e+00,  2.5155e+00,  3.9361e+00,  1.1945e+00,  1.2189e+00,
          1.1906e+00,  1.2070e+00,  1.2083e+00,  1.2030e+00,  1.2217e+00,
          1.1946e+00,  1.1946e+00,  1.2497e+00,  1.2027e+00,  1.2144e+00,
          1.2428e+00,  1.2428e+00,  1.2259e+00,  1.2622e+00,  1.1771e+00,
          1.2174e+00,  1.3530e+00,  1.4255e+00,  1.3359e+00,  1.3644e+00,
          1.4012e+00,  1.4139e+00,  1.3123e+00,  1.2155e+00,  1.3307e+00,
          1.2888e+00,  1.2763e+00,  1.2598e+00,  1.2347e+00,  1.2356e+00,
          1.2602e+00,  1.2854e+00,  1.2151e+00,  1.2314e+00],
        [ 1.1660e+00,  1.1925e+00,  1.2233e+00,  1.2233e+00,  1.1975e+00,
          1.1707e+00,  1.1788e+00,  1.1637e+00,  1.1637e+00,  1.2401e+00,
          1.2663e+00,  1.2531e+00,  1.2939e+00,  1.2323e+00,  1.2866e+00,
          1.2452e+00,  1.1685e+00,  1.2938e+00,  2.7323e+00,  2.9606e+00,
          2.9469e+00,  2.7498e+00,  2.6941e+00,  2.6890e+00,  2.9116e+00,
          2.6803e+00,  2.6803e+00,  1.2071e+00,  1.2668e+00,  1.2002e+00,
          1.2239e+00,  1.2080e+00,  1.2103e+00,  1.2420e+00,  1.2045e+00,
          1.2028e+00,  1.3970e+00,  1.4588e+00,  1.4306e+00,  1.3251e+00,
          1.4364e+00,  1.4211e+00,  1.4120e+00,  1.2927e+00,  1.2942e+00,
          1.3239e+00,  1.2698e+00,  1.2556e+00,  1.2338e+00,  1.3153e+00,
          1.2558e+00,  1.3585e+00,  1.1960e+00,  1.2308e+00],
        [ 1.1709e+00,  1.1979e+00,  1.2286e+00,  1.2296e+00,  1.2033e+00,
          1.1757e+00,  1.1841e+00,  1.1685e+00,  1.1685e+00,  1.2444e+00,
          1.2711e+00,  1.2577e+00,  1.2958e+00,  1.2364e+00,  1.2874e+00,
          1.2496e+00,  1.2202e+00,  1.2493e+00,  1.2227e+00,  1.2212e+00,
          1.2580e+00,  1.2353e+00,  1.1961e+00,  1.1914e+00,  1.1907e+00,
          1.1839e+00,  1.1839e+00,  2.9939e+00,  2.9439e+00,  2.6215e+00,
          2.7110e+00,  2.9914e+00,  2.6328e+00,  2.9055e+00,  2.6330e+00,
          2.6244e+00,  1.3937e+00,  1.4569e+00,  1.4256e+00,  1.3792e+00,
          1.4356e+00,  1.4195e+00,  1.4048e+00,  1.2824e+00,  1.3483e+00,
          1.3300e+00,  1.2735e+00,  1.2074e+00,  1.1884e+00,  1.3231e+00,
          1.2592e+00,  1.3671e+00,  1.1511e+00,  1.2336e+00],
        [ 1.7471e+00,  1.3680e+00,  5.8580e-01,  8.7252e-01,  1.2680e+00,
          1.6802e+00,  1.5588e+00,  1.7812e+00,  1.7812e+00,  1.5584e+00,
          1.2152e+00,  1.4155e+00,  8.6060e-01,  1.6089e+00,  1.0996e-01,
          1.5001e+00,  1.7726e+00,  7.6869e-01,  1.2744e+00,  9.7005e-01,
          7.2864e-01,  1.0955e+00,  1.6212e+00,  1.6844e+00,  1.4784e+00,
          1.7861e+00,  1.7861e+00,  8.2159e-01,  8.0376e-01,  1.7571e+00,
          1.5551e+00,  8.2503e-01,  1.7002e+00,  1.1823e+00,  1.8087e+00,
          1.7229e+00,  1.1598e-02, -2.1454e-01, -2.4655e-01, -4.0049e-02,
          1.9165e-01,  2.6194e-01, -1.0082e-01,  1.9472e+01,  2.1791e+00,
          6.9365e-01,  1.2594e+00,  1.3235e+00,  1.5525e+00,  8.9557e-01,
          1.4895e+00,  3.1108e-01,  1.6712e+00,  1.7115e+00],
        [ 1.2209e+00,  1.2586e+00,  1.3256e+00,  1.3031e+00,  1.2667e+00,
          1.2276e+00,  1.1958e+00,  1.2176e+00,  1.2176e+00,  1.1907e+00,
          1.3202e+00,  1.2093e+00,  1.3595e+00,  1.2717e+00,  1.4168e+00,
          1.1981e+00,  1.2495e+00,  1.2713e+00,  1.2837e+00,  1.2698e+00,
          1.3341e+00,  1.3012e+00,  1.2467e+00,  1.2401e+00,  1.1360e+00,
          1.2296e+00,  1.2296e+00,  1.2989e+00,  1.3454e+00,  1.2477e+00,
          1.0285e+00,  1.2547e+00,  1.1292e+00,  1.3062e+00,  1.1221e+00,
          1.2514e+00,  1.2695e+00,  9.8652e-01,  1.2654e+00,  1.2867e+00,
          8.2620e-01,  7.5630e-01,  1.2924e+00,  1.1111e+00,  6.2917e-01,
          3.5869e+00,  2.5147e+00,  3.6512e+00,  2.8143e+00,  2.1115e+00,
          1.7868e+00,  2.9550e+00,  3.4966e+00,  1.7628e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 329 : 178.7034439198776
Test loss for epoch 329 : 179.20136137092632
Test Precision for epoch 329 : 0.26153846153846155
Test Recall for epoch 329 : 0.26153846153846155
Test F1 for epoch 329 : 0.26153846153846155


theta for epoch 330 : tensor([[ 2.7000e+00,  2.7328e+00,  2.8085e+00,  2.9482e+00,  2.9107e+00,
          2.7056e+00,  2.8862e+00,  2.6974e+00,  2.6974e+00,  1.2361e+00,
          1.2618e+00,  1.2488e+00,  1.2888e+00,  1.2285e+00,  1.3296e+00,
          1.2412e+00,  1.2134e+00,  1.2460e+00,  1.2123e+00,  1.1885e+00,
          1.2026e+00,  1.2244e+00,  1.1867e+00,  1.1822e+00,  1.2003e+00,
          1.1750e+00,  1.1750e+00,  1.2192e+00,  1.2645e+00,  1.1961e+00,
          1.2206e+00,  1.2648e+00,  1.2060e+00,  1.2372e+00,  1.1556e+00,
          1.1987e+00,  1.4007e+00,  1.4611e+00,  1.4352e+00,  1.4127e+00,
          1.4409e+00,  1.3889e+00,  1.4154e+00,  1.2986e+00,  1.3840e+00,
          1.3212e+00,  1.2668e+00,  1.2528e+00,  1.2315e+00,  1.3146e+00,
          1.2530e+00,  1.3570e+00,  1.2145e+00,  1.2286e+00],
        [ 1.1812e+00,  1.2113e+00,  1.2588e+00,  1.2417e+00,  1.2186e+00,
          1.1873e+00,  1.1960e+00,  1.1793e+00,  1.1793e+00,  2.3782e+00,
          2.4024e+00,  2.3402e+00,  2.5909e+00,  2.3135e+00,  4.1285e+00,
          2.3773e+00,  2.5272e+00,  3.9090e+00,  1.1938e+00,  1.2182e+00,
          1.1899e+00,  1.2063e+00,  1.2076e+00,  1.2023e+00,  1.2208e+00,
          1.1939e+00,  1.1939e+00,  1.2490e+00,  1.2024e+00,  1.2136e+00,
          1.2420e+00,  1.2431e+00,  1.2251e+00,  1.2614e+00,  1.1765e+00,
          1.2166e+00,  1.3529e+00,  1.4254e+00,  1.3359e+00,  1.3644e+00,
          1.4011e+00,  1.4139e+00,  1.3124e+00,  1.2161e+00,  1.3315e+00,
          1.2883e+00,  1.2757e+00,  1.2592e+00,  1.2341e+00,  1.2352e+00,
          1.2595e+00,  1.2851e+00,  1.2144e+00,  1.2308e+00],
        [ 1.1658e+00,  1.1924e+00,  1.2229e+00,  1.2231e+00,  1.1974e+00,
          1.1705e+00,  1.1786e+00,  1.1635e+00,  1.1635e+00,  1.2399e+00,
          1.2661e+00,  1.2529e+00,  1.2936e+00,  1.2321e+00,  1.2862e+00,
          1.2451e+00,  1.1681e+00,  1.2936e+00,  2.7327e+00,  2.9625e+00,
          2.9476e+00,  2.7502e+00,  2.6944e+00,  2.6892e+00,  2.9135e+00,
          2.6805e+00,  2.6805e+00,  1.2066e+00,  1.2666e+00,  1.2000e+00,
          1.2238e+00,  1.2076e+00,  1.2101e+00,  1.2419e+00,  1.2043e+00,
          1.2026e+00,  1.3971e+00,  1.4588e+00,  1.4307e+00,  1.3248e+00,
          1.4365e+00,  1.4209e+00,  1.4120e+00,  1.2926e+00,  1.2945e+00,
          1.3238e+00,  1.2697e+00,  1.2555e+00,  1.2337e+00,  1.3151e+00,
          1.2557e+00,  1.3583e+00,  1.1956e+00,  1.2307e+00],
        [ 1.1706e+00,  1.1977e+00,  1.2282e+00,  1.2293e+00,  1.2030e+00,
          1.1754e+00,  1.1839e+00,  1.1683e+00,  1.1683e+00,  1.2441e+00,
          1.2708e+00,  1.2573e+00,  1.2953e+00,  1.2361e+00,  1.2872e+00,
          1.2494e+00,  1.2198e+00,  1.2491e+00,  1.2225e+00,  1.2206e+00,
          1.2577e+00,  1.2350e+00,  1.1958e+00,  1.1911e+00,  1.1902e+00,
          1.1836e+00,  1.1836e+00,  2.9947e+00,  2.9433e+00,  2.6231e+00,
          2.7104e+00,  2.9922e+00,  2.6344e+00,  2.9048e+00,  2.6348e+00,
          2.6260e+00,  1.3936e+00,  1.4568e+00,  1.4252e+00,  1.3788e+00,
          1.4356e+00,  1.4191e+00,  1.4045e+00,  1.2825e+00,  1.3485e+00,
          1.3298e+00,  1.2733e+00,  1.2073e+00,  1.1882e+00,  1.3229e+00,
          1.2590e+00,  1.3670e+00,  1.1506e+00,  1.2334e+00],
        [ 1.7479e+00,  1.3690e+00,  5.8696e-01,  8.7339e-01,  1.2690e+00,
          1.6811e+00,  1.5597e+00,  1.7821e+00,  1.7821e+00,  1.5589e+00,
          1.2160e+00,  1.4164e+00,  8.6178e-01,  1.6097e+00,  1.1144e-01,
          1.5006e+00,  1.7735e+00,  7.6990e-01,  1.2754e+00,  9.7133e-01,
          7.2981e-01,  1.0964e+00,  1.6221e+00,  1.6853e+00,  1.4795e+00,
          1.7870e+00,  1.7870e+00,  8.2281e-01,  8.0480e-01,  1.7579e+00,
          1.5559e+00,  8.2602e-01,  1.7010e+00,  1.1832e+00,  1.8096e+00,
          1.7237e+00,  9.4334e-03, -2.1648e-01, -2.4849e-01, -4.2295e-02,
          1.8931e-01,  2.5933e-01, -1.0287e-01,  1.9544e+01,  2.1303e+00,
          6.9472e-01,  1.2602e+00,  1.3242e+00,  1.5532e+00,  8.9654e-01,
          1.4902e+00,  3.1236e-01,  1.6722e+00,  1.7121e+00],
        [ 1.2207e+00,  1.2585e+00,  1.3255e+00,  1.3030e+00,  1.2665e+00,
          1.2275e+00,  1.1957e+00,  1.2175e+00,  1.2175e+00,  1.1906e+00,
          1.3201e+00,  1.2091e+00,  1.3592e+00,  1.2715e+00,  1.4167e+00,
          1.1980e+00,  1.2492e+00,  1.2714e+00,  1.2836e+00,  1.2696e+00,
          1.3339e+00,  1.3011e+00,  1.2465e+00,  1.2399e+00,  1.1357e+00,
          1.2294e+00,  1.2294e+00,  1.2987e+00,  1.3453e+00,  1.2475e+00,
          1.0282e+00,  1.2546e+00,  1.1290e+00,  1.3060e+00,  1.1219e+00,
          1.2512e+00,  1.2690e+00,  9.8610e-01,  1.2649e+00,  1.2862e+00,
          8.2572e-01,  7.5590e-01,  1.2919e+00,  1.1101e+00,  6.2948e-01,
          3.5897e+00,  2.5149e+00,  3.6510e+00,  2.8141e+00,  2.1121e+00,
          1.7874e+00,  2.9549e+00,  3.4994e+00,  1.7634e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 330 : 178.6901132267705
Test loss for epoch 330 : 179.19425001121118
Test Precision for epoch 330 : 0.26153846153846155
Test Recall for epoch 330 : 0.26153846153846155
Test F1 for epoch 330 : 0.26153846153846155


theta for epoch 331 : tensor([[ 2.7010e+00,  2.7338e+00,  2.8095e+00,  2.9492e+00,  2.9117e+00,
          2.7066e+00,  2.8871e+00,  2.6984e+00,  2.6984e+00,  1.2358e+00,
          1.2614e+00,  1.2484e+00,  1.2883e+00,  1.2280e+00,  1.3292e+00,
          1.2408e+00,  1.2130e+00,  1.2457e+00,  1.2122e+00,  1.1883e+00,
          1.2024e+00,  1.2243e+00,  1.1865e+00,  1.1820e+00,  1.2000e+00,
          1.1748e+00,  1.1748e+00,  1.2189e+00,  1.2644e+00,  1.1959e+00,
          1.2204e+00,  1.2646e+00,  1.2058e+00,  1.2370e+00,  1.1554e+00,
          1.1985e+00,  1.4007e+00,  1.4611e+00,  1.4352e+00,  1.4128e+00,
          1.4409e+00,  1.3890e+00,  1.4154e+00,  1.2985e+00,  1.3847e+00,
          1.3210e+00,  1.2666e+00,  1.2526e+00,  1.2313e+00,  1.3144e+00,
          1.2528e+00,  1.3568e+00,  1.2143e+00,  1.2283e+00],
        [ 1.1807e+00,  1.2108e+00,  1.2591e+00,  1.2418e+00,  1.2179e+00,
          1.1866e+00,  1.1954e+00,  1.1786e+00,  1.1786e+00,  2.3846e+00,
          2.4097e+00,  2.3490e+00,  2.6025e+00,  2.3222e+00,  4.1012e+00,
          2.3843e+00,  2.5387e+00,  3.8823e+00,  1.1932e+00,  1.2176e+00,
          1.1892e+00,  1.2056e+00,  1.2069e+00,  1.2016e+00,  1.2201e+00,
          1.1932e+00,  1.1932e+00,  1.2485e+00,  1.2022e+00,  1.2129e+00,
          1.2413e+00,  1.2433e+00,  1.2244e+00,  1.2607e+00,  1.1760e+00,
          1.2159e+00,  1.3528e+00,  1.4253e+00,  1.3360e+00,  1.3645e+00,
          1.4010e+00,  1.4139e+00,  1.3125e+00,  1.2167e+00,  1.3323e+00,
          1.2878e+00,  1.2751e+00,  1.2586e+00,  1.2335e+00,  1.2349e+00,
          1.2589e+00,  1.2848e+00,  1.2138e+00,  1.2302e+00],
        [ 1.1657e+00,  1.1922e+00,  1.2225e+00,  1.2230e+00,  1.1972e+00,
          1.1704e+00,  1.1784e+00,  1.1634e+00,  1.1634e+00,  1.2397e+00,
          1.2658e+00,  1.2525e+00,  1.2932e+00,  1.2318e+00,  1.2857e+00,
          1.2448e+00,  1.1676e+00,  1.2932e+00,  2.7333e+00,  2.9646e+00,
          2.9486e+00,  2.7507e+00,  2.6948e+00,  2.6895e+00,  2.9156e+00,
          2.6809e+00,  2.6809e+00,  1.2062e+00,  1.2663e+00,  1.1999e+00,
          1.2236e+00,  1.2072e+00,  1.2099e+00,  1.2418e+00,  1.2042e+00,
          1.2025e+00,  1.3971e+00,  1.4589e+00,  1.4307e+00,  1.3245e+00,
          1.4365e+00,  1.4207e+00,  1.4121e+00,  1.2925e+00,  1.2949e+00,
          1.3237e+00,  1.2696e+00,  1.2553e+00,  1.2335e+00,  1.3148e+00,
          1.2555e+00,  1.3580e+00,  1.1952e+00,  1.2305e+00],
        [ 1.1704e+00,  1.1975e+00,  1.2278e+00,  1.2291e+00,  1.2027e+00,
          1.1752e+00,  1.1836e+00,  1.1680e+00,  1.1680e+00,  1.2437e+00,
          1.2704e+00,  1.2569e+00,  1.2946e+00,  1.2357e+00,  1.2868e+00,
          1.2490e+00,  1.2193e+00,  1.2488e+00,  1.2223e+00,  1.2200e+00,
          1.2575e+00,  1.2348e+00,  1.1956e+00,  1.1909e+00,  1.1897e+00,
          1.1834e+00,  1.1834e+00,  2.9957e+00,  2.9429e+00,  2.6248e+00,
          2.7099e+00,  2.9932e+00,  2.6361e+00,  2.9043e+00,  2.6368e+00,
          2.6277e+00,  1.3934e+00,  1.4567e+00,  1.4249e+00,  1.3785e+00,
          1.4355e+00,  1.4188e+00,  1.4041e+00,  1.2825e+00,  1.3488e+00,
          1.3296e+00,  1.2730e+00,  1.2073e+00,  1.1880e+00,  1.3227e+00,
          1.2587e+00,  1.3668e+00,  1.1501e+00,  1.2331e+00],
        [ 1.7487e+00,  1.3700e+00,  5.8818e-01,  8.7433e-01,  1.2701e+00,
          1.6820e+00,  1.5606e+00,  1.7830e+00,  1.7830e+00,  1.5593e+00,
          1.2167e+00,  1.4172e+00,  8.6285e-01,  1.6103e+00,  1.1289e-01,
          1.5011e+00,  1.7743e+00,  7.7102e-01,  1.2764e+00,  9.7264e-01,
          7.3103e-01,  1.0974e+00,  1.6231e+00,  1.6862e+00,  1.4807e+00,
          1.7879e+00,  1.7879e+00,  8.2406e-01,  8.0590e-01,  1.7588e+00,
          1.5568e+00,  8.2707e-01,  1.7019e+00,  1.1842e+00,  1.8104e+00,
          1.7246e+00,  7.2319e-03, -2.1845e-01, -2.5046e-01, -4.4558e-02,
          1.8691e-01,  2.5670e-01, -1.0496e-01,  1.9614e+01,  2.0834e+00,
          6.9579e-01,  1.2610e+00,  1.3249e+00,  1.5540e+00,  8.9751e-01,
          1.4910e+00,  3.1365e-01,  1.6732e+00,  1.7128e+00],
        [ 1.2206e+00,  1.2584e+00,  1.3254e+00,  1.3028e+00,  1.2664e+00,
          1.2273e+00,  1.1955e+00,  1.2173e+00,  1.2173e+00,  1.1904e+00,
          1.3198e+00,  1.2087e+00,  1.3589e+00,  1.2712e+00,  1.4165e+00,
          1.1978e+00,  1.2488e+00,  1.2713e+00,  1.2835e+00,  1.2693e+00,
          1.3338e+00,  1.3010e+00,  1.2463e+00,  1.2398e+00,  1.1355e+00,
          1.2293e+00,  1.2293e+00,  1.2985e+00,  1.3452e+00,  1.2473e+00,
          1.0280e+00,  1.2544e+00,  1.1288e+00,  1.3059e+00,  1.1217e+00,
          1.2510e+00,  1.2685e+00,  9.8571e-01,  1.2644e+00,  1.2858e+00,
          8.2529e-01,  7.5554e-01,  1.2914e+00,  1.1092e+00,  6.2984e-01,
          3.5925e+00,  2.5152e+00,  3.6509e+00,  2.8141e+00,  2.1128e+00,
          1.7882e+00,  2.9550e+00,  3.5023e+00,  1.7642e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 331 : 178.67722933379582
Test loss for epoch 331 : 179.18751709496917
Test Precision for epoch 331 : 0.26153846153846155
Test Recall for epoch 331 : 0.26153846153846155
Test F1 for epoch 331 : 0.26153846153846155


theta for epoch 332 : tensor([[ 2.7020e+00,  2.7348e+00,  2.8106e+00,  2.9502e+00,  2.9127e+00,
          2.7076e+00,  2.8881e+00,  2.6994e+00,  2.6994e+00,  1.2355e+00,
          1.2611e+00,  1.2481e+00,  1.2880e+00,  1.2278e+00,  1.3289e+00,
          1.2406e+00,  1.2126e+00,  1.2456e+00,  1.2120e+00,  1.1881e+00,
          1.2022e+00,  1.2241e+00,  1.1864e+00,  1.1819e+00,  1.1999e+00,
          1.1747e+00,  1.1747e+00,  1.2187e+00,  1.2642e+00,  1.1957e+00,
          1.2202e+00,  1.2644e+00,  1.2056e+00,  1.2368e+00,  1.1552e+00,
          1.1982e+00,  1.4007e+00,  1.4612e+00,  1.4352e+00,  1.4129e+00,
          1.4410e+00,  1.3891e+00,  1.4154e+00,  1.2983e+00,  1.3854e+00,
          1.3208e+00,  1.2664e+00,  1.2525e+00,  1.2311e+00,  1.3143e+00,
          1.2526e+00,  1.3566e+00,  1.2140e+00,  1.2281e+00],
        [ 1.1801e+00,  1.2102e+00,  1.2593e+00,  1.2417e+00,  1.2170e+00,
          1.1858e+00,  1.1946e+00,  1.1778e+00,  1.1778e+00,  2.3911e+00,
          2.4170e+00,  2.3580e+00,  2.6142e+00,  2.3311e+00,  4.0745e+00,
          2.3915e+00,  2.5502e+00,  3.8565e+00,  1.1927e+00,  1.2170e+00,
          1.1886e+00,  1.2051e+00,  1.2062e+00,  1.2010e+00,  1.2194e+00,
          1.1926e+00,  1.1926e+00,  1.2479e+00,  1.2020e+00,  1.2122e+00,
          1.2406e+00,  1.2434e+00,  1.2237e+00,  1.2600e+00,  1.1754e+00,
          1.2152e+00,  1.3527e+00,  1.4251e+00,  1.3361e+00,  1.3645e+00,
          1.4009e+00,  1.4138e+00,  1.3125e+00,  1.2173e+00,  1.3331e+00,
          1.2874e+00,  1.2744e+00,  1.2580e+00,  1.2329e+00,  1.2346e+00,
          1.2583e+00,  1.2845e+00,  1.2132e+00,  1.2295e+00],
        [ 1.1654e+00,  1.1919e+00,  1.2220e+00,  1.2227e+00,  1.1969e+00,
          1.1701e+00,  1.1782e+00,  1.1631e+00,  1.1631e+00,  1.2394e+00,
          1.2655e+00,  1.2522e+00,  1.2929e+00,  1.2315e+00,  1.2853e+00,
          1.2446e+00,  1.1671e+00,  1.2929e+00,  2.7341e+00,  2.9668e+00,
          2.9497e+00,  2.7514e+00,  2.6953e+00,  2.6901e+00,  2.9179e+00,
          2.6815e+00,  2.6815e+00,  1.2058e+00,  1.2660e+00,  1.1997e+00,
          1.2234e+00,  1.2067e+00,  1.2097e+00,  1.2416e+00,  1.2039e+00,
          1.2023e+00,  1.3971e+00,  1.4589e+00,  1.4307e+00,  1.3242e+00,
          1.4366e+00,  1.4205e+00,  1.4121e+00,  1.2924e+00,  1.2953e+00,
          1.3236e+00,  1.2694e+00,  1.2552e+00,  1.2334e+00,  1.3145e+00,
          1.2553e+00,  1.3577e+00,  1.1947e+00,  1.2304e+00],
        [ 1.1701e+00,  1.1971e+00,  1.2273e+00,  1.2287e+00,  1.2024e+00,
          1.1749e+00,  1.1833e+00,  1.1677e+00,  1.1677e+00,  1.2434e+00,
          1.2701e+00,  1.2565e+00,  1.2940e+00,  1.2354e+00,  1.2864e+00,
          1.2487e+00,  1.2189e+00,  1.2485e+00,  1.2221e+00,  1.2194e+00,
          1.2573e+00,  1.2347e+00,  1.1954e+00,  1.1907e+00,  1.1893e+00,
          1.1832e+00,  1.1832e+00,  2.9968e+00,  2.9425e+00,  2.6266e+00,
          2.7096e+00,  2.9943e+00,  2.6379e+00,  2.9039e+00,  2.6388e+00,
          2.6294e+00,  1.3933e+00,  1.4566e+00,  1.4245e+00,  1.3781e+00,
          1.4354e+00,  1.4185e+00,  1.4038e+00,  1.2824e+00,  1.3491e+00,
          1.3294e+00,  1.2728e+00,  1.2071e+00,  1.1877e+00,  1.3225e+00,
          1.2585e+00,  1.3666e+00,  1.1496e+00,  1.2329e+00],
        [ 1.7495e+00,  1.3709e+00,  5.8940e-01,  8.7527e-01,  1.2711e+00,
          1.6829e+00,  1.5614e+00,  1.7839e+00,  1.7839e+00,  1.5598e+00,
          1.2176e+00,  1.4181e+00,  8.6403e-01,  1.6111e+00,  1.1449e-01,
          1.5018e+00,  1.7751e+00,  7.7229e-01,  1.2775e+00,  9.7399e-01,
          7.3231e-01,  1.0985e+00,  1.6241e+00,  1.6872e+00,  1.4819e+00,
          1.7889e+00,  1.7889e+00,  8.2532e-01,  8.0702e-01,  1.7597e+00,
          1.5577e+00,  8.2816e-01,  1.7028e+00,  1.1851e+00,  1.8113e+00,
          1.7255e+00,  4.9699e-03, -2.2047e-01, -2.5248e-01, -4.6864e-02,
          1.8445e-01,  2.5400e-01, -1.0710e-01,  1.9685e+01,  2.0385e+00,
          6.9688e-01,  1.2619e+00,  1.3256e+00,  1.5547e+00,  8.9848e-01,
          1.4917e+00,  3.1497e-01,  1.6742e+00,  1.7134e+00],
        [ 1.2204e+00,  1.2581e+00,  1.3252e+00,  1.3026e+00,  1.2662e+00,
          1.2271e+00,  1.1953e+00,  1.2171e+00,  1.2171e+00,  1.1903e+00,
          1.3196e+00,  1.2085e+00,  1.3586e+00,  1.2710e+00,  1.4164e+00,
          1.1977e+00,  1.2485e+00,  1.2714e+00,  1.2834e+00,  1.2692e+00,
          1.3337e+00,  1.3009e+00,  1.2462e+00,  1.2397e+00,  1.1353e+00,
          1.2292e+00,  1.2292e+00,  1.2983e+00,  1.3451e+00,  1.2471e+00,
          1.0278e+00,  1.2543e+00,  1.1286e+00,  1.3057e+00,  1.1215e+00,
          1.2508e+00,  1.2681e+00,  9.8534e-01,  1.2639e+00,  1.2854e+00,
          8.2488e-01,  7.5519e-01,  1.2910e+00,  1.1082e+00,  6.3022e-01,
          3.5954e+00,  2.5157e+00,  3.6509e+00,  2.8141e+00,  2.1137e+00,
          1.7890e+00,  2.9552e+00,  3.5053e+00,  1.7650e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 332 : 178.6647826200517
Test loss for epoch 332 : 179.18103643914628
Test Precision for epoch 332 : 0.26153846153846155
Test Recall for epoch 332 : 0.26153846153846155
Test F1 for epoch 332 : 0.26153846153846155


theta for epoch 333 : tensor([[ 2.7031e+00,  2.7360e+00,  2.8118e+00,  2.9514e+00,  2.9138e+00,
          2.7087e+00,  2.8893e+00,  2.7005e+00,  2.7005e+00,  1.2353e+00,
          1.2608e+00,  1.2478e+00,  1.2876e+00,  1.2275e+00,  1.3287e+00,
          1.2404e+00,  1.2123e+00,  1.2454e+00,  1.2118e+00,  1.1878e+00,
          1.2020e+00,  1.2239e+00,  1.1861e+00,  1.1816e+00,  1.1996e+00,
          1.1744e+00,  1.1744e+00,  1.2184e+00,  1.2639e+00,  1.1954e+00,
          1.2200e+00,  1.2642e+00,  1.2053e+00,  1.2366e+00,  1.1549e+00,
          1.1980e+00,  1.4007e+00,  1.4612e+00,  1.4352e+00,  1.4129e+00,
          1.4410e+00,  1.3892e+00,  1.4153e+00,  1.2981e+00,  1.3861e+00,
          1.3207e+00,  1.2662e+00,  1.2523e+00,  1.2309e+00,  1.3141e+00,
          1.2524e+00,  1.3564e+00,  1.2138e+00,  1.2279e+00],
        [ 1.1795e+00,  1.2096e+00,  1.2594e+00,  1.2416e+00,  1.2162e+00,
          1.1850e+00,  1.1939e+00,  1.1770e+00,  1.1770e+00,  2.3977e+00,
          2.4244e+00,  2.3670e+00,  2.6258e+00,  2.3400e+00,  4.0485e+00,
          2.3986e+00,  2.5616e+00,  3.8313e+00,  1.1922e+00,  1.2163e+00,
          1.1879e+00,  1.2046e+00,  1.2054e+00,  1.2003e+00,  1.2187e+00,
          1.1919e+00,  1.1919e+00,  1.2473e+00,  1.2018e+00,  1.2115e+00,
          1.2399e+00,  1.2434e+00,  1.2230e+00,  1.2592e+00,  1.1748e+00,
          1.2144e+00,  1.3525e+00,  1.4249e+00,  1.3361e+00,  1.3645e+00,
          1.4007e+00,  1.4137e+00,  1.3125e+00,  1.2178e+00,  1.3338e+00,
          1.2870e+00,  1.2738e+00,  1.2574e+00,  1.2323e+00,  1.2344e+00,
          1.2576e+00,  1.2842e+00,  1.2125e+00,  1.2289e+00],
        [ 1.1652e+00,  1.1917e+00,  1.2216e+00,  1.2225e+00,  1.1967e+00,
          1.1699e+00,  1.1779e+00,  1.1629e+00,  1.1629e+00,  1.2392e+00,
          1.2653e+00,  1.2520e+00,  1.2926e+00,  1.2313e+00,  1.2849e+00,
          1.2444e+00,  1.1666e+00,  1.2927e+00,  2.7349e+00,  2.9691e+00,
          2.9508e+00,  2.7522e+00,  2.6960e+00,  2.6906e+00,  2.9201e+00,
          2.6821e+00,  2.6821e+00,  1.2054e+00,  1.2657e+00,  1.1995e+00,
          1.2232e+00,  1.2063e+00,  1.2095e+00,  1.2414e+00,  1.2037e+00,
          1.2021e+00,  1.3971e+00,  1.4590e+00,  1.4308e+00,  1.3239e+00,
          1.4367e+00,  1.4203e+00,  1.4121e+00,  1.2922e+00,  1.2957e+00,
          1.3234e+00,  1.2692e+00,  1.2550e+00,  1.2332e+00,  1.3142e+00,
          1.2552e+00,  1.3574e+00,  1.1943e+00,  1.2302e+00],
        [ 1.1698e+00,  1.1968e+00,  1.2268e+00,  1.2284e+00,  1.2021e+00,
          1.1746e+00,  1.1830e+00,  1.1674e+00,  1.1674e+00,  1.2432e+00,
          1.2698e+00,  1.2562e+00,  1.2935e+00,  1.2351e+00,  1.2861e+00,
          1.2485e+00,  1.2186e+00,  1.2483e+00,  1.2218e+00,  1.2188e+00,
          1.2570e+00,  1.2344e+00,  1.1951e+00,  1.1905e+00,  1.1889e+00,
          1.1829e+00,  1.1829e+00,  2.9980e+00,  2.9423e+00,  2.6284e+00,
          2.7094e+00,  2.9956e+00,  2.6397e+00,  2.9036e+00,  2.6410e+00,
          2.6313e+00,  1.3932e+00,  1.4565e+00,  1.4242e+00,  1.3778e+00,
          1.4353e+00,  1.4182e+00,  1.4034e+00,  1.2823e+00,  1.3494e+00,
          1.3291e+00,  1.2726e+00,  1.2070e+00,  1.1875e+00,  1.3223e+00,
          1.2582e+00,  1.3664e+00,  1.1492e+00,  1.2326e+00],
        [ 1.7503e+00,  1.3719e+00,  5.9071e-01,  8.7630e-01,  1.2722e+00,
          1.6839e+00,  1.5623e+00,  1.7848e+00,  1.7848e+00,  1.5605e+00,
          1.2185e+00,  1.4191e+00,  8.6526e-01,  1.6120e+00,  1.1618e-01,
          1.5026e+00,  1.7760e+00,  7.7364e-01,  1.2785e+00,  9.7528e-01,
          7.3355e-01,  1.0996e+00,  1.6250e+00,  1.6882e+00,  1.4830e+00,
          1.7899e+00,  1.7899e+00,  8.2659e-01,  8.0818e-01,  1.7606e+00,
          1.5586e+00,  8.2928e-01,  1.7037e+00,  1.1861e+00,  1.8122e+00,
          1.7264e+00,  2.6497e-03, -2.2254e-01, -2.5454e-01, -4.9213e-02,
          1.8192e-01,  2.5125e-01, -1.0930e-01,  1.9755e+01,  1.9955e+00,
          6.9802e-01,  1.2628e+00,  1.3264e+00,  1.5554e+00,  8.9950e-01,
          1.4925e+00,  3.1634e-01,  1.6752e+00,  1.7141e+00],
        [ 1.2202e+00,  1.2579e+00,  1.3250e+00,  1.3024e+00,  1.2660e+00,
          1.2268e+00,  1.1951e+00,  1.2168e+00,  1.2168e+00,  1.1902e+00,
          1.3195e+00,  1.2084e+00,  1.3583e+00,  1.2708e+00,  1.4163e+00,
          1.1976e+00,  1.2483e+00,  1.2714e+00,  1.2833e+00,  1.2689e+00,
          1.3335e+00,  1.3008e+00,  1.2460e+00,  1.2395e+00,  1.1350e+00,
          1.2290e+00,  1.2290e+00,  1.2981e+00,  1.3449e+00,  1.2469e+00,
          1.0276e+00,  1.2541e+00,  1.1284e+00,  1.3056e+00,  1.1212e+00,
          1.2506e+00,  1.2676e+00,  9.8496e-01,  1.2635e+00,  1.2850e+00,
          8.2446e-01,  7.5482e-01,  1.2905e+00,  1.1072e+00,  6.3058e-01,
          3.5985e+00,  2.5164e+00,  3.6510e+00,  2.8144e+00,  2.1147e+00,
          1.7900e+00,  2.9556e+00,  3.5084e+00,  1.7659e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 333 : 178.652759136109
Test loss for epoch 333 : 179.17481792135175
Test Precision for epoch 333 : 0.26153846153846155
Test Recall for epoch 333 : 0.26153846153846155
Test F1 for epoch 333 : 0.26153846153846155


theta for epoch 334 : tensor([[ 2.7045e+00,  2.7373e+00,  2.8131e+00,  2.9527e+00,  2.9151e+00,
          2.7100e+00,  2.8906e+00,  2.7018e+00,  2.7018e+00,  1.2349e+00,
          1.2604e+00,  1.2473e+00,  1.2871e+00,  1.2271e+00,  1.3283e+00,
          1.2400e+00,  1.2118e+00,  1.2451e+00,  1.2115e+00,  1.1876e+00,
          1.2017e+00,  1.2237e+00,  1.1859e+00,  1.1814e+00,  1.1993e+00,
          1.1742e+00,  1.1742e+00,  1.2182e+00,  1.2637e+00,  1.1952e+00,
          1.2197e+00,  1.2639e+00,  1.2051e+00,  1.2363e+00,  1.1547e+00,
          1.1977e+00,  1.4007e+00,  1.4612e+00,  1.4352e+00,  1.4129e+00,
          1.4410e+00,  1.3892e+00,  1.4153e+00,  1.2979e+00,  1.3868e+00,
          1.3204e+00,  1.2660e+00,  1.2521e+00,  1.2307e+00,  1.3138e+00,
          1.2522e+00,  1.3562e+00,  1.2135e+00,  1.2277e+00],
        [ 1.1790e+00,  1.2091e+00,  1.2596e+00,  1.2414e+00,  1.2156e+00,
          1.1843e+00,  1.1934e+00,  1.1764e+00,  1.1764e+00,  2.4042e+00,
          2.4315e+00,  2.3758e+00,  2.6373e+00,  2.3488e+00,  4.0230e+00,
          2.4056e+00,  2.5728e+00,  3.8066e+00,  1.1917e+00,  1.2158e+00,
          1.1873e+00,  1.2042e+00,  1.2047e+00,  1.1996e+00,  1.2181e+00,
          1.1912e+00,  1.1912e+00,  1.2468e+00,  1.2016e+00,  1.2108e+00,
          1.2392e+00,  1.2435e+00,  1.2223e+00,  1.2586e+00,  1.1743e+00,
          1.2138e+00,  1.3524e+00,  1.4247e+00,  1.3361e+00,  1.3645e+00,
          1.4006e+00,  1.4137e+00,  1.3126e+00,  1.2184e+00,  1.3345e+00,
          1.2866e+00,  1.2732e+00,  1.2568e+00,  1.2317e+00,  1.2342e+00,
          1.2570e+00,  1.2839e+00,  1.2119e+00,  1.2283e+00],
        [ 1.1650e+00,  1.1915e+00,  1.2212e+00,  1.2223e+00,  1.1965e+00,
          1.1697e+00,  1.1777e+00,  1.1627e+00,  1.1627e+00,  1.2389e+00,
          1.2649e+00,  1.2516e+00,  1.2921e+00,  1.2309e+00,  1.2844e+00,
          1.2441e+00,  1.1661e+00,  1.2923e+00,  2.7359e+00,  2.9715e+00,
          2.9521e+00,  2.7531e+00,  2.6968e+00,  2.6914e+00,  2.9226e+00,
          2.6829e+00,  2.6829e+00,  1.2050e+00,  1.2654e+00,  1.1993e+00,
          1.2231e+00,  1.2060e+00,  1.2093e+00,  1.2412e+00,  1.2035e+00,
          1.2019e+00,  1.3971e+00,  1.4590e+00,  1.4308e+00,  1.3237e+00,
          1.4367e+00,  1.4202e+00,  1.4121e+00,  1.2920e+00,  1.2961e+00,
          1.3232e+00,  1.2691e+00,  1.2549e+00,  1.2330e+00,  1.3139e+00,
          1.2550e+00,  1.3571e+00,  1.1939e+00,  1.2300e+00],
        [ 1.1695e+00,  1.1966e+00,  1.2264e+00,  1.2282e+00,  1.2018e+00,
          1.1743e+00,  1.1827e+00,  1.1671e+00,  1.1671e+00,  1.2428e+00,
          1.2694e+00,  1.2557e+00,  1.2928e+00,  1.2346e+00,  1.2857e+00,
          1.2481e+00,  1.2181e+00,  1.2480e+00,  1.2216e+00,  1.2182e+00,
          1.2567e+00,  1.2342e+00,  1.1948e+00,  1.1902e+00,  1.1885e+00,
          1.1827e+00,  1.1827e+00,  2.9994e+00,  2.9423e+00,  2.6304e+00,
          2.7093e+00,  2.9970e+00,  2.6417e+00,  2.9035e+00,  2.6432e+00,
          2.6333e+00,  1.3930e+00,  1.4564e+00,  1.4238e+00,  1.3775e+00,
          1.4352e+00,  1.4179e+00,  1.4030e+00,  1.2821e+00,  1.3498e+00,
          1.3289e+00,  1.2723e+00,  1.2069e+00,  1.1872e+00,  1.3221e+00,
          1.2579e+00,  1.3661e+00,  1.1487e+00,  1.2323e+00],
        [ 1.7512e+00,  1.3730e+00,  5.9209e-01,  8.7741e-01,  1.2733e+00,
          1.6849e+00,  1.5633e+00,  1.7858e+00,  1.7858e+00,  1.5611e+00,
          1.2194e+00,  1.4200e+00,  8.6639e-01,  1.6128e+00,  1.1782e-01,
          1.5033e+00,  1.7768e+00,  7.7489e-01,  1.2796e+00,  9.7656e-01,
          7.3480e-01,  1.1007e+00,  1.6260e+00,  1.6891e+00,  1.4841e+00,
          1.7908e+00,  1.7908e+00,  8.2789e-01,  8.0938e-01,  1.7615e+00,
          1.5596e+00,  8.3045e-01,  1.7047e+00,  1.1872e+00,  1.8131e+00,
          1.7273e+00,  3.0300e-04, -2.2464e-01, -2.5663e-01, -5.1575e-02,
          1.7936e-01,  2.4847e-01, -1.1151e-01,  1.9825e+01,  1.9547e+00,
          6.9915e-01,  1.2636e+00,  1.3271e+00,  1.5562e+00,  9.0051e-01,
          1.4933e+00,  3.1771e-01,  1.6761e+00,  1.7148e+00],
        [ 1.2201e+00,  1.2578e+00,  1.3248e+00,  1.3023e+00,  1.2658e+00,
          1.2267e+00,  1.1949e+00,  1.2167e+00,  1.2167e+00,  1.1900e+00,
          1.3192e+00,  1.2081e+00,  1.3580e+00,  1.2705e+00,  1.4160e+00,
          1.1973e+00,  1.2479e+00,  1.2713e+00,  1.2831e+00,  1.2686e+00,
          1.3333e+00,  1.3006e+00,  1.2458e+00,  1.2393e+00,  1.1347e+00,
          1.2288e+00,  1.2288e+00,  1.2980e+00,  1.3448e+00,  1.2467e+00,
          1.0274e+00,  1.2539e+00,  1.1282e+00,  1.3054e+00,  1.1210e+00,
          1.2504e+00,  1.2672e+00,  9.8460e-01,  1.2631e+00,  1.2846e+00,
          8.2406e-01,  7.5447e-01,  1.2902e+00,  1.1062e+00,  6.3096e-01,
          3.6016e+00,  2.5173e+00,  3.6514e+00,  2.8149e+00,  2.1158e+00,
          1.7910e+00,  2.9561e+00,  3.5116e+00,  1.7670e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 334 : 178.6411418055468
Test loss for epoch 334 : 179.16892814619555
Test Precision for epoch 334 : 0.26153846153846155
Test Recall for epoch 334 : 0.26153846153846155
Test F1 for epoch 334 : 0.26153846153846155


theta for epoch 335 : tensor([[ 2.7058e+00,  2.7387e+00,  2.8145e+00,  2.9541e+00,  2.9165e+00,
          2.7114e+00,  2.8920e+00,  2.7032e+00,  2.7032e+00,  1.2346e+00,
          1.2601e+00,  1.2470e+00,  1.2867e+00,  1.2268e+00,  1.3280e+00,
          1.2397e+00,  1.2114e+00,  1.2449e+00,  1.2114e+00,  1.1874e+00,
          1.2015e+00,  1.2235e+00,  1.1857e+00,  1.1812e+00,  1.1991e+00,
          1.1740e+00,  1.1740e+00,  1.2180e+00,  1.2635e+00,  1.1950e+00,
          1.2195e+00,  1.2637e+00,  1.2048e+00,  1.2361e+00,  1.1544e+00,
          1.1975e+00,  1.4006e+00,  1.4612e+00,  1.4352e+00,  1.4129e+00,
          1.4410e+00,  1.3893e+00,  1.4153e+00,  1.2976e+00,  1.3874e+00,
          1.3202e+00,  1.2658e+00,  1.2519e+00,  1.2305e+00,  1.3136e+00,
          1.2519e+00,  1.3560e+00,  1.2133e+00,  1.2274e+00],
        [ 1.1784e+00,  1.2084e+00,  1.2596e+00,  1.2411e+00,  1.2148e+00,
          1.1836e+00,  1.1928e+00,  1.1756e+00,  1.1756e+00,  2.4108e+00,
          2.4388e+00,  2.3848e+00,  2.6488e+00,  2.3578e+00,  3.9981e+00,
          2.4127e+00,  2.5841e+00,  3.7828e+00,  1.1912e+00,  1.2152e+00,
          1.1866e+00,  1.2039e+00,  1.2040e+00,  1.1989e+00,  1.2175e+00,
          1.1906e+00,  1.1906e+00,  1.2463e+00,  1.2014e+00,  1.2101e+00,
          1.2386e+00,  1.2434e+00,  1.2216e+00,  1.2579e+00,  1.1738e+00,
          1.2131e+00,  1.3522e+00,  1.4245e+00,  1.3361e+00,  1.3644e+00,
          1.4004e+00,  1.4135e+00,  1.3125e+00,  1.2189e+00,  1.3352e+00,
          1.2861e+00,  1.2726e+00,  1.2562e+00,  1.2311e+00,  1.2339e+00,
          1.2564e+00,  1.2836e+00,  1.2113e+00,  1.2277e+00],
        [ 1.1647e+00,  1.1912e+00,  1.2208e+00,  1.2220e+00,  1.1962e+00,
          1.1694e+00,  1.1774e+00,  1.1624e+00,  1.1624e+00,  1.2386e+00,
          1.2646e+00,  1.2512e+00,  1.2917e+00,  1.2306e+00,  1.2839e+00,
          1.2438e+00,  1.1655e+00,  1.2919e+00,  2.7371e+00,  2.9741e+00,
          2.9536e+00,  2.7543e+00,  2.6977e+00,  2.6923e+00,  2.9251e+00,
          2.6839e+00,  2.6839e+00,  1.2046e+00,  1.2650e+00,  1.1991e+00,
          1.2229e+00,  1.2056e+00,  1.2091e+00,  1.2410e+00,  1.2033e+00,
          1.2016e+00,  1.3971e+00,  1.4590e+00,  1.4308e+00,  1.3234e+00,
          1.4367e+00,  1.4200e+00,  1.4121e+00,  1.2917e+00,  1.2965e+00,
          1.3230e+00,  1.2689e+00,  1.2547e+00,  1.2328e+00,  1.3135e+00,
          1.2547e+00,  1.3567e+00,  1.1935e+00,  1.2297e+00],
        [ 1.1692e+00,  1.1963e+00,  1.2260e+00,  1.2279e+00,  1.2015e+00,
          1.1740e+00,  1.1824e+00,  1.1668e+00,  1.1668e+00,  1.2425e+00,
          1.2690e+00,  1.2554e+00,  1.2922e+00,  1.2343e+00,  1.2852e+00,
          1.2477e+00,  1.2177e+00,  1.2476e+00,  1.2213e+00,  1.2177e+00,
          1.2565e+00,  1.2340e+00,  1.1946e+00,  1.1899e+00,  1.1881e+00,
          1.1824e+00,  1.1824e+00,  3.0009e+00,  2.9423e+00,  2.6325e+00,
          2.7094e+00,  2.9986e+00,  2.6438e+00,  2.9035e+00,  2.6456e+00,
          2.6354e+00,  1.3929e+00,  1.4563e+00,  1.4234e+00,  1.3772e+00,
          1.4351e+00,  1.4177e+00,  1.4026e+00,  1.2819e+00,  1.3502e+00,
          1.3286e+00,  1.2720e+00,  1.2067e+00,  1.1869e+00,  1.3218e+00,
          1.2577e+00,  1.3659e+00,  1.1483e+00,  1.2320e+00],
        [ 1.7521e+00,  1.3740e+00,  5.9349e-01,  8.7854e-01,  1.2744e+00,
          1.6859e+00,  1.5642e+00,  1.7868e+00,  1.7868e+00,  1.5619e+00,
          1.2204e+00,  1.4210e+00,  8.6764e-01,  1.6137e+00,  1.1959e-01,
          1.5042e+00,  1.7777e+00,  7.7627e-01,  1.2807e+00,  9.7793e-01,
          7.3615e-01,  1.1019e+00,  1.6270e+00,  1.6901e+00,  1.4852e+00,
          1.7918e+00,  1.7918e+00,  8.2923e-01,  8.1064e-01,  1.7625e+00,
          1.5605e+00,  8.3167e-01,  1.7057e+00,  1.1883e+00,  1.8140e+00,
          1.7283e+00, -2.1280e-03, -2.2680e-01, -2.5879e-01, -5.4011e-02,
          1.7670e-01,  2.4561e-01, -1.1381e-01,  1.9894e+01,  1.9158e+00,
          7.0034e-01,  1.2646e+00,  1.3279e+00,  1.5570e+00,  9.0156e-01,
          1.4941e+00,  3.1916e-01,  1.6771e+00,  1.7155e+00],
        [ 1.2198e+00,  1.2576e+00,  1.3246e+00,  1.3020e+00,  1.2656e+00,
          1.2264e+00,  1.1947e+00,  1.2164e+00,  1.2164e+00,  1.1898e+00,
          1.3190e+00,  1.2078e+00,  1.3576e+00,  1.2703e+00,  1.4159e+00,
          1.1972e+00,  1.2476e+00,  1.2712e+00,  1.2830e+00,  1.2684e+00,
          1.3332e+00,  1.3005e+00,  1.2456e+00,  1.2391e+00,  1.1345e+00,
          1.2286e+00,  1.2286e+00,  1.2978e+00,  1.3447e+00,  1.2465e+00,
          1.0272e+00,  1.2538e+00,  1.1280e+00,  1.3053e+00,  1.1208e+00,
          1.2502e+00,  1.2668e+00,  9.8422e-01,  1.2626e+00,  1.2842e+00,
          8.2363e-01,  7.5409e-01,  1.2898e+00,  1.1052e+00,  6.3129e-01,
          3.6049e+00,  2.5183e+00,  3.6519e+00,  2.8155e+00,  2.1170e+00,
          1.7922e+00,  2.9568e+00,  3.5149e+00,  1.7681e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 335 : 178.6299117993389
Test loss for epoch 335 : 179.16317099609188
Test Precision for epoch 335 : 0.26153846153846155
Test Recall for epoch 335 : 0.26153846153846155
Test F1 for epoch 335 : 0.26153846153846155


theta for epoch 336 : tensor([[ 2.7074e+00,  2.7402e+00,  2.8161e+00,  2.9556e+00,  2.9180e+00,
          2.7129e+00,  2.8935e+00,  2.7047e+00,  2.7047e+00,  1.2343e+00,
          1.2597e+00,  1.2466e+00,  1.2863e+00,  1.2264e+00,  1.3277e+00,
          1.2394e+00,  1.2111e+00,  1.2447e+00,  1.2111e+00,  1.1871e+00,
          1.2012e+00,  1.2233e+00,  1.1854e+00,  1.1809e+00,  1.1989e+00,
          1.1737e+00,  1.1737e+00,  1.2177e+00,  1.2632e+00,  1.1947e+00,
          1.2193e+00,  1.2634e+00,  1.2045e+00,  1.2359e+00,  1.1541e+00,
          1.1972e+00,  1.4006e+00,  1.4612e+00,  1.4352e+00,  1.4129e+00,
          1.4410e+00,  1.3893e+00,  1.4153e+00,  1.2974e+00,  1.3881e+00,
          1.3200e+00,  1.2656e+00,  1.2517e+00,  1.2302e+00,  1.3134e+00,
          1.2517e+00,  1.3558e+00,  1.2130e+00,  1.2272e+00],
        [ 1.1778e+00,  1.2078e+00,  1.2595e+00,  1.2407e+00,  1.2141e+00,
          1.1828e+00,  1.1922e+00,  1.1749e+00,  1.1749e+00,  2.4175e+00,
          2.4460e+00,  2.3938e+00,  2.6603e+00,  2.3668e+00,  3.9739e+00,
          2.4199e+00,  2.5952e+00,  3.7596e+00,  1.1908e+00,  1.2147e+00,
          1.1860e+00,  1.2036e+00,  1.2033e+00,  1.1982e+00,  1.2169e+00,
          1.1898e+00,  1.1898e+00,  1.2458e+00,  1.2012e+00,  1.2094e+00,
          1.2379e+00,  1.2433e+00,  1.2209e+00,  1.2572e+00,  1.1733e+00,
          1.2124e+00,  1.3520e+00,  1.4243e+00,  1.3361e+00,  1.3644e+00,
          1.4002e+00,  1.4134e+00,  1.3125e+00,  1.2193e+00,  1.3359e+00,
          1.2857e+00,  1.2720e+00,  1.2556e+00,  1.2305e+00,  1.2337e+00,
          1.2557e+00,  1.2833e+00,  1.2107e+00,  1.2271e+00],
        [ 1.1645e+00,  1.1910e+00,  1.2203e+00,  1.2217e+00,  1.1959e+00,
          1.1691e+00,  1.1772e+00,  1.1621e+00,  1.1621e+00,  1.2384e+00,
          1.2643e+00,  1.2509e+00,  1.2914e+00,  1.2303e+00,  1.2835e+00,
          1.2435e+00,  1.1650e+00,  1.2916e+00,  2.7384e+00,  2.9768e+00,
          2.9552e+00,  2.7555e+00,  2.6987e+00,  2.6933e+00,  2.9278e+00,
          2.6849e+00,  2.6849e+00,  1.2042e+00,  1.2646e+00,  1.1988e+00,
          1.2226e+00,  1.2051e+00,  1.2088e+00,  1.2408e+00,  1.2030e+00,
          1.2014e+00,  1.3971e+00,  1.4590e+00,  1.4308e+00,  1.3231e+00,
          1.4368e+00,  1.4199e+00,  1.4121e+00,  1.2915e+00,  1.2970e+00,
          1.3228e+00,  1.2687e+00,  1.2545e+00,  1.2326e+00,  1.3132e+00,
          1.2545e+00,  1.3563e+00,  1.1932e+00,  1.2295e+00],
        [ 1.1689e+00,  1.1959e+00,  1.2255e+00,  1.2275e+00,  1.2012e+00,
          1.1736e+00,  1.1821e+00,  1.1665e+00,  1.1665e+00,  1.2422e+00,
          1.2686e+00,  1.2550e+00,  1.2915e+00,  1.2339e+00,  1.2848e+00,
          1.2474e+00,  1.2173e+00,  1.2473e+00,  1.2211e+00,  1.2171e+00,
          1.2562e+00,  1.2337e+00,  1.1943e+00,  1.1896e+00,  1.1877e+00,
          1.1821e+00,  1.1821e+00,  3.0026e+00,  2.9425e+00,  2.6347e+00,
          2.7096e+00,  3.0003e+00,  2.6460e+00,  2.9036e+00,  2.6481e+00,
          2.6375e+00,  1.3928e+00,  1.4562e+00,  1.4231e+00,  1.3769e+00,
          1.4351e+00,  1.4174e+00,  1.4022e+00,  1.2817e+00,  1.3506e+00,
          1.3284e+00,  1.2718e+00,  1.2065e+00,  1.1866e+00,  1.3215e+00,
          1.2574e+00,  1.3656e+00,  1.1478e+00,  1.2317e+00],
        [ 1.7530e+00,  1.3751e+00,  5.9491e-01,  8.7970e-01,  1.2755e+00,
          1.6869e+00,  1.5652e+00,  1.7877e+00,  1.7877e+00,  1.5628e+00,
          1.2215e+00,  1.4220e+00,  8.6891e-01,  1.6146e+00,  1.2138e-01,
          1.5052e+00,  1.7786e+00,  7.7767e-01,  1.2818e+00,  9.7925e-01,
          7.3746e-01,  1.1030e+00,  1.6280e+00,  1.6911e+00,  1.4863e+00,
          1.7927e+00,  1.7927e+00,  8.3054e-01,  8.1188e-01,  1.7634e+00,
          1.5615e+00,  8.3287e-01,  1.7066e+00,  1.1893e+00,  1.8149e+00,
          1.7292e+00, -4.5698e-03, -2.2897e-01, -2.6095e-01, -5.6448e-02,
          1.7403e-01,  2.4274e-01, -1.1612e-01,  1.9963e+01,  1.8792e+00,
          7.0150e-01,  1.2654e+00,  1.3287e+00,  1.5577e+00,  9.0259e-01,
          1.4948e+00,  3.2058e-01,  1.6780e+00,  1.7162e+00],
        [ 1.2196e+00,  1.2574e+00,  1.3244e+00,  1.3018e+00,  1.2654e+00,
          1.2262e+00,  1.1945e+00,  1.2162e+00,  1.2162e+00,  1.1897e+00,
          1.3187e+00,  1.2076e+00,  1.3574e+00,  1.2701e+00,  1.4157e+00,
          1.1970e+00,  1.2473e+00,  1.2712e+00,  1.2828e+00,  1.2682e+00,
          1.3330e+00,  1.3004e+00,  1.2455e+00,  1.2389e+00,  1.1342e+00,
          1.2284e+00,  1.2284e+00,  1.2976e+00,  1.3445e+00,  1.2463e+00,
          1.0270e+00,  1.2536e+00,  1.1277e+00,  1.3051e+00,  1.1206e+00,
          1.2500e+00,  1.2665e+00,  9.8387e-01,  1.2623e+00,  1.2839e+00,
          8.2326e-01,  7.5375e-01,  1.2894e+00,  1.1043e+00,  6.3165e-01,
          3.6082e+00,  2.5194e+00,  3.6525e+00,  2.8163e+00,  2.1184e+00,
          1.7935e+00,  2.9577e+00,  3.5184e+00,  1.7694e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 336 : 178.61905132380897
Test loss for epoch 336 : 179.15767986483453
Test Precision for epoch 336 : 0.26153846153846155
Test Recall for epoch 336 : 0.26153846153846155
Test F1 for epoch 336 : 0.26153846153846155


theta for epoch 337 : tensor([[ 2.7091e+00,  2.7419e+00,  2.8178e+00,  2.9574e+00,  2.9197e+00,
          2.7146e+00,  2.8952e+00,  2.7064e+00,  2.7064e+00,  1.2339e+00,
          1.2593e+00,  1.2462e+00,  1.2858e+00,  1.2260e+00,  1.3272e+00,
          1.2389e+00,  1.2106e+00,  1.2443e+00,  1.2108e+00,  1.1868e+00,
          1.2009e+00,  1.2230e+00,  1.1851e+00,  1.1806e+00,  1.1985e+00,
          1.1734e+00,  1.1734e+00,  1.2174e+00,  1.2630e+00,  1.1944e+00,
          1.2190e+00,  1.2631e+00,  1.2042e+00,  1.2356e+00,  1.1538e+00,
          1.1969e+00,  1.4006e+00,  1.4611e+00,  1.4352e+00,  1.4129e+00,
          1.4410e+00,  1.3893e+00,  1.4152e+00,  1.2971e+00,  1.3887e+00,
          1.3197e+00,  1.2653e+00,  1.2514e+00,  1.2300e+00,  1.3131e+00,
          1.2514e+00,  1.3555e+00,  1.2128e+00,  1.2269e+00],
        [ 1.1772e+00,  1.2073e+00,  1.2594e+00,  1.2403e+00,  1.2134e+00,
          1.1822e+00,  1.1917e+00,  1.1742e+00,  1.1742e+00,  2.4241e+00,
          2.4532e+00,  2.4026e+00,  2.6717e+00,  2.3757e+00,  3.9503e+00,
          2.4269e+00,  2.6062e+00,  3.7371e+00,  1.1903e+00,  1.2142e+00,
          1.1854e+00,  1.2033e+00,  1.2026e+00,  1.1975e+00,  1.2164e+00,
          1.1892e+00,  1.1892e+00,  1.2454e+00,  1.2010e+00,  1.2088e+00,
          1.2373e+00,  1.2431e+00,  1.2202e+00,  1.2566e+00,  1.1728e+00,
          1.2117e+00,  1.3518e+00,  1.4241e+00,  1.3362e+00,  1.3643e+00,
          1.4000e+00,  1.4132e+00,  1.3126e+00,  1.2198e+00,  1.3365e+00,
          1.2853e+00,  1.2714e+00,  1.2551e+00,  1.2300e+00,  1.2335e+00,
          1.2552e+00,  1.2830e+00,  1.2101e+00,  1.2265e+00],
        [ 1.1643e+00,  1.1908e+00,  1.2200e+00,  1.2214e+00,  1.1957e+00,
          1.1689e+00,  1.1770e+00,  1.1619e+00,  1.1619e+00,  1.2381e+00,
          1.2639e+00,  1.2505e+00,  1.2909e+00,  1.2300e+00,  1.2829e+00,
          1.2432e+00,  1.1644e+00,  1.2911e+00,  2.7398e+00,  2.9795e+00,
          2.9569e+00,  2.7569e+00,  2.6999e+00,  2.6944e+00,  2.9305e+00,
          2.6860e+00,  2.6860e+00,  1.2038e+00,  1.2642e+00,  1.1986e+00,
          1.2224e+00,  1.2048e+00,  1.2086e+00,  1.2406e+00,  1.2028e+00,
          1.2012e+00,  1.3972e+00,  1.4591e+00,  1.4309e+00,  1.3229e+00,
          1.4368e+00,  1.4198e+00,  1.4121e+00,  1.2912e+00,  1.2974e+00,
          1.3226e+00,  1.2685e+00,  1.2543e+00,  1.2324e+00,  1.3128e+00,
          1.2543e+00,  1.3560e+00,  1.1928e+00,  1.2293e+00],
        [ 1.1686e+00,  1.1956e+00,  1.2251e+00,  1.2272e+00,  1.2009e+00,
          1.1733e+00,  1.1818e+00,  1.1662e+00,  1.1662e+00,  1.2418e+00,
          1.2682e+00,  1.2545e+00,  1.2908e+00,  1.2335e+00,  1.2843e+00,
          1.2470e+00,  1.2168e+00,  1.2469e+00,  1.2208e+00,  1.2165e+00,
          1.2558e+00,  1.2334e+00,  1.1940e+00,  1.1893e+00,  1.1873e+00,
          1.1818e+00,  1.1818e+00,  3.0045e+00,  2.9429e+00,  2.6370e+00,
          2.7100e+00,  3.0022e+00,  2.6483e+00,  2.9039e+00,  2.6507e+00,
          2.6399e+00,  1.3926e+00,  1.4561e+00,  1.4227e+00,  1.3766e+00,
          1.4350e+00,  1.4172e+00,  1.4018e+00,  1.2814e+00,  1.3510e+00,
          1.3281e+00,  1.2715e+00,  1.2063e+00,  1.1864e+00,  1.3212e+00,
          1.2571e+00,  1.3653e+00,  1.1474e+00,  1.2314e+00],
        [ 1.7540e+00,  1.3763e+00,  5.9639e-01,  8.8093e-01,  1.2766e+00,
          1.6879e+00,  1.5662e+00,  1.7888e+00,  1.7888e+00,  1.5637e+00,
          1.2226e+00,  1.4231e+00,  8.7012e-01,  1.6155e+00,  1.2314e-01,
          1.5061e+00,  1.7794e+00,  7.7902e-01,  1.2829e+00,  9.8056e-01,
          7.3878e-01,  1.1042e+00,  1.6290e+00,  1.6921e+00,  1.4874e+00,
          1.7937e+00,  1.7937e+00,  8.3189e-01,  8.1316e-01,  1.7643e+00,
          1.5624e+00,  8.3411e-01,  1.7076e+00,  1.1905e+00,  1.8158e+00,
          1.7302e+00, -7.0556e-03, -2.3118e-01, -2.6315e-01, -5.8922e-02,
          1.7131e-01,  2.3984e-01, -1.1847e-01,  2.0031e+01,  1.8446e+00,
          7.0272e-01,  1.2664e+00,  1.3296e+00,  1.5585e+00,  9.0367e-01,
          1.4957e+00,  3.2205e-01,  1.6789e+00,  1.7169e+00],
        [ 1.2195e+00,  1.2572e+00,  1.3242e+00,  1.3017e+00,  1.2652e+00,
          1.2261e+00,  1.1943e+00,  1.2161e+00,  1.2161e+00,  1.1895e+00,
          1.3184e+00,  1.2073e+00,  1.3570e+00,  1.2698e+00,  1.4155e+00,
          1.1967e+00,  1.2469e+00,  1.2710e+00,  1.2826e+00,  1.2679e+00,
          1.3328e+00,  1.3002e+00,  1.2452e+00,  1.2387e+00,  1.1340e+00,
          1.2282e+00,  1.2282e+00,  1.2974e+00,  1.3443e+00,  1.2461e+00,
          1.0268e+00,  1.2534e+00,  1.1275e+00,  1.3049e+00,  1.1203e+00,
          1.2498e+00,  1.2661e+00,  9.8350e-01,  1.2619e+00,  1.2835e+00,
          8.2286e-01,  7.5338e-01,  1.2891e+00,  1.1033e+00,  6.3196e-01,
          3.6117e+00,  2.5207e+00,  3.6534e+00,  2.8173e+00,  2.1199e+00,
          1.7948e+00,  2.9588e+00,  3.5220e+00,  1.7707e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 337 : 178.60853908439748
Test loss for epoch 337 : 179.15238893214405
Test Precision for epoch 337 : 0.26153846153846155
Test Recall for epoch 337 : 0.26153846153846155
Test F1 for epoch 337 : 0.26153846153846155


theta for epoch 338 : tensor([[ 2.7109e+00,  2.7437e+00,  2.8196e+00,  2.9592e+00,  2.9215e+00,
          2.7164e+00,  2.8971e+00,  2.7082e+00,  2.7082e+00,  1.2336e+00,
          1.2589e+00,  1.2458e+00,  1.2854e+00,  1.2256e+00,  1.3269e+00,
          1.2386e+00,  1.2102e+00,  1.2441e+00,  1.2106e+00,  1.1865e+00,
          1.2006e+00,  1.2228e+00,  1.1849e+00,  1.1804e+00,  1.1983e+00,
          1.1731e+00,  1.1731e+00,  1.2171e+00,  1.2627e+00,  1.1941e+00,
          1.2187e+00,  1.2628e+00,  1.2040e+00,  1.2354e+00,  1.1535e+00,
          1.1967e+00,  1.4005e+00,  1.4611e+00,  1.4351e+00,  1.4128e+00,
          1.4410e+00,  1.3893e+00,  1.4151e+00,  1.2967e+00,  1.3894e+00,
          1.3195e+00,  1.2651e+00,  1.2512e+00,  1.2298e+00,  1.3129e+00,
          1.2512e+00,  1.3552e+00,  1.2125e+00,  1.2267e+00],
        [ 1.1766e+00,  1.2067e+00,  1.2592e+00,  1.2398e+00,  1.2127e+00,
          1.1815e+00,  1.1911e+00,  1.1735e+00,  1.1735e+00,  2.4308e+00,
          2.4604e+00,  2.4116e+00,  2.6830e+00,  2.3847e+00,  3.9273e+00,
          2.4341e+00,  2.6172e+00,  3.7153e+00,  1.1899e+00,  1.2137e+00,
          1.1848e+00,  1.2031e+00,  1.2020e+00,  1.1969e+00,  1.2159e+00,
          1.1885e+00,  1.1885e+00,  1.2450e+00,  1.2007e+00,  1.2082e+00,
          1.2367e+00,  1.2429e+00,  1.2196e+00,  1.2560e+00,  1.1723e+00,
          1.2111e+00,  1.3515e+00,  1.4238e+00,  1.3362e+00,  1.3643e+00,
          1.3998e+00,  1.4131e+00,  1.3125e+00,  1.2202e+00,  1.3371e+00,
          1.2848e+00,  1.2708e+00,  1.2546e+00,  1.2295e+00,  1.2332e+00,
          1.2546e+00,  1.2827e+00,  1.2095e+00,  1.2259e+00],
        [ 1.1640e+00,  1.1905e+00,  1.2195e+00,  1.2211e+00,  1.1954e+00,
          1.1686e+00,  1.1767e+00,  1.1616e+00,  1.1616e+00,  1.2378e+00,
          1.2635e+00,  1.2502e+00,  1.2905e+00,  1.2296e+00,  1.2824e+00,
          1.2428e+00,  1.1639e+00,  1.2907e+00,  2.7414e+00,  2.9825e+00,
          2.9588e+00,  2.7585e+00,  2.7012e+00,  2.6957e+00,  2.9335e+00,
          2.6874e+00,  2.6874e+00,  1.2034e+00,  1.2638e+00,  1.1983e+00,
          1.2222e+00,  1.2043e+00,  1.2083e+00,  1.2403e+00,  1.2025e+00,
          1.2009e+00,  1.3971e+00,  1.4590e+00,  1.4309e+00,  1.3226e+00,
          1.4369e+00,  1.4196e+00,  1.4121e+00,  1.2909e+00,  1.2978e+00,
          1.3224e+00,  1.2683e+00,  1.2541e+00,  1.2322e+00,  1.3124e+00,
          1.2541e+00,  1.3556e+00,  1.1925e+00,  1.2291e+00],
        [ 1.1683e+00,  1.1953e+00,  1.2247e+00,  1.2268e+00,  1.2005e+00,
          1.1730e+00,  1.1814e+00,  1.1658e+00,  1.1658e+00,  1.2414e+00,
          1.2677e+00,  1.2541e+00,  1.2901e+00,  1.2331e+00,  1.2838e+00,
          1.2466e+00,  1.2164e+00,  1.2465e+00,  1.2205e+00,  1.2159e+00,
          1.2555e+00,  1.2331e+00,  1.1937e+00,  1.1890e+00,  1.1869e+00,
          1.1815e+00,  1.1815e+00,  3.0065e+00,  2.9435e+00,  2.6394e+00,
          2.7106e+00,  3.0042e+00,  2.6507e+00,  2.9044e+00,  2.6535e+00,
          2.6423e+00,  1.3924e+00,  1.4560e+00,  1.4222e+00,  1.3763e+00,
          1.4348e+00,  1.4170e+00,  1.4014e+00,  1.2811e+00,  1.3514e+00,
          1.3278e+00,  1.2712e+00,  1.2061e+00,  1.1861e+00,  1.3209e+00,
          1.2567e+00,  1.3650e+00,  1.1470e+00,  1.2311e+00],
        [ 1.7549e+00,  1.3774e+00,  5.9786e-01,  8.8217e-01,  1.2778e+00,
          1.6890e+00,  1.5672e+00,  1.7898e+00,  1.7898e+00,  1.5646e+00,
          1.2237e+00,  1.4242e+00,  8.7143e-01,  1.6165e+00,  1.2498e-01,
          1.5071e+00,  1.7804e+00,  7.8047e-01,  1.2841e+00,  9.8194e-01,
          7.4018e-01,  1.1055e+00,  1.6300e+00,  1.6931e+00,  1.4886e+00,
          1.7947e+00,  1.7947e+00,  8.3326e-01,  8.1447e-01,  1.7653e+00,
          1.5634e+00,  8.3538e-01,  1.7085e+00,  1.1916e+00,  1.8168e+00,
          1.7311e+00, -9.5999e-03, -2.3344e-01, -2.6541e-01, -6.1449e-02,
          1.6853e-01,  2.3687e-01, -1.2087e-01,  2.0099e+01,  1.8122e+00,
          7.0395e-01,  1.2673e+00,  1.3304e+00,  1.5593e+00,  9.0477e-01,
          1.4965e+00,  3.2356e-01,  1.6798e+00,  1.7177e+00],
        [ 1.2193e+00,  1.2570e+00,  1.3239e+00,  1.3014e+00,  1.2650e+00,
          1.2258e+00,  1.1941e+00,  1.2158e+00,  1.2158e+00,  1.1893e+00,
          1.3182e+00,  1.2070e+00,  1.3566e+00,  1.2696e+00,  1.4152e+00,
          1.1965e+00,  1.2466e+00,  1.2709e+00,  1.2825e+00,  1.2677e+00,
          1.3326e+00,  1.3001e+00,  1.2451e+00,  1.2385e+00,  1.1338e+00,
          1.2280e+00,  1.2280e+00,  1.2972e+00,  1.3441e+00,  1.2458e+00,
          1.0266e+00,  1.2531e+00,  1.1273e+00,  1.3048e+00,  1.1201e+00,
          1.2495e+00,  1.2658e+00,  9.8311e-01,  1.2615e+00,  1.2831e+00,
          8.2243e-01,  7.5298e-01,  1.2887e+00,  1.1024e+00,  6.3221e-01,
          3.6153e+00,  2.5222e+00,  3.6544e+00,  2.8185e+00,  2.1215e+00,
          1.7963e+00,  2.9600e+00,  3.5257e+00,  1.7722e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 338 : 178.5983532987232
Test loss for epoch 338 : 179.14720645551807
Test Precision for epoch 338 : 0.26153846153846155
Test Recall for epoch 338 : 0.26153846153846155
Test F1 for epoch 338 : 0.26153846153846155


theta for epoch 339 : tensor([[ 2.7128e+00,  2.7457e+00,  2.8216e+00,  2.9612e+00,  2.9235e+00,
          2.7183e+00,  2.8990e+00,  2.7101e+00,  2.7101e+00,  1.2333e+00,
          1.2585e+00,  1.2455e+00,  1.2850e+00,  1.2253e+00,  1.3265e+00,
          1.2382e+00,  1.2098e+00,  1.2438e+00,  1.2103e+00,  1.1862e+00,
          1.2003e+00,  1.2225e+00,  1.1846e+00,  1.1801e+00,  1.1980e+00,
          1.1728e+00,  1.1728e+00,  1.2168e+00,  1.2624e+00,  1.1938e+00,
          1.2184e+00,  1.2625e+00,  1.2036e+00,  1.2351e+00,  1.1532e+00,
          1.1963e+00,  1.4005e+00,  1.4611e+00,  1.4351e+00,  1.4128e+00,
          1.4410e+00,  1.3893e+00,  1.4151e+00,  1.2964e+00,  1.3900e+00,
          1.3192e+00,  1.2648e+00,  1.2510e+00,  1.2295e+00,  1.3126e+00,
          1.2509e+00,  1.3550e+00,  1.2122e+00,  1.2264e+00],
        [ 1.1760e+00,  1.2061e+00,  1.2589e+00,  1.2393e+00,  1.2120e+00,
          1.1808e+00,  1.1906e+00,  1.1729e+00,  1.1729e+00,  2.4376e+00,
          2.4676e+00,  2.4205e+00,  2.6943e+00,  2.3937e+00,  3.9050e+00,
          2.4413e+00,  2.6281e+00,  3.6943e+00,  1.1895e+00,  1.2132e+00,
          1.1843e+00,  1.2029e+00,  1.2013e+00,  1.1962e+00,  1.2154e+00,
          1.1879e+00,  1.1879e+00,  1.2445e+00,  1.2004e+00,  1.2075e+00,
          1.2361e+00,  1.2427e+00,  1.2189e+00,  1.2553e+00,  1.1719e+00,
          1.2105e+00,  1.3513e+00,  1.4236e+00,  1.3362e+00,  1.3642e+00,
          1.3996e+00,  1.4129e+00,  1.3125e+00,  1.2205e+00,  1.3376e+00,
          1.2843e+00,  1.2703e+00,  1.2540e+00,  1.2289e+00,  1.2330e+00,
          1.2540e+00,  1.2824e+00,  1.2090e+00,  1.2253e+00],
        [ 1.1637e+00,  1.1901e+00,  1.2191e+00,  1.2208e+00,  1.1951e+00,
          1.1683e+00,  1.1764e+00,  1.1613e+00,  1.1613e+00,  1.2375e+00,
          1.2632e+00,  1.2498e+00,  1.2901e+00,  1.2293e+00,  1.2819e+00,
          1.2425e+00,  1.1633e+00,  1.2903e+00,  2.7432e+00,  2.9855e+00,
          2.9609e+00,  2.7602e+00,  2.7027e+00,  2.6972e+00,  2.9365e+00,
          2.6889e+00,  2.6889e+00,  1.2030e+00,  1.2633e+00,  1.1980e+00,
          1.2219e+00,  1.2039e+00,  1.2080e+00,  1.2401e+00,  1.2022e+00,
          1.2006e+00,  1.3971e+00,  1.4591e+00,  1.4309e+00,  1.3224e+00,
          1.4369e+00,  1.4195e+00,  1.4121e+00,  1.2906e+00,  1.2982e+00,
          1.3221e+00,  1.2680e+00,  1.2539e+00,  1.2320e+00,  1.3119e+00,
          1.2538e+00,  1.3551e+00,  1.1921e+00,  1.2288e+00],
        [ 1.1679e+00,  1.1949e+00,  1.2242e+00,  1.2265e+00,  1.2002e+00,
          1.1726e+00,  1.1811e+00,  1.1655e+00,  1.1655e+00,  1.2411e+00,
          1.2674e+00,  1.2537e+00,  1.2895e+00,  1.2327e+00,  1.2834e+00,
          1.2462e+00,  1.2160e+00,  1.2461e+00,  1.2201e+00,  1.2153e+00,
          1.2552e+00,  1.2328e+00,  1.1933e+00,  1.1887e+00,  1.1865e+00,
          1.1812e+00,  1.1812e+00,  3.0087e+00,  2.9442e+00,  2.6419e+00,
          2.7113e+00,  3.0064e+00,  2.6533e+00,  2.9050e+00,  2.6564e+00,
          2.6448e+00,  1.3923e+00,  1.4558e+00,  1.4218e+00,  1.3760e+00,
          1.4348e+00,  1.4168e+00,  1.4009e+00,  1.2807e+00,  1.3518e+00,
          1.3275e+00,  1.2709e+00,  1.2059e+00,  1.1858e+00,  1.3206e+00,
          1.2564e+00,  1.3647e+00,  1.1466e+00,  1.2307e+00],
        [ 1.7559e+00,  1.3785e+00,  5.9932e-01,  8.8340e-01,  1.2789e+00,
          1.6900e+00,  1.5682e+00,  1.7908e+00,  1.7908e+00,  1.5657e+00,
          1.2249e+00,  1.4253e+00,  8.7275e-01,  1.6175e+00,  1.2681e-01,
          1.5082e+00,  1.7813e+00,  7.8192e-01,  1.2852e+00,  9.8328e-01,
          7.4153e-01,  1.1067e+00,  1.6310e+00,  1.6941e+00,  1.4897e+00,
          1.7957e+00,  1.7957e+00,  8.3460e-01,  8.1575e-01,  1.7662e+00,
          1.5644e+00,  8.3662e-01,  1.7095e+00,  1.1927e+00,  1.8177e+00,
          1.7321e+00, -1.2135e-02, -2.3569e-01, -2.6765e-01, -6.3964e-02,
          1.6575e-01,  2.3393e-01, -1.2327e-01,  2.0167e+01,  1.7820e+00,
          7.0512e-01,  1.2682e+00,  1.3313e+00,  1.5601e+00,  9.0580e-01,
          1.4972e+00,  3.2499e-01,  1.6807e+00,  1.7183e+00],
        [ 1.2190e+00,  1.2568e+00,  1.3237e+00,  1.3012e+00,  1.2647e+00,
          1.2256e+00,  1.1939e+00,  1.2156e+00,  1.2156e+00,  1.1892e+00,
          1.3180e+00,  1.2068e+00,  1.3564e+00,  1.2694e+00,  1.4151e+00,
          1.1963e+00,  1.2464e+00,  1.2708e+00,  1.2823e+00,  1.2674e+00,
          1.3324e+00,  1.2999e+00,  1.2449e+00,  1.2383e+00,  1.1335e+00,
          1.2277e+00,  1.2277e+00,  1.2970e+00,  1.3439e+00,  1.2456e+00,
          1.0264e+00,  1.2529e+00,  1.1271e+00,  1.3046e+00,  1.1198e+00,
          1.2493e+00,  1.2654e+00,  9.8273e-01,  1.2611e+00,  1.2827e+00,
          8.2203e-01,  7.5260e-01,  1.2884e+00,  1.1014e+00,  6.3245e-01,
          3.6190e+00,  2.5239e+00,  3.6556e+00,  2.8198e+00,  2.1232e+00,
          1.7979e+00,  2.9614e+00,  3.5295e+00,  1.7737e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 339 : 178.58847392823816
Test loss for epoch 339 : 179.1422282634023
Test Precision for epoch 339 : 0.26153846153846155
Test Recall for epoch 339 : 0.26153846153846155
Test F1 for epoch 339 : 0.26153846153846155


theta for epoch 340 : tensor([[ 2.7149e+00,  2.7478e+00,  2.8238e+00,  2.9633e+00,  2.9256e+00,
          2.7204e+00,  2.9012e+00,  2.7122e+00,  2.7122e+00,  1.2329e+00,
          1.2581e+00,  1.2450e+00,  1.2845e+00,  1.2249e+00,  1.3261e+00,
          1.2378e+00,  1.2094e+00,  1.2434e+00,  1.2100e+00,  1.1858e+00,
          1.2000e+00,  1.2221e+00,  1.1842e+00,  1.1797e+00,  1.1976e+00,
          1.1725e+00,  1.1725e+00,  1.2165e+00,  1.2621e+00,  1.1935e+00,
          1.2182e+00,  1.2622e+00,  1.2033e+00,  1.2348e+00,  1.1529e+00,
          1.1960e+00,  1.4004e+00,  1.4610e+00,  1.4351e+00,  1.4127e+00,
          1.4410e+00,  1.3893e+00,  1.4150e+00,  1.2961e+00,  1.3905e+00,
          1.3189e+00,  1.2646e+00,  1.2508e+00,  1.2292e+00,  1.3123e+00,
          1.2506e+00,  1.3547e+00,  1.2120e+00,  1.2261e+00],
        [ 1.1755e+00,  1.2055e+00,  1.2586e+00,  1.2388e+00,  1.2115e+00,
          1.1802e+00,  1.1901e+00,  1.1723e+00,  1.1723e+00,  2.4444e+00,
          2.4747e+00,  2.4294e+00,  2.7055e+00,  2.4026e+00,  3.8833e+00,
          2.4484e+00,  2.6389e+00,  3.6739e+00,  1.1891e+00,  1.2128e+00,
          1.1837e+00,  1.2026e+00,  1.2007e+00,  1.1956e+00,  1.2149e+00,
          1.1872e+00,  1.1872e+00,  1.2442e+00,  1.2001e+00,  1.2069e+00,
          1.2355e+00,  1.2424e+00,  1.2184e+00,  1.2548e+00,  1.1715e+00,
          1.2099e+00,  1.3511e+00,  1.4234e+00,  1.3362e+00,  1.3641e+00,
          1.3994e+00,  1.4127e+00,  1.3125e+00,  1.2208e+00,  1.3382e+00,
          1.2839e+00,  1.2698e+00,  1.2535e+00,  1.2284e+00,  1.2327e+00,
          1.2535e+00,  1.2820e+00,  1.2085e+00,  1.2248e+00],
        [ 1.1635e+00,  1.1899e+00,  1.2187e+00,  1.2205e+00,  1.1948e+00,
          1.1680e+00,  1.1761e+00,  1.1611e+00,  1.1611e+00,  1.2371e+00,
          1.2628e+00,  1.2494e+00,  1.2896e+00,  1.2289e+00,  1.2813e+00,
          1.2421e+00,  1.1627e+00,  1.2898e+00,  2.7451e+00,  2.9887e+00,
          2.9631e+00,  2.7621e+00,  2.7043e+00,  2.6987e+00,  2.9396e+00,
          2.6904e+00,  2.6904e+00,  1.2026e+00,  1.2629e+00,  1.1977e+00,
          1.2217e+00,  1.2035e+00,  1.2078e+00,  1.2398e+00,  1.2019e+00,
          1.2003e+00,  1.3971e+00,  1.4591e+00,  1.4309e+00,  1.3222e+00,
          1.4369e+00,  1.4195e+00,  1.4120e+00,  1.2903e+00,  1.2986e+00,
          1.3219e+00,  1.2678e+00,  1.2537e+00,  1.2318e+00,  1.3115e+00,
          1.2536e+00,  1.3547e+00,  1.1918e+00,  1.2286e+00],
        [ 1.1676e+00,  1.1946e+00,  1.2238e+00,  1.2261e+00,  1.1998e+00,
          1.1723e+00,  1.1808e+00,  1.1652e+00,  1.1652e+00,  1.2406e+00,
          1.2669e+00,  1.2532e+00,  1.2888e+00,  1.2323e+00,  1.2828e+00,
          1.2457e+00,  1.2155e+00,  1.2456e+00,  1.2198e+00,  1.2146e+00,
          1.2548e+00,  1.2325e+00,  1.1930e+00,  1.1883e+00,  1.1861e+00,
          1.1808e+00,  1.1808e+00,  3.0110e+00,  2.9450e+00,  2.6446e+00,
          2.7122e+00,  3.0088e+00,  2.6559e+00,  2.9058e+00,  2.6594e+00,
          2.6475e+00,  1.3921e+00,  1.4557e+00,  1.4214e+00,  1.3758e+00,
          1.4347e+00,  1.4166e+00,  1.4005e+00,  1.2804e+00,  1.3522e+00,
          1.3272e+00,  1.2706e+00,  1.2057e+00,  1.1855e+00,  1.3203e+00,
          1.2561e+00,  1.3644e+00,  1.1462e+00,  1.2304e+00],
        [ 1.7569e+00,  1.3797e+00,  6.0083e-01,  8.8471e-01,  1.2801e+00,
          1.6911e+00,  1.5692e+00,  1.7918e+00,  1.7918e+00,  1.5667e+00,
          1.2260e+00,  1.4264e+00,  8.7404e-01,  1.6185e+00,  1.2862e-01,
          1.5092e+00,  1.7822e+00,  7.8333e-01,  1.2863e+00,  9.8460e-01,
          7.4289e-01,  1.1079e+00,  1.6320e+00,  1.6951e+00,  1.4908e+00,
          1.7966e+00,  1.7966e+00,  8.3598e-01,  8.1707e-01,  1.7672e+00,
          1.5654e+00,  8.3790e-01,  1.7105e+00,  1.1939e+00,  1.8186e+00,
          1.7330e+00, -1.4713e-02, -2.3797e-01, -2.6993e-01, -6.6517e-02,
          1.6293e-01,  2.3094e-01, -1.2570e-01,  2.0234e+01,  1.7538e+00,
          7.0637e-01,  1.2692e+00,  1.3321e+00,  1.5609e+00,  9.0692e-01,
          1.4981e+00,  3.2651e-01,  1.6816e+00,  1.7190e+00],
        [ 1.2189e+00,  1.2565e+00,  1.3235e+00,  1.3010e+00,  1.2645e+00,
          1.2254e+00,  1.1937e+00,  1.2154e+00,  1.2154e+00,  1.1889e+00,
          1.3176e+00,  1.2065e+00,  1.3560e+00,  1.2691e+00,  1.4148e+00,
          1.1960e+00,  1.2461e+00,  1.2706e+00,  1.2820e+00,  1.2671e+00,
          1.3321e+00,  1.2997e+00,  1.2446e+00,  1.2380e+00,  1.1332e+00,
          1.2275e+00,  1.2275e+00,  1.2968e+00,  1.3437e+00,  1.2454e+00,
          1.0262e+00,  1.2527e+00,  1.1268e+00,  1.3044e+00,  1.1196e+00,
          1.2491e+00,  1.2650e+00,  9.8231e-01,  1.2607e+00,  1.2823e+00,
          8.2158e-01,  7.5217e-01,  1.2880e+00,  1.1005e+00,  6.3260e-01,
          3.6229e+00,  2.5257e+00,  3.6570e+00,  2.8214e+00,  2.1251e+00,
          1.7996e+00,  2.9631e+00,  3.5335e+00,  1.7754e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 340 : 178.5788775174822
Test loss for epoch 340 : 179.13733835624964
Test Precision for epoch 340 : 0.26153846153846155
Test Recall for epoch 340 : 0.26153846153846155
Test F1 for epoch 340 : 0.26153846153846155


theta for epoch 341 : tensor([[ 2.7171e+00,  2.7500e+00,  2.8260e+00,  2.9656e+00,  2.9279e+00,
          2.7226e+00,  2.9034e+00,  2.7144e+00,  2.7144e+00,  1.2325e+00,
          1.2577e+00,  1.2446e+00,  1.2840e+00,  1.2245e+00,  1.3257e+00,
          1.2374e+00,  1.2090e+00,  1.2431e+00,  1.2096e+00,  1.1855e+00,
          1.1996e+00,  1.2218e+00,  1.1839e+00,  1.1794e+00,  1.1973e+00,
          1.1722e+00,  1.1722e+00,  1.2162e+00,  1.2617e+00,  1.1932e+00,
          1.2179e+00,  1.2619e+00,  1.2030e+00,  1.2345e+00,  1.1525e+00,
          1.1957e+00,  1.4004e+00,  1.4610e+00,  1.4350e+00,  1.4126e+00,
          1.4410e+00,  1.3893e+00,  1.4150e+00,  1.2957e+00,  1.3910e+00,
          1.3186e+00,  1.2643e+00,  1.2505e+00,  1.2290e+00,  1.3120e+00,
          1.2503e+00,  1.3544e+00,  1.2117e+00,  1.2258e+00],
        [ 1.1748e+00,  1.2049e+00,  1.2581e+00,  1.2382e+00,  1.2108e+00,
          1.1796e+00,  1.1896e+00,  1.1716e+00,  1.1716e+00,  2.4513e+00,
          2.4820e+00,  2.4383e+00,  2.7167e+00,  2.4116e+00,  3.8623e+00,
          2.4556e+00,  2.6496e+00,  3.6543e+00,  1.1888e+00,  1.2124e+00,
          1.1832e+00,  1.2024e+00,  1.2001e+00,  1.1949e+00,  1.2145e+00,
          1.1866e+00,  1.1866e+00,  1.2438e+00,  1.1997e+00,  1.2063e+00,
          1.2350e+00,  1.2421e+00,  1.2178e+00,  1.2542e+00,  1.1711e+00,
          1.2093e+00,  1.3509e+00,  1.4231e+00,  1.3362e+00,  1.3640e+00,
          1.3992e+00,  1.4125e+00,  1.3125e+00,  1.2211e+00,  1.3387e+00,
          1.2834e+00,  1.2692e+00,  1.2530e+00,  1.2279e+00,  1.2324e+00,
          1.2529e+00,  1.2817e+00,  1.2080e+00,  1.2242e+00],
        [ 1.1632e+00,  1.1896e+00,  1.2183e+00,  1.2202e+00,  1.1945e+00,
          1.1677e+00,  1.1758e+00,  1.1607e+00,  1.1607e+00,  1.2367e+00,
          1.2624e+00,  1.2490e+00,  1.2892e+00,  1.2285e+00,  1.2808e+00,
          1.2417e+00,  1.1621e+00,  1.2894e+00,  2.7472e+00,  2.9920e+00,
          2.9654e+00,  2.7642e+00,  2.7061e+00,  2.7005e+00,  2.9429e+00,
          2.6922e+00,  2.6922e+00,  1.2022e+00,  1.2624e+00,  1.1975e+00,
          1.2214e+00,  1.2031e+00,  1.2075e+00,  1.2395e+00,  1.2016e+00,
          1.2000e+00,  1.3971e+00,  1.4591e+00,  1.4308e+00,  1.3220e+00,
          1.4369e+00,  1.4194e+00,  1.4120e+00,  1.2900e+00,  1.2990e+00,
          1.3216e+00,  1.2676e+00,  1.2535e+00,  1.2315e+00,  1.3111e+00,
          1.2533e+00,  1.3542e+00,  1.1914e+00,  1.2283e+00],
        [ 1.1673e+00,  1.1942e+00,  1.2234e+00,  1.2258e+00,  1.1995e+00,
          1.1719e+00,  1.1804e+00,  1.1648e+00,  1.1648e+00,  1.2402e+00,
          1.2664e+00,  1.2528e+00,  1.2881e+00,  1.2318e+00,  1.2823e+00,
          1.2453e+00,  1.2151e+00,  1.2451e+00,  1.2194e+00,  1.2140e+00,
          1.2545e+00,  1.2321e+00,  1.1926e+00,  1.1879e+00,  1.1857e+00,
          1.1804e+00,  1.1804e+00,  3.0135e+00,  2.9461e+00,  2.6474e+00,
          2.7132e+00,  3.0113e+00,  2.6587e+00,  2.9067e+00,  2.6625e+00,
          2.6503e+00,  1.3920e+00,  1.4556e+00,  1.4210e+00,  1.3755e+00,
          1.4346e+00,  1.4165e+00,  1.4001e+00,  1.2801e+00,  1.3526e+00,
          1.3269e+00,  1.2703e+00,  1.2055e+00,  1.1851e+00,  1.3200e+00,
          1.2558e+00,  1.3641e+00,  1.1458e+00,  1.2301e+00],
        [ 1.7580e+00,  1.3809e+00,  6.0232e-01,  8.8599e-01,  1.2813e+00,
          1.6921e+00,  1.5703e+00,  1.7928e+00,  1.7928e+00,  1.5677e+00,
          1.2271e+00,  1.4275e+00,  8.7536e-01,  1.6196e+00,  1.3044e-01,
          1.5103e+00,  1.7832e+00,  7.8479e-01,  1.2875e+00,  9.8596e-01,
          7.4428e-01,  1.1092e+00,  1.6330e+00,  1.6961e+00,  1.4920e+00,
          1.7976e+00,  1.7976e+00,  8.3736e-01,  8.1839e-01,  1.7681e+00,
          1.5664e+00,  8.3918e-01,  1.7114e+00,  1.1951e+00,  1.8196e+00,
          1.7340e+00, -1.7303e-02, -2.4026e-01, -2.7222e-01, -6.9082e-02,
          1.6010e-01,  2.2795e-01, -1.2815e-01,  2.0300e+01,  1.7278e+00,
          7.0756e-01,  1.2701e+00,  1.3330e+00,  1.5617e+00,  9.0798e-01,
          1.4988e+00,  3.2797e-01,  1.6824e+00,  1.7197e+00],
        [ 1.2186e+00,  1.2563e+00,  1.3232e+00,  1.3007e+00,  1.2643e+00,
          1.2252e+00,  1.1935e+00,  1.2151e+00,  1.2151e+00,  1.1887e+00,
          1.3174e+00,  1.2062e+00,  1.3556e+00,  1.2688e+00,  1.4145e+00,
          1.1957e+00,  1.2458e+00,  1.2704e+00,  1.2818e+00,  1.2669e+00,
          1.3319e+00,  1.2995e+00,  1.2444e+00,  1.2378e+00,  1.1330e+00,
          1.2272e+00,  1.2272e+00,  1.2966e+00,  1.3435e+00,  1.2451e+00,
          1.0260e+00,  1.2525e+00,  1.1266e+00,  1.3043e+00,  1.1193e+00,
          1.2489e+00,  1.2647e+00,  9.8190e-01,  1.2603e+00,  1.2819e+00,
          8.2114e-01,  7.5175e-01,  1.2876e+00,  1.0996e+00,  6.3271e-01,
          3.6270e+00,  2.5277e+00,  3.6586e+00,  2.8231e+00,  2.1270e+00,
          1.8013e+00,  2.9649e+00,  3.5377e+00,  1.7772e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 341 : 178.56954570766948
Test loss for epoch 341 : 179.1325616308696
Test Precision for epoch 341 : 0.26153846153846155
Test Recall for epoch 341 : 0.26153846153846155
Test F1 for epoch 341 : 0.26153846153846155


theta for epoch 342 : tensor([[ 2.7195e+00,  2.7524e+00,  2.8284e+00,  2.9680e+00,  2.9302e+00,
          2.7250e+00,  2.9058e+00,  2.7168e+00,  2.7168e+00,  1.2322e+00,
          1.2573e+00,  1.2442e+00,  1.2836e+00,  1.2241e+00,  1.3253e+00,
          1.2370e+00,  1.2086e+00,  1.2428e+00,  1.2093e+00,  1.1852e+00,
          1.1993e+00,  1.2215e+00,  1.1836e+00,  1.1791e+00,  1.1970e+00,
          1.1719e+00,  1.1719e+00,  1.2158e+00,  1.2614e+00,  1.1929e+00,
          1.2176e+00,  1.2616e+00,  1.2027e+00,  1.2342e+00,  1.1522e+00,
          1.1954e+00,  1.4003e+00,  1.4610e+00,  1.4350e+00,  1.4126e+00,
          1.4410e+00,  1.3893e+00,  1.4149e+00,  1.2954e+00,  1.3916e+00,
          1.3183e+00,  1.2640e+00,  1.2502e+00,  1.2287e+00,  1.3117e+00,
          1.2500e+00,  1.3541e+00,  1.2114e+00,  1.2255e+00],
        [ 1.1742e+00,  1.2042e+00,  1.2576e+00,  1.2375e+00,  1.2102e+00,
          1.1790e+00,  1.1891e+00,  1.1710e+00,  1.1710e+00,  2.4583e+00,
          2.4893e+00,  2.4473e+00,  2.7278e+00,  2.4207e+00,  3.8420e+00,
          2.4629e+00,  2.6604e+00,  3.6355e+00,  1.1884e+00,  1.2120e+00,
          1.1827e+00,  1.2022e+00,  1.1995e+00,  1.1943e+00,  1.2140e+00,
          1.1859e+00,  1.1859e+00,  1.2434e+00,  1.1993e+00,  1.2057e+00,
          1.2344e+00,  1.2417e+00,  1.2172e+00,  1.2536e+00,  1.1706e+00,
          1.2087e+00,  1.3506e+00,  1.4229e+00,  1.3362e+00,  1.3639e+00,
          1.3991e+00,  1.4124e+00,  1.3125e+00,  1.2213e+00,  1.3391e+00,
          1.2829e+00,  1.2687e+00,  1.2526e+00,  1.2274e+00,  1.2321e+00,
          1.2524e+00,  1.2813e+00,  1.2074e+00,  1.2237e+00],
        [ 1.1628e+00,  1.1892e+00,  1.2178e+00,  1.2198e+00,  1.1942e+00,
          1.1674e+00,  1.1755e+00,  1.1604e+00,  1.1604e+00,  1.2364e+00,
          1.2620e+00,  1.2486e+00,  1.2888e+00,  1.2282e+00,  1.2802e+00,
          1.2413e+00,  1.1616e+00,  1.2889e+00,  2.7494e+00,  2.9954e+00,
          2.9680e+00,  2.7664e+00,  2.7080e+00,  2.7024e+00,  2.9464e+00,
          2.6941e+00,  2.6941e+00,  1.2017e+00,  1.2619e+00,  1.1971e+00,
          1.2211e+00,  1.2027e+00,  1.2072e+00,  1.2393e+00,  1.2012e+00,
          1.1997e+00,  1.3970e+00,  1.4590e+00,  1.4308e+00,  1.3218e+00,
          1.4369e+00,  1.4193e+00,  1.4120e+00,  1.2896e+00,  1.2994e+00,
          1.3214e+00,  1.2673e+00,  1.2533e+00,  1.2313e+00,  1.3106e+00,
          1.2530e+00,  1.3537e+00,  1.1911e+00,  1.2280e+00],
        [ 1.1669e+00,  1.1939e+00,  1.2229e+00,  1.2254e+00,  1.1991e+00,
          1.1716e+00,  1.1801e+00,  1.1644e+00,  1.1644e+00,  1.2398e+00,
          1.2660e+00,  1.2524e+00,  1.2874e+00,  1.2314e+00,  1.2818e+00,
          1.2449e+00,  1.2147e+00,  1.2447e+00,  1.2191e+00,  1.2134e+00,
          1.2541e+00,  1.2318e+00,  1.1923e+00,  1.1876e+00,  1.1853e+00,
          1.1801e+00,  1.1801e+00,  3.0162e+00,  2.9473e+00,  2.6502e+00,
          2.7144e+00,  3.0140e+00,  2.6616e+00,  2.9078e+00,  2.6658e+00,
          2.6531e+00,  1.3918e+00,  1.4555e+00,  1.4206e+00,  1.3753e+00,
          1.4345e+00,  1.4163e+00,  1.3996e+00,  1.2797e+00,  1.3530e+00,
          1.3265e+00,  1.2700e+00,  1.2052e+00,  1.1848e+00,  1.3196e+00,
          1.2554e+00,  1.3637e+00,  1.1455e+00,  1.2297e+00],
        [ 1.7590e+00,  1.3820e+00,  6.0377e-01,  8.8726e-01,  1.2825e+00,
          1.6931e+00,  1.5713e+00,  1.7938e+00,  1.7938e+00,  1.5689e+00,
          1.2283e+00,  1.4287e+00,  8.7671e-01,  1.6207e+00,  1.3227e-01,
          1.5114e+00,  1.7842e+00,  7.8627e-01,  1.2886e+00,  9.8731e-01,
          7.4567e-01,  1.1104e+00,  1.6341e+00,  1.6971e+00,  1.4932e+00,
          1.7986e+00,  1.7986e+00,  8.3871e-01,  8.1969e-01,  1.7691e+00,
          1.5674e+00,  8.4045e-01,  1.7124e+00,  1.1962e+00,  1.8205e+00,
          1.7350e+00, -1.9898e-02, -2.4256e-01, -2.7451e-01, -7.1650e-02,
          1.5727e-01,  2.2495e-01, -1.3060e-01,  2.0366e+01,  1.7039e+00,
          7.0875e-01,  1.2710e+00,  1.3338e+00,  1.5624e+00,  9.0905e-01,
          1.4996e+00,  3.2942e-01,  1.6832e+00,  1.7203e+00],
        [ 1.2184e+00,  1.2561e+00,  1.3229e+00,  1.3005e+00,  1.2641e+00,
          1.2249e+00,  1.1933e+00,  1.2149e+00,  1.2149e+00,  1.1885e+00,
          1.3171e+00,  1.2059e+00,  1.3553e+00,  1.2685e+00,  1.4143e+00,
          1.1955e+00,  1.2456e+00,  1.2703e+00,  1.2816e+00,  1.2666e+00,
          1.3317e+00,  1.2992e+00,  1.2442e+00,  1.2376e+00,  1.1327e+00,
          1.2270e+00,  1.2270e+00,  1.2963e+00,  1.3432e+00,  1.2449e+00,
          1.0257e+00,  1.2522e+00,  1.1264e+00,  1.3041e+00,  1.1190e+00,
          1.2486e+00,  1.2643e+00,  9.8148e-01,  1.2599e+00,  1.2816e+00,
          8.2070e-01,  7.5132e-01,  1.2873e+00,  1.0988e+00,  6.3277e-01,
          3.6311e+00,  2.5298e+00,  3.6604e+00,  2.8250e+00,  2.1291e+00,
          1.8032e+00,  2.9668e+00,  3.5420e+00,  1.7790e+00]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 342 : 178.56045759554644
Test loss for epoch 342 : 179.12786558614619
Test Precision for epoch 342 : 0.26153846153846155
Test Recall for epoch 342 : 0.26153846153846155
Test F1 for epoch 342 : 0.26153846153846155


theta for epoch 343 : tensor([[ 2.7220,  2.7550,  2.8310,  2.9706,  2.9328,  2.7275,  2.9084,  2.7193,
          2.7193,  1.2317,  1.2568,  1.2437,  1.2831,  1.2236,  1.3249,  1.2365,
          1.2082,  1.2424,  1.2090,  1.1848,  1.1989,  1.2211,  1.1832,  1.1787,
          1.1967,  1.1715,  1.1715,  1.2155,  1.2611,  1.1925,  1.2172,  1.2612,
          1.2023,  1.2339,  1.1518,  1.1951,  1.4002,  1.4609,  1.4349,  1.4125,
          1.4409,  1.3892,  1.4148,  1.2951,  1.3920,  1.3181,  1.2638,  1.2500,
          1.2284,  1.3114,  1.2498,  1.3538,  1.2111,  1.2252],
        [ 1.1736,  1.2037,  1.2571,  1.2370,  1.2096,  1.1784,  1.1887,  1.1705,
          1.1705,  2.4653,  2.4965,  2.4561,  2.7389,  2.4296,  3.8223,  2.4702,
          2.6710,  3.6173,  1.1880,  1.2116,  1.1822,  1.2020,  1.1989,  1.1937,
          1.2136,  1.1853,  1.1853,  1.2431,  1.1988,  1.2052,  1.2339,  1.2414,
          1.2166,  1.2531,  1.1703,  1.2082,  1.3504,  1.4227,  1.3362,  1.3638,
          1.3989,  1.4122,  1.3126,  1.2215,  1.3396,  1.2825,  1.2682,  1.2521,
          1.2270,  1.2319,  1.2519,  1.2809,  1.2070,  1.2232],
        [ 1.1626,  1.1889,  1.2175,  1.2195,  1.1939,  1.1671,  1.1752,  1.1601,
          1.1601,  1.2360,  1.2616,  1.2482,  1.2883,  1.2278,  1.2796,  1.2409,
          1.1610,  1.2884,  2.7518,  2.9989,  2.9706,  2.7688,  2.7100,  2.7044,
          2.9499,  2.6962,  2.6962,  1.2013,  1.2614,  1.1968,  1.2209,  1.2022,
          1.2069,  1.2390,  1.2009,  1.1994,  1.3970,  1.4590,  1.4308,  1.3216,
          1.4370,  1.4192,  1.4119,  1.2893,  1.2997,  1.3211,  1.2671,  1.2531,
          1.2311,  1.3101,  1.2528,  1.3533,  1.1908,  1.2278],
        [ 1.1666,  1.1935,  1.2225,  1.2250,  1.1988,  1.1712,  1.1797,  1.1641,
          1.1641,  1.2394,  1.2655,  1.2519,  1.2866,  1.2309,  1.2812,  1.2444,
          1.2142,  1.2442,  1.2187,  1.2128,  1.2537,  1.2314,  1.1919,  1.1872,
          1.1849,  1.1797,  1.1797,  3.0191,  2.9487,  2.6533,  2.7158,  3.0169,
          2.6646,  2.9091,  2.6692,  2.6562,  1.3917,  1.4554,  1.4201,  1.3751,
          1.4344,  1.4162,  1.3991,  1.2793,  1.3534,  1.3262,  1.2697,  1.2050,
          1.1845,  1.3193,  1.2551,  1.3634,  1.1451,  1.2294],
        [ 1.7601,  1.3832,  0.6053,  0.8886,  1.2837,  1.6942,  1.5724,  1.7949,
          1.7949,  1.5699,  1.2294,  1.4298,  0.8780,  1.6217,  0.1341,  1.5124,
          1.7851,  0.7877,  1.2898,  0.9886,  0.7470,  1.1116,  1.6351,  1.6981,
          1.4944,  1.7996,  1.7996,  0.8401,  0.8210,  1.7700,  1.5685,  0.8417,
          1.7134,  1.1974,  1.8214,  1.7359, -0.0225, -0.2449, -0.2768, -0.0742,
          0.1544,  0.2220, -0.1331, 20.4319,  1.6820,  0.7100,  1.2719,  1.3347,
          1.5632,  0.9102,  1.5004,  0.3309,  1.6840,  1.7210],
        [ 1.2182,  1.2558,  1.3227,  1.3003,  1.2639,  1.2247,  1.1931,  1.2147,
          1.2147,  1.1882,  1.3168,  1.2056,  1.3549,  1.2682,  1.4140,  1.1951,
          1.2453,  1.2701,  1.2813,  1.2663,  1.3314,  1.2990,  1.2439,  1.2373,
          1.1325,  1.2267,  1.2267,  1.2961,  1.3430,  1.2446,  1.0255,  1.2520,
          1.1261,  1.3039,  1.1187,  1.2484,  1.2639,  0.9810,  1.2595,  1.2811,
          0.8202,  0.7509,  1.2869,  1.0979,  0.6327,  3.6355,  2.5322,  3.6625,
          2.8272,  2.1313,  1.8051,  2.9690,  3.5465,  1.7809]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 343 : 178.5515945830683
Test loss for epoch 343 : 179.12323924892058
Test Precision for epoch 343 : 0.26153846153846155
Test Recall for epoch 343 : 0.26153846153846155
Test F1 for epoch 343 : 0.26153846153846155


theta for epoch 344 : tensor([[ 2.7247,  2.7576,  2.8337,  2.9734,  2.9355,  2.7302,  2.9111,  2.7220,
          2.7220,  1.2313,  1.2564,  1.2433,  1.2826,  1.2232,  1.3244,  1.2361,
          1.2078,  1.2420,  1.2086,  1.1844,  1.1985,  1.2208,  1.1829,  1.1784,
          1.1963,  1.1711,  1.1711,  1.2151,  1.2607,  1.1922,  1.2169,  1.2608,
          1.2020,  1.2336,  1.1515,  1.1947,  1.4001,  1.4609,  1.4348,  1.4124,
          1.4409,  1.3892,  1.4147,  1.2947,  1.3924,  1.3178,  1.2635,  1.2497,
          1.2282,  1.3111,  1.2494,  1.3534,  1.2108,  1.2249],
        [ 1.1730,  1.2030,  1.2565,  1.2363,  1.2091,  1.1779,  1.1882,  1.1699,
          1.1699,  2.4724,  2.5038,  2.4650,  2.7498,  2.4386,  3.8032,  2.4775,
          2.6815,  3.5999,  1.1876,  1.2113,  1.1818,  1.2018,  1.1983,  1.1931,
          1.2131,  1.1847,  1.1847,  1.2428,  1.1984,  1.2047,  1.2334,  1.2411,
          1.2161,  1.2526,  1.1699,  1.2076,  1.3502,  1.4225,  1.3363,  1.3637,
          1.3987,  1.4121,  1.3126,  1.2217,  1.3400,  1.2819,  1.2678,  1.2517,
          1.2265,  1.2315,  1.2514,  1.2805,  1.2066,  1.2227],
        [ 1.1622,  1.1886,  1.2170,  1.2192,  1.1936,  1.1668,  1.1749,  1.1598,
          1.1598,  1.2356,  1.2612,  1.2478,  1.2879,  1.2274,  1.2790,  1.2405,
          1.1604,  1.2879,  2.7543,  3.0026,  2.9735,  2.7713,  2.7123,  2.7066,
          2.9536,  2.6984,  2.6984,  1.2009,  1.2609,  1.1965,  1.2206,  1.2018,
          1.2065,  1.2387,  1.2006,  1.1991,  1.3969,  1.4590,  1.4307,  1.3213,
          1.4370,  1.4192,  1.4119,  1.2890,  1.3000,  1.3209,  1.2668,  1.2528,
          1.2308,  1.3096,  1.2525,  1.3528,  1.1905,  1.2275],
        [ 1.1662,  1.1931,  1.2221,  1.2246,  1.1984,  1.1708,  1.1794,  1.1637,
          1.1637,  1.2389,  1.2651,  1.2514,  1.2859,  1.2305,  1.2806,  1.2439,
          1.2138,  1.2437,  1.2183,  1.2121,  1.2533,  1.2310,  1.1915,  1.1868,
          1.1844,  1.1793,  1.1793,  3.0221,  2.9502,  2.6564,  2.7174,  3.0200,
          2.6678,  2.9106,  2.6728,  2.6593,  1.3915,  1.4553,  1.4197,  1.3748,
          1.4343,  1.4161,  1.3987,  1.2790,  1.3537,  1.3259,  1.2694,  1.2048,
          1.1842,  1.3190,  1.2547,  1.3631,  1.1447,  1.2290],
        [ 1.7611,  1.3843,  0.6067,  0.8898,  1.2848,  1.6952,  1.5735,  1.7959,
          1.7959,  1.5710,  1.2306,  1.4310,  0.8793,  1.6228,  0.1358,  1.5135,
          1.7861,  0.7892,  1.2909,  0.9900,  0.7484,  1.1128,  1.6361,  1.6991,
          1.4955,  1.8006,  1.8006,  0.8414,  0.8223,  1.7710,  1.5695,  0.8430,
          1.7143,  1.1985,  1.8223,  1.7369, -0.0251, -0.2471, -0.2791, -0.0768,
          0.1516,  0.2190, -0.1355, 20.4968,  1.6620,  0.7111,  1.2728,  1.3355,
          1.5639,  0.9112,  1.5012,  0.3323,  1.6848,  1.7217],
        [ 1.2179,  1.2556,  1.3224,  1.3000,  1.2637,  1.2244,  1.1929,  1.2144,
          1.2144,  1.1879,  1.3165,  1.2053,  1.3546,  1.2679,  1.4138,  1.1948,
          1.2450,  1.2699,  1.2811,  1.2661,  1.3312,  1.2987,  1.2437,  1.2371,
          1.1322,  1.2265,  1.2265,  1.2959,  1.3427,  1.2444,  1.0253,  1.2517,
          1.1259,  1.3037,  1.1185,  1.2481,  1.2635,  0.9806,  1.2590,  1.2807,
          0.8197,  0.7504,  1.2864,  1.0971,  0.6326,  3.6399,  2.5346,  3.6647,
          2.8295,  2.1335,  1.8071,  2.9713,  3.5511,  1.7829]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 344 : 178.54294039350583
Test loss for epoch 344 : 179.11869274324468
Test Precision for epoch 344 : 0.26153846153846155
Test Recall for epoch 344 : 0.26153846153846155
Test F1 for epoch 344 : 0.26153846153846155


theta for epoch 345 : tensor([[ 2.7275,  2.7604,  2.8365,  2.9762,  2.9384,  2.7330,  2.9140,  2.7248,
          2.7248,  1.2309,  1.2560,  1.2429,  1.2822,  1.2228,  1.3241,  1.2357,
          1.2074,  1.2417,  1.2082,  1.1841,  1.1982,  1.2204,  1.1826,  1.1780,
          1.1960,  1.1708,  1.1708,  1.2148,  1.2603,  1.1918,  1.2166,  1.2605,
          1.2017,  1.2332,  1.1511,  1.1944,  1.4001,  1.4608,  1.4347,  1.4123,
          1.4409,  1.3892,  1.4147,  1.2944,  1.3928,  1.3175,  1.2632,  1.2495,
          1.2279,  1.3107,  1.2491,  1.3531,  1.2105,  1.2245],
        [ 1.1724,  1.2024,  1.2558,  1.2357,  1.2085,  1.1773,  1.1876,  1.1693,
          1.1693,  2.4796,  2.5111,  2.4739,  2.7608,  2.4476,  3.7849,  2.4849,
          2.6921,  3.5832,  1.1873,  1.2109,  1.1814,  1.2015,  1.1977,  1.1925,
          1.2127,  1.1842,  1.1842,  1.2424,  1.1978,  1.2041,  1.2329,  1.2407,
          1.2155,  1.2520,  1.1696,  1.2071,  1.3500,  1.4223,  1.3363,  1.3636,
          1.3986,  1.4119,  1.3126,  1.2217,  1.3403,  1.2814,  1.2673,  1.2513,
          1.2261,  1.2312,  1.2509,  1.2801,  1.2061,  1.2222],
        [ 1.1619,  1.1883,  1.2166,  1.2188,  1.1932,  1.1665,  1.1746,  1.1595,
          1.1595,  1.2353,  1.2608,  1.2474,  1.2875,  1.2270,  1.2785,  1.2401,
          1.1599,  1.2874,  2.7571,  3.0065,  2.9765,  2.7740,  2.7146,  2.7090,
          2.9574,  2.7008,  2.7008,  1.2005,  1.2604,  1.1962,  1.2202,  1.2014,
          1.2062,  1.2384,  1.2002,  1.1988,  1.3969,  1.4590,  1.4307,  1.3211,
          1.4370,  1.4191,  1.4118,  1.2887,  1.3002,  1.3206,  1.2666,  1.2526,
          1.2306,  1.3091,  1.2522,  1.3523,  1.1901,  1.2272],
        [ 1.1658,  1.1927,  1.2216,  1.2242,  1.1980,  1.1704,  1.1790,  1.1633,
          1.1633,  1.2385,  1.2647,  1.2510,  1.2853,  1.2301,  1.2801,  1.2435,
          1.2134,  1.2432,  1.2179,  1.2115,  1.2529,  1.2306,  1.1912,  1.1865,
          1.1840,  1.1789,  1.1789,  3.0253,  2.9519,  2.6597,  2.7192,  3.0232,
          2.6710,  2.9122,  2.6765,  2.6626,  1.3914,  1.4551,  1.4192,  1.3746,
          1.4342,  1.4159,  1.3982,  1.2786,  1.3540,  1.3256,  1.2690,  1.2045,
          1.1839,  1.3186,  1.2544,  1.3627,  1.1443,  1.2287],
        [ 1.7622,  1.3855,  0.6081,  0.8911,  1.2860,  1.6963,  1.5746,  1.7969,
          1.7969,  1.5721,  1.2317,  1.4321,  0.8807,  1.6239,  0.1376,  1.5146,
          1.7872,  0.7907,  1.2920,  0.9913,  0.7498,  1.1140,  1.6372,  1.7001,
          1.4967,  1.8015,  1.8015,  0.8427,  0.8236,  1.7719,  1.5705,  0.8442,
          1.7153,  1.1997,  1.8232,  1.7378, -0.0277, -0.2494, -0.2814, -0.0793,
          0.1488,  0.2160, -0.1380, 20.5612,  1.6440,  0.7123,  1.2736,  1.3363,
          1.5646,  0.9122,  1.5019,  0.3337,  1.6855,  1.7223],
        [ 1.2177,  1.2553,  1.3221,  1.2997,  1.2634,  1.2242,  1.1926,  1.2142,
          1.2142,  1.1877,  1.3162,  1.2050,  1.3543,  1.2676,  1.4135,  1.1946,
          1.2448,  1.2697,  1.2808,  1.2658,  1.3309,  1.2984,  1.2434,  1.2368,
          1.1319,  1.2262,  1.2262,  1.2956,  1.3425,  1.2441,  1.0250,  1.2515,
          1.1256,  1.3034,  1.1182,  1.2478,  1.2630,  0.9801,  1.2586,  1.2803,
          0.8192,  0.7499,  1.2860,  1.0962,  0.6325,  3.6446,  2.5372,  3.6671,
          2.8320,  2.1359,  1.8092,  2.9739,  3.5559,  1.7849]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 345 : 178.5344786493219
Test loss for epoch 345 : 179.11413761278158
Test Precision for epoch 345 : 0.26153846153846155
Test Recall for epoch 345 : 0.26153846153846155
Test F1 for epoch 345 : 0.26153846153846155


theta for epoch 346 : tensor([[ 2.7305,  2.7634,  2.8395,  2.9793,  2.9414,  2.7360,  2.9171,  2.7277,
          2.7277,  1.2305,  1.2555,  1.2424,  1.2817,  1.2223,  1.3236,  1.2352,
          1.2070,  1.2413,  1.2078,  1.1836,  1.1978,  1.2200,  1.1822,  1.1776,
          1.1956,  1.1704,  1.1704,  1.2144,  1.2600,  1.1915,  1.2162,  1.2601,
          1.2013,  1.2329,  1.1507,  1.1940,  1.4000,  1.4608,  1.4347,  1.4122,
          1.4409,  1.3892,  1.4146,  1.2941,  1.3932,  1.3172,  1.2629,  1.2492,
          1.2276,  1.3104,  1.2488,  1.3528,  1.2103,  1.2242],
        [ 1.1719,  1.2018,  1.2552,  1.2351,  1.2080,  1.1768,  1.1872,  1.1688,
          1.1688,  2.4867,  2.5184,  2.4827,  2.7716,  2.4565,  3.7672,  2.4923,
          2.7025,  3.5672,  1.1869,  1.2106,  1.1810,  1.2012,  1.1972,  1.1920,
          1.2122,  1.1836,  1.1836,  1.2421,  1.1974,  1.2036,  1.2324,  1.2404,
          1.2150,  1.2516,  1.1693,  1.2066,  1.3498,  1.4221,  1.3364,  1.3635,
          1.3984,  1.4118,  1.3127,  1.2218,  1.3407,  1.2809,  1.2669,  1.2509,
          1.2257,  1.2308,  1.2505,  1.2798,  1.2057,  1.2218],
        [ 1.1616,  1.1880,  1.2162,  1.2185,  1.1929,  1.1662,  1.1743,  1.1592,
          1.1592,  1.2349,  1.2604,  1.2470,  1.2870,  1.2266,  1.2778,  1.2397,
          1.1593,  1.2869,  2.7600,  3.0104,  2.9796,  2.7769,  2.7171,  2.7114,
          2.9613,  2.7032,  2.7032,  1.2001,  1.2599,  1.1959,  1.2200,  1.2010,
          1.2059,  1.2381,  1.1999,  1.1985,  1.3968,  1.4590,  1.4306,  1.3209,
          1.4370,  1.4190,  1.4117,  1.2884,  1.3005,  1.3203,  1.2663,  1.2524,
          1.2303,  1.3087,  1.2520,  1.3519,  1.1898,  1.2269],
        [ 1.1654,  1.1924,  1.2212,  1.2239,  1.1977,  1.1701,  1.1786,  1.1630,
          1.1630,  1.2381,  1.2642,  1.2505,  1.2845,  1.2296,  1.2795,  1.2430,
          1.2130,  1.2427,  1.2175,  1.2108,  1.2525,  1.2301,  1.1908,  1.1861,
          1.1836,  1.1785,  1.1785,  3.0287,  2.9538,  2.6630,  2.7211,  3.0266,
          2.6744,  2.9140,  2.6803,  2.6659,  1.3912,  1.4550,  1.4188,  1.3744,
          1.4341,  1.4158,  1.3978,  1.2782,  1.3543,  1.3252,  1.2687,  1.2043,
          1.1836,  1.3183,  1.2541,  1.3624,  1.1440,  1.2283],
        [ 1.7633,  1.3866,  0.6095,  0.8923,  1.2872,  1.6973,  1.5757,  1.7979,
          1.7979,  1.5731,  1.2328,  1.4332,  0.8819,  1.6249,  0.1394,  1.5156,
          1.7881,  0.7921,  1.2931,  0.9926,  0.7511,  1.1151,  1.6382,  1.7011,
          1.4979,  1.8025,  1.8025,  0.8440,  0.8248,  1.7728,  1.5715,  0.8454,
          1.7163,  1.2008,  1.8241,  1.7388, -0.0302, -0.2517, -0.2836, -0.0819,
          0.1460,  0.2131, -0.1404, 20.6250,  1.6277,  0.7135,  1.2745,  1.3371,
          1.5654,  0.9133,  1.5026,  0.3351,  1.6863,  1.7229],
        [ 1.2174,  1.2551,  1.3218,  1.2995,  1.2632,  1.2239,  1.1924,  1.2139,
          1.2139,  1.1873,  1.3159,  1.2046,  1.3539,  1.2672,  1.4132,  1.1942,
          1.2445,  1.2695,  1.2805,  1.2655,  1.3306,  1.2981,  1.2432,  1.2365,
          1.1316,  1.2259,  1.2259,  1.2953,  1.3422,  1.2438,  1.0247,  1.2512,
          1.1253,  1.3032,  1.1179,  1.2476,  1.2626,  0.9796,  1.2581,  1.2799,
          0.8188,  0.7494,  1.2856,  1.0954,  0.6323,  3.6494,  2.5400,  3.6698,
          2.8347,  2.1384,  1.8114,  2.9766,  3.5608,  1.7871]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 346 : 178.5261948083937
Test loss for epoch 346 : 179.1096666767052
Test Precision for epoch 346 : 0.26153846153846155
Test Recall for epoch 346 : 0.26153846153846155
Test F1 for epoch 346 : 0.26153846153846155


theta for epoch 347 : tensor([[ 2.7336,  2.7665,  2.8426,  2.9825,  2.9446,  2.7391,  2.9202,  2.7308,
          2.7308,  1.2301,  1.2551,  1.2419,  1.2812,  1.2219,  1.3232,  1.2348,
          1.2066,  1.2409,  1.2075,  1.1833,  1.1974,  1.2196,  1.1818,  1.1773,
          1.1952,  1.1701,  1.1701,  1.2140,  1.2596,  1.1911,  1.2159,  1.2597,
          1.2010,  1.2326,  1.1504,  1.1937,  1.3999,  1.4608,  1.4346,  1.4121,
          1.4408,  1.3891,  1.4145,  1.2938,  1.3935,  1.3169,  1.2626,  1.2490,
          1.2273,  1.3101,  1.2485,  1.3525,  1.2100,  1.2239],
        [ 1.1713,  1.2012,  1.2545,  1.2345,  1.2075,  1.1763,  1.1867,  1.1683,
          1.1683,  2.4940,  2.5258,  2.4915,  2.7824,  2.4654,  3.7501,  2.4997,
          2.7130,  3.5520,  1.1865,  1.2102,  1.1806,  1.2009,  1.1967,  1.1914,
          1.2117,  1.1830,  1.1830,  1.2418,  1.1968,  1.2031,  1.2319,  1.2401,
          1.2145,  1.2510,  1.1690,  1.2061,  1.3496,  1.4220,  1.3365,  1.3634,
          1.3983,  1.4117,  1.3128,  1.2218,  1.3410,  1.2804,  1.2665,  1.2505,
          1.2253,  1.2305,  1.2500,  1.2794,  1.2053,  1.2213],
        [ 1.1613,  1.1876,  1.2158,  1.2182,  1.1926,  1.1658,  1.1740,  1.1589,
          1.1589,  1.2345,  1.2600,  1.2466,  1.2866,  1.2261,  1.2773,  1.2393,
          1.1587,  1.2863,  2.7630,  3.0145,  2.9830,  2.7799,  2.7198,  2.7141,
          2.9654,  2.7059,  2.7059,  1.1996,  1.2594,  1.1956,  1.2197,  1.2005,
          1.2056,  1.2378,  1.1996,  1.1982,  1.3968,  1.4590,  1.4306,  1.3208,
          1.4370,  1.4190,  1.4117,  1.2881,  1.3006,  1.3201,  1.2661,  1.2521,
          1.2301,  1.3082,  1.2517,  1.3514,  1.1895,  1.2266],
        [ 1.1651,  1.1920,  1.2207,  1.2235,  1.1973,  1.1697,  1.1783,  1.1626,
          1.1626,  1.2377,  1.2637,  1.2500,  1.2838,  1.2291,  1.2789,  1.2426,
          1.2126,  1.2422,  1.2171,  1.2102,  1.2521,  1.2297,  1.1904,  1.1857,
          1.1832,  1.1781,  1.1781,  3.0322,  2.9559,  2.6665,  2.7231,  3.0301,
          2.6779,  2.9160,  2.6842,  2.6694,  1.3911,  1.4549,  1.4183,  1.3742,
          1.4340,  1.4157,  1.3973,  1.2779,  1.3545,  1.3249,  1.2684,  1.2041,
          1.1832,  1.3179,  1.2537,  1.3621,  1.1436,  1.2280],
        [ 1.7643,  1.3877,  0.6109,  0.8936,  1.2883,  1.6983,  1.5768,  1.7989,
          1.7989,  1.5741,  1.2339,  1.4343,  0.8832,  1.6260,  0.1411,  1.5166,
          1.7891,  0.7935,  1.2942,  0.9938,  0.7524,  1.1163,  1.6392,  1.7021,
          1.4990,  1.8035,  1.8035,  0.8453,  0.8260,  1.7738,  1.5725,  0.8467,
          1.7172,  1.2019,  1.8250,  1.7397, -0.0327, -0.2539, -0.2859, -0.0844,
          0.1433,  0.2102, -0.1427, 20.6883,  1.6133,  0.7146,  1.2753,  1.3379,
          1.5661,  0.9143,  1.5033,  0.3364,  1.6870,  1.7235],
        [ 1.2171,  1.2548,  1.3215,  1.2993,  1.2629,  1.2237,  1.1921,  1.2137,
          1.2137,  1.1870,  1.3156,  1.2043,  1.3536,  1.2669,  1.4130,  1.1939,
          1.2442,  1.2693,  1.2802,  1.2652,  1.3303,  1.2978,  1.2429,  1.2363,
          1.1313,  1.2257,  1.2257,  1.2951,  1.3420,  1.2436,  1.0245,  1.2509,
          1.1250,  1.3030,  1.1176,  1.2473,  1.2621,  0.9791,  1.2576,  1.2794,
          0.8182,  0.7490,  1.2851,  1.0946,  0.6320,  3.6543,  2.5429,  3.6727,
          2.8376,  2.1410,  1.8136,  2.9795,  3.5659,  1.7893]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 347 : 178.5180770424657
Test loss for epoch 347 : 179.1052006509036
Test Precision for epoch 347 : 0.26153846153846155
Test Recall for epoch 347 : 0.26153846153846155
Test F1 for epoch 347 : 0.26153846153846155


theta for epoch 348 : tensor([[ 2.7368,  2.7697,  2.8459,  2.9858,  2.9479,  2.7423,  2.9236,  2.7340,
          2.7340,  1.2297,  1.2547,  1.2415,  1.2808,  1.2215,  1.3228,  1.2344,
          1.2063,  1.2406,  1.2071,  1.1829,  1.1970,  1.2192,  1.1815,  1.1770,
          1.1948,  1.1697,  1.1697,  1.2137,  1.2592,  1.1908,  1.2156,  1.2594,
          1.2006,  1.2322,  1.1500,  1.1933,  1.3998,  1.4607,  1.4345,  1.4120,
          1.4408,  1.3891,  1.4144,  1.2935,  1.3937,  1.3166,  1.2624,  1.2487,
          1.2270,  1.3098,  1.2482,  1.3522,  1.2097,  1.2236],
        [ 1.1707,  1.2006,  1.2538,  1.2339,  1.2069,  1.1757,  1.1861,  1.1678,
          1.1678,  2.5013,  2.5332,  2.5003,  2.7931,  2.4744,  3.7338,  2.5072,
          2.7233,  3.5374,  1.1862,  1.2099,  1.1802,  1.2005,  1.1962,  1.1909,
          1.2112,  1.1825,  1.1825,  1.2415,  1.1963,  1.2026,  1.2314,  1.2398,
          1.2140,  1.2505,  1.1687,  1.2056,  1.3495,  1.4218,  1.3365,  1.3633,
          1.3982,  1.4116,  1.3129,  1.2218,  1.3412,  1.2799,  1.2660,  1.2501,
          1.2249,  1.2301,  1.2496,  1.2790,  1.2049,  1.2209],
        [ 1.1609,  1.1873,  1.2154,  1.2178,  1.1923,  1.1655,  1.1737,  1.1585,
          1.1585,  1.2341,  1.2596,  1.2462,  1.2862,  1.2258,  1.2767,  1.2389,
          1.1582,  1.2858,  2.7662,  3.0187,  2.9865,  2.7831,  2.7226,  2.7169,
          2.9696,  2.7087,  2.7087,  1.1992,  1.2588,  1.1952,  1.2193,  1.2001,
          1.2053,  1.2375,  1.1992,  1.1978,  1.3967,  1.4589,  1.4305,  1.3206,
          1.4370,  1.4189,  1.4116,  1.2878,  1.3007,  1.3198,  1.2658,  1.2519,
          1.2298,  1.3077,  1.2514,  1.3509,  1.1892,  1.2263],
        [ 1.1647,  1.1916,  1.2203,  1.2231,  1.1969,  1.1693,  1.1779,  1.1622,
          1.1622,  1.2372,  1.2633,  1.2496,  1.2832,  1.2287,  1.2783,  1.2422,
          1.2122,  1.2417,  1.2167,  1.2095,  1.2517,  1.2293,  1.1901,  1.1853,
          1.1828,  1.1778,  1.1778,  3.0359,  2.9581,  2.6701,  2.7254,  3.0339,
          2.6815,  2.9182,  2.6883,  2.6730,  1.3909,  1.4548,  1.4178,  1.3740,
          1.4339,  1.4156,  1.3968,  1.2775,  1.3547,  1.3246,  1.2681,  1.2039,
          1.1829,  1.3176,  1.2534,  1.3617,  1.1433,  1.2276],
        [ 1.7653,  1.3888,  0.6122,  0.8948,  1.2894,  1.6993,  1.5778,  1.7999,
          1.7999,  1.5752,  1.2350,  1.4354,  0.8845,  1.6270,  0.1428,  1.5176,
          1.7901,  0.7950,  1.2953,  0.9951,  0.7537,  1.1174,  1.6402,  1.7031,
          1.5002,  1.8044,  1.8044,  0.8465,  0.8273,  1.7747,  1.5735,  0.8479,
          1.7181,  1.2030,  1.8259,  1.7406, -0.0352, -0.2561, -0.2881, -0.0868,
          0.1406,  0.2074, -0.1451, 20.7510,  1.6004,  0.7157,  1.2761,  1.3387,
          1.5667,  0.9153,  1.5040,  0.3377,  1.6877,  1.7240],
        [ 1.2169,  1.2546,  1.3212,  1.2990,  1.2627,  1.2234,  1.1919,  1.2134,
          1.2134,  1.1867,  1.3153,  1.2040,  1.3533,  1.2666,  1.4127,  1.1936,
          1.2440,  1.2692,  1.2799,  1.2649,  1.3301,  1.2975,  1.2427,  1.2360,
          1.1311,  1.2254,  1.2254,  1.2948,  1.3417,  1.2433,  1.0242,  1.2507,
          1.1248,  1.3027,  1.1173,  1.2470,  1.2616,  0.9786,  1.2571,  1.2790,
          0.8177,  0.7485,  1.2846,  1.0938,  0.6316,  3.6594,  2.5460,  3.6758,
          2.8406,  2.1436,  1.8158,  2.9825,  3.5712,  1.7915]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 348 : 178.51011564234202
Test loss for epoch 348 : 179.10073017448414
Test Precision for epoch 348 : 0.26153846153846155
Test Recall for epoch 348 : 0.26153846153846155
Test F1 for epoch 348 : 0.26153846153846155


theta for epoch 349 : tensor([[ 2.7402,  2.7731,  2.8493,  2.9893,  2.9514,  2.7457,  2.9271,  2.7374,
          2.7374,  1.2292,  1.2542,  1.2411,  1.2803,  1.2210,  1.3223,  1.2340,
          1.2059,  1.2402,  1.2067,  1.1825,  1.1966,  1.2188,  1.1811,  1.1766,
          1.1945,  1.1694,  1.1694,  1.2133,  1.2589,  1.1904,  1.2152,  1.2590,
          1.2003,  1.2319,  1.1496,  1.1930,  1.3997,  1.4607,  1.4344,  1.4119,
          1.4408,  1.3891,  1.4143,  1.2932,  1.3939,  1.3163,  1.2621,  1.2485,
          1.2268,  1.3095,  1.2479,  1.3519,  1.2094,  1.2233],
        [ 1.1702,  1.2001,  1.2531,  1.2334,  1.2064,  1.1753,  1.1856,  1.1673,
          1.1673,  2.5087,  2.5406,  2.5091,  2.8037,  2.4832,  3.7180,  2.5147,
          2.7336,  3.5236,  1.1858,  1.2096,  1.1799,  1.2002,  1.1957,  1.1904,
          1.2107,  1.1820,  1.1820,  1.2412,  1.1958,  1.2022,  1.2309,  1.2395,
          1.2136,  1.2501,  1.1684,  1.2051,  1.3494,  1.4217,  1.3367,  1.3632,
          1.3981,  1.4115,  1.3131,  1.2218,  1.3414,  1.2794,  1.2657,  1.2498,
          1.2245,  1.2298,  1.2492,  1.2786,  1.2046,  1.2205],
        [ 1.1606,  1.1870,  1.2150,  1.2175,  1.1920,  1.1652,  1.1734,  1.1582,
          1.1582,  1.2337,  1.2592,  1.2458,  1.2857,  1.2253,  1.2761,  1.2385,
          1.1576,  1.2853,  2.7696,  3.0230,  2.9901,  2.7865,  2.7255,  2.7198,
          2.9739,  2.7116,  2.7116,  1.1988,  1.2583,  1.1949,  1.2191,  1.1997,
          1.2049,  1.2372,  1.1989,  1.1975,  1.3966,  1.4589,  1.4305,  1.3204,
          1.4370,  1.4189,  1.4115,  1.2876,  1.3008,  1.3196,  1.2656,  1.2517,
          1.2296,  1.3072,  1.2511,  1.3505,  1.1889,  1.2260],
        [ 1.1643,  1.1912,  1.2199,  1.2227,  1.1966,  1.1690,  1.1775,  1.1618,
          1.1618,  1.2368,  1.2629,  1.2491,  1.2824,  1.2282,  1.2777,  1.2417,
          1.2118,  1.2411,  1.2163,  1.2089,  1.2513,  1.2289,  1.1897,  1.1849,
          1.1823,  1.1774,  1.1774,  3.0398,  2.9606,  2.6738,  2.7278,  3.0378,
          2.6852,  2.9205,  2.6925,  2.6767,  1.3907,  1.4547,  1.4174,  1.3738,
          1.4338,  1.4155,  1.3963,  1.2772,  1.3549,  1.3243,  1.2678,  1.2036,
          1.1826,  1.3172,  1.2530,  1.3614,  1.1429,  1.2273],
        [ 1.7663,  1.3899,  0.6135,  0.8959,  1.2905,  1.7003,  1.5789,  1.8008,
          1.8008,  1.5761,  1.2360,  1.4363,  0.8857,  1.6280,  0.1444,  1.5185,
          1.7911,  0.7963,  1.2964,  0.9963,  0.7549,  1.1185,  1.6412,  1.7041,
          1.5013,  1.8054,  1.8054,  0.8477,  0.8285,  1.7756,  1.5745,  0.8490,
          1.7191,  1.2040,  1.8268,  1.7415, -0.0377, -0.2582, -0.2902, -0.0892,
          0.1379,  0.2046, -0.1474, 20.8131,  1.5891,  0.7167,  1.2769,  1.3394,
          1.5674,  0.9162,  1.5047,  0.3390,  1.6884,  1.7246],
        [ 1.2166,  1.2543,  1.3210,  1.2988,  1.2624,  1.2232,  1.1916,  1.2131,
          1.2131,  1.1864,  1.3150,  1.2037,  1.3530,  1.2662,  1.4125,  1.1933,
          1.2437,  1.2690,  1.2796,  1.2646,  1.3298,  1.2972,  1.2424,  1.2358,
          1.1308,  1.2252,  1.2252,  1.2945,  1.3414,  1.2430,  1.0239,  1.2504,
          1.1245,  1.3025,  1.1169,  1.2468,  1.2611,  0.9781,  1.2566,  1.2785,
          0.8172,  0.7480,  1.2841,  1.0930,  0.6312,  3.6647,  2.5492,  3.6791,
          2.8438,  2.1464,  1.8181,  2.9858,  3.5767,  1.7938]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 349 : 178.50229829870617
Test loss for epoch 349 : 179.0963256851339
Test Precision for epoch 349 : 0.26153846153846155
Test Recall for epoch 349 : 0.26153846153846155
Test F1 for epoch 349 : 0.26153846153846155


theta for epoch 350 : tensor([[ 2.7437,  2.7767,  2.8528,  2.9930,  2.9550,  2.7492,  2.9307,  2.7409,
          2.7409,  1.2288,  1.2538,  1.2406,  1.2799,  1.2206,  1.3219,  1.2336,
          1.2055,  1.2399,  1.2063,  1.1821,  1.1962,  1.2184,  1.1808,  1.1762,
          1.1941,  1.1690,  1.1690,  1.2129,  1.2585,  1.1901,  1.2149,  1.2586,
          1.1999,  1.2315,  1.1492,  1.1926,  1.3997,  1.4606,  1.4343,  1.4119,
          1.4408,  1.3890,  1.4142,  1.2929,  1.3941,  1.3160,  1.2618,  1.2482,
          1.2265,  1.3092,  1.2476,  1.3516,  1.2091,  1.2230],
        [ 1.1696,  1.1995,  1.2524,  1.2329,  1.2059,  1.1748,  1.1851,  1.1669,
          1.1669,  2.5161,  2.5481,  2.5178,  2.8143,  2.4920,  3.7030,  2.5222,
          2.7439,  3.5104,  1.1854,  1.2093,  1.1795,  1.1998,  1.1952,  1.1899,
          1.2103,  1.1816,  1.1816,  1.2409,  1.1953,  1.2017,  1.2305,  1.2392,
          1.2131,  1.2496,  1.1682,  1.2047,  1.3492,  1.4216,  1.3368,  1.3631,
          1.3981,  1.4115,  1.3132,  1.2217,  1.3416,  1.2790,  1.2653,  1.2495,
          1.2242,  1.2295,  1.2488,  1.2783,  1.2042,  1.2201],
        [ 1.1603,  1.1866,  1.2146,  1.2172,  1.1916,  1.1649,  1.1730,  1.1579,
          1.1579,  1.2333,  1.2588,  1.2454,  1.2854,  1.2250,  1.2755,  1.2382,
          1.1571,  1.2848,  2.7730,  3.0274,  2.9939,  2.7899,  2.7286,  2.7228,
          2.9783,  2.7147,  2.7147,  1.1984,  1.2578,  1.1946,  1.2187,  1.1993,
          1.2046,  1.2369,  1.1986,  1.1972,  1.3966,  1.4589,  1.4304,  1.3202,
          1.4370,  1.4188,  1.4115,  1.2873,  1.3009,  1.3194,  1.2653,  1.2515,
          1.2293,  1.3068,  1.2509,  1.3500,  1.1886,  1.2257],
        [ 1.1640,  1.1909,  1.2194,  1.2223,  1.1962,  1.1686,  1.1772,  1.1615,
          1.1615,  1.2364,  1.2624,  1.2487,  1.2818,  1.2278,  1.2772,  1.2413,
          1.2114,  1.2406,  1.2159,  1.2082,  1.2509,  1.2285,  1.1893,  1.1846,
          1.1819,  1.1770,  1.1770,  3.0438,  2.9631,  2.6776,  2.7304,  3.0418,
          2.6890,  2.9230,  2.6968,  2.6805,  1.3906,  1.4546,  1.4169,  1.3736,
          1.4337,  1.4154,  1.3959,  1.2769,  1.3550,  1.3240,  1.2675,  1.2034,
          1.1823,  1.3169,  1.2527,  1.3611,  1.1426,  1.2269],
        [ 1.7673,  1.3909,  0.6148,  0.8971,  1.2916,  1.7013,  1.5799,  1.8018,
          1.8018,  1.5770,  1.2371,  1.4374,  0.8869,  1.6289,  0.1461,  1.5195,
          1.7920,  0.7977,  1.2974,  0.9975,  0.7562,  1.1196,  1.6422,  1.7051,
          1.5024,  1.8063,  1.8063,  0.8489,  0.8296,  1.7764,  1.5754,  0.8502,
          1.7200,  1.2051,  1.8276,  1.7424, -0.0401, -0.2603, -0.2923, -0.0916,
          0.1353,  0.2019, -0.1497, 20.8747,  1.5793,  0.7178,  1.2777,  1.3401,
          1.5680,  0.9171,  1.5053,  0.3403,  1.6890,  1.7251],
        [ 1.2163,  1.2540,  1.3207,  1.2985,  1.2622,  1.2229,  1.1914,  1.2128,
          1.2128,  1.1861,  1.3147,  1.2033,  1.3526,  1.2659,  1.4122,  1.1930,
          1.2434,  1.2688,  1.2793,  1.2643,  1.3295,  1.2969,  1.2421,  1.2355,
          1.1304,  1.2249,  1.2249,  1.2943,  1.3412,  1.2427,  1.0236,  1.2501,
          1.1242,  1.3023,  1.1166,  1.2465,  1.2606,  0.9776,  1.2560,  1.2780,
          0.8167,  0.7475,  1.2836,  1.0922,  0.6307,  3.6702,  2.5525,  3.6827,
          2.8472,  2.1492,  1.8205,  2.9892,  3.5823,  1.7962]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 350 : 178.494618863762
Test loss for epoch 350 : 179.09188925047954
Test Precision for epoch 350 : 0.26153846153846155
Test Recall for epoch 350 : 0.26153846153846155
Test F1 for epoch 350 : 0.26153846153846155


theta for epoch 351 : tensor([[ 2.7473,  2.7803,  2.8564,  2.9967,  2.9588,  2.7528,  2.9344,  2.7445,
          2.7445,  1.2285,  1.2535,  1.2403,  1.2795,  1.2202,  1.3216,  1.2332,
          1.2052,  1.2396,  1.2060,  1.1817,  1.1958,  1.2181,  1.1804,  1.1759,
          1.1937,  1.1687,  1.1687,  1.2125,  1.2582,  1.1897,  1.2146,  1.2583,
          1.1996,  1.2312,  1.1489,  1.1923,  1.3996,  1.4606,  1.4343,  1.4118,
          1.4408,  1.3890,  1.4142,  1.2927,  1.3942,  1.3158,  1.2615,  1.2479,
          1.2262,  1.3089,  1.2473,  1.3514,  1.2088,  1.2226],
        [ 1.1691,  1.1989,  1.2518,  1.2324,  1.2054,  1.1743,  1.1846,  1.1664,
          1.1664,  2.5236,  2.5556,  2.5265,  2.8248,  2.5008,  3.6885,  2.5298,
          2.7541,  3.4980,  1.1851,  1.2091,  1.1792,  1.1994,  1.1947,  1.1895,
          1.2098,  1.1811,  1.1811,  1.2406,  1.1949,  1.2013,  1.2300,  1.2390,
          1.2126,  1.2491,  1.1679,  1.2042,  1.3491,  1.4215,  1.3370,  1.3630,
          1.3980,  1.4114,  1.3134,  1.2216,  1.3418,  1.2785,  1.2649,  1.2491,
          1.2238,  1.2291,  1.2484,  1.2779,  1.2039,  1.2197],
        [ 1.1600,  1.1863,  1.2142,  1.2168,  1.1913,  1.1646,  1.1727,  1.1576,
          1.1576,  1.2330,  1.2585,  1.2450,  1.2850,  1.2246,  1.2749,  1.2378,
          1.1566,  1.2843,  2.7767,  3.0320,  2.9978,  2.7936,  2.7318,  2.7260,
          2.9829,  2.7179,  2.7179,  1.1980,  1.2573,  1.1943,  1.2184,  1.1989,
          1.2043,  1.2366,  1.1983,  1.1969,  1.3965,  1.4589,  1.4303,  1.3201,
          1.4370,  1.4188,  1.4114,  1.2871,  1.3009,  1.3191,  1.2651,  1.2512,
          1.2291,  1.3063,  1.2506,  1.3495,  1.1883,  1.2254],
        [ 1.1636,  1.1905,  1.2190,  1.2220,  1.1958,  1.1683,  1.1768,  1.1611,
          1.1611,  1.2360,  1.2621,  1.2483,  1.2811,  1.2274,  1.2766,  1.2409,
          1.2110,  1.2401,  1.2155,  1.2076,  1.2505,  1.2281,  1.1890,  1.1842,
          1.1815,  1.1767,  1.1767,  3.0480,  2.9659,  2.6815,  2.7331,  3.0460,
          2.6930,  2.9256,  2.7012,  2.6845,  1.3905,  1.4545,  1.4165,  1.3735,
          1.4337,  1.4153,  1.3954,  1.2766,  1.3551,  1.3237,  1.2672,  1.2032,
          1.1820,  1.3166,  1.2524,  1.3608,  1.1422,  1.2266],
        [ 1.7683,  1.3919,  0.6161,  0.8982,  1.2927,  1.7022,  1.5809,  1.8027,
          1.8027,  1.5780,  1.2381,  1.4383,  0.8880,  1.6299,  0.1477,  1.5204,
          1.7930,  0.7991,  1.2984,  0.9986,  0.7574,  1.1206,  1.6432,  1.7060,
          1.5034,  1.8072,  1.8072,  0.8501,  0.8308,  1.7773,  1.5764,  0.8513,
          1.7208,  1.2061,  1.8284,  1.7433, -0.0424, -0.2624, -0.2944, -0.0939,
          0.1328,  0.1992, -0.1519, 20.9356,  1.5708,  0.7188,  1.2783,  1.3408,
          1.5686,  0.9180,  1.5059,  0.3415,  1.6896,  1.7256],
        [ 1.2160,  1.2538,  1.3204,  1.2982,  1.2619,  1.2226,  1.1911,  1.2126,
          1.2126,  1.1858,  1.3145,  1.2030,  1.3524,  1.2655,  1.4120,  1.1927,
          1.2432,  1.2687,  1.2791,  1.2641,  1.3292,  1.2966,  1.2419,  1.2352,
          1.1302,  1.2246,  1.2246,  1.2940,  1.3409,  1.2424,  1.0233,  1.2499,
          1.1239,  1.3020,  1.1163,  1.2462,  1.2600,  0.9771,  1.2555,  1.2775,
          0.8162,  0.7470,  1.2830,  1.0914,  0.6302,  3.6758,  2.5559,  3.6864,
          2.8507,  2.1520,  1.8229,  2.9927,  3.5881,  1.7985]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 351 : 178.48707015477203
Test loss for epoch 351 : 179.0874795329512
Test Precision for epoch 351 : 0.26153846153846155
Test Recall for epoch 351 : 0.26153846153846155
Test F1 for epoch 351 : 0.26153846153846155


theta for epoch 352 : tensor([[ 2.7511,  2.7841,  2.8602,  3.0007,  2.9627,  2.7565,  2.9384,  2.7483,
          2.7483,  1.2280,  1.2531,  1.2398,  1.2791,  1.2198,  1.3211,  1.2328,
          1.2048,  1.2392,  1.2056,  1.1813,  1.1954,  1.2177,  1.1801,  1.1755,
          1.1933,  1.1683,  1.1683,  1.2122,  1.2578,  1.1894,  1.2142,  1.2579,
          1.1992,  1.2309,  1.1485,  1.1920,  1.3995,  1.4606,  1.4342,  1.4117,
          1.4408,  1.3890,  1.4141,  1.2925,  1.3943,  1.3155,  1.2613,  1.2477,
          1.2259,  1.3086,  1.2470,  1.3511,  1.2086,  1.2224],
        [ 1.1686,  1.1984,  1.2512,  1.2319,  1.2050,  1.1739,  1.1841,  1.1660,
          1.1660,  2.5310,  2.5630,  2.5351,  2.8352,  2.5095,  3.6747,  2.5373,
          2.7642,  3.4862,  1.1848,  1.2088,  1.1789,  1.1990,  1.1943,  1.1890,
          1.2093,  1.1807,  1.1807,  1.2404,  1.1944,  1.2009,  1.2296,  1.2388,
          1.2122,  1.2487,  1.1677,  1.2038,  1.3491,  1.4215,  1.3372,  1.3630,
          1.3980,  1.4114,  1.3136,  1.2215,  1.3419,  1.2780,  1.2646,  1.2488,
          1.2235,  1.2288,  1.2481,  1.2776,  1.2036,  1.2194],
        [ 1.1597,  1.1860,  1.2138,  1.2165,  1.1910,  1.1643,  1.1724,  1.1573,
          1.1573,  1.2326,  1.2581,  1.2446,  1.2846,  1.2242,  1.2744,  1.2374,
          1.1560,  1.2838,  2.7805,  3.0366,  3.0019,  2.7973,  2.7351,  2.7293,
          2.9875,  2.7212,  2.7212,  1.1976,  1.2568,  1.1940,  1.2182,  1.1985,
          1.2040,  1.2363,  1.1980,  1.1966,  1.3965,  1.4589,  1.4303,  1.3199,
          1.4370,  1.4187,  1.4113,  1.2869,  1.3009,  1.3189,  1.2648,  1.2510,
          1.2288,  1.3058,  1.2503,  1.3491,  1.1880,  1.2252],
        [ 1.1632,  1.1902,  1.2186,  1.2216,  1.1955,  1.1679,  1.1765,  1.1608,
          1.1608,  1.2356,  1.2616,  1.2478,  1.2805,  1.2269,  1.2760,  1.2405,
          1.2107,  1.2396,  1.2151,  1.2070,  1.2501,  1.2277,  1.1886,  1.1839,
          1.1811,  1.1763,  1.1763,  3.0524,  2.9687,  2.6856,  2.7359,  3.0504,
          2.6970,  2.9284,  2.7058,  2.6885,  1.3903,  1.4544,  1.4160,  1.3733,
          1.4336,  1.4152,  1.3950,  1.2763,  1.3551,  1.3235,  1.2669,  1.2030,
          1.1817,  1.3163,  1.2521,  1.3605,  1.1419,  1.2263],
        [ 1.7692,  1.3929,  0.6173,  0.8993,  1.2937,  1.7031,  1.5819,  1.8036,
          1.8036,  1.5788,  1.2390,  1.4393,  0.8891,  1.6307,  0.1493,  1.5213,
          1.7939,  0.8004,  1.2994,  0.9997,  0.7585,  1.1216,  1.6441,  1.7069,
          1.5044,  1.8081,  1.8081,  0.8512,  0.8319,  1.7781,  1.5773,  0.8524,
          1.7217,  1.2071,  1.8293,  1.7441, -0.0447, -0.2644, -0.2964, -0.0962,
          0.1303,  0.1966, -0.1540, 20.9961,  1.5636,  0.7198,  1.2790,  1.3415,
          1.5691,  0.9189,  1.5065,  0.3427,  1.6902,  1.7261],
        [ 1.2157,  1.2535,  1.3202,  1.2980,  1.2617,  1.2223,  1.1908,  1.2123,
          1.2123,  1.1855,  1.3141,  1.2027,  1.3520,  1.2652,  1.4117,  1.1924,
          1.2429,  1.2685,  1.2788,  1.2638,  1.3289,  1.2963,  1.2416,  1.2349,
          1.1298,  1.2243,  1.2243,  1.2937,  1.3407,  1.2421,  1.0230,  1.2496,
          1.1236,  1.3017,  1.1160,  1.2459,  1.2595,  0.9766,  1.2550,  1.2770,
          0.8156,  0.7465,  1.2825,  1.0906,  0.6296,  3.6816,  2.5595,  3.6904,
          2.8545,  2.1549,  1.8253,  2.9964,  3.5940,  1.8009]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 352 : 178.47964689946232
Test loss for epoch 352 : 179.08308557047985
Test Precision for epoch 352 : 0.26153846153846155
Test Recall for epoch 352 : 0.26153846153846155
Test F1 for epoch 352 : 0.26153846153846155


theta for epoch 353 : tensor([[ 2.7549,  2.7879,  2.8641,  3.0047,  2.9667,  2.7604,  2.9424,  2.7522,
          2.7522,  1.2277,  1.2527,  1.2394,  1.2787,  1.2194,  1.3208,  1.2324,
          1.2044,  1.2389,  1.2052,  1.1809,  1.1950,  1.2173,  1.1797,  1.1752,
          1.1930,  1.1680,  1.1680,  1.2118,  1.2575,  1.1891,  1.2139,  1.2576,
          1.1989,  1.2306,  1.1482,  1.1916,  1.3995,  1.4606,  1.4341,  1.4117,
          1.4408,  1.3890,  1.4140,  1.2923,  1.3944,  1.3153,  1.2610,  1.2475,
          1.2257,  1.3083,  1.2467,  1.3509,  1.2083,  1.2221],
        [ 1.1681,  1.1979,  1.2506,  1.2315,  1.2045,  1.1735,  1.1836,  1.1655,
          1.1655,  2.5385,  2.5705,  2.5437,  2.8456,  2.5182,  3.6616,  2.5449,
          2.7743,  3.4751,  1.1844,  1.2085,  1.1786,  1.1986,  1.1939,  1.1886,
          1.2088,  1.1802,  1.1802,  1.2401,  1.1940,  1.2004,  1.2291,  1.2386,
          1.2118,  1.2482,  1.1674,  1.2034,  1.3490,  1.4215,  1.3374,  1.3629,
          1.3980,  1.4114,  1.3138,  1.2214,  1.3421,  1.2776,  1.2643,  1.2485,
          1.2232,  1.2285,  1.2477,  1.2773,  1.2033,  1.2190],
        [ 1.1594,  1.1857,  1.2134,  1.2162,  1.1907,  1.1640,  1.1721,  1.1570,
          1.1570,  1.2322,  1.2577,  1.2442,  1.2842,  1.2238,  1.2738,  1.2371,
          1.1555,  1.2834,  2.7844,  3.0414,  3.0061,  2.8012,  2.7385,  2.7328,
          2.9922,  2.7246,  2.7246,  1.1972,  1.2563,  1.1937,  1.2179,  1.1981,
          1.2037,  1.2360,  1.1976,  1.1963,  1.3964,  1.4589,  1.4302,  1.3198,
          1.4370,  1.4187,  1.4113,  1.2867,  1.3008,  1.3187,  1.2646,  1.2508,
          1.2286,  1.3054,  1.2501,  1.3487,  1.1877,  1.2249],
        [ 1.1629,  1.1898,  1.2182,  1.2213,  1.1952,  1.1676,  1.1761,  1.1604,
          1.1604,  1.2352,  1.2613,  1.2474,  1.2798,  1.2265,  1.2755,  1.2401,
          1.2103,  1.2391,  1.2148,  1.2064,  1.2498,  1.2273,  1.1883,  1.1835,
          1.1807,  1.1760,  1.1760,  3.0568,  2.9718,  2.6897,  2.7389,  3.0549,
          2.7011,  2.9313,  2.7104,  2.6926,  1.3902,  1.4543,  1.4156,  1.3732,
          1.4335,  1.4152,  1.3945,  1.2760,  1.3551,  1.3232,  1.2666,  1.2028,
          1.1814,  1.3160,  1.2518,  1.3603,  1.1416,  1.2260],
        [ 1.7701,  1.3939,  0.6185,  0.9004,  1.2947,  1.7040,  1.5828,  1.8045,
          1.8045,  1.5796,  1.2399,  1.4402,  0.8902,  1.6316,  0.1508,  1.5221,
          1.7947,  0.8016,  1.3004,  1.0008,  0.7596,  1.1226,  1.6450,  1.7078,
          1.5054,  1.8090,  1.8090,  0.8523,  0.8330,  1.7789,  1.5782,  0.8534,
          1.7225,  1.2080,  1.8300,  1.7449, -0.0469, -0.2663, -0.2983, -0.0983,
          0.1279,  0.1941, -0.1561, 21.0559,  1.5575,  0.7207,  1.2797,  1.3421,
          1.5697,  0.9197,  1.5070,  0.3438,  1.6908,  1.7265],
        [ 1.2154,  1.2532,  1.3199,  1.2978,  1.2614,  1.2221,  1.1905,  1.2120,
          1.2120,  1.1852,  1.3139,  1.2023,  1.3517,  1.2648,  1.4115,  1.1921,
          1.2426,  1.2683,  1.2785,  1.2635,  1.3286,  1.2960,  1.2413,  1.2347,
          1.1295,  1.2241,  1.2241,  1.2934,  1.3404,  1.2418,  1.0227,  1.2493,
          1.1233,  1.3015,  1.1157,  1.2456,  1.2589,  0.9761,  1.2544,  1.2765,
          0.8151,  0.7460,  1.2819,  1.0898,  0.6290,  3.6875,  2.5631,  3.6946,
          2.8583,  2.1579,  1.8277,  3.0003,  3.6001,  1.8033]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 353 : 178.47234491421395
Test loss for epoch 353 : 179.07869810037818
Test Precision for epoch 353 : 0.26153846153846155
Test Recall for epoch 353 : 0.26153846153846155
Test F1 for epoch 353 : 0.26153846153846155


theta for epoch 354 : tensor([[ 2.7589,  2.7919,  2.8681,  3.0089,  2.9709,  2.7644,  2.9465,  2.7561,
          2.7561,  1.2273,  1.2523,  1.2391,  1.2783,  1.2190,  1.3204,  1.2321,
          1.2041,  1.2386,  1.2049,  1.1806,  1.1947,  1.2169,  1.1794,  1.1749,
          1.1927,  1.1677,  1.1677,  1.2115,  1.2572,  1.1888,  1.2136,  1.2573,
          1.1986,  1.2303,  1.1479,  1.1913,  1.3994,  1.4606,  1.4341,  1.4117,
          1.4408,  1.3890,  1.4140,  1.2921,  1.3944,  1.3151,  1.2608,  1.2472,
          1.2255,  1.3081,  1.2465,  1.3506,  1.2081,  1.2218],
        [ 1.1676,  1.1974,  1.2500,  1.2310,  1.2040,  1.1730,  1.1831,  1.1651,
          1.1651,  2.5461,  2.5780,  2.5522,  2.8559,  2.5269,  3.6490,  2.5525,
          2.7843,  3.4646,  1.1841,  1.2083,  1.1783,  1.1982,  1.1935,  1.1882,
          1.2083,  1.1798,  1.1798,  1.2398,  1.1936,  1.2000,  1.2287,  1.2384,
          1.2113,  1.2478,  1.1672,  1.2029,  1.3490,  1.4214,  1.3376,  1.3629,
          1.3980,  1.4115,  1.3141,  1.2212,  1.3421,  1.2772,  1.2639,  1.2482,
          1.2229,  1.2282,  1.2473,  1.2770,  1.2030,  1.2187],
        [ 1.1591,  1.1854,  1.2131,  1.2159,  1.1904,  1.1637,  1.1718,  1.1567,
          1.1567,  1.2319,  1.2574,  1.2439,  1.2838,  1.2235,  1.2733,  1.2368,
          1.1550,  1.2829,  2.7884,  3.0463,  3.0105,  2.8053,  2.7421,  2.7363,
          2.9971,  2.7282,  2.7282,  1.1968,  1.2559,  1.1934,  1.2176,  1.1978,
          1.2034,  1.2357,  1.1973,  1.1960,  1.3964,  1.4589,  1.4302,  1.3197,
          1.4371,  1.4187,  1.4112,  1.2865,  1.3007,  1.3185,  1.2644,  1.2506,
          1.2284,  1.3050,  1.2498,  1.3483,  1.1874,  1.2247],
        [ 1.1626,  1.1895,  1.2178,  1.2209,  1.1948,  1.1673,  1.1758,  1.1601,
          1.1601,  1.2348,  1.2609,  1.2471,  1.2792,  1.2262,  1.2750,  1.2398,
          1.2100,  1.2386,  1.2145,  1.2058,  1.2494,  1.2270,  1.1879,  1.1832,
          1.1803,  1.1757,  1.1757,  3.0615,  2.9750,  2.6938,  2.7421,  3.0595,
          2.7053,  2.9344,  2.7151,  2.6968,  1.3901,  1.4543,  1.4151,  1.3730,
          1.4335,  1.4151,  1.3941,  1.2757,  1.3551,  1.3230,  1.2663,  1.2026,
          1.1811,  1.3157,  1.2515,  1.3600,  1.1412,  1.2256],
        [ 1.7710,  1.3948,  0.6197,  0.9014,  1.2956,  1.7049,  1.5837,  1.8053,
          1.8053,  1.5804,  1.2409,  1.4410,  0.8913,  1.6324,  0.1523,  1.5229,
          1.7956,  0.8029,  1.3013,  1.0019,  0.7607,  1.1236,  1.6459,  1.7087,
          1.5064,  1.8098,  1.8098,  0.8533,  0.8340,  1.7797,  1.5790,  0.8545,
          1.7234,  1.2089,  1.8308,  1.7457, -0.0490, -0.2682, -0.3002, -0.1004,
          0.1256,  0.1916, -0.1581, 21.1152,  1.5524,  0.7216,  1.2803,  1.3427,
          1.5702,  0.9204,  1.5075,  0.3449,  1.6913,  1.7269],
        [ 1.2151,  1.2530,  1.3197,  1.2975,  1.2612,  1.2218,  1.1902,  1.2117,
          1.2117,  1.1849,  1.3136,  1.2020,  1.3514,  1.2645,  1.4113,  1.1919,
          1.2423,  1.2682,  1.2782,  1.2632,  1.3284,  1.2957,  1.2411,  1.2344,
          1.1293,  1.2238,  1.2238,  1.2932,  1.3402,  1.2415,  1.0224,  1.2491,
          1.1230,  1.3012,  1.1153,  1.2453,  1.2583,  0.9756,  1.2538,  1.2760,
          0.8146,  0.7455,  1.2813,  1.0890,  0.6284,  3.6935,  2.5669,  3.6990,
          2.8623,  2.1608,  1.8301,  3.0043,  3.6064,  1.8057]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 354 : 178.46515986840785
Test loss for epoch 354 : 179.0743349583381
Test Precision for epoch 354 : 0.26153846153846155
Test Recall for epoch 354 : 0.26153846153846155
Test F1 for epoch 354 : 0.26153846153846155


theta for epoch 355 : tensor([[ 2.7630,  2.7960,  2.8722,  3.0132,  2.9751,  2.7685,  2.9508,  2.7602,
          2.7602,  1.2269,  1.2520,  1.2387,  1.2779,  1.2186,  1.3200,  1.2317,
          1.2038,  1.2383,  1.2045,  1.1802,  1.1943,  1.2166,  1.1791,  1.1746,
          1.1923,  1.1674,  1.1674,  1.2111,  1.2569,  1.1885,  1.2133,  1.2569,
          1.1983,  1.2299,  1.1475,  1.1910,  1.3994,  1.4605,  1.4340,  1.4116,
          1.4408,  1.3890,  1.4139,  1.2919,  1.3944,  1.3149,  1.2605,  1.2470,
          1.2252,  1.3079,  1.2462,  1.3504,  1.2079,  1.2215],
        [ 1.1672,  1.1970,  1.2495,  1.2307,  1.2036,  1.1726,  1.1826,  1.1647,
          1.1647,  2.5536,  2.5855,  2.5607,  2.8660,  2.5354,  3.6370,  2.5600,
          2.7942,  3.4548,  1.1838,  1.2080,  1.1780,  1.1979,  1.1931,  1.1878,
          1.2078,  1.1795,  1.1795,  1.2396,  1.1933,  1.1996,  1.2282,  1.2383,
          1.2109,  1.2474,  1.1670,  1.2025,  1.3490,  1.4214,  1.3379,  1.3629,
          1.3981,  1.4115,  1.3143,  1.2211,  1.3422,  1.2768,  1.2636,  1.2480,
          1.2226,  1.2280,  1.2470,  1.2768,  1.2027,  1.2184],
        [ 1.1588,  1.1851,  1.2127,  1.2156,  1.1901,  1.1634,  1.1715,  1.1564,
          1.1564,  1.2316,  1.2571,  1.2435,  1.2835,  1.2231,  1.2727,  1.2364,
          1.1545,  1.2825,  2.7926,  3.0512,  3.0150,  2.8094,  2.7457,  2.7400,
          3.0021,  2.7318,  2.7318,  1.1965,  1.2554,  1.1932,  1.2173,  1.1974,
          1.2032,  1.2354,  1.1971,  1.1958,  1.3963,  1.4589,  1.4302,  1.3196,
          1.4371,  1.4187,  1.4112,  1.2864,  1.3006,  1.3184,  1.2642,  1.2504,
          1.2282,  1.3046,  1.2496,  1.3479,  1.1872,  1.2244],
        [ 1.1622,  1.1892,  1.2174,  1.2206,  1.1945,  1.1669,  1.1755,  1.1598,
          1.1598,  1.2344,  1.2605,  1.2467,  1.2786,  1.2258,  1.2744,  1.2394,
          1.2096,  1.2381,  1.2141,  1.2052,  1.2491,  1.2267,  1.1876,  1.1829,
          1.1799,  1.1754,  1.1754,  3.0662,  2.9783,  2.6981,  2.7453,  3.0643,
          2.7096,  2.9376,  2.7200,  2.7010,  1.3900,  1.4542,  1.4147,  1.3729,
          1.4334,  1.4150,  1.3936,  1.2755,  1.3550,  1.3227,  1.2661,  1.2024,
          1.1809,  1.3155,  1.2512,  1.3598,  1.1409,  1.2254],
        [ 1.7718,  1.3957,  0.6208,  0.9024,  1.2966,  1.7057,  1.5846,  1.8061,
          1.8061,  1.5812,  1.2417,  1.4419,  0.8923,  1.6332,  0.1538,  1.5237,
          1.7964,  0.8040,  1.3022,  1.0029,  0.7618,  1.1245,  1.6467,  1.7095,
          1.5073,  1.8106,  1.8106,  0.8543,  0.8350,  1.7805,  1.5798,  0.8555,
          1.7241,  1.2098,  1.8315,  1.7465, -0.0511, -0.2700, -0.3020, -0.1025,
          0.1234,  0.1893, -0.1601, 21.1739,  1.5483,  0.7224,  1.2809,  1.3433,
          1.5706,  0.9212,  1.5080,  0.3459,  1.6918,  1.7273],
        [ 1.2149,  1.2527,  1.3194,  1.2973,  1.2609,  1.2215,  1.1900,  1.2114,
          1.2114,  1.1845,  1.3133,  1.2017,  1.3511,  1.2642,  1.4111,  1.1916,
          1.2419,  1.2680,  1.2779,  1.2630,  1.3281,  1.2955,  1.2408,  1.2342,
          1.1290,  1.2235,  1.2235,  1.2929,  1.3399,  1.2412,  1.0221,  1.2488,
          1.1227,  1.3010,  1.1150,  1.2450,  1.2577,  0.9750,  1.2533,  1.2754,
          0.8141,  0.7450,  1.2807,  1.0881,  0.6277,  3.6998,  2.5707,  3.7036,
          2.8664,  2.1639,  1.8326,  3.0084,  3.6128,  1.8082]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 355 : 178.45808765250985
Test loss for epoch 355 : 179.06997539921014
Test Precision for epoch 355 : 0.26153846153846155
Test Recall for epoch 355 : 0.26153846153846155
Test F1 for epoch 355 : 0.26153846153846155


theta for epoch 356 : tensor([[ 2.7672,  2.8002,  2.8765,  3.0176,  2.9795,  2.7727,  2.9552,  2.7644,
          2.7644,  1.2266,  1.2516,  1.2383,  1.2775,  1.2183,  1.3197,  1.2314,
          1.2035,  1.2380,  1.2042,  1.1799,  1.1940,  1.2162,  1.1788,  1.1743,
          1.1920,  1.1670,  1.1670,  1.2108,  1.2565,  1.1882,  1.2130,  1.2566,
          1.1980,  1.2296,  1.1472,  1.1907,  1.3994,  1.4605,  1.4340,  1.4116,
          1.4408,  1.3890,  1.4139,  1.2918,  1.3944,  1.3147,  1.2603,  1.2468,
          1.2250,  1.3076,  1.2460,  1.3502,  1.2076,  1.2213],
        [ 1.1668,  1.1965,  1.2490,  1.2303,  1.2032,  1.1722,  1.1822,  1.1643,
          1.1643,  2.5612,  2.5930,  2.5691,  2.8761,  2.5439,  3.6257,  2.5676,
          2.8041,  3.4456,  1.1835,  1.2078,  1.1777,  1.1975,  1.1926,  1.1874,
          1.2074,  1.1791,  1.1791,  1.2393,  1.1930,  1.1992,  1.2278,  1.2381,
          1.2105,  1.2470,  1.1668,  1.2021,  1.3490,  1.4215,  1.3382,  1.3629,
          1.3981,  1.4116,  1.3146,  1.2210,  1.3422,  1.2765,  1.2633,  1.2477,
          1.2223,  1.2278,  1.2467,  1.2766,  1.2024,  1.2180],
        [ 1.1585,  1.1848,  1.2124,  1.2153,  1.1898,  1.1631,  1.1713,  1.1561,
          1.1561,  1.2313,  1.2568,  1.2432,  1.2831,  1.2228,  1.2722,  1.2361,
          1.1540,  1.2820,  2.7968,  3.0563,  3.0195,  2.8137,  2.7495,  2.7437,
          3.0071,  2.7356,  2.7356,  1.1961,  1.2550,  1.1929,  1.2171,  1.1971,
          1.2029,  1.2352,  1.1968,  1.1955,  1.3963,  1.4589,  1.4301,  1.3195,
          1.4371,  1.4187,  1.4112,  1.2863,  1.3005,  1.3182,  1.2640,  1.2503,
          1.2280,  1.3042,  1.2494,  1.3476,  1.1870,  1.2242],
        [ 1.1619,  1.1889,  1.2171,  1.2203,  1.1942,  1.1666,  1.1752,  1.1595,
          1.1595,  1.2341,  1.2602,  1.2463,  1.2780,  1.2254,  1.2739,  1.2391,
          1.2093,  1.2377,  1.2138,  1.2046,  1.2488,  1.2263,  1.1873,  1.1826,
          1.1796,  1.1751,  1.1751,  3.0711,  2.9817,  2.7025,  2.7487,  3.0692,
          2.7139,  2.9410,  2.7249,  2.7054,  1.3899,  1.4541,  1.4143,  1.3728,
          1.4334,  1.4150,  1.3932,  1.2753,  1.3549,  1.3225,  1.2658,  1.2022,
          1.1806,  1.3152,  1.2509,  1.3596,  1.1407,  1.2251],
        [ 1.7726,  1.3965,  0.6219,  0.9034,  1.2975,  1.7065,  1.5855,  1.8069,
          1.8069,  1.5819,  1.2426,  1.4427,  0.8932,  1.6340,  0.1552,  1.5245,
          1.7972,  0.8052,  1.3031,  1.0038,  0.7627,  1.1254,  1.6475,  1.7103,
          1.5082,  1.8114,  1.8114,  0.8553,  0.8360,  1.7812,  1.5806,  0.8564,
          1.7249,  1.2107,  1.8322,  1.7472, -0.0531, -0.2718, -0.3038, -0.1044,
          0.1212,  0.1870, -0.1619, 21.2321,  1.5449,  0.7232,  1.2814,  1.3438,
          1.5711,  0.9219,  1.5085,  0.3469,  1.6922,  1.7276],
        [ 1.2146,  1.2525,  1.3192,  1.2970,  1.2606,  1.2213,  1.1897,  1.2112,
          1.2112,  1.1843,  1.3130,  1.2014,  1.3508,  1.2638,  1.4109,  1.1913,
          1.2416,  1.2679,  1.2776,  1.2627,  1.3279,  1.2952,  1.2405,  1.2339,
          1.1287,  1.2233,  1.2233,  1.2927,  1.3397,  1.2409,  1.0218,  1.2486,
          1.1224,  1.3007,  1.1147,  1.2447,  1.2571,  0.9745,  1.2527,  1.2749,
          0.8135,  0.7445,  1.2801,  1.0873,  0.6271,  3.7061,  2.5746,  3.7083,
          2.8707,  2.1669,  1.8350,  3.0127,  3.6194,  1.8106]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 356 : 178.45112736855015
Test loss for epoch 356 : 179.0656619958669
Test Precision for epoch 356 : 0.26153846153846155
Test Recall for epoch 356 : 0.26153846153846155
Test F1 for epoch 356 : 0.26153846153846155


theta for epoch 357 : tensor([[ 2.7715,  2.8045,  2.8807,  3.0221,  2.9840,  2.7769,  2.9597,  2.7687,
          2.7687,  1.2263,  1.2513,  1.2380,  1.2772,  1.2180,  1.3194,  1.2311,
          1.2032,  1.2378,  1.2039,  1.1796,  1.1936,  1.2159,  1.1785,  1.1740,
          1.1917,  1.1668,  1.1668,  1.2105,  1.2563,  1.1879,  1.2127,  1.2563,
          1.1977,  1.2294,  1.1469,  1.1904,  1.3993,  1.4606,  1.4340,  1.4116,
          1.4408,  1.3890,  1.4139,  1.2917,  1.3944,  1.3145,  1.2601,  1.2467,
          1.2248,  1.3074,  1.2457,  1.3500,  1.2074,  1.2210],
        [ 1.1664,  1.1961,  1.2485,  1.2300,  1.2028,  1.1718,  1.1817,  1.1639,
          1.1639,  2.5687,  2.6005,  2.5774,  2.8861,  2.5524,  3.6149,  2.5752,
          2.8139,  3.4370,  1.1832,  1.2076,  1.1775,  1.1971,  1.1923,  1.1870,
          1.2069,  1.1787,  1.1787,  1.2391,  1.1927,  1.1988,  1.2274,  1.2380,
          1.2101,  1.2465,  1.1666,  1.2017,  1.3491,  1.4215,  1.3385,  1.3629,
          1.3982,  1.4116,  1.3149,  1.2208,  1.3423,  1.2762,  1.2630,  1.2474,
          1.2221,  1.2276,  1.2464,  1.2764,  1.2022,  1.2177],
        [ 1.1582,  1.1845,  1.2120,  1.2151,  1.1896,  1.1628,  1.1710,  1.1558,
          1.1558,  1.2310,  1.2565,  1.2429,  1.2828,  1.2225,  1.2717,  1.2358,
          1.1535,  1.2816,  2.8012,  3.0614,  3.0243,  2.8180,  2.7534,  2.7476,
          3.0122,  2.7394,  2.7394,  1.1958,  1.2545,  1.1926,  1.2168,  1.1967,
          1.2026,  1.2349,  1.1965,  1.1952,  1.3963,  1.4589,  1.4301,  1.3194,
          1.4372,  1.4187,  1.4111,  1.2862,  1.3003,  1.3180,  1.2638,  1.2501,
          1.2278,  1.3038,  1.2492,  1.3472,  1.1867,  1.2240],
        [ 1.1616,  1.1886,  1.2167,  1.2200,  1.1939,  1.1663,  1.1749,  1.1592,
          1.1592,  1.2338,  1.2599,  1.2460,  1.2774,  1.2251,  1.2734,  1.2388,
          1.2090,  1.2372,  1.2135,  1.2040,  1.2485,  1.2260,  1.1871,  1.1824,
          1.1793,  1.1748,  1.1748,  3.0761,  2.9853,  2.7069,  2.7522,  3.0742,
          2.7183,  2.9445,  2.7299,  2.7098,  1.3898,  1.4541,  1.4139,  1.3727,
          1.4334,  1.4149,  1.3928,  1.2751,  1.3548,  1.3223,  1.2656,  1.2020,
          1.1804,  1.3150,  1.2506,  1.3594,  1.1404,  1.2248],
        [ 1.7734,  1.3973,  0.6229,  0.9043,  1.2983,  1.7073,  1.5863,  1.8077,
          1.8077,  1.5827,  1.2434,  1.4435,  0.8942,  1.6347,  0.1565,  1.5253,
          1.7979,  0.8063,  1.3039,  1.0048,  0.7637,  1.1263,  1.6483,  1.7111,
          1.5090,  1.8122,  1.8122,  0.8562,  0.8369,  1.7819,  1.5814,  0.8573,
          1.7256,  1.2115,  1.8329,  1.7480, -0.0550, -0.2735, -0.3055, -0.1063,
          0.1191,  0.1849, -0.1638, 21.2898,  1.5423,  0.7240,  1.2819,  1.3443,
          1.5715,  0.9225,  1.5089,  0.3479,  1.6926,  1.7280],
        [ 1.2143,  1.2522,  1.3190,  1.2968,  1.2604,  1.2210,  1.1894,  1.2109,
          1.2109,  1.1840,  1.3128,  1.2011,  1.3506,  1.2635,  1.4107,  1.1910,
          1.2413,  1.2677,  1.2774,  1.2624,  1.3276,  1.2949,  1.2403,  1.2336,
          1.1284,  1.2230,  1.2230,  1.2924,  1.3395,  1.2406,  1.0216,  1.2483,
          1.1221,  1.3005,  1.1144,  1.2444,  1.2565,  0.9740,  1.2521,  1.2743,
          0.8130,  0.7440,  1.2795,  1.0864,  0.6264,  3.7127,  2.5786,  3.7133,
          2.8750,  2.1699,  1.8374,  3.0170,  3.6261,  1.8130]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 357 : 178.44427539186393
Test loss for epoch 357 : 179.0613452291455
Test Precision for epoch 357 : 0.26153846153846155
Test Recall for epoch 357 : 0.26153846153846155
Test F1 for epoch 357 : 0.26153846153846155


theta for epoch 358 : tensor([[ 2.7758,  2.8089,  2.8851,  3.0267,  2.9886,  2.7813,  2.9643,  2.7730,
          2.7730,  1.2260,  1.2510,  1.2377,  1.2768,  1.2176,  1.3191,  1.2308,
          1.2028,  1.2375,  1.2036,  1.1793,  1.1933,  1.2156,  1.1782,  1.1737,
          1.1914,  1.1665,  1.1665,  1.2102,  1.2560,  1.1876,  1.2124,  1.2560,
          1.1974,  1.2291,  1.1466,  1.1902,  1.3993,  1.4606,  1.4340,  1.4116,
          1.4409,  1.3890,  1.4138,  1.2916,  1.3943,  1.3143,  1.2599,  1.2465,
          1.2246,  1.3072,  1.2455,  1.3498,  1.2072,  1.2208],
        [ 1.1660,  1.1957,  1.2481,  1.2297,  1.2024,  1.1715,  1.1813,  1.1636,
          1.1636,  2.5762,  2.6079,  2.5857,  2.8960,  2.5607,  3.6047,  2.5827,
          2.8236,  3.4290,  1.1829,  1.2074,  1.1772,  1.1968,  1.1919,  1.1867,
          1.2065,  1.1784,  1.1784,  1.2389,  1.1924,  1.1985,  1.2270,  1.2379,
          1.2098,  1.2462,  1.1664,  1.2014,  1.3491,  1.4215,  1.3388,  1.3630,
          1.3983,  1.4117,  1.3152,  1.2207,  1.3423,  1.2759,  1.2628,  1.2472,
          1.2218,  1.2274,  1.2461,  1.2763,  1.2019,  1.2175],
        [ 1.1580,  1.1843,  1.2117,  1.2148,  1.1893,  1.1626,  1.1707,  1.1556,
          1.1556,  1.2307,  1.2561,  1.2426,  1.2825,  1.2222,  1.2713,  1.2356,
          1.1531,  1.2812,  2.8056,  3.0666,  3.0291,  2.8225,  2.7573,  2.7515,
          3.0174,  2.7434,  2.7434,  1.1955,  1.2541,  1.1924,  1.2166,  1.1964,
          1.2024,  1.2347,  1.1963,  1.1950,  1.3963,  1.4589,  1.4301,  1.3193,
          1.4372,  1.4187,  1.4111,  1.2861,  1.3002,  1.3179,  1.2636,  1.2499,
          1.2276,  1.3035,  1.2490,  1.3469,  1.1865,  1.2238],
        [ 1.1613,  1.1883,  1.2164,  1.2197,  1.1936,  1.1661,  1.1746,  1.1589,
          1.1589,  1.2335,  1.2596,  1.2456,  1.2769,  1.2248,  1.2729,  1.2385,
          1.2087,  1.2367,  1.2132,  1.2035,  1.2482,  1.2258,  1.1868,  1.1821,
          1.1790,  1.1746,  1.1746,  3.0812,  2.9890,  2.7113,  2.7558,  3.0794,
          2.7228,  2.9481,  2.7349,  2.7143,  1.3897,  1.4541,  1.4135,  1.3726,
          1.4334,  1.4149,  1.3924,  1.2750,  1.3546,  1.3222,  1.2654,  1.2019,
          1.1801,  1.3148,  1.2504,  1.3592,  1.1401,  1.2246],
        [ 1.7741,  1.3981,  0.6239,  0.9052,  1.2991,  1.7081,  1.5871,  1.8084,
          1.8084,  1.5833,  1.2442,  1.4442,  0.8951,  1.6354,  0.1578,  1.5259,
          1.7986,  0.8073,  1.3047,  1.0057,  0.7647,  1.1272,  1.6491,  1.7119,
          1.5098,  1.8129,  1.8129,  0.8571,  0.8379,  1.7826,  1.5821,  0.8582,
          1.7263,  1.2123,  1.8336,  1.7486, -0.0568, -0.2751, -0.3071, -0.1081,
          0.1172,  0.1828, -0.1655, 21.3469,  1.5403,  0.7247,  1.2824,  1.3447,
          1.5718,  0.9232,  1.5092,  0.3488,  1.6930,  1.7282],
        [ 1.2140,  1.2520,  1.3187,  1.2966,  1.2601,  1.2207,  1.1891,  1.2106,
          1.2106,  1.1837,  1.3125,  1.2008,  1.3503,  1.2632,  1.4105,  1.1908,
          1.2410,  1.2676,  1.2771,  1.2622,  1.3274,  1.2947,  1.2400,  1.2334,
          1.1281,  1.2227,  1.2227,  1.2922,  1.3393,  1.2403,  1.0213,  1.2481,
          1.1218,  1.3002,  1.1141,  1.2441,  1.2559,  0.9735,  1.2515,  1.2737,
          0.8125,  0.7435,  1.2789,  1.0855,  0.6257,  3.7193,  2.5826,  3.7185,
          2.8795,  2.1730,  1.8398,  3.0215,  3.6329,  1.8154]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 358 : 178.43753000586037
Test loss for epoch 358 : 179.05707536429432
Test Precision for epoch 358 : 0.26153846153846155
Test Recall for epoch 358 : 0.26153846153846155
Test F1 for epoch 358 : 0.26153846153846155


theta for epoch 359 : tensor([[ 2.7803,  2.8133,  2.8896,  3.0314,  2.9933,  2.7857,  2.9690,  2.7775,
          2.7775,  1.2257,  1.2507,  1.2374,  1.2765,  1.2174,  1.3188,  1.2305,
          1.2026,  1.2373,  1.2033,  1.1790,  1.1930,  1.2153,  1.1779,  1.1734,
          1.1911,  1.1662,  1.1662,  1.2099,  1.2557,  1.1874,  1.2122,  1.2557,
          1.1972,  1.2288,  1.1464,  1.1899,  1.3993,  1.4606,  1.4339,  1.4116,
          1.4409,  1.3890,  1.4138,  1.2915,  1.3942,  1.3142,  1.2597,  1.2463,
          1.2244,  1.3071,  1.2453,  1.3497,  1.2071,  1.2206],
        [ 1.1657,  1.1953,  1.2478,  1.2294,  1.2020,  1.1711,  1.1809,  1.1632,
          1.1632,  2.5838,  2.6154,  2.5938,  2.9058,  2.5690,  3.5951,  2.5902,
          2.8332,  3.4216,  1.1826,  1.2072,  1.1770,  1.1964,  1.1915,  1.1863,
          1.2061,  1.1780,  1.1780,  1.2387,  1.1922,  1.1981,  1.2266,  1.2378,
          1.2094,  1.2458,  1.1663,  1.2010,  1.3492,  1.4216,  1.3391,  1.3630,
          1.3984,  1.4118,  1.3156,  1.2206,  1.3423,  1.2756,  1.2625,  1.2470,
          1.2216,  1.2273,  1.2458,  1.2762,  1.2017,  1.2172],
        [ 1.1577,  1.1840,  1.2114,  1.2145,  1.1891,  1.1623,  1.1705,  1.1553,
          1.1553,  1.2304,  1.2559,  1.2423,  1.2822,  1.2219,  1.2708,  1.2353,
          1.1526,  1.2808,  2.8102,  3.0719,  3.0340,  2.8270,  2.7613,  2.7555,
          3.0227,  2.7474,  2.7474,  1.1952,  1.2537,  1.1922,  1.2163,  1.1962,
          1.2022,  1.2344,  1.1960,  1.1948,  1.3963,  1.4590,  1.4301,  1.3192,
          1.4373,  1.4187,  1.4111,  1.2860,  1.3000,  1.3178,  1.2635,  1.2498,
          1.2275,  1.3032,  1.2488,  1.3466,  1.1864,  1.2236],
        [ 1.1611,  1.1880,  1.2161,  1.2194,  1.1934,  1.1658,  1.1743,  1.1587,
          1.1587,  1.2332,  1.2593,  1.2454,  1.2763,  1.2245,  1.2724,  1.2382,
          1.2084,  1.2363,  1.2129,  1.2030,  1.2479,  1.2255,  1.1865,  1.1818,
          1.1787,  1.1743,  1.1743,  3.0865,  2.9928,  2.7159,  2.7595,  3.0846,
          2.7273,  2.9518,  2.7401,  2.7188,  1.3897,  1.4540,  1.4131,  1.3725,
          1.4334,  1.4148,  1.3921,  1.2748,  1.3545,  1.3220,  1.2652,  1.2017,
          1.1799,  1.3146,  1.2502,  1.3590,  1.1399,  1.2243],
        [ 1.7748,  1.3989,  0.6249,  0.9061,  1.2999,  1.7088,  1.5878,  1.8091,
          1.8091,  1.5840,  1.2450,  1.4449,  0.8959,  1.6361,  0.1591,  1.5266,
          1.7993,  0.8083,  1.3055,  1.0065,  0.7655,  1.1280,  1.6498,  1.7126,
          1.5106,  1.8136,  1.8136,  0.8580,  0.8387,  1.7832,  1.5828,  0.8590,
          1.7270,  1.2131,  1.8342,  1.7493, -0.0585, -0.2766, -0.3086, -0.1098,
          0.1153,  0.1808, -0.1671, 21.4035,  1.5389,  0.7254,  1.2828,  1.3451,
          1.5721,  0.9237,  1.5096,  0.3496,  1.6933,  1.7285],
        [ 1.2138,  1.2517,  1.3185,  1.2964,  1.2599,  1.2205,  1.1889,  1.2104,
          1.2104,  1.1834,  1.3122,  1.2005,  1.3500,  1.2629,  1.4103,  1.1905,
          1.2407,  1.2675,  1.2769,  1.2619,  1.3271,  1.2944,  1.2397,  1.2331,
          1.1278,  1.2225,  1.2225,  1.2919,  1.3390,  1.2400,  1.0210,  1.2479,
          1.1215,  1.3000,  1.1138,  1.2438,  1.2552,  0.9730,  1.2509,  1.2732,
          0.8120,  0.7430,  1.2783,  1.0846,  0.6250,  3.7261,  2.5867,  3.7238,
          2.8841,  2.1760,  1.8422,  3.0261,  3.6399,  1.8177]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 359 : 178.43088920431248
Test loss for epoch 359 : 179.05284277110167
Test Precision for epoch 359 : 0.26153846153846155
Test Recall for epoch 359 : 0.26153846153846155
Test F1 for epoch 359 : 0.26153846153846155


theta for epoch 360 : tensor([[ 2.7848,  2.8178,  2.8941,  3.0362,  2.9981,  2.7902,  2.9738,  2.7820,
          2.7820,  1.2254,  1.2504,  1.2371,  1.2762,  1.2171,  1.3185,  1.2303,
          1.2023,  1.2370,  1.2030,  1.1787,  1.1927,  1.2151,  1.1777,  1.1732,
          1.1908,  1.1660,  1.1660,  1.2096,  1.2555,  1.1871,  1.2119,  1.2555,
          1.1969,  1.2286,  1.1461,  1.1897,  1.3993,  1.4606,  1.4339,  1.4117,
          1.4410,  1.3891,  1.4138,  1.2915,  1.3942,  1.3141,  1.2596,  1.2462,
          1.2243,  1.3069,  1.2452,  1.3496,  1.2069,  1.2204],
        [ 1.1653,  1.1950,  1.2474,  1.2291,  1.2016,  1.1707,  1.1805,  1.1628,
          1.1628,  2.5913,  2.6228,  2.6019,  2.9155,  2.5771,  3.5860,  2.5977,
          2.8428,  3.4148,  1.1824,  1.2070,  1.1767,  1.1961,  1.1912,  1.1860,
          1.2057,  1.1777,  1.1777,  1.2385,  1.1920,  1.1977,  1.2263,  1.2377,
          1.2090,  1.2454,  1.1661,  1.2007,  1.3493,  1.4216,  1.3394,  1.3631,
          1.3985,  1.4119,  1.3159,  1.2206,  1.3423,  1.2753,  1.2622,  1.2467,
          1.2213,  1.2272,  1.2456,  1.2761,  1.2014,  1.2169],
        [ 1.1575,  1.1838,  1.2111,  1.2143,  1.1888,  1.1621,  1.1702,  1.1551,
          1.1551,  1.2302,  1.2556,  1.2420,  1.2819,  1.2217,  1.2704,  1.2351,
          1.1522,  1.2804,  2.8148,  3.0772,  3.0390,  2.8317,  2.7654,  2.7596,
          3.0280,  2.7515,  2.7515,  1.1949,  1.2534,  1.1919,  1.2161,  1.1959,
          1.2019,  1.2342,  1.1958,  1.1945,  1.3963,  1.4590,  1.4302,  1.3192,
          1.4374,  1.4188,  1.4112,  1.2860,  1.2999,  1.3177,  1.2633,  1.2497,
          1.2273,  1.3029,  1.2486,  1.3463,  1.1862,  1.2234],
        [ 1.1608,  1.1878,  1.2158,  1.2192,  1.1931,  1.1656,  1.1741,  1.1584,
          1.1584,  1.2329,  1.2590,  1.2451,  1.2758,  1.2242,  1.2720,  1.2380,
          1.2082,  1.2359,  1.2127,  1.2025,  1.2476,  1.2252,  1.1863,  1.1816,
          1.1784,  1.1741,  1.1741,  3.0918,  2.9967,  2.7204,  2.7633,  3.0899,
          2.7319,  2.9556,  2.7453,  2.7234,  1.3896,  1.4540,  1.4128,  1.3724,
          1.4334,  1.4148,  1.3917,  1.2747,  1.3543,  1.3219,  1.2650,  1.2016,
          1.1797,  1.3145,  1.2500,  1.3589,  1.1396,  1.2241],
        [ 1.7754,  1.3996,  0.6259,  0.9069,  1.3007,  1.7094,  1.5885,  1.8098,
          1.8098,  1.5846,  1.2457,  1.4456,  0.8968,  1.6367,  0.1603,  1.5273,
          1.7999,  0.8093,  1.3062,  1.0073,  0.7664,  1.1288,  1.6505,  1.7133,
          1.5113,  1.8143,  1.8143,  0.8588,  0.8395,  1.7839,  1.5835,  0.8598,
          1.7276,  1.2138,  1.8348,  1.7499, -0.0602, -0.2781, -0.3101, -0.1115,
          0.1135,  0.1789, -0.1687, 21.4595,  1.5379,  0.7261,  1.2832,  1.3455,
          1.5724,  0.9243,  1.5099,  0.3505,  1.6936,  1.7287],
        [ 1.2135,  1.2515,  1.3183,  1.2961,  1.2597,  1.2202,  1.1886,  1.2101,
          1.2101,  1.1832,  1.3119,  1.2003,  1.3497,  1.2626,  1.4101,  1.1903,
          1.2404,  1.2673,  1.2766,  1.2617,  1.3269,  1.2942,  1.2395,  1.2328,
          1.1276,  1.2222,  1.2222,  1.2917,  1.3388,  1.2397,  1.0207,  1.2477,
          1.1213,  1.2997,  1.1135,  1.2435,  1.2546,  0.9724,  1.2503,  1.2726,
          0.8114,  0.7425,  1.2777,  1.0837,  0.6243,  3.7330,  2.5909,  3.7294,
          2.8888,  2.1791,  1.8446,  3.0308,  3.6470,  1.8201]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 360 : 178.4243523602181
Test loss for epoch 360 : 179.04862635216358
Test Precision for epoch 360 : 0.26153846153846155
Test Recall for epoch 360 : 0.26153846153846155
Test F1 for epoch 360 : 0.26153846153846155


theta for epoch 361 : tensor([[ 2.7893,  2.8224,  2.8987,  3.0411,  3.0029,  2.7948,  2.9787,  2.7865,
          2.7865,  1.2252,  1.2501,  1.2368,  1.2759,  1.2168,  1.3182,  1.2300,
          1.2020,  1.2368,  1.2028,  1.1784,  1.1925,  1.2148,  1.1775,  1.1730,
          1.1906,  1.1658,  1.1658,  1.2094,  1.2552,  1.1869,  1.2117,  1.2552,
          1.1967,  1.2284,  1.1459,  1.1894,  1.3994,  1.4607,  1.4340,  1.4117,
          1.4410,  1.3891,  1.4139,  1.2914,  1.3941,  1.3140,  1.2594,  1.2461,
          1.2241,  1.3068,  1.2450,  1.3495,  1.2068,  1.2203],
        [ 1.1650,  1.1947,  1.2471,  1.2288,  1.2012,  1.1704,  1.1801,  1.1625,
          1.1625,  2.5987,  2.6301,  2.6099,  2.9251,  2.5852,  3.5774,  2.6051,
          2.8522,  3.4084,  1.1822,  1.2068,  1.1765,  1.1958,  1.1909,  1.1857,
          1.2053,  1.1774,  1.1774,  1.2383,  1.1919,  1.1974,  1.2259,  1.2377,
          1.2087,  1.2451,  1.1660,  1.2003,  1.3494,  1.4217,  1.3397,  1.3632,
          1.3986,  1.4121,  1.3163,  1.2205,  1.3423,  1.2751,  1.2620,  1.2465,
          1.2211,  1.2271,  1.2453,  1.2760,  1.2012,  1.2167],
        [ 1.1572,  1.1836,  1.2108,  1.2140,  1.1886,  1.1619,  1.1700,  1.1549,
          1.1549,  1.2299,  1.2553,  1.2418,  1.2816,  1.2214,  1.2699,  1.2348,
          1.1518,  1.2801,  2.8195,  3.0826,  3.0442,  2.8364,  2.7696,  2.7638,
          3.0334,  2.7556,  2.7556,  1.1947,  1.2530,  1.1917,  1.2159,  1.1956,
          1.2017,  1.2340,  1.1956,  1.1943,  1.3964,  1.4591,  1.4302,  1.3192,
          1.4374,  1.4188,  1.4112,  1.2859,  1.2998,  1.3176,  1.2632,  1.2496,
          1.2272,  1.3026,  1.2485,  1.3460,  1.1860,  1.2233],
        [ 1.1606,  1.1875,  1.2155,  1.2189,  1.1929,  1.1653,  1.1738,  1.1582,
          1.1582,  1.2327,  1.2587,  1.2448,  1.2753,  1.2239,  1.2715,  1.2377,
          1.2079,  1.2355,  1.2125,  1.2020,  1.2474,  1.2250,  1.1861,  1.1814,
          1.1781,  1.1739,  1.1739,  3.0972,  3.0007,  2.7250,  2.7671,  3.0954,
          2.7365,  2.9595,  2.7505,  2.7280,  1.3896,  1.4540,  1.4124,  1.3723,
          1.4334,  1.4148,  1.3913,  1.2746,  1.3541,  1.3218,  1.2649,  1.2015,
          1.1796,  1.3143,  1.2498,  1.3588,  1.1394,  1.2239],
        [ 1.7761,  1.4003,  0.6267,  0.9077,  1.3014,  1.7101,  1.5892,  1.8104,
          1.8104,  1.5852,  1.2464,  1.4463,  0.8975,  1.6373,  0.1614,  1.5279,
          1.8005,  0.8102,  1.3069,  1.0081,  0.7672,  1.1295,  1.6511,  1.7139,
          1.5120,  1.8149,  1.8149,  0.8596,  0.8403,  1.7844,  1.5841,  0.8606,
          1.7282,  1.2145,  1.8354,  1.7505, -0.0618, -0.2795, -0.3115, -0.1130,
          0.1118,  0.1771, -0.1702, 21.5151,  1.5372,  0.7267,  1.2835,  1.3459,
          1.5726,  0.9248,  1.5101,  0.3512,  1.6938,  1.7288],
        [ 1.2132,  1.2513,  1.3181,  1.2959,  1.2594,  1.2199,  1.1884,  1.2098,
          1.2098,  1.1829,  1.3117,  1.2000,  1.3494,  1.2623,  1.4099,  1.1900,
          1.2400,  1.2672,  1.2764,  1.2615,  1.3267,  1.2940,  1.2392,  1.2326,
          1.1273,  1.2220,  1.2220,  1.2915,  1.3386,  1.2395,  1.0205,  1.2474,
          1.1210,  1.2995,  1.1132,  1.2432,  1.2540,  0.9719,  1.2497,  1.2720,
          0.8109,  0.7420,  1.2770,  1.0828,  0.6236,  3.7400,  2.5950,  3.7350,
          2.8935,  2.1821,  1.8469,  3.0355,  3.6543,  1.8223]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 361 : 178.41791544091
Test loss for epoch 361 : 179.0444732532667
Test Precision for epoch 361 : 0.26153846153846155
Test Recall for epoch 361 : 0.26153846153846155
Test F1 for epoch 361 : 0.26153846153846155


theta for epoch 362 : tensor([[ 2.7940,  2.8270,  2.9033,  3.0460,  3.0079,  2.7994,  2.9836,  2.7912,
          2.7912,  1.2249,  1.2499,  1.2365,  1.2756,  1.2166,  1.3179,  1.2298,
          1.2018,  1.2366,  1.2025,  1.1782,  1.1922,  1.2146,  1.1772,  1.1727,
          1.1904,  1.1655,  1.1655,  1.2091,  1.2550,  1.1867,  1.2115,  1.2550,
          1.1965,  1.2281,  1.1456,  1.1892,  1.3994,  1.4607,  1.4340,  1.4118,
          1.4411,  1.3892,  1.4139,  1.2914,  1.3940,  1.3139,  1.2593,  1.2460,
          1.2240,  1.3067,  1.2448,  1.3494,  1.2066,  1.2201],
        [ 1.1647,  1.1943,  1.2469,  1.2286,  1.2009,  1.1701,  1.1798,  1.1622,
          1.1622,  2.6061,  2.6374,  2.6178,  2.9345,  2.5932,  3.5694,  2.6125,
          2.8616,  3.4027,  1.1820,  1.2067,  1.1763,  1.1956,  1.1906,  1.1854,
          1.2049,  1.1771,  1.1771,  1.2382,  1.1917,  1.1971,  1.2256,  1.2376,
          1.2084,  1.2447,  1.1658,  1.2000,  1.3495,  1.4218,  1.3401,  1.3633,
          1.3987,  1.4122,  1.3166,  1.2205,  1.3423,  1.2749,  1.2618,  1.2463,
          1.2209,  1.2270,  1.2451,  1.2759,  1.2010,  1.2164],
        [ 1.1570,  1.1834,  1.2106,  1.2138,  1.1884,  1.1617,  1.1698,  1.1547,
          1.1547,  1.2297,  1.2551,  1.2415,  1.2813,  1.2212,  1.2695,  1.2346,
          1.1514,  1.2797,  2.8243,  3.0881,  3.0493,  2.8411,  2.7738,  2.7680,
          3.0388,  2.7598,  2.7598,  1.1944,  1.2526,  1.1916,  1.2157,  1.1954,
          1.2015,  1.2338,  1.1954,  1.1941,  1.3964,  1.4591,  1.4302,  1.3192,
          1.4375,  1.4189,  1.4112,  1.2859,  1.2996,  1.3176,  1.2631,  1.2495,
          1.2271,  1.3023,  1.2484,  1.3458,  1.1859,  1.2231],
        [ 1.1604,  1.1873,  1.2152,  1.2187,  1.1926,  1.1651,  1.1736,  1.1580,
          1.1580,  1.2325,  1.2585,  1.2446,  1.2748,  1.2237,  1.2711,  1.2375,
          1.2077,  1.2351,  1.2123,  1.2016,  1.2472,  1.2248,  1.1859,  1.1812,
          1.1779,  1.1737,  1.1737,  3.1027,  3.0048,  2.7297,  2.7711,  3.1009,
          2.7412,  2.9635,  2.7558,  2.7326,  1.3896,  1.4540,  1.4121,  1.3723,
          1.4334,  1.4148,  1.3910,  1.2746,  1.3539,  1.3217,  1.2647,  1.2014,
          1.1794,  1.3142,  1.2496,  1.3587,  1.1392,  1.2238],
        [ 1.7767,  1.4010,  0.6276,  0.9084,  1.3021,  1.7107,  1.5898,  1.8110,
          1.8110,  1.5858,  1.2471,  1.4469,  0.8983,  1.6379,  0.1625,  1.5286,
          1.8011,  0.8111,  1.3076,  1.0089,  0.7680,  1.1302,  1.6518,  1.7145,
          1.5127,  1.8155,  1.8155,  0.8604,  0.8411,  1.7850,  1.5847,  0.8614,
          1.7288,  1.2152,  1.8359,  1.7511, -0.0633, -0.2808, -0.3128, -0.1145,
          0.1101,  0.1754, -0.1716, 21.5702,  1.5368,  0.7272,  1.2838,  1.3462,
          1.5728,  0.9252,  1.5103,  0.3520,  1.6940,  1.7290],
        [ 1.2130,  1.2510,  1.3179,  1.2957,  1.2592,  1.2197,  1.1882,  1.2096,
          1.2096,  1.1826,  1.3114,  1.1997,  1.3492,  1.2621,  1.4097,  1.1898,
          1.2397,  1.2671,  1.2762,  1.2612,  1.3265,  1.2938,  1.2390,  1.2323,
          1.1271,  1.2217,  1.2217,  1.2912,  1.3384,  1.2392,  1.0202,  1.2472,
          1.1207,  1.2993,  1.1129,  1.2430,  1.2533,  0.9714,  1.2491,  1.2713,
          0.8103,  0.7415,  1.2764,  1.0818,  0.6229,  3.7472,  2.5992,  3.7409,
          2.8984,  2.1851,  1.8491,  3.0404,  3.6616,  1.8246]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 362 : 178.41157864916318
Test loss for epoch 362 : 179.04034165765034
Test Precision for epoch 362 : 0.26153846153846155
Test Recall for epoch 362 : 0.26153846153846155
Test F1 for epoch 362 : 0.26153846153846155


theta for epoch 363 : tensor([[ 2.7986,  2.8317,  2.9080,  3.0510,  3.0129,  2.8041,  2.9886,  2.7958,
          2.7958,  1.2247,  1.2496,  1.2363,  1.2754,  1.2164,  1.3177,  1.2295,
          1.2016,  1.2364,  1.2023,  1.1779,  1.1919,  1.2143,  1.1770,  1.1725,
          1.1901,  1.1653,  1.1653,  1.2089,  1.2548,  1.1865,  1.2113,  1.2548,
          1.1963,  1.2279,  1.1454,  1.1890,  1.3995,  1.4608,  1.4340,  1.4118,
          1.4412,  1.3893,  1.4139,  1.2914,  1.3940,  1.3138,  1.2592,  1.2459,
          1.2239,  1.3066,  1.2447,  1.3493,  1.2065,  1.2200],
        [ 1.1644,  1.1940,  1.2466,  1.2283,  1.2005,  1.1697,  1.1795,  1.1619,
          1.1619,  2.6134,  2.6447,  2.6256,  2.9439,  2.6010,  3.5618,  2.6198,
          2.8709,  3.3974,  1.1818,  1.2065,  1.1761,  1.1953,  1.1903,  1.1851,
          1.2046,  1.1768,  1.1768,  1.2380,  1.1916,  1.1968,  1.2253,  1.2375,
          1.2081,  1.2444,  1.1657,  1.1997,  1.3496,  1.4219,  1.3404,  1.3634,
          1.3989,  1.4124,  1.3170,  1.2205,  1.3423,  1.2748,  1.2616,  1.2462,
          1.2207,  1.2269,  1.2448,  1.2759,  1.2008,  1.2162],
        [ 1.1568,  1.1831,  1.2103,  1.2136,  1.1882,  1.1614,  1.1696,  1.1545,
          1.1545,  1.2295,  1.2549,  1.2413,  1.2811,  1.2210,  1.2691,  1.2344,
          1.1511,  1.2794,  2.8291,  3.0936,  3.0546,  2.8459,  2.7781,  2.7723,
          3.0443,  2.7641,  2.7641,  1.1942,  1.2523,  1.1914,  1.2156,  1.1951,
          1.2013,  1.2336,  1.1952,  1.1940,  1.3965,  1.4592,  1.4303,  1.3192,
          1.4377,  1.4190,  1.4113,  1.2860,  1.2995,  1.3175,  1.2630,  1.2494,
          1.2270,  1.3021,  1.2482,  1.3456,  1.1858,  1.2230],
        [ 1.1602,  1.1871,  1.2150,  1.2185,  1.1924,  1.1649,  1.1734,  1.1578,
          1.1578,  1.2323,  1.2583,  1.2443,  1.2744,  1.2235,  1.2707,  1.2373,
          1.2075,  1.2348,  1.2121,  1.2011,  1.2470,  1.2246,  1.1857,  1.1810,
          1.1777,  1.1735,  1.1735,  3.1083,  3.0089,  2.7343,  2.7751,  3.1065,
          2.7458,  2.9676,  2.7611,  2.7373,  1.3896,  1.4540,  1.4118,  1.3723,
          1.4335,  1.4148,  1.3907,  1.2745,  1.3538,  1.3216,  1.2646,  1.2013,
          1.1793,  1.3141,  1.2495,  1.3586,  1.1391,  1.2236],
        [ 1.7772,  1.4016,  0.6284,  0.9092,  1.3027,  1.7113,  1.5904,  1.8116,
          1.8116,  1.5864,  1.2477,  1.4475,  0.8990,  1.6384,  0.1636,  1.5291,
          1.8017,  0.8120,  1.3082,  1.0096,  0.7688,  1.1309,  1.6523,  1.7151,
          1.5133,  1.8161,  1.8161,  0.8611,  0.8418,  1.7855,  1.5853,  0.8620,
          1.7293,  1.2158,  1.8364,  1.7516, -0.0647, -0.2821, -0.3141, -0.1159,
          0.1086,  0.1738, -0.1730, 21.6248,  1.5366,  0.7277,  1.2841,  1.3464,
          1.5729,  0.9256,  1.5105,  0.3526,  1.6941,  1.7291],
        [ 1.2127,  1.2508,  1.3177,  1.2955,  1.2590,  1.2194,  1.1879,  1.2093,
          1.2093,  1.1824,  1.3112,  1.1995,  1.3489,  1.2618,  1.4096,  1.1895,
          1.2395,  1.2669,  1.2760,  1.2610,  1.3263,  1.2936,  1.2387,  1.2321,
          1.1269,  1.2215,  1.2215,  1.2910,  1.3382,  1.2389,  1.0200,  1.2470,
          1.1205,  1.2991,  1.1126,  1.2427,  1.2526,  0.9708,  1.2484,  1.2707,
          0.8098,  0.7410,  1.2757,  1.0809,  0.6222,  3.7544,  2.6034,  3.7469,
          2.9032,  2.1880,  1.8513,  3.0452,  3.6691,  1.8268]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 363 : 178.40533978678218
Test loss for epoch 363 : 179.03626809610182
Test Precision for epoch 363 : 0.26153846153846155
Test Recall for epoch 363 : 0.26153846153846155
Test F1 for epoch 363 : 0.26153846153846155


theta for epoch 364 : tensor([[ 2.8033,  2.8364,  2.9127,  3.0561,  3.0179,  2.8088,  2.9936,  2.8005,
          2.8005,  1.2245,  1.2494,  1.2361,  1.2751,  1.2161,  1.3174,  1.2293,
          1.2014,  1.2362,  1.2021,  1.1777,  1.1917,  1.2141,  1.1768,  1.1723,
          1.1899,  1.1651,  1.1651,  1.2087,  1.2546,  1.1863,  1.2111,  1.2546,
          1.1961,  1.2277,  1.1452,  1.1888,  1.3995,  1.4608,  1.4341,  1.4119,
          1.4413,  1.3894,  1.4140,  1.2915,  1.3939,  1.3137,  1.2591,  1.2458,
          1.2238,  1.3065,  1.2446,  1.3492,  1.2064,  1.2198],
        [ 1.1642,  1.1938,  1.2464,  1.2280,  1.2002,  1.1694,  1.1792,  1.1616,
          1.1616,  2.6207,  2.6518,  2.6333,  2.9531,  2.6088,  3.5547,  2.6271,
          2.8800,  3.3926,  1.1816,  1.2064,  1.1759,  1.1951,  1.1900,  1.1848,
          1.2043,  1.1765,  1.1765,  1.2379,  1.1915,  1.1965,  1.2250,  1.2375,
          1.2078,  1.2441,  1.1656,  1.1994,  1.3497,  1.4220,  1.3408,  1.3635,
          1.3990,  1.4125,  1.3173,  1.2205,  1.3423,  1.2746,  1.2614,  1.2460,
          1.2205,  1.2269,  1.2446,  1.2759,  1.2006,  1.2160],
        [ 1.1566,  1.1829,  1.2101,  1.2134,  1.1880,  1.1613,  1.1694,  1.1543,
          1.1543,  1.2293,  1.2547,  1.2411,  1.2808,  1.2207,  1.2687,  1.2342,
          1.1507,  1.2791,  2.8340,  3.0991,  3.0599,  2.8508,  2.7824,  2.7766,
          3.0498,  2.7684,  2.7684,  1.1940,  1.2519,  1.1912,  1.2154,  1.1949,
          1.2012,  1.2334,  1.1950,  1.1938,  1.3965,  1.4593,  1.4304,  1.3192,
          1.4378,  1.4191,  1.4113,  1.2860,  1.2994,  1.3175,  1.2629,  1.2494,
          1.2269,  1.3018,  1.2481,  1.3453,  1.1857,  1.2229],
        [ 1.1600,  1.1869,  1.2147,  1.2183,  1.1922,  1.1647,  1.1732,  1.1576,
          1.1576,  1.2320,  1.2580,  1.2441,  1.2739,  1.2233,  1.2702,  1.2371,
          1.2073,  1.2344,  1.2119,  1.2007,  1.2468,  1.2244,  1.1855,  1.1808,
          1.1775,  1.1733,  1.1733,  3.1139,  3.0132,  2.7390,  2.7791,  3.1121,
          2.7505,  2.9717,  2.7664,  2.7420,  1.3896,  1.4541,  1.4115,  1.3722,
          1.4335,  1.4148,  1.3904,  1.2745,  1.3536,  1.3215,  1.2645,  1.2012,
          1.1791,  1.3140,  1.2494,  1.3585,  1.1389,  1.2234],
        [ 1.7778,  1.4022,  0.6292,  0.9099,  1.3034,  1.7119,  1.5910,  1.8121,
          1.8121,  1.5869,  1.2483,  1.4481,  0.8997,  1.6389,  0.1645,  1.5297,
          1.8022,  0.8128,  1.3088,  1.0103,  0.7695,  1.1315,  1.6529,  1.7156,
          1.5139,  1.8166,  1.8166,  0.8618,  0.8425,  1.7860,  1.5858,  0.8627,
          1.7298,  1.2164,  1.8369,  1.7521, -0.0661, -0.2833, -0.3153, -0.1172,
          0.1071,  0.1722, -0.1743, 21.6790,  1.5366,  0.7282,  1.2843,  1.3466,
          1.5730,  0.9260,  1.5107,  0.3533,  1.6942,  1.7291],
        [ 1.2125,  1.2506,  1.3176,  1.2953,  1.2588,  1.2192,  1.1877,  1.2091,
          1.2091,  1.1822,  1.3109,  1.1992,  1.3487,  1.2615,  1.4094,  1.1892,
          1.2392,  1.2668,  1.2758,  1.2608,  1.3261,  1.2934,  1.2385,  1.2319,
          1.1266,  1.2212,  1.2212,  1.2908,  1.3380,  1.2387,  1.0198,  1.2468,
          1.1203,  1.2989,  1.1124,  1.2425,  1.2520,  0.9703,  1.2478,  1.2700,
          0.8092,  0.7404,  1.2751,  1.0799,  0.6216,  3.7618,  2.6076,  3.7530,
          2.9082,  2.1909,  1.8535,  3.0502,  3.6767,  1.8289]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 364 : 178.39919695671392
Test loss for epoch 364 : 179.03223719943418
Test Precision for epoch 364 : 0.26153846153846155
Test Recall for epoch 364 : 0.26153846153846155
Test F1 for epoch 364 : 0.26153846153846155


theta for epoch 365 : tensor([[ 2.8081,  2.8411,  2.9175,  3.0612,  3.0230,  2.8135,  2.9987,  2.8052,
          2.8052,  1.2243,  1.2492,  1.2359,  1.2749,  1.2159,  1.3172,  1.2291,
          1.2012,  1.2361,  1.2019,  1.1775,  1.1915,  1.2139,  1.1766,  1.1721,
          1.1897,  1.1650,  1.1650,  1.2085,  1.2544,  1.1861,  1.2109,  1.2543,
          1.1959,  1.2276,  1.1450,  1.1886,  1.3996,  1.4609,  1.4341,  1.4120,
          1.4414,  1.3895,  1.4140,  1.2915,  1.3939,  1.3137,  1.2590,  1.2457,
          1.2237,  1.3064,  1.2445,  1.3492,  1.2063,  1.2197],
        [ 1.1639,  1.1935,  1.2461,  1.2278,  1.1999,  1.1692,  1.1789,  1.1613,
          1.1613,  2.6280,  2.6590,  2.6409,  2.9623,  2.6164,  3.5482,  2.6343,
          2.8891,  3.3883,  1.1814,  1.2063,  1.1757,  1.1949,  1.1897,  1.1845,
          1.2040,  1.1763,  1.1763,  1.2378,  1.1914,  1.1962,  1.2247,  1.2374,
          1.2075,  1.2438,  1.1655,  1.1992,  1.3498,  1.4221,  1.3411,  1.3636,
          1.3991,  1.4127,  1.3177,  1.2206,  1.3423,  1.2745,  1.2612,  1.2459,
          1.2203,  1.2269,  1.2444,  1.2759,  1.2005,  1.2158],
        [ 1.1565,  1.1828,  1.2099,  1.2132,  1.1878,  1.1611,  1.1692,  1.1541,
          1.1541,  1.2291,  1.2545,  1.2409,  1.2806,  1.2206,  1.2683,  1.2340,
          1.1504,  1.2788,  2.8389,  3.1046,  3.0652,  2.8557,  2.7867,  2.7809,
          3.0554,  2.7727,  2.7727,  1.1937,  1.2516,  1.1910,  1.2152,  1.1947,
          1.2010,  1.2333,  1.1948,  1.1936,  1.3966,  1.4594,  1.4304,  1.3192,
          1.4379,  1.4192,  1.4114,  1.2861,  1.2994,  1.3174,  1.2629,  1.2493,
          1.2268,  1.3016,  1.2481,  1.3452,  1.1856,  1.2228],
        [ 1.1598,  1.1867,  1.2145,  1.2181,  1.1921,  1.1645,  1.1731,  1.1574,
          1.1574,  1.2319,  1.2578,  1.2439,  1.2735,  1.2231,  1.2699,  1.2369,
          1.2071,  1.2341,  1.2117,  1.2003,  1.2466,  1.2242,  1.1853,  1.1806,
          1.1773,  1.1731,  1.1731,  3.1196,  3.0175,  2.7437,  2.7832,  3.1179,
          2.7552,  2.9759,  2.7718,  2.7467,  1.3896,  1.4541,  1.4112,  1.3722,
          1.4336,  1.4148,  1.3902,  1.2745,  1.3535,  1.3215,  1.2644,  1.2012,
          1.1790,  1.3139,  1.2492,  1.3585,  1.1388,  1.2233],
        [ 1.7783,  1.4028,  0.6299,  0.9105,  1.3039,  1.7124,  1.5915,  1.8126,
          1.8126,  1.5875,  1.2489,  1.4487,  0.9004,  1.6395,  0.1655,  1.5302,
          1.8027,  0.8136,  1.3094,  1.0110,  0.7702,  1.1321,  1.6534,  1.7161,
          1.5145,  1.8171,  1.8171,  0.8624,  0.8431,  1.7865,  1.5863,  0.8634,
          1.7303,  1.2170,  1.8373,  1.7526, -0.0674, -0.2845, -0.3165, -0.1185,
          0.1057,  0.1708, -0.1755, 21.7327,  1.5367,  0.7287,  1.2845,  1.3468,
          1.5731,  0.9264,  1.5108,  0.3539,  1.6943,  1.7291],
        [ 1.2123,  1.2504,  1.3174,  1.2952,  1.2586,  1.2190,  1.1875,  1.2089,
          1.2089,  1.1819,  1.3107,  1.1990,  1.3485,  1.2613,  1.4093,  1.1890,
          1.2389,  1.2667,  1.2756,  1.2606,  1.3259,  1.2932,  1.2383,  1.2316,
          1.1264,  1.2210,  1.2210,  1.2907,  1.3378,  1.2384,  1.0196,  1.2466,
          1.1200,  1.2987,  1.1121,  1.2422,  1.2513,  0.9697,  1.2471,  1.2694,
          0.8087,  0.7399,  1.2744,  1.0790,  0.6209,  3.7692,  2.6118,  3.7593,
          2.9131,  2.1938,  1.8556,  3.0552,  3.6843,  1.8310]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 365 : 178.3931485176313
Test loss for epoch 365 : 179.02825545869587
Test Precision for epoch 365 : 0.26153846153846155
Test Recall for epoch 365 : 0.26153846153846155
Test F1 for epoch 365 : 0.26153846153846155


theta for epoch 366 : tensor([[ 2.8128,  2.8459,  2.9223,  3.0663,  3.0281,  2.8183,  3.0038,  2.8100,
          2.8100,  1.2241,  1.2490,  1.2357,  1.2746,  1.2158,  1.3170,  1.2289,
          1.2010,  1.2359,  1.2017,  1.1773,  1.1913,  1.2138,  1.1765,  1.1720,
          1.1896,  1.1648,  1.1648,  1.2083,  1.2542,  1.1859,  1.2108,  1.2541,
          1.1957,  1.2274,  1.1448,  1.1885,  1.3997,  1.4610,  1.4342,  1.4121,
          1.4415,  1.3896,  1.4141,  1.2916,  1.3939,  1.3137,  1.2590,  1.2457,
          1.2236,  1.3064,  1.2444,  1.3491,  1.2063,  1.2196],
        [ 1.1637,  1.1932,  1.2459,  1.2276,  1.1996,  1.1689,  1.1786,  1.1610,
          1.1610,  2.6351,  2.6660,  2.6483,  2.9713,  2.6239,  3.5420,  2.6414,
          2.8981,  3.3844,  1.1813,  1.2061,  1.1755,  1.1948,  1.1894,  1.1843,
          1.2038,  1.1760,  1.1760,  1.2377,  1.1913,  1.1960,  1.2245,  1.2374,
          1.2072,  1.2436,  1.1654,  1.1989,  1.3500,  1.4223,  1.3415,  1.3637,
          1.3993,  1.4128,  1.3180,  1.2207,  1.3424,  1.2744,  1.2611,  1.2457,
          1.2202,  1.2269,  1.2443,  1.2759,  1.2003,  1.2156],
        [ 1.1563,  1.1826,  1.2096,  1.2130,  1.1876,  1.1609,  1.1691,  1.1539,
          1.1539,  1.2289,  1.2543,  1.2407,  1.2804,  1.2204,  1.2680,  1.2338,
          1.1500,  1.2785,  2.8438,  3.1102,  3.0707,  2.8606,  2.7910,  2.7853,
          3.0609,  2.7771,  2.7771,  1.1935,  1.2513,  1.1909,  1.2151,  1.1945,
          1.2009,  1.2331,  1.1947,  1.1935,  1.3967,  1.4595,  1.4305,  1.3192,
          1.4380,  1.4193,  1.4115,  1.2861,  1.2993,  1.3174,  1.2628,  1.2493,
          1.2267,  1.3014,  1.2480,  1.3450,  1.1855,  1.2227],
        [ 1.1597,  1.1866,  1.2143,  1.2179,  1.1919,  1.1644,  1.1729,  1.1572,
          1.1572,  1.2317,  1.2576,  1.2437,  1.2731,  1.2230,  1.2695,  1.2367,
          1.2070,  1.2337,  1.2115,  1.1999,  1.2464,  1.2241,  1.1852,  1.1805,
          1.1771,  1.1730,  1.1730,  3.1254,  3.0218,  2.7484,  2.7873,  3.1236,
          2.7599,  2.9802,  2.7772,  2.7514,  1.3897,  1.4542,  1.4110,  1.3722,
          1.4337,  1.4149,  1.3899,  1.2745,  1.3534,  1.3214,  1.2643,  1.2011,
          1.1789,  1.3139,  1.2491,  1.3584,  1.1386,  1.2232],
        [ 1.7787,  1.4033,  0.6306,  0.9111,  1.3045,  1.7129,  1.5920,  1.8131,
          1.8131,  1.5880,  1.2495,  1.4492,  0.9011,  1.6399,  0.1664,  1.5307,
          1.8031,  0.8143,  1.3099,  1.0116,  0.7708,  1.1327,  1.6539,  1.7166,
          1.5150,  1.8176,  1.8176,  0.8631,  0.8438,  1.7869,  1.5868,  0.8640,
          1.7308,  1.2176,  1.8377,  1.7530, -0.0686, -0.2855, -0.3176, -0.1197,
          0.1044,  0.1694, -0.1767, 21.7859,  1.5368,  0.7291,  1.2847,  1.3470,
          1.5731,  0.9267,  1.5109,  0.3544,  1.6943,  1.7291],
        [ 1.2121,  1.2502,  1.3172,  1.2950,  1.2584,  1.2188,  1.1873,  1.2086,
          1.2086,  1.1817,  1.3104,  1.1988,  1.3482,  1.2610,  1.4091,  1.1888,
          1.2386,  1.2666,  1.2754,  1.2604,  1.3257,  1.2931,  1.2381,  1.2314,
          1.1262,  1.2207,  1.2207,  1.2905,  1.3377,  1.2382,  1.0194,  1.2465,
          1.1198,  1.2985,  1.1119,  1.2420,  1.2506,  0.9691,  1.2465,  1.2687,
          0.8081,  0.7393,  1.2737,  1.0780,  0.6202,  3.7768,  2.6160,  3.7657,
          2.9181,  2.1966,  1.8576,  3.0602,  3.6921,  1.8330]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 366 : 178.38719182860737
Test loss for epoch 366 : 179.0243291044701
Test Precision for epoch 366 : 0.26153846153846155
Test Recall for epoch 366 : 0.26153846153846155
Test F1 for epoch 366 : 0.26153846153846155


theta for epoch 367 : tensor([[ 2.8176,  2.8507,  2.9271,  3.0715,  3.0333,  2.8230,  3.0090,  2.8148,
          2.8148,  1.2240,  1.2488,  1.2355,  1.2744,  1.2156,  1.3168,  1.2287,
          1.2008,  1.2357,  1.2016,  1.1771,  1.1911,  1.2136,  1.1763,  1.1718,
          1.1894,  1.1646,  1.1646,  1.2081,  1.2540,  1.1858,  1.2106,  1.2540,
          1.1956,  1.2272,  1.1447,  1.1883,  1.3998,  1.4611,  1.4343,  1.4122,
          1.4417,  1.3897,  1.4142,  1.2917,  1.3939,  1.3137,  1.2589,  1.2457,
          1.2235,  1.3064,  1.2444,  1.3491,  1.2062,  1.2196],
        [ 1.1635,  1.1930,  1.2457,  1.2273,  1.1994,  1.1686,  1.1784,  1.1608,
          1.1608,  2.6422,  2.6730,  2.6557,  2.9801,  2.6313,  3.5363,  2.6484,
          2.9069,  3.3810,  1.1812,  1.2060,  1.1753,  1.1947,  1.1892,  1.1840,
          1.2035,  1.1758,  1.1758,  1.2376,  1.1912,  1.1957,  1.2242,  1.2373,
          1.2070,  1.2433,  1.1654,  1.1987,  1.3501,  1.4224,  1.3418,  1.3638,
          1.3995,  1.4130,  1.3184,  1.2208,  1.3424,  1.2743,  1.2609,  1.2456,
          1.2200,  1.2270,  1.2441,  1.2759,  1.2002,  1.2154],
        [ 1.1562,  1.1824,  1.2094,  1.2128,  1.1874,  1.1608,  1.1689,  1.1538,
          1.1538,  1.2288,  1.2541,  1.2405,  1.2802,  1.2202,  1.2676,  1.2336,
          1.1497,  1.2782,  2.8488,  3.1158,  3.0761,  2.8656,  2.7954,  2.7896,
          3.0665,  2.7814,  2.7814,  1.1934,  1.2510,  1.1908,  1.2150,  1.1943,
          1.2007,  1.2330,  1.1945,  1.1933,  1.3968,  1.4596,  1.4306,  1.3193,
          1.4382,  1.4194,  1.4116,  1.2862,  1.2993,  1.3174,  1.2628,  1.2493,
          1.2267,  1.3013,  1.2479,  1.3448,  1.1855,  1.2226],
        [ 1.1595,  1.1864,  1.2140,  1.2177,  1.1917,  1.1642,  1.1728,  1.1571,
          1.1571,  1.2315,  1.2574,  1.2436,  1.2727,  1.2228,  1.2691,  1.2365,
          1.2068,  1.2334,  1.2114,  1.1996,  1.2462,  1.2239,  1.1850,  1.1803,
          1.1769,  1.1729,  1.1729,  3.1312,  3.0262,  2.7531,  2.7915,  3.1294,
          2.7646,  2.9845,  2.7826,  2.7561,  1.3897,  1.4543,  1.4108,  1.3722,
          1.4338,  1.4150,  1.3897,  1.2746,  1.3532,  1.3214,  1.2643,  1.2011,
          1.1789,  1.3138,  1.2491,  1.3584,  1.1385,  1.2231],
        [ 1.7792,  1.4039,  0.6313,  0.9118,  1.3051,  1.7134,  1.5925,  1.8136,
          1.8136,  1.5885,  1.2500,  1.4497,  0.9017,  1.6404,  0.1673,  1.5312,
          1.8036,  0.8151,  1.3105,  1.0122,  0.7715,  1.1333,  1.6544,  1.7171,
          1.5156,  1.8180,  1.8180,  0.8637,  0.8444,  1.7873,  1.5873,  0.8646,
          1.7312,  1.2181,  1.8381,  1.7534, -0.0698, -0.2866, -0.3186, -0.1209,
          0.1031,  0.1681, -0.1778, 21.8388,  1.5368,  0.7295,  1.2848,  1.3471,
          1.5732,  0.9270,  1.5109,  0.3549,  1.6943,  1.7291],
        [ 1.2119,  1.2500,  1.3170,  1.2948,  1.2582,  1.2185,  1.1871,  1.2084,
          1.2084,  1.1815,  1.3102,  1.1985,  1.3480,  1.2608,  1.4090,  1.1885,
          1.2384,  1.2664,  1.2752,  1.2603,  1.3255,  1.2929,  1.2379,  1.2312,
          1.1260,  1.2205,  1.2205,  1.2903,  1.3375,  1.2379,  1.0192,  1.2463,
          1.1196,  1.2983,  1.1116,  1.2417,  1.2498,  0.9686,  1.2458,  1.2680,
          0.8075,  0.7388,  1.2730,  1.0770,  0.6195,  3.7844,  2.6202,  3.7722,
          2.9232,  2.1993,  1.8595,  3.0652,  3.6999,  1.8349]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 367 : 178.3813253939673
Test loss for epoch 367 : 179.02044246389525
Test Precision for epoch 367 : 0.26153846153846155
Test Recall for epoch 367 : 0.26153846153846155
Test F1 for epoch 367 : 0.26153846153846155


theta for epoch 368 : tensor([[ 2.8224,  2.8555,  2.9318,  3.0767,  3.0385,  2.8278,  3.0142,  2.8195,
          2.8195,  1.2238,  1.2486,  1.2353,  1.2742,  1.2154,  1.3166,  1.2286,
          1.2007,  1.2356,  1.2014,  1.1769,  1.1909,  1.2134,  1.1761,  1.1717,
          1.1893,  1.1645,  1.1645,  1.2079,  1.2538,  1.1857,  1.2105,  1.2538,
          1.1954,  1.2271,  1.1445,  1.1882,  1.3999,  1.4612,  1.4344,  1.4123,
          1.4418,  1.3899,  1.4143,  1.2918,  1.3939,  1.3137,  1.2589,  1.2457,
          1.2235,  1.3063,  1.2443,  1.3491,  1.2062,  1.2195],
        [ 1.1632,  1.1928,  1.2455,  1.2271,  1.1991,  1.1684,  1.1782,  1.1605,
          1.1605,  2.6492,  2.6799,  2.6629,  2.9889,  2.6386,  3.5311,  2.6554,
          2.9156,  3.3780,  1.1810,  1.2059,  1.1751,  1.1945,  1.1889,  1.1838,
          1.2033,  1.1755,  1.1755,  1.2375,  1.1911,  1.1955,  1.2240,  1.2373,
          1.2067,  1.2431,  1.1653,  1.1984,  1.3502,  1.4225,  1.3422,  1.3640,
          1.3996,  1.4132,  1.3187,  1.2209,  1.3425,  1.2742,  1.2608,  1.2455,
          1.2199,  1.2270,  1.2440,  1.2760,  1.2000,  1.2152],
        [ 1.1560,  1.1823,  1.2092,  1.2127,  1.1873,  1.1606,  1.1688,  1.1537,
          1.1537,  1.2286,  1.2539,  1.2404,  1.2800,  1.2201,  1.2673,  1.2335,
          1.1495,  1.2779,  2.8538,  3.1214,  3.0816,  2.8706,  2.7998,  2.7940,
          3.0721,  2.7858,  2.7858,  1.1932,  1.2507,  1.1906,  1.2148,  1.1941,
          1.2006,  1.2328,  1.1944,  1.1932,  1.3969,  1.4597,  1.4307,  1.3193,
          1.4383,  1.4196,  1.4117,  1.2863,  1.2994,  1.3174,  1.2627,  1.2493,
          1.2266,  1.3011,  1.2479,  1.3447,  1.1854,  1.2226],
        [ 1.1594,  1.1863,  1.2138,  1.2176,  1.1916,  1.1641,  1.1726,  1.1570,
          1.1570,  1.2314,  1.2573,  1.2434,  1.2724,  1.2227,  1.2688,  1.2364,
          1.2067,  1.2331,  1.2112,  1.1992,  1.2461,  1.2238,  1.1849,  1.1802,
          1.1768,  1.1727,  1.1727,  3.1370,  3.0306,  2.7578,  2.7957,  3.1353,
          2.7693,  2.9888,  2.7879,  2.7607,  1.3898,  1.4543,  1.4105,  1.3723,
          1.4339,  1.4150,  1.3895,  1.2747,  1.3532,  1.3214,  1.2642,  1.2010,
          1.1788,  1.3138,  1.2490,  1.3584,  1.1384,  1.2230],
        [ 1.7796,  1.4044,  0.6320,  0.9123,  1.3056,  1.7138,  1.5930,  1.8140,
          1.8140,  1.5889,  1.2506,  1.4502,  0.9023,  1.6408,  0.1681,  1.5317,
          1.8040,  0.8158,  1.3109,  1.0128,  0.7721,  1.1338,  1.6548,  1.7175,
          1.5160,  1.8184,  1.8184,  0.8643,  0.8449,  1.7877,  1.5877,  0.8651,
          1.7316,  1.2186,  1.8385,  1.7538, -0.0709, -0.2876, -0.3196, -0.1220,
          0.1019,  0.1668, -0.1789, 21.8912,  1.5369,  0.7298,  1.2849,  1.3472,
          1.5731,  0.9272,  1.5109,  0.3554,  1.6943,  1.7290],
        [ 1.2117,  1.2498,  1.3169,  1.2946,  1.2580,  1.2183,  1.1869,  1.2082,
          1.2082,  1.1813,  1.3100,  1.1983,  1.3478,  1.2606,  1.4089,  1.1883,
          1.2381,  1.2663,  1.2750,  1.2601,  1.3254,  1.2927,  1.2376,  1.2310,
          1.1258,  1.2203,  1.2203,  1.2901,  1.3373,  1.2377,  1.0190,  1.2461,
          1.1194,  1.2982,  1.1114,  1.2415,  1.2491,  0.9680,  1.2451,  1.2673,
          0.8069,  0.7382,  1.2723,  1.0760,  0.6189,  3.7921,  2.6243,  3.7789,
          2.9282,  2.2020,  1.8614,  3.0703,  3.7078,  1.8368]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 368 : 178.37554788298178
Test loss for epoch 368 : 179.01662377600792
Test Precision for epoch 368 : 0.26153846153846155
Test Recall for epoch 368 : 0.26153846153846155
Test F1 for epoch 368 : 0.26153846153846155


theta for epoch 369 : tensor([[ 2.8271,  2.8602,  2.9366,  3.0819,  3.0437,  2.8326,  3.0194,  2.8243,
          2.8243,  1.2237,  1.2484,  1.2351,  1.2740,  1.2153,  1.3164,  1.2284,
          1.2005,  1.2354,  1.2012,  1.1768,  1.1907,  1.2133,  1.1760,  1.1715,
          1.1891,  1.1643,  1.1643,  1.2078,  1.2537,  1.1855,  1.2103,  1.2536,
          1.1953,  1.2270,  1.1444,  1.1881,  1.4000,  1.4614,  1.4345,  1.4124,
          1.4420,  1.3900,  1.4144,  1.2919,  1.3940,  1.3137,  1.2589,  1.2457,
          1.2235,  1.3063,  1.2443,  1.3491,  1.2061,  1.2194],
        [ 1.1630,  1.1925,  1.2453,  1.2268,  1.1989,  1.1682,  1.1780,  1.1603,
          1.1603,  2.6561,  2.6867,  2.6700,  2.9975,  2.6457,  3.5262,  2.6622,
          2.9242,  3.3754,  1.1809,  1.2059,  1.1750,  1.1944,  1.1887,  1.1836,
          1.2031,  1.1753,  1.1753,  1.2374,  1.1910,  1.1953,  1.2238,  1.2372,
          1.2065,  1.2428,  1.1652,  1.1982,  1.3504,  1.4226,  1.3425,  1.3641,
          1.3998,  1.4134,  1.3191,  1.2211,  1.3426,  1.2741,  1.2607,  1.2454,
          1.2197,  1.2270,  1.2438,  1.2760,  1.1999,  1.2151],
        [ 1.1559,  1.1821,  1.2090,  1.2125,  1.1871,  1.1605,  1.1686,  1.1535,
          1.1535,  1.2285,  1.2537,  1.2402,  1.2798,  1.2200,  1.2670,  1.2333,
          1.1492,  1.2776,  2.8587,  3.1270,  3.0871,  2.8755,  2.8042,  2.7984,
          3.0777,  2.7902,  2.7902,  1.1930,  1.2504,  1.1905,  1.2147,  1.1939,
          1.2005,  1.2327,  1.1943,  1.1931,  1.3971,  1.4598,  1.4309,  1.3194,
          1.4385,  1.4197,  1.4118,  1.2865,  1.2994,  1.3175,  1.2627,  1.2493,
          1.2266,  1.3009,  1.2479,  1.3445,  1.1854,  1.2225],
        [ 1.1593,  1.1861,  1.2137,  1.2174,  1.1915,  1.1640,  1.1725,  1.1568,
          1.1568,  1.2313,  1.2571,  1.2433,  1.2720,  1.2225,  1.2685,  1.2363,
          1.2066,  1.2329,  1.2111,  1.1989,  1.2459,  1.2237,  1.1848,  1.1801,
          1.1766,  1.1726,  1.1726,  3.1428,  3.0351,  2.7625,  2.7999,  3.1412,
          2.7740,  2.9932,  2.7933,  2.7654,  1.3899,  1.4544,  1.4104,  1.3723,
          1.4340,  1.4151,  1.3893,  1.2748,  1.3531,  1.3215,  1.2642,  1.2010,
          1.1788,  1.3138,  1.2490,  1.3585,  1.1383,  1.2230],
        [ 1.7800,  1.4048,  0.6326,  0.9129,  1.3061,  1.7142,  1.5934,  1.8144,
          1.8144,  1.5894,  1.2510,  1.4507,  0.9029,  1.6413,  0.1689,  1.5322,
          1.8044,  0.8165,  1.3114,  1.0133,  0.7727,  1.1343,  1.6552,  1.7179,
          1.5165,  1.8188,  1.8188,  0.8648,  0.8455,  1.7881,  1.5882,  0.8656,
          1.7320,  1.2191,  1.8389,  1.7542, -0.0720, -0.2886, -0.3206, -0.1230,
          0.1008,  0.1657, -0.1799, 21.9432,  1.5368,  0.7301,  1.2849,  1.3472,
          1.5730,  0.9274,  1.5109,  0.3559,  1.6942,  1.7288],
        [ 1.2115,  1.2496,  1.3167,  1.2945,  1.2579,  1.2181,  1.1868,  1.2080,
          1.2080,  1.1811,  1.3098,  1.1981,  1.3476,  1.2603,  1.4087,  1.1881,
          1.2379,  1.2662,  1.2748,  1.2599,  1.3252,  1.2925,  1.2374,  1.2308,
          1.1257,  1.2201,  1.2201,  1.2900,  1.3372,  1.2375,  1.0188,  1.2460,
          1.1191,  1.2980,  1.1112,  1.2413,  1.2484,  0.9674,  1.2444,  1.2665,
          0.8063,  0.7377,  1.2716,  1.0750,  0.6182,  3.7998,  2.6284,  3.7856,
          2.9333,  2.2046,  1.8632,  3.0753,  3.7158,  1.8385]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 369 : 178.3698562874694
Test loss for epoch 369 : 179.01284368204298
Test Precision for epoch 369 : 0.26153846153846155
Test Recall for epoch 369 : 0.26153846153846155
Test F1 for epoch 369 : 0.26153846153846155


theta for epoch 370 : tensor([[ 2.8319,  2.8650,  2.9414,  3.0872,  3.0489,  2.8374,  3.0246,  2.8291,
          2.8291,  1.2235,  1.2482,  1.2350,  1.2738,  1.2151,  1.3162,  1.2283,
          1.2004,  1.2353,  1.2011,  1.1766,  1.1905,  1.2131,  1.1759,  1.1714,
          1.1890,  1.1642,  1.1642,  1.2076,  1.2535,  1.1854,  1.2102,  1.2535,
          1.1952,  1.2268,  1.1442,  1.1879,  1.4001,  1.4615,  1.4346,  1.4125,
          1.4421,  1.3902,  1.4145,  1.2920,  1.3941,  1.3137,  1.2589,  1.2457,
          1.2235,  1.3063,  1.2443,  1.3491,  1.2061,  1.2194],
        [ 1.1629,  1.1923,  1.2452,  1.2266,  1.1987,  1.1679,  1.1778,  1.1601,
          1.1601,  2.6628,  2.6934,  2.6770,  3.0059,  2.6527,  3.5217,  2.6689,
          2.9327,  3.3732,  1.1808,  1.2058,  1.1748,  1.1943,  1.1885,  1.1834,
          1.2029,  1.1751,  1.1751,  1.2374,  1.1909,  1.1951,  1.2236,  1.2371,
          1.2063,  1.2426,  1.1652,  1.1980,  1.3505,  1.4228,  1.3429,  1.3643,
          1.4000,  1.4135,  1.3194,  1.2213,  1.3427,  1.2741,  1.2606,  1.2453,
          1.2196,  1.2271,  1.2437,  1.2761,  1.1998,  1.2150],
        [ 1.1558,  1.1820,  1.2089,  1.2123,  1.1870,  1.1603,  1.1685,  1.1534,
          1.1534,  1.2284,  1.2536,  1.2400,  1.2796,  1.2198,  1.2667,  1.2332,
          1.1489,  1.2774,  2.8637,  3.1325,  3.0926,  2.8805,  2.8086,  2.8028,
          3.0832,  2.7946,  2.7946,  1.1928,  1.2502,  1.1904,  1.2146,  1.1937,
          1.2003,  1.2326,  1.1941,  1.1930,  1.3972,  1.4600,  1.4310,  1.3195,
          1.4387,  1.4199,  1.4119,  1.2866,  1.2995,  1.3175,  1.2627,  1.2493,
          1.2266,  1.3008,  1.2478,  1.3444,  1.1854,  1.2225],
        [ 1.1592,  1.1860,  1.2135,  1.2173,  1.1913,  1.1639,  1.1724,  1.1567,
          1.1567,  1.2312,  1.2570,  1.2431,  1.2717,  1.2224,  1.2682,  1.2361,
          1.2065,  1.2326,  1.2110,  1.1986,  1.2458,  1.2235,  1.1847,  1.1800,
          1.1765,  1.1725,  1.1725,  3.1487,  3.0395,  2.7671,  2.8041,  3.1471,
          2.7786,  2.9976,  2.7987,  2.7701,  1.3899,  1.4546,  1.4102,  1.3723,
          1.4341,  1.4152,  1.3891,  1.2749,  1.3531,  1.3215,  1.2642,  1.2011,
          1.1787,  1.3138,  1.2489,  1.3585,  1.1383,  1.2230],
        [ 1.7804,  1.4053,  0.6332,  0.9134,  1.3066,  1.7146,  1.5939,  1.8148,
          1.8148,  1.5898,  1.2515,  1.4511,  0.9035,  1.6417,  0.1697,  1.5326,
          1.8048,  0.8171,  1.3119,  1.0139,  0.7732,  1.1348,  1.6556,  1.7183,
          1.5170,  1.8192,  1.8192,  0.8653,  0.8460,  1.7885,  1.5886,  0.8662,
          1.7324,  1.2196,  1.8392,  1.7546, -0.0730, -0.2895, -0.3215, -0.1240,
          0.0997,  0.1645, -0.1809, 21.9949,  1.5367,  0.7304,  1.2850,  1.3473,
          1.5729,  0.9276,  1.5109,  0.3563,  1.6941,  1.7287],
        [ 1.2113,  1.2495,  1.3166,  1.2943,  1.2577,  1.2180,  1.1866,  1.2078,
          1.2078,  1.1808,  1.3096,  1.1979,  1.3474,  1.2601,  1.4086,  1.1879,
          1.2376,  1.2661,  1.2746,  1.2597,  1.3251,  1.2924,  1.2373,  1.2306,
          1.1255,  1.2199,  1.2199,  1.2898,  1.3370,  1.2373,  1.0186,  1.2458,
          1.1190,  1.2978,  1.1109,  1.2411,  1.2476,  0.9668,  1.2437,  1.2658,
          0.8057,  0.7371,  1.2708,  1.0740,  0.6175,  3.8076,  2.6324,  3.7924,
          2.9383,  2.2071,  1.8649,  3.0804,  3.7238,  1.8402]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 370 : 178.3642498471109
Test loss for epoch 370 : 179.00912997152534
Test Precision for epoch 370 : 0.26153846153846155
Test Recall for epoch 370 : 0.26153846153846155
Test F1 for epoch 370 : 0.26153846153846155


theta for epoch 371 : tensor([[ 2.8367,  2.8698,  2.9462,  3.0924,  3.0541,  2.8421,  3.0298,  2.8338,
          2.8338,  1.2234,  1.2481,  1.2348,  1.2737,  1.2150,  1.3160,  1.2281,
          1.2003,  1.2351,  1.2010,  1.1765,  1.1903,  1.2130,  1.1758,  1.1713,
          1.1889,  1.1641,  1.1641,  1.2074,  1.2534,  1.1853,  1.2101,  1.2533,
          1.1951,  1.2267,  1.1441,  1.1878,  1.4003,  1.4617,  1.4347,  1.4126,
          1.4423,  1.3903,  1.4146,  1.2922,  1.3942,  1.3137,  1.2589,  1.2457,
          1.2234,  1.3063,  1.2443,  1.3492,  1.2061,  1.2194],
        [ 1.1627,  1.1921,  1.2450,  1.2264,  1.1984,  1.1677,  1.1776,  1.1599,
          1.1599,  2.6695,  2.7000,  2.6838,  3.0143,  2.6596,  3.5177,  2.6756,
          2.9410,  3.3714,  1.1807,  1.2057,  1.1747,  1.1943,  1.1883,  1.1832,
          1.2027,  1.1749,  1.1749,  1.2373,  1.1908,  1.1949,  1.2234,  1.2371,
          1.2061,  1.2424,  1.1651,  1.1978,  1.3506,  1.4229,  1.3432,  1.3644,
          1.4001,  1.4137,  1.3198,  1.2215,  1.3428,  1.2741,  1.2605,  1.2453,
          1.2195,  1.2272,  1.2436,  1.2762,  1.1997,  1.2149],
        [ 1.1557,  1.1819,  1.2087,  1.2122,  1.1869,  1.1602,  1.1684,  1.1533,
          1.1533,  1.2282,  1.2534,  1.2399,  1.2795,  1.2197,  1.2664,  1.2331,
          1.1487,  1.2772,  2.8687,  3.1381,  3.0981,  2.8855,  2.8130,  2.8072,
          3.0888,  2.7990,  2.7990,  1.1927,  1.2499,  1.1903,  1.2145,  1.1936,
          1.2002,  1.2325,  1.1940,  1.1929,  1.3973,  1.4601,  1.4311,  1.3196,
          1.4389,  1.4201,  1.4120,  1.2868,  1.2996,  1.3175,  1.2627,  1.2493,
          1.2266,  1.3007,  1.2478,  1.3443,  1.1854,  1.2225],
        [ 1.1591,  1.1859,  1.2133,  1.2171,  1.1912,  1.1638,  1.1723,  1.1566,
          1.1566,  1.2311,  1.2569,  1.2430,  1.2714,  1.2223,  1.2679,  1.2360,
          1.2064,  1.2324,  1.2109,  1.1983,  1.2456,  1.2234,  1.1846,  1.1799,
          1.1764,  1.1724,  1.1724,  3.1546,  3.0440,  2.7717,  2.8083,  3.1530,
          2.7832,  3.0020,  2.8040,  2.7747,  1.3900,  1.4547,  1.4100,  1.3724,
          1.4343,  1.4153,  1.3890,  1.2750,  1.3531,  1.3215,  1.2642,  1.2011,
          1.1787,  1.3138,  1.2489,  1.3585,  1.1382,  1.2229],
        [ 1.7808,  1.4057,  0.6337,  0.9140,  1.3070,  1.7150,  1.5943,  1.8152,
          1.8152,  1.5902,  1.2520,  1.4516,  0.9040,  1.6421,  0.1704,  1.5330,
          1.8052,  0.8178,  1.3123,  1.0144,  0.7738,  1.1352,  1.6560,  1.7187,
          1.5174,  1.8196,  1.8196,  0.8659,  0.8465,  1.7888,  1.5890,  0.8667,
          1.7327,  1.2200,  1.8395,  1.7549, -0.0740, -0.2904, -0.3224, -0.1250,
          0.0987,  0.1635, -0.1818, 22.0462,  1.5364,  0.7306,  1.2850,  1.3472,
          1.5728,  0.9278,  1.5108,  0.3567,  1.6939,  1.7285],
        [ 1.2111,  1.2493,  1.3165,  1.2942,  1.2576,  1.2178,  1.1864,  1.2076,
          1.2076,  1.1807,  1.3094,  1.1977,  1.3472,  1.2599,  1.4085,  1.1877,
          1.2374,  1.2660,  1.2745,  1.2596,  1.3249,  1.2922,  1.2371,  1.2304,
          1.1253,  1.2197,  1.2197,  1.2897,  1.3369,  1.2371,  1.0184,  1.2457,
          1.1188,  1.2977,  1.1107,  1.2409,  1.2468,  0.9661,  1.2429,  1.2650,
          0.8051,  0.7365,  1.2700,  1.0729,  0.6168,  3.8155,  2.6364,  3.7993,
          2.9433,  2.2095,  1.8666,  3.0855,  3.7319,  1.8418]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 371 : 178.35872523927827
Test loss for epoch 371 : 179.0054614991411
Test Precision for epoch 371 : 0.26153846153846155
Test Recall for epoch 371 : 0.26153846153846155
Test F1 for epoch 371 : 0.26153846153846155


theta for epoch 372 : tensor([[ 2.8414,  2.8745,  2.9509,  3.0976,  3.0593,  2.8469,  3.0351,  2.8386,
          2.8386,  1.2233,  1.2479,  1.2347,  1.2735,  1.2149,  1.3159,  1.2280,
          1.2002,  1.2350,  1.2008,  1.1763,  1.1902,  1.2128,  1.1757,  1.1712,
          1.1888,  1.1640,  1.1640,  1.2073,  1.2532,  1.1852,  1.2100,  1.2532,
          1.1950,  1.2266,  1.1440,  1.1877,  1.4004,  1.4618,  1.4349,  1.4128,
          1.4425,  1.3905,  1.4148,  1.2924,  1.3943,  1.3138,  1.2589,  1.2457,
          1.2235,  1.3064,  1.2443,  1.3492,  1.2061,  1.2194],
        [ 1.1625,  1.1919,  1.2448,  1.2262,  1.1982,  1.1676,  1.1775,  1.1597,
          1.1597,  2.6761,  2.7065,  2.6905,  3.0225,  2.6663,  3.5140,  2.6821,
          2.9493,  3.3699,  1.1806,  1.2057,  1.1745,  1.1942,  1.1881,  1.1830,
          1.2026,  1.1747,  1.1747,  1.2372,  1.1907,  1.1948,  1.2232,  1.2370,
          1.2060,  1.2422,  1.1651,  1.1977,  1.3508,  1.4231,  1.3435,  1.3646,
          1.4003,  1.4139,  1.3201,  1.2217,  1.3430,  1.2740,  1.2604,  1.2452,
          1.2195,  1.2272,  1.2435,  1.2763,  1.1997,  1.2148],
        [ 1.1555,  1.1817,  1.2085,  1.2120,  1.1868,  1.1601,  1.1683,  1.1532,
          1.1532,  1.2281,  1.2533,  1.2398,  1.2793,  1.2196,  1.2661,  1.2329,
          1.1485,  1.2769,  2.8737,  3.1437,  3.1036,  2.8905,  2.8173,  2.8115,
          3.0944,  2.8033,  2.8033,  1.1925,  1.2496,  1.1902,  1.2144,  1.1934,
          1.2001,  1.2324,  1.1939,  1.1928,  1.3975,  1.4603,  1.4313,  1.3197,
          1.4391,  1.4203,  1.4122,  1.2869,  1.2997,  1.3176,  1.2627,  1.2493,
          1.2266,  1.3006,  1.2478,  1.3443,  1.1854,  1.2224],
        [ 1.1590,  1.1858,  1.2131,  1.2170,  1.1911,  1.1637,  1.1722,  1.1565,
          1.1565,  1.2310,  1.2567,  1.2429,  1.2710,  1.2222,  1.2676,  1.2359,
          1.2063,  1.2321,  1.2108,  1.1980,  1.2455,  1.2233,  1.1845,  1.1798,
          1.1763,  1.1723,  1.1723,  3.1605,  3.0485,  2.7763,  2.8125,  3.1589,
          2.7878,  3.0064,  2.8093,  2.7793,  1.3902,  1.4548,  1.4099,  1.3725,
          1.4344,  1.4154,  1.3888,  1.2751,  1.3531,  1.3216,  1.2642,  1.2011,
          1.1787,  1.3139,  1.2489,  1.3586,  1.1382,  1.2229],
        [ 1.7811,  1.4062,  0.6343,  0.9145,  1.3075,  1.7154,  1.5947,  1.8155,
          1.8155,  1.5906,  1.2524,  1.4520,  0.9045,  1.6425,  0.1712,  1.5334,
          1.8055,  0.8184,  1.3127,  1.0149,  0.7743,  1.1357,  1.6564,  1.7190,
          1.5178,  1.8199,  1.8199,  0.8663,  0.8470,  1.7891,  1.5893,  0.8672,
          1.7331,  1.2205,  1.8398,  1.7552, -0.0749, -0.2912, -0.3233, -0.1260,
          0.0977,  0.1624, -0.1827, 22.0971,  1.5360,  0.7309,  1.2850,  1.3472,
          1.5726,  0.9280,  1.5107,  0.3571,  1.6937,  1.7283],
        [ 1.2109,  1.2491,  1.3163,  1.2940,  1.2574,  1.2176,  1.1863,  1.2074,
          1.2074,  1.1804,  1.3092,  1.1975,  1.3471,  1.2597,  1.4084,  1.1875,
          1.2372,  1.2659,  1.2743,  1.2594,  1.3248,  1.2921,  1.2369,  1.2302,
          1.1252,  1.2195,  1.2195,  1.2896,  1.3367,  1.2369,  1.0183,  1.2455,
          1.1186,  1.2975,  1.1105,  1.2407,  1.2460,  0.9655,  1.2421,  1.2642,
          0.8044,  0.7359,  1.2692,  1.0719,  0.6161,  3.8234,  2.6403,  3.8063,
          2.9483,  2.2119,  1.8681,  3.0905,  3.7400,  1.8434]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 372 : 178.35328011900955
Test loss for epoch 372 : 179.00184741574446
Test Precision for epoch 372 : 0.26153846153846155
Test Recall for epoch 372 : 0.26153846153846155
Test F1 for epoch 372 : 0.26153846153846155


theta for epoch 373 : tensor([[ 2.8461,  2.8792,  2.9557,  3.1028,  3.0645,  2.8516,  3.0403,  2.8433,
          2.8433,  1.2231,  1.2478,  1.2346,  1.2733,  1.2148,  1.3157,  1.2279,
          1.2001,  1.2349,  1.2007,  1.1762,  1.1900,  1.2127,  1.1755,  1.1711,
          1.1887,  1.1639,  1.1639,  1.2071,  1.2531,  1.1851,  1.2099,  1.2530,
          1.1949,  1.2265,  1.1439,  1.1876,  1.4006,  1.4620,  1.4350,  1.4129,
          1.4427,  1.3907,  1.4149,  1.2925,  1.3945,  1.3138,  1.2589,  1.2458,
          1.2235,  1.3064,  1.2443,  1.3493,  1.2061,  1.2194],
        [ 1.1623,  1.1917,  1.2446,  1.2259,  1.1980,  1.1674,  1.1773,  1.1596,
          1.1596,  2.6826,  2.7128,  2.6971,  3.0306,  2.6729,  3.5106,  2.6886,
          2.9573,  3.3687,  1.1806,  1.2056,  1.1744,  1.1941,  1.1879,  1.1828,
          1.2024,  1.1746,  1.1746,  1.2372,  1.1906,  1.1946,  1.2231,  1.2370,
          1.2058,  1.2421,  1.1651,  1.1975,  1.3509,  1.4232,  1.3439,  1.3648,
          1.4005,  1.4141,  1.3205,  1.2220,  1.3432,  1.2740,  1.2603,  1.2452,
          1.2194,  1.2273,  1.2435,  1.2763,  1.1996,  1.2147],
        [ 1.1554,  1.1816,  1.2084,  1.2119,  1.1866,  1.1600,  1.1682,  1.1531,
          1.1531,  1.2280,  1.2531,  1.2397,  1.2792,  1.2195,  1.2658,  1.2328,
          1.1483,  1.2767,  2.8786,  3.1492,  3.1092,  2.8954,  2.8217,  2.8159,
          3.0999,  2.8077,  2.8077,  1.1924,  1.2494,  1.1901,  1.2143,  1.1933,
          1.2000,  1.2323,  1.1938,  1.1927,  1.3976,  1.4605,  1.4314,  1.3198,
          1.4393,  1.4205,  1.4123,  1.2871,  1.2999,  1.3177,  1.2628,  1.2494,
          1.2266,  1.3005,  1.2479,  1.3442,  1.1854,  1.2224],
        [ 1.1589,  1.1857,  1.2130,  1.2169,  1.1910,  1.1636,  1.1721,  1.1565,
          1.1565,  1.2309,  1.2566,  1.2428,  1.2708,  1.2221,  1.2673,  1.2358,
          1.2062,  1.2319,  1.2107,  1.1977,  1.2454,  1.2232,  1.1844,  1.1797,
          1.1762,  1.1722,  1.1722,  3.1665,  3.0530,  2.7809,  2.8167,  3.1648,
          2.7924,  3.0109,  2.8146,  2.7838,  1.3903,  1.4550,  1.4098,  1.3725,
          1.4346,  1.4156,  1.3887,  1.2753,  1.3532,  1.3217,  1.2643,  1.2012,
          1.1787,  1.3139,  1.2489,  1.3587,  1.1382,  1.2229],
        [ 1.7815,  1.4066,  0.6348,  0.9149,  1.3079,  1.7158,  1.5950,  1.8159,
          1.8159,  1.5910,  1.2528,  1.4524,  0.9050,  1.6428,  0.1719,  1.5338,
          1.8059,  0.8190,  1.3131,  1.0154,  0.7748,  1.1361,  1.6568,  1.7194,
          1.5183,  1.8202,  1.8202,  0.8668,  0.8475,  1.7894,  1.5897,  0.8677,
          1.7334,  1.2209,  1.8401,  1.7556, -0.0759, -0.2920, -0.3241, -0.1269,
          0.0967,  0.1615, -0.1836, 22.1477,  1.5354,  0.7311,  1.2849,  1.3472,
          1.5725,  0.9281,  1.5106,  0.3574,  1.6935,  1.7281],
        [ 1.2107,  1.2490,  1.3162,  1.2939,  1.2573,  1.2174,  1.1861,  1.2072,
          1.2072,  1.1802,  1.3090,  1.1973,  1.3469,  1.2595,  1.4083,  1.1873,
          1.2370,  1.2658,  1.2742,  1.2593,  1.3246,  1.2919,  1.2367,  1.2300,
          1.1250,  1.2193,  1.2193,  1.2894,  1.3366,  1.2367,  1.0181,  1.2454,
          1.1184,  1.2974,  1.1103,  1.2405,  1.2452,  0.9648,  1.2414,  1.2634,
          0.8038,  0.7352,  1.2684,  1.0708,  0.6154,  3.8313,  2.6442,  3.8134,
          2.9533,  2.2141,  1.8696,  3.0955,  3.7481,  1.8448]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 373 : 178.34791386925428
Test loss for epoch 373 : 178.99829060571443
Test Precision for epoch 373 : 0.26153846153846155
Test Recall for epoch 373 : 0.26153846153846155
Test F1 for epoch 373 : 0.26153846153846155


theta for epoch 374 : tensor([[ 2.8508,  2.8839,  2.9604,  3.1081,  3.0697,  2.8563,  3.0455,  2.8480,
          2.8480,  1.2230,  1.2477,  1.2345,  1.2732,  1.2147,  1.3155,  1.2277,
          1.2000,  1.2348,  1.2006,  1.1761,  1.1899,  1.2126,  1.1754,  1.1710,
          1.1886,  1.1638,  1.1638,  1.2070,  1.2530,  1.1850,  1.2098,  1.2529,
          1.1948,  1.2264,  1.1438,  1.1875,  1.4007,  1.4622,  1.4351,  1.4131,
          1.4429,  1.3909,  1.4151,  1.2927,  1.3947,  1.3139,  1.2589,  1.2458,
          1.2235,  1.3064,  1.2443,  1.3493,  1.2062,  1.2194],
        [ 1.1622,  1.1916,  1.2443,  1.2257,  1.1979,  1.1672,  1.1772,  1.1594,
          1.1594,  2.6890,  2.7191,  2.7035,  3.0385,  2.6794,  3.5076,  2.6949,
          2.9653,  3.3678,  1.1805,  1.2055,  1.1743,  1.1941,  1.1877,  1.1826,
          1.2023,  1.1744,  1.1744,  1.2371,  1.1905,  1.1945,  1.2229,  1.2369,
          1.2057,  1.2419,  1.1651,  1.1974,  1.3511,  1.4234,  1.3442,  1.3649,
          1.4007,  1.4143,  1.3208,  1.2222,  1.3434,  1.2740,  1.2603,  1.2451,
          1.2193,  1.2274,  1.2434,  1.2764,  1.1995,  1.2146],
        [ 1.1554,  1.1815,  1.2082,  1.2118,  1.1865,  1.1599,  1.1681,  1.1530,
          1.1530,  1.2279,  1.2530,  1.2396,  1.2790,  1.2194,  1.2656,  1.2327,
          1.1481,  1.2765,  2.8835,  3.1547,  3.1147,  2.9003,  2.8260,  2.8202,
          3.1054,  2.8120,  2.8120,  1.1922,  1.2491,  1.1900,  1.2143,  1.1931,
          1.1999,  1.2321,  1.1937,  1.1926,  1.3978,  1.4607,  1.4316,  1.3199,
          1.4395,  1.4208,  1.4125,  1.2873,  1.3001,  1.3177,  1.2628,  1.2494,
          1.2266,  1.3004,  1.2479,  1.3441,  1.1854,  1.2225],
        [ 1.1588,  1.1856,  1.2128,  1.2168,  1.1909,  1.1635,  1.1721,  1.1564,
          1.1564,  1.2308,  1.2565,  1.2427,  1.2705,  1.2221,  1.2671,  1.2357,
          1.2062,  1.2317,  1.2106,  1.1974,  1.2453,  1.2231,  1.1843,  1.1796,
          1.1761,  1.1722,  1.1722,  3.1724,  3.0575,  2.7854,  2.8208,  3.1707,
          2.7969,  3.0153,  2.8198,  2.7883,  1.3904,  1.4551,  1.4097,  1.3726,
          1.4348,  1.4157,  1.3886,  1.2755,  1.3533,  1.3217,  1.2643,  1.2012,
          1.1787,  1.3140,  1.2490,  1.3587,  1.1382,  1.2229],
        [ 1.7818,  1.4070,  0.6353,  0.9154,  1.3083,  1.7161,  1.5954,  1.8162,
          1.8162,  1.5913,  1.2533,  1.4528,  0.9055,  1.6432,  0.1726,  1.5342,
          1.8062,  0.8196,  1.3135,  1.0159,  0.7753,  1.1365,  1.6571,  1.7197,
          1.5187,  1.8205,  1.8205,  0.8673,  0.8480,  1.7897,  1.5901,  0.8681,
          1.7337,  1.2213,  1.8404,  1.7559, -0.0768, -0.2929, -0.3250, -0.1277,
          0.0958,  0.1605, -0.1845, 22.1980,  1.5346,  0.7313,  1.2849,  1.3471,
          1.5723,  0.9282,  1.5105,  0.3578,  1.6933,  1.7278],
        [ 1.2106,  1.2489,  1.3161,  1.2938,  1.2571,  1.2173,  1.1860,  1.2071,
          1.2071,  1.1801,  1.3088,  1.1971,  1.3467,  1.2593,  1.4082,  1.1871,
          1.2368,  1.2657,  1.2740,  1.2591,  1.3245,  1.2918,  1.2365,  1.2298,
          1.1248,  1.2191,  1.2191,  1.2893,  1.3365,  1.2365,  1.0180,  1.2453,
          1.1182,  1.2973,  1.1101,  1.2403,  1.2443,  0.9642,  1.2406,  1.2625,
          0.8031,  0.7346,  1.2676,  1.0697,  0.6147,  3.8393,  2.6480,  3.8205,
          2.9583,  2.2163,  1.8710,  3.1005,  3.7563,  1.8462]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 374 : 178.34262425684796
Test loss for epoch 374 : 178.99477832652462
Test Precision for epoch 374 : 0.26153846153846155
Test Recall for epoch 374 : 0.26153846153846155
Test F1 for epoch 374 : 0.26153846153846155


theta for epoch 375 : tensor([[ 2.8555,  2.8886,  2.9650,  3.1133,  3.0749,  2.8609,  3.0507,  2.8526,
          2.8526,  1.2229,  1.2475,  1.2343,  1.2730,  1.2146,  1.3154,  1.2276,
          1.2000,  1.2346,  1.2005,  1.1759,  1.1897,  1.2124,  1.1754,  1.1709,
          1.1885,  1.1637,  1.1637,  1.2069,  1.2528,  1.1849,  1.2097,  1.2528,
          1.1947,  1.2263,  1.1437,  1.1875,  1.4009,  1.4623,  1.4353,  1.4133,
          1.4431,  1.3911,  1.4152,  1.2929,  1.3949,  1.3140,  1.2590,  1.2459,
          1.2235,  1.3065,  1.2443,  1.3494,  1.2062,  1.2194],
        [ 1.1620,  1.1914,  1.2441,  1.2255,  1.1977,  1.1671,  1.1770,  1.1593,
          1.1593,  2.6952,  2.7253,  2.7098,  3.0463,  2.6857,  3.5049,  2.7011,
          2.9732,  3.3673,  1.1804,  1.2055,  1.1742,  1.1940,  1.1876,  1.1825,
          1.2021,  1.1742,  1.1742,  1.2371,  1.1904,  1.1943,  1.2228,  1.2368,
          1.2055,  1.2417,  1.1651,  1.1972,  1.3513,  1.4236,  1.3445,  1.3651,
          1.4009,  1.4146,  1.3211,  1.2225,  1.3436,  1.2740,  1.2603,  1.2451,
          1.2193,  1.2274,  1.2434,  1.2765,  1.1995,  1.2145],
        [ 1.1553,  1.1814,  1.2081,  1.2116,  1.1864,  1.1598,  1.1680,  1.1529,
          1.1529,  1.2278,  1.2529,  1.2394,  1.2789,  1.2193,  1.2653,  1.2326,
          1.1479,  1.2763,  2.8884,  3.1602,  3.1202,  2.9052,  2.8303,  2.8245,
          3.1109,  2.8163,  2.8163,  1.1921,  1.2489,  1.1899,  1.2142,  1.1930,
          1.1999,  1.2320,  1.1936,  1.1925,  1.3980,  1.4608,  1.4318,  1.3200,
          1.4398,  1.4210,  1.4126,  1.2875,  1.3003,  1.3178,  1.2629,  1.2495,
          1.2267,  1.3004,  1.2479,  1.3441,  1.1855,  1.2225],
        [ 1.1588,  1.1855,  1.2127,  1.2167,  1.1909,  1.1634,  1.1720,  1.1563,
          1.1563,  1.2307,  1.2564,  1.2426,  1.2702,  1.2220,  1.2668,  1.2356,
          1.2061,  1.2315,  1.2105,  1.1971,  1.2451,  1.2230,  1.1843,  1.1796,
          1.1760,  1.1721,  1.1721,  3.1783,  3.0620,  2.7898,  2.8250,  3.1766,
          2.8014,  3.0197,  2.8250,  2.7928,  1.3906,  1.4553,  1.4096,  1.3727,
          1.4350,  1.4159,  1.3885,  1.2757,  1.3534,  1.3218,  1.2643,  1.2013,
          1.1788,  1.3140,  1.2490,  1.3588,  1.1382,  1.2229],
        [ 1.7821,  1.4074,  0.6358,  0.9159,  1.3088,  1.7164,  1.5958,  1.8165,
          1.8165,  1.5917,  1.2537,  1.4532,  0.9060,  1.6435,  0.1732,  1.5345,
          1.8066,  0.8201,  1.3139,  1.0163,  0.7758,  1.1370,  1.6575,  1.7200,
          1.5191,  1.8209,  1.8209,  0.8678,  0.8485,  1.7900,  1.5904,  0.8686,
          1.7340,  1.2217,  1.8406,  1.7562, -0.0776, -0.2936, -0.3258, -0.1286,
          0.0949,  0.1596, -0.1853, 22.2479,  1.5337,  0.7315,  1.2848,  1.3470,
          1.5720,  0.9283,  1.5103,  0.3581,  1.6930,  1.7276],
        [ 1.2104,  1.2487,  1.3160,  1.2937,  1.2570,  1.2171,  1.1858,  1.2069,
          1.2069,  1.1799,  1.3086,  1.1969,  1.3466,  1.2590,  1.4081,  1.1869,
          1.2366,  1.2656,  1.2738,  1.2590,  1.3244,  1.2916,  1.2364,  1.2297,
          1.1247,  1.2189,  1.2189,  1.2892,  1.3363,  1.2363,  1.0178,  1.2451,
          1.1181,  1.2971,  1.1099,  1.2401,  1.2435,  0.9635,  1.2398,  1.2617,
          0.8024,  0.7340,  1.2668,  1.0686,  0.6139,  3.8473,  2.6517,  3.8277,
          2.9632,  2.2184,  1.8723,  3.1055,  3.7645,  1.8475]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 375 : 178.33740906364966
Test loss for epoch 375 : 178.991330613669
Test Precision for epoch 375 : 0.26153846153846155
Test Recall for epoch 375 : 0.26153846153846155
Test F1 for epoch 375 : 0.26153846153846155


theta for epoch 376 : tensor([[ 2.8601,  2.8932,  2.9697,  3.1184,  3.0801,  2.8655,  3.0558,  2.8572,
          2.8572,  1.2228,  1.2474,  1.2342,  1.2729,  1.2145,  1.3152,  1.2275,
          1.1999,  1.2345,  1.2004,  1.1758,  1.1896,  1.2123,  1.1753,  1.1708,
          1.1884,  1.1636,  1.1636,  1.2067,  1.2527,  1.1848,  1.2096,  1.2526,
          1.1946,  1.2262,  1.1436,  1.1874,  1.4010,  1.4625,  1.4355,  1.4134,
          1.4433,  1.3913,  1.4154,  1.2931,  1.3951,  1.3141,  1.2591,  1.2460,
          1.2236,  1.3066,  1.2444,  1.3495,  1.2062,  1.2194],
        [ 1.1619,  1.1912,  1.2439,  1.2253,  1.1975,  1.1669,  1.1769,  1.1591,
          1.1591,  2.7013,  2.7314,  2.7160,  3.0539,  2.6919,  3.5025,  2.7072,
          2.9809,  3.3670,  1.1803,  1.2055,  1.1741,  1.1940,  1.1874,  1.1823,
          1.2020,  1.1741,  1.1741,  1.2370,  1.1903,  1.1942,  1.2226,  1.2368,
          1.2054,  1.2416,  1.1651,  1.1971,  1.3514,  1.4237,  1.3448,  1.3653,
          1.4012,  1.4148,  1.3214,  1.2228,  1.3438,  1.2740,  1.2602,  1.2451,
          1.2192,  1.2275,  1.2433,  1.2766,  1.1995,  1.2145],
        [ 1.1552,  1.1813,  1.2079,  1.2115,  1.1863,  1.1597,  1.1679,  1.1528,
          1.1528,  1.2277,  1.2528,  1.2393,  1.2787,  1.2192,  1.2650,  1.2325,
          1.1477,  1.2761,  2.8933,  3.1657,  3.1257,  2.9101,  2.8345,  2.8287,
          3.1163,  2.8205,  2.8205,  1.1920,  1.2487,  1.1899,  1.2141,  1.1928,
          1.1998,  1.2319,  1.1935,  1.1924,  1.3981,  1.4610,  1.4319,  1.3202,
          1.4400,  1.4212,  1.4128,  1.2877,  1.3005,  1.3179,  1.2629,  1.2496,
          1.2267,  1.3003,  1.2480,  1.3441,  1.1855,  1.2225],
        [ 1.1587,  1.1854,  1.2125,  1.2166,  1.1908,  1.1634,  1.1719,  1.1563,
          1.1563,  1.2306,  1.2563,  1.2425,  1.2700,  1.2219,  1.2666,  1.2355,
          1.2061,  1.2313,  1.2104,  1.1969,  1.2450,  1.2229,  1.1842,  1.1795,
          1.1759,  1.1720,  1.1720,  3.1842,  3.0665,  2.7942,  2.8291,  3.1825,
          2.8058,  3.0241,  2.8301,  2.7972,  1.3907,  1.4555,  1.4095,  1.3728,
          1.4352,  1.4161,  1.3885,  1.2759,  1.3536,  1.3219,  1.2644,  1.2014,
          1.1788,  1.3141,  1.2491,  1.3589,  1.1382,  1.2230],
        [ 1.7825,  1.4078,  0.6364,  0.9163,  1.3092,  1.7168,  1.5961,  1.8168,
          1.8168,  1.5920,  1.2541,  1.4536,  0.9065,  1.6439,  0.1739,  1.5349,
          1.8069,  0.8207,  1.3143,  1.0168,  0.7763,  1.1374,  1.6578,  1.7204,
          1.5195,  1.8212,  1.8212,  0.8682,  0.8489,  1.7903,  1.5908,  0.8691,
          1.7344,  1.2221,  1.8409,  1.7565, -0.0785, -0.2944, -0.3266, -0.1295,
          0.0940,  0.1587, -0.1862, 22.2976,  1.5326,  0.7317,  1.2847,  1.3469,
          1.5718,  0.9284,  1.5102,  0.3584,  1.6927,  1.7273],
        [ 1.2102,  1.2486,  1.3158,  1.2936,  1.2569,  1.2169,  1.1857,  1.2067,
          1.2067,  1.1797,  1.3084,  1.1968,  1.3464,  1.2588,  1.4080,  1.1867,
          1.2364,  1.2655,  1.2737,  1.2589,  1.3243,  1.2915,  1.2362,  1.2295,
          1.1245,  1.2187,  1.2187,  1.2890,  1.3362,  1.2361,  1.0177,  1.2450,
          1.1179,  1.2970,  1.1097,  1.2399,  1.2426,  0.9628,  1.2389,  1.2608,
          0.8017,  0.7333,  1.2659,  1.0675,  0.6132,  3.8553,  2.6553,  3.8350,
          2.9680,  2.2204,  1.8735,  3.1104,  3.7728,  1.8486]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 376 : 178.3322658723028
Test loss for epoch 376 : 178.98792135370957
Test Precision for epoch 376 : 0.26153846153846155
Test Recall for epoch 376 : 0.26153846153846155
Test F1 for epoch 376 : 0.26153846153846155


theta for epoch 377 : tensor([[ 2.8647,  2.8978,  2.9743,  3.1236,  3.0852,  2.8701,  3.0610,  2.8618,
          2.8618,  1.2227,  1.2473,  1.2341,  1.2728,  1.2144,  1.3151,  1.2274,
          1.1998,  1.2344,  1.2002,  1.1757,  1.1894,  1.2122,  1.1752,  1.1707,
          1.1883,  1.1635,  1.1635,  1.2066,  1.2526,  1.1848,  1.2095,  1.2525,
          1.1945,  1.2261,  1.1435,  1.1873,  1.4012,  1.4627,  1.4356,  1.4136,
          1.4436,  1.3915,  1.4156,  1.2933,  1.3954,  1.3141,  1.2591,  1.2460,
          1.2236,  1.3066,  1.2444,  1.3496,  1.2063,  1.2195],
        [ 1.1617,  1.1911,  1.2437,  1.2251,  1.1974,  1.1668,  1.1768,  1.1590,
          1.1590,  2.7073,  2.7373,  2.7220,  3.0615,  2.6980,  3.5004,  2.7131,
          2.9884,  3.3670,  1.1803,  1.2054,  1.1739,  1.1939,  1.1873,  1.1822,
          1.2019,  1.1740,  1.1740,  1.2370,  1.1902,  1.1941,  1.2225,  1.2367,
          1.2053,  1.2414,  1.1651,  1.1970,  1.3516,  1.4239,  1.3452,  1.3655,
          1.4014,  1.4150,  1.3218,  1.2231,  1.3441,  1.2740,  1.2602,  1.2451,
          1.2192,  1.2276,  1.2433,  1.2767,  1.1994,  1.2144],
        [ 1.1551,  1.1812,  1.2078,  1.2114,  1.1862,  1.1597,  1.1679,  1.1527,
          1.1527,  1.2276,  1.2527,  1.2392,  1.2786,  1.2191,  1.2648,  1.2324,
          1.1476,  1.2759,  2.8981,  3.1711,  3.1311,  2.9149,  2.8387,  2.8330,
          3.1217,  2.8247,  2.8247,  1.1918,  1.2485,  1.1898,  1.2140,  1.1927,
          1.1997,  1.2318,  1.1935,  1.1924,  1.3983,  1.4612,  1.4321,  1.3203,
          1.4403,  1.4215,  1.4130,  1.2879,  1.3008,  1.3180,  1.2630,  1.2496,
          1.2268,  1.3003,  1.2480,  1.3440,  1.1856,  1.2225],
        [ 1.1586,  1.1854,  1.2124,  1.2165,  1.1907,  1.1633,  1.1719,  1.1562,
          1.1562,  1.2306,  1.2562,  1.2425,  1.2697,  1.2219,  1.2664,  1.2355,
          1.2060,  1.2311,  1.2103,  1.1966,  1.2449,  1.2228,  1.1841,  1.1795,
          1.1758,  1.1720,  1.1720,  3.1900,  3.0710,  2.7986,  2.8332,  3.1884,
          2.8102,  3.0285,  2.8352,  2.8016,  1.3909,  1.4557,  1.4095,  1.3730,
          1.4355,  1.4163,  1.3884,  1.2761,  1.3537,  1.3220,  1.2645,  1.2014,
          1.1788,  1.3142,  1.2491,  1.3590,  1.1382,  1.2230],
        [ 1.7828,  1.4081,  0.6369,  0.9168,  1.3096,  1.7171,  1.5965,  1.8171,
          1.8171,  1.5924,  1.2545,  1.4540,  0.9070,  1.6442,  0.1746,  1.5352,
          1.8072,  0.8213,  1.3147,  1.0173,  0.7767,  1.1378,  1.6581,  1.7207,
          1.5199,  1.8215,  1.8215,  0.8687,  0.8494,  1.7906,  1.5911,  0.8695,
          1.7347,  1.2225,  1.8412,  1.7568, -0.0793, -0.2952, -0.3273, -0.1303,
          0.0932,  0.1578, -0.1870, 22.3469,  1.5313,  0.7318,  1.2846,  1.3467,
          1.5715,  0.9285,  1.5100,  0.3587,  1.6924,  1.7270],
        [ 1.2101,  1.2484,  1.3157,  1.2935,  1.2568,  1.2168,  1.1856,  1.2066,
          1.2066,  1.1795,  1.3083,  1.1966,  1.3463,  1.2586,  1.4079,  1.1865,
          1.2362,  1.2655,  1.2735,  1.2587,  1.3241,  1.2913,  1.2361,  1.2293,
          1.1244,  1.2186,  1.2186,  1.2889,  1.3361,  1.2359,  1.0175,  1.2449,
          1.1177,  1.2969,  1.1095,  1.2397,  1.2417,  0.9621,  1.2381,  1.2599,
          0.8010,  0.7326,  1.2650,  1.0664,  0.6125,  3.8634,  2.6589,  3.8422,
          2.9729,  2.2223,  1.8746,  3.1152,  3.7810,  1.8498]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 377 : 178.32719363350327
Test loss for epoch 377 : 178.98457365883866
Test Precision for epoch 377 : 0.26153846153846155
Test Recall for epoch 377 : 0.26153846153846155
Test F1 for epoch 377 : 0.26153846153846155


theta for epoch 378 : tensor([[ 2.8692,  2.9023,  2.9788,  3.1287,  3.0903,  2.8746,  3.0661,  2.8663,
          2.8663,  1.2226,  1.2472,  1.2340,  1.2726,  1.2143,  1.3149,  1.2273,
          1.1998,  1.2343,  1.2001,  1.1755,  1.1893,  1.2121,  1.1751,  1.1706,
          1.1882,  1.1635,  1.1635,  1.2065,  1.2524,  1.1847,  1.2094,  1.2524,
          1.1944,  1.2260,  1.1434,  1.1872,  1.4014,  1.4630,  1.4358,  1.4138,
          1.4438,  1.3917,  1.4157,  1.2935,  1.3956,  1.3142,  1.2592,  1.2461,
          1.2237,  1.3067,  1.2445,  1.3497,  1.2063,  1.2195],
        [ 1.1616,  1.1909,  1.2435,  1.2249,  1.1972,  1.1667,  1.1766,  1.1589,
          1.1589,  2.7132,  2.7431,  2.7279,  3.0688,  2.7039,  3.4986,  2.7190,
          2.9959,  3.3673,  1.1802,  1.2054,  1.1738,  1.1939,  1.1872,  1.1821,
          1.2018,  1.1738,  1.1738,  1.2369,  1.1901,  1.1940,  1.2224,  1.2367,
          1.2052,  1.2413,  1.1651,  1.1969,  1.3517,  1.4241,  1.3455,  1.3657,
          1.4016,  1.4152,  1.3221,  1.2234,  1.3444,  1.2740,  1.2602,  1.2451,
          1.2192,  1.2277,  1.2433,  1.2768,  1.1994,  1.2144],
        [ 1.1550,  1.1811,  1.2076,  1.2113,  1.1861,  1.1596,  1.1678,  1.1527,
          1.1527,  1.2275,  1.2525,  1.2391,  1.2785,  1.2190,  1.2645,  1.2323,
          1.1474,  1.2757,  2.9029,  3.1764,  3.1365,  2.9197,  2.8429,  2.8371,
          3.1271,  2.8289,  2.8289,  1.1917,  1.2482,  1.1897,  1.2139,  1.1926,
          1.1996,  1.2317,  1.1934,  1.1923,  1.3985,  1.4615,  1.4323,  1.3205,
          1.4405,  1.4217,  1.4131,  1.2881,  1.3011,  1.3181,  1.2630,  1.2497,
          1.2268,  1.3003,  1.2481,  1.3440,  1.1856,  1.2226],
        [ 1.1586,  1.1853,  1.2122,  1.2164,  1.1906,  1.1632,  1.1718,  1.1562,
          1.1562,  1.2305,  1.2561,  1.2424,  1.2695,  1.2218,  1.2661,  1.2354,
          1.2060,  1.2309,  1.2102,  1.1964,  1.2448,  1.2227,  1.1841,  1.1794,
          1.1757,  1.1719,  1.1719,  3.1959,  3.0754,  2.8029,  2.8372,  3.1943,
          2.8145,  3.0329,  2.8403,  2.8059,  1.3911,  1.4559,  1.4095,  1.3731,
          1.4357,  1.4165,  1.3884,  1.2763,  1.3540,  1.3221,  1.2646,  1.2015,
          1.1789,  1.3143,  1.2492,  1.3591,  1.1382,  1.2231],
        [ 1.7831,  1.4085,  0.6374,  0.9172,  1.3100,  1.7174,  1.5969,  1.8174,
          1.8174,  1.5927,  1.2549,  1.4543,  0.9074,  1.6446,  0.1752,  1.5356,
          1.8075,  0.8218,  1.3151,  1.0177,  0.7772,  1.1382,  1.6585,  1.7210,
          1.5202,  1.8218,  1.8218,  0.8691,  0.8498,  1.7909,  1.5915,  0.8700,
          1.7350,  1.2229,  1.8414,  1.7570, -0.0801, -0.2959, -0.3281, -0.1311,
          0.0923,  0.1569, -0.1878, 22.3959,  1.5298,  0.7320,  1.2845,  1.3466,
          1.5713,  0.9286,  1.5098,  0.3590,  1.6921,  1.7267],
        [ 1.2099,  1.2483,  1.3156,  1.2934,  1.2566,  1.2166,  1.1854,  1.2064,
          1.2064,  1.1793,  1.3081,  1.1964,  1.3461,  1.2584,  1.4078,  1.1863,
          1.2360,  1.2654,  1.2734,  1.2586,  1.3240,  1.2912,  1.2359,  1.2292,
          1.1242,  1.2184,  1.2184,  1.2888,  1.3360,  1.2357,  1.0174,  1.2448,
          1.1176,  1.2967,  1.1094,  1.2396,  1.2407,  0.9614,  1.2372,  1.2590,
          0.8003,  0.7320,  1.2641,  1.0652,  0.6117,  3.8714,  2.6624,  3.8496,
          2.9776,  2.2241,  1.8757,  3.1200,  3.7893,  1.8508]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 378 : 178.32219100261784
Test loss for epoch 378 : 178.98126909810549
Test Precision for epoch 378 : 0.26153846153846155
Test Recall for epoch 378 : 0.26153846153846155
Test F1 for epoch 378 : 0.26153846153846155


theta for epoch 379 : tensor([[ 2.8737,  2.9068,  2.9833,  3.1338,  3.0954,  2.8791,  3.0711,  2.8708,
          2.8708,  1.2225,  1.2471,  1.2339,  1.2725,  1.2142,  1.3148,  1.2272,
          1.1997,  1.2342,  1.2000,  1.1754,  1.1892,  1.2119,  1.1750,  1.1705,
          1.1881,  1.1634,  1.1634,  1.2063,  1.2523,  1.1846,  1.2094,  1.2522,
          1.1944,  1.2259,  1.1433,  1.1872,  1.4016,  1.4632,  1.4360,  1.4140,
          1.4440,  1.3920,  1.4159,  1.2937,  1.3959,  1.3143,  1.2592,  1.2462,
          1.2237,  1.3068,  1.2446,  1.3498,  1.2064,  1.2196],
        [ 1.1615,  1.1907,  1.2433,  1.2247,  1.1971,  1.1665,  1.1765,  1.1588,
          1.1588,  2.7190,  2.7488,  2.7336,  3.0761,  2.7096,  3.4971,  2.7247,
          3.0032,  3.3678,  1.1801,  1.2053,  1.1737,  1.1938,  1.1870,  1.1819,
          1.2017,  1.1737,  1.1737,  1.2369,  1.1899,  1.1939,  1.2223,  1.2366,
          1.2050,  1.2411,  1.1651,  1.1968,  1.3519,  1.4243,  1.3458,  1.3658,
          1.4018,  1.4155,  1.3224,  1.2237,  1.3447,  1.2740,  1.2602,  1.2452,
          1.2192,  1.2278,  1.2433,  1.2769,  1.1994,  1.2144],
        [ 1.1550,  1.1810,  1.2075,  1.2112,  1.1860,  1.1595,  1.1677,  1.1526,
          1.1526,  1.2274,  1.2524,  1.2390,  1.2783,  1.2190,  1.2643,  1.2322,
          1.1473,  1.2755,  2.9077,  3.1818,  3.1419,  2.9245,  2.8471,  2.8413,
          3.1324,  2.8330,  2.8330,  1.1915,  1.2480,  1.1896,  1.2139,  1.1924,
          1.1996,  1.2316,  1.1933,  1.1922,  1.3987,  1.4617,  1.4325,  1.3206,
          1.4408,  1.4220,  1.4133,  1.2883,  1.3013,  1.3182,  1.2631,  1.2498,
          1.2269,  1.3002,  1.2481,  1.3440,  1.1857,  1.2226],
        [ 1.1585,  1.1852,  1.2121,  1.2163,  1.1906,  1.1632,  1.1718,  1.1561,
          1.1561,  1.2304,  1.2561,  1.2423,  1.2693,  1.2217,  1.2659,  1.2353,
          1.2060,  1.2307,  1.2101,  1.1961,  1.2447,  1.2226,  1.1840,  1.1793,
          1.1756,  1.1719,  1.1719,  3.2017,  3.0799,  2.8072,  2.8412,  3.2001,
          2.8187,  3.0373,  2.8453,  2.8101,  1.3913,  1.4561,  1.4095,  1.3732,
          1.4359,  1.4167,  1.3884,  1.2765,  1.3542,  1.3222,  1.2646,  1.2016,
          1.1789,  1.3144,  1.2493,  1.3593,  1.1382,  1.2231],
        [ 1.7834,  1.4089,  0.6379,  0.9177,  1.3104,  1.7177,  1.5972,  1.8177,
          1.8177,  1.5931,  1.2553,  1.4547,  0.9079,  1.6449,  0.1759,  1.5360,
          1.8078,  0.8223,  1.3155,  1.0182,  0.7777,  1.1386,  1.6588,  1.7214,
          1.5206,  1.8221,  1.8221,  0.8696,  0.8503,  1.7912,  1.5918,  0.8704,
          1.7353,  1.2233,  1.8417,  1.7573, -0.0810, -0.2966, -0.3289, -0.1319,
          0.0915,  0.1560, -0.1886, 22.4447,  1.5281,  0.7321,  1.2844,  1.3464,
          1.5710,  0.9287,  1.5096,  0.3593,  1.6918,  1.7264],
        [ 1.2098,  1.2482,  1.3155,  1.2933,  1.2565,  1.2165,  1.1853,  1.2063,
          1.2063,  1.1791,  1.3080,  1.1963,  1.3460,  1.2582,  1.4077,  1.1862,
          1.2359,  1.2653,  1.2733,  1.2585,  1.3239,  1.2911,  1.2358,  1.2290,
          1.1241,  1.2182,  1.2182,  1.2887,  1.3359,  1.2356,  1.0172,  1.2447,
          1.1174,  1.2966,  1.1092,  1.2394,  1.2398,  0.9607,  1.2363,  1.2581,
          0.7996,  0.7313,  1.2632,  1.0640,  0.6109,  3.8795,  2.6657,  3.8569,
          2.9823,  2.2258,  1.8766,  3.1248,  3.7976,  1.8517]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 379 : 178.3172553626685
Test loss for epoch 379 : 178.97801922443625
Test Precision for epoch 379 : 0.26153846153846155
Test Recall for epoch 379 : 0.26153846153846155
Test F1 for epoch 379 : 0.26153846153846155


theta for epoch 380 : tensor([[ 2.8781,  2.9113,  2.9878,  3.1388,  3.1004,  2.8836,  3.0762,  2.8753,
          2.8753,  1.2225,  1.2470,  1.2338,  1.2724,  1.2142,  1.3146,  1.2272,
          1.1997,  1.2341,  1.1999,  1.1753,  1.1890,  1.2118,  1.1749,  1.1705,
          1.1880,  1.1633,  1.1633,  1.2062,  1.2522,  1.1846,  1.2093,  1.2521,
          1.1943,  1.2258,  1.1432,  1.1871,  1.4018,  1.4634,  1.4362,  1.4141,
          1.4443,  1.3922,  1.4161,  1.2940,  1.3962,  1.3144,  1.2593,  1.2463,
          1.2238,  1.3069,  1.2446,  1.3499,  1.2064,  1.2196],
        [ 1.1613,  1.1906,  1.2431,  1.2245,  1.1969,  1.1664,  1.1764,  1.1586,
          1.1586,  2.7246,  2.7544,  2.7393,  3.0832,  2.7153,  3.4958,  2.7303,
          3.0104,  3.3685,  1.1801,  1.2053,  1.1736,  1.1937,  1.1869,  1.1818,
          1.2015,  1.1736,  1.1736,  1.2368,  1.1898,  1.1938,  1.2221,  1.2365,
          1.2049,  1.2410,  1.1651,  1.1967,  1.3521,  1.4245,  1.3461,  1.3660,
          1.4021,  1.4157,  1.3227,  1.2241,  1.3450,  1.2740,  1.2602,  1.2452,
          1.2192,  1.2278,  1.2433,  1.2770,  1.1994,  1.2144],
        [ 1.1549,  1.1809,  1.2074,  1.2110,  1.1860,  1.1594,  1.1676,  1.1525,
          1.1525,  1.2274,  1.2524,  1.2390,  1.2782,  1.2189,  1.2640,  1.2322,
          1.1471,  1.2753,  2.9124,  3.1871,  3.1473,  2.9292,  2.8512,  2.8454,
          3.1377,  2.8371,  2.8371,  1.1914,  1.2478,  1.1896,  1.2138,  1.1923,
          1.1995,  1.2316,  1.1932,  1.1921,  1.3989,  1.4619,  1.4327,  1.3208,
          1.4410,  1.4223,  1.4135,  1.2885,  1.3016,  1.3183,  1.2632,  1.2499,
          1.2269,  1.3002,  1.2482,  1.3440,  1.1857,  1.2227],
        [ 1.1585,  1.1852,  1.2120,  1.2162,  1.1905,  1.1631,  1.1717,  1.1561,
          1.1561,  1.2304,  1.2560,  1.2423,  1.2690,  1.2217,  1.2657,  1.2353,
          1.2060,  1.2305,  1.2100,  1.1959,  1.2446,  1.2225,  1.1840,  1.1793,
          1.1755,  1.1718,  1.1718,  3.2075,  3.0842,  2.8113,  2.8452,  3.2059,
          2.8229,  3.0416,  2.8502,  2.8143,  1.3915,  1.4563,  1.4095,  1.3734,
          1.4362,  1.4169,  1.3884,  1.2768,  1.3544,  1.3224,  1.2647,  1.2017,
          1.1790,  1.3145,  1.2493,  1.3594,  1.1382,  1.2232],
        [ 1.7837,  1.4093,  0.6384,  0.9182,  1.3108,  1.7181,  1.5976,  1.8180,
          1.8180,  1.5934,  1.2557,  1.4551,  0.9084,  1.6453,  0.1765,  1.5363,
          1.8082,  0.8229,  1.3159,  1.0186,  0.7782,  1.1390,  1.6592,  1.7217,
          1.5210,  1.8224,  1.8224,  0.8700,  0.8508,  1.7915,  1.5922,  0.8709,
          1.7356,  1.2237,  1.8420,  1.7576, -0.0818, -0.2974, -0.3296, -0.1328,
          0.0907,  0.1552, -0.1894, 22.4932,  1.5263,  0.7322,  1.2842,  1.3463,
          1.5707,  0.9287,  1.5094,  0.3595,  1.6915,  1.7261],
        [ 1.2096,  1.2481,  1.3155,  1.2932,  1.2564,  1.2164,  1.1852,  1.2061,
          1.2061,  1.1789,  1.3078,  1.1961,  1.3459,  1.2580,  1.4077,  1.1860,
          1.2357,  1.2652,  1.2731,  1.2584,  1.3238,  1.2909,  1.2356,  1.2289,
          1.1239,  1.2181,  1.2181,  1.2886,  1.3358,  1.2354,  1.0171,  1.2446,
          1.1173,  1.2965,  1.1090,  1.2392,  1.2388,  0.9599,  1.2354,  1.2572,
          0.7989,  0.7306,  1.2622,  1.0628,  0.6101,  3.8876,  2.6690,  3.8643,
          2.9869,  2.2275,  1.8775,  3.1295,  3.8058,  1.8526]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 380 : 178.31238533789377
Test loss for epoch 380 : 178.97481483498257
Test Precision for epoch 380 : 0.26153846153846155
Test Recall for epoch 380 : 0.26153846153846155
Test F1 for epoch 380 : 0.26153846153846155


theta for epoch 381 : tensor([[ 2.8825,  2.9157,  2.9922,  3.1438,  3.1055,  2.8880,  3.0812,  2.8797,
          2.8797,  1.2224,  1.2469,  1.2337,  1.2722,  1.2141,  1.3144,  1.2271,
          1.1996,  1.2340,  1.1998,  1.1752,  1.1889,  1.2117,  1.1749,  1.1704,
          1.1879,  1.1633,  1.1633,  1.2061,  1.2521,  1.1845,  1.2092,  1.2520,
          1.1942,  1.2257,  1.1431,  1.1870,  1.4020,  1.4636,  1.4364,  1.4143,
          1.4446,  1.3924,  1.4163,  1.2942,  1.3965,  1.3145,  1.2594,  1.2464,
          1.2238,  1.3070,  1.2447,  1.3500,  1.2065,  1.2197],
        [ 1.1612,  1.1904,  1.2428,  1.2243,  1.1968,  1.1663,  1.1763,  1.1585,
          1.1585,  2.7301,  2.7599,  2.7448,  3.0902,  2.7208,  3.4948,  2.7358,
          3.0174,  3.3695,  1.1800,  1.2052,  1.1735,  1.1937,  1.1868,  1.1817,
          1.2014,  1.1735,  1.1735,  1.2368,  1.1897,  1.1937,  1.2220,  1.2365,
          1.2048,  1.2409,  1.1651,  1.1966,  1.3523,  1.4247,  1.3464,  1.3662,
          1.4023,  1.4159,  1.3230,  1.2244,  1.3454,  1.2741,  1.2602,  1.2452,
          1.2192,  1.2279,  1.2433,  1.2770,  1.1994,  1.2144],
        [ 1.1548,  1.1808,  1.2072,  1.2109,  1.1859,  1.1594,  1.1675,  1.1524,
          1.1524,  1.2273,  1.2522,  1.2389,  1.2781,  1.2188,  1.2638,  1.2321,
          1.1470,  1.2751,  2.9170,  3.1923,  3.1526,  2.9338,  2.8552,  2.8494,
          3.1429,  2.8412,  2.8412,  1.1913,  1.2476,  1.1895,  1.2137,  1.1922,
          1.1994,  1.2315,  1.1932,  1.1921,  1.3991,  1.4621,  1.4329,  1.3209,
          1.4413,  1.4225,  1.4137,  1.2888,  1.3019,  1.3184,  1.2633,  1.2500,
          1.2270,  1.3002,  1.2483,  1.3441,  1.1858,  1.2227],
        [ 1.1584,  1.1851,  1.2118,  1.2161,  1.1904,  1.1631,  1.1717,  1.1560,
          1.1560,  1.2303,  1.2559,  1.2422,  1.2688,  1.2216,  1.2655,  1.2352,
          1.2059,  1.2304,  1.2099,  1.1957,  1.2445,  1.2224,  1.1839,  1.1792,
          1.1754,  1.1718,  1.1718,  3.2133,  3.0886,  2.8155,  2.8491,  3.2117,
          2.8271,  3.0459,  2.8551,  2.8185,  1.3917,  1.4565,  1.4095,  1.3735,
          1.4364,  1.4171,  1.3884,  1.2770,  1.3547,  1.3225,  1.2648,  1.2018,
          1.1791,  1.3146,  1.2494,  1.3595,  1.1383,  1.2232],
        [ 1.7840,  1.4097,  0.6389,  0.9186,  1.3112,  1.7184,  1.5979,  1.8183,
          1.8183,  1.5937,  1.2561,  1.4555,  0.9089,  1.6456,  0.1772,  1.5367,
          1.8085,  0.8234,  1.3163,  1.0191,  0.7786,  1.1395,  1.6595,  1.7220,
          1.5214,  1.8227,  1.8227,  0.8705,  0.8512,  1.7918,  1.5925,  0.8713,
          1.7359,  1.2241,  1.8423,  1.7580, -0.0826, -0.2981, -0.3304, -0.1336,
          0.0898,  0.1543, -0.1901, 22.5414,  1.5244,  0.7323,  1.2841,  1.3461,
          1.5704,  0.9288,  1.5092,  0.3598,  1.6911,  1.7257],
        [ 1.2095,  1.2479,  1.3154,  1.2931,  1.2563,  1.2162,  1.1850,  1.2060,
          1.2060,  1.1788,  1.3077,  1.1959,  1.3457,  1.2578,  1.4076,  1.1859,
          1.2355,  1.2651,  1.2730,  1.2582,  1.3237,  1.2908,  1.2355,  1.2287,
          1.1238,  1.2179,  1.2179,  1.2885,  1.3357,  1.2352,  1.0169,  1.2445,
          1.1171,  1.2964,  1.1088,  1.2390,  1.2378,  0.9592,  1.2345,  1.2562,
          0.7981,  0.7299,  1.2613,  1.0615,  0.6094,  3.8956,  2.6722,  3.8717,
          2.9915,  2.2290,  1.8784,  3.1341,  3.8141,  1.8534]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 381 : 178.30757926491634
Test loss for epoch 381 : 178.9716594829835
Test Precision for epoch 381 : 0.26153846153846155
Test Recall for epoch 381 : 0.26153846153846155
Test F1 for epoch 381 : 0.26153846153846155


theta for epoch 382 : tensor([[ 2.8868,  2.9200,  2.9965,  3.1488,  3.1104,  2.8923,  3.0862,  2.8840,
          2.8840,  1.2223,  1.2468,  1.2337,  1.2721,  1.2140,  1.3143,  1.2270,
          1.1995,  1.2338,  1.1997,  1.1750,  1.1887,  1.2116,  1.1748,  1.1703,
          1.1878,  1.1632,  1.1632,  1.2059,  1.2519,  1.1844,  1.2091,  1.2518,
          1.1941,  1.2256,  1.1430,  1.1869,  1.4022,  1.4638,  1.4366,  1.4145,
          1.4448,  1.3927,  1.4165,  1.2944,  1.3969,  1.3147,  1.2595,  1.2465,
          1.2239,  1.3071,  1.2448,  1.3501,  1.2066,  1.2197],
        [ 1.1611,  1.1903,  1.2426,  1.2242,  1.1966,  1.1662,  1.1761,  1.1584,
          1.1584,  2.7356,  2.7653,  2.7501,  3.0970,  2.7262,  3.4940,  2.7412,
          3.0244,  3.3706,  1.1799,  1.2052,  1.1734,  1.1936,  1.1867,  1.1816,
          1.2013,  1.1734,  1.1734,  1.2367,  1.1896,  1.1936,  1.2219,  1.2364,
          1.2047,  1.2407,  1.1651,  1.1965,  1.3525,  1.4249,  1.3467,  1.3664,
          1.4026,  1.4162,  1.3233,  1.2247,  1.3457,  1.2741,  1.2603,  1.2453,
          1.2192,  1.2280,  1.2433,  1.2771,  1.1994,  1.2144],
        [ 1.1547,  1.1807,  1.2071,  1.2108,  1.1858,  1.1593,  1.1675,  1.1524,
          1.1524,  1.2272,  1.2521,  1.2388,  1.2780,  1.2188,  1.2636,  1.2320,
          1.1469,  1.2749,  2.9216,  3.1975,  3.1579,  2.9384,  2.8592,  2.8534,
          3.1481,  2.8452,  2.8452,  1.1911,  1.2474,  1.1894,  1.2137,  1.1920,
          1.1993,  1.2314,  1.1931,  1.1920,  1.3993,  1.4623,  1.4331,  1.3211,
          1.4416,  1.4228,  1.4139,  1.2890,  1.3023,  1.3186,  1.2633,  1.2501,
          1.2270,  1.3003,  1.2483,  1.3441,  1.1859,  1.2228],
        [ 1.1584,  1.1850,  1.2117,  1.2160,  1.1904,  1.1630,  1.1716,  1.1560,
          1.1560,  1.2302,  1.2558,  1.2421,  1.2686,  1.2216,  1.2652,  1.2351,
          1.2059,  1.2302,  1.2099,  1.1955,  1.2444,  1.2223,  1.1839,  1.1792,
          1.1753,  1.1717,  1.1717,  3.2190,  3.0929,  2.8196,  2.8530,  3.2174,
          2.8311,  3.0502,  2.8599,  2.8225,  1.3919,  1.4568,  1.4095,  1.3737,
          1.4367,  1.4173,  1.3884,  1.2773,  1.3550,  1.3226,  1.2649,  1.2020,
          1.1791,  1.3147,  1.2495,  1.3597,  1.1383,  1.2233],
        [ 1.7844,  1.4101,  0.6394,  0.9191,  1.3116,  1.7187,  1.5983,  1.8187,
          1.8187,  1.5941,  1.2565,  1.4559,  0.9093,  1.6459,  0.1778,  1.5370,
          1.8088,  0.8239,  1.3167,  1.0195,  0.7791,  1.1399,  1.6599,  1.7224,
          1.5218,  1.8230,  1.8230,  0.8710,  0.8517,  1.7921,  1.5929,  0.8718,
          1.7363,  1.2245,  1.8425,  1.7583, -0.0834, -0.2989, -0.3311, -0.1344,
          0.0890,  0.1535, -0.1909, 22.5894,  1.5223,  0.7325,  1.2840,  1.3459,
          1.5701,  0.9289,  1.5090,  0.3601,  1.6907,  1.7254],
        [ 1.2093,  1.2478,  1.3153,  1.2930,  1.2562,  1.2161,  1.1849,  1.2058,
          1.2058,  1.1786,  1.3075,  1.1958,  1.3456,  1.2577,  1.4075,  1.1857,
          1.2353,  1.2651,  1.2728,  1.2581,  1.3236,  1.2907,  1.2353,  1.2286,
          1.1237,  1.2177,  1.2177,  1.2884,  1.3356,  1.2350,  1.0168,  1.2444,
          1.1170,  1.2962,  1.1087,  1.2389,  1.2368,  0.9584,  1.2336,  1.2552,
          0.7974,  0.7292,  1.2603,  1.0603,  0.6086,  3.9037,  2.6753,  3.8791,
          2.9960,  2.2305,  1.8791,  3.1386,  3.8223,  1.8542]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 382 : 178.30283528930642
Test loss for epoch 382 : 178.9685516936205
Test Precision for epoch 382 : 0.26153846153846155
Test Recall for epoch 382 : 0.26153846153846155
Test F1 for epoch 382 : 0.26153846153846155


theta for epoch 383 : tensor([[ 2.8911,  2.9243,  3.0008,  3.1538,  3.1154,  2.8966,  3.0911,  2.8883,
          2.8883,  1.2222,  1.2467,  1.2336,  1.2720,  1.2139,  1.3141,  1.2269,
          1.1995,  1.2337,  1.1996,  1.1749,  1.1886,  1.2115,  1.1747,  1.1702,
          1.1877,  1.1631,  1.1631,  1.2058,  1.2518,  1.1843,  1.2090,  1.2517,
          1.1941,  1.2255,  1.1430,  1.1869,  1.4024,  1.4641,  1.4367,  1.4147,
          1.4451,  1.3929,  1.4167,  1.2947,  1.3972,  1.3148,  1.2596,  1.2466,
          1.2240,  1.3072,  1.2449,  1.3502,  1.2066,  1.2198],
        [ 1.1610,  1.1902,  1.2424,  1.2240,  1.1965,  1.1661,  1.1760,  1.1583,
          1.1583,  2.7408,  2.7705,  2.7554,  3.1038,  2.7314,  3.4935,  2.7464,
          3.0312,  3.3720,  1.1799,  1.2051,  1.1733,  1.1935,  1.1866,  1.1815,
          1.2012,  1.1733,  1.1733,  1.2366,  1.1895,  1.1935,  1.2218,  1.2364,
          1.2047,  1.2406,  1.1651,  1.1964,  1.3527,  1.4251,  1.3470,  1.3666,
          1.4028,  1.4164,  1.3236,  1.2250,  1.3461,  1.2741,  1.2603,  1.2453,
          1.2192,  1.2281,  1.2433,  1.2772,  1.1994,  1.2144],
        [ 1.1547,  1.1806,  1.2070,  1.2107,  1.1857,  1.1592,  1.1674,  1.1523,
          1.1523,  1.2271,  1.2521,  1.2387,  1.2779,  1.2187,  1.2633,  1.2319,
          1.1467,  1.2748,  2.9262,  3.2027,  3.1632,  2.9430,  2.8632,  2.8574,
          3.1533,  2.8491,  2.8491,  1.1910,  1.2472,  1.1894,  1.2136,  1.1919,
          1.1993,  1.2313,  1.1930,  1.1919,  1.3995,  1.4626,  1.4333,  1.3213,
          1.4418,  1.4231,  1.4141,  1.2892,  1.3026,  1.3187,  1.2634,  1.2501,
          1.2271,  1.3003,  1.2484,  1.3441,  1.1859,  1.2228],
        [ 1.1583,  1.1849,  1.2115,  1.2159,  1.1903,  1.1630,  1.1716,  1.1559,
          1.1559,  1.2302,  1.2557,  1.2421,  1.2684,  1.2215,  1.2650,  1.2351,
          1.2059,  1.2300,  1.2098,  1.1952,  1.2442,  1.2222,  1.1838,  1.1791,
          1.1752,  1.1717,  1.1717,  3.2247,  3.0972,  2.8236,  2.8569,  3.2231,
          2.8352,  3.0545,  2.8646,  2.8266,  1.3921,  1.4570,  1.4096,  1.3738,
          1.4370,  1.4176,  1.3885,  1.2775,  1.3553,  1.3228,  1.2650,  1.2021,
          1.1792,  1.3148,  1.2496,  1.3598,  1.1383,  1.2234],
        [ 1.7847,  1.4105,  0.6399,  0.9195,  1.3120,  1.7191,  1.5987,  1.8190,
          1.8190,  1.5945,  1.2570,  1.4563,  0.9098,  1.6463,  0.1784,  1.5374,
          1.8091,  0.8245,  1.3171,  1.0200,  0.7796,  1.1403,  1.6602,  1.7227,
          1.5222,  1.8233,  1.8233,  0.8714,  0.8522,  1.7924,  1.5933,  0.8722,
          1.7366,  1.2250,  1.8428,  1.7586, -0.0842, -0.2996, -0.3319, -0.1352,
          0.0882,  0.1526, -0.1917, 22.6371,  1.5200,  0.7326,  1.2838,  1.3458,
          1.5697,  0.9289,  1.5088,  0.3604,  1.6904,  1.7251],
        [ 1.2092,  1.2477,  1.3152,  1.2929,  1.2561,  1.2159,  1.1848,  1.2057,
          1.2057,  1.1784,  1.3074,  1.1956,  1.3455,  1.2575,  1.4074,  1.1855,
          1.2351,  1.2650,  1.2727,  1.2580,  1.3235,  1.2906,  1.2352,  1.2284,
          1.1235,  1.2176,  1.2176,  1.2882,  1.3355,  1.2349,  1.0167,  1.2443,
          1.1168,  1.2961,  1.1085,  1.2387,  1.2358,  0.9576,  1.2326,  1.2543,
          0.7966,  0.7284,  1.2593,  1.0590,  0.6078,  3.9117,  2.6783,  3.8865,
          3.0004,  2.2318,  1.8798,  3.1431,  3.8306,  1.8548]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 383 : 178.29815329496276
Test loss for epoch 383 : 178.96548700858733
Test Precision for epoch 383 : 0.26153846153846155
Test Recall for epoch 383 : 0.26153846153846155
Test F1 for epoch 383 : 0.26153846153846155


theta for epoch 384 : tensor([[ 2.8954,  2.9286,  3.0051,  3.1587,  3.1202,  2.9008,  3.0960,  2.8925,
          2.8925,  1.2221,  1.2466,  1.2335,  1.2718,  1.2138,  1.3140,  1.2268,
          1.1994,  1.2336,  1.1995,  1.1748,  1.1884,  1.2113,  1.1746,  1.1702,
          1.1876,  1.1631,  1.1631,  1.2056,  1.2517,  1.1843,  1.2089,  1.2516,
          1.1940,  1.2254,  1.1429,  1.1868,  1.4026,  1.4643,  1.4369,  1.4149,
          1.4453,  1.3932,  1.4169,  1.2949,  1.3976,  1.3149,  1.2597,  1.2467,
          1.2240,  1.3073,  1.2449,  1.3503,  1.2067,  1.2199],
        [ 1.1609,  1.1900,  1.2422,  1.2239,  1.1964,  1.1660,  1.1759,  1.1583,
          1.1583,  2.7460,  2.7757,  2.7605,  3.1104,  2.7365,  3.4932,  2.7516,
          3.0379,  3.3735,  1.1798,  1.2051,  1.1732,  1.1934,  1.1865,  1.1814,
          1.2011,  1.1732,  1.1732,  1.2366,  1.1893,  1.1934,  1.2217,  1.2363,
          1.2046,  1.2405,  1.1651,  1.1963,  1.3529,  1.4254,  1.3473,  1.3668,
          1.4031,  1.4167,  1.3240,  1.2254,  1.3464,  1.2742,  1.2603,  1.2453,
          1.2192,  1.2282,  1.2434,  1.2773,  1.1994,  1.2144],
        [ 1.1546,  1.1805,  1.2068,  1.2106,  1.1856,  1.1591,  1.1673,  1.1522,
          1.1522,  1.2271,  1.2519,  1.2386,  1.2777,  1.2186,  1.2631,  1.2318,
          1.1466,  1.2746,  2.9307,  3.2078,  3.1684,  2.9475,  2.8671,  2.8613,
          3.1584,  2.8531,  2.8531,  1.1909,  1.2470,  1.1893,  1.2135,  1.1917,
          1.1992,  1.2312,  1.1929,  1.1919,  1.3997,  1.4628,  1.4335,  1.3214,
          1.4421,  1.4234,  1.4143,  1.2895,  1.3029,  1.3188,  1.2635,  1.2502,
          1.2272,  1.3003,  1.2485,  1.3442,  1.1860,  1.2229],
        [ 1.1583,  1.1849,  1.2114,  1.2158,  1.1902,  1.1629,  1.1715,  1.1559,
          1.1559,  1.2301,  1.2557,  1.2420,  1.2682,  1.2215,  1.2648,  1.2350,
          1.2058,  1.2299,  1.2097,  1.1950,  1.2441,  1.2221,  1.1837,  1.1791,
          1.1751,  1.1717,  1.1717,  3.2304,  3.1015,  2.8275,  2.8607,  3.2288,
          2.8391,  3.0587,  2.8693,  2.8305,  1.3923,  1.4572,  1.4096,  1.3740,
          1.4373,  1.4178,  1.3885,  1.2778,  1.3556,  1.3229,  1.2651,  1.2022,
          1.1793,  1.3149,  1.2497,  1.3599,  1.1384,  1.2235],
        [ 1.7850,  1.4109,  0.6404,  0.9200,  1.3124,  1.7194,  1.5990,  1.8193,
          1.8193,  1.5948,  1.2574,  1.4567,  0.9103,  1.6467,  0.1791,  1.5378,
          1.8094,  0.8250,  1.3175,  1.0205,  0.7801,  1.1408,  1.6606,  1.7231,
          1.5226,  1.8236,  1.8236,  0.8719,  0.8527,  1.7927,  1.5936,  0.8727,
          1.7369,  1.2254,  1.8431,  1.7589, -0.0850, -0.3003, -0.3326, -0.1360,
          0.0873,  0.1517, -0.1925, 22.6846,  1.5177,  0.7327,  1.2837,  1.3456,
          1.5694,  0.9290,  1.5086,  0.3606,  1.6900,  1.7247],
        [ 1.2090,  1.2476,  1.3151,  1.2928,  1.2560,  1.2158,  1.1846,  1.2055,
          1.2055,  1.1782,  1.3072,  1.1955,  1.3454,  1.2573,  1.4073,  1.1854,
          1.2349,  1.2649,  1.2726,  1.2579,  1.3234,  1.2905,  1.2350,  1.2283,
          1.1234,  1.2174,  1.2174,  1.2881,  1.3354,  1.2347,  1.0165,  1.2442,
          1.1167,  1.2960,  1.1083,  1.2385,  1.2348,  0.9569,  1.2317,  1.2532,
          0.7958,  0.7277,  1.2583,  1.0577,  0.6070,  3.9197,  2.6812,  3.8940,
          3.0047,  2.2331,  1.8804,  3.1475,  3.8388,  1.8554]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 384 : 178.2935311878795
Test loss for epoch 384 : 178.96247455441105
Test Precision for epoch 384 : 0.26153846153846155
Test Recall for epoch 384 : 0.26153846153846155
Test F1 for epoch 384 : 0.26153846153846155


theta for epoch 385 : tensor([[ 2.8995,  2.9328,  3.0093,  3.1635,  3.1251,  2.9050,  3.1008,  2.8967,
          2.8967,  1.2221,  1.2465,  1.2334,  1.2717,  1.2138,  1.3138,  1.2267,
          1.1994,  1.2335,  1.1994,  1.1746,  1.1883,  1.2112,  1.1745,  1.1701,
          1.1875,  1.1630,  1.1630,  1.2055,  1.2515,  1.1842,  1.2088,  1.2514,
          1.1939,  1.2252,  1.1428,  1.1867,  1.4028,  1.4645,  1.4371,  1.4151,
          1.4456,  1.3934,  1.4171,  1.2952,  1.3979,  1.3150,  1.2598,  1.2468,
          1.2241,  1.3074,  1.2450,  1.3505,  1.2068,  1.2199],
        [ 1.1608,  1.1899,  1.2420,  1.2237,  1.1963,  1.1659,  1.1758,  1.1582,
          1.1582,  2.7511,  2.7807,  2.7655,  3.1168,  2.7416,  3.4931,  2.7566,
          3.0445,  3.3752,  1.1797,  1.2050,  1.1731,  1.1933,  1.1864,  1.1813,
          1.2010,  1.1732,  1.1732,  1.2365,  1.1892,  1.1934,  1.2216,  1.2363,
          1.2045,  1.2403,  1.1651,  1.1962,  1.3531,  1.4256,  1.3477,  1.3670,
          1.4034,  1.4170,  1.3243,  1.2257,  1.3468,  1.2742,  1.2604,  1.2454,
          1.2193,  1.2283,  1.2434,  1.2774,  1.1995,  1.2144],
        [ 1.1545,  1.1804,  1.2067,  1.2105,  1.1855,  1.1591,  1.1672,  1.1522,
          1.1522,  1.2270,  1.2519,  1.2385,  1.2776,  1.2185,  1.2629,  1.2318,
          1.1465,  1.2744,  2.9351,  3.2128,  3.1736,  2.9519,  2.8710,  2.8652,
          3.1634,  2.8569,  2.8569,  1.1907,  1.2468,  1.1892,  1.2134,  1.1916,
          1.1991,  1.2310,  1.1929,  1.1918,  1.3999,  1.4630,  1.4337,  1.3216,
          1.4424,  1.4237,  1.4145,  1.2897,  1.3032,  1.3190,  1.2636,  1.2503,
          1.2272,  1.3004,  1.2486,  1.3442,  1.1861,  1.2230],
        [ 1.1582,  1.1848,  1.2112,  1.2157,  1.1901,  1.1629,  1.1714,  1.1558,
          1.1558,  1.2301,  1.2556,  1.2419,  1.2680,  1.2214,  1.2646,  1.2350,
          1.2058,  1.2297,  1.2096,  1.1948,  1.2440,  1.2220,  1.1837,  1.1790,
          1.1750,  1.1716,  1.1716,  3.2360,  3.1057,  2.8314,  2.8644,  3.2344,
          2.8430,  3.0629,  2.8739,  2.8344,  1.3925,  1.4575,  1.4097,  1.3742,
          1.4375,  1.4181,  1.3886,  1.2781,  1.3560,  1.3230,  1.2652,  1.2023,
          1.1793,  1.3151,  1.2498,  1.3601,  1.1384,  1.2236],
        [ 1.7854,  1.4113,  0.6410,  0.9205,  1.3128,  1.7198,  1.5994,  1.8196,
          1.8196,  1.5952,  1.2578,  1.4571,  0.9108,  1.6470,  0.1797,  1.5382,
          1.8098,  0.8255,  1.3179,  1.0209,  0.7806,  1.1412,  1.6609,  1.7234,
          1.5230,  1.8240,  1.8240,  0.8724,  0.8531,  1.7930,  1.5940,  0.8732,
          1.7373,  1.2258,  1.8435,  1.7592, -0.0859, -0.3011, -0.3334, -0.1369,
          0.0865,  0.1509, -0.1933, 22.7318,  1.5152,  0.7328,  1.2835,  1.3454,
          1.5691,  0.9290,  1.5084,  0.3609,  1.6896,  1.7244],
        [ 1.2089,  1.2475,  1.3150,  1.2927,  1.2558,  1.2156,  1.1845,  1.2054,
          1.2054,  1.1781,  1.3071,  1.1953,  1.3452,  1.2571,  1.4073,  1.1852,
          1.2347,  1.2648,  1.2725,  1.2578,  1.3233,  1.2903,  1.2349,  1.2281,
          1.1232,  1.2173,  1.2173,  1.2880,  1.3353,  1.2345,  1.0164,  1.2441,
          1.1165,  1.2959,  1.1081,  1.2384,  1.2337,  0.9561,  1.2307,  1.2522,
          0.7950,  0.7270,  1.2573,  1.0564,  0.6062,  3.9277,  2.6841,  3.9014,
          3.0090,  2.2344,  1.8810,  3.1519,  3.8470,  1.8560]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 385 : 178.28896725143326
Test loss for epoch 385 : 178.95949727552778
Test Precision for epoch 385 : 0.26153846153846155
Test Recall for epoch 385 : 0.26153846153846155
Test F1 for epoch 385 : 0.26153846153846155


theta for epoch 386 : tensor([[ 2.9037,  2.9369,  3.0134,  3.1683,  3.1299,  2.9092,  3.1056,  2.9008,
          2.9008,  1.2220,  1.2463,  1.2333,  1.2716,  1.2137,  1.3136,  1.2267,
          1.1993,  1.2334,  1.1992,  1.1745,  1.1881,  1.2111,  1.1745,  1.1700,
          1.1874,  1.1629,  1.1629,  1.2053,  1.2514,  1.1841,  1.2088,  1.2513,
          1.1938,  1.2251,  1.1427,  1.1866,  1.4030,  1.4648,  1.4373,  1.4153,
          1.4459,  1.3937,  1.4173,  1.2954,  1.3983,  1.3151,  1.2598,  1.2469,
          1.2242,  1.3075,  1.2451,  1.3506,  1.2068,  1.2200],
        [ 1.1607,  1.1898,  1.2418,  1.2236,  1.1961,  1.1658,  1.1757,  1.1581,
          1.1581,  2.7560,  2.7856,  2.7704,  3.1232,  2.7465,  3.4932,  2.7615,
          3.0509,  3.3771,  1.1796,  1.2049,  1.1730,  1.1932,  1.1863,  1.1812,
          1.2009,  1.1731,  1.1731,  1.2364,  1.1891,  1.1933,  1.2215,  1.2362,
          1.2044,  1.2402,  1.1651,  1.1962,  1.3533,  1.4258,  1.3480,  1.3673,
          1.4036,  1.4172,  1.3246,  1.2260,  1.3472,  1.2743,  1.2604,  1.2454,
          1.2193,  1.2283,  1.2435,  1.2775,  1.1995,  1.2145],
        [ 1.1545,  1.1804,  1.2065,  1.2103,  1.1854,  1.1590,  1.1672,  1.1521,
          1.1521,  1.2269,  1.2518,  1.2384,  1.2775,  1.2185,  1.2626,  1.2317,
          1.1464,  1.2742,  2.9395,  3.2178,  3.1787,  2.9563,  2.8748,  2.8690,
          3.1684,  2.8607,  2.8607,  1.1906,  1.2467,  1.1892,  1.2134,  1.1915,
          1.1991,  1.2309,  1.1928,  1.1917,  1.4001,  1.4633,  1.4339,  1.3218,
          1.4427,  1.4240,  1.4147,  1.2900,  1.3036,  1.3191,  1.2637,  1.2504,
          1.2273,  1.3004,  1.2487,  1.3443,  1.1862,  1.2230],
        [ 1.1582,  1.1847,  1.2111,  1.2156,  1.1901,  1.1628,  1.1714,  1.1558,
          1.1558,  1.2300,  1.2555,  1.2419,  1.2678,  1.2214,  1.2644,  1.2349,
          1.2058,  1.2295,  1.2095,  1.1946,  1.2439,  1.2218,  1.1836,  1.1790,
          1.1749,  1.1716,  1.1716,  3.2416,  3.1099,  2.8353,  2.8681,  3.2400,
          2.8469,  3.0671,  2.8785,  2.8383,  1.3927,  1.4577,  1.4098,  1.3744,
          1.4378,  1.4183,  1.3887,  1.2784,  1.3563,  1.3232,  1.2653,  1.2024,
          1.1794,  1.3152,  1.2499,  1.3602,  1.1385,  1.2236],
        [ 1.7857,  1.4117,  0.6415,  0.9209,  1.3132,  1.7201,  1.5998,  1.8200,
          1.8200,  1.5956,  1.2582,  1.4575,  0.9113,  1.6474,  0.1804,  1.5386,
          1.8101,  0.8261,  1.3183,  1.0214,  0.7811,  1.1417,  1.6613,  1.7238,
          1.5234,  1.8243,  1.8243,  0.8729,  0.8536,  1.7934,  1.5944,  0.8737,
          1.7377,  1.2262,  1.8438,  1.7596, -0.0867, -0.3018, -0.3342, -0.1377,
          0.0856,  0.1500, -0.1941, 22.7788,  1.5126,  0.7329,  1.2834,  1.3452,
          1.5688,  0.9291,  1.5081,  0.3612,  1.6892,  1.7240],
        [ 1.2087,  1.2473,  1.3150,  1.2927,  1.2557,  1.2155,  1.1844,  1.2052,
          1.2052,  1.1779,  1.3069,  1.1951,  1.3451,  1.2569,  1.4072,  1.1851,
          1.2345,  1.2647,  1.2723,  1.2577,  1.3232,  1.2902,  1.2347,  1.2280,
          1.1231,  1.2171,  1.2171,  1.2879,  1.3352,  1.2343,  1.0162,  1.2440,
          1.1164,  1.2958,  1.1080,  1.2382,  1.2327,  0.9553,  1.2297,  1.2512,
          0.7942,  0.7262,  1.2562,  1.0550,  0.6053,  3.9357,  2.6868,  3.9089,
          3.0132,  2.2355,  1.8815,  3.1562,  3.8552,  1.8565]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 386 : 178.28446074807425
Test loss for epoch 386 : 178.95657346011086
Test Precision for epoch 386 : 0.26153846153846155
Test Recall for epoch 386 : 0.26153846153846155
Test F1 for epoch 386 : 0.26153846153846155


theta for epoch 387 : tensor([[ 2.9078,  2.9410,  3.0175,  3.1731,  3.1347,  2.9132,  3.1104,  2.9049,
          2.9049,  1.2219,  1.2462,  1.2332,  1.2714,  1.2136,  1.3134,  1.2266,
          1.1992,  1.2332,  1.1991,  1.1744,  1.1880,  1.2110,  1.1744,  1.1699,
          1.1874,  1.1628,  1.1628,  1.2052,  1.2513,  1.1841,  1.2087,  1.2512,
          1.1938,  1.2250,  1.1426,  1.1866,  1.4033,  1.4650,  1.4375,  1.4155,
          1.4461,  1.3939,  1.4175,  1.2957,  1.3986,  1.3153,  1.2599,  1.2469,
          1.2243,  1.3076,  1.2452,  1.3507,  1.2069,  1.2201],
        [ 1.1606,  1.1896,  1.2416,  1.2234,  1.1960,  1.1657,  1.1755,  1.1580,
          1.1580,  2.7609,  2.7904,  2.7752,  3.1294,  2.7512,  3.4935,  2.7663,
          3.0573,  3.3792,  1.1795,  1.2049,  1.1729,  1.1931,  1.1862,  1.1811,
          1.2007,  1.1730,  1.1730,  1.2363,  1.1890,  1.1932,  1.2214,  1.2361,
          1.2043,  1.2401,  1.1651,  1.1961,  1.3535,  1.4260,  1.3483,  1.3675,
          1.4039,  1.4175,  1.3249,  1.2263,  1.3476,  1.2743,  1.2605,  1.2455,
          1.2193,  1.2284,  1.2435,  1.2776,  1.1995,  1.2145],
        [ 1.1544,  1.1803,  1.2064,  1.2102,  1.1853,  1.1589,  1.1671,  1.1520,
          1.1520,  1.2268,  1.2516,  1.2384,  1.2773,  1.2184,  1.2624,  1.2316,
          1.1463,  1.2740,  2.9439,  3.2228,  3.1838,  2.9607,  2.8785,  2.8728,
          3.1734,  2.8645,  2.8645,  1.1904,  1.2465,  1.1891,  1.2133,  1.1913,
          1.1990,  1.2308,  1.1927,  1.1917,  1.4003,  1.4635,  1.4341,  1.3220,
          1.4429,  1.4242,  1.4149,  1.2902,  1.3039,  1.3192,  1.2638,  1.2505,
          1.2274,  1.3005,  1.2487,  1.3444,  1.1862,  1.2231],
        [ 1.1581,  1.1846,  1.2109,  1.2155,  1.1900,  1.1628,  1.1713,  1.1557,
          1.1557,  1.2300,  1.2554,  1.2418,  1.2676,  1.2213,  1.2642,  1.2349,
          1.2058,  1.2294,  1.2094,  1.1944,  1.2437,  1.2217,  1.1836,  1.1789,
          1.1748,  1.1715,  1.1715,  3.2471,  3.1141,  2.8391,  2.8718,  3.2456,
          2.8507,  3.0712,  2.8830,  2.8421,  1.3930,  1.4580,  1.4098,  1.3745,
          1.4381,  1.4185,  1.3888,  1.2786,  1.3566,  1.3233,  1.2654,  1.2025,
          1.1795,  1.3153,  1.2500,  1.3604,  1.1385,  1.2237],
        [ 1.7861,  1.4121,  0.6420,  0.9214,  1.3137,  1.7205,  1.6002,  1.8203,
          1.8203,  1.5960,  1.2587,  1.4579,  0.9118,  1.6478,  0.1810,  1.5390,
          1.8105,  0.8266,  1.3188,  1.0219,  0.7816,  1.1421,  1.6617,  1.7241,
          1.5239,  1.8247,  1.8247,  0.8734,  0.8541,  1.7937,  1.5948,  0.8742,
          1.7380,  1.2267,  1.8441,  1.7599, -0.0876, -0.3026, -0.3350, -0.1385,
          0.0847,  0.1491, -0.1949, 22.8255,  1.5100,  0.7330,  1.2832,  1.3450,
          1.5684,  0.9292,  1.5079,  0.3614,  1.6889,  1.7237],
        [ 1.2086,  1.2472,  1.3149,  1.2926,  1.2556,  1.2154,  1.1842,  1.2051,
          1.2051,  1.1777,  1.3068,  1.1950,  1.3450,  1.2567,  1.4071,  1.1849,
          1.2342,  1.2647,  1.2722,  1.2576,  1.3231,  1.2901,  1.2346,  1.2278,
          1.1229,  1.2170,  1.2170,  1.2878,  1.3351,  1.2342,  1.0161,  1.2438,
          1.1162,  1.2956,  1.1078,  1.2380,  1.2316,  0.9545,  1.2287,  1.2501,
          0.7934,  0.7255,  1.2552,  1.0537,  0.6045,  3.9437,  2.6895,  3.9163,
          3.0173,  2.2366,  1.8820,  3.1604,  3.8634,  1.8569]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 387 : 178.2800098552305
Test loss for epoch 387 : 178.95368196049307
Test Precision for epoch 387 : 0.26153846153846155
Test Recall for epoch 387 : 0.26153846153846155
Test F1 for epoch 387 : 0.26153846153846155


theta for epoch 388 : tensor([[ 2.9118,  2.9450,  3.0215,  3.1778,  3.1394,  2.9173,  3.1151,  2.9090,
          2.9090,  1.2218,  1.2461,  1.2331,  1.2713,  1.2135,  1.3133,  1.2265,
          1.1992,  1.2331,  1.1990,  1.1742,  1.1878,  1.2108,  1.1743,  1.1699,
          1.1873,  1.1628,  1.1628,  1.2050,  1.2511,  1.1840,  1.2086,  1.2510,
          1.1937,  1.2249,  1.1425,  1.1865,  1.4035,  1.4652,  1.4377,  1.4157,
          1.4464,  1.3942,  1.4177,  1.2959,  1.3990,  1.3154,  1.2600,  1.2470,
          1.2243,  1.3077,  1.2453,  1.3509,  1.2070,  1.2201],
        [ 1.1605,  1.1895,  1.2414,  1.2233,  1.1959,  1.1656,  1.1754,  1.1579,
          1.1579,  2.7656,  2.7952,  2.7798,  3.1356,  2.7559,  3.4939,  2.7710,
          3.0635,  3.3814,  1.1795,  1.2048,  1.1727,  1.1930,  1.1861,  1.1810,
          1.2006,  1.1729,  1.1729,  1.2362,  1.1889,  1.1931,  1.2213,  1.2361,
          1.2042,  1.2400,  1.1651,  1.1960,  1.3538,  1.4263,  1.3486,  1.3677,
          1.4042,  1.4178,  1.3252,  1.2267,  1.3480,  1.2744,  1.2605,  1.2456,
          1.2193,  1.2285,  1.2435,  1.2777,  1.1995,  1.2145],
        [ 1.1543,  1.1802,  1.2062,  1.2101,  1.1852,  1.1588,  1.1670,  1.1520,
          1.1520,  1.2268,  1.2515,  1.2383,  1.2772,  1.2183,  1.2622,  1.2315,
          1.1461,  1.2739,  2.9482,  3.2277,  3.1889,  2.9650,  2.8823,  2.8765,
          3.1783,  2.8682,  2.8682,  1.1903,  1.2463,  1.1890,  1.2132,  1.1912,
          1.1989,  1.2307,  1.1926,  1.1916,  1.4006,  1.4637,  1.4344,  1.3222,
          1.4432,  1.4245,  1.4151,  1.2905,  1.3042,  1.3194,  1.2639,  1.2506,
          1.2274,  1.3005,  1.2488,  1.3445,  1.1863,  1.2232],
        [ 1.1581,  1.1846,  1.2108,  1.2154,  1.1899,  1.1627,  1.1712,  1.1557,
          1.1557,  1.2299,  1.2554,  1.2417,  1.2674,  1.2213,  1.2639,  1.2348,
          1.2057,  1.2292,  1.2093,  1.1941,  1.2436,  1.2216,  1.1835,  1.1789,
          1.1747,  1.1715,  1.1715,  3.2526,  3.1182,  2.8428,  2.8754,  3.2511,
          2.8544,  3.0753,  2.8875,  2.8458,  1.3932,  1.4582,  1.4099,  1.3747,
          1.4384,  1.4188,  1.3889,  1.2789,  1.3570,  1.3234,  1.2656,  1.2027,
          1.1796,  1.3155,  1.2501,  1.3605,  1.1385,  1.2238],
        [ 1.7864,  1.4125,  0.6426,  0.9219,  1.3141,  1.7208,  1.6006,  1.8207,
          1.8207,  1.5964,  1.2591,  1.4583,  0.9123,  1.6482,  0.1817,  1.5394,
          1.8108,  0.8271,  1.3192,  1.0224,  0.7821,  1.1426,  1.6621,  1.7245,
          1.5243,  1.8250,  1.8250,  0.8739,  0.8546,  1.7941,  1.5952,  0.8746,
          1.7384,  1.2271,  1.8444,  1.7603, -0.0884, -0.3034, -0.3357, -0.1394,
          0.0839,  0.1482, -0.1958, 22.8720,  1.5072,  0.7332,  1.2831,  1.3448,
          1.5681,  0.9292,  1.5077,  0.3617,  1.6885,  1.7233],
        [ 1.2084,  1.2471,  1.3148,  1.2925,  1.2555,  1.2152,  1.1841,  1.2049,
          1.2049,  1.1776,  1.3066,  1.1948,  1.3449,  1.2565,  1.4070,  1.1847,
          1.2340,  1.2646,  1.2721,  1.2574,  1.3230,  1.2900,  1.2344,  1.2277,
          1.1228,  1.2168,  1.2168,  1.2877,  1.3350,  1.2340,  1.0160,  1.2437,
          1.1161,  1.2955,  1.1076,  1.2378,  1.2305,  0.9537,  1.2277,  1.2491,
          0.7926,  0.7247,  1.2541,  1.0523,  0.6037,  3.9517,  2.6920,  3.9238,
          3.0214,  2.2376,  1.8825,  3.1645,  3.8715,  1.8574]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 388 : 178.27561382209873
Test loss for epoch 388 : 178.9508406169005
Test Precision for epoch 388 : 0.26153846153846155
Test Recall for epoch 388 : 0.26153846153846155
Test F1 for epoch 388 : 0.26153846153846155


theta for epoch 389 : tensor([[ 2.9158,  2.9490,  3.0255,  3.1825,  3.1441,  2.9213,  3.1198,  2.9129,
          2.9129,  1.2217,  1.2460,  1.2330,  1.2712,  1.2135,  1.3131,  1.2264,
          1.1991,  1.2330,  1.1989,  1.1741,  1.1877,  1.2107,  1.1742,  1.1698,
          1.1872,  1.1627,  1.1627,  1.2049,  1.2510,  1.1839,  1.2085,  1.2509,
          1.1936,  1.2248,  1.1424,  1.1864,  1.4037,  1.4654,  1.4379,  1.4159,
          1.4467,  1.3944,  1.4179,  1.2962,  1.3993,  1.3155,  1.2601,  1.2471,
          1.2244,  1.3079,  1.2454,  1.3510,  1.2070,  1.2202],
        [ 1.1604,  1.1894,  1.2412,  1.2231,  1.1957,  1.1655,  1.1753,  1.1578,
          1.1578,  2.7702,  2.7998,  2.7844,  3.1416,  2.7605,  3.4946,  2.7757,
          3.0696,  3.3837,  1.1794,  1.2047,  1.1726,  1.1929,  1.1860,  1.1810,
          1.2005,  1.1728,  1.1728,  1.2361,  1.1887,  1.1930,  1.2212,  1.2360,
          1.2041,  1.2398,  1.1651,  1.1959,  1.3540,  1.4265,  1.3489,  1.3679,
          1.4045,  1.4181,  1.3255,  1.2270,  1.3484,  1.2744,  1.2606,  1.2456,
          1.2194,  1.2286,  1.2436,  1.2779,  1.1996,  1.2146],
        [ 1.1542,  1.1801,  1.2061,  1.2100,  1.1851,  1.1588,  1.1669,  1.1519,
          1.1519,  1.2267,  1.2514,  1.2382,  1.2771,  1.2183,  1.2620,  1.2314,
          1.1460,  1.2737,  2.9524,  3.2326,  3.1939,  2.9692,  2.8860,  2.8802,
          3.1832,  2.8719,  2.8719,  1.1901,  1.2461,  1.1890,  1.2131,  1.1910,
          1.1988,  1.2306,  1.1926,  1.1915,  1.4008,  1.4639,  1.4346,  1.3223,
          1.4435,  1.4248,  1.4153,  1.2907,  1.3046,  1.3195,  1.2640,  1.2507,
          1.2275,  1.3006,  1.2489,  1.3445,  1.1864,  1.2232],
        [ 1.1580,  1.1845,  1.2106,  1.2153,  1.1898,  1.1627,  1.1712,  1.1556,
          1.1556,  1.2299,  1.2553,  1.2417,  1.2672,  1.2212,  1.2637,  1.2348,
          1.2057,  1.2290,  1.2092,  1.1939,  1.2435,  1.2215,  1.1834,  1.1788,
          1.1746,  1.1714,  1.1714,  3.2581,  3.1223,  2.8465,  2.8789,  3.2566,
          2.8581,  3.0793,  2.8919,  2.8495,  1.3934,  1.4585,  1.4100,  1.3749,
          1.4387,  1.4190,  1.3890,  1.2792,  1.3573,  1.3236,  1.2657,  1.2028,
          1.1796,  1.3156,  1.2502,  1.3607,  1.1386,  1.2239],
        [ 1.7868,  1.4130,  0.6431,  0.9224,  1.3145,  1.7212,  1.6010,  1.8210,
          1.8210,  1.5968,  1.2596,  1.4588,  0.9128,  1.6486,  0.1823,  1.5398,
          1.8112,  0.8277,  1.3196,  1.0229,  0.7826,  1.1431,  1.6625,  1.7249,
          1.5247,  1.8254,  1.8254,  0.8744,  0.8551,  1.7944,  1.5956,  0.8751,
          1.7388,  1.2276,  1.8448,  1.7607, -0.0893, -0.3041, -0.3365, -0.1402,
          0.0830,  0.1472, -0.1966, 22.9183,  1.5044,  0.7333,  1.2829,  1.3446,
          1.5678,  0.9293,  1.5075,  0.3620,  1.6881,  1.7230],
        [ 1.2083,  1.2470,  1.3147,  1.2924,  1.2554,  1.2151,  1.1840,  1.2048,
          1.2048,  1.1774,  1.3065,  1.1947,  1.3447,  1.2563,  1.4070,  1.1846,
          1.2338,  1.2645,  1.2720,  1.2573,  1.3229,  1.2899,  1.2343,  1.2275,
          1.1227,  1.2166,  1.2166,  1.2876,  1.3349,  1.2338,  1.0158,  1.2436,
          1.1159,  1.2954,  1.1075,  1.2377,  1.2294,  0.9528,  1.2267,  1.2480,
          0.7918,  0.7239,  1.2531,  1.0509,  0.6029,  3.9596,  2.6945,  3.9313,
          3.0253,  2.2386,  1.8829,  3.1686,  3.8797,  1.8577]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 389 : 178.2712722426399
Test loss for epoch 389 : 178.94803304175258
Test Precision for epoch 389 : 0.26153846153846155
Test Recall for epoch 389 : 0.26153846153846155
Test F1 for epoch 389 : 0.26153846153846155


theta for epoch 390 : tensor([[ 2.9197,  2.9530,  3.0295,  3.1872,  3.1487,  2.9252,  3.1245,  2.9169,
          2.9169,  1.2216,  1.2459,  1.2329,  1.2710,  1.2134,  1.3129,  1.2263,
          1.1990,  1.2328,  1.1988,  1.1740,  1.1875,  1.2106,  1.1741,  1.1697,
          1.1871,  1.1626,  1.1626,  1.2047,  1.2508,  1.1838,  1.2084,  1.2507,
          1.1935,  1.2247,  1.1424,  1.1863,  1.4039,  1.4657,  1.4381,  1.4161,
          1.4469,  1.3946,  1.4181,  1.2964,  1.3997,  1.3156,  1.2602,  1.2472,
          1.2245,  1.3080,  1.2455,  1.3511,  1.2071,  1.2203],
        [ 1.1603,  1.1893,  1.2411,  1.2230,  1.1956,  1.1654,  1.1752,  1.1577,
          1.1577,  2.7748,  2.8043,  2.7889,  3.1475,  2.7650,  3.4954,  2.7802,
          3.0757,  3.3861,  1.1793,  1.2047,  1.1725,  1.1927,  1.1860,  1.1809,
          1.2004,  1.1728,  1.1728,  1.2360,  1.1886,  1.1930,  1.2211,  1.2359,
          1.2040,  1.2397,  1.1651,  1.1958,  1.3542,  1.4268,  1.3492,  1.3682,
          1.4048,  1.4184,  1.3258,  1.2273,  1.3488,  1.2745,  1.2607,  1.2457,
          1.2194,  1.2287,  1.2436,  1.2780,  1.1996,  1.2146],
        [ 1.1542,  1.1800,  1.2059,  1.2098,  1.1850,  1.1587,  1.1668,  1.1518,
          1.1518,  1.2266,  1.2513,  1.2381,  1.2769,  1.2182,  1.2617,  1.2314,
          1.1459,  1.2735,  2.9566,  3.2374,  3.1988,  2.9734,  2.8896,  2.8838,
          3.1880,  2.8755,  2.8755,  1.1900,  1.2459,  1.1889,  1.2130,  1.1909,
          1.1987,  1.2305,  1.1925,  1.1914,  1.4010,  1.4642,  1.4348,  1.3225,
          1.4438,  1.4251,  1.4155,  1.2910,  1.3049,  1.3196,  1.2640,  1.2508,
          1.2276,  1.3006,  1.2490,  1.3446,  1.1864,  1.2233],
        [ 1.1580,  1.1844,  1.2105,  1.2152,  1.1897,  1.1626,  1.1711,  1.1556,
          1.1556,  1.2298,  1.2552,  1.2416,  1.2670,  1.2212,  1.2635,  1.2347,
          1.2056,  1.2288,  1.2091,  1.1937,  1.2434,  1.2214,  1.1834,  1.1788,
          1.1745,  1.1714,  1.1714,  3.2636,  3.1264,  2.8501,  2.8825,  3.2620,
          2.8617,  3.0834,  2.8962,  2.8531,  1.3937,  1.4587,  1.4101,  1.3751,
          1.4389,  1.4193,  1.3891,  1.2795,  1.3577,  1.3237,  1.2658,  1.2029,
          1.1797,  1.3157,  1.2503,  1.3608,  1.1386,  1.2240],
        [ 1.7872,  1.4134,  0.6437,  0.9229,  1.3150,  1.7216,  1.6014,  1.8214,
          1.8214,  1.5972,  1.2601,  1.4592,  0.9133,  1.6490,  0.1830,  1.5402,
          1.8115,  0.8283,  1.3201,  1.0234,  0.7831,  1.1435,  1.6629,  1.7253,
          1.5252,  1.8258,  1.8258,  0.8749,  0.8556,  1.7948,  1.5961,  0.8756,
          1.7392,  1.2281,  1.8452,  1.7611, -0.0902, -0.3049, -0.3373, -0.1411,
          0.0821,  0.1463, -0.1974, 22.9644,  1.5016,  0.7334,  1.2828,  1.3444,
          1.5675,  0.9293,  1.5073,  0.3623,  1.6877,  1.7226],
        [ 1.2081,  1.2469,  1.3147,  1.2923,  1.2553,  1.2149,  1.1839,  1.2046,
          1.2046,  1.1773,  1.3063,  1.1945,  1.3446,  1.2561,  1.4069,  1.1844,
          1.2336,  1.2644,  1.2718,  1.2572,  1.3228,  1.2898,  1.2342,  1.2274,
          1.1225,  1.2165,  1.2165,  1.2875,  1.3348,  1.2336,  1.0157,  1.2435,
          1.1158,  1.2953,  1.1073,  1.2375,  1.2283,  0.9520,  1.2257,  1.2469,
          0.7910,  0.7232,  1.2520,  1.0496,  0.6021,  3.9676,  2.6969,  3.9387,
          3.0292,  2.2395,  1.8832,  3.1725,  3.8878,  1.8581]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 390 : 178.2669837011178
Test loss for epoch 390 : 178.94527271805472
Test Precision for epoch 390 : 0.26153846153846155
Test Recall for epoch 390 : 0.26153846153846155
Test F1 for epoch 390 : 0.26153846153846155


theta for epoch 391 : tensor([[ 2.9236,  2.9569,  3.0334,  3.1918,  3.1533,  2.9291,  3.1291,  2.9208,
          2.9208,  1.2216,  1.2458,  1.2328,  1.2709,  1.2133,  1.3127,  1.2262,
          1.1990,  1.2327,  1.1987,  1.1738,  1.1873,  1.2104,  1.1740,  1.1696,
          1.1870,  1.1625,  1.1625,  1.2046,  1.2507,  1.1838,  1.2083,  1.2506,
          1.1934,  1.2246,  1.1423,  1.1863,  1.4041,  1.4659,  1.4383,  1.4164,
          1.4472,  1.3949,  1.4183,  1.2967,  1.4000,  1.3158,  1.2603,  1.2473,
          1.2245,  1.3081,  1.2455,  1.3513,  1.2072,  1.2203],
        [ 1.1602,  1.1892,  1.2409,  1.2229,  1.1955,  1.1653,  1.1751,  1.1576,
          1.1576,  2.7792,  2.8087,  2.7933,  3.1533,  2.7693,  3.4964,  2.7846,
          3.0816,  3.3887,  1.1792,  1.2046,  1.1724,  1.1926,  1.1859,  1.1808,
          1.2003,  1.1727,  1.1727,  1.2359,  1.1885,  1.1929,  1.2210,  1.2359,
          1.2040,  1.2396,  1.1650,  1.1957,  1.3545,  1.4270,  1.3495,  1.3684,
          1.4051,  1.4187,  1.3262,  1.2276,  1.3492,  1.2746,  1.2607,  1.2457,
          1.2195,  1.2288,  1.2437,  1.2781,  1.1996,  1.2146],
        [ 1.1541,  1.1798,  1.2058,  1.2097,  1.1849,  1.1586,  1.1667,  1.1517,
          1.1517,  1.2265,  1.2512,  1.2380,  1.2768,  1.2181,  1.2615,  1.2313,
          1.1458,  1.2734,  2.9607,  3.2422,  3.2038,  2.9776,  2.8932,  2.8874,
          3.1928,  2.8791,  2.8791,  1.1898,  1.2457,  1.1888,  1.2130,  1.1907,
          1.1987,  1.2304,  1.1924,  1.1914,  1.4012,  1.4644,  1.4350,  1.3227,
          1.4441,  1.4254,  1.4157,  1.2913,  1.3052,  1.3198,  1.2641,  1.2509,
          1.2277,  1.3007,  1.2491,  1.3447,  1.1865,  1.2234],
        [ 1.1579,  1.1843,  1.2103,  1.2151,  1.1896,  1.1625,  1.1710,  1.1555,
          1.1555,  1.2298,  1.2551,  1.2415,  1.2668,  1.2211,  1.2633,  1.2346,
          1.2056,  1.2287,  1.2090,  1.1935,  1.2432,  1.2213,  1.1833,  1.1787,
          1.1744,  1.1713,  1.1713,  3.2690,  3.1304,  2.8537,  2.8860,  3.2674,
          2.8653,  3.0874,  2.9005,  2.8567,  1.3939,  1.4590,  1.4102,  1.3753,
          1.4392,  1.4195,  1.3892,  1.2798,  1.3580,  1.3239,  1.2659,  1.2030,
          1.1798,  1.3158,  1.2504,  1.3609,  1.1386,  1.2240],
        [ 1.7876,  1.4138,  0.6442,  0.9234,  1.3155,  1.7220,  1.6018,  1.8218,
          1.8218,  1.5976,  1.2605,  1.4597,  0.9138,  1.6494,  0.1836,  1.5407,
          1.8119,  0.8288,  1.3205,  1.0239,  0.7837,  1.1440,  1.6633,  1.7257,
          1.5257,  1.8262,  1.8262,  0.8754,  0.8561,  1.7952,  1.5965,  0.8761,
          1.7396,  1.2285,  1.8455,  1.7615, -0.0910, -0.3057, -0.3382, -0.1420,
          0.0811,  0.1454, -0.1983, 23.0102,  1.4987,  0.7335,  1.2827,  1.3442,
          1.5671,  0.9294,  1.5071,  0.3625,  1.6873,  1.7223],
        [ 1.2080,  1.2468,  1.3146,  1.2922,  1.2552,  1.2148,  1.1837,  1.2044,
          1.2044,  1.1771,  1.3062,  1.1944,  1.3445,  1.2560,  1.4068,  1.1843,
          1.2334,  1.2643,  1.2717,  1.2571,  1.3227,  1.2897,  1.2340,  1.2272,
          1.1224,  1.2163,  1.2163,  1.2874,  1.3347,  1.2335,  1.0156,  1.2434,
          1.1156,  1.2951,  1.1071,  1.2373,  1.2272,  0.9512,  1.2247,  1.2458,
          0.7902,  0.7224,  1.2509,  1.0482,  0.6013,  3.9755,  2.6992,  3.9461,
          3.0330,  2.2403,  1.8836,  3.1765,  3.8959,  1.8584]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 391 : 178.26274657098662
Test loss for epoch 391 : 178.9425420123572
Test Precision for epoch 391 : 0.26153846153846155
Test Recall for epoch 391 : 0.26153846153846155
Test F1 for epoch 391 : 0.26153846153846155


theta for epoch 392 : tensor([[ 2.9275,  2.9607,  3.0372,  3.1964,  3.1579,  2.9330,  3.1337,  2.9246,
          2.9246,  1.2215,  1.2457,  1.2327,  1.2707,  1.2132,  1.3125,  1.2261,
          1.1989,  1.2325,  1.1985,  1.1737,  1.1872,  1.2103,  1.1739,  1.1695,
          1.1868,  1.1624,  1.1624,  1.2044,  1.2505,  1.1837,  1.2082,  1.2504,
          1.1933,  1.2244,  1.1422,  1.1862,  1.4043,  1.4661,  1.4385,  1.4166,
          1.4474,  1.3951,  1.4185,  1.2969,  1.4004,  1.3159,  1.2604,  1.2474,
          1.2246,  1.3082,  1.2456,  1.3514,  1.2072,  1.2204],
        [ 1.1601,  1.1890,  1.2407,  1.2227,  1.1954,  1.1652,  1.1750,  1.1576,
          1.1576,  2.7836,  2.8131,  2.7975,  3.1591,  2.7736,  3.4976,  2.7889,
          3.0874,  3.3914,  1.1791,  1.2045,  1.1722,  1.1925,  1.1858,  1.1807,
          1.2002,  1.1726,  1.1726,  1.2358,  1.1884,  1.1928,  1.2209,  1.2358,
          1.2039,  1.2395,  1.1650,  1.1957,  1.3547,  1.4273,  1.3498,  1.3686,
          1.4054,  1.4190,  1.3265,  1.2279,  1.3496,  1.2746,  1.2608,  1.2458,
          1.2195,  1.2289,  1.2437,  1.2782,  1.1996,  1.2147],
        [ 1.1540,  1.1797,  1.2056,  1.2095,  1.1848,  1.1585,  1.1666,  1.1517,
          1.1517,  1.2264,  1.2511,  1.2379,  1.2766,  1.2180,  1.2613,  1.2312,
          1.1457,  1.2732,  2.9649,  3.2470,  3.2087,  2.9817,  2.8968,  2.8910,
          3.1975,  2.8827,  2.8827,  1.1897,  1.2456,  1.1887,  1.2129,  1.1906,
          1.1986,  1.2303,  1.1923,  1.1913,  1.4014,  1.4646,  1.4352,  1.3229,
          1.4443,  1.4256,  1.4159,  1.2915,  1.3055,  1.3199,  1.2642,  1.2510,
          1.2277,  1.3008,  1.2492,  1.3448,  1.1866,  1.2234],
        [ 1.1578,  1.1842,  1.2101,  1.2149,  1.1895,  1.1624,  1.1709,  1.1554,
          1.1554,  1.2297,  1.2550,  1.2414,  1.2666,  1.2211,  1.2630,  1.2346,
          1.2056,  1.2285,  1.2089,  1.1933,  1.2431,  1.2212,  1.1832,  1.1786,
          1.1743,  1.1712,  1.1712,  3.2743,  3.1344,  2.8572,  2.8894,  3.2728,
          2.8688,  3.0913,  2.9047,  2.8602,  1.3941,  1.4592,  1.4104,  1.3755,
          1.4395,  1.4198,  1.3893,  1.2801,  1.3584,  1.3240,  1.2660,  1.2031,
          1.1798,  1.3160,  1.2505,  1.3611,  1.1386,  1.2241],
        [ 1.7880,  1.4143,  0.6448,  0.9239,  1.3159,  1.7224,  1.6022,  1.8222,
          1.8222,  1.5981,  1.2610,  1.4601,  0.9144,  1.6498,  0.1843,  1.5411,
          1.8123,  0.8294,  1.3210,  1.0244,  0.7842,  1.1445,  1.6637,  1.7261,
          1.5261,  1.8266,  1.8266,  0.8759,  0.8566,  1.7956,  1.5969,  0.8767,
          1.7400,  1.2290,  1.8459,  1.7618, -0.0919, -0.3065, -0.3390, -0.1429,
          0.0802,  0.1444, -0.1992, 23.0558,  1.4958,  0.7336,  1.2825,  1.3440,
          1.5668,  0.9295,  1.5069,  0.3628,  1.6869,  1.7220],
        [ 1.2078,  1.2467,  1.3145,  1.2921,  1.2551,  1.2146,  1.1836,  1.2043,
          1.2043,  1.1769,  1.3060,  1.1942,  1.3443,  1.2558,  1.4067,  1.1841,
          1.2332,  1.2642,  1.2716,  1.2570,  1.3227,  1.2896,  1.2339,  1.2271,
          1.1223,  1.2162,  1.2162,  1.2873,  1.3346,  1.2333,  1.0155,  1.2433,
          1.1155,  1.2950,  1.1070,  1.2372,  1.2261,  0.9504,  1.2236,  1.2448,
          0.7894,  0.7216,  1.2498,  1.0468,  0.6005,  3.9833,  2.7015,  3.9536,
          3.0368,  2.2411,  1.8839,  3.1803,  3.9039,  1.8587]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 392 : 178.2585607209452
Test loss for epoch 392 : 178.93985911364322
Test Precision for epoch 392 : 0.26153846153846155
Test Recall for epoch 392 : 0.26153846153846155
Test F1 for epoch 392 : 0.26153846153846155


theta for epoch 393 : tensor([[ 2.9313,  2.9645,  3.0411,  3.2009,  3.1625,  2.9368,  3.1382,  2.9284,
          2.9284,  1.2214,  1.2455,  1.2326,  1.2706,  1.2131,  1.3123,  1.2260,
          1.1988,  1.2324,  1.1984,  1.1735,  1.1870,  1.2102,  1.1738,  1.1694,
          1.1867,  1.1624,  1.1624,  1.2043,  1.2504,  1.1836,  1.2081,  1.2502,
          1.1932,  1.2243,  1.1421,  1.1861,  1.4045,  1.4663,  1.4387,  1.4168,
          1.4477,  1.3954,  1.4187,  1.2972,  1.4007,  1.3160,  1.2605,  1.2475,
          1.2247,  1.3083,  1.2457,  1.3515,  1.2073,  1.2205],
        [ 1.1601,  1.1889,  1.2405,  1.2226,  1.1952,  1.1651,  1.1749,  1.1575,
          1.1575,  2.7878,  2.8173,  2.8017,  3.1647,  2.7778,  3.4989,  2.7932,
          3.0932,  3.3943,  1.1790,  1.2044,  1.1721,  1.1924,  1.1857,  1.1806,
          1.2001,  1.1726,  1.1726,  1.2357,  1.1883,  1.1927,  1.2208,  1.2357,
          1.2038,  1.2393,  1.1650,  1.1956,  1.3550,  1.4275,  1.3501,  1.3689,
          1.4057,  1.4193,  1.3268,  1.2283,  1.3500,  1.2747,  1.2608,  1.2459,
          1.2195,  1.2290,  1.2438,  1.2783,  1.1997,  1.2147],
        [ 1.1539,  1.1796,  1.2055,  1.2094,  1.1846,  1.1584,  1.1665,  1.1516,
          1.1516,  1.2264,  1.2510,  1.2378,  1.2765,  1.2180,  1.2610,  1.2311,
          1.1456,  1.2730,  2.9689,  3.2517,  3.2135,  2.9858,  2.9003,  2.8945,
          3.2022,  2.8862,  2.8862,  1.1895,  1.2454,  1.1887,  1.2128,  1.1904,
          1.1985,  1.2302,  1.1922,  1.1912,  1.4016,  1.4649,  1.4354,  1.3231,
          1.4446,  1.4259,  1.4161,  1.2918,  1.3058,  1.3200,  1.2643,  1.2511,
          1.2278,  1.3009,  1.2492,  1.3449,  1.1866,  1.2235],
        [ 1.1578,  1.1841,  1.2099,  1.2148,  1.1894,  1.1624,  1.1709,  1.1554,
          1.1554,  1.2296,  1.2549,  1.2413,  1.2664,  1.2210,  1.2628,  1.2345,
          1.2055,  1.2283,  1.2088,  1.1931,  1.2429,  1.2211,  1.1832,  1.1785,
          1.1742,  1.1712,  1.1712,  3.2796,  3.1383,  2.8607,  2.8928,  3.2781,
          2.8723,  3.0953,  2.9089,  2.8637,  1.3944,  1.4595,  1.4105,  1.3756,
          1.4398,  1.4200,  1.3894,  1.2804,  1.3587,  1.3241,  1.2661,  1.2032,
          1.1799,  1.3161,  1.2506,  1.3612,  1.1387,  1.2242],
        [ 1.7884,  1.4147,  0.6453,  0.9244,  1.3164,  1.7228,  1.6027,  1.8226,
          1.8226,  1.5985,  1.2615,  1.4606,  0.9149,  1.6503,  0.1850,  1.5416,
          1.8127,  0.8299,  1.3214,  1.0250,  0.7847,  1.1450,  1.6641,  1.7265,
          1.5266,  1.8270,  1.8270,  0.8764,  0.8572,  1.7960,  1.5974,  0.8772,
          1.7404,  1.2295,  1.8463,  1.7622, -0.0928, -0.3073, -0.3398, -0.1438,
          0.0793,  0.1434, -0.2000, 23.1012,  1.4928,  0.7338,  1.2824,  1.3438,
          1.5665,  0.9295,  1.5067,  0.3631,  1.6866,  1.7216],
        [ 1.2077,  1.2465,  1.3144,  1.2921,  1.2550,  1.2145,  1.1835,  1.2041,
          1.2041,  1.1768,  1.3058,  1.1941,  1.3442,  1.2556,  1.4066,  1.1839,
          1.2330,  1.2641,  1.2715,  1.2569,  1.3226,  1.2895,  1.2337,  1.2269,
          1.1221,  1.2160,  1.2160,  1.2872,  1.3345,  1.2331,  1.0153,  1.2432,
          1.1153,  1.2949,  1.1068,  1.2370,  1.2250,  0.9495,  1.2226,  1.2437,
          0.7886,  0.7209,  1.2487,  1.0453,  0.5996,  3.9912,  2.7036,  3.9610,
          3.0405,  2.2419,  1.8842,  3.1841,  3.9120,  1.8590]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 393 : 178.25442560328085
Test loss for epoch 393 : 178.93720375525666
Test Precision for epoch 393 : 0.26153846153846155
Test Recall for epoch 393 : 0.26153846153846155
Test F1 for epoch 393 : 0.26153846153846155


theta for epoch 394 : tensor([[ 2.9351,  2.9683,  3.0448,  3.2054,  3.1670,  2.9405,  3.1427,  2.9322,
          2.9322,  1.2213,  1.2454,  1.2325,  1.2704,  1.2131,  1.3121,  1.2259,
          1.1988,  1.2322,  1.1983,  1.1734,  1.1868,  1.2100,  1.1737,  1.1693,
          1.1866,  1.1623,  1.1623,  1.2041,  1.2502,  1.1835,  1.2080,  1.2501,
          1.1931,  1.2242,  1.1420,  1.1860,  1.4048,  1.4666,  1.4389,  1.4170,
          1.4479,  1.3956,  1.4189,  1.2974,  1.4010,  1.3161,  1.2606,  1.2476,
          1.2247,  1.3084,  1.2458,  1.3516,  1.2074,  1.2205],
        [ 1.1600,  1.1888,  1.2404,  1.2224,  1.1951,  1.1651,  1.1748,  1.1574,
          1.1574,  2.7920,  2.8215,  2.8059,  3.1702,  2.7820,  3.5004,  2.7974,
          3.0989,  3.3972,  1.1789,  1.2043,  1.1719,  1.1922,  1.1856,  1.1805,
          1.2000,  1.1725,  1.1725,  1.2356,  1.1881,  1.1927,  1.2207,  1.2356,
          1.2037,  1.2392,  1.1650,  1.1955,  1.3553,  1.4278,  1.3504,  1.3691,
          1.4060,  1.4196,  1.3271,  1.2286,  1.3504,  1.2748,  1.2609,  1.2459,
          1.2196,  1.2291,  1.2438,  1.2784,  1.1997,  1.2147],
        [ 1.1538,  1.1795,  1.2053,  1.2093,  1.1845,  1.1583,  1.1664,  1.1515,
          1.1515,  1.2263,  1.2509,  1.2377,  1.2764,  1.2179,  1.2608,  1.2310,
          1.1455,  1.2728,  2.9729,  3.2563,  3.2183,  2.9898,  2.9038,  2.8980,
          3.2069,  2.8897,  2.8897,  1.1894,  1.2452,  1.1886,  1.2127,  1.1902,
          1.1984,  1.2300,  1.1921,  1.1911,  1.4019,  1.4651,  1.4356,  1.3232,
          1.4449,  1.4262,  1.4163,  1.2920,  1.3062,  1.3202,  1.2644,  1.2512,
          1.2279,  1.3010,  1.2493,  1.3450,  1.1867,  1.2236],
        [ 1.1577,  1.1840,  1.2098,  1.2147,  1.1893,  1.1623,  1.1708,  1.1553,
          1.1553,  1.2296,  1.2548,  1.2413,  1.2662,  1.2210,  1.2626,  1.2344,
          1.2055,  1.2282,  1.2087,  1.1929,  1.2428,  1.2210,  1.1831,  1.1785,
          1.1741,  1.1711,  1.1711,  3.2849,  3.1422,  2.8641,  2.8962,  3.2834,
          2.8758,  3.0992,  2.9130,  2.8671,  1.3946,  1.4597,  1.4106,  1.3758,
          1.4401,  1.4203,  1.3896,  1.2807,  1.3591,  1.3243,  1.2662,  1.2033,
          1.1800,  1.3162,  1.2507,  1.3614,  1.1387,  1.2243],
        [ 1.7888,  1.4152,  0.6459,  0.9250,  1.3169,  1.7233,  1.6031,  1.8230,
          1.8230,  1.5990,  1.2620,  1.4611,  0.9154,  1.6507,  0.1857,  1.5420,
          1.8131,  0.8305,  1.3219,  1.0255,  0.7853,  1.1455,  1.6646,  1.7269,
          1.5271,  1.8274,  1.8274,  0.8769,  0.8577,  1.7964,  1.5978,  0.8777,
          1.7408,  1.2299,  1.8467,  1.7627, -0.0937, -0.3081, -0.3406, -0.1447,
          0.0783,  0.1425, -0.2009, 23.1463,  1.4899,  0.7339,  1.2822,  1.3436,
          1.5662,  0.9296,  1.5064,  0.3634,  1.6862,  1.7213],
        [ 1.2075,  1.2464,  1.3144,  1.2920,  1.2548,  1.2143,  1.1833,  1.2040,
          1.2040,  1.1766,  1.3057,  1.1939,  1.3441,  1.2554,  1.4065,  1.1838,
          1.2328,  1.2640,  1.2714,  1.2568,  1.3225,  1.2894,  1.2336,  1.2268,
          1.1220,  1.2158,  1.2158,  1.2871,  1.3344,  1.2329,  1.0152,  1.2431,
          1.1151,  1.2948,  1.1066,  1.2368,  1.2238,  0.9487,  1.2215,  1.2426,
          0.7877,  0.7201,  1.2476,  1.0439,  0.5988,  3.9990,  2.7057,  3.9684,
          3.0441,  2.2426,  1.8845,  3.1878,  3.9200,  1.8592]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 394 : 178.25033974530584
Test loss for epoch 394 : 178.93459365362668
Test Precision for epoch 394 : 0.26153846153846155
Test Recall for epoch 394 : 0.26153846153846155
Test F1 for epoch 394 : 0.26153846153846155


theta for epoch 395 : tensor([[ 2.9388,  2.9721,  3.0486,  3.2099,  3.1714,  2.9443,  3.1472,  2.9359,
          2.9359,  1.2212,  1.2453,  1.2324,  1.2703,  1.2130,  1.3119,  1.2258,
          1.1987,  1.2321,  1.1982,  1.1732,  1.1866,  1.2099,  1.1736,  1.1692,
          1.1865,  1.1622,  1.1622,  1.2039,  1.2501,  1.1834,  1.2079,  1.2499,
          1.1931,  1.2241,  1.1419,  1.1859,  1.4050,  1.4668,  1.4391,  1.4172,
          1.4482,  1.3958,  1.4190,  1.2977,  1.4014,  1.3162,  1.2607,  1.2477,
          1.2248,  1.3085,  1.2459,  1.3518,  1.2074,  1.2206],
        [ 1.1599,  1.1887,  1.2402,  1.2223,  1.1950,  1.1650,  1.1747,  1.1573,
          1.1573,  2.7961,  2.8256,  2.8099,  3.1757,  2.7860,  3.5020,  2.8015,
          3.1044,  3.4002,  1.1788,  1.2042,  1.1718,  1.1921,  1.1855,  1.1805,
          1.1999,  1.1724,  1.1724,  1.2355,  1.1880,  1.1926,  1.2206,  1.2355,
          1.2036,  1.2391,  1.1650,  1.1954,  1.3555,  1.4281,  1.3507,  1.3694,
          1.4063,  1.4199,  1.3274,  1.2289,  1.3508,  1.2749,  1.2610,  1.2460,
          1.2196,  1.2292,  1.2439,  1.2785,  1.1997,  1.2148],
        [ 1.1537,  1.1794,  1.2051,  1.2091,  1.1844,  1.1582,  1.1663,  1.1514,
          1.1514,  1.2262,  1.2508,  1.2376,  1.2762,  1.2178,  1.2606,  1.2309,
          1.1454,  1.2727,  2.9769,  3.2610,  3.2231,  2.9938,  2.9073,  2.9015,
          3.2115,  2.8932,  2.8932,  1.1892,  1.2450,  1.1885,  1.2126,  1.1901,
          1.1983,  1.2299,  1.1921,  1.1910,  1.4021,  1.4653,  1.4358,  1.3234,
          1.4452,  1.4265,  1.4165,  1.2923,  1.3065,  1.3203,  1.2645,  1.2513,
          1.2279,  1.3010,  1.2494,  1.3451,  1.1868,  1.2236],
        [ 1.1576,  1.1839,  1.2096,  1.2145,  1.1892,  1.1622,  1.1707,  1.1552,
          1.1552,  1.2295,  1.2547,  1.2412,  1.2660,  1.2209,  1.2624,  1.2343,
          1.2054,  1.2280,  1.2086,  1.1927,  1.2426,  1.2208,  1.1830,  1.1784,
          1.1740,  1.1710,  1.1710,  3.2902,  3.1461,  2.8675,  2.8995,  3.2887,
          2.8792,  3.1031,  2.9171,  2.8705,  1.3948,  1.4599,  1.4107,  1.3760,
          1.4404,  1.4205,  1.3897,  1.2810,  1.3594,  1.3244,  1.2663,  1.2034,
          1.1800,  1.3163,  1.2508,  1.3615,  1.1387,  1.2243],
        [ 1.7892,  1.4157,  0.6465,  0.9255,  1.3173,  1.7237,  1.6036,  1.8234,
          1.8234,  1.5994,  1.2625,  1.4616,  0.9160,  1.6511,  0.1863,  1.5425,
          1.8136,  0.8311,  1.3224,  1.0260,  0.7858,  1.1460,  1.6650,  1.7274,
          1.5275,  1.8278,  1.8278,  0.8775,  0.8582,  1.7968,  1.5983,  0.8782,
          1.7413,  1.2304,  1.8471,  1.7631, -0.0946, -0.3089, -0.3414, -0.1456,
          0.0774,  0.1415, -0.2018, 23.1912,  1.4869,  0.7340,  1.2821,  1.3435,
          1.5659,  0.9297,  1.5062,  0.3637,  1.6858,  1.7210],
        [ 1.2074,  1.2463,  1.3143,  1.2919,  1.2547,  1.2142,  1.1832,  1.2038,
          1.2038,  1.1764,  1.3055,  1.1937,  1.3439,  1.2552,  1.4064,  1.1836,
          1.2325,  1.2639,  1.2712,  1.2567,  1.3224,  1.2892,  1.2334,  1.2266,
          1.1219,  1.2157,  1.2157,  1.2869,  1.3343,  1.2328,  1.0151,  1.2430,
          1.1150,  1.2947,  1.1064,  1.2366,  1.2227,  0.9479,  1.2205,  1.2414,
          0.7869,  0.7193,  1.2465,  1.0425,  0.5980,  4.0068,  2.7078,  3.9758,
          3.0476,  2.2433,  1.8847,  3.1914,  3.9280,  1.8595]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 395 : 178.2463019349253
Test loss for epoch 395 : 178.93201055167603
Test Precision for epoch 395 : 0.26153846153846155
Test Recall for epoch 395 : 0.26153846153846155
Test F1 for epoch 395 : 0.26153846153846155


theta for epoch 396 : tensor([[ 2.9425,  2.9758,  3.0523,  3.2144,  3.1759,  2.9480,  3.1516,  2.9396,
          2.9396,  1.2211,  1.2452,  1.2323,  1.2701,  1.2129,  1.3117,  1.2257,
          1.1986,  1.2319,  1.1980,  1.1731,  1.1865,  1.2097,  1.1735,  1.1691,
          1.1864,  1.1621,  1.1621,  1.2038,  1.2499,  1.1833,  1.2078,  1.2498,
          1.1930,  1.2239,  1.1418,  1.1858,  1.4052,  1.4670,  1.4392,  1.4174,
          1.4484,  1.3961,  1.4192,  1.2980,  1.4017,  1.3164,  1.2608,  1.2478,
          1.2249,  1.3087,  1.2459,  1.3519,  1.2075,  1.2207],
        [ 1.1598,  1.1886,  1.2400,  1.2222,  1.1948,  1.1649,  1.1746,  1.1572,
          1.1572,  2.8002,  2.8297,  2.8139,  3.1811,  2.7900,  3.5037,  2.8055,
          3.1100,  3.4034,  1.1787,  1.2041,  1.1717,  1.1920,  1.1854,  1.1804,
          1.1998,  1.1723,  1.1723,  1.2354,  1.1879,  1.1925,  1.2205,  1.2354,
          1.2035,  1.2390,  1.1649,  1.1954,  1.3558,  1.4283,  1.3510,  1.3696,
          1.4066,  1.4202,  1.3277,  1.2293,  1.3512,  1.2750,  1.2610,  1.2460,
          1.2197,  1.2293,  1.2440,  1.2786,  1.1998,  1.2148],
        [ 1.1536,  1.1793,  1.2050,  1.2090,  1.1843,  1.1581,  1.1662,  1.1513,
          1.1513,  1.2261,  1.2506,  1.2375,  1.2760,  1.2177,  1.2604,  1.2308,
          1.1453,  1.2725,  2.9809,  3.2656,  3.2278,  2.9977,  2.9107,  2.9049,
          3.2161,  2.8966,  2.8966,  1.1891,  1.2448,  1.1884,  1.2125,  1.1899,
          1.1982,  1.2298,  1.1920,  1.1909,  1.4023,  1.4655,  1.4360,  1.3236,
          1.4454,  1.4267,  1.4167,  1.2926,  1.3068,  1.3204,  1.2646,  1.2513,
          1.2280,  1.3011,  1.2495,  1.3452,  1.1868,  1.2237],
        [ 1.1575,  1.1838,  1.2094,  1.2144,  1.1891,  1.1621,  1.1706,  1.1551,
          1.1551,  1.2294,  1.2546,  1.2411,  1.2659,  1.2208,  1.2621,  1.2342,
          1.2054,  1.2278,  1.2085,  1.1925,  1.2425,  1.2207,  1.1829,  1.1783,
          1.1739,  1.1710,  1.1710,  3.2954,  3.1500,  2.8709,  2.9028,  3.2939,
          2.8825,  3.1069,  2.9211,  2.8739,  1.3951,  1.4602,  1.4108,  1.3762,
          1.4406,  1.4208,  1.3898,  1.2812,  1.3597,  1.3245,  1.2664,  1.2035,
          1.1801,  1.3165,  1.2509,  1.3616,  1.1387,  1.2244],
        [ 1.7896,  1.4161,  0.6470,  0.9260,  1.3178,  1.7241,  1.6040,  1.8238,
          1.8238,  1.5999,  1.2630,  1.4620,  0.9165,  1.6516,  0.1870,  1.5430,
          1.8140,  0.8317,  1.3229,  1.0265,  0.7863,  1.1465,  1.6654,  1.7278,
          1.5280,  1.8282,  1.8282,  0.8780,  0.8587,  1.7972,  1.5987,  0.8788,
          1.7417,  1.2309,  1.8475,  1.7635, -0.0956, -0.3098, -0.3423, -0.1465,
          0.0764,  0.1405, -0.2026, 23.2359,  1.4840,  0.7341,  1.2820,  1.3433,
          1.5656,  0.9298,  1.5060,  0.3640,  1.6854,  1.7206],
        [ 1.2072,  1.2462,  1.3142,  1.2918,  1.2546,  1.2141,  1.1831,  1.2037,
          1.2037,  1.1763,  1.3054,  1.1936,  1.3438,  1.2550,  1.4063,  1.1834,
          1.2323,  1.2638,  1.2711,  1.2566,  1.3223,  1.2891,  1.2333,  1.2264,
          1.1217,  1.2155,  1.2155,  1.2868,  1.3342,  1.2326,  1.0149,  1.2429,
          1.1148,  1.2945,  1.1063,  1.2365,  1.2216,  0.9470,  1.2195,  1.2403,
          0.7861,  0.7185,  1.2454,  1.0411,  0.5972,  4.0146,  2.7097,  3.9832,
          3.0511,  2.2440,  1.8850,  3.1950,  3.9360,  1.8597]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 396 : 178.24231240754355
Test loss for epoch 396 : 178.92946958006257
Test Precision for epoch 396 : 0.26153846153846155
Test Recall for epoch 396 : 0.26153846153846155
Test F1 for epoch 396 : 0.26153846153846155


theta for epoch 397 : tensor([[ 2.9462,  2.9794,  3.0559,  3.2188,  3.1803,  2.9516,  3.1560,  2.9433,
          2.9433,  1.2210,  1.2450,  1.2322,  1.2699,  1.2128,  1.3115,  1.2256,
          1.1985,  1.2317,  1.1979,  1.1729,  1.1863,  1.2096,  1.1734,  1.1690,
          1.1863,  1.1620,  1.1620,  1.2036,  1.2497,  1.1832,  1.2077,  1.2496,
          1.1929,  1.2238,  1.1417,  1.1857,  1.4054,  1.4672,  1.4394,  1.4175,
          1.4487,  1.3963,  1.4194,  1.2982,  1.4020,  1.3165,  1.2608,  1.2479,
          1.2249,  1.3088,  1.2460,  1.3520,  1.2075,  1.2207],
        [ 1.1597,  1.1885,  1.2399,  1.2220,  1.1947,  1.1648,  1.1745,  1.1571,
          1.1571,  2.8041,  2.8336,  2.8178,  3.1864,  2.7939,  3.5056,  2.8094,
          3.1154,  3.4066,  1.1786,  1.2040,  1.1715,  1.1919,  1.1853,  1.1803,
          1.1997,  1.1723,  1.1723,  1.2353,  1.1878,  1.1924,  1.2204,  1.2353,
          1.2035,  1.2388,  1.1649,  1.1953,  1.3561,  1.4286,  1.3513,  1.3699,
          1.4069,  1.4205,  1.3281,  1.2296,  1.3516,  1.2750,  1.2611,  1.2461,
          1.2197,  1.2293,  1.2440,  1.2787,  1.1998,  1.2148],
        [ 1.1535,  1.1792,  1.2048,  1.2088,  1.1842,  1.1580,  1.1661,  1.1512,
          1.1512,  1.2260,  1.2505,  1.2374,  1.2759,  1.2176,  1.2601,  1.2307,
          1.1452,  1.2723,  2.9848,  3.2702,  3.2326,  3.0016,  2.9141,  2.9083,
          3.2207,  2.9000,  2.9000,  1.1889,  1.2447,  1.1883,  1.2124,  1.1898,
          1.1981,  1.2297,  1.1919,  1.1909,  1.4025,  1.4657,  1.4362,  1.3238,
          1.4457,  1.4270,  1.4169,  1.2928,  1.3071,  1.3205,  1.2647,  1.2514,
          1.2281,  1.3012,  1.2496,  1.3453,  1.1869,  1.2237],
        [ 1.1574,  1.1837,  1.2092,  1.2143,  1.1890,  1.1620,  1.1705,  1.1551,
          1.1551,  1.2293,  1.2545,  1.2410,  1.2657,  1.2207,  1.2619,  1.2342,
          1.2053,  1.2276,  1.2084,  1.1923,  1.2423,  1.2206,  1.1828,  1.1782,
          1.1738,  1.1709,  1.1709,  3.3006,  3.1539,  2.8742,  2.9061,  3.2991,
          2.8859,  3.1107,  2.9251,  2.8772,  1.3953,  1.4604,  1.4110,  1.3764,
          1.4409,  1.4210,  1.3900,  1.2815,  1.3600,  1.3246,  1.2665,  1.2036,
          1.1801,  1.3166,  1.2509,  1.3618,  1.1387,  1.2245],
        [ 1.7900,  1.4166,  0.6476,  0.9265,  1.3183,  1.7245,  1.6045,  1.8242,
          1.8242,  1.6004,  1.2635,  1.4625,  0.9171,  1.6521,  0.1877,  1.5434,
          1.8144,  0.8322,  1.3233,  1.0271,  0.7869,  1.1469,  1.6659,  1.7282,
          1.5285,  1.8286,  1.8286,  0.8785,  0.8593,  1.7976,  1.5992,  0.8793,
          1.7421,  1.2314,  1.8479,  1.7639, -0.0965, -0.3106, -0.3431, -0.1474,
          0.0755,  0.1395, -0.2035, 23.2803,  1.4810,  0.7343,  1.2819,  1.3431,
          1.5653,  0.9298,  1.5058,  0.3643,  1.6851,  1.7203],
        [ 1.2071,  1.2461,  1.3141,  1.2917,  1.2545,  1.2139,  1.1829,  1.2035,
          1.2035,  1.1761,  1.3052,  1.1934,  1.3437,  1.2548,  1.4062,  1.1833,
          1.2321,  1.2637,  1.2710,  1.2565,  1.3222,  1.2890,  1.2331,  1.2263,
          1.1216,  1.2153,  1.2153,  1.2867,  1.3341,  1.2324,  1.0148,  1.2428,
          1.1147,  1.2944,  1.1061,  1.2363,  1.2204,  0.9462,  1.2184,  1.2392,
          0.7853,  0.7178,  1.2443,  1.0397,  0.5964,  4.0224,  2.7117,  3.9906,
          3.0545,  2.2447,  1.8853,  3.1985,  3.9439,  1.8599]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 397 : 178.23836850885374
Test loss for epoch 397 : 178.92695151947055
Test Precision for epoch 397 : 0.26153846153846155
Test Recall for epoch 397 : 0.26153846153846155
Test F1 for epoch 397 : 0.26153846153846155


theta for epoch 398 : tensor([[ 2.9498,  2.9831,  3.0596,  3.2232,  3.1847,  2.9553,  3.1604,  2.9469,
          2.9469,  1.2209,  1.2449,  1.2320,  1.2698,  1.2127,  1.3113,  1.2255,
          1.1984,  1.2316,  1.1978,  1.1727,  1.1861,  1.2095,  1.1733,  1.1689,
          1.1862,  1.1619,  1.1619,  1.2034,  1.2496,  1.1831,  1.2076,  1.2494,
          1.1928,  1.2237,  1.1416,  1.1856,  1.4056,  1.4674,  1.4396,  1.4177,
          1.4489,  1.3965,  1.4196,  1.2985,  1.4023,  1.3166,  1.2609,  1.2479,
          1.2250,  1.3089,  1.2461,  1.3521,  1.2076,  1.2208],
        [ 1.1597,  1.1884,  1.2397,  1.2219,  1.1946,  1.1647,  1.1744,  1.1570,
          1.1570,  2.8080,  2.8375,  2.8216,  3.1916,  2.7977,  3.5076,  2.8133,
          3.1208,  3.4099,  1.1785,  1.2039,  1.1714,  1.1918,  1.1852,  1.1802,
          1.1996,  1.1722,  1.1722,  1.2352,  1.1876,  1.1924,  1.2203,  1.2353,
          1.2034,  1.2387,  1.1649,  1.1952,  1.3563,  1.4289,  1.3516,  1.3701,
          1.4072,  1.4209,  1.3284,  1.2299,  1.3520,  1.2751,  1.2612,  1.2462,
          1.2197,  1.2294,  1.2441,  1.2788,  1.1999,  1.2149],
        [ 1.1534,  1.1790,  1.2046,  1.2087,  1.1840,  1.1579,  1.1660,  1.1511,
          1.1511,  1.2259,  1.2504,  1.2373,  1.2757,  1.2176,  1.2599,  1.2306,
          1.1451,  1.2721,  2.9886,  3.2747,  3.2372,  3.0055,  2.9175,  2.9117,
          3.2253,  2.9034,  2.9034,  1.1888,  1.2445,  1.1882,  1.2123,  1.1896,
          1.1981,  1.2295,  1.1918,  1.1908,  1.4027,  1.4660,  1.4364,  1.3240,
          1.4460,  1.4273,  1.4171,  1.2931,  1.3074,  1.3207,  1.2648,  1.2515,
          1.2281,  1.3013,  1.2496,  1.3454,  1.1870,  1.2238],
        [ 1.1574,  1.1836,  1.2090,  1.2141,  1.1889,  1.1620,  1.1704,  1.1550,
          1.1550,  1.2292,  1.2543,  1.2409,  1.2655,  1.2207,  1.2617,  1.2341,
          1.2053,  1.2274,  1.2083,  1.1921,  1.2422,  1.2205,  1.1827,  1.1782,
          1.1737,  1.1708,  1.1708,  3.3058,  3.1577,  2.8775,  2.9094,  3.3043,
          2.8892,  3.1146,  2.9290,  2.8805,  1.3955,  1.4606,  1.4111,  1.3765,
          1.4412,  1.4212,  1.3901,  1.2818,  1.3603,  1.3247,  1.2665,  1.2037,
          1.1802,  1.3167,  1.2510,  1.3619,  1.1388,  1.2245],
        [ 1.7904,  1.4171,  0.6482,  0.9271,  1.3188,  1.7250,  1.6049,  1.8246,
          1.8246,  1.6008,  1.2640,  1.4630,  0.9176,  1.6525,  0.1884,  1.5439,
          1.8148,  0.8328,  1.3238,  1.0276,  0.7874,  1.1474,  1.6663,  1.7287,
          1.5290,  1.8290,  1.8290,  0.8791,  0.8598,  1.7980,  1.5996,  0.8798,
          1.7426,  1.2319,  1.8483,  1.7643, -0.0974, -0.3114, -0.3439, -0.1483,
          0.0745,  0.1385, -0.2044, 23.3246,  1.4781,  0.7344,  1.2817,  1.3429,
          1.5649,  0.9299,  1.5056,  0.3646,  1.6847,  1.7200],
        [ 1.2069,  1.2459,  1.3140,  1.2916,  1.2544,  1.2138,  1.1828,  1.2034,
          1.2034,  1.1759,  1.3051,  1.1933,  1.3435,  1.2547,  1.4061,  1.1831,
          1.2319,  1.2636,  1.2709,  1.2563,  1.3221,  1.2889,  1.2330,  1.2261,
          1.1215,  1.2152,  1.2152,  1.2866,  1.3340,  1.2322,  1.0147,  1.2427,
          1.1146,  1.2943,  1.1059,  1.2361,  1.2193,  0.9454,  1.2174,  1.2381,
          0.7845,  0.7170,  1.2432,  1.0383,  0.5956,  4.0301,  2.7135,  3.9980,
          3.0578,  2.2453,  1.8855,  3.2020,  3.9519,  1.8601]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 398 : 178.2344725461504
Test loss for epoch 398 : 178.92448069185812
Test Precision for epoch 398 : 0.26153846153846155
Test Recall for epoch 398 : 0.26153846153846155
Test F1 for epoch 398 : 0.26153846153846155


theta for epoch 399 : tensor([[ 2.9534,  2.9867,  3.0632,  3.2276,  3.1891,  2.9589,  3.1648,  2.9505,
          2.9505,  1.2208,  1.2448,  1.2319,  1.2696,  1.2126,  1.3111,  1.2254,
          1.1984,  1.2314,  1.1976,  1.1726,  1.1860,  1.2093,  1.1732,  1.1688,
          1.1861,  1.1618,  1.1618,  1.2033,  1.2494,  1.1830,  1.2074,  1.2493,
          1.1927,  1.2235,  1.1415,  1.1855,  1.4058,  1.4676,  1.4398,  1.4179,
          1.4492,  1.3967,  1.4198,  1.2987,  1.4026,  1.3167,  1.2610,  1.2480,
          1.2251,  1.3090,  1.2462,  1.3523,  1.2076,  1.2208],
        [ 1.1596,  1.1882,  1.2396,  1.2217,  1.1945,  1.1646,  1.1743,  1.1570,
          1.1570,  2.8119,  2.8414,  2.8254,  3.1968,  2.8015,  3.5097,  2.8171,
          3.1261,  3.4133,  1.1784,  1.2038,  1.1712,  1.1916,  1.1852,  1.1801,
          1.1995,  1.1721,  1.1721,  1.2351,  1.1875,  1.1923,  1.2202,  1.2351,
          1.2033,  1.2386,  1.1648,  1.1951,  1.3566,  1.4292,  1.3519,  1.3704,
          1.4075,  1.4212,  1.3287,  1.2302,  1.3524,  1.2752,  1.2612,  1.2462,
          1.2198,  1.2295,  1.2441,  1.2789,  1.1999,  1.2149],
        [ 1.1533,  1.1789,  1.2044,  1.2085,  1.1839,  1.1578,  1.1659,  1.1510,
          1.1510,  1.2258,  1.2503,  1.2372,  1.2756,  1.2175,  1.2597,  1.2305,
          1.1450,  1.2720,  2.9925,  3.2792,  3.2419,  3.0093,  2.9208,  2.9151,
          3.2298,  2.9068,  2.9068,  1.1886,  1.2443,  1.1882,  1.2122,  1.1895,
          1.1980,  1.2294,  1.1917,  1.1907,  1.4029,  1.4662,  1.4366,  1.3242,
          1.4462,  1.4276,  1.4173,  1.2934,  1.3077,  1.3208,  1.2649,  1.2516,
          1.2282,  1.3014,  1.2497,  1.3455,  1.1870,  1.2239],
        [ 1.1573,  1.1835,  1.2088,  1.2140,  1.1888,  1.1619,  1.1703,  1.1549,
          1.1549,  1.2292,  1.2542,  1.2408,  1.2653,  1.2206,  1.2614,  1.2340,
          1.2052,  1.2272,  1.2082,  1.1919,  1.2420,  1.2203,  1.1827,  1.1781,
          1.1735,  1.1708,  1.1708,  3.3109,  3.1615,  2.8808,  2.9126,  3.3094,
          2.8924,  3.1184,  2.9329,  2.8838,  1.3957,  1.4609,  1.4112,  1.3767,
          1.4414,  1.4215,  1.3902,  1.2821,  1.3606,  1.3249,  1.2666,  1.2037,
          1.1803,  1.3168,  1.2511,  1.3620,  1.1388,  1.2246],
        [ 1.7909,  1.4175,  0.6488,  0.9276,  1.3193,  1.7254,  1.6054,  1.8250,
          1.8250,  1.6013,  1.2645,  1.4635,  0.9182,  1.6530,  0.1891,  1.5444,
          1.8153,  0.8334,  1.3243,  1.0281,  0.7880,  1.1479,  1.6668,  1.7291,
          1.5295,  1.8295,  1.8295,  0.8796,  0.8603,  1.7984,  1.6001,  0.8803,
          1.7430,  1.2324,  1.8487,  1.7648, -0.0983, -0.3122, -0.3448, -0.1492,
          0.0735,  0.1375, -0.2053, 23.3686,  1.4752,  0.7345,  1.2816,  1.3428,
          1.5647,  0.9300,  1.5055,  0.3649,  1.6843,  1.7197],
        [ 1.2068,  1.2458,  1.3140,  1.2915,  1.2543,  1.2136,  1.1827,  1.2032,
          1.2032,  1.1758,  1.3049,  1.1931,  1.3434,  1.2545,  1.4060,  1.1830,
          1.2317,  1.2635,  1.2708,  1.2562,  1.3220,  1.2888,  1.2328,  1.2260,
          1.1213,  1.2150,  1.2150,  1.2865,  1.3339,  1.2320,  1.0146,  1.2426,
          1.1144,  1.2942,  1.1058,  1.2359,  1.2182,  0.9446,  1.2163,  1.2370,
          0.7837,  0.7162,  1.2421,  1.0368,  0.5948,  4.0378,  2.7153,  4.0054,
          3.0611,  2.2459,  1.8858,  3.2054,  3.9598,  1.8604]],
       dtype=torch.float64, requires_grad=True)
Train loss for epoch 399 : 178.23062213302128
Test loss for epoch 399 : 178.92202578954104
Test Precision for epoch 399 : 0.26153846153846155
Test Recall for epoch 399 : 0.26153846153846155
Test F1 for epoch 399 : 0.26153846153846155


Max Test F1 is for epoch 0 : 0.26153846153846155
