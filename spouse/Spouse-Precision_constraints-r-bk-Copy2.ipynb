{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12\n",
    "import sys\n",
    "orig_stdout = sys.stdout\n",
    "NoOfClasses = 2\n",
    "dataType = 'discrete'\n",
    "sys.stdout = orig_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2625, 1: 189}\n",
      "{0: 2484, 1: 218}\n",
      "2814 2702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "import model_only\n",
    "\n",
    "gold_labels_dev = np.load(\"data/true_labels_dev.npy\")\n",
    "gold_labels_test = np.load(\"data/true_labels_test.npy\")\n",
    "\n",
    "unique, counts = np.unique(gold_labels_dev, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(gold_labels_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print(len(gold_labels_dev),len(gold_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def draw2DArray(a):\n",
    "    fig = plt.figure(figsize=(6, 3.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('colorMap')\n",
    "    plt.imshow(np.array(a))\n",
    "    ax.set_aspect('equal')\n",
    "    cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "    cax.get_xaxis().set_visible(False)\n",
    "    cax.get_yaxis().set_visible(False)\n",
    "    cax.patch.set_alpha(0)\n",
    "    cax.set_frame_on(False)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "      \n",
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return pd.DataFrame(D_class_data).T\n",
    "\n",
    "def predictAndPrint(pl):\n",
    "    print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "    print(precision_recall_fscore_support(gold_labels_test,pl,average='binary'))\n",
    "    print(confusion_matrix(gold_labels_dev,pl))\n",
    "#     draw2DArray(confusion_matrix(gold_labels_dev,pl))\n",
    "#     return report2dict(classification_report(gold_labels_dev, pl))# target_names=class_names))\n",
    "    \n",
    "\n",
    "\n",
    "def drawPRcurve(y_test,y_score,it_no):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    splt = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=1)\n",
    "\n",
    "    splt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    splt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.title('{0:d} Precision-Recall curve: AP={1:0.2f}'.format(it_no,\n",
    "              average_precision))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dataType == 'merged':\n",
    "    LF_l = [\n",
    "        1,1,1,1,1,-1,1,-1,-1,-1\n",
    "    ]\n",
    "    dscr = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
    "    def merge(a,b):\n",
    "        c = []\n",
    "        for i in range(len(a)):\n",
    "            ci = []\n",
    "            ci_l = a[i,0,:].tolist()+b[i,0,:].tolist()\n",
    "            ci_s = a[i,1,:].tolist()+b[i,1,:].tolist()\n",
    "            ci.append(ci_l)\n",
    "            ci.append(ci_s)\n",
    "            c.append(ci)\n",
    "        return c\n",
    "    import numpy as np\n",
    "    dev_L_S_s = np.load(\"data/dev_L_S_smooth.npy\")\n",
    "    test_L_S_s = np.load(\"data/test_L_S_smooth.npy\")\n",
    "    train_L_S_s = np.load(\"data/train_L_S_smooth.npy\")\n",
    "\n",
    "    dev_L_S_d = np.load(\"data/dev_L_S_discrete.npy\")\n",
    "    test_L_S_d = np.load(\"data/test_L_S_discrete.npy\")\n",
    "    train_L_S_d = np.load(\"data/train_L_S_discrete.npy\")\n",
    "\n",
    "    dev_L_S = np.array(merge(dev_L_S_d,dev_L_S_s))\n",
    "    train_L_S = np.array(merge(train_L_S_d,train_L_S_s))\n",
    "    test_L_S = np.array(merge(test_L_S_d,test_L_S_s))\n",
    "\n",
    "    LF_l = LF_l + LF_l\n",
    "    NoOfLFs= len(LF_l)\n",
    "\n",
    "    print(len(LF_l))\n",
    "\n",
    "    print(dev_L_S.shape, test_L_S.shape, train_L_S.shape)\n",
    "    print(train_L_S[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2814 2702\n",
      "(2702, 2, 10) (2814, 2, 10) (22276, 2, 10)\n",
      "[[ 0.   0.   0.   0.   0.   0.   0.  -1.  -1.   0. ]\n",
      " [ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  1.   1.   0.5]]\n"
     ]
    }
   ],
   "source": [
    "if dataType == 'discrete':\n",
    "    LF_l = [\n",
    "        1,1,1,1,1,-1,1,-1,-1,-1\n",
    "    ]\n",
    "    NoOfLFs= len(LF_l)\n",
    "    dscr = np.ones(10)\n",
    "\n",
    "    dev_L_S = np.load(\"data/dev_L_S_discrete.npy\")\n",
    "    test_L_S = np.load(\"data/test_L_S_discrete.npy\")\n",
    "    train_L_S = np.load(\"data/train_L_S_discrete.npy\")\n",
    "\n",
    "    print(len(gold_labels_dev),len(gold_labels_test))\n",
    "    print(test_L_S.shape,dev_L_S.shape,train_L_S.shape)\n",
    "    print(train_L_S[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dataType == 'cont':\n",
    "    LF_l = [\n",
    "        1,1,1,1,1,-1,1,-1,-1,-1\n",
    "    ]\n",
    "    dscr = np.array([1,1,0,0,1,1,0,0,0,0])\n",
    "    NoOfLFs= len(LF_l)\n",
    "\n",
    "    dev_L_S = np.load(\"data/dev_L_S_smooth.npy\")\n",
    "    test_L_S = np.load(\"data/test_L_S_smooth.npy\")\n",
    "    train_L_S = np.load(\"data/train_L_S_smooth.npy\")\n",
    "\n",
    "    print(len(gold_labels_dev),len(gold_labels_test))\n",
    "    print(test_L_S.shape,dev_L_S.shape,train_L_S.shape)\n",
    "    print(train_L_S[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 2 {0.0: 22243, 1.0: 33}\n",
      "1 \t 2 {0.0: 22096, 1.0: 180}\n",
      "2 \t 2 {0.0: 19945, 1.0: 2331}\n",
      "3 \t 2 {0.0: 20538, 1.0: 1738}\n",
      "4 \t 2 {0.0: 21904, 1.0: 372}\n",
      "5 \t 2 {-1.0: 13366, 0.0: 8910}\n",
      "6 \t 2 {0.0: 22261, 1.0: 15}\n",
      "7 \t 2 {-1.0: 2323, 0.0: 19953}\n",
      "8 \t 2 {-1.0: 1634, 0.0: 20642}\n",
      "9 \t 2 {-1.0: 208, 0.0: 22068}\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]10\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "discr = []\n",
    "for j in range(len(LF_l)):\n",
    "    temp = np.array(train_L_S[:,0,j]*np.array(train_L_S[:,1,j]))\n",
    "    unique, counts = np.unique(temp, return_counts=True)\n",
    "    temp_d = dict(zip(unique, counts))\n",
    "    print(j, '\\t', len(temp_d), temp_d if len(temp_d)==2 else '')\n",
    "    discr.append(int(not(len(temp_d)-2)))\n",
    "sys.stdout.write('[')\n",
    "for x in range(len(discr)-1):\n",
    "    sys.stdout.write(str(discr[x]) + ', ')\n",
    "sys.stdout.write(str(discr[-1])+']')\n",
    "\n",
    "print(len(LF_l))\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#added new model\n",
    "def train2(lr,ep,th,af,batch_size=32,LF_acc=None,LF_rec=None,pcl=np.array([-1,1],dtype=np.float64),norm=True,\\\n",
    "          smooth=True,penalty=0,p3k=3,alp=1,Gamma=1.0,debug=True, \\\n",
    "           r1=1.0, r2=1.0, a_pr=None, n_pr=None, user_a = None, isdiscrete = None, alpha_max = None, r_pr=None):\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## pcl : all possible class labels  = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    ## alp : alpha parameter (to set a max value for alpha)\n",
    "    ## norm : use normalization or not\n",
    "    ## Gamma : penalty tuning parameter\n",
    "    \n",
    "    BATCH_SIZE = batch_size\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    seed = 12\n",
    "    \n",
    "    LF_k = []\n",
    "    if(len(pcl)==2):\n",
    "        for i in range(len(LF_l)):\n",
    "            LF_k.append(int((LF_l[i]+1)/2))\n",
    "    with tf.Graph().as_default():\n",
    "        xtra = tf.Variable(0, trainable=False)\n",
    "        gammaR = tf.constant(0, dtype=tf.float64)\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(dev_L_S).batch(len(dev_L_S))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "        test_init_op = iterator.make_initializer(test_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        thetas,alphas = model_only.allocate_params(NoOfLFs, 2, penalty, th, af)\n",
    "        \n",
    "        LF_label = tf.convert_to_tensor(LF_k, dtype=tf.int32)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "        g = tf.convert_to_tensor(Gamma, dtype=tf.float64)\n",
    "        \n",
    "        if(penalty in [4,5,7,8,9,10,11, 44, 42, 41]):\n",
    "            LF_a = tf.convert_to_tensor(LF_acc, dtype=tf.float64)\n",
    "        \n",
    "        if(penalty in [6,7,11,12,15]):\n",
    "            LF_r = tf.convert_to_tensor(LF_rec, dtype=tf.float64)\n",
    "        \n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "\n",
    "        if(smooth and penalty < 100):\n",
    "            s_ = tf.maximum(tf.subtract(s,tf.minimum(alphas,alp)), 0)\n",
    "            if(debug):\n",
    "                print(\"s_\",s_)\n",
    "\n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "            if(debug):\n",
    "                print(\"out\",out)\n",
    "            return out\n",
    "#MAP\n",
    "        if(penalty < 100):\n",
    "            if(smooth):\n",
    "                pout = tf.map_fn(lambda c: l*c*s_ ,pcl,name=\"pout\")\n",
    "            else:\n",
    "                pout = tf.map_fn(lambda c: l*c ,pcl,name=\"pout\")\n",
    "\n",
    "            t =  tf.squeeze(thetas)                \n",
    "                \n",
    "            def ints(y): # called for y=1 and y=-1\n",
    "                ky = iskequalsy(k,y)  # ky = 1 if k==y else -1\n",
    "                if(debug):\n",
    "                    print(\"ky\",ky)\n",
    "                out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "                if(debug):\n",
    "                    print(\"intsy\",out1)\n",
    "                return out1                \n",
    "                \n",
    "            if(smooth):\n",
    "                #smooth normalizer\n",
    "                zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                               pcl,name=\"zy\")\n",
    "            else:\n",
    "                #discrete normalizer\n",
    "                zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                               pcl,name=\"zy\")            \n",
    "#new model\n",
    "\n",
    "        if(penalty > 200):\n",
    "\n",
    "#             z_y_new = [tf.reduce_prod(1 + 1/(-1*k*thetas) * (tf.exp(-1*k*thetas) - tf.exp(-1*k*thetas*user_alphas)) ), \\\n",
    "#                    tf.reduce_prod(1 + 1/(1*k*thetas) * (tf.exp(1*k*thetas) - tf.exp(1*k*thetas*user_alphas)) ) ]\n",
    "            numbins = tf.constant(10, dtype=tf.float64)\n",
    "            #TODO: 2 binned integration over the s values to allow stable gradients.\n",
    "            sbin_widths = (1-user_alphas)/numbins\n",
    "            sbins = tf.einsum('i,j->ij', sbin_widths, tf.cast(tf.range(0,numbins+1), dtype=tf.float64))+tf.expand_dims(user_alphas,1)\n",
    "            sbins = tf.transpose(sbins)\n",
    "            \n",
    "            def pot(s):\n",
    "                if(penalty%10 == 1):\n",
    "                    return thetas*s-alphas\n",
    "                elif(penalty%10 == 2):\n",
    "                    return thetas*tf.clip_by_value(s-alphas,0,1)\n",
    "                elif(penalty%10 == 3):\n",
    "                    return thetas*s\n",
    "                return 0\n",
    "                                       \n",
    "            # over the y-s it is okay to use a map function, but not over the LFs.\n",
    "            z_y_new = tf.map_fn(lambda y: tf.reduce_prod(1 + tf.reduce_sum(tf.exp(-y*k*pot(sbins)), axis=0)), tf.constant([1,-1], dtype=tf.float64))\n",
    "#             z_y_new = tf.reduce_sum(tf.exp(-1*k*thetas*sbins), axis=0)*sbin_widths/(1-user_alphas)\n",
    "# *sbin_widths\n",
    "\n",
    "            Z_new = tf.reduce_sum(z_y_new)\n",
    "            print(\"new z \", Z_new)\n",
    "\n",
    "#p theta without exp [y x i]\n",
    "            # snap s_ to the nearest bin. \n",
    "            s_ = tf.round((s_-user_alphas)*numbins/(1-user_alphas))*sbin_widths + user_alphas\n",
    "            logp_theta_new_t = tf.map_fn(lambda y:  tf.reduce_sum(-y*l*pot(s_), axis=1), tf.constant([1,-1], dtype=tf.float64))\n",
    "\n",
    "\n",
    "            loss_new_t = tf.reduce_logsumexp(logp_theta_new_t, axis=0) - tf.log(Z_new)\n",
    "            loss_new = tf.negative(tf.reduce_sum(loss_new_t))\n",
    "        \n",
    "#marginals as softmax\n",
    "\n",
    "            marginals_new = tf.expand_dims(tf.nn.softmax(logp_theta_new_t, axis=0), 2)\n",
    "\n",
    "        if(penalty < 100):\n",
    "            \n",
    "            if(debug):\n",
    "                print(\"pout\",pout)    \n",
    "    #MAP\n",
    "            t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                               name=\"t_pout\")\n",
    "\n",
    "            if(debug):\n",
    "                print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        if(debug):\n",
    "            print(\"t\",t)\n",
    "\n",
    "        if(penalty < 100):\n",
    "            marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "#         else:\n",
    "#             marginals = marginals_new\n",
    "        \n",
    "            if(debug):\n",
    "                print(\"zy\",zy)\n",
    "            logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "            if(debug):\n",
    "                print(\"logz\",logz)\n",
    "    ##         tf.summary.scalar('logz', logz)\n",
    "            lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "            if(debug):\n",
    "                print(\"lsp\",lsp)\n",
    "##         tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "        \n",
    "    \n",
    "        if(penalty == 20 or penalty > 100):\n",
    "            a_t = tf.convert_to_tensor(a_pr, dtype=tf.float64)\n",
    "            n_t = tf.convert_to_tensor(n_pr, dtype=tf.float64)\n",
    "            r_t = tf.convert_to_tensor(r_pr, dtype=tf.float64)\n",
    "        def get_loss_20():\n",
    "#NEW MODEL\n",
    "\n",
    "            # unnormalized_marginals [numY]\n",
    "            unnormalized_marginals = [tf.reduce_prod(tf.exp(-thetas*LF_l) + 1), \\\n",
    "                                      tf.reduce_prod(tf.exp(thetas*LF_l) + 1)]\n",
    "            # same for continuous, just use the new formulation with sbins for summation, no intergration\n",
    "            Z = tf.reduce_sum(unnormalized_marginals)\n",
    "\n",
    "            # unnormalized_marginals_tiled: [numLF, numY]\n",
    "            # per-LF-marginals: [numLFs]\n",
    "            per_LF_marginals = tf.gather(unnormalized_marginals, LF_label)\n",
    "\n",
    "#             return per_LF_marginals\n",
    "            # PÎ¸(kj=y): [numLFs]  (computing Eq 14)                       \n",
    "            per_LF_agreement_prob = tf.exp(thetas)/(1 + tf.exp(thetas))*per_LF_marginals/Z\n",
    "\n",
    "#             p_thetas =  tf.expand_dims(prod__,1) * exp_terms/(1+exp_terms) / Z\n",
    "            p_thetas = per_LF_agreement_prob\n",
    "\n",
    "            ptheta_terms = a_t * n_t * tf.log(p_thetas) + (1-a_t) * n_t * tf.log(1-p_thetas)\n",
    "                                                   \n",
    "#-------------------------------\n",
    "\n",
    "            return tf.negative(tf.reduce_sum(ptheta_terms)) # add other loss component\n",
    "\n",
    "        loss_recall = 0\n",
    "        if(penalty > 100):\n",
    "            numYs=2\n",
    "            loss_new, per_lf_prob, marginals, per_lf_recall, pots = model_only.model(numYs, k, l, s, thetas, alphas, isdiscrete, user_a, penalty,alpha_max)\n",
    "            loss_precision = model_only.precision_loss(a_t, n_t, per_lf_prob, penalty)\n",
    "            if r_t is not None and (penalty//10) % 10 == 3:\n",
    "                loss_recall = model_only.recall_loss(r_t, n_t, per_lf_recall, isdiscrete)\n",
    "\n",
    "#adding ne      \n",
    "           \n",
    "        prec_loss = tf.constant(0)\n",
    "    \n",
    "        if(not norm):\n",
    "            print(\"unnormlized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  ))\n",
    "        elif(penalty == 1):\n",
    "            print(\"penalty1\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +(g*tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas)))\n",
    "        elif(penalty == 2):\n",
    "            print(\"penalty2\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -(g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "            prec_loss = tf.constant(0)\n",
    "        elif(penalty == 3):\n",
    "            print(\"penalty3\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +(g*tf.reduce_sum(tf.log(1+tf.exp(-thetas-p3k))))\n",
    "        \n",
    "\n",
    "        elif(penalty == 4):\n",
    "            print(\"precision penalty\")\n",
    "            prec_loss = tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g* prec_loss)\n",
    "        \n",
    "        elif(penalty == 41):\n",
    "            print(\"precision penalty\")\n",
    "            prec_loss, xtra = sfp()\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g * prec_loss)\n",
    "#                 + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "#                                              dtype=tf.float64)))\n",
    "        \n",
    "        elif(penalty == 42):\n",
    "            print(\"precision penalty\")\n",
    "            temp_prloss, _ = sfpp()\n",
    "            temp_uloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "            r21 = tf.gradients(temp_uloss, thetas)\n",
    "            r22 = tf.gradients(temp_prloss, thetas)\n",
    "            xtra_tfg = tf.reduce_sum(tf.abs(r21[0][0]))/tf.reduce_sum(tf.abs(r22[0][0]))\n",
    "#             gammaR = temp_uloss/temp_prloss\n",
    "#             prec_loss, xtra = sfpp()\n",
    "            prec_loss = tf.reduce_sum(temp_prloss)\n",
    "\n",
    "            grad_ratio = 1\n",
    "\n",
    "            xtra = [xtra_tfg]\n",
    "\n",
    "            loss = temp_uloss \\\n",
    "                + (g * prec_loss)\n",
    "\n",
    "        elif(penalty == 44):\n",
    "            print(\"precision penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_pp(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "                \n",
    "                \n",
    "        elif(penalty == 5):\n",
    "            print(\"precision log(softplus) penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: tf.log(softplus_p(j)),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 6):\n",
    "            print(\"recall penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 7):\n",
    "            print(\"precision and recall penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64)))\n",
    "        elif(penalty == 8):\n",
    "            print(\"precision and sign 1 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas)))\n",
    "        elif(penalty == 9):\n",
    "            print(\"precision and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 10):\n",
    "            print(\"precision and sign 3 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.log(1+tf.exp(-thetas-p3k))))\n",
    "        elif(penalty == 11):\n",
    "            print(\"precision and recall and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_p(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                  - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 12):\n",
    "            print(\"recall and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                  - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "        elif(penalty == 15):\n",
    "            print(\"equation 15 and sign 2 penalty\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                + (g*tf.reduce_sum(tf.map_fn(lambda j: softplus_r15(j),np.arange(NoOfLFs),\\\n",
    "                                             dtype=tf.float64))) \\\n",
    "                  - (g*tf.minimum( tf.reduce_min(thetas),0.0))\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "        elif(penalty == 20):\n",
    "            print(\"new model\")\n",
    "            prec_loss = get_loss_20()\n",
    "            loss =  tf.negative(tf.reduce_sum(lsp  - logz  )) + prec_loss\n",
    "                  \n",
    "        elif(penalty >100 and penalty<111):\n",
    "            sys.stdout = stdout_saved\n",
    "            print(\"new model smooth \", penalty)\n",
    "            # sys.stdout = open(\"trash\", \"w\")            \n",
    "            print(\"new model smooth \", penalty)\n",
    "            loss = loss_new\n",
    "#             loss, _ = smooth_new_prec()\n",
    "            \n",
    "                    \n",
    "        elif(penalty >110):\n",
    "            sys.stdout = stdout_saved\n",
    "            print(\"new model smooth with constraints \", penalty)\n",
    "            # sys.stdout = open(\"trash\", \"w\")            \n",
    "            print(\"new model smooth with constraints \", penalty)\n",
    "            loss = loss_new + loss_precision + loss_recall\n",
    "#             loss_un, loss_pr = smooth_new_prec()\n",
    "#             loss = loss_un + loss_pr\n",
    "\n",
    "        else:\n",
    "            print(\"normalized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "            prec_loss = tf.constant(0)\n",
    "       \n",
    "        if(debug):\n",
    "            print(\"loss\",loss)\n",
    "\n",
    "#         marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        if(debug):\n",
    "            print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(loss)#, var_list=[thetas, alphas]) \n",
    "\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        \n",
    "        dev_high = np.zeros(3)\n",
    "        test_high = np.zeros(3)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            flg = False\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "#                 temprun = sess.run(next_element2)\n",
    "#                 print('len next ',len(temprun), len(temprun[0]))\n",
    "#                 print(temprun[0])\n",
    "                tl = 0\n",
    "                pll = 0\n",
    "                unl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    \n",
    "                    grad_sum = 0.0\n",
    "                    while True:\n",
    "#                         print(en, it)\n",
    "\n",
    "                        _,ls,ploss,lfProbs,t,al,p = sess.run([train_step,loss_new,loss_precision,per_lf_prob,thetas,alphas,pots])\n",
    "                        if(penalty == 42):\n",
    "                            un_loss = sess.run(temp_uloss)\n",
    "\n",
    "                        tl = tl + ls\n",
    "                        pll = pll + ploss\n",
    "                        if(penalty == 42):\n",
    "                            unl = unl + un_loss\n",
    "                        it = it + 1\n",
    "                        probs = np.exp(lfProbs)\n",
    "                        if (np.amax(probs) > 1+1e-6):\n",
    "                            print(\"Invalid probabilities=\",probs)\n",
    "                            \n",
    "                        # print(\"various shapes=\",p)\n",
    "                        # print(\"Loss, prec_loss=\", lfProbs)\n",
    "                        # potsv, sv, lv, kv = sess.run([pots,s,l,k])\n",
    "                        # print(t,al)\n",
    "                        # print(sv,lv,kv)\n",
    "                        # print(potsv)\n",
    "#                         newptheta = sess.run(sbins)\n",
    "#                         ztemp = sess.run(xyz)\n",
    "                \n",
    "#                         print(it*BATCH_SIZE)\n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                opstring = \"\"\n",
    "                print(en,\"loss=\",tl, \" precision loss=\",pll)\n",
    "                opstring = opstring + str(en) + \",\" + str(tl) + \",\"\n",
    "#                 print('temp__', temp__)\n",
    "                \n",
    "                print(\"ploss\", pll)\n",
    "                print(\"ratio\", unl/pll)\n",
    "#                 dloss = sess.run(dev_loss)\n",
    "#                 print(\"dloss\", dloss)\n",
    "#                 print(\"expected ratio\", xpp/(xpp+1))\n",
    "                print(\"dev set\")\n",
    "                sess.run(dev_init_op)\n",
    "##                 sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "#                 a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "                a,t,m,pl,ddloss = sess.run([alphas,thetas,marginals,predict,loss])\n",
    "##                 test_writer.add_summary(sm, en)\n",
    "                print('init dev loss', ddloss)\n",
    "                opstring = opstring + str(ddloss) + \",\"\n",
    "                print(\"alphas=\", a)\n",
    "                print(\"thetas=\",t)\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(\"Unique,counts of marginals\", dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "                dev_results = precision_recall_fscore_support(np.array(gold_labels_dev),np.array(pl),average=\"binary\")\n",
    "                print('devresults ', dev_results)\n",
    "                roc_dev = roc_auc_score(np.array(gold_labels_dev), np.array(m[1,:,0]))\n",
    "                print('roc score', roc_dev)\n",
    "                opstring = str(en) + ',' #do not print losses\n",
    "                opstring = opstring + str(dev_results[2]) + \",\" + str(roc_dev) + \",\"\n",
    "#                 if(dev_results[2]>dev_high[2]):\n",
    "                dev_high = np.array(dev_results)\n",
    "#                 dev_high = max(dev_high, dev_results[2])\n",
    "                print()\n",
    "                print(\"test set\")\n",
    "                sess.run(test_init_op)\n",
    "                a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(gold_labels_test,pl))\n",
    "                test_results = precision_recall_fscore_support(np.array(gold_labels_test),np.array(pl),average=\"binary\")\n",
    "                print('testresults ', test_results)\n",
    "                roc_test = roc_auc_score(np.array(gold_labels_test), np.array(m[1,:,0]))\n",
    "                print('roc score', roc_test)\n",
    "                opstring = opstring + str(test_results[2]) + \",\" + str(roc_test)\n",
    "#                 if(test_results[2]>test_high[2]):\n",
    "                test_high = np.array(test_results)\n",
    "                print()\n",
    "        \n",
    "                sys.stdout = stdout_saved\n",
    "                print(opstring)\n",
    "                print(a, t)\n",
    "# #                 newptheta = sess.run(marginals)\n",
    "#                 print(\"new z \", ztemp)\n",
    "#                 print(\"new z shape \", np.array(ztemp).shape)\n",
    "#                 print('shape ',np.array(newptheta).shape)\n",
    "                # sys.stdout = open(\"trash\", \"w\")\n",
    "                \n",
    "\n",
    "    return pl, m, dev_high, opstring#test_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "============ 111\n",
      "Using binomial precision constraints\n",
      "new model smooth with constraints  111\n",
      "new model smooth with constraints  111\n",
      "0 loss= 7340.07950314  precision loss= 4428301.47279\n",
      "ploss 4428301.47279\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 6154.37324317\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.96954594  0.96954593  0.96954618  0.96954622  0.9695458   1.03058055\n",
      "   0.96954582  1.0305806   1.03058062  1.03058009]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.778327034518\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.817024368804\n",
      "\n",
      "0,0.428274428274,0.778327034518,0.49569707401,0.817024368804\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.96954594  0.96954593  0.96954618  0.96954622  0.9695458   1.03058055\n",
      "   0.96954582  1.0305806   1.03058062  1.03058009]]\n",
      "1 loss= 7176.70365966  precision loss= 4166907.9372\n",
      "ploss 4166907.9372\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5817.23535\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.94110031  0.94110034  0.94110133  0.94110128  0.9411002   1.05947311\n",
      "   0.94110014  1.05947267  1.05947264  1.05947159]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77751675485\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819181292381\n",
      "\n",
      "1,0.428274428274,0.77751675485,0.49569707401,0.819181292381\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.94110031  0.94110034  0.94110133  0.94110128  0.9411002   1.05947311\n",
      "   0.94110014  1.05947267  1.05947264  1.05947159]]\n",
      "2 loss= 7042.30263195  precision loss= 3959675.8072\n",
      "ploss 3959675.8072\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5559.80041597\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.91512011  0.91512024  0.91512279  0.91512251  0.91512014  1.08635371\n",
      "   0.91511986  1.08635226  1.08635211  1.08635009]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77747845805\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819181292381\n",
      "\n",
      "2,0.428274428274,0.77747845805,0.49569707401,0.819181292381\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.91512011  0.91512024  0.91512279  0.91512251  0.91512014  1.08635371\n",
      "   0.91511986  1.08635226  1.08635211  1.08635009]]\n",
      "3 loss= 6937.4732394  precision loss= 3807888.01813\n",
      "ploss 3807888.01813\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5380.66906932\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.89221338  0.8922137   0.8922192   0.89221848  0.89221369  1.11086121\n",
      "   0.892213    1.11085794  1.11085756  1.11085389]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77747845805\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819181292381\n",
      "\n",
      "3,0.428274428274,0.77747845805,0.49569707401,0.819181292381\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.89221338  0.8922137   0.8922192   0.89221848  0.89221369  1.11086121\n",
      "   0.892213    1.11085794  1.11085756  1.11085389]]\n",
      "4 loss= 6861.28039589  precision loss= 3708014.59126\n",
      "ploss 3708014.59126\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5270.97831987\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.87322392  0.87322462  0.87323553  0.873234    0.87322479  1.13261421\n",
      "   0.8732233   1.1326078   1.13260706  1.13260062]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "4,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.87322392  0.87322462  0.87323553  0.873234    0.87322479  1.13261421\n",
      "   0.8732233   1.1326078   1.13260706  1.13260062]]\n",
      "5 loss= 6811.35449987  precision loss= 3651264.65552\n",
      "ploss 3651264.65552\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5214.53828452\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.8592933   0.8592947   0.8593156   0.85931257  0.85929521  1.15131461\n",
      "   0.85929222  1.15130298  1.15130163  1.15129067]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "5,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.8592933   0.8592947   0.8593156   0.85931257  0.85929521  1.15131461\n",
      "   0.85929222  1.15130298  1.15130163  1.15129067]]\n",
      "6 loss= 6784.32368889  precision loss= 3624471.93778\n",
      "ploss 3624471.93778\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5190.46267197\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.85171293  0.85171563  0.85175487  0.85174908  0.85171677  1.16705633\n",
      "   0.85171103  1.16703633  1.16703399  1.1670158 ]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "6,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.85171293  0.85171563  0.85175487  0.85174908  0.85171677  1.16705633\n",
      "   0.85171103  1.16703633  1.16703399  1.1670158 ]]\n",
      "7 loss= 6776.39360272  precision loss= 3613127.40392\n",
      "ploss 3613127.40392\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5179.24753595\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.85122072  0.85122567  0.85129654  0.851286    0.85122792  1.18086314\n",
      "   0.85121742  1.18083052  1.18082671  1.18079762]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "7,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.85122072  0.85122567  0.85129654  0.851286    0.85122792  1.18086314\n",
      "   0.85121742  1.18083052  1.18082671  1.18079762]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 loss= 6783.59926216  precision loss= 3606144.45372\n",
      "ploss 3606144.45372\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5169.29181931\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.8570675   0.85707586  0.85719471  0.85717696  0.8570798   1.19490607\n",
      "   0.85706206  1.19485641  1.1948506   1.1948067 ]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "8,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.8570675   0.85707586  0.85719471  0.85717696  0.8570798   1.19490607\n",
      "   0.85706206  1.19485641  1.1948506   1.1948067 ]]\n",
      "9 loss= 6801.99943369  precision loss= 3598409.4502\n",
      "ploss 3598409.4502\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5156.85943301\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.86751612  0.86752902  0.86771148  0.86768421  0.8675352   1.21157519\n",
      "   0.86750784  1.21150556  1.21149739  1.21143592]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "9,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.86751612  0.86752902  0.86771148  0.86768421  0.8675352   1.21157519\n",
      "   0.86750784  1.21150556  1.21149739  1.21143592]]\n",
      "10 loss= 6828.75201194  precision loss= 3588671.32385\n",
      "ploss 3588671.32385\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5141.41108595\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.88135452  0.88137288  0.88163164  0.881593    0.88138175  1.23216633\n",
      "   0.88134281  1.23207695  1.23206641  1.23198717]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "10,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.88135452  0.88137288  0.88163164  0.881593    0.88138175  1.23216633\n",
      "   0.88134281  1.23207695  1.23206641  1.23198717]]\n",
      "11 loss= 6862.5222736  precision loss= 3576910.73589\n",
      "ploss 3576910.73589\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5123.28627598\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.8979702   0.89799465  0.89833813  0.89828696  0.89800648  1.2566493\n",
      "   0.89795465  1.25654381  1.25653129  1.25643702]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "11,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.8979702   0.89799465  0.89833813  0.89828696  0.89800648  1.2566493\n",
      "   0.89795465  1.25654381  1.25653129  1.25643702]]\n",
      "12 loss= 6902.28388647  precision loss= 3563534.10253\n",
      "ploss 3563534.10253\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5103.26298004\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.91669843  0.9167293   0.91716188  0.91709766  0.91674421  1.2841989\n",
      "   0.91667878  1.2840826   1.2840687   1.28396368]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "12,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.91669843  0.9167293   0.91716188  0.91709766  0.91674421  1.2841989\n",
      "   0.91667878  1.2840826   1.2840687   1.28396368]]\n",
      "13 loss= 6946.60722101  precision loss= 3549143.59888\n",
      "ploss 3549143.59888\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5082.22843015\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.9367656   0.93680315  0.93732792  0.93725036  0.93682121  1.31375743\n",
      "   0.93674167  1.31363506  1.31362031  1.31350846]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "13,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.9367656   0.93680315  0.93732792  0.93725036  0.93682121  1.31375743\n",
      "   0.93674167  1.31363506  1.31362031  1.31350846]]\n",
      "14 loss= 6993.98028916  precision loss= 3534308.48425\n",
      "ploss 3534308.48425\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5060.89299376\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.9575165   0.95756112  0.95818317  0.95809171  0.95758247  1.34442515\n",
      "   0.95748798  1.34429977  1.34428453  1.34416846]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "14,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.9575165   0.95756112  0.95818317  0.95809171  0.95758247  1.34442515\n",
      "   0.95748798  1.34429977  1.34428453  1.34416846]]\n",
      "15 loss= 7043.2218172  precision loss= 3519432.77778\n",
      "ploss 3519432.77778\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5039.70339316\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.9785186   0.97857101  0.97929949  0.97919302  0.9785959   1.37559933\n",
      "   0.97848501  1.37547253  1.37545699  1.37533804]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777482489292\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "15,0.428274428274,0.777482489292,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.9785186   0.97857101  0.97929949  0.97919302  0.9785959   1.37559933\n",
      "   0.97848501  1.37547253  1.37545699  1.37533804]]\n",
      "16 loss= 7093.58246802  precision loss= 3504749.93111\n",
      "ploss 3504749.93111\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 5018.8942907\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 0.99953307  0.99959432  1.00044323  1.00031998  0.99962319  1.40693582\n",
      "   0.99949369  1.40680828  1.4067925   1.40667123]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77747845805\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819183139062\n",
      "\n",
      "16,0.428274428274,0.77747845805,0.49569707401,0.819183139062\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.99953307  0.99959432  1.00044323  1.00031998  0.99962319  1.40693582\n",
      "   0.99949369  1.40680828  1.4067925   1.40667123]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 loss= 7144.65141054  precision loss= 3490373.86422\n",
      "ploss 3490373.86422\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4998.56917672\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.02044685  1.02051835  1.0215066   1.02136415  1.02055179  1.43826064\n",
      "   1.02040073  1.43813252  1.43811653  1.43799304]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777436130008\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "17,0.428274428274,0.777436130008,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.02044685  1.02051835  1.0215066   1.02136415  1.02055179  1.43826064\n",
      "   1.02040073  1.43813252  1.43811653  1.43799304]]\n",
      "18 loss= 7196.2298077  precision loss= 3476349.72813\n",
      "ploss 3476349.72813\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4978.76149225\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.04121683  1.04130034  1.04245147  1.04228682  1.04133909  1.46949661\n",
      "   1.0411628   1.46936786  1.46935164  1.46922583]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777436130008\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "18,0.428274428274,0.777436130008,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.04121683  1.04130034  1.04245147  1.04228682  1.04133909  1.46949661\n",
      "   1.0411628   1.46936786  1.46935164  1.46922583]]\n",
      "19 loss= 7248.23614161  precision loss= 3462687.63929\n",
      "ploss 3462687.63929\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4959.47093039\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.06183501  1.06193261  1.0632744   1.06308399  1.06197754  1.50061702\n",
      "   1.0617717   1.50048749  1.50047101  1.50034267]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777436130008\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "19,0.428274428274,0.777436130008,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.06183501  1.06193261  1.0632744   1.06308399  1.06197754  1.50061702\n",
      "   1.0617717   1.50048749  1.50047101  1.50034267]]\n",
      "20 loss= 7300.64862156  precision loss= 3449381.57045\n",
      "ploss 3449381.57045\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4940.68260762\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.08230942  1.08242342  1.08398715  1.08376707  1.08247549  1.53161955\n",
      "   1.08223529  1.53148906  1.5314723   1.53134119]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777436130008\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "20,0.428274428274,0.777436130008,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.08230942  1.08242342  1.08398715  1.08376707  1.08247549  1.53161955\n",
      "   1.08223529  1.53148906  1.5314723   1.53134119]]\n",
      "21 loss= 7353.47351122  precision loss= 3436418.99591\n",
      "ploss 3436418.99591\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4922.37648659\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.10265442  1.10278731  1.10460675  1.10435279  1.10284749  1.56251271\n",
      "   1.10256783  1.56238107  1.562364    1.56222987]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777436130008\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "21,0.428274428274,0.777436130008,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.10265442  1.10278731  1.10460675  1.10435279  1.10284749  1.56251271\n",
      "   1.10256783  1.56238107  1.562364    1.56222987]]\n",
      "22 loss= 7406.72874907  precision loss= 3423785.50545\n",
      "ploss 3423785.50545\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4904.53172347\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.12288618  1.12304043  1.1251504   1.1248583   1.12310969  1.59330894\n",
      "   1.12278545  1.59317599  1.59315857  1.59302119]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "22,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.12288618  1.12304043  1.1251504   1.1248583   1.12310969  1.59330894\n",
      "   1.12278545  1.59317599  1.59315857  1.59302119]]\n",
      "23 loss= 7460.43592683  precision loss= 3411466.86145\n",
      "ploss 3411466.86145\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4887.12850375\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.14302072  1.14319863  1.14563306  1.14529872  1.1432778   1.62402135\n",
      "   1.14290427  1.62388694  1.62386915  1.62372828]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "23,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.14302072  1.14319863  1.14563306  1.14529872  1.1432778   1.62402135\n",
      "   1.14290427  1.62388694  1.62386915  1.62372828]]\n",
      "24 loss= 7514.61663813  precision loss= 3399449.81261\n",
      "ploss 3399449.81261\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4870.14868375\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.16307327  1.16327674  1.16606637  1.16568615  1.16336637  1.65466228\n",
      "   1.16293973  1.65452626  1.65450808  1.65436351]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "24,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.16307327  1.16327674  1.16606637  1.16568615  1.16336637  1.65466228\n",
      "   1.16293973  1.65452626  1.65450808  1.65436351]]\n",
      "25 loss= 7569.29101185  precision loss= 3387722.32796\n",
      "ploss 3387722.32796\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4853.57589123\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.18305814  1.18328841  1.18645837  1.18602931  1.18338866  1.68524271\n",
      "   1.18290655  1.68510497  1.68508636  1.68493787]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "25,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.18305814  1.18328841  1.18645837  1.18602931  1.18338866  1.68524271\n",
      "   1.18290655  1.68510497  1.68508636  1.68493787]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 loss= 7624.47724953  precision loss= 3376273.57649\n",
      "ploss 3376273.57649\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4837.39540074\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.20298881  1.20324616  1.2068137   1.2063338   1.20335666  1.71577213\n",
      "   1.20281872  1.71563256  1.7156135   1.71546091]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "26,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.20298881  1.20324616  1.2068137   1.2063338   1.20335666  1.71577213\n",
      "   1.20281872  1.71563256  1.7156135   1.71546091]]\n",
      "27 loss= 7680.19153416  precision loss= 3365093.80777\n",
      "ploss 3365093.80777\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4821.59393178\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.22287782  1.22316137  1.22713426  1.22660257  1.22328108  1.74625864\n",
      "   1.22268948  1.74611714  1.74609761  1.74594072]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "27,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.22287782  1.22316137  1.22713426  1.22660257  1.22328108  1.74625864\n",
      "   1.22268948  1.74611714  1.74609761  1.74594072]]\n",
      "28 loss= 7736.44798967  precision loss= 3354174.20527\n",
      "ploss 3354174.20527\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4806.15943683\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.2427366   1.24304415  1.24742001  1.24683667  1.24317131  1.77670905\n",
      "   1.242531    1.77656553  1.77654551  1.77638413]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "28,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.2427366   1.24304415  1.24742001  1.24683667  1.24317131  1.77670905\n",
      "   1.242531    1.77656553  1.77654551  1.77638413]]\n",
      "29 loss= 7793.25858045  precision loss= 3343506.74369\n",
      "ploss 3343506.74369\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4791.08090628\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.26257513  1.26290307  1.26766999  1.26703605  1.26303521  1.80712908\n",
      "   1.26235411  1.80698346  1.80696292  1.80679689]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "29,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.26257513  1.26290307  1.26766999  1.26703605  1.26303521  1.80712908\n",
      "   1.26235411  1.80698346  1.80696292  1.80679689]]\n",
      "30 loss= 7850.63299198  precision loss= 3333084.06202\n",
      "ploss 3333084.06202\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4776.34819956\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.28240185  1.28274523  1.28788325  1.28720038  1.28287919  1.83752348\n",
      "   1.28216814  1.83737569  1.83735462  1.83718376]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "30,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.28240185  1.28274523  1.28788325  1.28720038  1.28287919  1.83752348\n",
      "   1.28216814  1.83737569  1.83735462  1.83718376]]\n",
      "31 loss= 7908.57859263  precision loss= 3322899.35554\n",
      "ploss 3322899.35554\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4761.9519035\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.30222364  1.30257621  1.30805947  1.30732952  1.3027083   1.86789623\n",
      "   1.30198099  1.8677462   1.86772456  1.86754872]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "31,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.30222364  1.30257621  1.30805947  1.30732952  1.3027083   1.86789623\n",
      "   1.30198099  1.8677462   1.86772456  1.86754872]]\n",
      "32 loss= 7967.10056126  precision loss= 3312946.28573\n",
      "ploss 3312946.28573\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4747.88321571\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.32204587  1.32240017  1.3281989   1.32742349  1.32252633  1.8982506\n",
      "   1.32179923  1.89809827  1.89807605  1.89789506]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "32,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.32204587  1.32240017  1.3281989   1.32742349  1.32252633  1.8982506\n",
      "   1.32179923  1.89809827  1.89807605  1.89789506]]\n",
      "33 loss= 8026.20214524  precision loss= 3303218.90628\n",
      "ploss 3303218.90628\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4734.13384946\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.34187219  1.34221955  1.34830168  1.34748193  1.34233564  1.92858933\n",
      "   1.34162796  1.92843463  1.92841181  1.92822551]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "33,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.34187219  1.34221955  1.34830168  1.34748193  1.34233564  1.92858933\n",
      "   1.34162796  1.92843463  1.92841181  1.92822551]]\n",
      "34 loss= 8085.88486401  precision loss= 3293711.60232\n",
      "ploss 3293711.60232\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4720.69595483\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.36170463  1.36203506  1.36836782  1.36750423  1.36213742  1.95891466\n",
      "   1.36147094  1.95875753  1.95873409  1.95854232]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "34,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.36170463  1.36203506  1.36836782  1.36750423  1.36213742  1.95891466\n",
      "   1.36147094  1.95875753  1.95873409  1.95854232]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 loss= 8146.14851999  precision loss= 3284419.04057\n",
      "ploss 3284419.04057\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4707.56205304\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.38154429  1.38184651  1.38839808  1.38749071  1.38193233  1.98922845\n",
      "   1.38133117  1.98906884  1.98904474  1.98884736]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "35,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.38154429  1.38184651  1.38839808  1.38749071  1.38193233  1.98922845\n",
      "   1.38133117  1.98906884  1.98904474  1.98884736]]\n",
      "36 loss= 8206.99101002  precision loss= 3275336.12815\n",
      "ploss 3275336.12815\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4694.72498226\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.40139153  1.40165371  1.40839456  1.40744373  1.40172139  2.01953223\n",
      "   1.40121061  2.01937007  2.01934531  2.01914215]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "36,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.40139153  1.40165371  1.40839456  1.40744373  1.40172139  2.01953223\n",
      "   1.40121061  2.01937007  2.01934531  2.01914215]]\n",
      "37 loss= 8268.40815383  precision loss= 3266457.97729\n",
      "ploss 3266457.97729\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4682.17784798\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.421246    1.42145789  1.42836219  1.42736873  1.4215072   2.04982728\n",
      "   1.42110967  2.04966252  2.04963707  2.04942798]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "37,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.421246    1.42145789  1.42836219  1.42736873  1.4215072   2.04982728\n",
      "   1.42110967  2.04966252  2.04963707  2.04942798]]\n",
      "38 loss= 8330.3933395  precision loss= 3257779.87305\n",
      "ploss 3257779.87305\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4669.91397621\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.44110585  1.44126079  1.44831012  1.44727505  1.44129277  2.0801147\n",
      "   1.44102684  2.07994728  2.07992111  2.07970594]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "38,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.44110585  1.44126079  1.44831012  1.44727505  1.44129277  2.0801147\n",
      "   1.44102684  2.07994728  2.07992111  2.07970594]]\n",
      "39 loss= 8392.93743578  precision loss= 3249297.24468\n",
      "ploss 3249297.24468\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4657.92688358\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.46096635  1.4610615   1.46824836  1.46717343  1.46107714  2.11039549\n",
      "   1.46095676  2.11022534  2.11019844  2.10997703]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777430083144\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819194219149\n",
      "\n",
      "39,0.428274428274,0.777430083144,0.49569707401,0.819194219149\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.46096635  1.4610615   1.46824836  1.46717343  1.46107714  2.11039549\n",
      "   1.46095676  2.11022534  2.11019844  2.10997703]]\n",
      "40 loss= 8456.03030362  precision loss= 3241005.64793\n",
      "ploss 3241005.64793\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4646.21026589\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.48082231  1.48085803  1.48818495  1.48707228  1.48085727  2.14067056\n",
      "   1.48089028  2.14049762  2.14046995  2.14024216]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777407911313\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819314253424\n",
      "\n",
      "40,0.428274428274,0.777407911313,0.49569707401,0.819314253424\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.48082231  1.48085803  1.48818495  1.48707228  1.48085727  2.14067056\n",
      "   1.48089028  2.14049762  2.14046995  2.14024216]]\n",
      "41 loss= 8519.66265256  precision loss= 3232900.75803\n",
      "ploss 3232900.75803\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4634.75798763\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.50067091  1.50065118  1.50812667  1.50697786  1.50063343  2.1709407\n",
      "   1.50081822  2.17076492  2.17073646  2.17050212]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777438145629\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "41,0.428274428274,0.777438145629,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.50067091  1.50065118  1.50812667  1.50697786  1.50063343  2.1709407\n",
      "   1.50081822  2.17076492  2.17073646  2.17050212]]\n",
      "42 loss= 8583.82707262  precision loss= 3224978.36156\n",
      "ploss 3224978.36156\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4623.56407148\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.52051085  1.52044299  1.52807729  1.52689336  1.52040847  2.20120665\n",
      "   1.52073378  2.20102795  2.20099868  2.20075764]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777438145629\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "42,0.428274428274,0.777438145629,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.52051085  1.52044299  1.52807729  1.52689336  1.52040847  2.20120665\n",
      "   1.52073378  2.20102795  2.20099868  2.20075764]]\n",
      "43 loss= 8648.51835468  precision loss= 3217234.34949\n",
      "ploss 3217234.34949\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4612.62269371\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.54034227  1.54023504  1.5480375   1.54681927  1.54018538  2.23146904\n",
      "   1.54063385  2.23128736  2.23125725  2.23100936]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.777438145629\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "43,0.428274428274,0.777438145629,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.54034227  1.54023504  1.5480375   1.54681927  1.54018538  2.23146904\n",
      "   1.54063385  2.23128736  2.23125725  2.23100936]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 loss= 8713.73271494  precision loss= 3209664.71611\n",
      "ploss 3209664.71611\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4601.92818284\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.56016664  1.56002825  1.56800665  1.56675488  1.55996585  2.26172843\n",
      "   1.56051845  2.26154371  2.26151273  2.26125783]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "44,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.56016664  1.56002825  1.56800665  1.56675488  1.55996585  2.26172843\n",
      "   1.56051845  2.26154371  2.26151273  2.26125783]]\n",
      "45 loss= 8779.46674088  precision loss= 3202265.55904\n",
      "ploss 3202265.55904\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4591.47501636\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.57998598  1.57982308  1.58798391  1.58669915  1.57975025  2.29198528\n",
      "   1.58038945  2.29179746  2.29176559  2.29150352]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "45,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.57998598  1.57982308  1.58798391  1.58669915  1.57975025  2.29198528\n",
      "   1.58038945  2.29179746  2.29176559  2.29150352]]\n",
      "46 loss= 8845.71682454  precision loss= 3195033.07637\n",
      "ploss 3195033.07637\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4581.25781419\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.59980209  1.59961968  1.60796852  1.60665098  1.59953822  2.32223998\n",
      "   1.6002494   2.32204899  2.32201619  2.3217468 ]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "46,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.59980209  1.59961968  1.60796852  1.60665098  1.59953822  2.32223998\n",
      "   1.6002494   2.32204899  2.32201619  2.3217468 ]]\n",
      "47 loss= 8912.47899523  precision loss= 3187963.56158\n",
      "ploss 3187963.56158\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4571.27133019\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.61961637  1.61941805  1.62795983  1.62660931  1.61932925  2.35249282\n",
      "   1.62010088  2.35229858  2.35226484  2.35198796]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "47,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.61961637  1.61941805  1.62795983  1.62660931  1.61932925  2.35249282\n",
      "   1.62010088  2.35229858  2.35226484  2.35198796]]\n",
      "48 loss= 8979.7488916  precision loss= 3181053.39767\n",
      "ploss 3181053.39767\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4561.51044353\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.63942975  1.63921809  1.64795731  1.6465733   1.63912288  2.38274405\n",
      "   1.63994619  2.38254649  2.38251176  2.38222724]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "48,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.63942975  1.63921809  1.64795731  1.6465733   1.63912288  2.38274405\n",
      "   1.63994619  2.38254649  2.38251176  2.38222724]]\n",
      "49 loss= 9047.52178397  precision loss= 3174299.05146\n",
      "ploss 3174299.05146\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4551.97015096\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.65924287  1.65901967  1.66796057  1.66654231  1.6589187   2.41299384\n",
      "   1.65978722  2.41279289  2.41275715  2.41246481]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "49,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.65924287  1.65901967  1.66796057  1.66654231  1.6589187   2.41299384\n",
      "   1.65978722  2.41279289  2.41275715  2.41246481]]\n",
      "50 loss= 9115.79262507  precision loss= 3167697.06872\n",
      "ploss 3167697.06872\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4542.64556034\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.67905613  1.67882264  1.68796934  1.68651596  1.6787164   2.44324234\n",
      "   1.67962546  2.44303792  2.44300115  2.44270083]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "50,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.67905613  1.67882264  1.68796934  1.68651596  1.6787164   2.44324234\n",
      "   1.67962546  2.44303792  2.44300115  2.44270083]]\n",
      "51 loss= 9184.55611069  precision loss= 3161244.07008\n",
      "ploss 3161244.07008\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4533.5318855\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.69886979  1.69862688  1.70798344  1.70649397  1.69851572  2.47348967\n",
      "   1.69946202  2.47328171  2.47324386  2.47293539]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "51,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.69886979  1.69862688  1.70798344  1.70649397  1.69851572  2.47348967\n",
      "   1.69946202  2.47328171  2.47324386  2.47293539]]\n",
      "52 loss= 9253.80673647  precision loss= 3154936.74781\n",
      "ploss 3154936.74781\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4524.62444212\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.71868404  1.71843228  1.72800276  1.72647622  1.71831647  2.50373593\n",
      "   1.71929775  2.50352435  2.5034854   2.5031686 ]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "52,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.71868404  1.71843228  1.72800276  1.72647622  1.71831647  2.50373593\n",
      "   1.71929775  2.50352435  2.5034854   2.5031686 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 loss= 9323.53884498  precision loss= 3148771.86326\n",
      "ploss 3148771.86326\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4515.91864439\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.73849901  1.73823875  1.74802727  1.74646266  1.73811849  2.53398121\n",
      "   1.73913326  2.53376593  2.53372583  2.53340053]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "53,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.73849901  1.73823875  1.74802727  1.74646266  1.73811849  2.53398121\n",
      "   1.73913326  2.53376593  2.53372583  2.53340053]]\n",
      "54 loss= 9393.74666248  precision loss= 3142746.24479\n",
      "ploss 3142746.24479\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4507.41000232\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.75831476  1.75804622  1.76805694  1.76645328  1.75792168  2.56422557\n",
      "   1.75896899  2.56400649  2.56396522  2.56363123]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "54,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.75831476  1.75804622  1.76805694  1.76645328  1.75792168  2.56422557\n",
      "   1.75896899  2.56400649  2.56396522  2.56363123]]\n",
      "55 loss= 9464.42432685  precision loss= 3136856.78607\n",
      "ploss 3136856.78607\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4499.09411949\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.77813137  1.77785464  1.7880918   1.78644811  1.77772593  2.59446907\n",
      "   1.77880525  2.59424611  2.59420364  2.59386077]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "55,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.77813137  1.77785464  1.7880918   1.78644811  1.77772593  2.59446907\n",
      "   1.77880525  2.59424611  2.59420364  2.59386077]]\n",
      "56 loss= 9535.56590873  precision loss= 3131100.44462\n",
      "ploss 3131100.44462\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4490.96669106\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.79794886  1.79766397  1.80813189  1.80644721  1.79753118  2.62471176\n",
      "   1.79864229  2.62448484  2.62444111  2.62408919]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "56,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.79794886  1.79766397  1.80813189  1.80644721  1.79753118  2.62471176\n",
      "   1.79864229  2.62448484  2.62444111  2.62408919]]\n",
      "57 loss= 9607.1654275  precision loss= 3125474.24064\n",
      "ploss 3125474.24064\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4483.02350203\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.81776727  1.81747416  1.82817727  1.82645063  1.81733738  2.6549537\n",
      "   1.81848027  2.65472272  2.65467771  2.65431654]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "57,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.81776727  1.81747416  1.82817727  1.82645063  1.81733738  2.6549537\n",
      "   1.81848027  2.65472272  2.65467771  2.65431654]]\n",
      "58 loss= 9679.21686352  precision loss= 3119975.25582\n",
      "ploss 3119975.25582\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4475.2604256\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.8375866   1.8372852   1.84822801  1.84645845  1.83714447  2.68519492\n",
      "   1.83831929  2.68495979  2.68491345  2.68454283]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "58,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.8375866   1.8372852   1.84822801  1.84645845  1.83714447  2.68519492\n",
      "   1.83831929  2.68495979  2.68491345  2.68454283]]\n",
      "59 loss= 9751.71416784  precision loss= 3114600.63232\n",
      "ploss 3114600.63232\n",
      "ratio 0.0\n",
      "dev set\n",
      "init dev loss 4467.67342166\n",
      "alphas= [ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ]\n",
      "thetas= [[ 1.85740687  1.85709705  1.86828418  1.86647075  1.85695241  2.71543547\n",
      "   1.85815945  2.71519609  2.71514839  2.71476812]]\n",
      "Unique,counts of marginals {0: 2522, 1: 292}\n",
      "acc 0.902274342573\n",
      "devresults  (0.35273972602739728, 0.544973544973545, 0.4282744282744283, None)\n",
      "roc score 0.77744016125\n",
      "\n",
      "test set\n",
      "{0: 2339, 1: 363}\n",
      "acc 0.89156180607\n",
      "testresults  (0.39669421487603307, 0.66055045871559637, 0.49569707401032703, None)\n",
      "roc score 0.819321640148\n",
      "\n",
      "59,0.428274428274,0.77744016125,0.49569707401,0.819321640148\n",
      "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
      "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 1.85740687  1.85709705  1.86828418  1.86647075  1.85695241  2.71543547\n",
      "   1.85815945  2.71519609  2.71514839  2.71476812]]\n"
     ]
    }
   ],
   "source": [
    "#added 2\n",
    "r42d = []\n",
    "r42t = []\n",
    "\n",
    "\n",
    "a = 0.80\n",
    "\n",
    "ua = np.repeat(a, len(LF_l))\n",
    "\n",
    "stdout_saved = orig_stdout\n",
    "# for rx in [1, len(LF_l), len(train_L_S)]:\n",
    "# for i in np.linspace(1,1,1):\n",
    "b = 32\n",
    "\n",
    "\n",
    "print(discr)\n",
    "for pen_i in [111]: # [101,102,103,104,105,106,111,112,113,114,115,116]:#[0, 4, 42]:\n",
    "# for b in [32]:#[32,64,128,512,1024,2048,4096]:\n",
    "    print(int(pen_i)//10 % 10)\n",
    "    devmax = np.zeros(3)\n",
    "    testmax = np.zeros(3)\n",
    "    for gg in range(1):#[1]:#np.linspace(0,100,101):#, 10, 30, 50, 100]:\n",
    "#         print(\"batch-size:\",b, \"gamma:\",gg)\n",
    "        print('============', pen_i)\n",
    "        # sys.stdout = open('trash', 'w')\n",
    "#        sys.stdout = stdout_saved\n",
    "        _, _, _, ops = train2(1/len(train_L_S),200,batch_size = b, th = tf.truncated_normal_initializer(1,0,seed),\\\n",
    "                                    af = tf.truncated_normal_initializer(0,0.1,seed),\\\n",
    "                                    user_a = ua, \\\n",
    "                                    LF_acc = np.repeat(0.4, len(LF_l)) ,pcl=np.array([-1,1],dtype=np.float64),\\\n",
    "                                    norm=True,smooth=True,penalty=pen_i, Gamma=gg, debug=False,\\\n",
    "                                    a_pr = np.repeat(0.750, len(LF_l)), \\\n",
    "                                           n_pr = np.repeat(600, len(LF_l)),\\\n",
    "                                     isdiscrete = dscr, alpha_max=np.repeat(0.9, len(LF_l)),\n",
    "                             r_pr = np.repeat(0.750, len(LF_l)))\n",
    "        sys.stdout = orig_stdout\n",
    "# get_LF_acc(dev_L_S,gold_labels_dev)\n",
    "#                 if(devmax_t[2]>devmax[2]):\n",
    "#         devmax = np.array(devmax_t)\n",
    "#                 if(testmax_t[2]>testmax[2]):\n",
    "#         testmax = np.array(testmax_t)\n",
    "#         r42d.append(devmax)\n",
    "#         r42t.append(testmax)\n",
    "#         print(\"\\n\\nfinal_result_line: \",\"thetas:\",0,0.1,\"batch size\",b,\"penalty\",pen_i,)\n",
    "##        sys.stdout = stdout_saved\n",
    "#         print(\"\\n\\nfinal_result_line: \",\"thetas:\",0,0.1,\"batch size\",b,\"penalty\",pen_i,)\n",
    "# sys.stdout = open('opfile2', 'a')\n",
    "# print('rate = 1/train_len')      \n",
    "# sys.stdout = stdout_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1,0.43006263048,0.762761400857,0.498327759197,0.818907060231\n",
    "[ 0.11754463 -0.18578547  0.06448096  0.05554933  0.10637787  0.04133855\n",
    "  0.22405651 -0.02316195  0.09187082  0.01032644] [[ 0.94514111  0.94514112  0.94514827  0.94514484  0.94514112  1.05462089\n",
    "   0.9452137   1.05444394  1.05452913  1.05446836]]\n",
    "   \n",
    "   Cont: 111\n",
    "   10,0.407002188184,0.746422776518,0.483636363636,0.80223891622\n",
    "[ 0.11754463 -0.18578547  0.1191033   0.11100223  0.10637787  0.04133855\n",
    "  0.26315504 -0.05675751  0.04734599 -0.02641954] [[ 0.90034616  0.90035037  0.89118076  0.89039836  0.90035211  1.12112825\n",
    "   0.90581917  1.08926482  1.09932218  1.09215784]]\n",
    "   \n",
    "   Cont: 112\n",
    "   9,0.296052631579,0.685242630385,0.375,0.737930092039\n",
    "[ 0.11754463 -0.18578547  0.16593194  0.15628545  0.10637787  0.04133855\n",
    "  0.32336718 -0.11055429 -0.00683302 -0.08423155] [[ 0.84517908  0.84518043  0.85065344  0.85047745  0.84518095  1.16100097\n",
    "   0.85390063  1.16385916  1.16524347  1.16419562]]\n",
    "\n",
    "    Cont: 112 with max_alpha = 0.7\n",
    "    140,0.414587332054,0.780391030486,0.481300813008,0.830555924892\n",
    "[ 1.11754463  0.81421453  1.00955965  1.00062431  1.10637787  1.04133855\n",
    "  1.169206    1.03120785  1.14633471  1.0647233 ] [[ 0.2137293   0.22307502  4.16844262  3.91339975  0.23617798  1.17968475\n",
    "   0.48896712  2.30967195  2.14310226 -0.46482738]]\n",
    "   \n",
    "   Discrete: 111\n",
    "   10,0.428274428274,0.777492567397,0.49569707401,0.819183139062\n",
    "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
    "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.82293943  0.82294084  0.82296135  0.82295826  0.82294152  1.18440805\n",
    "   0.82293851  1.18439077  1.18438875  1.18437385]]\n",
    "   \n",
    "   Discrete: 112\n",
    "   10,0.428274428274,0.777492567397,0.49569707401,0.819183139062\n",
    "[ 0.11754463 -0.18578547  0.00955965  0.00062431  0.10637787  0.04133855\n",
    "  0.169206    0.03120785  0.14633471  0.0647233 ] [[ 0.82293943  0.82294084  0.82296135  0.82295826  0.82294152  1.18440805\n",
    "   0.82293851  1.18439077  1.18438875  1.18437385]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
